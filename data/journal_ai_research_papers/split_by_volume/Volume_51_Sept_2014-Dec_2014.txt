Journal of Artificial Intelligence Research 51 (2014) 533-554

Submitted 02/14; published 10/14

Optimal Scheduling of Contract Algorithms for
Anytime Problem-Solving
Alejandro Lopez-Ortiz

alopez-o@uwaterloo.ca

Cheriton School of Computer Science
University of Waterloo
Waterloo, Ontario, Canada, N2L 3G1

Spyros Angelopoulos

spyros.angelopoulos@upmc.fr

CNRS and Laboratoire dInformatique
Universite Pierre et Marie Curie
4 Place Jussieu 75252, France

Angele M. Hamel

ahamel@wlu.ca

Department of Physics and Computer Science
Wilfrid Laurier University
Waterloo, Ontario, Canada, N2L 3C5

Abstract
A contract algorithm is an algorithm which is given, as part of the input, a specified
amount of allowable computation time. The algorithm must then complete its execution
within the allotted time. An interruptible algorithm, in contrast, can be interrupted at
an arbitrary point in time, at which point it must report its currently best solution. It
is known that contract algorithms can simulate interruptible algorithms using iterative
deepening techniques. This simulation is done at a penalty in the performance of the
solution, as measured by the so-called acceleration ratio.
In this paper we give matching (i.e., optimal) upper and lower bounds for the acceleration ratio under such a simulation. We assume the most general setting in which n problem
instances must be solved by means of scheduling executions of contract algorithms in m
identical parallel processors. This resolves an open conjecture of Bernstein, Finkelstein, and
Zilberstein who gave an optimal schedule under the restricted setting of round robin and
length-increasing schedules, but whose optimality in the general unrestricted case remained
open.
Lastly, we show how to evaluate the average acceleration ratio of the class of exponential
strategies in the setting of n problem instances and m parallel processors. This is a broad
class of schedules that tend to be either optimal or near-optimal, for several variants of the
basic problem.

1. Introduction
Anytime algorithms are algorithms whose quality of output improves gradually as the
amount of available computation time increases. This class of algorithms was introduced
first by Dean and Boddy (1988) in the context of time-depending planning, as well as by
Horvitz (1987, 1998) in the context of flexible computation. Anytime algorithms occur
c
2014
AI Access Foundation. All rights reserved.

fiLopez-Ortiz, Angelopoulos, & Hamel

naturally in settings where a computationally intensive problem is addressed under uncertainty with respect to the available computation time. An example of this is a problem in
which the answer must be provided when determined by an external input over which we
have no control. For instance, consider an automated trading program for the stock market.
These programs run time-intensive simulations to price various financial instruments. When
a change in the bid price of a given stock occurs the algorithm must produce a decision
(buy/sell/hold) at that very instant, using whatever information it had garnished over the
course of the simulations, so as to take advantage of the newly posted price. Another example is given by real-time applications. For instance, consider a motion planning algorithm
for a robot in which a solution must be produced within a certain, but varying, amount
of time: for example if a robot is about to collide a move is needed momentarily even if
the algorithm is to produce a suboptimal move, while in others, there is sufficient time to
carefully compute the next step. In this situation, the amount of allotted time is given to
the algorithm beforehand.
According to Russell and Zilberstein (1991), a further distinction can be made between
two different types of anytime algorithms. On the one hand, interruptible algorithms are
algorithms whose allowable running time is not known in advance, and thus can be interrupted (queried) at any given point throughout their execution. Such algorithms typically
include versions of local search, e.g., simulated annealing and hill climbing. On the other
hand, the more stringent class of contract algorithms consists of algorithms which are given
the amount of allowable computation time (i.e, the intended query time) as part of the
input. However, if the algorithm is interrupted at any point before the contract time expires, the algorithm may not return any meaningful results. Such algorithms are thus less
flexible than interruptible algorithms, however they tend to be simpler to construct, and
it is easier to prove strict guarantees on their performance. A typical example of contract
algorithms are polynomial-time approximation schemes (PTAS) based on Dynamic Programming (DP): the bigger the amount of computation time, the better an approximation
is achieved. However, the algorithm may require all the available computation time in order to fill in the important entries of the DP table, otherwise the solution returned may be
useless.
Consider then the following general scenario: we are given a set P of n different problem
instances, and we want to design an efficient interruptible algorithm that can be applied,
in a concurrent fashion, to all n problem instances. The amount of computation time is
not known in advance; instead, it is expected that at some unknown point in time, an
interruption will occur, at which point the algorithm is stopped and is queried to report
its (partial) solutions to any one among the problem instances. Clearly, the algorithm
must make judicious use of its resources and ensure that it can produce a reasonably good
solution, despite having no knowledge of the exact time at which interruptions may occur.
As indicated earlier, it is hardly surprising that this setting arises very frequently in the
design of AI systems, in applications such as game-playing programs (Althofer, 1997; Kao,
Reif, & Tate, 1996; Kao, Ma, Sipser, & Yin, 1998), e-trading agents, and medical diagnosis
systems. Essentially the problem captures a fundamental trade-off between the quality of
the solution returned by the algorithm and the amount of available computation time. We
refer the reader to the survey of Zilberstein (1996) for the importance of anytime algorithms
in the design of intelligent systems.
534

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

PTAS (Polynomial Time Approximation Schemes) provide a rich source of contract
algorithms with guaranteed performance. This motivates the study of general constructions
for creating interruptible versions for any given contract algorithm. This provides the
flexibility of focusing only on the design of contract algorithms, then converting them to
interruptible algorithms by applying a standard, black-box transformation. Indeed, a
standard method for simulating an interruptible algorithm is by repeatedly executing the
contract algorithm using increasing execution times. Consider the general setting in which
a set M of m processors of identical speed is available for the execution of this simulation,
and each problem instance has a corresponding (single-thread) contract algorithm. The
problem we face is how to schedule the executions of the various contract algorithms to
the processors in a way that guarantees an efficient interruptible algorithm. In this setting,
at query time, the algorithm will report for each problem instance the solution of the
corresponding contract of longest length (i.e., contract time) which has been completed by
query time.
It becomes obvious that a formal measure of the quality of this simulation is required.
While one may think of several possible ways of evaluating the quality of the simulation, in
our work we adopt the standard measure in this area, namely the acceleration ratio (Russell
& Zilberstein, 1991). A formal definition is provided in Section 2; informally, the acceleration ratio indicates how much faster the processors in M should be in order to guarantee
a solution as good as the one of an ideal algorithm that has foreknowledge not only of the
query time t but also of the problem instance p of interest. Such an ideal algorithm would
simply utilize a single processor to run solely a contract for instance p, up to time t. In a
sense, the acceleration ratio reflects the loss in optimality due to lack of future knowledge
about the query times and the problem instance in question, and is motivated by similar
considerations to the competitive ratio in the context of the analysis of online algorithms.
In the case of one problem instance and a single processor, Russell and Zilberstein (1991)
showed that iterative doubling of contract lengths gives rise to an interruptible algorithm of
acceleration ratio at most four. Zilberstein, Charpillet, and Chassaing (2003) showed that
this is the optimal acceleration ratio, in the sense that any scheduling strategy defined over
any set of contracts has acceleration ratio at least four.
Zilberstein et al. (2003) also studied the generalization of the problem in which multiple
problem instances are considered (assuming |M | = 1), and Bernstein, Perkins, Zilberstein,
and Finkelstein (2002) studied the generalization in which contracts for a single problem
instance must be scheduled in a set of multiple processors. For both versions, algorithms of
optimal acceleration ratios were derived. The problem, in its full generality, involves a set
of processors and a set of problems, both of cardinality greater than one. Bernstein et al.
n m+n m+n
(2003) showed an upper bound of m
( n ) m on the acceleration ratio; in addition, using
elegant techniques, they showed that this bound is optimal for a restricted, though natural
and intuitive, class of schedules that use a round robin and length-increasing strategy. Such
strategies are known as cyclic strategies. Bernstein et al. leave open the question of whether
this bound is tight among all possible schedules. In this paper we answer this question in
the affirmative.
In general, it has been observed that the theoretical analysis of geometric searches and
robot motion planning is closely linked to the scheduling of heuristics and algorithms for
problem solving. This connection was first established by Kao et al. (1996, 1998) in the
535

fiLopez-Ortiz, Angelopoulos, & Hamel

context of randomized algorithms. The work of Bernstein et al. (2003) drew a similar connection between scheduling contract algorithms and robot searching on a set of rays (Alpern
& Gal, 2003). In the latter problem, p robots search for a target that is located in one of
m concurrent rays. We seek a search strategy that minimizes the competitive ratio, namely
the worst-case ratio of the search cost over the distance from the starting position to the
target.
It turns out that interesting parallels can be drawn for the two problems: informally, the
rays correspond to problem instances, the robots to processors, and the (unknown) location
of the target corresponds to the (also unknown) query time. For the general problem of
p robots and m rays Lopez-Ortiz and Schuierer (2004) showed an optimal strategy that
m
m
p
achieves a competitive ratio of 1 + 2 mp
p ( mp ) . Bernstein et al. (2003) independently
derived the same bound by directly translating their approach in the context of contract
scheduling to a solution for robot searching in parallel rays. It should be noted that the
upper bounds in the work of Lopez-Ortiz and Schuierer and Bernstein et al. are based on
exponential strategies. Informally, these are cyclic strategies where the lengths to which the
rays are searched (respectively, the lengths of contracts in the schedule) form a geometric
sequence (see Section 2 for the precise definition).
At an intuitive level, the problem of scheduling contract algorithms on multiple processors is more involved than the problem of multi-robot searching in concurrent rays. This
difficulty stems from the fact that multiple searchers on the same ray are of no benefit,
whereas multiple contract algorithms (of different lengths) on the same problem could very
well improve the performance. However, in this paper we show that the ideas behind the
solution of Lopez-Ortiz and Schuierer (2004) can be adapted, in a non-trivial manner, so
as to show the optimality of the schedule of Bernstein et al. (2003) without any restrictions
(such as cyclicality) on the scheduling strategy.
The problem of removing the assumption of cyclicality has a long history in searchrelated problems. For instance, Jaillet and Stafford (2001) argue rigorously that cyclicality
can be waived for single-searcher problems on m rays (whereas in the original work BaezaYates, Culberson, & Rawlins, 1993, cyclicality is implicit). Along the same lines, LopezOrtiz and Schuierer (2004) remove cyclicality assumptions in the context of multi-searcher
problems. Similar conclusions are harder to establish concerning randomized algorithms
(for instance, see Schuierer, 2003). In a sense, cyclic strategies are simple to analyze and
provide relatively easy upper bounds; however, the difficulty lies in establishing optimality
within the space of all possible strategies.
The remainder of this paper is organized as follows. In Section 2 we present a formal
discussion of the problem setting. Our main result, namely Theorem 3, is presented in Section 3 where we show the optimality of the exponential schedule of Bernstein et al. (2003)
without any restrictions. In Section 4 we present an average-case analysis of the acceleration ratio of exponential strategies in the multi-processor setting, assuming a uniform
distribution of the interruption times.

2. Preliminaries
Let P denote the set of n problem instances or simply problems. A contract c is a pair
(p, d), where p  P denotes the problem instance to which c is assigned (also called the
536

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

problem tag of c) and d the duration or length of the contract, which specifies the processing
time required to complete c. We denote by M the set of m identical processors. Let C
denote a (potentially infinite) set of contracts. Define a schedule X for a set of contracts C
as a feasible assignment of all contracts in C to the set M of m processors. In particular,
X can be described as the set {(ci , mi , si ) : ci  C}, where mi  {0, . . . , m  1} denotes
the processor to which ci is scheduled, and si denotes the time its processing begins. The
schedule X must be feasible, in the sense that for any two contracts ci = (pi , di ), cj = (pj , dj )
in C that are assigned to the same processor by X, and such that cj is scheduled immediately
after ci , we have that si + di  sj . In other words, cj does not start before ci has been
completed. Note that we assume non-preemptive schedules, in the sense that we cannot
interrupt and later resume a contract.
Observation 1 Without loss of generality we consider only schedules in which the processors are never idle, i.e., the start time of a contract is always the finish time of another
contract.
For n problem instances and m identical processors, Bernstein et al. (2003) define the
class of cyclic schedules as schedules which have the following natural properties:
1. Property 1 (Problem Round Robin) If ci = (pi , di ) is the ith contract in the cyclic
schedule order, the problem instance pi is such that pi = i mod n.
2. Property 2 (Length Increasing) For all ci = (pi , di ) and cj = (pj , dj ) if pi = pj and
i < j, then di < dj .
3. Property 3 (Processor Round Robin) mi = i mod m for all i.
An exponential schedule is a cyclic schedule in which the lengths of contracts in the roundrobin order increase exponentially. More formally, the i-th contract in the order has length
bi for some fixed number b.
We use the acceleration ratio as the standard measure of evaluating the quality of a
schedule. Following Bernstein et al. (2003), we assume that when a contract is completed
at time t its solution is available when the interruption occurs at any time after, or including
time t. We also limit the interruptions to occur only after at least one contract for each
problem in P has completed, otherwise the problem is vacuous (this is again a canonical
assumption). Denote by lX (p, t) the length of the longest contract for problem p that has
been completed by or at time t in X (if there is no source of confusion we omit the subscript.)
Definition 1 Given a set P of n problem instances and a set M of m processors of identical
speed, the acceleration ratio of a schedule X for P , denoted by Rm,n (X) is defined as the
smallest value r, with r  1 such that for any allowable interruption time t, and any
problem p  P , we have that lX (p, t)  t/r. Then the acceleration ratio for P and a set M
of processors of identical speed is defined as

Rm,n
= inf Rm,n (X).
X

 .
A schedule X is optimal if Rm,n (X) = Rm,n

537

fiLopez-Ortiz, Angelopoulos, & Hamel

We argue that for a given schedule X, the acceleration ratio Rm,n (X) can be determined
by looking at a discrete subset of the timeline, instead of at all possible interruption times t.
Let  denote an infinitesimally small positive value, and let F denote the set of finish times
of all contracts in X. Then it is easy to see that it suffices to consider interruptions that
occur only at times t  , for all t  F . To see this, consider a certain interruption t that
does not conform with the above rule, and let t0 be the earliest time in which a contract
finishes in X such that t0  > t. Then for all problems p, l(p, t0 ) = l(p, t); in other words
the algorithm has not made any progress on any problem on the time interval [t, t0  ], thus
t/l(p, t) < (t0  )/l(p, t0  ).
The following is essentially an alternative definition of the acceleration ratio, based on
the above observation.
Observation 2 (Bernstein et al., 2003) Let F denote the set of all finish times of contracts in the schedule X. The acceleration ratio of a schedule X for P is




t
t
Rm,n (X) = sup
= sup
.
l(p, t)
p,t
p,tF,0 l(p, t  )
For a given interruption time t, let p (t) denote the function t/l(p, t). In other words, the
acceleration ratio of X is simply the maximum value of p (t), over all possible interruption
times t and all problem instances p. Figure 1 illustrates an example of a schedule for
2 problem instances and 4 processors. Note how the value of p peaks just before each
contract is completed, for each problem instance.
Given a schedule X with associated set of contracts C, and two problem instances
p1 , p2  P , let C1 , C2 denote two (potentially infinite) subsets of C, such that all contracts
in C1 have problem tag p1 , and all contracts in C2 have problem tag p2 . Consider a new
set of contracts C 0 which is identical to C, with the exception that every contract in C1
acquires problem tag p2 instead of p1 and every contract in C2 acquires problem tag p1
instead of p2 . Consider also the schedule X 0 which is otherwise identical to X (except for
the problem tag swaps described above). We say that X 0 is obtained from X by a swap for
sets C1 and C2 .
Following the convention of Lopez-Ortiz and Schuierer (2004), given two schedules X
and X 0 , we say that X is contained in X 0 up to time T , denoted by X T X 0 if the two
schedules are identical up to time T . Given a sequence of schedules V = (X1 , X2 , . . .) we
say that V converges to a limit schedule X if for all T > 0 there exists N such that for all
m  N , Xm T Xm+1 . The limit schedule X is defined in the obvious way.

3. A Matching Lower Bound on the Acceleration Ratio
In this section we prove a lower bound on the acceleration ratio which applies to all schedules. Before we proceed with the proof of the main result, we present the intuition behind
our approach which is illustrated in Figure 2. Given an arbitrary schedule, we implement
transformations that successively transform it into schedules complying with certain regularization conditions (see Lemma 1, Lemma 2, and Theorem 1 below). These transformations
either preserve or reduce the acceleration ratio, and their purpose is to infuse a certain
amount of structure into the schedule. It is important to observe that the transformation
538

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

Processor 0
Processor 1
Processor 2
Processor 3

6
5

 p (t)

4
3
2
1

1

2

3

4

5

6

7

8

9

10

Time

Figure 1: The top figure depicts a schedule of contracts for the case of 4 processors and
2 problems, for the first ten time units. Here, the white and hatched rectangles
correspond to executions of contracts for the two problems, respectively, with no
idle time in the schedule. The bottom figure depicts the plots of the function
p (t) vs time for the two problems (p  {1, 2}). The hatched (white) area on
top corresponds to the solid (hashed) line plot on the bottom (respectively). The
acceleration ratio is the maximum value, on the y axis, attained by either curve,
and in this example it is equal to 4.

of Theorem 1 might actually result in an object which is a non-feasible schedule, but with
a well defined acceleration ratio which is, once again, shown to be no greater than that of
the original schedule. We then lower-bound the acceleration ratio of all the obtained (i.e.,
normalized) schedules, and show that it matches the upper bound of Bernstein et al. (2003).
A similar approach in showing optimality of cyclic strategies was applied by Lopez-Ortiz
and Schuierer (2004), in the context of parallel robot searching in concurrent rays. We need
to emphasize, however, that the series of transformations for the problem we consider in
this paper differ significantly from the ones by Lopez-Ortiz and Schuierer. This is due to
the fact that for the ray-searching problem it is easier to argue about structural properties
of the optimal algorithm. Consider the following example. Suppose that by time t, a given
ray r has been explored up to distance d. Then an optimal algorithm (and indeed every
reasonable search algorithm) must be such that at any time t0 > t, if a robot explores ray
r, then it will proceed at least up to distance d from the origin (otherwise, the algorithm
gains nothing from this exploration). In contrast, in the scheduling problem we consider
in this paper, it may be the case that in a certain processor M1 , a contract of length l is
scheduled with start time t and finish time t + l, whereas in a different processor M2 , a
different contract for the same problem is scheduled with start time bigger than t and finish
time smaller than t + l (i.e., of length smaller than l). At first sight, the latter contract
539

fiLopez-Ortiz, Angelopoulos, & Hamel

appears to be redundant; however if l is too large, and an interruption occurs right before
t + l, then the schedule may gain from the smaller-length contract. In fact, such schedules
are indeed possible in an optimal algorithm, as they are not ruled out by our transformation
techniques. In particular, the above example illustrates that it is difficult to give a blackbox transformation of the proof by Lopez-Ortiz and Schuierer to our problem of interest
(although it would be very interesting to obtain such an explicit reduction).
(worst)
Space of all schedules
Lemma 1
acceleration
ratio

Lemma 2
Theorem 1

(best)

Figure 2: Illustration of the proof technique. The shaded region corresponds to artificial,
and possibly infeasible, strategies which are by-products of the proof and could
in principle have acceleration ratio strictly smaller than the optimal acceleration
ratio; however, we show that this never happens, thus the shaded region collapses
to the line of all strategies and non-strategies with acceleration ratio exactly equal
to the optimal value.
Note that we can assume, without loss of generality, that the schedule does not start a
contract that is smaller than or equal to one that has already been completed on a given
problem.
Let X be a given schedule of contracts. We will follow the convention of denoting by
lower-case d and upper-case D the lengths of a pair of consecutively completed contracts,
for a given problem p, respectively. More precisely, if (pi , di ) denotes a contract of length
di for problem pi , then the earliest contract in X for pi which is completed after contract
(pi , di ) finishes will be denoted by (pi , Di ).
Definition 2 For a schedule X of contracts, given a contract c of length Dc we define the
acceleration ratio at Dc (that is, immediately before the completion of c in X) as r(c) =
(Tc + Dc )/dc (assuming dc 6= 0), where Tc denotes the time when a processor is to start
working on the contract (pc , Dc ).
In particular, let C 0 denote the set of all contracts in the schedule, excluding the first
completed contract for each problem. Then from Observation 2,
Rm,n (X) =

sup
cC 0 ,0

which converges to supcC 0 r(c).
540

Tc + Dc  
dc

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

The following lemma establishes a quasi-cyclic property of an optimal strategy schedule.
It states that a problem with a shorter-length completed contract should generally be given
precedence over another problem with a longer completed contract; there is one possible
exception: if the smaller-length contract is passed over during a processor assignment then
the next contract in its schedule must be shorter than the one assigned to any problem that
went ahead instead.
Lemma 2 establishes another facet of the quasi-cyclicality property: a problem with
a shorter-length contract, whether favored or not in its next processor assignment, must
complete its next contract before any other problem with a longer completed contract, thus
re-establishing a quasi-cyclic property.
Lemma 1 Consider a schedule X, and suppose that at time Ti a processor is to start
working on contract (pi , Di ) for which there is another problem pj with contracts (pj , dj )
and (pj , Dj ) in X. Let Tj denote the time at which a processor is to start working on
contract (pj , Dj ).
Given any two problems pi and pj as described above for which dj < di and Tj > Ti , then
either Dj < Di or we can define a new schedule such that Dj < Di , and whose acceleration
ratio is no worse than that of the original schedule.
Proof. Suppose X is such that dj < di and Tj > Ti , and suppose that Dj > Di . Execute
a swap of program tags for all contracts on pi that complete after (pi , di ) and all contracts
on pj that complete after (pj , dj ), so as to obtain a new schedule X 0 (recall the definition
of problem swapping, as given in Section 2).
Observe that all contracts before the swapping remain untouched. Likewise, contracts
for problems not involved in the swap are also unaffected. Therefore, the contribution of
the acceleration ratio for those is unchanged.
Consider now the contracts for the swapped problems once their very first swapped
contract is completed. That is, let cr for r > i be a contract for problem pi in the original
schedule. In that schedule its contribution to the acceleration ratio is (Tr +Dr )/dr . After the
swap this expression still denotes the acceleration ratio but now corresponding to problem
pj , since contracts dr and Dr are now run on problem pj , which implies that the schedule
remains unaffected by the swapping for those contracts as well.
Thus the only place where the acceleration ratio changes is right at the time of the
swapping when the previously longest completed contract (the denominator) comes from
the old schedule while the new contract about to be completed comes from the new schedule
(the numerator). We will show that the acceleration ratio of the new schedule X 0 on those
contracts is no worse than that of the original schedule.
The acceleration ratio of the original schedule at Di , Dj is


Ti + Di Tj + Dj
max
,
di
dj
whereas the acceleration ratio of X 0 at Di , Dj is


Ti + Di Tj + Dj
max
,
.
dj
di
541

fiLopez-Ortiz, Angelopoulos, & Hamel

Then since Tj > Ti and Dj > Di , we have that
Tj +Dj
dj

Tj +Dj
dj



Ti +Di
dj ;

moreover since dj < di ,

Tj +Dj
di .

we have

Therefore, the acceleration ratio of X is greater than or equal to
the acceleration ratio of the alternative schedule.

Corollary 1 Given a schedule X there is a schedule X 0 of no worse acceleration ratio with
the property that for any two problems pi and pj , with dj < di in X, and Tj > Ti , it is
always the case that Dj < Di in X 0 .
Proof. If X already satisfies this condition then set X 0 := X and there is nothing to show.
Otherwise we apply the process, i.e., appropriate problem swapping, as argued in the proof
of Lemma 1 in the following way: Let F = {f1 , f2 , . . . , } be the sorted sequence of contract
finish times for all problems in X. For a given f` define p(f` ) to be the problem associated
with finishing time f` in X. Let pj = p(f` ) and let dj be the length of the contract associated
with f` . Now starting with f1 and letting f` range over ` = 1, 2 . . . we check that for each
dj < di and Tj > Ti we have Dj < Di and if not, we swap the contracts as described in the
proof of Lemma 1.

We introduce some notation that will be needed in the statement and proof of Lemma 2.
For a schedule X, let ST denote the set of all contracts completed by time T inclusive.
Also let S T be the complement of ST , namely all contracts in X  ST . Fix a contract
C0 = (p0 , D0 ), which is scheduled to start at time T0 . For any problem pj observe that
because of Lemma 1 we have Dj = min{D : (pj , D)  S T0 +D0 }. Observe that in the context
of the above definitions, we have dj = max{d : (pj , d)  ST0 +D0 }.
Lemma 2 Let Ci = (pi , Di ) be a contract scheduled by X at time Ti and Cj = (pj , Dj ) be
any contract in S Ti . Then there exists a schedule X 0 of no worse acceleration ratio such
that if di  dj for a problem pj 6= pi then Ti + Di  Tj + Dj .
Proof. If X itself satisfies the conditions then we set X 0 := X and the lemma holds.
Otherwise if this is not the case, the schedule X is such that di  dj for at least one
problem pj 6= pi and Ti + Di < Tj + Dj . Consider then the swap in which all contracts
for problems pi and pj in S Ti +Di swap problem tags as defined in Section 2. We will argue
that the swap gives rise to a new schedule X 0 which has no worse acceleration ratio. One
can see that it suffices to look at how the acceleration ratio is affected at the points right
before Ci and Cj are completed. First, note that before the swap, the acceleration ratio at
these two points is equal to the quantity


Ti + Di Tj + Dj
 = max
,
di
dj
and after the swap, the acceleration ratio at the same two points becomes


Ti + Di Tj + Dj
 = max
,
.
dj
di
T +D

Since dj  di and Ti + Di  Tj + Dj we have   j dj j and thus   , which means that
the acceleration ratio does not worsen at those two specific points.

542

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

As in Lemma 1 we can apply this process repeatedly, starting with dj which is the length
of the contract associated with the smallest finish time f` (with ` = 1, 2 . . .) and checking
that no larger contract length di  dj is such that Ti +Di  Tj +Dj . If there are one or more
such contracts, we select the Di with the smallest completion time Ti + Di and swap tags
with (pj , Dj ). We then proceed to the next finishing time f`+1 . This produces a schedule
in which for all contracts such that di  dj (and pj 6= pi ) we have that Ti + Di  Tj + Dj .
Definition 3 A schedule X is said to be normalized if it satisfies the conditions of Corollary 1 and Lemma 2.
Lemma 3 There exists an optimal normalized schedule.
Proof. Since Lemma 2 is stronger than Lemma 1, applying Lemma 2 cannot violate
the conditions of Lemma 1 on the pair of contracts being swapped. It is indeed possible,
however, that after the swap some other contract is now in conflict with the earliest of the
recently modified contracts. To be more precise, consider the configuration of Figure 3(a)
where in the original schedule after the next scheduled contracts after the completion of
contracts di and dj , were such that Tj +Dj was originally larger than Ti +Di . After the swap
we get new completion times Tj0 + Dj0 := Ti + Di and Ti0 + Di0 := Tj + Dj . Observe, however
that the new completion time Ti0 + Di0 can create a new conflict with another schedule dk as
illustrated in Figure 3. It is not hard to verify that this figure represents the general case
and that no other type of conflict can be created.
dj

di

dk

Ti + Di

Tk + Dk

Tj + Dj

dj

di

dk

Tj0 + Dj0

Tk + Dk

Ti0 + Di0

Figure 3: Situation before and after a single application of Lemma 2.
The key now is to observe that in the original setting the pairs hdj , di i and hdj , dk i formed
an inversion, i.e. each constituted a violation of Lemma 2. However after the application
of the lemma both inversions disappeared while a new inversion hdi , dk i is created for a
net decrease of one in the number of inversions in the schedule. Hence this process must
eventually resolve all inversions involving contracts up to an index N for any fixed value of
N and this process converges to a well defined strategy.

Theorem 1 The acceleration ratio Rm,n (X) of an optimal normalized schedule X for n
problems with m processors is at least
k+n
P

Rm,n (X)  sup
k0

i=0
k
P

xsi

i=km+1

(1)
xsi

where X s = (xs0 , xs1 , . . .) is the sorted sequence of contract lengths (in increasing order, ties
broken arbitrarily) in the schedule Xand we define xsi = 0 if i < 0.
543

fiLopez-Ortiz, Angelopoulos, & Hamel

Proof. Let X be an optimal normalized schedule. Consider a time T0 such that processor
M0 is about to begin a new contract. Since X is a normalized schedule, M0 will choose
a problem p0 in a way that satisfies the conditions of Corollary 1. Let D0 be the alloted
processing time that M0 will devote to p0 starting at time T0 . Let the longest completed
contract for problem p0 at time just before T0 + D0 be d0 .
Now observe that, because of Lemmas 1 and 2, every contract of length strictly smaller
than d0 must complete within the open interval (0, T0 + D0 ), and hence at the end of this
interval every processor is engaged in a contract of length at least d0 and every problem
has completed a contract to length at most d0 in the previous step.
The lengths of these contracts d`  d0 for 0  `  n  1 are elements in the sequence
X s . Similarly let Mj denote a processor and denote as Ij the set of indices in X s of all the
contracts executed on processor Mj up to time T0 + D0 , not inclusively, for 0  j  m  1.
Note that d0 = xsk0 , for some k0  0.
Furthermore, let Dj be the last completed contract on processor Mj , say for a problem
p` , such that the previous completed contract dj for p` , is less than d0 . Then the acceleration
ratio for the problem p` at Dj is given by
P
s
iIj xi
xskj
according to Observation 2, for 0  j  m  1. Hence, the worst case acceleration ratio
that has occurred up to the time when all the contracts first exceeding d0 are completed is
at least
(P
)
Pm1 P
s
s
iIj xi
j=0
iIj xi
.
(2)
Rm,n (X)  max

Pm1 s
0jm1
xskj
j=0 xkj
Here we make use ofPthe fact
for all a, b, c, d > 0. Note
P that smax {a/c, b/d}  (a + b)/(c + d),
s that have been completed
x
contains
as
summands
all
x
that the sum A = m1
i
j=0
iIj i
up to time T0 + D0 . In particular we know that A includes all xs` that are smaller than xsk0 ,
as Lemma 2 guarantees that any problem completed to a contract dj will complete another
contract Dj before a problem completed to a contract d0  dj before T0 + D0 and hence
the summation given at time T0 + D0 contains all xs` s (i.e. dj s) that are smaller than xsk0
(i.e. d0 ). In other words, every element up to xsk0 in the sorted schedule X s appears in A.
Now observe that the other n  1 problems p1 , . . . , pn1 must have been completed to
durations exceeding xsk0 as otherwise the current contract of length D0 would have been
assigned to that problem instead of p0 . Then we have that A contains all sorted values in
X s up to xsk0 plus at least n  1 larger values corresponding to the finished contracts in
each of the n  1 problems. The smallest choices for these n  1 values together with the
D0 itself are xsk0 +1 , . . . , xsk0 +n . Hence, we obtain
m1
XX

xsi



j=0 iIj

kX
0 +n

xsi .

(3)

i=0

Consider now the values xkj = dj , for 1  j  m  1. Recall that the value Dj is the time to
which problem pj will be completed at time T0 + D0 by processor Mj and dj is the longest
544

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

completed contract for pj just before time Tj + Dj . Then by Lemma 2 d0 is the largest time
among the di s. The m  1 largest di values are xsk0 m+1 , . . . , xsk0 1 and
m1
X

k0
X

dj 

xsi .

(4)

i=k0 m+1

j=0

Combining (2),(3) and (4) we have
kP
0 +n

Pm1 P
Rm,n (X) 

s
iIj xi

j=0
Pm1 s
j=0 xkj



i=0
k0
P

xsi

i=k0 m+1

,
xsi

for all k0  n.

In order to prove a lower bound on the right hand side of Inequality (1) we make use of
the results by Gal (1980) and Schuierer (2001) which we state here without proof and in a
simplified form for completeness; in particular, we follow the work of Schuierer (2001, Thm.
1)1 . Define Ga = (1, a, a2 , . . .) to be the geometric sequence in a and X +i = (xi , xi+1 , . . .)
the suffix of sequence X starting at xi .
Theorem 2 (Schuierer, 2001) Let X = (x0 , x1 , . . .) be a sequence of positive numbers,
r an integer, and a = limn (xn )1/n , for a  R  {+}. If Fk , k  0, is a sequence of
functionals which satisfy
1. Fk (X) only depends on x0 , x1 , . . . , xk+r ,
2. Fk (X) is continuous, for all xi > 0, with 0  i  k + r,
3. Fk (X) = Fk (X), for all  > 0,
4. Fk (X + Y )  max{Fk (X), Fk (Y )}, and
5. Fk+i (X)  Fk (X +i ), for all i  1,
then
sup Fk (X)  sup Fk (Ga ).
0k<

0k<

For our case, the sequence X represents the lengths of the contracts in the schedule.
The acceleration ratio at the completion of each contract forms a sequence of functionals.
The value of each functional depends only on the prefix of contracts whose start time is
before the current time. The sequence Ga represents a geometric sequence, for which we
wish to show that it describes the optimal schedule.
1. Theorem 1 as proven by Schuierer (2001) applies in a broad setting, and for the purposes of our proof it
suffices to consider only the case p = 1.

545

fiLopez-Ortiz, Angelopoulos, & Hamel

Proposition 1 Let Fk (X s ) be a sequence of functionals defined as follows:
k+n
X

s

Fk (X ) =

xsi

k
X



i=0

xsi ,

i=km+1

then Fk (X s ) satisfies the conditions of Theorem 2.
Proof. It is straightforward to see that Fk (X s ) satisfies conditions (1)-(3). To verify
k+n
k
P s
P
xsi and define YT and YB analogously (i.e.,
condition (4), let XT =
xi , XB =
i=0

i=km+1

km
P

by substituting xsi with yis ). Observe that YT = YB + Q, where Q =

i=0

yis +

k+n
P
i=k+1

yis . Now,

we wish to show that Fk (X + Y )  max{Fk (X), Fk (Y )} or equivalently
XT + YT
XT + YB + Q
=
 max
XB + YB
XB + YB



XT YT
,
XB YB


(5)

which follows from the previously noted inequality max {a/c, b/d}  (a + b)/(c + d), for all
a, b, c, d > 0.
To verify Condition (5) of Theorem 2, first note that from the definition of Fk (X s ) we
have
Pk+n+j s
xi
Fk+j (X) = Pk+ji=0
s
i=km+1+j xi
while
Pk+n
Fk (X

+j

) = Pk

i=0

xsi+j

s
i=km+1 xi+j

Pk+n+j
i=j

= Pk+j

xsi

i=km+1+j

xsi

.

Lastly we observe that since all the terms in X s are positive and hence
j1
X
i=0

xsi

0

=

j1
X

k+n+j
X
xsi +
xsi
i=0
i=j



k+n+j
X

Pj1
xsi

i=0

=

Pk+n+j

xsi +

i=j

Pk+j

i=j

i=km+1+j

xsi

xsi

Pk+n+j
i=j

 Pk+j

i=km+1+j

as required.
Therefore, combining Theorem 1, Proposition 1 and Theorem 2 we have:
s

Rm,n (X)  sup Fk (X )  sup Fk (Ga ) = sup
0k<

0k<
k+n
P

Note that for a 6= 1, we have

ai

i=0
k
P

=
ai

0k<

ak+n+1 1
ak+1 akm+1

=

(k+n
X

i



a

i=0

1
an  k+1
a
m
1a

k
X



)
i

a

.

i=km+1

. Therefore, if a < 1,

i=km+1

we deduce that Rm,n (X) tends to infinity as k  . Moreover, if a = 1, we obtain that
546

xsi
xsi

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

Rm,n (X) = k+n+1
m , which, likewise, tends to infinity as k  . Hence, we can assume that
a > 1 and obtain


(ak+n+1  1)/(a  1)
Rm,n (X) 
sup
k+1  akm+1 )/(a  1)
0k< (a
 k+n+1

a
1
an
an+m
(a>1)
=
sup
=
=
.
k+1  akm+1
1  am
am  1
0k< a
The above expression is minimized for a = ((m + n)/n)1/m , which implies that the acceleration ratio of X is bounded from below by

m+n (m+n)/m
 n   m + n  m+n
m
n
Rm,n (X) 
.
=
m+n
m
n
n 1
We have thus shown the following theorem:
Theorem 3 Given n problem instances and m processors, every schedule that simulates an
interruptible algorithm using executions of contract algorithms has an acceleration ratio no
less than
 n   m + n  m+n
m
.
m
n
It is worth pointing out that the round-robin schedule of contract lengths 1, a, a2 , ... for
1
 m+n  m+n
n
m
m has acceleration ratio that is precisely
a value of a = m+n
, as shown by
n
m
n
Bernstein et al. (2003), and thus matches our lower bound. In other words, the round robin
and length-increasing schedule proposed by Bernstein et al. is optimal among all possible
schedules whether round robin and length-increasing, or not. This is not to say that all
optimal schedules are round robin and length-increasing, in fact one can easily construct
optimal non round-robin schedules for the case when n is a multiple of m. More formally,
we obtain the following theorem.
Theorem 4 The optimal schedule for n problems and m processors that simulates an interruptible algorithm using executions of contract algorithms has an acceleration ratio of
 n   m + n  m+n
m
.
m
n
Theorem 4 provides a tight bound on the worst-case acceleration ratio. More precisely,
we assume that interruptions are issued by a malicious adversary, typically right before
a contract algorithm terminates its execution. In this sense, the measure is extremely
pessimistic, and reflects only the performance of a schedule in an adversarial setting. In the
next section we show how to upper-bound the average-case acceleration ratio of exponential
schedules. The issue of stochastic deadlines has been addressed by Zilberstein et al. (2003) in
the case of a single processor and n problem instances. In their setting, there is uncertainty
about both the interruption and the quality of the output of the contract algorithm. Similar
types of analysis have been applied by Kao and Littman (1997) to the ray-search problem
on two rays, assuming some probabilistic knowledge on the placement of the target.
547

fiLopez-Ortiz, Angelopoulos, & Hamel

G3

G0

b3
b0

b1

b2

Figure 4: Example with m = 2, n = 3. Each line corresponds to the acceleration ratio on
that problem if interrupted at time t.

4. Average-Case Analysis of Exponential Strategies
In this section we present an average-case analysis of the acceleration ratio of exponential
strategies (recall the formal definition given in Section 2). In this scenario, the interruption
occurs at a time which is not chosen adversarially, rather it is chosen uniformly at random
in the interval [0, U ], for some U > 0. Likewise, the problem instance which is queried is
also chosen uniformly at random among the n problems.
A similar problem has been considered in the context of robots searching for a target on
m rays. A natural scenario is a hiker who becomes injured in the woods. The searchers must
then efficiently explore the forest trails as to find the injured person as soon as possible.
In this setting there is no reason to expect that the hiker would locate itself adversarially.
Hence while the worst case bound provides an exact upper bound on the worst possible
delay in reaching the target, the average case analysis gives a more realistic estimate of the
expected amount of time before the target is found. Kao et al. (1996) showed that on the
average the target is found nearly twice as fast as in the worst case scenario.
Here we consider the analogous setting in which the interruption time is chosen independently at random, rather than adversarially. Hence, we expect that the randomly-chosen
interruption will most likely not coincide with interruptions that yield high values of the
acceleration ratio in the worst-case scenario.
For the remainder of this section, we consider an exponential schedule X with base b;
that is, the length of the k-th contract in the cyclic ordering is bk . Let Gk denote the finish
time of this contract. We also assume that the problems are numbered 0, . . . , n  1; this
ordering makes the presentation easier to follow.
Before formalizing the concept of the average acceleration ratio we illustrate the intuition
using an example. Refer to Figure 4, which depicts an example with n = 3 problems
and m = 2 processors. Here, each of the three jagged line segments corresponds to the
acceleration ratio of each problem as a function of interruption time. More precisely, each
line is a plot of the function p (t), as formally defined in Section 2. Consider for example
problem 0 as shown by the solid line in Figure 4. The first contract completed for this
problem is contract 0, of length b0 , and has completion time G0 . After this contract is
completed, the available processors are occupied computing contracts of length b1 and b2
548

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

for problems 1 and 2 respectively. Eventually, a processor becomes available and computes
a contract of length b3 for problem 0, which is completed at time G3 . Note that the
acceleration ratio for problem 0 degrades linearly (i.e., increases) in the time interval between
G0 and G3 . Similar observations can be made for the remaining linear segments of the plot,
as well as for the other two problems.
The average acceleration ratio for a specific problem is then described by the area under
its respective acceleration ratio curve, normalized by the length U of the sampled space
[0, U ]. The overall average acceleration ratio is then given by the average of the individual
acceleration ratio averages for each of the n problems2 . Since the acceleration ratio for
each problem is a piece-wise linear function, in order to obtain the average we compute
the integral under each line segment, and sum over all segments. To normalize, we need to
divide by the length of the interval as well as by the number n of problems.
Consider now an interruption T in the interval [Gk , Gn+k ), for some index k in the cyclic
order, and let pk denote the problem that corresponds to the contract with finish time Gk .
Since the schedule is exponential, it follows that pk (T ) = T /bk . Since T is a random
variable, pk is also a random variable. Thus, we can compute the average acceleration
ratio for problem pk within the interval [Gk , Gn+k ) as

E[Gk ,Gk+n ) [pk ] =

1
Gk+n  Gk

=

1
Gk+n  Gk

=
=
=

Z

Gk+n

pk (x) dx
Gk
Z Gk+n
Gk

x
dx
bk

Z Gk+n Gk
Gk + x
1
dx
Gk+n  Gk 0
bk


1
Gk (Gk+n  Gk ) (Gk+n  Gk )2

+
Gk+n  Gk
bk
2 bk
Gk+n + Gk
.
2bk

To compute the average acceleration ratio of problem pk over the entire span [0, U ] we need
to add up the area below the entire jagged line that corresponds to this problem. Observe
that the area below a single sawtooth is given by the quantity (Gk+n  Gk )  E[Gk ,Gk+n ) [pk ].
This allows us to give expressions for the acceleration ratio of each one of the n problems.

2. Normally, a standard assumption is that interruptions occur after at least one contract for each problem
is completed, namely after time Gn1 . We make the simplifying assumption that interruptions can occur
earlier than Gn1 , in which case the acceleration ratio is 0. A refinement to interruptions only after
Gn1 follows along the lines of the discussion in this section. In this case the average is over the sampled
space [Gn1 , U ) and has a net zero effect on the asymptotic acceleration ratio (the extra term goes to
zero as U goes to infinity), but it results in much more complicated expressions.

549

fiLopez-Ortiz, Angelopoulos, & Hamel

In particular, the average acceleration ratio of problem 0 is given by:


br/nc
X

1 
G(k+1)n  Gkn E[Gkn ,G(k+1)n ) [0 ] + (U  Gr+n )E[Gr+n ,U ) [0 ]
E[0,U ) [0 ] =
U
k=0


br/nc 2
2
2
2
X
G

G
U  Gr+n
1 
kn
(k+1)n

=
+
(6)
U
2br+n
2bkn
k=0

where r is such that U  [Gr+n , Gr+n+1 ). Note that the last term corresponds to the
truncated sawtooth in the interval [Gr+n , U ].
The expression for the average acceleration ratio for problem i  {1, . . . n  1} is similar; however, instead of endpoints at G0 , Gn , G2n , . . . we need to consider the endpoints
Gi , Gn+i , G2n+i , . . .; More precisely, we obtain the expression


ri
bX
2
2
n c
G(w+1)n+i  Gwn+i U 2  G2r+i 
1 
E[0,U ) [i ] = 
+
(7)
.
U
2bwn+i
2br+i
w=0

The overall acceleration ratio  is a random variable defined as  =
and (7) we obtain

1
n

Pn1
i=0

i . Using (6)

n1

1X
E[0,U ] [i ]
n

E[0,U ] [] =

i=0

1
nU

=

1
nU

=

r
X
k=0
r
X
k=0

(Gk+n  Gk ) E[Gk ,Gk+n ) [0 ] +

n1
X

!
(U  Gr+i ) E[Gr+i ,U ] [i ]

i=1

X U 2  G2r+i
G2k+n  G2k n1
+
2br+i
2bk

!
.

(8)

i=1

It is easy to compute Gk (Bernstein et al., 2003, Proof of Theorem 1). Namely,
bk/mc

Gk =

X

bk/mc
mi+(k mod m)

b

k mod m

= b

i=0

X

bmi =

i=0

bk+m  bk mod m
.
bm  1

For simplicity of presentation we consider only the case U = Gr+n . The more general case
is analogous, though contains slightly more complicated expressions.
!
r
X
X G2r+n  G2r+i
G2k+n  G2k n1
1
E[0,Gr+n ] [] =
+
nGr+n
2br+i
2bk
k=0

=

1/(bm  1)
2n(br+n+m  bJr+nKm )

i=1
r
X (bk+n+m

 bJk+nKm )2  (bk+m  bJkKm )2
bk
k=0
!
n1
X (br+n+m  bJr+nKm )2  (br+i+m  bJr+iKm )2
+
.
(9)
br+i
i=1

550

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

where JxKm denotes x mod m We now evaluate separately the two summations involved
in (9). First,
r
X
(bk+n+m  bJk+nKm )2  (bk+m  bJkKm )2
k=0

=
=

=

bk

=

r
X

!
2Jk+nKm
2JkKm
b
b
b2(n+m)+k  2bn+m+Jk+nKm +
 b2m+k + 2bm+JkKm 
bk
bk
k=0
!
r
2Jk+nKm
2JkKm
X
b
b
(b2(n+m)  b2m )bk  2bn+m+Jk+nKm +
+ 2bm+JkKm 
bk
bk
k=0

r 
X
b2m
b2m
2(n+m)
2m k
n+2m
2m
(b
 b )b + 2b
+ k + 2b + k
b
b
k=0



 r+1  1

b2m+1
2(n+m)
2m b
n+2m
b
b
+ O rb
+O
,
(10)
b1
b1

where in the penultimate step we used that JxKm < m. Second, we get
n1
X

(br+n+m  bJr+nKm )2  (br+i+m  bJr+iKm )2
=
br+i
i=1

n1
X  b2(n+m)+r  2bn+m+Jr+nKm
b2Jr+nKm
b2Jr+iKm
2m++i
m+Jr+iKm
=
+
b
+ 2b

bi
br+i
br+i
i=1
 2m+1 n1

n1  1
n1  1
2b
(b
 1)
2m+r+n+1 b
2m+r+1 b
= b
+O

b
+
b1
br (b  1)
b1

 2m+1n n1

b
(b
 1)
2m
.
(11)
+ O nb
+O
br (b  1)
Substituting (10) and (11) in (9) and using simple algebraic expansion and simplification
we obtain


 b
 n1  1
(bm  1)1
2(n+m)
2m
2m+n+1
2m+1 b
E[0,Gr+n ] [] =
b
b
+ b
b
b1
b1
2n(bn+m  bJr+nKm r )
 

 2m+1 n1

m
1
(b  1)
1
b
(b
 1) 1
+
 r
O rnbn+2m  r + O
. (12)
Jr+nK
r
n+m
m
b
b1
b
2n(b
b
)
Note that in (12) the O-terms tend asymptotically to 0 as r approaches infinity. Hence,
these terms have negligible impact on the acceleration ratio when the interruption occurs
far ahead in time, and in this sense they can be considered error terms. In particular, we
obtain the following simplified expression for the asymptotic acceleration ratio:


 b
m
1 
 n1  1
r (b  1)
2(n+m)
2m
2m+n+1
2m+1 b
E[0,Gr+n ] [] =
b
b
+ b
b
2nbn+m
b1
b1
m
n
b (b  1)(b + 1)
=
.
2n(bm  1)(b  1)
551

fiLopez-Ortiz, Angelopoulos, & Hamel

Theorem 5 The asymptotic average acceleration ratio of an exponential schedule bi , for
i = 0, 1, . . ., with interruption chosen uniformly at random in [0, U ] is bounded by
(bm+n  bm ) (b + 1)
.
2n (bm  1) (b  1)
Proof. Follows from the discussion above.



Corollary 2 The asymptotic average acceleration ratio of the optimal schedule in Theorem
4 is bounded by



n
1
m+n m
m

1
+
1
(m + n) m+n
n
n


.
1

m
2mn m+n

1
n
Corollary 3 The schedule with optimal acceleration ratio has a non-optimal average acceleration ratio.
Proof. This can readily be verified by computing the derivative of the expression from
Theorem 5 and evaluating it around the value b = ((m+n)/n)1/m used by the optimal worst
case strategy. One can then observe through algebraic manipulation that the derivative is
always negative at this point, which implies that a larger value b0 = b +  results in a lower
(i.e. better) average acceleration ratio and hence the worst-case optimal schedule is not
optimal in the average sense.


5. Conclusion
In this paper we resolved an open question posed by Bernstein et al. (2003) concerning
the optimal acceleration ratio of a schedule of contract algorithms. This is a well-studied
problem in artificial intelligence, with several applications in the design of real-time systems.
Our main result shows that optimal schedules can be found in the class of cyclic schedules,
or, alternatively, that we cannot improve the quality of the simulation by designing more
complicated schedules. We also performed an average-case analysis of exponential schedules,
assuming a uniform distribution of the interruption times.
In more recent work, Angelopoulos, Lopez-Ortiz, and Hamel (2008) were able to apply
similar techniques so as to design optimal schedules for interruptible algorithms at the
presence of soft deadlines. In this setting, the interruption is not a hard deadline, in the sense
that when an interruption occurs, the algorithm is allowed an additional window of time to
complete its execution (which can be seen, intuitively, as a grace period). The algorithm
must then report the solution to the queried problem within the additional time window.
In a different example of further work, Angelopoulos and Lopez-Ortiz (2009) addressed
refinements of the acceleration ratio which reflect better the performance of schedules when
the number of problems is larger than the number of available processors. In both cases,
we resorted to the use of normalization techniques along the same lines as Section 3. This
provides evidence that our techniques are not tied to this specific variant of the problem,
but instead can be applicable in much wider settings.
An interesting open problem is to find tight bounds for randomized strategies, namely
schedules in which the length of contracts, as well as the processors to which the contracts
552

fiOptimal Scheduling of Contract Algorithms for Anytime Problem-Solving

are assigned are random variables. Note that randomization is known to be of help in the
context of the ray searching problem (Kao et al., 1996). A related (and very challenging) problem is to find schedules that achieve optimal average-case acceleration ratio. Are
exponential schedules optimal under this measure? Based on our analysis in Section 4,
we expect that an answer to this question will be fairly technical and involved. An even
more ambitious problem is to find optimal schedules assuming a certain known probability
distribution on the interruption times and problems that are queried.
Exponential schedules can be seen as an example of a doubling algorithm, in that the
lengths of contracts increase geometrically. The challenging part of this work (as in Angelopoulos et al., 2008; Angelopoulos & Lopez-Ortiz, 2009) is to lower-bound the performance of arbitrary strategies: this is accomplished by lower-bounding the supremum of a
sequence of functions by functionals over geometric sequences (Theorem 2). We believe that
similar techniques can be applied to many other optimization problems for which doubling
algorithms are known to perform well (see, e.g., the survey of Chrobak & Mathieu, 2006).
A recent example can be found in the work of Langetepe (2010), concerning the optimality
of spiral search for locating a target on the plane.
Last, but not least, while the optimal schedule presented in our work has parallels to
search strategies for the problem of searching m rays using p robots, the exact correspondence remains to be shown. Such a correspondence would extend the one established by
Bernstein et al. (2003) concerning cyclic schedules and strategies.

6. Acknowledgments
A preliminary version of this paper (Lopez-Ortiz, Angelopoulos, & Hamel, 2006) appeared in
the Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI).

References
Alpern, S., & Gal, S. (2003). The Theory of Search Games and Rendezvous. Kluwer
Academic Publishers.
Althofer, I. (1997). A symbiosis of man and machine beats grandmaster Timoshchenko.
Journal of the International Computer Chess Association., 20 (1), 4047.
Angelopoulos, S., & Lopez-Ortiz, A. (2009). Interruptible algorithms for multi-problem
solving. In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI), pp. 380386.
Angelopoulos, S., Lopez-Ortiz, A., & Hamel, A. (2008). Optimal scheduling of contract
algorithms with soft deadlines. In Proceedings of the 23rd National Conference on
Artificial Intelligence (AAAI), pp. 868873.
Baeza-Yates, R., Culberson, J., & Rawlins, G. (1993). Searching in the plane. Information
and Computation, 106, 234252.
Bernstein, D. S., Finkelstein, L., & Zilberstein, S. (2003). Contract algorithms and robots
on rays: Unifying two scheduling problems.. In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence (IJCAI), pp. 12111217.
553

fiLopez-Ortiz, Angelopoulos, & Hamel

Bernstein, D., Perkins, T. J., Zilberstein, S., & Finkelstein, L. (2002). Scheduling contract algorithms on multiple processors. In Proceedings of the Eighteenth National
Conference on Artificial Intelligence (AAAI), pp. 702706.
Chrobak, M., & Mathieu, C. (2006). Competitiveness via doubling. SIGACT News, 37 (4),
115126.
Dean, T., & Boddy, M. S. (1988). An analysis of time-dependent planning. In Proceedings
of the 7th National Conference on Artificial Intelligence, pp. 4954.
Gal, S. (1980). Search Games. Academic Press.
Horvitz, E. (1987). Reasoning about beliefs and actions under computational resource constraints. In Proceedings of the Third Annual Conference on Uncertainty in Artificial
Intelligence (UAI), pp. 301324.
Horvitz, E. (1998). Reasoning under varying and uncertain resource constraints. In Proceedings of the 7th National Conference on Artificial Intelligence (AAAI), pp. 111116.
Jaillet, P., & Stafford, M. (2001). Online searching. Operations Research, 49, 501515.
Kao, M.-Y., & Littman, M. L. (1997). Algorithms for informed cows. In AAAI workshop
on Online Search.
Kao, M.-Y., Ma, Y., Sipser, M., & Yin, Y. (1998). Optimal constructions of hybrid algorithms. Journal of Algorithms, 29 (1), 142164.
Kao, M.-Y., Reif, J. H., & Tate, S. R. (1996). Searching in an unknown environment: An optimal randomized algorithm for the cow-path problem. Information and Computation,
131 (1), 6379.
Langetepe, E. (2010). On the optimality of spiral search. In Proceedings of the 21st Annual
ACM-SIAM Symposium on Discrete Algorithms (SODA).
Lopez-Ortiz, A., Angelopoulos, S., & Hamel, A. (2006). Optimal scheduling of contract
algorithms for anytime problems. In Proceedings of the 21st National Conference on
Artificial Intelligence (AAAI).
Lopez-Ortiz, A., & Schuierer, S. (2004). Online parallel heuristics, processor scheduling
and robot searching under the competitive framework. Theoretical Computer Science,
310, 527537.
Russell, S. J., & Zilberstein, S. (1991). Composing real-time systems. In Proceedings of the
12th International Joint Conference on Artificial Intelligence (IJCAI), pp. 212217.
Schuierer, S. (2001). Lower bounds in on-line geometric searching. Computational Geometry:
Theory and Applications, 18 (1), 3753.
Schuierer, S. (2003). A lower bound for randomized searching on m rays. In Computer
Science in Perspective, pp. 264277.
Zilberstein, S. (1996). Using anytime algorithms in intelligent systems. AI Magazine, 17 (3),
7383.
Zilberstein, S., Charpillet, F., & Chassaing, P. (2003). Real-time problem-solving with
contract algorithms. Annals of Mathematics and Artificial Intelligence, 39 (12), 1
18.

554

fiJournal of Artificial Intelligence Research 51 (2014)

Submitted 02/14; published 11/14

Using Meta-mining to Support Data Mining Workflow
Planning and Optimization
Phong Nguyen
Melanie Hilario

Phong.Nguyen@unige.ch
Melanie.Hilario@unige.ch

Department of Computer Science
University of Geneva
Switzerland

Alexandros Kalousis

Alexandros.Kalousis@hesge.ch

Department of Business Informatics
University of Applied Sciences
Western Switzerland, and
Department of Computer Science
University of Geneva
Switzerland

Abstract
Knowledge Discovery in Databases is a complex process that involves many different
data processing and learning operators. Todays Knowledge Discovery Support Systems
can contain several hundred operators. A major challenge is to assist the user in designing
workflows which are not only valid but also  ideally  optimize some performance measure
associated with the user goal. In this paper we present such a system. The system relies
on a meta-mining module which analyses past data mining experiments and extracts metamining models which associate dataset characteristics with workflow descriptors in view of
workflow performance optimization. The meta-mining model is used within a data mining
workflow planner, to guide the planner during the workflow planning. We learn the metamining models using a similarity learning approach, and extract the workflow descriptors
by mining the workflows for generalized relational patterns accounting also for domain
knowledge provided by a data mining ontology. We evaluate the quality of the data mining
workflows that the system produces on a collection of real world datasets coming from
biology and show that it produces workflows that are significantly better than alternative
methods that can only do workflow selection and not planning.

1. Introduction
Learning models and extracting knowledge from data using data mining can be an extremely
complex process which requires combining a number of Data Mining (DM) operators, selected from large pools of available operators, combined into a data mining workflow. A DM
workflow is an assembly of individual data transformations and analysis steps, implemented
by DM operators, composing a DM process with which a data analyst chooses to address
his/her DM task. Workflows have recently emerged as a new paradigm for representing and
managing complex computations accelerating the pace of scientific progress. Their (meta-)
analysis is becoming increasingly challenging with the growing number and complexity of
available operators (Gil et al., 2007).
c
2014
AI Access Foundation. All rights reserved.

fiNguyen, Hilario & Kalousis

Todays second generation knowledge discovery support systems (KDSS) allow complex
modeling of workflows and contain several hundreds of operators; the RapidMiner platform (Klinkenberg, Mierswa, & Fischer, 2007), in its extended version with Weka (Hall
et al., 2009) and R (R Core Team, 2013), proposes actually more than 500 operators, some
of which can have very complex data and control flows, e.g. bagging or boosting operators,
in which several sub-workflows are interleaved. As a consequence, the possible number of
workflows that can be modeled within these systems is on the order of several millions,
ranging from simple to very elaborated workflows with several hundred operators. Therefore the data analyst has to carefully select among those operators the ones that can be
meaningfully combined to address his/her knowledge discovery problem. However, even the
most sophisticated data miner can be overwhelmed by the complexity of such modeling,
having to rely on his/her experience and biases as well as on thorough experimentation in
the hope of finding the best operator combination. With the advance of new generation
KDSS that provide even more advanced functionalities, it becomes important to provide
automated support to the user in the workflow modeling process, an issue that has been
identified as one of the top-ten challenges in data mining (Yang & Wu, 2006).

2. State of the Art in DM Workflow Design Support
During the last decade, a rather limited number of systems have been proposed to provide
automated user support in the design of DM workflows. Bernstein, Provost, and Hill (2005)
propose an ontology-based Intelligent Discovery Assistant (ida) that plans valid DM workflows  valid in the sense that they can be executed without any failure  according to basic
descriptions of the input dataset such as attribute types, presence of missing values, number
of classes, etc. By describing into a DM ontology the input conditions and output effects of
DM operators, according to the three main steps of the KD process, pre-processing, modeling and post-processing (Fayyad, Piatetsky-Shapiro, & Smyth, 1996), ida systematically
enumerates with a workflow planner all possible valid operator combinations, workflows,
that fulfill the data input request. A ranking of the workflows is then computed according
to user defined criteria such as speed or memory consumption which are measured from
past experiments.
Zakova, Kremen, Zelezny, and Lavrac (2011) propose the kd ontology to support automatic design of DM workflows for relational DM. In this ontology, DM relational algorithms
and datasets are modeled with the semantic web language OWL-DL, providing semantic
reasoning and inference in querying over a DM workflow repository. Similar to ida, the
kd ontology describes DM algorithms with their data input/output specifications. The
authors have developed a translator from their ontology representation to the Planning Domain Definition Language (PDDL) (McDermott et al., 1998), with which they can produce
abstract directed-acyclic graph workflows using a FF-style planning algorithm (Hoffmann,
2001). They demonstrate their approach on genomic and product engineering (CAD) usecases where complex workflows are produced that make use of relational data structure and
background knowledge.
More recently, the e-LICO project1 featured another ida built upon a planner which
constructs DM plans following a hierarchical task networks (HTN) planning approach. The
1. http://www.e-lico.eu

606

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

specification of the HTN is given in the Data Mining Workflow (dmwf) ontology (Kietz,
Serban, Bernstein, & Fischer, 2009). As its predecessors, the e-LICO ida has been designed
to identify operators whose preconditions are met at a given planning step in order to plan
valid DM workflows and does an exhaustive search in the space of possible DM plans.
None of the three DM support systems that we have just discussed consider the eventual
performance of the workflows they plan with respect to the DM task that they are supposed
to address. For example, if our goal is to plan/design workflows that solve a classification
problem, we would like to consider a measure of classification performance, such as accuracy,
and deliver workflows that optimize it. All the discussed DM support systems deliver an
extremely large number of plans, DM workflows, which are typically ranked with simple
heuristics, such as workflow complexity or expected execution time, leaving the user at a
loss as to which is the best workflow in terms of the expected performance in the DM task
that he/she needs to address. Even worse, the planning search space can be so large that
the systems can even fail to complete the planning process, see for example the discussion
by Kietz, Serban, Bernstein, and Fischer (2012).
There has been considerable work that tries to support the user, in view of performance
maximization, for a very specific part of the DM process, that of modeling or learning. A
number of approaches have been proposed, collectively identified as meta-learning (Brazdil,
Giraud-Carrier, Soares, & Vilalta, 2008; Kalousis, 2002; Kalousis & Theoharis, 1999; Hilario, 2002; Soares & Brazdil, 2000). The main idea in meta-learning is that given a new
dataset the system should be able to rank a pool of learning algorithms with respect to their
expected performance on the dataset. To do so, one builds a meta-learning model from the
analysis of past learning experiments, searching for associations between algorithms performances and dataset characteristics. However, as already mentioned, all meta-learning
approaches address only the learning/modeling part and are not applicable on the complete
process level.
In the work of Hilario, Nguyen, Do, Woznica, and Kalousis (2011), we did a first effort to
lift meta-learning ideas to the level of complete DM workflows. We proposed a novel metalearning framework that we called meta-mining or process-oriented meta-learning applied
on the complete DM process. We associate workflow descriptors and dataset descriptors,
applying decision tree algorithms on past experiments, in order to learn which couplings of
workflows and datasets will lead to high predictive performance. The workflow descriptors
were extracted using frequent pattern mining accommodating also background knowledge,
given by the Data Mining Optimization (dmop) ontology, on DM tasks, operators, workflows, performance measures and their relationships. However the predictive performance
of the system was rather low, due to the limited capacity of decision trees in capturing
the relations between the dataset and the workflow characteristics that were essential for
performance prediction.
To address the above limitation, we presented in the work of Nguyen, Wang, Hilario, and
Kalousis (2012b) an approach that learns what we called heterogeneous similarity measures,
associating dataset and workflow characteristics. There we learn similarity measures in
the dataset space, the workflow space, and the dataset-workflow space. These similarity
measures reflect respectively: the similarity of the datasets as it is given by the similarity of
the relative workflow performance vectors of the workflows that were applied on them; the
similarity of the workflows given by their performance based similarity on different datasets;
607

fiNguyen, Hilario & Kalousis

the dataset-workflow similarity based on the expected performance of the latter applied on
the former. However the two meta-mining methods described here were limited to select
from, or rank, a set of given workflows according to their expected performance, i.e. they
cannot plan new workflows given an input dataset.
Retrospectively, we presented in the work of Nguyen, Kalousis, and Hilario (2011) an
initial blueprint of an approach that does DM workflow planning in view of workflow performance optimization. There we suggested that the planner should be guided by a metamining model that ranks partial candidate workflows at each planning step. We also gave a
preliminary evaluation of the proposed approach with interesting results (Nguyen, Kalousis,
& Hilario, 2012a). However, the meta-mining module was rather trivial, it uses dataset and
pattern-based workflow descriptors and does a nearest-neighbor search over the dataset descriptors to identify the most similar datasets to the dataset for which we want to plan
the workflows. Within that neighborhood, it ranks the partial workflows using the support
of the workflow patterns on the workflows that perform best on the datasets of the neighborhood. The pattern-based ranking of the workflows was cumbersome and heuristic; the
system was not learning associations of dataset and workflow characteristics which explicitly optimize the expected workflow performance, which is what must guide the workflow
planning. This approach was then deployed by Kietz et al. (2012).
In this paper, we follow the line of work we first sketched in the work of Nguyen et al.
(2011). We couple tightly together a workflow planning and a meta-mining module to
develop a DM workflow planning system that given an input dataset designs workflows
that are expected to optimize the performance on the given dataset. The meta-mining
module applies the heterogeneous similarity learning method presented by Nguyen et al.
(2012b) to learn associations between dataset and workflow descriptors that lead to optimal
performance. It exploits then the learned associations to guide the planner in the workflow
construction during the planning. To the best of our knowledge, it is the first system
of its kind, i.e. being able to design DM workflows that are specifically tailored to the
characteristics of the input dataset in view of optimizing a DM task performance measure.
We evaluate the system on a number of real world datasets and show that the workflows it
plans are significantly better than the workflows delivered by a number of baseline methods.
The rest of this paper is structured as follows. In section 3, we present the global architecture of the system, together with a brief description of the planner. In section 4 we
describe in detail the meta-mining module, including the dataset and workflow characteristics it uses, the learning model, and how the learned model is used for workflow planning.
In section 5, we provide detailed experimental results and evaluate our approach in different
settings. Finally, we conclude in section 6.

3. System Description
In this section, we will provide a general description of the system. We will start by defining
the notations that we will use throughout the paper and then give a brief overview of the
different components of the system. Its two most important components, the planner and
the meta-miner will be described in subsequent sections (3.4 and 4 respectively). We will
close the section by providing the formal representation of the DM workflows which we will
use in the planner and the meta-miner.
608

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

Symbol
o
e
wl = [o1 , . . . , ol ]
wcl = (I(p1 t wl ), . . . , I(p|P | t wl ))T
xu = (x1 , . . . , xd )T
r(x, w)
g
t
m
O = {o1 , . . . , on }
Cl
Sl

Meaning
a workflow operator.
a workflow data type.
a ground DM workflow as a sequence of l operators.
the fixed length |P |-dimensional vector description
of a workflow wl
the d-dimensional vector description of a dataset.
the relative performance rank of w workflow on x
dataset
a DM goal.
a HTN task.
a HTN method.
a HTN abstract operator with n possible operators.
a set of candidate workflows at some abstract operator O.
a set of candidate workflows selected from Cl .

Table 1: Summary of notations used.
3.1 Notations
We will provide the most basic notations here and subsequently introduce additional notations as they are needed. We will use the term DM experiment to designate the execution of
a DM workflow w  W on a dataset x  X . We will describe a dataset x by a d-dimensional
column vector xu = (x1 , . . . xd )T ; we describe in detail in section 4.1.1 the dataset descriptions that we use. Each experiment will be characterized by some performance measure;
for example if the mining problem we are addressing is a classification problem one such
performance measure can be the accuracy. From the performance measures of the workflows
applied on a given dataset x we will extract the relative performance rank r(x, w)  R+ of
each workflow w for the x dataset. We will do so by statistically comparing the performance
differences of the different workflows for the given dataset (more on that in section 4.1.3).
The matrix X : n  d contains the descriptions of n datasets that will be used for the training of the system. For a given workflow w we will have two representations. wl will denote
the l-length operator sequence that constitutes the workflow. Note that different workflows
can have different lengths, so this is not a fixed length representation. wcl will denote the
fixed-length |P |-dimensional binary vector representation of the w workflow; each feature
of wcl indicates the presence or absence of some relational feature/pattern in the workflow.
Essentially wcl is the propositional representation of the workflow; we will describe in more
detail in section 4.1.2 how we extract this propositional representation. Finally W denotes
a collection of m workflows, which will be used in the training of the system, and W is the
corresponding m  |P | matrix that contains their propositional representations. Depending on the context the different workflow notations can be used interchangeably. Table 1
summarizes the most important notations.
3.2 System Architecture and Operational Pipeline
We provide in Figure 1 a high level architectural description of our system. The three blue
shaded boxes are: (i) the Data Mining Experiment Repository (dmer) which stores all the
609

fiNguyen, Hilario & Kalousis

input data

3. User Interface
goal
input MD

1.

input MD

DMER

optimal plans 5.

training MD

MetaMiner

Intelligent Discovery Assistant (IDA)

(partial) candidate workflows
AI
Planner

DM Workflow
Ontology (DMWF)

workflow ranking
4.

online
mode

metamined
model

offline
mode

2.

DM Optimization
Ontology (DMOP)

software
data flow

Figure 1: The meta-mining systems components and its pipeline.
base-level resources, i.e. training datasets, workflows, as well as the performance results
of the application of the latter on the former; essentially dmer contains the training data
that will be used to derive the models that will be necessary for the workflow planning and
design; (ii) the user interface through which the user interacts with the system, specifying
data mining tasks and input datasets and (iii) the Intelligent Discovery Assistant (ida)
which is the component that actually plans data mining workflows that will optimize some
performance measure for a given dataset and data mining task that the user has provided
as input. ida constitutes the core of the system and contains a planning component and a
meta-mining component which interact closely in order to deliver optimal workflows for the
given input problem; we will describe these two components in detail in sections 3.4 and 4
respectively. The system operates in two modes, an offline and an online mode. In the offline
mode the meta-mining component analyses past base-level data mining experiments, which
are stored in the dmer, to learn a meta-mining model that associates dataset and workflow
characteristics in view of performance optimization. In the online mode the meta-miner
interacts with the planner to guide the planning of the workflows using the meta-mining
model.
We will now go briefly through the different steps of the systems life cycle. We first
need to collect in the dmer a sufficient number of base-level data mining experiments,
i.e. applications of different data mining workflows on different datasets (step 1). These
experiments will be used in step 2 by the meta-miner to generate a meta-mining model.
More precisely we extract from the base level experiments a number of characteristics that
describe the datasets and the workflows and the performance that the latter achieved when
applied on the former. From these meta-data the meta-miner learns associations of dataset
and workflow characteristics that lead to high performance; it does so by learning a heterogeneous similarity measure which outputs a high similarity of a workflow to a dataset if
the former is expected to achieve a high performance when it will be applied to the latter
(more details in section 4.2).
Once the model is learned, the offline phase is completed and the online phase can
start. In the online phase the system directly interacts with its user. A given user can
select a data mining task g  G, such as classification, regression, clustering, etc, as well
610

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

as an input dataset on which the task should be applied; he or she might also specify the
number of top-k optimal workflows that should be planned (step 3). Given a new task
and an input dataset the action is transfered in the IDA where the ai-planner starts the
planning process. At each step of the planning process the ai-planner generates a list of
valid actions, partial candidate workflows, which it passes for ranking to the meta-miner
according to their expected performance on the given dataset, step 4. The meta-miner
ranks them using the learned meta-mining model and the planning continues with the topranked partial candidate workflows until the data mining task is resolved. At the end of
this planning process, the top-k workflows are presented to the user in the order given
by their expected performance on the input dataset. This is a greedy planning approach
where at each step we select the top-k current solutions. In principle we can let the aiplanner first generate all possible workflows and then have the meta-miner rank them.
Then the resulting plans would not be ranked according to a local greedy approach, but
they would be ranked globally and thus optimally with respect to the meta-mining model.
However in general this is not feasible due to the complexity of the planning process and
the combinatorial explosion in the number of plans.
3.3 DM Workflow Representation
We will now give a formal definition of a DM workflow and how we represent it. DM
workflows are directed acyclic typed graphs (DAGs), in which nodes correspond to operators
and edges between nodes to data input/output objects. In fact they are hierarchical DAGs
since they can have dominating nodes/operators that contain sub-workflows. A typical
example is the cross-validation operator whose control flow is given by the parallel execution
of training sub-workflows, or a complex operator such as boosting. More formally, let:
 O be the set of all available operators that can appear in a DM workflow, e.g. classification operators, such as J48, SVMs, etc. O also includes dominating operators
which are defined by one or more sub-workflows they dominate. An operator o  O
is defined by its name through a labelling function (o), the data types e  E of its
inputs and outputs, and its direct sub-workflows if o is a dominating operator.
 E be the set of all available data types that can appear in a DM workflow, namely
the data types of the various I/O objects that can appear in a DM workflow such as
models, datasets, attributes, etc.
The graph structure of a DM workflow is a pair (O , E  ), which also contains all subworkflows if any. O  O is the set of vertices which correspond to all the operators used in
this DM workflow and its sub-workflow(s), and E   E is the set of pairs of nodes, (oi , oj ),
directed edges, that correspond to the data types of the output/input objects, that are
passed from operator oi to operator oj . Following this graph structure, the topological sort
of a DM workflow is a permutation of the vertices of the graph such that an edge (oi , oj )
implies that oi appears before oj , i.e. this is a complete ordering of the nodes of a directed
acyclic graph which is given by the node sequence:
wl = [o1 , .., ol ]
611

(1)

fiNguyen, Hilario & Kalousis

Legend
input / output edges
sub input / output edges
X
X

End

Retrieve

basic nodes
output

composite nodes

result
X-Validation
Split

training set

Join

test set

Weight by Information Gain

weights
example set
Apply Model
performance
Select by Weights
labelled data
training set
Performance
Naive Bayes
model

Figure 2: Example of a DM workflow that does performance estimation of a combination
of feature selection and classification algorithms.

where the subscript in wl denotes the length l (i.e. number of operators) of the topological
sort. The topological sort of a DM workflow can be structurally represented with a rooted,
labelled and ordered tree (Bringmann, 2004; Zaki, 2005), by doing a depth-first search over
its graph structure where the maximum depth is given by expanding recursively the subworkflows of the dominating operators. Thus the topological sort of a workflow or its tree
representation is a reduction of the original directed acyclic graph where the nodes and
edges have been fully ordered.
An example of the hierarchical DAG representing a RapidMiner DM workflow is given in
Figure 2. The graph corresponds to a DM workflow that cross-validates a feature selection
method followed by a classification model building step with the NaiveBayes classifier. XValidation is a typical example of a dominating operator which itself is a workflow  it has
two basic blocks, a training block which can be any arbitrary workflow that receives as
input a dataset and outputs a model, and a testing block which receives as input a model
and a dataset and outputs a performance measure. In particular, we have a training subworkflow, in which feature weights are computed by the InformationGain operator, after
which a number of features is selected by the SelectByWeights operator, followed by the
final model building by the NaiveBayes operator. In the testing block, we have a typical
sub-workflow which consists of the application of the learned model on the testing set with
the ApplyModel operator, followed by a performance estimation given by the Performance
operator. The topological sort of this graph is given by the ordered tree given in Figure 3.
612

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

Retrieve
1

Weight by
Information Gain
3

Select by
Weights
4

X-Validation
2/8

Naive
Bayes
5

End
9

Apply
Model
6

Performance
7

Figure 3: The topological order of the DM workflow given in Figure 2.

3.4 Workflow Planning
The workflow planner we use is based on the work of Kietz et al. (2009, 2012), and designs
DM workflows using a hierarchical task network (HTN) decomposition of the crisp-dm process model (Chapman et al., 2000). However this planner only does workflow enumeration
generating all possible plans, i.e. it does not consider the expected workflow performance
during the planning process and does not scale to large set of operators which explode the
search space. In order to address these limitations, we presented some preliminary results
in which the planner was coupled with a frequent pattern meta-mining algorithm and a
nearest-neighbor algorithm to rank the partial workflows at each step of the workflow planning (Nguyen et al., 2011, 2012a). This system was also deployed by Kietz et al. (2012).
The approach we followed was to prioritize the partial workflows according to the support
that the frequent patterns they contained achieved on a set of workflows that performed
well on a set of datasets that were similar to the input dataset for which we want to plan
the workflow. However we were not learning associations between dataset and workflow
characteristics, which is the approach we follow here.
In section 3.4.1 we briefly describe the HTN planner of Kietz et al. (2009, 2012); and
in section 3.4.2 we describe how we use the prediction of the expected performance of a
partial-workflow applied on a given dataset to guide the HTN planner. We will give the
complete description of our meta-mining module that learns associations of dataset and
workflow characteristics that are expected to achieve high performance in section 4.
3.4.1 HTN Planning
Given some goal g  G, the AI-planner will decompose in a top-down manner this goal into
elements of two sets, tasks T and methods M . For each task t  T that can achieve g,
there is a subset M   M of associated methods that share the same data input/output
(I/O) object specification with t and that can address it. In turn, each method m  M 
defines a sequence of operators, and/or abstract operators (see below), and/or sub-tasks,
which executed in that order can achieve m. By recursively expanding tasks, methods and
operators for the given goal g, the AI-planner will sequentially construct an HTN plan
in which terminal nodes will correspond to operators, and non-terminal nodes to HTN
task or method decompositions, or to dominating operators (X-Validation for instance will
dominate a training and a testing sub-workflows). An example of an HTN plan is given
613

fiNguyen, Hilario & Kalousis

EvaluateAttributeSelectionClassification
X-Validation
In: Dataset
Out: Performance

AttributeSelection
ClassificationTraining

Classification
Training

AttributeSelection
Training

Attribute
Weighting
Operator
In: Dataset
Out: AttributeWeights

Select by
Weights
In: Dataset
In: AttributeWeights
Out: Dataset

Predictive
Supervised
Learner
In: Dataset
Out: Predictive
Model

AttributeSelection
ClassificationTesting

Model
Application
Apply
Model
In: Dataset
In: Predictive
Model
Out: Labelled
Dataset

Model
Evaluation
In: Labelled
Dataset
Out: Performance

Figure 4: The HTN plan of the DM workflow given in Figure 2. Non-terminal nodes are
HTN tasks/methods, except for the dominating operator X-Validation. Abstract
operators are in bold and simple operators in italic, each of which is annotated
with its I/O specification.

in Figure 4. This plan corresponds to the feature selection and classification workflow of
Figure 2 with exactly the same topological sort (of operators) given in Figure 3.
The sets of goals G, tasks T , methods M , and operators O, and their relations, are
described in the dmwf ontology (Kietz et al., 2009). There, methods and operators are
annotated with their pre- and post-conditions so that they can be used by the AI-planner.
Additionally, the set of operators O has been enriched with a shallow taxonomic view in
which operators that share the same I/O object specification are grouped under a common
ancestor:
O = {o1 , . . . , on }

(2)

where O defines an abstract operator, i.e. an operator choice point or alternative among a set
of n syntactically similar operators. For example, the abstract AttributeWeighting operator
given in Figure 4 will include any feature weighting algorithms such as InformationGain or
ReliefF, and similarly the abstract Predictive Supervised Learner operator will contain any
classification algorithms such as NaiveBayes or a linear SVM.
The HTN planner can also plan operators that can be applied on each attribute, e.g.
a continuous attribute normalization operator, or a discretization operator. It uses cyclic
planning structures to apply them on subsets of attributes. In our case we use its attributegrouping functionality which does not require the use of cyclic planning structures. More
precisely if such an operator is selected for application it is applied on all appropriate
attributes. Overall the HTN grammar contains descriptions of 16 different tasks and more
614

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

than 100 operators, over which the planner can plan. These numbers are only limited by the
modeling effort required to describe the tasks and the operators, they are not an inherent
limitation of the HTN grammar/planner. Kietz et al. (2012) have developed a module for
the open-source ontology editor Protege called E-ProPlan2 to facilitate the modelling of
new operators and describe task-method decomposition grammars for DM problems in the
dmwf ontology.
3.4.2 The Workflow Selection Task
The AI-planner designs during the construction of an HTN plan several partial workflows,
each of which will be derived by substituting an abstract operator O with one of its n
operators. The number of planned workflows can be in the order of several thousands
which will leave the user at a loss as to which workflow to choose for her/his problem;
even worse, it is possible that the planning process never succeeds to find a valid plan and
terminate due to the complexity of the search space.
To support the user in the selection of DM workflows, we can use a post-planning approach in which the designed workflows will be evaluated according to some evaluation
measure in order to find the k ones that will be globally the best for the given mining problem. However, this global approach will be very computational expensive in the planning
phase as we mentioned above. Instead, we will follow here a planning approach in which we
will locally guide the AI-planner towards the design of DM workflows that will be optimized
for the given problem, avoiding thus the need to explore the whole planning search space.
Clearly, by following a local approach the cost that one has to pay is a potential reduction
in performance since not all workflows are explored and evaluated, potentially missing good
ones due to the greedy nature of the plan construction.
We adopt a heuristic hill climbing approach to guide the planner. At each abstract
operator O we need to determine which of the n candidate operators o  O are expected to
achieve the best performance on the given dataset. More formally, we will define by:
Cl := {wlo = [wl1  Sl1 |o  O]}kn

(3)

the set of k  n partial candidate workflows of length l which are generated from the
expansion of an abstract operator O by adding one of the n candidate operators o  O to
one of the k candidate workflows of length l  1 that constitute the set Sl1 of workflows
selected in the previous planning step (S0 is the empty set see below). Now let xu be a vector
description of the input dataset for which we want to plan workflows which address some
data mining goal g and optimize some performance measure. Moreover let wclo be a binary
vector that provides a propositional representation of the wlo workflow with respect to the
set of generalized relational frequent workflow patterns that it contains3 . We construct the
set Sl of selected workflows at the current planning step according to:
Sl := {arg max r(xu , wclo |g)}k

(4)

{wlo Cl }

2. Available at http://www.e-lico.eu/eproplan.html
3. We will provide a detailed description of how we extract the wclo descriptors in section 4.1.2, for the
moment we note that these propositional representations are fixed length representations, that do not
depend on l.

615

fiNguyen, Hilario & Kalousis

where r(xu , wclo |g) is the estimated performance of a workflow with the propositional description wclo when applied to a dataset with description xu , i.e. at each planning step
we select the best current partial workflows according to their estimated expected performance. It is the meta-mining model, that we learn over past experiments, that delivers
the estimations of the expected performance. In section 4.2 we describe how we derive the
meta-mining models and how we use them to get the estimates of the expected performance.
We should stress here that in producing the performance estimate r(xu , wclo |g) the
meta-mining model uses the workflow description wclo , and not just the candidate operator descriptions. These pattern-based descriptions capture dependencies and interactions
between the different operators of the workflows (again more on the wclo representation in
section 4.1.2). This is a rather crucial point since it is a well known fact that when we construct data mining workflows we need to consider the relations of the biases of the different
algorithms that we use within them, some bias combinations are better than others. The
pattern based descriptions that we will use provide precisely that type of information, i.e.
information on the operator combinations appearing within the workflows.
In the next section we will provide the complete description of the meta-miner module,
including how we characterize datasets, workflows and the performance of the latter applied
to the former, and of course how we learn the meta-mining models and use them in planning.

4. The Meta-Miner
The meta-miner component operates in two modes. In the offline mode it learns from
past experimental data a meta-mining model which provides the expected performance
estimates r(xu , wclo |g). In the on-line mode it interacts with the AI-planner at each step
of the planning process, delivering the r(xu , wclo |g) estimates which are used by the planner
to select workflows at each planning step according to Eq.(4).
The rest of the section is organised as follows. In subsection 4.1.1 we explain how we
describe the datasets, i.e. how we derive the xu dataset descriptors; in subsection 4.1.2 how
we derive the propositional representation wclo of the data mining workflows and in subsection 4.1.3 how we rank the workflows according to their performance on a given dataset, i.e.
r(xu , wclo |g). Finally in subsection 4.2 we explain how we build models from past mining
experiments which will provide the expected performance estimations r(xu , wclo |g) and how
we use these models within the planner.
4.1 Meta-Data and Performance Measures
In this section we will describe the meta-data, namely dataset and workflow descriptions,
and the performance measures that are used by the meta-miner to learn meta-mining models
that associate dataset and workflow characteristics in view of planning DM workflows that
optimize a performance measure.
4.1.1 Dataset Characteristics
The idea to characterize datasets has been a full-fledged research problem from the early
inception of meta-learning until now (Michie, Spiegelhalter, Taylor, & Campbell, 1994;
Kopf, Taylor, & Keller, 2000; Pfahringer, Bensusan, & Giraud-Carrier., 2000; Soares &
616

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

Brazdil, 2000; Hilario & Kalousis, 2001; Peng, Flach, Soares, & Brazdil, 2002; Kalousis,
Gama, & Hilario, 2004). Following state-of-art dataset characteristics, we will characterize
a dataset x  X by the three following groups of characteristics.
 Statistical and information-theoretic measures: this group refers to data characteristics
defined in the STATLOG (Michie et al., 1994; King, Feng, & Sutherland, 1995) and
METAL projects4 (Soares & Brazdil, 2000), and it includes number of instances,
number of classes, proportion of missing values, proportion of continuous / categorical
features, noise signal ratio, class entropy, mutual information. They mainly describe
attribute statistics and class distributions of a given dataset sample.
 Geometrical and topological measures: this group concerns new measures which try
to capture geometrical and topological complexity of class boundaries (Ho & Basu,
2002, 2006), and it includes non-linearity, volume of overlap region, maximum Fishers
discriminant ratio, fraction of instance on class boundary, ratio of average intra/inter
class nearest neighbour distance.
 Landmarking and model-based measures: this group is related to measures asserted
with fast machine learning algorithms, so called landmarkers (Pfahringer et al., 2000),
and its derivative based on the learned models (Peng et al., 2002), and it includes error
rates and pairwise 1p values obtained by landmarkers such as 1NN or DecisionStump,
and histogram weights learned by Relief or SVM. We have extended this last group
with new landmarking methods based on the weight distribution of feature weighting
algorithms such as Relief or SVM where we have build twenty different histogram
representations of the discretized feature weights.
Overall, our system makes use of a total of d = 150 numeric characteristics to describe
a dataset. We will denote this vectorial representation of a dataset x  X by xu . We
have been far from exhaustive in the dataset characteristics that we used, not including
characteristics such as subsampling landmarks (Leite & Brazdil, 2010). Our main goal in
this work is not to produce a comprehensive set of dataset descriptors but to design a DM
workflow planning system that given a set of dataset characteristics, coupled with workflow
descriptors, can plan DM workflows that optimize some performance measure.
4.1.2 Workflow Characteristics
As we have seen in section 3.3 workflows are graph structures that can be quite complex
containing several nested sub-structures. These are very often difficult to analyze not only
because of their spaghetti-like structure but also because we do not have any information
on which subtask is addressed by which workflow component (Van der Aalst & Giinther,
2007). Process mining addresses this problem by mining for generalized patterns over
workflow structures (Bose & der Aalst, 2009).
To characterize DM workflows we will follow a process mining like approach; we will
extract generalized, relational, frequent patterns over their tree representations, that we
will use to derive propositional representations of them. The possible generalizations will
4. http://www.metal-kdd.org/

617

fiNguyen, Hilario & Kalousis

DM-Algorithm
DataProcessing
Algorithm

PredictiveModelling
Algorithm

FeatureWeighting
Algorithm

ClassificationModelling
Algorithm

LearnerFreeFW
Algorithm

UnivariateFW
Algorithm

MultivariateFW
Algorithm

MissingValues
Tolerant
Algorithm

Irrelevant
Tolerant
Algorithm

ExactCOS
Based
Algorithm

C4.5

Naive
Bayes

SVM

EntropyBasedFW
Algorithm

IG

ReliefF
is-followed-by

is-implemented-by

Figure 5: A part of the dmops algorithm taxonomies. Short dashed arrows represent the
is-followed-by relation between DM algorithms, and long dashed arrows represent the is-implemented-by relation between DM operators and DM algorithms.

(a)

(b)

X-Validation

(c)

X-Validation

Feature
Weighting
Algorithm

Classification
Modeling
Algorithm

Feature
Weighting
Algorithm

Classification
Modeling
Algorithm

UnivariateFW
Algorithm

Irrelevant
Tolerant
Algorithm

LearnerFreeFW
Algorithm

MissingValues
Tolerant
Algorithm

EntropyBasedFW
Algorithm

X-Validation
Feature
Weighting
Algorithm

Classification
w
Algorithm
ExactCOS
Based
Algorithm

Figure 6: Three workflow patterns with cross-level concepts. Thin edges depict workflow
decomposition; double lines depict dmops concept subsumption.

be described by domain knowledge which, among other knowledge, will be given by a data
mining ontology. We will use the Data Mining Optimization (dmop) ontology (Hilario
et al., 2009, 2011). Briefly, this ontology provides a formal conceptualization of the DM
domain by describing DM algorithms and defining their relations in terms of DM tasks,
models and workflows. It describes learning algorithms such as C4.5, NaiveBayes or SVM,
according to their learning behavior such as their bias/variance profile, their sensitivity to
the type of attributes, etc. For instance, the algorithms cited above are all tolerant to irrelevant attributes, but only C4.5 and NaiveBayes algorithms are tolerant to missing values,
whereas only the SVM and NaiveBayes algorithms have an exact cost function. Algorithm characteristics and families are classified as taxonomies in dmop under the primitive
618

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

concept of DM-Algorithm. Moreover, dmop specifies workflow relations, algorithm order,
with the is-followed-by relation and relates workflow operators with DM algorithms with
the is-implemented-by relation. Figure 5 shows a snapshot of the dmops algorithm taxonomies with ground operators at the bottom related to the DM algorithms they implement.
To mine generalized relational patterns from DM workflows, we will follow the method
presented by Hilario et al. (2011). First, we use the dmop ontology to annotate a set W
of workflows. Then, we extract from this set generalized patterns using a frequent pattern
mining algorithm. Concretely, for each operator contained in the parse tree of a training DM
workflow wl  W , we insert into the tree branch above the operator the taxonomic concepts,
ordered from top to bottom, that are implemented by this operator, as these are given in
the dmop. The result is a new parse tree that has additional nodes which are dmops
concepts. We will call this parse tree an augmented parse tree. We then reorder the nodes
of each augmented parse tree to to satisfy dmops algorithm taxonomies and relations. For
example a feature selection algorithm is typically composed of a feature weighting algorithm
followed by a decision rule that selects features according to some heuristics. The result
is a set of augmented and reordered workflow parse trees. Over this representation, we
apply a tree mining algorithm (Zaki, 2005) to extracts a set P of frequent patterns. Each
pattern corresponds to a tree that appears frequently within the augmented parse trees;
we mine patterns that have a support higher or equal to five. In principle we can go as
low as a support of one, exploding the dimensionality of the description of workflows, with
what probably will be features of poor discriminatory power. Nevertheless since our metamining models rely on metric learning, which is able to learn the importance of the different
meta-features, they would be able to cope also with such a scenario. Note that to extract
the workflow characteristics we could have used other different techniques such as graph
mining directly over the graph structures defined by the workflows and the ontology, the
main reason for not doing that was the computational cost of the latter approaches, as well
as the fact that frequent pattern mining propositionalization is known to work very well.
In Figure 6 we give examples of the mined patterns. Note that the extracted patterns are
generalized, in the sense that they contain entities defined at different abstraction levels,
as these are provided by the dmop ontology. They are relational because they describe
relations, such as order relations, between the structures that appear within a workflow,
and they also contain properties of entities as these are described in the dmop ontology. For
example pattern (c) of Figure 6 states that we have a feature weighting algorithm (abstract
concept) followed by (relation) a classification algorithm that has an exact cost function
(property), within a cross-validation.
We use the set P of frequent workflow patterns to describe any DM workflow wl  W
through the patterns p  P that this wl workflow contains. The propositional description
of a workflow wl is given by the |P |-length binary vector:
wcl = (I(p1 t wl ), . . . , I(p|P | t wl ))T  {0, 1}|P |

(5)

where t denotes the induced tree relation (Zaki, 2005) and I(pi t wl ) returns one if the
frequent pattern, pi , appears within the workflow and zero otherwise.
We will use this propositional workflow representation together with a tabular representation of the datasets characteristics to learn the meta-mining models which we will describe
in the next section. Although we could have used tree or even graph properties to represent
619

fiNguyen, Hilario & Kalousis

workflows, propositionalization is a standard approach used extensively and successfully in
learning problems in which the learning instances are complex structures (Kramer, Lavrac,
& Flach, 2000).
Also, the propositional workflow representation can easily deal with the parameter values
of the different operators that appear within the workflows. To do so, we can discretize the
range of values of a continuous parameter to ranges such as low, medium, high, or other
ranges depending on the nature of the parameter, and treat these discretized values as
simply a property of the operators. The resulting patterns will now be parameter-aware;
they will include information on the parameter range of the mined operators and they can
be used to support also the parameter setting during the planning of the DM workflows.
However within this paper we will not explore this possibility.
4.1.3 Performance-Based Ranking of DM Workflow
To characterize the performance of a number of workflows applied on a given dataset we
will use a relative performance rank schema that we will derive using statistical significance
tests. Given the estimations of some performance measure of the different workflows on a
given dataset we use a statistical significance test to compare the estimated performances
of every pair of workflows. If within a given pair one of the workflows was significantly
better than the other then it gets one point and the other gets zero points. If there was
no significance difference then both workflows get half a point. The final performance rank
of a workflow for the given dataset is simply the sum of its points over all the pairwise
performance comparisons, the higher the better. We will denote this relative performance
rank of a workflow wc applied on dataset xu by r(xu , wc ). Note that if a workflow was not
applicable, or not executed, on the dataset x, we set its rank score to the default value of zero
which means that the workflow is not appropriate (if not yet executed) for the given dataset.
When the planning goal g is the classification task, we will use as evaluation measure in our
experiments the classification accuracy, estimated by ten-fold cross-validation, and do the
significance testing using McNemars test, with a significance level of 0.05.
In the next section we will describe how we build the meta-mining models from the
past data-mining experiments using the meta-data and the performance measures we have
described so far and how we use these models to support the DM workflow planning.
4.2 Learning Meta-mining Models for Workflow Planning
Before starting to describe in detail how we build the meta-mining models let us take a
step back and give a more abstract picture of the type of meta-mining setting that we will
address. In the previous sections, we described two types of learning instances: datasets
x  X and workflows w  W. Given the set of datasets and the set of workflows stored in
the dmer, the meta-miner will build from these, two training matrices X and W. The
X : n  d dataset matrix, has as its ith row the description xui of the ith dataset. The
W : m  |P | workflow matrix, has as its j th row the description wcj of the jth workflow.
We also have a preference matrix R : n  m, where Rij = r(xui , wcj ), i.e. it gives the
relative performance rank of the workflow wj when applied to the dataset xi with respect
to the other workflows. We can see Rij as a measure of the appropriateness or match of
the wj workflow for the xi dataset. The ith line of the R matrix contains the vector
620

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

of the relative performance ranks of the workflows that were applied on the xui dataset.
The meta-miner will take as input the X, W and R matrices and will output a model that
predicts the expected performance, r(xu , wc ), of a workflow w applied to a dataset x.
We construct the meta-mining model using similarity learning, exploiting two basic
strategies initially presented in the context of DM workflow selection (Nguyen et al., 2012b).
Here we will give only a high level presentation of them, for more details the interested user
should refer to the original paper. In the first strategy we learn homogeneous similarity
measures, measuring similarity of datasets and similarity of workflows, which we then use to
derive the r(xu , wc |g) estimates. In the second we learn heterogeneous similarity measures
which directly estimate the appropriateness of a workflow for a dataset, i.e. they produce
direct estimates of r(xu , wc |g).
4.2.1 Learning Homogeneous Similarity Measures
Our goal is to provide meta-mining models that are good predictors of the performance
of a workflow applied to a dataset. In the simplest approach we want to learn a good
similarity measure on the dataset space that will deem two datasets to be similar if a set
of workflows applied to both of them will result in a similar relative performance, i.e. if
we order the workflows according to the performance they achieve on each dataset then
two datasets will be similar if the workflow orders are similar. Thus the learned similarity
measure on the dataset space should be a good predictor of the similarity of the datasets
as this is determined by the relative performance order of the workflows. In a completely
symmetrical manner we will consider two workflows to be similar if they achieve similar
relative performance scores on a set of datasets. Thus in the case of workflows we will learn
a similarity measure on the workflow space that is a good predictor of the similarity of their
relative performance scores over a set of datasets.
Briefly, we learn two Mahalanobis metric matrices, MX , MW , over the datasets and the
workflows respectively, by optimizing the two following convex metric learning optimization
problems:
min F1 = ||RRT  XMX XT ||2F +  tr(MX )
MX

s.t.

(6)

MX  0

and
min F2 = ||RT R  WMW WT ||2F +  tr(MW )
MW

s.t.

(7)

MW  0

where ||.||F is the Frobenius matrix norm, tr() the matrix trace, and   0 is a parameter
controlling the trade-off between empirical error and the metric complexity to control overfitting. The RRT : n  n matrix reflects the similarity of the relative workflow performance
vectors over the different dataset pairs which the learned dataset similarity metric should
reflect. The RT R : m  m matrix gives the respective similarities for the workflows. For
more details on the learning problem and how we solve it, see the work of Nguyen et al.
(2012b).
621

fiNguyen, Hilario & Kalousis

Note that so far we do not have a model that computes the expected relative performance
r(xu , wclo ). In the case of the homogeneous metric learning we will compute it in the on-line
mode during the planning phase; we will describe right away how we do so in the following
paragraph.
Planning with the homogeneous similarity metrics (P1) We will use the two
learned Mahalanobis matrices, MX , MW , to compute the dataset similarity and the workflow similarity out of which we will finally compute the estimates r(xu , wclo ) at each planning
step.
Concretely, prior to planning we determine the similarity of the input dataset xu (for
which we want to plan optimal DM workflows) to each of the training datasets xui  X using
the MX dataset metric to measure the dataset similarities. The Mahalanobis similarity of
two datasets, xu , xui , is given by
sX (xu , xui ) = xTu MX xui

(8)

Then, during planning at each planning step we determine the similarity of each candidate
workflow wlo  Cl to each of the training workflows wcj of W, by
sW (wclo , wcj ) = wcTlo MW wcj .

(9)

Finally we derive the r(xu , wclo ) estimate through a weighted average of the elements
of the R matrix. The weights are given by the similarity of the input dataset xu to the
training datasets, and the similarities of the candidate workflow wclo to each of the training
workflows. More formally the expected rank is given by:
P
P
wcj W  xui  wcj r(xui , wcj |g)
xui X
P
P
(10)
r(xu , wclo |g) =
wc W  xui  wcj
xu X
j

i

 xui and  wcj are the Gaussian weights given by  xui = exp(sX (xu , xui )/x ) and  wcj =
exp(sW (wclo , wcj )/w ); x and w are the kernel widths that control the size of the neighbors
in the data and workflow spaces respectively (Smart & Kaelbling, 2000; Forbes & Andre,
2000).
Using the rank performance estimates delivered by Eq.(10), we can select at each planning step the best candidate workflows set, Sl , according to Eq.(4). We will call the resulting
planning strategy P1. Under P1 the expected performance of the set of selected candidate
workflows Sl greedily increases until we deliver the k DM complete workflows which are
expected to achieve the best performance on the given dataset.
4.2.2 Learning a Heterogeneous Similarity Measure
The P1 planning strategy makes use of two similarity measures that are learned independently of each other, each one defined in its own feature space. This is a simplistic
assumption because it does not model for the interactions of workflows and datasets, we
know that certain types of DM workflows are more appropriate for datasets with certain
types of characteristics. In order to address this limitation, we will define a heterogeneous
metric learning problem in which we will directly estimate the similarity/appropriateness
622

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

of a workflow for a given dataset as this is given by the r(xu , wc ) relative performance
measure.
Since learning a Mahalanobis metric is equivalent to learning a linear transformation we
can rewrite the two Mahalanobis metric matrices described previously as MX = UUT and
MW = VVT . U : d  t and V : |P |  t are the respective linear transformation matrices
with dimensionality t = min(rank(X), rank(W)).
To learn a heterogeneous similarity
measure between datasets and workflows using these two linear transformations we solve
the following optimization problem:
min F4 = ||R  XUVT WT ||2F + ||RRT  XUUT XT ||2F
U,V

+ ||RT R  WVVT WT ||2F +

(11)


(||U||2F + ||V||2F )
2

using an alternating gradient descent algorithm, where we first optimize for U keeping
V fixed and vice versa. The optimization problem is non-convex and the algorithm will
converge to a local minimum. The first term is similar to the low-rank matrix factorization
of Srebro, Rennie, and Jaakkola (2005). However the factorization that we learn here
is a function of the dataset and workflow feature spaces and as a result it can address
samples that are out of the training instances, also known as the cold start problem in
recommendation systems. In the case of the DM workflow planning problem this is a strong
requirement because we need to be able to plan workflows for datasets that have never been
seen during training, and also be able to qualify workflows that have also not been seen
during training. The second and third terms define metrics that reflect the performancebased similarities of datasets and workflows respectively (along the lines of the homogeneous
metrics given previously), while together they give directly the similarity/appropriateness
of a DM workflow for a dataset by estimating the expected relative predictive performance
as:
r(xu , wclo |g) = xu UVT wcTlo

(12)

We can see the heterogeneous similarity metric as performing a projection of the dataset and
workflow spaces on a common latent space on which we can compute a standard similarity
between the projections. Again for more details, see the work of Nguyen et al. (2012b).
Planning with the heterogeneous similarity measure (P2) Planning with the heterogeneous similarity measure, a strategy we will denote by P2, is much simpler than planning with the homogeneous similarity measures. Given an input dataset described by xu
at each step of the planning we make use of the relative performance estimate r(xu , wclo |g)
delivered by Eq.(12) to select the set of best workflows Sl from the set of partial workflows Cl using the selection process described by Eq.(4). Unlike the planning strategy P1
which computes r(xu , wclo |g) through a weighted average with the help of the two independently learned similarity metrics, P2 relies on a heterogeneous metric that directly computes
r(xu , wclo |g), modeling thus explicitly the interactions between dataset and workflow characteristics.
We should note here that both P1 and P2 planning strategies are able to construct
workflows even over pools of ground operators that include operators with which we have
never experimented with in the baseline experiments, provided that these operators are well
623

fiNguyen, Hilario & Kalousis

described within the dmop. This is because the meta-mining models that the planner uses
to prioritize the workflows rely on the wclo descriptions of a workflow which are generalized
descriptions over workflows and operators.
In the next section we evaluate the ability of the two planning strategies that we have
introduced to plan DM workflows that optimize the predictive performance and compare
them to a number of baseline strategies under different scenarios.

5. Experimental Evaluation
We will evaluate our approach on the data mining task of classification. The reasons for
that are rather practical. Classification is a supervised task which means that there is a
ground truth against which we can compare the results produced by some classification
algorithm, using different evaluation measures such as accuracy, error, precision etc; for
other mining tasks such as clustering, performance evaluation and comparison is a bit more
problematic due to the lack of ground truth. It has been extensively studied, and it is
extensively used in many application fields, resulting in a plethora of benchmark datasets,
which we can easily reuse to construct our base-level experiments as well as to evaluate
our system. Moreover, it has been extensively addressed in the context of meta-learning,
providing baseline approaches against which to compare our approach. Finally our approach
requires that the different algorithms and operators that we use are well described in the
dmop ontology. Due to the historical predominance of the classification task and algorithms
as well as their extensive use in real world problems, we started developing dmop from them;
as a result the task of classification and the corresponding algorithms are well described.
Having said all this, we should emphasize that our approach is not limited to the task
of classification. It can be applied to any mining task for which we can define an evaluation
measure, collect a set of benchmark datasets on which we will perform the base-level experiments, and provide descriptions of the task and the respective algorithms in the dmop.
To train and evaluate our approach, we have collected a set of benchmark classification
datasets. We have applied on them a set of classification data mining workflows. From
these base-level experiments we learn our meta-mining models which are then used by the
planner to plan data mining workflows. Then we challenge the system with new datasets
which were not used in the training of the meta-mining models, datasets for which it has to
plan new classification workflows that will achieve a high level of predictive performance.
We will explore two distinct evaluation scenarios. In the first one, we will constrain the
system so that it plans DM workflows by selecting operators from a restricted operator
pool, namely operators with which we have experimented in the base-level experiments.
Thus these are operators that are characterized in the dmop ontology and are tested in
the base-level experiments; we will call them tested operators. In the second scenario we
will allow the system to also choose from operators with which we have never experimented
but which are characterized in the dmop ontology; we will call these operators untested
operators. The goal of the second scenario is to evaluate the extend to which the system
can effectively use untested operators in the workflows it designs.
624

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

Type
FS/tested
FS/tested
FS/tested

Abbr.
IG
CHI
RF

Parameters
-#features selected k = 10
-#features selected k = 10
-#features selected k = 10

SVMRFE

-#features selected k = 10

FS/untested
CL/tested

Operator
Information Gain
Chi-Square
ReliefF
Recursive feature
elimination with SVM
Information Gain Ratio
One-nearest-neighbor

IGR
1NN

-#features selected k = 10

CL/tested

C4.5

C4.5

CL/tested

CART

CART

FS/tested

CL/tested
CL/tested

NaiveBayes with normal
density estimation
Logistic regression
Linear kernel SVM

CL/tested

Gaussian kernel SVM

SVMr

CL/untested
CL/untested
CL/untested
CL/untested

Linear discriminant analysis
Rule induction
Random decision tree
Perceptron neural network

LDA
Ripper
RDT
NNet

CL/tested

-pruning confidence C
-min. inst. per leaf M
-pruning confidence C
-min. inst. per leaf M

= 0.25
=2
= 0.25
=2

NB
LR
SVMl

-complexity C = 1
-complexity C = 1
-gamma  = 0.1

Table 2: Table of operators we used to design DM workflows for the 65 datasets. The type
corresponds to feature selection (FS) or classification (CL) operators. The operators that have been experimented are marked as tested, otherwise untested.

5.1 Base-Level Datasets and DM Workflows
To construct the base-level experiments, we have collected 65 real world datasets on genomic
microarray or proteomic data related to cancer diagnosis or prognosis, mostly from The
National Center for Biotechnology Information5 . As is typical with such datasets, the
datasets we use are characterized by high-dimensionality and small sample size, and a
relatively low number of classes, most often two. They have an average of 79.26 instances,
15268.57 attributes, and 2.33 classes.
To build the base-level experiments, we applied on these datasets workflows that consisted either of a single classification algorithm, or of a combination of feature selection and
a classification algorithm. Although the HTN planner we use (Kietz et al., 2009, 2012) is
able to generate much more complex workflows, over 16 different tasks, with more than 100
operators, we had to limit ourselves to the planning of classification, or feature selection
and classification, workflows simply because the respective tasks, algorithms and operators
are well annotated in the dmop. This annotation is important for the characterization of
the workflows and the construction of good meta-mining models which are used to guide
the planning. Nevertheless, the system is directly usable on planning scenarios of any com5. http://www.ncbi.nlm.nih.gov/

625

fiNguyen, Hilario & Kalousis

plexity, as these are describe in the HTN grammar, provided that the appropriate tasks,
algorithms and operators are annotated in the dmop ontology.
We used four feature selection algorithms together with seven classification algorithms
to build our set of base-level training experiments. These are given in Table 2, noted as
tested. As we have mentioned previously, we can also plan over the operators parameters
by discretizing the range of values of the parameters and treating them as properties of
the operators. Another alternative is to use inner cross-validation to automatically select
over a set of parameter values; strictly speaking, in that case, we would not be selecting a
standard operator but its cross-validated variant. Nevertheless, this would incur a significant
computational cost.
Overall, we have seven workflows that only contained a classification algorithm, and
28 workflows that had a combination of a feature selection with a classification algorithm,
resulting to a total of 35 workflows applied on 65 datasets which corresponds to 2275 baselevel DM experiments. The performance measure we use is accuracy which we estimate
using ten-fold cross-validation. For all algorithms, we used the implementations provided
in the RapidMiner DM suite (Klinkenberg et al., 2007).
As already said, we have two evaluation settings. In the first, Scenario 1, we constrain
the system to plan workflows using only the tested operators. In the second, Scenario 2,
we allow the system to select also from untested operators. These additional operators are
also given in Table 2, denoted as untested. The total number of possible workflows in this
setting is 62.
5.2 Meta-learning & Default Methods
We will compare the performance of our system against two baseline methods and a default
strategy. The two baseline methods are simple approaches that fall in the more classic metalearning stream but instead of selecting between individual algorithms they select between
workflows. Thus they cannot plan DM workflows and they can only be used in a setting in
which all workflows to choose from have been seen in the model construction phase.
The first meta-learning method that we will use, which we will call Eucl, is the standard
approach in meta-learning (Kalousis & Theoharis, 1999; Soares & Brazdil, 2000), which
makes use of the Euclidean based similarity over the dataset characteristics to select the N
most similar datasets to the input dataset xu for which we want to select workflows and
then averages their workflow rank vectors to produce the average rank vector:
N
1 X
rxui , xui  {arg max xTu xui }N
N
xui X

(13)

i

which it uses to order the different workflows. Thus this method simply ranks the workflows
according to the average performance they achieve over the neighborhood of the input
dataset. The second meta-learning method that we call Metric makes use of the learned
dataset similarity measure given by Eq.(8) to select the N most similar datasets to the
input dataset and then averages as well their respective workflow rank vectors:
N
1 X
rxui , xui  {arg max xTu MX xui }N
N
xui X
i

626

(14)

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

0.8

0.6

0.4

0.2

CHI+C45
RF+NBN
SVMRFE+C45
CHI+CART
RF+C45
SVMr
1NN
IG+C45
RF+1NN
SVMRFE+CART
C45
CHI+SVMr
RF+CART
CHI+SVMl
IG+CART
RF+SVMr
RF+SVMl
SVMRFE+1NN
CHI+1NN
IG+1NN
SVMRFE+SVMr
CART
CHI+NBN
IG+SVMr
SVMRFE+LR
CHI+LR
RF+LR
SVMRFE+NBN
IG+SVMl
SVMl
IG+LR
SVMRFE+SVMl
NBN
IG+NBN
LR

0.0

Figure 7: Percentage of times that a workflow is among the top-5 workflows over the different datasets.

For the default recommendation strategy, we will simply use the average of the rxui workflow
rank vectors over the collection of training datasets:
1X
rxui , xui  X
n
n

(15)

i

to rank and select the workflows. We should note that this is a rather difficult baseline to
beat. To see why this is the case we plot in Figure 7 the percentage of times that each of
the 35 DM workflows appears among the top-5 worfklows over the 65 datasets. The top
workflow, consisting of just the LR algorithm, is among the top-5 for more than 80% of
the datasets. The next two workflows, NBN and IG with NBN, are among the top-5 for
almost 60% of the datasets. In other words if we select the top-5 workflows using the default
strategy then in roughly 80% of the datasets LR will be correctly between them, while for
NBN and IG with NBN this percentage is around 60%. Thus the set of dataset we have
here is quite similar with respect to the workflows that perform better on them, making the
default strategy a rather difficult one to beat.
5.3 Evaluation Methodology
To estimate the performance of the planned workflows in both evaluation scenarios we will
use leave-one-dataset-out, using each time 64 datasets on which we build the meta-mining
models and one dataset for which we plan.
We will evaluate each method by measuring how well the list, L, of top-k ranked workflows, that it delivers for a given dataset, correlates with the true list, T , of top-k ranked
627

fiNguyen, Hilario & Kalousis

workflows for that dataset using a rank correlation measure. We place true between quotes
because in the general case, i.e. when we do not restrict the choice of operators to a specific
set, we cannot know which are the true best workflows unless we exhaustively examine an
exponential number of them, however since here we select from a restricted list of operators
we can have the set of the best. More precisely, to measure the rank correlation between
two lists L and T , we will use the Kendall distance with p penalty, which we will denote
K (p) (L, T ) (Fagin, Kumar, & Sivakumar, 2003). The Kendall distance gives the number of
exchanges needed in a bubble sort to convert one list to the other. It assigns a penalty of
p to each pair of workflows such that one workflow is in one list and not in the other; we
set p = 1/2. Because K (1/2) (L, T ) is not normalized, we propose to define the normalized
Kendall similarity Ks(L,T) as:
1

K ( 2 ) (L, T )
Ks(L, T ) = 1 
u

(16)

1

(2)
and
Pktakes values in [0, 1]. u is the upper bound of K (L, T ) given by u = 0.5k(5k + 1) 
2 i=1 i, derived from a direct application of lemma 3.2 of the work of Fagin et al. (2003),
where we assume that the two lists do not share any element. We will qualify each method,
m, including the two baselines, by its Kendall similarity gain, Kg(m), i.e. the gain (or loss)
it achieves with respect to the default strategy for a given datasets, which we compute as:

Kg(m)(L, T ) =

Ks(m)(L, T )
1
Ks(def )(L, T )

(17)

For each method, we will report its average Kendall similarity gain overall the datasets,
Kg(m). Note that, in Scenario 1, the default strategy is based on the average ranks of the
35 workflows. In Scenario 1, the default strategy is based on the average ranks of the 62
workflows, which we also had to experiment with in order to set the baseline.
In addition to see how well the top-k ranked list of workflows, that a given method
suggests for a given dataset, correlates to the true list, we also compute the average accuracy
that the top-k workflows it suggests achieve for the given dataset, and we report the average
overall datasets.
5.4 Meta-mining Model Selection
At each iteration of the leave-one-dataset-out evaluation of the planning performance, we
rebuild the meta-mining model and we tune its  parameter of the Mahalanobis metric
learning using inner ten-fold cross-validation; we select the  value that maximizes the
Spearman rank correlation coefficient between the predicted workflow rank vectors and the
real rank vectors. For the heterogenous metric, we used the same parameter setting defined
by Nguyen et al. (2012b). For the two meta-learning methods, we fixed the number N
of nearest neighbors to five, reflecting our prior belief on appropriate neighborhood size.
For planning, we set manually the dataset kernel width parameter to kx = 0.04 and the
workflow kernel width parameter to kw = 0.08 which result on small dataset and workflow
neighborhoods respectively. Again, these two parameters were not tuned but simply set on
our prior belief of their respective neighborhood size.
628

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

(b) Scenario 2, tested and untested operators.

0.10

10

15

20

25

30

Kg

0.00

0.05

5

0.10
0.15

0.15

0

P2
P1
def62

0.05

0.00
0.05

P2
P1
Metric
Eucl
def32

0.10

Kg

0.05

0.10

(a) Scenario 1, only tested operators.

35

0

k

5

10

15

20

25

30

35

k

Figure 8: Average correlation gain Kg of the different methods against the baseline on the
65 bio-datasets. In the x-axis, k = 2 . . . 35, we have the number of top-k workflows
suggested to the user. P1 and P2 are the two planning strategies. Metric and
Eucl are baseline methods and defX is the default strategy computed over the set
of X workflows.

5.5 Experimental Results
In the following sections we give the results of the experimental evaluation of the different
methods we presented so far under the two evaluation scenarios described above.
5.5.1 Scenario 1, Building DM workflows from a Pool of Tested Only
Operators
In this scenario, we will evaluate the quality of the DM workflows constructed by the two
planning strategies P1 and P2 and compare it to that of the two baseline methods as well
as to that of the default strategy. We do leave-one-dataset-out to evaluate the workflow
recommendations given by each method. In Figure 8(a) we give the average Kendall gain
Kg for each method against the default strategy which we compute over their top-k lists for
k = 2, . . . , 35. Clearly the P2 strategy is the one that gives the largest improvements with
respect to the default strategy, between 5% to 10% of gain, compared to any other method.
We establish the statistical significance of these results for each k, counting the number
of datasets for which each method was better/worse than the default, using a McNemars
test. We summarize in Figure 9 the statistical significance results given the p-values for
the different ks and give the detailed results in Table 4 in the appendix for all methods for
k = 2 . . . 35. We can see that the P 2 is by far the best method being significantly better
than the default for 16 out of the 34 values of k, close to significant (0.05 < p-value  0.1)
ten out of the 34 times and never significantly worse. From the other methods, only P2
managed to beat the default and this only for 2 out of the 34 cases of k.
629

fiNguyen, Hilario & Kalousis

0.5
5

10

15

20

25

30

35

5

10

15

20

25

30

Metric (0 Wins/0 Losses)

Eucl (0 Wins/0 Losses)

35

0.5
0.0
1.0

1.0

0.5

0.0

pvalue

0.5

1.0

k

1.0

k

0.5

pvalue

0.0

pvalue

1.0

0.5

0.0
1.0

0.5

pvalue

0.5

1.0

P1 (2 Wins/0 Losses)

1.0

P2 (16 Wins/0 Losses)

5

10

15

20

25

30

35

5

k

10

15

20

25

30

35

k

Figure 9: P-values of the McNemars test on the number of times that the Kendal similarity
of a method is better than the default for a given k, Scenario 1. A positive pvalue means more wins than losses, a negative the opposite. The solid lines are
at p = +/  0.05, the dash-dotted at p = +/  0.1. The X Wins/ Y Losses in
the header indicates the number of times over k = 3..35 that the method was
significantly better/worse then the default.

When we examine the average accuracy that the top-k workflows suggested by each
method achieve, the advantage of P2 is even more striking. Its average accuracy is 1.25%
and 1.43% higher than that of the default strategy, for k = 3 and k = 5 respectively, see
Table 3(a). For k = 3, P2 achieves a higher average accuracy than the default in 39 out of
the 65 datasets, while it under-performs compared to the default only in 20. Using again
a McNemars test the statistical significance is 0.02, i.e. P2 is significantly better than
the default strategy when it comes to the average accuracy of the top k = 3 workflows it
plans; the results are similar for k = 5. In fact for the eight top-k lists, k = 3 . . . 10, P2 is
significantly better than the default for five values of k, close to significantly better once,
and never significantly worse. For the higher values of k, k = 11 . . . 35, it is significantly
better 11 times, close to significantly better three times, and never significantly worse. It
stops being significantly better when k > 30. For such large k values, the average is taken
over almost all workflows, thus we do not expect important differences between the lists
produced by the different methods. In Figure 10, we visualize the statistical significance
results for the different values of k = 3 . . . 35 and give the detailed results in Table 5 of the
Appendix.
630

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

0.5
5

10

15

20

25

30

35

5

10

15

20

25

30

Metric (4 Wins/0 Losses)

Eucl (0 Wins/0 Losses)

35

0.5
0.0
1.0

1.0

0.5

0.0

pvalue

0.5

1.0

k

1.0

k

0.5

pvalue

0.0

pvalue

1.0

0.5

0.0
1.0

0.5

pvalue

0.5

1.0

P1 (6 Wins/0 Losses)

1.0

P2 (16 Wins/0 Losses)

5

10

15

20

25

30

35

5

k

10

15

20

25

30

35

k

Figure 10: P-values of the McNemars test on the number of times that the Average Accuracy of a method is better than the default for a given k, Scenario 1. Same
figure interpretation as in Figure 9

P1 is never significantly better than the default for all k = 3 . . . 10, while for k = 11 . . . 35,
it is significantly better for nine values of k, close to significantly better three times, and
close to significantly worse once. The Metric baseline is never significantly better than the
default for all k = 3 . . . 10, while for k = 11 . . . 35, it is significantly better for four values of
k,and close to significantly better four times. The results of EC are quite poor. In terms of
the average accuracy, it is very similar to the default, while in terms of the number of times
that it performs better than the default, for most of the cases, it is less than the number of
times that it performs worse than the default. As before in Figure 10 we give the results
of the statistical significance results for the different values of k and the detailed results in
Table 5 of the appendix. P2 is the only method that directly learns and exploits in the
workflow planning the associations between the dataset and the workflow characteristics
which as the experimental results clearly demonstrate is the strategy that best pays off.
5.5.2 Scenario 2: Building DM workflows from a Pool of Tested and
Non-Tested Operators
In the second scenario, we evaluate the performance of the two planning strategies, P1 and
P2, where the pool of available operators during the planning is not any more limited to
operators with which we have already experimented in the base-level experimented with,
but it is extended to include additional operators which are described in the dmop ontology.
631

fiNguyen, Hilario & Kalousis

(a) Scenario 1, only tested operators

P2
P1
Metric
Eucl
def35

Avg. Acc
0.7988
0.7886
0.7861
0.7829
0.7863

k=3
W/L
39/20
26/38
25/38
30/32

p  value
+0.02
0.17
0.13
0.90

Avg. Acc
0.7925
0.7855
0.7830
0.7782
0.7787

k=5
W/L
41/21
35/28
32/33
32/33

p  value
+0.02
0.45
1.00
1.00

(b) Scenario 2, tested and untested operators

P2
P1
def62

Avg. Acc
0.7974
0.7890
0.7867

k=3
W/L
39/24
29/34

p  value
0.08
0.61

Avg. Acc
0.7907
0.7853
0.7842

k=5
W/L
34/29
31/34

p  value
0.61
0.80

Table 3: Average accuracy of the top-k workflows suggested by each method. W indicates
the number of datasets that a method achieved a top-k average accuracy larger
than the respective of the default, and L the number of datasets that it was smaller
than the default. p  value is the result of the McNemars statistical significance
test; + indicates that the method is statistically better than the default.

We have already described the exact setting in section 5.1; as a reminder the number of
possible workflows is now 62. As before, we will estimate performances using leave-onedataset-out. Note that the two baseline methods, Metric and Eucl, are not applicable in
this setting, since they can be only deployed over workflows with which we have already
experimented in the baseline experiments. Here, as we already explained in section 5.3, the
default strategy will correspond to the average rank of the 62 possible workflows and we
will denote it with def62. Note that this is a highly optimistically-biased default method
since it relies on the execution of all 62 possible workflows on the base-level datasets, unlike
P1 and P2 which only get to see 35 workflows for the model building, and the operators
therein, but will plan over the larger pool.
In Figure 8(b), we give the average Kendall gain Kg for P1 and P2 over the def62
baseline. Similarly to the first evaluation scenario, P2 has an advantage over P1 since it
demonstrates higher gains over the default. Note though that these performance gains are
now smaller than they were previously. In terms of the number of k values for which P2
is (close to be) significantly better than the default, these are now six and eight, for the
different k = 2 . . . 35. def62 is now once significantly better than P2 and once close to
being significantly better. In what concerns P1, there is no significant difference between
its performance and def62, for any value of k. For values of k > 30, P2 systematically
under-performs compared to def62, due to the advantage of the latter that comes from
seeing the performance of all 62 workflows over the base-level dataset. We visualize the
statistical significance results in the top row of Figure 11, and give the detailed results in
Table 6 of the Appendix for all values of k = 2 . . . 35.
632

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

0.5
10

15

20

25

30

35

5

10

15

20

25

30

k

P2 (1 Wins/13 Losses)

P2 (0 Wins/3 Losses)

35

0.5
0.0
0.5
1.0

1.0

0.5

0.0

pvalue

0.5

1.0

k

1.0

5

pvalue

0.0

pvalue

1.0

0.5

0.0
1.0

0.5

pvalue

0.5

1.0

P1 (0 Wins/0 Losses)

1.0

P2 (4 Wins/1 Loss)

5

10

15

20

25

30

35

5

k

10

15

20

25

30

35

k

Figure 11: Top row p-values of the McNemars test on the number of times that the Kendall
similarity of a method is better than the default for a given k, Scenario 2. Bottom
row same for Average Accuracy. Same figure interpretation as in Figure 9.

In what concerns the performance of P2 with respect to the average accuracy of the
top-k workflows it suggests, it has a slight advantage over def62 but only for very small
values of k, up to four. It is significantly better compared to def62 only once, k = 4. For
k = 5 to 17, the two methods have no significant difference, while for k = 18 . . . 35 P2 is
worse, 13 times in a significant manner. For P1 the picture is slightly different, its average
accuracy is not significantly different than def62, with the exception of three k values for
which it is significantly worse. We visualize the statistical significance results in the bottom
row of Figure 11, and give the detailed results in Table 7. It seems that the fact that P2
learns directly the associations between datasets and workflow characteristics puts it at a
disadvantage when we want to plan over operators that have not been tested in the training
phase. In such a scenario, the P1 strategy which weights preferences by dataset similarity
and by workflow similarity seems to cope better with untested operators. Nevertheless
it is still not possible to outperform the default strategy in a significant manner, keeping
however in mind that def62 is an optimistic default strategy because it is based on the
experimentation of all possible workflows on the training dataset.
5.6 Discussion
In the previous sections, we evaluated the two workflow planning strategies in two settings:
planning only over tested operators, and planning with both tested and untested operators.
633

fiNguyen, Hilario & Kalousis

In the first scenario, the P2 planning strategy that makes use of the heterogeneous metric
learning model, which directly connects dataset to workflow characteristics, clearly stands
out. It outperforms the default strategy in terms of the Kendall Similarity gain, in a
statistically significant, or close to statistically significant, manner for 24 values of k 
[2, . . . , 35]; in terms of the average accuracy of its top-k workflows, it outperforms it for 20
values of k in a statistically significant, or close to statistically significant, manner. All the
other methods, including P1, follow with a large performance difference from P2.
When we allow the planners to include in the workflows operators which have not
been used in the baseline experiments, but which are annotated in the dmop ontology, P2s
performance advantage is smaller. In terms of the Kendall similarity gain, this is statistically
significant, or close to, for k  [10, . . . , 20]. With respect to the average accuracy of its top-k
lists, this is better than the default only for very small lists, k = 3, 4; for k > 23, it is in
fact significantly worse. P1 fairs better in the second scenario, however its performance is
not different from the default method. Keep in mind though that the baseline used in the
second scenario is a quite optimistic one.
In fact, what we see is that we are able to generalize and plan well over datasets, as
evidenced by the good performance of P2 in the first setting. However, when it comes
to generalizing both over datasets and operators as it is the case for the second scenario
the performance of the planned workflows is not good, with the exception of the few top
workflows. If we take a look at the new operators we added in the second scenario, these were
a feature selection algorithm, Information Gain Ratio, and four classification algorithms,
namely a Linear Discriminant Algorithm, the Ripper rule induction algorithm, a Neural Net
algorithm, and a Random Tree. Out of them, only for Information Gain Ratio we have seen
during the base level set of experiments an algorithm, Information Gain, that has a rather
similar learning bias to it. The Ripper rule induction is a sequential covering algorithm,
the closest operators to which in our set of training operators are the two decision tree
algorithms which are recursive partitioning algorithms. With respect to the dmop ontology,
Ripper shares a certain number of common characteristics with decision trees, however the
meta-mining model contains no information on how the set-covering learning bias performs
over different datasets. This might lead to it being selected for a given dataset based on its
common features with the decision trees, while its learning bias is not in fact appropriate
for that dataset. Similar observations hold for the other algorithms, for example LDA
shares a number of properties with SVMl and LR, however its learning bias, maximizing
the between-to-within class distances ratio, is different from the learning biases of these
two, as before the meta-mining model contains no information on how its bias associates
with dataset characteristics.
Overall, the extent to which the system will be able to plan, over tested and untested
operators, workflows that achieve a good performance, depends on the extend to which
the properties of the latter have been seen during the training of the meta-mining models
within the operators with which we have experimented with, as well as on whether the
unseen properties affect critically the final performance. In the case that all operators are
well characterized experimentally, as we did in Scenario 1, then the performance of the
workflows designed by the P2 strategy is very good. Note that it is not necessary that all
operators or workflows are applied to all datasets, it is enough to have a sufficient set of
experiments for each operator. The heterogeneous metric learning algorithm can handle
634

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

(b)

(a)

X-Validation

X-Validation

DataProcessing
Algorithm
FWAlgorithm

ClassificationModeling DataProcessing
Algorithm
Algorithm
FWAlgorithm

HighBiasCMA

MultivariateFW
Algorithm

ClassificationModeling
Algorithm
HighVarianceCMA

UnivariateFW
Algorithm

Figure 12: Top-ranked workflow patterns according to their average absolute weights given
in matrix V.

incomplete preference matrices, using only the available information. Of course it is clear
that the more the available information, whether in the form of complete preference matrices
or in the form of extensive base-level experiments over large number of datasets, the better
the quality of the learned meta-mining model will be. It will be interesting to explore the
sensitivity of the heterogeneous metric learning method over different levels of completeness
of the preference matrix; however this is outside the scope of the present paper.
We can quantify the importance of the different workflow patterns and that of the
operators properties by analyzing the linear transformation over the workflow patterns
contained in the heterogeneous metric. More precisely, we establish the learned importance
of each workflow pattern by averaging the absolute values of the weights it is assigned over
the different factors (rows) of the V linear transformation matrix of Eq.(11). Note that
under this approach, we only establish the importance of the patterns, and not whether
they are associated with good or bad predictive performance. In Figure 12, we give the two
most important patterns as these are determined on the basis of their averaged absolute
weights. Both of them describe relations between the workflow operators, the first one
indicates that we have a multivariate feature weighting algorithm followed by a high bias
classification algorithm, while the second describes a univariate feature weighting algorithm
followed by a high bias classification algorithm. A systematic analysis of the learned model
could provide hints on where one should focus the ontology building effort, looking at what
are the important patterns as well as what are the patterns that are not used. In addition,
it can reveal which parts of the ontology might need refinement in order to distinguish
between different workflows with respect to their expected performance.

6. Conclusions and Future Work
In this paper, we have presented what is, to the best of our knowledge, the first system
that is able to plan data mining workflows, for a given task and a given input dataset,
that are expected to optimize a given performance measure. The system relies on the tight
interaction of a hierarchical task network planner with a learned meta-mining model to
plan the workflows. The meta-mining model, a heterogeneous learned metric, associates
datasets characteristics with workflow characteristics which are expected to lead to good
635

fiNguyen, Hilario & Kalousis

performance. The workflow characteristics describe relations between the different components of the workflows, capturing global interactions of the various operators that appear
within them, and incorporate domain knowledge as the latter is given in a data mining ontology (dmop). We learn the meta-mining model on a collection of past base-level mining
experiments, data mining workflows applied on different datasets. We carefully evaluated
the system on the task of classification and we showed that it outperforms in a significant
manner a number of baselines and the default strategy when it has to plan over operators
with which we have experimented with in the base-level experiments. The performance
advantage is less pronounced when it has to consider also during planning operators with
which we have not experimented with in the base-level experiments, especially when the
properties of these operators were not present within other operators with which we have
experimented with in the base-level experiments.
The system is directly applicable to other mining tasks e.g. regression, clustering. The
reasons for which we focused on classification were mainly practical: there is extensive
annotation of the classification task and the related concepts in the data mining ontology,
large availability of classification datasets, and extensive relevant work on meta-learning
and dataset characterization for classification. The main hurdle in experimenting with a
different mining task is the annotation of the necessary operators in the dmop ontology and
the set up of a base-level collection of mining experiments for the specific task. Although
the annotation of new algorithms and operators is a quite labor intensive task, many of the
concepts currently available in the dmop are directly usable in other mining tasks, e.g. cost
functions, optimization problems, feature properties etc. In addition, there is a small active
community, the DMO-foundry6 , maintaining and augmenting collaboratively the ontology
with new tasks and operators, significantly reducing the deployment barrier for a new task.
In the DMO-foundry web site, one can find a number of tools and templates to facilitate
the addition of new concepts and operators in the ontology as well as to annotate the
existing ones. Having said that we should note that the use of dmop is not sine-qua-non
for the system to function. We can very well perform the workflow characterization task
by mining just over ground operators, without using the ontology. The downside of that
would be that the extracted patterns will not be generalized nor will they contain operator
properties. Instead they will be defined over ground operators. Everything else remains as
it is.
There are a number of issues that we still need to explore in a finer detail. We would
like to gain a deeper understanding and a better characterization of the reduced performance in planning over untested operators; for example, under what conditions we can be
relatively confident on the suitability of an untested operator within a workflow. We want
to experiment with the strategy we suggested for parameter tuning, in which we treat the
parameters as yet another property of the operators, in order to see whether it gives better
results; we expect it will. We want to study in detail how the level of missing information
in the preference matrix affects the performance of the system, as well as whether using
ranking based loss functions in the metric learning problem instead of sum of squares would
lead to even better performance.

6. http://www.dmo-foundry.org/

636

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

On a more ambitious level we want to bring in ideas from reinforcement learning (Sutton
& Barto, 1998); let the system design its own workflows in a systematic way and have them
applied on the collection of available datasets in order to derive even better characterizations
of the workflow space and how they relate to the dataset space, exploring for example areas
in which the meta-mining model is less confident.

Acknowledgments
This work has been partially supported by the European Community 7th framework program ICT-2007.4.4 under grant number 231519 e- Lico: An e-Laboratory for Interdisciplinary Collaborative Research in Data Mining and Data-Intensive Science. Alexandros
Kalousis was partially supported by the RSCO ISNET NFT project. The basic HTN planner has been the result of collaborative work within the e-LICO project of Jorg-Uwe Kietz,
Floarea Serban, Simon Fischer. We would like to thank Jun Wang for his important contribution in developing the metric learning part of the paper. In addition we would like to
thank all the members of the AI lab, Adam Woznica, Huyen Do, and Jun Wang, for the
significant effort they placed in providing content in the DMOP. Finally, we would like to
thank the reviewers for the suggestions that helped improve the paper.

637

fiNguyen, Hilario & Kalousis

Appendix A. Detailed Results
k
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
Total

P2
W L p-value
8
7
1
17 11 0.344
24 18 0.440
35 21 0.082
39 23 0.056
41 19 0.006
43 20 0.005
43 22 0.013
47 18 0.000
40 24 0.060
42 21 0.011
40 25 0.082
40 25 0.082
43 21 0.008
40 25 0.082
40 25 0.082
40 25 0.082
40 25 0.082
38 27 0.214
38 27 0.214
39 25 0.104
38 27 0.214
41 24 0.047
40 24 0.060
39 26 0.136
41 23 0.033
42 22 0.017
41 24 0.047
41 24 0.047
44 21 0.006
44 21 0.006
43 21 0.008
42 21 0.011
42 21 0.011
Wins 16/Losses 0

P1
W L p-value
13 13 1
17 20 0.742
18 27 0.233
24 29 0.582
29 31 0.897
33 31 0.900
36 27 0.313
33 31 0.900
35 30 0.619
30 35 0.619
34 29 0.614
33 28 0.608
38 26 0.169
38 26 0.169
37 27 0.260
35 29 0.531
35 29 0.531
34 30 0.707
37 26 0.207
35 30 0.619
37 27 0.260
35 29 0.531
36 28 0.381
36 28 0.381
36 29 0.456
38 27 0.214
38 26 0.169
39 26 0.136
39 25 0.104
40 24 0.060
42 23 0.025
41 24 0.047
39 25 0.104
40 24 0.060
Wins 2/Losses 0

Metric
W L p-value
4
11 0.121
12 16 0.570
19 27 0.302
23 27 0.671
26 35 0.305
27 37 0.260
30 34 0.707
30 33 0.801
29 35 0.531
26 38 0.169
33 31 0.900
32 33 1.000
34 31 0.804
34 30 0.707
34 31 0.804
32 32 1.000
34 31 0.804
32 33 1.000
31 32 1.000
30 35 0.619
31 34 0.804
32 33 1.000
33 31 0.900
33 32 1.000
31 34 0.804
32 32 1.000
35 29 0.531
35 30 0.619
37 28 0.321
39 26 0.136
39 26 0.136
38 27 0.214
37 27 0.260
36 28 0.381
Wins 0/Losses 0

Eucl
W L p-value
9
11 0.823
16 15 1.000
25 19 0.450
29 25 0.683
32 27 0.602
35 25 0.245
31 30 1.000
32 32 1.000
33 31 0.900
30 35 0.619
27 37 0.260
28 36 0.381
33 31 0.900
32 33 1.000
30 35 0.619
31 34 0.804
33 32 1.000
32 33 1.000
32 33 1.000
28 37 0.321
30 35 0.619
30 35 0.619
32 33 1.000
31 34 0.804
30 35 0.619
29 35 0.531
29 35 0.531
29 36 0.456
30 35 0.619
31 34 0.804
32 33 1.000
32 33 1.000
32 33 1.000
31 34 0.804
Wins 0/Losses 0

Table 4: Wins/Losses and respective P-values of the McNemars test on the number of
times that the Kendal similarity of a method is better than the Kendal similarity
of the default, Scenario 1. In bold, the winning p-value that are lower than 0.05.

638

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

k
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
Total

P2
Avg.Acc W L p-value
0.798
39 20 0.019
0.793
41 21 0.015
0.792
41 21 0.015
0.789
43 21 0.008
0.786
39 24 0.077
0.784
38 25 0.130
0.782
41 24 0.047
0.780
36 26 0.253
0.778
41 20 0.010
0.777
36 27 0.313
0.777
44 20 0.004
0.774
38 23 0.073
0.773
38 25 0.130
0.772
40 22 0.030
0.771
43 18 0.002
0.770
40 22 0.030
0.769
40 22 0.030
0.767
36 26 0.253
0.766
42 21 0.011
0.765
34 29 0.614
0.763
39 24 0.077
0.762
38 26 0.169
0.761
37 25 0.162
0.760
37 24 0.124
0.759
39 19 0.012
0.757
33 20 0.099
0.755
32 14 0.012
0.753
33 15 0.014
0.751
32 10 0.001
0.749
21 15 0.404
0.747
8
5
0.579
0.742
18 10 0.185
0.737
2
3
1
Wins 16/Losses 0

P1
Avg.Acc W L p-value
0.788
26 38 0.169
0.786
28 35 0.449
0.785
35 28 0.449
0.785
38 25 0.130
0.786
33 30 0.801
0.783
33 29 0.703
0.782
40 25 0.082
0.781
38 27 0.214
0.778
38 25 0.130
0.777
30 33 0.801
0.777
40 22 0.030
0.775
40 23 0.043
0.774
37 26 0.207
0.772
40 24 0.060
0.771
41 21 0.015
0.770
40 22 0.030
0.769
39 23 0.056
0.768
35 27 0.374
0.767
41 18 0.004
0.765
33 24 0.289
0.763
45 19 0.001
0.762
33 27 0.518
0.761
34 30 0.707
0.760
43 18 0.002
0.758
43 20 0.005
0.757
39 23 0.056
0.754
34 17 0.025
0.751
32 27 0.602
0.748
28 30 0.895
0.746
22 31 0.271
0.744
16 30 0.055
0.741
26 36 0.253
0.737
2
2
1
Wins 6/0 Losses

Metric
Avg.Acc W L p-value
0.786
25 38 0.130
0.784
26 37 0.207
0.783
32 33 1
0.782
33 32 1
0.780
32 31 1
0.779
28 33 0.608
0.779
35 27 0.374
0.778
34 30 0.707
0.776
34 28 0.525
0.775
29 33 0.703
0.774
40 24 0.060
0.773
39 25 0.104
0.771
32 33 1
0.770
33 29 0.703
0.770
40 25 0.082
0.769
38 27 0.214
0.767
36 26 0.253
0.767
29 35 0.531
0.766
38 25 0.130
0.765
36 25 0.200
0.764
42 22 0.017
0.763
35 27 0.374
0.762
36 29 0.456
0.761
45 11 0.001
0.759
41 20 0.010
0.758
38 24 0.098
0.755
35 10 0.000
0.752
33 19 0.071
0.750
34 17 0.025
0.748
22 18 0.635
0.745
13 17 0.583
0.742
19 21 0.874
0.737
2
5
0.449
Wins 4/Losses 0

EC
Avg.Acc W L p-value
0.782
30 32 0.898
0.780
32 32 1
0.778
32 33 1
0.777
34 30 0.707
0.776
30 33 0.801
0.774
30 35 0.619
0.773
30 34 0.707
0.773
31 33 0.900
0.773
31 34 0.804
0.772
26 37 0.207
0.772
31 33 0.900
0.772
33 30 0.801
0.771
31 34 0.804
0.770
30 33 0.801
0.769
34 30 0.707
0.767
33 31 0.900
0.767
32 31 1
0.766
30 35 0.619
0.765
37 28 0.321
0.764
33 30 0.801
0.762
32 30 0.898
0.761
30 32 0.898
0.760
30 32 0.898
0.758
37 26 0.207
0.757
37 22 0.068
0.756
33 26 0.434
0.754
31 19 0.119
0.751
32 24 0.349
0.749
25 28 0.783
0.747
20 28 0.312
0.745
12 25 0.048
0.742
13 18 0.472
0.737
2
3
1
Wins 0/ Losses 0

Def
Avg.Acc
0.786
0.785
0.778
0.777
0.780
0.778
0.775
0.775
0.774
0.774
0.771
0.771
0.771
0.769
0.766
0.765
0.765
0.766
0.763
0.763
0.761
0.761
0.760
0.756
0.756
0.756
0.753
0.751
0.749
0.748
0.747
0.742
0.737

Table 5: Average Accuracy, Wins/Losses, and respective P-values of the McNemars test on
the number of times the Average Accuracy of a method is better than the Average
Accuracy of the default, Scenario 1. In bold, the winning p-value that are lower
than 0.05.

639

fiNguyen, Hilario & Kalousis

k
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
Total

P2
W L p-value
9
24 0.014
15 28 0.067
25 32 0.426
28 34 0.525
33 30 0.801
36 29 0.456
38 27 0.214
40 25 0.082
43 22 0.013
43 22 0.013
40 25 0.082
41 24 0.047
43 22 0.013
43 22 0.013
40 25 0.082
42 23 0.025
40 25 0.082
40 25 0.082
40 25 0.082
39 26 0.136
39 26 0.136
38 27 0.214
38 27 0.214
40 25 0.082
40 25 0.082
38 27 0.214
38 27 0.214
38 27 0.214
37 28 0.321
35 30 0.619
35 30 0.619
30 35 0.619
29 36 0.456
29 36 0.456
Wins 4/Losses 0

P1
W L p-value
8
11 0.646
13 13 1.000
17 18 1.000
21 25 0.658
24 29 0.582
32 28 0.698
34 26 0.366
34 29 0.614
35 30 0.619
33 32 1.000
34 31 0.804
32 32 1.000
34 31 0.804
36 29 0.456
35 30 0.619
36 29 0.456
35 30 0.619
35 30 0.619
36 29 0.456
36 28 0.381
37 28 0.321
35 30 0.619
35 30 0.619
34 31 0.804
34 31 0.804
35 30 0.619
34 30 0.707
34 31 0.804
33 32 1.000
33 32 1.000
33 32 1.000
33 32 1.000
34 31 0.804
32 33 1.000
Wins 0/Losses 0

Table 6: Wins/Losses and P-values of the McNemars test on the number of times Kendal
similarity of a method is better than the Kendal similarity of the default, Scenario
2. In bold, the winning p-value that are lower than 0.05.

640

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

k
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
Total

P2
Avg.Acc W L
0.797
39 24
0.792
44 20
0.790
34 29
0.787
37 27
0.785
37 27
0.783
36 28
0.782
35 28
0.781
38 26
0.779
38 25
0.777
34 30
0.775
34 30
0.774
35 28
0.773
35 29
0.773
33 32
0.772
32 33
0.770
19 44
0.769
26 39
0.768
24 37
0.768
25 39
0.767
24 39
0.767
26 38
0.766
23 40
0.765
23 42
0.763
20 45
0.762
14 51
0.762
15 50
0.761
16 48
0.760
18 47
0.759
18 47
0.757
18 47
0.756
17 48
0.756
16 49
0.755
13 51
Wins 1/Losses

p-value
0.077
0.004
0.614
0.260
0.260
0.381
0.449
0.169
0.130
0.707
0.707
0.449
0.531
1.000
1.000
0.002
0.136
0.124
0.104
0.077
0.169
0.043
0.025
0.002
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
0.000
13

P1
Avg.Acc W L p-value
0.789
29 34 0.614
0.784
33 31 0.900
0.785
31 34 0.804
0.782
32 32 1.000
0.783
33 32 1.000
0.783
32 33 1.000
0.783
30 34 0.707
0.784
31 33 0.900
0.782
35 29 0.531
0.780
36 29 0.456
0.779
38 27 0.214
0.779
38 26 0.169
0.777
37 27 0.260
0.776
34 31 0.804
0.774
31 33 0.900
0.773
26 38 0.169
0.772
27 37 0.260
0.772
28 37 0.321
0.770
23 42 0.025
0.770
24 40 0.060
0.769
29 36 0.456
0.768
26 38 0.169
0.768
29 36 0.456
0.767
24 40 0.060
0.768
22 42 0.017
0.767
24 41 0.047
0.767
32 32 1.000
0.766
33 31 0.900
0.766
39 26 0.136
0.765
35 29 0.531
0.765
33 33 1.000
0.764
31 34 0.804
0.763
27 38 0.214
Wins 0/Losses 3

Def
Avg.Acc
0.786
0.780
0.784
0.778
0.778
0.779
0.778
0.776
0.773
0.772
0.770
0.770
0.770
0.770
0.771
0.773
0.772
0.771
0.770
0.771
0.769
0.768
0.767
0.768
0.769
0.768
0.766
0.764
0.763
0.764
0.764
0.764
0.764

Table 7: Avg.Acc., Wins/Losses, and respective P-values of the McNemars test on the
number of times the Average Accuracy of a method is better than the Average
Accuracy of the default, Scenario 2. In bold, the winning p-value that are lower
than 0.05.

641

fiNguyen, Hilario & Kalousis

References
Bernstein, A., Provost, F., & Hill, S. (2005). Toward intelligent assistance for a data mining
process: An ontology-based approach for cost-sensitive classification. Knowledge and
Data Engineering, IEEE Transactions on, 17 (4), 503518.
Bose, R. J. C., & der Aalst, W. M. V. (2009). Abstractions in process mining: A taxonomy
of patterns. In Proceedings of the 7th International Conference on Bussiness Process
Management.
Brazdil, P., Giraud-Carrier, C., Soares, C., & Vilalta, R. (2008). Metalearning: Applications
to Data Mining (1 edition). Springer Publishing Company, Incorporated.
Bringmann, B. (2004). Matching in frequent tree discovery. In Proceedings of the Fourth
IEEE International Conference on Data Mining (ICDM04, pp. 335338.
Chapman, P., Clinton, J., Kerber, R., Khabaza, T., Reinartz, T., Shearer, C., & Wirth, R.
(2000). Crisp-dm 1.0 step-by-step data mining guide. Tech. rep., The CRISP-DM
consortium.
Fagin, R., Kumar, R., & Sivakumar, D. (2003). Comparing top k lists. In Proceedings of
the fourteenth annual ACM-SIAM symposium on Discrete algorithms, SODA 03, pp.
2836, Philadelphia, PA, USA. Society for Industrial and Applied Mathematics.
Fayyad, U., Piatetsky-Shapiro, G., & Smyth, P. (1996). From data mining to knowledge
discovery in databases. AI magazine, 17 (3), 37.
Forbes, J., & Andre, D. (2000). Practical reinforcement learning in continuous domains.
Tech. rep., Berkeley, CA, USA.
Gil, Y., Deelman, E., Ellisman, M., Fahringer, T., Fox, G., Gannon, D., Goble, C., Livny,
M., Moreau, L., & Myers, J. (2007). Examining the challenges of scientific workflows.
Computer, 40 (12), 2432.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009).
The weka data mining software: An update. SIGKDD Explor. Newsl., 11 (1), 1018.
Hilario, M. (2002). Model complexity and algorithm selection in classification. In Proceedings of the 5th International Conference on Discovery Science, DS 02, pp. 113126,
London, UK, UK. Springer-Verlag.
Hilario, M., & Kalousis, A. (2001). Fusion of meta-knowledge and meta-data for casebased model selection. In Proceedings of the 5th European Conference on Principles
of Data Mining and Knowledge Discovery, PKDD 01, pp. 180191, London, UK, UK.
Springer-Verlag.
Hilario, M., Kalousis, A., Nguyen, P., & Woznica, A. (2009). A data mining ontology for
algorithm selection and meta-learning. In Proc of the ECML/PKDD09 Workshop on
Third Generation Data Mining: Towards Service-oriented Knowledge Discovery.
Hilario, M., Nguyen, P., Do, H., Woznica, A., & Kalousis, A. (2011). Ontology-based metamining of knowledge discovery workflows. In Jankowski, N., Duch, W., & Grabczewski,
K. (Eds.), Meta-Learning in Computational Intelligence. Springer.
642

fiUsing Meta-mining to Support DM Workflow Planning and Optimization

Ho, T. K., & Basu, M. (2002). Complexity measures of supervised classification problems.
IEEE Trans. Pattern Anal. Mach. Intell., 24 (3), 289300.
Ho, T. K., & Basu, M. (2006). Data complexity in pattern recognition. Springer.
Hoffmann, J. (2001). Ff: The fast-forward planning system. AI magazine, 22 (3), 57.
Kalousis, A. (2002). Algorithm Selection via Metalearning. Ph.D. thesis, University of
Geneva.
Kalousis, A., Gama, J., & Hilario, M. (2004). On data and algorithms: Understanding
inductive performance. Machine Learning, 54 (3), 275312.
Kalousis, A., & Theoharis, T. (1999). Noemon: Design, implementation and performance
results of an intelligent assistant for classifier selection. Intell. Data Anal., 3 (5), 319
337.
Kietz, J.-U., Serban, F., Bernstein, A., & Fischer, S. (2009). Towards Cooperative Planning of Data Mining Workflows. In Proc of the ECML/PKDD09 Workshop on Third
Generation Data Mining: Towards Service-oriented Knowledge Discovery (SoKD-09).
Kietz, J.-U., Serban, F., Bernstein, A., & Fischer, S. (2012). Designing kdd-workflows via
htn-planning for intelligent discovery assistance. In 5th PLANNING TO LEARN
WORKSHOP WS28 AT ECAI 2012, p. 10.
King, R. D., Feng, C., & Sutherland, A. (1995). Statlog: Comparison of classification
algorithms on large real-world problems. Applied Artificial Intelligence, 9 (3), 289
333.
Klinkenberg, R., Mierswa, I., & Fischer, S. (2007). Free data mining software: Rapidminer
4.0 (formerly yale). http://www.rapid-i.com/.
Kopf, C., Taylor, C., & Keller, J. (2000). Meta-analysis: From data characterisation for
meta-learning to meta-regression. In Proceedings of the PKDD-00 Workshop on Data
Mining, Decision Support,Meta-Learning and ILP.
Kramer, S., Lavrac, N., & Flach, P. (2000). Relational data mining.. chap. Propositionalization Approaches to Relational Data Mining, pp. 262286. Springer-Verlag New
York, Inc., New York, NY, USA.
Leite, R., & Brazdil, P. (2010). Active testing strategy to predict the best classification algorithm via sampling and metalearning. In Proceedings of the 2010 conference on ECAI
2010: 19th European Conference on Artificial Intelligence, pp. 309314, Amsterdam,
The Netherlands, The Netherlands. IOS Press.
McDermott, D., Ghallab, M., Howe, A., Knoblock, C., Ram, A., Veloso, M., Weld, D., &
Wilkins, D. (1998). Pddl-the planning domain definition language..
Michie, D., Spiegelhalter, D. J., Taylor, C. C., & Campbell, J. (1994). Machine learning,
neural and statistical classification..
Nguyen, P., Kalousis, A., & Hilario, M. (2011). A meta-mining infrastructure to support kd
workflow optimization. Proc of the ECML/PKDD11 Workshop on Planning to Learn
and Service-Oriented Knowledge Discovery, 1.
643

fiNguyen, Hilario & Kalousis

Nguyen, P., Kalousis, A., & Hilario, M. (2012a). Experimental evaluation of the e-lico
meta-miner. In 5th PLANNING TO LEARN WORKSHOP WS28 AT ECAI 2012,
p. 18.
Nguyen, P., Wang, J., Hilario, M., & Kalousis, A. (2012b). Learning heterogeneous similarity
measures for hybrid-recommendations in meta-mining. In IEEE 12th International
Conference on Data Mining (ICDM), pp. 1026 1031.
Peng, Y., Flach, P. A., Soares, C., & Brazdil, P. (2002). Improved dataset characterisation
for meta-learning. In Discovery Science, pp. 141152. Springer.
Pfahringer, B., Bensusan, H., & Giraud-Carrier., C. (2000). Meta-learning by landmarking various learning algorithms.. Proc. 17th International Conference on Machine
Learning, 743750.
R Core Team (2013). R: A language and environment for statistical computing. http:
//www.R-project.org/.
Smart, W. D., & Kaelbling, L. P. (2000). Practical reinforcement learning in continuous
spaces. In Proceedings of the Seventeenth International Conference on Machine Learning, ICML 00, pp. 903910, San Francisco, CA, USA. Morgan Kaufmann Publishers
Inc.
Soares, C., & Brazdil, P. (2000). Zoomed ranking: Selection of classification algorithms based
on relevant performance information. In Proceedings of the 4th European Conference
on Principles of Data Mining and Knowledge Discovery, PKDD 00, pp. 126135,
London, UK. Springer-Verlag.
Srebro, N., Rennie, J. D. M., & Jaakkola, T. S. (2005). Maximum-margin matrix factorization. In Saul, L. K., Weiss, Y., & Bottou, L. (Eds.), Advances in Neural Information
Processing Systems 17, pp. 13291336. MIT Press, Cambridge, MA.
Sutton, R., & Barto, A. (1998). Reinforcement learning: An introduction. Neural Networks,
IEEE Transactions on, 9 (5), 1054.
Van der Aalst, W. M., & Giinther, C. (2007). Finding structure in unstructured processes:
The case for process mining. In Application of Concurrency to System Design, 2007.
ACSD 2007. Seventh International Conference on, pp. 312. IEEE.
Yang, Q., & Wu, X. (2006). 10 challenging problems in data mining research. International
Journal of Information Technology & Decision Making, 5 (04), 597604.
Zaki, M. J. (2005). Efficiently mining frequent trees in a forest: Algorithms and applications.
IEEE Transactions on Knowledge and Data Engineering, 17 (8), 10211035. special
issue on Mining Biological Data.
Zakova, M., Kremen, P., Zelezny, F., & Lavrac, N. (2011). Automating knowledge discovery workflow composition through ontology-based planning. Automation Science and
Engineering, IEEE Transactions on, 8 (2), 253264.

644

fiJournal of Artificial Intelligence Research 51 (2014) 207-226

Submitted 1/14; published 09/14

Sensitivity of Diffusion Dynamics to Network Uncertainty
Abhijin Adiga
Chris J. Kuhlman

abhijin@vbi.vt.edu
ckuhlman@vbi.vt.edu

Network Dynamics and Simulation Science Laboratory,
Virginia Bioinformatics Institute,
Virginia Tech, VA 24061

Henning S. Mortveit

hmortvei@vbi.vt.edu

Network Dynamics and Simulation Science Laboratory,
Virginia Bioinformatics Institute, and
Department of Mathematics,
Virginia Tech, VA 24061

Anil Kumar S. Vullikanti

akumar@vbi.vt.edu

Network Dynamics and Simulation Science Laboratory,
Virginia Bioinformatics Institute, and
Department of Computer Science,
Virginia Tech, VA 24061

Abstract
Simple diffusion processes on networks have been used to model, analyze and predict
diverse phenomena such as spread of diseases, information and memes. More often than
not, the underlying network data is noisy and sampled. This prompts the following natural
question: how sensitive are the diffusion dynamics and subsequent conclusions to uncertainty
in the network structure?
In this paper, we consider two popular diffusion models: Independent cascade (IC) model
and Linear threshold (LT) model. We study how the expected number of vertices that are
influenced/infected, for particular initial conditions, are affected by network perturbations.
Through rigorous analysis under the assumption of a reasonable perturbation model we
establish the following main results. (1) For the IC model, we characterize the sensitivity to
network perturbation in terms of the critical probability for phase transition of the network.
We find that the expected number of infections is quite stable, unless the transmission
probability is close to the critical probability. (2) We show that the standard LT model
with uniform edge weights is relatively stable under network perturbations. (3) We study
these sensitivity questions using extensive simulations on diverse real world networks and
find that our theoretical predictions for both models match the observations quite closely.
(4) Experimentally, the transient behavior, i.e., the time series of the number of infections,
in both models appears to be more sensitive to network perturbations.

1. Introduction
A number of diverse phenomena are modeled by simple diffusion processes on graphs, such
as the spread of epidemics (Newman, 2003), viral marketing (Kempe, Kleinberg, & Tardos,
2005; Goldenberg, Libai, & Muller, 2001) and memes in online social media (Romero, Meeder,
& Kleinberg, 2011; Bakshy, Hofman, Mason, & Watts, 2011). It is common to associate with
each vertex a state of 0 (denoting not infected or not influenced) or state 1 (denoting
c
2014
AI Access Foundation. All rights reserved.

fiAdiga, Kuhlman, Mortveit & Vullikanti

infected or influenced) in these models; each node in state 0 switches to state 1 based
on a probabilistic rule and nodes in state 1 remain in state 1. We focus on two such
models, referred to as the independent cascade (IC) model (which is a special case of the SIR
process), and the linear threshold (LT) model. In most applications, however, the underlying
networks are inherently noisy and incomplete, since they are often inferred by indirect
measurements, for instance: (i) networks based on Twitter data (Gonzlez-Bailn, BorgeHolthoefer, Rivero, & Moreno, 2011; Bakshy et al., 2011; Galuba, 2010) are constructed
by limited samples available through public APIs, (ii) biological networks are inferred by
experimental correlations (Hagmann, 2008; Schwab, Bruinsma, Feldman, & Levine, 2010),
which might be incomplete, and (iii) the Internet router/AS level graphs are constructed
using traceroutes (Faloutsos, Faloutsos, & Faloutsos, 1999), which are known to give a biased
and incomplete structure (Achlioptas, Clauset, Kempe, & Moore, 2005).
This raises a fundamental issue for diffusion processes on networks: How does the
uncertainty in the network affect the conclusions drawn from a study of the diffusion
dynamics over that network? For instance, how robust is an inference that there will be
no large outbreak in the network, in the face of noise/uncertainty in the network? Recent
statistical and simulation-based studies involving perturbation of the network by rewiring
pairs of edges (which preserves the degree sequence) show that changes in the network
structure significantly alter the dynamics even when aggregate structural properties such
as the degree distribution and assortativity are preserved (Eubank, 2010; Chen, 2010).
Surprisingly, there is limited mathematically rigorous work to explain the empirical findings
in a systematic manner, despite a large body of research on diffusion models.
Our work is motivated by these considerations of sensitivity of the dynamics to noise and
the adequacy of sampling of a network G = (V, E). Since there is very limited understanding
of how noise should be modeled, we consider two simple random edge perturbation models
for noise: uniform and degree-assortative. In uniform perturbation, each pair u, v of vertices
is selected for edge addition or deletion (or both) with probability n , where  > 0 is a
parameter,
and n is the number of vertices; thus, on average, the perturbed graph differs in

 n
n
n 2  2 edges. This model has been used quite extensively both in social network analysis
and computer science for understanding the sensitivity to graph properties (Costenbader
& Valente, 2003; Borgatti, Carley, & Krackhardt, 2006; Flaxman & Frieze, 2004; Flaxman,
2007). We study how the expected number of infections, given some initial conditions,
is affected by the magnitude of the perturbation parameter, . In the degree-assortative
perturbation, the probability of an edge modification is proportional to the product of the
degrees of the end points in G.

1.1 Our Contributions
All the results we obtain are under the assumption of the uniform edge addition model, i.e.,
edges absent in the network are added with probability n to obtain the perturbed network.
Later, in Section 5, we compare the addition model with the addition/deletion model and
also discuss our results on degree-assortative perturbation. We describe the independent
cascade and linear threshold models in Section 2.2.
208

fiSensitivity of Diffusion Dynamics to Network Uncertainty

1.1.1 Independent Cascade Model
We consider networks G which exhibit a phase transition in the infection sizes, with a critical
transition probability pc (see Section 2 for definitions). In Theorem 1, we characterize the
expected number of infections in the perturbed graph in terms of transmission probability p
and pc for a single random seed node. When p < pc , we show that there exists a threshold t
such that for any positive constant c < 1: (i) if  < (1  c)t , and in addition, if pc and the
average degree davg satisfy a technical condition, then, the expected number of infections in
the perturbed graph remains close to that in G and, (ii) if  > (1 + c)t , there is a phase
transition, and the expected number of infections after perturbation is much larger than that
in G. The main implication is that the dynamics are quite robust to perturbations, unless
the transmission probability is close to pc , and  is over some critical value. We find this to
be consistent with extensive simulations on a large number of real networksthe sensitivity
to perturbations is maximized at a point which approximately matches the experimentally
determined threshold t in many networks. We also examine the transient behavior (i.e., the
time series of the number of infections) studying in particular how the time and magnitude
of the peak number of new infections are affected by uncertainty. We find these measures to
be more sensitive than the expected total number of infections.
1.1.2 Linear Threshold Model
In Theorem 2, we show formally that for any network G with maximum degree  =
O(n/ log n), the expected number of infections after perturbation, starting at s random
initial infections, is bounded by O(s( +  + log n) log n). This implies that the dynamics
are quite stable for low s and . Our result is based on the analysis of the random graph
model in which each node selects a random in-edge. This is shown to correspond to the
LT model (Kempe, Kleinberg, & Tardos, 2003). We first show that the diameter is bounded
by O(0 log n), where 0 is the maximum degree of the perturbed graph, and then prove
that the expected number of infections, starting at a random source, is bounded by the
diameter. Our theoretical bounds corroborate well with our experimental observations on a
large set of real networks, which show a gradual variation with . We find that the expected
number of infections grows more sharply with , as the number of sources is increased.
1.1.3 Discussion and Implications
From the point of view of dynamical system theory, our work may be regarded as a study of
stability of dynamics over a network with respect to the edge structure. The existence of the
critical value for the parameter  in the IC model can be thought of as a bifurcation point.
Admittedly, our results only hold for the specific random edge perturbation model of noise;
uncertainty in networks is a much more complex process, and might involve dependencies
arising out of the network evolution. Although we focus on specific dynamical properties
and the random edge perturbation model, our results give the first rigorous theoretical
and empirical analysis of the noise susceptibility of these diffusion models. Further, our
analytical and empirical techniques, based on the random graph characterization, are likely
to help in the analysis of other more complex noise models, which take dependencies into
account.
209

fiAdiga, Kuhlman, Mortveit & Vullikanti

1.2 Related Work
Noise and issues of sampling are well recognized as fundamental challenges in complex
networks, and there has been some work on characterizing it and the sensitivity to different
parameters, especially in network properties. In some works (Costenbader & Valente, 2003;
Borgatti et al., 2006), certain centrality measures are shown to be robust to random edge
and node perturbations, and in another (Achlioptas et al., 2005), it is shown that there is
an inherent bias in traceroute-based inference of the Internet router network, which might
give incorrect degree distributions. Flaxman and Frieze (Flaxman & Frieze, 2004; Flaxman,
2007) formally characterize conditions under which the graph expansion and diameter are
highly sensitive to random edge additions; these are among the few analytical results of this
type. Some of the approaches to address noise include: (i) the prediction of missing links
using clustering properties (Clauset, Moore, & Newman, 2008), and (ii) property testing
algorithms (Ron, 2010) and smoothed analysis (Spielman, 2009) for efficient computation
of graph properties.
To our knowledge, most work on the sensitivity of graph dynamical systems to noise
in a network is empirical. However, for regular networks such as rings, topics such as
synchronization and bifurcations are studied (Kaneko, 1985; Wu, 2005). As discussed
earlier, the effects of changes in a network by edge rewirings on epidemic properties are
investigated (Eubank, 2010; Chen, 2010). The effect of stochastic changes in the network on
influence maximization problems is studied (Lahiri, Maiya, Caceres, Habiba, & Berger-Wolf,
2008). Using simulations, they find that in the LT model, the spread size is quite robust;
our techniques help explain some of these observations.
1.2.1 Organization
In Section 2, we introduce notation and describe the noise models and diffusion models in
detail. In Sections 3 and 4, we analyze the sensitivity of IC and LT models, respectively.
Experimental results are presented in Section 5, and we conclude in Section 6.

2. Preliminaries
We consider only undirected, simple networks. For a network G = (V, E), let  denote its
maximum degree and davg , its average degree. For any vertex v, deg(v, G) and N (v) denote
its degree and the set of neighbors respectively. Let  correspond to the largest eigenvalue of
the adjacency matrix of G. We say that an event A(n) occurs asymptotically almost surely
(a.a.s.) if P (A(n))  1 as n  .
2.1 Noise Models
Since there is no consensus on the best way to model uncertainty and noise, we consider
two simple models of random edge modifications: (i) uniform and (ii) degree-assortative
perturbations. Uniform perturbation has been studied quite extensively in social network
analysis (Costenbader & Valente, 2003; Borgatti et al., 2006); some problems have also
been studied analytically in this model (Flaxman & Frieze, 2004; Flaxman, 2007). Let
G = (V, E) be the unperturbed graph; all graphs in this work are undirected and simple.
Let Ru () = (V, E()) be a random graph on V in which each pair u, v  V is connected
210

fiSensitivity of Diffusion Dynamics to Network Uncertainty

with probability n . In our analysis, we consider perturbations involving just addition of
edges: This is denoted by G + Ru (), and consists of all edges (u, v)  E  E(Ru ()). For
our experimental studies, we also considered addition/deletion of edges. In this case, the
perturbation graph G0 = G  Ru () is a graph constructed in the following manner: each
pair u, v  V is connected in G0 if (u, v)  Ru ()  E or (u, v)  E  Ru (). In other words,
each pair u, v is selected for addition/deletion with probability n . In the degree-assortative
perturbation
random graph Rd () for which u, v  V are adjacent with

 model, we consider
deg(u,G) deg(v,G) 
probability
n , i.e., the edge probability is proportional to the product of the
d2avg
degrees of the end points in G. In both models, the expected number of edge modifications
is approximately n
2 .
2.2 Network Diffusion Models
Let G = (V, E) denote an undirected network. In all the models we study, each vertex v  V
can be in state xv  {0, 1}, with state 0 denoting inactive/uninfected/uninfluenced and
state 1 denoting active/infected/influenced, depending on the application. We restrict
ourselves to monotone or progressive processes, i.e., an infected node stays infected. Each
node is associated with an activation function whose inputs include the states of its neighbors.
This function computes the next state of the node. The diffusion process starts with a few
vertices set as active/infected; we refer to this set as the initial set or the seed set. For
an initial set of active nodes S, let (S) denote the expected number of active nodes at
termination. These models always reach fixed points. We consider the following models:
(1) Independent Cascade (IC) Model (Kempe et al., 2003): This model is a special case of
the SIR model for epidemics. An infected node v infects each neighbor w with probability
p (referred to as the transmission probability). Equivalently, each edge (v, w) can be
live with probability p, independently of all other edges. All those nodes which are
connected to the initial set through a live path are considered infected. In the graph,
let (v, x) be an edge. Suppose v gets infected at time t, and x is in state 0. Then v
tries to infect x with probability p at time t + 1. Irrespective of whether x gets infected
by v, v remains in state 1 for all subsequent times, but never again tries to infect x.
(2) Linear Threshold (LT) Model (Kempe et al., 2005): Each node v has a threshold
v  [0, 1], chosen uniformly at random. Node v is influenced by its neighbor w
P
according to weight bv,w such that wN (v) bv,w  1. Node v becomes infected if
P
wA(v) bv,w  v , where A(v)  N (v) is the set of neighbors of v which is currently
infected. In our analysis and experiments, we assume that bv,w = 1/ deg(v, G) for all
w  N (v), where deg(v, G) is the degree of v in G. This means that v is influenced
equally by all its neighbors. This model was considered in (Kempe et al., 2003). In
the perturbed graph G0 = G + Ru (), bv,w = 1/ deg(v, G0 ), where deg(v, G0 ) is the new
degree of v.

3. Analyzing the Sensitivity of the IC Model
In this section, we rigorously analyze the sensitivity of the IC model to edge perturbations.
As mentioned earlier, we restrict our attention to uniform edge addition model, i.e., the
211

fiAdiga, Kuhlman, Mortveit & Vullikanti

perturbed graph is obtained by adding an edge between every pair of vertices with probability
/n.
Before stating the main result, we discuss some aspects of the IC model and develop
notation which will be used in the analysis. For a transmission probability p, let G(p)
denote a random subgraph of G obtained by retaining edges of G with probability p. The
relationship between infection spread in the IC model and the structure of G(p) is well-known;
the question of whether or not a large spread occurs in G is equivalent to asking if there
exists a giant component in G(p). Another interesting aspect is that the IC model exhibits
a threshold phenomenon. For many graph families there exists a critical transmission
probability pc at which an abrupt phase transition occurs from a small spread at p < pc to
a large one at p > pc with high probability. A formal definition of pc follows (see (Bollobs,
1985) for more details).
Definition 3.1. For a graph G on n nodes, pc is the critical transmission probability if
starting with a single random initial infection, for any transmission probability p  pc
the total number of infections is a.a.s. o(n) or equivalently, all components in G(p) are of
size o(n), while for p  pc , the number of infections is a.a.s. (n) or there exists a giant
component in G(p).
Recall from Section 2 that the notion of asymptotically almost surely is formally defined for a
sequence of graphs. However, we do not state this explicitly, in order to reduce the notational
overload. Now we state our main result of this section where we analyze the sensitivity of
the IC model for a graph operating at probability p < pc and satisfying pdavg  1 where,
davg is the average degree of G. We conclude with a discussion on the implications of this
theorem.
Theorem 1. Consider a graph G on n nodes with average degree davg and critical transmis
sion probability pc . Let the transmission probability p satisfy pdavg = o(1) and p =  1/n1
for some constant . Let G + Ru () be the perturbed graph obtained by adding edges uniformly
at random with factor . Then, for a single seed node chosen uniformly at random, the
following hold:
(a) The number of infections in G is o(n) a.a.s. and therefore, p < pc .
(b) If pdavg = o 1/ log2 n , then, there exists a threshold perturbation factor t = p1 such that
for any positive constant c < 1, if   (1  c)t , the number of infections in G + Ru ()
for a transmission probability of p is a.a.s. o(n) while if   (1 + c)t , the number of
infections is (n).


(c) For any positive constant c, if  
(n).

1+c
p ,

the number of infections in G + Ru () is a.a.s.

Proof. Let G0 = G + Ru () and let G0 (p) be the random subgraph of G0 obtained by choosing
edges with probability p. Since, for any edge e 
/ E(G), Pr(e  G0 (p)) = p  Pr(e  Ru ()) =
p
0
n , it follows that G (p) can be obtained by adding edges between every pair of nodes in
G(p) with probability p
n . Now, we will prove Statement (a).
p



Claim 1. The number of components in G(p) with more than one node is O n pdavg a.a.s.
and therefore, G(p) has no giant component.
212

fiSensitivity of Diffusion Dynamics to Network Uncertainty

Proof. We use Chebychevs inequality.

 For any
 x> davg , the number of nodes with degree
davg
d
greater than x in G is at most n x+1 < n avg
. Let niso denote the number of isolated
x
nodes in G(p). Then,
E[niso ] =

X

X

Pr(v is isolated) 

vV (G)

Pr(v is isolated)

vV (G),deg(v,G)x

davg
 (1  p)x n 1 
x




q

davg
> (1  px)n 1 
.
x




2

p

p



Choosing x to be davg /p, E[niso ]  1  pdavg n  1  2 pdavg n. Since by assumption, davg = o(1/p), E[niso ] = (1  o(1))n. For any node v  V (G), let Iv = 1 if v has no
neighbors in G(p) and 0 otherwise. Let Var[] and Cov[] denote the variance and covariance,
respectively. Using the bounds Var[Iv ]  E[Iv ] and Cov[Ia Ib ] = P (Ia  Ib )  1,
Var[niso ] =

X

X

Var[Iv ] + 2

vV (G)

Cov[Ia Ib ]

(a,b)E(G)

X

 E[niso ] + 2

Cov[Ia Ib ]  E[niso ] + ndavg = O(ndavg ) .

(a,b)E(G)

Since we have assumed that p =  1/n1 , it follows that Var[niso ] = O n2 pdavg .
Applying Chebychevs inequality,


q









P |niso  E[niso ]| > n pdavg  P |niso  E[niso ]| >

q



n Var[niso ] 

p

Therefore, a.a.s., n  niso  3n davg p.

1
.
n


Let {Ci | i  N } be the set of connected components in G(p), where N is the number of
components and let ni denote the size of Ci . The probability that components Ci and Cj
n n p
are connected by at least one edge of Ru () in G0 (p) is at most i nj . Let Siso denote the
set of isolated nodes in G(p) and S iso the set of remaining nodes.
Let H be the graph obtained by adding a special vertex v to G0 (p) and making it adjacent
to all nodes in S iso . Clearly, S iso belongs to a component in H and any component in G0 (p)
is contained in a component of H. This implies that G0 (p) has a giant component only if H
has one. Now, we will prove the first part of Statement (b).
Claim 2. H has components of size o(n) if pdavg = o 1/ log2 n and  


(1c)
p .

Proof. Let H[Siso ] and H[S iso ] be graphs induced by Siso and S iso , respectively, in H. Note
that since Siso is a set of isolated nodes in G(p), H[Siso ] is an Erds-Rnyi graph on |Siso |
p
nodes with edge probability |Sp
= n(1o(1))
. Since p < 1  c, it follows that H[Siso ] has
iso |
components of size O(log n) (see, e.g., Bollobs, 1985). Now we will show that the component
containing S iso is of size o(n) a.a.s., thus completing the proof.
Let N (S iso ) denote the size of the neighborhood of S iso in H. The probability that a
node in Siso is a neighbor of S iso is at most
h

|S iso |p
.
n

i

E N (S iso )  |Siso | 
213

Therefore,

|S iso |p
 |S iso |p.
n

fiAdiga, Kuhlman, Mortveit & Vullikanti

Applying a version of Chernoff bound (Chung & Lu, 2002), we have the following:



h

i

2





i
 .
P N (S iso )  E N (S iso ) >   exp  h
2 E N (S iso ) + /3

We have two regimes to consider: (i) |S iso |p = (1) and (ii) |S iso |p = O(1). If |S iso |p =
(1), setting  = |S iso |p, it follows that N (S iso )  2|S iso |p a.a.s. Since H[Siso ] has
components of size O(log n), the size of the component containing S iso is




 q



O |S iso | + N (S iso ) log n = O |S iso | + |S iso |p log n = O n pdavg (1 + p log n) .
The last expression
follows from p
Claim 1. Since   (1  c)t and pdavg = o 1/ log2 n , it
p
follows that n pdavg p log n  n pdavg log n(1  c) = o(n). Now we consider regime (ii):
|S iso |p = O(1). By setting  = log n, the component size is O log2 n = o(n). Hence, we
have proved the claim.



The proofs of the second part of Statement (b) and Statement (c) are straightforward.
Let Rp denote the random subgraph of the perturbation network Ru () obtained by sampling
its edges with probability p. It is easy to see that Rp is an Erds-Rnyi graph with edge
1+c
probability p
n = n which implies that it has a giant component (Bollobs, 1985). This in
turn implies that G0 (p) has a giant component. Hence, we have proved the theorem.
Theorem 1 indicates that for a large class of networks, the closer we operate to pc ,
the more sensitive the dynamics is to structural perturbation. This is indeed true if the
conditions of Statement (b) are met: for any p1 < p2 < pc , t (p1 ) > t (p2 ). It implies that
greater perturbation is required in the case of p1 (compared to p2 ) to observe a significant
difference in the expected infection size after perturbation. We have observed the same in
our experiments; see the last three columns of Table 1. In the AstroPh graph, for example,
at p = 0.03, phase transition occurs for t = 8 while for p = 0.02, t has to be greater than
20 for a transition to occur.

4. Analyzing the Sensitivity of the LT Model
We now analyze the impact of edge perturbations on the LT model on a graph G = (V, E).
As in the previous section, we restrict our attention to the uniform edge addition model.
Recall that in the specific version of the LT model we consider here, we set bv,w = 1/ deg(v)
for each node v  V and w  N (v).
The fixed points and the number of infected nodes can be studied through an elegant
random graph model (Kempe et al., 2003) which we describe here. Construct a random
directed graph HLT = (V, E 0 ) in the following manner: for each node v  V , a neighbor w is
chosen with probability bv,w and a directed edge is added from w to v. Figure 1 illustrates a
graph G and an instance of HLT . Note that even though G is undirected, HLT is a directed
graph. For a set S  V , let (S, HLT ) denote the number of nodes reachable from S in HLT
(including those in S). Then, (S), the expected number of infections with a starting set S,
P
satisfies (S) = HLT Pr[HLT ](S, HLT ) (Kempe et al., 2003). We use this characterization
to analyze the impact of edge perturbations.
214

fiSensitivity of Diffusion Dynamics to Network Uncertainty

1

1

2

3

2

3

4

5

4

5

6

7

6

7

Figure 1: A graph (on the left) and an instance of the random graph HLT (on the right)
corresponding to the LT model. For the component T induced by {1, 2, 3, 4, 5}, 1 is chosen
as the root and as a result, T0 = {1}, T1 = {3}, T2 = {2, 5} and T3 = {4}.

The random graph HLT constructed by the above process has the following structure: in
each connected component T of HLT , every vertex has one incoming edge and therefore,
there exists exactly one directed cycle. If we choose a vertex in the cycle as the root r and
remove its incoming edge, then, T corresponds to a tree rooted at r with all edges oriented
away from r. T can be partitioned into sets T0 , . . . , Tk such that for each i > 0, a vertex
v  Ti has an incoming edge from some vertex u  Ti1 . The set T0 is a singleton consisting
of the root vertex r. The incoming edge for r is from some neighbor in ki=1 Ti . This is
illustrated in Figure 1. First, we will show the following:
Lemma 4.1. In the LT model, let  = minvV,wN (v) bv,w . Each component in the random
subgraph HLT has depth O



1




log n with probability at least 1 

1
.
n3

Proof. Consider a component T in HLT , which is partitioned into sets T0 , . . . , Tk , as mentioned above. For any i = 1, . . . , k  1, a vertex v  Ti would become a root if it chooses
an incoming edge from one of its descendants. The probability of this event is at least
minwN (v) bv,w  . Therefore, the probability that none of the vertices in Ti becomes a
root is at most 1  , which in turn implies that the probability that none of the vertices in
Ti , for i = 1, . . . , k  1 becomes a root is at most (1  )k1 . Hence, the probability that
P
T has depth more than k = 4  1 log n + 1 is at most nk4 1 log n+1 (1  )k1  n14 . Since

there are at most
n such
components in HLT , the probability that any of these has depth


more than O 1 log n is at most n13 .
Consider a vertex v contained in a component T . Let n(v, T ) denote the number of
vertices reachable from v in T . Then, the number of infections resulting from v is the expected
value of n(v, T ), averaged over all random subgraphs HLT and components containing v. Let
P
A(T ) = |T1 | vT n(v, T ). Conditioned on a random subgraph HLT , the average number of
infections starting at a random source is
starting at a random source is

P

HLT

P

A(T ) |Tn | . The average number of infections

T HLT

Pr[HLT ]

P

T HLT

A(T ) |Tn | .

Lemma 4.2. For each component T in a random subgraph HLT , A(T )  2d, where d is the
depth of T .
215

fiAdiga, Kuhlman, Mortveit & Vullikanti

Proof. Define T to be the tree obtained by removing the incoming edge for the root in T .
As described above, T is an out-tree. For each v  T , we define n(v, T ) as the number of
vertices reachable from v in T  this corresponds to the size of the subtree rooted at v in
P
T . We define A(T ) = |T1 | vT n(v, T ), and prove that A(T )  d by induction on the depth
of the out-tree. The base case is a leaf node u, for which A(u) = 1.
Let r be the root of T . Suppose it has children v1 , . . . , va . Let Ti be the subtree rooted at
P
vi , and let ni be the number of vertices in Ti . By induction, A(Ti ) = n1i vTi n(v, Ti )  d1.
A(T ) =

1 X
n(v, T )
|T |
vT

=

a
X
1
1 X
n(r, T ) +
n(v, Ti )
|T |
i=1 |T |
vTi

= 1+

a
X
ni
i=1

|T |

A(Ti )  1 +

a
X
ni
i=1

|T |

(d  1)

|T |  1
 1+
(d  1)  d
|T |
The third equality follows because n(r, T ) = |T |, and by definition, A(Ti ) = n1i vTi n(v, Ti ).
The first inequality follows by the induction hypothesis, since the depth of each Ti  d  1.
P
The second inequality follows because ai=1 ni = |T |  1.
Next, we consider A(T ). We recall that T is a tree with a cycle of length at most d. Let
the cycle consist of vertices u0 = r, u1 , . . . , ub , with b  d  1. For each ui , n(ui , T ) = |T |,
since there is a path from ui to r. For every other vertex u 6= ui in T , n(u, T ) = n(u, T ).
|
This implies that A(T )  d|T
|T | + A(T )  2d.
P

Finally, we bound the number of infections in the perturbed graph below.
Theorem 2. Let G(V, E) be a graph with maximum degree  and G + Ru () be the perturbed
graph obtained by adding edges uniformly at random with factor . For the LT model where
bv,w = 1/ deg(v) for each node v  V and w  N (v), the expected number of infected
vertices starting with an initial random seed set of size s in the perturbed graph G + Ru () is
O(s( +  + log n) log n).
Proof. By a direct application of the Chernoff bound, it can be shown that with probability
at least 1  n13 , the maximum degree of G0 = G + Ru () is at most  +  + c  log n for a
constant c with the remaining probability of n13 , the maximum degree is O(n). We consider
the random graph process to generate a subgraph HLT of G0 . Since bv,w = 1/ deg(v) for
each node v  V and w  N (v), for this model, the value of  of Lemma 4.1 is 1/(G0 )
and therefore, each component in HLT has depth at most O(( +  + log n) log n), with
probability at least 1  n13 . Conditioned on HLT satisfying this bound on the depth,
A(T ) = O(( +  + log n) log n) for all T  HLT . If HLT does not satisfy the depth bound,
A(T ) = O(n) for all T  HLT . Therefore, the expected number of infections for a single
random seed is O(( +  + log n) log n) + O( nn3 ) = O(( +  + log n) log n). The result
extends to s > 1 by submodularity of the expected number of infections.
216

fiSensitivity of Diffusion Dynamics to Network Uncertainty

Theorem 2 implies that the LT model with uniform edge weights is in general very robust
to perturbation. Note that the final part of the proof of Theorem 2 is essentially based on
the maximum degree of G0 . Replacing G0 with G and retracing the steps, one can show that
the expected spread in the unperturbed graph G is O(s log n), where  is its maximum
degree. Hence, we see that for a reasonably high value of  (say (log n)), the difference
between the total number of infections in G and G0 is at most a linear function of  and
therefore there is no abrupt change in the outcome. Moreover, the bound suggests that
the higher the , the lower the effect of perturbation. However, making this formal would
require obtaining good lower bounds on the expected number of infections, which we leave
as an interesting research question.

5. Experimental Results
We study the sensitivity to edge perturbations on twenty diverse real-world networks (Leskovec,
2011) with varying degrees of perturbation and other factors for both IC and LT models.
They are listed in Table 1 along with some of their properties, the first four of which
are number of nodes, average degree, maximum eigenvalue, and maximum degree. Other
properties will be discussed subsequently. We present representative results for selected
networks, with other networks exhibiting the same behavior unless stated otherwise. We
focus primarily on the sensitivity of expected number of infections and transient behavior
to edge perturbation. Of course, all of our observations are restricted to the conditions for
which the experiments were performed.
5.1 Experimental Setup and Methodology
Each network G in Table 1 was perturbed with values of  ranging from 0 to 100, where
 = 0 corresponds to the unperturbed network. For each , we generated ten graph instances
G0 = G + R or G  R. Here, R may be Ru or Rd , depending on whether the perturbation
is a uniform edge approach or a degree-assortative approach. For each graph instance, we
performed a simulation run, which consists of 100 separate diffusion instances. A diffusion
instance is the process of setting all node states initially to zero, assigning relevant properties
to graph entities (e.g., transmission probability on edges for the IC model and edge weights
and node thresholds for the LT model), selecting a seed node set S whose element states
are changed to 1 (i.e., are initially infected), and marching time forward in discrete units,
continuing the simulation until a fixed point is reached. We record each nodes time of
infection in each diffusion instance. Thus, for example, the experimental data displayed as
average and variance quantities are based on 1000 values.
5.2 Edge Additions vs. Deletions
We find that perturbations involving both edge additions and deletions do not alter the
results by much, compared to perturbations involving just edge additions. This is due to
the sparsity of the graphs considered. For example, for uniform perturbations, the expected
number of edges deleted is |E|/n = davg /2 while the expected number of edges modified is
n/2. Therefore, the remainder of the paper focuses on perturbation by addition of edges
only; i.e., only graphs of the form G0 = G + R.
217

fiAdiga, Kuhlman, Mortveit & Vullikanti

Network

n = |V |

davg





 pc

(p; t ) pairs by experiments

Synthetic graphs
Random-Regular-20

10000

20.0

20.0

20

0.05

0.04;9

0.03;>10

0.02;>20

0.2
0.2
0.2

0.15;2
0.15;<2
0.15;<1

0.1;5
0.1;5
0.1;5

0.05;>10
0.05;10
0.05;10

0.04
0.12
0.2
0.1
0.2

0.03;8
0.1;2
0.15;<2
0.07;<2
0.15;<1

0.02;>20
0.08;4
0.1;5
0.04;8
0.1;5

0.01;>40
0.06;8
0.05;10
0.01;>20
0.05;10

0.04
0.05

0.03;6
0.04;<2

0.02;>20
0.03;8

0.01;>40
0.02;>40

0.1
0.3

0.07;4
0.2;<2

0.04;10
0.1;6

0.01;>20
0.05;10

0.15
0.1
0.1
0.2
0.04

0.12;<1
0.07;3
0.07;3
0.15;<2
0.03;3

0.1;2
0.04;9
0.04;9
0.1;4
0.02;10

0.08;4
0.01;>20
0.01;>20
0.05;10
0.01;>20

0.1;2
0.15;1

0.07;7
0.1;6

0.04;>10
0.05;>10

Autonomous Systems
AS-2000-01-02
Oregon1-01-03-31
Oregon2-01-03-31

6474
10670
10900

3.88
4.12
5.72

46.31
58.72
70.74

AstroPh
CondMat
Grqc
HepPh
HepTh

17903
21363
4158
11204
8638

22.0
8.54
6.45
20.99
5.74

94.42
37.88
45.61
244.93
31.03

HepPh
HepTh

34546
27770

24.46
25.37

76.58
111.25

1458
2312
2343

Co-authorship
504
279
81
491
65

Citation
846
2468

Communication
Email-Enron
Email-EuAll

33696
265214

10.02
2.74

118.41
102.53

1383
7636

Social
Epinion
Slashdot0811
Slashdot0902
Twitter
Wiki-Vote

75877
77360
82168
22405
7066

10.69
12.12
12.27
5.34
28.51

184.17
131.34
134.62
54.08
138.15

3044
2539
2552
888
1065

Internet peer-to-peer
Gnutella04
Gnutella24

10876
26518

7.35
4.93

15.7
19.06

103
355

0.125
0.2

Table 1: Some relevant properties of the networks used in our simulations and results from
experiments.
5.3 The Independent Cascade Model
We have experimental results for both uniform and degree-assortative perturbation, about
which we make observations relating to the theoretical results and about the behavior of the
networks in general.
5.3.1 Uniform Perturbation
Effect of p on final infection size. Figure 2 consists of plots of variation in the average
and variance of the fraction of infected nodes with (i) the transmission probability p for
various levels of perturbation and (ii) the perturbation level  for various p values for three
networks. The plots for the remaining networks are in the full version (Adiga, Kuhlman,
Mortveit, & Vullikanti, 2014). We note that when p > 1 (and p  pc ), the average infection
size is generally high, agreeing with Statement (c) of Theorem 1. We observe that in all the
plots the final fraction of infections is at least 0.5 when p > 1.

218

fiSensitivity of Diffusion Dynamics to Network Uncertainty

Average Final Size
Variance Final Size

Average Final Size
Variance Final Size

Average Final Size

1.0 Random-Regular-20
0.8
0.6
 =0
0.4
 =0.5
 =1
0.2
 =5
 =10
0.0
0.00 0.05 0.10 0.15 0.20
Probability, p
Random-Regular-20
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probability, p
Random-Regular-20
1.0
0.8
0.6
p =0.02
0.4
p =0.03
p =0.04
0.2
p =0.05
p =0.06
0.00 20 40 60 80
100
Perturbation, 

Average Final Size

Average Final Size
Variance Final Size

Wiki-Vote
1.0
0.8
0.6
 =0
0.4
 =0.5
 =1
0.2
 =5
 =10
0.0
0.00 0.05 0.10 0.15 0.20
Probability, p
Wiki-Vote
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probabilty, p
Wiki-Vote
1.0
0.8
0.6
p =0.01
0.4
p =0.02
p =0.03
0.2
p =0.04
p =0.05
0.00 20 40 60 80
100
Perturbation, 

Average Final Size

AS-2000-01-02
1.0
0.8
0.6
 =0
0.4
 =0.5
 =1
0.2
 =5
0.00.0 0.2 0.4 0.6 =100.8
Probability, p
AS-2000-01-02
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probability, p
AS-2000-01-02
1.0
0.8
0.6
p =0.05
0.4
p =0.10
p =0.15
0.2
p =0.20
p =0.25
0.00 20 40 60 80
100
Perturbation, 

Figure 2: Uniform perturbation (IC model): Average and variance of fraction of infections
for a single random seed (i) vs. transmission probability p for various  values and (ii) vs. 
for various values of p. The plots in the first and third rows are average final fraction of
infected nodes and those in the second row are average variance in final fraction of infected
nodes. The remaining plots are in the full version (Adiga et al., 2014).

The sensitivity of final infection size with  is modulated by davg . We first consider
the relationship between pc and davg of the unperturbed networks. Since for finite networks,
there is no clear definition of pc , we chose it to be that value of p for which the average total
number of infections is 10% of the number of nodes in the network. Table 1 contains pc for
each network. The dependence of pc on davg is shown in Figure 3 where each data point
corresponds to one graph and is colored according to the type of graph. Clearly, the plot
is indicating an inverse relationship between the two values. This implies that the higher
the davg , the lower the p for which the spread is small. Note that Theorem 1 shows that the
minimum  for which there is a large spread is inversely proportional to p. This strongly
suggests that the greater the edge density, the greater the perturbation required to achieve
significant change in dynamics. This is supported by our experiments, too. For example, see
plots for AS-2000-01-02 and Wiki-Vote in the first row of Figure 2. Consider p = 0.2 and
note the change in spread in going from  = 0 to 10. For Wiki-Vote, it goes from 0.38 to 0.89,
219

fiAdiga, Kuhlman, Mortveit & Vullikanti

for a ratio of 2.3. For AS-2000-01-02, it changes from 0.08 to 0.82, for a ratio of 10.3. Thus,
AS-2000-01-02, with a factor of 7 smaller davg than Wiki-Vote, has much greater sensitivity
of spread for changes in . Note the numbers of nodes in the two graphs are comparable. We
see this same behavior in other (high davg , low davg ) network pairs: (AstroPh, CondMat),
(HepPh, HepTh), and (Email-Enron, Email-EuAll).

Critical Probability

0.5
0.4
0.3
0.2
0.1
0.00

auton.
co-auth.
citation
comm.
social
internet

10 20 30
Average Degree

40

Figure 3: Dependence of pc on davg . Data are for the graphs in Table 1, and colors correspond
to graph types in the table.

Variance of final infection size. In Figure 2 (and more plots in the full version Adiga
et al., 2014), the middle row of plots contains variance in final infection size as a function
of transmission probability. There are several observations. First, for all graphs whose
dynamics exhibit a phase transition to larger infection sizes with increasing  for fixed p
(and for increasing p for fixed ), the variance of the infection size qualitatively increases
with p, peaks in the region of phase transition and again decreases. The peaks in variance
correspond to the regimes where the change in final infected fractions are changing the most
with p, as expected (cf., the first row of figures). Second, the greater the perturbation, the
lesser the range of p values for which the variance is high. This is because the greater the
value of , the faster the contagion spreads, thus driving down variance. The last observation
is non-intuitive. That is, the peak of the variance does not seem to vary for combinations
of  and p where 0    10 and 0  p  0.6. For these ranges, only the value of p where
the peak occurs decreases with increasing . In fact, the peak of the variance is around 0.1
for all graphs for these conditions.
Effect of regular network structure on numbers of infected nodes. There are
several reasons to investigate random networks with uniform degree. First, in an investigation
of voter model dynamics (Kuhlman, Kumar, & Ravi, 2013), it was shown that uniform degree
networks generated results very near to those of realistic graphs whose degree distribution
was exponential decay, but far from those for graphs with scale free degree distributions. So
the question arises here as to how close the behavior of uniform degree networks is to those
of realistic networks. Second, since the perturbing subgraph R in this study is a random
graph, the perturbed graph G0 in some sense maintains its random structure compared to G,
when G is the random 20-regular graph (a random graph where each node has degree 20).
Figure 2 shows that this latter consideration dominates. That is, the upper right plot shows
that the curves are basically shifted left as  increases. So, too, in the plot at the right of
220

fiSensitivity of Diffusion Dynamics to Network Uncertainty

the middle row, the variance curves shift slightly left as  increases, but this effect is much
smaller than in Wiki-Vote or AS-2000-01-02.
Effect of  on the average time-to-peak number of new infections. The average
time histories for 1000 diffusion instances that comprise each curve for one graph of each
type are provided in the top row of Figure 4. The transmission probabilities used for each
plot are such that p > pc . The average time at which the maximum number of new infections
occurs can decrease, stay the same, or increase as a function of , depending on the graph,
moving left to right. Over all graphs of Table 1, there seems to be a fairly even split in
that nine of the graphs show an increase in average time-to-peak with increasing  and eight
show a decrease in average time-to-peak. The remainder show no change in time-to-peak.

20

10 15
Time
Twitter

20

Average Max New Inf

1.0
 =0
 =0.5
0.8
 =1
 =5
0.6
 =10
0.4
0.2
0.00.0 0.2 0.4 0.6 0.8 1.0
Probability, p
Twitter
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probability, p

Variance Max New Inf

Variance Max New Inf

Average Max New Inf

1.0
 =0
 =0.5
0.8
 =1
 =5
0.6
 =10
0.4
0.2
0.00.0 0.2 0.4 0.6 0.8 1.0
Probability, p
CondMat
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probability, p

5

 =0
 =0.5
 =1
 =5
 =10

0.5 Wiki-Vote (p =0.12)=0
 =0.5
0.4
 =1
 =5
0.3
 =10
0.2
0.1
0.00
5 10 15 20
Time
Wiki-Vote
1.0
 =0
 =0.5
0.8
 =1
 =5
0.6
 =10
0.4
0.2
0.00.0 0.2 0.4 0.6 0.8 1.0
Probability, p
Wiki-Vote
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probability, p

Average Max New Inf

10 15
Time
CondMat

Twitter (p =0.5)

Variance Max New Inf

5

0.5
0.4
0.3
0.2
0.1
0.00

Average New Inf

 =0
 =0.5
 =1
 =5
 =10

Average New Inf

CondMat (p =0.3)

Average New Inf

0.5
0.4
0.3
0.2
0.1
0.00

Figure 4: Sensitivity of temporal characteristics to uniform perturbation (IC model): Plots
of (i) average number of new infections for each time step for selected p values, (ii) average of
maximum number of new infections at any time vs. p. and (iii) variance of maximum number
of new infections at any time vs. p. The remaining plots are in the full version (Adiga et al.,
2014).

221

fiAdiga, Kuhlman, Mortveit & Vullikanti

Effect of  on the average peak number of new infections. The second row of plots
in Figure 4 depicts the average maximum number of new infections at any one time as a
function of transmission probability, for different . As  increases, the maximum number of
new infections increase.
Variance in average maximum number of new infections for any discrete time.
The last row of plots in Figure 4 provides variance in the 1000 experimentally determined
values used to compute the average maximum number of new infections; that is, in the peak
value of each curve in the plots of the top row. For these particular graphs, the variances
are very roughly on the order of 0.01, which is, interestingly, much smaller than those for
the final number of infections in Figure 2.
5.3.2 Degree-Assortative Perturbation
Here, we focus on results that are different from those for uniform perturbation.
Effect of  and degree-assortativity on average final number of infections and
variance. The first row of plots in Figure 5 shows the average final number of infections,
from 1000 measurements, as a function of p and . The  = 0 curves are the same as
those in Figure 2. By comparison with the top row of plots in that figure, it is clear that
degree-assortativity perturbations significantly reduce the effect of  on changes in the
average final number of infections. We find, over all networks, that AS-2000-01-02 and
Wiki-Vote provide two bounding cases, i.e., least effect and most effect of degree-assortative
perturbations, respectively. From comparison of the second row of plots in each of Figure 5
and Figure 2, it is also clear that degree-assortative perturbations correspondingly collapse
the variances across  values for Wiki-Vote, but those for AS-2000-01-02 are less affected.
Effect of perturbation method on average final number of infections. Since the
 = 0 curves are the same in Figure 2 and Figure 5, when all other factors are the same,
uniform perturbations generate greater numbers of infections than do degree-assortative
perturbations (compare the top rows of plots in the two figures).
Effect of network structure for degree-assortative perturbations. The effects of
degree assortative perturbations appear to be more network-specific than those for uniform
perturbations. This is expected since the perturbation instances inherit some of the network
properties.
Effect of degree-assortative perturbations on the random regular graph. The
effects of the two perturbation methods on the random regular graphs are the same because
of the uniform node degrees.
5.4 Linear Threshold Model
We have results for the effect of uniform perturbation in the LT model. Figure 6 shows the
plots of average number of infections vs.  for three representative networks for different
seed probabilities s. The remaining plots are in the full version (Adiga et al., 2014). In each
diffusion instance, the seed set was constructed by sampling the vertex set uniformly with
222

fiSensitivity of Diffusion Dynamics to Network Uncertainty

Average Final Size

Average Final Size
Variance Final Size

1.0 Random-Regular-20
 =0
 =0.5
0.8
 =1
 =5
0.6
 =10
0.4
0.2
0.00.0 0.1 0.2 0.3 0.4
Probability, p
Random-Regular-20
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probability, p

Variance Final Size

Average Final Size

Wiki-Vote
1.0
 =0
 =0.5
0.8
 =1
 =5
0.6
 =10
0.4
0.2
0.00.0 0.2 0.4 0.6 0.8 1.0
Probability, p
Wiki-Vote
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probability, p

Variance Final Size

AS-2000-01-02
1.0
0.8
0.6
 =0
0.4
 =0.5
 =1
0.2
 =5
0.00.0 0.2 0.4 0.6 =100.8
Probability, p
AS-2000-01-02
0.12
 =0
 =0.5
0.10
 =1
0.08
 =5
 =10
0.06
0.04
0.02
0.000.0 0.2 0.4 0.6 0.8 1.0
Probability, p

Figure 5: Degree-assortative perturbation (IC model): Average and variance of fraction of
infections for a single random seed vs. transmission probability p for various  values. The
remaining plots are in the full version (Adiga et al., 2014).

probability s, and every node was assigned a threshold chosen uniformly at random in the
interval [0, 1].
Recall from Theorem 2 that the spread is bounded by a linear function of . From
Figure 6, we observe that the model is generally robust to perturbation and the spread is a
linear or sublinear function of  depending on the seed probability s. In particular, when the
seed probability is low (s = 0.0001 for example), there is hardly any change in the average
spread. Note that in the plots,  ranges from 0 all the way up to 100 which is an extreme
value for perturbation considering the sizes of the networks. However, for larger values
of s, especially when it is comparable to the maximum degree , the effect of  is more
pronounced, even for low values of . This observation is worth investigating and could lead
to better bounds for spread than what we have in Theorem 2.

6. Conclusions and Open Problems
We give the first rigorous results on the stability of the independent cascade and linear
threshold models with respect to edge perturbations. We considered two popular noise
models namely, uniform and degree-assortative perturbations, and studied the sensitivity of
the final outbreak size and temporal characteristics to these perturbations. Our analysis
was supported by experimental observations on 20 diverse real networks. We showed that
the sensitivity of the independent cascade model depends on the transmission probability
and perturbation can lead to abrupt changes in the outcome, while the linear threshold
model with uniform edge weights is in general stable to network perturbations. Also,
our experiments suggest that dynamics are more sensitive to uniform perturbation than
223

fiAdiga, Kuhlman, Mortveit & Vullikanti

0.6

s =0.0001
s =0.001
s =0.01

0.4
0.2

0.8

0.00 20 40 60 80 100
Perturbation, 

CIT-HepPh

0.6

0.4

s =0.0001
s =0.001
s =0.01

0.8

Average Final Size

CA-AstroPh

Average Final Size

Average Final Size

0.8

0.6

Slashdot-09-02

s =0.0001
s =0.001
s =0.01

0.4

0.2

0.00 20 40 60 80 100
Perturbation, 

0.2

0.00 20 40 60 80 100
Perturbation, 

Figure 6: Uniform perturbation (LT model): Average fraction of infected nodes vs. perturbation  for various seed probabilities s. The remaining plots are in the full version (Adiga
et al., 2014).

degree-assortative. Extending our results to other models of noise, especially those involving
dependencies, sensitivity to the number of sources, and examining the sensitivity of other
dynamical properties in more general diffusion models (including the IC and LT models
with heterogeneous probabilities or weights) are natural open problems for future research.

7. Acknowledgments
This work has been partially supported by the following grants: DTRA Grant HDTRA111-1-0016, DTRA CNIMS Contract HDTRA1-11-D-0016-0010, NSF Career CNS 0845700,
NSF ICES CCF-1216000, NSF NETSE Grant CNS-1011769 and DOE DE-SC0003957. Also
supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department
of Interior National Business Center (DoI/NBC) contract number D12PC000337, the US
Government is authorized to reproduce and distribute reprints for Governmental purposes
notwithstanding any copyright annotation thereon.
Disclaimer: The views and conclusions contained herein are those of the authors and should
not be interpreted as necessarily representing the official policies or endorsements, either
expressed or implied, of IARPA, DoI/NBC, or the US Government.
A preliminary version of this paper appeared in Twenty-Seventh AAAI Conference on
Artificial Intelligence (2013).

References
Achlioptas, D., Clauset, A., Kempe, D., & Moore, C. (2005). On the bias of traceroute
sampling: or, power-law degree distributions in regular graphs. In Proceedings of the
thirty-seventh annual ACM Symposium on Theory of Computing, pp. 694703. ACM.
Adiga, A., Kuhlman, C., Mortveit, H. S., & Vullikanti, A. K. S. (2014). Sensitivity of diffusion dynamics to network uncertainty. Technical report, available at
http://ndssl.vbi.vt.edu/supplementary-info/vskumar/sensitivity-jair.pdf.
Bakshy, E., Hofman, J. M., Mason, W. A., & Watts, D. J. (2011). Everyones an influencer:
quantifying influence on Twitter. In Proceedings of the fourth ACM international
224

fiSensitivity of Diffusion Dynamics to Network Uncertainty

conference on Web search and data mining, pp. 6574. ACM.
Bollobs, B. (1985). Random graphs. Academic Press.
Borgatti, S., Carley, K., & Krackhardt, D. (2006). On the robustness of centrality measures
under conditions of imperfect data. Social Networks, 28, 124136.
Chen, J. (2010). The effects of demographic and spatial variability on epidemics: A comparison
between Beijing, Delhi and Los Angeles. In Conf. on Crit. Inf.
Chung, F., & Lu, L. (2002). Connected components in random graphs with given expected
degree sequences.. Annals of Combinatorics, 6, 125145.
Clauset, A., Moore, C., & Newman, M. (2008). Hierarchical structure and the prediction of
missing links in networks. Nature, 453, 98101.
Costenbader, E., & Valente, T. (2003). The stability of centrality measures when networks
are sampled. Social Networks, 25, 283307.
Eubank, S. (2010). Detail in network models of epidemiology: are we there yet?. Journal of
Biological Dynamics, 4(5), 446455.
Faloutsos, M., Faloutsos, P., & Faloutsos, C. (1999). On power-law relationships of the
internet topology. In SIGCOMM, Vol. 29, pp. 251262.
Flaxman, A., & Frieze, A. M. (2004). The diameter of randomly perturbed digraphs and
some applications. In APPROX-RANDOM, pp. 345356.
Flaxman, A. (2007). Expansion and lack thereof in randomly perturbed graphs. Internet
Mathematics, 4 (2-3), 131147.
Galuba, W. (2010). Outtweeting the twitterers - predicting information cascades in microblogs. In WOSN.
Goldenberg, J., Libai, B., & Muller, E. (2001). Talk of the network: A complex systems look
at the underlying process of word-of-mouth. Marketing Letters.
Gonzlez-Bailn, S., Borge-Holthoefer, J., Rivero, A., & Moreno, Y. (2011). The dynamics
of protest recruitment through an online network. Scientific Reports, 1.
Hagmann, P. (2008). Mapping the structural core of human cerebral cortex. PLoS Biol,
6(7).
Kaneko, K. (1985). Spatiotemporal intermittency in coupled map lattices. Progress of
Theoretical Physics, 74 (5), 10331044.
Kempe, D., Kleinberg, J., & Tardos, . (2003). Maximizing the spread of influence through
a social network. In Proceedings of the ninth ACM SIGKDD international conference
on Knowledge discovery and data mining, pp. 137146. ACM.
Kempe, D., Kleinberg, J., & Tardos, . (2005). Influential nodes in a diffusion model for
social networks. In Automata, languages and programming, pp. 11271138. Springer.
Kuhlman, C., Kumar, V., & Ravi, S. (2013). Controlling opinion propagation in online
networks. Journal of Computer Networks, 57, 21212132.
Lahiri, M., Maiya, A. S., Caceres, R. S., Habiba, & Berger-Wolf, T. Y. (2008). The impact
of structural changes on predictions of diffusion in networks. In ICDM, pp. 939948.
225

fiAdiga, Kuhlman, Mortveit & Vullikanti

Leskovec, J. (2011). Stanford network analysis project. http://snap.stanford.edu/index.html.
Newman, M. (2003). The structure and function of complex networks. SIAM Review, 45 (2),
167256.
Romero, D., Meeder, B., & Kleinberg, J. (2011). Differences in the mechanics of information
diffusion across topics: idioms, political hashtags, and complex contagion on twitter.
In Proc. of WWW, pp. 695704. ACM.
Ron, D. (2010). Algorithmic and analysis techniques in property testing. Foundations and
Trends in TCS, 5 (2), 73205.
Schwab, D. J., Bruinsma, R. F., Feldman, J. L., & Levine, A. J. (2010). Rhythmogenic
neuronal networks, emergent leaders, and k-cores. Phys. Rev. E, 82, 051911.
Spielman, D. (2009). Smoothed analysis: An attempt to explain the behavior of algorithms
in practice. Communications of the ACM, 7684.
Wu, C. W. (2005). Synchronization in networks of nonlinear dynamical systems coupled via
a directed graph. Nonlinearity, 18, 10571064.

226

fiJournal of Artificial Intelligence Research 51 (2014) 413-441

Submitted 06/14; published 10/14

Scoring Functions Based on Second Level Score
for k-SAT with Long Clauses
Shaowei Cai

SHAOWEICAI . CS @ GMAIL . COM

State Key Laboratory of Computer Science,
Institute of Software, Chinese Academy of Sciences, Beijing, China
Queensland Research Lab, NICTA, Brisbane, Australia

Chuan Luo

CHUANLUOSABER @ GMAIL . COM

Key Laboratory of High Confidence Software Technologies,
Peking University, Beijing, China

Kaile Su

K . SU @ GRIFFITH . EDU . AU

Institute for Integrated and Intelligent Systems,
Griffith University, Brisbane, Australia

Abstract
It is widely acknowledged that stochastic local search (SLS) algorithms can efficiently find
models for satisfiable instances of the satisfiability (SAT) problem, especially for random k-SAT
instances. However, compared to random 3-SAT instances where SLS algorithms have shown great
success, random k-SAT instances with long clauses remain very difficult. Recently, the notion of
second level score, denoted as score2 , was proposed for improving SLS algorithms on long-clause
SAT instances, and was first used in the powerful CCASat solver as a tie breaker.
In this paper, we propose three new scoring functions based on score2 . Despite their simplicity,
these functions are very effective for solving random k-SAT with long clauses. The first function
combines score and score2 , and the second one additionally integrates the diversification property
age. These two functions are used in developing a new SLS algorithm called CScoreSAT.
Experimental results on large random 5-SAT and 7-SAT instances near phase transition show
that CScoreSAT significantly outperforms previous SLS solvers. However, CScoreSAT cannot
rival its competitors on random k-SAT instances at phase transition. We improve CScoreSAT
for such instances by another scoring function which combines score2 with age. The resulting
algorithm HScoreSAT exhibits state-of-the-art performance on random k-SAT (k > 3) instances
at phase transition. We also study the computation of score2 , including its implementation and
computational complexity.

1. Introduction
The Boolean Satisfiability (SAT) problem is a prototypical NP-complete problem whose task is to
decide whether the variables of a given Boolean formula can be assigned in such a way as to make
the formula evaluate to TRUE. This problem plays a prominent role in various areas of computer
science and artificial intelligence, and has been widely studied due to its significant importance in
both theory and applications.
Two popular approaches for solving SAT are conflict driven clause learning (CDCL) and
stochastic local search (SLS). The latter operates on complete assignments and tries to find a model
by iteratively flipping a variable. Although SLS algorithms are typically incomplete in the sense
2014 AI Access Foundation. All rights reserved.

fiC AI , L UO & S U

that they cannot prove an instance to be unsatisfiable, they often find models of satisfiable formulas
surprisingly effectively.
Most SLS algorithms for SAT switch between two different modes, i.e., the greedy
(intensification) mode and the diversification mode. In the greedy mode, they prefer to flip variables
whose flips can decrease the number of falsified clauses; in the diversification mode, they tend to
better explore the search space and avoid local optima, usually using randomized strategies and
exploiting diversification properties of variables to pick a variable for this aim.
SLS is well known as the most effective approach for solving random satisfiable instances, and
SLS algorithms are often evaluated on uniform random k-SAT benchmarks. These benchmarks
have a large variety of instances to test the robustness of algorithms, and by controlling the
instance size and the clause-to-variable ratio, they provide adjustable hardness levels to assess the
solving capabilities. Moreover, the performance of algorithms are usually stable on random kSAT instances, either good or bad. Thus, we can easily recognize good heuristics by testing SLS
algorithms on random k-SAT instances, and these heuristics may be beneficial for solving realistic
problems. Numerous works have been devoted to designing SLS algorithms for random k-SAT
instances with a clause-to-variable ratio at or near the solubility phase transition, which are the most
difficult among random k-SAT instances (Kirkpatrick & Selman, 1994).
Among random k-SAT instances, random 3-SAT ones exhibit some particular statistical
properties and are easy to solve, for example, by SLS algorithms and a statistical physics approach
called Survey Propagation (Braunstein, Mzard, & Zecchina, 2005). It has been shown that the
famous SLS algorithm WalkSAT (Selman, Kautz, & Cohen, 1994), which was proposed two
decades ago, scales linearly with the number of variables for random 3-SAT instances near the phase
transition and can solve such instances with one million variables (Kroc, Sabharwal, & Selman,
2010). The latest state of the art in this direction is an SLS algorithm called FrwCB, which solves
random 3-SAT instances near the phase transition (at ratio 4.2) with millions of variables within 2-3
hours (Luo, Cai, Wu, & Su, 2013).
In contrast, random k-SAT instances with long clauses remain very difficult, and the
performance of SLS algorithms on such instances has stagnated for a long time. Indeed, such
instances are challenging for all kinds of algorithms, including the Survey Propagation algorithm,
which solves random 3-SAT instances extremely fast (Mzard, 2003) and is also adapted for solving
MaxSAT (Chieu & Lee, 2009). Recently, a few progresses such as Sattime (Li & Li, 2012), probSAT
(Balint & Schning, 2012) and CCASat (Cai & Su, 2013b), have been made in this direction. In
particular, when solving random instances near the phase transition, the Sattime algorithm is good
at solving random 6-SAT and 7-SAT instances, and probSAT is good at solving random 4-SAT and
5-SAT instances. Comparatively, CCASat shows good performance on all random k-SAT instances
for k  {4, 5, 6, 7} and won the random track of SAT Challenge 2012. Note that the second and
third solvers in that track are variants of the portfolio solver SATzilla (Xu, Hutter, Hoos, & LeytonBrown, 2008). On the other hand, probSAT and Sattime show better performance than CCASat on
random k-SAT instances at the threshold ratio of phase transition.
A key notion in CCASat is the score2 property1 , which shares the same spirit with the
commonly used score property and can be regarded as the second level score. It considers
transformations between clauses with one true literal and those with two true literals. By breaking
ties using score2 , the performance of CCASat is significantly improved for random k-SAT instances
1. the score2 property is denoted by subscore in CCASat (Cai & Su, 2013b).

414

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

with k > 3 (Cai & Su, 2013b). This leads us to such a question  Can we further improve SLS
algorithms on such instances by making better use of the score2 property? In this paper, we give
a positive answer to this question by proposing three new scoring functions based on score2 , and
using them to develop two SLS algorithms which outperform state-of-the-art solvers on random
k-SAT with k > 3 near and at phase transition.
The first scoring function proposed in this paper is called cscore, which is a linear combination
of score and score2 . The cscore function differs from previous hybrid scoring functions in that it
considers two score properties of different levels. Based on this scoring function, we also define
a new type of decreasing variables namely comprehensively decreasing variables. The cscore
function enhances intensification in the greedy mode by integrating the current greediness and the
look-ahead greediness. Further, by combining cscore with the diversification property age (the
definition of age can be found in Section 2.1), we propose the second scoring function dubbed
hscore, which is used to improve the diversification mode. These two scoring functions are used to
develop an SLS algorithms called CScoreSAT.
We conduct extensive experiments to compare CScoreSAT against state-of-the-art SLS solvers
including winners from the most recent SAT competitions. The experiments on large random 5SAT and 7-SAT instances near phase transition show that CScoreSAT significantly outperforms its
competitors in terms of success rate or run time. In particular, CScoreSAT is able to solve random
5-SAT instances with up to 5000 variables and random 7-SAT instances with up to 300 variables,
whereas all its competitors fail to solve such instances of this size.
However, the performance of CScoreSAT on random k-SAT instances at the threshold ratio of
phase transition is not as good as other state-of-the-art solvers such as probSAT and Sattime, which
are the top two solvers in the random SAT category of SAT Competition 2013. Note that the major
part of the random SAT benchmark in SAT Competition 2013 consists of random k-SAT instances
at phase transition.
The second contribution of this paper is to improve CScoreSAT for random k-SAT instances
at the threshold ratio of phase transition. The idea is to reduce the intensification of the greedy
mode, because such instances have fewer models (if satisfiable). Our considerations give rise to
the third scoring function dubbed hscore2 , which combines score2 with age. This function is used
to improve the greedy mode of CScoreSAT, leading to a new algorithm called HScoreSAT. In the
greedy mode, HScoreSAT utilizes the score property to pick the flipping variable, and breaks ties by
the hscore2 function. We evaluate HScoreSAT on random k-SAT (k > 3) instances at the threshold
ratio of phase transition, including those from SAT Competition 2013, and the experimental results
show that HScoreSAT significantly improves CScoreSAT on such instances.
We note that the first two functions and the CScoreSAT algorithm (Section 3), have been
presented in a conference paper (Cai & Su, 2013a), while the third scoring function and the
HScoreSAT algorithm (Section 4), as well as further experimental analyses (including Section 3.5
and the whole Section 5) are new contributions in this paper.
This paper proceeds as follows. Section 2 introduces some preliminary concepts. Section 3
presents the cscore and hscore functions and describes the CScoreSAT algorithm, along with
experimental evaluations and analyses of CScoreSAT on random k-SAT (k > 3) instances near
phase transition. Section 4 presents the hscore2 function and the HScoreSAT algorithm, as
well as evaluations of HScoreSAT on random k-SAT (k > 3) instances at phase transition and
related experimental analyses. In Section 5, we study the computation of score2 , including
415

fiC AI , L UO & S U

its implementation, complexity and computational overhead. Finally, we give some concluding
remarks and future directions in Section 6.

2. Preliminaries
In this section, we first introduce some basic definitions and notation about the problem. Then, we
briefly review the notion of second level properties and related works. Finally, we introduce the
configuration checking strategy, which is also an important component in our algorithms.
2.1 Basic Definitions and Notation
Given a set of n Boolean variables {x1 , x2 , ..., xn }, a literal is either a variable x (which is called
positive literal) or its negation x (which is called negative literal), and a clause is a disjunction
of literals. A conjunctive normal form (CNF) formula F = c1  c2  ...  cm is a conjunction of
clauses. A satisfying assignment for a formula is an assignment to its variables such that the formula
evaluates to true. Given a CNF formula F , the Boolean Satisfiability problem is to find a satisfying
assignment or prove that none exists.
A well-known generation model for SAT is the uniform random k-SAT model (Achlioptas,
2009). In a random k-SAT instance, each clause contains exactly k distinct non-complementary

literals, and is picked up with uniform probability distribution from the set of 2k nk possible clauses.
The clause-to-variable ratio of a CNF formula F is defined as r = m/n, where n is the number of
variables and m is the number of clauses.
For a CNF formula F , we use V (F ) to denote the set of all variables that appear in F . We say
a variable appears in a clause, if the clause contains either x or x. Two variables are neighbors if
and only if they appear simultaneously in at least one clause. The neighbourhood of a variable x is
N (x) = {y|y occurs in at least one clause with x}, which is the set of all neighboring variables
of variable x. For a subset X  V (F ) and an assignment , [X] is the projection of  on the
variables of X.
We say that a literal is true if the current value of the variable is the same as its phase. E.g., if
x1 = false, then the negative literal x1 is true, while the positive literal x1 is not true. A clause is
satisfied if it has at least one true literal, and falsified otherwise.
SLS algorithms for SAT usually select a variable to flip in each step under the guidance of
scoring f unctions. Most SLS algorithms have more than one scoring function, and adopt one of
them for the current search step according to some conditions, such as whether a local optimum is
reached. A scoring function can be a simple variable property or any mathematical expression with
one or more properties.
Perhaps the most popular variable property used by SLS algorithms for SAT is score, which
measures the increase in the number of satisfied clauses by flipping a variable. The score property
is also defined as score(x) = make(x)  break(x), where make and break is the number of
clauses that would become satisfied and falsified, respectively, if x were to be flipped. Note that
the two definitions of score are equivalent. In dynamic local search algorithms which use clause
weighting techniques, score measures the increase in the total weight of satisfied clauses by flipping
a variable, while make and break measures the total weight of clauses that would become satisfied
and falsified, respectively, by flipping x. A variable is decreasing if its score is positive, and
increasing if its score is negative. The age of a variable is defined as the number of search steps
that have occurred since the variable was last flipped.
416

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

2.2 Second Level Properties
In this subsection, we introduce the second level properties, especially the second level score, which
is an important concept in the proposed scoring functions in this work.
The second level properties take into account the satisfaction degree of clauses, which is defined
as the number of true literals in the clause (Cai & Su, 2013a). A clause with a satisfaction degree
of  is said to be a -satisfied clause. For a variable x, score2 (x) is defined as make2 (x) minus
break2 (x), where make2 (x) is the number of 1-satisfied clauses that would become 2-satisfied
by flipping x, and break2 (x) is the number of 2-satisfied clauses that would become 1-satisfied
by flipping x. One can easily define properties of other levels and the weighted version of these
properties.
The first SLS solver using second level properties is CCASat (Cai & Su, 2013b), which simply
uses score2 as a tie breaker and achieves surprising improvements on random k-SAT with long
clauses. Then, in the conference version of this paper, we combine score and score2 to develop the
CScoreSAT algorithm (Cai & Su, 2013a). We also propose the notion of multi-level properties and
use make2 to improve the famous WalkSAT/SKC algorithm (Cai, Su, & Luo, 2013a). Afterwards,
multi-level break is used to improve the probSAT solver (Balint, Biere, Frhlich, & Schning,
2014). In this work, we further exploit the score2 property by using it to design scoring functions
that directly guide the algorithm to pick the flipping variable.
We note that both algorithms in this work utilize the unweighted version of score2 (although
they use the weighted version of score), just as CCASat does. In our algorithms, the unweighted
score2 is found to be much more effective than the weighted one, yet at this time we could not
figure out the reason or find an effective way using weighted score2 in these algorithms.
2.3 Configuration Checking for SAT
In this subsection, we briefly introduce the configuration checking (CC) strategy for SAT, which is
an important component in the proposed algorithms in this work.
Initially introduced for improving local search for the Minimum Vertex Cover (MVC) problem
(Cai, Su, & Sattar, 2011), the CC strategy aims at avoiding cycling in local search, i.e., revisiting
the already visited candidate solutions too early. It has been successfully used in MVC (Cai et al.,
2011; Cai, Su, Luo, & Sattar, 2013b), as well as SAT (Cai & Su, 2012; Luo et al., 2013; Abram,
Habet, & Toumi, 2014; Luo, Cai, Wu, & Su, 2014; Li, Huang, & Xu, 2014) and MaxSAT (Luo, Cai,
Wu, Jie, & Su, 2014).
The CC strategy is based on the concept of configuration. One can define configuration
in different ways and design different CC strategies accordingly. In the context of SAT, the
configuration of a variable typically refers to truth values of all its neighboring variables (Cai &
Su, 2013b). Formally, given an assignment , the CC strategy for SAT defines the configuration
C(xi ) of a variable xi as a subset of  restricted to the variables of N (xi ), i.e., C(xi ) = [N (xi )].
If a variable in C(xi ) has been flipped since the last flip of xi then C(xi ) is said changed. The CC
strategy for SAT forbids the flip of a variable xi if its configuration C(xi ) has not changed since the
last flip of xi .
The CC strategy is used to decrease blind unreasonable greedy search. This strategy has been
successfully applied to SAT solving, resulting in several efficient SLS algorithms for SAT, such as
CCASat (Cai & Su, 2013b), Ncca+ (the bronze medal winner of the random SAT track of SAT
Competition 2013) (Abram et al., 2014), BalancedZ (Li et al., 2014) and CSCCSat (Luo et al.,
417

fiC AI , L UO & S U

2014) (the silver and bronze medal winner of random SAT track of SAT Competition 2014), and
CCAnr+glucose (Cai & Su, 2012) (the silver medal winner of hard combinatorial SAT track of SAT
Competition 2014), etc.

3. Two New Scoring Functions and the CScoreSAT Algorithm
In this section, we design two new scoring functions, namely cscore and hscore. Then we use them
to develop a new SLS algorithm called CScoreSAT, which shows excellent performance on random
k-SAT with k > 3 near the phase transition.
3.1 The cscore Function
In this subsection, we introduce the cscore (short for comprehensive score) function, which is a
linear combination of the score and score2 properties.
The score property characterizes the greediness of flipping a variable at the current search step,
as it tends to decrease the number of falsified clauses, which is indeed the aim of the SAT problem.
On the other hand, the score2 property can be regarded as a measurement of look-ahead greediness,
as it tends to reduce 1-satisfied clauses by transforming them into 2-satisfied clauses, noting that
1-satisfied clauses may become falsified in the next step while 2-satisfied ones do not.
It seems short sighted to simply take the score property as the scoring function, especially for
formulas with long clauses, in which the number of true literals varies considerably among satisfied
clauses. To address this issue, we propose a scoring function that incorporates both score and
score2 . When deciding the candidate variables priorities of being selected, although score is more
important than score2 , in some cases score2 should be allowed to overwrite the priorities. For
example, for two variables which have a relatively small score difference and a significant score2
difference, it is advisable to prefer to flip the one with greater score2 .
The above considerations suggest two principles in designing the desired scoring functions.
 First, the score property plays a more important role;
 Second, the score2 property is allowed to overwrite the variables priorities (of being
selected).
As a result, we have the notion of comprehensive score, which is formally defined as follows.
Definition 1. For a CNF formula F , the comprehensive score function, denoted by cscore, is a
function on V (F ) such that
cscore(x) = score(x) + score2 (x)/d,
where d is a positive integer parameter.
Note that cscore is defined to be an integer function, and thus the value of cscore will be
rounded down to an integer if it is not.
The cscore function is a linear combination of score and score2 with a bias towards score, and
thus embodies the two principles well. This function is so simple that it can be computed with little
overhead and the parameter can be easily tuned. Moreover, its simplicity allows its potential usage
in solving structured SAT instances and perhaps other combinatorial search problems.
Recall that a variable is decreasing if and only if it has a positive score. In the following, we
define a new type of deceasing variables based on the cscore function.
418

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Definition 2. Given a CNF formula F and its cscore function, a variable x is comprehensively
decreasing if and only if cscore(x) > 0 and score(x)  0.
While the condition cscore(x) > 0 is straightforward, the other condition score(x)  0
requires the variable to be non-increasing. This is necessary, as flipping an increasing variable leads
the local search away from the objective, which should not be accepted without any controlling
mechanism such as the Metroplis probability in Simulated Annealing (Kirkpatrick, Gelatt, &
Vecchi, 1983), unless the algorithm gets stuck in a local optimum.
Most SLS algorithms for SAT prefer to flip decreasing variables in the greedy search mode.
In some respect, the notion of comprehensively decreasing variables is an extension of decreasing
variables, and is a good alternative to be considered as flip candidates in the greedy search phases.
3.2 The hscore Function
We combine cscore with the diversification property age, resulting in a hybrid scoring function
dubbed hscore, which can be used to improve the diversification mode.
One of the most commonly used variable property in the diversification mode of SLS algorithms
for SAT is age. Previous SLS algorithms usually use age to pick the oldest variable from a candidate
variable set (Gent & Walsh, 1993; Li & Huang, 2005; Cai & Su, 2012; Abram et al., 2014) or only
to break ties (Prestwich, 2005; Pham, Thornton, Gretton, & Sattar, 2007; Luo, Su, & Cai, 2012).
In our opinion, however, these oldest strategies are too strict as they always prefer the oldest one,
regardless of other important information such as score or cscore. Thus, these oldest strategies
may miss better variables quite often.
For example, suppose an SLS algorithm gets stuck in a local optimum, and it would like to pick
one variable to flip from such two variables x1 and x2 : the two variables have similar ages and x1
is older than x2 , while cscore(x2 ) is significantly greater than cscore(x1 ). In this case, we believe
x2 is the right choice rather than the older variable x1 , as the flipping of these two variables leads to
similar diversification and flipping x2 does less harm to the object function.
Based on the above considerations, we design a hybrid scoring function taking account into both
the greediness information cscore and the diversification information age. The resulting scoring
function is dubbed as hscore and is given as follows.
Definition 3. For a CNF formula F , the hscore function is a function on V (F ) such that
hsocre(x) = cscore(x) + age(x)/ = score(x) + score2 (x)/d + age(x)/,
where d and  are positive integer parameters.
In our algorithms, when reaching a local optimum, the algorithms make use of this hybrid
function. We will show that the hscore function is a better choice than the oldest strategy for the
diversification mode.
3.3 The CScoreSAT Algorithm
This section presents the CScoreSAT algorithm, which adopts the cscore function to guide the
search in the greedy mode, and makes use of the hscore function when meets local optima.
Before getting into the details of the CScoreSAT algorithm, we first introduce two techniques
employed in the algorithm.
419

fiC AI , L UO & S U

1. PAWS weighting scheme. For the sake of diversification, CScoreSAT employs the PAWS
clause weighting scheme (Thornton, Pham, Bain, & Ferreira Jr., 2004). Each clause is
associated with a positive integer as its weight, which is initiated as 1. When a local optimum
is reached, the clause weights are updated as follows. With probability sp (the so-called
smooth probability), for each satisfied clause whose weight is larger than one, its weight is
decreased by one; with probability (1  sp), the weights of all falsified clauses are increased
by one.
2. Configuration checking. In order to reduce blind greedy search, we utilize the configuration
checking strategy for SAT (Cai & Su, 2012). Recall that a variable is said to be configuration
changed if and only if after its last flip at least one of its neighboring variables has been
flipped. According to the configuration checking strategy, only configuration changed
variables are allowed to be flipped in the greedy mode.
Algorithm 1: CScoreSAT
Input: CNF-formula F , maxSteps
Output: A satisfying assignment  of F , or unknown
1 begin
2
 := randomly generated truth assignment;
3
for step := 1 to maxSteps do
4
if  satisfies F then return ;
5
if S = {x|x is comprehensively decreasing and configuration changed } =
6  then
6
v := a variable in S with the greatest cscore, breaking ties in favor of the oldest
one;
7
else
8
update clause weights according to PAWS;
9
pick a random falsified clause C;
10
v := the variable in C with the greatest hscore;
11
12
13

 :=  with v flipped;
return unknown;
end

The CScoreSAT algorithm is outlined in Algorithm 1, as described below. In the beginning,
CScoreSAT generates a random complete assignment, initiates all clause weights to 1 and computes
score and score2 of variables accordingly. After initialization, CScoreSAT executes a loop until
it finds a satisfying assignment or reaches a limited number of steps denoted by maxSteps (or a
given cutoff time).
Like most SLS algorithms for SAT, CScoreSAT switches between two modes. In each search
step, it works in either the greedy mode or the diversification mode, depending on whether there
exist comprehensively decreasing variables that are configuration changed. If there exist such
variables, CScoreSAT works in the greedy mode. It picks such a variable with the greatest cscore
value to flip, breaking ties by preferring the oldest one.
If no variables are both comprehensively decreasing and configuration changed, then
CScoreSAT switches to the diversification mode. It first updates clause weights according to the
420

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

PAWS scheme. Then it randomly selects a falsified clause C, and picks the variable from C with
the greatest hscore value to flip.
3.4 Evaluations of CScoreSAT
In this subsection, we carry out extensive experiments to evaluate CScoreSAT on random k-SAT
instances with k  {4, 5, 6, 7} near phase transition. First, we compare CScoreSAT with state-ofthe-art SLS solvers on random 5-SAT and 7-SAT instances. Then, we compare CScoreSAT with
state-of-the-art SLS solvers on random k-SAT with instances k  {4, 5, 6, 7} from SAT Challenge
2012. Finally, we study the effectiveness of the cscore and hscore functions through empirical
analysis on random 5-SAT and 7-SAT instances.
3.4.1 B ENCHMARKS

AND

E XPERIMENT P RELIMINARIES

All the instances used in these experiments are generated according to the random k-SAT model
near the solubility phase transition. Specifically, we adopt the following five benchmarks. The first
two benchmarks are for random 5-SAT, and the third and fourth benchmarks are for random 7-SAT,
while the last one consists of random k-SAT instances with k = 4, 5, 6, 7 at various ratios.
1. 5-SAT Comp11: all large random 5-SAT instances from SAT Competition 2011 (r = 20,
750  n  2000, 50 instances, 10 for each size).
2. 5-SAT Huge: 5-SAT instances generated randomly according to the random k-SAT model
(r = 20, 3000  n  5000, 500 instances, 100 for each size).
3. 7-SAT Comp11: all large random 7-SAT instances from SAT Competition 2011 (r = 85,
150  n  400, 50 instances, 10 for each size).
4. 7-SAT Random: 7-SAT instances generated randomly according to the random k-SAT model
(r = 85, 220  n  300, 500 instances, 100 for each size).
5. SAT Challenge 2012: all random k-SAT instances with k > 3 from SAT Challenge 2012
(480 instances, 120 for each k-SAT, k = 4, 5, 6, 7), which vary in both size and ratio. These
random instances occupy 80% of the random benchmark in SAT Challenge 2012, indicating
that the importance of random k-SAT instances with k > 3 has been highly recognized by the
SAT community. The instances vary from 800 variables at r = 9.931 to 10000 variables at
r = 9.0 for 4-SAT, from 300 variables at r = 21.117 to 1600 variables at r = 20 for 5-SAT,
from 200 variables at r = 43.37 to 400 variables at  = 40 for 6-SAT, and from 100 variables
at r = 87.79 to 200 variables at r = 85 for 7-SAT.

parameter
sp (for PAWS)
d


4-SAT
0.62
9
2000

5-SAT
0.62
8
2000

6-SAT
0.9
7
2000

7-SAT
0.9
6
2000

Table 1: Parameter setting of CScoreSAT
421

fiC AI , L UO & S U

CScoreSAT is implemented in C++ and compiled by g++ with the -O2 option. The parameter
setting of CScoreSAT is reported in Table 1. We compare CScoreSAT with four state-of-the-art
SLS solvers, including Sparrow2011 (Balint & Frhlich, 2010), CCASat (Cai & Su, 2013b),
probSAT (Balint & Schning, 2012), and Sattime2012 (Li & Li, 2012). Sparrow2011 and
probSAT won the gold medal of the random SAT track of the SAT competitions 2011 and 2013
respectively. CCASat is the winner of this same category in SAT Challenge 2012. Sattime regularly
won medals during SAT competitions of the same track.
All experiments are carried out parallel on a workstation under a 32-bit Ubuntu Linux Operation
System, using 2 cores of Intel(R) Core(TM) 2.6 GHz CPU and 8 GB RAM. The experiments are
conducted with EDACC, an experimental platform for testing SAT solvers, which has been used
for SAT Challenge 2012 and SAT Competition 2013. Each run terminates upon either finding a
satisfying assignment or reaching a given cutoff time which is set to 5000 seconds (as in SAT
Competition 2011) for the 5-SAT and 7-SAT benchmarks, and 1000 seconds for the SAT Challenge
2012 benchmark (close to the cutoff in SAT Challenge 2012, i.e., 900 seconds).
For the 5-SAT Comp11 and 7-SAT Comp11 benchmarks (where each instance class has 10
instances), we run each solver 10 times for each instance and thus 100 runs for each instance
class. For the 5-SAT Huge and 7-SAT Random benchmarks (where each instance class contains 100
instances) and the SAT Challenge 2012 benchmark (120 k-SAT instances for each k), we run each
solver one time for each instance, as the instances in each class are enough to test the performance
of the solvers.
For each solver on each instance class, we report the number of successful runs in which a
satisfying assignment is found (suc runs) or the solved instances (#solved), as well as the
PAR10 (par10), which is a penalized average run time where a timeout of a solver is penalized
as 10(cutoff time). Note that PAR10 is adopted in SAT competitions and has been widely used in
the literature as a prominent performance measure for SLS-based SAT solvers (KhudaBukhsh, Xu,
Hoos, & Leyton-Brown, 2009; Tompkins & Hoos, 2010; Tompkins, Balint, & Hoos, 2011; Balint
& Schning, 2012). The results in bold indicate the best performance for an instance class. If a
solver has no successful run on an instance class, the corresponding par10 is marked with n/a.
3.4.2 E XPERIMENTAL R ESULTS

OF

CS CORE SAT

In the following, we present the comparative experimental results of CScoreSAT and its competitors
on each benchmark.
Results on 5-SAT Comp11 Benchmark:
Table 2 shows the comparative results on the 5-SAT Comp11 benchmark. As is clear from Table
2, CScoreSAT shows significantly better performance than other solvers on the whole benchmark.
CScoreSAT is the only solver that solves all these 5-SAT instances in all runs. Also, CScoreSAT
significantly outperforms its competitors in terms of run time, which is more obvious as the instance
size increases. In particular, on the 5-SAT-v2000 instances, which are of the largest size in SAT
competitions, the runtime of CScoreSAT is 15 times less than that of CCASat, and 2 orders of
magnitudes less than that of other state-of-the-art SLS solvers.
Results on 5-SAT Huge Benchmark:
The experimental results on the 5-SAT Huge benchmark are presented in Table 3. It is
encouraging to see the performance of CScoreSAT remains surprisingly good on these very large 5SAT instances, where state-of-the-art solvers show very poor performance. CScoreSAT solves these
422

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Instance
Class
5-SAT-v750
5-SAT-v1000
5-SAT-v1250
5-SAT-v1500
5-SAT-v2000

Sattime2012
suc runs
par10
100
754
100
1254
95
5288
56
24101
14
43249

Sparrow2011
suc runs
par10
100
51
100
159
100
174
99
1231
72
15288

probSAT
suc runs
par10
100
88
100
185
100
237
98
1753
71
15635

CCASat
suc runs
par10
100
47
100
81
100
128
100
443
93
4386

CScoreSAT
suc runs
par10
100
35
100
38
100
47
100
145
100
289

Table 2: Experimental results on the 5-SAT Comp11 benchmark. There are 10 instances in
each class and each solver is executed 10 times on each instance with a cutoff time of
5000 seconds.

Instance
Class
5-SAT-v3000
5-SAT-v3500
5-SAT-v4000
5-SAT-v4500
5-SAT-v5000

Sattime2012
suc runs
par10
0
n/a
0
n/a
0
n/a
0
n/a
0
n/a

Sparrow2011
suc runs
par10
31
35360
8
46147
4
48080
0
n/a
0
n/a

probSAT
suc runs
par10
40
30867
6
47188
3
48591
0
n/a
0
n/a

CCASat
suc runs
par10
64
19403
35
33540
10
45287
0
n/a
0
n/a

CScoreSAT
suc runs
par10
100
694
100
1431
87
8167
62
21513
38
32005

Table 3: Experimental results on the 5-SAT Huge benchmark. There are 100 instances in each
class and each solver is executed one time on each instance with a cutoff time of 5000
seconds.

5-SAT instances with up to (at least) 3500 variables consistently (i.e., with 100% success rate), and
is about 30 times faster than other solvers on the 5-SAT-v3500 instances. Furthermore, CScoreSAT
succeeds in 62 and 38 runs for the 5-SAT-v4500 and 5-SAT-v5000 instances respectively, whereas
all its competitors fail to find a solution for any of these instances. Indeed, to the best of our
knowledge, such large random 5-SAT instances (at r = 20) are solved for the first time. Given the
good performance of CScoreSAT on the 5-SAT instances with 5000 variables, we are confident it
could be able to solve larger 5-SAT instances.
423

fiC AI , L UO & S U

Instance
Class
7-SAT-v150
7-SAT-v200
7-SAT-v250
7-SAT-v300
7-SAT-v400

Sattime2012
suc runs
par10
100
498
49
26998
2
49095
0
n/a
0
n/a

Sparrow2011
suc runs
par10
100
642
17
41912
0
n/a
0
n/a
0
n/a

probSAT
suc runs
par10
88
6980
11
44806
0
n/a
0
n/a
0
n/a

CCASat
suc runs
par10
100
232
72
14912
7
46731
0
n/a
0
n/a

CScoreSAT
suc runs
par10
100
131
90
5853
35
34070
11
44776
0
n/a

Table 4: Experimental results on the 7-SAT Comp11 benchmark. There are 10 instances in
each class and each solver is executed 10 times on each instance with a cutoff time of
5000 seconds.

Instance
Class
7-SAT-v220
7-SAT-v240
7-SAT-v260
7-SAT-v280
7-SAT-v300

Sattime2012
suc runs
par10
39
31868
13
43935
4
48113
0
n/a
0
n/a

Sparrow2011
suc runs
par10
13
43407
2
49051
0
n/a
0
n/a
0
n/a

probSAT
suc runs
par10
10
45253
2
49052
0
n/a
0
n/a
0
n/a

CCASat
suc runs
par10
68
17189
33
34158
9
45736
5
47605
0
n/a

CScoreSAT
suc runs
par10
83
10639
66
17901
53
24825
24
39283
11
44889

Table 5: Experimental results on the 7-SAT Random benchmark. There are 100 instances in
each class and each solver is executed one time on each instance with a cutoff time of
5000 seconds.

Results on 7-SAT Comp11 Benchmark:
Table 4 summarizes the experimental results on the 7-SAT Comp11 benchmark. None of the
solvers can solve any 7-SAT instance with 400 variables, indicating that random 7-SAT instances
near the phase transition are so difficult even with a relatively small size. Nevertheless, CScoreSAT
significantly outperforms its competitors on this 7-SAT benchmark, and is the only solver that can
solve such 7-SAT instances with 300 variables. Actually, all the competitors become ineffective
424

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Instance
Class
4-SAT
5-SAT
6-SAT
7-SAT
Over All

Sattime2012
#solved
par10
49
6031
32
7407
84
3187
81
3422
246
5011

Sparrow2011
#solved
par10
79
3514
52
5812
72
4193
65
4714
268
4558

probSAT
#solved
par10
111
778
54
5657
76
3877
57
5380
298
3923

CCASat
#solved
par10
112
751
71
4264
99
1887
77
3734
359
2659

CScoreSAT
#solved
par10
119
174
84
3146
110
935
91
2559
404
1703

Table 6: Experimental results on SAT Challenge 2012 benchmark. Each instance class contains
120 instances, and each solver is executed once on each instance with a cutoff time of 1000
seconds.

(among which CCASat has the highest success rate of 7%) on the 7-SAT-v250 instances, while
CScoreSAT still achieves a success rate of 35% for this instance class.
Results on 7-SAT Random Benchmark:
The sizes of random 7-SAT instances from SAT Competition 2011 are not continuous enough
to provide a good spectrum of instances for SLS solvers. In order to investigate the detailed
performance of CScoreSAT and state-of-the-art SLS solvers on random 7-SAT instances, we
evaluate them on the 7-SAT Random benchmark, where the instance size increases more slowly.
Once again, Table 5 suggests that the difficulty of such 7-SAT instances increases significantly
with a relatively small increment of the size. As reported in Table 5, the results show CScoreSAT
dramatically outperforms its competitors. Compared to the competitors whose performance
descends steeply as the instance size increases, CScoreSAT shows good scalability. For example,
from 7-SAT-v220 to 7-SAT-v260, the success rates of all the competitors decline eight times or
more, whereas that of CScoreSAT drops only thirty percents. When coming to the 7-SAT-v260
instances, probSAT and Sparrow2011 fail in all runs, and the other competitors succeed in less than
10 runs, while CScoreSAT succeeds in 53 runs. Finally, CScoreSAT is the only solver that survives
throughout the whole benchmark.
Results on SAT Challenge 2012 Benchmark:
To investigate the performance of CScoreSAT on random k-SAT instances with various k (k >
3), we compare it with state-of-the-art solvers on all random k-SAT instances with k > 3 from SAT
Challenge 2012. Table 6 reports the number of solved instances and PAR10 for each solver on each
k-SAT instance class. The results show that CScoreSAT significantly outperforms its competitors
in terms of both metrics. Overall, CScoreSAT solves 404 instances. Further observations show that
CScoreSAT solves 365 instances within half cutoff time, whereas none of its competitors solves
more than 360 instances within the cutoff time. More encouragingly, Table 6 shows that CScoreSAT
solves the most k-SAT instances for each k, which illustrates its robustness. The good performance
425

fiC AI , L UO & S U

1000
Sattime2012
Sparrow2011
probSAT
CCASat
CScoreSAT

900
800

run time (s)

700
600
500
400
300
200
100
0

0

50

100

150

200
#solved

250

300

350

400

Figure 1: Comparison of run time distributions on the SAT Challenge 2012 benchmark, with a cutoff
time of 1000 seconds.

of CScoreSAT on the SAT Challenge 2012 benchmark is also clearly illustrated by Figure 1, which
summarizes the run time distributions of the solvers on this benchmark.
3.5 Experimental Analyses of cscore and hscore Functions
In order to demonstrate the effectiveness of the cscore and hscore functions, we also test two
alternative versions of CScoreSAT, namely CScoreSAT1 and CScoreSAT2 . These two algorithms
are modified from CScoreSAT as follows.
 CScoreSAT1 : in the greedy mode, CScoreSAT1 uses score as the scoring function instead of
cscore; also, CScoreSAT1 does not utilize the concept of comprehensively decreasing, and a
variable is allowed to flip if it is decreasing and configuration changed.
 CScoreSAT2 : in the diversification mode, CScoreSAT2 uses the age property instead of
hscore as the scoring fucntion, i.e., it picks the oldest variable from the selected falsified
clause.
We carry out experiments to compare CScoreSAT with its two degraded versions on random 5SAT and 7-SAT instances. The experimental results are reported in Table 7. An obvious observation
is that the performance of CScoreSAT1 is essentially worse than that of CScoreSAT. For example,
it cannot solve any 5-SAT instance with 2000 variables or any 7-SAT instance with 250 instance.
This indicates the cscore function is critical to the good performance of CScoreSAT. Compared
to cscore, the hscore function used in the random mode does not show that much contribution.
Nevertheless, the usage of hscore does improve CScoreSATs performance on 5-SAT and 7-SAT
instances. A more careful comparison of CScoreSAT and CScoreSAT2 shows that hscore is more
important in solving 7-SAT instances than 5-SAT ones.
426

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Instance
Class
5-SAT-v1500
5-SAT-v2000
5-SAT-v4000
7-SAT-v150
7-SAT-v200
7-SAT-v250

CScoreSAT1
suc runs
par10
41
31452
0
n/a
0
n/a
89
5359
22
40406
0
n/a

CScoreSAT2
suc runs
par10
100
152
100
330
78
12118
100
569
75
13669
10
45329

CScoreSAT
suc runs
par10
100
145
100
289
87
8167
100
131
90
5853
35
34070

Table 7: Comparison of CScoreSAT and its two alternative algorithms on random 5-SAT and
7-SAT instances.

4. Improving CScoreSAT on Random k-SAT at Phase Transition
The above section shows the excellent performance of CScoreSAT on random k-SAT (k > 3) near
phase transition. However, the performance of CScoreSAT degrades on those instances at phase
transition. CScoreSAT participated in the satisfiable random category of SAT Competition 2013,
where the major part of the benchmark consists of instances generated at the threshold ratio of phase
transition. Although it is ranked 4th in the category, its performance is not good enough on this kind
of instances, and is worse than other state-of-the-art SLS solvers such as probSAT and Sattime2013,
which are the top two solvers in the satisfiable random category of SAT Competition 2013.
This section improves CScoreSAT for random k-SAT (k > 3) at phase transition. To this end,
we propose another scoring function combining score2 and age, and utilize it to improve the greedy
mode of CScoreSAT, resulting in a new algorithm called HScoreSAT. Our experiments show that
HScoreSAT significantly improves CScoreSAT and gives state-of-the-art performance on random kSAT (k > 3) at the threshold ratio of phase transition. We also compare CScoreSAT and HScoreSAT
on instances with various ratios and find the boundary ratios beyond which HScoreSAT outperforms
CScoreSAT.
4.1 The hscore2 Function and the HScoreSAT Algorithm
An important issue in SLS algorithms for SAT is the balance between intensification and
diversification. Indeed, most improvements on SLS algorithms for SAT are due to proper regulation
of intensification and diversification in local search. For random k-SAT instances at the solubility
phase transition, most of the search regions do not contain a model (if the instance is satisfiable).
Therefore, it is inadvisable to have strong intensification for such instances, which might waste the
search much time on unpromising regions so that the search does not explore enough regions for
discovering a model.
427

fiC AI , L UO & S U

In order to improve CScoreSAT for random k-SAT instances at phase transition, we propose to
reduce intensification in the greedy mode. In CScoreSAT, we use cscore as the scoring function, and
break ties by age. As mentioned before, the cscore function is quite a greedy scoring function as it
combines score and score2 , which represent the greediness and look-ahead greediness respectively.
Therefore, in our opinion, cscore is not suitable for random k-SAT instances at phase transition.
Recalling that the object of SLS algorithms for SAT is to minimize the number or total weight
of falsified clauses, the score property should be the primary criterion in the greedy mode. Also,
we believe the score2 property is important information for solving long-clause instances, as it
considers the satisfaction degree of clauses. However, when score and score2 are combined
together as the primary scoring function, it is too intensifying for solving (satisfiable) random kSAT instances at phase transition.
Based on the above considerations, we move score2 from the primary scoring function to the
tie-breaking function, where it is combined with the diversification property age. This leads to a
new scoring function which we refer to as hscore2 as it is a hybrid function of score2 and age.
Definition 4. For a CNF formula F , the hscore2 function is a function on V (F ) such that
hscore2 (x) = score2 (x) + age(x)/,
where  is a positive integer parameter.
Accordingly, we modify the greedy mode of CScoreSAT, and obtain a new algorithm which we
refer to as HScoreSAT. The pseudo-codes of HScoreSAT is given in Algorithm 2.
HScoreSAT differs from CScoreSAT in the following two aspects. First, although both
algorithms utilize the CC strategy, HScoreSAT only allows decreasing variables to be flipped in the
greedy mode, while CScoreSAT allows comprehensively decreasing variables (which is a super-set
of decreasing variables) to be flipped. More importantly, HScoreSAT uses hscore2 to break ties in
the greedy mode, while CScoreSAT breaks ties by age.
Since the hscore2 -based tie-breaking is an important component of HScoreSAT, we are
interested in this question: when there exist configuration changed decreasing variables, how often
the tie-breaking is executed to pick one from them? We have conducted an experiment on the
threshold benchmark from the random satisfiable category of SAT Competition 2013 to calculate
this frequency, which is the ratio of the following two statistics.
 #stepsccd : the number of steps in which configuration changed decreasing (CCD) variables
exist.
 #stepsbt : the number of steps in which configuration changed decreasing (CCD) variables
exist, and the best CCD variable is picked via hscore2 -based tie-breaking.
The experimental results are summarized in Table 8, which are averaged over all instances
with each run per instance. As is demonstrated in Table 8, the frequency of the hscore2 -based
tie-breaking in CCD steps is significant, and is very high for 4-SAT and 5-SAT (68% and 60%
respectively). This indicates that the hscore2 -based tie-breaking mechanism plays a critical role
in HScoreSAT. Another interesting observation is that this frequency decreases with the length of
clauses in the instance.
428

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Algorithm 2: HScoreSAT
Input: CNF-formula F , maxSteps
Output: A satisfying assignment  of F , or unknown
1 begin
2
 := randomly generated truth assignment;
3
for step := 1 to maxSteps do
4
if  satisfies F then return ;
5
if S = {x|x is decreasing and configuration changed } =
6  then
6
v := a variable in S with the greatest score, breaking ties by preferring the one
with the greatest hscore2 ;
7
else
8
update clause weights according to PAWS;
9
pick a random falsified clause C;
10
v := a variable in C with the greatest hscore;
11
12
13

 :=  with v flipped;
return unknown;
end

#stepsbt
#stepsccd
#stepsbt
#stepsccd

4-SAT
218465135
317682739
68%

5-SAT
514417498
849513823
60%

6-SAT
198497368
404629074
49%

7-SAT
17260095
43678889
38%

Table 8: Averaged number of CCD steps and hscore2 -based tie-breaking steps, as well as their
averaged ratio for each k-SAT with k  {4, 5, 6, 7} in the threshold benchmark from SAT
Competition 2013.

4.2 Evaluations of HScoreSAT on Threshold Instances
In this subsection, we carry out extensive experiments to evaluate HScoreSAT on random k-SAT
instances with k  {4, 5, 6, 7} at phase transition. First, we compare HScoreSAT with CScoreSAT
as well as state-of-the-art SLS solvers on the random benchmark at the threshold of phase transition
from SAT Competition 2013. Then, we compare HScoreSAT with state-of-the-art SLS solvers on
large-sized random k-SAT (k  {4, 5, 6, 7}) instances generated randomly at the threshold of phase
transition.
4.2.1 B ENCHMARK

AND

E XPERIMENT P RELIMINARIES

In the experiments in this section, all benchmark instances are generated according to the random
k-SAT model at the threshold ratio of the solubility phase transition. These instances have a clauseto-variable ratio equal to the conjectured threshold ratio of the solubility phase transition2 (Mertens,
Mzard, & Zecchina, 2006). Specifically, we adopt the following two benchmarks.
2. The clause-to-variable ratio for which 50% of the uniform random formulas are satisfiable. For most algorithms, the
closer a formula is generated near the threshold ratio, the harder it is to solve it.

429

fiC AI , L UO & S U

1. Threshold Comp13: the threshold benchmark from the random satisfiable category of SAT
Competition 2013. For each k-SAT, the instances have various sizes. We also note that
no filtering was applied to construct the competition suite. As a consequence, a significant
fraction (approximately 50%) of the generated threshold instances is unsatisfiable. The details
of the benchmark are given in Table 9.
2. Large-sized Threshold: random k-SAT instances at the threshold ratio of phase transition,
generated randomly by the random k-SAT generator3 used in SAT Competition 2013. This
benchmark contains 400 instances, 100 for each k-SAT class with k  {4, 5, 6, 7}. The sizes
of instances in this benchmark (n = 2000, 550, 250, 150 for k = 4, 5, 6, 7, respectively) are
relatively large compared to those in the Threshold Comp13 benchmark. These instances are
evenly divided into two categories: the training set and test set, both of which
have 50 instances for each k-SAT class.
Note that the training set is only used to tune the parameters in HScoreSAT, and then
HScoreSAT with the tuned parameter setting is evaluated on Threshold Comp13 benchmark and the
test set in Large-sized Threshold benchmark.
4-SAT
5-SAT
6-SAT
7-SAT
#inst.
50
50
50
50
ratio
9.931
21.117
43.37
87.79
size n  {830, 860, ..., 2300} n  {305, 310, ..., 550} n  {191, 192, ..., 240} n  {91, 92, ..., 140}

Table 9: The instance numbers, ratios and sizes for each k-SAT with k  {4, 5, 6, 7} in the
Threshold Comp13 benchmark.

HScoreSAT is implemented on the basis of CScoreSAT source code and complied by g++ with
the -O2 option. The parameter setting of HScoreSAT is presented in Table 10, which are tuned
based on the training set of the Large-sized Threshold benchmark. We compare HScoreSAT
with CScoreSAT, as well as three other state-of-the-art SLS solvers, including CCASat, probSAT
(version 2013) and Sattime2013. Especially, we note that probSAT and Sattime2013 are the top
two solvers in the random SAT track in SAT Competition 2013.
parameter
sp
d



4-SAT
0.75
9
50
500

5-SAT
0.75
8
100
500

6-SAT
0.92
7
500
500

7-SAT
0.9
6
500
500

Table 10: Parameter setting of HScoreSAT
The computing environments for these experiments are the same as those used for experiments
in Section 3. Following the experiment setup in SAT Competition 2013, we perform each solver
one run on each instance, where each run terminates upon either finding a satisfying assignment or
reaching a given cutoff time which is set to 5000 seconds. We report the number of solved instances
3. http://sourceforge.net/projects/ksatgenerator/

430

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Instance
Class
4-SAT
(r = 9.931)
5-SAT
(r = 21.117)
6-SAT
(r = 43.37)
7-SAT
(r = 87.79)
Over All

CCASat
#solved
par10
10
40168
9
41117
15
35435
23
27308
57
36007

Sattime2013
#solved
par10
8
42174
9
41153
18
31445
26
24351
61
35006

probSAT
#solved
par10
13
37160
10
40185
15
35440
23
27363
61
35037

CScoreSAT
#solved
par10
9
41193
8
42176
13
37211
21
29189
51
37442

HScoreSAT
#solved
par10
14
36176
11
39296
19
31538
25
25275
69
33071

Table 11: Experimental results on Threshold Comp13 benchmark. Each instance class contains
50 instances and each solver is executed once on each instance with a cutoff time of 5000
seconds.

(#solved) and PAR10 for each k-SAT class and the whole benchmark (as in the competition). The
rules at SAT competitions establish that the winner is the solver which solves the most instances,
and ties are broken by selecting the solver with the minimum PAR10.
4.2.2 E XPERIMENTAL R ESULTS

ON

T HRESHOLD B ENCHMARK

In the following, we present the comparative experimental results of HScoreSAT and its competitors
on each benchmark.
Results on Threshold Comp13 Benchmark:
Table 11 presents the experimental results of HScoreSAT and its competitors on random kSAT instances at phase transition from SAT Competition 20134 . Since HScoreSAT is based on
CScoreSAT, we first compare these two solvers. As shown in Table 11, HSocreSAT solves more
instances than CScoreSAT on all instance classes. Overall, CScoreSAT solves 51 instances, while
HScoreSAT solves 69 instances, which is 1.35 times as many as CScoreSAT does.
HScoreSAT solves a few more instances than probSAT and Sattime2013. Overall, HScoreSAT
solves 69 instances, compared to 61 for both probSAT and Sattime2013 and 57 for CCASat. Further
observation shows that, HScoreSAT has similar performance with probSAT on random 4-SAT and
5-SAT instances, and has similar performance with Sattime2013 on 6-SAT and 7-SAT instances.
Results on Large-sized Threshold Benchmark:
To mesure the performance of HScoreSAT on random phase-transition k-SAT instances more
accurately, we additionally test HScoreSAT on the test set of the Large-sized Threshold
benchmark, compared with Sattime2013 and probSAT, which are the top two solvers in the random
SAT track in SAT Competition 2013.
4. It seems that our machine is slightly slower than the ones used in SAT Competition 2013, as Sattime2013, probSAT
and CScoreSAT all solved slightly fewer instances in our experiment than they did in the competition. CCASat did
not participate in SAT Competition 2013.

431

fiC AI , L UO & S U

The results are presented in Table 12. For 4-SAT class, HScoreSAT and probSAT solve the
same number of instances, but HScoreSAT has less accumulative run time. For 5-SAT and 6SAT classes, HScoreSAT solves the most instances. Particularly, HScoreSAT shows significantly
superior performance than other solvers on 6-SAT class, where it solves 9 instances, while
Sattime2013 and probSAT both solve 4 instances. The only instance class for which HScoreSAT
does not give the best performance is 7-SAT. Nevertheless, on this instance class, HScreSAT has
similar performance as the best solver Sattime2013, solving only one less instance. For the whole
benchmark, HScoreSAT solves 40 instances, compared to 26 and 28 instances for Sattime2013 and
probSAT.
Instance
Class
4-SAT-v2000
(r = 9.931)
5-SAT-v550
(r = 21.117)
6-SAT-v300
(r = 43.37)
7-SAT-v150
(r = 87.79)
Over All

Sattime2013
#solved
par10
0
n/a
8
42147
4
46120
14
36433
26
43675

probSAT
#solved
par10
8
42197
9
41262
4
46132
7
43248
28
43209

HScoreSAT
#solved
par10
8
42181
10
40130
9
41523
13
37091
40
40231

Table 12: Experimental results on the Large-size Threshold benchmark. Each instance class
contains 50 instances and each solver is executed once on each instance with a cutoff
time of 5000 seconds.

4.3 Experimental Analyses of the hscore2 Function
To demonstrate the effectiveness of the hscore2 function, we test two alternative versions
of HScoreSAT. These two algorithms are different from HScoreSAT only in the tie-breaking
mechanism in the greedy mode.
 HScoreSAT1 breaks ties in the greedy mode by preferring the variable with the greatest
score2 ;
 HScoreSAT2 breaks ties in the greedy mode by preferring the variable with the greatest age.
The comparative results of HScoreSAT and its two alternative versions are displayed in Table
13. It is clear from the table that HScoreSAT has superior performance than both its alternatives
on all instance classes. More careful observations show that for 4-SAT and 5-SAT instances, the
performance of HScoreSAT2 and HScoreSAT are similar, which are significantly better than that of
HScoreSAT1 . This indicates that the age property is more suitable than score2 as a tie-breaker for 4SAT and 5-SAT, and is almost as good as the hscore2 for tie-breaking. In contrast, the performance
432

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Instance
Class
4-SAT
(r = 9.931)
5-SAT
(r = 21.117)
6-SAT
(r = 43.37)
7-SAT
(r = 87.79)
Over All

HScoreSAT1
#solved
par10
5
45062
7
43136
16
34255
24
26328
52
37195

HScoreSAT2
#solved
par10
13
37242
10
40293
16
34371
22
28128
61
35008

HScoreSAT
#solved
par10
14
36176
11
39296
19
31538
25
25275
69
33071

Table 13: Comparative results of HScoreSAT and its two alternative solvers on the Threshold
Comp13 benchmark. Each solver is executed one time on each instance, with a cutoff
time of 5000 seconds.

of HScoreSAT1 and HScoreSAT on 7-SAT are similar, which are better than that of HScoreSAT2 .
This indicates that score2 is more suitable than age as a tie-breaker for 7-SAT. Indeed, it is from this
experimental analysis that we gain the intuition to set  in the hscore2 function to be a relatively
small value for 4-SAT and 5-SAT instances, and a relatively large value for 7-SAT. However, for
6-SAT, both alternatives cannot achieve performance close to that of HScoreSAT.
4.4 Evaluation on Huge Random k-SAT in SAT Competition 2013
In the random SAT category of SAT Competition 2013, there are two kinds of instances. Besides
the instances at phase-transition threshold, there are also instances whose ratios are not that close
to phase transition while at the same time they have huge sizes. In this subsection, we conduct
experiments to evaluate the performance of our solvers on these huge instances, compared with
state-of-the-art solvers.
The experimental results are presented in Table 14, which show that CScoreSAT is clearly the
best solver on this benchmark of huge instances. CScoreSAT gives the best performance for all
k-SAT instance classes except for 4-SAT, and especially it solves more 6-SAT and 7-SAT instances
than all other solvers. For 4-SAT, CScoreSAT solves as many instances as probSAT but the PAR10
is a little more than probSATs. These experimental results confirm the good performance of
CScoreSAT on the huge benchmark in SAT Competition 2013, where it also solved more huge
instances than probSAT and Sattime2013.
4.5 Boundary Ratios for Performance of CScoreSAT and HScoreSAT
As we mentioned before, CScoreSAT has good performance on solving random k-SAT (k > 3)
instances at some ratios near the phase-transition threshold, such as the ratios of large random
instances in SAT Competition 2011. On the other hand, HScoreSAT is improved from CScoreSAT
for solving random k-SAT (k > 3) instances at the phase-transition threshold. Thus, we conjecture
433

fiC AI , L UO & S U

Instance
Class
4-SAT-v500000
(r  [7.0, 9.5])
5-SAT-v250000
(r  [15.0, 20.0])
6-SAT-v100000
(r  [30.0, 40.0])
7-SAT-v50000
(r  [60.0, 85.0])
Over All

CCASat
#solved
par10
4
17017
3
25106
2
33386
1
41693
10
29300

Sattime2013
#solved
par10
3
25205
2
33502
2
33710
1
41963
8
33595

probSAT
#solved
par10
5
8385
4
16710
2
33338
1
41669
12
25026

CScoreSAT
#solved
par10
5
9096
4
16535
3
25200
2
34167
14
21249

HScoreSAT
#solved
par10
5
9418
3
25116
2
33376
1
41683
11
27398

Table 14: Experimental results on huge random k-SAT (k > 3) instances from SAT
Competition 2013. Each instance class contains 6 instances and each solver is executed
once on each instance with a cutoff time of 5000 seconds.

there exists a boundary ratio for each k-SAT, beyond which HScoreSAT outperforms CScoreSAT.
This subsection is dedicated to finding these boundary ratios through experiments.
Our experiment is carried out on SAT Challenge 2012 benchmark, where each k-SAT has 10
different ratios and there are 12 instances for each ratio. Details of the bechmark can be found in
its benchmark description. We run CScoreSAT and HScoreSAT one time on each instance with a
cutoff time of 1000 seconds, and compare the performance of the two solvers at each ratio.
The comparison results are presented in Table 15. The results suggest that there exists a
boundary ratio r , beyond which HScoreSAT gives better performance than CScoreSAT. This is
especially clear for 4-, 5- and 7-SAT, while not so clear for 6-SAT as HScoreSAT solves more
instances than CScoreSAT at all rations which are not smaller than 42.359 except for one ratio
r = 42.696, where CScoreSAT solves one more instance. To check whether this result is just an
outlier due to a single instance, we conduct an additional experiment to execute both solvers 10
times on each instance at r = 42.696. The experimental results show that the two solvers have very
close performance  HScoreSAT succeeds in 84 runs while CScoreSAT succeeds in 83 runs. We

 , r
give the conjectured interval (rmin
max ) of the boundary ratio r for each k-SAT in Table 16.
These results suggest that, a hybrid solver combining CScoreSAT and HScoreSAT would
have good performance on k-SAT instances with long clauses at different ratios. However, both
CScoreSAT and HScoreSAT have poor performance on random 3-SAT instances. Hence, these
two solvers or their hybrid solver did not participate in SAT Competition 2014, as the competition
requires a participating solver to be a core solver which can have at most two different solvers.
Instead, we develop a solver called CSCCSat, which combines two solvers namely FrwCB (for
large sized instances) (Luo et al., 2014) and DCCASat (for threshold instances) (Luo et al., 2014).
Note that DCCASat is improved from HScoreSAT by using the double configuration checking
heuristic, and it also uses the hscore and hscore2 functions for random k-SAT with k > 3. In SAT
Competition 2014, CSCCSat won the bronze medal of random SAT track, and especially it gives
the best performance for threshold instances, indicating the effectiveness of our scoring functions.
434

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

4-SAT
r=9
4-SAT
r=9.121
4-SAT
r=9.223
4-SAT
r=9.324
4-SAT
r=9.425
4-SAT
r=9.526
4-SAT
r=9.627
4-SAT
r=9.729
4-SAT
r=9.83
4-SAT
r=9.931

CScoreSAT
HScoreSAT
4.8(12)
6.5(12)
9.7(12)
10.8(12)
11.6(12)
18.6(12)
19.1(12)
29.1(12)
42.7(12)
63.8(12)
66.5(12)
72.2(12)
133(12)
192(12)
243(12)
212(12)
1252(11)
344(12)
149(12)
118(12)

5-SAT
r=20
5-SAT
r=20.155
5-SAT
r=20.275
5-SAT
r=20.395
5-SAT
r=20.516
5-SAT
r=20.636
5-SAT
r=20.756
5-SAT
r=20.876
5-SAT
r=20.997
5-SAT
r=21.117

CScoreSAT
HScoreSAT
222(12)
1060(11)
271(12)
2022(10)
1918(10)
3471(8)
2935(9)
6025(5)
6108(5)
7647(3)
4363(7)
6003(5)
3468(8)
4452(7)
5118(6)
3051(8)
5100(6)
4436(7)
2522(9)
1772(10)

6-SAT
r=40
6-SAT
r=40.674
6-SAT
r=41.011
6-SAT
r=41.348
6-SAT
r=41.685
6-SAT
r=42.022
6-SAT
r=42.359
6-SAT
r=42.696
6-SAT
r=43.033
6-SAT
r=43.37

CScoreSAT
HScoreSAT
4.1(12)
11.5(12)
8.6(12)
36.3(12)
29.1(12)
52.3(12)
76.6(12)
98.4(12)
83(12)
1827(10)
31(12)
1928(10)
1003(11)
227(12)
2757(9)
3528(8)
4418(7)
3647(8)
939(11)
165(12)

7-SAT
r=85
7-SAT
r=85.558
7-SAT
r=85.837
7-SAT
r=86.116
7-SAT
r=86.395
7-SAT
r=86.674
7-SAT
r=86.953
7-SAT
r=87.232
7-SAT
r=87.511
7-SAT
r=87.79

CScoreSAT
HScoreSAT
4345(7)
8346(2)
2767(9)
6773(4)
2666(9)
5065(6)
3435(8)
4296(7)
1902(10)
2797(9)
3499(8)
4340(7)
3415(8)
2646(9)
150(12)
135(12)
2589(9)
1054(11)
899(11)
74(12)

Table 15: Comparing CScoreSAT and HScoreSAT at each ratio of random k-SAT (k > 3) in SAT
Challenge 2012 benchmark. Each solver is executed one time on each instance, with a cutoff
time of 1000 seconds. Each cell reports the result of CScoreSAT in the upper row and that of
HScoreSAT in the lower row, in the form of par10(#solved). We color the ratios gray at which
HScoreSAT performs better than CScoreSAT. Note that for 6-SAT at r = 42.696 where the results
seem a little odd, we conduct an additional experiment executing both solvers 10 times on each
instance, and HScoreSAT succeeds in 84 runs while CScoreSAT succeeds in 83 runs.

 , r
(rmin
max )

4-SAT
(9.627,9.729)

5-SAT
(20.756,20.876)

6-SAT
(42.022,42.359)

7-SAT
(86.674,86.953)

Table 16: The conjectured interval of the boundary ratio r . HScoreSAT has worse performance
 , and has better (or at least competitive) performance
than CScoreSAT at ratios r  rmin

at ratios r  rmax
, based on experiments on the SAT Challenge 2012 benchmark.

5. On Computation of score2
For algorithms employing scoring functions based on score2 , such as CScoreSAT and HScoreSAT,
the computation of score2 has a considerable impact on their efficiency. In this section,
we investigate the computation issues of score2 . Particularly, we propose a cache-based
implementation and analyze its time complexity in each flip. We also measure its overhead in
the two algorithms through experiments.
435

fiC AI , L UO & S U

5.1 Implementation and Complexity of Computing score2
We propose a caching implementation for computing variables score2 values, which is inspired
by the caching implementation for computing variable scores. Typically, not all variable scores (or
score2 values) change after each search step; this suggests that rather than recomputing all variable
scores (or score2 values) in each step, it should be more efficient to compute all scores (or score2
values) when the search is initialized, but to subsequently only update the scores (or score2 values)
affected by a variable that has been flipped (Hoos & Sttzle, 2004).
In our caching implementation, the score2 values of all variables are computed when the search
is initialized, and are subsequently updated in each flip. The initialized computation of score2 is
straightforward according to the definition of score2 and will not be discussed. Comparatively, the
procedure of updating score2 values are of much more interest.
To facilitate describing the procedure of updating score2 values and analyzing its time
complexity, we first introduce some notations and definitions below.
Given a CNF formula F ,
 for a variable x  V (F ), CL(x) = {c|c is a clause in F and x appears in c};
 for a clause c  F , c.num_true_lit is the number of true literals in c;
 for a clause c  F with exactly two true literals, we use true_lit_var(c) and true_lit_var2(c) to
record the two corresponding variables of the two true literals in c (these two notations will
only be used in pseudo-code for the sake of formalization);
 we use x to denote the variable flipped in the current step;
 n, m, k, r is the number of variables, the number of clauses, the maximum clause length, and
the clause-to-variable ratio.
Definition 5. Given a clause c and a variable x, we say the contribution of clause c to score2 (x) is
+1 if flipping x would cause c transform from 1-satisfied to 2-satisfied, -1 if flipping x would cause
c transform from 2-satisfied to 1-satisfied, and 0 otherwise.
A useful observation is that for a variable x  V (F ), score2 (x) equals the sum of contributions
of all clauses to it. Also, it is obvious that clauses in which x does not appear always contribute 0
to score2 (x).
Now we describe in detail the procedure of updating score2 values in each flip, whose pseudocode is shown in Algorithm 3. After flipping x , according to the definition of score2 , score2 (x )
just changes to its opposite number (lines 1 and 21). The essential part is updating score2 values for
variables that share clauses with x (since other variables would not change their score2 values),
which is accomplished with a loop (lines 2-20). In each iteration of the loop, a clause c  CL(x ) is
considered and necessary updates are performed, according to two different cases: either the literal
of x in c becomes a true literal, or not. Here we explain the updates for the first case, and those for
the other case can be understood similarly.
In the first case (i.e., the literal of x in c becomes a true literal), along with the flip of x ,
c.num_true_lit is increased by 1. Suppose c.num_true_lit changes from t  1 to t. If neither t  1
nor t is 1 or 2, then flipping x causes no change to any variables score2 (easy to see from the
definition of score2 ). So, we only need to consider the following three cases.
436

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Algorithm 3: updating score2 values in a flip step
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21

org_score2 (x ) := score2 (x );
for each c  CL(x ) do
if the literal of x in c becomes a true literal then
c.num_true_lit+=1;
if c.num_true_lit=3 then
score2 (true_lit_var(c))+=1;
score2 (true_lit_var2(c))+=1;
else if c.num_true_lit=2 then
for each xi  c do score2 (xi )=1;
else if c.num_true_lit=1 then
for each xi  c do score2 (xi )+=1;
else
c.num_true_lit=1;
if c.num_true_lit=2 then
score2 (true_lit_var(c))=1;
score2 (true_lit_var2(c))=1;
else if c.num_true_lit=1 then
for each xi  c do score2 (xi )+=1;
else if c.num_true_lit=0 then
for each xi  c do score2 (xi )=1;
score2 (x ) := org_score2 (x );

 c.num_true_lit changes from 2 to 3: Before flipping x , c had two true literals, and let us
denote their corresponding variables as y1 and y2 . The contributions of c to score2 (y1 ) and
score2 (y2 ) were both -1 before flipping x . After flipping x , c becomes a 3-satisfied clause,
and the contributions of c to score2 (y1 ) and score2 (y2 ) both become 0. Hence, along with
flipping x , the changes on score2 (y1 ) and score2 (y2 ) are both 0-(-1)=+1 (lines 6-7). For
other variables in c, either before or after the flip of x , the contributions of c to their score2
values are 0.
 c.num_true_lit changes from 1 to 2: Before flipping x , c had only one true literal, and let
us denote its corresponding variable as y1 . The contribution of c to score2 (y1 ) was 0 before
flipping x , but becomes -1 after flipping x , indicating a change of -1 on score2 (y1 ). For
other variables in c (except x ), the contributions of c to their score2 values were +1 before
flipping x , but become 0 after flipping x , indicating a change of -1 on their score2 values.
Therefore, for all variables in c (except x ), along with flipping x , the changes on their
score2 values are -1 (lines 8-9).
Note that we include x in the loop (line 9) just in order to save computational consumption.
As we have a special update for score2 (x ), any change on score2 (x ) between line 1 and
line 21 has no impact in effect.
437

fiC AI , L UO & S U

 c.num_true_lit changes from 0 to 1: Before flipping x , for all variables in c, the contributions
of c to their score2 values were 0. After flipping x , c becomes 1-satisfied (the true literals
corresponding variable is x ), and for all variables in c (except x ), the contributions of c
to their score2 values become +1. Therefore, for all variables in c (except x ), along with
flipping x , the changes on their score2 values are +1 (lines 10-11).
The complexity of the score2 updating procedure in each flip is determined by the main loop
(lines 2-20). When flipping a variable x, there are |CL(x)| items in the main loop, and in each
iteration there are three possible cases, where the first case requires only 2 operations5 and the latter
two require (k) operations. Therefore, the worst-case time complexity of the score2 updating
procedure in each flip is (maxxV (F ) |CL(x)|  max{2, k, k})=(maxxV (F ) |CL(x)|  k).
For uniform random k-SAT formulas with clause-to-variable ratio r, there are totally m  k
literals and each variable is expected to have mk/n = kr literals. That is, each variable x  V (F )
is expected to appear in kr clauses (when n approaches to +, this is true with probability almost
1), i.e., |CL(x)|  kr. Therefore, the complexity of the score2 updating procedure in each flip
becomes (kr  k) = (k 2 r).
Fortunately, for uniform random k-SAT formulas with constant ratio r, both k and r are
constants. Therefore, independent of instance size, this implementation of score2 computation
achieves a time complexity of (1) for each search step, just as the caching implementation of
score computation does (referring to pages 272-273 in (Hoos & Sttzle, 2004)).
5.2 Computational Overhead of Computing score2
In this subsection, we study the computational overhead of computing score2 in CScoreSAT and
HScoreSAT. We carry out experiments with the Threshold Comp13 benchmark to figure out the
CPU time per 107 steps for computing score2 and its percentage in the total CPU time of the solver
per 107 steps.

CScoreSAT
computing score2
percentage
HScoreSAT
computing score2
percentage

4-SAT
13.9
1.6
11.5%
14.3
1.6
11.2%

5-SAT
28.5
8.0
28.1%
28.7
8.4
29.3%

6-SAT
52.4
17.9
34.2%
53.2
17.8
33.5%

7-SAT
94.6
37.1
39.2%
95.1
36.9
38.8%

Table 17: CPU time consumption (in seconds) per 107 steps for CScoreSAT and HscoreSAT, and
for computing score2 , as well as their ratios. The results are averaged over all instances
in the Threshold Comp13 benchmark.
Our investigation shows that the overhead of computing score2 occupies a considerable
percentage of the solvers whole run time, ranging from 11% to 40%. Nevertheless, since score2 is
critical to the solvers, this price indeed pays off. Further observation reveals that more than 90% of
5. note that true_lit_var(c) and true_lit_var2(c) are recorded initially for accelerating updating variable scores, and thus
we do not need extra price to maintain them for score2 updates.

438

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

the solvers run time are due to the flip function, where two most costly parts are score and score2
updates. Another interesting phenomenon is that the percentage of overhead caused by score2
computation rises as the clause length increases, although score2 is less used (for tie-breaking) for
longer clauses (see Table 8). The reason might be that as the clause length increases, the portion of
variables whose score2 values need to be updated is increasing compared to that of variables whose
scores need to be updated.

6. Summary and Future Work
In this paper, we proposed three new scoring functions based on score2 for improving SLS
algorithms on random SAT instances with long clauses. Despite their simplicity, the proposed
scoring functions are very effective, and the resulting SLS algorithms namely CScoreSAT and
HscoreSAT show excellent performance on random k-SAT instances with long clauses.
First, we combined the score and score2 properties to design a scoring function named cscore
(comprehensive score), which aims to improve the greedy mode by combining greediness and lookahead greediness. We also defined comprehensively decreasing variables accordingly. We further
proposed the hscore function combining cscore with the diversification age, which is devoted
to improving the diversification mode. These two scoring functions were used to develop the
CScoreSAT algorithm. The experiments show that the performance of CScoreSAT exceeds that of
state-of-the-art SLS solvers by orders of magnitudes on large random 5-SAT and 7-SAT instances
near phase transition. Moreover, CScoreSAT significantly outperforms its competitors on random
k-SAT instances with various ratios for each k  {4, 5, 6, 7} from SAT Challenge 2012.
To improve CScoreSAT for solving random k-SAT instances at the threshold ratio of phase
transition, we propose another scoring function called hscore2 , which combines score2 and age.
By using hscore2 to break ties and adjust the greedy mode accordingly, we obtain the HScoreSAT
algorithm. Experiments on random k-SAT instances at phase-transition threshold show that
HScoreSAT significantly improves CScoreSAT and outperforms state-of-the-art SLS algorithms.
Finally, as the score2 property is a key notion in our algorithms, we also present the
implementation details of score2 computation, and analyze its complexity per flip and its
computational overhead.
As for future work, a significant research issue is to improve SLS algorithms for structured
instances by score2 -based scoring functions. Furthermore, the notions in this work are so simple
that they can be easily applied to other problems, such as constrained satisfaction and graph search
problems.

Acknowledgement
This work is supported by China National 973 Program 2010CB328103 and 2014CB340301,
National Natural Science Foundation of China 61370072 and 61472369, and ARC Grant
FT0991785. We would like to thank the anonymous referees for their helpful comments on the
earlier versions of this paper, which significantly improve the quality of this paper.
439

fiC AI , L UO & S U

References
Abram, A., Habet, D., & Toumi, D. (2014). Improving configuration checking for satisfiable
random k-SAT instances. In Proc. of ISAIM-14.
Achlioptas, D. (2009). Random satisfiability. In Handbook of Satisfiability, pp. 245270.
Balint, A., Biere, A., Frhlich, A., & Schning, U. (2014). Improving implementation of SLS
solvers for SAT and new heuristics for k-sat with long clauses. In Proc. of SAT-14, pp. 302
316.
Balint, A., & Frhlich, A. (2010). Improving stochastic local search for SAT with a new probability
distribution. In Proc. of SAT-10, pp. 1015.
Balint, A., & Schning, U. (2012). Choosing probability distributions for stochastic local search
and the role of make versus break. In Proc. of SAT-12, pp. 1629.
Braunstein, A., Mzard, M., & Zecchina, R. (2005). Survey propagation: An algorithm for
satisfiability. Random Struct. Algorithms, 27(2), 201226.
Cai, S., & Su, K. (2012). Configuration checking with aspiration in local search for SAT. In Proc.
of AAAI-12, pp. 334340.
Cai, S., & Su, K. (2013a). Comprehensive score: Towards efficient local search for SAT with long
clauses. In Proc. of IJCAI-13, pp. 489495.
Cai, S., & Su, K. (2013b). Local search for Boolean Satisfiability with configuration checking and
subscore. Artif. Intell., 204, 7598.
Cai, S., Su, K., & Luo, C. (2013a). Improving walksat for random k-satisfiability problem with k >
3. In Proc. of AAAI-13, pp. 145151.
Cai, S., Su, K., Luo, C., & Sattar, A. (2013b). NuMVC: An efficient local search algorithm for
minimum vertex cover. J. Artif. Intell. Res. (JAIR), 46, 687716.
Cai, S., Su, K., & Sattar, A. (2011). Local search with edge weighting and configuration checking
heuristics for minimum vertex cover. Artif. Intell., 175(9-10), 16721696.
Chieu, H. L., & Lee, W. S. (2009). Relaxed survey propagation for the weighted maximum
satisfiability problem. J. Artif. Intell. Res. (JAIR), 36, 229266.
Gent, I. P., & Walsh, T. (1993). Towards an understanding of hill-climbing procedures for SAT. In
Proc. of AAAI-93, pp. 2833.
Hoos, H. H., & Sttzle, T. (2004). Stochastic Local Search: Foundations & Applications. Elsevier
/ Morgan Kaufmann.
KhudaBukhsh, A. R., Xu, L., Hoos, H. H., & Leyton-Brown, K. (2009). Satenstein: Automatically
building local search SAT solvers from components. In Proc. of IJCAI-09, pp. 517524.
Kirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization by simulated annealing. Science,
220, 671680.
Kirkpatrick, S., & Selman, B. (1994). Critical behavior in the satisfiability of random boolean
formulae. Science, 264, 12971301.
Kroc, L., Sabharwal, A., & Selman, B. (2010). An empirical study of optimal noise and runtime
distributions in local search. In Proc. of SAT-10, pp. 346351.
440

fiS CORING F UNCTIONS BASED ON S ECOND L EVEL S CORE FOR k-SAT WITH L ONG C LAUSES

Li, C. M., Huang, C., & Xu, R. (2014). Balance between intensification and diversification: a unity
of opposites. In Proc. of SAT Competition 2014: Solver and Benchmark Descriptions, pp.
1011.
Li, C. M., & Huang, W. Q. (2005). Diversification and determinism in local search for satisfiability.
In Proc. of SAT-05, pp. 158172.
Li, C. M., & Li, Y. (2012). Satisfying versus falsifying in local search for satisfiability - (poster
presentation). In Proc. of SAT-12, pp. 477478.
Luo, C., Cai, S., Wu, W., Jie, Z., & Su, K. (2014). CCLS: An efficient local search algorithm for
weighted maximum satisfiability. IEEE Transactions on Computers, in press.
Luo, C., Cai, S., Wu, W., & Su, K. (2013). Focused random walk with configuration checking and
break minimum for satisfiability. In Proc. of CP-13, pp. 481496.
Luo, C., Cai, S., Wu, W., & Su, K. (2014). Double configuration checking in stochastic local search
for satisfiability. In Proc. of AAAI-14, pp. 27032709.
Luo, C., Su, K., & Cai, S. (2012). Improving local search for random 3-SAT using quantitative
configuration checking. In Proc. of ECAI-2012, pp. 570575.
Mertens, S., Mzard, M., & Zecchina, R. (2006). Threshold values of random k-SAT from the cavity
method. Random Struct. Algorithms, 28(3), 340373.
Mzard, M. (2003). Passing messages between disciplines. Science, 301, 16851686.
Pham, D. N., Thornton, J., Gretton, C., & Sattar, A. (2007). Advances in local search for
satisfiability. In Australian Conference on Artificial Intelligence, pp. 213222.
Prestwich, S. D. (2005). Random walk with continuously smoothed variable weights. In Proc. of
SAT-05, pp. 203215.
Selman, B., Kautz, H. A., & Cohen, B. (1994). Noise strategies for improving local search. In Proc.
of AAAI-94, pp. 337343.
Thornton, J., Pham, D. N., Bain, S., & Ferreira Jr., V. (2004). Additive versus multiplicative clause
weighting for SAT. In Proc. of AAAI-04, pp. 191196.
Tompkins, D. A. D., Balint, A., & Hoos, H. H. (2011). Captain jack: New variable selection
heuristics in local search for SAT. In Proc. of SAT-11, pp. 302316.
Tompkins, D. A. D., & Hoos, H. H. (2010). Dynamic scoring functions with variable expressions:
New SLS methods for solving SAT. In Proc. of SAT-10, pp. 278292.
Xu, L., Hutter, F., Hoos, H. H., & Leyton-Brown, K. (2008). SATzilla: Portfolio-based algorithm
selection for SAT. J. Artif. Intell. Res. (JAIR), 32, 565606.

441

fiJournal of Artificial Intelligence Research 51 (2014) 555-577

Submitted 05/14; published 11/14

Iterative Plan Construction for the Workflow Satisfiability Problem
David Cohen
Jason Crampton
Andrei Gagarin
Gregory Gutin
Mark Jones

D.C OHEN @ RHUL . AC . UK
JASON .C RAMPTON @ RHUL . AC . UK
A NDREI .G AGARIN @ RHUL . AC . UK
G.G UTIN @ RHUL . AC . UK
M ARK .J ONES @ RHUL . AC . UK

Royal Holloway, University of London, UK

Abstract
The Workflow Satisfiability Problem (WSP) is a problem of practical interest that arises whenever tasks need to be performed by authorized users, subject to constraints defined by business
rules. We are required to decide whether there exists a plan  an assignment of tasks to authorized
users  such that all constraints are satisfied. It is natural to see the WSP as a subclass of the
Constraint Satisfaction Problem (CSP) in which the variables are tasks and the domain is the set
of users. What makes the WSP distinctive is that the number of tasks is usually very small compared to the number of users, so it is appropriate to ask for which constraint languages the WSP is
fixed-parameter tractable (FPT), parameterized by the number of tasks.
This novel approach to the WSP, using techniques from CSP, has enabled us to design a generic
algorithm which is FPT for several families of workflow constraints considered in the literature.
Furthermore, we prove that the union of FPT languages remains FPT if they satisfy a simple compatibility condition. Lastly, we identify a new FPT constraint language, user-independent constraints, that includes many of the constraints of interest in business processing systems. We
demonstrate that our generic algorithm has provably optimal running time O (2k log k ), for this
language, where k is the number of tasks.

1. Introduction
A workflow formalises a business process. It is a collection of interrelated tasks that are performed
by users in order to achieve some objective. In many situations, we wish to restrict the users that
can perform certain tasks. In particular, we may wish to specify lists of users who are authorized to
perform each of the workflow tasks. Additionally, we may wish  either because of the particular
requirements of the business logic or security requirements  to prevent certain combinations of
users from performing particular combinations of tasks (Crampton, 2005). Such constraints include
separation-of-duty (also known as the two-man rule), which may be used to prevent sensitive
combinations of tasks being performed by a single user, and binding-of-duty, which requires that a
particular combination of tasks is executed by the same user. The use of constraints in workflow
management systems to enforce security policies has been studied extensively in the last fifteen
years; for example see the work of Bertino, Ferrari, and Atluri (1999), Crampton (2005) or Wang
and Li (2010).
1.1 The Workflow Satisfiability Problem
It is possible that the combination of constraints and authorization lists is unsatisfiable, in the
sense that there does not exist an assignment of users to tasks such that all contraints are satisfied
c
2014
AI Access Foundation. All rights reserved.

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

and every task is performed by an authorized user; perhaps the minimal example being a requirement
that two tasks are performed by the same user but the intersection of the authorization lists for these
tasks is empty. A plan that satisfies all constraints and allocates an authorized user to each task is said
to be valid. The Workflow Satisfiability Problem (WSP) takes a workflow specification as input
and returns a valid plan if one exists and a null value otherwise. It is important to determine whether
a business process is satisfiable or not, since an unsatisfiable one can never be completed without
violating the security policy encoded by the constraints and authorization lists. Wang and Li (2010)
have shown, by a reduction from G RAPH C OLORING, that the WSP is an NP-hard subclass of the
CSP, even when we only consider binary separation-of-duty constraints. Nevertheless, for practical
applications of the WSP, we require a solving algorithm that is as efficient as possible (Crampton &
Gutin, 2013, 2.2).
Many hard problems become less complex if some natural parameter of the instance is bounded.
Hence, we say a problem with input size n and parameter k is fixed-parameter tractable (FPT) if it
admits an algorithm with running time O(f (k)nd ), where d is a constant independent of n and k,
and f is a computable function depending only on k.1
Wang and Li (2010) were the first to observe that fixed-parameter algorithmics is an appropriate
way to study the WSP, because the number of tasks is usually small and often much smaller than the
number of users. (The literature does not directly support this assumption, although a widely-cited
study, Schaad, Moffett, & Jacob, 2001, found that the number of users exceeds that of job functions,
or roles, by a multiplicative factor of around 25; this finding has been confirmed by a recent followup study, Jayaraman, Ganesh, Tripunitara, Rinard, & Chapin, 2011. A workflow specification will
usually be concerned with a particular business objective and involve a small number of roles.
Taking roles as a proxy for tasks, it seems reasonable to assume that the number of users will be an
order of magnitude greater than the number of tasks.) We believe, therefore, that it is appropriate to
extend the work initiated by Wang and Li on the use of fixed parameter algorithms for solving the
WSP parameterized by the number of tasks, and, in particular, to ask which constraint languages
are fixed parameter tractable.
Wang and Li (2010) proved that, in general, the WSP is W[1]-hard and thus is highly unlikely
to admit a fixed-parameter algorithm. They also showed that the WSP is FPT if we consider only
separation-of-duty and binding-of-duty constraints. Crampton, Gutin, and Yeo (2013) obtained significantly faster fixed-parameter algorithms that were applicable to regular constraints, thereby
including the cases shown to be FPT by Wang and Li. This work, and other recent research, has
demonstrated the existence of fixed-parameter algorithms for the WSP in the presence of other constraint types (Crampton, Crowston, Gutin, Jones, & Ramanujan, 2013; Crampton & Gutin, 2013).
We define the WSP formally and introduce a number of different constraint types, including regular
constraints, in Section 2.
We will use the O notation, which suppresses polynomial factors.
That is,
g(n, k, m) = O (h(n, k, m)) if there exists a polynomial q(n, k, m) such that g(n, k, m) =
O(q(n, k, m)h(n, k, m)). In particular, an FPT algorithm is one that runs in time O (f (k)) for
some computable function f depending only on k.

1. An introduction to fixed-parameter algorithms and complexity can be found in, for example, the books by Downey
and Fellows (2013), or Niedermeier (Niedermeier, 2006).

556

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

1.2 The Relation Between the WSP and the CSP
The Constraint Satisfaction Problem (CSP) is a general paradigm for expressing, in a declarative
format, problems where variables are to be assigned values from some domain. The assignments
are constrained by restricting the allowed simultaneous assignments to some sets of variables. This
model is useful in many application areas including planning, scheduling, frequency assignment and
circuit verification (Rossi, van Beek, & Walsh, 2006). The CSP community is a well-established
research community dedicated to finding effective solution techniques for the CSP (Dechter, 2003).
The CSP is NP-hard, even when only binary not-equals constraints are allowed and the domain
has three elements, as we can reduce G RAPH 3-C OLORING to the CSP. 2 Hence, a considerable
effort has been made to understand the effect of restricting the type of allowed constraints. Recently there has been significant progress towards the completion of this research program and
there is now strong evidence to support the algebraic dichotomy conjecture of Bulatov, Jeavons
and Krokhin (2005), characterising precisely which kinds of constraint language lead to polynomial
solvability.
It is worth noting that the WSP is a subclass of the CSP where for each variable s (called a task
in WSP terminology) we have an arbitrary unary constraint (called an authorization) that assigns
possible values (called users) for s; this is called the conservative CSP. Note, however, that while
usually in CSP the number of variables is much larger than the number of values, for the WSP the
number of tasks is usually much smaller than the number of users. It is important to remember that
for the WSP we do not use the term constraint for authorizations and so when we define special
types of constraints, we do not extend these types to authorizations, which remain arbitrary.
1.3 Outline of the Paper
Our novel approach to the WSP using techniques for the CSP, characterising types of constraints
as constraint languages with particular characteristics, enables us to generalise and unify existing
algorithms. So, in this paper, for the first time, rather than considering algorithms for specific
constraints, we design a generic algorithm which is a fixed-parameter algorithm for several families
of workflow constraints considered in the literature. In particular we introduce the notions of userindependent constraints, which subsume a number of well-studied constraint types from the WSP
literature, including the regular constraints studied by Crampton et al. (2013).
Our generic algorithm builds plans incrementally, discarding partial plans that can never satisfy
the constraints. It is based on a naive algorithm, presented in Section 2.2. This naive algorithm
stores far more information than is required to solve the WSP, so its running time is no better than
exhaustively searching for a valid plan.
Our generic algorithm uses a general and classic paradigm: retain as little information as possible in every step of the algorithm. This paradigm is used in such classical polynomial-time algorithms as Gaussian elimination for solving systems of linear equations and constraint propagation
algorithms (used, for example, to solve 2SAT in polynomial time). Our generic algorithm uses
this paradigm in a problem-specific way, based on the concepts of extension-equivalence, planindistinguishability and patterns, enabling us to retain a single pattern for each equivalence class of
indistinguishable plans. Extension-equivalence and plan encodings are described in Section 3. The
way the solution is constructed by our algorithm is quite unusual because the accumulation of the
2. Wang and Lis NP-hardness result for the WSP is thus a restatement of this well-known result for CSP.

557

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

(representatives of) set of solutions goes along the users (i.e., values for CSP), not along the tasks
(i.e., variables for CSP).
To analyze the running time of our algorithm we introduce the notion of diversity (see Definition 6). This notion is reminiscent of pathwidth (measures are taken over all prefixes and the largest
outcome is the diversity) with the difference that the diversity is based on the number of equivalence classes, hiding the actual structure behind the scenes. This approach might also be useful for
structural analysis of hypergraphs.
In Section 4, we describe our pattern-based algorithm and demonstrate that it is a fixedparameter algorithm for the WSP with user-independent constraints. We show the running time
of our algorithm is O (2k log k ) for the WSP with user-independent constraints and that there is
no algorithm of running time O (2o(k log k) ) for the WSP with user-independent constraints unless
the Exponential Time Hypothesis3 (ETH) fails. Thus, unlike the WSP with regular constraints
(and problems studied by Bodlaender, Cygan, Kratsch, & Nederlof, 2013; Fomin, Lokshtanov, &
Saurabh, 2014), the WSP with user-independent constraints is highly unlikely to admit an algorithm
of running time O (2O(k) ). To show that our generic algorithm is of interest for constraints other
than user-independent, we prove that the generic algorithm is a single-exponential algorithm for a
constraint language obtained by an equivalence relation on the set of users.
In Section 5 we show how our generic algorithm can deal with unions of constraint languages.
This leads to a generalisation of our result for user-independent constraints. In Section 6 we discuss
the results of computational experiments using an implementation of our algorithm (discussed in
full detail in the work of Cohen, Crampton, Gagarin, Gutin, & Jones, 2014). A brief conclusion is
given in in Section 7.

2. Background
We define a workflow schema to be a tuple (S, U, A, C), where S is the set of tasks in the workflow,
U is the set of users, A = {A(s) : s  S}, where A(s)  U is the authorization list for task s, and
C is a set of workflow constraints. A workflow constraint is a pair c = (L, ), where L  S and 
is a set of functions from L to U : L is the scope of the constraint;  specifies those assignments of
elements of U to elements of L that satisfy the constraint c.
Given T  S and X  U , a plan is a function  : T  X. Given a workflow constraint (L, ),
T  S and X  U , a plan  : T  X satisfies (L, ) if either L \ T 6=  or |L =  for some
  . A plan  : T  X is eligible if  satisfies every constraint in C. A plan  : T  X is
authorized if (s)  A(s) for all s  T . A plan is valid if it is both authorized and eligible. A plan
 : S  U is called a complete plan. An algorithm to solve the WSP takes a workflow schema
(S, U, A, C) as input and outputs a valid, complete plan, if one exists (and null, otherwise).
As a running example, consider the following instance of the WSP.
Instance 1. The task set S = {s1 , . . . , s4 } and the user set U = {u1 , . . . , u6 }. The authorization
lists are as follows (where a tick indicates that the given user is authorized for the given task):
3. The Exponential Time Hypothesis claims there is no algorithm of running time O (2o(n) ) for 3SAT on n variables (Impagliazzo, Paturi, & Zane, 2001).

558

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

s1
s2
s3
s4

u1
4

u2
4
4
4
4

u3

u4

u5

u6

4
4

4
4

4
4

4

The constraints are as follows: s1 and s2 must be assigned to the same user; s2 and s3 must
be assigned to different users; s3 and s4 must be assigned to different users; s1 and s4 must be
assigned to different users.
Example 1 illustrates the meanings of eligible, complete and authorised plans in the context of
Instance 1.
Example 1. The following table gives assignments for four plans, 1 , 2 , 3 , 4 :

1
2
3
4

s1
u1
u1
u1
u2

s2
u2
u1
u2

s3
u4
u4
u4
u4

s4
u5
u5
u5
u5

Authorized
4
4
4

Eligible
4
4
4

Complete
4
4
4

 1 is a complete plan which is authorized but not eligible, as s1 and s2 are assigned to
different users.
 2 is a complete plan which is eligible but not authorized, as u1 is not authorized for s2 .
 3 is a plan which is authorized and eligible, and therefore valid. However, 3 is not a
complete plan as there is no assignment for s2 .
 4 is a complete plan which is eligible and authorized. Thus 4 is a valid complete plan, and
is therefore a solution.
For an algorithm that runs on an instance (S, U, A, C) of the WSP, we will measure the running
time in terms of n = |U |, k = |S|, and m = |C|. (The set A of authorization lists consists of k
lists each of size at most n, so we do not need to consider the size of A separately when measuring
the running time.) We will say an algorithm runs in polynomial time if it has running time at most
p(n, k, m), where p(n, k, m) is polynomial in n, k and m.
2.1 WSP Constraints
In this paper we are interested in the complexity of the WSP when the workflow constraint language
(the set of permissible workflow constraints) is restricted. In this section we introduce the constraint
types of interest. All of them have practical applications for real world workflows.
We assume that all constraints and authorizations can be checked in polynomial time. This
means that it takes polynomial time to check whether any plan is authorized, eligible and valid.
The correctness of our algorithm is unaffected by this assumption, but choosing constraints not
checkable in polynomial time would naturally affect the running time.
559

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

2.1.1 C ONSTRAINTS D EFINED BY A B INARY R ELATION
Constraints on two tasks, s and s0 , can be represented in the form (s, s0 , ), where  is a binary
relation on U (Crampton, 2005). A plan  satisfies such a constraint if (s)  (s0 ). Writing
= to denote the relation {(u, u) : u  U } and 6= to denote the relation {(u, v) : u, v  U, u 6= v},
separation-of-duty and binding-of-duty constraints may be represented in the form (s, s0 , 6=) and
(s, s0 , =), respectively. Crampton et al. (2013) considered constraints for which  is  or , where
 is an equivalence relation defined on U . A practical example of such workflow constraints is
when the equivalence relation partitions the users into different departments: constraints could then
enforce that two tasks be performed by members of the same department. Constraints that are not
restricted to singleton tasks have also been considered (Crampton et al., 2013; Wang & Li, 2010): a
plan  satisfies a constraint of the form (S 0 , S 00 , ) if there are tasks s0  S 0 and s00  S 00 such that
(s0 )  (s00 ).
2.1.2 C ARDINALITY C ONSTRAINTS
A tasks-per-user counting constraint has the form (t` , tr , T ), where 1 6 t` 6 tr 6 k and T  S. A
plan  satisfies (t` , tr , T ) if a user performs either no tasks in T or between t` and tr tasks. Tasksper-user counting constraints generalize the cardinality constraints which have been widely adopted
by the WSP community (American National Standards Institute, 2004; Bertino, Bonatti, & Ferrari,
2001; Joshi, Bertino, Latif, & Ghafoor, 2005; Sandhu, Coyne, Feinstein, & Youman, 1996).
2.1.3 R EGULAR C ONSTRAINTS
We say that C is regular if it satisfies the following condition: If a partition S1 , . . . , Sp of S is such
1
that for every
Sp i  [p] there exists an eligible complete plan  and user u with  (u) = Si , then
the plan i=1 (Si  ui ), where all ui s are distinct, is eligible. Regular constraints extend the set
of constraints considered by Wang and Li (2010). Crampton et al. (2013) show that the following
constraints are regular: (S 0 , S 00 , 6=); (S 0 , S 00 , =), where at least one of the sets S 0 , S 00 is a singleton;
tasks-per-user counting constraints of the form (t` , tr , T ), where t` = 1.
2.1.4 U SER -I NDEPENDENT C ONSTRAINTS
Many business rules are not concerned with the identities of the users that complete a set of tasks;
they are only concerned with the relationships between those users. Accordingly, we say a constraint (L, ) is user-independent if whenever    and  : U  U is a permutation, then
    . The most obvious example of a user-independent constraint is the requirement that two
tasks are performed by different users (separation-of-duty). As a more complex example suppose
that at most/at least/exactly p users are required to complete some sensitive set of tasks (cardinality
constraints), where p is usually small, i.e., 1, 2, 3 or so. There is a substantial literature on constraints as a method for specifying and enforcing business rules (for example, Gligor, Gavrila, &
Ferraiolo, 1998; Simon & Zurko, 1997), including work by researchers at SAP and IBM (for example, Basin, Burri, & Karjoth, 2014; Wolter & Schaad, 2007). The most widely studied constraints
are cardinality constraints and separation-of-duty, which form part of the ANSI standard on rolebased access control (American National Standards Institute, 2004), developed by the US National
Institute of Standards and Technology (NIST). In short, the literature and relevant standards suggest that user-independent constraints are those of most interest in business processes and workflow
560

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

management systems. Our definition of user-independent includes all the constraints defined in the
ANSI RBAC standard and many more.
Every regular constraint is user-independent, but many user-independent constraints are not
regular. Indeed, constraints of the type (S 0 , S 00 , =) are user-independent, but not necessarily
regular (Crampton et al., 2013). Many counting constraints in the Global Constraint Catalogue (Beldiceanu, Carlsson, & Rampon, 2012) are user-independent, but not regular. In particular, the constraint NVALUE, which bounds from above the number of users performing a set of
tasks, is user-independent but not regular. Note, however, that constraints of the form (s0 , s00 , )
and (s0 , s00 , 6) are not user-independent in general.
It is important to note that authorization lists, which are fundamental to any access control
system, when viewed as unary constraints, are certainly not user-independent. It is the presence of
both user-independent constraints and authorization lists in a workflow specification that makes the
WSP challenging.
2.2 A Naive Algorithm
The main aim of this section is to present a simple algorithm (Algorithm 1) which will solve any
instance of the WSP. The running time of the algorithm is slightly worse than a brute-force algorithm, but the algorithms basic structure provides a starting point from which to develop a more
efficient algorithm.
We need to introduce some additional notation and terminology.
Let  : T  X be a plan for some T  S, X  U . Then let TASK() = T and U SER() = X.
It is important for our generic algorithm that TASK() and U SER() are given as explicit parts of .
In particular, the set U SER() may be different from the set of users assigned to a task by . That is,
a user u can be in U SER() without there being a task s such that (s) = u. It is worth observing
that TASK() may be empty (because  may not allocate any tasks to users in X). For any T  S
and u  U , (T  u) denotes the plan  : T  {u} such that (s) = u for all s  T .
Two functions f1 : D1  E1 and f2 : D2  E2 are disjoint if D1  D2 = E1  E2 = . The
union of two disjoint functions f1 : D1  E1 , f2 : D2  E2 is a function f = f1  f2 such that
f : D1  D2  E1  E2 and f (d) = fi (d) for each d  Di , where i  {1, 2}. Let g : D  E
and h : E  F be functions. Then h  g denotes the composite function from D to F such that
h  g(d) = h(g(d)) for each d  D. For an integer p > 0, the set [p] = {1, 2, . . . , p}.
Proposition 1. Let (S, U, A, C) be an instance of the WSP, with n = |U |, k = |S| and m = |C|.
Then (S, U, A, C) can be solved in time O ((n + 1)k ) by Algorithm 1.
Proof. Let u1 , . . . , un be an ordering of U , and let Ui = {u1 , . . . , ui } for each i  [n]. For each
i  [n] in turn, we will construct the set i of all plans  such that U SER() = Ui and  is valid.
If the set n contains no plan  with TASK() = S, then (S, U, A, C) has no solution; otherwise,
any such plan is a solution for (S, U, A, C).
Algorithm 1 shows how to construct the sets i . It is not hard to verify that i contains exactly
every valid plan  with U SER() = Ui , for each i. This implies the correctness of our algorithm. It
remains to analyse the running time.
For each i  [n] and each T  S, there are at most i|T | valid plans  with U SER() =
Ui , TASK() = T . To construct 1 , we need to consider all plans  with U SER() = U1 , and there
are exactly 2k such plans. For each plan we can decide in polynomial time whether to add it to 1 .
561

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

Algorithm 1: Naive solution procedure for the WSP
input : An instance (S, U, A, C) of the WSP
1 Construct an ordering u1 , . . . , un of U ;
2 Set 1 = ;
3 foreach T  S do
4
Set  = (T  u1 );
5
if  is eligible and u1  A(s) for all s  T then
6
Set 1 = 1  {};
7
end
8 end
9 Set i = 1;
10 while i < n do
11
Set i+1 = ;
12
foreach  0  i do
13
foreach T  S \ TASK( 0 ) do
14
if ui+1  A(s) for all s  T then
15
Set  =  0  (T  ui+1 );
16
if  is eligible then
17
Set i+1 = i+1  {};
18
end
19
end
20
end
21
end
22
Set i = i + 1;
23 end
24 foreach   n do
25
if TASK() = S then
26
return ;
27
end
28 end
29 return NULL ;

To construct i+1 for each i  [n  1], we need to consider every pair ( 0 , T ) where  0  i and
T  S \ TASK( 0 ). Consider the pair ( 0 , T ), where  0 is an (S 0 , Ui )-plan for some S 0  S, and
0
0
T  S \ S 0 . Thus there are i|S | possibilities
for  0 , and there
are 2|S||S | choices for T . Thus,
P
P
0
0
k
k
the total number of pairs is given by S 0 S i|S | 2|S||S | = j=0 j ij 2kj = (i + 2)k . For each
pair ( 0 , T ) we can decide whether
to add  0  (T  ui+1 ) to i+1 in polynomial time. Thus, to
P
k

k

k
construct all i takes time O ( n1
i=0 (i + 2) ) = O (n(n + 1) ) = O ((n + 1) ).

Algorithm 1 is inefficient even for small k, due to the fact that each i contains all valid plans
with U SER( 0 ) = {u1 , . . . , ui }. We show in the next section that it is not necessary to store so
much information to solve the WSP.

0

562

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

3. Plan-Indistinguishability Relations
We first introduce the notion of extension-equivalence, defined by an equivalence relation on the set
of all plans. Informally, the relation enables us to keep a single member of each equivalence class
when building plans incrementally.
Definition 1. Given an instance (S, U, A, C) of the WSP, and two eligible plans 1 and 2 , define
1  2 if the following conditions hold:
1. U SER(1 ) = U SER(2 ) and TASK(1 ) = TASK(2 );
2. 1   0 is eligible if and only if 2   0 is eligible, for any plan  0 disjoint from 1 and 2 .
Then  is an equivalence relation on the set of eligible plans, and we say 1 and 2 are extensionequivalent if 1  2 .
Example 2. Consider Instance 1.
Let 1 : {s3 , s4 }  {u2 , u4 } be the function such that 1 (s3 ) = u2 and 1 (s4 ) = u4 . Let
2 : {s3 , s4 }  {u2 , u4 } be the function such that 2 (s3 ) = u4 and 2 (s4 ) = u2 .
The plans 1 and 2 are both eligible, and U SER(1 ) = U SER(2 ) and TASK(1 ) =
TASK(2 ). For any plan  0 disjoint from 1 and 2 , the plan 1   0 will satisfy the constraints
(s2 , s3 , 6=), (s1 , s4 , 6=). Thus 1   0 is eligible if and only if  0 is eligible. Similarly, 2   0 is
eligible if and only if  0 is eligible. Thus 1   0 is eligible if and only if 2   0 is eligible, and so
1 and 2 are extension-equivalent.
Suppose that we had a polynomial time algorithm to check whether two eligible plans are
extension-equivalent. Then in Algorithm 1, we could keep track of just one plan from each equivalence class: when constructing i , we will only add 2 to i if there is no 1 extension-equivalent
to 2 already in i ; when we construct i+1 , we may use 1 as a proxy for 2 . If the number of
extension-equivalent classes is small compared to the number of plans, then the worst-case running
time of the algorithm may be substantially lower than that of Algorithm 1.
Unfortunately, it is not necessarily easy to decide if two eligible plans are extension-equivalent,
so this approach is not practical. However, we can always refine4 extension-equivalence to an equivalence relation for which equivalence is easy to determine. For example, the identity equivalence
relation where each plan is only equivalent to itself is such a refinement.
This refined equivalence relation may have more equivalence classes than extensionequivalence, but substantially fewer than the identity relation, so we may obtain a better running
time than the naive algorithm.
Definition 2. Given an instance (S, U, A, C) of the WSP, let  be the set of all eligible plans
and let  be an equivalence relation refining extension-equivalence on . We say  is a planindistinguishability relation (with respect to C) if, for all eligible 1 , 2 such that 1  2 , and for
any plan  0 disjoint from 1 and 2 such that 1   0 is eligible, we have that 1   0  2   0 .
Example 3. Let  be the identity relation on plans. That is, 1  2 if and only if U SER(1 ) =
U SER(2 ), TASK(1 ) = TASK(2 ), and 1 (s) = 2 (s) for all s  U SER(1 ). Then  is a
4. An equivalence relation 2 is a refinement of an equivalence relation 1 if every equivalence class of 2 is a subset
of some equivalence class of 1 .

563

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

plan-indistinguishability relation. This shows that not every plan-indistinguishability relation is the
extension-equivalence relation. Indeed, the plans given in Example 2 are extension-equivalent but
not identical.
Recall that we refined extension-equivalence since it may be hard to determine whether two
eligible plans are extension-equivalent. It is therefore natural to assume the following:
Assumption 1. Given a plan-indistinguishability relation , it takes polynomial time to check
whether two eligible plans are equivalent under .
The correctness of our algorithms does not depend on this assumption. However, a poor choice
of the plan-indistinguishability relation could affect the running times.
We now describe appropriate plan-indistinguishability relations for the constraints that we will
be using. In each case determining if two eligible plans are equivalent under  will take polynomial
time.
3.1 Plan-Indistinguishability Relation for User-Independent Constraints
Lemma 1. Suppose all constraints are user-independent, and let ui be a relation such that 1 ui
2 if and only if
1. U SER(1 ) = U SER(2 ) and TASK(1 ) = TASK(2 );
2. For all s, t  TASK(1 ), 1 (s) = 1 (t) if and only if 2 (s) = 2 (t).
Then ui is a plan-indistinguishability relation on the set of eligible plans.
Proof. By definition of user-independent constraints, if  is an eligible plan and  : U  U is
a permutation, then    is also eligible. Suppose that 1 ui 2 , and let T = TASK(1 ) and
X = U SER(1 ). Let  0 : 1 (T )  2 (T ) be a function such that  0 (1 (t)) = 2 (t) for any
task t. Let  00 : X \ 1 (T )  X \ 2 (T ) be an arbitrary bijection (note that |1 (T )| = |2 (T )| by
Condition 2 of ui ). Let  =  0   00 . Then  is a permutation such that 2 =   1 . Thus 1 is
eligible if and only if 2 is eligible.
Now consider two eligible plans 1 , 2 such that 1 ui 2 , and a plan  0 disjoint from 1 and
2 . First we show that 1   0 ui 2   0 . It is clear that U SER(1   0 ) = U SER(2   0 ) and
TASK(1   0 ) = TASK(2   0 ). Now for any s, t  U SER(1   0 ), if (1   0 )(s) = (1   0 )(t),
then either s, t are both in TASK( 0 ), in which case (2   0 )(s) = (2   0 )(t) trivially, or s, t
are both in TASK(1 ), in which case 2 (s) = 2 (t) since 1 ui 2 , and hence (2   0 )(s) =
(2   0 )(t). Thus if (1   0 )(s) = (1   0 )(t) then (2   0 )(s) = (2   0 )(t) and, by a similar
argument, the converse holds. Thus 1   0 ui 2   0 . Furthermore, it follows by the argument
in the first paragraph that 1   0 is eligible if and only if 2   0 is eligible. Thus, the condition of
Definition 2 and the second condition of Definition 1 hold.
The first condition of ui trivially satisfies the first condition of Definition 1. Thus, ui satisfies
all the conditions of a plan-indistinguishability relation.
Example 4. Consider an instance of the WSP with users u1 , . . . u6 and tasks s1 , . . . , s6 in which
all constraints are user-independent. Let ui be the plan-indistinguishability relation given by
Lemma 1. Let c1 be the constraint with scope {s2 , s3 , s4 , s5 } such that c1 is satisfied if and only if
an even number of users are assigned to tasks in {s2 , s3 , s4 , s5 }. Let c2 be the constraint with scope
564

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

{s1 , s3 , s4 , s6 } such that c2 is satisfied if and only if either s1 and s3 are assigned to different users,
or s4 and s6 are assigned to different users. Suppose that c1 and c2 are the only constraints whose
scope contains tasks from both {s1 , s2 , s3 } and {s4 , s5 , s6 }.
Now consider the plans 1 , 2 : {s1 , s2 , s3 }  {u1 , u2 , u3 , u4 } such that 1 (s1 ) =
u1 , 1 (s2 ) = u2 , 1 (s3 ) = u1 , and 2 (s1 ) = u3 , 2 (s2 ) = u4 , 2 (s3 ) = u3 , and suppose that
1 , 2 are both eligible. Then 1 and 2 are equivalent under ui .
Observe that for any plan  0 disjoint from 1 and 2 , 1   0 is eligible if and only if 2   0
is eligible. As 1 and 2 both assign two users to {s2 , s3 },  0 must assign two users to {s4 , s5 } in
order to satisfy c1 . As 1 and 2 both assign s1 and s3 to the same user,  0 must assign s4 and s5
to different users in order to satisfy c2 . As long as these conditions are satisfied, and  0 satisfies all
constraints with scope in {s4 , s5 , s6 }, then 1   0 and 2   0 will both be eligible.
3.2 Plan-Indistinguishability Relation for Equivalence Relation Constraints
Recall that given a binary relation  on U , a constraint of the form (si , sj , ) is satisfied by a plan 
if (si )  (sj ). Recall that such constraints are not user-independent in general.
Lemma 2. Suppose  is an equivalence relation on U . Let V1 , . . . , Vl be the equivalence classes
of  over U . Suppose all constraints are of the form (si , sj , ) or (si , sj , 6). Let e be a relation
such that 1 e 2 if and only if
1. U SER(1 ) = U SER(2 ) and TASK(1 ) = TASK(2 );
2. For all equivalence classes Vj such that Vj  U SER(1 ) 6=  and Vj \ U SER(1 ) 6= , we
have that for all s  TASK(1 ), 1 (s)  Vj if and only if 2 (s)  Vj .
Then e is a plan-indistinguishability relation.
Proof. It is clear that e satisfies the first condition of Definition 1. Now suppose 1 , 2 are eligible
plans such that 1 e 2 , and let  0 be a plan disjoint from 1 and 2 . We first show that 1   0 is
eligible if and only if 2   0 is eligible.
Suppose that 1  0 is eligible. Consider two tasks t, t0  TASK(2  0 ). If {t, t0 }  TASK( 0 ),
then 2   0 will not falsify any constraint on t and t0 since it is equal to 1   0 when restricted to
{t, t0 } and 1   0 is eligible. If {t, t0 }  TASK(2 ), then 2   0 will not break any constraints
since 2 is eligible.
So we may assume that t  TASK(2 ), t0  TASK( 0 ). By definition, (2  0 )(t)  (2  0 )(t0 )
if and only if there exists j  [l] such that 2 (t),  0 (t0 )  Vj . Then Vj  U SER(2 ) 6=  and
Vj \ U SER(2 ) 6= . Therefore, by definition of e , 1 (s)  Vj if and only if 2 (s)  Vj , for all
s  TASK(1 ). In particular, 1 (t)  Vj , and so (1  0 )(t)  (1  0 )(t0 ). By a similar argument,
if (1   0 )(t)  (1   0 )(t0 ) then (2   0 )(t)  (2   0 )(t0 ). Therefore, every constraint is
satisfied by (1   0 ) if and only if it is satisfied by (2   0 ). Therefore if 1   0 is eligible then
so is 2   0 , and by a similar argument the converse holds.
It remains to show that 1   0 e 2   0 . It is clear that the user and task sets are the same.
As they have the same user set, the sets {Vj : Vj  U SER(1   0 ) 6= , Vj \ U SER(1   0 ) 6= }
and {Vj : Vj  U SER(2   0 ) 6= , Vj \ U SER(2   0 ) 6= } are the same. Furthermore, for each
Vj in this set and any s  TASK(1   0 ), if (1   0 )(s)  Vj then (2   0 )(s)  Vj , as either
s  TASK(1 ), in which case Vj  U SER(1 ) 6= , Vj \ U SER(1 ) 6=  and so 2 (s)  Vj , or
565

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

s  TASK( 0 ), in which case (2   0 )(s) =  0 (s) = (1   0 )(s). By a similar argument, if
(2   0 )(s)  Vj , then (1   0 )(s)  Vj . Thus 1   0 e 2   0 .
Example 5. Let  be an equivalence relation on users with equivalence classes
{u1 }, {u2 }, {u3 , u4 , u5 }, {u6 , u7 , u8 }. Consider an instance of the WSP with users u1 , . . . , u8
and tasks s1 , . . . , s6 in which all constraints are of the form (si , sj , ) or (si , sj , 6). Let e be the
plan-indistinguishability relation given by Lemma 2. Suppose that the only constraints whose scope
contains tasks from both {s1 , s2 , s3 } and {s4 , s5 , s6 } are the constraints (s1 , s5 , 6), (s2 , s5 , ) and
(s2 , s6 , 6).
Now consider the plans 1 , 2 : {s1 , s2 , s3 }  {u1 , u2 , u3 , u4 } such that 1 (s1 ) =
u1 , 1 (s2 ) = u3 , 1 (s3 ) = u3 , and 2 (s1 ) = u2 , 2 (s2 ) = u3 , 2 (s3 ) = u4 , and suppose that
1 , 2 are both eligible. Then 1 and 2 are equivalent under e .
Observe that for any plan  0 disjoint from 1 and 2 , 1   0 is eligible if and only if 2   0
is eligible. The only -equivalence class with members in {u1 , u2 , u3 , u4 } and members not in
{u1 , u2 , u3 , u4 } is the class {u3 , u4 , u5 }. 1 and 2 both assign members of {u3 , u4 } to exactly the
set {s2 , s3 }. Thus for any plan  0 disjoint from 1 and 2 , 1   0 and 2   0 will both satisfy the
constraint (s1 , s5 , 6) whatever  0 assigns to s5 . They will both satisfy (s2 , s5 , ) only if  0 assigns
s5 to u5 , and they will both satisfy (s2 , s6 , 6) only if  0 does not assign s6 to u5 . As long as these
conditions are satisfied, and  0 satisfies all constraints with scope in {s4 , s5 , s6 }, then 1   0 and
2   0 will both be eligible.

4. A Generic Algorithm for the WSP
In what follows, for each X  U, T  S, we let [X, T ] denote the set of all eligible plans  with
U SER() = X an TASK() = T . In this section we will introduce an algorithm that works in a
similar way to Algorithm 1, except that instead of storing all valid plans over a particular set of users
or tasks, we will construct [X, T ]-representative sets for each task set T and certain user sets X.
By definition, the equivalence classes of any plan-indistinguishability relation necessarily partition
[X, T ]. Hence any such equivalence class has a representation of the form (X, T, ), where  is
dependent on the constraint language. In the remainder of this section we describe the algorithm
and give examples of these representations.
4.1 Encodings and Patterns
In our generic algorithm, we will construct plans iteratively, using at most one plan from each
equivalence class under a plan-indistinguishability relation. The running time of the algorithm will
depend on the number of equivalence classes under this relation, over certain sets of plans. To
ensure that sets of equivalence classes can be ordered and therefore searched and sorted efficiently,
we introduce the notion of encodings and patterns. Loosely speaking, an encoding is a function that
maps all the plans in a -equivalence class to the same element (the pattern of those plans). These
encodings ensure logarithmic-time access and insertion operations into a representative set of plans,
rather than the linear time that a naive method would allow.
Note that the use of encodings and patterns is not necessary for any of our fixed-parameter
tractability results; the same problems could be solved without the use of patterns and encodings in
fixed-parameter time, but the function in k would grow more quickly.

566

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

Definition 3. Given an instance (S, U, A, C) of the WSP and a plan-indistinguishability relation
, let  be the set of all plans. Let PAT be some set and consider a function ENC :   PAT. For
any X  U, T  S, let PAT[X, T ] = ENC([X, T ]). Then we say ENC is a -encoding (or an
encoding for ) if, for any X  U, T  S and any 1 , 2  [X, T ], we have that
1. ENC(1 ) = ENC(2 ) if and only if 1  2 ;
2. ENC(1 ) can be calculated in time polynomial in n, k, m;
3. There exists a linear ordering  on PAT[X, T ] such that, for p, p0  PAT[X, T ], we can decide
whether p  p0 in time polynomial in n, k, m.
The elements of PAT are called -patterns. If ENC() = p then we say p is the -pattern of .
The second and third conditions of Definition 3 ensure that we may use encodings to organise
our plans in a reasonable time. When  is clear from the context, we will refer to a -encoding as
an encoding and -patterns as patterns.
We note some complexity consequences of Definition 3 in the following:
Proposition 2. For an encoding of a plan-indistinguishability relation  and a set of patterns PAT ,
by assigning patterns in PAT to the nodes of a balanced binary tree, we can perform the following
two operations in time O (log(|PAT |)): (i) check whether p  PAT , and (ii) insert a pattern
p
/ PAT into PAT .
Proof. Recall that comparisons are polynomial in n, k, m. Now our result follows from the wellknown properties of balanced binary trees (e.g., see (Cormen, Stein, Rivest, & Leiserson, 2001)).
We now show that the plan-indistinguishability relations given in the previous section have
encodings. We first need to define a lexicographic order.
Definition 4. Given a totally ordered set (A, ), the (total) lexicographic order  on d-tuples from
Ad is defined as follows. We say that (x1 , . . . , xd )  (y1 , . . . , yd ) if either xj = yj for all j  [d]
or there is an i with xi < yi such that xj = yj for all j < i.
Taking A = N and d = k we obtain the natural lexicographic order on Nk0 .
We can also lexicographically order the sets of disjoint subsets of an ordered set T =
{t1 , . . . , tk }, where t1 <    < tk .
Definition 5. We associate a k-tuple (x1 , . . . , xk )  Nk0 with each set S of disjoint subsets
{S1 , . . . , Sr } of {t1 , . . . , tk } as follows. We have xi = 0 if ti 
/ rm=1 Sm . For ti  rm=1 Sm ,
 if there are j < i and m such that {ti , tj }  Sm then xi = xj ,
 otherwise xi = max{x1 , . . . , xi1 } + 1, where max  = 0.
We will write VEC(S) = (x1 , . . . , xk ). Note that VEC(S) can be computed in time O(k 2 ).
Thus, tasks in the same subset are assigned the same value; this assignment of integers
to tasks can be performed iteratively. For example, for T = {1, . . . , 8} and the sets A =
{{2, 4}, {3}, {5, 7}} and B = {{2, 3, 4}, {5, 7}}, we have VEC(A) = (0, 1, 2, 1, 3, 0, 3, 0) and
VEC (B) = (0, 1, 1, 1, 2, 0, 2, 0). So A is lexicographically bigger than B.
567

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

Corollary 1. Let ui be the plan-indistinguishability relation given for a set of user-independent
constraints in Lemma 1. Then there exists an encoding for ui .
Proof. Let s1 , . . . , sk be an ordering of S and  a plan. Let S  = { 1 (u) : u  U SER()} and
let VEC() = VEC(S  ). For a plan , let ENC() be the tuple (U SER(), TASK(), VEC()).
It is clear that ENC(1 ) = ENC(2 ) if and only if 1 ui 2 , as r (si ) = r (sj ) if and only
if yi = yj in VEC(r ) = (y1 , . . . , yk ), for r  {1, 2}. Furthermore it is clear that ENC() can be
determined in polynomial time for any .
It remains to define a linear ordering on PAT[X, T ] for a given X  U, T  S. For two
patterns p = (X, T, (x1 , . . . , xk )), p0 = (X, T, (y1 , . . . , yk ))  PAT[X, T ], we define p  p0 if
(x1 , . . . , xk )  (y1 , . . . , yk ).
Example 6. Let ENC be the encoding given in the proof of Corollary 1. Let 1 , 2 be the plans
given in Example 4. Then ENC(1 ) = ENC(2 ) = {{u1 , u2 , u3 , u4 }, {s1 , s2 , s3 }, (1, 2, 1, 0, 0, 0)}.
Corollary 2. Let e be the plan-indistinguishability relation given for a set of constraints on equivalence relations in Lemma 2. Then there exists an encoding for e .
Proof. Suppose  is an equivalence relation on users, and let V1 , . . . , Vp be the equivalence classes
of  over U . Suppose all constraints are of the form (si , sj , ) or (si , sj , 6).
For a plan , define ENC() to be (U SER(), TASK(), T  ), where

	
T  =  1 (Vj  U SER()) : Vj  U SER() 6= , Vj \ U SER() 6= , 1  j  p .
It is clear that ENC(1 ) = ENC(2 ) if and only if 1 e 2 , as i (s)  Vj if and only if
s  i1 (Vj ), for i  {1, 2}. Furthermore it is clear that ENC() can be determined in polynomial
time for any .
It remains to define a linear ordering on PAT[X, T ] for a given X  U, T  S. Let  : T  X
be a plan. As T  is a set of disjoint subsets of TASK(), and T has a natural order, we can order
patterns in PAT[X, T ] according to the lexicographic order of T  .

Example 7. Let ENC be the encoding given in the proof of Corollary 2. Let 1 , 2 be the plans
given in Example 5. Then ENC(1 ) = ENC(2 ) = {{u1 , u2 , u3 , u4 }, {s1 , s2 , s3 }, {{s2 , s3 }}}.
4.2 The Generic Algorithm
We use the notion of diversity introduced in the next definition to analyse the running time of our
generic algorithm.
Definition 6. Let (S, U, A, C) be an instance of the WSP, with n = |U |, k = |S| and m = |C|, and
suppose  is a plan-indistinguishability relation with respect to C. Given an ordering u1 , . . . , un
of U , let Ui = {u1 , . . . , ui } for each i  [n]. Let wi be the number of equivalence classes of  over
the set [Ui , T ] of eligible plans. Then we define the diversity of  with respect to u1 , . . . , un to be
w = maxi[n] wi .
Since our generic algorithm only stores one plan from each equivalence class under , we need
the notion of a representative set.
568

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

Definition 7. Given an instance (S, U, A, C) of the WSP, let 0 be a set of eligible plans and let 
be a plan-indistinguishability relation. A set 00 is said to be a 0 -representative set with respect to
 if the following properties hold:
1. 00  0 ; every plan in 00 is valid;
2. for every valid  0  0 , there exists a  00  00 such that  0   00 .
When  is clear from context, we will say 00 is a 0 -representative set or a representative set
for 0 . Our generic algorithm is based on finding plan-indistinguishability relations for which there
exist small representative sets.
Theorem 1. Let (S, U, A, C) be an instance of the WSP, with n = |U |, k = |S| and m = |C|. Let
u1 , . . . , un be an ordering of U , and let Ui = {u1 , . . . , ui } for each i  [n], and U0 = . Suppose
 has diversity w with respect to u1 , . . . , un . Furthermore suppose that there exists a -encoding
ENC . Then (S, U, A, C) can be solved in time O  (3k w log w).
Proof. The proof proceeds by demonstrating the correctness and then bounding the running time of
Algorithm 2, which solves the WSP. To begin the proof, we give an overview of Algorithm 2.
 For each i  [n] in turn and each T  S, we will construct a representative set for [Ui , T ],
denoted by [Ui , T ] .
 As well as constructing the set [Ui , T ] , we also maintain a companion set PAT[Ui , T ] =
ENC ([Ui , T ] ). This provides an efficient way of representing the equivalence classes of
[Ui , T ] . In particular, it allows us to check whether a given valid plan  should be added
to [Ui , T ] , faster than by searching [Ui , T ] linearly.
 After [Un , S] has been constructed, it remains to check whether [Un , S] is non-empty,
as if there exists any valid complete plan , there exists a valid complete plan  0  [Un , S]
with    0 .
Algorithm 2 gives the details on how to construct [Ui , T ] for each i and T .
The proof of correctness of Algorithm 2 proceeds by induction. Observe first that for the case
of [U0 , T ] , if T 6=  then there is no possible plan in [U0 , T ], and so we set [U0 , T ] = . If
T =  then the only possible plan is the empty plan   ). This plan is added to [U0 , ] , as it
is trivially valid. Thus [U0 , T ] is a [U0 , T ]-representative set for each T .
So now assume that for all T  S the set [Ui , T ] has been constructed and is a [Ui , T ]representative set. Now consider the construction of [Ui+1 , T ] for some T  S. It is clear that
for any  added to [Ui+1 , T ] ,   [Ui+1 , T ], and  is eligible. Furthermore  is authorized,
as it is the union of the authorized plans  0  [Ui , T 0 ] and (T 00  ui+1 ). Thus every plan
in [Ui+1 , T ] is a valid plan in [Ui+1 , T ]. On the other hand, suppose  is a valid plan in
[Ui+1 , T ]. Then let T 00 =  1 ({ui+1 }) and T 0 = T \ T 00 , and let  0 = |Ui , so that  =
 0  (T 00  ui+1 ). By assumption, there exists  0   [Ui , T ] such that  0    0 . Consider
the plan   =  0   (T 00  ui+1 ). It is clear that   will be considered during the algorithm.
Furthermore, as  0    0 and  =  0  (T 00  ui+1 ), we have that    . Therefore   is
eligible (as  is eligible) and also authorized (as it is the union of two authorized plans). Therefore
569

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

Algorithm 2: Generic algorithm for the WSP
input : An instance (S, U, A, C) of the WSP, an ordering u1 , . . . , un of U , a
plan-indistinguishability relation 
1 Set [U0 , ] = {(  )};
2 foreach  =
6 T  S do
3
Set [U0 , T ] = ;
4 end
5 Set i = 0;
6 while i < n do
7
foreach T  S do
8
Set [Ui+1 , T ] = ;
9
Set PAT[Ui+1 , T ] = ;
10
foreach T 0  T do
11
Set T 00 = T \ T 0 ;
12
if ui+1  A(s) for all s  T 00 then
13
foreach  0  [Ui , T 0 ] do
14
Set  =  0  (T 00  ui+1 );
15
if  is eligible then
16
Set p = ENC();
17
if p 
/ PAT[Ui+1 , T ] then
18
Insert p into PAT[Ui+1 , T ] ;
19
Set [Ui+1 , T ] = [Ui+1 , T ]  {};
20
end
21
end
22
end
23
end
24
end
25
end
26
Set i = i + 1;
27 end
28 if [Un , S] 6=  then
29
return   [Un , S] ;
30 else
31
return NULL;
32 end

  is valid and will be added to [Ui+1 , T ] unless [Ui+1 , T ] already contains another plan equivalent to . Thus, [Ui+1 , T ] contains a plan -equivalent to , from which it follows that
[Ui+1 , T ] is a [Ui+1 , T ]-representative set, as required.
It remains to analyse the running time of the algorithm. By Proposition 2, testing whether
a pattern p is in PAT[Ui , T ] and inserting p into PAT[Ui , T ] takes O (log(|PAT[Ui , T ] |)) time.
Since by Assumption 1 and our assumption on the time to check constraints and authorizations it
takes polynomial time to check eligibility, authorization and -equivalence of plans, the running
570

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

P
P
P
P

time of the algorithm is O ( n1
i=0
T S
T 0 T
[Ui ,T 0 ] log(|[Ui+1 , T ] |)). It is clear by
construction that [Ui , T 0 ] contains at most one plan for each -equivalence class over [Ui , T 0 ],
and soP
by definition
|[Ui , T 0 ] |  w for all i, T 0 . It follows that the running time of the algorithm
P
n1 P

is O ( i=0 T S T 0 T w log w) = O (3k w log w).
Remark 1. Rather than checking whether [Un , S] is non-empty at the end of the algorithm, we
could instead check whether [Ui , S] is non-empty after the construction of [Ui , S] for each i.
That is, we can stop our search as soon as we have a valid plan with task set S. This is likely to lead
to a saving in the running time of an implementation of the algorithm. As this paper is concerned
with the worst-case running time, which would be unaffected by this change, we perform the check
at the end of the algorithm in the interest of clarity.
4.3 Application to User-Independent Constraints and its Optimality
In this subsection, we show that the WSP with user-independent constraints is FPT. Let Bk denote
the kth Bell number, the number of partitions of a set with k elements.
Lemma 3. Let u1 , . . . , un be any ordering of U , and let ui be the plan-indistinguishability relation
given in Lemma 1. Then ui has diversity Bk with respect to u1 , . . . , un .
Proof. For any plan , the set { 1 (u) : u  U SER()} is a partition of the tasks in TASK().
Furthermore, two plans that generate the same partition are equivalent under ui . Therefore the
number of equivalence classes of ui over [Ui , T ] is exactly the number of possible partitions of
T , which is B|T | . Thus, Bk is the required diversity.
Theorem 2. If all constraints are user-independent, then the WSP can be solved in time
O (2k log k ).
Proof. Let u1 , . . . , un be any ordering of U , and let ui be the plan-indistinguishability relation
given in Lemma 1.
By Lemma 3, ui has diversity Bk with respect to u1 , . . . , un . Furthermore, by Corollary 1,
there exists an encoding for ui . Therefore, we may apply Theorem 1 with w = Bk , to get an
algorithm with running time O (3k Bk log Bk ) = O (2k log k ) as Bk < (0.792k/ ln(k + 1))k for
every k (Berend & Tassa, 2010).
The running time O (2k log k ) obtained is optimal in the sense that no algorithm of running time
exists, unless the ETH fails. In the proof of the following theorem, we use a result
from Lokshtanov, Marx, & Saurabh, 2011 (Theorem 2.2).

O (2o(k log k) )

Theorem 3. There is no algorithm for the WSP with user-independent constraints of running time
O (2o(k log k) ), unless the ETH fails.
Proof. We give a reduction from the problem kk I NDEPENDENT S ET: Given an integer parameter
k and a graph G with vertex set V = {(i, j) : i, j  [k]}, decide whether G has an independent set
I such that |I| = k and for each r  [k], there exists i such that (r, i)  I.
Informally, k  k I NDEPENDENT S ET gives us a graph on a k  k grid of vertices, and asks
whether there is an independent set with one vertex from each row. Lokshtanov et al. (2011) proved
that there is no algorithm to solve k  k I NDEPENDENT S ET in time 2o(k log k) , unless the ETH fails.
571

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

Consider an instance of k  k I NDEPENDENT S ET with graph G. We will first produce an
equivalent instance of the WSP in which the constraints are not user-independent. We will then
refine this instance to one with user-independent constraints.
Let U = {u1 , . . . , uk } be a set of k users and S = {s1 , . . . , sk } a set of k tasks. Let the
authorization lists be A(si ) = U for all i  [k]. For i, j, h, l  [k], let c((i, j), (h, l)) denote
the constraint with scope {si , sh }, and which is satisfied by any plan  unless (si ) = uj and
(sh ) = ul . For every pair of vertices (i, j), (h, l) which are adjacent in G, add the constraint
c((i, j), (h, l)) to C.
We now show that (S, U, A, C) is a Y ES-instance of the WSP if and only if G has an independent set with one vertex from each row. Suppose (S, U, A, C) is a Y ES-instance of the WSP and
let  be a valid complete plan. Then for each i  [k], let f (i) be the unique j such that (si ) = uj .
Then I = {(i, f (i)) : i  [k]} is a set with one vertex from each row in G; furthermore, as  satisfies every constraint, no edge in G contains more than one element of I, and so I is an independent
set.
Conversely, suppose G is a Y ES-instance of k  k I NDEPENDENT
S ET. For each i  [k], let
S
f (i) be an integer such that (i, f (i))  I. Then observe that ki=1 ({si }  uf (i) ) is a valid complete
plan.
We now show how to reduce (S, U, A, C) to an instance of the WSP in which all constraints
are user-independent. The main idea is to introduce some new tasks representing the users, and in
the constraints, replace the mention of a particular user with the mention of the user that performs a
particular task.
Create k new tasks t1 , . . . , tk and let S 0 = S  {t1 , , . . . , tk }. Let the authorization lists be
0
A (s) = U for each s  S and A0 (ti ) = {ui } for each i  [k]. For each constraint c((i, j), (h, l))
in C, let d((i, j), (h, l)) be the constraint with scope {si , sh , tj , tl }, which is satisfied by any plan 
unless (si ) = (tj ) and (sh ) = (tl ). Let initially C 0 = C. Now replace, in C 0 , every constraint
c((i, j), (h, l)) with d((i, j, ), (h, l)).
Since they are defined by equalities, and no users are mentioned, the constraints in C 0 are userindependent. We now show that (S 0 , U, A0 , C 0 ) is equivalent to (S, U, A, C). First, suppose that 
is a valid complete plan for (S, U, A, C). Then let  0 : S 0  U be the plan such that  0 (si ) = (si )
for all i  [k], and  0 (tj ) = uj for all j  [k]. It is easy to check that if  satisfies every constraint
of C then  0 satisfies every constraint of C 0 . Since  0 is an authorized and eligible plan,  0 is a valid
complete plan for (S 0 , U, A0 , C 0 ).
Conversely, suppose that  0 is a valid complete plan for (S 0 , U, A0 , C 0 ). Since A0 (ti ) = {ui } for
each i  [k],  0 (ti ) = ui for every i  [k]. For each i  [k], let f (i) be the unique integer such that
 0 (si ) = uf (i) . Then define  : S  U by (si ) = uf (i) , and observe that all constraints in C are
satisfied by . So,  is a valid complete plan for (S, U, A, C).
4.4 Application to Equivalence Relation Constraints
It is known that restricting the WSP to have only equivalence relation constraints is enough to ensure
that the problem is FPT (Crampton et al., 2013). However, we can derive this result by applying our
algorithm directly having shown the appropriate properties of the language of equivalence relation
constraints. This serves to demonstrate the wide applicability of our approach.

572

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

Lemma 4. Let e be the plan-indistinguishability relation given for a set of equivalence relation
constraints in Lemma 2. Then there exists an ordering u1 , . . . , un of U such that e has diversity
2k with respect to U .
Proof. Suppose  is an equivalence relation on users, and let V1 , . . . , Vp be the equivalence classes
of  over U . Suppose all constraints are of the form (si , sj , ) or (si , sj , 6).
Let u1 , . . . , un be an ordering of U such that all the elements of Vj appear before all the elements
of Vj 0 , for any j < j 0 . Thus, for any i and any plan  with U SER() = Ui = {u1 , . . . , ui }, there is
at most one integer ji such that Vji  U SER() 6= , Vji \ U SER() 6= .
It follows that any two plans 1 , 2  [Ui , T ] are e -equivalent, for any i  [n], T  S,
provided that 1 (t)  Vji if and only if 2 (t)  Vji for any t  T . Therefore e has at most 2k
equivalence classes over [Ui , T ], as required.
Theorem 4. Suppose  is an equivalence relation on U . Suppose all constraints are of the form
(si , sj , ) or (si , sj , 6). Then the WSP can be solved in time O (6k ).
Proof. Let u1 , . . . , un be the ordering of U given by Lemma 4, and let e be the planindistinguishability relation given in Lemma 2.
By Lemma 4, e has diversity 2k with respect to u1 , . . . , un . Furthermore by Corollary 2, there
exists an encoding for e . Therefore, we may apply Theorem 1 with w = 2k , to get an algorithm
with running time O (3k 2k log(2k )) = O (6k ).

5. Unions of Constraint Languages
In this section we show how our approach allows us easily to combine constraint languages shown
to be FPT for the WSP. We do not need to build bespoke algorithms for the new constraint language
obtained, only to show that the two languages are in some sense compatible.
This highlights the advantages of our approach over previous methods, which required the development of new algorithms when different constraint languages were combined in an instance of
the WSP (e.g., see Crampton et al., 2013).
Theorem 5. Let (S, U, A, C1  C2 ) be an instance of the WSP, and suppose 1 is a planindistinguishability relation with respect to C1 and 2 is a plan-indistinguishability relation with
respect to C2 . Given an ordering u1 , . . . , un of U , let W1 be the diversity of 1 with respect to
u1 , . . . , un and W2 the diversity of 2 with respect to u1 , . . . , un .
Let  be the equivalence relation such that    0 if and only if  1  0 and  2  0 . Then
 is a plan-indistinguishability relation with respect to C1  C2 , and  has diversity W1 W2 with
respect to u1 , . . . , un .
Proof. We first show that  is a plan-indistinguishability relation with respect to C1  C2 . Let 
and  0 be eligible plans (with respect to C1  C2 ). As    0 implies  1  0 and 1 satisfies
the conditions of a plan-indistinguishability relation, it is clear that if    0 then U SER() =
U SER( 0 ) and TASK() = TASK( 0 ). Now consider a plan  00 disjoint from  and  0 . As 1 is a
plan-indistinguishability relation with respect to C1 and  1  0 , we have that    00 is C1 -eligible
if and only if  0   00 is. Similarly    00 is C2 -eligible if and only if  0   00 is. Observing that a
plan is C1  C2 -eligible if and only if it is C1 -eligible and C2 -eligible, this implies that    00 is
C1  C2 -eligible if and only if  0   00 is. Thus we have that  and  0 are extension equivalent.
573

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

As 1 and 2 are plan-indistinguishability relations, we have that    00 1  0   00 and
   00 2  0   00 , and therefore    00   0   00 . Thus,  satisfies all the conditions of a
plan-indistinguishability relation.
To bound the diversity of  with respect to u1 , . . . , un , consider any T  S and Ui =
{u1 , . . . , ui }. It is enough to note that any -equivalent plans in [Ui , T ] must be in the same
1 and 2 -equivalence classes. As there are at most W1 choices for the 1 -equivalence class and
at most W2 choices for the 2 equivalence class,  has at most W1 W2 equivalence classes over
[Ui , T ].
Remark 2. Given an encoding ENC1 for 1 and an encoding ENC2 for 2 , we may construct an
encoding for . Given a plan , let ENC() be the ordered pair (ENC1 (), ENC2 ()). It is clear
that ENC() = ENC( 0 ) if and only if    0 .
Given sets T  S and Ui = {u1 , . . . , ui }, fix linear orderings of ENC1 ([Ui , T ]) and
ENC 2 ([Ui , T ]). Then let  be the lexicographic ordering of ENC ([Ui , T ]) = ENC 1 ([Ui , T ]) 
ENC 2 ([Ui , T ]).
There is nothing to stop us applying Theorem 5 multiple times, in order to get a planindistinguishability relation with bounded diversity for a union of several constraint languages.
Note that the diversity can be expected to grow exponentially with the number of languages in the
union. Thus, it makes sense to only apply Theorem 5 to the union of a small number of languages.
However, as long as there is a fixed number of languages, and each has a plan-indistinguishability
relation with fixed-parameter diversity, the resulting union of languages will also have a planindistinguishability relation with fixed-parameter diversity.
We can now use this result directly to show that if all our constraints are either user independent
or equivalence relation constraints, then the WSP is still FPT.
Theorem 6. Suppose  is an equivalence relation on U . Let (S, U, A, C) be an instance of the
WSP, and suppose that all constraints are either of the form, (s1 , s2 , ), (s1 , s2 , 6) or userindependent constraints. Then the WSP can be solved in time O (2k log k+k ).
Proof. Let Ce  C be the set of constraints of the form (s1 , s2 , ), (s1 , s2 , 6), and let Cui be the
remaining (user-independent) constraints.
Let u1 , . . . , un be the ordering of U given by Lemma 4. By Lemmas 2 and 4, there exists a planindistinguishability relation e for Ce that has diversity 2k with respect to u1 , . . . , un . Furthermore
by Corollary 2, e has an encoding. By Lemmas 1 and 3, there exists a plan-indistinguishability
relation ui for Cui that has diversity Bk with respect to u1 , . . . , un . Furthermore by Corollary 1,
ui has an encoding.
Therefore by Theorem 5, we may find a plan-indistinguishability relation  for C, such
that  has diversity Bk  2k with respect to u1 , . . . , un and  has an encoding. Thus we
may apply Theorem 1 with w = Bk  2k , to get a running time of O (3k Bk 2k log(Bk 2k )) =
O (3k 2k log k(1o(1))+k log(2k log k(1o(1))+k )) = O (2k log k+k ).

6. Computational Experiments with WSP Algorithms
Apart from conducting theoretical research on the WSP, Wang and Li (2010) carried out an experimental study of the problem. Due to the difficulty of acquiring real-world workflow instances,
574

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

Wang and Li used synthetic data in their experimental study. They encoded instances of the WSP
into pseudo-Boolean SAT in order to use a pseudo-Boolean SAT solver SAT4J.
We have implemented our algorithm and compared its performance to SAT4J on another set
of synthetic instances of the WSP (Cohen et al., 2014). These instances use k = 16, 20 and
24, n = 10k and user-independent (cardinality) constraints of three different types: we vary the
number of constraints and the proportions of the different constraint types; each user is authorized
for between 1 and 8 tasks for k = 16, between 1 and 10 tasks for k = 20, and between 1 and 12
tasks for k = 24. The algorithm was implemented in C++ and has been enhanced by the inclusion
of techniques employed in CSP solving, such as propagation. We also converted WSP instances into
pseudo-Boolean problems for processing by SAT4J. All experiments were performed on a MacBook
Pro computer with a 2.6 GHz Intel Core i5 processor and 8 GB 1600 MHz DDR3 RAM (running
Mac OS X 10.9.2).
For lightly-constrained instances, SAT4J was often faster than our algorithm, largely because
the number of patterns considered by our algorithm is large for such instances. However, for highlyconstrained instances, SAT4J was unable to compute a decision for a number of instances (because
it ran out of memory), in sharp contrast to our algorithm which solved all instances. Overall, on
average, our algorithm was faster than SAT4J and, in particular, was two orders of magnitude faster
for k = 16. Moreover, the time taken by our algorithm varies much less than that of SAT4J, even
for unsatisfiable instances, because the time taken is proportional to the product of the number of
patterns and the number of users. (In particular, in tested instances, it is much less dependent on the
number of constraints, a parameter that can cause significant fluctuations in the time taken by SAT4J
because it leads to a sharp increase in the number of variables in the pseudo-Boolean encoding.) Full
details of our results have been published (Cohen et al., 2014).

7. Conclusion
In this paper we introduced an algorithm based on the notion of plan-indistinguishability, applicable
to a wide range of WSP instances. We showed that our algorithm is powerful enough to be optimal,
in a sense, for the wide class of user-independent constraints. The generic algorithm is also a
fixed-parameter algorithm for equivalence relation constraints, which are not user-independent. We
showed how to deal with unions of different types of constraints using our generic algorithm. In
particular, we proved that the generic algorithm is a fixed-parameter algorithm for the union of
user-independent and equivalence relation constraints.

Acknowledgments
Our research was supported by EPSRC grant EP/K005162/1. We are grateful to the referees for
their useful comments and suggestions.

References
American National Standards Institute (2004).
CITS RBAC 359-2012).
575

Role Based Access Control (ANSI IN-

fiC OHEN , C RAMPTON , G AGARIN , G UTIN , & J ONES

Basin, D. A., Burri, S. J., & Karjoth, G. (2014). Obstruction-free authorization enforcement: Aligning security and business objectives. Journal of Computer Security, 22(5), 661698.
Beldiceanu, N., Carlsson, M., & Rampon, J.-X. (2012). Global constraint catalog, 2nd edition
(revision a). working copy 5195, Swedish Institute of Computer Science, Kista, Sweden.
Berend, D., & Tassa, T. (2010). Improved bounds on bell numbers and on moments of sums of
random variables. Probability and Mathematical Statistics, 30(2), 185205.
Bertino, E., Bonatti, P. A., & Ferrari, E. (2001). TRBAC: a temporal role-based access control
model. ACM Trans. Inf. Syst. Secur., 4(3), 191233.
Bertino, E., Ferrari, E., & Atluri, V. (1999). The specification and enforcement of authorization
constraints in workflow management systems. ACM Trans. Inf. Syst. Secur., 2(1), 65104.
Bodlaender, H. L., Cygan, M., Kratsch, S., & Nederlof, J. (2013). Deterministic single exponential
time algorithms for connectivity problems parameterized by treewidth. In Proceedings of the
40th International Conference on Automata, Languages, and Programming - Volume Part I,
ICALP13, pp. 196207, Berlin, Heidelberg. Springer-Verlag.
Bulatov, A., Jeavons, P., & Krokhin, A. (2005). Classifying the complexity of constraints using
finite algebras. SIAM Journal on Computing, 34, 720742.
Cohen, D., Crampton, J., Gagarin, A., Gutin, G., & Jones, M. (2014). Engineering algorithms
for workflow satisfiability problem with user-independent constraints. In Chen, J., Hopcroft,
J. E., & Wang, J. (Eds.), Frontiers in Algorithmics - 8th International Workshop, FAW 2014,
Zhangjiajie, China, June 28-30, 2014. Proceedings, Vol. 8497 of Lecture Notes in Computer
Science, pp. 4859. Springer.
Cormen, T. H., Stein, C., Rivest, R. L., & Leiserson, C. E. (2001). Introduction to Algorithms (2nd
edition). McGraw-Hill Higher Education.
Crampton, J., Crowston, R., Gutin, G., Jones, M., & Ramanujan, M. (2013). Fixed-parameter
tractability of workflow satisfiability in the presence of seniority constraints. In Fellows, M.,
Tan, X., & Zhu, B. (Eds.), Frontiers in Algorithmics and Algorithmic Aspects in Information
and Management, Vol. 7924 of Lecture Notes in Computer Science, pp. 198209. Springer
Berlin Heidelberg.
Crampton, J. (2005). A reference monitor for workflow systems with constrained task execution.
In Proceedings of the Tenth ACM Symposium on Access Control Models and Technologies,
SACMAT 05, pp. 3847, New York, NY, USA. ACM.
Crampton, J., & Gutin, G. (2013). Constraint expressions and workflow satisfiability. In Proceedings of the 18th ACM Symposium on Access Control Models and Technologies, SACMAT 13,
pp. 7384, New York, NY, USA. ACM.
Crampton, J., Gutin, G., & Yeo, A. (2013). On the parameterized complexity and kernelization of
the workflow satisfiability problem. ACM Trans. Inf. Syst. Secur., 16(1), 4:14:31.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann Publishers, 340 Pine Street, Sixth
Floor, San Francisco, CA 94104-3205.
Downey, R. G., & Fellows, M. R. (2013). Fundamentals of Parameterized Complexity. Texts in
Computer Science. Springer.
576

fiI TERATIVE P LAN C ONSTRUCTION FOR THE W ORKFLOW S ATISFIABILITY P ROBLEM

Fomin, F. V., Lokshtanov, D., & Saurabh, S. (2014). Efficient computation of representative sets
with applications in parameterized and exact algorithms. In Proceedings of the Twenty-Fifth
Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 14, pp. 142151. SIAM.
Gligor, V., Gavrila, S., & Ferraiolo, D. (1998). On the formal definition of separation-of-duty policies and their composition. In 1998 IEEE Symposium on Security and Privacy, 1998. Proceedings., pp. 172183.
Impagliazzo, R., Paturi, R., & Zane, F. (2001). Which problems have strongly exponential complexity?. J. Comput. Syst. Sci., 63(4), 512530.
Jayaraman, K., Ganesh, V., Tripunitara, M. V., Rinard, M. C., & Chapin, S. J. (2011). ARBAC
policy for a large multi-national bank. CoRR, abs/1110.2849.
Joshi, J. B. D., Bertino, E., Latif, U., & Ghafoor, A. (2005). A generalized temporal role-based
access control model. IEEE Transactions on Knowledge and Data Engineering,, 17(1), 423.
Lokshtanov, D., Marx, D., & Saurabh, S. (2011). Slightly superexponential parameterized problems.
In Proceedings of the Twenty-second Annual ACM-SIAM Symposium on Discrete Algorithms,
SODA 11, pp. 760776. SIAM.
Niedermeier, R. (2006). Invitation to Fixed-Parameter Algorithms. Oxford University Press.
Rossi, F., van Beek, P., & Walsh, T. (Eds.). (2006). The Handbook of Constraint Programming.
Elsevier.
Sandhu, R. S., Coyne, E. J., Feinstein, H. L., & Youman, C. E. (1996). Role-based access control
models. Computer, 29(2), 3847.
Schaad, A., Moffett, J., & Jacob, J. (2001). The role-based access control system of a european
bank: A case study and discussion. In Proceedings of the Sixth ACM Symposium on Access
Control Models and Technologies, SACMAT 01, pp. 39, New York, NY, USA. ACM.
Simon, R., & Zurko, M. (1997). Separation of duty in role-based environments. In Computer
Security Foundations Workshop, 1997. Proceedings., 10th, pp. 183194.
Wang, Q., & Li, N. (2010). Satisfiability and resiliency in workflow authorization systems. ACM
Trans. Inf. Syst. Secur., 13(4), 40:140:35.
Wolter, C., & Schaad, A. (2007). Modeling of task-based authorization constraints in bpmn. In
Proceedings of the 5th International Conference on Business Process Management, BPM07,
pp. 6479, Berlin, Heidelberg. Springer-Verlag.

577

fiJournal of Artificial Intelligence Research 51 (2014) 377-411

Submitted 7/14; published 10/14

A Novel SAT-Based Approach to Model Based Diagnosis
Amit Metodi

AMITMET @ CS . BGU . AC . IL

Department of Computer Science,
Ben Gurion University of the Negev, Beer-Sheva, Israel

Roni Stern
Meir Kalech

RONI . STERN @ GMAIL . COM
KALECH @ BGU . AC . IL

Department of Information Systems Engineering,
Ben Gurion University of the Negev, Beer-Sheva, Israel

Michael Codish

MCODISH @ CS . BGU . AC . IL

Department of Computer Science,
Ben Gurion University of the Negev, Beer-Sheva, Israel

Abstract
This paper introduces a novel encoding of Model Based Diagnosis (MBD) to Boolean Satisfaction (SAT) focusing on minimal cardinality diagnosis. The encoding is based on a combination
of sophisticated MBD preprocessing algorithms and the application of a SAT compiler which optimizes the encoding to provide more succinct CNF representations than obtained with previous
works. Experimental evidence indicates that our approach is superior to all published algorithms
for minimal cardinality MBD. In particular, we can determine, for the first time, minimal cardinality diagnoses for the entire standard ISCAS-85 and 74XXX benchmarks. Our results open the way
to improve the state-of-the-art on a range of similar MBD problems.

1. Introduction
Automated diagnosis is concerned with reasoning about the health of systems, including the identification of abnormal behavior, isolation of faulty components and prediction of system behavior
under normal and abnormal conditions. As systems become large-scale and more complex, their
automated diagnosis becomes more challenging. Model Based Diagnosis (MBD) is an artificial
intelligence based approach that aims to cope with the diagnosis problem (Reiter, 1987; de Kleer
& Williams, 1987). In MBD, a model of the system is first built. A diagnoser then observes the
system to predict its behavior by the model. Discrepancies between the observation and the prediction are used as the input for a diagnosis algorithm which produces a set of possible faults that
can explain the observation. MBD has been deployed in several real-world applications, including
spacecrafts (Williams & Nayak, 1996), satellite decision support systems (Feldman, de Castro, van
Gemund, & Provan, 2013), the automotive industry (Struss & Price, 2003) and spreadsheets (Jannach & Schmitz, 2014). Also, there exist several commercial MBD tools (Feldman, 2012; Dressler
& Struss, 1995).
MBD is known to be a hard problem where algorithms have exponential runtime (exponential
in the number of components in the diagnosed system). Moreover, the number of potential diagnoses for a given observation can be huge. Therefore, MBD algorithms typically focus on minimal
c
2014
AI Access Foundation. All rights reserved.

fiM ETODI , S TERN , K ALECH & C ODISH

diagnoses: minimal subset  that do not contain other diagnoses, and minimal cardinality  that
are smallest in size. Computing the first minimal diagnosis is in P , but computing the next one is
NP-hard (Bylander, Allemang, Tanner, & Josephson, 1991). Computing the minimal cardinality is
NP-hard, even for the first diagnosis (Selman & Levesque, 1990). In this work we focus on this
hard task of finding minimal cardinality diagnoses.
The study of Model-Based Diagnosis has resulted in a variety of computational and modeling
challenges. In this paper we focus on one such challenge which has received much attention over
the years. Originally defined by Reiter (1987) and by de Kleer and Williams (1987), this problem
aims to diagnose multiple faulty components in the so-called weak fault model, which ignores the
mode of abnormal behavior of components. This problem has been extensively researched for more
than 25 years and a wide range of papers propose different algorithms to solve it, including a range
of papers from recent years (Feldman & van Gemund, 2006; Williams & Ragno, 2007; Feldman,
Provan, & van Gemund, 2010a; Siddiqi & Huang, 2007, 2011). When addressing this challenge, it
is common practice to focus on the diagnosis of Combinational Logic Circuits. Namely, Boolean
circuits where the single output of each component is determined only by the logical function of its
current input state (independent of time and with no feedback).
In the basic setting a diagnosis considers a single observation on the inputs and outputs of
the system. Variations consider additional information such as probabilities on component failure,
multiple observations on the inputs and outputs of the system, and observations on internal positions
of the system (probes). In this paper we focus on the basic setting. Extensions and variations are
discussed in Section 8.
Even in the basic setting, solving an MBD problem is often impractical, especially for highcardinality faults. For instance, in a system of 1000 components, to find a minimal cardinality
diagnosis of size 5, a diagnosis engine must verify the absence of a diagnosis consisting of 4 components (there are more than 1010 such combinations). To overcome the complexity of the problem
we consider a novel encoding to SAT.
In recent years, Boolean SAT solving techniques have improved dramatically. Todays SAT
solvers are considerably faster and able to manage larger instances than yesterdays. Moreover, encoding and modeling techniques are better understood and increasingly innovative. SAT is currently
applied to solve a wide variety of hard and practical combinatorial problems, often outperforming
dedicated algorithms. For a survey on the state-of-the-art in SAT solving see the work by Biere,
Heule, van Maaren, and Walsh (2009) or the draft of the forthcoming volume of The Art of Computer Programming (Knuth, 2014).
The general idea is to encode a (typically, NP) hard problem instance, , to a Boolean formula,
 , such that the solutions of  correspond to the satisfying assignments of  . Given the encoding,
a SAT solver is then applied to solve .
SAT-based solutions for MBD have already been proposed. Smith et al. (2005) encode a circuit,
representing each component through its clauses and add constraints for cardinality. This is the basis
for all the other SAT-based encodings, including the one we contribute in this paper. Bauer (2005)
introduces a tailored SAT solver specifically designed to return many diagnoses. Stein et al. (2006)
address diagnosis of qualitative models of physical systems with multiple fault modes. More recently, Feldman et al. (2010) propose an encoding to MAX-SAT and demonstrate that off-the-shelf
solvers require more calls to a SAT solver than the stochastic diagnosis algorithm SAFARI (Feldman
et al., 2010a).
378

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

These previous applications of SAT for MBD appear to indicate that SAT and MAX-SAT solvers
are doomed to perform poorly on the standard benchmarks (Feldman et al., 2010). This paper proves
the contrary. Our SAT-based approach differs from previous SAT encodings in several key aspects.
First, sophisticated MBD preprocessing techniques are applied to facilitate the construction of a
carefully designed constraint model, which includes constraints that exploit unique substructures in
the diagnosed system. Second, this constraint model is compiled to a corresponding CNF using a
constraint compiler called BEE (Metodi & Codish, 2012), that simplifies constraints and generates
an encoding to CNF which significantly improves the subsequent runtime of the underlying SAT
solver. Lastly, a structural abstraction inspired by Siddiqi and Huang (2007) is used to decompose
the diagnosis problem, such that the SAT solver is only used to find top-level diagnoses, and
we show a simple poly-time algorithm to expand these top-level diagnoses to find all minimal
cardinality diagnoses. Our approach requires some preprocessing of the diagnosed system, but the
complexity of that preprocessing is a low-order polynomial, and negligible (both theoretically and
empirically) compared to the cost of the actual SAT solving.
We evaluated our SAT-based approach using two standard benchmarks: ISCAS-85 (Brglez,
Bryan, & Kozminski, 1989) and 74XXX. These are the standard benchmarks in the MBD literature, used extensively from the time they were made available until today (Feldman & van Gemund,
2006; Feldman et al., 2010a; Siddiqi & Huang, 2007, 2011; Stern, Kalech, Feldman, & Provan,
2012; Nica, Pill, Quaritsch, & Wotawa, 2013). Finding minimal cardinality diagnoses for hard sets
of observations in the ISCAS-85 has been a long standing challenge in the MBD community and
used in diagnosis competitions (DXC, 2009). The ISCAS-85 systems were also used as a standard
for automatic benchmark generation (Wang & Provan, 2010).
We consider three known sets of observations with minimal cardinalities between 131, and
for the first time succeed to compute a minimal cardinality diagnosis for all observations in the
benchmark. We compare our approach to a wide collection of state-of-the-art algorithms for MBD,
including: HA* (Feldman & van Gemund, 2006), CDA* (Williams & Ragno, 2007), SAFARI (Feldman et al., 2010a), HDIAG (Siddiqi & Huang, 2007) and DCAS (Siddiqi & Huang, 2011). Results
are unequivocal. Our approach outperforms the others, often by orders of magnitude, in terms of
runtime. This result is even more significant, as SAFARI is a stochastic algorithm, known as fast,
which does not even aim to guarantee minimal cardinality. Our approach, on the other hand, guarantees a minimal cardinality diagnosis and runs faster than SAFARI.
This paper goes beyond our preliminary version of this work (Metodi, Stern, Kalech, & Codish,
2012a). We provide a detailed description of each of the components of our approach, we present
detailed algorithms, prove correctness, provide additional examples and present a more elaborate
experimental evaluation. In the next section we discuss additional related work. Section 3 presents
the required background on MBD. In Section 4 we present the standard approach to model MBD
with SAT. Section 5 is the main part of this paper in which we describe the building blocks of our tool
to find minimal cardinality diagnosis. Section 6 describes how these building blocks are combined
into a diagnosis algorithm. Comprehensive evaluation of our approach is given in Section 7. Section
8 discusses the applicability of our approach in a more general setting and Section 9 concludes.

2. Related Work
Since the late 80s, the Model Based Diagnosis problem with weak fault model has been widely
researched and a wide range of papers propose different algorithms to solve it (Reiter, 1987; de Kleer
379

fiM ETODI , S TERN , K ALECH & C ODISH

& Williams, 1987; Feldman & van Gemund, 2006; Williams & Ragno, 2007; Feldman et al., 2010a;
Siddiqi & Huang, 2007, 2011). Till today it is considered a challenge as reflected by the synthetic
track in the annual DXC diagnosis competition (DXC, 2009).
Many of the existing diagnosis techniques propose to apply a combination of deterministic reasoning and search algorithms. One classic approach involves a two stage process. First, it identifies
conflict sets, each of which includes at least one fault. Then, it applies a hitting set algorithm to
compute sets of multiple faults that explain the observation (de Kleer & Williams, 1987; Williams
& Ragno, 2007). These methods guarantee sound diagnoses, and some of them are even complete.
However, they tend to fail for large systems due to infeasible runtime or space requirements.
An alternative method is to directly search for diagnoses by trying different assumptions on
which components are faulty. For example, the DRUM-II diagnosis engine finds a minimal diagnosis by performing an iterative deepening search, limiting in every iteration, the number of
components that are assumed to be faulty (Frohlich & Nejdl, 1997). DRUM-II also analyzes the
dependencies between components to prune irrelevant diagnoses. Recent work presents empirical
evidence suggesting that direct search for diagnoses is often better than conflict-directed diagnosis algorithms (Nica et al., 2013). Nica et al. did not compare against our SAT-based approach,
as it uses pre-processing. In this work we show that the proposed pre-processing is very efficient
computationally and results in huge speedups during the search for a diagnosis. This form of preprocessing is a key ingredient which enables us to find very large minimal cardinality diagnoses,
even with sizes up to 31.
Another approach considers the diagnosis problem in terms of inductive learning. Here, one
tries to learn relations between the symptoms and the faults (Murray, Hughes, & Kreutz-Delgado,
2006). One disadvantage of most works in this approach is that they learn only a single fault rather
than multiple faults (Balakrishnan & Honavar, 1998). In addition, inductive learning methods do
not guarantee sound diagnoses nor completeness. We, on the other hand, propose a method which
addresses multiple faults and guarantees sound and complete minimal cardinality diagnoses.
Feldman et al. (2010a) propose a stochastic diagnosis algorithm, called SAFARI. Although this
method is not guaranteed to return diagnoses of minimal cardinality, it presents solutions which are
close to minimal cardinality in very low runtime. In Section 7, we demonstrate that our approach
outperforms SAFARI in terms of runtime, and also guarantees that minimal cardinality diagnoses
are returned.
Compilation-based methods have also been proposed in the MBD context. Torasso and Torta
(2006) proposed to compile the system description to a Binary Decision Diagrams (BDDs). Darwiche (2001) proposed to compile the system description into Decomposable Negation Normal
Form (DNNF). In both cases, the compiled model allowed finding minimal cardinality diagnosis
in time that is polynomial in the size of the compiled model. However, in these works, the size of
the compiled model (BDD or DNNF) may grow exponentially and is shown to become a bottleneck (Siddiqi & Huang, 2007).
Siddiqi and Huang (2007) suggest to optimize MBD by identifying components that dominate
others. We adopt this idea and apply it in our SAT-based approach. Another compilation-based
diagnosis algorithm is the HA* algorithm (Feldman & van Gemund, 2006). HA* is designed to
exploit a given hierarchy of the diagnosed system. This is done by converting a given system
hierarchy to a DNF hierarchy. Each element in this DNF hierarchy is then solved by a simple
best-first search using as a heuristic function given a prior probability on the health of the system
components. In Section 7, we demonstrate that our approach substantially outperforms HA*.
380

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

= {X1 , X2 , A1 , A2 , O1 }
OBS = {A, B, C, D, E}
COMPS

Figure 1: An MBD problem: A (faulty) full adder.
Another previously proposed approach imposes a tree structure over a given system description.
A system in a tree structure can be diagnosed by joining the diagnoses of its constituent subsystems.
El Fattah and Dechter (1995) obtained a tree structure by converting the diagnosed system into a
chordal graph and then decomposed it to a tree of maximal cliques. The TREE* algorithm is another
such tree-decomposition algorithm, initially proposed only for tree-structured systems (Stumptner
& Wotawa, 2001). TREE* was later generalized to perform on any system by embedding a hyper
tree over a specific representation of the diagnosed system (Stumptner & Wotawa, 2003). Follow up
work further generalized TREE* to support various forms of diagnosis optimization tasks, such as
finding minimal cardinality diagnoses, or finding subset minimal diagnoses, or finding most probable diagnoses (Sachenbacher & Williams, 2004). Note that the complexity of TREE* is exponential
in the width of the hyper-tree embedded in the system description as defined in these works.

3. Model-Based Diagnosis: Preliminaries
This section introduces the background on Model Based Diagnosis. In addition to the basic definitions, we review several other concepts from the literature that we build on in this paper.
Model Based Diagnosis problems arise when the normal behavior of a system is violated due
to faulty components as indicated by certain observations. We focus on weak fault models, which
ignore the mode of abnormal behavior of components. An MBD problem is specified as a triplet
hSD, COMPS , OBS i where: SD is a system description, COMPS is a set of components, and OBS is an
observation. The system description takes into account that some components might be abnormal
(faulty). This is specified by an unary predicate h() on components such that h(c) is true when
component c is healthy and false when c is faulty. Denoting the correct behavior of c as a propositional formula, c , SD is given formally as
^
SD =
h(c)  c
cCOMPS

Namely, each component which is not faulty follows its correct behavior. A diagnosis problem
arises when, under the assumption that none of the components are faulty, there is an inconsistency
between the system description and the observations (de Kleer & Williams, 1987; Reiter, 1987).
Definition 1 [Diagnosis Problem]. Given an MBD problem, hSD, COMPS , OBS i, a diagnosis problem
arises when
^
SD 
h(c)  OBS ` 
cCOMPS

381

fiM ETODI , S TERN , K ALECH & C ODISH

For example, a diagnosis problem arises for the MBD of Figure 1 as normal behavior would give
output E = 1. Once there is an inconsistency, a diagnosis algorithm tries to find a subset   COMPS
which, if assumed faulty, explains the observation.
Definition 2 [Diagnosis] Given an MBD problem, hSD, COMPS , OBS i, the set of components  
COMPS is a diagnosis if
^
^
h(c)  OBS 0 
SD 
h(c) 
c

c
/

We say that  is a minimal diagnosis if no proper subset 0   is a diagnosis, and that  is a
minimal cardinality diagnosis if no other diagnosis 0  COMPS exists such that |0 | < ||.
For the MBD of Figure 1, 1 ={X1 , X2 }, 2 ={O1 }, 3 ={A2 } are minimal diagnoses, and 2 ,
3 are minimal cardinality diagnoses, as there is no smaller diagnosis.
An important concept that we make use of in this paper is that of gate domination, used
for automatic test pattern generation (ATPG) (Kirkland & Mercer, 1987; Fujiwara, Member, Shimono, & Member, 1983) and in some modern SAT solvers (Marques-Silva, Lynce, & Malik, 2009),
sometimes under the name unique sensitization. Siddiqi and Huang (2007) applied gate domination in model-based diagnosis, introducing the notion of a cone. The following wording is
taken from Siddiqi and Huangs paper in a setting where the system is a Boolean circuit and the
components are its gates.
Definition 3 (Dominator and Cone) A gate X in the fan-in region of gate G is dominated by G and
conversely G is a dominator of X if any path from X to an output of the circuit contains G. The cone
corresponding to a gate G is the set of gates dominated by G. A maximal cone is one that is either
contained in no other cone or contained in exactly one other cone which is the entire circuit.
For example, in the circuit depicted as Figure 1, the components {A1 , A2 , O1 } form a cone, since
any path from A1 or from A2 to a system output contains O1 . Here O1 is the dominator and A1 and A2
are the dominated gates.
Although Definition 3 is stated in terms of Boolean circuits and logical gates, the notions of
dominators and cones can be generalized for many systems, where components correspond to gates,
and a component C1 dominates a component C2 if all of the paths passing through C2 also pass
through C1 . For example, in the system illustrated in Figure 3 components C1 and C2 form a cone,
where C2 dominates C1 .
The importance of cones to MBD algorithms is rooted in two observations presented by Siddiqi
and Huang. Firstly, cones are single-output sub-systems and as such, a minimal cardinality diagnosis will always, independent of the observation, indicate at most one unhealthy component per cone.
Secondly, if C is a cone in SD, then without loss of generality, we may assume that all dominated
components in C are healthy. This is correct because if X is unhealthy in some minimal cardinality
diagnosis and dominated by G, then G must be healthy. So, there exists another minimal cardinality
diagnosis where X is healthy and G is not. For example, in the circuit depicted in Figure 1, 3 is
a minimal cardinality diagnosis that signifies dominated A2 as unhealthy, and there exists another
minimal cardinality diagnosis, 2 , in which A2 is healthy but O1 , which dominates A2 , is unhealthy.
Based on these observations we can restrict the search for minimal cardinality diagnoses, to
so-called top-level minimal cardinality diagnoses. The notion of top-level diagnoses was introduced by Siddiqi and Huang.
382

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Definition 4 (top-level diagnosis (TLD)) We say that a minimal cardinality diagnosis is top-level
if it does not contain any dominated components.
To formally justify the focus on top-level diagnoses we make explicit the following Propositions 1 and 2, which are left implicit in previous work.
Proposition 1 Let 0 be a minimal cardinality diagnosis for a given MBD problem. Then there is
a top-level diagnosis , of the same cardinality.
Proof: Straightforward. To obtain , replace each dominated component from 0 by its corresponding dominator.

We further note that the set of all minimal cardinality diagnoses can be obtained by expanding the set of all top-level minimal cardinality diagnoses in the following sense: Given a minimal
cardinality top-level diagnosis,  = {c1 , . . . , c` } consisting of ` dominators from corresponding
cones {C1 . . . , C` }, denote
fi
n
o
fi
i = c0i  Ci fi  \ {ci }  {c0i } is a diagnosis
(1)
We say that  expands to the set of minimal cardinality diagnoses defined in terms of a crossproduct by: () = 1      ` . For example, consider the system from Figure 1 with the
observation OBS = {A, B, C, D, E}. The cones in the system are C1 = {X1 }, C2 = {X2 }, and C3 =
{A1 , A2 , O1 }. The corresponding MBD problem has two top-level minimal cardinality diagnoses,
1 = {X1 , O1 } and 2 = {X2 , O1 } and we have (1 ) = {X1 }  {O1 } = {{X1 , O1 }} and (2 ) =
{X2 }  {A1 , O1 } = {{X2 , A1 }, {X2 , O1 }}.
Proposition 2 0 is a minimal cardinality diagnosis if and only if there is a top-level minimal
cardinality diagnosis  that expands to include 0 .
Proof: The proof is straightforward from the construction.

Finally, we comment that the sets i which specify the expansion of a top-level diagnosis 
in Equation (1) are easy to compute: for each component c0i  Ci checking if  \ {ci }  {c0i } is
a diagnosis means propagating the observed inputs through the system, flipping the outputs when
propagating through a component in  \ {ci }  {c0i } and checking if there is no conflict to the
observed outputs. This observation is not explicit in previous work and it is essential to justify the
focus on top-level diagnoses. Proposition 2 is important as it applies for any diagnosis algorithm.
As such, diagnosis algorithms in general can focus, and be compared on finding TLDs, instead of
finding all minimal cardinality diagnoses.

4. The Standard Approach to SAT-Based MBD
The standard encoding of an MBD problem hSD, COMPS , OBS i to Boolean Satisfiability (as introduced in Smith et al., 2005) associates each component c  COMPS with a propositional formula,
c , denoting its correct behavior, and with a Boolean variable, Hc , signifying if c is healthy.
Viewing the observation as a propositional statement, an encoding is obtained by specifying
^
 = OBS 
Hc  c
(2)
cCOMPS

383

fiM ETODI , S TERN , K ALECH & C ODISH

In a satisfying assignment for , the health variables assigned the value false determine a (not
necessarily minimal) diagnosis .
For example, consider the MBD problem of Figure 1, and let comp(A, B, C) with
comp  {and, or, xor} denote the propositional formula describing the behavior of the component which is an and00 , or00 or xor00 gate with inputs A, B and output C. So, Equation (2) takes
the form:


A  B  C  D  E  HX1  xor(A, B, Z1 ) 


(3)
 =  HA1  and(A, B, Z2 )
 HX2  xor(Z1 , C, D)  
HA2  and(Z1 , C, Z3 )  HO1  or(Z2 , Z3 , E)
This formula is satisfied by the assignment of variables {A, C, HA1 , HA2 , HO1 } to true and of variables
{B, D, E, Z1 , Z2 , Z3 , HX1 , HX2 } to false. This assignment indicates that  = {X1 , X2 } is a diagnosis.
To obtain a minimal cardinality diagnosis we seek a satisfying assignment with a minimal number of health variables taking value false. For example the assignment of variables
{A, C, Z1 , Z3 , HX1 , HX2 , HA1 , HA2 } to true and of variables {B, D, E, Z2 , HO1 } to false which also satisfies Equation (3) and indicates only one faulty component. This can be achieved using a MAX-SAT
solver (Feldman et al., 2010), or using a SAT solver as done in the implementation underlying this
paper, where a cardinality constraint (encoded to CNF) is introduced to constrain the number of
faulty components as detailed in the next section.
No matter how the cardinality constraint is encoded to CNF, for a setting with |COMPS | = n and
a constant k, The formula
fi
n
o
fi
k =   sum leq( Hc fi c  COMPS , k)
(4)
is satisfied only if at most k of the n health variables take the value false. More specifically, we seek
a minimal value of k such that (the CNF corresponding to) k is satisfiable. This involves iterating
over calls to the SAT solver with formulae k for decreasing values of k until k is satisfiable but
k1 is not. This approach takes advantage of the fact that SAT solvers are typically incremental:
adding clauses to a satisfiable instance allows to solve again while maintaining all of the derived
information about the search space from the previous call.

5. Our Approach to SAT-Based MBD
Our approach to encoding an MBD problem hSD, COMPS , OBS i to SAT proceeds as follows: First, we
adopt a finite domain constraint based representation to express the basic model. Second, we analyze
the structure and substructures of the SD to introduce additional (redundant) constraints that will
later boost the search for a minimal cardinality analysis. Third, we introduce constraints to model
the given observation OBS with an additional constraint that imposes a bound on the cardinality
of the diagnosis (the number of unhealthy components). This additional constraint reduces the
subsequent number of iterations in search of the minimal cardinality diagnosis. Each such iteration
involves a call to the underlying SAT solver and hence has worst-time exponential complexity. So,
reducing this number is important. Given all of these constraints, we apply a finite domain constraint
compiler (Metodi & Codish, 2012; Metodi, Codish, & Stuckey, 2013) to simplify and encode them
to a corresponding CNF. Finally we apply a SAT solver to seek a suitable satisfying assignment
and solve the problem. In the rest of this section we describe these phases in more detail. An
384

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Figure 2: Modeling component c by composition with xor
experimental evaluation illustrating the impact of the various constraints in the model is presented
in Section 7.
5.1 The Basic Model for MBD
We build on the standard approach, as in Equation (2). However, we observe that for model based
diagnosis in the weak fault model with a single observation and when searching for a minimal
diagnosis, the behavior of a faulty component can be assumed to produce an output opposite to that
of its normal behavior. This is because any diagnosis that assumes that a component c is faulty but
still produces its normal output can be replaced by a smaller diagnosis that does not contain c. Thus,
if  is a minimal diagnosis (i.e, no subset of  is a diagnosis), this means that all the components
in  are assumed to produce the opposite of their normal output. In this paper we focus on minimal
cardinality diagnoses, which are in particular also minimal subset, so we modify Equation (2) as
follows, replacing the implication by a bi-implication.
 = OBS 

^

Hc  c

(5)

cCOMPS

We model the behavior (Hc  c ) of a possibly faulty component c as if encapsulated together
with a xor gate as illustrated in Figure 2. Here, the output of the encapsulated component is the
xor of the usual output of c and its negated health variable Hc . One can observe that if Hc is
true then this composition is equivalent to the normal behavior of c, otherwise it is equivalent to
component c with a negated output.
Our decision to model the relation between a component c and its health variable Hc by introducing an additional xor gate (instead of just introducing CNF clauses to directly encode Hc  c )
has two motivations: (1) to improve CNF encodings we provide tools to reason about, and simplify
system components  so there is an advantage to a uniform representation where all of the logic is
expressed in the system model itself; and (2) the underlying SAT solver that we apply, CryptoMiniSat (Soos, 2010), offers direct support for xor clauses. Because of (1) our MBD problem is more
amenable to simplification, and because of (2) the underlying SAT solver can optimize the search
for a satisfying assignment. We comment that it is straightforward to apply our technique with other
SAT solvers, which do not support xor clauses, by adding their CNF encodings to the model. The
finite domain constraint compiler, BEE (Metodi & Codish, 2012), which we apply, is configurable
to work with both types of solvers.
As in Equation (3), we write comp(A, B, C) with comp  {and, or, xor} to represent a component which is an and00 , or00 or xor00 gate with inputs A, B and output C. We also write
compH (A, B, C) to represent the corresponding encapsulated component with a health variable H.
So,
compH (A, B, C) = comp(A, B, C0 )  xor(H, C0 , C)
385

fiM ETODI , S TERN , K ALECH & C ODISH

and we view
compH (A, B, C)

(Constraints 1)

as a constraint on the Boolean variables A, B, C and H. Given this notation, the system depicted as
Figure 1 is modeled by the following constraints:
xorHX1 (A, B, Z1 )  andHA1 (A, B, Z2 )  xorHX2 (Z1 , C, D) 
andHA2 (Z1 , C, Z3 )  orHO1 (Z2 , Z3 , E)
Finally, we add to the constraints representing the system components an additional cardinality
constraint:
fi
o
n
fi
sum leq( Hc fi c  COMPS , k)
(Constraint 2)
to specify for an integer constant k that the number of faulty components must be at most k.
For example, for the system depicted as Figure 1 and a constant k, we introduce the constraint
sum leq({HX1 , HX2 , HA1 , HA2 , HO1 }, k). Later we will require to satisfy the constraints of the
model and also to minimize the value of k.
To summarize this presentation of the basic model, we show the complete constraint model
for the minimal cardinality diagnosis of the MBD problem of Figure 1. For an integer value k, a
solution of these constraints is a diagnosis of cardinality  k:
xorHX1 (A, B, Z1 )  andHA1 (A, B, Z2 )  xorHX2 (Z1 , C, D) 
andHA2 (Z1 , C, Z3 )  orHO1 (Z2 , Z3 , E) 
sum leq({HX1 , HX2 , HA1 , HA2 , HO1 }, k) 
A=1  B=0  C=1  D=0  E=0
This type of constraint model can be solved by encoding it to a CNF formula and then applying
a SAT solver. By repeatedly seeking a solution for decreasing values of k we can find a minimal
cardinality diagnosis. However, we do not apply this basic modeling. Instead we further refine it as
described in the rest of this section.
5.2 Encoding Cardinality Constraints
The encoding of cardinality constraints to CNF is the topic of a large body of research papers. Many
of these, such as that described by Een and Sorensson (2006), are based on the use of Batchers oddeven sorting network (Batcher, 1968). A sorting network is a Boolean circuit with n inputs and n
outputs. Given Boolean values on its inputs, the output consists of the same values but sorted: say,
zeroes before ones. In our context we apply such a sorting network where the n inputs are the health
variables of the n components in the given system, and the n outputs are the sorted values. Now, to
encode that at most k health variables take the value false we assert that the (k + 1)th output of the
sorting network is a one. Because its outputs are sorted this implies that the last n  k outputs are
also ones thus imposing that at most all of the k remaining outputs are zero. Looking backwards
through the sorting network this implies that at most k of its inputs take the value false.
Sorting networks, like other Boolean circuits are straightforward to encode to a CNF formula.
With Batchers odd-even construction this results in a CNF with O(n log2 (n)) clauses. Further
improvements enable an encoding with O(n log2 (k)) clauses to constrain the sum of the n Boolean
inputs to be less than k (Asn, Nieuwenhuis, Oliveras, & Rodrguez-Carbonell, 2009, 2011; Codish
386

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

& Zazon-Ivry, 2010). In this paper we encode cardinality constraints to CNF using BEE (Metodi &
Codish, 2012; Metodi et al., 2013) which takes such an improved approach.
5.3 From Cones to Sections
Reasoning about relations between the components in a system description SD enables to infer additional constraints on the number of unhealthy components in certain subsystems of SD. These
constraints when compiled into the CNF, help boost the search, by the SAT solver, for a minimal
cardinality diagnosis. Proposition 2 enables a diagnosis algorithm to focus on top-level diagnoses
based on a partitioning of the system into cones: each cone contains at most one unhealthy component, and without loss of generality, it can be assumed to be the dominator of the cone.
To restrict the SAT-based search to top-level minimal cardinality diagnoses we simply add the
following constraints where D denotes the set of dominated components.
V

(Constraint 3)

cD Hc

Introducing constraints to indicate healthy components reduces the number of (unassigned) health
variables and hence boosts the search for minimal cardinality diagnosis. In Section 7 we show that
reasoning about cones to restrict the search to top-level diagnoses improves considerably the search
for minimal cardinality diagnosis.
Motivated by the utility of partitioning a system into cones, we seek a more general partitioning,
which enables to apply similar cardinality constraints to larger subsystems of components. To this
end we introduce the notion of a section. We denote by sysout(c) the set of system outputs which
occur at the end of a path from a component c. As an example, in the system depicted in Figure 3
sysout(C1 ) = {O2 , O3 } and sysout(C5 ) = {O1 , O2 }.
Definition 5 (Section) Given a system description SD with components COMPS we define a disjoint
partitioning COMPS = S1  S2      Sn such that for every c1 , c2  COMPS , c1 and c2 are in the
same section Si if and only if sysout(c1 ) = sysout(c2 ).

C5
C1
C3

C2
C4

S1

S2

C6

S3

C7

C8

C9

C10

O1
S4

S5

O2

O3

Figure 3: Partitioning a system into cones and sections.
Figure 3 shows a partitioning of a system into maximal cones and sections. The cones are depicted with dotted lines, and the sections with dashed. For example, components {C1 , C2 } form a
cone, and section S1 consists of three cones. We observe that partitioning a system into sections can
be done in polynomial time as demonstrated by Algorithm 1 presented below. Given a partitioning
387

fiM ETODI , S TERN , K ALECH & C ODISH

{S1 , . . . , Sn } to sections, we introduce to the constraint model the following constraints which further improve the encoding and hence the subsequent search for minimal cardinality diagnosis. For
each section Si , the constraint
fi
o
n
fi
sum leq( Hc fi c  Si , bi )
(Constraints 4)
expresses that the sum of the negated health variables in Si is bounded from above by a constant bi
that is the smaller of the following two bounds on the number of unhealthy components in section
Si : (a) The number of outputs from Si ; and (b) The value of |sysout(c)| for some component
c  Si . Note that by Definition 5, this value is the same for any c  Si . We justify this statement
below in Proposition 3.
To illustrate the utility of sections, consider again the system given as Figure 3 and its partition
into 5 sections. Observe that the section labeled S1 has 3 outputs, but each component c  S1
has only 2 corresponding system outputs (|sysout(c)| = 2). So, b1 = min{3, 2} and hence 2
is an upper bound on the number of unhealthy components in S1 . This is also an improvement
over the reasoning with cones where the bound on the number of unhealthy components in S1 is 3
(since there are three cones). Similarly, b2 = min{1, 2}, b3 = min{1, 1}, b4 = min{1, 1} and
b5 = min{1, 1}.
Reasoning about constraints on the number of faulty components per section facilitates the
MBD encoding in another way. For Constraints 4 we have already encoded the number of faulty
components per section. These numbers are partial sums in the context of Constraint 2 which
specifies the total number of faulty components in the system and can be reused in the encoding.
The following justifies Constraints 4 .
Proposition 3 Let hSD, COMPS , OBS i be an MBD problem, S  SD be a section, c  S be a component and  be a minimal cardinality diagnosis. Then, both (a) the number of outputs from S, and
(b) the value |sysout(c)| are bounds on the number of unhealthy components (from ) in S.
Proof: The statement regarding the number of outputs from S follows directly from an assertion
by de Kleer (2008) that the number of outputs from any (sub-) system is a bound on the number of
its unhealthy components. So, it remains to prove the statement regarding |sysout(c)|.
Assume the premise of the proposition, denote || = k and |S  | = t (so t  k). Assume
for contradiction that t > |sysout(c)|. We construct a diagnosis 0 with less than k unhealthy
components. First note the obvious: that given  we can propagate the observed system inputs
to the system outputs where in each step we choose a component with known inputs and produce
its normal output if the component is healthy, or its opposite to normal output otherwise. Because
 is a diagnosis this process will result in no contradictions between propagated outputs and the
observed outputs.
Now, take 0 =  \ S. This is not (yet) a diagnosis. With 0 , propagate the observed system
inputs in the same way as before with . Now, because 0 is not a diagnosis there will be some
flipped system outputs (those which contradict the observed outputs). Each such flipped output
o must be due to one of the unhealthy components in S that was marked healthy in 0 and so we
have o  sysout(c). Now consider the component g which outputs o. If g  0 , then remove it;
and if g 6 0 , then add it. So, now 0 is a diagnosis and k 0 = |0 |  k  t + |sysout(c)| < k. 
Algorithm 1 describes how to partition a system into sections. Denoting the components and
outputs of the system as COMPS = {c1 , . . . , cn } and OUTS = {o1 , . . . , om }, an n  m Boolean
388

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

matrix b is computed so that bij = true if oj  sysout(ci ) and false otherwise. Figure 4 shows an
example of this matrix b for the system in Figure 3. So, by Definition 5, a pair of components ci , cj
are in the same section if and only if row i and row j in matrix b are identical. For instance, section
S5 includes the components C9 and C10 since their system output O3 is identical. The computational
complexity of this partitioning process is the complexity of running a graph search algorithm for
every system output and is in the worst case O(n2  m). The algorithm returns a mapping from
components to bit vectors which can be seen as section identifiers. So, the algorithm returns a
mapping of components to sections.
Algorithm 1 partitioning a system into sections
input: A system (view it as a graph)
output: A partitioning of the system into sections
= {c1 , . . . , cn }
the system components
OUTS
= {o1 , . . . , om } the system outputs
b
= (bij )
an n  m Boolean matrix
for all (oj  OUTS ) do
apply DFS on the reverse edges of the system, with source = oj
for all (ci  COMPS ) do
bij
fi oj )
	
 = (ci is reachable from
return ci 7 hbi1 , . . . , bim i fi 1  i  n

1: Denote:

2:
3:
4:
5:
6:

COMPS

Example 1 (partition into sections) Consider
the (abstract) system depicted as Figure 3 where COMPS = {c1 , . . . , c10 } and
OUTS = {o1 , . . . , o3 }. The Boolean matrix evaluated by application of Algorithm 1 is illustrated
in Figure 4.

Figure 4: Partitioning the system
from Figure 3 into sections
There is another benefit of partitioning into sections: the identification of cones may be performed per section which is more efficient. This works because, if component X is dominated by component G then sysout(X ) = sysout(G) implying that the components of a cone
are always in the same section. For example, in Figure 3 component C1 is dominated by C2 and
sysout(C1 ) = sysout(C2 ) = {O1 , O2 }.
The recursively defined Algorithm 2 shows how to compute cones given a partition into sections.
It computes the set of dominators for a component c in a section S of the system. We denote by
succ(c) the set of components that c feeds into directly. If c  S feeds into a component that is
not in S then it is only dominated by itself. Otherwise, c is dominated by c0  S only if c0 is
dominated by all elements of succ(c). For instance, given section S1 and component C1 in Figure 3
succ(C1 ) = {C2 }. In the next recursive call succ(C2 ) does not include any component of S1
389

fiM ETODI , S TERN , K ALECH & C ODISH

(condition in line 2) and thus C2 is returned (line 5). The union of both calls (C1 , C2 ) is returned as
a cone (line 3).
It is straightforward to implement Algorithm 2 efficiently using a memoization table to avoid
recomputing dominators for components already encountered. Since a system is a directed acyclic
graph, the recursion in Algorithm 2 will halt when a leaf node is reached. Thus the complexity of
calculating the dominators of every component c in a section S is O(|S|2 ). Given the sets of dominators per component, it is straightforward to specify the set of maximal cones. A component c is a
dominator of a maximal cone, if it is only dominated by itself, and the maximal cone corresponding
to such a c is the set of components which have c as dominator.
To find all cones in a system, Algorithm 2 is applied once per component per section, and the
cost depends on the size of the largest section. In contrast, without the partition into sections, the
same algorithm is applied, but considering all of the components in the system instead of all the
components in a section. Practice shows that the partition into sections benefits the computation of
cones.
Algorithm 2 dominators (component c, section S, system C)
input: component c in section S of system C
output: The set of dominators of c
fi

	
1: Denote: succ(c) = c0  C fi the output of c is an input to c0
2: if (succ(c)  S) then \
3:
return {c} 
dominators(c0 , S, C)
c0 succ(c)

4: else
5:
return {c}

5.4 Modeling the Observation and Further Boosting the Search
Let OBS + and OBS  denote the sets of variables assigned true and false in OBS , respectively. Then,
to model the observation we add the obvious constraints.
V
V
(Constraint 5)
xOBS  x
xOBS + x 
To improve the search for a minimal cardinality diagnosis one can introduce an upper bound
on the minimal cardinality: the number of outputs in a system is an upper bound on the minimal
cardinality (de Kleer, 2008). Such a bound, as well as the section-specific constraint given above
(Constraints 4 ) ignores the observed inputs and outputs. Siddiqi and Huang (2011) propose to
obtain a tighter upper bound on the minimal cardinality for a given observation by propagating
the input values through the system, and taking as an upper bound the number of contradictions
between the observed and the propagated outputs. For example, considering the MBD problem
from Figure 1, k = 2 is an upper bound on the size of a minimal cardinality diagnosis because the
system has 2 outputs. Siddiqi and Huangs proposal states that also 1 is an upper bound because
when propagating the inputs through the system there is only one contradiction to the observed
outputs.
While Siddiqi and Huangs (2011) proposal is intuitively appealing, it is correct only in case
that no observed output is also input to another component, and in fact their results are restricted
to systems where this is the case. This does not work for the example in Figure 5. Propagating the
390

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Figure 5: Minimal cardinality diagnosis is of size 2, but propagating observed inputs leads to 1
contradiction to the observed outputs.
observed inputs through the system assigns 0 to both outputs indicating a single contradiction with
the observation (on O1 ). However, the smallest diagnosis for this example has cardinality 2. This
example is not contrived: 83 of the 350 observations for system 74181 of the 74XXX benchmark,
exhibit a minimal cardinality diagnosis larger than the (erroneous) bound obtained when counting
conflicts between propagated and observed outputs.
Algorithm 3 is about computing an upper bound on the number of faulty components by propagating observed inputs and counting conflicts. The algorithm computes a diagnosis , and || is
thus an upper bound on the minimal cardinality of a diagnosis. The basic idea is to propagate inputs
as long as they do not contradict observed, or other already computed, outputs. The components
in the system are processed one at a time. At line 3 we select some component c whose inputs
are already determined (initially only the system inputs are determined). For this c we consider its
already determined output, oobs , and denote oobs =  if its output is not yet determined. We also
consider its propagated output oprop which is obtained by propagating the inputs through c assuming that c is healthy. Now there are three cases (lines 610): if c has no already determined output
then we fix its output to oprop and mark c as healthy. If c has an already determined output and it
is consistent with oprop then we also mark c as healthy. Otherwise we mark c as not healthy, but do
not propagate its output (which is already determined).
Algorithm 3 Find a diagnosis  (and upper bound || on min. card.)
input: A system with components, COMPS , and observation, OBS
output: A diagnosis 
1: C  COMPS ,  = 
2: while (C 6= ) do
3:
select c  C such that the inputs of c are determined
4:
oobs  the value on the output of c (N/A if it is undefined)
5:
oprop  the value if propagating the inputs of c (assume c is healthy)
6:
if (oobs = N/A then
7:
set output of c to oprop and mark c as healthy
8:
else if (oobs = oprop ) then
9:
mark c as healthy
10:
else
11:
mark c as faulty and  =   {c}
12:
C  C \ {c}
13: Return 

When Algorithm 3 terminates we have marked all components as healthy or faulty and have
in fact determined a correct diagnosis. As such applying Algorithm 3 provides an upper bound
on a minimal cardinality diagnosis  the number of components marked as faulty in the returned
diagnosis. Note that Algorithm 3 is correct also when given probes (observed values on the outputs
391

fiM ETODI , S TERN , K ALECH & C ODISH

from internal components). Assuming that the components are maintained in a data-structure where
components are sorted (topologic) according to their depth, Algorithm 3 is performed as a single
linear traversal of this data-structure with complexity O(|COMPS |).
As an example application of Algorithm 3, consider the circuit in Figure 5. Propagating the
inputs of gate A1 gives the output 0 in contradiction to the observation on O1 . Hence, we mark A1 as
unhealthy and propagate the observation O1 = 1 as an input to A2 together with I3 = 1. This results
in an additional contradiction to the observation O2 = 0 and so we mark A2 as unhealthy too, and
report  = {A1 , A2 } hence the value 2 as an upper bound for the minimal cardinality.
Let kUB be the bound found by application of Algorithm 3. We refine Constraint 2 and introduce
instead:
fi
n
o
fi
sum leq( Hc fi c  COMPS , kUB )
(Constraint 20 )
To appreciate the impact of Algorithm 3 we note that, for the benchmark considered in this
paper, Algorithm 3 determines an upper bound equal to the actual minimal cardinality for 81% of
the 28,527 observations considered. Of course, even when given a precise upper bound, an MBD
algorithm still needs to validate its minimality. In our SAT-based approach this requires one single
iteration with the underlying SAT solver. Typically, this is the hardest iteration as it involves a call
which is unsatisfiable and is of the largest cardinality for which the instance is unsatisfiable.
5.5 Compiling Constraints to CNF
Metodi and Codish (2012) introduced a compiler called BEE that encodes finite domain constraints
to CNF. Besides facilitating the encoding process, this compiler also applies partial evaluation and
other optimizations to simplify the constraints before encoding them to CNF. In particular, it applies
equi-propagation (Metodi, Codish, Lagoon, & Stuckey, 2011) which is the process of identifying
equalities between literals (and constants) implied by other such equations and a given constraint.
If X=L is implied by a constraint (where X is a variable and L is a literal or a Boolean constant), then
all occurrences of X can be replaced by L, reducing the number of variables in the subsequent CNF
encoding. We illustrate constraint simplification for the diagnosis of the circuit in Figure 1. Consider
the following constraints (we have omitted some of the constraints as they do not contribute to the
example):
(1)
(2)
(3)
(4)
(5)

xorHX1 (A, B, Z1 )  andHA1 (A, B, Z2 )  xorHX2 (Z1 , C, D) 
andHA2 (Z1 , C, Z3 )  orHO1 (Z2 , Z3 , E) 
sum leq({HX1 , HX2 , HA1 , HA2 , HO1 }, k) 
A=1  B=0  C=1  D=0  E=0
HA1 = 1  HA2 = 1

The constraints on lines (1)  (3) comprise the basic constraint model described in Section 5.1; the
constraints on line (4) model the observation; and the constraints in line (5) express that without
loss of generality the dominated components {A1 , A2 } from the cone {A1 , A2 , O1 } are healthy. We
observe the following equi-propagation steps:
1. (A = 1)  (B = 0)  xorHX1 (A, B, Z1 ) |= (Z1 = HX1 )
2. (A = 1)  (B = 0)  (HA1 = 1)  andHA1 (A, B, Z2 ) |= (Z2 = 0)
392

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

3. (C = 1)  (HA2 = 1)  andHA2 (Z1 , C, Z3 ) |= (Z1 = Z3 )
4. (C = 1)  (D = 0)  xorHX2 (Z1 , C, D) |= (Z1 = HX2 )
5. (E = 1)  (Z2 = 0)  orHO1 (Z2 , Z3 , E) |= (Z3 = HO1 )
From these (and the other given) equalities between literals we obtain a substitution:
)
(
A 7 1, B 7 0, C 7 1, D 7 0, E 7 0, Z1 7 HX1 , Z2 7 0,
=
Z3 7 HX1 , HX2 7 HX1 , HA1 7 1, HA2 7 1, HO1 7 HX1
Applying  to specialize the constraint system we get:
(1)
(2)
(3)
(4)
(5)

xorHX1 (1, 0, HX1 )  and1 (1, 0, 0)
 xorHX1 (HX1 , 1, 0) 
and1 (HX1 , 1, HX1 )  or(HX1 ) (0, HX1 , 0) 
sum leq({HX1 , HX1 , 0, 0, HX1 }, k) 
1=1  0=0  1=1  0=0  0=0
1=1  1=1

Now, most of the constraints are tautologies and we remove them. All that remains is a single
constraint:
(3) sum leq({HX1 , HX1 , HX1 }, k)
which is satisfied for k = 1 when HX1 = 1, and as implied from  then we have
HA1 = 1, HA2 = 1, HX2 = 1, HO1 = 0. This example illustrates how equi-propagation and partial evaluation are applied to simplify constraints prior to their encoding to CNF.
We summarize with the following observations:
1. The constraint model for MBD is polynomial in the size of the system: each component
contributes a constraint and a fresh health variable, each cone contributes an assignment to
the health variables for its dominated components, each section contributes a cardinality constraint, and finally the observation contributes an assignment to the input and out variables of
the system.
2. Constraint simplification using BEE is polynomial in the size of the constraint model. This is
because: (a) each simplification step reduces the number of Boolean variables in the model by
at least one  so there are a linear number of steps, and (b) each step checks the applicability
of a fixed number of simplification patterns to each constraint.
3. The CNF encoding of the constraint model is polynomial in size, as each of the constraints
introduces a polynomial number of clauses to the CNF (all of the constraints supported by
BEE have this property).

6. Process and Implementation
In this section we summarize the different phases of the diagnosis process in our approach. In
Section 6.1 we focus on the case where we seek a single minimal cardinality diagnosis, and then in
Section 6.2, on the case when we seek all minimal cardinality diagnoses.
393

fiM ETODI , S TERN , K ALECH & C ODISH

6.1 Single Minimal Cardinality Diagnosis
The process for a single minimal cardinality diagnosis consists of four phases. Let  =
hSD, COMPS , OBS i be an MBD problem. In the first two phases we construct a constraint model.
First, focusing on SD, to introduce constraints which are independent of the observation, and then
per observation to introduce further constraints. In the third phase we encode the constraint model
to a CNF, k where k is an upper bound on the size of the minimal cardinality diagnosis. In the
fourth phase, solving k using a SAT solver results in a diagnosis with cardinality at most k. We
now detail these four phases.
Phase 1. Modeling the system (offline): The system SD is first preprocessed to partition it into
sections (Algorithm 1) and cones (Algorithm 2). Then, we introduce Constraints 1 to model SD in
terms of its components behavior and introduce Constraints 4 to bound the number of unhealthy
components per section. Finally, using information about cones, we add Constraint 3 which asserts
that, without loss of generality, all dominated components are healthy. All of the system preprocessing is performed offline, once per system.
Phase 2. Modeling the observation (online): Constraint 5 is added to model the observation
and Constraint 20 is added to bound the total number of unhealthy components by the upper
bound kUB obtained by application of Algorithm 3.
OBS ,

Phase 3. Encoding: The constraint system is then simplified online, for each observation and
encoded to a CNF k , applying the optimizing CNF compiler (Metodi et al., 2011). The parameter k
reflects the bound set in Constraint 20 to bound the number of unhealthy components in a diagnosis.
Initially, k is computed by Algorithm 3.
Phase 4. Solving: To compute a diagnosis, , we seek a satisfying assignment for the encoding, k ,
by applying the CryptoMiniSat solver (Soos, 2010).  is then the set of health variables assigned
false by this assignment. Denoting || = k 0 , we again seek a satisfying assignment, but this time
0
for the formula k 1 . If a satisfying assignment is found, it indicates a smaller diagnosis, 0 .
Otherwise,  is of minimal cardinality. This process is invoked repeatedly, each time finding a
0
smaller diagnosis, until for some k 0 the formula k 1 is not satisfiable. Then, the diagnosis found
in the previous iteration is of minimal cardinality.
To facilitate the search for a minimal cardinality diagnosis, we apply the SAT solver wrapper, SCryptoMiniSat (Metodi, 2012b). SCryptoMiniSat takes as input a CNF formula (k ) and
the Boolean variables representing the number k. It provides a satisfying assignment which minimizes k. SCryptoMiniSat takes advantage of the incrementality of the underlying SAT solver which
maintains learned clauses over consecutive calls which only add clauses.
Algorithm 4 illustrates the process of finding a single minimal cardinality diagnosis (identified
at line 17), and of returning the set of all minimal cardinality diagnoses (line 23).
6.2 All Minimal Cardinality Diagnoses
To find all minimal cardinality diagnoses we first apply the process described in Section 6.1 to find
a single minimal cardinality diagnosis. This provides us with the value k 0 indicating the number of
faulty components in a minimal cardinality diagnosis.
Then, to enumerate the set of all top-level minimal cardinality diagnoses (each of size k 0 ) we
apply an additional functionality of SCryptoMiniSat which allows to enumerate (possibly with a
394

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Algorithm 4 SATbD
input: A system SD with components COMPS and an observation OBS
output: , the set of minimal cardinality diagnoses
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:

// Phase 1: Offline pre-processing

Sections  partition SD into sections
Constraints  
for all (S  Sections) do
for all (c  S) do
Add Constraints 1 to Constraints
Dominators  dominators(c, S, SD)
if |Dominators| > 1 then
Add Constraint 3 for component c to Constraints

// Algorithm 1

// describes normal behavior of component c
// Algorithm 2
// sets dominated gates to healthy

// Phase 2: Modeling the observation

Add Constraint 5 to Constraints
  Find initial diagnosis
Add Constraint 20 to Constraints with kUB = ||

// add constraints representing OBS
// Algorithm 3

// Phase 3: Encoding

  BEE(Constraints)

// run the constraint compiler to obtain a CNF

// Phase 4: Solving

MC  SCryptoMiniSatMinimize(k,)

// find min. card. diagnosis (assignment that minimizes k = ||MC )

// Finding all diagnoses of minimal cardinality

    cnf(kUB = |M C |)
  , T LD  SCryptoMiniSatAllSolutions()
for all (  T LD ) do
Add to  all the diagnoses expanded from 
return 

395

// restrict Constraint 20 to use kUB = |M C |
// find all top-level diagnoses
// Proposition 2

fiM ETODI , S TERN , K ALECH & C ODISH

Name
74181
74182
74283
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

|COMP|
65
19
36
160
202
383
546
880
1193
1669
2307
2416
3512

System Details
in
out
offline
14
8
0.02
9
5
0.01
9
5
0.01
36
7
0.03
41
32
0.08
60
26
0.06
41
32
0.24
33
25
0.37
233 140
0.29
50
22
0.71
178 123
1.50
32
32
1.48
207 108
1.73

Feldman
#obs.
350
250
202
301
835
1182
836
846
1162
756
2038
404
1557

DXC-09

1-10

11-20

21-30

100
100
100
100
93
44
87
93
66
98
47
100
49

0
0
0
0
7
44
13
7
34
2
45
0
46

0
0
0
0
0
12
0
0
0
0
8
0
5

#obs.
54
50
30
45
141
198
98
127
168
36
248
1
176

1-10

11-20

21-30

100
100
100
100
73
41
79
74
52
100
43
100
45

0
0
0
0
27
40
21
26
43
0
40
0
41

0
0
0
0
0
19
0
0
5
0
17
0
14

Sidd.
#obs.
700
400
800
800
800
800
40
40
40

Table 1: The Benchmark suite: systems 74XXX and ISCAS-85, and observations: Feldman, DXC-09
and Siddiqi.

specified time-out) all, or a specified number of, satisfying assignments for a given CNF. We apply
this option to enumerate all satisfying assignments for the formula, k described in Section 6.1 with
k = k0 .
Finally, based on Proposition 2 we expand the obtained top-level diagnoses to provide all minimal cardinality diagnoses. Note that the observation that a TLD can be expanded easily to all
minimal cardinality diagnoses applies for any diagnosis algorithm. As such, diagnosis algorithms
in general can focus, and be compared on finding TLDs, instead of finding all minimal cardinality
diagnoses.

7. Experimental Results
This section presents an experimental evaluation of our proposed SAT-based encoding for MBD.
In Section 7.1, we consider the search for a single minimal cardinality diagnosis and compare the
performance of SATbD to the algorithms: HA* (Feldman & van Gemund, 2006), CDA* (Williams
& Ragno, 2007) and SAFARI (Feldman et al., 2010a). In Section 7.2, we consider the search for
all minimal cardinality diagnoses and compare SATbD to the algorithms: HDIAG (Siddiqi & Huang,
2007) and DCAS (Siddiqi & Huang, 2011). Finally, in Section 7.3, we evaluate the impact of the
various components of our SAT-based encoding of MBD. All experiments were run on an Intel Core
2 Duo (E8400 3.00GHz CPU, 4GB memory) under Linux (Ubuntu lucid, kernel 2.6.32-24-generic)
unless stated otherwise. The entire set of our tools, range of benchmarks, as well as a more detailed
report of the results can be found online (Metodi, 2012a; Metodi, Stern, Kalech, & Codish, 2012b).
Table 1 provides basic details concerning the systems and three observation sets in our benchmark suite. The systems are 74XXX (Hansen, Yalcin, & Hayes, 1999), described in the first 3 rows,
and ISCAS-85 (Brglez et al., 1989), described in the following 10 rows. The left column in the
table specifies the system name. The next four columns (from the left) describe the systems: the
numbers of components, inputs and outputs in each of the systems, and also the preprocessing time
per system for the SAT-based approach. This includes all actions performed once per system as
described in Section 6.1: decomposing the system to sections and cones and computing the bounds
per section.
396

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

The rest of the columns are divided to three groups describing experiments with the three observation sets. The first two describe the observation set generated by Feldman et al. (2010a) and
the DXC-09 observation set used in the diagnosis competition (DXC) of 2009. These are applied in
our experimentation to evaluate the search for a single minimal cardinality diagnosis. The minimal
cardinality of the diagnoses in these observations is between 1 and 30. The columns in each of these
two groups indicate the number of observations and a distribution of the observations according to
the size of their minimal cardinality diagnoses. The observations in these sets are considered hard
and many of them, have high minimal cardinality diagnoses. The third group (the rightmost column
in the table) presents the observation set generated by Siddiqi and Huang (2011) where minimal
cardinality is bounded by 8 and the observations are distributed uniformly according to the size of
their minimal cardinality diagnoses. This set is used in the evaluation of the search for all minimal
cardinality diagnoses.
Table 1 illustrates a comprehensive experimental benchmark involving a total of 28,527 observations of varied minimal cardinality diagnosis size. Observe also that the (offline) preprocessing
time per system is negligible. For instance, reprocessing the largest system, c7552, takes less than
two seconds.
7.1 SATbD vs. Other MBD Algorithms: Single Minimal Cardinality Diagnosis
We now compare SATbD to the algorithms: HA* (Feldman & van Gemund, 2006), CDA* (Williams
& Ragno, 2007) and SAFARI (Feldman et al., 2010a) in their application to search for a single minimal cardinality diagnosis. HA* and CDA* are based on a complete algorithm to find all minimal
subset diagnoses  those that do not contain other diagnoses. They can be configured such that the
first minimal subset diagnosis is guaranteed to be also of minimal cardinality and it is this configuration that we apply for comparison with SATbD. SAFARI applies an algorithm based on stochastic
search which does not guarantee minimal cardinality and not even minimal subset diagnosis. Feldman et al. (2010a) report that even for single and double fault cardinalities, SAFARI does not always
find the minimal cardinality. So, at the expense of minimality, SAFARI is often faster, comparing to
HA* and CDA*.
Name

HA*
Succ.
Time
rate%
Sec.

74181
68.3
74182
100.0
74283
100.0
c432
78.1
c499
24.1
c880
11.9
c1355
11.4
c1908
6.4
c2670
12.3
c3540
3.7
c5315
2.7
c6288
13.6
c7552
4.2
80 sec timeout
c7552
7.3

CDA*
Succ.
Time
rate%
Sec.

Succ.
rate%

SAFARI
Min Diag.
card.%
ratio

3.15
0.00
0.04
3.63
5.45
3.76
3.90
1.75
4.83
4.30
11.94
7.87
1.06

46.3
100.0
100.0
38.2
10.1
6.3
0.0
0.0
0.0
0.0
0.0
0.0
0.0

4.51
0.01
1.45
5.15
1.22
6.66
-

100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
53.5
0.0

44.0
91.0
57.0
28.0
7.0
48.0
5.0
17.0
14.0
9.0
9.0
25.0
-

20.77

0.0

0.0

99.5

13.0

Time
Sec.

SATbD
Succ.
Time
rate%
Sec.

1.33
1.04
1.28
1.68
2.00
1.09
1.96
1.92
1.52
2.06
1.96
7.88
-

0.00
0.00
0.00
0.03
0.05
0.18
0.37
1.08
2.71
5.25
13.34
16.18
-

100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
99.3

0.02
0.01
0.02
0.03
0.04
0.05
0.07
0.14
0.15
0.27
0.42
0.56
1.07

1.68

43.50

100.0

1.49

Table 2: Single minimal cardinality diagnosis, Feldmans observations (30 sec. timeout).
397

fiM ETODI , S TERN , K ALECH & C ODISH

Algorithm
System
74181
74182
74283
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

Min
0.00
0.00
0.00
0.00
0.02
0.01
0.04
0.44
0.05
0.22
0.19
0.21
0.47

HA*
Max
29.40
0.00
0.76
29.53
21.43
29.43
22.12
14.78
27.91
29.42
29.68
28.32
9.47

St. dev.
6.04
0.00
0.08
6.33
5.03
6.70
3.88
2.51
6.88
6.26
11.98
8.38
1.86

Min
0.00
0.00
0.00
0.04
0.88
0.24
-

CDA*
Max
St. dev.
29.01
7.30
0.08
0.02
28.14
2.79
26.26
7.00
1.55
0.21
29.87
8.18
-

Min
0.00
0.00
0.00
0.02
0.04
0.14
0.32
0.95
2.44
4.78
12.24
13.27
30.00

SAFARI
Max
St. dev.
0.01
0.00
0.00
0.00
0.00
0.00
0.03
0.00
0.06
0.00
0.21
0.01
0.43
0.02
1.19
0.04
3.03
0.09
6.20
0.16
14.68
0.36
30.96
4.78
30.22
0.01

Min
0.00
0.00
0.00
0.00
0.01
0.01
0.02
0.03
0.04
0.06
0.09
0.10
0.14

SATbD
Max
St. dev.
0.03
0.01
0.02
0.00
0.03
0.01
0.05
0.01
0.07
0.01
0.14
0.01
0.10
0.02
0.52
0.04
0.22
0.04
0.84
0.10
5.93
0.31
1.27
0.22
24.30
2.03

Table 3: Single minimal cardinality diagnosis, Feldmans observations, additional statistics.
Table 2 presents the evaluation focusing on Feldmans observations imposing a 30 second timeout (except for the bottom line). The columns indicate for each algorithm, the percentage of observations solved within the prescribed timeout (Succ. rate %) and the average search time (Time
Sec.) where the average is computed over the set of observations excluding timeouts. For SATbD,
the search time: (1) includes all actions performed once per observation as described in Section
6.1 (Modeling the observation (online)); (2) Excludes the cost of actions performed once per system as described in Table 1 of Section 6.1 (column offline); and (3) includes times for adding the
observation and the cardinality constraints, encoding to CNF and solving with SCryptoMiniSat.
The results in Table 2 show clearly that SATbD outperforms all of the other evaluated algorithms,
both in terms of success rate as well as in terms of average runtime. SATbD also outperforms
SAFARI which succeeds to compute a diagnosis for almost all of the systems. However, only a
small percentage of these are of minimal cardinality as indicated by the column Min card%
which shows the percentage (excluding timeouts) of observations where the diagnosis found by
SAFARI is actually of minimal cardinality. We also show, in the column titled Diag. ratio,
the ratio between the average cardinality of the diagnoses found by SAFARI and the average minimal
cardinality. So for example looking at the data for system 74181, 44% of the diagnoses found by
SAFARI are minimal, and the average diagnosis size found is 1.33 times larger than the average
size of the minimal cardinality diagnosis. We observe that SATbD computes and verifies minimal
cardinality diagnoses even for observations with a minimal cardinality of 30. To the best of our
knowledge, no algorithm before succeeded to compute minimal cardinality diagnosis for such hard
observations.
Table 3 details additional statistics for the running times presented in Table 2, showing the
minimum, maximum, and standard deviation of the runtime for the solved observations. As can
be seen, the standard deviation of SATbD is very small compared to the other algorithms. The
displayed statistics are only over cases solved within the 30 second timeout. Table entries with
- mark cases where the corresponding algorithms could not find a minimal cardinality diagnosis
(within the timeout) even for a single observation.
Observe in Table 2 that 99.3% of the 1,557 observations for system c7552 are solved by SATbD
within the 30 second timeout (only 11 observations are not solved). All of the observations are,
however, solved within 80 seconds each, as indicated by the last row in the table. One may observe
that while SATbD solves all observations given 80 seconds, the other algorithms are still not able to
398

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

solve all of them, with the exception of SAFARI. Given the extended 80 seconds timeout, SAFARI
is also able to solve almost all of the observations for this system, but returns minimal cardinality
diagnoses only in 13% of the cases, and in average, the size of the diagnosis found by SAFARI is
1.68 times larger than the actual minimal cardinality.
Name

HA*
Succ.
Time
rate%
Sec.

CDA*
Succ.
Time
rate%
Sec.

Succ.
rate%

SAFARI
Min
card.%

Time
Sec.

SATbD
Succ. Time
rate%
Sec.

74181
74182
74283
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c6288
c7552

94.4
100.0
100.0
75.6
12.8
10.1
9.2
7.1
11.3
11.1
1.2
100
2.3

57.4
100.0
100.0
40.0
5.7
4.5
0.0
0.0
0.0
0.0
0.0
0.0
0.0

100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
0.0

65
90
80
22
3
48
4
14
18
31
7
100
-

0.00
0.00
0.00
0.03
0.05
0.18
0.38
1.12
2.85
5.83
13.12
25.28
-

100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0
100.0

3.86
0.00
0.01
3.70
4.81
5.51
3.33
3.10
5.86
1.23
19.77
0.24
0.47

5.19
0.01
0.32
7.17
1.20
9.66
-

0.02
0.00
0.01
0.03
0.05
0.05
0.07
0.20
0.14
0.29
0.62
0.1
1.01

Table 4: Single minimal cardinality diagnosis, DXC-09 observations (30 sec. timeout).
Table 4 shows the evaluation for the DXC-09 benchmark and is in the same format as Table 2
(except that we omit the details regarding the size of the diagnoses found by SAFARI). The results
exhibit the same trend: our SAT-based method is substantially faster than all of the previous algorithms. Note that this benchmark even contains observations with minimal cardinality diagnoses of
31 (!), which were also solved by SATbD under the 30 seconds timeout. Table 5 provides additional
statistics for these runtimes in the same format as in Table 3. Here too, we see a small standard
deviation for SATbD compared to the other algorithms. Note that the data for the c6288 system is
not given, as there is only a single observation for this system in the DXC-09 observation set.
Figure 6 details the evaluation for a single minimal cardinality diagnosis with Feldmans observations for four systems (from smaller to larger). For each system we plot the average runtime
to find a single minimal cardinality diagnosis (including timeouts) as a function of the value of
the minimal cardinality. The black diamond labeled Timeout marks the time limit, after which
algorithms were halted.
Typically, the diagnosis problem becomes harder as the minimal cardinality increases. First
consider the three plots in Figures 6a, 6b and 6c. The two upper curves correspond to the systems
HA* and CDA* and they quickly converge to the 30 seconds timeout. The curves for SAFARI are
more or less constant but only a minority of the diagnoses are actually of minimal cardinality (7%
in c499, 48% in c880 and 9% in c5315). The performance of SAFARI is not affected by the
cardinality since it first finds an arbitrary diagnosis and then proceeds stochastically to minimize the
diagnosis using a pre-defined number of attempts. This process involves consistency checks which
are affected only by the size of the system and not by the cardinality of the diagnosis.
Now consider the plot in Figure 6d where we omit the curves for HA* and CDA* as they depict
a constant 80 second timeout. The performance of SAFARI is more or less constant (around the
average 43.5 seconds) but only 13% of the diagnoses found are actually of minimal cardinality. In
contrast, SATbD is considerably faster and scales to solve even the hardest observations.
399

fiM ETODI , S TERN , K ALECH & C ODISH

Algorithm
System
System
74181
74182
74283
c432
c499
c880
c1355
c1908
c2670
c3540
c5315
c7552

Min
Min
0.00
0.00
0.00
0.00
0.01
0.01
2.74
0.85
0.05
0.31
9.86
0.47

HA*
Max
Max
27.26
0.00
0.02
23.06
11.34
29.60
6.52
15.34
26.04
3.44
28.39
0.47

St. dev.
St. dev.
6.70
0.00
0.01
5.98
4.99
8.34
1.20
4.63
8.06
1.49
9.34
0.00

CDA*
Max
St. dev.
Max
St. dev.
20.12
7.44
0.08
0.02
1.22
0.40
26.14
8.75
1.42
0.16
20.33
8.97
-

Min
Min
0.00
0.00
0.01
0.05
0.93
0.27
-

SAFARI
Max
St. dev.
Max
St. dev.
0.01
0.00
0.00
0.00
0.00
0.00
0.04
0.00
0.07
0.01
0.24
0.01
0.42
0.02
1.25
0.05
3.07
0.11
6.18
0.16
14.11
0.32
-

Min
Min
0.00
0.00
0.00
0.03
0.04
0.16
0.34
1.00
2.56
5.53
12.10
-

Min
Min
0.00
0.00
0.00
0.01
0.01
0.02
0.02
0.03
0.05
0.06
0.10
0.17

SATbD
Max
St. dev.
Max
St. dev.
0.03
0.01
0.02
0.00
0.03
0.01
0.04
0.01
0.07
0.01
0.07
0.01
0.09
0.02
1.36
0.16
0.21
0.03
0.84
0.20
10.06
0.90
11.54
1.54

100 Timeout

100

Time (sec.), log scale

Time (sec.), log scale

Table 5: Single minimal cardinality diagnosis, DXC-09 observations (30 sec. timeout), additional
statistics.

10
CDA*

HA*

Safari

SATbD

1
0.1

10
CDA*

HA*

Safari

SATbD

1
0.1

0.01

0.01
1

3

5
7
9
11
Minimal Cardinality

13

15

1

(a) System c499 (30 sec. timeout).
100

Time (sec.), log scale

10
CDA*

HA*

Safari

3

5

7

9 11 13 15 17 19 21 23 25
Minimal Cardinality

(b) System c880 (30 sec. timeout).

100 Timeout

Time (sec.), log scale

Timeout

SATbD

1

Timeout

10

Safari

SATbD

1

0.1

0.1

0.01

0.01
1

3

5

7

9 11 13 15 17 19 21 23 >24
Minimal Cardinality

1

(c) System c5315 (30 sec. timeout).

3

5

7

9 11 13 15 17 19 21 >22
Minimal Cardinality

(d) System c7552 (80 sec. timeout).

Figure 6: Single minimal cardinality diagnosis, Feldmans observations, average search time per
size of the minimal cardinality diagnosis.

The results of this section clearly indicate that our SAT based approach outperforms the other
three algorithms in the search for a single minimal cardinality diagnosis.
400

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Name
c432
c499
c880
c1355
c1908
c2670
c5315
c6288
c7552

IntelXeon X3220, 2.4GHz, 2Gb RAM
HDIAG
DCAS
Succ.
Time
Succ.
Time
rate%
Sec.
rate%
Sec.
100.0
0.21
100.0
0.31
100.0
0.12
100.0
0.20
99.0
0.07
99.0
0.12
99.5
0.16
99.5
0.15
90.5
368.13
76.5
82.25
90.0
176.17
100.0
3.15
0.0
97.5
52.34
0.0
27.5
305.10
0.0
87.5
260.93

Intel Core 2-Duo E8400, 3.00GHz, 4GB RAM
SATbD
Succ.
TLD
Time
TLD
ALL
rate%
Sec.
Sec.
count
count
100.0
0.07
0.09
7.9
72
100.0
0.08
0.10
2.4
345
100.0
0.08
0.11
10.3
963342
100.0
0.13
0.16
2.8
331927
100.0
0.25
0.30
19.9
1894733
100.0
0.23
0.29
6.7
8492
100.0
0.58
0.67
26.4
356949
50.0
104.58
105.14
7231.8
37499
100.0
1.01
1.12
64.9
68396

Table 6: Siddiqis observation set: search for all minimal cardinality diagnoses (1800 sec. timeout).
7.2 SATbD vs. Other MBD Algorithms: All Minimal Cardinality Diagnosis
We now compare SATbD to the algorithms HDIAG (Siddiqi & Huang, 2007) and DCAS (Siddiqi
& Huang, 2011) in their application to search for all minimal cardinality diagnosis. Both algorithms search for a complete set of the minimal cardinality diagnoses. We consider the observations
generated by Siddiqi and Huang (2011) where minimal cardinality is bounded by 8.
Table 6 presents the results of our evaluation. The results for the HDIAG and DCAS are quoted
from Siddiqi and Huangs work (2011) where experiments are reported for an IntelXeon X3220
2.4GHz, 2Gb RAM. We present results only for the systems for which Siddiqi and Huang reported
results. Although the machines differ (with an advantage for SATbD), the results show a clear
advantage for SATbD which is faster in orders of magnitude for the larger systems.
For each of the three algorithms the table reports on:
Succ. rate% indicating the percentage of the observations for which the algorithm finds all
minimal cardinality diagnoses within an 1800 second timeout; and
Time sec. indicating the average computation times to find all minimal cardinality diagnoses
(taking the average over the set of observations for which there is no time out).
For SATbD we report also
TLD sec. the average runtime to compute all top level diagnoses;
TLD count the number of top level diagnoses; and
ALL count the total number of minimal cardinality diagnoses found.
Table 6 illustrates that SATbD clearly outperforms HDIAG and DCAS. It succeeds to compute all
minimal cardinality diagnoses for all observations for all of the systems except for c6288 where
it succeeds on 50% of the 40 observations compared to 26.5% for DCAS. Note that because of
the higher success rate, the average runtimes for SATbD involve harder observations not solved by
DCAS.
Observe that most of the diagnosis time for SATbD is spent to find all top level diagnoses indicated in column TLD sec. The cost to compute all minimal cardinality diagnoses is indicated in
column Time sec and the difference between these two columns is negligible. This reflects the
401

fiM ETODI , S TERN , K ALECH & C ODISH

fact that the set of all minimal cardinality diagnoses is derived as a cross product representation of
the set of all minimal cardinality diagnoses. Observe also that the number of TLDs (column TLD
count) is small in comparison to the huge number of minimal cardinality diagnoses (column ALL
count). The focus on TLDs is essential as each additional solution invokes an additional call to
the SAT solver. Using the SAT solver to find the minimal cardinality diagnoses directly would be
hopeless due to their sheer number.
7.3 Impact of the Components of SATbD
We proceed to illustrate the impact of the various components of our SAT-based encoding of MBD.
SATbD is designed using a variety of techniques that distinguish it from the simple vanilla encoding of an MBD problem to a SAT problem described in Section 5.1. We present here an evaluation
of the impact of these techniques based on several experiments using the following five configurations of our SAT based system. These configurations are incremental: starting from the basic
model, each one adds another component, ending with the final model applied in SATbD.
1. Vanilla. This is the minimal basic SAT encoding for MBD described in Section 5.1. Here
we assume the naive upper bound on the minimal cardinality determined as the number of
outputs of the given system.
2. Improved Cardinality Bound. Here we assume the same vanilla setting but consider the
improved bound on the minimal cardinality of a diagnosis using Algorithm 3.
3. E.P. This setting is the same as the previous but applies the Equi-Propagation constraint compiler of Metodi and Codish (2011, 2012) to optimize the encoding as described in Section 5.5.
4. Cones. This setting is the same as the previous but also partitions the system into its cones
and adds constraints to restrict the search to find top-level diagnoses (TLDs), as described in
Section 3.
5. Sections. This setting is the same as the previous but also partitions the system into its
sections and introduces corresponding redundant cardinality constraints as described in Section 5.3.
Figure 7 illustrates the impact of each of the five settings on the search for a single minimal
cardinality diagnosis for 1182 observations from Feldmans observation set for system c880. On
the horizontal axis, we consider the observations according to the size of their minimal cardinality
diagnosis. On the vertical axis, we illustrate the average runtime in seconds. All runs apply a 300
second timeout. We choose system c880 to present these results as: (a) it is the only midsize system
for which the observation sets contain observations with minimal cardinality diagnosis larger than
20; and (b) it is the largest system which exhibits an interesting behavior for all five configurations
without too many timeouts which shadow the results. With larger systems, such as c3515 and
c7552 considered below, only the last two of the five configurations exhibit interesting curves.
The other three configurations timeout on most of the observations.
The upper curve in Figure 7 describes the Vanilla setting and one may observe that as the cardinality increases the curve converges to the 300 second timeout. The second curve down describes
the Improved Bound setting and illustrates the impact of Algorithm 3, especially for the observations with minimal cardinality diagnoses of size 1  10. Here, using the improved bound reduces
402

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Figure 7: Impact of the different settings on the search for a single minimal cardinality diagnosis
for system c880.

the number of iterations with the SAT solver and this is the source of the improvement. To explain
why we see no improvement when the minimal cardinality diagnosis involves a larger number of
faults, consider first that for large minimal cardinalities, the results are meaningless as both of the
upper curves converge on the timeout. As for the medium sized minimal cardinalities, consider
that with both techniques the overwhelming part of the runtime is spent on the last UNSAT iteration. Moreover, the number of iterations with the SAT solver with both techniques is more or
less the same. This is because system c880 has only 26 outputs which is the naive bound used
in the vanilla setting which then jumps down in each iteration to a smaller bound (but not using a
one-by-one decrement). Given this evaluation we might consider omitting the constraints for the
improved lower bound depending on the parameters of the instance. However, the cost of running
Algorithm 3 is negligible so we always impose the corresponding constraints.
The third curve down (E.P.) shows the additional impact when applying the Equi-Propagation
constraint compiler. This results in substantial speedups over the first two settings. For example,
finding a diagnosis of minimal cardinality 20 requires an average of 18.5 seconds with this setting
in comparison to 214.9 seconds without it. The two lower curves of the graph coincide, and it
is the fourth setting (cones) which makes the dramatic impact on performance for system c880.
The average runtime required to find the first minimal cardinality using this setting is under 0.1
seconds for all observations. This includes finding diagnoses with minimal cardinality of 26 (!) in
58 milliseconds, on average. The runtimes with this setting are so small that we cannot observe any
additional added value when applying the fifth setting (sections). To this end we consider in the
next experiment a comparison using two larger systems, namely c5315 and c7552.
Figure 8 illustrates the impact of the fifth setting which involves the partitioning of a system into
sections. The left graph illustrates the impact of sections when seeking a single minimal cardinality
diagnosis for the observations in system c5315 and the right graph illustrates the impact when
seeking all top-level minimal cardinality diagnoses (TLDs). The lower curve (in both graphs), summarizes the results using sections and the upper curve without. For example, for the observations
with minimal cardinality 24, with sections finding the first minimal cardinality diagnosis requires
403

fiM ETODI , S TERN , K ALECH & C ODISH

Figure 8: Impact of sections and cones on the search for a single minimal cardinality diagnosis (left)
and on the search for all TLDs (right) using system c5315.

Figure 9: Impact of sections and cones on the search for a single minimal cardinality diagnosis (left)
and on the search for all TLDs (right) using system c7552.
an average of 1.13 seconds, while without it requires 2.43 seconds. For the same observations, with
sections, we find all TLDs in an average of 6 seconds, and without it requires 15 seconds.
Similar trends are illustrated in Figure 9 which depicts the same information for system c7552.
Here we apply a timeout of 300 seconds, and this timeout is encountered for 48 of the 1,557 observations when searching for all minimal cardinality TLDs (timeout observations are not considered in
the average runtimes). However, even for these 48 observations, using sections provides on average
50% more TLDs than without (15,785 vs. 9,585 TLDs) before reaching the timeout.
Table 7 details, for the ISCAS-85 benchmark with Feldmans observations, the average sizes
of the SAT encodings when using the full SATbD algorithm. The table indicates the number of
System
# Components
# Variables
# Clauses

c432
160
190
556

c499
202
240
1193

c880
383
227
758

c1908
880
1026
4063

c2670
1193
636
2055

c3540
1669
2051
7456

c5315
2307
2407
11277

c6288
2416
7161
22061

c7552
3512
3525
12731

Table 7: Average SAT encoding sizes for the ISCAS-85 benchmark with Feldmans observations.
404

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

components in each system and the number of variables and clauses in the resulting CNFs, taking
the average over all observations in the Feldman benchmark. Notably, as indicated by the table, the
SAT encodings are extremely small with (in the worst case) less than three CNF variables and ten
CNF clauses per system component.

8. Discussion
This paper focuses on an MBD problem considering possibly multiple faulty components in a weak
fault model. The presentation is restricted to assume that: every component has a single output, the
observation includes a single input/output, there are no queries about observations of specific components (probes), and there is no information regarding the probability of component failures. Even
with these restrictions, the problem addressed in this paper is computationally hard and has been the
focus of many prior works in the model-based diagnosis literature (Feldman & van Gemund, 2006;
Williams & Ragno, 2007; Feldman et al., 2010a; Siddiqi & Huang, 2007, 2011).
We discuss here briefly the applicability of our approach in a more general setting. Deeper
analysis of how to adapt our approach to a more general setting is a research topic on its own. We
believe that our success in applying SAT solvers to MBD problems in this simplified setting paves
the way to their application in other more general settings.
8.1 Boolean Extensions
Our approach applies directly in any setting where the components are described by propositional
formulae and where their mode of fault can be ignored (i.e., any weak fault model setting). Boolean
circuits are just one straightforward example where this is obvious and where the community has
focused attention. Other examples with similar assumptions and where our SAT-based approach can
be expected to apply directly include the works by: Abreu et al. (2009) where the authors model
software components as propositional formulae and apply an MBD algorithm to find bugs; Kalech
and Kaminka (2005, 2006) where the authors model robots in a multi-robot system and diagnose
the violation of coordination constraints among robots; and Felfernig et al. (2012) where the authors
model finite domain constraints and diagnose inconsistent constraint sets.
Note that restricting components to have a single output is not really a restriction as it is straightforward to represent a component with multiple outputs as a conjunction of single output components. In this way the partition into cones and sections is fully compatible with multiple-output
components.
8.2 Probabilities
Real world applications of MBD typically come with information regarding the probability of a
component to be faulty and many MBD algorithms exploit this information to prioritize diagnoses
with respect to their likelihood (interalia, see de Kleer & Williams, 1989; Williams & Ragno,
2007). Sachenbacher and Williams (2004) showed how to incorporate fault probabilities in a treedecomposition diagnosis algorithm. Extending our approach tonconsider
fi probabilities
o is straightfi
forward. The essential difference is in Constraint 2, sum leq( Hc fi c  COMPS , k), which
specifies the objective function we n
aim to minimize.fiIt can be replaced
o with a constraint that takes
fi
probabilities into account: sum leq( Hc  (1  pc ) fi c  COMPS , k) where pc is the probabil405

fiM ETODI , S TERN , K ALECH & C ODISH

ity that component c is faulty. So, constraints which are more likely to be faulty contribute less to the
objective function. Note that it is straightforward to normalize the constraint so that the coefficients
are integers. Constraints of this form are called Pseudo-Boolean constraints and their encoding to
CNF is well studied (Een & Sorensson, 2006).
8.3 Testing and Probes
Another extension that is straightforward to model in SAT concerns testing and probing (de Kleer
& Williams, 1987). Here, the diagnosis algorithm is given multiple observations on the input/output
behavior of the system (in testing) or additional observations on internal wires in the system (in
probing). Under the assumption that faulty components are consistently faulty, we can invalidate
diagnoses that are inconsistent with multiple observations. Similarly, probes can invalidate diagnoses that are not consistent with the new internal observation. Both methods can be run iteratively
until there is a single consistent diagnosis. Both techniques are straightforward to encode to SAT.
For testing, to improve the diagnosis we simply take the conjunction of encodings with respect to
different observations, but using the same health variables. For probing we also take a conjunction
with the internal observations. The main challenge for both methods is to reduce the number of
probes (or tests) required to find the actual diagnosis. A common, greedy, approach to address this
challenge is to choose a probe (test) that maximizes the information gain as described by Feldman
et al. (2010b).
8.4 The Strong Fault Model
Now consider an extension of our approach to a setting in which components are associated with
a wider range of possible faulty behavior modes. This is called the Strong Fault Model. For
instance, a setting where a circuit component may be stuck at 0 (always returns output 0), stuck
at 1(always returns output 1), or flip (always flips its output) (Struss & Dressier, 1989; de Kleer
& Williams, 1989). In the context of this example, a naive SAT model may be obtained as follows.
Instead of considering only a single propositional health variable Hc , consider one additional varif
s1
able per fault mode: Hs0
c (stuck at zero), Hc (stuck at one), and Hc (flip). Now, introduce clauses
f
s1
s0
(a) to express that any fault mode is a fault (Hc  Hc  Hc  Hc ); and (b) to express that there is at
s1
f
most one fault on a component sum leq({Hs0
c , Hc , Hc }, 1). In this way the propositional health
variable Hc , as before, indicates if a component is healthy but a diagnosis is now an assignment of
fault types to each component. However, this extension requires to reconsider the definitions of
minimal diagnosis and cardinality and presents a new challenge in identifying useful partitions of
the system and in solving the problem with SAT. We consider this as future work.
8.5 Diagnosis for Physical Systems
This is the most challenging problem. Physical systems are typically dynamic, involve components
with time dependent behavior, and described in terms of continuous variables. One common approach to apply MBD to physical systems is to use qualitative models where the behavior of the
system is modeled as a set of constraints over non-numerical (discrete) descriptions (Subramanian
& Mooney, 1996). A well-known example of an MBD engine that makes such relaxations is the
Livingstone Model-Based Diagnosis System (Williams & Nayak, 1996). Livingstone has been successfully applied in Deep Space One, the first spacecraft for NASAs New Millennium program.
406

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

A first and important step for a SAT based approach for the diagnosis of physical systems is to
provide a setting for MBD in the strong fault model and able to capture probabilities. Of course,
there are many additional challenges and the modeling of such systems using SAT is an important
but feasible challenge.

9. Conclusion
This paper addresses an MBD challenge which has been extensively researched for more than 25
years and for which a wide range of papers propose different algorithms. We present a novel SATbased solution for this problem and determine for the first time, minimal cardinality diagnoses for
the entire standard benchmarks. We present an extensive experimental evaluation comparing our
algorithm to HA*, CDA*, SAFARI, HDIAG and DCAS. Results are unequivocal. Our algorithm outperforms the others, often by orders of magnitude, both for the search of a single minimal cardinality
diagnosis as well as for the search for all minimal cardinality diagnoses. We succeed to find and
verify a minimal cardinality diagnosis for all but 11 of the 28,257 observations of the benchmark
in under 30 seconds per observation, and for the remaining 11 in under 80 seconds each. To the
best of our knowledge, our SATbD algorithm is the first algorithm to find the minimal cardinality of
these standard benchmarks discussed above. Further details regarding the experimental evaluation
as well as a prototype implementation of our SAT-based MBD tool can be found online (Metodi,
2012a; Metodi et al., 2012b).
A major contribution to the success of our approach is the range of preprocessing techniques
presented in Section 5. Their impact is demonstrated through five configurations of the system
in Section 7.3 and their full combination is the fifth such configuration. Even as SAT, and other
related solvers, improve we conjecture that careful modeling choices involving combinations of
these techniques are invaluable to the success of future MBD algorithms. It is our belief that the
results of this paper will pave the way to develop and apply SAT-based methodologies to other
MBD problems. In particular, extensions for diagnosis with probabilities of components to be
faulty, for sequential diagnosis with testing and probes, and, most challenging, for the diagnosis
of physical systems with qualitative models. We expect that our methodology, which combines
domain dependent preprocessing, clever modeling in SAT, and application of tools to optimize the
CNF encodings, is relevant to other hard problems in AI where SAT-based techniques are applicable.
Acknowledgments
This research was supported by the Israel Science Foundation, grant 182/13.

References
Abreu, R., Zoeteweij, P., Golsteijn, R., & van Gemund, A. J. C. (2009). A practical evaluation of
spectrum-based fault localization. Journal of Systems and Software, 82(11), 17801792.
Asn, R., Nieuwenhuis, R., Oliveras, A., & Rodrguez-Carbonell, E. (2009). Cardinality networks
and their applications. In Kullmann, O. (Ed.), SAT, Vol. 5584 of Lecture Notes in Computer
Science, pp. 167180. Springer.
Asn, R., Nieuwenhuis, R., Oliveras, A., & Rodrguez-Carbonell, E. (2011). Cardinality networks:
a theoretical and empirical study. Constraints, 16(2), 195221.
407

fiM ETODI , S TERN , K ALECH & C ODISH

Balakrishnan, K., & Honavar, V. (1998). Intelligent diagnosis systems. Journal of Intelligent Systems, 8(3/4), 239290.
Batcher, K. E. (1968). Sorting networks and their applications. In AFIPS Spring Joint Computing
Conference, Vol. 32 of AFIPS Conference Proceedings, pp. 307314.
Bauer, A. (2005). Simplifying diagnosis using LSAT: a propositional approach to reasoning from
first principles. In Bartak, R., & Milano, M. (Eds.), International Conference on Integration of
AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems
(CP-AI-OR), Vol. 3524 of Lecture Notes in Computer Science, pp. 4963, Berlin, Heidelberg.
Springer-Verlag.
Biere, A., Heule, M., van Maaren, H., & Walsh, T. (Eds.). (2009). Handbook of Satisfiability, Vol.
185 of Frontiers in Artificial Intelligence and Applications. IOS Press.
Brglez, F., Bryan, D., & Kozminski, K. (1989). Combinatorial profiles of sequential benchmark
circuits. In IEEE International Symposium on Circuits and Systems, pp. 19291934.
Bylander, T., Allemang, D., Tanner, M. C., & Josephson, J. R. (1991). The computational complexity of abduction. Artificial Intelligence, 49(1-3), 2560.
Codish, M., & Zazon-Ivry, M. (2010). Pairwise cardinality networks. In Logic for Programming,
Artificial Intelligence, and Reasoning (LPAR), pp. 154172.
Darwiche, A. (2001). Decomposable negation normal form. Journal of the ACM, 48(4), 608647.
de Kleer, J., & Williams, B. C. (1987). Diagnosing multiple faults. Artificial Intelligence, 32(1),
97130.
de Kleer, J. (2008). An improved approach for generating max-fault min-cardinality diagnoses. In
International Workshop on Principles of Diagnosis (DX).
de Kleer, J., & Williams, B. C. (1989). Diagnosis with behavioral modes. In International Joint
Conference on Artificial Intelligence (IJCAI), pp. 13241330.
Dressler, O., & Struss, P. (1995). Occm. http://www.occm.de.
DXC

(2009).
International diagnostic
https://sites.google.com/site/dxcompetition/.

competition

series.

Website.

Een, N., & Sorensson, N. (2006). Translating pseudo-Boolean constraints into SAT. Journal on
Satisfiability (JSAT), 2(1-4), 126.
El Fattah, Y., & Dechter, R. (1995). Diagnosing tree-decomposable circuits. International Joint
Conference on Artificial Intelligence (IJCAI), 95, 17421749.
Feldman, A., Provan, G., de Kleer, J., Robert, S., & van Gemund, A. (2010). Solving model-based
diagnosis problems with Max-SAT solvers and vice versa. In International Workshop on
Principles of Diagnosis (DX), pp. 185192.
Feldman, A. (2012). Lydia-ng. http://www.general-diagnostics.com/products.
php.
Feldman, A., de Castro, H. V., van Gemund, A., & Provan, G. (2013). Model-based diagnostic
decision-support system for satellites. In IEEE Aerospace Conference, pp. 114. IEEE.
Feldman, A., Provan, G., & van Gemund, A. (2010a). Approximate model-based diagnosis using
greedy stochastic search. Journal of Artificial Intelligence Research (JAIR), 38, 371413.
408

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Feldman, A., Provan, G., & van Gemund, A. (2010b). A model-based active testing approach to
sequential diagnosis. Journal of Artificial Intelligence Research (JAIR), 39, 301334.
Feldman, A., & van Gemund, A. J. C. (2006). A two-step hierarchical algorithm for model-based
diagnosis. In Conference on Artificial Intelligence (AAAI), pp. 827833.
Felfernig, A., Schubert, M., & Zehentner, C. (2012). An efficient diagnosis algorithm for inconsistent constraint sets. Artificial Intelligence for Engineering Design, Analysis and Manufacturing, 26(1), 5362.
Frohlich, P., & Nejdl, W. (1997). A static model-based engine for model-based reasoning. In
International Joint Conference on Artificial Intelligence (IJCAI), pp. 466473.
Fujiwara, H., Member, S., Shimono, T., & Member, S. (1983). On the acceleration of test generation
algorithms. IEEE Transactions on Computers, 32, 11371144.
Hansen, M. C., Yalcin, H., & Hayes, J. P. (1999). Unveiling the ISCAS-85 benchmarks: A case
study in reverse engineering. IEEE Des. Test, 16, 7280.
Jannach, D., & Schmitz, T. (2014). Model-based diagnosis of spreadsheet programs: a constraintbased debugging approach. Automated Software Engineering, 1, 140.
Kalech, M., & Kaminka, G. A. (2005). Towards model-based diagnosis of coordination failures. In
Conference on Artificial Intelligence (AAAI), pp. 102107.
Kalech, M., Kaminka, G. A., Meisels, A., & Elmaliach, Y. (2006). Diagnosis of multi-robot coordination failures using distributed CSP algorithms. In Conference on Artificial Intelligence
(AAAI), pp. 970975.
Kirkland, T., & Mercer, M. R. (1987). A topological search algorithm for ATPG. In ACM/IEEE
Design Automation Conference, DAC, pp. 502508.
Knuth, D. E. (2014). The Art of Computer Programming: Volume 4B, Pre-fascicle 6A, Section
7.2.2.2: Satisfiability. Unpublished. Draft available from: http://www-cs-faculty.
stanford.edu/knuth/fasc6a.ps.gz.
Marques-Silva, J., Lynce, I., & Malik, S. (2009). Conflict-driven clause learning SAT solvers.
Handbook of satisfiability, 185, 131153.
Metodi, A. (2012a). SCryptodiagnoser: A SAT based MBD solver. http://amit.metodi.
me/research/mbdsolver.
Metodi, A. (2012b). SCryptominisat. http://amit.metodi.me/research/scrypto.
Metodi, A., & Codish, M. (2012). Compiling finite domain constraints to SAT with BEE. Theory
and Practice of Logic Programming (TPLP), 12(4-5), 465483.
Metodi, A., Codish, M., Lagoon, V., & Stuckey, P. J. (2011). Boolean equi-propagation for optimized SAT encoding. In CP, pp. 621636.
Metodi, A., Codish, M., & Stuckey, P. J. (2013). Boolean equi-propagation for concise and efficient
SAT encodings of combinatorial problems. Journal of Artificial Intelligence Research (JAIR),
46, 303341.
Metodi, A., Stern, R., Kalech, M., & Codish, M. (2012a). Compiling model-based diagnosis to
Boolean satisfaction. In Conference on Artificial Intelligence (AAAI).
409

fiM ETODI , S TERN , K ALECH & C ODISH

Metodi, A., Stern, R., Kalech, M., & Codish, M. (2012b). Compiling model-based diagnosis to
Boolean satisfaction: Detailed experimental results and prototype implementation. http:
//www.cs.bgu.ac.il/mcodish/Papers/Pages/aaai-2012.html.
Murray, J., Hughes, G., & Kreutz-Delgado, K. (2006). Machine learning methods for predicting failures in hard drives: A multiple-instance application. Journal of Machine Learning Research
(JMLR), 6(1), 783.
Nica, I., Pill, I., Quaritsch, T., & Wotawa, F. (2013). The route to success - a performance comparison of diagnosis algorithms. In International Joint Conference on Artificial Intelligence
(IJCAI), pp. 10391045.
Reiter, R. (1987). A theory of diagnosis from first principles. Artificial Intelligence, 32(1), 5795.
Sachenbacher, M., & Williams, B. (2004). Diagnosis as semiring-based constraint optimization. In
Eureopean Conference on Artificial Intelligence (ECAI), pp. 873877.
Selman, B., & Levesque, H. J. (1990). Abductive and default reasoning: A computational core. In
National Conference on Artificial Intelligence (AAAI), pp. 343348.
Siddiqi, S. A., & Huang, J. (2007). Hierarchical diagnosis of multiple faults. In International Joint
Conference on Artificial Intelligence (IJCAI), pp. 581586.
Siddiqi, S. A., & Huang, J. (2011). Sequential diagnosis by abstraction. Journal of Artificial Intelligence Research (JAIR), 41, 329365.
Smith, A., Veneris, A. G., Ali, M. F., & Viglas, A. (2005). Fault diagnosis and logic debugging
using Boolean satisfiability. IEEE Trans. on CAD of Integrated Circuits and Systems, 24(10),
16061621.
Soos, M. (2010). Cryptominisat, v2.5.1. http://www.msoos.org/cryptominisat2.
Stein, B., Niggemann, O., & Lettmann, T. (2006). Speeding up model-based diagnosis by a heuristic
approach to solving SAT. In IASTED international conference on Artificial intelligence and
applications, pp. 273278.
Stern, R. T., Kalech, M., Feldman, A., & Provan, G. M. (2012). Exploring the duality in conflictdirected model-based diagnosis. In AAAI.
Struss, P., & Dressier, O. (1989). Physical negation: Integrating fault models into the general
diagnostic engine. In International Joint Conference on Artificial Intelligence (IJCAI), pp.
13181323.
Struss, P., & Price, C. (2003). Model-based systems in the automotive industry. AI magazine, 24(4),
1734.
Stumptner, M., & Wotawa, F. (2001). Diagnosing tree-structured systems. Artificial Intelligence,
127(1), 129.
Stumptner, M., & Wotawa, F. (2003). Coupling CSP decomposition methods and diagnosis algorithms for tree-structured systems. In International Joint Conference on Artificial Intelligence
(IJCAI), pp. 388393.
Subramanian, S., & Mooney, R. J. (1996). Qualitative multiple-fault diagnosis of continuous dynamic systems using behavioral modes. In National Conference on Artificial Intelligence
(AAAI), pp. 965970.
410

fiA N OVEL SAT-BASED A PPROACH TO M ODEL BASED D IAGNOSIS

Torasso, P., & Torta, G. (2006). Model-based diagnosis through OBDD compilation: A complexity
analysis. In Reasoning, Action and Interaction in AI Theories and Systems, pp. 287305.
Wang, J., & Provan, G. (2010). A benchmark diagnostic model generation system. Part A: Systems
and Humans, IEEE Transactions on Systems, Man and Cybernetics, 40(5), 959981.
Williams, B. C., & Nayak, P. P. (1996). A model-based approach to reactive self-configuring systems. In National Conference on Artificial Intelligence (AAAI), pp. 971978.
Williams, B. C., & Ragno, R. J. (2007). Conflict-directed A* and its role in model-based embedded
systems. Discrete Applied Mathematics, 155(12), 15621595.

411

fiJournal of Artificial Intelligence Research 51 (2014) 255-291

Submitted 03/14; published 09/14

Automaton Plans
Christer Backstrom

CHRISTER . BACKSTROM @ LIU . SE

Department of Computer Science
Linkoping University
SE-581 83 Linkoping, Sweden

Anders Jonsson

ANDERS . JONSSON @ UPF. EDU

Dept. Information and Communication Tecnologies
Universitat Pompeu Fabra
Roc Boronat 138
08018 Barcelona, Spain

Peter Jonsson

PETER . JONSSON @ LIU . SE

Department of Computer Science
Linkoping University
SE-581 83 Linkoping, Sweden

Abstract
Macros have long been used in planning to represent subsequences of operators. Macros can
be used in place of individual operators during search, sometimes reducing the effort required to
find a plan to the goal. Another use of macros is to compactly represent long plans. In this paper
we introduce a novel solution concept called automaton plans in which plans are represented using
hierarchies of automata. Automaton plans can be viewed as an extension of macros that enables
parameterization and branching. We provide several examples that illustrate how automaton plans
can be useful, both as a compact representation of exponentially long plans and as an alternative
to sequential solutions in benchmark domains such as L OGISTICS and G RID. We also compare
automaton plans to other compact plan representations from the literature, and find that automaton
plans are strictly more expressive than macros, but strictly less expressive than HTNs and certain
representations allowing efficient sequential access to the operators of the plan.

1. Introduction
In this paper we introduce a novel solution concept for planning that we call automaton plans.
For ease of presentation we divide the introduction into two parts. In the first part we discuss
existing concepts for plan representation from the literature. In the second part we describe the
novel representation that we propose.
1.1 Plan Representations
Following the introduction of S TRIPS planning (Fikes & Nilsson, 1971), it did not take researchers
long to discover the utility of storing sequences of planning operators, or macros (Fikes, Hart, &
Nilsson, 1972). Macros were first used as a tool during plan execution and analysis. However,
macros turned out to have several other useful properties that have been exploited by researchers in
the planning community ever since.
c
2014
AI Access Foundation. All rights reserved.

fiB ACKSTR OM , J ONSSON , & J ONSSON

One such property is the possibility to compute cumulative preconditions and effects, effectively
making macros indistinguishable from individual operators. A planning instance can be augmented
with a set of macros, potentially speeding up the search for a solution since macros can reach further
into the state space than individual operators. In the extreme, the search space over macros can be
exponentially smaller than the search space over the original planning operators (Korf, 1987).
Moreover, if subsequences of operators are repeated, a hierarchy of macros can represent a plan
more compactly than a simple operator sequence, replacing each occurrence of a repeating subsequence with a single operator (i.e. a macro). In the extreme, one can represent an exponentially long
plan using polynomially many macros of polynomial length (Gimenez & Jonsson, 2008; Jonsson,
2009). Sometimes it is even possible to generate such a compact macro plan in polynomial time,
in which case macros can be viewed as a tool for complexity analysis, reducing the complexity of
solving a particular class of planning instances.
Macros clearly show that there are advantages associated with plan representations that do not
simply store the plan as a sequence of actions. Apart from the obvious purpose of saving space, there
are other reasons for considering alternative representations. One important reason is to highlight
properties of a plan that might not be apparent from a sequential representation and that can be
exploited for increased planning efficiency. One prominent example is partially ordered plans that
represent plans as sets of actions with associated partial orders. Partially ordered plans have often
been used in planning to speed up search (McAllester & Rosenblitt, 1991). In general, the fact that
there exists a compact representation of a plan implies that the planning instance exhibits some form
of structure that might be possible to exploit for simpler and more efficient reasoning.
Potentially, there exist many alternative plan representations that can store plans compactly.
Such compact representations can broadly be divided into two categories. The first type of plan
representation stores a single plan, while the second type stores a set of plans. Macros are an
illustrative example of the first type, and we have already seen that macro plans can be exponentially
smaller than a sequential representation. An example of the second type is reactive plans, also
known as universal plans or reactive systems, which represent one plan for each state from which
the goal is reachable.
The usefulness of a compact representation depends of several factors.
1.1.1 C OMPRESSION P ROPERTIES
Clearly, one important property of a compact plan representation is its size. However, there is an
information-theoretic bound on the compressibility of plans: a representation containing n bits can
only distinguish between 2n different plans, limiting the applicability of highly compact represenn
tations. There exist S TRIPS instances with n variables having 22 1 different plans (Backstrom &
Jonsson, 2012, Construction 10), implying that at least 2n  1 bits are needed to distinguish one
particular solution from the rest. However, it may often suffice to represent a single solution that is
not arbitrarily chosen. In the extreme, we can represent a solution compactly by storing the planning
instance together with an algorithm for solving it.
1.1.2 ACCESS P ROPERTIES
Another important property of a compact plan representation is the ability to access a particular
action of the plan. Two alternative concepts have been proposed (Backstrom & Jonsson, 2012):
sequential and random access. Sequential access implies that the actions of the plan can be retrieved
256

fiAUTOMATON P LANS

in order, while random access implies that we can retrieve the action at any given position i of the
plan. For both forms of access, ideally we should be able to retrieve actions in polynomial time,
something that is not always possible.
1.1.3 V ERIFICATION
A third property of a compact plan representation is being able to verify that the plan actually constitutes a solution to a given planning instance. The complexity of plan verification is directly related
to the complexity of plan existence, i.e. determining whether or not an instance has a solution. Assume that the problem of plan verification for a compact plan representation R is in complexity class
C. Let X be the set of S TRIPS instances p satisfying the following condition: if p is solvable there
exists a solution to p that can be represented with R using O(p(||p||)) bits, where p is a polynomial
function and ||p|| is the number of bits in the representation of p. Under these assumptions, the
problem of plan existence for X is in complexity class NPC : non-deterministically guess a compact
plan in R and verify that the plan solves p. For many choices of C, plan existence for X is bounded
away from PSPACE, i.e. easier than general S TRIPS planning. We conclude that simple verification
comes at a price: decreased expressiveness of the corresponding planning instances.
It is obviously difficult to identify representations that satisfy all three properties while being
able to express reasonably complex plans. A reasonable approach is to look for balanced representations that are both expressive and computationally efficient. Let us evaluate macros according to
the three properties above. In this paper we consider grounded macros that are totally ordered and
allow nesting, i.e. a macro can involve other macros as long as this does not create cyclic dependencies among macros. We know that there exist examples for which macros provide a powerful
compact representation mechanism. Macro plans have excellent access properties: both sequential
and random access can be performed in polynomial time (Backstrom & Jonsson, 2012). They are
also verifiable in polynomial time (Backstrom, Jonsson, & Jonsson, 2012b), implying that planning
instances whose solutions can be represented using polynomial-size macro plans are easier than
general S TRIPS planning, but also less expressive.
1.2 Automaton Plans
In this paper we introduce a novel solution concept for planning, inspired by macros, that we call
automaton plans. An automaton plan consists of a hierarchy of automata, each endowed with the
ability to call other automata. At the bottom level of the hierarchy are the individual plan operators.
Automaton plans can be viewed as an extension of macro plans along two dimensions. First, an
automaton is parameterized, enabling it to compactly represent not just a single operator sequence
but a whole family of sequences. Second, an automaton can branch on input, making it possible to
store different subsequences of operators and distinguish between them by providing different input
to the automaton.
The main motivation for automaton plans is to express plans compactly that macro plans cannot, while maintaining access properties and verification at a reasonable level. We present several
examples of automaton plans, and show how they can be useful in a variety of ways. In domains
such as Towers of Hanoi, automaton plans can represent exponentially long plans even more compactly than macro plans. Even when plans are not necessarily very long, the ability to parameterize
plans makes it possible to store repeating families of action subsequences in common benchmark
domains.
257

fiB ACKSTR OM , J ONSSON , & J ONSSON

To test the usefulness of automaton plans, we formally compare automaton plans to other compact plan representations from the literature along the three dimensions discussed in Section 1.1:
compression, access, and verification. Each macro plan is also an automaton plan, implying that
automaton plans are at least as compressed as macro plans. Just like macro plans, automaton plans
can be sequentially accessed in polynomial time. We also show that a subclass of automaton plans
admit polynomial-time random access, although it is still unknown whether this result generalizes
to all automaton plans. Finally, verification of automaton plans is p2 -complete, causing automaton
plans to be strictly more expressive than macros.
Hierarchical Task Networks (Erol, Hendler, & Nau, 1996), or HTNs for short, can also be
viewed as a type of compact plan representation. In addition to planning operators, an HTN defines
a set of tasks, each with a set of associated methods for expanding the task. As the name suggests,
the tasks are organized in a hierarchy with planning operators at the bottom. This hierarchy may be
considerably more compact than the actual sequence of operators in a plan. In general, the plans
represented by HTNs are not unique and search may be required to find a valid plan.
Instead of comparing automaton plans to general HTNs, we only consider totally ordered HTNs
with unique plans, i.e. the methods associated with each task are mutually exclusive and specify a
totally ordered expansion. We show that each automaton plan can be efficiently translated to such
an HTN, causing HTNs to be at least as compressed as automaton plans. HTNs with unique plans
can be sequentially accessed in polynomial time, but the same is not true for random access. Finally,
plan existence for totally ordered HTNs is known to be PSPACE-hard (Erol et al., 1996), implying
that verification of HTNs is harder than for automaton plans, in turn causing HTNs to be strictly
more expressive.
Combining these results, an automaton plan appears to offer a reasonable tradeoff between
compression, access, and verification, making it an interesting candidate for the type of balanced
plan representation that we discussed earlier. Since automaton plans are strictly more expressive
than macros, we can use them to represent plans compactly for a wider range of planning instances.
However, this does not come at the expense of prohibitively expensive computational properties,
since verification is easier for automaton plans than for HTNs as well as general S TRIPS planning.
Automaton plans were first introduced in a conference paper (Backstrom, Jonsson, & Jonsson,
2012a). The present paper makes the following additional contributions:
 A formalization of automaton plans using Mealy machines, providing a stronger theoretical
foundation of automaton plans in automaton theory.
 A proof that plan verification for automaton plans is p2 -complete, a result that is used to
compare the expressive power of automaton plans to that of other compact plan representations.
 A reduction from automaton plans to HTNs, proving that HTNs are strictly more expressive
than automaton plans, which comes at the price of more expensive computational properties.
The rest of the paper is organized as follows. Section 2 describes notation and basic concepts, while
Section 3 introduces automaton plans. Section 4 illustrates automaton plans using several practical
examples. Section 5 compares the computational properties of automaton plans to those of other
compact plan representations from the literature. Section 6 describes related work, while Section 7
concludes with a discussion.
258

fiAUTOMATON P LANS

2. Notation
In this section we describe the notation used throughout the paper. We first introduce a formal
definition of S TRIPS planning domains based on function symbols, and show how S TRIPS planning
instances are induced by associating sets of objects with planning domains. The same idea is used
in the PDDL language to compactly express planning domains and planning instances, and our
definition can be viewed as a mathematical adaptation of PDDL.
Given a set of symbols , let n denote the set of strings of length n composed of symbols
in . Let x  n be such a string. For each 1  k  n, we use xk to denote the k-th symbol
of x. As is customary, we use  to denote the empty string, which satisfies x = x = x. Given
a set of elements S, let S  and S + denote sequences and non-empty sequences of elements of S,
respectively. Given a sequence   S  , let || denote its length. For any construct X, let ||X||
denote its size, i.e. the number of bits in its representation.
2.1 Function Symbols
A planning domain is an abstract description that can be instantiated on a given set of objects  to
form a planning instance. In this section we introduce function symbols to facilitate the description
of planning domains. Formally, a function symbol f has fixed arity ar(f ) and can be applied to any
vector of objects x  ar(f ) to produce a new object f [x]. Let F be a set of function symbols and
let  be a set of objects. We define F = {f [x] : f  F, x  ar(f ) }  F   as the set of
new objects obtained by applying each function symbol in F to each vector of objects in  of the
appropriate arity.
Let f and g be two function symbols in F . An argument map from f to g is a function  :
ar(f
)  ar(g) mapping arguments of f to arguments of g. Intuitively, as a result of applying 

to an argument x  ar(f ) of f , each argument of g is either a component of x or a constant object
in  independent of x. Formally, for each 1  k  ar(g), either k (x) = xj for a fixed index j
satisfying 1  j  ar(f ), or k (x) =  for a fixed object   . An argument map  from f to g
enables us to map an object f [x]  F to an object g[(x)]  F .
Since argument maps have a restricted form, we can characterize an argument map  from f to
g using an index string from f to g, i.e. a string   ({1, . . . , ar(f )}  )ar(g) containing indices of
f and/or objects in . An index string  from f to g induces an argument map  from f to g such
that for each 1  k  ar(g), k (x) = x(k)   if (k)  {1, . . . , ar(f )} and k (x) = (k)  
otherwise.
To illustrate the idea, let F = {f, g} with ar(f ) = ar(g) = 2 and let  = {1 , 2 }. An
example index string from f to g is given by  = 21 , which induces an argument map  from f
to g such that on input x  2 , the first component of (x) always equals the second component of
x, and the second component of (x) always equals 1 . Given , the object f [1 2 ]  F maps to
the object g[(1 2 )] = g[2 1 ]  F .
2.2 Planning
Let V be a set of propositional variables or fluents. A literal l is a non-negated or negated fluent,
i.e. l = v or l = v for some v  V . Given a set of literals L, let L+ = {v  V : v  L}
and L = {v  V : v  L} be the set of fluents that appear as non-negated or negated in L,
/ L for each v  V , which is
respectively. We say that a set of literals L is consistent if v 
/ L or v 
259

fiB ACKSTR OM , J ONSSON , & J ONSSON

equivalent to L+  L = . A state s  V is a set of fluents that are currently true; all fluents not
in s are assumed to be false. A set of literals L holds in a state s if L+  s and L  s = . We
define an update operation on a state s and a set of literals L as s  L = (s \ L )  L+ .
In this paper we focus on S TRIPS planning with negative preconditions. Formally, a S TRIPS
planning domain is a tuple d = hP, Ai, where P is a set of function symbols called predicates and
A is a set of function symbols called actions. Each action a  A has an associated precondition
pre(a) = {(p1 , 1 , b1 ), . . . , (pn , n , bn )} where, for each 1  k  n, pk is a predicate in P ,
k is an argument map from a to pk , and bk is a Boolean. To be well-defined, pre(a) should not
simultaneously contain (p, , true) and (p, , false) for some predicate p and argument map  from
a to p. The postcondition post(a) of a is similarly defined.
A S TRIPS planning instance is a tuple p = hP, A, , I, Gi, where hP, Ai is a planning domain,
 a set of objects, I an initial state, and G a goal state, i.e. a set of literals implicitly defining a set of
states in which G holds. P and  implicitly define a set of fluents P = {p[x] : p  P, x  ar(p) }
by applying each predicate to each vector of objects in . Likewise, A and  implicitly define a
set of operators A . Thus fluents correspond to grounded predicates, and operators correspond to
grounded actions, which is the reason we distinguish between action and operator in the text.
The initial state I  P and goal state G  P are both subsets of (non-negated) fluents.
For each action a  A and each x  ar(a) , the precondition of operator a[x]  A is given
by pre(a[x]) = {b1 p1 [1 (x)], . . . , bn pn [n (x)]}, where pre(a) = {(p1 , 1 , b1 ), . . . , (pn , n , bn )},
bp[y] = p[y] if b is false, and bp[y] = p[y] if b is true. In other words, pre(a[x]) is the result
of applying each argument map k in the precondition of a to the argument x to obtain a fluent
pk [k (x)]  P , which is then appropriately negated. The postcondition post(a[x]) of a[x] is
similarly defined. Note that if pre(a) and post(a) are well-defined, pre(a[x]) and post(a[x]) are
consistent sets of literals on P .
An operator o  A is applicable in state s if and only if pre(o) holds in s, and the result of
applying o in s is s  post(o). A plan for p is a sequence of operators  = ho1 , . . . , on i  A such
that pre(o1 ) holds in I and, for each 1 < k  n, pre(ok ) holds in I  post(o1 )      post(ok1 ).
We say that  solves p if G holds in I  post(o1 )      post(on ). Given two operator sequences
 and   , let ;   denote their concatenation.
P
P
Note that p has pP ||ar(p) fluents and aA ||ar(a) operators, which can both be exponential in ||p||, the description length of p. To avoid errors due to discrepancies in instance description
length and actual instance size, we only consider P and A such that, for each p  P and a  A,
ar(p) and ar(a) are constants that are independent of ||p||. We sometimes describe planning instances directly on the form p = hP , A , , I, Gi by defining predicates and actions of arity 0,
implying that each predicate is a fluent and each action an operator.

3. Automaton Plans
In this section we define the concept of automaton plans, which is similar to macro plans. Just
like a macro plan consists of a hierarchy of macros, an automaton plan consists of a hierarchy of
automata. Unlike macros, the output of an automaton depends on the input, making it possible for
a single automaton to represent a family of similar plans. We can either use an automaton plan
to represent a single plan by explicitly specifying an input string of the root automaton, or allow
parameterized plans by leaving the input string of the root automaton undefined.
260

fiAUTOMATON P LANS

3.1 Mealy Machines
To represent individual automata we use a variant of deterministic finite state automata called Mealy
machines (Mealy, 1955), each defined as a tuple M = hS, s0 , , , T, i where
 S is a finite set of states,
 s0  S is an initial state,
  is an input alphabet,
  is an output alphabet,
 T : S    S is a transition function,
  : S     is an output function.
A Mealy machine M is a transducer whose purpose it is to generate a sequence of output for
a given input string. This is in contrast to acceptors that generate binary output (accept or reject). Executing a Mealy machine M on input x = x1 x2    xn  n generates the output
(s0 , x1 )(s1 , x2 )    (sn1 , xn )  n where sk = T (sk1 , xk ) for each 1  k < n.
We extend Mealy machines to allow -transitions (i.e. transitions that do not consume input
symbols in ). While this may in general cause Mealy machines to be non-deterministic, we include
several restrictions that preserve determinism:
 We redefine T as a partial function T : S  (  {})  S such that for each s  S, either
T (s, ) is defined or T (s, ) is defined for each   , but not both. This is still, in a sense, a
total function on S since there is always exactly one possible transition from each state s  S,
but the transition may or may not consume an input symbol.
 We do not allow -cycles, i.e. there must not exist any subset {s1 , . . . , sn }  S of states such
that T (sk1 , ) = sk for each 1 < k  n and T (sn , ) = s1 .
 We further require that -transitions must always fire, in order to make the behavior of Mealy
machines well defined also when all input symbols have been consumed.
We also allow  as output, i.e. a transition may or may not generate an output symbol in . To allow
for -transitions and -output we redefine  as a partial function  : S  (  {})    {}.
The definition of  should be consistent with T , i.e. for each state s  S, if T (s, ) is defined then
(s, ) is defined, else (s, ) is defined for each   . We define an extended output function
 : S     such that for each state s  S, input symbol    and input string x   ,

(s, ) (T (s, ), ), if T (s, ) is defined,

 (s, ) =
,
otherwise,


(s, ) (T (s, ), x), if T (s, ) is defined,
 (s, x) =
(s, ) (T (s, ), x), otherwise.
The deterministic output of a Mealy machine M on input x is given by  (s0 , x)   .
As is customary we use graphs to represent automata. The graph associated with a Mealy
machine M has one node per state in S. An edge between states s and t with label i/o, where
i  (  {}) and o  (  {}), implies that T (s, i) = t and (s, i) = o. To simplify the graphs
we adopt the following conventions:
261

fiB ACKSTR OM , J ONSSON , & J ONSSON

1/b
/ha, bi
0/c

/

1/c
0/a

Figure 1: An example Mealy machine.
 An edge between states s and t with label i/h1 , . . . , n i  (  {})  n is used as shorthand to describe a series of intermediate states s2 , . . . , sn such that T (s, i) = s2 , T (sk1 , ) =
sk for each 2 < k  n, T (sn , ) = t, (s, i) = 1 , and (sk , ) = k for each 2  k  n.
 An edge between states s and t with label n / is used as shorthand to describe a series of
intermediate states s2 , . . . , sn such that for each   , T (s, ) = s2 , T (sk1 , ) = sk for
each 2 < k  n, T (sn , ) = t, (s, ) = , and (sk , ) =  for each 2  k  n.
Figure 1 shows an example Mealy machine M = hS, s0 , , , T, i with |S| = 4,  = {0, 1}, and
 = {a, b, c}. The initial state s0 is identified by an incoming edge without origin. Two example
outputs are  (s0 , 01) = aab and  (s0 , 1011) = cccbab.
3.2 Automaton Hierarchies
In this section we explain how to construct hierarchies of automata in order to represent plans. Each
automaton hierarchy is associated with a S TRIPS planning instance p = hP, A, , I, Gi. We define
a set Au of function symbols called automata, i.e. each automaton M  Au has fixed arity ar(M ),
something that is unusual in automaton theory. The motivation is that the automata used to represent
plans can be viewed as abstract actions, and the input to each automaton serves a dual purpose: to
determine how to fire the transitions of the automaton in order to generate the output, and to copy
input symbols onto actions and other automata.
Each automaton M  Au corresponds to a Mealy machine hSM , s0 , , M , TM , M i, where 
is the set of objects of the S TRIPS instance p and M = (A  Au)  ({1, . . . , ar(M )}  ) . Each
output symbol (u, )  M is a pair consisting of an action u  A or automaton u  Au and an
index string  from M to u. For each input string x  ar(M ) , we require the output of automaton
M on input x to be non-empty, i.e. M (s0 , x) = h(u1 , 1 ), . . . , (un , n )i  +
M.
Given Au, we define an expansion graph that denotes dependencies among the automata in Au:
Definition 1. Given a set Au of automata, the expansion graph GAu = hAu, i is a directed graph
over automata where, for each pair M, M   Au, M  M  if and only if there exists a state-input
pair (s, )  SM   of M such that M (s, ) = (M  , ) for some index string .
Thus there is an edge between automata M and M  if and only if M  appears as an output of M .
We next define an automaton hierarchy as a tuple H = h, A, Au, ri where
 , A, and Au are defined as above,
 GAu is acyclic and weakly connected,
262

fiAUTOMATON P LANS

 r  Au is the root automaton, and
 there exists a directed path in GAu from r to each other automaton in Au.
For each M  Au, let Succ(M ) = {M   Au : M  M  } be the set of successors of M . The
height h(M ) of M is the length of the longest directed path from M to any other node in GAu , i.e.

0,
if Succ(M ) = ,
h(M ) =

1 + maxM  Succ(M ) h(M ), otherwise.
Given an automaton hierarchy H, let S = maxM Au |SM | be the maximum number of states of
the Mealy machine representation of each automaton, and let Ar = 1 + maxuAAu ar(u) be the
maximum arity of actions and automata, plus one.
The aim of an automaton M  Au is not only to generate the output M (s0 , x) on input x, but
to define a decomposition strategy. This requires us to process the output of M in a concrete way
described below. An alternative would have been to integrate this processing step into the automata,
but this would no longer correspond to the well-established definition of Mealy machines.
We first define a notion of grounded automata, analogous to the notion of grounded actions
(i.e. operators) of a planning instance. An automaton call M [x] is an automaton M and associated
input string x  ar(M ) , representing that M is called on input x. The sets Au and  define a set of
automaton calls Au = {M [x] : M  Au, x  ar(M ) }, i.e. automata paired with all input strings
of the appropriate arity. We next define a function Apply that acts as a decomposition strategy:
Definition 2. Let Apply : Au  (A  Au )+ be a function such that for M [x]  Au ,
Apply(M [x]) = hu1 [1 (x)], . . . , un [n (x)]i, where M (s0 , x) = h(u1 , 1 ), . . . , (un , n )i and,
for each 1  k  n, k is the argument map from M to uk induced by the index string k .
The purpose of Apply is to replace an automaton call with a sequence of operators and other
automaton calls. Recursively applying this decomposition strategy should eventually result in a
sequence consisting exclusively of operators. We show that Apply can always be computed in
polynomial time in the size of an automaton.
Lemma 3. For each automaton call M [x]  Au , the complexity of computing Apply(M [x]) is
bounded by S  Ar2 .
Proof. Our definition of Mealy machines requires each cycle to consume at least one input symbol.
In the worst case, we can fire |SM |  1 -transitions followed by a transition that consumes an input
symbol. Since the input string x has exactly ar(M ) symbols, the total number of transitions is
bounded by (|SM |  1)(1 + ar(M )) + ar(M )  |SM |  (1 + ar(M ))  S  Ar.
Let h(u1 , 1 ), . . . , (un , n )i be the output of M on input x. For each 1  k  n, uk is
a single symbol, while k contains at most Ar  1 symbols. Applying the argument map k
induced by k to the input string x is linear in |k |  Ar. Thus computing Apply(M [x]) =
hu1 [1 (x)], . . . , un [n (x)]i requires at most Ar time and space for each element, and since n 
S  Ar, the total complexity is bounded by S  Ar2 .
To represent the result of recursively applying the decomposition strategy, we define an expansion function Exp on automaton calls and operators:
Definition 4. Let Exp be a function on (A  Au )+ defined as follows:
263

fiB ACKSTR OM , J ONSSON , & J ONSSON

1. Exp(a[x]) = ha[x]i if a[x]  A ,
2. Exp(M [x]) = Exp(Apply(M [x])) if M [x]  Au ,
3. Exp(hu1 [y1 ], . . . , un [yn ]i) = Exp(u1 [y1 ]); . . . ; Exp(un [yn ]).
In the following lemma we prove that the expansion of any automaton call is a sequence of operators.
Lemma 5. For each automaton call M [x]  Au , Exp(M [x])  A+
.
Proof. We prove the lemma by induction over h(M ). If h(M ) = 0, Apply(M [x]) is a sequence of
operators ha1 [x1 ], . . . , an [xn ]i  A+
 , implying
Exp(M [x]) = Exp(Apply(M [x])) = Exp(ha1 [x1 ], . . . , an [xn ]i) =
= Exp(a1 [x1 ]); . . . ; Exp(an [xn ]) = ha1 [x1 ]i; . . . ; han [xn ]i =
= ha1 [x1 ], . . . , an [xn ]i  A+
.
We next prove the inductive step h(M ) > 0. In this case, Apply(M [x]) is a sequence of operators
and automaton calls hu1 [y1 ], . . . , un [yn ]i  (A  Au )+ , implying
Exp(M [x]) = Exp(Apply(M [x])) = Exp(hu1 [x1 ], . . . , un [xn ]i) =
= Exp(u1 [x1 ]);    ; Exp(un [xn ]).
For each 1  k  n, if uk [xk ] is an operator we have Exp(uk [xk ]) = huk [xk ]i  A+
 . On the
other hand, if uk [xk ] is an automaton call, Exp(uk [xk ])  A+
by
hypothesis
of
induction
since

h(uk ) < h(M ). Thus Exp(M [x]) is the concatenation of several operator sequences in A+
,
which

is itself an operator sequence in A+
.

Note that the proof depends on the fact that the expansion graph GAu is acyclic, since otherwise
the height h(M ) of automaton M is ill-defined. We also prove an upper bound on the length of the
operator sequence Exp(M [x]).
Lemma 6. For each automaton call M [x]  Au , |Exp(M [x])|  (S  Ar)1+h(M ) .
Proof. By induction over h(M ). If h(M ) = 0, Apply(M [x]) = ha1 [x1 ], . . . , an [xn ]i is a sequence
of operators in A , implying Exp(M [x]) = Apply(M [x]) = ha1 [x1 ], . . . , an [xn ]i. It follows that
|Exp(M [x])|  (S  Ar)1+0 since n  S  Ar.
If h(M ) > 0, Apply(M [x]) = hu1 [x1 ], . . . , un [xn ]i is a sequence of operators and automaton
calls, implying Exp(M [x]) = Exp(u1 [x1 ]);    ; Exp(un [xn ]). For each 1  k  n, if uk  A
then |Exp(uk [xk ])| = 1, else |Exp(uk [xk ])|  (S  Ar)h(M ) by hypothesis of induction since
h(uk ) < h(M ). It follows that |Exp(M [x])|  (S  Ar)1+h(M ) since n  S  Ar.
An automaton plan is a tuple  = h, A, Au, r, xi where h, A, Au, ri is an automaton hierarchy and x  ar(r) is an input string to the root automaton r. While automaton hierarchies represent
families of plans, an automaton plan represents a unique plan given by  = Exp(r[x])  A+
.
In subsequent sections we exploit the notion of uniform expansion, defined as follows:
Definition 7. An automaton hierarchy h, A, Au, ri has uniform expansion if and only if for each
automaton M  Au there exists a number M such that |Exp(M [x])| = M for each x  ar(M ) .
In other words, expanding an automaton call M [x] always results in an operator sequence of length
exactly M , regardless of the input x.
264

fiAUTOMATON P LANS

/

1/M3 [1]
0/M3 [c]

1/M2 [b]

/

1/M3 [1]

0/a1 [0]

/
1/a1 [1]

0/a2 [1]

0/M2 [1]
M1 [abc]

M2 [a]

M3 [a]

Figure 2: The three automata in the simple example.

4. Examples of Automaton Plans
In this section we present several examples of automaton plans. Our aim is first and foremost
to illustrate the concept of automaton plans. However, we also use the examples to illuminate
several interesting properties of automaton plans. For example, we can use small automaton plans
to represent exponentially long plans.
We begin by showing an example of a relatively simple automaton plan on two symbols, two
actions, and three automata, defined as  = h{0, 1}, {a1 , a2 }, {M1 , M2 , M3 }, M1 , 100i. Actions a1
and a2 both have arity 1, and Figure 2 shows the three automata M1 , M2 , and M3 (with arity 3, 1,
and 1, respectively). In the figure, the edge without origin points to the initial state of the automaton,
and the label on this edge contains the name and input string of the automaton.
To simplify the description of index strings and argument maps we assign explicit names (a,
b, and c) to each symbol of the input string of an automaton. Each argument map is described
as a string of input symbol names and symbols from  = {0, 1}. For example, the label M2 [b]
in automaton M1 corresponds to the output symbol (M2 , 2), i.e. the index string from M1 to M2
assigns the second input symbol (b) of M1 to the lone input symbol of M2 . Recall that the symbols
of the input string have two separate functions: to decide which edges of the automaton to transition
along, and to propagate information by copying symbols onto actions and other automata.
The plan  represented by  is given by
 = Exp(M1 [100]) = Exp(Apply(M1 [100])) = Exp(hM2 [0], M3 [0], M2 [1]i) =
= Exp(M2 [0]); Exp(M3 [0]); Exp(M2 [1]) =
= Exp(Apply(M2 [0])); Exp(Apply(M3 [0])); Exp(Apply(M2 [1])) =
= Exp(ha1 [0]i); Exp(ha2 [1]i); Exp(hM3 [1]i) = Exp(a1 [0]); Exp(a2 [1]); Exp(M3 [1]) =
= ha1 [0]i; ha2 [1]i; Exp(Apply(M3 [1])) = ha1 [0]i; ha2 [1]i; Exp(ha1 [1]i) =
= ha1 [0]i; ha2 [1]i; Exp(a1 [1]) = ha1 [0]i; ha2 [1]i; ha1 [1]i = ha1 [0], a2 [1], a1 [1]i.
Selecting another root automaton call would result in a different operator sequence. For example,
the root M1 [000] would result in the sequence Exp(M1 [000]) = ha1 [1]i, and the root M1 [101] would
result in Exp(M1 [101]) = ha1 [0], a1 [1], a1 [0]i.
We next show that just like macro plans, automaton plans can compactly represent plans that
are exponentially long. Figure 3 shows an automaton Mn for moving n discs from peg a to peg
b via peg c in Towers of Hanoi. In the figure, An [ab] is the action for moving disc n from a to
b. For n = 1 the edge label should be /hA1 [ab]i. It is not hard to show that the automaton plan
 = h{1, 2, 3}, {A1 , . . . , AN }, {M1 , . . . , MN }, MN , 132i is a plan for the Towers of Hanoi instance
265

fiB ACKSTR OM , J ONSSON , & J ONSSON

/hMn1 [acb], An [ab], Mn1 [cba]i

/

Mn [abc]
Figure 3: The automaton Mn in the automaton plan for Towers of Hanoi.
li = qi /

/A[zqf qt ap]

qt = lt /
/

D[li qi qt lt ci ct ti xtt yazp]

li 6= qi /T[xli qi ci ti p]
x = y/

qt 6= lt /T[yqt lt ct tt p]
/hLT[tpy], DT[tyzc], UT[tpz]i
/

T[xyzctp]

x 6= y/DT[txyc]
x = y/

/hLA[apy], FA[ayz], UA[apz]i
/

A[xyzap]

x 6= y/FA[axy]

Figure 4: The automata D for delivering a package and T, A for moving a package using a
truck/airplane.

with N discs. Unlike macro solutions for Towers of Hanoi (Jonsson, 2009), the automaton plan has
a single automaton per disc, which is possible because of parameterization.
The ability to parameterize automata also makes it possible to represent other types of plans
compactly. Figure 4 shows three automata D, T, and A that can be combined to construct an
automaton plan for any instance of the L OGISTICS domain. The set of symbols  contains the
objects of the instance: packages, airplanes, trucks, cities, and locations. The automaton T moves a
package using a truck, and the input string xyzctp consists of three locations x, y, and z, a city c, a
truck t, and a package p. Initially, truck t is at x, package p is at y, and the destination of package p
is z. The actions DT, LT, and UT stand for DriveTruck, LoadTruck, and UnloadTruck, respectively.
Automaton T assumes that locations y and z are different, else there is nothing to be done and
the automaton outputs the empty string, violating the definition of automaton plans. On the other
hand, locations x and y may be the same, and the automaton checks whether they are equal. Only
when x and y are different is it necessary to first drive truck t from x to y. We use the notation
x = y and x 6= y as shorthand to denote that there are |L| intermediate notes, one per location, such
that the automaton transitions to a distinct intermediate node for each assignment of a location to x.
From each intermediate node there are |L| edges to the next node: |L|  1 of these edges correspond
to x 6= y and only one edge corresponds to x = y.
Once the truck is at location y, the operator sequence output by T loads package p in t, drives
t to the destination, and unloads p from t. Automaton A for moving a package using an airplane
is similarly defined on actions FA (FlyAirplane), LA (LoadAirplane), and UA (UnloadAirplane).
Automaton D delivers a package from its current location to its destination, and the input string
li qi qt lt ci ct ti xtt yazp consists of the initial location li of the package, intermediate airports qi and
266

fiAUTOMATON P LANS

/hU[rk1 l1 ], . . . , U[ln1 kn ln ], D[ln k2 d1 ], . . . , D[dn1 k2 dn ]i
M[rk1 l1 d1    kn ln dn ]
U[l1 l2 l3 ]

/hN[l1 l2 ], pickup-and-loose[l2 ], N[l2 l3 ], unlock[l3 ]i
/hN[l1 l2 ], pickup[l2 ], N[l2 l3 ], putdown[l3 ]i

/
/
/

D[l1 l2 l3 ]
Figure 5: The automata in an automaton plan for the G RID domain.

qt , the target location lt , the initial and target cities ci and ct , a truck ti in city ci initially at x, a
truck tt in city ct initially at y, an airplane a initially at z, and the package p itself. Automaton D
assumes that cities ci and ct are different, else we could use automaton T to transport the package
using a truck within a city. However, locations li and qi may be equal, as well as qt and lt , and the
automaton only moves the package using a truck whenever necessary.
We also show an example automaton plan for the G RID domain, in which a robot has to deliver
keys to locations, some of which are locked. The keys are distributed at initial locations, and the
robot can only carry one key at a time. The actions are to move the robot to a neighboring location,
pick up a key (possibly loosing the key currently held), put down a key, and unlock a location.
Figure 5 shows an automaton plan for an instance of G RID. The root automaton M takes as
input the current location of the robot (r) and three locations ki , li , and di for each key, where ki
is the current location of the key, li is the associated locked location, and di is the destination. The
plan works by first unlocking all locations in a prespecified order (which must exist for the problem
to be solvable) and then delivering all keys to their destination.
The automaton U takes three locations: the location of the robot (l1 ), the location of the key
(l2 ), and the location to be unlocked (l3 ). The decomposition navigates to the key, picks it up,
navigates to the location, and unlocks it. Delivering a key works in a similar way. For simplicity
some parameters of actions have been omitted, and a few modifications are necessary: the first time
U is applied there is no key to loose, and the first time D is applied there is a key to loose.
The automaton N (not shown) navigates between pairs of locations l1 and l2 . Since automaton
plans cannot keep track of the state, N has to include one automaton state for each possible input
(l1 , l2 ) (alternatively we can define a separate automaton for each destination l2 ). Note that the
automaton M can be used to represent solutions to different instances on the same set of locations.

5. Relationship to Other Compact Plan Representations
In this section we compare and contrast automaton plans to other compact plan representations from
the literature: macro plans, HTNs (Erol et al., 1996), as well as C RARs and C SARs (Backstrom &
Jonsson, 2012). Informally, C RARs and C SARs are theoretical concepts describing any compact
representation of a plan that admits efficient random access (C RAR) or sequential access (C SAR)
to the operators of the plan. To compare plan representations we use the following subsumption
relation (Backstrom et al., 2012b):
267

fiB ACKSTR OM , J ONSSON , & J ONSSON

p

p

M ACR

C RAR

C SAR

p
6p

p

p
p

AUTRUE

AUTR

p

HTN

Figure 6: Summary of subsumption results, with dashed edges marking previously known results.
Definition 8. Let X and Y be two plan representations. Then Y is at least as expressive as X, which
we denote X p Y , if there is a polynomial-time function g such that for each S TRIPS planning
instance p and each plan  for p, if  is an X representation of , g() is a Y representation of .
Figure 6 summarizes the subsumption results for the different plan representations considered
in this paper. M ACR and AUTR refer to macro plans and automaton plans, respectively, while
AUTRUE refer to automaton plans with uniform expansion. Previously known results are shown
using dashed edges; the remaining results are proven in this section. We use the notation X p Y
to indicate that X p Y and Y 6p X. From the figure we see that automaton plans are strictly
more expressive than macro plans, but strictly less expressive than C SARs and HTNs. In the case
of C RARs, we only prove a partial result: that automaton plans with uniform expansion can be
translated to C RARs.
In the rest of this section, we first show that automaton plans with uniform expansion can be
efficiently transformed to C RARs. We then prove that plan verification for automaton plans is p2 complete. We use this latter result to prove separation between macro plans and automaton plans,
and between automaton plans and C SARs/HTNs. When proving that X p Y holds for two representations X and Y , we assume that the size of the X representation is polynomial in ||p||, the
description size of the planning instance. Trivially, automaton plans with uniform expansion are
also automaton plans, while it is unknown whether general automaton plans can be efficiently transformed such that they have uniform expansion.
5.1 Automaton Plans and C RARs
In this section we show that automaton plans with uniform expansion can be efficiently translated to
C RARs, i.e. compact plan representations that admit efficient random access. We first define C RARs
and then describe an algorithm for transforming each automaton plan with uniform expansion to a
corresponding C RAR.
Definition 9. Let p be a polynomial function. Given a S TRIPS planning instance p = hP, A, , I, Gi
with associated plan , a p-C RAR of  is a representation  such that ||||  p(||p||) and  outputs
the k-th element of  in time and space p(||p||) for each 1  k  ||.
Note that for  to be a p-C RAR, the polynomial function p has to be independent of the planning
instance p, else we can always find a constant for each individual instance p such that the size of
any representation for p is bounded by this constant.
268

fiAUTOMATON P LANS

1
2
3
4
5
6
7
8

function Find(k, u[x])
if u[x]  A return u[x]
else
hu1 [x1 ], . . . , un [xn ]i  Apply(u[x])
s  0, j  1
while s + (uj ) < k do
s  s + (uj ), j  j + 1
return Find(k  s, uj [xj ])
Figure 7: Algorithm for using an automaton plan as a C RAR.

Theorem 1. AUTRUE p C RAR.
Proof. To prove the theorem we show that for each S TRIPS planning instance p and each automaton
plan  = h, A, Au, r, xi with uniform expansion representing a plan  for p, we can efficiently
construct a corresponding p-C RAR for  with p(||p||) = (Ar + (log S + log Ar)|Au|)  S  Ar  |Au|.
Since  has uniform expansion there exist numbers M , M  Au, such that |Exp(M [x])| = M
for each x  ar(M ) . The numbers M can be computed bottom up as follows. Traverse the
automata of the expansion graph GAu in reverse topological order. For each M  Au, pick an input
string x  ar(M ) at random and compute Apply(M [x]) = hu1 [y1 ], . . . , un [yn ]i. The number M
is given by M = u1 + . . . + un where, for each 1  k  n, uk = 1 if uk  A and uk has already
been computed if uk  Au since by definition, uk comes after M in any topological ordering.
Because of Lemma 3, the total complexity of computing Apply(M [x]) for all M  Au is
S  Ar2  |Au|. Due to Lemma 6, M  (S  Ar)1+h(M )  (S  Ar)|Au| for each M  Au. Since
(S  Ar)|Au| = 2(log S+log Ar)|Au| , we need at most (log S + log Ar)|Au| bits to represent M , and
computing M requires at most (log S +log Ar)S Ar|Au| operations. Repeating this computation
for each M  Au gives us a complexity bound of (Ar + (log S + log Ar)|Au|)  S  Ar  |Au|.
We prove that the recursive algorithm Find in Figure 7 has the following properties, by induction
over the number of recursive calls:
1. for each M [x]  Au such that Exp(M [x]) = ha1 [x1 ], . . . , an [xn ]i, Find(k, M [x]) returns
operator ak [xk ] for 1  k  n, and
2. for each a[x]  A , Find(k, a[x]) returns a[x].
Basis: If Find(k, u[x]) does not call itself recursively, then u[x] must be an operator. By definition, Exp(u[x]) = u[x] since u[x]  A .
Induction step: Suppose the claim holds when Find makes at most m recursive calls for some
m  0. Assume Find(k, u[x]) makes m+1 recursive calls. Let hu1 [x1 ], . . . , un [xn ]i = Apply(u[x])
and, for each 1  k  n, (uk ) = 1 if uk [xk ]  A and (uk ) = uk if uk [xk ]  Au . Lines 57
computes s and j such that either
1. j = 1, s = 0 and k  (u1 ) or
2. j > 1, s = (u1 ) + . . . + (uj1 ) < k  (u1 ) + . . . + (uj ).
By definition, Exp(u[x]) = Exp(u1 [x1 ]); . . . ; Exp(un [xn ]), implying that operator k in Exp(u[x])
is operator k  s in Exp(uj [xj ]). It follows from the induction hypothesis that the recursive call
Find(k  s, uj [xj ]) returns this operator.
269

fiB ACKSTR OM , J ONSSON , & J ONSSON

To prove the complexity of Find, note that Find calls itself recursively at most once for each
M  Au since GAu is acyclic. Moreover, the complexity of computing Apply(M [x]) is bounded
by S  Ar2 , and the while loop on lines 67 runs at most n  S  Ar times, each time performing
at most (log S + log Ar)|Au| operations to update the value of s. We have thus showed that the
automaton plan  together with the procedure Find and the values M , M  Au, constitute a pC RAR for  with p(||p||) = (Ar + (log S + log Ar)|Au|)  S  Ar  |Au|.
5.2 Verification of Automaton Plans
In this section we show that the problem of plan verification for automaton plans is p2 -complete.
We first prove membership by reducing plan verification for automaton plans to plan verification for
C RARs, which is known to be p2 -complete (Backstrom et al., 2012b). We then prove hardness by
reducing -SAT, which is also p2 -complete, to plan verification for automaton plans with uniform
expansion. The complexity result for plan verification is later used to separate automaton plans from
macro plans, C SARs, and HTNs, but we do not obtain a similar separation result between automaton
plans and C RARs since the complexity of plan verification is the same.
To prove membership we first define an alternative expansion function Exp that pads the original plan with dummy operators until the expansion of each automaton has the same length for each
accepting input. Intuitively, even though the original automaton plan need not have uniform expansion, the alternative expansion function Exp emulates an automaton plan that does. Note that this
is not sufficient to prove that we can transform any automaton plan to a p-C RAR, since operators
have different indices in the plans represented by the two expansion functions Exp and Exp .
Let p be a planning instance, and let  = h, A, Au, r, xi be an automaton plan representing a
solution  to p. For each automaton M  Au, let IM = (S  Ar)1+h(M ) be the upper bound on
|Exp(M [x])| from Lemma 6. Let  = h, i be a parameter-free dummy operator with empty preand postcondition, and add  to A . Define  k , k > 0, as a sequence containing k copies of . We
define an alternative expansion function Exp on (A  Au )+ as follows:
1. Exp (a[x]) = ha[x]i if a[x]  A ,
2. Exp (M [x]) = Exp (Apply(M [x]));  L if M [x]  Au , where the length of  L is L =
IM  |Exp (Apply(M [x]))|,
3. Exp (hu1 [y1 ], . . . , un [yn ]i) = Exp (u1 [y1 ]); . . . ; Exp (un [yn ]).
The only difference with respect to the original expansion function Exp is that the alternative expansion function Exp appends a sequence  L of dummy operators to the result of Exp (Apply(M [x])),
causing Exp (M [x]) to have length exactly IM .
In the following lemma we prove that the operator sequence output by the alternative expansion
function Exp is equivalent to the operator sequence output by the original expansion function Exp.
Lemma 10. For each automaton call M [x]  Au , Exp (M [x])  AIM , and applying Exp(M [x])
and Exp (M [x]) to any state s either is not possible or results in the same state.
Proof. We prove the lemma by induction over |Au|. The base case is given by |Au| = 1. In this
case, since GAu is acyclic, Apply(M [x]) is a sequence of operators ha1 [x1 ], . . . , an [xn ]i  A+
,
270

fiAUTOMATON P LANS

implying
Exp(M [x]) = ha1 [x1 ], . . . , an [xn ]i,
Exp (M [x]) = ha1 [x1 ], . . . , an [xn ]i;  L ,
where L = IM  n. Thus Exp (M [x])  AIM , and applying Exp (M [x]) in a state s has the same
effect as applying Exp(M [x]) since the dummy operator  is always applicable and has no effect.
We next prove the inductive step |Au| > 1. In this case, Apply(M [x]) is a sequence of operators
and automaton calls hu1 [y1 ], . . . , un [yn ]i  (A  Au )+ , implying
Exp(M [x]) = Exp(u1 [x1 ]);    ; Exp(un [xn ]),
Exp (M [x]) = Exp (u1 [x1 ]);    ; Exp (un [xn ]);  L ,
where  L contains enough copies of  to make |Exp (M [x])| = IM . For each 1  k  n, if uk [xk ]
is an operator we have Exp (uk [xk ]) = Exp(uk [xk ]) = huk [xk ]i, which clearly has identical
effects. On the other hand, if uk [xk ] is an automaton call, since GAu is acyclic we have uk [xk ] 
(Au \ {M }) , implying that Exp (uk [xk ]) has the same effect as Exp(uk [xk ]) by hypothesis of
induction since |Au \ {M }| < |Au|. Thus Exp (M [x])  AIM , and applying Exp (M [x]) in a
state s has the same effect as applying Exp(M [x]) since the dummy operator  is always applicable
and has no effect.
We are now ready to prove membership in p2 . Because of Lemma 10, instead of verifying the
plan Exp(r[x]), we can verify the plan Exp (r[x]) given by the alternative expansion function Exp .
Lemma 11. Plan verification for AUTR is in p2 .
Proof. We prove the lemma by reducing plan verification for automaton plans to plan verification
for C RARs, which is known to be p2 -complete (Backstrom et al., 2012b). Consider any automaton
plan  = h, A, Au, r, xi associated with a S TRIPS planning instance p. Instead of constructing
a p-C RAR for the operator sequence Exp(r[x]) represented by , we construct a p-C RAR for the
operator sequence Exp (r[x]). Due to Lemma 10, Exp(r[x]) is a plan for p if and only if Exp (r[x])
is a plan for p.
A p-C RAR for Exp (r[x]) can be constructed by modifying the algorithm Find in Figure 7.
Instead of using the numbers M associated with an automaton plan with uniform expansion, we
use the upper bounds IM on the length of any operator sequence output by each automaton. The
only other modification we need to make is add a condition j  n to the while loop, and if the while
loop terminates with j = n + 1, we should return , since this means that Iu1 +    + Iun < k  Iu .
The complexity of the resulting p-C RAR is identical to that in the proof of Theorem 1 since the
numbers IM are within the bounds used in that proof, i.e. IM  (S  Ar)|Au| for each M  Au.
As an example, consider the automaton plan  = h{0, 1}, {a1 , a2 }, {M1 , M2 , M3 }, M1 , 100i
with M1 , M2 , and M3 defined in Figure 2. Applying the definitions we obtain S = 3, Ar = 4,
h(M1 ) = 2, h(M2 ) = 1, and h(M3 ) = 0, which yields
IM1 = (S  Ar)1+h(M1 ) = 123 = 1728,
IM2 = (S  Ar)1+h(M2 ) = 122 = 144,
IM3 = (S  Ar)1+h(M3 ) = 121 = 12.
271

fiB ACKSTR OM , J ONSSON , & J ONSSON

Although IM1 = 1728 is a gross overestimate on the length of any operator sequence output by
M1 , the number of bits needed to represent IM1 is polynomial in ||||. Applying the alternative
expansion function Exp to  yields Exp (M1 [100]) = ha1 [0]i;  143 ; ha2 [1]i;  11 ; ha1 [1]i;  1571 .
To prove p2 -completeness, it remains to show that plan verification for automaton plans is
p
2 -hard. The proof of the following lemma is quite lengthy, so we defer it to Appendix A.
Lemma 12. Plan verification for AUTRUE is p2 -hard.
The main theorem of this section now follows immediately from Lemmas 11 and 12.
Theorem 2. Plan verification for AUTRUE and AUTR is p2 -complete.
Proof. Since AUTRUE  AUTR, Lemma 11 implies that plan verification for AUTRUE is in p2 ,
while Lemma 12 implies that plan verification for AUTR is p2 -hard. Thus plan verification for both
AUTRUE and AUTR is p2 -complete.
5.3 Automaton Plans and Macro Plans
In this section we show that automaton plans are strictly more expressive than macros. To do this, we
first define macro plans and show that any macro plan can trivially be converted into an equivalent
automaton plan with uniform expansion. We then show that there are automaton plans that cannot
be efficiently translated to macro plans.
A macro plan  = hM, mr i for a S TRIPS instance p consists of a set M of macros and a root
macro mr  M. Each macro m  M consists of a sequence m = hu1 , . . . , un i where, for each
1  k  n, uk is either an operator in A or another macro in M. The expansion of m is a
sequence of operators in A obtained by recursively replacing each macro in hu1 , . . . , un i with its
expansion. This process is well-defined as long as no macro appears in its own expansion. The plan
 represented by  is given by the expansion of the root macro mr .
Lemma 13. M ACR p AUTRUE.
Proof. To prove the lemma we show that there exists a polynomial p such that for each S TRIPS
planning instance p and each macro plan  representing a solution  to p, there exists an automaton
plan  for  with uniform expansion such that |||| = O(p(||||)).
Each macro of  is a parameter-free sequence m = hu1 , . . . , ul i of operators and other macros.
We can construct an automaton plan  by replacing each macro m with an automaton Mm such that
ar(Mm ) = 0. The automaton Mm has two states s0 and s, and two edges: one from s0 to s with
label /h(w1 , 1 ), . . . , (wl , l )i, and one from s to itself with label /. For each 1  j  l, if
uj is an operator, then wj is the associated action and the index string j  ar(uj ) contains the
arguments of uj in the sequence m, which have to be explicitly stated since m is parameter-free. If
uj is a macro, then wj = Muj and j =  since ar(Mm ) = ar(Muj ) = 0. The root of  is given
by r = Mmr [], where mr is the root macro of .
We show by induction that, for each macro m = hu1 , . . . , ul i of , Exp(Mm []) equals the
expansion of m. The base case is given by |Au| = 1. Then m is a sequence of operators in
A+
 , and Apply(Mm []) returns m, implying Exp(Mm []) = Apply(Mm []) = m. If |Au| > 1,
Apply(Mm []) contains the same operators as m, but each macro uj in m, where 1  j  l,
is replaced with the automaton call Muj []. By hypothesis of induction, Exp(Muj []) equals the
expansion of uj . Then Exp(Mm []) equals the expansion of m since both are concatenations of
272

fiAUTOMATON P LANS

identical sequences. It is easy to see that the size of each automaton Mm is polynomial in m. We
have shown that each macro plan  can be transformed into an equivalent automaton plan  whose
size is polynomial in ||||, implying the existence of a polynomial p such that |||| = O(p(||||)).
The automaton plan trivially has uniform expansion since each automaton is always called on the
empty input string.
We next show that automaton plans with uniform expansion are strictly more expressive than
macro plans.
Theorem 3. M ACR p AUTRUE unless P = p2 .
Proof. Due to Lemma 13 it remains to show that AUTRUE 6p M ACR, i.e. that we cannot efficiently
translate arbitrary automaton plans with uniform expansion to equivalent macro plans. Backstrom
et al. (2012b) showed that plan verification for macro plans is in P. Assume that there exists a
polynomial-time algorithm that translates any automaton plan with uniform expansion to an equivalent macro plan. Then we could verify automaton plans with uniform expansion in polynomial
time, by first applying the given algorithm to produce an equivalent macro plan and then verifying
the macro plan in polynomial time. However, due to Theorem 2, no such algorithm can exist unless
P = p2 .
5.4 Automaton Plans and C SARs
In this section we show that automaton plans are strictly less expressive than C SARs, defined as
follows:
Definition 14. Let p be a polynomial function. Given a S TRIPS planning instance p = hP, A, , I, Gi
with associated plan , a p-C SAR of  is a representation  such that ||||  p(||p||) and  outputs
the elements of  sequentially, with the time needed to output each element bounded by p(||p||).
Just as for p-C RARs, the polynomial function p of a p-C SAR has to be independent of the planning
instance p. We first show that any automaton plan can be transformed into an equivalent p-C SAR
in polynomial time. We then show that there are p-C SARs that cannot be efficiently translated to
automaton plans.
Lemma 15. AUTR p C SAR.
Proof. To prove the lemma we show that for each S TRIPS planning instance p and each automaton
plan  representing a solution  to p, we can efficiently construct a corresponding p-C SAR for 
with p(||p||) = S  Ar2  |Au|. We claim that the algorithm Next in Figure 8 always outputs the next
operator of  in polynomial time. The algorithm maintains the following global variables:
 A call stack S = [M1 [x1 ], . . . , Mk [xk ]] where M1 [x1 ] = r[x] is the root of  and, for each
1 < i  k, Mi [xi ] is an automaton call that appears in Apply(Mi1 [xi1 ]).
 An integer k representing the current number of elements in S.
 For each 1  i  k, a sequence i that stores the result of Apply(Mi [xi ]).
 For each 1  i  k, an integer zi which is an index of i .
273

fiB ACKSTR OM , J ONSSON , & J ONSSON

1 function Next()
2
while zk = |k | do
3
if k = 1 return 
4
else
5
pop Mk [xk ] from S
6
k k1
7
repeat
8
zk  zk + 1
9
u[x]  k [zk ]
10
if u[x]  A return u[x]
11
else
12
push u[x] onto S
13
k k+1
14
k  Apply(u[x])
15
zk  0
Figure 8: Algorithm for finding the next operator of an automaton plan.
Prior to the first call to Next, the global variables are initialized to S = [r[x]], k = 1, 1 =
Apply(r[x]), and z1 = 0.
The algorithm Next works as follows. As long as there are no more elements in Apply(Mk [xk ]),
the automaton call Mk [xk ] is popped from the stack S and k is decremented. If, as a result, k = 1
and Apply(M1 [x1 ]) contains no more elements, Next returns , correctly indicating that the plan
 has no further operators.
Once we have found an automaton call Mk [xk ] on the stack such that Apply(Mk [xk ]) contains
more elements, we increment zk and retrieve the element u[x] at index zk of k . If u[x]  A , u[x]
is the next operator of the plan and is therefore returned by Next. Otherwise u[x] is pushed onto the
stack S, k is incremented, k is set to Apply(u[x]), zk is initialized to 0, and the process is repeated
for the new automaton call Mk [xk ] = u[x].
Since the expansion graph GAu is acyclic, the number of elements k on the stack is bounded by
|Au|. Thus the complexity of the while loop is bounded by |Au| since all operations in the loop have
constant complexity. Since Exp(M1 [x1 ]) = Exp(r[x])  A+
 , the repeat loop is guaranteed to find
k and zk such that u[x] = k [zk ] is an operator, proving the correctness of the algorithm. The only
operation in the repeat loop that does not have constant complexity is Apply(u[x]); from Lemma 3
we know that this complexity is bounded by S  Ar2 , and we might have to repeat this operation
at most |Au| times. The space required to store the global variables is bounded by Ar  |Au|. We
have shown that the global variables together with the algorithm Next constitute a p-C SAR with
p(||p||) = O(S  Ar2  |Au|).
We next show that automaton plans are strictly less expressive than p-C SARs. Let P1 be the
subclass of S TRIPS planning instances such that at most one operator is applicable in each reachable
state. The following lemma is due to Bylander (1994):
Lemma 16. Plan existence for P1 is PSPACE-hard.
274

fiAUTOMATON P LANS

Proof. Bylander presented a polynomial-time reduction from polynomial-space deterministic Turing machine (DTM) acceptance, a PSPACE-complete problem, to S TRIPS plan existence. Given
any DTM, the planning instance p constructed by Bylander belongs to P1 and has a solution if
and only if the DTM accepts.
Theorem 4. AUTR p C SAR unless PSPACE = p3 .
Proof. Due to Lemma 15 it remains to show that C SAR 6p AUTR. We first show that plan verification for C SARs is PSPACE-hard. Given a planning instance p in P1 , let  be the unique plan
obtained by always selecting the only applicable operator, starting from the initial state. Without
loss of generality, we assume that no operators are applicable in the goal state. Hence  either solves
p, terminates in a dead-end state, or enters a cycle. It is trivial to construct a p-C SAR  for : in each
state, loop through all operators and select the one whose precondition is satisfied. Critically, the
construction of  is independent of . Due to Lemma 16, it is PSPACE-hard to determine whether
p has a solution, i.e. whether the plan represented by  solves p.
On the other hand, assume that there exists an automaton plan  for  such that |||| = O(p(||p||))
p
for some fixed polynomial p. Then we can solve plan existence for p in NP2 = p by non3

deterministically guessing an automaton plan and verifying that it represents a solution to p. This
implies that PSPACE = p3 .
5.5 Automaton Plans and HTNs
In this section we show that automaton plans are strictly less expressive than HTNs. We begin
by defining the class of HTNs that we compare to automaton plans. We then show that we can
efficiently transform automaton plans to HTNs, but not the other way around.
Just like planning instances, an HTN involves a set of fluents, a set of operators, and an initial
state. Unlike planning instances, however, in which the aim is to reach a goal state, the aim of
an HTN is to produce a sequence of operators that perform a given set of tasks. Each task has
one or more associated methods that specify how to decompose the task into subtasks, which can
either be operators or other tasks. Planning proceeds by recursively decomposing each task using
an associated method until only primitive operators remain. While planning, an HTN has to keep
track of the current state, and operators and methods are only applicable if their preconditions are
satisfied in the current state.
In general, the solution to an HTN is not unique: there may be more than one applicable method
for decomposing a task, and each method may allow the subtasks in the decomposition to appear in
different order. In contrast, our subsumption relation p is only defined for compact representations
of unique solutions. For this reason, we consider a restricted class of HTNs in which the methods
associated with a task are mutually exclusive and the subtasks in the decomposition of each method
are totally ordered. This class of HTNs does indeed have unique solutions, since each task can only
be decomposed in one way. Since this class of HTNs is a strict subclass of that of HTNs in general,
our results hold for general HTNs if we remove the requirement on the uniqueness of the solution.
Our definition of HTNs is largely based on SHOP2 (Nau, Ilghami, Kuter, Murdock, Wu, &
Yaman, 2003), the state-of-the-art algorithm for solving HTNs. We formally define an HTN domain as a tuple H = hP, A, T, i where hP, Ai is a planning domain, T a set of function symbols called tasks, and  a set of function symbols called methods. Each method    is of
the form ht, pre(), i, where t  T is the associated task, pre() is a precondition, and  =
275

fiB ACKSTR OM , J ONSSON , & J ONSSON

h(t1 , 1 ), . . . , (tk , k )i is a task list where, for each 1  i  k, ti  A  T is an action or a task
and i is an argument map from  to ti . The arity of  satisfies ar()  ar(t), and the arguments
of t are always copied onto . If ar() > ar(t), the arguments with indices ar(t) + 1, . . . , ar()
are free parameters of  that can take on any value. The precondition pre() has the same form
as the precondition of an action in A, i.e. pre() = {(p1 , 1 , b1 ), . . . , (pl , l , bl )} where, for each
1  j  l, pl  P is a predicate, l is an argument map from  to pl , and bl is a Boolean. Each task
t may have multiple associated methods.
An HTN instance is a tuple h = hP, A, T, , , I, Li where hP, A, T, i is an HTN domain, 
a set of objects, I  P an initial state, and L a task list. An HTN instance implicitly defines a set
of grounded tasks T and a set of grounded methods  , and the task list L  T+ is a sequence
of grounded tasks. The precondition pre([xy]) of a grounded method [xy]   , where x is the
parameters copied from t and y is an assignment to the free parameters of , is derived from pre()
in the same way as the precondition pre(a[x]) of an operator a[x] is derived from pre(a).
Unlike S TRIPS planning, the aim of an HTN instance is to recursively expand each grounded
task t[x]  T in L by applying an associated grounded method [xy] until only primitive operators
remain. The grounded method [xy] is applicable if the precondition pre([xy]) is satisfied, and
applying [xy] replaces task t[x] with the sequence of grounded operators or tasks obtained by
applying the sequence of argument maps in  to [xy]. The problem of plan existence for HTNs is
to determine if such an expansion is possible.
Lemma 17. AUTR p HTN.
The proof of Lemma 17 appears in Appendix B. Intuitively, the idea is to construct an HTN in
which tasks are associated with states in the graphs of the automata, and methods with the edges
of these graphs. The HTN emulates an execution model for : each grounded task corresponds to
an automaton M , a current state s in the graph of M , an input string x  ar(M ) , and an index k
of x. The associated grounded methods indicate the possible ways to transition from s to another
state. Given an edge with label /u, the corresponding method is only applicable if xk = , and
applying the method recursively applies all operators and tasks in the sequence u, followed by the
task associated with the next state, incrementing k if necessary.
Theorem 5. AUTR p HTN unless PSPACE = p3 .
Proof. Due to Lemma 17 it remains to show that HTN 6p AUTR. Erol et al. (1996) showed that the
problem of plan existence for propositional HTNs with totally ordered task lists is PSPACE-hard.
Their proof is by reduction from propositional S TRIPS planning, and the number of applicable
methods for each task equals the number of applicable S TRIPS operators in the original planning
instance, which can in general be larger than one. However, due to Lemma 16, we can instead
reduce from the class P1 , resulting in HTNs with at most one applicable method for each task.
If there exists a polynomial-time algorithm that translates HTNs to equivalent automaton plans,
p
we can solve plan existence for HTNs in NP2 = p by non-deterministically guessing an automa3

ton plan and verifying that the automaton plan is a solution. This implies that PSPACE = p3 .

The reasoning used in the proof of Theorem 5 can also be used to show that HTN 6p C RAR,
implying that random access is bounded away from polynomial for HTNs. However, it is unknown
whether C RARs can be efficiently translated to HTNs.
276

fiAUTOMATON P LANS

1
2
3
4
5
6

function Lowest(hP, A, , I, Gi)
sI
while G 6 s do
O  {oi  A : oi is applicable in s}
m  mini oi  O
s  (s \ pre(om ) )  pre(om )+
Figure 9: Algorithm that always selects the applicable operator with lowest index.

One important difference between automaton plans and HTNs is that the latter keeps track
of the state. We conjecture that such state-based compact representations are hard to verify in
general. Consider the algorithm in Figure 9 that always selects the applicable operator in A with
lowest index. This algorithm is a compact representation of a well-defined operator sequence. Plan
verification for this compact representation is PSPACE-hard due to Lemma 16, since for planning
instances in P1 , the algorithm will always choose the only applicable operator. Arguably, our
algorithm is the simplest state-based compact representation one can think of, but plan verification
is still harder than for automaton plans.

6. Related Work
The three main sources of inspiration for automaton plans are macro planning, finite-state automata,
and string compression. Below, we briefly discuss these three topics and their connections with
automaton plans.
6.1 Macro Planning
The connection between macros and automaton plans should be clear at this point: the basic mechanism in automaton plans for recursively defining plans is a direct generalization of macros. In the
context of automated planning, macros were first proposed by Fikes et al. (1972) as a tool for plan
execution and analysis. The idea did not immediately become widespread and even though it was
used in some planners, it was mainly viewed as an interesting idea with few obvious applications.
Despite this, advantageous ways of exploiting macros were identified by, for instance, Minton and
Korf: Minton (1985) proposed storing useful macros and adding them to the set of operators in order
to speed up search while Korf (1987) showed that the search space over macros can be exponentially
smaller than the search space over the original planning operators.
During the last decade, the popularity of macros has increased significantly. This is, for example, witnessed by the fact that several planners that exploit macros have participated in the International Planning Competition. M ARVIN (Coles & Smith, 2007) generates macros online that
escape search plateaus, and offline from a reduced version of the planning instance. M ACRO -FF
(Botea, Enzenberger, Muller, & Schaeffer, 2005) extracts macros from the domain description as
well as solutions to previous instances solved. W IZARD (Newton, Levine, Fox, & Long, 2007) uses
a genetic algorithm to generate macros. Researchers have also studied how macros influence the
computational complexity of solving different classes of planning instances. Gimenez and Jonsson
(2008) showed that plan generation is provably polynomial for the class 3S of planning instances
if the solution can be expressed using macros. Jonsson (2009) presented a similar algorithm for
277

fiB ACKSTR OM , J ONSSON , & J ONSSON

optimally solving a subclass of planning instances with tree-reducible causal graphs. In both cases,
planning instances in the respective class can have exponentially long optimal solutions, making it
impossible to generate a solution in polynomial time without the use of macros.
6.2 Finite State Automata
When we started working on new plan representations, it soon become evident that automata are a
convenient way of organizing the computations needed inside a compactly represented plan. This
thought was not particularly original since automata and automaton-like representations are quite
common in planning. In order to avoid confusion, we want to emphasize that our automaton hierarchies are not equivalent to the concept of hierarchical automata. The term hierarchical automata is
used in the literature as a somewhat loose collective term for a large number of different approaches
to automaton-based hierarchical modelling of systems; notable examples can be found in control
theory (Zhong & Wonham, 1990) and model checking (Alur & Yannakakis, 1998).
There are many examples where solutions to planning problems are represented by automata but
these examples are, unlike automaton plans, typically in the context of non-deterministic planning.
Cimatti, Roveri, and Traverso (1998) presented an algorithm that, when successful, returns strong
cyclic solutions to non-deterministic planning instances. Winner and Veloso (2003) used examples
to learn generalized plans. Bonet, Palacios, and Geffner (2010) used a transformation to classical
planning to generate finite-state controllers for non-deterministic planning. Finally, Hu and De
Giacomo (2013) presented a general algorithm for synthesizing finite state controllers based on a
behavior specification of the domain.
Automata have also been used for representing other objects in planning. Hickmott, Rintanen,
Thiebaux, and White (2007) and LaValle (2006) used automata to represent the entire planning instance. In contrast, Toropila and Bartak (2010) used automata to represent the domains of individual
variables of the instance. Baier and McIlraith (2006) showed how to convert an LTL representation
of temporally extended goals, i.e. conditions that must hold over the intermediate states of a plan,
into a non-deterministic finite automaton.
6.3 String Compression
The ideas behind automaton plans and macro plans are closely related to string compression. Most
algorithms for string compression are variants of the pioneering work by Lempel and Ziv (1976).
Normally, the compressed representation of a string is a straight line program (SLP) which is a
context free grammar that can only generate one single string. One might say that this is precisely
what a hierarchical macro plan is. Although not widely used, there have also been attempts to
use automaton representations of strings in order to achieve more compact representations (cf., see
Zipstein, 1992). One might say that such approaches generalize SLPs in a way that is very similar
to the way automaton plans generalize macro plans. It is important to note that string compression
algorithms per se have limited interest when it comes to representing plans. The basic reason is that
a complete plan first needs to be generated and then compressed by the compression algorithm, and
this excludes the utilization of compact plans in the planning process. For instance, the previously
mentioned polynomial-time macro planning algorithms (Gimenez & Jonsson, 2008; Jonsson, 2009)
cannot be replaced (with preserved computational properties) by a planner combined with a string
compression algorithm since the planner may need to produce an exponentially long plan.
278

fiAUTOMATON P LANS

String compression usually makes no assumptions at all about the content of the string to represent. This makes the methods very general although often not optimal for a particular application.
There are examples, though, of more specialised representations. For instance, Subramanian and
Shankar (2005) present a method for compressing XML documents by using automata that are
based on the XML syntax. Our automaton plans, just like macro plans, do not make any particular
assumptions either about the sequence (or string) to be represented. However, it should be evident
from our examples that we primarily intend the automata of a plan representation to have some
functional correspondence to the plan structure.

7. Discussion
We have introduced the novel concept of automaton plans, i.e. plans represented by hierarchies
of finite state automata. Automaton plans extend macro plans by allowing parameterization and
branching, and can be used to represent solutions to a variety of planning instances. We have showed
that automaton plans are strictly more expressive than macro plans, but strictly less expressive than
HTNs and C SARs, i.e. compact representations allowing polynomial-time sequential access. The
precise relationship between automaton plans and C RARs is still an open question, but we have
presented a partial result: that automaton plans with uniform expansion can be transformed into
C RARs.
In our definition of automaton plans we have restricted ourselves to S TRIPS planning, and a
possible extension would be to consider more general planning formalisms. Below we describe how
such an extension would affect the complexity results in Section 5. Most of our transformations
are valid for any string, and hence independent of the planning formalism. In particular, macro
plans can always be translated to automaton plans with uniform expansion, the latter can always be
transformed to C RARs, and automaton plans can always be transformed to C SARs. However, we
are not aware of any HTN formalism that extends the action definition to allow for more complex
actions. Hence our transformation from automaton plans to HTNs involve actions with S TRIPSstyle preconditions and effects. All separation results for S TRIPS also carry over to more general
planning formalisms since there cannot exist a polynomial function for translating all instances.
Although we have mainly studied the computational properties of automaton plans in the context
of compact plan representation, we believe that automaton plans may find other uses. Probably the
most interesting question from a practical perspective is how to construct automaton plans. We do
not have a definite answer to this question, but there are at least two ideas that we believe are worth
exploring. One possible way to generate automaton plans is to first construct an HTN for a given
domain, and then use the HTN to solve instances of the domain. Instead of flattening the solution
as is typically done, the idea would be to keep its hierarchical structure and transform it into an
automaton plan. It does not matter which HTN representation we consider as long as we can verify
whether a solution to an instance is valid; once the solution has been verified the transformation to
an automaton plan might become tractable, at least in practical cases. This approach would likely
require more sophisticated techniques for generating HTNs than those currently available, unless
the HTN is already provided.
Another interesting extension of automaton plans is to allow recursive automata that include
calls to themselves. Consider the automaton Mn from Section 4 for moving n discs in Towers of
Hanoi. If we introduced symbols j1 , . . . , jN representing the number of discs, we could define a
single recursive automaton M that includes a fourth parameter jn representing the number of discs
279

fiB ACKSTR OM , J ONSSON , & J ONSSON











G

















 

Figure 10: An example contingent planning instance.
to be moved. The recursive calls to M on input jn would include the symbol jn1 , effectively
decrementing the number of discs. For the recursive mechanism to work there would need to exist
a base case for which no more recursive calls are made (in the case of Towers of Hanoi, the base
case typically consists in moving 0 or 1 discs). We remark that the computational properties of
automaton plans from this paper would no longer apply since the expansion graph would no longer
be acyclic.
Finally, modified automaton plans could be used to represent contingent plans compactly. Solutions to contingent planning instances are typically in the form of directed graphs in which each
node is a belief state, i.e. a subset of states. Edges correspond to actions that are applicable in each
belief state, as well as observations about the current state. The outcome of an observation is a single bit indicating whether the current value of a given fluent is true or false. Since the outcome of an
observation is uncertain, each observation splits a belief state into one belief state containing states
for which the fluent is true, and one containing states for which the fluent is false. The solution
represents a policy, indicating which action should be applied in each belief state.
Figure 10 shows an example of a contingent planning instance. Each location is described by
an (x, y)-coordinate. At each location there is an arrow indicating which way to go, and a flag
indicating whether we have reached the target destination G. Two fluents are sufficient to represent
the direction in which the arrow is pointing:
00: up
01: down
10: left
11: right
There are four actions U, D, L, and R for moving up, down, left, and right, respectively. The (x, y)coordinate is not observable, and the initial state is unknown. In each state we can only observe
whether or not we have reached the destination and in which direction the arrow is pointing.
Figure 11 shows an automaton that represents a solution to the example contingent planning
instance. The set of symbols is  = {0, 1}, i.e. symbols are outcomes of observations and are
used to branch on edges of the automaton. In each state we make three consecutive observations:
whether or not we have reached the goal (0 or 1), and in which direction the arrow is pointing (two
bits). If we reach the goal we move to a state where we simply consume the remaining observations
(if any). If not, we use the direction of the arrow to decide which action to apply next.
The automaton solution is independent of the size of the contingent planning instance as long as
the arrows point in the right direction. In contrast, the number of belief states is doubly exponential
|P |
in the number of fluents, i.e. 22  . If we add locations to the example contingent planning problem,
the number of belief states increases exponentially, and so does the size of a solution in the form
280

fiAUTOMATON P LANS

0/
1/D

1/
0/

0/L
1/R

0/U
1/

/

Figure 11: An automaton representing a contingent plan.
of a directed graph. Although the example automaton plan is not hierarchical, it is not difficult to
imagine that navigation is a subtask of a larger problem, in which case we could call the automaton
from other automata.
Although the semantics of contingent planning is different from that of classical planning, the
automata in Figure 11 can be used to construct a perfectly valid automaton plan. However, our
definition imposes two restrictions on contingent plans. First, since automata in automaton plans
have fixed arity, we can only represent contingent plans with a constant number of observations.
Second, the entire sequence of observations has to be passed as input to the automaton beforehand.
It may therefore make sense to consider a relaxation of the definition: allowing input to be passed
to an automaton online, thus allowing the arity of an automaton to vary.

Acknowledgments
The authors would like to thank the anonymous reviewers for their helpful comments and suggestions.

Appendix A. Proof of Lemma 12.
In this section we prove Lemma 12, which states that plan verification for automaton plans with
uniform expansion is p2 -hard. We prove the lemma by reduction from -SAT to plan verification
for automaton plans with uniform expansion. Our proof proceeds in three steps. We first show
how to construct a S TRIPS planning instance pF for any given -SAT formula F . We then prove
that there exists an operator sequence F such that pF has unique solution F if and only if F is
satisfiable. Finally, we construct an automaton plan F with uniform expansion that represents the
sequence F , i.e. F represents a valid plan for pF if and only if F is satisfiable.
Construction 18. Let F = x1    xm y1    yn   be a -SAT formula where  is a 3SAT
formula, and let LF = {1 , . . . , 2(m+n) } be a set of literals, where 2i1 = xi and 2i = xi for
each 1  i  m and 2(m+j)1 = yj and 2(m+j) = yj for each 1  j  n. Also define a
total order < on LF such that i < j if and only if i < j. The formula  = (c1      ch ) is a
conjunction of 3-literal clauses ck = 1k  2k  3k such that 1k , 2k , 3k  LF . Assume without loss of
generality that 1k  2k  3k .
Given the formula F , construct a S TRIPS planning instance pF = hPF , AF , F , IF , GF i
where PF = {f x, f y, f s, sat, x1 , . . . , xm , y1 , . . . , yn , v0 , . . . , vh }, F = {0, 1}, IF = , GF =
281

fiB ACKSTR OM , J ONSSON , & J ONSSON

{f x, sat, x1 , . . . , xm }, and AF contains the following operators, each described on the form
pre(a)  post(a):
os :
olk1 :
olk2 :
olk3 :
onk :
ot :
of :
oyj :
od :
oxi :

{f x, f y, v0 }  {v0 , f s}
{vk1 , vk , 1k }  {vk }
{vk1 , vk , 1k , 2k }  {vk }
{vk1 , vk , 1k , 2k , 3k }  {vk }
{vk1 , vk , 1k , 2k , 3k }  {vk , f s}
{vh , f s}  {f y, v0 , . . . , vh , sat}
{vh , f s}  {f y, v0 , . . . , vh }
{f y, yj , yj+1 , . . . , yn }  {f y, yj , yj+1 , . . . , yn }
{f y, y1 , . . . , yn }  {f x, f y, y1 , . . . , yn }
{f x, sat, xi , xi+1 , . . . , xm }  {f x, sat, xi , xi+1 , . . . , xm }

We explain the intuition behind the planning instance pF . First note that all predicates and actions
are parameter-free, so the set of fluents equals the set of predicates and the set of operators equals
the set of actions. No function map is thus necessary to describe the pre- or postcondition of an
operator. The indices used for operators are in the ranges 1  i  m, 1  j  n, and 1  k  h.
A plan for pF takes the form of three nested loops. The outer loop uses operators of type
oxi to iterate over all assignments to x1 , . . . , xm , the universal variables of the formula F . The
middle loop uses operators of type oyj to iterate over all assignments to y1 , . . . , yn , the existential
variables of F . The inner loop uses operators of type olk1 , olk2 , olk3 , onk to iterate over all clauses of
the 3SAT formula , at the same time verifying whether  is satisfied given the current assignment
to x1 , . . . , xm , y1 , . . . , yn . The remaining fluents have the following functions:
f x: control the applicability of the operators oxi used to iterate over all assignments to x1 , . . . , xm .
f y: control the applicability of the operators oyj used to iterate over all assignments to y1 , . . . , yn .
v0 : control the applicability of the operators olk1 , olk2 , olk3 , onk used to iterate over all clauses.
f s: remember whether  is satisfied for the current assignment to x1 , . . . , xm , y1 , . . . , yn .
sat: remember whether y1 , . . . , yn  is satisfied for the current assignment to x1 , . . . , xm .
During each inner loop, we first have to apply operator os to add fluent v0 . For each clause ck , we
then have to apply one of the operators olk1 , olk2 , olk3 , onk to add vk . Finally, we have to apply one of
ot and of to delete v0 , . . . , vh . During this process, fluent f s is added by os and deleted only if onk
is applied for some clause ck .
Operators ot and of also add f y, causing an operator of type oyj to become applicable. If f s is
true, operator ot also adds sat. Applying an operator of type oyj has the effect of moving to the next
assignment to y1 , . . . , yn . When y1 , . . . , yn are all true, operator od is applicable instead, adding
fluent f x and resetting y1 , . . . , yn to false. When f x is true, we can apply an operator of type oxi
to move to the next assignment to x1 , . . . , xm . These operators all require sat as a precondition.
When x1 , . . . , xm are all true, the goal state GF ensures that we iterate one last time over the middle
loop to make f x and sat true.
282

fiAUTOMATON P LANS

Lemma 19. The -SAT formula F is satisfiable if and only if the planning instance pF has a
unique solution F of the form
F

= E0 , ox, E1 , ox, . . . , ox, E2m 1 ,
n 1

Ei = Vi0 , oy, Vi1 , oy, . . . , oy, Vi2
Vij

, od,

= os, oz1 , oz2 , . . . , ozh , ow,

where each ox is an operator among ox1 , . . . , oxm , each oy is an operator among oy1 , . . . , oyn ,
each ozk , for 1  k  h, is an operator among olk1 , olk2 , olk3 , onk , and ow is an operator among ot,
of .
Proof. We prove the lemma by showing the following:
1. In each state reachable from the initial state IF , at most one operator is applicable.
2. Repeatedly selecting the only applicable operator results in the sequence F given above.
3. The sequence F is applicable in the initial state IF and the goal state GF holds in the resulting state if and only if F is satisfiable.
We first show that in each reachable state, there exists 0  k  h + 1 such that a) when k = 0, all
variables among v0 , . . . , vh are false; b) when 1  k  h, v0 , . . . , vk1 are true and vk , . . . , vh are
false; and c) when k = h + 1 all variables among v0 , . . . , vh are true. While doing so we ignore
operators oyj , od, and oxi since they have no effect on v0 , . . . , vh . In the initial state all fluents are
false so the statement holds for k = 0. If k = 0, the only applicable operator is os which sets v0
to true, effectively incrementing the current value of k. If 1  k  h, the possible operators are
olk1 , olk2 , olk3 , onk . However, the preconditions of these operators are mutually exclusive such that
exactly one of them is applicable. Each of these operators sets vk to true, incrementing the value of
k. Finally, if k = h + 1, the possible operators are ot and of . The preconditions of these operators
are also mutually exclusive, and both operators set v0 , . . . , vh to false, effectively resetting the value
of k to 0.
The only operators affecting fluents y1 , . . . , yn are oy1 , . . . , oyn . Each of these requires f y as a
precondition and sets f y to false. The only operators setting f y to true are ot and of , which both
reset k to 0. This implies that each time we want to apply an operator of type oyj , fluents v0 , . . . , vh
need to go through a complete cycle from k = 0 to k = h + 1 and finish with ot or of . This cycle
corresponds exactly to the sequence Vij of the lemma.
We next show that y1 , . . . , yn act as a binary counter from 0 to 2n  1, enumerating all assignments to the existential variables of the formula F . Note that the preconditions of oy1 , . . . , oyn are
mutually exclusive, since oyn requires yn , oyn1 requires yn1 , yn , and so on. Specifically, the only
applicable operator is oyj , where 1  j  n is the largest index such that yj is false. Repeatedly
283

fiB ACKSTR OM , J ONSSON , & J ONSSON

applying the only available operator results in the following series of values for y1 , . . . , yn :
0    000
0    001
0    010
0    011
0    100
0    101
..
.
If y1 , . . . , yn are all true, there exists no applicable operator of type oyj , but operator od is applicable
instead.
The only operators affecting fluents x1 , . . . , xm are ox1 , . . . , oxm . Each of these requires f x
as a precondition and sets f x to false. The only operator setting f x to true is od, which also resets
y1 , . . . , yn to false. This implies that each time we want to apply an operator of type oxi , fluents
y1 , . . . , yn need to go through a complete cycle from 0 to 2n  1 and finish with od. This cycle
corresponds exactly to the sequence Ei of the lemma.
Since the operators ox1 , . . . , oxm have the same form as oy1 , . . . , oyn , at most one of them
is applicable, and repeatedly applying the only available operator among ox1 , . . . , oxm causes the
fluents x1 , . . . , xm to act as a binary counter from 0 to 2m  1, enumerating all assignments to the
universal variables of the formula F . The precondition {f x, f y} of operator os ensures that os is
not applicable whenever we are about to apply an operator of type oyj or oxi . To achieve the goal
state GF = {f x, sat, x1 , . . . , xm }, the fluents x1 , . . . , xm have to complete a full cycle from 0 to
2m  1, and to set f x to true the fluents y1 , . . . , yn have to complete one last cycle after setting
x1 , . . . , xm to true. This corresponds exactly to the sequence F of the lemma.
Finally, we need to show that the sequence F is applicable in the initial state IF and that the
goal state GF holds in the resulting state if and only if the formula F is satisfiable. In the initial
state IF and after using an operator of type oxi to iterate over x1 , . . . , xm , the fluent sat is false.
Each time we apply os, fluent f s is added. While iterating over the clauses, f s is deleted if and only
if we apply an operator of type onk , i.e. there exists a clause ck that is not satisfied by the current
assignment to x1 , . . . , xm , y1 , . . . , yn . If f s is true at the end of this loop, operator ot adds sat.
If the formula F is not satisfied, there exists an assignment to x1 , . . . , xm such that  is unsatisfied for each assignment to y1 , . . . , yn . Consequently, sat is false when applying the operator od
making f x true for that assignment to x1 , . . . , xm . Then either no operator of type oxi is applicable
(if at least one fluent among x1 , . . . , xm is false) or the goal state GF does not hold in the resulting
state (if x1 , . . . , xm are all true). Conversely, if F is satisfied, sat is always true when applying od,
causing F to be applicable and GF to hold in the resulting state.
We now proceed to construct an automaton plan that represents the operator sequence F described in Lemma 19.
Construction 20. Let pF = hPF , AF , F , IF , GF i be the planning instance defined in Construction 18. Construct an automaton plan F = hF , AF , AuF , r, xi with the following properties:
 AuF = {X1 , . . . , Xm , Y1 , . . . , Yn , S1 , . . . , Sh+1 , U1 , . . . , Uh+1 },
284

fiAUTOMATON P LANS

/
Xi [x]

/hXi+1 [x0], oxi , Xi+1 [x1]i

Xm [x]

/hY1 [x0], od, oxm , Y1 [x1], odi

Yj [x]

/hYj+1 [x0], oyj , Yj+1 [x1]i

Yn [x]

/hos, S1 [x0], oyn , os, S1 [x1]i

/

/

/

/Sk+1 [x]
1k /olk1
Sk [x]

a /

2k /olk2
1k /

b /

3k /olk3

2k /

c /

/
3k /honk , Uk+1 [x]i
/Uk+1 [x]

1k /olk1
Uk [x]

a /

2k /olk2
1k /

b /

3k /olk3

2k /

c /

/
3k /honk , Uk+1 [x]i
/

Sh+1 [x]

/hoti

Uh+1 [x]

/hof i

/

Figure 12: Graphs of the automata defined in Construction 20.

285

fiB ACKSTR OM , J ONSSON , & J ONSSON

 for each 1  i  m, ar(Xi ) = i  1,
 for each 1  j  n, ar(Yj ) = m + j  1,
 for each 1  k  h + 1, ar(Sk ) = ar(Uk ) = m + n,
 r = X1 and x = .
The graphs associated with the automata in Aun are shown in Figure 12. The indices used to
describe automata are in the ranges 1  i < m, 1  j < n, and 1  k  h. For each automaton
M [x], the argument maps are described as u[x], u[x0], or u[x1], indicating that the input string x
of M [x] is copied onto u, possibly appending 0 or 1 at the end.
Intuitively, the input string x of automata Sk and Uk represents an assignment to the fluents
x1 , . . . , xm , y1 , . . . , yn . The edge with label a consumes a input symbols, where a is the number
of variables that precede the variable corresponding to the literal 1k . Likewise, b is the number of
variables between 1k and 2k , and c is the number of variables between 2k and 3k . The assignment to
1k determines whether to output operator olk1 or continue checking whether ck is satisfied.
Note that all automata defined in Construction 20 have uniform expansion. For each 1  k  h
and x  m+n , Apply(Sk [x]) contains exactly one operator among olk1 , olk2 , olk3 , onk , followed by
either Sk+1 [x] or Uk+1 [x]. The same is true for Uk . We show that the automaton plan F defined in
Construction 20 indeed represents the operator sequence F from Lemma 19.
Lemma 21. The automaton plan F represents the operator sequence F .
Proof. For each 1  i  m, the input string x to the automaton Xi represents an assignment of
values to the fluents x1 , . . . , xi1 of the planning instance pF . For each 1  j  n, the input string
to Yj represents an assignment of values to x1 , . . . , xm , y1 , . . . , yj1 , and for each 1  k  h + 1,
the input string to Sk and Uk represents a complete assignment of values to x1 , . . . , xm , y1 , . . . , yn .
Consequently, the symbol that Xi appends to x represents the current value of xi , and the symbol
that Yj appends represents the current value of yj .
Since each automaton Xi first sets xi to 0 and then to 1, the series of assignments to x1 , . . . , xm
becomes
0    000
0    001
0    010
0    011
0    100
0    101
..
.
which is identical to the binary counter on x1 , . . . , xm induced by the plan F . Likewise, for each
assignment to x1 , . . . , xm , the assignments to y1 , . . . , yn describe the same binary counter as F .
Before changing the value of fluent xi from 0 to 1, the automaton Xi inserts operator oxi .
The last assignment to xi+1 , . . . , xm before appending oxi is 1, . . . , 1, and the first assignment to
xi+1 , . . . , xm after appending oxi is 0, . . . , 0. Consequently, the automata perfectly emulate the
286

fiAUTOMATON P LANS

pre- and postcondition of oxi . The same is true of the operator oyj inserted by Yj . Automaton Xm
inserts operator od after each cycle of assignments to y1 , . . . , yn , and automaton Yn inserts operator
os at the beginning of each iteration over the fluents v0 , . . . , vh .
For each 1  k  h, the purpose of automata Sk and Uk is to decide which operator to append
among olk1 , olk2 , olk3 , onk . To do this, they first access the value of the variable associated with the
literal 1k . If 1k is satisfied, operator olk1 is appended, else literal 2k is checked, then 3k if necessary.
Only if all three literals are unsatisfied by the current variable assignment is operator onk appended.
The only difference between automata Sk and Uk is that Sh+1 appends operator ot, while Uh+1
appends of . Being in automaton Sk indicates that the first k 1 clauses of the current 3SAT instance
are satisfied by the current variable assignment. Only if clause ck is unsatisfied does Sk call Uk+1 ,
in which case all subsequent calls will be to automata of type U. In other words, another purpose
of automata Sk and Uk is to remember the current value of the variable f s. This way, the correct
operator among ot and of is appended at the end of each iteration over fluents v0 , . . . , vh , which
concludes the proof.
To show that plan verification is p2 -hard for automaton plans with uniform expansion, given
any -SAT formula F , construct (in polynomial time) the planning instance pF in Construction
18 and the automaton plan F in Construction 20. Lemma 21 states that F represents the operator
sequence F defined in Lemma 19. Due to Lemma 19, F is a plan for pF if and only if F is
satisfiable. We have thus reduced -satisfiability (a p2 -complete problem) to plan verification for
automaton plans with uniform expansion.

Appendix B. Proof of Lemma 17
In this section we prove Lemma 17, which states that any automaton plan  can be efficiently
transformed to an equivalent HTN instance h. Let p = hP, A, , I, Gi be a S TRIPS instance and let
 = h, A, Au, ri be an automaton plan representing a solution  to p. We define an HTN instance
h = hP  , A , T, ,  , I  , Li as follows:
 P  = P  {consec}  {precedes}  {isset-M }M Au with ar(consec) = ar(precedes) =
ar(isset-M ) = 2 for each M  Au,
 A = A  {set-M, unset-M }M Au with ar(set-M ) = ar(unset-M ) = 2 for each M  Au,
  =   J, where J = {j0 , . . . , jK } is a set of indices and K = maxM Au ar(M ),
 I  = I  {consec[ji1 ji ] : 1  i  K}  {precedes[ji jk ] : 0  i < k  K}.
In the induced set of fluents P  , the static fluent consec[jk] is true if and only if j and k are consecutive indices in J, and precedes[jk] is true if and only if j precedes k in J. For each automaton
M  Au, each symbol   , and each index 1  i  ar(M ), the fluent isset-M [ji ] indicates
whether the i-th symbol of the input string x  ar(M ) of M equals . In the induced set of operators A , the operators set-M [j] and unset-M [j] add and delete fluent isset-M [j], respectively.
For each automaton M  Au, we also add the following tasks and methods to the sets T and :
 A task setall-M with arity ar(M ),
 A method dosetall-M with arity ar(M ) and associated task setall-M ,
287

fiB ACKSTR OM , J ONSSON , & J ONSSON

 For each state s  S of M , a task visit-M -s with arity ar(M ) + 1,
 For each edge (s, t) with label /u, a method traverse-M -s-t with arity ar(M ) + 1 and
associated task visit-M -s,
 For each edge (s, t) with label /u,   , a method consume-M -s-t with arity ar(M ) + 2
and associated task visit-M -s,
 For each state s  S with || outgoing edges, a method finish-M -s with arity ar(M ) + 1 and
associated task visit-M -s.
Formally, the precondition and task list of each method    should contain pairs (u, ) of an
action or task u and an associated argument map  from  to u. However, to simplify notation we
instead describe grounded preconditions and task lists of grounded methods [xy]. In the induced
set of grounded tasks T , the grounded task setall-M [x] sets the current input string of M to x. The
lone associated grounded method dosetall-M [x]   has empty precondition and the following
task list:
 = hunset-M [1 j1 ], . . . , unset-M [n j1 ], set-M [x1 j1 ],
..
.
unset-M [1 jar(M ) ], . . . , unset-M [n jar(M ) ], set-M [xar(M ) jar(M ) ]i,
where 1 , . . . , n are the symbols in the set . In other words, dosetall-M [x] first unsets all symbols
at each index of the input string, then sets the symbol according to x.
The grounded task visit-M -s[xjk ] indicates that we are currently at state s of automaton M ,
that the input string is x and that the current index of x is k. If s has a single outgoing edge
(s, t) with label /(u, ), the only associated grounded method is traverse-M -s-t[xjk ] with empty
precondition. Let u[(x)] be the result of applying the argument map  induced by the index
string  to the input string x of M . If u  A, the grounded task list  of traverse-M -s-t[xjk ]
equals  = hu[(x)], visit-M -t[xjk ]i, effectively applying operator u[(x)]. On the other hand,
if u  Au, the task list is  = hsetall-u[(x)], visit-u-s0 [(x)j0 ], visit-M -t[xjk ]i, first setting the
input string of u to (x) and then visiting the initial state s0 of u with index j0 . In either case,
the grounded task visit-M -t[xjk ] at the end of  ensures that we next visit state t of M without
incrementing k.
If, instead, s has multiple outgoing edges, then for each outgoing edge (s, t) with label /(u, )
for some   , there is an associated grounded method consume-M -s-t[xjk jk+1 ] with precondition {consec[jk jk+1 ], precedes[jk jar(M ) ], isset-M [jk+1 ]}. The index jk+1 is a free parameter
of consume-M -s-t, but the precondition consec[jk jk+1 ] ensures that jk and jk+1 are consecutive
indices in J. The precondition precedes[jk jar(M ) ] ensures that k < ar(M ), i.e. that there are input
symbols left in x to process. Note that indices start at j0 , so it is the symbol at index jk+1 of the
input string x that should be set to . The task list is identical to that of traverse-M -s-t[xjk ], except
that the last task visit-M -t[xjk+1 ] is associated with the next index jk+1 , indicating that we have
consumed a symbol of the input string.
For each s  S with || outgoing edges, the grounded method finish-M -s[xjk ] has precondition
jk = jar(M ) , i.e. the method is only applicable if we have consumed all symbols of the input string.
We assume that jk = jar(M ) can be checked without introducing an additional predicate in P  . The
288

fiAUTOMATON P LANS

task list  is empty, indicating that we have finished traversing the states of M . The method is not
applicable for states with a single outgoing edge since we should fire all applicable -transitions
before terminating.
The task list of the HTN instance h is given by L = hsetall-r[x], visit-r-s0 [xj0 ]i where r[x] is
the root of the automaton plan . Because of the way tasks and methods are defined, expanding
visit-r-s0 [xj0 ] corresponds exactly to executing the automaton r with input string x starting from
s0 . Thus the expansion of L corresponds exactly to the solution  of p represented by  if we
remove all instances of operators set-M and unset-M . Since  is a solution to p, each operator in
the sequence is guaranteed to be applicable.
The only type of task with multiple associated methods is visit-M -s. The methods consumeM -s-t associated with visit-M -s are mutually exclusive since at any moment, isset-M [jk ] is true
for at most one symbol    at each index 1  k  ar(M ) of the input string x of M . If
jk = jar(M ) , the method finish-M -s is applicable instead. The task list of each method is totally
ordered, implying that the instance h belongs to our restricted class of HTNs with mutually exclusive
methods and totally ordered task lists.

References
Alur, R., & Yannakakis, M. (1998). Model Checking of Hierarchical State Machines. In Proceedings of the ACM SIGSOFT International Symposium on Foundations of Software Engineering,
pp. 175188.
Backstrom, C., Jonsson, A., & Jonsson, P. (2012a). From Macro Plans to Automata Plans. In
Proceedings of the 20th European Conference on Artificial Intelligence (ECAI), pp. 9196.
Backstrom, C., Jonsson, A., & Jonsson, P. (2012b). Macros, Reactive Plans and Compact Representations. In Proceedings of the 20th European Conference on Artificial Intelligence (ECAI),
pp. 8590.
Backstrom, C., & Jonsson, P. (2012). Algorithms and Limits for Compact Plan Representation.
Journal of Artificial Intelligence Research, 44, 141177.
Baier, J., & McIlraith, S. (2006). Planning with Temporally Extended Goals Using Heuristic Search.
In Proceedings of the 16th International Conference on Automated Planning and Scheduling
(ICAPS), pp. 342345.
Bonet, B., Palacios, H., & Geffner, H. (2010). Automatic Derivation of Finite-State Machines for
Behavior Control. In Proceedings of the 24th National Conference on Artificial Intelligence
(AAAI).
Botea, A., Enzenberger, M., Muller, M., & Schaeffer, J. (2005). Macro-FF: Improving AI Planning
with Automatically Learned Macro-Operators. Journal of Artificial Intelligence Research,
24, 581621.
Bylander, T. (1994). The Computational Complexity of Propositional STRIPS Planning. Artificial
Intelligence, 69, 165204.
Cimatti, A., Roveri, M., & Traverso, P. (1998). Automatic OBDD-based Generation of Universal
Plans in Non-Deterministic Domains. In Proceedings of the 15th National Conference on
Artificial Intelligence (AAAI), pp. 875881.
289

fiB ACKSTR OM , J ONSSON , & J ONSSON

Coles, A., & Smith, A. (2007). MARVIN: A Heuristic Search Planner with Online Macro-Action
Learning. Journal of Artificial Intelligence Research, 28, 119156.
Erol, K., Hendler, J., & Nau, D. (1996). Complexity Results for HTN Planning. Annals of Mathematics and Artificial Intelligence, 18, 6993.
Fikes, R., Hart, P., & Nilsson, N. (1972). Learning and executing generalized robot plans. Artificial
Intelligence, 3(4), 251288.
Fikes, R., & Nilsson, N. (1971). STRIPS: A New Approach to the Application of Theorem Proving
to Problem Solving. Artificial Intelligence, 2(3/4), 189208.
Gimenez, O., & Jonsson, A. (2008). The Complexity of Planning Problems With Simple Causal
Graphs. Journal of Artificial Intelligence Research, 31, 319351.
Hickmott, S., Rintanen, J., Thiebaux, S., & White, L. (2007). Planning via Petri Net Unfolding. In
Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI), pp.
19041911.
Hu, Y., & De Giacomo, G. (2013). A Generic Technique for Synthesizing Bounded Finite-State
Controllers. In Proceedings of the 23rd International Conference on Automated Planning
and Scheduling (ICAPS).
Jonsson, A. (2009). The Role of Macros in Tractable Planning. Journal of Artificial Intelligence
Research, 36, 471511.
Korf, R. (1987). Planning as Search: A Quantitative Approach. Artificial Intelligence, 33(1), 6588.
LaValle, S. (2006). Planning Algorithms. Cambridge Press.
Lempel, A., & Ziv, J. (1976). On the Complexity of Finite Sequences. IEEE Transactions on
Information Theory, 22(1), 7581.
McAllester, D., & Rosenblitt, D. (1991). Systematic Nonlinear Planning. In Proceedings of the 9th
National Conference on Artificial Intelligence (AAAI), pp. 634639.
Mealy, G. (1955). A Method to Synthesizing Sequential Circuits. Bell System Technical Journal,
34, 10451079.
Minton, S. (1985). Selectively Generalizing Plans for Problem-Solving. In Proceedings of the 9th
International Joint Conference on Artificial Intelligence (IJCAI), pp. 596599.
Nau, D., Ilghami, O., Kuter, U., Murdock, J., Wu, D., & Yaman, F. (2003). SHOP2: An HTN
Planning System. Journal of Artificial Intelligence Research, 20, 379404.
Newton, M., Levine, J., Fox, M., & Long, D. (2007). Learning Macro-Actions for Arbitrary Planners
and Domains. In Proceedings of the 17th International Conference on Automated Planning
and Scheduling (ICAPS), pp. 256263.
Subramanian, H., & Shankar, P. (2005). Compressing XML Documents Using Recursive Finite
State Automata. In Proceedings of the 10th International Conference on Implementation and
Application of Automata (CIAA), pp. 282293.
Toropila, D., & Bartak, R. (2010). Using Finite-State Automata to Model and Solve Planning
Problems. In Proceedings of the 11th Italian AI Symposium on Artificial Intelligence (AI*IA),
pp. 183189.
290

fiAUTOMATON P LANS

Winner, E., & Veloso, M. (2003). DISTILL: Towards Learning Domain-Specific Planners by Example. In Proceedings of the 20th International Conference on Machine Learning (ICML),
pp. 800807.
Zhong, H., & Wonham, M. (1990). On the Consistency of Hierarchical Supervision in DiscreteEvent Systems. IEEE Transactions on Automatic Control, 35(10), 11251134.
Zipstein, M. (1992). Data Compression with Factor Automata. Theoretical Computer Science,
92(1), 213221.

291

fiJournal of Artificial Intelligence Research 51 (2014) 493-532

Submitted 07/14; published 10 /14

Reasoning about Topological and Cardinal Direction Relations
Between 2-Dimensional Spatial Objects
Anthony G. Cohn

A.G.C OHN @ LEEDS . AC . UK

School of Computing, University of Leeds, UK
Faculty of Engineering and Information Technology,
University of Technology Sydney, Australia

Sanjiang Li

S ANJIANG .L I @ UTS . EDU . AU

AMSS-UTS Joint Research Lab,
Centre for Quantum Computation & Intelligent Systems,
University of Technology Sydney, Australia
College of Computer Science, Shaanxi Normal University, China

Weiming Liu

L IU W EIMING @ BAIDU . COM

Baidu (China) Co., Ltd., Shanghai, China

Jochen Renz

J OCHEN .R ENZ @ ANU . EDU . AU

Research School of Computer Science,
The Australian National University, Australia

Abstract
Increasing the expressiveness of qualitative spatial calculi is an essential step towards meeting the
requirements of applications. This can be achieved by combining existing calculi in a way that
we can express spatial information using relations from multiple calculi. The great challenge is
to develop reasoning algorithms that are correct and complete when reasoning over the combined
information. Previous work has mainly studied cases where the interaction between the combined
calculi was small, or where one of the two calculi was very simple. In this paper we tackle the
important combination of topological and directional information for extended spatial objects. We
combine some of the best known calculi in qualitative spatial reasoning, the RCC8 algebra for
representing topological information, and the Rectangle Algebra (RA) and the Cardinal Direction
Calculus (CDC) for directional information. We consider two different interpretations of the RCC8
algebra, one uses a weak connectedness relation, the other uses a strong connectedness relation.
In both interpretations, we show that reasoning with topological and directional information is decidable and remains in NP. Our computational complexity results unveil the significant differences
between RA and CDC, and that between weak and strong RCC8 models. Take the combination of
basic RCC8 and basic CDC constraints as an example: we show that the consistency problem is
in P only when we use the strong RCC8 algebra and explicitly know the corresponding basic RA
constraints.

1. Introduction
Qualitative Spatial Reasoning (QSR) is a multi-disciplinary research field that aims at establishing
expressive representation formalisms of qualitative spatial knowledge and providing effective reasoning mechanisms. Originating from Allens work (1983) on temporal interval relations, QSR has
been widely acknowledged as the AI approach to spatial knowledge representation and reasoning,
with applications ranging from natural language understanding (Davis, 2013), robot navigation (Shi,
Jian, & Krieg-Bruckner, 2010; Falomir, 2012), geographic information systems (GISs) (Egenhofer
c
2014
AI Access Foundation. All rights reserved.

fiC OHN , L I , L IU , & R ENZ

& Mark, 1995), sea navigation (Wolter et al., 2008), to high level interpretation of video data (Sridhar, Cohn, & Hogg, 2011; Cohn, Renz, & Sridhar, 2012). We refer the reader to the work of Cohn
and Renz (2008), and Wolter and Wallgrun (2012) for more information.
The qualitative approach usually represents spatial information by introducing a relation model
on the domain of spatial entities, which could be points, line segments, rectangles, or arbitrary
regions. In the literature, such a relation model is often called a qualitative calculus (Ligozat &
Renz, 2004), which contains a finite set of jointly exhaustive and pairwise disjoint (JEPD) relations
defined on the domain. In the past three decades, dozens of spatial relation models have been
proposed in the literature (Cohn & Renz, 2008; Chen, Cohn, Liu, Wang, Ouyang, & Yu, 2013).
Many of these qualitative calculi approximate spatial entities by points. While this is convenient
when representing spatial direction, distance and positions (providing the extent of the objects is
small compared to their distance apart), it is inappropriate as far as the shapes and/or topology
of the spatial objects are concerned. In this paper, we represent spatial entities as 2-dimensional
bounded regions in the real plane, which may have holes or multiple connected components.
In the literature, most spatial calculi focus on one single aspect of space, e.g. topology, direction, distance, position, or shape. Topological relations are those relations that are invariant under
homeomorphisms such as scale, rotation, and translation. It is widely acknowledged that topological relations are of crucial importance. One influential formalism for topological relations is the
region connection calculus (RCC) (Randell, Cui, & Cohn, 1992). Based on one primitive binary
connectedness relation, a set of eight JEPD topological relations can be defined in the RCC. This
calculus is known as the RCC8 algebra. According to different interpretations of connectedness,
this calculus may have different variants. In this paper, we say two (closed) regions are weakly connected if they share at least a common point, and say they are strongly connected if their intersection
is at least one-dimensional. Accordingly, we address the two resulting RCC8 algebras as the weak
and the strong RCC8 algebras respectively. For convenience, we denote the weak RCC8 algebra as
RCC8, and the strong one as RCC80 .
The importance of the distinction between strong and weak RCC8 becomes clear when analysing
the different ways of defining the neighbourhood of pixels commonly used in Computer Vision. 4connectedness refers to the pixels that are horizontally and vertically connected to a pixel, while
8-connectedness includes the diagonally neighbouring pixels as well. This distinction corresponds
nicely to the distinction between strong and weak RCC8 as 8-connectedness considers connections at a point, while 4-connectedness only considers connections along a line (which is onedimensional). Therefore, we can use strong or weak RCC8 in a similar way we use 4- or 8connectedness, depending on the requirements of the application at hand.
The RCC8 algebra only represents topological information between spatial objects. In many
practical applications, however, other kinds of relations are often used together with topological
relations. For example, when recommending a restaurant you dined at before it is common to give
descriptions such as the restaurant is in the city centre, west of the central station, and nearby there
is a McDonalds.
Among all these aspects of spatial information other than topology, directional relations are
perhaps the most important. There are two well-known formalisms that can cope with directional
relations between extended spatial objects. One is the Rectangle Algebra (RA) (Balbiani, Condotta,
& Farinas del Cerro, 1999), the other is the Cardinal Direction Calculus (CDC) (Goyal & Egenhofer,
2001; Skiadopoulos & Koubarakis, 2005). When representing the direction of a primary object
to a reference object, RA approximates both the reference object and the primary object by their
494

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

minimum bounding rectangles (MBRs), and relates the two objects by the interval relations between
the projected intervals. On the other hand, CDC only approximates the reference object by its MBR,
while leaving the primary object unchanged. The CDC has 511 basic relations, and RA has 169
basic relations. Most (487 out of 511) basic CDC relations intersect with one and only one basic
RA relation and, hence, are contained in a unique basic RA relation. Therefore, CDC is in a sense
more expressive than RA.
A central reasoning problem in QSR is the consistency problem. An instance of the consistency
problem is a set  of constraints like (xy), where x, y are spatial variables, and  is a qualitative
relation from a qualitative calculus. We say  is consistent or satisfiable if there exists an instantiation of the spatial variables such that all constraints in  are satisfied. Without loss of generality,
we assume that there is a unique constraint between any two variables. Note that if x and y are not
related, we can add (x ? y) in  without changing its consistency, where ? is the universal relation
in the calculus. Unlike classical CSPs, the domain of a spatial variable is usually infinite, and it may
be undecidable to determine the consistency of binary CSPs with infinite domains (Hirsch, 1999).
In the past three decades, QSR has made significant progress in solving the consistency problems
for a variety of qualitative calculi (Renz & Nebel, 1999; Renz, 1999; Balbiani et al., 1999; Zhang,
Liu, Li, & Ying, 2008; Skiadopoulos & Koubarakis, 2005; Liu, Zhang, Li, & Ying, 2010; Liu & Li,
2011).
In order to bring spatial reasoning theory closer to practical applications, it is necessary to
combine multiple aspects of spatial information. A growing number of works have been devoted to
combining topological RCC relations with other aspects of spatial information, e.g. qualitative size
(Gerevini & Renz, 2002), cardinal directions (Sistla & Yu, 2000; Li, 2006a, 2007; Liu, Li, & Renz,
2009; Li & Cohn, 2012), connectivity (Kontchakov, Nenov, Pratt-Hartmann, & Zakharyaschev,
2011), convexity (Davis, Gotts, & Cohn, 1999; Schockaert & Li, 2012), betweenness (Schockaert
& Li, 2013), and gravity (Ge & Renz, 2013). Recently, Wolfl and Westphal (2009) also empirically
compared two approaches to the combination of binary qualitative constraint calculi in general.
There are also interesting works on combining spatial and temporal formalisms (Gerevini & Nebel,
2002; Gabelaia, Kontchakov, Kurucz, Wolter, & Zakharyaschev, 2005). Moreover, in other subareas
of formalisms of constraint research, combination of formalisms has been discussed for a long time
and there are some very strong results, see e.g. the work by Bodirsky and Kara (2010), and Jonsson
and Krokhin (2004).
The current paper considers the full combination of RCC8 and RCC80 with the two directional
relation models RA and CDC. We identify the joint satisfaction problem (JSP) as the main reasoning
task. Given a network of topological (RCC8 or RCC80 ) constraints  and a network of directional
(RA or CDC) constraints , assuming that  and  involve the same set of variables, the JSP is to
decide when the joint network  ]  is satisfiable. Note that we use ], instead of , to indicate
that  and  are over the same variables.
Since topological and directional information is not independent, it is possible that the joint
network  ]  is unsatisfiable while both  and  are satisfiable. Solving the joint satisfaction
problem is in general harder than solving  and  independently. In this paper, we interpret directional relations in terms of RA and CDC, and interpret topological relations in terms of the weak
and the strong RCC8 algebras. When only basic constraints are involved, we show that the JSP
for basic (weak or strong) RCC8 and basic RA networks can be solved in polynomial time, but the
JSP for basic (weak or strong) RCC8 and basic CDC networks is NP-complete. Furthermore, we
show that, when the three calculi (viz. RCC8, RA, and CDC) are combined together, the JSP for
495

fiC OHN , L I , L IU , & R ENZ

basic RCC80 networks and basic RA and CDC networks is tractable. Since non-basic constraints
can always be backtracked to basic constraints, these results show that the JSP over (weak or strong)
RCC8 and RA or CDC is in NP.
This paper is a significant extension of the conference paper (Liu et al., 2009), where the combination of basic weak RCC8 and RA or CDC constraints was considered. This paper also considers
the combination of RCC80 and RA and/or CDC constraints. In addition, we extend our tractable
results to two maximal tractable subsets of RCC8 and one large tractable subset of RA. This paper
is also closely related to the work of Li (2007), and Li and Cohn (2012), where the combination of
the weak RCC8 algebra and two subalgebras (viz. DIR9 and DIR49) of RA is considered.
1.1 An Application Scenario
As an example for demonstrating the usefulness of our results, we use the Angry Birds domain.
Similar representation and reasoning tasks can be applied whenever we use computer vision to
detect objects in image or video. Angry Birds is a popular computer game that has gained increasing
attention within the AI community, see e.g. the work of Zhang and Renz (2014). The Angry Birds
AI competition is an AI challenge problem, where the goal is to build an intelligent agent that can
play Angry Birds better than the best human players (see http://aibirds.org).

Figure 1: A screenshot of the Angry Birds game.
The Angry Birds domain includes a number of building blocks of different materials, sizes
and shapes, and even with holes. The building blocks form complicated spatial structures that
protect pigs from the attacking birds (see Figure 1). AI agents have to be able to play the game
like humans do, that is they only get visual information about the game in the form of screenshots.
The competition organisers provide a basic computer vision software that detects the minimum
bounding boxes of all objects in a screenshot as well as the object category. So what is given is a
set of rectangles that form the minimum bounding boxes of the actual objects (see Figure 1). While
each object is a solid physical object that cannot overlap another object (only RCC8 relations DC
and EC are possible between objects), their bounding boxes can be related in any relation of the
Rectangle Algebra and any relation in CDC. Instead of considering only spatial relations between
single objects, we can also take into account sets of objects, for example, the set of all objects that
are directly or indirectly supported by a particular other object, or the set of all objects that provide
cover for a particular pig, or the set of all wooden blocks.
496

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

Notations
, , , , , 
D, R, S, T

 w 
x, y, z,vi , vj
, , 
a, b, c, m
b8 , Q8 , C8
H
P, Q
H
Ix (a), Iy (a)
M(a)

m = (mi )ni=1
(, )
x (, ), y (, )
(, )
]
JSP(S, T )
RA(T )
RCC8(D)
CCP(vi , vj )

Meanings
relations, usually basic relations (page 498)
relations, usually non-basic relations (page 498)
the converse relation of  (page 498)
the weak composition of  and  (page 498)
spatial variable or interval variable (page 498)
network of constraints (page 498)
bounded regions (page 500)
the three maximal tractable subclasses of RCC8 (page 500)
points (page 501)
the unique maximal tractable subclass of IA (page 502)
the x- and y- projective intervals of region a (page 503)
the minimal bounding rectangle (MBR) of region a (page 503)
the RA relation induced by two IA relations ,  (page 503)
an n-tuple of regions mi that form a solution to some network (page 504)
a consistent pair of basic CDC relations (page 505)
the x- and y- projective interval relations of (, ) (page 505)
the RA relation x (, )  y (, ) induced by (, ) (page 506)
the combination of two networks over the same set of variables (page 507)
the joint satisfaction problem over subclasses S and T (page 507)
the RA relation induced by an RCC8 relation T (page 509)
the RCC8 relation induced by an RA relation D (page 509)
two variables vi , vj have the common conflict point relation (page 510)
Table 1: Notations.

These sets of building blocks form spatial regions in the general sense as used by RCC8 and
BRCC8 (Wolter & Zakharyaschev, 2000), which also include regions with multiple disconnected
pieces or regions with holes. In particular, it means that any RCC8 relation is possible between two
sets of objects, not just DC or EC.
Given spatial configurations in the Angry Birds domain, we can now use RCC8 relations as well
as RA and CDC relations to represent spatial information about (sets of) objects and their minimum
bounding boxes that is extracted from the screenshots. The results of this paper allow us to accurately reason about the combined information represented using RCC8, RA, and CDC. Important
reasoning tasks that can benefit from our results include, for example, inferring how a configuration
changes after it is hit by a bird or inferring whether a given representation is consistent or whether
it is stable under gravity (Zhang & Renz, 2014). An algorithm for predicting the configuration of
the blocks after a shot might work by envisaging individual possible block positions but these might
be mutually or globally inconsistent. An algorithm for reasoning about the consistency of such
predictions is therefore desirable.
The remainder of this paper proceeds as follows. Section 2 introduces basic notions, important
examples, and essential results of qualitative calculi. Section 3 then describes the joint satisfaction
problem and considers the simple example of the combination of RA and CDC constraints. Sections
4 and 5 consider the computational complexity of the combination of weak and, respectively, strong
497

fiC OHN , L I , L IU , & R ENZ

RCC8 with RA. Section 6 discusses the computational complexity of the combination of weak and
strong RCC8 with CDC. We conclude the paper in Section 7 and give proofs of major computational complexity results in the appendices. For the convenience of the reader, Table 1 summarises
notations used in this paper.

2. Qualitative Calculi
The establishment of a proper qualitative calculus is the key to the success of the qualitative approach to temporal and spatial reasoning. This section introduces basic notions of qualitative calculi and recalls the RCC8 algebra, the Rectangle Algebra, and the Cardinal Direction Calculus. In
addition, we will also summarise some essential results that will be used in the main part of the
paper.
2.1 Basic Notions
Let U be the domain of temporal or spatial entities, and Rel(U) be the set of binary relations on U.
With the usual relational operations of intersection, union, and complement, Rel(U) is a Boolean
algebra. A finite set B of nonempty binary relations on U is jointly exhaustive and pairwise disjoint
(JEPD for short) if any two entities in U are related by one and only one relation in B. Write hBi
for the subalgebra of Rel(U) generated by B. Clearly, relations in B are atoms in the algebra hBi.
We call hBi a qualitative calculus on U, and call relations in B basic relations of the calculus.
Notation. Note that each relation in hBi is the union of a set of basic relations. In this paper, we
write R = {1 , 2 , ..., k } if R is the union of basic relations 1 , 2 , ..., k . For convenience, we
regard each basic relation  as the singleton {}.
For two relations R, S in a qualitative calculus M = hBi, we write R for the converse of R,
which is defined as
R = {(x, y)  U  U : (y, x)  R},

(1)

and write R w S for the smallest relation in M which contains R  S, the usual composition of R
and S, which is defined as
R  S = {(x, y)  U : (z  U)(x, z)  R  (z, y)  S}.
We call R w S the weak composition of R and S (Duntsch, Wang, & McCloskey, 2001).
A constraint over hBi has the form (xRy), where R is a relation in hBi. We call (xRy) a basic
constraint if R is a basic relation in B. An important reasoning problem in a qualitative calculus is to
determine the satisfiability or consistency of a network  = {vi Rij vj }ni,j=1 of constraints over hBi,
where  is satisfiable (or consistent) if there is an instantiation (ai )ni=1 in U such that (ai , aj )  Rij
holds for all 1  i, j  n.
Given two constraint networks  = {vi Rij vj }ni,j=1 and  = {vi Tij vj }ni,j=1 , we say  refines
 if Tij is a subset of Rij for any 1  i, j  n. A consistent scenario of  is a consistent basic
network that refines . It is clear that  is consistent iff it has a consistent scenario. On the other
hand, given an n-tuple of entities (ai )ni=1 in U, write ij for the basic relation in a fixed qualitative
calculus that relates ai to aj . Then  = {vi ij vj }ni,j=1 is a consistent scenario and we call this the
scenario (or basic constraint network) induced by (ai )ni=1 .
498

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

The consistency of a constraint network can be partially determined by path-consistency algorithms. We say a network  = {vi Rij vj }ni,j=1 is path-consistent if

Rji = Rij
,

 6= Rij  Rik w Rkj

(2)

for any i, j and any k 6= i, j. In case  is a basic network, this is equivalent to saying that every
subnetwork involving three variables of  is consistent.
Path-consistency can be enforced in cubic time (Vilain & Kautz, 1986). That is, if we apply
the path-consistency algorithm on a constraint network , then in cubic time the algorithm will
terminate and we either get an empty constraint (and hence know that  is inconsistent) or transform
 into an equivalent path-consistent network. For basic networks, it is easy to see that consistency
implies path-consistency, but the opposite proposition does not always hold.
In the following subsections we recall the qualitative topological and directional calculi that will
be discussed in this paper.
2.2 The Region Connection Calculus RCC8
The region connection calculus (RCC) (Randell et al., 1992) is a first-order theory based on a binary
connectedness relation. Standard RCC models arise from topological spaces. In this paper, we are
only concerned with interpretations of RCC in the real plane, which provides arguably the most
important model for RCC. Another reason lies in that the directional calculi considered in this paper
are also defined over the real plane. A plane region (or region) is a nonempty regular closed subset
of the real plane. We only consider bounded regions, as cardinal directions only involve bounded
regions. But these regions could have multi-pieces and/or have holes.1
One standard interpretation of RCC is based on the Whiteheadean connectedness (Whitehead,
1929) on plane regions, where two regions are connected if they have a common point. This connectedness may be considered too weak in many cases. For example, a worm cannot pass from the
interior of one apple to another, which touch just at a point, without becoming visible to the exterior  so from the worms point of view we might as well say that the apples are not sufficiently
connected. (Borgo, Guarino, & Masolo, 1996, p. 223) In this paper, we also consider a stronger
connectedness, in which two regions are regarded as connected if their intersection is at least onedimensional (Li, Liu, & Wang, 2013). In the case of a rectangular grid of spatial primitive entities,
as already noted, strong and weak connectedness correspond to, respectively, the important notion
of 4- and 8-neighbourhood of pixels commonly used in Computer Vision.
In both interpretations, the relations in Table 2 and the converses of TPP and NTPP form a
JEPD set. Write Brcc8 and Brcc80 for these two sets. We call the Boolean algebras generated by
Brcc8 and Brcc80 , respectively, the weak and the strong RCC8 models, written as RCC8 and RCC80 .
Strong connectedness has been considered by Borgo et al., (1996), Cohn and Varzi (1999), and
Li et al., (2013). It is easy to see that, as relations, strong connectedness is contained in weak
connectedness. Table 2 illustrates a configuration (the 2nd from the left) which is an instance of EC
in RCC8 but an instance of DC in RCC80 , and a configuration (the 2nd from the right) which is an
instance of TPP in RCC8 but an instance of NTPP in RCC80 .
1. We stress here that the restriction of RCC to bounded plane regions does not affect the complexity of reasoning with
RCC8, as every consistent RCC8 network has a solution in any RCC model (Li, 2006b).

499

fiC OHN , L I , L IU , & R ENZ

Relation
equals
disconnected
externally connected

Symb.
EQ
DC
EC

partially overlap

PO

tangential proper part
non-tangential proper part

TPP
NTPP

Definition (weak)
a=b
ab=
a  b 6=   a  b = 
a  b 6=  
a 6 b  a 6 b
a  b  a 6 b
a  b

Definition (strong)
a=b
dim(a  b)  0
dim(a  b) = 1
a  b 6=  
a 6 b  a 6 b
a  b  dim(a  b) = 1
a  b  dim(a  b)  0

Table 2: The set of basic RCC8 and RCC80 relations, where a, b are two plane regions and x , x, dim(x)
denote, respectively, the interior, boundary, and dimension of x. Note that for notational convenience we set dim() = 1.

Remark 1. As far as consistency and realisations are concerned, Li (2006b) has shown that any
consistent RCC8 network has a solution in any RCC model. The cubic realisation algorithm described there can be used to construct a solution in both the weak and the strong RCC8 models.
This implies in particular that an RCC8 network has a solution in the weak RCC8 model iff it has
a solution in the strong RCC8 model. As we will show in this paper, this is, however, not the case
when cardinal directions are combined with topological relations.
In the following, we recall some important properties of the three maximal tractable subclasses
b
H8 , C8 , and Q8 of RCC8 identified by Renz (1999). A complete list of relations in these subclasses
can be found in Appendix A of the work of Renz (2002).
Lemma 2. Suppose R is a non-basic RCC8 relation such that R  {DC, EC, PO} = . Then
(1) R  Q8 iff R is either {TPP, NTPP} or {TPP , NTPP }.
b8 iff R is in Q8 or one of the following relations
(2) R  H
{TPP, EQ}, {TPP, NTPP, EQ}, {TPP , EQ}, {TPP , NTPP , EQ}.
b8 , or either {NTPP, EQ} or {NTPP , EQ}.
(3) R  C8 iff R is in H
We note the above lemma does not define these subclasses. In particular, these subclasses do
include RCC8 relations R such that R  {DC, EC, PO} =
6 .
Renz also shows that a consistent scenario can be constructed in O(n2 ) time for any pathconsistent network  over one of the three maximal tractable subclasses.
500

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

Theorem 3 (Renz, 1999). A consistent scenario s of a path-consistent network  of constraints
b8 , C8 , or over Q8 can be computed in O(n2 ) time, by replacing every constraint (vi Rvj )  
over H
with (vi base(R) vj )  s , where base(R) is a basic relation obtained as follows:
(1) If R  B, then base(R) = R;
(2) else if {DC}  R, then base(R) = {DC};
b8 , then base(R) = {EC};
(3) else if {EC}  R and S = Q8 or S = H
(4) else if {PO}  R, then base(R) = {PO};
(5) else if {NTPP}  R and S = C8 , then base(R) = {NTPP};
(6) else if {TPP}  R, then base(R) = {TPP};
(7) else base(R) = base(R ).
In what follows, we call s the canonical consistent scenario of .
2.2.1 R EALISATION OF BASIC RCC8 N ETWORKS
It is known that, for basic RCC8 networks, path-consistency implies consistency (Nebel, 1995). We
next give a a short description of the cubic realisation algorithm proposed by Li (2006b), as we need
to devise a similar algorithm later for the combination cases.
Given a basic RCC8 network  = {vi ij vj }ni,j=1 , suppose  is path-consistent. An ntpp-chain
in  is defined to be a series of variables vi1 , vi2 ,    , vik such that vis NTPPvis+1   for all
s = 1,    , k  1. The ntpp-level l(i) of a variable vi is defined to be the maximum length of the
ntpp-chains contained in  that ends with vi .
A realisation can be constructed as follows, where a variable may be interpreted as a bounded
region with multiple pieces. Without loss of generality, we assume (vi EQvj )   only when
i = j. We first define for each variable vi a finite set Xi of control points as follows. For each i,
introduce a point Pi to vi ; if vi ECvj or vi POvj , then introduce a point Pij to vi ; if vi TPPvj or
vi NTPPvj , then put all Xi points into Xj . We then expand each point P in Xi a little to obtain a
square s(P ). These squares are pairwise disjoint. Then, taking the union of these squares, we obtain
an instantiation of bounded regions to these vi . This works for all but the EC and NTPP constraints.
Further modifications are needed to cope with these constraints (cf. Li, 2006b or Appendix C of
this paper).
2.3 Interval Algebra and Rectangle Algebra
In this subsection, we recall Interval Algebra (IA) (Allen, 1983) and Rectangle Algebra (RA) (Balbiani et al., 1999). IA is the qualitative calculus generated by the 13 basic relations between closed
intervals on the real line shown in Table 3. We write
Bint = {b, m, o, s, d, f, eq, fi, di, si, oi, mi, bi}

(3)

for the set of basic IA relations. Ligozat (1994) defines the dimension2 of a basic interval relation
as 2 minus the number of equalities appearing in the definition of the relation (see Table 3). That is,
2. We stress that this notion of dimension is different from the topological dimension.

501

fiC OHN , L I , L IU , & R ENZ

for basic relations we have
dim(eq) = 0, dim(m) = dim(s) = dim(f) = 1, dim(b) = dim(o) = dim(d) = 2.

(4)

For a non-basic relation R we define
dim(R) = max{dim() :  is a basic relation in R}.

Relation
before
meets
overlaps
starts
during
finishes
equals

Symb.
b
m
o
s
d
f
eq

Conv.
bi
mi
oi
si
di
fi
eq

Dim.
2
1
2
1
2
1
0

(5)

Definition
x+ < y 
x+ = y 
x < y  < x+ < y +
x = y  < x+ < y +
y  < x < x+ < y +
y  < x < x+ = y +
x = y  < x+ = y +

(i)

(ii)

Table 3: IA basic relations (i) definitions and (ii) conceptual neighbourhood graph, where x =
[x , x+ ], y = [y  , y + ] are two intervals.
Nebel and Burckert (1995) have shown that there is a unique maximal tractable subclass of IA
which contains all basic relations. This subclass, written as H, is known as the ORD-Horn class.
Using the conceptual neighbourhood graph (CNG) of IA (Freksa, 1992), Ligozat (1994) gives a
geometrical characterisation for ORD-Horn relations. Consider the CNG of IA (shown in Table 3
(ii)) as a partially ordered set (Bint , ) (by interpreting any relation smaller than its right or upper
neighbours). For 1 , 2  Bint with 1  2 , we write [1 , 2 ] as the set of basic interval relations 
such that 1    2 , and call such a relation a convex interval relation. An IA relation R is called
pre-convex if it can be obtained from a convex relation by removing one or more basic relations with
dimension lower than R. For example, [o, eq] = {o, s, fi, eq} is a convex relation and {o, eq} is a
pre-convex relation. Ligozat has shown that ORD-Horn relations are precisely pre-convex relations.
Nebel and Burckert also show that every path-consistent IA network over H is consistent. Furthermore, we can construct a consistent scenario for every path-consistent IA network over H in
quadratic time.
Suppose R is an IA relation and let
Rcore = {  Bint : dim() = dim(R),   R}.

(6)

By (6) it is clear that Rcore = {eq} iff R = {eq}, and Rcore = R  {b, o, d, di, oi, bi} if R 
{b, o, d, di, oi, bi} is nonempty, and Rcore = R \ {eq} otherwise. Then we have
Lemma 4. (Renz, 1999) Suppose  = {vi Rij vj }ni,j=1 is a path-consistent IA network over H. Let
core
core = {vi Rij
vj }ni,j=1 .

Then core is also path-consistent.
502

(7)

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

From Table 3 (ii) it is easy to see that a pre-convex relation R has dimension 1 iff either R is a
1-dim basic relation or R is contained in {s, eq, si} or {fi, eq, f}. As a consequence, we know
Corollary 5. Suppose  = {vi Rij vj }ni,j=1 is a path-consistent network over H. Then  has a
 v }n
consistent scenario  = {vi Rij
j i,j=1 which has the following property:
 ) = dim(R ), and
dim(Rij
ij
 = {eq} only if R = {eq}, R = {m} only if R = {m}, R = {mi} only if R = {mi}.
Rij
ij
ij
ij
ij
ij

This result shows that, for any path-consistent network  over H, we can construct in quadratic
time a consistent scenario for .

(i)

(ii)

Figure 2: (i) The minimum bounding rectangle M(a) of a region a; (ii) the RA relation of a to b is
m  o.
IA can be naturally extended to regions in the plane. We assume an orthogonal basis in the Euclidean plane. For a bounded region a, its minimum bounding rectangle (MBR), denoted by M(a),
is the smallest rectangle which contains a and whose sides are parallel to the axes of the basis.
We write Ix (a) and Iy (a) as, respectively, the x- and y-projections of M(a). The basic rectangle
relation between two bounded regions a, b is    iff (Ix (a), Ix (b))   and (Iy (a), Iy (b))  ,
where ,  are two basic IA relations (see Figure 2 for illustration). We write Brec for the set of
basic rectangle relations, i.e.,
Brec = {   : ,   Bint }.

(8)

There are 169 different basic rectangle relations in Brec . The Rectangle Algebra (RA) is the algebra
generated by relations in Brec (Balbiani et al., 1999).
The following definitions will be used later.
Definition 6. Suppose  = 1  2 is a basic RA relation. We say  is a 0-meet relation if
1 , 2  {m, mi}, and is a corner relation if 1 , 2  {m, mi, s, si, f, fi, eq}. In general, we say a
non-basic RA relation R = {1 , ..., k } (k  2) is a corner relation if each i (1  i  k) is a
corner relation.
By definition, each 0-meet relation is a corner relation. Furthermore, it is easy to see that a basic
RA relation  is a 0-meet relation iff, for every two rectangles r, r0 with (r, r0 )  , r  r0 is a
singleton in the plane; and  is a corner relation iff every two rectangles r, r0 with (r, r0 )   have,
at least, a corner point in common.
The following lemma is straightforward.
503

fiC OHN , L I , L IU , & R ENZ

Lemma 7. Let  = {vi (Rij  Sij )vj }ni,j=1 be an RA network, where Rij and Sij are arbitrary IA
relations. Then  is satisfiable iff its projections x = {xi Rij xj }ni,j=1 and y = {yi Sij yj }ni,j=1
are satisfiable IA networks.
By Corollary 5 and the above lemma we have
Lemma 8. Suppose  = {vi Rij vj } is a path-consistent RA network over H  H. Then  has a
consistent scenario  = {vi ij vj } such that
 ij is a 0-meet relation iff Rij is a 0-meet basic relation, and
 ij is a corner relation iff Rij consists only of basic corner relations.
As a consequence, we know H H is a tractable subclass of RA. No maximal tractable subclass
has been identified for RA, but a larger tractable subclass of RA has been identified (Balbiani et al.,
1999).
We next show that each path-consistent basic IA or RA network has a canonical solution in the
following sense.
+ n
Definition 9 (canonical tuple of intervals (rectangles)). Suppose m = ([m
i , mi ])i=1 is an n-tuple
of intervals. Let E(m) be the set of the values of the end points of intervals in m. We say m is
canonical iff E(m) = {0, 1,    , M }. A tuple of rectangles (mi )ni=1 is canonical iff its x- and
y-projections, (Ix (mi ))ni=1 and (Iy (mi ))ni=1 , are canonical tuples of intervals. A solution of an
IA (RA, respectively) network is called a canonical solution if it is a canonical tuple of intervals
(rectangles, respectively).

For a basic satisfiable IA network, we can compute the total order of all the end points. Hence
we can obtain a canonical solution (by assigning 0 to the first end point, 1 to the second, etc.). This
gives us the following proposition.
Proposition 10. Suppose  is a satisfiable basic IA (RA) constraint network. Then  has a unique
canonical solution.
2.4 Cardinal Direction Calculus
The cardinal direction calculus (CDC) was proposed by Goyal and Egenhofer (1997). Given a
bounded region b in the real plane, by extending the four edges of M(b), we partition the plane into
nine tiles, denoted by bij (1  i, j  3), see Figure 3 (i) for illustration.
For a primary region a and a reference region b, the CDC relation of a to b, denoted by ab ,
is encoded in a 3  3 Boolean matrix (dij )1i,j3 , where dij = 1 iff a  bij 6=  (where a is
again the interior of a). For example, the basic CDC relations ab and ba for the regions a, b in
Figure 3(ii) are represented by the following matrices.




0 0 0
0 0 1
  = ab = 1 0 0 ,   = ba = 0 0 1 .
(9)
0 0 0
0 0 1
A CDC relation can be any but the zero Boolean matrix, so there are 29 1 = 511 basic relations
in CDC. We denote this set by Bcdc . A pair of basic CDC relations (, ) is called a consistent pair
504

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

(i)

(ii)

(iii)

Figure 3: Illustrations of (i) the nine tiles of a reference region; (ii) and (iii): two solutions of the
CDC basic constraint network {v1   v2 , v2   v1 }, where   and   are defined in Eq. (9).

if the constraint network {v1 v2 , v2 v1 } has a solution. We also call  a weak converse of  if
(, ) is a consistent pair. Figure 4 shows that a basic CDC relation may have more than one weak
converse. Therefore, we need both the relation of a to b and the relation of b to a to give a complete
description (in terms of the CDC calculus) of the directional information between two regions a, b.

(i)

(ii)

Figure 4: Illustration of two consistent CDC pairs (i) (ab , ba ) and (ii) (a0 b0 , b0 a ), where ab =
a0 b0 but ba 6= b0 a0 . Also note that the rectangle relation between a, b and that between
a0 , b0 are both o  o.
In the following we show that there is a strong connection between CDC and RA relations.
Definition 11. (Zhang et al., 2008; Liu et al., 2010) For a pair of basic CDC relations (, ), we
define the x-projective interval relation of (, ), written as x (, ), as the disjunction of all basic
IA relations  which has an instance that is the x-projection of some solution of {v1 v2 , v2 v1 },
i.e.
x (, ) = {  Bint : (m1 , m2 )[(m1 , m2 )    (m2 , m1 )    (Ix (m1 ), Ix (m2 ))  ]}.
A similar definition applies for the y-direction.
Note that if (, ) is not a consistent pair, then both x (, ) and y (, ) are the empty relation.
If (, ) is a consistent pair, then we can prove (Liu et al., 2010) that its x- (or y-) projective interval
505

fiC OHN , L I , L IU , & R ENZ

relation is an IA relation R which has the following property
R = {b, m} or R = {bi, mi}, or R is a basic IA relation in {o, s, d, f, eq, oi, si, di, fi}.

(10)

The two projective interval relations can then be combined into an RA relation.
Definition 12. (Zhang et al., 2008; Liu et al., 2010) For a pair of basic CDC relations (, ), we
call (, ) = x (, )  y (, ) the RA relation induced by (, ). In general, for a basic CDC
constraint network  = {vi ij vj }ni,j=1 , we call () = {vi Rij vj }ni,j=1 the RA constraint network
induced by , where Rij = (ij , ji ).
Note that (, ) is not necessarily a basic RA relation. If (, ) is consistent, then we know the
RA relation (, ) has the form   , where ,  are IA relations that satisfy (10). Furthermore,
a solution of {v1 v2 , v2 v1 } is always a solution of {v1 (, )v2 }. We note that a solution of
{v1 (, )v2 } is not necessarily a solution of {v1 v2 , v2 v1 }.
Take the consistent pair (  ,   ) defined in (9) as an example. Figure 3 (ii) and (iii) show two
solutions (a, b) and (a0 , b0 ) of the basic CDC constraint network {v1   v2 , v2   v1 }. This implies
by definition that x (  ,   ) contains {b, m}. It is easy to see from the definition that x (  ,   )
contains no other basic IA relations and x (  ,   ) = {b, m}. Similarly, we can show y (  ,   ) =
{d}. This shows that this consistent pair (  ,   ) corresponds to basic RA relations, viz. m  d and
b  d.
2.4.1 C ANONICAL S OLUTIONS OF BASIC CDC N ETWORKS
Just like IA and RA, consistent CDC networks also have canonical solutions.
Definition 13 (regular solution, Zhang et al., 2008; Liu et al., 2010). Suppose m = (mi )ni=1 is
a solution of a basic CDC constraint network . We say that m is maximal if m0i  mi holds
for any solution (m0i )ni=1 of  with M(mi ) = M(m0i ); we say m is regular if m is maximal and
(M(mi ))ni=1 is a canonical tuple of rectangles.
A basic CDC network in general has many regular solutions, but we have the following result.
Proposition 14. Let  be a basic CDC network. Suppose  is a basic RA network that refines
(), the induced RA network of . Then we can determine in cubic time whether  has a solution
that also satisfies . Moreover, if  has a solution, then it has a unique regular solution which also
satisfies . Furthermore, this unique regular solution can be constructed in cubic time.
Proof. The proof is similar to that for Proposition 12 in the work of Liu et al., (2010). A sketch is
given in Appendix A.
From the proof of the above result, we can see that each region mi in a regular solution (mi )ni=1
consists of unit cells (i.e. rectangles of the form [i, i+1][j, j +1], where i, j  Z) in the canonical
solution of , i.e. for each region mi and each cell c, we have either c  mi or c  mi  = .
For a basic CDC network , there may exist exponentially many different basic RA networks
that refine (). Hence,  may have exponentially many different regular solutions (see Figure 11(a) for an example of such a network). However, to verify that  has a solution, we need
only prove that  has a solution for some special basic RA network that refines () (Liu et al.,
2010, Proposition 12).3 Therefore, the consistency of  can be determined in cubic time, and, if 
is consistent, a regular solution can be constructed in cubic time (Liu et al., 2010).
3. Such a special network is called a meet-free basic RA network in the work of Liu et al., (2010).

506

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

3. The Joint Satisfaction Problem
After the preparatory introduction of basic notions and essential results of qualitative calculi, we are
now ready to describe the joint satisfaction problem.
Let M1 and M2 be two qualitative calculi over the same domain U. Suppose Si is a subclass of
Mi (i = 1, 2). We write JSP(S1 , S2 ) for the joint satisfaction problem (Gerevini & Renz, 2002; Li,
2007) over S1 and S2 .
Suppose  = {vi Tij vj }ni,j=1 is a constraint network over S1 , and  = {vi Dij vj }ni,j=1 is a
constraint network over S2 involving the same variables. Then we say  ]  is an instance of
JSP(S1 , S2 ). The joint satisfaction problem was first considered for RCC8 and the qualitative size
calculus (identical to the Point Algebra in Vilain & Kautz, 1986) by Gerevini and Renz (2002).
Moreover, it was shown that the consistency of a joint network can be approximated by the polynomial bipath-consistency algorithm. Li and Cohn (2012) recently showed that bipath-consistency
can be equivalently expressed as below.
Definition 15. Let ] be a joint constraint network over M1 and M2 , where  = {vi Tij vj }ni,j=1
and  = {vi Dij vj }ni,j=1 . We say  ]  is bi-closed if   Dij and Tij   are nonempty for any
basic relation   Tij , any basic relation   Dij , and any 1  i, j  n (here we regard each
relation as a subset of U  U). A bi-closed joint network  ]  is bipath-consistent if  and  are
both path-consistent.
Informally speaking, a joint constraint network is bi-closed if each basic relation of a given
relation in one of the calculi is consistent with the corresponding relation in the other calculus.
As a simple example of the joint satisfaction problem, we consider the combination of RA and
CDC in the next subsection.
3.1 The Combination of RA and CDC
Let R be a basic CDC relation. Then R , the set-theoretic converse (or inverse) relation of R
(cf. (1)), may be not representable in the relation algebra CDC (Cicerone & Di Felice, 2004; Liu
et al., 2010). That is, R cannot be represented as the union of several basic CDC relations. In this
sense, we say the CDC is not closed under converse. Recently, Schneider et al. (2012) proposed a
variant of CDC, called the Object Interaction Model (OIM), which is closed under converse.
For two bounded regions a, b, OIM divides the plane into up to (l1 + 2)  (l2 + 2) tiles by
extending the edges of M(a) and M(b), where l1 + 1 and l2 + 1 are the numbers of horizontal
and, respectively, vertical lines. It is clear that 1  l1 , l2  3 since edges of M(a) and M(b) may
coincide. The OIM relation ab is represented by an l1  l2 matrix (also written as ab ) considering
existence of interior points of a and/or b in corresponding bounded tiles. Let T be such a bounded
tile. We set the entry corresponding to T in the matrix ab to 0 if T has no interior point which is in
either a or b; and set it 1 (2, respectively) if T has an interior point which is in a (b, respectively) and
has no interior point which is in b (a, respectively); and set it 3 otherwise. The converse relation of
a basic OIM relation is also a basic OIM relation. In particular, the basic OIM relation ba of b to a
can be obtained by swapping the occurrences of 1 and 2 in ab .
For example, the OIM relations between the regions in Figure 3 (ii) and (iii) are respectively




0 0 2
0 2
ab = 1 0 2 , a0 b0 = 1 2 ,
0 0 2
0 2
507

fiC OHN , L I , L IU , & R ENZ

and the OIM relations between the regions in Figure 4 are respectively

ab



0 2 2
= 1 3 2 ,
1 1 0

a0 b0



0 2 2
= 1 1 2 .
1 1 0

We note that for regions a, b, a0 , b0 in both figures we have ab = a0 b0 . This suggests that OIM is
finer grained than CDC in the sense that it splits one basic CDC relation into several OIM relations.
Nevertheless, since CDC is not closed under converse, we need to consider consistent pairs of basic
CDC relations in order to evaluate its expressivity. When comparing the expressivity of the two
calculi in this way, we can see that (ab , ba ) 6= (a0 b0 , b0 a0 ) in Figure 4, but (ab , ba ) = (a0 b0 , b0 a0 )
in Figure 3. This shows that OIM makes finer distinctions than CDC in describing the scenarios
given in Figure 3(ii) and (iii): when saying a is west of b, CDC does not differentiate if the east
boundary of a meets or precedes the west boundary of b. The following result shows that OIM is
only finer than CDC in describing these cardinal relations, and it is in essence the combination of
CDC and RA.
Theorem 16. (Li & Liu, 2014) For any two regions a and b, we can compute the RA relation of a
to b, the CDC relation of a to b, and the CDC relation of b to a from the OIM relation of a to b, and
vice versa.
In other words, for each basic OIM relation , there exist two basic CDC relations ,  0 and a
basic RA relation  such that  =    0   , i.e. for any two regions a and b, the relation  is the
OIM relation of a to b iff ,  0 and  are, respectively, the CDC relation of a to b, the CDC relation
of b to a, and the RA relation of a to b. Because basic CDC and RA relations are both JEPD, the
above choices of ,  0 ,  are unique. In the following, we call  the CDC relation induced by  and
call  the RA relation induced by . Note that in this case  0 (as a relation of b to a) is the CDC
relation induced by  , which is the OIM relation of b to a.
As a consequence, we have the following result.
 for any
Proposition 17. Suppose  = {vi ij vj }ni,j=1 is a basic OIM network such that ji = ij
n
n
i, j. Let  = {vi ij vj }i,j=1 and  = {vi ij vj }i,j=1 , where ij and ij are, respectively, the CDC
relation and the RA relation induced by ij . Then  is consistent iff the joint network  ]  is
consistent.

Proof. Recall that the converse of a basic OIM relation is also a basic OIM relation. Because
 , it is straightforward to show that  =       . Therefore, solutions of  are
ji = ij
ij
ij
ij
ji
exactly the solutions of  ] .
As a consequence of Propositions 14 and 17 we have
Corollary 18. Let ,  and  be as given in Proposition 17. Then  is a basic RA network that
refines (), and the consistency of  can be determined in cubic time. Moreover, if  is consistent,
then there is a unique regular solution of  that is also a solution of .
So far, we have described by an example what is a JSP. In the next three sections, we will
consider the main task of this paper: the JSP of topological and directional constraints.
508

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

4. Combination of Weak RCC8 and RA Networks
In this section we represent topological information as weak RCC8 relations and directional information as RA relations. We first consider the interaction between weak RCC8 and RA relations,
then consider the JSP for basic constraints, and, lastly, consider the JSP in general.
4.1 Interaction Between Weak RCC8 and RA Relations
Relations in different calculi may interact in the sense that a relation from one calculus may intersect
with several relations from the second calculus. We here recall related definitions and preliminary
results obtained by Li and Cohn (2012).
Definition 19. Let T be an RCC8 relation and D an RA relation. The RA relation induced by T
and the RCC8 relation induced by D are defined as
RA(T ) = { :  is a basic RA relation and   T 6= }

(11)

RCC8(D) = { :  is a basic RCC8 relation and   D 6= }.

(12)

Note that a joint network  ]  is bi-closed if ij  RA(ij ) and ij  RCC8(ij ) for any i, j.
S
It is easy to see (cf. Li and Cohn, 2012) that RA(T ) = {RA({}) :   T } and
RA({DC})  RA({EC}) RA({PO})  RA({TPP})  RA({NTPP, EQ}),




RA({PO})  RA({TPP })  RA({NTPP , EQ}),

(13)
(14)

where, for example, RA({EC})  RA({PO}) holds because, for each basic RA relation ,  is
in RA({EC}) if M(a)  M(b) 6=  for all (a, b)  , and  is in RA({PO}) if M(a)  M(b) is
a non-degenerate rectangle for all (a, b)  .
Lemma 20. Let T be an RCC8 relation and D an RA relation. Then RCC8(D) is a relation in the
b8 , Q8 , and C8 ; and RA(T ) is a relation in H  H if T is a relation in H
b8 or Q8 .
intersection of H
Proof. This follows from the definitions of RCC8(D) and RA(T ) and a simple table look-up from
Appendix A of the work of Renz (2002).
The second statement does not apply to relations in C8 . For example, consider T = {NTPP,
EQ}. Then T is a relation in C8 , but RA(T ) = {d  d, eq  eq} is outside H  H.
4.2 Combination of Basic Networks
We now consider the combination of RCC8 and RA. First we show that bipath-consistency is not
sufficient for consistency in JSP(Brcc8 , Brec ) (Li & Cohn, 2012). Let  = {vi ij vj }4i,j=1 be the
basic RA network induced by the four rectangles mi (i = 1, 2, 3, 4) illustrated below.
Let  = {vi ij vj }4i,j=1 be the basic RCC8 constraint network in which 12 = 34 = {EC} and
all the others are {DC}. Clearly,  is satisfiable. Although  ]  is bipath-consistent, it is not
satisfiable. This is because, otherwise, there exists a solution m = (mi )4i=1 and M(m1 )M(m2 ) =
M(m3 )  M(m4 ) = {P } is a singleton. By 12 = 34 = {EC} we know P  mi (i = 1, 2, 3, 4).
This contradicts 13 = {DC}.
We call point P in the above configuration a conflict point. In general, we have the following
definition.
509

fiC OHN , L I , L IU , & R ENZ

Definition 21 (conflict point). Let  = {vi ij vj }ni,j=1 be a basic RCC8 network and  = {vi
ij vj }ni,j=1 a basic RA network. Suppose m is the canonical solution of . A point Q is called a
conflict point of mi if there exists j such that mi  mj = {Q} and ij = {EC}. We write Ci for
the set of all conflict points of mi .
Clearly, each conflict point of mi is also a corner point of mi . This implies that mi and mj
may have at most one common conflict point. Moreover, suppose m = (mi )ni=1 is a solution of
 ]  such that M(mi ) = mi for all 1  i  n. Then each conflict point of mi is contained in
mi . This means Ci  mi . As a consequence, we have
Ci  Cj 6=   ij 6= {DC} (1  i, j  n)

(15)

The following theorem shows that this is also sufficient.
Theorem 22. Let  = {vi ij vj }ni,j=1 be a basic RCC8 network and  = {vi ij vj }ni,j=1 a basic RA
network. Suppose  ]  is bipath-consistent. Then  ]  is satisfiable iff (15) holds.
Proof. The necessity part is clear. We defer the proof of the sufficiency part to Appendix B.
As a corollary, we have JSP(Brcc8 , Brec ) is in P.
Corollary 23. For a basic RCC8 network  and a basic RA network , the consistency of  ] 
can be decided in cubic time.
Proof. Bipath-consistency of  ]  can be checked in cubic time. We can construct the unique
canonical rectangle solution of  in quadratic time. The conflict point set Ci can also be computed
in quadratic time. That is, the condition of Theorem 22 can be checked in cubic time.
4.3 Large Tractable Subsets
b8 , C8 , and Q8 , and IA has one maximal
Recall that RCC8 has three maximal tractable subclasses H
tractable subclass H, all containing the basic relations. In this subsection, we aim to extend the
b8 , C8 of RCC8, and the large tractable subset H  H of
above result to maximal tractable subsets H
RA.
To this end, we need to extend the notion of conflict points from basic networks to arbitrary
networks. Recall that 0-meet relations and corner relations are basic RA relations defined in Definition 6.
Definition 24 (common conflict point). Let  = {vi Tij vj }ni,j=1 be an RCC8 network and  =
{vi Dij vj }ni,j=1 an RA network. We say two variables vi , vj have the CCP (common conflict point)
relation, written CCP(vi , vj ), if Dij is a 0-meet (basic) relation and Tij = {EC}, or
 Dij is a (possibly disjunctive) corner relation; and
510

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

 there exist i0 , j 0 such that Dii0 and Djj 0 are 0-meet (basic) relations, Dij 0 , Di0 j and Di0 j 0 are
(possibly disjunctive) corner relations, and Tii0 = Tjj 0 = {EC}.
If CCP(vi , vj ) and vi0 , vj0 are variables that satisfy the above conditions, we also write CCP(i, j :
i0 , j 0 ) to stress the roles of vi0 and vj 0 .

(i)

(ii)

Figure 5: Two joint constraint networks in JSP(RCC8, RA), where in both (i) and (ii)
Dij is the basic RA relation between vi and vj as illustrated in the picture, T14 = T23 = {EC} and all unspecified RCC8 constraints are
non-basic RCC8 relation {DC, EC, PO}.
In both (i) and (ii) we have
CCP(1, 2), CCP(1, 3), CCP(1, 4), CCP(2, 3), CCP(2, 4), CCP(3, 4).

Examples are shown in Figure 5. Note that if  and  are all basic networks, then vi and vj
have the CCP relation iff Ci  Cj is nonempty, i.e. vi and vj have a common conflict point.
Definition 25. Let  = {vi Tij vj }ni,j=1 be an RCC8 network and  = {vi Dij vj }ni,j=1 an RA
network. We say  ]  is CCP-consistent if
CCP(vi , vj )  DC 6 Tij

(16)

holds for any i 6= j. We say a joint network  ]  is BC-consistent if it is bipath-consistent and
CCP-consistent.
In general, if vi and vj have the CCP relation, then (in any realisation) vi and vj share at least
one corner point (of their MBRs) in common. Therefore, in the weak RCC8 algebra, they cannot be
disconnected, and neither can be contained in another as a non-tangential proper part. Note that the
latter statement also follows from the bi-closedness of  ] .
Similar to the bipath-consistency algorithm (Gerevini & Renz, 2002), we devise an algorithm
(Algorithm 1) for enforcing BC-consistency. The following theorem shows that this algorithm is
sound.
Theorem 26. Suppose  ]  is a joint network of RCC8 and RA constraints, where  = {vi Tij
vj }ni,j=1 and  = {vi Dij vj }ni,j=1 . Then in O(n4 ) time, the algorithm BC-C ONSISTENCY either
finds an inconsistency or transforms  ]  into an equivalent joint network 0 ] 0 which is
BC-consistent.
511

fiC OHN , L I , L IU , & R ENZ

Input: A joint network  ] , where  = {vi Tij vj }ni,j=1 and  = {vi Dij vj }ni,j=1 .
Output: false, if an empty constraint is generated; a BC-consistent joint network equivalent
to  ] , otherwise.
Q  {(i, k, j) | i 6= j, k 6= i, k 6= j};
(i indicates the i-th variable of  ] .
Analogously for j and k)
while Q 6=  do
select and delete a path (i, k, j) from Q;
if BC-R EVISION(i, k, j) then
if Tij =  or Dij =  then
return false;
end
Q  Q  {(i, j, k), (k, i, j) | k 6= i, k 6= j};
end
end
Function: BC-R EVISION(i, k, j)
Input: three variables i, k and j
Output: true, if Tij or Dij is revised; false otherwise.
Side effects: Tij and Dji revised using the operations  and w .
Tij 
(Tij  RCC8(Dij ))  (Tji  RCC8(Dji ))  (Tik  RCC8(Dik )) w (Tkj  RCC8(Dkj ));
Dij  (Dij  RA(Tij ))  (Dji  RA(Tji ))  (Dik  RA(Tik )) w (Dkj  RA(Tkj ));
if CCP(i, j : k) then
Tij  Tij \ {DC};
end
if neither Tij nor Dij is revised then
return false;
end
;
Dji  Dij
Tji  Tij ;
return true.
Algorithm 1: BC-C ONSISTENCY, where we write CCP(i, j : k) to represent the situation
where there exists another variable vl such that vl and vk together are evidence of CCP(i, j).

512

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

Proof. This is because, if we iteratively use the following updating rules then either an empty constraint occurs or the network becomes stable.
Tij  (Tij  RCC8(Dij ))  (Tji  RCC8(Dji ))
 (Tik  RCC8(Dik )) w (Tkj  RCC8(Dkj ))


(17)

Dij  (Dij  RA(Tij ))  (Dji  RA(Tji ))  (Dik  RA(Tik )) w (Dkj  RA(Tkj ))

(18)

Tij  Tij \ {DC} if CCP(i, j : k),

(19)

where i, j, k represent the variables vi , vj and vk and CCP(i, j : k) represents the situation where
there exists another variable vl such that vl and vk together are evidence of CCP(i, j). For each
triple, CCP(i, j : k) can be determined in O(n) time and the subroutine BC-R EVISION(i, k, j) can
be carried out in O(n) time. Since each Tij is a set of basic RCC8 relations and each Dij is a set of
basic RA relations, (Tij , Dij ) can be revised for a constant number of times. Therefore the number
of the loops remains cubic, and BC-C ONSISTENCY will terminate in O(n4 ) time.
The algorithm is in general not complete. The following lemma will be useful to prove the main
result (Theorem 28), which will guarantee the completeness of the algorithm for RCC8 networks
b8 and RA networks over H  H.
over H
Lemma 27. Let  = {vi Tij vj }ni,j=1 be an RCC8 network and  = {vi Dij vj }ni,j=1 an RA network.
b8 or Q8 and  ]  is bipath-consistent. Assume that  is the canonical
Suppose  is over H
consistent scenario of  (cf. Theorem 3), and  is any consistent scenario of . Then  ]  is
bipath-consistent.
Proof. Because both  and  are path-consistent basic networks, we need only show that  ]
  RA(  ) and    RCC8(  ) for any i 6= j. Since   and   are both basic
is bi-closed, i.e. ij
ij
ij
ij
ij
ij
    is nonempty for any i 6= j. By (13) and (14) it
relations, this is equivalent to showing that ij
ij
 ). Therefore    D  RA(T ) = RA(  ),
is straightforward to show that RA(Tij ) = RA(ij
ij
ij
ij
ij


i.e. ij  ij is nonempty.
We note that this result does not apply to C8 . For example, let T = {NTPP, EQ}, D =
{d  d, eq  eq}. The RCC8 relation NTPP is inconsistent with the RA relation eq  eq.
Theorem 28. Let  = {vi Tij vj }ni,j=1 be an RCC8 network and  = {vi Dij vj }ni,j=1 an RA netb8 , and  is over H  H. Then  ]  is consistent if it is BC-consistent.
work. Suppose  is over H
Proof. Recall that each RA network over H  H is in essence a pair of IA networks over H. By
 is a 0-meet relation iff D is;
Lemma 8 we know  has a consistent scenario  such that (i) ij
ij

and (ii) ij is a corner relation iff Dij consists of corner relations. Let  be the canonical consistent
scenario of . We show  ]  is consistent.
By Lemma 27 we know  ]  is bipath-consistent. We next show it satisfies (15), which is
equivalent to (16) when only basic constraints are concerned. To this end, we show that CCP(i, j :
i0 , j 0 ) holds in  ]  only if it holds in  ] . By the choice of  and  , we know Tii0 =
Tjj 0 = {EC} and all the RA relations are either 0-meet relations or consist of corner relations.
Therefore, CCP(i, j : i0 , j 0 ) also holds in  ] . Because  ]  is BC-consistent, we know DC is
 6= {DC} and  ] satisfies (15). By Theorem 22, we know  ] ,
not in ij . This implies ij
hence  ] , is consistent.
513

fiC OHN , L I , L IU , & R ENZ

b8 or Q8 and H  H can be
As a consequence, we know the joint consistency problem over H
solved in polynomial time.
b8 , H  H) and JSP(Q8 , H  H) are in P.
Theorem 29. The joint satisfaction problems JSP(H
b8 or Q8 , and  is over H  H.
Proof. Suppose  ]  is a joint network such that  is over H
We first apply the algorithm BC-C ONSISTENCY to  ] . If an empty relation occurs during the
process, then  ]  is inconsistent. Otherwise, suppose 0 ] 0 is the BC-consistent joint network
b8 or Q8 and 0 is over H  H. We note that,
equivalent to  ] . We assert that 0 is still over H
b8 (or Q8 ), and any RA relation D in H  H, we have by Lemma 31
for any RCC8 relation T in H
b8 and Q8 ;
 RCC8(D) is a relation in both H
 RA(T ) is a relation in H  H;
b8 (or Q8 ).
 T \ {DC} = T  {EC, PO, TPP, NTPP, TPP , NTPP , EQ} is in H
Because BC-C ONSISTENCY only uses the rules (17)-(19) to update relations, each RCC8 relation
b8 (or Q8 ), and each RA relation in 0 remains in HH. The consistency 0 ]0
in 0 remains in H
then follows from Theorem 28.
The property in the proof of the above theorem does not hold for C8 . It remains open if
JSP(C8 , H  H) is tractable (though this is not very important for practical purposes since either
b8 or Q8 can be used to backtrack over to find a solution if required).
H

5. Combination of RCC80 and RA Networks
In this section, we represent topological information as RCC80 relations and directional information
as RA relations. In the previous section we have shown that, for certain tractable subclasses of RCC8
and RA, the JSP can be determined in polynomial time, but we also show that bipath-consistency
is incomplete for these subclasses. The reason lies in that two regions that are constrained by DC
may have a common conflict point. For RCC80 , this situation does not exist anymore because two
disjoint regions may still have a 0-dimensional intersection. This section will show that, for RCC80 ,
bipath-consistency alone is sufficient to show the consistency of a joint network  ]  for  over
H8 or C8 and  over H  H.
As in the case of weak RCC8, we first consider the interaction between RCC80 and RA relations,
then consider the consistency of joint basic networks, and, lastly, consider the general case.
Similar to Definition 19, we have the following definition.
Definition 30. Let T be an RCC80 relation and D an RA relation. The RA relation induced by T
and the RCC80 relation induced by D are defined as
RA(T ) = { :  is a basic RA relation and   T 6= }
0

RCC8 (D) = { :  is a basic RCC80 relation and   D 6= }.
S
It is easy to see that RA(T ) = {RA({}) :   T } and

(20)
(21)

RA({DC})  RA({EC}) RA({PO})  RA({TPP}) = RA({NTPP})  RA({EQ}).
RA({PO})  RA({TPP }) = RA({NTPP })  RA({EQ}).
514

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

Note that we have RA({TPP}) = RA({NTPP})= {s, d, f, eq}  {s, d, f, eq}. This is because
in RCC80 a non-tangential proper part of a region a may have the same MBR as a. For example,
each star region in Figure 6 is a non-tangential proper part of its MBR in RCC80 .
Lemma 31. Let T be an RCC80 relation and D an RA relation. Then RCC80 (D) is a relation in
b8 , Q8 , and C8 ; and RA(T ) is a relation in H  H if T is a relation in H
b8 or
the intersection of H
Q8 or C8 .
In particular, unlike the case for weak RCC8, we have RA({NTPP, EQ}) = {s, d, f, eq} 
{s, d, f, eq} is a relation in H  H.

Figure 6: Basic regions of a control point P in the combination of RCC80 and RA.
Theorem 32. Suppose  is a basic RCC80 network and  is a basic RA network. Then  ]  is
consistent if it is bipath-consistent.
Proof. The proof follows the same pattern as for the combination of weak RCC8 and RA (Theorem 22), but we need to replace the basic regions around a control point P with the star regions shown in Figure 6, where we only show three regions b, r, g around P , and bNTPPr and
rNTPPg.
We have the following result for RCC80 and RA.
b8 or Q8 in RCC80 ,  is an RA network. Then  ] 
Theorem 33. Suppose  is a network over H
is consistent if  ]  is bi-closed,  is path-consistent, and  is consistent.
Proof. Assume that  is the canonical consistent scenario of , and  is any consistent scenario
 ) = RA( ) and hence the
of . Then, completely similar to Lemma 27, we can show that RA(ij
ij




bi-closeness of  ]  . Because  and  are consistent, we know  ]  is bipath-consistent,
hence consistent by Theorem 32.
b8 , RA) can be polynoThe above result shows that the consistency of a joint network in JSP(H
b8 and an RA network.
mially reduced to determining the consistency of an RCC8 network over H
b8 , RA) is a separable problem. In particular, we have
In this sense, JSP(H
515

fiC OHN , L I , L IU , & R ENZ

Theorem 34. If RCC8 relations are interpreted by using strong connectedness, then the joint satisb8 , H  H) and JSP(Q8 , H  H) are in P.
faction problems JSP(H
Again, it remains open whether the above result holds for networks over C8 in RCC80 , even
though in this case RA({NTPP, EQ}) = RA(TPP) is a relation in H  H.
In the following section, we consider the combination of RCC8 and CDC constraints.

6. Combination of RCC8 and CDC Constraints
Although basic RCC8 networks and basic CDC networks can be solved in cubic time independently, the interaction between RCC8 and CDC constraints makes the joint satisfaction problem
hard to solve. In this section, we first show that the joint satisfaction problem is in NP by designing a polynomial non-deterministic algorithm and then show it is NP-hard even for basic constraints. This shows that JSP(Brcc8 , Bcdc ) is NP-complete. We then consider three variants of
JSP(Brcc8 , Bcdc ) obtained by replacing RCC8 with RCC80 and/or CDC with OIM. Write Boim for
the set of basic OIM relations. We show JSP(Brcc8 , Boim ) and JSP(Brcc80 , Bcdc ) are NP-complete,
but JSP(Brcc80 , Boim ) is in P.
6.1 Algorithms
Let  be an instance of a joint basic RCC8 or RCC80 network and  a basic CDC or OIM network
over the same set of variables. We provide in this subsection algorithms for determining the consistency of  ] . Our key idea is first showing that  ]  is consistent iff  has a regular solution
that is RA consistent with  (see below) and then giving algorithms for determining whether  has
such a regular solution.
Suppose m = (mi )ni=1 is a solution of . Recall that we say m = (mi )ni=1 is a regular solution
if it is a maximal solution and {M(mi )}ni=1 is a canonical tuple of rectangles (cf. Dfn. 13). Note
that each region in a regular solution m is the union of a set of cells introduced by the canonical
tuple of rectangles.
Definition 35. Let  = {vi ij vj }ni,j=1 be a basic RCC8 network and  = {vi ij vj }ni,j=1 a basic
CDC network. Suppose m = (mi )ni=1 is a regular solution of . Write  for the RA network
induced by m. We say a regular solution m of  is RA consistent with  if there exists a solution of
 ]  which also satisfies .
The following lemma gives a characterisation of consistent joint basic networks.
Lemma 36. Let  = {vi ij vj }ni,j=1 be a basic RCC8 network and  = {vi ij vj }ni,j=1 a basic
CDC network. Then  ]  is consistent iff  has a regular solution that is RA consistent with .
Proof. The sufficiency part is clear by definition. We only prove the necessity part. Suppose a =
(ai )ni=1 is a solution of ]. Write  for the RA network induced by a. Then a is also a solution of
 ] . Hence there is a unique regular solution of  which also satisfies . Write m = (mi )ni=1 for
this regular solution. It is clear that m is a regular solution of  that is RA consistent with .
By this lemma, to determine the consistency of  ] , we need only determine the existence
of regular solutions of  that are RA consistent with . Suppose m is a regular solution of . We
next give a necessary and sufficient condition for m being RA consistent with .
516

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

To this end, we first fix some notation and terminology. For a region mi in m, we say a corner
point P of mi is a potential conflict point (in m) if exactly one of the four cells incident to P is
contained in mi . For example, the grey region shown in Figure 7 has five potential conflict points
Pi (i = 1, ..., 5). Later we will show that these points may introduce conflicts that are hard to resolve
when RCC8 constraints are involved. Furthermore, we denote by Gi the set of cells contained in
mi , Ei the set of edges of cells which lie on the boundary of mi , and Ni the set of potential conflict
points of vi .

Figure 7: Illustration of potential conflict points.
Lemma 37. Let  = {vi ij vj }ni,j=1 be a basic RCC8 network and  = {vi ij vj }ni,j=1 a basic
CDC network. If a regular solution m = (mi )ni=1 of  is RA consistent with , then we have:
if ij = TPP or NTPP then Gi  Gj .

(22)

Proof. We prove this by contradiction. Assume that (vi TPPvj ) or (vi NTPPvj ) is a constraint in
 and Gi * Gj .
Suppose (vs vt ) is a constraint in , where  is a basic CDC relation represented by the 3  3
Boolean matrix (dpq )1p,q3 . Because m is a solution of , we have for any 1  p, q  3 that
dpq = 1 iff ms  mpq
t 6= ,

(23)

where mpq
t denotes one of the nine tiles generated by the MBR of mt (cf. Fig. 3). Since m is a
regular solution and Gs is the set of cells contained in ms , this is equivalent to saying that
dpq = 1 iff

Gs and mpq
t have a common cell.

(24)

Now let g be a cell in Gi \ Gj . Because g is not in Gj , by the construction procedure of regular
solutions (see Appendix A), there exists a constraint (vj  0 vk )   with  0 = (d0uv ) such that g is a
0pq = 0 and hence,
cell contained in mpq
k for some p, q. By (24) and that g is not in Gj we know d
pq

00
by (23), mj  mk = . Let (vi  vk ) be the CDC constraint between vi and vk in  and suppose
00pq = 1 by (24).
 00 = (d00uv ). Because g is cell in both Gi and mpq
k , we have d
Because m is RA consistent with , there exists a solution a = (ai )ni=1 of  ]  such that
M(ai ) = M(mi ). Since (vi TPPvj ) or (vi NTPPvj ) is in , we know ai  aj . Furthermore,
pq
we have aj  mj as m is a maximal solution of . Therefore, ai  mj . Because mpq
k = ak
pq
pq


00
00pq
and mj  mk = , ai  ak is empty. This shows that (ai , ak ) is not in  since d
= 1. A
contradiction.
The NTPP constraints may furthermore exclude some edges in Ei and nodes in Ni from the
valuation of vi . Suppose vi NTPPvj is a constraint in  and m = (mi )ni=1 is RA consistent with
. For any solution a = (ai )ni=1 of  ]  with M(ai ) = M(mi ), by ai NTPPaj and aj  mj
517

fiC OHN , L I , L IU , & R ENZ

we have aj  mj = . This is to say, ai cannot touch the edges and nodes in Ej and Nj . To
characterise this, we define
[
Ei  Ei \ {Ej : vi NTPPvj  },
(25)
[
Ni  Ni \ {Nj : vi NTPPvj  }.
(26)
Since every region in m can be represented by a Boolean matrix, Gi , Ei , Ni can be calculated
in polynomial time. The following proposition then gives a necessary and sufficient condition for m
being RA consistent with .
Lemma 38. Let  = {vi ij vj }ni,j=1 be a basic RCC8 network and  = {vi ij vj }ni,j=1 a basic
CDC network. Then a regular solution m = (mi )ni=1 of  is RA consistent with  iff
 vi TPPvj   or vi NTPPvj   implies Gi  Gj , and
S
 M( Ei ) = M(mi ) for any i, and
 vi POvj   implies Gi  Gj 6= , and
S
 there exists a resolving function f , which is defined as a function from V to P( {N1 ,    , Nn })
satisfying (27)-(29).
f (vi )  Ni ,

(27)

vi ECvj    Gi  Gj 6=  or Ei  Ej 6=  or f (vi )  f (vj ) 6= ,

(28)

vi DCvj    f (vi )  f (vj ) = .

(29)

Proof. We begin with the necessity part. Suppose m is RA consistent with . Then by definition
there exists a solution a = (ai )ni=1 of  ]  such that M(ai ) = M(mi ). The first condition is
proven in Lemma 37. For the second condition, because M(ai ) = M(mi ), and ai  mi , we know
that ai has a nonempty intersection with one unit edge on a cell that lies on the top (bottom, leftmost,
or rightmost) edge of M(mi ). This unit
S edge is clearly in Ei . Furthermore, it can be proven that this
edge is in Ei , and thus we have M( Ei ) = M(mi ). The following two conditions guarantee that
the PO, EC constraints can
S be satisfied while not violating DC constraints. The third condition
follows directly from ai  Gi and ai POaj . For the last condition, we define a resolving function
f as f (vi ) = {P  Ni : P  ai }. It is straightforward to prove that f satisfies (27)-(29).
For the sufficiency part, we construct a solution of  ] . The procedure is quite similar to that
given for Theorem 22 in Appendix B. For vi , we choose a control point from each cell in Gi and
a control point from each edge in Ei . If vi POvj , we choose a control point for both of them from
a common cell of Gi and Gj . If vi ECvj , we choose a control point for them in a common cell if
Gi  Gj 6= , or from a common edge if Ei  Ej 6= , or from f (vi )  f (vj ) by the resolving
function f . It can then be proven that these control points lead to a solution of . Moreover, the
choice of control points ensures that the regions are also a solution of .
Since the conditions in Lemma 38 can be verified by a nondeterministic polynomial algorithm,
we have the following theorem.
Theorem 39. JSP(Brcc8 , Bcdc ) is in NP.
518

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

Proof. Suppose ] is an instance of JSP(Brcc8 , Bcdc ). We devise a nondeterministic polynomial
algorithm as follows. We first guess a basic RA network  that is consistent with the basic CDC
network , and compute the regular solution m of  that satisfies  in cubic time, and further guess
a resolving function f that satisfies the conditions (27)-(29), and check whether m is consistent
with the basic RCC8 network  by Lemma 38 via f . If this is the case, the algorithm returns true.
Otherwise, the algorithm returns false. This shows that JSP(Brcc8 , Bcdc ) is in NP.
Since each OIM network has at most one regular solution, by Lemma 38 we have
Corollary 40. JSP(Brcc8 , Boim ) is in NP.
If we interpret topological constraints in RCC80 , then we have the following simplified condition
for determining whether a regular solution of  is RA consistent with .
Proposition 41. Suppose that  is a basic RCC80 network, and  is a basic CDC network, both
over the same set of variables V = {v1 ,    , vn }. Then a regular solution of  is RA consistent
with  iff
 vi TPPvj   or vi NTPPvj   implies Gi  Gj , and
 vi POvj   implies Gi  Gj 6= , and
 vi ECvj   implies that either Gi  Gj or Ei  Ej is nonempty.
Moreover, the above conditions can be checked in polynomial time.
Proof. The proof is similar to that for Lemma 38. The resolving function is now irrelevant, because
in RCC80 conflict points are no longer evidence for EC relations, where a point P (a set X, respectively) is regarded as evidence
S of a relation (aECb) if P 0 a  b (X  a  b), respectively.
Note that we do not require M( Ei ) = M(mi ), as in RCC8 it is possible that aNTPPb and
M(a) = M(b), see Figure 6 for illustration.
This directly leads to the following two results.
Theorem 42. JSP(Brcc80 , Bcdc ) is in NP.
Proof. The proof is similar to that for Theorem 39. Suppose ] is an instance of JSP(Brcc8 , Bcdc ).
We first guess a basic RA network  that is consistent with  and construct a regular solution m of
 that satisfies  and then check whether m is RA consistent with  by Proposition 41.
Recall that OIM is in essence the combination of CDC and RA, and a basic OIM network is
consistent iff the two component CDC and RA networks are consistent (see Proposition 17). In the
case when RCC80 is combined with OIM, we have the following tractability result.
Theorem 43. JSP(Brcc80 , Boim ) is in P.
Proof. The algorithm for JSP(Brcc80 , Boim ) contains three steps. Suppose  ]  is an instance
with n variables. The first step is to decide whether  and  are independently consistent. If not
so, then return false; otherwise, construct the unique regular solution m of . This can be achieved
in O(n3 ) time. We then calculate Gi and Ni , which can be done in O(n4 ) time. The third step is
to decide whether m is RA consistent with  according to Proposition 41, which can be done in
O(n4 ) time. Therefore, the consistency of  ]  can be determined in O(n4 ) time and, hence,
JSP(Brcc80 , Boim ) is in P.
519

fiC OHN , L I , L IU , & R ENZ

In the next subsection, we show that JSP(Brcc8 , Bcdc ), JSP(Brcc80 , Bcdc ), and JSP(Brcc8 , Boim )
are all NP-hard.
6.2 NP-Hardness Results
Recall that in the proof of Theorem 39, we guess twice when determining the consistency of an
instance  ]  of JSP(Brcc8 , Bcdc ), once for a basic RA network that is consistent with , and
once for a resolving function f that satisfies (27)-(29) (see Proposition 38). In this subsection we
devise two polynomial reductions from known NP-hard problems to JSP(Brcc8 , Bcdc ) by exploiting
these two facts.
Theorem 44. JSP(Brcc8 , Bcdc ) is NP-hard.
Proof. The first reduction is from 3-SAT to JSP(Brcc8 , Bcdc ). Because it is quite complicated, we
defer the construction to Appendix C. Here we only explain why this problem is NP-hard.
For each 3-SAT instance , we construct an instance  ]  of JSP(Brcc8 , Bcdc ) such that
each RCC8 constraint is either a DC or an EC constraint. Furthermore, we can show that  has a
unique regular solution that is RA consistent with  if  is consistent.
The intractability is caused by the potential conflict points in the regular solution, which, together with the EC and DC constraints, may introduce conflicts that are hard to resolve. By
Lemma 38, to satisfy an EC constraint vi ECvj , we need to check whether mi and mj share a
cell, or else an edge, or else a corner point. In the last case, it can be proven without much difficulty
that points shared by mi and mj are exactly those points in Ni  Nj . Therefore, if mi and mj share
no cell or edge, then the evidence point for the constraint vi ECvj can only be chosen from Ni  Nj .
It turns out that choosing such evidence points for all the EC constraints while not violating the
DC constraints in  is NP-hard.
The second reduction is from Graph 3-colouring problem to JSP(Brcc8 , Bcdc ). We defer the construction to Appendix D. For each graph G, we construct an instance G ] G in JSP(Brcc8 , Bcdc ).
This reduction differs from the first one in that it does not exploit the intractability of finding a
resolving function. In fact, when vi ECvj is a constraint, then in each regular solution m of G ,
either mi and mj share a cell or an edge, or mi and mj are disjoint (in which case m is not RA
consistent with ). That is to say, resolving functions have no effect on the RA consistency of m.
The reduction is based on the fact that G has exponentially many regular solutions, and there is no
general way to test all of them in polynomial time (unless P = NP).
Note that in the first reduction we have shown  has a unique regular solution that is RA
consistent with  if  is consistent, where  is a 3-SAT instance and  ]  is the instance
of JSP(Brcc8 , Bcdc ) defined by the reduction. Write  for the basic RA network induced by this
particular regular solution of  . It is easy to see that  ]  is consistent iff  ]  ]  is
consistent. In other words, the reduction from 3-SAT is also a reduction to JSP(Brcc8 , Boim ).
Corollary 45. JSP(Brcc8 , Boim ) is NP-hard.
Similarly, the second reduction is also a reduction to JSP(Brcc80 , Bcdc ). This is because the
JSP(Brcc8 , Bcdc ) instance for each graph G only uses DC and EC constraints, and when two variables are required to be EC, then their MBRs do not 0-meet, but their MBRs may overlap.
Corollary 46. JSP(Brcc80 , Bcdc ) is NP-hard.
520

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

By these NP-hardness results and Theorem 39, Corollary 40, and Theorem 42, we know
Theorem 47. The joint satisfaction problems JSP(Brcc8 , Bcdc ), JSP(Brcc80 , Bcdc ), and JSP(Brcc8 ,
Boim ) are all NP-complete.

7. Conclusion
In this paper, we have investigated the computational complexity of reasoning with topological
relations and cardinal directions between extended spatial objects. We used two different interpretations of the well-known RCC8 algebra for representing topological information, and use the
Rectangle Algebra (RA) and the cardinal direction calculus (CDC) to describe directional information. We have shown that the joint satisfaction problems are decidable and remain in NP for all
these interpretations of topological and directional information. More importantly, we have shown
that the consistency problem is in P when basic (weak or strong) RCC8 and basic RA constraints
are involved, or when topological constraints are basic strong RCC8 constraints and directional
constraints are jointly represented by basic RA and CDC constraints.
Some related work has been reported in the work of Sistla and Yu (2000), Li (2007), and Li
and Cohn (2012), but only small fragments of RA are used to express directional information. Our
results represent a large step towards the applicability of qualitative spatial reasoning techniques for
real-world problems. In particular the tractable results are very promising as they enable efficient
reasoning about these important calculi. It also means that if efficient reasoning is important for
a potential application, developers should aim for representing directional information using RA
(or together with CDC) instead of CDC alone and/or representing topological information by using
RCC80 instead of RCC8. Our results about combining RCC8 and CDC/OIM are very important
from a theoretical point of view as they are the first formal results for this combination. As demonstrated using a concrete application scenario, our results are also of practical significance, as the
combined information we consider can be easily extracted in cases where computer vision is used
for obtaining spatial information.

Acknowledgments
We thank the anonymous reviewers for their invaluable comments and detailed suggestions. The
first author also thanks the University of Technology Sydney for their funding of a visit to Sydney
as an Adjunct Professor. This work was partially supported by Australian Research Council (Grant
No.s DP120104159, DP120103758 and FT0991917), the National Natural Science Foundation of
China (Grant No. 61228305), and the EU funded projects RACE (FP7-ICT-287752) and STRANDS
(FP7-ICT-600623).

Appendix A. Realisation of Basic CDC Networks
We here describe the cubic algorithm given in the work of Zhang et al., (2008), and Liu et al., (2010).
Given a basic CDC network, first, we compute a canonical solution of the induced (possibly nonbasic) RA network. Next, we remove the cells that violate some constraints from each rectangle.
Third, we check whether what we have obtained is a valid solution. In the following, we give a
detailed description with a running example illustrated in Table 4 and Figure 8.
521

fiC OHN , L I , L IU , & R ENZ

(1, 2)

(1, 3)

(2, 3)


0
1
1
0
1
1
1
1
0

ij
0
1
0
0
0
0
1
0
0


0
0
0
0
0
0
0
0
0


0
0
0
0
0
0
0
0
0

ji
1
1
0
0
1
0
0
0
1

xij  yij

xij  yij

oo

oo

{m, b}  fi

b  fi

o  oi

o  oi



1
1
0
0
0
0
0
1
1

Table 4: Example of solving a basic CDC network.

Step 1. Compute the induced RA network 0 of .
Step 2. Refine 0 to a basic RA network  = {vi (xij  yij )vj }ni,j=1 by setting xij = xij \{m, mi}
and yij = yij \{m, mi}. If  is unsatisfiable, then neither is . Suppose  is satisfiable and construct
its canonical solution m = (mi )ni=1 (cf. Figure 8).

Figure 8: Illustration of Step 3: Deriving a solution m of  from a canonical solution m of .
Step 3. This step tries to find a solution m = (mi )ni=1 of the basic CDC network  such that
M(mi ) = M(mi ). Recall a basic CDC relation ij is represented as a 3  3 Boolean matrix
((ij )xy ). If m is a solution, mi  (mj )xy =  holds for every (ij )xy = 0, where (mj )xy is one
of the nine tiles generated by M(mj ) (cf. Figure 3). This
to make m a solution to , we
S means,


need to exclude all impossible cells from mi . Set Ti = {(mj )xy : (ij )xy = 0}nj=1 . Let mi be
the closure of mi \ Ti (cf. Figure 8 left).
Step 4. The last step checks whether m = (mi )ni=1 is a solution of . If it is a solution, then m
must be a regular solution; if it is not, then we assert that  has no solution at all.
We note that other regular solutions may exist (cf. Figure 8 right). We can get all of them by
repeating Steps 2 to 4 using every possible refinement of 0 .

Appendix B. Proof of Theorem 22
We only need to show the sufficiency part. Similar to the cubic construction method for basic RCC8 constraints (cf. Li, 2006b and Section 2.2.1 of this paper), we construct a solution
m = (mi )ni=1 with an additional requirement that M(mi ) = mi for each 1  i  n, where
{m1 , ..., mn } is the canonical solution of . Recall that the coordinates of each corner point of a
rectangle mi are integral. Assuming the ntpp-level l(i) has been computed for each 1  i  n, we
next describe the construction in detail.
522

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

Step 1. Selection of Control Points
For each vi we select a set of control points Xi . First of all, each corner point in Ci is a control point
for vi . We then select one (non-integral) point from each edge of mi and put the four points into
Xi . Then, for any j > i with ij = EC or PO select a point Pij from mi  mj (which is nonempty
because of the bipath-consistency of  ] ), and put it into both Xi and Xj . Note that mi  mj
could be a single point, or a line segment, or a rectangle. When choosing Pij from mi  mj , we
require that each Pij is a fresh point that has not been chosen before and is not a corner point of any
rectangle (unless i  mj is a singleton set). We write P for the set of all the control points.
Step 2. Basic Regions Associated to Control Points
For each control point Q, we construct a series of sectors {q i,k : k = 1,    , 4}ni=1 and a series
of squares {q (i) }ni=1 (see Figure 9). We call these the basic regions associated to Q. Note that we
use an upper case letter to denote a control point, and use the corresponding lower case letter (with
indices) to denote basic regions. The sectors are chosen in this way as this allows us to distinguish
up to four connecting regions in cases where Q is a corner point (such as point P in Figure3). The
sectors completely fill all the disks.

Figure 9: Basic regions of a control point Q.
For any two different control points, we require their outermost squares to be disjoint. Furthermore, a basic region must be small enough so that it is not crossed by the border of any mi of which
Q is not a boundary point.
Step 3. Region Construction
For each control point Q, set q i =
a1i
a2i
a3i
a4i

S4

k=1 q

i,k .

Let
[
= mi  {q i : Q  Xi }
[
= a1i  (mi  {q j : ij = PO, Q  Xi  Xj })
[
= a2i  {a2j : ji = TPP or ji = NTPP}
[
= a3i  {q (l(i)) : ji = NTPP, Q  a3j }

Set mi = a4i and m = (mi )ni=1 . It is easy to prove that m satisfies all RCC8 constraints in . For
example, suppose (vi DC vj ) is a constraint in . Because (15) holds, we know vi and vj share no
common conflict point, i.e. Ci  Cj = . Due to the choice of control points for vi and vj , we know
523

fiC OHN , L I , L IU , & R ENZ

Xi  Xj is also empty. It is now easy to show that mi  mj is empty and hence the DC constraint
is satisfied.
To show m also satisfies , we need only prove M(mi ) = mi for each i. It is clear that a1i
and a2i are subsets of mi . By the choice of Xi , we know mi = M(a1i ) = M(a2i ). If ji = TPP
or NTPP, then mj  mi by bipath-consistency. This implies M(a3i ) = mi . Furthermore, if
ji = NTPP, we have (mj , mi )  d  d by bipath-consistency. So for any control point Q in
a3j  mj , Q is also in the interior of mi . Therefore, by the choice of basic regions, we know the
outmost square q (n) at Q, hence q (l(i)) , is contained in mi . Therefore, M(a4i ) = mi . This proves
that m is a solution to  ] .

Appendix C. The Reduction from 3SAT to JSP(Brcc8 , Bcdc )
V
n
Let  = m
i=1 cj be a 3SAT instance involving n propositional variables {pk }k=1 and m clauses.
Assume that the j-th clause cj is qi1  qi2  qi3 , where each qij is a literal in {pk }nk=1  {pk }nk=1 .
We construct a JSP(Brcc8 , Bcdc ) instance  ]  and choose a particular regular solution m of
 such that  is satisfiable iff m is RA consistent with  .
There are three types of spatial variables in  ]  : auxiliary variables (called grid variables)
which are used to fix the relative locations of other variables, variables to simulate propositional
variables, and variables to simulate propositional clauses.
C.1 Grid Variables
We introduce 10  n grid variables Gij (1  i  2n, 1  j  5). The CDC constraints between
these variables are specified as in Figure 10 (left). The RCC8 relation between two grid variables
Gij , Gi0 j 0 is EC if they are 4-neighbours, i.e. {|i  i0 |, |j  j 0 |} = {0, 1}. These EC constraints
make sure that there is no gap between the MBRs of two neighbouring grid variables. This implies
that there is at most one regular solution of  .
Grid variables are mainly used to locate other spatial variables. For a new variable v and a grid
variable Gij , we say v occupies Gij if v  M(Gij ) is nonempty, and its MBR is M(Gij ), i.e.
M(v  M(Gij )) = M(Gij ).

Figure 10: Grid and spatial variables for propositional variables.

C.2 Spatial Variables for Propositional Variables
For each propositional variable pi in , four spatial variables Ai , Bi , Ci and Di are introduced such
that each occupies two grid cells, but has an empty intersection with the interiors of the MBRs of
524

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

all other grid variables. The corresponding grid cells are illustrated in Figure 10 (right). Take Ai
as example. By assigning the CDC constraints between Ai and the grid variables, we require Ai
occupies G2i1,1 and G2i1,4 , but is disjoint from the MBRs of all other grid variables. It is easy to
see that Ai  Bi contains at most two points, viz. Pi+ and Pi , and so does Ci  Di .
As for the topological constraints, we require Ai ECBi and Ci ECDi , and all other constraints
are DC. The EC constraints imply that both Ai  Bi and Ci  Di are nonempty. On the other hand,
since Ai DCCi , we can conclude that Ai and Bi must share only one of Pi+ and Pi , while Ci and
Di share the other one.
C.3 Spatial Variables for Propositional Clauses
For each clause (qj1  qj2  qj3 ) in , we introduce two new spatial variables Ej and Fj , both
occupy three grid cells. The precise occupied grid cells are set according to the variables and signs
of qjk . Figure 11 gives an example to illustrate the construction, where we assume qj1 = pi1 , qj2 =
pi2 , qj3 = pi3 . As for the topological constraints, we set the constraint between Ej and Fj
as EC, and set all other constraints as DC. This implies Ej  Fj contains at least one point of
Pi1 , Pi+2 , Pi+3 . We claim that it is not the case that Ai1  Bi1 = {Pi1 }, Ai2  Bi2 = {Pi+2 } and
Ai3  Bi3 = {Pi+3 }. Otherwise, some DC constraint, e.g. that between Ai1 and Ej , will be violated.
C.4 The Regular Solution That May Be RA Consistent with 

Figure 11: Spatial variables for clauses.
We have now finished the construction. Note that  is always satisfiable and there are exponentially many regular solutions of it (as there may be or may be not a gap between 4-neighbouring
grid variables). However, the EC constraints between the 4-neighbouring grid variables imply that
only the regular solution in which there is no gap between 4-neighbouring grid variables can be RA
consistent with  . We denote this regular solution by m.
We next show that  is consistent iff  ]  is consistent. Suppose  ]  has a solution a.
We define an assignment  : {pi }ni=1  {true, f alse} such that (pi ) = true iff Ai  Bi = {Pi+ }
in a. We can verify that  satisfies . On the other hard, suppose  is an assignment that satisfies
. We prove that  ]  has a solution. The idea is to introduce an instance of JSP(Brcc8 , Brec ),

in which we have two spatial variables A+
i and Ai instead of Ai (also for Bi , Ci , Di ), and three
k
variables Ej (1  k  3) instead of Ej (also for Fj ). The RA constraints are set according to
Figure 10 and Figure 11, while the RCC8 constraints are set by  and . It can be proven that
this new joint network satisfies (15), and a solution can be obtained in cubic time. A solution of

 ]  can then be obtained by merging the related regions (e.g. merging A+
i and Ai into Ai ).
525

fiC OHN , L I , L IU , & R ENZ

The verification is straightforward. Therefore,  is satisfiable iff  ]  is satisfiable, and thus 
is satisfiable iff m is RA consistent with  .

Appendix D. The Reduction from Graph 3-Colouring to JSP(Brcc8 , Bcdc )
Suppose G = (V, E) is a graph. We construct an instance G ] G of JSP(Brcc8 , Bcdc ) as follows.
For each node vi in V , we construct a gadget with 10 spatial variables: uki (k = 1, 2,    , 8), xi
0
and yi . We first describe their CDC constraints. The basic CDC constraints between uki and uki are
specified as in Figure 12 (i). For example, G contains the following basic CDC constraints








0 0 0
0 0 0
1 1 0
0 0 0
u1i 1 0 0 u2i , u2i 0 0 1 u1i , u2i 1 1 0 u7i , u7i 0 1 1 u2i .
0 0 0
0 0 0
0 0 0
0 1 1
Note that, the induced RA constraint between u2l+1
and u2l+2
for l = 0, 1, 2 is (b  m)  eq. The
i
i
basic CDC constraints between xi and yi are specified as in Figure 12 (ii), i.e.




0 0 0
0 0 0
xi 1 1 0 yi , yi 0 1 1 xi .
0 0 0
0 0 0
The CDC constraints concerning xi , yi and uki are specified as follows.

0
xi 0
0

1
xi 0
0

0
k
ui 0
0

0

yi 0
0

1
yi 0
0

0
uki 0
0




0 0 0
0 0
1 0 u1i , xi 1 0 0 u2i ,
0 0 1
0 1



0 0
1 0 0
1 0 u5i , xi 1 0 0 u6i ,
0 0
0 0 0

0 0
1 0 xi (k 6= 6),
0 0



0 0
0 0 0
0 1 u1i , yi 0 1 0 u2i ,
0 1
0 0 1



0 0
1 0 0
0 1 u5i , yi 0 1 0 u6i ,
0 0
0 0 0

0 0
1 0 yi (2  k  8),
0 0


1
xi 0
0

1
xi 0
0

0
6
ui 0
0

1

yi 0
0

1
yi 0
0

0
u1i 1
0




1 0 0
0 0
1 0 u3i , xi 1 0 0 u4i ,
0 0 1
0 1

0 0
0 0 uki (k = 7, 8),
0 1

0 0
0 1 xi ;
0 0



0 0
1 0 0
0 1 u3i , yi 0 1 0 u4i ,
0 1
0 0 1

0 0
0 0 uki (k = 7, 8),
0 1

0 0
0 0  yi .
0 0

Figure 12 (ii) illustrates a regular solution of uki , xi and yi , where u1i meets u2i while there is
a gap between u3i and u4i , and between u5i and u6i . We note that there are in total eight different
regular solutions when the network is restricted to the gadget of vi .
526

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

(i)

(ii)
Figure 12: Illustrations of the CDC constraints: (i) constraints between uki (k = 1, 2,    , 8); (ii)
constraints relating xi , yi . Note we use dashed squares to denote variables u7i and u8i ,
which connect two other variables. Note that both xi and yi have three disjoint parts.

527

fiC OHN , L I , L IU , & R ENZ

The RCC8 constraint between any two variables is either EC or DC. We require xi ECyi . This
is realisable only if u2l+1
meets u2l+2
in x-direction for at least one l  {0, 1, 2}.4 We use this fact
i
i
to mimic that the node vi  V is coloured with one of the three colours. The RCC8 constraints of
the remaining pairs of variables are all specified as DC. 5
The gadgets for all nodes in V are horizontally aligned, as illustrated in Figure 13.

Figure 13: Illustrations of the gadgets for all nodes in V

Figure 14: Illustrations of the gadget for edge ek = (vi , vj ), where dashed lines suggest that corresponding edges are aligned according to proper CDC constraints.
We then devise the gadgets for edges in graph G. Let ek = (vi , vj ) be an edge in E. For each
0 , w 1 , w 2 and w 3 as well as constraints to
colour l  {0, 1, 2}, we introduce four variables wk,l
k,l
k,l
k,l
2l+2
2l+1
2l+2
guarantee that u2l+1
cannot
meet
u
if
u
meets
u
,
which
corresponds
to that nodes vi
i
i
j
j
and vj cannot both have colour l (because ek is an edge in G). The CDC constraints are specified
1 meets w 3 iff u2l+1 meets u2l+2 , and w 3 meets w 2 iff u2l+1
as in Figure 14. We note that wk,l
i
i
j
k,l
k,l
k,l
3 ) is contained in
meets u2l+2
,
all
in
x-direction.
By
the
CDC
constraints
we
can
show
that
M(w
j
k,l
0 ). This implies that there is either a gap between w 1 and w 3 or a gap between w 3 and
M(wk,l
k,l
k,l
k,l
2 . In other words, w 1 meets w 3 and w 3 meets w 2 cannot happen simultaneously. By the
wk,l
k,l
k,l
k,l
k,l
4. If there are more than one l such that u2l+1
meets u2l+2
in x-direction, we always choose the smallest such l as the
i
i
colour of the node vi .
5. Note that u1i DCu2i together with the CDC relations between u1i and u2i does not necessarily imply that u1i should
precede u2i in x-direction. That is, u1i could still meet u2i in x-direction in this case.

528

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

constraints enforcing the dashed lines we know u2l+1
cannot meet u2l+2
if u2l+1
meets u2l+2
, and
i
i
j
j
vice versa.
Note that we need to complete both  and . While unspecified CDC constraints can be easily
deduced from these figures, unspecified RCC8 constraints are all DC.
It is not hard to verify that graph G is 3-colourable iff the joint network G ] G is consistent.
The idea is that, if  : V  {0, 1, 2} is a 3-colouring of G, then we may construct a solution of
G ] G in which the RA relation between u2l+1
and u2l+2
is m  eq if (i) = l, and is b  eq
i
i
otherwise. This guarantees that xi and yi are realisable. The fact that no incident nodes in G have
r are realisable. On the other hand, if  ]  is satisfiable,
the same colour implies that all wk,l
G
G
then at least one pair in {(u1i , u2i ), (u3i , u4i ), (u5i , u6i )} should have RA relation m  eq (otherwise,
xi ECyi is violated). Define  : V  {0, 1, 2} by (vi ) = min{l : u2l+1
m  eq u2l+2
}. It can be
i
i
r are realisable.
verified that  is a 3-colouring of G due to the fact that wk,l
Now we have completed the reduction from Graph 3-Colouring to JSP(Brcc8 , Bcdc ). We note
that the EC constraints can also be interpreted in terms of RCC80 . This means that G ] G can
also be regarded as an instance of JSP(Brcc8 , Bcdc ). Therefore, we have also provided a reduction
from Graph 3-Colouring to JSP(Brcc80 , Bcdc ).

References
Allen, J. F. (1983). Maintaining knowledge about temporal intervals. Communications of the ACM,
26(11), 832843.
Balbiani, P., Condotta, J.-F., & Farinas del Cerro, L. (1999). A new tractable subclass of the rectangle algebra. In Dean, D. (Ed.), Proceedings of the Sixteenth International Joint Conference
on Artificial Intelligence (IJCAI-99), pp. 442447. Morgan Kaufmann.
Bodirsky, M., & Kara, J. (2010). The complexity of temporal constraint satisfaction problems. J.
ACM, 57(2).
Borgo, S., Guarino, N., & Masolo, C. (1996). A pointless theory of space based on strong connection
and congruence. In Aiello, L. C., Doyle, J., & Shapiro, S. C. (Eds.), KR, pp. 220229. Morgan
Kaufmann.
Chen, J., Cohn, A. G., Liu, D., Wang, S., Ouyang, J., & Yu, Q. (2013). A survey of qualitative
spatial representations. The Knowledge Engineering Review, FirstView, 131.
Cicerone, S., & Di Felice, P. (2004). Cardinal directions between spatial objects: the pairwiseconsistency problem. Information Sciences, 164(1-4), 165188.
Cohn, A. G., & Renz, J. (2008). Qualitative spatial reasoning. In van Harmelen, F., Lifschitz, V., &
Porter, B. (Eds.), Handbook of Knowledge Representation. Elsevier.
Cohn, A. G., Renz, J., & Sridhar, M. (2012). Thinking inside the box: A comprehensive spatial
representation for video analysis. In KR, pp. 588592.
Cohn, A. G., & Varzi, A. C. (1999). Modes of connection. In Freksa, C., & Mark, D. M. (Eds.),
COSIT, Vol. 1661 of Lecture Notes in Computer Science, pp. 299314. Springer.
Davis, E. (2013). Qualitative spatial reasoning in interpreting text and narrative. Spatial Cognition
& Computation, 13(4), 264294.
529

fiC OHN , L I , L IU , & R ENZ

Davis, E., Gotts, N. M., & Cohn, A. G. (1999). Constraint networks of topological relations and
convexity. Constraints, 4(3), 241280.
Duntsch, I., Wang, H., & McCloskey, S. (2001). A relation-algebraic approach to the Region
Connection Calculus. Theoretical Computer Science, 255, 6383.
Egenhofer, M. J., & Mark, D. M. (1995). Naive geography. In Frank, A., & Kuhn, W. (Eds.),
COSIT-95, pp. 115. Springer.
Falomir, Z. (2012). Qualitative distances and qualitative description of images for indoor scene
description and recognition in robotics. AI Communications, 25(4), 387389.
Freksa, C. (1992). Temporal reasoning based on semi-intervals. Artificial Intelligence, 54(1), 199
227.
Gabelaia, D., Kontchakov, R., Kurucz, A., Wolter, F., & Zakharyaschev, M. (2005). Combining
spatial and temporal logics: Expressiveness vs. complexity. Journal of Artificial Intelligence
Research, 23, 167243.
Ge, X., & Renz, J. (2013). Representation and reasoning about general solid rectangles. In Rossi,
F. (Ed.), IJCAI. IJCAI/AAAI.
Gerevini, A., & Renz, J. (2002). Combining topological and size information for spatial reasoning.
Artificial Intelligence, 137(1), 142.
Gerevini, A., & Nebel, B. (2002). Qualitative spatio-temporal reasoning with rcc-8 and allens
interval calculus: Computational complexity. In ECAI, pp. 312316.
Goyal, R., & Egenhofer, M. (1997). The direction-relation matrix: A representation for directions
relations between extended spatial objects. In The Annual Assembly and the Summer Retreat
of University Consortium for Geographic Information Systems Science.
Goyal, R., & Egenhofer, M. (2001). Similarity of cardinal directions. In Jensen, C., Schneider, M.,
Seeger, B., & Tsotras, V. (Eds.), Proceedings of the 7th International Symposium on Advances
in Spatial and Temporal Databases (SSTD-01), pp. 3658. Springer.
Hirsch, R. (1999). A finite relation algebra with undecidable network satisfaction problem. Logic
Journal of the IGPL, 7(4), 547554.
Jonsson, P., & Krokhin, A. A. (2004). Complexity classification in qualitative temporal constraint
reasoning. Artificial Intelligence, 160(1-2), 3551.
Kontchakov, R., Nenov, Y., Pratt-Hartmann, I., & Zakharyaschev, M. (2011). On the decidability of
connectedness constraints in 2D and 3D Euclidean spaces. In IJCAI, pp. 957962.
Li, S. (2006a). Combining topological and directional information: First results. In Lang, J., Lin, F.,
& Wang, J. (Eds.), Proceedings of the First International Conference on Knowledge Science,
Engineering and Management (KSEM-06), pp. 252264. Springer.
Li, S. (2006b). On topological consistency and realization. Constraints, 11(1), 3151.
Li, S. (2007). Combining topological and directional information for spatial reasoning. In Veloso,
M. (Ed.), Proceedings of the 20th International Joint Conference on Artificial Intelligence
(IJCAI-07), pp. 435440. AAAI.
Li, S., & Cohn, A. G. (2012). Reasoning with topological and directional spatial information.
Computational Intelligence, 28(4), 579616.
530

fiR EASONING ABOUT T OPOLOGICAL AND C ARDINAL D IRECTION R ELATIONS

Li, S., & Liu, W. (2014). Cardinal directions: A comparison of direction relation matrix and objects
interaction matrix. International Journal of Geographical Information Science, accepted for
publication, doi: http://dx.doi.org/10.1080/13658816.2014.954580.
Li, S., Liu, W., & Wang, S. (2013). Qualitative constraint satisfaction problems: An extended
framework with landmarks. Artificial Intelligence, 201, 3258.
Ligozat, G. (1994). Tractable relations in temporal reasoning: pre-convex relations. In ECAI-94.
Workshop on Spatial and Temporal Reasoning, pp. 99108.
Ligozat, G., & Renz, J. (2004). What is a qualitative calculus? A general framework. In Zhang, C.,
Guesgen, H., & Yeap, W.-K. (Eds.), PRICAI-04, pp. 5364. Springer.
Liu, W., & Li, S. (2011). Reasoning about cardinal directions between extended objects: The NPhardness result. Artificial Intelligence, 175(18), 21552169.
Liu, W., Li, S., & Renz, J. (2009). Combining RCC-8 with qualitative direction calculi: Algorithms
and complexity. In Boutilier, C. (Ed.), Proceedings of the Twenty-first International Joint
Conference on Artificial Intelligence (IJCAI-09), pp. 854859.
Liu, W., Zhang, X., Li, S., & Ying, M. (2010). Reasoning about cardinal directions between extended objects. Artificial Intelligence, 174(12-13), 951983.
Nebel, B. (1995). Computational properties of qualitative spatial reasoning: First results. In KI-95,
pp. 233244, Berlin, Germany. Springer-Verlag.
Nebel, B., & Burckert, H.-J. (1995). Reasoning about temporal relations: A maximal tractable
subclass of Allens interval algebra. Journal of the ACM, 42(1), 4366.
Randell, D. A., Cui, Z., & Cohn, A. G. (1992). A spatial logic based on regions and connection. In
KR-92, pp. 165176.
Renz, J. (1999). Maximal tractable fragments of the Region Connection Calculus: A complete
analysis. In Dean, D. (Ed.), Proceedings of the Sixteenth International Joint Conference on
Artificial Intelligence (IJCAI-99), pp. 448454. Morgan Kaufmann.
Renz, J. (2002). Qualitative spatial reasoning with topological information, Vol. 2293 of Lecture
Notes in Artificial Intelligence. Springer-Verlag, Berlin, Germany.
Renz, J., & Nebel, B. (1999). On the complexity of qualitative spatial reasoning: A maximal
tractable fragment of the Region Connection Calculus. Artificial Intelligence, 108, 69123.
Schneider, M., Chen, T., Viswanathan, G., & Yuan, W. (2012). Cardinal directions between complex
regions. ACM Transactions on Database Systems, 37(2), 8:18:40.
Schockaert, S., & Li, S. (2012). Convex solutions of RCC8 networks. In ECAI, pp. 726731.
Schockaert, S., & Li, S. (2013). Combining RCC5 relations with betweenness information. In
IJCAI, pp. 10831089.
Shi, H., Jian, C., & Krieg-Bruckner, B. (2010). Qualitative spatial modelling of human route instructions to mobile robots. In ACHI, pp. 16.
Sistla, A., & Yu, C. (2000). Reasoning about qualitative spatial relationships. Journal of Automated
Reasoning, 25(4), 291328.
Skiadopoulos, S., & Koubarakis, M. (2005). On the consistency of cardinal direction constraints.
Artificial Intelligence, 163(1), 91135.
531

fiC OHN , L I , L IU , & R ENZ

Sridhar, M., Cohn, A. G., & Hogg, D. C. (2011). From video to RCC8: Exploiting a distance
based semantics to stabilise the interpretation of mereotopological relations. In COSIT, pp.
110125.
Vilain, M. B., & Kautz, H. A. (1986). Constraint propagation algorithms for temporal reasoning. In
AAAI, pp. 377382.
Whitehead, A. (1929). Process and Reality: An Essay in Cosmology. Cambridge University Press,
Cambridge.
Wolfl, S., & Westphal, M. (2009). On combinations of binary qualitative constraint calculi. In
Boutilier, C. (Ed.), Proceedings of the Twenty-first International Joint Conference on Artificial
Intelligence (IJCAI-09), pp. 967972.
Wolter, D., & Wallgrun, J. (2012). Qualitative spatial reasoning for applications: New challenges
and the sparq toolbox. In Hazarika, M. (Ed.), Qualitative Spatio-Temporal Representation
and Reasoning: Trends and Future Directions, pp. 336362.
Wolter, D., Dylla, F., Wolfl, S., Wallgrun, J. O., Frommberger, L., Nebel, B., & Freksa, C. (2008).
Sailaway: Spatial cognition in sea navigation. KI, 22(1), 2830.
Wolter, F., & Zakharyaschev, M. (2000). Spatial reasoning in RCC-8 with boolean region terms. In
ECAI, pp. 244250.
Zhang, P., & Renz, J. (2014). Qualitative spatial representation and reasoning in angry birds: the
extended rectangle algebra. In KR.
Zhang, X., Liu, W., Li, S., & Ying, M. (2008). Reasoning with cardinal directions: An efficient
algorithm. In Fox, D., & Gomes, C. (Eds.), Proceedings of the Twenty-Third AAAI Conference
on Artificial Intelligence (AAAI-08), pp. 435440. AAAI.

532

fiJournal of Artificial Intelligence Research 51 (2014) 1-70

Submitted 2/14; published 9/14

Cooperative Monitoring to Diagnose Multiagent Plans
Roberto Micalizio
Pietro Torasso

micalizio@di.unito.it
torasso@di.unito.it

Dipartimento di Informatica,
Universita di Torino
corso Svizzera 185, 10149 - Torino, Italy

Abstract
Diagnosing the execution of a Multiagent Plan (MAP) means identifying and explaining
action failures (i.e., actions that did not reach their expected effects). Current approaches
to MAP diagnosis are substantially centralized, and assume that action failures are independent of each other.
In this paper, the diagnosis of MAPs, executed in a dynamic and partially observable
environment, is addressed in a fully distributed and asynchronous way; in addition, action
failures are no longer assumed as independent of each other.
The paper presents a novel methodology, named Cooperative Weak-Committed Monitoring (CWCM), enabling agents to cooperate while monitoring their own actions. Cooperation helps the agents to cope with very scarcely observable environments: what an agent
cannot observe directly can be acquired from other agents. CWCM exploits nondeterministic action models to carry out two main tasks: detecting action failures and building
trajectory-sets (i.e., structures representing the knowledge an agent has about the environment in the recent past). Relying on trajectory-sets, each agent is able to explain its own
action failures in terms of exogenous events that have occurred during the execution of the
actions themselves. To cope with dependent failures, CWCM is coupled with a diagnostic
engine that distinguishes between primary and secondary action failures.
An experimental analysis demonstrates that the CWCM methodology, together with
the proposed diagnostic inferences, are effective in identifying and explaining action failures
even in scenarios where the system observability is significantly reduced.

1. Introduction
Multiagent Plans (MAPs) are adopted in many applicative domains, from Web services to
service robots, whenever the interactions among cooperative agents have to be organized in
advance (i.e., planned), in order to reach an acceptable efficiency level during the execution;
consider for instance, orchestrated Web services (Yan, Dague, Pencole, & Cordier, 2009),
assembling tasks (Heger, Hiatt, Sellner, Simmons, & Singh, 2005; Sellner, Heger, Hiatt,
Simmons, & Singh, 2006), or service robotics (Micalizio, Torasso, & Torta, 2006). MAPs are
therefore characterized by a cooperative team of agents that perform actions concurrently
in order to achieve a common global goal.
The use of MAPs in real-world scenarios, however, has to cope with a critical issue:
plan actions can deviate from their expected nominal behaviors due to the occurrence of
(unpredictable) exogenous events. These deviations are typically considered as plan failures
since they prevent the agents to reach their goals. Indeed, although MAPs are very versatile
c
2014
AI Access Foundation. All rights reserved.

fiMicalizio & Torasso

systems, they are also particularly fragile: the failure of an action can easily propagate
through the system causing the failures of other actions, even assigned to different agents.
In order to make the execution of a MAP robust (i.e., tolerant to at least some exogenous
events), it is therefore important to detect and isolate action failures, and provide a human
user (or a plan repair module) with a set of possible explanations for the detected failures.
Some recent works (see e.g., Mi & Scacchi, 1993; Gupta, Roos, Witteveen, Price, & de Kleer,
2012; Micalizio, 2013) have argued that a plan repair procedure can be more effective when
the causes of the plan failure are known (e.g., identified via diagnosis).
Over the last decade, the problem of diagnosing the execution of a MAP has been faced
from different perspectives. Since their seminal work, Kalech and Kaminka (2003) focus on
coordination failures and introduce the notion of social diagnosis. Social diagnosis relies on
an abstract representation of the MAP at hand, given in terms of behaviors, and aims at
explaining why two or more agents have selected conflicting behaviors. Kalech and Kaminka
(2011) and Kalech (2012) present alternative algorithms for inferring a social diagnosis.
Other approaches (see e.g., de Jonge, Roos, & Witteveen, 2009; Roos & Witteveen,
2009; Micalizio & Torasso, 2008, 2009) adopt an explicit representation of a MAP in terms
of agents actions and shared resources. In particular, in their diagnostic framework, Roos
and Witteveen (2009) and de Jonge et al. (2009) consider action failures (i.e., actions that
do not reach their expected effects), and introduce the notion of plan diagnosis. A plan
diagnosis is a subset of (already performed) actions that, when assumed abnormal, make
the plan execution consistent with the observations received so far. Since the same set of
observations can possibly be explained by many plan diagnoses, Roos and Witteveen (2009)
present a criterion for identifying preferred diagnoses that is based on the predictive power
of these diagnoses.
These proposals, however, rely on some assumptions that might limit their applicability in some real-world scenarios. First of all, they assume some form of synchronization
among the agents (e.g., synchronized selection of behaviors, or execution of actions). More
importantly, action failures are assumed to be mutually independent. Furthermore, in the
particular case of social diagnosis, agents cooperate with each other by exchanging their
own belief states, but this might be a critical issue when they have to keep some information private. On the other hand, in the framework proposed by Roos and Witteveen (2009),
diagnostic inferences are substantially centralized.
In this paper we aim at relaxing these assumptions by extending the relational-based
framework introduced by Micalizio and Torasso (2008, 2009). Similarly to Roos and Witteveen, we adopt an explicit representation of the MAP at hand in term of agents actions
and shared resources. But differently from them, our action models include nominal as well
as faulty evolutions. As we will argue in the rest of the paper, this kind of extended action
models subsumes the action models proposed by Roos and Witteveen.
In addition, we aim at a fully distributed solution that does not rely on the synchronized
execution of the actions (i.e., no global clock is available). A distributed solution to social
diagnosis was also proposed by Kalech, Kaminka, Meisels, and Elmaliach (2006). In their
work, however, a form of synchronization among the agents is required as agents select their
next behavior simultaneously. Moreover, the agents cooperate with each other by sharing
their own belief states. In our proposal, coordination among the agents is achieved by means
of the exchange of direct observations between agents. The idea is that an observation
2

fiCooperative Monitoring to Diagnose Multiagent Plans

acquired by an agent can be used by other agents in their own reasoning. To understand
the difference between exchanging belief states and direct observations, we have to note
that a belief state is an interpretation of observations made by a specific agent according
to its local knowledge. Since the agent might have a partial knowledge of the environment,
its belief states could be ambiguous or even erroneous. Therefore, when agents exchange
with each other their own beliefs, they may also propagate their errors. Conversely, when
the coordination consists in the exchange of direct observations, agents can infer their own
beliefs without the risk of being conditioned by the errors made by others.
We propose a framework that, relying on the notion of Partial-Order, Causal-Link
(POCL) Plans (see Cox, Durfee, & Bartold, 2005; Weld, 1994; Boutilier & Brafman, 2001),
limits the number of messages exchanged between agents to the number of causal links
existing between actions assigned to different agents.
In our proposal, communication plays a central role not only for assuring a consistent
execution of the MAP, but also for easing the diagnostic task. We consider that the environment where the agents operate is scarcely observable, so agents can directly acquire
information about just a small portion of their surroundings. Dealing with scarce observations can be very challenging for solving the diagnostic task as this situation might
prevent the detection of action failures. To cope with this issue we propose in this paper
a strategy named Cooperative Weak-Committed Monitoring (CWCM), which extends the
weak-committed monitoring introduced by Micalizio and Torasso (2009). CWCM allows
the agents to cooperate with each other so that an agent can infer the outcome of its own
actions (i.e., failure detection) from the pieces of information provided by the other agents.
As soon as failures are detected, these must be diagnosed in order to identify their
root causes. In this paper, we propose a local diagnostic process where each agent can
diagnose the failure of its own actions without the need of interacting with other agents.
In particular, our diagnostic inferences take into account that failures of different actions
may be dependent. In other words, an action failure can be an indirect consequence (i.e.,
a secondary failure) of the failure of a preceding action (i.e., primary failure). Identifying
primary and secondary failures is essential from the point of view of plan repair as primary
failures are the root causes for the anomalous observed execution. In principle, a plan repair
that recovers from primary failures should also recover from secondary failures. An interesting property of our methodology is that the process of inferring primary and secondary
failures is performed autonomously by each agent, just relying on the trajectory-sets built
during the cooperative monitoring.
1.1 Contributions
The paper contributes to the diagnosis of MAP execution in many ways. First of all,
the paper shows how the extended action models proposed for the monitoring purpose can
be obtained compositionally from the nominal models of actions, and from the models of
the exogenous events that can affect those actions. Thus, a knowledge engineer can take
advantage of this by focusing on the models of the elementary components of the systems
(e.g., actions and exogenous events), and then creating complex, extended, action models
by composing the elementary components.
3

fiMicalizio & Torasso

In addition, the proposed CWCM framework is fully distributed: each agent monitors
its own actions, and there is no a central agent that traces all actions in progress. Thus,
CWCM can be applied in those domains where agents operate in physically distributed
environments, and hence a centralized solution could be impractical. Another important
feature of CWCM is that it is asynchronous: neither assumption on synchronized execution
of actions, nor assumptions on how long actions should last are made. In other words, agents
do not share a global clock. Of course, some form of synchronization is still necessary when
mutual exclusion is required for accessing critical resources. In such cases, however, we will
prefer to use the term coordination.
CWCM also represents a valid solution whenever a diagnosis of a MAP is performed in
environments characterized by scarce observability levels. In fact, a significant contribution
of CWCM is its cooperative monitoring protocol that enables the agents to acquire information about the system resources from each other. In the paper we argue that the number
of messages exchanged via our cooperative protocol is linear in the number of inter-agent
causal links (i.e., causal dependencies existing between any pair of agents).
A last important contribution of the paper is the ability of distinguishing between primary and secondary failures. Previous approaches (see e.g., Micalizio & Torasso, 2008; Roos
& Witteveen, 2009), in fact, assume that action failures are independent of each other.
1.2 Outline
The paper is organized as follows. In Section 2 we introduce a basic multiagent planning
framework that we use as a starting point of our work. In Section 3 the basic framework is
extended by relaxing some important assumptions. Section 4 formally presents the Cooperative Weak-Committed Monitoring (CWCM) strategy, while the local diagnostic inferences
are discussed in Section 5. The paper closes with a detailed experimental analysis in Section
6, and a critical discussion of related works in Section 7.
The paper also includes an Appendix where we briefly discuss how CWCM can be
implemented by means of Ordered Binary Decision Diagrams (OBDDs) (Bryant, 1992,
1986), and formally analyze the computational complexity of such an implementation.

2. Multiagent Planning: a Basic Framework
This section is organized in three parts. First, we introduce some basic notions on Multiagent Planning and the terminology we use throughout the paper. Then, we discuss how
the propositional planning language can be translated into a state-variable representation.
Finally, we present a basic strategy for plan execution in multiagent settings in which we
highlight the importance of the cooperation among the agents even under the strong assumption that no exogenous event occurs. Such an assumption is relaxed in Section 3.
2.1 Preliminary Concepts on Multiagent Planning
Since we are interested in diagnosing systems that can be modeled as multiagent plans, we
begin our discussion by presenting a framework developed within the planning community to
represent and synthesize this kind of plans. It is worth noting that the planning problem is
typically approached in propositional terms: preconditions and effects of actions are literals
4

fiCooperative Monitoring to Diagnose Multiagent Plans

that must be true, respectively, before and after the application of the actions themselves.
Thus we intuitively introduce in this section some planning notions in propositional terms,
however, in Section 2.2, we argue that when addressing the problem of plan execution, it is
more convenient to handle a representation of the system in terms of state variables, and
hence we translate the propositional framework into a state variables one.
An important assumption holding throughout the paper is that, although the observations gathered by agents at execution time can be partial, they are always correct; we will
elaborate more on this point in Section 3.1.
2.1.1 Multiagent Plans
The Multiagent Plan (MAP) systems we take into account in this paper can be modeled as
a tuple S=hT , RES , P i, where:
 T is the team of cooperating agents; agents are denoted by letters i and j;
 RES is the set of shared resources and objects available in the environment; we
assume that all the resources are reusable (i.e., they are not consumable), and can
only be accessed in mutual exclusion; note that agents can exchange each other pieces
of information about these resources, so the space of resource names is a common
language through which agents communicate;
 P is a completely instantiated Partial-Order Causal-Link Plan (POCL) (Weld, 1994),
resulting from a planning phase as the ones by Boutilier and Brafman (2001) or by
Cox et al. (2005). For the sake of simplicity, our MAP P has a simplified structure
since it does not involve concurrency and non-concurrency constraints. More precisely,
our MAP P is a tuple hI, G, A, R, Ci where:
- I is a set of propositional atoms representing the initial state of the system at
planning time.
- G is another set of propositional atoms representing the global goal to be achieved.
Note that G is the conjunction of sub-goals Gi each agent i  T is in charge of.
- A is the set of the action instances the agents have to execute; each action a is
assigned to a specific agent in T . At planning time, we assume that an action a
is modeled just in terms of preconditions pre(a) and effects eff (a), where both
are conjunctions of grounded atoms (see PDDL level 1, Fox & Long, 2003). In
the rest of the paper, we denote as ail the l-th action performed by agent i.
- R is a set of precedence links between action instances; the precedence link ha, a0 i
in R means that action a0 can only start after the completion of action a.
- C is a set of causal links of the form lk : ha, q, a0 i; the link lk states that action
a provides action a0 with service q, where q is an atom occurring both in the
effects of a and in the preconditions of a0 .
We assume that MAP P :
 is flaw-free: a nominal execution of P from I achieves G;
5

fiMicalizio & Torasso

 is safe with respect to the use of the resources. Intuitively, we say that a resource
res  RES is used safely iff at each execution step, res is either not assigned, or
assigned to exactly one agent. This is similar to the concurrency requirement (Roos
& Witteveen, 2009): two actions are not executed concurrently if they both require
the same subset of resources;
 has no redundant actions: even though P is not necessarily optimal, it only contains
actions that directly or indirectly provide services to help the achievement of the goal.
This means that there always exists a chain of causal links between any action in the
plan and at least one atom in the goal G.
To guarantee the resource safeness, we introduce the notion of working sessions associated with resources and agents:
Definition 1 Let res be a resource in RES , and i be an agent in T , a working session
wshres,ii for i using res is a pair haio , aic i of actions in Ai such that:
 aio precedes aic (i.e., aio  aic , where  is the transitive closure of the precedence
relations in R).
 aio is an action in Ai through which agent i acquires res, this is modeled by specifying
the atom available(res) in the preconditions of aio . Moreover, there exists in C an
incoming causal link of the form hajk , available(res), aio i, where ajk is an action assigned
to agent j (possibly ajk can be a0 i.e., the pseudo action whose effects determine the
initial state of the system). Action aio opens the working session. No other action
aih  Ai between aio and aic (i.e., aio  aih  aic ), has an incoming causal link labeled
with service available(res) coming from an action of another agent j 6= i.
 aic is an action in Ai through which agent i relinquishes resource res in favor of another
agent j 6= i. This is modeled by means of a causal link haic , available(res), ajk i in C,
meaning that action aic releases res as one of its effects, and that available(res) is
one of the preconditions of ajk . Action aic closes the working session. Of course,
agent i can release resource res to at most one agent; i.e., the outgoing link
haic , available(res), ajk i is unique. In addition, no action aih  Ai between aio and aic ,
has an outgoing link labeled with service available(res) directed towards an action of
another agent j.
 any action aih between aio and aic can use res; i.e., res can be mentioned in the preconditions and effects of aih . More precisely, a causal link mentioning res between two
actions aih and aik in Ai is allowed only if both aih and aik belong to the same working
session, namely, aio  aih  aik  aic .
Given a working session wshres,ii , we denote its opening and closing actions as
opening(wshres,ii ) and closing(wshres,ii ), respectively. Two working sessions wshres,ii and
ws0hres,ji are consecutive, wshres,ii / ws0hres,ji , if closing(wshres,ii ) provides opening(ws0hres,ji )
with service available(res).
Proposition 1 A MAP P satisfies the resource safeness requirement if for each resource
res  RES, all the working sessions over res can be totally ordered in a sequence
ws1hres,i1 i / ws2hres,i2 i . . . / wsnhres,in i , for any agent ij  T (with j : 1..n).
6

fiCooperative Monitoring to Diagnose Multiagent Plans

This means that, independently of the agents accessing the resource, two working sessions
over the same resource res never overlap each other. Possibly, an agent i can have more
than one session in the sequence, meaning that the agent acquires and relinquishes resource
res many times along the plan.
The resource safeness requirement is an extension of the concurrency requirement introduced by Roos and Witteveen (2009). In fact, while the concurrency requirement implicitly
imposes an ordering between two actions that cannot be performed simultaneously, the
resource safeness imposes an ordering between blocks of actions identified by a working session. This is necessary in order to model situations where an agent uses a set of resources
for a number of consecutive actions that cannot be interleaved with the actions of other
agents. A working session is a sort of critical section that cannot be interrupted. It is worth
noting that, since a working session is associated with a single resource, and since there is
no constraint between the working sessions of two resources, it is possible that an action
aic  Ai closes two different working sessions. For example, let wshres,ii and ws0hres0 ,ii be
two working sessions of agent i using resources res and res0 , respectively; then it is possible
that an action aic is both closing(wshres,ii ) and closing(ws0hres0 ,ii ). In addition, the resource
res could be released in favor of agent j, while resource res0 could be released in favor of
another agent k. This is modeled through the two causal links haic , available(res), ajx i and
haic , available(res0 ), aky i.
2.1.2 Local Plans
Since we are interested in a fully distributed framework for both plan execution and plan
diagnosis, we impose that every agent just knows the portion of P it has to perform; we
thus introduce the notion of local plan. Intuitively, a local plan P i is the projection of P
over the actions assigned to agent i; P is therefore partitioned into as many local plans as
there are agents in T . More formally, given an agent i  T , the local plan P i assigned
i
i , C i i, where I i represents the portion of the
to i is a tuple P i =hI i , Gi , Ai , Ri , Clocal
, Cin
out
initial state known by agent i when the plan execution starts; Gi is the sub-goal assigned
i
to agent i; Ai , Ri and Clocal
have the same meaning as A, R and C, respectively, restricted
i , highlight the causal
i
and Cin
to the actions assigned to agent i. The remaining sets, Cout
dependencies existing between the actions of agent i and actions assigned to other agents in
i maintains all the outgoing causal links modeling services that agent i provides other
T : Cout
i maintains all the incoming causal links modeling services that
agents with; whereas, Cin
agent i receives from other agents. To simplify the plan structure, precedence links between
actions of different agents are not allowed in R. This, however, is not a real limitation as
precedence links between actions of different agents could be expressed as causal links in
which the exchanged service refers to a dummy resource.
In the rest of the paper we will consider a local plan P i as a partially ordered set of
actions. However, we assume that each agent can perform just one action per time, so in
the rest of the paper we index the actions according to their execution step. In other words,
P i will be executed by i as a sequence hai0 , ai1 , . . . , ain , ai i, where ai0 and ai are two pseudoactions similar to the ones introduced by Weld (1994). Action ai0 has no preconditions and
its effects coincide to the initial state I i known by agent i; in particular, this pseudo-action
is also used to determine the initial set of resources assigned to agent i: any link leaving
7

fiMicalizio & Torasso

from ai0 and labeled with service available(resk ) denotes that resk is assigned to agent i.
Action ai , on the other hand, has no effects and its preconditions correspond to sub-goal
Gi assigned to i.
2.2 Translating the Propositional Framework into a State-Variable
Representation
Although most of the planning approaches in literature relies on the propositional language
to represent planning problems, we adopt in this paper a representation based on multivalued state variables which is similar to the SAS+ approach introduced by Jonsson and
Backstrom (1998). The reason for this choice stems from the fact that a multi-valued
variable implicitly encode mutual exclusion constraints among the values of its domain:
the variable can just assume one value at a given time. Thus, it is easier to represent the
evolution of the system state over the time as a sequence of assignments of values to the state
variables. This solution has also been effectively adopted for the diagnosis of plans (Roos &
Witteveen, 2009), and as Helmert (2009) has proven, it is not restrictive since it is always
possible to translate a propositional representation into a set of multi-valued state variables.
In the rest of the section we briefly describe how the propositional planning language (see
e.g., Nebel, 2000) can be mapped to the state variables representation. Three main aspects
are addressed: (1) how to represent agents states in terms of state variables rather than
sets of propositional fluents; (2) how to represent the exchange of services among agents;
and (3) how to model actions in terms of state variables.
2.2.1 Mapping Atoms to Variables
From our point of view, both action models and system states can be represented in terms
of a finite set of multi-valued state variables, each of which has a finite and discrete domain.
Given the MAP system S=hT , RES, P i, we associate all agents in T and resources in
RES with a set of state variables; each of these variables maps a subset of atoms of the
corresponding propositional representation.
It follows that the current system state is given by the values currently assigned to the
state variables of all agents and resources. Such a global view, however, is inadequate to
achieve a fully distributed framework. We thus introduce the notion of agent state, which
just captures the portion of the system state relevant for a specific agent i in the team.
Each agent i  T is associated with a set VARi of variables. Each variable v  VARi has
a finite and discrete domain dom(v). A state Sli for agent i at a given execution step l is
therefore an assignment of values to the variables in VARi . More precisely, Sli (v)  dom(v)
is the value assumed by variable v  VARi in the agent state Sli . A partial agent state li
is an assignment of values to just a subset of variables in VARi .
Variables in VARi are partitioned into two subsets: END i and ENV i . Set END i includes
endogenous state variables (e.g., the agent position); whereas ENV i includes variables about
the shared resources. Because of the partitioning of the global system state into agent states,
the state variables of the resources are duplicated into as many copies as there are agents in
T . Therefore, for each resource resk  RES , there exists a private copy resik belonging to
ENV i . To maintain the consistency among these private copies, we rely on two assumptions:
(1) MAP P is flaw-free, and (2) P satisfies the resource safeness requirement. These two
8

fiCooperative Monitoring to Diagnose Multiagent Plans

assumptions induce on variables in ENV i an implicit constraint: at each execution step
only one agent i knows the actual state of a given resource resk . As a consequence, only the
private copy resik keeps the correct value. For all the other agents, resource resk is out of
sight; this is modeled by assigning the value unknown to their local variables about resk ;
namely, for each j 6= i, resjk =unknown. Thus the consistency among the different private
copies is implicitly maintained.
Of course, when agent j acquires resource resk from agent i, it also comes to know the
actual state of that resource. The values of variables in ENV i can in fact be exchanged
among the agents. In Section 2.3 we present a basic cooperative protocol that enables the
agents to share their knowledge about the resources while preserving the resource safeness
requirement; such a basic protocol will be later extended in Section 4.5. Variables in END i ,
on the other hand, refer to agent i, and in our framework cannot be shared with other
agents.
2.2.2 Mapping Services to Variables Assignments
Since we adopt a representation based on state variables, also a service exchanged between
two agents is conveniently modeled as a value assignment to a resource variable. For instance, the causal link lk : hai , available(resk ), aj i is used in the propositional representation
to model that action ai  Ai provides action aj  Aj with resource resk . The same link can
be rewritten in the state variables representation as hai , resk = available, aj i, where resk
is the name with which agents i and j refer to a specific resource in RES . In other words,
resk is a sort of meta-variable that is known both by agent i and agent j. Of course, each
agent maps the meta-variable resk into its own private copy. More precisely, by means of
the link hai , resk = available, aj i, agent i is able to communicate j a change in the state of
resource resk : agent j knows that, after the execution of ai , its private variable resjk has the
value available, meaning that j can now use resk . It is worth noting that available is just
a special value, used by agents for exchanging resources. In general, agents communicate
each other domain-dependent values about the state of a resource (e.g., the position of a
block in the blocks world domain).
Relying on the state variables representation, we can identify the set of resources
available to a given agent i at the l-th plan execution step as availResi (l) = {resk 
RES |Sli (resik ) = available}. In the next subsection we focus on a coordination protocol
that allows agents i and j to exchange information about the shared resources.
2.2.3 Mapping Propositional Action Models to Function-Like Models
Let Q be a subset of the state variables VARi , in the rest of the paper we denote with (Q)
the space of possible assignments to the variables in Q, and with Q we denote a specific
assignment in (Q); that is, a specific partial state for agent i. In the rest of the paper
we use premises(ali ) and effects(ail ) to denote the subset of status variables in VARi over
which preconditions and effects, respectively, of action ail are defined. Thus premises(ail )
represents a specific assignment of values in the space (premises(ail )). Note that the set
of premises includes also those services that must be provided by other agents, and which
therefore correspond to incoming causal links for action ail . Similarly, the set of effects
9

fiMicalizio & Torasso

includes also those services that agent i provides other agents with, encoded as causal links
outgoing from ail .
Given an action instance ail  Ai , the deterministic (nominal) model of ail is a mapping:
: premises(ail )  effects(ail )
fanom
i
l

where premises(ail ) is an assignment of variables in premises(ail )  VAR i representing
the preconditions of ail , and effects(ail ) is an assignment of variables in effects(ail )  VARi
modeling the effects of the action. We also assume that effects(ail )  premises(ail ); this
is not a substantial limitation, however. Any variable v, that in principle would only be
mentioned in the effects of an action model, can also be mentioned in the premises of
the action by allowing v to assume any possible value of its domain. The reason for this
assumption will be clear in Section 3.2 where we formalize the notion of exogenous events.
Since we are interested in the execution of plans, we reformulate the applicability of
an action to a state (see Nebel, 2000) in terms of executability. Given an agent state Sli ,
an action instance ail  Ai is executable in Sli  (VARi ) iff Sli |= premises(ail ); indeed,
this strong condition will be relaxed in the next section. Using the same terminology by
Roos and Witteveen (2009), we can say that action ail is executable in Sli only if ail is fully
i
in
enabled in Sli . The result of the execution of ail enabled in Sli is the new agent state Sl+1
i
(VAR ), called successor state:


(Sli \ effects(ail ))  effects(ail ) if Sli |= premises(ail ) and




Sli 6|=  and effects(ail ) 6|= ,
i
Sl+1
=




,
otherwise.

More precisely, Sli \ effects(ail ) is a partial agent state obtained by removing from Sli
all variables mentioned in effects(ail ). Such a partial state is subsequently completed with
i . This state
the new assignments in effects(ail ), yielding a new (complete) agent state Sl+1
transformation, however, is legal only when: (1) action ail is fully enabled in Sli (i.e., Sli 6|= 
and Sli |= premises(ail )), and (2) the action effects are consistent (i.e., effects(ail ) 6|= ).
Otherwise, the new agent state is undefined.

2.3 Plan Execution Under Nominal Conditions
The actual execution of a MAP requires some form of coordination among the agents.
The decomposition of the global plan into local plans, in fact, allows the agents to execute their actions in a fully distributed way without the intervention of a global manager:
agents execute actions concurrently and asynchronously (i.e., no global clock is required).
In addition, differently from previous approaches (see e.g., de Jonge et al., 2009; Micalizio
& Torasso, 2008), where actions just take a single time slot to be completed and their execution is globally synchronized, we do not make any assumption on the duration of each
action. Agent coordination is therefore essential in order not to violate the precedence and
causal constraints introduced during the planning phase. For the sake of clarity, we first
present a basic coordination strategy by assuming that:
10

fiCooperative Monitoring to Diagnose Multiagent Plans

i
i
i
BaDE(P i =hI i , Gi , Ai , E i , Clocal
, Cin
, Cout
i)
1. l  1
2. Sli  I i
3. while ail 6= ai do
4.
Sli  consume-inter-agent-messages(inbox)
5.
if ail is executable in Sli then
6.
execute ail
i
7.
Sl+1
 fanom
(Sli )
i
l

8.
obsil+1  gather observations
i
9.
if Sl+1
 obsil+1 |=  then
10.
stop execution and propagate failure
11.
end if
i
12.
for each causal link lk  Cout
such that lk : hail , v = d, ajm i do
13.
notify agent j about the achievement of service v = d
14.
if v  RES and d = available then
i
15.
Sl+1
(v)  unknown
16.
end if
17.
end for
18.
l l+1
19.
end if
20. end while

Figure 1: Basic Distributed Plan Execution (BaDE) strategy.
- action-based observability: even though the agents do not have a complete view of the
environment, each agent is always able to observe the preconditions and the effects of
the actions it performs. In addition, observations are assumed reliable and correct.
We denote as obsil+1 the set of observations received by agent i at the l-th plus 1
execution step after the execution of the l-th action. The observations obsil+1 can be
thought of as sets of value assignments to the variables in effects(ail ). That is, for each
variable v  effects(ail ), an assignment v = d belongs to obsil+1 ; where d  dom(v);
- deterministic actions: actions can never fail and their models precisely define how the
agent state changes;
- static environment: the environment can change only as a consequence of the execution
of the agents actions.
These three strong assumptions will be relaxed in Section 3, where we will present a more
complex coordination strategy that guarantees a consistent access to the resources even
when actions can fail.
2.3.1 Basic Coordination Protocol
The coordination protocol we adopt is very simple but effective, and exploits the causal links
i models, in fact, the exchange of a service/resource between
in P i . Each outgoing link in Cout
agent i - the service provider - and another agent j - the service client. In order to support
the communication among the agents, we assume that each agent has an inbox, i.e., a folder
where messages coming from the other agents are stored. Whenever i executes an action
i , i sends a message for each outgoing link of ai notifying
ail having outgoing links in Cout
l
i
the receiver that the needed service/resource is now available. Likewise, each link in Cin
11

fiMicalizio & Torasso

models the exchange of a service/resource in which i is the receiver and another agent j is
i , it waits for a
the provider. Whenever i has to execute an action having incoming links in Cin
message for each of these links since the action becomes executable only when all the required
services/resources are provided. Under the assumptions made about the MAP P , this
protocol guarantees that resources are always accessed consistently. In fact, by assumption
P satisfies the resource safeness requirement, which assures that working sessions over the
same resource are totally serialized; in particular, two working sessions wshres,ii /ws0hres,ji are
serialized by means of a causal link hclosing(wshres,ii ), res = available, opening(ws0hres,ji )i.
Therefore, when wshres,ii closes, agent i notifies agent j that resource res is now available.
2.4 Basic Distributed Plan Execution (BaDE) Strategy
The high-level plan execution strategy performed by each agent i in the team is outlined
in Figure 1. The strategy consists of a loop that iterates as long as there are actions in
P i to be executed. The first step in the loop is to acquire new information from other
agents about the shared resources. To accomplish this task, agent i plays the role of client
of our coordination protocol and gathers all the notification messages, if any, sent by other
agents; these notification messages (i.e., the value assignments they convey) are asserted
within the current agent state Sli so that i updates its local view about the system status
and acquires (if available) new resources. After this step, the next action ail is selected: if
ail is not executable yet, agent i keeps waiting for further notification messages (i.e., some
services/resources are still missing). Otherwise, the agent executes ail in the real world, and
i
. (Note that
by exploiting the nominal model fanom
then estimates the successor state Sl+1
i
l

the actual execution of ail in the real world may take some time which is not necessarily
known in advance.)
Once the action ail has been completed, the agent gathers observations about the efi .
fects of the action and matches these observations with the estimated successor state Sl+1
Since we are assuming that actions cannot fail, no discrepancy between observations and
estimations can be discovered. We include the control in line 9 for compatibility with the
extension described in sections 3 and 4, where actions may fail.
After the execution of ail , agent i plays the role of provider in our coordination protocol
and propagates the (positive) effects of action ail towards other agents by sending a notificai (see lines 13 through 16 of the algorithm in
tion message for each outgoing link of ail in Cout
Figure 1). In particular, in case agent i has just released a resource (v  RES), the agent
sets its private copy about that resource to unknown, in this way the resource becomes
unreachable to i and the mutual exclusive access is guaranteed.
The last remark about the basic strategy regards the increment of counter l. Note that
l is only incremented when an action is executed; thus l does not correspond to a metric
time, but it is a pointer to the next action to be performed. Adhering to the BaDE strategy,
an agent can conclude its own local plan within a finite amount of time.
Proposition 2 Let S = hT , RES, P i be a MAP system such that P is flaw-free and satisfies
the resource safeness requirement. If all agents in T follow the BaDE strategy in Figure 1,
then P is successfully completed in a finite amount of time.
12

fiCooperative Monitoring to Diagnose Multiagent Plans

Proof: It is sufficient to show that at least one action of P is always in execution, at
each step, until the achievement of the goal. By contradiction, let us assume that the goal
has not been reached, and no action is in progress. Since we assume here that no failure
can occur, this situation can happen when agents are in deadlock, waiting for services no
one will provide them with. A deadlock may arise either because of an erroneous planning
phase, but then P is not flaw-free as initially assumed, or because the BaDE coordination
strategy is erroneous. Let us show that when all agents adopt the BaDE strategy, and no
failure occurs, the agents never wait indefinitely for accessing a resource. Since P satisfies
by assumption the resource safeness requirement, it must hold that wshres,ji / wshres,ii ; i.e.,
closing(wshres,ji ) provides opening(wshres,ii ) (i.e., ail ) with service res = available. Agent
i waits for service res = available only in two situations: (1) agent j has not performed
action closing(wshres,ji ) yet (correct behavior), or (2) agent j has already performed action
closing(wshres,ji ), but has not sent the appropriate message to i. This second case contradicts the hypotheses that the agents adopt the BaDE coordination protocol. In fact, as
required by the protocol, whenever a working session wshres,ji closes, agent j has to send a
message to the next agent accessing that resource.
Therefore, if agents are never in deadlock, at least one action is always in execution, and
since P has a finite number of actions, the goal G must be achieved within a finite amount
of time.

Example 1. We conclude the section by briefly exemplifying the concepts introduced so
far. In particular, we present here the office-like domain we used as a test scenario for our
experiments (Section 6), this domain is similar to the ones adopted by Micalizio (2013)
and Steinbauer and Wotawa (2008). In this domain, robotic agents deliver parcels to the
desks of a number of clerks. A robot can carry one or two parcels depending on whether
they are heavy or light, respectively. Figure 2 shows the office-like environment we used for
our tests; it includes: 9 desks, distributed over 5 office-rooms, which are connected to each
other by means of 8 doors. Moreover, two repositories contain 12 parcels to be delivered
(8 light and 4 heavy). Parcels, repositories, doors, and desks are all critical resources as
they can be used and accessed by only one agent per time. The domain also includes three
parking areas, these are locations where more agents can be positioned simultaneously as
they are not critical resources. (The term location is used to identify either parking areas
or resources where agent can be physically positioned; e.g., parcels are not locations.)
Agents can perform the following actions: move from a location to another, load/unload
parcels within resources which are locations (i.e., not in parking areas), in addition, we
impose that no more than one parcel can be positioned on a desk, while repositories have
unlimited capacity. Finally, agents can carry one heavy parcel or two light parcels from a
location to another.
Figure 3 shows a simple example of MAP in our office domain. The team involves three
agents A1, A2, and A3, whose plans are in given in three columns, respectively. At the
bottom of the picture the effects of pseudoaction a0 represent the initial states of the three
agents. At the top of the picture, the premises of pseudoaction a represent the desired
final state. The objective of the MAP in the figure is to deliver parcel1 to desk3 (i.e., an
agent has to unload parcel1 when positioned in desk3), and then to bring the parcel back to
its initial position in repository repos1. Similarly, parcel2 has first to be delivered to desk6,
13

fiMicalizio & Torasso

Figure 2: The office-like environment used for the experiments: five rooms R1-R5, two
repositories: repos1 and repos2, eight doors, nine desks, and three parking areas.

and brought back to repository repos2; while parcel3, that has already been delivered to
desk3, has to be delivered to desk4. To ease the readability of the picture, we only show the
inter-agent causal links. We use two different graphical notations to distinguish between
causal links giving access to resources (diamond-headed), and the causal links that model
other kinds of services (black-circle-headed). For instance, the link between actions a13 and
a24 is diamond-headed, this means that action a13 provides a24 with service desk3 = available
(i.e., after a13 , agent A1 has no longer access to desk3). The three dashed rectangles in the
picture represent the working sessions associated with resource desk3, which is used by the
three agents at different execution steps. (The working sessions for the other resources have
not been highlighted to avoid the picture becoming too confused.)
Black-circle-headed links are used to represent all the other services. For instance, the
1 encodes the service desk3.content=empty,
link between actions a12 and a25 (labeled as )
required by action a25 since at most one parcel can be located on a desktop. The link labeled
2 (from a25 to a37 ) encodes two services: desk3.content=parcel1 and parcel1.pos=desk3.
as 
3 but they refer to desk6 and parcel2.
Similar services are encoded by link ,


3. Extending the Framework
In the previous section we have described a simple coordination strategy that guarantees
the consistent execution of a MAP P when three strong assumptions hold: (1) each agent
has an action-based observability: it can precisely observe the preconditions and the effects
of the actions it performs; (2) the environment is static (no exogenous events are permitted);
and (3) the actions are deterministic (no deviation from the nominal behavior is possible).
Henceforth we extend the basic framework by relaxing these three assumptions and, as a
consequence, by increasing the complexity of the strategy for controlling the distributed
plan execution.
14

fiCooperative Monitoring to Diagnose Multiagent Plans

parcel1.pos=repos1
parcel1.delivered=desk6
A3.pos=P1

a
parcel3.pos=desk4
parecel3.delivered=desk4
A1.pos=P2

parcel2.pos=repos2
parcel2.delivered=desk3
A2.pos=P3

a212

move(repos2, P3)

a211

a311

unload(repos2, parcel2)

a210

a17

move(repos1, P1)

repos2

a310

carry(desk6, repos2)

move(door2, P2)

a29

a16

unload(repos1, parcel1)
repos1

3


a39

load(desk6, parcel2)

move(desk4, door2)

carry(door1, repos1)

desk6

a28

a15

a38

move(door4, desk6)

unload(desk4, parcel3)

a27

a14

door4

move(P2, door4)

carry(door2, desk4)

1


a12

move(P2, desk3)

desk3

move(door4, desk3)

a35

unload(desk3, parcel1)

move(desk6. door4)

a24

a34

carry(door1, desk3)

unload(desk6, parcel2)

a23

a33

carry(repos1, door1)

A1.pos=P2
desk3=avail
desk4=avail
parcel3.pos=desk3
parcel3.delivered=desk3
door2=avail

load(desk3, parcel1)

a25

load(desk3, parcel3)
desk3

a37
a36

move(desk3, P2)

a11

parcel1

a26

a13
carry(desk3, door2)

carry(desk3, door1)

2


carry(repos2, desk6)

a22

a32

load(repos1, parcel1)

load(repos2, parcel2)

a21

a31

move(P1, repos1)

move(P3, repos2)

A2.pos=P1
repos1=avail
parcel1.pos=repos1
parcel1.delivered=no
door1=avail

A3.pos=P3
repos2=avail
parcel2.pos=repos2
parcel2.delivered=no
desk6=avail
door4=avail

a0

Figure 3: A simple example of MAP in the office-like domain used for testing.

15

fiMicalizio & Torasso

3.1 Partial Observability
The first assumption we relax is the action-based observability. In the basic framework,
the observations obsil+1 agent i receives at the (l + 1)-th step of execution cover all the
variables in effects(ail ). In the extended framework, obsil+1 becomes just partial since only a
subset of variables in effects(ail ) is covered in general, and possibly obsil can even be empty.
Also in this case we assume that the observations are correct, meaning that the actual
state of an agent cannot be inconsistent with the observations received by the agent itself.
However, observations can be ambiguous in the sense that for a given variable, an agent
just receives a disjunction of possible values. In addition, to guarantee the termination of
the plan execution phase, we assume that each agent observes at least the achievement of
the atoms in its local goal Gi  G.
3.2 Plan Threats
The second extension is about the dynamics of the system: we move from a static system
to a dynamic one. This means that, besides the changes due to the agents actions, the
system can also change as a consequence of exogenous, unpredictable events, which typically represent plan threats (Birnbaum, Collins, Freed, & Krulwich, 1990) for the nominal
execution of the plan. Intuitively, a plan threat can be seen as an abrupt change happened
in the environment (i.e., resources), or in the state of an agent.
In this paper we associate the occurrence of an exogenous event to the execution of
an action. In other words, an exogenous event can only occur during the execution of
an action and can only affect the active variables of that action; namely, the variables
mentioned within the premises and the effects of the action. Thus, an exogenous event
cannot affect simultaneously two or more actions, but it can have indirect effects on many
actions, even of different agents, by means of the shared resources.
In principle, given an exogenous event , one could define a model to predict how  will
affect the execution of an action. In real-world domains, however, it is not always possible
to precisely know in advance the actual impact of an exogenous event: on the one hand,
 may have non-deterministic effects; on the other hand, not all the effects of  may be
known. To take into account the possibly non-deterministic effects of exogenous events, we
model an exogenous event  as a relation happens  defined as follows:
happens  (affectedby  )  {}  (affectedby  )

(1)

where affectedby   VARi , and (affectedby  ) is the space of partial agent states defined
over affectedby  . It is worth noting that (affectedby  ) can only be empty when affectedby  is
empty, too. This enables us to state that, when an exogenous event occurs, then a variable in
affectedby  must necessarily evolve unexpectedly. Thus, each tuple in the relation happens 
represents a non-deterministic effect of ; namely, each tuple represents a possible abrupt
change in some agents status variables.
To deal with not known effects of an exogenous event , we extend the domain dom(v)
of each variable v  VARi with the special value unknown which leaves open any possible
evolution for v.
We denote as X the set of all exogenous events which might occur during the plan
execution. Note that X also includes a pseudo event  modeling the absence of abrupt
16

fiCooperative Monitoring to Diagnose Multiagent Plans

changes. Only for this special event it must hold that affectedby  = . Since an exogenous
event  is defined as a state transition over agents state variables,  can only affect an
action ail iff
affectedby   effects(ail ).
(2)
Namely,  affects a subset of the variables over which action ail is defined.
Given an action ail , X (ail ) denotes the subset of exogenous events in X which satisfy
relation (2). Note that, the pseudo event  is always included in X (ail ), for any action
ail  Ai , since affectedby  (i.e., the empty set) trivially satisfies relation (2).
3.3 Extended Action Models
The last extension we propose is about the action models. Since plan threats occur during
the execution of actions, their effects combine with the actions effects. To estimate how
the system evolves over time, it is essential to extend the nominal action model in order to
encode, in a single piece of knowledge, the nominal as well as the anomalous evolutions of an
action. Intuitively, such an extended model should describe how an agent state Sli evolves
i
when agent i has carried out an action instance ail , and when,
into a new agent state Sl+1
during the execution of the action, an exogenous event   X has occurred, possibly just .
Moreover, in the basic framework we give for granted that an action is performed when it is
fully enabled. In our extended framework this condition is not necessarily satisfied. Due to
the partial observability, in fact, agent i may be unable to precisely determine whether its
next action is fully enabled or not. To cope with this situation, we introduce in Section 3.4
the concept of possibly enabled action. For the time being, we just anticipate that an agent
may decide to perform an action even when that action is not fully enabled, and hence the
extended action model must be so rich to estimate how the state of agent evolves even in
such a situation.
, given
The extended model M(ail ) of action ail is derived from the nominal model fanom
i
l

in terms of premises and effects, and from the set of exogenous events X (ail ); it is formally
defined as:
, X (ail ), (ail ), (ail )i,
M(ail ) : hfanom
i
l

and X (ail ) have already been introduced; whereas (ail ) and (ail ) are two
where fanom
i
l

transition relations between partial states in (premises(a)) and in (effects(a)), through
which it is possible to predict how the execution of action ail changes the state of the
environment (i.e., the resources held by i) and of agent i itself.
Relation (ail ) estimates the next agents states when action ail is fully enabled in a
state Sli . This relation results from the combination of the nominal action model with the
models of the exogenous events in X (ail ):
(ail ) =

[

fi happens  }
{fanom
i
l

X (ail )

(3)

Intuitively, fanom
fi happens  is a set of tuples of the form hpre, , eff i, where pre equals
i
l

premises(ail ), and eff  (effects(ail )) models the abrupt changes caused by event  to the
17

fiMicalizio & Torasso

nominal effects of action ail . Formally, for each happening h, ,  0 i in happens  it holds:


premises(ail )  {}  {(effects(ail ) \ affectedby )   0 }




[
if Sli |= premises(ail ) and premises(ail ) |= ;
fanom
fihappens  =
i
l


h,,0 ihappens  

 otherwise.

(4)
It is important to note that, since  is always part of X (ail ), the nominal model hpremises(ail ),
, effects(ail )i is always included in (ail ). In particular, in such a state transition, no variable can assume value unknown. This follows directly by: (1) the nominal model fanom
i
l

cannot mention the unknown value by definition, and (2) the exogenous event  cannot
fi happens  just
affect any variable since affectedby  is empty. Thus, the operation fanom
i
l
reproduces the nominal behavior.
In addition, note that X (ail ) can also include a special exogenous event ? . This symbol
denotes an indefinite exogenous event for which no model is given, and hence all variables
in effects(ail ) are mapped to unknown: after the occurrence of ? no prediction is possible.
Relation (ail ) has the same structure as (ail ) in terms of preconditions, effects and
exogenous events, but represents a dual version of (ail ) since it is defined when ail is not
executable in Sli . In fact, (ail ) is defined in all those states where action ail is not enabled.
Let (premises(ail )) be the space of assignments of values to the variables in premises(ail ),
(ail ) is defined over the space of states (premises(ail ))=(premises(ail )) \ premises(ail )
as:
(ail )  (premises(ail ))  {? }  hunknown, . . . , unknowni,
(5)
where ? denotes an indefinite exogenous event as in . Note that (ail ) is a weaker model
than (ail ) since it invariably assigns the unknown value to each variable in effects(ail ).
That is to say, whenever an action is performed in a wrong configuration, its impact on the
effects(ail ) variables becomes unpredictable. Although we use the same symbol ? to denote
indefinite events occurring in (ail ) and in , they have slightly different meanings from a
diagnostic point of view that will be discussed in detail in Section 5.
Remark 1. The relational action models we propose are sufficiently flexible to deal with
incomplete or imprecise knowledge. In many cases, in fact, it may be too costly (or even
impossible) to determine how exogenous events impact the variables in effects(ali ). The
extended framework copes with this problem by allowing three forms of incompleteness:
- The unknown value included in the domain of each variable allows to represent that, as
an effect of an exogenous event, the value of a variable becomes no more predictable.
In the extreme case, all the variables in the effects of an action are set to unknown
(see the weak model for the exogenous event ? ).
- Non-deterministic action evolutions can be defined: an exogenous event may have
non-deterministic effects on the states of the agents.
- The weak relation  allows us to model the status of an agent after the execution of
an action under wrong conditions.
18

fiCooperative Monitoring to Diagnose Multiagent Plans

Remark 2. Since actions can be performed even though they are not fully enabled, how
can we guarantee that the execution of the plan does not violate the resource safeness
requirement? The answer to this question is in the coordination protocol which is part of
the Cooperative Weak-Committed Monitoring (CWCM) strategy discussed in Section 4. It
is useful to anticipate, however, that the coordination protocol guarantees that an agent
uses a resource only when its actions do not violate the resource safeness requirement.
Example 2. Let us consider a simple example from the office domain, and assume that
agent A1 is in charge of performing action carry(A1, Parc2, desk1, desk2); such an
action requires A1 to move from its current position desk1 to position desk2 while it is
loaded with parcel Parc2. The nominal model for such an action can be expressed as the
state transition:
hpos = desk1, cObj=Parc2, Parc2pos1=A1, , pos = desk2, cObj=Parc2, Parc2pos1=A1i;
where pos and cObj are two endogenous variables for A1 representing the current position
of the agent and the carried object, respectively. The state of shared resource Parc2 is
encoded by variable Parc2pos1, which is the private variable agent A1 keeps to maintain
the position of parcel Parc2. For all the other agents, the local copy of variable Parc2pos
is unknown.
The actual execution of the carry action can be affected by a number of exogenous
events; for instance, wheelsblocked prevents the agent from moving at all, while wrongstep
allows the agent to move, but in a wrong direction. Another event that can affect the
carry action is lostparcel : while the agent is moving, the carried object(s) is lost; finally,
? denotes an unpredictable event occurring when the carry action is attempted in a state
in which its preconditions are not satisfied. All these alternative situations are summarized
within the extended model showed in Table 1. The first entry of the table is the nominal
state transition, the only one labeled with . Entries from 2 to 5 describe how the action
behaves when some known exogenous event occurs. Note that, although the exogenous
event is one of the foreseen possibilities, not all its effects may be precisely known; for
instance, as an effect of wrongstep and lostparcel some of the variables assume the value
unknown. The first five entries of the table represent the  relation of the extended model.
The last entry of the table, instead, is the  relation which allows us to make just weak
predictions. The tuple hpos=*, cObj=*, Parc2-place=*i is just a shortcut to represent any
possible assignment in which the preconditions are not satisfied. Note that, from a practical
point of view, it is not necessary to compute this (potentially huge) set explicitly, as we
discuss in Appendix A about the implementation.

3.4 Extending Some Basic Concepts
Since we have relaxed the three assumptions of the basic framework, we have to review
three important concepts: the state of an agent, the executability of an action, and the
outcome of an action.
19

fiMicalizio & Torasso

END

t1
t2
t3
t4
t5
t6

ENV

END

ENV

pos

cObj

Parc2pos1

event

pos

cObj

Parc2pos1

desk1
desk1
desk1
desk1
desk1
*

Parc2
Parc2
Parc2
Parc2
Parc2
*

A1
A1
A1
A1
A1
*



desk2
desk1
unknown
desk2
desk2
unknown

Parc2
Parc2
Parc2
empty
empty
unknown

A1
A1
A1
desk1
unknown
unknown

wheelblocked
wrongstep
lostparcel
lostparcel
?

Table 1: The extended model for the action instance carry(A1, B2, desk1, desk2) from
the office domain.

3.4.1 Agents Belief States
First of all, each agent in the team must be able to deal with some form of uncertainty.
Since actions may evolve non-deterministically and since the agent cannot observe all the
effects of its actions, an agent must be able to deal with belief states rather than with agent
states. Like an agent state Sli , an agent belief state Bli encodes the knowledge agent i has
about itself at the l-th execution step. While Sli is the precise state assumed by i at step
l, Bli is a set of possible agent states consistent with the observations received by i. In the
rest of the paper we use lowercase s to indicate an agent state among others within a given
belief state, while we use uppercase S to indicate the actual agent state at a given execution
step. It is important to note that, exactly as an agent state Sli , a belief state Bli is defined
over all the state variables of agent i; but two states s1 and s2 in Bli differ for at least one
variable. In other words, there must exists at least one variable v  VARil such that s1 (v),
the value assumed by v in s1 , is different from s2 (v). Of course, this ambiguity represents
an issue in understanding whether the next action ail is executable.
3.4.2 Possibly Enabled Actions
Since we have an agent belief state Bli , also the notion of action executability needs to be
revised. A very conservative policy would require action ail to be fully enabled in every
state s in Bli ; but due to the partial observability this condition might not be satisfied, so
the execution of a MAP could be stopped because no action is enabled even though no plan
threat has occurred.
To avoid this situation, we propose a more optimistic policy and introduce the notion
of possibly enabled action.
Definition 2 Optimistic Policy Action ail is possibly enabled in Bli iff s  Bli such that
ail is fully enabled in s; namely, s |= premises(ail ).
It is worth noting that the value unknown cannot be used to qualify an action as fully
enabled. Such a value, in fact, is used explicitly to state that the agent does not know the
value of a variable. Therefore, if variable v has value unknown in a state s, and v is also
mentioned in premises(ail ), then ail is not fully enabled in s.
A possibly enabled action is therefore a sort of conjecture: since the action premises
are satisfied in at least one state of the belief state, the action is assumed executable. Of
20

fiCooperative Monitoring to Diagnose Multiagent Plans

course, it may be the case that s, although possible, is not the real state of the agent, and
hence the action is performed when its preconditions are not satisfied in the real world.
3.4.3 Action Outcome
In the basic framework we have given for granted that the outcome of an action is always
nominal. In the extended framework, however, actions can fail. We individuate three possible action outcomes: the nominal ok, the anomalous failed, and pending for the intermediate
situations.
i , s |= effects(ai ).
Definition 3 Action ail has outcome ok iff s  Bl+1
l
i
(estimated after the execution of ail ).
That is, the actions effects hold in every state in Bl+1
i
Definition 3 does not hold when there exists at least one state s  Bl+1
where the nominal
effects are not satisfied. In some previous approaches (Micalizio & Torasso, 2008, 2007a),
we have introduced and adopted the strong committed policy: when the effects of action ail
i , the action has outcome failed (see
are not satisfied in each state of the belief state Bl+1
Definition 3). The strong committed policy is based on the assumption that, whenever action
ail has been successfully completed, agent i receives an amount of observations sufficient to
detect the success. Thereby, when the success cannot be detected, a failure must have
occurred.
This policy, however, may be unacceptable in some real-world domains where there are
no guarantees about the system observability. As a consequence, agent i could infer a failure
even when action ail has been completed with success, but the observations are not sufficient
to confirm it.
In this paper we define the failure of an action as the dual case of the success:
i , s 6|= effects(ai ).
Definition 4 Action ail has outcome failed iff s  Bl+1
l
i
a state s in which all the expected effects of ail
Namely, it is not possible to find in Bl+1
have been achieved.
In all those situations where neither the success (Definition 3) nor the failure (Definition
4) can be inferred, the action outcome is pending.
i , s |= effects(ai ) and s0  B i ,
Definition 5 Action ail has outcome pending iff s  Bl+1
l+1
l
0
i
s 6|= effects(al ).

In other words, whenever agent i is unable to determine the success or the failure of
action ail , it postpones the evaluation of the action outcome to some step in the future; the
action is enqueued into a list pActsi of pending actions maintained by agent i. We refer
to this policy as weak committed since the agent does not take decisions whenever there
are insufficient observations sufficient to support them. In the next section we discuss the
impact of the weak committed policy on the monitoring task.

4. Cooperative Weak-Committed Monitoring
In this section we discuss a fully distributed approach to the problem of monitoring the
execution of a MAP. We consider the extended framework previously discussed which introduces two sources of ambiguity: the agent belief states, and the ambiguous action outcomes.
21

fiMicalizio & Torasso

To cope with these forms of uncertainty, we propose a monitoring methodology called
Cooperative Weak-Committed Monitoring (CWCM), which relies on the weak-committed
policy. The CWCM approach allows an agent to detect the outcome of an action some
time after its execution. The idea is that the possibly uncertain knowledge an agent has
about the environment and itself can be refined over time by exploiting observations that
the agent will receive in the future. To get this result, CWCM allows the team members to
cooperate with each other during their monitoring tasks.
The rest of this section is organized as follows. We first formalize the notion of trajectoryset maintained by each agent, and explain how the extended action models can be used
to extend the trajectory-set one step further. Then we discuss how the trajectory-set
is refined through the observations and how this helps in determining the outcomes of
pending actions (if any). Finally, we redefine the cooperative protocol sketched in the basic
framework to obtain a cooperative monitoring protocol. CWCM is entirely formalized in
terms of Relational Algebra operators. (For a short introduction to the used operators, see
Micalizio, 2013.)
4.1 Trajectory-Set
The weak-committed approach requires that an agent be able to reason about its past.
This means that the agent cannot maintain just the last belief state, but it has to keep a
trajectory-set; i.e., a sequence of belief states that traces the recent history of the agents
state.
We define a trajectory-set as a generalization of an agent trajectory. An agent trajectory
for agent i, denoted as tr i (1, l), is defined over a segment [ai1 , . . . , ail1 ] of the local plan P i ,
and consists of an ordered sequence of agent states interleaved with exogenous events in X
(including ). An agent trajectory represents a possible evolution of the status of agent i,
consistent with the observations the agent has received so far; more formally:
Definition 6 The agent trajectory tr i (1, l) over the plan segment [ai1 , . . . , ail1 ] is
tr i (1, l)=hs1 , e1 , s2 , . . . , el1 , sl i
where:
- sk (k : 1..l) is the state of agent i at the k-th step such that obsik  sk 6|= .
- eh (h : 1..l  1) is an event in X (ah ) labeling the state transition from sh to sh+1 .
An agent trajectory is therefore a sequence of agent states, interleaved by events, that traces
the agent behavior along a given plan segment. For the sake of discussion, we consider the
plan segment as starting from the first performed action ai1 ; in practice, however, the plan
segment under consideration can be an intermediate portion of an agents local plan. We
will return on this point in Section 4.6.
Since each state sk (k in [1..l]) is a complete assignment of values to the agent state
variables in VARi , these variables are duplicated as many times as there are actions in the
plan segment under consideration; in the following, we will denote as VARik the copies of
the state variables referring to the k-th execution step.
As noticed above, however, the partial system observability is in general not sufficient for
the estimation of a unique trajectory; for this reason agent i keeps a trajectory-set T r i [1..l],
22

fiCooperative Monitoring to Diagnose Multiagent Plans

which contains all possible agent trajectories tr i (1, l) consistent with the observations received during the execution of the plan segment [ai1 , . . . , ail1 ].
Note that, given a trajectory-set T r i [1, l], the agent belief state at any execution step k
in [1..l] can easily be inferred by projecting T r i [1..l] over the state variables VARik :
Bki = projectVARi (T r i [1..l])
k

(6)

Thus definitions 2 (possibly enabled actions), 3 (successfully completed actions), 4 (failed
actions), and 5 (pending action), which are all based on belief states, are still meaningful
and do not require to be redefined.
In the rest of the paper, the term trajectory frontier (or simply frontier) refers to the
last belief state maintained within a trajectory-set. For instance, the frontier of T r i [1, l] is
the belief state Bli . As a general rule, we use l to denote the index of the last execution step
(and hence of the frontier); while k is used to refer to a generic execution step in [1, l].
4.2 Extending the Trajectory-Set
The extension of a trajectory-set corresponds to the predictive step of the basic framework
through which the next agent state is estimated. However, while in the basic framework this
step was as easy as a mapping from a state to another, we need a more complex procedure
in our extended framework. Given the current trajectory-set T r i [1, l] and the extended
model M(ail ), the estimation step is defined in Relational terms as follows:
T r i [1, l + 1] = T r i [1, l]  M(ail ) = T r i [1, l] join ((ail )  (ail )).

(7)

The new trajectory-set T r i [1, l + 1] is built with the contribution of both  and 
relations. Both relations are in fact used to estimate how the execution of action ail changes
the state of the system. Relation  is applied to that portion of Bli where action ail is fully
enabled. Whereas, relation  is applied to all those states in Bli where action ail is not
enabled; i.e., the occurrence of an exogenous event has already been assumed.
4.3 Refining the Trajectory-Set with Observations
In the basic framework we have assumed that, whenever action ail is completed, the agent
i . In the extended framework,
receives observation obsil+1 just about the new agent state Sl+1
agent i can also receive observation obsik referring to a past execution step k (i.e., 1  k  l).
In the next section we present the cooperative monitoring protocol that is at the basis of
such a message passing among the agents. In this section we discuss how an observation
about the past is handled by a given agent i. Intuitively, consuming observation obsik means
selecting from Bki all the states that are consistent with it; in Relational terms:
refined Bki = selectobsi Bki
k

(8)

The result is a refined belief state which is less ambiguous than the original one as a number
of states inconsistent with the observations have been pruned off.
It is important to note that the unknown value is consistent with any concrete observed
value. Therefore, for each state s  Bki , if a variable v is unknown in s, but v is mentioned
in obsik , then v assumes the observed value obsik (v) in refined Bki . Note that we do not allow
an observed variable in obsik to assume the value unknown.
23

fiMicalizio & Torasso

BlA1
s1l



s1l+1
wheelblocked
wrongstep

s2l

A1
Bl+1

s2l+1
s3l+1

lostparcel
lostparcel
?

s4l+1
s5l+1
s6l+1

Figure 4: A one-step trajectory-set corresponding to the transition from step l to step l + 1.

Example 3. Let us consider again the office domain, and assume that after l steps, the
trajectory frontier of agent A1 consists of the following belief state BlA1 :
s1l : h pos = desk1, cObj = Parc2, Parc2pos1= A1 i
s2l : h pos = unknown , cObj = Parc2, Parc2pos1= A1 i
Namely, BlA1 consists of two alternative agent states s1l and s2l . Let us assume that
the next l-th action performed by A1 is a carry action, whose model has been previously
presented in Table 1. According to equation (7), it is easy to see that s1l matches with
state transitions t1 through t5 of the carry action model ( portion of the model), whereas
state s2l matches with transition t6 ( portion of the model). Figure 4 gives an idea of how
these two relations are used to infer the new frontier:
s1l+1 : h pos = desk2, cObj = Parc2, Parc2pos1 = A1 i
s2l+1 : h pos = desk1, cObj = Parc2, Parc2pos1 = A1 i
s3l+1 : h pos = unknown, cObj = Parc2, Parc2pos1= A1 i
s4l+1 : h pos = desk2, cObj = empty, Parc2pos1= desk1 i
s5l+1 : h pos = desk2, cObj = empty, Parc2pos1= unknown i
s6l+1 : h pos = unknown , cObj =unknown, Parc2pos1=unknown i
Now, let us assume that agent A1 receives the observation obsA1
l+1 = {hpos = desk2i},
which is used to refine the new frontier. It is easy to see that obsA1
l+1 is consistent with all
the states except s2l+1 , in which pos is assigned to a different value. States s3l+1 and s6l+1
are consistent with obsA1
l+1 because the unknown value is consistent with any precise value.
The new refined frontier is therefore
s1l+1 : h pos = desk2, cObj = Parc2, Parc2pos1 = A1 i
s3l+1 : h pos = desk2 , cObj = Parc2, Parc2pos1 = A1 i
24

fiCooperative Monitoring to Diagnose Multiagent Plans

s4l+1 : h pos = desk2, cObj = empty, Parc2pos1= desk1 i
s5l+1 : h pos = desk2, cObj = empty, Parc2pos1= unknown i
s6l+1 : h pos = desk2 , cObj =unknown, Parc2pos1=unknown i
It seems that s1l+1 and s3l+1 are now identical, indeed we do not just consider single
belief states, but trajectories; these two states differ in the way they are achieved: s1l+1 is
inferred assuming that everything goes smoothly; s3l+1 is inferred assuming that something
wrong has occurred (i.e., wrongstep ). Of course, this second hypothesis is not plausible
and we will discuss in the next section how it can be pruned off the trajectory-set.

This example shows how consuming a set of observations obsik reduces the ambiguity
within the agent belief state Bki . In addition, the consumption of messages has also a
beneficial effect in reducing the ambiguity of the trajectory-set T r i [1, l]. In fact, the refined
belief state can in turn be used to filter the trajectory-set as follows:
refined T r i [1, l] = selectrefinedBi T r i [1, l].
k

(9)

The refined T r i [1, l] maintains all and only the trajectories that at their k-th step have a
state in refined Bki . This is an important result since an agent can take advantage of the
observations whenever they are available, even though they refer to a past execution step.
It may happen, in fact, that even though obsik is not enough to determine the outcome
of action aik1 , another belief state Bhi  refined T r i [1, l] becomes sufficiently precise to
determine the outcome of the pending action aih1 . In the next section, we exploit this
characteristic to determine the outcomes of pending actions.
4.4 Inferring and Propagating Action Outcomes
Whenever the current trajectory-set is refined with observations, it is useful to scan the
pending action list pActsi , and assess, for each action aik  pActsi , whether either Definition
3 or 4 applies.
The outcome of an action is an important piece of information that we can exploit, as
well as observations, to refine the current trajectory-set. The outcome of action aik , either
positive or negative, can in fact be used to infer the outcome of other actions in pActsi .
To reach this result we exploit the notions of causal predecessors of aik (predecessors(aik )),
and of causal successors of aik (successors(aih )). First of all, we say that action aih indirectly
provides action aik with a service, or that aik indirectly receives a service from aih , iff there
exists a sequence of actions aiv1 , . . . , aivn such that:
1. aiv1 coincides with aih
2. aivn coincides with aik
i
.
3. for each action aivx , x : 1..n  1, there exists a causal link haivx , q, aivx+1 i in Clocal

In other words, there must exist a chain of causal links that starts from aih , passes
through the actions in the sequence aiv1 , . . . , aivn , and ends in aik . Indirect causal dependencies that pass through the plans of other agents are not considered by our definition.
For example, having the two causal links haih , q, ajv i and hajv , q 0 , aik i, we cannot say that aih
25

fiMicalizio & Torasso

indirectly provides aik with a service since action ajv belongs to agent j. This is not a limitation, but an advantage as otherwise the agents should interact heavily in order to compute
indirect causal relations. This notion of indirect dependency between actions is at the basis
of a locality principle that allows an agent to consider just a portion of its local plan during
monitoring and diagnosis.
The set predecessors (aik ) is therefore the subset of Ai including all and only the actions
that directly or indirectly provide aik with a service. On the other side, successors(aik ) is
the subset of Ai including all and only the actions which, directly or indirectly, receive a
service from aik .
i
Given an action aik , we denote as chains to(aik ) the subset of causal links in Clocal
defined
i
i
between actions in predecessors(ak ). Similarly, we denote as chains f rom(ak ) the subset
i
defined between actions in successors(aki ).
of causal links in Clocal
Proposition 3 Let aik be an action whose outcome is ok, then all the causal links in
chains to(aik ) represent services that have been satisfied.
In fact, if aik has outcome ok, then all the services required by aik were satisfied, and
recursively, all the services required by the actions in predecessors(aik ) were satisfied too.
Proposition 4 (Backward Propagation of Success) Let aik be an action whose outcome is ok, and let us mark as satisfied all causal links in chains to(aik ), then any action
a  pActsi  predecessors (aik ) having all outgoing links marked as satisfied, has outcome ok,
too.
Proposition 5 Let aik be an action whose outcome is failed, then the services in
chains f rom(aik ) might be missing.
In fact, since aik has outcome f ailed, at least one of its expected effects is missing; on the
other hand, action aik could have reached a subset of its effects, and such services could be
sufficient to enable some subsequent actions. The forward propagation of the failure must
therefore take into account the results successfully achieved. Let us denote as miss(aik ) the
set of causal links leaving from aik representing missing services.
Proposition 6 (Forward Propagation of Failure) Let aik be an action whose outcome
is failed, and let us mark as missing each causal link cl in chains f rom(aik ) that is reachable
from one of the links in miss(aik ) via a chain of missing causal links, unless cl has already
been marked as satisfied. Then, any action a  pActsi  successors(aik ), having at least one
outgoing link marked as missing, has outcome failed, too.
Intuitively, properties 4 and 6 assume that an action performed when it is not fully
enabled does not produce correct results. On the other hand, an action that achieves all
its effects must have been performed when it was fully enabled, and hence all the services
mentioned in its premises must have been provided.
26

fiCooperative Monitoring to Diagnose Multiagent Plans

a2

2

a3

1
...

7

a1

a6

8

4

a4

3

a5

a7

...

6

5
i
.
Figure 5: A portion of a local plan restricted to causal links in Clocal

Example 4. In this example we show how the outcome of an action a is actually exploited
to determine the outcomes of other actions. Of course, an agent is able to determine the
outcome of a relying on observations and messages from other agents. The cooperative
protocol is discussed in details in the following subsection; for the time being, it is important
to observe that:
 all the positive messages (formalized as confirm messages in the following) received
at a given step are processed before any negative message (i.e., disconfirm message)
received at the same step;
 an agent receiving at least one negative message will stop the execution of its plan,
and start a diagnostic phase.
i
are shown,
Let us consider the plan segment in Figure 5, where only the links in Clocal
and let us assume that agent i performs these actions in the order a1 , a2 , a3 , a4 , a5 , and a6 ,
and that all these actions are pending. After the execution of a5 , agent i discovers that a5 has
outcome ok. The outcome is propagated backwards: predecessors(a5 ) = {a1 , a4 }, thereby
the links in chains to(a5 ) = {4, 5} are marked as satisfied; of course, link 6 is also marked
satisfied because of the nominal outcome of a5 . This enables i to conclude that action a4 has
outcome ok; whereas nothing can be concluded about action a1 since links 1 and 7 are neither
marked as satisfied, nor as missing. Let us assume now that i receives some observations
about the service on link 1, and as a consequence it concludes that a1 has outcome failed.
In this case the outcome is propagated forwardly: successors(a1 ) = {a2 , a3 , a4 , a5 , a6 , a7 },
thereby chains f rom(a1 ) = {1, 2, 3, 4, 5, 6, 7, 8}; however, links 4, 5, and 6 have already
been marked as satisfied; in addition, links 7 and 8 are not reachable via chain of missing
causal links from link 1; thus, only links 2, and 3 are marked as missing. Agent i hence
concludes that actions a2 and a3 have both outcome f ailed. No outcome is inferred for
action a6 , which remains pending, and no outcome is inferred for action a7 that has not
been performed yet. The outcome of the pending action a6 is inferred by means of diagnosis
inferences discussed in Section 5.


Relying on properties 4 and 6, we can determine the outcome of other pending actions
by just exploiting the causal dependencies existing among the actions, even though the
current trajectory-set is still too ambiguous to apply either Definition 3 (outcome ok) or
Definition 4 (outcome failed).
27

fiMicalizio & Torasso

Note that when we discover that action aih has outcome ok, the exogenous event occurred
during that action is necessarily ; thus, we can also filter T r i [1, l] as follows:
refined T r i [1, l] = selecteh = T r i [1, l]

(10)

where eh refers to the h-th exogenous event labeling the transition from state sh to state
sh+1 in T r i [1, l]. Through the refinement in (10) we keep in T r i [1, l] all the trajectories
which at their h-th exogenous event have . Thus we keep the transitions that are obtained
through relation , and prune off spurious trajectories contributed by relation .
On the other hand, when the outcome of an action aih is f ailed, we cannot refine the
trajectory-set via eh since we just know that eh cannot be , but this is already implicitly
obtained thanks to the refinement in equation (9).
Summing up, our weak-committed methodology is able to deal with very scarce observations by using two essential mechanisms. First, we build a trajectory-set maintaining
the history of an agent state, and we keep a list of pending action outcomes. Second, we
take advantage from observations whenever they are available by revising the knowledge an
agent has about itself; in the very favorable case, this revision process can empty the set of
pending actions.
4.5 Cooperative Monitoring Protocol
The last element of our CWCM methodology is a cooperative monitoring protocol that
allows each agent to exploit information provided by others. The idea is that an agent can
take advantage not only of its own direct observations, but also of the observations that
other agents have about the environment, and in particular about the shared resources.
The cooperative protocol plays a central role in preserving the resource safeness requirement even when actions that are not fully enabled are performed.
4.5.1 Interaction Scenarios
As in the BaDE strategy, in CWCM two agents, i and j, need to interact with each other
when they share a causal link lk : hail , v = d, ajm i where v  RES, d  dom(v), and v = d is
a value assignment representing the change in the state of some resource requested by agent
i ); whereas,
j. Contextually to lk, agent i plays the service provider role (with lk  Cout
j
agent j plays the role of service client (with lk  Cin ). In the following we first present
the three interaction scenarios of CWCM. For each of them we shortly report the messages
exchanged between the two agents. Then, we present the client and provider roles in detail
by means of high-level algorithms.
 Notify-ready interaction In this interaction the provider is sure of having provided the
client with the requested service. Thus, the provider i sends a message habout lk notify
v = d readyi to the client j; no answer from the client to the provider is required.
 Notify-not-accomplished interaction In this scenario, agent i is sure that the requested
service is missing; it therefore sends agent j a message habout lk notify v = d notaccomplishedi to client j; no answer from j is foreseen.
 Ask-if interaction In this case, the provider i is unable to determine whether the
service v = d has been achieved; thus i asks j for more info by sending j a message
28

fiCooperative Monitoring to Diagnose Multiagent Plans

cooperative-protocol::client(inbox, T r i [1, l], ail )
1. for each message m: h about lk notify v = d ready i in inbox s.t. lk is an incoming link for ail do
2.
remove m from inbox
3.
assert v = d in the frontier of T r i [1, l]
4. end for
5. for each message m: h about lk ask-if v = d accomplished? i in inbox s.t. lk is an incoming link for ail
do
6.
remove m from inbox
7.
if unable to observe v then
8.
reply h about lk no-info i
9.
else
10.
obs  observe v
11.
if obs equals d then
12.
reply h about lk confirm v = d i
13.
else if obs is not equal d then
14.
reply h about lk disconfirm v = d i
15.
end if
16.
end if
17. end for
18. for each message m:habout lk notify v = d not-accomplishedi in inbox s.t. lk is an incoming message
for ail do
19.
remove m from inbox
20.
stop plan execution
21. end for

Figure 6: The pseudo-code of the cooperative protocol, client behavior.
habout lk ask-if v = d accomplished?i. The client can reply to this message in three
different ways:
1. habout lk confirm v = di, this message confirms to the provider that the expected
service v = d has actually been achieved;
2. habout lk disconfirm v = di when the expected service is missing;
3. habout lk no-infoi when the client is unable to determine whether the assignment
v = d holds in the environment or not.
In case i receives a no-info message from j, i will eventually reply either with a ready
message or with a not-accomplished one.
4.5.2 Client Role
The algorithm in Figure 6 outlines the behavior of agent i when behaving as a client. This
algorithm takes as inputs the inbox (i.e., a collector of messages coming from other agents),
the current trajectory-set T r i [1, l], and the next action to be performed ail .
Agent i consumes a message m from inbox only when m is about a service required as a
premise for the execution of ail . For each incoming message m of type ready (lines 1 through
4), agent i uses the information provided by another agent as an observation, we use the
term assert (line 3) as a shortcut for the relational operations presented in equations (8)
and (9).
For each incoming message of the ask-if interaction (lines 5 through 17), agent i determines whether it is capable of observing v (e.g., is i equipped with the right sensor for v?).
29

fiMicalizio & Torasso

In case i cannot observe v, it replies to the provider with a no-info message. Otherwise, the
agent acquires an observation of v, and replies to the provider accordingly.
Finally, whenever agent i receives a not-accomplished message (lines 18 through 21), i
just stops the execution of its plan as a service required for performing ail is missing.1
It is important to note that an agent playing as a client consumes a message m only
if m is relevant for the next action to be performed. Thereby, an ask-if message could be
answered with a certain amount of delay.
4.5.3 Provider Role
The provider behavior is outlined in Figure 7. The algorithm takes as inputs the inbox, the
current trajectory-set T r i [1, l], the list of pending actions pActsi , and the last performed
action ail . More precisely, the last argument can either be null, when no action has been
performed recently, or an actual action instance whose outcome has still to be assessed. We
refine the concept of recently performed action in the next section where we present the
main CWCM plan execution loop.
The algorithm starts by checking the inbox in order to consume answers (if any) to
previous ask-if interactions. The algorithm specifies the behavior of agent i according to
the type of received message. In case of confirm messages (lines 1 through 5), agent i uses
v = d as an observation to refine its trajectory-set. The term assert is used again as
a shortcut for the relational operations in equations (8) and (9); the belief state which is
actually refined is the k-th +1; that is, the one that contains the effects of action aik . In
case of a disconfirm message (lines 6 through 10), agent i prunes off from the k-th +1 belief
state in T r i [1, l] each state s in which v = d holds. In case of an incoming message of
type no-info (line 11 through 18), agent i checks whether all the outgoing links of action
i
have been marked as ans-no-info, meaning that none of the services provided
aik in Cout
i
by ak to other agents have been achieved for sure. If this is the case, agent i marks aik as
not-enough-info.
After these preliminary steps, agent i has possibly acquired some further information
from others. Thus, it can assess the outcome of all pending actions in pActsi , including ail if
not null (line 19). The algorithm in Figure 8 outlines the steps for assessing the outcomes of
actions in pActsi , and is discussed later on. Here it is sufficient to say that assess-pendingactions returns two lists of actions, ok-list and f ailed-list, which can be empty, and contain
actions whose outcome is ok or f ailed, respectively. Of course, whenever an action in pActsi
is found to be either ok or f ailed, it is removed from pActsi , and added in the corresponding
list. This process also involves actions previously marked as not-enough-info.
If action ail is not null (an action has been performed recently), this is the first time
that the outcome of ail is assessed. Thus, in case ail has outcome pending (line 20), agent
i starts an ask-if interaction (lines 21-24) by asking for further information to all agents
that requires one of the services produced by ail . Otherwise, ail is null or ail outcome is not
pending, and the ask-if interaction can be skipped.
From line 25 through line 34, agent i just sends ready and not-accomplished messages
according to the actions in ok-list and f ailed-list, respectively. In addition, agent i sends a
1. The impact of an action failure can be estimated by means of a failure propagation mechanism (Micalizio
& Torasso, 2007b). For the sake of discussion, we leave the topic out of this paper.

30

fiCooperative Monitoring to Diagnose Multiagent Plans

cooperative-protocol::provider(inbox, T r i [1, l], pActsi , ail )
1. for each message m:habout lk confirm v = di in inbox do
2.
remove m from inbox
3.
let lk be haik , v = d, ajm i
4.
assert v = d in the k-th +1 belief state within T r i [1, l]
5. end for
6. for each message m:habout lk disconfirm v = di in inbox do
7.
remove m from inbox
8.
let lk be haik , v = d, ajm i
9.
prune from the k-th +1 belief state within T r i [1, l] any state s in which v = d
10. end for
11. for each message m:habout lk no-infoi in inbox do
12.
remove m from inbox
13.
let lk be haik , v = d, ajm i
14.
mark lk as ans-no-info
15.
if all the links outgoing from aik are marked as ans-no-info then
16.
mark aik as not-enough-info
17.
end if
18. end for
19. hok-list, f ailed-listi  assess-pending-actions(pActsi , T r i [1, l])
20. if ail is not null and has outcome pending then
i
21.
for each link lk:hail , v = d, ajm i, lk  Cout
(i 6= j) do
22.
send to j message m:h ask-if v = d accomplished?i
23.
end for
24. end if
25. for each action aik  ok-list do
26.
for each link lk : haik , v = d, ajm i do
27.
send to j message m:habout lk notify v = d readyi
28.
end for
29. end for
30. for each action aik s.t. (aik  f ailed-list) or (aik  pActsi and marked as not-enough-info) do
31.
for each link lk : haik , v = d, ajm i do
32.
send to j message m:habout lk notify v = d not-accomplishedi
33.
end for
34. end for
35. return hok-list, f ailed-listi

Figure 7: The pseudo-code of the cooperative protocol, provider behavior.

not-accomplished message for each pending action aik marked as not-enough-info. A pending
action marked as not-enough-info highlights how scarcely observable the environment is.
In fact, neither agent i, nor other agents waiting for services provided by aik , are capable
of determine whether at least one of the expected services has been provided or not. To
deal with such an ambiguity, agent i prudentially considers the action as probably failed.
Although this choice could seem strong, it is necessary to preserve the resource safeness
requirement in very scarcely observable environments. Agent i has no evidence supporting
the successful achievement of the effects expected by ail , and hence i cannot notify the
success. At the same time, other agents might be waiting for the services provided by ail ,
thus these agents would be stalling without even knowing it. Considering ail as failed allows
i to get out of the impasse by notifying the failure to the other agents, which may attempt
some form of plan repair.
31

fiMicalizio & Torasso

assess-pending-actions(pActsi , T r i [1, l])
1. ok-list  {}
2. f ailed-list  {}
3. for each action aik  pActsi do
i
4.
if s  Bk+1
, s |= effects(aik ) then
5.
ok-list  ok-list  {aik }
6.
T r i [1, l]  selectek = T r i [1, l]
7.
oks propagateSuccess(pActsi , aik )
8.
ok-list  ok-list  oks
9.
pActsi  pActsi \ oks
i
10.
else if s  Bk+1
, s 6|= effects(aik ) then
11.
f ailed-list  f ailed-list  {aik }
12.
faultypropagateFailure(pActsi , aik )
13.
f ailed-list  f ailed-list  faulty
14.
pActsi  pActsi \ faulty
15.
end if
16. end for
17. remove, if present, mark not-enough-info from any action in ok-list or in f ailed-list
18. return hok-list, f ailed-listi

Figure 8: The pseudo-code for the assessment of the pending actions.
The algorithm terminates by returning the two lists ok-list and f ailed-list to the calling
algorithm, shown in Figure 10 and discussed in the next section.
4.5.4 Assessing Action Outcomes
Before presenting the main CWCM algorithm, we shortly present the algorithm for assessing
the pending actions in pActsi at a given execution step. As discussed earlier, the assessment
relies on properties 4 and 6, and on equation (10). The algorithm is shown in Figure 8; it
takes as inputs the list of pending actions pActsi , and the current trajectory-set T r i [1, l].
The algorithm returns two lists, ok-list and f ailed-list, of actions whose outcomes are either
ok or f ailed, respectively.
The algorithm considers the actions in pActsi (if any), and for each of them tests whether
the action has outcome ok or f ailed. In the first case, the success is backward propagated
(line 7): oks is the list of successfully completed actions discovered by means of the propagation; these actions are removed from pActsi and added to ok-list. In the second case, the
failure is forward propagated (line 12): faulty is the list of faulty actions discovered by means
of the failure propagation; these actions are removed from pActsi and added to f ailed-list.
The algorithm terminates by returning the two, possibly empty, lists ok-list and f ailed-list.
As mentioned above, an action aik  pActsi , previously marked as not-enough-info, can be
found with a definitive outcome (ok or f ailed). This may happen because, although the
other agents have not provided i with information about the effects of aik , agent i could
exploit the outcome propagation of the actions preceding and following aik . Of course, mark
not-enough-info is removed from actions in ok-list or in f ailed-list.
Proposition 7 (Protocol Correctness - Resource Usage) The cooperative monitoring protocol guarantees that the resource safeness requirement is never violated during the
32

fiCooperative Monitoring to Diagnose Multiagent Plans

execution of MAP P . In other words, shared resources are used correctly throughout the
plan execution even when action failures occur.
Proof: Let us consider the interaction scenarios, and show that in each of them the
resources are accessed consistently; namely, it never happens that two (or more) agents
access the same resource simultaneously.
Given the causal link lk : haik , res = available, ajm i, the interaction activated by agent i
depends on the outcome of action aik .
The notify-ready interaction is equivalent to the only interaction of the BaDE framework,
and occurs when aik has outcome ok. In this case all the expected services have been achieved
for sure. Thus, when i notifies j that res is now available, i has already released res: the
resource is passed from i to j consistently.
The ask-if scenario occurs when aik has outcome pending, and splits into three cases.
1. Agent j (i.e., the client) directly observes that the resource is available. It can therefore
access the resource safely in mutual exclusion.
2. Agent j directly observes that the resource is still occupied by i. In this case j does not
attempt to access res. The resource is being used by a single agent and the resource
safeness requirement is not violated.
3. Agent j is unable to say whether resource res is available. From the point of view
of j, the state of res is unknown, and hence, since the preconditions of ajm are not
satisfied, j keeps waiting for more information from i. Also in this case res is used at
most by one agent.
The last interaction scenario occurs when aik has outcome f ailed. In this case, i notifies
j that the resource is not available: j does not try to use res as the preconditions of ajm are
not satisfied.

Proposition 8 (Protocol Correctness - Provided Services) Let i and j be two agents
playing the roles of provider and client, respectively, about a given causal link lk : haik , v =
d, ajm i. The cooperative monitoring protocol enables the two agents to determine the actual
value of variable v or at least to determine whether v is different from the expected value d.
Proof: The proposition can be proved by considering the different interaction scenarios
of the protocol. The notify-ready interaction occurs when agent i can conclude that action
aik has outcome ok. (This may happen by means of direct observations about the effects
of aik , or by means of the backward propagation of nominal outcomes.) Since action aik
has outcome ok, all its effects, including v = d, have been achieved. The ask-if interaction
occurs when agent i cannot determine the outcome of aik , and hence the truth value of
statement v = d is not known. In that case agent j is in charge of determining whether
the statement v = d is true or false. Agent j can reach this result by means of direct
observations on v. The possible answers of j are three:
 j directly observes v = d, thus the service has been provided;
 j directly observes that v is not d, thus the service has not been provided;
33

fiMicalizio & Torasso

e3 = 


B1A1
T r A1 [1, 5]



B2A1
s2

2
3

B4A1

obsA1
4
B5A1


B3A1



s4

6

s8

s5

7

s9

11

s6

8

s10

12

s14

s7

9

s11

13

s15

s12
10
s13

4

s1
1

s3
5

Figure 9: The trajectory-set kept by agent A1 after the execution of the first four actions.
 j is unable to observe v, in that case agent i relies on answers provided by other agents,
if any, asked about the same link. Agent i can only conclude that v = d is true when
at least one of the received answers allows it to conclude the nominal outcome of aik ;
otherwise, the action is assumed failed, and hence also the service v = d is considered
as missing.
In the last interaction scenario, agent i has directly observed, or indirectly inferred by means
of the forward failure propagation, that v = d is false.

This proposition can be considered as a sort of generalization of Proposition 7 as it
applies to all possible services, not only those services mentioning the available value. This
proposition is important because allows the agents to diagnose themselves without the
necessity of interacting with each other, as we discuss in Section 5.
Proposition 9 (Protocol Complexity) The number of messages exchanged among the
agents is linear in the number n of inter-agent causal links.
Proof: The provider-client interaction occurs only when an agent, playing the role of
provider, has performed an action ail with at least one outgoing, inter-agent causal link.
The number of messages exchanged for handling an inter-agent causal link depends on the
outcome of ail . When ail has either outcome ok or f ailed, the provider sends just one message
to the client (i.e., ready or not-accomplished, respectively). On the other hand, when ail has
outcome pending, the two agents exchange each other up to three messages: provider sends
ask-if, client answers no-info, and then provider either replies ready or not-accomplished.
Thus in the worst scenario, the number of messages exchanged among the agents is 3n,
and hence O(n).

Example 5. Let us assume that after the execution of the first four actions, the trajectoryset kept by agent A1 is the one depicted in Figure 9. This trajectory-set contains 5 belief
states and none of them is sufficiently refined to determine the outcome of an action; thus,
all the actions are currently pending. The edges from a state to another labeled with
 represent the nominal progress of the plan execution; the others instead, labeled with
1 . . . 13 , model the occurrence of some exogenous event (possibly ? ).
34

fiCooperative Monitoring to Diagnose Multiagent Plans

To show how an agent can take advantage of the pieces of information provided by
others, let us assume that agent A1 receives from another agent an observation obsA1
4 about
the effects of action a3 . For instance, let us assume that action a3 corresponds to a move
action, and that observation obsA1
4 refers to the position of agent A1 after the execution of
A1
a3 . Observation obs4 is therefore used to refine the belief state B4A1 . In our example, s8
and s9 are the only states in B4A1 that are consistent with the observation. Thanks to this
first refinement (see equations (8) and (9)) we are able to prune off all those trajectories
that do not pass either through s8 or through s9; these trajectories are depicted as dotted
edges. Dashed edges, on the other hand, are still possible so these trajectories are still kept
within the trajectory set.
However, a further refinement of the trajectory-set is possible when we discover that
the refined B4A1 is now sufficiently precise to determine that action a3 has outcome ok. In
fact, the A1s position conveyed by observation obsA1
4 matches with the expected one; this
means that event e3 , affecting a3 , has to be . By pruning the trajectory-set with e3 = 
(equation (10)), we are in the fortunate case in which B3A1 contains just state s4 , where the
nominal effects of action a2 are satisfied, too. By backwards propagating the success of a3 ,
first on a2 , and then on a1 we can conclude that the three actions have all outcome ok.
In fact, after this process, the resulting trajectory-set maintains just the bold, solid edges;
whereas all dashed edges have been pruned off. The resulting trajectory-set, however, does
not allow us to conclude anything about a4 , which still remains pending.

4.6 Cooperative Weak-Committed Monitoring: Main Algorithm
The main CWCM algorithm is outlined in Figure 10. Each agent i  T follows this algorithm to execute and monitor its own local plan P i .
After a few initial steps that set up the agent trajectory-set and the set of pending
actions, the algorithm iterates over the actions in P i as far as the next action to be performed
coincides with the pseudo-action ai , meaning that P i has been completed. (Remind that
we assume all actions in P i providing atoms in premises(ai ) have observable effects.) At
the beginning of each iteration, the agent interacts with other agents (line 5) by playing
the client role of the cooperative protocol. At this step, an agent i consumes ready and
not-accomplished messages (if any), and acquires information about the resources required
to perform its next action ail . In case the agent receives a not-accomplished message, it stops
the plan execution as some of the preconditions for ail will never be satisfied. In case an
ask-if message is received, the agent establishes whether it is able to observe the required
service and answers accordingly (see algorithms in figures 6 and 7).
Once new information has been acquired and asserted within the agent trajectory-set,
agent i assesses whether the next action ail is possibly enabled (Definition 2). In the positive
case, the action is performed in the real world (line 8). Subsequently, the agent estimates
the possible evolutions of ail by exploiting both (ail ) and (ail ) to extend the current
trajectory-set (line 9). After the completion of action ail , the agents direct observations are
gathered in obsil+1 (line 10) and asserted in the extended trajectory-set (line 11); also in
this case assert is a shortcut for the relational operations described in equations (8) and
(9). Action ail is then temporarily put into the list of the pending actions (line 12). The
outcome assessment is in fact postponed as this step regards all the current pending actions,
35

fiMicalizio & Torasso

Cooperative-Weak-Committed-Monitoring(P i )
1. l  1
2. T r i [1, l]  I i //The initial belief state is the initial state of agent i
3. pActsi  
4. while ail 6= a do
5.
cooperative-protocol::client(inbox, T r i [1, l], ail )
6.
last  null
7.
if ail is possibly enabled in frontier of T r i [1, l] then
8.
execute ail
9.
T r i [1, l + 1]  T r i [1, l]  M(ail )// trajectory-set extension by using (ail ) and (ail )
10.
obsil+1  gather direct observations
11.
assert obsil+1 in the frontier of T r i [1, l + 1]
12.
pActsi  pActsi  {ail }
13.
last  ail
14.
l l+1
15.
end if
16.
hok-list, f ailed-listi cooperative-protocol::provider(inbox, T r i [1, l], pActsi , last)
17.
if f ailed-list 6=  or aik  pActsi marked as not-enough-info then
18.
stop execution
19.
diagnose(P i , pActsi , ok-list, f ailed-list, T r i [1, l])
20.
switch to safe mode
21.
end if
22. end while

Figure 10: Cooperative Weak-Committed Monitoring: high-level algorithm.
and it is activated even when no action has been executed. It is important to note that
each iteration of the loop does not necessarily corresponds to the execution of an action.
As we have seen, the provider behavior of the cooperative protocol needs to know whether
an action has been recently performed or not (i.e., whether an action has been performed
in the current iteration). To this purpose we use variable last, which is set to null at the
beginning of each iteration, and set to action ail only when the action is actually performed
(line 13). Whenever an action has been performed, the counter l is incremented (line 14);
that is, the l-th plan execution step has been completed.
The while loop proceeds with agent i behaving as provider (line 16). This step also
includes the evaluation of the outcomes of all the actions in the pActsi list (see algorithm in
Figure 7). The provider behavior returns two lists, ok-list and f ailed-list, maintaining the
actions with outcome ok and f ailed, respectively; of course, both lists could be empty. As a
side effect, pActsi is modified by removing any action whose outcome is no longer pending.
When the list f ailed-list is not empty, or at least one action in pActsi is marked as notenough-info, the agent stops the plan execution, and starts a diagnostic process (discussed in
Section 5), then switches to safe mode. An agent in safe mode does not perform actions, but
interacts with other agents trying to reduce the impact of its failure. First of all, an agent
in safe mode answers any ask-if message with no-info, this prevents the sender from waiting
indefinitely for an answer. Moreover, an agent in safe mode releases as many resources as
possible by sending appropriate ready messages; this allows other agents to access those
resources and proceed with their plans. A detailed discussion of the safe mode is out the
scope of this paper, but it can be found in the works by Micalizio and Torasso (2007b) and
Micalizio (2013).
36

fiCooperative Monitoring to Diagnose Multiagent Plans

In case no failure has been discovered, and all actions performed so far have outcome
ok (i.e., pActsi gets empty), the trajectory-set T r i can be simplified. In fact, since all the
past actions have a nominal outcome, it is no longer required to keep the whole past history
since the beginning of the plan execution. Thus, it is safe and convenient to forget the past
and keep within the trajectory-set just the frontier. The implementation we used in our
experiments adopts this strategy for keeping the size of a trajectory-set manageable. For
the sake of discussion, we do not provide further details on this point.
4.7 Cooperative Weak-Committed Monitoring: Correctness
We conclude this section by discussing the correctness of the algorithm in Figure 10.
Theorem 1 [CWCM Correctness] CWCM assigns action aik outcome:
- ok iff the action has not been affected by exogenous events;
- f ailed iff an exogenous event, possibly ? , has affected aik ;
- alternatively, CWCM marks a pending action aik as not-enough-info iff no outcome can
be inferred relying on observations from other agents, nor on the outcome propagation technique.
Proof: Part 1: action aik has outcome ok iff aik is not affected by exogenous events. In
other words, we have to show that aik reaches effects(aik ) iff ek =  in each trajectory within
T r i [1, l], where k : 1..l  1.
() By contradiction, let us assume that effects(aik ) have been reached, but the nominal
trajectory has been pruned off T r i [1, l]. This can happen during the monitoring process in
just two ways: (a) through observations, or (b) through the outcome propagation. Let us
consider case (a), and let us suppose that during the monitoring phase agent i receives observations obsik+1 consistent with effects(aik ). As an effect of pruning T r i [1, l] with obsik+1 ,
the nominal transition ek =  is pruned off T r 1 [1, l]; this, however, is in contradiction with
the definition of extended model M(aik ), in which only the nominal transitions labeled with
 lead to the nominal effects(aik ). Thus, either obsik+1 is inconsistent with effects(aik ), and
hence aik cannot be ok, or obsik+1 is consistent with effects(aik ) and ek is  in all trajectories
within T r i [1, l].
Let us now consider case (b), the outcome propagation. There are two cases: backward
propagation of ok, and forward propagation of f ailed. The backward propagation of ok
possibly assigns the nominal outcome to actions aik  pActsi ; after the propagation, ek
equals  in each trajectory within T r i , by definition. The forward propagation of f ailed
possibly assigns the not nominal outcome to some actions in aik  pActsi ; after the propagation ek is not  in any trajectory in T r i [1, l]. The two propagations cannot change the
outcome of an action which is not in pActsi : if an action has already been assigned an outcome, that outcome cannot be changed anymore. In particular, if aik has outcome ok, and
aih  predecessors(aik ) is discovered faulty, then the forward propagation of f ailed cannot
prune ek =  from T r i [1, l]. In fact, as discussed in Proposition 6, the forward propagation
impacts only the causal links that are neither marked as satisfied, nor as missing, and that
are along a chain of links starting from one of the links in miss(aih ). But if aik has been
assigned outcome ok, then agent i must have received sufficient observations to determine
that the premises of aik were satisfied. It follows that the services required by aik have
37

fiMicalizio & Torasso

already been marked as satisfied. Thus, the nominal transition ek =  cannot be lost as an
effect of the outcome propagation.
() If aik is not affected by an exogenous event, and hence eh =  in each trajectory within
T r 1 [1, l], then aik has outcome ok (i.e., reaches effects(aik )). By construction, the extended
model M(aik ) guarantees that only the transitions labeled as  leads to states where all
expected effects hold. It follows that, when ek =  in all trajectories in T r i [1, l], aik must
have outcome ok necessarily.
Part 2: action aik has outcome f ailed iff an exogenous event, possibly ? , has affected its
execution. This can be demonstrated following a reasoning similar to the one in Part 1; we
omit it for brevity.
Part 3: action aik marked as not-enough-info iff no outcome can be inferred relying on
observations from other agents, nor on the outcome propagation technique. It is easy to see
that CWCM marks aik as not-enough-info only in one occasion: in the provider behavior,
after that all the answers gathered about aik in an ask-if interaction are no-info. This exactly
means that no other agent in the team can provide information about the services provided
by aik . On the other hand, the marking is removed only after that aik has been inserted either
into ok-list or f ailed-list; thus it cannot happen that an action with a definite outcome is
also marked as not-enough-info.

Theorem 2 Given the MAP system S = hT , RES, P i, where P is the plan hI, G, A, R, Ci,
the global goal G is achieved from I iff all actions in A have outcome ok.
Proof: In the previous theorem we have demonstrated that an action has outcome ok only
when all its effects have been achieved, and that such an outcome cannot be changed as an
effect of further refinements of the trajectory-set. Thereby, if the global goal G has been
reached, all actions in A must have reached their effects, and hence must have outcome ok.
In fact, since we assume that P has no redundant action (i.e., each action in P contributes
to G), it is sufficient that at least one action fails reaching one effect to have: 1) at least
one action has outcome f ailed, and 2) at least one piece of G has not been achieved.
On the other hand, if all actions in A have outcome ok, G must have been achieved
necessarily. By absurd, all actions in A are ok, but G has not been reached. This can only
happen when P has a flaw, and does not produce G even under nominal conditions, against
the initial assumptions (see Section 2) that P is flaw-free and actually produces G.

Example 5 can be used to clarify the proof. In this example we have shown that, when
we restrict B4A1 to a belief state in which each state satisfies the expected effects of action
a3 , then action a3 has outcome ok. At the same time, this outcome is backward propagated
so that only edges labeled with  can lead to B4A1 . If action a4 were the last action of A1s
plan, the effects of such an action must be observable, by hypothesis. Now, depending on
the available observations, agent A1 can either conclude that s12 is the actual state after a4
(thereby: (1) the goal has been reached, (2) the trajectory-set contains just one trajectory
in which each edge is labeled with , and (3) all actions have outcome ok), or s13 is the
actual agents state, and hence at least one action (i.e., a4 itself) must have outcome f ailed.
Corollary 1 When the global goal G is achieved, each agent i  T keeps in its trajectory-set
T r i [1, l] only the nominal trajectory hs1 , , s2 , . . . , , sl+1 i, where s1 |= I i and sl+1 |= Gi .
38

fiCooperative Monitoring to Diagnose Multiagent Plans

Proof: This follows from the two previous theorems. If G has been reached, all actions
in A have outcome ok (Theorem 2). On the other hand, since aik is ok iff ek =  in
every trajectory within T r i [1, l] (Theorem 1), it follows that each agent i only keeps in its
trajectory-set the nominal trajectory.

The correctness of the monitoring process can therefore be summarized in the following
statement: When the execution of P is not affected by any anomalous event, the cooperative
monitoring is able to keep a trace of the progress until the achievement of the goal G since
the nominal transition is never lost. On the other hand, when the execution of P is affected
by at least one anomalous event, even not known in advance, the cooperative monitoring is
able to detect it and to stop the execution phase. In addition, Proposition 7 assures that
in nominal, as well as anomalous, situations the resources are always accessed consistently.

5. Plan Diagnosis: a Local Strategy
Plan diagnostic inferences start as soon as the CWCM algorithm has discovered the failure
of at least one action (i.e., f ailed-list is not empty), or a pending action is marked as notenough-info. In this section we discuss what we mean by plan diagnosis, and how it can be
inferred. We propose a distributed approach in which each agent infers a diagnosis about
its local plan autonomously. In fact, thanks to Proposition 8, the plan execution is safe
with respect to the use of resources, so an agent can never blame other agents to explain
its own action failures.
5.1 Inputs from CWCM
In the previous section we have focused on the monitoring purpose of the CWCM methodology. It is important to note, however, that CWCM also produces useful pieces of information
from a diagnostic point of view. First of all, the actions in f ailed-list could be considered as
a plan diagnosis according to the definition by Roos and Witteveen (2009); namely, a subset
of actions that when assumed faulty explain the observations. However, in f ailed-list we
do not take into account that some action failures might be the indirect consequences of
others. Thus, f ailed-list is not sufficient as we would like to isolate the primary action
failures that have caused other secondary action failures.
In addition, CWCM produces a trajectory-set T r i [1, l], which can be seen as a set
of consistency-based diagnoses (Reiter, 1987). Each trajectory in T r i [1, l] is a possible
explanation for the agents behavior consistent with the observations received by the agent
itself.
5.2 Event-Based Explanations
Dealing directly with T r i [1, l], however, might be awkward since it encodes all the possible explanations, including the ones mentioning the indefinite exogenous event ? , which
should be considered as very unlikely. Moreover, trajectories which share the same sequence
of events, but differ for a few state variables, are considered as completely different explanations. Thus, T r i [1, l] needs to be processed in order to be useful. A first reduction of
T r i [1, l] is given by projecting it over the event variables e1 , . . . , el1 ; we call the resulting
39

fiMicalizio & Torasso

structure Event-based Explanations (EVE):
EVE = projecte1 ,...,el1 T r i [1, l].

(11)

EVE is a set of sequences of exogenous events (including  and ? ). Each sequence in
this set is a possible consistency-based diagnosis for the anomalous behavior of the agent.
Since EVE could still contain a huge number of diagnoses, EVE is not very informative
for a human user who has to decide how to recover from a plan failure. One way for
further reducing the number of diagnoses would be to prefer diagnoses which involve the
minimum number of exogenous events. Unfortunately, this preference criterion would lead
to misleading results because events are dependent on one another. To find meaningful
explanations, one should identify what exogenous events have caused primary action failures
and what exogenous events correspond to secondary action failures.
5.3 Minimum Primary Action Failures
To facilitate the identification of primary action failures, we distinguish between indefinite
events ? contributed by the  portion of an action model, and indefinite events ? contributed by the  portion. While this distinction is not necessary in CWCM, it turns out to
be useful for the diagnostic purpose. Intuitively, ? denotes the occurrence of an exogenous
event affecting the execution of a (possibly) enabled action; ? is therefore an unknown
abrupt change affecting the nominal behavior of an action. On the other hand, ? is just
the indefinite event we use to label state transitions when an action has been performed
from a state not satisfying its preconditions. Relying on this distinction, it is possible to
identify a primary failure by means of the following definition.
Definition 7 An action ak  pActsi  f ailed-list is a primary action failure iff there exists
an explanation x  EVE such that x[ek ] 6=  and x[ek ] 6= ? , where x[ek ] is the k-th event
in explanation x.
In other words, an action ak is considered as a primary failure in a given event-based
explanation x  EVE iff the occurrence of an exogenous event mentioned in (ak ) is
assumed in x. Note that in Definition 7 we also examine the set of pending actions pActsi ,
including actions marked as not-enough-info. In addition, note that the set of primary action
failures can never be empty. In fact, an agent starts a diagnosis phase only when one of its
performed actions has been labeled as failed. On the other hand, when an agent stops the
execution of its plan because of another agent fails in providing a service, the first agent is
exonerated from diagnosing itself since none of its actions have been labeled as failed, and
the root causes for the missing service have been located outside its plan.
Secondary failures are caused by a primary failure, and are defined as follows:
Definition 8 Let x  EVE be a possible explanation, let ak  f ailed-list  pActsi be
a primary failure in x, then all actions ah  successors(ak ) such that x[eh ] = ? are
secondary failures caused by ak according to explanation x.
Note that, given a primary failure ak in an explanation x  EVE , not all the actions in
successors(ak ) are necessarily secondary failures (see Proposition 4). In fact, even though
ak has not achieved all its effects (i.e., it has outcome failed), the action may have reached
40

fiCooperative Monitoring to Diagnose Multiagent Plans

some of them. As a consequence, some of the actions in successors(ak ) may be enabled
despite the failure of ak . For this reason, in Definition 8 we require that an action ah 
successors(ak ) is labeled as a secondary failure only when the exogenous event ? is assumed
in the explanation x. From the definitions of primary and secondary failures the proposition
below follows directly.
Proposition 10 Given an explanation x  EVE , the set of primary action failures P rmx ,
and the set of secondary action failures Sndx extracted from x are disjointed.
Relying on this proposition, we define Primary Action Failure Diagnoses (PADs):
Definition 9 Let x  EVE be a possible event-based explanation, the primary action-failure
explanation (PAD) extracted from x is the pair hP rmx , Sndx i such that P rmx and Sndx
are the sets of primary and secondary failures, respectively, extracted from x.
Of course, since EVE in general contains several explanations, and since primary failures are
assumed to be independent of each other, it is possible to extract the minimum cardinality
primary action-failure diagnoses (mPADs) by simply selecting the explanations with the
minimum set of primary failures:
mP ADs = {P rmx such that x  EVE and |P rmx | is minimum }

(12)

Minimum primary action failure diagnoses (mPADs) are indeed what we mean for plan
diagnosis: they localize which actions should be qualified as failed in order to explain the
anomalous observations.2
5.4 Refining the Plan Diagnosis
Having inferred plan diagnosis, one can refine these diagnoses by identifying their root
causes. Our refined explanations are expressed in terms of exogenous events, and can be
extracted from the EVE set.
Definition 10 Let ah be a primary action failure, and let EVE (ah ) be the set of explanations x  EVE such that ah  P rmx , then the refined explanation for action ah is
refinedExp(ah ) =

[

x[eh ].

(13)

xEVE (ah )

In other words, refinedExp(ah ) consists of all the exogenous events that might have
occurred during the execution of action ah , and hence might have caused the failure of ah .
Of course, since ah is a primary failure, all secondary failures caused by ah can also be
explained by the occurrence of one of the events in refinedExp(ah ).
2. Note that different preference criteria could be adopted to select explanations in EVE . For instance, one
could prefer minimality rather than minimum cardinality.

41

fiMicalizio & Torasso

a1

a2

a4

a3

a5

a7

a6

a8

Figure 11: A portion of the local plan assigned to agent i
Example 6. Let us consider the simple local plan in Figure 11 assigned to agent i. To
i
. Let us assume that, after
simplify the picture we just show the local causal links in Clocal
the execution of such a local plan, agent i detects the failure of action a8 . The diagnostic
process is activated in order to explain such a failure by identifying its (minimum) set of
primary action failures. The diagnostic process receives in input the list of failed actions
f ailed-list={a8 }, the list of successfully completed actions ok-list={a4 }, and the list of
the pending actions pActsi = {a1 , a2 , a3 , a5 , a6 , a7 }. In addition, the diagnostic process
receives also the trajectory-set T r i [1, 9], but for simplicity we show in Table 2 just the set
of event-based explanations (EVE ) extracted from the trajectory-set.
From Table 2 it is easy to see that all the explanations, except the last one, explain
the failure of action a8 as an indirect effect of a previous failure (i.e., a8 is a secondary
failure). Only the last explanation considers a8 as a primary failure, but an unknown, and
very unlikely, exogenous event ? must be assumed.
The first step of the diagnostic process consists in inferring the set of mP ADs diagnoses.
Thus, we identify primary and secondary failures for each explanation in EVE :
P AD : { x1, x2 :
x3 :

h{a1 },

{a3 , a5 , a8 }i

h{a6 , a7 },

{a8 }i

x4 : h{a3 , a6 , a7 }, {a8 }i
x5 :

h{a2 },

{a7 , a8 }i

x6 :

h{a8 },

i }

We can observe some interesting consequences. First of all, some explanations in EVE are
collapsed within a single explanation in P ADs; see for instance explanations x1 and x2.
This is an advantage as we can reduce the number of alternative explanations. In addition,
the sets of primary action failures can be used to identify (subset-)minimal diagnoses. For
instance, explanation {a6 , a7 } derived from x3 is a minimal diagnosis, whereas explanation
{a3 , a6 , a7 } extracted from x4 is not. Finally, since we assume that primary failures are
independent of each other, we can prefer the subset-minimal diagnoses whose cardinality is

x1
x2
x3
x4
x5
x6

a1
1
5





a2




4


a3
?
?

6



a4







a5
?
?





a6


2
2



a7


3
3
?


a8
?
?
?
?
?
?

Table 2: The set EVE maintained within the current trajectory-set
42

fiCooperative Monitoring to Diagnose Multiagent Plans

minimal. In our example they are mP ADs = {{a1 }, {a2 }, {a8 }}. In fact, it is thus sufficient
to assume the failure of one of these actions to explain the observations.
As a further step, for each action in mP ADs, one can also infer a refined diagnosis.
For instance, it is easy to see that the primary action failure a1 has two alternative refined
diagnoses: either 1 or 5 (see Table 2); whereas the primary action failure a2 has 4 as
single possible refined diagnosis. Finally, one has to assume the occurrence of ? to explain
the primary action failure a8 . Relying on refined diagnoses, other preference criteria could
be employed and conclude that the primary failure a8 is less likely than a1 and a2 , and
hence it could be disregarded.

Note that, since each agent is able to diagnose its own plan autonomously, a plan
diagnosis at global level could be inferred by combining the local solutions inferred by each
agent in the team, and such an integration is guaranteed to be globally consistent. In fact,
thanks to Proposition 8 an agent can never blame another agent for the failure of one of its
actions.

6. Experimental Analysis
So far we have addressed both the CWCM methodology and the diagnostic inferences in
a declarative manner by means of relations and Relational operators between relations.
Relations are a simple, yet powerful formalism to represent nondeterministic action models
and ambiguous belief states. In addition, they can also be used to model very complex
structures such as the trajectory-set and the event-based explanations (EVE ).
When it comes to actually implementing the CWCM methodology, however, it must be
noticed that the computational complexity of the algorithm in Figure 10 is dominated by the
complexity of the (macro-)operator  involved in the extension of the current trajectoryset. On the other hand, the diagnostic inferences are based on the projection of the current
trajectory-set over the event variables (see equation 11). Both these steps might be computationally very expensive, and an efficient implementation of relations and relational
operators therefore becomes essential. A possible way to cope with this issue is to translate
the relations into some symbolic, and hence compact, formalism, and then encode the Relational operators as operations in the selected symbolic formalism. Alternatively, it may be
possible to exploit the recent advancements in Continuous Query Languages (CQLs) to deal
with data streams (see e.g., the STREAM system in Arasu, Babu, & Widom, 2006), and implement CWCM relying on the primitives made available by the Data Stream Management
System at hand.
In this paper, we have chosen the method of knowledge compilation, and in particular,
we have selected the Ordered Binary Decision Diagram (OBDD) (Bryant, 1986, 1992) formalism to encode relation and Relational operators. This choice is justified by two main
reasons: first, OBDDs are nowadays a well-known language made available through many
mature libraries; second, the theoretical results by Darwiche and Marquis (2002) suggest
that OBDDs can answer most of queries in polynomial time provided that their sizes remain
tractable. An in-depth description on how the cooperative monitoring and diagnosis have
been implemented via OBDDs is reported in the Appendix.
The rest of the section is organized as follows. First, in Section 6.1, we sketch the
software architecture of our implementation; then in Section 6.2, we present the experimen43

fiMicalizio & Torasso

domain

initial
state

P

XML

XML

XML

DISPATCHER

A1

P A1

RA1

outcome assessment

CW CM

RAN

outcome assessment

...

CW CM

DIAGNOSIS

extend trj

AN

P AN

T r A1

DIAGNOSIS

extend trj

detected failure

T r AN

detected failure

cooperative protocol messages

observations for AN
observations for A1

ANs next action

SIMULATOR

A1s next action

domain; initial state

XML

exogenous events

Figure 12: The software architecture of the CWCM implementation used in tests.

tal setting we used to carry out the tests, consisting in the simulated execution of several
MAPs. Finally, we discuss the most interesting results about monitoring (Section 6.4), and
diagnosis (Section 6.5).

6.1 Software Architecture and Implementation
The CWCM proposal has been implemented as a Java SDK 7 program. The software
architecture is shown in Figure 12, highlighting the main actors: the Dispatcher, the N
agents of a team (from agent A1 to agent AN), and the Simulator. The picture also shows
the internal architecture of the agents. Solid edges between modules represent data flows,
dashed edges represents instead control flows, whereas the dotted edge between CW CM s
abstracts all the messages exchanged by the agents during the cooperative monitoring. The
simulation of a MAP P starts by submitting to the Dispatcher module three XML files
containing, respectively, the system domain (i.e., what agents and objects are defined in the
scenario at hand), the system initial state (e.g., the initial positions of agents, the initial
states of resources, etc.), and the MAP P to be performed. The Dispatcher decomposes
P into local plans so that each agent will receive just the portion of P of its interest. In
particular, once P has been decomposed, the Dispatcher activates the agents, which are
implemented as threads, by passing them their initial states and their local plans.
44

fiCooperative Monitoring to Diagnose Multiagent Plans

OBDDs are made available through the JavaBDD library 3 , which provides a java, easyto-use interface between Java and BuDDy 4 , a popular and mature library for manipulating
OBDDs written in C.
Besides the agents, the Dispatcher activates also a Simulator, implemented as a thread.
Differently from agents, however, the Simulator does not receives in input a plan, but just
the initial state of the system. In addition, the Simulator reads from a fourth XML file the
exogenous events that have to be injected during the plan execution. More precisely, the
file is a list of agents actions, each of which is associated with the anomalous event that
must occur during the execution of that action. Of course, only the subset of actions to be
affected by exogenous events are mentioned in this file.
Once the environment has been set-up, the Dispatcher starts the agents, which will
execute the CWCM algorithm as discussed in Section 4. The actual execution of an action
is just simulated by the Simulator: Whenever an agent intends to perform an action, it
sends a message to the Simulator conveying the action to be performed. The Simulator
will simulate the action execution taking into account possible exogenous events that have
to be injected. If the action is associated with observations, the Simulator sends to the
corresponding agent an appropriate message. It is worth noting that also the Simulator,
like any other agent, uses OBDDs to estimate the next state of the whole system according
to the actions that are currently in progress. Differently from the agents, however, the
Simulator always knows the precise state of each agent and resource in the system. Some
more details about the use of OBDDs for handling relations are given in Appendix A.
As discussed in Section 4, whenever the failure of an action is detected by an agent i,
the Diagnosis module of that agent is activated. The results of the diagnosis inferences,
discussed in Section 5 are saved in a report file Ri associated with agent i.
The experiments described in the following were performed on a PC, Intel Core 2 Duo,
2.80 Ghz, 8 GB RAM equipped with Windows 7 OS. Each test is repeated ten times,
and average values are considered in the experimental analysis in order to absorb load
fluctuations of the CPU.
6.2 Experimental setting
The domain we used for our tests has already been introduced in Example 1. The actions
each agent can perform are summarized in Table 3 5 , reporting some details about the
encoding of the action models as OBDDs. More precisely, # variables is the number of state
variables over which the OBDD is defined; this number includes one variable for encoding
the possibly anomalous event occurring during the action execution; the remaining variables
are used to encode an agent state transition from step t, when the action starts, to step t+1,
when the action ends. Columns #-nodes and #-trans. report, respectively, the number
of nodes of the OBDD encoding the  portion of the action model, and the number of state
transitions encoded by . Columns #M-nodes and #M-trans. refer to the whole extended
model M, including the  portion. In such a domain, each agent handles 36 variables to
encode its own belief state about the environment.
3. http://javabdd.sourceforge.net/index.html
4. http://sourceforge.net/projects/buddy/
5. Examples of test cases and action models can be found at
http://www.di.unito.it/micalizi/CWCM/index.html.

45

fiMicalizio & Torasso

move
carry
load
unload

# variables
15
19
17
17

#-nodes
193
346
386
386

#-trans.
34
38
40
40

#M-nodes
291
374
892
892

#M-trans.
420
1857
169
169

Table 3: Some details on the relational action models.
6.3 Objectives of the Experimental Analysis
There are at least three main questions that we want to get answered by means of our
experiments. These questions are:
 Does CWCM scale up well as the number of agents in the team grows?
 Is CWCM affected by the level of system observability? and if so to what extent?
 Is the cooperation among agents really useful for the monitoring purpose?
To answer these questions, we carried out our tests by varying three main characteristics:
team size, observability level, and monitoring strategy.
6.3.1 Team Size
To assess the scalability of CWCM, we have generated MAPs with teams from 3 to 8 agents.
Thus, we have 6 scenarios, and for each of them, we have synthesized 30 MAPs. The main
characteristics of these MAPs are reported in Table 4. Note that the MAPs are not trivial as
they consist of a significant number of actions and subgoals to be achieved. The term MAPspan refers to the number of execution steps that are required to complete the plan under
nominal conditions and full observability. The concurrency rate, computed as the number
of actions divided by MAP-span, indicates that agents do perform actions concurrently.
Finally, the number of inter-agent causal links shows how often agents interact with each
other to achieve their own subgoals.
6.3.2 Observability Level
To assess the competence of CWCM, the MAPs were performed under different conditions
of observability. In particular, we considered three degrees of domain observability. In the
following, the term FULL denotes a complete observability of the effects of the actions
performed by the agents. Such a level of observability is unrealistic in practice, but it
represents our benchmark to compare the performance of CWCM in the other observability
conditions. The term HIGH denotes a degree of observability that guarantees to observe
the effects of 70% of the MAPs actions, randomly selected. Finally, the term LOW denotes
a degree of observability of just 30% of the MAPs actions, again randomly selected.
6.3.3 Monitoring Strategies
Finally, to assess the actual benefits achieved by the cooperation among the agents during
the monitoring phase, we considered three alternative monitoring strategies:
 BaDE, already presented in Section 2, is the simplest strategy, based on the strong
committed policy.
46

fiCooperative Monitoring to Diagnose Multiagent Plans

scenario

#agents

#actions

#subgoals

MAP-span

concurrency
rate

SCN3

3

SCN4

4

SCN5

5

SCN6

6

SCN7

7

SCN8

8

67.67

47.00

30.78

14.04

10.20

9.94

69.00

52.00

27.90

5.42

3.15

2.93

91.60

77.80

34.40

7.37

3.97

3.10

128.90

73.60

27.00

40.27

4.63

8.10

180.40

73.90

30.90

36.84

18.35

5.27

156.40

48.80

20.50

6.13

7.63

2.70

2.2
2.5
2.7
4.8
5.9
7.2

#causal

#inter-agent

links

links

226.44

10.5

32.82

1.87

239.30

20.1

13.39

1.45

329.80

26.8

11.34

1.1

377.70

28

70.14

4.75

467.20

36.6

60.55

4.92

360.60

45.00

6.90

2.82

Table 4: Characteristics of the MAPs in the six scenarios under nominal conditions (average
values and confidence intervals).

 WCM (Weak-Committed Monitoring) introduced by Micalizio and Torasso (2008,
2009) is based on the weak-committed policy that allows agents to keep trajectorysets to cope with scarce observability. In WCM, an agent i is able to keep pending
actions as far as these actions do not provide services to other agents. Differently
from CWCM, in WCM agents cannot cooperate with each other; therefore, when the
outcome of an action a cannot be precisely determined, and a provides another agent
j (i.e., i 6= j) with a service, a is assumed as failed by i, which also stops the execution
of its own plan.
 CWCM, discussed in Section 4, extends the weak-committed policy with the active
cooperation among the agents.
6.3.4 Exogenous Events
Although exogenous events have been generated randomly, their generation reflects the
(expected) probability with which a given exogenous event can occur. For instance, a completely unexpected event, encoded by ? , is very unlikely to occur, and hence its frequency
in our experiments is pretty low. Table 5 shows the probability distribution used to generate
exogenous events randomly.
6.4 Experimental Analysis: Monitoring
The experimental analysis of the monitoring task is subdivided into two main parts. In
the first one, we assess the three strategies BaDE, WCM, and CWCM, under nominal
conditions; that is, when no exogenous event occurs during the simulated execution of
MAPs. The goal is to study the impact of the observability degree on the competence
47

fiMicalizio & Torasso

Exogenous event
blocked-wheel
wrong-move
lose-parcel
slip-parcel
blocked-arm
?

Probability
25 %
10 %
25 %
10 %
25 %
5%

Table 5: The exogenous events and their frequencies in the experiments.
HIGH observability

WCM

CWCM

% achieved subgoals

% performed actions

HIGH observability
BaDE
100
80
60
40
20
0
3

4

5

6

7

8

BaDE

WCM

80
60
40
20
0
3

4

# agent

100
80
60
40
20
0
3

4

5

6

6

7

8

7

8

LOW observability
BaDE

CWCM

% achieved subgoals

% performed actions

WCM

5

# agents

LOW observability
BaDE

CWCM

100

7

8

WCM

CWCM

100
80
60
40
20
0
3

4

5

6

# agents

# agents

Figure 13: [Nominal Conditions] Competence:
achieved goals.

percentage of performed actions and

of the three strategies. In the second part, we assess again the competence of the three
strategies when exogenous events do occur.
6.4.1 Nominal Conditions
Competence. The competence is estimated as the percentage of actions performed and
subgoals actually achieved by the agents. Since under the condition of FULL observability
the agents perform 100% of their actions and achieve 100% of their subgoals in each of the
three strategies, in Figure 13 we just report the results under HIGH and LOW conditions.
As expected, BaDE is very sensitive to the observability degree. On the other hand, since
WCM and CWCM keep trajectory-sets, they are more tolerant to partial observability,
and generally behave much better than BaDE. CWCM does better than WCM as the
cooperation between the agents allows them to compensate the lack of direct observations
with messages coming from others. As discussed in Section 4.5, however, it may be possible
that even the other agents are unable to provide useful pieces of information. Thus, also
with the CWCM strategy, an agent decides to stop the execution of its own plan when,
even asking other agents for more observations, it is not possible to determine the outcome
of an action. As explained in Section 4.5, in this case an agent stops the execution of its
plan by marking some actions as not-enough-info. This is the reason why the percentage
of performed actions and achieved goals is below 100% with observability levels HIGH and
48

fiCooperative Monitoring to Diagnose Multiagent Plans

FULL observability
WCM

LOW observability

HIGH observability
BaDE

CWCM

WCM

CWCM

BaDE

300

300

250

250

250

200

200

200

150

msec

300

msec

msec

BaDE

150

100

100

50

50

50

0

0

4

5

6

# agents

7

8

CWCM

150

100

3

WCM

0
3

4

5

6

# agents

7

8

3

4

5

6

7

8

# agents

Figure 14: [Nominal Conditions] Monitoring time (average and 95% confidence interval) for
a single execution step.

LOW. The results obtained by CWCM are in any case remarkable: in the worst case, SCN5,
at least 80% of actions have been performed and 70% of subgoals have been achieved despite
only 30% of the actions were observable.
Computational Time. Figure 14 shows the average time (and the 95% confidence interval) for monitoring a single step of execution. Note that for the BaDE strategy the monitoring just consists in estimating the next belief state; whereas, WCM and CWCM have to
extend their trajectory-sets. In addition, CWCM has also to cooperate with other agents.
The cooperation can introduce further costs as the consumption of a message from another
agent corresponds to an operation on the OBDD encoding the current trajectory-set. A first
positive result emerging from Figure 14 is that, even in the worst scenario, CWCM takes
no more than 300 milliseconds for monitoring the execution of an action. This allows us to
conclude that CWCM could be employed effectively in real-world domains where agents
actions are performed in the order of seconds.
In addition, it is easy to see that computational time strongly depends on the observability level. For example, under FULL observability, CWCM and WCM behave very similarly;
in this case, in fact, CWCM agents do not need to cooperate each other, and hence the
two strategies are almost the same. However, when the observability decreases, CWCM
is slightly more expensive than WCM and BaDE. This higher cost is counterbalanced by
the competence of CWCM, that, as already noticed, outperforms the competence of both
BaDE and WCM.
From the charts in Figure 14 it is also apparent that there is no strict dependency
between the number of agents in the team and the computational time of the three strategies.
This, in fact, is a consequence of our distributed approach where each agent maintains its
own point of view about the environment, and the cooperation with other agents is just
based on the exchange of messages and not belief states.
OBDD dimensions. The relation between time and observability becomes clear when
we consider the sizes of the OBDDs encoding the trajectory-sets; see Figure 15, left. For
brevity we just report the average sizes of the OBDDs maintained by the three strategies
under HIGH and LOW observability conditions6 . It is easy to see that there exists a relation
between the computational time shown in Figure 14 and the sizes of the OBDDs in Figure
6. In the FULL observability case, the OBDD sizes for CWCM are well below 3000 nodes, on average. In
addition, CWCM and WCM generate OBDDs with similar sizes, as expected.

49

fiMicalizio & Torasso

HIGH observability

HIGH observability
BaDE

WCM

CWCM

WCM

HIGH observability
WCM

CWCM

CWCM

12.00

12000
8000
4000
0
3

4

5

6

7

80
70
60
50
40
30
20
10
0

Length of a trajectory

# trajectories

# OBDD nodes

16000

3

8

4

5

LOW observability
WCM

7

8.00
6.00
4.00
2.00
0.00

8

3

4

5

# agents

# agents

BaDE

6

10.00

LOW observability

CWCM

WCM

6

7

8

7

8

#agents
LOW observability
WCM

CWCM

CWCM

12.00

12000
8000
4000
0
3

4

5

6

# agents

7

8

80
70
60
50
40
30
20
10
0

Length of a trajectory

# trajectories

# OBDD nodes

16000

3

4

5

6

# agents

7

8

10.00
8.00
6.00
4.00
2.00
0.00
3

4

5

6

#agents

Figure 15: [Nominal Conditions] Left: Sizes of OBDDs in number of nodes (average and
95% confidence interval); center: Average number of trajectories within a
trajectory-set; right: Average length of one trajectory.

15, left: the bigger the OBDDs the higher the computational time. As we have already
noted, although OBDDs may get very large, the computational time is still acceptable.
(The biggest OBDD that has been observed had 17,707 nodes, and was built by CWCM in
SCN5 under LOW observability.)
Obviously, the level of observability has a strong impact on the dimensions of the OBDDs. In fact, a reduced level of observability makes the trajectory-sets more ambiguous,
and hence more trajectories have to be encoded within a single OBDD. This is made explicit in Figure 15, center, where we show the number of trajectories encoded, on average,
within a trajectory-set at each time instant, and their length (Figure 15, right). Of course,
in these two last charts, we only consider WCM and CWCM since the BaDE strategy does
not build trajectory-sets. Moreover, note that in the actual implementation of CWCM, the
extension of a trajectory-set does not cover the whole plan performed so far, but only the
current subset of pending actions.
CWCM Communication Analysis. We conclude the study under nominal conditions
with an analysis of the communication required by the CWCM methodology. Figure 16
shows the average number of messages exchanged among the agents. The first interesting
result is that, under FULL conditions, the number of exchanged messages coincides with
the number of inter-agent causal links. In fact, since these results are taken under nominal
conditions, each action reaches its nominal effects; therefore, the cooperative protocol handles each inter-agent causal link by means of a simple ready message sent by the provider to
the client, no answer is required. When the observability level is just HIGH, however, the
number of messages tends to increase, even though it does not increase significantly except
for scenario SCN8. As expected, the largest number of messages is exchanged when the
observation is LOW, as expected.
50

fiCooperative Monitoring to Diagnose Multiagent Plans

CWCM messages in nominal conditions
FULL

HIGH

LOW

70

# messages

60
50
40
30
20
10
0
3

4

5

6

7

8

# agents

Figure 16: The number of messages exchanged by CWCM agents in nominal conditions.
HIGH observability

CWCM

BaDE

100
80
60
40
20
0
4

5

6

7

8

60
40
20
0
3

4

40
20
0
6

7

8

# agents

% achieved subgoals

% achieved subgoals

60

5

6

7

8

WCM

60
40
20
0
3

4

BaDE

60
40
20
0
5

6

# agents

6

7

8

7

8

LOW observability

CWCM

80

4

5

# agents

100

3

CWCM

80

HIGH observability
BaDE

CWCM

80

4

5

WCM

100

# agents

100

3

BaDE

80

FULL observability
WCM

LOW observability

CWCM

100

# agents

BaDE

WCM

7

8

% achieved subgoals

3

% performed actions

% performed actions

WCM

% performed actions

FULL observability
BaDE

WCM

CWCM

100
80
60
40
20
0
3

4

5

6

# agents

Figure 17: [Faulty Conditions] Competence: percentages of performed actions and achieved
goals.
6.4.2 Faulty Conditions
Competence. Let us now consider the same test set as before, but we randomly inject
a single exogenous event in each MAP. The goal is to assess how well the three strategies
behave when partial observability and exogenous events combine together. Figure 17 shows
the competence of the three strategies in such a faulty setting under the three observability
levels. When the environment is fully observable, the three strategies behave exactly the
same, as expected. Of course, the percentages of performed actions and achieved goals
depend on how early, or how late, the exogenous event occurs in the MAP. In general, we
can say that at least 70% of the actions are performed despite the injected exogenous event.
A similar consideration can be made for the percentage of achieved goals.
When the observability conditions degrade to HIGH and LOW, however, it is easy to
see that CWCM outperforms the other two strategies. This means that CWCM is actually
more tolerant than the other strategies to partial observability even in the faulty scenario.
51

fiMicalizio & Torasso

FULL observability
WCM

BaDE

CWCM

WCM

LOW observability

CWCM

BaDE

300

300

250

250

250

200

200

200

150
100

150
100

50

50

0

0

3

4

5

6

7

msec

300

msec

msec

BaDE

HIGH observability

8

WCM

CWCM

150
100
50
0

3

4

# agents

5

6

7

8

3

4

# agents

5

6

7

8

# agents

Figure 18: [Faulty Conditions] Monitoring time (average and 95% confidence interval) for
a single execution step.
HIGH observability

HIGH obervability

CWCM

WCM

12000
10000
8000
6000
4000
2000

50
40
30
20
10
0

0
3

4

5

6

7

3

8

4

5

WCM

7

8

WCM

CWCM

14000

# trajectories

12000
10000
8000
6000
4000
2000
5

6

# agents

6
4
2
0
3

4

5

7

8

WCM

50
40
30
20
10
3

4

5

6

# agents

6

7

8

7

8

LOW observability

CWCM

0

0
4

8

# agents

60

3

10

LOW observability

LOW observability
BaDE

6

CWCM

12

# agents

# agents

# OBDD nodes

WCM

60

# trajectories

# OBDD nodes

14000

HIGH observability

CWCM

Length of a trajectory

WCM

7

8

length of a trajectory

BaDE

CWCM

12
10
8
6
4
2
0
3

4

5

6

# agents

Figure 19: [Faulty Conditions] Average sizes of OBDDs encoding a trajectory-set (left),
average number of trajectories within a trajectory-set (center), average length
of a trajectory-set (right).
In particular, since the only difference between CWCM and WCM is the cooperative monitoring, we can conclude that the cooperation among the agents is actually beneficial.
Computational time. Figure 18 reports the computational cost, in milliseconds, of the
three strategies under faulty conditions and for the three levels of system observability. It
is important to note that also in this case the computational time strongly depends on
observability level; whereas it does not depend on the number of agents in the team, nor
on the presence of an exogenous event. In fact, the time for monitoring a MAP affected by
an exogenous event has the same order of magnitude as the monitoring of a MAP under
nominal conditions. The differences that can be observed by comparing charts in Figure
14 with charts in Figure 18 are due to the fact that the execution of a MAP affected by a
fault terminates earlier than a MAP executed under nominal conditions, independently on
the level of observability.
Of course, the BaDE strategy is the cheapest of the three, but it is unable to monitor
effectively the execution of a MAP. In fact, the strong committed policy at the basis of this
52

fiCooperative Monitoring to Diagnose Multiagent Plans

CWCM messages in faulty conditions
FULL

HIGH

LOW

60

# messages

50
40
30
20
10
0
3

4

5

6

7

8

#agents

Figure 20: The number of messages exchanged by CWCM agents in faulty conditions.
strategy is too sensitive to the level of observability, and under HIGH and LOW conditions
it performs poorly.
OBDD dimensions. Let us consider the dimensions of the OBDDs maintained by the
three strategies. On the left-hand side of Figure 19, we report the sizes, in number of
nodes, of the OBDDs representing the current belief state (BaDE strategy), and the current
trajectory-set (WCM and CWCM strategies) under the three conditions of observability.
As expected, BaDE keeps the smallest OBDDs since it just maintains the last belief state,
but this makes the BaDE strategy unable to deal with low observability levels. WCM
and CWCM behave similarly under FULL observability conditions, but CWCM tends to
maintain bigger OBDDs when the observability level decreases. This result can be explained
by the fact that CWCM can build longer trajectory-sets than WCM (Figure 19, right), and
these longer trajectory-sets tend to be more ambiguous as demonstrated by the average
number of trajectories within a trajectory-set (Figure 19, right).
CWCM Communication Analysis. Figure 20 shows the number of messages exchanged
by CWCM agents under faulty conditions. The trend is similar to that of nominal conditions, however, the number of messages is slightly lower. This happens because the occurrence of a failure prevents the agents from performing some actions, and as a consequence
some messages will not be exchanged. This is also the reason for having slightly less messages in SCN6 than SCN5. In fact, the number of inter-agent causal links in the two
scenarios is almost the same, but faults in SCN6 have a stronger impact than in SCN5, this
is evident looking at the number of performed actions in SCN5 and SCN6 (see Figure 17).
6.5 Experimental Analysis: Diagnosis
Competence. The competence of the diagnostic inferences is evaluated as the percentage
of cases in which the action affected by the injected exogenous event has been included
within the set of preferred explanations mP ADs. Figure 21 (left-hand side) shows how our
diagnostic inferences behave in the three levels of observability. Obviously, under FULL
observability, the diagnostic inferences always identify the correct primary action failure.
Under HIGH and LOW observability, however, the impaired agent can stop the plan execution due to lack of observations (i.e., not-enough-info). In those cases the diagnosis cannot
identify the primary failure. Figure 21 (right-hand side) shows also the average distance
(i.e., number of actions), between the action affected by an exogenous event, and the action
53

fiMicalizio & Torasso

FULL

HIGH

LOW

FULL

HIGH

LOW

8

80

#actions

% diagnosed cases

100

60
40

6
4
2

20
0

0
3

4

5

6

7

8

3

4

5

#agents

6

7

8

#agents

Figure 21: [Diagnosis] Competence (left), and responsiveness (right).

 	 
 xplanations

EVE: all inferred explanations
FULL

HIGH

LOW

FULL

# explanantions

# explanations

50
40
30
20
10
0
3

4

5

6

7

8

LOW

4
3
2
1
0
3

# agents

HIGH

5

4

5

6

7

8

# agents

Figure 22: [Diagnosis] EVE explanations (left), mPADs explanations (right).
in which the failure is actually detected. Under FULL observability, the diagnosis is highly
responsive as it detects an action failure as soon as the exogenous event occurs (i.e., the
distance is zero). On the other hand, when the observability is just partial, a CWCM agent
can take longer to detect a failure.
Explanations and Preferred Explanations. In Section 5, we have pointed out that,
given a trajectory-set, one can identify two types of explanations: EVE and mP ADs. The
set EVE represents all the explanations that are consistent with the observations received
by an agent; whereas mP ADs is the set of primary action failures inferred from EVE . Figure 22 shows the cardinalities (on average) of the two sets inferred in the six scenarios and
with different levels of observability. From the two charts in Figure 22 we can draw two conclusions. First, the cardinality of EVE strongly depends on the observability level; namely,
the reduction in the observability level causes an increment in the number of possible explanations. However, the cardinality of mP ADs is almost independent of the observability
level. In fact, the number of preferred explanations inferred with LOW observability is similar to the number of preferred explanations inferred with FULL observability in all the six
scenarios. Of course, mP ADs sets computed under LOW observability tend to be slightly
bigger than mP ADs sets computed under FULL observability, but this is a consequence
of the fact that the initial EVE set was more ambiguous under LOW observability. This
means that, regardless of the initial ambiguity of the EVE sets, the preferred explanations
are reduced to almost the same subsets in all the six scenarios.
The second important conclusion is that mP ADs explanations are substantially more
useful in identifying a fault than EVE explanations. In fact, the average cardinality of
mP ADs sets is three in the worst cases with LOW observability; whereas, the average
54

fiCooperative Monitoring to Diagnose Multiagent Plans

Diagnosis: Computational Time
FULL

HIGH

LOW

1000

msec

800
600
400
200
0
3

4

5

6

7

8

# agents

Figure 23: Diagnosis: Computational Time.

number of EVE explanations in the best case with FULL observability is eight, but it
rises up to 38 in the worst case with LOW observability (see SCN3). This means that the
mP ADs explanations may actually help a human user refine her/his hypotheses about the
current situation of the system. This is essential when we consider that diagnosis is just
the first step for recovery (Micalizio, 2013). Thus, a human user, or possibly an automatic
supervisor, has to consider a small number of alternative explanations, and hence can better
focus the plan recovery process on the fault(s) that are believed more plausible.
Computational Effort. Finally, we consider the computational time required to infer the
diagnoses. In inferring the EVE explanations, the computational cost is mainly due to the
cost of removing non-relevant variables from the trajectory-set provided by CWCM (see the
Appendix for a discussion from a theoretical point of view about the cost of such variable
removal). Figure 23 reports the average computational time, in milliseconds, for extracting
EVE explanations in the six scenarios and with the three different levels of observability.
As noticed in the previous section, under LOW observability, the trajectory-set tends to
be bigger than with the other two observability levels. As a consequence the time for
inferring diagnoses under LOW conditions tends to be higher; however, this time is below
1 second even in the worst case. On the other side, under HIGH observability conditions,
the worst time is below 150 milliseconds (see scenario SCN3). The worst time falls below
50 milliseconds when we consider the FULL observability level. These computational times
allow us to conclude that the diagnostic task, as the monitoring one, can be performed
on-line in a number of applicative domains where actions are performed in the order of
seconds, or even minutes.
6.6 Discussion
At the beginning of this experimental analysis we posed three questions, and now we are in
the position to answering them. First of all, the experimental results show that CWCM is
not sensitive to number of agents in the team. This is a consequence of the partitioning of
the global plan into local plans. In such a way, in fact, each agent keeps just its own point
of view on the states of the shared resources; namely, each agent has a local belief state that
does not depend on the number of agents in the team. As we have seen, the consistency
among these local beliefs is guaranteed through the exchange of messages whose number is
linear in the number of inter-agent causal links of the MAP under consideration.
55

fiMicalizio & Torasso

On the other hand, the level of observability of the system has a strong impact both on
the computational effort of CWCM and on the ambiguity of the trajectory-sets computed.
The lower the observability, the higher is the computational cost and the bigger is the
trajectory-sets. An important result that emerges from our analysis is that the worst-case
scenarios depicted in the Appendix are very rare, and never occurred during our experiments. Indeed, the compact encoding of trajectory-sets and action models obtained via
OBDDs facilitates a very efficient implementation of CWCM that takes, on average, just
hundreds of milliseconds to monitor a single action. This allows us to conclude that CWCM
can be successfully employed for on-line monitoring in many real-world domains.
The level of observability has also an impact on the diagnostic inferences. In fact,
the number of EVE explanations significantly grows as the observability level decreases.
However, the number of preferred mP ADs explanations is not so strongly influenced by
the observability level.
Finally, the direct comparison between CWCM and WCM demonstrates that the cooperation among the agents is essential to be tolerant to very scarce observations. The
cooperation, in fact, is the means through which an agent in CWCM can keep longer
trajectory-sets than in WCM. These longer trajectory-sets give each agent more chances to
collect pieces of information about the successful completion of some pending actions.

7. Related Works
We consider four main families of model-based approaches to the diagnosis of dynamic
systems close to our MAPs:
 Discrete-Event Systems (DESs);
 Relation-oriented;
 Team-oriented;
 Resource-oriented.
In the rest of this section we briefly review the main approaches within these families,
highlighting differences and similarities with the CWCM methodology proposed here.
7.1 Discrete-Event Systems
Since the seminal work by Sampath, Sengupta, Lafortune, Sinnamohideen, and Teneketzis
(1995) on the Diagnoser, a huge number of works have addressed the diagnosis of dynamic
systems by modeling such systems as DESs. While the Diagnoser approach compiles the
diagnostic model (i.e., the Diagnoser itself) of the whole system off-line, other approaches
(see e.g., Lamperti & Zanella, 2002; Cordier & Grastien, 2007) compute all possible system
behaviors, and check which of these behaviors are correct. Grastien, Haslum, and Thiebaux
(2012) extends to DESs the conflict-based approach initially proposed by Reiter (1987) on
static systems.
To the best of our knowledge, the DES framework that gets closer to ours is the one
presented by Grastien, Anbulagan, Rintanen, and Kelareva (2007). In such a framework,
a diagnosis is a label either normal or faulty, associated with a system trajectory; where a
trajectory is a sequence of system states interleaved with events, thus very similar to the
56

fiCooperative Monitoring to Diagnose Multiagent Plans

trajectories kept within our trajectory-sets. A trajectory is normal if it does not contain
fault events; the trajectory is faulty, otherwise.
Grastien et al. propose to reduce a diagnosis problem to a SAT one. The idea is to formulate a SAT problem, in order to answer the question is the observed behavior compatible
with at most i faults occurring?. Of course, when the answer is yes for i = 0, the system is
assumed nominal as there exists at least one normal path consistent with the observations.
In principle, the proposed system description could encode a MAP: the execution of actions
could be modeled by a subset of observable events; whereas our exogenous events could be
mapped to unobservable events directly. However, the DES framework cannot be directly
applied to the same domains CWCM can deal with. First of all, in the DES approach the
next state of the whole system is inferred taking into account the synchronous occurrence
of a set of events. Thus, if agents are event generators, it follows that they can only perform
actions synchronously, but in CWCM this restriction is not imposed. Moreover, the SATbased methodology is centralized as trajectories are about whole system states, whereas
CWCM enables each agent to build local trajectory-sets in a distributed way.
7.2 Relation-Oriented Approaches
Relation-oriented approaches have been proposed by Micalizio and Torasso (2008, 2009). We
define these works as relation-oriented since action models are expressed in terms of relations
over agents state variables. The advantage of such a kind of model is the possibility of
representing in a single piece of knowledge both the nominal and the abnormal evolutions of
an action. The CWCM methodology falls within such a category, and extends the previous
works in two ways. First of all, CWCM is able to deal with completely unexpected events,
denoted as ? , for which no model exists. Indeed, the occurrence of ? during the execution
of an action a maps all variables in effects(a) to the unknown value; meaning that these
variables are no longer predictable.
The second important extension is the protocol that allows the agents to cooperate with
each other during the monitoring task. As the experimental results have demonstrated,
cooperation among agents is essential to cope with very scarce observations. By means of
the cooperation, in fact, an agent can acquire new pieces of information that it would not
acquire directly. These further pieces can therefore be used to refine its own trajectory-set,
and possibly the outcome of some pending actions could be determined.
7.3 Teamwork-Oriented Approaches
Rather than diagnosing action failures, as in CWCM, teamwork-oriented approaches are
focused on diagnosing teamwork failures; i.e., coordination failures. This type of failures
are not necessarily due to erroneous actions, but to wrong decisions taken by the agents.
The detection of teamwork failures has been addressed in some seminal works by Tambe
(1998) and Kaminka and Tambe (2000). Kalech and Kaminka (2003) have later focused
on the diagnosis of these coordination failures, and have introduced the notion of social
diagnosis. More specifically, the team of cooperating agents is represented in abstract
terms by means of a hierarchy of behaviors. A behavior is an abstraction of the concrete
actions that an agent actually takes in the real world. Indeed, behaviors abstract not just
single actions, but possibly sequences of actions. Thus, differently from relational- and
57

fiMicalizio & Torasso

resource-oriented approaches (see later), an explicit model of the agents plans is missing in
teamwork-oriented solutions.
The social diagnosis framework assumes that agents synchronize themselves to jointly
select a team behavior. A disagreement arises when at least two agents select two behaviors
that are incompatible with each other. Such disagreements represent instances of social
diagnosis problems. Of course, agents select their behaviors according to their own beliefs,
thus a social diagnosis for a disagreement is a set of conflicting belief states held by a subset
of agents. Kalech and Kaminka (2005, 2007, 2011) propose different methods for inferring
a social diagnosis. These solutions, however, rely on some assumptions that may limit their
applicability in real-world scenarios. First of all, it is assumed that all the agents in the team
share the hierarchy of behaviors and that the belief states of the agents are homogeneous
(i.e., defined over the same set of propositional atoms). Moreover, agents must be willing
to exchange each other their own beliefs. The CWCM methodology we propose, however,
does not suffer from these limitations. CWCM, in fact, makes no assumption about the
agents internal beliefs. In addition, the communication among the agents does not exchange
agents internal beliefs, but observations about shared resources that agents directly gather,
and this guarantees the agents a high degree of privacy.
7.4 Resource-Oriented Approaches
The approaches within the resource-oriented family have mainly been proposed by Roos and
Witteveen. We call their approaches resource-oriented because, from their point of view,
the system to be diagnosed is a plan, and the state of such a system is given by the states of
the system resources. The execution of an action can just change the state(s) of one or more
resource(s). These approaches deserve particular attention as they have some similarities
with the CWCM methodology, but there are also a number of relevant differences.
Witteveen, Roos, van der Krogt, and de Weerdt (2005) present the basic framework that
they use and extend in their subsequent works. In this framework, actions are modeled as
atomic plan steps; more precisely, action models are functions that deterministically map
resource states in input into resource states in output. These models therefore represent
just the changes normally caused by actions when they are successfully performed. The
faulty behavior of actions, conversely, is modeled via a very weak abnormal function, which
maps the state of each resource in input to the unknown value. This means that, when an
action fails, the states of the resources handled by that action become unpredictable.
A diagnostic problem arises when the observations received at an execution step are
inconsistent with the nominal predictions made through the action models. This means
that at least one of the actions performed so far behaved abnormally. Witteveen et al.
(2005) introduce the notion of plan diagnosis as a subset of plan actions that, once qualified
as abnormal, make the observations consistent with the predictions made assuming all the
other actions as nominal.
Of course, since there may exist many possible plan diagnoses, it is important to look for
diagnoses that are more preferable than others. Roos and Witteveen (2009) propose a different preference criterion based on the predictive power that each plan diagnosis has. They
therefore introduce the notion of maximally-informative plan diagnosis (maxi-diagnosis) as
a set of plan diagnoses that predict correctly the biggest subset of observations. This no58

fiCooperative Monitoring to Diagnose Multiagent Plans

tion of diagnosis is subsequently refined by the notion of minimal maximally-informative
plan diagnosis (mini-maxi-diagnosis), which is just a subset of maxi-diagnosis such that the
number of failed actions to be assumed is minimal.
In the work by de Jonge et al. (2009), the basic framework is extended: agents are
seen as resources, and action models also includes variables about agents equipment and
environment events (i.e., exogenous events). This extension allows the distinction between
primary and secondary diagnoses. While a primary diagnosis is a plan diagnosis (i.e.,
expressed in terms of failed actions), a secondary diagnosis can be thought of as a second
level diagnosis that tries to explain why a given action failure has occurred.
CWCM tries to resolve the same problem as the one addressed by Roos and Witteveen
(2009): Diagnosing the execution of a MAP. However, action models are significantly different in the two approaches. From Roos and Witteveens point of view, action models are
deterministic functions of nominal behavior only. Whereas in CWCM, we model actions
as relations that easily accommodate both nominal and faulty evolutions. In particular,
faulty evolutions can be nondeterministic, and just partially specified as they support the
unknown value to indicate that no expectations are possible for a given variable.
Another important difference between the two approaches is about the execution of
actions. Roos and Witteveen assume that actions take just one time instant to be performed
and that action execution proceeds synchronously all over the agents. Our CWCM is more
realistic since action execution is asynchronous: even though actions are modeled just in
terms of preconditions and effects, their actual duration is not necessarily one time instant.
As we have seen, in fact, agents cooperate with each other by exploiting the causal and
precedence links that are explicitly defined within our plan model. The plan model adopted
by Roos and Witteveen, instead, mentions explicitly precedence links only, while it does
not include causal links.
Also the process with which a diagnosis is inferred presents substantial differences.
Witteveen et al. (2005) and de Jonge et al. (2009) present a centralized method to carry out
diagnostic inferences. A distributed procedure for qualifying actions as abnormal is proposed
by Roos and Witteveen (2009), but also in this case the detection of a diagnostic problem is
made in a centralized way. Moreover, the methodology proposed by Roos and Witteveen is a
sort of strong committed approach, in the sense that whenever there are some observations,
the system has to infer a diagnosis. On the other hand, our CWCM methodology is fully
distributed both in the detection of a diagnostic problem (i.e., monitoring), and in its
solution. In addition, CWCM is inherently weak committed: observations do not necessarily
trigger a diagnostic process, but diagnosis inferences start after an interpretation of the
observations that either lead to (1) determining an action failure, or (2) determining that a
service produced in favor of another agents action is actually missing. CWCM achieves this
second point by exploiting both direct observations gathered by the agent, and messages
coming from other agents. This means that when observations are not sufficient to either
reach condition (1) or (2), a diagnosis is not inferred.
As said above, de Jonge et al. (2009) introduce a distinction between primary and
secondary diagnosis. Such a distinction can also be found in our methodology. The primary
diagnosis by de Jonge et al. corresponds to our minimum primary action failures (mPADs),
which identify the actions that should be assumed faulty in order to make the plan execution
consistent with the observations. The secondary diagnosis, on the other hand, corresponds
59

fiMicalizio & Torasso

to our refined explanations (refinedExp), in which we associate each action in mPADs with
a set of exogenous events that, consistently with the observations, might have occurred and
hence caused the action failure.
In this paper we also assess the impact of a primary action failure a  mP ADs by
inferring the set of secondary action failures; namely, the subset of actions that fail as an
indirect consequence of the failure of a. Although the identification of secondary failures
would be possible, de Jonge et al. do not take into account the problem.
In conclusion, the CWCM framework can be considered as an extension of the frameworks by de Jonge et al. (2009) and Roos and Witteveen (2009). In fact, the action models
proposed by Roos and Witteveen can be reproduced within our framework by including in
each relation-based model just two entries: one for the deterministic nominal evolution of
the action, and one for the abnormal behavior where all the agent variables become unknown as a consequence of an unpredictable event. These action models could be used by
CWCM as usual to infer a plan diagnosis in a fully distributed way.

8. Conclusion
Plan diagnosis is an essential step to implement robust multiagent planning systems. As
shown in other works (Mi & Scacchi, 1993; Gupta et al., 2012; Micalizio, 2013), in fact, the
explanations provided by a plan diagnosis can steer a repair procedure and make the repair
process more effective.
In this paper we have addressed the problem of plan diagnosis by splitting it into two
subproblems: the detection of action failures, and the actual explanation of the detected
action failures in terms of exogenous events that might have occurred. The detection of action failures is achieved by means of the Cooperative Weak-Committed Monitoring (CWCM)
strategy, which allows agents to cooperate with each other during the monitoring task. Cooperation among agents plays a central role not only for the detection of action failures, but
also for their explanations. The CWCM methodology, in fact, allows each agent to build
a structure (i.e., a trajectory-set), that is an internal representation of the world from the
point of view of the agent itself. Relying on this structure, each agent can infer explanations
for its own action failures without the need of interacting with other agents.
The proposed framework to the diagnosis of MAPs extends previous approaches in
literature. First of all, CWCM is fully distributed and asynchronous. Previous approaches
(see e.g., Kalech & Kaminka, 2011; Roos & Witteveen, 2009; Micalizio & Torasso, 2008),
instead, are all based on some synchronous step (e.g., agents execute actions synchronously).
In our framework an agent can perform its next action as soon as the actions preconditions
are satisfied. To verify this condition, we just impose that agents adhere to a coordination
protocol that guarantees the consistent access to the shared resources.
In addition, we propose here an extension to the relational language for modeling nondeterministic actions (Micalizio & Torasso, 2008). In the previous approach, in fact, we
assume to know in advance all the exogenous events that can affect a given action; in this
paper we are able to deal with partial knowledge about the exogenous events. In particular, we allow to specify just a subset of the effects an exogenous event has on an action
(i.e., some agents variables might become unknown after the event), but we also allow to
specify that an action might be affected by an indefinite event whose effects are completely
60

fiCooperative Monitoring to Diagnose Multiagent Plans

unpredictable (i.e., all agents variables become unknown due to the event). This kind of
extended action model subsumes the action models proposed by Roos and Witteveen, which
just consists of two parts: the nominal action model, and an abnormal model that maps
each agents variable into the unknown value.
Cooperation among agents and nondeterministic action models make CWCM particularly apt to deal with dynamic and partially observable environments. On the one side, the
nondeterministic action models we have discussed here capture unexpected changes in the
environment. On the other side, the cooperative monitoring allows each agent to acquire
information about the environment from the other agents. It is important to note that,
differently from other works where agents exchange each other their internal belief states
(see e.g., Kalech & Kaminka, 2011), in CWCM an agent just needs to communicate what
it observes. This enables agents to keep private their internal beliefs; in addition, agents
could adopt specific policies for deciding what observations should be forwarded to what
agents. Forwarding some observations to more agents, and not just to a single agent as
in the current proposal, might help the agents to discover earlier the outcomes of some
pending actions; we leave this opportunity for future research.
It must also be noted that CWCM just assumes that observations are correct: The
actual state of an agent must not be pruned off the agent belief state due to an erroneous
observation. This assumption is often made also in many model-based approaches to diagnosis (see e.g., Birnbaum et al., 1990; Brusoni, Console, Terenziani, & Theseider Dupre,
1998; Pencole & Cordier, 2005; Roos & Witteveen, 2009; Eiter, Erdem, Faber, & Senko,
2007, just to mention a few). Correctness of the observations, however, does not implies
that observations must be precise. CWCM can in fact consume ambiguous messages given
as a disjunction of values for the same variable (i.e., var = v1  var = v2  . . . var = vn ),
or as a negation of a specific value (i.e., var 6= v). From the point of view of CWCM,
consuming such observations simply corresponds to the selection of states within the belief
state the observations refer to. Although this aspect has not been emphasized in the paper,
the ability of dealing with ambiguous observations enriches the communicative capacities
of the agents. For instance, in an ask-if interaction, a client, rather than answering with
a generic no-info, could give the provider a disjunction of possible resource states among
which, however, the client is incapable to discriminate the actual one. This set of alternative
states is, from the point of view of the provider, much more informative than no-info, and
possibly could lead the provider to determine the actual state of the resource at hand.
From the point of view of the diagnostic inference, we have shown that it is possible to
explain action failures by extracting explanations from the trajectory-sets built by CWCM.
In particular, we have pointed out that assuming action failures independent of each other
might lead to spurious diagnoses. For this reason we have proposed a methodology for
identifying primary action failures and secondary action failures, which are just an indirect
consequence of the primary ones. A simple preference criterion, based on the minimality of
the primary action failures, has been proposed to prefer alternative explanations.
A deep experimental analysis has shown that both the cooperative monitoring and diagnosis are practically feasible. An efficient implementation based on OBDDs is discussed in
the Appendix together with a computational analysis from a theoretical point of view. The
experiments have highlighted that CWCM scales up well with the number of agents, but it is
affected by the level of observability of the environment: the trajectory-sets tend to be big61

fiMicalizio & Torasso

ger as the environment is less observable. However, the experiments demonstrate that the
cooperation is effective even in dealing with very scarcely observable environments. Competence rates for noncooperative solutions, in fact, are comparable with those of CWCM
only when the environment is fully observable; in other situations, instead, CWCM always
exhibits the highest competence.
The proposed framework can be extended in different ways. As mentioned above, we
have so far adopted a careful approach to communication by restricting the agents to talk
with each other only about the exchanged services. However, the agents might be willing
to communicate further pieces of knowledge they have acquired. An interesting possible
extension is to improve the cooperative protocol along this direction. The intuition, in fact,
is that when an agent acquires more information, it could infer the outcome of some of
its pending actions earlier than what it does now. Of course, the communication must not
become a bottleneck, so agents should be able to identify what piece of information is worth
to be forwarded to what agents, and avoid broadcasting every observation to all the agents.
The most important extension we aim at, however, is to relax the assumption that
communication among the agents is always reliable. Removing such an assumption has
many consequences. First of all, the cooperative monitoring protocol should be extended in
order to deal with messages that can be lost. Moreover, Proposition 7, about the safe use
of resources, might no longer be guaranteed by CWCM; thus resources could be accessed
inconsistently. To diagnose these situations we could take a point of view similar to Kalech
and Kaminkas social diagnosis. In fact, erroneous access to resources, could be considered
as coordination failures. This would impact the diagnostic inferences that should no longer
be local, but distributed. That is, as for the monitoring task, also diagnosis should be
performed by means of the cooperation of a number of agents.

Acknowledgments
The authors wish to thank the anonymous reviewers for their insightful comments, that
have substantially contributed to the final shape of this work.

Appendix A. Implementation and Computational Analysis
In this Appendix we first recall some basic OBDD operators and their complexities, and
then we study the computational cost of the most expensive relational operations involved
by the CWCM and diagnostic methodologies discussed above.
A.1 OBDD Operators and their Complexities
The computational analysis we discuss in the next subsection relies on the results presented
by Bryant (1986, 1992). In these works, the author discusses an efficient implementation of
OBDDs operators and their corresponding computational complexities. These results are
summarized in Table 6, where f , f1 , and f2 denote the Boolean functions, encoded by the
reduced function graphs G, G1 , and G2 , respectively. The size of graph G corresponds to
the number of its vertices, and it is represented as |G|. The primitive OBDD operators are
reported in the upper side of Table 6:
62

fiCooperative Monitoring to Diagnose Multiagent Plans

- reduce builds the canonical form of a Boolean function f ; i.e., given a specific variables
ordering, the reduce operator gets a graph G whose size is minimal.
- apply implements binary logical operations between two Boolean functions f1 and f2 ;
the operator works on graphs G1 and G2 encoding the two functions, respectively;
op can be any binary logical operator (, , , ). The computational complexity
in the worst case is O the product of the sizes (i.e., number of vertices) of the two
graphs.
- restrict substitutes a constant b to a variable xi in time almost linear in the number
of vertices within the graph G.
- rename renames a set of variables ~x with a new one ~x0 ; its complexity is exponential
in the number of renamed variables.
- equiv checks the equivalence of the two Boolean functions f1 and f2 ; since this operator
scans the two corresponding graphs simultaneously, the computational complexity is
linear in their sizes.
In the lower side of Table 6 we report the computational cost in time and space for the relational operators join, intersect, union and project that can be obtained by combining
primitive OBDD operators. Observe that, among the relational operators, the projection
is the most expensive; in fact, it is exponential in the number of the (binary) variables to
be removed (see e.g., Torta & Torasso, 2007; Torasso & Torta, 2006 for details).
A.2 CWCM: Computational Analysis
To analyze the computational complexity of CWCM, we consider the high-level algorithm
presented in Figure 10, and focus on the computational cost of performing a single iteration
of the while loop when an action ail is actually performed in the real-world. In such a
situation there are three main steps that hide potentially expensive operations on relations:
 the extension of the current trajectory-set (line 9);
 the refinement of the trajectory-set with the available observations (line 11);
 the detection of the outcomes of the pending actions (line 19, Figure 7).
In the rest of this section we analyze the computational effort of each of these steps.
operator
reduce(f )
apply(op, f1 , f2 )
restrict(xi , b, f )
rename (f , ~x, ~x0 )
equiv(f1 , f2 )

time
O(|G|  log |G|)
O(|G1 |  |G2 |)
O(|G|)
O(|G|  2|~x| )
O(max(|G1 |, |G2 |))

size
|G|
 |G1 |  |G2 |
 |G|
 |G|  2|~x|
N/A

join (f1 , f2 ); union(f1 , f2 );
intersect(f1 , f2 ) (i.e., select)
project(f , {x1 , . . . , xn }, {y1 , . . . , ym })

O(|G1 |  |G2 |)
O(|G1 |  |G2 |)
O((2(nm)  |G|)2 )

 |G1 |  |G2 |
 |G1 |  |G2 |
 2(nm) |G|

Table 6: OBDD operators and their complexity.
63

fiMicalizio & Torasso

A.2.1 Extending the Trajectory-Set
According to equation (7), the operator , which from T r i [1, l] yields a new trajectory-set
T r i [i, l + 1], involves two join operations: one between T r i [1, l] and (ail ), and one between
T r i [1, l] and (ail ). The results of these two operations are subsequently merged into a new
trajectory-set T r i [1, l + 1] via a union operation. To understand the computational cost of
these relational operations, it is necessary to map them into OBDD operators. As already
shown in previous works (see e.g., Torta & Torasso, 2007; Micalizio, 2013), the natural
join can be mapped to the and between two Boolean functions (and hence between two
OBDDs), whereas the union of two relations becomes the Boolean or. Let Gl , Gl+1 , G ,
and G be the OBDDs corresponding to the relations T r i [1, l], T r i [1, l + 1], (ail ), and
(ail ), respectively; the  operator can be mapped to the following expression in terms of
OBDDs operations:
Gl+1 = apply(, apply(, Gl , G ), apply(, Gl , G ))

(14)

Given the operator complexities in Table 6, the computational effort to infer the new
trajectory-set is in the worst case:
O(|Gl+1 |) = O(|Gl |  |G |)  O(|Gl |  |G |)
= O(|Gl |2  |G |  |G |).

(15)

A.2.2 Refinement with Observations
Once the new trajectory-set has been inferred, it is refined with the observations obsik
received by the agent. For the sake of exposition, in equations (8) and (9) we defined
the refinement of a trajectory-set as an intersection between the trajectory-set itself and
the belief state Bki refined with obsik . Note that the extraction of a belief state is a very
expensive operation, thus we try to avoid this operation whenever possible. In this particular
case, since the agent variables V ARki are included within the current trajectory-set, the
refinement operation can be carried out as an intersection between T r i [1, l + 1] and obsik ;
in terms of OBDD operators:
Gref .l+1 = apply(, Gl+1 , Gobsi )
k

(16)

where Gobsi is the OBDD encoding obsik , and Gref .l+1 is the OBDD corresponding to the
k
refined trajectory-set refinedT r i [1, l + 1]. It follows that the computational cost of this
operation is
(17)
O(|Gref .l+1 |) = O(|Gl+1 |  |Gobsi |)
k

A.2.3 Detecting Pending Actions Outcomes
The last step of the CWCM algorithm we consider is the assessment of the outcome of every
action currently within the list of pending actions pActsi . In Section 4, we noted that to
verify the success of a given action aik  pActsi , it is sufficient to check whether the nominal
i
effects of aik are satisfied in every state in Bk+1
(Definition 3). In case such a condition does
not hold, one has to verify whether the expected nominal effects of aik are missing in each
64

fiCooperative Monitoring to Diagnose Multiagent Plans

i
state of Bk+1
(Definition 4). If both checks result in a negative answer (i.e., the belief state
i
Bk+1 is still too ambiguous), action aik remains pending.
i
for explicitly checking these conditions might be parExtracting the belief state Bk+1
ticularly expensive, especially when the trajectory-set grows over time. The extraction of
a belief state through the project operation, in fact, would require the elimination from
T r i [1, l + 1] of all the variables we are not interested in; thus, we would remove the variables
about steps 1, 2, . . . , k, k + 2, . . . , l + 1, that is l  |VARi | variables. As Table 6 shows, the
complexity of project is exponential in the number of variables to be removed, so it could
easily become a bottleneck.
To cope with this problem, we implemented the checking for the ok and f ailed outcomes
in a different way. In particular, from Definition 3 it directly follows:
i
i
.
join effects(aik ) equals Bk+1
Proposition 11 aik has outcome ok iff Bk+1

Proof: The proof is straightforward: by definition aik has outcome ok iff its nominal effects
i
i
i
are satisfied in every state in Bk+1
; the join between Bk+1
and effects(aik ) yields Bk+1
only
i
when the nominal effects are already included in every state in Bk+1 , and hence the action
has outcome ok.

Since Bk+1 is included in refinedT r i [1, +l + 1], the above proposition can be extended
to the whole trajectory-set:
Proposition 12 aik has outcome ok iff
refined T r i [1, l + 1] join effects(aik )equalsrefined T r i [1, l + 1].
That is to say, after the refinement of the trajectory-set with the observations, action aik has
outcome ok iff its nominal effects do not filter out any trajectory from refinedT r i [1, l + 1].
Relying on this proposition, we can verify whether aik has outcome ok in two steps: first,
we build a temporary OBDD maintaining the result of the join between T r i [1, l + 1] and
effects(aik ), and then we check whether the temporary OBDD is equivalent to the original
trajectory-set; in terms of OBDD operators:
outcomeOK? = equiv(Gref.l+1 , apply(, Gref.l+1 , Geffects(ai ) ))
k

(18)

Since the size of Geffects(ai ) is negligible when compared to the size of Gref.l+1 , computak
tional complexity of this check is about O(|Gref.l+1 |2 ).
The f ailed outcome can be checked in a similar way; in this case we want to discover
whether the nominal effects of aik are missing in T r i [1, l + 1]; this happens only when the
negation of the effects effects(aik ) do not represent a possible filter for T r i [1, l + 1] so that
T r i [1, l + 1] join effects(aik ) is again equals to T r i [1, l + 1]. In terms of OBDD operators
outcomeFailed? = equiv(Gref.l+1 , apply(, Gref.l+1 , Geffects(ai ) ))

(19)

k

It is important to note that the OBDD Geffects(ai ) is computed in constant time directly
k
from Geffects(ai ) ; in fact, given a Boolean function f and the corresponding graph Gf , it
k
is sufficient to exchange with each other the 0 and 1 nodes in Gf to obtain the graph
representation of the Boolean function not(f ). Thus, also this check is about O(|Gref.l+1 |2 ).
65

fiMicalizio & Torasso

It follows that the cost for determining the outcomes of the actions in pActsi is:
O(|pActsi |  |G(ref.)l+1 |2 ).

(20)

From equation (20), it is easy to see that the computational cost of the CWCM methodology strongly depends on the amount of available observations. The worst case is in fact
when at a give step l, due to very scarce observations, the number of pending actions is
close to l itself; that is, |pActsi |  l, meaning that almost all the actions performed so far
have outcome pending.
A.3 Diagnosis: Computational Analysis
The computational cost of the diagnostic process is strongly dominated by the cost for
inferring the event-based explanations (EVE ). As we have shown, in fact, it is possible to
extract the set of minimum cardinality primary action failures explanations (mP ADs) from
such a structure. According to Equation 11, the EVE set can be extracted as a projection
of the current trajectory-set T r i [1, l] over the event variables e1 , . . . , el1 ; unfortunately, in
this case there is no way to avoid this expensive operation.
To estimate its computational cost, we have first to consider how many binary variables
are within the OBDD Gl encoding T r i [1, l], and how many (binary) variables we are going to
remove from that OBDD. Each state and event variable in T r i [i, l] is in fact a multi-valued
variable that is actually implemented in terms of a number of binary variables within the
OBDD Gl . The number of required binary variables depends on the size of the domain of
the original high-level variable. Let us assume that d is the size of the largest domain of the
variables in VARi , then we can estimate that we need b = log d binary variables for each
variable mentioned in T r i [1, l] (both state and event variables). It is easy to see that the
number of binary variables required to represent a single belief state is w = b  |VARi |: for
each multi-valued variable in VARi we have b binary variables at OBDD level.
The number of binary variables encoding the trajectory-set T r i [i, l] is therefore p =
l  w + (l  1)  b; in fact, within T r i [1, l], we have l beliefs and l-1 event variables. The cost
of projecting T r i [1, l] over the event variables is therefore:
O((2plw  |Gl |)2 ).

(21)

Once EVE diagnoses have been extracted, it is possible to infer the minimum cardinality
primary failures by exploiting techniques by Torasso and Torta (2003), which are proven to
be polynomial in the size of the OBDD.
A.4 Discussion
A first important result that emerges from the computational analysis above is that the
monitoring of a single execution step with CWCM is not exponential. In fact, we have
shown that each step of its declarative definition can be mapped into a number of OBDD
operators whose complexity is polynomial, provided that the sizes of the involved OBDDs
remain manageable. In particular, we have shown that the only exponential operation used
in the declarative definition, the projection, can be avoided in the actual implementation.
The main concern with CWCM is that the trajectory-set may grow over time as an agent
66

fiCooperative Monitoring to Diagnose Multiagent Plans

performs actions without receiving observations. Consequently, also the computational cost
of CWCM tends to grow over time since the size of the OBDD encoding the trajectoryset may increase. It is important to note, however, that such a growth is not exponential
but quadratic (see equation (15)). In addition, to estimate the computational costs of
both monitoring and diagnosis, we exploited the estimations reported in Table 6; these,
however, are estimates of the very worst possible cases, but in practice these cases are not
very common. Bryant conjectures that, although the theoretical cost of the apply operator
between two OBDDs G1 and G2 is O(|G1 |  |G2 |) in the worst case, in practice the actual
cost is in most of the cases closer to O(|G1 | + |G2 | + |G3 |) where G3 is the resulting OBDD
(Bryant, 1986). Thus also the size of the resulting, intermediate OBDDs plays a central
role in determining the actual computational cost.
In the specific case of CWCM, we have to observe that it is not very common for an
agent to perform a long portion of its plan without receiving observations. The CWCM
allows in fact the agents to communicate with each other; therefore, unless an agent is
completely isolated from others, each agent will likely receive observations coming from the
other agents about the services it has provided them with. This means that, in practice,
the size of the OBDD encoding the trajectory-set should not become intractable because of
the cooperation among the agents, and the experiments we have conducted so far support
this hypothesis.
On the other hand, the diagnostic inferences are slightly more expensive than the monitoring strategy. This because the project operation cannot be avoided in order to infer a
diagnosis. In this case, however, we have to observe that the plan execution has already
been stopped as a consequence of a detected failure. Thus, the diagnosis can take more
time to infer a result since it is not constrained to be on-line.

References
Arasu, A., Babu, S., & Widom, J. (2006). The CQL continuous query language: semantic
foundations and query execution. The International Journal on Very Large Data
Bases, 15 (2), 121142.
Birnbaum, L., Collins, G., Freed, M., & Krulwich, B. (1990). Model-based diagnosis of
planning failures. In Proc. of Association for the Advancement of Artificial Intelligence
(AAAI90), pp. 318323.
Boutilier, C., & Brafman, R. I. (2001). Partial-order planning with concurrent interacting
actions. Journal of Artificial Intelligence Research, 14, 105136.
Brusoni, V., Console, L., Terenziani, P., & Theseider Dupre, D. (1998). A spectrum of
definitions for temporal model based diagnosis. Artificial Intelligence, 102, 3979.
Bryant, R. (1986). Graph-based algorithms for boolean function manipulation. IEEE Transactions on Computers, 35 (8), 677691.
Bryant, R. (1992). Symbolic boolean manipulation with ordered binary-decision diagrams.
ACM Computer Surveys, 24, 293318.
67

fiMicalizio & Torasso

Cordier, M.-O., & Grastien, A. (2007). Exploiting independence in a decentralised and
incremental approach of diagnosis. In Proc. of the International Joint Conference on
Artifical Intelligence (IJCAI07), pp. 292297.
Cox, J. S., Durfee, E. H., & Bartold, T. (2005). A distributed framework for solving the
multiagent plan coordination problem. In Proc. of International Conference on Autonomous Agents and Multiagent Systems (AAMAS05), pp. 821827.
Darwiche, A., & Marquis, P. (2002). A knowledge compilation map. Journal of Artificial
Intelligence Research, 17, 229264.
de Jonge, F., Roos, N., & Witteveen, C. (2009). Primary and secondary diagnosis of multiagent plan execution. Journal of Autonomous Agent and Multiagent Systems, 18 (2),
267294.
Eiter, T., Erdem, E., Faber, W., & Senko, J. (2007). A logic-based approach to finding
explanations for discrepancies in optimistic plan execution. Fundamenta Informaticae,
79 (1-2), 2569.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal
planning domains. Journal of Artificial Intelligence Research, 20, 61124.
Grastien, A., Anbulagan, Rintanen, J., & Kelareva, E. (2007). Diagnosis of discrete-event
systems using satisfiability algorithms. In Proc. of Association for the Advancement
of Artificial Intelligence (AAAI07), pp. 305310.
Grastien, A., Haslum, P., & Thiebaux, S. (2012). Conflict-based diagnosis of discrete event
systems: Theory and practice. In Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning (KR12), pp. 489499.
Gupta, S., Roos, N., Witteveen, C., Price, B., & de Kleer, J. (2012). Exploiting shared
resource dependencies in spectrum based plan diagnosis. In Proc. of Association for
the Advancement of Artificial Intelligence (AAAI12), pp. 2425  2426.
Heger, F. W., Hiatt, L. M., Sellner, B., Simmons, R., & Singh, S. (2005). Results in Sliding
Autonomy for Multi-Robot Spatial Assembly. In Proc. International Symposium on
Artificial Intelligence, Robotics and Automation in Space (iSAIRAS).
Helmert, M. (2009). Concise finite-domain representations for PDDL planning tasks. Artificial Intelligence, 173 (5-6), 503535.
Jonsson, P., & Backstrom, C. (1998). State-variable planning under structural restrictions:
Algorithms and complexity. Artificial Intelligence, 100 (1-2), 125176.
Kalech, M. (2012). Diagnosis of coordination failures: A matrix-based approach. Journal
of Autonomous Agents and Multiagent Systems, 24 (1), 69103.
Kalech, M., & Kaminka, G. A. (2003). On the design of social diagnosis algorithms for
multi-agent teams. In Proc. International Joint Conference on Artificial Intelligence
(IJCAI03), pp. 370375.
Kalech, M., & Kaminka, G. A. (2005). Diagnosing a team of agents: Scaling up. In Proc.
of International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS05), pp. 249255.
68

fiCooperative Monitoring to Diagnose Multiagent Plans

Kalech, M., & Kaminka, G. A. (2007). On the design of coordination diagnosis algorithms
for teams of situated agents. Artificial Intelligence, 171 (8-9), 491513.
Kalech, M., & Kaminka, G. A. (2011). Coordination diagnostic algorithms for teams of
situated agents: Scaling up. Computational Intelligence, 27 (3), 393421.
Kalech, M., Kaminka, G. A., Meisels, A., & Elmaliach, Y. (2006). Diagnosis of multi-robot
coordination failures using distributed CSP algorithms. In Proc. of Association for
the Advancement of Artificial Intelligence (AAAI06), pp. 970975.
Kaminka, G. A., & Tambe, M. (2000). Robust multi-agent teams via socially-attentive
monitoring. Journal of Artificial Intelligence Research, 12, 105147.
Lamperti, G., & Zanella, M. (2002). Diagnosis of discrete-event systems from uncertain
temporal observations. Artificial Intelligence, 137 (1-2), 91163.
Mi, P., & Scacchi, W. (1993). Articulation: an integrated approach to the diagnosis, replanning, and rescheduling of software process failures. In Proc. of Knowledge-Based
Software Engineering Conference, pp. 7784.
Micalizio, R. (2013). Action failure recovery via model-based diagnosis and conformant
planning. Computational Intelligence, 29 (2), 233280.
Micalizio, R., & Torasso, P. (2007a). On-line monitoring of plan execution: a distributed
approach. Knowledge-Based Systems, 20 (2), 134142.
Micalizio, R., & Torasso, P. (2007b). Plan diagnosis and agent diagnosis in multi-agent
systems. In Proc. Congress of the Italian Association for Artificial Intelligence
(AI*IA07), Vol. 4733 of LNCS, pp. 434446.
Micalizio, R., & Torasso, P. (2008). Monitoring the execution of a multi-agent plan: Dealing
with partial observability. In Proc. of European Conference on Artificial Intelligence
(ECAI08), pp. 408412.
Micalizio, R., & Torasso, P. (2009). Agent cooperation for monitoring and diagnosing a
MAP. In Proc. of Multiagent System Technologies (MATES09), Vol. 5774 of LNCS,
pp. 6678.
Micalizio, R., Torasso, P., & Torta, G. (2006). On-line monitoring and diagnosis of a team
of service robots: a model-based approach. AI Communications, 19 (4), 313349.
Nebel, B. (2000). On the compilability and expressive power of propositional planning
formalisms. Journal of Artificial Intelligence Research, 12, 271315.
Pencole, Y., & Cordier, M. (2005). A formal framework for the decentralized diagnosis of
large scale discrete event systems and its application to telecommunication networks.
Artificial Intelligence, 164, 121170.
Reiter, R. (1987). A theory of diagnosis from first principles. Artificial Intelligence, 32 (1),
5796.
Roos, N., & Witteveen, C. (2009). Models and methods for plan diagnosis. Journal of
Autonomous Agent and Multiagent Systems, 19 (1), 3052.
Sampath, M., Sengupta, R., Lafortune, S., Sinnamohideen, K., & Teneketzis, D. (1995).
Diagnosability of discrete event systems.. IEEE Transactions on Automatic Control,
40 (9), 15551575.
69

fiMicalizio & Torasso

Sellner, B., Heger, F., Hiatt, L., Simmons, R., & Singh, S. (2006). Coordinated multiagent teams and sliding autonomy for large-scale assembly. IEEE - Special Issue on
Multi-Robot Systems, 94 (7), 1425  1444.
Steinbauer, G., & Wotawa, F. (2008). Enhancing plan execution in dynamic domains using
model-based reasoning. In Intelligent Robotics and Applications, First International
Conference, (ICIRA08), Vol. 5314 of LNAI, pp. 510519.
Tambe, M. (1998). Implementing agent teams in dynamic multi-agent environments. Applied
Artificial Intelligence, 12 (2-3), 189210.
Torasso, P., & Torta, G. (2003). Computing minimum-cardinality diagnoses using OBDDs.
In German Conference on AI (KI03), Vol. 2821 of LNCS, pp. 224238.
Torasso, P., & Torta, G. (2006). Model-based diagnosis through OBDD compilation: A complexity analysis. In Reasoning, Action and Interaction in AI Theories and Systems,
Vol. 4155 of LNCS, pp. 280298.
Torta, G., & Torasso, P. (2007). On the role of modeling causal independence for system
model compilation with OBDDs. AI Communications, 20 (1), 1726.
Weld, D. S. (1994). An introduction to least commitment planning. AI Magazine, 15 (4),
2761.
Witteveen, C., Roos, N., van der Krogt, R., & de Weerdt, M. (2005). Diagnosis of single
and multi-agent plans. In Proc. of International Conference on Autonomous Agents
and Multiagent Systems (AAMAS05), pp. 805812.
Yan, Y., Dague, P., Pencole, Y., & Cordier, M.-O. (2009). A model-based approach for
diagnosing fault in web service processes. Journal of Web Service Research., 6 (1),
87110.

70

fiJournal of Artificial Intelligence Research 51 (2014) 707-723

Submitted 07/14; published 12/14

On Minimum Representations of Matched Formulas
Ondrej Cepek
Stefan Gursky
Petr Kucera

ondrej.cepek@mff.cuni.cz
stevko@mail.ru
kucerap@ktiml.mff.cuni.cz

Charles University in Prague
Faculty of Mathematics and Physics
Department of Theoretical Computer Science
Malostranske nam. 25, 118 00 Praha 1, Czech Republic

Abstract
A Boolean formula in conjunctive normal form (CNF) is called matched if the system of
sets of variables which appear in individual clauses has a system of distinct representatives.
Each matched CNF is trivially satisfiable (each clause can be satisfied by its representative
variable). Another property which is easy to see, is that the class of matched CNFs is not
closed under partial assignment of truth values to variables. This latter property leads to
a fact (proved here) that given two matched CNFs it is co-NP complete to decide whether
they are logically equivalent. The construction in this proof leads to another result: a much
shorter and simpler proof of p2 -completeness of Boolean minimization for matched CNFs.
The main result of this paper deals with the structure of clause minimum CNFs. We prove
here that if a Boolean function f admits a representation by a matched CNF then every
clause minimum CNF representation of f is matched.

1. Introduction
In this paper we study the class of matched formulas introduced by Franco and Van Gelder
(2003). Given a formula  in conjunctive normal form (CNF) we consider its incidence
graph I() defined as follows. I() is a bipartite graph with one part consisting of clauses
of  and the other part containing the variables of . An edge {C, x} for a clause C and
variable x is in I() if x appears in C. It was observed by Aharoni and Linial (1986),
and Tovey (1984) that if I() admits a matching (i.e. a set of pairwise disjoint edges) of
size m (where m is the number of clauses in ), then  is satisfiable. Later the formulas
satisfying this condition were called matched formulas by Franco and Van Gelder (2003).
Since a matching of maximum size in a given graph can be found in polynomial time (e.g.,
Lovasz & Plummer, 1986), we can check whether a given formula is matched. Given an
arbitrary CNF  we can measure how far it is from being matched by considering its
maximum deficiency   (), the number of clauses which remain unmatched in a maximum
matching of I(). A formula  is thus matched iff   () = 0. A weaker notion of deficiency
() = m  n (where m is the number of clauses and n the number of variables in ) is also
often considered.
Since their introduction, matched formulas were considered as a base class in parameterized algorithms for satisfiability (e.g., for an overview of parameterized algorithms theory
see Flum & Grohe, 2006). In particular, Fleischner, Kullmann, and Szeider (2002) show
that satisfiability of the formulas whose maximum deficiency is bounded by a constant
c
2014
AI Access Foundation. All rights reserved.

fiCepek, Gursky, & Kucera

can be decided in polynomial time. This result was later improved by Szeider (2003) to
an algorithm for satisfiability parameterized with maximum deficiency of a formula. Parameterization based on backdoor sets with respect to matched formulas were considered
by Szeider (2007).
Several generalizations of matched formulas were considered in the literature, too. Kullmann (2000) generalized the class of matched formulas into the class of linearly satisfiable
formulas and Kullmann (2003) studied autarkies based on matchings. Another generalization was considered by Szeider (2005) as classes of bi-clique satisfiable and var-satisfiable
formulas. Unfortunately, for both bi-clique and var-satisfiable formulas it is hard to check
if a formula falls into one of these classes (Szeider, 2005).
The results listed in the previous paragraphs show that matched formulas play a significant role in the theory of satisfiability solving which is, without any doubt, one of the
most studied problems in theoretical computer science that has many practical applications.
Despite this fact, little is known about the structure of matched CNFs. We say that a CNF
 representing a function f is irredundant if it is set-minimal representation of f , i.e. if for
any clause C in  we have that 0 =  \ {C} does not represent f . We say that  is a prime
CNF representing f if all clauses in  are prime implicates of f , where a clause C is an
implicate of f if it is satisfied by all assignments satisfying f and it is a prime implicate if it
is a set-minimal implicate of f (considering a clause as a set of literals). If we only say that
a CNF  is prime without mentioning the function f in question we implicitly consider f to
be the function represented by . It is not hard to come up with examples of matched CNFs
such that some logically equivalent prime and irredundant CNFs are not matched. This
is quite an interesting phenomenon which does not occur in most classes with polynomial
time satisfiability testing such as quadratic CNFs (also 2-CNFs, i.e. CNFs consisting of
clauses with at most two literals), Horn CNFs (a CNF is Horn if every clause in it contains
at most one positive literal), and their various generalizations, for which once a CNF is
in the class, all logically equivalent prime CNFs are guaranteed to be in the class as well.
This brings an interesting question: given a (nonprime) matched CNF does there exist at
least one equivalent prime CNF which is also matched? In this paper we give an affirmative
answer to this question. This answer may seem to be quite intuitive because usually it is
enough to consider prime implicates of a function when studying its CNF representations,
however, the proof of this answer is not easy.
Another problem we study in this paper is Boolean minimization of matched CNFs.
The Boolean minimization problem (BM) can be stated as follows: given a CNF find a
logically equivalent CNF with a minimum possible number of clauses. The number of
clauses can be viewed as a number of rules or implicates in a representation of a knowledge
base and it is a standard measure used in this context. One can also consider the length
of the formula, i.e. the total number of literal occurrences in the formula, as a measure
of optimality, in this paper we use the number of clauses as a measure and we leave as
an open question whether the results in this paper could be extended to the case of the
formula length as well. The optimization version of the Boolean minimization problem can
be turned into a decision version by adding a number k and asking whether there exists a
logically equivalent CNF with at most k clauses. Umans (2001) showed that the decision
version of BM is p2 -complete (e.g., for related results see the review paper Umans, Villa,
& Sangiovanni-Vincentelli, 2006). Buchfuhrer and Umans (2011) later showed that BM is
708

fiOn Minimum Representations of Matched Formulas

p2 -complete when considering general formulas of constant depth as the input and output
to the Boolean minimization problem.
It is also long known that BM is NP-hard already for some classes of CNFs where
SAT is solvable in polynomial time. Maybe a best known example is the class of Horn
CNFs where the NP-hardness with respect to both output measures was proved (Ausiello,
DAtri, & Sacca, 1986; Boros & Cepek, 1994; Cepek, 1995; Hammer & Kogan, 1993; Maier,
1980). There exists a hierarchy of tractable subclasses of Horn CNFs for which there are
polynomial time minimization algorithms, namely acyclic and quasi-acyclic Horn CNFs
(Hammer & Kogan, 1995), and CQ Horn CNFs (Boros, Cepek, Kogan, & Kucera, 2009).
There are also few heuristic minimization algorithms for Horn CNFs (Boros, Cepek, &
Kogan, 1998).
The complexity of BM for matched CNFs does not fit the above picture. Despite the fact
that SAT is trivial for matched CNFs, BM for this class is p2 -complete, i.e. as hard as for
the general case. This fact was proved by Gursky (2011), where the proof modifies the proof
for the general case by Umans (2001). In this paper we give a much simpler proof of the
same fact which is based on an observation, that equivalence testing is co-NP-complete for
matched CNFs. We also study the structure of clause minimum CNFs. Based on the above
mentioned result concerning prime CNFs we prove that if a Boolean function f admits a
representation by a matched CNF then every clause minimum CNF representation of f is
matched. This is the main result of the current paper.
The paper is structured as follows. We start by introducing the necessary notation,
definitions and basic results in Section 2. In Section 3 we prove that testing logical equivalence for matched CNFs is co-NP-complete and further use the idea from this proof to show
that BM for matched formulas is p2 -complete. This is a known fact, but the current proof
is much shorter and simpler. Section 4 studies prime representations of functions defined
by matched CNFs (possibly nonprime). We prove that every such function has at least
one prime representation which is matched. Finally, in Section 5 we study the structure of
clause minimum representations of functions defined by matched CNFs. Using the result
from Section 4 we prove that if a Boolean function f admits a representation by a matched
CNF then every clause minimum CNF representation of f is matched. Section 6 concludes
the paper with closing remarks.

2. Definitions and Results
We shall start with the basic definitions of the notions we need in this paper. We shall also
recall the results we shall use in this paper.
2.1 Boolean Functions
A Boolean function of n variables is a mapping f : {0, 1}n  {0, 1}. A literal is either a variable (x, called positive literal ) or its negation (x or x, called negative literal ). A clause is
a disjunction of literals. We assume that no clause contains both positive and negative literals of the same variable. Formula  is in conjuntive normal form (CNF) if it is a conjuction
of clauses (we also say that  is a CNF formula). We shall often treat a clause as a set
of its literals and a CNF formula as a set of its clauses. Thus || will denote the number
of clauses in . It is a well known fact that every Boolean function can be represented by
709

fiCepek, Gursky, & Kucera

a CNF formula (e.g., Genesereth & Nilsson, 1987). If two CNF formulas 1 and 2 define
the same function, we say that they are equivalent and we denote this fact with 1  2 .
A CNF  is called clause minimum if for every CNF  such that    we have ||  ||.
Clause C is called an implicate of f if every assignment ~x  {0, 1}n satisfying f (i.e.
f (~x) = 1) also satisfies C (i.e. C(~x) = 1). We say that a clause C1 subsumes a clause C2 , if
every literal from C1 occurs also in C2 (i.e. C1  C2 ). C is a prime implicate of a function
f if it is an implicate of f and there is no other implicate C 0 of f subsuming C (i.e. C
is a set-minimal implicate of f ). We say that CNF formula  representing function f is a
prime representation of f if it contains only prime implicates of f (if we refer to a prime
CNF  without specifying a function f we consider the function which is represented by
). A CNF formula  is irredundant if there is no sub-CNF 0   which represents the
same function as .
An assignment t which assigns values to only a subset of (possibly to all) variables of
a function f on n is called a partial assignment. Formally, a partial assignment can be
viewed as a mapping t : Y 7 {0, 1} where Y is a subset of variables of f . Given a CNF ,
(t) denotes the CNF after applying a partial assignment t. In particular (t) is produced
from  in the following way: Clauses which contain some literal which is satisfied by t
(assigned value 1) are removed from , occurences of literals on variables from Y which are
not satisfied by t are removed from all clauses in .
2.2 Resolution
We say that two clauses have a conflict in variable x if there is a positive occurrence of
f1  x) and
x in one clause and a negative occurrence in the other. Two clauses C1 = (C
f
f
f
C2 = (C2  x) are resolvable over x if C1 and C2 do not have a conflict in any variable. We
f1  C
f2 and this disjunction is called a resolvent of the parent clauses
write R(C1 , C2 ) = C
C1 and C2 .
Let  be a CNF formula representing a Boolean function f , we say that C can be derived
from  by a series of resolutions if there is a sequence of clauses C1 , . . . , Ck = C such that
every Ci , 1  i  k, either belongs to , or Ci = R(Cj1 , Cj2 ), where j1 , j2 < i. Such a series
of resolutions is also called a resolution proof of C from . A resolution proof of an empty
clause (denoted as ) from an unsatisfiable formula is called refutation. The length of a
resolution proof is the number of clauses in the sequence.
It is a well known fact that for any Boolean function the resolvent of two implicates
is again an implicate (e.g., Buning & Lettmann, 1999). Another well known fact is that
every prime implicate of f can be derived from any CNF representation  of f by a series
of resolutions (e.g., Buning & Lettmann, 1999).
We shall also use the notions of regular and tree-like resolution proofs. A resolution
proof is a tree-like resolution proof if every occurrence of a clause in the proof is used at
most once as the premise of a resolution where the only clause not used as a premise of a
resolution is the conclusion; a tree-like resolution proof can be represented as a tree, where
the leaves are labelled with input clauses, and the root of the tree with the conclusion of
the proof. The depth of a tree-like resolution proof T is then the length of a longest path
from a leaf to the root in T . A resolution proof is regular if in any path in the proof from
an input clause to the conclusion, no variable is resolved more than once.
710

fiOn Minimum Representations of Matched Formulas

It can be observed that if  is an unsatisfiable CNF, then it has a regular tree-like
refutation (Urquhart, 2011), basically we can turn any resolution derivation to a tree-like
resolution derivation by repeating clauses if necessary. Then any tree-like refutation can be
turned into a regular tree-like refutation (Tseitin, 1983; Urquhart, 1995, 2011). It can be
further observed that if C is an implicate which can be derived by a series of resolutions
from , then there is a clause C 0  C which can be derived by a regular tree-like resolution
T satisfying that no variable from C 0 is resolved in T . Indeed, if C is an implicate of , then
let t be the partial assignment which assigns false to all literals in C. It follows that (t)
is an unsatisfiable formula, and thus it has a regular tree-like refutation T 0 . If we put back
the falsified literals from C and the clauses satisfied by t, we get a resolution derivation of
a sub-CNF C 0 from . The following proposition now follows immediately.
Lemma 2.1 Let  be a CNF and let C be a prime implicate of , then C can be derived
by a regular tree-like resolution from .
2.3 Exclusive Sets of Implicates of a Boolean Function
In this section we recall the definition of exclusive sets of implicates of a Boolean function
and we state some of their properties, which were shown by Boros, Cepek, Kogan, and
Kucera (2010).
Let us first introduce the following notation. By I p (f ) we shall denote the set of all
prime implicates of a function f . By I(f ) we shall denote the resolution closure of I p (f ),
i.e. an implicate C of f belongs to I(f ) if it can be derived by a series of resolutions from
I p (f ).
Definition 2.2 (Boros et al., 2010) Let f be a Boolean function and let X  I(f ) be a
set of clauses. We shall say, that X is an exclusive set of clauses of f if for every pair of
resolvable clauses C1 , C2  I(f ) the following implication holds:
R(C1 , C2 )  X = C1  X and C2  X ,
i.e. the resolvent belongs to X only if both parent clauses are in X . If the function f is
clear from the context, we shall simply say that X is an exclusive set.
We shall recall some of the properties of exclusive sets, which were proved by Boros
et al. (2010) and which we will use in this paper.
Lemma 2.3 (Boros et al., 2010) Let A, B  I(f ) be exclusive sets of implicates of f , then
both A  B and A  B are also exclusive sets of implicates of f .
Theorem 2.4 (Boros et al., 2010) Let f be an arbitrary Boolean function, let C1 , C2  I(f )
be two distinct sets of clauses which both represent f , and let X  I(f ) be an exclusive set
of clauses. Then C1  X  C2  X , i.e. both represent the same function.
Based on this proposition we define an exclusive component of a Boolean function.
Definition 2.5 (Boros et al., 2010) Let f be an arbitrary Boolean function, X  I(f )
be an exclusive set of clauses of f , and C  I(f ) be a set of clauses which represents f .
The Boolean function fX represented by the set C  X is called the X -component of the
function f . We shall simply call a function g an exclusive component of f , if g = fX for
some exclusive subset X  I(f ).
711

fiCepek, Gursky, & Kucera

Theorem 2.4 guarantees that the X -component fX is well defined for every exclusive set
X  I(f ). Theorem 2.4 has the following corollary.
Corollary 2.6 (Boros et al., 2010) Let C1 , C2  I(f ) be two distinct sets of clauses such
that C1  C2  f , i.e. such that both sets represent f , and let X  I(f ) be an exclusive set
of clauses. Then (C1 \ X )  (C2  X ) also represents f .
2.4 Autarkies
Autark assignments were introduced by Monien and Speckenmeyer (1985) and they are
defined as follows.
Definition 2.7 Let  be a CNF on the set V of variables, let Y  V be a subset of
variables, let L = {x | x  Y }  {x | x  Y } be the corresponding set of literals, and let
t : Y 7 {0, 1} be a partial assignment on . Then t is an autarky on  if for every clause
C   either C  L =  or C is satisfied by t.
An autarky is a special type of partial assignment which satisfies every clause in which
it substitutes a value for some literal. We shall prove two simple lemmas about autarkies
which will be needed later in this paper. The first lemma was (in a different notation)
shown by Kullmann (2000) as Lemma 3.13, but we will give a short proof here as well to
make this paper self-contained.
Lemma 2.8 Let  be a CNF on the set V of variables which represents a function f . Let
Y  V be a subset of variables, and let t : Y 
7 {0, 1} be an autarky on . Then t is an
autarky on I(f ).
Proof : Since all clauses in I(f ) can be derived from  by resolution, it will suffice to
show that resolution preserves the autarky properties, namely that if the parent clauses
are satisfied by t whenever they contain a literal from L = {x | x  Y }  {x | x  Y },
then so does the resolvent. Let C, C1 , C2  I(f ) be clauses such that C = R(C1 , C2 ). Let
`  L be a literal in C. If ` is satisfied by t we are done, so let us asssume that ` is not
satisfied by t. Clause C inherited ` from one of its parent clauses so let us assume without
loss of generality `  C1 . By the autarky property, C1 must be now satisfied by t, so it
must contain another literal `0  L satisfied by t. Now there are two possibilities: either
`0  C (clause C inherited both ` and `0 from C1 ) in which case C is satisfied by t and we
are done, or `0 6 C which means that R(C1 , C2 ) resolves over `0 . That implies `0  C2 , i.e.
C2 contains a literal from L not satisfied by t. Thus, by the autarky property, C2 must be
satisfied by t, so it must contain another literal `00  L satisfied by t. However, in this case
C inherits `00 from C2 , which finishes the proof.
Corollary 2.9 Let  be a CNF on the set V of variables which represents a function f .
Let Y  V be a subset of variables, and let t : Y 7 {0, 1} be an autarky on . Let   I(f )
be an arbitrary representation of f . Then t is an autarky on .
Let us mention that Corollary 2.9 would not hold without the assumption   I(f ).
Consider e.g. a CNF  = (x  y)  z and a CNF  = (x  y)  (z  y)  (z  y). It should be
obvious that   , i.e. both CNFs represent the same function f , but  6 I(f ). Now if t
712

fiOn Minimum Representations of Matched Formulas

is an assignment which sets y to 1, t is autarky on . On the other hand t is not autarky
on  because (z  y) is not satisfied by t.
Lemma 2.10 Let  be a CNF on the set V of variables, let Y  V be a subset of variables,
let L = {x | x  Y }  {x | x  Y } be the corresponding set of literals, and let t : Y 7 {0, 1}
be an autarky on . Then (t) represents an exclusive component fX of f defined by the
exclusive set of clauses
X = {C  I(f ) | C  L = }.
Proof : It suffices to show that X is an exclusive subset of I(f ) Let C, C1 , C2  I(f ) be
clauses such that C = R(C1 , C2 ) and C  X . Let us assume by contradiction that one of
the parent clauses, say C1 , does not belong to X , which means that there exists `  C1  L.
Since ` 6 C, R(C1 , C2 ) must resolve over `, which implies `  C2 . However, one of `, ` is not
satisfied by t, so the corresponding clause (one of C1 , C2 ) must contain some other literal
`0  L which is satisfied by t because t is an autarky. But now we get `0  C contradicting
the assumption C  X .
Since t is an autarky on  it follows that (t) =   X and since   I(f ) and X is an
exclusive set of implicates of f , it follows by Theorem 2.4 that (t) =   X  I(f )  X
defines an exclusive compontent fX .
2.5 Matched Formulas
In this subsection we shall define the key concept of this paper. This concept is based on
graph properties, so to this end we shall use standard graph terminology (e.g., see Bollobas,
1998). Given an undirected graph G = (V, E), a subset of edges M  E is a matching in
G if the edges in M are pairwise disjoint. A bipartite graph G = (A, B, E) is an undirected
graph with disjoint sets of vertices A and B, and the set of edges E satisfying E  A  B.
For a set W of vertices of G, let (W ) denote the neighbourhood of W in G, i.e. the set of
all vertices adjacent to some element of W . We shall use the following well-known result
on matchings in bipartite graphs:
Theorem 2.11 (Halls Theorem  Hall, 1935; Lovasz & Plummer, 1986) Let G = (A, B, E)
be a bipartite graph. A matching M of size |M | = |A| exists if and only if for every subset
S of A we have that |S|  |(S)|.
Now we are ready to define matched formulas.
Definition 2.12 Let  = C1  . . .  Cm be a CNF on n variables X = {x1 , . . . , xn }. We
shall associate a bipartite graph I() = (, X, E) with  (also called the incidence graph of
), where the vertices correspond to clauses in CNF  and the variables X. A clause Ci is
connected to a variable xj (i.e. {Ci , xj }  E) if Ci contains xj or xj . A CNF  is matched
if I() has a matching of size m, i.e. if there is a matching which pairs each clause with a
unique variable.
Note that a matching of maximum size in a given graph can be found in polynomial
time (e.g., Lovasz & Plummer, 1986) and thus we can test in polynomial time whether given
CNF is matched. The fact that a clause Ci is matched to a variable xj in a matching M
will be denoted as {Ci , xj }  M . A variable which is matched to some clause in matching
713

fiCepek, Gursky, & Kucera

M is called matched in M , it is free in M otherwise. Note, that a matched CNF is trivially
satisfiable. If a clause Ci is matched to variable xj , then we can simply assign xj a value
which will satisfy Ci . The name matched was given to these formulas by Franco and
Van Gelder (2003), although they were already considered by Aharoni and Linial (1986),
and Tovey (1984).

3. Equivalence Testing and Hardness of Clause Minimization of Matched
Formulas
Following a definition given by Cepek, Kucera, and Savicky (2012) a class of CNFs X is
called tractable if it satisfies the following four properties.
 Recognition: Given an arbitrary CNF  it is possible to decide in polynomial time
with respect to the size of  whether   X .
 Satisfiability: Given an arbitrary CNF   X it is possible to decide in polynomial
time with respect to the size of  whether  is satisfiable.
 Partial assignment: Given an arbitrary CNF   X , if  is produced from  by fixing
some variables to 0 or 1 and substituting these values into , then   X .
 Prime representations: Given an arbitrary CNF   X , if  represents a function f
then all prime CNF representations of f belong to X .
It was shown by Cepek et al. (2012) that given two CNFs from a tractable class, it
can be tested in polynomial time, whether these two CNFs are logically equivalent or not.
The class of matched CNFs clearly satisfies the first two tractability conditions, but fails
to satisfy the remaining two. Costructing a counterexample to the third property is easy.
The CNF
(x  y  z)  (x  y  z)  (x  y  z)
is clearly matched, but a partial assignment x  0 creates a CNF
(y  z)  (y  z)  (y  z)
that is not matched. We defer the counterexample to the fourth property to the next
section. In the light of these findings it is an interesting question what is the complexity
of equivalence testing for matched CNFs. Despite the fact that satisfiability is trivial for
matched CNFs, equivalence testing is co-NP-complete.
Matched equivalence
Instance :

Two matched CNFs  and 

Question : Is   ?
Theorem 3.1 The problem Matched equivalence is co-NP-complete.
714

fiOn Minimum Representations of Matched Formulas

Proof : A nondeterministic polynomial procedure checking that the two CNFs are not
equivalent simply guesses an assignment t and checks whether (t) 6= (t). The problem
Matched equivalence is thus in co-NP.
To show co-NP-hardness we reduce from the problem of checking that a given CNF 
is unsatisfiable (this problem is a prominent example of a co-NP-complete problem as its
complement is the satisfiability problem, e.g., see Garey & Johnson, 1979). Let  be an
arbitrary CNF on n variables and m clauses, in particular let  = C1  C2  . . .  Cm . Let
us define a clause D = (a1  a2  . . .  am ) on m new variables not occuring in . Now let
us define two CNFs:
 = (C1  D)  (C2  D)  . . .  (Cm  D)
 = D
Both  and  are obviously matched, since each clause Ci0 = (Ci  D) can be matched to
a variable ai . Now we have that    iff   , i.e. iff  is unsatisfiable. This follows
directly from the fact that     D    . We have reduced a co-NP-complete problem
of unsatisfiability to the problem Matched Equivalence and thus the problem Matched
Equivalence is co-NP-complete as well.
The fact, that equivalence testing is co-NP-hard, is probably the principal reason behind
the fact proved by Gursky (2011) that clause minimization of matched CNFs is p2 -complete.
The proof by Gursky (2011) basically follows the proof of p2 -completeness of general CNFs
presented by Umans (1999), and Buchfuhrer and Umans (2011) and is quite long and
complicated. Here we present a much shorter and simpler proof based on a similar idea as
the proof for the hardness of equivalence testing.
Matched minimization
Instance :

A matched CNF  and an integer k

Question : Is there a CNF  equivalent to  with at most k clauses?
Theorem 3.2 The problem Matched minimization is p2 -complete.
Proof : Since Matched Minimization is a special case of Boolean minimization, and it
is known that Boolean minimization is p2 -complete, Matched Minimization must be in
p2 . To see that this problem is p2 -hard, we reduce the p2 -complete Boolean minimization
to it.
Let (, k) be an instance of Boolean minimization where  = C1  C2  . . .  Cm . Now
let us repeat the construction from the proof of Theorem 3.1. Let a1 , a2 , . . . , am be new
variables that do not occur in . Let then  be a matched CNF defined by   (a1  a2 
0 where C 0 = (C  a  a  . . .  a ) for 1  i  m.
. . .  am ), that is  = C10  C20  . . .  Cm
i
1
2
m
i
The instance of Matched minimization is now (, k).
Let (, k) be a positive instance of Boolean minimization. Then there exists CNF
 = D1  D2  . . .  Dk0 (with k 0  k) that is equivalent to . Let  be a CNF equivalent to
  (a1  a2  . . .  am ) that is let  = D10  D20  . . .  Dk0 0 where Di0 = Di  a1  a2  . . .  am
715

fiCepek, Gursky, & Kucera

for 1  i  k 0 . Clearly  is equivalent to  and has at most k clauses. Therefore (, k) is a
positive instance of Matched minimization.
To see the other direction let (, k) be a positive instance of Matched minimization
and let  be a CNF equivalent to  with at most k clauses. Let  be a CNF originating
from  by a partial assignment that sets all a-variables to zero and sets no other variable.
Since  is equivalent to  and that is equivalent to   (a1  a2  . . .  am ), we have that
 is equivalent to . Clearly ||  ||  k and since  is equivalent to  we conclude that
(, k) is a positive instance of Boolean minimization.
Remark 3.3 Since all occurrences of a-variables in  in the proof of Theorem 3.2 were
positive, every resolution from  keeps all a-variables in every derived clause. We can assume
that  is prime and therefore every clause of  also contains all a-variables positively and
thus in fact  has the same number of clauses as .

4. Prime Representations of Matched Formulas
It is not difficult to see that unlike some well-behaved classes of CNFs (such as e.g. Horn
CNFs or quadratic CNFs) for which all prime and irredundant CNFs lie inside the class,
this is not the case for matched CNFs. Consider the CNF
(a  b)  (b  c)  (c  a)
which is matched and a logically equivalent CNF
(a  b)  (b  a)  (c  b)  (b  c)
which is not matched despite being prime and irredundant. Thus it is a legitimate question,
whether given a (nonprime) matched CNF, there exists at least one logically equivalent
prime and irredundant CNF which is also matched. In the rest of this section we will prove
an affirmative answer to this question. Let us start with a simple but useful observation.
Observation 4.1 Let  = C1 . . .Cm be a matched CNF and let C be a clause derived by
a regular tree-like resolution derivation T from . Let C = R(D1 , D2 ), where D1 = (A1  z)
and D2 = (A2  z), i.e. the resolution is over z. Let T1 denote the subtree of T rooted at
D1 , and let T2 denote the subtree of T rooted at D2 . If Ci  , i  {1, . . . , m} is a leaf
clause in both T1 and T2 , then Ci contains neither z nor z and thus it cannot be matched
to z in any matching for .
Proof : Since T is regular, the only resolution over z in T is C = R(D1 , D2 ). Thus there
can be no z in T1 and no z in T2 , since then they would be in D1 and D2 respectively as
well. Thus Ci which is in both T1 and T2 cannot contain z at all.
The following lemma will allow us to exchange one free variable with a matched variable
in any matching for a given matched CNF .
Lemma 4.2 Let  = C1  . . .  Cm be a matched CNF and let M be a matching for . Let
D be a clause derived by a regular tree-like resolution T from . Let x  D be a variable
which is free in M , then there is a variable y  D matched in M and a matching M 0 for 
which satisfy the following property: If X denotes the set of variables which are matched
in M , and X 0 denotes the set of variables matched in M 0 , then X 0 = (X \ {y})  {x}.
716

fiOn Minimum Representations of Matched Formulas

Proof : We shall proceed by induction on the depth of the regular tree-like resolution
proof T of D. If D is in , then we set y to be the variable matched with D in M and

n
o n
o
M 0 := M \ {D, y}  {D, x} .
Now let us assume that D = R(D1 , D2 ), where D1 and D2 are either clauses in , or
they are derived by a regular tree-like resolution from . Suppose the resolution is over a
variable z and let us denote D1 = (A1  z), D2 = (A2  z). For i = 1, 2 let Ti denote the
subtree rooted at Di , Li the set of leaf clauses in Ti , i the sub-CNF of  formed by clauses
in Li , Mi the sub-matching of M on clauses from i , and Xi the set of variables matched
in Mi .
First let us assume that variable x  A1 \ A2 . Let us without loss of generality assume
that x appears positively in D1 (otherwise we can switch the polarity of x in ), thus
D1 = (A01  x  z), where A01 = A1 \ {x}. Now we can use the induction hypothesis on the
subtree T1 rooted at D1 , and matching M1 on 1 . It follows that there is a matching M10
on 1 in which x is a matched variable and there is a variable y1 in D1 which is matched
in M1 but free in M10 . Moreover if X10 denotes the set of variables matched in M10 , then
X10 = (X1 \ {y1 })  {x}. We can extend the matching M10 to the whole  by adding pairs
matching clauses in L2 \L1 to variables in X2 \X1 as in M , let the new matching be denoted
M 00 . If y1 6= z, then y1 occurs in D and we can set M 0 = M 00 .
If y1 = z, then it is a free variable in M 00 . Let M200 denote the sub-matching of M 00 on
clauses of 2 . Now we can use induction hypothesis on 2 , its resolvent D2 , and variable
y1 = z (playing role of the free variable). By this we find a matching M2 for 2 and a
variable y in D2 such that y1 is matched in M2 , y is free in M2 while it was matched in M200 .
In particular if X2 denotes the set of matched variables in M2 and X200 denotes the set of
variables matched in M200 , then X2 = (X200 \ {y})  {y1 }. We can now extend the matching
M2 to the whole formula  by adding pairs matching clauses in L1 \ L2 to variables X100 \ X200
as in M 00 (here X100 denotes the set of variables matched in M 00 to leaves of T1 ). In this
way we obtain the desired matching M 0 . It is clear that y 6= z and thus y  D. Moreover
X 0 = (X \ {y})  {x}.
Now, let us assume x  A1  A2 . By Observation 4.1 we have that z 6 X1  X2 . Let
i  {1, 2} be such that z 6 Xi . Now let us use induction hypothesis on i and variable
x. We get a matching Mi0 for formula i which can be extended to the whole  by adding
the pairs matching clauses in L3i \ Li to variables in X3i \ Xi as in M (the extended
matching is then the desired matching M 0 ). We also get a variable y which is matched in
Mi , but which is free in Mi0 . Since y  Xi , we get that y 6= z and thus y is in D. Clearly
X 0 = (X \ {y})  {x}.
Lemma 4.3 Let  = C1  C2  . . .  Cm be a matched CNF and let us assume that an
implicate D is derived by a regular tree-like resolution derivation T from  in which C1 is
used, then 0 = D  C2  . . .  Cm is a matched CNF.
Proof : The fact that C1 is used in this resolution derivation implies that C1 is a leaf
clause in T . We shall proceed by induction on the depth of T . Let M be a matching for
 and let X denote the set of variables, which are matched in M . We shall preserve the
following invariant:
717

fiCepek, Gursky, & Kucera

(*) If M 0 is a matching for 0 constructed by the proof and X 0 denotes the matched
variables in M 0 , then X 0 = X.
Let us at first assume that D = C1 . Then the proposition trivially follows and invariant
(*) is satisfied. Now let us suppose that D = R(C1 , Cj ), where j  {2, . . . , m}. Let y be
the variable which is matched to C1 in M , i.e. {C1 , y}  M . If y  D, then we set

n
o n
o
M 0 = M \ {C1 , y}  {D, y} .
If y 6 D, then it follows that C1 and Cj resolve over y. Let us without loss of generality
assume that y appears positively in C1 and let us denote C1 = (A1  y) and Cj = (Aj  y),
hence D = A1  Aj . Then Cj is matched with another variable z  Aj in M , thus we can
set

n
o n
o
M 0 = M \ {C1 , y}, {Cj , z}  {Cj , y}, {D, z} .
Then M 0 is a matching for 0 with X 0 = X.
Now let us assume that D = R(D1 , D2 ) where D1 and D2 are themselves derived by
resolution derivation from , or they belong to . Suppose the resolution is over a variable
z and let us denote D1 = (A1  z), D2 = (A2  z). For i = 1, 2 let Ti denote the subtree of T
rooted at Di , Li the set of leaf clauses in Ti , i the sub-CNF of  formed by clauses in Li ,
let Mi be the sub-matching of M on clauses from i , and Xi the set of variables matched
in Mi .
Let us at first assume that C1  L1  L2 . By Observation 4.1 we get that z 6 X1  X2 .
Let i  {1, 2} be such that z 
/ Xi . Let us use the induction hypothesis on Ti and Di to
find a matching for a formula 0i which is a CNF formed by clauses (Li \ {C1 })  {Di }. By
the induction hypothesis 0i is a matched formula, let Mi0 be a matching constructed for 0i
which satisfies invariant (*), i.e. the set of matched variables in Mi0 is Xi . Let x be the
variable matched with Di in Mi0 . Now since z 6 Xi we have that x  Ai , thus x belongs
to D as well. We can now construct a matching M 0 for 0 by extending Mi0 with pairs
matching variables in X3i \ Xi to clauses in L3i \ Li as in M . Moreover we replace the
pair {Di , x} with the pair {D, x}. The result M 0 is a matching for 0 in which exactly the
variables in X are matched and thus M 0 satisfies invariant (*).
In the rest of the proof we shall assume that C1  L1 \ L2 . We can use induction
hypothesis on T1 and D1 to find a matching M10 for a formula 01 which is again a CNF
formed by clauses (L1 \ {C1 })  {D1 }. By induction hypothesis M10 satisfies invariant (*)
and thus the matched variables in M10 are exactly the variables in set X1 . Let x be the
variable to which clause D1 is matched in M10 . Now there are two cases to consider .
1. If x  A1 , then we can construct a matching M 0 for the whole formula 0 by extending
M10 with pairs matching clauses in L2 \ L1 to variables in X2 \ X1 as in M , and we
replace pair {D1 , x} with pair {D, x}. Then M 0 is a matching which again matches
variables in X and thus it also satisfies invariant (*).
2. If x = z, the situation is more complicated. In this case we can observe that z  X1 \X2
(z 6 X1  X2 by Observation 4.1, on the other hand z is matched in M1 and M10 ). Let
M20 be a matching for the sub-CNF 2 formed by clauses in L2 which is constructed
718

fiOn Minimum Representations of Matched Formulas

as follows. The clauses in L1  L2 are matched to the same variables as in M10 , the
clauses in L2 \ L1 are matched to the same variables as in M . Note that M20 formed in
this way is really a matching, in particular C1 does not belong to L2 and thus it does
not matter that it is not matched to any variable in M10 . Moreover, if X20 denotes the
set of variables matched in M20 , then each variable in X20 is matched to exactly one
clause. This is because M10 did not change anything on clauses in L2 \ L1 and it did
not match any of the variables in X2 \ X1 . Note, that X20 is not necessarily equal to
X2 , because M10 is allowed to use variables from X1 \ X2 for the clauses in L1  L2 ,
but we have that X = X20  X1 . We also have that z is a free variable in M20 , that is
because z  X1 \ X2 , thus it is not matched to any clause in L2 in M , and because z
is matched to D1 in M10 , thus z is not matched to any clause in L1  L2 in M10 .
Now we have the following situation: We have a formula 2 , we have a clause D2
which is derived by a regular tree-like resolution T2 from 2 . We have a matching M20
for 2 which matches the variables in set X20 . We have a variable z which is free in
M20 , thus we can use Lemma 4.2 to find another matching M200 for 2 and a variable
y in D2 such that z is matched to some clause in M200 , and y is now free in M200 while
it was matched in M20 . Moreover, if X200 denotes the set of variables matched in M200 ,
then X200 = (X20 \ {z})  {y}. Necessarily z 6= y, and thus y  A2 . Now we are ready
to form desired matching M 0 for .
(a) A clause C from L1 \ (L2  {C1 }) is matched to variable a in M 0 such that
{C, a}  M10 .
(b) A clause C from L2 is matched to a variable a in M 0 such that {C, a}  M200 .
(c) A clause D is matched to the variable y in M 0 .
M 0 defined in this way is indeed a matching, in particular if C  L1 \(L2 {C1 }), then
the matched variable a belongs to X1 \ (X20  {z}), and thus a is free in both M20 and
M200 , and it still can be used for C. Let us also observe that M 0 preserves invariant
(*), in particular if X 0 denotes the set of variables matched in M 0 , then X 0 = X. Let
a be a variable from X 0 , we shall show that a  X as well, because |X 0 | = |X|, it
follows that X 0 = X.
(a) If a is matched to a clause C  L1 \ (L2  {C1 }), then this is because {C, a}  M10
since by induction hypothesis invariant (*) is preserved for M10 we have that
a  X1 and thus a  X.
(b) If a is matched to a clause C  L2 , then this is because {C, a}  M200 , then
a  X 00 = (X20 \ {y})  {z}. We know that z  X and that X20  X.
(c) If a is matched to D, then a = y  X20  X.
Together we have that invariant (*) is satisfied for M 0 .
In any case we found a matching M 0 for CNF 0 which satisfies invariant (*), and the proof
is finished.
Theorem 4.4 Let  be a matched CNF representing function f , then there is a prime
and irredundant representation of f which is also matched.
719

fiCepek, Gursky, & Kucera

Proof : This follows from Lemma 4.3. Firstly, we can drop any redundant clauses from 
without spoiling its matched property. If 0 is an irredundant representation of f originated
from  by dropping these redundant clauses, then we can turn it into a prime representation
by using Lemma 4.3 as follows. If 0 = C1  . . .  Cm , and C10 ( C1 is a prime implicate,
then C10 can be derived by a resolution derivation from 0 . Since 0 is already irredundant,
in every resolution derivation of C10 from 0 we have to use C1 . Thus by Lemma 4.3, the
formula 00 = C10  C2  . . .  Cm is also matched. In this way we can replace every clause
in 0 by a prime subimplicate. Thus we obtain a prime and irredundant representation of
f.

5. Minimum Representations of Matched Formulas
In the previous sections we have seen that for a matched CNF there may be some logically
equivalent prime and irredundant CNFs which are not matched but always at least one such
CNF is matched. In this section we shall show that a stronger statement holds for CNFs
which are not only prime and irredundant but also clause minimum. We shall prove that
if a Boolean function f admits a matched CNF representation, then every clause minimum
CNF representation of f is a matched CNF.
Theorem 5.1 Let  be a matched CNF representing function f on the set of variables V
and let  be a clause minimum CNF representation of f . Then  is a matched CNF.
Proof : Due to Theorem 4.4 we may assume that  is prime and irredundant and thus
  I(f ). Let us assume by contradiction that  is not matched and that X   is a
maximal (under inclusion) sub-CNF violating Halls condition (such a subset must exist
due to Theorem 2.11). Let us denote X the set of variables in the sub-CNF X , Y = V \ X
the set of remaining variables in , and Y =  \ X the remaining clauses in  (note that
clauses in Y may contain variables not only from Y but also from X). Now the following
holds:
 By the violation of Halls condition we have |X | > |X|.
 By the maximality of X there exists a matching M of all clauses in Y to variables
in Y , i.e. Y is a matched CNF even if we drop all variables in X from its clauses.
This follows from the fact that every subset of Y must satisfy Halls condition even
with respect to the variables in Y , since otherwise any such violating subset could be
added to X contradicting its maximality.
The existence of matching M implies that Y can be satisfied using only variables from Y
(each clause can be satisfied by its matched variable). So let t : Y 7 {0, 1} be some partial
assignment satisfying all clauses in Y (t is not necessarily unique). Clearly, t is an autarky
on  as it satisfies every clause containing an assigned literal.
It follows from Lemma 2.10 that (t) = X represents an exclusive component fX of f
defined by the exclusive set X  I(f ), which contains all clauses consisting only of variables
from X. Since  also represents f and we assumed   I(f ), it follows from Corollary 2.9
that t is an autarky also on . Thus, similarly as for (t) above, we can conclude that
(t) is a sub-CNF of  which represents the exclusive component fX of f , i.e. (t)  (t).
720

fiOn Minimum Representations of Matched Formulas

However,  is matched, so every its sub-CNF (and in particular (t)) is matched, and thus
|(t)|  |X| while |(t)| = |X | > |X|. But now, since both (t) and (t) = X represent
an exclusive component of f , also CNF  0 = ( \ (t))  (t) represents f by Corollary 2.6.
However, we get | 0 | < || contradicting the assumed minimality of .

6. Conclusions
In this paper we study the class of matched CNFs which is an important class of formulas
in the theory of parametrized SAT algorithms. We focus on clause minimum CNF representations of Boolean functions which can be represented by matched CNFs. The results
presented in this paper are of two types:
1. Complexity results. We show that testing logical equivalence of two matched CNFs
is co-NP-complete. Then we use a similar construction to prove that Boolean minimization for matched CNFs is p2 -complete. This is an already known fact, but the
presented proof is much shorter and simpler than the proof by Gursky (2011). Both
results appear in Section 3.
2. Structural results. We prove that given a (non-prime) matched CNF representing
function f , there may be some prime representations of f which are not matched, but
there exists at least one prime representation of f which is matched. Furthermore we
prove that in such a case all clause minimum CNFs of f are guaranteed to be matched.
The latter result of course implies the former, however, the proof of the latter result
uses the former one. Thus both subsequently appear in the text as the main results
of Sections 4 and 5.
An interesting question for future research is whether the structural results from Sections 4 and 5 can be extended in some way from matched CNFs, i.e. CNFs with maximum
deficiency zero, to CNFs with maximum deficiency bounded by a constant (see Section 1
for the definition of maximum deficiency).
In our paper we use the number of clauses in a CNF as a measure of optimality. It is
an interesting question whether our result would hold if the total length of the formula (i.e.
the total number of literal occurrences in a formula) would be considered.

Acknowledgments
The second author gratefully acknowledges the support of the Charles University Grant
Agency (grant No. 1390213).

References
Aharoni, R., & Linial, N. (1986). Minimal non-two-colorable hypergraphs and minimal
unsatisfiable formulas. Journal of Combinatorial Theory, Series A, 43 (2), 196  204.
Ausiello, G., DAtri, A., & Sacca, D. (1986). Minimal representation of directed hypergraphs. SIAM Journal on Computing, 15 (2), 418431.
721

fiCepek, Gursky, & Kucera

Bollobas, B. (1998). Modern Graph Theory, Vol. 184 of Graduate Texts in Mathematics.
Springer.
Boros, E., & Cepek, O. (1994). On the complexity of Horn minimization. Tech. rep. 1-94,
RUTCOR Research Report RRR, Rutgers University, New Brunswick, NJ.
Boros, E., Cepek, O., & Kogan, A. (1998). Horn minimization by iterative decomposition.
Annals of Mathematics and Artificial Intelligence, 23, 321  343.
Boros, E., Cepek, O., Kogan, A., & Kucera, P. (2009). A subclass of Horn CNFs optimally
compressible in polynomial time. Annals of Mathematics and Artificial Intelligence,
57, 249291.
Boros, E., Cepek, O., Kogan, A., & Kucera, P. (2010). Exclusive and essential sets of
implicates of boolean functions. Discrete Applied Mathematics, 158 (2), 81  96.
Buchfuhrer, D., & Umans, C. (2011). The complexity of boolean formula minimization.
Journal of Computer and System Sciences, 77 (1), 142  153.
Buning, H. K., & Lettmann, T. (1999). Propositional Logic: Deduction and Algorithms.
Cambridge University Press, New York, NY, USA.
Cepek, O. (1995). Structural Properties and Minimization of Horn Boolean Functions.
Ph.D. dissertation, Rutgers University, New Brunswick, NJ, October 1995.
Cepek, O., Kucera, P., & Savicky, P. (2012). Boolean functions with a simple certificate for
CNF complexity. Discrete Applied Mathematics, 160 (4-5), 365  382.
Fleischner, H., Kullmann, O., & Szeider, S. (2002). Polynomial-time recognition of minimal unsatisfiable formulas with fixed clause-variable difference. Theoretical Computer
Science, 289 (1), 503  516.
Flum, J., & Grohe, M. (2006). Parameterized complexity theory, Vol. 3. Springer.
Franco, J., & Van Gelder, A. (2003). A perspective on certain polynomial-time solvable
classes of satisfiability. Discrete Appl. Math., 125 (2-3), 177214.
Garey, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory of
NP-Completeness. W.H. Freeman and Company, San Francisco.
Genesereth, M., & Nilsson, N. (1987). Logical Foundations of Artificial Intelligence. Morgan
Kaufmann, Los Altos, CA.
Gursky, S. (2011). Minimization of matched formulas. In Safrankova, J., & Pavlu, J. (Eds.),
WDS11 Proceedings of Contributed Papers: Part I  Mathematics and Computer
Science, pp. 101105, Prague. Matfyzpress.
Hall, P. (1935). On representatives of subsets. Journal of The London Mathematical Societysecond Series, s1-10, 2630.
Hammer, P., & Kogan, A. (1993). Optimal compression of propositional Horn knowledge
bases: Complexity and approximation. Artificial Intelligence, 64, 131  145.
Hammer, P., & Kogan, A. (1995). Quasi-acyclic propositional Horn knowledge bases: Optimal compression. IEEE Transactions on Knowledge and Data Engineering, 7 (5),
751  762.
722

fiOn Minimum Representations of Matched Formulas

Kullmann, O. (2000). Investigations on autark assignments. Discrete Applied Mathematics,
107 (13), 99  137.
Kullmann, O. (2003). Lean clause-sets: generalizations of minimally unsatisfiable clausesets. Discrete Applied Mathematics, 130 (2), 209  249.
Lovasz, L., & Plummer, M. D. (1986). Matching Theory. North-Holland.
Maier, D. (1980). Minimal covers in the relational database model. Journal of the ACM,
27, 664  674.
Monien, B., & Speckenmeyer, E. (1985). Solving satisfiability in less than 2n steps. Discrete
Applied Mathematics, 10 (3), 287  295.
Szeider, S. (2003). Minimal unsatisfiable formulas with bounded clause-variable difference
are fixed-parameter tractable. In Warnow, T., & Zhu, B. (Eds.), Computing and
Combinatorics, Vol. 2697 of Lecture Notes in Computer Science, pp. 548558. Springer
Berlin Heidelberg.
Szeider, S. (2005). Generalizations of matched CNF formulas. Annals of Mathematics and
Artificial Intelligence, 43 (1-4), 223238.
Szeider, S. (2007). Matched formulas and backdoor sets. In Marques-Silva, J., & Sakallah,
K. (Eds.), Theory and Applications of Satisfiability Testing  SAT 2007, Vol. 4501 of
Lecture Notes in Computer Science, pp. 9499. Springer Berlin Heidelberg.
Tovey, C. A. (1984). A simplified NP-complete satisfiability problem. Discrete Applied
Mathematics, 8 (1), 85  89.
Tseitin, G. S. (1983). On the complexity of derivation in propositional calculus. In Automation of Reasoning, pp. 466483. Springer.
Umans, C. (2001). The minimum equivalent DNF problem and shortest implicants. J.
Comput. Syst. Sci., 63 (4), 597611.
Umans, C., Villa, T., & Sangiovanni-Vincentelli, A. L. (2006). Complexity of two-level
logic minimization. IEEE Trans. on CAD of Integrated Circuits and Systems, 25 (7),
12301246.
Umans, C. M. (1999). Hardness of approximating p2 minimization problems. In FOCS 99:
Proceedings of the 40th Annual Symposium on Foundations of Computer Science, pp.
465474, Washington, DC, USA. IEEE Computer Society.
Urquhart, A. (1995). The complexity of propositional proofs. The Bulletin of Symbolic
Logic, 1 (4), pp. 425467.
Urquhart, A. (2011). The depth of resolution proofs. Stud. Log., 99 (1-3), 349364.

723

fiJournal of Artificial Intelligence Research 51 (2014) 579-603

Submitted 4/14; published 11/14

No Agent Left Behind: Dynamic Fair Division of Multiple Resources
Ian Kash

IANKASH @ MICROSOFT. COM

Microsoft Research Cambridge, UK

Ariel D. Procaccia

ARIELPRO @ CS . CMU . EDU

Carnegie Mellon University, USA

Nisarg Shah

NKSHAH @ CS . CMU . EDU

Carnegie Mellon University, USA

Abstract
Recently fair division theory has emerged as a promising approach for allocation of multiple
computational resources among agents. While in reality agents are not all present in the system
simultaneously, previous work has studied static settings where all relevant information is known
upfront. Our goal is to better understand the dynamic setting. On the conceptual level, we develop
a dynamic model of fair division, and propose desirable axiomatic properties for dynamic resource
allocation mechanisms. On the technical level, we construct two novel mechanisms that provably
satisfy some of these properties, and analyze their performance using real data. We believe that our
work informs the design of superior multiagent systems, and at the same time expands the scope of
fair division theory by initiating the study of dynamic and fair resource allocation mechanisms.

1. Introduction
The question of how to fairly divide goods or resources has been the subject of intellectual curiosity
for millennia. While early solutions can be traced back to ancient writings, rigorous approaches
to fairness were proposed only as late as the mid Twentieth Century, by mathematicians and social
scientists. Over time, fair division has emerged as an influential subfield of microeconomic theory.
In the last few years fair division has also attracted the attention of AI researchers (see, e.g., Chevaleyre, Endriss, Estivie, & Maudet, 2007; Procaccia, 2009; Chen, Lai, Parkes, & Procaccia, 2010;
Moulin, 2003; Brams & Taylor, 1996), who envision applications of fair division in multiagent systems (Chevaleyre, Dunne, Endriss, Lang, Lematre, Maudet, Padget, Phelps, Rodrguez-Aguilar, &
Sousa, 2006). However, fair division theory has seen relatively few applications to date.
It is only very recently that an exciting combination of technological advances and theoretical
innovations has pointed the way towards concrete applications of fair division. In modern data
centers, clusters, and grids, multiple computational resources (such as CPU, memory, and network
bandwidth) must be allocated among heterogeneous agents. Agents demands for resources are
typically highly structured, as we explain below. Several recent papers (Gutman & Nisan, 2012;
Ghodsi, Zaharia, Hindman, Konwinski, Shenker, & Stoica, 2011; Parkes, Procaccia, & Shah, 2014;
Dolev, Feitelson, Halpern, Kupferman, & Linial, 2012) suggest that classic fair division mechanisms
possess excellent properties in these environments, in terms of their fairness guarantees as well as
their game-theoretic properties.
Nevertheless, some aspects of realistic computing systems are beyond the current scope of fair
division theory. Perhaps most importantly, the literature does not capture the dynamics of these
systems. Indeed, it is typically not the case that all the agents are present in the system at any
c
2014
AI Access Foundation. All rights reserved.

fiK ASH , P ROCACCIA , & S HAH

given time; agents may arrive and depart, and the system must be able to adjust the allocation of
resources. Even on the conceptual level, dynamic settings challenge some of the premises of fair
division theory. For example, if one agent arrives before another, the first agent should intuitively
have priority; what does fairness mean in this context? We introduce the concepts that are necessary
to answer this question, and design novel mechanisms that satisfy our proposed desiderata. Our
contribution is therefore twofold: we design more realistic resource allocation mechanisms for
multiagent systems that provide theoretical guarantees, and at the same time we expand the scope of
fair division theory to capture dynamic settings.
1.1 Overview of Model and Results
As in previous papers (e.g., Ghodsi et al., 2011; Parkes et al., 2014), we assume that agents demand
the resources in fixed proportions. Such Leontief preferences  as they are known in economics 
are easily justified in typical settings where agents must run many instances of a single task (e.g.,
map jobs in the MapReduce framework). Hence, for example, an agent that requires twice as much
CPU as RAM to run a task prefers to be allocated 4 CPU units and 2 RAM units to 2 CPU units and
1 RAM unit, but is indifferent between the former allocation and 5 CPU units and 2 RAM units.
We consider environments where agents arrive over time (but do not depart  see Section 7 for
additional discussion of this point). We aim to design resource allocation mechanisms that make
irrevocable allocations, i.e., the mechanism can allocate more resources to an agent over time, but
can never take resources back.
We adapt prominent notions of fairness, efficiency, and truthfulness to our dynamic settings.
For fairness, we ask for envy freeness (EF), in the sense that agents like their own allocation best;
and sharing incentives (SI), so that agents prefer their allocation to their proportional share of the
resources. We also seek strategyproof (SP) mechanisms: agents cannot gain from misreporting
their demands. Finally, we introduce the notion of dynamic Pareto optimality (DPO): if k agents
are entitled to k/n of each resource, the allocation should not be dominated (in a sense that will be
formalized later) by allocations that divide these entitlements. Our first result (in Section 3) is an
impossibility: DPO and EF are incompatible. We proceed by relaxing each of these properties.
In Section 4, we relax the EF property. The new dynamic property, which we call dynamic EF
(DEF), allows an agent to envy another agent that arrived earlier, as long as the former agent was not
allocated resources after the latter agents arrival. We construct a new mechanism, DYNAMIC DRF,
and prove that it satisfies SI, DEF, SP, and DPO.
In Section 5, we relax the DPO property. Our cautious DPO (CDPO) notion allows allocations
to only compete with allocations that can ultimately guarantee EF, regardless of the demands of
future agents. We design a mechanism called C AUTIOUS LP, and show that it satisfies SI, EF, SP,
and CDPO. In a sense, our theoretical results are tight: EF and DPO are incompatible, but relaxing
only one of these two properties is sufficient to enable mechanisms that satisfy both, in conjunction
with SI and SP.
Despite the assumptions imposed by our theoretical model, we believe that our new mechanisms are compelling, useful guides for the design of practical resource allocation mechanisms in
realistic settings. Indeed, in Section 6, we test our mechanisms on real data obtained from a trace
of workloads on a Google cluster, and obtain encouraging results.
580

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

1.2 Related Work
Walsh (2011) proposed the problem of fair cake cutting where agents arrive, take a piece of cake,
and immediately depart. The cake cutting setting deals with the allocation of a single, heterogeneous
divisible resource; contrast with our setting, which deals with multiple, homogeneous divisible resources. Walsh suggested several desirable properties for cake cutting mechanisms in this setting,
and showed that adaptations of classic mechanisms achieve these properties (Walsh also pointed
out that allocating the whole cake to the first agent achieves the same properties). In particular, his
notion of forward envy freeness, which is discussed below, is related to our notion of dynamic envy
freeness.
The networking community has studied the problem of fairly allocating a single homogeneous
resource in a queuing model where each agents task requires a given number of time units to be
processed. In other words, in these models tasks are processed over time, but demands stay fixed,
and there are no other dynamics such as agent arrivals and departures. The well-known fair queuing
solution (Demers, Keshav, & Shenker, 1989) allocates one unit per agent in successive round-robin
fashion. This solution has also been analyzed by economists (Moulin & Stong, 2002).
Previous papers on the allocation of multiple resources study a static setting. For example,
Ghodsi et al. (2011) proposed the dominant resource fairness (DRF) mechanism, which guarantees
a number of desirable theoretical properties. Li and Xue (2013) presented characterizations of
mechanisms satisfying various desiderata while Wong et al. (2012) analyzed the classic tradeoff
between fairness and efficiency, both in generic frameworks that capture DRF as a special case.
Parkes et al. (2014) extended DRF in several ways, and in particular studied the case of indivisible
tasks. Finally, DRF has also been extended to the queuing domain (Ghodsi, Sekar, Zaharia, &
Stoica, 2012) and to incorporate job placement considerations (Ghodsi, Zaharia, Shenker, & Stoica,
2013), but these generalizations also use a static setting. Recently, Zahedi and Lee (2014) applied
the concept of Competitive Equilibrium from Equal Outcomes (CEEI) in the case of Cobb-Douglas
utilities to achieve properties similar to DRF. They empirically show that these utilities are well
suited for modeling user preferences over hardware resources such as cache capacity and memory
bandwidth. Dolev et al. (2012) defined a notion of fairness that is different from the one considered
in DRF. They also proved that a fair allocation according to this new notion is always guaranteed
to exist in a static setting. Gutman and Nisan (2012) gave a polynomial time algorithm to find such
an allocation, and also considered generalizations of DRF in a more general model of utilities. We
elaborate on several of these results below.

2. Preliminaries
In our setting, each agent has a task that requires fixed amounts of different resources. The utility
of the agent depends on the quantity (possibly fractional) of its tasks that it can execute given the
allocated resources. Formally, denote the set of agents by N = {1, . . . , n}, and the set of resources
by R, |R| = m. Let Dir denote the ratio between the maximum amount of resource r agent i can
use given the amounts of other resources present in the system and the total amount of that resource
available in the system, either allocated or free. In other words, Dir is the fraction of resource r
required by agent i. Following Ghodsi et al. (2011), the dominant resource of agent i is defined
as the resource r that maximizes Dir , and the fraction of dominant resource allocated to agent i is
called its dominant share. Following Parkes et al. (2014), the (normalized) demand vector of agent
i is given by di = hdi1 , . . . , dim i, where dir = Dir /(maxr0 Dir0 ) for each resource r. Let D be the
581

fiK ASH , P ROCACCIA , & S HAH

set of all possible normalized demand vectors. Let dk = hd1 , . . . , dk i denote the demand vectors
of agents 1 through k. Similarly, let d>k = hdk+1 , . . . , dn i denote the demand vectors of agents
k + 1 through n.
AnP
allocation A allocates a fraction Air of resource r to agent i, subject to the feasibility condition iN Air  1 for all r  R. Throughout the paper we assume that resources are divisible
and that each agent requires a positive amount of each resource, i.e., dir > 0 for all i  N and
r  R. Under such allocations, our model for preferences coincides with the domain of Leontief
preferences, where the utility of an agent for its allocation vector Ai is given by
ui (Ai ) = max{y  R+ : r  R, Air  y  dir }.
In words, the utility of an agent is the fraction of its dominant resource that it can actually use, given
its proportional demands and its allocation of the various resources. However, we do not rely on an
interpersonal comparison of utilities; an agents utility function simply induces ordinal preferences
over allocations, and its exact value is irrelevant.
We say that an allocation A is Pareto-dominated by another allocation A0 if ui (A0i )  ui (Ai )
for every agent i, and uj (A0j ) > uj (Aj ) for some agent j. For allocations A over agents in S  N
and A0 over agents in T  N such that S  T , we say that A0 is an extension of A to T if
A0ir  Air for every agent i  S and every resource r. When S = T , we simply say that A0 is an
extension of A. An allocation A is called non-wasteful if for every agent i there exists y  R+ such
that for all r  R, Air = y  dir . For a non-wasteful allocation, the utility of an agent is the share
of its dominant resource allocated to the agent. Also, if A is a non-wasteful allocation then for all
i  N,
ui (A0i ) > ui (Ai )  r  R, A0ir > Air .

(1)

3. Dynamic Resource Allocation: A New Model
We consider a dynamic resource allocation model where agents arrive at different times and do not
depart (see Section 7 for a discussion of this point). We assume that agent 1 arrives first, then agent
2, and in general agent k arrives after agents 1, . . . , k  1; we say that agent k arrives in step k.
An agent reports its demand when it arrives and the demand does not change over time. Thus, at
step k, demand vectors dk are known, and demand vectors d>k are unknown. A dynamic resource
allocation mechanism operates as follows. At each step k, the mechanism takes as input the reported
demand vectors dk and outputs an allocation Ak over the agents present in the system. Crucially,
for every step k  2, every agent
we assume that allocations are irrevocable, i.e., Akir  Ak1
ir
i  k  1, and every resource r. We also assume that the mechanism knows the total number of
agents n in advance.
Irrevocability can be justified in various settings, e.g., in cases where resources are committed
to long-term projects. One example is that of a research cluster shared between faculty members
at a university. In such a cluster, the total number of faculty members who can access the cluster
(denoted n in our setting) is known to the mechanism in advance  as we assume in our model.
Another important setting where irrevocability becomes a necessary assumption is the case of divisible consumable resources. In this case, an agent may consume the resources it receives in a certain
step, so they cannot be reclaimed later on.
582

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

Previous work on static resource allocation (e.g., Ghodsi et al., 2011; Parkes et al., 2014) focused
on designing mechanisms that satisfy four prominent desiderata. Three of these  two fairness
properties and one game-theoretic property  immediately extend to the dynamic setting.
1. Sharing Incentives (SI). We say that a dynamic allocation mechanism satisfies SI if ui (Aki ) 
ui (h1/n, . . . , 1/ni) for all steps k and all agents i  k. In words, when an agent arrives it
receives an allocation that it likes at least as much as an equal split of the resources. This
models a setting where agents have made equal contributions to the system and hence have
equal entitlements. In such cases, the contributions are typically recorded, which allows the
mechanism to know the total number of agents n in advance, as assumed in our setting.
2. Envy Freeness (EF). A dynamic allocation mechanism is EF if ui (Aki )  ui (Akj ) for all steps
k and all agents i, j  k, that is, an agent that is present would never prefer the allocation of
another agent.
3. Strategyproofness (SP). A dynamic allocation mechanism is SP if no agent can misreport its
demand vector and be strictly better off at any step k, regardless of the reported demands of
other agents. Formally, a dynamic allocation mechanism is SP if for any agent i  N and any
step k, if Aki is the allocation to agent i at step k when agent i reports its true demand vector
and Bki is the allocation to agent i at step k when agent i reports a different demand vector
(in both cases all the other agents report their true demand vectors), then ui (Aki )  ui (Bki ).
We avoid introducing additional notations that will not be required later.
In the static setting, the fourth prominent axiom, Pareto optimality (PO), means that the mechanisms allocation is not Pareto dominated by any other allocation. Of course, in the dynamic setting
it is unreasonable to expect the allocation in early stages to be Pareto undominated, because we need
to save resources for future arrivals (recall that allocations are irrevocable). We believe though that
the following definition naturally extends PO to our dynamic setting.
4. Dynamic Pareto Optimality (DPO). A dynamic allocation mechanism is DPO if at each step k,
the allocation Ak returned by the mechanism is not Pareto dominated by any other allocation
Bk that allocates up to a (k/n)-fraction of each resource among the k agents present in the
system. Put another way, at each step the allocation should not be Pareto dominated by any
other allocation that only redistributes the collective entitlements of the agents present in the
system among those agents.
It is straightforward to verify that a non-wasteful mechanism (a mechanism returning a nonwasteful allocation at each step) satisfies DPO if and only if the allocation returned by the mechanism at each step k uses at least a (k/n)-fraction of at least one resource (the assumption of strictly
positive demands plays a role here).
Before moving on to possibility and impossibility results, we give examples that illustrate how
various combinations of the properties constrain the allocation of resources.
Example 1 (Satisfying Sharing Incentives (SI) and Dynamic Pareto Optimality (DPO)). In this
paper, we only consider non-wasteful allocations. Hence, as described above, DPO is equivalent
to allocating at least a (k/n)-fraction of at least one resource in every step k, when allocations are
proportional. On the other hand, if a mechanism seeks to satisfy SI, it cannot allocate more than
583

fiK ASH , P ROCACCIA , & S HAH

a (k/n)-fraction of any resource in step k. Indeed, if more than a (k/n)-fraction of resource r
is allocated at step k, and every agent arriving after step k reports r as its dominant resource, the
mechanism would not have enough of resource r left to allocate each of them at least a (1/n)fraction of r, as required by SI. Thus, a non-wasteful mechanism satisfying both SI and DPO must
allocate, in every step k, exactly a (k/n)-fraction of some resource and at most a (k/n)-fraction
of every other resource. In other words, in every step k, the mechanism has a pool of available
resources  which contains a (k/n)-fraction of each resource, minus the fraction already allocated
 to be allocated to the k agents that are currently present. The mechanism can only allocate from
this pool, and must exhaust at least one resource from the pool.
Example 2 (Understanding Strategyproofness (SP)). In this example, we take a mechanism that
may seem SP at first glance, and show that it violates our definition of SP. For simplicity, we
will allow the agents to have possibly zero demands for some of the resources in this example. This allows beneficial manipulations for the following simple mechanism, which we call
DYNAMIC D ICTATORSHIP. (We note that DYNAMIC D ICTATORSHIP is otherwise strategyproof
for strictly positive demands  see the discussion following Theorem 3.) At each step k, the mechanism allocates a 1/n share of each resource to agent k, takes back the shares of different resources
that the agent cannot use, and then allocates resources to the k present agents in the order of their
arrival using serial dictatorship, that is, it allocates to each agent as many resources as the agent can
use, and then proceeds to the next agent. The mechanism keeps allocating until a k/n share of at
least one resource is allocated. Note that the mechanism trivially satisfies SI because it allocates
resources as valuable as an equal split to each agent as soon as it arrives. The mechanism would
satisfy DPO in our standard setting with non-zero demands, because it is non-wasteful and at every
step k it allocates a k/n fraction of at least one resource. Intuitively, it seems that the first agent
should not gain by reporting a false demand vector because in each round it gets to pick first and
is allowed to take as much as it can use from the available pool of resources. We show that this
intuition is incorrect. Let us denote the pool of resources available to the mechanism in any step by
a vector of the fraction of each available resource. Consider the case of four agents (agents 1, 2,
3, and 4), and three resources (R1 , R2 , and R3 ). Let the true demand vectors of the agents be as
follows:
d1 = h1, 0.5, 0.5i, d2 = h0, 1, 1i, d3 = h1, 0.5, 0i, d4 = h0, 1, 0.5i.
Figure 1 shows the allocations returned by DYNAMIC D ICTATORSHIP in various steps when all
agents report their true demand vectors. Now, suppose agent 1 raises its demand for R3 by reporting
a false demand vector h1, 0.5, 1i. In this case the allocations returned by the mechanism in various
steps are shown in Figure 2. We can see that the manipulation makes agent 1 strictly worse off in
step 2, but strictly better off in the final step. Our definition of SP requires that an agent should not
be able to benefit in any step of the process by lying  thus DYNAMIC D ICTATORSHIP is not SP.
3.1 Impossibility Result
Ideally, we would like to design a dynamic allocation mechanism that is SI, EF, SP, and DPO.
However, we show that even satisfying EF and DPO simultaneously is impossible.
Theorem 3. Let n  3 and m  2. Then no dynamic resource allocation mechanism satisfies EF
and DPO.
584

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

1

1

1

1

3
4

3
4

3
4

3
4

1/4

1
2

1
2

1
2

1
2

1/4

1
4

0

1/4

1/8
1/8

1/8
1/8

R1

R2

R3

1/4

1/4

1/2

1/4

1/4

R1

R2

R3

1
4

0

(a) Step 1

1/8
1/4
3/8

3/8

1/2

1/4

1/4

R1

R2

R3

1
4

0

1/8

0

1/4
1/8

Agent 2
Agent 3

3/8

3/8

Agent 4

1/2

1/4

1/4

Unallocated resource
available in the pool

R1

R2

R3

1
4

(c) Step 3

(b) Step 2

Agent 1
1/4
1/8

(d) Step 4

Figure 1: Allocations returned by DYNAMIC D ICTATORSHIP when agent 1 reports its true demand vector.
1

1

1

1

3
4

3
4

3
4

3
4

1
2

1
2

1
4

0

1
4

1/4

1/8
1/8

1/4

R1

R2

R3

(a) Step 1

0

1
2

1/8
1/4

1/4

1/4

1/4
1/8

1/4

R1

R2

R3

(b) Step 2

1/4

1/4

1/4

1/16

1/4
1/8

1/8
1/4

1/4

1/2

R1

R2

R3

(c) Step 3

0

Agent 2

Agent 4

1
4

1/2

Agent 1

Agent 3

1
2

1/4

1/4

1
4

0

1/8
1/8

1/8

5/8

5/16

5/8

R1

R2

R3

Unallocated resource
available in the pool

(d) Step 4

Figure 2: Allocations returned by DYNAMIC D ICTATORSHIP when agent 1 manipulates.
Proof. Consider a setting with three agents and two resources. Agents 1 and 2 have demand vectors
h1, 1/9i and h1/9, 1i, respectively (i.e., d11 = 1, d12 = 1/9, etc.). At step 2 (after the second
agent arrives), at least one of the two agents must be allocated at least an x = 3/5 share of its
dominant resource. Suppose for contradiction that the two agents are allocated x0 and x00 shares
of their dominant resources where 0 < x0 , x00 < x. Then, the total fractions of the two resources
allocated at step 2 would be x0 + x00  (1/9) and x00 + x0  (1/9), both less than x + x  (1/9) = 2/3,
violating DPO. Without loss of generality, assume that agent 1 is allocated at least an x = 3/5 share
of its dominant resource (resource 1) at step 2. If agent 3 reports the demand vector h1, 1/9i 
identical to that of agent 1  then it can be allocated at most a 2/5 share of its dominant resource
(resource 1), and would envy agent 1.
It is easy to extend this argument to the case of n > 3, by adding n  3 agents with demand
vectors that are identical to the demand vector of agent 3. Once again, it can be verified that at the
end of step 2, at least one of the first two agents (w.l.o.g., agent 1) must be allocated at least a 9/(5n)
share of its dominant resource. If we take the remaining resources (in particular, at most a 19/(5n)
share of resource 1), and divide them among the remaining n  2 agents that have demand vectors
identical to that of agent 1, at least one of them will get at most a (1  9/(5n))/(n  2) < 9/(5n)
share of its dominant resource, and will envy agent 1. To extend to the case of m > 2, let all agents
have negligibly small demands for the additional resources.  (Proof of Theorem 3)
It is interesting to note that if either EF or DPO is dropped, the remaining three axioms can
be easily satisfied. For example, the trivial mechanism E QUAL S PLIT that just gives every agent
a 1/n share of each resource when it arrives satisfies SI, EF and SP. Achieving SI, DPO, and
585

fiK ASH , P ROCACCIA , & S HAH

SP is also simple. Indeed, consider the DYNAMIC D ICTATORSHIP mechanism from Example 2.
The example explains why DYNAMIC D ICTATORSHIP satisfies both SI and DPO. Even though
DYNAMIC D ICTATORSHIP is not SP under possibly zero demands (as shown in the example), it
is clearly SP for strictly positive demands (as assumed throughout this paper). When agent k arrives
in step k, it is allocated a 1/n share of its dominant resource (and other resources in proportion), and
subsequently agent 1 is allocated resources until a k/n share of at least one resource is exhausted.
Since every agent requires the exhausted resource due to strictly positive demands, the allocation
stops. In summary, all agents except agent 1 receive exactly a 1/n share of their dominant resource
when they arrive, and do not receive any resources later on; hence, they cannot gain by reporting
a false demand vector. In step k, agent 1 receives as much resources as it can from the pool of
resources that remain after allocating to agents 2 through k a 1/n share of their dominant resource
from an original pool that contains a k/n share of each resource. Therefore, agent 1 also cannot
gain from manipulation.
While both E QUAL S PLIT and DYNAMIC D ICTATORSHIP satisfy maximal subsets of our proposed desiderata, neither is a compelling mechanism. Since these mechanisms are permitted by
dropping EF or DPO entirely, we instead explore relaxations of EF and DPO that rule these mechanisms out and guide us towards more compelling mechanisms.

4. Relaxing Envy Freeness
Recall that DPO requires a mechanism to allocate at least a k/n fraction of at least one resource at
step k, for every k  {1, . . . , n}. Thus the mechanism sometimes needs to allocate a large amount
of resources to agents arriving early, potentially making it impossible for the mechanism to prevent
the late agents from envying the early agents. In other words, when an agent i enters the system it
may envy some agent j that arrived before i did; this is inevitable in order to be able to satisfy DPO.
However, it would be unfair to agent i if agent j were allocated more resources since agent i arrived
while i still envied j. To distill this intuition, we introduce the following dynamic version of EF.
20 . Dynamic Envy Freeness (DEF). A dynamic allocation mechanism is DEF if at any step an
agent i envies an agent j only if j arrived before i did and j has not been allocated any
resources since i arrived. Formally, for every k  {1, . . . , n}, if ui (Akj ) > ui (Aki ) then j < i
and Akj = Ai1
j .
Walsh (2011) studied a dynamic cake cutting setting and proposed forward EF, which requires
that an agent not envy any agent that arrived later. This notion is weaker than DEF because it
does not rule out the case where an agent i envies an agent j that arrived earlier and j received
resources since i arrived. In our setting, even the trivial mechanism DYNAMIC D ICTATORSHIP (see
Section 3.1) satisfies forward EF, but fails to satisfy our stronger notion of DEF.
We next construct a dynamic resource allocation mechanism  DYNAMIC DRF  that achieves
the relaxed fairness notion of DEF, together with SI, DPO, and SP. The mechanism is given as Algorithm 1.
Intuitively, at each step k the mechanism starts from the current allocation among the present
agents and keeps allocating resources to agents that have the minimum dominant share at the same
rate, until a k/n fraction of at least one resource is allocated. Always allocating to agents that
have the minimum dominant share ensures that agents are not allocated any resources while they
586

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

ALGORITHM 1: DYNAMIC DRF
Data: Demands d
Result: Allocation Ak at each step k
k  1;
while k  n do
{xki }ki=1  Solution of the LP in the box below;
Akir  xki  dir , i  k;
k  k + 1;
end
Maximize M k
subject to
xki  M k , i  k
xki  xk1
, i  k  1
Pk ik
i=1 xi  dir  k/n, r  R

are envied. This water-filling mechanism is a dynamic adaptation of the dominant resource fairness
(DRF) mechanism proposed by Ghodsi et. al. (2011). See Figure 3 for an example.
1

1

1

2
3

2
3

2
3

2/9
1
3

0

2/9
1/3

1
3

1/3

1/6

1/4

R1

R2

R3

(a) Step 1

0

4/9

4/9

1/3

R1

R2

R3

1/6

1/6

2/9

2/9

1
3

0

(b) Step 2

1/3

Agent 1

1/3

Agent 2

4/9

4/9

1/3

Agent 3

R1

R2

R3

Dominant share

(c) Step 3

Figure 3: Allocations returned by DYNAMIC DRF at various steps for 3 agents with demands d1 =
h1, 1/2, 3/4i, d2 = h1/2, 1, 3/4i, and d3 = h1/2, 1/2, 1i, and three resources R1 , R2 , and
R3 . Agent 1 receives a 1/3 share of its dominant resource at step 1. At step 2, water-filling drives
the dominant shares of agents 1 and 2 up to 4/9. At step 3, however, agent 3 can only receive a
1/3 dominant share and the allocations of agents 1 and 2 remain unchanged.

Theorem 4. DYNAMIC DRF satisfies SI, DEF, DPO, and SP, and can be implemented in polynomial time.
Proof. First we show that DYNAMIC DRF satisfies SI. We need to prove that xki  1/n for all
agents i  k at every step k  {1, . . . , n}. We prove this by induction on k. For the base case
k = 1, it is easy to see that x11 = 1/n and M 1 = 1/n is a solution of the LP of DYNAMIC DRF
and hence the optimal solution satisfies x11  M 1  1/n (in fact, there is an equality). Assume that
this is true at step k  1 and let us prove the claim for step k, where k  {2, . . . , n}. At step k, one
feasible solution of the LP is given by xki = xk1
for agents i  k  1, xkk = 1/n and M k = 1/n.
i
To see this, note that it trivially satisfies the first two constraints of the LP, because by the induction
587

fiK ASH , P ROCACCIA , & S HAH

hypothesis we have xk1
 1/n for i  k  1. Furthermore, in the proposed feasible solution, for
i
any r  R we have
k
X
i=1

xki  dir =

k1
X
i=1

xk1
 dir +
i

k1 1
k
1
 dkr 
+  ,
n
n
n
n

where the first transition follows from the construction of the feasible solution and the second transition holds because {xk1
}k1
i
i=1 satisfies the LP of step k  1, and in particular the third constraint
of the LP. Since a feasible solution achieves M k = 1/n, the optimal solution achieves M k  1/n.
Thus in the optimal solution xki  M k  1/n for all i  k, which is the requirement for SI.
Next we show that DYNAMIC DRF satisfies DPO. Observe that at any step k, the third constraint
of the LP must be tight for at least one resource in the optimal solution (otherwise every xki along
with M k can be increased by a sufficiently small quantity, contradicting the optimality of M k ).
Thus, at each step k the (non-wasteful) mechanism allocates a k/n fraction of at least one resource,
which implies that the mechanism satisfies DPO.
To prove that the mechanism satisfies DEF and SP, we first prove several useful lemmas about
the allocations returned by the mechanism. In the proof below, M k and xki refer to the optimal
solution of the LP in step k. Furthermore, we assume that xki = 0 for agents i > k (i.e., agents not
present in the system are not allocated any resources). We begin with the following lemma, which
essentially shows that if an agent is allocated some resources in a step using water-filling, then the
agents dominant share after the step will be the minimum among the present agents.
Lemma 5. At every step k  {1, . . . , n}, it holds that xki = max(M k , xk1
) for all agents i  k.
i
Proof. Consider any step k  {1, . . . , n}. From the first and the second constraints of the LP it
= 0), thus xki  max(M k , xik1 ) for
is evident that xki  M k and xki  xk1
(note that xk1
i
k
all i  k. Suppose for contradiction that xki > max(M k , xk1
) for some i  k. Then xki can
i
be reduced by a sufficiently small  > 0 without violating any constraints. This makes the third
constraint of the LP loose by at least   dir , for every resource r  R. Consequently, the values
of xkj for j 6= i and M k can be increased by a sufficiently small  > 0 without violating the
third constraint of the LP. Finally,  (and correspondingly ) can be chosen to be small enough so
that xki  M k is not violated. It follows that the value of M k can be increased, contradicting the
optimality of M k .  (Proof of Lemma 5)
Next we show that at each step k, the dominant shares of agents 1 through k are monotonically
non-increasing with their time of arrival. This is intuitive because at every step k, agent k enters with
zero dominant share and subsequently we perform water-filling, hence monotonicity is preserved.
Lemma 6. For all agents i, j  N such that i < j, we have xki  xkj at every step k  {1, . . . , n}.
Proof. Fix any two agents i, j  N such that i < j. We prove the lemma by induction on k. The result trivially holds for k < j since xkj = 0. Assume that xk1
 xk1
where k  {j, . . . , n}. At step
i
j
k1
k1
k
k
k
k
k, we have xi = max(M , xi )  max(M , xj ) = xj , where the first and the last transition
follow from Lemma 5 and the second transition follows from our induction hypothesis.  (Proof of
Lemma 6)
588

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

The following lemma shows that if agent j has a greater dominant share than agent i at some
step, then j must have arrived before i and j must not have been allocated any resources since i
arrived. Observe that this is very close to the requirement of DEF.
Lemma 7. At any step k  {1, . . . , n}, if xkj > xki for some agents i, j  k, then j < i and
xkj = xi1
j .
Proof. First, note that j < i trivially follows from Lemma 6. Suppose for contradiction that
xkj > xi1
(it cannot be smaller because allocations are irrevocable). Then there exists a step
j
t
t
t
t  {i, . . . , k} such that xtj > xt1
j . Now Lemma 5 implies that xj = M  xi , where the last transition follows because xti satisfies the second constraint of the LP at step t (note that i  t). However, xtj  xti due to Lemma 6. Thus, xtj = xti . Now using Lemma 5, xt+1
= max(M t+1 , xtj ) =
j
t0
t0
max(M t+1 , xti ) = xt+1
i . Extending this argument using a simple induction shows that xj = xi for
every step t0  t, in particular, xkj = xki , contradicting our assumption.  (Proof of Lemma 7)
We proceed to show that DYNAMIC DRF satisfies DEF. We need to prove that for any step k 
{1, . . . , n} and any agents i, j  k, if agent i envies agent j in step k (i.e., ui (Akj ) > ui (Aki )), then
k
k
k
k
j < i and xkj = xi1
j . First, note that ui (Aj ) > ui (Ai ) trivially implies that xj > xi , otherwise
for the dominant resource ri of agent i, we would have Akir = xki  xkj  xkj  djri = Akjr and
i
i
agent i would not envy agent j. Now DEF follows from Lemma 7.
To prove that DYNAMIC DRF is SP, suppose for contradiction that an agent i  N can report
an untruthful demand vector d0i such that the agent is strictly better off in at least one step. Let k be
the first such step. Denote by xtj the dominant share of an agent j at step t with manipulation (for
agent i, this is the share of the dominant resource of the untruthful demand vector) and similarly,
denote by M t the value of M t in the optimal solution of the LP of step t with manipulation.
Lemma 8. xkj  xkj for every agent j  k.
Proof. For any agent j such that xkj > xki , we have
xkj = xji1 = xji1  xkj .
Here, the first transition follows from Lemma 7, the second transition holds because manipulation
by agent i does not affect the allocation at step i  1, and the third transition follows from the LP.
For any agent j with xkj  xki , we have
xkj  xki < xki = M k  xkj .
The second transition is true because if xki  xki then agent i could not be better off as the true
dominant share it receives with manipulation would be no more than it received without manipulation. To justify the third transition, note that agent i must be allocated some resources at step k
with manipulation. If k = i, this is trivial, and if k > i, this follows because otherwise k would
not be the first step when agent i is strictly better off as we would have ui (Ak1
) = ui (Aki ) >
i
k1
k
k
ui (Ai )  ui (Ai ), where Ai denotes the allocation to agent i at step k with manipulation. Thus,
xki > xk1
, and the third transition now follows from Lemma 5. The last transition holds because
i
k
xj satisfies the first constraint of the LP of step k. Thus, we conclude that xkj  xkj for all agents
j  k.  (Proof of Lemma 8)
589

fiK ASH , P ROCACCIA , & S HAH

Now, the mechanism satisfies DPO and thus allocates at least a k/n fraction of at least one
resource at step k without manipulation. Let r be such a resource. Then the fraction of resource r
allocated at step k with manipulation is
X
X
xkj  djr  k/n.
xkj  djr > xki  dir +
xki  d0ir +
jk
s.t.j6=i

jk
s.t.j6=i

To justify the inequality, note that xki  d0ir > xki  dir by Equation (1) (as agent i is strictly better
off), and in addition xkj  xkj for every j  k. However, this shows that more than a k/n fraction
of resource r must be allocated at step k with manipulation, which is impossible due to the third
constraint of the LP. Hence, a successful manipulation is impossible, that is, DYNAMIC DRF is SP.
Finally, note that the LP has a linear number of variables and constraints, therefore the mechanism can be implemented in polynomial time.  (Proof of Theorem 4)

5. Relaxing Dynamic Pareto Optimality
We saw (Theorem 3) that satisfying EF and DPO is impossible. We then explored an intuitive
relaxation of EF. Despite the positive result (Theorem 4), the idea of achieving absolute fairness 
as conceptualized by EF  in our dynamic setting is compelling.
As a straw man, consider waiting for all the agents to arrive and then using any EF static allocation mechanism. However, this scheme is highly inefficient, e.g., it is easy to see that one can always
allocate each agent at least a 1/n share of its dominant resource (and other resources in proportion)
as soon as it arrives and still maintain EF at every step. How much more can be allocated at each
step? We put forward a general answer to this question using a relaxed notion of DPO that requires
a mechanism to allocate as many resources as possible while ensuring that EF can be achieved in
the future, but first we require the following definition. Given a step k  {1, . . . , n}, define an
allocation A over the k present agents with demands dk to be EF-extensible if it can be extended
to an EF allocation over all n agents with demands d = (dk , d>k ), for all possible future demand
vectors d>k  Dnk .
40 . Cautious Dynamic Pareto optimality (CDPO). A dynamic allocation mechanism satisfies
CDPO if at every step k, the allocation Ak returned by the mechanism is not Pareto dominated by any other allocation A0 over the same k agents that is EF-extensible.
In other words, a mechanism satisfies CDPO if at every step it selects an allocation that is at
least as generous as any allocation that can ultimately guarantee EF, irrespective of future demands.
At first glance, it may not be obvious that CDPO is indeed a relaxation of DPO (i.e., that CDPO
is implied by DPO). However, note that DPO requires a mechanism to allocate at least a k/n fraction
of at least one resource r in the allocation Ak at any step k, and thus to allocate at least a 1/n
fraction of that resource to some agent i. Any alternative allocation that Pareto dominates Ak must
also allocate at least a 1/n fraction of r to agent i. Consequently, in order to ensure an EF extension
over all n agents when all the future demands are identical to the demand of agent i, the alternative
allocation must allocate at most a k/n fraction of r , as each future agent may also require at least
a 1/n fraction of r to avoid envying agent i. It follows that the alternative allocation cannot Pareto
dominate Ak . Thus, the mechanism satisfies CDPO.
590

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

Recall that DYNAMIC DRF extends the water-filling idea of the static DRF mechanism (Ghodsi
et al., 2011) to our dynamic setting. DYNAMIC DRF is unable to satisfy the original EF, because 
to satisfy DPO  at every step k it needs to allocate resources until a k/n fraction of some resource
is allocated. We wish to modify DYNAMIC DRF to focus only on competing with EF-extensible
allocations, in a way that achieves CDPO and EF (as well as other properties).
The main technical challenge is checking when an allocation at step k violates EF-extensibility.
Indeed, there are uncountably many possibilities for the future demands d>k over which an EF
extension needs to be guaranteed by an EF-extensible allocation! Of course, checking all the possibilities explicitly is not feasible. Ideally, we would like to check only a small number of possibilities.
The following lemma establishes that it is sufficient to verify that an EF extension exists under the
assumption that all future agents will have the same demand vector that is moreover identical to the
demand vector of one of the present agents.
Lemma 9. Let k be the number of present agents, dk be the demands reported by the present
agents, and A be an EF allocation over the k present agents. Then A is EF-extensible if and only
if there exists an EF extension of A over all n agents with demands d = (dk , d>k ) for all future
demands d>k  D0 , where D0 = {hd1 ink , hd2 ink , . . . , hdk ink }.
To prove this lemma, we first introduce the notion of the minimum EF extension. Intuitively, the
minimum EF extension is the smallest EF extension (allocating the least resources) of a given EF
allocation to a larger set of agents. Formally, let A be an EF allocation over a set of agents S  N
and A be an EF extension of A to a set of agents T  N (S  T ). Then A is called the minimum
EF extension of A to T if for any EF extension A0 of A to T , we have that A0 is an extension of
A . We show that the minimum EF extension exists and exhibits a simple structure.
Lemma 10. Let A be an EF allocation over a set of agents S  N and let xi be the dominant
share of agent i  S in A. Let T be such that S  T  N and let A be an allocation over T with
xi as the dominant share of agent i  T . Let xi = xi for all i  S, and xi = maxjS yij for all
i  T \ S, where yij = xj  minrR djr /dir . Then A is a minimum EF extension of A to T .
Proof. For agent i with dominant share xi to avoid envying agent j with dominant share xj , there
must exist r  R such that xi  dir  xj  djr , that is, xi  xj  djr /dir . It follows that xi 
xj  minrR djr /dir , and thus the minimum dominant share is given by yij = xj  minrR djr /dir .
Now it is easy to argue that any EF extension A0 of A over T must allocate at least an xi dominant
share to any agent i  T , for both i  S and i  T \ S, and thus A0 must be an extension of A .
It remains to prove that A is EF. First we prove an intuitive result regarding the minimum
dominant share agent i needs to avoid envying agent j, namely yij . We claim that for every r  R,
yij  dir  xj  djr .

(2)

Formally, for any r  R,
djr0
djr
 dir  xj 
 dir = xj  djr .
r R dir0
dir

yij  dir = xj  min
0

Therefore, to prevent agent i from envying agent j, we need to allocate at least an xj  djr
fraction of resource r to agent i for some r  R. Next we show that A is EF, i.e., no agent i envies
any agent j in A . We consider four cases.
591

fiK ASH , P ROCACCIA , & S HAH

Case 1: i  S and j  S. This case is trivial as A is identical to A over S and A is EF.
Case 2: i  T \ S and j  S. This case is also trivial because i receives at least a yij fraction of
its dominant resource.
Case 3: i  S and j  T \ S. We must have xj = yjt for some t  S. Agent i does not envy
agent t in A, and hence in A . Thus, there exists a resource r  R such that Air  Atr  Ajr ,
where the last step follows from Equation (2). Thus, agent i does not envy agent j.
Case 4: i  T \ S and j  T \ S. Similarly to Case 3, let xj = yjt for some t  S. Now xi  yit ,
so agent i does not envy agent t in A . Thus, there exists a resource r such that Air  Atr  Ajr ,
where again the last step follows from Equation (2).
Therefore, A is an EF extension of A over T and we have already established that any EF
extension of A over T must be an extension of A . We conclude that A is a minimum EF extension
of A over T .  (Proof of Lemma 10)
It is not hard to see from the construction of the minimum EF extension that it not only exists,
it is unique. We are now ready to prove Lemma 9.
Proof of Lemma 9. The only if direction of the proof is trivial. To prove the if part, we prove
its contrapositive. Assume that there exist future demand vectors d>k  Dnk such that there does
not exist any EF extension of A to N with demands d = (dk , d>k ). We want to show that there
exists d0>k  D0 for which there is no EF extension as well.
Let K = {1, . . . , k} and N \ K = {k + 1, . . . , n}. Denote the minimum EF extension of A
to N with demands d by A . Let the dominant share of agent i  K in A be xi and the dominant
share of agent j  N in A be xj .

No EF extension of A over N with demands
Pn d is feasible, hence A must be infeasible too.
Therefore, there exists a resource r such that i=1 xi dir > 1. Note that for every agent j  N \K,
there exists an agent i  K such that xj = xi  minr0 R dir0 /djr0 , and hence xj  djr  xi  dir by
Equation (2). Taking the maximum over i  K, we get that xj  djr  maxiK (xi  dir ) for every
agent j  N \ K. Taking t  arg maxiK (xi  dir ),
1<

n
X

xi  dir =

i=1

k
X

xi  dir +

i=1



k
X

n
X

xi  dir

i=k+1

xi  dir + (n  k)  xt  dtr .

i=1

Consider the
case where
d0>k = hdt ink  D0 . The minimum EF extension A0 of A to N with


ff
demands d0 = dk , d0>k allocates an xi dominant share to every i  K (same as A) and allocates
exactly
an xt dominant share to every j  N \ K. Thus, the fraction of resource r allocated in A0 is
Pk
0
i=1 xi  dir + (n  k)  xt  dtr > 1, implying that the minimum EF extension of d>k is infeasible.
0
We conclude that there is no feasible EF extension for d>k , as required.  (Proof of Lemma 9)
The equivalent condition of Lemma 9 provides us with k  m linear constraints that can be
checked to determine whether an allocation over k agents is EF-extensible. Using this machinery, we can write down a small linear program (LP) that begins with the allocation chosen in
the previous step (recall that the allocations are irrevocable), gives agent k a jump start so that it
does not envy agents 1 through k  1, and then uses water-filling to allocate resources similarly to
592

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

DYNAMIC DRF, but subject to the constraint that the allocation stays EF-extensible. This intuition
is formalized via the mechanism C AUTIOUS LP, which is given as Algorithm 2.
ALGORITHM 2: C AUTIOUS LP
Data: Demands d
Result: Allocation Ak at each step k
k  1;
while k  n do
{xki }ki=1  Solution of the LP in the box below;
Akir  xki  dir , i  k;
k k+1
end
Maximize M k
subject to
xki  M k , i  k
xki  xk1
, i k  1
i



min
d
/d
xkk  maxik1 xk1
rR ir kr
i
Pk
k
k
i=1 xi  dir + (n  k)  xt  dtr  1, t  k, r  R
The mechanisms third LP constraint jump-starts agent k to a level where it does not envy earlier
agents, and the fourth LP constraint is derived from Lemma 9. To see why the mechanism satisfies
CDPO, observe that if at any step k there is an EF-extensible allocation A0 that Pareto dominates the
allocation Ak returned by the mechanism, then (by Lemma 9) A0 must also satisfy the LP at step k.
However, it can be shown that no allocation from the feasible region of the LP can Pareto dominate
Ak . Indeed, if an allocation from the feasible region did dominate Ak , we could redistribute some
of the resources of the agent that is strictly better off to obtain a feasible allocation with a value of
M k that is higher than the optimal solution. It is also easy to see why intuitively C AUTIOUS LP is
EF: the initial allocation to agent k achieves an EF allocation over the k agents, and water-filling
preserves EF because it always allocates to agents with minimum dominant share. It is equally
straightforward to show that C AUTIOUS LP also satisfies SI. Establishing SP requires some work,
but the proof is mainly a modification of the proof of Theorem 4. We are therefore able to establish
the following theorem, which formalizes the guarantees given by C AUTIOUS LP.
Theorem 11. C AUTIOUS LP satisfies SI, EF, CDPO, and SP, and can be implemented in polynomial
time.
Proof. The proof is along the lines of the proof of Theorem 4. For now, assume that the LP is
feasible at each step and thus the mechanism does return an allocation at each step (we show this
below). In the LP at step k, let


k1
k
E = max xi  min dir /dkr .
rR

ik1

Intuitively, E k is the jump start that agent k requires at the beginning of step k to be envy free of
the allocations of agents 1 through k  1 from step k  1.
593

fiK ASH , P ROCACCIA , & S HAH

Proof of CDPO: First we show that C AUTIOUS LP satisfies CDPO. Assume for contradiction,
that at some step k  {1, . . . , n}, an alternative EF-extensible allocation A0 over the k present
agents Pareto dominates the allocation Ak returned by the mechanism. Let x0i be the dominant
share of agent i in A0 , for i  k. Since A0 Pareto dominates Ak , we have that x0i  xki for every
i  k. This trivially implies that A0 also satisfies the first three constraints of the LP at step k.
Moreover, since A0 is EF-extensible, it also satisfies the fourth constraint of the LP at step k as the
fourth constraint only requires EF extension to exist in specific cases (in particular, it requires the
minimum EF extension and thus any EF extension over all n agents to exist when all future demand
vectors are identical to the demand vector of some present agent). Thus, A0 is in the feasible region
of the LP and Pareto dominates an optimal solution Ak . Now, taking back the extra resources that
A0 allocates to agents compared to Ak shows that the fourth constraint is not tight in Ak for any
value of t and r (the assumption of strictly positive demands is crucial here). However, this implies
that in the allocation Ak , every xki and correspondingly M k can be increased by a sufficiently small
quantity while still satisfying the LP at step k, which contradicts the optimality of Ak . Thus, no
alternative EF-extensible allocation can Pareto dominate the allocation given by the mechanism at
any step, i.e., C AUTIOUS LP satisfies CDPO.
Proof of SI: Next, we show that C AUTIOUS LP satisfies SI. We show this by induction over step
k. For the base case k = 1, it is easy to show that setting x11 = 1/n and M k = 1/n satisfies the
LP at step 1; it trivially satisfies the first three constraints of the LP and for the fourth constraint,
observe that
1
1
 dir + (n  1)   dir = dir  1, r  R.
n
n
Therefore, in the optimal solution, M 1  1/n and thus x11  1/n (in fact, equality holds).
Now consider any step k  {2, . . . , n}. As our induction hypothesis, we assume that xti  1/n
for all agents i  t, at every step t  k  1. We want to show that xki  1/n for all agents i  k.
Consider two cases.
1. E k  1/n. Observe that xk1
 1/n for all i  k  1 due to the induction hypothesis. Thus,
i
using the second and the third constraints of the LP at step k, we have xki  1/n for all i  k.
2. E k < 1/n. We first show that xki = xk1
for i  k  1, xkk = 1/n and M k = 1/n is in the
i
feasible region of the LP at step k. Note that this assignment trivially satisfies the first three
constraints of the LP.
For the fourth constraint, fix any r  R. Define Tr = maxik1 xik1  dir . First, we show
P
k1
that k1
 dir  1  (n  k + 1)  max(Tr , 1/n). To see this, note that {xik1 }k1
i=1 xi
i=1
satisfies the LP at step k  1 and, in particular, the fourth constraint of the LP. Therefore,
k1
X

xk1
 dir + (n  k + 1)  Tr  1 =
i

i=1

k1
X

xk1
 dir  1  (n  k + 1)  Tr .
i

i=1

Now we prove that
k1
X

xk1
 dir  1  (n  k + 1)  1/n = (k  1)/n.
i

i=1

594

(3)

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

Suppose for contradiction that the left hand side is more than (k  1)/n. Then, by the pigeonhole principle, there exists some agent i  k  1 such that xk1
 dir  1/n, and thus
i
Tr  1/n. But we have already shown that
k1
X

xk1
 dir  1  (n  k + 1)  Tr  1  (n  k + 1)  1/n = (k  1)/n,
i

i=1

contradicting our assumption; this establishes (3). Thus, we have that
k1
X
i=1

xk1
i



1
.
 dir  1  (n  k + 1)  max Tr ,
n

Finally, we show that in the fourth constraint of the LP, xkt  dtr  max(Tr , 1/n). To see this,
observe that for t  k 1, xkt dtr = xk1
dtr  Tr and for t = k, xkt dtr = 1/ndkr  1/n.
t
Thus, the fourth constraint of the LP is satisfied for every t  k and every r  R.
We have established that C AUTIOUS LP satisfies SI. Our next goal is to prove that the mechanism also satisfies EF and SP. As in the proof of Theorem 4, we first establish several useful lemmas
about the allocations returned by C AUTIOUS LP. In the proof below, M k and xki refer to the optimal
solution of the LP in step k.
We begin with the following lemma (similar to Lemma 5), which essentially shows that if an
agent is allocated some resources in step k using water-filling (in addition to the jump-start to E k for
agent k), then the agents dominant share after the step would be the minimum among the present
agents.
Lemma 12. At every step k  {1, . . . , n}, it holds that xki = max(M k , xk1
) for all agents
i
k
k
k
i  k  1, and xk = max(M , E ).
Proof. Consider any step k  {1, . . . , n}. From the first three constraints of the LP, it is evident that
)
xki  M k for all i  k, xki  xk1
for all i  k  1 and xkk  E k . Thus, xki  max(M k , xk1
i
i
for all i  k  1 and xkk  max(M k , E k ).
Suppose for contradiction that a strict inequality holds for some agent i  k. Then xki can
be reduced by a sufficiently small  > 0 without violating any constraints. This makes the third
constraint of the LP loose by at least   dir , for every resource r  R. Consequently, the values
of xkj for j 6= i and M k can be increased by a sufficiently small  > 0 without violating the
third constraint of the LP. Finally,  (and correspondingly ) can be chosen to be small enough so
that xki  M k is not violated. It follows that the value of M k can be increased, contradicting the
optimality of M k .  (Proof of Lemma 12)
Next, we formulate the equivalent of Lemma 6 as two separate lemmas. First we show that if an
agent has greater or equal dominant share than another agent in some step (where both are present),
then the order is preserved in future steps. Next we show that at each step k, the dominant shares
of agents 1 through k are monotonically non-increasing with their time of arrival, except for agents
that have not received any resources apart from their jump-start.
Lemma 13. For any agents i, j  N and any step k  max(i, j) (i.e., both agents are present at
step k), xki  xkj implies that xti  xtj for all t  k.
595

fiK ASH , P ROCACCIA , & S HAH

Proof. Fix any two agents i, j  N and step k  max(i, j) such that xki  xkj . We use induction on
t. The result trivially holds for t = k. Consider any t > k and assume the result holds for step t  1.
t1
t
t
t
Then, since t > k  max(i, j) we know that xti = max(xt1
i , M )  max(xj , M ) = xj , where
the first and the last transitions follow from Lemma 12 and the second transition follows from our
induction hypothesis.  (Proof of Lemma 13)
Lemma 14. For all agents i, j  N such that i < j and any step k  j, we have that either i)
xki  xkj or ii) xkj = xjj = E j .
Proof. Fix any two agents i, j  N such that i < j and any step k  j. Note that xkj  xjj 
E j , where the first inequality is due to irrevocability of resources and the last inequality is due to
Lemma 12. If xkj = E j , then the lemma trivially holds. Assume xkj > E j . Consider the first step t
where xtj > E j (thus j  t  k). If t = j, then we have xjj > E j . If t > j, then we have xtj > xt1
j
j by the definition of t. In any case, Lemma 12 implies that xt = M t  xt . Thus
since xt1
=
E
j
i
j
we have xtj  xti and now Lemma 13 implies that xkj  xki .  (Proof of Lemma 14)
We now consider the equivalent of Lemma 7 from the proof of Theorem 4, and observe that
there are two cases. If agent j has greater dominant share than agent i at some step, then either j
arrived before i and j has not been allocated any resources since i arrived (as we had previously),
or j arrived after i and has not been allocated any resources apart from its jump-start.
Lemma 15. For any agents i, j  N and any step k  max(i, j) (i.e., both agents are present),
xkj > xki implies that either i) j < i and xkj = xji1 , or ii) j > i and xkj = xjj = E j .
Proof. Fix any two agents i, j  N and any step k  max(i, j) such that xkj > xki . Note that if
j > i then Lemma 14 implies that xkj = xjj = E j and the result holds trivially. Now assume j < i.
Suppose for contradiction that xkj > xji1 (it cannot be smaller because allocations are irrevocable). Then there exists a step t  {i, . . . , k} such that xtj > xt1
j . Therefore, Lemma 12 implies
t
t
t
k
that xj = M  xi . Using Lemma 13 this shows that xj  xki , which is a contradiction to the
assumption that xkj > xki . Thus we have xkj = xi1
j , as required.  (Proof of Lemma 15)
Finally, we establish an additional lemma which will be helpful in proving SP. For agents i, j
such that j > i, if the jump-start E j for agent j requires allocating agent j greater dominant share
than agent i had in step j  1, then clearly the jump-start must have been due to agent j envying
some agent l 6= i, and l must have greater dominant share than i in step j  1. But then using
Lemma 14 and extending the argument, we can eventually trace this back to an agent t < i. We
show that we can find such t < i such that the jump-start of the original agent j was actually due to
agent j envying agent t.
Lemma 16. For any agents i, j  N such that j > i, E j > xji implies that E j = xj1

t
minrR dtr /djr , for some agent t < i.
Proof. Fix any agent i  N . We use induction over j  {i + 1, . . . , n}. First, we prove several
implications that hold for any agent j > i. Recall that E j = maxp<j (xj1
 minrR dpr /djr ).
p
596

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

Thus, we have E j = xlj1  minrR dlr /djr for some agent l < j. But it does not follow from the
definition that we can take l < i. Observe that
xlj1  xlj1  min dtr /djr = E j > xji  xj1
,
i
rR

(4)

where the first transition holds since minrR dtr /djr is at most 1 (consider the dominant resource
of agent j), the third transition is the assumption of the lemma and the last transition holds since
allocations are irrevocable.
Now we have three cases. If l < i, then we are done. Further, l 6= i since Equation (4) shows
that xj1
> xj1
. Now assume that l > i. Note that this case cannot appear in the base case
i
l
j = i + 1 since l < j. Therefore, the argument given above already shows that the lemma holds
for the base case j = i + 1. By our induction hypothesis, we assume that the lemma holds for
agent l < j. Now since l > i and xj1
> xj1
= xll = E l and
, Lemma 15 implies that xj1
i
l
l
j1
j1
l
l
l
thus E > xi
 xi where xi
 xi because l < j and allocations are irrevocable. Due to
our induction hypothesis, there exists t < i such that E l = xl1
 minrR dtr /dlr . We prove that
t
E j = xtj1  minrR dtr /djr . Indeed,
 min dlr /djr
E j = xj1
l
rR

l

= E  min dlr /djr
rR

=

xl1
t

 min dtr /dlr  min dlr /djr



xl1
t

 min dtr /djr



xj1
t

 min dtr /djr  E j .

rR

rR

rR

rR

Here, the fourth transition is true because for any r0  R,
dtr0
dtr0 dlr0
dtr
dlr
=

 min
 min
.
0
0
0
rR dlr rR djr
djr
dlr djr
Taking minimum over all r0  R, we get that minrR dtr /djr  minrR dtr /dlr  minrR dlr /djr .
The last transition holds due to the definition of E j . Now it is trivial to see that we must have equality
at every step, so E j = xj1
 minrR dtr /djr for t < i, as required.  (Proof of Lemma 16)
t
Proof of LP Feasibility and EF: Now we use an inductive argument to simultaneously show that
the LP of C AUTIOUS LP is feasible at every step and that C AUTIOUS LP satisfies EF. Consider the
following induction hypothesis: the LP at step t is feasible and the allocation At returned by the
mechanism at step t is EF. For the base case t = 1, the LP is trivially feasible and the allocation A1
is also trivially EF. Assume that the hypothesis holds for t = k  1 for some step k  {2, . . . , n}.
We want to show that the hypothesis holds for step k.
For feasibility, we show that the allocation A given by xki = xk1
for i  k  1 and xkk = E k
i
k
along with M = 0 satisfies the LP at step k. Clearly, it satisfies the first three constraints of the LP.
To see why it satisfies the fourth constraint, note that Ak1 is an EF allocation due to our induction
hypothesis. Moreover, it satisfies the LP at step k  1, in particular, the fourth constraint of the
LP. Hence Lemma 9 implies that Ak1 must be an EF-extensible allocation. Let dk denote the
597

fiK ASH , P ROCACCIA , & S HAH

demand reported by agent k in step k and let d>k  Dnk . Then any EF extension of Ak1 over
all n agents with future demands (dk , d>k ) is an EF extension of A over all n agents with future
demands d>k . Since this holds for any d>k  Dnk , A is EF-extensible and hence satisfies the
fourth constraint of the LP. We conclude that the LP is feasible at step k.
Now we want to show that the allocation Ak is an EF allocation. Intuitively, we can see that
the mechanism starts from A which is EF (it is a minimum EF extension), and then uses waterfilling to allocate more resources in a way that preserves EF. Formally, note that the dominant shares
allocated to agents in Ak are given by Lemma 12. Take any two agents i, j  k. We want to show
that agent i does not envy agent j in step k. Denote the dominant share of an agent l in A by xl ,
i.e., xl = xk1
for l  k  1 and xk = E k . It holds that
l






djr
djr
xki = max xi , M k  max xj  min
, M k  max xj , M k  min
rR dir
rR dir
= xkj  min djr /dir ,
rR

where the first and the last transitions follow from Lemma 12, the second transition holds since the
allocation A is EF, and the third transition holds since the quantity minrR djr /dir is at most 1.
Thus, Ak is EF. By induction, it holds that the LP of C AUTIOUS LP is feasible at every step and
C AUTIOUS LP is EF.
Proof of SP: Our last task is to prove that C AUTIOUS LP is SP. Suppose for contradiction that
an agent i  N can report an untruthful demand vector d0i such that the agent is strictly better off in
at least one step. Let k be the first such step. Denote by xtj the dominant share of an agent j at step
t with manipulation (for agent i, this is the share of the dominant resource of the untruthful demand
vector) and, similarly, denote by M t the value of M t in the optimal solution of the LP of step t with
manipulation.
Lemma 17. xkj  xkj for every agent j  k.
Proof. Fix any agent j  k. We provide a case by case analysis and show that the lemma holds in
each case.
1. xkj  xki . In this case, we have
xkj  xki < xki = M k  xkj .
The second transition holds because if xki  xki then agent i could not be better off as the
share of the dominant resource of its true demand vector that it receives with manipulation
would be no more than it received without manipulation. To justify the third transition, note
that agent i must be allocated some resources at step k with manipulation. If k = i, then
note that since E i only depends on the allocation at step i  1 which is not affected due
to manipulation by agent i, we have E i = E i  xii < xii and Lemma 12 implies that
, but then
xii = M i . If k > i and xki 6= M k , then Lemma 12 implies that xki = xk1
i
k ) > u (Ak )  u (Ak1 ), where Ak is the allocation to agent i at step
ui (Ak1
)
=
u
(
A
i
i
i
i
i
i
i
i
k with manipulation. That is, agent i would have been better off with manipulation in step
k  1, which is a contradiction since k is the first such step. The last transition holds because
xkj satisfies the first constraint of the LP of step k with manipulation.
598

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

2. xkj > xki . For this, we have three sub-cases.
(a) j < i. Then we have xkj = xi1
= xi1
 xkj , where the first transition follows
j
j
due to Lemma 15, the second transition holds because manipulation by agent i does not
affect the allocations at step i  1, and the third transition follows since allocations are
irrevocable.
(b) j = i. This cannot happen since we have assumed xkj > xki in this case.
(c) j > i. Since xkj > xki , Lemma 15 implies that xkj = xjj = E j , so E j > xki .
Now using Lemma 16, E j = xj1
 minrR dtr /djr for some t < i. Then, xj1

t
t
j1
j1
j
k
xt  minrR dtr /djr = E > xi  xi , where the first transition follows since
minrR dtr /djr is at most 1 and the last transition follows since allocations are irrevocable. Now Lemma 15 implies that xj1
= xti1 . Putting all the pieces together,
t
xkj = E j = xtj1  min dtr /djr = xti1  min dtr /djr = xj1
 min dtr /djr
t
rR



xj1
t

j

 min dtr /djr  E 
rR

xjj



rR
xkj ,

rR

where the fifth transition follows since manipulation by agent i does not change the
allocation at step i  1, the sixth transition follows due to the definition of E j (which
is the value of E j after manipulation), the seventh transition follows due to the third
constraint of the LP at step j after manipulation, and the last transition follows since
allocations are irrevocable.
Thus, we conclude that xkj  xkj for all agents j  k.  (Proof of Lemma 17)
Now, in the optimal solution of the LP at step k without manipulation (i.e., in Ak ), the fourth
constraint must be tight for some t  k and r  R (otherwise xkj for every j  k and M k can be
increased, contradicting the optimality of M k ). Thus,
k
X

xkj  djr + (n  k)  xkt  dtr = 1.

j=1

Now consider the fourth constraint of the LP at step k after manipulation for the same values of
t and r. For simplicity of notation, let d0jr = djr for j 6= i. Then,
k
X
j=1

xkj  d0jr + (n  k)  xkt  d0tr >

k
X

xkj  djr + (n  k)  xkt  dtr = 1.

j=1

To justify the inequality, note that xki  d0ir > xki  dir by Equation (1) (as agent i is strictly better
off), and for any j  k such that j 6= i, xkj  d0jr = xkj  djr  xkj  djr by Lemma 17. However, this
shows that the allocation at step k with manipulation violates the fourth constraint of the LP, which
is impossible. Hence, a successful manipulation is impossible, that is, C AUTIOUS LP is SP.
Finally, note that at every step the LP has O(n) variables and O(n  m) constraints, and there
are n such steps. Hence, the mechanism can be implemented in polynomial time.  (Proof of
Theorem 11)
599

fiK ASH , P ROCACCIA , & S HAH

6. Experimental Results
We presented two potentially useful mechanisms, DYNAMIC DRF and C AUTIOUS LP, each with
its own theoretical guarantees. Our next goal is to analyze the performance of both mechanisms on
real data, for two natural objectives: the sum of dominant shares (the maxsum objective) and the
minimum dominant share (the maxmin objective) of the agents present in the system.1
We compare the objective function values achieved by the two mechanisms with certain lower
and upper bounds. Since both mechanisms satisfy SI, their maxsum and maxmin objective values
are provably lower bounded by k/n and 1/n, respectively, at step k.
For upper bounds, we consider the omniscient (hence unrealistic) mechanisms that maximize
the objectives in an offline setting where the mechanisms have complete knowledge of future demands. These mechanisms need to guarantee an EF extension only on the real future demands rather
than on all possible future demands. The comparison of C AUTIOUS LP with these offline mechanisms demonstrates the loss C AUTIOUS LP (an online mechanism) suffers due to the absence of
information regarding the future demands, that is, due to its cautiousness. Because DYNAMIC DRF
is not required to have an EF extension, the offline mechanisms are not theoretical upper bounds for
DYNAMIC DRF, but our experiments show that they provide upper bounds in practice.
As our data we use traces of real workloads on a Google compute cell, from a 7 hour period in
2011 (Hellerstein, 2010). The workload consists of tasks, where each task ran on a single machine,
and consumed memory and one or more cores; the demands fit our model with two resources. For
various values of n, we sampled n random positive demand vectors from the traces and analyzed
the value of the two objective functions under DYNAMIC DRF and C AUTIOUS LP along with the
corresponding lower and upper bounds. We averaged over 1000 such simulations to obtain data
points.
Figures 4(a) and 4(b) show the maxsum values achieved by the different mechanisms, for 20
agents and 100 agents respectively. The performance of our two mechanisms is nearly identical.
Figures 4(c) and 4(d) show the maxmin values achieved for 20 agents and 100 agents, respectively. Observe that DYNAMIC DRF performs better than C AUTIOUS LP for lower values of k,
but performs worse for higher values of k. Intuitively, DYNAMIC DRF allocates more resources
in early stages to satisfy DPO while C AUTIOUS LP cautiously waits. This results in the superior
performance of DYNAMIC DRF in initial steps but it has fewer resources available and thus lesser
flexibility for optimization in later steps, resulting in inferior performance near the end. In contrast,
C AUTIOUS LP is later able to make up for its loss in early steps. Encouragingly, by the last step
C AUTIOUS LP achieves near optimal maxmin value. For the same reason, unlike DYNAMIC DRF
the maxmin objective value for C AUTIOUS LP monotonically increases as k increases in our experiments (although it is easy to show that this is not always the case).

7. Discussion
We have presented a new model for resource allocation with multiple resources in dynamic environments that, we believe, can spark the study of dynamic fair division more generally. The model is
directly applicable to data centers, clusters, and cloud computing, where the allocation of multiple
resources is a key issue, and it significantly extends the previously studied static models. That said,
1. Under a cardinal notion of utility where the dominant share of an agent is its utility, the sum of dominant shares is
the utilitarian social welfare and the minimum dominant share is the egalitarian social welfare.

600

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

Upper Bound
CautiousLP
DynamicDRF
Lower Bound

2.5
2

Upper Bound
CautiousLP
DynamicDRF
Lower Bound

2.25

1.5

1.5

1
0.75
0.5
0

0
0

5

10

15

20

0

(a) Maxsum for 20 agents

0.095

50

75

100

(b) Maxsum for 100 agents

0.0175

Upper Bound
CautiousLP
DynamicDRF
Lower Bound

0.08

25

Upper Bound
CautiousLP
DynamicDRF
Lower Bound

0.015

0.065

0.0125

0.05

0.01
0

5

10

15

20

0

(c) Maxmin for 20 agents

25

50

75

100

(d) Maxmin for 100 agents

Figure 4: The maxsum and maxmin objectives as a function of the time step k, for n = 20 and
n = 100.

the model also gives rise to technical challenges that need to be tackled to capture more realistic
settings.
First, our model assumes positive demands, that is, each agent requires every resource. To see
how the positive demands assumption plays a role, recall that achieving EF and DPO is impossible.
We established that dropping DPO leads to the trivial mechanism E QUAL S PLIT, which satisfies the
remaining three properties; this is also true for possibly zero demands. When we dropped EF, we
observed that the trivial mechanism DYNAMIC D ICTATORSHIP satisfies SI, DPO and SP, and we
subsequently suggested the improved mechanism DYNAMIC DRF that satisfies DEF in addition to
SI, DPO and SP. Surprisingly though, it can be shown that neither DYNAMIC D ICTATORSHIP (see
Example 2) nor DYNAMIC DRF are SP under possibly zero demands.2 In fact, despite significant
effort, we were unable to settle the question of the existence of a mechanism that satisfies SI, DPO
and SP under possibly zero demands.
Second, our analysis is restricted to the setting of divisible tasks, where agents value fractional
quantities of their tasks. Parkes et. al. (2014) consider the indivisible tasks setting, where only
2. Under possibly zero demands, we modify DYNAMIC D ICTATORSHIP and DYNAMIC DRF to continue allocating
even when some resources become saturated so that they satisfy DPO.

601

fiK ASH , P ROCACCIA , & S HAH

integral quantities of an agents task are executed, albeit in a static environment. It can be shown
that even forward EF  the weakest of all EF relaxations considered in this paper  is impossible
to achieve along with DPO under indivisible tasks. It remains open to determine which relaxations
of EF are feasible in dynamic resource allocation settings with indivisible tasks. While we restrict
our attention to Leontief utilities, it should be noted that the desiderata we propose are well-defined
in our dynamic setting with any utility function.
Third, while our model of fair division extends the classical model by introducing dynamics,
and our results can directly inform the design of practical mechanisms, we do make the assumption
that agents arrive over time but do not depart. In reality, agents may arrive and depart multiple times,
and their preferences may also change over time (note that changing preferences can be modeled
as a departure and simultaneous re-arrival with a different demand vector). Departures without
re-arrivals are easy to handle; one can allocate the resources that become free in a similar way to
allocations of entitlements, e.g., using DYNAMIC DRF (this scheme would clearly satisfy SI, DEF,
and DPO, and it would be interesting to check whether it is also strategyproof). However, departures
with re-arrivals immediately lead to daunting impossibilities. Note though that mechanisms that
were designed for static settings performed well in realistic (fully dynamic) environments (Ghodsi
et al., 2011), and it is quite likely that our mechanisms  which do provide theoretical guarantees
for restricted dynamic settings  would yield even better performance in reality.

Acknowledgements
A preliminary version of this paper appeared in AAMAS13. Procaccia and Shah were partially
supported by the NSF under grant NSF CCF-1215883, and by a gift from the CMU-MSR Center
for Computational Thinking.

References
Brams, S. J., & Taylor, A. D. (1996). Fair Division: From Cake-Cutting to Dispute Resolution.
Cambridge University Press.
Chen, Y., Lai, J. K., Parkes, D. C., & Procaccia, A. D. (2010). Truth, justice, and cake cutting. In
Proceedings of the 24th AAAI Conference on Artificial Intelligence (AAAI), pp. 756761.
Chevaleyre, Y., Dunne, P. E., Endriss, U., Lang, J., Lematre, M., Maudet, N., Padget, J., Phelps,
S., Rodrguez-Aguilar, J. A., & Sousa, P. (2006). Issues in multiagent resource allocation.
Informatica, 30, 331.
Chevaleyre, Y., Endriss, U., Estivie, S., & Maudet, N. (2007). Reaching envy-free states in distributed negotiation settings. In Proceedings of the 20th International Joint Conference on
Artificial Intelligence (IJCAI), pp. 12391244.
Demers, A., Keshav, S., & Shenker, S. (1989). Analysis and simulation of a fair queueing algorithm. In Proceedings of the ACM Symposium on Communications Architectures & Protocols
(SIGCOMM), pp. 112.
Dolev, D., Feitelson, D. G., Halpern, J. Y., Kupferman, R., & Linial, N. (2012). No justified complaints: On fair sharing of multiple resources. In Proceedings of the 3rd Innovations in Theoretical Computer Science Conference (ITCS), pp. 6875.
602

fiN O AGENT L EFT B EHIND : DYNAMIC FAIR D IVISION OF M ULTIPLE R ESOURCES

Ghodsi, A., Sekar, V., Zaharia, M., & Stoica, I. (2012). Multi-resource fair queueing for packet
processing. In Proceedings of the ACM Symposium on Communications Architectures &
Protocols (SIGCOMM), pp. 112.
Ghodsi, A., Zaharia, M., Hindman, B., Konwinski, A., Shenker, S., & Stoica, I. (2011). Dominant Resource Fairness: Fair allocation of multiple resource types. In Proceedings of the 8th
USENIX Conference on Networked Systems Design and Implementation (NSDI), pp. 2437.
Ghodsi, A., Zaharia, M., Shenker, S., & Stoica, I. (2013). Choosy: Max-min fair sharing for datacenter jobs with constraints. In Proceedings of the 8th ACM European Conference on Computer
Systems (EUROSYS), pp. 365378.
Gutman, A., & Nisan, N. (2012). Fair allocation without trade. In Proceedings of the 11th International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS), pp.
719728.
Hellerstein, J. L. (2010). Google cluster data. Google research blog. Posted at http://
googleresearch.blogspot.com/2010/01/google-cluster-data.html.
Joe-Wong, C., Sen, S., Lan, T., & Chiang, M. (2012). Multi-resource allocation: Fairness-efficiency
tradeoffs in a unifying framework. In Proceedings of the 31st Annual IEEE International
Conference on Computer Communications (INFOCOM), pp. 12061214.
Li, J., & Xue, J. (2013). Egalitarian division under Leontief preferences. Economic Theory, 54(3),
597622.
Moulin, H. (2003). Fair Division and Collective Welfare. MIT Press.
Moulin, H., & Stong, R. (2002). Fair queuing and other probabilistic allocation methods. Mathematics of Operations Research, 27(1), 130.
Parkes, D. C., Procaccia, A. D., & Shah, N. (2014). Beyond Dominant Resource Fairness: Extensions, limitations, and indivisibilities. ACM Transactions on Economics and Computation.
Forthcoming.
Procaccia, A. D. (2009). Thou shalt covet thy neighbors cake. In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI), pp. 239244.
Walsh, T. (2011). Online cake cutting. In Proceedings of the 3rd International Conference on
Algorithmic Decision Theory (ADT), pp. 292305.
Zahedi, S. M., & Lee, B. C. (2014). REF: Resource elasticity fairness with sharing incentives
for multiprocessors. In Proceedings of the 19th International Conference on Architectural
Support for Programming Languages and Operating Systems (ASPLOS), pp. 145160.

603

fiJournal of Artificial Intelligence Research 51 (2014) 829-866

Submitted 06/14; published 12/14

An Exact Double-Oracle Algorithm for Zero-Sum
Extensive-Form Games with Imperfect Information
Branislav Bosansky

branislav.bosansky@agents.fel.cvut.cz

Agent Technology Center
Department of Computer Science
Faculty of Electrical Engineering
Czech Technical University in Prague

Christopher Kiekintveld

cdkiekintveld@utep.edu

Computer Science Department
University of Texas at El Paso, USA

Viliam Lisy
Michal Pechoucek

viliam.lisy@agents.fel.cvut.cz
michal.pechoucek@agents.fel.cvut.cz

Agent Technology Center
Department of Computer Science
Faculty of Electrical Engineering
Czech Technical University in Prague

Abstract
Developing scalable solution algorithms is one of the central problems in computational
game theory. We present an iterative algorithm for computing an exact Nash equilibrium
for two-player zero-sum extensive-form games with imperfect information. Our approach
combines two key elements: (1) the compact sequence-form representation of extensiveform games and (2) the algorithmic framework of double-oracle methods. The main idea of
our algorithm is to restrict the game by allowing the players to play only selected sequences
of available actions. After solving the restricted game, new sequences are added by finding
best responses to the current solution using fast algorithms.
We experimentally evaluate our algorithm on a set of games inspired by patrolling
scenarios, board, and card games. The results show significant runtime improvements in
games admitting an equilibrium with small support, and substantial improvement in memory use even on games with large support. The improvement in memory use is particularly
important because it allows our algorithm to solve much larger game instances than existing
linear programming methods.
Our main contributions include (1) a generic sequence-form double-oracle algorithm for
solving zero-sum extensive-form games; (2) fast methods for maintaining a valid restricted
game model when adding new sequences; (3) a search algorithm and pruning methods for
computing best-response sequences; (4) theoretical guarantees about the convergence of
the algorithm to a Nash equilibrium; (5) experimental analysis of our algorithm on several
games, including an approximate version of the algorithm.

1. Introduction
Game theory is a widely used methodology for analyzing multi-agent systems by applying
formal mathematical models and solution concepts. One focus of computational game theory is the development of scalable algorithms for reasoning about very large games. The
c
2014
AI Access Foundation. All rights reserved.

fiBosansky, Kiekintveld, Lisy, & Pechoucek

need for continued algorithmic advances is driven by a growing number of applications of
game theory that require solving very large game instances. For example, several decision
support systems have recently been deployed in homeland security domains to recommend
policies based on game-theoretic models for placing checkpoints at airports (Pita, Jain,
Western, Portway, Tambe, Ordonez, Kraus, & Parachuri, 2008), scheduling Federal Air
Marshals (Tsai, Rathi, Kiekintveld, Ordonez, & Tambe, 2009), and patrolling ports (Shieh,
An, Yang, Tambe, Baldwin, Direnzo, Meyer, Baldwin, Maule, & Meyer, 2012). The capabilities of these systems are based on a large amount of research in fast algorithms for
security games (Tambe, 2011). Another notable example is the algorithmic progress that
has led to game-theoretic Poker agents that are competitive with highly skilled human
opponents (e.g., see Zinkevich, Bowling, & Burch, 2007; Sandholm, 2010).
We focus on developing new algorithms for an important general class of games that
includes security games and Poker, as well as many other familiar games. More precisely, we
study two-player zero-sum extensive-form games (EFGs) with imperfect information. This
class of games captures sequential interactions between two strictly competitive players in
situations where they make decisions under uncertainty. Uncertainty can be caused either
by having a stochastic environment or by having opponent actions that are not directly
observable. We consider general models for both sequential interactions and uncertainty,
while many of the fast algorithms that have been developed for Poker and security domains
rely on more specific game structure.
We propose a new class of algorithms for finding exact (or approximate) Nash equilibrium solutions for the class of EFGs with imperfect information. The leading exact
algorithm in the literature uses the compact sequence-form representation and linear programming optimization techniques to solve games of this type (Koller, Megiddo, & von
Stengel, 1996; von Stengel, 1996). Our approach exploits the same compact representation, but we improve the solution methods by adopting the algorithmic framework based
on decompositions known in the computational game theory literature as oracle algorithms
(McMahan, Gordon, & Blum, 2003). Oracle algorithms are related to the methods of constraint/column generation used for solving large-scale optimization problems (Dantzig &
Wolfe, 1960; Barnhart, Johnson, Nemhauser, Savelsbergh, & Vance, 1998) and exploit two
characteristics commonly found in games. First, in many cases finding a solution to a
game only requires using a small fraction of the possible strategies, so it is not necessary to
enumerate all of the strategies to find a solution (Wilson, 1972; Koller & Megiddo, 1996).
Second, finding a best response to a specific opponent strategy in a game is computationally
much less expensive than solving for an equilibrium. In addition, best response algorithms
can often make use of domain-specific knowledge or heuristics to speed up the calculations
even further.
Our sequence-form double-oracle algorithm integrates the decomposition ideas of oracle
algorithms with the compact sequence-form representation for EFGs with imperfect information. This results in an iterative algorithm that does not always need to generate the
complete linear program for the game to find a Nash equilibrium solution. The main idea
of the algorithm is to create a restricted game in which the players choose from a limited
space of possible strategies (represented as sequences of actions). The algorithm solves
the restricted game and then uses a fast best-response algorithm to find strategies in the
original unrestricted game that perform well against the current solution of the restricted
830

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

game. These strategies are added to the restricted game and the process iterates until no
best response can be found to improve the solution. In this case, the current solution is an
equilibrium of the original game. Typically, a solution can be found by adding only a small
fraction of the strategies to the restricted game.
We begin by presenting related work, technical background, and our notation. We then
describe our main algorithm in three parts: (1) methods for creating, solving, and expanding a valid restricted game, (2) the algorithm for finding the best-response strategies to be
added to the restricted game, and (3) variants of the main loop controlling the iterative
process of solving restricted games and adding new strategies. We present a formal analysis
and prove that our algorithm converges to a Nash equilibrium of the original game. Finally, we provide an experimental evaluation of the runtime performance and convergence
behavior of our algorithm on several realistic games with different characteristics including
a border patrolling scenario, Phantom Tic-Tac-Toe, and a simplified variant of Poker. We
compare our results with state-of-the-art algorithms for finding both exact and approximate solutions: linear programming using the sequence form, and Counterfactual Regret
Minimization (CFR, Zinkevich, Johanson, Bowling, & Piccione, 2008; Lanctot, 2013).
The experimental results confirm that our algorithm requires only a fraction of all possible sequences to solve a game in practice and significantly reduces memory requirements
when solving large games. This advances the state of the art and allows us to exactly solve
much larger games compared to the existing algorithms. Moreover, in games admitting
an equilibrium with small support (i.e., only a few sequences have non-zero probability in
an equilibrium), our algorithm also achieves significant improvements in computation time
and finds an equilibrium after only few iterations. These result hold without using any
domain-specific knowledge, but we also show that incorporating domain-specific heuristics
and bounds into the algorithm in a straightforward way can lead to even more significant
performance improvements. Analysis of the convergence rate shows that the approximative
bounds on the value of the game are either similar or a bit worse during the early stages
compared to CFR. However, the convergence behavior of CFR algorithm has a very long
tail and our algorithm always finds an exact solution much faster than CFR.

2. Related Work
Solving imperfect-information EFGs is a computationally challenging task, primarily due
to uncertainty about the actions of the opponent and/or a stochastic environment. The
leading exact algorithm (Koller et al., 1996; von Stengel, 1996) is based on formulating the
problem of finding an optimal strategy to play as a linear program. This algorithm exploits
a compact representation of strategies as sequences of individual actions (called the sequence
form) and results in a linear program of linear size in the size of the game tree. However,
this approach has limited applicability since the game tree grows exponentially with the
number of sequential actions in the game. A common practice for overcoming the limited
scalability of sequence-form linear programming is to use an approximation method. The
best known approximative algorithms include counterfactual regret minimization (CFR,
Zinkevich et al., 2008), improved versions of CFR with sampling methods (Lanctot, Waugh,
Zinkevich, & Bowling, 2009; Gibson, Lanctot, Burch, Szafron, & Bowling, 2012); Nesterovs
Excessive Gap Technique (EGT, Hoda, Gilpin, Pena, & Sandholm, 2010); and variants of
831

fiBosansky, Kiekintveld, Lisy, & Pechoucek

Monte Carlo Tree Search (MCTS) algorithms applied to imperfect-information games (e.g.,
see Ponsen, de Jong, & Lanctot, 2011).
The family of counterfactual regret minimization algorithms is based on learning methods that can be informally described as follows. The algorithm repeatedly traverses the
game tree and learns a strategy to play by applying a no-regret learning rule that minimizes a specific variant of regret (counterfactual regret) in each information set. The
no-regret learning converges to an optimal strategy in each information set. The overall
regret is bounded by the sum of the regret in each information set; hence, the strategy
as a whole converges to a Nash equilibrium. The main benefits of this approach include
simplicity and robustness, as it can be adapted for more generic games (e.g., see Lanctot,
Gibson, Burch, Zinkevich, & Bowling, 2012, where CFR is applied on games with imperfect
recall). However, the algorithm operates on the complete game tree and therefore requires
convergence in all information sets, which can be very slow for large games when one desires
a solution with small error.
Another popular method is Excessive Gap Technique that exploits the convex properties
of the sequence-form representation and uses recent mathematical results on finding extreme
points of smooth functions (see Hoda et al., 2010, for the details). The main idea is to approximate the problem of finding a pair of equilibrium strategies by two smoothed functions
and guiding them to find an approximate solution. Although this approach achieves faster
convergence in comparison with CFR, the algorithm is less robust (it is not known whether
a similar approach can be used for more general classes of games) and less used in practice.
Like CFR, EGT also operates in the complete strategy space of all sequences.
Monte Carlo Tree Search (MCTS) is another family of methods that has shown promise
for solving very large games, in particular perfect information board games such as Go (e.g.,
Lee et al., 2009). While the CFR and EGT algorithms are guaranteed to find an -Nash
equilibrium, convergence to an equilibrium solution has not been formally shown for any of
the variants of MCTS in imperfect-information games. On the contrary, the most common
version of MCTS based on the Upper Confidence Bounds (UCB) selection function can
converge to incorrect solutions even in simultaneous-move games (Shafiei, Sturtevant, &
Schaeffer, 2009) that are the simplest class of imperfect-information EFGs. MCTS algorithms therefore do not (in general) guarantee finding an (approximate) optimal solution in
imperfect-information games. One exception is the recent proof of convergence of MCTS
with certain selection methods for simultaneous-move games (Lisy, Kovarik, Lanctot, &
Bosansky, 2013). Still, using MCTS is sometimes a reasonable choice since it can produce
good strategies in practice (Ponsen et al., 2011).
Contrary to the existing approximative approaches, our algorithm aims to find an exact solution without explicitly considering the strategy in the complete game tree. Our
work combines the compact sequence-form representation and the double-oracle algorithmic framework. Previous work on the double-oracle framework has focused primarily on
applications in normal-form games, where the restricted game was expanded by adding pure
best-response strategies in each iteration. One of the first examples of solving games using
the double-oracle principle was by McMahan et al. (2003). They introduced the doubleoracle algorithm, proved the convergence to a Nash equilibrium, and experimentally verified
that the algorithm achieves computation time improvements on a search game where an
evader was trying to cross an environment without being detected by sensors placed by the
832

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

opponent. The double-oracle algorithm reduced the computation time from several hours
to tens of seconds and allowed to solve much larger instances of this game. Similar success
with the domain-specific double-oracle methods has been demonstrated on a variety of different domains inspired by pursuit-evasion games (Halvorson, Conitzer, & Parr, 2009) and
security games played on a graph (Jain, Korzhyk, Vanek, Conitzer, Tambe, & Pechoucek,
2011; Letchford & Vorobeychik, 2013; Jain, Conitzer, & Tambe, 2013).
Only a few works have tried to apply the iterative framework of oracle algorithms to
EFGs, primarily using pure and mixed strategies in EFGs. The first work that exploited this
iterative principle is the predecessor of the sequence-form linear-program formulation (Koller
& Megiddo, 1992). In this algorithm, the authors use a representation similar to the sequence form only for a single player, while the strategies for the opponent are iteratively
added as constraints into the linear program (there is an exponential number of constraints
in their formulation). This approach can be seen as a specific variant of the oracle algorithms, where the strategy space is expanded gradually for a single player. Our algorithm
is a generalization of this work, since our algorithm uses the sequence-form representation
for both players and it also incrementally expands the strategy space for both players.
More recent work has been done by McMahan in his thesis (McMahan, 2006) and followup work (McMahan & Gordon, 2007). In these works the authors investigated an extension
of the double-oracle algorithm for normal-form games to the extensive-form case. Their
double-oracle algorithm for EFGs operates very similarly to the normal-form variant and
uses pure and mixed strategies defined for EFGs. The main disadvantage of this approach
is that in the basic version it still requires a large amount of memory since a pure strategy
for an EFG is large (one action needs to be specified for each information set), and there
is an exponential number of possible pure strategies. To overcome this disadvantage, the
authors propose a modification of the double-oracle algorithm that keeps the number of the
strategies in the restricted game bounded. The algorithm removes from the restricted game
those strategies that are the least used in the current solution of the restricted game. In
order to guarantee the convergence, the algorithm adds in each iteration into the restricted
game a mixed strategy representing the mean of all removed strategies; convergence is then
guaranteed similarly to fictitious play (see McMahan & Gordon, 2007, for the details).
Bounding the size of the restricted game results in low memory requirements. However, the
algorithm converges extremely slowly and it can take a very long time (several hours for a
small game) for the algorithm to achieve a small error (see the experimental evaluation in
McMahan, 2006; McMahan & Gordon, 2007).
A similar concept for using pure strategies in EFGs is used in an iterative algorithm
designed for Poker in the work of Zinkevich et al. (2007). The algorithm in this work
expands the restricted game with strategies found by a generalized best response instead of
using pure best response strategies. Generalized best response is a Nash equilibrium in a
partially restricted game  the player computing the best response can use any of the pure
strategies in the original unrestricted game, while the opponent is restricted to use only the
strategies from the restricted game. However, the main disadvantages of using pure and
mixed strategies in EFGs are still present and result in large memory requirements and an
exponential number of iterations.
In contrast, our algorithm directly uses the compact sequence-form representation of
EFGs and uses the sequences as the building blocks (i.e., the restricted game is expanded
833

fiBosansky, Kiekintveld, Lisy, & Pechoucek

by allowing new sequences to be played in the next iteration). Using sequences and the
sequence form for solving the restricted game reduces the size of the restricted game and
the number of iterations, however, it also introduces new challenges when constructing and
maintaining the restricted game, and ensuring the convergence to a Nash equilibrium, which
we must solve for our algorithm to converge to a correct solution.

3. Technical Background
We begin by presenting the standard game-theoretic model of extensive-form games, followed by a discussion of the most common solution concepts and the algorithms for computing these solutions. Then we present the sequence-form representation and the state-of-theart linear program for computing solutions using this representation. Finally, we describe
oracle algorithms as they are used for solving normal-form games. A summary of the most
common notation is provided in Table 1 for quick reference.
3.1 Extensive-Form Games
Extensive-form games (EFGs) model sequential interactions between players in a game.
Games in the extensive form are visually represented as game trees (e.g., see Figure 2).
Nodes in the game tree represent states of the game; each state of the game corresponds to
a sequence of moves executed by all players in the game. Each node is assigned to a player
that acts in the game state associated with this node. An edge in the game tree from a
node corresponds to an action that can be performed by the player who acts in this node.
Extensive-form games model limited observations of the players by grouping the nodes into
information sets, so that a given player cannot distinguish between nodes that belong to
the same information set when the player is choosing an action. The model also represents
uncertainty about the environment and stochastic events by using a special Nature player.
Formally, a two-player EFG is defined as a tuple G = (N, H, Z, A, p, u, C, I): N is a set
of two players N = {1, 2}. We use i to refer to one of the two players (either 1 or 2), and i
to refer to the opponent of i. H denotes a finite set of nodes in the game tree. Each node
corresponds to a unique history of actions taken by all players and Nature from the root of
the game; hence, we use the terms history and node interchangeably. We denote by Z  H
the set of all terminal nodes of the game. A denotes the set of all actions and we overload
the notation and use A(h)  A to represent the set of actions available to the player acting
in node h  H. We specify ha = h0  H to be node h0 reached from node h by executing
action a  A(h). We say that h is a prefix of h0 and denote it by h v h0 . For each terminal
node z  Z we define a utility function for each player i (ui : Z  R). We study zero-sum
games, so ui (z) = ui (z) holds for all z  Z.
The function p : H  N  {c} assigns each node to a player who takes an action in the
node, where c means that the Nature player selects an action in the node based on a fixed
probability distribution known to all players. We use function C : H  [0, 1] to denote
the probability of reaching node h due to Nature (i.e., assuming that both players play all
required actions to reach node h). The value of C(h) is the product of the probabilities
assigned to all actions taken by the Nature player in history h. Imperfect observation of
player i is modeled via information sets Ii that form a partition over the nodes assigned
to player i {h  H : p(h) = i}. Every information set contains at least one node and each
834

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

node belongs to exactly one information set. Nodes in an information set of a player are
indistinguishable to the player. All nodes h in a single information set Ii  Ii have the
same set of possible actions A(h). Action a from A(h) uniquely identifies information set
Ii and there cannot exist any other node h0  H that does not belong to information set
Ii and for which a is allowed to be played (i.e., a  A(h0 )). Therefore we overload notation
and use A(Ii ) to denote the set of actions defined for each node h in this information set.
We assume perfect recall, which means that players perfectly remember their own actions
and all information gained during the course of the game. As a result, all nodes in any
information set Ii have the same history of actions for player i.
3.2 Nash Equilibrium in Extensive-Form Games
Solving a game requires finding a strategy profile (i.e., one strategy for each player) that
satisfies conditions defined by a specific solution concept. Nash equilibrium (NE) is the
best known solution concept in game theory and it describes the behavior of players under
certain assumptions about their rationality. In a Nash equilibrium, every player plays a
best response to the strategies of the other players. Let i be the set of pure strategies for
player i. In EFGs, a pure strategy is an assignment of exactly one action to be played in
each information set. A mixed strategy is a probability distribution over the set of all pure
strategies of a player. We denote by i the set of all mixed strategies of player i. For any
pair of strategies    = (1 , 2 ) we use ui () = ui (i , i ) for the expected outcome
of the game for player i when players follow strategies . A best response of player i to
the opponents strategy i is a strategy iBR , for which ui (iBR , i )  ui (i0 , i ) for all
strategies i0  i . A strategy profile  = (1 , 2 ) is a NE if and only if for each player i
it holds that i is a best response to i . A game can have multiple NEs; in the zero-sum
setting, all of these equilibria have the same value (i.e., the expected utility for every player
is the same). This is called the value of the game, denoted V  . The problem of finding a
NE in a zero-sum game has a polynomial computational complexity in the size of the game.
The NE solution concept is somewhat weak for extensive-form games. Nash equilibrium
requires that both players act rationally. However, there can be irrational strategies selected
for the parts of the game tree that are not reachable when both players follow the NE
strategies (these parts are said to be off the equilibrium path). The reason is that NE does
not expect this part of the game to be played and therefore does not sufficiently restrict
strategies in these information sets. To overcome these drawbacks, a number of refinements
of NE have been introduced imposing further restrictions with the intention of describing
more sensible strategies. Examples include subgame-perfect equilibrium (Selten, 1965) used
in perfect-information EFGs. The subgame-perfect equilibrium forces the strategy profile
to be a Nash equilibrium in each sub-game (i.e., in each sub-tree rooted in some node h)
of the original game. Unfortunately, sub-games are not particularly useful in imperfectinformation EFGs; hence, here the refinements include strategic-from perfect equilibrium
(Selten, 1975), sequential equilibrium (Kreps & Wilson, 1982), or quasi-perfect equilibrium
(van Damme, 1984; Miltersen & Srensen, 2010). The first refinement avoids using weakly
dominated strategies in equilibrium strategies for two-player games (van Damme, 1991,
p. 29) and it is also known as the undominated equilibrium. Sequential equilibrium tries
to exploit the mistakes of the opponent by using the notion of beliefs consistent with the
835

fiBosansky, Kiekintveld, Lisy, & Pechoucek

strategy of the opponent even in information sets off the equilibrium path. The main
intuitions behind the first two refinements are combined in quasi-perfect equilibrium.
Even though the solution described by NE does not always prescribe rational strategies
off the equilibrium path, it is still valuable to compute exact NE of large extensive-form
games for several reasons. We focus on zero-sum games, so the NE strategy guarantees
the value of the game even off the equilibrium path. In other words, the strategy off
the equilibrium path does not optimally exploit the mistakes of the opponent, but it still
guarantees an outcome of at least value gained by following the equilibrium path. Moreover,
a refined equilibrium is still a NE and calculating the value of the game is often a starting
point for many of the algorithms that compute these refinements  for example it is used
for computing undominated equilibrium (e.g., see Ganzfried & Sandholm, 2013; Cermak,
Bosansky, & Lisy, 2014) and normal-form proper equilibrium (Miltersen & Srensen, 2008).
3.3 Sequence-Form Linear Program
Extensive-form games with perfect recall can be compactly represented using the sequence
form (Koller et al., 1996; von Stengel, 1996). A sequence i is an ordered list of actions taken
by a single player i in a history h. The number of actions (i.e., the length of sequence i )
is denoted by |i | and the empty sequence (i.e., sequence with no actions) is denoted by .
The set of all possible sequences for player i is denoted by i and the set of sequences for all
players is  = 1  2 . A sequence i  i can be extended by a single action a taken by
player i, denoted by i a = i0 (we use i v i0 to denote that i is a prefix of i0 ). In games
with perfect recall, all nodes in an information set Ii share the same sequence of actions
for player i and we use seqi (Ii ) to denote this sequence. We overload the notation and use
seqi (h) to denote the
i leading to node h, and seqi (H 0 )  i ,
S sequence of0 actions of player
0
0
where seqi (H ) = h0 H 0 seqi (h ) for some H  H. Since action a uniquely identifies
information set Ii and all nodes in an information set share the same history of actions of
player i, each sequence uniquely identifies an information set. We use the function infi (i0 )
to denote the information set in which the last action of the sequence i0 is taken. For an
empty sequence, function infi () is the information set of the root node.
Finally, we define the auxiliary payoff function gi :   R that extends the utility
function to all nodes in the game tree. The payoff function gi represents the expected
utility of all nodes reachable by sequentially executing the actions specified in a pair of
sequences :
X
gi (i , i ) =
ui (h)  C(h)
(1)
hZ : jN j =seqj (h)

The value of the payoff function is defined to be 0 if no leaf is reachable by sequentially executing all of the actions in the sequences   either all actions from the pair of sequences 
are executed and an inner node (h  H \ Z) is reached, or during the sequential execution of the actions node h is reached, for which the current action a to be executed from
sequence (h) is not defined (i.e., a 
/ A(h)). Formally we define a pair of sequences  to
be compatible if there exists node h  H such that sequence i of every player i equals to
seqi (h).
We can compute a Nash equilibrium of a two-player zero-sum extensive-form game
using a linear program (LP) of a polynomial size in the size of the game tree using the
836

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

sequence form (Koller et al., 1996; von Stengel, 1996). The LP uses an equivalent compact
representation of mixed strategies of players in a form of realization plans. A realization
plan for a sequence i is the probability that player i will play this sequence of actions
under the assumption that the opponent will choose compatible sequences of actions that
reach the information sets for which the actions specified in the sequence i are defined. We
denote the realization plan for player i by ri : i  R. The equilibrium realization plans
can be computed using the following LP (e.g., see Shoham & Leyton-Brown, 2009, p. 135):

vinfi (i ) 

X

max vinfi ()
r,v
X
0
vIi

gi (i , i )  ri (i )

0 I :seq (I 0 )=
Ii
i
i
i i

i  i

i i

ri () = 1
X

(2)
(3)

ri (i a) = ri (i )

Ii  Ii , i = seqi (Ii )

(4)

i  i

(5)

aA(Ii )

ri (i )  0

Solving the LP yields a realization plan for player i using variables ri , and expected values
for the information sets of player i (variables vIi ). The LP works as follows: player i
maximizes the expected utility value by selecting the values for the variables of realization plan that is constrained by Equations (35). The probability of playing the empty
sequence is defined to be 1 (Equation 3), and the probability of playing a sequence i is
equal to the sum of the probabilities of playing sequences extended by exactly one action
(Equation 4). Finding such a realization plan is also constrained by the best responding
opponent, player i. This is ensured by Equation (2), where player i selects in each
information set Ii such action that minimizes the expected utility value vIi in this information set. There is one constraint defined for each sequence i , where the last action of
this sequence determines the best action to be played in information set infi (i ) = Ii .
The expected utility is composed of the expected utilities of the information sets reachable
after playing sequence i (sum of v variables on the left side) and of the expected utilities
of leafs to which this sequence leads (sum of g values on the right side of the constraint).
3.4 Double-Oracle Algorithm for Normal-Form Games
We now describe the concept of column/constraint generation techniques applied previously
in normal-form games and known as the double-oracle algorithm (McMahan et al., 2003).
Normal-form games are represented using game matrices; rows of the matrix correspond
to pure strategies of one player, columns correspond to pure strategies of the opponent,
and values in the matrix cells represent the expected outcome of the game when players
play corresponding pure strategies. Zero-sum normal-form games can be solved by linear
programming in polynomial time in the size of the matrix (e.g., see Shoham & LeytonBrown, 2009, p. 89).
Figure 1 shows the visualization of the main structure of the double-oracle algorithm for
normal-form games. The algorithm consists of the following three steps that repeat until
convergence:
837

fiBosansky, Kiekintveld, Lisy, & Pechoucek

Figure 1: Schematic of the double-oracle algorithm for a normal-form game.
1. create a restricted game by limiting the set of pure strategies that each player is
allowed to play
2. compute a pair of Nash equilibrium strategies in this restricted game using the LP for
solving normal-form games
3. for each player, compute a pure best response strategy against the equilibrium strategy
of the opponent found in the previous step; the best response may be any pure strategy
in the original unrestricted game
The best response strategies computed in step 3 are added to the restricted game, the game
matrix is expanded by adding new rows and columns, and the algorithm continues with the
next iteration. The algorithm terminates if neither of the players can improve the outcome
of the game by adding a new strategy to the restricted game. In this case both players
play a best response to the strategy of the opponent in the original unrestricted game.
The algorithm maintains the values of the expected utilities of the best-response strategies
throughout the iterations of the algorithm. These values provide bounds on the value of
the original unrestricted game V   from the perspective of player i, the minimal value
of all of her past best-response calculations represents an upper bound of the value of the
original game, ViU B , and the maximal value of all of past best-response calculations of the
opponent represents the lower bound on the value of the original game, ViLB . Note that for
the bounds it holds that the lower bound for player i is equal to the negative of the value
of the upper bound for the opponent:
UB
ViLB = Vi

In general, computing best responses is computationally less demanding than solving the
game, since the problem is reduced to a single-player optimization. Due to the fact that bestresponse algorithms can operate very quickly (e.g., also by exploiting additional domainspecific knowledge), they are called oracles in this context. If the algorithm incrementally
adds strategies only for one player, the algorithm is called a single-oracle algorithm, if
the algorithm incrementally adds the strategies for both players, the algorithm is called a
double-oracle algorithm. Double-oracle algorithms are typically initialized by an arbitrary
pair of strategies (one pure strategy for each player). However, we can also use a larger set
of initial strategies selected based on a domain-specific knowledge.
The double-oracle algorithm for zero-sum normal-form games runs in a polynomial time
in the size of the game matrix. Since each iteration adds at least one pure strategy to
838

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

Figure 2: Example of a two-player extensive-form game visualized as a game tree. Circle
player aims to maximize the utility value, box aims to minimize the utility value. The bold
edges represent the sequences of actions added to the restricted game.
the restricted game and there are finite pure strategies, the algorithm stops after at most
|i | + |i | iterations. Each iteration is also polynomial, since it consists of solving the
linear program and computing best responses. The relative performance of the doubleoracle algorithm compared to solving the linear program for the original unrestricted game
closely depends on the number of iterations required for convergence. In the worst case, the
algorithm adds all pure strategies and solves the original game, although this is rarely the
case in practice. Estimating the expected number of iterations needed for the double-oracle
algorithm to converge, however, remains an open problem.
3.4.1 Towards Extensive-Form Games
The straightforward method of applying the double-oracle algorithm for EFGs is to use pure
strategies defined in EFGs (i.e., assignments of action for each information set, or realization
plans) and apply exactly the algorithm described in this section  i.e., iteratively add
pure strategies from the unrestricted extensive-form game into the restricted game matrix.
However, this can result in an exponential number of iterations and an exponentially large
restricted game in the worst case. Our algorithm differs significantly from this idea since it
directly operates on (more compact) sequences instead of full strategies.

4. Sequence-Form Double-Oracle Algorithm for Extensive-Form Games
We now describe our sequence-form double-oracle algorithm for solving extensive-form
games with imperfect information. First, we give an informal overview of our algorithm.
We use an example game depicted in Figure 2 to illustrate some of the key concepts. Afterwards, we formally define the restricted game and describe the key components of the
algorithm, following by a full example run of our algorithm.
The overall scheme of our algorithm is based on the double-oracle framework described in
the previous section. The main difference is that our algorithm uses the sequences to define
the restrictions in the game tree. The restricted game in our model is defined by allowing
players to use (i.e., to play with non-zero probability) only a subset of the sequences from
the original unrestricted game. This restricted subset of sequences defines the subsets of
reachable actions, nodes, and information sets from the original game tree. Consider our example in Figure 2. A restricted game can be defined by sequences , A, AC, AD for the circle
player, and , x for the box player. These sequences represent actions allowed in the game,
839

fiBosansky, Kiekintveld, Lisy, & Pechoucek

they define reachable nodes (using history we can reference them as , A, Ax, AxC, AxD),
and reachable information sets (I1 , I2 for the circle player and the only information set I
for the box player).
The algorithm iteratively adds new sequences of allowed actions into the restricted
game, similarly to the double-oracle algorithm for normal-form games. The restricted game
is solved as a standard zero-sum extensive-form game using the sequence-form linear program. Then a best response algorithm searches the original unrestricted game to find new
sequences to add to the restricted game. When the sequences are added, the restricted
game tree is expanded by adding all new actions, nodes, and information sets that are now
reachable based on the new sets of allowed sequences. The process of solving the restricted
game and adding new sequences iterates until no new sequences that improve the solution
can be added.
There are two primary complications that arise when we use sequences instead of full
strategies in the double-oracle algorithm, both due to the fact that sequences do not necessarily define actions in all information sets: (1) a strategy computed in the restricted game
may not be a complete strategy in the original game, because it does not define behavior
for information sets that are not in the restricted game, and (2) it may not be possible to
play every action from a sequence that is allowed in the restricted game, because playing
a sequence can depend on having a compatible sequence of actions for the opponent. In
our example game tree in Figure 2, no strategy of the circle player in the restricted game
specifies what to play in information sets I3 and I4 . The consequence of the second issue
is that some inner nodes of the original unrestricted game can (temporarily) become leafs
in the restricted game. For example, the box player can add sequence y into the restricted
game making node Ay a leaf in the restricted game, since there are no other actions of the
circle player in the restricted game applicable in this node.
Our algorithm solves these complications using two novel ideas. The first idea is the
concept of a default pure strategy (denoted iDef  i ). Informally speaking, the algorithm
assumes that each player has a fixed implicit behavior that defines what the player does by
default in any information set that is not part of the restricted game. This is described by
the default strategy iDef , which specifies an action for every information set. Note that this
default strategy does not need to be represented explicitly (which could use a large amount
of memory). Instead, it can be defined implicitly using rules, such as selecting the first action
from a deterministic method for generating the ordered set of actions A(h) in node h. We
use the default pure strategies to map every strategy from the restricted game into a valid
strategy in the full game. Specifically, the strategy in the original unrestricted game selects
actions according to the probabilities specified by a strategy for the restricted game in
every information set that is part of the restricted game, and for all other information sets
it plays according to the default pure strategy. Recall our example in Figure 2, where the
pure default strategy for the circle player can be hA, C, E, Gi (i.e., selecting the leftmost
action in each information set). Hence, a strategy in the original unrestricted game can use
a strategy from the restricted game in information sets I1 and I2 , and select pure actions
in E, G in information sets I3 and I4 respectively.
The second key idea is to use temporary utility values for cases where there are no
allowed actions that can be played in some node in the restricted game that is an inner
node in the original game (so called temporary leaf ). To ensure the correct convergence of
840

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

H
ZH
iDef
ri : i 7 R
C : H 7 R
gi : H 7 R
seqi
infi : i 7 Ii

game-tree nodes / histories
leafs / terminal states
implicit default pure strategy for player i
realization plan of player i for a sequence
probability of reaching a node due to Nature play
extension of the utility function to all nodes;
gi (h) = ui (h)  C(h) if h  Z and gi (h) = 0 if h is not a terminal node (h 
/ Z)
sequence(s) of actions of player i leading to a node / a set of nodes /
/ an information set
an information set in which the last action of the sequence was executed

Table 1: An outline of the main symbols used in the paper.

the algorithm these temporary utilities must be assigned so that they provide a bound on
the expected value gained by continuing the play from the given node. Our algorithm uses
a value that corresponds to the expected outcome of continuing the game play, assuming
the player making the choice in the temporary leaf uses the default strategy, while the
opponent plays a best response. Assume we add sequence y for the box player into the
restricted game in our example tree in Figure 2. The temporary utility value for node Ay
would correspond to value 2, since the default strategy in information set I3 is to play E
for the circle player. In the next section we formally describe this method and prove the
correctness of the algorithm given these temporary values.
We now describe in detail the key parts of our method. We first formally define the
restricted game and methods for expanding the restricted game, including the details of
both of the key ideas introduced above. Then we describe the algorithm for selecting the
new sequences that are allowed in the next iteration. The decision of which sequences to add
is based on calculating a best response in the original unrestricted game using game-tree
search improved with additional pruning techniques. Finally, we discuss different variations
of the main logic of the double-oracle algorithm that determines for which player(s) the
algorithm adds new best-response sequences in the current iteration.
4.1 Restricted Game
This section formally defines the restricted game as a subset of the original unrestricted
game. A restricted game can be fully specified by the set of allowed sequences. We define
the sets of nodes, actions, and information sets as subsets of the original unrestricted sets
based on the allowed sequences. We denote the original unrestricted game by a tuple
G = (N, H, Z, A, p, u, C, I) and the restricted game by G0 = (N, H 0 , Z 0 , A0 , p, u0 , C, I 0 ). All
sets and functions associated with the restricted game use prime in the notation; the set of
players, and the functions p and C remain the same.
The restricted game is defined by a set of allowed sequences (denoted by 0  ) that
are returned by the best response algorithms. As indicated above, even an allowed sequence
i  0 might not be playable to the full length due to missing compatible sequences of the
opponent. Therefore, the restricted game is defined using the maximal compatible set of
sequences 0  0 for a given set of allowed sequences 0 . We define 0 as the maximal
841

fiBosansky, Kiekintveld, Lisy, & Pechoucek

subset of the sequences from 0 such that:
0i  {i  0i : i  0i h  H j  N seqj (h) = j }

i  N

(6)

Equation (6) means that for each player i and every sequence i in 0i , there exists a
compatible sequence of the opponent i that allows the sequence i to be executed in full
(i.e., by sequentially executing of all the actions in these sequences  some node h can be
reached such that seqj (h) = j for all players j  N ).
The set of sequences 0 fully defines the restricted game, because all other sets in the
tuple G0 can be derived from 0 . A node h is in the restricted game if and only if the
sequences that must be played to reach h are in the set 0 for both players:
H 0  {h  H : i  N seqi (h)  0 }

(7)

If a pair of sequences is in 0 , then all nodes reachable by executing this pair of sequences
are included in H 0 . Actions defined for a node h are in the restricted game if and only if
playing the action in this node leads to a node that is in the restricted game:
A0 (h)  {a  A(h) : ha  H 0 }

h  H 0

(8)

Nodes from the restricted game corresponding to inner nodes in the original unrestricted
game may not be inner nodes in the restricted game. Therefore, the set of leaves in the
restricted game is a union of leaf nodes of the original game and inner nodes from the
original game that currently do not have a valid continuation in the restricted game, based
on the allowed sequences:

Z 0  Z  H 0  {h  H 0 \ Z : A0 (h) = }
(9)
We explicitly differentiate between leaves in the restricted game that correspond to leaves in
the original unrestricted game (i.e., Z 0 Z) and leaves in the restricted game that correspond
to inner nodes in the original unrestricted game (i.e., Z 0 \ Z), since the algorithm assigns
temporary utility values to nodes in the latter case.
The information sets in the restricted game correspond to information sets in the original
unrestricted game. If some node h belongs to an information set Ip(h) in the original game,
then the same holds in the restricted game. We define an information set to be a part of
the restricted game if and only if at least one inner node that belongs to this information
set is included in the restricted game:
Ii0  {Ii  Ii : h  Ii h  H 0 \ Z 0 }

(10)

An information set in the restricted game Ii  Ii0 consists only of nodes that are in the
restricted game  i.e., h  Ii : h  H 0 .
Finally, we define the modified utility function u0 for the restricted game. The primary
reason for the modified utility function is to define the temporary utility values for leaves in
the set Z 0 \Z. Consider h  Z 0 \Z to be a temporary leaf and player i to be the player acting
in this node (i = p(h)). Moreover, let ui (h) be the expected outcome of the game starting
from this node assuming both players are playing NE strategies in the original unrestricted
game. The modified utility function u0i for this leaf must return a value that is a lower bound
842

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

on value ui (h). Due to the zero-sum assumption, this value represents an upper bound on
value for the opponent i. Setting the value this way ensures two things: (1) player i is
likely to use sequences leading to node h in optimal strategies in the restricted game (since
the modified utility value is an upper bound of an actual value), and (2) player i adds new
sequences using best-response algorithms that prolong sequence seqi (h) leading to node h
if there are sequences that would yield better expected value than u0i . Later we show a
counterexample where setting the value otherwise can cause the algorithm to converge to
an incorrect solution. We calculate the lower bound by setting the utility value so that it
corresponds to the outcome in the original game if the player i continues by playing the
BR to this default strategy.
default strategy iDef and the opponent plays a best response i
This is a valid lower bound since we consider only a single strategy for the player acting in
node h, which correspond to the default strategy; considering other strategies could allow
this player to improve the value of continuing from the node h. For all other leaf nodes
h  Z 0  Z we set u0i (h)  ui (h).
4.1.1 Solving the Restricted Game
The restricted game defined in this section is a valid zero-sum extensive-form game and
it can be solved using the sequence-form linear programming described in Section 3. The
algorithm computes a NE of the restricted game by solving a pair of linear programs using
the restricted sets 0 , H 0 , Z 0 , I 0 , and the modified utility function u0 .
Each strategy from the restricted game can be translated to the original game by using
the pure default strategy to extend the restricted strategy where it is not defined. Formally,
if ri0 is a mixed strategy represented as a realization plan of player i in the restricted
game, then we define the extended strategy r0i to be a strategy identical to the strategy in
the restricted game for sequences included in the restricted game, and correspond to the
default strategy iDef if a sequence is not included in the restricted game:
(
ri0 (i )
i  0i
r0i (i ) 
(11)
ri0 (i0 )  iDef (i \ i0 ) i 
/ 0i ; i0 = arg maxi00 0i ; i00 vi |i00 |
The realization plan of a sequence i not allowed in the restricted game (i.e., i 
/ 0i )
is equal to the realization probability of the longest prefix of the sequence allowed in the
restricted game (denoted by i0 ), and setting the remaining part of the sequence (i.e., i \ i0 )
to correspond to the default strategy of player i. This computation is expressed as a
multiplication of two probabilities, where we overload the notation and use iDef (i \ i0 ) to
be 1 if the remaining part of the sequence i corresponds to the default strategy of player i,
and 0 otherwise.
In each iteration of the double-oracle algorithm one sequence-form LP is solved for each
player to compute a pair of NE strategies in the restricted game. We denote these strategies
 ) and (r  , r  ) when they are extended to the original unrestricted game using
as (ri , ri
i i
the default strategies.
4.1.2 Expanding the Restricted Game
The restricted game is expanded by adding new sequences to the set 0 and updating the
remaining sets according to their definition. After adding new sequences, the algorithm
843

fiBosansky, Kiekintveld, Lisy, & Pechoucek

calculates and stores the temporary utility values for leaves in Z 0 \ Z so they can be used
in the sequence-form LP.
After updating the restricted game, the linear programs are modified so that they correspond to the new restricted game. For all newly added information sets and sequences,
new variables are created in the linear programs and the constraints corresponding to these
information sets/sequences are created (Equations 2 and 4). Moreover, some of the constraints already existing in the linear program need to be updated. If a sequence i is
added to the set 0i and the immediate prefix sequence (i.e., sequence i0 v i such that
|i0 | + 1 = |i |) was already a part of the restricted game, then we need to update the
constraint for information sets Ii for which i0 = seqi (Ii ) to ensure the consistency of the
strategies (Equation 4), and the constraint corresponding to sequence i0 (Equation 2). In
addition, the algorithm updates Equations (2) assigned to sequences of the opponent i
for which g(i , i ) 6= 0. Finally, the algorithm updates all constraints that previously used
utilities for temporary leaf nodes that are no longer leaf nodes in the restricted game after
adding the new sequences.
New sequences for each player are found using the best response sequence (BRS) algorithms described in Section 4.2. From the perspective of the sequence-form double-oracle
algorithm, the BRS algorithm calculates a pure best response for player i against a fixed
strategy of the opponent in the original unrestricted game. This pure best response specifies
an action to play in each information set that is currently reachable given the opponents
extended strategy ri . The best response can be formally defined as a pure realization
plan riBR that assigns only integer values 0 or 1 to the sequences. This realization plan
is not necessarily a pure strategy in the original unrestricted game because there may not
be an action specified for every information set. Specifically, there is no action specified
for information sets that are not reachable (1) due to choices of player i, and (2) due to
zero probability in the realization plan of the opponent ri . Omitting these actions does
not affect the value of the best response because these information sets are never reached;
hence, for riBR it holds that r0i  i ui (riBR , ri )  ui (r0i , ri ) and there exists a pure best
response strategy iBR  i such that ui (riBR , ri ) = ui (iBR , ri ). The sequences that are
used in the best-response pure realization plan with probability 1 are returned by BRS
algorithm and we call these the best-response sequences:
{i  i : riBR (i ) = 1}

(12)

4.1.3 Example Run of the Algorithm
We now demonstrate the sequence-form double-oracle algorithm on an example game depicted in Figure 3a. In our example, there are two players: circle and box. Circle aims to
maximize the utility value in the leafs, box aims to minimize the utility value. We assume
that choosing the leftmost action in each information set is the default strategy for both
players in this game.
The algorithm starts with an empty set of allowed sequences in the restricted game
0  ; hence, the algorithm sets the current pair of (ri , ri ) strategies to be equivalent to
Def ). Next, the algorithm adds new sequences that correspond to the best response
(iDef , i
to the default strategy of the opponent; in our example the best response sequences for
the circle player are {, A, AD}, and {, y} for the box player. These sequences are added
844

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

(a) Step 0

(b) Step 1

(d) Step 3

(c) Step 2

(e) Step 4

Figure 3: Example of the steps of the sequence-form double-oracle algorithm in a two-player
zero-sum game, where circle player aims to maximize the utility value, box aims to minimize
the utility value. Bold edges correspond to the sequences of actions added into the restricted
game. The dashed boxes indicate the information sets.
to the set of allowed sequences 0 . Next, the set of sequences of the restricted game 0 is
updated. The maximal compatible set of sequences from set 0 cannot contain sequence
AD because the compatible sequence of the box player (i.e., x in this case) is not allowed
in the restricted game yet and sequence AD cannot be fully executed. Moreover, by adding
sequences A and y, the restricted game will contain node Ay for which actions E and F
are defined in the original unrestricted game. However, there is no continuation in the
current restricted game yet; hence, this node is a temporary leaf, belongs to Z 0 \ Z, and
the algorithm needs to define a new value for a modified utility function u0 for this node.
The value u0 (Ay) is equal to 2 and corresponds to the outcome of the game if the circle
player continues by playing the default strategy and the box player plays the best response.
To complete the first step of the algorithm we summarize the nodes and information sets
included in the restricted game; H 0 contains 3 nodes (the root, the node after playing an
action A and the node Ay), and two information sets (the information set for node Ay is
not added into the restricted game, because this node is now a leaf in the restricted game).
Playing the sequences A and y with probability 1 is the Nash equilibrium of the restricted
game. The situation is depicted in Figure 3b, the sequences in 0 are shown as bold edges.
The algorithm proceeds further and the complete list of steps of the algorithm is summarized in Table 2. In the second iteration, new sequences B and BH are added into the
restricted game. The box player does not add new sequences in this iteration because y is
the best response to the extended equilibrium strategy of the circle player  i.e., playing
sequences A, AC, AE with probability 1. NE in the updated restricted game changes to
playing sequences B, BH and sequence y, all with probability 1. In the third iteration the
situation changes and the box player adds sequence x, while there are no new sequences
845

fiBosansky, Kiekintveld, Lisy, & Pechoucek

added for the circle player. After adding sequence x, sequence AD also becomes a part of
the set 0 as it can now be fully executed due to adding the compatible sequence x. NE in
the restricted game is now fully mixed, the sequences starting with A and with B are played
in a ratio of 3 : 4, x and y in a ratio of 4 : 3. In the fourth iteration, the algorithm adds
sequence AF to the restricted game (the best response for the circle player), which removes
the assigned value u0 (Ay) since the node no longer belongs to set Z 0 . The algorithm stops
after four iterations. No other sequences are added into the restricted game, the solution of
 ) can be translated to the solution in the original unrestricted
the restricted game (ri , ri


game, and (ri , ri ) is Nash equilibrium of the original game.
Iteration
1.
2.
3.
4.

BR
r
, A, AD
, B, BH
, B, BH
, A, AF

BR
r
, y
, y
, x
, y

0
, A
, A, B, BH
, A, AD, B, BH
, A, AD, AF, B, BH

0
, y
, y
, y, x
, y, x

Table 2: Steps of the sequence-form double-oracle algorithm applied to the example.
Consider now a small modification of the example game where there is a utility value
of 3 in the leaf following action F (i.e., node AyF ). In this case, the algorithm does not
need to add sequence AF (nor AE) to the restricted game because it does not improve
the value of the restricted game. Note that this modified example game shows why the
algorithm needs to set the utility values for nodes in Z 0 \ Z. If the algorithm simply uses
the unmodified utility function, then the node Ay will be treated as if it had zero utility
value. This value overestimates the outcome of any actual continuation following this node
in the original game for the circle player and since sequences AE or AF will never be a
part of the best response for the circle player, the algorithm can converge to an incorrect
solution.
4.2 Best-Response Sequence Algorithm
The purpose of the best-response sequence (BRS) algorithm is to generate new sequences
that will be added to the restricted game in the next iteration, or to prove that there is
no best response with better expected value that uses sequences currently not allowed in
the restricted game. Throughout this section we use the term searching player to represent
the player for whom the algorithm computes the best response sequences. We refer to this
player as i.
The BRS algorithm calculates the expected value of a pure best response to the opponents strategy ri . The algorithm returns both the set of best-response sequences as well
as the expected value of the strategy against the extended strategy of the opponent.
The algorithm is based on a depth-first search that traverses the original unrestricted
game tree. The behavior of the opponent i is fixed to the strategy given by the extended
realization plan ri . To save computation time, the best-response algorithms use branch
and bound during the search for best-response sequences. The algorithm uses a bound on
the expected value for each inner node, denoted by . This bound represents the minimal
utility value that the node currently being evaluated needs to gain in order to be a part
846

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

Require: i - searching player, h - current node, Iik - current information set, r0i - opponents
strategy, Min/MaxUtility - bounds on utility values,  - lower bound for a node h
1: w  r i (seqi (h))  C(h)
2: if h  Z then
3:
return ui (h)  w
4: else if h  Z 0 \ Z then
5:
return u0i (h)  w
6: end if

7: sort a  A(h) based on probability wa  r 0i seqi (ha)  C(ha)
8: v h  0
9: for a  A(h),
 wa > 0 do

10:
0    v h + (w  wa )  MaxUtility
11:
if 0  wa MaxUtility then
12:
v 0  BRSi (ha, 0 )
13:
if v 0 =  then
14:
return 
15:
end if
16:
vh  vh + v0
17:
w  w  wa
18:
else
19:
return 
20:
end if
21: end for
22: return v h

Figure 4: BRSi in the nodes of other players.

of a best-response sequence. Using this bound during the search, the algorithm is able to
prune branches that will certainly not be part of any best-response sequence. The bound 
is set to MinUtility for the root node.
We distinguish 2 cases in the search algorithm: either the algorithm is evaluating an
information set (or more specifically a node h) assigned to the searching player i, or the
node is assigned to one of the other players (either to the opponent, player i, or it is a
chance node). The pseudocode for these two cases is depicted in Figures 4 and 5.
4.2.1 Nodes of the Opponent
We first describe the case used when the algorithm evaluates node h assigned to either
the opponent of the searching player or to Nature (see Figure 4). The main idea is to
calculate the expected utility for this node according to the (fixed) strategy of the player.
The strategy is known because it is either given by the extended realization plan ri , or by
the stochastic environment (C). Throughout the algorithm, the variable w represents the
probability of this node based on the realization probability of the opponent and stochastic
environment (line 1). This value is iteratively decreased by values wa that represent realization probabilities of the currently evaluated action a  A(h). Finally, vh is the expected
utility value for this node.
The algorithm evaluates actions in the descending order according to the probability
of being played (based on r0i and C; lines 921). First, we calculate a new lower bound
847

fiBosansky, Kiekintveld, Lisy, & Pechoucek

0 for the successor ha (line 10). The new lower bound is the minimal value that must
be returned from the recursive call BRSi (ha) under the optimistic assumption that all the
remaining actions will yield the maximum possible utility. If the lower bound does not
exceed the maximum possible utility in the game, the algorithm is executed recursively
on the successors (line 12). Note that the algorithm does not evaluate branches with zero
realization probability (line 9).
There are 3 possibilities for pruning in this part of the search algorithm. The first
pruning is possible if the currently evaluated node is a leaf in the restricted game, but this
node is an inner node in the original node (i.e., h  Z 0 \ Z; line 5). The algorithm can
directly use the value from the modified utility function u0 in this case, since it is calculated
as a best response of the searching player against the default strategy of the opponent that
will be applied in the successors of node h since h  Z 0 . Secondly, a cut-off also occurs
if the new lower bound for a successor is larger than the maximum possible utility in the
game, since this value can never be obtained in the successor (line 19). Finally, a cut-off
occurs if there was a cut-off in one of the successors (line 14).
4.2.2 Nodes of the Searching Player
In nodes assigned to the searching player, the algorithm evaluates every action in each
state that belongs to the current information set. The algorithm traverses the states in
the descending order according to the probability of occurrence given the strategies of the
opponent and Nature (line 8). Similar to the previous case, in each iteration the algorithm
calculates a new lower bound for the successor node (line 17). The new lower bound 0
is the minimal value that must be returned from the recursive call BRSi (h0 a) in order for
the action a to be selected as the best action for this information set under the optimistic
assumption that this action yields the maximum possible utility value after applying it in
each of the remaining states in this information set. The algorithm performs a recursive call
(line 20) only for an action that still could be the best in this information set (i.e., the lower
bound does not exceed the maximal possible utility in the game). Note that if a cut-off
occurs in one of the successors, the currently evaluated action a can no longer be the best
action in this information set. Hence, va is set to  and action a will not be evaluated for
any of the remaining nodes. When the algorithm determines which action will be selected
as the best one in an information set, it evaluates only this action for all remaining nodes
in the information set. Finally, the algorithm stores the values for the best action for all
nodes in this information set (line 30). These are reused if the same information set is
visited again (i.e., the algorithm reaches a different node h0 from the same information set
Ii ; line 5).
A cut-off occurs in this part of the search algorithm if the maximal possible value vah
is smaller than the lower bound  after evaluating node h. This means that regardless of
which action will be selected as the best action in this information set, the lower bound
for node h will not be reached; hence, the cut-off occurs (line 27). If a cut-off occurs in
an information set, this information set cannot be reached again and the sequences of the
searching player leading to this information set cannot be a part of the best response. This
is due to propagating the cut-off to at least one previous information set of the searching
player, otherwise there will be no tight lower bound set (the bound is first set only in the
848

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

Require: i - searching player, h - current node, Iik - current information set, ri - opponents
strategy, Min/MaxUtility - bounds on utility values,  lower bound for a node h
1: if h  Z then
2:
return ui (h)  r0i (seqi (h))  C(h)
3: end if
4: if v h is already calculated then
5:
return v h
6: end if
7: H 0  {h0 ; h0  Ii }
0
8: sort H
to value ri (seqi (h0 ))  C(h0 )
P descending according
0
9: w  h0 H 0 r i (seqi (h ))  C(h0 )
10: va  0 a  A(h); maxAction  
11: for h0  H 0 do
12:
wh0  r0i (seqi (h0 ))  C(h0 )
13:
for a  A(h0 ) do
14:
if maxAction is empty then
15:
0  wh0 MinUtility
16:
else
17:
0  (vmaxAction + w  MinUtility)  (va + (w  wh0 )  MaxUtility)
18:
end if
19:
if 0  wh0  MaxUtility then
0
20:
vah  BRSi (h0 a, 0 )
0
21:
va  va + vah
22:
end if
23:
end for
24:
maxAction  arg maxaA(h0 ) va
25:
w  w  wh0

26:
if h was evaluated  maxaA(h) vah <  then
27:
return 
28:
end if
29: end for
0
h0
as v h h0  H 0
30: store vmaxAction
h
31: return vmaxAction

Figure 5: BRSi in the nodes of the searching player.

information sets of the searching player). Therefore, there exists at least one action of the
searching player that will never be evaluated again (after a cut-off, the value va for this
action is set to ) and cannot be selected as the best action in the information set. Since
we assume perfect recall, all nodes in information set Ii share the same sequence of actions
seqi (Ii ); hence, no node h0  Ii can be reached again.
4.3 Main Loop Alternatives
We now introduce several alternative formulations for the main loop of the sequence-form
double-oracle algorithm. The general approach in the double-oracle algorithm is to solve the
restricted game to find the equilibrium strategy for each player, compute the best responses
in the original game for both of the players, and continue with the next iteration. However,
the sequence-form LP is formulated in our double-oracle scheme in such a way that on each
849

fiBosansky, Kiekintveld, Lisy, & Pechoucek

iteration the algorithm can solve the restricted game only from the perspective of a single
player i. In other words, we formulate a single LP as described in Section 3.3 that computes
the optimal strategy of the opponent in the restricted game (player i), and then compute
the best response of player i to this strategy. This means that on each iteration we can
select a specific player i, for whom we compute the best response in this iteration. We call
this selection process the player-selection policy.
There are several alternatives for the player-selection policy that act as a domainindependent heuristics in double-oracle algorithm. We consider three possible policies:
(1) the standard double-oracle player-selection policy of selecting both players on each iteration, (2) an alternating policy, where the algorithm selects only one player and switches
between the players regularly (player i is selected in one iteration, player i is selected in
the following iteration), and finally (3) a worse-player-selection policy that selects the player
who currently has the worse bound on the solution quality. At the end of an iteration the
algorithm selects the player i for whom the upper bound on utility value is further away
from the current value of the restricted game. More formally,
fi
fi
arg max fiViU B  ViLP fi
(13)
iN

where ViLP is the last calculated value of the restricted game for player i. The intuition
behind this choice is that either this bound is precise and there are some missing sequences
of this player in the restricted game that need to be added, or the upper bound is overestimated. In either case, the best-response sequence algorithm should be run for this player
in the next iteration, either to add new sequences or to tighten the bound. In case of a tie,
the alternating policy is applied in order to guarantee regular switching of the players. We
experimentally compare these policies to show their impact on the overall performance of
the sequence-form double-oracle algorithm (see Section 6).

5. Theoretical Results
In this section we prove that our sequence-form double-oracle algorithm will always converge to a Nash equilibrium of the original unrestricted game. First, we formally define the
strategy computed by the best-response sequence (BRS) algorithm, then we prove lemmas
about the characteristics of the BRS strategies, and finally we prove the main convergence
result. Note that variations of the main loop described in Section 4.3 do not affect the
correctness of the algorithm as long as the player-selection policy ensures that if no improvement is made by the BRS algorithm for one player that the BRS algorithm is run for
the opponent on the next iteration.
0 be a realization plan of player i in some restricted game G0 . BRS(r 0 )
Lemma 5.1 Let ri
i
returns sequences corresponding to a realization plan riBR in the unrestricted game, such that
riBR is part of a pure best response strategy to r0i . The value returned by the algorithm is
the value of executing the pair of strategies ui (r0i , riBR ).
0 ) searches the game tree and selects the action that maximizes the value
Proof BRS(ri
of the game for player i in all information sets Ii assigned to player i reachable given
the strategy of the opponent r0i . In the opponents nodes, it calculates the expected value

850

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

0 where it is defined and the value according to the pure action of the default
according to ri
Def
0 is not defined. In chance nodes, it returns the expected value of
strategy i where ri
the node as the sum of the values of the successor nodes weighted by their probabilities. In
each node h, if the successors have the maximal possible value for i then node h also has
the maximal possible value for i (when playing against r0i ). The selections in the nodes
that belong to i achieves this maximal value; hence, they form a best response to strategy
r0i . 
0 )) to denote the value returned by the BRS algorithm,
For brevity we use v(BRS(ri
which is equal to ui (r0i , riBR ).
0 be a realization plan of player i in some restricted game G0 and let
Lemma 5.2 Let ri

Vi be the value of the original unrestricted game G for player i, then
0
v(BRS(ri
))  Vi .

(14)

0 )) is a value of the best response against r 0
Proof Lemma 5.1 showed that v(BRS(ri
i
0 )) < V  then
which is a valid strategy in the original unrestricted game G. If v(BRS(ri
i
Vi cannot be the value of the game since player i has a strategy r0i that achieves better
utility, which is a contradiction. 
0 be a realization plan of player i that is returned by the LP for some
Lemma 5.3 Let ri
0
restricted game G and let ViLP be the value of the restricted game returned by the LP, then
0
v(BRS(ri
))  ViLP .

(15)

0
Proof The realization plan ri
is part of the Nash equilibrium strategy in a zero-sum
LP
game that guarantees value Vi
in G0 . If the best response computation in the original
unrestricted game G selects only the actions from restricted game G0 , it creates the best
response in game G0 as well obtaining value ViLP . If the best response selects an action
that is not allowed in the restricted game G0 , there are two cases.
Case 1 : The best response strategy uses an action in a temporary leaf h  Z 0 \ Z.
Player i makes the decision in the leaf, because otherwise the value of the temporary leaf
would be directly returned by BRS. The value of the temporary leaf has been underestimated for player i in the restricted game by the modified utility function u0 and it is
Def .
over-estimated in the BRS computation as the best response to the default strategy i
The value of the best response can only increase by including this action.
Case 2 : The best response strategy uses an action not allowed in G0 in an internal node
of the restricted game H 0 \ Z 0 . This can occur in nodes assigned to player i, because the
actions of player i going out of G0 have probability zero in r0i . BRS takes the action
with maximum value in the nodes assigned to player i, so the reason for selecting an action
leading outside G0 is that it has greater or equal value to the best action in G0 . 
0 )) > V LP then it
Lemma 5.4 Under the assumptions of the previous lemma, if v(BRS(ri
i
returns sequences that are added to the restricted game G0 in the next iteration.

851

fiBosansky, Kiekintveld, Lisy, & Pechoucek

Proof Based on the proof of the previous Lemma, BRS for player i can improve over
the value of the LP (ViLP ) only by selecting an action a that is not present in G0 but is
performed in a node h that is included in G0 (in which i makes decision). Let (i , i ) be
the pair of sequences leading to h. Then in the construction of the restricted game for the
next iteration, sequence i is the sequence that ensures that i a can be executed in full
and will be part of the new restricted game. 
Note, that Lemmas 5.2 and 5.4 would not hold if the utility values u0 for temporary
leaves (h  Z 0 \ Z) are set arbitrarily. The algorithm sets the values in temporary leaf h
as if the player p(h) continues by playing the default strategy and the opponent (p(h)) is
playing the best response. If the utility values for the temporary leaves are set arbitrarily
and used in the BRS algorithms to speed-up the calculation as proposed (see the algorithm
in Figure 4, line 5), then Lemma 5.2 does not need to hold in cases where the value in
node h strictly overestimates the optimal expected value for player p(h). In this case, the
best-response value of the opponent may be lower than the optimal outcome,


v BRS(rp(h) ) < Vp(h)
(16)
On the other hand, if the BRS algorithm does not use the temporary values u0 for such a
node, then Lemma 5.4 is violated because the best-response value will be strictly higher for
player p(h) even though no new sequences are to be added into the restricted game.
Theorem 5.5 The sequence-form double-oracle algorithm for extensive-form games described in the previous section terminates if and only if
0
v(BRS(ri
)) = v(BRS(ri0 )) = ViLP = Vi ,

(17)

which always happens after a finite number of iterations (because the game is finite), and
strategies (r0i , r0i ) are a Nash equilibrium of the original unrestricted game.
Proof First we show that the algorithm continues until all equalities (17) hold. If
0 )) 6= v(BRS(r 0 )) then from Lemma 5.2 and Lemma 5.4 we know that for
v(BRS(ri
i
0 ) > V LP , so the restricted game in the following itersome player i it holds that BRS(ri
i
ation is larger by at least one action and the algorithm continues. In the worst case, the
restricted game equals the complete game G0 = G, and it cannot be extended any further.
In this case the BRS cannot find a better response then Vi and the algorithm stops due
to Lemma 5.4.
If the condition in the theorem holds the algorithm has found a NE in the complete
BR = BRS(r 0 ) is the best response to r 0 in
game, because from Lemma 5.1 we know that ri
i
i
the complete game. However, if the value of the best response to a strategy in a zero-sum
game is the value of the game, then the strategy r0i is optimal and it is part of a Nash
equilibrium of the game. 

6. Experiments
We now present our experimental evaluation of the performance of the sequence-form
double-oracle algorithm for EFGs. We compare our algorithm against two state-of-the-art
852

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

baselines, the full sequence-form LP (referred to as FullLP from now on), and Counterfactual Regret Minimization (CFR). The first baseline is the standard exact method for
solving sequence-form EFG, while CFR is one of the leading approximate algorithms applied to EFG. Our experimental results demonstrate the advantages of the double-oracle
algorithm on three different classes of realistic EFGs. We also test the impact of the different
variants of the main loop of the algorithm described in Section 4.3.
We compare three variants of the sequence-form double-oracle algorithm: (1) DO-b
is a variant in which the best-responses are calculated for both players in each iteration;
(2) DO-sa calculates the best-response for a single player on each iteration according to
a simple alternating policy; and (3) DO-swp is a variant in which the best-response is
calculated for a single player according to the worse-player selection policy. For all of the
variants of the double-oracle algorithm we use the same default strategy where the first
action applicable in a state is played by default.
Since there is no standardized collection of zero-sum extensive-form games for benchmark purposes, we use several specific games to evaluate the double-oracle algorithm and
to identify the strengths and weaknesses of the algorithm. The games were selected to
evaluate the performance under different conditions, so the games differ in the maximal
utility the players can gain, in the causes of the imperfect information, and in the structure
of the information sets. One of the key characteristics that affects the performance of the
double-oracle algorithm is the relative size of the support of Nash equilibria (i.e., the number of sequences used in a NE with non-zero probability). If there does not exist a NE with
small support, the algorithm must necessarily add a large fraction of the sequences into the
restricted game to find a solution, mitigating the advantages of the double-oracle approach.
We present results for two types of games where the double-oracle significantly outperforms the FullLP on all instances: a search game motivated by border patrol and Phantom
Tic-Tac-Toe. We also present results on a simplified version of poker for which the doubleoracle algorithm does not always improve the computation time. However, the FullLP
also has limited scalability due to larger memory requirements and cannot find solutions for
larger variants of poker, while the double-oracle algorithm is able to solve these instances.
Our principal interest is in developing new generic methods for solving extensive-form
games. Therefore, we implemented the algorithm in a generic framework for modeling arbitrary extensive-form games.1 The algorithms do not use any domain-specific knowledge in
the implementation, and do not rely on any specific ordering of the actions. The drawbacks
of this generic implementation are higher memory requirements and additional overhead
for the algorithms. A domain-specific implementation could improve the performance by
eliminating some of the auxiliary data structures. We run all of the experiments using a
single thread on an Intel i7 CPU running at 2.8 GHz. Each of the algorithms was given a
maximum of 10 GB of memory for Java heap space. We used IBM CPLEX 12.5 for solving
the linear programs, with parameter settings to use a single thread and the barrier solution
algorithm.
In addition to runtimes, we analyze the speed of convergence of the double-oracle algorithms and compare it to one of the state-of-the-art approximative algorithms, Counterfactual Regret Minimization (CFR). We implemented CFR in a domain independent way
1. Source code is available at the home pages of the authors.

853

fiBosansky, Kiekintveld, Lisy, & Pechoucek

based on the pseudocode in the work of Lanctot (2013, p. 22). In principle, it is sufficient
for CFR to maintain only a set of information sets and apply the no-regret learning rule
in each information set. However, maintaining and traversing such a set effectively in a
domain independent manner could be affected by our implementation of generic extensiveform games data structures (i.e., generating applicable actions in the states of the game,
applying the actions, etc.). Therefore we use an implementation where CFR traverses the
complete game tree that is held in memory to maintain the fairness of the comparison, and
to guarantee the maximal possible speed of convergence of the CFR algorithm. The time
necessary to build the game tree is not included in the computation time of CFR.
6.1 Test Domains
Search Games Our first test belongs to the class of search (or pursuit-evasion) games,
often used in experimental evaluation of double-oracle algorithms (McMahan et al., 2003;
Halvorson et al., 2009). The search game has two players: the patroller (or the defender)
and the evader (or the attacker). The game is played on a directed graph (see Figure 6),
where the evader aims to cross safely from a starting node (E) to a destination node (D).
The defender controls two units that move in the intermediate nodes (the shaded areas)
trying to capture the evader by occupying the same node as the evader. During each turn
both players move their units simultaneously from the current node to an adjacent node,
or the units stay in the same location. The only exception is that the evader cannot stay in
the two leftmost nodes. If a pre-determined number of turns is made without either player
winning, the game is a draw. This is an example of a win-tie-loss game and the utility
values are from the set {1, 0, 1}.
Players are unaware of the location and the actions of the other player with one exception
 the evader leaves tracks in the visited nodes that can be discovered if the defender visits
the nodes later. The game also includes an option for the evader to avoid leaving the tracks
using a special move (a slow move) that requires two turns to simulate the evader covering
the tracks.
Figure 6 shows examples of the graphs used in the experiments. The patrolling units
can move only in the shaded areas (P1,P2), and they start at any node in the shaded
areas. Even though the graph is small, the concurrent movement of all units implies a large
branching factor (up to  50 for one turn) and thus large game trees (up to  1011 nodes).
In the experiments we used three different graphs, varied the maximum number of turns
of the game (from 3 to 7), and we altered the ability of the attacker to perform the slow
moves (labeled SA if the slow moves are allowed, SD otherwise).
Phantom Tic-Tac-Toe The second game is a blind variant of the well-known game of
Tic-Tac-Toe (e.g., used in Lanctot et al., 2012). The game is played on a 3  3 board, where
two players (cross and circle) attempt to place 3 identical marks in a horizontal, vertical,
or diagonal row to win the game. In the blind variant, the players are unable to observe
the opponents moves and each player only knows that the opponent made a move and it is
her turn. Moreover, if a player tries to place her mark on a square that is already occupied
by an opponents mark, the player learns this information and can place the mark in some
other square. Again, the utility values of this game are from the set {1, 0, 1}.
854

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

Figure 6: Three variants of the graph used in the experiments on the search game; we refer
to them as G1 (left), G2 (middle), and G3 (right).
The uncertainty in phantom Tic-Tac-Toe makes the game large ( 109 nodes). In
addition, since one player can try several squares before her move is successful, the players
do not necessarily alternate in making their moves. This rule makes the structure of the
information sets rather complicated and since the opponent never learns how many attempts
the first player actually performed, a single information set can contain nodes at different
depths in the game tree.
Poker Games Poker is frequently studied in the literature as an example of a large
extensive-form game with imperfect information. We include experiments with a simplified
two-player poker game inspired by Leduc Holdem.
In our version of poker, each player starts with the same amount of chips and both
players are required to put some number of chips in the pot (called the ante). In the next
step, the Nature player deals a single card to each player (the opponent is unaware of the
card) and the betting round begins. A player can either fold (the opponent wins the pot),
check (let the opponent make the next move), bet (being the first to add some amount of
chips to the pot), call (add the amount of chips equal to the last bet of the opponent into
the pot), or raise (match and increase the bet of the opponent). If no further raise is made
by any of the players, the betting round ends, the Nature player deals one card on the
table, and the second betting round with the same rules begins. After the second betting
round ends, the outcome of the game is determined  a player wins if: (1) her private card
matches the table card and the opponents card does not match, (2) none of the players
cards matches the table card and her private card is higher than the private card of the
opponent, or (3) the opponent folds. The utility value is the amount of chips the player has
won or lost. If no player wins, the game is a draw and the pot is split.
In the experiments we alter the number of types of the cards (from 3 to 4; there are
3 types of cards in Leduc), the number of cards of each type (from 2 to 3; set to 2 in Leduc),
the maximum length of sequence of raises in a betting round (ranging from 1 to 4; set to 1
in Leduc), and the number of different sizes of bets (i.e., amount of chips added to the pot)
for bet/raise actions (ranging from 1 to 4; set to 1 in Leduc).
6.2 Results
Search Games The results for the search game scenarios show that the sequence-form
double-oracle algorithm is particularly successful when applied to games where NEs with
small support exist. Figure 7 shows a comparison of the running times for FullLP and
variants of the double-oracle algorithm (note the logarithmic y-scale). All variants of the
855

fiBosansky, Kiekintveld, Lisy, & Pechoucek

102

101

100

103

FullLP
DO-B
DO-SA
DO-SWP
Time [s] (log scale)

Time [s] (log scale)

103

G1-SD

G2-SD

G3-SD

G1-SA

G2-SA

102

101

100

G3-SA

Search Game Scenarios - Depth 6

FullLP
DO-B
DO-SA
DO-SWP

G1-SD

G2-SD

G3-SD

G1-SA

G2-SA

G3-SA

Search Game Scenarios - Depth 7

Figure 7: Comparison of the running times on 3 different graphs with either slow moves
allowed (SA) or disallowed (SD), the depth is set to 6 (left subfigure) or 7 (right subfigure).
Missing values for the FullLP algorithm indicate that the algorithm runs out of memory.

double-oracle algorithm are several orders of magnitude faster than FullLP. This is most
apparent on the fully-connected graph (G2) that generates the largest game tree. When
slow moves are allowed and the depth is set to 6, it takes almost 100 seconds for FullLP
to solve the instance of the game but all variants of the double-oracle algorithms solve the
game in less than 3 seconds. Moreover, when the depth is increased to 7, FullLP was
unable to solve the game due to the memory constraints, while the fastest variant DO-swp
solved the game in less than 5 seconds. Similar results were obtained for the other graphs.
The graph G1 induced a game that was the most difficult for the double-oracle algorithm:
when the depth is set to 7, it takes almost 6 minutes for FullLP to solve the instance, while
the fastest variant DO-swp solved the game in 21 seconds. The reason is that even though
the game tree is not the largest, there is a more complex structure of the information sets.
This is due to limited compatibility among the sequences of the players; when the patrolling
unit P1 observes the tracks in the top-row node, the second patrolling unit P2 can capture
the evader only in the top-row node, or in the middle-row node.
Comparing the different variants of the sequence-form double-oracle algorithm does
not show consistent results. There is no variant consistently better in this game since all
the double-oracle variants are typically able to compute a Nash equilibrium very quickly.
However, DO-swp is often the fastest and for some settings the difference is quite significant.
The speed-up this variant offers is most apparent on the G1 graph. On average through all
instances of the search game, DO-sa uses 92.59% of the computation time of DO-b, and
DO-swp uses 88.25%.
Table 3 shows a breakdown of the cumulative computation time spent in different components of the double-oracle algorithm: solving the restricted game (LP), calculating best
responses (BR), and creating a valid restricted game after selecting new sequences to add
(Validity). The results show that due to the size of the game, the computation of the
best-response sequences takes the majority of the time (typically around 75% on larger
instances), while creating the restricted game and solving it takes only a small fraction of
the total time. It is also noticeable that the size of the final restricted game is very small
856

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

DO-B

DO-SA

DO-SWP

CFR

Bounds Interval Size [-] (log scale)

10
1
0.1
0.01
0.001
0.0001
1e-05
0

50

100
Time [s]

150

200

Figure 8: Convergence of variants of the double-oracle algorithm and CFR on the search
game domain: y-axis displays the current approximation error.
Algorithm
FullLP
DO-b
DO-sa
DO-swp

Overall [s]
351.98
81.51
54.32
21.15

LP [s]

6.97
5.5
1.93

BR [s]

63.39
39.11
16.28

Validity [s]

10.58
9.09
2.47

Iterations

187
344
209

|0 |

|01 |( |11 | )

252 (17.22%)
264 (18.05%)
193 (13.19%)

|0 |

|02 |( |22 | )

711 (0.26%)
649 (0.24%)
692 (0.25%)

Table 3: Cumulative running times for different components of the double-oracle algorithm,
iterations, and size of the restricted game in terms of the number of sequences compared to
the size of the complete game. The results are shown for scenario G1, depth 7, and allowed
slow moves.
compared to the original game, since the number of sequences for the second player (the
defender) is less than 1% (there are 273,099 sequences for the defender).
Finally, we analyze the convergence rate of the variants of the double-oracle algorithm.
The results are depicted in Figure 8, where the size of the interval given by the bounds
ViU B and ViLB defines the current error of the double-oracle algorithm as |ViU B  ViLB |.
The convergence rate of the CFR algorithm is also depicted. The error of CFR is calculated
in the same way, as a sum of the best-response values to the current mean strategies from
the CFR algorithm. We can see that all variants of the double-oracle algorithm perform
similarly  the error drops very quickly to 1 and a few iterations later each version of the
algorithm quickly converges to an exact solution. These results show that in this game the
double-oracle algorithm can very quickly find the correct sequences of actions and compute
an exact solution, in spite of the size of the game. In comparison, the CFR algorithm can
also quickly learn the correct strategies in most of the information sets, but the convergence
has a very long tail. After 200 seconds, the error of CFR is equal to 0.0657 and it is dropping
very slowly (0.0158 after 1 hour). The error of CFR is quite significant considering the value
of the game in this case (0.3333).
Phantom Tic-Tac-Toe The results on Phantom Tic-Tac-Toe confirm that this game is
also suitable for the sequence-form double-oracle algorithm. Due to the size of the game,
both baseline algorithms (the FullLP and CFR) ran out of memory and were not able
857

fiBosansky, Kiekintveld, Lisy, & Pechoucek

DO-SA

DO-SWP
DO-B
DO-SA
DO-SWP

1
Time [s] (log scale)

Bounds Interval Size [-] (log scale)

DO-B

0.1
0.01
0.001

104

0.0001
1e-05
0

5000

10000
15000
Time [s]

20000

25000

103

Random

Domain-dependent

Different Action Ordering in Phantom Tic-Tac-Toe

Figure 9: (left) Comparison of the convergence rate of the double-oracle variants for Phantom Tic-Tac-Toe; (right) Comparison of the performance of the double-oracle variants for
Phantom Tic-Tac-Toe when domain-specific move ordering and default strategy is used.
Algorithm
FullLP
DO-b
DO-sa
DO-swp

Overall [s]
N/A
21,197
17,667
17,589

LP [s]

2,635
2,206
2,143

BR [s]

17,562
14,560
14,582

Validity [s]

999
900
864

Iterations

335
671
591

|0 |

|01 |( |11 | )

7,676 (0.60%)
7,518 (0.59%)
8,242 (0.65%)

|0 |

|02 |( |22 | )

10,095 (0.23%)
9,648 (0.22%)
8,832 (0.20%)

Table 4: Cumulative running times for different components of the double-oracle algorithm
for the game of Phantom Tic-Tac-Toe.
to solve the game. Therefore, we only compare the times for different variants of the
double-oracle algorithm. Figure 9 (left subfigure) shows the overall performance of all three
variants of the double-oracle algorithm in the form of a convergence graph. We see that the
performance of two of the variants is similar, with the performance of DO-sa and DO-swp
almost identical. On the other hand, the results show that DO-b converges significantly
slower.
The time breakdown of the variants of the double-oracle algorithm is shown in Table 4.
Similarly to the previous case, the majority of the time ( 83%) is spent in calculating
the best responses. Out of all variants of the double-oracle algorithm, the DO-swp variant
is the fastest one. It converged in significantly fewer iterations compared to the DO-sa
variant (iterations are twice as expensive in the DO-b variant).
We now present the results that demonstrate the potential of combining the sequenceform double-oracle algorithm with domain-specific knowledge. Every variant of the doubleoracle algorithm can use a move ordering based on domain-specific heuristics. The move
ordering determines the default strategy (recall that our algorithm uses the first action as
the default strategy for each player), and the direction of the search in the best response
algorithms. By replacing the randomly generated move ordering with a heuristic one that
chooses better actions first, the results show a significant improvement in the performance
of all of the variants (see Figure 9, right subfigure), even though there are no changes to
the rest of the algorithm. Each variant was able to solve the game in less than 3 hours, and
it took 2 hours for the fastest DO-swp variant.
858

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

200

FullLP
DO-B
DO-SA
DO-SWP
103
Time [s] (log scale)

150
Time [s]

104

FullLP
DO-B
DO-SA
DO-SWP

100

102

101

50

100

0
R1

R2

R3

R4

Increasing number of allowed "Raise Actions"

B1

B2

B3

B4

Increasing size of possible bets

Figure 10: Comparison of the running times on different variants of the simplified poker
game. The left subfigure shows the computation times with an increasing number of raise
actions allowed, the right subfigure shows the computation times with an increasing number
of different bet sizes for raise/bet actions.
Poker Games Poker represents a game where the double-oracle algorithms do not perform as well and the sequence-form LP is often faster on smaller instances. One significant
difference compared to the previous games is that the size of the NE support is larger
(around 5% of sequences for larger instances). Secondly, the game trees of poker games
are relatively shallow and the only imperfect information in the game is due to Nature.
As a result, the double-oracle algorithms require a larger number of iterations to add more
sequences into the restricted game (up to 10% of all sequences for a player are added even
for the largest poker scenarios) in order to find the exact solution. However, with increasing
depth and/or branching factor, the size of the game grows exponentially and FullLP is
not able to solve the largest instances due to the memory constraints.
Figure 10 shows the selected results for simplified poker variants. The results in the
left subfigure show the computation times with increasing depth of the game by allowing
the players to re-raise (players are allowed to re-raise their opponent a certain number of
times). The remaining parameters are fixed to 3 types of cards, 2 cards of each type, and 2
different betting sizes. The size of the game grows exponentially, with the number of possible
sequences increasing to 210,937 for each player for the R4 scenario. The computation time
for FullLP is directly related to the size of the tree and increases exponentially with the
increasing depth (note that there is a standard y scale). On the other hand, the increase is
less dramatic for all of the variants of the double-oracle algorithm. The DO-swp variant is
the fastest for the largest scenario  while FullLP solved this instance in 126 seconds, it
took only 103 seconds for DO-swp. Finally, FullLP is not able to solve the games if we
increase the length to R5 due to memory constraints, while the computation time of all of
the double-oracle algorithms increases only marginally.
The right subfigure of Figure 10 shows the increase in computation time with an increasing number of different bet sizes for raise/bet actions. The remaining parameters were
fixed to 4 types of cards, 3 cards of each type, and 2 raise actions allowed. Again, the
game grows exponentially with the increasing branching factor. The number of sequences
increases up to 685,125 for each player for the B4 scenario, and the computation time of
859

fiBosansky, Kiekintveld, Lisy, & Pechoucek

DO-B

DO-SA

DO-SWP

CFR

DO-B

DO-SWP

CFR

10
Bounds Interval Size [-] (log scale)

Bounds Interval Size [-] (log scale)

10

DO-SA

1
0.1
0.01
0.001
0.0001
1e-05

1
0.1
0.01
0.001
0.0001
1e-05

0

50

100

150

200
250
Time [s]

300

350

400

0

200

400

600
800
Time [s]

1000

1200

1400

Figure 11: Comparison of the convergence of the variants of the double-oracle algorithm
and CFR for two variants of the simplified poker with 4 types of cards, and 3 cards of each
type. There are 4 raise actions allowed, 2 different bet sizes in the left subfigure; there are
2 raise actions allowed, 3 different bet sizes in the right subfigure.
Algorithm
FullLP
DO-b
DO-sa
DO-swp

Overall [s]
278.18
234.60
199.24
182.68

LP [s]

149.32
117.71
108.95

BR [s]

56.04
51.25
48.25

Validity [s]

28.61
29.59
24.8

Iterations

152
289
267

|0 |

|01 |( |11 | )

6,799 (1.81%)
6,762 (1.80%)
6,572 (1.75%)

|0 |

|02 |( |22 | )

6,854 (1.83%)
6,673 (1.78%)
6,599 (1.76%)

Table 5: Cumulative running times for different components of the double-oracle algorithm,
iterations, and sizes of the restricted game in terms of the number of sequences compared
to the size of the complete game. The results are shown for poker scenario with 4 raise
actions allowed, 2 different betting values, 4 types of cards, and 3 cards of each type.
all algorithms increases exponentially as well (note logarithmic y scale). The results show
that even with the increasing branching factor, the double-oracle variants tend to be slower
than solving the FullLP. However, while the FullLP ran out of memory for the largest
B4 setting, all of the double-oracle variants were able to find the exact solution using less
memory.
Comparing the different variants of the double-oracle algorithm using the convergence
graph (see Figure 11) and the decomposition of the computation times (see Table 5) shows
that DO-swp is the fastest variant in the selected scenario (and in nearly all of poker
scenarios). Decomposition of the overall time shows that the majority of the computation
time is spent in solving the restricted game LP (up to 65%). The decomposition also shows
that DO-swp is typically faster due to the lower number of iterations. In addition, the
final size of the restricted game is typically the smallest for this variant. On average over
all instances of the poker games, DO-sa uses 86.57% of the computation time of DO-b,
and DO-swp uses 82.3% of the computation time.
Convergence in poker games is slower compared to search games of similar size (note the
logarithmic scale in Figure 11). Comparing the double-oracle algorithm variants with CFR
shows an interesting result in the left subfigure. Due to the size of the game, the speed of
the CFR convergence is nearly the same as for the double-oracle algorithms during the first
860

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

iterations. However, while the double-oracle algorithms continue to converge at roughly the
same rate and are able to find an exact solution, the error of the CFR algorithm decreases
very slowly. In the scenario depicted in the left subfigure, the CFR algorithm converged
to an error of 0.1212 (the value of the game in this case is  0.09963) after 400 seconds.
After 1 hour, the error dropped to 0.0268. For scenarios with more shallow game trees and
larger branching factor, the convergence of CFR is faster at the beginning compared to the
double-oracle algorithms (right subfigure of Figure 11). However, the main disadvantage of
CFR having a long tail for convergence is still the case and the error after 1600 seconds is
still over 0.0266 (the value of this game is  0.09828).
6.3 Discussion of the Results
The experimental results support several conclusions. The results demonstrate that the
sequence-form double-oracle algorithm is able to compute an exact solution for much larger
games compared to the state-of-the-art exact algorithm based on the sequence-form linear
program. Moreover, we have experimentally shown that there are realistic games where only
a small fraction of sequences are necessary to find a solution of the game. In these cases,
the double-oracle algorithms also significantly speed up the computation time. Our results
indicate that the DO-swp variant is typically the fastest, but not in all cases. By selecting
the player that currently has the worse bound on performance, the DO-swp version can
add more important sequences, or prove that there are not any better sequences and adjust
the upper bound on the value faster.
Comparing the speed of convergence of the double-oracle algorithms with the state-ofthe-art approximative algorithm CFR showed that CFR quickly approximates the solution
during the first iterations. However, the convergence of CFR has a very long tail and CFR is
not able to find an exact solution for larger games in a reasonable time. Another interesting
observation is that for some games the convergence rate of the double-oracle algorithms
and CFR is similar in the first iterations, and while the double-oracle algorithms continue
at this rate and find an exact solution, the long tail convergence remains for CFR. This is
despite the fact that our implementation of CFR has an advantage of having the complete
game tree including the states for all histories in memory.
Unfortunately, it is difficult to characterize the exact properties of the games for which
the double-oracle algorithms perform better in terms of computation time compared to the
other algorithms. Certainly, the double-oracle algorithm is not suitable for games were
the only equilibria have large support due to the necessity of large number of iterations.
However, having a small support equilibrium is not a sufficient condition. This is apparent
due to two graphs shown in the poker experiments, where either the depth of the game tree
or the branching factor was increased. Even though the game grows exponentially and the
size of the support decreases to  2.5% in both cases, the behavior of the double-oracle
algorithms is quite different. Our conjecture is that games with longer sequences suit the
double-oracle algorithms better, since several actions that form the best-response sequences
can be added during a single iteration. This contrasts with shallow game trees with large
branching factors, where more iterations are necessary to add multiple actions. However,
a deeper analysis to identify the exact properties of the games that are suitable is an open
question that must be analyzed for normal-form games first.
861

fiBosansky, Kiekintveld, Lisy, & Pechoucek

7. Conclusion
We present a novel exact algorithm for solving two player zero-sum extensive-form games
with imperfect information. Our approach combines the compact sequence-form representation for extensive-form games with the iterative algorithmic framework of double-oracle
methods. This integrates two successful approaches for solving large scale games that have
not yet been brought together for the general class of games that our algorithm addresses.
The main idea of our algorithm is to restrict the game by allowing players to play only a
restricted set of sequences from the available sequences of actions, and to iteratively expand
the restricted game over time using fast best-response algorithms. Although in the worst
case the double-oracle algorithm may need to add all possible sequences, the experimental
results on different domains prove that the double-oracle algorithm can find an exact Nash
equilibrium prior to constructing the full linear program for the complete game. Therefore,
the sequence-form double-oracle algorithm reduces the main limitation of the sequence-form
linear programmemory requirementsand it is able to solve much larger games compared
to state-of-the-art methods. Moreover, since our algorithm is able to identify the sequences
of promising actions without any domain-specific knowledge, it can also provide a significant
runtime improvements.
The proposed algorithm also has another crucial advantage compared to the current state
of the art. The double-oracle framework offers a decomposition of the problem of computing
a Nash equilibrium into separate sub-problems, including the best-response algorithms, the
choice of the default strategy, and the algorithms for constructing and solving the restricted
game. We developed solutions for all of these sub-problems in a domain-independent manner. However, we can also view our algorithm as a more general framework that can be
specialized with domain-specific components that take advantage of the structure of specific
problems to improve the performance of these sub-problems. This can lead to substantial
improvements in the speed of the algorithm, the number of iterations, as well as reducing
the final size of the restricted game. We demonstrated the potential of the domain-specific
approach on the game of Phantom Tic-Tac-Toe. Another example is that fast best-response
algorithms that operate on the public tree (i.e., a compact representation of games with
publicly observable actions; see Johanson, Bowling, Waugh, & Zinkevich, 2011) can be exploited for games like poker. Finally, our formal analysis identifies the key properties that
these domain-specific implementations need to satisfy to guarantee the convergence to the
correct solution of the game.
Our algorithm opens up a large number of directions for future work. It represents a new
class of methods for solving extensive-form games with imperfect information that operates
very differently than other common approaches (e.g., counterfactual regret minimization),
and many possible alternatives to improve the performance of the algorithm remain to
be investigated. Examples include more sophisticated calculation of utility values for the
temporary leaves, alternative strategies for expanding the restricted game, and removing
unused sequences from the restricted game. A broader analysis of using the sequenceform double-oracle algorithm as an approximation technique should be performed, possibly
by exploring alternative approximative best-response algorithms based on sampling (e.g.,
Monte Carlo) techniques.
862

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

There are also several theoretical questions that could be investigated. First, the performance of the double-oracle algorithm depends strongly on the number of iterations and
sequences that need to be added. However, the theoretical question regarding the expected
number of iterations and thus the speed of the convergence of the double-oracle algorithm
have not been explored even for simpler game models (e.g., games in the normal form). An
analysis of these simpler models is needed to identify the general properties of games where
the double-oracle methods tend to be faster and to identify the optimal way of expanding
the restricted game.

Acknowledgements
Earlier versions of this paper were published at the European Conference on Artificial
Intelligence (ECAI) (Bosansky, Kiekintveld, Lisy, & Pechoucek, 2012) and the conference
on Autonomous Agents and Multi Agent Systems (AAMAS) (Bosansky, Kiekintveld, Lisy,
Cermak, & Pechoucek, 2013). The major additions to this full version include (1) a novel,
more detailed description of all parts of the algorithm, (2) introduction and analysis of
different policies for the player selection in the main loop of the double-oracle algorithm,
(3) new experiments on the phantom tic-tac-toe domain together with a more thorough
analysis of the experimental results on all domains, including the analysis of the convergence
of the algorithm, (4) experimental comparison with CFR, and finally (5) extended analysis
of related work.
This research was supported by the Czech Science Foundation (grant no. P202/12/2054)
and by U.S. Army Research Office (award no. W911NF-13-1-0467).

References
Barnhart, C., Johnson, E. L., Nemhauser, G. L., Savelsbergh, M. W. P., & Vance, P. H.
(1998). Branch-And-Price: Column Generation for Solving Huge Integer Programs.
Operations Research, 46, 316329.
Bosansky, B., Kiekintveld, C., Lisy, V., Cermak, J., & Pechoucek, M. (2013). Doubleoracle Algorithm for Computing an Exact Nash Equilibrium in Zero-sum Extensiveform Games. In Proceedings of International Conference on Autonomous Agents and
Multiagent Systems (AAMAS), pp. 335342.
Bosansky, B., Kiekintveld, C., Lisy, V., & Pechoucek, M. (2012). Iterative Algorithm for
Solving Two-player Zero-sum Extensive-form Games with Imperfect Information. In
Proceedings of the 20th European Conference on Artificial Intelligence (ECAI), pp.
193198.
Cermak, J., Bosansky, B., & Lisy, V. (2014). Practical Performance of Refinements of
Nash Equilibria in Extensive-Form Zero-Sum Games. In Proceedings of European
Conference on Artificial Intelligence (ECAI), pp. 201206.
Dantzig, G., & Wolfe, P. (1960). Decomposition Principle for Linear Programs. Operations
Research, 8, 101111.
Ganzfried, S., & Sandholm, T. (2013). Improving Performance in Imperfect-Information
Games with Large State and Action Spaces by Solving Endgames. In Computer
863

fiBosansky, Kiekintveld, Lisy, & Pechoucek

Poker and Imperfect Information Workshop at the National Conference on Artificial
Intelligence (AAAI).
Gibson, R., Lanctot, M., Burch, N., Szafron, D., & Bowling, M. (2012). Generalized Sampling and Variance in Counterfactual Regret Minimization. In Proceedings of the 26th
AAAI Conference on Artificial Intelligence, pp. 13551361.
Halvorson, E., Conitzer, V., & Parr, R. (2009). Multi-step Multi-sensor Hider-seeker Games.
In Proceedings of the Joint International Conference on Artificial Intelligence (IJCAI),
pp. 159166.
Hoda, S., Gilpin, A., Pena, J., & Sandholm, T. (2010). Smoothing Techniques for Computing
Nash Equilibria of Sequential Games. Mathematics of Operations Research, 35 (2),
494512.
Jain, M., Conitzer, V., & Tambe, M. (2013). Security Scheduling for Real-world Networks.
In Proceedings of the International Conference on Autonomous Agents and Multiagent
Systems (AAMAS), pp. 215222.
Jain, M., Korzhyk, D., Vanek, O., Conitzer, V., Tambe, M., & Pechoucek, M. (2011). Double
Oracle Algorithm for Zero-Sum Security Games on Graph. In Proceedings of the 10th
International Conference on Autonomous Agents and Multiagent Systems (AAMAS),
pp. 327334.
Johanson, M., Bowling, M., Waugh, K., & Zinkevich, M. (2011). Accelerating Best Response
Calculation in Large Extensive Games. In Proceedings of the 22nd International Joint
Conference on Artificial Intelligence (IJCAI), pp. 258265.
Koller, D., & Megiddo, N. (1992). The Complexity of Two-Person Zero-Sum Games in
Extensive Form. Games and Economic Behavior, 4, 528552.
Koller, D., Megiddo, N., & von Stengel, B. (1996). Efficient Computation of Equilibria for
Extensive Two-Person Games. Games and Economic Behavior, 14 (2), 247259.
Koller, D., & Megiddo, N. (1996). Finding Mixed Strategies with Small Supports in Extensive Form Games. International Journal of Game Theory, 25, 7392.
Kreps, D. M., & Wilson, R. (1982). Sequential Equilibria. Econometrica, 50 (4), 86394.
Lanctot, M. (2013). Monte Carlo Sampling and Regret Minimization for Equilibrium Computation and Decision Making in Large Extensive-Form Games. Ph.D. thesis, University of Alberta.
Lanctot, M., Gibson, R., Burch, N., Zinkevich, M., & Bowling, M. (2012). No-Regret
Learning in Extensive-Form Games with Imperfect Recall. In Proceedings of the 29th
International Conference on Machine Learning (ICML 2012), pp. 121.
Lanctot, M., Waugh, K., Zinkevich, M., & Bowling, M. (2009). Monte Carlo Sampling
for Regret Minimization in Extensive Games. In Advances in Neural Information
Processing Systems (NIPS), pp. 10781086.
Lee, C.-S., Wang, M.-H., Chaslot, G., Hoock, J.-B., Rimmel, A., Teytaud, O., Tsai, S.-R.,
Hsu, S.-C., & Hong, T.-P. (2009). The Computational Intelligence of Mogo Revealed
in Taiwans Computer Go Tournaments. IEEE Transactions on Computational Intelligence and AI in Games, 1, 7389.
864

fiAn Exact Double-Oracle Algorithm for Zero-Sum EFGs with Imperfect Information

Letchford, J., & Vorobeychik, Y. (2013). Optimal Interdiction of Attack Plans. In Proceedings of the 12th International Conference on Automonous Agents and Multiagent
Systems (AAMAS), pp. 199206.
Lisy, V., Kovarik, V., Lanctot, M., & Bosansky, B. (2013). Convergence of Monte Carlo Tree
Search in Simultaneous Move Games. In Advances in Neural Information Processing
Systems (NIPS), Vol. 26, pp. 21122120.
McMahan, H. B. (2006). Robust Planning in Domains with Stochastic Outcomes, Adversaries, and Partial Observability. Ph.D. thesis, Carnegie Mellon University.
McMahan, H. B., & Gordon, G. J. (2007). A Fast Bundle-based Anytime Algorithm for
Poker and other Convex Games. Journal of Machine Learning Research - Proceedings
Track, 2, 323330.
McMahan, H. B., Gordon, G. J., & Blum, A. (2003). Planning in the Presence of Cost
Functions Controlled by an Adversary. In Proceedings of the International Conference
on Machine Learning, pp. 536543.
Miltersen, P. B., & Srensen, T. B. (2008). Fast Algorithms for Finding Proper Strategies
in Game Trees. In Proceedings of Symposium on Discrete Algorithms (SODA), pp.
874883.
Miltersen, P. B., & Srensen, T. B. (2010). Computing a Quasi-Perfect Equilibrium of a
Two-Player Game. Economic Theory, 42 (1), 175192.
Pita, J., Jain, M., Western, C., Portway, C., Tambe, M., Ordonez, F., Kraus, S., & Parachuri,
P. (2008). Deployed ARMOR protection: The Application of a Game-Theoretic Model
for Security at the Los Angeles International Airport. In Proceedings of the 8th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp.
125132.
Ponsen, M. J. V., de Jong, S., & Lanctot, M. (2011). Computing Approximate Nash Equilibria and Robust Best-Responses Using Sampling. Journal of Artificial Intelligence
Research (JAIR), 42, 575605.
Sandholm, T. (2010). The State of Solving Large Incomplete-Information Games, and
Application to Poker. AI Magazine, special issue on Algorithmic Game Theory, 13
32.
Selten, R. (1975). Reexamination of the Perfectness Concept for Equilibrium Points in
Extensive Games. International Journal of Game Theory, 4, 2555.
Selten, R. (1965). Spieltheoretische Behandlung eines Oligopolmodells mit Nachfragetrgheit
[An oligopoly model with demand inertia]. Zeitschrift fur die Gesamte Staatswissenschaft, 121, 301324.
Shafiei, M., Sturtevant, N., & Schaeffer, J. (2009). Comparing UCT versus CFR in Simultaneous Games. In IJCAI Workshop on General Game Playing.
Shieh, E., An, B., Yang, R., Tambe, M., Baldwin, C., Direnzo, J., Meyer, G., Baldwin, C. W.,
Maule, B. J., & Meyer, G. R. (2012). PROTECT : A Deployed Game Theoretic System
to Protect the Ports of the United States. In International Conference on Autonomous
Agents and Multiagent Systems (AAMAS), pp. 1320.
865

fiBosansky, Kiekintveld, Lisy, & Pechoucek

Shoham, Y., & Leyton-Brown, K. (2009). Multiagent Systems: Algorithmic, GameTheoretic, and Logical Foundations. Cambridge University Press.
Tambe, M. (2011). Security and Game Theory: Algorithms, Deployed Systems, Lessons
Learned. Cambridge University Press.
Tsai, J., Rathi, S., Kiekintveld, C., Ordonez, F., & Tambe, M. (2009). IRIS - A Tool
for Strategic Security Allocation in Transportation Networks Categories and Subject
Descriptors. In Proceedings of the 8th International Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 3744.
van Damme, E. (1984). A Relation Between Perfect Equilibria in Extensive Form Games
and Proper Equilibria in Normal Form Games. Game Theory, 13, 113.
van Damme, E. (1991). Stability and Perfection of Nash Equilibria. Springer-Verlag.
von Stengel, B. (1996). Efficient Computation of Behavior Strategies. Games and Economic
Behavior, 14, 220246.
Wilson, R. (1972). Computing Equilibria of Two-Person Games From the Extensive Form.
Management Science, 18 (7), 448460.
Zinkevich, M., Johanson, M., Bowling, M., & Piccione, C. (2008). Regret Minimization
in Games with Incomplete Information. Advances in Neural Information Processing
Systems (NIPS), 20, 17291736.
Zinkevich, M., Bowling, M., & Burch, N. (2007). A New Algorithm for Generating Equilibria
in Massive Zero-Sum Games. In Proceedings of National Conference on Artificial
Intelligence (AAAI), pp. 788793.

866

fiJournal of Artificial Intelligence Research 51 (2014) 725778

Submitted 04/14; published 12/14

Tutorial on Structured Continuous-Time Markov Processes
Christian R. Shelton

cshelton@cs.ucr.edu

University of California, Riverside

Gianfranco Ciardo

ciardo@iastate.edu

Iowa State University

Abstract
A continuous-time Markov process (CTMP) is a collection of variables indexed by
a continuous quantity, time. It obeys the Markov property that the distribution over
a future variable is independent of past variables given the state at the present time.
We introduce continuous-time Markov process representations and algorithms for filtering,
smoothing, expected sufficient statistics calculations, and model estimation, assuming no
prior knowledge of continuous-time processes but some basic knowledge of probability and
statistics. We begin by describing flat or unstructured Markov processes and then move
to structured Markov processes (those arising from state spaces consisting of assignments
to variables) including Kronecker, decision-diagram, and continuous-time Bayesian network
representations. We provide the first connection between decision-diagrams and continuoustime Bayesian networks.

1. Tutorial Goals
This tutorial is intended for readers interested in learning about continuous-time Markov
processes, and in particular compact or structured representations of them. It is assumed
that the reader is familiar with general probability and statistics and has some knowledge
of discrete-time Markov chains and perhaps hidden Markov model algorithms.
While this tutorial deals only with Markovian systems, we do not require that all variables be observed. Thus, hidden variables can be used to model long-range interactions
among observations. In these models, at any given instant the assignment to all state variables is sufficient to describe the future evolution of the system. The variables themselves
real-valued (continuous) times. We consider evidence or observations that can be regularly
spaced, irregularly spaced, or continuous over intervals. These evidence patterns can change
by model variable and time.
We deal exclusively with discrete-state continuous-time systems. Real-valued variables
are important in many situations, but to keep the scope manageable, we will not treat them
here. We refer to the work of Sarkka (2006) for a machine-learning-oriented treatment of
filtering and smoothing in such models. The literature on parameter estimation is more
scattered. We will further constrain our discussion to systems with finite states, although
many of the concepts can be extended to countably infinite state systems.
We will be concerned with two main problems: inference and learning (parameter estimation). These were chosen as those most familiar to and applicable for researchers in
artificial intelligence. At points we will also discuss the computation of steady-state properties, especially for model for which most research concentrates on this computation.
c
2014
AI Access Foundation. All rights reserved.

fiShelton & Ciardo

The first section (Section 2) covers the basics of flat (unstructured state-space) continuoustime Markov processes. The remaining sections discuss compact representations. This tutorials goal is to make the mathematical foundations clear and lay out the current research
landscape so that more detailed papers can be read more easily.
1.1 Related Models
There are many non-Markov continuous time models. Gaussian processes (Williams, 1998)
are the best-known and model continuous-valued processes. For discrete-valued processes,
most models build upon Poisson processes, or more general marked processes. As a Poisson
process is memoryless, to make an interesting model, researchers usually generalize to allow
the rate of an event to be a function of the processs history.
Poisson networks (Rajaram, Graepel, & Herbrich, 2005) constrain this function to depend only on the counts of the number of events (possibly of different event types) during
a finite time window. The cascade of Poisson process model (Rajaram et al., 2005) defines
the rate function to be the sum of a kernel applied to each historic event. The kernel has
parameters for the effect of time passing, overall event rate, and chance that one type of
event follows another. Piecewise-constant intensity models (PCIMs) (Gunawardana, Meek,
& Xu, 2012; Parikh, Gunamwardana, & Meek, 2012) define the intensity function as a
decision tree, with internal nodes tests drawn from a set of pre-specified binary tests of
the history. Forest-based point processes (Weiss & Page, 2013) extend this by allowing the
intensity function to be the product of a set of functions, each a PCIM-like tree. Didelez
(2008) presents a generalization of the continuous-time Bayesian networks (see Section 5)
to inhomogeneous point processes, but without specific parameterizations or algorithms.
1.2 Why Continuous Time
Contemporary computers are discrete-time computation engines (or at least present a model
of one). Therefore, why would we consider a continuous-time model? The quickest answer is
by analogy: We build models of non-temporal systems employing real-valued variables. The
tools of linear algebra, calculus, and the like allow us to derive and analyze these algorithms
and methods. Yet, in the end they will be implemented on discrete-valued computers with
finite memory and precision. However, we find the abstraction of continuous-valued variables useful and only make approximations during the final implementation when employing
fixed- or floating-point precision arithmetic.
Similarly, it is productive to treat time as a continuous quantity. It allows us to more
naturally discuss and reason about systems in which
1. Events, measurements, or durations are irregularly spaced,
2. Rates vary by orders of magnitude, or
3. Durations of continuous measurement need to be expressed explicitly.
All of these happen in asynchronous systems. Most dynamic systems of interest are asynchronous: events or measurements (or both) do not occur based on some global clock. Social
networks, phylogenetic trees, and computer system logs are just some examples.
Note that while the underlying system model is continuous-time, observations and measurements of that model need not be continuous. We directly treat discrete-time observations, both at regular and irregular intervals.
726

fiTutorial on Structured Continuous-Time Markov Processes

1.3 Why Not Discrete Time
Clearly for any given continuous-time system specification, some discretization of time values could be made without introducing too much approximation error. Such a conversion
of time from real-valued to integral makes it mathematically more difficult to be flexible
about how to treat time algorithmically. This makes the development of computationally
efficient algorithms more difficult. For instance, in a discrete-time model, it is natural to
have computations proceed one time step at a time. However, for uneventful times, this
can be computationally overly burdensome. With a continuous-time model, because there
is no natural time step, it is simpler to think about methods that can jump over such
uneventful time periods. Additionally, there are a few oddities about Markov chains built
by discretizing continuous time. Finally, the full system specification may not be known
when the discretization must be selected (for instance, if parameters must be estimated).
1.3.1 Time Discretization and Markovian-ness
Consider the two-state Markov chain X described by the stochastic matrix1


0.75 0.25
.
T1 =
0.5 0.5

(1)

The elements of T 1 are the probabilities p(Xt | Xt1 ) for each value of Xt and Xt1 . Over
one time unit, the probability of moving from state 1 to state 2 is 0.25, for example.
If T 1 describes a continuous-time system, sampled at a period of 1 time unit, there
should be a matrix T 1/2 describing the same system, sampled at a period of 12 time unit
(or twice the sampling rate). Indeed there is:


0.83 0.17
.
(2)
T 1/2 =
0.33 0.67
This can be verified:
P (Xt = j | Xt1 = i) =

X

P (Xt1/2 = k | Xt1 = i)P (Xt = j | Xt1/2 = k)

k

T 1 (i, j) =

X

T 1/2 (i, k)T 1/2 (k, j)

k

T 1 = T 1/2 T 1/2 .
That is, T 1/2 is the matrix square root of T 1 .
Now take a different two-state Markov chain transition matrix


0.1 0.9
S1 =
0.9 0.1
and construct the corresponding transition matrix at half the sampling period, S 1/2 :


0.5 + .447i 0.5  .447i
S 1/2 =
.
0.5 + .447i 0.5  .447i

(3)

(4)

1. We will use row-stochastic matrices exclusively in this tutorial. While column-stochastic matrices are
often used for discrete time, row-stochastic matrices are more common in continuous time.

727

fiShelton & Ciardo

x1

x2

x3

x1

x3

y1

y2

y3

y1

y3

z1

z2

z3

z1

z3

x1

x3

y1

y3

z1

z3

(a) unrolled DBN

(b) marginalized DBN

Figure 1: Example of (a) a DBN unrolled, and (b) the same DBN marginalized to twice
the sampling periodicity

There is no real-valued stochastic matrix describing the same processes as S 1 , but at half the
sampling periodicity. Put differently, there is no two-state continuous-time Markov system
that when sampled at a rate of 1 time unit produces the Markov chain with transition
matrix S 1 .
The problem in generating S 1/2 arises because S 1 has a negative eigenvalue (by contrast,
all eigenvalues of T 1 are positive). In general, only stochastic matrices with all positive
eigenvalues correspond to a continuous-time Markov process sampled at a given periodicity.
This can be viewed in two ways. First, it means that the set of continuous-time Markov
processes is smaller than the set of discrete-time Markov processes. Second, it means that
there are processes that are Markovian only when sampled at a particular periodicity and
the only way to extend them to time points outside that periodicity would be to construct
a non-Markovian (and non-stationary) process.
If the periodicity of a discrete-time Markov chain is inherent to the process, then this
result is not of concern. However, many systems do not have a natural sampling rate. The
rate is chosen for computational or measurement convenience. In this case, we must be
careful about how we employ our Markovian assumption. Or, we should directly model the
underlying system in continuous time.
1.3.2 Independencies and Markovian-ness
A similar problem arises for independencies. We describe the problem here in terms of
dynamic Bayesian networks (DBNs) (Dean & Kanazawa, 1989). If unfamiliar with DBNs,
the reader may skip to the next section.
Consider the DBN in Figure 1(top,a), which has been unrolled one time step. We can
marginalize out the middle time slice and the result is the DBN in Figure 1(top,b): the
same model, but over twice the sampling periodicity. However, perhaps we wish to go the
opposite direction (to half the sampling periodicity). Figure 1(bottom,b) shows a DBN over
728

fiTutorial on Structured Continuous-Time Markov Processes

0

Test Log-Likelihood

20

40

60

80
optimal
CTBN
100

t = 0.1
t = 1.0
t = 5.0

120
2

4

6
Number of Trajectories

8

10

Figure 2: Comparison of learning DBNs with different time-slice widths
two time units. There is no DBN graph structure over one time unit that would marginalize
to this graph structure. There may be a DBN, but the independencies expressed by the
graph structure over two time units are not expressible in the graph structure at half the
sampling periodicity. Such independencies would be buried in the parameters of the DBN
(if those parameters are possible, given the previous discussion). This means that the
independencies expressed by a DBNs graph are a function of both the underlying process
and the sampling rate.
1.3.3 Structure Learning
Selection of a sampling rate is not just a theoretical problem. Nodelman, Shelton, and Koller
(2003) demonstrate the problem for parameter estimation. In particular, they considered
data drawn from a continuous-time Markovian process of eight variables (mostly binary).
The resulting trajectories were discretized in time according to a parameter t and DBNs
(including structure) were learned for each setting. Figure 2 shows the test log-likelihood
accuracy as a function of the number of training trajectories and t. It also shows the
result of not discretizing time (the CTBN line, a model explained in Section 5).
While it is not too surprising that the CTBN model does the best (as the data were
generated from this model), it is instructive that the best t depends on the number of
observed trajectories. This means that, if the sampling periodicity is a model parameter,
its choice cannot be made independently of the amount of data used to estimate the DBN.

2. Continuous-Time Markov Processes
A continuous-time Markov process (CTMP) is a distribution over trajectories. A trajectory
(or sample) of a CTMP is a right-continuous piece-wise constant function of a real-valued
variable, time. Figure 3 illustrates example trajectories. If the states have a natural order729

fiShelton & Ciardo

3
2
1

t

(a) ordered states

t

(b) unordered states

t

(c) multiple state variables

Figure 3: Example continuous-time Markov process samples (trajectories)
ing, Figure 3(a) might be a natural depiction. If the states are not ordered, Figure 3(b)
depicts the same sample for a three-state system. In later sections we will be considering
large factored state spaces in which a state is an assignment to multiple variables. Figure 3(c) depicts such a trajectory.
A finite CTMP defines a set of random variables, each with the same finite sample space
(the state space), indexed by a real-value usually denoted as t for time. Let X be such a
process. The Markovian property states that
X(t1 )  X(t3 ) | X(t2 ),  t1 < t2 < t3 .

(5)

Throughout this tutorial, we will describe distributions over both continuous and discrete random variables. We will use lowercase letters for the densities of continuous random
variables and uppercase letters for the probabilities of discrete random variables.
2.1 Parameterization
We will parameterize a CTMP X by a starting distribution at time t = 0, P (X(0)) (and
restrict t  0) and an intensity matrix QX (or just Q if the context is clear). The starting
distribution is just as in a discrete-time Markov chain, and we will largely ignore it. The
intensity matrix is analogous to the transition matrix of a discrete-time process.
2.1.1 Comparison to Discrete-Time
Consider the following (roughly equivalent) discrete-time transition matrix M and continuoustime intensity matrix Q:




0.5 0.2 0.3
0.8
0.32
0.48
0.12  .
M =  0.1 0.8 0.1 
Q =  0.12 0.24
0.2 0.1 0.7
0.27
0.13 0.4
We can interpret a row of M in two ways. The first row could be viewed as stating
that if the process is in state 1, at the next time step there is a 0.5 chance that it will be
in state 1, a 0.2 chance that it will be in state 2, and a 0.3 chance that it will be in state 3.
Alternatively, it could be viewed as stating that if the process is in state 1, it will remain
there for a number of steps geometrically distributed: Pr(stay for n steps) = 0.5n . And,
when it leaves it will transition to state 2 with probability 0.2/0.5 = 0.4 and to state 3 with
probability 0.3/0.5 = 0.6.
The intensity matrix Q has two similar interpretations. The first row states that if the
process is in state 1, after a short period of time , there is approximately a 1  0.8 chance
of being in state 1, a 0.32 chance of being in state 2, and a 0.48 chance of being in state
730

fiTutorial on Structured Continuous-Time Markov Processes

3. The approximation has error O(2 ). Alternatively, it states that if the process is in state
1 it remains there for a duration exponentially distributed: p(dwell time = t) = 0.8e0.8t .
And when it leaves, it will transition to state 2 with probability 0.32/0.8 = 0.4 and to state
3 with probability 0.48/0.8 = 0.6.
2.1.2 Racing Exponentials
We can also view a row of the matrix as describing racing exponential distributions. There
are two important properties of an exponential distribution. First, it is memoryless:
pZ (t) = pZ (t + s|Z > s)

if Z is exponentially distributed

(6)

and thus is the right distribution for dwell times in a Markovian process. (The amount of
time the process has stayed in this state does not affect the remaining dwell time.) It is
also closed under minimization: Given a collection of random variables Z1 , Z2 , . . . , Zn ,
pZi (t) = ri eri t

(7)

Y = min Zi

(8)

J = arg min Zi

(9)

i

i

implies
pY (t) = rert
rj
Pr(J = j) =
r

(10)
(11)

where
r=

n
X

ri .

(12)

i=1

That is, if we have a set of exponential distributions with (potentially) different rates, their
minimum (the time of the earliest one) is also exponentially distributed with rate equal to
the sum of the component rates. Furthermore, the component which causes this minimum
is independent of the time and is proportional to that components rate. Thus, we can view
each row of the matrix as a set of racing exponential distributions: one for each potential
next state with rates dictated by the off-diagonal elements. Whichever potential transition
happens first is the one actually taken by the process, and the rest are discarded.
2.1.3 Event Decomposition
Further, we can use this to build an interpretation of the summation of two intensity
matrices. If Q = Q1 + Q2 , where both Q1 and Q2 are valid intensity matrices, then
the process of Q can be viewed as the combination of processes of Q1 and Q2 in which
both sub-processes race to produce the next transition: For each current state, the two
sub-processes have their own rate of transition for the possible new states. Whichever
transition happens first switches the state and the joint process continues with the new
731

fiShelton & Ciardo

state. We can also view this as two different event types each with its own intensity matrix.
The process of Q is the joint process of running both events at the same time, but throwing
away (marginalizing out) the event types associated with the transitions, leaving only the
transitions themselves.
2.1.4 Infinitesimal Rate Semantics
More formally, the dynamics of an n-state CTMP are described by a n-by-n intensity matrix
Q. The diagonal elements of Q are non-positive and the non-diagonal elements of Q are
non-negative. The rows of Q sum to 0 (thus the diagonal elements are the negative row
sums, if the diagonal element is excluded from the sum). We will denote the i, j element of
Q as qi,j . Further, for notational simplicity, we will let qi = qi,i . That is, qi is the rate of
leaving state i, the absolute value of the corresponding diagonal element.
If we let p(t) be a row-vector of the marginal distribution of the process at time t, then
the semantics of Q can be stated as
p(t + ) = p(t)(I + Q) + o() .

(13)

This implies that
p(t + )  p(t) = p(t)Q + o()

(14)

lim (p(t + )  p(t))/ = p(t)Q

(15)

dp(t)
= p(t)Q
dt

(16)

0

(17)
This first-order linear homogeneous differential equation has solution
p(t + s) = p(t)eQs

(18)

assuming s > 0 and the initial conditions at t, p(t), are known. The exponential is the
matrix exponential, defined by its Taylor expansion:
eQs =

 k
X
s
k=0

k!

Qk .

(19)

Although not often practical computationally, we can also express the matrix exponential
in terms of the eigenvalues ({i }) and corresponding right and left eigenvectors ({vi } and
{wi }) of Q:
X
eQs =
ei s vi wi> .
(20)
i

If Q is of finite size and irreducible (there is a positive-rate path from any state to any
other state), then the process is ergodic (the notion of cycling behavior does not exist
in continuous-time Markov processes) and there will be exactly one eigenvalue equal to 0.
The corresponding right eigenvector is the unique steady-state (or stationary) distribution
of the process. If the process is not ergodic, then there may be multiple 0 eigenvalues and
no unique stationary distribution. All other eigenvalues will be less than 0 and correspond
to transients in the system. Therefore, Q will always be negative semi-definite.
732

fi0.6

0.6

0.5

0.5

Pr(state)

Pr(state)

Tutorial on Structured Continuous-Time Markov Processes

0.4
0.3
0.2

0.3
0.2

0

2

4
time

6

0.1

8

0.6

0.6

0.5

0.5

Pr(state)

Pr(state)

0.1

0.4

0.4
0.3
0.2
0.1

0

2

4
time

6

8

0

2

4
time

6

8

0.4
0.3
0.2

0

2

4
time

6

0.1

8

fixed step-size

adaptive step-size

Figure 4: Propagation of marginal distribution from time 0 to time 8 by Euler integration. Left: fixed step-size. Right: adaptive step-size. Top: 11 evaluation points.
Bottom: 5 evaluation points.

2.2 Matrix Exponential
The matrix exponential plays a critical role in many aspects of reasoning about continuoustime dynamic systems. At first, this would seem to be a significant downside, relative to
discrete-time systems. Propagation of distribution p (as a vector) n time steps in a discretetime system requires the multiplication by M n (if M is the stochastic transition matrix).
By contrast, the same operation in continuous-time requires the calculation of the matrix
exponential, which is an infinite sum of matrix powers.
Consider computing the marginal distribution at time t by integrating the differential
equation of Equation 18. The simplest method would be to use Euler integration with a
fixed step size of t. This amounts to propagating over a fixed time interval by multiplying
by M = I + tQ. This is essentially the same as discretizing time and approximating the
stochastic matrix over the resulting interval. To propagate to time t requires t/t matrix
multiplications. This is shown on the left side of Figure 4.
However, because time is continuous, we need not limit ourselves to time steps of uniform
size. If we choose an adaptive step size, we can achieve the same accuracy with fewer
evaluation points. Figure 4 demonstrates this for the simplest adaptive scheme (Euler steps
with step size proportional to derivative magnitude). Note that for the same number of
steps (computational complexity), the accuracy with adaptive steps is better.
For real applications, we would use a more advanced differential equation solver with
more intelligent step size selection; see the work of Press, Teukolsky, Vetterling, and Flannery (1992) for an introduction. Yet, the idea is essentially the same: we can take larger
steps during less interesting time periods. To do something similar with discrete time
would require computations that essentially convert the discrete-time system to a continuous733

fiShelton & Ciardo

time one. Techniques like squaring and scaling to multiply by large matrix powers can also
be applied to the matrix exponential. For a full discussion of matrix exponential calculations, we refer to the excellent treatments of Moler and Loan (2003) and Najfeld and Havel
(1994, 1995).
2.3 Uniformization
Uniformization (also called randomization) is a method for converting questions about a
continuous-time Markov process into ones about a discrete-time one (Grassmann, 1977).
Given an intensity matrix Q, uniformization constructs the stochastic matrix
M = Q/ + I

(21)

where   maxi qi (that is,  is no less than the largest rate in Q). For example, the
following uniformization is with  = 0.5 (the smallest possible value for ).




0.5
0.1
0.4
0.0 0.2 0.8
0.1   M =  0.2 0.6 0.2 
Q =  0.1 0.2
(22)
0.2
0.1 0.3
0.4 0.2 0.4
The resulting stochastic matrix can be interpreted as a discrete-time process. However it
is not equivalent to sampling the continuous-time process at uniform intervals. Nor is it, in
general, equivalent to the embedded Markov chain (the sequence of states, discarding the
times of transitions). The former is achieved through the matrix exponential and the latter
is achieved by setting all diagonal elements of Q to zero and then normalizing each row to
sum to one.
Rather, the discrete-time process associated with the stochastic matrix M is related to
the continuous-time process associated with the intensity matrix Q in the following way.
Consider the procedure of (1) sampling event times from a Poisson process with rate 
(that is, the times between consecutive events are independently and identically distributed
as an exponential distribution with rate ), then (2) sampling state transitions at these
event times from the discrete-time process described by M , and then (3) discarding any
self transitions. This procedure produces samples from the same distribution as the original
CTMP described by Q.
This transformation is useful for simulation (sampling), but also for understanding and
computing the matrix exponential. Because the intensity matrix Q is negative semi-definite,
the Taylor expansion of the matrix exponential is unstable, as the sign of the terms
alternates. However, we can fix this by using M instead of Q. By reworking Equation 21,
we note that Q = (M  I). We can then write
eQt = e(M I)t

(23)

t M t

=e

= et

e

X
 k tk

(24)

Mk

(25)

k tk
et
Mk
k!
{z }
k=0 |

(26)

k=0

=

[eA+B = eA eB if AB = BA]

k!


X

k

734

fiTutorial on Structured Continuous-Time Markov Processes

s0

s1

t0

t1

s2
t2

s3

s4
t4

t3

t5

Figure 5: Pictorial representation of a finite-length sample from a CTMP.
where k is the probability of having exactly k events from a Poisson process with rate 
in time t. This series is more stable (M is positive semi-definite) and for a finite number
of terms, the sum is a quasi-probability vector (it is non-negative and sums to less than
1). The missing probability is a bound on the error. The sequence k grows and then
decays. Therefore, discarding not only the tail of the series, but also early terms can speed
up computations. Fox and Glynn (1988) give a method to compute left and right bounds
on k to ensure a desired error tolerance.
Note that, if Q represents an ergodic continuous-time Markov process, then M represents an ergodic discrete-time Markov process when  is strictly greater than maxi qi (a
sufficient, but not necessary condition). If M is ergodic, then the stationary distribution
of Q is the same as the stationary distribution of M .
2.4 Likelihood
A complete finite-length sample (trajectory) Tr from a CTMP is sequence of states and the
times of the transitions, plus an ending time: Tr = {(s0 , t0 ), (s1 , t1 ), . . . , (sn1 , tn1 )}, tn .
Figure 5 shows a pictorial representation, for n = 5. If we use the convention that the
process starts at time 0, then t0 must be equal to 0.
The likelihood of this sample is the product of the conditional probabilities of each event
(the starting state, each dwell duration, and each state transition):


pr of last duration
density of duration pr of trans
init dist
}|
{
z
z
}|
{
}|
{
z
n2
z
}|
{Y

q
s
,s
i
i+1
qsn1 (tn tn1 )
qsi (ti+1 ti )


p(Tr) = Pr(X(t0 ) = s0 )
e
(27)
 qs i e
qsi 
i=0

= P0 (s0 )

n1
Y

qsi (ti+1 ti )

e

i=0

ln p(Tr) = ln P0 (s0 ) 

n2
Y

qsi ,si+1

(28)

i=0
n1
X

qsi (ti+1  ti ) +

i=0

n2
X

ln qsi ,si+1

(29)

i=0

We let P0 be the distribution over the starting state of the process. Note that at time tn
the process does not transition. Rather, we observe that the process remains in state sn1
for a duration of at least tn  tn1 .
Equation 29 can be rewritten as
X
X
ln p(Tr) = ln P0 (s0 ) 
T [s]qs +
N [s, s0 ] ln qs,s0
(30)
s6=s0

s

where T [s] is the total time spent in state s and N [s, s0 ] is the total number of transitions
from s to s0 , both of which are functions of Tr. This demonstrates that a CTMP is a
735

fiShelton & Ciardo

member of an exponential family in which the sufficient statistics are T [] and N [, ] (plus
the relevant sufficient statistics for the starting distribution), and the natural parameters
are the diagonal elements of the intensity matrix and the logarithm of the non-diagonal
elements. The likelihood of multiple trajectories has the same form, where T [s] and N [s, s0 ]
are the sums of the sufficient statistics over the individual trajectories.
2.4.1 Parameter Estimation
The maximum likelihood
P parameters can be easily derived by differentiating Equation 30,
after replacing qs with s0 6=s qs,s0 :
 ln p(Tr)
N [s, s0 ]
=
 T [s]
qs,s0
qs,s0

 s0 6= s

(31)

 s0 6= s

(32)

s

(33)

which implies the ML parameters are
qs,s0 = N [s, s0 ]/T [s]
X
qs =
N [s, s0 ]/T [s]
s0 6=s

A maximum a posteriori (MAP) estimate can be calculated if we place suitable prior distributions on the parameters. In particular, we will put an independent gamma distribution
prior over each of the independent parameters, qs,s0 ,  s 6= s0 :


p(qs,s0 ; s,s0 , s,s0 ) =

s,ss,s
0

0 +1

(s,s0 + 1)



0

qs,ss,s0 eqs,s0 s,s0

(34)

which has parameters s,s0 and s,s0 . The posterior distribution over the parameters given
data summarized by the sufficient statistics T [s] and N [s, s0 ] is also gamma-distributed with
parameters s,s0 + N [s, s0 ] and s,s0 + T [s]. Thus, the MAP estimates of the parameters are
qs =

X N [s, s0 ] + s,s0
s0

qs,s0 =

T [s] + s,s0

N [s, s0 ] + s,s0
.
T [s] + s,s0

(35)
(36)

2.5 Inference
We will now consider two classic problems of reasoning in temporal systems: filtering and
smoothing. Initially, we will assume we have observations (evidence) with a pattern like that
in Figure 6: a sequence of times {t0 , t1 , . . . , tk } and a sequence of evidences {e1 , e2 , . . . , ek }.
We assume that we know the prior marginal distribution over X(t0 ), either from previous
reasoning or because t0 = 0.
Filtering is the task of computing p(X(t) | e1 , e2 , . . . , ek ) for t  tk . If the evidence at
each point is an observation of the state of the system, the Markovian property of the process
makes inference trivial. Instead we will assume that ei is only probabilistically related to
X(ti ) but independent of everything else given X(ti ). (This is analogous to a discrete-time
736

fiTutorial on Structured Continuous-Time Markov Processes

t0

e1

e2

e3

t1

t2

t3

Figure 6: Example evidence pattern, point evidence.
hidden Markov model.) Thus we can view each observation as a noisy measurement of the
system.
As with a hidden Markov model, we define a recursive filtering solution using a forward
message  whose components are defined as
i (t) = Pr X(t) = i, e[t0 ,t)



(37)

where we denote e[s,t) = {(ti , ei ) | s  ti < t}: the set of evidence in the interval [s, t). By
analogy we will also define e[s,t] and e(s,t] to be the evidence on [s, t] and (s, t] respectively
(which we will need later). Note that  is a row vector of probabilities, one for each state
of the system. Recursive calculation of  can be derived from
 X


Pr X(t) = j, e[t0 ,t) =
Pr X(s) = i, e[t0 ,s) Pr X(t) = j, e[s,t) | X(s) = i  t0  s < t
i

(38)
 t0  s < t
(39)

(t) = (s)F (s, t)

where the second equation is the vector version of the first equation, and the matrix F (s, t)
has element i, j equal to Pr X(t) = j, e[s,t) | X(s) = i .
If there is no evidence in [s, t), F (s, t) = eQ(ts) . Thus, we can propagate the distribution
from one evidence time point to the next with the matrix exponential. To propagate across
evidence times, we define

+ (t) = Pr X(t), e[t0 ,t]
(40)
to be the same as (t), but including evidence at t. If there is no evidence at t, the two
vectors are the same. If there is evidence at t, then + (t) is the same as (t), except that
each element is multiplied by the probability of the evidence at that time point.
If we let O (i) be a diagonal matrix in which diagonal element j is Pr(ei | X(ti ) = j),
then the recurrence for  can be written as
(t0 ) = + (t0 ) = given

(41)

+

(ti ) =  (ti1 )e

Q(ti ti1 )

+ (ti ) = (ti )O (i)
+

(t) =  (ti )e

Q(tti )

0<ik

(42)

0<ik

(43)

 ti < t  ti+1 or ti < t, i = k

(44)

Equation 42 is a special case of Equation 44. It propagates from just after one evidence
time until just before the next. Equation 43 propagates across an evidence point.
737

fiShelton & Ciardo

Equation 44 can be used to construct the filtered estimate at any non-evidence time by
normalizing (t) to sum to 1 (dividing by the probability of the evidence prior to t).
Finally, note that a similar set of recurrences can be derived for F (, ). The result allows
for the propagation of any distribution across time intervals which includes evidence; that
is, we are not restricted to any particular initial condition, (t0 ). However, if only a single
 is to be propagated, computing F first is more computationally expensive.
2.5.1 More Complex Evidence
The above filtering equations are just an inhomogeneous hidden Markov model (that is, the
transition matrix is not constant) and familiar to those who have employed hidden Markov
models. However, with continuous time, there are evidence patterns that do not have
direct corresponding analogies in discrete-time. If the evidence consists of a finite number
of observations, we can convert it into a similar form, by breaking time into intervals of
constant evidence.
For instance, we might observe that the system is in a subset of states for a duration
of time: During this time interval, the system does not leave the subset, but we do not
observe whether there are any transitions within the subset. We can augment our evidence
to include this information. For each interval [ti1 , ti ), we let Si denote the subset of states
in which the evidence constrains the system. If there are no such constraints, Si is the full
state space. For time points at which there is a change in Si , but no point evidence, O (i)
is the identity matrix (inducing no change in the filtering estimate). Both Si and O (i) may
be non-trivial for the same i.
Now to propagate from ti1 to ti , we must use a modified intensity matrix. In particular,
we set to zero any rate which is inconsistent with the evidence Si : all rates to, from, or
within the set of states that are not in Si . Let Q(i) denote such a matrix. If the rows
and columns are permuted such that the states in Si are in the upper left corner, then this
matrix has the form
Q

(i)



QSi
=
0


0
0

(45)

where QSi is the submatrix of Q of the rows and columns corresponding to Si . Additionally,
we modify O (i1) , setting to 0 any diagonal elements corresponding to states not in Si .
Note that Q(i) is not (strictly) an intensity matrix: its rows do not sum to 0. In
general, a diagonal element is greater (in absolute value) than the sum of the other row
elements because we have set to zero non-diagonal rates. This missing rate corresponds to
the probability of leaving the evidence set (and therefore not conforming to the evidence).
While eQ(ti ti1 ) is a stochastic matrix representing the conditional distribution at time ti
(i)
given the state at time ti1 , eQ (ti ti1 ) is a substochastic matrix (the row sums are less
than or equal to 1), where the sum of each row is the probability of the evidence over the
interval, given the state at time ti1 .
738

fiTutorial on Structured Continuous-Time Markov Processes

The new filtering recurrence is
(t0 ) = given

(46)
(i)

(ti ) = + (ti1 )eQ
+

 (ti ) = (ti )O

(ti ti1 )

(i)

(t) = + (ti )eQ

(i+1)

(tti )

0<ik

(47)

0<ik

(48)

 ti < t  ti+1 or ti < t, i = k .

(49)

We might also observe a transition at an exact time point. More generally, at time ti we
might observe that a transition occurred from one state of the set Ui to one state of the set
Ui+ (without knowing exactly which states within the sets). In this case, elements of (t)
have the probabilities of a duration lasting until at least t, and + (t) should have the probability density of a duration lasting exactly until t. The difference between the probability
of the tail of an exponential and the density at the same point is just a multiplication by
the relevant rate q. Thus, for this type of evidence, we can just modify O (i) . In particular,
(
qj,k if j  Ui , k  Ui+ , and j 6= k
(i)
O j,k =
.
(50)
0
otherwise
The recurrence remains the same, with the new definition of O (i) . Other evidence types
are also possible and can be derived from the above types by augmenting the state space.
2.5.2 Smoothing

Smoothing is the problem of calculating Pr X(t) | e[t0 ,tk ] for t0  t  tk . As common with
Markov processes, we note that



Pr X(t) | e[t0 ,tk ]  Pr X(t) | e[t0 ,t) Pr e[t,tk ] | X(t)
(51)
where the constant of proportionality can be found by noting that the sum of Equation 51
over the value of X(t) must equal 1. The first term on the right is calculated with the
() recurrence above. The second term we calculate with a backward message recurrence.
Define

i (t) = Pr e[t,tk ] | X(t) = i
(52)

+
i (t) = Pr e(t,tk ] | X(t) = i
(53)
If we let  be a column vector, then the backward recurrence is analogous the forward one,
but with right multiplication instead of left multiplication:
 + (tk ) = 1
(ti ) = O

(i)

+

 (ti )

(i)

(ti ti1 )

(i)

(ti t)

 + (ti1 ) = eQ

(t) = eQ

(ti )

(ti )

vector of 1s

(54)

0<ik

(55)

0<ik

(56)

 ti1  t < ti .

(57)

For any time t, the vector of the distribution of the state of the system at t given all the
evidence is
p(X(t) | e[t0 ,tk ] )  (t) fi (t)
(58)
where fi is the Hadamard (point-wise) product.
739

fiShelton & Ciardo

2.6 Parameter Estimation from Incomplete Evidence
Section 2.4.1 demonstrated that a CTMP is a member of an exponential family with sufficient statistics T [i] (the amount of time spent in state i) and N [i, j] (the number of
transitions from i to j). If the evidence trajectories are fully observed over a continuous
interval of time, then these sufficient statistics can be trivially tallied. Further, if each
evidence trajectory is observed at t = 0, the sufficient statistics for the initial distribution
are also directly observed.
However, if portions of the interval are hidden, or more generally the observations are
of the form of the previous section, direct likelihood maximization is not feasible. There
are two basic approaches for maximum likelihood estimation in this case: gradient ascent
and expectation maximization (EM).
For gradient ascent, we can replace the sufficient statistics in Equation 31 with their
expected values The standard argument for exponential models applies: Let Tr be a partially
observed trajectory and let h stand for any potential completion of it.
ln p(Tr) = ln

X

eln p(Tr,h)

(59)

h

 ln p(Tr)
1 X
 ln p(Tr, h)
=
p(Tr, h)
qi,j
p(Tr)
qi,j
h


N [i, j]
= Eh|Tr
 T [i]
qi,j


N [i, j]
=
 T [i]
qi,j

(60)
(61)
(62)

where N [i, j] and T [i] are the expected values of N [i, j] and T [i] with respect to completions
of Tr. For EM, we similarly replace N [i, j] and T [i] in Equation 32 with N [i, j] and T [i].
We are therefore left with the problem of computing the expected values of N [i, j] and T [i].
Full derivations are shown in the work of Nodelman et al. (2003). A quick version for
T [i] is
Z

tk

T [i] =
t0

=

p(X(t) = i | e[t0 ,tk ] ) dt

1
p(Tr)

Z

(63)

tk

i (t)i (t) dt .

(64)

t0

The expected value of N [i, j] has a similar form:
qi,j
N [i, j] =
p(Tr)

Z

tk

i (t)j (t) dt +
t0

X i (tl )O (l) i,j j+ (tl )
P
(l)
i0 ,j 0 O i0 ,j 0
lTrans

(65)

where Trans is the set of evidence indices at which time a transition was (perhaps partially)
observed: The first term handles unobserved transitions and the second handles (partially)
observed transitions.
740

fiTutorial on Structured Continuous-Time Markov Processes

If we let i,j be a matrix of all zeros, except for a single one in location (i, j), the
integrals in both Equation 64 and Equation 65 have the form
Z

tk

i (t)j (t) dt =
t0

=

k Z
X

tl

l=1 tl1
k Z tl
X
l=1

i (t)j (t) dt
(i)

+ (tl1 )eQ

(66)
(ttl1 )

(i)

i,j eQ

(tl t)

(tl ) dt .

(67)

tl1

Thus, after a forward and backward pass to calculate + (i) and (i) at each evidence
change point i, each integral is relatively simple. They can be solved by standard quadrature
methods or by the solution of a differential equation (Asmussen, Nerman, & Olsson, 1996).
Alternatively, the calculation of  and  usually results in values for each at various time
points, which can be interpolated to full functions and used to directly solve the integrals.

3. Kronecker Algebra Representations
When the number of states is no more than a few thousand, the above methods are computationally feasible on a modern computer. However, most models are described in terms of
assignments to variables. Thus the number of states grows exponentially with the number
of variables. For more than a few tens of variables, we must seek more compact representations.
For the remainder of this paper, we will consider the state space of the process X to
be an assignment to L variables, {X1 , X2 , . . . , XL }. We Q
let variable Xi have ni possible
assignments. Thus, the total state space is of size n = L
i=1 nl . We let a bold x stand
for a state (joint assignment to all L variables), with component xi being the assignment
to variable i in state x. Such a state space is often referred to as factored or structured or
variable-based.
Kronecker products and sums are natural basic operations from which to build compact representations of the process intensities. In some cases, these compact representations
naturally describe the transition rates, but do not as naturally describe the diagonal elements of Q (the negative rates of leaving each state). Thus, we will define R to be the same
as Q, except with zeros at each diagonal position. The diagonals can be reconstructed from
the non-diagonal elements in the same row, so the information content is the same.
3.1 Kronecker Product
The first basic operation is the Kronecker product. Given matrices A(1) , A(2) , . . . , A(K)
where A(k) is of general size mk -by-nk , the Kronecker product is written
A=

K
O

A(k)

(68)

k=1

Q
Q
where A (the result) is an m-by-n matrix: m = k mk and n = k nk . The elements of A
represent all possible multiplications of one element from each of A(1) , A(2) , . . . , A(K) . Let
Mk = {1, 2, . . . , mk } and Nk = {1, 2, . . . , nk }, that is the valid indices into matrix A(k) .
741

fiShelton & Ciardo

"
Given A =

a00 a01



#

a10 a11


a00 b00

a00 b10


 
a00 b20
a Ba01 B 
A  B = 00
=
a10 Ba11 B 
a10 b00

a b
 10 10
a10 b20

b00 b01 b02





and B =  b10 b11 b12 
b20 b21 b22
a00 b01 a00 b02 a01 b00 a01 b01 a01 b02




a00 b11 a00 b12 a01 b10 a01 b11 a01 b12 


a00 b21 a00 b22 a01 b20 a01 b21 a01 b22 


a10 b01 a10 b02 a11 b00 a11 b01 a11 b02 

a10 b11 a10 b12 a11 b10 a11 b11 a11 b12 

a10 b21 a10 b22 a11 b20 a11 b21 a11 b22

Figure 7: Example Kronecker product
Then, let Ir be a mapping from M1 M2   MK to {1, 2, . . . , m} and let Ic be similarly
defined as a mapping from N1  N2      NK to {1, 2, . . . , n}. It does not matter usually
what the mappings are, but by convention we take them to be lexicographic
orderings (or
P
i
m
mixed-base
numbering
index).
For
instance
I
(i
,
i
,
.
.
.
,
i
)
=
r
1
2
K
k
1:k1 where
1kK
Q
ma:b = akb mk . Then
AIr (i1 ,i2 ,...,iK ),Ic (j1 ,j2 ,...,jK ) =

K
Y

A(k) ik ,jk .

(69)

k=1

While the notation makes it appear complex, the concept is simple. Figure 7 demonstrates
a simple example. In terms of sparsity (one measure of structure), the Kronecker product
has a number of non-zero elements equal to the product of the number of non-zero elements
in each input matrix.
A Kronecker product is analogous to a factor product (in Bayesian network terminology)
if we treat each operand matrix as a factor over two different variables (and no matrices
share the same variables), and the result matrix is a factor in which half of the variables
are flattened into the column dimension and the other half are flattened into the row
dimension.
In terms of distributions, the Kronecker product represents independence. Given two
variables X1 and X2 with marginal distributions represented by the vectors v 1 and v 2 ,
v 1  v 2 is a joint distribution over both X1 and X2 . In particular, it is the independent
joint distribution with marginals v 1 and v 2 .
In terms of a rate matrix, the Kronecker product represents synchronization (Plateau,
1985). If we have two variables, X1 and X2 with rate2 matrices R1 and R2 , R1  R2
is a rate matrix over the state space X = X1  X2 (joint assignments to X1 and X2 ). It
represents a rate matrix in which changes in the state of X1 must occur at the same time
as those in the state of X2 (both variables will be changed by every transition).
2. This does not hold generally for intensity matrices, as the Kronecker product does not do anything
sensible with the diagonal elements.

742

fiTutorial on Structured Continuous-Time Markov Processes

A  B = A  I3 + I2  B =

 
a0,0
a0,1
b0,0 b0,1 b0,2

  b1,0 b1,1 b1,2
a
a
0,0
0,1

 

  b2,0 b2,1 b2,2
a
a
0,1
0,0

+
a1,0
 
a1,1
b0,0 b0,1 b0,2

 

 
a1,0
a1,1
b1,0 b1,1 b1,2
a1,0
a1,1
b2,0 b2,1 b2,2













=




a0,0+b0,0
b0,1
b0,2
a0,1
a0,1
b1,0
a0,0+b1,1
b1,2
b2,0
b2,1
a0,0+b2,2
a0,1
a1,0
a1,1+b0,0
b0,1
b0,2
a1,0
b1,0
a1,1+b1,1
b1,2
b2,0
b2,1
a1,1+b2,2
a1,0










Figure 8: Example Kronecker sum, given same matrices A and B as in Figure 7. Zeros are
omitted. Note that the non-zero off-diagonal entries all correspond to only one
of the two indices (into A or B) changing.

3.2 Kronecker Sum
The other Kronecker operation is the Kronecker sum. It is only defined on square matrices.
Given square matrices A(1) , A(2) , . . . , A(K) where A(k) has size nk -by-nk , the Kronecker
sum is defined in terms of the Kronecker product:
A=

K
M
k=1

A

(k)

=

K
X

I n1  I n2  . . . I nk1  A(k)  I nk+1      I nK

(70)

k=1

where I n is the identity matrix of size n-by-n. The Kronecker sum has the same size as
the Kronecker product of the same matrices and we can use the same indexing function
to reference elements in the sum, but we need only one because the matrix is square, thus
Ir = Ic = I:
PK
(k)

 k=1 A ik ,ik if il = jl for all l
AI(i1 ,i2 ,...,iK ),I(j1 ,j2 ,...,jK ) = A(k) ik ,jk
(71)
if il = jl for all l except l = k


0
otherwise.
Figure 8 demonstrates a simple example.
In terms of a CTMP, the Kronecker sum represents asynchronicity. Given two variables,
X1 and X2 with intensity3 matrices Q1 and Q2 , Q1 Q2 is an intensity matrix over the joint
state space in which each processs events proceed irrespective of the others state. That
is, the processes are independent (assuming their starting distributions are independent).
3. The same holds for rate matrices, but we can be stronger here than for the Kronecker product and make
this statement about the intensity matrices too.

743

fiShelton & Ciardo

Note that the intensity of any transition that involves two or more variables is zero (at any
instant, a maximum of one variable can change).
3.3 Properties
The Kronecker product obeys the classic distributive property:
(A + B)  C = A  C + B  C
The mixed product property provides a relationship between the Kronecker product and
the matrix product. Given matrices A, B, C, D and assuming that AC and BD are valid
matrix products,
(A  B)(C  D) = (AC)  (BD) .
(72)
One consequence is that the Kronecker product can be expressed as
K
O

A(k) =

k=1

=

K
Y
k=1
K
Y

I n1  I n2      I nk1  A(k)  I nk+1      I nK

(73)

I n1:k1  A(k)  I nk+1:K

(74)

k=1

where na:b is the product of the terms na through nb as defined above. This shows a
bit of the relationship between Kronecker products and sums: Compare Equation 70 and
Equation 73.
This can be further reworked as
K
O
i=k

(k)

A

=

K
Y

P n1:k ,nk+1:K >  (I nk  A(k) )  P n1:k ,nk+1:K

(75)

i=k

where nk = n1:K /nk and P a,b is the matrix describing an a,b-perfect shuffle permutation of
(0, ..., ab  1): its entry in position (i, j) is 1 if j = (i mod a)  b + bi/ac, and 0 otherwise (in
particular, P a,b = P a,b = I ab if a or b is 1). Whereas Equation 74 orders the Kronecker
products of the outer products terms so that the elements of Ak are in the correct places,
Equation 75 repeats Ak on the diagonal and then permutes the rows and columns to place
the elements in the correct locations. A similar transformation can be used to rewrite
Equation 70 as a sum of shuffled block-diagonal matrices. Because the permutations can
often be done implicitly in code, these versions can be useful in deriving algorithms.
3.4 Compact Kronecker Representations
Given a factored state space as before, any joint rate matrix R can be expressed as a sum
of Kronecker products:
E O
L
X
(l)
R=
Re
(76)
e=1 l=1
(l)
Re

where there are L variables and
is a rate matrix over the space of variable l only. In
particular, an exponentially sized (in the number of variables) representation is straightforward: e ranges over the elements in the resulting matrix. For element corresponding to
744

fiTutorial on Structured Continuous-Time Markov Processes

(l)

(x1 , x2 , . . . , xL ), (x01 , x02 , . . . , x0L ), Re = xl ,x0l for 1 < l  L and the same for l = 1, except
multiplied by the scalar value to be placed in this location. In this way each term in the
sum is a matrix with at most a single non-zero element. However, for many processes we
can expect E to be a manageable number. For instance, if the variables are all independent,
E = L (and all but L of the L2 rate components are identity matrices), as per the Kronecker
sum above.
We can view each of the E terms in the sum as separate events whose identities have
been marginalized out to produce the resulting process (see Section 2.1.3). These events
must couple variables synchronously (due to the Kronecker product). We exploit this type
of decomposition more extensively in the next sections.

4. Decision Diagram Representations
While the encoding in Equation 76 can be efficient, we can do better by exploiting more
internal structure. R can be viewed as a mapping from two discrete domains (the row index
and the column index) to a real value. Decision diagrams have long been used in computer
science to compactly encode functions over discrete domains. Here we show how they have
been used in CTMPs and how they can be seen as an alternative to Kronecker algebra
encodings, in the case of the MTBDDs used in PRISM (Kwiatkowska, Norman, & Parker,
2011), or even as an extension of Kronecker algebra encodings, in the case of the Matrix
Diagrams used in Mobius (Deavours, Clark, Courtney, Daly, Derisavi, Doyle, Sanders, &
Webster, 2002) or the EVMDDs used in SMART (Ciardo, Jones, Miner, & Siminiceanu,
2006).
4.1 Decision Diagram Overview
Decision diagrams encode functions of the form f : X  X0 where, as before, the domain
state space X is structured: X = X1      XL . In other words, f is applied to a (state)
tuple and evaluates to an element of a range set X0 . One can then think of f as the encoding
of a vector indexed by X and having entries with values in X0 . Of course, the same idea can
be employed to encode matrices, we simply need to use the domain X  X. (In practice, we
actually use the interleaved domain X10  X1      XL0  XL , where the unprimed state
variables refer to row indices, or from states, while the primed state variable refer to
column indices, or to states, as this usually leads to more compact decision diagrams.)
Binary decision diagrams, or BDDs (Bryant, 1986), encode functions for which all sets
forming the domain X are binary, while multiway decision diagrams, or MDDs (Kam, Villa,
Brayton, & Sangiovanni-Vincentelli, 1998), allow non-binary domain sets. However, for both
the range X0 is binary. For our numeric application, we need to extend such representations
to allow the range X0 to be either the integers Z (possibly augmented with the value  to
indicate undefined) or the reals R (possibly, again, augmented with , or restricted to
the nonnegative reals R0 ). The range Z is used primarily to encode indexing functions for
non-consecutive sets of states. The range R is used to encode the rates themselves.
Informally, decision diagrams are directed acyclic graphs organized in layers with each
layer corresponding to a different variable in the domain of the function. The outgoing
edges from a node correspond to the values the variable on that layer can take on. The
745

fiShelton & Ciardo

value of the function is determined by following the path from the root corresponding to the
values taken by the domain variables. The path ends in a terminal node which, in BDDs
and MDDs, give the value of the function.
A first proposal to encode non-binary function was to extend BDDs and MDDs so that,
instead of the terminals 0 and 1, any element of X0 can be a terminal node. The resulting multi-terminal (Clarke, Fujita, McGeer, Yang, & Zhao, 1993) BDDs (or MTMDDs)
are quite general. However, as we will see, MTMDDs are sometimes unable to compactly
encode even simple functions. We therefore focus on a newer class of edge-valued decision diagrams, which can be exponentially more compact, and provably never larger, than
MTMDDs (Roux & Siminiceanu, 2010). For edge-valued decision diagrams, a value is associated with each edge in the tree, and the functions value is determined from the values
along the path to the terminal node. The exact definition of these diagrams depends on
the operator used to combine edge values. We consider two cases, EV+MDDs (Ciardo &
Siminiceanu, 2002) (where X0 is either Z  {} or R  {} and edge values along a path
are summed) and EVMDDs (Wan, Ciardo, & Miner, 2011) (where X0 is R0 and edge
values along a path are multiplied).
4.2 Multiterminal and Edge-Valued Decision Diagrams
Formally, both an EV+MDD and an EVMDD are acyclic directed edge-labeled and edgevalued graphs. A node in the graph p has a level p.lvl and a set of directed edges indexed
by x. The edge associated with label x is written as p[x] = hp[x].val,p[x].chi, where p[x].val
is the value associated with the edge and p[x].ch is the target of the edge.
 The only terminal node (one without outgoing edges) is , at level 0: .lvl = 0.
 A nonterminal node p is at level k  {1, . . . , L}: p.lvl = k. For each xk  Xk , it has
an outgoing edge labeled xk , associated with a value v  X0 , and pointing to a node
q with q.lvl < k. Thus p[xk ] = hv,qi.
 A node p at level k encodes the function fp : X1      Xk  X0 . For EV+MDDs,
fp is defined recursively as fp = 0 if p = , and fp (x1 , . . . , xk ) = p[xk ].val +
fp[xk ].ch (x1 , . . . , xp[xk ].ch.lvl ) otherwise (that is, if p is a nonterminal node).
For EVMDDs, fp is defined recursively as fp = 1 if p = , and fp (x1 , . . . , xk ) =
p[xk ].val  fp[xk ].ch (x1 , . . . , xp[xk ].ch.lvl ) otherwise.
Most decision diagram definitions have additional restrictions to ensure canonicity, that
is so that any representable function has a unique representation. For the edge-valued
decision diagrams we have defined, this is achieved by additionally requiring all of the
following.
 There are no duplicate nodes: if p.lvl = q.lvl = k and, for each xk  Xk , we have
p[xk ] = q[xk ], then p = q.
 The absorbing value terminates a path: for EV+MDDs, p[xk ].val =  implies that
p[xk ].ch = ; for EVMDDs, p[xk ].val = 0 implies that p[xk ].ch = .
 Each node p at level k > 0 is normalized : for EV+MDDs, min{p[xk ].val : xk  Xk } =
0; for EVMDDs, max{p[xk ].val : xk  Xk } = 1.
746

fiTutorial on Structured Continuous-Time Markov Processes

MDD X

EV+MDD X

MTMDD X

EV+MDD Y

MTMDD Y

MDD Y

0
x3

x2

x1

0

1

0

0

1

0

1

1

0

0

0

1

1

1

1

0

2

0

1

3

0

4

1

5

1

0

6

1

7

0

1

0

4

0

1

0

2

0

1

0

1

0
0

x3

0

x2

x1

0

1

1



0

1

0

0

0

1

1

1

0

0

1

0



1

1

0

0

1

0

1

1

0

2

1

1

0

3

1

4

0

1

0

2

0

1

0

1

0

1

0

2

0 1
 0

0

1

0

1

0 1
0 



Figure 9: Encoding the lexicographic index function, X , for set X. The left panel shows
the quasi-reduced MDD encoding X followed by the MTMDD and the EV+MDD
encoding X ; the right panel shows the corresponding encodings for the set Y =
{100, 110, 001, 101, 011}. In either case, the EV+MDD is isomorphic to the MDD.
Each level of the tree corresponds to a different variable. Black boxes are the
values of this variable (and traversal of the diagram follows the edge leading out
of this box for the value of input). White boxes (for EV+MDD) are the values
of the corresponding edge (which are summed to produce the functions value).
The 0 at the top of the EV+MDD is the value added to any path or traversal of
the diagram.

Furthermore, we require that one of the following two reduction forms must be used.
 In quasi-reduced form, only nodes at level L have no incoming edges (except the special
case of the graph consisting of just ) and the children of a node at level k are at
level k  1 (except for absorbing-valued edges, which point to , as stated above).
 In fully-reduced form, there are no redundant nodes, where a node p at level k is
redundant if p[xk ] = p[yk ] for all xk , yk  Xk .
Strictly speaking, an EV+MDD node encodes a function with values between 0 (included) and  (possibly included); thus, a function f with range Z  {} or R  {} is
encoded by h,pi where  = min{f (i) : i  X} and fp = f   (the special case f  
is encoded by the pair h,i). Analogously, an EVMDD node encodes a function with
values between 0 (possibly included) and 1 (included); thus a function f with range R0 is
encoded by h,pi where  = max{f (i) : i  X} and fp = f / (the special case f  0 is
encoded by the pair h0,i). In the following, we use the term EV+MDD or EVMDD also
for the pair h,pi, with the understanding that  is just a parameter that scales the values
of the function encoded by node p.
4.3 Lexicographic Index Example
We illustrate the compactness of these decision diagrams using the lexicographic
index, also
P
called the mixed-base value, of a state x = (x1 , . . . , xL ), defined as (x) = 1kL xk n1:k1 ,
747

fiShelton & Ciardo

where na:b = na    nb for a  b (as in Section 3.1). We discuss the importance of this
function after showing its encoding.
Figure 9 (left) shows the lexicographic index function  (along side the MDD encoding
the set of states). The MTMDD for  is a full L-level tree with n1:L leaves. By contrast,
the EV+MDD for  contains just one node at each level, where the child labeled xk of the
node at level k points to the node at level k  1 and has value xk  n1:k1 .
Interestingly, this function retains a compact encoding even if we modify it so that
it applies to a set Y  X, that is Y (x) = |{y  Y : (y) < (x)}| if x  Y , and
Y (x) =  otherwise, in the sense that the MDD encoding Y and the EV+MDD encoding
Y are isomorphic (right panel in Figure 9). This is of particular importance for the exact
numerical solution of structured CTMPs whose reachable state space Xrch is a strict (and
possibly complicated) subset of X, since in this case we need to frequently and efficiently
map a state x = (x1 , . . . , xL ) to its index Xrch (x) in a full probability vector of size |Xrch |.
Compactly representing this index function is key to efficient calculations in such CTMPs.
Obviously, EVMDDs can also be exponentially more compact than MTMDDs; simply
consider that the EVMDD encoding of e also has one node per level, where the child
with label xk of the node at level k has value exk n1:k1 .
4.4 Decision Diagram Operations
In addition to efficiently encoding structured functions, decision diagrams are also able
to efficiently manipulate functions. All decision diagram operations proceed recursively
from the root node(s) and make extensive use of dynamic programming. Specifically, they
use an operation cache to retrieve the result of a specific operation on a specific choice of
parameters, if this result has been previously computed when exploring different paths in the
recursion. This reduces the worst-case complexity of an operation (for example, computing
c = a + b, where a and b are functions encoded by two EVMDDs) from exponential (i.e.,
the size of the domain) to polynomial. For example, Figure 10 shows the pseudocode for
an algorithm to perform the element-wise addition of two EVMDDs, that is when ,   0
and a, b are EVMDD nodes at level L (unless  = 0, in which case a = , or  = 0,
in which case b = ), Sum(L, h,ai, h,bi) returns an EVMDD h,ri such that, for all
x = (x1 , . . . , xL )  X, we have   fr (x) =   fa (x) +   fb (x); of course, the input
EVMDDs are assumed to be in canonical form, and the output EVMDD is guaranteed
to be in the same canonical form. Its complexity is the product of the sizes of the input
EVMDDs.
In a practical implementation, the unique table, which stores nodes and avoids duplicates, is implemented as a lossless hash table which, given a lookup key hlevel, r[0], . . . , r[nk 
1]i, returns a nodes address, while the cache is implemented as a (possibly) lossy hash table. The cache can be made more effective by scaling and exploiting commutativity. For
example, by defining an arbitrary order on nodes (for example, a  b if the memory address
of a is smaller than that of b), we can exchange the two input EVMDDs to ensure that
a  b prior to cache lookup, and then observe that fa + fb = (fa + fb ), for  = /,
so that we just store entries of the form hSU M , a, , b  , ri in the cache. Then, assuming
p  q, the call Sum(k, h0.5,pi, h0.2,qi) would be cached as hSU M , p, 0.4, q  , s, i and
748

fiTutorial on Structured Continuous-Time Markov Processes

function Sum(level k, EVMDDh,ai, EVMDDh,bi)
if a = b then return h + ,ai . This includes the terminal case k = 0: a = b = 
if  = 0 then return h,bi
. a =  by definition
if  = 0 then return h,ai
. b =  by definition
if cache contains hSU M , , a, , b  , ri then return h,ri . Check if result is in
the cache
r  NewNode(k)
. Create new temporary result node at level k
for all xk  Xk do
r[xk ]  Sum(k  1,h  a[xk ].val,a[xk ].chi,h  b[xk ].val,b[xk ].chi) . Recurse down
one level
  maxxk Xk {r[xk ].val}; . Maximum edge value for node r before normalization
for all xk  xk do
r[xk ].val  r[xk ].val/ . Normalize node r so that the maximum edge value is 1
r  UniqueTableInsert(r);
. If node like r exists, return it and delete r, else
return r
Enter hSU M , , a, , b  , ri in cache;
. Remember the result in the operation
cache
return h,ri;
Figure 10: Pseudo-code for sum of quasi-reduced EVMDDs (a and b are either  or nodes
at level k). The fully-reduced version is similar but slightly more involved, as it
needs to take into account the levels of a and b.

return h0.5,si, while a subsequent call Sum(k, h0.25,pi, h0.1,qi) or Sum(k, h0.1,qi, h0.25,pi)
would find hSU M , p, 0.4, q  , s, i in the cache and immediately return h0.25,si.
4.5 Encoding Transition Rate Matrices with EVMDDs
We now turn to the use of EVMDDs to compactly encode the transition rate matrix R
(the same as the intensity matrix Q, but without the diagonal) of a CTMP. This can be
accomplished using various approaches.
4.5.1 Monolithic Encoding vs. Disjunctive Partition Encoding
Clearly, a node r of a 2L-level EVMDD can encode an arbitrary function of the form
X  X  [0, 1]. Then, for   0, the pair h,ri encodes an arbitrary function of the
form X  X  [0, ], where EVMDD levels (1, . . . , 2L) correspond to state variables
(x01 , x1 , . . . , x0L , xL ), that is, we use an interleaved order to describe the transition rate from
x to x0 . With a monolithic approach, we can then store R using a single EVMDD h,ri
where  is the largest rate in R and r encodes matrix R/.
However, many practical systems exhibit asynchronous behavior, that is each state
change is due to some event e  E occurring (asynchronously) somewhere in the system.
In these situations, we can employ a disjunctive partition to encode R, storing a set of
EVMDDs {he ,re i : e  E}, so that he ,re i encodes matrix Re , where Re (x, x0 ) describes
the rate at which the system moves from state x to state x0 due to the occurrence of event e.
749

fiShelton & Ciardo

P
With this disjunctive partition encoding, R = eE Re does not have to be built explicitly;
rather, the individual matrices Re are directly used in the numerical computations used to
solve the CTMP. The idea of a disjunctive partition was initially suggested for BDDs (Burch,
Clarke, & Long, 1991), although it is obviously also related to Kronecker encodings: consider
Equation 76, which expresses R first and foremost as a sum.
The choice between a monolithic or a disjunctive partition encoding is largely modeldependent. In most applications, the high-level language description of the model suggests
what the set of asynchronous events E should be. Thus, we first build the EVMDDs for the
disjuncts Re then, if desired, we can explicitly build the EVMDD for R by summing the
EVMDDs for the disjunct corresponding to each event (using the algorithm in Figure 10,
for instance).
However, while the disjunct EVMDDs are usually quite compact, the EVMDD for
R obtained by summing the disjuncts Re might still be very compact, or it might grow
very large. In the former case, the monolithic approach is preferable, as it allows us to
directly use the EVMDD encoding R in the numerical iterations. In the latter case, the
disjunctive partition approach is preferable, as it allows us to use the EVMDD for each Re
individually, without even attempting to build the monolithic EVMDD encoding R.
For example, consider a simple system of four Boolean variables, X1 , X2 , X3 , and
X4 , and two events. The first event, c21 , changes the value of (X2 , X1 ), interpreted as
a 2-bit integer, in the sequence 0 [1] 1 [1/2] 2 [1/4] 3 [1/8] 0 [1]    , where the
numbers in the square brackets indicate the rate of the corresponding transition. The second
event, c43 , changes the value of (X4 , X3 ), interpreted as a 2-bit integer, in the sequence
0 [3] 1 [1] 2 [1/3] 3 [1/9] 0 [3]    . Figure 11 on the left shows the EVMDDs
encoding the matrices R21 and R43 corresponding to these two events, as well as the matrix
R = R21 + R43 . (for visual simplicity, edges with value 0, which by definition point to the
terminal node , are not shown).
4.5.2 Adopting Ideas from Kronecker Encodings: Identity Patterns
Neither the monolithic approach nor the disjunctive partition approach exploit locality: the
fact that most events (synchronously) affect only a few state variables. In other words,
while each matrix Re is conceptually of size |X|  |X|, it usually has a much smaller
support Se  {x1 , . . . , xL }. Specifically, Xk  Se if and only if Xk and e are dependent: the
local state xk affects the rate at which e occurs (including the case where it may disable e
altogether, that is set its rate to 0) or is changed by the occurrence of e. When Xk 6 Se ,
Xk and e are independent and the EVMDD encoding Re contains identity patterns in
correspondence to xk . For example, the EVMDD encoding R21 in Figure 11 on the left
exhibits such patterns with respect to variables X4 and X3 , while the one for R43 exhibits
them for X2 and X1 .
Essentially, these identity patterns simply describe the fact that the value of x0k (the
new value of xk after the occurrence of e) equals the old value of Xk and that the rate is
not affected by the value of Xk , and this is true for all possible values of Xk . When this
(k)
happens, the Kronecker encoding of event e has Re = I nk , while the quasi-reduced or
the fully-reduced forms alone cannot take advantage of these common patterns. To exploit
these patterns, a combination of the fully-reduced form, for unprimed level Xk , and a new
750

fiTutorial on Structured Continuous-Time Markov Processes

R21

R43

1

x4
x04

x03

0

1

1

1 1/9

1

0

1

1 1/3

1

0

0 1
1/3 1

1

0

1

0

1

1

1

1

1 1/3

1

1

0

1

1

1

1

1

1 1/4

0

1

1 1/2

1

1

0

1 1/3

0

1

1

1

0

1

1

1

1

0

1

0

1

1

1 1/3

1

0

1

1 1/4

1

0

1

0

1/2 1

1

1

1 1/2

1

1

0

1

0

1

1

1

1

0

1

1

1

x1

0

1

0

1

0

1

0

1

1

1

1

1

1

1

1

1

x01

1

0

0

1

0

1

1

1

1

1

1

1





0

x03

x02

1

0

0

1 1/3

0

x2

1/2 1

3

1

1 1/9

x3

1

1

0

x04

1/9 1

R

3

x4

1/3 1

0

R43

1

1 1/3

0

0

0

1

0

x2
x02

0

1

1

x3

3

0

0

R21

R

3

1

0

1/3 1

1

0

1

1

1 1/3

1

0
1

1

0

0

1

1

0

1

1

1

1

1

1

0

0

1/3 1

1

1 1/3

1

0

1 1/4

0

1

0

1 1/2

1

1/9 1

1 1/3

0

1

1

1 1/3

1

1 1/4

1

0

1/2 1

1

1 1/2

0

x1

0

1

0

1

1

1

1

1

x01

1

0

1

0

1

1

1

1







1

1/2 1



Figure 11: An example of EVMDDs encoding transition rate matrices using the quasireduced form (left) or the fully-identity-reduced form (right). Omitted edges
have implied value 0 (thus resulting in value 0 for any path containing them).
The right diagrams are the same as those on the left, except that identity patterns have been omitted and are implied: Any completely skipped pair of levels
is assumed to have an identity structure (compare to corresponding diagram on
the left).

identity-reduced form (Ciardo & Yu, 2005) for primed level Xk0 , is needed. This allows
us to encode Re in an EVMDD which has nodes only at (unprimed and primed) levels
corresponding to state variables in Se . A further advantage of this fully-identity-reduced
form is that the resulting decision diagrams, unlike a Kronecker encoding, also recognize
and exploit partial identity patterns (those arising in models where Xk remains unchanged
after e occurs in certain states but not in others). Figure 11 on the right shows the encoding
of the same matrices R21 , R43 , and R, but using this new fully-identity-reduced form.
4.5.3 Beyond Kronecker: Disjunctive-then-Conjunctive Partition Encoding
We can push the decomposition further by employing a disjunctive-then-conjunctive partition approach. This idea was first introduced for logic analysis (Ciardo & Yu, 2005) but
it is also related to Equation 76, which expresses R as a sum of products. This is particularly appropriate for globally-asynchronous locally-synchronous systems, where not only
each state change is due to an (asynchronous) event e  E, but the occurrence of e de751

fiShelton & Ciardo

pends on and (synchronously) changes only a few state variables. Each Re is then further
Q
(c)
decomposed into the product of m matrices, Re = 1cm Re and, again, each matrix
(c)

(c)

Re is conceptually of size |X|  |X| but, in practice, it usually has a small support Se .
(c)
(c)
Specifically, Xk  Se if and only if the fully-identity-reduced EVMDD for Re contains
0
a node associated to Xk or Xk . We restrict ourselves to the case where the supports of
S
(c)
(c)
the conjuncts for an event are disjoint, so that 1cm Se = Se and each Se is substantially smaller than Se . For example, when a Kronecker encoding for Re exists, that is
N
(k)
(k)
(k)
Re = 1kL Re , we have Se = {Xk } for each Xk  Se , that is for each Re 6= I nk ;
in this case, a disjunctive-then-conjunctive approach that uses an EVMDD to store each
(c)
Re is as compact as the disjunctive partition approach that uses an EVMDD to store
each Re , and both are essentially just as compact as the Kronecker approach (except that
they can save additional memory by exploiting partial identity patterns).
The disjunctive-then-conjunctive approach is instead distinctly more efficient when the
Kronecker approach is not applicable (that is, when the Kronecker approach would require
an enormous set of events to correctly describe R), but it can nevertheless be seen as an
extension of the Kronecker approach. Consider using the decomposition of Equation 75:
O
Y
(k)
(k)
Re =
Re =
P n1:k ,nk+1:L >  (I nk  Re )  P n1:k ,nk+1:L
1kL

1kL

Y

=

(k)

P n1:k ,nk+1:L >  (I nk  Re )  P n1:k ,nk+1:L

Xk Se
(k)

where the last step simply stresses that, when Re = I nk , the corresponding factor is just
I n1:L and can be skipped.
This is the idea behind the Shuffle Algorithm (Fernandes, Plateau, & Stewart, 1998),
which, as observed by Buchholz, Ciardo, Donatelli, and Kemper (2000), is very efficient,
(k)
but only when the matrices Re are not too sparse. (The perfect shuffle pre- and postmultiplications are essentially free; they simply describe a different state indexing.)
Then, the disjunctive-then-conjunctive approach extends the Kronecker expression of
Re to allow situations where the factors are not restricted to a support consisting of just
one variable, but still exploits each factors locality:


Y
Re =
P S (c) >  I (c)  RS (c)  P S (c)
(77)
Se

e

1cm

e

e

where P S (c) > and P S (c) are perfect shuffle permutations that respectively move all dee

e

(c)

pendent state variables in Se at the end ofQthe variable order and back to their original
position, I (c) is the identity matrix of size X 6S (c) nh (the skipped levels), and RS (c) is
Se
e
e
h
Q
a square matrix of size X S (c) nh (the conjunct encoded by an EVMDD if we ignore the
h

e

(c)

skipped levels corresponding to state variables not in Se ).
(c)
Since the supports Se are disjoint, this generalization of the Kronecker approach comes
at no additional cost and essentially corresponds to a Kronecker approach where we allow
each event to be defined on a different set of state variables, each set corresponding to
752

fiTutorial on Structured Continuous-Time Markov Processes

a different partition of the basic state variables (X1 , .., XL ). In this case, building the
EVMDD for Re by multiplying the EVMDDs for each RS (c) does not involve any numeric
e

(c)

multiplication, but it grows the size of the diagram if the spans of the sets Se are not
(1)
(2)
disjoint; for example, if Se = {X3 , X7 } and Se = {X4 , X6 }, then each path from X7 to
X3 in the EVMDD for Re will contain a copy of the entire EVMDD encoding Re(2) .
4.5.4 Numerical Solutions with Decision Diagrams
We have described a method for storing the rate or intensity matrix compactly for common
process models. We now address the use of these data structures in CTMP computations.
The literature surrounding decision diagrams and CTMPs is primarily concerned with computation of the unconditional distribution of the resulting process, either at a finite time or
(more commonly) in the limit of infinite time (the stationary distribution). We follow the
convention of this literature and refer to this as the solution of the process. Model estimation, solutions conditioned on evidence, and computations of marginals or other statistics
are, to our knowledge, unexplored for these representations, but we return to this later.
When matrix R is stored using 2L-level EVMDDs (using a monolithic, a disjunctive
partition, or a disjunctive-then-conjunctive partition encoding), the traditional numerical
solution algorithms need to be adjusted accordingly. First of all, when seeking an exact
solution, neither the stationary vector  nor the transient vector (t) admit a compact
EVMDD representation (unless the modeled system contains extensive symmetries or is
composed of completely independent subsystems, which is rarely the case in practice).
Two approaches have been explored. For an exact solution for the stationary distribution
 (the null-space of Q), a hybrid approach (Kwiatkowska, Norman, & Parker, 2004) is
usually best, where the solution is stored as a full vector of reals having size equal to the
number of reachable states (|Xrch |, equal to |X| only if all states are reachable) while the
rate matrix R is stored with EVMDDs, and the expected holding time vector h (the inverse
absolute values of the diagonal of Q) is stored either as a full vector or with EVMDDs.
Clearly, such an approach scales the size of the tractable problems by eliminating the main
memory obstacle (the storage of R), only to encounter the next memory obstacle (the
storage of the solution vector). For example, Figure 12 shows the pseudocode for a classic
Jacobi-style stationary solution of an ergodic CTMP when the transition rate matrix is
monolithically encoded by the EVMDD h,ri, while the state space Xrch is indexed by an
EV+MDD h0,pi, as previously discussed, so that, for each i  X, we can compute Xrch (i),
an index between 0 and |Xrch |  1 included if i  Xrch , or  if i 6 Xrch . Function
Xrch is used to index entries of the solution vector:  new and  old . The holding time
vector is stored as the full vector h, also indexed by Xrch (but it could have been stored
using EVMDDs instead). At each recursive call of JacobiRecur, we descend a from
and a to level from the current rate matrix EVMDD node and a single level from the
corresponding source and destination EV+MDD nodes (these are needed to index the
full vectors of reals, and are initially both set to h0,pi, encoding the entire Xrch function).
Note that, in the simple case when all states are reachable
(that is, X = Xrch ) the indexing
P
function Xrch is just the mixed-base value (i) = 1kL ik  n1:k1 discussed in Section
4.3 and, as such, it does not really require an EV+MDD for its encoding; on the other hand,
as shown in Figure 9, this EV+MDD is just a single path of nodes, so its use does not carry
753

fiShelton & Ciardo

. Computes  such that Q = 0. h,ri is R, h0,pi is Xrch
function JacobiIteration(EVMDDh,ri,EV+MDDh0,pi)
 old  initial guess
. Real vector of size |Xrch |, visible to JacobiRecur
num iter  0
repeat
 new  zero vector
. Real vector of size |Xrch |, visible to JacobiRecur
JacobiRecur(L,h,ri,h0,pi,h0,pi)
for all i  {0, . . . , |Xrch |  1} do
 new [i]   new [i]  h[i]
. h is the holding time vector
old
new
swap( ,  )
num iter  num iter + 1
until num iter > M AX IT ER or Converged( old , new )
. for example, using a relative or absolute test
. Computes  new   old R
function
JacobiRecur(level
k,
EVMDDh,mi,
EV+MDDhsrc ,srci,
+
EV MDDhdes ,desi)
if src = des =  then
 new [des ]   new [des ] +  old [src ]  
return
for i from 0 to nk 1 s.t. m[i].val 6= 0 and src[i].val 6=  do
. from level k
for j from 0 to nk 1 s.t. m[i][j].val 6= 0 and des[j].val 6=  do . to level k 0
0
src
 src + src[i].val
0
des  des + des[j].val
 0    m[i][j].val
0 ,src[i].chi, h 0 ,des[j].chi)
JacobiRecur(k1, h 0 ,m[i][j].chi, hsrc
des
Figure 12: A Jacobi-style iteration for the stationary solution (Q = d
dt = 0) when R

(non-diagonal elements of Q) is stored as a monolithic EV MDD and h (inverse
absolute value of the diagonal elements of Q) is stored in a vector. h,ri is the
encoding of R and h0,pi is the encoding of the mapping from states to indices
(for  and h).

any overhead. A similar hybrid approach can be used to compute a transient solution using
a uniformization-style algorithm where R is also stored using EVMDDs but, again, the
size of the full vectors limits scalability.
The filtering and smoothing operations as described in Section 2.5 have not been explicitly tackled for decision-diagram encodings. However, if we are willing to represent
the distribution exactly (as above), we can do the necessary vector-matrix multiplications
directly on the decision-diagrams (without expanding them). Estimating an EVMDD representation of R from data is completely unexplored.
To tackle larger problems we must instead be willing to accept an approximate solution.
However, work in this area is mostly restricted to systems exhibiting special structures.
754

fiTutorial on Structured Continuous-Time Markov Processes

One exception is the work of Wan et al. (2011), which addresses the stationary solution of
arbitrary ergodic CTMPs whose state space is encoded as an MDD and whose transition rate
matrix is encoded as one or more EVMDDs. The approach uses L different approximate
aggregations of the exact CTMP and solves them iteratively, until reaching a fixpoint.
This approach provides an exact solution under certain conditions  essentially, if the
system has a so-called product-form (Baskett, Chandy, Muntz, & Palacios-Gomez, 1975).
Unfortunately, no similar approximation for the transient solution of a structured CTMP
has been proposed so far.
Thus for state spaces large enough that a single vector over their values cannot be
maintained, the literature for inference and estimation with these models is very limited.
However, in the next section we describe a different model that can be viewed as a restricted
form of the disjunctive EVMDD encoding of this section. This model has many inference
and estimation method and we believe this link between the two may allow for those methods
to be extended to more general decision-diagram representations.

5. Continuous-Time Bayesian Networks
In the artificial intelligence and machine learning literatures, continuous-time Bayesian networks (CTBNs) (Nodelman, Shelton, & Koller, 2002) were developed as an extension of
dynamic Bayesian networks (DBNs). As we discuss in this section, they are a more limited
case of the disjunctive EVMDD encodings above. However, approximate methods and
computations conditioned on evidence have been more extensively developed for CTBNs.
A CTBN consists of a set of variables, {X1 , X2 , . . . , XL }, a directed graph G with a oneto-one mapping between the nodes and the variables, a set of conditional intensity matrices
for each variable, and an initial distribution. The initial distribution is usually described
as a Bayesian network (to keep its description compact), but many of the algorithms and
theory hold for other compact distribution representations.
The graph G describes instantaneous influence of variables on each other. An edge from
Xi to Xj denotes that the rates of transitions of Xj depend on the instantaneous value of
Xi . Note that G may be cyclic.
These dependent rates are captured in the conditional intensity matrices. Let ni be
the number of states for variable Xi . We denote the parents of variable Xi as Pari and a
joint assignment to Pari as pari . The set of conditional intensity matrices for variable Xi
consists of one ni -by-ni intensity matrix for each possible instantiation pari : QXi |pari for
which we denote element xi , x0i as qxi ,x0i |pari , the rate of Xi transitioning from xi to x0i when
Pari have values pari .
Semantically, a CTBN is a continuous-time Markov process over the joint state space of
all constituent variables. We let (x, x0 ) be equal to the set of variables whose assignments
differ between joint assignments x and x0 . The joint intensity matrix for the entire process
can be described as

qx,x0

PL

 i=1 qxi ,x0i |pari
= qxi ,x0 |pari
i


0
755

if (x, x0 ) = {}
if (x, x0 ) = {Xi }
otherwise

(78)

fiShelton & Ciardo

1
2

1
2



4
=
3

4
3





5
6



7
8




QX1 |X2 =0 =

X1



QX1 |X2 =1

X2
X3

QX2 |X1 =0
QX2 |X1 =1

5
=
6

7
=
8



QX3 |X2 =0

9
= 8
7


QX3 |X2 =1

12
= 8
7

0
10
4
6
13
7


9
2 
11

6
5 
14

Figure 13: An example CTBN graph. See Figures 14, 15, and 17 for the same CTMP in
other representations.

where pari is the assignment to Pari in x. The intensity of transition between two states
that differ only by one variable can be read from the appropriate conditional intensity matrix
for that variable. The intensity of transition between any other two states (that differ by
more than one variable) is zero. The diagonal elements are filled in to be the negative row
sums. This process allows two variables to transition at arbitrarily close times, but not at
exactly the same time.
A CTBN retains the local Markov properties of a standard Bayesian network. In particular, a variable (local process) is independent of its non-descendants, given its parents. Of
course, because of cycles, parents may also be descendants, but this does not pose a problem
to the definition. Note, however, that given refers to conditioning on the entire trajectory
of a variable (from the starting time until the ending time, after which no variables are
queried or observed). Conditioning on the current value is not sufficient (even for rendering
only the current values independent).
The global Markov properties also hold. The Markov blanket for a variable is the union
of the sets of its parents, its children, and its childrens parents. Note that these sets can
have significant overlap, as cycles are permitted. Conditioned on its Markov blanket, a
variable is independent of all other variables.
5.1 Connections to Other Representations
A CTBN can be related to a number of other representations. For instance, Portinale and
Codetta-Raiteri (2009) link CTBNs to stochastic Petri nets (Ajmone Marsan, Balbo, Conte,
Donatelli, & Franceschinis, 1995). Donatelli (1994) shows the translation from stochastic
Petri nets to Kronecker operators and Ciardo, Zhao, and Jin (2012) show the translation
from (ordinary, timed, or stochastic) Petri nets to various classes of decision diagrams.
However, below we concentrate on more direct comparisons of the approaches presented in
this tutorial.
Figure 13 shows a simple small CTBN of two binary variables (X1 and X2 ) and one
ternary variable (X3 ). We will use this as a running example for how to convert from a
CTBN to other compact representations.
756

fiTutorial on Structured Continuous-Time Markov Processes

X10

X1

X20

X2

P (X10 |X1 , X2 ) : 0
1

0, 0
11t
1t

1, 0
2t
12t

0, 1
14t
4t

1, 1
3t
13t

P (X20 |X2 , X1 ) : 0
1

0, 0
15t
5t

1, 0
6t
16t

0, 1
17t
7t

1, 1
8t
18t

0
:
1
2

0, 0
19t
0
9t

1, 0
8t
110t
2t

X30

X3
time = t

time = t + t

P (X30 |X3 , X2 )

2, 0
7t
4t
111t

0, 1
112t
6t
6t

1, 1
8t
113t
5t

2, 1
7t
7t
114t

Figure 14: A DBN whose limit as t  0 approaches the CTBN of Figure 13.
5.1.1 Connection to DBN
From a CTBN, we can construct a dynamic Bayesian network (DBN) whose parameters are
a function of the time between slices such that its limit as this time-slice width approaches
zero is the original CTBN. In particular, the DBN has no intra-time-slice edges (this is
because two variables in the CTBN cannot change at exactly the same time). If Xi has
parents Pari in the CTBN, then it has the same parents (at the previous time slice) plus
its previous value in the DBN. Figure 14 shows the CTBN of Figure 13 as a DBN. If Xi in
the CTBN has an intensity matrix QXi |pari for parent values pari , then the corresponding
variable in the DBN has the conditional probability distribution
pDBN (x0i |xi , pari ) = x0i ,xi + t qxi ,x0i |pari

(79)

where x0i is the value of Xi at the next time step (and xi and pari are the values at the
previous time step), x0i ,xi is 1 if x0i = xi and 0 otherwise, and t is the time between time
slices. The limit of this process as t approaches 0 is the original CTBN.
5.1.2 Connection to Kronecker Algebra
The joint intensity matrix expressed in Equation 78 can also be written as a sum of Kronecker products. We need first to define a conceptually simple, but notationally cumbersome, term. First, let i,j be a matrix of all 0, except for a single 1 in location i, j (same as
before). Second, let QXi |pari denote the Kronecker product of one matrix for each variable
in the CTBN. If the variable is Xi , the matrix is QXi |pari . If the variable is a parent of Xi
and has value xk in pari , then the matrix is xk ,xk . Otherwise, the matrix is the identity
matrix. In this way this Kronecker product distributes the elements of QXi |pari to the
relevant entries of the joint intensity matrix.
P
We can now define the joint intensity matrix. Let QXi be
pari QXi |pari . Then,
P
Q = i QXi . Figure 15 gives an example for the CTBN of Figure 13. Figure 16 gives
another example. While the Kronecker product in general does not handle the diagonal
elements, the expansion works for the intensity matrix in this case, since only one of the
matrices in each product is non-diagonal.
757

fiShelton & Ciardo

QX1 =

X

QX1 |x2  x2 ,x2  I

x2

QX2 =

X

x1 ,x1  QX2 |x1  I

x1

QX3 =

X

I  x2 ,x2  QX3 |x2

x2

Q = QX1 + QX2 + QX3
Figure 15: Sum of Kronecker encoding of the rate matrix Q of the CTBN in Figure 13.

QW = QW  I  I  I
X
QX =
I  QX|z  I  z,z

W

z

X

Y

QY =

w,w  I  QY |w  I

w

QZ =
Z

X
X

I  x,x  y,y  QZ|x,y

x,y

Q = QW + QX + QY + QZ

Figure 16: Sum of Kronecker product encoding of a CTBN with more than one parent per
node.

5.1.3 Connection to Decision Diagrams
The above decomposition of a CTBN into a sum of Kronecker products helps clarify the
connection to the edge-valued decision diagrams of the previous section. A CTBN is a
particularly structured version of the disjunctive EVMDD encoding of Section 4.5.1 paired
with the identity encoding of Section 4.5.2. In particular, a CTBN describes a CTMP
which can also be described by a sum of EVMDDs in fully-identity-reduced form. The two
descriptions have the same order space complexity. The decision-diagram encoding has one
EVMDD for each variable and each joint value for its parents.
Figure 17 shows the disjunction of EVMDDs for the CTBN in Figure 13. Each EVMDD
only encodes the non-identity matrices in the Kronecker product expression; the identity
matrices are implied by the fully-identity-reduced form. As another example, for the CTBN
in Figure 16, we could construct 9 EVMDDs: 1 for W , 2 for each of X and Y , and 4 for Z.
758

fiTutorial on Structured Continuous-Time Markov Processes

RX1|X2=0

RX1|X2=1

2

RX2|X1=0

4

RX2|X1=1

6

RX3|X2=0

8
0

x3

x2

0

1

1

1

0

0

8
2

0

0



0

1

1 5/8

2



0

1

0

1

1

1

1



1

2



1



0

1

1
1

1

1

1

1

1 4/7

1

1

0

0

1

0

1

2

0

1

1

0

1 1/4

2

6/8 1 7/8

1

1

1



0

2
1

1

7/8 1

3/4 1

1

1/2 1

1

5/6 1

x02

x01

1

1 8/9 7/9

x03

x1

RX3|X2=1

9

0

1

1

1

Figure 17: A set of identity-reduced EVMDDs whose sum is the same as the CTBN of
Figure 13.

Note that a disjunction of EVMDDs can compactly encode structure within a variables
local rate matrix, while a CTBN cannot. In this way, they represent a generalization that
can exploit context-sensitive independence.
Whether merging EVMDDs for a given variable or merging EVMDDs for multiple
variables will result in a reduction or increase in the representation size is largely an empirical
question. However, we would generally expect an increase in size because only one transition
is allowed at a time, so the paths through the levels must remember whether any previous
variable has changed and, if so, which one (for example, as in Figure 11).
5.2 Sampling
Sampling from a CTBN can be done by straight-forward application of the sampling method
described in Section 2.1. We need not construct the full intensity matrix. Instead, for any
joint assignment x, we can find the diagonal element by summing the diagonals of the
relevant conditional intensity matrices. This gives us the rate of the exponential to sample
for the time to the next variable change. We can read the intensities for each variables
potential transitions from the relevant row of its conditional intensity matrix and we select
a variable and the new state for that variable in proportion to the intensity. This process
takes O(L) time for each transition (where L is the number of variables).
We can do better by exploiting the racing and memoryless properties of exponential
distributions (discussed in Section 2.1). To select which variable transitions next, we will
race exponential distributions for each variable with rates of the corresponding diagonal
759

fiShelton & Ciardo

function SampleCTBN(CTBN, initial distribution 0 , end time T )
Let Tr  empty trajectory
Let (x1 , x2 , . . . , xL )  joint sample from 0
. As per algorithm for 0 s
representation
for i from 1 to L do
Add (Xi = xi @ 0) to Tr
Let t  0
Let E  an empty event priority queue of time-variable pairs.
repeat
for all variables Xi that do not have an event in E do
Sample t from an exponential with rate qxi |pari
Add ht + t,Xi i to E
Let ht,Xi i  the earliest event in E . Update t and get new variable to change
if t < T then
Sample x0i from a multinomial proportional to qxi ,x0i |pari
Let xi  x0i
. Update local copy of variable assignments
Add (Xi = xi @ t) to Tr
Remove Xi and all children of Xi from E
. Their times must be resampled
until t  T
Figure 18: Algorithm to sample from CTBN

elements of their conditional intensity matrices. We then note that if a variable is not
chosen, we can treat its transition time as two separate random draws: a draw stating
that its transition time is after the chosen time and a draw stating when after the chosen
transition time it will next transition (because of the memoryless property of the exponential
distribution). That means that if the chosen transition did not affect the rate for the variable
in question, we do not need to resample its transition time. By using a priority queue for
transitions times (not durations), we can reduce the running time per transition to O(D ln L)
where D is the maximal out-degree of the graph. This method is made explicit in Figure 18.
5.3 Inference
Inference in a CTBN is the process of calculating an expected value of the full trajectory,
given some partial trajectory. The most basic case is to infer the conditional probability of a
single variable at a single time point (the expectation of an indicator function) given a partial
trajectory. There are many ways in which a trajectory may be partial. The most obvious
for a variable-based model like a CTBN is to have variables only observed at particular
times and intervals. Each variable can have its own observation times and intervals. Thus,
for each variable, we assume we have evidence like that of Section 2.5.1: There are time
points at which the variable has known values and there are time intervals during which
the variable has known values (which might include observations of transitions).
Unfortunately, even if there is no evidence, this problem is NP-hard. In particular,
deciding whether the marginal probability of a single value of a single variable at a single
760

fiTutorial on Structured Continuous-Time Markov Processes

time point is greater than any positive threshold is NP-hard. This has been generally
accepted, although never formally demonstrated. We provide the proof in the Appendix.
Thus, all known algorithms for CTBN inference have exponential (in the number of
variables) running time. The simplest method is to treat the CTBN as a general CTMP with
a single intensity matrix Q. We can apply the forward and backward passes of Section 2.5.
While the intensity matrix can be stored in compact form, the resulting vectors require
space for each instantiation to every variable in the CTBN (exponential space). We need
only keep values for states consistent with the evidence. Thus, if at all times only a few
variables are unobserved, the inference is tractable. But, if there are periods during which
many variables are unobserved, we require approximate inference methods (overviewed in
Section 5.5).
Other than calculating the probability of a variable at a time, the other common case
of inference is to calculate the expected sufficient statistics. As shown in Section 5.4.1, this
means calculating N [xi , x0i |pari ] and T [xi |pari ] for all values of i, xi , x0i , and pari . The
former is the expected number of times variable Xi transitioned from xi to x0i while its
parents were in state pari , and the latter is the expected amount of time variable Xi was
in state xi while its parents were in state pari .
The proof for marginal calculation can easily be adapted to show that deciding whether
these quantities are non-zero is also NP-hard. Therefore, the only known method is to
again treat the system as a general CTMP with a single large Q matrix. We can then
apply Equation 65 and Equation 64 to find the expected number of transitions and expected
amount of time for any joint assignments. If we let J(xi , pari ) be the set of joint assignments
to all variables that are consistent with Xi = xi and Pari = pari , we can find the expected
sufficient statistics for the CTBN as
T [xi |pari ] =

X

T [x]

(80)

xJ(xi ,pari )

N [xi , x0i |pari ] =

X

X

N [x, x0 ]

(81)

xJ(xi ,pari ) x0 J(x0i ,pari )

5.4 Parameter and Graph Estimation
The initial distribution of a CTBN can be estimated separately using any standard method
for estimation of a Bayesian network (or whatever other compact representation is desired).
This requires only data about the value of the trajectorys value (or trajectories values) at
time 0.
We will concentrate on estimation of the rate parameters and dynamics graph structure (G). This exposition will assume there is a single trajectory, Tr. However, multiple
trajectories can be used by summing their sufficient statistics.
5.4.1 Parameter Estimation
The set of CTBNs with a fixed graph structure is just a subset of the exponential family of
CTMPs in which most parameters are fixed to 0 and many of the remaining ones are tied
to each other (share the same value). Thus, the log-likelihood of Equation 30 applies here
761

fiShelton & Ciardo

too, but where the sufficient statistics for tied parameters are summed:


X
X
T [xi |pari ]qx |par +
ln pCTBN (Tr) = ln P0 (Tr(0)) +
N [xi , x0i |pari ] ln qxi ,x0i |pari 
i
i
x0i 6=xi

i,pari ,xi

X

= ln P0 (Tr(0)) +



(82)


T [xi |pari ]qxi ,x0i |pari + N [xi , x0i |pari ] ln qxi ,x0i |pari

i,pari ,xi ,x0i 6=xi

(83)
= ln P0 (Tr(0)) +

X

lXi (Tr)

(84)

i

where i ranges over variables, pari ranges over joint assignments to the parents of i, and
xi and x0i range over differing assignments to Xi . T [xi |pari ] denotes the amount of time
Xi = xi while Pari = pari . Similarly, N [xi , x0i |pari ] denotes the number of transitions of
Xi from xi to x0i while Pari = pari . These new sufficient statistics are sums of the sufficient
statistics of the flat CTMP, summing over all assignments to all CTBN variables in which
Xi and Pari remain the same (see Equations 80 and 81). Given a complete trajectory, we
can construct them directly without employing such (exponentially large) sums. The last
line above is by definition of lXi , the local log-likelihood of variable Xi . Note that this is
a function only of the trajectories of Xi and its parents (not of all of Tr).
Maximizing Equation 83 is a straight-forward extension of maximizing Equation 30:
qxi ,x0i |pari = N [xi , x0i |pari ]/T [xi |pari ] .

(85)

We can produce Bayesian posterior distributions over the parameters if we take independent
conjugate prior distributions over each qxi ,x0i |pari parameter (Nodelman et al., 2003). Just
as for a flat CTMP, our conjugate prior is a gamma distribution with hyper-parameters
xi ,x0i |pari and xi ,x0i |pari for parameter qxi ,x0i |pari . The resulting posterior is also a gamma
distribution with corresponding hyper-parameters xi ,x0i |pari +N [xi , x0i |pari ] and xi ,x0i |pari +
T [xi |pari ]. Thus the MAP parameter estimates are
qxi ,x0i |pari =

N [xi , x0i |pari ] + xi ,x0i |pari
T [xi |pari ] + xi ,x0i |pari

.

(86)

5.4.2 Structure Estimation
Estimating the CTBN structure could be accomplished by statistical tests of the independence of the processes. Yet, we are unaware of any methods that use this or of suitable
independence tests.
Instead, CTBN structures have been estimated by graph scoring functions. If the score
function decomposes as the likelihood does (Equation 83) into a sum of terms, one per
variable, in which the selection of a variables parents only affects the term for the same
variable, the search for the maximal scoring graph is very simple. Each variables parents
can be chosen independently by maximizing the corresponding term in the sum. While
there are an exponentially large (in the total number of variables) number of parent sets
762

fiTutorial on Structured Continuous-Time Markov Processes

to consider for each variable, if we limit the cardinality of parent sets to no more than D,
then each variables parents can be chosen by exhaustive search and the total running time
is O(L2D ), which is linear in the number of variables, L.
This is in contrast to Bayesian networks where a similar strategy does not lead to
an efficient algorithm (unless a variable ordering is known a priori). Learning CTBNs
structure is efficient because there are no restrictions on the graph: A CTBNs graph may
be cyclic. A similar situation arises with dynamic Bayesian networks (DBNs). If we only
allow inter-time-slice edges (those from the previous time point to the current time
point), the graph structure may be searched efficiently, like in CTBNs. However, if we
allow intra-time-slice edges (those within the current time point) in a DBN, we must
enforce acyclicity constraints and the search is no longer efficient.
The Bayesian information criterion (Lam & Bacchus, 1994) can be made into a score:
!
X
ln |Tr|
scoreBIC (G : Tr) =
lXi (Tr) 
Dim(G)
(87)
2
i
fi
X
ln |Tr| fifi
fi
(88)
=
lXi (Tr) 
fiQXi |pari fi
2
i

where Dim(G)
fi is the finumber of independent parameters in the network defined by the
fi
fi
graph G and fiQXi |pari fi is the number of independent parameters in the conditional intensity
matrices associated with Xi . This second term is equal to ni (ni  1) (because the diagonal
elements are not independent) times the number of parent instantiations. The data size,
|Tr|, is the number of transitions in the trajectory Tr (or in the total data set if it consists
of multiple trajectories). This score is consistent (Nodelman et al., 2003) because the term
lXi (Tr) grows linearly with the amount of data and represents the likelihood and the second
term grows logarithmically with the amount of data and penalizes excess parameters.
A Bayesian score can also be constructed by placing a prior on graphs (as well as
parameters) and finding the maximum of ln P (G | Tr) = ln p(Tr | G)+ln P (G)ln p(Tr). The
last term isnt
P affected by the choice of G, so we drop it. We assume structure modularity:
ln P (G) = i ln P (Pari ). The remaining data term, ln P (Tr | G), is the (logarithm of the)
integral of the likelihood multiplied by the prior, over all possible parameter values. Using
the independent gamma priors from above, this decomposes into a separate term for each
variable (dropping the ln P0 (Tr(0)) term which does not affect the choice of G):

+1
0
Z 
h
X
(xi ,x0i |pari ) xi ,xi |pari
ln p(Tr | G) =
ln
exp (T [xi |pari ] + xi ,x0i |pari )qxi ,x0i |pari
(xi ,x0i |pari + 1)
0
i,pari ,xi 6=x0i
i
+(N [xi , x0i |pari ] + xi ,x0i |pari ) ln qxi ,x0i |pari dqxi ,x0i |pari
(89)
x

=

X

X

i

pari ,xi 6=x0i

+1
0
i ,xi |pari

ln

(xi ,x0i |pari )
(xi ,x0i |pari + 1)

!

(N [xi , x0i |pari ] + xi ,x0i |pari + 1)
N [xi ,x0i |pari ]+x

(T [xi |pari ] + xi ,x0i |pari )

+1
0
i ,xi |pari

(90)
=

X

lscoreB (pari : Tr)

(91)

i

763

fiShelton & Ciardo

where the last line is by the definition of lscoreB . This derivation is almost the same as the
one given in Nodelman et al. (2003). The difference is that our prior consists of a gamma
distribution for each independent variable whereas their prior consists of a gamma distribution for each diagonal rate parameter and a Dirichlet prior over the ratios qxi ,x0i |pari /qxi |pari .
The two are equivalent, but parameterized differently.
The Bayesian score is therefore
X
scoreB (G : Tr) =
lscoreB (pari : Tr) + ln P (Pari ) .
(92)
i

It converges to the BIC score in the limit of infinite data (Nodelman et al., 2003) and is
therefore also consistent.
5.4.3 Incomplete Data
For the case where the trajectory Tr is incomplete, we are back in the same situation as in
Section 2.6. As the likelihood takes the same form in a CTBN as in a general CTMP, the
solutions for maximizing the likelihood of this incomplete trajectory have the same form.
Namely, if we compute the expected sufficient statistics (using inference), we can apply
gradient ascent or expectation-maximization to find the maximum likelihood parameters.
The gradient is
!
p(Tr)
N [xi , x0i |pari ]
= p(Tr)
 T [xi |pari ]
(93)
qxi ,x0i |pari
qxi ,x0i |pari
and the expectation-maximization update equation is the same as Equation 85 except the
sufficient statistics are replaced by their expected values, given the partially observed trajectory and the current model.
For graph estimation, we can apply structural expectation-maximization (Friedman,
1997) (SEM) to CTBNs (Nodelman, Shelton, & Koller, 2005). While SEM for Bayesian
networks can be a little complex due to the structure search step, for CTBNs, it is simpler
as the structure search step need not enforce acyclicity constraints and therefore can be
carried out more simply (see above). The tricky point (which also holds for standard
Bayesian networks) is that the graph search scoring function must be calculated using
expected sufficient statistics and therefore, given a current model, our inference algorithm
must produce expected sufficient statistics not only for the current models parent sets,
but also for any other parent sets to be considered by the structure search. If using exact
inference (by flattening the CTBN to a general CTMP), these are available. However,
approximate methods (below) differ in how simple it is to extract such expected sufficient
statistics. Once this inference is performed, a joint optimization of parameters and structure
is performed, the new model is used to find new expected sufficient statistics, and the process
repeats.
5.5 Approximate Inference
As mentioned in Section 5.3, exact inference is intractable when there are many concurrently
missing variables. Therefore, many approximate inference methods have been developed.
We briefly cover them in this section, but would refer to the full papers for more complete
descriptions.
764

fiTutorial on Structured Continuous-Time Markov Processes

5.5.1 Sampling-Based Inference
Sampling is an obvious method for producing approximate inference. It has a number of
advantages. First, it produces a set of full trajectories from which any inference question can
be answered. Second, most sampling methods converge to the correct value if allowed to run
long enough. Third, sampling methods are usually easily parallelized, lending themselves
to multiple processors and multiple cores.
Hobolth and Stone (2009) have a description of a number of such methods for the
unstructured case and for full evidence at the beginning and the end of the trajectory, but
no evidence in between. Here we discuss work on CTBNs and for more general evidence
patterns.
Fan and Shelton (2008) and Fan, Xu, and Shelton (2010) developed an importance
sampler and a particle filter and smoother. Forward sampling (like in Figure 18) can be
turned into an importance sampler by taking the observed data as given and sampling for
the missing portions, marching time along. The weight of the sample is the probability of
having sampled the observed data (which was not sampled) given the trajectory up to those
data. The problem arises when a variable goes from being not observed to being observed.
In this case, the sampling must agree with up coming observation evidence. Adding a
transition exactly when the evidence starts is not correct (as there is almost surely not an
event at that time). These samplers handle it with some forward look ahead to sample
the necessary transition in advance, with suitable importance weight corrections. This is
then extended to a particle filter and smoother which are resampled based on the number
of transitions, rather than the absolute time. This method was extended to more general
temporal models by Pfeffer (2009).
El-Hay, Friedman, and Kupferman (2008) developed a Gibbs sampler for CTBN models.
They start with a simply developed trajectory that agrees with all of the evidence. Then,
the algorithm removes a single variables full trajectory and resamples it (keeping any time
periods during which the value is known). Conditioned on the full trajectories of a variables
Markov blanket (the union of the variables children, parents, and childrens parents), the
trajectory for that variable is independent of all other variables, so the sampler needs to
only consider the variables Markov blanket. The posterior distributions over the times of
transitions are no longer exponential distributions. Their forms are complex and thus the
Gibbs sampler must sample by performing binary search.
Fan and Shelton (2009) combined the ideas from the Gibbs sampler and their earlier
work on importance sampling to produce a Metropolis-Hastings sampler. The importance
sampling method is used instead of Gibbs sampling and the importance weight is used to
find the acceptance probability. While faster to generate samples, the samples take longer
to converge. The balance of the trade-off depends on the typicality of the evidence and the
inference query.
Rao and Teh (2011, 2013) used uniformization to develop an auxiliary Gibbs sampler
which is faster than the previous Gibbs sampler. The auxiliary variables are the times
of the self-transitions from an uniformization sampler (Section 2.3). Thus to resample a
variable, the algorithm samples auxiliary times, given the old trajectory (which can be
done quickly). It then throws away all of the transitions, but keeps the full set of times
(old times and the new times). Then, using a forward-backward two-pass algorithm, state
765

fiShelton & Ciardo

transitions are sampled from the uniformized discrete-time process (conditioned on the
evidence). Finally, the self transitions are discarded. Rao and Teh (2012) extended this to
a time-varying uniformization rate to speed up convergence, but only explicitly in the case
of an unstructured process.
5.5.2 Non-Sampling Methods
A number of other non-sampling methods have also been proposed. Their advantages
include determinism (often helpful when used inside of EM to keep the estimates consistent),
and fewer parameters that need to be set well (number of samples, length of burn-in, and
others).
Cohn, El-Hay, Kupferman, and Friedman (2009) and Cohn, El-Hay, Friedman, and
Kupferman (2010) derived a mean-field approximation. The approximate distribution is an
independent time-inhomogeneous Markov process for each variable. That is, the variables
are independent (in the approximation), but the intensities depend on time. The natural
parameterization also differs slightly. Instead of transition rates, transition densities are
used, but the idea is the same. The resulting algorithm changes one variables distribution at
a time, again depending only on the Markov blanket. The update involves solving a system
of differential equations (to get the time-varying parameters of the inhomogeneous Markov
process). These are solved by adaptive integration which means that less computation is
required during intervals of less rapid change. The result is that the time-varying parameters
are represented by a series of time-value points (those produced during adaptive integration)
and linear interpolation between these points.
Nodelman, Koller, and Shelton (2005) derived an expectation-propagation method. The
propagation uses piece-wise constant time-homogeneous Markov processes, where each piece
corresponds to a period of constant evidence. These piece-wise constant approximations are
propagated instead of the true marginals (as such marginals would be intractably large).
Saria, Nodelman, and Koller (2007) extended this method to subdivide the pieces of the
approximations further and adaptively. El-Hay, Cohn, Friedman, and Kupferman (2010)
produced a belief propagation algorithm in the same spirit as the mean-field approximation
above, employing a free energy functional for CTMPs. Instead of propagating piece-wise
time-homogeneous Markov processes, they propagate a single time-inhomogeneous Markov
process and then use the same adaptive integration representation as in mean-field. The
result is more adaptive and mathematically cleaner.
Finally, for filtering (but not general inference), Celikkaya, Shelton, and Lam (2011)
developed a factored version of a uniformized Taylor expansion to approximate the matrix
exponential calculations. The result is something similar to that of Boyen and Koller (1998)
for dynamic Bayesian networks, but also involving a truncation of an infinite sum and a
mixture of propagation distributions. This method is the only current non-sampling method
with accuracy bounds, although they are very loose.
5.6 Extensions
As shown above, a CTBN can be converted into a sum of decision diagrams. In that way
decision diagrams (and other similarly convertible models) can be viewed as extensions of
766

fiTutorial on Structured Continuous-Time Markov Processes

CTBNs. Many of the non-Markovian processes of Section 1.1 could, if restricted in the right
way, also be so viewed. However, there are a few more direct extensions of CTBNs.
First, El-Hay et al. (2010) introduced continuous-time Markov networks (CTMNs).
They are undirected graphical models of Markov processes in the same way that CTBNs
are directed graphical models. They model the subclass of reversible processes, ones for
which detailed balance holds: There exists a distribution  (the stationary distribution of
the process) such that (x)qx,x0 = (x0 )qx0 ,x for all pairs of states x and x0 . A CTMN
can be converted to a CTBN by replacing each undirected edge with a pair of directed
edges. Their parameterization directly reveals the stationary distribution of the process as
a Markov network.
Second, Portinale and Codetta-Raiteri (2009) and Codetta-Raiteri and Portinale (2010)
showed an extension of CTBNs to allow for simultaneous transition of multiple variables. It
is based on Petri nets and encodes cascades of transitions that all happen simultaneously.
Finally, Weiss, Natarajan, and Page (2012) presented a method for constructing the
local rate matrices for each variable not as a matrix, but as the multiplication of regression
trees. This is akin to exploiting context-specific independence (Shimony, 1991) in a standard
Bayesian network by use of trees (Boutilier, Friedman, Goldszmidt, & Koller, 1996). This
multiplication of trees is not the same as our reduction of a CTBN to a sum of EVMDDs
(see Figure 17). In particular, their trees do not require the tests be made in a particular
variable order, they use trees instead of DAGS, and they multiply the trees together (instead
of adding them). Weiss et al. (2012) also give a boosting-style algorithm for learning this
parameterization. No similar method is known for learning a sum of EVMDDs.

6. Applications and Current Directions
To provide some context for the theory and algorithms above, we describe how these methods have been used in applications. We then discuss what we believe to be the most
promising and pressing research directions.
6.1 Decision-Diagram-Based Models
Structured CTMPs arise in many applications areas, from performance and reliability evaluation of computer systems to the investigation of biological systems. As the underlying
CTMPs describing the dynamics being analyzed are usually very large, most software tools
used for such studies rely on compact symbolic techniques to encode them.
In particular, PRISM (Kwiatkowska et al., 2011) uses a hybrid form of MTBDDs,
Mobius (Deavours et al., 2002) uses Matrix Diagrams (a data structure almost equivalent to
EVMDDs), and SMART (Ciardo et al., 2006) uses EVMDDs to encode the transition rate
matrix of a CTMP. These tools can compute both stationary and transient exact numerical
solutions of compactly encoded CTMPs. (Indeed, they can compute much more complex
stochastic temporal logic properties such as those that can be expressed in CSL (Baier,
Haverkort, Hermanns, & Katoen, 2000), but these, too, ultimately require a sequence of
stationary or transient numerical solutions.) While such exact solutions place very large
computational demands due to the exponential explosion of the state space, the situation
is often somewhat mitigated by the fact that, in most applications targeted by these tools,
the actual state space is a small subset of the full cross-product of the state variable values.
767

fiShelton & Ciardo

As an example application, we briefly summarize a study done using PRISM for the
analysis of a complex biological pathway called FGF (Fibroblast Growth Factor) (Heath,
Kwiatkowska, Norman, Parker, & Tymchyshyn, 2006). The state of the system consists of
the number of proteins (e.g., A, B) or protein complexes (e.g., A:B) present at the current
time. The events in the system consist of various reactions such as complexation (e.g.,
A + B  A : B) and decomplexation (its reverse, A:B  A + B), as well as degradation
(e.g., A ). Finally, each event has an occurrence rate, which can of course depend on the
number of proteins currently present for the types involved in the particular reaction. The
actual model for the FGF pathway, even after substantial simplifications to focus only on
key and well-known aspects in real cells, contains 87 different proteins or protein complexes
(each of them corresponding to a local state variable) and 50 different reactions (if we count
complexation and decomplexation separately). We stress that each reaction concerns just
a few proteins or compounds; thus its decision diagram representation in isolation is quite
compact.
Even the smallest meaningful model where there is only zero or one protein or compound
of each type would have a potential state space of size 287 . However, as almost always the
case in this type of models, only a tiny fraction of these states is reachable, thus the model
used in the work of Heath et al. (2006) has merely 801,616 states and 560,000 state-tostate transitions. The study focused on several key questions such as what fraction of
time particular proteins are bound, or the probability that a particular degradation has
occurred within a given time bound, all quantities obtainable through numerical stationary
or transient analysis of the underlying CTMP. Notwithstanding the relatively small size
of the state space (which could likely be scaled by a factor of 1000, to around 108 states,
given a modern workstation with sufficient memory) the results and predictions obtained
from this model using PRISM were shown to agree with biological data, demonstrating the
viability of these technique to perform in silico genetics as a much less costly alternative
to the in vitro experiments traditionally performed in biology.
6.2 Continuous-Time Bayesian networks
CTBNs have been employed on a number of real-world datasets and problems including life
event history data (Nodelman et al., 2003), user activity modeling (Nodelman & Horvitz,
2003), computer system failure modeling (Herbrich, Graepel, & Murphy, 2007), mobile
robotics (Ng, Pfeffer, & Dearden, 2005), network intrusion detection (Xu & Shelton, 2008,
2010), phylogentic trees (Cohn et al., 2009), social networks (Fan & Shelton, 2009), cardiovascular health model (Weiss et al., 2012), and heart failure (Gatti, Luciani, & Stella,
2012). Many of these also innovated in extending the CTBN framework. For instance, Ng
et al. (2005) allowed for continuous-state variables whose dynamics are dictated by differential equations. The form of evidence is more limited, but a particle filter is developed
for this situation. Cohn et al. (2009) applied the CTBN model to a time-tree to allow
branching (as first done in Felsenstein, 1981 for general CTMPs). Weiss et al. (2012) added
context-specific independence.
To give an idea of the application of CTBNs, we briefly review the intrusion detection
work of Xu and Shelton (2008, 2010). In this work, the goal was to build a model of normal
768

fiTutorial on Structured Continuous-Time Markov Processes

G

H

Pin

Cinc

Pout

Cdec
N

Figure 19: CTBN model for network traffic (Xu & Shelton, 2010). N is the number of
destination ports.

computer system events, specific to a particular machine. This model could then be used
to detect abnormal events or time windows as a method of intrusion detection.
Two models were built: one modeling network traffic in and out of the machine, and one
modeling system calls from processes. The network model was as in Figure 19. There is one
global hidden variable G with four states. The traffic is divided into different destination
ports (for instance, 80 for HTTP traffic and 995 for POP traffic). The most frequent
eight ports are separated out and the traffic from the remaining destinations are grouped
together. Each of these N = 9 groups has its own model (the plate in Figure 19). This
submodel has one hidden variable H and four completely observed binary variables, Pin ,
Pout , Cinc , and Cdec , representing packets sent and received and connections started and
stopped respectively. These observed variables toggle state to represent an event of the
relevant type, but their state has no intrinsic meaning. Therefore, their matrices have only
a single independent parameter: the rate of transition from either state to the other. In
this way, these observed variables are really conditional Poisson processes.
The hidden variable H is structured to exploit domain knowledge. It has 8 states which
are grouped into pairs, one pair for each of its children. For each pair only one of its children
has a non-zero rate. Thus, H encodes what type of event will happen and some substate
of this meta-state.
The entire model has 4  89 or approximately 500 million hidden states (as the observed
variables are observed at all times, only the distribution over the G and the Hs need be
tracked). Yet, each submodel has only 8 hidden states, so exact inference over a submodel
is very reasonable. Thus, they adapted the particle filter and smoother of Fan and Shelton
(2008) to distributional particles, producing a Rao-Blackwellized particle filter in which G
is sampled and each of the models (which are independent, given a full trajectory of G) are
reasoned about exactly.
This inference method allows learning of specific models to each host using EM. These
models were then run on data in which computer virus or worm traffic had been injected
(very slowly to make it blend in with background traffic). The model was asked the likelihood of 50-second window of traffic (given the previous traffic). This likelihood was thresh769

fiShelton & Ciardo

olded to produce an alarm (if the likelihood dropped too low). The results out-performed
SVM-spectrum kernels, nearest-neighbor (using features from the computer network literature for this task), and other methods on this task and other similar tasks.
For process system calls, the model was similar, with a single hidden variable coordinating the behavior of a set of observed system-call variables. The dataset on which this model
was trained had time stamps for each system call. However, due to clock resolution, many
time stamps were the same. Yet, the temporal order was preserved (although the exact
durations between events was not). The paper demonstrates a method to use such data,
without assuming event durations, but employing the ordering. In this case, the results
were better than the SVM-spectrum kernel and nearest-neighbor and the same as stide
with frequency thresholding (Warrender, Forrest, & Pearlmutter, 1999).
6.3 Relative Comparison
Neither of the above two applications could currently be tackled with the other modeling
language. In the biological pathway example of Section 6.1, a transition in the system involved more than one variable (increasing the number of protein complexes, while decreasing
the number of individual proteins). A CTBN cannot represent simultaneous transitions of
multiple variables. The pathways cannot be reformulated in terms of composite variables
to prevent such simultaneous transitions without placing all of the state in a single variable.
As a simpler example, consider a system of three variables, x, y, and z. A single event
performs three variable updates at the same time: {x0  x + y; y 0  y + 1; z 0  z  1} with
rate r(x, y, z). We assume that each variable is a natural number in the range [0, . . . , n]
and that any update that would move a variable outside its range is disabled. Figure 20
demonstrates how an EVMDD can encode such a transition. Neither a Kronecker encoding
nor a CTBN can encode this event without merging variables.
Likewise, the network traffic example from Section 6.2 cannot be handled with current
decision-diagram-based models. It depends on hidden unseen variables and estimation of
transient solutions conditioned on data. More critically, it relies on estimation of the model
parameters from data, which has not been developed for decision-diagram models.
6.4 Current Research Directions
There are a range of open modeling, algorithmic, and theoretic problems. First, questions of steady-state distributions and efficient exact solutions have not been addressed for
CTBNs (as they have for EVMDDs). Similarly, questions of structure and parameter estimation and approximate inference have not been addressed for EVMDDs (as they have
for CTBNs).
Optimal decision making has been formulated as general continuous-time Markov decision processes (Puterman, 1994). Yet, extending the general mathematical framework to
structured variable-based models is largely unexplored (Kan & Shelton, 2008).
CTBNs were extended to handle continuous-valued variables and measurements in a
limited fashion (Ng et al., 2005), but otherwise this has been unexplored. For many applications this is critical. If the underlying system is discrete and the measurements are
continuous, techniques like those in Section 2.5 work. But, systems with continuous state
require stochastic differential equations (ksendal, 2003), at least in some form. The work
770

fiTutorial on Structured Continuous-Time Markov Processes

x
y
z
x0
y0
z0

0
0
0




1
0
0




2
0
0




0
1
0




1
1
0




2
1
0




0
2
0




1
2
0




2
2
0




0
0
1
0
1
0

1
0
1
1
1
0

2
0
1
2
1
0

0
1
1
1
2
0

1
1
1
2
2
0

2
1
1




0
2
1




1
2
1




2
2
1




0
0
2
0
1
1

1
0
2
1
1
1

x0

y

y0

z

z0

0
1
2
1
2
1

1
1
2
2
2
1

2
1
2




0
2
2




1
2
2




2
2
2








x

2
0
2
2
1
1

0

1

2

0

1

2













0

1

1

2

2

0

1

1

2

2









1









1

0

1

0

1

0

0

1

1

1

1

1

1

1

1

1

2

1

2

1

1

2

1

1

1

1

1

1

1

1

2

1

2

1

2

1

2

1

2

1

2

























0

1

0

1

1

1

1

1





Figure 20: An example of an EVMDD encoding simultaneous transitions of multiple variables. Top: the 10 possible transitions and resulting states (dash indicates
disabled) from state (x, y, z) to state (x0 , y 0 , z 0 ). Bottom, left: worst case for
an arbitrary set of 10 rates for r(x, y, z). Bottom, right: best case when
r(x, y, z) = r1 (x, y)r2 (z). A dot indicates a positive value (used to encode the
particular rates). In each block of dots, one must be equal to 1 and the others
must be  1.

of Sarkka (2006) describes filtering and smoothing in such models. Yet, parameter estimation is much more difficult and systems with both continuous and discrete state variables
have not been systematically addressed.
Finally, new approximate inference methods are always of interest (as with any probabilistic model). Recent methods such as the auxiliary Gibbs sampler (Rao & Teh, 2013)
and belief propagation (El-Hay et al., 2010) demonstrate that exploiting the properties of
continuous time can lead to great benefits. We hope that further research explores more
such methods.
771

fiShelton & Ciardo

7. Conclusions
Compared with discrete-time models, CTMPs are better suited for domains in which data
have real-valued time stamps (the time between events is not regular or well-approximated
by a single clock step rate). Thus, in selecting a value for the time-slice-width (t) for
a discrete-time model, either the time width will be large resulting in multiple events per
time window (obscuring temporal information), or it will be small resulting in unnecessary
computational burdens (propagating across many time windows). Further, the optimal
middle ground between too large and too small will differ depending on the data size, the
application, and the model component.
We have presented two different CTMP modeling languages. Edge-valued decision diagrams (of Section 4) are more general: They allow multiple variables to change simultaneously. By contrast, CTBNs directly encode independence assumptions (see Section 5).
Either an EVMDD or a CTBN might be more compact for a given situation, although any
CTBN can be compactly rerepresented as a sum of EVMDDs (see Section 5.1.3).
The models forms and histories have given rise to differences in available algorithms,
and here the distinctions are greater. The literature on exact solution methods is richer for
decision diagram models. Furthermore, this literature is more focused on computing the
models steady state. Approximate methods (especially for transients) and model estimation
are notably absent (from an artificial intelligence point-of-view). The literature for CTBNs
is more focused on model estimation and approximate inference conditioned on evidence.
The CTBN literature has paid no attention to issues of reachability (when much of the joint
state space is not reachable) and optimization of exact inference methods.
For processes with a natural synchronization clock (such as modeling daily high and low
temperatures), a discrete-time model is the best fit. For processes without such a natural
time-slice-width we recommend a continuous-time model. If the questions of interest are
about steady states of the system or an exact solution is necessary, an EVMDD is probably
the best choice. If the model must be built from data or approximate inference (especially
conditioned on data) is necessary, a CTBN is probably the best choice.
However, we have shown that the two models share much in common. Thus, we hope
that the efficient exact algorithms from EVMDDs can be applied to CTBNs and the approximate inference and model estimation methods from CTBNs can be applied to EVMDDs.
If so, then the choice of model would depend more upon the model properties and not the
existing suite of algorithms. In particular, a CTBN makes the assumption that each variable is distinct. In contrast, a disjunctive EVMDD encoding decomposes the system into
local events. The variable-level independencies are more easily read from a CTBN graph,
but they disallow simultaneous transition of multiple variables. The application domain
should guide whether variable-level explicit independences or simultaneous transitions are
more important.
Regardless of the model used, we believe time is a continuous quantity and best modeled
as such. While the introduction of the matrix exponential would at first seem to complicate
matters (compared with discrete time), we believe it makes the true coupling of variables
more obvious and opens up mathematical and algorithmic possibilities for more efficient
and precise solutions.
772

fiTutorial on Structured Continuous-Time Markov Processes

Acknowledgements
Shelton was supported by DARPA award FA8750-12-2-0010 and by The Laura P. and Leland
K. Whittier Virtual PICU at Childrens Hospital Los Angeles (awards UCR-12101024 and
8220-SGNZZ0777-00). Ciardo was supported by the NSF through grant CCF-1442586.

Appendix A. NP-hardness of CTBN Inference
The theorem and proof of the NP-hardness of CTBN inference are straight-forward extensions of the similar proof for Bayesian networks (Koller & Friedman, 2009). The literature
has widely accepted it to be true, but no proof has been formally presented. Thus, while
straight-forward, we present it here for completeness.
Definition 1. CTBN-Inf is the following decision problem. Given a CTBN specified as
a directed graph G over nodes {X1 , X2 , . . . , XL }, a set of conditional intensity matrices
Q = {QXi |pari }, and an initial distribution  in which each node is independent with
marginals {Xi }; a variable Xj ; a value for Xj , xj ; and a time t > 0, decide whether
PG,Q, (Xj (t) = xj ) > 0.
Theorem 1. CTBN-Inf is NP-hard.
Proof. The proof is a polynomial time reduction from 3-SAT, following the same lines as
the similar proof for Bayesian networks.
Given a 3-SAT problem with variables z1 , z2 , . . . , zm and clauses c1 , c2 , . . . , ck in which
zA(i,j) is the jth variable (j  {1, 2, 3}) in clause i (i  {1, 2, . . . , k}) with sign sA(i,j) 
{+, }, we construct a CTBN with m + 2k  1 binary variables (taking values F or T ):
Y1 , Y2 , . . . , Ym , C1 , C2 , . . . , Ck , B1 , B2 , . . . , Bk2 , and S.
Variable Yi has no parents, a uniform initial distribution Yi , and an intensity matrix
QYi | that is all 0.
Variable Ci has three parents: YA(i,1) , YA(i,2) , and YA(i,3) . If none of the truth value
of the parents (yA(i,1) , yA(i,2) , yA(i,3) ) match the formulas signs (sA(i,1) , sA(i,2) , sA(i,3) ), the
conditional intensity matrix is all 0. For the other parent assignments
(in which at least one


1 1
variable matches), the conditional intensity matrices are
. The initial distribution
0 0


is 1 0 .
Variable B1 has parents C1 and C2 . Variable Bi (for 1 < i < k  1) has parents Bi1
and Ci+1 . Variable S has parents Bk2 and Ck . For all of these
variables, the conditional

1 1
intensity matrix if the two parents values are T is
. Otherwise, the conditional
0 0


intensity matrix is all 0. All of these variables have an initial distribution of 1 0 .
This reduction is polynomial in size (all numeric values are small and there are a polynomial number of variables, each with a maximum of 3 parents) and can obviously be output
in polynomial time. By construction, Yi selects at time 0 a truth value for zi and never
changes. Each Cj will then eventually change to T if and only if the clause is satisfied by
the selected truth values. Bj will eventually change to be T if and only if clauses 1 through
j + 1 are all T . S will similarly eventually change to be T if and only if all clauses are
satisfied.
773

fiShelton & Ciardo

Because of the Markov nature of the process, for any time t > 0, PG,Q, (S(t) = T ) > 0 if
the formula is satisfiable and the same probability is 0 if the formula is not satisfiable.
This demonstrates that determining whether a marginal is non-zero is NP-hard. By similar construction as for Bayesian networks (Koller & Friedman, 2009), this can be extended
to show that absolute and relative error formulations of inference are also NP-hard.

References
Ajmone Marsan, M., Balbo, G., Conte, G., Donatelli, S., & Franceschinis, G. (1995). Modelling with Generalized Stochastic Petri Nets. John Wiley & Sons.
Asmussen, S., Nerman, O., & Olsson, M. (1996). Fitting phase-type distributions via the
EM algorithm. Scandavian Journal of Statistics, 23, 419441.
Baier, C., Haverkort, B. R., Hermanns, H., & Katoen, J.-P. (2000). Model checking
continuous-time Markov chains by transient analysis. In Proceedings of Computer
Aided Verification, pp. 358372.
Baskett, F., Chandy, K. M., Muntz, R. R., & Palacios-Gomez, F. (1975). Open, closed, and
mixed networks of queues with different classes of customers. Journal of the ACM,
22 (2), 335381.
Boutilier, C., Friedman, N., Goldszmidt, M., & Koller, D. (1996). Context-specific independence in Bayesian networks. In Proceedings of the Twelfth International Conference
on Uncertainty in Artificial Intelligence, pp. 115123.
Boyen, X., & Koller, D. (1998). Tractable inference for complex stochastic processes. In
Proceedings of the Fourteenth Annual Conference on Uncertainty in Artificial Intelligence, pp. 3342.
Bryant, R. E. (1986). Graph-based algorithms for boolean function manipulation. IEEE
Transactions on Computers, 35 (8), 677691.
Buchholz, P., Ciardo, G., Donatelli, S., & Kemper, P. (2000). Complexity of memoryefficient Kronecker operations with applications to the solution of Markov models.
INFORMS Journal on Computing, 12 (3), 203222.
Burch, J. R., Clarke, E. M., & Long, D. E. (1991). Symbolic model checking with partitioned
transition relations. In International Conference on Very Large Scale Integration, pp.
4958. IFIP Transactions, North-Holland.
Celikkaya, E. B., Shelton, C. R., & Lam, W. (2011). Factored filtering of continuoustime systems. In Proceedings of the Twenty-Seventh International Conference on
Uncertainty in Artificial Intelligence.
Ciardo, G., Jones, R. L., Miner, A. S., & Siminiceanu, R. (2006). Logical and stochastic
modeling with SMART. Performance Evaluation, 63, 578608.
Ciardo, G., & Siminiceanu, R. (2002). Using edge-valued decision diagrams for symbolic
generation of shortest paths. In Proceedings of Formal Methods in Computer-Aided
Design (FMCAD), LNCS 2517, pp. 256273. Springer.
774

fiTutorial on Structured Continuous-Time Markov Processes

Ciardo, G., & Yu, A. J. (2005). Saturation-based symbolic reachability analysis using
conjunctive and disjunctive partitioning. In Proceedings of Correct Hardware Design
and Verification Methods (CHARME), LNCS 3725, pp. 146161. Springer.
Ciardo, G., Zhao, Y., & Jin, X. (2012). Ten years of saturation: a Petri net perspective.
Transactions on Petri Nets and Other Models of Concurrency, V, 5195.
Clarke, E., Fujita, M., McGeer, P. C., Yang, J. C.-Y., & Zhao, X. (1993). Multi-terminal
binary decision diagrams: an efficient data structure for matrix representation. In
IWLS 93 International Workshop on Logic Synthesis.
Codetta-Raiteri, D., & Portinale, L. (2010). Generalized continuous time Bayesian networks
and their GSPN semantics. In European Workshop on Probabilistic Graphical Models,
pp. 105112.
Cohn, I., El-Hay, T., Friedman, N., & Kupferman, R. (2010). Mean field variational approximation for continuous-time Bayesian networks. Journal of Machine Learning
Research, 11 (Oct), 27452783.
Cohn, I., El-Hay, T., Kupferman, R., & Friedman, N. (2009). Mean field variational approximation for continuous-time Bayesian networks. In Proceedings of the Twenty-Fifth
International Conference on Uncertainty in Artificial Intelligence.
Dean, T., & Kanazawa, K. (1989). A model for reasoning about persistence and causation.
Computational Intelligence, 5 (3), 142150.
Deavours, D. D., Clark, G., Courtney, T., Daly, D., Derisavi, S., Doyle, J. M., Sanders,
W. H., & Webster, P. G. (2002). The mobius framework and its implementation.
IEEE Transactions on Software Engineering, 28 (10), 956969.
Didelez, V. (2008). Graphical models for marked point processes based on local independence. Journal of the Royal Statitical Society: Series B, 70 (1), 245264.
Donatelli, S. (1994). Superposed generalized stochastic Petri nets: definition and efficient
solution. In Proceedings of International Conference on Application and Theory of
Petri Nets (ICATPN), LNCS 815, pp. 258277. Springer.
El-Hay, T., Cohn, I., Friedman, N., & Kupferman, R. (2010). Continuous-time belief propagation. In Proceedings of the 27th International Conference on Machine Learning,
pp. 343350, Haifa, Israel.
El-Hay, T., Friedman, N., & Kupferman, R. (2008). Gibbs sampling in factorized continuoustime Markov processes. In Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial Intelligence, pp. 169178.
Fan, Y., & Shelton, C. R. (2008). Sampling for approximate inference in continuous time
Bayesian networks. In Proceedings of the Tenth International Symposium on Artificial
Intelligence and Mathematics.
Fan, Y., & Shelton, C. R. (2009). Learning continuous-time social network dynamics. In
Proceedings of the Twenty-Fifth International Conference on Uncertainty in Artificial
Intelligence.
Fan, Y., Xu, J., & Shelton, C. R. (2010). Importance sampling for continuous time Bayesian
networks. Journal of Machine Learning Research, 11 (Aug), 21152140.
775

fiShelton & Ciardo

Felsenstein, J. (1981). Evolutionary trees from DNA sequences: A maximum likelihood
approach. Journal of Molecular Evolution, 17, 368376.
Fernandes, P., Plateau, B., & Stewart, W. J. (1998). Efficient descriptor-vector multiplication in stochastic automata networks. Journal of the ACM, 45 (3), 381414.
Fox, B. L., & Glynn, P. W. (1988). Computing poisson probabilities. Communications of
the ACM, 31 (4), 440445.
Friedman, N. (1997). Learning belief networks in the presence of missing values and hidden
variables. In Proceedings of the Fourteenth International Conference on Machine
Learning, pp. 125133.
Gatti, E., Luciani, D., & Stella, F. (2012). A continuous time Bayesian network model
for cardiogenic heart failure. Flexible Services and Manufacturing Journal, 24 (4),
496515.
Grassmann, W. K. (1977). Transient solutions in Markovian queueing systems. Computers
& Operations Research, 4 (1), 4753.
Gunawardana, A., Meek, C., & Xu, P. (2012). A model for temporal dependencies in event
streams. In Advances in Neural Information Processing Systems, Vol. 24.
Heath, J., Kwiatkowska, M., Norman, G., Parker, D., & Tymchyshyn, O. (2006). Probabilistic model checking of complex biological pathways. In Priami, C. (Ed.), Proceedings
Computational Methods in Systems Biology (CMSB), Vol. 4210 of Lecture Notes in
Bioinformatics, pp. 3247. Springer Verlag.
Herbrich, R., Graepel, T., & Murphy, B. (2007). Structure from failure. In Proceedings
of the 2nd USENIX workshop on Tackling computer systems problems with machine
learning techniques, pp. 16. USENIX Association.
Hobolth, A., & Stone, E. A. (2009). Simulation from endpoint-conditioned continuous-time
Markov chains on a finite state space, with applications to molecular evolution. The
Annals of Applied Statistics, 3 (3), 12041231.
Kam, T., Villa, T., Brayton, R. K., & Sangiovanni-Vincentelli, A. (1998). Multi-valued
decision diagrams: theory and applications. Multiple-Valued Logic, 4 (12), 962.
Kan, K. F., & Shelton, C. R. (2008). Solving structured continuous-time Markov decision processes. In Proceedings of the Tenth International Symposium on Artificial
Intelligence and Mathematics.
Koller, D., & Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. The MIT Press.
Kwiatkowska, M., Norman, G., & Parker, D. (2011). PRISM 4.0: Verification of probabilistic real-time systems. In Gopalakrishnan, G., & Qadeer, S. (Eds.), Proceedings of
Computer Aided Verification, Vol. 6806 of LNCS, pp. 585591. Springer.
Kwiatkowska, M. Z., Norman, G., & Parker, D. (2004). Probabilistic symbolic model checking with PRISM: a hybrid approach. Software Tools for Technology Transfer, 6 (2),
128142.
Lam, W., & Bacchus, F. (1994). Learning Bayesian belief networks: An approach based on
the MDL principle. Computational Intelligence, 10, 269293.
776

fiTutorial on Structured Continuous-Time Markov Processes

Moler, C., & Loan, C. V. (2003). Nineteen dubious ways to compute the exponential of a
matrix, twenty-five years later. SIAM Review, 45 (1), 349.
Najfeld, I., & Havel, T. F. (1994). Derivatives of the matrix exponential and their computation. Tech. rep. TR-33-94, Center for Research in Computing Technology, Harvard
University.
Najfeld, I., & Havel, T. F. (1995). Derivatives of the matrix exponential and their computation. Advances in Applied Mathematics, 16, 321375.
Ng, B., Pfeffer, A., & Dearden, R. (2005). Continuous time particle filtering. In Proceedings
of the Nineteenth International Joint Conference on Artificial Intelligence, pp. 1360
1365.
Nodelman, U., & Horvitz, E. (2003). Continuous time Bayesian networks for inferring
users presence and activities with extensions for modeling and evaluation. Tech. rep.
MSR-TR-2003-97, Microsoft Research.
Nodelman, U., Koller, D., & Shelton, C. R. (2005). Expectation propagation for continuous
time Bayesian networks. In Proceedings of the Twenty-First International Conference
on Uncertainty in Artificial Intelligence, pp. 431440.
Nodelman, U., Shelton, C. R., & Koller, D. (2002). Continuous time Bayesian networks.
In Proceedings of the Eighteenth International Conference on Uncertainty in Artificial
Intelligence, pp. 378387.
Nodelman, U., Shelton, C. R., & Koller, D. (2003). Learning continuous time Bayesian
networks. In Proceedings of the Nineteenth International Conference on Uncertainty
in Artificial Intelligence, pp. 451458.
Nodelman, U., Shelton, C. R., & Koller, D. (2005). Expectation maximization and complex
duration distributions for continuous time Bayesian networks. In Proceedings of the
Twenty-First International Conference on Uncertainty in Artificial Intelligence, pp.
421430.
ksendal, B. (2003). Stochastic Differential Equations: An Introduction with Applications
(Sixth edition). Springer-Verlag.
Parikh, A. P., Gunamwardana, A., & Meek, C. (2012). Cojoint modeling of temporal
dependencies in event streams. In UAI Bayesian Modelling Applications Workshop.
Pfeffer, A. (2009). CTPPL: A continuous time probabilistic programming language. In
Proceedings of the 21st International Joint Conference on Artifical Intelligence, pp.
19431950.
Plateau, B. (1985). On the stochastic structure of parallelism and synchronisation models
for distributed algorithms. In Proceedings of ACM SIGMETRICS, pp. 147153.
Portinale, L., & Codetta-Raiteri, D. (2009). Generalizing continuous time Bayesian networks with immediate nodes. In Proceedings of the Workshop on Graph Structure for
Knowledge Represetnation and Reasoning, pp. 1217.
Press, W. H., Teukolsky, S. A., Vetterling, W. T., & Flannery, B. P. (1992). Numerical
Recipes in C (Second edition). Cambridge University Press.
777

fiShelton & Ciardo

Puterman, M. L. (1994). Markov Decision Processes. Wiley-Interscience.
Rajaram, S., Graepel, T., & Herbrich, R. (2005). Poisson networks: A model for structured
point processes. In Proceedings of the AI STATS 2005 Workshop.
Rao, V., & Teh, Y. W. (2011). Fast MCMC sampling for Markov jump processes and continuous time Bayesian networks. In Proceedings of the Twenty-Seventh International
Conference on Uncertainty in Artificial Intelligence.
Rao, V., & Teh, Y. W. (2012). MCMC for continuous-time discrete-state systems. In
Advances in Neural Information Processing Systems 25, pp. 710718.
Rao, V., & Teh, Y. W. (2013). Fact MCMC sampling for Markov jump processes and
extensions. Journal of Machine Learning Research, 1, 126.
Roux, P., & Siminiceanu, R. (2010). Model Checking with Edge-valued Decision Diagrams. In Proceedings of the Second NASA Formal Methods Symposium (NFM 2010),
NASA/CP-2010-216215, pp. 222226. NASA.
Saria, S., Nodelman, U., & Koller, D. (2007). Reasoning at the right time granularity. In
Proceedings of the Twenty-third Conference on Uncertainty in AI, pp. 421430.
Sarkka, S. (2006). Recursive Bayesian Inference on Stochastic Differential Equations. Ph.D.
thesis, Helsinki University of Technology.
Shimony, S. E. (1991). Explanation, irrelevance and statistical independence. In Proceedings
of the Ninth National Conference on Artificial Intelligence, pp. 482487.
Wan, M., Ciardo, G., & Miner, A. S. (2011). Approximate steady-state analysis of large
Markov models based on the structure of their decision diagram encoding. Performance Evaluation, 68, 463486.
Warrender, C., Forrest, S., & Pearlmutter, B. (1999). Detecting intrusions using system
calls: Alternative data models. In IEEE Symposium on Security and Privacy, IEEE
Computer Society.
Weiss, J. C., Natarajan, S., & Page, D. (2012). Multiplicative forests for continuous-time
processes. In Advanced in Neural Information Processing Systems.
Weiss, J. C., & Page, D. (2013). Forest-based point processes for event prediction from electronic health records. In Proceedings of the European Conference in Machine Learning and Principals and Practice of Knowledge and Discovery in Databases (ECMLPKDD).
Williams, C. K. I. (1998). Prediction with Gaussian processes: From linear regression to
linear prediction and beyond. In Jordan, M. I. (Ed.), Learning in Graphical Models,
pp. 599621.
Xu, J., & Shelton, C. R. (2008). Continuous time Bayesian networks for host level network
intrusion detection. In European Conference on Machine Learning, pp. 613627.
Xu, J., & Shelton, C. R. (2010). Intrusion detection using continuous time Bayesian networks. Journal of Artificial Intelligence Research, 39, 745774.

778

fiJournal of Artificial Intelligence Research 51 (2014) 645-705

Submitted 05/14; published 12/14

The Complexity of Answering Conjunctive and Navigational
Queries over OWL 2 EL Knowledge Bases
Giorgio Stefanoni
Boris Motik

giorgio.stefanoni@cs.ox.ac.uk
boris.motik@cs.ox.ac.uk

Department of Computer Science, University of Oxford
Parks Road, Oxford OX1 3QD, United Kingdom

Markus Krotzsch
Sebastian Rudolph

markus.kroetzsch@tu-dresden.de
sebastian.rudolph@tu-dresden.de

Faculty of Computer Science, TU Dresden
Nothnitzer Strae 46, 01062 Dresden, Germany

Abstract
OWL 2 EL is a popular ontology language that supports role inclusionsaxioms of the
form S1    Sn v S that capture compositional properties of roles. Role inclusions closely
correspond to context-free grammars, which was used to show that answering conjunctive
queries (CQs) over OWL 2 EL knowledge bases with unrestricted role inclusions is undecidable. However, OWL 2 EL inherits from OWL 2 DL the syntactic regularity restriction on
role inclusions, which ensures that role chains implying a particular role can be described
using a finite automaton (FA). This is sufficient to ensure decidability of CQ answering;
however, the FAs can be worst-case exponential in size so the known approaches do not
provide a tight upper complexity bound.
In this paper, we solve this open problem and show that answering CQs over OWL
2 EL knowledge bases is PSpace-complete in combined complexity (i.e., the complexity
measured in the total size of the input). To this end, we use a novel encoding of regular role
inclusions using bounded-stack pushdown automatathat is, FAs extended with a stack of
bounded size. Apart from theoretical interest, our encoding can be used in practical tableau
algorithms to avoid the exponential blowup due to role inclusions. In addition, we sharpen
the lower complexity bound and show that the problem is PSpace-hard even if we consider
only role inclusions as part of the input (i.e., the query and all other parts of the knowledge
base are fixed). Finally, we turn our attention to navigational queries over OWL 2 EL
knowledge bases, and we show that answering positive, converse-free conjunctive graph
XPath queries is PSpace-complete as well; this is interesting since allowing the converse
operator in queries is known to make the problem ExpTime-hard. Thus, in this paper we
present several important contributions to the landscape of the complexity of answering
expressive queries over description logic knowledge bases.

1. Introduction
Description logics (DLs) (Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2010)
are a family of knowledge representation formalisms that logically underpin the Web Ontology Language OWL 2 (Cuenca Grau, Horrocks, Motik, Parsia, Patel-Schneider, & Sattler,
2008). DL knowledge bases describe a domain in terms of concepts (i.e., unary predicates),
roles (i.e., binary predicates), and individuals (i.e., constants), and they describe the relationships between concepts, roles, and individuals using logical axioms. DLs and OWL

c
2014
AI Access Foundation. All rights reserved.

fiStefanoni, Motik, Krotzsch, & Rudolph

2 have been steadily gaining in popularity because they provide the developers of modern
information systems with a flexible graph-like data model that is natural in countless application areas, such as the Semantic Web (Gutierrez, Hurtado, Mendelzon, & Perez, 2011),
social network analysis (Fan, 2012), and network traffic analysis (Barrett, Jacob, & Marathe,
2000). Answering queries over DL/OWL knowledge bases is the core service in applications
as diverse as monitoring financial products within the Italian Ministry of Economy and
Finance (De Giacomo et al., 2012), accessing real-time diagnostic data of turbines (Giese
et al., 2013), and integrating configuration data of air traffic control systems (Calvanese
et al., 2011). Due to the practical importance of query answering, theoretical investigation
of the expressivity and computational complexity of query languages has been high up on
the research agenda of the knowledge representation community in the past decade.
Conjunctive queries (CQs) (Chandra & Merlin, 1977) are the basic class of queries in
relational databases. Querying DL knowledge bases using CQs has been studied in a diverse range of settings (Calvanese, De Giacomo, Lembo, Lenzerini, & Rosati, 2007; PerezUrbina, Motik, & Horrocks, 2010; Rudolph & Glimm, 2010; Kontchakov, Lutz, Toman,
Wolter, & Zakharyaschev, 2011; Ortiz, Rudolph, & Simkus, 2011; Gottlob & Schwentick,
2012; Venetis, Stoilos, & Stamou, 2012). However, conjunctive queries are first-order definable and thus cannot express certain important properties such as graph reachability.
Regular path queries (RPQs) (Cruz, Mendelzon, & Wood, 1987; Barcelo, 2013) are an alternative query language capable of describing connections between graph vertices using
regular expressions, allowing users to navigate inside a graph. For example, the RPQ
(isPartOf   hasLocation) retrieves all pairs of vertices connected via zero or more isPartOf
edges followed by one hasLocation edge. Furthermore, 2RPQs extend RPQs with the converse operator (i.e., backward navigation) (Calvanese, Vardi, De Giacomo, & Lenzerini,
2000); nested regular expressions allow for existential quantification over paths (Perez,
Arenas, & Gutierrez, 2010); and C(2)RPQs extend both (2)RPQs and CQs to conjunctions of (2)RPQs (Calvanese, De Giacomo, Lenzerini, & Vardi, 2000; Bienvenu, Ortiz, &
Simkus, 2013). Finally, inspired by the XPath query language for XML, graph XPath queries
(GXQs) have been recently proposed as a language for querying graph databases (Libkin,
Martens, & Vrgoc, 2013) and DL knowledge bases (Kostylev, Reutter, & Vrgoc, 2014; Bienvenu, Calvanese, Ortiz, & Simkus, 2014). GXQs extend 2RPQs with negation on regular
expressions, and checking properties of vertices using Boolean combinations of node tests
that is, concepts or existential quantifications over paths. For example, the graph XPath
query (isPartOf   test(Cell  hhasSpecialityi)  hasLocation) refines the aforementioned RPQ
by requiring that the node between the isPartOf edges and the hasLocation edge is an instance of the Cell concept and does not have an outgoing hasSpeciality edge. Graph XPath
queries can be straightforwardly extended to conjunctive graph XPath queries (CGXQs). A
query in any of these languages is Boolean if it has no answer variables; hence, an answer
to such a query is a Boolean value.
1.1 Problem Setting
Although computing answers to a query over a DL knowledge base is a function problem, it
is common in the literature to consider the complexity of the associated decision problem
that is, of checking whether a Boolean query is entailed by the knowledge base. In this article

646

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

we follow this well-established practice and analyse the computational properties of several
query languages over DL knowledge bases. We follow Vardi (1982) and measure the input
size in two ways: combined complexity measures the complexity in terms of the combined
size of the query and the knowledge base, while data complexity measures the complexity
in terms of the size of the data (i.e., the query and all other parts of the knowledge bases
are considered to be fixed).
The computational properties of query answering over DL knowledge bases depend on
the expressivity of both the constructs used in the knowledge base and the query language
used. In particular, conjunctive query answering over expressive description logics is at
least exponential in combined complexity (Glimm, Lutz, Horrocks, & Sattler, 2008; Lutz,
2008) and intractable in data complexity (Calvanese, De Giacomo, Lembo, Lenzerini, &
Rosati, 2013; Ortiz, Calvanese, & Eiter, 2008). The problem becomes tractable in data
complexity for the RL (Grosof, Horrocks, Volz, & Decker, 2003; ter Horst, 2005) and the
QL (Calvanese et al., 2007; Artale, Calvanese, Kontchakov, & Zakharyaschev, 2009) profiles
of OWL 2, and several worst-case optimal algorithms have been proposed that perform well
in practice (Urbani, van Harmelen, Schlobach, & Bal, 2011; Rodriguez-Muro & Calvanese,
2012). In this paper, however, we focus on the OWL 2 EL profile of OWL 2, which is based
on the EL family of DLs (Baader, Brandt, & Lutz, 2005). Basic reasoning problems for
OWL 2 EL, such as checking concept subsumption and instance checking, can be decided
in polynomial time (Baader et al., 2005; Krotzsch, 2011), which makes this language very
interesting for practical applications. Motivated by this observation, in this paper we present
several novel complexity results for answering queries over OWL 2 EL knowledge bases.
One of the important modelling constructs of OWL 2 EL are role inclusionsaxioms
of the form S1    Sn v S that express compositional properties of roles. For example, the
following inclusions state that role isPartOf is transitive and that, if x is located in y and y
is part of z, then x is located in z.
isPartOf  isPartOf v isPartOf

hasLocation  isPartOf v hasLocation

Prior to the introduction of the EL family, role inclusions had already been identified as
a source of undecidability in expressive DLs because they loosely correspond to context-free
grammars: if each inclusion S1    Sn v S in a knowledge base is seen as a production rule
S  S1    Sn , then the knowledge base induces a context-free language L(S) for each role
S. Using this correspondence, Wessel (2001) showed that checking satisfiability of ALCR
knowledge bases with unrestricted role inclusions is undecidable. To regain decidability,
Horrocks and Sattler (2004) proposed a syntactic regularity restriction on role inclusions
ensuring that each language L(S) is regular and can thus be recognised using a finite
automaton (FA); Kazakov (2008) later showed that, in some cases, the size of this automaton
is necessarily exponential in the knowledge base size. The OWL 2 DL profile of OWL 2
extends ALCR and thus incorporates the regularity restriction into its definition.
Even with unrestricted role inclusions, all standard reasoning problems for EL can be
solved in polynomial time (Baader et al., 2005). Moreover, Stefanoni, Motik, and Horrocks
(2013) showed that answering CQs over OWL 2 EL knowledge bases without role inclusions
is NP-complete. However, using the correspondence between role inclusions and contextfree grammars, Rosati (2007) and Krotzsch, Rudolph, and Hitzler (2007) independently
proved that answering CQs over EL knowledge bases with unrestricted role inclusions is
647

fiStefanoni, Motik, Krotzsch, & Rudolph

undecidable; furthermore, Krotzsch et al. (2007) also showed that checking concept subsumptions over EL knowledge bases with inverse roles and unrestricted role inclusions is
undecidable.
OWL 2 EL inherits the regularity restriction from OWL 2 DL, and so the undecidability proofs by Rosati (2007) and Krotzsch et al. (2007) do not apply to OWL 2 EL. In
fact, Krotzsch et al. (2007) showed that answering CQs over EL knowledge bases extended
with regular role inclusions is PSpace-hard in combined complexity, and they proposed a
CQ answering algorithm for a fragment of OWL 2 EL with regular role inclusions. This
algorithm, however, runs in PSpace only if, for each role S, language L(S) can be represented using an automaton of polynomial size; due to the mentioned result by Kazakov
(2008), this approach does not provide us with a matching PSpace upper bound for the
problem. Ortiz et al. (2011) proposed a different algorithm for answering CQs over OWL 2
EL knowledge bases (with regular role inclusions and without any restriction on the usage
of other features). Similarly to the algorithm by Krotzsch et al. (2007), the algorithm by
Ortiz et al. (2011) also encodes regular role inclusions using finite automata. Hence, while
both of these algorithms run in time polynomial in the size of the data and thus settle the
question of data complexity, they do not settle the question of combined complexity.
There are comparatively few works on studying the complexity of (conjunctive) graph
XPath queries over DL knowledge bases. In particular, Kostylev et al. (2014) observed that
GXQs are closely related to propositional dynamic logic with full negation (Harel, Tiuryn,
& Kozen, 2000), which immediately shows that answering GXQs over DL knowledge bases
is undecidable even with respect to the empty knowledge base. Several GXQ fragments
were proposed as a possible solution to this problem: path-positive GXQs disallow negation
over role expressions, and positive GXQs further prohibit negation over concepts as well.
Kostylev et al. (2014) showed that answering path-positive GXQs is intractable in data
complexity already for queries without the transitive closure operator and for knowledge
bases containing only instance assertions. Recently, Bienvenu et al. (2014) showed that
answering positive GXQs in a fragment of OWL 2 EL is tractable in data complexity, but
ExpTime-complete in combined complexity.
1.2 Our Contributions
In this paper, we present several novel complexity results on answering queries over OWL 2
EL knowledge bases.
First, we present the first CQ answering algorithm that can handle all of OWL 2 EL
(with regular role inclusions but without any restriction on the size of the FAs) and that
runs in PSpace, and thus we settle the open question of the combined complexity of
CQ answering for OWL 2 EL. Our result is based on a novel encoding of the languages
induced by regular role inclusions using pushdown automata (PDAs)that is, FAs extended
with a stack. We show that, for each role S, we can construct in polynomial time a
PDA that accepts language L(S) and whose computations use a stack of size linear in the
number of role inclusions. Bounded-stack PDAs (Anselmo, Giammarresi, & Varricchio,
2003) recognise precisely the class of regular languages and can be exponentially more
succinct than finite automata (Geffert, Mereghetti, & Palano, 2010). To obtain a CQ
answering algorithm running in PSpace, we extend the algorithm by Krotzsch et al. (2007)

648

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

data
combined

ELHOdr

PTime

OWL 2 EL
PTime

Horn-SHOIQ
PTime

Horn-SROIQ
PTime

(Ortiz et al., 2011)

(Theorem 31)

(Ortiz et al., 2011)

(Ortiz et al., 2011)

NP

PSpace

ExpTime

2ExpTime

(Stefanoni et al., 2013)

(Theorem 31)

(Ortiz et al., 2011)

(Ortiz et al., 2011)

Table 1: The complexity landscape of CQ answering (all are completeness results)
to handle the universal role, keys, self-restrictions, and reflexive roles, thus covering all
features of the EL profile apart from datatypes, and we adapt it so that it can handle
regular role inclusions encoded using PDAs. Apart from allowing us to obtain the complexity
results presented in this paper, the tableau algorithm by Horrocks, Kutz, and Sattler (2006)
used in popular reasoners such as Pellet (Sirin, Parsia, Cuenca Grau, Kalyanpur, & Katz,
2007) and FaCT++ (Tsarkov & Horrocks, 2006) can be straightforwardly modified to use
bounded-stack PDAs instead of FAs, which could eliminate a potential source of inefficiency
in practice. Finally, for brevity and simplicity we do not deal with datatypes in this paper;
however, the set of OWL 2 EL datatypes has been designed so as to enable datatype
reasoning using an external datatype checking procedure (Baader, Brandt, & Lutz, 2008;
Cuenca Grau et al., 2008) that can be easily incorporated into our algorithm.
Second, we improve the PSpace lower bound by Krotzsch et al. (2007) by showing
that answering CQs in OWL 2 EL is PSpace-hard already if just the role inclusions are
considered as part of the input (i.e., the conjunctive query, the TBox, and the ABox are all
fixed). Furthermore, we show that CQs can be answered in polynomial time if the query
and the role inclusions are fixed, which emphasises the observation that role inclusions are
the main source of the problems PSpace-hardness.
Third, we show that positive, converse-free CGXQsthat is, CGXQs that do not allow
for negation over paths, negation of concepts, and the converse operatorcan be answered
over OWL 2 EL knowledge bases using polynomial space. In particular, OWL 2 EL allows
for role inclusions, self-restrictions, and reflexive roles, which allow us to polynomially reduce answering a CGXQ to answering a CQ over an extended knowledge base. We also
show that answering positive, converse-free GXQs (i.e., CGXQs with a single atom) can
be done in time polynomial in the input size. This result is interesting because Bienvenu
et al. (2014) proved that answering positive GXQs over EL knowledge bases is ExpTimecomplete; hence, adding the converse operator increases the complexity of GXQs. Our
results thus show that answering GXQs and CGXQs is as difficult as instance checking and
answering conjunctive queries, respectively, which at least from a theoretical perspective
makes GXQs and CGXQs appealing as query languages for OWL 2 EL knowledge bases.
1.3 Summary of the Complexity Landscape
Table 1 summarises the complexity landscape of answering CQs in various DLs related to
OWL 2 EL. Here, ELHOdr
 is the fragment of OWL 2 EL obtained by allowing only simple
role inclusions of the form T v S, and by disallowing the universal role, reflexive roles,
self-restrictions, and datatypes, and the combined complexity result for this logic is due to
Stefanoni et al. (2013). Furthermore, Horn-SHOIQ extends ELHOdr
 with inverse roles
and Horn qualified number restrictions, and Horn-SROIQ extends Horn-SHOIQ with role
649

fiStefanoni, Motik, Krotzsch, & Rudolph

data

positive
positive
converse-free converse-free
GXQs
CGXQs
PTime-c
PTime-c
(Theorem 34)

combined

PTime-c
(Theorem 34)

positive
GXQs

path-positive
GXQs

GXQs

PTime-h

coNP-h

coNP-h

(Theorem 34) (Bienvenu et al., 2014) (Kostylev et al., 2014) (Kostylev et al., 2014)

PSpace-c

ExpTime-h

ExpTime-h

undecidable

(Theorem 34) (Bienvenu et al., 2014) (Bienvenu et al., 2014) (Kostylev et al., 2014)

Table 2: The complexity of answering navigational queries over OWL 2 EL knowledge bases
(c means complete, and h means hard)

inclusions; the results for these logics are due to Ortiz et al. (2011). CQ answering is PTimecomplete in data complexity in all cases, which is essentially due to the fact that all of these
logics are Horn so no disjunctive reasoning is needed. For the combined complexity, the
table illustrates how the presence of different constructs affects the complexity of answering
CQs. In particular, extending ELHOdr
 with role inclusions increases the complexity from
NP to PSpace; by our PSpace lower bound, this increase is solely due to role inclusions.
Furthermore, extending ELHOdr
 with inverse roles increases the complexity from NP to
ExpTime. Finally, extending OWL 2 EL with inverse roles increases the complexity from
PSpace to 2ExpTime.
Table 2 summarises the complexity landscape of answering navigational queries over
OWL 2 EL knowledge bases. As one can see, adding the converse operator increases the
combined complexity of GXQs to ExpTime (Bienvenu et al., 2014). Moreover, adding
negation over node tests increases the data complexity of GXQs to coNP, whereas adding
negation over path expressions leads to the undecidability in combined complexity (Kostylev
et al., 2014). In contrast, existential quantification over paths does not increase the complexity: answering positive, converse-free (C)GXQs over OWL 2 EL knowledge bases is as
difficult as answering (C)RPQs over EL knowledge bases (Bienvenu et al., 2013).
1.4 Organisation of the Article
The rest of this article is organised as follows. In Section 2, we present the basic definitions
of finite automata, pushdown automata, the DL underpinning OWL 2 EL, and conjunctive
queries. In Section 3, we introduce our novel encoding of regular role inclusions using PDAs
of bounded stack size. In Section 4, we present the CQ answering algorithm for OWL 2
EL and discuss its complexity. In Section 5, we present our improved PSpace lower-bound
of answering CQs in OWL 2 EL. Finally, in Section 6, we introduce (conjunctive) graph
XPath queries, we show how to reduce the problem of answering positive, converse-free
conjunctive graph XPath queries to answering ordinary conjunctive queries, and we present
the aforementioned complexity results.

650

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

2. Preliminaries
In this section we recapitulate the basic definitions of finite automata, pushdown automata,
the DL ELRO+ underpinning OWL 2 EL, and conjunctive queries. In the rest of the paper,
[i..j] is the set containing each natural number k  N such that i  k  j.
2.1 Automata and Language Theory
In this article, we use the standard notions of alphabets (which must be finite), strings, string
concatenation, Kleene operators, and languages from formal language theory (Hopcroft,
Motwani, & Ullman, 2003). We assume that alphabets do not contain the special symbol
, which we will use to label transitions in automata that do not consume input symbols.
Furthermore,  is the empty word. Finally, for w and w0 words, |w| is the number of symbols
occurring in w; and w  w0 is the unique word w00 such that w := w00  w0 if such w00 exists,
and otherwise w  w0 is undefined.
2.1.1 Finite Automata
A finite automaton (FA) is a tuple F = hQ, , , i, f i where Q is a finite set of states,  is
the input alphabet,  : Q    {} 7 2Q is the transition function, i  Q is the start state,
and f  Q is the final state. Such F is deterministic if |(s, )| = 0 and |(s, c)|  1 for each
s  Q and each c  ; otherwise, F is nondeterministic. The size |F| of F is the number
of symbols used to encode F on a tape of a Turing machine.
An instantaneous description of F is a pair hs, wi such that s  Q and w   . The
derivation relation ` for F is the smallest set such that, for all states s and s0 in Q, each
symbol c  , and each word w   , we have
 if s0  (s, c), then hs, c  wi ` hs0 , wi; and
 if s0  (s, ), then hs, wi ` hs0 , wi.
Let ` be the reflexive and transitive closure of `. Then, the language accepted by F is
defined as L(F) = {w   | hi, wi ` hf, i}. A language L is regular if and only if an FA
F exists such that L = L(F).
2.1.2 Pushdown Automata
A pushdown automaton (PDA) is a tuple P = hQ, , , , i, I, f, F i where Q is a finite set
of states;  is the input alphabet;  is the stack alphabet;  is a transition function mapping
each state s  Q, each symbol c    {}, and each stack symbol X   to a finite subset
(s, c, X)  Q   ; i  Q is the start state; I   is the start stack ; f  Q is the final
state; and F   is the final stack. The size |P| of P is the number of symbols used to
encode P on a tape of a Turing machine.
An instantaneous description of P is a triple hs, w, i such that s  Q, w   , and
   . We read the stack content  from left to rightthat is, the leftmost symbol in  is
the top of the stack. The derivation relation ` for P is the smallest set such that, for all
states s and s0 in Q, each symbol c  , each word w   , each stack symbol X  , and
all words  and  0 in  , we have

651

fiStefanoni, Motik, Krotzsch, & Rudolph

 hs0 ,  0 i  (s, c, X) implies hs, c  w, X  i ` hs0 , w,  0  i; and
 hs0 ,  0 i  (s, , X) implies hs, w, X  i ` hs0 , w,  0  i.
Let ` be the reflexive and transitive closure of relation `. Then, the language accepted by
P is defined as L(P) = {w   | hi, w, Ii ` hf, , F i}.
Our definitions of a PDA P and of a language L(P) are somewhat nonstandard: the
literature typically considers a Hopcroft PDA (Hopcroft et al., 2003) Ph that differs from
our definition in that it does not contain the final stack F and its initial stack I is a symbol
from  (rather than a word over ); moreover, the language accepted by Ph is defined as
Lh (Ph ) = {w   |    : hi, w, Ii ` hf, , i}. We show next that our definitions are
equivalent to the standard definitions by Hopcroft et al. (2003).
Proposition 1. The following two properties hold.
(1) For each PDA P, a Hopcroft PDA Ph exists such that L(P) = Lh (Ph ).
(2) For each Hopcroft PDA Ph , a PDA P exists such that Lh (Ph ) = L(P).
Proof (Sketch). We first prove property (1), after which we prove property (2).
(1) We show how to transform an arbitrary PDA P into a Hopcroft PDA Ph such that
L(P) = Lh (Ph ). Such Ph uses a fresh initial state i0 and fresh stack symbols Z0 and 
not occurring in . Symbol Z0 is the start stack symbol of Ph ; furthermore, Ph has a new
-transition that moves the PDA from state i0 to the initial state i of P by replacing Z0
with I  , where I is the start stack of P. At this point, Ph simulates P, always leaving
 at the bottom of the stack until it reaches the final state f of P. Next, Ph uses fresh
states s1 , . . . , s|F | and fresh -transitions that move Ph from state f to s|F | by reading F
from the stack. Finally, from s|F | , PDA Ph -moves to a fresh final state f 0 if the top-most
symbol on the stack is , thus accepting the input whenever P reaches f with F on its
stack. Automata P and Ph clearly accept the same languages.
(2) We show how to transform an arbitrary Hopcroft PDA Ph into a PDA P such that
Lh (Ph ) = L(P). PDA P uses a fresh stack symbol , its initial stack is I   where I is
the initial stack symbol of Ph , and its final stack is the empty word. Then P simulates Ph ,
always leaving  at the bottom of the stack until it reaches the final state f of Ph . Next, P
-moves to a fresh final state f 0 and pops the topmost symbol off the stack. At this point,
the PDA takes further -transitions to empty its stack, eventually reaching its final state
with the empty stack. Automata P and Ph clearly accept the same languages.
For k a natural number, the k-bounded language accepted by P is the set Lk (P) containing each word w   for which a derivation hs0 , w0 , 0 i `    ` hsn , wn , n i exists where
 s0 and sn are the start and the final state of P, respectively;
 w0 = w and wn = ;
 0 and n are the start and the final stack of P, respectively; and
 |i |  k for each i  [0..n].

652

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

Then, P has a k-bounded stack if L(P) = Lk (P). As the stack of P is bounded by a
constant, PDA P can be simulated by a finite automaton that encodes the stack contents
using its states, and so L(P) is regular, but translating P into a finite automaton may
require space exponential in k (Geffert et al., 2010). In contrast, the following proposition
shows that there exists a PDA Pk such that L(Pk ) = Lk (P) and the size of Pk is polynomial
in the size of P and k.
Proposition 2. For each PDA P and natural number k, one can compute in polynomial
time a PDA Pk such that L(Pk ) = Lk (P).
Proof. Let P = hQ, , , , i, I, f, F i be a PDA and let k  N be a natural number. Let
Pk = hQk , , , k , ik , I, fk , F i be the PDA defined by
 Qk = Q  [0..k];
 transition function k is the smallest function such that, for each `  [0..k], each symbol
c    {}, all states s, s0  Q, and each word    such that hs0 , i  (s, c, X)
and ` + ||  1  k, we have hhs0 , ` + ||  1i, i  k (hs, `i, c, X); and
 ik = hi, |I|i and fk = hf, |F |i.
Clearly, Pk can be computed in time polynomial in the size of P and k. Let ` and `k be
the derivation relations for P and Pk , respectively. By the definitions of k and ik , we have
that hhs, `i, w, i `k hhs0 , ji, w0 ,  0 i if and only if hs, w, i ` hs0 , w0 ,  0 i, || = ` and | 0 | = j,
and max(`, j)  k. Thus, we have Lk (P) = L(Pk ), as required.
2.2 Description Logic ELRO+ and Conjunctive Queries
The description logic ELRO+ , underpinning OWL 2 EL, is defined w.r.t. a signature consisting of mutually disjoint and countably infinite alphabets C, R, and I of atomic concepts,
roles, and individuals, respectively. We assume that {>c , c }  C, where >c is the top
concept and c is the bottom concept; similarly, we assume that {>r , r }  R, where >r is
the top role (universal role) and r is the bottom role. For each individual a  I, expression
{a} is a nominal that is, a concept consisting precisely of individual a. Then, N is the set
containing nominal {a} for each individual a  I. We call each B  C  N a basic concept.
A role chain  is a word over R; for || = 0, we call  the empty role chain and we write it
as . Concepts, TBox axioms, RBox axioms, and ABox axioms are defined as specified in
Table 3. An ELRO+ TBox T is a finite set of concept inclusions, range restrictions, and
keys; and an ELRO+ RBox R is a finite set of role inclusions.
For R an ELRO+ RBox, let R := {>r }  {S  R | S occurs in R}; furthermore, the
rewrite relation =
 w.r.t. R is the smallest relation on role chains such that the following
holds for all role chains 1 and 2 .
 1  S  2 =
 1    2 for each axiom  v S  R.
 1  >r  2 =
 1    2 for each role chain   R .
Then =
 is the reflexivetransitive closure of 
= . For S a role, L(S) := {  R | S =
 }
is the language induced by RBox R. A role S is simple in R if, for each role chain  with
653

fiStefanoni, Motik, Krotzsch, & Rudolph

Concepts:
top concept
bottom concept
nominal
conjunction
self-restriction
existential restriction
Role chains:
top role
bottom role
empty role chain
nonempty role chain
TBox axioms:
concept inclusion
range restriction
key

RBox axioms:
role inclusion
ABox axioms:
concept assertion
role assertion

Syntax

Semantics

>c
c
{a}
C uD
S.Self
S.C

I

{aI }
C I  DI
{x  I | hx, xi  S I }
{x  I | y  C I : hx, yi  S I }

>r
r

S1    Sn

I  I

{hx, xi | x  I }
S1I      SnI

CvD
range(S, C)
key(C, S1 . . . Sn )

C I  DI
S I  I  C I
For all x, y, z1 , . . . , zn in I such that
individuals a, b, c1 , . . . , cn in I exist with
x = aI , y = bI , and zi = cIi for 1  i  n,
x = y holds whenever {x, y}  C I and
{hx, zi i, hy, zi i}  SiI for 1  i  n.

vS

I  S I
bI  S I
 SI

A(b)
S(a, b)

haI , bI i

Table 3: Interpreting ELRO+ concepts, roles, and axioms in an interpretation I = hI , I i

S=
 , we have ||  1. An ELRO+ ABox A is a finite set of concept and role assertions.
Finally, an ELRO+ knowledge base (KB) is a tuple K = hT , R, Ai where T is an ELRO+
TBox, R is an ELRO+ RBox, and A is an ELRO+ ABox such that
 for each concept S.Self occurring in T , role S is simple in R; and
 for each S1    Sn v S  R and each range(S 0 , C)  T such that S 0 =
 S, a role Sn0  R
0

0
exists such that Sn =
 Sn and range(Sn , C)  T .
Let |T |, |R|, and |A| be the numbers of symbols needed to encode T , R, and A, respectively,
on a tape of a Turing machine, and let |K| = |T |+|R|+|A|. Furthermore, for  a knowledge
base, a TBox, or an ABox, we define
I := {a  I | a occurs in }, N := {{a} | a  I }, and C := {A  C | A occurs in }.
654

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

The semantics of ELRO+ is defined as follows. An interpretation is a tuple I = hI , I i
where I is a nonempty set of domain elements, called the domain of I, and I is the interpretation function that maps each individual a  I to a domain element aI  I , each
atomic concept A  C \ {>c , c } to a set AI  I , and each atomic role S  R \ {>r , r }
to a relation S I  I  I . Function I is extended to concepts and role chains as shown
in the upper part of Table 3, where  denotes composition of binary relations. An interpretation I is a model of K if it satisfies all axioms occurring in K as shown at the bottom of
Table 3. Moreover, K is consistent if a model of K exists; K is inconsistent if no model of
K exists; and K entails a first-order sentence  (resp. a concept inclusion C v D or a role
inclusion  v S), written K |=  (resp. K |= C v D or K |=  v S), if I |=  (resp. C I  DI
or I  S I ) for each model I of K. By the definition of L(S), we have that   L(S) implies
K |=  v S. Knowledge base consistency, entailment of concept inclusions, and entailment
of role inclusions can be decided in polynomial time (Krotzsch, 2011; Baader et al., 2005).
2.2.1 Conjunctive Queries
A term is an individual or a variable. An atom is an expression of the form A(t) or R(t0 , t)
where A is an atomic concept, R is a role, and t0 and t are terms. A conjunctive query (CQ)
is a formula q = ~y .(~x, ~y ) with  a conjunction of atoms over variables ~x  ~y . Variables ~x
are the answer variables of q. When ~x is empty, we call q = ~y .(~y ) a Boolean CQ (BCQ).
A substitution  is a partial mapping from variables to terms; and dom() and rng()
are the domain and the range of , respectively. For  a conjunction of atoms, () is the
result of applying substitution  to the atoms in . Then, (q) = ~z.(), where ~z contains
(i) (y) for each variable y  ~y such that (y) is a variable, and (ii) each variable y  ~y such
that (y) is undefined. Our definition of (q) is somewhat nonstandard because quantified
variables can also be replaced: for example, given q = y1 , y2 , y3 .R(y1 , y2 )  T (y1 , y3 ) and
 = {y2 7 a, y3 7 z}, we have (q) = y1 , z.R(y1 , a)  T (y1 , z).
Let K = hT , R, Ai be an ELRO+ knowledge base and let q = ~y .(~x, ~y ) be a CQ. Then
q is over K if q uses only the predicates and the individuals occurring in K. A substitution
 is a candidate answer for q over K, if dom() = ~x and rng()  IK , and such  is a certain
answer to q over K if and only if K |= (q). Answering q over K amounts to computing
the set of all certain answers to q over K. As stated, CQ answering is a function problem;
thus in this article we study the complexity of the associated decision problem named BCQ
answering, which is the problem of deciding, given a Boolean CQ q over K, whether K |= q.
Please note that BCQ answering is equivalent to the recognition problem which decides,
given a CQ q over K and a candidate answer , whether  is a certain answer to q over K.
Following Vardi (1982), combined complexity assumes that both q and K are part of the
input, and data complexity assumes that only the ABox A is part of the input.
2.3 Ensuring Decidability of BCQ Answering via Regularity
Rosati (2007) and Krotzsch et al. (2007) independently showed that answering Boolean
CQs over ELRO+ knowledge bases is undecidable. Intuitively, role inclusions can simulate derivations in context-free languages; thus, a Boolean CQ can check whether two
context-free languages have a non-empty intersection, which is a known undecidable problem (Hopcroft et al., 2003).

655

fiStefanoni, Motik, Krotzsch, & Rudolph

To regain decidability, we next recapitulate the definition of so-called regular RBoxes
by Horrocks and Sattler (2004). Let R be an ELRO+ RBox and let  be the smallest
transitive relation on R such that, for each   T  0 v S  R with S 6= T , we have T  S.
Then, RBox R is regular if  is irreflexive and each role inclusion  v S  R is of the form
(t1)  v S,
(t2) S  S v S,
(t3) S1    Sn  S v S and Si 6= S for each i  [1..n],
(t4) S1    Sn v S and Si 6= S for each i  [1..n], or
(t5) S  S1    Sn v S and Si 6= S for each i  [1..n].
By induction on  we then define the level lv(S) of each role S  R as follows: lv(S) = 0
if no T  R exists such that T  S; otherwise, lv(S) = 1 + max{lv(T ) | T  S}. Clearly,
lv(S) can be computed in time polynomial in |R|. In Section 4 we show that BCQ answering
over ELRO+ KBs with regular RBoxes is in PSpace.
2.4 Normalising ELRO+ Knowledge Bases
For simplicity, in the rest of this paper we assume that each ELRO+ knowledge base
K = hT , R, Ai is normalised, which is the case if the following properties hold.
(n1) We have IK 6= , and K 6|= {a} v {b} for all {a, b}  IK with a 6= b.
(n2) Each axiom in T is of one of the following forms, for A(i) basic concepts and S a role.
A1 u A2 v A3

A1 v S.A2

S.A1 v A2

A v S.Self

S.Self v A

(n3) Each axiom  v S  R is such that ||  2 and S 6= >r , and each role in T  A also
occurs in R.
We next show that each knowledge base K can be normalised in polynomial time without
affecting the regularity of the RBox component nor the answers to Boolean CQs.
Proposition 3. For each ELRO+ knowledge base K with a regular RBox and each Boolean
CQ q over K, one can compute in polynomial time a normalised ELRO+ knowledge base
K0 and a Boolean CQ q 0 such that
 the RBox of K0 is regular, and
 q 0 is over K0 , and K |= q if and only if K0 |= q 0 .
Proof. Let K be an ELRO+ KB with regular RBox and let q be a Boolean CQ over K.
We first satisfy property (n1). Let K1 be obtained from K by extending the ABox
of K with assertion >c (c) for c a fresh individual; clearly, K1 |= q if and only if K |= q.
Next, let K2 and q 0 be obtained from K1 and q, respectively, by uniformly substituting each
individual a with an arbitrary, but fixed, individual b such that K1 |= {a} v {b}. Entailment
656

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

of concept inclusions can be decided in polynomial time, so K2 and q 0 can be computed in
polynomial time. Moreover, K2 and q 0 are obtained by replacing each individual a with an
arbitrary, but fixed individual b such that aI = bI for each model I of K1 , so q 0 is over K2 ,
and K2 |= q 0 if and only if K1 |= q.
We next satisfy property (n2). Let K3 be the result of eliminating all keys from K2 . As
one can see from Table 3, keys can only derive axioms of the form {a} v {b}; moreover,
the effects of such conclusions have already been captured by K2 , and so K3 |= q 0 if and
only if K2 |= q 0 . Next, we eliminate in polynomial time all range restrictions occurring in
K by applying the syntactic transformation by Baader et al. (2008); let K4 be the resulting
knowledge base. Since the definition of ELRO+ knowledge base carefully restricts the
interactions between role inclusions and range restrictions, we have K4 |= q 0 if and only if
K3 |= q 0 (Baader et al., 2008). Next, following Krotzsch (2011), we compute in polynomial
time a knowledge base K5 that satisfies (n2) such that K5 |= q 0 if and only if K4 |= q 0 .
We next satisfy property (n3). Let K6 be the result of exhaustively decomposing each
role inclusion  v S of the form (t3)(t5) with || > 2 occurring in K5 according to the
following rewrite rules, where each occurrence of role S 0 is fresh.
(t3) S1    Sn  S v S 7 {S 0  S v S,
S 1    Sn v S 0 }
0
(t4)
S1    Sn v S 7 {S  Sn v S, S1    Sn1 v S 0 }
(t5) S  S1    Sn v S 
7
{S  S 0 v S,
S 1    Sn v S 0 }
Only linearly many rewrite steps are required to satisfy (n3), and the resulting RBox is
regular. Furthermore, each model of K6 is also a model of K5 and each model I of K5
can be expanded to a model J of K6 by interpreting each role S 0 occurring in K6 \ K5 as
(S 0 )J = (0 )J , where 0 is the unique role chain such that 0 v S 0 occurs in K6 . Thus, we
have K6 |= q 0 if and only if K5 |= q 0 . Next, let K7 be the result of removing each axiom
 v >r in K6 ; all removed axioms are tautologies, so we have K7 |= q 0 if and only if K6 |= q 0 .
Finally, let K0 be the result of adding axiom r v S, for each role S that occurs in K7 but
does not occur in its RBox component. The axioms in K0 \ K7 preserve regularity and are
tautologies, so K0 |= q 0 if and only if K7 |= q 0 , as required.

3. Encoding Regular RBoxes Succinctly Using Bounded-Stack PDAs
Each reasoning algorithm for a DL with role inclusions known to us uses a step that checks
whether   L(S) holds for an arbitrary role chain  and a role S. For example, to check
whether K |= S(a, b) holds, an algorithm must ensure that, in each model of K, a role chain
  L(S) exists connecting the elements interpreting a and b. Although they characterise
languages L(S), role inclusions do not lend themselves well to language recognition, so all
algorithms known to us transform role inclusions into another, more manageable form. This
is analogous to the fact that, while regular expressions characterise regular languages, the
former are routinely transformed into FAs in order to facilitate language recognition.
Horrocks and Sattler (2004) showed that, for each regular RBox R and each role S
occurring in R, one can construct an FA FS such that L(FS ) = L(S). These FAs are used
in a tableau decision procedure for SROIQthe DL underpinning OWL 2 DL (Horrocks
et al., 2006). Given a SROIQ knowledge base, the tableau procedure tries to construct
657

fiStefanoni, Motik, Krotzsch, & Rudolph

S2

iS2

start




iS1

S1

fS2

iS1

fS1



S0

fS0

fS1





iS0

S1


iS0

S0

iS0

fS0

S0

fS0

iS0

S0

fS0

Figure 1: The FA FS2 as constructed following Horrocks and Sattler (2004)
a finite graph representing a model of the KB, in which edges are labelled by roles, and
vertices are labelled by concepts. The aforementioned FAs are used to ensure that universal
restriction S.C obey the constraints imposed by role inclusions; roughly speaking, this is
obtained by running FS over the graph while updating the current state of FS along the
path, and by labelling each reachable vertex in which the state of FS is final with concept
C. Simanck (2012) optimised the tableau procedure by simulating FAs on-the-fly, rather
than precomputing them in advance.
Horrocks and Sattler (2004) observed that their FAs can contain exponentially many
states. Kazakov (2008) proved that this is unavoidable in some cases: for the regular RBox
Rn containing axioms (1), the size of each FA F with L(F) = L(Sn ) is exponential in n.
Si1  Si1 v Si

i  [1..n]

(1)

This blowup in the number of states is caused by the simple model of computation underlying FAs, where the behaviour of the automaton is determined solely by the current state.
In the example above, we have   L(Sn ) whenever  consists of Si repeated j times for
some i  [0..n] with j = 2ni . Thus, while parsing such , the FA recognising L(Sn ) must
remember the number of occurrences of Si it has already seen, which can be achieved only
by using a different state for each number between 0 and 2n . Figure 1 shows the FA FS2
constructed by Horrocks and Sattler (2004): to remember the current state, FS2 contains
two copies of automaton FS1 , and each copy of FS1 contains two copies of automaton FS0 .
Hence, to obtain a PSpace procedure, we must devise a more succinct representation for
the languages induced by role inclusions. Towards this goal, we note that role inclusions are
closely related to context-free grammars, and that context-free languages can be efficiently
recognised using pushdown automata (Hopcroft et al., 2003)that is, FAs extended with
an infinite stack for storing contextual information. Hence, given a regular RBox R and a
role S occurring in R, we construct a PDA PS that accepts L(S). Unlike the FA shown in
Figure 1 that remembers contextual information using states, PDA PS uses the stack to
remember the current status of the computation and determine how to proceed. We show
that the number of states in PS is polynomial in the size of R, and that PS can recognise
L(S) by using a stack of size linear in the size of R; thus, PS provides us with the required
succinct encoding of FS . In Section 4, we use these PDAs in an algorithm that answers
Boolean CQs over ELRO+ knowledge bases using polynomial space.
658

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

start

iS2

S2 , X/X

fS2
, X/X

, X/iS1  fS2  X

iS1

S1 , X/X

i>r

fS1

R, X/X

f>r

, X/X
, X/iS0  fS1  X

iS0

S0 , X/X

fS0

Figure 2: The PDA PS2 corresponding to the FA FS2 , where X  R and R  R
In the rest of this section, we fix an arbitrary regular RBox R. By Proposition 3, we
can assume that each role inclusion  v S  R is such that ||  2 and S 6= >r . For each
role S occurring in R , we next define the PDA PS .
Definition 4. Let S  R be a role. Then, PS = hQR , R , R , R , iS , , fS , i is the PDA
where QR = {iT , fT | T  R } is the set of states, R = QR  {} is the stack alphabet, and
R is the smallest transition function satisfying the following conditions for each X  R .
(r) For each T  R \ {>r }, we have hfT , Xi  R (iT , T, X).
(t1) For each  v T  R, we have hfT , Xi  R (iT , , X).
(t2) For each T  T v T  R, we have hiT , Xi  R (fT , , X).
(t3) For each T1  T v T  R, we have hiT1 , iT  Xi  R (iT , , X).
(t4) For each T1  T2 v T  R, we have hiT1 , iT2  fT  Xi  R (iT , , X).
(t5) For each T  T2 v T  R, we have hiT2 , fT  Xi  R (fT , , X).
(ur) For each T  R , we have hf>r , Xi  R (i>r , T, X).
(u1) hf>r , Xi  R (i>r , , X).
(u2) hi>r , Xi  R (f>r , , X).
(p) For each T  R and each s  QR , we have hs, i  R (fT , , s).
In the following examples, we present the PDA that succinctly encodes the FA FS2 , and
we explain the different types of transitions in Definition 4, and how the content of the
stack influences the computation of PDAs.
Example 5. Figure 2 shows the PDA PS2 corresponding to the FA FS2 in Figure 1. A
c, X/

transition hs0 , i  R (s, c, X) is shown as s  s0 , where X/ indicates that the transition replaces the top-most stack symbol X with word ; moreover, transitions of the form
(p) from Definition 4 are not shown in the figure for the sake of clarity. As one can see
from the figure, unlike in FA FS2 , there is no copying of states in PDA PS2 .
659

fiStefanoni, Motik, Krotzsch, & Rudolph

, X/X

start

iS

S, X/X

, X/i>r  fS  X

i>r

fS

R, X/X

f>r

, X/X

, X/fS  X
, X/iT  X

iP

iT

T, X/X

fT

, X/X
, X/X

P, X/X

fP
Figure 3: The PDA PS for the RBox in Example 6, where X  R and R  R
Example 6. To explain the different types of transitions in Definition 4 and how the stack
is used in the computation of a PDA, we use the regular RBox R containing role inclusions
(2)(6). Figure 3 shows PDA PS using the notation from Example 5.
vP

(2)

T T vT

(3)

P  >r v S

(4)

ST vS

(5)

P T vT

(6)

Each role T  R is associated with states iT and fT , and moving from the former to
the latter ensures that the PDA reads a role chain   L(T ). A transition of type (r) allows
the PDA to read T in state iT . An -transition of type (t1) from iT to fT is added if T
is reflexive, and it allows the PDA to read the empty role chain; in our example, axiom
(2) introduces the -transition from iP to fP . Moreover, an -transition of type (t2) from
fT to iT is added if T is transitive, and it allows the PDA to read any number of role
chains 1 , . . . , n  L(T ); in our example, axiom (3) introduces the -transition from fT
to iT . Transitions of types (ur), (u1), and (u2) analogously reflect the properties of >r :
(ur) allows the PDA to read an arbitrary role, and (u1) and (u2) reflect the reflexivity and
transitivity of >r , respectively. None of these transitions affect the PDAs stack.
To illustrate transitions of type (t4), we next show how, for 1 = P  S, PDA PS
determines that 1  L(S); the latter is ensured by axiom (4). Now assume that PDA PS is
in state iS with  on its stack. Due to axiom (4), PS can make an -transition of type (t4)
to state iP , pushing i>r  fS on the stack. Since the new state is iP , the PDA will next need
to read P ; furthermore, the stack content signals to the PDA that, after it finishes reading
P , it should move to state i>r to read >r and then to state fS to finish reading S. Indeed,
PS can then make a transition of type (r) to state fP to read P , followed by an -transition
of type (p) to state i>r popping i>r off the stack; next, the PDA can make a transition of
660

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

type (ur) to state f>r reading S, followed by an -transition of type (p) to state fS popping
fS off the stack. At this point, the PDA accepts the input.
To illustrate transitions of types (t3) and (t5), we next show how, for 2 = S P T , PDA
PS determines that 2  L(S); the latter is ensured by axioms (5) and (6). Again, assume
that PDA PS is in state iS with  on its stack. PDA PS can then make a transition of type
(r) to state fS , reading S and leaving the stack unchanged; next, due to axiom (5), PS can
make an -transition of type (t5) to state iT , pushing fS on the stack. Due to axiom (6),
PDA PS can next make an -transition of type (t3) to state iP , pushing iT on the stack;
at this point, the stack contains iT  fS  . Next, the PDA can make a transition of type
(r) to state fP reading P , and then an -transition of type (p) to state iT popping iT off
the stack; furthermore, in an analogous way, the PDA can move to state fT reading T and
leaving fS   on the stack. Finally, the PDA can make an -transition of type (p) to state
fS popping fS off the stack. At this point, the PDA accepts the input.
To understand the benefit of using PDAs rather than FAs, note that PS reaches state iP
while recognising both 1 and 2 . Role P occurs in axioms (4) and (6), so when PS moves
into state iP in order to read an occurrence of P , it must remember which of the two
axioms caused the move so that it knows how to continue after reading P : for 1 , PS must
continue reading >r , whereas for 2 , it must continue reading T . Unlike the FAs by Horrocks
and Sattler (2004) that remember this information by copying states, PS remembers this
information on its stack: for 1 , it reaches iP with i>r  fS   on its stack, whereas for 2 ,
PS reaches iP with iT  fS   on its stack. Thus, the stack of PS is analogous to stacks in
programming languages: stack symbols correspond to return addresses, and transitions of
type (p) correspond to return statements.
The following proposition is immediate from the definition of PDA PS .
Proposition 7. PDA PS can be computed in time polynomial in |R|.
The following theorem states that PDA PS accepts L(S) and that PS has stack bounded
by the size of R. The proof of this result is given in Section 3.1.
Theorem 8. For each role S  R and each role chain ,
1.   L(PS ) if and only if   L(S), and
2. PS has stack bounded by 2  lv(S) + 1.
Theorem 8 gives rise to the following notion of the depth of RBox R, which provide us
with a global bound on the stack size of the PDAs encoding R.
Definition 9. The depth of the RBox R is defined as dR := maxSR (2  lv(S) + 1).
Finally, we outline how our bounded-stack encoding of regular RBoxes can reduce the
space used by the tableau algorithm for SROIQ. Since ELRO+ does not support inverse
roles, Definition 4 does not directly provide us with an encoding of the languages induced
by SROIQ RBoxes. Nevertheless, we can extend the construction above by completing
RBox R so that inv(Sn )    inv(S1 ) v inv(S)  R for each role inclusion S1    Sn v S in the
RBox, where inv() maps each role to its inverse. One can check that, for each (inverse) role
661

fiStefanoni, Motik, Krotzsch, & Rudolph

S, the PDA PS constructed using the completed RBox R encodes FS . Then, we can modify
the portion of the tableau algorithm responsible for checking the satisfaction of universal
restrictions by running a bounded-stack PDA over the graph constructed by the tableau
procedure. Roughly speaking, for each universal restriction S.C labelling a vertex, we run
PS over the graph while updating the current state and the stack of PS , and we label each
reachable vertex in which the current state and stack of PS are final with concept C. Since
PS and its stack are of size polynomial in |R|, this requires polynomial space, unlike the
FAs by Horrocks and Sattler (2004) and the optimised encoding by Simanck (2012), which
may require exponential space.
3.1 Proof of Correctness
In this section, we prove Theorem 8. Towards this goal, let ` be the derivation relation
w.r.t. transition function R ; furthermore, for each derivation step hs, , i ` hs0 , 0 ,  0 i,
we write hs, , i `x hs0 , 0 ,  0 i if hs0 , 0 ,  0 i can be obtained from hs, , i by applying a
transition of the form (x) from Definition 4 with x  {r, t1, . . . , t5, ur, u1, u2, p}.
3.1.1 Soundness and Stack Boundedness
In this section, we prove that, for each role S  R and each role chain ,
1.   L(PS ) implies that   L(S), and
2. PS has stack bounded by 2  lv(S) + 1.
To this end, we first show that PDA PS satisfies the following liveness property: if during
its computation PS pushes a state s  QR on the stack, then PS will eventually pop s off
the stack. Then, we show that each derivation of PS moving from state iS to state fS takes
one of five forms; we call such derivations regular. Finally, we show that regular derivations
satisfy properties (1) and (2).
We start by showing that each PDA PS satisfies the following liveness property.
Lemma 10. Let hs0 , 0 , 0  i `    ` hsn , n , n  i be an arbitrary derivation such that
s0 = iS , sn = fS , and 0 =  for some role S  R and some word   R . Then, for each
role T such that lv(T ) < lv(S) and each i  [0..n] such that si  {iT , fT } and i = s0i  i0
with s0i  QR , an index j  [i..n] exists such that
(a) sj = fT and j = i ;
(b) for each k  [i..j], word k is of the form k := k00  i for some k00  R ; and,
(c) sj+1 = s0i , j+1 = i0 , and j+1 = j .
Proof. Let hs0 , 0 , 0  i `    ` hsn , n , n  i be as above, and for each i  [0..n  1], let
xi  {r , t1 , . . . , t5 , ur , u1 , u2 , p} be the form of derivation step ithat is, we fix xi (arbitrarily if there is more than one possibility) such that hsi , i , i  i `xi hsi+1 , i+1 , i+1  i
holds. Furthermore, for each role T such that lv(T ) < lv(S), let IT be the set containing
each index i  [0..n] such that si  {iT , fT } and i is of the form i := s0i  i0 with s0i  QR .
Note that, for each index i  IT , due to lv(T ) < lv(S), si  {iT , fT }, and sn = fS , we have
662

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

that i < nthat is, hsi , i , i  i ` hsi+1 , i+1 , i+1  i occurs in our derivation. Next, by
induction on m  N, we show that, for each role T with m = lv(T ) < lv(S) and each i  IT ,
some j  [i..n] exists satisfying properties (a)(c).
Base case (). Consider an arbitrary role T  R such that 0 = lv(T ) < lv(S). We
consider the interesting case where IT 6= ; otherwise, properties (a)(c) hold vacuously.
Since lv(T ) = 0 and si  {iT , fT }, we have xi  {r , t1 , t2 , ur , u1 , u2 , p}. By reverseinduction on IT (i.e., by induction starting from the maximal element), we next show that
each index i  IT satisfies the required properties.
Base case. Let i = max IT . If xi  {r , t1 , t2 , ur , u1 , u2 }, then si+1  {iT , fT } and
i+1 = i ; thus, we have i + 1  IT , which contradicts the maximality of i. The only
remaining possibility is xi = p, which implies that si = fT , si+1 = s0i , i+1 = i0 , and
i+1 = i ; but then, j = i satisfies properties (a)(c).
Inductive step. Consider an arbitrary index i  IT such that properties (a)(c) hold for
each `  IT with ` > i. If xi  {r , t1 , t2 , ur , u1 , u2 }, then si+1  {iT , fT } and i+1 = i ;
hence, ii+1  IT so, by the inductive hypothesis, an index j exists satisfying properties
(a)(c). Otherwise, if xi = p, then si = fT , si+1 = s0i , i+1 = i0 , and i+1 = i , so j = i
satisfies properties (a)(c).
Inductive Step (). Consider an arbitrary m  N such that properties (a)(c) hold for
each role P  R with lv(P )  m and lv(P ) < lv(S) and each index in IP . Furthermore,
consider an arbitrary role T such that m + 1 = lv(T ) < lv(S). We consider the interesting
case where IT 6= ; otherwise, properties (a)(c) hold vacuously. Recall that for each
 v S 0  R we have S 0 6= >r , so lv(>r ) = 0 and T 6= >r . Thus, each i  IT is such that
xi 6 {ur , u1 , u2 }. By reverse-induction on IT , we next show that each index i  IT satisfies
the required properties.
Base case (). Let i = max IT . If xi  {r , t1 , t2 }, then si+1  {iT , fT } and i+1 = i ;
thus, we have i + 1  IT , which contradicts the maximality of i. If xi  {t3 , t4 , t5 }, then
si+1  {iP , fP } for some role P such that lv(P ) < lv(T ) and lv(P ) < lv(S); furthermore, we
00  s   where s  {i , f } and  00
have that i+1 is of the form i+1 := i+1
i
T
T
T T
i+1 is a sequence
00
of zero or one states. Each state s occurring in i+1
is such that s  {iR , fR } for some role
R of level less than T . But then, by the inductive hypothesis (), an index ` > i exists
such that s` = sT and ` = i , which contradicts the maximality of i. Finally, if xi = p,
then si = fT , si+1 = s0i , i+1 = i0 , and i+1 = i , so j = i satisfies properties (a)(c).
Inductive step (). Consider an arbitrary index i  IT such that properties (a)(c) hold
for each index `  IT with ` > i, and consider the possible forms of xi .
 xi  {r , t1 , t2 }. Then, si+1  {iT , fT } and i+1 = i , so i + 1  IT . By the inductive
hypothesis (), an index j exists satisfying properties (a)(c).
 xi = t3 . Then, si+1 = iT1 and i+1 = iT  i for some role T1 with lv(T1 ) < lv(T ).
Thus, i + 1  IT1 . By the inductive hypothesis (), an index `  [i + 1..n] exists such
that s` = fT1 and ` = i+1 ; furthermore, for each k  [i + 1..`], we have that k is
of the form k := k00  i+1 for some word k00  R ; finally, s`+1 = iT and `+1 = i .
By the definition of IT , we have that ` + 1  IT . By the inductive hypothesis (), an
index j exists satisfying properties (a)(c).
663

fiStefanoni, Motik, Krotzsch, & Rudolph

 xi = t4 . Then, si+1 = iT1 and i+1 = iT2  fT  i for some roles T1 and T2 with
lv(T1 ) < lv(T ) and lv(T2 ) < lv(T ). Thus, i + 1  IT1 . By the inductive hypothesis
(), an index `1  [i + 1..n] exists such that s`1 = fT1 and `1 = i+1 ; furthermore, for
each k  [i..`1 ], we have that k is of the form k := k00  i+1 for some word k00  R ;
finally, s`1 +1 = iT2 and `1 +1 = fT  i . Then, `1 + 1  IT2 . Again, by the inductive
hypothesis (), an index `2  [`1 + 1..n] exists such that s`2 = fT2 and `2 = `1 +1 ;
furthermore, for each k  [`1 + 1..`2 ], we have that k is of the form k := k00  `1 +1
for some word k00  R ; finally, s`2 +1 = fT and `2 +1 = i . By the definition of IT , we
have that `2 + 1  IT . So, by the inductive hypothesis (), an index j exists satisfying
properties (a)(c).
 xi = t5 . Then, si+1 = iT2 and i+1 = fT  i for some role T2 with lv(T2 ) < lv(T ).
Then, i + 1  IT2 . By the inductive hypothesis (), an index `  [i + 1..n] exists
such that s` = fT2 and ` = i+1 ; for each k  [i..`], we have that k is of the form
k := k00  i+1 for some word k00  R ; finally, s`+1 = fT and `+1 = i . By the
definition of IT , we have that ` + 1  IT . So, by the inductive hypothesis (), an
index j exists satisfying properties (a)(c).
 xi = p. Then, si = fT , si+1 = s0i , i+1 = i0 , and i+1 = i . Therefore, j = i satisfies
properties (a)(c).
Next, for each role S  R , we define the notion of regular derivations of PS .
Definition 11. The set of regular derivations of P>r is inductively defined as follows, for
each role T  R , each role chain i  R , and each   R .
sequr hi>r , T  0 , i `ur hf>r , 0 , i is a regular derivation of P>r .
sequ1 hi>r , 0 , i `u1 hf>r , 0 , i is a regular derivation of P>r .
sequ2 If hi>r , 0 , i `    ` hf>r , k , i and hi>r , k , i `    ` hf>r , n , i are regular derivations of P>r , then the following is also a regular derivation of P>r .
hi>r , 0 , i `    ` hf>r , k , i `u2 hi>r , k , i `    ` hf>r , n , i
Next, consider an arbitrary natural number m  N and assume that regular derivations of
PT have already been defined for T = >r and each role T  R \ {>r } such that lv(T )  m.
Then, for each role S  R \ {>r } with lv(S) = m + 1, regular derivations of PS are defined
as follows, for each S(i)  R , each i  R , and each   R .
seqr hiS , S  0 , i `r hfS , 0 , i is a regular derivation of PS .
seqt1 If  v S  R, then hiS , 0 , i `t1 hfS , 0 , i is a regular derivation of PS .
seqt2 If S  S v S  R and hiS , 0 , i `    ` hfS , k , i and hiS , k , i `    ` hfS , n , i
are regular derivations of PS , then the following is also a regular derivation of PS .
hiS , 0 , i `    ` hfS , k , i `t2 hiS , k , i `    ` hfS , n , i

664

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

seqt3 If S1  S v S  R, hiS1 , 0 , iS  i `    ` hfS1 , k , iS  i is a regular derivation of
PS1 , and hiS , k , i `    ` hfS , n , i is a regular derivation of PS , then the following
is also a regular derivation of PS .
hiS , 0 , i `t3 hiS1 , 0 , iS  i `    ` hfS1 , k , iS  i `p hiS , k , i `    ` hfS , n , i
seqt4 If S1 S2 v S  R, hiS1 , 0 , iS2  fS  i `    ` hfS1 , k , iS2  fS  i is a regular derivation of PS1 , and hiS2 , k , fS  i `    ` hfS2 , n , fS  i is a regular derivation of PS2 ,
then the following is also a regular derivation of PS .
hiS , 0 ,
hiS1 , 0 , iS2  fS
fS
hiS2 , k ,
hfS , n ,

i `t4
 i `    ` hfS1 , k , iS2  fS  i `p
fS  i `p
 i `    ` hfS2 , n ,
i

seqt5 If S  S2 v S  R, hiS , 0 , i `    ` hfS , k , i is a regular derivation of PS , and
hiS2 , k , fS  i `    ` hfS2 , n , fS  i is a regular derivation of PS2 , then the following is also a regular derivation of PS .
hiS , 0 , i `    ` hfS , k , i `t5 hiS2 , k , fS i `    ` hfS2 , n , fS i `p hfS , n , i
We are left to show that each derivation of PS that moves the PDA from the start state
iS to the final state fS is regular and that regular derivations satisfy the required properties.
In the following lemma, we show that derivations which leave a particular word  at the
bottom of the stack are regular and satisfy properties (1) and (2). Subsequently, we will
show that each accepting derivation of PS is of this form.
Lemma 12. For each role S  R , each word   R , and each derivation of the form
hs0 , 0 , 0  i `    ` hsn , n , n  i such that s0 = iS , sn = fS , and 0 = ,
(i) the derivation is regular for PS ;
(ii) for each i  [0..n], we have that |i |  2  lv(S); and
(iii) S 
=  0  n .
Proof. We prove the claim by induction on n  N+ .
Base case. For n = 1, consider an arbitrary role S  R , word   R , and sequence
hiS , 0 , 0  i ` hfS , 1 , 1  i. By Definition 4, only transitions from cases (r), (t1), (ur),
and (u1) move PS from state iS to state fS . These transitions leave the stack untouched,
so 1 =  = 0 and property (ii) holds. For properties (i) and (iii), we next consider the
four different forms that the sequence may take.
 hiS , S  1 , 0  i `r hfS , 1 , 1  i. Then S 6= >r , so this is a regular derivation of
PS by case seqr and (i) holds. Finally, 0  1 = S, which implies S =
 0  1 , and
so (iii) holds.
665

fiStefanoni, Motik, Krotzsch, & Rudolph

 hiS , 0 , 0  i `t1 hfS , 0 , 1  i. Then S 6= >r , so this is a regular derivation of PS
by case seqt1 and (i) holds. Finally, 0  1 = ; moreover, by case t1 of Definition 4,
we have  v S  R, so S =
 ; hence, S =
 0  1 and (iii) holds.
 hiS , T  1 , 0  i `ur hfS , 1 , 1  i. Then S = >r and T  R , so this is a regular
derivation of P>r by case sequr and (i) holds. Finally, 0  1 = T  R , which
implies S =
 0  1 , and so (iii) holds.
 hiS , 0 , 0  i `u1 hfS , 0 , 1  i. Then S = >r , so this is a regular derivation of P>r
by case sequ1 and (i) holds. Finally, 0  1 = ; hence, S =
 , and so (iii) holds.
Inductive step. Consider an arbitrary n  N+ and assume that (i)(iii) hold for each
role S 0  R , each word  0  R , and each derivation hs00 , 00 , 00   0 i `    ` hs0c , 0c , c0   0 i
of length at most n and of the form required by this lemma. Furthermore, consider an
arbitrary role S  R , an arbitrary word   R , and an arbitrary derivation
hs0 , 0 , 0  i `    ` hsn+1 , n+1 , n+1  i

(7)

of length n + 1 such that s0 = iS , 0 = , and sn+1 = fS . For each i  [0..n  1], let
xi  {r , t1 , . . . , t5 , ur , u1 , u2 , p} be the form of derivation step ithat is, we fix xi (arbitrarily if there is more than one possibility) such that hsi , i , i  i `xi hsi+1 , i+1 , i+1  i
holds. We next consider the possible forms the sequence might have, and we show that
properties (i)(iii) hold in each case.
(Case 1) S = >r . We consider the form of hs0 , 0 , 0  i `x0 hs1 , 1 , 1  i. Since
s0 = i>r , we have x0  {t1 , t3 , t4 , ur , u1 }. As R is normalised, each  v S 0  R is
such that S 0 6= >r , so x0  {ur, u1} and we have s1 = f>r and 1 =  = 0 . Since n > 1,
hs1 , 1 , 1  i `x1 hs2 , 1 , 2  i occurs in the sequence with x1  {t2 , t5 , u2 , p}. Since
s1 = f>r and R is normalised, we have x1  {u2 , p}; furthermore, since 1 =  and by our
assumption on the form of (7), we have x1 6= p. Hence, the only remaining possibility is
that x1 = u2 . By case (u2) in Definition 4, we have s2 = i>r , 2 = 1 , and 2 = 1 . We
next prove that properties (i)(iii) hold.
(i) By sequr and sequ1 , hs0 , 0 , 0  i `x0 hs1 , 1 , 1  i is a regular derivation of P>r . By
the inductive hypothesis, hs2 , 2 , 2  i `    ` hsn+1 , n+1 , n+1  i is also a regular
derivation of PS . By the definition of regular derivations, we have n = 2 = . But
then, (7) is a regular derivation of PS by case sequ2 .
(ii) Words 0 , 1 , 2 are all empty. By the inductive hypothesis, we have |` |  2  lv(>r )
for each `  [2..n + 1]. Therefore, |i |  2  lv(>r ) holds for each i  [0..n + 1].
(iii) By the inductive hypothesis, we have >r =
 2  n+1 . By cases (ur) and (u1), either
0  2 =  or 0  2 = T  R . But then, >r 
=  0  n+1 holds.
(Case 2) S 6= >r and k  [0..n] exists with hsk , k , k  i `t2 hsk+1 , k+1 , k+1  i and
sk = fS . Then, by case (t2) in Definition 4, we have S  S v S  R, sk+1 = iS , k+1 = k ,
and k+1 = k . We next prove that properties (i)(iii) hold.

666

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

(i) By the inductive hypothesis, hs0 , 0 , 0 i `    ` hsk , k , k i is a regular derivation
of PS . By the definition of regular derivations, we have k = 0 = . Since sk+1 = iS
and k+1 = k = , we have that hsk+1 , k+1 , k+1  i `    ` hsn+1 , n+1 , n+1  i
is of the form shown in (7) and it is shorter than n + 1 so, by the inductive hypothesis,
it is a regular derivation of PS . Then, (7) is a regular derivation of PS by case seqt2 .
(ii) By the inductive hypothesis, we have |`1 |  2  lv(S) for each `1  [0..k], as well as
|`2 |  2  lv(S) for each `2  [k + 1..n + 1]. Therefore, |i |  2  lv(S) holds for each
i  [0..n + 1].
(iii) By the inductive hypothesis, we have S =
 0  k and S =
 k+1  n+1 . But then,

S  S v S  R and k+1 = k implies that S =
 0  n+1 holds.
(Case 3) S 6= >r and no `  [0..n] exists with hs` , ` , `  i `t2 hs`+1 , `+1 , `+1  i
and s` = fS , but k  [0..n] exists such that hsk , k , k  i `t5 hsk+1 , k+1 , k+1  i and
sk = fS . Then, let k be the largest such indexthat is, we assume that no m > k exists
such that hsm , m , m  i `t5 hsm+1 , m+1 , m+1  i and sm = fS . Then, by case (t5) in
Definition 4, for some role S2 of level less than S, we have that S  S2 v S  R, sk+1 = iS2 ,
k+1 = k , and k+1 = fS  k . We next prove that properties (i)(iii) hold.
(i) Since sk = fS , by the inductive hypothesis then hs0 , 0 , 0  i `    ` hsk , k , k  i
is a regular derivation of PS . By Definition 12, we have that k = 0 . Since sk+1 = iS2
and k+1 = fS  0 , by Lemma 10, an index j  [k + 1..n] exists such that sj = fS2
and j = k+1 ; furthermore, sj+1 = fS and j+1 = 0 and j+1 = j . We prove that
j + 1 = n + 1. For the sake of contradiction, assume that j + 1 < n + 1 and consider
the form of transition hsj+1 , j+1 , j+1  i `xj +1 hsj+2 , j+2 , j+2  i. Given that
sj+1 = fS and S 6= >r , we must have xj+1  {t2 , t5 , p}. By the initial assumption,
we have xj+1 6= t2 ; furthermore, by the maximality of k, we have xj+1 6= t5 ; finally,
since j+1 = 0 = , we have xj+1 6= p. Thus, j + 1 = n + 1, as required. It follows
that the sequence is of the following form, where k+1 = k and n+1 = n .
hiS , 0 ,
0  i `    ` hfS , k , 0  i `t5
hiS2 , k+1 , k+1  i `    ` hfS2 , n , n  i `p
hfS , n+1 , 0  i
By Lemma 10, for each `  [k + 1..n], we have that ` is of the form ` = `00  fS  0 . In
00
particular, words k+1
and n00 are both empty. Then, by the inductive hypothesis, we
have that hiS2 , k+1 , k+1  i `    ` hfS2 , n , n  i is a regular derivation of PS2 .
By case seqt5 , then (7) is a regular derivation of PS .
(ii) By the inductive hypothesis, for each `1  [0..k], we have that |`1 |  2  lv(S). Furthermore, for each `2  [k + 1..n], we have that |`002 |  2  lv(S2 ). Since lv(S2 ) < lv(S)
and `2 = `002  fS , we also have that |`2 |  2  lv(S). Given that n+1 = , for each
i  [0..n + 1], we have that |i |  2  lv(S).
(iii) By the inductive hypothesis, we have that S =
 0  k and S2 =
 k+1  n . Given

that S =
 S  S2 , that k+1 = k , and that n+1 = n , we obtain that S =
 0  n+1 .

667

fiStefanoni, Motik, Krotzsch, & Rudolph

(Case 4) S 6= >r and no `  [0..n] exists with hs` , ` , `  i `x` hs`+1 , `+1 , `+1  i,
s` = fS and x`  {t2 , t5 }; but hs0 , 0 , 0  i `t3 hs1 , 1 , 1  i. Then, by case (t3) in Definition 4, for some role S1 of level less than S, we have that S1  S v S  R, s1 = iS1 ,
1 = 0 , and 1 = iS  0 . We next prove that properties (i)(iii) hold.
(i) Since s1 = iS1 and 1 = iS  0 , by Lemma 10, some j  [1..n] exists such that sj = fS1
and j = 1 ; furthermore, sj+1 = iS and j+1 = 0 and j+1 = j . Then, the sequence
is of the following form, where 1 = 0 .
hiS , 0 ,
0  i `t3
j  i `p
1  i `    ` hfS1 , j ,
hiS1 , 1 ,
hiS , j+1 , j+1  i `    ` hfS , n+1 , n+1  i
By Lemma 10, for each `  [1..j], we have that ` is of the form ` = `00  iS  0 .
In particular, words 100 and j00 are both empty. By the inductive hypothesis, then
hiS1 , 0 , 1  i `    ` hfS1 , j , j  i is a regular derivation of PS1 . Since j+1 = 0 ,
by the inductive hypothesis, then hiS , j+1 , j+1  i `    ` hfS , n+1 , n+1  i is a
regular derivation of PS . By case seqt3 , then (7) is a regular derivation of PS .
(ii) By the inductive hypothesis, for each `2  [j + 1..n + 1], we have that |`2 |  2  lv(S);
furthermore, for each `1  [1..j], we have that |`001 |  2  lv(S1 ). Since lv(S1 ) < lv(S)
and `1 = `001  iS , we also have that |`1 |  2  lv(S). Finally, since 0 = , for each
i  [0..n + 1], we have that |i |  2  lv(S).
(iii) By the inductive hypothesis, we have that S1 =
 1  j and that S =
 j+1  n+1 .
Given that S =
 S1 S, that 1 = 0 , and that j+1 = j , we have that S =
 0 n+1 .
(Case 5) S 6= >r and no `  [0..n] exists with hs` , ` , `  i `x` hs`+1 , `+1 , `+1  i,
s` = fS , and x`  {t2 , t5 }; in addition, hs0 , 0 , 0  i `x0 hs1 , 1 , 1  i is such that x0 6= t3.
We next consider the remaining possibilities for x0 . As s0 = iS , we have x0 6 {t2 , t5 , u2 , p}
by cases (t2), (t5), (u2), and (p) of Definition 4; furthermore, due to S 6= >r , we have
x0 6 {ur , u1 } by cases (ur) and (u1) of Definition 4. Moreover, assume that x0  {r , t1 };
then, we have s1 = fS and 1 = 0 by cases (r) and (t1) of Definition 4; since n > 1 and
S 6= >r , the only possibility is that hs1 , 1 , 1  i `p hs2 , 2 , 2  i, which is impossible
due to 1 =  and our assumption on the form of (7). Hence, the only remaining possibility
is that x0 = t4 . By case (t4) in Definition 4, for some roles S1 and S2 of level less than
S, we have S1  S2 v S  R, s1 = iS1 , 1 = 0 , and 1 = iS2  fS  0 . We next prove that
properties (i)(iii) hold.
(i) Since s1 = iS1 and 1 = iS2  fS  0 , by Lemma 10, j1  [1..n] exists such that sj1 = fS1
and j1 = 1 ; furthermore, sj1 +1 = iS2 and j1 +1 = fS  0 and j1 +1 = j1 . Again,
by Lemma 10, j2  [j1 + 1..n] exists such that sj2 = fS2 and j2 = j1 +1 ; furthermore,
sj2 +1 = fS and j2 +1 = 0 and j2 +1 = j2 . Next, we prove that j2 + 1 = n + 1.
For the sake of contradiction, suppose that j2 + 1 < n + 1 and consider the form
of hsj2 +1 , j2 +1 , j2 +1  i `xj2 +1 hsj2 +2 , j2 +2 , j2 +2  i. Given that sj2 +1 = fS , we
must have that xj2 +1  {t2 , t5 , u2 , p}. However, we assumed that xj2 +1 6 {t2 , t5 }
and that S 6= >r , so xj2 +1 6= u2 ; finally, since j2 +1 = 0 = , we have xj2 +1 6= p.
668

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

Therefore, we have j2 + 1 = n + 1, as required, and the sequence is of the following
form, for 1 = 0 , j1 +1 = j , and n+1 = n .
hiS , 0 ,
0  i `t4
hiS1 , 1 ,
1  i `    ` hfS1 , j1 , j1  i `p
hiS2 , j1 +1 , j1 +1  i `    ` hfS2 , n , n  i `p
hfS , n+1 , n+1  i
By Lemma 10, for each `1  [1..j1 ], word `1 is of the form `1 = `001  iS2  fS  0 .
In particular, words 100 and j001 are both empty. Then, by the inductive hypothesis,
we have that hiS1 , 1 , 1  i `    ` hfS1 , j1 , j1  i is a regular derivation of PS1 .
Similarly, by Lemma 10, for each `2  [j1 + 1..n], we have that `2 is of the form
`2 = `002  fS  0 . In particular, words j001 +1 and n00 are both empty. Then, by the
inductive hypothesis, we have that hiS2 , j1 +1 , j1 +1  i `    ` hfS2 , n , n  i is a
regular derivation of PS2 . By case seqt4 , then (7) is a regular derivation of PS .
(ii) By the inductive hypothesis, for each `1  [1..j1 ], we have that |`001 |  2  lv(S1 ). Since
lv(S1 ) < lv(S) and `1 = `001  iS2  fS , we also have that |`1 |  2  lv(S). Similarly, by
the inductive hypothesis, for each `2  [j1 + 1..n], we have that |`002 |  2  lv(S2 ). Since
lv(S2 ) < lv(S) and `2 = `002  fS , we also have that |`2 |  2  lv(S). Since 0 = , for
each i  [0..n + 1], we have that |i |  2  lv(S).
(iii) By the inductive hypothesis, we have that S1 =
 1 j1 and S2 =
 j1 +1  n . Given

that S =
 S1  S2 , that 1 = 0 , and that n+1 = n , we conclude that S =
 0  n+1 .
There are no other possibilities for the form of (7), so the claim of this lemma holds for
each derivation of that form.
We are finally ready to show that PDA PS satisfies properties (1) and (2).
Lemma 13. For each role S  R and each role chain , we have that
1.   L(PS ) implies   L(S), and
2. PS has stack bounded by 2  lv(S) + 1.
Proof. By the definition of PS , transitions resulting from case p in Definition 4 are the only
ones popping elements from the stack, and these never pop symbol ; hence, at each point
i in an accepting derivation of PS , the stack content i is of the form i := i0  . Then,
the two claims follow immediately from Lemma 12.
3.1.2 Completeness
We next prove that our encoding is also complete, thus proving Theorem 8.
Lemma 14. For each role S  R and each role chain , we have that   L(S) implies
  L(PS ).

669

fiStefanoni, Motik, Krotzsch, & Rudolph

Axiom Type
(t1)
vT
(t2)

(t3)

(t4)

(t5)

Derivation
i i `t1 hfT ,

00

hiT ,

 ,

T T vT

hiT ,
hiT ,

T  T  00 ,
T  00 ,

T1  T v T

hiT , T1  T  00 ,
hiT1 , T1  T  00 ,
hiT ,
T  00 ,

T1  T2 v T

hiT , T1  T2  00 ,
hiT1 , T1  T2  00 , iT2  fT
hiT2 ,
T2  00 ,
fT
00
hfT ,
 ,

T  T2 v T

hiT , T  T2  00 ,
hiT2 ,
T2  00 ,
hfT ,
00 ,

i i
i i

`r
`r

i i `t3
i T  i i ` r
i i `r
i i `t4
 i i ` r
 i i ` r
i i

i i `r
fT   i i ` r
i i

00 ,

i i

hfT , T  00 ,
hfT ,
00 ,

i i
i i

`t2

hfT1 , T  00 ,
hfT ,
00 ,

i T  i i
i i

`p

hfT1 , T2 00 , iT2  fT  i i `p
hfT2 ,
00 ,
fT   i i ` p
hfT , T2  00 ,
hfT2 ,
00 ,

i i `t5
fT   i i ` p

Table 4: Definition of derivation (9) depending on the form of axiom  v T .
Proof. Consider an arbitrary role S  R . In the following, for each role chain , we write
0
m
S =
  if  = S; furthermore, for each m  N+ , we write S =
  if role chains 1 , . . . , m
exist such that S =
 1 =
  =
 m and m = . By the definition of L(S), we have that
m
  L(S) if and only if a natural number m  N exists such that S =
 . By induction on
m
m  N, we next show that S =
  implies   L(PS ).
0

Base case. Let m = 0. Then, we have that S =
 S. We consider two cases depending
on the form of role S  R .
 S = >r . By case (ur) in Definition 4, we have that hi>r , >r , i `ur hf>r , , i.
 S  R \ {>r }. By case (r) in Definition 4, we have hiS , S, i `r hfS , , i.
In either case we have S  L(PS ), as required.
Inductive step. Consider an arbitrary m  N and assume that, for each role chain 0
m
such that S =
 0 , we have 0  L(PS ); we show that the same holds for m + 1. Then,
consider arbitrary role chains 1 , . . . , m+1 such that S =
 1 =
  =
 m =
 m+1 . By the
definition of relation =
, a role T  R and role chains 0 , , 00 exist such that role chain
m is of the form m := 0  T  00 , role chain m+1 is of the form m+1 := 0    00 , and
m
T =
 . Since S =
 0  T  00 , by the inductive hypothesis, we have 0  T  00  L(PS ), so a
sequence hs0 , 0 , 0 i `    ` hsn , n , n i of PS exists with s0 = iS and sn = fS ; furthermore,
0 =  and n = ; finally, 0 = 0  T  00 and n = . Then there exists an index
i  [0..n  1] such that i = T  00 and i+1 = 00 . Furthermore, for each j  [0..i], role chain


00
j is of the form j := 
j  T   for some role chain j  R . Next, consider the form of
xi in hsi , i , i i `xi hsi+1 , i+1 , i+1 i. By Definition 4, only transitions in cases (r) and (ur)
read symbols from the input, so xi  {r, ur}. We show that the lemma holds in each case.
670

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

(Case 1) Consider the case in which xi = r . Then, we have si = iT and si+1 = fT ,
i = i+1 , and T  R \ {>r }. Due to T =
  and T 6= >r , we have  v T  R. Then, the
following is also a derivation of PS

00
00

hs0 , 
0     , 0 i `    ` hsi , i     , i i `

(8)



(9)

[The derivation from Table 4 for  v T ] `
00

hsi+1 ,  , i+1 i `    ` hsn , , n i

(10)

where the derivation in (9) is defined in Table 4 depending on the form of axiom  v T  R.
(Case 2) Consider the case in which xi = ur . Then, we have si = i>r and si+1 = f>r ,
i = i+1 and T  R . Then, the following is also a derivation of PS

00
00

hs0 , 
0     , 0 i `    ` hsi , i     , i i `
00

[The derivation seq(,  , i ) in (14)] `



00

hsi+1 ,  , i+1 i `    ` hsn , , n i
where the derivation seq(, 0 , i ) in (12) is inductively defined as follows.
(
hi>r , 00 , i i `u1 hf>r , 00 , i i
if  = ,
00
seq(,  , i ) :=
00
00
00
hi>r ,    , i i `ur hf>r ,    , i i `u2 seq(,  , i ) if  = P  .

(11)
(12)
(13)

(14)

Therefore, in either case, we have 0    00  L(PS ), as required.

4. A Polynomial Space BCQ Answering Algorithm for ELRO+
Each ELRO+ knowledge base K can be translated into a set of first-order Horn clauses, so
a Boolean CQ q over K can be answered by evaluating q over a so-called canonical model 
a model that can be homomorphically embedded into any other model of K. Canonical
models are usually obtained using chase. Many different chase variants have been studied
in the literature, each producing a different, but homomorphically equivalent, canonical
model (Johnson & Klug, 1984; Marnette, 2009; Cal, Gottlob, & Kifer, 2013; Baget, Leclere,
Mugnier, & Salvat, 2011). In this paper, we introduce a variant that we call consequencebased chase, and the (possibly infinite) set of assertions IK it produces on K we call the
universal interpretation of K. To compute IK , consequence-based chase initialises IK to
contain the ABox of K, as well as assertions {a}(a), >c (a), and >r (a, b) for all individuals a
and b occurring in K; then, it iteratively extends IK using chase rules. The slightly unusual
aspect of our chase variant is that it considers the axioms entailed by (and not only contained
in) K. For example, if IK at some point contains assertion A(w) and K |= A v S.B holds,
then IK is extended with assertions S(w, w0 ) and B(w0 ) where w0 is a fresh term; term w0 is
said to be auxiliary and have type S, B and concept type B. The BCQ answering algorithm
we present in this section is based on checking consequences of K, so our chase variant
makes our proofs simpler. Example 15 illustrates these aspects.
Example 15. Let K = hT , R, i be an ELRO+ KB, where T contains axioms (15)(21),
and R contains role inclusion (22).
{a} v S.A
671

(15)

fiStefanoni, Motik, Krotzsch, & Rudolph

a

b

S

S

1 S, A

2 S, A

a

S
T

3 T, B

R

S

b

6 S, B

S

S

S

4 S, C

oS,A

S

S

T

oT,B

oS,B

R
T

S

oS,C

T
S
S, A

S, A

5
T, B

Universal Interpretation

Compact Interpretation

Figure 4: The universal interpretation and the compact interpretation for K
A v S.A

(16)

{b} v S.A

(17)

{b} v T.B

(18)

{b} v S.C

(19)

C v T.B

(20)

C v R.{b}

(21)

ST vS

(22)

Figure 4 shows the universal interpretation IK of K. Assertions involving >c and >r are
not shown for clarity. The edges obtained via role inclusions are dashed; remaining edges
are solid, apart from the dotted edges, which denote repetition of solid edges. Black edges
are obtained using conventional chase variants, whereas the light grey subbranches of IK
are caused by axioms entailed by, but not occurring in, K. Auxiliary terms are labelled
using integers, and the terms type is shown next to each term. Universal interpretation IK
can be viewed as a family of directed trees whose roots are the individuals in K and where
solid edges point from parents to children or to the individuals in K. Axiom (16) makes IK
infinite, so a decision procedure for BCQ answering cannot simply materialise IK and then
evaluate the query in it; instead, a finitary representation of IK is needed.
By axioms (19), (20), and (22), we have K |= {b} v S.B; but then, since {b}(b)  IK ,
the consequence-based chase ensures that {S(b, 6), B(6)}  IK holds as well. In contrast,
commonly considered chase variants do not ensure {S(b, 6), B(6)}  IK because K does not
contain axiom {b} v S.B.
In the rest of this section, we present the first worst-case optimal algorithm that decides
K |= q given an arbitrary regular ELRO+ KB K and a Boolean CQ q over K. Towards this
goal, in Section 4.1 we review the existing approaches to answering CQs in DLs and discuss
672

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

why these techniques do not provide an optimal procedure for ELRO+ ; in Section 4.2
we discuss the intuitions behind our algorithm; in Section 4.3 we introduce the algorithm
formally and show that it runs in polynomial space in the combined size of K and q and in
polynomial time in the size of K; and in Section 4.4 we prove the algorithms correctness.
4.1 Existing Approaches to Answering CQs
Techniques for answering conjunctive queries over DL knowledge bases developed thus far
can be broadly classified into the following three groups.
The first group consists of automata-based approaches for DLs such as Horn-SHIQ
and Horn-SROIQ (Ortiz et al., 2011), SH (Eiter, Ortiz, & Simkus, 2012a), and the fragment of ELRO+ obtained by disallowing the universal role, reflexive roles, and self restrictions (Krotzsch et al., 2007). All these techniques, however, require constructing automata
whose size can be exponential in the size of the knowledge base.
The second group consists of rewriting-based approaches. Roughly speaking, these approaches rewrite the query and/or the TBox into another formalism, usually a union of
CQs or a datalog program; the relevant answers can then be obtained by evaluating the
rewriting over the ABox. Rewriting-based approaches have been proposed for members
of the DL-Lite family (Artale et al., 2009; Calvanese et al., 2007), the DLs EL (Rosati,
2007), ELHIO (Perez-Urbina et al., 2010; Mora, Rosati, & Corcho, 2014) and HornSHIQ (Eiter, Ortiz, Simkus, Tran, & Xiao, 2012b), and members of the datalog family (Virgilio, Orsi, Tanca, & Torlone, 2012), to name just a few. No rewriting approach,
however, supports for both nominals and role inclusions. Moreover, a common shortcoming
is that rewritings can be exponential in the query and/or TBox size, so these approaches
may also use exponential space.
The third group consists of approaches based on a particular interpretation of K that
we call the compact interpretation. Figure 4 shows this interpretation for the KB K from
Example 15: it finitely approximates the universal interpretation by using individuals of the
form oS,B to represent all auxiliary terms of type S, B. The compact interpretation can thus
be materialised in space polynomial in |K|, and it can be used to answer instance queries
and test atomic subsumptions over K (Baader et al., 2005; Krotzsch, 2011). Materialising
the compact interpretation lies at the core of many reasoning algorithms for EL variants, so
it is natural to try to use this interpretation for answering CQs as well. Since the compact
interpretation is a model of K, each CQ that maps on the universal interpretation maps on
the compact interpretation as well; however, as Example 16 shows, the converse does not
necessarily hold.
Example 16. Let K be as in Example 15, and let q1 , q2 , and q3 be the following BCQs.
q1 = x. R(x, b)

q2 = x. S(a, x)  S(b, x)

q3 = x. T (b, x)  S(b, x)

The compact interpretation for K is shown in Figure 4; as one can see, it is obtained from
the universal interpretation by merging all terms of type S, B onto the individual oS,B . Now
query q1 can be mapped onto both the compact and the universal interpretation, while queries
q2 and q3 can be mapped only onto the compact interpretation. Thus, evaluating q2 and q3
over the compact interpretation produces unsound answers.
673

fiStefanoni, Motik, Krotzsch, & Rudolph

a

b

{a} a

b {b}

Ax

y B

R
R,D 1

S

T,B
3

S
S

S,B 5
S

R

T

T

T R,A
2

T
T

S

4 T,B

T

T

T
T,B
6

P
S
S

S

T,B

T

7

S
8 S,B

S

S

P,B 9

S
S

T

T,B 10

Universal Interpretation

S
11 S,B

S

z B

Skeleton for q

Figure 5: The universal interpretation of K and the skeleton for q
As a remedy, combined approaches were developed that first evaluate the query in the
compact interpretation and then filter the results to eliminate unsound answers. Such
approaches have been developed for members of the DL-Lite family (Kontchakov et al.,
2011; Lutz, Seylan, Toman, & Wolter, 2013) and the EL family (Lutz, Toman, & Wolter,
2009; Stefanoni et al., 2013) of DLs, and the datalog family (Gottlob, Manna, & Pieris,
2014) of rule-based languages. In particular, Stefanoni et al. (2013) developed a filtering
step applicable to the DL ELHOdr
 , but this step breaks down if K contains role inclusions.
Query q3 from Example 16 can be mapped onto the compact interpretation by mapping
atom S(b, x) to a dashed edge (i.e., to an edge obtained via role inclusions); moreover, q3
is tree-shaped, and so the filtering step by Stefanoni et al. (2013) does not identify this
match as unsound. This problem can be intuitively understood as follows. By unfolding
the query by (22), query q3 essentially asks whether role chains 1  L(S) and 2  L(T )
exist that label a path of solid edges in IK starting at b. In the compact interpretation,
this is satisfied by 1 = S  T and 2 = T when x is mapped to individual oT,B . Individual
oT,B , however, represents distinct terms 3 and 5 from IK ; hence, although 3 is connected
to b via 1 and 5 is connected to b via 2 , role chains 1 and 2 do not satisfy query q3 . In
other words, the compact interpretation is too small to represent the relevant conditions.
4.2 Intuitions
Our worst-case optimal procedure for BCQ answering in ELRO+ is shown in Algorithm 1
on page 681. It essentially extends and refines the algorithm by Krotzsch et al. (2007). We
explain the underlying intuitions using the knowledge base shown in Example 17.
Example 17. Let K be the ELRO+ knowledge base whose TBox contains axioms (23)(29)
and whose RBox contains role inclusions (30)(31).
{a} v R.A
A v T.{b}
674

(23)
(24)

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

iS

S, X/X

fS

, X/fS  X

iT

T, X/X

fT

, X/X

Figure 6: The transitions of R corresponding to axioms (30)(31)
AvD

(25)

{b} v T.B

(26)

{b} v P.B

(27)

B v S.Self

(28)

B v T.B

(29)

T T vT

(30)

ST vS

(31)

Moreover, let q be the following Boolean CQ over K.
q = x, y, z. D(x)  T (x, z)  S(y, z)

(32)

Figure 5 shows the universal interpretation IK for K; notation is as in Example 15. The
solid looping edges on auxiliary terms of concept type B are obtained from axiom (28). One
can see that K |= q holds; for example, the following substitution  embeds q into IK .
 = {x 7 2, y 7 6, z 7 7}

(33)

Our algorithm uses the PDA encoding of the RBox described in Section 3. The transition
function R for axioms (30)(31) is shown in Figure 6; notation is the same as in Example 6;
and note that Figure 6 is contained in Figure 3.
We must prove the existence of a substitution  mapping q into IK . Such a substitution
 can map the binary atoms in q to the dashed edges in Figure 5. Dashed edges introduce
shortcuts between terms in IK , but each dashed edge can be unfolded into a path consisting
only of solid edges using the role inclusions in K. The solid paths in IK can be of two
types: auxiliary paths involve only auxiliary terms, whereas nominal paths require moving
through at least one individual. For instance, edge T (2, 7) can be unfolded into the path
T = T  T  T connecting 2 with b, b with 6, and 6 with 7. In contrast, edge S(6, 7) can
be unfolded into the path S = S  T connecting 6 with itself, and 6 with 7. Our algorithm
then uses PDAs with transition function from Figure 6 to represent each binary atom in
q as a sequence of binary atoms to be mapped over the corresponding solid path in IK .
Interpretation IK , however, is infinite, so the space of possible substitutions is also infinite.
Hence, to prove the existence of a substitution  mapping q into IK , we cannot simply
enumerate all of them, and we use Algorithm 1 instead.
675

fiStefanoni, Motik, Krotzsch, & Rudolph

In line 1 we check whether K is unsatisfiable; if so, then K |= q holds trivially. Next,
in line 2 we guess a substitution  and continue checking K |= (q); thus, this step takes
into account that variables could be mapped to individuals, and that two variables could be
mapped to the same term. In our example, we can guess  to be the identity mapping on
~y . In step 3, we then guess a finite structure, called the skeleton for (q), which represents
a (possibly infinite) set of substitutions mapping the variables of (q) to distinct auxiliary
terms in IK . Figure 5 shows the skeleton S for the query in Example 17: skeleton vertices
are the individuals of K and the variables of (q), and they are arranged as a forest whose
roots are the individuals; moreover, each vertex v of S is assigned an atomic concept (v).
After this step, skeleton S represents each substitution  (if any) satisfying the following
two properties:
1.  maps each variable x to a term of concept type (x), and
2. for each edge hv, v 0 i in S, we have that  (v 0 ) is a descendant of  (v) in IK .
We next extend S with conditions that prune this set of substitutions, with the goal of
leaving only substitutions compatible with (q)that is, that embed (q) into IK .
We establish compatibility with the unary atoms of (q) in line 4. In particular, consider
atom D(x) in (q). By property (1), each substitution  represented by the skeleton in
Figure 5 maps variable x to a term of concept type (x) = A, implying that A( (x))  IK
holds. But then, since K |= (x) v D holds, we know that D( (x))  IK holds as well; thus,
atom D(x) is satisfied for each substitution represented by S.
In contrast, we cannot establish compatibility of binary query atoms using entailment
checking only, because vertex labels and the relative position of vertices do not sufficiently
describe the substitutions. For example, substitution
1 = {x 7 2, y 7 9, z 7 10}

(34)

satisfies properties (1) and (2), but T (1 (x), 1 (z)) 6 IK .
To prune such substitutions, in lines 516 of Algorithm 1 we guess for each binary atom
in (q) how to unfold it as a sequence of solid steps in IK . As solid paths in IK can go
through nominals or through auxiliary terms only, the two possibilities are accounted for
by the guessing in line 8. Moreover, the skeleton already constrains the relative positions of
query terms, so we represent the unfolding of each binary atom by labelling each edge hv, v 0 i
in S with a set L(v, v 0 ) of bounded-stack PDAs with transition function from Figure 6 so
that each substitution  represented by S also satisfies the following property:
3. for each PDA P  L(v, v 0 ), a nonempty role chain   L(P) exists labelling a path in
IK over solid edges from  (v) to  (v 0 ).
We next illustrate how to label the edges of S so that all substitutions satisfying properties
(1)(3) are compatible with each binary atom of (q).
For T (x, z), we must ensure that, for each substitution  represented by S, a role chain
T  L(T ) exists connecting  (x) to  (z) using only solid edges. Since the relative positions
of  (x) and  (z) in IK is determined by S as shown in Figure 5, such a path must connect
 (x) with b, then connect b with  (y), and finally connect  (y) with  (z). In addition, we
can assume that no individuals occur on paths from b to  (y), and from  (y) to  (z): if a
676

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

>r

D
R

{a}

R

B
T

A

S, T

T, P
T

{b}

start

B

S

start

Figure 7: On the left-hand side, the walking finite automaton wfa(A, {b}) (transitions involving >c and >r are not shown for clarity); on the right-hand side, the stationary finite automaton sfa(B)

path from  (x) to  (z) involves individuals other than b or if it visits b more than once, we
can absorb all such path segments into the subpath from  (x) to b. Thus, we check the
existence of such T by setting v0 = au = b in lines 78 (no guessing is possible in line 8 in
this case) and splitting in lines 711 the path T into the three subpaths. In particular,
in line 10 we guess states s0 , s1 , and s2 = fT and in line 11 we guess stack words 0 , 1 ,
and 2 =  with the following properties:
(i) the subpaths from  (x) to b are described by PDA PT0 whose start state and stack are
iT and , respectively, and the final state and stack are s0 and 0 , respectively;
(ii) the subpaths from b to  (y) are described by PDA PT1 whose start state and stack are
s0 and 0 , respectively, and the final state and stack are s1 and 1 , respectively; and
(iii) the subpaths from  (y) to  (z) are described by PDA PT2 whose start state and stack
are s1 and 1 , respectively, and the final state and stack are s2 and 2 , respectively.
We do not know what terms of IK variables y and z should be mapped to, so we cannot
check the existence of paths in (ii) and (iii) independently. Therefore, we add in line 12
PDAs PT1 and PT2 as constraints on edges hb, yi and hy, zi in S, respectively. The edges
of S thus accumulate all constraints that the moves to auxiliary terms must satisfy; later
we shall explain how in lines 1718 we check these constraints and, if this check passes,
how we know that we can map y and z to auxiliary terms whose concept types are (y)
and (z), respectively. In contrast, the path in (i) finishes in an individual, so we can
check existence of such a path independently from any other constraint. To this end, we
construct the walking finite automaton wfa(A, {b}) shown on the left-hand side of Figure
7. Such wfa(A, {b}) describes the moves in IK from terms with concept type (x) = A to
individual bthat is, such that   L(wfa(A, {b})) for each term w with concept type A
and for each role chain  connecting w to b in IK via solid edges; then, in line 14 we check
whether the intersection of the languages of wfa(A, {b}) and PT0 is empty. As wfa(A, {b})
is a FA and PT0 is a PDA, we can test the emptiness of the intersection of their languages in
polynomial time (Hopcroft et al., 2003). In our example, we can guess s0 = s1 = s2 = fT .
677

fiStefanoni, Motik, Krotzsch, & Rudolph

Thus, PT1 accepts the language T  , and because b is connected to 1 (y) by a solid edge
labelled by P , adding PT1 as constraint on edge hb, yi ensures that substitution 1 from (34)
does not satisfy property (3).
For S(y, z), we must ensure that, for each substitution  represented by S, a role chain
S  L(S) exists connecting  (y) to  (z) using only solid edges. Now even though z is a
descendant of y in S, in line 8 we could guess v0 = au = b, so that S connects  (y) with b
and then, without going through individuals, connects b with  (z) via  (y). In the rest of
this paragraph, however, we consider the case in which S connects  (y) with  (z) directly,
since that is the only possibility in our example, as one can see in Figure 5. Therefore, in
line 8, we guess v0 = t = y. But then, a path from  (y) to  (z) could first loop on  (y)
due to self-restrictions; then it must actually move from  (y) to  (z); and finally it could
loop on  (z). For reasons we discuss in the following paragraph, we absorb the latter loop
into a constraint added to edge hy, zi; however, we check the existence of the former loop
independently. Therefore, in lines 711 we split S into two subpaths. In particular, in
line 10 we guess states s0 and s1 = fS , and in line 11 we guess stack words 0 and 1 = 
with the following properties:
(i) the looping on  (y) is described by PDA PS0 whose start state and stack are iS and
, respectively, and the final state and stack are s0 and 0 , respectively; and
(ii) the subpaths from  (y) to  (z) that start with a move from  (y), but possibly involve
looping on  (z), are described by PDA PS1 whose start state and stack are s0 and 0 ,
respectively, and the final state and stack are s1 and 1 , respectively.
As in the previous case, we check (ii) by adding PS1 as constraint on edge hy, zi in S.
Furthermore, we check the existence of a path in (i) by constructing the stationary finite
automaton sfa(B) shown on the right-hand side of Figure 7. Such sfa(B) describes the
possible loops on terms with concept type (y) = B; that is, such that   L(sfa(B)) for
each term w with concept type B and for each role chain  corresponding to a (possibly
empty) loop on w; then, in line 16 we check whether the intersection of the languages
of sfa(B) and PS0 is empty. In our example, we guess s0 = s1 = fS ; thus PS0 accepts the
language S  T  , whereas PS1 accepts the language T  .
Before line 17, skeleton S represents all substitutions that are compatible with the
atoms in (q), but we must still show that at least one such substitution can be realised
by the universal interpretation IK . To this end, we apply Algorithm 2 on page 681 to each
edge hv, v 0 i in the skeleton, and thus we check whether terms  (v) and  (v 0 ) in IK exist
that satisfy properties (1)(3) for all PDAs in L(v, v 0 ). Roughly speaking, we solve this
problem by running all PDAs in parallel in lines 715 of Algorithm 2. However, we cannot
materialise IK , so we exploit a property of our consequence-based chase procedure: a term
w with concept type A is connected to a term w0 with concept type B in IK using a solid
edge labelled by S if and only if K |= A v S.B. Furthermore, the concept type of w fully
describes the solid paths to descendants of w, so we do not need to keep track of the actual
position in IK ; instead, we use variable concept to keep track of the current terms concept
type. Thus, in line 9 we check existence of edges in IK via entailment checking; after that,
for each PDA, in line 11 we guess a state s and a stack  of the PDA, in line 12 we check
whether the PDA can perform the move, and in line 14 we actually move the PDA. Due to
678

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

self-restrictions and reflexive roles, however, the PDAs need not move in synchrony: after
each move over a solid edge, each of the PDAs can independently loop on the current term.
To this end, in line 11 we guess a state s0 and a stack  0 that the PDA moves into after
looping, and in line 13 we check whether the PDA can move from state s with stack  to
state s0 with stack  0 using a role chain compatible with the concept type of the term the
PDA is moving into, as given by the stationary finite automaton sfa(D). Because not all
PDAs are required to loop, FA sfa(D) accepts the empty word. Algorithm 2 thus checks
loops only after each move, which is why line 16 in Algorithm 1 is necessary. Lines 25
take into account that each of the PDAs is nondeterministic and so it can initially make
several -transitions; note that an explicit check for -transitions is required only initially
since line 13 allows for possible -transitions after each move along a solid edge. Finally, we
ensure termination of Algorithm 2 by observing that, since the stack of each PDA in L(v, v 0 )
is bounded, the number of current configurations of each of the PDA is exponential, and
so the number of distinct tuples of the current PDA configurations is exponential as well;
hence, the algorithm repeats computations after at most exponentially many steps. We
thus obtain a nondeterministic decision procedure running in polynomial space by using a
binary counter to stop the computation after all distinct configurations have been explored.
For the constraints added to S in the previous paragraphs, one can check that Algorithm 2
returns true on all edges of S; hence, K |= (q) holds, and thus K |= q holds as well.
4.3 Formalisation
We now formalise the intuitions from the previous section. Towards this goal, we fix a
normalised ELRO+ KB K = hT , R, Ai with a regular RBox R, we let QR , R , and R be
as specified in Definition 4, and we let dR be the depth of R as specified in Section 3. We
start by formalising the notion of a skeleton of a Boolean CQ.
Definition 18. A skeleton for a Boolean CQ q = ~y . (~y ) is a triple S = hV, E, i with
the following components.
1. V = IK  ~y is the set of vertices.
2. E  V  ~y is the set of edges such that the directed graph hV, Ei is a forest whose
roots are precisely the elements of IK .
3.  : ~y 7 {>c }  CK is a function that maps the existential variables of q to atomic
concepts. For convenience,  is extended to V by (v) := {v} for each v  IK .
A path in S is a nonempty sequence of (distinct) vertices v0 , . . . , vn such that n  0 and,
for each i  [0..n  1], we have that hvi , vi+1 i  E.
Please observe that, as K is in normal form, there exists at least one individual occurring
in K and thus V  I 6= . We next generalise the notion of a PDA encoding the RBox R
from Definition 4 by allowing arbitrary start and final states as well as arbitrary start and
final stacks of size at most dR . These generalised PDA will be used in our algorithm to
implement the splitting operation mentioned in Section 4.2.
Definition 19. For states s, s0  QR and words ,  0  R with ||  dR and | 0 |  dR , a
generalised PDA for R is given by pda(s, , s0 ,  0 ) := hQR , R , R , R , s, , s0 ,  0 i.
679

fiStefanoni, Motik, Krotzsch, & Rudolph

The following definition introduces automata that one can use to succinctly represent
the axioms that logically follow from K.
Definition 20. Let A and B be basic concepts. The walking finite automaton from A to
B is given by wfa(A, B) := hQ, R , w , A, Bi where Q and w are as follows.
 Q = {>c }  CK  NK .
 w is the transition function containing D  w (C, S) for each role S  R and all
states C and D in Q such that K |= C v S.D.
The stationary finite automaton for A is given by sfa(A) := h{A}, R , s , A, Ai where s
contains A  s (A, S) for each role S  R with K |= A v S.Self or K |=  v S.
Boolean CQs can be answered by the nondeterministic procedure entails shown in Algorithm 1, which uses an auxiliary procedure exist shown in Algorithm 2. The following
theorem states that entails(K, q) decides K |= q, and its proof is given in Section 4.4.
Theorem 21. Let q be a Boolean CQ over K. Then, K |= q if and only if a nondeterministic
computation exists such that entails(K, q) returns true.
Finally, we determine the complexity of the algorithm entails, and towards this goal we
first determine the complexity of the auxiliary function exist.
Lemma 22. Function exist(A, B, {Pj = pda(sj , j , s0j , j0 ) | 0  j  m}) can be implemented so that it uses space polynomial in m  |K| and, if the RBox R is fixed, it runs in
time polynomial in |T | + |A|.
Proof. Consider arbitrary A, B, and Pj = pda(sj , j , s0j , j0 ) as stated above; let M be as
in Algorithm 2; and let ` be the derivation relation corresponding to R . By the definition
of generalised PDAs, we have |j |  dR and |j0 |  dR for each j  [1..m].
By Proposition 2, using polynomial time one can compute PDAs accepting languages
LdR (pda(sj , j , s, )) and LdR (pda(s, , s0 ,  0 )) in lines 4 and 13; therefore, checks in lines
4 and 13 can be implemented so that they use time (and therefore space) polynomial in
|K| (Hopcroft et al., 2003, ch. 7).
For the space usage of Algorithm 2, please observe that the function stores the following
information at each computation step:
(a) an array state of length m such that state[j]  QR for each j  [1..m], an array stack of
length m such that stack[j]  R and |stack[j]|  dR for each j  [1..m],
(b) a generalised PDA in line 4,
(c) a generalised PDA and a stationary automaton in line 14,
(d) a concept concept  {A, >c }  CK in line 1,
(e) a binary counter k such that 1  k  M , and
(f) the depth dR of R, an atomic concept D  {>c }  CK , and a role S  R .
680

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

Algorithm 1: entails(K, q)
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

if K is inconsistent then return true
guess a substitution  with dom() = ~y and rng()  ~y  IK
guess a skeleton S = hV, E, i for (q)
if an atom A(t) in (q) exists such that K 6|= (t) v A then return false
foreach hv, v 0 i  E do let L(v, v 0 ) := 
foreach binary atom S(t, u) in (q) do
let au be the unique individual such that u is reachable from au in S
guess v0  {t, au } such that u is reachable from v0 in S
let v0 , . . . , vn be the unique path in S such that vn = u
guess states s0 , . . . , sn in QR such that sn = fS
guess words 0 , . . . .n in R such that n =  and |i |  dR for each i  [0..n]
foreach i  [1..n] do let L(vi1 , vi ) := L(vi1 , vi )  {pda(si1 , i1 , si , i )}
if v0  I then
if L(wfa((t), (v0 )))  L(pda(iS , , s0 , 0 )) =  then return false
else
if L(sfa((v0 )))  L(pda(iS , , s0 , 0 )) =  then return false
foreach hv, v 0 i  E do
if not exist((v), (v 0 ), L(v, v 0 )) then return false
return true

Algorithm 2: exist(A, B, {Pj = pda(sj , j , s0j , j0 ) | 0  j  m})
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

let concept := A and let M := (1 + |CK |)  |QR |m  (|R |1+dR )m
for j = 1 to m do
guess a state s  QR and a word   R such that ||  dR
if  6 LdR (pda(sj , j , s, )) then return false
set state[j] := s and stack[j] := 
guess k  N such that 1  k  M
for r = 1 to k do
guess S  R and D  {>c }  CK
if K 6|= concept v S.D, or K |= D v {a} for some a  IK then return false
for j = 1 to m do
guess {s, s0 }  QR and {,  0 }  R with ||  dR and | 0 |  dR
if hstate[j], S, stack[j]i 6` hs, , i then return false
if L(sfa(D))  LdR (pda(s, , s0 ,  0 )) =  then return false
set state[j] := s0 and stack[j] :=  0
set concept := D
if concept 6= B then return false
if there exists an index j  [1..m] such that state[j] 6= s0j or stack[j] 6= j0 then
return false
return true

681

fiStefanoni, Motik, Krotzsch, & Rudolph

By the definition of dR , we have that dR is linearly bounded by the number of axioms occurring in R; hence, we need at most O(m  |R|) space to store the two arrays. Furthermore, we
need at most O(m  |K|) space to store the counter k using binary encoding. By Definition
20, the size of sfa(D) is polynomial in |K|; by Definition 4, the size of pda(s, , s0 ,  0 ) is polynomial in |R|. Overall, the space needed to store the required information is polynomial in
m  |K|. Finally, following Krotzsch (2011), we can realise the check in step 9 in polynomial
time. Thus, exist can be implemented so that it uses space polynomial in m  |K|.
Next, assume that the RBox R is fixed. Then dR , QR , R , and R are all fixed as
well; moreover, m is bounded by the size of R and so it is fixed, and M is linear in the
size of T and A. Thus, the number of alternatives in the nondeterministic step in line 3
of Algorithm 2 is fixed, so lines 15 require time polynomial in |T | + |A|. Furthermore,
instead of guessing k using the nondeterministic step 6, we can repeat lines 715 for each
k  [1..M ], which requires a linear number of iterations. To show that lines 715 can also
be implemented to run in polynomial time, we first define three sets which can be used to
perform the checks in lines 9, 12, and 13.
{hS, C, Di  R  (CK  NK  {>c })2 | K |= C v S.D and a  IK : K 6|= D v {a}} (35)
{hS, pda(s, , s0 ,  0 )i | for S  R with hs, S, i ` hs0 , ,  0 i} (36)
{hC, pda(s, , s0 ,  0 )i | for C  CK  {>c } with L(sfa(C))  LdR (pda(s, , s0 ,  0 )) 6= } (37)
Given that R is fixed, these sets can be computed in time polynomial in the size of T and
A. We next show that we can implement the for-loop in steps 715 to use space logarithmic
in the size of T , A, and of the sets in equations (35)(37). For the space usage in lines 715,
at each computation step of the for-loop we store the information from points (a)(f) above.
Since R and m are fixed, however, points (a)(c) require constant space. Furthermore, the
checks in lines 9, 12, and 13 can be performed by a lookup in sets (35)(37); by storing
these sets using a suitable binary encoding and by using a binary index into the sets, this
check can be implemented using logarithmic space. Finally, as CK and M are linear in the
size of T and A, we can store counter k, concepts D and concept, and role S using a binary
encoding, so the overall space the function needs to store is logarithmic in |T | + |A|, and the
size of the sets (35)(37). Thus, steps 715 require nondeterministic logarithmic space, and
it is well known that this implies that steps 715 can be implemented to run in polynomial
time. Finally, steps 1619 clearly require polynomial time. Consequently, function exist can
be implemented so that it runs in time polynomial in |T | + |A| for fixed R.
We are now ready to establish the complexity of function entails(K, q); in Section 5 we
shall show that our function is worst-case optimal in combined and data complexities.
Theorem 23. For q a BCQ over K, function entails(K, q) can be implemented so that
1. it uses space polynomial in the input size,
2. if the RBox R is fixed, it runs in nondeterministic polynomial time in the size of the
TBox T , the ABox A, and the query q, and
3. if the RBox R and the query q are fixed, it runs in (deterministic) polynomial time in
the size of the TBox T and the ABox A.
682

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

Proof. Let q = ~y .(~y ) be a Boolean CQ over K.
As shown in Proposition 2, one can compute in lines 14 and 16 a PDA accepting language
LdR (pda(iS , , s0 , 0 )) in polynomial time, so the checks in lines 14 and 16 require time
(and therefore space) polynomial in |K| (Hopcroft et al., 2003, ch. 7). Moreover, the checks
in lines 1 and 4 also require time polynomial in |K| (Krotzsch, 2011).
For (1), please observe that the function entails as specified in Algorithm 1 stores the
following information at each computation step:
 a substitution  with dom() = ~y and rng()  ~y  IK ;
 a skeleton S = hV, E, i for (q);
 a path v0 , . . . , vn in S, a sequence of states s0 , . . . , sn in QR , and a sequence of words
0 , . . . , n in R such that |i |  dR for each i  [0..n];
 a function L mapping each edge hv, v 0 i  E to a set of generalised PDA; and,
 a walking automaton wfa((t), (v0 )) and a stationary automaton sfa((v0 )).
By the definition of skeleton for (q), we need space polynomial in the size q and K to
store S. Moreover, the length of the longest path in S is given by the number of variables
occurring in (q), so we can store the sequences of vertices, states, and words in space
polynomial in |q| and |K| as well. Also, each set L(v, v 0 ) contains at most m PDAs, where
m is the number of binary atoms occurring in (q). Then, by Lemma 22, entails can be
implemented so that it uses space polynomial in the input size.
For (2), assume that the RBox R is fixed. By Lemma 22, for a fixed RBox R, step 18
can be implemented so that it runs in time polynomial in |T | + |A|. Clearly, all other steps
in Algorithm 1 can be implemented to run in nondeterministic polynomial time in the size
of TBox T , ABox A, and query q. Consequently, for a fixed RBox R, function entails can
be implemented so that it runs in nondeterministic polynomial time in in the size of TBox
T , ABox A, and query q.
For (3), assume that the RBox R and the query q are fixed. Then dR , QR , R , and R
are all fixed as well. Given that the number of variables occurring in q is fixed, the number
of guessing steps required in steps 2 and 3 is fixed; also, the number of alternatives for these
steps is linear in |T | + |A|. Thus, steps 2 and 3 require polynomial time. Furthermore, the
maximum number of iterations of the for-loop in steps 616 is fixed and the length of the
longest path in S is fixed. Thus, the number of guessing steps in lines 11 and 12 is also
fixed. In addition, the number of alternatives for the guessing steps in lines 8, 11, and 12
is fixed as well. Therefore, steps 616 require time polynomial in |T | + |A|. Finally, since
the query is fixed, the maximum number of iterations of the for-loop in steps 17 and 18
is also fixed and so, by Lemma 22, steps 17 and 18 require time polynomial in T and A.
Therefore, entails can be implemented so that it runs in time polynomial in |T | + |A| for
fixed R and q.

683

fiStefanoni, Motik, Krotzsch, & Rudolph

4.4 Proof of Theorem 21
We now prove that our function entails(K, q) indeed decides K |= q. Towards this goal, we
start by proving the correctness of function exist, after which we introduce the universal
interpretation of K, and, finally, we show that entails is sound and complete.
4.4.1 Correctness of exist
The following proposition proves the correctness of function exist from Algorithm 2.
Lemma 24. Function exist(A, B, {Pj = pda(sj , j , s0j , j0 ) | 0  j  m}) returns true if
and only if there exist a natural number k  1, roles S1 , . . . , Sk , basic concepts A0 , . . . , Ak
with A0 = A and Ak = B, and role chains {j,i | j  [1..m] and i  [1..k]} such that the
following conditions hold for each i  [1..k] and each j  [1..m].
1. For each a  IK , we have K |= Ai1 v Si .Ai and K 6|= Ai v {a}.
2. For each role T occurring in j,i , we have K |= Ai v T.Self or K |=  v T .
3. S1  j,1    Sk  j,k  LdR (Pj ).
Proof. Consider arbitrary A, B, and Pj = pda(sj , j , s0j , j0 ) as stated in the lemma. Moreover, let ` be the derivation relation corresponding to R .
() Assume that there is a nondeterministic computation of exist such that the function
returns true. Let k  N be as guessed in step 6; we show that the for-loop in steps 715
satisfies the following invariant: after each iteration r, there exist roles S1 , . . . , Sr , basic
concepts A0 , . . . , Ar , and, for each j  [1..m], role chains j,1 , . . . , j,r such that A0 = A,
Ar = concept, and the following holds for each i  [1..r] and j  [1..m].
(i) K |= Ai1 v Si .Ai and, for each a  IK , we have K 6|= Ai v {a}.
(ii) For each role T occurring in j,i , we have K |= Ai v T.Self or K |=  v T .
(iii) S1  j,1    Sr  j,r  LdR (pda(sj , j , state[j], stack[j])).
Base case. Before the first iteration of the loop (i.e., after steps 15 and for r = 0),
we have concept = A, and   LdR (pda(sj , j , state[j], stack[j]) for each j  [1..m], so
properties (i)(iii) clearly hold.
Inductive step. Consider an arbitrary iteration r  [1..k  1] and assume that properties
(i)(iii) hold at the end of iteration r; we show that the same is true after iteration r + 1.
By the inductive hypothesis, there exist roles S1 , . . . , Sr , basic concepts A0 , . . . , Ar , and, for
each j  [1..m], role chains j,1 , . . . , j,r such that A0 = A, Ar = concept and properties
(i)(iii) hold. Let role Sr+1 = S and atomic concept Ar+1 = D be as guessed in step 8.
Clearly, we have K |= concept v Sr+1 .Ar+1 and that K 6|= Ar+1 v {a} for each a  IK , as
required for property (i). Furthermore, consider an arbitrary j  [1..m], let s, s0 , , and
 0 be as guessed in step 11, and let state[j] and stack[j] be as at the end of iteration r;
then, hstate[j], Sr+1 , stack[j]i ` hs, , i due to step 12; furthermore, due to step 13, a role
chain j,r+1 exists such that j,r+1  L(sfa(D))  LdR (pda(s, , s0 ,  0 )). By Definition 20
of stationary automata, for each role T occurring in j,r+1 we have K |= D v T.Self or
684

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

K |=  v T , as required for property (ii). Finally, let state[j] and stack[j] be as specified
in step 14; then S1  j,1    Sr  j,r  Sr+1  j,r+1  LdR (pda(sj , j , state[j], stack[j])), so
property (iii) holds.
Step 16 ensures that concept = B; furthermore, steps 1718 ensure that state[j] = s0j and
stack[j] = j0 for each j  [1..m], so PDA Pj accepts S1  j,1    Sk  j,k . Thus, properties
(1)(3) of this lemma hold, as required.
() Let S1 , . . . , Sn be roles, let A0 , . . . , An be basic concepts with A0 = A and An = B,
and let j,i be role chains satisfying properties (1)(3) of this lemma. Each derivation for
S1  j,1    Sn  j,n of PDA Pj is of the following form, where sj,n+1 = s0j and j,n+1 = j0 :
hsj , S1  j,1    Sn  j,n , j i `
hs0j,1 ,

hsj,1 , S1  j,1    Sn  j,n , j,1 i `

j,1  S2    Sn  j,n ,

hsj,2 , S2  j,2    Sn  j,n , j,2 i `

0
j,1
i

(39)



(40)



(41)

. . . `

(42)

`

... `
hs0j,i ,

hsj,i , Si  j,i    Sn  j,n , j,i i `

j,i  Si+1    Sn  j,n ,

hsj,i+1 , Si+1  j,i    Sn  j,n , j,i+1 i `
hs0j,n ,

hsj,n , Sn  j,n , j,n i `
hsj,n+1 , , j,n+1 i

j,n ,

(38)



0
j,i
i
0
j,n
i

`



`

(43)
(44)

Transition from (38) to (39) is special in the sense that it allows Pj to make an arbitrary
number of -transitions; the rest of the derivation is regular and consists of reading Si and
j,i . Thus, sj,i and s0j,i are the states of Pj before and after, respectively, reading Si , and
0 are the respective stacks. By property (3) of this lemma, we have | |  d
j,i and j,i
j,i
R
0
and |j,i |  dR .
Let Xi = hAi , s1,i , 1,i , . . . , sm,i , m,i i. For each PDA, there are |QR | many different
P R
|R |` many difstates, 1+|CK | different elements in {>c }CK ; furthermore, there are d`=0
PdR
ferent stacks of length at most dR . As |R | > 0 and dR > 0, we have `=0 |R |`  |R |1+dR ;
consequently, there are at most M distinct such tuples. Thus, for some k  M , we have that
Xk = Xn+1 . But then, Ak = B; furthermore, for each j  [1..m], we have sj,k = sj,n+1 = s0j
and j,k = j,n+1 = j0 , so we have S1  j,1    Sk  j,k  LdR (Pj ).
We can now easily construct a nondeterministic computation of exist as follows. In
step 3, for each j we let s = sj,1 and  = j,1 ; clearly, condition in step 4 is not satisfied.
For each r in the for-loop in lines 715, we proceed as follows.
 In step 8 we let S = Si and D = Ai , respectively; clearly, condition in step 9 is not
satisfied due to property (1).
0 , and  0 = 
 For each j  [1..m], we let s = s0j,r , s0 = sj,r+1 ,  = j,r
j,r+1 ; clearly,
condition in step 12 is not satisfied due to the form of the derivation; furthermore,
condition in step 13 is not satisfied due to property (2) and Definition 20.

Finally, conditions in steps 16 and 17 are not satisfied due to the way in which we chose k.
Therefore, function exist returns true in step 19.

685

fiStefanoni, Motik, Krotzsch, & Rudolph

Rule
(cr1)
(cr2)

(cr3)

(cr4)
(cr5)

(cr6)

(cr7)

Precondition
K |= A1 u A2 v B
{A1 (w), A2 (w)}  I
K |= A v S.B
K |= B v {a} for some a  IK
A(w)  I
K |= A v S.B
K 6|= B v {a} for each a  IK
A(w)  I
K |= S.A v B
{S(w, w0 ), A(w0 )}  I
K |= S.Self v B
S(w, w)  I
role S is simple
K |= A v S.Self
A(w)  I
role S is simple
  L(S)
(w, w0 )  I

Conclusion
B(w)
S(w, a), B(a)

S(w, fS,B (w)), B(fS,B (w))
>c (fS,B (w)), >r (fS,B (w), fS,B (w))
>r (fS,B (w), w0 ) for each term w0 occurring in I
>r (w0 , fS,B (w)) for each term w0 occurring in I
B(w)
B(w)

S(w, w)

S(w, w0 )

Table 5: Rules of the consequence-based chase
4.4.2 Consequence-Based Chase and Universal Interpretations
To prove that entails(K, q) is sound and complete, we interpret K using the forest-shaped
universal interpretation described in Section 4.2. Towards this goal, we next define some
auxiliary notions, then define the universal interpretation, and, finally, we prove two properties of such interpretation.
The universe of K is the set of all terms built from the individuals occurring in K and the
unary function symbols of the form fS,A with S  R and A  CK . Since K is normalised,
the universe of K is nonempty. A fact is a ground atom constructed using the predicates
occurring in K and the terms from the universe of K. For a role chain  = S1    Sn , terms
w and w0 , and a set of facts I, we write (w, w0 )  I if (not necessarily distinct) terms
w = w0 , . . . , wn = w0 exists such that Si (wi1 , wi )  I for each i  [1..n]. A set of facts
I entails a Boolean CQ q = ~y . (~y ), written I |= q, if a substitution  exists such that
dom( ) = ~y and  (q)  I. The universal interpretation IK of K is defined as follows.
Definition 25. A chase rule from Table 5 is applicable to a set of facts I if the preconditions
of the rule are satisfied, but I does not contain all conclusions of the rule. A consequencebased chase (often just chase) for K is a sequence of sets of facts I0 , I1 , . . . where
I0 = {{a}(a), >c (a), >r (a, b) | {a, b}  IK }  A

(45)

and, for each i  1, set Ii+1 is obtained by extending Ii with the conclusion of one (arbitrarily
chosen) chase rule applicable to Ii , and Ii+1 = Ii if no chase rule is applicable to Ii . This
686

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

sequence must be fairthat is, if a derivation rule is applicable to some Ii for a specific
precondition, then j  i exists suchSthat Ij+1 is obtained from Ij by applying the rule to the
mentioned precondition. Set IK = iN Ii is a universal interpretation of K.
Since K is in normal form, we have K 6|= {a} v {b} for all distinct individuals a and
b in IK ; hence, at most one individual a  IK exists in rule (cr2) such that K |= B v {a}.
Because of that, it is straightforward to see that IK is independent from the order in which
the chase rules are applied, so we call IK the universal interpretation of K. Moreover,
due to fairness, no derivation rule is applicable to IK that is, for each chase rule from
Table 5 either the preconditions of the rule are not satisfied in IK , or IK contains all the
conclusions of the rule. Finally, it is well-known that, if K is consistent, then IK can be
homomorphically embedded into any model of K (Krotzsch et al., 2007). Consequently, the
universal interpretation IK can be used to answer arbitrary Boolean CQs over K.
Fact 26. For each Boolean CQ q, we have K |= q if and only if K |= >c v c or IK |= q.
Next, we show how IK relates to the axioms entailed by K. To this end, let  be the
following function mapping each term w in the universe of K to a basic concept:
(
{w} if w  I
(w) :=
A
if w is of the form w = fS,A (w0 )
Proposition 27. The universal model IK satisfies the following properties.
1. For each A(w)  IK , we have K |= (w) v A.
2. For each S(w, w0 )  IK , a nonempty role chain  = 0  S1  1    m1  Sm  m with
  L(S) and terms w0 , . . . , wm from the universe of K with w0 = w and wm = w0
exist such that
(a) for each i  [1..m], either wi  IK , or an atomic concept Ai  {>c }  CK exists
such that wi = fSi ,Ai (wi1 ) and K 6|= Ai v {a} for each individual a  IK ,
(b) for each i  [1..m], we have K |= (wi1 ) v Si .(wi ), and
(c) for each i  [0..m] and each role T occurring in i , we have K |= (wi ) v T.Self
or K |=  v T .
Proof. Let I0 , I1 , . . . be a chase sequence for K. We show by induction on rule applications that properties (1) and (2) are satisfied for each A(w)  In and each S(w, w0 )  In ,
respectively, and that In additionally satisfies the following property:
3. For each term w occurring in In , we have K |= x.(w)(x).
By the definition of I0 and (cr3), for each In and all terms w and w0 occurring in In , we
clearly have {>c (w), >r (w, w0 ), >r (w0 , w)}  In .
Base case. Consider I0 , and note that each term w occurring in I0 is an individual so
(w) = {w}. Consider some A(a)  I0 ; then either A(a)  A, A = {a}, or A = >c , so we
have K |= {a} v A, and property (1) holds. Furthermore, consider some S(a, b)  I0 ; then
687

fiStefanoni, Motik, Krotzsch, & Rudolph

S(a, b)  A or S = >r , so we have K |= {a} v S.{b}, and property (2) holds for w0 = a,
w1 = b, and  = S. Finally, property (3) holds because K |= x.{a}(x) for each a  IK .
Inductive step. Assume that some In satisfies properties (1)(3). By considering each
derivation rule, we assume that the rule is applicable to In as shown in Table 5, and we
show that properties (1)(3) hold for all conclusions of the rule. Note that only rule (cr3)
can affect property (3), and we do not explicitly consider properties that hold vacuously.
(cr1) By the inductive hypothesis, we have K |= (w) v A1 and K |= (w) v A2 , which
implies K |= (w) v B, as required for property (1).
(cr2) By the inductive hypothesis, we have K |= (w) v A and K |= x.(w)(x), which
clearly imply K |= (w) v S.B and K |= x.B(x). Moreover, (a) = {a}, so K |= (a) v B,
and property (1) holds. Finally, since K |= (w) v S.(a), property (2) holds for w0 = w,
w1 = a, and  = S.
(cr3) Let w00 = fS,B (w). By the inductive hypothesis, we have K |= (w) v A and
K |= x.(w)(x), so we have K |= (w) v S.B and K |= x.B(x). Moreover, (w00 ) = B, so
K |= (w00 ) v B, K |= (w00 ) v >c , and K |= x.(w00 )(x), as required for properties (1) and
(3), respectively. For property (2), we consider all role assertions derived by the rule.
 S(w, w00 ). Note that K |= (w) v S.(w00 ) and K 6|= B v {a} for each a  IK , so
property (2) holds for w0 = w, w1 = w00 , and  = S.
 >r (w00 , w00 ). Clearly, property (2) holds for w0 = w00 and  = 0 = >r .
 >r (w00 , w0 ) for some term w0 occurring in In . Let a be the individual that w0 is rooted
in; then, >r (a, w0 )  In so, by the inductive hypothesis, a role chain   L(>r ) and
terms a = w0 , . . . , wm = w0 exist satisfying properties (a)(c). Since K |= x.(w00 )(x),
we have K |= (w00 ) v >r .{a}; thus, >r   and w00 , w0 , . . . , wm satisfy property (2).
 >r (w0 , w00 ) for some term w0 occurring in In . Then, >r (w0 , w)  In so, by the inductive
hypothesis, a role chain   L(>r ) and terms w0 = w0 , . . . , wm = w exist satisfying
properties (a)(c). But then,   >r and w0 , . . . , wm , w00 satisfy property (2).
(cr4) By the inductive hypothesis, we have K |= (w0 ) v A; moreover, terms w0 , . . . , wm
with w0 = w and wm = w0 and a nonempty role chain  = 0  S1  1    m1  Sm  m with
  L(S) exist satisfying properties (a)(c). By the definition of L(S), we have K |=  v S;
together with the entailments in properties (b) and (c), we have K |= (w) v S.(w0 ). But
then, we have K |= (w) v S.A, which implies K |= (w) v B, as required for property (1).
(cr5) By the inductive hypothesis, a nonempty role chain   L(S) exist satisfying
properties (a)(c); moreover, K |=  v S by the definition of L(S). Role S is simple, so
|| = 1, and therefore  can have one of the following two forms.
  = 0 and 0 = T . By property (c), we have K |= (w) v T.Self or K |=  v T .
Furthermore, due to K |=  v S, we have K |= T v S. But then, K |= (w) v S.Self,
and so K |= (w) v B holds, as required for property (1).
  = S1 . Terms w0 and w1 satisfying property (2) are then both equal to w; moreover,
w1 is not of the form fS1 ,A1 (w), so w  IK . Furthermore, by property (b) we have
688

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

K |= (w) v S1 .(w); together with w  IK , we have K |= (w) v S1 .Self. Finally,
due to K |=  v S, we have K |= S1 v S. But then, K |= (w) v S.Self, and so
K |= (w) v B holds, as required for property (1).
(cr6) By the inductive hypothesis, we have K |= (w) v A, from which we can conclude
K |= (w) v S.Self, so property (2) holds for w0 = w and  = 0 = S.
(cr7) If  = , then w = w0 and K |=  v S, and property (2) holds for w0 = w
and  = 0 = S. Otherwise, assume that  is nonempty and of the form  = S1    Sk .
Thus, terms w0 , . . . , wk with w0 = w and wk = w0 exist such that Si (wi1 , wi )  In for
i
each i  [1..k]. By the inductive hypothesis, for each i  [1..k], terms w0i , . . . , wm
with
i
i
i
i
i
w0 = wi1 and wmi = wi and a role chain  with   L(Si ) exist satisfying properties
k
i1 = w i for each
(a)(c); note that w0i = w0 = w, that wm
= wk = w0 , and that wm
0
i1
k
1
k
i  [1..k]. By the definition of L(S), then       L(S), and so property (2) holds for
1 , . . . , wk , . . . , wk .
role chain 1    k and terms w0 , w11 , . . . , wm
mk
1
1
4.4.3 Soundness
We are now ready to show that our algorithm entails is sound.
Lemma 28. If a nondeterministic computation exists such that entails(K, q) returns true,
then K |= q.
Proof. Assume that a nondeterministic computation exists such that entails(K, q) returns
true. If our algorithm returns true in step 1, then K |= q, as K is inconsistent; hence, in the
rest of this proof, we assume that K is consistent and show that IK |= q. To this end, let
substitution , skeleton S = hV, E, i, and function L be as determined by entails. Graph
hV, Ei is a forest rooted in the individuals occurring in K so, by structural induction on this
forest, we define mapping  from V to the universe of K that will satisfy the following:
(i) for each v  V , we have (v)( (v))  IK ; and
(ii) for each hv, v 0 i  E and each Pj  L(v, v 0 ), a role chain j  L(Pj ) exists such that
j ( (v),  (v 0 ))  IK .
Base case. For each a  IK , let  (a) = a. Since (a) = {a} and {a}(a)  IK , the first
property clearly holds, and the second property is vacuous.
Inductive step. Consider hv, v 0 i  E such that  (v) has been defined, but  (v 0 ) has not;
let L(v, v 0 ) = {P1 , . . . , Pm }. Since exist((v), (v 0 ), L(v, v 0 )) returns true, by Lemma 24
we have that roles S1 , . . . , Sn , atomic concepts A1 , . . . , An , and, for each j  [1..m], a role
chain j = S1  j,1    Sn  j,n exist such that n  1, A0 = (v) and An = (v 0 ), and the
following holds for each i  [1..n] and each j  [1..m].
1. For each a  IK , we have K |= Ai1 v Si .Ai and K 6|= Ai v {a}.
2. For each role T occurring in j,i , we have K |= Ai v T.Self or K |=  v T .
3. j  LdR (Pj ).

689

fiStefanoni, Motik, Krotzsch, & Rudolph

Let w0 =  (v); let wi = fSi ,Ai (wi1 ) for i  [1..n]; and let  (v 0 ) = wn . Since A0 = (v), by
the inductive hypothesis we have A0 ( (v))  IK . Furthermore, (cr3) is not applicable to
IK so, for each i  [1..n], we have Si (wi1 , wi )  IK and Ai (wi )  IK ; thus, ( (v 0 ))  IK ,
as required. Finally, for each role T occurring in each j,i , we have K |= Ai v T.Self or
K |=  v T ; (cr6) and (cr7) are not applicable to IK , respectively, so we have T (wi , wi )  IK ;
thus, we have j ( (v),  (v 0 ))  IK , as required.
We next show that  ((q))  IK by considering independently each atom in (q). To
prove the lemma, we can combine  and  in the obvious way.
Consider an arbitrary unary atom A(t) in (q). By step 4 of Algorithm 1, we have
K |= (t) v A, which also implies K |= (t) u (t) v A. By property (i), we have
(t)( (t))  IK . Since rule (cr1) is not applicable to IK , we have A( (t))  IK , as required.
Consider an arbitrary binary atom S(t, u) in (q). Let v0 , . . . , vn , s0 , . . . , sn , and
0 , . . . , n be as determined in steps 811 when Algorithm 1 considers atom S(t, u). For each
i  [1..n], we have pda(si1 , i1 , si , i )  L(vi1 , vi ) by step 12; but then, by property (ii)
a role chain i exists such that i  L(pda(si1 , i1 , si , i )) and i ( (vi1 ),  (vi ))  IK .
Next, we define 0 by considering the following two cases.
 v0  I. By step 14 of Algorithm 1, a role chain 0 = S1    Sk exists such that
0  L(wfa((t), (v0 ))). By property (i), we have (t)( (t))  IK ; moreover, by Definition 20, basic concepts (t) = A0 , A1 , . . . , Ak = {v0 } exist with K |= Aj1 v Sj .Aj
for each j  [1..k]. Rules (cr2) and (cr3) are not applicable to IK , so we have
0 ( (t),  (v0 ))  IK .
 v0 6 I, which implies v0 = t. By step 16 of Algorithm 1, a role chain 0 = T1    Tk
exists such that 0  L(sfa((v0 ))). By property (i), we have (v0 )( (v0 ))  IK ;
moreover, by Definition 20, K |= (v0 ) v Tj .Self or K |=  v Tj for each j  [1..k].
Rules (cr6) and (cr7), respectively, are not applicable to IK , thus 0 ( (t),  (v0 ))  IK .
In either case, by steps 14 and 16 we have 0  L(pda(iS , , s0 , 0 )). Now let 0 = 0    n ;
note that we can have n = 0, in which case 0 = 0 . Clearly, we have 0 ( (t),  (vn ))  IK ,
where vn = u. Moreover, 0  L(pda(iS , , sn , n )) with sn = fS and n = . Finally,
rule (cr7) is not applicable to IK , so S( (t),  (u))  IK , as required.
4.4.4 Completeness
We next prove that our encoding is also complete, thus proving Theorem 21.
Lemma 29. If K |= q, then a nondeterministic computation exists such that entails(K, q)
returns true.
Proof. Assume that K |= q. If K is inconsistent, then entails(K, q) returns true, as required;
hence, in the rest of this proof, we assume that K is consistent. But then, IK |= q, so a
substitution  exists such that (q)  IK . Let  be as defined in Section 4.4.2.
For the substitution  in step 2, let (y) := (y) if (y)  I; otherwise, let (y) be an
arbitrary, but fixed, variable y 0 from q such that (y) = (y 0 ). It is straightforward to see
that ((q))  IK .

690

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

For the skeleton S = hV, E, i in step 3, set V contains IK and the variables occurring
in (q), and (y) = ((v)) for each variable y  V . Furthermore, let  be the smallest
irreflexive and transitive relation on the universe of K such that w  fS,A (w) for each term
w in the universe of K; then, let hv, v 0 i  E if and only if (v)  (v 0 ) and no v 00  V exists
such that (v)  (v 00 )  (v 0 ). By the definition of , graph hV, Ei is a forest rooted in
IK , as required by Definition 18.
In step 4, for an arbitrary atom A(t) in (q), we have A((t))  IK ; by property (1) of
Proposition 27, we have K |= ((t)) v A; hence, the condition is not satisfied.
Now consider an arbitrary edge hv, v 0 i  E; and let w0 , . . . , wk be terms, let A1 , . . . , Ak
be atomic concepts, and let S1 , . . . , Sk be roles such that w0 = (v), wk = (v 0 ), and
wi = fSi ,Ai (wi1 ) for each i  [1..k]; finally, let A0 = (v). Note that all of these are
uniquely defined by the edge, and that, by the construction of IK , for each i  [1..k], we have
K |= Ai1 v Si .Ai and K 6|= Ai v {a} for each a  IK . Then, a role chain  is compatible
with the edge hv, v 0 i if role chains 1 , . . . , k exists such that  = S1  1    Sk  k and, for
each i  [1..k] and each role T occurring in i , we have K |= Ai v T.Self or K |=  v T .
In the rest of this proof we will show the following property.
() For each PDA P  L(v, v 0 ), a role chain   L(P) exists that is compatible with the
edge hv, v 0 i.
By Lemma 24 and the above definition of compatibility, property () implies that the
condition in step 18 is not satisfied for edge hv, v 0 i.
For the loop in steps 616, let S(t, u) be an arbitrary binary atom in (q); we next
determine the required nondeterministic choices that preserve () in step 12, and that
satisfy conditions in steps 14 and 16, which completes the proof of this lemma. Let au  IK
be the unique individual connected to u in hV, Ei. Since S((t), (u))  IK , a nonempty
role chain  = 0  S1  1    m1  Sm  m with   L(S) and terms w0 , . . . , wm from the
universe of K with w0 = (t) and wm = (u) exist satisfying property (2) of Proposition 27.
To define vertex v0 in step 8, we consider two possibilities, and for each we also define an
index `0  [0..m] such that w`0 = (v0 ).
 If some j  [0..m] exists such that wj  IK , let v0 = au and let `0 be the largest index
such that w`0 = au .
 Otherwise, let v0 = t and let `0 = 0.
Let v0 , . . . , vn be the unique path connecting v0 to u in S. By the definition of `0 and the
form of the terms w`0 +1 , . . . , wm , we have wj 6 I for each j  [`0 + 1..m]; (v0 ) = w`0 ;
and (vn ) = wm . Thus, for each i  [1..n], a unique index `i exists such that (vi ) = w`i .
Now let 0 = 0    S`0  `0 , and let i = S`i1 +1  `i1 +1    S`i  `i for each i  [1..n];
clearly,  = 0    n . By properties (a)(c) of Proposition 27, for each i  [1..n], role chain
i is compatible with the edge hvi1 , vi i. Furthermore,   L(S) and Theorem 8 imply
  LdR (pda(iS , , fS , )), and so states s0 , . . . , sn with sn = fS and words 0 , . . . , n with
n =  exist such that 0  LdR (pda(iS , , s0 , 0 )) and i  LdR (pda(si1 , i1 , si , i ) for
each i  [1..n]. Since each i is compatible with hvi1 , vi i, step 12 preserves property (),
as required. Finally, we consider step 13.

691

fiStefanoni, Motik, Krotzsch, & Rudolph

 v0  I. By property (b) of Proposition 27, K |= (wj1 ) v Sj .(wj ) for each j  [1..`0 ].
Furthermore, by property c of Proposition 27, K |= (wj ) v T.Self or K |=  v T for
each j  [0..`0 ] and each role T occurring in j ; thus, K |= (wj ) v T.(wj ). But
then, 0  L(wfa((t), (v0 ))), so condition in step 14 is not satisfied.
 v0 6 I, so v0 = t and 0 = 0 . By property (c) of Proposition 27, K |= (wj ) v T.Self
or K |=  v T for each role T occurring in 0 . But then, 0  L(sfa((v0 ))), so
condition in step 16 is not satisfied.

5. The Lower Complexity Bound
In the previous section, we presented a BCQ answering algorithm for ELRO+ that uses
space polynomial in the total size of the input. This algorithm is worst-case optimal in
combined complexity since Krotzsch et al. (2007) reduced the PSpace-hard problem of
checking nonemptiness of the intersection of the languages generated by m deterministic
finite automata F1 . . . Fm over a common alphabet  (Kozen, 1977) to BCQ answering in
ELRO+ . In the knowledge base K encoding the problem, a regular RBox contains roles
S1 . . . Sm such that L(Si ) = L(Fi ) for each i  [1..m]; furthermore, a TBox ensures that
the universal interpretation IK is a rooted tree so, for each    , a term w exists that
is reachable from the root by a chain T
of roles corresponding to ; finally, a Boolean CQ
contains m atoms that check whether i L(Fi ) is nonempty. We next improve this lower
bound by showing that the problem is hard already in the restricted setting where the query,
the TBox, and the ABox are all fixed, and just the RBox varies.
Theorem 30. For K a regular ELRO+ knowledge base and q a Boolean conjunctive query,
checking K |= q is PSpace-hard even when
 the query is fixed and consist of two binary atoms over a single quantified variable,
 the TBox is fixed and contains only axioms of the form A v S.A, and
 the ABox is fixed and contains a single unary assertion.
Proof. We reduce the PSpace-hard problem of deciding whether the intersection of the
languages generated by m deterministic finite automata is nonempty (Kozen, 1977). Let
0 be deterministic finite automata over alphabet 0 , let  and  be fresh symbols
F10 , . . . , Fm
1
2
not occurring in 0 , and let  = 0  {1 , 2 }. For each j  [1..m], let Fj = hQj , , j , ij , fj i
be the deterministic finite automaton over alphabet  obtained by extending Fj0 with a
transition labelled by 1 from the final state fj0 of Fj0 to T
itself, and with a transition labelled
0
0
by T
2 from fj to a fresh final state fj of Fj . Then,
j ) 6=  if and only if a word
T j L(F
0
w  j L(Fj ) exist such that |w| is odd: given w  j L(Fj ), if |w| is odd, then |w  1  2 |
is odd and w  1  2  L(Fj ) for each j  [1..m], and if |w| is even, then |w  2 | is odd and
w  2  L(Fj ) for each j  [1..m]. Finally, we assume w.l.o.g. that Qi  Qj 6=  and Qi  R
hold for each 1  i < j  m, and that   R as well.
Let w = ST1    Sn be a word in  such that n is odd, and let  =   Q1  . . .  Qm .
Clearly, w  j L(Fj ) holds if and only if a word w   of the form
n
n
w = e01    e0m  S1  o1m    o11  S2  e21    e2m       e1n1    en1
m  Sn  om    o1

692

(46)

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

exists such that the following conditions hold for each j  [1..m]:
i
(i) for each i  [1..n] with i odd, we have oij  Qj and j (ei1
j , Si ) = oj ;
i
(ii) for each i  [1..n] with i even, we have eij  Qj and j (oi1
j , Si ) = ej ; and

(iii) e0j = ij and onj = fj .
Now let LO , LE , L1 , and L2 be the following languages.
LO :={e1    em  S  om    o1 | S   and j (ej , S) = oj , for each j  [1..m]}

(47)

LE :={om    o1  S  e1    em | S   and j (oj , S) = ej , for each j  [1..m]}

(48)



L1 :=(LO  )  LO

(49)


L2 :={i1    im }  (  LE )    {fm    f1 }

(50)

Consider an arbitrary word w   and the corresponding word w   . By the definition
of L1 , we have that w  L1 if w is of the form (46) and it satisfies property (i). Similarly,
by the definition of L2 , we have that w  L2 if w is of theT form (46) and it satisfies
properties (ii) and (iii). Thus, w  L1  L2 if and only if w  j L(Fj ). For simplicity, in
the rest of this proof, we will use the following equivalent formulations of L1 and L2 .
L1 =LO  (LO  )+  LO

(51)
+

L2 ={i1    im }    {fm    f1 }  {i1    im }  (  LE )    {fm    f1 }

(52)

TWe next define a knowledge base K and a fixed query q such that K |= q if and only
if j L(Fj ) 6= . We will present our construction in stages, and for each we will describe
how it affects the canonical model I = hI , I i of Kthat is, the model constructed using
the standard notion of chase (i.e., as in Definition 25, but with all semantic conditions on
K replaced by the syntactic checks for axioms in K). For simplicity, we first present K in
which the TBox depends on , and later we modify the encoding to use a fixed TBox.
The TBox T contains axioms (53), and the ABox A contains only axiom (54). We
assume that aI = a ; then, for each word    , a domain element a exists that is
connected to a via a chain of roles corresponding to .
A v.A

for each symbol   

(53)

A(a )

(54)

We next present an RBox R consisting of four parts, each encoding languages LO , LE ,
S,m+1
S,m
L1 , and L2 . Our encoding uses fresh roles LS,1
and LS,0
uniquely
O , . . . , LO
E , . . . , LE
0
associated with each role S  , as well as fresh roles LO , LE , L , L1 , L1 , L2 , and L02 .
The first part of R contains axioms (55)(57). It should be clear that, for all words
1 , 2   where 1 is a prefix of 2 , we have ha1 , a2 i  LIO if and only if 2  1  LO .
S v LS,m+1
O
ej 

LS,j+1
O

 oj v

LS,j
O

S  

(55)

j  [1..m] S   ej , oj  Qj with j (ej , S) = oj

(56)

LS,1
O v LO

(57)
693

fiStefanoni, Motik, Krotzsch, & Rudolph

The second part of R contains axioms (58)(60). It should be clear that, for all words
1 , 2   where 1 is a prefix of 2 , we have ha1 , a2 i  LIE if and only if 2  1  LE .

oj 

S,j1
LE

S v LS,0
E

S  

(58)

LS,j
E

j  [1..m] S   ej , oj  Qj with j (oj , S) = ej

(59)

 ej v

LS,m
v LE
E

(60)

The third part of R contains axioms (61)(65). It should be clear that, for all words
1 , 2   where 1 is a prefix of 2 , we have ha1 , a2 i  LI1 if and only if 2  1  L1 .
S v L

S  

(61)

LO v L1

(62)

L01
L01

(63)

v L1

(65)

LO  L v
L01  L01
L01  LO

v

(64)

The fourth part of R contains axioms (66)(69). It should be clear that, for all words
1 , 2   where 1 is a prefix of 2 , we have ha1 , a2 i  LI2 if and only if 2  1  L2 .
i1    im  L  fm    f1 v L2

(66)

L02
L02

(67)
(68)

 L  fm    f1 v L2

(69)

L  LE v
L02
i1    im 

L02



L02

v

Query q is given in (70). Then, K |= q if and only if a word    exists such that
ha , a i  LI1 and ha , a i  LI2 , and the latter is clearly the case if and only if   L1  L2 .
RBox R is regular and of size polynomial in the size of automata F1 , . . . , Fm .
q = y. L1 (a , y)  L2 (a , y)

(70)

We next tighten this reduction to use the fixed TBox T 0 consisting of axioms (71)(72),
where P0 and P1 are fresh roles.
A v P0 .A

(71)

A v P1 .A

(72)

Now let k = dlog2 ||e, and assume that each symbol    corresponds to a k-digit binary
number b1    bk with bi  {0, 1}. Then, let R0 be R extended with axioms (73).
Pb 1    Pb k v 

for each    corresponding to b1    bk

(73)

Finally, let K0 = hT 0 , R0 , Ai, and let I 0 be the canonical model of K0 . Axioms (54), (71),
and (72) ensure existence of a binary tree whose edges are labelled with roles P0 and P1 .
Furthermore, axioms (73) ensure that, for each    and each sequence of k edges in this
tree corresponding to the binary number assigned to , there is a shortcut in the tree
694

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

labelled with . Thus, I can be homomorphically embedded into I 0 . Finally, roles P0 and
P1 do not occur in R and query q checks for existence of a domain element connected to a ;
therefore, the extra edges in I 0 are irrelevant. Consequently, the encoding of languages L1
and L2 works in the same way as with the varying TBox T .
Finally, we characterise the complexity of BCQ answering over ELRO+ knowledge bases.
Theorem 31. For K a regular ELRO+ KB and q a Boolean CQ, checking K |= q is
1. PTime-complete in data complexity,
2. NP-complete, if the RBox R is fixed, and
3. PSpace-complete in combined complexity.
Proof. Calvanese et al. (2006) proved that BCQ answering is PTime-hard in data complexity already for EL knowledge bases. Furthermore, when the query is not fixed, BCQ
answering is NP-hard already over relational databases (Chandra & Merlin, 1977). Then
the theorem follows by Theorems 23 and 30, and by Savitchs theorem.

6. Navigational Queries
The data in DL knowledge bases has graph-like structure, where unary assertions encode
properties of graph nodes and binary assertions encode graph edges. Conjunctive queries
cannot express recursive properties such as reachability, and so their expressivity is often insufficient in applications that require graph navigation. As the popularity of graph
databases is on the rise, a number of navigational languages for querying graph-like data
have been proposed; for example, regular path queries (Barcelo, 2013) use regular expressions to express complex navigational patterns between graph vertices, and graph XPath
queries (Libkin et al., 2013) extend regular path queries with the converse operator, negation on regular expressions, and checking properties of vertices using Boolean combinations
of concepts and existential quantifications over paths. In the DL context, the computational complexity of navigational queries has been studied for several expressive DLs and
members of the DL-Lite family and the EL(H) fragment of ELRO+ (Calvanese, Eiter, &
Ortiz, 2009; Bienvenu et al., 2013; Kostylev et al., 2014; Bienvenu et al., 2014). In order to
complete the complexity landscape of this problem, in this section we study the problem of
answering graph XPath queries over ELRO+ knowledge bases.
6.1 Graph XPath Queries
Graph XPath queries consist of node expressions and path expressions, whose syntaxes are
defined respectively by the following two context-free grammars for B a basic concept and
S a role.
  B |  | 1  2 | 1  2 | hi
  S | S  | 1  2 | 1 + 2 |  |  | test()
Following Libkin et al. (2013), we consider the following expression fragments.
695

fiStefanoni, Motik, Krotzsch, & Rudolph

P,E
4

P

g

P

P,F
3

S,D
5

R,S

a

R

b

U
P

S,D
6

S

S,A
7

S

U

P,A
2

S

f

P

R,S

c
B

R

d

R,S

e

S

P,E
1

Figure 8: Interpretation I
1. The path-positive fragment disallows path expressions of the form .
2. The positive fragment disallows path expressions of the form  and node expressions
of the form .
3. The converse-free fragment disallows path expressions of the form S  .
A graph XPath atom has the form (s) or (s, t), for  a node expression,  a path
expression, and s and t terms. A conjunctive graph XPath query (CGXQ) g is an expression
g = ~y . (~x, ~y ) where  is a conjunction of graph atoms over variables ~x  ~y ; variables ~x
are called the answer variables of g. If ~x = , then g = ~y . (~y ) is a Boolean CGXQ.
Path-positive, positive, and converse-free CGXQs are obtained by restricting query atoms
accordingly. Finally, a graph XPath query (GXQ) is a CGXQ containing a single atom.
To define the semantics of CGXQs, let I = hI , I i be a first-order interpretation. The
interpretation of node and path expressions in I is inductively defined as follows.
()I
(1  2 )I
(1  2 )I
(hi)I

=
=
=
=

I \ ()I
(1 )I  (2 )I
(1 )I  (2 )I
{x  I | y  I : hx, yi  I }

(S  )I
(1  2 )I
(1 + 2 )I
( )I
()I
(test())I

=
=
=
=
=
=

{hy, xi | hx, yi  S I }
(1 )I  (2 )I
(1 )I  (2 )I
(I )
I  I \ ()I
{hx, xi | x  I }

Please observe that the difference of path expressions 1 and 2 corresponds to (1 + 2 ),
whereas the intersection of 1 and 2 corresponds to (1 + 2 ); moreover, Libkin et al.
(2013) define a path expression , which in our setting corresponds to test(>c ). Satisfaction
of a Boolean CGXQ g in I and CGXQ entailment are defined in the obvious way; moreover,
Boolean CGXQ answering is the problem of checking K |= g.
Example 32. We illustrate these definitions using interpretation I shown in Figure 8;
notation is as in Example 15. Moreover, let 1 , 2 , and 3 be the following path expressions.
1 =(R  test(hS   test(A  B)i))

(74)

2 =(U  test(hP  test(A  B)i))

(75)

696

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

Node expressions
TB = {B v CB }
T1 2 = {C1 u C1 v C1 2 }  T1  T2
T1 2 = {C1 v C1 2 , C2 v C1 2 }  T1  T2
Thi = {T .>c v Chi }  T
Path expressions
TS = 
T1 2 = T1  T2
T1 +2 = T1  T2
T = T
Ttest() = {C v Ttest() .Self}  T

RB = 
R1 2 = R1  R2
R1 2 = R1  R2
Rhi = R

RS = {S v TS }
R1 2 = {T1  T2 v T1 2 }  R1  R2
R1 +2 = {T1 v T1 +2 , T2 v T1 +2 }  R1  R2
R = { v T , T v T , T  T v T }  R
Rtest() = R

Table 6: Encoding positive, converse-free node and path expressions using axioms
3 =((R  S) )

(76)

Expression 1 is positive, and it retrieves all pairs of individuals that are connected by a
path of R-edges such that, for each element occurring in the path other than the first, there
exists an outgoing path of S-edges reaching a member of concept A t B. For example, we
have {haI , dI i, haI , eI i}  (1 )I .
In contrast, expression 2 is path-positive, and it retrieves all pairs of individuals that
are connected by a U -edge such that no P -successor exists that is a member of concept AtB.
For example, we have haI , g I i  (2 )I , but haI , f I i 6 (2 )I .
Finally, expression 3 is neither positive nor path-positive, and it retrieves all pairs of
individuals that are connected by a path not consisting of a sequence of edges described by
the regular expression (R  S) . For example, we have haI , dI i  (3 )I , but haI , eI i 6 (3 )I .
Let g = x, y, z.1 (x, y)  2 (x, z)  3 (x, y) be a conjunctive graph XPath query, and let
 = {x 7 a, y 7 d, z 7 g} be a substitution. Using Figure 8, one can check that I |= (g).
As observed by Kostylev et al. (2014), node expressions in graph XPath queries correspond precisely to formulas in propositional dynamic logic with negation (PDL ) (Harel
et al., 2000); the satisfiability problem for PDL is undecidable (Harel, 1984), so answering
GXQs under DL constraints is undecidable. Decidability results have been recently obtained for path-positive and positive queries over DL-Lite knowledge bases (Kostylev et al.,
2014). In addition, Kostylev et al. (2014) proved that, for all DLs, answering path-positive,
converse-free GXQs is coNP-hard in data-complexity. Finally, Bienvenu et al. (2014) proved
that answering positive GXQs over EL knowledge bases is ExpTime-complete. Thus, in
the rest of this section we focus on positive, converse-free graph XPath queries.
6.2 Complexity of Answering Positive, Converse-Free Graph XPath Queries
In the rest of this section, we fix an ELRO+ KB K = hT , R, Ai such that R is regular.
We next show that, given a positive, converse-free Boolean CGXQ g, one can construct in
polynomial time a regular ELRO+ KB K0 and a Boolean CQ q 0 such that K |= g if and
only if K0 |= q 0 . Our construction of K0 combines various expressive features of ELRO+ :
697

fiStefanoni, Motik, Krotzsch, & Rudolph

role inclusions and reflexive roles encode the path expressions of g in the RBox, and selfrestrictions encode the node expressions of g in the TBox.
Proposition 33. Given a positive, converse-free Boolean CGXQ g over K, one can compute
in time polynomial in |K| + |g| an ELRO+ KB K0 and a Boolean CQ q 0 such that the RBox
of K0 is regular, g and q 0 have equally many atoms, and K |= g if and only if K0 |= q 0 .
Proof. Let g = ~y . (~y ) be a positive, converse-free Boolean CGXQ over K. For each
positive node expression , let C be a fresh atomic concept uniquely associated with 
and, for each positive, converse-free path expression , let T be a fresh role uniquely
associated with . By structural induction, we associate with each  (resp. ) a TBox
T and an RBox R (resp. a TBox T and an RBox R ) as shown in Table 6. Then, let
K0 = hT  T 0 , R  R0 , Ai where TBox T 0 and RBox R0 are as follows.
[
[
[
[
T0=
T 
T
R0 =
R 
R
(s)

(s,t)

(s)

(s,t)

Now let q 0 = ~y .  0 (~y ) be the Boolean CQ where  0 contains C (s) for each atom (s)  
and T (s, t) for each atom (s, t)  . Clearly, g and q 0 have the same number of atoms;
moreover, since query g is over K, query q 0 is over K0 . Finally, both q 0 and K0 can be
computed in polynomial time in the input size, and the RBox of K0 is clearly regular. We
next show that K0 6|= q 0 if and only if K 6|= g.
() Assume that K0 6|= q 0 , so an interpretation I exists such that I |= K0 and I 6|= q 0 .
Since each axiom of K is also an axiom of K0 , we have that I |= K. Furthermore, for
each positive node expression  and positive path expression , we have I  (C )I and
I  (T )I . We prove this claim by simultaneous induction on the structure of node and
path expressions.
Base case. For the base case, let  be an arbitrary node expression of the form  = B and
let  be an arbitrary path expression of the form  = S. Since B v CB  T 0 , S v TS  R0 ,
and I is a model of K0 , the claim easily follows.
Inductive step. For the inductive step, we distinguish two cases.
First, consider an arbitrary node expression  such that the property holds for all node
and path expressions occurring in . Then let x be an arbitrary element of I and assume
that x  I ; we show that x  CI by considering the various forms that  can take.
  = 1  2 . Since x  I , we have x  I1 and x  I2 . By the inductive hypothesis,
we have x  CI1 and x  CI2 . By the definition of T 0 , we have C1 u C2 v C  T 0 .
Since I is a model of T 0 , we have x  CI , as required.
  = 1  2 . The proof for this case is similar to the one above.
  = hi. Since x  I , there exists y  I such that hx, yi  I . By the inductive
hypothesis, we have hx, yi  TI . By the definition of T 0 , we have T .>c v C  T 0 .
Since I is a model of T 0 , we have x  CI , as required.
Second, consider an arbitrary path expression  such that the property holds for all
node and path expressions occurring in . Then let x and y be arbitrary elements of I
and assume that hx, yi  I ; we show that hx, yi  TI by considering the various forms
that  can take.
698

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

  = 1  2 . Since hx, yi  I , there exists z  I such that hx, zi  1I and
hz, yi  2I . By the inductive hypothesis, we have hx, zi  TI1 and hz, yi  TI2 .
Moreover, by the definition of R0 , we have T1  T2 v T  R0 . Since I is a model of
R0 , we have hx, yi  TI , as required.
  = 1 + 2 . Since hx, yi  I , we have that hx, yi  1I or hx, yi  2I . By the
inductive hypothesis, we have hx, yi  TI1 or hx, yi  TI2 . By the definition of R0 , we
have {T1 v T , T2 v T }  R0 . Since I is a model of R0 , we have hx, yi  TI .
  = 1 . First, consider the case in which x = y. By the definition of R0 , we have
 v T  R0 . Since I is a model of R0 , we have hx, yi  TI , as required. Otherwise,
consider the case in which x 6= y. Since hx, yi  I , elements x0 , . . . , xn with x0 = x
and xn = y exist in I such that n > 0 and hxi1 , xi i  1I for each i  [1..n]. By the
inductive hypothesis, for each i  [1..n], we have hxi1 , xi i  TI1 . By the definition
of R0 , we have T1  T1 v T  R0 . Since I is a model of R0 , we have hx, yi  T .
  = test(). It follows that x = y and that x  I . By the inductive hypothesis, we
have x  CI . By the definition of T 0 , we have C v T .Self  T 0 . Since I is a model
of T 0 , we have hx, yi  TI , as required.
But then, since node and path expressions in g are positive, I 6|= q 0 implies I 6|= g.
I0

() Assume that K 6|= g, so an interpretation I exists such that I |= K and I 6|= g. Let
be the interpretation obtained by extending I to the fresh concepts and roles as follows.
0

(C )I = I

0

0

(T )I = I

0

By the definition of K0 , it is straightforward to see that I 0 |= K0 ; furthermore, by the
definition of q 0 , it is straightforward to see that I 0 6|= q 0 , as required.
Next, we establish the complexity of answering positive, converse-free (C)GXQs over
ELRO+ knowledge bases.
Theorem 34. For K a regular ELRO+ KB and g a positive, converse-free Boolean CGXQ,
checking K |= g is PTime-complete in data complexity, and PSpace-complete in combined
complexity. For g a positive, converse-free Boolean GXQ, checking K |= g is PTimecomplete in combined and data complexities.
Proof. The hardness in data complexity of Boolean positive, converse-free (C)GXQs follows
from the PTime-hardness of instance checking in EL (Calvanese et al., 2006).
For positive, converse-free GXQs, hardness in combined complexity is inherited from the
PTime-hardness of TBox reasoning in EL (Baader et al., 2005). For the matching upper
bounds, Proposition 33 allows us to reduce Boolean GXQ answering to checking entailments
of the form K0 |= q 0 where q 0 is a BCQ containing only one atom. We next show that, for
each possible form of q 0 , we can reduce the latter problem to checking entailment of ELRO+
concept inclusions, which can be decided in PTime. In the following, c is an arbitrarily
chosen individual from IK0 .
 K0 |= A(a) if and only if K0 |= {a} v A.
699

fiStefanoni, Motik, Krotzsch, & Rudolph

 K0 |= y.A(y) if and only if K0 |= {c} v >r .A.
 K0 |= S(a, b) if and only if K0 |= {a} v S.{b}.
 K0 |= y.S(y, b) if and only if K0 |= {c} v >r .S.{b}.
 K0 |= y.S(a, y) if and only if K0 |= {a} v S.>c .
 K0 |= y1 , y2 .S(y1 , y2 ) if and only if K0 |= {c} v >r .S.>c .
For positive, converse-free CGXQs, hardness in combined complexity is given by Theorem 31, and the matching upper bounds follow from Theorem 23 and Proposition 33.

7. Conclusions
In this paper, we presented the first CQ answering algorithm for OWL 2 EL that runs
in PSpace, thus closing a longstanding open question. Our algorithm is based on an
innovative, succinct encoding of regular role inclusions using bounded-stack PDAthat is,
finite automata extended with a stack of fixed size. We believe this encoding is interesting
in its own right, as it can be used to optimise popular OWL 2 DL reasoners. Moreover, we
refined the previously known PSpace lower bound for CQ answering by showing that the
problem remains PSpace-hard even if the query, the TBox, and the ABox are all fixed (and
only the RBox varies); thus, we identify role inclusions as the only culprit for the problems
PSpace-hardness. Finally, we showed that positive, converse-free GXQs and CGXQs can
be answered over OWL 2 EL knowledge bases in PTime and PSpace, respectively; this is
interesting because Bienvenu et al. (2014) have showed that adding the converse operator
makes the problem ExpTime-hard. Thus, at least from a theoretical perspective, positive,
converse-free (C)GXQs seem to provide an adequate language for querying OWL 2 EL
knowledge bases.
We see two main open problems for our future work. First, by drawing inspiration
from the succinct encoding of role inclusions, we shall extend the combined approach by
Stefanoni et al. (2013) to OWL 2 EL and thus obtain a practical algorithm. Second, as static
query analysis is a fundamental task in query optimisation, we shall study the containment
problem for graph queries under ELRO+ constraints.

Acknowledgements
The results in this article are an extension of the results that were published in preliminary form by Krotzsch et al. (2007) in the Proceedings of the 6th International Semantic
Web Conference (ISWC 2007). This work was supported by Alcatel-Lucent; the EU FP7
project OPTIQUE; the EPSRC projects MASI3 , Score!, and DBOnto; and the DFG project
DIAMOND (Emmy Noether grant KR 4381/1-1).

References
Anselmo, M., Giammarresi, D., & Varricchio, S. (2003). Finite automata and non-selfembedding grammars. In Proceedings of the 7th International Conference on Im-

700

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

plementation and Application of Automata, CIAA02, pp. 4756, Berlin, Heidelberg.
Springer-Verlag.
Artale, A., Calvanese, D., Kontchakov, R., & Zakharyaschev, M. (2009). The DL-Lite family
and relations. J. Artif. Intell. Res. (JAIR), 36, 169.
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing the EL envelope. In Kaelbling, L. P.,
& Saffiotti, A. (Eds.), Proceedings of the 19th International Joint Conference on Artificial Intelligence (IJCAI 2005), pp. 364369, Edinburgh, UK. Morgan Kaufmann
Publishers.
Baader, F., Brandt, S., & Lutz, C. (2008). Pushing the EL envelope further. In Clark, K.,
& Patel-Schneider, P. F. (Eds.), In Proceedings of the OWLED 2008 DC Workshop
on OWL: Experiences and Directions.
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2010). The Description Logic Handbook: Theory, Implementation, and Applications.
Cambridge University Press. Paperback edition.
Baget, J.-F., Leclere, M., Mugnier, M.-L., & Salvat, E. (2011). On rules with existential
variables: Walking the decidability line. Artif. Intell., 175 (9-10), 16201654.
Barcelo, P. (2013). Querying graph databases. In Hull, R., & Fan, W. (Eds.), PODS, pp.
175188. ACM.
Barrett, C., Jacob, R., & Marathe, M. (2000). Formal-language-constrained path problems.
SIAM J. Comput., 30 (3), 809837.
Bienvenu, M., Calvanese, D., Ortiz, M., & Simkus, M. (2014). Nested regular path queries
in Description Logics. In Proc. of the 14th Int. Conf. on the Principles of Knowledge
Representation and Reasoning (KR 2014). AAAI Press.
Bienvenu, M., Ortiz, M., & Simkus, M. (2013). Conjunctive regular path queries in
lightweight Description Logics. In Rossi, F. (Ed.), IJCAI. IJCAI/AAAI.
Cal, A., Gottlob, G., & Kifer, M. (2013). Taming the infinite chase: Query answering under
expressive relational constraints. J. Artif. Intell. Res. (JAIR), 48, 115174.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., Poggi, A., Rodriguez-Muro, M.,
Rosati, R., Ruzzi, M., & Savo, D. F. (2011). The MASTRO system for Ontology-Based
Data Access. Semantic Web, 2 (1), 4353.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2006). Data
complexity of query answering in Description Logics. In Proc. of the 10th Int. Conf.
on the Principles of Knowledge Representation and Reasoning (KR 2006), pp. 260
270.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning and efficient query answering in Description Logics: The DL-Lite family. J.
Autom. Reasoning, 39 (3), 385429.
Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini, M., & Rosati, R. (2013). Data
complexity of query answering in Description Logics. Artificial Intelligence, 195, 335
360.

701

fiStefanoni, Motik, Krotzsch, & Rudolph

Calvanese, D., De Giacomo, G., Lenzerini, M., & Vardi, M. Y. (2000). Containment of
conjunctive regular path queries with inverse. In Proc. of the 7th Int. Conf. on the
Principles of Knowledge Representation and Reasoning (KR 2000), pp. 176185.
Calvanese, D., Eiter, T., & Ortiz, M. (2009). Regular path queries in expressive Description
Logics with nominals. In Boutilier, C. (Ed.), IJCAI 2009, Proceedings of the 21st
International Joint Conference on Artificial Intelligence, Pasadena, California, USA,
July 11-17, 2009, pp. 714720.
Calvanese, D., Vardi, M. Y., De Giacomo, G., & Lenzerini, M. (2000). View-based query
processing for regular path queries with inverse. In Proceedings of the Nineteenth ACM
SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems, PODS
00, pp. 5866, New York, NY, USA. ACM.
Chandra, A. K., & Merlin, P. M. (1977). Optimal implementation of conjunctive queries in
relational data bases. In Hopcroft, J. E., Friedman, E. P., & Harrison, M. A. (Eds.),
Proc. of the 9th annual ACM Symposium on Theory of Computing (STOC 77), pp.
7790, Boulder, CO, USA. ACM Press.
Cruz, I. F., Mendelzon, A. O., & Wood, P. T. (1987). A graphical query language supporting
recursion. SIGMOD Rec., 16 (3), 323330.
Cuenca Grau, B., Horrocks, I., Motik, B., Parsia, B., Patel-Schneider, P. F., & Sattler, U.
(2008). OWL 2: The next step for OWL. J. Web Sem., 6 (4), 309322.
De Giacomo, G., Lembo, D., Lenzerini, M., Poggi, A., Rosati, R., Ruzzi, M., & Savo, D. F.
(2012). MASTRO: A reasoner for effective Ontology-Based Data Access. In Horrocks,
I., Yatskevich, M., & Jimenez-Ruiz, E. (Eds.), ORE, Vol. 858 of CEUR Workshop
Proceedings. CEUR-WS.org.
Eiter, T., Ortiz, M., & Simkus, M. (2012a). Conjunctive query answering in the Description
Logic SH using knots. J. Comput. Syst. Sci., 78 (1), 4785.
Eiter, T., Ortiz, M., Simkus, M., Tran, T.-K., & Xiao, G. (2012b). Query rewriting for
Horn-SHIQ plus rules. In Hoffmann, J., & Selman, B. (Eds.), AAAI. AAAI Press.
Fan, W. (2012). Graph pattern matching revised for social network analysis. In Deutsch,
A. (Ed.), ICDT, pp. 821. ACM.
Geffert, V., Mereghetti, C., & Palano, B. (2010). More concise representation of regular
languages by automata and regular expressions. Information and computation, 208 (4),
385394.
Giese, M., Calvanese, D., Haase, P., Horrocks, I., Ioannidis, Y., Kllapi, H., Koubarakis, M.,
Lenzerini, M., Moller, R., Rodriguez-Muro, M., Ozcep, O., Rosati, R., Schlatte, R.,
Schmidt, M., Soylu, A., & Waaler, A. (2013). Scalable end-user access to big data. In
Akerkar, R. (Ed.), Big Data Computing. CRC Press.
Glimm, B., Lutz, C., Horrocks, I., & Sattler, U. (2008). Conjunctive query answering for
the Description Logic SHIQ. J. Artif. Intell. Res. (JAIR), 31, 157204.
Gottlob, G., Manna, M., & Pieris, A. (2014). Polynomial combined rewritings for existential
rules. In Proc. of the 14th Int. Conf. on the Principles of Knowledge Representation
and Reasoning (KR 2014). AAAI Press.
702

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

Gottlob, G., & Schwentick, T. (2012). Rewriting ontological queries into small nonrecursive
datalog programs. In Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Principles of
Knowledge Representation and Reasoning: Proceedings of the Thirteenth International
Conference, KR 2012, Rome, Italy, June 10-14, 2012. AAAI Press.
Grosof, B. N., Horrocks, I., Volz, R., & Decker, S. (2003). Description Logic Programs: Combining logic programs with Description Logic. In Proceedings of the 12th international
conference on World Wide Web, pp. 4857.
Gutierrez, C., Hurtado, C. A., Mendelzon, A. O., & Perez, J. (2011). Foundations of
semantic web databases. J. Comput. Syst. Sci., 77 (3), 520541.
Harel, D. (1984). Dynamic logic. In Gabbay, D., & Guenthner, F. (Eds.), Handbook of
Philosophical Logic Vol. II, pp. 497604. Reidel Publishing Company.
Harel, D., Tiuryn, J., & Kozen, D. (2000). Dynamic Logic. MIT Press, Cambridge, MA,
USA.
Hopcroft, J. E., Motwani, R., & Ullman, J. D. (2003). Introduction to Automata Theory,
Languages, and Computation - international edition (2. ed). Addison-Wesley.
Horrocks, I., Kutz, O., & Sattler, U. (2006). The even more irresistible SROIQ. In Doherty,
P., Mylopoulos, J., & Welty, C. A. (Eds.), KR, pp. 5767. AAAI Press.
Horrocks, I., & Sattler, U. (2004). Decidability of SHIQ with complex role inclusion axioms.
Artificial Intelligence, 160 (12), 79104.
Johnson, D. S., & Klug, A. C. (1984). Testing containment of conjunctive queries under
functional and inclusion dependencies. J. Comput. Syst. Sci., 28 (1), 167189.
Kazakov, Y. (2008). RIQ and SROIQ are harder than SHOIQ. In Brewka, G., & Lang,
J. (Eds.), KR, pp. 274284. AAAI Press.
Kontchakov, R., Lutz, C., Toman, D., Wolter, F., & Zakharyaschev, M. (2011). The combined approach to Ontology-Based Data Access. In Walsh, T. (Ed.), IJCAI 2011,
Proceedings of the 22nd International Joint Conference on Artificial Intelligence,
Barcelona, Catalonia, Spain, July 16-22, 2011, pp. 26562661. IJCAI/AAAI.
Kostylev, E. V., Reutter, J. L., & Vrgoc, D. (2014). XPath for DL-Lite ontologies. In
Bienvenu, M., Ortiz, M., Rosati, R., & Simkus, M. (Eds.), Informal Proceedings of
the 27th International Workshop on Description Logics, Vienna, Austria, July 17-20,
2014., Vol. 1193 of CEUR Workshop Proceedings, pp. 258269. CEUR-WS.org.
Kozen, D. (1977). Lower bounds for natural proof systems. In FOCS, pp. 254266. IEEE
Computer Society.
Krotzsch, M. (2011). Efficient rule-based inferencing for OWL EL. In Walsh, T. (Ed.),
Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI11). AAAI Press/IJCAI. 26682673.
Krotzsch, M., Rudolph, S., & Hitzler, P. (2007). Conjunctive queries for a tractable fragment
of OWL 1.1. In Aberer, K., Choi, K.-S., Noy, N., Allemang, D., Lee, K.-I., Nixon, L.,
Golbeck, J., Mika, P., Maynard, D., Mizoguchi, R., Schreiber, G., & Cudre-Mauroux,
P. (Eds.), Proceedings of the 6th International Semantic Web Conference (ISWC07),
Vol. 4825 of LNCS, pp. 310323. Springer.
703

fiStefanoni, Motik, Krotzsch, & Rudolph

Libkin, L., Martens, W., & Vrgoc, D. (2013). Querying graph databases with XPath. In
Tan, W.-C., Guerrini, G., Catania, B., & Gounaris, A. (Eds.), ICDT, pp. 129140.
ACM.
Lutz, C. (2008). The complexity of conjunctive query answering in expressive Description
Logics. In Automated Reasoning.
Lutz, C., Seylan, I., Toman, D., & Wolter, F. (2013). The combined approach to OBDA:
Taming role hierarchies using filters. In Alani, H., Kagal, L., Fokoue, A., Groth, P. T.,
Biemann, C., Parreira, J. X., Aroyo, L., Noy, N. F., Welty, C., & Janowicz, K. (Eds.),
International Semantic Web Conference (1), Vol. 8218 of Lecture Notes in Computer
Science, pp. 314330. Springer.
Lutz, C., Toman, D., & Wolter, F. (2009). Conjunctive query answering in the Description Logic EL using a relational database system. In Boutilier, C. (Ed.), IJCAI
2009, Proceedings of the 21st International Joint Conference on Artificial Intelligence,
Pasadena, California, USA, July 11-17, 2009, pp. 20702075.
Marnette, B. (2009). Generalized schema-mappings: From termination to tractability. In
Paredaens, J., & Su, J. (Eds.), PODS, pp. 1322. ACM.
Mora, J., Rosati, R., & Corcho, O. (2014). kyrie2: Query rewriting under extensional
constraints in ELHIO. In Mika, P., Tudorache, T., Bernstein, A., Welty, C., Knoblock,
C. A., Vrandecic, D., Groth, P. T., Noy, N. F., Janowicz, K., & Goble, C. A. (Eds.),
The Semantic Web - ISWC 2014 - 13th International Semantic Web Conference, Riva
del Garda, Italy, October 19-23, 2014. Proceedings, Part I, Vol. 8796 of Lecture Notes
in Computer Science, pp. 568583. Springer.
Ortiz, M., Calvanese, D., & Eiter, T. (2008). Data complexity of query answering in expressive Description Logics via tableaux. J. Autom. Reasoning, 41 (1), 6198.
Ortiz, M., Rudolph, S., & Simkus, M. (2011). Query answering in the Horn fragments of the
Description Logics SHOIQ and SROIQ. In Walsh, T. (Ed.), IJCAI 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, Barcelona,
Catalonia, Spain, July 16-22, 2011, pp. 10391044. IJCAI/AAAI.
Perez, J., Arenas, M., & Gutierrez, C. (2010). nSPARQL: A navigational language for RDF.
Web Semant., 8 (4), 255270.
Perez-Urbina, H., Motik, B., & Horrocks, I. (2010). Tractable query answering and rewriting
under Description Logic constraints. J. Applied Logic, 8 (2), 186209.
Rodriguez-Muro, M., & Calvanese, D. (2012). High performance query answering over
DL-Lite ontologies. In Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Principles of
Knowledge Representation and Reasoning: Proceedings of the Thirteenth International
Conference, KR 2012, Rome, Italy, June 10-14, 2012. AAAI Press.
Rosati, R. (2007). On conjunctive query answering in EL. In Calvanese, D., Franconi, E.,
Haarslev, V., Lembo, D., Motik, B., Turhan, A.-Y., & Tessaris, S. (Eds.), Description
Logics, Vol. 250 of CEUR Workshop Proceedings. CEUR-WS.org.
Rudolph, S., & Glimm, B. (2010). Nominals, inverses, counting, and conjunctive queries or:
Why infinity is your friend!. J. Artif. Intell. Res. (JAIR), 39, 429481.
704

fiThe Complexity of Answering CQs and GXQs over OWL 2 EL KBs

Simanck, F. (2012). Elimination of complex rias without automata. In Kazakov, Y.,
Lembo, D., & Wolter, F. (Eds.), Proceedings of the 2012 International Workshop
on Description Logics, DL-2012, Rome, Italy, June 7-10, 2012, Vol. 846 of CEUR
Workshop Proceedings. CEUR-WS.org.
Sirin, E., Parsia, B., Cuenca Grau, B., Kalyanpur, A., & Katz, Y. (2007). Pellet: A practical
OWL-DL reasoner. J. Web Sem., 5 (2), 5153.
Stefanoni, G., Motik, B., & Horrocks, I. (2013). Introducing nominals to the combined
query answering approaches for EL. In desJardins, M., & Littman, M. L. (Eds.),
AAAI. AAAI Press.
ter Horst, H. J. (2005). Completeness, decidability and complexity of entailment for RDF
Schema and a semantic extension involving the OWL vocabulary. Web Semantics:
Science, Services and Agents on the World Wide Web, 3 (2-3), 79115.
Tsarkov, D., & Horrocks, I. (2006). FaCT++ Description Logic reasoner: System description. In Furbach, U., & Shankar, N. (Eds.), IJCAR, Vol. 4130 of Lecture Notes in
Computer Science, pp. 292297. Springer.
Urbani, J., van Harmelen, F., Schlobach, S., & Bal, H. E. (2011). QueryPIE: Backward
reasoning for OWL Horst over very large knowledge bases. In Aroyo, L., Welty, C.,
Alani, H., Taylor, J., Bernstein, A., Kagal, L., Noy, N. F., & Blomqvist, E. (Eds.),
International Semantic Web Conference (1), Vol. 7031 of Lecture Notes in Computer
Science, pp. 730745. Springer.
Vardi, M. Y. (1982). The complexity of relational query languages (extended abstract). In
Proceedings of the fourteenth annual ACM symposium on Theory of computing, STOC
82, pp. 137146, New York, NY, USA. ACM.
Venetis, T., Stoilos, G., & Stamou, G. B. (2012). Incremental query rewriting for OWL 2 QL.
In Kazakov, Y., Lembo, D., & Wolter, F. (Eds.), Proceedings of the 2012 International
Workshop on Description Logics, DL-2012, Rome, Italy, June 7-10, 2012, Vol. 846 of
CEUR Workshop Proceedings. CEUR-WS.org.
Virgilio, R. D., Orsi, G., Tanca, L., & Torlone, R. (2012). NYAYA: A system supporting the
uniform management of large sets of semantic data. In Kementsietsidis, A., & Salles,
M. A. V. (Eds.), IEEE 28th International Conference on Data Engineering (ICDE
2012), Washington, DC, USA (Arlington, Virginia), 1-5 April, 2012, pp. 13091312.
IEEE Computer Society.
Wessel, M. (2001). Obstacles on the Way to Qualitative Spatial Reasoning with Description
Logics: Some Undecidability Results. In Working Notes of the 2001 International
Description Logics Workshop (DL-2001), Vol. 49. CEUR-WS.org.

705

fiJournal of Artificial Intelligence Research 51 (2014) 805-827

Submitted 5/14; published 12/14

A Hidden Markov Model-Based Acoustic Cicada Detector for
Crowdsourced Smartphone Biodiversity Monitoring
Davide Zilli
Oliver Parson
Geoff V Merrett
Alex Rogers

DZ 2 V 07@ ECS . SOTON . AC . UK
OSP @ ECS . SOTON . AC . UK
GVM @ ECS . SOTON . AC . UK
ACR @ ECS . SOTON . AC . UK

University of Southampton
Southampton, SO17 1BJ, UK

Abstract
In recent years, the field of computational sustainability has striven to apply artificial intelligence techniques to solve ecological and environmental problems. In ecology, a key issue for the
safeguarding of our planet is the monitoring of biodiversity. Automated acoustic recognition of
species aims to provide a cost-effective method for biodiversity monitoring. This is particularly
appealing for detecting endangered animals with a distinctive call, such as the New Forest cicada.
To this end, we pursue a crowdsourcing approach, whereby the millions of visitors to the New
Forest, where this insect was historically found, will help to monitor its presence by means of a
smartphone app that can detect its mating call. Existing research in the field of acoustic insect
detection has typically focused upon the classification of recordings collected from fixed field microphones. Such approaches segment a lengthy audio recording into individual segments of insect
activity, which are independently classified using cepstral coefficients extracted from the recording
as features. This paper reports on a contrasting approach, whereby we use crowdsourcing to collect
recordings via a smartphone app, and present an immediate feedback to the users as to whether an
insect has been found. Our classification approach does not remove silent parts of the recording
via segmentation, but instead uses the temporal patterns throughout each recording to classify the
insects present. We show that our approach can successfully discriminate between the call of the
New Forest cicada and similar insects found in the New Forest, and is robust to common types
of environment noise. A large scale trial deployment of our smartphone app collected over 6000
reports of insect activity from over 1000 users. Despite the cicada not having been rediscovered in
the New Forest, the effectiveness of this approach was confirmed for both the detection algorithm,
which successfully identified the same cicada through the app in countries where the same species
is still present, and of the crowdsourcing methodology, which collected a vast number of recordings
and involved thousands of contributors.

1. Introduction
The field of computational sustainability, which seeks to apply computer science and artificial intelligence to issues of sustainability, has received great attention in recent years as our planet is under
ever stronger environmental, societal and economical pressure (Quinn, Frias-Martinez, & Subramanian, 2014; Gomes, 2009). Work in this field has striven to bring artificial intelligence research
to the real world, implementing practices to promote the sustainability of our environment and to
safeguard its living organisms. Towards this goal, the first step is the monitoring of biodiversity,
that is the variety of living species in a given environment. Biodiversity is a key measure of the
health of an ecosystem, and as land-use and climate change impact on the natural environment,
c
2014
AI Access Foundation. All rights reserved.

fiZ ILLI , PARSON , M ERRETT & ROGERS

Figure 1: Cicadetta montana. Photograph by Jaroslav Maly, reproduced with permission.

many countries are increasingly seeing the need to monitor and protect it. For example, the UK has
formalised this endeavour within the UK Biodiversity Action Plan and has established a priority
species list to focus work on a small number of critically important species (Joint Nature Conservation Committee, 2010). One of these, of particular interest in this paper, is the New Forest cicada
(Cicadetta montana s. str., see Figure 1), the only native cicada known to the UK, which was first
identified in the New Forest, a national park on the south coast of England, in 1812. Despite being
well studied at a number of sites in the 1960s, there has been no confirmed observation of the New
Forest cicada in the last 20 years (Pinchen & Ward, 2002). Understanding whether this is simply
due to the migration of the cicada to as yet undiscovered sites, or whether the cicada is now extinct
in the UK due to climate change or land-use change, is an important question for UK biodiversity
research.
Today, traditional approaches for searching for rare species typically require trained ecologists
to perform detailed manual surveys. However, the obvious costs of such work have led to significant
recent research into automated approaches whereby animals and plants can be classified remotely
without requiring that trained experts be in the field. In the case of insects, this is most often
performed by deploying fixed sensors with sensitive microphones that record the sounds (or calls)
emitted by the insects (MacLeod, 2007). These recordings are then analysed later to automatically
identify the insects whose calls were captured. The algorithms for such classification typically range
from those that operate solely in the time domain, such as time domain signal coding (Chesmore,
2004; Chesmore & Ohya, 2004), to those inspired by the literature of human speech recognition
(for example Potamitis, Ganchev, & Fakotakis, 2006; Pinhas, Soroker, Hetzoni, Mizrach, Teicher, &
Goldberger, 2008). The latter typically use a Gaussian mixture model or a hidden Markov model for
classification (Leqing & Zhen, 2010), and perform a number of pre-processing stages, often taken
directly from the human speech recognition literature, to extract features from the raw recording.
For example, Chaves, Travieso, Camacho, and Alonso (2012) present a state-of-the-art approach
that pre-processes the recorded sound to remove un-sounded periods where no insect call is detected,
before mapping the raw frequencies to the mel scale, which better represents human hearing. The
approach then converts mel scale features back into a pseudo-time domain, called the cepstrum, by
calculating a number of mel frequency cepstral coefficients (MFCC), that are then used as features
806

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

for the hidden Markov model (HMM) classification. Such approaches have been shown to classify
insects to very high levels of accuracy from clean recordings collected using purpose-built hardware.
The use of such automatic acoustic recognition is particularly appealing in the case of the New
Forest cicada, since this insect has a particularly loud high-pitched mating song which, while being
close to the upper frequency limit of a normal adults hearing range and inaudible to most adults
over 40 years of age, can easily be detected by conventional microphones. However, the use of
fixed sensors to collect these recordings for later analysis is less compelling. The New Forest covers
600 km2 , and would require tens of thousands of sensors to exhaustively survey it for potential
cicada breeding sites. Furthermore, since the cicada only emits its mating call during the months of
June and July, any approach must be able to survey a large area over a short space of time, further
decreasing the applicability of fixed sensors.
To address this challenge, we pursue a different approach, which aims to exploit the 13 million day visits to the New Forest that occur each year by the general public to crowdsource the
search for the New Forest cicada using a smartphone app. The involvement of the general public
in the collection of observations about the natural environment is by no means a recent practice,
as records of farmers and clergymen devoted to this activity date back centuries (Miller-Rushing,
Primack, & Bonney, 2012; Brenna, 2011). The start of more structured collection of data, similar
to what we know today as the practice of citizen science, can be attributed to the beginning of the
20th century, with events such as the Christmas Bird Count and the foundation of the American Association for Variable Star Observers in 1911 (Silvertown, 2009). However, the Internet has made
remote communication and collaboration far easier, and the widespread adoption of smartphones
has greatly facilitated the cooperation of amateur scientists around the world to collect and process
large amounts of data. In ecology, this method has been a vehicle for such a wide participation of
citizens that a plethora of different initiatives has proliferated in the last decade (see for example
the survey paper, Dickinson, Zuckerberg, & Bonter, 2010). An example of this is the iRecord Ladybirds app (Nature Locator, 2013), a system that allows users to collect geo-located photographs
of ladybirds and helps them identify the correct species through a series of morphological and taxonomic questions (e.g. colour and number of spots). Records are stored on a database and presented
on a public page. However, the app does not attempt to automate the analysis and classification
process, outsourcing the task entirely to the users. More recently, the automation of the classification process on a portable device has been attempted for both birds and bats (Jones, Russ, Catto,
Walters, Szodoray-Paradi, Szodoray-Paradi, Pandourski, Pandourski, & Pandourski, 2009). For the
former, due to the difficulty in differentiating these calls, work is still in progress and to date no
deployed prototype exists. For the latter, a project called BatMobile (Nature Locator, 2012) is starting to implement the automated detection on Apple iOS devices, but the requirement for expensive
ultrasonic microphones hinders the accessibility of the tool to the general public on a large scale.
The system we propose in this paper is therefore, to the best of our knowledge, the first deployed
real-time acoustic species recognition system to run entirely on a mobile device.
However, crowdsourcing acoustic biodiversity using a smartphone app presents a number of
challenges. Firstly, smartphones can only be expected to collect short recordings while the user is
waiting (30 seconds in our case), in contrast with the always-on recordings collected from fixed
sensors. Such fixed sensors would generate much longer recordings (in the order of hours and
days) and as a result, existing classification methods are required to automatically remove silent
periods from the recording. As a side effect, this can also remove useful time-domain information
that can be used to easily differentiate insects with similar frequency calls, especially in lower
807

fiZ ILLI , PARSON , M ERRETT & ROGERS

quality recordings from a smartphone. This makes existing methods unsuitable for our purpose.
Furthermore, the smartphone app would require that the algorithm provides some real-time feedback
to the user as to the identification of the insect being heard. This allows the user to be requested
to collect a recording if a cicada is detected, and conversely the user is not required to upload
unnecessary recordings if a cicada is not detected1 . However, low-end mobile devices have limited
processing capabilities compared to that of high-end servers, and therefore the previously proposed
complex feature extraction methods are not suitably efficient to be run in real-time. In addition, it
is essential for an acoustic cicada detector to be able to discriminate between the call of the New
Forest cicada and that of other insects commonly found in the New Forest. Two examples of insects
with similar calls are the dark bush-cricket, whose call is of a similar pitch to the New Forest cicada
but instead chirps with a duration of typically only 0.1 seconds; and the Roesels bush-cricket,
whose call is similar in duration to the New Forest cicada but covers a broader frequency band.
Although this scenario involves the detection of relatively few insects compared to existing work,
the challenge is to design an approach which can be deployed to the field via low cost hardware for
the rediscovery of the New Forest cicada.
Therefore, in this paper we present an algorithm, which we call the Cicada Detection Algorithm
(CDA), specifically intended for real-time detection of the New Forest cicada on computationally
constrained smartphones. Rather than calculating a number of cepstral coefficients as in existing
work, we use the Goertzel algorithm to calculate the magnitude of specific frequency bands, which
is an efficient method for approximating individual terms of a discrete Fourier transform (DFT)
(Goertzel, 1958). We extract the following three frequency bands: the first centred at 14 kHz
corresponding to the strongest frequency component of the calls of the New Forest cicada and the
dark bush-cricket, the second centred at 19 kHz, where both the dark bush-cricket and the Roesels
bush-cricket are still present, but the cicada is not, and the third centred at 8 kHz, which is far
from both general background noise (mostly lower than 5 kHz) and the insects calls. We then
calculate the following two features which form the input to the hidden Markov model: the ratio
between 14 kHz and 8 kHz to distinguish between the New Forest cicada and white noise across
all frequencies, and the ratio between 19 kHz and 14 kHz to distinguish between the New Forest
cicada and the dark bush-cricket. Next, we use a five-state hidden Markov model which explicitly
represents the idle period between insect calls, the calls of the New Forest cicada, dark bush-cricket
and Roesels bush-cricket, and also the short pauses during the dark bush-crickets call. Hence,
rather than attempting to independently classify individual segments of insect calls using a complex
set of features, we exploit the temporal patterns present throughout the recording using the HMM.
We then use the Viterbi algorithm to identify the most likely sequence of insect calls throughout a
recording.
We evaluate our approach using 235 recordings of 30 seconds each in duration collected from
the New Forest and Slovenia (where the same species of cicada is still present). Unlike standard
library recordings, our data set represents the range of crowdsourced data that we are likely to
encounter, exhibiting significant noise (e.g. handling noise, road traffic noise, human voice and
noise generated by the wind), and insect calls of varying amplitude depending on the proximity of
the recording device to the specimen. We show that our approach is able to classify the call of the
New Forest cicada in normal environmental conditions with an F1 score of 0.82. Since existing
approaches are designed for the batch processing of significantly longer recordings, we compare
1. A 30s mono recording at 44,100 samples per second, is about 2.7MB; a significant file to upload in areas with poor
mobile phone reception where connection rates may be down to 100kbps or less.

808

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

Amplitude

Freq (kHz)

20
15
10
5

0
1
0

-1

00:05

00:10

00:15

00:20
00:25
Time (mm:ss)

00:30

00:35

00:40

Figure 2: Spectrogram and waveform of a New Forest cicada call (recording by Jim Grant, 1971
and courtesy of the British Library, wildlife sounds collection).

our approach to three variants in order to evaluate the benefit of various components of the pipeline.
Our results show that our feature extraction procedure is robust to noise, to the call of the Roesels
bush-cricket and to the call of the dark bush-cricket, and therefore satisfies the requirements of our
deployment environment.
This algorithm was implemented on a mobile app, developed for iOS and Android, which was
downloaded over 1500 times by members of the public. This culminated in a large-scale trial deployment, with citizen scientists submitting over 6000 reports worldwide. Although the New Forest
cicada was not found in this first phase, the accuracy of the detection algorithm and wide geographical coverage achieved via crowdsourcing clearly motivate a second phase of deployment. The same
approach can also be applied to the monitoring of many other singing species, and an app that can
recognise all British Orthoptera is currently under development.
A preliminary version of our proposed method has also been compared to a state-of-the-art
approach for batch classification of insects proposed by Chaves et al. (2012). The comparison,
presented by Zilli, Parson, Merrett, and Rogers (2013), shows that our method is considerably more
computationally efficient, and therefore better suited for real-time operation. The method proposed
in this paper has further improved accuracy and efficiency over that presented in Zilli et al.
The remainder of this paper is organised as follows. In Section 2 we describe our proposed
approach, highlighting the different techniques used. In Section 3 we analyse its performance using
hundreds of smartphone recordings. In Section 4 we present the first phase of deployment of our
approach as a smartphone application, and analyse the coverage of reports collected to date. Finally,
we conclude in Section 5 along with our plans for a second phase of deployment to ensure a more
complete coverage of the New Forest.

2. Real-Time Insect Detection Using Hidden Markov Models
We now give a description of our proposed approach for real-time insect detection. We first describe
an efficient method by which individual terms of a DFT can be extracted from raw audio recordings
using the Goertzel algorithm. We then describe two features which can be calculated from three
individual terms of the DFT to produce a feature vector that can discriminate between the insects
of interest and is also robust to environment noise. Next, we formalise the classification of the ex809

fiZ ILLI , PARSON , M ERRETT & ROGERS

tracted features as an inference problem over a HMM. Last, we propose a five-state HMM designed
specifically to capture the temporal patterns of the insects calls.
2.1 Feature Extraction Using Goertzel Algorithm
We observed strong high frequency components in the calls of each of the insects of interest. These
frequencies are sufficiently distant from any common background noise, such as wind noise, road
traffic or people speaking, to be a reliable indicator for the presence of each insect. Figure 2 shows
an example of such a frequency component, in the call of the New Forest cicada which is centred at
14 kHz. An efficient approximation of the magnitude of such frequencies can be calculated using
the Goertzel algorithm; a method that evaluates individual terms of a DFT, implemented as a second
order infinite impulse response filter.
An efficient implementation of the Goertzel algorithm requires two steps. The first step produces
a coefficient that can be pre-computed and cached to reduce CPU cycles:

c = 2 cos

2f
fs


(1)

where f is the central frequency in question and fs is the sampling rate of the recording.
The second step consists of iteratively updating the values of a temporary sequence y with any
incoming sample sn such that:
yn = hamming(sn ) + (c  yn1 )  yn2

(2)

where the samples are passed through a Hamming filter, given by:

hamming(sn ) = 0.54  0.46 cos

2sn
N 1


(3)

and the length of the sequence of samples N determines the bandwidth B of the Goertzel filter, such
that:
fs
B=4
(4)
N
A shorter sequence length N yields a larger bandwidth, at the cost of a noisier output. In
practice, we use multiples of 128 samples to match a typical smartphones audio recording buffer
size. For example, a block size of N = 128 samples gives a bandwidth of just under 1.4 kHz. The
magnitude m of the frequency band centred at f and with bandwidth B in time slice t is then given
by:
q
2 + y2
(5)
mt,f = yN
N 1  c  yN  yN 1
In terms of computational complexity, this approach shows a considerable benefit compared to
the single-bin DFT. An efficient algorithm to compute the latter, the fast Fourier transform, has a
complexity of O(N logN ), while the Goertzel algorithm is only of order O(N ), where N is the
number of samples per window. Moreover, the sample update described in Equation 5 can be processed in real-time, eliminating the need for an independent background thread on the smartphone
app and the need to store sample values.
810

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

z1

z2

z3

zT

x1

x2

x3

xT

Figure 3: A hidden Markov model. Unshaded square nodes represent hidden discrete variables,
while shaded circular nodes represent observed continuous variables. Each xt is a vector of the two
features xt,1 and xt,2 .

2.2 Feature Combination Using Filter Ratio
The magnitude of the frequency component at 14 kHz is a good indicator of the presence of a
New Forest cicada, robust against most background noise, which is normally contained in the lower
5 kHz of the frequency spectrum. However, it may be sensitive to white noise that covers the entire
spectrum, such as handling noise. Furthermore, it will not be able to discriminate between the
calls of the New Forest cicada and the Roesels bush-cricket, both of which exhibit a prolonged
call at a similar frequency. Therefore, we extract the following three frequencies using the Goertzel
algorithm: mt,8 which represents the 8 kHz frequency which is outside the range of both the cicada
call and environmental noise, mt,14 which represents the 14 kHz frequency of both the New Forest
cicada and the dark bush-cricket, and mt,19 which represents the 19 kHz frequency of only the dark
bush-cricket and the Roesels bush-cricket. We then take ratios of these frequencies to produce two
features:
mt,14
mt,19
xt,1 =
, xt,2 =
(6)
mt,8
mt,14
As such, at any point t, xt,1 will be high in the presence of any of the insects considered and
tend to one when either no sound is detected in the cicada range or if sound is present across
both bands. In addition, xt,2 will be high in the presence of the dark bush-cricket, and tend to
zero in the presence of the New Forest cicada. These two features form a T -by-2 feature vector
which is used for classification by our model. In order to obtain real-time computationally efficient
insect identification, we adopt a HMM-based approach to classification as described in the following
section.
2.3 Classification Using Hidden Markov Model
A HMM consists of a Markov chain of discrete latent variables and a sequence of continuous observed variables, each of which is dependent upon one discrete variables state (Ghahramani, 2001).
Figure 3 shows the graphical structure of a HMM, where the discrete, hidden variables (e.g. idle,
cicada singing) are represented by the sequence z1 , . . . , zT , and the continuous, observed variables
(the features extracted from the audio recording) are represented by the sequence x1 , . . . , xT . The
value of each discrete variable zt corresponds to one of K states, while each continuous variable
can take on the value of any real number.
The behaviour of a hidden Markov model is completely defined by the following three parameters. First, the probability of each state of the hidden variable at t = 1 is represented by the vector
811

fiZ ILLI , PARSON , M ERRETT & ROGERS

 such that:
k = p(z1 = k)

(7)

Second, the transition probabilities from state i at t  1 to state j at t are represented by the
matrix A such that:
Ai,j = p(zt = j|zt1 = i)
(8)
Third, the emission probabilities that describe the observed feature, x, given parameters , in
our case follow a log-normal distribution such that:
xt,f |zt ,   ln N (zt , z2t )

(9)

where  = {,  2 }, and zt and z2t are the mean and variance of the Gaussian distribution for
state zt . Figure 4 shows a histogram of data generated by a cicadas song, along with a log-normal
distribution fitted to the data. A log-likelihood ratio test on a normal, log-normal and exponential
distributions fitted to our data set of cicada songs shows that the log-normal distribution matches the
data better than the normal (F = 3512.13, p < 0.001) and exponential (F = 1516.06, p < 0.001)
distributions. However, despite its long tail, the log-normal distribution still has poor support for
data of unusually high magnitude, as are often generated by handling noise. In order to prevent
the model from strongly favouring a certain state when a data point is in the extreme of the lognormal distribution, we cap the emission probabilities to capture cases where our data are likely
to be poorly represented by this model. The outcome of this is that the likelihood that such data
points result from the correct state may be so low that the model triggers a state change even though
the transition probability strongly discourages it (by being itself very low). Therefore, we cap the
emission probability of such data points such that there is a maximum ratio, initially 100, with
which any state can be preferred to another.
Equations 7, 8 and 9 can then be used to calculate the joint likelihood of a hidden Markov
model:
T
T
Y
Y
p(x, z|) = p(z1 |)
p(zt |zt1 , A)
p(xt |zt , )
(10)
t=2

t=1

where the model parameters are collectively defined by  = {, A, }.
We use the Viterbi algorithm (Viterbi, 1967) to infer the most likely sequence of hidden states
given the features described. Despite the fact that the number of possible paths grows exponentially with the length of the chain, this algorithm efficiently finds the most probable sequence by
maximising Equation 10, with a cost that grows only linearly with the length of the chain.
2.4 5-State Finite State Model of Insect Call
We propose a five-state HMM for cicada detection, in which the states consist of: an idle state in
which no insect is singing (I), a cicada singing state (C), a state where the dark bush-cricket is
chirping (DC ), a short pause in between the dark bush-crickets chirps (DSP ) and a state in which
the Roesels bush-cricket is calling (R). The emission parameters, i.e. the location a and scale b of
the log-normal distribution, are learned empirically using:
s 
!

2
2
a = ln p
, b = ln 1 + 2
(11)

 2 + 2
812

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

Log-normal emission
probabilities

Probability density function

Empirical data
for cicada call

Feature value (mt,14 /mt,8 )

Figure 4: Log-normal distribution of the extracted feature for the cicada call
D

R

I
DC

DSP

I

C

Idle state
D

D Dark bush-cricket
DC Dark bush-cricket's chirp
DSP Dark bush-cricket's short pause
R

Roesel's bush-cricket

C

New Forest cicada

(a) 5-state model used by our approach.

R

C

(b) 3-state model.

Figure 5: Comparison of finite state machines.

where  represents the mean and  2 represents the variance of the data. This manual estimation
was originally based on the few recordings the authors had gathered from historical archives, and
has therefore been improved with recordings obtained by the deployment of this work, described in
the following section.
The transition matrices describing the dynamics of a Markovian process can be represented
graphically using finite state machines. Figure 5a shows the five states described above and all possible transitions, where those with non-zero probability are represented by arrows connecting two
states. Our model explicitly represents the silence between the dark bush-crickets chirps, which is
essential information for distinguishing between the calls of the New Forest cicada and dark bushcricket. This is in contrast to existing batch classification methods which remove such silent periods
of a recording in order to improve the computational cost of the operation and classify only sounded
periods of the sample file (Chaves et al., 2012). These methods also employ a feature extraction process whereby they compute a number of mel-frequency cepstral coefficients for each species in the
model, making the process scalable to several insects, at the cost of higher computational complex813

fiZ ILLI , PARSON , M ERRETT & ROGERS

ity. In contrast, the method we proposed in Section 2.1 is more closely tailored to the requirements
of our scenario, producing the improvement in efficiency necessary for our mobile application. Figure 5b shows a variant of our approach where the silent states have been removed, against which we
compare our approach in the following section. Furthermore, the HMM could be arranged so as to
be fully-connected, allowing transitions between states that are otherwise disconnected (for example between a Roesels Bush-cricket and a Dark bush-cricket). However, this confuses the model
between states that have very similar emission probabilities, without providing any improvement in
accuracy. We therefore exclude this variation from the comparison in the following section.

3. Empirical Evaluation Using Smartphone Recordings
We introduce three variants of the approach described thus far that, following the practices in the
literature, motivate the choices made to construct our Cicada Detection Algorithm. The first variant
uses the same approach as proposed in Section 2, but the three raw frequencies, as opposed to their
ratio, are used directly as features (CDA raw frequencies). The second variant removes un-sounded
periods from the recording and, as such, segments it into individual calls. It then applies the 3-state
model shown in Figure 5b to classify the insects (CDA silence removed). The third approach does
not apply a HMM at all, and instead uses the ratio of frequencies to directly identify the most likely
state, given only the instantaneous emission probabilities of the features. As such, this method can
be considered as a mixture model, since each time slice is classified independently. This method
is considerably more computationally efficient, at the cost of losing the information of the time
domain.
We evaluate the accuracy of each approach using a collection of 235 recordings taken by citizen
scientists using smartphones from the New Forest (the only known UK habitat of the New Forest
cicada) and by the authors of this paper in Slovenia (where the same species of cicada is still present)
over the summer of 2013. Each recording is 30 seconds long, and in most cases contains a call of
either the New Forest cicada, a dark bush-cricket or a Roesels bush-cricket. Some recordings
contain different types of noise, including people speaking, walking, calls of birds, handling noise
and even people mimicking the sound of the cicada. In contrast to existing recording libraries, this
data set represents the typical quality of crowdsourced data, exhibiting significant noise and insect
calls of varying amplitude depending on the proximity of the recording device to the specimen.
Each recording was later labelled by domain experts as containing either one or none of the insects
of interest. Although multiple insects in the recordings will not make the classification fail, we
consider only one singing insect per recording. If more than one is present, we set the ground truth
across the 30-second recording as the longest or loudest singing insect, therefore taking the state
active for the longest period as the outcome of the model. Since the emission probabilities in our
model are purposely tuned, we do not require any training data as such, and hence we use the entire
data set as test data. We describe the deployment of the smartphone app used to collect this data in
more detail in Section 4.
We assess the accuracy by which each approach can correctly classify the cicada using the
standard precision, recall and F1 score metrics. The precision represents the fraction of recordings
in which the approach detected the cicada as singing when it was in fact singing, while the recall
represents the fraction of recordings in which the cicada was singing that were correctly detected.
814

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

Approach
CDA
CDA raw frequencies
CDA silence removed
Mixture model

Precision
0.66
0.46
0.62
0.61

Recall
0.78
0.94
0.99
0.65

F1 -score
0.82
0.62
0.75
0.67

Table 1: Accuracy metrics of cicada detection
I

C

D

I

R

C

D

I

R

C

D

R

I

I

I

I

C

C

C

D

D

D

D

R

R

R

R

(a) CDA

C

D

R

I
D

(b) CDA raw frequencies (c) CDA silence removed

C

(d) Mixture model

Figure 6: Confusion matrices for the four variants of the detection algorithm. On the y-axis, the
actual class; on the x-axis, the predicted class.
Precision and recall are defined as:
precision =

tp
,
tp + f p

recall =

tp
tp + f n

(12)

where tp represents the number of correct cicada song detections, f p represents the number of
cicada song detections when it was actually not singing, and f n represents the number of cicada
songs which were not detected. This work is primarily concerned with the detection of the New
Forest cicada, and as such other insects are modelled in order to avoid false positive detections of
the New Forest cicada. We also use the F1 score, which represents a weighted combination of
precision and recall, defined as:
F1 = 2 

precision  recall
precision + recall

(13)

Table 1 shows the precision, recall and F1 score metrics of our approach compared to the three
variants over the data set of recordings from the New Forest and Slovenia. Similarly, Figure 6
reports the true and false positives, with real values along the y axis and predicted class along the x
axis. It can be seen that our approach (CDA) achieves an F1 score of 0.82, and as such outperforms
each benchmark variant, visually apparent from the darkness along the main diagonal in Figure 6a.
In contrast, the variant of our approach which uses the raw frequency measurements as the HMM
feature vector (CDA raw frequencies) receives an F1 score of 0.62. This is a result of the approachs
lack of robustness to noise, such as handling noise, as shown by the high number of false positives in
Figure 6b. Furthermore, the variant of our approach which removes the silent periods (CDA silence
removed) receives an F1 score of 0.75. Although this appears as positive result, Figure 6c highlights
815

fiZ ILLI , PARSON , M ERRETT & ROGERS

its lack of ability to discriminate between the dark bush-cricket and the New Forest cicada. This
method, as well as the raw frequencies approach, favour the New Forest cicada, scoring a good
true positive rate but consequently also a high false postive rate. Finally, the mixture model method
receives an F1 score of 0.67 because the lack of transition probabilities leaves the decision to the
emission probabilities only, not utilising the information contained in the time domain, making
the number of true and false positives more equally distributed (Figure 6d). Insects with similar
emission probabilities, such as the Roesels bush-cricket and the dark bush-cricket, will therefore be
difficult to classify with this method. It should be noted however that this approach is considerably
more computationally efficient, as it decides on the most likely state instantaneously and without
traversing the entire recording.
Figures 7, 8, 9 and 10 show a comparison of the four approaches over a sample recording for
each of the four species in the recordings analysed. The top plot of each figure shows a spectrogram
with the time domain on the x-axis, and the frequency domain on the y-axis, with the magnitude
of the frequency bins varying with the colour of the plot. Subsequently, the figure shows the most
likely state identified by each approach. In each plot, the states are labelled as in Figure 5a, where
I represents the un-sounded idle state (if present), C represents the cicadas song, R represents
the Roesels bush-cricket and DC and DSP the dark bush-crickets chirping and short pause states,
respectively. The gaps in the silence-removed variant correspond to unsounded periods.
Figure 7 shows that classifying the cicada is easier for the HMM-based methods, as the call lasts
for a long period without interruption and is clearly distinct from background noise. A more noisy
recording would cause the raw-frequency approach to fail. The mixture model approach struggles to
distinguish between the cicada and the dark bush-cricket call, since they are similar in features but
different in the time domain, which this model does not capture. Figure 8 shows how the variants are
more sensitive to noise than the CDA for different reasons. The raw frequencies approach doesnt
filter out background noise, while the mixture model triggers a cicada state even for a very short
noise in the right frequency band. The silence-removed method is only active in the short period of
higher background noise, and not having an idle state, it is forced to classify the sound as any of
the sounded states. Figure 9 shows how, when silence is removed, a Roesels bush-cricket becomes
very similar to a dark bush-cricket, having very similar emission probabilities. The same perception
is observed by the mixture model, that doesnt have a perception of time. Similarly, Figure 10 shows
that the dark bush-cricket is difficult to classify for the mixture model and the approach with silence
removed, as explained thus far. Moreover, it shows how a trade-off between a very quiet insect
(visible throughout the recording) and no insect must be made, as the insect could be at any distance
from the microphone, and thus there is no limit to how quiet it may be.
The analysis of each of the 235 recordings is presented in detail on the projects web page, together with the parameters of the HMM, the audio file, and information about the recording device2 .

4. Automated Classification on a Smartphone App
We deployed the insect detection algorithm within a smartphone app that enables wide participation
in the search for this critically endangered species. This process, often referred to as citizen science,
attempts to leverage the widespread presence of users willing to participate such that they act as a
distributed network of sensors, while learning about the scientific process behind a certain research,
2. Result at http://www.newforestcicada.info/devdash. The data can be used free of charge, provided
that the New Forest Cicada Project is attributed according to the Creative Commons Attribution (BY) licence.

816

fiMost likely state

Freq (kHz)

A N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

20

Spectrogram

15
10
5
0
R
C
DC
DSP
I

CDA

CDA
raw frequencies

R
C
DC
DSP
I

CDA
silence removed

R
C
D

Mixture model

R
C
DC
DSP
I

Most likely state

Freq (kHz)

Figure 7: Model comparison on a New Forest cicada recording

20

Spectrogram

15
10
5
0
R
C
DC
DSP
I

CDA

CDA
raw frequencies

R
C
DC
DSP
I

CDA
silence removed

R
C
D

Mixture model

R
C
DC
DSP
I

Figure 8: Model comparison on a recording with no singing insect

817

fiMost likely state

Freq (kHz)

Z ILLI , PARSON , M ERRETT & ROGERS

20
15
10
5

Spectrogram

0
R
C
DC
DSP
I

CDA

R
C
DC
DSP
I

CDA
raw frequencies

R
C

CDA
silence removed

D
R
C
DC
DSP
I

Mixture model

Most likely state

Freq (kHz)

Figure 9: Model comparison on a Roesels bush-cricket recording

20

Spectrogram

15
10
5
0
R
C
DC
DSP
I

CDA

CDA
raw frequencies

R
C
DC
DSP
I

CDA
silence removed

R
C
D

Mixture model

R
C
DC
DSP
I

Figure 10: Model comparison on a dark bush-cricket recording

818

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

Possible cicada
detected
Save audio
recording
Live detection

Record audio

Sounds interesting
Upload report
No cicada
detected

Figure 11: Flow of the detection and classification process on the app.
in this case the automated identification of species for biodiversity monitoring. Examples of the
communities to which this app caters include tourists and visitors to the New Forest National Park,
local residents and bug enthusiasts. In order to maximise the number of citizen scientists taking
part, it was essential for the app to be compatible with a wide range of hardware, in addition to
being simple and unobtrusive to use. Therefore, we released both an iPhone and Android client,
which ensures compatibility with over 80% of smartphone users (Go-Gulf, 2012). Furthermore, we
designed the app to be simple to use, require user consent when recording audio and to constrain
usage of both battery and mobile data usage.
Figure 11 shows an overview of the flow of interaction when a user takes a recording with
the app. When a user first opens the app they are presented with the live detection screen, which
displays a graphical representation of the audio signal entering the microphone, in the form of a
circular spectrogram, and an immediate feedback on the presence of a singing cicada, obtained
through the output of the mixture-model described in Section 2. Upon selecting to start an audio
recording, the user is shown the current progress through the 30 second recording. On completing
the recording, the CDA is run and the user is presented with one of three possibilities: a possible
cicada detected screen, a sounds interesting screen (which notes that the algorithm has detected an
insect that is not the cicada), or the no cicada detected screen (where nothing known was found). A
report of the survey is saved locally and uploaded upon connecting to the Internet. If the recording
contains any of the known insects, the user is asked for their consent to upload the recorded audio.
4.1 Stages of Real-Time Classification
In order to capture a sound to be fed to the automated classifier, the user is presented with an intuitive
interface, summarised in Figures 12 and 13 and detailed as follows:
4.1.1 L IVE D ETECTOR
Figure 12a shows the detector screen, which appears upon loading the app. A crucial difficulty for
a human to detect the New Forest cicadas call is the fact that the pitch is too high for most people
to hear, since the central frequency is at the limit of the hearing range of the average 40 year old. To
address this issue, this tab presents a visualisation of the sound drawn as a circular spectrogram. In
the centre, the cicada logo lights up when a call is detected, triggered by the instantaneous output of
the mixture model described in Section 2, updated every 128 samples from the microphone. Twenty
819

fiZ ILLI , PARSON , M ERRETT & ROGERS

(a) Live detector

(b) Audio recording

(c) Upload recording

Figure 12: Three screens of Cicada Hunt on Android. On the left, a cicada singing lights up the
icon and the frequency bands around 14 kHz. In the middle, a cicada was singing during a survey
and stopped shortly after 15 seconds. On the right, the latest survey is waiting to be uploaded.
concentric circles around it represent twenty frequency bands of the spectrum, centred from 1 to
20 kHz with a bandpass of 1.4 kHz, extracted with 20 Goertzel filters, which ensure rapid updating
of the interface. Each of these becomes brighter with a higher signal strength (i.e. a louder sound
at that pitch) and paler when the band is quieter. The outer bands, roughly from 12 to 18 kHz, are
those triggered by the cicada call, producing the distinctive effect shown in Figure 12a. Tapping the
cicada icon at the centre of the app starts a 30-second survey, during which the sound is recorded
and then analysed by the algorithm described in Section 2. This idea is core to the interface, as it
encourages users to stop and wait in silence, thus maximising the chance of detecting the required
sound. The choice of 30 seconds strikes a balance between the length of the cicada call and the
amount of time a usermostly an occasional visitor to the forestcan be expected to stand still
and in silence.
4.1.2 AUDIO R ECORDING
Figure 12b shows the screen shown during a 30 second audio recording. Once the recording has
finished, the audio is analysed by the HMM-based algorithm described in Section 2. Depending on
the result of the classification, the user is shown either the no cicada detected screen, the sounds
interesting screen or the possible cicada detected screen.
4.1.3 U PLOAD R ECORDING
Figure 12c shows a list of reports which have been saved locally. Each report is geo-tagged and
time-stamped, and saves a unique identifier of the phone as well as basic information about the
device. The report also saves an uncompressed 44.1 kHz 16 bit PCM WAV sound recording in the
820

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

(a) No cicada detected

(b) Sounds interesting

(c) Possible cicada detected

Figure 13: Three possible outcomes of the CDA, where no known insect is found, an insect that is
not a cicada is found, or the cicada itself is found.
case that either the cicada or another insect is found, provided the user has granted permission to do
so. Since the audio recording requires 2.7 MB on disk, it is deleted from the smartphone as soon as
the report is sent to the server to minimise the storage space required on each smartphone. Last, a
low-resolution spectrogram is saved in all cases, constructed from the combination of the output of
20 Goertzel filters over the 30 seconds survey, saved every 128 samples. This constitutes the easiest
way for a human to check for the presence of the cicada and avoids any privacy concerns (speech
could not be reconstructed from such a spectrogram). Moreover, the payload of the image file,
saved in Base64 (Josefsson, 2006), is around 15 KB and therefore much lighter than a raw sound
recording. Once an Internet connection becomes available, the report is uploaded to the projects
servers, where it is available to the research team to analyse further.
4.1.4 N O C ICADA D ETECTED
Figure 13a shows the screen shown if nothing was detected. A fact about the cicada, its habitat, the
New Forest or the technology behind the app is shown to provide an informative notion, encouraging
the user to try again. This intends to both support the morale of the user who is receiving negative
results, and to provide educational content so that the citizen scientist receives some information in
exchange for the work they have performed.
4.1.5 S OUNDS I NTERESTING
Figure 13b shows the screen displayed when another insect is detected, whose call is similar to that
of the New Forest cicada. At present, the app encompasses two other insects present in the New
Forest: the dark bush-cricket and the Roesels bush-cricket. The user is shown a spectrogram of a
typical call of these insects, as well as a spectrogram of what they have just recorded, and they are
821

fiZ ILLI , PARSON , M ERRETT & ROGERS

Device
iPhone 4
iPhone 5
iPhone 4S
iPhone 3
HTC Desire
Xperia Mini
Moto A953
Galaxy S3
Xperia Z
HTC One S
Nexus 4
HTC Desire X
Galaxy Ace 2
Galaxy S2
Nexus One
HTC One X
HTC Wildfire S

OS
iOS
iOS
iOS
iOS
Android
Android
Android
Android
Android
Android
Android
Android
Android
Android
Android
Android
Android

Filtered
No
No
No
No
No
No
No
No
No
No
No
No
No
No
Yes
Yes
No

Silence (SEM)
1.623 (0.075)
1.897 (0.076)
1.466 (0.050)
1.469 (0.047)
0.844 (0.041)
2.480 (0.155)
2.015 (0.104)
1.374 (0.038)
0.951 (0.032)
1.466 (0.040)
0.675 (0.025)
1.243 (0.054)
1.953 (0.063)
1.916 (0.085)
1.514 (0.051)
1.933 (0.062)
2.032 (0.088)

Cicada (SEM)
13.047 (0.327)
14.793 (0.388)
10.549 (0.337)
10.539 (0.430)
4.255 (0.265)
10.190 (0.262)
5.845 (0.148)
3.279 (0.088)
1.971 (0.059)
2.915 (0.085)
1.314 (0.026)
1.817 (0.075)
2.162 (0.059)
2.101 (0.031)
1.568 (0.045)
1.732 (0.052)
1.683 (0.063)

Ratio (SEM)
8.041 (0.442)
7.800 (0.373)
7.196 (0.336)
7.173 (0.372)
5.041 (0.397)
4.109 (0.277)
2.901 (0.167)
2.387 (0.093)
2.072 (0.094)
1.988 (0.079)
1.946 (0.081)
1.462 (0.087)
1.107 (0.047)
1.097 (0.051)
1.036 (0.046)
0.896 (0.040)
0.828 (0.047)

Table 2: Comparison of most popular smartphone devices. Values are means of ratios of 14 and
8 kHz Goertzel filters, sampled every  3 ms (128 samples at 44,100 kHz). Standard error of the
mean (SEM) is given in brackets.
asked to select which insect their recording looks most similar. This promotes the involvement of
the user in the process, who would otherwise be passively observing the detection performed on the
smartphone.
4.1.6 P OSSIBLE C ICADA D ETECTED
Figure 13c shows a message informing the user of the discovery of the cicada. Since the algorithm
can be tricked by a recording of an actual call, the detection is presented as possible.
4.2 Evaluation of Microphones Frequency Response
Prior to deployment, it was noted that not all smartphones are equally capable of detecting the
cicada. Our tests reveal that some smartphones are equipped with a microphone considerably more
sensitive than others. We tested a range of different devices by reproducing four types of sound for at
least 2 seconds each: silence, white noise, a frequency sweep from 50 to 20,000 Hz, and the cicada
call. These were reproduced in a custom-built sound-proof chamber, placed in a quiet location, with
a Visaton KE 25 SC 8 Ohm tweeter producing the four test sounds. The phones were arranged with
the microphone facing the speaker and all equally distant from it. From our experiences recording
cicada calls in Slovenia, the sound volume was calibrated so that the volume of the cicada call was
equivalent to that likely to be detected in the wild. The synthetic white noise and frequency sweep
were tuned to match the maximum amplitude of the cicada call.
We report a comparison of the sensitivity of the microphones based on how well they detect
the cicada call in our test environment. Table 2 summarises the outcome of the test, reporting the
822

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

Ampl.

(a)

Freq (kHz)

20
15
(b) 10
5
0
20
15
(c) 10
5
0
20
15
(d) 10
5
0
20
15
(e) 10
5
0
00:05

00:10

Time (s)

00:15

00:20

00:25

Figure 14: Comparison of three phones. At the top, the waveform (a) and spectrogram (b) of the
sample calibration file. At the bottom, the very sensitive iPhone 5 (c), the Google Nexus 4 (d) and
the hardware-filtered HTC One X (e), all top-end devices for iOS and Android.
ratio between the 14 kHz and 8 kHz bands extracted with the Goertzel filter when no sound was
played (marked as Silence), when the cicada call was played (Cicada), and the ratio between these
two. A higher value of the latter means a clearer indication of the cicada call, which results in a
clearer separation of the log-normal distributions representing the sounded and unsounded states,
and therefore greater confidence in the detection. It can be seen that all models of iPhone capture
the call of the New Forest cicada most accurately, while Android phones exhibit a wide range in
performance. This is not due to the operating system itself, but rather to the more varied range of
hardware specifications in common Android devices. Figure 14 shows the reference sound played to
the phone, together with three examples of high-end devices; the Apple iPhone 5, which detects the
cicada call very clearly, the Nexus 4, which detects it most of the time, and the HTC One X, which
despite having a sensitive microphone, uses a low-pass frequency filter, and is therefore incapable
of detecting the insects call. This is confirmed by the divergent rank these devices score in Table 2.
4.3 Large-Scale Trial Deployment
The smartphone app was launched on 8th June 2013 and collected data until the end of the mating
season of the New Forest cicada. Since its launch, over 1000 citizen scientists have submitted over
6000 reports worldwide. Of these, at least 1777 were in the New Forest (over 1600 were submitted
before a GPS fix had been acquired); of the New Forest reports, 162 were classified as either sounds
interesting or potential cicada detected, and as a result include a 30 second audio recording. Of the
citizen scientists who submitted reports, 738 used the iOS version of the app, while 346 used the
Android version.
Figure 15 shows a bar graph of the number of reports uploaded by the top 25 contributors, with
the trend for the top 100 users displayed in the top-right corner. It should be noted that among these,
5 are entomologists and authors of this paper. However, these users only covered specific areas of
the forest, in particular those where the cicada had historically been observed. In contrast, the citizen
scientists submitted much fewer reports per user, but the reports were much more evenly distributed
823

fiiOS
Android

Number of Reports

247

200

236

164

100

150

0

78

63

54 52

1

Ranking

100

42 40 38 38 37 37 37 36 36 34
33 33 31 30 29 29

0

50

Number of Reports

300

306 301

250

300

350

Z ILLI , PARSON , M ERRETT & ROGERS

1

2

3

4

5

6

7

8 9

10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
Ranking

Figure 15: Reports per user by operating system for the top 25 users (right, trend of the top 100).

across the New Forest, as shown in Figure 16. This shows the crucial difference that this distributed
approach can make, as entomologists cannot be ubiquitously present in different areas of the forest
when the conditions are favourable, and can only cover a limited territory, while visitors, though
contributing individually less, can help rediscover the cicada if it has moved to different sites, as
it is currently suspected. At the same time, while entomologists have the tools and the knowledge
to recognise insects calls, the general public must be equipped with an accessible method. In this
space, the implementation and deployment of our automated acoustic insect detection algorithm has
succeeded to bring to the public the possibility to contribute to the distributed monitoring of insect
species, as shown by the large number of downloads of the app and submitted reports.

5. Conclusions
In this paper we have presented a novel algorithm designed specifically to detect the mating call of
the New Forest cicada. We have shown that through a careful analysis of its call, key features can be
extracted at minimal cost, greatly simplifying the identification process. We compared our approach
with three variants of our own approach, as no method exists to date to the best of our knowledge to
automatically classify insects calls on a constrained platform, such as a mobile phone. Of the three
variants, one uses the raw frequency components as HMM feature vectors, a second variant removes
the silent periods of a recording and a third one classifies time slices independently based upon only
the emission distributions. Our results show that our approach achieves an accuracy of F1 = 0.82
for the detection of the New Forest cicada on a data set of recordings collected from the New Forest
and Slovenia using iPhone and Android smartphones. Such recordings included various forms of
background noise, insects calls and human voices. Rather than focusing on the batch processing
of large data sets of species, our approach is focused upon the identification of a small number of
species in real time.
824

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

(a) The New Forest

(b) UK

Figure 16: Map of submitted surveys around the New Forest and across the UK. The area of the
New Forest corresponds to the green area in the centre.

With the development of the robust acoustic classifier complete, we integrated the technology
into the smartphone app for iOS and Android. A large-scale deployment resulted in the collection
of at least 1777 reports in the New Forest, of which 162 detected the call of an insect of interest,
from over 1000 citizen scientists. Although the New Forest cicada was not successfully detected
during its two month mating season in 2013, the use of the app in Slovenia confirmed the accuracy
of the acoustic detector and the deployment in the New Forest attested the suitability of using citizen
scientists to crowdsource the collection of audio reports via smartphones. The app is now also used
by expert entomologists in Slovenia to detect the presence of Cicadetta montana.
Our future work will consist of a second deployment of the smartphone app during the two
month mating season of the New Forest cicada, with the aim of achieving a greater coverage of the
New Forest, and as such it will require the mobilisation of a larger community of citizen scientists
to cover the areas of the New Forest which have not yet been surveyed. Such a deployment will
constitute the largest survey of the New Forest cicadas habitat to date, and therefore will provide
unprecedented insight into the existence of this endangered species. Moreover, an app for the classification of all British Orthoptera is also currently under development, and will pose a new set
of challenges. In fact, with a higher number of different calls, the selection of distinctive features
for the HMM becomes more difficult, and may require sampling at a higher frequency, increasing
the computational complexity of the approach. To increase our accuracy and encompass a wider
number of devices, we will use techniques such as cepstral mean normalisation to account for the
difference in sensitivity of microphones.
Since the learning part of the algorithm is completed offline, our algorithm remains an efficient
solution to classify insects calls in real time on a mobile device, and may readily be extended to
the calls of different animals, such as other insects and birds. Preliminary work on this extension
has now started, with the goal of an adaptive acoustic classifier that can be trained for different
sound-emitting wildlife species.
825

fiZ ILLI , PARSON , M ERRETT & ROGERS

Acknowledgements
This research was supported by an EPSRC Doctoral Training Centre grant (EP/G03690X/1) and
by the ORCHID Project, www.orchid.ac.uk (EP/I011587/1). Many thanks to Dr Tomi Trilar and
Prof Matija Gogala for their field guidance in Slovenia and to Dr David Chesmore for his original
suggestion and ongoing support.

References
Brenna, B. (2011). Clergymen Abiding in the Fields: The Making of the Naturalist Observer in
Eighteenth-Century Norwegian Natural History. Science in Context, 24(02), 143166.
Chaves, V. A. E., Travieso, C. M., Camacho, A., & Alonso, J. B. (2012). Katydids acoustic classification on verification approach based on MFCC and HMM. Proceedings of the 16th IEEE
International Conference on Intelligent Engineering Systems (INES), 561566.
Chesmore, E. D. (2004). Automated bioacoustic identification of species. Anais da Academia
Brasileira de Ciencias, 76(2), 436440.
Chesmore, E. D., & Ohya, E. (2004). Automated identification of field-recorded songs of four
British grasshoppers using bioacoustic signal recognition. Bulletin of Entomological Research, 94(04), 319330.
Dickinson, J. L., Zuckerberg, B., & Bonter, D. N. (2010). Citizen Science as an Ecological Research
Tool: Challenges and Benefits. Annual Review of Ecology, Evolution, and Systematics, 41(1),
149172.
Ghahramani, Z. (2001). An Introduction to Hidden Markov models and Bayesian Networks. In
Journal of Pattern Recognition and Artificial Intelligence, Vol. 15, pp. 942.
Go-Gulf (2012). Smartphone Users Around the World  Statistics and Facts.
http://www.go-gulf.com/blog/smartphone, retrieved 19/07/2012.

On-line,

Goertzel, G. (1958). An algorithm for the evaluation of finite trigonometric series. The American
Mathematical Monthly, 65(1), 3435.
Gomes, C. P. (2009). Computational Sustainability: Computational methods for a sustainable environment, economy, and society. The Bridge, 39(4), 513.
Joint Nature Conservation Committee (2010). UK priority species pages Cicadetta montana (New
Forest Cicada). Tech. rep..
Jones, K. E., Russ, J., Catto, C., Walters, C., Szodoray-Paradi, A., Szodoray-Paradi, F., Pandourski,
E., Pandourski, I., & Pandourski, T. (2009). Monitoring bat biodiversity: indicators of sustainable development in Eastern Europe Darwin Initiative  Final Report. Tech. rep., Zoological
Society London.
Josefsson, S. (2006). The base16, base32, and base64 data encodings. RFC 4648, Standards Track.
Leqing, Z., & Zhen, Z. (2010). Insect Sound Recognition Based on SBC and HMM. In International
Conference on Intelligent Computation Technology and Automation (ICICTA), Changsha,
China, Vol. 2, pp. 544 548.
MacLeod, N. (2007). Automated Taxon Identification in Systematics: Theory, Approaches and Applications. CRC Press.
826

fiA N HMM ACOUSTIC C ICADA D ETECTOR FOR C ITIZEN S CIENCE

Miller-Rushing, A., Primack, R., & Bonney, R. (2012). The history of public participation in ecological research. Frontiers in Ecology and the Environment, 10(6), 285290.
Nature Locator (2012).
10/04/2014.

BatMobile Project.

On-line, http://batmobile.blogs.ilrt.org, retrieved

Nature Locator (2013). iRecord Ladybirds Project. On-line, http://naturelocator.org/ladybird.html,
retrieved 10/04/2014.
Pinchen, B. J., & Ward, L. K. (2002). The history, ecology and conservation of the New Forest
Cicada. British Wildlife, 13(4), 258266.
Pinhas, J., Soroker, V., Hetzoni, A., Mizrach, A., Teicher, M., & Goldberger, J. (2008). Automatic
acoustic detection of the red palm weevil. Computer and Electronics in Agriculture, 63, 131
139.
Potamitis, I., Ganchev, T., & Fakotakis, N. (2006). Automatic acoustic identification of insects
inspired by the speaker recognition paradigm.. In Interspeech 2006, Pittsburgh, Pennsylvania,
pp. 21262129.
Quinn, J. A., Frias-Martinez, V., & Subramanian, L. (2014). Computational Sustainability and
Artificial Intelligence in the Developing World. AI Magazine Special Issue on Computational
Sustainability.
Silvertown, J. (2009). A new dawn for citizen science.. Trends in ecology & evolution, 24(9),
46771.
Viterbi, A. (1967). Error bounds for convolutional codes and an asymptotically optimum decoding
algorithm. IEEE Transactions on Information Theory, 13(2), 260269.
Zilli, D., Parson, O., Merrett, G. V., & Rogers, A. (2013). A Hidden Markov Model-Based Acoustic
Cicada Detector for Crowdsourced Smartphone Biodiversity Monitoring. In International
Joint Conference for Artificial Intelligence, Beijing, China. AAAI Press.

827

fiJournal of Artificial Intelligence Research 51 (2014) 779804

Submitted 09/14; published 12/14

Research Note
BDD Ordering Heuristics for Classical Planning
Peter Kissmann
Jorg Hoffmann

KISSMANN @ CS . UNI - SAARLAND . DE
HOFFMANN @ CS . UNI - SAARLAND . DE

Saarland University, Saarbrucken, Germany

Abstract
Symbolic search using binary decision diagrams (BDDs) can often save large amounts of memory due to its concise representation of state sets. A decisive factor for this methods success is the
chosen variable ordering. Generally speaking, it is plausible that dependent variables should be
brought close together in order to reduce BDD sizes. In planning, variable dependencies are typically captured by means of causal graphs, and in preceding work these were taken as the basis for
finding BDD variable orderings. Starting from the observation that the two concepts of dependency are actually quite different, we introduce a framework for assessing the strength of variable
ordering heuristics in sub-classes of planning. It turns out that, even for extremely simple planning
tasks, causal graph based variable orders may be exponentially worse than optimal.
Experimental results on a wide range of variable ordering variants corroborate our theoretical
findings. Furthermore, we show that dynamic reordering is much more effective at reducing BDD
size, but it is not cost-effective due to a prohibitive runtime overhead. We exhibit the potential of
middle-ground techniques, running dynamic reordering until simple stopping criteria hold.

1. Introduction
Finding good variable orderings is an important task in many areas of Artificial Intelligence, such as
constraint satisfaction problems (CSPs), SAT, and planning (for some heuristic search approaches,
but especially when applying symbolic search). In many cases, an efficient ordering is determined
by evaluating a graphical representation of the underlying problem. For CSPs, for example, the
constraint graph can be used to determine a variable ordering for backtracking-based approaches.
Typical approaches take the minimum width (Freuder, 1982), maximum degree, or maximum cardinality (Dechter & Meiri, 1989) of nodes in the constraint graph into account. An alternative
approach considers the bandwidth of the constraint graph under a given ordering, which is the maximal distance in that ordering of any two nodes that are adjacent in the graph; the idea is to find an
ordering that minimizes the bandwidth (Zabih, 1990).
In SAT, a widely used approach to determine the variable order in conflict-driven clause learning
(CDCL) is variable state independent decaying sum (VSIDS) (Moskewicz, Madigan, Zhao, Zhang,
& Malik, 2001). This is based on the weights of propositional variables, i.e., how often such a
variable occurs in the clauses. Recently, Rintanen (2012) noted that for applying SAT solvers to
planning tasks, a different ordering might be more efficient, giving better coverage in the typical
benchmarks of the international planning competition (IPC). This ordering takes the structure of
planning tasks into account, trying to support (sub)goals as early on as possible.
In planning, variable dependencies are typically represented by the causal graph (e.g., Knoblock,
1994; Jonsson & Backstrom, 1995; Brafman & Domshlak, 2003; Helmert, 2006), capturing variable
dependencies in terms of co-occurences in action descriptions. This kind of graph has turned out
c
2014
AI Access Foundation. All rights reserved.

fiK ISSMANN & H OFFMANN

to be useful for a great variety of purposes, including problem decomposition (Knoblock, 1994),
system design (Williams & Nayak, 1997), complexity analysis (e.g. Jonsson & Backstrom, 1995;
Domshlak & Dinitz, 2001; Brafman & Domshlak, 2003; Katz & Domshlak, 2008; Gimenez &
Jonsson, 2008; Chen & Gimenez, 2010), derivation of heuristic functions (Helmert, 2004, 2006),
and search topology analysis (Hoffmann, 2011b, 2011a). For our purposes here, the causal graphs
most relevant application is the derivation of variable orderings. That has been done for BDDs, to
which we return in detail below, as well as for merge-and-shrink heuristics (Helmert, Haslum, &
Hoffmann, 2007; Helmert, Haslum, Hoffmann, & Nissim, 2014). In merge-and-shrink, a complete
variable ordering corresponds to a (linear) merging strategy, an order in which variables are merged
into a global abstraction. In a recent extension to non-linear merging strategies (Sievers, Wehrle,
& Helmert, 2014), the order of the merges is instead given by a tree. Such a merge tree bears
some similarity to the concept of vtrees, which are used as a generalization of variable orderings for
sentential decision diagram (SDDs) (Darwiche, 2011). Fan, Muller, and Holte (2014) have shown
that efficient merge trees can be determined by means of the causal graph. To do so, they use MinCuts in the causal graph, putting the two resulting sets of variables into two different branches of
the merge tree and recursively continue in the subgraphs.
In this paper, we are concerned with symbolic search based on binary decision diagrams (BDDs)
(Bryant, 1986) for optimal planning. A variable ordering here refers to the order in which variables
are queried within the BDDs, a key ingredient for the practical efficiency of the approach. In
planning, not much work has been invested into finding good variable orderings, but in model
checking, where symbolic search originated (McMillan, 1993), many different variable ordering
schemes have been proposed in the past (e.g., Malik, Wang, Brayton, & Sangiovanni-Vincentelli,
1988; Minato, Ishiura, & Yajima, 1990). Again, many of those are based on the evaluation of
a graphical representation of the problem. Often, bringing dependent variables close together
results in smaller BDDs. This can be straightforwardly applied to planning, by defining variable
dependencies via the causal graph. That is exactly how Gamer, a state-of-the-art symbolic search
planner, determines its variable ordering (Kissmann & Edelkamp, 2011).
The starting point of our investigation is a feeling of discomfort with the double use of the word
dependency in the above. In causal graphs, such a dependency means that the corresponding
variables appear in at least one common action, so changing the value of one variable may require
changing the other variable as well. BDDs, on the other hand, represent Boolean functions .
If many assignments to a subset P of all variables immediately determine the truth value of ,
independently of the value of the other variables, then the variables in P should be grouped closely
together. In planning,  typically represents a layer of states sharing the same distance to the initial
state (forward search) or the goal (backward search). So the concept of dependence here relates
to determining whether or not a state is a member of such a layer. What, if anything, does this have
to do with causal graph dependencies?
We do not have a conclusive answer to that question, but we contribute a number of insights
suggesting that the two concepts of dependence do not have much in common. We consider the
issue from both a theoretical and a practical perspective. On the theoretical side, we introduce a
simple formal framework for assessing the strength of variable ordering heuristics in sub-classes of
planning. Applying that framework to causal graph based variable orders, we show that these may
be exponentially worse than optimal orderings, even for extremely simple planning tasks.
On the practical side, we experiment with a wide range of variable ordering schemes, several
ones based on the causal graph, and also a range of techniques adapted from the model checking
780

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

literature. To get an idea of how good these ordering schemes are, on the grand scale of things,
we use an upper and a lower delimiter. For the latter, we use random variable orderings. Not
too surpisingly, most ordering schemes are better than random; surprisingly, not all of them are.
Indeed, Fast Downwards level heuristic (Helmert, 2006) turns out to be much worse than the
average random BDD variable ordering.
As the upper delimiter, we employ dynamic reordering techniques that minimize BDD size
online, during the construction process. Compared to static up-front variable ordering schemes,
such reordering has a much better basis for taking decisions, but is much more time-consuming. It
is thus expected for the BDD size results to be much better. The extent to which that happens in our
experiments is remarkable, however: Static orderings are hardly ever even a tiny bit better, whereas
the advantage of dynamic reordering easily and frequently goes up to three orders of magnitude.
While it has been successfully employed in at least one domain in non-deterministic planning
(Cimatti, Pistore, Roveri, & Traverso, 2003), dynamic reordering usually is prohibitively slow and
not cost-effective. Still, its prowess at reducing BDD size, combined with our pessimistic outlook
on static ordering schemes, suggests that it may be the better alternative. An initial experiment
indicates that this could, indeed, be the case: With very simple adaptive stopping criteria, running
dynamic reordering only up to a certain point, we obtain better results than with any of the static
ordering schemes.
The remainder of the paper is organized as follows. Section 2 gives the necessary background
on our planning framework and the use of BDDs. Section 3 introduces our theoretical framework
and investigates the properties of causal graph based ordering schemes in a range of well-known
planning sub-classes. Section 4 presents our experiments regarding the quality of causal graph
based ordering schemes, and Section 5 presents our experiments with adaptive stopping criteria for
dynamic reordering. Section 6 concludes the paper with a brief discussion and outlook.
This research note is an extension of the authors previous short conference paper (Kissmann
& Hoffmann, 2013). The present paper contains comprehensive details regarding the technical
background and the variable orderings we implemented, and it includes full proofs. The experiments
with adaptive stopping criteria for dynamic reordering, Section 5, are new.

2. Background
For BDD-based planning, as argued e.g. by Edelkamp and Helmert (1999), it is important to have
a small encoding of the given planning task. So we use a finite-domain variable representation as
the basis for our investigation. A finite-domain representation (FDR) planning task is a tuple
 = hV, A, I, Gi, where V is the set of state variables and each v  V is associated with its
finite domain D(v). A is a finite set of actions where each a  A is a pair hpre a , eff a i of partial
assignments to V with pre a being the precondition and eff a the effect of action a. The initial state
I is a complete assignment to V . The goal G is a partial assignment to V . By V(pa), for a partial
assignment pa, we denote the variables v  V where pa(v) is defined.
An action a  A is applicable in a state s iff pre a  s. For the resulting successor state s0 it
holds that s0 (v) = eff a (v) for all v  V(eff a ) and s0 (v) = s(v) for all v  V \ V(eff a ). A plan
is a sequence of actions whose successive application starting in the initial state results in a state sg
with G  sg . A plan is optimal if no plan of shorter length exists.
Binary decision diagrams (BDDs) as introduced by Bryant (1986) represent Boolean functions
. A BDD  is a directed acyclic graph with one root and two terminal nodes, the 0-sink and the
781

fiK ISSMANN & H OFFMANN

x1

x1

x3

x2

x2

x3

x3

0

1

x2

x3

x3

0

(a) Full OBDD.

1

(b) Reduced OBDD.

Figure 1: Example BDDs for the function  = ((x1  x2 )  x3 ). Dashed arrows denote low edges;
solid ones high edges.
1-sink. Each internal node corresponds to a binary variable p and has two successors, one following
the high edge taken if p is true and one following the low edge taken if p is false. For any assignment
to all variables the sink reached corresponds to the value of the function  represented by .
As is common in practice, here we use reduced ordered BDDs. An ordered BDD (OBDD)
is a BDD in which the ordering of the binary variables on any path is fixed. A reduced OBDD
applies two reduction rules to result in a canonical representation: (i) remove any node with identical
successor along the high and the low edge; (ii) merge nodes of the same variable that have the same
successor along the high edge and the same successor along the low edge. Figure 1 illustrates
example BDDs for the function  = ((x1  x2 )  x3 ) with the ordering hx1 , x2 , x3 i. In Figure 1a
we have the full OBDD without any reduction. When considering the nodes for x3 , we note that
the rightmost one can be removed due to rule (i), and the other three can be merged due to rule (ii).
Applying these rules to preceding layers as well, we end up with the reduced OBDD in Figure 1b.
We consider BDD-based planning in terms of symbolic search (McMillan, 1993) as implemented in Gamer (Kissmann & Edelkamp, 2011). The finite-domain variables V of the FDR task
are encoded by replacing each v  V with a binary counter (v) using dlog2 |D(v)|e bits. For a task
representable by n bits we need 2n BDD variables in two sets, one set x representing the current
state variables, another set x0 representing the successor state variables. Each action a  A is represented by a transition relation BDD, Ta (x, x0 ), which captures the changes due to the application
of a but also the frame, i.e., the variables that do not change:
Ta (x, x0 ) = pre a (x)  eff a (x0 )  frame(V \ V(eff a ), x, x0 )
W
with frame(V 0 , x, x0 ) = vV 0 v(x)  v(x0 ) modeling the
W frame. It is possible to create a monolithic transition relation over all actions, i.e., T (x, x0 ) = aA Ta (x, x0 ). However, this typically
is not feasible in terms of memory. Thus, we store the transition relations of all actions separately
(Burch, Clarke, & Long, 1991).
In order to calculate the successors of a set of states S, represented in the current state variables,
we use the image function
image(S) =

_

x.(S(x)  Ta (x, x0 ))[x0  x].

aA

782

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

The conjunction makes sure that only applicable actions are considered, and sets the corresponding
successor state variables. The existential quantification removes the current state variables. The
operator [x0  x] stands for a swapping of the current and successor state variables, so that in the
end the successor states are again represented in the current state variables, i.e., they are the new
current states. Finally, the disjunction ensures that the successors based on all actions are calculated.
For the case of backward search, the pre-image calculating the predecessors of a set given in the
successor variables looks similar, only that the successor state variables are quantified instead of the
current state variables.
Using these two functions, symbolic breadth-first search is straightforward: Starting at the initial
state (or the set of goal states), iterate the image (or the pre-image), until a goal (or the initial state)
is reached. Storing the entire set of reached states we can ensure completeness. During search, each
layer L of states  a subset of states with identical distance to the initial state (forward search) or
the goal (backward search)  is then represented by a BDD for its characteristic function.
Based on a given variable ordering, the size of the BDD, i.e., the number of nodes needed to
represent the corresponding function, can differ exponentially, so that finding good orderings is
crucial in practice. As the size also has an influence on the runtime (e.g., the time and memory
requirements for the conjunction of two BDDs is polynomial in the product of the sizes of the two
BDDs), smaller size is important not only in terms of memory but also in terms of runtime. BDD
packages typically contain dynamic reordering algorithms, which can reduce the BDD sizes based
on the current situation. However, as previous work has argued (Kissmann & Edelkamp, 2011),
and as our experiments here reconfirm, the runtime overhead of dynamic reordering is prohibitive
in planning. The alternative is to use static variable ordering schemes instead. We define such
schemes as functions  mapping any planning task  to a non-empty set () of variable orderings, i.e., orderings of the planning tasks finite-domain variables V . We use a set () here, as
opposed to a single ordering, because the variable ordering schemes we consider here contain ambiguity, i.e., they impose only some constraints on the final variable ordering as opposed to fixing a
unique complete ordering.
Before the first BDD is created, the set of possible orderings is determined in a pre-processing
step, and the actual ordering hv1 , . . . , vn i = o  () is chosen arbitrarily (i.e., we do not consider
this step here). The calculated ordering is defined over the set of multi-valued variables. Thus, to
get the final BDD binary variable order we replace each finite-domain variable vi in o with its binary
counter (vi ). This means that the BDD treats these counters like inseparable fixed blocks. (Note
that the bits of the counters are not represented at the level of the planning tasks , so that it is
impossible for  to make an informed choice for a separation of such a block.) In addition to these
blocks we store the current and successor state variables in an interleaved fashion (Burch, Clarke,
Long, McMillan, & Dill, 1994).
For any layer L and ordering o of the planning tasks finite-domain variables, the ordered BDD
is unique. We denote its size, i.e., the number of nodes, by BDDSize(o, L). By BDDSize  (L) :=
mino BDDSize(o, L) we denote the size of the BDD for an optimal variable ordering. Finding
such an optimal ordering is NP-hard (Bryant, 1986).
The state of the art ordering scheme in symbolic planning is based on the causal graph CG
of the planning task (Knoblock, 1994; Domshlak & Dinitz, 2001). CG is a directed graph with
nodes V and an arc (v, v 0 ) iff v 6= v 0 and there exists an action a  A such that (v, v 0 )  V(eff a ) 
V(pre a )  V(eff a ). In other words, we have an arc from v to v 0 if both appear as an effect of some
action or v appears in the precondition of an action that has v 0 in its effect.
783

fiK ISSMANN & H OFFMANN

Gamers scheme,
denoted ga , maps  to the set of orderings o = hv1 , . . . , vn i that minimize
P
the expression (vi ,vj )CG (i  j)2 . The idea is that variables vi , vj that are adjacent in the CG
are dependent and should be brought close together in the ordering by minimizing their distance
|i  j|. This bears some similarity to the minimal bandwidth variable ordering in CSPs (Zabih,
1990), though there the maximum of the distances is to be minimized, while we minimize the sum.
In practice, Gamer approximates ga by a limited amount of local search in the space of orderings,
as finding an optimal solution is NP-hard (Kissmann & Edelkamp, 2011). For this, it starts several
searches with a random ordering, swaps two variables and checks if the sum decreased. If it did,
the search continues with the new ordering, otherwise it will stick to the old one. In the end, the
generated ordering with the smallest sum is used. The original hope was that there is a connection
between the two notions of dependency. This was supported by the fact that the new ordering
resulted in improved coverage in the used benchmark set compared to what was used before.
Apart from ga , we also consider the scheme cg , which is only defined for an acyclic CG . It
maps  to the set of topological orderings of the nodes in CG . We consider this to be of theoretical
interest since it is the straightforward way to trust the causal graph completely, i.e., to take the
dependencies as derived from the causal graph and order the BDD variables accordingly.

3. Whats in a Causal Graph: Theory
As we have pointed out in the introduction, it is doubtful whether the concept of dependency in the
causal graph has any real relation with the concept of dependency relevant to BDD size. We now
frame this in terms of a classification of the guarantees offered, or rather, the guarantees not offered,
by ga and cg in restricted classes of planning tasks.
We first introduce our theoretical framework, then outline our results for cg and ga .
3.1 Classification Framework
We classify ordering schemes, relative to a given scalable family of planning tasks, as follows:
Definition 1 (Classification of Ordering Schemes). Let F = {n } be an infinite family of FDR
planning tasks parameterized by n, where the size of n is bounded by a polynomial in n. Let
d  {forward, backward} be a search direction. A variable ordering scheme  is:
(i) perfect in F for d if for all n  F, all d-layers L in n , and all o  (n ), we have
BDDSize(o, L) = BDDSize  (L).
(ii) safe in F for d if there exists a polynomial p s.t. for all n  F, all d-layers L in n , and all
o  (n ), we have BDDSize(o, L)  p(BDDSize  (L)).
(iii) viable in F for d if there exists a polynomial p s.t. for all n  F and all d-layers L in n ,
there exists o  (n ) with BDDSize(o, L)  p(BDDSize  (L)).
In other words, a perfect  guarantees to deliver only optimal orderings, a safe  guarantees
at most polynomial overhead, and a viable  always delivers at least one good ordering but runs
the risk of super-polynomial overhead. If  is not viable, then it actively deceives the planner, in
the sense that all variable orderings suggested are super-polynomially bad in some task and layer.
Note that our interpretation of viability is generous in that, while at least one good ordering
must be delivered, that ordering may differ for different search directions and layers, so that the
784

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

x

x1

x2

x3

x4

g1

x5

(a) Chains

g2

g4

g3

g5

(b) Forks

G chain
x1

x2

x3

x4

x5

G

G fork

G dag

G

G ifork

g

(d) Relations (arrows mean )

(c) Inverted Forks

Figure 2: Causal graph special cases and their relation.
disambiguation over (n ) is left with the job of determining which ordering actually is the good
one. One could define this notion more strictly, but as our results will be negative anyhow we stick
to this optimistic version.
We extend the classification to arbitrary sub-classes C of FDR (whose sizes still are bounded
by a polynomial) by the worst case over all families F contained in C: if C contains at least one F
where  is not perfect, then  is not perfect in C; if C contains at least one F where  is not safe,
then  is not safe in C; if C contains at least one F where  is not viable, then  is not viable in C.
As we are interested in variable orderings derived from the causal graph, it is natural to consider
sub-classes of FDR characterized by their causal graphs. For a set of directed graphs G, by FDR(G)
we denote the class of FDR planning tasks whose causal graphs are elements of G. We investigate
some widely considered causal graph special cases, namely:
 Chains (G chain ), where we can find an order x1 , . . . , xn of the variables so that there are only
arcs from each xi to xi+1 for 1  i  n  1 (cf. Figure 2a).
 Forks (G fork ), where we have one variable x, and a set of variables gi , with an arc from x to
each gi (cf. Figure 2b).
 Inverted forks (G ifork ), where we have a set of variables xi , and one variable g, with an arc
from each xi to g (cf. Figure 2c).
 Directed acyclic graphs (DAGs, G dag ).
As simple limiting cases, we also consider causal graphs without any arcs (G  ), as well as arbitrary
causal graphs (G  ). Figure 2d illustrates the relations between the cases considered.
Bad cases are inherited in the hierarchy of Figure 2d: if G  G 0 , then for any ordering scheme
the classification within FDR(G 0 ) is at least as bad as that in FDR(G), simply because the culprit
worst-case (not-perfect/not-safe/not-viable) family F of FDR planning tasks in FDR(G) will be
contained in FDR(G 0 ) as well.
3.2 Classification Results
We start our investigation with empty causal graphs, i.e., causal graphs with no arcs:
785

fiK ISSMANN & H OFFMANN

00

01

00

01

10

10

11

11

(a) DTG for variable x.

(b) DTG for variable y.

Figure 3: DTGs for the two variables of the planning task used in the proof of Theorem 1.
Theorem 1. For both search directions, any ordering scheme is safe in FDR(G  ). ga and cg are
not perfect.
Proof. If the causal graph has no arcs, then all variables move independently, i.e., each action
may have only a single variable in the precondition, and the same variable in the effect. So any
forward/backward layer with distance d contains exactly the states in which the sum of individual
distances (from a variables initial value/to a variables goal value) equals d. For any variable v of
the task, the number of vertices (more precisely, of copies of its binary counter (v)) needed is thus
bounded by the number of possible individual-distance sums of the variables preceding v. Hence
BDD size is polynomially bounded regardless of the variable ordering.
To see that ga and cg are not perfect, consider the following simple example. We design an
FDR task n that uses 2 variables x and y, each with a domain of size 4, represented by the values
00, 01, 10, and 11. For forward search, initially x = 00 and y = 00 holds. For the x variable we
have an action setting it to 01 if it is currently 00, another setting it to 10 from 00, and two setting it
to 11 from 01 or 10, respectively. For the y variable we have an action setting it to 01 if it is currently
00, another setting it from 01 to 10 and another setting it from 10 to 11. Thus, for the values of the
x variable we have distances of 0, 1, 1, and 2, respectively, from the initial value of x, and for the y
variable we have distances of 0, 1, 2, and 3, respectively, from ys initial value. Figure 3 illustrates
the domain transition graphs (DTGs) for variables x and y. A similar task having the same distances
to the goal values can be defined for backward search.
Each variable is represented by two BDD variables, x0 , x1 and y0 , y1 . If we keep the order
within the x and y variables fixed, we have two possible orderings: x before y or vice versa. For
a distance of 1 from the initial (or goal) state, we get the BDDs illustrated in Figure 4: Ordering
x before y results in a slightly larger BDD. Thus, ga and cg , which correspond to all possible
orderings, are not perfect, which concludes the proof.
Even though the schemes ga and cg do not constrain the set of possible orderings in any way,
Theorem 1 can be seen as a good case for the connection of causal graphs and BDD orderings:
Empty causal graphs entail that any ordering is safe. The connection doesnt seem to carry any
further than this trivial case, though: In all other sub-classes considered, the space of BDD orderings
contains exponentially bad ones. Indeed, that is true not only for the set of all BDD orderings, but
786

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

y0

x0

x1

x1

y0

y0

x0

x0

y1

y1

x1

x1

0

1

0

1

y1

(a) x before y.

(b) y before x.

Figure 4: BDDs showing that not all orderings are perfect in the proof of Theorem 1. Solid arrows
represent high edges, dashed ones low edges.
x1

x1

y1

x3

x2

x2

x3

x3

x3

y1

y1

y1

y2

y2

x3

y1

y2

y3

y3

0

x2

0

1

(a) Good variable ordering: hx1 , y1 , x2 , y2 , x3 , y3 i

1

(b) Bad variable ordering: hx1 , x2 , x3 , y1 , y2 , y3 i

Figure 5: BDDs with different variable orderings for Q(, ) with n = 3: (x1  y1 )  (x2  y2 ) 
(x3  y3 ). Solid arrows denote high edges, dashed ones low edges.
also for the subsets delivered by ga and cg . The classification of these schemes is very bad in
almost all considered cases, with a little bit of hope only for chain causal graphs.
Our negative results employ Boolean functions in quadratic form. These have the variables
{x1 , y1 , . . . , xn , yn }, and take the form (x1 oplow y1 )ophi . . . ophi (xn oplow yn ), where either ophi 
{, } and oplow = , or vice versa. We denote these functions by Q(ophi , oplow ). For each of
these functions, the ordering hx1 , y1 , . . . , xn , yn i (i.e., bringing pairs of xi and yi together) yields a
BDD whose size is polynomial in n, while the ordering hx1 , . . . , xn , y1 , . . . , yn i (i.e., splitting the
variables in two blocks, one with all x and one with all y variables) yields a BDD of exponential
size. (Wegener, 2000, proves this for Q(, ) as depicted in Figure 5; similar arguments apply for
the other quadratic forms.)

787

fiK ISSMANN & H OFFMANN

g

x1

x1

y1

y1

x2

g

x2

0

g

y2

y2

x3

x3

y3

y3

1

1

0

(a) g at the front.

g

(b) g within a pair.

Figure 6: BDDs representing g  Q(, ) with different positions of the g variable. Solid arrows
represent high edges, dashed ones low edges.
Theorem 2. For both search directions, ga and cg are not safe in FDR(G ifork ).
W
Proof. To prove the claim for backward search, consider the function Q(, ) = ni=1 (xi  yi ).
We design an FDR task n that uses 2n + 1 Boolean variables, {g, x1 , y1 , . . . , xn , yn } including an
additional variable g that the goal requires to be true. There are n actions achieving g, each of which
requires a pair (xi  yi ) to be true as the precondition. Clearly, Wn  FDR(G ifork ). The backward
layer with a distance of 1 from the goal is characterized by g  ni=1 (xi  yi ).
An optimal ordering for Q(, ) consists of pairs of (xi , yi ) or (yi , xi ). Adding the g variable,
an optimal ordering places it either at the front (as depicted in Figure 6a) or at the end. These cases
require exactly one node representing the g variable. Placing the g variable anywhere else requires
as many nodes representing g as there are nodes (different from the 0-sink) reached by edges passing
through that layer. In this case, there are two g nodes if g is placed between two pairs, and up to
three nodes if it is placed between two nodes constituting a pair (see Figure 6b for the latter case).
Any ordering following ga (n ) places g in the middle and the x and y variables in an arbitrary
order around it. Any ordering following cg (n ) places g at the end and the x and y variables in an
arbitrary order before it. In both cases, all x variables may be placed before all y variables, resulting
in an exponential overhead which concludes the proof for backward search.
For forward search, we consider the same function Q(, ), and construct n , which has the
same variables {g, x1 , y1 , . . . , xn , yn } but where the domains of {x1 , y1 , . . . , xn , yn } are ternary:
unknown, true (>), or false (). All x and y variables are initially unknown, and can be set to either
true or false if they are currently unknown. There are n actions achieving g, exactly as above. Then
in the states with initial state distance 2n + 1 all x and W
y variables are either true or false and the
states are exactly those that satisfy g  Q(, ) = g  ni=1 (xi = >)  (yi = >). As the causal
788

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

d1

x1

dx1

dy1

y1

dy2

y2

dyn

yn

d2

x2

dx2

d3

dn

xn

dxn

dn+1

Figure 7: DTG for variable z used in the proof of Theorem 3. The dashed edges correspond to
preconditions for changes in the value of the corresponding variable.
graph remains unchanged, the set of possible orderings following ga (n ) and cg (n ) remains
the same as in backward search as well, so that again some orders result in exponential overhead
which concludes the proof for forward search.
Note that, while the proof construction shows that some orders possible in ga and cg are
super-polynomially bad, other possible orders are good. Hence, while as claimed we prove that ga
and cg are not safe in FDR(G ifork ), it might be the case that ga and cg are viable in FDR(G ifork ).
We leave this as an open question.
Theorem 3. For both search directions, ga and cg are not safe in FDR(G fork ).
V
Proof. For both search directions, we use the same function Q(, ) = ni=1 (xi yi ), and the same
FDR task n with Boolean variables {x1 , y1 , . . . , xn , yn } plus an additional variable z with domain
{d1 , dx1 , dy1 , d2 , dx2 , dy2 , . . . , dn , dxn , dyn , dn+1 }. The actions are such that, for 1  i  n,
z can move from di to either dxi or dyi , and from each of these to di+1 (see Figure 7). An action
preconditioned on dxi achieves xi , an action preconditioned on dyi achieves yi . Initially, z = d1
and all xi , yi are false. The goal requires that z = dn+1 and all xi , yi are true. In forward search, the
states with initial state distance 3n are exactly those where z = dn+1 and Q(, ) is true, and in
backward search the states with goal state distance 3n are exactly those where z = d1 and Q(, )
is true.
Any ordering following ga (n ) places z in the middle and the x and y variables arbitrarily
around it; any ordering following cg (n ) places z at the beginning and the x and y variables
arbitrarily after it. Thus, there is no constraint on the variables {x1 , y1 , . . . , xn , yn }, so that placing
789

fiK ISSMANN & H OFFMANN

x1

x2

y1

x3

y2

y3

g

Figure 8: Causal graph for the planning task used in the proof of Theorem 4.
all x variables before all y variables is an ordering compatible with both schemes, and results in
exponential overhead.
Again, the proof shows that ga and cg are not safe, but makes no statement regarding viability.
Note also that the task in the proof construction is unsolvable. It is easy to modify the task to be
solvable without breaking the proof argument for the forward search direction. We did not investigate whether the same is true of the backward search direction as well. In practice, while proving
unsolvability has not traditionally been a popular objective in planning, state space exhaustion is
one of the traditional purposes BDDs are deemed to be good for.
For DAG causal graphs, we prove that there are cases where all orderings admitted by ga and
cg
 are super-polynomially bad:
Theorem 4. For both search directions, ga and cg are not viable in FDR(G dag ).
Proof. For the backward search claim, we use the combination of a chain causal graph and an
inverted fork as illustrated in Figure 8. We design an FDR task n that uses 2n + 1 Boolean
variables, {g, x1 , y1 , . . . , xn , yn }, including a variable g that the goal requires to be true. There are
n actions achieving g, each of which requires a pair (xi  yi ) to be true as the precondition (this
part of the task is the same as in the proof of Theorem 2). We add actions ensuring that in our two
schemes all x variables will be placed before all y variables (or vice versa). One action has an empty
precondition and sets x1 to true in its effect, another one requires xn to be true in the precondition
and sets y1 to true in its effect, the rest have xi1 (or yi1 ) in the precondition and set xi (or yi ) to
true in the effect. All states with a goal distance of 1 are thus characterized by g  Q(, ).
Any order induced by ga places g in the middle, and either places all x variables in increasing
order before g and all y variables in increasing order after g, or places all y variables in decreasing
order before g and all x variables in decreasing order after g. cg induces an order starting with
all x variables in increasing order, followed by all y variables in increasing order, followed by g.
Thus, in all cases, the x variables are placed separately from the y variables, resulting in exponential
overhead which proves the claim for the backward search direction.
For forward search we use the same approach as in the proof of Theorem 2, namely to extend
the domain of all x and y variables to {true (>), false (), unknown}. All x and y variables are
initialized to the value unknown. There are n actions setting g to true, all requiring a pair of (xi yi )
to be true. The additional actions are as follows. Two require x1 to be unknown and set it to true
or false, respectively. Two require xn to be true and y1 to be unknown and set y1 to true or false,
respectively. Two require xn to be false and y1 to be unknown and set y1 to true or false, respectively.
In the same manner we have four actions for each xi and yi (2  i  n), requiring xi1 (yi1 ) to be
true respectively false, and requiring xi (yi ) to be unknown, and setting xi (yi ) to true respectively
false. Thus, all states
W with an initial state distance of 2n + 1 can be characterized by the function
g  Q(, ) = g  ni=1 (xi = >)  (yi = >). The variable orders induced by ga and cg are the
same as in backward search, resulting in exponential overhead, concluding the proof.
790

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

x1

y1

y2

x2

y3

x3

Figure 9: Causal graph for the planning task used in the proof of Theorem 5.
x1

x1

y1

y1

x3

x2

y2

y2

y2

y1

y1

x2

x2

x3

x3

y1

x3

y1

y2

y3

y3

0

1

0

(a) Optimal ordering

x3

y1

y1

y2

y2

y3

y3

y1

y2

1

(b) Exponential ordering

W
L
Figure 10: BDDs representing 3i=1 yi  3i=1 (xi  yi ), as used in the proof of Theorem 5. Solid
arrows represent high edges, dashed ones low edges.
From this we immediately get (recall that cg is defined only for acyclic causal graphs):
Corollary 1. ga is not viable in FDR(G  ).
We close our investigation with a somewhat positive result for chain causal graphs:
Theorem 5. For both search directions, ga and cg are not perfect in FDR(G chain ). There exists
an ordering scheme that is not viable in FDR(G chain ).
Proof. The first part of the claim is inherited from FDR(G  ), i.e., as a corollary of Theorem 1.
For the second part of the claim, existence of a non-viableW
ordering scheme, we consider first
the backward search direction, using the function Q(, ) = ni=1 (xi  yi ). We design an FDR
task n that uses 2n Boolean variables, {x1 , y1 , . . . , xn , yn }. The goal requires all y variables to be
false. We have an action without precondition to set x1 to true, actions with preconditions requiring
yi1 to be false setting xi to true, and actions preconditioned on xi being true setting yi to false.
The causal graph is depicted in Figure 9. Clearly, n  FDR(G chain ).
The states with distance 1 from the goal are the ones where all except oneLyi are false, and for
n
the
single
true
Ln
Wn yi we have xi true as well. This is characterized by the formula i=1 yi  Q(, ) =
i=1 yi  i=1 (xi  yi ). It is easy to see that the exclusive or part of this formula does not change
the relevant properties of BDDs for the quadratic form, i.e., we still have orderings with polynomial
and other orderings with exponential number of nodes, e.g., those placing all x variables before all y
791

fiK ISSMANN & H OFFMANN

safe?
G chain
trivially
safe
G

not
viable
G dag

not safe
G fork

not
viable
G

not safe
G ifork

Figure 11: Overview of our classification results. These hold for each of ga and cg , and for each search
direction.

variables (see Figure 10 for illustration). Any ordering scheme including only such latter orderings
is not viable.
For the forward search direction case, we construct a planning task where all x and y variables
are ternary (unknown, true (>), false ()), and are unknown initially. The value of x1 can be set
freely; yi can be set to true or false if xi is true, and can only be set to true if xi is false; xi+1
can be set freely once yi has been set
V to either true or false. In 2n steps, we can reach exactly the
states characterized by Q(, ) = ni=1 (xi = >)  (yi = >). A BDD representing Q(, ) is of
exponential size if, e.g., all x variables are placed before all y variables, and any ordering scheme
including only such orderings is not viable.
Note that, for both planning task families {n } just described, both ga and cg and force the
xi and yi variable to be ordered in pairs, resulting in BDDs of minimal size (see Figure 10a). In that
sense, these two planning task families constitute our only truly positive result: Within them, the
ordering information in the causal graph keeps us from making exponentially bad mistakes. That
positive message would be much stronger if ga and cg were safe for all families of tasks with
chain causal graphs. It remains an open question whether that is so.
Figure 11 gives an overview of our results. The evidence speaks rather clearly against a strong
connection between causal graph dependencies and dependencies as relevant for BDD size. Note
that the causal graph underlying Theorem 4  non-viability for FDR(G dag )  has a very simple
form combining a chain with an inverted fork, and that Theorem 2  non-safety for FDR(G ifork ) 
relies on planning tasks which fall into a known syntactically identified tractable class for optimal
planning (Katz & Domshlak, 2010). Note also that being not safe already is quite bad in practice,
incurring an exponential risk unless we have a clever way of choosing an ordering within ()
(which, at the moment, we do not have).

4. Whats in a Causal Graph: Practice
While we have shown poor worst-case performance of causal graph based variable ordering schemes
in theory, practice might be another matter. To assess the latter, we implemented a comprehensive
set of causal graph based variable ordering schemes, comprising 12 such schemes in total, and ran
them in comparison to practical good/bad delimiters. As the bad delimiter, we used random
orderings. As the good delimiter, we used the off-the-shelf dynamic reordering algorithm of
Gamers BDD package CUDD, which is based on sifting (Rudell, 1993).
A few words are in order regarding how sifting works. The variable with the greatest number
of nodes in the current BDD is chosen. It is first moved towards the end of the ordering, then
792

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

towards the beginning of the ordering, by iteratively swapping its position with the next variable in
the corresponding direction. Once all positions have been tried, the variable is moved to the position
where the BDD size was smallest. This done, the next variable is chosen, until all variables have
been processed. For better comparability with our ordering schemes, we restrict the algorithm to
keep the variables representing each (v) together.
As previously indicated, dynamic reordering consumes too much runtime to be cost-effective.
In the present experiments, where we are interested only in BDD size, we give dynamic reordering ample runtime. In Section 5, we will identify simple adaptive criteria for stopping dynamic
reordering automatically during the search, taking advantage of its size reduction capacity without
suffering too much from its runtime consumption.
We ran the benchmarks of the 2011 International Planning Competition (IPC11), and we used
Gamer as the base implementation for all planners, running them on one core of an Intel Xeon
X5690 CPU with 3.47 GHz. Unless otherwise stated, we used the IPC11 settings, namely a timeout
of 30 minutes and a memory limit of 6 GB.
4.1 Ordering Schemes
We ran six schemes based directly on the causal graph:
Gamer is Gamers original ordering scheme, which approximates ga .
GamerPre is like Gamer but on a causal graph extended by arcs between pairs of precondition
variables. The idea here is to capture not only dependency for forward search, but also for
backward search, i.e., when inverting the actions.
WGamer is like Gamer but with arcs weighted by the number of relevant actions, i.e., the number
of actions inducing the corresponding arcs.
WGamerPre is like GamerPre with weighted arcs.
CGLevel is Fast Downwards (Helmert, 2006) level heuristic, which approximates cg . It orders
the variables by strongly connected components and, within these components, considers the
weighted causal graph and orders variables with smallest incoming weight first. Similar to
WGamer, the weights correspond to the number of actions that induce an arc.
CGSons is another approximation of cg . It always selects a variable v all of whose parents have already been selected; or at least one of whose parents has already been selected; or an arbitrary
variable if no such v exists.
Additionally, we used six ordering schemes we adopted from the model checking literature,
based on a structure called the abstract syntax tree (AST) (e.g., Maisonneuve, 2009). That is a
directed graph containing a root node for the overall task and subtrees for all actions. Each subtree
consists of nodes representing the subformulas of the specified action (i.e., subformulas for the
actions precondition and its effect). The variables of the task are the leaves of the AST. The leaves
are merged, i.e., we have only one node for each variable of the task. Edges point from a node
representing some function to all corresponding subtrees.
We construct the AST based on the PDDL input. Consider the following example actions, similar to those in the Floortile domain. We have predicates at(r, t), denoting the tile t robot r is
793

fiK ISSMANN & H OFFMANN

A

a2

a1







at(r1 , t1 )



painted (t2 )

at(r2 , t3 )

Figure 12: Example AST.
currently on and painted (t) denoting whether tile t has already been painted. We have two actions
a1 = paint(r1 , t1 , t2 ) with precondition (at(r1 , t1 )  painted (t2 )) and effect (painted (t2 )) denoting that a robot r1 can paint tile t2 if it currently is on t1 and t2 has not been painted. Similarly,
action a2 = paint(r2 , t3 , t2 ) with precondition (at(r2 , t3 )painted (t2 )) and effect (painted (t2 ))
denotes that robot r2 can paint tile t2 if it currently is on t3 and t2 has not been painted.
Figure 12 illustrates the corresponding AST. We have the root for all actions A, and one subtree
for each of the two actions a1 and a2 . For both actions the preconditions and effects are encoded
but we retain only one copy of each variable in the leaves (here relevant only for painted (t2 )).
Using their first authors names for reference, the additional ordering schemes are the following.
Butler (Butler, Ross, Kapur, & Mercer, 1991) is an extension of an approach by Fujita, Fujisawa,
and Kawato (1988). The latter proposed to perform a depth-first search (DFS) in the AST,
starting at the root node, and to order the variables in the order in which they are reached the
first time. Butler et al. extended this to a setting with several roots (if we remove the overall
root and retain only the subtrees for the various actions we arrive at exactly the same setting).
Their approach starts the DFS at the action containing the highest number of variables. Within
the tree it advances in a similar manner: It always continues with the subtree that contains the
highest number of variables among all subtrees of the current node. The retrieved ordering is
then again in the order in which the variables are reached the first time.
Chung1 (Chung, Hajj, & Patel, 1993) is a two-step approach. In the first step it assigns values
to all nodes of the AST. Starting at the leaves, assigning them a value of 0, it assigns each
inner node the maximum of the values assigned to its successors plus 1. In the second step it
performs a DFS starting at the root, which is guided by the values of the nodes, visiting those
successors with highest value first. The order in which the variables are reached for the first
time is then chosen as the variable ordering.
Chung2 (Chung et al., 1993) determines the shortest distance between each pair of variables, which
can be calculated by considering all edges in the AST as undirected. Additionally, the total
distances, i.e., the sum of the minimal distances to all other variables, are stored for all variables. A variable with smallest total distance is chosen first. The next one is the one closest
794

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

to the last variable inserted into the ordering. In case of a tie the distance to the preceding
variables is also taken into account.
Maisonneuve (Maisonneuve, 2009) is a greedy approach starting with an empty sequence. In each
step it temporarily extends the current sequence by a variable not yet in the sequence. For
this variable, a weight is determined, which is the number of variables from this extended
sequence that appear in an action, summed over all actions. The variable is then removed
from the sequence and the next one added. When all weights are calculated the variable with
highest weight is appended to the sequence, and the next iteration starts, calculating the new
weights for the remaining variables. In the end, the last sequence contains all variables and
thus corresponds to the variable ordering.
Malik (Malik et al., 1988) assigns a level value (the maximal level of all its predecessors plus 1)
to each node within the AST. The root is assigned value 0. The variables are then ordered
according to their level values, those with highest values coming first.
Minato (Minato et al., 1990) calculates weights for all nodes in the AST. The weight of the root
node of each action is set to 1, that of all successors of a node to w/m if w is the nodes weight
and m the number of successors of that node. One of the variables with highest weight is then
chosen first and all its nodes removed (along with all ingoing edges and  recursively  those
nodes with no remaining successors). For the reduced graph the weights are recalculated and
the procedure continues until finally all variables are in the ordering.
4.2 Bad Delimiter
To get the bad delimiter we ran 5000 random orderings, where each such ordering corresponds
to one run of the IPC11 benchmark tasks, using a random variable ordering for each instance. To
make this feasible we used a time-out of one minute (our backward search implementation is not
viable for such a short time-out, so that we use only forward search here). For comparison to this
data, the same settings (1 minute time-out, only forward search) was used with the twelve static
ordering schemes. Initially we ran all ordering schemes and the random orderings on all tasks; after
200 random runs we removed all tasks from the benchmark set that were not solved at least once
during the previous (random or static ordering) runs, retaining 85 tasks. Figure 13 shows coverage,
i.e., the number of solved planning tasks, on the x axis, and the fraction of random orderings having
that coverage on the y axis. The coverage data for the ordering schemes are shown as vertical lines.
Malik and CGLevel lie in and below the middle of the Gaussian distribution, respectively. In
other words, Malik is as bad as, and CGLevel is even worse than, the average random ordering.
Matters are not as bleak for the other ten ordering schemes, which are close together and lie clearly
above the Gaussian distribution. Compared to a best-of over the random orders, however, all the
ordering schemes appear rather humble. Consider Table 1. In particular, consider nr
+ , giving the
number of instances solved by ordering scheme  but not by any random order, and consider n+r
 ,
giving the number of instances not solved by the scheme but solved by some random order. As
+r
Table 1 shows, nr
+ is strictly smaller than n in all but three of the ordering schemes , and is
strictly larger (by a single task) only for one of the schemes (namely Butler). The average over nr
+
is 2.92 while that over n+r
is
9.08.

795

fiK ISSMANN & H OFFMANN

Percentage of Random Orderings

16

CGLevel
Malik
Maisonneuve+WGamerPre
Minato+WGamer
CGSons
Gamer+GamerPre
Chung1+Chung2
Butler

14
12
10
8
6
4
2
0
20

30

40

50
Coverage

60

70

80

Type

Butler

CGLevel

CGSons

Chung1

Chung2

Gamer

GamerPre

Maisonneuve

Malik

Minato

WGamer

WGamerPre

Best Scheme

Figure 13: Coverage for random orders vs. ordering schemes. Schemes are ordered top-to-bottom
from worst to best coverage. X +Y means that both schemes, X and Y , result in the same coverage.

nr
+
n+r

n+r
+
nr


3
2
77
3

1
26
53
5

2
4
75
4

4
4
75
2

2
2
77
4

5
6
73
1

5
6
73
1

3
11
68
3

0
22
57
6

4
8
71
2

3
7
72
3

3
11
68
3

6
1
78
0

Table 1: Differences in solved instances for the 85 IPC11 tasks (1 minute timeout); r means
solved by no random ordering, +r by at least one random ordering,  not solved by the corresponding ordering scheme, + solved by the corresponding ordering scheme.
4.3 Good Delimiter
Here we performed bidirectional blind search, i.e., the most competitive setup in general. Figure 14
contains one data point for every pair (I, ) of IPC11 benchmark instance I and ordering scheme
 that were solved by both (a) Gamer using dynamic reordering starting from an arbitrary variable
order (the one returned by Gamers grounding process), and (b) Gamer using ordering scheme 
(without dynamic reordering). The time-out is 6 hours for (a), and 30 minutes for (b). The x-value
of each data point is the size of the largest BDD constructed for I by (a), the y-value is the size of the
largest BDD constructed for I by (b). We allowed a much higher time-out for dynamic reordering
because such reordering is not runtime effective: The question we are asking here is merely which
of the two methods yields smaller BDDs. Figure 14 shows that dynamic reordering is universally
much better at this, giving us sizes that are up to three orders of magnitude smaller than those of the
schemes. For a total of 1911 instances (solved by both an ordering scheme and dynamic reordering),
in 1431 cases the BDD sizes are smaller by a factor of up to 10 when using dynamic reordering, in
796

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

Peak Size Ordering Schemes

108
107
106
105
104
104

105
106
Peak Size Dynamic Reordering

107

108

Dynamic
Reordering

WGamerPre

WGamer

Minato

Malik

Maisonneuve

GamerPre

Gamer

Chung2

Chung1

CGSons

CGLevel

Butler

Figure 14: BDD size for dynamic reordering vs. ordering schemes.

Domain
Barman
4
4
4
4
8
8
7
4
4
4
5
4
9(5)
Elevators 19 19 19 19 19 19 19 19 19 19 19 19
19(17)
Floortile
8
8
7
8
8
8
8
7
7
8
8
8
7(6)
14(12)
NoMystery 14 14 14 14 14 13 14 14 15 14 14 14
Openstacks 20 18 20 20 20 20 20 19 19 19 20 20
20(20)
PARC-Printer
6
6
5
6
5
6
6
6
5
6
6
7
8(7)
PegSol 17 17 17 17 17 18 18 17 17 17 18 18
18(17)
Scanalyzer
8
7
9
9
8
9
9
9
9
9
9
7
9(9)
Sokoban 17 18 18 17 19 19 19 18 18 18 19 19
19(13)
Tidybot 16
7 14 15 15
9 12 14
9 15 12
8
16(8)
Transport
8
9
9
7
8
8
8
9
7
9
7
7
10(7)
9 11 11 11 11 11 11 10 10 11 11
12(11)
VisitAll 11
Woodworking 16 13 10 14 16 16 16 12
8 16 15 16
19(16)
Total (260) 164 149 157 161 168 164 167 159 147 164 163 158 180(148)

Table 2: Coverage in the IPC11 tasks. For dynamic reordering, the numbers in parentheses represent the coverage with a 30 minute timeout.
406 cases they are smaller by a factor between 10 and 100, and in 20 cases they are smaller by a
factor of more than 100.
Table 2 shows the coverage of the different schemes on the IPC11 tasks. We can make a
similar observation to that of the one minute, only forward search results, namely that CGLevel
and Malik are clearly behind the others. The last column shows the coverage of Gamer using
dynamic reordering, and provides two numbers, first the coverage with the 6 hours timeout, second
the coverage with the same timeout as the schemes, i.e., 30 minutes. From this it becomes clear that
applying dynamic reordering for the entire search time is not feasible in practice when limiting the
runtime.
797

fi600
500
400
300
200
100
0

Total Runtime
Reordering Time
Transition Relation Creation

0

2

4

6
8
Reorderings

Time (s)

Time (s)

K ISSMANN & H OFFMANN

10

12

1400
1200
1000
800
600
400
200
0

Total Runtime
Reordering Time
Transition Relation Creation

0

(a) VisitAll, task 011

2

4

6
8 10
Reorderings

12

14

16

(b) PegSol, task 015

Figure 15: Total runtime and time spent in reordering for limited number of reordering steps for two
example IPC11 tasks. All reorderings until the vertical line were performed during the transition
relation creation.

5. Limited Dynamic Reordering
Given the much more memory-efficient behavior of dynamic reordering, a possible approach is
to run dynamic reordering for a limited time only, hoping to get an ordering that is good enough
for the remainder of the search. Reordering is automatically started when the number of allocated
BDD nodes reaches a certain threshold (by default, the first threshold is 4000 nodes), which is
dynamically adapted after each reordering (by default, the next threshold is set to 2 times the number
of nodes after reordering). A simple way to control dynamic reordering is to limit the number of
reordering steps, and to turn dynamic reordering off once the desired number of reorderings has
been performed.
For different reordering limits, the total runtime for a task often looks similar to the situation
depicted in Figure 15a. With too few reorderings it takes a long time to solve the task due to a
bad initial ordering. Also, the first reorderings can sometimes hurt, as they are performed at the
very beginning or during construction of the transition relation, before enough information on good
orderings is available. However, with too many reorderings solving takes a long time due to an
immense overhead in reordering time, which grows exponentially with each step.
An important different behavioral pattern is depicted in Figure 15b: In some domains, such as
PegSol or Sokoban, the minimum of the curve is at the very beginning (without any reordering),
and the total runtime only increases afterward (mainly based on the increase in reordering time).
An explanation for this behavior might be that the initial ordering is already pretty good, so that
dynamic reordering cannot improve much and its overhead is incurred in vain. The same also often
happens in the easier tasks of a domain, so that learning a good setting based on the simpler tasks
seems impossible.
Attempting to exploit these observations to design adaptive stopping criteria, geared at finding
a good point for stopping dynamic reordering, given only the available observations (e.g., number
of BDD nodes before/after reordering, reordering times, current total runtimes), we experimented
with the following approaches.
First, we noticed that early on the reordering time increases from step to step by a small factor,
but later on that factor increases. In some preliminary runs we saw that often the area of smallest
runtime coincides with the situation when the increase in reordering time reaches some threshold,
often between 1.25 and 1.75 (see, e.g., Figure 16a and compare it to the runtime minimum in
Figure 15a for the same planning task). We call this the factor criterion.
798

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

2.5

Factor
Percentage

Factor

2
1.5
1
0.5
0
0

2

4

6
8
10
12
Reorderings
(a) Factor of the time for the last reordering and
the previous one.

70
60
50
40
30
20
10
0

Percentage

0

2

4

6
8
10
12
Reorderings
(b) Percentage of the time for the last reordering
of the total runtime so far.

Figure 16: Factor and percentage criterion for limited number of reordering steps for task 011 of
the IPC11 VisitAll domain.
Second, another observation from these preliminary runs is that the percentage of the time spent
in the last reordering step on the total current runtime often follows a U-like curve, and the minimum
of that curve often lies close to the same number of reorderings as the total runtime minimum (see,
e.g., Figure 16b and compare to the runtime minimum in Figure 15a for the same task). We employ
a percentage criterion, which stops reordering after a (possibly local) minimum has been reached,
i.e., we compare the percentage of the current step with that of the previous step; when the current
one is greater we stop reordering.
Finally, A simple combination of both criteria is to stop reordering as soon as one of them tells
us to do so.
To evaluate these adaptive stopping criteria, we ran all tasks of the IPC11 domains with different limits for the number of reorderings, ranging from 0 to 20.1 Based on those runs we calculated
the results we would achieve with the adaptive stopping criteria. See Table 3. The best possible
coverage, i.e., the number of tasks solved by at least one setting with limited number of reorderings,
is 175, while without any reordering we found 167 solutions. The adaptive stopping criteria yield
coverage between 158 and 171. Performance is reasonable for the factor criterion, but is quite bad
for the percentage criterion and the combination of both criteria. Recall that the percentage criterion aims at stopping reordering before incurring prohibitive overhead. Indeed, with this criterion,
reordering is often stopped earlier than with the factor criterion. In some cases this was detrimental,
particularly in the Woodworking domain where this strategy happens to fall into a dramatic local
peak of the total-runtime curve, resulting in 9 problem instances no longer being solved.
As, in several cases, dynamic reordering during the transition relation creation was counterproductive, we also ran delayed reordering, where dynamic reordering is started only after the BDDs
for the transition relation have been created. The results are in Table 4. The case without reordering
is unchanged with respect to Table 3. The best possible result is now slightly worse than before,
with coverage 174. For the adaptive stopping criteria, the picture changes substantially: In contrast
to Table 3, the percentage criterion now excels, delivering coverage just 1 short of the best possible.
Regarding the factor criteria, overly small or large factors now are bad and the best behavior (2 short
of best possible) is obtained in the middle.
1. In all those cases the highest number of reorderings we could observe was clearly below 20. Either the planner ran
out of time or memory, or finished before the last reorderings could be performed. In all cases we used GamerPre as
the initial ordering, which turned out to be among the best in a preliminary set of experiments.

799

fiK ISSMANN & H OFFMANN

Domain
Barman
Elevators
Floortile
NoMystery
Openstacks
PARC-Printer
PegSol
Scanalyzer
Sokoban
Tidybot
Transport
VisitAll
Woodworking
Total

no
reord
7
19
8
14
20
6
18
9
19
12
8
11
16
167

best
possible
8
19
8
16
20
7
18
9
19
14
9
12
16
175

1.25
8
19
7
14
20
6
17
9
17
14
9
11
10
161

factor criterion
1.5 1.75 2.0
8
8
8
19
19
19
8
8
8
14
14
14
20
20
20
6
7
7
17
17
18
9
9
9
17
17
17
14
14
14
9
9
9
12
12
12
15
16
16
168 170 171

percentage
criterion
8
19
8
14
20
6
17
9
17
13
9
11
7
158

1.25
8
19
7
14
20
6
17
9
17
13
9
11
9
159

both criteria
1.5 1.75
8
8
19
19
8
8
14
14
20
20
6
6
17
17
9
9
17
17
13
13
9
9
11
11
7
7
158 158

2.0
8
19
8
14
20
6
17
9
17
13
9
11
7
158

Table 3: Coverage results for different stopping criteria. Immediate reordering.

Domain
Barman
Elevators
Floortile
NoMystery
Openstacks
PARC-Printer
PegSol
Scanalyzer
Sokoban
Tidybot
Transport
VisitAll
Woodworking
Total

no
reord
7
19
8
14
20
6
18
9
19
12
8
11
16
167

best
possible
8
19
8
16
20
7
18
9
19
13
9
12
16
174

1.25
8
19
7
16
20
6
17
9
19
13
9
12
10
165

factor criterion
1.5 1.75 2.0
8
8
7
19
19
19
8
8
8
16
14
14
20
20
20
7
7
6
17
17
17
9
9
9
19
19
19
13
13
13
9
9
9
12
12
12
15
16
16
172 171 169

percentage
criterion
8
19
8
16
20
7
17
9
19
13
9
12
16
173

1.25
8
19
7
16
20
6
17
9
19
13
9
12
10
165

both criteria
1.5 1.75
8
8
19
19
8
8
16
16
20
20
7
7
17
17
9
9
19
19
13
13
9
9
12
12
15
16
172 173

2.0
8
19
8
16
20
7
17
9
19
13
9
12
16
173

Table 4: Coverage results for different stopping criteria. Delayed reordering, i.e., reordering started
only after creation of the transition relation BDDs.
To shed some light on these observations, Figure 17 shows coverage as a function of more
different factor values, for both the case of immediate reordering (Figure 17a) and that of delayed
reordering (Figure 17b). In Figure 17a, we see that the percentage criterion stops reordering too
early. Without it, the coverage resulting from stopping reordering based solely on the factor criterion
can get as high as 173. However, before the ascend in the coverage actually starts the percentage
criterion stops reordering, thus cutting off many solutions. In Figure 17b, up to a factor of 1.6
both curves are identical, both mainly increasing with increasing factor. After that, the combination
criterion rises another little bit, while the factor criterion alone drops substantially. The combined
criterion avoids that drop because, at some point (here, at a factor of roughly 2.0), the percentage
criterion stops reordering at least as early as the factor criterion.
800

fi180
175
170
165
160
155
150

Factor
Both
Coverage

Coverage

BDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

0

0.5

1

1.5
2
Factor
(a) Immediate reordering.

2.5

3

180
175
170
165
160
155
150

Factor
Both

0

0.5

1

1.5
2
Factor
(b) Delayed reordering.

2.5

3

Figure 17: Coverage as a function of factor, for the factor criterion alone, and for its combination
with the percentage criterion (denoted as Both).

6. Conclusion
It is tempting to equate the variable dependencies in BDD-based symbolic search with those
identified in causal graphs, and previous research has done so unquestioningly. Looking a little more
closely at this issue, we have shown that causal graph based variable orderings are exponentially bad
even in severely restricted sub-classes of planning. Empirically, Fast Downwards level heuristic is
worse than random, and all ordering schemes lag far behind off-the-shelf reordering.
One may wonder about the meaning of the theoretical results: How could a static ordering
scheme not incur exponential overhead in the worst case? We agree with that view in principle,
but we did not expect this to happen in planning tasks so restricted as to be tractable for domainindependent optimal planning. It remains to be seen to what extent our classification framework is
suitable to characterize the properties of other ordering schemes and/or planning fragments.
Our impression at this point is that static ordering schemes are so limited as to be hopeless.
Prior to actually building the BDDs, it appears impossible to extract any reliable information about
which form they will take. The way forward, then, is to use dynamic reordering techniques in a
more targeted manner. Our initial experiments in that direction did not meet with an immediate
breakthrough, but certainly they show promise, especially considering the primitive nature of the
method and of the stopping criteria employed. Promising future directions include more flexible
on/off strategies for dynamic reordering, machine learning for deciding when to toggle the switch,
and planning-specific reordering techniques exploiting the particular structure of the BDDs at hand.

Acknowledgments
We thank the anonymous reviewers of the ICAPS 2013 short version and those of a previous version
of this article, whose comments helped tremendously to improve the paper.

References
Brafman, R., & Domshlak, C. (2003). Structure and complexity in planning with unary operators.
Journal of Artificial Intelligence Research, 18, 315349.
Bryant, R. E. (1986). Graph-based algorithms for boolean function manipulation. IEEE Transactions on Computers, 35(8), 677691.
801

fiK ISSMANN & H OFFMANN

Burch, J. R., Clarke, E. M., & Long, D. E. (1991). Symbolic model checking with partitioned
transition relations. In Halaas, A., & Denyer, P. B. (Eds.), Proceedings of the International
Conference on Very Large Scale Integration (VLSI-91), Vol. A-1 of IFIP Transactions, pp.
4958, Edinburgh, Scotland. North-Holland.
Burch, J. R., Clarke, E. M., Long, D. E., McMillan, K. L., & Dill, D. L. (1994). Symbolic model
checking for sequential circuit verification. IEEE Transactions on Computer-Aided Design of
Integrated Circuits and Systems, 13(4), 401424.
Butler, K. M., Ross, D. E., Kapur, R., & Mercer, M. R. (1991). Heuristics to compute variable
orderings for efficient manipulation of ordered binary decision diagrams. In Proceedings
of the 28th Conference on Design Automation (DAC-91), pp. 417420, San Francisco, CA,
USA. ACM.
Chen, H., & Gimenez, O. (2010). Causal graphs and structurally restricted planning. Journal of
Computer and System Sciences, 76(7), 579592.
Chung, P.-Y., Hajj, I. N., & Patel, J. H. (1993). Efficient variable ordering heuristics for shared
ROBDD. In Proceedings of the 1993 IEEE International Symposium on Circuits and Systems
(ISCAS-93), pp. 16901693, Chicago, IL, USA. IEEE.
Cimatti, A., Pistore, M., Roveri, M., & Traverso, P. (2003). Weak, strong, and strong cyclic planning
via symbolic model checking. Artificial Intelligence, 147(12), 3584.
Darwiche, A. (2011). SDD: A new canonical representation of propositional knowledge bases. In
Walsh, T. (Ed.), Proceedings of the 22nd International Joint Conference on Artificial Intelligence (IJCAI11), pp. 819826. AAAI Press/IJCAI.
Dechter, R., & Meiri, I. (1989). Experimental evaluation of preprocessing techniques in constraint
satisfaction problems. In Sridharan, N. S. (Ed.), Proceedings of the 11th International Joint
Conference on Artificial Intelligence (IJCAI-89), pp. 271277, Detroit, MI. Morgan Kaufmann.
Domshlak, C., & Dinitz, Y. (2001). Multi-agent offline coordination: Structure and complexity. In
Cesta, A., & Borrajo, D. (Eds.), Recent Advances in AI Planning. 6th European Conference
on Planning (ECP-01), Lecture Notes in Artificial Intelligence, pp. 3443, Toledo, Spain.
Springer-Verlag.
Edelkamp, S., & Helmert, M. (1999). Exhibiting knowledge in planning problems to minimize
state encoding length. In Biundo, S., & Fox, M. (Eds.), Recent Advances in AI Planning.
5th European Conference on Planning (ECP99), Lecture Notes in Artificial Intelligence, pp.
135147, Durham, UK. Springer-Verlag.
Fan, G., Muller, M., & Holte, R. (2014). Non-linear merging strategies for merge-and-shrink based
on variable interactions. In Edelkamp, S., & Bartak, R. (Eds.), Proceedings of the 7th Annual
Symposium on Combinatorial Search (SOCS14). AAAI Press.
Freuder, E. C. (1982). A sufficient condition for backtrack-free search. Journal of the Association
for Computing Machinery, 29(1), 2432.
Fujita, M., Fujisawa, H., & Kawato, N. (1988). Evaluation and improvements of boolean comparison method based on binary decision diagrams. In Proceedings of the 1988 International
Conference on Computer-Aided Design (ICCAD-98), pp. 25. IEEE Computer Society Press.
802

fiBDD O RDERING H EURISTICS FOR C LASSICAL P LANNING

Gimenez, O., & Jonsson, A. (2008). The complexity of planning problems with simple causal
graphs. Journal of Artificial Intelligence Research, 31, 319351.
Helmert, M. (2004). A planning heuristic based on causal graph analysis. In Koenig, S., Zilberstein,
S., & Koehler, J. (Eds.), Proceedings of the 14th International Conference on Automated
Planning and Scheduling (ICAPS04), pp. 161170, Whistler, Canada. Morgan Kaufmann.
Helmert, M. (2006). The Fast Downward planning system. Journal of Artificial Intelligence Research, 26, 191246.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics for optimal sequential planning. In Boddy, M., Fox, M., & Thiebaux, S. (Eds.), Proceedings of the 17th
International Conference on Automated Planning and Scheduling (ICAPS07), pp. 176183,
Providence, Rhode Island, USA. Morgan Kaufmann.
Helmert, M., Haslum, P., Hoffmann, J., & Nissim, R. (2014). Merge & shrink abstraction: A method
for generating lower bounds in factored state spaces. Journal of the Association for Computing Machinery, 61(3).
Hoffmann, J. (2011a). Analyzing search topology without running any search: On the connection
between causal graphs and h+ . Journal of Artificial Intelligence Research, 41, 155229.
Hoffmann, J. (2011b). Where ignoring delete lists works, part II: Causal graphs. In Bacchus, F.,
Domshlak, C., Edelkamp, S., & Helmert, M. (Eds.), Proceedings of the 21st International
Conference on Automated Planning and Scheduling (ICAPS11), pp. 98105. AAAI Press.
Jonsson, P., & Backstrom, C. (1995). Incremental planning. In European Workshop on Planning.
Katz, M., & Domshlak, C. (2008). New islands of tractability of cost-optimal planning. Journal of
Artificial Intelligence Research, 32, 203288.
Katz, M., & Domshlak, C. (2010). Implicit abstraction heuristics. Journal of Artificial Intelligence
Research, 39, 51126.
Kissmann, P., & Edelkamp, S. (2011). Improving cost-optimal domain-independent symbolic planning. In Burgard, W., & Roth, D. (Eds.), Proceedings of the 25th National Conference of the
American Association for Artificial Intelligence (AAAI-11), pp. 992997, San Francisco, CA,
USA. AAAI Press.
Kissmann, P., & Hoffmann, J. (2013). Whats in it for my BDD? On causal graphs and variable orders in planning. In Borrajo, D., Fratini, S., Kambhampati, S., & Oddi, A. (Eds.), Proceedings
of the 23rd International Conference on Automated Planning and Scheduling (ICAPS13), pp.
327331, Rome, Italy. AAAI Press.
Knoblock, C. (1994). Automatically generating abstractions for planning. Artificial Intelligence,
68(2), 243302.
Maisonneuve, V. (2009). Automatic heuristic-based generation of MTBDD variable orderings for
PRISM models. Internship report, Oxford University Computing Laboratory.
Malik, S., Wang, A., Brayton, R., & Sangiovanni-Vincentelli, A. (1988). Logic verification using
binary decision diagrams in a logic synthesis environment. In Proceedings of the 1988 International Conference on Computer-Aided Design (ICCAD-98), pp. 69. IEEE Computer
Society Press.
803

fiK ISSMANN & H OFFMANN

McMillan, K. L. (1993). Symbolic Model Checking. Kluwer Academic Publishers.
Minato, S., Ishiura, N., & Yajima, S. (1990). Shared binary decision diagram with attributed edges
for efficient boolean function manipulation. In Proceedings of the 27th ACM/IEEE Design
Automation Conference (DAC-90), pp. 5257, Orlando, FL, USA. IEEE Computer Society
Press.
Moskewicz, M., Madigan, C., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering an
efficient SAT solver. In Proceedings of the 38th Conference on Design Automation (DAC01), Las Vegas, Nevada, USA. IEEE Computer Society.
Rintanen, J. (2012). Planning as satisfiability: Heuristics. Artificial Intelligence, 193, 4586.
Rudell, R. (1993). Dynamic variable ordering for ordered binary decision diagrams. In Lightner,
M. R., & Jess, J. A. G. (Eds.), Proceedings of the 1993 IEEE/ACM International Conference
on Computer-Aided Design (ICCAD-93), pp. 4247, Santa Clara, CA, USA. IEEE Computer
Society.
Sievers, S., Wehrle, M., & Helmert, M. (2014). Generalized label reduction for merge-and-shrink
heuristics. In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI14),
Quebec City, Quebec, Canada. AAAI Press.
Wegener, I. (2000). Branching Programs and Binary Decision Diagrams. SIAM.
Williams, B. C., & Nayak, P. P. (1997). A reactive planner for a model-based executive. In Pollack,
M. (Ed.), Proceedings of the 15th International Joint Conference on Artificial Intelligence
(IJCAI-97), pp. 11781185, Nagoya, Japan. Morgan Kaufmann.
Zabih, R. (1990). Some applications of graph bandwidth to constraint satisfaction problems. In
Proceedings of the 8th National Conference of the American Association for Artificial Intelligence (AAAI-90), pp. 4651, Boston, MA. MIT Press.

804

fiJournal of Artificial Intelligence Research 51 (2014)

Submitted 04/14; published 10/14

Verification of Agent-Based Artifact Systems
Francesco Belardinelli

BELARDINELLI @ IBISC . FR

Laboratoire Ibisc, Universite dEvry, France

Alessio Lomuscio

A . LOMUSCIO @ IMPERIAL . AC . UK

Department of Computing, Imperial College London, UK

Fabio Patrizi

FABIO . PATRIZI @ DIS . UNIROMA 1. IT

Dipartimento di Ingegneria Informatica,
Automatica e Gestionale A. Ruberti
Universita di Roma La Sapienza, Italy

Abstract
Artifact systems are a novel paradigm for specifying and implementing business processes described in terms of interacting modules called artifacts. Artifacts consist of data and lifecycles, accounting respectively for the relational structure of the artifacts states and their possible evolutions
over time. In this paper we put forward artifact-centric multi-agent systems, a novel formalisation
of artifact systems in the context of multi-agent systems operating on them. Differently from the
usual process-based models of services, we give a semantics that explicitly accounts for the data
structures on which artifact systems are defined.
We study the model checking problem for artifact-centric multi-agent systems against specifications expressed in a quantified version of temporal-epistemic logic expressing the knowledge
of the agents in the exchange. We begin by noting that the problem is undecidable in general.
We identify a noteworthy class of systems that admit bisimilar, finite abstractions. It follows that
we can verify these systems by investigating their finite abstractions; we also show that the corresponding model checking problem is EXPSPACE-complete. We then introduce artifact-centric
programs, compact and declarative representations of the programs governing both the artifact system and the agents. We show that, while these in principle generate infinite-state systems, under
natural conditions their verification problem can be solved on finite abstractions that can be effectively computed from the programs. We exemplify the theoretical results here pursued through a
mainstream procurement scenario from the artifact systems literature.

1. Introduction
Much of the work in the area of reasoning about knowledge involves the development of formal
techniques for the representation of epistemic properties of rational actors, or agents, in a multiagent system (MAS). The approaches based on modal logic are often rooted on interpreted systems (Parikh & Ramanujam, 1985), a computationally grounded semantics (Wooldridge, 2000)
used for the interpretation of several temporal-epistemic logics. This line of research was thoroughly explored in the 1990s leading to a significant body of work (Fagin, Halpern, Moses, &
Vardi, 1995; Meyer & van der Hoek, 1995). A recent topic of interest has been the development
of automatic techniques, including model checking (Clarke, Grumberg, & Peled, 1999), for the
verification of temporal-epistemic specifications for the autonomous agents in a MAS (Gammie &
van der Meyden, 2004; Lomuscio, Qu, & Raimondi, 2009; Kacprzak, Nabialek, Niewiadomski,
Penczek, Polrola, Szreter, Wozna, & Zbrzezny, 2008). This has led to developments in a number
of areas traditionally outside artificial intelligence, knowledge representation and MAS, including

c
2014
AI Access Foundation. All rights reserved.

fiB ELARDINELLI , L OMUSCIO & PATRIZI

security (Dechesne & Wang, 2010; Ciobaca, Delaune, & Kremer, 2012), web-services (Lomuscio,
Penczek, Solanki, & Szreter, 2011) and cache-coherence protocols in hardware design (Baukus &
van der Meyden, 2004). The ambition of the present paper is to offer a similar change of perspective
in the area of artifact systems (Cohn & Hull, 2009), a growing topic in Service-Oriented Computing
(SOC).
Artifacts are structures that combine data and process in an holistic manner as the basic building
block[s] (Cohn & Hull, 2009) of systems descriptions. Artifact systems are services constituted by
complex workflow schemes based on artifacts which the agents interact with. The data component
is given by the relational databases underpinning the artifacts in a system, whereas the workflows
are described by lifecycles associated with each artifact schema. While in the standard service
paradigm services are made public by exposing their process interfaces, in artifact systems both the
data structures and the lifecycles are advertised. Services are composed in a hub where operations on the artifacts are executed. Implementations of artifact systems, such as the IBM engine
BARCELONA (Heath et al., 2013), provide a hub where service choreography and service orchestration (Alonso, Casati, Kuno, & Machiraju, 2004) are carried out.
Artifact systems are beginning to drive new application areas, such as case management systems (Marin, Hull, & Vaculn, 2013). However, we identify two shortcomings in the present stateof-the-art. Firstly, the artifact systems literature (Bhattacharya, Gerede, Hull, Liu, & Su, 2007;
Deutsch, Hull, Patrizi, & Vianu, 2009; Hull, 2008; Nooijen, Fahland, & Dongen, 2013) focuses
exclusively on the artifacts themselves. While there is obviously a need to model and implement the
artifact infrastructure, in order to be able to reason comprehensively about artifact systems, there
is also a need to account for the agents implementing the services in the system, as it is normally
done in the area of reasoning about services (Baresi, Bianculli, Ghezzi, Guinea, & Spoletini, 2007).
Secondly, there is a pressing demand to provide the hub with automatic choreography and orchestration capabilities. It is well-known that choreography techniques can be leveraged on automatic
model checking techniques; orchestration can be recast as a synthesis problem, which, in turn, can
also benefit from model checking technology. However, while model checking and its applications
are relatively well-understood in plain process-based modelling, the presence of data makes these
problems much harder and virtually unexplored. Additionally, infinite domains in the underlying
databases lead to infinite state-spaces and undecidability of the model checking problem.
The aim of this paper is to make a concerted contribution to both problems above. Firstly,
we provide a computationally grounded semantics to systems comprising the artifact infrastructure
and the agents operating on it. We use this semantics to interpret a temporal-epistemic language
with first-order quantifiers to reason about the evolution of the hub as well as the knowledge of the
agents in the presence of evolving, structured data. We observe that the model checking problem for
these structures is undecidable in general and analyse a notable decidable fragment. For these we
derive finite abstractions to infinite-state artifact systems, thereby presenting a technique for their
effective verification. We evaluate this methodology by studying its computational complexity and
by demonstrating its use on a well-known scenario from the artifact systems literature.
1.1 Artifact-Centric Systems
Service-oriented computing is concerned with the study and development of distributed applications that can be automatically discovered and composed by means of remote interfaces. A point of
distinction over more traditional distributed systems is the interoperability and connectedness of ser-

334

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

vices and the shared format for both data and remote procedure calls. Two technology-independent
concepts permeate the service-oriented literature: orchestration and choreography (Alonso et al.,
2004; Singh & Huhns, 2005). Orchestration involves the ordering of actions of possibly different
services, facilitated by a controller or orchestrator, to achieve a certain overall goal. Choreography concerns the distributed coordination of different actions through publicly observable events to
achieve a certain goal. A MAS perspective (Wooldridge, 2001) is known to be particularly helpful
in service-oriented computing in that it allows us to ascribe information states and private or common goals to the various services. Under this view the agents of the system implement the services
and interact with one another in a shared infrastructure or environment.
A key theoretical problem in SOC is to devise effective mechanisms to verify that service composition is correct against some specification. Techniques based on model checking (Clarke et al.,
1999) and synthesis (Berardi, Cheikh, Giacomo, & Patrizi, 2008) have been put forward to solve
the composition and orchestration problem for services described and advertised at interface level
through finite state machines (Calvanese, De Giacomo, Lenzerini, Mecella, & Patrizi, 2008). More
recently, attention has turned to services described by languages such as WS-BPEL (Alves et al.,
2007), which provide potentially unbounded variables in the description of the service process.
Again, model checking approaches have successfully been used to verify complex service compositions (Bertoli, Pistore, & Traverso, 2010; Lomuscio, Qu, & Solanki, 2012).
While WS-BPEL provides a model for services with variables, the data referenced by them is
non-permanent. The area of data-centric workflows (Hull et al., 2009; Nigam & Caswell, 2003)
evolved as an attempt to provide support for permanent data, typically present in the form of underlying databases. Although usually abstracted away, permanent data is of central importance to
services, which typically query data sources and are driven by the answers they obtain; see, e.g.,
(Berardi, Calvanese, De Giacomo, Hull, & Mecella, 2005). Therefore, a faithful model of a service behaviour cannot, in general, disregard this component. In response to this, proposals have
been made in the workflows and service communities in terms of declarative specifications of datacentric services that are advertised for automatic discovery and composition. The artifact-centric
approach (Cohn & Hull, 2009) is now one of the leading emerging paradigms in the area. Artifactcentric systems can be presented along four dimensions (Hull, 2008; Hull et al., 2011).
Artifacts are the holders of all structured information available in the system. In a businessoriented scenario this may include purchase orders, invoices, payment records, etc. Artifacts may
be created, amended, and destroyed at run time; however, abstract artifact schemas are provided
at design time to define the structure of all artifacts to be manipulated in the system. Intuitively,
external events cause changes in the system, including in the value of artifact attributes.
The evolution of artifacts is governed by lifecycles. These capture the changes that an artifact
may go through from creation to deletion. Intuitively, a purchase order may be created, amended
and operated on before it is fulfilled and its existence in the system terminated: a lifecycle associated
with a purchase order artifact formalises these transitions.
Services are seen as the actors operating on the artifact system. They represent both human and
software actors, possibly distributed, that generate events on the artifact system. Some services may
own artifacts, and some artifacts may be shared by several services. However, not all artifacts, or
parts of artifacts, are visible to all services. Views and windows respectively determine which parts
of artifacts and which artifact instances are visible to which service. An artifact hub is a system that
maintains the artifact system and processes the events generated by the services.

335

fiB ELARDINELLI , L OMUSCIO & PATRIZI

Services generate events on the artifact system according to associations. Typically these are
declarative descriptions providing the precondition and post-conditions for the generation of events.
These generate changes in the artifact system according to the artifact lifecycles. Events are processed by a well-defined semantics (Damaggio, Hull, & Vaculn, 2011; Hull et al., 2011) that governs the sequence of changes an artifact system may undertake upon consumption of an event. Such
a semantics, based on the use of Prerequisite-Antecedent-Consequent (PAC) rules, ensures acyclicity and full determinism in the updates on the artifact system. GSM is a declarative language that
can be used to describe artifact systems. BARCELONA is an engine that executes GSM-based artifact
systems (Heath et al., 2013).
The above is a partial and incomplete description of the artifact paradigm. We refer to the
literature for more details (Cohn & Hull, 2009; Hull, 2008; Hull et al., 2011).
As it will be clear in the next section, in line with the agent-based approach to services, we will
use agent-based concepts to model services. The artifact system will be represented as an environment, constituted by evolving databases, upon which the agents operate; lifecycles and associations
will be modelled by local and global transition functions. The model is intended to incorporate all
artifact-related concepts including views and windows.
In view of the above in this paper we address the following questions. How can we give a
transition-based semantics for artifacts and agents operating on them? What language should we
use to specify properties of the agents and the artifacts themselves? Can we verify whether or not
an artifact system satisfies certain properties? As this will be shown to be undecidable, can we
find suitable fragments on which this question can always be answered? If so, what is the resulting
complexity? Can we provide declarative specifications for the agent programs so that these can be
verified by model checking? Lastly, can this technique be used on mainstream scenarios from the
SOC literature?
1.2 Related Work
As stated above, virtually all current literature on artifact-centric systems focuses on properties and
implementations of the artifact systems as such. Little or no attention is given to the actors of the
system, whether they are human or artificial agents. A few formal techniques have, however, been
put forward to verify the core, non-agent aspects of the system; in the following we briefly compare
these to this contribution.
To our knowledge the verification of artifact-centric business processes was first discussed by
Bhattacharya et al. (2007), where reachability and deadlocks are phrased in the context of artifactcentric systems and complexity results for the verification problem are given. Even disregarding the
agent-related aspects here investigated, the present contribution differs markedly from their work
by employing a more expressive specification language and by putting forward effective abstraction
procedures for verification.
Gerede and Su (2007) study a verification technique for artifact-centric systems against a variant
of computation-tree logic. The decidability of the verification problem is proven for the language
considered under the assumption that the interpretation domain is bounded. Decidability is also
shown for the unbounded case by making restrictions on the values that quantified variables can
range over. In the work here presented we also work on unbounded domains, but do not require
the restrictions present therein: we only insist on the fact that the number of distinct values in the
system does not exceed a given threshold at any point in any run. Most importantly, the interplay

336

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

between quantification and modalities here considered allows us to bind and use variables in different states. This is a major difference as this feature is very expressive and known to lead potentially
to undecidability.
In a related line of research the verification problem for artifact systems against two variants
of first-order linear-time temporal logic is considered (Deutsch et al., 2009; Damaggio, Deutsch, &
Vianu, 2012). Decidability of the verification problem is retained by imposing syntactic restrictions
on both the system description and the specification to check. This effectively limits the way in
which new values introduced at every computational step can be used by the system. Properties
based on arithmetic operators are also considered (Damaggio et al., 2012). While there are elements
of similarity between these approaches and the one we put forward here, including the fact that the
concrete interpretation domain is replaced by an abstract one, there are also significant differences.
Firstly, our setting is branching-time and not linear-time thereby resulting in different expressive
power. Secondly and most importantly, differently from similar contributions (Deutsch et al., 2009;
Damaggio et al., 2012), we impose no constraints on nested quantifiers or on their interaction with
temporal modalities. In contrast, Damaggio et al. admit only a guarded form of quantification on
state formulas, and universal quantification at the outermost syntactic level of the formula, over
the free variables of state formulas. These two restrictions represent a major, crucial difference
with respect to the present work, in that the former syntactical restrictions prevent representing
the interaction between data at different states, which is instead expressible in the present work.
Our branching time setting also requires a different abstraction technique. Indeed, the approach
above (Deutsch et al., 2009; Damaggio et al., 2012) is based on the construction of a counterexample
to the formula to be checked, a fact that is technically made possible by two key factors: (i) the
exclusive use of universal quantification over paths, guaranteed by the use of linear-time logics;
(ii) the syntactic restriction on quantifiers over values, which permits only universal quantifiers to
include temporal modalities within their scope. None of such features is required in our work.
Namely, we allow both existential and universal quantification over paths to be present (although in
a CTL fashion), and we do not put any restriction on the use of first-order quantifiers. Additionally,
the abstraction results we present here are given in general terms on the semantics of declarative
programs and do not depend on a particular presentation of the system.
Finally, following an approach similar to ours, Bagheri Hariri et al. (2013) give conditions for
the decidability of the model checking problem for data-centric dynamic systems, i.e., dynamic
systems with relational states. In this case the specification language used is a first-order version of
the -calculus. While our temporal fragment is subsumed by the -calculus, the two specification
languages have different expressive power, since we use indexed epistemic modalities as well as a
common knowledge operator. To retain decidability, like we do here, the authors assume a constraint
on the size of the states. However, differently from this contribution, Bagheri Hariri et al. also
assume limited forms of quantification whereby only individuals persisting in the system evolution
can be quantified over. We do not make this restriction here.
Irrespective of what above, the most important feature that characterises our work is that the
set-up is entirely based on epistemic logic and multi-agent systems. We use agents to represent
the autonomous services operating in the system and agent-based concepts play a key role in the
modelling, the specifications, and the verification techniques put forward. Differently from all
approaches presented above we are not only concerned with whether the artifact system meets
a particular specification. Instead, we also wish to consider what knowledge the agents in the
system acquire by interacting among themselves and with the artifact system during a system run.
337

fiB ELARDINELLI , L OMUSCIO & PATRIZI

Additionally, the abstraction methodology put forward is modular with respect to the agents in
the system, that is, first we define abstract agents and then compose them together to obtain the
abstract system. These features enable us to give constructive procedures for the generation of
finite abstractions for artifact-centric programs associated with infinite models. We are not aware
of any work in the literature tackling any of these aspects.
This paper combines and expands our preliminary results on artifact-centric systems (Belardinelli, Lomuscio, & Patrizi, 2011a, 2011b, 2012a, 2012b). In particular, the technical set up of
artifacts and agents is different from that of our preliminary studies and makes it more natural to
express artifact-centric concepts such as views. Differently from our previous attempts, we here
incorporate an operator for common knowledge and provide constructive methods to define abstractions. We also consider the complexity of the verification problem, previously unexplored, and
evaluate the technique in detail on a case study.
1.3 Scheme of the Paper
The rest of the paper is organised as follows. In Section 2 we introduce artifact-centric multiagent systems (AC-MAS), the semantics we will be using throughout the paper to describe agents
operating on an artifact system. In the same section we put forward FO-CTLK, a first-order logic
with knowledge and time to reason about the evolution of the knowledge of the agents and the
artifact system. This enables us to propose a satisfaction relation based on the notion of bounded
quantification, define the model checking problem, and highlight some properties of isomorphic
states. An immediate result we will explore concerns the undecidability of the model checking
problem for AC-MAS in their general setting.
Section 3 is devoted to identifying a subclass of AC-MAS that admits a decidable model checking problem against full FO-CTLK specifications. The key finding here is that bounded and uniform
AC-MAS, a class identified by studying a strong bisimulation relation, admit finite, truth-preserving
abstractions for any FO-CTLK specification. In Section 3.4 we explore the verification problem further and also investigate its complexity thereby showing it to be EXPSPACE-complete.
We turn our attention to artifact programs in Section 4 by defining the concept of artifact-centric
programs. We define them through natural, first-order preconditions and post-conditions in line with
the artifact-centric approach. We give a semantics to them in terms of AC-MAS and show that their
generated models are precisely those uniform AC-MAS studied earlier in the paper. It follows that,
under some boundedness conditions which can be naturally expressed, the model checking problem
for artifact-centric programs is decidable and can be executed on finite models.
Section 4.2 reports a scenario from the artifact systems literature. This is used to exemplify the
technique by providing finite abstractions that can be effectively verified. We conclude in Section 5
where we consider the limitations of the approach and point to further work.

2. Artifact-Centric Multi-agent Systems
In this section we formalise artifact-centric systems and state their verification problem. As data
and databases are equally important constituents of artifact systems, our formalisation of artifacts
relies on them as underpinning concepts. However, as discussed in the previous section, we here
give prominence to agent-based concepts. As such, we define our systems as comprising both the
artifacts and the agents interacting with it.
338

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

A standard paradigm for logic-based reasoning about agents is interpreted systems (Parikh &
Ramanujam, 1985; Fagin et al., 1995). In this setting agents are endowed with private local states
and evolve by performing actions according to an individual protocol. As data play a key part, as
well as to allow us to specify properties of the artifact system, we will define the agents local states
as evolving database instances. We call this formalisation artifact-centric multi-agent systems (ACMAS). AC-MAS enable us to represent naturally and concisely concepts much used in the artifact
paradigm such as the one of view discussed earlier.
Our specification language will include temporal-epistemic logic but also quantification over a
domain so as to represent the data. This is an usual verification setting, so we will formally define
the model checking problem for this set up.
2.1 Databases and First-Order Logic
As discussed above, we use databases as the basic building blocks for defining the states of the
agents and the artifact system. We here fix the notation and terminology used. We refer to the
literature for more details on databases (Abiteboul, Hull, & Vianu, 1995).
Definition 2.1 (Database Schemas) A (relational) database schema D is a set {P1 /q1 , . . . , Pn /qn }
of relation symbols Pi , each associated with its arity qi  N.
Instances of database schemas are defined over interpretation domains, i.e., sets of individuals.
Definition 2.2 (Database Instances) Given a countable interpretation domain U and a database
schema D, a D-instance over U is a mapping D associating each relation symbol Pi  D with a
finite qi -ary relation over U , i.e., D(Pi )  U qi .
The set of all D-instances over a countable interpretation domain U is denoted by D(U ). We
simply refer to instances whenever the database schema D is clear by the context. The active
domain of an instance D, denoted as adom(D), is the set of all individuals in U occurring in some
tuple of some predicate interpretation D(Pi ). Observe that, since D contains a finite number of
relation symbols and each D(Pi ) is finite, so is adom(D). Also, in the rest of the paper we assume
that the interpretation domains are always countable without explictly mentioning this fact.
To fix the notation, we recall the syntax of first-order formulas with equality and no function
symbols. Let Var be a countable set of individual variables and Con be a finite set of individual
constants. A term is any element t  Var  Con.
Definition 2.3 (FO-formulas over D) Given a database schema D, the formulas  of the firstorder language LD are defined by the following BNF grammar:
 ::= t = t0 | Pi (t1 , . . . , tqi ) |  |    | x
where Pi  D, t1 , . . . , tqi is a qi -tuple of terms and t, t0 are terms.
We assume = to be a special binary predicate with fixed obvious interpretation. To summarise,
LD is a first-order language with equality over the relational vocabulary D with no function symbols
and with finitely many constant symbols from Con. Observe that considering a finite set of constants
is not a limitation. Indeed, since we will be working with finite sets of formulas, Con can always be
defined so as to be able to express any formula of interest.
339

fiB ELARDINELLI , L OMUSCIO & PATRIZI

In the following we use the standard abbreviations , , , and 6=. Also, free and bound
variables are defined as standard. For a formula  we denote the set of its variables as var(), the
set of its free variables as free(), and the set of its constants as con(). We write (~x) to list
explicitly in arbitrary order all the free variables x1 , . . . , x` of . By slight abuse of notation, we
treat ~x as a set, thus we write ~x = free(). A sentence is a formula with no free variables.
Given an interpretation domain U suchthat Con  U , an assignment is a function
 : Var 7 U .

For an assignment , we denote by  ux the assignment such that: (i)  ux (x) = u; and (ii)
 ux (x0 ) = (x0 ), for every x0  Var different from x. For convenience, we extend assignments to
constants so that (t) = t, if t  Con; that is, we assume a Herbrand interpretation of constants.
We can now define the semantics of LD .
Definition 2.4 (Satisfaction of FO-formulas) Given a D-instance D, an assignment , and an
FO-formula   LD , we inductively define whether D satisfies  under , written (D, ) |= , as
follows:
(D, ) |= Pi (t1 , . . . , tqi )
(D, ) |= t = t0
(D, ) |= 
(D, ) |=   
(D, ) |= x

iff
iff
iff
iff
iff

h(t1 ), . . . , (tqi )i  D(Pi )
(t) = (t0 )
it is not the case that (D, ) |= 
(D, ) |=  or (D, ) |= 

for all u  adom(D), we have that (D,  ux ) |= 

A formula  is true in D, written D |= , iff (D, ) |= , for all assignments .
Observe that we adopt an active-domain semantics, that is, quantified variables range only over the
active domain of D. We claim that this form of quantification is sufficient to express specifications
of interest (see Section 4.2) while retaining decidability. Also notice that constants are interpreted
rigidly; so, two constants are equal if and only if they are syntactically the same. In the rest of the
paper, we assume that every interpretation domain includes Con. Also, as a usual shortcut, we write
(D, ) 6|=  to express that it is not the case that (D, ) |= .
Finally, we introduce the  operator on D-instances that will be used later in the paper. Let the
primed version of a database schema D be the schema D0 = {P10 /q1 , . . . , Pn0 /qn } obtained from D
by syntactically replacing each predicate symbol Pi with its primed version Pi0 of the same arity.
Definition 2.5 ( Operator) Given two D-instances D and D0 , we define D  D0 as the (D  D0 )instance such that D  D0 (Pi ) = D(Pi ) and D  D0 (Pi0 ) = D0 (Pi ).
Intuitively, the  operator defines a disjunctive join of the two instances, where relation symbols in
D are interpreted according to D, while their primed versions are interpreted according to D0 .
2.2 Artifact-Centric Multi-agent Systems
In the following we introduce the semantic structures that we will use throughout the paper. We
define an artifact-centric multi-agent system as a system comprising an environment representing
all artifacts and a finite set of agents interacting with such environment. As agents have views of the
artifact state, i.e., projections of the status of particular artifacts, we assume that the building blocks
of their private local states are also modelled as database instances. In line with the interpreted
systems semantics (Fagin et al., 1995) not everything in the agents states needs to be present in the
environment; a portion of it may be entirely private and not replicated in other agents states. So,
we start by introducing the notion of agent.
340

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

Definition 2.6 (Agent) Given an interpretation domain U , an agent is a tuple A = hD, Act, P ri,
where:
 D is the local database schema;
 Act is the finite set of action types (~
p), where p~ is the tuple of abstract parameters;
 P r : D(U ) 7 2Act(U ) is the local protocol function, where Act(U ) is the set of ground
actions of the form (~u) where (~
p)  Act and ~u  U |~p| is a tuple of ground parameters.
Intuitively, at a given time each agent A is in some local state l  D(U ) that represents all the
information agent A has at its disposal. In this sense we follow the standard approach to multiagent systems (Fagin et al., 1995), but require that this information is structured as a database.
Again, following standard literature we assume that the agents are autonomous and proactive and
perform the actions in Act according to the protocol function P r, which returns the set of grounded
actions enabled in any local state. In the definition above we use the term abstract parameters to
denote variables, i.e., the language in which particular action parameters are given; we use the term
ground parameters to refer to their concrete values.
We assume that the agents interact among themselves and with an environment comprising
all artifacts in the system. As artifacts are entities involving both data and processes, we can see
them as collections of database instances paired with actions and governed by special protocols.
Without loss of generality we can assume the environment state to be a single database instance
including all artifacts in the system. From a purely formal point of view this allows us to represent
the environment as a special agent. Of course, in any specific instantiation the environment and the
agents will be different entities, exactly in line with the standard propositional version of interpreted
systems.
We can therefore define the synchronous composition of agents with the environment.
Definition 2.7 (Artifact-Centric Multi-agent Systems) Given an interpretation domain U and a
set Ag = {A0 , . . . , An } of agents Ai = hDi , Acti , P ri i defined on U , an artifact-centric multiagent system (or AC-MAS) is a tuple P = hAg, s0 ,  i where:
Q
 s0  Ai Ag Di (U ) is the initial global state;
Q
Q
Ai Ag Di (U )
  :
is the global transition function, where
Ai Ag Di (U )  Act(U ) 7 2
Act(U ) = Act0 (U )      Actn (U ) is the set of global (ground) actions, and  (hl0 , . . . , ln i,
h0 (~u0 ), . . . , n (~un )i) is defined whenever i (~ui )  P ri (li ) for every i  n.

As we will see in later sections, AC-MAS are the natural extension of interpreted systems to
the first order to account for environments constituted of artifact-centric systems. They can be seen
as a specialisation of quantified interpreted systems (Belardinelli & Lomuscio, 2012), a general
extension of interpreted systems to the first-order case.
In the formalisation above the agent A0 is typically referred to as the environment S
E. The environment normally includes all artifacts in the system (notably by assuming that D0  0<in Dn ),
as well as additional information to facilitate communication
S between the agents and the hub, e.g.,
messages in transit etc. In what follows we consider D0 = 0<in Dn for simplicity; this modelling
choice does not impact the results presented later on. At any given time an AC-MAS is described
by a tuple of database instances, representing all the agents in the system as well as the artifact
341

fiB ELARDINELLI , L OMUSCIO & PATRIZI

system. A single interpretation domain for all database schemas is given. Note that this does not
break the generality of the representation as we can always extend the domain of all agents and the
environment before composing them into a single AC-MAS. The global transition function defines
the evolution of the system through synchronous composition of actions for the environment and all
agents in the system.
Much of the interaction we are interested in modelling involves message exchanges with payload, hence the action parameters, between agents and the environment, i.e., agents operating on the
artifacts. However, note that the formalisation above does not preclude us from modelling agent-toagent interactions, as the global transition function does not rule out successors in which only some
agents change their local state following some actions. Also observe that essential concepts such as
views are easily expressed in AC-MAS by insisting that the local state of an agent includes part of
the environments, i.e., the artifacts the agent has access to. Not all AC-MAS need to have views
defined, so it is also possible for the views to be empty.
Other artifact-based concepts such as lifecycles are naturally expressed in AC-MAS. As artifacts
are modelled as part of the environment, a lifecycle is naturally encoded in AC-MAS simply as
the sequence of changes induced by the transition function  on the fragment of the environment
representing the lifecycle in question. We will show an example of this in Section 2.4.
Some technical remarks now follow. To simplify the notation, we denote a global ground action
as 
~ (~u), where 
~ = h0 (p0 ), . . . , n (pnQ
)i and ~u = h~u0 , . .Q
. , ~un i, with each ~ui of appropriate size.
We define the transition relation  on Ai Ag Di (U )  Ai Ag Di (U ) such that s  s0 if and
only if there exists 
~ (~u)  Act(U ) such that s0   (s, 
~ (~u)). If s  s0 , we say that s0 is a
successor of s. A run r from s  S is an infinite sequence s0  s1     , with s0 = s. For
.
n  N, we take r(n) = sn . A state s0 is reachable from s if there exists a run r from the global
state r(0) = s such that r(i) = s0 , for some i  0. We assume that the relation  is serial, i.e.,
for every global state s there exists s0 such that s  s0 . This can be easily obtained by assuming
that each agent has a skip action enabled at each local state and that performing skip induces no
changes in any of the local states. We introduce S as the set of states reachable from the initial
state s0 according to the transition relation . Notice that assuming a unique initial state does not
hinder the generality of the approach, as for any finite set I of states we can encode in  transitions
from s0 to the states in I. As in plain interpreted systems (Fagin et al., 1995), we say that two global
states s = hl0 , . . . , ln i and s0 = hl00 , . . . , ln0 i are epistemically indistinguishable for agent Ai , written
s i s0 , if li = li0 . Differently from interpreted systems the local equality is evaluated on database
instances. For convenience we will use also the concept of temporal-epistemic (t.e., for short) run.
Formally a t.e. run r from a state s  S is an infinite sequence s0 ; s1 ; . . . such that s0 = s
and si  si+1 or si k si+1 , for some k  Ag. A state s0 is said to be temporally-epistemically
reachable (t.e. reachable, for short) from s if there exists a t.e. run r from the global state r(0) = s
such that for some i  0 we have that r(i) = s0 . Obviously, temporal-epistemic runs include purely
temporal runs as a special case. Also, notice that we admit U to be infinite, thereby allowing the
possibility of the set of states S to be infinite. Indeed, unless we specify otherwise, we will assume
to be working with infinite-state AC-MAS.
Finally, for technical reasons it is useful to refer to the global database schema D = D0   Dn
of an AC-MAS. Every global stateS s = hl0 , . . . , ln i is associated with the (global) D-instance
Ds  D(U ) such that Ds (Pi ) = jAg lj (Pi ), for Pi  D. We omit the subscript s whenever
s is clear from the context and we write adom(s) for adom(Ds ). The justification for this choice
comes from the fact that we think of each agent as having a partial, although truthful, view of the
342

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

global state. If the same relation appears in several agent database schemas, possibly with different
interpretations, it means that each agent is aware of only a subset of the total extension of the
relation. We maintain that this modeling choice is justified by the application to artifact systems,
as it will become apparent in Section 2.4. Notice that for every s  S, the Ds associated with s is
unique, while the converse is not true in general. Finally, we lift the disjoint union operator  to
.
global states so that s  s0 = hl0  l00 , . . . , ln  ln0 i. It can be seen that Ds  Ds0 and Dss0 represent
in fact the same D  D0 -instance.
2.3 Model Checking
We now define the problem of verifying an artifact-centric multi-agent system against a specification
of interest. By following the artifact-centric model, we wish to give data the same prominence as
processes. To deal with data and the underlying database instances, our specification language needs
to include first-order logic. Further, we require temporal logic to describe the system execution.
Lastly, we use epistemic logic to express the information the agents have at their disposal. Hence,
we define a first-order temporal-epistemic specification language to be interpreted on AC-MAS. The
specification language will be used in Section 4 to formalise properties of artifact-centric programs.
Definition 2.8 (The Logic FO-CTLK) The first-order CTLK (or FO-CTLK) formulas  over a
database schema D are inductively defined by the following BNF:
 ::=  |  |    | x | AX | AU  | EU  | Ki  | C
where   LD and 0 < i  n.
The notions of free and bound variables for FO-CTLK extend straightforwardly from LD , as well
as functions var, free, and con. As usual, the temporal formulas AX and AU 0 (resp. EU 0 )
are read as for all runs, at the next step  and for all runs (resp. some run),  until 0 . The
epistemic formulas Ki  and C intuitively mean that agent Ai knows  and it is common
knowledge among all agents that  respectively. We use the abbreviations EX, AF , AG,
EF , and EG as standard. Observe that free variables can occur within the scope of modal
operators, thus admitting the unconstrained alternation of quantifiers and modal operators, thereby
allowing us to refer to elements in different modal contexts.
The semantics of FO-CTLK formulas is defined as follows.
Definition 2.9 (Satisfaction for FO-CTLK) Consider an AC-MAS P, an FO-CTLK formula , a
state s  P, and an assignment . We inductively define whether P satisfies  in s under , written
(P, s, ) |= , as follows:
(P, s, ) |= 
(P, s, ) |= 
(P, s, ) |=   0
(P, s, ) |= x
(P, s, ) |= AX
(P, s, ) |= AU 0

iff
iff
iff
iff
iff
iff

(P, s, ) |= EU 0

iff

(Ds , ) |= , if  is an FO-formula
it is not the case that (P, s, ) |= 
(P, s, ) |=  or (P, s, ) |= 0
for all u  adom(s), (P, s,  ux ) |= 
for all runs r, if r(0) = s, then (P, r(1), ) |= 
for all runs r, if r(0) = s, then there is k  0 s.t. (P, r(k), ) |= 0 ,
and for all j, 0  j < k implies (P, r(j), ) |= 
for some run r, r(0) = s and there is k  0 s.t. (P, r(k), ) |= 0 ,
343

fiB ELARDINELLI , L OMUSCIO & PATRIZI

and for all j, 0  j < k implies (P, r(j), ) |= 
for all s0  S, s i s0 implies (P, s0 , ) |= 
for all s0  S, s  s0 implies (P, s0 , ) |= 
S
where  is the transitive closure of 1in i .
(P, s, ) |= Ki 
(P, s, ) |= C

iff
iff

A formula  is said to be true at a state s, written (P, s) |= , if (P, s, ) |=  for all assignments
. Moreover,  is said to be true in P, written P |= , if (P, s0 ) |= .
A key concern in this paper is to explore the model checking of AC-MAS against first-order
temporal-epistemic specifications (Grohe, 2001).
Definition 2.10 (Model Checking Problem) Given an AC-MAS P and a FO-CTLK formula  the
model checking problem consists in finding an assignment  such that (P, s0 , ) |= .
It is easy to see that whenever U is finite the model checking problem is decidable as P is a finitestate system. In general, however, this is not the case. To see this, notice that, by assuming computability, both the agents protocol functions P ri and the AC-MAS transition function  , can be
finitely represented (e.g., as Turing machines). Since all other components of agents and AC-MAS
definitions are finite, it follows that all AC-MAS, in particular infinite-state ones, admit a finite
representation. Assuming fixed the representation formalism, we have the following result.
Theorem 2.11 The model checking problem for AC-MAS w.r.t. FO-CTLK is undecidable.
Proof (sketch). This can be proved by showing that every Turing machine T whose tape contains
an initial input I can be simulated by an artifact system PT,I . The problem of checking whether T
terminates on that particular input can be reduced to checking whether PT,I |= , where  encodes
the termination condition. The detailed construction is similar to that of the work of Deutsch, Sui,
and Vianu (2007, Thm. 4.10).
Given the general setting in which the model checking problem is defined above, the negative result is not surprising. In the following we identify semantic restrictions for which the problem is
decidable.
2.4 The Order-to-Cash Scenario
We analyse a business process inspired by a concrete IBM customer use case (Hull et al., 2011). The
order-to-cash scenario describes the interactions of a number of agents in an e-commerce situation
relating to the purchase and delivery of a product. The agents in the artifact-centric system consist
of a manufacturer, some customers, and some suppliers. The process begins when a customer
prepares and submits a purchase order (PO), i.e., a list of products the customer requires, to the
manufacturer. Upon receiving a PO, the manufacturer prepares a material order (MO), i.e., a
list of components needed to assemble the requested products. The manufacturer then selects a
supplier and forwards him the relevant material order. Upon receiving an MO a supplier can either
accept or reject it. In the former case he then proceeds to deliver the requested components to the
manufacturer. In the latter case he notifies the manufacturer of his rejection. If an MO is rejected,
the manufacturer deletes it and then prepares and submits a new MO. When the manufacturer
receives the delivered components, he assembles the product and, provided the order has been paid
344

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

id

PO
prod code offer

status

id

MO
prod code price

status

Products
prod code budget
Materials
mat code cost
Figure 1: The Data Model for the Order-to-Cash Scenario.
createPO

prepared

submitPO

pending

pay

paid

shipPO

shipped

deletePO

(a) Purchase Order lifecyle
accepted

shipMO

shipped

acceptMO
createMO

preparation

doneMO

submitted

deleteMO

rejectMO
rejected

deleteMO

(b) Material Order lifecyle

Figure 2: Lifecycles of the artifacts involved in the order-to-cash scenario.
for, delivers it to the customer. Any manufacturer order which is directly or indirectly related to a
PO can be deleted only after the PO is deleted.
We can encode the order-to-cash business process as an artifact-centric multi-agent system,
where the artifact data models are represented as database schemas and their evolution is characterised by an appropriate set of operations. It is natural to identify two artifact types, representing
the PO and the MO. We reserve a distinguished relation for each artifact type. In addition, we
introduce static relations to store product and material information. As a result, the data model of
the order-to-cash scenario with associated attributes can be given as in Figure 1.
The intended meaning of relations is self-explanatory. Note the presence of the attribute status
in the relations corresponding to artifact classes. An intuitive representation of the artifact lifecycles,
i.e., the evolution of some key records in the artifacts states, capturing only the dependence of
actions from the artifact statuses, is shown in Figure 2. For example, a purchase order, with initial
status prepared, is created by the agent customer through the action createPO. Once the order
is submitted to the agent manufacturer, the PO status changes to pending. The other transitions
labelled by pay, shipPO and deletePO, act similarly, according to their semantics, on the status
of the purchase order. Note that this is an incomplete representation of the business process, as the
interaction between actions and the artifact data content is not represented.

345

fiB ELARDINELLI , L OMUSCIO & PATRIZI

We now formally encode the scenario as an AC-MAS. For the sake of presentation in what
follows we assume to be dealing with three agents only: one customer c, one manufacturer m and
one supplier s. The database schema Di for each agent i  {c, m, s} can be given as:
 Customer c:
Dc = {Products(prod code, budget), PO(id , prod code, offer , status)};
 Manufacturer m:
Dm = {PO(id , prod code, offer , status), MO(id , prod code, price, status)};
 Supplier s:
Ds = {Materials(mat code, cost), MO(id , prod code, price, status)}.
We consider the infinite set Uotc of alphanumeric strings as the interpretation domain, and introduce a parametric action for each transition in the lifecycles in Figure 2. Also, we assume that
in the initial state the only non-empty relations are Products and Materials, which contain background information, such as a catalogue of available products. We can now define the agents in the
order-to-cash scenario as follows.
Definition 2.12 the agents Ac , Am and As are given as
 Ac = hDc , Actc , P rc i, where (i) Dc is as above; (ii) Actc = {createPO(id , pcode),
submitPO(id ), pay(id ), deletePO(id )}; and (iii) P rc respects the intended meaning of the
customers actions. For instance, createPO(id , pcode)  P rc (lc ) iff the interpretation
lc (Products) of the relation Products in the local state lc contains a tuple hpcode, bi for
some budget b.
 Am = hDm , Actm , P rm i, where (i) Dm is as above; (ii) Actm = {createMO(id , price),
doneMO(id ), shipPO(id ), deleteMO(id )}; and (iii) P rm respects the intended meaning
of the manufacturers actions. For instance, createMO(po id , price)  P rm (lm ) iff the
interpretation lm (MO) of the relation MO in the local state lm does not contain a tuple
hpo id, pc, pr, preparationi for the same PO id po id.
 As
=
hDs , Acts , P rs i, where (i) Ds is as above;
(ii) Acts
=
{acceptMO(id ), rejectMO(id ), shipMO(id )}; and (iii) P rc respects the intended
meaning of the suppliers actions. For instance, acceptMO(mo id )  P rs (ls ) iff ls (M O)
does not contain a tuple with id mo id and status accepted.
Further, we can now define the AC-MAS induced by the set of agents Agotc = {Ac , Am , As }
according to Definition 2.7.
Definition 2.13 Given the set of agents Agotc
hAgotc , s0otc , otc i is such that

=

{Ac , Am , As }, the AC-MAS Potc

=

 s0otc = hlc , lm , ls i is the initial global state, where the only non-empty relations are Products
and Materials in lc and ls respectively;
 otc is the global transition function defined so as to respect the intended meaning of
the evolution of the order-to-cash scenario. For instance, consider the global action
346

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

(~u) = hcreatePO(pc), doneMO(m), acceptMO(m 0 )i enabled by the respective protocols in a global state s. By the definition of the actions createPO(pc), doneMO(m), and
acceptMO(m 0 ) we have that li (s)  P ri for i  {c, m, s} implies that the Products relation contains information about the product pc. Also, the interpretation of the relation MO
contains the tuples hm, p, pr, preparationi and hm0 , p0 , pr0 , submittedi for some products p
and p0 . Hence, s0  otc (s, (~u)) iff the interpretation of the relation PO in s0 extends
Ds (P O) with the tuple hid, pc, b, preparedi, where id is a fresh id. The tuples for the material orders m and m0 are updated in Ds0 (M O) by becoming hm, p, pr, submittedi and
hm0 , p0 , pr0 , acceptedi, respectively. No other element is changed in the transition.
Clearly, the function otc given above can easily be completed to encode the artifacts lifecycles
as given in Figure 2. In section 4.2 we will give a succinct encoding of Potc in terms of an artifactcentric program.
We can now investigate properties of the present business process by using specifications in
FO-CTLK. For instance, the following formula intuitively specifies that the manufacturer m knows
that each material order MO has to match a corresponding purchase order PO:
match = AG id, pc (pr, s M O(id, pc, pr, s)  Km o, s0 P O(id, pc, o, s0 ))
The next specification states that given a material order MO, the customer will eventually know
that the corresponding PO will be shipped.
fulfil

= AG id, pc (pr, s M O(id, pc, pr, s)  EF Kc o P O(id, pc, o, shipped))

Further, we may be interested in checking whether or not budget and costs are always kept secret
from the supplier s and the customer c respectively, and whether the customer (resp., the supplier)
knows this fact:
budget = Kc pc AG b Ks Products(pc, b)
cost = Ks mc AG c Kc Materials(mc, c)
Other interesting specifications describing properties of the artifact system and the agents operating in it can be similarly formalised in FO-CTLK, thereby providing the engineer with a valuable
tool to assess the implementation.
Observe that the AC-MAS for the order-to-cash scenario has an infinite number of states thereby
making it difficult to investigate by means of traditional model checking techniques. We will return
to this scenario in Subsection 4.2 where we will investigate how it may still be verified. Before
doing so we develop a methodology for associating finite abstractions to infinite AC-MAS.

3. Abstraction for Artifact-Centric Multi-agent Systems
In the previous section we have observed that model checking AC-MAS against FO-CTLK is undecidable in general. It is clearly of interest to isolate decidable settings. In what follows we identify
semantic constraints resulting in a decidable model checking problem. The investigation is carried
out on a rather natural subclass of AC-MAS that we call bounded, as defined below. Our goal for
proceeding in this manner is to identify finite abstractions of infinite-state AC-MAS so that verification of programs that admit bounded AC-MAS as models can be conducted on them, rather than
on the original infinite-state AC-MAS. We will see this in detail in Section 4.
347

fiB ELARDINELLI , L OMUSCIO & PATRIZI

The key concept that enables us to achieve the above is uniformity. Uniform AC-MAS are
systems for which the behaviour does not depend on the actual data present in the states. This
means that the system contains all possible transitions that are enabled according to parametric
action rules, thereby resulting in a full transition relation. This notion is related to genericity
in databases (Abiteboul et al., 1995). Here we use the term uniformity as we refer to transition
systems and not databases.
To achieve finite abstractions we proceed as follows. We first propose an adaptation of the notion
of isomorphism to our setting; then we introduce bisimulations; finally in Subsection 3.2 we show
how this notion can be exploited to guarantee that uniform AC-MAS satisfy the same FO-CTLK
formulas. We then use this result to show that bounded, uniform systems admit finite abstractions
(Subsection 3.3). The complexity of the model checking problem is analysed in Subsection 3.4.
In the rest of the section we let P = hAg, s0 ,  i and P 0 = hAg 0 , s00 ,  0 i be two AC-MAS and
assume, unless stated differently, that s = hl0 , . . . , ln i  S, and s0 = hl00 , . . . , ln0 i  S 0 .
3.1 Isomorphisms
We now investigate the concept of isomorphism on AC-MAS. This will be needed in later sections
to define finite abstractions of infinite-state AC-MAS.
Definition 3.1 (Isomorphism) Two local states l, l0  D(U ) are isomorphic, written l ' l0 , iff
there exists a bijection  : adom(l)  Con 7 adom(l0 )  Con such that:
(i)  is the identity on Con;
(ii) for every Pi  D, ~u  U qi , we have that ~u  l(Pi ) iff (~u)  l0 (Pi ).
When this is the case, we say that  is a witness for l ' l0 .
Two global states s  S and s0  S 0 are isomorphic, written s ' s0 , iff there exists a bijection
 : adom(s)  Con 7 adom(s0 )  Con such that for every j  Ag,  is a witness for lj ' lj0 .
Notice that isomorphisms preserve the interpretation of constants in Con as well as of predicates
in the local states up to renaming of the corresponding terms. Any function  as above is called
a witness for s ' s0 . Obviously, the relation ' is an equivalence relation. Given a function f :
U 7 U 0 defined on adom(s), f (s) denotes the instance in D(U 0 ) obtained from s by renaming
each u  adom(s) as f (u). If f is also injective (thus invertible) and the identity on Con, then
f (s) ' s.
Example As an example of isomorphic states, consider an agent with local database schema D =
{P1 /2, P2 /1}, let U = {a, b, c, . . .} be an interpretation domain, and fix the set Con = {b} of
constants. Let l be the local state such that l(P1 ) = {ha, bi, hb, di} and l(P2 ) = {a} (see Figure 3).
Then, the local state l0 such that l0 (P1 ) = {hc, bi, hb, ei} and l0 (P2 ) = {c} is isomorphic to l. This
can be easily seen by considering the isomorphism , where: (a) = c, (b) = b, and (d) = e.
However, the state l00 where l00 (P1 ) = {hf, di, hd, ei} and l00 (P2 ) = {f } is not isomorphic to l.
Indeed, although a bijection exists that maps l into l00 , it is easy to see that none can be such that
0 (b) = b.
Note that, while isomorphic states have the same relational structure, two isomorphic states do
not necessarily satisfy the same FO-formulas as satisfaction depends also on the values assigned to
free variables. To account for this, we introduce the following notion.
348

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

l(P1 )
a b
b d

l(P2 )
a

l0 (P1 )
c b
b e

l0 (P2 )
c

l00 (P1 )
f d
d e

l00 (P2 )
f

Figure 3: Examples of isomorphic and non-isomorphic local states.
Definition 3.2 (Equivalent assignments) Given two states s  S and s0  S 0 , and a set of variables V  V ar, two assignments  : V ar 7 U and  0 : V ar 7 U 0 are equivalent for V w.r.t. s
and s0 iff there exists a bijection  : adom(s)  Con  (V ) 7 adom(s0 )  Con   0 (V ) such that:
(i) |adom(s)Con is a witness for s ' s0 ;
(ii)  0 |V =   |V .
Intuitively, equivalent assignments preserve both the (in)equalities of the variables in V and the
constants in s, s0 up to renaming. Note that, by definition, the above implies that s, s0 are isomorphic.
We say that two assignments are equivalent for an FO-CTLK formula , omitting the states s and
s0 when clear from the context, if these are equivalent for free().
We can now show the following standard result in first-order (non-modal) logic, i.e., isomorphic
states satisfy exactly the same FO-formulas (Abiteboul et al., 1995).
Proposition 3.3 Given two isomorphic states s  S and s0  S 0 , an FO-formula , and two
assignments  and  0 equivalent for , we have that
(Ds , ) |=  iff (Ds0 ,  0 ) |= 
Moreover, if  is an FO-sentence,
Ds |=  iff Ds0 |= 
Thus, isomorphic states cannot be distinguished by FO-sentences. This enables us to use this
notion, when defining simulations.
3.2 Bisimulations
Plain bisimulations are known to be satisfaction preserving in a modal propositional setting (Blackburn, de Rijke, & Venema, 2001). In the following we explore the conditions under which this
applies to AC-MAS as well. We introduce a notion of bisimulation, based on isomorphisms, and
later explore its properties in the context of uniform AC-MAS.
Definition 3.4 (Simulation) A relation R on S  S 0 is a simulation if hs, s0 i  R implies:
1. s ' s0 ;
2. for every t  S, if s  t then there exists t0  S 0 s.t. s0  t0 , s  t ' s0  t0 , and ht, t0 i  R;
3. for every t  S, for every 0 < i  n, if s i t then there exists t0  S 0 s.t. t i t0 ,
s  t ' s0  t0 , and ht, t0 i  R.

349

fiB ELARDINELLI , L OMUSCIO & PATRIZI

P
1

2

3

4

5

P0
1

2

Figure 4: Bisimilar AC-MAS not satisfying the same FO-CTLK formulas.
Definition 3.4 has many similarities with the standard notion of simulation in the propositional
setting. In particular, the co-inductive structure of the definition requires similar states to satisfy
some local property and to preserve this along corresponding transitions. However, differently from
the propositional case, we here insist that s  t ' s0  t0 ; this ensures that similar transitions in
AC-MAS preserve isomorphic disjoint unions.
A state s0  S 0 is said to simulate s  S, written s  s0 , iff there exists a simulation R
s.t. hs, s0 i  R. When no ambiguity arises, we simply say that s and s0 are similar. Note that
similar states are isomorphic, as condition (2) above ensures that s ' s0 . The similarity relation can
be shown to be the largest simulation, reflexive and transitive on S  S 0 . Further, we say that P 0
simulates P, written P  P 0 , if s0  s00 .
Simulations can naturally be extended to bisimulations, as follows.
Definition 3.5 (Bisimulation) A relation B on S  S 0 is a bisimulation iff both B and B 1 =
{hs0 , si | hs, s0 i  B} are simulations.
Two states s  S and s0  S 0 are said to be bisimilar, written s  s0 , iff there exists a bisimulation
B such that hs, s0 i  B. It can be shown that  is the largest bisimulation, and an equivalence
relation, on S  S 0 . We say that P and P 0 are bisimilar, written P  P 0 iff so are s0 and s00 .
It is instructive to note that bisimilar systems do not preserve FO-CTLK formulas. This is
markedly different from the modal propositional case.
Example Consider Figure 4, where Con =  and P and P 0 are given as follows. For a number n
of agents equal to 1, we define D = D0 = {P/1} and U = N; s0 (P ) = s00 (P ) = {1};  = {hs, s0 i |
s(P ) = {i}, s0 (P ) = {i + 1}};  0 = {hs, s0 i | s(P ) = {i}, s0 (P ) = {(i mod 2) + 1}}. Notice
that S  D(N) and S 0  D(N). Clearly we have that P  P 0 . Now, consider the constant-free
FO-CTLK formula  = AG(x(P (x)  AXAGP (x))). It can be easily seen that P |=  while
P 0 6|= .
The above shows that, differently from the propositional case, bisimilarity is not a sufficient
condition to guarantee the preservation of FO-CTLK formulas. Intuitively, this is a consequence
of the fact that bisimilar AC-MAS do not preserve value associations along runs. For instance, the
value 1 in P 0 is associated infinitely many times with the odd values occurring in P. By quantifying
across states we are able to express this fact and can therefore distinguish the two structures. This is
a difficulty as, intuitively, we would like to use bisimulations to demonstrate the existence of finite
abstractions. However, as we show later, this happens on the class of uniform AC-MAS, defined
below.

350

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

Definition 3.6 (Uniformity) An AC-MAS P is said to be uniform iff for every s, t, s0  S, t0 
D(U ),
1. if t   (s, 
~ (~u)) and s  t ' s0  t0 for some witness , then for every constant-preserving
0
bijection  that extends  to ~u, we have that t0   (s0 , 
~ (0 (~u)));
2. if s i t and s  t ' s0  t0 , then s0 i t0 .
This definition captures the idea that actions take into account and operate only on the relational
structure of states and action parameters, irrespective of the actual data they contain (apart from a
finite set of constants). Intuitively, uniformity expresses that if t can be reached by executing (~u)
in s, and we replace the same element v with v 0 in s, ~u and t, obtaining s0 , ~u0 and t0 , then t0 can
be reached by executing (~u0 ) in s0 . In terms of the underlying Kripke structures, i.e., the frames
induced on S by relations  and i for Ai  Ag, this means that the systems are full up to , that
is, in all uniform AC-MAS the states t0 identified above are indeed part of the system and reachable
from s0 . A similar condition is required on the epistemic relation. A property of uniform systems is
that the latter requirement is implied by the former, as shown by the following result.
Proposition 3.7 If an AC-MAS P satisfies req. 1 in Def. 3.6 and adom(s0 )  Con, then req. 2 is
also satisfied.
Proof. If s  t ' s0  t0 , then there is a witness  : adom(s)  adom(t)  Con 7 adom(s0 ) 
adom(t0 )  Con that is the identity on Con (hence on adom(s0 )). Assume s i t, thus li (s) = li (t),
and li (s0 ) = (li (s)) = (li (t)) = li (t0 ). Notice that this does not guarantee that s0 i t0 , as we
need to prove that t0  S. This can be done by showing that t0 is reachable from s0 . Since t is
reachable from s0 , there exists a run s0  s1  . . .  sk s.t. sk = t. Extend now  to a total and
injective function 0 : adom(s0 )      adom(sk )  Con 7 U . This can always be done because
|U |  |adom(s0 )      adom(sk )  Con|. Now consider the sequence 0 (s0 ), 0 (s1 ), . . . , 0 (sk ).
Since adom(s0 )  Con then (s0 ) = s0 and, because 0 extends , we have that 0 (s0 ) = (s0 ) = s0 .
Further, 0 (sk ) = (t) = t0 . By repeated applications of req. 1 we can show that 0 (sm+1 ) 
 (0 (sm ), 
~ (0 (~u))) whenever sm+1   (sm , 
~ (~u)), for m < k. Hence, the sequence is actually a
0
0
0
0
run from s0 to t . Thus, t  S, and s i t .
Thus, as long as adom(s0 )  Con, to check whether an AC-MAS is uniform, it is sufficient to
take into account only the transition function.
A further distinctive feature of uniform systems is that all isomorphic states are bisimilar.
Proposition 3.8 If an AC-MAS P is uniform, then for every s, s0  S, s ' s0 implies s  s0 .
Proof. We prove that B = {hs, s0 i  S  S | s ' s0 } is a bisimulation. Observe that since '
is an equivalence relation, so is B. Thus B is symmetric and B = B 1 . Therefore, proving that B
is a simulation proves also that B 1 is a simulation; hence, that B is a bisimulation. To this end, let
hs, s0 i  B, and assume s  t for some t  S. Then, t   (s, (~u)) for some (~u)  Act(U ).
Consider a witness  for s ' s0 . By cardinality considerations  can be extended to a total and
injective function 0 : adom(s)  adom(t)  {~u}  Con 7 U . Consider 0 (t) = t0 ; it follows that 0
is a witness for s  t ' s0  t0 . Since P is uniform, t0   (s0 , (0 (~u))), that is, s0  t0 . Moreover,
0 is a witness for t ' t0 , thus ht, t0 i  B. Next assume that hs, s0 i  B and s i t, for some t  S.
351

fiB ELARDINELLI , L OMUSCIO & PATRIZI

By reasoning as above we can find a witness  for s ' s0 , and an extension 0 of  s.t. t0 = 0 (t) and
0 is a witness for s  t ' s0  t0 . Since P is uniform, s0 i t0 and ht, t0 i  B.
This result intuitively means that submodels generated by isomorphic states are bisimilar.
Next we prove some partial results, which will be useful in proving our main preservation theorem. The first two guarantee that under appropriate cardinality constraints the bisimulation preserves
the equivalence of assignments w.r.t. a given FO-CTLK formula.
Lemma 3.9 Consider two bisimilar and uniform AC-MAS P and P 0 , two bisimilar states s  S
and s0  S 0 , and an FO-CTLK formula . For every assignments  and  0 equivalent for  w.r.t. s
and s0 , we have that:
1. for every t  S s.t. s  t, if |U 0 |  |adom(s)  adom(t)  Con  (free())|, then there
exists t0  S 0 s.t. s0  t0 , t  t0 , and  and  0 are equivalent for  w.r.t. t and t0 .
2. for every t  S s.t. s i t, if |U 0 |  |adom(s)  adom(t)  Con  (free())|, then there
exists t0  S 0 s.t. s0 i t0 , t  t0 , and  and  0 are equivalent for  w.r.t. t and t0 .
Proof. To prove (1), let  be a bijection witnessing that  and  0 are equivalent for  w.r.t. s and s0 .
Suppose that s  t. Since s  s0 , by definition of bisimulation there exists t00  S 0 s.t. s0  t00 ,
.
s  t ' s0  t00 , and t  t00 . Now define Domj = adom(s)  adom(t)  Con, and partition it into:
.
 Dom = adom(s)  Con  (adom(t)  (free());
.
 Dom0 = adom(t) \ Dom .
Let 0 : Dom0 7 U 0 \ Im() be an invertible total function. Observe that |Im()| =
|adom(s0 )  Con   0 (free())| = |adom(s)  Con  (free())|, thus from the fact that |U 0 | 
|adom(s)  adom(t)  Con  (free())| we have |U 0 \ Im()|  |Dom(0 )|, which guarantees
the existence of 0 .
Next, define j : Domj 7 U 0 as follows:

(u), if u  Dom
j(u) =
0 (u), if u  Dom0
Obviously, j is invertible. Thus, j is a witness for s  t ' s0  t0 , where t0 = j(t). Since
s  t ' s0  t00 and ' is an equivalence relation, we obtain that s0  t0 ' s0  t00 . Thus, s0  t0 ,
as P 0 is uniform. Moreover,  and  0 are equivalent for  w.r.t. t and t0 , by construction of t0 . To
check that t  t0 , observe that, since t0 ' t00 and P 0 is uniform, by Prop. 3.8 it follows that t0  t00 .
Thus, since t  t00 and  is transitive, we obtain that t  t0 . The proof for (2) has an analogous
structure and therefore is omitted.
It can be proven that this result is tight, i.e., that if the cardinality requirement is violated, there
exist cases where assignment equivalence is not preserved along temporal or epistemic transitions.
Lemma 3.9 easily generalises to t.e. runs.
Lemma 3.10 Consider two bisimilar and uniform AC-MAS P and P 0 , two bisimilar states s  S
and s0  S 0 , an FO-CTLK formula , and two assignments  and  0 equivalent for  w.r.t. s and
s0 . For every t.e. run r of P, if r(0) = s and for all i  0, |U 0 |  |adom(r(i))  adom(r(i + 1)) 
Con  (free())|, then there exists a t.e. run r0 of P 0 s.t. for all i  0:
352

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

(i) r0 (0) = s0 ;
(ii) r(i)  r0 (i);
(iii)  and  0 are equivalent for  w.r.t. r(i) and r0 (i).
(iv) for every i  0, if r(i)  r(i + 1) then r0 (i)  r0 (i + 1), and if r(i) j r(i + 1), for some
j, then r0 (i) j r0 (i + 1).
Proof. Let r be a t.e. run satisfying the lemmas hypothesis. We inductively build r0 and show
that the conditions above are satisfied. For i = 0, let r0 (0) = s0 . By hypothesis, r is s.t. |U 0 | 
|adom(r(0))  adom(r(1))  Con  (free())|. Thus, since r(0) ; r(1), by Lemma 3.9 there
exists t0  S 0 s.t. r0 (0) ; t0 , r(1)  t0 , and  and  0 are equivalent for  w.r.t. r(1) and t0 . Let
r0 (1) = t0 . Lemma 3.9 guarantees that the transitions r0 (0) ; t0 and r(0) ; r(1) can be chosen so
that they are either both temporal or both epistemic with the same index.
The case for i > 0 is similar. Assume that r(i)  r0 (i) and  and  0 are equivalent for 
w.r.t. r(i) and r0 (i). Since r(i) ; r(i + 1) and |U 0 |  |adom(r(i))  adom(r(i + 1))  Con 
(free())|, by Lemma 3.9 there exists t0  S 0 s.t. r0 (i) ; t0 ,  and  0 are equivalent for 
w.r.t. r(i + 1) and t0 , and r(i + 1)  t0 . Let r0 (i + 1) = t0 . It is clear that r0 is a t.e. run in P 0 , and
that, by Lemma 3.9, the transitions of r0 can be chosen so as to fulfil requirement (iv).
We can now prove that FO-CTLK formulas cannot distinguish bisimilar and uniform AC-MAS.
This is in marked contrast with the earlier example in this section which related to bisimilar but
non-uniform AC-MAS.
Theorem 3.11 Consider two bisimilar and uniform AC-MAS P and P 0 , two bisimilar states s  S
and s0  S 0 , an FO-CTLK formula , and two assignments  and  0 equivalent for  w.r.t. s and s0 .
If
1. for every t.e. run r s.t. r(0) = s, for all k  0 we have |U 0 |  |adom(r(k))  adom(r(k +
1))  Con  (free())| + |var() \ free()|; and
2. for every t.e. run r0 s.t. r0 (0) = s0 , for all k  0 we have |U |  |adom(r0 (k))  adom(r0 (k +
1))  Con   0 (free())| + |var() \ free()|;
then
(P, s, ) |=  iff (P 0 , s0 ,  0 ) |= .
Proof. The proof is by induction on the structure of . We prove that if (P, s, ) |=  then
|= . The other direction can be proved analogously. The base case for atomic formulas
follows from Prop. 3.3. The inductive cases for propositional connectives are straightforward.
For   x, assume that x  free() (otherwise consider , and the corresponding case),
and no variable is quantified more than once (otherwise rename variables). Let  be a bijection witnessing that  and  0 are equivalent for  w.r.t. s and s0 . For u  adom(s), consider
x
the assignment  ux . By definition, (u)  adom(s0 ), and  0 (u)
is well-defined. Note that


x
x
0
free() = free()  {x}; so  u and  (u) are equivalent for  w.r.t. s and s0 . Moreover,

| ux (free())|  |(free())| + 1, as u may not occur in (free()). The same considerations apply to  0 . Further, |var() \ free()| = |var() \ free()|  1, as var() = var(),
(P 0 , s0 ,  0 )

353

fiB ELARDINELLI , L OMUSCIO & PATRIZI

free() = free()  {x}, and x 
/ free(). Thus, both hypotheses (1) and (2) remain satisfied
x
. Therefore, by the induction hypothesis,
if we replace  with ,  with  ux , and  0 with  0 (u)


x
x
0
0
0
if (P, s,  u ) |=  then (P , s ,  (u) ) |= . Since u  adom(s) is generic and  is a bijection,
the result follows.
For   AX, assume by contradiction that (P, s, ) |=  but (P 0 , s0 ,  0 ) 6|= . Then, there
exists a run r0 s.t. r0 (0) = s0 and (P 0 , r0 (1),  0 ) 6|= . Since |var() \ free()|  0, by Lemma 3.10,
there exists a run r s.t. r(0) = s, and for all i  0, r(i)  r0 (i) and  and  0 are equivalent for 
w.r.t. r(i) and r0 (i). Since r is a run s.t. r(0) = s, it satisfies hypothesis (1). Moreover, the same
hypothesis is necessarily satisfied by all the t.e. runs r00 s.t. for some i  0, r00 (0) = r(i) (otherwise,
the t.e. run r(0) ;    ; r(i) ; r00 (1) ; r00 (2) ;    would not satisfy the hypothesis for r); the
same considerations apply w.r.t hypothesis (2) and for all the t.e. runs r000 s.t. r000 (0) = r0 (i), for some
i  0. In particular, these hold for i = 1. Thus, we can inductively apply the lemma, by replacing s
with r(1), s0 with r0 (1), and  with  (observe that var() = var() and free() = free()). But
then we obtain (P, r(1), ) 6|= , thus (P, r(0), ) 6|= AX. This is a contradiction.
For   EU , assume that the only variables common to  and  occur free in both formulas
(otherwise rename the quantified variables). Let r be a run s.t. r(0) = s, and there exists k  0
s.t. (P, r(k), ) |= , and (P, r(j), ) |=  for 0  j < k. By Lemma 3.10 there exists a run
r0 s.t. r0 (0) = s0 and for all i  0, r0 (i)  r(i) and  and  0 are equivalent for  w.r.t. r0 (i)
and r(i). From each bijection i witnessing that  and  0 are equivalent for  w.r.t. r0 (i) and
r(i), define the bijections i, = i |adom(r(i))Con(free()) and i, = i |adom(r(i))Con(free()) .
Since free()  free(), free()  free(), it can be seen that i, and i, witness that  and
 0 are equivalent for respectively  and  w.r.t. r0 (i) and r(i). By the same argument used for
the AX case above, hypothesis (1) holds for all the t.e. runs r00 s.t. r00 (0) = r(i), for some
i  0, and hypothesis (2) holds for all the t.e. runs r000 s.t. r000 (0) = r0 (i). Now observe that
|(free())|, |(free())|  |(free())|. Moreover, by the assumption on the common variables
of  and , (var() \ free()) = (var() \ free()) ] (var() \ free()), thus |var() \ free()| =
|(var() \ free()| + |(var() \ free()|, hence |(var() \ free()|, |(var() \ free()| 
|var() \ free()|. Therefore hypotheses (1) and (2) hold also with  uniformly replaced by either  or . Then, the induction hypothesis applies for each i, by replacing s with r(i), s0 with
r0 (i), and  with either  or . Thus, for each i, (P, r(i), ) |=  iff (P 0 , r0 (i),  0 ) |= , and
(P, r(i), ) |=  iff (P 0 , r0 (i),  0 ) |= . Therefore, r0 is a run s.t. r0 (0) = s0 , (P 0 , r0 (k),  0 ) |= ,
and for every j, 0  j < k implies (P 0 , r0 (j),  0 ) |= , i.e., (P 0 , s0 ,  0 ) |= EU .
For   AU , assume by contradiction that (P, s, ) |=  but (P 0 , s0 ,  0 ) 6|= . Then, there
exists a run r0 s.t. r0 (0) = s0 and for every k  0, either (P 0 , r0 (k),  0 ) 6|=  or there exists j
s.t. 0  j < k and (P 0 , r0 (j),  0 ) 6|= . By Lemma 3.10 there exists a run r s.t. r(0) = s, and
for all i  0, r(i)  r0 (i) and  and  0 are equivalent for  w.r.t. r(i) and r0 (i). Similarly to
the case of EU , it can be shown that  and  0 are equivalent for  and  w.r.t. r(i) and r0 (i),
for all i  0. Further, assuming w.l.o.g. that all variables common to  and  occur free in both
formulas, it can be shown, as in the case of EU , that the induction hypothesis holds on every
pair of runs obtained as suffixes of r and r0 , starting from their i-th state, for every i  0. Thus,
(P, r(i), ) |=  iff (P 0 , r0 (i),  0 ) |= , and (P, r(i), ) |=  iff (P 0 , r0 (i),  0 ) |= . But then r
is s.t. r(0) = s and for every k  0, either (P, r(k), ) 6|=  or there exists j s.t. 0  j < k and
(P, r(j), ) 6|= , that is, (P, s, ) 6|= AU . This is a contradiction.
For   Ki , assume by contradiction that (P, s, ) |=  but (P 0 , s0 ,  0 ) 6|= . Then, there
exists s00 s.t. s0 i s00 and (P 0 , s00 ,  0 ) 6|= . By Lemma 3.10 there exists s000 s.t. s000  s00 , s i s000 ,
354

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

and  and  0 are equivalent for  w.r.t. s00 and s000 . Thus, by an argument analogous to that used
for the case of AX, we can apply the induction hypothesis, obtaining (P, s000 , ) 6|= . But then
(P, s, ) 6|= Ki , which is a contradiction.
Finally, for   C, assume by contradiction that (P, s, ) |=  but (P 0 , s0 ,  0 ) 6|= . Then,
there exists an s00 s.t. s0  s00 and (P 0 , s00 ,  0 ) 6|= . Again by Lemma 3.10 there exists s000 s.t. s000 
s00 , s  s000 , and  and  0 are equivalent for  w.r.t. s00 and s000 . Thus, by an argument analogous to
that used for the case of Ki , we can apply the induction hypothesis, obtaining (P, s000 , ) 6|= . But
then (P, s, ) 6|= C, which is a contradiction.
We can now easily extend the above result to the model checking problem for AC-MAS.
Theorem 3.12 Consider two bisimilar and uniform AC-MAS P and P 0 , and an FO-CTLK formula
.
If
1. for all t.e. runs r s.t. r(0) = s0 , and for all k  0, |U 0 |  |adom(r(k))  adom(r(k + 1)) 
Con| + |var()|, and
2. for all t.e. runs r0 s.t. r0 (0) = s00 , and for all k  0, |U |  |adom(r0 (k))  adom(r0 (k + 1)) 
Con| + |var()|
then
P |=  iff P 0 |= .
Proof. Equivalently, we prove that if (P, s0 , ) 6|=  for some , then there exists a  0
s.t. (P 0 , s00 ,  0 ) 6|= , and viceversa. To this end, observe that hypotheses (1) and (2) imply, respectively, hypotheses (1) and (2) of Theorem 3.11. Further, notice that, by cardinality considerations,
given the assignment  : V ar 7 U , there exists an assignment  0 : V ar 7 U 0 s.t.  and  0 are
equivalent for  w.r.t. s0 and s00 . Thus, by applying Theorem 3.11 we have that if there exists an
assignment  s.t. (P, s0 , ) 6|= , then there exists an assignment  0 s.t. (P 0 , s00 ,  0 ) 6|= . The
converse can be proved analogously, as the hypotheses are symmetric.
This result shows that uniform AC-MAS can in principle be verified by model checking a bisimilar one. Note that this applies to an infinite AC-MAS P, as well. In this case the results above
enable us to show that the verification question can be posed on the corresponding, possibly finite
P 0 as long as U 0 , as defined above, is sufficiently large for P 0 to bisimulate P. A noteworthy class
of infinite systems for which these results prove particularly powerful is that of bounded AC-MAS,
which, as discussed in the next subsection, always admit a finite abstraction.
3.3 Finite Abstractions
We now define a notion of finite abstraction for AC-MAS, and prove that, under uniformity, abstractions are bisimilar to the corresponding concrete model. We are particularly interested in finite
abstractions; so we operate on a special class of infinite models that we call bounded.
Definition 3.13 (Bounded AC-MAS) An AC-MAS P is b-bounded, for b  N, if for all s  S,
|adom(s)|  b.

355

fiB ELARDINELLI , L OMUSCIO & PATRIZI

An AC-MAS is b-bounded if none of its reachable states contain more than b distinct elements.
Observe that bounded AC-MAS may be defined on infinite domains. Furthermore, note that a bbounded AC-MAS may contain infinitely many states, all bounded by b. So b-bounded systems
are infinite-state in general. Notice also that the value b constrains only the number of distinct
individuals in a state, not the size of the state itself, intended as the amount of memory required
to accommodate the individuals. Indeed, the infinitely many elements in a domain U need an
unbounded number of bits to be represented (e.g., as finite strings), so, even though each state is
guaranteed to contain at most b distinct elements, nothing can be said about how large the actual
space required by such elements is. Conversely, memory-bounded AC-MAS are finite-state (hence
b-bounded, for some b).
Since b-bounded AC-MAS are in general memory-unbounded, they cannot be verified by trivially generating and checking all their possibly infinite executions. However, we will show later
that any b-bounded and uniform infinite-state AC-MAS admits a finite-state abstraction which can
be used to verify it.
We introduce abstractions in a modular manner by first introducing a set of abstract agents from
a concrete AC-MAS.
Definition 3.14 (Abstract agent) Let A = hD, Act, P ri be an agent defined on the interpretation
domain U . Given an interpretation domain U 0 , the abstract agent of A on U 0 is the agent A0 =
hD0 , Act0 , P r0 i such that:
1. D0 = D;
2. Act0 = Act;
3. (~u0 )  P r0 (l0 ), with l0  D0 (U 0 ), iff there exist l  D(U ) and (~u)  P r(l) s.t. l0 ' l, for
some witness , and ~u0 = 0 (~u), for some bijection 0 extending  to ~u.
Given a set Ag of agents defined on U , Ag 0 denotes the set of corresponding abstractions on U 0 of
the agents in Ag.
We remark that the abstract agent A0 is an agent in line with Definition 2.6. Notice that the protocol of A0 is defined on the basis of its corresponding concrete agent A and requires the existence of
a bijection between the elements in the corresponding local states and the action parameters. Thus,
in order for a ground action of A to have a counterpart in A0 , the last requirement of Definition 3.14
constrains U 0 to contain a sufficient number of distinct values. As it will become apparent later, the
size of U 0 determines how closely an abstract system can simulate its concrete counterpart. Notice
also that, in general, an agent may not be an abstraction of itself on U , as for instance data may
impact the agents protocol.
Next, we combine the notion of uniformity with that of boundedness. Our aim is to identify
conditions under which the verification of an infinite AC-MAS can be reduced to the verification of
a finite one. The main result here is given by Corollary 3.19 which guarantees that, in the context
of bounded AC-MAS, uniformity is a sufficient condition for bisimilar finite abstractions to be
satisfaction-preserving.
In the following we assume that any AC-MAS P is such that adom(s0 )  Con. If this is not the
case, Con can be extended so as to include all the (finitely many) elements in adom(s0 ). We start
by formalising the notion of abstraction.
356

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

Definition 3.15 (Abstract AC-MAS) Let P = hAg, s0 ,  i be an AC-MAS and Ag 0 the set of abstract agents obtained as in Definition 3.14 for some interpretation domain U 0 . The AC-MAS
P 0 = hAg 0 , s00 ,  0 i is said to be an abstraction of P iff:
 s00 = s0 ;
 t0   0 (s0 , 
~ (~u0 )) iff there exist s, t  S and 
~ (~u)  Act(U ) such that s  t ' s0  t0 , for
0
0
some witness , t   (s, 
~ (~u)), and ~u =  (~u) for some bijection 0 extending  to ~u.
It can be checked that P 0 , as defined above, is indeed an AC-MAS as it satisfies the relevant
conditions on protocols and transitions in Definition 2.7. Indeed, if t0   0 (s0 , 
~ (~u0 )), then there
exist s, t  S, and 
~ (~u) such that t   (s, 
~ (~u)), s  t ' s0  t0 for some witness , and ~u = 0 (~u0 )
0
for some bijection  extending . This means that i (~ui )  P ri (li ) for i  n. By definition of P ri0
we have that i (~u0i )  P ri0 (li0 ) for i  n.
The definition requires abstractions to have initial states isomorphic to their concrete counterparts; specifically they have to be equal as adom(s0 )  Con. Moreover, the second constraint entails
that a transition in the concrete model exists if and only if the same transition, up to renaming of the
involved values, exists in the abstraction. So, for example, a copy action in the concrete model has a
corresponding copy action in the abstract model. Crucially, this condition requires that the domain
U 0 contains enough elements to bisimulate the concrete states and action effects. This will be made
precise in Lemma 3.17.
Obviously, if U 0 has finitely many elements, then S 0 has finitely many states. Observe also that
by varying U 0 we obtain different abstractions. Finally, notice that an AC-MAS is not necessarily
an abstraction of itself. This issue is addressed in Lemma 3.16.
Next, we investigate the relationship between an AC-MAS and its abstractions. A first useful
result states that every finite abstraction is uniform, independently of the properties of the AC-MAS
they abstract.
Lemma 3.16 Every abstraction P 0 of an AC-MAS P is uniform. Moreover, if P is uniform and
U 0 = U , then P 0 = P.
Proof. Consider s, t, s0  S 0 , t0  D(U 0 ), and 
~ (~u)  Act0 (U 0 ) s.t. t   0 (s, 
~ (~u)) and
0
0
s  t ' s  t , for some witness . We need to show that P 0 admits a transition from s0 to t0 . Since
P 0 is an abstraction of P, given the definition of  0 , there exist s00 , t00  S and 
~ (~u00 )  Act(U )
00
00
00
00
00
0
00
s.t. t   (s , 
~ (~u )), s  t ' s  t, for some witness , and ~u =  (~u ), for some constantpreserving bijection 0 extending  to ~u00 . Consider ~u0  U 0|~u| such that ~u0 =  0 (~u), for some
constant-preserving bijection  0 extending  to ~u. Obviously, the composition  0  0 is a constantpreserving bijection such that ~u0 =  0 (0 (~u00 )). Moreover, it can be restricted to a witness for
s00  t00 ' s0  t0 . But then, since P 0 is an abstraction of P, this implies that t0   0 (s0 , 
~ (~u0 )). Thus,
P 0 is uniform.
Moreover, to prove that P is an abstraction of itself every time P is uniform and U 0 = U ,
we notice that if the transition t   (s, 
~ (~u)) is in P, then it is also in P 0 by the definition of
0
abstraction. Also, if the transition t   0 (s0 , 
~ (~u0 )) appears in P 0 , then there exist s, t  S and
0
0
~ ) s.t. s  t ' s  t for some witness , t   (s, 

~ (~u)  Act(U
~ (~u)), and ~u0 = 0 (~u) for some
constant-preserving bijection 0 extending  to ~u. Finally, since P is uniform it is the case that the
transition t0   0 (s0 , (~u0 )) is in P as well.

357

fiB ELARDINELLI , L OMUSCIO & PATRIZI

This lemma provides sufficient conditions under which an AC-MAS is an abstraction of itself,
namely being uniform and having the same interpretation domain.
The second result below guarantees that every uniform, b-bounded AC-MAS is bisimilar to
any of its abstractions, provided these areP
built over a sufficiently large interpretation domain. In
0
the following, we take NAg = NAg =
x|}, i.e., NAg is the sum of the
x)Acti {|~
Ai Ag max(~
maximum number of parameters contained in the action types of each agent in Ag.
Lemma 3.17 Consider a uniform, b-bounded AC-MAS P over an infinite interpretation domain U ,
and an interpretation domain U 0 such that Con  U 0 . If |U 0 |  2b + |Con| + NAg , then any
abstraction P 0 of P over U 0 is bisimilar to P.
Proof. Let B = {hs, s0 i  S  S 0 | s ' s0 }. We prove that B is a bisimulation such that
hs0 , s00 i  B. We start by proving that B is a simulation relation. To this end, observe that since
s0 = s00 , then s0 ' s00 , and hs0 , s00 i  B. Next, consider hs, s0 i  B, thus s ' s0 . Assume that
s  t, for some t  S. Then, there
~ (~u)  Act(U ) such that t   (s, 
~ (~u)). Moreover,
Pmust exist 
since |U 0 |  2b + |Con| + NAg ,S Ai Ag |~ui |  NAg , and |adom(s)  adom(t)|  2b, the witness
 for s ' s0 can be extended to Ai Ag ~ui as a bijection 0 . Now let t0 = 0 (t). By the way 0 has
been defined, it can be seen that s  t ' s0  t0 . Further, since P 0 is an abstraction of P, we have
that t0   0 (s0 , 
~ (~u0 )) for ~u0 = 0 (~u), that is, s0  t0 in P 0 . Therefore, there exists t0  S 0 such
that s0  t0 , s  t ' s0  t0 , and ht, t0 i  B. As regards the epistemic relation, assume s i t
for some i  {1, . . . , n} and t  S. By definition of i , li (s) = li (t). Since |U 0 |  2b + |Con|,
any witness  for s ' s0 can be extended to a witness 0 for s  t ' s0  t0 , where t0 = 0 (t).
Obviously, li (s0 ) = li (t0 ). Thus, to prove that s0 i t0 , we are left to show that t0  S 0 , i.e., that t0 is
reachable in P 0 from s00 = s0 . To this end, observe that since t  S, there exists a purely temporal
run r such that r(0) = s0 and r(k) = t, for some k  0. Thus, there exist 
~ 1 (~u1 ) . . . , 
~ k (~uk ) such
that r(j + 1)   (r(j), 
~ j+1 (~uj+1 )), for 0  j < k. Since |U 0 |  2b + |Con|, we can define, for
0  j < k, a function j that is a witness for r(j)  r(j + 1) ' j (r(j))  j (r(j + 1)). In particular,
this can be done starting from j = k  1, defining k1 so that k1 (r(k)) = k1 (t) = t0 , and
proceeding backward to j = 0, so that, for 0  j < k, we have j (r(j + 1)) = j+1 (r(j + 1)).
Observe that since adom(s0 )  Con, necessarily i0 (r(0)) = i0 (s0 ) = s0 = s00 . Moreover, as
|U 0 |  2b + |Con| + NAg , each j can be extended to a bijection 0j , to the elements occurring in
~uj+1 . Thus, given that P 0 is an abstraction of P, for 0  j < k, we have that 0j (r(j + 1)) 
 (0j (r(j)), 
~ (0j (~uj+1 ))). Hence, the sequence 00 (r(0))      0k1 (r(k)) is a run of P 0 , and,
since t0 = 0k1 (r(k)), t0 is reachable in P 0 . Therefore s0 i t0 . Further, since t ' t0 , by definition
of B, it is the case that ht, t0 i  B, hence B is a simulation.
To prove that B 1 is a simulation, given hs, s0 i  B (thus s ' s0 ), assume that s0  t0 , for
some t0  S 0 . Obviously, there exists 
~ (~u0 )  Act(U 0 ) such that t0   0 (s0 , 
~ (~u0 )). Because P 0 is
00
00
00
00
an abstraction of P, there exist s , t  S and 
~ (~u )  Act(U ) such that s  t00 ' s0  t0 , for some
witness , and t00   (s00 , (~u00 )), with ~u00 = 0 (~u0 ), for some bijection 0 extending  to ~u0 . Observe
that s0 ' s00 , thus, by transitivity of ' we have s ' s00 . The fact that there exists t  S such that
s  t easily follows from the uniformity of P. Thus, since t0 ' t, we have ht, t0 i  B. For the
epistemic relation, assume s0 i t0 for some t0  S 0 and 0 < i  n. Let  be a witness for s0 ' s,
and let 0 be an extension of  that is a witness for s0  t0 ' s  t. For t = 0 (t0 ), it can be seen that
li (s) = li (t). Observe that t0  S 0 . Using an argument analogous to the one above, but exploiting
the fact that P is uniform, that P 0 is certainly b-bounded, and that |U | > 2b + |Con| + NAg as U is
infinite, we can show that t  S by constructing a run r of P such that r(k) = t, for some k  0.
358

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

Then s i t. Further, since t0 ' t, we have ht, t0 i  B. Therefore, B 1 is a simulation. So, P and
P 0 are bisimilar.
This result allows us to prove our main abstraction theorem.
Theorem 3.18 Consider a b-bounded and uniform AC-MAS P over an infinite interpretation domain U , an FO-CTLK formula , and an interpretation domain U 0 such that Con  U 0 . If
|U 0 |  2b + |Con| + max{|vars()|, NAg }, then for any abstraction P 0 of P over U 0 , we have
that:
P |=  iff P 0 |= .
Proof. By Lemma 3.16, P 0 is uniform. Thus, by the hypothesis on the cardinalities of U and U 0 ,
Lemma 3.17 applies, so P and P 0 are bisimilar. Obviously, also P 0 is b-bounded. Thus, since P
and P 0 are b-bounded, and by the cardinality hypothesis on U and U 0 , Theorem 3.12 applies. In
particular, notice that for every temporal-epistemic run r s.t. r(0) = s0 , and for all k  0, we have
that |U 0 |  |adom(r(k))adom(r(k+1))Con|+|var()|, as |adom(r(k))|  b by b-boundedness.
Therefore, P |=  iff P 0 |= .
It follows that by using a sufficiently large number of abstract values in U 0 , we can reduce the
verification of an infinite, bounded, and uniform AC-MAS to the verification of a finite one.
Corollary 3.19 Given a b-bounded and uniform AC-MAS P over an infinite interpretation domain
U , and an FO-CTLK formula , there exists an AC-MAS P 0 over a finite interpretation domain U 0
such that P |=  iff P 0 |= .
It should also be noted that U 0 can simply be taken to be any finite subset of U (including Con)
satisfying the cardinality requirement above. By doing so, the finite abstraction P 0 can be defined
simply as the restriction of P to U 0 . Thus, every infinite, b-bounded and uniform AC-MAS is
bisimilar to a finite subsystem, which then satisfies the same formulas.
Note that we are not concerned with the actual construction of the finite abstraction. This is because we intend to construct it directly from an artifact-centric program, as we will do in Section 4.
Before that, we explore the complexity of the model checking problem.
3.4 The Complexity of Model Checking Finite AC-MAS against FO-CTLK Specifications
We now analyse the complexity of the model checking problem for finite AC-MAS with respect to
FO-CTLK specifications. The input of the problem consists of an AC-MAS P on a finite domain U
and an FO-CTLK formula ; the output is an assignment  such that (P, s0 , ) |= , whenever the
property is satisfied. Hereafter we follow standard literature for basic notions and definitions (Grohe,
2001).
To encode an AC-MAS P we use a tuple EP = hU, D, s0 ,  i, where U is the (finite) interpretation domain, D is the global database schema, s0 is the initial state, and  = {~ 1 , . . . , ~ m } is
a set of FO-formulas, each capturing the transitions associated with a ground joint action 
~ i . Since
U is finite, so is the set of ground actions, thus  . Each ~ i is a FO-formula over the alphabet
j
0 , where D
DAg  DAg
Ag = {Pi /qi | Pi /qi  D, j  n} is the set containing one distinct relation
~)
symbol Pij , for each agent j  n and the relation symbol Pi  D. We take  such that s0   (s, 

359

fiB ELARDINELLI , L OMUSCIO & PATRIZI

0 |=  , for s, s0  D(U ), such that for every P  D and j  n, l (P ) = D (P j )
iff DAg  DAg
i
j
i
Ag

~
i
j
0
0
and lj (Pi ) = DAg (Pi ).
As an example, for D = {P } (thus DAg = {P j | j  n}) and an action type  with no
V
0
parameters, consider the formula ~ = nj=0 xP j (x)  P j (x), which intuitively captures all
transitions in which in the successor state predicate P contains all and only those elements of U that
in the current state are not in P .
It can be proved that every transition relation  can be represented as discussed above, and that,
.
given EP , the size ||P|| = |S| + | | of the encoded AC-MAS P is such that ||P||  |Act|  |U |pmax 
23`qmax , where: pmax is the largest number of parameters in some action type of Act, ` is the
number of relation symbols in D, and qmax is the largest arity of such symbols. This corresponds
to
P
.
a doubly exponential bound for ||P|| w.r.t. ||EP || = |U | + ||D|| + | |, where ||D|| = Pk D qk ,
||E

||4

for qk the arity of Pk . Specifically, we have ||P||  232 P .
We carry out the complexity analysis on the basis of the input above; clearly the same results
apply for equally compact inputs such as the AC programs to be presented in Section 4.
We consider the combined complexity of the input, that is, ||EP || + ||||. We say that
the combined complexity of model checking finite AC-MAS against FO-CTLK specifications is
EXPSPACE-complete if the problem is in EXPSPACE, i.e., there is a polynomial p(x) and an
algorithm solving the problem in space bounded by 2p(||EP ||+||||) , and the problem is EXPSPACEhard, i.e., every EXPSPACE problem can be reduced to model checking finite AC-MAS against
FO-CTLK specifications.
Theorem 3.20 The model checking problem for finite AC-MAS succinctly presented as above
against FO-CTLK specifications is EXPSPACE-complete.
Proof. To show that the problem is in EXPSPACE, recall that ||P|| is at most doubly exponential
w.r.t. the size of the input, thus so is |S|. We describe an algorithm that works in NEXPSPACE; this
combines the algorithm for model checking the first-order fragment of FO-CTLK and that for the
temporal-epistemic fragment. Since NEXPSPACE = EXPSPACE, the result follows. Given an ACMAS P and an FO-CTLK formula , we guess an assignment  and check whether (P, s0 , ) |= .
This can be done by induction according to the structure of . If  is atomic, this check can be done
in polynomial time w.r.t. the size of the state it is evaluated on, that is, exponential time w.r.t. ||EP ||.
If  is of the form x, then we can apply the algorithm for model checking first-order (non-modal)
logic, which works in PSPACE. Finally, if the outmost operator in  is either a temporal or epistemic
modality, then we can extend the automata-based algorithm to model check propositional CTL
(Kupferman, Vardi, & Wolper, 2000; Lomuscio & Raimondi, 2006), which works in logarithmic
space in |S|. However, we remarked above that |S| is generally doubly exponential in ||EP ||. Thus,
this step can be performed in space singly exponential in ||EP ||. All these steps can be performed
in time polynomial in the size of . As a result, the total combined complexity of model checking
finite AC-MAS is in NEXPSPACE = EXPSPACE.
To prove that the problem is EXPSPACE-hard we show a reduction from any problem in
EXPSPACE. We assume standard definitions of Turing machines and reductions (Papadimitriou,
1994). If A is a problem in EXPSPACE, then there exists a deterministic Turing machine
TA = hQ, , q0 , F, i, where Q is the finite set of states,  the machine alphabet, q0  Q the
initial state, F the set of accepting states, and  the transition function, that solves A using at most
space 2p(|in|) on a given input in, for some polynomial function p. As standard, we assume  to be a
360

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

relation on (QQD), with D = {L, R}, and hq, c, q 0 , c0 , di   representing a transition
from state q to state q 0 , with characters c and c0 read and written respectively , and head direction d
((L)eft and (R)ight). Without loss of generality, we assume that TA uses only the righthand half of
the tape.
From TA and in, we build an encoding EP = hD, U, s0 ,  i of an AC-MAS P induced by a
single (environment) agent AE = hDE , ActE , P rE i defined on U =   Q  {0, 1}, where: (i)
DE = {P/p(|in|) + 1, Q/1, H/p(|in|), F/1}; (ii) ActE is the singleton {E }, with E parameterfree; (iii) E  P rE (lE ) for every lE  D(U ). Intuitively, the states of P correspond to configurations of TA , while  mimics . To define EP , we let D = DE . The intended meaning
of the predicates in D is as follows: the first p(|in|) elements of a P -tuple encode (in binaries)
the position of a non-blank cell, and the (p(|in|) + 1)-th element contains the symbol appearing
in that cell; Q contains the current state q of TA ; H contains the position of the cell the head is
currently on; F contains the final states of TA , i.e., F = F. The initial state s0 represents the
initial configuration of TA , that is, for in = in0    in` : s(Q) = {q0 }; s(H) = {h0, . . . , 0i}; and
s(P ) = {hBIN(i), ini i | i  {0, . . . , `}}, where BIN(i) stands for the binary encoding in p(|in|)
bits of the integer i. Observe that p(|in|) bits are enough to index the (at most) 2p(|in|) cells used by
TA .
As to the transition relation, we define  = {E }, where (we avoid sub- and superscripts in
predicate symbols, i.e., D = DAg as no ambiguity can arise with only one agent):
 E =

_

(xF (x)  F 0 (x)) 

(1)

hq,c,q 0 ,c0 ,di

Q(q)  (xQ(x)  x = q)  Q0 (q 0 )  (xQ0 (x)  x = q 0 ) 

(2)

~
p(H(~
p)  (xH(x)  x = p~)  (P (~
p, c)  (c = 2  xP (~
p, x)))) 
(3)
0
0
p~0 (d = R  SUCC(~
p, p~0 ))  (d = L  SUCC(p~0 , p~))  H (p~0 )  (xH (x)  x = p~0 )  (4)
(P 0 (~
p, c0 )  (c0 6= 2))  (xP 0 (~
p, x)  x = c0 ) 
0

0

(5)
0

(~x, y(P (~x, y)  (~x 6= p~)  P (~x, y))  (~x, yP (~x, y)  (P (~x, y)  (~x = p~  y = c )))) (6)

Vp(|in|)
The symbol 2 represents the content of blank cells, while SUCC(~x, x~0 ) = i=1 (x0i = 0x0i =
Vi1
V
0
1)  (x0i = 1  ((x0i = 0  i1
j=1 xj = 1)  (xi = 1   j=1 xj = 1))) is a formula capturing that
x~0 is the successor of ~x, for ~x and x~0 interpreted as p(|in|)-bit binary encodings of integers (observe
that {0, 1}  U ). Such a formula can obviously be written in polynomial time w.r.t. p(|in|), as well
as EP , and in particular s0 and E . Formula E is obtained as a disjunction of subformulas, each
referring to a transition of . For each subformula, i.e., transition hq, c, q 0 , c0 , di: line 1 expresses
that F , which encodes the final states of the machine, does not change along the transition (this
formula could be moved out of the big disjunction); line 2 encodes that the machine will be in
exactly one state, q 0 , after the transition takes place; line 3 expresses that the symbol read by the
head is c (possibly blank); line 4 captures that the head moves in direction d; line 5 states that the
head writes symbol c on the cell, before moving; finally, line 6 states that the content of the tape
does not change, except for the cell that the head is on.
The obtained transition function is such that  (s, E ) = s0 iff, for (q, c) = (q 0 , c0 , d) in TA , we
have that: s0 (P ) is obtained from s(P ) by overwriting with c0 (if not blank) the symbol in position
(p(|in|) + 1) of the tuple in s(P ) beginning with the p(|in|)-tuple s(H) (that is, c by definition of
E ); by updating s(H) according to d, that is by increasing or decreasing the value it contains; and
361

fiB ELARDINELLI , L OMUSCIO & PATRIZI

by setting s0 (Q) = {q 0 }. The predicate F does not change. Observe that cells not occurring in P
are interpreted as if containing 2 and when 2 is to be written on a cell, the cell is simply removed
from P .
It can be checked that, starting with s = s0 , by iteratively generating the successor state s0
according to  , i.e., s0 s.t. s  s0 |= E , one obtains a (single) P-run that is a representation of
the computation of TA on in, where each pair of consecutive P-states corresponds to a computation
step. In particular, at each state, Q contains the current state of TA . It should be clear that  =
EF (xQ(x)  F (x)) holds in P iff TA accepts in. Thus, by model checking  on P, we can check
whether TA accepts in. This completes the proof of EXPSPACE-hardness.
Note that the result above is given in terms of the data structures in the model, i.e., U and D,
and not the state space S itself. This accounts for the high complexity of model checking AC-MAS,
as the state space is doubly exponential in the size of the data. By analysing the refined bound on the
size of ||P|| (||P||  |Act||U |pmax 23`qmax ), it can be seen that the double exponential is essentially
due to the number of parameters in action types, the number of relation symbols occurring in D,
and their respective arities. Thus, for fixed database schema and set of action types, the resulting
space complexity is reduced to singly exponential.
While EXPSPACE-hardness indicates intractability, we note that this is to be expected given that
we are dealing with quantified structures which are in principle prone to high complexity. Recall
also from Section 3.3 that the size of the interpretation domain U 0 of the abstraction P 0 is linear
in the bound b, the number of constants in Con, the size of , and NAg . Hence, model checking
bounded and uniform AC-MAS is EXPSPACE-complete with respect to these elements, whose size
will generally be small. Thus, we believe that in several cases of practical interest model checking
AC-MAS may be entirely feasible.

4. Artifact-Centric Programs
We have so far developed a formalism that can be used to specify and reason about temporalepistemic properties of models representing artifact-centric systems. We have identified a notable
class of models that admit finite abstractions. As we remarked in the Introduction, however, artifact
systems are typically implemented through declarative languages such as GSM (Hull et al., 2011).
It is therefore of interest to investigate the verification problem, not just on a Kripke semantics
such as AC-MAS, but on actual programs. As discussed, while GSM is a mainstream declarative
language for artifact-centric environments, alternative declarative approaches exist. In what follows
for the sake of generality we ground our discussion on a very wide class of declarative languages
and define the notion of artifact-centric program. Intuitively, an artifact-centric program (or AC
program) is a declarative description of a whole multi-agent system, i.e., a set of services, that
interact with the artifact system (see the discussion in the Introduction). Since artifact systems are
also typically implemented declaratively (Heath et al., 2013), AC programs will be used to encode
both the artifact system itself and the agents in the system. This also enables us to import into
the formalism the previously discussed features of views and windows typical in GSM and other
languages.
The rest of this section is organised as follows. We begin in Subsection 4.1 by defining AC
programs and giving their semantics in terms of AC-MAS. We then show that any AC-MAS that
results from an AC program is uniform. As long as the generated AC-MAS is bounded, by using the
results of Section 3.3, we deduce that any AC program admits an AC-MAS as its finite model. In this
362

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

context it is important to give constructive procedures for the generation of the finite abstraction; we
provide such a procedure here. This enables us to state that, under the assumptions we identify, AC
programs admit decidable verification by means of model checking their finite model. In Section 4.2
we ground and exemplify the constructions above on the Order-to-Cash Scenario introduced in
Subsection 2.4.
4.1 Verifying Artifact-Centric Programs
We start by defining the abstract syntax of AC programs.
Definition 4.1 (AC Programs) An artifact-centric program (or AC program) is a tuple ACP =
hD, U, , i, where:
 D is the programs database schema;
 U is the programs interpretation domain;
  = {0 , . . . , n } is the set of agent programs i = hDi , li0 , Acti i, where:
 Di  D is agent is database schema;
 li0  Di (U ) is agent is initial state (as a database instance);
 Acti is a set of local actions (~x), where  is the action name and ~x are the action
parameter names; without loss of generality, we assume that no two action types use the
same parameter names;
 each local action (~x) is associated with a precondition (~x) (~y ), i.e., an FO-formula
over Di , where ~y  ~x are free variables.
  = {~ (~x) (~z) | 
~ (~x) = h1 (~x1 ), . . . , n (~xn )i  Act1      Actn , ~x = h~x1 , . . . , ~xn i, ~z 
~x} represents the AC programs transitions expressed as a set of postconditions, i.e., FOformulas over action parameters as free variables. The formulas in  are defined over the
j
0 , where D
alphabet DAg  DAg
Ag = {Pi /qi | Pi /qi  D, j  n} is the set containing one
distinct relation symbol Pij , for each agent j  n and relation symbol Pi  D.
AC programs are defined modularly by giving all the agents programs, including their action
preconditions and postconditions. Notice that preconditions use relation symbols from the local
database only, while the programs transitions  refer to the local relations for all agents in an unconstrained way. More precisely, postconditions are global, i.e., they are associated with global
actions, rather than local ones. Indeed, a formula ~ (~x) (~z) describes the effects of the execution of
the global action 
~ (~z) (under a particular assignment to the parameters) where each agent i executes
i (~zi ). As reported below, this accounts for the intuition that in choosing the next action, an agent
can only rely on information locally stored, while its actions, as a result of mutual interactions, may
change the local state of any agent, i.e., they affect the global state of the system. Obviously, this
does not prevent the possibility of specifying actions that affect local states only. This is in line with
the AC-MAS semantics and the literature on interpreted systems.
Given a tuple ~x of variables and a tuplue ~u of elements from U such that |~x| = |~u|, by (~x) = ~u
we denote an assignment that binds the i-th component
of ~u to the i-th component of
S
S ~x. For a joint
action 
~ (~x) given as above, we let con(~
) = in con(i )  con(), var(~
) = in var(i ) 
363

fiB ELARDINELLI , L OMUSCIO & PATRIZI

var(), and free(~
) = ~x. An execution of 
~ (~x) with ground parameters ~u  U |~x| is the ground
action 
~ (~u), where ~v (resp. w)
~ is obtained by replacing each yi (resp. zi ) with the value occurring
in ~u at the same position as yi (resp. zi ) in ~x. Such replacements make both each i (~v ) and (w)
~
ground, that is, first-order sentences. Finally,
we
define
the
set
Con
of
all
constants
mentioned
ACP
S
S
in the AC program ACP , i.e., ConACP = ni=1 adom(li0 )  ~ Act con(~
).
The semantics of an AC program is given in terms of the AC-MAS induced by the agents that
the program implicitly defines. Formally, this is captured by the following definition.
Definition 4.2 (Induced Agents) Given an AC program ACP = hD, U, , i, an agent A =
hDi , Acti , P ri i is induced by ACP on the interpretation domain U iff for the agent program
i = hDi , li0 , Acti i   we have that:
 for every li  Di (U ) and ground action (~u) such that (~x)  Acti , it is the case that
(~u)  P ri (li ) iff (li , ) |= (~x) (~y ), for (~x) = ~u (recall that ~y  ~x).
Note that induced agents are agents as formalised in Definition 2.6. Agents defined as above are
composed to give the AC-MAS associated with an AC program.
Definition 4.3 (Induced AC-MAS) Given an AC program ACP = hD, U, , i and the set Ag =
{A0 , . . . , An } of all agents induced by ACP , the AC-MAS induced by ACP is the tuple PACP =
hAg, s0 ,  i, where:
 s0 = hl00 , . . . , ln0 i is the initial global state;
  is the global transition function defined by the following condition: s0   (s, 
~ (~u)), where
0
0
0
s = hl0 , . . . , ln i, s = hl0 , . . . , ln i, 
~ (~u) = h1 (~u0 ), . . . , n (~un )i, ~u = h~u0 , . . . , ~un i, iff for
every i  {0, . . . , n},
 (li , i ) |= i (~xi ) (~yi ) for i (~xi ) = ~ui ;
 adom(s0 )  adom(s)  ~u  con(~ (~x) );
0 , ) |= 
0
 (DAg  DAg
z ), for an assignment  such that (~x) = ~u, and DAg , DAg

~ (~
x) (~
j
are the DAg -instances such that, for every Pi  D and j  n, DAg (Pi ) = lj (Pi ) and
0 (P j ) = l0 (P ).
DAg
i
j
i

Given an AC program ACP , its induced AC-MAS represents the programs execution tree and
encodes all the data in the system. Intuitively, this is obtained by iteratively executing at each state,
starting from the initial one, all possible ground actions. Observe that all actions performed are
enabled by the respective protocols and that transitions can introduce only a bounded number of
new elements in the active domain, i.e., those bound to the action parameters. It follows from the
above that AC programs are parametric with respect to the interpretation domain, i.e., by replacing
the interpretation domain we obtain a different AC-MAS.
We assume that every program induces an AC-MAS whose transition relation is serial, i.e.,
states always have successors. This is a basic requirement that can be easily fulfilled, for instance,
by assuming that each agent has a skip action with a trivially true precondition and that when all
agents execute skip, the global state of the system remains unchanged. In the next Subsection we
present an example of one such program.
A significant feature of AC programs is that they induce uniform AC-MAS.
364

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

Lemma 4.4 Every AC-MAS P induced by an AC program ACP is uniform.
Proof. Since by definition adom(s0 )  ConACP , by Prop. 3.7 it is sufficient to consider only
the temporal transition relation . Consider s, s0 , s00  S and s000  L0      Ln such that
s  s0 ' s00  s000 for some witness . In particular, for every Aj  Ag, lj00 ' lj and lj000 ' lj0 , namely,
lj00 = (lj ) and lj000 = (lj0 ). Also, assume that there exists 
~ (~u) = h1 (~u1 ), . . . , n (~un )i  Act(U )
such that s0   (s, 
~ (~u)). First of all, j (~uj )  P rj (lj ) implies that (lj , j ) |= j (~xj ) (~yj ) for
j (~xj ) = ~uj . Since lj00 ' lj , by Prop. 3.3 we have that (lj00 , j0 ) |= j (~xj ) (~yj ) where j0 (~xi ) = 0 (~ui )
for any 0 extending  to ~ui . Thus, j (0 (~uj ))  P rj (lj00 ) for every j  Ag. Further, assume
0 , ) |= 
0 are the D -instances obtained as above and
that (DAg  DAg
z ), where DAg , DAg
Ag

~ (~
x) (~
00 , D 000 such that D 00 (P j ) = l00 (P ) = (l (P )), and
(~x) = ~u. Consider the DAg -instances DAg
i
j
i
j
Ag
Ag
i
000 (P j ) = l000 (P ) = (l0 (P )). Since s  s0 ' s00  s000 , we obtain that D
0 ' D 00  D 000
DAg

D
i
i
Ag
j
j
Ag
Ag
Ag
i
00  D 000 ,  0 ) |= 
0 (~
0 (~
for the same witness . In particular, (DAg
(~
z
),
where

x
)
=

u
)
for
any
0

~
(~
x
)
Ag
000
00
0
extending  to ~u. Finally, it can be easily checked that adom(s )  adom(s )   (~u)  con(~ (~x) ).
As a result, s000   (s00 , 
~ (0 (~u))), i.e., P is uniform.
We can now define what it means for an AC program to satisfy a specification, by referring to
its induced AC-MAS.
Definition 4.5 Given an AC program ACP , a FO-CTLK formula , and an assignment , we say
that ACP satisfies  under , written (ACP, ) |= , iff (PACP , s0 , ) |= .
Thus, the model checking problem for an AC program against a specification  is defined in terms
of the model checking problem for the corresponding AC-MAS PACP against .
The following result allows us to reduce the verification of any AC program with an infinite
interpretation domain U1 , that induces a b-bounded AC-MAS, to the
Pverification of an AC program
over a finite U2 . To show how this is constructed, we let NACP = i{1,...,n} max(~x)i {|~x|} be
the maximum number of different parameters that can occur in a joint action of ACP .
Lemma 4.6 Consider an AC program ACP1 = hD, U1 , i operating on an infinite interpretation
domain U1 and assume that its induced AC-MAS PACP1 = hAg1 , s10 , 1 i is b-bounded. Consider
a finite interpretation domain U2 such that ConACP1  U2 and |U2 |  2b + |ConACP1 | + NACP1
and the AC program ACP2 = hD, U2 , i. Then, the AC-MAS PACP2 = hAg2 , s20 , 2 i induced by
ACP2 is a finite abstraction of PACP1 .
Proof. Let Ag1 and Ag2 be the set of agents induced respectively by ACP1 and ACP2 , according
to Def. 4.2. Firstly, we prove that the set Ag1 and Ag2 of agents satisfy Def. 3.14, for Ag = Ag1
and Ag 0 = Ag2 . To this end, observe that because ACP1 and ACP2 differ only in U , by Def. 4.2,
D = D0 , and Act0 = Act. Thus, only requirement 3 of Def. 3.14 needs to be checked. For this, fix
i  {1, . . . , n} and assume that (~u)  P ri (li ). By Def. 4.2, we have that (li , ) |= i (~xi ) (~yi )
for (~xi ) = ~ui . By the assumption on |U2 |, since con()  ConACP1  U2 , |~u|  NACP1 , and
|adom(li )|  b, we can define an injective function  : adom(li )  ~u  ConACP1 7 U2 that is
the identity on ConACP1 . Thus, for li0 = (li ), we can easily extract from  a witness for li ' li0 .
Moreover, it can be seen that (y) = ~v and  0 (y) = ~v 0 = (~v ) are equivalent for . Then,
by applying Prop. 3.3 to li and li0 , we conclude that (li0 ,  0 ) |= i (~xi ) (~yi ). Hence, by Def. 4.2,
(~u0 )  P ri0 (li0 ) for ~u0 = (~u). So, we have shown the right-to-left part of requirement 3. The
left-to-right part can be shown similarly and more simply since U1 is infinite.
365

fiB ELARDINELLI , L OMUSCIO & PATRIZI

Thus, we have proven that Ag = Ag1 and Ag 0 = Ag2 are obtained as in Def. 3.14. Hence, the
assumption on Ag and Ag 0 in Def. 3.15 is fulfilled. We show next that also the remaining requirements of Def. 3.15 are satisfied. Obviously, since  is the same for ACP1 and ACP2 , by Def. 4.3,
s10 = s20 , so the initial states of PACP1 and PACP2 are the same. It remains to show that the
requirements on 1 and 2 are satisfied. We prove the right-to-left part. To this end, take two states
0 , . . . , l0 i in S and a joint action 
s1 = hl10 , . . . , l1n i, s01 = hl10
~ (~u) = h0 (~u0 ), . . . , n (~un )i 
1
1n
0
Act(U1 ) such that s1  1 (s1 , 
~ (~u)). Consider s1  s01 . By the assumptions on U2 , there exists an
injective function  : adom(s1 )adom(s01 )~u ConACP1 7 U2 that is the identity on ConACP1 (re0 ), . . . , (l0 )i
call that |adom(s1 )|, |adom(s01 )|  b). Then, for s2 = h(l10 ), . . . , (l1n )i, s02 = h(l10
1n
0
0
in S2 , we can extract from  a witness for s1  s1 ' s2  s2 . Moreover, it can be seen that for every
i (~xi ) and ~ (~x) , the assignments (~x) = ~u and  0 (~x) = ~u0 = (~u) are equivalent with respect to
s1  s01 and s2  s02 . Now, consider Def. 4.3 and recall that both PACP1 and PACP2 are AC-MAS induced by ACP1 and ACP2 , respectively. By applying Prop. 3.3, we have that, for i  {0, . . . , n},
0
(i) ((l1i ),  0 ) |= i (~xi ) (~yi ) iff (l1i , ) |= i (~xi ) (~yi ); (ii) (DAg2  DAg
,  0 ) |= ~ (~x) (~zi ) iff
2
0
(DAg1  DAg1 , ) |= ~ (~x) (~zi ), where each DAgi is obtained from si as detailed in Def. 4.3; (iii)
adom(s01 )  adom(s1 )  ~u  con(~ (~x) ) iff adom(s02 )  adom(s2 )  (~u)  con(~ (~x) ) by the defi~ ((~u))). So we have proved the right-to-left part
nition of . But then, it is the case that s02  2 (s2 , 
of the second requirement of Def. 3.15. The other direction follows similarly. Therefore, PACP2 is
an abstraction of PACP1 .
Intuitively, Lemma 4.6 shows that the following diagram commutes, where [U1 /U2 ] stands for
the replacement of U1 by U2 in the definition of ACP1 . Observe that since U2 is finite, one can
actually apply Def. 4.3 to obtain PACP2 ; in particular the transition function 2 can be computed.
Instead, PACP1 , and in particular 1 , cannot be directly computed from ACP1 by applying Def. 4.3,
as U1 is infinite.
ACP1


Def. 4.3

[U1 /U2 ]

ACP2

/ PACP
1


Def. 4.3

Def. 3.15

/ PACP
2

The following result, a direct consequence of Lemma 3.17 and Lemma 4.6, is the key conclusion
of this section.
Theorem 4.7 Consider an FO-CTLK formula , an AC program ACP1 operating on an infinite interpretation domain U1 and assume its induced AC-MAS PACP1 is b-bounded. Consider a finite interpretation domain U2 such that CACP1  U2 and |U2 |  2b + |CACP1 | + max{NACP1 , |var()|},
and the AC program ACP2 = hD, U2 , i. Then we have that:
ACP1 |=  iff ACP2 |= .
Proof. By Lemma 4.6 PACP2 is a finite abstraction of PACP1 . Moreover, |U2 |  2b +
|ConACP1 | + max{NACP1 , |var()|} implies |U2 |  2b + |ConACP1 | + |var()|. Hence, we can
apply Lemma 3.17 and the result follows.
The results shows that if the generated AC-MAS model is bounded, then any AC program can
be verified by model checking its finite abstraction, i.e., a bisimilar AC-MAS defined on a finite
366

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

interpretation domain. Note that the procedure is constructive: given an AC program ACP1 =
hD, U1 , i on an infinite domain U1 and an FO-CTLK formula , to check whether ACP1 satisfies
the specification , we first consider its finite abstraction ACP2 = hD, U2 , i defined on a finite
domain U2 satisfying the cardinality requirement of Theorem 4.7. Since U2 is finite, the induced
AC-MAS PACP2 is also finite; hence we can apply standard model checking techniques to verify
whether PACP2 satisfies . Finally, by definition of satisfaction for AC programs and Theorem 4.7,
we can transfer the result obtained to decide the model checking problem for the original infinite
AC program ACP1 against the specification .
Also observe that in the finite abstraction considered above the abstract interpretation domain
U2 depends on the number of distinct variables that the specification  contains. Thus, in principle,
to check the same AS program against a different specification 0 , one should construct a new
abstraction PACP20 using a different interpretation domain U20 , and then check 0 against it. However,
it can be seen that if the number of distinct variables of 0 does not exceed that of , the abstraction
PACP2 , used to check , can be re-used for 0 . Formally, let FO-CTLKk be the set of all FO-CTLK
formulas containing at most k distinct variables. We have the following corollary to Theorem 4.7.
Corollary 4.8 If |U2 |  2b + |ConACP1 | + max{NACP1 , k}, then, for every FO-CTLKk formula
, ACP1 |=  iff ACP2 |= .
This result holds in particular for k = NACP ; thus for FO-CTLKNACP formulas, we have an
abstraction procedure that is specification-independent.
Theorem 4.7 requires the induced AC-MAS to be bounded, which may seem a difficult condition
to check a priori. Note however that AC programs are declarative. It is therefore straightforward
to give postconditions that enforce that no transition will generate states violating the boundedness
requirement. The scenario in the next Subsection will exemplify this.
4.2 Verifying the Order-to-Cash Scenario
In Section 2.4 we introduced the order-to-cash scenario (Hull et al., 2011), a business process modelled as an artifact-centric system. Now we show how it can be formalised within the framework
of AC programs. For the sake of simplicity we assumed only three agents in our scenario: one
customer c, one manufacturer m and one supplier s. Further, the database schema Di for each agent
i  {c, m, s} was given as:
 Customer c: Dc = {Products(pcode, budget), PO(id , pcode, offer , status)};
 Manufacturer m: Dm = {PO(id , pcode, offer , status), MO(id , pcode, price, status)};
 Supplier s: Ds = {Materials(mcode, cost), MO(id , pcode, price, status)}.
Also, we assumed that in the initial state the only non-empty relations are Products and
Materials. Hence, the artifact-centric program ACPotc corresponding to the order-to-cash scenario
can be given formally as follows:
Definition 4.9 (ACPotc ) The artifact-centric program ACPotc is a tuple hDotc , Uotc , otc , otc i,
where:
 the programs database schema Dotc and interpretation domain Uotc are defined as in
Sec. 2.4, i.e., Dotc = Dc  Dm  Ds = {PO/4, MO/4, Products/2, Materials/2} and
Uotc is the set of all alphanumeric strings.
367

fiB ELARDINELLI , L OMUSCIO & PATRIZI

createPO(id,pcode)

= b.Products(b, pcode)
p, o, s.P O(id, p, o, s)

doneMO(id)

= pc, p.M O(id, pc, p, preparation)

acceptMO(id)

= pc, p.M O(id, pc, p, submitted)

requires id to be a fresh identifier for
POs, and the newly created PO to refer
to an existing product
requires id to refer to an existing MO
currently in preparation
which requires id to refer to an existing
MO that has been submitted

Table 1: Preconditions for the actions createPO(id , pcode), doneMO(id ), and acceptMO(id )
  = {c , m , s } is the set of agent specifications for the customer c, the manufacturer m
and the supplier s. Specifically, for each i  {c, m, s}, i = hDi , li0 , Acti , i i is such that:
 Di  D is agent is database schema as detailed above, i.e., Dc =
{Products/2, PO/4}, Dm = {PO/4, MO/4}, and Ds = {MO/4, Materials/2}.
 lc0 , lm0 , and ls0 are database instances in Dc (Uotc ), Dm (Uotc ), and Ds (Uotc ) respectively s.t. lc0 (Products) and ls0 (Materials) are non-empty, i.e., they contain some background information, while lc0 (PO), lm0 (PO), lm0 (MO) and ls0 (MO) are all empty.
 The sets of actions are given as
 Actc = {createPO(id , pcode), submitPO(id ), pay(id ), deletePO(id ), skip}.
 Actm = {createMO(id , price), doneMO(id ), shipPO(id ), deleteMO(id ), skip};
 Acts = {acceptMO(id ), rejectMO(id ), shipMO(id ), skip}.
Each action (~x) is associated with a precondition (~x) . The preconditions for the
actions createPO(id , pcode), doneMO(id ), acceptMO(id ) are reported in Table 1.
The remaining preconditions are omitted for brevity.
  = {~ (~x) | (~x))  Actc  Actm  Acts }, where
DAg = {P roductsc , P Oc , P Om , M Om , M aterialss , M Os }.
Table 2 illustrates only the postcondition of the joint action

~ (id, pc, m1 , m2 ) = hcreatePO(id, pc), doneMO(m1 ), acceptMO(m2 )i.
The others are omitted.
In the postcondition in Table 2 variables (from V ) and constants (from U ) are distinguished by fonts
v and c, respectively. The first two lines impose that the interpretation of the relations Products and
Materials, occurring only in the local database of agents c (customer) and s (supplier), respectively,
remain unchanged. The third line states that the relation PO of agents c and m (manufacturer)
contains a new procurement order, with identifier id and product code pc, both taken from the
parameters of action createPO. Observe that, although executed by the customer, this action affects
also the local state of the manufacturer. The next 3 lines express that the local PO relation of c and
m, in addition to the newly added item, contains also all, and only, the items present before the
action execution. The next conjunct (3 lines) states that new identifiers must be unique within each
local PO relation. Notice that while this cannot be guaranteed by agent c when executing createPO
368

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS


~x.Products c (~x)  Products c0 (~x) 

~y .Materials s (~y )  Materials s0 (~y ) 

c
c0
m0
b.Products
(pc,
b)

PO
(id,
pc,
b,
prepared)

PO
(id,
pc,
b,
prepared)


i, pc, b, s.i 6= id 

(PO c0 (i, pc, b, s)  PO c (i, pc, b, s)) 

(PO m0 (i, pc, b, s)  PO c (i, pc, b, s)) 


i, pc, b, s, pc0 , b0 , s0 .
(PO c0 (i, pc, b, s)  PO c0 (i, pc0 , b0 , s0 )  (pc = pc0  b = b0  s = s0 )) 

(PO m0 (i, pc, b, s)  PO m0 (i, pc0 , b0 , s0 )  (pc = pc0  b = b0  s = s0 )) 



m1 = m2  m3 , pc, p, s.
(MO m (m3 , pc, p, s)  MO m0 (m3 , pc, p, s))

(MO s (m3 , pc, p, s)  MO s0 (m3 , pc, p, s)) 



m1 6= m2  pc, p, s.MO m (m1 , pc, p, s)  (
MO m0 (m1 , pc, p, s)  MO m0 (m1 , pc, p, submitted)

MO s0 (m1 , pc, p, s)  MO s0 (m1 , pc, p, submitted)) 
pc, p, s.MO s (m2 , pc, p, s)  (
MO s0 (m2 , pc, p, s)  MO s0 (m2 , pc, p, accepted) 

MO m0 (m2 , pc, p, s)  MO m0 (m2 , pc, p, accepted)) 



m3 , pc, p, s.m1 6= m2  m1 6= m3 
(MO m0 (m3 , pc, p, s)  MO m (m3 , pc, p, s))

(MO s0 (m3 , pc, p, s)  MO m (m3 , pc, p, s))

Table 2: The postcondition ~ (id,pc,m1 ,m2 ) for the joint action 
~ (id, pc, m1 , m2 )
hcreatePO(id, pc), doneMO(m1 ), acceptMO(m2 )i

369

=

fiB ELARDINELLI , L OMUSCIO & PATRIZI

(as it cannot access relation PO of m), this value might actually be returned automatically by the
system, and then used as input by the agent. The successive 3 lines state that if m1 and m2 coincide,
i.e., two distinct operations are to be executed on the same material order m1 , then the action has
no effect on any local MO relation. On the contrary, as the successive 6 lines state, if m1 6= m2
then in the local MO relations of both agent s and m the material order with id m1 changes its state
to submitted and the one with id m2 to accepted. Finally, the last 3 lines state that all material
orders not involved in the executed (joint) action are propagated unchanged to their respective local
relations.
Notice that although actions are typically conceived to manipulate artifacts of a specific class,
their preconditions and postconditions may depend on artifact instances of different classes. For
example, note that the action createMO manipulates MO artifacts, but its precondition depends
on PO artifacts. Also, we stress that action executability depends not only on the status attribute
of an artifact, but on the actual data content of the whole database, i.e., of all the other artifacts.
Similarly, action executions affect not W
only status attributes. Most importantly, by using first-order
formulas such as b = x1 , . . . , xb+1 i6=j (xi = xj ) in the postcondition , we can guarantee that
the AC program in question is bounded and is therefore amenable to the abstraction methodology
of Section 4.
We now define the agents induced by the AC program ACPotc given above according to Definition 4.2.
Definition 4.10 Given the AC program ACPotc = hDotc , Uotc , otc i, the agents Ac , Am and As
induced by ACPotc are defined as follows:
 Ac = hDc , Actc , P rc i, where (i) Dc is as above; (ii) Actc = c = {createPO, submitPO,
pay, deletePO}; and (iii) (~u)  P rc (lc ) iff (lc , ) |= (~x) (~y ) for (~x) = ~u.
 Am = hDm , Actm , P rm i, where (i) Dm is as above; (ii) Actm = m =
{createMO, doneMO, shipPO, deleteMO}; and (iii) (~u)  P rm (lm ) iff (lm , ) |=
(~x) (~y ) for (~x) = ~u.
 As = hDs , Acts , P rs i, where (i) Ds is as above; (ii) Acts = s = {acceptMO, rejectMO,
shipMO}; and (iii) (~u)  P rs (ls ) iff (ls , ) |= (~x) (~y ) for (~x) = ~u.
Note that the agents Ac , Am and As strictly correspond to the agents defined in Def. 2.12.
In particular, by the definition of Am above we can see that createMO(id , price)  P rm (lm )
if and only if the interpretation lm (P O) of the relation PO in the local state lm contains a tuple hid, pc, o, preparedi for some product pc and offer o; while doneMO(mo id )  P rm (lm ) iff
lm (M O) contains a tuple with id mo id and status preparation. As a result, the formal preconditions for createMO and doneMO satisfy the intended meaning of these actions.
We can now define the AC-MAS generated by the set of agents Ag = {Ac , Am , As } according
to Definition 4.3.
Definition 4.11 Given the AC program ACPotc and the set Ag = {Ac , Am , As } of agents induced
by ACPotc , the AC-MAS induced by ACPotc is the tuple Potc = hAg, s0otc , otc i, where:
 s0otc = hlc0 , lm0 , ls0 i is the initial global state, where the only non-empty relations are
Products and Materials;

370

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

 otc is the global transition function defined according to Def. 4.3.
The AC-MAS generated by the AC program ACPotc corresponds closely to the AC-MAS appearing in Def. 2.13. As an example we give a snippet of the transition function otc by considering the global action (~u) = hcreatePO(id, pcode), doneMO(m1 ), acceptMO(m2 )i enabled
by the respective protocols in a global state s. By the definition of actions createPO(id, pcode),
doneMO(m1 ), and acceptMO(m2 ) we have that li (s)  P ri for i  {c, m, s} implies that the
Products relation contains information about the product pcode. Also, the interpretation of the relation MO contains the tuples hm1 , p, pr, preparationi and hm2 , p0 , pr0 , submittedi for some prod(~
u)

ucts p and p0 . By the definition of otc it follows that for every s0  Sotc , s  s0 implies that
0 , ) |= 
0
0
(DAg  DAg
(~
u) (id, pcode, m1 , m2 ), where DAg and DAg are obtained from s and s by
renaming the relation symbols, (~u) = hcreatePO(id, pcode), doneMO(m1 ), acceptMO(m2 )i,
and  is an interpretation of the formal parameters id, pcode, m1 and m2 in Uotc . In particu0
lar, the interpretation of the relation PO in DAg
extends both DAg (P Oc ) and DAg (P Om ) with
the tuple hid, pc, b, preparedi, where id is a fresh identifier. The tuples for the material orders
0 (M O m ) (resp. D 0 (M O s )) and become hm , p, pr, submittedi
m1 and m2 are updated in DAg
1
Ag
0
0
(resp. hm2 , p , pr , acceptedi). In light of the specification of (~u) for action (~u), no other element is updated in the transition. Finally, notice that these extensions are indeed the interpretations
of PO and MO in s0 . Thus, the semantics satisfies the intended meaning of the actions. It can also
be checked that, in line with the discussion in Section 2.4, a full version of the function otc given
above can easily encode the artifacts lifecycles as given in Figure 2.
We now proceed to exploit the methodology of Section 4 to verify the AC program ACPotp .
We use the formula match from Section 2.4 as an example specification; analogous results can be
obtained for the other formulas. Observe that according to Definition 4.3 the AC-MAS induced by
ACPotp has infinitely many states. We assume two interpretations for the relations Products and
Materials, which determine an initial state D0 . Consider the maximum number max of parameters
and the constants C in the operations in c , m and s . In the case under analysis we have
that max = 2. We earlier remarked that formulas such as b in the postcondition of actions force
the AC-MAS Potc corresponding to ACPotc to be bounded. Here we have that Potc is b-bounded.
According to Corollary 3.19, we can therefore consider any finite domain U 0 such that
U 0  D0  C  con(match )
 D0 (Products)  D0 (Materials)  C
and such that
|U 0 |  2b + |D0 | + |C | + |con(match )| + max
= 2b + |D0 | + |C | + 2
For instance, we can consider any subset U 0 of Uotc satisfying the conditions above. Given that U 0
satisfies the hypothesis of Theorem 4.7, it follows that the AC program ACPotc over Uotc satisfies
match if and only if ACPotc over U 0 does. But the AC-MAS induced by the latter is a finite-state
system, which can be constructively built by running the AC program ACPotc on the elements in
U 0 . Thus, ACPotc |= match is a decidable instance of model checking that can be therefore solved
by means of standard techniques.

371

fiB ELARDINELLI , L OMUSCIO & PATRIZI

A manual check on the finite model indeed reveals that match , budget and cost are satisfied
in the finite model, whereas fulfil is not. By Corollary 3.19 the AC-MAS Potc induced by ACPotp
satisfies the same specifications. Hence, in view of Definition 4.5, we conclude that the artifactcentric program ACPotp satisfies match , budget and cost but does not satisfy fulfil . This is in
line with our intuitions of the scenario.

5. Conclusions and Future Work
In this paper we put forward a methodology for verifying agent-based artifact-centric systems. We
proposed AC-MAS, a novel semantics incorporating first-order features, that can be used to reason about multi-agent systems in an artifact-centric setting. We observed that the model checking
problem for these structures against specifications given in a first-order temporal-epistemic logic is
undecidable and proceeded to identify a suitable fragment for which decidability can be retained.
Specifically, we showed that the class of bounded, uniform AC-MAS we identified admit finite abstractions that preserve the first-order specification language we introduced. Previous results in the
literature, discussed in Subsection 1.2, limit the preservation to fragments of the quantified language
and do not allow the interplay between first-order quantifiers and modalities.
We explored the complexity of the model checking problem in this context and showed this to
be EXPSPACE-complete. While this is obviously a hard problem, we need to consider that these
are first-order structures which normally lead to problems with high complexity. We note that the
abstract interpretation domain is actually linear in the size of the bound considered.
Mindful of the practical needs for verification in artifact-centric systems, we then explored how
finite abstractions can actually be built. To this end, rather than investigating one specific datacentric language, we defined a general class of declarative artifact-centric programs. We showed
that these systems admit uniform AC-MAS as their semantics. Under the assumption of bounded
systems we showed that model checking these multi-agent system programs is decidable and gave
a constructive procedure operating on bisimilar, finite models. While the results are general, they
can be instantiated for various artifact-centric languages. For instance, Belardinelli et al. (2012b)
explore finite abstractions of GSM programs by using these results.
We exemplified the methodology put forward on a use case consisting of several agents purchasing and delivering products. While the system has infinitely many states we showed it admits a
finite abstraction that can be used to verify a variety of specifications on the system.
A question left open in the present paper is whether the uniform condition we provided is tight.
While we showed this to be a sufficient condition, we did not explore whether this is necessary for
finite abstractions or whether more general properties can be given. In this context it is of interest
that artifact-centric programs generate uniform structures. Also, it will be worthwhile to explore
whether a notion related to uniformity can be applied to other domains in AI, for example to retain
decidability of specific calculi. This would appear to be the case as preliminary studies in the
Situation Calculus demonstrate (De Giacomo, Lesperance, & Patrizi, 2012).
On the application side, we are also interested in exploring ways to use the results of this paper to
build a model checker for artifact-centric MAS. Previous efforts in this area (Gonzalez, Griesmayer,
& Lomuscio, 2012) are limited to finite state systems. It would therefore be of great interest to
construct finite abstractions on the fly to check practical e-commerce scenarios such as the one here
discussed.

372

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

References
Abiteboul, S., Hull, R., & Vianu, V. (1995). Foundations of Databases. Addison-Wesley.
Alonso, G., Casati, F., Kuno, H. A., & Machiraju, V. (2004). Web Services - Concepts, Architectures
and Applications. Data-Centric Systems and Applications. Springer.
Alves, A., Arkin, A., Askary, S., Barreto, C., Ben, Curbera, F., Ford, M., Goland, Y., Guzar, A.,
Kartha, N., Liu, C. K., Khalaf, R., Konig, D., Marin, M., Mehta, V., Thatte, S., van der Rijn,
D., Yendluri, P., & Yiu, A. (2007). Web Services Business Process Execution Language Version 2.0. Tech. rep., OASIS Web Services Business Process Execution Language (WSBPEL)
TC.
Bagheri Hariri, B., Calvanese, D., De Giacomo, G., Deutsch, A., & Montali, M. (2013). Verification
of Relational Data-centric Dynamic Systems with External Services. In Hull, R., & Fan, W.
(Eds.), Proceedings of the 32nd ACM SIGMOD-SIGACT-SIGART Symposium on Principles
of Database Systems (PODS13), pp. 163174. ACM.
Baresi, L., Bianculli, D., Ghezzi, C., Guinea, S., & Spoletini, P. (2007). Validation of Web Service
Compositions. IET Software, 1(6), 219232.
Baukus, K., & van der Meyden, R. (2004). A knowledge based analysis of cache coherence. In
Davies, J., Schulte, W., & Barnett, M. (Eds.), Proceedings of the 6th International Conference on Formal Engineering Methods (ICFEM04), Vol. 3308 of Lecture Notes in Computer
Science, pp. 99114. Springer.
Belardinelli, F., & Lomuscio, A. (2012). Interactions between Knowledge and Time in a First-Order
Logic for Multi-Agent Systems: Completeness Results. Journal of Artificial Intelligence Research, 45, 145.
Belardinelli, F., Lomuscio, A., & Patrizi, F. (2011a). A Computationally-Grounded Semantics for
Artifact-Centric Systems and Abstraction Results. In Walsh, T. (Ed.), Proceedings of the 22nd
International Joint Conference on Artificial Intelligence (IJCAI12), pp. 738743. AAAI.
Belardinelli, F., Lomuscio, A., & Patrizi, F. (2011b). Verification of Deployed Artifact Systems via
Data Abstraction. In Kappel, G., Maamar, Z., & Nezhad, H. R. M. (Eds.), Proceedings of
the 9th International Conference on Service-Oriented Computing (ICSOC11), Vol. 7084 of
Lecture Notes in Computer Science, pp. 142156. Springer.
Belardinelli, F., Lomuscio, A., & Patrizi, F. (2012a). An Abstraction Technique for the Verification
of Artifact-Centric Systems. In Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Proceedings of
the 13th International Conference on Principles of Knowledge Representation and Reasoning
(KR12). AAAI.
Belardinelli, F., Lomuscio, A., & Patrizi, F. (2012b). Verification of gsm-based artifact-centric
systems through finite abstraction. In Liu, C., Ludwig, H., Toumani, F., & Yu, Q. (Eds.), Proceedings of the 10th International Conference on Service-Oriented Computing (ICSOC12),
Vol. 7636 of Lecture Notes in Computer Science, pp. 1731. Springer.
Berardi, D., Calvanese, D., De Giacomo, G., Hull, R., & Mecella, M. (2005). Automatic Composition of Transition-based Semantic Web Services with Messaging. In Bohm, K., Jensen,
C. S., Haas, L. M., Kersten, M. L., Larson, P.-A., & Ooi, B. C. (Eds.), Proceedings of the 31st
International Conference on Very Large Data Bases (VLDB05), pp. 613624. ACM.
373

fiB ELARDINELLI , L OMUSCIO & PATRIZI

Berardi, D., Cheikh, F., Giacomo, G. D., & Patrizi, F. (2008). Automatic Service Composition via
Simulation. International Journal of Foundations of Computer Science, 19(2), 429451.
Bertoli, P., Pistore, M., & Traverso, P. (2010). Automated Composition of Web Services via Planning in Asynchronous Domains. Artificial Intelligence, 174(3-4), 316361.
Bhattacharya, K., Gerede, C. E., Hull, R., Liu, R., & Su, J. (2007). Towards Formal Analysis
of Artifact-Centric Business Process Models. In Alonso, G., Dadam, P., & Rosemann, M.
(Eds.), Proceedings of the 5th International Conference on Business Process Management
(BPM07), Vol. 4714 of Lecture Notes in Computer Science, pp. 288304. Springer.
Blackburn, P., de Rijke, M., & Venema, Y. (2001). Modal Logic, Vol. 53 of Cambridge Tracts in
Theoretical Computer Science. Cambridge University Press.
Calvanese, D., De Giacomo, G., Lenzerini, M., Mecella, M., & Patrizi, F. (2008). Automatic Service
Composition and Synthesis: the Roman Model. IEEE Data Engineering Bulletin, 31(3), 18
22.
Ciobaca, S., Delaune, S., & Kremer, S. (2012). Computing Knowledge in Security Protocols Under
Convergent Equational Theories. Journal of Automated Reasoning, 48(2), 219262.
Clarke, E. M., Grumberg, O., & Peled, D. A. (1999). Model Checking. The MIT Press.
Cohn, D., & Hull, R. (2009). Business Artifacts: A Data-Centric Approach to Modeling Business
Operations and Processes. IEEE Data Engineering Bulletin, 32(3), 39.
Damaggio, E., Deutsch, A., & Vianu, V. (2012). Artifact Systems with Data Dependencies and
Arithmetic. ACM Transactions on Database Systems, 37(3), 22:122:36.
Damaggio, E., Hull, R., & Vaculn, R. (2011). On the Equivalence of Incremental and Fixpoint
Semantics for Business Artifacts with Guard-Stage-Milestone Lifecycles. In Rinderle-Ma, S.,
Toumani, F., & Wolf, K. (Eds.), Proceedings of the 9th International Conference on Business
Process Management (BPM11), Vol. 6896 of Lecture Notes in Computer Science, pp. 396
412. Springer.
De Giacomo, G., Lesperance, Y., & Patrizi, F. (2012). Bounded Situation Calculus Action Theories
and Decidable Verification. In Brewka, G., Eiter, T., & McIlraith, S. A. (Eds.), Proceedings of
the 13th International Conference on Principles of Knowledge Representation and Reasoning
(KR12). AAAI.
Dechesne, F., & Wang, Y. (2010). To Know or not to Know: Epistemic Approaches to Security
Protocol Verification. Synthese, 177(Supplement-1), 5176.
Deutsch, A., Hull, R., Patrizi, F., & Vianu, V. (2009). Automatic Verification of Data-centric Business Processes. In Fagin, R. (Ed.), Proceedings of the 12th International Conference on
Database Theory (ICDT09), Vol. 361 of ACM International Conference Proceeding Series,
pp. 252267. ACM.
Deutsch, A., Sui, L., & Vianu, V. (2007). Specification and Verification of Data-Driven Web Applications. Journal of Computer and System Sciences, 73(3), 442474.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning About Knowledge. The MIT
Press.

374

fiV ERIFICATION OF AGENT-BASED A RTIFACT S YSTEMS

Gammie, P., & van der Meyden, R. (2004). MCK: Model Checking the Logic of Knowledge. In
Alur, R., & Peled, D. (Eds.), Proceedings of 16th International Conference on Computer
Aided Verification (CAV04), Vol. 3114 of Lecture Notes in Computer Science, pp. 479483.
Springer.
Gerede, C. E., & Su, J. (2007). Specification and Verification of Artifact Behaviors in Business
Process Models. In Kramer, B. J., Lin, K.-J., & Narasimhan, P. (Eds.), Proceedings of the 5th
International Conference on Service-Oriented Computing (ICSOC07), Vol. 4749 of Lecture
Notes in Computer Science, pp. 181192. Springer.
Gonzalez, P., Griesmayer, A., & Lomuscio, A. (2012). Verifying GSM-Based Business Artifacts.
In Goble, C. A., Chen, P. P., & Zhang, J. (Eds.), Proceedings of the 19th IEEE International
Conference on Web Services (ICWS12), pp. 2532. IEEE.
Grohe, M. (2001). Generalized Model-Checking Problems for First-Order Logic. In Ferreira, A.,
& Reichel, H. (Eds.), Proceedings of the 18th Annual Symposium on Theoretical Aspects of
Computer Science (STACS01), Vol. 2010 of Lecture Notes in Computer Science, pp. 1226.
Springer.
Heath, F. T., Boaz, D., Gupta, M., Vaculn, R., Sun, Y., Hull, R., & Limonad, L. (2013). Barcelona:
A Design and Runtime Environment for Declarative Artifact-Centric BPM. In Basu, S., Pautasso, C., Zhang, L., & Fu, X. (Eds.), Proceedings of the 11th International Conference on
Service-Oriented Computing (ICSOC13), Vol. 8274 of Lecture Notes in Computer Science,
pp. 705709. Springer.
Hull, R. (2008). Artifact-Centric Business Process Models: Brief Survey of Research Results and
Challenges. In Meersman, R., & Tari, Z. (Eds.), Proceedings (part II) of Confederated International Conferences, CoopIS, DOA, GADA, IS, and ODBASE 2008 (On the Move to
Meaningful Internet Systems: OTM08), Vol. 5332 of Lecture Notes in Computer Science,
pp. 11521163. Springer.
Hull, R., Damaggio, E., De Masellis, R., Fournier, F., Gupta, M., Heath, III, F. T., Hobson, S., Linehan, M., Maradugu, S., Nigam, A., Sukaviriya, P. N., & Vaculin, R. (2011). Business Artifacts
with Guard-Stage-Milestone Lifecycles: Managing Artifact Interactions with Conditions and
Events. In Eyers, D. M., Etzion, O., Gal, A., Zdonik, S. B., & Vincent, P. (Eds.), Proceedings
of the 5th ACM International Conference on Distributed Event-Based Systems (DEBS11),
pp. 5162. ACM.
Hull, R., Narendra, N. C., & Nigam, A. (2009). Facilitating Workflow Interoperation Using ArtifactCentric Hubs. In Baresi, L., Chi, C.-H., & Suzuki, J. (Eds.), Proceedings of the 7th International Conference on Service-Oriented Computing (ICSOC-ServiceWave 09), Vol. 5900 of
Lecture Notes in Computer Science, pp. 118. Springer.
Kacprzak, M., Nabialek, W., Niewiadomski, A., Penczek, W., Polrola, A., Szreter, M., Wozna, B.,
& Zbrzezny, A. (2008). VerICS 2007 - a Model Checker for Knowledge and Real-Time.
Fundamenta Informaticae, 85(1-4), 313328.
Kupferman, O., Vardi, M. Y., & Wolper, P. (2000). An Automata-Theoretic Approach to BranchingTime Model Checking. Journal of the ACM, 47(2), 312360.
Lomuscio, A., Penczek, W., Solanki, M., & Szreter, M. (2011). Runtime Monitoring of Contract
Regulated Web Services. Fundamenta Informaticae, 111(3), 339355.
375

fiB ELARDINELLI , L OMUSCIO & PATRIZI

Lomuscio, A., Qu, H., & Raimondi, F. (2009). MCMAS: A Model Checker for the Verification of
Multi-Agent Systems. In Bouajjani, A., & Maler, O. (Eds.), Proceedings of the 21st International Conference on Computer Aided Verification (CAV09), Vol. 5643 of Lecture Notes in
Computer Science, pp. 682688. Springer.
Lomuscio, A., Qu, H., & Solanki, M. (2012). Towards Verifying Contract Regulated Service Composition. Autonomous Agents and Multi-Agent Systems, 24(3), 345373.
Lomuscio, A., & Raimondi, F. (2006). The Complexity of Model Checking Concurrent Programs
Against CTLK Specifications. In Baldoni, M., & Endriss, U. (Eds.), Proceedings of the 4th
International Workshop on Declarative Agent Languages and Technologies (DALT06), Selected, Revised and Invited Papers, Vol. 4327 of Lecture Notes in Computer Science, pp.
2942. Springer.
Marin, M., Hull, R., & Vaculn, R. (2013). Data Centric BPM and the Emerging Case Management
Standard: A Short Survey. In La Rosa, M., & Soffer, P. (Eds.), Proceedings of Business
Process Management Workshops - BPM 2012 International Workshops. Revised Papers, Vol.
132 of Lecture Notes in Business Information Processing, pp. 2430. Springer.
Meyer, J.-J. C., & van der Hoek, W. (1995). Epistemic Logic for AI and Computer Science, Vol. 41
of Cambridge Tracts in Theoretical Computer Science. Cambridge University Press.
Nigam, A., & Caswell, N. S. (2003). Business Artifacts: An Approach to Operational Specification.
IBM Systems Journal, 42(3), 428445.
Nooijen, E., Fahland, D., & Dongen, B. V. (2013). Automatic Discovery of Data-Centric and
Artifact-Centric Processes. In La Rosa, M., & Soffer, P. (Eds.), Proceedings of Business
Process Management Workshops - BPM 2012 International Workshops. Revised Papers, Vol.
132 of Lecture Notes in Business Information Processing, pp. 316327. Springer.
Papadimitriou, C. H. (1994). Computational complexity. Addison-Wesley.
Parikh, R., & Ramanujam, R. (1985). Distributed Processes and the Logic of Knowledge. In Parikh,
R. (Ed.), Logic of Programs, Vol. 193 of Lecture Notes in Computer Science, pp. 256268.
Springer.
Singh, M. P., & Huhns, M. N. (2005). Service-Oriented Computing: Semantics, Processes, Agents.
John Wiley & Sons.
Wooldridge, M. (2000). Computationally Grounded Theories of Agency. In Proceedings of the 4th
International Conference on Multi-Agent Systems (ICMAS00), pp. 1322. IEEE.
Wooldridge, M. (2001). Introduction to Multiagent Systems. John Wiley & Sons.

376

fiJournal of Artificial Intelligence Research 51 (2014) 133164

Submitted 05/14; published 09/14

Text Rewriting Improves Semantic Role Labeling
Kristian Woodsend
Mirella Lapata

k.woodsend@ed.ac.uk
mlap@inf.ed.ac.uk

Institute for Language, Cognition and Computation
School of Informatics, University of Edinburgh
10 Crichton Street, Edinburgh EH8 9AB

Abstract
Large-scale annotated corpora are a prerequisite to developing high-performance NLP
systems. Such corpora are expensive to produce, limited in size, often demanding linguistic
expertise. In this paper we use text rewriting as a means of increasing the amount of labeled
data available for model training. Our method uses automatically extracted rewrite rules
from comparable corpora and bitexts to generate multiple versions of sentences annotated
with gold standard labels. We apply this idea to semantic role labeling and show that
a model trained on rewritten data outperforms the state of the art on the CoNLL-2009
benchmark dataset.

1. Introduction
Recent years have witnessed increased interest in the automatic identification and labeling
of the semantic roles conveyed by sentential constituents (Gildea & Jurafsky, 2002). The
goal of the semantic role labeling task is to discover the relations that hold between a
predicate and its arguments in a given input sentence (e.g., who did what to whom,
when, where, and how).
(1)

[Mrs. Yeargin]A0 [gave]V [the questions and answers]A1 [two days before the
examination]TMP to [two low-ability geography classes]ARG2 .

In sentence (1), A0 represents the Agent or giver, A1 represents the theme or thing given,
A2 represents the Recipient, TMP is a temporal modifier indicating when the action took
place, and V determines the boundaries of the predicate. The semantic roles in the example
are labeled in the style of PropBank (Palmer, Gildea, & Kingsbury, 2005), a broad-coverage
human-annotated corpus of semantic roles and their syntactic realizations. Under the PropBank annotation framework each predicate is associated with a set of core roles (named A0,
A1, A2, and so on) whose interpretations are specific to that predicate1 and a set of adjunct
roles such as location or time whose interpretation is common across predicates (e.g., two
days before the examination in sentence (1) above).
This type of semantic information is shallow but relatively straightforward to infer automatically and useful for the development of broad coverage, domain-independent language
understanding systems. Indeed, the analysis produced by existing semantic role labelers has
been shown to benefit a wide spectrum of applications ranging from information extraction
(Surdeanu, Harabagiu, Williams, & Aarseth, 2003) and question answering (Shen & Lapata,
1. More precisely, A0 and A1 have a common interpretation across predicates as proto-agent and protopatient in the sense described by Dowty (1991).
c
2014
AI Access Foundation. All rights reserved.

fiWoodsend & Lapata

Source
1. The retreating guerrillas were soon pursued by the government forces.
2. A survey conducted by the Gallup Poll
last summer indicated that one in four
Americans takes cues from the stars or believes in ghosts.
3. The examiner who was kind let the student finish his lunch.
4. Because she didnt know the rules, she
died.
5. Mexico City, the biggest city in the world,
has many interesting archaeological sites.
6. The arrival of the train was unexpected.

Target
Government forces soon pursued the retreating guerrillas.
A survey was conducted by the Gallup
Poll last summer. It indicated that one in
four Americans takes cues from the stars
or believes in ghosts.
The kind examiner let the student finish
his lunch.
She died, because she didnt know the
rules.
Mexico City has many interesting archaeological sites.
The trains arrival was unexpected.

Table 1: Examples of syntactic rewriting.

2007), to machine translation (Wu & Fung, 2009) and summarization (Melli, Wang, Liu,
Kashani, Shi, Gu, Sarkar, & Popowich, 2005).
Most SRL systems to date conceptualize the semantic role labeling task as a supervised
learning problem and rely on role-annotated data for model training. Supervised methods
deliver reasonably good performance, with F1-scores in the low eighties on standard test
collections for English. They rely primarily on syntactic features (such as path features)
in order to identify and classify roles. This has been a mixed blessing as the path from an
argument to the predicate can be very informative but also quite complicated. Many paths
through the parse tree are likely to occur a relatively small number of times (or not at all)
resulting in very sparse information for the classifier to learn from. Even if the training
data includes examples for a specific predicate and set of arguments, unless a test sentence
contains them in the same syntactic structure, then as far as the classifier is concerned, the
labeling of items within the two sentences is unrelated.
Our idea is to use use rewrite rules in order to create several syntactic variants for
a sentence, thus alleviating the training requirements for semantic role labeling. Rewrite
rules are typically synchronous grammar rules defining how a sequence of source terminals
and nonterminals rewrites to a sequence of target terminals and nonterminals. Such rules
are most often extracted from monolingual corpora containing parallel translations of the
same source text (Barzilay & McKeown, 2001; Pang, Knight, & Marcu, 2003), bilingual
corpora consisting of documents and their translations (Bannard & Callison-Burch, 2005a;
Callison-Burch, 2007), or comparable corpora such as Wikipedia revision histories (Coster
& Kauchak, 2011; Woodsend & Lapata, 2011). Examples of rewrites are given in Table 1.
These include transforming passive to active sentences (see sentence pair (1) in Table 1),
splitting a long and complicated sentence into several shorter ones (see (2) in Table 1),
removing redundant parts of a sentence (see (3) in Table 1), reordering parts in a sentence
(see (4) in Table 1), deleting appositives (see (5) in Table 1), transforming a prepositional
phrase into a genitive (see (6) in Table 1), and so on.
134

fiText Rewriting Improves Semantic Role Labeling

We automatically extract syntactic rewrite rules from corpora and use them to generate
multiple versions of role annotated sentences whilst preserving their original semantic roles.
We therefore expand the training data with a wide range of syntactic variations for each
predicate-argument combination and then learn a semantic role labeler on the expanded
dataset. The approach we describe essentially increases the size of the training data by
creating many different syntactic variations for different predicates and their roles.
Rewrite rules have been previously deployed in a variety of text-to-text generation applications ranging from summarisation (Galley & McKeown, 2007; Yamangil & Nelken, 2008;
Cohn & Lapata, 2009; Ganitkevitch, Callison-Burch, Napoles, & Van Durme, 2011), to
question answering (Wang, Smith, & Mitamura, 2007), information retrieval (Park, Croft,
& Smith, 2011), simplification (Zhu, Bernhard, & Gurevych, 2010; Woodsend & Lapata,
2011; Feblowitz & Kauchak, 2013), and machine translation (Callison-Burch, 2008; Marton, Callison-Burch, & Resnik, 2009; Ganitkevitch, Cao, Weese, Post, & Callison-Burch,
2012). However, the application of text rewriting as a means of increasing the amount of
labeled data available for model training is novel to our knowledge. We show experimentally, that syntactic transformations improve SRL performance beyond the state of the art
when using the CoNLL-2009 benchmark dataset and the best scoring system (Bjorkelund,
Hafdell, & Nugues, 2009). Importantly, our approach can be used in combination with any
SRL learner or role-annotated data. Moreover, it is not specifically tied to the SRL task
or the employed learning model and dataset. Rewrite rules could be used to expand the
training data for other tasks that make use of syntactic features such as semantic parsing
(Kwiatkowski, 2012) and textual entailment (Mehdad, Negri, & Federico, 2010; Wang &
Manning, 2010).
In the following, we present an overview of related work (Section 2) and then describe
how rewrite rules are automatically extracted and filtered for correctness (Section 3). Section 4 details our experiments and Section 5 reports our results.

2. Related Work
The idea of transforming sentences to make them more amenable to NLP technology dates
back to Chandrasekar, Doran, and Srinivas (1996) who argue that simpler sentences would
decrease the likelihood for an incorrect parse. To this end, they employ mostly hand-crafted
syntactic rules aimed at splitting long and complicated sentences into simpler ones. Klebanov, Knight, and Marcu (2004) preprocess texts into Easy Access Sentences, i.e., sentences
consisting of one finite verb and its dependents in order to facilitate information seeking applications such as summarization or information retrieval in accessing factual information.
In a similar vein, Vickrey and Koller (2008) devise a large number of hand-written rules
in order to simplify sentences for semantic role labeling. They present a log-linear model
which jointly learns to select the best simplification (out of a possibly exponential space
of candidates) and role labeling. Kundu and Roth (2011) use textual transformations for
domain adaptation. Rather than training a new model on out-of-domain data, they propose
to rewrite the out-of-domain text so that it is more similar to the training domain. They
pilot their idea in semantic role labeling using hand-written rewrite rules and show that it
compares favorably with approaches that retrain their model on the target domain.
135

fiWoodsend & Lapata

Other work has focused on the idea of automatically expanding the data available for a
given task without, however, applying any transformations. Furstenau and Lapata (2012)
combine labeled and unlabeled data by projecting semantic role annotations from a labeled
source sentence onto an unlabeled target sentence. They find novel instances for classifier
training based on their lexical and structural similarity to manually labeled seed instances.
Zanzotto and Pennacchiotti (2010) increase the datasets for textual entailment by mining
Wikipedia revision histories.
Contrary to previous work, we automatically extract general rewrite rules from various data sources including Wikipedia revision histories, comparable articles, and bilingual
corpora. Given a sentence in the (semantic role) annotated data, we create several syntactic transformations, many of which may be erroneous. We only maintain for model
training the transformations whose role labels are preserved under a syntactic rewrite. We
identify which transformations are label-preserving automatically, without requiring any
SRL-specific knowledge. Our approach differs from that of Vickrey and Koller (2008) in
three important aspects: (a) we employ automatic rules which are not simplification specific, (b) we do not attempt to select the best rewrite, any transformations that preserve
the gold standard role labels are used for training (c) we do not have a model that jointly
rewrites sentences and labels their semantic roles; we only rewrite the training data which
is then available to any model for the SRL task. Our work shares with that of Kundu
and Roth (2011) the idea of transforming the sentences while preserving the gold standard
role labels. However, we do not transform the test data to make it look like the training
data. This unavoidably requires specialized knowledge of the differences between the two
domains, which our more general model does not have.
As mentioned earlier, we use synchronous grammars to extract the set of possible syntactic rewrites. Synchronous context-free grammars (SCFGs; Aho & Ullman, 1969) are
a generalization of the context-free grammar (CFG) formalism to simultaneously produce
strings in two languages. They have been used extensively in syntax-based statistical MT
(Wu, 1997; Yamada & Knight, 2001; Chiang, 2007; Graehl & Knight, 2004) and related
generation tasks such as sentence compression (Galley & McKeown, 2007; Cohn & Lapata,
2009, 2013; Ganitkevitch et al., 2011), sentence simplification (Zhu et al., 2010; Feblowitz
& Kauchak, 2013; Woodsend & Lapata, 2011), and summarization (Woodsend & Lapata,
2012). Rather than focusing on one type of transformation (e.g., simplification or compression), we learn the full spectrum of rewrite operations and then select rules appropriate for
the task at hand. Furthermore, our results show that rewrite rules improve semantic role
labeling performance across the board, irrespectively of the specific variant of synchronous
grammar or corpus used. We experiment with conventional (weighted) SCFGs (Aho &
Ullman, 1969) and tree substitution grammars (Eisner, 2003) and employ transformation
rules extracted from Wikipedia revision histories (Zhu et al., 2010; Woodsend & Lapata,
2011) and bitexts (Ganitkevitch, Van Durme, & Callison-Burch, 2013).

3. Method
In this section we describe the general idea behind our algorithm and then move on to
present our specific implementation. We define a transformation g to be a function that
maps an example sentence s into a modified sentence s0 . Let G be the set of known
136

fiText Rewriting Improves Semantic Role Labeling

transformation functions, G = {g1 , g2 , . . . , gn }. Suppose now that there are labels associated
with example s. In the context of this paper, these are semantic role labels. Labels could be
defined over spans of tokens, but here we use the CoNLL 20089 formalism where it is the
head word of the span that is labelled. The transformation function is therefore a mapping
between tokens t in sentence s to tokens t0 in s0 . We do not require that the mapping
involves all the tokens of s or s0 , but we do require that the mappings are one-to-one.
A label-preserving transformation is a transformation gi mapping from (some of the)
tokens t in example s to tokens t0 in s0 , such that the (correct) labels of t0 are identical to
the labels of its source tokens t for all the token mappings defined in gi . In other words, those
labels that could be preserved, have been preserved, and no others have been introduced.
Let G be the set of label-preserving transformation functions, with G  G. The problem
that we address in this paper is therefore two-fold: Firstly, to find automatically a set of
possible transformation functions G which due to its automated nature will unavoidably be
an error-prone process. Secondly, to identify (again automatically) those transformations G
which are actually label-preserving  more specifically, those transformations that rewrite
a training instance s into s0 through varying its syntactic structure, and yet preserve the
semantic roles of those arguments that appear in the new version s0 .
Algorithm 1 describes our approach which boils down to three steps: (a) extracting
transformations, (b) refining transformations, and (c) generating and labeling an extended
corpus. A standard gold annotated corpus is used to train an initial semantic role labeling
model (see lines 12 in Algorithm 1). Meanwhile, a set of candidate transformation functions G are extracted from some suitable comparable or parallel corpus (line 3). This full
set of transformation functions is used to rewrite the gold corpus, creating a much extended
corpus which inevitably will contain grammatically or semantically incorrect sentences. The
extended corpus is next automatically labeled using the original SRL model after preprocessing through a normal SRL pipeline (whose details we discuss in Section 4.2), without
knowledge of the transformation functions involved.
We could in theory use this extended corpus as the basis of training a further SRL
model. However, it will contain many errors, and is unlikely to yield useful information
to guide the model. One approach could be to manually correct the rewrites that have
been generated automatically, but this would be very time and resource-intensive. Instead,
we do the corrections automatically, and create an extended corpus where the rewrites do
not impair the quality of the training data. We therefore learn which rules yield accurate
rewrites, i.e., rewrites which preserve the labels of the gold-standard. Our intuition is
that, given a large number of possible rewrites, the SRL model will in general label the
accurate rewrites correctly and mis-label the erroneous sentences, due to it finding them
more confusing. We thus compare the semantic role labels produced by the model with the
labels for corresponding predicate-argument pairs in the gold corpus, and provide them as
samples to train a binary classifier (here an SVM) which learns to predict which rewrites
are likely to be successful and which are problematic (lines 1119 in Algorithm 1).
Each rewritten sentence is classed as a positive sample if the SRL model is able to label
the transformation to the same standard or better than it was able to label the original
sentence, i.e. the labels that the SRL model predicts for the transformed sentence match
those it predicted for the original, or have now been corrected with respect to the mapped
gold labels. If, however, a semantic role is no longer predicted correctly, or missed, or an
137

fiWoodsend & Lapata

Algorithm 1 Learn SRL model Mextended by extending a gold training corpus Cgold through
transformation functions G.
1: Mgold  SRL model trained on Cgold
2: Cmodel  label Cgold using Mgold
Extract transformations:
3: G  all transformation functions that can be extracted from pairs of aligned sentences
in comparable corpora
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:

19:
20:
21:
22:
23:
24:
25:
26:
27:

Refine transformations:
initialize SVM training data DSVM  
for s  sentences in Cgold do
for g  applicable transformations in G do
s0  rewrite s using g
label s0 using Mgold
if SRL labels of s0 match labels of s in Cgold or equivalent s in Cmodel then
y  true
else
y  false
end if
add (s0 , y) to DSVM
end for
end for
train SVM using DSVM
G  {g  G : g has positive SVM weight}
Generate extended corpus:
initialize refined rewrite corpus Crefined  
for s  sentences in Cgold do
for g  applicable transformations in G do
s0  rewrite s using g
project labels from s to s0 using g
add s0 to Crefined
end for
end for
Cextended  Cgold  Crefined

Retrain SRL model:
Mextended  SRL model trained on Cextended
29: return Mextended

28:

138

fiText Rewriting Improves Semantic Role Labeling

erroneous role introduced, this is classified as a negative sample, as such a sample is likely
to harm the training of a new SRL model.
Once the SVM has identified the refined set of transformation functions G (line 20), these
transformations are used to create an extended training corpus. This time, knowledge of
the transformation function is involved to project the labels that correspond to the original
gold corpus (lines 2128). In the case of SRL, the labels describe the predicate and its
arguments. This extended corpus supplements the original gold standard corpus (line 29),
and the combination is then used to create a further SRL model (line 30).
It is worth noting that our method does not impinge on the actual process of learning an
SRL model, as it is concerned with the preparation of training data. We therefore believe
it can be applied to a range of SRL modeling approaches, and that gains in performance
we achieve are largely orthogonal to those that could be made by improving other aspects
of the learning process (see Section 5.3 for empirical evidence).
3.1 Learning Transformations
Conceptually a wide range of text-rewriting transformation functions could be included in
the set G, such as paraphrasing, simplification or translation into another language. Here,
we focus on transformation functions that can be expressed in synchronous context-free
grammars (Aho & Ullman, 1969). Synchronous rules operate on parse tree constituents in
a context-free manner, and typically modify the syntax. The transformations we consider
can be sub-categorized into:
1. Statement extraction. Constituents of a sub-tree of the parse tree are identified, extracted from their context and rewritten as a complete sentence, typically shorter and
simpler, although not necessarily so.
2. Compression. The original sentence is rewritten by compressing constituents of the
parse tree, typically by deleting nodes.
3. Insertion. New elements are added to the parse tree. As significant chunks of new
text would have semantic role information of their own, in practice these insertions
are often additional punctuation to clarify the scope of phrases, or a simple structure
such as It is . . . . to aid in statement extraction.
4. Substitution. Through using a lexicalized synchronous grammar, text can be replaced
with new text, and paraphrases represented.
We obtain a set of possible transformations G from monolingual comparable corpora
drawn from Wikipedia and bitexts (see Section 4 for details). In the following we describe
the grammar formalisms and resources we consider.
3.1.1 Transformations from Monolingual Corpora
We extract transformation rules from corpora that are only broadly comparable, using an
unsupervised process. These corpora are constructed from Wikipedia revision histories, and
comparable Wikipedia articles. As a result, it cannot be guaranteed that the aligned source
and target sentences are truly related, nor can it be expected that the source sentence will
139

fiWoodsend & Lapata

fully generate the target sentence. In practice this means that in addition to not requiring
a strictly synchronous structure over the source and target sentences, we cannot assume
an alignment between source and target root nodes, or require a surjective alignment of all
target nodes to nodes in the source parse tree. To be able to describe structural mismatches
and non-isomorphic tree pairs (the grammar rules can comprise trees of arbitrary depth,
and fragments can be mapped) we represent transformation functions using the synchronous
tree substitution grammar formalism (Eisner, 2003).
A synchronous tree-substitution grammar (STSG) defines the space of valid pairs of
source and target parse trees. Rules specify how to map tree fragments of the source parse
tree into fragments in the target tree, recursively and free of context. Following Cohn and
Lapata (2009), a STSG is a 7-tuple, G = (NS , NT , S , T , P, RS , RT ) where N are the
non-terminals and  are the terminals, with the subscripts S and T indicating source and
target respectively. P are the productions and RS  NS and RT  NT are the distinguished
root symbols.
Typically, each production is a rewrite rule for two aligned non-terminals X  NS and
Y  NT in the source and target:
hX, Y i  h, , i,
where  and  are elementary trees rooted with the symbols X and Y respectively. While
in a synchronous context free grammar  and  would be limited to one level elementary
trees, an STSG imposes no such limits and the elementary trees can be arbitrarily deep.
A one-to-one alignment between the frontier nodes (non-terminal leaves of the elementary
trees) in  and  is specified by .
In our experiments, we investigate two STSG variants, the strictly synchronous tree
substitution grammar T3 (Cohn & Lapata, 2009), which was originally developed for the
task of text compression, but does support a full range of transformation operations and
the quasi-synchronous tree substitution grammar (QTSG) of Woodsend and Lapata (2011),
which has been used in text simplification and summarization (Woodsend & Lapata, 2012).
In T3 tokens are first aligned using a probabilistic aligner which has been initially provided
with identity mappings for the entire vocabulary. In our experiments we used the Berkeley
aligner (Liang, Taskar, & Klein, 2006), however any aligner with broadly similar output
could have been used instead. Synchronous rules comprising trees of arbitrary depth are
extracted from the pair of input CFG parse trees, consistent with the alignment. Across
the complete corpus of aligned trees, T3 filters the extracted rules to provide the maximally
general rule set, consisting of rules with the smallest depth, which are still capable of
synchronously deriving any of the original aligned tree pairs. After removing identity rules,
the resulting grammar forms the transformation functions G.
Unlike T3, QTSG works with only a partial alignment of tokens, based on identity.
Non-terminal nodes in the parse trees are then aligned to be consistent with the token
alignment. This can have the result that sections of both the source and target parse trees
remain unaligned. Then, like T3, synchronous rules comprising trees of minimum necessary
depth are extracted from the pair of input trees, consistent with the alignment, and as
before, identity rules are removed to form G.
As an example, Figure 1 shows two comparable parse trees aligned at the token level.
The synchronous rules extracted from this alignment by T3 and QTSG are shown in Table 2.
140

fiText Rewriting Improves Semantic Role Labeling

ROOT
S

NNP

.

VP

NP
NNS

VP

VBP

S

VBN

VP
VP

TO

NP

VB

PP

NP

NP

IN

NN

DT

ADVP

Modern

scholars

come

have

Some

scholars

to

question

question

the

the

existence

existence

NNS
NP

at

least

JJ

CD

NNS

the

first

nine

emperors

the

first

nine

emperors

DT

JJ

CD

NNS

.

.

NP
PP

NP
NNP

JJS

IN

NN

DT

of

of

IN

DT

NP

VBP
VP

.
S
ROOT

Figure 1: Example of sentence alignment showing source (above) and target (below) trees.

Where it is possible to extract rules from nodes at the child level, then the rules that T3
and QTSG extract at the parent level will be identical. In cases where a sub-tree has been
compressed, (in the example, have come to question is compressed to question), QTSG
extracts the full sub-tree until frontier nodes align, while T3 will extract several rules of the
smallest depth.
3.1.2 Transformations from Bitexts
We also obtain transformation rules from the ParaPhrase DataBase (PPDB, Ganitkevitch
et al., 2013), a collection of English (and Spanish) paraphrases derived from large bilingual
parallel corpora. A variety of paraphrases (lexical, phrasal, and syntactic) are obtained
following Bannard and Callison-Burchs (2005b) bilingual pivoting method.
141

fiWoodsend & Lapata

Rules extracted by T3
], [S NP
VP
. ]i

hS, Si



h[S NP

hNP, NPi



h[NP [NNP Modern] NNS

hVP, VPi



h[VP VBP

hVP, VPi



h[VP VBN

hVP, VPi



h[VP TO

hVP, VPi



h[VP [VB question] NP

hNP, NPi



h[NP NP

hNP, NPi



h[NP DT

hPP, PPi



h[PP IN

hNP, NPi



h[NP ADVP

hS, Si



h[S NP

hNP, NPi



h[NP NNP

hVP, VPi



h[VP VBP

hNP, NPi



h[NP NP

hNP, NPi



h[NP DT

hPP, PPi



h[PP IN

hNP, NPi



h[NP ADVP

VP

1

2

VP



VP

PP

1

NP



1

.

JJ

NP


2

2

3

]i

1

]i

PP

1

NP
CD

2

2

NN

1

1

]i

]i

2

]i

2

NNS

3

1

]i

4

], [NP DT

1

1

1

JJ

2

CD

3

NNS

4

]i

3

[S [VP TO



], [PP IN
1

2

], [NP [DT Some] NNS

JJ

2

1

PP

1

], [NP DT

DT

]i

1

1

]i

1

], [VP [VBP question] NP

], [NP NP

2

3

Rules extracted by QTSG
], [S NP
VP
. ]i

[VP VBN

NN

1

1

], [NP DT

1

2

]], [VP VP

], [PP IN

2

PP

1

2

2

1

], [NP NP

2

NNS



1

], [VP VP

DT



VP

1

1

], [NP [DT Some] NNS

], [VP VP

1

1

NN

1

3

[S VP





1

.

2

NN

1

NP
CD

3

2



1

]i

[VP VB

1

NP

2

]]]]], [VP VBP

1

NP

2

]i

]i

2

]i

]i
NNS

4

], [NP DT

1

JJ

2

CD

3

NNS

4

]i

Table 2: Synchronous tree grammar rules extracted by T3 and QTSG from the aligned
sentences in Figure 1. Boxed indices are short-hand notation for the alignment, .

The intuition is that two English strings e1 and e2 that translate to the same foreign
string f can be assumed to have the same meaning. The method then pivots over f to
extract he1 , e2 i as a pair of paraphrases. An example is shown in Figure 2 (taken from
Ganitkevitch et al., 2013). The method extracts a wide range of possible paraphrases some
of which are unavoidably noisy due to inaccurate word alignments. Paraphrases are ranked
by computing p(e1 |e2 ) as shown below:
X
p(e2 |e1 ) 
p(e2 |f )p(f |e1 )
(2)
f

where p(ei |f ) and p(f |ei ) are translation probabilities estimated from the bitext (Koehn,
Och, & Marcu, 2003).
Rewrite rules in PPDB are obtained using a generalization of the method sketched
above to extract syntactic paraphrases (Ganitkevitch et al., 2011). Using techniques from
syntactic machine translation (Koehn, 2010), SCFG rules are first extracted from Englishforeign sentence pairs. For a foreign phrase the corresponding English phrase is found via the
142

fiText Rewriting Improves Semantic Role Labeling

... 5 farmers were thrown into jail

in Ireland ...

... fnf Landwirte

festgenommen

, weil ...

... oder wurden

festgenommen

, gefoltert ...

... or have been

imprisoned

, tortured ...

Figure 2: Paraphrases extracted via bilingual pivoting.
word alignments. This phrase pair is turned into a SCFG rule by assigning a left-hand side
nonterminal symbol, corresponding to the syntactic constituent that dominates the English
phrase. To introduce nonterminals into the right-hand sides of the rule, corresponding subphrases in the English and foreign phrases are replaced with nonterminal symbols. Doing
this for all sentence pairs in a bilingual parallel corpus results in a translation grammar
that serves as the basis for syntactic machine translation. A translation grammar can be
converted into a paraphrase grammar as follows. Let r1 and r2 denote translation rules
where the left-hand side nonterminals hX, Y i and foreign language strings  match:
r1 = hX, Y i  h1 , , i

(3)

r2 = hX, Y i  h2 , , i
A paraphrase rule rp is then created by pivoting over f :
rp = hX, Y i  h1 , 2 , i

(4)

Although not shown in equations (3) and (4), the rules of the SCFG are associated
with a set of features that are combined in a log-linear model to estimate the derivation
probabilities.
3.1.3 Manual Transformations
Our experiments primarily make use of automatically learned transformations since these
can be adapted to different tasks, domains or languages. However, for the proposed approach it is not necessary that transformation functions are acquired automatically  such
functions could be also crafted by hand. We thus also investigated the effectiveness of
rewrites generated by the system of Heilman and Smith (2010) (henceforth H&S), which
uses a sophisticated hand-crafted rule-based algorithm to extract simplified declarative sentences in English from syntactically complex ones. These rules are similar to those engineered by Vickrey and Koller (2008) but deterministic in that they will only generate
a unique rewrite for a given sentence. The algorithm operates on the standard phrase
143

fiWoodsend & Lapata

structure tree of an input sentence. It extracts new sentence trees from the input tree for
the following: non-restrictive appositives and relative clauses; subordinate clauses with a
subject and finite verb; and participial phrases that modify noun phrases, verb phrases, or
clauses. In addition, the algorithm splits conjoined S, SBAR, or VP nodes, and extracts new
sentence trees for each conjunct. Each output tree is further processed to move any leading
prepositional phrases and quotations to be the last children of the main verb phrase, and
the following are removed: noun modifiers offset by commas (non-restrictive appositives,
non-restrictive relative clauses, parenthetical phrases, participial phrases), verb modifiers
offset by commas (subordinate clauses, participial phrases, prepositional phrases), leading
modifiers of the main clause (nodes that precede the subject).
Table 3 shows examples of rules extracted using the T3, QTSG and PPDB grammar
formalisms applied to a sentence from the CoNLL dataset. The final column of Table 3 indicates whether the transformation could be classed as statement extraction, compression,
insertion, or substitution. As reflected in the table, T3 captures compression transformations by deleting nodes in the parse tree; QTSG rules are a range of mainly syntactic
transformations; and PPDB transformations are substitutions of words or short phrases.
3.2 Refining Transformations
As mentioned earlier, the transformation rules obtained from our synchronous grammars
could be used to rewrite the gold standard sentences. Unfortunately, due to the nature of
the corpora from which the rules are obtained and the automatic extraction process, many
of the rules will contain errors which will impair rather than improve the quality of the
training data. Our idea is to extrapolate which rules to trust by observing how the SRL
labeler handles the rewritten sentences. If it has mis-labeled them, it is possible that the
rewrite is not correct or that the original labels have not been preserved.
Each rewritten sentence is classed as a positive sample if the SRL model predicts the
same labels for the transformed sentence as those it predicted for the original, or the labels
have now been corrected with respect to the gold labels. If, however, a semantic role is no
longer predicted correctly, or missed, or an erroneous role introduced, this is classified as a
negative sample, as such a sample is likely to harm the training of a new SRL model. To
capture the full impact of a candidate transformation function, a sentence is provided as
a positive sample to the classifier only if all the labels (i.e., all predicates and arguments)
from the source sentence have been successfully projected onto the rewrite. Table 4 shows
examples of positive and negative samples of T3, QTSG, and PPDB rewrites. Note that
no refining was used on the H&S outputs.
To decide which transformation function to include in the refined set, we used a linear
kernel SVM (Vapnik, 1995) as a binary classifier, but other classifiers or indeed suitable
statistical tests for contingency could be used. The input to the SVM learner is a set
of l training samples (x1 , y1 ), . . . , (xl , yl ), xi  Rn , y  {+1, 1}. xi is an n dimensional
feature vector representing the ith sample, and yi is the label for that sample. The learning
process involves solving a convex optimization problem to find a large-margin separation
hyperplane between positive and negative samples. In order to cope with inseparable data,
some misclassification is allowed, the amount of which is determined by a parameter C,
which can be thought of as a penalty for each misclassified training sample. From one
144

fiText Rewriting Improves Semantic Role Labeling

Grammar
Original

T3

Examples
Bell, based in Los Angeles, makes and distributes electronic, computer and
building products.
Bell, based, makes and distributes electronic, computer and building products.
hPP, PPi  h[PP IN  NP  ], [PP ]i

Comp

Bell, based in Los Angeles, makes and distributes.
hNP, NPi  h[NP ADJP  NNS  ], [NP ]i

Comp

Based in Los Angeles, makes and distributes electronic, computer and building
products.
hNP, NPi  h[NP NNP  ,], [NP ]i

Comp

Bell, based in Angeless, makes and distributes electronic, computer and building products.
hNP, NPi  h[NP NNP  NNP ], [NP NNP
[POS s]]i

Comp

Bell makes and distributes electronic, computer and building products.
hNP, NPi  h[NP NP
, VP  ,], [NP NP ]i

Comp

It makes and distributes electronic, computer and building products.
hS, Si
 h[S NP  VP
. ], [S [NP It] VP
. ]i

Ins

1

QTSG

1

1

1

1

Bell was based in Los Angeles.
hNP, Si
 h[NP NP
, VP
1

2

1

,], [S NP

2

1

2

[VP [VBD was] VP

2

] .]i

Ext

Bell, based in Los, makes and distributes electronic, computer and building
products.
hNP, NPi  h[NP NNP
NNP  ], [NP NNP ]i

Comp

Los Angeles makes and distributes electronic, computer and building products.
hNP, NPi  h[NP NP  , [VP VBN  [PP IN  NP ]] ,], [NP NP ]i

Comp

Bell, founded in Los Angeles, makes and distributes electronic, computer and
building products.
hVP, VPi  h[VP [X based] PP ], [VP [X founded] PP ]i

Sub

Bell, building in Los Angeles, makes and distributes electronic, computer and
building products.
hVP, VPi  h[VP [X based] IN
NP ], [VP [X building] IN
NP ]i

Sub

Bell, based during Los Angeles, makes and distributes electronic, computer
and building products.
hVP, VPi  h[VP VBN
IN  NP ], [VP VBN
[X during] NP
]i

Sub

1

1

1

PPDB

Type

1

1

1

1

1

2

2

1

1

2

2

Table 3: Examples of transformation rules extracted using T3, QTSG and PPDB grammar
formalisms, applied to the sentence marked Original. The final column indicates
whether the rule is statement extraction (Ext), compression (Comp), insertion
(Ins) or substitution (Sub). As before, boxed indices are short-hand notation for
the alignment, .

view (the dual problem), the result is a set of Support Vectors, the associated weights i ,
and a constant b. From another view (the primal problem), the result is a vector w that
defines the separation hyperplane, with a dimension that depends on the particular kernel
145

fiWoodsend & Lapata

Original Bell, based in Los Angeles, makes and distributes electronic, computer and building products.
T3

QTSG

Bell, based, makes and distributes electronic, computer and building products.
Bell, based in Los Angeles, makes and distributes.
Based in Los Angeles, makes and distributes electronic, computer and building products.
Bell, based in Angeless, makes and distributes electronic, computer and building products.

+
+
+


Bell makes and distributes electronic, computer and building products.
It makes and distributes electronic, computer and building products.
Bell was based in Los Angeles.
Bell, based in Los, makes and distributes electronic, computer and building products.
Bell, based in Angeles, makes and distributes electronic, computer and building products.
Los Angeles makes and distributes electronic, computer and building products.

+
+
+

+


PPDB

Bell, founded in Los Angeles, makes and distributes electronic, computer and building products. 
Bell, building in Los Angeles, makes and distributes electronic, computer and building products. 
Bell, based during Los Angeles, makes and distributes electronic, computer and building products. 

H&S

Bell makes. Bell distributes. Bell is based in Los Angeles.

Original For its employees to sign up for the options, a college also must approve the plan.
T3

For it, a college also must approve the plan.
A college also must approve the plan.
For its employees to sign up for the options, this a also must approve this the.
For its employees to sign up for, a college also must approve the plan.


+

+

QTSG

For its employees to sign up for the options, a college also must approve.
For its employees to sign up for the options, a college also must approve plan.
For its employees to sign up for all of the options, a college also must approve the plan.


+


PPDB

For
For
For
For

+

+


H&S

A college must approve the plan for its employees to sign up for the options.

its
its
its
its

employees
employees
employees
employees

to
to
to
to

sign
sign
sign
sign

up
up
up
up

for
for
for
for

the
the
the
the

options,
options,
options,
options,

a
a
a
a

college
college
college
college

also
also
also
also

must adopt the plan.
must agree to the plan.
must endorse the plan.
needs to approve the plan.

Original That went over the permissible line for warm and fuzzy feelings.
T3

That
That
That
That

went over the permissible line for feelings.
went over for warm and fuzzy feelings.
went over it for it.
went.

+


+

QTSG

That went over the line for warm and fuzzy feelings.
That went over the permissible line for feelings.
That went over permissible for warm and fuzzy feelings.

+



PPDB

That went over the permissible line for hot and fuzzy feelings.
That went during the permissible line for warm and fuzzy feelings.


+

H&S

That went over the permissible line for warm and fuzzy feelings.

Table 4: Examples of rewrites generated by T3, QTSG, and PPDB for a source sentence
(Original) from the CoNLL-2009 training set. Symbols +/ indicate whether the
sample was classified as positive (i.e., argument label preserving) and forms part
of extended training corpus, or not.

146

fiText Rewriting Improves Semantic Role Labeling

function used in the SVM. In the case of the linear kernel function, wPis ndimensional, as
the feature vectors, and there is a straight-forward relationship w = lj=1 yj j xj between
primal and dual variables, effectively assigning weights to the explicitly specified features.
Other kernel functions allow for interaction between variables. For instance when using
binary valued features, a degree2 polynomial kernel function implies that the classifier
considers all available pairs of features as well.
We used the identity of the transformation functions involved as the features of each
sample, so the size of the feature space n = kGk, and features were binary-valued. Other
features could be easily incorporated in this setting, perhaps capturing information on the
structure of the source sentence or the transformation function, and this might achieve good
results in conjunction with a polynomial kernel, but we did not pursue this avenue further.
Instead we used a linear kernel, and due to the simple structure of our features, the SVM
assigned a weight to each transformation function independent of the source sentence. We
chose which transformation functions should form the refined set based on whether their
corresponding weight was above a global threshold value, and we set the threshold value by
maximizing the performance of the resulting SRL model on the development set.
3.3 Labeling the Extended Corpus
Once the SVM has identified the refined set of transformation functions G, these transformations are used to create an extended training corpus. Using the alignment information
in the transformation functions to trace the position of tokens from the original sentence to
the rewrite, the semantic role labels of the gold corpus are projected onto the corresponding predicate-argument pairs in the rewritten corpus. Assuming the SVM has correctly
identified the transformation function involved as indeed label-preserving, and that the
transformation functions can be applied in the current context, the semantic role labeling
of the rewrite will now be of the same quality standard as the source. Both conditions are
however unlikely to be true, resulting in a degradation in the quality of the rewrite corpus.
The corpus of rewrites is appended to the original gold standard corpus to create a new
larger training corpus, which is then used to create a further SRL model.

4. Experimental Setup
In this section we present our experimental setup for assessing the performance of our approach. We give details on the corpora and grammars we used to create the transformations,
and model parameters used to identify those that preserve labels. We explain how an existing SRL system was modified through our approach, and how we evaluated the effects of
increasing the training data with our transformations.
4.1 Grammar Extraction
We extracted synchronous grammars from two monolingual comparable corpora drawn
from Wikipedia. A corpus of 137,362 aligned sentences created by pairing Simple English
Wikipedia with English Wikipedia (Kauchak, 2013). And a corpus of 14,831 paired sentences from comparing consecutive revisions of articles in Simple English Wikipedia (Woodsend & Lapata, 2011). These corpora provide a large repository of monolingual, comparable
147

fiWoodsend & Lapata

Grammar
T3
QTSG

Aligned
13,562
3,875

Revisions
5,386
669

Table 5: Non-identical rules extracted from each Wikipedia corpus, with rules appearing
only one or two times removed.

sentences, taken from real-world writing. Advantageously, Simple English Wikipedia encourages contributors to employ simpler grammar than the ordinary English Wikipedia; the
corpora therefore naturally contain many examples of syntactic variation such as reordering and sentence splitting, as well as paraphrasing and changes to content. Table 5 lists
the number of non-identical rules each grammar formalism extracted from the Wikipedia
corpora, once rules with an instance count of only one or two were removed.
In addition to these grammars extracted from Simple English Wikipedia, we worked
with the monolingual synchronous grammar included in the Paraphrase Database (Ganitkevitch et al., 2013), where paraphrases were extracted from bilingual parallel corpora.
The English portion of PPDB contains over 220 million paraphrase pairs, including 140
million paraphrase patterns capturing syntactic transformations with varying confidence.
To form a synchronous grammar, we used highest scoring 585,000 paraphrases from the
subset of constituent syntactic paraphrases (where all nonterminals were labeled with Penn
Treebank constituents).
4.2 Semantic Role Labeler
The method presented in this paper crucially relies on a semantic role labeler for refining
the transformations and performing the semantic analysis in general. We used the publicly available system of Bjorkelund et al. (2009). Out of the those that competed in the
CoNLL-2009 SRL-only challenge, it was ranked first for English language, and second overall. To the best of our knowledge, this system represents the state-of-the-art for English
SRL parsing. The system architecture consists of a four-stage pipeline of classifiers: for
predicate identification (although this module is not required in evaluation), for predicate
sense disambiguation, a binary classifier for argument identification, and finally argument
classification using a multiclass classifier. Beam search is used to identify the arguments of
each predicate and to label them, according to local classifiers using features which relate
mainly to dependency parse information linking predicates to potential arguments and their
siblings. In addition, a global reranker can be used to select the best combination of candidates (see Section 5 for details). The SRL system requires tokenized input with lemma,
POS-tag and dependency parse information. This information was already provided in the
gold-standard training corpus (see immediately below). To create equivalent information
for the transformed text and evaluation files, we used the mate-tools pipeline (Bjorkelund
et al., 2009), retrained (like the SRL model itself) on just the training partition of the data.
We used the English language benchmark datasets from the CoNLL-2009 shared task to
train and evaluate the SRL models. We identified and labeled semantic arguments for nouns
148

fiText Rewriting Improves Semantic Role Labeling

Corpus
Training
+ H&S
+ PPDB
+ T3
+ QTSG
+ T3 + QTSG
+ PPDB + T3
+ PPDB + QTSG
+ PPDB + T3 + QTSG
Development
Test in-domain
Test out-of-domain

Sentences
39,272
55,474
238,732
203,941
500,627
704,561
442,666
739,352
943,286
1,334
2,399
425

Tokens
958,174
909,358
7,071,550
4,701,688
9,623,471
14,325,166
11,773,245
16,695,028
21,396,723
33,368
57,676
7,207

Table 6: Statistics on corpora used to train and evaluate the SRL models.
and verbs (Hajic, Ciaramita, Johansson, Kawahara, Mart, Marquez, Meyers, Nivre, Pado,
Stepanek, Stranak, Surdeanu, Xue, & Zhang, 2009). We used the training, development,
test and out-of-domain test partitions as they were provided, and some statistics on these
data sets are shown in Table 6. Specifically, we show the increase on the training data
effected by our method when using transformations obtained from T3, QTSG, PPDB, and
their combinations. For comparison we also use the manual transformations available from
Heilman and Smith (2010). To train the SRL model (and also the previous stages in the NLP
pipeline), we used data from the training partition only, while the development partition
was used to identify the best subset of G transformations2 .
We used LibLinear (Fan, Chang, Hsieh, Wang, & Lin, 2008) to train the SVM, and
the hyper-parameters of the SVM were tuned by cross-validation on the training set to
maximise the area under ROC curve, using the automatic grid-search utility of the python
package scikit-learn (Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel,
Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, & Duchesnay, 2011). An assessment of the cross-validation accuracy (in terms of F1 score and area
under ROC curve) of the SVM for each grammar is shown in Table 7. The results show
that PPDB rewrites are the most accurate to employ, perhaps because the rules are the
most heavily lexicalized of all the grammars. T3 grammar is the most unpredictable to use,
although the SVM scores considerably higher than chance.
Test sets were used solely for evaluation, making use of the indicators in the data
files as to which words were argument-bearing predicates. Results were generated using
the CoNLL-2009 evaluation script unmodified. We only report results on semantic roles
(i.e., not in combination with syntactic dependencies which tends to yield higher scores)
using both the in-domain and out-of-domain evaluation data. In the evaluation script,
semantic propositions are evaluated by converting them to semantic dependencies between
2. The result of this re-training was that the performance reported here is worse than for the models
available on the mate website, which have been trained on all partitions of the CoNLL-2009 data
(training, development and test).

149

fiWoodsend & Lapata

Grammar
PPDB
T3
QTSG

F1
0.85
0.67
0.78

Area under ROC
0.82
0.61
0.72

Table 7: Statistics on the SVMs performance for each grammar, obtained through crossvalidation on the training set.

a predicate and each of its arguments, and labeling the dependency with the labels of the
corresponding argument. Additionally, a dependency is created from a virtual root node to
each predicate and labeled with the predicate sense. To be comparable with other published
results, in general we report the scores that combine predicate sense and argument role label
predictions. In Tables 12, 13 and 14, however, we focus on arguments only, and remove the
predicate sense scores.

5. Results
In this section we provide empirical evidence on the performance of our approach. Our
experiments were primarily designed to answer the following questions. Does text rewriting
generally improve SRL performance? Does it matter which transformation rules to use,
i.e., are some rules better than others? Are the transformation rules useful on out-ofdomain data? Which SRL labels are mostly affected by rewriting? Does performance vary
depending on the size of the original training data? Are the results sensitive to the learner
being employed? We first examine the effect of different (transformation) grammars on
the SRL task both on in-domain and out-of-domain test data, and then move on to assess
which labels are mostly affected by our method. Finally, we present results on the effect of
combining our approach with a global reranker and training with different-sized datasets.
5.1 Transformation Rules Improve F1 Across the Board
Table 8 (left half) shows SRL performance (measured in terms of precision, recall, and F1)
on the in-domain CoNLL-2009 test set. For the training corpora rewritten by the H&S
system, the T3, QTSG, and PPDB grammars, all of the resulting SRL models significantly
(p < 0.01) improve over a model trained on the original corpus. We used stratified shuffling (Noreen, 1989) to examine whether differences in F1 were significant (Pado, 2006).
Recall shows the largest increase, particularly with the acquired synchronous grammars,
indicating that the increased training data is resulting in better coverage. Generally this is
not at the expense of precision which in all cases apart from PPDB has increased as well.
Significant gains are also seen in the acquired grammars compared to the H&S system, with
the exception of T3 where there is greater variation in its performance.
We also combined the rewrites produced by the different grammars (see T3+QTSG,
PPDB+T3, PPDB+QTSG and PPDB+T3+QTSG in Table 8) but this did not significantly
improve performance over the individual grammars (although still significantly better than
the original model and the H&S system), suggesting that the grammars are capturing very
150

fiText Rewriting Improves Semantic Role Labeling

Original
H&S
PPDB
T3
QTSG
PPDB+T3
PPDB+QTSG
T3+QTSG
PPDB+QTSG+T3
 label projection

P
86.79
87.08
86.42
86.84
87.04
86.61
86.70
86.78
86.76
80.95

In-domain
R
F1
83.58 85.15
83.73 85.37 
84.64 85.52 
84.25 85.52 
84.34 85.67 
84.45 85.51 
84.81 85.75 
84.62 85.69 
84.69 85.71 
78.75 79.83 

Out-of-domain
P
R
F1
76.04 71.73 73.82
76.33 70.86 73.49
75.37 72.66 73.99 
76.04 72.29 74.12
76.88 72.83 74.89 
75.65 72.49 74.03 
76.64 73.22 74.89 
76.56 72.88 74.67 
76.54 73.19 74.83 
66.94 66.93 66.93 

Table 8: Semantic evaluation results on CoNLL-2009 in-domain and out-of-domain test
sets (combining predicate word sense and argument role labels). Results for the
models trained on the Original training set, a baseline extension to the training set,
extensions due to each grammar and all combinations.  label projection: results
from training on the PPDB+QTSG+T3 training corpus, but without rewriting
the labels using gold corpus information.  Difference from Original is significant
at p < 0.01.  Difference from H&S is significant at p < 0.01.

Proportion of sentences
produced by this grammar

H&S
QTSG

Also produced
PPDB
0.4
0.0

by this grammar
T3
QTSG
0.2
28.1
3.2

Table 9: Sentence rewrite overlap (%) in the refined rewrite corpora produced by H&S,
PPDB, T3 and QTSG.

similar information. For instance, T3 and QTSG are extracted from the same corpora
of aligned sentence pairs. The degree of overlap in the rewrite corpora produced by the
grammars is shown in Table 9. Although the degree of overlap in exact sentences is low,
the relative performance of the resulting models is closer (discussed below). Overall, the
best performing system uses transformations obtained from QTSG and PPDB, which is not
surprising as the rules extracted from these grammars present minimal overlap.
Benefits also transfer to out-of-domain text for the acquired grammars, improving the
overall performance even more than for the in-domain data (see right half in Table 8). The
F1-score of the QTSG model is over 1% higher than the original model, and Recall for
the model combining all the acquired grammars has increased by 1.5%. Meanwhile, the
rewrites of the H&S system do not seem to improve coverage, resulting in a drop in Recall
and F1-score.
151

fiWoodsend & Lapata

Original
PPDB
T3
QTSG

P
86.79
87.34
87.36
87.48

In-domain
R
F1
83.58 85.15
83.10 85.17
83.26 85.26
83.31 85.34

Out-of-domain
P
R
F1
76.04 71.73 73.82
76.41 71.42 73.83
76.49 71.76 74.05
76.75 72.00 74.30

Table 10: Results on CoNLL-2009 in-domain and out-of-domain test sets, training the SRL
model only on rewrites that were labeled as positive.

SVM
Thresholds Count
None

+0.001
10
-0.001
10
-0.2
10
All
10
+0.001
5
+0.001
3

P
80.26
80.74
80.82
80.65
80.55
80.46
80.00

Quality
R
76.28
76.99
76.87
76.86
77.08
76.54
76.13

F1
78.22
78.82
78.80
78.71
78.78
78.45
78.02

Table 11: Effect of selecting transforms by SVM on the quality of the resulting model
(precision, recall and F1 measures on labeling the development set).

In addition, we examined whether filtering the set of acquired transformation functions
is indeed beneficial. In the approach we have proposed, transformations are applied to the
training corpus twice: the first time as input to an SVM to identify the more reliable rewrite
rules, and in a second pass the reduced set of rules is applied to the whole training corpus.
An alternative approach would be to apply the transforms only once, and then train the SRL
model. We thus took the rewrites that are labeled positive in steps 914 of Algorithm 1 and
corrected the labels to gold-standard (step 23). SRL models were subsequently trained using
the extended training corpus, created by concatenating the original training dataset with
these rewrites. Table 10 shows SRL performance for different grammars (PPDB, T3, and
QTSG) on the test set. Although precision and F1 have increased over the original model,
the gains are much reduced compared to the results obtained using the SVM (Table 8). It
appears that the extra rewrites obtained by applying generally-reliable transforms to the
whole training set increases coverage, and so improves the performance of the models.
Table 11 shows how altering the quality threshold (and removing indicator features
for the number of times each transformation function was extracted) affects performance.
Results are shown for the QTSG grammar on the (in-domain) development set (we observed
similar patterns for all other grammars and grammar combinations). The SVM quality
threshold varied from very positive (no transformations accepted) to very negative (all
152

fiText Rewriting Improves Semantic Role Labeling

Original
H&S
PPDB
T3
QTSG
PPDB+T3
PPDB+QTSG
T3+QTSG
PPDB+QTSG+T3

P
82.69
83.08
82.34
82.88
83.00
82.61
82.62
82.75
82.83

In-domain
R
F1
78.25 80.41
78.45 80.70 
79.89 81.10 
79.30 81.05 
79.27 81.09 
79.62 81.09 
80.01 81.29 
79.77 81.23 
79.95 81.37 

Out-of-domain
P
R
F1
71.44 65.62 68.40
71.65 64.25 67.75
70.68 67.02 68.80 
71.54 66.46 68.90 
72.48 66.98 69.62 
71.16 66.88 68.95 
72.11 67.47 69.71 
72.08 67.09 69.49 
72.08 67.54 69.74 

Table 12: Performance in the labeling of semantic arguments (predicate word sense information removed).  Difference from Original is significant at p < 0.01.  Difference
from H&S is significant at p < 0.01.

Original
H&S
PPDB
T3
QTSG
PPDB+T3
PPDB+QTSG
T3+QTSG
PPDB+QTSG+T3

In-domain
P
R
F1
89.56 84.75 87.09
89.71 84.71 87.14
88.99 86.34 87.65
89.57 85.70 87.59
89.53 85.50 87.47
89.10 86.28 87.66
89.28 86.05 87.63
89.33 86.10 87.68
89.33 86.23 87.75

Out-of-domain
P
R
F1
87.20 80.10 83.50
87.40 78.38 82.65
86.24 81.78 83.95
87.09 80.90 83.88
87.28 80.66 83.84
86.75 81.53 84.06
86.77 81.18 83.88
87.34 81.29 84.20
86.90 81.43 84.07

Table 13: Accuracy of identification but not classification (labeling) of semantic arguments.

transformations). These findings indicate that constructing G to be transformations with
a positive SVM weight (threshold of +0.001) gives better results that no transformations,
or any more permissive threshold.
5.2 Transformation Rules Improve Semantic Role Assignment for Verbal and
Nominal Predicates
The results in Table 8 combine accuracy in predicting the sense of predicates and accuracy in
labeling their arguments. Generally, the models are better at assigning the correct predicate
sense. An interesting result is that much of the gain in performance seen here by rewriting
the training corpus comes through improving semantic role assignment. It appears that
153

fiWoodsend & Lapata



RAMMNR



RAMLOC





RAMCAU





RA2

















RA1
RA0
CA1





















































































































CA0
AMTMP









AMPRD
AMPNC

Argument



RAMTMP







AMNEG





AMMOD





AMMNR







AMLOC



















































AMDIR















AMCAU



















































AMDIS

AMADV







A5



A4

























A2





















A1



























A0







JJ

NN

VBP

VBZ

A3

NNP NNS

VB

+10%

+1%






AMEXT

Change in F1



VBD VBG VBN

0%
1%

10%
Occurrences




1+
10+

 100+



1000+

Predicate

Figure 3: Changes in F1-score for the PPDB+T3+QTSG model over Original, measured
by pairs of predicate POS-tag and argument.

introducing syntactic variation in the training data provides the model with wider coverage
in syntactic dependency paths between predicate and arguments.
Table 12 shows results for the same models and data sets as above, but focusing on
the argument labels only. The acquired grammars show the biggest improvements, with
over 1% improvement in Recall in each case, and gains in F1-score between 0.5% and 1.2%.
The same models and data sets were used in Table 13, with the results here for argument
identification only, not classification (unlabelled arguments). There are improvements over
154

fiText Rewriting Improves Semantic Role Labeling



RAMMNR



RAMLOC





RAMCAU





RA2

















RA1
RA0
CA1











































































+1%







0%







































CA0
AMTMP









AMPRD
AMPNC

Argument



RAMTMP







AMNEG





AMMOD





AMMNR







AMLOC






















































AMDIR















AMCAU



















































AMEXT
AMDIS

AMADV







A5



A4

























A2





















A1



























A0







JJ

NN

VBP

VBZ

A3

NNP NNS

VB



VBD VBG VBN

Change in F1
+10%

1%

10%
Occurrences




1+
10+

 100+



1000+

Predicate

Figure 4: Relative performance in terms of F1-score of the QTSG (red) and PPDB (blue)
models, by pairs of predicate POS-tag and argument.

Original in both Recall and F1. They are not as large as before, showing that the overall
gains are a result of improvements in both argument identification and classification.
A breakdown of the gains in F1-score by predicate POS-tag and argument is shown in
Figure 3, illustrating the relative improvements of the model trained on all acquired grammars (PPDB+T3+QTSG) to the model trained on the original CoNLL training data. This
further analysis reveals that most of the gain came from increased precision and recall in
predicting the core arguments. There are additional gains in the modifiers of nominal pred155

fiWoodsend & Lapata

Dependency path distance
Proportion of test set
SRL model:
Original
PPDB
T3
QTSG
PPDB+QTSG+T3

01
75.75

2
13.67

3
5.54

4
2.62

5
1.13

6
0.56

7+
0.73

88.83
+0.49
+0.63
+0.53
+0.74

74.27
+1.43
+1.15
+0.66
+1.60

61.73
+2.65
+1.65
+1.82
+2.49

54.76
+3.26
+1.67
+2.98
+2.02

43.08
+4.78
+1.42
+3.01
+6.20

23.91
+5.53
+1.22
0.96
+1.35

12.27
0.06
+0.69
+0.43
+1.61

Table 14: F1-scores for labeled arguments where distance between predicate and argument
is measured as the number of arcs in the dependency graph. Results are from
the CoNLL in-domain test set. Lower rows show the change in F1-score over the
Original SRL model.

icates. There was some improvement and some losses in the very common core arguments
(A0 and A1) of the verbal predicates, but the more striking gains were seen for the other
core argument labels. This seems consistent with the models learning from wider syntactic
coverage. Figure 4 shows a similar breakdown of the gains in F1-score by predicate POStag and argument, this time comparing the improvements seen from the QTSG corpus with
those resulting from PPDB. The differences are less pronounced, with PPDB improving the
core arguments more, and QTSG improving performance in labeling modifiers.
We also investigated the effect of the label projection mechanism itself. We used the
rewrites produced by all grammars (PPDB+T3+QTSG) to extend the training set. However, instead of using projected labels, we used the the original model Mgold (trained on the
training partition of CoNLL-2009) to label the refined corpus. We then retrained on the
extended corpus and used this retrained model to label the test corpus. In other words, we
removed step 25 in Algorithm 1. This can be considered as a form of self-training. Results
on both the test and out-of-domain sets show that using automatically generated labels
instead of projected ones seriously impairs the resulting model, with F1-scores decreasing
by almost 6% on the test set and 8% on the out-of-domain set (see last row of Table 8).
5.3 Transformation Rules Improve Performance of Relations Involving Long
Dependency Paths
The dependency path (the sequence of arcs through the syntactic dependency tree) between
a predicate and its argument is typically short. Table 14 shows that in the gold-labeled
test set, three-quarters of the arguments are direct dependency heads or children of the
predicate, or in the case of nominal predicates, the argument is the predicate itself. Existing
SRL models are highly accurate over these shorter pathsthe original SRL model has an
F1-score of almost 89%but prediction accuracy drops considerably as the dependency path
grows. As can be seen in Table 14, adding rewrites to the training set improves prediction
accuracy for almost all combinations of transformation grammar and dependency path
distance, and the largest gains are seen when the number of arcs in the dependency path
156

fiText Rewriting Improves Semantic Role Labeling

Original
H&S
PPDB
T3
QTSG
T3+QTSG
PPDB+T3
PPDB+QTSG
PPDB+QTSG+T3

P
88.44
88.68
86.42
88.04
88.41
88.24
86.61
86.70
87.94

In-domain
R
F1
84.42 86.38
84.34 86.46
84.64 85.52 
84.78 86.38
85.05 86.70 
85.21 86.70 
84.45 85.51 
84.81 85.75 
85.25 86.57 

Out-of-domain
P
R
F1
77.89 72.73 75.22
78.11 71.76 74.80
76.73 73.36 75.01 
77.07 72.97 74.97
78.34 73.70 75.95 
78.00 73.53 75.70 
77.30 73.51 75.35 
77.41 73.82 75.57 
77.67 73.73 75.64 

Table 15: Results on the CoNLL test sets for models combining extended training data and
global reranker.  Difference from Original is significant at p < 0.01.  Difference
from H&S is significant at p < 0.01.

is between three and six. Improvements in F1-score are observed for individual grammars
and their combination (PPDB+QTSG+T3).
5.4 Transformation Rules Improve Performance Even When a Global
Reranker is Used
The SRL system we used (Bjorkelund et al., 2009) can optionally incorporate a global
reranker (Toutanova, Haghighi, & Manning, 2005). The reranker re-scores the complete
predicate-argument structure, using features from all stages of the local pipeline and additional features representing the sequence of core argument labels for the current predicate.
Table 15 presents evaluation results for a global reranker trained with the extended corpora
produced by our method. Compared to the model trained on the original corpus, adding
the reranker does provide significant improvement.3 Training on the extended data gives
further increases in performance; these are now smaller, though still significant, than was
the case in Table 8. This indicates that the global reranker is compensating for some, but
not all, of the new information contained in the extended training data.
5.5 Transformation Rules Improve Performance Across (Small and Large)
Datasets
We also investigated the accuracy of the labeler as a function of the size of the original
training data. For each size, subsets of the original training data were created (with replacement) and used to train the SRL model, and the performance of each resulting model
measured using the development set. For each training subset, we applied Algorithm 1: the
original SRL model was trained only on the subset; we created an extended corpus from
3. The scores reported here are higher than the official CoNLL-2009 ones (in domain P:87.46, R:83.87,
F1:85.63; out of domain P:76.04, R:70.76, F1:73.31) through using the mate-tools NLP pipeline for
the dependency parse, rather than the dependency information provided in the test set.

157

fiWoodsend & Lapata




80

80











75




75












70

70

Recall

Precision











Rewrites



Source


65



65



60

60






55

55
160

625

2500

10000

40000



160

Source sentences

625

2500

10000

40000

Source sentences

Figure 5: SRL model performance as a function of the size of the training data, with and
without additional rewrites. Error bars show standard error over 10 experiments.

the subset using the grammar; an SVM was trained each time to refine the transformations
to those that preserved labels; and the SRL model retrained on the original plus refined
rewritten version of the corpus subset.
In particular, we wanted to investigate if the rewritten text provided a performance
benefit when there was only a small amount of training data, and any such benefit would be
subsumed if more labeled training data was provided. The learning curves in Figure 5 show
the contrary: while increasing the quantity of source training data undoubtedly improves
the quality of the SRL model, we found that including the rewritten training data in addition
consistently improves both precision and recall measures. The learning curves in Figure 5
use the QTSG grammar as the set of transformation functions; we obtained similar results
with PPDB and T3 (and all grammar combinations), however we omit them for the sake
of brevity.

6. Conclusions
In this paper we investigated the potential of text rewriting as a means of increasing the
amount of training data available for supervised NLP tasks. Our method automatically
extracts rewrite rules from comparable corpora and uses them to generate multiple syntactic variants for sentences annotated with gold standard labels. Application of our method
to semantic role labeling reveals that syntactic transformations improve SRL performance
158

fiText Rewriting Improves Semantic Role Labeling

QTSG

PPDB

hNP, NPi



h[NP DT

hNP, NPi



h[NP NP

hNP, Si



h[NP NP

hS, Si



h[S even if it VBZ

hADJP, ADJPi



h[ADJP just as JJ

hPP, PPi



h[PP in the past month], [PP in the last month]i

1
1
1

JJ



, NP
PP

NNS

], [NP DT

CC NP



2

2



1

NP

2

NNS

], [NP NP

], [S It is NP
1

1

1

PP

2

1

2

]i

]i

.]i

], [S even though it VBZ

], [ADJP equally JJ

1

1

NP

2

]i

]i

Table 16: Examples of QTSG and PPDB synchronous grammar rules given high importance
during refinement. Boxed indices indicate alignment, .

beyond the sate of the art on the CoNLL 2009 benchmark dataset. Specifically, we experimentally show that (a) rewrite rules, whether automatic or hand-written, consistently
improve SRL performance, although automatic variants tend to perform best; (b) syntactic transformations improve SRL performance both within- and out-of-domain; and (c)
improvements are observed across learners, even when using a global reranker.
In the future we would like to explore better ways of identifying the best (i.e., performance enhancing) rewrite rules which may be task and grammar specific. Table 16
illustrates the rules deemed important (i.e., given high weight) by our SVM classifier for
the SRL task. For instance, we could undertake more detailed feature engineering, including tree-based and ngram features to capture the grammaticality of the rewritten sentences.
Throughout this paper we have argued that transformation rules can be used to enhance
performance in the SRL task. Conversely, some of the work described here might be of
relevance to other NLP tasks employing rewriting. For example, the idea of identifying
label preserving transformations, could be used to learn which rules are meaning preserving
and consequently safe to use in tasks such simplification or sentence compression. Machine
translation, textual entailment, and semantic parsing are additional application areas which
stand to benefit from more accurate rewrite rules. Much of the methodology reported here
could be adapted to machine translation either for training with larger datasets (CallisonBurch, Koehn, & Osborne, 2006), for domain-adaptation (Irvine, Quirk, & Daume III,
2013), or evaluation (Kauchak & Barzilay, 2006)
Finally, beyond supervised SRL, we would like to adapt our method to unsupervised
semantic role induction (Lang & Lapata, 2011; Titov & Klementiev, 2012), investigate alternative synchronous grammar extraction methods (e.g., based on dependency information),
and obtain rewrite rules from larger comparable corpora.

Acknowledgments
We are grateful to the anonymous referees whose feedback helped to substantially improve
the present paper. We acknowledge the financial support of EPSRC (EP/K017845/1) in
the framework of the CHIST-ERA READERS project.
159

fiWoodsend & Lapata

References
Aho, A. V., & Ullman, J. D. (1969). Syntax directed translations and the pushdown assembler. Journal of Computer and System Sciences, 3 (1), 3756.
Bannard, C., & Callison-Burch, C. (2005a). Paraphrasing with Bilingual Parallel Corpora.
In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pp. 597604, Ann Arbor.
Bannard, C., & Callison-Burch, C. (2005b). Paraphrasing with Bilingual Parallel Corpora.
In Proceedings of the 43rd ACL, pp. 255262, Ann Arbor, MI.
Barzilay, R., & McKeown, K. (2001). Extracting Paraphrases from a Parallel Corpus. In
Proceedings of the ACL/EACL, pp. 5057, Toulouse, France.
Bjorkelund, A., Hafdell, L., & Nugues, P. (2009). Multilingual semantic role labeling. In
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task, pp. 4348, Boulder, Colorado. Software retrieved
from https://code.google.com/p/mate-tools/.
Callison-Burch, C. (2007). Paraphrasing and Translation. Ph.D. thesis, University of Edinburgh.
Callison-Burch, C. (2008). Syntactic Constraints on Paraphrases Extracted from Parallel
Corpora. In Proceedings of the 2008 Conference on Empirical Methods in Natural
Language Processing, pp. 196205, Honolulu, Hawaii.
Callison-Burch, C., Koehn, P., & Osborne, M. (2006). Improved statistical machine translation using paraphrases. In Proceedings of the Human Language Technology Conference
of the NAACL, Main Conference, pp. 1724, New York City, USA.
Chandrasekar, R., Doran, C., & Srinivas, B. (1996). Motivations and Methods for Text
Simplification. In Proceedings of the 16th International Conference on Computational
Linguistics, pp. 10411044, Copenhagen, Denmark.
Chiang, D. (2007). Hierarchical Phrase-Based Translation. Computational Linguistics,
33 (2), 201228.
Cohn, T., & Lapata, M. (2009). Sentence Compression as Tree Transduction. Journal of
Artificial Intelligence Research, 34, 637674.
Cohn, T., & Lapata, M. (2013). An abstractive approach to sentence compression. ACM
Trans. Intell. Syst. Technol., 4 (3), 41:141:35.
Coster, W., & Kauchak, D. (2011). Simple English Wikipedia: A New Text Simplification
Task. In Proceedings of the 49th Annual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pp. 665669, Portland, Oregon, USA.
Dowty, D. (1991). Thematic Proto Roles and Argument Selection. Language, 67 (3), 547
619.
Eisner, J. (2003). Learning Non-Isomorphic Tree Mappings for Machine Translation. In
Proceedings of the ACL Interactive Poster/Demonstration Sessions, pp. 205208, Sapporo, Japan.
160

fiText Rewriting Improves Semantic Role Labeling

Fan, R. E., Chang, K. W., Hsieh, C. J., Wang, X. R., & Lin, C. J. (2008). LIBLINEAR:
A Library for Large Linear Classification. Journal of Machine Learning Research, 9,
18711874.
Feblowitz, D., & Kauchak, D. (2013). Sentence simplification as tree transduction. In
Proceedings of the Second Workshop on Predicting and Improving Text Readability
for Target Reader Populations, pp. 110, Sofia, Bulgaria.
Furstenau, H., & Lapata, M. (2012). Semi-supervised semantic role labeling via structural
alignment. Computational Linguistics, 38 (1), 135171.
Galley, M., & McKeown, K. (2007). Lexicalized Markov Grammars for Sentence Compression. In Proceedings of the NAACL/HLT, pp. 180187, Rochester, NY.
Ganitkevitch, J., Callison-Burch, C., Napoles, C., & Van Durme, B. (2011). Learning
Sentential Paraphrases from Bilingual Parallel Corpora for Text-to-Text Generation.
In Proceedings of the 2011 Conference on Empirical Methods in Natural Language
Processing, pp. 11681179, Edinburgh, Scotland, UK.
Ganitkevitch, J., Cao, Y., Weese, J., Post, M., & Callison-Burch, C. (2012). Joshua 4.0:
Packing, pro, and paraphrases. In Proceedings of the Seventh Workshop on Statistical
Machine Translation, pp. 283291, Montreal, Canada.
Ganitkevitch, J., Van Durme, B., & Callison-Burch, C. (2013). PPDB: The Paraphrase
Database. In Proceedings of the 2013 Conference of the North American Chapter of
the Association for Computational Linguistics: Human Language Technologies, pp.
758764, Atlanta, Georgia. We used the prepackaged small constituent syntactic
subset of PPDB, retrieved from http://paraphrase.org.
Gildea, D., & Jurafsky, D. (2002). Automatic Labeling of Semantic Roles. Computational
Linguistics, 28 (3), 245288.
Graehl, J., & Knight, K. (2004). Training Tree Transducers. In HLT-NAACL 2004: Main
Proceedings, pp. 105112, Boston, MA.
Hajic, J., Ciaramita, M., Johansson, R., Kawahara, D., Mart, M. A., Marquez, L., Meyers,
A., Nivre, J., Pado, S., Stepanek, J., Stranak, P., Surdeanu, M., Xue, N., & Zhang, Y.
(2009). The conll-2009 shared task: Syntactic and semantic dependencies in multiple
languages. In Proceedings of the Thirteenth Conference on Computational Natural
Language Learning (CoNLL 2009): Shared Task, pp. 118, Boulder, Colorado.
Heilman, M., & Smith, N. (2010). Extracting Simplified Statements for Factual Question
Generation. In Proceedings of the 3rd Workshop on Question Generation, pp. 1120,
Carnegie Mellon University, PA. Software available at http://www.ark.cs.cmu.edu/
mheilman/questions/.
Irvine, A., Quirk, C., & Daume III, H. (2013). Monolingual marginal matching for translation model adaptation. In Proceedings of the 2013 Conference on Empirical Methods
in Natural Language Processing, pp. 10771088, Seattle, Washington, USA.
Kauchak, D. (2013). Improving text simplification language modeling using unsimplified
text data. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 15371546, Sofia, Bulgaria. We used
161

fiWoodsend & Lapata

the Version 2.0 sentence-aligned corpus, retrieved from http://www.cs.middlebury.
edu/~dkauchak/simplification/.
Kauchak, D., & Barzilay, R. (2006). Paraphrasing for automatic evaluation. In Proceedings
of the Human Language Technology Conference of the NAACL, Main Conference, pp.
455462, New York City, USA.
Klebanov, B. B., Knight, K., & Marcu, D. (2004). Text Simplification for InformationSeeking Applications. In Meersman, R., & Tari, Z. (Eds.), On the Move to Meaningful
Internet Systems 2004: CoopIS, DOA, and ODBASE, pp. 735747. Springer Berlin
Heidelberg.
Koehn, P. (2010). Statistical Machine Translation. Cambridge University Press.
Koehn, P., Och, F. J., & Marcu, D. (2003). Statistical phrase-based translation. In Proceedings of the HLT/NAACL, pp. 4854, Edmonton, Canada.
Kundu, G., & Roth, D. (2011). Adapting Text instead of the Model: An Open Domain
Approach. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pp. 229237, Portland, Oregon, USA.
Kwiatkowski, T. (2012). Probabilistic Grammar Induction from Sentences and Structured
Meanings. Ph.D. thesis, University of Edinburgh.
Lang, J., & Lapata, M. (2011). Unsupervised semantic role induction via split-merge clustering. In Proceedings of the 49th Annual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pp. 11171126, Portland, Oregon, USA.
Liang, P., Taskar, B., & Klein, D. (2006). Alignment by Agreement. In Proceedings of the
HLT/NAACL, pp. 104111, New York, NY.
Marton, Y., Callison-Burch, C., & Resnik, P. (2009). Improved statistical machine translation using monolingually-derived paraphrases. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Processing, pp. 381390, Singapore.
Mehdad, Y., Negri, M., & Federico, M. (2010). Towards cross-lingual textual entailment. In
Human Language Technologies: The 2010 Annual Conference of the North American
Chapter of the Association for Computational Linguistics, pp. 321324, Los Angeles,
California.
Melli, G., Wang, Y., Liu, Y., Kashani, M. M., Shi, Z., Gu, B., Sarkar, A., & Popowich, F.
(2005). Description of SQUASH, the SFU Question Answering Summary Handler for
the DUC-2005 Summarization Task. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language
Processing Document Understanding Workshop, Vancouver, Canada.
Noreen, E. (1989). Computer-intensive methods for testing hypotheses: an introduction.
Wiley.
Pado, S. (2006). Users guide to sigf: Significance testing by approximate randomisation.
Retrieved from http://www.nlpado.de/~sebastian/software/sigf.shtml.
Palmer, M., Gildea, D., & Kingsbury, P. (2005). The Proposition Bank: An Annotated
Corpus of Semantic Roles. Computational Linguistics, 31 (1), 71106.
162

fiText Rewriting Improves Semantic Role Labeling

Pang, B., Knight, K., & Marcu, D. (2003). Syntax-based Alignment of Multiple Translations:
Extracting Paraphrases and Generating New Sentences. In Proceedings of the NAACL,
pp. 181188, Edmonton, Canada.
Park, J. H., Croft, B., & Smith, D. A. (2011). A Quasi-synchronous Dependence Model for
Information Retrieval. In Proceedings of the 20th ACM International Conference on
Information and Knowledge Management, pp. 1726, Glasgow, United Kingdom.
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel,
M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau,
D., Brucher, M., Perrot, M., & Duchesnay, E. (2011). Scikit-learn: Machine learning
in Python. Journal of Machine Learning Research, 12, 28252830.
Shen, D., & Lapata, M. (2007). Using Semantic Roles to Improve Question Answering. In
Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language
Processing and Computational Natural Language Learning (EMNLP-CoNLL), pp. 12
21, Prague, Czech Republic.
Surdeanu, M., Harabagiu, S., Williams, J., & Aarseth, P. (2003). Using Predicate-Argument
Structures for Information Extraction. In Proceedings of the Annual Meeting of the
Association for Computational Linguistics, pp. 815, Sapporo, Japan.
Titov, I., & Klementiev, A. (2012). A bayesian approach to unsupervised semantic role
induction. In Proceedings of the 13th Conference of the European Chapter of the
Association for Computational Linguistics, pp. 1222, Avignon, France.
Toutanova, K., Haghighi, A., & Manning, C. (2005). Joint learning improves semantic role
labeling. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL05), pp. 589596, Ann Arbor, Michigan.
Vapnik, V. (1995). The Nature of Statistical Learning Theory. Springer-Verlag New York,
Inc.
Vickrey, D., & Koller, D. (2008). Sentence simplification for semantic role labeling. In
Proceedings of ACL-08: HLT, pp. 344352, Columbus, Ohio.
Wang, M., & Manning, C. (2010). Probabilistic tree-edit models with structured latent
variables for textual entailment and question answering. In Proceedings of the 23rd
International Conference on Computational Linguistics (Coling 2010), pp. 11641172,
Beijing, China.
Wang, M., Smith, N. A., & Mitamura, T. (2007). What is the Jeopardy model? a quasisynchronous grammar for QA. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language
Learning (EMNLP-CoNLL), pp. 2232, Prague, Czech Republic.
Woodsend, K., & Lapata, M. (2011). Learning to simplify sentences with quasi-synchronous
grammar and integer programming. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pp. 409420, Edinburgh, Scotland, UK.
We used the Wikipedia revisions corpus, retrieved from http://homepages.inf.ed.
ac.uk/kwoodsen/wiki.html.
Woodsend, K., & Lapata, M. (2012). Multiple aspect summarization using integer linear
programming. In Proceedings of the 2012 Joint Conference on Empirical Methods
163

fiWoodsend & Lapata

in Natural Language Processing and Computational Natural Language Learning, pp.
233243, Jeju Island, Korea.
Wu, D. (1997). Stochastic Inversion Transduction Grammars and Bilingual Parsing of
Parallel Corpora. Computational Linguistics, 23 (3), 377404.
Wu, D., & Fung, P. (2009). Semantic Roles for SMT: A Hybrid Two-Pass Model. In Proceedings of Human Language Technologies: The Annual Conference of the North American
Chapter of the Association for Computational Linguistics, Companion Volume: Short
Papers, pp. 1316, Boulder, Colorado.
Yamada, K., & Knight, K. (2001). A Syntax-based Statistical Translation Model. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,
pp. 523530, Toulouse, France.
Yamangil, E., & Nelken, R. (2008). Mining Wikipedia revision histories for improving
sentence compression. In Proceedings of ACL-08: HLT, Short Papers, pp. 137140,
Columbus, Ohio.
Zanzotto, F. M., & Pennacchiotti, M. (2010). Expanding textual entailment corpora
fromwikipedia using co-training. In Proceedings of the 2nd Workshop on The Peoples Web Meets NLP: Collaboratively Constructed Semantic Resources, pp. 2836,
Beijing, China. Coling 2010 Organizing Committee.
Zhu, Z., Bernhard, D., & Gurevych, I. (2010). A Monolingual Tree-based Translation Model
for Sentence Simplification. In Proceedings of the 23rd International Conference on
Computational Linguistics, pp. 13531361, Beijing, China.

164

fiJournal of Artificial Intelligence Research 51 (2014) 227-254

Submitted 04/14; published 09/14

Entrenchment-Based Horn Contraction
Zhiqiang Zhuang

z.zhuang@griffith.edu.au

Institute for Integrated and Intelligent Systems
Griffith University, QLD 4111, Australia

Maurice Pagnucco

morri@cse.unsw.edu.au

School of Computer Science and Engineering
The University of New South Wales, NSW 2052, Australia

Abstract
The AGM framework is the benchmark approach in belief change. Since the framework
assumes an underlying logic containing classical Propositional Logic, it can not be applied
to systems with a logic weaker than Propositional Logic. To remedy this limitation, several
researchers have studied AGM-style contraction and revision under the Horn fragment of
Propositional Logic (i.e., Horn logic). In this paper, we contribute to this line of research
by investigating the Horn version of the AGM entrenchment-based contraction. The study
is challenging as the construction of entrenchment-based contraction refers to arbitrary disjunctions which are not expressible under Horn logic. In order to adapt the construction to
Horn logic, we make use of a Horn approximation technique called Horn strengthening. We
provide a representation theorem for the newly constructed contraction which we refer to as
entrenchment-based Horn contraction. Ideally, contractions defined under Horn logic (i.e.,
Horn contractions) should be as rational as AGM contraction. We propose the notion of
Horn equivalence which intuitively captures the equivalence between Horn contraction and
AGM contraction. We show that, under this notion, entrenchment-based Horn contraction
is equivalent to a restricted form of entrenchment-based contraction.

1. Introduction
Given an agent with a set of beliefs, the theory of belief change deals with how the agent
changes its beliefs in a rational manner when it is confronted with new information. Two
kinds of changes are mainly studied, namely contraction and revision, for removing old
beliefs and for incorporating new beliefs respectively. The main strategies for studying
belief change are to articulate principles called rationality postulates that rational agents
should obey when contracting or revising their sets of beliefs and to specify explicit change
mechanisms called construction methods for the contraction and revision operation.
The dominant theory of belief change is the so called AGM framework (Alchourron,
Gardenfors, & Makinson, 1985; Gardenfors, 1988). The framework does not specify a specific underlying logic, however, it assumes that the logic contains classical Propositional
Logic. It is commonly accepted that the AGM framework provides the best set of rationality postulates for capturing the intuitions behind rational belief change along with well
motivated construction methods that can be characterised by the rationality postulates.
Regardless of its desirable properties, this assumption on the underlying logic is a severe
limitation.
Tractable fragments of Propositional Logic and some non-classic logics such as Description Logics (Baader, Calvanese, McGuinness, Nardi, & Patel-Schneider, 2003) are particuc
2014
AI Access Foundation. All rights reserved.

fiZhuang & Pagnucco

larly useful in artificial intelligence applications as they allow for efficient reasoning methods.
Since knowledge evolves, systems based on these logics are subject to change. However, fragments of Propositional Logic and Description Logics do not subsume Propositional Logic,
thus the AGM framework can not be applied to these systems. Consequently, extensive
attention has been paid to the problem of belief change under fragments of Propositional
Logic and Description Logics. A recent trend focuses on the Horn fragment of Propositional Logic (i.e., Horn Logic) which has found extensive usage in artificial intelligence and
database systems. In this paper we contribute to Horn belief change by thoroughly investigating the Horn version of entrenchment-based contraction (Gardenfors & Makinson, 1988;
Gardenfors, 1988) which we refer to as entrenchment-based Horn contraction.
Entrenchment-based contraction is based on rankings of formulas called epistemic entrenchments. The general idea is that formulas more entrenched in the ranking are more
preferred to those less entrenched and, when deciding which formulas to give up in a contraction; it is intuitive to give up the less preferred beliefs. An obvious obstacle in adapting
the entrenchment-based contraction to Horn logic is that the standard construction refers
to disjunctions which may be non-Horn formulas. Therefore, we can not apply the construction method directly under Horn logic. To get around this expressiveness problem we
propose to replace the non-Horn formulas with their Horn approximations (Kautz & Selman, 1996). The contraction thus constructed satisfies Horn versions of all the characterising
postulates for entrenchment-based contraction, except the Recovery postulate (Alchourron
et al., 1985). Due to the limited expressiveness of Horn logic, entrenchment-based Horn
contraction is not as comprehensive as entrenchment-based contraction. Therefore, in characterising entrenchment-based Horn contraction, an extra postulate is needed to capture
how restricted it is (compared to entrenchment-based contraction).
Ideally, Horn contraction should perform as rationally as AGM contraction. To evaluate the rationality of Horn contractions against AGM contraction, we propose the notion
of Horn equivalence which formalises the equivalence between Horn contraction functions
and AGM contraction functions from a constructive point of view. Horn contractions are
restricted to Horn formulas, thus it is fair to say a Horn contraction function performs
as rationally as an AGM one if the change over Horn formulas as a result of the AGM
contraction function is identical to that incurred by the Horn contraction function. Put
simply, a Horn contraction function is Horn equivalent to its AGM counterpart if they behave identically in terms of Horn formulas. In other words, Horn equivalence implies that
the change mechanism of the AGM contraction function is exactly the same as that of the
Horn contraction function, thus the latter preserves every property of the former. We are
able to identify a restricted form of entrenchment-based contraction that has a one-to-one
correspondence with entrenchment-based Horn contraction by means of Horn equivalence.
Due to the contention over the Recovery postulate, Makinson introduced the idea of
a Withdrawal function which encompasses a broader class of belief contraction functions.
In the AGM setting, Rott and Pagnucco (1999) explored severe withdrawal, an operation
similar to contraction but defined intentionally to violate the Recovery postulate. They propose a construction for severe withdrawal that is based on epistemic entrenchment which
we refer to as entrenchment-based withdrawal. Different from entrenchment-based contraction, the construction does not refer to arbitrary disjunctions. Moreover, as we will see,
Horn contractions are intrinsically incompatible with Recovery, thus it is curious to see
228

fiEntrenchment-Based Horn Contraction

if entrenchment-based withdrawal is seamlessly transferable to Horn logic. Through investigating the Horn version of entrenchment-based withdrawal we can give an affirmative
answer.
The rest of this paper is organised as follows. We first give the technical preliminaries
in Section 2, then in Section 3 we recall the details of entrenchment-based contraction.
In Section 4, we introduce entrenchment-based Horn contraction and present its representation theorem. In Section 5, we compare entrenchment-based Horn contraction and
entrenchment-based contraction through the notion of Horn equivalence. In Section 6 we
introduce entrenchment-based Horn withdrawal and demonstrate its close connection with
entrenchment-based withdrawal. Finally, the related work and conclusions are given in Section 7 and Section 8 respectively. Proofs are given in the appendix. This paper is a revised
and extended version of (Zhuang & Pagnucco, 2010).

2. Technical Preliminaries
We assume a propositional language L over a finite set of atoms P which is closed under
the usual truth-functional connectives and contains the propositional constants > (truth)
and  (falsum). Atoms are denoted by lower case Roman letters (p, q, . . .). Formulas are
denoted by lower case Greek letters (, , . . .). Sets of formulas are denoted by upper case
Roman letters (V, X, . . .).
The logic generated from L is specified by the standard Tarskian consequence operator
Cn. For any set of formulas X, Cn(X) denotes the set of formulas following logically from
X. For any formula , Cn() abbreviates Cn({}). We sometimes write X `  to denote
  Cn(X),    to denote Cn() = Cn(), and `  to denote   Cn(). The letter
K is reserved to represent a theory or a belief set which is a set of formulas such that
K = Cn(K). Standard propositional semantics is assumed. An interpretation  is a model
of a formula  if  is true in . For any set of formulas X, |X| denotes the set of models of
X. For any formula , || abbreviates |{}|.
A clause is a disjunction of positive and negative atoms. A Horn clause is a clause that
contains at most one positive atom, e.g. a  b  c. A Horn formula is a conjunction
of Horn clauses. The Horn language LH is the maximal subset of L containing only Horn
formulas. The Horn logic generated from LH is specified by the consequence operator CnH
such that, for any set of Horn formulas X, CnH (X) = Cn(X)  LH . The letter H is reserved
to represent a Horn theory or a Horn belief set which is a set of Horn formulas such that
H = CnH (H). The Horn subset function H : 2L  2LH is such that given a set of formulas
X, H(X) is the set of Horn formulas in X. Formally, H(X) = LH  X.

3. Entrenchment-Based Contraction
.
An AGM contraction function  takes as input a belief set K and a formula  and returns
.
another belief set K . We refer to K as the original belief set,  as the contracting
.
formula, and K  as the resulting belief set. Various constructions have been proposed
for contraction in the AGM framework. In this section, we review a classical one called
entrenchment-based contraction (Gardenfors, 1988; Gardenfors & Makinson, 1988).
229

fiZhuang & Pagnucco

The beliefs held by an agent are not equal in terms of epistemological importance. In
the work of Gardenfors (1988) and Gardenfors and Makinson (1988), the more important
beliefs are said to be more entrenched than the others. The idea behind entrenchmentbased contraction is that, in a contraction, we should give up the less entrenched formulas
whenever possible. The relative entrenchments between formulas are modeled by epistemic
entrenchments. Given a belief set K, the epistemic entrenchment associated with K is a
binary relation  over L such that    means  is at least as entrenched as . The
strict relation  <  is defined as    and  6 . Importantly,  satisfies the following
conditions:
(EE1)
(EE2)
(EE3)
(EE4)
(EE5)

If    and   , then   
If  ` , then   
     or     
If K 6`, then  6 K iff    for every 
If    for every , then ` 

(Transitivity)
(Dominance)
(Conjunctiveness)
(Minimality)
(Maximality)

Thus an epistemic entrenchment is a transitive relation (EE1) such that logically stronger
formulas are not more entrenched than weaker ones (EE2), a conjunction is equally or more
entrenched than one of its conjuncts (EE3), non-beliefs are least entrenched (EE4), and
tautologies are most entrenched (EE5).
Entrenchment-based contraction is defined through two conditions which establish the
connections between epistemic entrenchments and contraction functions. Condition (C )
generates an epistemic entrenchment from a contraction function. The motivation is that,
in the contraction of K by   , we have to give up either  or  (or both), however, it is
more intuitive to give up the epistemically less important one. Thus, if  is retracted, then
it must be the case that  is at least as entrenched as . In the limiting case that  and 
are both tautologies, they are equally important and, by (EE5), required to be maximally
entrenched.
.
(C ) :    iff  6 K    or `   .
.
Condition (C ) derives a contraction function from an epistemic entrenchment. Accord.
ing to (C ),  is retained in the contraction by  if and only if it was originally believed
(i.e.,   K) and either there is sufficient evidence for retaining it (i.e.,  <   ) or it
is not possible to remove  (i.e., ` ).
.
.
(C ) :   K  iff   K and either  <    or ` .
.
The contraction function generated via (C ) is referred to as an entrenchment-based
contraction function.
.
Definition 1 (Gardenfors & Makinson, 1988) A function  is an entrenchment-based contraction function for K iff its outcome is determined by the epistemic entrenchment for K
.
via (C ).
As pointed out in the work of Gardenfors and Makinson (1988), it is rather difficult to
.
motivate (C ), however, its appropriateness can be justified by the representation theorem
for entrenchment-based contraction.
230

fiEntrenchment-Based Horn Contraction

.
Theorem 1 (Gardenfors & Makinson, 1988) A function  is an entrenchment-based con.
traction function iff  satisfies the following postulates:
.
. = Cn(K )
.
(K 1)
K 
(Closure)
.
.
(K 2) K   K
(Inclusion)
.
. =K
(K 3)
If  6 K, then K 
(Vacuity)
.
.
(K 4) If 6` , then  6 K 
(Success)
.
. +
(K 5)
K  (K )
(Recovery)
.
. = K 
.
(K 6)
If   , then K 
(Extensionality)
.
.
.
.
(K 7) K   K   K   
(Conjunctive Overlap)
.
.   then K 
.    K 
.
(K 8)
If  6 K 
(Conjunctive Inclusion)

By Theorem 1, entrenchment-based contraction functions are characterised by the full set
.
.
.
.
of AGM postulates for contraction (K 1)(K 8). In the AGM tradition, (K 1)(K 6)
.
.
are referred to as the basic postulates and (K 7) and (K 8) are referred to as the supplementary postulates. According to the basic postulates, a contraction produces a belief set
.
.
(K 1) which does not contain the contracting formula unless it is a tautology (K 4). The
.
produced belief set is not larger than the original one (K 2). If the contracting formula
.
is not believed, then nothing has to be done (K 3). The contraction is syntax-insensitive
.
(K 6) and when the contracted formula is added back to the contracted belief set, the
.
.
result entails every formula in the original belief set (K 5). (K 5), which is often called
Recovery, is controversial and has been the subject of much discussion (e.g., Makinson, 1987;
Hansson, 1991; Levi, 1991). For example in the work of Hansson (1991), it is argued as an
emerging property rather than a fundamental postulate for contraction. The supplementary
postulates concern relations between contraction by a conjunction and contractions by the
constituent conjuncts. Formulas surviving the contraction of each conjunct also survive the
.
contraction by the conjunction (K 7). If a conjunct is removed in the contraction by the
conjunction, then formulas surviving the contraction by the conjunction also survive the
.
contraction by the removed conjunct (K 8).
.
Some postulates equivalent to (K 7) have been proposed which are essential for proving
the representation theorems for AGM contractions. In the presence of the basic postulates,
.
(K 7) is equivalent to the postulate of Partial Antitony (Alchourron et al., 1985)
.
.
.
(K pa) K   Cn()  K (  )
and the postulate of Conjunctive Trisection (Rott, 1992; Hansson, 1993).
.
.
.
(K ct) If   K (  ) then   K (    )
.
.
(K pa) has a rather technical nature, however, (K ct) is well motivated. Informally
speaking, it says the preferred belief (i.e., ) of a pair (i.e., , ) is not the least preferred
when a third belief (i.e., ) is added to the pair. In a contraction, it is rational to discard
the less entrenched formulas whenever possible, thus  being retained in contracting by
   means  is more entrenched than . Since  is more entrenched than , it is not the
least entrenched one among , , and . Therefore,  should be retained in contracting by
    . In other words, preferences cannot be changed when other beliefs are considered.
231

fiZhuang & Pagnucco

4. Entrenchment-Based Horn Contraction
Although entrenchment-based contraction is defined while assuming Propositional Logic,
the intuition behind the construction is universal and can be applied to fragments of Propositional Logic. In this section, we apply the intuition to the Horn fragment.
4.1 Horn Strengthening
Standard entrenchment-based contraction makes use of a disjunctive formula in the condi.
tion (C ). In adapting the construction method to Horn logic, an immediate problem is
that the disjunctive formula may be non-Horn. In such cases, we propose to replace the
non-Horn formula with its Horn approximations, more precisely, its Horn strengthenings
(Kautz & Selman, 1996). The notion of Horn strengthening is proposed by Kautz and
Selman in the context of knowledge compilation. Their original definition is for clauses and
sets of clauses such that a Horn strengthening for a clause C is logically the weakest Horn
clause that entails C and a Horn strengthening for a set of clauses {C1 , . . . , Cn } is any set of
Horn clauses {C10 , . . . , Cn0 } where Ci0 is the Horn strengthening of Ci . Here we reformulate
their definition to cover arbitrary formulas such that, for a formula , a Horn strengthening
is logically the weakest Horn formula that entails .
Definition 2 Let  be a formula. The set of Horn strengthenings of , denoted by HS(),
is such that   HS() iff
1.   LH ;
2. ||  ||; and,
3. there is no 0  LH such that ||  |0 |  ||.
According to Definition 2, a Horn formula has one Horn strengthening, namely itself. In the
limiting case of  being a tautology, we assume that its single Horn strengthening is itself.
The following results provide new properties of Horn strengthenings that will be helpful in
this paper. Firstly, since Definition 2 is model-theoretic, the set of Horn strengthenings for
logically equivalent formulas are identical.
Lemma 1 If   , then HS() = HS().
If a Horn formula  entails another formula  which is not necessarily Horn, then  must
also entail a Horn strengthening of .
Lemma 2 If  is a Horn formula such that  ` , then there is   HS() such that
 ` .
Any Horn strengthening of a conjunction can be formed by conjoining some Horn strengthenings for each conjunct.
Lemma 3 If   HS(  ), then there is 1  HS() and 2  HS() such that
  1  2 .
232

fiEntrenchment-Based Horn Contraction

If  is a Horn strengthening of    such that  and  are Horn formulas, then every Horn
strengthening of    is a Horn strengthening of   .
Lemma 4 Let  and  be Horn formulas. If   HS(  ), then HS(  )  HS(  ).
4.2 Construction
In constructing the Horn version of an entrenchment-based contraction function, we also
need a relation that captures the relative importance between formulas. Since, in Horn belief
change, formulas are restricted to the Horn fragment of Propositional Logic, the relation is
over Horn formulas. We define a Horn epistemic entrenchment as a binary relation over LH
that satisfies (HEE1)(HEE5):
(HEE1)
(HEE2)
(HEE3)
(HEE4)
(HEE5)

If    and   , then   
If  ` , then   
     or     
If H 6`, then  6 H iff    for every 
If    for every , then ` 

(HEE1)(HEE5) are simply (EE1)(EE5) restricted to Horn formulas and Horn belief
sets. We can derive the following properties for Horn epistemic entrenchment.
Lemma 5 Let  be a Horn epistemic entrenchment. Then  satisfies (cf. (Foo, 1990)):
1.    or   
2. If     , then    or   
3.  <  iff    < 
4. If    and   , then     
5. If  <  and  < , then  <   
6. If   , then     
7. If    then    and   
Particularly, Horn epistemic entrenchment is connected (Item 1) and is such that logically
equivalent formulas are equally entrenched (Item 7).
Clearly, we can obtain a Horn epistemic entrenchment from an epistemic entrenchment
by simply removing the entrenchment relations involving non-Horn formulas. The obtained
Horn epistemic entrenchment is called the Horn subset of the epistemic entrenchment.
Definition 3 Let H be a Horn epistemic entrenchment and P an epistemic entrenchment.
Then H is the Horn subset of P iff
 P  iff  H 
for all ,   LH .
233

fiZhuang & Pagnucco

Notice that each epistemic entrenchment has one Horn subset but different epistemic entrenchments may have the same Horn subset. In the latter case, the epistemic entrenchments
are identical with respect to the entrenchments between Horn formulas but different with
respect to those involving non-Horn formulas.
.
Condition (C ) is central in determining the outcome of entrenchment-based contrac.
tion functions. According to (C ), in the contraction of K by , if  is in K, then the
disjunction  being strictly more entrenched than  is a sufficient condition for retaining
.
. Since    is an arbitrary disjunction, it may not be a Horn formula. Therefore, (C )
is not applicable in Horn logic.
In forming a similar condition for Horn contraction, we replace the non-Horn disjunctions
by their Horn strengthenings which results in the following condition:
.
.
(HC ):   H  iff   H and either `  or there is   HS(  ) such that  < .
.
According to (HC ), in the contraction of H by , if  is in H, then the existence of one
Horn strengthening of    being strictly more entrenched than  is a sufficient condition
.
for retaining . Similar to (C ), another sufficient condition is  being a tautology. Since
   is logically weaker than its Horn strengthenings, for any epistemic entrenchment
(EE2) implies that    is equal or more entrenched than its Horn strengthenings. Thus
by (EE1) if any Horn strengthening of    is strictly more entrenched than , then so is
.
  . The converse, however, does not hold in general. So, informally speaking, (HC )
.
is a stricter condition than (C ) for retaining formulas in a contraction. We refer to the
.
Horn contraction function generated via (HC ) as an entrenchment-based Horn contraction
function.
.
Definition 4 A function  is an entrenchment-based Horn contraction function for H iff
.
its outcome is determined by the Horn epistemic entrenchment for H via (HC ).

p  q  r
p  q  r
p  r
p  q

p  r  q
q  r
H

p  q  r
p  r p  q  r
p  q
p  r  q
q  p  r q  r
P1

p  q  r
p  r
p  q
p  r  q
q  p  r q  r
P2

Figure 1: Entrenchment based Horn contraction function and entrenchment based contraction functions that are determined respectively by H , p1 and P2 such that H
is the Horn subset of P1 and P2 .
Figure 1 demonstrates the contraction of H = CnH ({p  q, q  r}) by p  r such that
.
the contraction is determined by the Horn epistemic entrenchment H via (HC ) and the
contraction of K = Cn(H) by p  r such that the contraction is determined respectively
.
by P1 and P2 via (C ). Notice that H is the Horn subset of both P1 and P2 . The
234

fiEntrenchment-Based Horn Contraction

rectangles illustrate the formulas in the Horn belief set H and the belief set K along with
their entrenchments. Formulas at the same level of a rectangle are equally entrenched.
Formulas at a level higher are strictly more entrenched than those in a level lower. Nonbeliefs, tautologies and conjunctions are not shown as their entrenchments are uniquely
determined by the formulas shown. The shaded formulas are retained after the contraction.
.
Lets examine the fate of p  q in the Horn contraction determined by H via (HC ).
The disjunction of p  q and p  r (i.e., p  q  r) has two Horn strengthenings p 
r and p  q. Since the Horn strengthenings are equally or less entrenched than p 
.
r, then p  q is discarded. In the contractions determined by P1 and P2 via (C ),
since p  q  r is allowed in the epistemic entrenchments the retention of p  q is then
determined by the entrenchment of p  q  r compared to that of p  r. Observe that
the contraction determined by P1 retains the same Horn formulas as the Horn contraction
but that determined by P2 retains more. In Section 5, we identify the entrenchmentbased contraction functions that always retain the same Horn formulas as the corresponding
entrenchment-based Horn contraction function.
Condition (C ) concerns the generation of an epistemic entrenchment from a contraction function. Its Horn version is used for generating a Horn epistemic entrenchment from
a Horn contraction function. It is identical to the (C ) condition but restricted to Horn
formulas.
.
(HC ):    iff  6 H    or `   .
4.3 Characterisation
Before giving the representation theorem for entrenchment-based Horn contraction, let us
consider the following postulates.
.
.
.
(H 1) H  = CnH (H )
.
.
(H 2) H   H
.
.
(H 3) If  6 H, then H  = H
.
.
(H 4) If 6` , then  6 H 
.
.
.
(H de) If   H and  6 H , then for all   HS(  ),  6 H 
.
.
.
(H wr) If   H and  6 H , then there is some H 0 such that H   H 0 ,  6 CnH (H 0 )
and   CnH (H 0  {})
.
.
.
(H 6) If   , then H  = H 
.
.
(H f ) If ` , then H  = H
.
.
.
(H hs) If   H , then there is   HS(  ) such that   H   
.
.
.
(H pa) (H )  CnH ()  H   
.
.
.
(H ct) If   H   , then   H     
235

fiZhuang & Pagnucco

.
.
.
.
(H 7) H   H   H   
.
.
.
.
(H 8) If  6 H   , then H     H 
.
.
Most of these postulates are well known in the belief change literature. (H 1)(H 4) and
.
.
(H 6)(H 8) are Horn versions of the AGM postulates Closure, Inclusion, Vacuity, Suc.
cess, Extensionality, Conjunctive Overlap and Conjunctive Inclusion respectively. (H f )
is the Horn version of the Failure postulate (Fuhrmann & Hansson, 1994).
.
(H de) is the Horn version of the Disjunctive Elimination postulate (Ferme, Krevneris,
& Reis, 2008):1
.
.
.
(K de) If   K and  6 K , then    6 K 
.
(K de) captures the minimal change properties of a contraction; in its contrapositive form
.
.
If   K and     K , then   K 
the postulate is a condition for a sentence  to survive the contraction process (Ferme
et al., 2008, p. 745). Combining some existing results (Ferme et al., 2008; Hansson, 1991),
.
.
.
.
we get that (K de) implies (K 5) in the presence of (K 2) and (K 3). The reverse
.
is also true as we can show that the contrapositive of (K de) follows from Recovery.2
.
.
.
.
Thus (K de) is equivalent to (K 5). (H de) is obtained from (K de) by replacing the
possibly non-Horn disjunction    with its Horn strengthenings. It deals with the removal
of formulas in regard to the related Horn strengthenings such that, if  is removed in
.
contracting , then so are all the Horn strengthenings of   . Interestingly, (H wr) that
is proposed in the work of Delgrande and Wassermann (2010) for characterising partial meet
.
.
Horn contraction is equivalent to (H de) in the presence of (H 2). Also, in the presence
.
.
.
of (H 2), (H f ) follows from (H de).
.
The Horn Strengthening postulate (H hs) has no counterpart in classic belief change.
For entrenchment-based contraction, if a formula  is retained in contracting , then   
is strictly more entrenched than  which means, in accordance with (C ), that    
.
K   (  ). Thus the property can be expressed as:
.
.
If   K , then     K   (  ).
The property however does not have to be postulated explicitly as it is deducible from
.
.
.
(K 6) and (K 1). Since   (  ) is logically equivalent to , by (K 6) we have
.
.
.
.
K   (  ) = K . Then     K   (  ) follows from the fact that   K 
.
and K  is logically closed. For entrenchment-based Horn contraction, if a Horn formula
 is retained in contracting a Horn formula , then there must be a Horn strengthening 
of    that is strictly more entrenched than  which means, in accordance with (HC ),
.
.
that   H   . Such property is captured exactly by (H hs). This time the property is
.
not deducible from other postulates thus we postulate it explicitly. Notice that (H hs) is
in fact the Horn adaptation of the above retention property for the classic case by replacing
the disjunction    with its Horn strengthenings.
1. Disjunctive Elimination was originally proposed in the context of belief base change. It is adapted to
belief set change here.
.
.
2. If  is in K, then Recovery ensures that    is in K . Hence if    is also in K , we have
.
  K .

236

fiEntrenchment-Based Horn Contraction

.
.
(H ct) and (H pa) are Horn versions of Conjunctive Trisection and Partial Antitony.
.
.
.
As in the classical case, (H pa) and (H ct) are equivalent in the presence of (H 6).
.
.
(K pa) and (K 7) are equivalent. Since the proof relies on Recovery which is not available
.
for Horn logic, we can not establish equivalence between their Horn analogues (H pa) and
.
(H 7). Proposition 1 summarises some connections between the postulates.
.
Proposition 1 Let  be a contraction function. Then:
.
.
.
.
1. if  satisfies (H 1) and (H de), then it satisfies (H f );
.
.
.
.
2. if  satisfies (H 2) and (H de), then it satisfies (H wr);
.
.
.
3. if  satisfies (H wr), then it satisfies (H de);
.
.
.
4. if  satisfies (H pa), then it satisfies (H ct); and,
.
.
.
.
5. if  satisfies (H 6) and (H ct), then it satisfies (H pa).
Now, we give the representation theorem for entrenchment-based Horn contraction.
.
Theorem 2 A function  is an entrenchment-based Horn contraction function iff it satis.
.
.
.
.
.
.
fies (H 1)(H 4), (H de), (H 6), (H hs), (H ct), and (H 8).
Comparing with the characterisation for entrenchment-based contraction, Recovery and
.
.
.
Conjunctive Overlap do not appear and instead (H de), (H hs), and (H ct) are used.
Lets go through the new postulates. The condition of decomposability that is proposed in
the work of Flouris, Plexousakis, and Antoniou (2004) characterises the logics that admit
contraction functions that satisfy Recovery. Langlois, Sloan, Szorenyi, and Turan (2008)
verified that Horn logic is not decomposable, thus there is no Horn contraction function that
.
satisfies Recovery. Here, (H de) plays a similar role to Recovery for capturing the minimal
.
change property of entrenchment-based Horn contraction. As just mentioned, (H 7) and
.
.
(H ct) are not equivalent in the Horn case. It turns out that instead of (H 7), it is the
.
property (H ct) that is needed for characterising entrenchment-based Horn contraction.
.
.
.
Since (HC ) is, in a sense, stricter than (C ), we need (H hs) to capture this extra
strictness of entrenchment-based Horn contraction.
Besides the characterising postulates, we can show that entrenchment-based Horn con.
traction functions satisfy (H 7).
.
Proposition 2 If  is an entrenchment-based Horn contraction function, then it satisfies
.
(H 7).
.
.
.
.
.
.
.
By Theorem 2, (H 1)(H 4), (H de), (H 6), (H hs), (H ct), and (H 8) characterise entrenchment-based Horn contraction functions. Thus it follows immediately from
.
Proposition 2 that (H 7) follows from these postulates.
.
.
.
.
.
Corollary 1 Let  be a Horn contraction function. If  satisfies (H 1)(H 4), (H de),
.
.
.
.
.
(H 6), (H hs), (H ct), and (H 8), then it satisfies (H 7).
237

fiZhuang & Pagnucco

Besides the representation results, another property of entrenchment-based Horn contraction that deserves mentioning is its uniqueness. Each Horn epistemic entrenchment
determines a unique entrenchment-based Horn contraction function. Specifically, given any
two distinct Horn epistemic entrenchments 1 and 2 for H and the two entrenchment.
.
based Horn contraction functions they determine 1 and 2 , there is a formula  such that
.
.
H 1  6= H 2 .
.
Theorem 3 Let 1 and 2 be two different Horn epistemic entrenchments and let 1 and
.
2 be entrenchment-based Horn contraction functions that are determined by 1 and 2
.
.
.
respectively via condition (HC ). Then 1 and 2 are not identical.
Uniqueness is a property of AGM contraction. It is shown in (Alchourron et al., 1985) that,
in the finite case, each selection function determines a unique partial meet contraction function (OBSERVATION 4.6). This is a desirable property which captures the intuition that
two agents with different preferences over a certain domain will have different contraction
outcomes. Notice that uniqueness is not an immediate property of Horn contraction and
revision. In fact, most of the existing Horn contractions and Horn revisions do not enjoy
the property, for instance the transitively relational partial meet Horn contraction (Zhuang
& Pagnucco, 2011), the model-based Horn contraction (Zhuang & Pagnucco, 2012), and the
model-based Horn revision (Delgrande & Peppas, 2011).

5. Connections with Entrenchment-Based Contraction
We have seen how entrenchment-based contraction is adapted naturally to Horn logic, which
results in entrenchment-based Horn contraction. But how well does entrenchment-based
Horn contraction perform in comparison to its classic counterpart? In this section, we
introduce the notion of Horn equivalence through which Horn contraction can be compared
with AGM contraction.
A properly defined Horn contraction should be as rational as AGM contraction. Horn
contraction is more restrictive than AGM contraction as it deals only with Horn formulas.
It is then reasonable to consider only Horn formulas in comparing Horn contraction with
AGM contraction. And we claim that a Horn contraction is as rational as an AGM one if
they perform identically in terms of Horn formulas. This forms the intuition behind Horn
equivalence.
In evaluating the possible equivalence between two contraction functions, it makes sense
to start with an identical belief set and check the effect of the two functions in contracting
the same formula. With this intuition and the fact that a Horn contraction function only
permits Horn formulas, Horn equivalence is defined for pairs of AGM contraction function
.
.
 for a belief set K and Horn contraction function H for a Horn belief set H such that H
.
is the Horn subset of K. Consider the set of Horn formulas in the resulting belief set of  in
contracting a Horn formula, if the same set can be returned by the Horn contraction function
.
.
.
H in contracting the same Horn formula, then we say H and  are Horn equivalent.
.
Definition 5 Let K be a belief set and H a Horn belief set such that H = H(K). Let 
.
be an AGM contraction function for K and H a Horn contraction function for H. Then
238

fiEntrenchment-Based Horn Contraction

.
.
H and  are Horn equivalent iff
.
.
H(K ) = H H 
for all   LH .
.
.
As depicted in Figure 2, the Horn equivalence between  and H stems from the fact that,
.
.
in contracting any Horn formula , the Horn belief set H H  returned by H is the Horn
.
.
subset of the belief set K  returned by .
K

.


.
H(K )

H(K)

H

.
K 

.
H 

.
H H 

.
Figure 2: Horn equivalence between the AGM contraction function  and the Horn con.
traction function H .
Obviously, for an entrenchment-based Horn contraction function to be Horn equivalent
to an entrenchment-based contraction function, the determining Horn epistemic entrenchment must be the Horn subset of the determining epistemic entrenchment. However, this
is not sufficient to guarantee Horn equivalence. As shown in Figure 1, although the Horn
epistemic entrenchment H is the Horn subset of the epistemic entrenchment P2 , the
entrenchment-based contraction function determined by P2 retains more Horn formulas
than the entrenchment-based Horn contraction function determined by H .
In Figure 1, Horn formulas are equally entrenched in H , P1 and P2 . However, the
non-Horn formula p  q  r, which is not allowed in H , is entrenched differently in P1
and P2 . With the extra preference information on the non-Horn formula, P1 and P2
give rise to two different entrenchment-based contraction functions. The point is that a
Horn epistemic entrenchment is consistent with several epistemic entrenchments (i.e., being
their Horn subset), thus an entrenchment-based Horn contraction function corresponds to
several entrenchment-based contraction functions. But which entrenchment-based contraction functions are Horn equivalent to the entrenchment-based Horn contraction function?
Essentially, this requires us to identify the epistemic entrenchments that will determine the
Horn equivalent entrenchment-based contraction functions. As we will show, the following
is a necessary and sufficient condition for this purpose:
(EE6) For ,   LH if ,   K and  <    then there is   HS(  ) such that
 < .
The condition requires that, for all pairs of Horn formulas ,  in K, if  is strictly less
entrenched than   , then it is also strictly less entrenched than a Horn strengthening
239

fiZhuang & Pagnucco

of   . Since a formula is entailed by any of its Horn strengthenings, it can be verified
through (EE1) and (EE2) that the converse is also true. Thus  is strictly less entrenched
than    if and only if  is strictly less entrenched than a Horn strengthening of   .
.
In the principal cases, to decide whether to retain  in the contraction by , (C )
.
compares the entrenchment between  and  whereas (HC ) compares the entrenchment
between the Horn strengthenings of  and . (EE6) assures that comparing  and  is
the same as comparing Horn strengthenings of  and . This means, if the entrenchment
.
satisfies (EE6), then the mechanism for retaining formulas for (C ) is essentially the same
.
as that for (HC ).
We call entrenchment-based contraction functions whose determining epistemic entrenchments satisfy (EE6) strict entrenchment-based contraction functions.
.
Definition 6 A function  is a strict entrenchment-based contraction function if it is an
entrenchment-based contraction function whose determining epistemic entrenchment satisfies (EE6).
To characterise strict entrenchment-based contraction functions we need, in addition to
.
.
.
(K 1)(K 8), the classic case of (H hs):
.
.
.
(K hs) For ,   LH , if   K  then there is   HS(  ) such that   K   .
.
In fact, (EE6) corresponds exactly to (K hs).
.
.
Theorem 4 A function  is a strict entrenchment-based contraction function iff  satisfies
.
.
.
(K 1)(K 8) and (K hs).
As the main result of this section, each entrenchment-based Horn contraction function is
Horn equivalent to a strict entrenchment-based contraction function and vice versa.
.
Theorem 5 If H is an entrenchment-based Horn contraction function, then there is a
.
.
.
strict entrenchment-based contraction function  such that H and  are Horn equivalent.
.
If  is a strict entrenchment-based contraction function, then there is an entrenchment.
.
.
based Horn contraction function H such that H and  are Horn equivalent.
Moreover, any entrenchment-based contraction function that is Horn equivalent to an
entrenchment-based Horn contraction function is a strict entrenchment-based contraction
function.
.
.
Theorem 6 Let H be an entrenchment-based Horn contraction function. If  is an
.
.
entrenchment-based contraction function such that H and  are Horn equivalent, then
.
 is a strict entrenchment-based contraction function.
Horn equivalence is a local feature which deals with the equivalence between specific
contraction functions. A number of functions can be constructed according to a particular
construction method and each contraction function represents a possible way of contracting
a formula. Thus we can also compare Horn contraction with AGM contraction in terms
of the possible ways of contracting a formula. A Horn contraction is as comprehensive as
AGM contraction if the Horn contraction permits all possible ways of contracting a Horn
240

fiEntrenchment-Based Horn Contraction

formula as the AGM does. Due to the allowance of non-Horn formulas, there are more ways
of forming epistemic entrenchments than Horn epistemic entrenchment; thus more ways of
generating entrenchment-based contraction functions. In Figure 1 there is no entrenchmentbased Horn contraction function that corresponds to (i.e., being Horn equivalent to) the
entrenchment-based contraction function determined by P2 . Entrenchment-based Horn
contraction is therefore not as comprehensive as entrenchment-based contraction. However,
this is not due to how the Horn contraction is defined but due to the limited expressiveness of
Horn logic compared to that of Propositional Logic. Entrenchment-based Horn contraction
is equally comprehensive to strict entrenchment-based contraction.

6. Entrenchment-Based Horn Withdrawal
Due to the controversy over the Recovery postulate in the AGM setting, Makinson (1987)
proposed an operation called withdrawal that satisfies five of the basic AGM contraction
postulates but not necessarily Recovery. Since Horn contraction is intrinsically incompatible
with Recovery, it makes sense to explore the Horn version of withdrawal.
Since our Horn contraction originates from entrenchment-based contraction, we focus on
the withdrawal version of entrenchment-based contraction. Such withdrawal has been characterised by Rott and Pagnucco (1999) and referred to as severe withdrawal. For uniformity,
we call it entrenchment-based withdrawal. An epistemic entrenchment is also assumed for
entrenchment-based withdrawal and the withdrawal outcome is determined by the following
condition:
.
.
(W ) :   K  iff   K and either  <  or ` .
.
Definition 7 (Rott & Pagnucco, 1999) A function  is an entrenchment-based withdrawal
.
function for K iff its outcome is determined by the epistemic entrenchment for K via (W ).
.
Notice that (W ) can also be used to generate an epistemic entrenchment from a withdrawal
function as, on the reverse reading,  is strictly more entrenched than  whenever  is
retained in the withdrawal by .
Rott and Pagnucco (1999) showed that to characterise entrenchment-based withdrawal
we need the full set of AGM contraction postulates except Recovery and we also need to
replace Conjunctive Overlap with the much stronger Antitony Condition.
.
Theorem 7 (Rott & Pagnucco, 1999) A function  is an entrenchment-based withdrawal
.
.
.
.
.
function iff  satisfies the following postulates: (K 1)(K 4), (K 6), (K 8), and
.
.  K 
.   (Antitony Condition)
(K 7a)
If 6` , then K 
Adapting entrenchment-based withdrawal to Horn logic is straightforward as everything is
Horn expressible. We obviously need a Horn epistemic entrenchment. By restricting to
.
Horn belief sets and Horn formulas (W ) is recast as follows:
.
.
(HW ) :   H  iff   H and either  <  or ` .
.
The Horn withdrawal function generated via (HW ) is referred to as an entrenchment-based
Horn withdrawal function.
241

fiZhuang & Pagnucco

.
Definition 8 A function  is an entrenchment-based Horn withdrawal function for H iff
.
its outcome is determined by the Horn epistemic entrenchment for H via (HW ).
It is obvious from the constructions that, unlike entrenchment-based Horn contraction,
entrenchment-based Horn withdrawal has the same change mechanism as that of its origin.
Therefore, entrenchment-based Horn withdrawal is characterised by exactly Horn versions
of the characterising postulates for entrenchment-based withdrawal.
.
.
Theorem 8 A function  is an entrenchment-based Horn withdrawal function iff  satis.
.
.
.
fies the following postulates: (H 1)(H 4), (H 6), (H 8), and
.
.
.
(H 7a) If 6`  then H   H   .
We can show that entrenchment-based Horn withdrawal and entrenchment-based withdrawal have a one-to-one correspondence under the notion of Horn equivalence.
.
Theorem 9 If H is an entrenchment-based Horn withdrawal function, then there is an
.
.
.
.
entrenchment-based withdrawal function  such that H and  are Horn equivalent. If 
is an entrenchment-based withdrawal function, then there is an entrenchment-based Horn
.
.
.
withdrawal function H such that H and  are Horn equivalent.

7. Related Work
Most of the existing approaches to Horn contraction are different Horn variants of partial
meet contraction (Alchourron et al., 1985). The notion of remainder sets is central to
the construction of partial meet contraction where the outcome of the contraction is the
intersection of some candidate remainder sets chosen by a selection function. In the standard
definition, a remainder set of K with respect to  is a maximal subset of K that fails to
imply . The maximal nature implies the following model-theoretic behaviour of remainder
sets (e.g., see Gardenfors 1998, p. 86). The set of models of each remainder set for  is
the union of the set of models of K and a model of . Furthermore, there is a bijection
between the remainder sets for  and the models of . Another property which is often
referred to as the convexity property states that any belief set that is a subset of the outcome
of a maxichoice contraction and a superset of the outcome of full meet contraction is the
outcome of some partial meet contraction. The above properties and behaviours are however
mutually exclusive for remainder sets under Horn logic, which gives rise to three Horn
variants of remainder sets thus three Horn variants of partial meet contraction. To avoid
confusion, remainder sets under Propositional Logic will be referred to as classic remainder
sets.
The first work on Horn contraction is by Delgrande (2008). In his seminal paper,
Delgrande studied the Horn analogue of orderly maxichoice contraction (Gardenfors, 1988)
which we term as orderly maxichoice Horn contraction. Here the remainder sets are defined
as in the standard definition which means they are maximal, thus we call it a maximal
remainder set. As in orderly maxichoice contraction, a transitive and antisymmetric relation
over maximal remainder sets is assumed for selecting the single best remainder set as the
contraction outcome.
242

fiEntrenchment-Based Horn Contraction

Booth, Meyer, and Varzinczak (2009) suggested that, while orderly maxichoice Horn
contractions are appropriate choices for Horn contraction, they do not constitute all the
appropriate forms of Horn contraction. The authors argued that a Horn contraction should
satisfy the convexity property. As they demonstrated, this is not the case for Horn contractions based on maximal remainder sets. They proposed infra Horn contraction (Booth,
Meyer, Varzinczak, & Wassermann, 2010, 2011). Infra Horn contraction is based on the
notion of infra remainder set. The set of infra remainder sets of H with respect to a Horn
formula  consist of any Horn belief set that is the subset of a maximal remainder set for
 and the superset of the intersection of all maximal remainder sets for . The notion of
infra remainder set subsumes that of maximal remainder set as each maximal remainder
set is an infra one but not vice versa.
As noticed by Delgrande and Wassermann (2010, 2013), both maximal and infra remainder sets do not exhibit the model-theoretic behaviour of classic remainder sets. They
therefore give another Horn variant called partial meet Horn contraction. It is based on
the notion of a weak remainder set which is defined to behave as classic remainder sets
model-theoretically. They show that weak remainder sets subsume maximal remainder sets
but weak remainder sets and infra remainder sets do not subsume one another. Thus partial
meet Horn contraction and infra Horn contraction are not more comprehensive than one
another. The nice thing about weak remainder sets is that they have a one-to-one correspondence with classic remainder sets which implies a one-to-one correspondence between
partial meet Horn contraction and partial meet contraction. This means the contractions
permitted by partial meet Horn contraction correspond exactly to those permitted by partial meet contraction. Zhuang and Pagnucco (2011) further studied partial meet Horn
contraction by assuming a preorder over weak remainder sets. This results in the construction of transitively relational partial meet Horn contraction which is the Horn analogue of
transitively relational partial meet contraction (Alchourron et al., 1985).
Apart from partial meet contraction, Zhuang and Pagnucco (2012) studied the Horn
analogue of model-based contraction (Katsuno & Mendelzon, 1992) which is called modelbased Horn contraction. As in the classic case (Katsuno & Mendelzon, 1992), a pre-order
over interpretations is assumed. It is shown that model-based Horn contraction is identical
to transitively relational partial meet contraction.
Partial meet Horn contraction and infra Horn contraction differ from entrenchmentbased Horn contraction in that they do not assume any explicit preference information.
Zhuang and Pagnucco (2012) showed that entrenchment-based Horn contraction is a restricted form of model-based Horn contraction thus a restricted form of transitively relational partial meet Horn contraction and partial meet Horn contraction. No exact relationship can be established between entrenchment-based Horn contraction and infra Horn
.
contraction as (H hs) is incompatible with infra Horn contraction and one of the characterising postulate of infra Horn contraction (i.e., Core-Retainment) is incompatible with
entrenchment-based Horn contraction. For similar reasons no exact relationship can be
established between entrenchment-based Horn contraction and orderly maxichoice Horn
contraction.
As shown in Section 5, entrenchment-based Horn contraction is not as comprehensive
as entrenchment-based contraction. In this respect, partial meet Horn contraction and
transitively relational partial meet Horn contraction outperform entrenchment-based Horn
243

fiZhuang & Pagnucco

contraction as bijections exist between partial meet Horn contractions and partial meet
contractions and between transitively relational partial meet Horn contraction and transitively relational partial meet contraction. However, the bijection comes at a price. Zhuang
and Pagnucco (2011) showed that Horn logic is not expressive enough for Horn contraction
to distinguish some different pre-orders of weak remainder sets. These different pre-orders
may generate identical transitively relational partial meet Horn contraction functions. The
observation which is termed loss of uniqueness is counterintuitive as it means that although
two agents who have different preferences over a certain domain, they always end up with
identical contraction outcomes. Entrenchment-based Horn contraction does not suffer from
this problem. Each Horn epistemic entrenchment determines a unique entrenchment-based
Horn contraction.
Beside the aforementioned works on Horn contractions, Delgrande and Peppas (2011)
studied model-based Horn revision in the manner of the classic model-based revision (Katsuno & Mendelzon, 1992). In the AGM setting, revision can be defined from contraction
via the so called Levi identity (Levi, 1991). Zhuang, Pagnucco, and Zhang (2013) explored
this connection in the Horn setting and showed that, under proper restrictions, Horn revision can be defined from Horn contraction via a variant of the Levi identity. They also
showed that the Horn revision functions generated from transitively relational partial meet
Horn contraction functions and from model-based Horn contraction functions suffer from
counter-intuitive results whereas the one generated from entrenchment-based Horn contraction functions are guaranteed to be meaningful (i.e., satisfies all the revision postulates
proposed in Delgrande & Peppas, 2011). Finally, Adaricheva, Sloan, and Szorenyi (2012)
provided some complexity results regarding Horn contractions.
By now all the major construction methods of AGM contraction have been adapted
to Horn logic. The principle of such adaptations is to make the adapted contraction as
close as possible to AGM contraction (i.e., equally rational in all aspects). As we explained
above, due to the limited expressiveness of Horn logic, none of the adapted contractions is
identical to its AGM origin in all aspects. However, this is by no means declaring failure on
the adaptations for we have emphasised in Section 5 that it is fair to expect the rationality
of Horn contractions only to the extent the expressiveness of Horn logic permits. Since
the adaptations focus on different aspects of AGM contraction and they often exhibit both
desirable and undesirable properties, it is not convincing to argue that one outperforms
the other. The best choice of Horn contraction then depends on the actual application. If
explicit preference is expected and loss of uniqueness is to be avoided then entrenchmentbased Horn contraction is a better choice.

8. Conclusion
In this paper, we defined entrenchment-based Horn contraction which is the Horn analogue of entrenchment-based contraction. The outcome of the Horn contraction is determined by epistemic entrenchments over Horn formulas via a refinement of the condition
.
.
(C ) proposed by Gardenfors and Makinson (1988). Since condition (C ) involves ar.
bitrary disjunctions which may not be Horn formulas, the refined condition (HC ) con.
.
siders the Horn strengthenings of the disjunctions. (HC ) closely resembles (C ), as
each entrenchment-based Horn contraction function performs identically to its classic coun244

fiEntrenchment-Based Horn Contraction

terpart (i.e., strict entrenchment-based contraction function) if only Horn formulas are
counted. Since non-Horn formulas are disallowed, the set of epistemic entrenchments for
determining entrenchment-based Horn contraction is a proper subset of those for determining entrenchment-based contraction. Entrenchment-based Horn contraction is therefore not
as comprehensive as entrenchment-based contraction. We are able to identify a restricted
form of entrenchment-based contraction called strict entrenchment-based contraction which
has a one-to-one correspondence with entrenchment-based Horn contraction.
Recently, Creignou, Papini, Pichler, and Woltran (2014) investigated revision operators
for fragments of Propositional Logic not limited to Horn. Their work promotes a new
direction for furthering the study on Horn belief change. Of the many Horn contractions
and revisions, it is important to find out if their adaptation strategies are generalisable to
fragments of Propositional Logic other than Horn. Thus for future work, we aim to develop
a generalised entrenchment-based contraction that can be applied to arbitrary fragments of
Propositional Logic.

Appendix A. Proofs of Results
We first present some notions and properties of Horn logic that will be used in the proofs.
The intersection of two interpretations is the interpretation that assigns true to those atoms
that are assigned true by both interpretations. We denote the intersection of interpretations
 and  by   . Given a set of interpretations M , the closure of M under intersection is
denoted by Cl (M ). Formally,
Cl (M ) = { |   M or there is ,   M such that    = }.
For any Horn formula, its set of models is closed under Cl and called Horn closed. Conversely, any Horn closed set of models corresponds to an unique Horn formula (modulo
logical equivalence). Moreover, intersections of Horn closed sets of models are also Horn
closed.
Lemma 1 If   , then HS() = HS().
Proof: The result is immediate as the definition of Horn strengthening is syntax insensitive.
Lemma 2 If  is a Horn formula such that  ` , then there is   HS() such that
 ` .
Proof: If   HS(), then the result trivially holds. Suppose  6 HS(), then by the
definition of Horn strengthening there is 1  LH such that ||  |1 |  ||. Again, if
1 6 HS(), then there must be 2  LH such that |1 |  |2 |  ||. Since || is finite,
eventually we will find a n which is a Horn strengthening of . Since ||  |n |,  ` n .
Lemma 3 If   HS(  ), then there is 1  HS() and 2  HS() such that
  1  2 .
Proof: Suppose   HS(  ), then by the definition of Horn strengthening || 
||  || which implies ||  || and ||  ||. Then it follows from Lemma 2 that there
are 1  HS() and 2  HS() such that ||  |1 | and ||  |2 |, thus ||  |1 |  |2 |.
245

fiZhuang & Pagnucco

Assume there is   |1 |  |2 | such that  6 ||. Then since |1 |  |2 |  ||  || we have
  ||  ||. It then follows from   HS(  ),   ||  ||, and  6 || that there is
  || such that    6 ||  ||. Now since ,   |1 |  |2 | we have     |1 |  |2 |
which implies     ||  ||, a contradiction! Therefore, there is no   |1 |  |2 | such
that  6 || which implies |1 |  |2 |  ||.
Lemma 4 Let  and  be Horn formulas. If   HS(  ), then HS(  )  HS(  ).
Proof: Suppose   HS() and 0  HS(), we need to show 0  HS(). By
the definition of Horn strengthening,   HS() implies ||  ||, and 0  HS()
implies |0 |  ||. It then follows from ||  || and ||  || that ||  ||
which implies |0 |  |  |. It remains to show there is no Horn formula 00 such that
|0 |  |00 |  |  |.
Assume to the contrary that there is Horn formula 00 such that |0 |  |00 |  |  |.
It follows from |0 |  |00 |, 0  HS(  ), and the definition of Horn strengthening that
|00 | 6 |  |. By set theory there is   |00 | \ |0 | such that   || \ |  |. It then follows
from  6 || and   HS(  ) that there is   || such that    =  and  6 |  |.
We also have  6 || for otherwise || =
6 Cl (||) and this implies   ||. Assume  6 |0 |
then there is x  |  | such that   x = y and y 6 |  |. If x  || then || =
6 Cl (||),
a contradiction! If x  ||, then || 6= Cl (||), again a contradiction! Thus we conclude
  |0 | which implies   |00 |. It then follows from   |00 |,    =  and  6 |  |
that |00 | =
6 Cl (|00 |), a contradiction! Thus there is no 00 such that |0 |  |00 |  |  |.
Lemma 5 Let  be a Horn epistemic entrenchment. Then  satisfies:
1.    or   
2. If     , then    or   
3.  <  iff    < .
4. If    and   , then     
5. If  <  and  < , then  <   
6. If   , then     
7. If    then    and   
Proof: The proofs are identical to the propositional case.
.
Proposition 1 Let  be a Horn contraction function. Then
.
.
.
.
1. if  satisfies (H 1) and (H de), then it satisfies (H f )
.
.
.
.
2. if  satisfies (H 2) and (H de), then it satisfies (H wr)
.
.
.
3. if  satisfies (H wr), then it satisfies (H de)
.
.
.
4. if  satisfies (H pa), then it satisfies (H ct)
246

fiEntrenchment-Based Horn Contraction

.
.
.
.
5. if  satisfies (H 6) and (H ct), then it satisfies (H pa)
Proof: 1. Suppose ` . For each   H, we have `  which implies HS() = .
.
.
.
.
Since H  = CnH (H ), all tautologies are in H . Thus     H . It then follows
.
.
.
from the contrapositive of (H de),   H, and     H  that   H . Thus
.
H  = H.
.
.
2. & 3. We will show that (H wr) and (H de) are equivalent to the following postulate:
.
.
.
(H mc) If   H \ H  then |H | 6 |  |.
.
.
.
.
We first show that  satisfies (H de) iff it satisfies (H mc). For one direction, suppose 
.
.
satisfies (H de). Let   H \ H . We have two cases:
.
.
Case 1,     LH : Then HS(  ) = {  }. By (H de) we have H  6`   
.
which implies |H | 6 |  |.
.
Case 2,    6 LH : Assume |H |  |  |. By Lemma 2, there is a   HS(  )
.
.
.
such that H  ` . However, it follows from (H de) that H  6`  for all   HS(  ),
a contradiction!
.
.
.
For the other direction, suppose  satisfies (H mc). Since |H | 6 |  |, there is
.
  |H | such that  6 |  |. Since ||  |  | for all   HS(  ),  6 || for all
.
.
  HS(  ). Then by model theory, it follows from   |H | that H  6`  for all
  HS(  ).
.
.
.
Now we show that  satisfies (H wr) iff it satisfies (H mc).
.
.
.
.
For one direction, suppose  satisfies (H wr). Let   H \ H . Assume |H | 
.
0
|  | then by set theory |H |  ||  ||. Again by set theory, for all H such
.
.
that |H 0 |  |H | and |H 0 |  || 6= , it follows from |H |  ||  || that there is
.
  |H 0 |  || such that   || which implies H 0  {} 6` . However, by (H wr) there
is one such H 0 that H 0  {} ` , a contradiction!
.
.
.
For the other direction, suppose  satisfies (H mc). Let   H \ H . Then by
.
.
(H mc) there is   |H |  || such that  6 ||. Let a Horn belief set H 0 be such that
.
.
|H 0 | = {}. Then   |H | implies |H 0 |  |H | and   || implies |H 0 |  ||. It
.
.
follows from |H 0 |  |H | and |H 0 |  || that H   H 0 and H 0 6` . It follows from
|H 0 | = {} and  6 || that |H 0 |  || = . Thus H 0  {} is inconsistent. All formulas
follow from an inconsistent set so does .
4. & 5. The proofs are identical to the propositional case which can be found on Page 117
of (Hansson, 1999) (OBSERVATION 2.59).
.
Theorem 2 A function  is an entrenchment-based Horn contraction function iff it satisfies
.
.
.
.
.
.
.
(H 1)(H 4), (H de), (H 6), (H hs), (H ct), and (H 8).
Proof: For one direction, let H be a Horn belief set,  a Horn epistemic entrenchment
.
for H, and  be the entrenchment-based Horn contraction function for H that is determined
.
.
.
.
.
.
.
by . We need to show  satisfies (H 1)(H 4), (H de), (H hs), (H ct), and (H 8).
.
.
(H 2): Follows directly from (HC ).
.
.
.
(H 1): If ` , then it follows from (HC ) that H  = H. It then follows from
.
.
.
H = CnH (H) that H  = CnH (H ). Suppose 6`  and   CnH (H ), we need to show
.
.
  (H ). By (HC ), it suffices to show   H and there is   HS(  ) such that
 < . We have two cases:
247

fiZhuang & Pagnucco

.
Case 1, 6` : Since   CnH (H ), by compactness of Horn logic, there is a finite
.
.
subset {1 , . . . , n } of H  such that 1      n ` . Since {1 , . . . , n }  H , it follows
.
from (H 2) that {1 , . . . , n }  H. It follows from {1 , . . . , n }  H and 1      n ` 
.
that H ` . It follows from H `  and H = CnH (H) that   H. It follows from (HC )
that there is i  HS(  i ) such that  < i for each i . It then follows from Lemma 5
(Part 5) that  < 1      n . Since 1      n ` (  1 )      (  n ) we have
by Lemma 2 that there is   HS((  1 )      (  n )) such that 1      n ` .
Thus  < . Since (  1 )      (  n )    (1      n ), we have by Lemma 1, that
HS((  1 )      (  n )) = HS(  (1      n )). Thus   HS(  (1      n )).
Since   (1      n ) `   , we have  `    which implies by Lemma 2 that there is
0  HS(  ) such that  ` 0 which implies   0 . Since  <  it follows from (HEE1)
.
.
that  < 0 . By (HC ), it follows from   H, and  < 0 that   H .
Case 2, ` : Then it follows from H = CnH (H) that   H. Also `  implies `   .
Thus by (HEE2) and (HEE5),      for all . Since 6` , it follows from Lemma 5
(Part 1) and (HEE5) that there is a  such that  < . Then by (HEE1), it follows from
     and  <  that  <   . By the definition of Horn strengthening, `   
.
implies HS(  ) = {  }. By (HC ), it then follows from   H and  <    that
.
  H .
.
.
.
.
(H 3): Suppose  6 H, we need to show H  = H. H   H follows from (H 2).
.
Let   H. It suffices to show   H . By (HEE4) and Lemma 5 (Part 1), it follows
from   H that there is some   LH such that  < . Since  `    we have by
Lemma 2 that there is   HS(  ) such that  ` . It follows from  ` , by (HEE2),
that   . Since  6 H, it follows from (HEE4) that   . We can now apply (HEE1)
.
to   ,  < ,   , and obtain  < . By (HC ), it follows from   H and  < 
.
that   H .
.
.
(H 4): Suppose 6` . We need to show  6 H . By (HEE2),  `  implies   .
By Lemma 5 (Part 1),    implies  6< . Since HS(  ) = HS() = {}, it follows
.
.
from  6<  and 6` , by (HC ), that  6 H .
.
.
.
.
(H 6): Suppose   . We first show H   H . Let   H . It then follows
.
from (HC ) that   H and either `  or there is   HS(  ) such that  < .
.
Case 1, ` : Since   , `  implies ` . It follows from `  and   H, by (HC ),
.
that   H .
Case 2, 6` : Then there is   HS(  ) such that  < . Since   , we have
      . By Lemma 1,        implies HS(  ) = HS(  ). Thus
  HS(  ) follows from   HS(  ). By intersubstitutativity of ,  <  follows
.
.
from    and  < . It then follows from   H and  < , by (HC ), that   H .
.
.
.
.
Thus H   H . We can show H   H  in the same way.
.
.
.
(H de): Suppose   H \ H . We need to show for all   HS(  ),  6 H . It
.
.
follows from (HC ) and  6 H  that for all   HS(  ),  6< . By Lemma 4, we
have for all   HS(  ), HS(  )  HS(  ). Thus we have for all 0  HS(  ),
.
.
 6< 0 . It then follows from (HC ) that for all   HS(  ),  6 H .
.
(HC ): For one direction, suppose    and   H   . We need to show
.
.
`   . Since   H    we have by (HC ) that   H and either `    or there
is   HS((  )  ) such that    < . Since (  )    , we have by Lemma 1
248

fiEntrenchment-Based Horn Contraction

that HS((  )  ) = HS() = {}. By Lemma 5 (Part 6),    implies     . By
connectivity of ,      implies    6< . Thus it must be the case that `   .
.
For the other direction, suppose either  6 H    or `   , we need to show   .
If `   , then we have `  and it follows from (HEE2) and  `  that   . So
.
.
suppose 6`    and  6 H   . It then follows from (HC ) that either  6 H or
for all   HS((  )  ),    6< . In the former case,  6 H gives us    as
required by (HEE4). In the latter case, since (  )    , we have by Lemma 1, that
HS((  )  ) = HS() = {}. Thus    6< . By the connectivity of ,    6< 
implies     . It follows from (HEE2) and    `  that     . It follows from
    ,      and (HEE1) that   .
.
.
(H hs): Suppose   H . We need to show there is   HS(  ) such that
.
.
.
  H   . It follows from   H  and (HC ) that there is   HS(  ) such that
.
.
 < . Since  satisfies (HC ), it then follows from  <  that   H   .
.
.
.
(H ct): Suppose   H   , we need to show   H     . By (HC ),
.
  H    implies  < . It follows from (HEE2) and    `  that     . It
follows from (HEE1),     , and  <  that    < . By (HC ),    <  implies
.
  H     .
.
.
.
.
(H 8): Suppose  6 H   . We need to show H     H . If  6 H then
.
.
.
.
.
we have by (H 3) that H  = H. H     H  then follows from (H 2). So
.
suppose   H. By (HC ),  6 H    implies   . By Lemma 5 (Part 6),   
.
.
implies     . Let   H   , it suffices to show   H . It follows from
.
.
  H    and (HC ) that there is   HS((  )  ) such that    < . By
Lemma 1, (  )    (  )  (  ) implies HS((  )  ) = HS((  )  (  )).
Thus by Lemma 3, there are 1  HS(  ) and 2  HS(  ) such that 1  2  .
Then by Lemma 5 (Part 7),    < 1  2 . It follows from (HEE2) and 1  2 ` 1
that 1  2  1 . It follows from (HEE1),     ,    < 1  2 , and 1  2  1
.
.
that  < 1 . It follows from 1  HS(  ) and  < 1 , by (HC ), that   H .
.
For the other direction, let H be a Horn belief set and  a Horn contraction function for
.
.
.
.
.
.
H that satisfies (H 1)(H 4), (H de), (H hs), (H ct), and (H 8). It suffices to show
the Horn epistemic entrenchment  determined by (HC ) satisfies (HEE1)(HEE5)
.
and (HC ). By replacing the AGM contraction postulates with their corresponding Horn
analogues, the proof for satisfaction of (HEE1)(HEE5) is the same as that of Theorem
.
2.50 in (Hansson, 1999). We therefore only give the proof for (HC ).
.
.
(HC ): For one direction, suppose   H . We need to show   H and either ` 
.
.
or there is   HS(  ) such that  < . Since   H , we have by (H hs) that there
.
.
is   HS(  ) such that   H   . By (HC ),   H    implies  < . By
.
.
(H 2),   H  implies   H.
For the other direction, suppose   H and either `  or there is   HS(  ) such
.
.
that  < . We need to show   H . If `  then H  = H. Thus   H implies
.
.
  H . So suppose 6` . It suffices to show if   H \ H  then for all   HS(  ),
.
.
.
  . By (H de),   H \ H  implies for all   HS(  ),  6 H . Assume
.
.
.
.
.
  H   . By (H 2),   H    implies  6 H   . It follows from (H 8) and
.
.
.
.
.
.
 6 H    that H     H . It follows from  6 H  and H     H  that
.
.
.
 6 H   , which is a contradiction. Thus  6 H   . By (HC ),  6 H   
implies   .
249

fiZhuang & Pagnucco

.
Proposition 2 If  is an entrenchment-based Horn contraction function, then it satisfies
.
(H 7).
.
Proof: Let  be an entrenchment-based Horn contraction function for H with an as.
.
sociated Horn epistemic entrenchment . We have by Theorem 2 that  satisfies (H 1)
.
.
.
.
.
.
.
(H 4), (H de), (H hs), (H ct), and (H 8). Suppose   (H )  (H ). We need
.
to show   H   .
.
.
.
Case 1, ` : Then     . It follows from (H 6) that H    = H , and thus
.
  H   .
Case 2, ` : The proof is similar to that of Case 1.
.
Case 3, 6`  and 6` : It follows from (HEE2) that     . It follows from   H 
.
and (HC ) that there is 1  HS() such that  < 1 . We then conclude from (HEE1)
.
that    < 1 . Similarly, it follows from (HEE2) that      and from   H 
.
and (HC ) that there is 2  HS(  ) such that  < 2 , and thus    < 2 . By
Lemma 5 (Part 5), we can deduce from    < 1 and    < 2 , that    < 1  2 .
By the definition of Horn strengthening we have 1 ` |   and 2 `    which implies
1  2 ` (  )  (  ). Since (  )  (  )  (  )  , we have 1  2 ` (  )  .
It then follows from Lemma 2 that there is   HS((  )  ) such that 1  2 ` . By
(HEE2), 1  2 `  implies 1  2  . We then have by (HEE1), that    < .
.
.
Finally, it follows from    <  and (HC ), that   H   .
.
.
Theorem 4 A function  is a strict entrenchment-based contraction function iff  satisfies
.
.
.
(K 1)(K 8) and (K hs).
.
Proof: For one direction, suppose  is a strict entrenchment-based contraction function
for K with an associated epistemic entrenchment . Then  satieties (EE6). Since a strict
entrenchment-based contraction function is an entrenchment-based contraction function, we
.
.
.
.
have by Theorem 1 that  satisfies (K 1)(K 8) and (C ). It remains to show  satisfies
.
.
(K hs). Suppose ,   LH and   K . We need to show there is   HS(  ) such
.
that   K   . If `  then by the definition of Horn strengthening we have `  thus
.
.
the result trivially holds. So suppose 6` . It then follows from   K  and (C ) that
.
 <   . Since  satisfies (EE6), there is   HS(  ) such that  < . Since 
.
satisfies (C ),  <  implies   K   .
.
.
.
.
For the other direction, suppose a function  satisfies (K 1)(K 8) and (K hs) we
.
need to show  is a strict entrenchment-based contraction function. It follows from The.
orem 1 that  is an entrenchment-based contraction function. It remains to show the
.
epistemic entrenchment  generated from  via (C ) satisfies (EE6). Suppose ,   LH
.
and  <   . We need to show there is   HS(  ) such that  < . By (C ),
.
.
 <    implies   K . Then it follows from (K hs) that there is   HS(  )
.
such that   K    which implies by (C ) that  < .
.
Theorem 5 If H is an entrenchment-based Horn contraction function, then there is a strict
.
.
.
.
entrenchment-based contraction function  such that H and  are Horn equivalent. If 
is a strict entrenchment-based contraction function, then there is an entrenchment-based
.
.
.
Horn contraction function H such that H and  are Horn equivalent.
Proof: Part 1: Let K be a belief set and H a Horn belief set such that H = H(K).
.
Suppose H is an entrenchment-based Horn contraction function for H and it is determined
250

fiEntrenchment-Based Horn Contraction

by the Horn epistemic entrenchment H for H. Let a binary relation  over L be such
that for ,   LH
(1)    iff  H , and
(2)  <    iff there is   HS(  ) such that  <H .
Then we can expand  with the rest of the non-Horn formulas to form an epistemic en.
trenchment. Let  be the entrenchment-based contraction function for K that is determined
.
by . Due to the definition of  (i.e., (2)),  satisfies (EE6) which implies  is a strict
entrenchment-based contraction function.
.
.
Suppose   LH . We need to show H(K ) = H H . If ` , then it follows from
.
.
.
.
(H f ) and its classic version (follows from (K 5)) that H H  = H and K  = K. Thus
.
.
.
H(K ) = H H  follows from H = H(K). So suppose 6` . We first show H H  
.
.
.
.
H(K ). Let   H H . It suffices to show   K . By (HC ), it follows from
.
  H H  that   H and there is   HS(  ) such that  <H . Then we have by
the definition of  (i.e., (2))  <   . Also since H = H(K),   H implies   K. It
.
.
follows from   K and  <    by (C ) that   K .
.
.
.
Now we show that H(K )  H H . Suppose   LH and   K . We need to
.
.
.
show   H H . By (C ), it follows from   K  that   K and  <   . Then
we have by the definition of  that there is   HS(  ) such that  <H . Also since
H = H(K),   H follows from   K and the fact that  is a Horn formula. Finally, it
.
.
follows from   H and  <H  by (HC ) that   H H .
Part 2: This part can be proved in a similar manner to Part 1. This time we need
to generate a Horn epistemic entrenchment from an epistemic entrenchment such that the
Horn epistemic entrenchment is the Horn subset of the epistemic entrenchment.
.
.
Theorem 6 Let H be an entrenchment-based Horn contraction function. If  is an
.
.
.
entrenchment-based contraction function such that H and  are Horn equivalent then  is
a strict entrenchment-based contraction function.
.
.
Proof: Let H be an entrenchment-based Horn contraction function for H and  an
.
.
entrenchment-based contraction function for K such that H = H(K) and H and  are
Horn equivalent.
.
.
.
By Theorem 4, it suffices to show  satisfies (K hs). Let ,   LH . Suppose   K .
.
.
.
We need to show there is   HS(  ) such that   K   . Since H and  are Horn
.
.
.
equivalent, it follows from   K  that   H H . Then it follows from (H hs) that
.
there is   HS(  ) such that   H H   . Again by the Horn equivalence between
.
.
.
.
H and ,   H H    implies   K H   .
.
.
Theorem 8 A function  is an entrenchment-based Horn withdrawal function iff  satisfies
.
.
.
.
the following postulates: (H 1)(H 4), (H 6), (H 8), and
.
.  H 
.  .
(H 7a)
If 6` , then H 
Proof: The proof is identical to the propositional case which can be found in the work
of Rott and Pagnucco (1999, pages 538540).
.
Theorem 9 If H is an entrenchment-based Horn withdrawal function, then there is an
.
.
.
.
entrenchment-based withdrawal function  such that H and  are Horn equivalent. If 
251

fiZhuang & Pagnucco

is an entrenchment-based withdrawal function, then there is an entrenchment-based Horn
.
.
.
withdrawal function H such that H and  are Horn equivalent.
Proof: Part 1: Let K be a belief set and H a Horn belief set such that H = H(K).
.
Suppose H is an entrenchment-based Horn withdrawal function for H and it is determined
by the Horn epistemic entrenchment H of H. Let  be such that
   iff  H  for all ,   LH .
Then we can expand  with all the non-Horn formulas to form an epistemic entrenchment.
.
Let  be the entrenchment-based withdrawal function for K that is determined by 
.
.
.
.
and via (W ). If ` , then it follows from (K 3) and (H 3) that K  = K and
.
.
.
H H  = H. Thus H(K ) = H H  follows from H = H(K). So suppose 6` . We first
.
.
.
.
.
show H H   H(K ). Let   H H . It suffices to show   K . By (HW ), it
.
follows from   H H  that   H and  <H . Since H = H(K),   H implies   K.
By the definition of ,  <H  implies  < . Then it follows from   K and  <  by
.
.
(W ) that   K .
.
.
.
Now we show that H(K )  H H . Let  be a Horn formula and   K . It
.
.
.
suffices to show   H H . By (W ), it follows from   K  that   K and  < .
Since H = H(K),   H follows from   K and the fact that  is a Horn formula. Since
 and  are Horn formulas and  < , we have by the definition of  that, by the definition
.
of ,  <  implies  <H . Then it follows from   H and  <H , by (HW ) that
.
  H H .
Part 2: This part can be proved in a similar manner to Part 1. This time we need
to generate a Horn epistemic entrenchment from an epistemic entrenchment such that the
Horn epistemic entrenchment is the Horn subset of the epistemic entrenchment.

References
Adaricheva, K., Sloan, R. H., & Szorenyi, B. (2012). Horn belief contraction: Remainders,
envelopes and complexity. In Proceedings of the 13th International Conference on
Principles of Knowledge Representation and Reasoning (KR-2012), pp. 107115.
Alchourron, C. E., Gardenfors, P., & Makinson, D. (1985). On the logic of theory change:
Partial meet contraction and revision functions. The Journal of Symbolic Logic, 50 (2),
510530.
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. (Eds.). (2003).
The Description Logic Handbook. Cambridge University Press, Cambridge, UK.
Booth, R., Meyer, T., & Varzinczak, I. J. (2009). Next steps in propositional Horn contraction. In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI-2009), pp. 702707.
Booth, R., Meyer, T., Varzinczak, I. J., & Wassermann, R. (2010). Horn belief change:
A contraction core. In Proceedings of the 20th European Conference on Artificial
Intelligence (ECAI-2011), pp. 10651066.
Booth, R., Meyer, T., Varzinczak, I. J., & Wassermann, R. (2011). On the link between
partial meet, kernel, and infra contraction and its application to horn logic. Journal
of Artificial Intelligence Research, 42, 3153.
252

fiEntrenchment-Based Horn Contraction

Creignou, N., Papini, O., Pichler, R., & Woltran, S. (2014). Belief revision within fragments
of propositional logic. Journal of Computer and System Sciences, 80 (2), 427449.
Delgrande, J. P. (2008). Horn clause belief change: Contraction functions. In Proceedings
of the 11th International Conference on Principles of Knowledge Representation and
Reasoning (KR-2008), pp. 156165.
Delgrande, J. P., & Peppas, P. (2011). Revising Horn Theories. In Proceedings of the 22nd
International Joint Conference on Artificial Intelligence (IJCAI-2011), pp. 839844.
Delgrande, J. P., & Wassermann, R. (2010). Horn clause contraction function: Belief set
and belief base approaches. In Proceedings of the 12th International Conference on
Principles of Knowledge Representation and Reasoning (KR-2010), pp. 143152.
Delgrande, J. P., & Wassermann, R. (2013). Horn clause contraction functions. Journal of
Artificial Intelligence Research, 48, 475551.
Ferme, E., Krevneris, M., & Reis, M. (2008).
An axiomatic characterization of
ensconcement-based contraction. Journal of Logic and Computation, 18 (5), 739753.
Flouris, G., Plexousakis, D., & Antoniou, G. (2004). Generalizing the AGM postulates: preliminary results and applications. In Proceedings of the 10th International Workshop
on Non-Monotonic Reasoning (NMR-2004), pp. 171179.
Foo, N. Y. (1990). Observations on AGM entrenchment. Tech. rep. 389, Basser Department
of Computer Science, University of Sydney.
Fuhrmann, A., & Hansson, S. O. (1994). A survey of multiple contractions. Journal of
Logic, Language and Information, 3 (1), 3974.
Gardenfors, P. (1988). Knowledge in Flux: Modelling the Dynamics of Epistemic States.
MIT Press.
Gardenfors, P., & Makinson, D. (1988). Revisions of knowledge systems using epistemic entrenchment. In Proceedings of the 2nd conference on Theoretical Aspects of Reasoning
about Knowledge (TARK-1988), pp. 8395.
Hansson, S. O. (1991). Belief Contraction Without Recovery. Studia Logica, 50 (2), 251260.
Hansson, S. O. (1993). Changes of disjunctively closed bases. Journal of Logic, Language
and Information, 2 (4), 255284.
Hansson, S. O. (1999). A Textbook of Belief Dynamics Theory Change and Database Updating. Kluwer.
Katsuno, H., & Mendelzon, A. O. (1992). Propositional knowledge base revision and minimal change. Artificial Intelligence, 52 (3), 263294.
Kautz, H., & Selman, B. (1996). Knowledge compilation and theory approximation. Journal
of the ACM, 43, 193224.
Langlois, M., Sloan, R. H., Szorenyi, B., & Turan, G. (2008). Horn complements: Towards
Horn-to-Horn belief revision. In Proceedings of the 23rd National Conference on Artificial Intelligence (AAAI-2008), pp. 466471.
Levi, I. (1991). The Fixation of Beliefs and its Udoing. Cambridge University Press.
253

fiZhuang & Pagnucco

Makinson, D. (1987). On the status of the postulate of recovery in the logic of theory
change. Journal of Philosophical Logic, 16 (4), 383394.
Rott, H. (1992). Preferential belief change using generalised epistemic entrenchment. Journal of Logic, Language and Information, 1 (1), 4578.
Rott, H., & Pagnucco, M. (1999). Severe withdrawal (and recovery). Journal of Philosophical
Logic, 28 (5), 501547.
Zhuang, Z., & Pagnucco, M. (2010). Horn contraction via epistemic entrenchment. In Proceedings of the 12th European Conference on Logics in Artificial Intelligence (JELIA2010), pp. 339351.
Zhuang, Z., & Pagnucco, M. (2011). Transitively Relational Partial Meet Horn Contraction.
In Proceedings of the 22nd International Joint Conference on Artificial Intelligence
(IJCAI-2011), pp. 11321138.
Zhuang, Z., & Pagnucco, M. (2012). Model Based Horn Contraction. In Proceedings of
the 13th International Conference on Principles of Knowledge Representation and
Reasoning (KR-2012), pp. 169178.
Zhuang, Z., Pagnucco, M., & Zhang, Y. (2013). Definability of horn revision from Horn
contraction. In Proceedings of the 23rd International Joint Conference on Artificial
Intelligence (IJCAI-2013), pp. 12051211.

254

fiJournal of Artificial Intelligence Research 51 (2014) 443-492

Submitted 05/14; published 10/14

Push and Rotate: a Complete Multi-agent Pathfinding Algorithm
Boris de Wilde
Adriaan W. ter Mors
Cees Witteveen

BOREUS @ GMAIL . COM
A . W. TERMORS @ TUDELFT. NL
C . WITTEVEEN @ TUDELFT. NL

Faculty of Electrical Engineering, Mathematics, and Computer Science
Mekelweg 4, 2628 CD Delft, The Netherlands

Abstract
Multi-agent Pathfinding is a relevant problem in a wide range of domains, for example in
robotics and video games research. Formally, the problem considers a graph consisting of vertices
and edges, and a set of agents occupying vertices. An agent can only move to an unoccupied,
neighbouring vertex, and the problem of finding the minimal sequence of moves to transfer each
agent from its start location to its destination is an NP-hard problem.
We present Push and Rotate, a new algorithm that is complete for Multi-agent Pathfinding
problems in which there are at least two empty vertices. Push and Rotate first divides the graph into
subgraphs within which it is possible for agents to reach any position of the subgraph, and then uses
the simple push, swap, and rotate operations to find a solution; a post-processing algorithm is
also presented that eliminates redundant moves. Push and Rotate can be seen as extending Luna and
Bekriss Push and Swap algorithm, which we showed to be incomplete in a previous publication.
In our experiments we compare our approach with the Push and Swap, MAPP, and Bibox algorithms. The latter algorithm is restricted to a smaller class of instances as it requires biconnected
graphs, but can nevertheless be considered state of the art due to its strong performance. Our experiments show that Push and Swap suffers from incompleteness, MAPP is generally not competitive
with Push and Rotate, and Bibox is better than Push and Rotate on randomly generated biconnected
instances, while Push and Rotate performs better on grids.

1. Introduction
Computer scientists and roboticists have long studied the problem of coordinating the motions of
multiple moving objects. A general formulation of the problem is to find conflict-free trajectories
in space and time for each of the objects. Cast as the warehousemans problem, this problem was
proved PSPACE-complete by Hopcroft et al. (1984). The problems complexity can be reduced to
NP-complete by assuming that agents can only move along a graph (Goldreich, 1993). The graph
(or roadmap) can be given, for instance in applications such as automated guided vehicles following
lines drawn on factory floors (Roszkowska & Reveliotis, 2008), but it can also be learned (Kavraki,
Svestka, Latombe, & Overmars, 1996) or otherwise constructed (LaValle & Kuffner, 2001).
Application domains of multi-agent pathfinding include many forms of robotics, for instance
mobile robots (Simeon, Leroy, & Laumond, 2002) and robot arms (Erdmann & Lozano-Perez,
1987); the routing of automated guided vehicles, for instance at container terminals (Vis, 2006;
Gawrilow, Kohler, Mohring, & Stenzel, 2007) or in warehousing or manufacturing (Narasimhan,
Batta, & Karwan, 1999; Desaulniers, Langevin, Riopel, & Villeneuve, 2004); video games, such as
role-playing games and real-time strategy games (Nieuwenhuisen, Kamphuis, & Overmars, 2007);
airport taxi routing (Trug, Hoffmann, & Nebel, 2004; Ter Mors, Zutt, & Witteveen, 2007) and collision avoidance of airplanes in flight (Sislak, Pechoucek, Volf, Pavlcek, Samek, Mark, & Losiewicz,
c
2014
AI Access Foundation. All rights reserved.

fiD E W ILDE , T ER M ORS & W ITTEVEEN

2008); but routing and multi-agent pathfinding also occurs in less obvious domains such as planning for mining carts (Beaulieu & Gamache, 2006) or routing sheets of paper through a modular
printer (Ruml, Do, Zhou, & Fromherz, 2011).
As remarked by Surynek (2011), the applicability of algorithmic approaches depends on the
freedom the agents have in their respective application domains. Incomplete reservation-based approaches, where agents typically plan independently, minding the reservations of the others (Lee,
Lee, & Choi, 1998), can be useful in case there is enough room in the infrastructure to guarantee (or
at least to make it highly likely) that a solution can be found. In this paper, we discuss approaches
that can also deal with more congested scenarios, in which the majority of the locations can be
occupied by agents. An inspiration for such a situation are real-time strategy computer games, in
which large numbers of units, both friendly and hostile, are competing for room to move around
(see Figure 1).

Figure 1: The Zerg attack the Protoss in Starcraft 2. The maps of the original Starcraft have been
made available for research at http://movingai.com/benchmarks/.

Kornhauser (1984) gave a complete algorithm for the multi-agent pathfinding problem, as well
as lower and upper bounds of O(n3 ) (where n is the number of vertices in the graph) for the number
of moves required in a solution. In recent years, a number of approaches have appeared that solve
subclasses of the multi-agent pathfinding problem (see Section 2.1). Roger and Helmert (2012)
suggested that one of the reasons that the results from Kornhauser have not been more widely
applied is:
. . . the approach is not described in one place, and most of its parts are not described
algorithmically. Therefore, the underlying algorithm must be derived from a number of
proofs in the paper.
444

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

The Push and Swap algorithm (Luna & Bekris, 2011b) is a complete algorithm for instances having
at least two unoccupied vertices, and is therefore the most general of the recent algorithms. However, we found a number of problems with the Push and Swap algorithm (De Wilde, Ter Mors, &
Witteveen, 2013), and presented our own Push and Rotate algorithm to overcome these shortcomings.
Our primary aim in this paper is to provide a complete and understandable specification of an
algorithm for the multi-agent pathfinding problem with at least two unoccupied vertices. More
specifically, this paper presents the following contributions:
1. A specification of a complete algorithm for multi-agent pathfinding, which involves a reconstruction, and in some cases a refinement of some of the theoretical results from Kornhauser (1984).
2. An empirical evaluation of our algorithm, which includes a comparison with the Bibox algorithm (Surynek, 2009), an algorithm that assumes biconnected instances, and which is among
the best performing of the recently developed approaches described in Section 2, both in terms
of number of moves and CPU time required (judging by the empirical evaluations in Surynek,
2009; Wang & Botea, 2011).
3. A brief exploration of the possibilities to improve solution quality and reduce computation
times through the use of heuristics, namely in the area of selecting which agent to plan next,
and which path each agent should choose.
Part of the first contribution has appeared in a conference paper (De Wilde et al., 2013), namely
Algorithms 1, 2, 3, and 8 and some of the proofs. The reconstruction of Kornhausers theoretical
results, as well as a complete listing of relevant algorithms and proofs are new to this paper, as are
contributions two and three (a different, more restricted empirical evaluation was conducted for the
conference paper).
This paper is organized as follows. In Section 2, we define the multi-agent pathfinding problem,
discuss its complexity and a number of algorithmic approaches. In Section 3, we describe our
Push and Rotate algorithm, and in Section 4 we prove its completeness and analyze its worstcase behavior. In Section 5, we describe heuristics for path and agent selection, before describing
the experiments in Section 6. The experiments comprise a comparison with the Bibox and Push
and Swap algorithms on different types of randomly generated instances. Finally, we finish with
conclusions and future work in Section 7.

2. Background and Problem Statement
We consider a simple1 connected2 graph G = (V, E), a set of agents A, with |A| < |V |, an assignment
function A of agents to vertices A : A  V , and a goal assignment of agents to vertices T : A  V .
The functions A and T are total, injective, and non-surjective; they are total functions as the location
1. A graph is simple if there is at most one edge between any two vertices; multiple edges between two vertices would
not expand the solution space, since we assume that an agent must always move to an empty vertex.
2. If the graph is not connected, then the Multi-agent Pathfinding problem can be considered for each of the components
separately. If there exists an agent for which the destination location is in a different component from the start
location, then the instance has no solution.

445

fiD E W ILDE , T ER M ORS & W ITTEVEEN

of each agent must be specified, injective because one vertex can hold only a single agent at a time,
and non-surjective as we require that there are always more vertices than there are agents.
A move is to transfer an agent ai  A from its current vertex v = A (ai ), to an adjacent, unoccupied vertex w, A 1 (w) = . We define the M ULTI - AGENT PATHFINDING problem as an optimization problem: to find a sequence  of moves that transforms the initial assignment to the goal
assignment, such that ||  |0 | for any sequence of moves 0 that transforms A into T .
The decision variant of the Multi-agent Pathfinding problem (i.e., does there exist a sequence
of K moves that transforms the initial assignment to the goal assignment) was shown to be NPcomplete (Goldreich, 1993)3 . The NP-completeness of the problem holds in case there is only one
agent with a destination location, with all other agents being obstacles that may be moved out of
the way (Papadimitriou, Raghavan, Sudan, & Tamaki, 1994) (i.e., the goal assignment is a partial
function with a domain of size 1). Our Push and Rotate algorithm that we will present in Section 3
will find move sequences for the Multi-agent Pathfinding problem with at least two unoccupied
vertices, although it does not guarantee optimal solutions, as that would require exponential running
time, assuming P 6= NP.
Goraly and Hassin (2010) presented a variant of the Multi-agent Pathfinding problem in which
there are m colors, and each of the p agents has a color. The goal configuration specifies for each
vertex which color the occupying agent must have (or whether the vertex should remain empty);
the authors show that feasibility can be decided in linear time (i.e., it can be decided whether an
instance has a solution), also in the case that m = p. Goraly and Hassin build on the work of Auletta
et al. (1999), who presented an algorithm for deciding the feasibility of Multi-agent Pathfinding
problems on trees, in linear time.
Calinescu et al. (2008) also distinguish between different kinds of chips, namely unlabeled and
labeled (where every label is unique), and they consider a different type of model where moving a
chip along an empty path is considered a single move. They prove that even for unlabeled chips, the
problem is APX-hard, and still NP-hard for instances on an infinite, rectangular grid. Finally, Wu
and Grumbach (2009) considered directed graphs, which have the interesting property that a wrong
move can put the problem in an unrecoverable configuration. Unrecoverable reconfigurations were
also at the heart of the PSPACE-completeness proof of the Sokoban puzzle game (Culberson, 1999;
Hearn & Demaine, 2005); Wu and Grumbach do not consider the complexity of the optimization
problem, however, but instead prove that feasibility can be decided in O(n2 m) time, where n is the
number of vertices, and m the number of arcs.
Early research into Multi-agent Pathfinding focused on the feasibility of reaching one assignment from another. Wilson (1974) studied simple biconnected4 graphs with a single empty vertex,
and he shows that any assignment can be reached from any other, except when the graph is bipartite, in which case there are two sets of assignments that can only reach the assignments in the same
set. Wilsons theorem includes two exceptions that are not generally solvable: polygon (or cycle)
graphs, and, remarkably, a single specific graph 0 (Figure 2).
Kornhauser et al. (1984) extend Wilsons result to general graphs with any number of unoccupied vertices and provide a polynomial-time decision procedure with an O(n3 ) bound on the number
of moves required. The result by Kornhauser is based on the insight that a graph may be viewed as
3. Goldreich proves the NP-completeness of the Shortest Move Sequence problem which is equivalent to our definition
of M ULTI - AGENT PATHFINDING, with the exception that Goldreich considers biconnected graphs.
4. A biconnected graph is a connected graph with no articulation vertices, i.e., vertices whose removal will disconnect
the graph; such graphs are also called nonseparable graphs.

446

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

(a) A polygon graph.

(b) Wilsons 0 graph.

Figure 2: Biconnected graphs that are not generally solvable for a single empty vertex.

a tree of biconnected components that are linked by chains of zero or more vertices with degree 2
(called isthmuses). It turns out that if two of these components are linked by an isthmus that contains
more vertices than the number of unoccupied vertices minus two, then it is impossible for agents in
components on different sides of the isthmus to swap positions.
a5
a8

a2
a1

a3

a6

a4
Able to cross

a7

Unable to cross

Figure 3: Illustration of isthmuses connecting nonseparable components.
In Figure 3, note that it is possible for any of the agents in A1 = {a1 , . . . , a6 } to swap positions,
and also the agents in A2 = {a7 , a8 } can exchange positions, but no agent from A1 can exchange
position with any agent in A2 . This means to say that, if we take agents a6 and a7 as an example,
then it is not possible to reach a configuration in which a6 occupies the position of a7 in Figure 3,
while at the same time a7 occupies the current position of a6 . The isthmuses that are impossible to
cross induce a decomposition of the graph into smaller subgraphs, which can be solved in turn. We
will demonstrate this decomposition in Section 3.1.
2.1 Algorithms
Standley (2010) proposed an algorithm that guarantees optimal5 solutions for multi-agent pathfinding in which the agents move in an eight-connected grid. In each time step, an agent either moves
to an adjacent grid cell or stands still, and the cost for a single agent is the number of time steps it
takes to reach its goal; the cost of the entire solution is the sum of all agent plan costs. Moves are
not only allowed to empty grid cells, but also in a cycle of agents where each agent moves to the cell
of the next agent in the cycle. Hence, Standleys algorithm can also be applied in problem instances
where the number of agents is equal to the number of vertices.
5. In this section, we will refer to an approach as optimal if it returns a solution consisting of a minimal number of
moves.

447

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Standleys approach can be seen to improve on a standard A*-based approach in which the state
is an n-tuple of grid locations, one for each of the n agents, and in which the moves of all agents
are considered simultaneously in one timestep, so each state has potentially 9n legal operators (nine
for each of the eight moves plus the wait move). Standleys operator decomposition divides each
time step such that one agent is considered at a time, thereby reducing the branching factor from
9n to 9, although the search depth increases by a factor of n. Coupled with a perfect heuristics and
a perfect tie-breaking strategy, the operator decoupling would reduce the number of required steps
from 9n  d, for a search depth d, to 9n  d. Hence, the operator decoupling scheme requires a good
heuristic to save computation time compared to the standard approach.
In further work, the operator decomposition technique is employed to create an anytime algorithm, based on the maximum group size of agents for which optimal solutions are found (Standley
& Korf, 2011). The anytime algorithm starts with a group size of one, and increases the group size
by one step when a solution is found, looking for more efficient solutions. The stand-alone operator
decomposition algorithm struggled to find solutions to problems larger than a 32  32 grid with
ten agents, but the anytime algorithm was able to produce good-quality solutions for more than a
hundred agents.
Another optimal approach is due to Sharon et al. (2011), which is called Increasing Cost Trees
(ICT). In ICT, there is a high-level search through a tree where each node consists of a k-vector
of individual path costs, and represents all possible solutions in which the cost for an agent equals
the value in the cost vector. To create a child node, a unit cost is added to the cost of one of the
agents. A low-level search is then performed to see if the new node can bring all agents to their
destinations. ICT can be efficient in scenarios with low interaction between the agents, in which
all agents can reach their destinations with a small number of extra moves; otherwise, Standleys
operator decomposition is more efficient.
Another optimal approach by Sharon et al. (2012) is meta-agent constraint-based search. In
constraint-based search, a high-level search is performed in a constraint tree, where nodes are constraints on individual agents, and a low-level search to find individual agent paths that respect the
constraint of the high-level node. The constraint-based approach performed poorly on some types of
problems, however, so the authors devised the meta-agent strategy, in which groups of agents with
many internal conflicts are merged into one meta agent, in order to reduce the number of conflicts
at the high-level constraint search.
Given the NP-completeness of the problem, many papers employ a sequential approach, in
which agents are planned for one after the other, to obtain a polynomial-time algorithm that is not
necessarily optimal. To ensure that the planning of agent n does not disrupt all the work done to put
agents 1, . . . , n  1 into position, existing algorithms either reserve time slots on nodes, or previous
agents are restored to their positions after the planning of agent n.
Reservation-based approaches are typically not complete, in the sense that the reservations made
by the first n agents can make it impossible for agent n + 1 to find a plan (even if a multi-agent
plan for all n + 1 agents could be found by other means), and as such these approaches are not
particularly suited to instances in which the ratio between the number of agents and the number
of empty vertices is high. In context-aware routing (Ter Mors, Witteveen, Zutt, & Kuipers, 2010),
agent n finds an optimal route plan (i.e., a path plus the times at which it will arrive at each node in
the path) around the reservations of the first n  1 agents, but it assumes that agents only enter the
graph at the start of their first reservation, and leave the graph at their destination. Alternatively, it
448

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

can be assumed that all start and destination locations are parking places, and can hold an infinite
number of agents (Zutt & Witteveen, 2004).
Velagapudi, Sycara, and Scerri (2010) use a reservation-based system to create a distributed
cooperative routing algorithm. Their problem definition is more general, as they simply assume a
set of robots that are looking for trajectories within a given time horizon, a binary obstacle map O,
and a function C OLLISION C HECK that takes two robot trajectories and returns true if these collide.
In their distributed routing algorithm, once an agent has found a route, it broadcasts this route to all
other agents. During route planning, an agent has to take into account the routes that higher-priority
agents have broadcast. In addition, if an agent receives a higher-priority route that conflicts with its
own route, it will have to re-plan.
Silver (2005) presents a windowed approach in which the agents only make reservations for a
restricted time horizon. Silver claims the following three advantages. First, the agents can continue
cooperating after they reach their destination vertices (instead of staying put and blocking their
destination vertices). The second advantage is that the sensitivity to agent ordering (or prioritization)
is reduced, as different agent priorities can be assigned for different time periods. Finally, there is
no need to plan for long-term contingencies that may not occur.


Alt.path p0



v

Path p

Figure 4: For the S LIDABLE class of instances, there must exist, for every path p and every vertex
v on p, an alternative path p0 connecting the predecessor and successor of v.

The MAPP algorithm (Wang & Botea, 2008) brings agents to their destination one by one along
a pre-computed path, where lower-priority agents may be temporarily pushed aside. MAPP requires
a number of restrictions on the instances for which it guarantees to find a solution; the S LIDABLE
class of instances requires:
1. for each node in an agents start-destination path (except for the start and destination), there
must exist an alternative path connecting its predecessor and successor nodes (see Figure 4),
2. the first node (after the start node) in the first agents path must be empty,
3. no target location may intersect with any of the paths and alternative paths of any of the
agents.
Khorshid et al. (2011) present a Tree-based Agent Swapping Strategy (TASS): in each iteration of
the algorithm, an agent is selected to be sent to its goal, which is accomplished by swapping it with
other agents. Swapping two agents is accomplished by moving both agents to a junction  a node
of degree three or more  and ensuring that at least two neighbors of the junction are empty. After
449

fiD E W ILDE , T ER M ORS & W ITTEVEEN

the swap has been performed, both the empty vertices and the other agents that have moved are
returned to their original locations, such that only the two swapping agents will have been affected.
To solve instances on general graphs, the authors first employ a graph-to-tree decomposition
algorithm. However, the decomposition is not complete in the sense that a solvable instance may
not have a solution any more after the transformation to a tree. The authors also provide conditions
under which an instance is guaranteed to be solvable, namely that the distance between any two
junctions may not be greater than the number of empty vertices minus two, which turns out to be
identical to the result obtained by Kornhauser (1984) when restricted to trees.
Suryneks Bibox algorithm (2009) requires (and is complete for) biconnected graphs with at
least two unoccupied vertices. The Bibox algorithm makes use of the fact that each biconnected
graph can be viewed as an original cycle, extended by a number of handles (see Figure 5; Kornhauser shows how any biconnected graph can be decomposed into handles). Agents with a destination in the outermost handle are brought to their destination first, after which that handle does not
need to be taken into account any more, and the algorithm proceeds with the next handle. Surynek
also implemented the approach by Kornhauser (1984), and reported that Bibox produced both lower
running times and shorter paths.

Figure 5: A graph consisting of an initial cycle, in white, and two handles in yellow and blue.

Finally, the Push and Swap algorithm (Luna & Bekris, 2011b) was presented as complete for any
graph with two or more unoccupied vertices. The algorithm works by iteratively selecting agents
in some unspecified priority order to move to their respective destination locations. For each agent,
the algorithm will move it to its destination location along any shortest path. When other agents are
encountered along this path, the action to be taken depends on the priority of the other agent. In
case the other agent has lower priority, the algorithm will attempt to move it out of the way with the
push operation. This can be accomplished by pushing the blocking agent forward along a shortest
path (not containing any higher-priority agents) to an empty vertex. In case the blocking agent has
a higher priority, the algorithm will attempt to exchange their positions using a swap operation that
450

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

is similar to the swap operation in TASS (Khorshid et al., 2011). The higher-priority agent must be
returned to its destination, for which the Push and Swap algorithm uses the resolve operation.
A parallel version of the Push and Swap was developed by Sajid, Luna, and Bekris (2012), with
the aim of reducing the length of solutions produced by Push and Swap, in which all moves are
sequential. The idea behind Parallel Push and Swap is to first resolve any dependencies between
agents that require a swap operation, after which some of the push steps can be performed in
parallel.
Although presented as complete, we showed that the Push and Swap algorithm is not complete,
and contains the following shortcomings (De Wilde, 2012; De Wilde et al., 2013):
1. The algorithm does not identify polygon graphs, i.e., graphs consisting only of a single cycle.
For a solvable polygon instance, Push and Swap will fail to find a solution if the wrong agent
priority ordering is chosen; if an agent tries to move a higher-priority agent out of the way
with a swap, the algorithm will fail, since a swap requires a vertex of degree  3, and in a
polygon graph all vertices have degree 2 (see Figure 6 for an illustration).
2. To enable the swap operation, two neighboring vertices of a junction (in TASS terminology)
must be emptied using the clear operation; the specification of clear by Luna and Bekris
identifies only two of the four cases that must be distinguished.
3. When moving a vertex back to its destination after a swap, the resolve may invoke the
swap operation again. Examples can be constructed in which these recursive calls result in a
higher-priority agent being two steps removed from its destination, and Push and Swap may
fail in those instances.
4. The Push and Swap algorithm does not take into account the result from Kornhauser (1984)
that it is impossible for agents to swap if they are separated by an isthmus longer than the
number of empty vertices minus two. The Push and Swap algorithm may fail in case an agent
ai must move out of the way for another agent a j , and ai has been assigned the higher priority,
but ai and a j cannot swap.

a1

a2

Figure 6: Regardless of which agent moves first, the second agent will try to reach its goal along
the shortest path, which is blocked by the other, higher-priority agent. A swap will be
attempted but there are no vertices of degree  3 to swap at.
The first shortcoming was resolved in a personal communication with the author: instead of
always choosing the shortest path, an agent must choose the shortest path to its destination that
does not contain any finished agents. The second shortcoming is rectified by our updated clear
operation (Algorithm 12, Appendix A). To fix the third point, we changed the way in which an agent
451

fiD E W ILDE , T ER M ORS & W ITTEVEEN

is returned to its position after a swap, and we introduce a new operation rotate to accomplish this.
To address the fourth point, we studied the theory on problem decomposition by Kornhauser (1984),
and developed new algorithms to decompose the problem into subgraphs (see Definition 4), assign
agents to subgraphs, and determine the agent priorities to the extent that they are determined by
the relation between the subgraphs. The result is an algorithm for multi-agent pathfinding that is
complete for general graphs with at least two empty vertices.

3. Push and Rotate
Our Push and Rotate algorithm consists of a pre-processing phase, and a phase in which agents
are moved to their destinations. In the pre-processing phase, we first divide the graph into subgraphs, and then we assign agents to the subgraphs. The definition of a subgraph (Definition 4
in Section 3.1) ensures that only agents assigned to the subgraph can swap positions6 . The third
and final step of pre-processing is to determine the order (priority) in which agents are planned for.
For agents assigned to the same subgraph, any priority ordering is feasible (we test an ordering
heuristic in Section 6.3), while for agents assigned to different subgraphs, it may be necessary to
complete one subgraph before starting another, so a partial priority relation between the subgraphs
is determined.
When it comes to the phase of moving agents to their destination locations, our algorithm works
in a fashion similar to Push and Swap (Luna & Bekris, 2011b). First, we determine a shortest path
for the agent to its destination, and then we attempt to move this agent forward along this path. If
other agents are encountered along the way, then the action to be taken depends on whether the
blocking agent has a higher priority. If it has a lower priority (meaning that we have not planned for
the agent yet), then we can try to push this agent out of the way along a shortest path to an empty
vertex. If this does not work, or if the agent has a higher priority (it has been planned for, and is
occupying its destination location), then we attempt to exchange the position of the agents using a
swap operation, which involves moving both agents to a vertex of degree three or higher, emptying
two of its neighbouring vertices, performing the exchange operation (Figure 7), and reversing the
appropriate moves to ensure that only the swapping agents are in a different position  namely
each others. After the swap operation, we must return the higher-priority agent to its destination.
In Push and Swap, this results in recursive calls to swap, and ultimately undefined behavior (see De
Wilde, 2012, for the analysis); in our Push and Rotate algorithm, we solve this problem by detecting
whether there is a cycle of agents that want to move forward. If so, all these agents are advanced
one step with the rotate operation.
If the swap operation fails, we (like Luna & Bekris, 2011b) conclude that the instance has no
solution. It should be noted, however, that this conclusion can only be validly drawn for particular
priority orderings. In Figure 8, for example, the instance is only solvable if agent a4 (or a5 , or both)
have a higher priority than agent a3 . Otherwise, if a3 is moved to its destination vertex v first, a push
operation for a4 or a5 will fail because a3 has higher priority; the swap operation will fail, because
a swap is impossible between a3 and a4 . To see why a swap is impossible, note that it requires both
6. We normally use the word swap to indicate the exchange of position of two agents occupying adjacent nodes. A
broader meaning of the word swap is that of any two agents changing position in an assignment. For the latter
meaning, Kornhauser interchangeably uses the terms 2-cycle, transposition, or swap (Kornhauser, 1984, p. 8). Both
meanings of the word swap hold with regard to agents being able to swap iff they are assigned to the same subgraph.
Note that when we write swap, we refer to the operation defined in Algorithm 5.

452

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

a1
v
a1

v

v

a2

a2

a1

a2
Figure 7: Sequence of states of the exchange operation.

agents to be at a vertex with degree three or more, with two neighbors unoccupied. The only two
vertices of degree three or more that can be reached by both a1 and a4 are v and v0 . With a3 at v,
there is only one empty neighbor to the left of v; if a3 moves back to its start location and a4 moves
to v0 , then there is only one empty neighbor to the right of v0 .

a2

a1

a3

a4

v0

v

a5

Figure 8: This instance is solvable iff the priority of a4 , a5 , or both is higher than the priority of a3 .

3.1 Problem Decomposition
Kornhauser (1984) proposed a decomposition of the graph into subgraphs, which we will reconstruct
in Section 3.1.1, along with an algorithm to obtain the decomposition. The subgraphs are defined in
such a manner that agents are either confined to one subgraph, or they are confined to an isthmus. In
Section 3.1.2, we will pose the proposition  with the proof to come later  that the swap operation
(Algorithm 5, Section 3.2) will succeed on two agents if and only if they are assigned to the same
subgraph. The results of Section 3.1.2 are a refinement of the results by Kornhauser, who did not
explicitly state all the details of the agent assignment problem. Finally, in Section 3.1.3, we consider
the interactions between agents assigned to different subgraphs, in the sense that some subgraphs
must be solved before others, in order to avoid the problems explained in Figure 8. Kornhauser
does not specify any priority for the agents, and therefore there are no restrictions regarding moving
agents with a higher priority, so the prioritization of subgraphs is unique to our approach.
3.1.1 C ONSTRUCTING S UBGRAPHS
Kornhauser (1984) remarked that any connected graph can be viewed as a tree of biconnected components. Within biconnected components, agents can exchange position, so the biconnected com453

fiD E W ILDE , T ER M ORS & W ITTEVEEN

ponents play a central role in the construction of subgraphs. In Kornhausers thesis, the first step to
creating subgraphs is to divide the graph into biconnected components, defined by Kornhauser as
follows (Kornhauser, 1984, p. 30):
Definition 1 (Biconnected Components). Let G = (V, E) be a simple connected graph. Two edges
e1 , e2  E are equivalent if and only if e1 = e2 or there is a cycle in G containing e1 and e2 ; this is an
equivalence relation. The equivalence classes, together with incident vertices, are the biconnected
components of G .
a9

a4
a6

a1
3

1

a2

1

a3

6

2

4

s1

s2

9

6

5

6

s3

a5

7

s4

a7

8

a8

10

s5

a10

1

(a) Ten biconnected components, and vertices s1 , . . . , s5 with degree 3 that join biconnected components.

a9

a4
a6

a1
a2

S1

S2

a5

a7

a8

S3

a10

a3
(b) With m = 3, this graph has three subgraphs S1 , S2 , and S3 .

Figure 9: Identifying biconnected components (9(a)) and subgraphs (9(b)).
Biconnected components consisting of one edge are called trivial. The graph in Figure 9(a)
contains ten biconnected components, two of which are nontrivial (components numbered 1 and 6).
Note that vertices s1 , . . . , s5 in Figure 9 are vertices7 with degree 3 that join biconnected components,
both trivial and nontrivial. On the basis of these vertices Kornhauser defines an equivalence relation
that we can use to construct subgraphs.
Definition 2 (Join vertices). Let G = (V, E) be a simple connected graph. The set of join vertices
S  V consists of vertices of degree  3 which are common to at least two biconnected components.
Note that the set of join vertices S cannot comprise the set of all vertices V : first suppose the
graph consists exclusively of trivial biconnected components. This implies that the graph is acyclic,
and there exist at least two vertices of degree 1, which are therefore not join vertices. In case the
graph also contains a nontrivial biconnected component C1 , then if S = V , all vertices in C1 must be
connected to other biconnected components C2 , . . . ,C j , the vertices of which would also all have to
7. We follow the notation from Kornhauser here, and denote join vertices by si rather than denoting vertices by vi as we
do elsewhere.

454

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

be connected to different biconnected components. Of course, it is not possible to keep creating new
biconnected components, and reusing an earlier one would create a cycle, meaning that all vertices
involved are in a single biconnected component, not connecting different ones.
In the following, let m be the number of empty vertices.
Definition 3 (Reachability Equivalence). Given a simple connected graph G = (V, E) and its set of
join vertices S, s1 , s2  S are equivalent if and only if
1. s1 = s2 , or
2. s1 and s2 are in the same nontrivial biconnected component, or
3. there is a unique path between s1 and s2 , and its length is  m  2.
The transitive closure of this relation is an equivalence relation.
In Figure 9(a), m = 3 and we have the equivalence classes S1 = {s1 , s2 }, S2 = {s3 , s4 }, and S3 =
{s5 }. Note that if we remove one agent from Figure 9, then m is 4, and condition 3 of Definition 3
ensures that s2 and s3 are in the same equivalence class, as well as s4 and s5 . Hence, with 4 empty
vertices, the graph in Figure 9 contains a single equivalence class S1 = {s1 , . . . , s5 }.
Definition 4 (Subgraph). Given an equivalence class Si , a subgraph Si = (Vi , Ei ) is a subgraph of
G , induced by the set of vertices Vi consisting of:
1. the equivalence class Si from Definition 3,
2. any vertices v  V such that v is in the same nontrivial biconnected component as some s  Si ,
3. any vertices on a unique path between two join vertices s1 , s2  Si .
Figure 9(b) shows that there are three subgraphs in our example, corresponding to the equivalence classes S1 , S2 , and S3 . An algorithm to obtain the division into subgraphs is given below in
Algorithm 1.
Algorithm 1 find subgraphs(G , m)
1: S  all nontrivial biconnected components in G
2: S  S  {{v}| v  V  degree(v)  3  6 i : v  Vi }
3: while  Si , S j  S | u, v(minvSi ,uS j distance(v, u))  m  2 do
4:
Sk = Si  S j  {v0 |v0  shortest path(u, v)}
5:
S  {S \ {Si , S j }}  {Sk }
6: return S
In line 1 of Algorithm 1, we first find all nontrivial biconnected components, which can be done
in O(|V | + |E|) time (Hopcroft & Tarjan, 1973). Next, we add all vertices of degree three or higher
that are not part of a nontrivial biconnected component to the set S . In the while loop starting on
line 3, all elements of S that have vertices with distance  m  2 will be joined into one subgraph.
Note that the shortest path between Si and S j in line 3 is always between two join vertices: two
nontrivial biconnected components are connected by an isthmus, and so the vertices connecting the
nontrivial component to the isthmus must be common to more than one biconnected component,
455

fiD E W ILDE , T ER M ORS & W ITTEVEEN

namely the nontrivial biconnected component, and the trivial biconnected component which is the
isthmus edge. Hence, line 3 corresponds to point 3 from Definition 3 (either u and v are join vertices,
or two join vertices are encountered on the path from u to v), and line 4 corresponds to point 3 from
Definition 4.
We note here that Kornhauser employs a slightly different definition of subgraph. He includes
in his definition also vertices on a plank of a subgraph.
Definition 5 (Plank). Given an equivalence class Si and the corresponding subgraph Si = (Vi , Ei ),
a plank is a unique and maximal path in G from some vertex v  (V \Vi ) to a vertex s j  Si of length
 m  1.
In Figure 9, the subgraph S2 has two planks: the plank on the left between s2 and s3 , and the
right plank between s4 and s5 . Subgraph S3 even has three planks: it shares the plank between s5
and s4 with S2 , and also the two outgoing edges from s5 are planks.
As a result of Kornhausers definition, subgraphs can overlap. We opted not to include planks
in Definition 4, as we prefer to keep them separate, which is useful in illustrations as in Figure 9(b).
3.1.2 A SSIGNING AGENTS TO S UBGRAPHS
In this section, we will state two important results on the relation between agents and subgraphs:
1. Algorithm 2 below assigns to a subgraph those agents that are confined to the subgraph and
its planks, i.e., agents that can only reach vertices of the subgraph and its planks.
2. In Proposition 3 we state that for any two adjacent agents assigned to the same subgraph, we
can exchange their positions using our swap operation. This implies that an agent assigned to
a subgraph can reach all of the vertices of the subgraph and its planks.
The implication of the second result is that individual subgraphs are solvable in case the goal positions of the agents assigned to a subgraph are inside the subgraph or its planks. The importance of
the first result is that we can determine exactly which agents belong to a subgraph. Note that not all
agents are assigned to a subgraph, as some agents are confined to an isthmus.
Algorithm 2 assign agents to subgraphs(G , A, A , S )
1: for all ai  A do
2:
f (ai ) 
3: for all Si = (Vi , Ei )  S do
4:
for all v  Vi do
5:
m00  number of unoccupied vertices reachable from Si in graph induced from V \ {v}
6:
for all u 
/ Vi for which {u, v}  E do
0
7:
m  number of unoccupied vertices reachable from v in (V, E \ {u, v})
8:
if ((m0  1  m0 < m)  m00  1)  ai  A 1 (v) 6= then
9:
f (ai )  Si
10:
Follow path from u away from v and assign the first m0  1 agents on this path to Si
11:
if {u 
/ Vi for which {u, v}  E} = 0/  (ai  A 1 (v) 6=) then
12:
f (ai )  Si
13: return f , the assignment of agents to S
456

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

Algorithm 2 iterates over all vertices in all subgraphs, and decides whether an agent occupying a
vertex should be assigned to the subgraph. We can distinguish two types of vertices in the subgraph:
there are vertices that only have connections to vertices inside the subgraph, and vertices that are
connected to vertices not in the subgraph  these vertices (which are join vertices, Definition 2)
form the start of a plank. Agents on the former type of vertex are immediately assigned to the
subgraph, whereas for plank vertices it is checked whether there are sufficient empty vertices to
move any agents on the plank into the subgraph.
For the treatment of plank vertices, our algorithm can be viewed as a refinement from Kornhauser (1984), who only remarks that an agent is assigned to the subgraph if enough blanks are
on the subgraph to one side of P [the pebble] to take P off the plank. . .. We specify the values
m0 and m00 (Figure 10) that encode exactly when sufficient free space is available for an agent to be
moved into the subgraph. The meaning of m0 and m00 and the condition on line 8 of Algorithm 2 are
explained further by the different cases in the proof of Proposition 1.

a5

a3

a5

a4

a3

a4

S1
a1

u

a2

S1
a1

v

(a) m0 = m = 2, meaning that a2 will not be assigned (yet) to S1 , and that a1 will be assigned to
S1 .

u

a2

v

(b) m00 = 1, meaning that a2 will be assigned to S1 .

Figure 10: Illustration of m0 and m00 . Unreachable and removed parts of the graph have been grayed
out.

Before we prove the correctness of Algorithm 2, let us first see how agents are assigned to
subgraphs in our example. Figure 11(a) shows that agents a1 , a2 , a3 , and a4 are assigned to S1 .
Agents a1 , . . . , a3 are clearly inside the subgraph, and will be assigned on the basis of line 12. Agent
a4 is on a plank, but not on a join vertex, so it will be assigned to S1 in line 10, since m0 = 3.
For subgraph S2 (Figure 11(b)), a6 is on an inner vertex, so it will be assigned to S2 in line 12.
Agent a5 occupies a join vertex, and three empty vertices can be reached without making use of
vertex A (a5 ), so m00 = 3, and a5 is assigned to S2 in line 9. Agents a7 and a8 are on a plank that
starts at join vertex A (a5 ); m0 = 3, so the first two agents on the plank, starting from vertex A (a7 ),
are assigned to S2 in line 10.
For subgraph S3 (Figure 11(c)), both a9 and a10 are on a (non-join) plank vertex, and with
m00 = 3, both are assigned to S3 in line 10. Note that when v = A (a8 ) (line 4) and u = A (a7 )
(line 6), we have m0 = m00 = 0, so a8 is not assigned to S3 .
Proposition 1. Algorithm 2 assigns agent ai to subgraph S j if and only if ai is confined to S j and
its planks.

457

fiD E W ILDE , T ER M ORS & W ITTEVEEN

a9

a4
a6

a1
a2

S1

S2

a5

a7

a8

S3

a10

a3
(a) Agents a1 , a2 , a3 , and a4 are assigned to S1 (the leftmost subgraph).

a9

a4
a6

a1
a2

S1

S2

a5

a7

a8

S3

a10

a3
(b) Agents a5 , a6 , a7 , and a8 are assigned to S2 (the middle subgraph).

a9

a4
a6

a1
a2

S1

S2

a5

a7

a3
(c) Agents a9 and a10 are assigned to S3 (the rightmost subgraph).

Figure 11: Assignment of agents to subgraphs.

458

a8

S3

a10

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

a3

a3

a4

S1
a1

a2

a4

S1

a5

a1

(a) For agent a2 , m00 = 0.

a2

a5

(b) For agent a2 , m00 = 2.

Figure 12: In Figure 12(a), a2 is not assigned to S1 ; in Figure 12(b), a2 is in S1 , but a3 is not.

Proof. The central idea of the proof is that if an agent can reach the inside of a subgraph, then
there are not sufficient empty vertices in the graph to move beyond one of its planks, as shown by
Kornhauser (1984). We will consider the following four cases:
1. An agent ai occupies a vertex v inside some subgraph S j , and v is not a plank vertex,
2. An agent ai occupies a plank vertex w 6 S j (i.e., not the join vertex),
3. An agent ai occupies a join vertex v that is the start of a plank (i.e., v  S j ).
4. An agent ai occupies a vertex v that is not in S j nor on any of its planks.
Case 1: inner vertex: first note that ai is assigned to S j (line 12 in Algorithm 2). To reach any
vertex not assigned to S j or one of its planks, agent ai must walk off one of the subgraphs
planks. First, the agent must take at least one step to a join vertex that is the start of a plank,
leaving behind one empty vertex. Then, walking to the end of the plank, which is m  1 long,
requires m  1 empty vertices. To step off the plank, another empty vertex is required, but
there are only m empty vertices in total, so ai can reach at most the end of a plank.
Case 2: plank vertex w: recall that m0 is defined as: the number of unoccupied vertices reachable
from v in (V, E\{u, v}), and here v is the start of the plank. m0  1 of these empty vertices
can be used to move m0  1 plank agents into the subgraph. Consider agent ai that is number
m0  1 on the plank: it takes m0  1 empty vertices to move to the start vertex of the plank, and
since m0 empty vertices are available into which other agents can be moved, one more empty
vertex is available for ai to step off the plank and into the subgraph. Then, we can apply the
first case to show that ai cannot leave the subgraph or any of its planks.
Case 3: join vertex: agent ai cannot always enter the subgraph, even when agents behind it on the
plank can. Consider Figure 12(a), in which agent a2 is on the start of two planks, and let
u = A (a1 ). Then m0 = 2, but a2 cannot enter the single subgraph S1 , because it has to move
out of the way to give the agents inside the subgraph space to move. In this case, m0 = m, and
all the empty vertices are behind a2 . Figure 12(b) shows that in case m0 = m, the agent at the
join vertex is only assigned to the subgraph in case empty vertices can be reached from S1
without using the join vertex. Hence, in Figure 12(b) agent a2 is assigned to S1 since m00  1.
459

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Note that if ai is not assigned to S j , then it is also not confined to S j or its planks: all empty
vertices are directly behind ai (m0 = m), so it can move m steps away from S j , while the plank
is only m  1 edges long.
In case the agent ai at the join vertex is assigned to the subgraph, then there is at least one
empty vertex that can be used to make room for ai to step into the subgraph or onto another
plank, and we can apply the reasoning of the first case to conclude that ai is confined to the
subgraph and its planks.
Case 4: vertex v outside S j and its planks: clearly, ai is not confined to S j and its planks. To see
that ai wont be assigned to S j , note that it can only enter S j via its planks. As the planks are
m  1 edges long (all shorter planks are not connected to another part of the graph), ai would
need at least m steps to reach the start of a plank of S j . Since there are only m empty vertices
in the graph, there are no empty vertices left to enter S j , and ai is therefore not assigned to
the subgraph.

An important property of subgraphs is that an agent can reach any vertex of the subgraph it is
assigned to. Kornhauser (1984) proved 2-transitivity: for any two pairs of agents a1 , a2 , and b1 , b2
assigned to the same subgraph, it is possible to send ai to the location of bi (possibly moving other
agents). In Section 3.2, we will prove that our swap operation will always succeed on two agents
assigned to the same subgraph, which achieves 2-transitivity.
3.1.3 P RIORITIES OF S UBGRAPHS
The third stage of the decomposition process is to assign priorities to agents based on their membership to subgraphs. Algorithm 3 generates a partial order of subgraphs, and agents inherit the priority
of the subgraph they are assigned to. For the completeness of our Push and Rotate approach, it is
not necessary to differentiate between priorities of agents assigned to the same subgraph, although
it is possible to do so in order to pursue better solution quality. Finally, agents that are not assigned
to any subgraph receive the lowest priority, and are therefore planned last.
Algorithm 3 generates precedence constraints between two subgraphs in case one of the subgraphs contains an agent that will restrict the movements of agents in the other subgraph. Specifically, given two subgraphs Si and S j , and an agent r assigned to S j , the priority relation Si  S j is
added in the following two cases8 :
1. The goal position of agent r is the start vertex of a plank9 of Si , or
2. The goal position of agent r is a vertex v0 on a plank of Si , and all vertices of the plank between
v0 and the start of the plank are goal positions of agents not assigned to any subgraph.
The intuition behind both cases is that once agent r has been moved into its goal position, there
will be no more empty vertices in the subgraph Si ; otherwise, in the first case, agent r would be able
8. A note on notation: in the coming algorithms, we use r and s to denote agents (as do Luna & Bekris, 2011b). In the
examples so far we have used a1 , . . . , ak , but having agents ai and a j can be confusing in combination with subgraphs
Si and S j .
9. Recall that the start vertex of a plank is the vertex of the plank that belongs to the subgraph.

460

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

a7

S3

a3

a1

a10

a2

S2

a8

S4

S1
a4

a5

a4
a9

a6

S1
a1

(a) S4  S3 due to agent a5 .

S2
a2

a3

a5

(b) S2  S1 due to agent a2 .

Figure 13: If agents from one subgraph have a goal location on the plank of another, then there
might be a precedence relation between the subgraphs.

to move into Si and would be part of Si , by Proposition 1, which is a contradiction (in the second
case: the agents not assigned to any subgraph could move into Si , so they would be assigned to Si ).
For the agents of subgraph Si to move into their goal locations, empty vertices must be brought into
Si . In case r has been moved into its goal, this is not possible: a push operation is not allowed, and
a swap operation is not possible, by Proposition 3. Hence, subgraph Si must have a higher priority
than agent r, and therefore subgraph Si  S j .
An example of the first case is shown in Figure 13(a), in which for all agents their start location
equals their destination location, except for agents a8 and a9 that want to exchange position. If a5
has a higher priority than a8 and a9 , then an algorithm based on the operations push and swap will
not succeed: to plan a8 , a push may not move a5 aside since a5 has higher priority; a swap will
fail because a5 and a8 are in different subgraphs, and therefore cannot swap. Hence, we must add
the priority relation S4  S3 . An example of the second case is shown in Figure 13(b), in which
the plank vertex of S2 is occupied by a3 . In this example, no solution using push and swap can be
found in case a2 has a higher priority than a4 and a5 . When agents a4 and a5 are planned, it is not
allowed to move agent a3  which is not assigned to any subgraph  away with a push, because
agent a2 behind it may not be moved by the push operation. An attempted swap between a3 and
one of the agents of S2 will fail because a3 is not in S2 . Hence, the priority relation S2  S1 must be
added.
Proposition 2. If the priority relation between subgraphs is cyclic, then the instance is not solvable.
Proof. Suppose by way of contradiction that we have two subgraphs Si and S j such that S j  Si ,
due to agent r from Si , and Si  S j , due to agent s from S j .
By definition of a subgraph, there is at most one connection between two separate subgraphs, so
the goal locations of both r and s are on the same isthmus. For agent r to induce S j  Si , it either has
to reach the start vertex v (from the perspective of S j ) of the isthmus, or there may only be agents
not assigned to S j (so not s) between itself and v. Hence, agent s may not occupy any vertex on the
isthmus between r and vertex v. The only way for s to induce Si  S j would be if the goal location
of s is behind (i.e., on the side of Si ) the goal location of r.
461

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Hence, the assumption that the priority relation is cyclic implies that in their goal locations r
and s have swapped, however Kornhauser proved that only agents assigned to the same subgraph
can swap positions (Kornhauser, 1984, p. 11).
As an example of Proposition 2, consider agents a1 and a2 in Figure 13(a). If the destination
location of agent a1 is the current location of a2 , then the precedence constraint S3  S1 would have
to be added. Similarly, if the destination of a2 is the current location of a1 , then we have S1  S3 . In
this configuration, agents a1 and a2 have swapped location, but since they are assigned to different
subgraphs, this is not possible, by Proposition 3.
Algorithm 3 subgraph priority(G , S , T , f )
1: for all Si = (Vi , Ei )  S do
2:
for all v  Si do
3:
for all u 
/ Vi for which {u, v}  E do
4:
Vertex u should be the first vertex on the path from Si to another subgraph S j , otherwise
continue with the next u
5:
v0  v
6:
while r : (T (r) = v0 )  ( f (r) 6= Si ) do
7:
if f (r) = S j then
8:
Si  S j
9:
Continue with next v (line 2)
0
10:
v  next vertex on path from Si to S j
11: return The priority relation 
Algorithm 3 checks for every subgraph Si , and for every join vertex v  Si connected to a node
u 6 Vi that is on a path (i.e., an isthmus) to a component S j , whether there exists an agent r assigned
to S j that restricts the movements of the agents assigned to Si . In order for the precedence constraint
Si  S j to be added, agent r should either occupy v, or it should occupy a node v0 such that all
nodes10 from (not including) v0 to v (including) are goal locations of agents not assigned to any
subgraph. In either case, agent r, if planned first, would bottle up the agents assigned to Si , hence
the latter agents should receive higher priority: Si  S j .
A final note on agents not assigned to any subgraph. Although Algorithm 3 does not assign any
priority to these agents, these agents will be planned after all agents assigned to a subgraph.
3.2 The Operations push, swap, and rotate
In Section 3.3 we will describe the operation solve that moves all agents to their destinations, if
possible, but in this section we will first present the main operations used in our algorithm: push,
swap, and rotate. The push and swap operations are conceptually similar to the operations presented by Luna and Bekris (2011b), while the rotate operation moves agents in a cycle one step
forwards. The rotate operation does not require that all agents move simultaneously.
A note on notation: in our algorithms we assume parameters are passed by reference, so the
algorithm from which a subroutine is called can see any changes made to the parameter by the
subroutine. Below,  stands for the set of generated moves, and U stands for the set of blocked
10. If there are vertices in between v and v0 that are empty in T , then the agents in Si would still have room to maneuver,
even if r is at its goal location.

462

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

vertices, i.e., vertices that the algorithm may not use (any agents on these vertices will therefore
remain in place).
Algorithm 4 push(, G , A , r, v, U )
1: if vertex v is occupied then
2:
U 0  U  {A (r)}
3:
if clear vertex(, G , A , v, U 0 ) = false then
4:
return false
5: move(, A , agent r to vertex v)
6: return true
The push operation attempts to move an agent r, currently at location A (r), to location v, which
is assumed to be adjacent to A (r). If successful, the move is recorded in the current sequence of
agent moves  (line 5). In case location v is occupied when push is called, the clear vertex
operation is used to try to clear v. In line 2, prior to calling clear vertex, the current location of
agent r is added to the set U of locations from which agents may not be moved.
The specification of the clear vertex (Algorithm 10) has been moved to Appendix A (as
well as some other auxiliary algorithms), so as not to disrupt the flow of text too much. What
clear vertex does is to find a shortest path from v to an unoccupied node u in the graph induced
by V \ U ; if such a path exists, all agents on this path are moved one place towards u.
Algorithm 5 swap(, G , A , r, s)
1: S  {vertex x  f S (r) | degree(x)  3}
2: for all vertex v  S do
3:
A0  A
4:
0  [ ]
5:
if multipush(0 , G , A 0 , r, s, v) = true then
6:
if clear(0 , G , A 0 , r, s, v) = true then
7:
   + 0
8:
A  A0
9:
exchange(, G , A , r, s, v)
10:
reverse(, A , 0r/s )
11:
return true
12: return false
The swap operation attempts to exchange the locations of two adjacent agents r and s, by moving
them to a vertex of degree three or higher, performing the exchange operation there (see Figure 7
and Algorithm 13), and moving the agents back to where the swap was initiated (at the same time
reversing the moves of all agents not involved  line 10, where 0r/s stands for the sequence of new
moves with the roles of r and s reversed). All vertices of degree three or higher that belong to the
same subgraph as agent r (denoted fS (r)) are eligible to perform the swap (we evaluate the vertices
closest to r and s first). For a candidate swap node v, the multipush operation (Algorithm 11,
Appendix A) attempts to bring both agents to v (line 5). Since all moves of swap will be reversed
(with the exception of the exchange operation, and with the roles of r and s reversed), multipush
does not take into account the set of blocked agents U ; these agents may be moved as well. The
463

fiD E W ILDE , T ER M ORS & W ITTEVEEN

multipush operation is essentially a series of push operations, iteratively moving agents r and s a
step closer to v, and moving other agents out of the way.
v0

a3
a4

v0

a3

a2

a4

a2

v
a5

a6

v
ax

a1

ay

a5



a8

a1

a6

a7

ax



ax



a8
a7

(a) Initial configuration

(b) a1 moves out

v0

a3

v0

a3

a4

a4
v

a5

a2

a6

v
a1

ax

a5



a8

a1

a6

a7

a8
a7

(d) agents rotate, starting with a3

(c) a2 moves forward, swaps with a1
v0

a4
a5

v0

a4
a5

a3

a3

v
a6

v
a2

a7

a2

ax

a6



a2

a7

a1

ax

ay



a1
a8

a8

(e) a2 moves back into cycle

(f) Goal configuration

Figure 14: The steps of the rotate operation.

If multipush succeeds, the next step in Algorithm 5 is to try to ensure that v has two empty
neighbors, by calling the clear operation. The idea behind clear is to push agents on vertices
adjacent to v out of the way towards empty vertices, but the exact specification is quite intricate, due
to the possible movements of r and s that have to be considered in order to allow the other agents to
reach the unoccupied vertices. The specification and explanation of the clear operation is given in
Appendix A. We now state the result that the swap operation will succeed for two agents assigned
to the same subgraph (the proof is in Appendix B).
Proposition 3. For two agents r and s on adjacent vertices in G , the operation swap(, G , A , r, s)
will succeed if and only if r and s are assigned to the same subgraph Si .
464

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

The rotate operation assumes a cycle c of locations, and moves all agents within that cycle
forward one step. In case c is not fully occupied, performing the rotate is a trivial operation; otherwise, one agent must first be moved out of the cycle to provide room for the other agents to move.
The steps of the rotate operation are illustrated in Figure 14. In Figure 14(a), we see an agent
a1 that will be temporarily pushed out of the cycle to make room for the others. It does not matter
whether or not agents ax and ay , and others behind them, have a higher priority, since the moves
performed to move a1 out of the cycle will be reversed.
In Figure 14(c), agent a2 moves forward into v0 , and a swap operation for agents a1 and a2
ensures that a1 and a2 will be in the right position after the rotate. Figure 14(d) depicts the actual
rotation of the agents, with a3 moving forward first, followed by a4 , etc. In Figure 14(e) agent
a2 moves back into the cycle to complete the rotate, and in Figure 14(f) the goal configuration is
reached by returning the other agents (ax and ay in the figure) to their previous locations.
Algorithm 6 rotate(, G , A , c)
1: for all vertices v  c do
2:
if v is unoccupied then
3:
Move all agents in c forward, starting with the agent moving to v
4:
return true
5: for all vertices v  c do
6:
r  A (v)
7:
0  [ ]
8:
if clear vertex(0 , G , A , v, c \ {v}) = true then
9:
   + 0
10:
v0  vertex in c before v
11:
r0  A (v0 )
12:
move(, A , agent r0 to vertex v)
13:
swap(, G , A , r, r0 )
14:
Move all agents in c forward, starting with the agent moving to v0
15:
reverse(, A , 0r/r0 )
16:
return true
17: return false
The specification of the rotate operation is given in Algorithm 6. Lines 1 to 4 deal with the
trivial case of a cycle in which at least one location v is unoccupied: the agent going to v is moved
first, after which there is room for the agents behind it to move in turn. For the main body of the
algorithm, line 5 iterates over all vertices in the cycle, looking for a vertex v that can be cleared
(Lemma 2 proves that, for a solvable instance, such a vertex can always be found), in line 8.
Once clear vertex has succeeded, the algorithm then proceeds with the steps as illustrated in
Figure 14; in lines 10 to 12, the next agent is moved to the vacated vertex, and in line 13 this agent
swaps with the agent that has moved out of the cycle (Lemma 2 proves that this swap is possible for
a solvable instance). Line 14 rotates the agents, and in line 15 the necessary moves are reversed.
3.3 The Push and Rotate Algorithm
In Algorithm 7 we present our Push and Rotate algorithm. It first determines the division into
subgraphs, and it determines the assignment of agents to subgraphs for both the initial and the goal
465

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Algorithm 7 Push and Rotate(G , A, A , T )
1: m  |V |  |A|
2: S  find subgraphs(G , m)
3: f  assign agents to subgraphs(G , A, A , S )
4: f 0  assign agents to subgraphs(G , A, T , S )
5: if f = f 0 then
6:
 subgraph priority(G , A , S , f )
7:
return solve(G , A, A , T , S , f , )
8: return false

assignment of agents. If these assignment functions f and f 0 are not the same, then the instance is
not feasible and the algorithm returns false. Otherwise, the main algorithm solve is called which
returns a sequence of moves transforming the initial agent assignment into the goal assignment.
The idea behind the solve operation is to move agents to their destinations one by one, and a
single agent is moved to its destination one step at a time, along a shortest path to its destination. In
every iteration, first a push is tried to move the agent to the next location in its path, and if the push
fails, then a swap is performed, which will succeed (as proved in Theorem 1, provided that there
are at least two unoccupied vertices) as solve is only called on feasible instances.
When an agent has been moved to its destination, it is added to F , the set of finished agents. The
path it has traversed has been encoded in q, as shown in Figure 15(b). Since the push operation is
not allowed to move agents in F , these agents can only be moved by the swap operation (line 22) or
the rotate operation (line 19). An agent in F can only be moved off its destination by the former
operation. We refer to such an agent as a resolving agent, until it has returned to its destination.
All resolving agents are contained in q, because the swap occurs along the path of an agent to its
destination, which is then added to q. Note that when an agent in F is moved by the rotate
operation, it is actually returned to its destination. The second stage (lines 26 to 35) of the solve
operation aims to return resolving agents to their destinations, while shrinking q.
There now follows a more detailed description of Algorithm 8. First, some initialization is done:
the sequence of moves  is initialized to the empty list [ ] (line 1), as is the path q of resolving agents
(line 2). The set of finished agents F is initially empty (line 3), and r, the pointer to the agent that
is selected in each iteration, is initially undefined, denoted  (line 4). In line 5, we check whether
the input graph G is a polygon. If so, then is polygon gets the value true, otherwise false.
The outer while loop of line 6 iterates until the set of finished agents equals the set of agents.
If no next agent has been selected yet (r =, line 7), then in line 8 we choose a next agent with
joint-highest priority of all agents in A \ F . Note that, if r 6= in line 8, this can only mean that an
agent has been selected in line 30 as part of resolving agents on q.
Next, we must choose a path along which r is moved to its destination. If the graph is a polygon
(is polygon = true, line 9), then we must choose a path that does not encounter any finished agents
(line 10)  as no swap is possible in a polygon instance  otherwise we simply choose a shortest
path (line 12).
The inner loop of line 14 will move r closer to its destination, one step with each iteration. If
the next step on the path of r is also on q, then we have detected a cycle of resolving agents, and we
466

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

Algorithm 8 solve(G , A, A , T , S , f , )
1:   [ ]
2: q  [ ]
3: F  0/
4: r 
5: is polygon  v  V : degree(v) = 2
6: while F 6= A do
7:
if r = then
8:
r  next agent(A \ F , )
9:
if is polygon then
10:
p  shortest path(G , A (r), T (r), A (F ))
11:
else
/
12:
p  shortest path(G , A (r), T (r), 0)
13:
q  q + [A (r)]
14:
while A (r) 6= T (r) do
15:
v  vertex after A (r) on p
16:
if v  q then
17:
c  get cycle(v, q)
18:
q  qc
19:
rotate(, G , A , c)
20:
else
21:
if push(, G , A , r, v, A (F )) = false then
22:
swap(, G , A , r, A 1 (v))
23:
q  q + [v]
24:
F  F  {r}
25:
r 
26:
while |q| > 0 do
27:
v  the last vertex on q
28:
s  A 1 (v)
29:
if s  F  v 6= T (s) then
30:
r  A 1 (T (s))
31:
if r = then
32:
move(, A , agent s to vertex T (s))
33:
else
34:
Break inner loop, continue outer loop
35:
q  q  [v]
36: return 

move r and all other agents involved in the cycle of q11 forwards by performing a rotate operation,
in line 19. Otherwise, we attempt to move agent r forwards with a push (line 21), and if that fails,
a swap operation (line 22). After either the push or the swap succeeds, we append the vertex v that
11. The list q appended with v can consist of a cycle and a simple path emanating from the cycle, in the shape of a q,
more or less, so the get cycle method in line 17 only returns the cyclic part of q.

467

fiD E W ILDE , T ER M ORS & W ITTEVEEN

agent r has just moved to, to q (line 23). When the while loop of line 14 has completed, agent r is
added to the set F of finished agents (line 24), and r is reset to  (line 25).
a2

a3

a1

a4

a5

a7

a6

a8

a4

(a) A shortest path of a2 to its destination vertex
through the destination vertex of a1 .

a4

a1

a5

a3

a6

a7

a1

a5

a3

a6

a7

a8

a2

(b) The state directly after a2 has reached its destination vertex, q is highlighted.

a8

a2

a4

(c) a1  F is encountered on q, hence r  a5 for
the next iteration of the algorithm.

a1

a6

a3

a7

a8

a5

a2

(d) q will continue to grow while a5 moves to its
destination vertex.

Figure 15: An example of how q changes while agents are being moved to their destination vertices.

After moving agent r to its destination, the while loop starting from line 26 iterates over the
locations in q to see whether there are any agents in F that need to be returned to their goal location,
starting from the last location v in q. If v contains a finished agent s (line 29), then that agent has
been moved off its goal, and we check in line 31 whether its goal location is occupied by another
agent r. If there is no such agent r, then we simply move agent s back to its goal location; otherwise,
in line 34, we break the while loop from line 26, thereby starting a new iteration of the while loop
from line 14 with the agent r.

4. Analysis of Push and Rotate
In this section, we will first prove the correctness and completeness of Push and Rotate, before
analyzing the computational complexity in section 4.1. The correctness is proved in Theorem 1,
which makes use of Proposition 3, and lemmas involving the push and rotate operations (the
proofs of Lemma 1 and Proposition 3 are quite long and have been moved to Appendix B).
The following lemma proves that, for a solvable instance, if the push operation fails, then the
two agents involved must belong to the same subgraph (and, because of Proposition 3, the swap
operation will succeed).
Lemma 1. Suppose push (Algorithm 4) is called in the context of Algorithm 7 for an agent r moving
to vertex v. If push does not succeed, then r and s = A 1 (v) are assigned to the same subgraph.
The next lemma shows that the rotate operation is sound.
Lemma 2. For an instance (G , A, A , T ) with at least two empty vertices, the rotate operation
moves all agents in a cycle forward by one step.
468

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

Proof. Consider Figure 14; to see that the rotate operation will always succeed given two empty
vertices, note the following:
 Because there are at least two empty vertices in G , we can find a path p from v to an empty
vertex. Since the operations required to clear v will be reversed at the end of the rotate
operation, it is always possible to push agents along p.
 Since all agents in the cycle are assigned to the same subgraph, agents a1 and a2 can swap.

Theorem 1. Push and Rotate is complete for the class of Multi-agent Pathfinding problems with at
least two empty vertices.
Proof. In this proof we will focus on the correctness of Algorithm 8, solve. That the approach of
Algorithm 7  of dividing the graph into subgraphs and solving the subgraphs sequentially  is
sound was proven by Kornhauser (1984). Here, we will prove that Algorithm 8 returns a solution if
one exists, and false otherwise. The idea behind the proof is:
1. In each iteration of solve in which an agent is selected that is not in F (line 8), an agent is
added to F .
2. In case a finished agent has been moved off its goal location, then its current location is
adjacent to its goal location, and the current location is on a path q.
3. After a finite number of iterations, all vertices on q will have been processed, restoring outof-position agents in F to their goal location.
To prove the first point, consider an agent r in the while-loop of line 6. First a shortest path p is
determined to its goal. If the graph is a polygon (is polygon = true, line 5), then a shortest path
is found in the graph G \ A[F ]. In each iteration of the while-loop in line 14, agent r is moved to v,
the next vertex on p:
 If v  q, then there is a cycle C in q, as q is constructed from vertices that have already been
visited (line 23). The rotate operation will move any agents on C one step forward (i.e., in
the direction of the C). Lemma 2 shows that this rotate operation is possible. The result of the
rotate is that all agents in F  A 1 (C) are returned to their goal positions (since a swap has
moved these agents one step backwards along q) and agent r moves to v. Also, q will now be
updated such that the cycle is removed.
 If push succeeds for agents r and s, then agent s will be pushed out of the way, and agent r
will move to v.
 Otherwise the swap operation will be executed. If push does not succeed for r and s, then,
due to Lemma 1, we have fS (r) = fS (s), and this in turn implies that swap will succeed
(Proposition 3), hence agents r and s will be swapped successfully.
To prove the second point, note that an agent in s  F can only be moved off its goal location
as a result of the swap operation, which moves it to a location adjacent to its goal location. To see
469

fiD E W ILDE , T ER M ORS & W ITTEVEEN

that s cannot be moved further away12 from its goal location by subsequent operations, note that all
agents on q will be moved back to their destination after agent r, with which agent s has swapped,
has reached its destination. If, during the processing of q, the current location v of s is encountered
again, then a rotate operation is performed, returning s to its destination.
To prove the third and final point, consider an agent s that has been moved off its goal position
T (s). Then, in line 30, we assign to r the agent occupying the goal position of s. If there is no such
agent, we can return s to its goal position using a single move. Otherwise, we will break the loop
that iterates over q  thus the number of iterations is finite  and start a new iteration of the loop
from line 6, for the agent r on T (s). Once this agent r has been added to F , a new processing loop
for q is started, and this occurs at most |A| times.
4.1 Runtime Analysis
Let k denote the number of agents in the instance and n the number of vertices in the roadmap. In
order to solve an instance, each agent needs to be sent to its goal position, along a shortest path of
length  n.
For each step along this shortest path, the rotate, push or swap operation will be performed.
Out of these operations, the runtime of swap operation is dominant13 , which simplifies the following
equation:
tsolve = O(k  n  tswap )
The swap tries multipush and clear on all v with sufficient degree. While further analysis may
show that only a very limited (O(1)) number of vertices need to be checked (indeed, such behavior
was observed in our experiments), for now we will have the following:
tswap = O(n  (tmultipush + tclear ))
Both these operations require O(n  tclear vertex ) time. The clear vertex operation can find a
free vertex with a simple breadth-first search, resulting in O(|V | + |E|) = O(n2 ). This leads to the
following runtime complexity for the solve operation:
tsolve = O(n5  k)
4.2 Solution Quality
Each of the k agents has to move along its (shortest) path (of length  n) towards its goal position.
Just like in the runtime analysis, the swap operation (Algorithm 5) is a dominant factor in the output
of the solve operation (Algorithm 8), as push moves at most k agents along a path of length at
most k (as in the runtime analysis, the worst-case performance of rotate is determined by its call
to swap). This yields the following expression for the number of moves that the solve operation
outputs:
lsolve = O(k  n  lswap )
The swap operation moves two agents to a vertex v by using multipush (Algorithm 11), and then
clears two neighbors of v. While many different attempts are made in the clear (Algorithm 12)
12. Note that during the operation of the swap operation, agents may temporarily be moved out of the way, but these
moves are reversed before the end of the swap operation.
13. Actually, rotate calls swap, but its worst-case running time is also determined by the call to swap.

470

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

operation to clear the two neighbors of v, the total output of moves is not more than a constant times
the number of moves generated by clear vertex (Algorithm 10) plus some constant number of
moves: O(lclear vertex ), which is O(n), as clear vertex pushes agents backwards along a path to
an empty vertex. Since the multipush operation executes the clear vertex for each step along
the way, its output is a dominant factor.
lsolve = O(k  n  lmultipush )
lsolve = O(k  n2  lclear vertex )
lsolve = O(k  n3 )
Note that the swap operation makes too little progress (it advances an agent one step) to achieve
the O(n3 ) bound that was shown to be possible by Kornhauser (1984). In Section 6, we will investigate to what extent this higher number of moves in the worst case manifests itself in practice,
by comparing our algorithm to the Bibox algorithm (Surynek, 2009), which does achieve an O(n3 )
bound on the number of moves required (although Bibox only works on biconnected graphs).

5. Heuristics and Post-Processing
Push and Rotate does not guarantee an optimal solution, and we can try to improve solution quality
through heuristics, and by processing the initial solution. In Section 5.1, we will discuss a postprocessing step that detects unnecessary moves, but first we will discuss at which points in the Push
and Rotate algorithm a heuristic might be used that can affect the solution quality (in the order in
which they appear in the text):
1. From the push operation (Algorithm 4), the clear vertex operation (Algorithm 10) is
called, which must choose an empty node to move other agents into.
2. Similarly, the swap operation (Algorithm 5) must choose a vertex v of degree  3 at which to
perform the swap.
3. In Algorithm 8 (solve), the order in which agents are planned is decided in line 8.
4. Also in Algorithm 8, p is assigned a shortest path to its destination, in line 12; if there are
multiple shortest paths, then one must be chosen.
So far, we have only considered heuristics for the third and fourth points. With regard to the
first two points, if we consider empty vertices or possible swap locations in a specific order, then a
different plan can be found assuming that multiple nodes are viable. With regards to the third point,
the agent ordering can be very important to solution quality as we shall show in Section 6. Note that
the agent ordering is partially determined by Algorithm 3, which introduces precedence constraints
between subgraphs. Within a subgraph, a heuristic can be used to order the agents.
Our agent-priority heuristic aims to limit the number of swap operations that are required. The
heuristic first determines the diameter of the graph, and then chooses two vertices between which the
distance is exactly the diameter. We first move agents away from one of these vertices14 , ensuring
that all empty spaces are at this vertex and the vertices closest to it. Agents are ordered based on
14. The moves produced by this pre-processing are part of the solution.

471

fiD E W ILDE , T ER M ORS & W ITTEVEEN

the distance of their destination to this vertex, with the farthest agents receiving the highest priority.
The idea is that, when a subset of the agents has been moved to their destinations, empty spaces will
never get stuck behind these finished agents. Remember that the push operation is not allowed to
move agents with higher priority. So as long as empty spaces can be reached, the push operation
can be performed, which is much cheaper than the otherwise required swap operation.
For the fourth point, we have implemented a heuristic that finds a path with the minimum number of agents in F on it (if there exist multiple such paths, we select a shortest one). Again, we aim
to avoid the use of the costly swap operation.
5.1 Removing Redundant Moves
The Push and Rotate algorithm is capable of outputting redundant moves. An example is shown in
Figure 16: as part of the swap between agents a1 and a2 , agent a3 will be moved into its goal location
(in particular, the clear operation will move agent a3 into its goal location, see Figure 16(b)). Since
the moves that are generated by the clear operation will be executed in reverse after the exchange of
position between agents a1 and a2 , agent a3 will be moved back to its initial position (Figure 16(d)).
Finally, when agent a3 is planned it is moved into its goal location for the second time. Clearly, the
final two moves of the sequence are redundant.
a3

a3

a2


a1

a2

a3




a1

(a) initial state

a2

(b) a3 makes room for a2

a1

(c) a1 and a2 swap

a3

a3


a2

a1

a2

(d) a3 has been put back

a1

(e) a3 moves to its destination

Figure 16: Example of redundancy: after the swap of a1 and a2 , a3 will be moved back.
A sequence of agent moves is redundant if the agent visits a vertex for a second time, and
no agents have visited the vertex in the meantime. When redundant moves are removed from the
solution, other moves may become redundant too. The approach taken by Luna and Bekris (2011a)
is to keep iterating over all moves in the solution, until no more redundancies are discovered.
In order to remove redundancies efficiently, Algorithm 9 below uses a linked-list-like structure,
encoded in the following functions. The PA :    (previous-agent) and NA :    (next-agent)
functions are back and forward pointers respectively that form a doubly-linked chain of all the moves
of a specific agent. The PV :    (previous-vertex) and NV :    (next-vertex) functions are
similar pointers that form a chain of all the moves to a specific vertex.
Algorithm 9 starts with a single pass (lines 2 to 4) over all moves to find redundancies. All redundant moves are added to Q, and are processed in the while loop starting from line 5. First, in line 6,
472

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

Algorithm 9 smooth()
1: Q  empty queue
2: for all (a, v) =    do
3:
if agent(PV ()) = a then
4:
Q.add(PV ())
5: while |Q| > 0 do
6:
  retrieve and remove next element from Q
7:
0  NA ()
8:
while 0 6= NV () do
9:
  \0
10:
PA (NA (0 ))  PA (0 ), NA (PA (0 ))  NA (0 )
11:
PV (NV (0 ))  PV (0 ), NV (PV (0 ))  NV (0 )
12:
if agent(PV (0 )) = agent(NV (0 )) then
13:
Q.add(PV (0 ))
14:
0  NA (0 )
15: return 

a redundant move  = (ai , v) is retrieved from Q. As  is redundant, this means that agent ai s plan
contains a number of moves to other vertices before returning to vertex v  without other agents
having visited v in between. This means that from the sequence [, NA (), NA (NA ()),    , NV ()]
all moves except for the first can be removed; this is achieved in the while loop of line 8.
Within the while loop of line 8, first a redundant move is removed from the sequence of moves
(line 9), and then the pointers PA and NA , and PV and NV are updated in lines 10 and 11 respectively.
Finally, it is checked whether other moves have become redundant as a result of this removal, in
line 12. This check is done in constant time, and does not require looping over all moves again, as
in the algorithm by Luna and Bekris (2011a).
5.2 Executing Moves in Parallel
The makespan of a multi-agent plan is the difference in time between the moment all agents have
stopped moving and the moment the first agent started moving. Push and Rotates initial output is
a list of agent moves, with no specification of which agent moves can be performed at the same
time, so the makespan is initially equal to the number of moves. In this section, we briefly discuss
the condense function15 , which tries to reduce the makespan by executing as many agent moves in
parallel as possible.
We can distinguish three models with regard to the allowed degree of parallelism. The least
restrictive model allows an agent to move to a vertex from which another agent is just moving away.
This, however, is not the Multi-agent Pathfinding problem as defined in Section 2, as it allows agent
movement even if there are no empty vertices. The most restrictive model is that an agent is only
allowed to move to an empty vertex, and this means that in each time step, only m moves can be
performed in parallel, where m is the number of empty vertices. We currently employ the most
restrictive model.
15. We do not include an algorithmic description in this paper for condense. Although the algorithm is not very complicated, it is still somewhat lengthy to write down.

473

fiD E W ILDE , T ER M ORS & W ITTEVEEN

An intermediate model, also supported by our condense function, is that agents are allowed to
move to vertices that are being vacated, as long as at the head of a chain of moving agents, there is an
empty vertex. Note that this degree of parallelism does not conflict with the Multi-agent Pathfinding
problem: it is still possible to serialize the moves such that each agent always moves to an empty
vertex.
The idea behind the condense function is as follows: for every time step starting from the first,
it inspects all empty vertices, and places all moves going into an empty vertex into the same time
step. In case the intermediate model is employed, the empty-vertex variables are then updated to
the vertices that have just been vacated, and it is checked whether there are any agents moving into
these vertices. This process continues until no more moves into emptying vertices can be found.

6. Experiments
In this section we compare the performance of Push and Rotate with that of MAPP, Push and Swap,
and Bibox. We previously compared MAPP to Push and Rotate on a game map16 from Baldurs
Gate II (De Wilde et al., 2013), and we repeat that experiment here (on a different map). Our
experiments on game maps are very preliminary as they did not lend themselves to comparisons with
other algorithms: MAPP produces too many moves, Push and Swap requires a lot of computation
time, while Bibox cannot solve the instances that are not biconnected.
Push and Swap is conceptually similar to Push and Rotate, so we would expect its performance
to be similar also. In addition, apart from the game map, all our experiments were conducted on
biconnected instances (to allow a comparison with Bibox), so the fact that Push and Swap does not
take into account subgraphs does not affect its success ratio for those instances. However, it turned
out that the other source of incompleteness of Push and Swap, namely the fact that recursive calls
to swap may fail  which we solved with the introduction of the rotate operation  resulted in
Push and Swap solving only a fraction of all problem instances.
The main focus of our experiments is therefore on Bibox. Bibox is not complete, as it requires a
biconnected graph, but it performs well compared to other approaches (Surynek, 2009). Moreover,
it achieves a bound of O(n3 ) on the number of moves, which Kornhauser (1984) showed to be the
lowest worst-case bound achievable for general graphs. Push and Rotate, by contrast, has a bound
of O(kn3 ) on the number of moves, where k is the number of agents. We have compared to Bibox
on two types of instances: instances from a random generator that is part of the Bibox code, and
grid instances.
For most experiments, we have run Push and Rotate both with and without the agent-ordering
heuristics from Section 5. The effectiveness of the heuristic is shown by the fact that it is almost
always better, in terms of number of moves and therefore also in terms of CPU time, to use the
agent-ordering heuristic with Push and Rotate.
6.1 Map AR0603SR from Baldurs Gate II
The problem instances in the benchmark set are characterized by a large set of vertices, many of
which are unoccupied. The map we chose for these experiments has 13765 vertices, and between
100 and 2000 agents (step size 100).
16. A set of benchmark maps from the video game industry is available at http://movingai.com/benchmarks/.

474

fi
































































0












500

1000

MAPP
Push & Rotate
P&R noorder
PAS

200






400



























CPU time (s)

500000 1000000










800







600

MAPP
Push & Rotate
P&R noorder
PAS




0

number of moves

2000000



1000 1200 1400

C OOPERATIVE M ULTI - AGENT PATHFINDING

1500

2000













500

number of agents




























1000













1500
















2000

number of agents

(a) number of moves

(b) CPU times

Figure 17: Comparison on map AR0603SR of Push and Rotate, Push and Swap (PAS), Push and
Rotate without agent-ordering heuristic (P & R no-order) and MAPP.

Figure 17 shows the number of moves produced by Push and Rotate, MAPP, and Push and Swap
(no Bibox, as the map was not biconnected), and the CPU times. Both Push and Rotate and Push
and Swap produce very efficient plans (which are in fact always within a few percent of the lower
bound of the sum of the shortest paths), but MAPP requires many more moves to find a solution,
and therefore we did not try to include it in our further experiments. Note that for these instances, it
does not matter whether or not the agent-ordering heuristic is employed for Push and Rotate.
From Figure 17(b) it is interesting to note that Push and Swap is quite a bit slower for this type
of instance, while for the instances in the remainder of our experiments section (grids and other
biconnected instances) the C++ implementation of Push and Swap (when it did find a solution) was
often a little bit faster than our Java implementation of Push and Rotate.
6.2 Random Biconnected Instances
Suryneks code17 generates random instances by iteratively adding handles to an initial cycle (see
Section 2.1) according to three parameters: the number of handles, the size of the initial cycle, and
the maximum handle length (where the length of the next handle is uniformly chosen between 0
and the maximum handle length minus one, but set to 1 if it equals 0). In addition, one can choose
the number of empty vertices, with a default value of 2. In our experiments we measure the number
of moves, the CPU time, and the makespan, which is the number of time steps required to get all
agents to their destination (in one time step an agent can perform one move, though multiple agents
can move during one time step).
17. We used the code available at http://ktiml.mff.cuni.cz/surynek/research/icra2009/.

475

fi200

400

600

800

0

200



Bibox
Push & Rotate
P&R noorder
PAS

400

CPU time (s)

3e+06
2e+06
0e+00











































































































































































































































































































































































































































































































































0



600

Bibox
Push & Rotate
P&R noorder
PAS



1e+06

number of moves

4e+06



800

D E W ILDE , T ER M ORS & W ITTEVEEN

1000
































































































































































































































































































































































0

number of vertices

200

400

600

800



1000

number of vertices

(a) number of moves

(b) CPU time

Figure 18: Comparison on random instances with parameters (handles, initial cycle, max handle
length): (20, 20, 20) to (50, 50, 50), with 2 empty vertices.

Figure 18 compares Push and Rotate, Push and Swap and Bibox on instances generated according to a single variable x that ranged from 20 to 50, with steps of two, that was used for all three
parameters (number of handles, initial cycle size, and maximum handle length), while the number
of empty vertices was kept at two. Clearly the number of moves required for Push and Rotate rises
much more quickly with instance size, and consequently CPU times increase as well. The results
for Push and Rotate are slightly better in terms of makespan, but still much worse than Bibox. We
can also see from the figures that the agent-ordering heuristic is useful, but not essential for the
performance of Push and Rotate. Push and Swap only managed to solve 1.17% of these instances,
so it is not really usable on such hard instances; later we shall see that it performs better if there are
more empty vertices.
Bibox works exceptionally well for large handle sizes, which is unsurprising since the algorithm
is based on the concept of filling handles: Bibox inserts vertices into their destination handle in the
right order, so once at their destination, vertices are not moved much. Push and Rotate, on the other
hand, has to bring agents into place using push and swap; to swap two agents in the middle of a
handle, many agents have to be moved out of the way in order to bring them to a node at which they
can swap. P & Rs rotate operation is rarely used for this type of instance, as a path of resolving
agents rarely intersects itself.
Figure 19 shows experiments on random biconnected instances with 40 handles, initial cycle
size 5, maximum handle length 10, and an increasing number of empty vertices, ranging from 2 to
40 (step size 2), and 180 instances per step. On the hardest instances, with few empty vertices, Push
and Rotate still produces more costly plans, but with a higher number of empty vertices, Push and
Rotate produces much better plans. Such instances are easier for Push and Rotate, as first of all the
476

fiBibox
Push & Rotate
P&R noorder
PAS

12000
number of moves



















5000



10

20













30







Bibox
Push & Rotate
P&R noorder





40

2000 4000 6000 8000

15000



10000

number of moves

20000

C OOPERATIVE M ULTI - AGENT PATHFINDING









10

number of empty vertices











20











30











40

number of empty vertices

(a) average number of moves

(b) average makespan

Figure 19: Comparison on random instances with 40 handles, initial cycle 5, and maximum handle
size 10.

push operation will succeed more often, and if a swap is still necessary, it will be easier to clear a
node at which two agents can swap.
Bibox, on the other hand, requires exactly two empty vertices in its current implementation, and
fills up the remaining empty vertices with dummy agents. Even though the moves involving these
dummy agents are removed from the final solution, Bibox does not manage to benefit from more
empty vertices to the extent that Push and Rotate does. Bibox still produces solutions more quickly,
however, requiring a few tenths of a second for each instance; Push and Rotate requires around 6
seconds to solve the hardest instances, and around 1 second for the easiest ones. Figure 19 suggests
that Push and Swap also performs very well, although it should be noted that the success ratio for
Push and Swap is still only 53.9% for these experiments.
In terms of makespan (Figure 19(b)), the performance advantage of Push and Rotate over Bibox
is even greater18 . This is something we observed in all our experiments comparing Push and Rotate
with Bibox. The main reason seems to be that our condense is more powerful than its counterpart
in the Bibox algorithm. Table 1 shows the parallelism, which is the number of moves divided by the
makespan, for Push and Rotate, Bibox, and Bibox plus our smooth (removing redundant moves)
and condense functions (Bibox++). Without using our post-processing algorithms, Bibox has
very poor parallelism, but after applying smooth and condense it is more parallel than Push and
Rotate for the emptier instances. However, Bibox still has more moves, so the makespan of Push
and Rotate and Bibox++ was about equal on average.
18. The implementation we had of Push and Swap did not have any kind of condense feature, so its makespan would
simply be the number of moves, which we did not include in the figure.

477

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Empty
P&R
Bibox
Bibox++

2
1.42
1.03
1.22

6
1.86
1.07
1.49

10
2.10
1.10
1.69

14
2.25
1.12
1.88

18
2.35
1.15
2.05

22
2.42
1.18
2.25

26
2.48
1.20
2.44

30
2.54
1.23
2.64

34
2.57
1.26
2.83

38
2.63
1.29
3.07

42
2.67
1.33
3.29

46
2.71
1.36
3.5

50
2.74
1.39
3.69

Table 1: Parallelism of Push and Rotate, Bibox, and Bibox plus smooth and condense, on biconnected from Figure 19.

6.2.1 T HE I NITIAL C YCLE
The Bibox algorithm solves the handles of an instance by inserting agents into one endpoint of the
handle, and using the lower part of the graph (i.e., the initial cycle and the handles with a lower
number) to move agents and empty vertices around. For the initial cycle, a different procedure is
followed in which a swap-like operation is used to exchange the position of the agent at vertex i
with the agent whose destination is i.

20

40

60

80

5e+05
4e+05
3e+05

makespan

1e+05
0e+00

1500000
1000000

makespan

500000
0

Bibox
Push & Rotate
P&R noorder
Bibox++

2e+05





















































































































































































































































































































































































100








 



 



 



 

  














  






 











































































































































































20

number of vertices



Bibox
Push & Rotate
P&R noorder
Bibox++

40

60

80

100

number of vertices

(a) initial cycle: {4, . . . , 100}, max handle size: 4

(b) initial cycle: 4, max handle size: {4, . . . , 100}

Figure 20: Makespan comparison for instances with an initial cycle and one handle, and two empty
vertices.

Figure 20 shows, however, that this initial-cycle procedure is not as efficient as the processing
of the handles, or indeed as Push and Rotate19 . Figure 20(a) shows a comparison on instances
in which the length of the initial cycle varied from 4 to 100, with a single handle of maximum
size 4. Figure 20(b) shows experiments on similar types of graphs, but these with a small initial
cycle of 4 vertices, and a maximum handle length that varies from 4 to 100. The number of empty
vertices in both figures is two. In the first setting, Push and Rotate performs considerably better than
19. Due to a scripting error, the experiments with a handle size of more than 80 were only run for Bibox(++).

478

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

Bibox, while in the second setting the relative performances are similar to the other experiments with
random instances. For these experiments, removing redundant moves from the solution of Bibox
using our smooth algorithm removed only a small percentage of moves, while trying to reduce
makespan with condense did result in a significant reduction. However, even the condensed Bibox
output was far worse, for large initial cycles, than the plans produced by Push and Rotate.
It is interesting to note that Bibox produces in excess of n3 moves for instances with a large
initial cycle  it produces around two million moves at 100 vertices  yet CPU times are less than
a second for all instances. For Push and Rotate, by contrast, the CPU times grow with the number
of moves; around 5 seconds for 50 vertices, and up to 70 seconds for instances of 100 vertices.
6.3 Grid Instances

2000000

Bibox
Push & Rotate
P&R noorder

1000000

makespan

500000

1500000
 
      

0

500





1000




















0

0



1500000

Bibox
Push & Rotate
P&R noorder
PAS

2500000



500000

number of moves

3500000

For any problem instance, Bibox requires a specification of the handle decomposition of the graph.
For the grid instances we generated, we adopted the decomposition suggested by Surynek (2011):
the initial cycle consists of the four vertices in the top left corner of the grid, and handles are added
first to the right of the initial cycle, then below the initial cycle, and finally the remaining vertices
are added one by one, from top left to bottom right.

1500

2000

2500


  
    

0

number of vertices

500





1000









1500










2000







2500

number of vertices

(a) number of moves

(b) makespan

Figure 21: Comparison on grid instances with sizes from 4  4 to 50  50, with 2 empty vertices.
Figure 21 shows that for grid instances with only two empty vertices, the performance of Push
and Rotate relies heavily on the agent-ordering heuristic. With the heuristic enabled, Push and
Rotate performs consistently better than Bibox; without it, the performance is usually much worse.
For this set of experiments, Push and Swap solved only 31.9% of the instances, and very few beyond
grid sizes of 25  25.
We also conducted experiments with increasing numbers of empty vertices, on 24  24 grid
instances. These problems turn out to be relatively easy for Push and Rotate, but Bibox is unable to
leverage the increased freedom of movement, and produces quite costly plans. Figure 22(a) shows
479

fi














 



  





 

 
 
 
 
 
 
 
 


 


 
 





 
 
 
 
 
 

 


 
 
 
 

  

 
 

 
 
 


 
 
 

 
 


 
 

 


 

  



 
 
 


 
 
 
 







 


 



 

 
 




 
 

 
 

 
 

 


  
 

 
 


 
 
   

 
 
 
 


 
 
 

 
 
 


 

 
 
 


 






 



 
 
 
 
 
 
 

 

 

 
 




 

 
 



 

10

20

30

40

Bibox
Push & Rotate
P&R noorder

20000



















140000
makespan







100000

Bibox
Push & Rotate
P&R noorder
PAS

60000



150000
100000
50000

number of moves

200000

D E W ILDE , T ER M ORS & W ITTEVEEN

50

10

number of empty vertices

20

30

40

50

number of empty vertices

(a) number of moves

(b) makespan

Figure 22: Increasing number of empty vertices for 24  24 grid instances.

that for two empty vertices, Bibox produces around 10% more moves; for 40 empty vertices, it
requires around 35% more moves. In terms of makespan, the difference between the algorithms
is even larger: for two empty vertices, the span of the Push and Rotate solution is around 75% of
Biboxs solution, while for 40 empty vertices it is less than 25%. These instances proved just easy
enough for Push and Swap, and 98.1% of the instances were solved, with a performance comparable
to that of Push and Rotate without the agent-ordering heuristic.
Finally, in Figure 23 we present the CPU times for the algorithms on grid instances; Figure 23(a)
for the experiments of increasing grid sizes, and Figure 23(b) for the experiments with increasing
numbers of empty vertices. First, an interesting thing to note is that Push and Rotates good performance (heuristic enabled) on grids is also expressed in terms of lower CPU times, while Biboxs
times grow steadily with the number of moves. Second, the algorithms are not sensitive, in terms of
CPU times, to the number of empty vertices, even though all algorithms produce solutions containing fewer moves.
6.4 Experiment Conclusions
From the experiments in this section it is apparent that the performance of both algorithms depends
considerably on the type of problem instance. Bibox is well-suited to the type of random instances
generated by the Bibox program, while Push and Rotate performs really well on grid instances, as
long as the agent-ordering heuristic is employed. Although we havent been able to run Bibox on
any game maps from movingai.com, we suspect that Push and Rotate will perform better on these
instances: there are plenty of open spaces (essentially grids), and many free vertices, too, both of
which play to the strengths of Push and Rotate.
With regard to the other algorithms on comparison, Push and Swap performed reasonably well
when a plan was found, but for larger instances, especially with only a few empty vertices, a solution
480

fi

Bibox
Push & Rotate
P&R noorder
PAS













20

30








400

CPU time (s)

40









Bibox
Push & Rotate
P&R noorder
PAS

CPU time (s)



600

800

C OOPERATIVE M ULTI - AGENT PATHFINDING

200





10







 
 

 
  

 

 
 
 
 
 

 
 
 
 




 
 


 
 


 
 
 
 






 

 
 
 
 
 
 

  
 
 
 
 
  
 

 
      







0

0




0

500

1000

1500

2000

2500

10

number of vertices

(a) grid sizes from 4  4 to 50  50, 2 empty vertices

20

30

40

50

number of empty vertices

(b) 24  24 grids with increasing number of empty vertices

Figure 23: CPU times on grid experiments.

was rarely found, so it is not practically usable. Similarly, the solutions produced by MAPP contain
too many moves, and also it is only guaranteed to return a solution on instances of the S LIDABLE
class. Finally, Push and Rotate without the agent-ordering heuristic often performs well, but it is
never significantly better than employing the heuristic, and often significantly worse, so for the
instances weve seen there is no reason not to use it.
With regard to CPU times, if the problem domain suits the algorithm, CPU times are low and
do not grow at the same rate as the number of moves; otherwise, CPU times grow steadily with
the number of moves. An exception seems to be the performance of Bibox on random biconnected
instances with a small single handle and a large initial cycle: in a few tenths of a second, Bibox
manages to produce millions of moves. It should be noted, however, that Biboxs post-processing
algorithms are quite rudimentary and do not spend a lot of CPU time improving the solution. For
Push and Rotate, on the other hand, the post-processing algorithms are important to solution quality,
but they also make up about 1% to 5% of the total computation time.

7. Conclusions and Future Work
We have presented a complete and polynomial-time algorithm for the multi-agent pathfinding problem. Our approach is similar to that of Luna and Bekris (2011b); using simple the primitive operations push, swap, and, in our algorithm, rotate, an algorithm can be constructed that is both easy
to understand and performs competitively. Although our Push and Rotate does not achieve the (best
possible) worst-case bound of O(n3 ) moves (n the number of vertices in the graph), it produces
competitive solutions when compared to Bibox, which does achieve the O(n3 ) bound (Surynek,
2011), but is restricted to biconnected graphs.
481

fiD E W ILDE , T ER M ORS & W ITTEVEEN

We argue that Push and Rotate is currently the algorithm of choice for multi-agent pathfinding
problems. Bibox performs comparably well, but it is only applicable to biconnected graphs, and
moreover the algorithm is not yet very mature, for instance in the way it handles more than two
empty vertices, and its post-processing algorithms are comparatively basic. Finally, there is the
work by Kornhauser (1984), which demonstrated the O(n3 ) bound on the number of moves. Surynek
reports that his implementation of Kornhausers work performs considerably worse (in terms of the
number of moves) than his Bibox algorithm. Moreover, Kornhausers algorithm is very difficult to
understand and therefore to implement. A more accessible specification and implementation are
under construction (Roger & Helmert, 2012), and we are in contact with the authors to compare
their work with ours in due course.
A useful next step in multi-agent pathfinding would be to develop an algorithm that guarantees
an O(n3 ) bound, performs (at least) competitively with Bibox and Push and Rotate, and is easy
to understand and implement. Arguably, Push and Rotate ticks two of these boxes, so it would
make sense to try and adapt it to reach the O(n3 ) bound. This would probably entail replacing the
expensive swap operation, which can require O(n2 ) moves just to further one agent a single step,
and make more use of rotations, as already done by the Bibox algorithm and our rotate operation.

Acknowledgements
This research was sponsored by the SUPPORT project from the Dutch Ministry of Economic Affairs.

Appendix A. Algorithms
In this appendix we present the algorithms used but not defined in the main text.
A.1 Operation clear vertex
Algorithm 10 clear vertex(, G , A , v, U )
1: for all unoccupied vertex u  V do
2:
p  shortest path in G \U from u to v
3:
if p 6= then
4:
x0 
5:
for all vertices x on path p (in order) do
6:
if x0 6= then
7:
r  A 1 (x)
8:
move(, A , agent r to vertex x0 )
9:
x0  x
10:
return true
11: return false
Algorithm 10 is called from the push, multipush, and rotate operations, and, if successful,
clears a vertex v. Algorithm 10 iterates over all empty vertices u  G (line 1), and starts each
iteration by finding a shortest path, avoiding all blocked vertices U , from u to the vertex v that must
be cleared (line 2). If such a path is found (p 6=, line 3), then all agents on p are moved one step
482

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

towards u (the for-loop from line 5). Note that choosing the right u in line 1 can impact both the
running time of the clear vertex operation, as well as the total number of moves of the solution
produced by Push and Rotate.
A.2 Operation multipush
Algorithm 11 multipush(, G , A , r0 , s0 , v)
1: r  agent r0 or s0 closest to v
2: s  the other agent
3: p  shortest path in G from A (r) to v
4: if p = then
5:
return false
6: for all vertices x on path p do
7:
vr  A (r), vs  A (s)
8:
if vertex x is occupied then
9:
U  {vr , vs }
10:
if clear vertex(, G , A , x, U ) = false then
11:
return false
12:
move(, A , agent r to vertex x)
13:
move(, A , agent s to vertex vr )
14: return true
Operation multipush (Algorithm 11) is called from the swap operation, and moves two agents
r0 and s0 that are next to each other, to a node v (which is a node of degree three or more, at which r0
and s0 can be swapped). First, a shortest path is found in line 3, and then the algorithm proceeds to
move r and s forwards along this path one step at a time, calling clear vertex if the next vertex
on the path is non-empty.
A.3 Operation clear
The clear operation (Algorithm 12) is called from swap, and attempts to clear two neighbors of
a potential swap node. The algorithm works in four stages: in the first stage (Figure 24(a)) it simply
attempts to push agents, that are occupying neighbors of v, away from v. If there are two vertices
cleared in this stage, the operation is done. Otherwise, the other three stages need one unoccupied
vertex next to v to work. If there is no unoccupied vertex after stage one, the clear operation fails.
In the second stage (Figure 24(b)) a neighbor n is required that has a path to the already empty
neighbor  that does not go through v. The agent at n is first moved to , and if the clear vertex
operation subsequently succeeds on  (with n, v, and v0 blocked vertices), then clear succeeds.
The third stage (Figure 24(c)) checks whether an agent occupying a neighbor n of v may be able
to vacate n by moving through the vertex v0 that currently holds agent s. This is tried by moving
agent r into the empty vertex , and agent s into v.
The idea behind the final stage (Figure 24(d)) is that it may be possible to create additional space
behind the already empty vertex , similar to the second stage. In stage four, however, instead of
using a direct connection between n and , the agent at n tries to move to  through v, meaning that
r and s must move backwards to make room.
483

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Algorithm 12 clear(, G , A , r0 , s0 , v)
1: r  agent r0 or s0 on v ; s  agent r0 or s0 not on v ; v0  A (s)
2: E  {unoccupied n  neighbours(v)}
3: if |E |  2 then
4:
return true
5: for all n  neighbours(v)\(E  {v0 }) do
6:
if clear vertex(, G , A , n, E  {v, v0 }) = true then
7:
if |E |  1 then
8:
return true
9:
E  E  {n}
10: if |E | = 0 then
11:
return false
12:   the vertex in E
13: for all n  neighbours(v)\{v0 , } do
14:
0  [ ] ; A 0  A
15:
if clear vertex(0 , G , A 0 , n, {v, v0 }) = true then
16:
if clear vertex(0 , G , A 0 , , {v, v0 , n}) = true then
17:
A  A 0 ;    + 0
18:
return true
19:
break
20: for all n  neighbours(v)\{v0 , } do
21:
0  [ ] ; A 0  A
22:
move(0 , A 0 , agent r to vertex ) ; move(0 , A 0 , agent s to vertex v)
23:
if clear vertex(0 , G , A 0 , n, {v, }) = true then
24:
if clear vertex(0 , G , A 0 , v0 , {v, , n}) = true then
25:
A  A 0 ;    + 0
26:
return true
27:
break
28: if clear vertex(, G , A , v0 , {v}) = false then
29:
return false
30: move(, A, agent r to vertex v0 )
31: if clear vertex(, G , A , , {v, v0 , A (s)}) = false then
32:
return false
33: n  any vertex from neighbours(v)\{v0 , } , t  A 1 (n)
34: move(, A , agent t through vertex v to vertex )
35: move(, A , agent r to vertex v) ; move(, A , agent s to vertex v0 )
36: return clear vertex(, G , A , , {v, v0 , n})

484

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

n

v0
s

v
r

n



y
n

v0

x

(a) 1: push agents

s

v
r



y
v0

n
s

x

v

v0



r

(b) 2: move agent through (c) 3: agent s makes room
empty neighbor

s

v
r

n
x

(d) 4: agents r and s clear v

Figure 24: The four stages of the clear operation.

Note that the stages of clear omitted from the work of Luna and Bekris (2011b) are stages
24(b) and 24(c), so Luna and Bekris effectively considered the clear operation for trees.
A.4 Operation exchange
Algorithm 13 exchange(, G , A , r0 , s0 , v)
1: r  agent r0 or s0 on v
2: s  agent r0 or s0 not on v
3: (v1 , v2 )  two unoccupied neighbors of v
4: vs  A (s)
5: move(, A , agent r to vertex v1 )
6: move(, A , agent s through vertex v to vertex v2 )
7: move(, A , agent r through vertex v to vertex vs )
8: move(, A , agent s to v)
The exchange algorithm was illustrated in Figure 7 in Section 3.

Appendix B. Proofs
Lemma 1. Suppose push (Algorithm 4) is called in the context of Algorithm 7 for an agent r moving
to vertex v. If push does not succeed, then r and s = A 1 (v) are assigned to the same subgraph.
Proof. Note that, as push is called in the context of Algorithm 7, the problem instance is solvable,
and all agents with a higher priority than r have already been planned for.
To prove the lemma, we will prove the equivalent statement that if r and s are not assigned to
the same subgraph, then push will succeed.
Case 1: r is not assigned to any subgraph By definition, r and s are not assigned to the same
subgraph, and, by Proposition 3, this means that r cannot swap with any other agent. Note that, as a
result of not being assigned to any subgraph, agent r is trapped on an isthmus (see Figure 25 for
an illustration). All agents assigned to a subgraph have a higher priority than r, and are therefore in
F by the time the call push is made20 .
20. Note that Algorithm 8, and the operations that are called from it, make only a single call to push, in which the set of
blocked vertices U is equal to the set of locations that currently hold an agent in F .

485

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Subproblem Si




s

r

Subproblem S j
Figure 25: Agent r, trapped on the isthmus, can only move to A (s) using a push.

By way of contradiction, suppose that the instance is solvable yet push does not succeed. First,
suppose that s  F ; r cannot have the same goal location as s, so rs goal location must be behind
A (s). However, if it is possible for r to reach such a location, then it would be assigned to subgraph
fS (s), by Proposition 1, so a contradiction has been reached.
Next, suppose that s 6 F . Since r has a priority greater or equal to s, we can conclude that s is
also not assigned to any subgraph. If the instance is solvable yet push(r, s) does not succeed, then
there exists an empty vertex beyond s, but there is no path in G \ A (F ) that reaches it; i.e., the
path to the empty vertex is blocked by agents in F . However, if there would exist an assignment A 0
in which s would move out of the way for r, and all agents in F are returned to their goal location,
then s will have swapped with the empty vertex that is within or beyond a subgraph. Hence, s would
reach locations in which it would be assigned to the subgraph (S j in Figure 25), so a contradiction
has been reached.
Case 2: r is assigned to subgraph fS (r) Since fS (r) 6= fS (s), the blocking agent s can reach
(at most) a plank vertex of fS (r). Suppose that s is on the start of a plank of fS (r); then, due to
Algorithm 3, fS (r)  fS (s). Hence, it is not possible that s, or any agents in subgraphs behind it,
are in F . Therefore, push will succeed in case the instance is solvable.
In case s is not on the start of a plank of fS (r), then the goal location of r must be on a plank
of fS (r). Due to Kornhausers thesis (1984), we know that r can reach any vertex of fS (r) and its
planks (the 2-transitivity result). Since the agents cannot swap (Proposition 3), agent r can only
reach its goal by pushing agent s away, which is what push achieves without restrictions. Finally,
note that s 6 F ; if s were at its goal position, then the instance would not be solvable: r and s cannot
swap, so the goal location of r cannot be at or beyond T (s).
Proposition 3. For two agents r and s on adjacent vertices in G , the operation swap(, G , A , r, s)
will succeed if and only if r and s are assigned to the same subgraph Si .
Proof. First we show that if a swap between r and s succeeds then both agents are assigned to the
same subgraph: fS (r) = fS (s) 6= . After a successful swap, the only change in the assignment are
the positions of agents r and s. Now consider the assignment A and the assignment A 0 , which has
the positions of agents r and s swapped:


A (s) if a = r
0
A (a) = A (r) if a = s


A (a) otherwise
486

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

Hence, the subgraph of r prior to the swap must equal the subgraph of s after the swap. Furthermore,
we know from Proposition 1 that any agent is confined to at most a single subgraph, so fS (r) = fS (s).
To see that swap succeeding implies that fS (r) 6= , note that the swap has occurred at some
vertex v with degree  3. Vertex v is clearly part of some subgraph Si , and r and s have reached v
with two of vs neighbors empty, so r and s are assigned to Si :
1. In case r and s are on a plank: m0  1m0 < m, by choosing the right u (line 6 in Algorithm 2),
see Figure 7.
2. In case either r and s are on an inner vertex: such an agent is assigned to Si in line 12,
Algorithm 2.
Now we show  6= fS (r) = fS (s) implies that swap will succeed for agents r and s. When one
of the agents r and s occupies a vertex v with degree(v)  3 and two empty neighbor vertices, and
the other agent occupies a neighbor vertex of v, then the agents r and s can exchange positions by
moving into the empty vertices in one order, and exiting them in the other order (see Algorithm 13).
Hence, swap succeeds if and only if there exists a vertex v for which multipush and clear also
succeed.
This leaves us to prove that if r and s are assigned to the same subgraph, then such a v always
exists. The assignment criteria for agents to subgraphs guarantee that:
1. an agent is inside a biconnected component, or
2. an agent is less than m steps away from a vertex within fS (r), with degree  3.
In case both agents are inside a biconnected component, multipush succeeds trivially. In a biconnected component there are two paths between any pair of vertices, so it is always possible to bring
r and s to any vertex v with degree  3 in the biconnected component (note that the only blocked
vertices that multipush considers are A (r) and A (s), since moves that put other agents out of place
will be reversed later). Second, clear will always succeed for the same reason: there always exists
one v with degree  3 such that the (at least two) unoccupied vertices can both be reached from v
by at least two paths. Hence, there is at least one path from v to each of the empty vertices that is
not blocked by r and s, so two neighbors of v can be emptied (possibly with r and s momentarily
stepping aside as illustrated in Figures 24(c) and 24(d)).
In case the agents are not both inside a biconnected component, we must show that a vertex of
degree  3 can be reached, and also that clear will succeed.
In case exactly one agent (say r) is inside a biconnected component, but agent s is not, then
r already occupies a (join) vertex with degree  3. In case neither agent is inside a biconnected
component, then the agents are either between two vertices of degree  3, or they are not occupying
vertices that are assigned to the subgraph. Consider the two agents between two vertices with degree
 3. There are not more than m  2 vertices between these two vertices, two of which are occupied
by agents r and s. Suppose l1 and l2 steps are required to reach the vertices, and there are m1 and
m2 free vertices on the respective sides of the agents. This leads to:
l1 + l2  m  4
m1 + m2 = m
487

(1)
(2)

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Assume one of the vertices is unreachable:
l1 > m 1 = m  m 2

(3)

Then the other vertex is reachable:
l2  m  4  l1

(4)

l2 < m  4  (m  m2 )

(5)

l2 < m2  4

(6)

If the agents are outside the vertices assigned to the subgraph, then the assignment criteria of agents
to subgraphs state that it must be possible for any agent assigned to a subgraph to enter the subgraph
while one additional empty vertex remains in the subgraph.
m1 free vertices




s

r



v
m2 free vertices
Figure 26: Illustration of reachable free vertices.
Consider the amount of free vertices on both sides of the two agents (see Figure 26).
1. Having  1 free vertices on one side of the two agents and > 1 on the other side is sufficient
to make clearing two vertices easy.
2. In the case that all free vertices are on one side of the two agents, either the agents are not in
the same subgraph, or another vertex v00 with degree  3 is reachable in m  2 steps. Moving
the agents towards v00 will leave  2 free vertices behind v00 and  1 free vertex behind the
trailing agent. This means that the first case applies to vertex v00 .
3. Having exactly one free vertex on both sides of the agents implies that m = 2. This means that
each subgraph is either a single vertex, or a biconnected component of the graph, since no
two components are joined together in Algorithm 1. In the single vertex case, it is impossible
for both agents to belong to the same subgraph, as moving agent s into this single-vertex
subgraph will not leave sufficient free vertices reachable as is required in Algorithm 2.
When the agents belong to the same biconnected component, stage three of the clear operation applies: it is possible to push the agents towards one of the free vertices, such that
the trailing agent ends up on vertex v. This clears the path for an additional vertex next to v
to push towards the other free vertex through the original position of the trailing agent. This
clears vertices next to v.
488

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

Finally, to see that  6= fS (r), note that a swap requires r and s to be adjacent to a vertex v
of degree  3. Clearly, it is possible for both r and s to step off the vertex v and into one of the
unoccupied vertices, which are either in Si , or are part of other planks of Si . Hence, r and s are
confined to Si and its planks by Proposition 1.

References
Auletta, V., Monti, A., Parente, M., & Persiano, P. (1999). A linear-time algorithm for the feasibility
of pebble motion on trees. Algorithmica, 23(3), 223245.
Beaulieu, M., & Gamache, M. (2006). An enumeration algorithm for solving the fleet management
problem in underground mines. Computers & Operations Research, 33(6), 16061624.
Calinescu, G., Dumitrescu, A., & Pach, J. (2008). Reconfigurations in graphs and grids. SIAM
Journal on Discrete Mathematics, 22(1), 124138.
Culberson, J. (1999). Sokoban is PSPACE-complete. In Proceedings in Informatics, Vol. 4, pp.
6576. Citeseer.
De Wilde, B. (2012). Cooperative multi-agent path planning. Masters thesis, Delft University of
Technology.
De Wilde, B., Ter Mors, A. W., & Witteveen, C. (2013). Push and Rotate: Cooperative multi-agent
path planning. In Proceedings of the twelfth international conference on autonomous agents
and multiagent systems, AAMAS, pp. 8794, Saint Paul, Minnesota, USA.
Desaulniers, G., Langevin, A., Riopel, D., & Villeneuve, B. (2004). Dispatching and conflict-free
routing of automated guided vehicles: An exact approach. International Journal of Flexible
Manufacturing Systems, 15(4), 309331.
Erdmann, M., & Lozano-Perez, T. (1987). On multiple moving objects. Algorithmica, 2(1), 477
521.
Gawrilow, E., Kohler, E., Mohring, R. H., & Stenzel, B. (2007). Mathematics - Key Technology for
the Future, chap. Dynamic Routing of Automated Guided Vehicles in Real-time, pp. 165177.
Springer Berlin Heidelberg.
Goldreich, O. (1993). Finding the shortest move-sequence in the graph-generalized 15-puzzle is
NP-hard. Tech. rep. 792, Technion  Israel Institute of Technology. The work on this paper
was completed in July 1984.
Goraly, G., & Hassin, R. (2010). Multi-color pebble motion on graphs. Algorithmica, 58(3), 610
636.
Hearn, R. A., & Demaine, E. D. (2005). PSPACE-completeness of sliding-block puzzles and other
problems through the nondeterministic constraint logic model of computation. Theoretical
Computer Science, 343(12), 7296.
Hopcroft, J. E., & Tarjan, R. E. (1973). Algorithm 447: efficient algorithms for graph manipulation.
Communications of the ACM, 16(6), 372378.
Hopcroft, J. E., Schwartz, J. T., & Sharir, M. (1984). On the complexity of motion planning for
multiple independent objects; PSPACE-hardness of the warehousemans problem. The International Journal of Robotics Research, 3(4), 7688.
489

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Kavraki, L. E., Svestka, P., Latombe, J.-C., & Overmars, M. H. (1996). Probabilistic roadmaps for
path planning in high-dimensional configuration spaces. IEEE Transactions on Robotics and
Automation, 12(4), 566580.
Khorshid, M. M., Holte, R. C., & Sturtevant, N. (2011). A polynomial-time algorithm for nonoptimal multi-agent pathfinding. In Proceedings of the Fourth International Symposium on
Combinatorial Search, SoCS, pp. 7683.
Kornhauser, D., Miller, G., & Spirakis, P. (1984). Coordinating pebble motion on graphs, the diameter of permutation groups, and applications. In Proceedings of the 25th Annual Symposium
on Foundations of Computer Science, FOCS, pp. 241250.
Kornhauser, D. M. (1984). Coordinating pebble motion on graphs, the diameter of permutation
groups, and applications. Masters thesis, Massachusetts Institute of Technology.
LaValle, S. M., & Kuffner, J. J. (2001). Rapidly-exploring random trees: Progress and prospects.
In Donald, B. R., Lynch, K. M., & Rus, D. (Eds.), Algorithmic and Computational Robotics:
New Directions, pp. 293308. A K Peters, Wellesley, MA.
Lee, J. H., Lee, B. H., & Choi, M. H. (1998). A real-time traffic control scheme of multiple AGV
systems for collision-free minimum time motion: a routing table approach. IEEE Transactions
on Man and Cybernetics, Part A, 28(3), 347358.
Luna, R., & Bekris, K. E. (2011a). Efficient and complete centralized multi-robot path planning.
In Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems,
IROS, pp. 32683275, San Francisco, CA, USA. IEEE.
Luna, R., & Bekris, K. E. (2011b). Push and Swap: fast cooperative path-finding with completeness
guarantees. In Proceedings of the Twenty-Second international joint conference on Artificial
Intelligence  Volume One, IJCAI, pp. 294300. AAAI Press.
Narasimhan, R., Batta, R., & Karwan, H. (1999). Routing automated guided vehicles in the presence
of interruptions. International Journal of Production Research, 37(3), 653681.
Nieuwenhuisen, D., Kamphuis, A., & Overmars, M. (2007). High quality navigation in computer
games. Science of Computer Programming, 67(1), 91  104. Special Issue on Aspects of
Game Programming.
Papadimitriou, C., Raghavan, P., Sudan, M., & Tamaki, H. (1994). Motion planning on a graph. In
Proceedings of the 35th Annual Symposium on Foundations of Computer Science, FOCS, pp.
511 520.
Roger, G., & Helmert, M. (2012). Non-optimal multi-agent pathfinding is solved (since 1984). In
Proceedings of the Fifth Annual Symposium on Combinatorial Search, SoCS, pp. 173174.
AAAI Press.
Roszkowska, E., & Reveliotis, S. A. (2008). On the liveness of guidepath-based, zone-controlled
dynamically routed, closed traffic systems. IEEE Transactions on Automatic Control, 53(7),
16891695.
Ruml, W., Do, M. B., Zhou, R., & Fromherz, M. P. (2011). On-line planning and scheduling: An
application to controlling modular printers. Journal of Artificial Intelligence Research, 40,
415468.
490

fiC OOPERATIVE M ULTI - AGENT PATHFINDING

Sajid, Q., Luna, R., & Bekris, K. E. (2012). Multi-agent pathfinding with simultaneous execution
of single-agent primitives. In Proceedings of the Fifth Annual Symposium on Combinatorial
Search, SoSC, pp. 8896, Niagara Falls, Canada. AAAI.
Sharon, G., Stern, R., Felner, A., & Sturtevant, N. (2012). Meta-agent conflict-based search for
optimal multi-agent path finding. In Proceedings of the Fifth Annual Symposium on Combinatorial Search, SoSC, pp. 97104, Niagara Falls, Canada. AAAI.
Sharon, G., Stern, R., Goldenberg, M., & Felner, A. (2011). The increasing cost tree search for
optimal multi-agent pathfinding. In Proceedings of the Twenty-Second International Joint
Conference on Artificial Intelligence, IJCAI, pp. 662667.
Silver, D. (2005). Cooperative pathfinding. In Proceedings of the 1st Conference on Artificial
Intelligence and Interactive Digital Entertainment, AIIDE, pp. 117122.
Simeon, T., Leroy, S., & Laumond, J.-P. (2002). Path coordination for multiple mobile robots: a
resolution-complete algorithm. IEEE Transactions on Robots and Automation, 18(1), 4249.
Sislak, D., Pechoucek, M., Volf, P., Pavlcek, D., Samek, J., Mark, V., & Losiewicz, P. (2008).
AGENTFLY: Towards Multi-Agent Technology in Free Flight Air Traffic Control, chap. 7, pp.
7397. Birkhauser Verlag.
Standley, T. (2010). Finding optimal solutions to cooperative pathfinding problems. In Proceedings
of the Twenty-Fourth AAAI Conference on Artificial Intelligence, AAAI, pp. 173178.
Standley, T., & Korf, R. (2011). Complete algorithms for cooperative pathfinding problems. In
Proceedings of the Twenty-Second international joint conference on Artificial Intelligence 
Volume One, IJCAI, pp. 668673. AAAI Press.
Surynek, P. (2009). A novel approach to path planning for multiple robots in bi-connected graphs. In
Proceedings of the 2009 IEEE International Conference on Robotics and Automation, ICRA,
pp. 36133619, Kobe, Japan.
Surynek, P. (2011). Multi-Robot Systems, Trends and Development, chap. Multi-Robot Path Planning, pp. 267290. InTech - Open Access Publisher, Vienna, Austria.
Ter Mors, A. W., Witteveen, C., Zutt, J., & Kuipers, F. A. (2010). Context-aware route planning. In
Proceedings of the Eighth German Conference on Multi-Agent System Technologies, MATES,
Leipzig, Germany. Springer.
Ter Mors, A. W., Zutt, J., & Witteveen, C. (2007). Context-aware logistic routing and scheduling. In Proceedings of the Seventeenth International Conference on Automated Planning and
Scheduling, ICAPS, pp. 328335.
Trug, S., Hoffmann, J., & Nebel, B. (2004). Applying automatic planning systems to airport groundtraffic control  a feasibility study. In 27th Annual German Conference on AI, KI, pp. 183197.
Velagapudi, P., Sycara, K., & Scerri, P. (2010). Decentralized prioritized planning in large multirobot teams. In Proceedings of the 2010 IEEE/RSJ International Conference on Intelligent
Robots and Systems, IROS, pp. 46034609, Taipei, Taiwan.
Vis, I. F. A. (2006). Survey of research in the design and control of automated guided vehicle
systems. European Journal of Operational Research, 170(3), 677709.
491

fiD E W ILDE , T ER M ORS & W ITTEVEEN

Wang, K.-H. C., & Botea, A. (2008). Fast and memory-efficient multi-agent pathfinding. In Proceedings of the Eighteenth International Conference on Automated Planning and Scheduling,
ICAPS, pp. 380387.
Wang, K.-H. C., & Botea, A. (2011). MAPP: a scalable multi-agent path planning algorithm with
tractability and completeness guarantees. Journal of Artificial Intelligence Research, 42, 55
90.
Wilson, R. M. (1974). Graph puzzles, homotopy, and the alternating group. Journal of Combinatorial Theory, Series B, 16(1), 8696.
Wu, Z., & Grumbach, S. (2009). Feasibility of motion planning on directed graphs. In Theory and
Applications of Models of Computation, Vol. 5532 of Lecture Notes in Computer Science, pp.
430439. Springer.
Zutt, J., & Witteveen, C. (2004). Multi-agent transport planning. In Proceedings of the Sixteenth
Belgium-Netherlands Artificial Intelligence Conference, BNAIC, pp. 139146, Groningen.

492

fiJournal of Artificial Intelligence Research 51 (2014) 293-332

Submitted 01/14; published 10/14

Distributed Heuristic Forward Search
for Multi-agent Planning
Raz Nissim
Ronen Brafman

raznis@cs.bgu.ac.il
brafman@cs.bgu.ac.il

Ben-Gurion University of the Negev,
Beer Sheva, Israel

Abstract
This paper deals with the problem of classical planning for multiple cooperative agents
who have private information about their local state and capabilities they do not want
to reveal. Two main approaches have recently been proposed to solve this type of problem  one is based on reduction to distributed constraint satisfaction, and the other on
partial-order planning techniques. In classical single-agent planning, constraint-based and
partial-order planning techniques are currently dominated by heuristic forward search. The
question arises whether it is possible to formulate a distributed heuristic forward search
algorithm for privacy-preserving classical multi-agent planning. Our work provides a positive answer to this question in the form of a general approach to distributed state-space
search in which each agent performs only the part of the state expansion relevant to it. The
resulting algorithms are simple and efficient  outperforming previous algorithms by orders
of magnitude  while offering similar flexibility to that of forward-search algorithms for
single-agent planning. Furthermore, one particular variant of our general approach yields a
distributed version of the a* algorithm that is the first cost-optimal distributed algorithm
for privacy-preserving planning.

1. Introduction
Interest in multi-agent systems is constantly rising, and examples of virtual and real systems
abound, with virtual social communities providing many such instances. The ability to plan
for such systems and the ability of such systems to autonomously plan for themselves is
an important challenge for artificial intelligence, especially as the size of these systems can
be quite large. In this context, a fundamental question is how to perform planning for a
distributed multi-agent system efficiently, and in many cases, how to do it while preserving
privacy.
Distributed planning is interesting for a number of reasons. Scientifically and intellectually, it is interesting to seek distributed algorithms for fundamental computational tasks,
such as classical planning. Similarly, it is interesting (and likely very useful in the long
term) to seek distributed versions of fundamental tools in computer science, and search is
definitely such a tool. Moreover, there are pragmatic reasons for seeking distributed algorithms. As an example, imagine a setting in which different manufacturers or service
providers can publish their capabilities and then collaborate with each other to provide new
products or services that none of them can provide alone. Such providers will certainly
need to reveal some sort of public interface, describing what they can contribute, as well as
what they require from others. But most likely, they will not want to describe their inner
c
2014
AI Access Foundation. All rights reserved.

fiNissim & Brafman

workings: their internal state and how they can manipulate it (e.g., their current stock
levels, machinery, logistics capabilities, personnel, other commitments, etc.). This is usually confidential proprietary information that an agent would not want to reveal, although
clearly one must reason about it during the planing process.
In principle, the above problem can be addressed using a central trusted party running a suitable planning algorithm. However, such a trusted party may not exist in all
settings. Moreover, centralized planning puts the entire computational burden on a single
agent, rather than distributing it across the system. Thus, centralized algorithms are less
robust, they are prone to agent failures, and are sometimes less efficient. For these reasons,
distributed algorithms are often sought, and in our case in particular, distributed, privacypreserving algorithms. Indeed, this is the main motivation for the field of distributed algorithms, and in particular, the work on distributed constraint satisfaction problems (CSP)
(Conry, Kuwabara, Lesser, & Meyer, 1991; Yokoo, Durfee, Ishida, & Kuwabara, 1998;
Meisels, 2007).
Moreover, it is often the case that good distributed algorithms formulated for a cooperative team provide the foundation for algorithms and mechanisms for solving similar
problems for teams of self-interested agents. For example, the work on planning games
(Brafman, Domshlak, Engel, & Tennenholtz, 2009, 2010) suggests modified versions of an
earlier algorithm for cooperative multi-agent systems (Brafman & Domshlak, 2008), and
work on mechanism design for solving distributed CSPs by self-interested agents (Petcu,
Faltings, & Parkes, 2008) is based on earlier work in distributed CSPs for cooperative
teams (Petcu & Faltings, 2005). In fact, the work presented in this paper forms the basis
of work on mechanism design for privacy-preserving MA planning, where the agents are
self-interested (Nissim & Brafman, 2013).
Yet another motivation for developing distributed algorithms is provided by planning
domains in which search operators that correspond to actions are implemented using complex simulation software that is accessible only to the relevant agent, because that agent is
not interested in sharing it (due to privacy concerns or commercial interests) or because it
is not realistic to transfer, integrate, and appropriately execute such software as part of a
planning algorithm. As an example, consider planning by a group of robotic agents, each
with different capabilities. Each agent has a simulator that can compute the effect of its
actions, which the agents do not want to share with each other. Thus, the application of
each agents actions during search can only be done by the agents themselves.
There is a long tradition of work on multi-agent planning for cooperative and noncooperative agent teams involving centralized and distributed algorithms, often using involved models that model uncertainty, resources, and more (Conry et al., 1991; Ephrati
& Rosenschein, 1997; Hansen & Zilberstein, 2001; Bernstein, Givan, Immerman, & Zilberstein, 2002; Szer, Charpillet, & Zilberstein, 2005; Witwicki, Oliehoek, & Kaelbling, 2012),
and much work on how to coordinate the local plans of agents or to allow agents to plan
locally under certain constraints (Cox & Durfee, 2005; Steenhuisen, Witteveen, ter Mors, &
Valk, 2006; ter Mors, Valk, & Witteveen, 2004; ter Mors & Witteveen, 2005). Our work is
influenced and motivated by some of the results in that area, but takes as its starting point
a more basic model introduced by Brafman and Domshlak (BD) that offers what is possibly
the simplest model of MA planning  ma-strips (Brafman & Domshlak, 2008). ma-strips
minimally extends standard strips (or PDDL) models by specifying a set of agent ids, and
294

fiDistributed Heuristic Forward Search

associating each action in the domain with one of the agents. Thus, essentially, it partitions
the set of actions among the set of agents.
One motivation for exploring MA planning in this simple setting is the belief that simple
models make it easier to study fundamental ideas, and that techniques developed can often
be generalised to more complex settings. Another closely related reason for working on this
model is the recent influential trend in the field of planning, of solving richer, more complex
models by reduction to the simpler settings and, especially, by using classical planners. This
is expected, given that classical planners  like SAT solvers, which are widely used as black
boxes for solving various problems (Kautz & Selman, 1992; Clarke, Biere, Raimi, & Zhu,
2001)  have now reached a certain performance level, which makes them capable of (quickly)
solving large problems. These planners incorporate a wealth of ideas and techniques which
are usually difficult (and sometimes impossible) to export to non-classical models. The use
of classical planners has been shown to be efficient in many different settings of planning
under uncertainty  Stochastic Shortest Path (Yoon, Fern, & Givan, 2007), Conformant
Planning (Palacios & Geffner, 2009), Conformant Probabilistic Planning (Albore, Palacios,
& Geffner, 2010; Taig & Brafman, 2013) and Contingent Planning (Albore, Palacios, &
Geffner, 2009)  as well as other planning models such as Net-Benefit Planning (Keyder
& Geffner, 2009) and Generalized Planning (Srivastava, Immerman, Zilberstein, & Zhang,
2011).
Recently, a number of ma-strips planning algorithms that respect agent privacy and
utilize the inherent distributed structure of the system have emerged. The first of these is an
approach based on distributed CSP techniques and was introduced in BDs original work.1
BD formulate a CSP that is particularly suited for ma-strips problems and whose solution
is a plan. This algorithm can be transformed into a fully distributed algorithm simply by
using a distributed CSP solver. BDs work establishes an upper bound on the complexity
of solving an ma-strips problem which depends exponentially only on two parameters
quantifying the level of agents coupling in the system. Unfortunately, distributed CSP
solvers cannot handle even the smallest instances of MA planning problems. Consequently,
a dedicated algorithm, based on the ideas of BD, was developed (Nissim, Brafman, &
Domshlak, 2010). While performing well on some domains, this algorithm had trouble
scaling up to problems in which each agent had to execute more than a small number of
actions. (Indeed, BDs algorithm scales exponentially with the min-max number of actions
per agent in a solution plan.) Recently, a new, improved algorithm, based on partialorder planning, map-pop, was developed (Torreno, Onaindia, & Sapena, 2012). Yet, this
algorithm, too, leaves a serious gap between what we can solve using a distributed planner
and what can be solved using a centralized planner. Moreover, neither algorithm attempts
to generate a cost-optimal plan.
In classical single-agent planning, constraint-based and partial-order planning techniques
are currently dominated by heuristic forward search techniques2 . Thus, it is natural to
ask whether it is possible to formulate a distributed heuristic forward search algorithm for
privacy-preserving classical planning. This paper provides a positive answer to this question
1. The idea of using distributed CSP techniques for MA planning was first introduced by Conry et al. (1991).
2. Winners of the sequential satisficing (non-optimal) tracks of the last three International Planning Competitions were heuristic forward search planners. Such a planner was also the winner of the optimal track
in the previous IPC (2011).

295

fiNissim & Brafman

in the form of a general approach to distributed state-space search in which each agent
performs only the part of the state expansion relevant to it. The resulting algorithms are
very simple and very efficient  outperforming previous algorithms by orders of magnitude
 and offer similar flexibility to that of forward-search based algorithms for single-agent
planning. They respect the natural distributed structure of the system, and thus allow us
to formulate privacy-preserving versions.
One particular variant of our general approach yields a distributed version of the a*
algorithm, called mad-a*, which is the first distributed algorithm for privacy-preserving
cost-optimal planning in ma-strips. mad-a* solves a more difficult problem than centralized search since in the privacy-preserving setting, each agent has an abstracted (partial)
view of the problem. Yet, it is still able to solve problems efficiently, outperforming centralized a* in some cases. As we will show, the main reason for this is an interesting optimality
preserving pruning technique that is naturally built into our search approach. This insight
has led to a new pruning technique for centralized search that we shall describe later on.
The rest of this paper is organized as follows. We start by providing some background
and then describe the model we use. This is followed by a discussion of related work.
Section 4 describes our MA forward search algorithm, and Section 5 describes mad-a*,
a modified version which maintains cost-optimality. Then, we present the MA planning
framework used, ma-fd, and empirical results evaluating the effectiveness of our algorithms.
Section 8 discusses a pruning method built-in to our algorithms, and how it can be
applied in centralized search. Section 9 provides a discussion of the privacy properties of
our algorithms and some open research challenges, and is followed by a conclusion.

2. Background
We describe the ma-strips model for multi-agent planning, and then proceed to define
privacy-preserving planning in ma-strips.
2.1 MA-STRIPS
A ma-strips problem (Brafman & Domshlak, 2008) for a set of agents  = {i }ki=1 , is
given by a 4-tuple  = hP, {Ai }ki=1 , I, Gi, where P is a finite set of propositions, I  P
and G  P encode the initial state and goal, respectively, and for 1  i  k, Ai is the
set of actions agent i is capable of performing. Each action a = hpre(a), eff(a), cost(a)i is
given by its preconditions, effects and cost. A plan is a solution to  iff it is a solution to
the underlying strips problem obtained by ignoring the identities of the agent associated
with each action. Since each action is associated with an agent, a plan tells each agent
what to do and when to do it. In different planning contexts, one might seek special types
of solutions. For example, in the context of planning games (Brafman et al., 2009), stable
solutions (equilibria) are sought. Our focus is on cooperative multi-agent systems, seeking
either a standard solution or a cost-optimal one, which minimizes the sum of action costs
of the plan.
The partitioning of the actions to agents yields a natural distinction between private and
public propositions and actions. A private proposition of agent  is required and affected
only by the actions of . An action is private if all its preconditions and effects are private.
All other actions are classified as public. That is, s private actions affect and are affected
296

fiDistributed Heuristic Forward Search

only by s actions, while its public actions may require or affect the actions of other agents.
For ease of the presentation of our algorithms and their proofs, we assume that all actions
that achieve a goal condition are considered public. Our methods are easily modified to
remove this assumption.
To get a clearer picture of the ma-strips model, consider the well known Logistics
classical planning domain, in which packages should be moved from their initial to their
target locations using a given fleet of vehicles such as trucks, airplanes, etc. The packages can
be loaded onto and unloaded off the vehicles, and each vehicle can move between a certain
subset of locations. Propositions are associated with each package location, on the map or
in a vehicle, and with every vehicles location on the map. Possible actions are drive/fly,
load, and unload, each with its suitable parameters (e.g., drive(truck, origin, destination)
and load(package, truck, location)). A natural partitioning of this problem associates each
vehicle with an agent, assigning this agent all drive, load and unload actions in which it is
involved. ma-strips includes this action assignment as part of the problem description.
In the Logistics domain, since all vehicle locations are private propositions (affect and are
affected only by their respective agents move actions), all move actions are certainly private,
depending on and affecting only private location propositions. Package location propositions
can be either private or public, depending on whether they are required/affected by more
than one agent. For example, the proposition at(package,location) is private if location is
accessible only to one agent (e.g. inside the vehicle, or, can be reached only by a single
vehicle), and public otherwise. Therefore, load (respectively unload ) actions that require
(respectively affect) public package location propositions are considered public.
We note that while the notion of private/public is natural to the ma-strips encoding,
it can easily be applied in models having multi-valued variables. For example, in SAS+,
where each variable may have multiple values, the analogue of a (boolean) proposition in
ma-strips is a hvariable, valuei pair. Such a pair is considered private if it is required,
achieved or destroyed only by the actions of a single agent. Consequently, actions which
require, achieve or destroy only private hvariable, valuei pairs are considered private. For
clarity and consistency with previous work we use ma-strips notation when discussing
the theoretical aspects of our work. However, the examples given, as well the practical
framework we present for MA planning, use the more concise multi-valued variables SAS+
encoding.
2.2 Privacy Preserving Planning
Given the notion of private/public propositions and actions, we can now formalize the
problem that is the focus of our work  Privacy-preserving MA-STRIPS planning. Privacypreserving ma-strips planning seeks to find a solution to a ma-strips planning problem
without exposing information that is private to an agent. Specifically: its set of private
variables and their possible values, its set of private actions and their cost, and the private
preconditions and effects of its public actions. Public actions and variables can be considered
as the exposed interfaces of an agent, while private actions and variables correspond to
the agents local state and the actions that manipulate its local state.
More formally, in a privacy-preserving ma-strips planning problem, each agent has
access to a description of its own actions and to a public projection of the public actions of
297

fiNissim & Brafman

other agents. The public projection of an action consists of the lists of public preconditions
and public effects. In a weak privacy preserving planning algorithm an agent need not
communicate a description of any of its private variables, private actions and their cost, and
the private preconditions and effects of public actions, to another agent. In a strong privacy
preserving algorithm, no agent can deduce an isomorphic model (i.e., the same model, up
to renaming) of a private variable, a private action and its cost, or the private preconditions
and effects of a public action that cannot be deduced from the initial information available to
that agent and the public parts of the plan. We will present a distributed search approach
that lies somewhere in-between weak and strong privacy preserving. We will discuss its
privacy properties in Section 9.1. At this stage, let us illustrate the meaning and need for
such privacy properties.
Consider the classical Logistics domain. Agent  knows about the existence and value of
its (private) location propositions, the locations of public packages and of packages that are
private to it (only it can load and unload them). Thus, the initial state known to  will not
contain the initial locations of other vehicles, nor package locations reachable only by a single
agent that is different from . The agent has full knowledge of its actions, but has access
to projections of other agents public actions only. For example, another agents action
a =unload(package, truck, location) has preconditions at(package, in-truck) and at(truck,
location) and effects at(package, in-truck) and at(package, location). However, since only
at(package, location) is a public proposition (assuming that location is reachable by more
than one agent), the projection of a known to  contains no preconditions and only that
single effect. The implication of preserving strong privacy in this example is that agents do
not know of packages that are handled by a single agent only (private to it). They do not
know the locations served by an agent, nor its actual location in different stages of the plan,
or how it changes its location. In fact, they are unaware of the existence of a location of
an agent, as this is a private variable.
In real life, some of this may seem absurd, as we all know that trucks and planes have
a location and can move among locations. Privacy guarantees do not take into account
general knowledge we have about how things work. However, even in this example, it is
appealing that agents do not know about the set of locations an agent serves, how it moves
between them, and at what cost. Nor do they know about packages that are handled only
by this agent. We believe that the ability to provide privacy at this or a similar level is a
clear advantage for a planning algorithm, facilitating the ability to construct ad-hoc teams
of cooperating, but privacy seeking agents.
Many service-oriented domains have similar abstract structure, where one agent does
some work towards a goal (getting the package to its destination) that requires the collaboration of multiple agents (e.g. truck in one country, plane, truck in another country).
As an example, imagine multiple part-manufacturers, together with an aggregator, that
can build a complex object together that none can build on their own, e.g., a laptop.
This would require monitors, various cards (graphic card, mother board, wifi), casing, etc.
Each of these components, in turn, requires diverse electronic parts, wiring, empty boards,
etc. The mother board manufacturers interface to the external world consists of the action of selling a mother board, and actions for purchasing relevant components  these
are its public actions. The public action sell-mother-board may have preconditions such
as stock > 0, have-payment, have-address and an effect such as stock=stock-1, has-mother298

fiDistributed Heuristic Forward Search

board(customer), where stock variables are private and other variables are public. It would
also have a private action such as produce-mother-board which will have various technical
preconditions related to availability of parts, workers, machinery. Alternatively, perhaps
producing the board requires multiple steps, possibly using different machines and different
workers. These will be reflected by its set of private actions. Its public variables will refer
to mother board orders, availability, and payments received. Its internal variable will refer
to where it produces, who are its workers and what roles they can take, where it stores its
inventory, and what are its stock levels at each facility. Its private actions will describe how
shipping from warehouse to plant is done, the actions used to actually construct the board,
who does what, and much more. A privacy preserving algorithm will neither expose, nor
require the knowledge of these inner workings, which are typically considered proprietary
information that manufacturers would not share, even with collaborators, unless required.
In Section 1 we discussed an example application of planning by a team of robotic
agents, which have complex simulators that generate the outcome of their actions. Fitting
this scenario into the ma-strips model, the public variables of an agent could describe
elements of the environment affected by an agent, and visible aspects of the robot (e.g.,
where it is, whether it is standing up or on the ground), whereas the local variables would
refer to its local state: the actual state of various motors, its charge level, perhaps various
local variables describing its current mode of operation. Public actions would be actions that
influence the environment and the observable state of the robot: moving, lifting, climbing a
ladder, collecting a rock. Local actions would involve local computations that manipulate
its internal, private state, such as charging. Note that public actions will influence many
private variables: moving an arm or climbing a ladder would change the internal state
of many variables and internal mechanical parts. Privacy preservation here serves two
purposes: not requiring one robot to understand and model the intricacies of another robot,
and not requiring one robot to disclose this information to other robots, both simplifying
the interaction between the robots, and maintaining confidentiality of, possibly proprietary
information. Thus, one robot can have public (and thus) abstract description of a move
action of anther robot, whose public effect is that the position of the robot changes. Yet, it
need not model, nor know about, the inner working involved in this move (or lift, or carry,
etc.) action. Most likely, the state of internal parts/motors/joints has to change in various
ways to accomplish this move action. Indeed, if ad-hoc robot teams will be as ubiquitous as
ad-hoc networks, this ability to work together without the burden and the exposure entailed
by sharing full models could be crucial.

3. Related Work
Our work focuses on the classical (deterministic) MA planning setting, in which agents
collaborate on a specific task, but prefer not to reveal private information about their local
states, their private actions, and the cost of these private actions. This preservation of agent
privacy is the main difference between our methods (and distributed planning in general)
and other approaches such as factored planning and parallel planning. Below we discuss
both related work on multi-agent systems and related work on privacy.
299

fiNissim & Brafman

3.1 Multi-agent Planning
Factored planning methods (Amir & Engelhardt, 2003; Brafman & Domshlak, 2006; Fabre
& Jezequel, 2009; Fabre, Jezequel, Haslum, & Thiebaux, 2010) seek to utilize the structure
of the planning problem, making centralized search more efficient. These methods can
exploit the MA structure of ma-strips problems (as is done by Brafman and Domshlak,
2008), but are not applicable for privacy-preserving settings, as they do not respect the
distributed form of the problem, giving a centralized entity access to the entire problem
description.
Parallel planning methods (Vrakas, Refanidis, & Vlahavas, 2001; Kishimoto, Fukunaga,
& Botea, 2009; Burns, Lemons, Ruml, & Zhou, 2010) aim to speed-up the solution of
centralized planning problems given access to a distributed computing environment, such
as a large cluster. Parallel planning can be performed in ma-strips by applying existing
approaches to the underlying strips problem (i.e., ignoring agent identities). While these
methods distribute the computation required for solving the planning problem, they ignore
privacy concerns, giving all agents (essentially processors) access to the entire planning
problem.
Given the privacy-preserving ma-strips model, it is natural to ask how to search for
a solution. A well-known example of privacy-preserving search is that of distributed CSPs
(Conry et al., 1991; Yokoo et al., 1998), for which various search techniques and heuristics
have been developed (Meisels, 2007). Distributed CSPs, where agents cooperate to find
a feasible assignment to constrained variables while keeping private internal constraints,
model a problem very similar to distributed ma-strips. In fact, planning problems can be
cast as CSP problems (given some bound on the number of actions), and the first attempt
to solve privacy-preserving ma-strips problems was based on a reduction to distributed
CSPs. More specifically, Brafman and Domshlak introduced the Planning as CSP+Planning
methodology for planning by a system of cooperative agents with private information. This
approach separates the public aspect of the problem, which involves finding public action
sequences that satisfy a certain distributed CSP, from the private aspect, which ensures
that each agent can actually execute these public actions in a sequence. Solutions found are
locally optimal, in the sense that they minimize , the maximal number of public actions
performed by an agent. This methodology was later extended to the first fully distributed
MA algorithm for ma-strips planning, Planning-First (Nissim et al., 2010). Planning First
was shown to be efficient in solving problems where the agents are very loosely coupled, and
where  is very low. However, it does not scale up as  rises, mostly due to the large search
space of the distributed CSP. Recently, a distributed planner based on partial order planning
was introduced (Torreno et al., 2012), which outperforms Planning First, effectively solving
more tightly coupled problems. Both methods are privacy preserving, but do not guarantee
cost-optimal solutions.
Our work attempts to solve privacy-preserving ma-strips using distributed heuristic
forward search algorithms. Heuristic forward search methods are widely used, and have
been applied in similar settings. Ephrati and Rosenschein (1994, 1997) showed that given
an a priori breakdown of the global goal into agent assigned subgoals, agents can plan
towards their subgoals, and then merge their possibly conflicting plans. This approach
essentially searches in plan-space, using heuristic estimates of states (which are the results
300

fiDistributed Heuristic Forward Search

of merged feasible subplans) in order to guide search. This approach does not guarantee
optimal solutions, relies on solving an exponential number of plan merging problems and
does not scale even in loosely-coupled problems (Cox & Durfee, 2009). As will be made
clear in the next section, our approach is a simple, general framework for forward search
in state-space, which easily specializes to a distributed version of the cost-optimal search
algorithm a*, and does not depend on complex plan merging algorithms.
In the setting of planning under uncertainty for distributed agents, forward search has
been shown to be effective. Szer, Charpillet and Zilberstein (2005) used a heuristic bestfirst approach in order to optimally solve Decentralized POMDPs. This approach performs
centralized forward search in the space of agents policy vectors. In order to compute
heuristic estimate for a single node, the solution of the underlying centralized MDP must
be computed for all possible states of the system. Both the search algorithm itself (which
is centralized) and the heuristic computation require full knowledge of the system and
therefore are not applicable in the privacy-preserving setting.
Another notable strategy for solving decentralized POMDPs was proposed by Nair et
al. (2003). JESP (Joint Equilibrium Based Search for Policies) computes a locally optimal
solution by iteratively modifying the policy of each agent to improve the joint (global)
policy. This algorithm is proved to converge to a Nash equilibrium. Subsequent work
(Ranjit, Varakantham, Tambe, & Yokoo, 2005) aims to exploit local interactions of the
agents, by applying distributed CSP techniques. Locality is exploited by computing the
agents best response only with respect to its neighbors, or the agents which are affected
by it, which improves JESPs efficiency. Similarly to Planning as CSP+Planning, these
methods generate locally optimal solutions and do not guarantee globally optimal solutions.
Additionally, the CSP-based methods suffer from exactly the same scalability drawback as
Planning-First, and will not be efficient as agent interaction rises.
Recently, in parallel with our own work, heuristic forward search for MA planning
under uncertainty was combined with influence-based abstraction (Witwicki & Durfee, 2010;
Oliehoek, Witwicki, & Kaelbling, 2012), producing a forward search algorithm for searching
the influence-space (Witwicki et al., 2012). Influence-based abstraction reformulates the
joint-policy search space into the space of influences, which represent the effect that agent
policies have on one another. The notion of influences relates closely to that of private/
public actions  the influences can be equated to public actions, and the intricate policies
on which the influences depend can be equated to private actions. The aforementioned
work shows that heuristic search in influence space can lead to significant improvement in
performance, which is mostly due to the pruning of the search space (we arrive at a similar
conclusion with respect to our work  this is discussed in Section 8). While the work on
heuristic search in influence space is similar to our work, there are two main differences
which sets them apart. First, the methods described apply only to transition-decoupled
POMDP models, which restrict the number of agents affecting a variable to at most one,
whereas ma-strips has no limit on the number of agents affecting each variable. Second,
the methods are not aimed at preserving privacy or at distributing search, but only at
making centralized search more efficient.
Overall, the motivation of most existing work in MA planning under uncertainty resembles that of Factored Planning  utilizing the (MA) structure in order to centrally solve
the problem more efficiently. Most of the research tackles problems which stem from the
301

fiNissim & Brafman

models characteristics (e.g. MDPs stochastic actions, POMDPs partial observability etc.).
Therefore, the product of this body of research is usually specialized methods which do not
provide a general solution schema applicable in other domains, despite solving more general (and complex) models. While these are important models representing problems which
are harder to solve than classical planning  DEC-POMDPs have been shown to be NEXPcomplete in the general case (Bernstein et al., 2002), we believe the field of MA planning will
benefit from general solutions for its simplest fundamental model of classical planning,
and this is what is presented in this work.
3.2 Privacy
Privacy is a wide topic of research with many technological, social, and legal aspects. Our
interest lies in the much more well defined area of secure multi-party computation (Yao,
1982, 1986), a subfield of Cryptography. The goal of methods developed for secure multiparty computation is to enable multiple agents to compute a function over their inputs,
while keeping these inputs private. More specifically, agents 1 , . . . , n , having private data
x1 , . . . , xn , would like to jointly compute some function f (x1 , . . . , xn ), without revealing any
of their private information, other than what can be reasonably deduced from the value of
f (x1 , . . . , xn ).
Formal results in this area provide protocols for computing various functions that are
guaranteed to be private under various assumptions, that is, in which no information about
the inputs to the functions is obtained beyond that which can be deduced from the output.
These assumptions cover three key aspects of the problem. The first aspect is the model
of the adversary  the party seeking to violate privacy. For example, a relatively simple
assumption is one of honest but curious, that is each of the agents follows the protocol
as laid out, but it is also curious and will try to deduce information about other agents
from the information that it obtains during the execution of the protocol. Malicious agents,
on the other hand, may deviate from the protocol in order to gain additional information.
Furthermore, agents may collude, and so various results will place a cap on the number of
malicious or colluding agents. Other aspects of an adversary could be its computational
power and memory. The second aspect is the network model. Is communication synchronous
or asynchronous? Are the channels secure? Can information get lost in the channel?
Finally, the third aspect is the meaning of secure. This actually has two sub-aspects
to it. First, what information exactly is being kept private. Second, how strong are the
security guarantees. Here, much like in cryptography, one makes various assumptions under
which the protocol is secure, e.g., factoring is hard.
Privacy-preserving ma-strips planning is clearly an instance of a secure multi-party
computation problem. The input to the function is the agents sets of actions, the initial
state, and the goal state, and the output is a plan. Our privacy requirements are a bit
weaker than in the standard model, as some of the inputs are public (i.e., public aspects
of public actions). On the other hand, some of the output is actually private: the private
actions of each agents in the plan. The most natural adversary model is one of honest-butcurious, although this requirement is not dictated by the problem definition, and diverse
adversary models can be considered.
302

fiDistributed Heuristic Forward Search

While in principle, it appears that techniques developed in the area of secure multiparty computation can be extended to our setting of distributed planning, their complexity
quickly becomes unmanageable. For example, a common approach for secure multi-party
computation uses cryptographic circuits. When solving the shortest path problem (e.g.,
network routing, Gupta et al., 2012), the size of the circuits created is polynomial in the
size of the graph. In our setting the function f computes a shortest path in the implicit
graph induced by the descriptions of the agents actions. As this graph is exponential in
the problem description size, it quickly becomes infeasible to construct these circuits given
time and memory limitations. While it is true that planning is NP-hard and forward search
algorithms do, in general, require exponential time/memory, the purpose of heuristic search
is to reduce the search space and to solve large problems in low-polynomial time. Requiring
the construction of exponential-sized circuits a-priori contradicts the goal of efficiency and
feasibility.
The computational problem that most closely resembles privacy-preserving ma-strips
planning is privacy preserving constraint satisfaction, which is the subject of the whole subfield of distributed CSPs, mentioned earlier. In DisCSP, each agent has a single variable,
and there exist both binary and unary constraints. Binary constraints are public since more
than one agent knows of their existence, while unary constraints are considered private
information. In meeting scheduling, an agent has a single variable whose values are possible
meeting time slots. A binary constraint could be an equality constraint between the values of
two variables belonging to different agents, while a unary constraint represents slots in which
the agent cannot hold meetings. Early work on distributed CSP did not explicitly consider
privacy issues, except for the type of weak privacy mentioned earlier. Thus, agents were
expected to solve the underlying CSP without explicitly revealing their unary constraints.
Later on, work on distributed CSPs (Yokoo, Suzuki, & Hirayama, 2002; Silaghi & Mitra,
2004) identified the fact that even if the algorithm is weakly private, private information
may leak during the search process. For example, during search, whenever an agent sends
some assignment of its variable to other agents, they can deduce that that value has no
unary constraint forbidding it. If this value does not end up being assigned in the solution,
the agent revealed some private information that could not have been deduced from only
viewing the solution. Thus, followup work focused on the question of how to measure
this privacy loss (Franzin, Rossi, Freuder, & Wallace, 2004; Maheswaran, Pearce, Bowring,
Varakantham, & Tambe, 2006), analyzing how much information specific algorithms lose
(Greenstadt, Pearce, & Tambe, 2006), and on the question of how to alter existing DisCSP
algorithms to handle stricter privacy demands (Greenstadt, Grosz, & Smith, 2007; Leaute
& Faltings, 2009). Very recently, work that provides formal guarantees for some DisCSP
algorithms has emerged (Leaute & Faltings, 2009; Grinshpoun & Tassa, 2014). This work
builds on techniques from the area of secure multi-party computation.

4. Multi-agent Forward Search
This section describes our distributed variant of forward best-first search, which we call
mafs. We begin with the algorithm itself, including an overview and pseudo-code. Then,
we provide an example of the flow of mafs, and a discussion of its finer points.
303

fiNissim & Brafman

4.1 The MAFS Algorithm
Algorithms 1-3 depict the mafs algorithm for agent i . In mafs, a separate search space is
maintained by each agent. Each agent maintains an open list of states that are candidates
for expansion and a closed list of already expanded states. It expands the state with the
minimal f value in its open list, which is initialized with the agents projected view of the
initial state. When an agent expands state s, it uses its own operators only. This means
two agents (that have different operators) expanding the same state, will generate different
successor states.
Since no agent expands all relevant search nodes, messages must be sent between agents,
informing one agent of open search nodes relevant to it expanded by another agent. Agent
i characterizes state s as relevant to agent j if j has a public operator whose public
preconditions (the preconditions i is aware of) hold in s, and the creating action of s is
public. In that case, Agent i will send s to Agent j .
Algorithm 1 mafs for agent i
1: while TRUE do
2:
for all messages m in message queue do
3:
process-message(m)
4:
s  extract-min(open list)
5:
expand(s)

Algorithm 2 process-message(m = hs, gj (s), hj (s)i)
if s is not in open or closed list or gi (s) > gj (s) then
add s to open list and calculate hi (s)
3:
gi (s)  gj (s)
4:
hi (s)  max(hi (s), hj (s))
1:

2:

The messages sent between agents contain the full state s, i.e. including both public and
private variable values (we later discuss how these can be encrypted), as well as the cost
of the best plan from the initial state to s found so far, and the sending agents heuristic
estimate of s. When agent  receives a state via a message, it checks whether this state
exists in its open or closed lists. If it does not appear in these lists, it is inserted into the
open list. If a copy of this state with higher g value exists, its g value is updated, and if it
is in the closed list, it is reopened. Otherwise, it is discarded. Whenever a received state is
(re)inserted into the open list, the agent computes its local h value for this state, and then
can choose between/combine the value it has calculated and the h value in the received
message. If both heuristics are known to be admissible, for example, the agent could choose
the maximal of the two estimates, as is done in Line 4 of Algorithm 2. Otherwise, an agent
is free to combine the estimates however it sees fit, depending on the known characteristics
of the heuristics. How the agent does this does not affect the correctness of the algorithm,
but could affect search efficiency. The issue of combining heuristic estimates is discussed
further in Section 9.1.
304

fiDistributed Heuristic Forward Search

Algorithm 3 expand(s)
1: move s to closed list
2: if s is a goal state then
3:
broadcast s to all agents
4:
if s has been broadcasted by all agents then
5:
return s as the solution
6: for all agents j   do
7:
if the last action leading to s was public and j has a public action for which all
public preconditions hold in s then
8:
send s to j
9: apply i s successor operator to s
10: for all successors s0 do
11:
update gi (s0 ) and calculate hi (s0 )
12:
if s0 is not in closed list or fi (s0 ) is now smaller than it was when s0 was moved to
closed list then
13:
move s0 to open list

Once an agent expands a solution state s, it sends s to all agents and awaits their
confirmation, which is sent whenever they expand, and then broadcast state s (Line 3
of Algorithm 3). For simplicity, and in order to avoid deadlocks, once an agent either
broadcasts or confirms a solution, it is not allowed to generate new solutions. If a solution
is found by more than one agent, the one with lower cost is chosen, and ties are broken
by choosing the solution of the agent having the lower ID. When the solution is confirmed
(broadcasted) by all agents (Line 4 of Algorithm 3), the agent returns the solution and
initiates the trace-back of the solution plan. This is also a distributed process, which
involves all agents that perform some action in the optimal plan. The initiating agent
begins the trace-back, and when arriving at a state received via a message, it sends a
trace-back message to the sending agent. This continues until arriving at the initial state.
When the trace-back phase is done, a terminating message is broadcasted and the solution
is outputted.
As we will see, this general and simple scheme  apply your own actions/operators
only and send relevant generated nodes to other agents  can be used to distribute other
search algorithms. However, there are various subtle points pertaining to message sending
and termination that influence the correctness and efficiency of the distributed algorithm,
which we discuss later.
To better demonstrate the flow of the algorithm, consider the example given in Figure
4.1. In this example, we have two agents who must cooperate in order to achieve a goal. The
agents actions are described on the left-hand side, where every node in the graph depicts
an action, and an edge (u, v) indicates that u either achieves or destroys a precondition of
v. There are two public actions a5 , a8 , which affect/depend on the only public variable, v4 ,
while the rest of the actions are private. The central part of the figure depicts the joint
search space, i.e., the nodes generated by centralized search. The right-hand site depicts
the local search space of the agents, i.e., the nodes generated and sent by each agent when
running mafs. In the initial state, all variable values are zero (i.e., I = 0000), and the goal
305

fiNissim & Brafman

Figure 1: Description of the actions of an example planning problem, its reachable search
space, and the search space generated by mafs. Actions are represented as <
pre, eff > and states are denoted by the values of variables v1 , v2 , v3 , v4 respectively
(For example, 1122 denotes the state where v1 = 1, v2 = 1, v3 = 2, v4 = 2.).

is G = {v4 = 2}. The values of private variables not belonging to the agents (v3 for agent
1, v1 , v2 for agent 2) are shown in bold. These values are not required to be known by the
agents, and they can in fact be regarded as dont cares, to be used only as identifiers. When
the agents begin searching using MAFS, each applies its own actions only. Therefore, agent
2 quickly exhausts its search space, since as far as it is concerned, state 0020 is a dead end.
Agent 1 generates its search space, until it applies public action a5 , which results in state
s = 2201. s is then sent to agent 2, since all the public preconditions of a8 hold in s (Line
7 of Algorithm 3). Upon receiving s, agent 2 continues applying its actions, eventually
reaching the goal state, which is then broadcasted.
4.2 Discussion
We now discuss some of the more subtle points of mafs.
4.2.1 Preserving Agent Privacy
If our goal is to preserve privacy, it may appear that mafs agents are revealing their
private data because they transmit their private state in their messages. Yet, in fact, this
information is not used by any of the other agents, nor is it altered. It is simply copied to
future states to be used only by the agent. Since private state data is used only as an ID,
the agents can encrypt this data and keep a table locally, which maps IDs to private states.
This encryption can easily be made to generate multiple IDs for each private state, so that
306

fiDistributed Heuristic Forward Search

the same ID is never used twice, and so other agents cannot identify each others private
states. Consequently, all algorithms based on the distributed search paradigm described
are weakly privacy preserving. The issue of privacy is discussed further in Section 9.1.
To compute heuristic estimates of states it receives, an agent must assess the effort
required to achieve the goal from them. To do this, it needs some information about the
effort required of other agents to construct their part of the plan. In a fully cooperative
setting, an agent can have access to the full description of other agents actions. In the
privacy preserving setting, two issues arise. First, agents have only partial information
about other agents capabilities  they only have access to their public interface. Second,
different agents may compute different heuristic estimates of the same state because each
agent has full information about its capabilities, but not about those of the others. This
issue does not affect the actual algorithm, which is agnostic to how agents compute their
heuristic estimate, although the fact that agents have less information can lead to poorer
heuristic estimates. On the other hand, agents are free to use different heuristic functions,
and as we will demonstrate empirically, using the public interfaces only, we are still able to
efficiently solve planning problems.
When a state is reached via a message, it includes the sending agents heuristic estimate.
Therefore, the receiving agent now has two (possibly different) estimates it can use. If the
heuristics are known to be admissible, then clearly the maximal (more accurate) value is
taken, as in line 4 of Algorithm 2. If not, the agent is free to decide how to use these
estimates, depending on their known qualities.
4.2.2 Relevancy and Timing of the Messages
State s is considered relevant to agent j if it has a public action for which all public preconditions hold in s and the last action leading to s was public (line 7 of Algorithm 3).
This means that all states that are products of private actions are considered irrelevant to
other agents. As it turns out, since private actions do not affect other agents capability to
perform actions, an agent need send only states in which the last action performed was public, in order to maintain completeness (and cost-optimality, as proved in the next section).
Regarding states that are products of private actions as irrelevant decreases communication, while effectively pruning large, symmetrical parts of the search space. In fact, we will
show in Section 8 how this property of mafs can be used to obtain state-space pruning in
centralized planning algorithms, using a method called Partition-based pruning.
As was hinted earlier, there exists some flexibility regarding when these relevant states
are sent. Centralized search can be viewed as essentially sending every state (i.e., inserting
it to its open list) once it is generated. In mafs, relevant states can be sent when they
are expanded (as in the pseudo-code) or once they are generated (changing Algorithm
3 by moving the for-loop on line 6 inside the for-loop on line 10). The timing of the
messages is especially important in the distributed setting since agents may have different
heuristic estimates. Sending the messages once they are generated increases communication,
but allows for states that are not considered promising by some agent to be expanded by
another agent in an earlier stage. Sending relevant states when they are expanded, on
the other hand, decreases communication, but delays the sending of states not viewed
as promising. Experimenting with the two options, we found that the lazy approach, of
307

fiNissim & Brafman

sending the messages only when they are expanded, dominates the other, most likely because
communication can be costly.
4.2.3 Concurrent Solutions
Although the solution plan outputted by mafs is sequential, i.e. requires agents to execute
their actions in turns, it can quite easily be parallelized. Since private actions require/
affect only the agents private propositions, agents can perform them concurrently without
hurting the correctness of the plan, as long as the public actions (interaction points between
agents) are performed in correct order. Intuitively, if the execution order of the public
actions is maintained, the agents are free to execute their private actions concurrently.
This parallelization can be done in time linear in solution length, and requires no joint
computation. Another option is using one of the many algorithms known for parallelization
of plans (Backstrom, 1998). Given the existence of private actions, these plans have much
potential for concurrency.
4.2.4 Search Using Complex Actions
In Section 1, we mentioned a scenario where search operators corresponding to real-world
actions are implemented using complex simulation software. This situation can arise, for
example, with a team of heterogeneous robotic agents, each of which has a dedicated simulator of its actions. Our approach is well suited for such settings: First, forward search
methods are capable of using generative, rather than declarative models of the agents actions, as their central step involves the generation of successor states and their insertion
into appropriate queues. They are oblivious as to how the operators are described or implemented, as long as successor states can be generated. Second, our approach respects the
natural system structure, and each agent need only apply its own operators. Thus, there is
no need to share the generative models amongst the agents.
One problem, however, is the fact that most contemporary methods for generating
heuristic functions require either a declarative strips-like description or a generative model
(in the case of sampling methods). Fortunately, our empirical results indicate that the use of
an approximate model works quite well in practice. Indeed, our approach assumes that other
agents use only the public part of an agents action model, which is only an approximation.
Even if the original action model is generative, a declarative approximate model can be
constructed using learning techniques (Yang, Wu, & Jiang, 2007). Alternatively, sampling
methods could use a suitably developed simplified simulator.

5. Optimal MAFS
mafs as presented, is not a cost-optimal planning algorithm. Recall that a cost-optimal
plan in single-agent planning is one which achieves the goal with the minimal cost, i.e.
minimizing the sum of action costs of the plan. This notion remains in the MA case, where
we wish to minimize the sum of cost over all agents participating in the plan. This metric
is important in MA systems which describe cooperative agents like ma-strips, where the
aim is to minimize the cost of the entire system, and not of specific agents. Moreover, costoptimal algorithms are required for applying mechanism design techniques for planning in
308

fiDistributed Heuristic Forward Search

MA systems comprising of selfish agents (Nissim & Brafman, 2013). In such settings, a
cost-optimal plan constitutes a social-welfare maximizing solution. mafs can be slightly
modified in order to achieve cost-optimality. We now describe these modifications, which
result in a MA variation of a* we refer to as Multi-Agent Distributed A* (mad-a*).
As in a*, the state chosen for expansion by each agent must be the one with the lowest
f = g + h value in its open list, where the heuristic estimates are admissible. In mad-a*,
therefore, extract-min (Line 4 in Algorithm 1) must return this state.
5.1 Termination Detection
Unlike in a*, expansion of a goal state in mafs does not necessarily mean an optimal
solution has been found. In our case, a solution is known to be optimal only if all agents
prove it so. Intuitively, a solution state s having solution cost f  is known to be optimal
if there exists no state s0 in the open list or the input channel of some agent, such that
f (s0 ) < f  . In other words, solution state s is known to be optimal if f (s)  flowerbound ,
where flowerbound is a lower bound on the f -value of the entire system (which includes all
states in all open lists, as well as states in messages that have not been processed, yet).
To detect this situation, we use Chandy and Lamports snapshot algorithm (Chandy
& Lamport, 1985), which enables a process to create an approximation of the global state
of the system, without freezing the distributed computation. In this approximation we
check whether a state exists whose f value is lower than the value of the candidate solution.
Although this check is conducted with respect to an approximate global state, the snapshot
algorithm guarantees that the answer is positive iff it is true for the global state.
The snapshot algorithm works using marker messages. Each process that wants to
initiate a snapshot records its local state and sends a marker on each of its outgoing channels.
All the other processes, upon receiving a marker, record their local state, the state of the
channel from which the marker just came as empty, and send marker messages on all of
their outgoing channels. If a process receives a marker after having recorded its local state,
it records the state of the incoming channel from which the marker came as carrying all the
messages received since it first recorded its local state.
Although there is no guarantee that the global state computed by the algorithm actually
occurred at some point during the run of mad-a*, the approximation is good enough to
determine whether a stable property currently holds in the system. A property of the system
is stable if it is a global predicate which remains true once it becomes true. Specifically,
properties of the form flowerbound  c for some fixed value c, are stable when h is a globally
consistent heuristic function. That is, when f values cannot decrease along a path. In our
case, this path may involve a number of agents, each with its h values. If each of the local
functions h are consistent, and agents apply the max operator when receiving a state via
a message (known as pathmax ), this property holds3 . The solution verification procedure
using the snapshot algorithm, is run whenever a solution state is expanded (meaning it
has minimal f -value), and an agent receives confirmation from all agents for that solution
state (In the pseudocode, change Line 5 in Algorithm 3 to initiate verification of s as a
solution.). This occurs when all other agents have expanded that solution state. Only when
3. Although recent work (Holte, 2010) shows that pathmax does not necessarily make a bona-fide consistent
heuristic, pathmax does ensure that f -values along a path are non-decreasing.

309

fiNissim & Brafman

the snapshot algorithm returns true for the stable property that no states exist with lower
f -value, does the algorithm return the solution as optimal (In the pseudocode, change Line
1 of Algorithm 1 to while did not receive true from a solution verification procedure.).
We note that for simplicity of the pseudo-code we omitted the detection of a situation
where a goal state does not exist. This can be done by determining whether the stable
property there are no open states in the system holds, using the same snapshot algorithm.
5.2 Proof of Optimality
We now prove the optimality of mad-a*. We must note that as it is presented, mada* maintains completeness (and optimality) only if all actions which achieve some goal
condition are considered public. This property is assumed throughout this section, but
the algorithm is easily modified to remove it.4 We begin by proving the following lemma
(and a corollary) regarding the solution structure of a MA planning problem. This will
demonstrate that there always exists an optimal solution having the structure that is found
by mad-a*. We continue by proving a MA extension of a well-known result for a*, which
is required for the completeness of mad-a*. Finally, before proving mad-a*s optimality,
we prove the correctness of our termination detection procedure.
Lemma 1. Let P = (a1 , a2 . . . , ak ) be a legal plan for a MA planning problem . Let
ai , ai+1 be two consecutive actions taken in P by different agents, of which at least one is
private. Then P 0 = (a1 , . . . , ai+1 , ai , . . . , ak ) is a legal plan for  and P (I) = P 0 (I).
Proof. By definition of private and public actions, and because ai , ai+1 are actions belonging
to different agents, varset(ai )varset(ai+1 ) = , where varset(a) is the set of variables which
affect and are affected by a. Therefore, ai does not achieve any of ai+1 s preconditions, and
ai+1 does not destroy any of ai s preconditions. Therefore, if s is the state in which ai
is executed in P , ai+1 is executable in s, ai is executable in ai+1 (s), and ai (ai+1 (s)) =
ai+1 (ai (s)). Therefore, P 0 = (a1 , . . . , ai+1 , ai , . . . , ak ) is a legal plan for . Since the suffix
(ai+2 , ai+3 , . . . , ak ) remains unchanged in P 0 , P (I) = P 0 (I), completing the proof.
Corollary 1. Let P = (a1 , a2 , . . . , ak ) be a solution of the MA planning problem . Then,
there exists an equal cost solution P 0 = (a01 , a02 , . . . , a0k ) that satisfies the following properties:
1. P 0 contains a permutation of the actions of P .
2. If ai is the first public action in P 0 , then a1 , . . . , ai belong to the same agent.
3. For each pair of consecutive public actions ai , aj in P 0 , all actions al , i < l  j belong
to the same agent.
Proof. Using repeated application of Lemma 1, we can move any ordered sequence of private
actions performed by agent , so that it would be immediately before s subsequent public
action and maintain legality of the plan. Clearly, P 0 is a permutation of P and therefore
the cost of P and P 0 is identical. This implies that if P is cost optimal, so is P 0 .
4. In order to remove this assumption, an agent must send as messages all states for which the creating
action achieved some goal (which may be private). An agent approves a solution state only if all its
private goal are achieved.

310

fiDistributed Heuristic Forward Search

Next, we prove the following lemma, which is a MA extension of a well known result for
a*. In what follows, we have tacitly assumed a liveness property with the conditions that
every sent message eventually arrives at its destination and that all agent operations take
a finite amount of time. Also, for the clarity of the proof, we assume the atomicity of the
expand and process-message procedures.
Lemma 2. For any non-closed node s and for any optimal path P from I to s which has
properties 2 & 3 of Corollary 1, there exists an agent  which either has an open node s0
or has an incoming message containing s0 , such that s0 is on P and g (s0 ) = g  (s0 ) .
Proof. : Let P = (I = n0 , n1 , . . . , nk = s). If I is in the open list of some agent  ( did
not finish the algorithms first iteration), let s0 = I and the lemma is trivially true since
g (I) = g  (I) = 0. Suppose I is closed for all agents. Let  be the set of all nodes ni in
P that are closed by some agent , such that g (ni ) = g  (ni ).  is not empty since, by
assumption, I  . Let nj be the element of  with the highest index, closed by agent .
Clearly, nj 6= s since s is non-closed. Let a be the action causing the transition nj  nj+1
in P . Therefore, g  (nj+1 ) = g (nj ) + cost(a).
If  is the agent performing a, then nj+1 is generated and moved to s open list in
lines 9-13 of Algorithm 3, where g (nj+1 ) is assigned the value g (nj ) + cost(a) = g  (nj+1 )
and the claim holds.
Otherwise, a is performed by agent 0 6= . If a is a public action, then all its preconditions hold in nj , and therefore nj is sent to 0 by  in line 8 in Algorithm 3. If a
is a private action, by the definition of P , the next public action a0 in P is performed by
0 . Since private actions do not change the values of public variables, the public preconditions of a0 must hold in nj , and therefore nj is sent to 0 by  in line 8 in Algorithm
3. Now, if the message containing nj has been processed by 0 , nj has been added to the
open list of 0 in Algorithm 2 and the claim holds since g0 (nj ) = g (nj ) = g  (nj ). Otherwise, 0 has an incoming (unprocessed) message containing nj and the claim holds since
g (nj ) = g  (nj ).
Corollary 2. Suppose h is admissible for every   , and suppose the algorithm has not
terminated. Then, for any optimal solution path P which follows the restrictions of Lemma
1 from I to any goal node s? , there exists an agent i which either has an open node s or
has an incoming message containing s, such that s is on P and fi (s)  h (I).
Proof. : By Lemma 2, for every restricted optimal path P , there exists an agent i which
either has an open node s or has an incoming message containing s, such that s is on P
and gi (s) = g  (s) . By the definition of f , and since hi is admissible, we have in both
cases:
fi (s) = gi (s) + hi (s) = g  (s) + hi (s)
 g  (s) + h (s) = f  (s)
But since P is an optimal path, f  (n) = h (I), for all n  P , which completes the proof.
Another lemma must be proved regarding the solution verification process. We assume
global consistency of all heuristic functions, since all admissible heuristics can be made
consistent by locally using the pathmax equation (Mero, 1984), and by using the max
311

fiNissim & Brafman

operator as in line 4 of Algorithm 2 on heuristic values of different agents. This is required
since flowerbound must be non-decreasing.
Lemma 3. Let  be an agent which either has an open node s or has an incoming message
containing s. Then, the solution verification procedure for state s with f (s ) > f (s) will
return false.
Proof. Let  be an agent which either has an open node s or has an incoming message
containing s, such that f (s) < f (s ) for some solution node s . The solution verification procedure for state s verifies the stable property p = f (s )  flowerbound . Since
flowerbound represents the lowest f -value of any open or unprocessed state in the system,
we have flowerbound  f (s) < f (s ), contradicting p. Relying on the correctness of the
snapshot algorithm, this means that the solution verification procedure will return false,
proving the claim.
We can now prove the optimality of our algorithm.
Theorem 1. mad-a* terminates by finding a cost-optimal path to a goal node, if one exists.
Proof. : We prove this theorem by assuming the contrary - the algorithm does not terminate
by finding a cost-optimal path to a goal node. Three cases are to be considered:
1. The algorithm terminates at a non-goal node. This contradicts the termination condition, since solution verification is initiated only when a goal state is expanded.
2. The algorithm does not terminate. Since we are dealing with a finite search space,
let () denote the number of possible non-goal states. Since there is only a finite
number of paths from I to any node s in the search space, s can be reopened a finite
number of times. Let () be the maximum number of times any non-goal node s
can be reopened by any agent. Let t be the time point when all non-goal nodes s
with f (s) < h (I) have been closed forever by all agents . This t exists, since:
a) we assume liveness of message passing and agent computations; b) after at most
()  () expansions of non-goal nodes by , all non-goal nodes of the search space
must be closed forever by ; and c) no goal node s with f (s ) < h (I) exists5 .
By Corollary 2 and since an optimal path from I to some goal state s exists, some
agent  expanded state s at time t0 , such that f (s )  h (I). Since s is an
optimal solution, if t0  t, flowerbound  f (s ) at time t0 . Therefore, s verification
procedure of s will return true, and the algorithm terminates.
Otherwise, t0 < t. Let 0 be the last agent to close a non-goal state s with f0 (s) <
f (s ). 0 has s in its open list or as an incoming message. This is true because s
has been broad-casted to all agents by , and because every time s is closed by some
agent (when it expands it), it is immediately broad-casted again, ending up in the
agents open list or in its message queue. Now, 0 has no more open nodes with f value lower than s , so it will eventually expand s , initiating the solution verification
procedure which will return true, since flowerbound  f (s ). This contradicts the
assumption of non-termination.
5. This is needed since goal node expansions are not bounded.

312

fiDistributed Heuristic Forward Search

3. The algorithm terminates at a goal node without achieving optimal cost. Suppose
the algorithm terminates at some goal node s with f (s) > h (I). By Corollary 2,
there existed just before termination an agent  having an open node s0 , or having an
incoming message containing s0 , such that s0 is on an optimal path and f (s0 )  h (I).
Therefore, by Lemma 3, the solution verification procedure for state s will return false,
contradicting the assumption that the algorithm terminated.
This concludes the proof.
As a final note, we point out that the above results can be used to prove that MAFS versions of other search algorithms, such as best-first search, are complete, thanks to Corollary 1
and Lemma 2. Corollary 1 guarantees that we can focus on solutions with certain properties.
That is, if a solution exists, then a solution with these properties exists. Lemma 2 ensures
that every path with these properties will be generated, eventually, until a solution is found.
We note that we cannot provide such guarantees for distributed versions of every search
algorithm simply because an arbitrary search algorithm may prune, for some reason, solutions with the properties ensured by the MAFS schema, while keeping other solutions. And
of course, completeness guarantees for MAFS require that the liveness properties discussed
earlier hold.

6. MA Planning Framework
One of the main goals of this work is to provide a general and scalable framework for solving
the MA planning problem. We believe that such a framework will provide researchers with
fertile ground for developing new search techniques and heuristics for MA planning, and
extensions to richer planning formalisms.
We chose Fast Downward (Helmert, 2006) (FD) as the basis for our MA framework
 MA-FD. FD is currently the leading framework for planning, both in the number of
algorithms and heuristics that it provides, and in terms of performance  winners of the
past three international planning competitions were implemented on top of it. FD is also
well documented and supported, so implementing and testing new ideas is relatively easy.
MA-FD uses FDs translator and preprocessor, with minor changes to support the distribution of operators to agents. Each agent also receives a projected version of the public
operators of the other agents. This information (its own actions and the projected public
actions) are provided to the heuristic used by the agent. In addition to the PDDL files describing the domain and the problem instance, MA-FD receives a file detailing the number
of agents, their names, and their IP addresses. The agents do not have shared memory,
and all information is relayed between agents using messages. Inter-agent communication
is performed using the TCP/IP protocol, which enables running multiple MA-FD agents as
processes on multi-core systems, networked computers/robots, or even cloud platforms like
Amazon Web Services. MA-FD is therefore fit to run as is on any number of (networked)
processors, in both its optimal and satisficing setting.
Both settings are currently implemented and available6 , and since there is full flexibility
regarding the heuristics used by agents, heuristics available on FD are also available on MAFD, requiring only preprocessing of the agents view of the problem, creating its projected
6. The code is available at http://github.com/raznis/dist-selfish-fd .

313

fiNissim & Brafman

view. New heuristics are easily implementable, as in FD, and creating new search algorithms
can also be done with minimal effort, since MA-FD provides the ground-work (parsing,
communication, etc.).

7. Empirical Results
The following section describes an empirical evaluation of our methods. We begin by evaluating mafs, comparing it to current state-of-the-art approaches. We then describe results
for mad-a*, compared to centralized cost-optimal search. We also provide scalability results
for both methods, scaling up to 40 agents.
7.1 Evaluating MAFS
To evaluate mafs in its non-optimal setting, we compare it to the state-of-the-art distributed
planner map-pop (Torreno et al., 2012), and to the Planning-First algorithm (Nissim et al.,
2010). As noted in Section 1, another available algorithm for distributed MA planning
is via reduction to distributed CSPs using an off-the-shelf disCSP solver. We found this
approach was incapable of solving even small planning problems, and therefore we omitted
its results from the tables. The problems used are benchmarks from the International
Planning Competition (IPC) where tasks can naturally be cast as MA problems. The
Satellites and Rovers domains were motivated by real MA applications used by NASA.
Satellites requires planning and scheduling observation tasks between multiple satellites,
each equipped with different imaging tools. Rovers involves multiple rovers navigating a
planetary surface, finding samples and communicating them back to a Lander. Logistics,
Transport and Zenotravel are transportation domains, where multiple vehicles transport
packages to their destination. The Transport domain generalizes Logistics, adding a capacity
to each vehicle (i.e., a limit on the number of packages it may carry) and different move
action costs depending on road length. We consider problems from the Rovers and Satellites
domains as loosely-coupled, i.e., problems where agents have many private actions (e.g.,
instrument warm-up and placement in Rovers, which does not affect other agents), and
where a small number of public actions are required in solution plans. On the other hand,
we consider the transportation domains as tightly-coupled, having few private actions (only
move actions in Logistics) and many public actions (load/unload actions).
For each planning problem, we ran mafs, using eager best-first search and an alternation open list with one queue for each of the two heuristic functions ff (Hoffmann &
Nebel, 2001) with preferred actions and the context-enhanced additive heuristic (Helmert &
Geffner, 2008). Table 7.1 depicts results of mafs, map-pop and Planning-First, on all IPC
domains supported by map-pop. We also include results for a baseline centralized planner
(denoted FD, implemented on top of Fast-Downward) using the same eager best-first search
and heuristics used in mafs. Recall that this planner solves the problem having complete
knowledge, unlike the other configurations. We compare the algorithms across three categories  1) solution cost which reports the total cost of the outputted plan, 2) running time,
and 3) the number of messages sent during the planning process. Experiments were run
on a AMD Phenom 9550 2.2GHZ processor, time limit was set at 60 minutes, and memory
usage was limited to 4GB. For all configurations shown in Table 7.1, experiments were re314

fiDistributed Heuristic Forward Search

#
problem
agents
Logistics4-0
3
Logistics5-0
3
Logistics6-0
3
Logistics7-0
4
Logistics8-0
4
Logistics9-0
4
Logistics10-0
5
Logistics11-0
5
Logistics12-0
5
Logistics13-0
7
Logistics14-0
7
Logistics15-0
7
Rovers5
2
Rovers6
2
Rovers7
3
Rovers8
4
Rovers9
4
Rovers10
4
Rovers11
4
Rovers12
4
Rovers13
4
Rovers14
4
Rovers15
4
Rovers17
6
Satellites3
2
Satellites4
2
Satellites5
3
Satellites6
3
Satellites7
4
Satellites8
4
Satellites9
5
Satellites10
5
Satellites11
5
Satellites12
5
Satellites13
5
Satellites14
6
Satellites15
8
Satellites16
10
Satellites17
12

Solution cost
fd mafs map-pop p-f
21
20
20
X
28
27
27
X
26
25
25
X
43
36
37
X
32
31
31
X
39
36
36
X
50
45
51
X
54
54
X
X
47
44
45
X
85
87
X
X
68
68
X
X
94
95
X
X
22
22
24 24
38
37
39
X
18
18
18
X
26
26
27
X
40
38
36
X
37
38
X
X
42
37
34
X
21
21
20
X
48
49
X
X
33
31
35
X
43
46
44
X
53
52
X
X
11
11
11 11
26
17
20 20
21
16
15
X
20
20
20
X
28
22
22
X
27
26
26
X
37
30
29
X
37
30
29
X
36
31
31
X
43
43
49
X
75
61
X
X
49
44
43
X
64
63
X
X
62
56
56
X
48
49
49
X

Runtime
fd mafs map-pop p-f
 0.1 0.05
20.9
X
 0.1
0.1
90.4
X
 0.1 0.06
60.6
X
 0.1
0.2
233.3
X
 0.1 0.16
261
X
 0.1 1.02
193.3
X
 0.1 0.43
471
X
 0.1
2.7
X
X
 0.1
1.3
1687
X
 0.1
0.9
X
X
 0.1 0.67
X
X
 0.1 0.74
X
X
 0.1 0.13
18.7 22.4
 0.1 0.07
18.2
X
 0.1 0.07
44.1
X
 0.1
0.2
744
X
 0.1 0.82
222
X
 0.1 0.41
X
X
 0.1 0.34
132.5
X
 0.1 0.09
34.4
X
 0.1 0.15
X
X
 0.1 0.42
443.8
X
 0.1 0.33
164
X
 0.1 0.57
X
X
 0.1 0.01
4.5 6.8
 0.1 0.17
6.4 35.2
 0.1 0.15
15.4
X
 0.1 0.02
12.2
X
 0.1 0.23
28.8
X
 0.1 0.21
40.7
X
 0.1 0.35
93.3
X
 0.1 0.41
65.9
X
 0.1 0.69
51
X
0.2
1.1
76.9
X
0.57 0.88
X
X
0.3
1.8
123.4
X
0.66
3.9
X
X
0.94
6.6
481.2
X
1.12
6.7
2681
X

Messages
mafs map-pop p-f
340
375
X
450
1565
X
470
1050
X
2911
4898
X
940
4412
X
2970
3168
X
2097
14738
X
14933
X
X
4230
28932
X
5140
X
X
2971
X
X
6194
X
X
84
323 590
27
313
X
225
490
X
937
12102
X
380
4467
X
271
X
X
299
2286
X
435
410
X
472
X
X
310
7295
X
252
2625
X
628
X
X
7
78 104
36
109 144
78
250
X
30
323
X
248
543
X
133
678
X
397
1431
X
355
942
X
514
904
X
390
1240
X
639
X
X
721
1781
X
1507
X
X
2279
4942
X
2172
26288
X

Table 1: Comparison of MA greedy best-first search, map-pop and Planning-First. Solution
cost, running time (in sec.) and the number of sent messages are shown. X
denotes problems which werent solved after one hour, or in which the 4GB memory
limit was exceeded. Best performance entries are in bold.

stricted to run on a single processor (core), so running time would be easily comparable7 .
An X signifies that the problem was not solved within the time-limit, or exceeded memory
constraints.
7. In all other result tables, multiple processors were used.

315

fiNissim & Brafman

It is clear that mafs overwhelmingly dominates both map-pop and Planning-First (denoted p-f), with respect to running time and communication, solving all problems faster
while sending less messages. All problems were solved at least 70 faster than map-pop,
with several Logistics and Rovers problems being solved over 1000 faster, and the largest
Satellites instance being solved over 400 faster. The low communication complexity of
mafs is important, since in distributed systems message passing could be more costly and
time-consuming than local computation. Moreover, as messages in mafs are essentially a
state description, message size is always linear in the number of propositions. Although
for some problems map-pop finds lower-cost solutions, in most cases mafs outputs better
solution quality. We believe that when mafs finds lower quality solutions, this is mostly
because message-passing takes longer than local computation  a subset of agents that have
the ability to achieve the goal on their own, will do so before being made aware of other,
less costly solutions including other agents. One possible way of improving solution quality
further would be using anytime search methods, which improve solution quality over time.
In comparison to the reference centralized planner, mafs takes longer to compute a solution, but in most cases these solutions have lower or equal cost. The slowdown is expected,
both because of communication times and the partial information mafs agents have, unlike
the centralized planner.
7.1.1 Scalability of MAFS
In order to evaluate the scalability of mafs, we conducted experiments on the Logistics,
Rovers and Satellite domains from the IPC. For each of the domains, we generated multiple
problem instances, increasing the number of agents k. In Logistics, the number of cities
grows linearly with k, the number of airplanes remains constant at 2, and the number of
packages is always 2k. For Satellites and Rovers, the number of targets grows linearly with
k, the number of available observations/locations is 2k, and the instrumentation remains
constant. The experiments were run on an Intel Xeon 2.4GHZ, 48-core machine. FD was
run on a single processor while each mafs agent was given a dedicated processor. Cutoff
time for both configurations was set at 1 hour (Wall-clock time), and memory limit was set
at 100GB, regardless of the number of processors used.
Results of the scalability experiment can be seen in Figure 7.1.1. For every value of
k, 5 different problem instances were generated. The runtime values shown are averages
over all 5 of them, and the error bars correspond to the standard deviation of the sample8 .
In the loosely-coupled domains Rovers and Satellites, mafss increase in runtime is nearly
linear, where the largest of the problem instances in both domains which were unsolved by
centralized FD, were solved in under 90 seconds. Efficiency (speedup divided by the number
of processors) values are always superlinear  16 for the largest Satellites problem solved
by both configurations and > 11 for the largest Rovers problems. While being superior in
speed, mafs outputs lower quality solutions (having higher total cost) in these domains. On
average, mafs solution cost is 14% higher in Rovers and 6% higher in Satellites, with the
maximal increase being 20% and 13% respectively. The cause of deterioration in solution
quality in these domains is most likely the fact that in many problems, small subsets of
agents can reach a solution without other agents. This may lead to mafs quickly finding
8. The error bars were omitted in cases where standard deviation was too small to be shown on this scale.

316

fiDistributed Heuristic Forward Search

a solution involving this subset, but this solution is usually more costly than that is found
by centralized search, which considers operators of all agents. In Logistics, a more tightlycoupled domain where many actions are public, problems are still solved much faster (5
faster for the 40-agent problems) by mafs, but the efficiency is < 1  on average 0.12 for
the largest instances. Here, solution cost is on average 0.5% higher than centralized search,
where the maximal increase is 2.5%, and the maximal decrease (improvement in solution
quality) is 2%. Overall, we can see that w.r.t. runtime, mafs is scalable  performing with
superlinear efficiency in loosely-coupled domains, and exhibiting speedup in the tightlycoupled ones.
7.2 Evaluating MAD-A*
To evaluate mad-a* with respect to centralized optimal search (a*), we ran both algorithms
using the state-of-the-art Merge&Shrink heuristic9 (Helmert, Haslum, & Hoffmann, 2007).
Both configurations were run on the same machine, where for mad-a*, each agent was
allocated a single processor, and a* was run on a single processor. Wall-clock time limit was
set at 30 minutes, and memory usage was limited to 4GB, regardless of the number of cores
used. We show results up to problems which constitute the limit of either configuration. No
more existing IPC problems in these domains were solvable by both configurations. Table
7.2 depicts the runtime, efficiency (speedup divided by the number of processors), number
of expanded nodes and the average of the agents initial state h-values.
When comparing mad-a* to centralized a*, our intuition is that efficiency will be low,
due to the inaccuracy of the agents heuristic estimates, and the overhead incurred by
communication. In fact, the local estimates of the agents are much less accurate than those
of the global heuristic, as is apparent from the lower average h values of the initial state,
given as approximate measures of heuristic quality  when discussing admissible heuristics
(which are required for optimal search), higher values are necessarily more accurate. In
the tightly-coupled domains  Logistics, Transport and Zenotravel, we do notice very low
efficiency values, mostly due to the large number of public actions, which result in many
messages being passed between agents, and the relatively small amount of local (private)
search by the agents. However, in the more loosely-coupled domains Satellites and Rovers,
mad-a* exhibits nearly linear and super-linear speedup, solving 2 problems not solved by
centralized a*. We analyze the reason for this superlinear speedup and elaborate on this
important issue in Section 8.
7.2.1 Scalability of MAD-A*
From the results in Table 7.2, it is clear that mad-a* does not scale well in tightly-coupled
domain such as Logistics, Transport and Zenotravel. In the loosely-coupled domains of
Rovers and Satellites, however, mad-a* exhibited high efficiency, outperforming centralized
search in some cases. This section examines the scalability of mad-a* in these domains
compared to that of centralized a*.
As in Section 7.1.1, we created new instances of problems with increasing agents using
problems generators. In both domains, the number of available locations and goals increased
9. We used exact bisimulation with abstraction size limit 10K (DFP-bop) as the shrink strategy of
Merge&Shrink (Nissim, Hoffmann, & Helmert, 2011).

317

fiNissim & Brafman

Logistics

Satellites

FD
MAFS

3,500
3,000

2,500

Runtime

Runtime

2,500
2,000
1,500
1,000

2,000
1,500
1,000

500

500

0

0
20

25

FD
MAFS

3,000

30

35

40

15

Number of agents

20

25

30

35

40

Number of agents

Rovers
1,400

FD
MAFS

1,200

Runtime

1,000
800
600
400
200
0
10

15

20

25

30

35

40

Number of agents

Figure 2: Scalability of MAFS w.r.t. centralized FD. For both configurations, runtime in
seconds is shown.

318

fiDistributed Heuristic Forward Search

problem
Logistics4-0
Logistics5-0
Logistics6-0
Logistics7-0
Logistics8-0
Logistics9-0
Logistics10-0
Logistics11-0
Rovers3
Rovers4
Rovers5
Rovers6
Rovers7
Rovers12
Satellites3
Satellites4
Satellites5
Satellites6
Satellites7
Transport1
Transport2
Transport3
Transport4
Transport5
Zenotravel3
Zenotravel4
Zenotravel5
Zenotravel6
Zenotravel7
Zenotravel8
Zenotravel9
Zenotravel10
Zenotravel11
Zenotravel12

agents
3
3
3
4
4
4
5
5
2
2
2
2
3
4
2
2
3
3
4
2
2
2
2
2
2
2
2
2
2
3
3
3
3
3

a*
0.07
0.16
0.29
1.42
1.28
2.17
132
180
0.2
0.07
8.24
X
32.4
190.8
0.3
0.6
16.83
1.93
X
0.02
0.17
1.35
54.6
X
0.33
0.32
0.3
0.47
0.55
1.22
31.7
9.3
2.99
X

Time
mad-a* Efficiency
0.03
0.78
0.13
0.41
0.15
0.64
8.26
0.04
2.89
0.11
11.6
0.05
X
0.00
X
0.00
0.11
0.91
0.04
0.88
4.4
0.94
301

6.82
1.58
27.6
1.73
0.29
0.52
0.4
0.75
3.9
1.44
0.92
0.70
18.26

0.08
0.13
0.21
0.40
20.64
0.03
335.15
0.08
X
N/A
0.42
0.39
0.43
0.37
0.42
0.36
0.61
0.39
0.8
0.34
1.71
0.24
315
0.03
338
0.01
11.7
0.09
X
N/A

Expansions
a*
mad-a*
21
2496
28
11020
547
9722
29216
520122
16771
157184
43283
687572
4560551
X
5713287
X
12
86
9
121
213079
307995
X 18274357
1172964
676750
4963979
2591428
12
1498
18
5045
236647
42557
1382
81731
X
1303910
6
285
242
1628
69500
546569
3527592
4397124
X
X
7
516
9
762
14
577
270
1280
621
5681
136
5461
775340
6745088
116872
4416461
20157
200868
X
X

a*
20
27
24
33
27
33
37
41
11
8
12
24
9
11
11
17
10
17
10
54
79
34
10
12
6
7
10
10
11
9
16
20
11
16

init-h
mad-a*
17
23
22
29
24
29
34
38
9
7
11
21
7
7
5
11
7
12
9
4
4
4
10
10
5
6
8
8
9
7
14
17
9
14

Table 2: Comparison of centralized a* and mad-a* running on multiple processors. Running time (in sec.), average initial state h-values and mad-a*s efficiency values
w.r.t. a* are shown. Entries in bold denote super-linear efficiency of mad-a*.

linearly with the number of agents k. For each value of k, we created 5 problem instances,
and the reported runtime values are averages. The experiments were run on the same Intel
Xeon machine used in Section 7.1.1, where a* was run on a single processor, and each
mad-a* agent was given a dedicated processor. Runtime limit was set at 90 minutes and
memory was limited to 100GB regardless of the number of processors.
In Figure 7.2.1 we can see that in both domains, mad-a* solves all problems faster than
centralized a*, and can solve larger problems within the time limit. However, efficiency
varies between the two domains  in Satellites, which is very loosely-coupled, efficiency is
superlinear in all cases, reaching up to 7.3 in the largest problem solved by both configura319

fiNissim & Brafman

Rovers

Satellites

A*
MAD-A*

2,500
2,000

4,000

Runtime

Runtime

A*
MAD-A*

5,000

1,500
1,000

3,000
2,000

500

1,000

0

0
3

4

5

6

4

Number of agents

5

6

7

8

9

10

Number of agents

Figure 3: Scalability of MAD-A* w.r.t. centralized A* in loosely-coupled domains. For both
configurations, runtime in seconds is shown.

tions. In Rovers, which is more tightly-coupled, efficiency is  0.5 in all problems, dropping
as low as 0.35 in the largest problem solved by both configurations. Recall that the problem
solved by mad-a* is more difficult, since each agent has private information unknown to
others, so this drop in efficiency is expected. As mentioned in the previous section, we next
elaborate on the reason for mad-a*s superlinear efficiency in loosely-coupled problems.

8. Partition-Based Path Pruning
The empirical results presented in the previous section raise an interesting question: how
does MAD-A* achieve > 1 efficiency in weakly-coupled environments? It is known that
when using a consistent heuristic, a* is optimal in the number of nodes it expands to
recognize an optimal solution. In principle, it appears that mad-a* should expand at least
the same search tree, so it is not clear, a-priori, why we reach super-linear speedup when
comparing to a*. This section provides an explanation to this phenomenon  a partial
order reduction method inherently built-in to mad-a* (and mafs as well), which exploits
symmetry in the search space to prune effect-equivalent paths. We will describe this pruning
method in detail, showing empirical evidence supporting the claim that within this method
lies much of the power of mad-a*.
This exploitation of symmetry utilizes the notion of public and private actions. As
we noted in Corollary 1, the existence of private actions implies the existence of multiple
effect-equivalent permutations of certain action sequences. a* does not recognize or exploit
this fact, and mafs does. Specifically, imagine that agent i just generated state s using
one of its public actions, and s satisfies the preconditions of some public action a of agent
j . Agent i will eventually send s to agent j , and the latter will eventually apply a to
it. Now, imagine that agent i has a private action a0 applicable at state s, resulting in the
320

fiDistributed Heuristic Forward Search

state s0 = a0 (s). Because a0 is private to i , from the fact that a is applicable at s we deduce
that a is applicable at s0 as well. Hence, a* would apply a at s0 . However, in mafs, agent
j would not apply a at s0 because it will not receive s0 from agent i . Thus, mafs does
not explore all possible action sequences. This fact can also be clearly seen in the example
given in Figure 4.1  The reachable search space in this example has 31 states, while the
number of reachable states using mafs is only 16.
Since mafss inherent pruning of action sequences requires only a partitioning of the
actions, it does not pertain only to MA systems, but to any factored system having internal
operators. Since the only difference between a ma-strips planning problem and a strips
one is the fact that actions are partitioned between agents, why not re-factor the centralized
problem into an artificial MA one? By mapping all actions into disjoint sets such that
Sk
i Ai = A, each representing an agent, we can now distinguish between private and
public operators. Given this distinction, the pruning rule used is simple:
Partition-Based (PB) Pruning Rule: Following a private action a  Ai ,
prune all actions not in Ai .
The fact that this pruning rule is optimality-preserving (i.e., does not prune all optimal
solutions) follows immediately from Corollary 1 as, if there exists an optimal solution  ? ,
it can be permuted into a legal, optimal plan which is not pruned. This, however, is not
enough to maintain the optimality of a* search. We now present a slight modification of
the a* algorithm, which allows the application of optimality preserving pruning methods
(such as PB-pruning) for the purpose of optimal planning.
8.1 Path Pruning A*
The path pruning a*, (denoted pp-a*), is a search algorithm which receives a planning
problem  and a pruning method  as input, and produces a plan , which is guaranteed to
be optimal provided that  respects the following properties: (i)  is optimality preserving,
and (ii)  prunes only according to the last action. It is easy to see, for example, that PB
pruning respects the second condition, since it fires only according to the last action.
8.1.1 pp-a* versus a*
pp-a* is identical to a* except for the following three changes. First, a different data-type
is used for recording an open node. In pp-a*, an open list node is a pair (A, s), where s is
the state and A is a set of actions, recording various possible ways to reach s from a previous
state. Second, node expansion is subject to the pruning rules of method . Namely, ppa* executes an applicable action a0 in state (A, s) only if there is at least one action a  A
s.t. the execution of a0 is allowed after a under s pruning rules. Third, duplicate states
are handled differently. In a*, when a state s which is already open is reached by another
search path, the open list node is updated with the action of the lower g value, and in case
of a tie  drops the competing path. In contrast, ties in pp-a* are handled by preserving
the last actions which led to s in each of the paths. Hence, if action a led to an open state s
via a path of cost g, and if the existing open list node (A, s) has the same g value, then the
node is updated to (A  {a}, s), thus all actions leading to s with path cost g are saved. Tie
breaking also affects the criterion under which closed nodes are reopened. In a*, nodes are
321

fiNissim & Brafman

reopened only when reached via paths of lower g values. In pp-a*, if an action a leading to
state s of some closed node (A, s) is not contained in A, and if the g values are equal, then
the node reopens as ({A  {a}}, s). However, when the node is expanded, only actions that
are now allowed by  and were previously pruned, are executed. We now move to prove the
correctness of pp-a*.
8.1.2 Proof of Correctness and Optimality
The next lemma refers to pp-a*, and assumes  to be an optimality preserving pruning
method, which prunes according to the last action. We say that node (A, s) is optimal on
path P , if A contains an action a which leads to state s on path P , and g(s) = g  (s). The
notation s P s0 denotes the fact that state s precedes state s0 in optimal path P .
Lemma 4. In pp-a*, for any non-closed state sk and for any optimal non--pruned path
P from I to sk , there exists an open list node (A0 , s0 ) which is optimal on P .
Proof. Let P be an optimal non--pruned path from I to sk . If I is in the open list, let
s0 = I and the lemma is trivially true since g(I) = g  (I) = 0. Suppose I is closed. Let 
be the set of all nodes (Ai , si ), optimal on P , that were closed.  is not empty, since by
assumption, I is in . Let the nodes in  be ordered such that si P sj for i < j, and let
j be the highest index of any si in .
Since the closed node (Aj , sj ) has an optimal g value, it had been expanded prior to
closing. From the properties of pp-a*, it follows that the expansion of (Aj , sj ), which is
optimal on P , is followed with an attempt to generate a node (Aj+1 , sj+1 ) which is optimal
on P as well. Generation of (Aj+1 , sj+1 ) must be allowed, since under the highest index
assumption there can be no closed node containing s which is optimal on P . Naturally,
sj P sj+1 .
At this point, we note that actions in Aj+1 cannot be removed by any competing path
from I to sj+1 , since (Aj+1 , sj+1 ) has an optimal g value. It is possible, though, that additional actions leading to sj+1 are added to the node. The updated node can be represented
by (A0j+1  Aj+1 , sj+1 ), and the property of optimality on P holds. Additionally, node
(A0j+1 , sj+1 ) cannot be closed after its generation, since again, this contradicts the highest
index property. Hence, there exists an open list node (A0 , s0 ) which is optimal on P . This
concludes the proof.
Corollary 3. If h is admissible and  is optimality-preserving, pp-a* using  is optimal.
Proof. This follows directly from Lemma 4, the optimality preserving property of  and the
properties of pp-a*, which allow every optimal, non--pruned path to be generated.
8.2 Empirical Analysis of PB-Pruning
We set out to check the effect of mad-a*s inherent exploitation of symmetry on its efficiency
compared to a*. The hypothesis that this is mad-a*s main advantage over a* is well
supported by the results in Table 8.2, which shows a comparison of mad-a* and centralized
a* using PB pruning. Here, we see that in all problems where mad-a* achieves superlinear
speedup w.r.t. a*, applying partition-based pruning where partition=agent reduces runtime
and expansions dramatically. In all cases, mad-a*s efficiency w.r.t. a* using PB pruning
322

fiDistributed Heuristic Forward Search

problem
Logistics4-0
Logistics5-0
Logistics6-0
Logistics7-0
Logistics8-0
Logistics9-0
Logistics10-0
Logistics11-0
Rovers3
Rovers4
Rovers5
Rovers6
Rovers7
Rovers12
Satellites3
Satellites4
Satellites5
Satellites6
Satellites7
Transport1
Transport2
Transport3
Transport4
Zenotravel3
Zenotravel4
Zenotravel5
Zenotravel6
Zenotravel7
Zenotravel8
Zenotravel9
Zenotravel10
Zenotravel11
Zenotravel12

agents
3
3
3
4
4
4
5
5
2
2
2
2
3
4
2
2
3
3
4
2
2
2
2
2
2
2
2
2
3
3
3
3
3

a*
0.07
0.16
0.29
1.42
1.28
2.17
132
180
0.2
0.07
8.24
X
32.4
190.8
0.3
0.6
16.83
1.93
X
0.02
0.17
1.35
54.6
0.33
0.32
0.3
0.47
0.55
1.22
31.7
9.3
2.99
X

Time
a?pb mad-a*
0.06
0.03
0.17
0.13
0.29
0.15
1.07
8.26
1.07
2.89
1.59
11.6
37
X
57.4
X
0.2
0.11
0.06
0.04
3.07
4.4
164.9
301
5.22
6.82
10.1
27.6
0.29
0.29
0.58
0.4
3.15
3.9
1.84
0.92
26.6
18.26
0.01
0.08
0.16
0.21
0.9
20.64
29.8
335.15
0.34
0.42
0.33
0.43
0.3
0.42
0.47
0.61
0.56
0.8
1.21
1.71
12.88
315
6.51
338
2.02
11.7
82.95
X

Efficiency
a*
a?pb
0.78 0.67
0.41 0.44
0.64 0.64
0.04 0.03
0.11 0.09
0.05 0.03
0
0
0
0
0.91 0.91
0.88 0.75
0.94 0.35
 0.27
1.58 0.26
1.73 0.09
0.52 0.50
0.75 0.73
1.44 0.27
0.70 0.67
 0.36
0.13 0.06
0.40 0.38
0.03 0.02
0.08 0.04
0.39 0.40
0.37 0.38
0.36 0.36
0.39 0.39
0.34 0.35
0.24 0.24
0.03 0.01
0.01 0.01
0.09 0.06
N/A
0

a*
21
28
547
29216
16771
43283
4560551
5713287
12
9
213079
X
1172964
4963979
12
18
236647
1382
X
6
242
69500
3527592
7
9
14
270
621
136
775340
116872
20157
X

Expansions
a?pb
21
28
527
22425
11750
29953
2132416
2980725
12
9
62672
8107327
235537
391372
12
18
23503
385
846394
6
225
49744
2589496
7
9
14
220
433
126
474180
104340
11565
2406708

mad-a*
2496
11020
9722
520122
157184
687572
X
X
86
121
307995
18274357
676750
2591428
1498
5045
42557
81731
1303910
285
1628
546569
4397124
516
762
577
1280
5681
5461
6745088
4416461
200868
X

Table 3: Comparison of centralized a* with and without partition-based pruning, and mada* running on multiple processors. Running time, number of expanded nodes, and
mad-a*s efficiency w.r.t. both centralized configurations are shown.

is sublinear. This is, of course, also due to the fact that mad-a* solves a more difficult
problem  having incomplete information has a negative effect on the quality of heuristics
computed by the agents.
We note that although MA structure is evident in some benchmark planning domains
(e.g. Logistics, Rovers, Satellites, Zenotravel etc.), in general there isnt always an obvious
way of decomposing the problem. In work further exploring PB pruning (Nissim, Apsel,
& Brafman, 2012), we describe an automated method for decomposing a general planning problem, making PB pruning applicable in the general classical planning setting. We
note that there exist many other partial-order reduction methods, such as Commutativity
Pruning (Haslum & Geffner, 2000), Stubborn Sets (Valmari, 1989; Wehrle & Helmert,
323

fiNissim & Brafman

2012; Alkhazraji, Wehrle, Mattmuller, & Helmert, 2012; Wehrle, Helmert, Alkhazraji, &
Mattmuller, 2013), Expansion Core (Chen & Yao, 2009), and more (Coles & Coles, 2010;
Xu, Chen, Lu, & Huang, 2011). None of these methods subsumes PB pruning, and the
interesting question of how to combine such methods while maintaining optimality remains
open in the field of classical planning.

9. Discussion
Our work raises a number of questions, research challenges, and opportunities that we now
discuss.
9.1 Privacy
As noted earlier, our algorithms are weakly privacy preserving. That is, no information
about private actions, their cost, private variables, and private preconditions and effects is
ever communicated by an agent to other agents. Nevertheless, as in the case of DisCSP
discussed earlier, information about these elements could be deduced by other agents during
the run of the algorithm. And given that privacy preservation is an important goal of our
work, it is important to try to understand the extent to which such information can leak.
To examine this, let us consider what is the maximal amount of explicit information that
is available to an agent about other agents. In the worse case, we would have to explore the
entire search tree rooted at the initial state during the run of the algorithm. However, an
agent does not see all the nodes in that tree, but only nodes that correspond to search states
obtained following a public action (because only these states are communicated). Thus, the
sub-tree visible to an agent corresponds to one obtained from the full search tree by a topdown recursive process where every state obtained following a private action is removed,
and the parent of a removed node becomes the parent of its children. Furthermore, the
only information available about each state to an agent consists only of the value of its local
variables in that state and the value of public variables. (Recall that, as each private state
is encrypted using a different identifier, the local states of other agents appear different in
every state, so they provide no useful information).
What can an agent learn from this projected search tree? First, it can try to identify
different states as identical. Two states whose sub-trees are identical can be deduced as
having the same local states for all agents. Notice that this information cannot be deduced
from the plan alone. Consequently, we cannot claim that our search-based methods are
strong privacy preserving. It is more difficult to identify the fact that two states have
the same local state for a particular agent only. Let us, however, assume the worst case
scenario in which such states are also identifiable  we will use the term the projected subtree with state ids to refer to this structure. Thus, the agent knows the possible values,
up to renaming, of the local states of an agent that occur following the execution of its
public actions. It also knows about the existence of macros consisting of a sequence of
private actions followed by a public action that allow an agent to move from its private
state following a public action to the next private state following the execution of its next
public action. It does not, however, know the structure of the local state  it can only
deduce some monolithic name. Nor does it know the nature of the local actions comprising
these macros that enable the transition between two post-public-action states.
324

fiDistributed Heuristic Forward Search

But while strong privacy preservation is not guaranteed, it is possible to show  at
present on a per domain basis  that distributed forward search algorithms offer more than
weak privacy preservation. As an example, we return to the logistics domain. Imagine that
the truck has various service stations or rest-stops in locations private to it (i.e., that are
served only by that truck). Their existence is not visible to the other agents. This can be
proven formally by showing that the projected search tree visible to an external agent is
identical regardless of the number of such private locations of the truck. As this projected
search tree contains all the information available to other agents, this implies that the
information available to other agents is the same in both cases. To see that this projected
tree is the same, recall that the public actions of a truck are load and unload. Furthermore,
note that loading or unloading a package in a location that is not accessible to any other
agent is a private action of the truck because its preconditions and effects are not required
or affected by any other agent. Thus, the states visible in the projected search tree are
states that follow a load/unload action in a location served by other agents as well, such as
the airport. In those states, the local state of the truck reflects being in such a location.
Consequently, no local state that corresponds to being in a private location is part of the
projected search tree. That is, the projected search tree is the same whether the agent has
no, one, or any number of private service locations.
Another piece of private information could be the existence of private packages. That
is, packages being delivered from a private location to another private location. Here,
the proof above does not work  the local state of the truck could be different following
unloading a (public) package in a public location, simply because the variable denoting the
location of the private package could have different values, which are technically part of
its local state (because only the truck can influence their value). In fact, the situation is
similar in the above case (of private service stations) if packages can be unloaded in the
private service stations. Again, local states in which some package is located in such a
station would appear in the projected search tree. However, in both cases, external agents
cannot infer that the larger set of private states stems from the fact that there is a private
package or a private service station. It may very well denote something else, e.g., whether
the driver is hungry or thirsty or sleepy, etc. They are only aware of the existence of a
larger domain of private states.
Similar techniques can be used to show that the inner processes used by the manufacturers in the laptop example are not visible to other manufacturers: they are very much
like the different locations of the truck.
The above discussion makes it clear that distributed forward search is able to provide important privacy guarantees. Future work should seek to go beyond such domain-dependent
reasoning and provide general, domain independent conditions under which strong privacy
guarantees can be obtained. We believe that this is doable and that the ideas above are a
good starting point.
In this context, it is useful to keep in mind the following observations about the projected
sub-tree with ids: 1. No practical search algorithm will explore the entire search tree, and as
the extent of the search space explored decreases, the difficulty of identifying identical local
states increases. Our empirical results indicate that many problems can be solved quickly
using distributed forward search, without expanding too many nodes. It is questionable
whether it is possible to build reasonable models of agents private states in such cases.
325

fiNissim & Brafman

Here, both empirical and theoretical work  similar to that conducted on distributed CSPs,
is desirable. 2. It is not clear whether it is possible to identify two states that share similar
local states among only some of the agents, especially given a small portion of the search
tree. 3. The number of macros consisting of a sequence of private actions followed by a
private one is exponential. Thus, in a reasonable search process, only a small portion of them
will be visible. As anecdotal evidence we note that we actually attempted to construct such
macros in order to improve heuristic computation, but their number exploded so quickly,
that this became impractical.
Another interesting alternative is to develop variants of current algorithms that have
stronger privacy preserving properties. For example, consider the problem of inferring
upper bounds on the minimal cost of applying action a in public state s. In general, private
actions which achieve preconditions of a public action do not have to be applied immediately
before that public action  an agent can perform some of the private actions required for a
public action before a previous public action. In other words, an agent can distribute the
private cost of a public action between different segments, or parts of the plan between
two public actions, making the cost of the first action appear higher and the cost of the
second action lower, although with some potential impact on optimality. In the case of
non-optimal search, g-values are not disclosed, so this is not an issue.
The above example illustrates a general idea: one can trade-off efficiency for privacy.
A similar tradeoff is explored in the area of differential privacy (Dwork, 2006). There,
some noise is inserted into a database before statistical queries are evaluated, such that the
answer to the statistical query is correct to within some given tolerance, , yet one cannot
infer information about a particular entry in the database (e.g., describing the medical
record of an individual). Similarly, in our context, one can consider algorithms in which
agents refrain from sending certain public states with some probability, or send it with some
random delay, or even possibly, generate bogus, intermediate public states. Such changes
are likely to have some impact on running time and solution quality, and these tradeoffs
would be interesting to explore.
We believe that as this area matures, much like in the area of DisCSP, more attention
will be given to the problem of precise quantification of privacy and privacy loss. Our
work brings us closer to this stage. It offers algorithms for distributed search that start
to match that of centralized search, a general methodology for distributed forward search
that respects the natural distributed structure of the system, that can form a basis for such
extensions, and some initial ideas on how formal privacy proofs can work.
An additional privacy-related question is the specification of privacy properties. In
ma-strips the distinction between private and public variables is derived in a certain way
from the domain definition. Recent work that builds on ma-strips suggests a slightly
different treatment of privacy. For example, Bonisoli et al. (2014) allow for finer notions
of privacy, where variables can be private to a subset of agents, rather than to a single
agent. Moreover, the privacy requirements are part of the problem description, so that a
variable that would be private in ma-strips could be made public because its privacy is
not important to maintain. This extends earlier models, where the set of variables visible
to each agent is explicitly stated (Torreno, Onaindia, & Sapena, 2014), and where the set
of private variables of an agent is not derived, as in ma-strips but rather specified (Luis
& Borrajo, 2014). One might also consider distinguishing between public variables that are
326

fiDistributed Heuristic Forward Search

write-only public variables. For example, an agent may not know the value of a certain
variable, except immediately after it assigns it a value. It would be interesting to explore
the ability of our algorithms, as well as others, to exploit such notions of privacy.
9.2 Accurate Heuristics Given Incomplete Information
The empirical results presented lead us to what is perhaps the greatest practical challenge
suggested by mafs and mad-a*  computing an accurate heuristic in a distributed (privacypreserving) system. Despite theoretical results saying that even having almost perfect
heuristics can lead to large (exponential) search spaces (Helmert & Roger, 2008), practically,
having an accurate heuristic has a large effect on search efficiency. In some domains, the
existence of private information that is not shared leads to serious deterioration in the
quality of the heuristic function, greatly increasing the number of nodes expanded, and/or
affecting solution quality. We believe that there are techniques that can be used to alleviate
this problem. As a simple example, consider a public action apub that can be applied
only after a private action apriv . For example, in the Rovers domain, a send message can
only be applied after various private actions required to collect data are executed. If the
cost of apub known to other agents would reflect the cost of apriv as well, the heuristic
estimates would be more accurate. Another possibility for improving heuristic estimates is
using an additive heuristic. In that case, rather than taking the maximum of the agents
own heuristic estimate and the estimate of the sending agent, the two could be added. To
maintain admissibility, this would require using something like cost partitioning (Katz &
Domshlak, 2008). One obvious way of doing this would be to give each agent the full cost of
its actions and zero cost for other actions. The problem with this approach is that initially,
when the state is generated and the only estimate available is that of the generating agent,
this estimate is very inaccurate, since it assigns 0 to all other actions. In fact, the agent
will be inclined to prefer actions performed by other agents, as they appear very cheap, and
we see especially poor results in domains where different agents can achieve the same goal,
as in the Rovers domain, resulting in estimates of 0 for many non-goal states. Therefore,
how to effectively compute accurate heuristics in the distributed setting is an important
research challenge.
One of the first attempts to address this issue is a recent paper by Maliah et al. (2014).
Building on the ma-strips model and the mafs approach discussed here, It suggests a
mechanism for propagating information about landmarks among agents without revealing
private information. Using this approach each agent can detect more landmarks than those
detected on the projected problems, resulting in a more informative heuristic for each agent.

10. Summary
We presented a formulation of heuristic forward search for classical MA planning that respects the natural distributed structure of the system, preserving agent privacy. mafs
dominates the state-of-the-art distributed planners w.r.t. runtime and communication, as
well as solution quality in most cases. In this class of privacy-preserving algorithms, mad-a*
is the first cost-optimal distributed planning algorithm, and it is competitive with its centralized counterpart, despite having partial information. We have studied the strengths and
weaknesses of these methods, providing empirical evidence of our claims. Both algorithms
327

fiNissim & Brafman

were shown to be scalable, solving problems with up to 40 agents with high efficiency, especially in loosely-coupled domains. Our distributed planning framework MA-FD, provides
researchers with a good starting point for future research into new algorithms and heuristics
for the privacy-preserving MA setting.
There are many interesting directions for future research. Recently, the work presented
here formed the basis for our work on mechanism design for privacy-preserving MA planning
(Nissim & Brafman, 2013). Specifically, mad-a* is used as the underlying cost-optimal
planner in a distributed implementation of the Vickerey-Clarke-Groves mechanism. This
results in a distributed method for cost-optimal planning by self-interested agents with
private information. It will be interesting to further explore methods for computing more
accurate heuristics, and the inevitable trade-off between privacy, accurate heuristics and
communication complexity. One could also explore how to modify our methods to deal
with extensions to the ma-strips model (e.g. to include joint actions), and with different
solution criteria (e.g. makespan). Finally, the notion of private/public actions can be refined
to distinguish between read-write public actions and read-only ones. This distinction could
have an effect on search methods and heuristics, and is an interesting avenue for future
research.
Acknowledgments
The authors are grateful to the Associate Editor and the anonymous referees for many
useful suggestions and corrections. This work was supported in part by ISF grant 1101/07
and the Lynn and William Frankel Center for Computer Science.

References
Albore, A., Palacios, H., & Geffner, H. (2009). A translation-based approach to contingent
planning. In Boutilier, C. (Ed.), IJCAI, pp. 16231628.
Albore, A., Palacios, H., & Geffner, H. (2010). Compiling uncertainty away in nondeterministic conformant planning. In ECAI, pp. 465470.
Alkhazraji, Y., Wehrle, M., Mattmuller, R., & Helmert, M. (2012). A stubborn set algorithm
for optimal planning. In ECAI, pp. 891892.
Amir, E., & Engelhardt, B. (2003). Factored planning. In IJCAI, pp. 929935.
Backstrom, C. (1998). Computational aspects of reordering plans. J. Artif. Intell. Res.
(JAIR), 9, 99137.
Bernstein, D. S., Givan, R., Immerman, N., & Zilberstein, S. (2002). The complexity of
decentralized control of Markov Decision Processes. Math. Oper. Res., 27 (4), 819840.
Bonisoli, A., Gerevini, A., Saetti, A., & Serina, I. (2014). A privacy-preserving model for the
multi-agent propositional planning problem. In ICAPS14 Workshop on Distributed
and Multi-Agent Planning.
Brafman, R. I., & Domshlak, C. (2006). Factored planning: How, when, and when not. In
AAAI.
328

fiDistributed Heuristic Forward Search

Brafman, R. I., & Domshlak, C. (2008). From one to many: Planning for loosely coupled
multi-agent systems. In ICAPS, pp. 2835.
Brafman, R. I., Domshlak, C., Engel, Y., & Tennenholtz, M. (2009). Planning games. In
IJCAI, pp. 7378.
Brafman, R. I., Domshlak, C., Engel, Y., & Tennenholtz, M. (2010). Transferable utility
planning games. In AAAI.
Burns, E., Lemons, S., Ruml, W., & Zhou, R. (2010). Best-first heuristic search for multicore
machines. J. Artif. Intell. Res. (JAIR), 39, 689743.
Chandy, K. M., & Lamport, L. (1985). Distributed snapshots: Determining global states of
distributed systems. ACM Trans. Comput. Syst., 3 (1), 6375.
Chen, Y., & Yao, G. (2009). Completeness and optimality preserving reduction for planning.
In IJCAI, pp. 16591664.
Clarke, E. M., Biere, A., Raimi, R., & Zhu, Y. (2001). Bounded model checking using
satisfiability solving. Formal Methods in System Design, 19 (1), 734.
Coles, A. J., & Coles, A. (2010). Completeness-preserving pruning for optimal planning. In
ECAI, pp. 965966.
Conry, S. E., Kuwabara, K., Lesser, V. R., & Meyer, R. A. (1991). Multistage negotiation
for distributed constraint satisfaction. IEEE Transactions on Systems, Man, and
Cybernetics, 21 (6), 14621477.
Cox, J. S., & Durfee, E. H. (2005). An efficient algorithm for multiagent plan coordination.
In AAMAS, pp. 828835. ACM.
Cox, J. S., & Durfee, E. H. (2009). Efficient and distributable methods for solving the
multiagent plan coordination problem. Multiagent and Grid Systems, 5 (4), 373408.
Dwork, C. (2006). Differential privacy. In ICALP (2), pp. 112.
Ephrati, E., & Rosenschein, J. S. (1994). Divide and conquer in multi-agent planning. In
AAAI, pp. 375380.
Ephrati, E., & Rosenschein, J. S. (1997). A heuristic technique for multi-agent planning.
Ann. Math. Artif. Intell., 20 (1-4), 1367.
Fabre, E., & Jezequel, L. (2009). Distributed optimal planning: an approach by weighted
automata calculus. In CDC, pp. 211216. IEEE.
Fabre, E., Jezequel, L., Haslum, P., & Thiebaux, S. (2010). Cost-optimal factored planning:
Promises and pitfalls. In ICAPS, pp. 6572.
Franzin, M. S., Rossi, F., Freuder, E. C., & Wallace, R. J. (2004). Multi-agent constraint
systems with preferences: Efficiency, solution quality, and privacy loss. Computational
Intelligence, 20 (2), 264286.
Greenstadt, R., Grosz, B. J., & Smith, M. D. (2007). SSDPOP: improving the privacy of
DCOP with secret sharing. In AAMAS, p. 171.
Greenstadt, R., Pearce, J. P., & Tambe, M. (2006). Analysis of privacy loss in distributed
constraint optimization. In AAAI, pp. 647653.
329

fiNissim & Brafman

Grinshpoun, T., & Tassa, T. (2014). A privacy-preserving algorithm for distributed constraint optimization. In AAMAS14.
Gupta, D., Segal, A., Panda, A., Segev, G., Schapira, M., Feigenbaum, J., Rexford, J., &
Shenker, S. (2012). A new approach to interdomain routing based on secure multiparty computation. In HotNets, pp. 3742.
Hansen, E. A., & Zilberstein, S. (2001). LAO* : A heuristic search algorithm that finds
solutions with loops. Artif. Intell., 129 (1-2), 3562.
Haslum, P., & Geffner, H. (2000). Admissible heuristics for optimal planning. In AIPS, pp.
140149.
Helmert, M. (2006). The fast downward planning system. J. Artif. Intell. Res. (JAIR), 26,
191246.
Helmert, M., & Geffner, H. (2008). Unifying the causal graph and additive heuristics. In
ICAPS, pp. 140147.
Helmert, M., Haslum, P., & Hoffmann, J. (2007). Flexible abstraction heuristics for optimal
sequential planning. In ICAPS, pp. 176183.
Helmert, M., & Roger, G. (2008). How good is almost perfect?. In AAAI, pp. 944949.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: fast plan generation through
heuristic search. J. Artif. Int. Res., 14 (1), 253302.
Holte, R. C. (2010). Common misconceptions concerning heuristic search. In SOCS.
ICAPS.
The international planning competition.
ipc2011-deterministic/.

http://www.plg.inf.uc3m.es/

Katz, M., & Domshlak, C. (2008). Optimal additive composition of abstraction-based
admissible heuristics. In ICAPS, pp. 174181.
Kautz, H. A., & Selman, B. (1992). Planning as satisfiability. In ECAI, pp. 359363.
Keyder, E., & Geffner, H. (2009). Soft goals can be compiled away. J. Artif. Intell. Res.
(JAIR), 36, 547556.
Kishimoto, A., Fukunaga, A. S., & Botea, A. (2009). Scalable, parallel best-first search for
optimal sequential planning. In ICAPS.
Leaute, T., & Faltings, B. (2009). Privacy-preserving multi-agent constraint satisfaction.
In CSE (3), pp. 1725.
Luis, N., & Borrajo, D. (2014). Plan merging by reuse for multi-agent planning. In ICAPS14
Workshop on Distributed and Multi-Agent Planning.
Maheswaran, R. T., Pearce, J. P., Bowring, E., Varakantham, P., & Tambe, M. (2006).
Privacy loss in distributed constraint reasoning: A quantitative framework for analysis
and its applications. Autonomous Agents and Multi-Agent Systems, 13 (1), 2760.
Maliah, S., Shani, G., & Stern, R. (2014). Privacy preserving landmark detection. In
ECAI14.
Meisels, A. (2007). Distributed Search by Constrained Agents: Algorithms, Performance,
Communication (Advanced Information and Knowledge Processing). Springer.
330

fiDistributed Heuristic Forward Search

Mero, L. (1984). A heuristic search algorithm with modifiable estimate. Artif. Intell., 23 (1),
1327.
Nair, R., Tambe, M., Yokoo, M., Pynadath, D., & Marsella, S. (2003). Taming decentralized
pomdps: Towards efficient policy computation for multiagent settings. In IJCAI.
Nissim, R., Apsel, U., & Brafman, R. I. (2012). Tunneling and decomposition-based state
reduction for optimal planning. In ECAI, pp. 624629.
Nissim, R., & Brafman, R. I. (2013). Cost-optimal planning by self-interested agents. In
AAAI.
Nissim, R., Brafman, R. I., & Domshlak, C. (2010). A general, fully distributed multi-agent
planning algorithm. In AAMAS, pp. 13231330.
Nissim, R., Hoffmann, J., & Helmert, M. (2011). Computing perfect heuristics in polynomial
time: On bisimulation and merge-and-shrink abstraction in optimal planning. In
IJCAI, pp. 19831990.
Oliehoek, F. A., Witwicki, S. J., & Kaelbling, L. P. (2012). Influence-based abstraction for
multiagent systems. In AAAI.
Palacios, H., & Geffner, H. (2009). Compiling uncertainty away in conformant planning
problems with bounded width. J. Artif. Intell. Res. (JAIR), 35, 623675.
Petcu, A., & Faltings, B. (2005). A scalable method for multiagent constraint optimization.
In IJCAI, pp. 266271.
Petcu, A., Faltings, B., & Parkes, D. C. (2008). M-DPOP: Faithful distributed implementation of efficient social choice problems. J. Artif. Intell. Res. (JAIR), 32, 705755.
Ranjit, N., Varakantham, P., Tambe, M., & Yokoo, M. (2005). Networked distributed
pomdps: A synthesis of distributed constraint optimization and pomdps. In AAAI.
Silaghi, M.-C., & Mitra, D. (2004). Distributed constraint satisfaction and optimization
with privacy enforcement. In IAT, pp. 531535.
Srivastava, S., Immerman, N., Zilberstein, S., & Zhang, T. (2011). Directed search for
generalized plans using classical planners. In ICAPS.
Steenhuisen, J. R., Witteveen, C., ter Mors, A., & Valk, J. (2006). Framework and complexity results for coordinating non-cooperative planning agents. In MATES, pp. 98109.
Szer, D., Charpillet, F., & Zilberstein, S. (2005). MAA*: A heuristic search algorithm for
solving decentralized POMDPs. In UAI, pp. 576590.
Taig, R., & Brafman, R. I. (2013). Compiling conformant probabilistic planning problems
into classical planning. In ICAPS.
ter Mors, A., Valk, J., & Witteveen, C. (2004). Coordinating autonomous planners. In
IC-AI, pp. 795.
ter Mors, A., & Witteveen, C. (2005). Coordinating self interested autonomous planning
agents. In BNAIC, pp. 383384.
Torreno, A., Onaindia, E., & Sapena, O. (2012). An approach to multi-agent planning with
incomplete information. In ECAI, pp. 762767.
331

fiNissim & Brafman

Torreno, A., Onaindia, E., & Sapena, O. (2014). Fmap: Distributed cooperative multi-agent
planning. Applied Intelligence, 41 (2), 606626.
Valmari, A. (1989). Stubborn sets for reduced state space generation. In Applications and
Theory of Petri Nets, pp. 491515.
Vrakas, D., Refanidis, I., & Vlahavas, I. P. (2001). Parallel planning via the distribution of
operators. J. Exp. Theor. Artif. Intell., 13 (3), 211226.
Wehrle, M., & Helmert, M. (2012). About partial order reduction in planning and computer
aided verification. In ICAPS.
Wehrle, M., Helmert, M., Alkhazraji, Y., & Mattmuller, R. (2013). The relative pruning
power of strong stubborn sets and expansion core. In ICAPS.
Witwicki, S. J., & Durfee, E. H. (2010). Influence-based policy abstraction for weaklycoupled dec-pomdps. In ICAPS, pp. 185192.
Witwicki, S. J., Oliehoek, F. A., & Kaelbling, L. P. (2012). Heuristic search of multiagent
influence space. In AAMAS, pp. 973980.
Xu, Y., Chen, Y., Lu, Q., & Huang, R. (2011). Theory and algorithms for partial order
based reduction in planning. CoRR, abs/1106.5427.
Yang, Q., Wu, K., & Jiang, Y. (2007). Learning action models from plan examples using
weighted MAX-SAT. Artif. Intell., 171 (2-3), 107143.
Yao, A. C.-C. (1982). Protocols for secure computations (extended abstract). In FOCS, pp.
160164.
Yao, A. C.-C. (1986). How to generate and exchange secrets (extended abstract). In FOCS,
pp. 162167.
Yokoo, M., Durfee, E. H., Ishida, T., & Kuwabara, K. (1998). The distributed constraint
satisfaction problem: Formalization and algorithms. IEEE Trans. Knowl. Data Eng.,
10 (5), 673685.
Yokoo, M., Suzuki, K., & Hirayama, K. (2002). Secure distributed constraint satisfaction:
Reaching agreement without revealing private information. In CP, pp. 387401.
Yoon, S. W., Fern, A., & Givan, R. (2007). FF-Replan: A baseline for probabilistic planning.
In ICAPS, pp. 352.

332

fiJournal of Artificial Intelligence Research 51 (2014) 165-205

Submitted 05/14; published 09/14

Simple Regret Optimization in Online Planning
for Markov Decision Processes
Zohar Feldman
Carmel Domshlak

zoharf@tx.technion.ac.il
dcarmel@ie.technion.ac.il

Faculty of Industrial Engineering & Management,
Technion - Israel Institute of Technology,
Haifa, Israel

Abstract
We consider online planning in Markov decision processes (MDPs). In online planning,
the agent focuses on its current state only, deliberates about the set of possible policies from
that state onwards and, when interrupted, uses the outcome of that exploratory deliberation
to choose what action to perform next. Formally, the performance of algorithms for online
planning is assessed in terms of simple regret, the agents expected performance loss when
the chosen action, rather than an optimal one, is followed.
To date, state-of-the-art algorithms for online planning in general MDPs are either
best effort, or guarantee only polynomial-rate reduction of simple regret over time. Here
we introduce a new Monte-Carlo tree search algorithm, BRUE, that guarantees exponentialrate and smooth reduction of simple regret. At a high level, BRUE is based on a simple
yet non-standard state-space sampling scheme, MCTS2e, in which different parts of each
sample are dedicated to different exploratory objectives. We further extend BRUE with
a variant of learning by forgetting. The resulting parametrized algorithm, BRUE(),
exhibits even more attractive formal guarantees than BRUE. Our empirical evaluation
shows that both BRUE and its generalization, BRUE(), are also very effective in practice
and compare favorably to the state-of-the-art.

1. Introduction
Markov decision processes (MDPs) offer a very general framework for sequential decision
making under uncertainty (Puterman, 1994). An MDP hS, A, T r, Ri is defined by a set
of possible agent states S, a set of agent actions A, a stochastic transition function T r :
SAS  [0, 1] defined by a set of |S||A| conditional probability functions P(S | s, a), and
a reward function R : S  A  S  R. The current state of the agent is fully observable.
When the agent performs action a at state s, the state changes to s0 with probability
P(s0 | s, a), and the agent then collects a reward R(s, a, s0 ). In the finite horizon setting, the
reward is accumulated over some predefined number of steps H.
The objective of the agent is to act so to maximize its accumulated reward, and the
decision problem is always what action to perform next. For a state s, with h steps to go,
a (possibly stochastic) action policy  prescribes an action to be taken in this situation.
A policy is called optimal if, in expectation, following it guarantees maximization of the
accumulated reward. The key property of the MDP model is that, for any MDP, there is a
deterministic optimal policy   : S  {1, . . . , H}  A (Bellman, 1957).
c
2014
AI Access Foundation. All rights reserved.

fiFeldman & Domshlak

Efficiency of finding optimal policies for MDPs is the primary focus of the computational research around this model. When the state space of the MDP is too large for the
allowed planning time, reasoning about the MDP is narrowed to a state space region that
is considered most relevant to the specific decision problem currently faced by the agent.
In particular, algorithms for online reasoning about MDPs focus only on the current state
s0 of the agent, deliberate about the set of possible courses of action from s0 onwards, and,
when interrupted, use the outcome of that exploratory deliberation, or planning, to issue
an instant recommendation of an action to perform at s0 . Once that action is applied in
the real environment, the planning process is repeated from the obtained state to select the
next action and so on.
Depending on the problem domain and the representation language, concise descriptions
of large-scale MDPs can be either declarative or generative (or mixed). With declarative representations, both transition and reward functions are described explicitly, while with generative models, they are given by a black box simulator. While the palette of algorithms
for finding good actions in concisely represented MDPs is already rather wide (Boutilier,
Dean, & Hanks, 1999; Guestrin, Koller, Parr, & Venkataraman, 2003; Kolobov, Mausam,
& Weld, 2012; Busoniu & Munos, 2012; Bonet & Geffner, 2012; Keller & Helmert, 2013;
Mausam & Kolobov, 2012; Geffner & Bonet, 2013), most of these algorithms are applicable
only to declaratively represented MDPs. One of the earliest and best-known online planning algorithms developed for generative MDP models is the sparse sampling algorithm by
Kearns, Mansour, and Ng (2002). Sparse sampling offers a near-optimal action selection
in discounted MDPs by constructing a sampled lookahead tree in time exponential in the
discount factor and sub-optimality bound, but independent of the state space size. However, if terminated before an action has proven to be near-optimal, sparse sampling offers
no quality guarantees on its action selection.
In the last decade, Monte-Carlo tree search (MCTS) algorithms (Browne, Powley, Whitehouse, Lucas, Cowling, Rohlfshagen, Tavener, Perez, Samothrakis, & Colton, 2012) became
extremely popular in online planning for MDPs, as well as in online planning for many other
settings of sequential decision making, including those with partial state observability and
adversarial effects (Gelly & Silver, 2011; Sturtevant, 2008; Bjarnason, Fern, & Tadepalli,
2009; Balla & Fern, 2009; Eyerich, Keller, & Helmert, 2010; Browne et al., 2012). The
capability of dealing with generative problem representations was not the only feature of
MCTS that made these methods so popular. First, while MCTS algorithms can natively exploit problem-specific heuristic functions, their correctness is independent of the heuristics
properties, and they can as well be applied without any heuristic information whatsoever.
Second, numerous MCTS algorithms exhibit strong anytimeness: not only can a meaningful
action recommendation be provided at any interruption point instantly, in time O(1), but
the quality of the recommendation is also improved very smoothly, in time steps that are
independent of the size of the explored state space.
Formally, denoting by shhi the state s with h steps-to-go, the quality of the action a,
recommended for s0 hHi, is assessed in terms of the choice-error probability, that is, the
probability that a is sub-optimal, and in terms of the (closely related) measure of simple
regret [shhi, a]. The latter captures the performance loss that results from taking a and
then following an optimal policy   for the remaining h  1 steps, instead of following  
166

fiSimple Regret Optimization in Online Planning for MDPs

from the beginning (Bubeck & Munos, 2010).1 That is,
[shhi, a] = Q(shhi,   (shhi))  Q(shhi, a),
where

(
Es0 [R(s, a, s0 ) + Q (s0 hh1i,   (s0 hh1i))] ,
Q(shhi, a) =
0,

h > 0,
.
h=0

Numerous MCTS algorithms, and in particular, the popular UCT (Kocsis & Szepesvari,
2006) algorithm and its variants (Coquelin & Munos, 2007; Tolpin & Shimony, 2012),
guarantee eventual convergence to the optimal choice of action, while providing smooth
reduction of the choice-error probability and simple regret over planning time. The relative
empirical attractiveness of the various MCTS planning algorithms depends on the specifics
of the problem at hand and usually cannot be predicted ahead of time. However, when it
comes to formal guarantees on the expected performance improvement over the planning
time, none of the online MCTS algorithms for MDPs breaks the barrier of the worst-case
polynomial-rate reduction of simple regret and choice-error probability over time.
This is precisely our contribution here. Our work has been motivated by a recently
growing understanding that the current MCTS algorithms for MDPs do not optimize the
reduction of simple regret directly, but only via optimizing what is called cumulative regret,
a performance measure suitable for the (very different) setting of reinforcement learning
while acting (Bubeck & Munos, 2010; Busoniu & Munos, 2012; Tolpin & Shimony, 2012;
Feldman & Domshlak, 2012).
 Departing from this high-level realization, we discuss certain pitfalls in simple regret
minimization via Monte-Carlo sampling, and identify two, somewhat competing, exploratory objectives that should be pursued by the sampling mechanism. We then
suggest a principle of separation of concerns, whereby different parts of each statespace sample should be devoted to different exploration objectives.
 We introduce MCTS2e, a novel sampling scheme that specializes MCTS and implements that principle of separation of concerns. Our main result is in the introduction
and analysis of BRUE, a concrete instance of MCTS2e that guarantees smooth and
exponential-rate reduction of both the simple regret and the choice-error probability
over time, and this for general MDPs over finite state spaces. In fact, we show that
qualitatively similar guarantees are satisfied by a broad class of what we call purely
exploring MCTS2e algorithms, with BRUE being a simple yet efficient instance of this
class.
 Finally, we discuss and analyze the prospects of learning by forgetting, a principle according to which old samples are degraded as newer (and higher-quality) samples are gathered. Generalizing BRUE by extending it with this ingredient forms a
1. It may appear to the reader as more intuitive to consider the loss that results from applying the recommendations instead of   at all the H steps, and not just at the first one. However, as Kearns et al.
(2002) show in their Lemma 5, the two measures are closely related, with this alternative measure being
directly from simple regret along the execution horizon.

167

fiFeldman & Domshlak

parametrized algorithm BRUE(), with the parameter  controlling the level of forgetfulness. We show that BRUE() exhibits even more attractive formal guarantees
than those exhibited by BRUE.
The rest of the paper is structured as follows. In Section 2.2 we provide background
on Monte-Carlo tree search, and in particular, on the UCT algorithm. Then, in Section 3,
we discuss simple regret minimization in MDPs via a multi-armed bandits perspective,
and in Section 4, we introduce the principle of separation of concerns and establish our
main algorithmic constructs along with the corresponding computational results. Section 5
is devoted to learning with forgetting in MCTS, and in particular, to the algorithm
BRUE(). In Section 6 we discuss some findings of our empirical evaluation. The proofs
of the formal claims are relegated to Appendix B, the three subsections of which contain,
respectively, the proofs for the three key theorems. For completeness, Appendix A provides
some standard concentration inequalities that we use in the paper.

2. Background
Henceforth, A(s)  A denotes the actions applicable in state s, the operation of drawing a
sample from a distribution D over set  is denoted by  D[], U denotes uniform distribution, and JnK for n  N denotes the set {1, . . . , n}. For a sequence of tuples , [i] denotes
the i-th tuple along , and [i].x denotes the value of the field x in that tuple. When considering an MDP hS, A, T r, Ri, K denotes the state branching factor (maximal number of
actions per state), B denotes the action branching factor (maximal number of outcomes per
action), and  = mina6= (s0 ,H) [s0 hHi, a] denotes the minimal possible non-zero simple
regret at the root.
2.1 Sparse Sampling
One of the earliest and best-known online planning algorithms developed for generative
MDP models is the sparse sampling (SS) algorithm by Kearns et al. (2002). While SS has
been originally developed for infinite-horizon discounted MDPs, its reformulation for finite
horizon MDPs is straightforward as follows.
For each action a  A(s0 ), SS estimates its value Q(s0 hHi, a) by averaging C recursive samples of as outcome states. The outcome states s0 are sampled from the generative model of the transition function T r(s0 , a), and the value of such a sample is set to
R(s0 , a, s0 ) + maxa0 Q(s0 hH  1i, a0 ), with the Q-values of the actions a0  A(s0 ) being estimated recursively the same way, until hitting depth H. The number of outcome samples
C is set so to guarantee that the quality of the recommendation issued upon termination
of the algorithm meets a desired level of accuracy. Alternatively, given C, the same formal
analysis can be used to derive the corresponding accuracy guarantee. Equivalent bounds
on simple regret are as follows.
Proposition 2.1.1 Let SS be called on a state s0 of an MDP hS, A, T r, Ri with rewards in
[0, 1] and finite horizon H. Then, the simple regret of the action  SS (s0 hHi), recommended
by SS with parameter C > 0, is bounded as
E[s0 hHi,  SS (s0 hHi)]  H(K  min(B, C))H e
168

2 C
H4

.

fiSimple Regret Optimization in Online Planning for MDPs

The proof of Proposition 2.1.1 is given in Appendix C, p. 200. The bound in Proposition 2.1.1 suggests that the formal guarantees of SS become meaningful only when
H 5 log(K  min{B, C})
.
2
Assuming that B < C, this implies that the bound in Proposition 2.1.1 becomes non-trivial
only when the overall number of SS calls to the generative model is

O 2 H 5 log(BK)(BK)H .
(1)
C>

Notably, SS is not a strong anytime algorithm, but what is called a contract algorithm (Zilberstein, 1993): The termination of SS is parametrized by C, and interrupting SS before
its normal termination results in no meaningful action recommendation. However, knowing
the overall number of allowed calls to the generative model can in principle enable more
knowledgeable allocation of the deliberation efforts (Hay, Shimony, Tolpin, & Russell, 2012).
Hence, in general, deliverables of the contract algorithms are expected to be better than
deliverables of the, de facto similarly budgeted, strong anytime algorithms (Zilberstein,
1993). Therefore, the bound in (1) sets a good reference for understanding the significance
of formal guarantees provided by strong anytime algorithms for online MDP planning.
2.2 Monte-Carlo Tree Search and UCT

MCTS, a canonical scheme for Monte-Carlo tree search that gives rise to various specific
algorithms for online MDP planning, is depicted in Figure 1, on the left. MCTS explores
the state space in the radius of H steps from the initial state s0 by iteratively rolling out
state-space samples from s0 . Each such rollout  comprises a sequence of simulated steps
hs, a, s0 , ri where s is a state, a is an action applicable in s, s0 is a state resulting from
applying a at s, and r is the corresponding immediate reward. In particular, [0].s = s0
and [t].s0 = [t+1].s for all t.
Each generated rollout is used to update some variables of interest associated with the
states visited and actions applied therein. These variables typically include at least the
b
action value estimators Q(shhi,
a), as well as the counters n(shhi, a) that keep the number
b (shhi, a) have been updated. The rollout-oriented
of times the corresponding estimators Q
exploration of MCTS allows information from states at deeper levels to be propagated to
the root s0 hHi in low-complexity iterations of O(H). This allows smooth improvement of
the intermediate quality of recommendation, which is probably one of the main reasons that
MCTS seems particularly appealing in the context of online planning.
Instances of MCTS vary mostly along the different implementation of the strategies
 StopRollout, specifying when to stop a rollout;
 RolloutAction, prescribing an action to apply in the current state of the rollout;
and
 Update, specifying how a rollout should expand the tree T and update the maintained
variables stored at the nodes of the constructed search tree.2
2. Due to the Markovian nature of MDPs, it is unreasonable to distinguish between nodes associated with
the same state at the same depth. Hence, the actual graph constructed by most instances of MCTS
forms a directed acyclic graph over nodes shhi  S  {0, 1, . . . , H}.

169

fiFeldman & Domshlak

MCTS: [input: hS, A, T r, Ri; s0  S]

procedure Update()
r  0
for d  ||, . . . , 1 do
hH d
a  [d].a
n(shhi)  n(shhi) + 1
n(shhi, a)  n(shhi, a) + 1
r  r +  [d] .r
MC-backup(shhi, a, r)

while time permits do
  Rollout // generate rollout
Update()
b 0 hHi, a)
return arg maxa Q(s
procedure Rollout
  hi
s  s0
d0
while not StopRollout() do
hH d
a  RolloutAction(shhi)
s0  RolloutOutcome(shhi, a)
r  R (s, a, s0 )
 [t]  hs, a, r, s0 i
s  s0 ; d  d + 1
return 

procedure MC-backup(shhi, a, r)
1
b
b
Q(shhi,
a)  n(shhi,a)1
Q(shhi,
a) + n(shhi,a)
r
n(shhi,a)
procedure StopRollout()
d  ||
return d = H or A([d].s0 ) = 
procedure RolloutAction(shhi) // UCB
if a : n (shhi, a) = 0 then
return a
q
h
i
n(shhi)
b
return argmaxa Q(shhi,
a) + c log
n(shhi,a)
procedure RolloutOutcome(shhi, a)
return s0  P(S | s, a)

Figure 1: A template for MCTS algorithms (left) , and the UCT algorithm as a specific set
of sub-routines for MCTS (right).

Once interrupted, MCTS uses the information collected throughout the exploration to recommend an action to perform at state s0 .
Numerous concrete instances of MCTS have been proposed, with the UCT algorithm
(Kocsis & Szepesvari, 2006) and its modifications (Coquelin & Munos, 2007; Tolpin &
Shimony, 2011) being the most popular such instances these days (Gelly & Silver, 2011;
Sturtevant, 2008; Bjarnason et al., 2009; Balla & Fern, 2009; Eyerich et al., 2010; Keller &
Eyerich, 2012). The specification of the UCT algorithm as an instance of MCTS is depicted
in Figure 1, on the right.
 Different versions of UCT use different rules to end a rollout. In the version depicted
here, rollouts end at terminal nodes, that is, either at depth H or at states with no
applicable actions.3
 The RolloutAction policy of UCT is based on the deterministic decision rule
UCB1 (Auer, Cesa-Bianchi, & Fischer, 2002), originally proposed for optimal balance
between exploration and exploitation for cumulative regret minimization in stochastic
3. In a more popular version of UCT, the search tree is grown incrementally, by ending the rollouts whenever
a new node is encountered. However, this point is extraneous for the exposition of this paper.

170

fiSimple Regret Optimization in Online Planning for MDPs

multi-armed bandit (MAB) problems (Robbins, 1952). At node shhi, the next-onthe-sample action a is selected as follows: If all the actions applicable in s have been
sampled by now at shhi, that is, if n(shhi, a) > 0 for all a  A(s), then the selected
action corresponds to
s
"
#
log
n(shhi)
b
argmax Q(shhi,
a) + c
,
(2)
n(shhi, a)
a

where c > 0 is a fixed parameter that balances between the first, exploitation-oriented,
and the second, exploration-oriented, summands in Eq. 2. Otherwise, a is selected
uniformly at random from the still unexplored actions {a  A(s) | n(shhi, a) = 0}. In
both cases, the procedure sample-outcome of UCT then samples the next state on
the rollout according to the transition probability P(S | s, a).
b
 UCT updates all the value estimators Q(shhi,
a) of the (shhi, a) pairs encountered
along the rollouts. The updates are done via the MC-backup procedure, which
averages the accumulated rewards of the rollouts from shhi to terminal states.
In terms of formal properties, UCT is an online algorithm that, from a certain point in
time, provides a smooth reduction of simple regret over time to zero, that is, a smooth convergence to the optimal action choice at s0 hHi (Kocsis & Szepesvari, 2006). Two aspects of
convergence are of interest: (1) the length of the transition period during which no reduction of simple regret can be guaranteed at all, and (2) the reduction rate of simple regret
over time, after the transition period is over. Considering (1), Coquelin and Munos (2007)
showed that the number of samples after which the bounds of UCT on simple regret become
meaningful might be as high as hyper-exponential in H. Considering (2), Theorem 6 in the
work of Kocsis and Szepesvari (2006) claims a polynomial-rate reduction of the probability
of choosing a non-optimal action, which implies the same for the simple regret4 .
Some attempts have recently been made to improve UCT, and online MCTS-based planning in general, in terms of these two aspects of convergence (Tolpin & Shimony, 2012; Hay
et al., 2012; Coquelin & Munos, 2007). While the reported empirical results were promising, none of these suggested MCTS instances breaks the UCTs barrier of the worst-case
polynomial-rate reduction of simple regret over time. Hence, the question of whether an
online, smoothly converging MCTS algorithm can substantially outperform UCT in terms
of these two convergence parameters remained open. In what comes next, we answer this
question affirmatively.

3. Simple Regret Minimization in MDPs
At a high level, the key property of UCT is that its exploration of the search space is obtained
by considering a hierarchy of forecasters (s, h), each minimizing its own cumulative regret,
that is, the loss of the total reward incurred while exploring the environment (Auer et al.,
2002). In that respect, according to Theorem 6 in the work of Kocsis and Szepesvari (2006),
UCT asymptotically achieves the best possible (logarithmic) cumulative regret. However, as
recently pointed out in numerous works (Bubeck & Munos, 2010; Busoniu & Munos, 2012;
4. Notably, these claims are made under some nontrivial assumptions

171

fiFeldman & Domshlak

Tolpin & Shimony, 2012; Feldman & Domshlak, 2012), cumulative regret does not seem to
be the right objective for online MDP planning, and this is because the rewards collected
at the simulation phase are fictitious. Furthermore, the work of Bubeck, Munos, and Stoltz
(2011) on multi-armed bandits shows that minimizing both the cumulative and the simple
regret are somewhat competing objectives, in the sense that the minimal simple regret can
increase as the bound on the cumulative regret decreases.
This relationship between simple and cumulative regret minimization in MABs suggests
that focusing online MDP planning directly on simple regret minimization may lead to algorithms that are, worst-case and/or empirically, substantially more effective than UCT. In
fact, in the context of MABs, Bubeck et al. (2011) already showed that a simple round-robin
sampling of MAB actions, followed by recommending the action with the highest empirical
mean, yields exponential-rate reduction of simple regret, while the UCB1 sampling strategy
that balances between exploration and exploitation yields only polynomial-rate reduction of
that measure. In that respect, the situation with MDPs is seemingly no different. In fact,
although designed for a slightly different setup, the sparse sampling algorithm provides an
evidence for the theoretical merits of being focused solely on exploration in online planning
for MDPs.
It appears, however, that the answer to the question of how one should focus on exploration, while preserving both onlineness and smoothness of convergence, is less straightforward in general MDPs than it is in the special case of MABs. Before we motivate and
discuss the various exploratory concerns in online Monte-Carlo planning for MDPs, and
what the separation of these concerns can possibly buy us, we begin with a MAB perspective on MDPs, which shows that smooth exponential-rate reduction of simple regret in
MDPs is indeed achievable, at least theoretically.
3.1 Multi-armed Bandit Perspective on MDPs
Let s0 be a state of an MDP hS, A, T r, Ri with rewards in [0, 1], and a finite horizon H.
In principle, such a general MDP can be viewed as a MAB, with each arm in the MAB
corresponding to a flat policy of acting for H steps starting from the current state s0 .
A flat policy  is a minimal partial mapping from state/steps-to-go pairs to actions that
fully specifies an acting strategy in the MDP for H steps, starting at s0 . Sampling such an
arm  is straightforward as  prescribes precisely which action should be applied at every
state that can possibly be encountered along the execution of . The reward of such an
arm  is stochastic, withPsupport [0, H], and expected value  . The number of arms in
H1 i
H
this schematic MAB is K i=0 B  K B . Now, consider a simple algorithm, NaiveUniform,
which systematically samples each flat policy in a loop, and uses the obtained reward to
update the empirical mean 
b of the corresponding policy arm . If stopped at iteration
n, the algorithm recommends the policy arm n with the best empirical value 
bn . By
iteration n of this algorithm, each arm will be sampled at least b Bn H c times. Therefore,
K
using Hoeffdings tail inequality5 , the probability that the chosen arm policy n is sub-

5. For completeness, Hoeffdings tail inequality is provided in Appendix A, pp. 188.

172

fiSimple Regret Optimization in Online Planning for MDPs

optimal in our MAB is upper-bounded by
X

6= 

P {b
 > 
b } =

X

b

6= 

P {b
  
b  ( )   }  K

BH 

e

n c2
H
KB
2H 2

,

(3)

where  =    and  = min6=  . Denoting the simple regret of n by rn , the
expected simple regret can therefore be bounded as
b

Ern  HK

BH 

e

n c2
H
KB
2H 2

.

(4)

Note that NaiveUniform uses each rollout  = hs0 hHi, a1 , s1 hH 1i, . . . , aH , sH h0ii to
update the estimation of only a single policy . However, recalling that arms in our MAB
problem are actually compound policies, the same sample can in principle be used to update
the estimates of all policies  0 that are consistent with  in the sense that, for 0  i  H 1,
 0 (si hH ii) is defined and  0 (si hH ii) = ai+1 . The resulting algorithm, CraftyUniform,
generates samples by choosing the actions along the sample uniformly at random, and uses
the outcome of each sample to update all the policies consistent with it. Note that the
policy arms in CraftyUniform cannot be sampled systematically as in NaiveUniform because
the set of policies updated at each iteration is stochastic.
Since the sampling is uniform, the probability of any policy to be updated by a sample
issued at any iteration of CraftyUniform is K1H . Let N  n denote the number of samples consistent with the policy  among the first n samples issued by CraftyUniform. The
probability
that n , the best empirical arm after n iterations, is sub-optimal is bounded by
P
P
{b

b } where

 >
6=



P {b
 > 
b }  P 
b   
2





+P 
b  



2



.

(5)

Each of the two terms on the right-hand side can be bounded as:




n

n o
n

 P N 
+ P N >
, 
b   
P 
b   
2
2K H
2K H
2
fi


n
X
()
 fifi
 nH
N = i
 e 8K +
P {N = i} P 
b   
2 fi
n
i=

e



n
8K H

e



n
8K H

()

e



n
8K H



 2e

2K H

+1

fi
 X
n
 fifi
n
+P 
b   
N
=
+
1
P {N = i}

2 fi
2K H
n
i= H +1
2K
fi


 fifi
n
+P 
b,n   
N =
+1
2 fi
2K H




+e

n2

8K H H 2

n2

4K H H 2

,
(6)
173

fiFeldman & Domshlak

where () and () are by Hoeffdings tail inequality. In turn, similarly to Eq. 4, the simple
regret for CraftyUniform is bounded by
H

Ern  4HK B e



n2
8K H H 2

.

(7)

Since H is a trivial upper-bound on Ern , the bound in Eq. 7 becomes effective only when
H

4K B e



n2
8K H H 2

< 1, that is, for
H

n > (KB)  4



H


2

log K.

(8)

Note that this cold start transition period is much shorter than that of UCT, which can
be hyper-exponential in H. At the same time, unlike in UCT, the rate of the simple regret
reduction here is exponential in the number of iterations. In terms of oracle calls, the length
of the transition period for CraftyUniform is


O 2 H 3 log(K) (KB)H .
Likewise, comparing to sparse sampling (Eq. 1), it appears that the transition period of
CraftyUniform has a smaller dependency on H (H 3 vs. H 5 ), and a smaller dependency on
B (log(K) vs. log(BK)).
In sum, CraftyUniform can be seen as a theoretical feasibility test for our agenda: The
algorithm uses Monte-Carlo sampling and averaging updates, it is strong anytime (action
recommendation can be issued instantly, at any time, and the expected quality of the
recommendation improves after every state-space sample), and simple regret decreases at
an exponential rate over time. Moreover, the transition period after which this reduction
rate is guaranteed is somewhat shorter than the (contracted) transition period of SS, and it
is much shorter than the transition period of UCT. In any case, however, the feasibility of
H
CraftyUniform is only conceptual: it requires explicit reasoning about K B arms, and thus
it cannot be efficiently implemented.

4. Separation of Concerns in Online MDP Planning
We now show a practical algorithm that achieves smooth, exponential-rate reduction of
simple regret in online MDP planning. To do so, we first motivate and introduce a principle
of separation of concerns, whereby different parts of each state-space sample are devoted
to different aspects of problem exploration. We then introduce MCTS2e, a specialized
MCTS sampling scheme that implements that principle of separation of concerns via
a two-phase scheme for generating state-space samples. Using MCTS2e as our basis, we
describe a concrete algorithm, BRUE, that achieves exponential-rate, smooth reduction of
simple regret over time, and has a transition period comparable to these of the schematic
CraftyUniform and of the non-interruptible SS. In fact, we show that these formal guarantees
are satisfied by the entire class of what we call purely exploring MCTS2e algorithms, one
of which is BRUE.
If we tried to achieve smooth, exponential-rate convergence by merely replacing the
UCB1 policy of UCT with a pure exploration policy such as uniform action selection, then
174

fiSimple Regret Optimization in Online Planning for MDPs

we would have failed miserably. In fact, this naive attempt would result in an algorithm
that does not even converge to the optimal action. The reason for that lies in a fundamental
difference between MABs and MDPs: Unlike in MABs, direct sampling of the actual value
of the actions is impossible because doing so requires knowledge of the optimal policy at
subsequent states in the entire look-ahead space. This knowledge, however, is unavailable
at the beginning of deliberation. Hence, when sampling the futures, each non-root node
shhi should actually serve two objectives:
(1) estimating the actions at the ancestor(s) of shhi in T , and
(2) identifying the optimal action   (shhi).
While both these objectives are exploratory, they are in opposition to some extent. To
meet the first objective, shhi should sample its optimal action   (shhi) with a probability
approaching 1 as the number of samples grows. To meet the second objective, however, all
actions at shhi must be selected frequently. When the same protocol for selecting actions is
used, as in UCT, throughout the entire rollout, and the rewards collected along this rollout
are used for updating value estimations at multiple nodes, this protocol should commit to
addressing these two objectives simultaneously. For instance, the UCB1 protocol employed
by UCT at all nodes shhi chooses the action that seems most attractive in potential, where
this potential stems partially from the relatively high empirical value (complying with objective (1)), and partially from the less frequent sampling of that action (complying with
objective (2)).
However, while such an overloading of the action selection protocol is unavoidable in
the learning while acting setup of reinforcement learning, this is not the case in online
planning. In some sense, the two objectives depicted above resemble the two tasks faced by
MAB forecasters: objective (1) can be seen as a type of recommendation, whereas objective
(2) can be viewed as exploration. It therefore makes perfect sense to fulfill these two
objectives by different policies, much like exploration and recommendation are handled by
different policies in MAB online planning (Bubeck et al., 2011). More specifically, different
policies can be used to choose the method by which node/action pairs should be updated
and the method by which the values of these pairs should be estimated. In what follows,
we refer to this separation of exploratory objectives as separation of concerns, and next
we elaborate on the implementation of this concept in online planning for MDPs.
4.1 Two-Phase Sampling and BRUE
We now introduce a novel Monte-Carlo tree search scheme, MCTS2e, tailored towards employing the principle of separation of concerns. MCTS2e is depicted in Figure 2(a) as
a specification of MCTSs Update procedure. The core difference between the MCTS2e
implementation of Update and that of UCT is in the samples used to update the value
estimators. As illustrated in Figure 3, the value estimators in UCT are updated with the
accumulated reward from the respective tail of the rollout, whereas in MCTS2e the estimators are updated with the accumulated reward of new sub-rollouts, created by the Estimate
procedure.
The Estimate procedure is parametrized with two policies, namely
 EstAction, prescribing the action used for estimation, and
175

fiFeldman & Domshlak

procedure Update()
for d  ||, . . . , 1 do
hH d
hs, a, r, s0 i  [d]
n(shhi)  n(shhi) + 1
n(shhi, a)  n(shhi, a) + 1
n(shhi, a, s0 )  n(shhi, a, s0 ) + 1
r  r + Estimate(s0 hh  1i)
MC-backup(shhi, a, r)

procedure StopRollout()
d  ||
return d = H or A([d].s0 ) = 
procedure RolloutAction(shhi)
return a  U[A(s)]

// uniform

procedure RolloutOutcome(shhi, a)
return s0  P(S | s, a)

procedure Estimate(shhi)
r  0
for d  0, . . . , h  1 do
a  EstAction(shh  di)
s0  EstOutcome(shh  di, a)
rd+1  R (s, a, s0 )
r  r + rd+1
s  s0
return r

procedure EstAction(shhi) // best
b
return argmaxaA(s) Q(shhi,
a)
procedure EstOutcome(shhi, a)
for s0 : n(shhi, a, s0 ) > 0 do
0
b = s0 | s, a)  n(shhi,a,s )
P(S
n(shhi,a)
b | s, a)
return s0  P(S

(a)

(b)

Figure 2: (a) MCTS2e as MCTS with specific Update procedure, and (b) the BRUE algorithm as a specific set of sub-routines for MCTS2e (right).

 EstOutcome, determining the next state to follow.
The policies RolloutAction and RolloutOutcome (used by the MCTSs Rollout
procedure) determine what value estimators to update, while the policies EstAction and
EstOutcome are used to update these estimators.
This separation allows us to introduce BRUE, which is, in a way, the most exploratory
MCTS2e instance possible.6 The BRUE setting of MCTS2e is depicted in Figure 2(b).
Similarly to UCT, the rollouts generated in BRUE end at terminal nodes, and, throughout
the rollout, the next state is sampled according to T r. However, unlike in UCT, the rollout
actions in BRUE are selected uniformly at random from all the applicable actions. In turn,
in the estimation sub-rollouts,
 the selected actions are the empirically best actions, that is, the actions that have the
highest value estimations, and
b =
 the next states are sampled according to the empirical transition probabilities P(S
0
0
s | s, a), that is, the number of times n(shhi, a, s) state s was followed when applying
6. Short for Best Recommendation with Uniform Exploration; the name is carried on from our first
presentation of the algorithm, where estimation was referred to as recommendation (Feldman &
Domshlak, 2012).

176

fiSimple Regret Optimization in Online Planning for MDPs

UCT

MCTS2e

b ([d].s, [d].a)
Q

H
Xd

b ([d].s, [d].a)
Q

H
X1

ri

i=1

[i].r

i=d

(a)

(b)

Figure 3: Illustration of a value estimator update in MCTS2e (a) vs. UCT (b). Circles
represent decision nodes, solid lines represent the actions taken, squares represent
the chance nodes, and dashed arrows represent the outcomes that result in the
subsequent decision nodes.

action a in node shhi, divided by the overall number of times n(shhi, a) that action a
was applied in shhi.7
We now proceed with a formal analysis of BRUE. In general, when considering an
instance of MCTS2e, by Tn we denote the search graph obtained after n iterations. For the
sake of simplicity, we assume uniqueness of the optimal policy   : at each state s and each
number h of steps-to-go, we assume a single optimal action, and denote it by   (s, h). For
all nodes shhi  Tn , nB (shhi) is a randomized strategy, uniformly choosing among actions
b
a maximizing Q(shhi,
a). In addition to the problem-specific state branching factor K, and
minimal non-zero simple regret at the root  = mina6= (s0 ,H) [s0 hHi, a], our bounds below
depend on the problem-specific action branching factor B, as well as on the horizon H. The
former two parameters are inherited from MAB, while the latter two connect between MAB
and general MDP.
Theorem 1 Let BRUE be called on a state s0 of an MDP hS, A, T r, Ri with rewards in
[0, 1], and finite horizon H. There exist pairs of parameters a, b > 0, dependent only on
7. Sampling according to P(S | s, a) as in RolloutOutcome is also a valid choice, although in terms of
formal guarantees, EstOutcome as in Figure 2 appears to be more attractive.

177

fiFeldman & Domshlak

{K, B, H, }, such that, after n > H iterations of BRUE, the simple regret is bounded as
E[s0 hHi, nB (s0 hHi)]  Ha  ebn ,
and the choice-error probability is bounded as

	
P nB (s0 hHi) 6=   (s0 hHi)  a  ebn .
In particular, Eq. 9 and 10 hold with a = 3K

b=

2
.
9K 2 (196BK)H1 H 2



1044B 2 K 2
2

H1

(9)

(10)
1

2

(196BK) 2 (H1) (H  1)!2 and

The proof of Theorem 1 is given in Appendix B.1, p. 188. The length of the transition
period implied by Theorem 1 is given by


BK
2 5
H
O  H log(
)(196BK)
(11)

This transition period is rather comparable to that of sparse sampling except for the rather
large constant appearing in the basis of the exponent in Equations 9 and 10. Although this
constant imposes a significant increase of the transition period, few things should be noted
with regards to the bounds provided for BRUE. First and foremost, the parameter b in
Theorem 1 reflects the worst-case in terms of the transition function T r, which corresponds
to a uniform distribution, that is, P(s0 | s, a) = B1 for all states s and actions a  A(s).
However, if the probability mass of the action transition functions each concentrates on a
small set of outcomes, then the convergence rate of BRUE is expected to be much better.
Proposition 4.1.1 formulates BRUEs bounds with respect to a problem-dependent parameter
1  Pe  B, which is related to the entropy of the transition function and is defined as
Pe = max kP( | s, a)k 1 .
s,a

2

Proposition 4.1.1 Let BRUE be called on a state s0 of an MDP hS, A, T r, Ri with rewards in [0, 1], and finite horizon H  4. Then BRUE converges at an exponential rate
H1
(H!)2 and b =
in the sense of Eq. 9 and 10 of Theorem 1 with a = 3K 172BK
2
2
.
4
H1 H5 2
9KB (1666K)

Pe

H

The formal guarantees of BRUE can therefore be even better than these for SS. The proof for
Proposition 4.1.1 (given in Appendix B.2, p. 195) is obtained by a rather minor modification
of the proof for Theorem 1.
Relating to the tightness of the bounds, it should be noted that the size of the scalar
constants in the analysis of BRUE partially stems from our attempt to avoid cumbersome
expressions, and thus can be considerably reduced. Furthermore, in a particular point in
our analysis where we bound the error of action-value estimations at different points in
time, we believe that our bound gets particularly loose. We comment about this issue in
more detail within the proof of Theorem 1 (right after Proposition B.1.1, p. 190).
Having read this far, the reader may rightfully ask to what extent the guarantees provided by BRUE are unique among the instances of MCTS2e. In general, the formal properties
178

fiSimple Regret Optimization in Online Planning for MDPs

of MCTS2e instances heavily depend on their specific sub-routines, and some of them will
not even guarantee convergence to the optimal action. However, BRUE is still very much
not unique in its deliverables. In particular, below we define a family of purely exploring MCTS2e algorithms that all guarantee exponential-rate reduction of simple regret over
time.8
Definition 1 (Purely exploring MCTS2e) An instance A of MCTS2e is called purely
exploring if, for each node shhi reachable from s0 , and each a  A(s), there exist parameters
, , , dependent only on {K, B, H, }, such that
P {n(shhi, a)  n(shhi)}  en(shhi) ,
and the estimation policy EstAction selects the empirically best arm.
Theorem 2 Let A be a purely exploring instance of MCTS2e. Then A converges at an
exponential rate in the sense of Eq. 9 and 10 of Theorem 1.
In Appendix B.3, p. 195 we show how a proof of Theorem 2 can be easily derived from
our proof of Theorem 1. Furthermore, the analysis provided in the proof for Theorem 1
can be used to extract the convergence parameters c, c0 for any purely exploring algorithm,
given its specific parameters , , .

5. Learning With Forgetting and BRUE()
In BRUE, as well as in other converging instances of both MCTS and MCTS2e, the evolution
of action value estimates at the internal nodes is based on biased samples that stem from
the selection of non-optimal actions at the descendant nodes. This bias tends to shrink as
more samples are accumulated at these descendants. Consequently, the estimates become
more accurate, the probability of selecting an optimal action increases accordingly, and the
bias of the ancestor nodes shrinks in turn.
An interesting question that arises in this context is whether samples obtained at different stages of the sampling process should be weighed differently. At a high level, our
intuition suggests that biased samples do provide us with some valuable information, especially when they are still all we have. At the same time, the value of this information
decreases as we obtain more accurate samples. Hence, in principle, putting more weight
on samples with smaller bias could increase the accuracy of our estimates. This led us to
consider BRUE(), an algorithm that generalizes BRUE  BRUE(1) by basing the estimates
only on the  fraction of most recent samples.
Technically, BRUE() differs from BRUE only in the implementation of the MC-backup
procedure as depicted in Figure 4. In addition to the variables maintained by BRUE,
each node/action pair (shhi, a) in BRUE() is associated with a list L(shhi, a) of rewards,
collected at each of the n(shhi, a) samples that are responsible for the current estimate
b
b
Q(shhi,
a). When (shhi, a) is updated by MC-backup, the value estimator Q(shhi,
a) is
assigned with the average of the most recent d  n(shhi, a)e samples, where dxe denotes the
8. We, of course, make no claims that these guarantees are exclusive to the purely exploring instances of
MCTS2e, or even to MCTS2e instances in general.

179

fiFeldman & Domshlak

procedure MC-backup(shhi, a, r)
n  d  n(shhi, a)e
n  n(shhi, a)
L(shhi, a)[n]  rP
b
Q(shhi,
a)  n1 ni=nn L(shhi, a)[i]

Figure 4: BRUE() modified MC-backup procedure

smallest integer that is greater than or equal to x. Theorem 3 below exhibits the benefits
of adopting  < 1 when it comes to convergence guarantees.
Theorem 3 Let BRUE() be called on a state s0 of an MDP hS, A, T r, Ri with rewards
in [0, 1] and finite horizon H. There exist pairs of parameters a, b > 0, dependent only
on {K, B, H, , }, such that, after n > H iterations of BRUE (), we have simple regret
bounded as
E[s, nB (s0 , H), H]  Ha  ebn ,
(12)
and choice-error probability bounded as

	
P nB (s0 , H) 6=   (s0 , H)  a  ebn .

(13)

1
In particular, for a depth-dependent h  (BK)
h1 , Eq. 12 and 13 hold with

H1
2
a = 3K 12BK
(H!)2 and b = 9K 2 (196BK)
H1 H 2 .
2

For the particular choice of h in Theorem 3, the length of the transition period of
BRUE() in terms of number of calls to the generative model is




BKH
2 4
H
O  H log
(196BK)
.


While the bound for BRUE() seems somewhat better than that of BRUE, this improvement should be attributed more to the looseness of the bound for BRUE and less to the
actual improvement in performance. The proof for Theorem 3 (given in Appendix B.4,
p. 196) does not offer a new technique to address the bound on the accuracy of action-value
estimations at different sampling times, but it reduces the bound by considering fewer samples. The selection of  in Theorem 3 stems from an attempt to balance as much as possible
between the two sources of inaccuracy appearing in Propositions B.4.1 and B.4.2 of the proof
for Theorem 3. The smaller  is, the lower is the sample inaccuracy that originates from
the inaccuracy of the estimates at the successor nodes. At the same time, however, the
inaccuracy that stems from basing the estimate on a fewer samples increases. Due to the
branching, nodes farther toward the horizon are sampled less frequently and thus are less
accurate. In the worst case, when the underlying graph Tn is a tree, a node is expected
1
to be sampled only a fraction (BK)
d of the number of samples that were taken at its d
steps higher predecessor. This is precisely the reason for the selection of h 
Theorem 3.
180

1
(BK)h1

in

fiSimple Regret Optimization in Online Planning for MDPs

In practice, however, these worst-case considerations tend to underrate the value of
samples. Since Tn is typically not a tree, the ratio between the number of samples at
different depths tends to be higher than the aforementioned worst-case ratio. Therefore,
 should better be adapted according to the observed ratios rather than according to the
worst-case ones. Furthermore, since our objective behind estimating the action values is
to identify the optimal action, the bias of the samples may have far less influence on the
quality of the planning outcome than that dictated by the formal guarantees. For instance,
suppose that all action estimators at a particular node shhi have an equal bias. If this is
b
the case, then shhi may home in on its optimal action while Q(shhi,
a) estimates are still
biased, and that will suffice for shhi to fulfill its role in value-estimating sub-rollouts issued
by its ancestor(s). While this illustrative setup is clearly extreme, the point here is that
biased estimators can still distinguish the better actions from the worse ones, as long as the
biases across the actions are correlated.

6. Experimental Evaluation
We have evaluated BRUE empirically on the MDP Sailing domain (Peret & Garcia, 2004),
used in previous works for evaluating MCTS algorithms (Peret & Garcia, 2004; Kocsis &
Szepesvari, 2006; Tolpin & Shimony, 2012), as well as on an MDP version of random game
trees used in the original empirical evaluation of UCT (Kocsis & Szepesvari, 2006).
In the Sailing domain, a sailboat navigates to a destination on an 8-connected grid
representing a marine environment, under fluctuating wind conditions. The goal is to reach
the destination as quickly as possible, by choosing at each grid location a neighbor location
to move to. The duration of each
 such move depends on the direction of the move (ceteris
paribus, diagonal moves take 2 more time than straight moves), the direction of the wind
relative to the sailing direction (the sailboat cannot sail against the wind and moves fastest
with a tail wind), and the tack. The direction of the wind changes over time, but its strength
is assumed to be fixed. This sailing problem can be formulated as a goal-driven MDP over
finite state space and a finite set of actions, with each state capturing the position of the
sailboat, wind direction, and tack.
In a goal-driven MDP, the lengths of the paths to a terminal state are not necessarily
bounded, and thus it is not entirely clear to what depth BRUE should construct its tree. In
the Sailing domain, we set H to 4  n, where n is the grid-size of the problem instance, and
this because it is unlikely that the optimal path between any two locations on the grid will
be longer than a complete encircling of the area.
We compared BRUE with two MCTS-based algorithms: the UCT algorithm, and a recent
modification of UCT, obtained from UCT by replacing the UCB1 policy at the root node with
the uniform policy (Tolpin & Shimony, 2012). In what follows, we denote this modification
of UCT as uUCT. The motivation behind the design of uUCT was to improve the empirical
simple regret of UCT, and the results for uUCT reported by Tolpin and Shimony (2012)
(and confirmed by our experiments here) are impressive. We also display the results for
an additional MCTS2e-based algorithm, baptized here as BRucbE, which is very similar to
BRUE except that, for exploration, it uses the UCB1 policy instead of the uniform policy. In
other words, BRucbE can be seen as UCT with separation of concerns. All four algorithms
were implemented within a single software infrastructure. In line with the setup underlying
181

fiFeldman & Domshlak

0.7

2

1.8

0.6

1.6

UCT
uUCT
BRUE
BRucbE

0.4

1.4
Simple Regret

Simple Regret

0.5

0.3

1.2

1

UCT
uUCT
BRUE
BRucbE

0.8

0.2
0.6

0.1

0

0.4

0

5

10

0.2

15

0

1

2

3

4

4

Iterations

x 10

3.5

4

3

3.5

UCT
uUCT
BRUE
BRucbE

2.5

2

7

8

9

10
4

x 10

UCT
uUCT
BRUE
BRucbE

3

2.5

2

1.5

1

6

10  10

Simple Regret

Simple Regret

55

5
Iterations

1.5
0

0.5

1

1.5

2
Iterations

2.5

3

3.5

4
4

x 10

20  20

0

0.5

1

1.5
Iterations

2

2.5

3
4

x 10

40  40

Figure 5: Empirical performance of UCT, uUCT (denoted as UUCT, for short), BRUE, and
BRucbE in terms of the average error on the Sailing domain tasks on n  n grids
with n  {5, 10, 20, 40}.

Theorem 6 of Kocsis and Szepesvari (2006), the exploration coefficient for UCT and uUCT
(parameter c in Eq. 2) was set to the difference between the largest possible and the smallest
possible values of the H-step rollouts from the root. In the Sailing domain, this corresponds
to the maximal move duration, 6, multiplied by the number of steps-to-go h.
Figure 5 shows the performance of the four algorithms in terms of the empirical simple
regret, that is, the average difference Q(s0 , a)  V (s0 ) between the true values of the action
a chosen by the algorithm and that of the optimal action   (s0 ). Each algorithm was run
on 1000 randomly chosen initial states s0 , with the target being fixed at one of the corners
of the grid. The performance was measured and depicted as a function of planning time.
For all the four algorithms, the planning time unit, or iteration, corresponds to H action
samples, that is, to the length of a single rollout.
182

fiSimple Regret Optimization in Online Planning for MDPs

4

3.5

3.5

3

3
UCT
uUCT
BRUE
BRucbE

2

UCT
uUCT
BRUE
BRucbE

2.5
Simple Regret

Simple Regret

2.5

1.5

2

1.5
1

1

0.5

0
0

0.5

0.2

0.4

0.6

0.8

1
Iterations

1.2

1.4

1.6

1.8

0

2
6

x 10

B = 6/D = 8

0

0.5

1

1.5

2

2.5
Iterations

3

3.5

4

4.5

5
5

x 10

B = 2/D = 22

Figure 6: Empirical performance of UCT, uUCT, BRUE, and BRucbE in terms of the average
error on the MDP version of random game trees with branching factor B and tree
depth D.

Consistently with the results reported in the work of Tolpin and Shimony (2012), on the
smaller tasks, uUCT outperformed UCT by a very large margin, with the latter exhibiting
very little improvement over time even on the smallest, 5  5, grid. The difference between
uUCT and UCT on the larger tasks was less notable. In turn, both BRUE and BRucbE
substantially outperformed UCT, with BRucbE being slightly better in smaller tasks, and
BRUE taking over in the larger instances, except for relatively short planning deadlines.
This shows that the value of MCTS2es separation of concerns lies not only in the ability
to employ a pure exploration policy, but also in the ability to base the estimations on the
empirically best values, regardless of the employed exploration policy.
Overall, these results on the Sailing domain clearly testify that BRUE is not only attractive in terms of formal guarantees, but can also be very effective in practice. We have
also evaluated the four algorithms in a domain of random game trees whose goal is a simple
modeling of two-person zero-sum games such as Go, Amazons and Globber. In such games,
the winner is decided by a global evaluation of the end board, with the evaluation employing
this or another feature counting procedure; the rewards thus are associated only with the
terminal states. Following Kocsis and Szepesvari (2006), the rewards in our domain are
calculated by first assigning values to moves, and then summing up these values along the
paths to the terminal states. Note that the move values are used for the tree construction
only and are not made available to the players. The values are chosen uniformly from
[0, 127] for the moves of MAX, and from [127, 0] for the moves of MIN. The players act
so to (depending on the role) maximize/minimize their individual payoff: the aim of MAX
is to reach terminal s with as high R(s) as possible, and the objective of MIN is similar,
mutatis mutandis. Our simple game tree model is similar in spirit to many other game tree
models used in previous work (Kocsis & Szepesvari, 2006; Smith & Nau, 1994), with two
exceptions. First, we measure the success/failure of the players via the actual payoffs they
183

fiFeldman & Domshlak

4

1.8

3.5

1.6

3

1.4

1.2

BRUE

Simple Regret

Simple Regret

2.5
BRUE()
2

BRUE
BRUE()
1

1.5

0.8

1

0.6

0.5

0.4

0

0

0.2

0.4

0.6

0.8

1
Iterations

1.2

1.4

1.6

1.8

0.2

2
6

x 10

Game Trees (B = 6/D = 8)

0

1

2

3

4

5
Iterations

6

7

8

9

10
4

x 10

Sailing (10  10)

Figure 7: Empirical performance of BRUE and BRUE() in terms of the average error on
the MDP version of random game trees and the sailing domain.

receive, rather than on a ternary scale of win/lose/draw. Moreover, to comply with the
setting addressed in this work, we model the game as an MDP where only the moves associated with the MAX player are considered as decision nodes, whereas the moves of MIN
are modeled as stochastic outcomes with the following distribution: The optimal minimax
move is chosen with probability p = 0.9, and the complementary probability 1  p is divided
uniformly between the rest of the moves.
Similarly to our setup for the Sailing domain, the exploration coefficient for UCT and
uUCT was
to the range
of the game values, 127H, since rewards are bounded by the
 set H

H
interval 127 2 , 127 2 . We ran experiments with two different settings of the branching
factor (B) and tree depth (D). As with the Sailing domain, we compared the empirical
simple regret obtained by UCT, uUCT, BRUE, and BRucbE over time. Figure 6 shows
the performance of the four algorithms for two game configurations, B = 6, D = 8 and
B = 2, D = 22, with each configuration being represented by 1000 game trees. The results
here appear encouraging as well, with BRUE and BRucbE overtaking UCT and uUCT, and
BRucbE even appearing slightly faster than BRUE in terms of convergence.
We also experimented with BRUE() in which, in line with our discussion right after
Theorem 3, the  parameter was dynamically adjusted as a function of the depth of the
estimated node/action pair. Specifically, we used  = nnHh , where nH denotes the average
number of samples of leaf nodes, and nh denotes the average number of samples of nodes
at the same depth of the value estimator under consideration. As we show in Figure 7,
we did not find any significant empirical benefit of BRUE() over BRUE (to match the
superior formal guarantees of the former), neither in the Sailing domain nor in the game
trees domain.
The last set of experiments complements on the theoretical comparison to the sparse
sampling (SS) algorithm. Specifically, we performed an empirical comparison between BRUE
and UCT with a variant of SS called forward-search sparse sampling (FSSS) (Walsh, Goschin,
184

fiSimple Regret Optimization in Online Planning for MDPs

& Littman, 2010). Like SS, FSSS estimates the action values at any node using C samples.
However, instead of estimating the action values recursively for any encountered state,
FSSS uses MCTS-style rollouts to explore the state space, initializing the values of yet
unexplored actions with predefined lower and upper bounds. Ultimately, FSSS computes
precisely the same values as SS, thus returning the same recommendation. However, it
potentially benefits from a kind of pruning to reduce the amount of computation. Notably,
unlike SS, FSSS can output an action recommendation at any point of time based on the
maintained lower and upper bounds on the actions values. A typical approach is to select
the action with the maximum lower bound. However, similarly to SS, FSSS cannot provide
any non-trivial guarantees prior to its termination. We therefore choose to use the following
experimental setup. First, we run FSSS with some value of C. We then take the overall
number of action samples performed by FSSS until termination, and use it as a stopping
criteria for BRUE and UCT. Figures 8 and 9 depict the empirical simple regret obtained
by the three algorithms upon the termination in the Sailing and game tree domains. For
each planning task, we picked a few values of C that allowed FSSS to terminate within a
reasonable amount of time.9 In the Sailing domain, the lower and upper bounds in FSSS
were set to 0 and 6h, respectively, whereas in the game trees domain, we used a lower bound
127 H2 and an upper bound 127 H2 .
As it appears, both BRUE and UCT outperform FSSS in most tasks, and notably, BRUE
outperforms FSSS in all tasks, and for every value of C. This is despite the purported
advantage of FSSS being aware of the termination point. Our explanation for this result
concerns two fundamental differences between MCTS-based algorithms and SS. First, recall
the formal discussion given after Theorem 1 around the entropy of the transition function.
Suppose that FSSS (or SS) estimates a certain action that has two outcomes, with one
outcome being more likely than the other. If both outcomes are caught by the C action
samples, the same efforts would be invested in estimating the values of these two states,
regardless of the fact that one outcome is more likely and thus has a larger contribution
to the value of the action. In contrast, both UCT and BRUE adapt to the structure of
the problem by skewing the rollouts towards states with higher probability, yielding better
results both theoretically and empirically.
Another potential advantage of MCTS algorithms over SS pertains to the allocation of
computational efforts to estimating the actions values at different depths. In FSSS (and SS),
all the estimations are based on the same number of samples C. In contrast, in both UCT
and BRUE, nodes closer to the root are sampled more frequently because of the branching
factor. To illustrate the potential benefit of focusing the efforts around the root, let us
consider the Sailing domain as an example. The position of the boat reached after taking
the optimal moves in the first few steps would probably be closer to the target compared to
the position reached after taking non-optimal moves in the fist steps. It is therefore likely
that following a random navigation policy from the position of the boat after the first few
steps, the target would be reached sooner on average in the former case than in the latter
case. In other words, the benefit of knowing the optimal policy at deeper states is smaller,
and putting more focus on estimating the actions at nodes closer to the root makes much
9. The time limit for FSSS was set to 24 hours. Notably, in our implementation of FSSS, we minimize the
number of action sample by sampling outcomes only for actions that are selected in the rollouts

185

fiFeldman & Domshlak

55

10  10

20  20

40  40

Figure 8: Empirical performance of FSSS, UCT, and BRUE in terms of the average error at
termination on the Sailing domain tasks on n  n grids with n  {5, 10, 20, 40}.
For n = 5, the empirical simple regret of BRUE was 0. For n = 40, running FSSS
with C > 1 took more than 24 hours.

186

fiSimple Regret Optimization in Online Planning for MDPs

B = 6/D = 8

B = 2/D = 20

Figure 9: Empirical performance of FSSS, UCT, and BRUE in terms of the average error at
termination on the MDP version of random game trees with branching factor B
and tree depth D.

sense. We believe that this property prevails in many practical cases, and in these cases
MCTS algorithms should be expected to be more efficient.
It is also interesting to see that, although UCT outperforms FSSS in most tasks, the
gap between them is decreasing with the size of the budget (C), and in the smaller tasks
(Sailing domain with grid 5  5 and 10  10), FSSS even outperforms UCT from some point.
We find this to be compliant with the theoretical merits of the pure-exploratory nature of
both SS and BRUE.

7. Summary
With the goal of improving the convergence guarantees of smooth Monte-Carlo tree search
algorithms for online planning in MDPs, we have introduced a principle of separation of
concerns, as well as a Monte-Carlo tree search scheme, MCTS2e, that allows operationalizing this principle. We showed that a subclass of purely exploring instances of MCTS2e
guarantees smooth exponential-rate improvement of the performance measures of interest,
improving over polynomial-rate guarantees provided by the state-of-the-art algorithms. We
then examined, both formally and empirically, a purely exploring MCTS2e algorithm called
BRUE. Finally, we explored the prospects of time-dependent forgetting of samples within
Monte-Carlo search, and showed concrete merits of such sample ignorance on a parametric
BRUE() algorithm that generalizes BRUE with such learning with forgetting.
The results open numerous questions for further investigation. First, while BRUE is a
rather straightforward implementation of pure exploration with MCTS2e, it is not necessarily the most efficient one. We believe that replacing the uniform exploration of BRUE
with a scheme that makes use of the knowledge acquired along the sampling to direct the
187

fiFeldman & Domshlak

exploration may result in an empirically more efficient instance of MCTS2e, and possibly
even improve on the formal guarantees of BRUE.
Another important point to consider is the speed of convergence to good actions, as
opposed to the speed of convergence to optimal actions. While BRUE is geared towards
identifying the optimal action, good is often the best one can hope for when dealing with
large MDPs. To identify the optimal solution, BRUE constructs a full-depth tree right from
the start. However, focusing on the nodes closer to the root node, e.g., by utilizing more
intelligent rules for rollout termination, may improve the quality of the recommendation if
the planning time is severely limited. We have recently reported on some successful steps
in this direction (Feldman & Domshlak, 2013), but these steps were far from closing this
interesting venue of research.
Finally, the core tree sampling scheme employed by BRUE is not the only plausible way
to implement the concept of separation of concerns discussed in this paper. For instance,
substituting the MC-backup procedure with value updates based on Bellmans principle,
as, e.g., was done by Keller and Helmert (2013), also constitutes a form of separation of
concerns. It would be interesting to have an in-depth comparison of both the formal and
empirical properties of the different protocols.
Acknowledgements
This work is partially supported by and carried out at the Technion-Microsoft Electronic
Commerce Research Center, as well as partially supported by the Air Force Office of Scientific Research, USAF, under grant number FA8655-12-1-2096.

Appendix A. Auxiliary Propositions
In the analysis below, we make extensive use of the Hoeffdings tail inequality for sums of
bounded independent random variables. In addition, we use the result of the mathematical
programming P1 below.
Hoeffdings tail inequality. Let X1 , . . . , Xn be independent bounded random P
variables
such that Xi falls in the interval [ai , bi ] with probability 1, and let Sn = ni=1 Xn .
Then, for any t > 0, we have
2/

P {Sn  ESn  t}  e2t

Pn

2
i=1 (bi ai )

.

In particular, if all Xi are identically distributed within [0, 1] and EXi = , then
P {Sn  n  t}  e

2t2
n

P1 For h  1, the solution of the mathematical program
maximize
p

subject to

B
X

i=1
B
X

pi

h
pi B
pi = 1

i=1

0  pi  1
188

.

fiSimple Regret Optimization in Online Planning for MDPs

has a value of 1. The result follows from the concavity of the objective function.

Appendix B. Proofs
This appendix is structured in four subsections, respectively dedicated to the proof of
Theorem 1, Proposition 4.1.1, and Theorems 2, and 3. For the sake of readability, in
places where we believe it does not create any confusion, the expressions of the form P(E |
X1 = x1 , . . . , Xk = xk )  f (x1 , . . . , xk ) where Xi are random variables are written simply
as P(E)  f (X1 , . . . , Xk ).
B.1 Proof of Theorem 1
In what follows, by Vp (shhi) we denote the h-steps value function defined as

E

"h1
X
i=0

fi
#
fi
fi
R (si ,  (si hh  ii) , si+1 ) fi s0 = s ,
fi

where the expectation is over the transition function T r, i.e., over the set of conditional
probability distributions {P(S | s, a)}s,a . Vp (shhi) denotes the value function of the optimal
policy   . The subscript p is omitted if p corresponds to the transition probabilities P of
the MDP in question.
Theorem 1 follows almost immediately from Lemma 4 below.

Lemma 4 For any node shhi we have
n
o
B
2
P V  (shhi)  VPb (shhi)    ah ebh  n(shhi)
n B
o
2
P VPb (shhi)  V  (shhi)    ah ebh  n(shhi) ,
where
h1
1
116  9B 2 K 2
2
(196BK) 2 (h1) (h  1)!2
2
1
bh =
.
2
9K (196BK)h1 h2
ah = 3K



189

fiFeldman & Domshlak

Proof: The proof is by induction on h. Starting with h = 1, we have
n
o
B
P V  (sh1i)  VPb (sh1i)  


2
 P Q(sh1i,   (sh1i))  Q(sh1i,  B (sh1i)) 
3
)
(
X

b 0 | s,  B (sh1i)))R(s,  B (sh1i), s0 ) >
by def. of Q
+P
(P(s0 | s,  B (sh1i))  P(s
3
s0


X

b
P Q(sh1i,

a)  Q(sh1i, a) 
3

a6= (sh1i)



b
+ P Q(sh1i,   (sh1i))  Q(sh1i,
  (sh1i)) 
3
)
(
X
X

b 0 | s, a))R(s,  B (sh1i), s0 ) >
+
P
(P(s0 | s, a)  P(s
3
s0
aA(s)


X
 2 n(sh1i)
n(sh1i)

P n(sh1i, a) 
+ 2Ke 9K
by Hoeffding
2K
aA(s)

 3Ke

 2 n(sh1i)
9K 2

.

by Hoeffding

Assuming now the claim holds for all h0  h, in proving the induction hypothesis for h + 1,
we encounter the following deficiencies:
b is an unbiased estimator of Q, that is, EQ
b = Q. In contrast, the
(F1) For h = 1, Q
b
estimates inside the tree (at nodes with h > 1) are biased. This bias stems from Q
possibly being based on numerous sub-optimal choices in the sub-tree rooted in shhi.

b are independent. This is not so for h > 1,
(F2) For h = 1, the summands accumulated by Q
where the accumulated reward depends on the selection of actions in subsequent nodes,
which in turn depends on previous rewards.
Our way to circumvent these deficiencies is captured by a sequence of bounding B.1.1B.1.5 below. At a very high level, we deal with the bias of samples by using a straightforward
extension of Hoeffding inequality. In the analysis, the dependence between samples is
alleviated by conditioning the outcome of each sample on the state of the information
collected at the nodes below the sampled one. All the propositions below are made under
the assumption of the induction hypothesis.
b
Considering a node shh + 1i, we first show that all the value estimations Q(shh+1i,
a)

of actions a  A(s) are sufficiently accurate. We show it only for a =  (shh + 1i), whereas
the bounds for all other actions can be derived in a similar way. For ease of presentation,
in what follows we use the abbreviations a =   (shh + 1i), aB =  B (shh+1i), and na =
n(shh + 1i,   (shh + 1i)). We also use the following notation. For t  {1, . . . , na }, let the
b
random variables Xt capture the accumulated reward samples averaged by Q(shh+1i,
a ),
bt capture the transition probatB capture the policy induced by BRUE at sample t, and P
b
bilities estimations at sample t. In Proposition B.1.2, we bound the error of Q(shh+1i,
a ),
190

fiSimple Regret Optimization in Online Planning for MDPs

bt at the descendants of shh + 1i during all samples is sufgiven that the error of tB and P
bt
ficiently small. In Proposition B.1.1 we bound the probability that the error of tB or P
during any sample t is too large.
Proposition B.1.1 For  > 0, let E be the event in which, while sampling all Xt , t =
1, . . . , na , it holds that,
1.

2.

P

s0



B
bt (s0 | s, a ) V  (s0 hhi)  V t (s0 hhi) 
P
b
Pt

P 
s0

where

t
2,

and


bt (s0 | s, a ) (R(s, a , s0 ) + V  (s0 hh  1i)) 
P(s0 | s, a )  P

t
2,

v


u
na  2 bh
u 2
4B
log
t  na
56B
1
 .
+
t =
9
bh
t

Then,

P {E } 

112B 2 ah  bh 2 na
36B
e
.
 2 bh

(14)

Proof: It follows from P1 that

P

(
X
s0



tB

bt (s0 | s, a ) V  (s0 hhi)  V
P
b

Pt



t
(s0 hhi) 
2

)




X 
B
t

.

P V  (s0 hhi)  V b t (s0 hhi)  q
Pt


0

b
0
s
2 B Pt (s | s, a )

(15)

B
Pt

Indeed, if for all states s0 in the summation, it holds that V  (s0 hhi)  V b t (s0 hhi) <


2

t
,
bt (s0|s,a )
BP

X
s0

then, in particular,


 X
B
t
bt (s0 | s, a ) V  (s0 hhi)  V t (s0 hhi) <
bt (s0 | s, a ) q
P
P
bt
P
bt (s0 | s, a )
s0
2 BP
=

191

b (s0 | s, a )
t X P
q t
2 0
bt (s0 | s, a )
s
BP
t
.
2

by P1

fiFeldman & Domshlak

Given that, we have


na

X
X 
t
B
P {E } 
P V  (s0 hhi)  V t (s0 hhi) > q

bt (s0 | s, a ) 
t=1 s0
2 BP
(
)
na

X
X
 t
0

0

 0
 0
b
+
P
P(s | s, a )  Pt (s | s, a ) R(s, a , s ) + V (s hh  1i) >
2
0
t=1
na



X

Bah e

t=1
na

+

s

b 2 t
 h4Bt

X

by I.H.

t2 t

e 4h2

by Hoeffding

t=1



na
X
t=1

=

2Bah e



bh t2 t
4B

na
X
b 2 n 
112B 2
 h36Ba

a
e
h
na  2 bh

by definition of t

t=1

112B 2 ah  bh 2 na
36B
e
 2 bh

Note that, while bounding the probability of the event E as in Eq. 14, we basically ignore
bt during different sampling times, and use a
the dependency between the state of tB and P
B
bt happen to be accurate at some sample t, the
crude union bound. However, if t and P
probability that they will remain accurate at subsequent samples is higher. It is possible
that factoring this dependency into the bound in Proposition B.1.1 can further improve the
tightness of the bound.
bt during all samples t = 1, . . . , na , and given that
Conditioned on the state of tB and P
they are sufficiently accurate as defined by the event E above, Proposition B.1.2 bounds
b
the probability that the value estimator Q(shh+1i,
a ) is inaccurate.

Proposition B.1.2 Under the definition of E introduced in Proposition B.1.1, for all
na
bt }na , and the event E ,
 > 0, it holds that, given {tB }t=1
, {P
t=1
(1) for all t, the random variables Xt are mutually independent,
h fi
i
fi
bt }, E  Q(shh+1i, a)  t , and
(2) for t  1, E Xt fi {tB }, {P

fi
n
o
 2 na

fi B
2


b
b
8(h+1)
(3) P Q(shh+1i, a )  Q(shh+1i, a )   fi {t }, {Pt }, E  e
.

Proof: The correctness of mutual independence (1) is direct from the definition of BRUE:
all the dependency between the samples in BRUE is induced by the state of the information
b In turn, the proof
collected by the samples, and these are determined solely by  B and P.
of (2) is obtained by the definition of E as follows:
192

fiSimple Regret Optimization in Online Planning for MDPs

h fi
i X
X
B
fi
bt }, E =
bt (s0 | s, a )R(s, a , s0 ) +
bt (s0 | s, a )V t (s0 hhi)
E Xt fi {tB }, {P
P
P
b
P
s0

t

s0

= Q(shh+1i, a )

X

bt (s0 | s, a )  R(s, a , s0 ) + V  (s0 hhi)

P(s0 | s, a )  P
s0



X
s0



B
bt (s0 | s, a ) V  (s0 hhi)  V t (s0 hhi)
P
b
Pt

t t

2
2
= Q(shh+1i, a )  t
 Q(shh+1i, a ) 

by definition of E

Finally, the proof of (3) is obtained by noting that
v


u
na  2 bh
u
na
na
4B
log
t  2 na
56B
1 X
1 X
1

+

t =
na
9
bh
na
t
t=1
t=1
v


u
na  2 bh
u 2
4B
log
t  na
56B
2

+

9
bh
na
r
4 2 4 2
log x
2
+
since


x
5
9
35
3
 
4
Therefore,
fi
o
n
fi
b
bt }, E
P Q(shh+1i, a )  Q(shh+1i,
a )   fi {tB }, {P
fi
(
)
na
fi
h
i
X
1
fi


B
bt }, E
b
b
= P E Q(shh+1i,
a )  Q(shh+1i,
a )
t fi {t }, {P
fi
na
t=1
fi

 h
i
 fifi B


b
b
b
 P E Q(shh+1i, a )  Q(shh+1i, a )  fi {t }, {Pt }, E
4
e



 2 na
8(h+1)2

,

b
We can now bound the error of the value estimator Q(shh+1i,
a ).
Proposition B.1.3 For all  > 0, it holds that

n
o 113B 2 a
2
h  bh  na
b
36B
P Q(shh+1i, a )  Q(shh+1i,
a )   
e
.
 2 bh
193

(16)

fiFeldman & Domshlak

Proof:
n
o
b
P Q(shh+1i, a )  Q(shh+1i,
a )  

 P {E }
fi
fi o
n
o n
X
fi
b
bt }, E P { B }, {P
bt } fifi E
P Q(shh+1i, a )  Q(shh+1i,
a )   fi {tB }, {P
+
t
bt }
{tB ,P



113B 2 ah  bh 2 na
36B
e
 2 bh

by Props. B.1.1 & B.1.2.

b
Proposition B.1.4 below employs the bounds on the accuracy of Q(shh+1i,
a) to bound
B
the simple regret of a .

Proposition B.1.4


	
P Q(shh+1i,   (shh+1i))  Q(shh+1i, aB )   

114B 2 ah  bh 2 n(shh+1i)
144BK
e
 2 bh

Proof:


	
P Q(shh+1i,   (shh+1i))  Q(shh+1i, aB )  


X

b

P Q(shh+1i, a)  Q(shh+1i, a) 
2
a6=  (shh+1i)





b
+ P Q(shh+1i,  (shh+1i))  Q(shh+1i,  (shh+1i)) 
2

2
X 
113B Kah  bh 2 n(shh+1i)
n(shh + 1i)
144BK
+
e

P n(shh + 1i, a) 
2K
 2 bh

by Prop. B.1.3

aA(s)



114B 2 Kah  bh 2 n(shh+1i)
144BK
e
 2 bh

by Hoeffding

The induction step is concluded by Proposition B.1.5.
Proposition B.1.5
n
o 116B 2 Ka
2
B
h  bh  n(shh+1i)
196BK
P V  (shh+1i)  VPb (shh+1i)   
e
.
 2 bh
Proof: Since we have
B

V  (shh+1i)  VPb (shh+1i)
= Q(shh+1i,   (shh+1i))  Q(shh+1i, aB )


X
b 0 | s, aB ) V  (s0 hhi)  V B (s0 hhi)
+
P(s
b
P
s0

+

X
s0



b 0 | s, aB ) R(s, aB , s0 ) + V  (s0 hhi) ,
P(s0 | s, aB )  P(s
194

fiSimple Regret Optimization in Online Planning for MDPs

it holds that
n
o
B
P V  (shh+1i)  VPb (shh+1i)  


6
 P Q(shh+1i,   (shh+1i))  Q(shh+1i, aB ) 
7
)
(


X

B
b 0 | s, aB ) V  (s0 hhi)  V  (s0 hhi) 
+P
P(s
b
P
14
s0
(
)

X


0
B
0
B
B 0
 0
b
+P
P(s | s, a )  P(s | s, a ) R(s, a , s ) + V (s hhi) >
14
0
s

114B 2 Kah  bh 2 n(shh+1i)
144BK

by Prop. B.1.4
e
 2 bh
(
)


X
X

B
b 0 | s, a) V  (s0 hhi)  V  (s0 hhi) 
+
P(s
P
b
P
14
s0
aA(s)
)
(

X
X


b 0 | s, a) R(s, a, s0 ) + V  (s0 hhi) >
+
P
P(s0 | s, a)  P(s
14
0
aA(s)

s

2

 n(shh+1i)
b  2 n(shh+1i)
114B 2 Kah  bh 2 n(shh+1i)

 h 196BK
196K(h+1)2
196BK
e
+
BKa
e
+
Ke
h
 2 bh
h2  2 n(shh+1i)
116B 2 Kah  bh196BK(h+1)
2

e
.
 2 bh



n B
o
Proving the bound for P V b (shh+1i)  V  (shh+1i)   is completely similar.
P

Finally, the proof of Theorem 1 is concluded by

	
P nB (s0 hHi) 6=   (s0 hHi)

	
 P Q(s0 hHi,   (s0 hHi))  Q(s0 hHi,  B (s0 hHi))  

H1
2 n
1
116  9B 2 K 2
(H1)2
2  9K 2 (196BK)H1 H 2
2
(H

1)!
e
 3K
(196BK)
2

(17)

and by noting that the maximal loss from choosing a sub-optimal action at s0 hHi is H.
B.2 Proof of Proposition 4.1.1 (BRUE bounds with Pe )
Basically, the proof for Proposition 4.1.1 is identical to that of Theorem 1 for h < 4. For
h  4, we note that
(
)

Xq
X 
p
Pe
0
0
0
b
b
P
Pt (s | s, a) > 3 Pe 
P Pt (s | s, a) > P(s | s, a) + 2
B
0
0
s

s

 Be



195

2t
B4

.

by Hoeffding

(18)

fiFeldman & Domshlak

bt (s0 | s, a)  P(s0 | s, a) +
Indeed, if P

Pe
B2

for all s0 , then

Xq
X
bt (s0 | s, a) 
P
s0

s0

r

P(s0 | s, a) +

Pe
B2
r

"
X p
2P(s0 | s, a) +

s0

2

p
p
2Pe  3 Pe

Pe
2 2
B

#

Therefore, the probability in Eq. 15 from Proposition B.1.1 can be bounded for h > 4 as
(
)
 

X
B

t
0
0


0
bt (s | s, a ) V (s hhi)  V t (s hhi) 
P
P
bt
P
2
0
s


(
)

X 
Xq
p
B


t
bt (s0 | s, a) > 3 Pe

P V  (s0 hhi)  V b t (s0 hhi)  q
+P
P
Pt


0

bt (s | s, a )
s0
s0
6 Pe P
bh t2 t

2t

 Bah e 36Pe + Be B4
bh t2 t
 36P
e

 2Bah e

by I.H. & Eq. 18

.

Consequently, we have that
 2 na
158B 2 ah  bh306P
e .
P {E } 
e
 2 bh

Plugging this bound for P {E } in the chain of bounding in Propositions B.1.2-B.1.5,
we obtain the result.
B.3 Proof for Theorem 2
The proof of Theorem 2 follows from the proof of Theorem 1 and noting that
 the effect of the rollout-action
policy on the
n
o convergence rate comes into play only
n(shh+1i)
in the bounds on P n(shh+1i, a) < 2K
, and
 the condition of Theorem 2 simply postulates such bounds so that the exponential-rate
convergence is guaranteed.
B.4 Proof for Theorem 3
In general, the proof of Theorem 3 follows the same lines as the proof of convergence rate for
BRUE in Theorem 1, with the role of each Proposition B.3.i here corresponding to the role
of Proposition B.1.i in the proof of Theorem 1. Essentially, the proof of Theorem 3 deviates
substantially from the proof of Theorem 1 only in the modification of Propositions B.1.1
and B.1.2 to partial averaging, captured by Propositions B.4.1 and B.4.2, respectively. The
bounds in the rest of the propositions are adjusted accordingly. We formulate the proof
196

fiSimple Regret Optimization in Online Planning for MDPs

for arbitrary values of , although we derive the bounds for a particular choice of depth1
dependent h  (BK)
h1 . Similarly to Theorem 1, the proof for Theorem 3 is based on
Lemma 5 below.
Lemma 5 For any node shhi we have
n
o
B
2
P V  (shhi)  VPb (shhi)    ah ebh  n(shhi)
n B
o
2
P VPb (shhi)  V  (shhi)    ah ebh  n(shhi) ,
where


12BK h1
(h!)2 ,
2
1
bh =
.
2
9K (196BK)h1 h2
ah = 3K



Proof: The proof is by induction on h. The base of the induction is identical to that in
Lemma 4, so we continue straight with the induction step. All the propositions below are
made under the assumption of the induction hypothesis. Considering a node shh + 1i, we
make use of the same notation used in the proof for Theorem 1, namely, a =   (shh + 1i),
aB =  B (shh+1i), na = n(shh + 1i,   (shh + 1i)), and, for t  {1, . . . , na }, the random
b
variables Xt capture the accumulated reward samples averaged by Q(shh+1i,
a ), tB capbt capture the transition probabilities estiture the policy induced by BRUE at sample t, and P
mations at sample t. In addition, we also use the additional abbreviation na = b(1)na c.
Proposition B.4.1 For  > 0, let E be the event in which, while sampling Xt , t =
na , . . . , na , it holds that


B
P b 0
 ) V  (s0 hhi)  V t (s0 hhi)  t , and
P
(s
|
s,
a
1.
0
t
s
b
2
Pt

2.

where

P 

Then,

s0



bt (s0 | s, a ) (R(s, a , s0 ) + V  (s0 hh  1i)) 
P(s0 | s, a )  P

t
2,

v


u
h+1 na  2
u 2
4B
log
t  na
1
8h2
 .
t =
+
3
bh
t
P {E } 

b 2 n 
8Bh2
 h12Ba
a
e
.
h
2

Proof: It follows from P1 that
)
(

 
X
B

t
bt (s0 | s, a ) V  (s0 hhi)  V t (s0 hhi) 
P
P
bt
P
2
0
s



X 
t
B

P V  (s0 hhi)  V b t (s0 hhi)  q
Pt

bt (s0 | s, a ) 
s0
2 BP
197

fiFeldman & Domshlak

Thus,


na

X
X 
t
B
P {E } 
P V  (s0 hhi)  V t (s0 hhi) > q

bt (s0 | s, a ) 
0
t=n
2 BP
a s
(
)
na

X
X
 t
0

0


0

0
bt (s | s, a ) R(s, a , s ) + V (s hh  1i) >
+
P
P(s | s, a )  P
2

0
t=na

s

na



X

Bah e

bh t2 t
4B

by I.H.

t=n
a

+

na
X



e

t2 t
4h2

by Hoeffding

t=n
a



na
X

2Bah e



bh t2 t
4B

t=n
a

=

b 2 n 
8Bh2
 h12Ba
a
e
h
2



na
X

t=n
a

b 2 n 
8Bh2
 h12Ba
a
e
h
h+1 na  2

by definition of t

Prop. B.4.2 is modified accordingly.

Proposition B.4.2 Under the definition of E introduced in Proposition B.4.1, for all
na
bt }na , and the event E ,
, {P
 > 0, it holds that, given {tB }t=1
t=1
(1) for all t, the random variables Xt are mutually independent,

h fi
i
fi
bt }, E  Q(shh+1i, a)  t , and
(2) for t  na , E Xt fi {tB }, {P

fi
n
o
b h2  2 na
 h
fi B


b
b
(3) P Q(shh+1i, a )  Q(shh+1i, a )   fi {t }, {Pt }, E  e 8B(h+1)2 .

Proof: The correctness of mutual independence (1) is direct from the definition of BRUE:
all the dependency between the samples in BRUE is induced by the state of the information
b In turn, the proof
collected by the samples, and these are determined solely by  B and P.
of (2) is obtained by the definition of E as follows:
198

fiSimple Regret Optimization in Online Planning for MDPs

h fi
i X
X
B
fi
bt }, E =
bt (s0 | s, a )R(s, a , s0 ) +
bt (s0 | s, a )V t (s0 hhi)
E Xt fi {tB }, {P
P
P
b
P
s0

t

s0

= Q(shh+1i, a )

X

bt (s0 | s, a )  R(s, a , s0 ) + V  (s0 hhi)

P(s0 | s, a )  P
s0



X
s0



B
bt (s0 | s, a ) V  (s0 hhi)  V t (s0 hhi)
P
b
Pt

t t

2
2
= Q(shh+1i, a )  t
 Q(shh+1i, a ) 

by definition of E

Finally, the proof of (3) is obtained by noting that
1
h+1 na

v


u

n  2
u 2
na
4B log h+18h2a
X
X
t  na
1
1


t =
+

3
b

n
t
h
h+1 a t=n
t=n
a
a
v


u
h+1 na  2

u 2
4B
log
2
t  na
2
1  1  h+1
8h

+


3
bh
na
h+1
r
4 2 4 2
log x
2
bh h2
+
since

 and h+1 =
x
5
B
9
35
3
 
4
na

Therefore,
fi
o
n
fi
b
bt }, E
P Q(shh+1i, a )  Q(shh+1i,
a )   fi {tB }, {P

na
 h
i
X
1
b
b
= P E Q(shh+1i,
a )  Q(shh+1i,
a )   
t

h+1 na

t=na
fi

 h
i
fi
 fi B


b
b
b
 P E Q(shh+1i, a )  Q(shh+1i, a )  fi {t }, {Pt }, E
4
e



bh h2  2 na
8B(h+1)2

fi

fi

fi B
bt }, E
fi {t }, {P
fi

fi

.

(19)

Proposition B.4.3 For all  > 0, it holds that
n
o 9Bh2
b h2  2 na
 h
b
12B(h+1)2 .
P Q(shh+1i, a )  Q(shh+1i,
a )   
a
e
h
2
199

fiFeldman & Domshlak

Proof:
n
o
b
P Q(shh+1i, a )  Q(shh+1i,
a )  

 P {E }
fi
fi o
n
o n
X
fi
b
bt }, E P {tB }, {P
bt } fifi E
P Q(shh+1i, a )  Q(shh+1i,
a )   fi {tB }, {P
+
bt }
{tB ,P

2 2

b h  na
9Bh2
 h
12B(h+1)2

a
e
h
2

by Props. B.4.1 & B.4.2.

The remainder of the proof is identical to the proof of Theorem 1, whereas only the
b
bounds on the error of the estimators Q(shh+1i,
a) are aligned with Proposition B.4.3.
Proposition B.4.4

Proof:


	
P Q(shh+1i, a )  Q(shh+1i, aB )   

2 2

b h  n(shh+1i)
10BKh2
 h
96BK(h+1)2
a
e
h
2


	
P Q(shh+1i, a )  Q(shh+1i, aB )  



X 




b
b

P Q(shh+1i, a)  Q(shh+1i, a) 
+ P Q(shh+1i, a )  Q(shh+1i, a ) 
2
2
a6=a


b h2  2 n(shh+1i)
X
9BKh2
n(shh + 1i)
 h
96BK(h+1)2
by Prop. B.4.3

+
a
e
P n(shh + 1i, a) 
h
2K
2
aA(s)

2 2

b h  n(shh+1i)
10BKh2
 h
96BK(h+1)2

.
a
e
h
2

by Hoeffding

The induction step is concluded by Proposition B.4.5.
Proposition B.4.5
n
o 12BKh2
b h2  2 n(shh+1i)
B
 h
196BK(h+1)2 .
P V  (shh+1i)  VPb (shh+1i)   
a
e
h
2

Proof: Since we have

B

V  (shh+1i)  VPb (shh+1i)
= Q(shh+1i,   (shh+1i))  Q(shh+1i, aB )


X
b 0 | s, aB ) V  (s0 hhi)  V B (s0 hhi)
+
P(s
b
P
s0

+

X
s0



b 0 | s, aB ) R(s, aB , s0 ) + V  (s0 hhi) ,
P(s0 | s, aB )  P(s
200

fiSimple Regret Optimization in Online Planning for MDPs

it holds that
n
o
B
P V  (shh+1i)  VPb (shh+1i)  


6
 P Q(shh+1i,   (shh+1i))  Q(shh+1i, aB ) 
7
(
)


X

B
b 0 | s, aB ) V  (s0 hhi)  V  (s0 hhi) 
+P
P(s
b
P
14
s0
)
(

X


b 0 | s, aB ) R(s, aB , s0 ) + V  (s0 hhi) >
+P
P(s0 | s, aB )  P(s
14
0
s

2 2

b h  n(shh+1i)
10BKh2
 h
136BK(h+1)2

by Prop. B.4.4
a
e
h
2
(
)


X
X

B
b 0 | s, a) V  (s0 hhi)  V  (s0 hhi) 
P(s
+
P
b
P
14
s0
aA(s)
)
(

X
X


b 0 | s, a) R(s, a, s0 ) + V  (s0 hhi) >
+
P(s0 | s, a)  P(s
P
14
0

s

aA(s)

2 2

2

b h  n(shh+1i)
 n(shh+1i)
b  2 n(shh+1i)
10BKh2
 h

 h 196BK
136BK(h+1)2
196K(h+1)2

a
e
+
BKa
e
+
Ke
h
h
2
b h2  2 n(shh+1i)
12BKh2
 h

ah e 196BK(h+1)2 .
2
n B
o
Proving the bound for P V b (shh+1i)  V  (shh+1i)   is completely similar.

P

Finally, the proof of Theorem 3 is concluded by

	
P nB (s0 hHi) 6=   (s0 hHi)

	
 P Q(s0 hHi,   (s0 hHi))  Q(s0 hHi,  B (s0 hHi))  


2 n
12BK H1
2  9K 2 (196BK)H1 H 2
 3K
(H!)
e
2

(20)

and by noting that the maximal loss from choosing a sub-optimal action at s0 hHi is H.

Appendix C. Proof for Proposition 2.1.1 (SS bound)
b
Let Q(shhi,
a) be the average of C recursive samples of the value of action a in shhi, and
b 0 | s, a) be the empirical transition probability based on these C samples. For any
let P(s
node shhi and action a, with probability at least 1  e

2 2 C
H2

, we have

fi
fi
fiX 
fi

fi
b 0 | s, a) V  (s0 hh  1i)fifi  
P(s0 | s, a)  P(s
fi
fi 0
fi
s

201

fiFeldman & Domshlak

Since sparse sampling encounters at most (min(B, C)  K)H nodes, we have that the probability of some bad estimate is bounded by (min(B, C)  K)H e

2 2 C
H2

. Therefore, we have

b
Q(shhi, a)  Q(shhi,
a)

X
b 0 | s, a) V  (s0 hh  1i)

P(s0 | s, a)  P(s
s0

+

X



0
0
 0
0
0
b
b
P(s | s, a) Q(s hh  1i,  (s hh  1i))  max
Q(s hh  1i, a )
0
a

s0

+

X
s0




b 0 | s, a) Q(s0 hh  1i,   (s0 hh  1i))  Q(s
b 0 hh  1i,   (s0 hh  1i)) ,
P(s

(21)

and similarly,
b
Q(shhi,
a)  Q(shhi, a)

X
b 0 | s, a)  P(s0 | s, a) V  (s0 hh  1i)

P(s
s0

+

X
s0

+



b 0 | s, a) max Q(s
b 0 hh  1i, a0 )  Q(s0 hh  1i,   (s0 hh  1i))
P(s
0

(22)

a

X
s0

n
o
b 0 | s, a) max Q(s
b 0 hh  1i, a0 )  Q(s0 hh  1i, a0 ) .
P(s
0
a

Note that the two bounds in Equations 21,22 above result in the recursion h =  + h1 =
h, where h upper bounds the respective difference. This implies that, with probability at
most (min(B, C)  K)H e

By setting  =


2H ,

2 2 C
H2

,
fi
fi
fi
fi
b
Q(s
hHi,
a)

Q(s
hHi,
a)
fi
fi > H
0
0

we obtain that the error probability is bounded by
2 C

(min(B, C)  K)H e 2H 4

The proof concludes by noting that the maximal loss for choosing non-optimal action at
the root node s0 hHi is H.

202

fiSimple Regret Optimization in Online Planning for MDPs

References
Auer, P., Cesa-Bianchi, N., & Fischer, P. (2002). Finite-time analysis of the multiarmed
bandit problem. Machine Learning, 47 (2-3), 235256.
Balla, R., & Fern, A. (2009). UCT for tactical assault planning in real-time strategy games.
In Proceedings of the 21st International Joint Conference on Artificial Intelligence
(IJCAI), pp. 4045.
Bellman, R. (1957). Dynamic Programming. Princeton University Press.
Bjarnason, R., Fern, A., & Tadepalli, P. (2009). Lower bounding Klondike Solitaire with
Monte-Carlo planning. In Proceedings of the 19th International Conference on Automated Planning and Scheduling (ICAPS).
Bonet, B., & Geffner, H. (2012). Action selection for MDPs: Anytime ao vs. uct. In
Proceedings of the 26th AAAI Conference on Artificial Intelligence (AAAI).
Boutilier, C., Dean, T., & Hanks, S. (1999). Decision-theoretic planning: Structural assumptions and computational leverage. Journal of Artificial Intelligence Research,
11, 194.
Browne, C., Powley, E. J., Whitehouse, D., Lucas, S. M., Cowling, P. I., Rohlfshagen, P.,
Tavener, S., Perez, D., Samothrakis, S., & Colton, S. (2012). A survey of Monte-Carlo
tree search methods. IEEE Transactions on Computational Intelligence and AI in
Games, 143.
Bubeck, S., & Munos, R. (2010). Open loop optimistic planning. In Proceedings of the 23rd
Annual Conference on Learning Theory (COLT), pp. 477489.
Bubeck, S., Munos, R., & Stoltz, G. (2011). Pure exploration in finitely-armed and
continuous-armed bandits. Theoretical Computer Science, 412 (19), 18321852.
Busoniu, L., & Munos, R. (2012). Optimistic planning for Markov decision processes. In
Proceedings of the Fifteenth International Conference on Artificial Intelligence and
Statistics (AISTATS), No. 22 in Journal of Machine Learning Research - Proceedings
Track, pp. 182189.
Coquelin, P.-A., & Munos, R. (2007). Bandit algorithms for tree search. In Proceedings
of the 23rd Conference on Uncertainty in Artificial Intelligence (UAI), pp. 6774,
Vancouver, BC, Canada.
Eyerich, P., Keller, T., & Helmert, M. (2010). High-quality policies for the Canadian Travelers problem. In Proceedings of the 24th AAAI Conference on Artificial Intelligence
(AAAI).
Feldman, Z., & Domshlak, C. (2012). Simple regret optimization in online planning for
markov decision processes. CoRR, arXiv:1206.3382v2 [cs.AI].
Feldman, Z., & Domshlak, C. (2013). Monte-Carlo planning: Theoretically fast convergence
meets practical efficiency. In Proceedings of the 29th Conference on Uncertainty in
Artificial Intelligence (UAI), pp. 212221.
Geffner, H., & Bonet, B. (2013). A Concise Introduction to Models and Methods for Automated Planning. Synthesis Lectures on Artificial Intelligence and Machine Learning.
Morgan & Claypool.
203

fiFeldman & Domshlak

Gelly, S., & Silver, D. (2011). Monte-Carlo tree search and rapid action value estimation in
computer Go. Artificial Intelligence, 175 (11), 18561875.
Guestrin, C., Koller, D., Parr, R., & Venkataraman, S. (2003). Efficient solution algorithms
for factored MDPs. Journal of Artificial Intelligence Research, 19, 399468.
Hay, N., Shimony, S. E., Tolpin, D., & Russell, S. (2012). Selecting computations: Theory
and applications. In Proceedings of the Annual Conference on Uncertainty in Artificial
Intelligence (UAI).
Kearns, M. J., Mansour, Y., & Ng, A. Y. (2002). A sparse sampling algorithm for nearoptimal planning in large Markov decision processes. Machine Learning, 49 (2-3),
193208.
Keller, T., & Eyerich, P. (2012). Probabilistic planning based on UCT. In Proceedings of
the 22nd International Conference on Automated Planning and Scheduling (ICAPS).
Keller, T., & Helmert, M. (2013). Trial-based heuristic tree search for finite horizon MDPs.
In Proceedings of the 23rd International Conference on Automated Planning and
Scheduling (ICAPS), pp. 135143.
Kocsis, L., & Szepesvari, C. (2006). Bandit based Monte-Carlo planning. In Proceedings
of the 17th European Conference on Machine Learning (ECML), pp. 282293, Berlin,
Germany.
Kolobov, A., Mausam, & Weld, D. (2012). LRTDP vs. UCT for online probabilistic planning. In Proceedings of the 26th AAAI Conference on Artificial Intelligence (AAAI).
Mausam, & Kolobov, A. (2012). Planning with Markov Decision Processes: An AI Perspective. Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan &
Claypool.
Peret, L., & Garcia, F. (2004). On-line search for solving Markov decision processes via
heuristic sampling. In Proceedings of the 16th Eureopean Conference on Artificial
Intelligence (ECAI), pp. 530534, Valencia, Spain.
Puterman, M. (1994). Markov Decision Processes. Wiley, New York.
Robbins, H. (1952). Some aspects of the sequential design of experiments. Bulletin of the
American Mathematical Society, 58 (5), 527535.
Smith, S. J., & Nau, D. S. (1994). An analysis of forward pruning. In Proceedings of the
AAAI Conference on Artificial Intelligence (AAAI), pp. 13861391.
Sturtevant, N. (2008). An analysis of UCT in multi-player games. In Proceedings of the 6th
International Conference on Computers and Games (CCG), p. 3749.
Tolpin, D., & Shimony, S. E. (2011). Doing better than UCT: Rational Monte Carlo sampling in trees. CoRR, arXiv:1108.3711v1 [cs.AI].
Tolpin, D., & Shimony, S. E. (2012). MCTS based on simple regret. In Proceedings of the
26th AAAI Conference on Artificial Intelligence (AAAI).
Walsh, T. J., Goschin, S., & Littman, M. L. (2010). Integrating sample-based planning and
model-based reinforcement learning. In Proceedings of the 24th AAAI Conference on
Artificial Intelligence (AAAI), pp. 612617.
204

fiSimple Regret Optimization in Online Planning for MDPs

Zilberstein, S. (1993). Operational Rationality through Compilation of Anytime Algorithms.
Ph.D. thesis, University of California at Berkeley.

205

fiJournal of Artificial Intelligence Research 51 (2014) 71-131

Submitted 5/14; published 9/14

On the Testability of BDI Agent Systems
Michael Winikoff
Stephen Cranefield

michael.winikoff@otago.ac.nz
stephen.cranefield@otago.ac.nz

Department of Information Science
University of Otago
New Zealand

Abstract
Before deploying a software system we need to assure ourselves (and stakeholders) that
the system will behave correctly. This assurance is usually done by testing the system.
However, it is intuitively obvious that adaptive systems, including agent-based systems,
can exhibit complex behaviour, and are thus harder to test. In this paper we examine this
obvious intuition in the case of Belief-Desire-Intention (BDI) agents. We analyse the
size of the behaviour space of BDI agents and show that although the intuition is correct,
the factors that influence the size are not what we expected them to be. Specifically, we
found that the introduction of failure handling had a much larger effect on the size of the
behaviour space than we expected. We also discuss the implications of these findings on
the testability of BDI agents.

1. Introduction
Increasingly we are called upon to develop software systems that operate in dynamic environments, that are robust in the face of failure, that are required to exhibit flexible behaviour, and that operate in open environments. One approach for developing such systems
that has demonstrated its effectiveness in a range of domains is the use of the metaphor
of software agents (Wooldridge, 2002). Agent-based systems have been increasingly finding
deployment in a wide range of applications (e.g. Munroe, Miller, Belecheanu, Pechoucek,
McBurney, & Luck, 2006; Benfield, Hendrickson, & Galanti, 2006).
As agent-based systems are increasingly deployed, the issue of assurance rears its head.
Before deploying a system, we need to convince those who will rely on the system (or those
who will be responsible if it fails) that the system will, in fact, work. Traditionally, this
assurance is done through testing1 . However, it is generally accepted that adaptive systems
can exhibit a wide and complex range of behaviours, making testing hard. For example:
Validation through extensive tests was mandatory . . . . However, the task proved
challenging . . . . Agent-based systems explore realms of behaviour outside peoples expectations and often yield surprises. (Munroe et al., 2006, Section 3.7.2)
That is, there is an intuition that agent systems exhibit complex behaviour, which makes
them hard to test. In this paper we explore this intuition, focusing on the well known BeliefDesire-Intention (BDI) approach to realising adaptive and flexible agents (Rao & Georgeff,
1. Although there is considerable research on formal methods in the context of agent systems (Dastani,
Hindriks, & Meyer, 2010), it is not yet ready for real world application (see Section 7), and there are
concerns about the scope of the work and its applicability (Winikoff, 2010).
c
2014
AI Access Foundation. All rights reserved.

fiWinikoff & Cranefield

1991; Bratman, 1987), which has been demonstrated to be practically applicable, resulting
in reduced development cost and increased flexibility (Benfield et al., 2006).
We explore the intuition that agent systems are hard to test by analysing both the
space of possible behaviours of BDI agents, that is, the number of paths through a BDI
program, and the probability of failure. We focus on BDI agents because they provide a welldefined execution mechanism that can be analysed, and also because we seek to understand
the complexities (and testability implications) of adaptive and intelligent behaviour in the
absence of parallelism (since the implications of parallelism are already well known).
We derive the number of paths through a BDI program as a function of various parameters (e.g. the number of applicable plans per goal and the failure fate). This naturally
leads us also to consider how the number of paths is affected by these various parameters.
As might be expected, we show that the intuition that agent systems are hard to test is
correct, i.e. that agent systems have a very large number of paths. We also show that BDI
agents are harder to test than procedural programs, by showing that the number of paths
through a BDI program is much larger than the number of paths through a similarly-sized
procedural program.
The contribution of this paper is threefold. Firstly, it confirms the intuition that BDI
programs are hard to test. Secondly, it does so by quantifying the number of paths, as a
function of parameters of the BDI program. Thirdly, we find some surprising results about
how the parameters influence the number of paths.
Although there has recently been increasing interest in testing agent systems (Zhang,
Thangarajah, & Padgham, 2009; Ekinci, Tiryaki, Cetin, & Dikenelli, 2009; Gomez-Sanz,
Bota, Serrano, & Pavon, 2009; Nguyen, Perini, & Tonella, 2009b), there has been surprisingly little work on determining the feasibility of testing agent systems in the first place.
Padgham and Winikoff (2004, pp. 1719) analyse the number of successful executions of a
BDI agents goal-plan tree (defined in Section 3), but they do not consider failure or failure
handling in their analysis, nor do they consider testability implications. Shaw, Farwer and
Bordini (2008) have analysed goal-plan trees and shown that checking whether a goal-plan
tree has an execution schedule with respect to resource requirements is NP-complete. This
is a different problem to the one that we tackle: they are concerned with the allocation of
resources amongst goals, rather than with the behaviour space.
We now briefly address a number of possible criticisms of this work, by considering
existing work.
1. Is the number of paths a useful metric for assessing testability?
We consider the related area of software testing (Section 1.1) and argue that the
metric is a well established one, and is appropriate to use to assess testability.
2. Isnt this just an obvious corollary of the complexity of HTN planning?
We consider in detail the HTN planning problem (Section 1.2) and argue that although
the BDI execution cycle has certain similarities with HTN planning, the differences
are significant, and, in particular, they mean that the problem of HTN planning is
simply different from the problem of testing BDI programs.
3. Why use combinatorial analysis, rather than complexity analysis?
Our combinatorial analysis is more precise: it yields formulae for the exact number
72

fiOn the Testability of BDI Agent Systems

of paths, and the exact probabilities of failure. The latter (see Section 4.5) is more
informative than just having an order of magnitude complexity. Additionally it allows
us to consider issues that complexity analysis would not address, such as the effect of
number of failures on the number of paths.
1.1 Software Testing
We are trying to assess how hard agent systems are to test. More concretely, given a BDI
agent program, we want to know how hard that program is to test. This can be reduced
directly to the question of test set adequacy. An agent program P is easy to test precisely
to the extent that there exists a test set T which is adequate for testing P , where T is
not infeasibly large. Conversely, an agent program P is hard to test to the extent that an
adequate test set T would have to be infeasibly large. In other words, the hardness of
testing a program is directly assessed by the size required for a test set to be adequate with
respect to a suitable adequacy criteria.
There are many criteria that can be used to assess whether a given set of tests is adequate (for a recent overview, see Mathur, 2008). Given that we are interested in assessing
the difficulty of testing a given program, we are clearly looking at white box testing. Furthermore, we will be working with abstract goal-plan trees rather than detailed programs
(see Section 2). This means that we need to consider control-flow based metrics, rather
than data-flow, since an abstract goal-plan tree does not contain data-flow information.
Focussing on white box testing criteria that are control-flow based, a basic and very
long-standing criterion for assessing test set adequacy is that all paths in the program be
covered (Miller & Maloney, 1963). For example, consider a program of the following form.
3. ... then do A
1. Input x

2. If condition ...

5. endif

6. do C

4. ... else do B

There are two paths through this program: (1, 2, 3, 5, 6) and (1, 2, 4, 5, 6), and an
adequate test set must have at least two tests to be adequate: one to exercise the first path,
and another to exercise the second. In this case a test set with only a single test will be
inadequate, and will result in part of the program not being executed at all during testing.
An obvious complication in covering all paths in a program is that any loop will result
in an infinite number of paths, since the loop can potentially be executed any number of
times. The standard technique for dealing with this is to bound the length of paths, or the
number of executions of a loop (Zhu, Hall, & May, 1997, p. 375). Bounding the execution of
loops can be done either by calculating an upper bound on the number of iterations based
on the data (Mathur, 2008, p. 53), or by only considering paths in which loops are executed
zero times or one time (Mathur, 2008, p. 408).
One question that might be asked is why we consider all paths, rather than a weaker
criterion. Agent applications typically involve environments that are non-episodic. That is,
the environments history matters. This means that the behaviour of a given plan or goal
is, in general, sensitive to the agents history, and hence we need to consider the different
possible histories. Achieving a goal may be different if it is being done as the first thing the
73

fiWinikoff & Cranefield

agent does, or after a failed plan which has already performed a number of actions. This
means that it makes sense to consider a path-based criterion for testing.
Furthermore, although the all paths adequacy criterion is often considered to be impractical, the reason appears to be primarily the existence of an infinite number of paths in
the presence of loops. For instance, Zhu et al. (1997, p. 375) say the plan coverage criterion
is too strong to be practically useful for most programs, because there can be an infinite
number of different paths in a program with loops. In our setting, where we do not have
loops, the existence of an infinite number of paths is not an issue, so considering the number
of paths is possible.
We therefore use the number of paths as our proxy measure for testing difficulty: if
there are few paths through the program, then an adequate test set (according to the all
paths criterion) will not need to be large. On the other hand, if the number of paths is
very large, then any adequate test set will need to be very large.
There is one issue we need to consider: since all paths is a strong criterion, it is
possible that, even in the absence (or bounding) of loops, this criterion always results in
an infeasibly large numbers of paths. In order to address this issue we also do an analysis
of the number of paths in procedural programs (of equivalent size), and compare this with
the number of paths for BDI programs (see Section 6).
Finally, it bears noting that the all paths criterion only considers which parts of the
program were traversed during testing, but ignores the values of variables. So, for example,
a trivial program consisting of the single statement x := x  x has a single one-step path,
which is trivially covered, but many traces (x = 0, 1, 2 . . .).
1.2 HTN Planning
There are similarities between Hierarchical Task Network (HTN) planning (Erol, Hendler,
& Nau, 1994) and BDI execution (de Silva & Padgham, 2004): both use a hierarchical
representation with goals (non-primitive tasks in HTN terminology), plans (decomposition methods) and goal-plan trees (task networks). The complexity of HTN planning
has been explored. Given these similarities, can we simply exploit these known complexity
results?
It turns out that we cannot do so, for the simple reason that the complexity of HTN
planning concerns the plan finding problem, which is different to BDI plan execution, as
Sardina and Padgham explain:
BDI agent systems and HTN planners come from different communities and
differ in many important ways. The former focus on the execution of plans,
whereas the latter is concerned with the actual generation of such plans. The
former are generally designed to respond to goals and information; the latter
are designed to bring about goals. In addition, BDI systems are meant to be
embedded in the real world and therefore take decisions based on a particular
(current) state. Planners, on the other hand, perform hypothetical reasoning
about actions and their interactions in multiple potential states. Thus, failure
has very different meaning for these two types of systems. In the context
of planning, failure means that a plan or potential plan is not suitable; within
BDI agent systems failure typically means that an active (sub)plan ought to be
74

fiOn the Testability of BDI Agent Systems

aborted. Whereas backtracking upon failure is an option for planning systems, it
is generally not for BDI systems, as actions are taken in the real world. (Sardina
& Padgham, 2011, p. 45, bold emphasis added)
In other words, HTN systems plan ahead of execution, whereas BDI systems interleave
execution and planning2 .
The HTN plan existence problem answers the question does a plan exist? and its
complexity has been studied. In settings that correspond to BDI execution (many goals,
total ordering within plans, and with variables) it is known to be EXPSPACE-hard and
in DEXPTIME (Erol, Hendler, & Nau, 1994, 1996). However, this work does not address
the question of BDI execution. When considering the complexity of plan existence in HTN
planning we are asking about the computational complexity of a search process that will
result in a plan. On the other hand, when we are asking about the number of paths in a
goal-plan tree we are asking about the possibilities that arise when executing a plan.
To illustrate this point, consider the following example. Suppose we have a single goal
G which can be decomposed into two alternative plans, P1 and P2 . Plan P1 consists of the
sequential execution of actions a, b, and c; and plan P2 consists of the sequential execution
of actions d and e. The plan existence problem boils down to considering the options P1
and P2 , since in this case the search space is very simple, offering only two options. On the
other hand, the question of how many paths exist in BDI execution considers the different
ways in which the goal-plan tree can be executed. Whereas HTN planning considers P1 as a
single atomic decomposition, BDI execution needs to consider the sequence of actions a, b, c
as distinct steps. It is possible for all three actions to succeed (giving the trace a, b, c), but
it also possible for action b to fail, followed by P2 being (successfully) used (giving the trace
a, b8, d, e), or for action c to fail, followed by P2 being (successfully) used (giving the trace
a, b, c8, d, e).
Overall, this means that the complexity analysis of Erol et al. (1994, 1996) is of a
different problem, and that the HTN complexity results are not relevant. Finally, we note
that, in fact, in our setting, the plan existence problem is actually trivially true: since
BDI programs do not have constraints there is always an expansion of the program into a
sequence of actions.
The remainder of this paper is structured as follows. We begin by briefly presenting
the BDI execution model (Section 2) and discussing how BDI execution can be viewed as a
process of transforming goal-plan trees (Section 3). Section 4 is the core of the paper where
we analyse the number of paths in a BDI-style goal-plan tree. We then consider how our
analysis and its assumptions hold up against a real system and a real platform (Section 5),
and how our analysis of BDI programs compares with the same analysis (number of paths)
of conventional procedural programs (Section 6). Finally, we conclude with a discussion of
the implications for testing and future work (Section 7).
2. There are approaches that blur this difference by adding look-ahead planning to BDI or online execution
to HTNs, for example the planner in the RETSINA multi-agent system (Paolucci, Shehory, Sycara, Kalp,
& Pannu, 2000) has the ability to interleave planning and execution. However, no theoretical analysis
of this extension has been reported, and the analysis of Erol, Hendler, and Nau (1994, 1996) applies to
classical HTN planning.

75

fiWinikoff & Cranefield

2. The BDI Execution Model
Before we describe the Belief-Desire-Intention (BDI) model we explain why we chose this
model of agent execution. In addition to being well known and widely used, the BDI model
is well defined and generic. That it is well defined allows us to analyse the behaviour spaces
that result from using it. That it is generic implies that our analysis applies to a wide range
of platforms.
The BDI model can be viewed from philosophical (Bratman, 1987) and logical (Rao
& Georgeff, 1991) perspectives, but we are interested here in the implementation perspective, as exhibited in a range of architectures and platforms, such as JACK (Busetta,
Ronnquist, Hodgson, & Lucas, 1999), JAM (Huber, 1999), dMARS (dInverno, Kinny, Luck,
& Wooldridge, 1998), PRS (Georgeff & Lansky, 1986; Ingrand, Georgeff, & Rao, 1992),
UM-PRS (Lee, Huber, Kenny, & Durfee, 1994), Jason (Bordini, Hubner, & Wooldridge,
2007), SPARK (Morley & Myers, 2004), Jadex (Pokahr, Braubach, & Lamersdorf, 2005)
and IRMA (Bratman, Israel, & Pollack, 1988). For the purposes of our analysis here, a
formal and detailed presentation is unnecessary. Those interested in formal semantics for
BDI languages are referred to the work of Rao (1996), Winikoff, Padgham, Harland, and
Thangarajah (2002) and Bordini et al. (2007), for example.
In the implementation of a BDI agent the key concepts are beliefs (or, more generally,
data), events and plans. The reader may find it surprising that goals are not key concepts in
BDI systems. The reason is that goals are modelled as events: the acquisition of a new goal
is viewed as a new goal event, and the agent responds by selecting and executing a plan
that can handle that event3 . In the remainder of this section, in keeping with established
practice, we will describe BDI plans as handling events (not goals).
A BDI plan consists of three parts: an event pattern specifying the event(s) it is relevant
for, a context condition (a Boolean condition) that indicates in what situations the plan can
be used, and a plan body that is executed. A plans event pattern and context condition
may be terms containing variables, so a matching or unification process (depending on the
particular BDI system) is used by BDI interpreters to find plan instances that respond to
a given event. In general the plan body can contain arbitrary code in some programming
language4 , however for our purposes we assume5 that a plan body is a sequence of steps,
where each step is either an action6 (which can succeed or fail) or an event to be posted.
For example, consider the simple plans shown in Figure 1. The first plan, Plan A, is
relevant for handling the event achieve goal go-home, and it is applicable in situations
where the agent believes that a train is imminent. The plan body consists of a sequence of
four steps (in this case we assume that these are actions, but they could also be modelled
as events that are handled by further plans).
A key feature of the BDI approach is that each plan encapsulates the conditions under
which it is applicable by defining an event pattern and context condition. This allows
for additional plans for a given event to be added in a modular fashion, since the invoking
3. Other types of event typically include the addition and removal of beliefs from the agents belief set.
4. For example, in JACK a plan body is written in a language that is a superset of Java.
5. This follows abstract notations such as AgentSpeak(L) (Rao, 1996) and Can (Winikoff et al., 2002)
which aim to capture the essence of a range of (more complex) BDI languages.
6. This includes both traditional actions that affect the agents environment, and internal actions that
invoke code, or that check whether a certain condition follows from the agents beliefs.

76

fiOn the Testability of BDI Agent Systems

Plan A: handles event:
achieve goal go-home
context condition:
train imminent
plan body:
(1) walk to train station
(2) check train running on time
(3) catch train
(4) walk home
Plan B: handles event:
achieve goal go-home
context condition:
not raining and have bicycle
plan body:
(1) cycle home
Plan C: handles event:
achieve goal go-home
context condition:
true (i.e. always applicable)
plan body:
(1) walk to bus stop
(2) check buses running
(3) catch bus
(4) walk home
Figure 1: Three Simple Plans
context (i.e. where the triggering event is posted) does not contain code that selects amongst
the available plans, and this is a key reason for the flexibility of BDI programming.
A typical BDI execution cycle is an elaboration of the following event-driven process
(summarised in Figure 2)7 :
1. An event occurs (either received from an outside source, or triggered from within the
agent).
2. The agent determines a set of instances of plans in its plan library with event patterns
that match the triggering event. This is the set of relevant plan instances.
3. The agent evaluates the context conditions of the relevant plan instances to generate
the set of applicable plan instances. A relevant plan instance is applicable if its context
condition is true. If there are no applicable plan instances then the event is deemed
to have failed, and if it has been posted from a plan, then that plan fails. Note that a
single relevant plan may lead to no applicable plan instances (if the context condition
is false), or to more than one applicable plan instance (if the context condition, which
may contain free variables, has multiple solutions).
4. One of the applicable plan instances is selected and is executed. The selection mechanism varies between platforms. For generality, our analysis does not make any as7. BDI engines are, in fact, more complicated than this as they can interleave the execution of multiple
active plan instances (or intentions) that were triggered by different events.

77

fiWinikoff & Cranefield

Boolean function execute(an-event)
let relevant-plans = set of plan instances resulting from
matching all plans event patterns to an-event
let tried-plans = 
while true do
let applicable-plans = set of plan instances resulting from
solving the context conditions of relevant-plans
applicable-plans := applicable-plans \ tried-plans
if applicable-plans is empty then return false
select plan p  applicable-plans
tried-plans := tried-plans  {p}
if execute(p.body) = true then return true
endwhile
Boolean function execute(plan-body)
if plan-body is empty then return true
elseif execute(first(plan-body)) = false then return false
else return execute(rest(plan-body))
endif
Boolean function execute(action)
attempt to perform the action
if action executed successfully then return true else return false endif

Figure 2: BDI Execution Cycle
sumptions about plan selection. The plans body may create additional events that
are handled using this process.
5. If the plan body fails, then failure handling is triggered.
For brevity, in the remainder of the paper we will use the term plan loosely to mean
either a plan or plan instance where the intention is clear from context.
Regarding the final step, there are a few approaches to dealing with failure. Perhaps
the most common approach, which is used in many of the existing BDI platforms, is to
select an alternative applicable plan, and only consider an event to have failed when there
are no remaining applicable plans. In determining alternative applicable plans one may
either consider the existing set of applicable plans, or re-calculate the set of applicable
plans (ignoring those that have already been tried), as is done in Figure 2. This makes
sense because the situation may have changed since the applicable plans were determined.
Many (but not all) BDI platforms use the same failure-handling mechanism of retrying
plans upon failure, and our analysis applies to all of these platforms.
One alternative failure-handling approach, used by Jason (Bordini et al., 2007), is to
post a failure event that can be handled by a user-provided plan. Although this is more
flexible, since the user can specify what to do upon failure, it does place the burden of
78

fiOn the Testability of BDI Agent Systems

specifying failure handling on the user. Note that Jason provides a pattern that allows the
traditional BDI failure-handling mechanism to be specified succinctly (Bordini et al., 2007,
pp. 171172). Another alternative failure-handling approach is used by 2APL (Dastani,
2008) and its predecessor, 3APL: they permit the programmer to write plan repair rules
which conditionally rewrite a (failed) plan into another plan. This approach, like Jasons,
is quite flexible, but is not possible to analyse in a general way because the plan rules can
be quite arbitrary. Another well known BDI architecture is IRMA, which is described at a
high-level and does not prescribe a specific failure-handling mechanism:
A full development of this architecture would have to give an account of the
ways in which a resource-bounded agent would monitor her prior plans in the
light of changes in belief. However this is developed, there will of course be
times when an agent will have to give up a prior plan in light of a new belief
that this plan is no longer executable. When this happens, a new process of
deliberation may be triggered (Bratman et al., 1988).
Given the BDI execution cycle discussed above, the three example plans given earlier
(Figure 1) can give rise to a range of behaviours, including the following:
 Suppose the event achieve goal go-home is posted and the agent believes that a
train is imminent. It walks to the train station, finds out that the train is running on
time, catches the train, and then walks home.
 Suppose that upon arrival at the train station the agent finds out that trains are
delayed. Step (2) of Plan A fails, and the agent considers alternative plans. If it is
raining at the present time, then Plan B is not applicable, and so Plan C is adopted
(to catch the bus).
 Suppose that the agent has decided to catch the bus (because no train is believed to
be imminent, and it is raining), and that attempting to execute Plan C fails (e.g. there
is a bus strike). The agent will reconsider its plans and if the rain has stopped (and
it has a bicycle) it may then use Plan B.
Note that correct (respectively incorrect) behaviour is distinct from successful
(respectively failed) execution of a plan. Software testing is in essence the process of running a system and checking whether an observed behaviour trace is correct (i.e. conforms
to a specification, which we do not model). On the other hand, BDI agents behaviour traces
are classified as being successful or failed. However, the correctness of a given execution
trace is independent of whether the trace is of a successful or failed execution. A successful
execution may, in fact, exhibit behaviour that is not correct, for instance, a traffic controller
agent may successfully execute actions that set all traffic signals at an intersection to green
and achieve a goal by doing so. This is a successful execution, but incorrect behaviour. It is
also possible for a failed execution to be correct. For instance, if a traffic controller agent is
attempting to route cars from point A to point B, but a traffic accident has blocked a key
bridge between these two points, then the rational (and correct) behaviour for the agent is
to fail to achieve the goal.
79

fiWinikoff & Cranefield

3. BDI Execution as Goal-Plan Tree Expansion
BDI execution, as summarised in Figure 2, is a dynamic process that progressively executes
actions as goals are posted. In order to more easily analyse this process, we now present an
alternative view that is more declarative. Instead of viewing BDI execution as a process,
we view it as a data transformation from a (finite) goal-plan tree into a sequence of action
executions.
The events and plans can be visualised as a tree where each goal8 has as children the
plan instances that are applicable to it, and each plan instance has as children the sub-goals
that it posts. This goal-plan tree is an and-or tree: each goal is realised by one of its plan
instances (or) and each plan instance needs all of its sub-goals to be achieved (and).
Viewing BDI execution in terms of a goal-plan tree and action sequences makes the
analysis of the behaviour space size9 easier. We consider BDI execution as a process of taking
a goal-plan tree and transforming it into a sequence recording the (failed and successful)
executions of actions, by progressively making decisions about which plans to use for each
goal and executing these plans.
This process is non-deterministic: we need to choose a plan for each goal in the tree.
Furthermore, when we consider failure, we need to consider for each action whether it fails
or not, and if it does fail, what failure recovery is done.
We now define the transformation process in detail. Prolog code implementing the
process can be found in Figure 3. It defines a non-deterministic predicate exec with its first
argument being the (input) goal-plan tree, and the second argument an (output) sequence
of actions. A goal-plan tree is represented as a Prolog term conforming to the following
simple grammar (where GPT abbreviates Goal-Plan Tree, AoGL abbreviates Action or
Goal List, and A is a symbol):
hGPT i ::= goal([]) | goal([hPlanListi])
hPlanListi ::= hPlani | hPlani,hPlanListi
hPlani ::= plan([]) | plan([hAoGLi])
hAoGLi ::= act(A) | hGPT i | act(A),hAoGLi | hGPT i,hAoGLi
For example, the simple goal-plan tree shown in Figure 4 is modelled by the Prolog term
goal([plan([act(a)]), plan([act(b)])]).
In our analysis we make a simplifying assumption. Instead of modelling the instantiation
of plans to plan instances, we assume that the goal-plan tree contains applicable plan
instances. Thus, in order to transform a goal node into a sequence of actions we (nondeterministically) select one of its applicable plan instances. The selected plan is then
transformed in turn, resulting in an action sequence (line 2 in Figure 3). When selecting a
plan, we consider the possibility that any of the applicable plans could be chosen, not just
the first plan. This is done because at different points in time different plan instances may
be applicable. We saw an example of this earlier, where Plan A was chosen and failed, then
8. In order to be consistent with existing practice we shall use the term goal rather than event in the
remainder of this paper.
9. In the remainder of this paper we will use the term behaviour space size, rather than the more
cumbersome term number of paths through a BDI program.

80

fiOn the Testability of BDI Agent Systems

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

exec ( goal ([]) ,[]).
exec ( goal ( Plans ) , Trace ) : - remove ( Plans , Plan , Rest ) , exec ( Plan , Trace1 ) ,
( failed ( Trace1 ) -> recover ( Rest , Trace1 , Trace ) ; Trace = Trace1 ).
exec ( plan ([]) , []).
exec ( plan ([ Step | Steps ]) , Trace ) : - exec ( Step , Trace1 ) ,
( failed ( Trace1 ) -> Trace = Trace1 ; continue ( Steps , Trace1 , Trace )).
exec ( act ( Action ) , [ Action ]).
exec ( act ( Action ) , [ Action , fail ]).
failed ( Trace ) : - append (X ,[ fail ] , Trace ).
recover ( Plans , Trace1 , Traces ) : exec ( goal ( Plans ) , Trace2 ) , append ( Trace1 , Trace2 , Traces ).
continue ( Steps , Trace1 , Trace ) : - exec ( plan ( Steps ) , Trace2 ) ,
append ( Trace1 , Trace2 , Trace ).
remove ([ X | Xs ] ,X , Xs ).
remove ([ X | Xs ] ,Y ,[ X | Z ]) : - remove ( Xs ,Y , Z ).

Figure 3: Prolog Code to Expand Goal-Plan Trees
goal
plan

plan

a

b

Figure 4: A Simple Goal-Plan Tree

Plan C was selected (and also failed), and then finally Plan B (which was not applicable
when Plan A failed) was selected.
If the selected plan executes successfully (i.e. the action trace doesnt end with a fail
marker; line 9), then the resulting trace is the trace for the goals execution (line 3). Otherwise, we perform failure recovery (line 10), which is done by taking the remaining plans
and transforming the goal with these plans as options. The resulting action sequence is
appended to the action sequence of the failed plan to obtain a complete action sequence for
the goal.
This process can easily be seen to match that described in Figure 2 (with the exception,
discussed above, that we begin with applicable plans, not relevant plans). Specifically, an
applicable plan is selected and executed, and if it is successful then execution stops. If it
is not successful, then an alternative plan is selected and execution continues (i.e. action
sequences are appended).
In order to transform a plan node we first transform the first step of the plan, which is
either a sub-goal or an action (line 5). If this is successful, then we continue to transform
the rest of the plan, and append the two resulting traces together (lines 6 and 12). If the
first step of the plan is not successful, then the trace is simply the trace of the first step
(line 6); in other words we stop transforming the plan when a step fails. Again, this process
can easily be seen to correspond to plan body execution in Figure 2.
81

fiWinikoff & Cranefield

Finally, in order to transform an action into an action sequence we simply take the
action itself as a singleton sequence (line 7). However, we do need to also take into account
the possibility that an action may fail, and thus a second possibility is the action followed
by a failure indicator (line 8). Again, this process can easily be seen to correspond to action
execution in Figure 2. Note that in our model we dont concern ourselves with why an
action fails: it could be because of a lack of resources, or other environmental issues.
An example of applying this process to two example goal-plan trees can be found in
Appendix A.

4. Behaviour Space Size of BDI Agents
We now consider how many paths there are through a goal-plan tree that is being used by
a BDI agent to realise a goal10 using that tree. We use the analysis of the previous section
as our basis; that is, we view BDI execution as transforming a goal-plan tree into action
traces. Thus, the question of how large the behaviour space is for BDI agents, is answered
by deriving formulae that allow one to compute the number of behaviours, both successful
and unsuccessful (i.e. failed), for a given goal-plan tree.
We make the following uniformity assumptions that allow us to perform the analysis.
These simplifying assumptions concern the form of the goal-plan tree.
1. We assume that all subtrees of a goal or plan node have the same structure. That is,
all of the leaves of the goal-plan tree are the same distance (number of edges) away
from the root of the tree. We can therefore define the depth of a goal-plan tree as
the number of layers of goal nodes it contains. A goal-plan tree of depth 0 is a plan
with no sub-goals, while a goal-plan tree of depth d > 0 is either a plan node with
children that are goal nodes at depth d or a goal node with children that are plan
nodes at depth d  1. Note that this definition of depth is the reverse of the usual
definition (where the depth of the trees root is defined as 0). We use this definition
as it simplifies the presentation of the derivations later in this section.
2. We assume that all plan instances at depth d > 0 have k sub-goals.
3. We assume that all goals have j applicable plan instances. This can be the case if
each goal has j relevant plans, each of which results in exactly one applicable plan
instance, but can also be the case in other ways. For instance, a goal may have 2j
relevant plans, half of which are applicable in the current situation, or a goal may have
a single relevant plan that has j applicable instances. Note that this assumption rules
out the possibility of there being an infinite number of applicable plan instances, which
would be the case if a plans context condition has an infinite number of solutions.
This cannot occur if the context condition is defined in terms of conjunctions over
propositions that refer to a finite belief base. However, it can occur if the agents
context conditions can also make use of a Prolog-like knowledge base (as is the case in
some agent-oriented programming languages, such as Jason or Goal). Nevertheless,
since we deal with applicable plans, we dont model context conditions.
10. We focus on a single goal in our analysis: multiple goals can be treated as the concurrent interleaving
of the individual goals. Multiple agents can also be treated as concurrent interleaving, but some care
needs to be taken with the details where an agent is waiting for another agent to respond.

82

fiOn the Testability of BDI Agent Systems

Figure 5 shows a uniform goal-plan tree of depth 2.
g2

d=2

@
R pj1
p11	 . . . @
..
.
@
	
R
@
g11 . . . gk1
..
.
@
	
R
@
p10 . . . pj0

d=1
d=1
d=0

Figure 5: A uniform goal-plan tree
The assumptions made are clearly unrealistic. This means that we have to consider
the possibility that real agent programs behave quite differently, since they do not meet
these assumptions. We address this issue in a number of ways. Firstly, in Section 4.4
we consider a relaxation of the assumptions by defining semi-uniform trees, in which the
number of available plan instances (j) can vary across different levels of the tree. Secondly,
in Section 5.2 we consider an example of a (non-uniform) goal-plan tree from an industrial
application. We derive the number of paths for this real goal-plan tree and compare it to
the analysis of similarly-sized uniform goal-plan trees to see whether a real (non-uniform)
tree has a significantly lower number of paths than a uniform tree. Finally, in Section 4.7,
we consider the issue of infinite trees by allowing trees to be recursive, and defining the
number of paths (up to a bound on the path length) of a recursive tree.
Our analysis uses the following terminology:
 Our uniformity assumptions mean that the structure of the subtree rooted at a goal
or plan node is determined solely by its depth, and we can therefore denote a goal or
plan node at depth d as gd or pd (respectively).
 We use n4(xd ) to denote the number of successful execution paths of a goal-plan tree
of depth d rooted at x (where x is either a goal g or a plan p). Where specifying d is
not important we will sometimes elide it, writing n4(x).
 Similarly, we use n8(xd ) to denote the number of unsuccessful execution paths of a
goal-plan tree of depth d with root x (either g or p).
 We extend this notation to plan body segments, i.e. sequences x1 ; . . . ; xn where each xi
is a goal or action and ; denotes sequential composition. We abbreviate a sequence
of n occurrences of x by xn (for example, g13 = g1 ; g1 ; g1 ).
4.1 Base Case: Successful Executions
We begin by calculating the number of successful paths through a goal-plan tree in the
absence of failure (and of failure handling). This analysis follows that of Padgham and
Winikoff (2004, pp. 1719).
Roughly speaking, the number of ways a goal can be achieved is the sum of the number
of ways in which its children can be achieved (since the children represent alternatives,
83

fiWinikoff & Cranefield

i.e. the goal is represented by an or node). On the other hand, the number of ways a plan
can be achieved is the product of the number of ways in which its children can be achieved
(since the children must all be achieved, i.e. the plan is represented by an and node).
More precisely, n4(x1 ; x2 ) = n4(x1 ) n4(x2 ); that is, the sequence is successful if both x1 and
x2 are successful.
Given a tree with root g (a goal), assume that each of its j children can be achieved in
n different ways11 ; then, because we select one of the children, the number of ways in which
g can be achieved is jn. Similarly, for a tree with root p (a plan), assume that each of its
k children can be achieved in n different ways, then, because we execute all of its children,
the number of ways in which p can be executed is n    n, or nk . A plan with no children
(i.e. at depth 0) can be executed (successfully) in exactly one way. This yields the following
definition:
n4(gd ) = j n4(pd1 )
n4(p0 ) = 1
n4(pd ) = n4(gd k ) = n4(gd )k
Expanding this definition we obtain
n4(g1 ) = j n4(p0 ) = j 1 = j
k

n4(g2 ) = j n4(p1 ) = j (n4(g1 ) ) = j (j k ) = j k+1
n4(g3 ) = j n4(p2 ) = j (j k+1 )k = j k
n4(g4 ) = j n4(p3 ) = j (j k

2 +k+1

2 +k+1

)k = j k

3 +k 2 +k+1

which can be generalised to:
n4(gd ) = j

Pd1
i=0

ki

If k > 1 this can be simplified using the equivalence k i1 + . . . + k 2 + k + 1 = (k i  1)/(k  1)
to give the following closed form definition: (and if k = 1 we have n4(gd ) = n4(pd ) = j d )
n4(gd ) = j (k
4

n (pd ) = j

d 1)/(k1)

k (kd 1)/(k1)

(1)
(2)

Note that the equation for n4(pd ) assumes that sub-goals are achieved sequentially. If
they are executed in parallel then the number of options is higher, since we need to consider
all possible interleavings of the sub-goals execution. For example, suppose that a plan pd
has two sub-goals, g1d and g2d , where each of the sub-goals has n4(gd ) successful executions,
and each execution has l steps (we assume for ease of analysis that both execution paths
have the same length). The number of ways of interleaving two parallel executions, each of
length l, can be calculated as follows (Naish, 2007, Section 3):


(2 l)!
2l
=
l
(l!) (l!)
11. Because the tree is assumed to be uniform, all of the children can be achieved in the same number of
ways, and are thus interchangeable in the analysis, allowing us to write j n rather than n1 + . . . + nj .

84

fiOn the Testability of BDI Agent Systems

and hence the number of ways of executing pd with parallel execution of subgoals is:
4

4

2



n (pd ) = n (gd )

2l
l



= n4(gd )2

(2 l)!
(l!) (l!)

In the remainder of this paper we assume that the sub-goals of a plan are achieved
sequentially, since this is the common case, and since it yields a lower figure which, as we
shall see, is still large enough to allow for conclusions to be drawn.
4.2 Adding Failure
We now extend the analysis to include failure, and determine the number of unsuccessful
executions, i.e. executions that result in failure of the top-level goal. For the moment we
assume that there is no failure handing (we add failure handling in Section 4.3).
In order to determine the number of failed executions we have to know where failure
can occur. In BDI systems there are two places where failure occurs: when a goal has no
applicable plan instances, and when an action (within an applicable plan instance) fails.
However, our uniformity assumption means that we do not address the former caseit is
assumed that a goal will always have j instances of applicable plans. Note that this is a
conservative assumption: relaxing it results in the number of unsuccessful executions being
even larger.
In order to model the latter case we need to extend our model of plans to encompass
actions. For example, suppose that a plan has a body of the form a1; ga; a2; gb; a3 where ai
are actions, ga and gb are sub-goals, and ; denotes sequential execution. Then the plan
has the following five cases of unsuccessful (i.e. failed) executions:
1. a1 fails
2. a1 succeeds, but then ga fails
3. a1 and ga succeed, but a2 fails
4. a1, ga, and a2 succeed, but then gb fails
5. a1, ga, a2 and gb succeed, but a3 fails
Suppose that ga can be executed successfully in n4(ga) different ways. Then the third
case corresponds to n4(ga) different failed executions: for each successful execution of ga,
extend it by adding a failed execution of a2 (actions can only be executed in one way,
i.e. n4(a) = 1 and n8(a) = 1). Similarly, if gb has n4(gb) successful executions then the fifth
case corresponds to n4(ga) n4(gb) different failed executions. If ga can be unsuccessfully
executed in n8(ga) different ways then the second case corresponds to n8(ga) different executions. Similarly, the fourth case corresponds to n4(ga) n8(gb) different executions. Putting
this together, we have that the total number of unsuccessful executions for a plan p with
body a1; ga; a2; gb; a3 is the sum of those for the above five cases:
1 + n8(ga) + n4(ga) + n4(ga) n8(gb) + n4(ga) n4(gb)
85

fiWinikoff & Cranefield

More formally, n8(x1 ; x2 ) = n8(x1 ) + n4(x1 ) n8(x2 ); that is, the sequence can fail if either
x1 fails, or if x1 succeeds but x2 fails. It follows that n4(xk ) = n4(x)k and n8(xk ) =
n8(x) (1 +    + n4(x)k1 ), which can easily be proven by induction.
More generally, we assume there are ` actions before, after, and between the sub-goals
in a plan, i.e. the above example plan corresponds to ` = 1, and the following plan body
corresponds to ` = 2: a1; a2; g3; a4; a5; g6; a7; a8. A plan with no sub-goals (i.e. at depth
0) is considered to consist of ` actions (which is quite conservative: in particular, when we
use ` = 1 we assume that plans at depth 0 consist of only a single action).
The number of unsuccessful execution traces of a goal-plan tree can then be defined,
based on the analysis above, as follows. First we calculate the numbers of successes and
failures of the following repeated section of a plan body: gd ; a` :
n4(gd ; a` ) = n4(gd ) n4(a` )
= n4(gd ) n4(a)`
= n4(gd ) 1`
= n4(gd )
n8(gd ; a` ) = n8(gd ) + n4(gd ) n8(a` )
= n8(gd ) + n4(gd ) n8(a) (1 +    + n4(a)`1 )
= n8(gd ) + n4(gd ) `
We then have for d > 0:
n8(pd ) = n8(a` ; (gd ; a` )k )
= n8(a` ) + n4(a` ) n8((gd ; a` )k )
= n8(a) (1 +    + n4(a)`1 )) + n4(a)` n8((gd ; a` )k )
= ` + 1 n8(gd ; a` ) (1 +    + n4(gd ; a` )k1 )
= ` + (n8(gd ) + n4(gd ) `) (1 +    + n4(gd )k1 ))
n4(gd )k  1
= ` + (n8(gd ) + ` n4(gd )) 4
(assuming n4(gd ) > 1)
n (gd )  1
This yields the following definitions for the number of unsuccessful executions of a goalplan tree, without failure handling. The equation for n8(gd ) is derived using the same
reasoning as in the previous section: a single plan is selected and executed, and there are j
plans.
n8(gd ) = j n8(pd1 )
n8(p0 ) = `
n4(gd )k  1
n4(gd )  1
4
(for d > 0 and n (gd ) > 1)

n8(pd ) = ` + (n8(gd ) + ` n4(gd ))

Finally, we note that the analysis of the number of successful executions of a goal-plan
tree in the absence of failure handling presented in Section 4.1 is unaffected by the addition
of actions to plan bodies. This is because there is only one way for a sequence of actions to
succeed, so Equations 1 and 2 remain correct.
86

fiOn the Testability of BDI Agent Systems

4.3 Adding Failure Handling
We now consider how the introduction of a failure-handling mechanism affects the analysis.
A common means of dealing with failure in BDI systems is to respond to the failure of a
plan by trying an alternative applicable plan for the event that triggered that plan. For
example, suppose that a goal g (e.g. achieve goal go-home) has three applicable plans pa,
pb and pc, that pa is selected, and that it fails. Then the failure-handling mechanism will
respond by selecting pb or pc and executing it. Assume that pc is selected. Then if pc fails,
the last remaining plan (pb) is used, and if it too fails, then the goal is deemed to have
failed.
The result of this is that, as we might hope, it is harder to fail: the only way a goal
execution can fail is if all of the applicable plans are tried and each of them fails12 .
The number of executions can then be computed as follows: if a goal gd has j applicable plan instances, each having n8(pd1 ) unsuccessful executions, then we have n8(pd1 )j
unsuccessful executions of all of these plans in sequence. Since the plans can be selected in
any order we multiply this by j! yielding n8(gd ) = j! n8(pd1 )j .
The number of ways in which a plan can fail is still defined by the same equation
because failure handling happens at the level of goalsbut where n8(g) refers to the new
definition:
j

n8(gd ) = j! n8(pd1 )

(3)

8

n (p0 ) = `

(4)
4

)k

n (gd  1
n4(gd )  1
4
(for d > 0 and n (gd ) > 1)

n8(pd ) = ` + (n8(gd ) + ` n4(gd ))

(5)

Turning now to the number of successful executions (i.e. n4(x)) we observe that the
effect of adding failure handling is to convert failures to successes, i.e. an execution that
would otherwise be unsuccessful is extended into a longer execution that may succeed.
Consider a simple case: a depth 1 tree consisting of a goal g (e.g. achieve goal go-home)
with three children: pa, pbandpc. Previously the successful executions corresponded to each
of the pi (i.e. select a pi and execute it). However, with failure handling, we now have
the following additional successful executions (as well as additional cases corresponding to
different orderings of the plans, e.g. pb failing and then pa being successfully executed):
 pa fails, then pb is executed successfully
 pa fails, pb is then executed and fails, and then pc is executed and succeeds
This leads to a definition of the form
n4(g) = n4(pa) + n8(pa) n4(pb) + n8(pa) n8(pb) n4(pc)
12. In fact, this is actually an underestimate: it is also possible for the goal to fail because none of the untried
relevant plans are applicable in the resulting situation. As noted earlier, we assume in our analysis that
goals cannot fail as a result of there being no applicable plan instances. This is a conservative assumption:
relaxing it results in the number of behaviours being even larger.

87

fiWinikoff & Cranefield

However, we need to account for different orderings of the plans. For instance, the case
where the first selected plan succeeds (corresponding to the first term, n4(pa)) in fact applies
for each of the j plans, so the first term, including different orderings, is j n4(p).
Similarly, the second term (n8(pa) n4(pb)), corresponding to the case where the initially
selected plan fails but the next plan selected succeeds, in fact applies for j initial plans, and
then for j  1 next plans, yielding j (j  1) n8(p) n4(p).
Continuing this process (for j = 3) yields the following formulae:
2

n4(g) = 3 n4(p) + 32 n8(p) n4(p) + 3! n8(p) n4(p)
which generalises to
j1

n4(g) = j n4(p) + j (j  1) n8(p) n4(p) +    + j! n8(p)

n4(p)

resulting in the following equations (again, since failure handling is done at the goal level,
the equation for plans is the same as in Section 4.1):
4

n (gd ) =

j
X

i1

n8(pd1 )

n4(pd1 )

i=1

n4(p0 ) = 1
4

j!
(j  i)!

(6)
(7)

4

n (pd ) = n (gd )

k

(for d > 0 )

(8)

We have used the standard BDI failure-handling mechanism of trying alternative
applicable plans. Now let us briefly consider an alternative failure-handling mechanism
that simply re-posts the event, without tracking which plans have already been attempted.
It is fairly easy to see that this, in fact, creates an infinite number of behaviours: suppose
that a goal g can be achieved by pa or pb, then pa could be selected, executed resulting
in failure, and then pa could be selected again, fail again, etc. This suggests that the
standard BDI failure-handling mechanism is, in fact, more appropriate, in that it avoids
an infinite behaviour space, and the possibility of an infinite loop. As discussed earlier (in
Section 2), the failure recovery mechanism used by 3APL and 2APL (Dastani, 2008) cannot
be analysed in a general way, since it depends on the details of the specific agent program;
and IRMA (Bratman et al., 1988) does not provide sufficient details to allow for analysis.
Tables 1 and 2 make the various equations developed so far concrete by showing illustrative values for n8 and n4 for a range of reasonable (and fairly low) values for j, k and
d and using ` = 1. The Number of columns show the number of goals, plans and actions in the tree. The number of actions in brackets is how many actions are executed in a
single (successful) execution with no failure handling. The number of goals is calculated
as follows. At depth 1 there is a single goal (see Figure 5). At depth n + 1 there are
1 + (j  k  G(n)) goals, where G(n) denotes the number of goals in a depth n tree. This
gives G(n) = 1 + (j  k) + (j  k)2 +    + (j  k)n1 . For example, for j = k = 2, we have
G(3) = 1 + 4 + 16 = 21. Since each goal has exactly j plans, the number of plans in a tree
of depth n is just j  G(n). We now consider the number of actions. Each non-leaf plan has
`  (k + 1) actions (since it has k goals, there are k + 1 places where there are ` actions).
Each leaf plan has ` actions. A tree of depth n has j  (j  k)n1 leaf plans. Let P (n)
be the number of plans in a depth n tree, which is comprised of Pn (n) non-leaf plans and
88

fiOn the Testability of BDI Agent Systems

Parameters
j k
d
2 2
3
3 3
3
2 3
4
3 4
3

goals
21
91
259
157

Number
plans
42
273
518
471

of
actions
62 (13)
363 (25)
776 (79)
627 (41)

n4(g)
128
1,594,323

n8(g)
614
6,337,425

1,099,511,627,776

6,523,509,472,174

10,460,353,203

41,754,963,603

Table 1: Illustrative values for n4(g) and n8(g) without failure handling. The first number under actions (e.g. 62) is the number of actions in the tree, the second
(e.g. 13) is the number of actions in a single execution where no failures occur.

Parameters
j k
d
2 2
3
3 3
3
2 3
4
3 4
3

goals
21
91
259
157

Number
plans
42
273
518
471

of
actions
62 (13)
363 (25)
776 (79)
627 (41)

n4(g)
 6.33  1012
 1.02  10107
 1.82  10157
 3.13  10184

n8(g)
 1.82  1013
 2.56  10107
 7.23  10157
 7.82  10184

Table 2: Illustrative values for n4(g) and n8(g) with failure handling
Pl (n) leaf plans, i.e. P (n) = Pn (n) + Pl (n). Then the number of actions in a depth n tree
is (`  (k + 1))  Pn (n) + `  Pl (n). For example, for j = k = 2 and ` = 1, we have that
P (3) = 2  G(3) = 42, which is comprised of 32 leaf plans and 10 non-leaf plans. There are
therefore (1  3  10) + (1  32) = 62 actions.
4.4 Recurrence Relations
The equations in the previous sections define the functions n4 and n8 as a mutual recurrence
on the depth d of a goal-plan tree with a uniform branching structure. The effect of
increasing the parameters k and ` is evident at each level of the recursion, but it is not
so clear what the effect is of increasing the number of applicable plan instances j for any
given goal. The aim of this section is to explore the effects of changing j. We do this by
relaxing our uniformity assumption. Specifically, we allow the number of plans available to
vary for goal nodes at different depths in the tree, while still assuming that all nodes at a
given depth have the same structure. We refer to these as semi-uniform goal-plan trees.
We then derive a set of recurrence relations for n4 and n8 in the presence of failure handling
that explicitly show the effect of adding a new plan for a goal at the root of any particular
sub-tree.
We begin by defining the generalised notation n8(gj ) and n4(gj ) where j is a list13
(jd , jd1 , . . . , j0 ) in which each element ji represents the number of plans available for goals
at depth i of the goal-plan tree. We denote the empty list by hi and write j  j to represent
the list with head j and tail j.
13. The order corresponds to our definition of depth, which decreases down the tree.

89

fiWinikoff & Cranefield

We can generalise Equations 3 and 6 to apply to semi-uniform goal-plan trees, as the
derivation of these equations depended only on the sub-nodes of each goal or plan node
having the same structure. This assumption is preserved in this generalised setting. We
therefore rewrite these equations below using this new notation, and also express the right
hand sides as functions f 8 and f 4 of n8(pj ) and (for f 4 ) n4(pj ). Our aim is to find a recursive
definition of f 8 and f 4 as a recurrence on j.
n8(gjj ) = f 8 (j, n8(pj ))
n4(gjj ) = f 4 (j, n8(pj ), n4(pj ))
where
f 8 (j, a) = j! aj
f 4 (j, a, b) =

j
X

b ai1

i=1

j!
(j  i)!

(change bounds on i to 0 . . . n, hence replace i by i + 1)
=

j1
X

b a(i+1)1

i=0

j!
(j  (i + 1))!

(simplify using (j  (i + 1))! = (j  i)!/(j  i) )
=

j1
X
i=0

b ai

j!(j  i)
(j  i)!

(multiple by i!/i! and reorder)
=

j1
X
i=0

j!
i! ai (j  i) b
i!(j  i)!

 
j
(use definition of binomial:
= j!/i!(j  i)!)
i
j1  
X
j
i! ai (j i) b
=
i

(9)

i=0

The expression on the right of the last line above corresponds to the following combinatorial analysis of f 4 . For a goal gjj , each successful execution will involve a sequence of
i plan executions thatfail (for some i, 0  i  j  1) followed by one plan execution that
succeeds. There are ji ways of choosing the failed plans, which can be ordered in i! ways,
and each plan has a = n8(pj ) ways to fail. There are then j i ways of choosing the final
successful plan, which has b = n4(pj ) ways to succeed.
Our goal is now to find an explicit characterisation of the incremental effect of adding an
extra plan on n8(gjj ) and n4(gjj ) by finding definitions of f 8 and f 4 as recurrence relations
in terms of the parameter j. Deriving the recurrence relation for f 8 is straightforward:
f 8 (j, a) = j! aj = (j (j  1) . . . 21) (a
. . a a}) = (j a) ((j  1) a) . . . (2 a) (1 a)
| a .{z
j times
90

fiOn the Testability of BDI Agent Systems

n4(gjj ) = f 4 (j, n8(pj ), n4(pj ))
n8(gjj ) = f 8 (j, n8(pj ))
f 4 (0, a, b) = 0
f 4 (j +1, a, b) = (j +1) (b + a f 4 (j, a, b))

(10)

8

f (0, a) = 1
8

f (j +1, a) = (j +1) a f 8 (j, a)
n4(phi ) = 1
n8(phi ) = `
n4(pj ) = n4(gj )k , for j 6= hi
 n4(gj )k  1
, for j 6= hi
n8(pj ) = ` + n8(gj ) + ` n4(gj )
n4(gj )  1
Figure 6: Recurrence relations for the numbers of failures and successes of a goal plan tree
in the presence of failure handling

This shows that f 8 (0, a) = 1 and f 8 (j +1, a) = (j +1) a f 8 (j, a)
However, the derivation of a recurrence relation for f 4 is not as simple. Here we use
the technique of first finding an exponential generating function (e.g.f.) (Wilf, 1994) for the
sequence {f 4 (j, a, b)}
j=0 , and then using that to derive a recurrence relation. The details
are given in Appendix B, and yield equation 10 in Figure 6.
Equation 10 (copied from Equation 25 in Appendix B) gives us the recurrence relation
14
for the sequence {f 4 (j, a, b)}
j=0 that we have been seeking . Figure 6 brings together the
equations we have so far for the failure-handling case (including those from the previous
section defining n4(pd ) and n8(pd ), generalised for semi-uniform trees).
This formulation gives us a different way of looking at the recurrence, and allows us to
more easily see how the behaviour space grows as the number of applicable plans, j, for a
goal grows. Considering the meaning of the parameters a and b as the numbers of failures
and successes (respectively) of a plan at a level below the current goal node, the equation
for f 4 (j +1, a, b) can be seen to have the following combinatorial interpretation. One plan
must be selected to try initially (there are j +1 choices) and it can either succeed (in one
of b different ways), meaning no further plans need to be tried, or fail (in one of a different
ways). If it fails, then the goal must then succeed using the remaining j plans, which can
occur in f 4 (j, a, b) ways.
We can see that the growth in the number of successful executions for a goal grows at
a rate greater than j!aj , because of the presence of the b term. The relaxed uniformity
14. In the simple case when a = b = 1 this is listed as sequence A007526 in the On-Line Encyclopedia of
Integer Sequences (Sloane, 2007): the number of permutations of nonempty subsets of {1,    , n}.

91

fiWinikoff & Cranefield

constraint used in these recurrence relations also gives us a way to investigate the numbers
of traces for goal-plan trees of different semi-uniform shapes. However, in the remainder of
this paper we will focus on uniform trees using our original parameter j (with the exception
of Section 4.7).
4.5 The Probability of Failing
In Section 4.3 we said that introducing failure handling makes it harder to fail. However,
Tables 1 and 2 appear at first glance to contradict this, in that there are many more ways
of failing with failure handling than there are without failure handling.
The key to understanding the apparent discrepancy is to consider the probability of
failing: Tables 1 and 2 merely count the number of possible execution paths, without
considering the likelihood of a particular path being taken. Working out the probability of
failing (as we do below) shows that although there are many more ways of failing (and also
of succeeding), the probability of failing is, indeed, much lower.
Let us denote the probability of an execution of a goal-plan tree with root x and depth
d failing as p8(xd ), and the probability of it succeeding as p4(xd ) = 1  p8(xd ).
We assume that the probability of an action failing is a 15 . Then the probability of a
given plans actions all succeeding is simply (1  a )x where x is the number of actions.
Hence the probability of a plan failing because of the failure of (one of) its actions is simply
1  (1  a )x , i.e. for a plan at depth 0 the probability of failure is:
0 = 1  (1  a )`
and for a plan at depth greater than 0 the probability of failure due to actions is:
 = 1  (1  a )` (k+1)
(recall that such a plan has ` actions before, after, and between, each of its k sub-goals).
Considering not only the actions but also the sub-goals g1 , . . . , gk of a plan p, we have
that for the plan to succeed, all of the sub-goals must succeed, and additionally, the plans
actions must succeed giving p4(pd ) = (1  ) p4(gd )k . We can easily derive from this an
equation for p8(pd ) (given below). Note that the same reasoning applies to a plan regardless
of whether there is failure handling, because failure handling is done at the goal level.
In the absence of failure handling, for a goal g with possible plans p1 , . . . , pj to succeed
we must select one plan and execute it, so the probability of success is the probability of
that plan succeeding, i.e. p4(gd ) = p4(pd1 ). We ignore for the moment the possibility of a
goal failing because there are no applicable plans. This assumption is relaxed later on.
Formally, then, we have for the case without failure handling:
p8(gd ) = p8(pd1 )
p8(p0 ) = 0
k

p8(pd ) = 1  [(1  ) (1  p8(gd )) ]
15. For simplicity, we assume that the failure of an action in a plan is independent of the failure of other
actions in the plan.

92

fiOn the Testability of BDI Agent Systems

a
0.05

0.01

d
2
3
4
2
3
4

No failure handling
30%
72%
98%
07%
22%
55%

With failure handling
0.64%
0.81%
0.86%
0.006%
0.006%
0.006%

Table 3: Goal failure probabilities with and without failure handling
Now consider what happens when failure handling is added. In this case, in order for
a goal to fail, all of the plans must fail, i.e. p8(gd ) = p8(pd1 )j . Since failure handling is at
the goal level, the equation for plans is unchanged, giving:
p8(gd ) = p8(pd1 )j
p8(p0 ) = 0
k

p8(pd ) = 1  [(1  ) (1  p8(gd )) ]
It is not easy to see from the equations what the patterns of probabilities actually are,
and so, for illustration purposes, Table 3 shows what the probability of failure is, both with
and without failure handling, for two scenarios. These values are computed using j = k = 3
(i.e. a relatively small branching factor) and with ` = 1. We consider two cases: where
a = 0.05 and hence   0.185 (which is rather high), and where a = 0.01 and hence
  0.04.
As can be seen, without failure handling, failure is magnified : the larger the goalplan tree is, the more actions are involved, and hence the greater the chance of an action
somewhere failing, leading to the failure of the top-level goal (since there is no failure
handling). On the other hand, with failure handling, the probability of failure is both low,
and doesnt appear to grow significantly as the goal-plan tree grows.
We now relax the assumption that a goal cannot fail because there are no applicable
plans, i.e. that a goal will only fail once all plans have been tried. Unfortunately, relaxing
this assumption complicates the analysis as we need to consider the possibility that none
of the remaining plans are applicable at each point where failure handling is attemped.
Let us begin by reconsidering the case where there is no failure handling. We use g to
denote the probability of a goal failing because none of the remaining plans are applicable.
For the case with no failure handling a non-zero g indicates that there are situations
where a goal does not have applicable plans, which may indicate an error on the part of
the programmer, or that in certain situations a goal may not be possible to achieve. We
assume, for analysis purposes, that this probability is constant, and in particular, that it
does not depend on which plans have already been tried nor on the number of relevant
plans remaining.
Then the probability of a goal failing is p8(gd ) = g + (1  g ) p8(pd1 ), i.e. the goal fails
either because no plans are applicable or because there are applicable plans and the selected
plan fails. As before, the equation for plans is unchanged, since failure handling is done at
93

fiWinikoff & Cranefield

the goal level. We now have the following equations for the case without failure handling:
p8(gd ) = g + (1  g ) p8(pd1 )
p8(p0 ) = 0
k

p8(pd ) = 1  [(1  ) (1  p8(gd )) ]
Observe that setting g = 0 yields the equations derived earlier, where we assumed that a
goal cannot fail due to inapplicable plans.
We now consider the probability of failure with failure handling. For a goal with two
plans we have the following cases:
 The goal can fail because no plans are applicable (g )
 If there are applicable plans ((1  g ) . . .) then the goal can fail if the first selected
plan fails (p8(pd1 ) . . .) and if failure handling is not successful, which can occur if
either there are no applicable plans (g ) or if there are applicable plans ((1  g ) . . .)
and the selected plan fails (p8(pd1 )).
Putting this together, for a goal with two plans we have:
p8(gd ) = g + (1  g ) p8(pd1 ) (g + (1  g ) p8(pd1 ))
In the general case of j available plans, we have that a goal can fail if:
A. there are no applicable plans at the outset, with probability g , or
B. there are applicable plans (1  g ), but the selected plan fails (p8(pd1 )) and then
either there are no further applicable plans (g ), or
C. there are applicable plans (1  g ), but the selected plan fails (p8(pd1 )) and then
either there are no further applicable plans (g ),
D. and so on: the reasoning of B is repeated j times.
This gives a definition of the following form:
g + (1  g ) p8(pd1 ) (g + (1  g ) p8(pd1 ) (g + . . .g ))
|{z} |
{z
}|
{z
} |{z}
B
C
D
A
This can be defined in terms of an auxiliary function p8(gd , i) which defines the probability
of failure for goal g at depth d where there are i remaining relevant plan instances that may
(or may not) yield any applicable plan instances:
p8(gd ) = p8(gd , j)
p8(gd , 1) = g + (1  g ) p8(pd1 )
p8(gd , i + 1) = g + (1  g ) p8(pd1 ) p8(gd , i)
p8(p0 ) = 0
k

p8(pd ) = 1  [(1  ) (1  p8(gd )) ]
94

fiOn the Testability of BDI Agent Systems

a
0.05

a
0.01

d
2
3
4
d
2
3
4

No failure handling
g = 0
g = 0.01 g = 0.05
30%
33%
43%
72%
76%
86%
98%
99%
100%
g = 0 g = 0.005 g = 0.01
7%
9%
10%
22%
27%
32%
55%
63%
70%

With failure handling
g = 0
g = 0.01 g = 0.05
0.64%
2.2%
9.4%
0.81%
2.6%
12.8%
0.86%
2.8%
16.5%
g = 0 g = 0.005 g = 0.01
0.006%
0.5%
1.1%
0.006%
0.6%
1.1%
0.006%
0.6%
1.1%

Table 4: Goal failure probabilities with and without failure handling when goals can have
no applicable plans

Observe that setting g = 0 reduces this to the definition derived earlier, since g +(1g ) X
simplifies to X, and hence p8(gd , i) = p8(pd1 )i .
As before, it is not immediately clear from the formulae what the actual patterns of
probability are. Considering illustrative examples, Table 4 shows that (a) the overall behaviour is the same as before, and (b) if g is assumed to be relatively low compared with the
probability of action failure ( and 0 ), then it doesnt significantly affect the probabilities.
4.6 Analysis of the Rate of Failures
In this section we briefly examine how the number of traces for a goal-plan tree is affected by
placing a bound on the rate of action failures that can occur within a trace. For simplicity,
we work with uniform goal-plan trees, but the construction below extends trivially to semiuniform goal-plan trees.
In Figure 6 we presented equations for calculating the total number of behaviours for a
goal-plan tree (with failure handling). But how many of these behaviours involve a possibly
unrealistic number of action failures? If we make an assumption that there is an upper
limit to the rate of action failures16 , i.e. the number of failures divided by the length of the
trace, how does this affect the number of possible behaviours? Do the large numbers that
we have seen reduce significantly?
For instance, considering j = k = 2, ` = 1 and d = 2, there are 1,922 possible executions
that result in failure. How many of these involve a high rate of action failure and how many
involve only a small percentage of failures? Figure 7 contains (cumulative) counts that
were generated by looking at all possible executions in this (small) case, plotted against the
number of action failures. The x axis shows for a given value N  {0, . . . , 6} how many
traces there are that have N or fewer action failures. For instance, for N = 2, there are 426
traces that have 2 or fewer action failures. Of these 426 traces, 328 are successful and 98 are
unsuccessful. Figure 8 shows the equivalent graph for the rate of action failure: each trace
has its failure rate computed (the number of failures divided by the length of the trace),
16. Bounding the rate of action failures allows us to model an assumption that the environment has limited
unpredictability, or perhaps that the programmer has limited incompetence!

95

fiWinikoff & Cranefield

ok"

failed"

both"

3500"

Number'of'traces'(cumula0ve)'

3000"

2500"

2000"

1500"

1000"

500"

0"

0"

1"

2"

3"

4"

5"

6"

ok"

8"

80"

328"

704"

960"

1024"

1024"

failed"

0"

0"

98"

546"

1282"

1794"

1922"

both"

8"

80"

426"

1250"

2242"

2818"

2946"

Number'of'failures'

Figure 7: Number of traces (cumulative) vs. number of failures for j = k = 2, ` = 1, d = 2
3500

3000

Number of traces (cumulative)

2500

2000

1500

1000

500

0
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Failure Rate

Figure 8: Number of traces (cumulative) vs. failure rate for j = k = 2, ` = 1, d = 2

96

fiOn the Testability of BDI Agent Systems

and the number of traces are counted for each range of failure rate. For instance, the first
data point in the graph shows that there are 40 traces with a failure rate  0.1.
The question is how to generalise this analysis for larger execution spaces. Clearly,
counting all possible executions is not feasible. Instead, we turn to generating functions.
For a given plan body segment17 s (and particularly for s = gd ), we are interested in
computing the numbers of successful and failed traces in which the failure rate is bounded
by a given ratio r between the number of failed actions and the total number of actions,
i.e. the proportion of actions in an execution trace that fail. We denote these by n4r(s)
and n8r(s). To compute these values, we first determine for integers m > 0 and n  0 the
numbers of successful and failed traces that have length m and contain exactly n action
failures, denoted n4r(s, m, n) and n8r(s, m, n), respectively. We define the length of a trace
to be the number of actions (both successful and unsuccessful) that it contains. Note that
for any finite goal-plan tree, such as a uniform or semi-uniform one, there is a maximum
possible trace length and so n4r(s, m, n) and n8r(s, m, n) can only be non-zero for a finite
number of integer pairs (m, n) in the positive quadrant of the plane or on the positive m
axis (in the case that n = 0). Once we have these values, we can calculate n4r(s) as the
n
 r, and similarly for n8rs using n8r(s, m, n).
sum of all n4r(s, m, n) for which m
We begin by considering ordinary 18 and bivariate generating functions (Wilf, 1994) for
the values n4r(s, m, n) and n8r(s, m, n):
4

Fr (s, x, y) =
Fr8(s, x, y) =

 X

X

n4r(s, m, n) xm y n

m=0 n=0
 X

X

n8r(s, m, n) xm y n

m=0 n=0

An action a has one successful execution, which has length 1 and contains no action
failures, so Fr4(a, x, y) = x (a power series with the coefficient of x1 y 0 being 1 and all other
coefficients being 0). Similarly, Fr8(a, x, y) = x1 y 1 = xy, as there is one failed execution,
which has length 1 and one action failure.
We now consider Fr4(s1 ; s2 ):
Fr4(s1 ; s2 , x, y) =
=

 X

X

n4r(s1 ; s2 , m, n) xm y n

m=0 n=0
 X
 
X
m=0 n=0

X

X


nr(s1 , p, t) nr(s2 , q, u) xm y n
4

4

p+q=m t+u=n

The double sum in parentheses considers, for any trace, all possible ways of allocating
the number of actions m and number of action failures n to the (necessarily) successful
executions of s1 and s2 , and the sums are over non-negative integer values of p, q, t and u.
17. Recall that, as defined towards the start of Section 4 (page 83), a plan body segment s is a sequence
x1 ; . . . ; xn where each xi is either a goal or an action.
18. Ordinary generating functions differ from exponential generating functions by not including denominators
that are factorials of the powers of the variable(s).

97

fiWinikoff & Cranefield

We then have:
Fr4(s1 ; s2 , x, y) =
=


 X
X
X X

n4r(s1 , p, t) xp y t n4r(s2 , q, u) xq y u

m=0 p+q=m n=0 t+u=n
 X
 X
 X

X

n4r(s1 , p, t) xp y t n4r(s2 , q, u) xq y u

p=0 q=0 t=0 u=0

X
X

 X

 X

4
p t
4
q u
=
nr(s1 , p, t) x y
nr(s2 , q, u) x y
p=0 t=0

q=0 u=0

4

4

= Fr (s1 , x, y) Fr (s2 , x, y)
P
P P
P
The second line above is derived using the identity 
q
p
m=0
p+q=m f (p, q) =
f (p, q). Both expressions sum over all non-negative integers p and q, but the first expression
does this by first summing over all non-negative values m on the horizontal axis, and then
summing over all pairs (p, q) of non-negative integers lying on a line with slope 1 that
intersects the horizontal axis at m.
Considering Fr8(s1 ; s2 , x, y), we have:
Fr8(s1 ; s2 , x, y) =
=

 X

X

n8r(s1 ; s2 , m, n) xm y n

m=0 n=0
 X
 
X

n8r(s1 , m, n)

m=0 n=0

+

=

X

X



nr(s1 , p, t) nr(s2 , q, u) xm y n
4

8

p+q=m t+u=n


XX

n8r(s1 , m, n) xm y n

m=0 n=0
 X
 
X

+

m=0 n=0

X

X


nr(s1 , p, t) nr(s2 , q, u) xm y n
4

8

p+q=m t+u=n

8

= Fr (s1 , x, y)
X
 X

 X

 X

+
n4r(s1 , p, t) xp y t
n8r(s2 , q, u) xq y u
p=0 t=0

q=0 u=0

= Fr8(s1 , x, y) + Fr4(s1 , x, y) Fr8(s2 , x, y)
The second line above is based on the observation that each failed execution of s1 ; s2 of
length m and with n action failures is either a failed execution of s1 of length m and with n
action failures occurring in that execution, or is a successful execution of s1 of length p and
with t failures followed by a failed execution of s2 of length q and with u failures, where
p + q = m and t + u = n.
Now, assuming that we know Fr4(gd , x, y) and Fr8(gd , x, y) for some depth d, we can
construct the functions Fr4(pd , x, y) and Fr8(pd , x, y) by applying the results above to expand
the right hand sides of the following equations (which simply replace pd with its plan body):
98

fiOn the Testability of BDI Agent Systems

Fr4(pd , x, y) = Fr4(a` ; (gd ; a` )k , x, y)
Fr8(pd , x, y) = Fr8(a` ; (gd ; a` )k , x, y)

It remains to define Fr4(gd , x, y) and Fr8(gd , x, y) in terms of Fr4(pd1 , x, y) and Fr8(pd1 ,
x, y). To count the successful executions of gd of length m and with n action failures, we
must first choose one of the j applicable plans to be the one that ultimately succeeds. We
must then choose between 0 and j1 of the remaining applicable plans that were tried but
failed, and consider all possible orderings of these plans. The m actions in the trace and
the n action failures must be distributed across the failed and successful plans. This leads
us to the following derivation of a procedure to construct Fr4(gd , x, y):
Fr4(gd , x, y)
 X

X
=
n4r(gd , m, n) xm y n
m=0 n=0

=

 X

X


j

m=0 n=0

= j

p=0


j1 
X
j 1
p

p=0

= j


j1 
X
j 1

p!

p

X

p!

X

n4r(pd1 , `0 , f0 )

p
Y


X

X


m=0 n=0

n8r(pd1 , `i , fi ) xm y n

i=1

`0 ++`p =m f0 ++fp =n

 X

X



n4r(pd1 , `0 , f0 )

p
Y


n8r(pd1 , `i , fi ) xm y n

i=1

`0 ++`p =m f0 ++fp =n

j1 
X
p=0

 X
 X
p
 X

 X

j 1
4
` f
8
` f
p!
nr(pd1 , `, f ) x y
nr(pd1 , `, f ) x y
p
`=0 f =0

`=0 f =0


j1 
X
j 1
= j
p! Fr4(pd1 , x, y) Fr8(pd1 , x, y)p
p
p=0

Constructing Fr8(gd , x, y) is simpler. A failed execution of a goal involves failed attempts
to execute all j applicable plans. All j! orderings of these plans must be considered. This
gives us the following construction for Fr8(gd , x, y):
Fr8(gd , x, y) =
=

 X

X

n8r(gd , m, n) xm y n

m=0 n=0
 X
 
X

X

j!

m=0 n=0

= j!

X
 X


X

`1 ++`j =m f1 ++fj =n
8

` f

nr(pd1 , `, f ) x y

`=0 f =0

= j! Fr8(pd1 , x, y)j
99

j



nr(pd1 , `1 , f1 )    nr(pd1 , `j , fj ) xm y n
8

8

fiWinikoff & Cranefield

The equations above define a recursive procedure for computing Fr4(gd , x, y) and Fr8(gd ,
x, y) for given values of d, j, k and `. As discussed earlier in this section, given a way of
n
calculating n4r(s, m, n), we can calculate n4r(s) as a sum of all n4r(s, m, n) for which m
 r,
8
and similarly for nrs. We have used the Python rmpoly and GMPY2 libraries to generate
polynomial representations of the functions Fr4(gd , x, y) and Fr8(gd , x, y) for any specified
values of d, j, k and l, and to calculate n4r(s) and n8r(s) for various ratios r19 . Figure 9
shows the results for d = j = k = 3 and ` = 1.
Examining Figure 9 we can conclude two things. On the one hand, the number of traces
really explodes for larger rates of action failures. For example, in Figure 9 most traces have
a failure rate greater than 0.4. On the other hand, although making assumptions about the
failure rate does reduce the number of possible traces, the number of traces is still quite
large (note the scale on the y-axis). For instance, for a failure rate of  0.1 there are around
4.8  1044 failed executions and 8.7  1047 successful executions. For a failure rate of  0.2
the respective numbers are 1.0  1077 and 6.7  1077 , and for a failure rate of  0.3 they
are 1.2  1096 and 2.7  1096 .
The shape of Figure 9 can be explained as follows. Firstly, the occurrence of an action
failure triggers further activity (alternative plans), so more failures result in longer traces.
Secondly, there are more longer traces than there are shorter traces, simply because the
longer the trace, the more possibilities there are for variations (e.g. different orders of trying
plans). This explains why the increase in Figure 9 starts off slowly and then accelerates:
as we get more failures, we have longer traces, and for these longer traces there are more
of them. In other word, if we were to plot the non-cumulative number of paths against the
ratio of action failures we would see an initial increase: as the ratio grows, there are more
paths. What this doesnt explain is why beyond a certain point we get fewer traces, and
the cumulative graph levels out. The explanation here is quite simple: beyond a certain
ratio (which appears to be around 0.4) there are no successful traces, and the number of
failed traces also declines.
4.7 Recursive Trees
In Section 4.4 we developed recurrence relations that allowed us to relax the assumption
that goal-plan trees are uniform, and considered semi-uniform trees. In this section we
relax the assumption that goal-plan trees are finite, and we also allow trees to have any
shape. We do this by considering arbitrary trees that are allowed to contain labels that
refer to other parts of the tree, i.e. we allow trees to be recursive. We then derive generating
functions, which can be seen as an extension of those derived in the previous section, for
the number of paths (both successful and unsuccessful) in executing these recursive goalplan trees. Obviously, an infinite tree has an infinite number of paths, and so we define
generating functions that take as a parameter a bound on the lengths of the paths counted.

19. There are a finite number of actions that can be attempted during any execution of a goal-plan tree, and
this bounds the length of its possible traces and the number of action failures that can occur within them.
Thus Fr4(gd , x, y) and Fr8(gd , x, y) are polynomials of finite orderonly a finite number of coefficients are
non-zero in the infinite sums that define them.

100

fiOn the Testability of BDI Agent Systems

Failed executions (cumulative)

Successful executions (cumulative)

Both (cumulative)

4E+107

3.5E+107

Number of traces (cumulative)

3E+107

2.5E+107

2E+107

1.5E+107

1E+107

5E+106

0.005
0.025
0.045
0.065
0.085
0.105
0.125
0.145
0.165
0.185
0.205
0.225
0.245
0.265
0.285
0.305
0.325
0.345
0.365
0.385
0.405
0.425
0.445
0.465
0.485
0.505
0.525
0.545
0.565
0.585
0.605
0.625
0.645
0.665
0.685
0.705
0.725
0.745
0.765
0.785
0.805
0.825
0.845
0.865
0.885
0.905
0.925
0.945
0.965
0.985

0

Failure rate

Figure 9: Number of traces (cumulative) vs. failure rate for j = k = d = 3 and ` = 1
For a given upper bound on path length  the equations specify the number of paths that
have at most that many actions20 .
We begin by defining some notation for representing recursive trees: goals, plan-body
multisets, plans, variables and bindings. A goal is represented by a term of the form
goal(plan-body-multiset) where plan-body-multiset is a multiset representing the different
applicable plan instances that can be used to satisfy the goal. This is a multiset because
for our combinatorial analysis, only the structure of plans is significant. Therefore we
use a single abstract action a to represent all actions21 , and a goal may be achievable
using multiple plan instances that have the same structure, but which we must treat as
distinct. We only need to represent the bodies of the plan instances, so each element in
the multiset (i.e. plan) is a sequence of terms separated by the right-associative sequential
composition operator ;. Each term in the sequence is either the abstract action term a,
a goal term as defined above (representing a sub-goal), or a label (see below). Formally,
a plan-body multiset P M is a multiset of plans, written {p1 :c1 , . . . , pj :cj } where each of
the ci is the number of times that the associated plan pi appears in the multiset. We
define the following multiset operations: set(P M ) is a set of all the pi in the multiset P M ,
P M (pi ) is the characteristic function denoting the number of times plan pi appears in
the multiset (i.e. ci ); and P M1  P M2 is multiset subtraction, defined as P M1 P M2 (x) =
max(P M1 (x)  P M2 (x), 0). Finally |P M | is the size of the multiset, i.e. the sum of the ci .

20. We can also use the equations derived in this section for non-recursive trees, in which case we allow
 = , where we define   1 =  and F power(x) = F .
21. However, to avoid confusion, we will use numeric subscripts (a1 , a2 , . . .) to distinguish different occurrences of actions.

101

fiWinikoff & Cranefield

In order to allow recursive trees to be represented, it is possible for a step in a plan to
be a label (denoted , i or  0 ) referring to a term in the provided binding, which is simply
a mapping from labels to terms (either goal or plan terms). If b is a binding then we write
b[] to denote the item that  is mapped to in b, or  if there is no entry for  in b.
For example, consider the simple tree below, consisting of a goal with two plans, together
with a binding that maps the variable  to the root of the tree. The first plan (on the left)
has two steps: an action (a1 ), and a recursive reference to the root of the tree (). The
second plan (on the right) just has a single action (a2 ).
 : goal
plan

plan
a1



a2

This recursive tree can be represented as follows. We define the binding b = { 7
goal({(a1 ; ):1, a2 :1})} which maps  to the whole tree, and then the tree itself is just .
Before we proceed to defining generating functions, we introduce some auxiliary notation. If P is a power series then we use the standard notation [xp11    xpnn ]P to denote
the coefficient of the term xp11    xpnn in the series. We define P cond to denote the power
xn

series containing all the terms in P that satisfy the condition cond. We define f  g as
(f  g) power(x)n , i.e. f  g with any terms having a power of x greater than n removed.
n
We define f mx as (f )m power(x)n , i.e. (f )m with any terms having a power of x greater
than n removed.22
We are now in a position to derive generating functions that specify the number of
paths through an arbitrary, and possible recursive, goal-plan tree, given a bound  on the
path length. We define s to be the BDI program represented as a term (i.e. goal, plan,
plan multiset, action, or label), and b to be a binding mapping labels to terms (as defined
above). We then define n4(s, m, n, b) to be the number of successful paths, with respect
to s and binding b, that have m actions, n of which are failed actions. Similarly we define
n8(s, m, n, b) to be the number of failed paths, with respect to s and b, that have m actions,
n of which are failed actions. We now want to derive recurrence relations for the generating
functions23 :
4
F
(s, x, y, b, ) =

8
F
(s, x, y, b, ) =

 X

X
m=0 n=0
 X

X

n4(s, m, n, b)xm y n
n8(s, m, n, b)xm y n

m=0 n=0

where  is an upper bound on the number of actions in a path.
22. This, and the previous operation, are directly supported by the rmpoly Python library for multivariate
polynomials and series, which we have used to compute these generating functions.
23. The subscript  is used to distinguish these generating functions, that allow for a recursive tree, from
other generating functions defined elsewhere in the paper.

102

fiOn the Testability of BDI Agent Systems

In order to simplify the presentation, the details of the more complex derivations are
given in Appendix C. The resulting equations are shown in Figure 10. The first two
equations (Equations 11 and 12 in Figure 10), which are applicable for any term t, capture
the assumption that  > 0 (and the remaining equations only apply when  > 0). The next
two equations simply specify that labels are looked up in the provided binding. Equation 15
indicates that there is a single successful path through action a, and that it has a single
action and no unsuccessful actions (i.e. the generating function is 1x1 y 0 ). Equation 16
similarly indicates that there is a single unsuccessful path through a single action a, which,
unsurprisingly, has a single unsuccessful action (so the generating function is 1x1 y 1 ).
Equations 17 and 18 deal with sequences: for a sequence s1 ; s2 to succeed both s1 and
s2 must succeed, and we count the paths by concatenating sub-paths, which corresponds to
multiplying power series. A sequence s1 ; s2 can fail if either s1 fails, or if s1 succeeds and
s2 then fails (alternatives correspond to the addition of power series). For both equations
there is a special case: if s1 is an action, then we can divide the overall path-length limit
 precisely: s1 must have a trace of length 1 (since it is an action) and s2 must therefore
have a maximum length of   1.
Having dealt with labels (), single actions, and sequences, we next turn to goals (equations 19 and 20). In both cases the derivation is complex, and is covered in Appendix C.
4
For F
(Equation 19 and Appendix C.1), the intuition is that a successful path through a
goals execution involves a single successful plan p, and some number of failed executions of
plan selected from the remaining multiset of plans (P M  {p:1}). In the case where a plan
appears more than once in the multiset, then we can select any of its occurrences, hence
the multiplication by P M (p). For the number of failed paths of a goal (Equation 20 and
Appendix C.2) we introduce an auxiliary generating function G8(P M, x, y, z, b, ), where
P M is a multiset of plans, and z is a variable whose power z o indicates the exact number of plans from P M that are used. In other words, given the power series denoted by
G8(P M, x, y, z, b, ), the term cmno xm y n z o /o! indicates that there are cmno paths that involve m actions, n of which failed, and exactly o of the plans in P M . The generating
8
function G8 is a technical device that allows us to derive the definition of F
that we need.
8
Given this power series, the definition of F simply selects the terms that have |P M | as
the power of z (since all plans must fail for a goal to fail) using  and then removes the
z |P M | terms by dividing. Because G8 is an exponential generating function in z, which
means that it includes a division by a factorial, we need to multiply by the factorial |P M |!
to remove it.
8
Equation 21 defines F
(P M, x, y, b, ), which is used in Equation 19, in terms of the
8
auxiliary function G. Its derivation is given in Appendix C.3. The intuition here is that
for each possible number of plans that could be used (o) we limit the power series G8 to
that value of o, and remove the z o by dividing. The o! is due to G8 being an exponential
generating function in z (see Appendix C).

Finally, Equations 22 and 23 give the definition of G8(P M, x, y, z, b, ) (see Appendix C.4
for the derivation). Intuitively, Equation 22 creates the power series for each plan type, and
x

then combines them (using  ). Equation 23 is a little more complex: there is a single way
of failing (when no plans are used, corresponding to the term x0 y 0 z 0 = 1). Otherwise we
can select any o of the c plans, and each of the plans must fail (corresponding to the term
103

fiWinikoff & Cranefield

4
F
(t, x, y, b, ) = 0 if   0

(11)

8

F(t, x, y, b, ) = 0 if   0

(12)

4

4

(13)

8

8

(14)

F(, x, y, b, ) = F(b[], x, y, b, )
F(, x, y, b, ) = F(b[], x, y, b, )
4

(15)

8

(16)

F(a, x, y, b, ) = x
F(a, x, y, b, ) = xy
4

F(s1 ; s2 , x, y, b, )
(
4
4
F
(s1 , x, y, b, 1) F
(s2 , x, y, b,   1) if s1 is an action
=
x
4
4
F(s1 , x, y, b, )  F
(s2 , x, y, b, ) otherwise
8
F
(s1 ; s2 , x, y, b, )
(
4
8
8
(s1 , x, y, b, 1)+F
(s1 , x, y, b, 1) F
(s2 , x, y, b,   1) if s1 is an action
F
=
x
8
4
8
F
(s1 , x, y, b, )+F
(s1 , x, y, b, )  F
(s2 , x, y, b, ) otherwise
4
F
(goal(P M ), x, y, b, )
X
x
4
8
=
P M (p)F
(p, x, y, b, )  F
(P M {p:1}, x, y, b, )

(17)

(18)

(19)

pset(P M )
8
F
(goal(P M ), x, y, b, ) = |P M |!

|P M |
8
F
(P M, x, y, b, ) =

X
o=0

o!

G8(P M, x, y, z, b, ) power(z)=|P M |
z |P M |
G8(P M, x, y, z, b, ) power(z)=o
zo

(20)
(21)

G8({p1 :c1 , . . . , pj :cj }, x, y, z, b, )
x

x

G8({p1 :c1 }, x, y, z, b, )      G8({pj :cj }, x, y, z, b, )

=

c  
X
c
G({p:c}, x, y, z, b, ) = 1 +
F 8 (p, x, y, b, )ox z o
o 
8

(22)

(23)

o=1

Figure 10: Equations for Recursive Goal-Plan Trees
8
F
(p, x, y, b, )), giving the number of failed traces across these o plans as:
x

x

8
8
8
F
(p, x, y, b, )ox = F
(p, x, y, b, )      F
(p, x, y, b, )
|
{z
}

o times

We have used the Python rmpoly and GMPY2 libraries to generate polynomial repre4
8
sentations of the functions F
(t, x, y, b, ) and F
(t, x, y, b, ) (as defined in Figure 10) for
any specified values of t, b, and . Then we defined a simple tree (the one given earlier in
this section as an example) and computed the number of paths for different values of .
104

fiOn the Testability of BDI Agent Systems

The values of  have been chosen to correspond to values in Table 2 (which is where the
values for n4(g) and n8(g) come from24 ). In Table 2, the values of 62 and 363 correspond to
the longest path, and so we argue that when comparing a recursive tree to a uniform tree,
we should consider the same path length limit. The results are shown in Table 5.

62
363

n4(g)
 6.33  1012
 1.02  10107

n8(g)
 1.82  1013
 2.56  10107

n4(s)
 3.8  1013
 1.9  1076

n8(s)
 4.3  109
 6.1  1054

Table 5: Comparing n4 and n4 (respectively n8 and n8).
Looking at the numbers in Table 5, it is worth noting that the recursive tree that we
have used is extremely simple: two plans, each with only a single action. The low number
of actions (and sparseness of the tree) account for the relatively low number of unsuccessful
paths. For instance, if we modify the tree by adding extra actions (giving the tree and
binding below) then for  = 62 there are around 3.9  1013 successful paths, and 1.5  1011
unsuccessful paths. Unfortunately, Python was unable to calculate n4 or n8 for this tree
with  = 363, but it did manage  = 362, for which there are 1.26  1064 successful paths,
and 3.281063 unsuccessful paths. This shows, as expected, that the number of unsuccessful
paths is higher for the more complex tree. That there are fewer successful paths for the
more complex tree can be explained by observing that, for this tree, traces are longer (more
actions need to be done), and so more of the traces are excluded by the bound on trace
length .
 : goal
plan

plan
a1

a3



a2

a4

Overall, the analysis in this section, and its application to  = 62 and 363 confirms
that the number of paths in a recursive tree depends on the trees structure (which is
unsurprising), but also indicates that even for a very simple recursive tree, the number of
paths for a given upper bound on path length quickly becomes extremely large.

5. A Reality Check
In the previous section we analysed an abstract model of BDI execution in order to determine
the size of the behaviour space. The analysis yielded information about the size of the
behaviour space and how it is affected by various factors, and on the probability of a goal
failing.
In this section we consider the two issues of whether this analysis is faithful, and whether
it is applicable to real systems. The analysis made a number of simplifying assumptions,
24. They correspond to the first two rows of the table, which respectively involve 62 and 363 actions.

105

fiWinikoff & Cranefield

and these mean that the results may not be faithful to the semantics of a real BDI platform,
or that they may not apply to real systems. We thus conduct two reality checks to assess
whether our analysis is faithful (Section 5.1) and whether it is applicable (Section 5.2).
We firstly assess whether our analysis is faithful to real BDI platforms, i.e. that it does
not omit significant features, or contain errors. We do this by comparing our abstract
BDI execution model with results from a real BDI platform, namely JACK (Busetta et al.,
1999). This comparison allows us to assess to what extent the analysis of our abstract BDI
execution model matches the execution that takes place in a real (industrial strength) BDI
platform. This comparison is, in essence, a basic reality check: we are simply checking that
the analysis in the previous section does indeed match the execution semantics of a typical
BDI platform. We do this by modelling an artificial goal-plan tree in the BDI platform.
Next, in order to assess to what extent our analysis results apply to real systems, we
analyse a goal-plan tree from a real industrial application. This analysis allows us to
determine the extent to which the conclusions of our analysis of uniform (and semi-uniform)
goal-plan trees applies to real applications, where the goal-plan trees are not likely to be
uniform. In other words, to what extent do the large numbers in Tables 1 and 2 apply to
real applications?
5.1 A Real Platform
In order to compare a real BDI platforms execution with the results of our abstract BDI
execution model we implemented the two goal-plan trees in Appendix A in the JACK agent
programming language25 . The structure of the plans and events26 precisely mirrors the
structure of the tree. As in the goal-plan tree, each event has two relevant plans, both
of which are always applicable, and selectable in either order. Actions were implemented
using code that printed out the action name, and then, depending on a condition (described
below), either continued execution or triggered failure (and printed out a failure indicator):
System.out.print("a"); // Action "a"
if ((N.i & 1)==0) {
System.out.print("x");
false; // trigger failure
}
The conditions that determined whether an action failed or succeeded, and which plan
was selected first, were controlled by an input (N.i, a Java class variable). A test harness
systematically generated all inputs, thus forcing all decision options to be explored.
The results matched those computed by the Prolog code of Figure 3, giving precisely
the same six traces for the smaller tree, and the same 162 traces for the larger tree. This
indicates that our abstract BDI execution model is indeed an accurate description of what
takes place in a real BDI platform (specifically JACK).
Note that we selected JACK for two reasons. One is that it is a modern, well known,
industry-strength BDI platform. The other, more important, reason, is that JACK is a descendent of a line of BDI platforms going back to PRS, and thus is a good representative for
25. The code is available upon request from the authors.
26. JACK models a goal as a BDIGoalEvent.

106

fiOn the Testability of BDI Agent Systems

Parameters
Number of
j k
d
goals
actions
2 2
3
21
62 (13)
3 3
3
91 363 (25)
Workflow with 57 goals(*)
(*) The paper says 60 goals,
but Figure 11 has 57 goals.

No failure handling
(secs 4.1 and 4.2)
n4(g)
n8(g)
128
614
1,594,323 6,337,425
294,912 3,250,604
294,912 1,625,302
294,912
812,651

With failure handling
(Section 4.3)
n4(g)
n8(g)
 6.33  1012
 1.82  1013
107
 1.02  10
 2.56  10107
 2.98  1020
 9.69  1020
15
 6.28  10
 8.96  1015
 9.66  1011
 6.27  1011

Table 6: Illustrative values for n4(g) and n8(g) (bottom part is ` = 4 in first row, ` = 2 in
second, and ` = 1 in last row)

a larger family of BDI platforms. In other words, by showing that the BDI execution model
analysed matches JACKs model, we are also able to argue that it matches the execution of
JACKs predecessors (including PRS and dMARS), and close relatives (e.g. UM-PRS and
JAM).
5.2 A Real Application
We now consider to what extent real systems have deep and branching goal-plan trees,
and to what extent the large numbers shown in Tables 1 and 2 apply to real applications,
rather than to uniform goal-plan trees. As an example of a real application we consider an
industrial application at Daimler which used BDI agents to realise agile business processes
(Burmeister, Arnold, Copaciu, & Rimassa, 2008). Note that finding a suitable application
is somewhat challenging: we need an application that is real (not a toy system). However,
in order to be able to analyse it, the application has to be BDI-based, and furthermore,
details about the applications goal-plan tree need to be available. Unfortunately, many of
the reported BDI-based industrial applications do not provide sufficient details about their
internals to allow analysis to be carried out.
Figure 11 shows27 a goal-plan tree from the work of Burmeister et al. (2008) which
has 60 achieve goals in up to 7 levels. 10 maintain goals, 85 plans and about 100 context
variables (Burmeister et al., 2008, p. 41). Unlike the typical goal-plan trees used in BDI
platforms, the tree in Figure 11 consists of layers of and-refined goals, with the only or
refinements being at the leaves (where the plans are). In terms of the analysis presented
in this paper we can treat a link from a goal g to a set of goals, say, g1 , g2 , g3 as being
equivalent to the goal g having a single plan p which performs g1 , g2 , g3 (and has no actions,
i.e. ` = 0 for non-leaf plans).
The last row of Table 6 gives the various n values for this goal-plan tree, for ` = 4 (top
row), ` = 2 (middle row) and ` = 1 (bottom row). Note that these figures are actually
lower bounds because we assumed that plans at depth 0 are simple linear combinations
of ` actions, whereas it is clear from Burmeister et al. (2008) that their plans are in fact
27. The details are not meant to be legible: the structure is what matters.

107

fiWinikoff & Cranefield

model
LS/AB
differe
model
keep th

figuretree6:from
goal
of ACM
prototype
Figure 11: Goal-plan
thehierarchy
work of Burmeister
et al. (2008,
Figure 6) (reproduced
with permission from IFAAMAS)

An advantage of this modeling approach is that it implicitly offers
support for parallel execution of the process parts that do not
depend on each other. This can reduce the overall time needed for
more complicated, and can contain nested decision making (e.g., see Burmeister et al., 2008,
process
execution. Moreover maintain goals are a good means to
Figure 4).
provide
process
with
the
agent
monitors
A roughthe
indication
of the size
of aadditional
goal-plan tree isagility:
the number
of goals.
With
57 goals,
the tree of Figure
has sizeto
in be
between
the firstthroughout
two rows of Table
Comparing(e.g.
the
conditions
that11 have
fulfilled
the6. process
number of possible behaviours of the uniform goal-plan trees against the real (and nontime
constraints)
and
pro-actively
activities
avoid
uniform)
goal-plan tree, we
see that
the behaviour initiates
space is somewhat
smaller to
in the
real
tree, but thatbefore
it is stillthey
quite appear.
large, especially in the case with failure handling. However,
problems
we do note the following points:

During development of the prototype the support for rapid
1. The tree of Figure 11 only has plans at the leaves, which reduces its complexity. In
prototyping
and execution of process models provided by
other words a goal-plan tree that was more typical in having plans alternating with
goals would
have
a larger number
possible
behaviours.
LS/ABPM
has
proven
to be ofvery
helpful.
The developed models
represent
living process models, which can be directly executed
2. The figures for the tree are a conservative estimate, since we assume that leaf plans
and visualized.
The
part ofIn the
interface
thatcalculated
is coupled
have only simple
behaviour.
otherweb
words,user
the number
of paths
is an
of theis
actual
number of directly
paths in thefrom
real application.
with under-estimate
the workflow
generated
the process model.
The
interface is computed directly from the parameters of the
6. Comparison with Procedural Programs
corresponding task: context variables, their types and possible
In order to argue that BDI programs are harder to test than non-agent programs, we need
values.
With
this approach
in the ofprocess
can be programs,
quickly
a comparison.
Specifically,
we need to changes
analyze the number
paths in non-agent
and compareand
with tested.
those in agent
programs.
us to address
concern that
modeled
Thus
errorsThis
in will
theallow
models
can bethediscovered
the all paths criterion for test suite adequacy always requires an infeasibly large number
and
corrected
in briefly
a short
of tests.
This section
doestime.
this, by analyzing the number of paths in a procedural
program.
As
stated above the starting point for building the ACM-prototype
model was the ACM-reference 108
process model developed for the
software demonstrator. The underlying agent engine of this
demonstrator (JadeX) has a partially different modeling and
execution semantics compared to the LS/ABPM tool. There were

The m
model
prototy
them
compl
depend
challen
and to
execut
depend
proces

Based
be con
of the
contex
manip
model
plans,
of the
compl
possib
variab
variab
one or
proces
variab
startin
goals.
create
but h
model

fiOn the Testability of BDI Agent Systems

Number of actions / statements
62
363
776
627

n(m)
6,973,568,802
 5.39  1057
 2.5  10123
 5.23  1099

n4(g)
 6.33  1012
 1.02  10107
 1.82  10157
 3.13  10184

n8(g)
 1.82  1013
 2.56  10107
 7.23  10157
 7.82  10184

Table 7: Comparison of values between n(m), n4(g) and n8(g).
We define a program as being composed of primitive statements s, sequences of statements P1 ; P2 , or conditionals that select between two sub-programs. Since we do not capture
the conditions of statements, we elide the condition, and write a conditional as P1 + P2 indicating that one of the Pi is selected. Note that, as for BDI analysis, we exclude loops.
We define the number of paths in a program P as n(P ). It is straightforward28 to see
that the definition of n(P ) is:
n(s) = 1
n(P1 ; P2 ) = n(P1 )  n(P2 )
n(P1 + P2 ) = n(P1 ) + n(P2 )
In order to compare with BDI programs, we consider the size of the program, and
compare programs of the same size. The key question then is: does a procedural program
with m nodes have significantly fewer paths than a BDI program of the same size? We define
the size of a program P as the number of primitive statements it contains, and denote it
|P |. Note that this means that we do not count the internal nodes of the syntax tree
(i.e. the + or ;). Therefore, when comparing with BDI programs, we consider the size
of a BDI program to be the number of actions29 .
We now work out how the number of paths varies with the size of the program P . If m is
the size of a program (and therefore a natural number), then we define n(m)  max{n(P ) :
|P | = m}. That is, n(m) is the largest number of paths possible for a program of size m.
Appendix D contains the derivation of n(m), resulting in the following definition (where
m  6 is a multiple of 3):
n(1)
n(3)
n(5)
n(m + 1)

=
=
=
=

1
3
6
4
3

 3m/3

n(2)
n(4)
n(m)
n(m + 2)

=
=
=
=

2
4
3m/3
2  3m/3

Table 7 shows some comparison values between n(m) and n4(g) and n8(g), for same-sized
programs, based on Table 2. It is worth emphasising that n(m) is the highest possible value:
it is defined as the maximum over all possible programs. However, the maximal program
is highly atypical. For example, considering all programs with seven statements, there are
28. A path of P1 ; P2 simply concatenates a path of P1 with a path of P2 , hence the product; and a path of
P1 + P2 is either a path of P1 or a path of P2 , hence the addition.
29. Using the total number of nodes in the tree yields almost identical results.

109

fiWinikoff & Cranefield

a total of 8,448 possible programs. Of these 8448 programs, only 32 have 12 paths (the
maximum). Figure 12 shows for each number of paths (112) how many programs have that
many paths. The maximum of 12 is clearly not typical: indeed, the mean number of paths
for a seven statement program is 4.379, and the median is 4. If we consider all programs
with 9 statements, then there are 366,080 such programs, but only 16 have the maximal
number of paths (which is 27). The average number of paths across all the programs is
5.95.
Overall, looking at Table 7, we conclude that the number of paths for BDI programs is
much larger than even the (atypical) maximal number of paths for a procedural program
of the same size. This supports the conclusion that BDI programs are harder to test than
procedural programs.
2500"

Number'of'programs'

2000"

1500"

1000"

500"

0"
1"

2"

3"

4"
5"
6"
7"
8"
9"
Number'of'paths'in'a'procedural'program'

10"

11"

12"

Figure 12: Profile of number of paths for all 7-statement programs

7. Conclusion
To summarise, our analysis has found that the space of possible behaviours for BDI agents is,
indeed, large, both in an absolute sense, and in a relative sense (compared with procedural
programs of the same size).
As expected, the number of possible behaviours grows as the trees depth (d) and breadth
(j and k) grow. However, somewhat surprisingly, the introduction of failure handling makes
a very significant difference to the number of behaviours. For instance, for a uniform goalplan tree with depth 3 and j = k = 2, adding failure handling took the number of successful
behaviours from 128 to 6,332,669,231,104.
Before we consider the negative consequences of our analysis, it is worth highlighting
one positive consequence: our analysis provides quantitative support for the long-held belief
110

fiOn the Testability of BDI Agent Systems

that BDI agents allow for the definition of highly flexible and robust agents. Flexibility is
defined as the number of possible behaviours of an agent, which we have shown to be large.
Robustness is defined as the ability of an agent to recover from failure. The analysis in
Section 4.6 showed that the BDI failure recovery mechanism is effective at achieving a low
rate of actual failure (< 1%), even when each action has a reasonable chance of failing (5%).
So what does the analysis in this paper tell us about the testability of BDI agent systems?
Before we can answer this question, we need to consider what is being tested. Testing is
typically carried out at the levels of individual components (unit testing), collections of
components (integration testing), and the system as a whole.
Consider testing of a whole system. The behaviour space sizes depicted in Tables 1, 2
and 6 suggest quite strongly that attempting to obtain assurance of a systems correctness
by testing the system as a whole is not feasible. The reason for this is that (as discussed in
Section 1.1), an adequate test suite (using the all paths criterion for adequacy) requires
at least as many tests as there are paths in the program being tested. If a program has, say,
 1013 paths, then even a test suite with tens of thousands of tests is not just inadequate,
but is hugely inadequate, since it only covers a tiny fraction of a percent of the number of
paths.
In fact, this situation is even worse when we consider not only the number of possible
executions but also the probability of failing: the space of unsuccessful executions is particularly hard to test, since there are many unsuccessful executions (more than successful ones),
and the probability of an unsuccessful execution is low, making this part of the behaviour
space hard to reach. Furthermore, as shown in Section 4.6, although making assumptions
about the possible numbers of action failures that can occur in a given execution reduces
the number of possible behaviours, there are still many many behaviours, even for relatively
small trees (e.g. j = k = d = 3).
So system testing of BDI agents seems to be impractical. What about unit testing
and integration testing? Unfortunately, it is not always clear how to apply them usefully
to agent systems where the interesting behaviour is complex and possibly emergent. For
example, given an ant colony optimisation system (Dorigo & Stutzle, 2004), testing a single
ant doesnt provide much useful information about the correct functioning of the whole
system. Similarly, for BDI agents, when testing a sub-goal it can be difficult to ensure that
testing covers all the situations in which the goal may be attempted. Consequently, it is
difficult to draw conclusions about the correctness of a goal from the results of testing its
sub-goals.
We do need to acknowledge that our analysis is somewhat pessimistic: real BDI systems
do not necessarily have deep or heavily branching goal-plan trees. Indeed, the tree from
a real application described in Section 5 has a smaller behaviour space than the abstract
goal-plan trees analysed in Section 4. However, even though smaller, it is still quite large,
and this did cause problems in validation:

One of the big challenges during the test phase was to keep the model consistent
and to define the right context conditions that result in the correct execution
for all scenarios. Therefore more support for dependency analysis, automated
111

fiWinikoff & Cranefield

simulation and testing of the process models is needed (Burmeister et al., 2008,
p. 42)30 .
So where does that leave us with respect to testing agent systems? The conclusion
seems to be that testing a whole BDI system is not feasible. There are a number of possible
approaches for dealing with this issue of testability that could be recommended:
 Keep BDI goal-plan trees shallow and sparse. This keeps the number of behaviours small. The issue with this approach is that we lose the benefits of the BDI
approach: a reasonably large number of behaviours is desirable in that it provides
flexibility and robustness.
 Avoid failure handling. Since failure handling is a large contributor to the behaviour space, we could modify agent languages to disable failure handling. Again,
this is not a useful approach because disabling failure handling removes the benefits
of the approach, specifically the ability to recover from failures.
 Make testing more sophisticated. Could testing coverage perhaps be improved
by incorporating additional information such as domain knowledge, and a detailed
model of the environment (which indicates the possible failure modes and their probabilities)? The answer is not known, but this is a potentially interesting area for
further work. However, the large number of paths does not encourage much optimism
for this approach.
Another, related, direction is to see whether patterns exist in the behaviour space.
Since the failure recovery mechanism has a certain structure, it may be that this
results in a behaviour space that is large, but, in some sense, structured. If such
structure exists, it may be useful in making agents more testable. However, at this
point in time, this is a research direction that may or may not turn out to be fruitful;
but is not a viable testing strategy.
Finally, a related direction is to try and be more intelligent about the selection of
test cases, in order to gain more coverage from a given number of test cases. One
approach for doing this, which has been recently described, is evolutionary testing
(Nguyen, Miles, Perini, Tonella, Harman, & Luck, 2009a), in which genetic evolution
is used to find good (i.e. challenging) test cases.
 Supplement testing with alternative means of assurance. Since testing is not
able to cover a large behaviour space, we should consider other forms of assurance.
A promising candidate here is some form of formal method31 . Unfortunately, formal
methods techniques are not yet applicable to industry-sized agent systems (we return
to this below, in Section 7.1).
30. Burmeister et al. made the following observation: With this approach changes in the process can be
quickly modeled and tested. Thus errors in the models can be discovered and corrected in a short time.
They were discussing the advantages of executable models, and arguing that being able to execute the
model allowed for testing, which was useful in detecting errors in the model. While being able to execute
a model is undoubtedly useful, there is no evidence given (nor is a specific claim made) that testing is
sufficient for assuring the correctness of an agent system.
31. See the volume edited by Dastani et al. (2010) for a recent overview of the current state-of-the-art,
including a chapter on the role of formal methods in the assurance of agents (Winikoff, 2010).

112

fiOn the Testability of BDI Agent Systems

 Proceed with caution. Accept that BDI agent systems are in general robust (due
to their failure-handling mechanisms), but that there is, at present, no practical way
of assuring that they will behave appropriately in all possible situations. It is worth
noting that humans are similar in this respect. Whilst we can train, examine and
certify a human for a certain role (e.g. a pilot or surgeon), there is no way of assuring
that he/she will behave appropriately in all situations. Consequently, in situations
where incorrect behaviour may have dire consequences, the surrounding system needs
to have safety precautions built in (e.g. a process that double-checks information, or
a backup system such as a co-pilot).
7.1 Future Work
There is room for extending the analysis of Section 4. Firstly, our analysis is for a single
goal within a single agent. Multiple agents that are collaborating to achieve a single highlevel goal can be viewed as having a shared goal-plan tree where certain goals and/or plans
are allocated to certain agents. Of course, in such a distributed goal plan tree there
is concurrency. Once concurrency is introduced, it would be useful to consider whether
certain interleavings of concurrent goals are in fact equivalent. Furthermore, we have only
considered achievement goals. It would be interesting to consider other types of goals (van
Riemsdijk, Dastani, & Winikoff, 2008). Secondly, our analysis has focused on BDI agents,
which are just one particular type of agent. It would be interesting to consider other sorts
of agent systems, and, more broadly, other sorts of adaptive systems.
Another extension of the analysis is to consider other criteria for test suite adequacy.
In this paper we have used the all paths criterion, arguing why it is appropriate. We
do recognize that all paths is actually quite a strong criterionit subsumes many other
criteria (Zhu et al., 1997, Figure 7). An alternative criterion that we could consider is all
edges, also known as branch coverage or decision coverage. It requires that where
there is a choice in the program, such as an if statement, then the tests in the test suite
exercise all options, i.e. that all edges in the program graph be covered. The all edges
criterion is weaker than all paths and is regarded as the generally accepted minimum
(Jorgensen, 2002).
Another area for refinement of the analysis is to make it less abstract. Two specific areas
where it could be made more detailed are resources and the environment. Our analysis does
not consider resources or the environment directly, instead, it considers that actions may
fail for a range of reasons which might include resource issues, or environmental issues. The
analysis could be extended to explicitly consider resources and their interaction with goals
(Thangarajah, Winikoff, Padgham, & Fischer, 2002). It could also be extended with an
explicit model of the environment.
Whilst our analysis did consider a real application, it would be desirable to consider a
range of applications. This could provide additional evidence that the analysis is not unduly
pessimistic, and would also lead to an understanding of the variance in goal-plan trees and
their characteristics across applications. A key challenge is finding suitable applications that
are BDI-based, are sufficiently complex (ideally real applications), and have detailed design
information available (and preferably source code). Another challenge is the methodology:
we analysed the shape of the goal-plan tree of the Daimler workflow application, but did
113

fiWinikoff & Cranefield

not have access to run the system. An alternative methodology, which requires access to
the implemented system and probably the source code, is to run it, and force it to generate
all traces for sub-goals32 (which would require modification of either the source code or
the underlying agent platform). Once we have collected data on the shape of real-world
industrial applications, we will be able to analyse whether uniform and semi-uniform goalplan trees are good models of these types of system, or whether we should seek ways to
further relax our uniformity assumption.
More importantly, having highlighted the difficulties in assuring BDI agent systems
through testing, we need to find other ways of assuring such systems.
An approach that has some promise is the automatic generation of test cases for agent
systems (Nguyen, Perini, & Tonella, 2007; Zhang, Thangarajah, & Padgham, 2009). However, the size of the behaviour space suggests that the number of test cases needed may
be very large, and that testing for failed plan execution is difficult. One interesting, and
potentially promising, avenue is to use formal techniques to help guide the test generation
process (e.g. symbolic execution or specification-guided testing) (Dwyer, Hatcliff, Pasareanu, Robby, & Visser, 2007).
Another approach33 that has attracted interest is model checking of agent systems
(Wooldridge, Fisher, Huget, & Parsons, 2002; Bordini, Fisher, Pardavila, & Wooldridge,
2003; Raimondi & Lomuscio, 2007). This work is promising because model checking techniques use a range of abstractions to cover a large search space without having to deal
with individual cases one-at-a-time (Burch, Clarke, McMillan, Dill, & Hwang, 1992; Fix,
Grumberg, Heyman, Heyman, & Schuster, 2005). Furthermore, because verifying a subgoal considers all possibilities, it is possible to combine the verification of different sub-goals.
However, more work is needed: Raimondi and Lomuscio (2007) verify systems where agents
are defined abstractly, i.e. not in terms of plans and goals. The MABLE agent programming
language (Wooldridge et al., 2002) is actually an imperative language augmented with certain agent features, not a BDI language; and the work of Bordini et al. (2003) does not
include failure handling. In general, the state of the art in model checking agent system
implementations is still limited to quite small systems (Dennis, Fisher, Webster, & Bordini,
2012).
Acknowledgements
We would like to thank members of the Department of Information Science at the University
of Otago for discussions relating to this paper. We would also like to thank Lin Padgham
for her comments on a draft of this paper. Finally, we would like to thank the anonymous
reviewers for their insightful comments which helped to improve this paper. Some of the
work on this paper was done while Winikoff was on sabbatical from RMIT, visiting the
University of Otago.

32. Generating all traces of the top level goal is not likely to be feasible.
33. There has also been work on deductive verification, but (based on research into the verification of
concurrent systems) this appears to be less likely to result in verification tools that are both (relatively)
easy to use and applicable to real systems.

114

fiOn the Testability of BDI Agent Systems

Appendix A. Example Goal-Plan Trees and their Expansions
Suppose we have the following two trees: sample (left) and sample2 (right). The trees
correspond to j = 2, k = ` = 1, d = 1 for sample and d = 2 for sample2.
goal
plan
a

goal

plan

goal

b c

goal

d

plan

plan

plan

plan

plan

plan

a

b

e

f

g

h

These trees can be expanded respectively into the following sequences of actions, where
a letter indicates the execution of an action, and a 8 indicates failure34 . As predicted by
our formulae, there are four successful executions and two unsuccessful executions for the
first tree:
a
b

a8b
b8a

a8b8
b8a8

For the second tree, the expansions are the following 162 possibilities (consisting of 64
successful and 98 unsuccessful traces).
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a

e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e

b
b8cgd
b8cgd8
b8cg8hd
b8cg8hd8
b8cg8h8
b8chd
b8chd8
b8ch8gd
b8ch8gd8
b8ch8g8
b8c8
8fb
8fb8cgd
8fb8cgd8
8fb8cg8hd
8fb8cg8hd8
8fb8cg8h8
8fb8chd
8fb8chd8

a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a

f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f
f

b8chd
b8chd8
b8ch8gd
b8ch8gd8
b8ch8g8
b8c8
8eb
8eb8cgd
8eb8cgd8
8eb8cg8hd
8eb8cg8hd8
8eb8cg8h8
8eb8chd
8eb8chd8
8eb8ch8gd
8eb8ch8gd8
8eb8ch8g8
8eb8c8
8e8cgd
8e8cgd8

c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c

g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g
g

d8
d8
d8
d8
d8
d8
d8
d8
d8
d8
d8
8h
8h
8h
8h
8h
8h
8h
8h
8h

aeb
aeb8
ae8fb
ae8fb8
ae8f8
afb
afb8
af8eb
af8eb8
af8e8
a8
d
d8aeb
d8aeb8
d8ae8fb
d8ae8fb8
d8ae8f8
d8afb
d8afb8
d8af8eb

c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c

h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h
h

d8afb8
d8af8eb
d8af8eb8
d8af8e8
d8a8
8gd
8gd8aeb
8gd8aeb8
8gd8ae8fb
8gd8ae8fb8
8gd8ae8f8
8gd8afb
8gd8afb8
8gd8af8eb
8gd8af8eb8
8gd8af8e8
8gd8a8
8g8aeb
8g8aeb8
8g8ae8fb

34. Note that the failure marker isnt counted when considering the length of the trace in Section 4.6.

115

fiWinikoff & Cranefield

a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a

e8fb8ch8gd
e8fb8ch8gd8
e8fb8ch8g8
e8fb8c8
e8f8cgd
e8f8cgd8
e8f8cg8hd
e8f8cg8hd8
e8f8cg8h8
e8f8chd
e8f8chd8
e8f8ch8gd
e8f8ch8gd8
e8f8ch8g8
e8f8c8
fb
fb8cgd
fb8cgd8
fb8cg8hd
fb8cg8hd8
fb8cg8h8

af8e8cg8hd
af8e8cg8hd8
af8e8cg8h8
af8e8chd
af8e8chd8
af8e8ch8gd
af8e8ch8gd8
af8e8ch8g8
af8e8c8
a8cgd
a8cgd8
a8cg8hd
a8cg8hd8
a8cg8h8
a8chd
a8chd8
a8ch8gd
a8ch8gd8
a8ch8g8
a8c8
cgd

c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c

g8hd8af8eb8
g8hd8af8e8
g8hd8a8
g8h8aeb
g8h8aeb8
g8h8ae8fb
g8h8ae8fb8
g8h8ae8f8
g8h8afb
g8h8afb8
g8h8af8eb
g8h8af8eb8
g8h8af8e8
g8h8a8
hd
hd8aeb
hd8aeb8
hd8ae8fb
hd8ae8fb8
hd8ae8f8
hd8afb

c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c
c

h8g8ae8fb8
h8g8ae8f8
h8g8afb
h8g8afb8
h8g8af8eb
h8g8af8eb8
h8g8af8e8
h8g8a8
8aeb
8aeb8
8ae8fb
8ae8fb8
8ae8f8
8afb
8afb8
8af8eb
8af8eb8
8af8e8
8a8

Appendix B. Analysis of Recurrence Relations
This appendix contains details of the derivation in Section 4.4.
The exponential generating function F (x) of the sequence {f 4 (j, a, b)}
j=0 is the function
defined by the following power series:
F (x) =


X

f 4 (j, a, b)

j=0

xj
j!

(24)

(by definition of f 4 )
!
!
j1  


  
j
X
X
X
X
x
xj
j
j
=
i!ai (j i)b
=
i!ai (j i)b
i
j!
i
j!
j=0

i=0

j=0

i=0

On the right hand side above we have
 changed the upper limit of the inner sum to  based
j
on the generalised definition of i as j(j 1)(j 2) . . . (j i + 1)/i!, which is valid for all

complex numbers j and non-zero integers i (Wilf, 1994) and gives ji = 0 for i > j.
The right hand side has the form of a product of exponential generating functions (Wilf,
1994, Rule 30 , Section 2.3):



!



  
j
j
X
X
X
X
x
x
j
xj

(j)  
(j)  =
(i)(j i)
j!
j!
i
j!
j=0

j=0

j=0

i=0

where, for our case, (j) = j! aj and (j) = j b. Therefore, we can write:





j
j
X
X
(ax)  
x
F (x) = 
j!
jb 
j!
j!
j=0

j=0

116

fiOn the Testability of BDI Agent Systems

P
1
The left hand sum is G(ax) where G(y) = n y n = 1y
(Wilf, 1994, Equation 2.5.1)35 .

P
n
x
d x
d
0
The right hand sum is equal to bx dx
n! (Wilf, 1994, Rule 2 , Section 2.3) = bx dx e
x
(Wilf, 1994, Equation 2.5.3) = bxe . Thus we have:
F (x) =

1
bxex
bxex =
1  ax
1  ax

P
xj
4
Therefore, f 4 (0, a, b) is the constant term in the power series 
j=0 f (j, a, b) j! , which
is F (0) = 0. To find a recurrence relation defining f 4 (j + 1, a, b) we equate the original
definition of F (x) in Equation 24 with our closed form of this function, differentiate each
side (to give us a power series with the f 4 (j, a, b) values shifted one position to the left),
and multiply by the denominator of the closed form, giving us the following derivation.





d X 4
d
bxex
xj 
(1  ax)
= (1  ax)
f (j, a, b)
dx
j!
dx 1  ax
j=0



X
xj1
b(x+1)ex
abxex
4
= (1  ax)
f (j, a, b)j
= (1  ax)
+
j!
1  ax
(1  ax)2
j=0

=


X
j=0



bxex
xj1 X 4
xj

= b(x+1)ex + a
f (j, a, b)j
af (j, a, b)j
j!
j!
1  ax
4

j=0

4

(recall that f (0, a, b) = 0)


X
X
xj
xj
4
=
f (j +1, a, b)(j +1)

ajf 4 (j, a, b)
(j +1)!
j!
j=0

j=0

= bxex + bex + a


X

f 4 (j, a, b)

j=0

(recall that

bxex

=

j=0

Equating the coefficients of

xj
j!

xj
j=0 jb j! ,

j
X

and ex =

j=0

j=0

P


X
xj
=b
j +b
j!

xj
j!
xj
j=0 j! )

P



X
xj
x
+a
f 4 (j, a, b)
j!
j!

we get:

f 4 (j +1, a, b)  ajf 4 (j, a, b) = bj + b + af 4 (j, a, b)
= f 4 (j +1, a, b) = b(j +1) + af 4 (j, a, b) + ajf 4 (j, a, b)
= (j +1)(b + af 4 (j, a, b))

(25)

35. Note that many of the operations performed on generating functions (and all those used in this paper) are
valid without concern about convergence of the series. In combinatorics, generating functions are often
treated not as analytic functions to be evaluated for specific variable values, but rather as formal (possibly
infinite) algebraic objects, which have well defined operations such as addition and multiplication. The
set of formal power series over a finite set of variables has the structure of a ring from abstract algebra,
and in this ring there is no notion of function convergence and evaluation (Wilf, 1994, ch. 2).

117

fiWinikoff & Cranefield

Appendix C. Analysis of Recursive Goal-Plan Trees
This appendix contains detailed derivations relating to Section 4.7.
4
C.1 Derivation of F
(goal(P M ), x, y, b, )
4
We can define F
(goal(P M ), x, y, b, ) in terms of n4 in the usual way, noting the upper
bound of  to realise the length bound:

4
F
(goal(P M ), x, y, b, ) =

 X

X

n4(goal(P M ), m, n, b)xm y n

m=0 n=0
4

where n(goal(P M ), m, n, b) is as defined in Section 4.7. We also make use of the nonbounded version (which has only four arguments):
4
F
(goal(P M ), x, y, b) =

 X

X

n4(goal(P M ), m, n, b)xm y n

m=0 n=0
4

We then can define n by counting successful traces:
n4(goal(P M ), m, n, b)
X
=
P M (p)

X

n4(p, m1 , n1 , b) n8(P M  {p:1}, m2 , n2 , b)

m1 +m2 =m
n1 +n2 =n

pset(P M )

where n8(P M, m, n, b) is the number of unsuccessful paths using zero or more of the plans
in the plan multiset P M (with respect to binding b) that have m actions, n of which are
failed actions.
The inner sum considers all ways to partition the numbers of actions (m) and action
failures (n) into those caused by a single plan of shape p and P
those P
caused by all the

other
plans.
As
in
Section
4.6
(page
98)
we
use
the
identity
m=0
p+q=m f (p, q) =
P P
p=0
q=0 f (p, q) to rewrite:
4
F
(goal(P M ), x, y, b)
 X

X
X
X
=
P M (p)
n4(p, m1 , n1 , b) n8(P M {p:1}, m2 , n2 , b)xm y n

m1 +m2 =m
n1 +n2 =n

m=0 n=0 pset(P M )

X

=

P M (p)

pset(P M )

 X

X

X

n4(p, m1 , n1 , b) n8(P M {p:1}, m2 , n2 , b)xm y n

m=0 n=0 m1 +m2 =m
n1 +n2 =n

to give us:
4
F
(goal(P M ), x, y, b)
X
=
P M (p)

pset(P M )


X
X

 X

X

n4(p, m1 , n1 , b)xm1 y n1 n8(P M {p:1}, m2 , n2 , b)xm2 y n2

m1 =0 m2 =0 n1 =0 n2 =0

118

fiOn the Testability of BDI Agent Systems

=

X

P M (p)

pset(P M )
 X

X

4

n(p, m1 , n1 , b)x

y

=

n8(P M {p:1}, m2 , n2 , b)xm2 y n2

m2 =0 n2 =0

m1 =0 n1 =0

X

 X

X

m1 n1

4

8

P M (p) F(p, x, y, b) F(P M  {p:1}, x, y, b)

pset(P M )
8
where F
(P M, x, y, b) is the generating function for n8(P M, m, n, b). In Section C.3 we
8
provide a definition of F
(P M, x, y, b) in terms of an auxiliary function G8 (see Section C.4).
We then introduce the bound on the length of paths  giving:
4
F
(goal(P M ), x, y, b, )
X
x
4
8
=
P M (p) (F
(p, x, y, b)  F
(P M  {p : 1}, x, y, b))

pset(P M )

=

X

x

4
8
P M (p) (F
(p, x, y, b, )  F
(P M  {p : 1}, x, y, b, ))

pset(P M )
8
C.2 Derivation of F
(goal(P M ), x, y, b, )

Similarly to the previous derivation, we define:
8
F
(goal(P M ), x, y, b, ) =

 X

X

n8(goal(P M ), m, n, b)xm y n

m=0 n=0
8
(goal(P M ), . . . ) in terms of the plans in P M , we
To derive a recursive definition of F
8
first define a new function n(P M, m, n, o, b), which denotes the number of unsuccessful
paths that use o of the plans in the multiset P M . We then have:

n8(goal(P M ), m, n, b) = n8(P M, m, n, |P M |, b)
This states that for the goal to fail, all |P M | plans in the multiset must be tried.
We define a generating function G8(P M, x, y, z, b, ) for n8(P M, m, n, o, b) that is ordinary in x and y but exponential in z, i.e. the coefficients of xm y n z o /o! are the values of
n8(P M, m, n, o, b).
We now have:
8
F
(goal(P M ), x, y, b, ) =

 X

X

n8(P M, m, n, |P M |, b)xm y n

m=0 n=0

which we wish to rewrite in terms of G8 . We do this by generalising the right hand side
to sum over possible values for the number of plans used (o), followed by a restriction to
select only values where o = |P M |:

119

fiWinikoff & Cranefield

8
F
(goal(P M ), x, y, b, )

= |P M |!

 X

X
n8 (P M, m, n, |P M |, b) z |P M |


|P M |! z |P M |

xm y n

m=0 n=0

 X
  P
8
o
X
o=0 n(P M, m, n, o, b)z /o! power(z)=|P M |
|P M |!
xm y n
|P M |
z
m=0 n=0

=

P
= |P M |!

P P 8

m n o
m=0
n=0
o=0 n(P M, m, n, o, b)x y z /o!



power(z)=|P M |

z |P M |

Since the nested sum is just the definition of G8 (see Section C.4), we can simplify this to:
8

F(goal(P M ), x, y, b, ) = |P M |!

G8(P M, x, y, z, b, ) power(z)=|P M |
z |P M |

8
In Section C.4 we derive a definition of G8(P M, . . .) in terms of F
(p, . . .) for each p 
set(P M ).

8
C.3 Definition of F
(P M, x, y, b, )

Recall that n8(P M, m, n, b) is the number of unsuccessful paths using zero or more of the
plans in the plan multiset P M (with respect to binding b) that have m actions, n of which
8
are failed actions, and F
(P M, x, y, b, ) is its ordinary generating function.
First we consider the case when P M is empty. In this case, there is precisely one way
8
to fail, and it generates a trace of length zero. Therefore, F
({}, x, y, b, ) = 1x0 y 0 = 1.
For the case when P M is non-empty we can sum over the number of plans used during
execution, which yields the following definition:
|P M |
8

n(P M, m, n, b) =

X

n8(P M, m, n, o, b)

o=0

where n8(P M, m, n, o, b) is, as before, the number of unsuccessful paths through the plan
8
multiset
M , using o of the plans. Therefore, using the definition of F
(P M, x, y, b, ) =
P PP

8
m
n
n
(P
M,
m,
n,
o,
b)x
y
,
we
have:
m=0
n=0 
8
F
(P M, x, y, b, )

=

M|
 X
 |P
X
X

n8(P M, m, n, o, b)xm y n

m=0 n=0 o=0

(replace n8 by looking up the coefficient of the corresponding term in G8 ,
the o! accounts for the division by o! in G8 ; we also reorder the summations)
|P M |

=

 X

X X

o![xm y n z o ]G8(P M, x, y, z, b, )xm y n

o=0 m=0 n=0

120

fiOn the Testability of BDI Agent Systems

(we shift o! outwards, and multiply by z o /z o )
P
|P M | P
m n o
8
m n o
X
n=0 [x y z ]G(P M, x, y, z, b, )x y z
m=0
=
o!
zo
o=0

|P M |

=

X
o=0

o!

G8(P M, x, y, z, b, ) power(z)=o
zo

C.4 Definition of G8(P M, x, y, z, b, )
We define G8(P M, x, y, z, b, ) as a generating function for n8(P M, m, n, o, b) that is ordinary in x and y but exponential in z (hence the division by o! below), with ( 0) as the
maximum allowed trace length:
G8(P M, x, y, z, b, ) =

 X
 X

X

n8(P M, m, n, o, b)

m=0 n=0 o=0

xm y n z o
o!

Recall that n8(P M, m, n, o, b) denotes the number of unsuccessful paths that use o of the
plans in the multiset P M . For an empty multiset of plans there is no successful execution,
and there is a single unsuccessful execution with 0 actions, that uses 0 plans, hence:
(
1 if m = n = o = 0
8
n({}, m, n, o, b) =
0 otherwise
Therefore, G8({}, x, y, z, b, ) = 1. For non-empty multisets we must partition the actions
in each trace, the action failures, and numbers of plans used, across the different plan bodies
in the multiset, and also consider all ways that the plans of the various plan shapes can be
interleaved to give an overall order for attempting plans:
n8({p1 :c1 , . . . , pj :cj }, m, n, o, b)
X
=
 n8({p1 :c1 }, m1 , n1 , o1 , b)    n8({pj :cj }, mj , nj , oj , b)
m1 ++mj =m
n1 ++nj =n
o1 ++oj =o

where  is the multinomial coefficient
Thus:

o
o1 ...oj



=

o!
o1 !...oj !

G8({p1 :c1 , . . . , pj :cj }, x, y, z, b, )
(by definition of G8, but using restriction, rather than a bounded sum on m,
and expanding n8 as above)



X
X
o
=
n8({p1 :c1 }, m1 , n1 , o1 , b)
o
.
.
.
o
1
j
m ++m =m
m,n,o=0

1

j

n1 ++nj =n
o1 ++oj =o

xm y n z o
   n({pj :cj }, mj , nj , oj , b)
o!
8

121

!
power(x)

fiWinikoff & Cranefield

=


X

X

o!
n8({p1 :c1 }, m1 , n1 , o1 , b)
o
!
.
.
.
o
!
1
j
=m

m,n,o=0 m1 ++mj
n1 ++nj =n
o1 ++oj =o

xm y n z o
   n8({pj :cj }, mj , nj , oj , b)
o!

!
power(x)

(cancelling o! and distributing the oi ! and the xmi , y ni and z oi )
=


X

X

n8({p1 :c1 }, m1 , n1 , o1 , b)

m,n,o=0 m1 ++mj =m
n1 ++nj =n
o1 ++oj =o

xm1 y n1 z o1
o1 !

xmj y nj z oj
   n({pj :cj }, mj , nj , oj , b)
oj !

!

8

(replacing


X

X

with

m=0 m1 +m2 =m


= 


X



X
X

and redistributing sums)

m1 =0 m2 =0

n8({p1 :c1 }, m1 , n1 , o1 , b)

xm1 y n1 z o1

m1 ,n1 ,o1 =0




X



power(x)

o1 !




n8({pj :cj }, mj , nj , oj , b)

xmj y nj z oj

mj ,nj ,oj =0

oj !


 power(x)

x

(replacing restriction  with  )



m
n
o
X
1
1
1
x y z  x
=
n8({p1 :c1 }, m1 , n1 , o1 , b)

o1 !
m1 ,n1 ,o1 =0



m
n
o
X
j
j
j
x
x y z 
  
n8({pj :cj }, mj , nj , oj , b)
oj !
mj ,nj ,oj =0

8

(by definition of G . . . )
x

x

= G8({p1 :c1 }, x, y, z, b, )      G8({pj :cj }, x, y, z, b, )

We now need to define G8({pi :ci }, x, y, z, b, ).
Consider n8({p:c}, m, n, o, b). The simple cases are where o = 0: if we do not use any
plans, then there is only a single unsuccessful
path, which has no actions (m = n = 0). On

c!
the other hand, if o > 0 then we have oc = o!(co)!
ways of selecting o out of the c available
copies of the plan p. These selected plans can be executed in o! different orders. For each
execution we sum over the possible distributions of actions (successful and unsuccessful)
122

fiOn the Testability of BDI Agent Systems

amongst the plans. This gives:
 
X
c


o!
n8(p, m1 , n1 , b)    n8(p, mo , no , b)


o

m1 ++mo =m
n1 ++no =n
n8({p:c}, m, n, o, b) =


1
if m = n = o = 0



0
otherwise

if o > 0

We therefore have the following definition of G8({p:c}, x, y, z, b, ), where the initial 1 abbreviates 1x0 y 0 z 0 /0!, i.e. the base case where m = n = o = 1, and the rest is from the
definition of G8 , expanding n8 using the above definition.
G8({p:c}, x, y, z, b, )
= 1+

 

X
c
o!
o
m


X

X

n8(p, m1 , n1 , b)    n8(p, mo , no , b)

1 ++mo =m
n1 ++no =n

m=0 n=0,o=1

xm y n z o
o!

(cancel o!/o!, rearrange sums and replace an upper bound of  on m
with a restriction)





   X
 X
 X
X

c 
8
8
m
n
o

= 1+
n(p, m1 , n1 , b)    n(p, mo , no , b)x y 

power(x) z
o 

o=1
m=0 n=0
m1 ++mo =m
n1 ++no =n


X

(replacing

X

m=0 m1 +m2 =m

= 1+

with



X
X

and redistributing sums)

m1 =0 m2 =0

  
X
c
o=1

o
 X

X

!
n8(p, m1 , n1 , b)xm1 y n1



m1 =0 n1 =0

 X

X

!!
n8(p, mo , no , b) xmo y no

mo =0 no =0
o

power(x) z
!o
   X
 X

X
c
= 1+
n8(p, m, n, b) xm y n
power(x) z o
o
m=0 n=0
o=1
XX
8
(Replace
n8(p, m, n, b)xm y n with F
(p, x, y, b, ) as per its definition)
m

n

c  
X
c
= 1+
F 8 (p, x, y, b, )o power(x) z o
o 
o=1
c  
X
c
F 8 (p, x, y, b, )ox z o
= 1+
o 
o=1

123

fiWinikoff & Cranefield

Appendix D. Analysis of Procedural Code Structures
We seek to derive an expression for the largest possible number of paths that a program of
given size m can have, i.e. a definition of n(m) = max{n(P ) : |P | = m}. Recall that a
program is either an (atomic) statement s which has a single path (i.e. n(s) = 1), a sequence
of two programs P1 ; P2 where n(P1 ; P1 ) = n(P1 )  n(P2 ), or a conditional P1 + P2 where
n(P1 + P2 ) = n(P1 ) + n(P2 ).
It is relatively easy to see by examining possible programs that for m  3 we have
n(m) = m. For instance, the largest number of paths for m = 3 is obtained by the program
s + s + s. It is also easy to show that for m = 4 the largest number of paths possible is 4.
But what about larger values of m? We observe that for all m > 4 the program36 with
the largest number of paths follows a particular form. For m = 5 the program with the
largest path can be written as P5 = (s + s + s); (s + s), and we have n(P5 ) = 3  2. More
generally, we define S2 to be s + s, and S3 to be s + s + s, and we then have the following
result, which shows that programs that have a maximal number of paths for their size, can
be considered to be of a particular form.
Theorem D.1 Any program of size i (for i > 4) that has the largest possible number of
paths can be written as Pi = Pi1 ; Pi2 ; . . . ; Pik where each of the Pij (1  j  k) is either S2
or S3 .
Proof: We establish this result by induction. We assume that it holds for all n such that
4 < n  m, and then show that it must also hold for m + 1. So, let us assume that
there is a program Pm+1 which has a maximal number of paths, but is not in the form
j
1
2
k
Pm+1
; Pm+1
; . . . ; Pm+1
where each Pm+1
is either S2 or S3 . There are two cases, depending
on the structure of Pm+1 . We consider each case in turn and show that in fact either (a)
Pm+1 can be rewritten to be in the desired form, preserving the number of paths and the
program size; or (b) Pm+1 cannot be maximal, since we can construct a program with size
m + 1 that has a larger number of paths than Pm+1 .
j
1
2
k
Case 1: Pm+1 has the form Pm+1
; Pm+1
; . . . ; Pm+1
but at least one of the Pm+1
is neither
i
S2 nor S3 . Let Pm+1 be one of the sub-programs that is neither S2 nor S3 . For convenience
i
we define P i as shorthand for Pm+1
. Now, since P i has size less than m + 1, the induction
hypothesis applies37 , and so it can be written in the form Pi1 ; Pi2 ; . . . Pil where each Pij is
either S2 or S3 . It is easy to see that one can then rewrite Pm+1 into the desired form by
exploiting the associativity of ;, rewriting it as follows:
i1
i+1
i1
i+1
. . . Pm+1
; (Pi1 ; Pi2 ; . . . Pij ); Pm+1
; . . . = . . . Pm+1
; Pi1 ; Pi2 ; . . . Pij ; Pm+1
;...
i
Applying this rewriting to all Pm+1
that are not S2 or S3 yields a program that has size
m + 1, the same number of paths as the original program, but that is in the desired form: a
sequence of sub-programs, each of which is either S2 or S3 . This shows that the result holds
for m + 1, i.e. that a maximal-path program can be written in the desired form.
1
2
k
Case 2: Pm+1 does not have the form Pm+1
; Pm+1
; . . . ; Pm+1
for any k, which means that
1
k
Pm+1 must consist of a single conditional, i.e. Pm+1 = Pm+1 + . . . + Pm+1
for some k > 1.

36. In fact there will be more than one maximal-path program, but they all have the same structure, modulo
swapping the order of arguments to + and ;.
37. Or, if it has size 4, then it can be written as S2 ; S2 which has the maximal number of paths for a program
of size 4 and meets the desired form.

124

fiOn the Testability of BDI Agent Systems

1
2
Without loss of generality we can view Pm+1 as being of the form Pm+1
+ Pm+1
(by viewing
1
k
1
k
Pm+1 + . . . + Pm+1 as (Pm+1 + . . .) + Pm+1 if k > 2). We now consider the following
1
2
sub-cases, depending on the values of n(Pm+1
) and n(Pm+1
).
1
2
Case 2a: Both n(Pm+1
) and n(Pm+1
) are greater than 2. We can then show that Pm+1 is
0
1
2
not maximal. Consider the program Pm+1
= Pm+1
; Pm+1
(i.e. where + is replaced
1
2
1
2
by ;). We know that n(Pm+1 ; Pm+1 ) = n(Pm+1 )  n(Pm+1
). Without loss of gen1
2
erality, lets assume that n(Pm+1 )  n(Pm+1 ). We then show that the original Pm+1
0
1
has fewer paths than Pm+1
. The number of paths of Pm+1 is n(Pm+1 ) = n(Pm+1
)+
2
1
2
1
2
n(Pm+1 ). Since n(Pm+1 )  n(Pm+1 ), we have that n(Pm+1 ) = n(Pm+1 ) + n(Pm+1 ) 
2
2
2
2
1
n(Pm+1
) + n(Pm+1
) = 2  n(Pm+1
). Since n(Pm+1
) and n(Pm+1
) are both greater
2
1
2
0
than 2, we then have that 2  n(Pm+1 ) < n(Pm+1 )  n(Pm+1 ) = n(Pm+1
), i.e. that
0
Pm+1 has more paths than Pm+1 , and hence Pm+1 is not maximal for m + 1.
1
2
Case 2b: At least one of n(Pm+1
) and n(Pm+1
) is not greater than 2. Without loss of
1
2
1
generality, we assume that n(Pm+1 )  n(Pm+1
). There are then two cases: n(Pm+1
)
can be either 2 or 1.
1
) = 1. Now the only
Sub-case 2b(i): Let us consider first the case where n(Pm+1
program that has one path is a statement s, or a sequence of statements s; s; . . . ; s.
Clearly the latter is not maximal since replacing it with s + s + . . . + s would
result in a program of the same size but with more paths. So, therefore if Pm+1
1
2
2
is maximal, then Pm+1
must be just s, so Pm+1 = s + Pm+1
. Therefore Pm+1
has
size m. There are now two sub-cases: either m is still greater than 4, or m = 4.
The second sub-case is simple: if m is 4 then we can show, by inspecting possible
2
programs of size 4, that n(4) = 4, and we therefore have that n(s + Pm+1
) 
1 + 4 = 5. However, we also know that (s + s + s); (s + s) has size 5 but 6 paths,
and hence in this sub-case Pm+1 cannot have the maximal number of paths. In
the first sub-case, where m is still greater than 4, the induction hypothesis applies
2
2
can be written in the desired form. We abbreviate Pm+1
by
and therefore Pm+1
j
i
1
2
P2 , and then have Pm+1 = s + (P2 ; P2 ; . . . ; P2 ) where each P2 is either S2 or
00
S3 . Consider now the variant program Pm+1
= ((s + P21 ); P22 ; . . . P2j ), which
00
clearly has the same size as Pm+1 . We now show that Pm+1
has more paths than
j
00
1
2
2
Pm+1 : n(Pm+1 ) = ((1 + n(P2 ))  n(P2 ; . . . ; P2 )) = n(P2 ; . . . ; P2j ) + (n(P21 ) 
n(P22 ; . . . ; P2j )). Now, n(Pm+1 ) = 1 + (n(P21 )  n(P22 ; . . . ; P2j )). In order to show
00
that n(Pm+1 ) < n(Pm+1
) we just need to show that 1 < n(P22 ; . . . ; P2j ) which
follows from the fact that there must be at least one P2i , and that, since each P2i
is either S2 or S3 , it has size of at least 2.
1
2
1
Sub-case 2b(ii): We know that n(Pm+1
) = 2 and that 2  n(Pm+1
). Since n(Pm+1
)
2
2
2
n(Pm+1 ) we have that n(Pm+1 )  2 and hence that n(Pm+1 ) = 2 + n(Pm+1 ) 
2
0
2
2  n(Pm+1
) = n(Pm+1
). Now, if n(Pm+1
) is strictly greater than 2 then we have
0
that n(Pm+1 ) is strictly less than n(Pm+1 ) and we have shown that Pm+1 actually
2
does not have a maximal number of paths. On the other hand, if n(Pm+1
)=2
2
then we have that n(Pm+1 ) = 2 + n(Pm+1 ) = 2 + 2 = 4. However, for values of
m where this theorem applies, we know that n(m) > 4, and so we therefore have
shown that in this sub-case Pm+1 is not maximal for m + 1.

125

fiWinikoff & Cranefield

We have shown that if we assume that Pm+1 is maximal but does not have the structure
specified, then in fact one can derive another program, also of size m + 1, but which either
does satisfy the desired structure, or has a larger number of paths than Pm+1 , which contradicts our assumption that Pm+1 is maximal. This establishes the desired property for Pm+1 .
By induction the result then applies for all m > 4, as desired.
The previous result shows that when considering programs of a given size m that have
the largest possible number of paths (denoted Pm ), we can limit ourselves to considering
programs that are of the form P1m ; P2m ; . . . ; Pkm where each Pim is either s + s or s + s + s.
We now derive a definition for n(m). Firstly, we observe that, by inspecting cases:
n(m) = m, if m  4
n(5) = 6
n(6) = 9
The two first cases have been discussed above. For the last case, there are only two programs
which have the appropriate structure and have size 6: S2 ; S2 ; S2 (with 8 paths) and S3 ; S3
(with 9 paths).
We now consider m > 6. Adding a statement to the program (i.e. going from m to m+1)
in effect modifies Pm by adding an s to one of the Pim , which increments n(Pim ) by one.
Since multiplication is commutative and associative, without loss of generality, we assume
m )  n(P m ) and
that we increment n(Pkm ). We therefore have that n(Pm ) = n(P1m ; . . . ; Pk1
k
m
m
m
that n(Pm+1 ) = n(P1 ; . . . ; Pk1 )  (n(Pk ) + 1). There are two cases:
m )3 and that therefore
Case 1: If all the Pim are S3 , then we have n(Pm ) = n(P1m ; . . . ; Pk1
m )  4 = n(P )  4 . Note that in this case P
n(Pm+1 ) = n(P1m ; . . . ; Pk1
m
m+1 can be
3
m
m
written as P1 ; . . . ; Pk1 ; S2 ; S2 .

Case 2: if some Pim are S2 and some are S3 then we observe that replacing a 2 with a 3 gives
a greater increase to the number of paths than replacing a 3 with a 4, and hence (after
m )2
possibly reordering the Pim so that Pkm = S2 ) we have n(Pm ) = n(P1m ; . . . ; Pk1
3
m
m
and that n(Pm+1 ) = n(P1 ; . . . ; Pk1 )  3 = n(Pm )  2 .
We therefore have a recursive definition for n(m) depending on the form of Pm . We next
observe that in fact the form of Pm follows a simple cycle. We know that for m = 6, case 1
holds (as above, P6 = S3 ; S3 ). We therefore have that P7 can be written as S3 ; S2 ; S2 , hence
P8 can be written as S3 ; S3 ; S2 or S3 ; S2 ; S3 , and hence P9 can be written as S3 ; S3 ; S3 .
More generally, we can prove by induction that Pm can be written as P1m ; . . . ; Pkm where
the following holds: (a) if m is a multiple of 3, then all of the Pim are S3 ; and (b) if m is
one more than a multiple of 3, then exactly two of the Pim are S2 and the rest are S3 ; and
(c) if m is two more than a multiple of 3, then exactly one of the Pim is S2 and the rest are
S3 . This gives us the following recursive definition, where m  6 is a multiple of 3:
n(m + 1) = n(m) 

4
3

n(m + 2) = n(m + 1) 
126

3
2

fiOn the Testability of BDI Agent Systems

n(m + 3) = n(m + 2) 

3
2

Which can be simplified to:
4
3
34
n(m + 2) = n(m) 
= 2  n(m)
23
334
= 3  n(m)
n(m + 3) = n(m) 
223
n(m + 1) = n(m) 

We can easily derive a non-recursive definition by focusing on the last case and observing
that as n(6) = 9 = 32 and n(m + 3) = 3  n(m) (for m  6 being a multiple of 3), then
we have that n(m) = 3m/3 . We can substitute this in the definition above to obtain the
following complete definition for n(m), where m  6 is a multiple of 3:
n(1) = 1
n(2) = 2
n(3) = 3
n(4) = 4
n(5) = 6
n(m) = 3m/3
4
n(m + 1) =
 3m/3
3
n(m + 2) = 2  3m/3

127

fiWinikoff & Cranefield

References
Benfield, S. S., Hendrickson, J., & Galanti, D. (2006). Making a strong business case for
multiagent technology. In Stone, P., & Weiss, G. (Eds.), Proceedings of the Fifth International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS),
pp. 1015. ACM Press.
Bordini, R. H., Fisher, M., Pardavila, C., & Wooldridge, M. (2003). Model checking AgentSpeak. In Proceedings of the Second International Joint Conference on Autonomous
Agents and Multiagent Systems (AAMAS), pp. 409416. ACM Press.
Bordini, R. H., Hubner, J. F., & Wooldridge, M. (2007). Programming multi-agent systems
in AgentSpeak using Jason. Wiley.
Bratman, M. E., Israel, D. J., & Pollack, M. E. (1988). Plans and resource-bounded practical
reasoning. Computational Intelligence, 4, 349355.
Bratman, M. E. (1987). Intentions, Plans, and Practical Reason. Harvard University Press,
Cambridge, MA.
Burch, J., Clarke, E., McMillan, K., Dill, D., & Hwang, J. (1992). Symbolic model checking:
1020 states and beyond. Information and Computation, 98 (2), 142170.
Burmeister, B., Arnold, M., Copaciu, F., & Rimassa, G. (2008). BDI-agents for agile goaloriented business processes. In Proceedings of the Seventh International Conference on
Autonomous Agents and Multiagent Systems (AAMAS) [Industry Track], pp. 3744.
IFAAMAS.
Busetta, P., Ronnquist, R., Hodgson, A., & Lucas, A. (1999). JACK Intelligent Agents Components for Intelligent Agents in Java. AgentLink News (2).
Dastani, M. (2008). 2APL: A practical agent programming language. Autonomous Agents
and Multi-Agent Systems, 16 (3), 214248.
Dastani, M., Hindriks, K. V., & Meyer, J.-J. C. (Eds.). (2010). Specification and Verification
of Multi-agent systems. Springer, Berlin/Heidelberg.
de Silva, L., & Padgham, L. (2004). A comparison of BDI based real-time reasoning and
HTN based planning. In Webb, G., & Yu, X. (Eds.), AI 2004: Advances in Artificial
Intelligence, Vol. 3339 of Lecture Notes in Computer Science, pp. 11671173. Springer,
Berlin/Heidelberg.
Dennis, L. A., Fisher, M., Webster, M. P., & Bordini, R. H. (2012). Model checking agent
programming languages. Automated Software Engineering, 19 (1), 363.
dInverno, M., Kinny, D., Luck, M., & Wooldridge, M. (1998). A formal specification of
dMARS. In Singh, M., Rao, A., & Wooldridge, M. (Eds.), Intelligent Agents IV:
Proceedings of the Fourth International Workshop on Agent Theories, Architectures,
and Languages, Vol. 1365 of Lecture Notes in Artificial Intelligence, pp. 155176,
Berlin/Heidelberg. Springer.
Dorigo, M., & Stutzle, T. (2004). Ant Colony Optimization. MIT Press.
Dwyer, M. B., Hatcliff, J., Pasareanu, C., Robby, & Visser, W. (2007). Formal software analysis: Emerging trends in software model checking. In Future of Software Engineering
2007, pp. 120136, Los Alamitos, CA. IEEE Computer Society.
128

fiOn the Testability of BDI Agent Systems

Ekinci, E. E., Tiryaki, A. M., Cetin, O., & Dikenelli, O. (2009). Goal-oriented agent testing
revisited. In Luck, M., & Gomez-Sanz, J. J. (Eds.), Agent-Oriented Software Engineering IX, Vol. 5386 of Lecture Notes in Computer Science, pp. 173186, Berlin/Heidelberg. Springer.
Erol, K., Hendler, J., & Nau, D. (1996). Complexity results for HTN planning. Annals of
Mathematics and Artificial Intelligence, 18 (1), 6993.
Erol, K., Hendler, J. A., & Nau, D. S. (1994). HTN planning: Complexity and expressivity.
In Proceedings of the 12th National Conference on Artificial Intelligence (AAAI), pp.
11231128. AAAI Press.
Fix, L., Grumberg, O., Heyman, A., Heyman, T., & Schuster, A. (2005). Verifying very
large industrial circuits using 100 processes and beyond. In Peled, D., & Tsay, Y.K. (Eds.), Automated Technology for Verification and Analysis, Vol. 3707 of Lecture
Notes in Computer Science, pp. 1125, Berlin/Heidelberg. Springer.
Georgeff, M. P., & Lansky, A. L. (1986). Procedural knowledge. Proceedings of the IEEE,
Special Issue on Knowledge Representation, 74 (10), 13831398.
Gomez-Sanz, J. J., Bota, J., Serrano, E., & Pavon, J. (2009). Testing and debugging of
MAS interactions with INGENIAS. In Luck, M., & Gomez-Sanz, J. J. (Eds.), AgentOriented Software Engineering IX, Vol. 5386 of Lecture Notes in Computer Science,
pp. 199212, Berlin/Heidelberg. Springer.
Huber, M. J. (1999). JAM: A BDI-theoretic mobile agent architecture. In Proceedings of
the Third International Conference on Autonomous Agents (Agents99), pp. 236243.
ACM Press.
Ingrand, F. F., Georgeff, M. P., & Rao, A. S. (1992). An architecture for real-time reasoning
and system control. IEEE Expert, 7 (6), 3344.
Jorgensen, P. (2002). Software Testing: A Craftsmans Approach (Second edition). CRC
Press.
Lee, J., Huber, M. J., Kenny, P. G., & Durfee, E. H. (1994). UM-PRS: An implementation of the procedural reasoning system for multirobot applications. In Proceedings of the Conference on Intelligent Robotics in Field, Factory, Service, and Space
(CIRFFSS94), pp. 842849. American Institute of Aeronautics and Astronautics.
Mathur, A. P. (2008). Foundations of Software Testing. Pearson.
Miller, J. C., & Maloney, C. J. (1963). Systematic mistake analysis of digital computer
programs. Communications of the ACM, 6 (2), 5863.
Morley, D., & Myers, K. (2004). The SPARK agent framework. In Proceedings of the
Third International Joint Conference on Autonomous Agents and Multiagent Systems
(AAMAS), pp. 714721, New York. ACM.
Munroe, S., Miller, T., Belecheanu, R., Pechoucek, M., McBurney, P., & Luck, M. (2006).
Crossing the agent technology chasm: Experiences and challenges in commercial applications of agents. Knowledge Engineering Review, 21 (4), 345392.
129

fiWinikoff & Cranefield

Naish, L. (2007). Resource-oriented deadlock analysis. In Dahl, V., & Niemela, I. (Eds.),
Proceedings of the 23rd International Conference on Logic Programming, Vol. 4670 of
Lecture Notes in Computer Science, pp. 302316. Springer, Berlin/Heidelberg.
Nguyen, C., Miles, S., Perini, A., Tonella, P., Harman, M., & Luck, M. (2009a). Evolutionary testing of autonomous software agents. In Proceedings of the 8th International
Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 521528.
IFAAMAS.
Nguyen, C. D., Perini, A., & Tonella, P. (2009b). Experimental evaluation of ontology-based
test generation for multi-agent systems. In Luck, M., & Gomez-Sanz, J. J. (Eds.),
Agent-Oriented Software Engineering IX, Vol. 5386 of Lecture Notes in Computer
Science, pp. 187198, Berlin/Heidelberg. Springer.
Nguyen, C. D., Perini, A., & Tonella, P. (2007). Automated continuous testing of multiagent systems. In Proceedings of the Fifth European Workshop on Multi-Agent Systems
(EUMAS).
Padgham, L., & Winikoff, M. (2004). Developing Intelligent Agent Systems: A Practical
Guide. John Wiley and Sons.
Paolucci, M., Shehory, O., Sycara, K. P., Kalp, D., & Pannu, A. (2000). A planning component for RETSINA agents. In Jennings, N. R., & Lesperance, Y. (Eds.), Proceedings
of the 6th International Workshop on Agent Theories, Architectures, and Languages
(ATAL), Vol. 1757 of Lecture Notes in Computer Science, pp. 147161, Berlin/Heidelberg. Springer.
Pokahr, A., Braubach, L., & Lamersdorf, W. (2005). Jadex: A BDI reasoning engine. In
Bordini, R. H., Dastani, M., Dix, J., & El Fallah Seghrouchni, A. (Eds.), Multi-Agent
Programming: Languages, Platforms and Applications, chap. 6, pp. 149174. Springer.
Raimondi, F., & Lomuscio, A. (2007). Automatic verification of multi-agent systems by
model checking via ordered binary decision diagrams. J. Applied Logic, 5 (2), 235
251.
Rao, A. S. (1996). AgentSpeak(L): BDI agents speak out in a logical computable language.
In de Velde, W. V., & Perrame, J. (Eds.), Agents Breaking Away: Proceedings of
the Seventh European Workshop on Modelling Autonomous Agents in a Multi-Agent
World (MAAMAW96), Vol. 1038 of Lecture Notes in Artificial Intelligence, pp. 4255,
Berlin/Heidelberg. Springer.
Rao, A. S., & Georgeff, M. P. (1991). Modeling rational agents within a BDI-architecture.
In Allen, J., Fikes, R., & Sandewall, E. (Eds.), Proceedings of the Second International
Conference on Principles of Knowledge Representation and Reasoning, pp. 473484.
Morgan Kaufmann.
Sardina, S., & Padgham, L. (2011). A BDI agent programming language with failure handling, declarative goals, and planning. Autonomous Agents and Multi-Agent Systems,
23 (1), 1870.
Shaw, P., Farwer, B., & Bordini, R. (2008). Theoretical and experimental results on the
goal-plan tree problem. In Proceedings of the Seventh International Conference on
Autonomous Agents and Multiagent Systems (AAMAS), pp. 13791382. IFAAMAS.
130

fiOn the Testability of BDI Agent Systems

Sloane, N. J. A. (2007). The on-line encyclopedia of integer sequences. http://www.research.
att.com/njas/sequences/.
Thangarajah, J., Winikoff, M., Padgham, L., & Fischer, K. (2002). Avoiding resource
conflicts in intelligent agents. In van Harmelen, F. (Ed.), Proceedings of the 15th
European Conference on Artificial Intelligence (ECAI), pp. 1822. IOS Press.
van Riemsdijk, M. B., Dastani, M., & Winikoff, M. (2008). Goals in agent systems: A
unifying framework. In Proceedings of the Seventh Conference on Autonomous Agents
and Multiagent Systems (AAMAS), pp. 713720. IFAAMAS.
Wilf, H. S. (1994). generatingfunctionology (Second edition). Academic Press Inc., Boston,
MA. http://www.math.upenn.edu/wilf/gfology2.pdf.
Winikoff, M. (2010). Assurance of Agent Systems: What Role should Formal Verification
play?. In Dastani, M., Hindriks, K. V., & Meyer, J.-J. C. (Eds.), Specification and
Verification of Multi-agent systems, chap. 12, pp. 353383. Springer, Berlin/Heidelberg.
Winikoff, M., Padgham, L., Harland, J., & Thangarajah, J. (2002). Declarative & procedural goals in intelligent agent systems. In Proceedings of the Eighth International
Conference on Principles of Knowledge Representation and Reasoning (KR2002), pp.
470481, Toulouse, France. Morgan Kaufmann.
Wooldridge, M. (2002). An Introduction to MultiAgent Systems. John Wiley & Sons,
Chichester, England.
Wooldridge, M., Fisher, M., Huget, M.-P., & Parsons, S. (2002). Model checking multi-agent
systems with MABLE. In Proceedings of the First International Joint Conference on
Autonomous Agents and Multi-Agent Systems (AAMAS), pp. 952959. ACM Press.
Zhang, Z., Thangarajah, J., & Padgham, L. (2009). Model based testing for agent systems.
In Filipe, J., Shishkov, B., Helfert, M., & Maciaszek, L. (Eds.), Software and Data
Technologies, Vol. 22 of Communications in Computer and Information Science, pp.
399413, Berlin/Heidelberg. Springer.
Zhu, H., Hall, P. A. V., & May, J. H. R. (1997). Software unit test coverage and adequacy.
ACM Computing Surveys, 29 (4), 366427.

131

fi