Journal of Artificial Intelligence Research 35 (2009) 593621

Submitted 02/09; published 07/09

Bounds Arc Consistency for Weighted CSPs
Matthias Zytnicki

Matthias.Zytnicki@versailles.inra.fr
INRA, Unite de Recherche en Genomique et Informatique
UR 1164, Versailles, France

Christine Gaspin
Simon de Givry
Thomas Schiex

Christine.Gaspin@toulouse.inra.fr
Simon.DeGivry@toulouse.inra.fr
Thomas.Schiex@toulouse.inra.fr

INRA, Unite de Biometrie et Intelligence Artificielle
UR 875, Toulouse, France

Abstract
The Weighted Constraint Satisfaction Problem (WCSP) framework allows representing
and solving problems involving both hard constraints and cost functions. It has been applied to various problems, including resource allocation, bioinformatics, scheduling, etc. To
solve such problems, solvers usually rely on branch-and-bound algorithms equipped with
local consistency filtering, mostly soft arc consistency. However, these techniques are not
well suited to solve problems with very large domains. Motivated by the resolution of an
RNA gene localization problem inside large genomic sequences, and in the spirit of bounds
consistency for large domains in crisp CSPs, we introduce soft bounds arc consistency, a
new weighted local consistency specifically designed for WCSP with very large domains.
Compared to soft arc consistency, BAC provides significantly improved time and space
asymptotic complexity. In this paper, we show how the semantics of cost functions can
be exploited to further improve the time complexity of BAC. We also compare both in
theory and in practice the efficiency of BAC on a WCSP with bounds consistency enforced
on a crisp CSP using cost variables. On two different real problems modeled as WCSP,
including our RNA gene localization problem, we observe that maintaining bounds arc consistency outperforms arc consistency and also improves over bounds consistency enforced
on a constraint model with cost variables.

1. Introduction
The Weighted Constraint Satisfaction Problem (WCSP) is an extension of the crisp Constraint Satisfaction Problem (CSP) that allows the direct representation of hard constraints
and cost functions. The WCSP defines a simple optimization (minimization) framework
with a wide range of applications in resource allocation, scheduling, bioinformatics (Sanchez,
de Givry, & Schiex, 2008; Zytnicki, Gaspin, & Schiex, 2008), electronic markets (Sandholm,
1999), etc. It also captures fundamental AI and statistical problems such as Maximum
Probability Explanation in Bayesian nets and Markov Random Fields (Chellappa & Jain,
1993).
As in crisp CSP, the two main approaches to solve WCSP are inference and search.
This last approach is usually embodied in a branch-and-bound algorithm. This algorithm
estimates at each node of the search tree a lower bound of the cost of the solutions of the
sub-tree.
c
2009
AI Access Foundation. All rights reserved.

fiZytnicki, Gaspin, de Givry & Schiex

One of the most successful approaches to build lower bounds has been obtained by
extending the notion of local consistency to WCSP (Meseguer, Rossi, & Schiex, 2006).
This includes soft AC (Schiex, 2000), AC* (Larrosa, 2002), FDAC* (Larrosa & Schiex,
2004), EDAC* (Heras, Larrosa, de Givry, & Zytnicki, 2005), OSAC (Cooper, de Givry,
& Schiex, 2007) and VAC (Cooper, de Givry, Sanchez, Schiex, & Zytnicki, 2008) among
others. Unfortunately, the worst case time complexity bounds of the associated enforcing
algorithms are at least cubic in the domain size and use an amount of space which is at
least linear in the domain size. This makes these consistencies useless for problems with
very large domains.
The motivation for designing a local consistency which can be enforced efficiently on
problems with large domains follows from our interest in the RNA gene localization problem. Initially modeled as a crisp CSP, this problem has been tackled using bounds consistency (Choi, Harvey, Lee, & Stuckey, 2006; Lhomme, 1993) and dedicated propagators
using efficient pattern matching algorithms (Thebault, de Givry, Schiex, & Gaspin, 2006).
The domain sizes are related to the size of the genomic sequences considered and can reach
hundreds of millions of values. In order to enhance this tool with scoring capabilities and
improved quality of localization, a shift from crisp to weighted CSP is a natural step which
requires the extension of bounds consistency to WCSP. Beyond this direct motivation, this
extension is also useful in other domains where large domains occur naturally such as temporal reasoning or scheduling.
The local consistencies we define combine the principles of bounds consistency with the
principles of soft local consistencies. These definitions are general and are not restricted
to binary cost functions. The corresponding enforcing algorithms improve over the time
and space complexity of AC* by a factor of d and also have the nice but rare property, for
WCSP local consistencies, of being confluent.
As it has been done for AC-5 by Van Hentenryck, Deville, and Teng (1992) for functional
or monotonic constraints, we show that different forms of cost functions (largely captured
by the notion of semi-convex cost functions) can be processed more efficiently. We also
show that the most powerful of these bounds arc consistencies is strictly stronger than the
application of bounds consistency to the reified representation of the WCSP as proposed
by Petit, Regin, and Bessiere (2000).
To conclude, we experimentally compare the efficiency of algorithms that maintain these
different local consistencies inside branch-and-bound on agile satellite scheduling problems (Verfaillie & Lematre, 2001) and RNA gene localization problems (Zytnicki et al.,
2008) and observe clear speedups compared to different existing local consistencies.

2. Definitions and Notations
This section will introduce the main notions that will be used throughout the paper. We
will define the (Weighted) Constraint Satisfaction Problems, as well as a local consistency
property frequently used for solving the Weighted Constraint Satisfaction Problem: arc
consistency (AC*).
594

fiBounds Arc Consistency for Weighted CSPs

2.1 Constraint Networks
Classic and weighted constraint networks share finite domain variables as one of their components. In this paper, the domain of a variable xi is denoted by D(xi ). To denote a value in
D(xi ), we use an index i as in vi , vi ,. . . For each variable xi , we assume that the domain of xi
is totally ordered by i and we denote by inf(xi ) and sup(xi ) the minimum (resp. maximum)
values of the domain D(xi ). An assignment tS of a set of variables S = {xi1 , . . . , xir } is a
function that maps variables to elements of their domains: tS = (xi1  vi1 , . . . , xir  vir )
with i  {i1 , . . . , ir }, tS (xi ) = vi  D(xi ). For a given assignment tS such that xi  S, we
simply say that a value vi  D(xi ) belongs to tS to mean that tS (xi ) = vi . We denote by
S , the set of all possible assignments on S.
Definition 2.1 A constraint network (CN) is a tuple P = hX , D, Ci, where X = {x1 , . . . , xn }
is a set of variables and D = {D(x1 ), . . . , D(xn )} is the set of the finite domains of each
variable. C is a set of constraints. A constraint cS  C defines the set of all authorized
combinations of values for the variables in S as a subset of S . S is called the scope of cS .
|S| is called the arity of cS . For simplicity, unary (arity 1) and binary (arity 2) constraints
may be denoted by ci and cij instead of c{xi } and c{xi ,xj } respectively. We denote by d the
maximum domain size, n, the number of variables in the network and e, the number of
constraints. The central problem on constraint networks is to find a solution, defined as
an assignment tX of all variables such that for any constraint cS  C, the restriction of tX
to S is authorized by cS (all constraints are satisfied). This is the Constraint Satisfaction
Problem (CSP).
Definition 2.2 Two CNs with the same variables are equivalent if they have the same set
of solutions.
A CN will be said to be empty if one of its variables has an empty domain. This
may happen following local consistency enforcement. For CN with large domains, the use
of bounds consistency is the most usual approach. Historically, different variants of bounds
consistency have been introduced, generating some confusion. Using the terminology introduced by Choi et al. (2006), the bounds consistency considered in this paper is the
bounds(D) consistency. Because we only consider large domains defining intervals, this is
actually equivalent to bounds(Z) consistency. For simplicity, in the rest of the paper we
denote this as bounds consistency.
Definition 2.3 (Bounds consistency) A variable xi is bounds consistent iff every constraint cS  C such that xi  S contains a pair of assignments (t, t )  S  S such that
inf(xi )  t and sup(xi )  t . In this case, t and t are called the supports of the two bounds
of xi s domain.
A CN is bounds consistent iff all its variables are bounds consistent.
To enforce bounds consistency on a given CN, any domain bound that does not satisfy
the above properties is deleted until a fixed point is reached.
595

fiZytnicki, Gaspin, de Givry & Schiex

2.2 Weighted Constraint Networks
Weighted constraint networks are obtained by using cost functions (also referred as soft
constraints) instead of constraints.
Definition 2.4 A weighted constraint network (WCN) is a tuple P = hX , D, W, ki, where
X = {x1 , . . . , xn } is a set of variables and D = {D(x1 ), . . . , D(xn )} is the set of the finite
domains of each variable. W is a set of cost functions. A cost function wS  W associates
an integer cost wS (tS )  [0, k] to every assignment tS of the variables in S. The positive
number k defines a maximum (intolerable) cost.
The cost k, which may be finite or infinite, is the cost associated with forbidden assignments. This cost is used to represent hard constraints. Unary and binary cost functions
may be denoted by wi and wij instead of w{xi } and w{xi ,xj } respectively. As usually for
WCNs, we assume the existence of a zero-arity cost function, w  [0, k], a constant cost
whose initial value is usually equal to 0. The cost of an assignment tX of all variables is
obtained by combining the costs of all the cost functions wS  W applied to the restriction
of tX to S. The combination is done using the function  defined as a  b = min(k, a + b).
Definition 2.5 A solution of a WCN is an assignment tX of all variables whose cost is
less than k. It is optimal if no other assignment of X has a strictly lower cost.
The central problem in WCN is to find an optimal solution.
Definition 2.6 Two WCNs with the same variables are equivalent if they give the same
cost to any assignments of all their variables.
Initially introduced by Schiex (2000), the extension of arc consistency to WCSP has
been refined by Larrosa (2002) leading to the definition of AC*. It can be decomposed into
two sub-properties: node and arc consistency itself.
Definition 2.7 (Larrosa, 2002) A variable xi is node consistent iff:
 vi  D(xi ), w  wi (vi ) < k.
 vi  D(xi ) such that wi (vi ) = 0. The value vi is called the unary support of xi .
A WCN is node consistent iff every variable is node consistent.
To enforce NC on a WCN, values that violate the first property are simply deleted.
Value deletion alone is not capable of enforcing the second property. As shown by Cooper
and Schiex (2004), the fundamental mechanism required here is the ability to move costs
between different scopes. A cost b can be subtracted from a greater cost a by the function
 defined by a  b = (a  b) if a 6= k and k otherwise. Using , a unary support for a
variable xi can be created by subtracting the smallest unary cost minvi D(xi ) wi (vi ) from
all wi (vi ) and adding it (using ) to w. This operation that shifts costs from variables
to w, creating a unary support, is called a projection from wi to w. Because  and 
cancel out, defining a fair valuation structure (Cooper & Schiex, 2004), the obtained WCN
is equivalent to the original one. This equivalence preserving transformation (Cooper and
Schiex) is more precisely described as the ProjectUnary() function in Algorithm 1.
We are now able to define arc and AC* consistency on WCN.
596

fiBounds Arc Consistency for Weighted CSPs

Algorithm 1: Projections at unary and binary levels
1
2
3
4
5
6
7
8
9
10

Procedure ProjectUnary(xi )
min  minvi D(xi ) {wi (vi )} ;
if (min = 0) then return;
foreach vi  D(xi ) do wi (vi )  wi (vi )  min ;
w  w  min ;

[ Find the unary support of xi ]

Procedure Project(xi , vi , xj )
[ Find the support of vi w.r.t. wij ]
min  minvj D(xj ) {wij (vi , vj )} ;
if (min = 0) then return;
foreach vj  D(xj ) do wij (vi , vj )  wij (vi , vj )  min ;
wi (vi )  wi (vi )  min ;

Definition 2.8 A variable xi is arc consistent iff for every cost function wS  W such that
xi  S, and for every value vi  D(xi ), there exists an assignment t  S such that vi  t
and wS (t) = 0. The assignment t is called the support of vi on wS . A WCN is AC* iff
every variable is arc and node consistent.
To enforce arc consistency, a support for a given value vi of xi on a cost function wS
can be created by subtracting (using ) the cost mintS ,vi t wS (t) from the costs of all
assignments containing vi in S and adding it to wi (vi ). These cost movements, applied
for all values vi of D(xi ), define the projection from wS to wi . Again, this transformation
preserves equivalence between problems. It is more precisely described (for simplicity, in
the case of binary cost functions) as the Project() function in Algorithm 1.

Example 2.9 Consider the WCN in Figure 1(a). It contains two variables (x1 and x2 ),
each with two possible values (a and b, represented by vertices). A unary cost function is
associated with each variable, the cost of a value being represented inside the corresponding
vertex. A binary cost function between the two variables is represented by weighted edges
connecting pairs of values. The absence of edge between two values represents a zero cost.
Assume k is equal to 4 and w is equal to 0.
Since the cost w1 (x1  a) is equal to k, the value a can be deleted from the domain
of x1 (by NC, first property). The resulting WCN is represented in Figure 1(b). Then,
since x2 has no unary support (second line of the definition of NC), we can project a cost
of 1 to w (cf. Figure 1(c)). The instance is now NC. To enforce AC*, we project 1 from
the binary cost function w12 to the value a of x1 since this value has no support on w12
(cf. Figure 1(d)). Finally, we project 1 from w1 to w, as seen on Figure 1(e). Ultimately,
we note that the value b of x2 has no support. To enforce AC*, we project a binary cost
of 1 to this value and remove it since it has a unary cost of 2 which, combined with w
reaches k = 4.

597

fiZytnicki, Gaspin, de Givry & Schiex

w = 0, k = 4
x1
x2

w = 0, k = 4
x2
x1
a

1

4

a

1

a

1

0

2

b

2

b

a
1

0

2

2

b

b

0

a

a

1

b

b

0

1

0

x1

0

a

a

1

b

b

(e) find unary support using
ProjectUnary(x1 )

(d) find support for (x1 
b) using Project(x1 , b, x2 )
(AC*)

0

a

2

1

b

(c) find unary support using
ProjectUnary(x2 ) (NC*)

w = 2, k = 4
x2
x1

w = 1, k = 4
x1
x2

1

a
1

(b) prune forbidden values
(NC*)

(a) original instance

b

a

1

1

b

w = 1, k = 4
x2
x1

w = 2, k = 4
x2
0

0

a
b

(f) Arc consistency enforced

Figure 1: Enforcing Arc Consistency.

3. Bounds Arc Consistency (BAC)
In crisp CSP, the bounds consistency enforcing process just deletes bounds that are not
supported in one constraint. In weighted CSP, enforcement is more complex. If a similar
value deletion process exists based on the first node consistency property violation (whenever
w  wi (vi ) reaches k), additional cost movements are performed to enforce node and arc
consistency.
As shown for AC*, these projections require the ability to represent an arbitrary unary
cost function wi for every variable xi . This requires space in O(d) in general since projections
can lead to arbitrary changes in the original wi cost function (even if they have an efficient
internal representation). To prevent this, we therefore avoid to move cost from cost functions
with arity greater than one to unary constraints. Instead of such projections, we only keep
a value deletion mechanism applied to the bounds of the current domain that takes into
account all the cost functions involving the variable considered. For a given variable xi
involved in a cost function wS , the choice of a given value vi will at least induce a cost
increase of mintS S ,vi tS wS (tS ). If these minimum costs, combined on all the cost functions
involving xi , together with w, reach the intolerable cost of k, then the value can be deleted.
As in bounds consistency, this is just done for the two bounds of the domain. This leads to
the following definition of BAC (bounds arc consistency) in WCSP:
Definition 3.1 In a WCN P = hX , D, W, ki, a variable xi is bounds arc consistent iff:


X
wS (tS ) < k
w 
min
tS S ,inf(xi )tS

wS W,xi S

w 

X

wS W,xi S



min

tS S ,sup(xi )tS


wS (tS ) < k

A WCN is bounds arc consistent if every variable is bounds arc consistent.
598

fiBounds Arc Consistency for Weighted CSPs

One can note that this definition is a proper generalization of bounds consistency since
when k = 1, it is actually equivalent to the definition of bounds(D) consistency for crisp
CSP (Choi et al., 2006) (also equivalent to bounds(Z) consistency since domains are defined
as intervals).
The algorithm enforcing BAC is described as Algorithm 2. Because enforcing BAC only
uses value deletion, it is very similar in structure to bounds consistency enforcement. We
maintain a queue Q of variables whose domain has been modified (or is untested). For
better efficiency, we use extra data-structures to efficiently maintain the combined cost associated with the domain bound inf(xi ), denoted winf (xi ). For a cost function wS involving
xi , the contribution of wS to this combined cost is equal to mintS S ,inf(xi )tS wS (tS ). This
contribution is maintained in a data-structure inf (xi , wS ) and updated whenever the minimum cost may change because of value removals. Notice that, in Algorithm 2, the line 14
is a concise way to denote the hidden loops which initialize the winf , wsup , inf and sup
data-structures to zero.
Domain pruning is achieved by function PruneInf() which also resets the data-structures
associated with the variable at line 35 and these data-structures are recomputed when the
variable is extracted from the queue. Indeed, inside the loop of line 20, the contributions
inf (xi , wS ) to the cost winf (xi ) from the cost functions wS involving xj are reset. The
Function pop removes an element from the queue and returns it.
Proposition 3.2 (Time and space complexity) For a WCN with maximum arity r of
the constraints, enforcing BAC with Algorithm 2 is time O(er2 dr ) and space O(n + er).
Proof: Regarding time, every variable can be pushed into Q at most d + 1 times: once
at the beginning, and when one of its values has been removed. As a consequence, the
foreach loop on line 18 iterates O(erd) times, and the foreach loop on line 20 iterates
O(er2 d) times. The min computation on line 22 takes time O(dr1 ) and thus, the overall
time spent at this line takes time O(er2 dr ). PruneInf() is called at most O(er2 d) times.
The condition on line 32 is true at most O(nd) times and so, line 35 takes time O(ed)
(resetting inf (xi , ) on line 35 hides a loop on all cost functions involving xi ). The total
time complexity is thus O(er2 dr ).
Regarding space, we only used winf , wsup and  data-structures. The space complexity
is thus O(n + er).

Note that exploiting the information of last supports as in AC2001 (Bessiere & Regin,
2001) does not reduce the worst-case time complexity because the minimum cost of a cost
function must be recomputed from scratch each time a domain has been reduced and the
last support has been lost (Larrosa, 2002). However, using last supports helps in practice
to reduce mean computation time and this has been done in our implementation.
Compared to AC*, which can be enforced in O(n2 d3 ) time and O(ed) space for binary
WCN, BAC can be enforced d times faster, and the space complexity becomes independent
of d which is a requirement for problems with very large domains.
Another interesting difference with AC* is that BAC is confluent  just as bounds
consistency is. Considering AC*, it is known that there may exist several different AC*
closures with possibly different associated lower bounds w (Cooper & Schiex, 2004). Note
that although OSAC (Cooper et al., 2007) is able to find an optimal w (at much higher
599

fiZytnicki, Gaspin, de Givry & Schiex

Algorithm 2: Algorithm enforcing BAC.
11
12
14
15
16
18
20
22
23
24
25
26
27
28
29

30
32
33
35
36
37
38
39
40
41
42
43

Procedure BAC(X , D, W, k)
QX ;
winf ()  0 ; wsup ()  0 ; inf (, )  0 ; sup (, )  0 ;
while (Q 6= ) do
xj  pop(Q) ;
foreach wS  W, xj  S do
foreach xi  S do
  mintS S ,inf(xi )tS wS (tS ) ;
winf (xi )  winf (xi )  inf (xi , wS )   ;
inf (xi , wS )   ;
if PruneInf(xi ) then Q  Q  {xi } ;
  mintS S ,sup(xi )tS wS (tS ) ;
wsup (xi )  wsup (xi )  sup (xi , wS )   ;
sup (xi , wS )   ;
if PruneSup(xi ) then Q  Q  {xi } ;
Function PruneInf(xi ) : boolean
if (w  winf (xi ) = k) then
delete inf(xi ) ;
winf (xi )  0 ; inf (xi , )  0 ;
return true;
else return false;
Function PruneSup(xi ) : boolean
if (w  wsup (xi ) = k) then
delete sup(xi ) ;
wsup (xi )  0 ; sup (xi , )  0 ;
return true;
else return false;

600

fiBounds Arc Consistency for Weighted CSPs

computational cost), it is still not confluent. The following property shows that BAC is
confluent.
Proposition 3.3 (Confluence) Enforcing BAC on a given problem always leads to a
unique WCN.
Proof: We will prove the proposition as follows. We will first define a set of problems
which contains all the problems that can be reached from the original WCN through BAC
enforcement. Notice that, at each step of BAC enforcement, in the general case, several
operations can be performed and no specific order is imposed. Therefore, a set of problems
can be reached at each step. We will show that the set of problems has a lattice structure
and ultimately show that the closure of BAC is the lower bound of this lattice, and is
therefore unique, which proves the property. This proof technique is usual for proving
convergence of the chaotic iteration of a collection of suitable functions and has been used
for characterizing CSP local consistency by Apt (1999).
During the enforcement of BAC, the original problem P = hX , D, W, ki is iteratively
transformed into a set of different problems which are all equivalent to P, and obtained
by deleting values violating BAC. Because these problems are obtained by value removals,
they belong to the set 1 (P ) defined by: {hX , D , W, ki : D  D}.
We now define a relation, denoted , on the set 1 (P ):
(P1 , P2 )  21 (P), P1  P2  i  [1, n], D1 (xi )  D2 (xi )
It is easy to see that this relation defines a partial order. Furthermore, each pair of
elements has a greatest lower bound glb and a least upper bound lub in 1 (P), defined by:
(P1 , P2 )  21 (P),
glb(P1 , P2 ) = hX , {D1 (xi )  D2 (xi ) : i  [1, n]}, W, ki  1 (P)
lub(P1 , P2 ) = hX , {D1 (xi )  D2 (xi ) : i  [1, n]}, W, ki  1 (P)
h1 (P), i is thus a complete lattice.
BAC filtering works by removing values violating the BAC properties, transforming
an original problem into a succession of equivalent problems. Each transformation can be
described by the application of dedicated functions from 1 (P) to 1 (P). More precisely,
there are two such functions for each variable, one for the minimum bound inf(xi ) of the
domain of xi and a symmetrical one for the maximum bound. For inf(xi ), the associated
function keeps the instance unchanged if inf(xi ) satisfies the condition of Definition 3.1 and
it otherwise returns a WCN where inf(xi ) alone has been deleted. The collection of all those
functions defines a set of functions from 1 (P ) to 1 (P ) which we denote by FBAC .
Obviously, every function f  FBAC is order preserving:
(P1 , P2 )  21 (P), P1  P2  f (P1 )  f (P2 )
By application of the Tarski-Knaster theorem (Tarski, 1955), it is known that every
function f  FBAC (applied until quiescence during BAC enforcement) has at least one
fixpoint, and that the set of these fixed points forms a lattice for . Moreover, the intersection of the lattices of fixed points of the functions f  FBAC , denoted by 1 (P), is also
601

fiZytnicki, Gaspin, de Givry & Schiex

a lattice. 1 (P) is not empty since the problem hX , {, . . . , }, Wi is a fixpoint for every
filtering function in FBAC . 1 (P) is exactly the set of fixed points of FBAC .
We now show that, if the algorithm reaches a fixpoint, it reaches the greatest element
of 1 (P). We will prove by induction that any successive application of elements of FBAC
on P yields problems which are greater than any element of 1 (P) for the order . Let
us consider any fixpoint P  of 1 (P). Initially, the algorithm applies on P, which is the
greatest element of 1 (P), and thus P   P. This is the base case of the induction. Let
us now consider any problem P1 obtained during the execution of the algorithm. We have,
by induction, P   P1 . Since  is order preserving, we know that, for any function f of
FBAC , f (P  ) = P   f (P1 ). This therefore proves the induction.
To conclude, if the algorithm terminates, then it gives the maximum element of 1 (P).
Since proposition 3.2 showed that the algorithm actually terminates, we can conclude that
it is confluent.

If enforcing BAC may reduce domains, it never increases the lower bound w. This is an
important limitation given that each increase in w may generate further value deletions and
possibly, failure detection. Note that even when a cost function becomes totally assigned,
the cost of the corresponding assignment is not projected to w by BAC enforcement. This
can be simply done by maintaining a form of backward checking as in the most simple
WCSP branch-and-bound algorithm (Freuder & Wallace, 1992). To go beyond this simple
approach, we consider the combination of BAC with another WCSP local consistency which,
similarly to AC*, requires cost movements to be enforced but which avoids the modification
of unary cost functions to keep a reasonable space complexity. This is achieved by directly
moving costs to w.

4. Enhancing BAC
In many cases, BAC may be very weak compared to AC* in situations where it seems to
be possible to infer a decent w value. Consider for example the following cost function:

D(x1 )  D(x2 ) 
E
D(x1 ) = D(x2 ) = [1, 10]
w12 :
(v1 , v2 )
7 v1 + v2
AC* can increase w by 2, by projecting a cost of 2 from w12 to the unary constraint w1
on every value, and then projecting these costs from w1 to w by enforcing NC. However,
if w = w1 = w2 = 0 and k is strictly greater than 11, BAC remains idle here. We can
however simply improve BAC by directly taking into account the minimum possible cost of
the cost function w12 over all possible assignments given the current domains.
Definition 4.1 A cost function wS is -inverse consistent (-IC) iff:
tS  S , wS (tS ) = 0
Such a tuple tS is called a support for wS . A WCN is -IC iff every cost function (except
w) is -IC.
Enforcing -IC can always be done as follows: for every cost function wS with a non
empty scope, the minimum cost assignment of wS given the current variable domains is
602

fiBounds Arc Consistency for Weighted CSPs

computed. The cost  of this assignment is then subtracted from all the tuple costs in wS
and added to w. This creates at least one support in wS and makes the cost function
-IC. For a given cost function wS , this is done by the Project() function of Algorithm 3.
In order to strengthen BAC, a natural idea is to combine it with -IC. We will call BAC
the resulting combination of BAC and -IC. To enforce BAC, the previous algorithm
is modified by first adding a call to the Project() function (see line 53 of Algorithm 3).
Moreover, to maintain BAC whenever w is modified by projection, every variable is tested
for possible pruning at line 66 and put back in Q in case of domain change. Note that
the subtraction applied to all constraint tuples at line 75 can be done in constant time
without modifying the constraint by using an additional wS data-structure, similar to
the  data-structure introduced by Cooper and Schiex (2004). This data-structure keeps
track of the cost which has been projected from wS to w. This feature makes it possible
to leave the original costs unchanged during the enforcement of the local consistency. For
example, for any tS  S , wS (t) refers to wS (t)  wS , where wS (t) denotes the original
cost. Note that wS , which will be later used in a confluence proof, precisely contains the
amount of cost which has been moved from wS to w. The whole algorithm is described
in Algorithm 3. We highlighted in black the parts which are different from Algorithm 2
whereas the unchanged parts are in gray.
Proposition 4.2 (Time and space complexity) For a WCN with maximum arity r of
the constraints, enforcing BAC with Algorithm 3 can be enforced in O(n2 r2 dr+1 ) time
using O(n + er) memory space.
Proof: Every variable is pushed at most O(d) times in Q, thus the foreach at line 51
(resp. line 55) loops at most O(erd) (resp. O(er2 d)) times. The projection on line 53 takes
O(dr ) time. The operation at line 57 can be carried out in O(dr1 ) time. The overall time
spent inside the if of the PruneInf() function is bounded by O(ed). Thus the overall time
spent in the loop at line 51 (resp. line 55) is bounded by O(er2 dr+1 ) (resp. O(er2 dr )).
The flag on line 66 is true when w increases, and so it cannot be true more than k times
(assuming integer costs). If the flag is true, then we spend O(n) time to check all the bounds
of the variables. Thus, the time complexity under the if is bounded by O(min{k, nd}  n).
To sum up, the overall time complexity is O(er2 dr+1 + min{k, nd}  n), which is bounded
by O(n2 r2 dr+1 ).
The space complexity is given by the , winf , wsup and wS data-structures which sums
up to O(n + re) for a WCN with an arity bounded by r.

The time complexity of the algorithm enforcing BAC is multiplied by d compared
to BAC without -IC. This is a usual trade-off between the strength of a local property
and the time spent to enforce it. However, the space complexity is still independent of d.
Moreover, like BAC, BAC is confluent.
Proposition 4.3 (Confluence) Enforcing BAC on a given problem always leads to a
unique WCN.
Proof: The proof is similar to the proof of Proposition 3.3. However, because of the
possible cost movements induced by projections, BAC transforms the original problem P
in more complex ways, allowing either pruning domains (BAC) or moving costs from cost
603

fiZytnicki, Gaspin, de Givry & Schiex

Algorithm 3: Algorithm enforcing BAC
44
45
46
47
48
49
51
53
55
57
58
59
60
61
62
63
64
66
67
68
69

70
71
72
73
75
76
77

Procedure BAC(X , D, W, k)
QX ;
winf ()  0 ; wsup ()  0 ; inf (, )  0 ; sup (, )  0 ;
while (Q 6= ) do
xj  pop(Q) ;
flag  false ;
foreach wS  W, xj  S do
if Project(wS ) then flag  true ;
foreach xi  S do
  mintS S ,inf(xi )tS wS (tS ) ;
winf (xi )  winf (xi )  inf (xi , wS )   ;
inf (xi , wS )   ;
if PruneInf(xi ) then Q  Q  {xi } ;
  mintS S ,sup(xi )tS wS (tS ) ;
wsup (xi )  wsup (xi )  sup (xi , wS )   ;
sup (xi , wS )   ;
if PruneSup(xi ) then Q  Q  {xi } ;
if (flag) then
foreach xi  X do
if PruneInf(xi ) then Q  Q  {xi } ;
if PruneSup(xi ) then Q  Q  {xi } ;
Function Project(wS ) : boolean
  mintS S wS (tS ) ;
if ( > 0) then
w  w   ;
wS ()  wS ()   ;
return true;
else return false;

604

fiBounds Arc Consistency for Weighted CSPs

functions to w. The set of problems that will be considered needs therefore to take this
into account. Instead of being just defined by its domains, a WCN reached by BAC is
also characterized by the amount of cost that has been moved from each cost function wS
to w. This quantity is already denoted by wS in Section 4, on page 603. We therefore
consider the set 2 (P) defined by:

	
(hX , D , W, ki, {w : w  W}) : i  [1, n], D (xi )  D(xi ), w  W, w  [0, k]
We can now define the relation  on 2 (P):

w
P1  P2  ((w  W, w
1  2 )  (xi  X , D1 (xi )  D2 (xi )))

This relation is reflexive, transitive and antisymmetric. The first two properties can be
easily verified. Suppose now that (P1 , P2 )  22 (P) and that (P1  P2 )  (P2  P1 ). We
have thus (w  W, w = w )(xi  X , D(xi ) = D (xi )). This ensures that the domains,
as well as the amounts of cost projected by each cost function, are the same. Thus, the
problems are the same and  is antisymmetric.
Besides, h2 (P), i is a complete lattice, since:
(P1 , P2 )  22 (P),
w
glb(P1 , P2 ) = (hX , {D1 (xi )  D2 (xi ) : i  [1, n]}, W, ki, {max{w
1 , 2 } : w  W})
w
lub(P1 , P2 ) = (hX , {D1 (xi )  D2 (xi ) : i  [1, n]}, W, ki, {min{w
1 , 2 } : w  W})

and both of them are in 2 (P).
Every enforcement of BAC follows from the application of functions from a set of functions FBAC  which may remove the maximum or minimum domain bound (same definition
as for BAC) or may project cost from cost functions to w. For a given cost function
w  W, such a function keeps the instance unchanged if the minimum  of w is 0 over
possible tuples. Otherwise, if  > 0, the problem returned is derived from P by projecting
an amount of cost  from w to w. These functions are easily shown to be order preserving
for .
As in the proof of Proposition 3.3, we can define the lattice 2 (P), which is the intersection of the sets of fixed points of the functions f  FBAC  . 2 (P) is not empty, since
(hX , {, . . . , }, W, ki, {k, . . . , k}) is in it. As in the proof of proposition 3.3, and since Algorithm 3 terminates, we can conclude that this algorithm is confluent, and that it results
in lub(2 (P)).


5. Exploiting Cost Function Semantics in BAC
In crisp AC, several classes of binary constraints make it possible to enforce AC significantly
faster (in O(ed) instead of O(ed2 ), as shown by Van Hentenryck et al., 1992). Similarly,
it is possible to exploit the semantics of the cost functions to improve the time complexity
of BAC enforcement. As the proof of Proposition 4.2 shows, the dominating factors in
this complexity comes from the complexity of computing the minimum of cost functions
during projection at lines 53 and 57 of Algorithm 3. Therefore, any cost function property
605

fiZytnicki, Gaspin, de Givry & Schiex

that makes these computations less costly may lead to an improvement of the overall time
complexity.
Proposition 5.1 In a binary WCN, if for any cost function wij  W and for any subintervals Ei  D(xi ), Ej  D(xj ), the minimum of wij over Ei  Ej can be found in time
O(d), then the time complexity of enforcing BAC is O(n2 d2 ).
Proof: This follows directly from the proof of Proposition 4.2. In this case, the complexity
of projection at line 53 is only in O(d) instead of O(d2 ). Thus the overall time spent in the
loop at line 51 is bounded by O(ed2 ) and the overall complexity is O(ed2 + n2 d)  O(n2 d2 ).

Proposition 5.2 In a binary WCN, if for any cost function wij  W and for any subintervals Ei  D(xi ), Ej  D(xj ), the minimum of wij over Ei  Ej can be found in
constant time, then the time complexity of enforcing BAC is O(n2 d).
Proof: This follows again from the proof of Proposition 4.2. In this case, the complexity
of projection at line 53 is only in O(1) instead of O(d2 ). Moreover, the operation at line 57
can be carried out in time O(1) instead of O(d). Thus, the overall time spent in the loop
at line 51 is bounded by O(ed) and the overall complexity is O(ed + n2 d) = O(n2 d).

These two properties are quite straightforward and one may wonder if they have non
trivial usage. They can actually be directly exploited to generalize the results presented
by Van Hentenryck et al. (1992) for functional, anti-functional and monotonic constraints.
In the following sections, we show that functional, anti-functional and semi-convex cost functions (which include monotonic cost functions) can indeed benefit from an O(d) speedup
factor by application of Proposition 5.1. For monotonic cost functions and more generally
any convex cost function, a stronger speedup factor of O(d2 ) can be obtained by Proposition 5.2.
5.1 Functional Cost Functions
The notion of functional constraint can be extended to cost functions as follows:
Definition 5.3 A cost function wij is functional w.r.t. xi iff:
 (vi , vj )  D(xi )  D(xj ), wij (vi , vj )  {0, } with   [1, k]
 vi  D(xi ), there is at most one value vj  D(xj ) such that wij (vi , vj ) = 0. When it
exists, this value is called the functional support of vi .
We assume in the rest of the paper that the functional
support can be computed in constant
(
0 if xi = xj
= =
time. For example, the cost function wij
is functional. In this case, the
1 otherwise
functional support of vi is itself. Note that for k = 1, functional cost functions represent
functional constraints.
Proposition 5.4 The minimum of a functional cost function wij w.r.t. xi can always be
found in O(d).
606

fiBounds Arc Consistency for Weighted CSPs

Proof: For every value vi of xi , one can just check if the functional support of vi belongs
to the domain of xj . This requires O(d) checks. If this is never the case, then the minimum
of the cost function is known to be . Otherwise, it is 0. The result follows.

5.2 Anti-Functional and Semi-Convex Cost Functions
Definition 5.5 A cost function wij is anti-functional w.r.t. the variable xi iff:
 (vi , vj )  D(xi )  D(xj ), wij (vi , vj )  {0, } with   [1, k]
 vi  D(xi ), there is at most one value vj  D(xj ) such that wij (vi , vj ) = . When it
exists, this value is called the anti-support of vi .
(
0 if xi 6= xj
6=
The cost function wij =
is an example of an anti-functional cost function.
1 otherwise
In this case, the anti-support of vi is itself. Note that for k = 1, anti-functional cost functions
represent anti-functional constraints.
Anti-functional cost functions are actually a specific case of semi-convex cost functions,
a class of cost functions that appear for example in temporal constraint networks with
preferences (Khatib, Morris, Morris, & Rossi, 2001).
Definition 5.6 Assume that the domain D(xj ) is contained in a set Dj totally ordered by
the order <j .
A function wij is semi-convex w.r.t. xi iff   [0, k], vi  Di , the set {vj  Dj :
wij (vi , vj )  }, called the -support of vi , defines an interval over Dj according to <j .
Semi-convexity relies on the definition of intervals defined in a totally ordered discrete
set denoted Dj , and ordered by <j . Even if they may be identical, it is important to avoid
confusion between the order j over D(xj ), used to define interval domains for bounds
arc consistency, and the order <j over Dj used to define intervals for semi-convexity. In
order to guarantee constant time access to the minimum and maximum elements of D(xj )
according to <j (called the <j -bounds of the domain), we assume that <j =j or <j =j 1 .
In this case, the <j -bounds and the domain bounds are identical.
One can simply check that anti-functional cost functions are indeed semi-convex: in
this case, the -support of any value is either the whole domain ( = 0), reduced to one
point (0 <   ) or to the empty set (otherwise). Another example is the cost function
wij = x2i  x2j which is semi-convex w.r.t. xi .
Proposition 5.7 The minimum of a cost function wij which is semi-convex w.r.t. one of
its variables can always be found in O(d).
Proof: We will first show that, if wij is semi-convex w.r.t. to one of its variables (let
say xi ), then for any value vi of xi , the cost function wij must be minimum at one of the
<j -bounds of Dj .
1. This restriction could be removed using for example a doubly-linked list data-structure over the values
in D(xj ), keeping the domain sorted according to <j and allowing constant time access and deletion but
this would be at the cost of linear space which we cannot afford in the context of BAC.

607

fiZytnicki, Gaspin, de Givry & Schiex

Assume xi is set to vi . Let b be the lowest cost reached on either of the two <j -bounds
of the domain. Since wij is semi-convex, then {vj  Dj : wij (vi , vj )  b } is an interval,
and thus every cost wij (vi , vj ) is not less than b for every value of Dj . Therefore, at least
one of the two <j -bounds has a minimum cost.
In order to find the global minimum of wij , we can restrict ourselves to the <j -bounds
of the domain of xj for every value of xi . Therefore, only 2d costs need to be checked. 
From Proposition 5.1, we can conclude
Corollary 5.8 In a binary WCN, if all cost functions are functional, anti-functional or
semi-convex, the time complexity of enforcing BAC is O(n2 d2 ) only.
5.3 Monotonic and Convex Cost Functions
Definition 5.9 Assume that the domain D(xi ) (resp. D(xj )) is contained in a set Di (resp.
Dj ) totally ordered by the order <i (resp. <j ).
A cost function wij is monotonic iff:
(vi , vi , vj , vj )  Di2  Dj2 , vi i vi  vj j vj  wij (vi , vj )  wij (vi , vj )
(

0 if xi  xj
is an example of a monotonic cost function.
1 otherwise
Monotonic cost functions are actually instances of a larger class of functions called convex
functions.
The cost function


wij

=

Definition 5.10 A function wij is convex iff it is semi-convex w.r.t. each of its variables.
For example, wij = xi + xj is convex.
Proposition 5.11 The minimum of a convex cost function can always be found in constant
time.
Proof: Since the cost function is semi-convex w.r.t. each of its variable, we know from the
proof of Proposition 5.7 that it must reach a minimum cost on one of the <j -bounds of the
domain of xj and similarly for xi . There are therefore only four costs to check in order to
compute the minimum cost.

From Proposition 5.2, we conclude that
Corollary 5.12 In a binary WCN, if all cost functions are convex, then the time complexity
of enforcing BAC is O(n2 d) only.
One interesting example for a convex cost function is wij = max{xi  xj + cst, 0}. This
type of cost function, which can be efficiently filtered by BAC, may occur in temporal
reasoning problems and is also used in our RNA gene localization problem for specifying
preferred distances between elements of a gene.
608

fiBounds Arc Consistency for Weighted CSPs

6. Comparison with Crisp Bounds Consistency
Petit et al. (2000) have proposed to transform WCNs into crisp constraint networks with
extra cost variables. In this transformation, every cost function is reified into a constraint,
which applies on the original cost function scope augmented by one extra variable representing the assignment cost. This reification of costs into domain variables transforms a WCN
in a crisp CN with more variables and augmented arities. As proposed by Petit et al., it
can be achieved using meta-constraints, i.e. logical operators applied to constraints. Given
this relation between WCNs and crisp CNs and the relation between BAC and bounds
consistency, it is natural to wonder how BAC enforcing relates to just enforcing bounds
consistency on the reified version of a WCN.
In this section we show that BAC is in some precise sense stronger than enforcing
bounds consistency on the reified form. This is a natural consequence of the fact that the
domain filtering in BAC is based on the combined cost of several cost functions instead of
taking each constraint separately in bounds consistency. We first define the reification process precisely. We then show that BAC can be stronger than the reified bounds consistency
on one example and conclude by proving that it can never be weaker.
The following example introduces the cost reification process.
Example 6.1 Consider the WCN in Figure 2(a). It contains two variables x1 and x2 , one
binary cost function w12 , and two unary cost functions w1 and w2 . For the sake of clarity,
every variable or constraint in the reified hard model, described on Figure 2(b), will be
indexed by the letter R.
First of all, we model every cost function by a hard constraint, and express that assigning
b to x1 yields a cost of 1. We create a new variable x1 C
R , the cost variable of w1 , that stores
the cost of any assignment of x1 . Then, we replace the unary cost function w1 by a binary
constraint c1R that involves x1 and x1 C
R , such that if a value v1 is assigned to x1 , then
x1 C
should
take
the
value
w
(v
).
We
do the same for the unary cost function w2 . The
1
1
R
idea is the same for the binary cost function w12 : we create a new variable x12 C
R , and we
replace w12 by a ternary constraint c12R , that makes sure that for any assignment of x1
and x2 to v1 and v2 respectively, x12 C
R takes the value w12 (v1 , v2 ). Finally, a global cost
C
constraint cR that states that the sum of the cost variables should be less than k is added:
C
C
x1 C
R + x2 R + x12 R < k. This completes the description of the reified cost hard constraint
network.
We can now define more formally the reification process of a WCN.
Definition 6.2 Consider the WCN P = hX , D, W, ki. Let reify(P) = hXR , DR , WR i be
the crisp CN such that:
 the set XR contains one variable xi R for every variable xi  X , augmented with an
extra cost variable xS C
R per cost function wS  W  {w}.
 the domains DR are:
 DR (xiR ) = D(xi ) for the xiR variables, with domain bounds lbiR and ubiR ,
C
C
 [lbS C
R , ubS R ] = [0, k  1] for the xS R variables.

609

fiZytnicki, Gaspin, de Givry & Schiex

x2 C
R

x1 C
R
x2R

x1R

0

0
a

a

b

b

1

1

2

2

k=3
x1

x2

a

0

1

a

b

1

0

b

x12 C
R
0

1

2

cC
R

(a) a small cost function
network

(b) the reified constraint network

Figure 2: A small cost function network and its reified counterpart.
 the set WR of constraints contains:
 cS R = {(t, wS (t)) : t  S , w  wS (t) < k}, with scope S  {xS C
R }, for every cost
function wS  W,
P
C
 cC
wS W xS R < k), an extra constraint that makes sure
R is defined as (w 
that the sum of the cost variables is strictly less than k.
It is simple to check that the problem reify(P) has a solution iff P has a solution and
the sum of the cost variables in a solution is the cost of the corresponding solution (defined
by the values of the xiR variables) in the original WCN.
Definition 6.3 Let P be a problem,  and  two local consistency properties. Let (P)
be the problem obtained after filtering P by .  is said to be not weaker than  iff  (P)
emptiness implies (P) emptiness.
 is said to be stronger than  iff it is not weaker than  , and if there exists a problem
P such that  (P) is not empty but (P) is empty.
This definition is practically very significant since the emptiness of a filtered problem is
the event that generates backtracking in tree search algorithms used for solving CSP and
WCSP.
Example 6.4 Consider the WCN defined by three variables (x1 , x2 and x3 ) and two binary
cost functions (w12 and w13 ). D(x1 ) = {a, b, c, d}, D(x2 ) = D(x3 ) = {a, b, c} (we assume
that a  b  c  d). The costs of the binary cost functions are described in Figure 3.
Assume that k = 2 and w = 0.
One can check that the associated reified problem is already bounds consistent and
obviously not empty. For example, a support of the minimum bound of the domain of
x1 R w.r.t. c12 R is (a, a, 1), a support of its maximum bound is (d, a, 1). Supports of the
maximum and minimum bounds of the domain of x12 C
R w.r.t. c12R are (b, a, 0) and (a, a, 1)
respectively. Similarly, one can check that all other variable bounds are also supported on
all the constraints that involve them.
610

fiBounds Arc Consistency for Weighted CSPs

a
a 1
(x2 ) b 1
c 1

(x1 )
b c
0 2
0 2
0 2

a
a 1
(x3 ) b 1
c 1

d
1
1
1

(x1 )
b c
2 0
2 0
2 0

d
1
1
1

Figure 3: Two cost matrices.
However, the original problem is not BAC since for example, the value a, the minimum
bound of the domain of x1 , does not satisfy the BAC property:
w 

X

wS W,x1 S



min

tS S ,atS


wS (tS ) < k

This means that the value a can be deleted by BAC filtering. By symmetry, the same applies
to the maximum bound of x1 and ultimately, the problem inconsistency will be proved by
BAC. This shows that bounds consistency on the reified problem cannot be stronger than
BAC on the original problem.
We will now show that BAC is actually stronger than bounds consistency applied
on the reified WCN. Because BAC consistency implies non-emptiness (since it requires
the existence of assignments of cost 0 in every cost function) we will start from any BAC
consistent WCN P (therefore not empty) and prove that filtering the reified problem reify(P)
by bounds consistency does not lead to an empty problem.
Lemma 6.5 Let P be a BAC consistent binary WCN. Then filtering reify(P) by bounds
consistency does not produce an empty problem.
Proof: We will prove here that bounds consistency will just reduce the maximum bounds
of the domains of the cost variables xS C
R to a non empty set and leave all other domains
unchanged.
More precisely, the final domain of xS C
R will become [0, max{wS (t) : t  S , w wS (t) <
k}]. Note that this interval is not empty because the network is BAC consistent which
means that every cost function has an assignment of cost 0 (by -IC) and w < k (or else
the bounds of the domains could not have supports and the problem would not be BAC).
To prove that bounds consistency will not reduce the problem by more than this, we
simply prove that the problem defined by these domain reductions only is actually bounds
consistent.
All the bounds consistency required properties apply to the bounds of the domains of the
variables of reify(P). Let us consider every type of variable in this reified reduced problem:
 reified variables xiR . Without loss of generality, assume that the minimum bound lbiR
of xiR is not bounds consistent (the symmetrical reasoning applies to the maximum
bound). This means it would have no support with respect to a given reified constraint
611

fiZytnicki, Gaspin, de Givry & Schiex

cS R , xi  S. However, by BAC, we have
w 

min

tS ,lbiR t

wS (t) < k

and so t  S , lbiR  t,

wS (t)  max{wS (t) : t  S , w  wS (t) < k}

which means that lbi R is supported w.r.t. cS R .
 cost variables. The minimum bound of all cost variables are always bounds consistent
w.r.t. the global constraint cC
R because this constraint is a less than inequality.
Moreover, since the minimum bounds of the cost variables are set to 0, they are also
consistent w.r.t. the reified constraints, by the definition of -inverse consistency.
Consider the maximum bound ubS C
R of a cost variable in the reduced reified problem.
Remember it is defined as max{wS (t) : t  S , w wS (t) < k}, and so w ubS C
R < k.
The minimum bounds of all other cost variables in the reified problem, which are 0,
C
C
form a support of ubS C
R w.r.t. the global constraint cR . So ubS R cannot be removed
by bounds consistency.

We will now prove the final assertion:
Proposition 6.6 BAC is stronger than bounds consistency.
Proof: Lemma 6.5 shows that BAC is not weaker than bounds consistency. Then,
example 6.4 is an instance where BAC, and therefore BAC is actually stronger than
bounds consistency after reification.

A filtering related to BAC could be achieved in the reified approach by an extra shaving
process where each variable is assigned to one of its domain bounds and this bound is deleted
if an inconsistency is found after enforcing bounds consistency (Lhomme, 1993).

7. Other Related Works
The Definition 3.1 of BAC is closely related to the notion of arc consistency counts introduced by Freuder and Wallace (1992) for Max-CSP processing. The Max-CSP can be seen
as a very simplified form of WCN where cost functions only generate costs of 0 or 1 (when
the associated constraint is violated). Our definition of BAC can be seen as an extension of
AC counts allowing dealing with arbitrary cost functions, including the usage of w and k,
and applied only to domain bounds as in bounds consistency. The addition of -IC makes
BAC more powerful.
Dealing with large domains in Max-CSP has also been considered in the Range-Based
Algorithm, again designed for Max-CSP by Petit, Regin, and Bessiere (2002). This algorithm uses reversible directed arc consistency (DAC) counts and exploits the fact that
in Max-CSP, several successive values in a domain may have the same DAC counts. The
algorithm intimately relies on the fact that the problem is a Max-CSP problem, defined
by a set of constraints and actively uses bounds consistency dedicated propagators for the
constraints in the Max-CSP. In this case the number of different values reachable by the
DAC counters of a variable is bounded by the degree of the variable, which can be much
612

fiBounds Arc Consistency for Weighted CSPs

smaller than the domain size. Handling intervals of values with a same DAC cost as one
value allows space and time savings. For arbitrary binary cost functions, the translation
into constraints could generate up to d2 constraints for a single cost function and makes the
scheme totally impractical.
Several alternative definition of bounds consistency exist in crisp CSPs (Choi et al.,
2006). Our extension to WCSP is based on bounds(D) or bounds(Z) consistencies (which
are equivalent on intervals). For numerical domains, another possible weaker definition
of bounds consistency is bounds(R) consistency, which is obtained by a relaxation to real
numbers. It has been shown by Choi et al. that bounds(R) consistency can be checked
in polynomial time on some constraints whereas bounds(D) or bounds(Z) is NP-hard (eg.
for linear equality). The use of this relaxed version in the WCSP context together with
intentional description of cost functions would have the side effect of extending the cost
domain from integer to real numbers. Because extensional or algorithmical description of
integer cost functions is more general and frequent in our problems, this possibility was
not considered. Since cost comparison is the fundamental mechanism used for pruning in
WCSP, a shift to real numbers for costs would require a safe floating number implementation
both in the local consistency enforcing algorithms and in the branch and bound algorithm.

8. Experimental Results
We experimented bounds arc consistency on two benchmarks translated into weighted CSPs.
The first benchmark is from AI planning and scheduling. It is a mission management
benchmark for agile satellites (Verfaillie & Lematre, 2001; de Givry & Jeannin, 2006). The
maximum domain size of the temporal variables is 201. This reasonable size and the fact
that there are only binary cost functions allows us to compare BAC with strong local
consistencies such as EDAC*. Additionally, this benchmark has also been modeled using
the reified version of WCN, thus allowing for an experimental counterpart of the theoretical
comparison of Section 6.
The second benchmark comes from bioinformatics and models the problem of the localization of non-coding RNA molecules in genomes (Thebault et al., 2006; Zytnicki et al.,
2008). Our aim here is mostly to confirm that bounds arc consistency is useful and practical
on a real complex problem with huge domains, which can reach several millions.
8.1 A Mission Management Benchmark for Agile Satellites
We solved a simplified version described by de Givry and Jeannin (2006) of a problem of
selecting and scheduling earth observations for agile satellites. A complete description of
the problem is given by Verfaillie and Lematre (2001). The satellite has a pool of candidate
photographs to take. It must select and schedule a subset of them on each pass above a
certain strip of territory. The satellite can only take one photograph at a time (disjunctive
scheduling). A photograph can only be taken during a time window that depends on the
location photographed. Minimal repositioning times are required between two consecutive
photographs. All physical constraints (time windows and repositioning times) must be
met, and the sum of the revenues of the selected photographs must be maximized. This is
equivalent to minimizing the rejected revenues of the non selected photographs.
613

fiZytnicki, Gaspin, de Givry & Schiex

Let N be the number of candidate photographs. We define N decision variables representing the acquisition starting times of the candidate photographs. The domain of each
variable is defined by the time window of its corresponding photograph plus an extra domain
value which represents the fact that the photograph is not selected. As proposed by de Givry
and Jeannin (2006), we create a binary hard constraint for every pair of photographs (resulting in a complete constraint graph) which enforces the minimal repositioning times if both
photographs are selected (represented by a disjunctive constraint). For each photograph, a
unary cost function associates its rejected revenue to the corresponding extra value.
In order to have a better filtering, we moved costs from unary cost functions inside
the binary hard constraints in a preprocessing step. This allows bounds arc consistency
filtering to exploit the revenue information and the repositioning times jointly, possibly
increasing w and the starting times of some photographs. To achieve this, for each variable
xi , the unary cost function wi is successively combined (using ) with each binary hard
 defined
constraint wij that involves xi . This yields N  1 new binary cost functions wij

as wij (t) = wij (t)  wi (t[xi ]), having both hard (+) and soft weights. These binary
 replace the unary cost function w and the N  1 original binary hard
cost functions wij
i
constraints wij . Notice that this transformation has the side effect of multiplying all soft
weights by N  1. This does preserve the equivalence with the original problem since all
finite weights are just multiplied by the same constant (N  1).
The search procedure is an exact depth-first branch-and-bound dedicated to scheduling
problems, using a schedule or postpone strategy as described by de Givry and Jeannin (2006)
which avoids the enumeration of all possible starting time values. No initial upper bound
was provided (k = +).
We generated 100 random instances for different numbers of candidate photographs
(N varying from 10 to 30)2 . We compared BAC (denoted by BAC0 in the experimental
results) with EDAC* (Heras et al., 2005) (denoted by EDAC*). Note that FDAC* and VAC
(applied in preprocessing and during search, in addition to EDAC*) were also tested on
these instances, but did not improve over EDAC* (FDAC* was slightly faster than EDAC*
but developed more search nodes and VAC was significantly slower than EDAC*, without
improving w in preprocessing). OSAC is not practical on this benchmark (for N = 20,
it has to solve a linear problem with 50, 000 variables and about 4 million constraints).
All the algorithms are using the same search procedure. They are implemented in the
toulbar2 C++ solver3 . Finding the minimum cost of the previously-described binary cost
functions (which are convex if we consider the extra domain values for rejected photographs
separately), is done in constant time for BAC. It is done in time O(d2 ) for EDAC*
(d = 201).
We also report the results obtained by maintaining bounds consistency on the reified
problem using meta-constraints as described by de Givry and Jeannin (2006), using the
claire/Eclair C++ constraint programming solver (de Givry, Jeannin, Josset, Mattioli,
Museux, & Saveant, 2002) developed by THALES (denoted by B-consistency).
The results are presented in Figure 4, using a log-scale. These results were obtained on
a 3 GHz Intel Xeon with 4 GB of RAM. Figure 4 shows the mean CPU time in seconds and
the mean number of backtracks performed by the search procedure to find the optimum
2. These instances are available at http://www.inra.fr/mia/ftp/T/bep/.
3. See http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro.

614

fiBounds Arc Consistency for Weighted CSPs

Satellite benchmark
10000

EDAC*
B consistency
BAC0

Cpu time in seconds

1000
100
10
1
0.1
0.01
0.001
1e-04
10

15
20
25
Number of candidate photographs

30

Satellite benchmark
1e+08

B consistency
BAC0
EDAC*

Number of backtracks

1e+07
1e+06
100000
10000
1000
100
10
10

15

20

25

30

Number of candidate photographs

Figure 4: Comparing various local consistencies on a satellite benchmark. Cpu-time (top)
and number of backtracks (bottom) are given.

615

fiZytnicki, Gaspin, de Givry & Schiex

and prove optimality as the problem size increases. In the legends, algorithms are sorted
by increasing efficiency.
The analysis of experimental results shows that BAC was up to 35 times faster than
EDAC* while doing only 25% more backtracks than EDAC* (for N = 30, no backtrack results are reported as EDAC* does not solve any instance within the time limit of 6 hours).
It shows that bounds arc consistency can prune almost as many search nodes as a stronger
local consistency does in much less time for temporal reasoning problems where the semantic of the cost functions can be exploited, as explained in Section 5. The second fastest
approach was bounds consistency on the reified representation which was at least 2.3 worse
than BAC in terms of speed and number of backtracks when N  25. This is a practical confirmation of the comparison of Section 6. The reified approach used with bounds
consistency introduces Boolean decision variables for representing photograph selection and
uses a criteria defined as a linear function of these variables. Contrarily to BAC, bounds
consistency is by definition unable to reason simultaneously on the combination of several
constraints to prune the starting times.
8.2 Non-coding RNA Gene Localization
A non-coding RNA (ncRNA) gene is a functional molecule composed of smaller molecules,
called nucleotides, linked together by covalent bonds. There are four types of these nucleotides, commonly identified by a single letter: A, U, G and C. Thus, an RNA can be
represented as a word built from the four letters. This sequence defines what is called the
primary structure of the RNA molecule.
RNA molecules have the ability to fold back on themselves by developing interactions
between nucleotides, forming pairs. The most frequently interacting pairs are: a G interacts
with a C, or a U interacts with an A. A sequence of such interactions forms a structure
called a helix. Helices are a fundamental structural element in ncRNA genes and are the
basis for more complex structures. The set of interactions is often displayed by a graph
where vertices represent nucleotides and edges represent either covalent bonds linking successive nucleotides (represented as plain lines in Figure 5) or interacting nucleotide pairs
(represented as dotted lines). This representation is usually called the molecules secondary
structure. See the graph of a helix in Figure 5(a).
The set of ncRNAs that have a common biological function is called a family. The
signature of a gene family is the set of conserved elements either in the sequence or the
secondary structure. It can be expressed as a collection of properties that must be satisfied
by a set of regions occurring on a sequence. Given the signature of a family, the problem we
are interested in involves searching for new members of a gene family in existing genomes,
where these members are in fact the set of regions appearing in the genome which satisfy the
signature properties. Genomic sequences are themselves long texts composed of nucleotides.
They can be thousand of nucleotides long for the simplest organisms up to several hundred
million nucleotides for the more complex ones. The problem of searching for an occurrence
of a gene signature in a genomic sequence is NP-complete for complex combinations of helix
structures (Vialette, 2004).
In order to find ncRNAs, we can build a weighted constraint network that scans a
genome, and detects the regions of the genome where the signature elements are present
616

fiBounds Arc Consistency for Weighted CSPs

A U A
C

A G C G U C

G

U C G C A G

helix

C
G A U

A G A C UA U U
xi
xj

loop

(cost: 1)
(b)
pattern(xi , xj , ACGUA)
cost function.

(a) An helix with its loop.

G

xi

U C

U A G

A G

xl

cost

xj

A G C

k

xk
(cost: 2)

(c) The helix(xi , xj , xk , xl , 6) cost
function.

The

0

xj  xi
d1 d2

d3

d4

(d)
The
cost
profile
spacer(xi , xj , d1 , d2 , d3 , d4 )
cost
tion.

of
func-

Figure 5: Examples of signature elements with their cost functions.
and correctly positioned. The variables are the positions of the signature elements in the
sequence. The size of the domains is the size of the genomic sequence. Cost functions
enforce the presence of the signature elements between the positions taken by the variables
involved. Examples of cost functions are given in Figure 5.
 The pattern(xi , xj , p) function states that a fixed word p, given as parameter, should
be found between the positions indicated by the variables xi and xj . The cost given
by the function is the edit distance between the word found at xi :xj and the word p
(see the cost function pattern with the word ACGUA in Figure 5(b)).
 The helix(xi , xj , xk , xl , m) function states that the nucleotides between positions xi
and xj should be able to bind with the nucleotides between xk and xl . Parameter
m specifies a minimum helix length. The cost given is the number of mismatches or
nucleotides left unmatched (see the helix function with 5 interacting nucleotide pairs
in Figure 5(c)).
 Finally, the function, spacer(xi , xj , d1 , d2 , d3 , d4 ) specifies a favorite range of distances
between positions xi and xj using a trapezoidal cost function as shown in Figure 5(d).
See the work of Zytnicki et al. (2008) for a complete description of the cost functions.
Because of the sheer domain size, and given that the complex pattern matching oriented
cost functions do not have any specific property that could speedup filtering, BAC alone
has been used for filtering these cost functions (Zytnicki et al., 2008). The exception is the
617

fiZytnicki, Gaspin, de Givry & Schiex

piecewise linear spacer cost function: its minimum can be computed in constant time for
BAC enforcement. The resulting C++ solver is called DARN!4 .
Size
# of solutions
AC*
Time
# of backtracks
BAC
Time (sec.)
# of backtracks

10k
32

50k
33

100k
33

500k
33

1M
41

4.9M
274

1hour 25min.
93

44 hours
101

-

-

-

-

0.016
93

0.036
101

0.064
102

0.25
137

0.50
223

2.58
1159

Table 1: Searching all the solutions of a tRNA motif in Escherichia coli genome.
A typical benchmark for the ncRNA localization problem is the transfer RNA (tRNA)
localization. The tRNA signature (Gautheret, Major, & Cedergren, 1990) can be modelled
by 22 variables, 3 nucleotide words, 4 helices, and 7 spacers. DARN! searched for all the
solutions with a cost strictly lower than the maximum cost k = 3. Just to illustrate the
absolute necessity of using bounds arc consistency in this problem, we compared bounds
arc consistency enforcement with AC* (Larrosa, 2002) on sub-sequences of the genome of
Escherichia coli, which is 4.9 million nucleotides long. Because of their identical space
complexity and because they have not been defined nor implemented on non-binary cost
functions (helix is a quaternarycost function), DAC, FDAC or EDAC have not been tested
(see the work of Sanchez et al., 2008, however for an extension of FDAC to ternary cost
functions).
The results are displayed in Table 1. For different beginning sub-sequences of the complete sequence, we report the size of the sub-sequence in which the signature is searched
for (10k is a sequence of 10,000 nucleotides), as well as the number of solutions found.
We also show the number of backtracks and the time spent on a 3 GHz Intel Xeon with
2 GB. A - means the instance could not be solved due to memory reasons, and despite
memory optimizations. BAC solved the complete sequence in less than 3 seconds. BAC
is approximately 300, 000 (resp. 4, 400, 000) times faster than AC* for the 10k (resp. 50k)
sub-sequence. More results on other genomes and ncRNA signatures can be found in the
work of Zytnicki et al. (2008).
The reason of the superiority of BAC over AC* is twofold. First, AC* needs to store all
the unary costs for every variable and projects costs from binary cost functions to unary
cost functions. Thus, the space complexity of AC* is at least O(nd). For very large domains
(in our experiments, greater than 100,000 values), the computer cannot allocate a sufficient
memory and the program is aborted. For the same kind of projection, BAC only needs to
store the costs of the bounds of the domains, leading to a space complexity of O(n).
Second, BAC does not care about the interior values and focuses on the bounds of the
domains only. On the other hand, AC* projects all the binary costs to all the interior values,
4. DARN!,
and
several
genomic
http://carlit.toulouse.inra.fr/Darn/.

sequences

618

and

family

signatures

are

available

at

fiBounds Arc Consistency for Weighted CSPs

which takes a lot of time, but should remove more values and detect inconsistencies earlier.
However, Table 1 shows that the number of backtracks performed by AC* and BAC are
the same. This can be explained as follows. Due to the nature of the cost functions used in
these problems, the supports of the bounds of the domains of the variables usually are the
bounds of the other variables. Thus, removing the values which are inside the domains, as
AC* does, do not help removing the bounds of the variables. As a consequence, the bounds
founds by BAC are the same as those found by AC*. This explains why enforcing of AC*
generally does not lead to new domain wipe out compared to BAC, and finding the support
inside the bounds of the domains is useless.
Notice that the spacer cost functions dramatically reduce the size of the domains. When
a single variable is assigned, all the other domain sizes are dramatically reduced, and the
instance becomes quickly tractable. Moreover, the helix constraint has the extra knowledge
of a maximum distance djk between its variables xj and xk (see Fig. 5(c)) which bounds the
time complexity of finding the minimum cost w.r.t. djk and not the length of the sequence.

9. Conclusions and Future Work
We have presented here new local consistencies for weighted CSPs dedicated to large domains as well as algorithms to enforce these properties. The first local consistency, BAC,
has a time complexity which can be easily reduced if the semantics of the cost function
is appropriate. A possible enhancement of this property, -IC, has also been presented.
Our experiments showed that maintaining bounds arc consistency is much better than AC*
for problems with large domains, such as ncRNA localization and scheduling for Earth observation satellites. This is due to the fact that AC* cannot handle problems with large
domains, especially because of its high memory complexity, but also because BAC behaves
particularly well with specific classes of cost functions.
Similarly to bounds consistency, which is implemented on almost all state-of-the-art
CSP solvers, this new local property has been implemented in the open source toulbar2
WCSP solver.5
BAC, BAC and -inverse consistency allowed us to transfer bounds consistency CSP to
weighted CSP, including improved propagation for specific classes of binary cost functions.
Our implementation for RNA gene finding is also able to filter non-binary constraints. It
would therefore be quite natural to try to define efficient algorithms for enforcing BAC,
BAC or -inverse consistency on specific cost functions of arbitrary arity such as the soft
global constraints derived from All-Diff, GCC or regular (Regin, 1994; Van Hoeve, Pesant,
& Rousseau, 2006). This line of research has been recently explored by Lee and Leung
(2009).
Finally, another interesting extension of this work would be to better exploit the connection between BAC and bounds consistency by exploiting the idea of Virtual Arc Consistency
introduced by Cooper et al. (2008). The connection established by Virtual AC between crisp
CNs and WCNs is much finer grained than in the reification approach considered by Petit
et al. (2000) and could provide strong practical and theoretical results.
5. Available at http://carlit.toulouse.inra.fr/cgi-bin/awki.cgi/ToolBarIntro.

619

fiZytnicki, Gaspin, de Givry & Schiex

References
Apt, K. (1999). The essence of constraint propagation. Theoretical computer science, 221 (12), 179210.
Bessiere, C., & Regin, J.-C. (2001). Refining the basic constraint propagation algorithm.
In Proc. of IJCAI01, pp. 309315.
Chellappa, R., & Jain, A. (1993). Markov Random Fields: Theory and Applications. Academics Press.
Choi, C. W., Harvey, W., Lee, J. H. M., & Stuckey, P. J. (2006). Finite domain bounds
consistency revisited. In Proc. of Australian Conference on Artificial Intelligence, pp.
4958.
Cooper, M., & Schiex, T. (2004). Arc consistency for soft constraints. Artificial Intelligence,
154, 199227.
Cooper, M. C., de Givry, S., Sanchez, M., Schiex, T., & Zytnicki, M. (2008). Virtual arc
consistency for weighted CSP.. In Proc. of AAAI2008.
Cooper, M. C., de Givry, S., & Schiex, T. (2007). Optimal soft arc consistency. In Proc. of
IJCAI07, pp. 6873.
de Givry, S., & Jeannin, L. (2006). A unified framework for partial and hybrid search
methods in constraint programming. Computer & Operations Research, 33 (10), 2805
2833.
de Givry, S., Jeannin, L., Josset, F., Mattioli, J., Museux, N., & Saveant, P. (2002). The
THALES constraint programming framework for hard and soft real-time applications.
The PLANET Newsletter, Issue 5 ISSN 1610-0212, pages 5-7.
Freuder, E., & Wallace, R. (1992). Partial constraint satisfaction. Artificial Intelligence,
58, 2170.
Gautheret, D., Major, F., & Cedergren, R. (1990). Pattern searching/alignment with RNA
primary and secondary structures: an effective descriptor for tRNA. Comp. Appl.
Biosc., 6, 325331.
Heras, F., Larrosa, J., de Givry, S., & Zytnicki, M. (2005). Existential arc consistency:
Getting closer to full arc consistency in weighted CSPs. In Proc. of IJCAI05, pp.
8489.
Khatib, L., Morris, P., Morris, R., & Rossi, F. (2001). Temporal constraint reasoning with
preferences. In Proc. of IJCAI01, pp. 322327.
Larrosa, J. (2002). Node and arc consistency in weighted CSP. In Proc. of AAAI02, pp.
4853.
Larrosa, J., & Schiex, T. (2004). Solving weighted CSP by maintaining arc-consistency.
Artificial Intelligence, 159 (1-2), 126.
Lee, J., & Leung, K. (2009). Towards Efficient Consistency Enforcement for Global Constraints in Weighted Constraint Satisfaction. In Proc. of IJCAI09.
Lhomme, O. (1993). Consistency techniques for numeric CSPs. In Proc. of IJCAI93, pp.
232238.
620

fiBounds Arc Consistency for Weighted CSPs

Meseguer, P., Rossi, F., & Schiex, T. (2006). Soft constraints. In Rossi, F., van Beek, P.,
& Walsh, T. (Eds.), Handbook of constraint programming, Foundations of Artificial
Intelligence, chap. 9, pp. 281328. Elsevier.
Petit, T., Regin, J.-C., & Bessiere, C. (2000). Meta-constraints on violations for over constrained problems. In Proc. of ICTAI00, pp. 358365.
Petit, T., Regin, J. C., & Bessiere, C. (2002). Range-based algorithm for Max-CSP. In
Proc. of CP02, pp. 280294.
Regin, J.-C. (1994). A filtering algorithm for constraints of difference in CSPs. In Proc. of
AAAI94, pp. 362367.
Sanchez, M., de Givry, S., & Schiex, T. (2008). Mendelian error detection in complex
pedigrees using weighted constraint satisfaction techniques. Constraints, 13 (1-2), 130
154.
Sandholm, T. (1999). An Algorithm for Optimal Winner Determination in Combinatorial
Auctions. In Proc. of IJCAI99, pp. 542547.
Schiex, T. (2000). Arc consistency for soft constraints. In Proc. of CP00, pp. 411424.
Tarski, A. (1955). A lattice-theoretical fixpoint theorem and its applications. Pacific Journal
of Mathematics, 5 (2), 285309.
Thebault, P., de Givry, S., Schiex, T., & Gaspin, C. (2006). Searching RNA motifs and their
intermolecular contacts with constraint networks. Bioinformatics, 22 (17), 207480.
Van Hentenryck, P., Deville, Y., & Teng, C.-M. (1992). A generic arc-consistency algorithm
and its specializations. Artificial Intelligence, 57 (23), 291321.
Van Hoeve, W., Pesant, G., & Rousseau, L. (2006). On global warming: Flow-based soft
global constraints. Journal of Heuristics, 12 (4), 347373.
Verfaillie, G., & Lematre, M. (2001). Selecting and scheduling observations for agile satellites: some lessons from the constraint reasoning community point of view. In Proc.
of CP01, pp. 670684.
Vialette, S. (2004). On the computational complexity of 2-interval pattern matching problems. Theoretical Computer Science, 312 (2-3), 223249.
Zytnicki, M., Gaspin, C., & Schiex, T. (2008). DARN! A soft constraint solver for RNA
motif localization. Constraints, 13 (1-2), 91109.

621

fiJournal of Artificial Intelligence Research 35 (2009) 717-773

Submitted 12/08; published 08/09

The Complexity of Circumscription in Description Logic
Piero A. Bonatti

bonatti@na.infn.it

Section of Computer Science, Department of Physics
University of Naples Federico II, Italy

Carsten Lutz

clu@informatik.uni-bremen.de

Department of Mathematics and Computer Science
University of Bremen, Germany

Frank Wolter

wolter@liverpool.ac.uk

Department of Computer Science
University of Liverpool, UK

Abstract
As fragments of first-order logic, Description logics (DLs) do not provide nonmonotonic
features such as defeasible inheritance and default rules. Since many applications would
benefit from the availability of such features, several families of nonmonotonic DLs have
been developed that are mostly based on default logic and autoepistemic logic. In this
paper, we consider circumscription as an interesting alternative approach to nonmonotonic
DLs that, in particular, supports defeasible inheritance in a natural way. We study DLs
extended with circumscription under different language restrictions and under different
constraints on the sets of minimized, fixed, and varying predicates, and pinpoint the exact
computational complexity of reasoning for DLs ranging from ALC to ALCIO and ALCQO.
When the minimized and fixed predicates include only concept names but no role names,
then reasoning is complete for NExpNP . It becomes complete for NPNExp when the number
of minimized and fixed predicates is bounded by a constant. If roles can be minimized or
fixed, then complexity ranges from NExpNP to undecidability.

1. Introduction
Early knowledge representation (KR) formalisms such as semantic networks and frames
included a wealth of features in order to provide as much expressive power as possible
(Quillian, 1968; Minsky, 1975). In particular, such formalisms usually admitted a structured representation of classes and objects similar to modern description logics (DLs), but
also mechanisms for defeasible inheritance, default rules, and other features that are nowadays studied in the area of nonmonotonic logics (NMLs). When KR theory developed
further, the all-embracing approaches were largely given up in favour of more specialized
ones due to unfavourable computational properties and problems with the semantics. This
process has caused DLs and NMLs to develop into two independent subfields. Consequently,
modern description logics such as SHIQ lack the expressive power to represent defeasible
inheritance and other nonmonotonic features (Horrocks, Sattler, & Tobies, 2000).
Despite (or due to) this development, there has been a continuous interest in the
(re)integration of nonmonotonic features into description logics. In recent years, the advent of several new applications of DLs have increased this interest even further. We briefly
discuss two of them. First, DLs have become a popular tool for the formalization of biomedc
2009
AI Access Foundation. All rights reserved.

fiBonatti, Lutz, & Wolter

ical ontologies such as GALEN (Rector & Horrocks, 1997) and SNOMED (Cote, Rothwell,
Palotay, Beckett, & Brochu, 1993). As argued for example by Rector (2004) and Stevens
et al. (2005), it is important for such ontologies to represent exceptions of the form in
humans, the heart is usually located on the left-hand side of the body; in humans with
situs inversus, the heart is located on the right-hand side of the body. Modelling such
situations requires defeasible inheritance, i.e., properties transfer to all instances of a class
by default, but can be explicitly overridden in special cases (McCarthy, 1986; Horty, 1994;
Brewka, 1994; Baader & Hollunder, 1995b). The second application is the use of DLs as security policy languages (Uszok, Bradshaw, Johnson, Jeffers, Tate, Dalton, & Aitken, 2004;
Kagal, Finin, & Joshi, 2003; Tonti, Bradshaw, Jeffers, Montanari, Suri, & Uszok, 2003). In
formalizing access control policies, one must deal with the situation where a given request
is neither explicitly allowed nor explicitly denied. Then, a default decision has to be taken
such as in open and closed policies, where authorizations are respectively granted or denied
by default (Bonatti & Samarati, 2003). Moreover, policies are often formulated incrementally, i.e., start with general authorizations for large classes of subjects, objects, and actions,
and then progressively refine them by introducing exceptions for specific subclasses. This
approach is clearly an incarnation of defeasible inheritance.
While the above applications illustrate that integrating nonmonotonic features into DLs
is worthwhile, the actual engineering of a computationally well-behaved nonmonotonic DL
that provides sufficient expressive power turns out to be a non-trivial task. In particular,
combinations of DLs and nonmonotonic logics typically involve subtle interactions between
the two component logics and this easily leads to undecidability. It appears that there is no
one optimal way to circumnavigate these difficulties, and thus many different combinations
of DLs and nonmonotonic logics have been proposed in the literature, each with individual
strengths and limitations (we provide a survey in Section 7). However, there is a striking
gap: almost all existing approaches are based on default logic and autoepistemic logic, while
circumscription has received very little attention in connection with DLs, and the computational properties of DLs with circumscription have been almost completely unknown. This
is all the more surprising since circumscription is known to be one of the weakest forms of
nonmonotonic reasoningsee the work by Janhunen (1999) for one of the most recent surveys, and the paper by Bonatti and Eiter (1996) for an expressiveness analysis in terms of
queries. Therefore, it is a natural idea to use circumscription for defining a computationally
well-behaved, yet expressive DL with nonmonotonic features.
In this paper, we study circumscription (McCarthy, 1980) as an alternative approach
to defining nonmonotonic DLs. In particular, we define a family of DLs with circumscription that enable a natural modelling of defeasible inheritance. Our general approach is to
generalize standard DL knowledge bases to circumscribed knowledge bases (cKBs) which,
additionally to a TBox for representing terminological knowledge and an ABox for representing knowledge about individuals, are equipped with a circumscription pattern. This
pattern lists predicates (i.e., concept and role names) to be minimized in the sense that, in
all admitted models of the cKB, the extension of the listed predicates has to be minimal
w.r.t. set inclusion. Following McCarthy (1986), the minimized predicates can be used as
abnormality predicates that identify instances which are not typical for their class. Circumscription patterns can require other predicates to be fixed during minimization, or allow
them to vary freely (McCarthy, 1986). A main feature of the DLs of our family is that they
718

fiThe Complexity of Circumscription in DLs

come with a built-in mechanism for defeasible inheritance: by default, the properties of a
class (humans in the first example above) transfer to each subclass (humans with situs
inversus), but exceptions can be specified based on a priority mechanism. It is well-known
that defeasible inheritance with priority cannot be modularly encoded with pure default or
autoepistemic logic (Horty, 1994), and workarounds such as the explicit listing of exceptions
lead to serious maintainability problems. Circumscription lends itself naturally to priorities,
based on circumscription patterns that can express preferences between minimized predicates in terms of a partial ordering. As argued by Baader and Hollunder (1995b), such an
approach is well-suited to ensure a smooth interplay between defeasible inheritance and DL
subsumption, and thus we prefer it over traditional prioritized circumscription.
To achieve decidability, nonmonotonic DLs usually have to adopt suitable restrictions
on the expressive power of the DL component, on non-monotonic features, or their interaction. In the case of default logic and autoepistemic logic, a typical restriction concerns
the different treatment of individuals that are explicitly denoted by a constant, and those
that are not. This goes back to reasoning in first-order default logic (Reiter, 1980) and
autoepistemic logic (Moore, 1985), which also involve tricky technical issues related to the
denotation of individuals. To make reasoning decidable in DLs based on default logic, default rules are applied only to the individuals denoted by constants that occur explicitly
in the knowledge base (Baader & Hollunder, 1995a), but not to unnamed individuals. As
a consequence, named and unnamed individuals are not treated uniformly. In approaches
based on autoepistemic logic (Donini, Lenzerini, Nardi, Nutt, & Schaerf, 1998; Donini,
Nardi, & Rosati, 1997, 2002), an alternative solution is to restrict the domain to a fixed, denumerable set of constants. This approach overcomes the different treatment of named and
unnamed individuals since all individuals are named. The flipside is that ad-hoc encodings
are required when the domain is finite or the unique name assumption is not enforced, i.e.,
when different constants are allowed to denote the same individual. In this respect, DLs
with circumscription pose no difficulty at all, and named individuals are treated in exactly
the same way as unnamed ones without any assumptions on the domain. At the same
time, we are able to base our nonmonotonic DLs on rather expressive DL components such
as ALCIO and ALCQO without losing decidability. However, we cannot do without any
restrictions either: we only allow to fix and minimize concept names during circumscription
and require that all role names vary.
The main contribution of this paper is a detailed analysis of the computational properties
of reasoning with cKBs. We show that, in the expressive DLs ALCIO and ALCQO, instance
checking, satisfiability and subsumption are decidable for concept-circumscribed KBs in
which only concept names (and no role names) are minimized and fixed. More precisely, we
prove that these reasoning problems are NExpNP -complete, where the lower bound applies
already to concept-circumscribed KBs in ALC with empty preference relation and without
fixed concept names and (1) empty TBox or (2) empty ABox and acyclic TBox. In addition,
we show that if a constant bound is imposed on the number of minimized and fixed concept
names, then the complexity drops to NPNExp .
The situation is completely different when role names are minimized or fixed. First, the
complexity of reasoning with cKBs formulated in ALC with a single fixed role name, empty
TBox, empty preference relation, and no minimized role names turns out to be outside the
analytic hierarchy, and thus very highly undecidable. This result is shown by a reduction
719

fiBonatti, Lutz, & Wolter

Name

Syntax
r

inverse role
nominal
negation
conjunction
disjunction
at-least restriction
at-most restriction

{a}
C
C uD
C tD
(> n r C)
(6 n r C)

Semantics
(rI )` = {(d, e) | (e, d)  rI }
{aI }
I \ C I
C I  DI
C I  DI
{d  I | #{e  C I | (d, e)  rI }  n}
{d  I | #{e  C I | (d, e)  rI }  n}

Figure 1: Syntax and semantics of ALCQIO.

of satisfiability in monadic second-order logic (MSO) with binary predicates over arbitrary
(i.e., not necessarily tree-shaped) structures. The reduction does not apply to cKBs in
which role names can be minimized, but not fixed. Surprisingly, we find that in this case
reasoning with empty TBoxes becomes decidable (and again NExpNP -complete) for DLs
between ALC and ALCQO, and only for ALCI and its extensions it is undecidable. For all
these logics, however, adding acyclic TBoxes leads to undecidability. The reader can find a
table summarising the complexity results in Section 7.
It is interesting to note that our results are somewhat unusual from the perspective of
NMLs. First, the arity of predicates has an impact on decidability: fixing concept names
(unary predicates) does not impair decidability, whereas fixing a single role name (binary
predicate) leads to a strong undecidability result. Second, the number of predicates that
are minimized or fixed (bounded vs. unbounded) affects the computational complexity of
reasoning. Although (as we note in passing) a similar effect can be observed in propositional
logic with circumscription, this has, to the best of our knowledge, never been explicitly
noted.
The paper is organized as follows. In the next section we introduce syntax, semantics,
and reasoning problems for circumscribed KBs, and provide some examples. Section 3
provides some basic results such as a polynomial simulation of fixed concepts by means of
minimized concepts, a polynomial reduction of reasoning with general TBoxes to reasoning with acyclic TBoxes, and a polynomial reduction of the simultaneous satisfiability of
multiple cKBs to standard satisfiability. Then, Section 4 proves the decidability and complexity results for concept-circumscribed knowledge bases. Fixed and minimized roles are
considered in Sections 5 and 6, respectively. Section 7 discusses related work, and Section 8
concludes the paper by summarizing the main results and pointing out some interesting
directions for further research. To improve readability, many proof details are deferred to
the appendix. This paper is an extended version of the article by Bonatti, Lutz, and Wolter
(2006).

2. Description Logics and Circumscription
In DLs, concepts are inductively defined with the help of a set of constructors, starting with
a set NC of concept names, a set NR of role names, and (possibly) a set NI of individual
720

fiThe Complexity of Circumscription in DLs

names (all countably infinite). We use the term predicates to refer to elements of NC  NR .
The concepts of the expressive DL ALCQIO are formed using the constructors shown in
Figure 1.
There, the inverse role constructor is a role constructor, whereas the remaining six
constructors are concept constructors. In Figure 1 and throughout this paper, we use #S
to denote the cardinality of a set S, a and b to denote individual names, r and s to denote
roles (i.e., role names and inverses thereof), A, B to denote concept names, and C, D to
denote (possibly complex) concepts. As usual, we use > as abbreviation for an arbitrary
(but fixed) propositional tautology,  for >,  and  for the usual Boolean abbreviations,
r.C (existential restriction) for (> 1 r C), and r.C (universal restriction) for (6 0 r C).
In this paper, we will not be concerned with ALCQIO itself, but with several of its
fragments.1 The basic such fragment allows only for negation, conjunction, disjunction,
and universal and existential restrictions, and is called ALC. The availability of additional
constructors is indicated by concatenation of a corresponding letter: Q stands for number restrictions, I stands for inverse roles, and O for nominals. This explains the name
ALCQIO, and also allows us to refer to fragments such as ALCIO, ALCQO, and ALCQI.
The semantics of ALCQIO-concepts is defined in terms of an interpretation I =
I
( , I ). The domain I is a non-empty set of individuals and the interpretation function I maps each concept name A  NC to a subset AI of I , each role name r  NR to a
binary relation rI on I , and each individual name a  NI to an individual aI  I . The
extension of I to inverse roles and arbitrary concepts is inductively defined as shown in the
third column of Figure 1. An interpretation I is called a model of a concept C if C I 6= .
If I is a model of C, we also say that C is satisfied by I.
A (general) TBox is a finite set of concept implications (CIs) C v D where C and D are
.
concepts. As usual, we use C = D as an abbreviation for C v D and D v C. An ABox is
a finite set of concept assertions C(a) and role assertions r(a, b), where a, b are individual
names, r is a role name, and C is a concept. An interpretation I satisfies (i) a CI C v D
if C I  DI , (ii) an assertion C(a) if aI  C I , and (iii) an assertion r(a, b) if (aI , bI )  rI .
Then, I is a model of a TBox T if it satisfies all implications in T , and a model of an ABox
A if it satisfies all assertions in A.
An important class of TBoxes are acyclic TBoxes: call a TBox T acyclic if it is a set
.
of concept definitions A = C, where A is a concept name and the following two conditions
hold:
 no concept name occurs more than once on the left hand side of a definition in T ;
.
 the relation T , defined by setting A T B iff A = C  T and B occurs in C, is
well-founded.
1. The reason that we do not consider ALCQIO in this paper is that it does not have the finite model
property; i.e., there are satisfiable concepts that are not satisfiable in finite models. Our proofs of the
complexity upper bounds assume the finite model property and, therefore, do not work for ALCQIO. Investigating circumscription for description logics without the finite model property remains an interesting
open problem.

721

fiBonatti, Lutz, & Wolter

2.1 Circumscription, Varying Predicates, and Partial Priority Ordering
Circumscription is a logical approach suitable for modelling what normally or typically
holds, and thus admits the modeling of defeasible inheritance (McCarthy, 1986; Lifschitz,
1993). The idea is to define, in a standard first-order language, both domain knowledge and
so-called abnormality predicates that identify instances of a class that violate the normal or
typical properties of that class. To capture the intuition that abnormality is exceptional,
inference is not based on the set of all models of the resulting theory as in classical logic,
but rather restricted to those models where the extension of the abnormality predicates is
minimal with respect to set inclusion. Intuitively, this means that reasoning is based only
on models that are as normal as possible. Since such models are classical models of the
given knowledge base, all classical first-order inferences are valid in circumscription (but
additional inferences may become possible).
Since description logics are fragments of first-order logic, circumscription can be readily
applied. Using ALC syntax, we can assert that mammals normally inhabitate land, and
that whales do not live on land:
Mammal v habitat.Land t AbMammal
Whale v Mammal u habitat.Land
The upper inclusion states that any mammal not inhabitating land is an abnormal mammal,
thus satisfying the abnormality predicate AbMammal . When applying circumscription to the
above TBox, we should thus only consider models where the extension of AbMammal is minimal.
However, there is more than one way of defining such preferred models because each nonminimized predicate can be treated in two different ways during minimization: we may
either fix its extension or let it vary freely.
Intuitively, fixed predicates retain their classical semantics while varying predicates may
be affected by minimization. As a concrete example, consider once more the above TBox
and assume that all non-minimized predicates are fixed. Then we can derive the following
subsumptions:
Whale v AbMammal
()
.
AbMammal = Mammal u habitat.Land.
Here, Whale v AbMammal and AbMammal w Mammal u habitat.Land are classical consequences
of the TBox. The minimization of AbMammal adds only the inclusion AbMammal v Mammal u
habitat.Land.
To further analyze fixed predicates, suppose that we explicitly introduce a concrete
mammal that is not a whale by adding an ABox assertion
Mammal u Whale(flipper)
We might expect that we can derive habitat.Land(flipper), but actually that is not the
case. To see this, observe that there is a classical model of the knowledge base that falsifies
habitat.Land(flipper); the extension of the fixed predicates habitat and Land are not
affected by minimization, so habitat.Land(flipper) must still be false after minimization.
The same argument can be applied to the negation of habitat.Land(flipper), which is
thus also not derivable. What we have just seen is that if a sentence uses only fixed
722

fiThe Complexity of Circumscription in DLs

predicates, then it is a consequence of a circumscribed knowledge base if, and only if, it is
a classical consequence of the knowledge base.
Now assume that we let the role habitat and the concept name Land vary freely, and fix
only Mammal and Whale. In view of the concept inclusion for Mammal in our original TBox,
this setup may be interpreted as expressing that it is very unlikely for a mammal not to
live on land: we are willing to modify the extension of habitat and Land in order to avoid
abnormality. We obtain an additional consequence, namely:
.
Whale = AbMammal .
()
To see that this is indeed a consequence note that, during minimization, we can (i) make
Land non-empty and (ii) for any mammal m that is not a whale, ensure that m is not
an AbMammal by linking it via habitat to the generated instance of Land.2 Intuitively, the
equality () can be seen as reflecting the unlikeliness of being abnormal: a mammal is only
abnormal if there is a reason, and the only reason that we have captured in our knowledge
base is being a whale.
Let us now return to the assertion Mammal u Whale(flipper). By applying classical
reasoning to () and (), we derive Whale w Mammal u habitat.Land (i.e., whales are
the only mammals that do not live on land). Thus we can now derive the expected conclusion habitat.Land(flipper). In summary, by turning habitat and Land into varying
predicates, we have obtained a more natural modelling in which the habitat attribute of
mammals can be forced to its default value.
Driving our example further, we might now consider whales abnormal to such a degree
that we do not believe they exist unless there is evidence that they do. Then we should,
additionally, let Whale vary freely. The result is that () and () can still be derived, and
additionally we obtain the consequence
.
.
Whale = AbMammal = .
We can then use an ABox to add evidence that whales exist, e.g. through the assertion
Whale(mobydick). As expected, the result of this change is that
.
.
Whale = AbMammal = {mobydick}.
Evidence for the existence of another, anonymous whale could be generated by adding the
ABox assertion Male(mobydick) and the TBox statement
Whale v mother.(Whale u Male)
with mother and Male varying freely. This knowledge base classically entails that there exist
two whales, satisfying Male and Male, respectively. The former is denoted by mobydick,
while the latter is not denoted by any ABox individual (which corresponds to a first-order
constant). After minimization, Whale contains exactly those two individuals.
In general, the appropriate combination of fixed and varying predicates depends on the
application. Therefore, we adhere to standard circumscription and give users the freedom
to choose which predicates are minimized, fixed, and varying.
2. Indeed, this is the only reason to let Land vary: to ensure that it can be made non-empty during
minimization.

723

fiBonatti, Lutz, & Wolter

As another example, consider the sentences: In humans, the heart is usually located
on the left-hand side of the body; in humans with situs inversus, the heart is located on the
right-hand side of the body. They can be axiomatized as follows:
Human v has heart.has position.{Left} t AbHuman
Situs Inversus v has heart.has position.{Right}
has heart.has position.{Left} u has heart.has position.{Right} v  .
The predicate AbHuman represents abnormal humans and should be minimized. If humans
with situs inversus are to be restricted to those individuals that are explicitly declared to
have this property, then by analogy with the previous example the roles specifying heart
position and the class of exceptional individuals Situs Inversus should be allowed to vary
while Human can be fixed and retain its classical semantics. As a result and in the absence of
any further axioms, AbHuman and Situs Inversus are empty in all minimized models. The
additional axiom has friend.Situs Inversus(John) turns AbHuman and Situs Inversus
into a singleton set containing an anonymous individual (though in some models, it may be
John himself). As an example for a nonclassical consequence, consider:
Human u Situs Inversus v has heart.has position.{Left} ,
that is, all humans have the default heart position with the only exception of those that are
explicitly declared to have situs inversus.
It has been extensively argued (McCarthy, 1986; Horty, 1994; Brewka, 1994; Baader &
Hollunder, 1995b) that there is an interplay between subsumption and abnormality predicates that should be addressed in nonmonotonic DLs. Consider, for example, the following
TBox:
User
Staff
Staff
BlacklistedStaff

v
v
v
v

hasAccessTo.{ConfidentialFile} t AbUser
User
hasAccessTo.{ConfidentialFile} t AbStaff
Staff u hasAccessTo.{ConfidentialFile}

To get models that are as normal as possible, as a first attempt we could minimize the
two abnormality predicates AbUser and AbStaff in parallel. Assume that hasAccessTo is
varying, and User, Staff, and BlacklistedStaff are fixed. Then, the result of parallel
minimization is that staff members may or may not have access to confidential files, with
equal preference. In the first case, they are abnormal users, and in the second case, they
are abnormal staff. However, one may argue that the first option should be preferred: since
Staff v User (but not the other way round), the normality information for staff is more
specific than the normality information for users and should have higher priority. Such effects are well-known also from the propositional/first-order case and indeed, circumscription
has soon after its introduction been extended with priorities to address issues of specificity
(McCarthy, 1986).
In our formalism, users can specify priorities between minimized predicates. Typically,
these priorities will reflect the subsumption hierarchy (as computed w.r.t. the class of all
models). Since the subsumption hierarchy is in general a partial order, the priorities between
minimized predicates may form a partial order, too. This approach is analogous to partially
724

fiThe Complexity of Circumscription in DLs

ordering priorities on default rules, as proposed by Brewka (1994). It is more general
than standard prioritized circumscription, which assumes a total ordering (McCarthy, 1986;
Lifschitz, 1985), and a special case of nested circumscription (Lifschitz, 1995).
2.2 Circumscribed Knowledge Bases
To define DLs with circumscription, we start by introducing circumscription patterns. They
describe how individual predicates are treated during minimization.
Definition 1 (Circumscription pattern, <CP ) A circumscription pattern is a tuple CP
of the form (, M, F, V ), where  is a strict partial order over M , and M , F , and V
are mutually disjoint subsets of NC  NR , the minimized, fixed, and varying predicates,
respectively. By , we denote the reflexive closure of . Define a preference relation <CP
on interpretations by setting I <CP J iff the following conditions hold:
1. I = J and, for all a  NI , aI = aJ ,
2. for all p  F , pI = pJ ,
3. for all p  M , if pI 6 pJ then there exists q  M , q  p, such that q I  q J ,
4. there exists p  M such that pI  pJ and for all q  M such that q  p, q I = q J .
When M  F  NC (i.e., the minimized and fixed predicates are all concepts) we call
(, M, F, V ) a concept circumscription pattern.
4
We use the term concept circumscription if only concept circumscription patterns are admitted. Based on circumscription patterns, we can define circumscribed DL knowledge
bases and their models.
Definition 2 (Circumscribed KB) A circumscribed knowledge base (cKB) is an expression CircCP (T , A), where T is a TBox, A an ABox, and CP = (, M, F, V ) a circumscription pattern such that M, F, V partition the predicates used in T and A. An interpretation
I is a model of CircCP (T , A) if it is a model of T and A and there exists no model I 0 of T
and A such that I 0 <CP I.
A cKB CircCP (T , A) is called a concept-circumscribed KB if CP is a concept circumscription pattern.
4
Note that partially ordered circumscription becomes standard parallel circumscription if
the empty relation is used for .
The main reasoning tasks for (non-circumscribed) KBs are satisfiability of concepts
w.r.t. KBs, subsumption w.r.t. KBs, and instance checking w.r.t. KBs. These reasoning
tasks are fundamental for circumscribed KBs as well. We now provide precise definitions
of these tasks. Throughout this and the following section, DL denotes the set of DLs
introduced in the previous section; i.e., ALC, ALCI, ALCO, ALCQ, ALCQI, ALCIO,
ALCQO, and ALCQIO.
Definition 3 (Reasoning tasks)
725

fiBonatti, Lutz, & Wolter

 A concept C is satisfiable w.r.t. a cKB CircCP (T , A) if some model I of CircCP (T , A)
satisfies C I 6= . Let L  DL. The satisfiability problem w.r.t. cKBs in L is defined
as follows: given a concept C in L and a cKB CircCP (T , A) in L, decide whether C
is satisfiable w.r.t. CircCP (T , A).
 A concept C is subsumed by a concept D w.r.t. a cKB CircCP (T , A), in symbols
CircCP (T , A) |= C v D, if C I  DI for all models I of CircCP (T , A). Let L  DL.
The subsumption problem w.r.t. cKBs in L is defined as follows: given concepts C
and D in L and a cKB CircCP (T , A) in L, decide whether CircCP (T , A) |= C v D.
 An individual name a is an instance of a concept C w.r.t. a cKB CircCP (T , A), in
symbols CircCP (T , A) |= C(a), if aI  C I for all models I of CircCP (T , A). Let
L  DL. The instance problem w.r.t. cKBs in L is defined as follows: given a
concept C in L, an individual name a, and a cKB CircCP (T , A) in L, decide whether
CircCP (T , A) |= C(a).
4
These reasoning problems can be polynomially reduced to one another: first, C is satisfiable
w.r.t. CircCP (T , A) iff CircCP (T , A) 6|= C v , and CircCP (T , A) |= C v D iff C u D
is not satisfiable w.r.t. CircCP (T , A). And second, C is satisfiable w.r.t. CircCP (T , A) iff
CircCP (T , A) 6|= C(a), where a is an individual name not appearing in T and A; conversely,
we have CircCP (T , A) |= C(a) iff AuC is not satisfiable w.r.t. CircCP0 (T , A{A(a)}), where
A is a concept name not occurring in T and A, and CP0 is obtained from CP by adding A
to M (and leaving  as it is). In this paper, we use satisfiability w.r.t. cKBs as the basic
reasoning problem.

3. Basic Reductions
We present three basic reductions between reasoning problems for circumscribed knowledge
bases that are interesting in their own right and, additionally, will be useful for establishing
the main results of this paper later on. More precisely, we replay a well-known reduction of
fixed predicates to minimized predicates in the context of DLs, reduce reasoning w.r.t. cKBs
with general TBoxes to reasoning w.r.t. cKBs with acyclic TBoxes, and show that, under
certain conditions, simultaneous satisfiability w.r.t. a collection of cKBs is reducible to
satisfiability w.r.t. a single cKB.
3.1 Fixed and minimized concepts
In circumscription, it is folklore that fixed predicates can be simulated in terms of minimized
predicates, see e.g. de Kleer (1989). In the case of DLs, the same simulation is possible
for concept names. To see this, let C0 be a concept and CircCP (T , A) a circumscribed
KB with CP = (, M, F, V ) and F0 = {A1 , . . . , Ak } = F  NC . Define a new pattern
CP0 = (, M 0 , F \ F0 , V ) with
 M 0 = M  {A1 , . . . , Ak , A01 , . . . , A0k }, where A01 , . . . , A0k are concept names that do not
occur in C0 , M , F , V , T , and A;
.
 T 0 = T  {A0i = Ai | 1  i  k}.
726

fiThe Complexity of Circumscription in DLs

It is not difficult to see that C0 is satisfiable w.r.t. CircCP (T , A) iff it is satisfiable w.r.t.
CircCP0 (T 0 , A). Thus, we get the following result.
Lemma 4 Let L  DL. Then satisfiability w.r.t. (concept-)circumscribed KBs in L can be
polynomially reduced to satisfiability w.r.t. (concept-)circumscribed KBs in L that have no
fixed concept names.
In contrast to concept names, fixed role names cannot be reduced to minimized role names
since Boolean operators on roles are not available in standard DLs such as ALCQIO. A
proof is given in Section 6, where we show that, in some cases, reasoning with minimized
role names is decidable, whereas the corresponding reasoning task for cKBs with fixed role
names is undecidable.
The reduction above clearly relies on TBoxes. However, in this paper we will sometimes
work with circumscribed KBs in which the TBox is empty. The following lemma, proved in
the appendix, shows that for cKBs in ALC without fixed role names and with empty TBox,
one can simulate fixed concept names using minimized concept names without introducing
a TBox. The proof, which may be viewed as a much more careful version of the proof of
Lemma 4, can be adapted to yield an analogous result for the other logics in DL.
Lemma 5 In ALC, satisfiability w.r.t. (concept-)circumscribed KBs with empty TBox and
without fixed roles can be polynomially reduced to satisfiability w.r.t. (concept-)circumscribed
KBs with empty TBox and without fixed predicates.
3.2 Acyclic and General TBoxes
For many DLs, satisfiability w.r.t. (non-circumscribed) KBs with general TBoxes is harder
than satisfiability w.r.t. (non-circumscribed) KBs with acyclic TBoxes. In the case of ALC,
ALCI, ALCQ, and ALCQO, the latter problem is PSpace-complete (Baader, McGuiness,
Nardi, & Patel-Schneider, 2003; Baader, Milicic, Lutz, Sattler, & Wolter, 2005b; Y. Ding
& Wu, 2007) while the former is ExpTime-complete (Baader et al., 2003). The only
DLs considered in this paper for which satisfiability is ExpTime-hard already with acyclic
TBoxes are ALCIO and its extensions (Areces, Blackburn, & Marx, 2000). We show that,
for circumscribed KBs, there is no difference in computational complexity between acyclic
and general TBoxes.
Let C0 be a concept and CircCP (T , A) a cKB with CP = (, M, F, V ). We may assume
.
without loss of generality that T = {> = C} for some concept C. (To see this, observe that
.
axioms C v D are equivalent to > = C t D). Define
.
.
.
.
 an acyclic TBox T 0 = {A = C, B = u.A, A0 = A, B 0 = B}, where A, B, A0 , B 0 , u
are new concept and role names not occurring in T , A, M , F , V , and C0 .
 a circumscription pattern CP0 = (, M 0 , F, V 0 ), where M 0 = M  {A0 , B 0 } and V 0 =
V  {A, B, u}.
We will ad B 0 conjunctively to C0 and thus be interested in models of CircCP0 (T 0 , A) where
(B 0 )I 6= . In such models, we have AI = I (and thus C I = I ) since, otherwise, we
can turn each instance d of B 0 into an instance of B 0 by making d an instance of B and
727

fiBonatti, Lutz, & Wolter

linking it via the role u to an instance of A, thus obtaining a more preferred model w.r.t.
<CP0 . This is the basis of the proof of the following lemma, given in the appendix.
Lemma 6 C0 is satisfiable w.r.t. CircCP (T , A) iff C0 uB 0 is satisfiable w.r.t. CircCP0 (T 0 , A).
Thus, we have obtained the following result.
Proposition 7 Let L  DL. Satisfiability w.r.t. (concept-)circumscribed KBs in L can be
polynomially reduced to satisfiability w.r.t. (concept-)circumscribed KBs in L with acyclic
TBoxes and without changing the ABox.
This shows that satisfiability w.r.t. cKBs with acyclic TBoxes is of the same complexity as
satisfiability w.r.t. cKBs with general TBoxes. In many cases considered in this paper, the
same is even true for cKBs with empty TBoxes, c.f. Section 4. However, we also identify
cases where cKBs with non-empty TBoxes have higher complexity (see Theorems 24 and 28),
and thus a general reduction as the one underlying Proposition 7 cannot exist for the case
of empty TBoxes.
3.3 Simultaneous Satisfiability
In applications, it is often necessary to merge TBoxes, ABoxes, and whole knowledge bases
by taking their union. We show that, under certain conditions, reasoning w.r.t. the union
of several circumscribed KBs can be reduced to reasoning w.r.t. the component cKBs. A
concept C is simultaneously satisfiable w.r.t. cKBs CircCP1 (T1 , A1 ), . . . , CircCPk (Tk , Ak ) if
there exists an interpretation I that is a model of all the cKBs and satisfies C I 6= .
The following lemma says that simultaneous satisfiability can be polynomially reduced to
satisfiability w.r.t. a single cKB if there are no two cKBs that share a role name.
The proof idea for the case k = 2 is as follows. Given CircCP1 (T1 , A1 ) and CircCP2 (T2 , A2 ),
we first take the union of these two cKBs, replacing in CircCP2 (T2 , A2 ) each concept name
A that is also used in CircCP1 (T1 , A1 ) with a fresh concept name A0 . We then introduce an
additional concept name P (for problem) and make sure that P is satisfied by each ABox
individual whenever there is a point in the model where the interpretation of A and A0
disagrees. We then look for a model where P is not satisfied in the ABox. Intuitively, the
additional concept name P satisfies the purpose of decoupling A and A0 , which is important
e.g. in the case where A/A0 is minimized both in CircCP1 (T1 , A1 ) and CircCP2 (T2 , A2 ). Details
are given in the appendix.
Lemma 8 For all L  DL, simultaneous satisfiability w.r.t. (concept-)circumscribed KBs
CircCP1 (T1 , A1 ), . . . CircCPk (Tk , Ak ), such that CircCPi (Ti , Ai ) and CircCPj (Tj , Aj ) share no
role names for 1  i < j  k, can be reduced in polynomial time to satisfiability w.r.t. single
(concept-)circumscribed KBs.

4. The Complexity of Reasoning in Concept-Circumscribed KBs
The main contributions of this paper consist in (i) showing that, in many cases, reasoning
with circumscribed knowledge bases is decidable; and (ii) performing a detailed analysis
728

fiThe Complexity of Circumscription in DLs

of the computational complexity of these decidable cases. In this section, we show that
satisfiability w.r.t. concept-circumscribed KBs is NExpNP -complete for the DL ALC and
its extensions ALCIO and ALCQO. We also show that it is NPNExp -complete if the number
of fixed and minimized concept names is bounded by a constant. We first present proofs of
the upper bounds and then establish matching lower bounds.
4.1 Upper Bounds
We start with the general case in which there is no bound on the number of fixed and
minimized predicates.
4.1.1 The General Case
We prepare the upper bound proof by showing that if a concept is satisfiable w.r.t. a
concept-circumscribed KB, then it is satisfiable in a model of bounded size. We use |C| to
denote the length of the concept C, i.e.,
P the number of (occurrences of) symbols needed to
write C. The size |T | of a TBox T is CvDT |C| + |D|, and the size |A| of an ABox A is
the sum of the sizes of all assertions in A, where the size of each role assertion is 1 and the
size of concept assertions C(a) is |C|.
Lemma 9 Let C0 be a concept, CircCP (T , A) a concept-circumscribed KB, and n := |C0 | +
|T | + |A|. If C0 is satisfiable w.r.t. CircCP (T , A), then the following holds:
(i) If T , A and C0 are formulated in ALCIO, then C0 is satisfied in a model I of
CircCP (T , A) with #I  22n .
(ii) If T , A and C0 are formulated in ALCQO and m is the maximal parameter occurring in a number restriction in T , A, or C0 , then C0 is satisfied in a model I of
CircCP (T , A) with #I  22n  (m + 1)  n.
Proof. Let CP, T , A, and C0 be as in Lemma 9. We may assume that A =  as every
assertion C(a) can be expressed as an implication {a} v C, and every assertion r(a, b) can
be expressed as {a} v r.{b}. Denote by cl(C, T ) the smallest set of concepts that contains
all subconcepts of C, all subconcepts of concepts appearing in T , and is closed under single
negations (i.e., if D  cl(C, T ) and D does not start with , then D  cl(C, T )).
Let I be a common model of C0 and CircCP (T , A), and let d0  C0I . Define an equivalence relation  on I by setting d  d0 iff
{C  cl(C0 , T ) | d  C I } = {C  cl(C0 , T ) | d0  C I }.
We use [d] to denote the equivalence class of d  I w.r.t. the  relation. Pick from each
equivalence class [d] exactly one member and denote the resulting subset of I by 0 .
We first prove Point (i). Thus, assume that T and C0 are formulated in ALCIO. We
define a new interpretation J as follows:
J

:= 0

AJ

:= {d  0 | d  AI }

rJ

:= {(d1 , d2 )  0  0 | d01  [d1 ], d02  [d2 ] : (d01 , d02 )  rI }

aJ

:= d  0 if aI  [d].
729

fiBonatti, Lutz, & Wolter

The following claim is easily proved using induction on the structure of C.
Claim: For all C  cl(C0 , T ) and all d  I , we have d  C I iff d0  C J for the element
d0  [d] of J .
Thus, J is a model of T satisfying C0 . To show that J is a model of CircCP (T , A), it thus
remains to show that there is no model J 0 of T with J 0 <CP J . Assume to the contrary
that there is such a J 0 . We define an interpretation I 0 as follows:
I

0

AI

0

:= I
[
[d]
:=
dAJ 0

r

I0

[

:=

(d1 ,d2
0
aI

[d1 ]  [d2 ]

)rJ 0

:= aI .

It is a matter of routine to show the following:
0

0

Claim: For all concepts C  cl(C0 , T ) and all d  I , we have d  C I iff d0  C J for the
element d0  [d] from J .
0

0

It follows that I 0 is a model of T . Observe that AI fi AI iff AJ fi AJ for each concept
name A and fi  {, }. Therefore  and since CP is a concept circumscription pattern 
I 0 <CP I follows from J 0 <CP J . We have derived a contradiction and conclude that J is
a model of CircCP (T , A). Thus we are done since the size of J is bounded by 22n .
Now for Point (ii). Pick, for each d  0 and each concept (> k r C)  cl(C0 , T )
such that d  (> k r C)I , k elements from {d0 | d0  C I , (d, d0 )  rI }. Also pick, for
each concept (6 k r C)  cl(C0 , T ) such that d  ((6 k r C))I , k + 1 elements from
{d0 | d0  C I , (d, d0 )  rI }. Denote by 00 the collection of the elements picked. Take for
each d  00 \ 0 an element ds  0 such that d  ds and define an interpretation J by
J

:= 0  00

AJ

:= {d  0  00 | d  AI }

rJ

:= {(d1 , d2 )  0  (0  00 ) | (d1 , d2 )  rI }
{(d1 , d2 )  (00 \ 0 )  (0  00 ) | (ds1 , d2 )  rI }

aJ

:= d if aI  [d].

The following claim is easily proved.
Claim: For all C  cl(C0 , T ), we have the following:
(i) for all d, d0  J , if d  d0 , then d  C J iff d0  C J ;
(ii) for all d  I , we have d  C I iff d0  C J for some element d0  [d] of J .
Thus, J is a model of T satisfying C0 . To show that J is a model of CircCP (T , A), it
thus remains to show that there is no model J 0 of T with J 0 <CP J . Assume to the
contrary that there is such a J 0 . We define an interpretation I 0 . To this end, take for each
730

fiThe Complexity of Circumscription in DLs

d  I \ J the dp  0 such that d  dp . Now define I 0 as follows
I
A

0

I0

:= I
0

0

:= AJ  {d  I \ J | dp  AJ }

rI

0

:= rJ  {(d1 , d2 )  (I \ J )  I | (dp1 , d2 )  rJ }

aI

0

:= aI .

0

0

Again, it is a matter of routine to show:
0

Claim: For all concepts C  cl(C0 , T ) and all d  I , we have d  C I  J iff d  C J
0
0
and d  C I  (I \ J ) iff dp  C J for the element dp  [d] from 0 .
0

0

0

It follows that I 0 is a model for T . Observe that AI fi AI iff AJ fi AJ for each concept
name A and fi  {, }. Therefore  and since CP is a concept circumscription pattern
 I 0 <CP I follows from J 0 <CP J . We have derived a contradiction and conclude that
J is a model of CircCP (T , A). Thus we are done since the size of J is clearly bounded
by 22n  (m + 1)  n.
o
It is interesting to note that the proof of Lemma 9 does not go through if role names are
minimized or fixed. This problem cannot be overcome, as proved by the undecidability
results presented in Sections 5 and 6.
Using the bounded model property just established, we can now prove decidability
of reasoning with concept-circumscribed KBs formulated in ALCIO and ALCQO. More
precisely, Lemma 9 suggests a non-deterministic decision procedure for satisfiability w.r.t.
concept circumscription patterns: simply guess an interpretation of bounded size and then
check whether it is a model. It turns out that this procedure shows containment of satisfiability in the complexity class NExpNP , which contains those problems that can be solved
by a non-deterministic exponentially time-bounded Turing machine that has access to an
NP oracle. It is known that NExp  NExpNP  ExpSpace.
Theorem 10 In ALCIO and ALCQO, it is in NExpNP to decide whether a concept is
satisfiable w.r.t. a concept-circumscribed KB CircCP (T , A).
Proof. It is not hard to see that there exists an NP algorithm that takes as input a
cKB CircCP (T , A) and a finite interpretation I, and checks whether I is not a model of
CircCP (T , A): the algorithm first verifies in polynomial time whether I is a model of T and
A, answering yes if this is not the case. Otherwise, the algorithm guesses an interpretation
J that has the same domain as I and interprets all individual names in the same way, and
then checks whether (i) J is a model of T and A, and (ii) J <CP I. It answers yes if
both checks succeed, and no otherwise. Clearly, checking whether J <CP I can be done
in time polynomial w.r.t. the size of J and I.
This NP algorithm may now be used as an oracle in a NExp-algorithm for deciding
satisfiability of a concept C0 w.r.t. a cKB CircCP (T , A): by Lemma 9, it suffices to guess
an interpretation of size 24k with k = |C0 | + |T | + |A|,3 and then use the NP algorithm
to check whether I is a model of CircCP (T , A). This proves that concept satisfiability is in
NExpNP .
o
3. The bound 24k clearly dominates the two bounds given in Parts (i) and (ii) of Lemma 9.

731

fiBonatti, Lutz, & Wolter

By the reductions given in Section 2, Theorem 10 yields co-NExpNP upper bounds for
subsumption and the instance problem. We will show in Section 4.2 that these upper
bounds are tight.
4.1.2 Bounded Number of Minimized and Fixed Predicates
Since NExpNP is a rather large complexity class, it is a natural question whether we can
impose restrictions on concept circumscription such that reasoning becomes simpler. In the
following, we identify such a case by considering concept-circumscribed KBs in which the
number of minimized and fixed concept names is bounded by some constant. In this case, the
complexity of satisfiability w.r.t. concept-circumscribed KBs drops to NPNExp . For readers
uninitiated to oracle complexity classes, we recall that NExp  NPNExp  NExpNP , and
that NPNExp is believed to be much less powerful than NExpNP , see for example the work
by Eiter et al. (2004).
To prove the NPNExp upper bound, we first introduce counting formulas as a common
generalization of TBoxes and ABoxes.
Definition 11 (Counting Formula) A counting formula  is a Boolean combination of
concept implications, ABox assertions C(a), and cardinality assertions (C = n) where C
is a concept and n a non-negative integer. We use , ,  and  to denote the Boolean
operators of counting formulas. An interpretation I satisfies a cardinality assertion (C = n)
if #C I = n. The satisfaction relation I |=  between models I and counting formulas  is
defined in the obvious way.
4
In the following, we assume that the integers occurring in cardinality assertions are coded
in binary. The NPNExp algorithm to be devised will use an algorithm for satisfiability of
(non-circumscribed) counting formulas as an oracle. Therefore, we should first determine
the computational complexity of the latter. It follows from results by Tobies (2000) that,
in ALC, satisfiability of counting formulas is NExp-hard. A matching upper bound for
the DLs ALCIO and ALCQO is obtained from the facts that (i) there is a polynomial
translation of counting formulas formulated in these languages into C2, the two-variable
fragment of first-order logic extended with counting quantifiers (Gradel, Otto, & Rosen,
1997; Pacholski, Szwast, & Tendera, 2000), and (ii) satisfiability in C2 is in NExp even if
the numbers in counting quantifiers are coded in binary (Pratt-Hartmann, 2005).
Theorem 12 (Tobies, Pratt) In ALC, ALCIO and ALCQO, satisfiability of counting
formulas is NExp-complete even if numbers in number restrictions are coded in binary.
We now establish the improved upper bound.
Theorem 13 Let c be a constant. In ALCIO and ALCQO, it is in NPNExp to decide satisfiability w.r.t. concept-circumscribed KBs CircCP (T , A), where CP = (, M, F, V ) is such
that #M  c and #F  c.

732

fiThe Complexity of Circumscription in DLs

Proof. Assume that we want to decide satisfiability of the concept C0 w.r.t. the cKB
CircCP (T , A), where CP = (, M, F, V ) with #M  c and #F  c. By Lemma 4, we
may assume that F =  (we may have to increase the constant c appropriately). We
may assume without loss of generality that the cardinality of M is exactly c. Thus, let
M = {A0 , . . . , Ac }. By Lemma 9, C0 is satisfiable w.r.t. CircCP (T , A) iff there exists a
model of C0 and CircCP (T , A) of size 24k , with k = |C0 | + |T | + |A|. Consider, for all
S  M , the concept
CS :=
Au
A.

u

AS

u

A{A1 ,...,Ac }\S

As c is constant, the number 2c of such concepts is constant as well. Clearly, the sets CSI ,
S  M , form a partition of the domain I of any model I. Introduce, for each concept
name B and role name r in T  A, a fresh concept name B 0 and a fresh role name r0 ,
respectively. For a concept C, denote by C 0 the result of replacing in C each concept name
B and role name r with B 0 and r0 , respectively. The primed versions A0 and T 0 of A and
T are defined analogously. Denote by N the set of individual names in T  A  {C0 }.
The NExp-oracle we are going to use in our algorithm checks whether a counting formula
 is satisfiable or not. Now, the NPNExp -algorithm is as follows (we use C @ D as an
abbreviation for the counting formula (C v D)  (D v C)):
1. Guess
 a sequence (nS | S  M ) of numbers nS  24k coded in binary;
 for each individual name a  N , exactly one set Sa  M ;
 a subset E of N  N .
2. By calling the oracle, check whether the counting formula 1 is satisfiable, where 1
is the conjunction over
 T  A  {(C0 = 0)};
 (CS = nS ), for all S  M ;
 CSa (a), for each a  N ;
 {({a} v {b}) | (a, b)  E}  {({a} v {b}) | (a, b)  N  E}.
3. By calling the oracle, check whether the counting formula 2 is satisfiable, where 2
is the conjunction over
 T 0  A0 ;
 (CS = nS ), for all S  M (note that we use the unprimed versions);
 CSa (a), for each individual name a  N (we use the unprimed versions);
 {({a} v {b}) | (a, b)  E}  {({a} v {b}) | (a, b)  N  E};
 for all A  M ,
(A0 v A) 

_
BM,BA

733

(B 0 @ B);

fiBonatti, Lutz, & Wolter

 and, finally,
_

^

(A0 @ A) 

AM


.
(B = B 0 ) .

BM,BA

4. The algorithm states that C0 is satisfiable in a model of CircCP (T , A) if, and only if,
1 is satisfiable and 2 is not satisfiable.
Using the fact that c is fixed, is is not hard to verify that this is a NPNExp -algorithm. It
remains to show correctness and completeness.
Suppose that there exists a model of CircCP (T , A) satisfying C0 . Then there is such a
model I of size bounded by 24k . Let the algorithm guess
 the numbers nS = #CSI , S  M ,
 the sets Sa such that aI  CSIa ,
 the set E = {(a, b), (b, a) | aI = bI , a, b  N }.
Clearly, 1 is satisfied in I. It remains to show that 2 is unsatisfiable. But suppose there
exists a model J satisfying 2 . By the definitions of 1 and 2 , we may assume that
 I = J ;
 AI = AJ for all A  M ;
 aI = aJ for all individual names a.
Moreover, as no unprimed role names occur in 2 and the only unprimed concept names in
2 are those in M , we may assume that the interpretation of all unprimed concept and role
names in I and J coincide. Thus, J is a model of CircCP (T , A) satisfying C0 . But now
define a model J 0 with domain J by setting
0

 aJ = aJ , for all individual names a;
0

 rJ = (r0 )J , for all role names r;
0

 AJ = (A0 )J , for all concept names A.
Then, by the conjunct under Item 1 of the definition of 2 , J 0 is a model for A  T . By
Items 5 and 6 of the definition of 2 , J 0 <CP J , and we have derived a contradiction.
Conversely, suppose the algorithm says that there exists a model of CircCP (T , A) satisfying C0 . Then take a model I for 1 . By the conjunct under Item 1 of 1 , I is a model
for T  A satisfying C0 . It follows from the unsatisfiability of 2 that I is a model for
CircCP (T , A).
o

734

fiThe Complexity of Circumscription in DLs

As a corollary, we obtain co-NPNExp upper bounds for subsumption and the instance problem. A similar drop of complexity occurs in propositional logic, where satisfiability w.r.t.
circumscribed theories is complete for NPNP and it is not difficult to see that bounding the
minimized and fixed predicates allows us to find a PNP algorithm.
4.2 Lower Bounds
We prove lower complexity bounds for reasoning with concept-circumscribed KBs that
match the upper bounds given in Section 4.1.
4.2.1 The General Case
As in Section 4.1, we start with the general case in which the number of fixed and minimized
predicates is not bounded. Our aim is to establish two NExpNP -lower bounds that both
match the upper bound established in Theorem 10. The first bound is for satisfiability w.r.t.
concept-circumscribed KBs that are formulated in ALC and have an empty TBox, but a nonempty ABox. The second bound is also for satisfiability w.r.t. concept-circumscribed KBs
formulated in ALC, but assumes an acyclic TBox and empty ABox. Both reductions work
already in the case of an empty preference relation, and without any fixed predicates. Note
that considering satisfiability of a concept C w.r.t. a concept-circumscribed KB CircCP (T , A)
with both T and A empty is not very interesting: it can be seen that C is satisfiable w.r.t.
CircCP (T , A) iff C is satisfiable (without reference to any KB), where C is the concept
obtained from C by replacing all minimized concept names with .
The proof of our first result is by reduction of a succinct version of the problem coCERT3COL, which is NExpNP -complete (Eiter, Gottlob, & Mannila, 1997), to satisfiability
w.r.t. concept-circumscribed KBs with empty TBox. Let us first introduce the regular (nonsuccinct) version of co-CERT3COL:
Instance of size n: an undirected graph G on the vertices {0, 1, . . . , n  1} such that every
edge is labelled with a disjunction of two literals over the Boolean variables {Vi,j | i, j < n}.
Yes-Instance of size n: an instance G of size n such that, for some truth value assignment
t to the Boolean variables, the graph t(G) obtained from G by including only those edges
whose label evaluates to true under t is not 3-colorable.
As shown by Stewart (1991), co-CERT3COL is complete for NPNP . To obtain a problem
complete for NExpNP , Eiter et al. use the complexity upgrade technique: by encoding the
input in a succinct form using Boolean circuits, the complexity is raised by one exponential
to NExpNP (Eiter et al., 1997). More precisely, the succinct version co-CERT3COLS of
co-CERT3COL is obtained by representing the input graph G with nodes {0, . . . , 2n  1}
as 4n + 3 Boolean circuits with 2n inputs (and one output) each. The Boolean circuits are
(1)
(2)
(i)
named cE , cS , cS , and cj , with i  {1, 2, 3, 4} and j < n. For all circuits, the 2n inputs
are the bits of the binary representation of two nodes of the graph. The purpose of the
circuits is as follows:
 circuit cE outputs 1 if there is an edge between the two input nodes, and 0 otherwise;
(1)

 if there is an edge between the input nodes, circuit cS outputs 1 if the first literal
(2)
in the disjunction labelling this edge is positive, and 0 otherwise; circuit cS does the
735

fiBonatti, Lutz, & Wolter

same for the second literal; if there is no edge between the input nodes, the output is
arbitrary;
(i)

 if there is an edge between the input nodes, the circuits cj compute the labelling
Vk1 ,k2 Vk3 ,k4 of this edge between the input nodes by generating the numbers k1 , . . . , k4 :
(i)
circuit cj outputs the j-th bit of ki ; if there is no edge between the input nodes, the
output is arbitrary.
We reduce co-CERT3COLS to satisfiability w.r.t. concept-circumscribed KBs that are formulated in ALC and whose TBox and preference relation are empty. It then remains to
apply Lemma 5 to eliminate fixed concept names (we note that the construction in the
proof of the lemma leaves the preference relation untouched). Let
(1)

(2)

(i)

G = (n, cE , cS , cS , {cj }i{1,..,4},j<n )
be the (succinct representation of the) input graph with 2n nodes. We construct an ABox
AG = {C0 u Root(a0 )}, a circumscription pattern CPG , and a concept CG such that G is a
yes-instance of co-CERT3COLS iff CG is satisfiable w.r.t. CircCPG (, AG ).
The concept C0 used in AG is a conjunction whose presentation is split into two parts.
Intuitively, the purpose of the first group of conjuncts is to fix a truth assignment t for
the variables {Vi,j | i, j < n}, and to construct (an isomorphic image of) the graph t(G)
obtained from G by including only those edges whose label evaluates to true under t. Then,
the purpose of the second group is to make sure that t(G) is not 3-colorable.
When formulating C0 , we use several binary counters for counting modulo 2n (the
number of nodes in the input graph). The main counters X and Y use concept names
X0 , . . . , Xn1 and Y0 , . . . , Yn1 as their bits, respectively. Additionally, we introduce concept
(i)
(i)
names K0 , . . . , Kn1 , i  {1, 2, 3, 4}, that serve as four additional counters K (1) , . . . , K (4) .
The first group of conjuncts of C0 can be found in Figure 2, where the following abbreviations
are used:
 ri .C denotes the n-fold nesting r.    .r.C;
 r.(K (i) = X) is an abbreviation for

u

j<n

(i)
(i) 
(Xj  r.Kj ) u (Xj  r.Kj ) and

similarly for r.(K (i) = Y );
 the abbreviations Wc , c a Boolean circuit, are explained later on.
The intuition behind Figure 2 is as follows. Lines (1) to (5) build up a binary tree of depth
2n whose edges are labeled with the role name r. The 22n leaves of the tree are instances
of the concept name Leaf, and they are labeled with all possible values of the counters X
and Y . Since we will minimize Leaf via the circumscription pattern CPG , this concept name
denotes precisely the leaves of the tree. Due to the use of the counters X and Y , the leaves
are all distinct.
The leaves of the tree just established satisfy a number of purposes. To start with,
each leaf with counter values X = i and Y = j corresponds to the variable Vi,j of co3CERTCOLS and determines a truth value for this variable via truth/falsity of the concept
736

fiThe Complexity of Circumscription in DLs

ri .(r.Xi u r.Xi )
j

r .((Xi  r.Xi ) u (Xi  r.Xi ))
r
r

n+j

n+i

.(r.Yi u r.Yi )

.((Yi  r.Yi ) u (Yi  r.Yi ))

for i < n

(1)

for i < n, j < 2n

(2)

i<n

(3)

for i < j < n

(4)

2n

r .Leaf

(5)

r2n .(WcE u Wc(1) u Wc(2) )

(6)

S

S

r2n .(Wc(1) u    u Wc(4) )
j

for j < n

r2n .(var1.LeafFix u var1.(K (1) =X) u var1.(K (2) =Y ))
2n

r .(var2.LeafFix u var2.(K

(3)

(7)

j

=X) u var2.(K

(4)

(8)

=Y ))

(9)

2n

P  r .var1.Leaf

(10)

2n

P  r .var2.Leaf

(11)

r2n .(S1  (Tr1  var1.Tr))

(12)

2n

r .(S1  (Tr1  var1.Tr))
2n

r .(S2  (Tr2  var2.Tr))
2n

(13)
(14)

r .(S2  (Tr2  var1.Tr))

(15)

2n

(16)

r .(Elim  (E t (Tr1 t Tr2 )))
Figure 2: The first group of conjuncts of C0 .

name Tr. Thus, the leaves jointly describe a truth assignment t for the instance G of co3CERTCOLS . A second purpose of the leaves is to represent the potential edges of G:
additionally to representing a variable, a leaf with X = i and Y = j corresponds to the
potential edge between the nodes i and j. To explain this more properly, we must first
discuss the abbreviations Wc used in Lines (6) and (7) of Figure 2.
Each concept Wc , c a Boolean circuit with 2n inputs, is the result of converting c into a
concept that uses only the constructors , u, t such that the following condition is satisfied:
if a d  I is an instance of Wc , the output of c upon input b0 , . . . , b2n1 is b, and the truth
value of the concept names X0 , . . . , Xn1 , Y0 , . . . , Yn1 at d is described by b0 , . . . , b2n1 ,
then the truth value of some concept name Out at d is described by b. By introducing one
auxiliary concept name for every inner gate of c, the translation can be done such that the
size of Wc is linear in the size of c. The following concept names are used as output:
 WcE uses the concept name E as output;
 Wc(i) uses the concept name Si as output, for i  {1, 2};
S

(i)

 Wc(i) uses the concept name Kj

as output, for i  {1, . . . , 4} and j < n.

j

737

fiBonatti, Lutz, & Wolter

r2n .(col1.LeafFix u col2.LeafFix)
2n

r .(col1.(X = X) u col1.(Y = 0))
2n

r .(col2.(Y = X) u col2.(Y = 0))

(17)
(18)
(19)

2n

(20)

2n

P  r .col2.Leaf

(21)

r2n .((Y = 0)  (R t B t G))

(22)

r .((Y = 0)  ((R u B) u (R u G) u (B u G)))

(23)

r2n .((Elim u col1.R u col2.R)  Clash)

(24)

r2n .((Elim u col1.G u col2.G)  Clash)

(25)

r2n .((Elim u col1.B u col2.B)  Clash)

(26)

P  r .col1.Leaf

2n

Figure 3: The second group of conjuncts of C0 .
Lines (6) and (7) ensure that these concepts are propagated to all leaves. Our next aim is to
ensure that each leaf that represents a potential edge (i, j) is connected via the role var1 to
the leaf that represents the variable in the first disjunct of the label of (i, j), and analogously
for the role var2 and the variable in the second disjunct of the edge label. If we replaced
the concept name LeafFix with Leaf in Lines (8) and (9), then these lines would apparently
encode these properties. However, we have to be careful as the mentioned replacement
would interact with the minimization of Leaf. To fix this problem, we resort to a trick: we
use the concept name LeafFix instead of Leaf. In this way, we may or may not reach an
instance of Leaf. If we do not, we force the concept name P to be true at the root of the
tree in Lines (10) and (11). We will use CG to rule out models in which P is true. Finally,
we fix LeafFix via CPG to eliminate interaction with the minimization of Leaf.
The remaining Lines (12) to (16) ensure that a leaf is an instance of Elim iff the potential
edge that it represents is not present in the graph t(G) induced by the truth assignment t
described by the leaves.
The second group of conjuncts of C0 can be found in Figure 3. Here, (Y = 0) stands
for the concept (Y0 u    u Yn1 ). As already mentioned, the purpose of these conjuncts
is to ensure that the graph t(G) described by the leaves does not have a 3-coloring. The
strategy for ensuring this is as follows: we use the 2n leaves with Y = 0 to store the colors
of the nodes, i.e., the leaf with X = i and Y = 0 stores the color of node i. By Lines (22)
and (23), there is a unique coloring. Then, Lines (17) to (21) ensure that each leaf (viewed
as an edge) is connected via the role col1 to the leaf that stores the color of the first node
of the edge, and analogously for the role col2 and the second node of the edge. LeafFix and
P have the same role as before. Lines (24) to (26) guarantee that the concept name Clash
identifies problems in the coloring: a leaf is in Clash if it represents an edge that exists
in G, is not dropped in t(G), and where both endpoints have the same color. The idea
is that Clash will be minimized while R, G, and B vary. When some additional concept
names are fixed, this corresponds to a universal quantification over all possible colorings.
738

fiThe Complexity of Circumscription in DLs

Set CG = Root u P u r2n .Clash, and recall that AG = {C0 u Root(a0 )}. The following
lemma is proved in the appendix.
Lemma 14 G is a yes-instance of co-3CERTCOLS iff CG is satisfiable with respect to
CircCPG (, AG ), where CPG = (, M, F, V ) with  = , M = {Root, Leaf, Clash},
F = {LeafFix, Tr, X0 , . . . , Xn1 , Y0 , . . . , Yn1 , },
and V the set of all remaining predicates in AG .
Since the size of AG is polynomial in n, we get the following result by applying Lemma 5.
Theorem 15 In ALC, satisfiability w.r.t. concept-circumscribed KBs is NExpNP -hard even
if the TBox and the preference relation are empty and there are no fixed predicates.
It is now rather straightforward to establish the announced second NExpNP lower bound by
a reduction of satisfiability w.r.t. concept-circumscribed KBs in the special case formulated
in Theorem 15. Details are given in the appendix.
Corollary 16 In ALC, satisfiability w.r.t. concept-circumscribed KBs is NExpNP -hard
even if the TBox is acyclic, the ABox and preference relations are empty, and there are no
fixed predicates.
Corresponding lower bounds for subsumption and the instance problems follow from the
reduction given in Section 2.
4.2.2 Bounded Number of Minimized and Fixed Predicates
We now establish a matching lower bound for Theorem 13 by showing that, in ALC, satisfiability w.r.t. concept-circumscribed KBs is NPNExp -hard even if only a constant number
of predicates is allowed to be minimized and fixed. In contrast to the previous section,
we ignore the case of empty TBoxes and directly establish the lower bound for the case
of non-empty TBoxes and empty ABoxes. This allows us to demonstrate the usefulness of
Lemma 8 for separating different parts of a lower bound proof: in the main reduction from
the previous section, the two parts of the reduction shown in Figure 2 and 3 are not truly
independent, which forced us to implement the technical trick that involves the concept
names LeafFix and P . When using Lemma 8, in contrast, we achieve a true separation of
concerns. In general, though, we conjecture that the lower bound proved in this section can
also be established for the case of empty TBoxes by adapting the mentioned technical trick.
We leave this as a problem to the interested reader.
Recall that a (non-deterministic) k-tape Turing machine is described by a tuple
(Q, , q0 , , qacc , qrej ),
with Q a finite set of states,  a finite alphabet, q0  Q a starting state,
  Q  k  Q  k  {L, R}k
a transition relation, and qacc , qrej  Q the accepting and rejecting states. For our purposes,
an oracle Turing machine is a 2-tape Turing machine M that, additionally, is equipped
with
739

fiBonatti, Lutz, & Wolter

 a 1-tape Turing machine M0 (the oracle) whose alphabet is identical to that of M,
 a query state q? , and
 two answer states qyes and qno .
The second tape of M is called the oracle tape. When M enters q? , the oracle determines the
next state of M: if the content of the oracle tape is contained in the language accepted by
the oracle, the next state is qyes . Otherwise, it is qno . During this transition, the head is not
moved and no symbols are written. The state q? cannot occur as the left-most component
of a tuple in Ms transition relation.
Let M = (Q, , q0 , , qacc , qrej , M0 , q? , qyes , qno ) be an oracle Turing machine such that
the following holds:
 M solves an NPNExp -complete problem;
 the time consumption of M is bounded by a polynomial p (where oracle calls contribute with a single clock tick);
0 , q 0 ) is bounded by 2q(n) , with q a
 the time consumption of M0 = (Q0 , , q00 , 0 , qacc
rej
polynomial.

We assume without loss of generality that M and M0 never attempt to move left from the
left-most position of the tape (neither right from the right-most position). Our NPNExp hardness proof uses a reduction of the word problem of M. Thus, let w   be an input
for M of length n, and let m = p(n) and m0 = q(p(n)). We construct three TBoxes
Tw , Tw0 , and Tw00 , circumscription patterns CP, CP0 , and CP00 , and a concept Cw such that
M accepts w iff Cw is simultaneously satisfiable w.r.t. CircCP (Tw , ), CircCP0 (Tw0 , ), and
CircCP00 (Tw00 , ). Then, Lemma 8 yields a reduction to (non-simultaneous) satisfiability w.r.t.
concept-circumscribed cKBs. Intuitively, the purpose of the first TBox Tw is to impose a
basic structure on the domain, while Tw0 describes computations of M, and Tw00 describes
computations of M0 . We use general TBoxes rather than acyclic ones since, by Lemma 6,
this can be done without loss of generality.
The TBox Tw is shown in Figure 4. As in the previous reduction, we use concept
names X0 , . . . , Xm0 1 and Y0 , . . . , Ym0 1 to implement two binary counters for counting
0
modulo 2m . We also use the same abbreviations as in the previous reduction. Additionally,
r.(X++) states that the value of the counter X0 , . . . , Xm0 1 is incremented when going to
r-successors, i.e.,


Xj  (Xk  r.Xk ) u (Xk  r.Xk )
0

u
u

k=0..m 1

k=0..m0 1

u
t

j=0..k1

j=0..k1



Xj  (Xk  r.Xk ) u (Xk  r.Xk )

The purpose of Lines (27) to (30) is to ensure that, for each possible value (i, j) of the
counters X and Y , there is at least one instance of NExp that satisfies (X = i) and (Y = j).
0
0
We minimize NExp, and thus enforce that NExp has exactly 2m  2m elements. These
0
0
elements are interconnected via the roles r (for right) and u (for up) to form a 2m 2m grid. Later on, we use this grid to encode computations of the oracle machine M0 . Observe
740

fiThe Complexity of Circumscription in DLs

> v aux.NExp
m0

NExp v ((X = 2

(27)
m0

 1)  r.NExp) u ((Y = 2

 1)  u.NExp)

(28)

NExp v r.(Y =Y ) u r.(X++)

(29)

NExp v u.(X=X) u u.(Y ++)

(30)

> v
Result v

u aux.(Result u R )
u (R u R )

(31)

i

i<m

i

i<j<m

(32)

j

> v aux.NP

(33)
Figure 4: The TBox Tw .

that, since we are working with simultaneous satisfiability, the minimization of NExp does
not interact with anything that we are going to put into the TBoxes Tw0 and Tw00 .
We also minimize the concept name Result, and thus Lines (31) and (32) guarantee that
there are exactly m instances of Result, identified by the concept names R0 , . . . , Rm1 . If
M makes a call to the oracle in the i-th step, then the result of this call will be stored
in the (unique) instance of Result u Ri , i.e., this instance will satisfy the concept name Rej
if M0 rejected the input and falsify it otherwise. Finally, we also minimize NP, and thus
Line (33) guarantees that there is exactly one instance of NP. This instance will be used to
represent the computation of M. Summing up, the circumscription pattern for Tw is
CP := (, {NExp, Result, NP}, , V ),
with V containing all remaining predicates used in Tw .
The purpose of Tw0 is to describe computations of M. We use the following concept
names:
 For all a  , i, j < m, and k  {1, 2}, we introduce a concept name Sai,j,k . Intuitively,
Sai,j,k expresses that a is the symbol in the j-th cell of the k-th tape in the i-th step
of Ms computation. We start our numbering of tape cells and steps with 0.
 For all q  Q and i < m, Qiq is a concept name expressing that M is in state q in the
i-th step of the computation.
 For all q  Q, i, j < m, and k  {1, 2}, Hji,k is a concept name expressing that the
k-th head of M is on cell j in the i-th step of the computation.
 For all q  Q, a  , i, j < m, k  {1, 2}, and M  {L, R}, concept names Aiq , Ai,j,k
a ,
i,k
i
AM that serve as markers. More precisely, Aq means that, at time point i, M has
executed a transition that switches to state q. Similarly, Ai,j,k
describes the symbol
a
i,k
written in that transition on tape k, and AM describes the move on tape k.
The details of Tw0 are given in Figure 5. One copy of the concept inclusions in this figure
are needed for every i, j, j 0 < m and every k  {1, 2}. We assume that w = a0    an1 and
741

fiBonatti, Lutz, & Wolter

0,n,1
0,m1,1
NP v Q0q0 u H00,1 u Sa0,0,1
u    Sa0,n1,1
u SB
u    u SB
0
n1

(34)

0,0,2
0,m1,2
NP v H00,2 u SB
u    u SB

(35)

NP v

u

i,j 0 ,2

a,b,qQ\{q? }

(Sai,j,1 u Sb

NP v
NP v
NP v
NP v
NP v

uA
uA

qQ

a
Ai,k
L
i,k
AR

i
q

i,j,k
a

0 ,2
i,2 
Aiq u Ai,j,1
u Ai,j
u Ai,1
a
M u AM 0 ) (37)
b

if i < m  1

(38)

(q,a,b,q 0 ,a0 ,b0 ,M,M 0 )

 Sai+1,j,k

i+1,k
 Hj1

if i < m  1

(39)

if i < m  1 and j > 0

(40)

i+1,k
 Hj+1

if i < m  1 and j < m  1

i+1,j,k
if i < m  1 and j 6= j 0
(Sai,j,k u Hji,k
0 )  Sa

u
u

a

 Qi+1
q

a,b,a6=b

(Sai,j,k u Sbi,j,k ) u

NP v (Hji,k u Hji,k
0 )

(36)

t

(
NP v

u Qiq u Hji,1 u Hji,2
0 ) 

u

q,q 0 Q,q6=q 0

(Qiq u Qiq0 )

if j 6= j 0

(41)
(42)
(43)
(44)

NP v resi .(Result u Ri ) u resi .(Result u Ri )

(45)

NP v (Qiq? u resi .Rej)  Qi+1
qno

(46)

NP v

(Qiq?

u resi .Rej) 

Qi+1
qyes

NP v (Qiq? u Hji,k )  Hji+1,k
NP v

u

a

if i < m  1
if i < m  1

if i < m  1

i+1,j,k

(Qiq? u Sai,j,k )  Sa

(47)
(48)
(49)

Figure 5: The TBox Tw0 .
use B to denote the (shared) blank symbol of M and M0 . Lines (34) to (43) describe the
behaviour of a Turing machine in the usual way: transitions follow the transition table, the
computation starts in the initial configuration, etc. Line (45) ensures that the instance of
NP can reach the (unique) instance of Result u Ri via the role resi , for all i < m. Lines (46)
and (47) deal with transitions of M in the query state by looking up the result of the oracle
call in the corresponding instance of Result. Finally, Lines (48) and (49) ensure that the head
position and tape symbols do not change when querying the oracle. The circumscription
pattern for Tw0 is simply CP0 := (, , , V ), with V the set of all predicates used in Tw0 .
The purpose of Tw00 is to describe computations of the oracle Turing machine M0 . Note
that we have to describe more than a single computation of M0 (but at most polynomially many) since M may visit the state q? more than once. All these computations are
represented in the NExp grid, where different computations are untangled by the use of
different concept names for each computation. We use the counter X0 , . . . , Xm0 1 to count
742

fiThe Complexity of Circumscription in DLs

configurations and the counter Y0 , . . . , Ym0 1 to count the tape cells of each configuration.
Moreover, we use the following concept names:
 For all a   and i < m, a concept name Sai . If Sai is satisfied by some instance of
NExp where X0 , . . . , Xm0 1 has value j and Y0 , . . . , Ym0 1 has value k, then the i-th
computation of M0 has, in its j-th step, symbol a on the k-th cell.
 For all q  Q and i < m, a concept name Qiq . The purpose of this concept name is
two-fold: first, it represents the current state of M0 in the i-th computation. And
second, it indicates the head position in the i-th computation.
 For all a  , q  Q, M  {L, R} and all i < m, a concept name Aiq,a,M as a marker.
The meaning of the marker Aiq,a,M is that, to reach the current configuration, M0 has
switched to q, written a, and moved its head in direction M . Additionally, the marker
indicates the head position in the previous configuration.
 An additional concept name NH (for nohead) that helps us to enforce that M0 has
only a single head position.
The details of Tw00 are shown in Figure 6, where we require one copy of each line for every
i < m. The purpose of Lines (50) and (51) is to regenerate the grid structure of NExp using
the roles r0 und u0 . This is necessary since the roles r and u are used in Tw , and, to use
Lemma 8, the TBoxes cannot share any role names. Lines (52) and (53) ensure that every
instance of NExp reaches (only) the unique instance of NP via the role toNP, and (only) the
unique instance of Result u Ri via the role res0i , for all i < m. Lines (54) to (64) describe the
computation of M0 in a straightforward way. More precisely, Lines (54) to (56) set up the
initial configuration by reading the contents of Ms oracle tape from the instance of NP.
Lines (57) to (61) implement transitions, and Lines (62) to (64) enforce a unique label of
the tape, a unique state, and a unique head position. Finally, Line (65) ensures that, if the
i-th computation of M0 is rejecting, then Rej is true in the instance of Result u Ri .
Note that M0 is a non-deterministic machine and may have more than one computation.
For storing Rej in Result u Ri , we need to know that all these computations are rejecting.
To deal with this issue, Rej is minimized with all other predicates varying: if there exists
an accepting computation of M0 on the i-th input, then we can represent this computation
in NExp and make Rej false in the instance of Result u Ri . Hence, Rej holds at Result u Ri
iff there exists no accepting computation. Note that we cannot fix the concept names
X0 , . . . , Xm0 1 , Y0 , . . . , Ym0 1 while minimizing Rej since we would get an unbounded number
of fixed concept names. This means that the elements of NExp can change their position
during minimization, and with them the roles r0 and u0 . This is not harmful since Tw and
Lines (50) and (51) ensure that that the structure (NExpI , (r0 )I , (u0 )I ) is always isomorphic
to a grid, and the rest of Tw00 ensures that the elements of NExp always encode computations
of M0 . We thus use the circumscription pattern CP00 := (, {Rej}, , V 0 ), where V 0 contains
all predicates used in Tw00 except Rej.
The proof of the following lemma is left to the reader. In its formulation, the union
over all Qiqacc imposes that at least one state in the computation is accepting.
743

fiBonatti, Lutz, & Wolter

0

0

NExp v ((X = 2m  1)  r0 .NExp) u ((Y = 2m  1)  u0 .NExp)
0

0

0

0

(50)

NExp v r .(Y =Y ) u r .(X++) u u .(X=X) u u .(Y ++)

(51)

NExp v res0i .(Result u Ri ) u res0i .(Result u Ri )

(52)

NExp v toNP.NP u toNP.NP

(53)

NExp v

uu



j<m a



(X = 0) u (Y = j) u toNP.Sai,j,2  Sai

(54)

i
NExp v ((X = 0) u (Y  m))  SB

(55)

Qiq0
0

(56)

NExp v ((X = 0) u (Y = 0)) 
NExp v

uu

a

(Sai u Qiq ) 

qQ0

t

(q,a,q 0 ,a0 ,M )0

r0 .Aiq0 ,a0 ,M



(57)

NExp v Aiq,a,R  (Sai u u0 .Qiq )

(58)

Aiq,a,L  Sai
u0 .Aiq,a,L 

(59)

NExp v
NExp v

NExp v
NExp v

(60)

t Q  u (S  r .S )
u (S u S ) u u
t Q   u .NH

NH   t Q u u .NH

NExp v 
NExp v

Qiq

qQ0

i
q

a,b,a6=b
qQ0

i
a

rej

i
b

i
a

(61)
(Qiq u Qiq0 )

q,q 0 Q0 ,q6=q 0

0

i
q

qQ0

NExp v Qiq0

0

i
a

a

i
q

(62)
(63)

0

(64)

 res0i .Rej

(65)

Figure 6: The TBox Tw00 .
Lemma 17 M accepts w iff Cw := NP u

tQ

i<m

i
qacc

is simultaneously satisfiable w.r.t.

CircCP (Tw , ), CircCP0 (Tw0 , ), and CircCP00 (Tw00 , ).

It remains to apply Lemmas 6, 4, and 8 to obtain the following result.
Theorem 18 In ALC, satisfiability w.r.t. concept-circumscribed cKBs is NPNExp -hard
even if the TBox is acyclic, the ABox and preference relations are empty, there are no
fixed predicates, and the number of minimized predicates is bounded by a constant.
As already mentioned, we conjecture that the same result can be proved with empty TBoxes
(but non-empty ABoxes). Corresponding lower bounds for subsumption and the instance
problems follow from the reduction given in Section 2.
744

fiThe Complexity of Circumscription in DLs

5. Circumscription with Fixed Roles
In the preceeding sections, we have analyzed the computational complexity of reasoning
w.r.t. concept-circumscribed KBs and, in particular, established decidability. In the current
section, we extend concept-circumscribed KBs to what we call role-fixing cKBs, which differ
from the former by allowing role names to be fixed (but not minimized). Interestingly, the
result of this seemingly harmless modification is that reasoning becomes highly undecidable.
We start with defining the cKBs studied in this section.
Definition 19 A cKB CircCP (T , A) with CP = (, M, F, V ) is called role-fixing if M contains no role names.
4
To pinpoint the exact complexity of reasoning in role-fixing cKBs, we present a reduction of
the logical consequence problem in monadic second-order logic with binary relation symbols
(over unrestricted structures, not over trees) to the instance problem w.r.t. role-fixing cKBs
formulated in ALC. It follows that the latter problem is harder than any problem definable
in second-order arithmetic and thus outside the analytical hierarchy. Analogous results for
satisfiability and subsumption follow by the reductions given in Section 2. Our reduction
applies already to the case where TBox and preference relation are empty.
For a finite set R of binary relation symbols, denote by MSO(R) the set of formulas
constructed from a countably infinite set P1 , P2 , . . . of variables for sets, a countable infinite
set x1 , x2 , . . . of individual variables, and the binary relation symbols in R, using Boolean
connectives, first-order quantification, and monadic second-order quantification. It is not
hard to see that reasoning with role-fixing cKBs corresponds to reasoning in a tiny fragment of MSO(R). More specifically, consider the standard translation of ALC-concepts C to
FO-formulas (and thus MSO(R)-formulas) C ] (x) with one free individual variable x as e.g.
given by Borgida (1996) and take a cKB CircCP (T , A) with CP = (, M, F, V ),  = V = ,
M = {A}, and F = {r}. Translate (T , A) to the MSO(R)-sentence
^
^
^
=
x(C ] (x)  D] (x)) 
C ] (xa ) 
r(xa , xb ),
CvDT

C(a)A

r(a,b)A

where the xa are individual variables.
Then an ALC-concept C is satisfiable w.r.t. CircCP (T , A) if, and only if, the MSO(R)formula
  xC ] (x)  P (P  A]  [P/A] ])
is satisfiable, where P  A] stands for x (P (x)  A] (x))x (A] (x)P (x)) and [P/A] ]
denotes  with A] replaced by P . This translation is easily extended to the case where an
arbitrary number of concept names is minimized and an arbitrary number of concept and
role names is fixed and varies.
When we prove that logical consequence in MSO(R) is reducible to the instance problem w.r.t. role-fixing cKBs, we thus establish the surprising result that reasoning in such
sKBs does not only correspond to the above tiny fragment of MSO(R), but is as hard as all
of MSO(R). Our reduction is indirect: instead of directly reducing logical consequence in
MSO(R), we reduce the semantic consequence problem of modal logic and exploit Thomasons result that logical consequence in MSO(R) can be reduced to the latter problem, see
745

fiBonatti, Lutz, & Wolter

the works by Thomason (1975b, 1975a) and the survey articles by Wolter et al. (2007) and
Goldblatt (2003) for details.
We first define the semantic consequence problem of modal logic (in the framework of
description logic) and present Thomasons result, starting with some notation.
Let R be a finite set of role names. An R-frame is a structure F = (F , RF ), where F
is a non-empty domain and rF  F  F for all r  R. An interpretation I = (I , I ) is
based on an R-frame F iff F = I and rI = rF for all r  R. We say that a concept C is
valid in F and write F |= C if C I = I for every interpretation I based on F. The semantic
consequence of modal logic is now defined as follows. Let C and D be ALC concepts with
roles from R. Then D is a semantic consequence of C, in symbols C  D, if for every
R-frame F, from F |= C it follows that F |= D. Note that since validity in an R-frame F
involves quantification over all possible interpretations of the symbols not contained in R,
the relation C  D is invariant over all uniform renamings of atomic concepts in D (this
will be used later on).
For simplicity, we consider only MSO(r), monadic second-order logic with one binary
relation symbol r. It is straighforward to extend our result to arbitrary finite sets R of
relation symbols. Given a set of role names R, an ALC-concept is called an ALC R -concept
if it uses no other role names other than those in R. The following theorem follows from
the results by Thomason (1975b, 1975a).
Theorem 20 There exist an effective translation  :  7 () of MSO(r) sentences to
ALC {r} -concepts and an ALC {r} -concept C0 such that for all MSO(r) sentences  and ,
the following conditions are equivalent:
  is a logical consequence of  in MSO(r);
 C0 u ()  ().
We can thus establish the reduction of MSO(r) to the instance problem w.r.t. role-fixing
cKBs by reducing instead the semantic consequence problem. In fact, such a reduction can
be implemented in a very transparent way if we extend ALC with the universal role, whereas
the reduction to ALC itself requires a number of rather technical intermediate steps. For
this reason, we defer the ALC case to the appendix and give the proof with the universal
role.
Let u be a new role name, called the universal role. In every interpretation I, u has the
fixed interpretation as uI = I  I . Since the interpretation of u is fixed anyway, we do
not allow to use it in circumscription patterns.
Now suppose that C and D are ALC {r} -concepts. To establish the reduction, we construct a role-fixing cKB CircCP (, {C0 (a)}) and concept C1 such that C  D if, and only if, a
is an instance of C1 w.r.t. CircCP (, {C0 (a)}). As noted above, we may assume that C, D do
not share any concept names (otherwise, simply replace the concept names in D with fresh
ones). Let A be a concept name that does not occur in C and D, let CP = (, M, {r}, V ),
where  = , M consists of A and the set of concept names in C, and V consists of the
concept names in D. Set A = {(u.C t u.
B)(a)}.

u

BM

Lemma 21 The following conditions are equivalent:
746

fiThe Complexity of Circumscription in DLs

 C  D;
 a is an instance of (u.C) t D w.r.t. CircCP (, A).
Proof. To prove that Point 1 implies Point 2, assume that Point 2 does not hold. Let I
be a model of CircCP (, A) such that aI  ((u.C) u D)I . Let I be based on F. To prove
that Point 1 does not hold, we show that F |= C and F 6|= D. The latter is easy as it is
witnessed by the interpretation I. To show the former, let J be an interpretation based
on F. We show that C J = I . First note that, since I is a model of A and aI  (u.C)I ,
we have B I = I , for all B  M . We now distinguish two cases:
 B J = I , for all B  M . In this case, all B  M have the same interpretation in I
and J . Thus, since all concept names in C are in M and I and J are based on the
same frame, we obtain C J = C I = I .
 B J 6= I , for at least one B  M . Then J <CP I. Assume that C J 6= I . Then
aI  (u.C)J and J is a model of A. Thus, we have derived a contradiction to the
assumption that I is a model of CircCP (, A).
To prove that Point 2 implies Point 1, assume that Point 1 does not hold. Consider a
frame F such that F |= C, but F 6|= D. Let I be an interpretation based on F such that
aI  (D)I . We may also assume that B I = I for all B  M (since no such B occurs in
D). Then aI  ((u.C) u D)I and I is a model of A. It remains to show that there does
not exist an I 0 <CP I such that I 0 is a model of A. This is straightforward: from F |= C, we
0
0
obtain that there does not exist any I 0 such that aI  (u.C)I . Moreover, there clearly
0
0
0
does not exist an I 0 such that B I ( B I for some B  M and aI  (u.
B)I .
o

u

BM

We have thus proved that the logical consequence problem of MSO(r) is effectively reducible
to the instance problem w.r.t. role-fixing cKBs formulated in ALC extended with the universal role. In our reduction, the TBox and preference relation are empty. In the appendix,
we show how the reduction above can be modified so as to prove the same result for ALC
without the universal role.
Theorem 22 The logical consequence problem of MSO(r) is effectively reducible to the
instance problem w.r.t. role-fixing cKBs formulated in ALC. This even holds when the
TBox and preference relation are empty.

6. Circumscription with Minimized Roles
Unlike fixed concept names, fixed role names cannot be simulated using minimized role
names. This is due to the fact that Boolean operators on roles are not available in standard
DLs. Thus, Theorem 22 does not imply undecidability of reasoning in cKBs in which role
names are allowed to be minimized, but not fixed. In this section, we investigate cKBs of
this type. The formal definition is as follows.
Definition 23 A cKB CircCP (T , A) with CP = (, M, F, V ) is called role-minimizing if F
contains no role names.
4
747

fiBonatti, Lutz, & Wolter

We show that role-minimizing cKBs behave rather differently from concept-circumscribed
KBs and from role-fixing cKBs. First, it turns out that reasoning with role-minimizing
cKBs with empty TBox is NExpNP -complete for ALCQO, but undecidable for ALCI.
Thus, in contrast to the circumscribed KBs considered so far, we now observe a difference
in complexity between ALCQO and ALCI, and even between ALC and ALCI. A second
difference to the results obtained so far is that the NExpNP -lower bound, which applies
to cKBs formulated in ALC with an empty TBox, even holds for role-minimizing cKBs in
which a single role is minimized and no other predicate is fixed or minimized. This result
is of interest because it shows that complexity does not drop to NPNExp if the number of
minimized predicates is constant. Finally, we show that, with non-empty TBoxes, reasoning
with role-minimizing cKBs becomes undecidable already for ALC.
6.1 Role-minimizing cKBs With Empty TBox in ALCQO
We first prove the NExpNP -completeness result discussed above for DLs without inverse
roles. We start with the upper bound. To prove it, we first establish a bounded model
property using a selective filtration-style argument, see e.g. Blackburn et al. (2001). The
difference to the bounded model property proof given above for concept-circumscribed KBs
is that, here, we do not build a quotient model of a given model by identifying nodes using an
equivalence relation, but construct a submodel of a given model by selecting relevant nodes.
In contrast to forming quotient models, this technique works only with empty TBoxes since
a TBox can force us to select infinitely many nodes. Similarly, the selection technique does
not work for DLs with the inverse role because, as we shall see below, inverse roles can be
used to simulate TBoxes.
Recall that the role depth rd(C) of a concept C is defined as the nesting depth of the
constructors (> k r D) and (6 k r D) in C.
Theorem 24 In ALCQO, satisfiability w.r.t. role-minimizing cKBs with empty TBox is
in NExpNP .
Proof. Let CircCP (, A) be a role-minimizing cKB with CP = (, M, F, V ), and let C0 be a
concept that is satisfiable w.r.t. CircCP (, A). Let m0 be the maximal parameter occurring
in number restrictions of A or C0 . Set
n := max({rd(C0 )}  {rd(C) | C(a)  A}) and m := ((m0 + 1)  (|A| + |C0 |))n+1 ,
We show that there exists a model J of CircCP (, A) satisfying C0 such that #J  m.
Let I be a model of CircCP (, A) such that there exists a d0  C0I . For each d  I , fix a
minimal set D(d)  I such that,
 for every concept (> k r C) which occurs in A or C0 with d  (> k r C)I there exist
at least k distinct e  D(d) such that (d, e)  rI and e  C I and
 for every concept (6 k r C) which occurs in A or C0 with d 6 (6 k r C)I there exist
at least k + 1 distinct e  D(d) such that (d, e)  rI and e  C I .
Clearly, #D(d)  (m0 + 1)  (|C0 | + |A|) for each d  I . Next, define a set D0  I by
setting
D0 := {d0 }  {aI | a  NI occurs in A or C0 }.
748

fiThe Complexity of Circumscription in DLs

Define sets Di  I , 1  i  n, inductively by
[
Di+1 := (
D(d))
dDi

and set n :=

S

0in Di .

Define an interpretation I 0 with domain I as follows:

0

 aI = aI , for all individual names a;
0

 for r  M  V , (d, e)  rI if d  n \ Dn , e  D(d), and (d, e)  rI ;
0

 for A  M  V , AI = AI  n ;
0

 for A  F , AI = AI .
0

A straightforward inductive argument shows that I 0 is a model of A such that d0  C0I .
0
Note that we did not change the interpretation of the A  F . Moreover, we have pI  pI
for every p  M . Together with the fact that I 0 is a model of A and I 0 6<CP I, we even get
0
pI = pI for every p  M . It follows that I 0 is a model for CircCP (, A) because J <CP I 0
would imply J <CP I.
0
Note that rI  n  n , for every role r. Now define an interpretation J with domain
J = n by putting
0

 AJ = AI  n , for every concept name A;
0

 rJ = rI , for every role name r;
 aJ = aI , for every individual name a from A or C0 .
We still have that J is a model for A satisfying C0 . Moreover, any interpretation J 0 <CP J
satisfying A can be easily extended to an interpretation I 00 <CP I 0 satisfying A. Hence, no
such interpretation exists and J is a model for CircCP (, A). From #n  m we derive
#J  m.
The proof of the NExpNP -upper bound is now exactly the same as the proof of Theorem
10; it suffices to replace the bound 24k for the size of interpretations by the bound m.
o
We now give a lower bound matching the upper bound of Theorem 24.
Theorem 25 In ALC, satisfiability w.r.t. role-minimizing cKBs with empty TBox is NExpNP hard. This holds even if there is only one minimized role name and no fixed prediates
Proof. By Theorem 15, in ALC it is NExpNP -hard to decide whether a concept C0 is
satisfiable w.r.t. CircCP (, A), where CP = (, M, , V ) and M contains concept names only.
Clearly, it is still NExpNP -hard to decide whether there exists a common model of C0 and
CircCP (, A) of size at least #M . Thus, it is sufficient to provide a polynomial reduction
of this problem to the satisfiability problem w.r.t. cKBs in ALC with a single minimized
role and all remaining predicates varying. Suppose C0 and CircCP (, A) are given. Let
M = {A1 , . . . , Ak } and take
 two fresh role names r0 , r1 ;
749

fiBonatti, Lutz, & Wolter

 Boolean concepts C1 , . . . , Ck built using fresh concept names B1 , . . . , Bk such that
every Ci , i  k, is satisfiable and every Ci u Cj , i 6= j, is unsatisfiable. One can take,
for example, Ci = B1 u    u Bi1 u Bi u Bi+1 u    u Bk , for i  k.
Let CP0 = (, {r0 }, , V  {B1 , . . . , Bk , r1 }) and define A0 and C00 as the result of replacing,
in A and C0 , every occurrence of Ai by r0 .Ci , for i  k. Finally, set A = A0  {r1 .Ci (a) |
i  k}. We show the following:
() C0 is satisfiable w.r.t. CircCP (, A) in a model of size at least #M if, and only if, C00 is
satisfiable w.r.t. CircCP0 (, A ).
Let I be a model of CircCP (, A) and C0 of size at least #M . Define an interpretation I 0
with domain I by extending I as follows: take mutually distinct d1 , . . . , dk  I and
interpret B1 , . . . , Bk , r0 , r1 , and a in such a way that
0

 CiI = {di }, for i  k,
0

 r0I = {(d, di ) | d  AIi , i  k},
 aI = d1 ,
0

 r1I = {(d1 , d1 ), . . . , (d1 , dk )}.
It is readily checked that I 0 is a model of C00 and CircCP0 (, A ).
Conversely, let I be a model of CircCP0 (, A ) and C00 . Define an interpretation I 0 by
0
extending I with AIi = (r0 .Ci )I , for i  k. It is readily checked that I 0 is a model of C0
and CircCP (, A).
o
6.2 Role-minimizing cKBs With Nonempty TBox
In the bounded model property proof above, it is important that the selection of nodes
stops after n iterations with the set n , where n is the maximum of the role depths of the
concepts in the ABox and the concept C we want to satisfy. Such a bound for the selection
of nodes does not exist if the TBox is non-empty, and we now show that reasoning w.r.t.
role-minimizing cKBs is indeed undecidable in this case. The proof is by a reduction of the
 -tiling problem (Berger, 1966).

N N

Definition 26 A tiling problem is a quadruple triple P = (T, H, V ), where T is a finite
set of tile types and H, V  T  T are the horizontal and vertical matching conditions. A
solution to P is a mapping  :   T such that

N N

 ( (i, j),  (i + 1, j))  H for all i, j  0;
 ( (i, j),  (i, j + 1))  V for all i, j  0.
4
750

fiThe Complexity of Circumscription in DLs

Let P = (T, H, V ) be an instance of the tiling problem. We define a TBox TP as follows:
> v x.> u y.>
> v
> v

t

At u

u

At 

tT

tT

u

(66)
At0
0



(67)

t0 T,t6=t

t

(t,t0 )H


x.At0 u

u

tT

At 

t

(t,t0 )V

y.At0



> v N t (x.y.B u y.x.B)
N

v D

(68)
(69)
(70)

D w x.D t y.D

(71)

D v x.D u y.D

(72)

Let CP = (, M, , V ) be the circumscription pattern in which V = {B, D} and M consists
of the remaining concept and role names.
Lemma 27 CircCP (TP , ) 6|= D(a) iff P has a solution.
Proof. Assume that P has a solution  . Define an interpretation I as follows:
I
xI
yI
AIt
NI
BI
DI
aI

:=
:=
:=
:=
:=
:=
:=
:=

NN

{((i, j), (i + 1, j)) | i, j  0}
{((i, j), (i, j + 1)) | i, j  0}
{(i, j)  I |  (i, j) = t}
I
{(i, j)  I | i > 0 and j > 0}

(0, 0)

It is straightforward to verify that I is a model of TP . Additionally, we clearly have aI 
/ DI .
It thus remains to show that there is no model J of TP with J <CP I. Assume there is
such a J . Since all concept and role names except D and B are minimized, it follows that
1. xI = xJ and y I = y J because J is a model of (66);
2. AIt = AJ
t for all t  T because of Point 1 and J is a model of (67);
3. N I = N J because, no matter what B J is, by Point 1 we have
(x.y.B u y.x.B)J = .
Thus and because J is a model of (69), N I = N J .
Thus, I and J differ at most in the interpretation of the concept names D and B, which
are varying. This is a contradiction to J <CP I.
Conversely, assume that CircCP (TP , ) 6|= D(a), and let I be a model of CircCP (TP , ) with
aI 6 DI . By induction on i + j, we define a mapping  that assigns to each (i, j)  
an element (i, j)  I such that for all i, j  0, we have

N N

751

fiBonatti, Lutz, & Wolter

1. ((i, j), (i + 1, j))  xI ;
2. ((i, j), (i, j + 1))  y I ;
To start, set (0, 0) = aI . In the `-th step, we do the following:
 Select a d  I such that ((0, `  1), d)  y I and put (0, `) := d. Such a d exists
since I is a model of (66).
 Select a d  I such that ((`  1, 0), d)  xI and put (`, 0) := d. Again, such a d
exists since I is a model of (66).
 Now let i, j > 0 such that i + j = `. Since I is a model of (66), there are d, d0  I
such that ((i  1, j), d)  xI and ((i, j  1), d0 )  y I . We show that d = d0 , and
then set (i, j) := d.
Assume to the contrary that d 6= d0 . By (70)(72) and since aI 
/ DI , we have
I
(i  1, j  1)  N . Define a new interpretation J that is obtained from I by the
following modifications:
 (i  1, j  1) is removed from N I ;
 let d0  B J and d 6 B J ;
 let DJ = I .
Clearly, J <CP I. To obtain a contradiction against I being a model of CircCP (TP , ),
it thus remains to show that J is a model of TP . It suffices to consider (69) to (72),
the only concept inclusions referring to N , B, and D. The axioms (70) to (72) hold
because DJ = I . To show (69), let e  I . We show that e  C J for C the concept
on the right hand side of (69). Clearly, e  C J since e  C I , if e is not {x, y, x , y  }reachable from aI . We have e  N I if e is {x, y, x , y  }-reachable from aI , because
otherwise we would have aI  DI by axioms (70) to (72). Thus, e  N J  C J if
e 6= (i  1, j  1). Finally, (i  1, j  1)  C J , by definition of B J .

N N

Now define a mapping  :   T by setting  (i, j) := t if (i, j)  At . By (67), this
mapping is well-defined. By (68), it satisfies the horizontal and vertical matching conditions.
Thus, P has a solution.
o
Thus, we have shown the following result.
Theorem 28 In ALC, satisfiability w.r.t role-minimizing cKBs is undecidable.
6.3 Reasoning in Role-minimizing cKBs With Empty TBox in ALCI
We prove undecidability of reasoning in role-minimizing cKBs with empty TBox in ALCI.
The proof uses the spy-point technique (Areces, Blackburn, & Marx, 1999); namely, we
show that ABoxes can simulate TBox reasoning by employing inverse roles and a simulation
of nominals by circumscription. Using this idea the proof is rather similar to the proof of
Theorem 28.
752

fiThe Complexity of Circumscription in DLs

Let P be an instance of the tiling problem and consider the cKB CircCP (TP , ) defined
in the proof of Lemma 27. We simulate its TBox axioms C v C 0 by ABox assertions
((C  C 0 ) u r0 .(C  C 0 ))(a) and enforcing the role r0 to connect all relevant points to a.
This is achieved by forcing all relevant points in the domain to satisfy r0 .{a}. Since we
do not have nominals in the language we use a concept name A instead of {a} and ensure
that it behaves like a nominal. We now present the details.
For the sake of readability, we write concept assertions C(a) in the form a : C and we
set 1 {r}.C = C u r.C. Let A, B 0 , and N 0 be fresh concept names and r0 be a fresh role
name not occurring in TP . Then AP consists of the assertions
a : 1 {r0 }.(C  C 0 ),

(73)

for C v C 0  TP ,
a : A,

a : 1 {r0 }.

u s.r

s=x,y




a : 1 {r0 }. N 0 t (A u B 0 ) t r0 .(A u B 0 ) u
a : 1 {r0 }.(N 0  D),


0 .A,

(74)

t s.r

s=x,y


0 .(A

u B 0 )



a : r0 .D  D

(75)

(76)

Now let CP = (, M, , {D, B, B 0 }), where M consists of all concept and role names distinct
from D, B, and B 0 .
Lemma 29 CircCP (, AP ) 6|= D(a) iff P has a solution.
Proof. Assume P has a solution  . Take the interpretation I from the proof of Lemma 27
expanded by
AI = {(0, 0)},

N 0I = I ,

B 0I = ,

r0I = {(aI , d) | d  I }.

We show that I is a model of CircCP (, AP ). Clearly, I is a model of AP . Thus it remains
to show that there is no model J of AP with J <CP I. Assume there exists J <CP I which
is a model of AP . As A is minimized and by (74), AJ = {(0, 0)}. It follows from axiom
(66) encoded in (73) that ((0, 0), (1, 0))  xJ and ((0, 0), (0, 1))  y J . Now one can prove
by induction on ` > 0 using again the axiom (66) encoded in (73) and (74) that for all (i, j)
with i + j = `, ((0, 0), (i, j))  r0J and ((i, j), (i + 1, j))  xJ , ((i, j), (i, j + 1))  y J . It
follows that xJ = xI and y J = y I . Also observe that N 0J = I because, no matter how
B 0 is interpreted,

J

(A u B 0 ) t r0 .(A u B 0 ) u
s.r0 .(A u B 0 )
= .

t

s=x,y

Now one can prove similarly to the proof of Lemma 27 that J can only differ from I in the
interpretation of B, B 0 , and D, which is a contradiction.
Conversely, suppose I is a model of CircCP (, AP ) with aI 6 DI . We first show that
(aI , d)  r0I whenever d 6= aI and d is {x, y}-reachable in I from aI in a finite number of
steps. Assume that this is not the case. Then there exist d, d0  I such that
753

fiBonatti, Lutz, & Wolter

 d = aI or (aI , d)  r0I ,
 (d, d0 )  xI or (d, d0 )  y I ,
 (a, d0 ) 6 r0I .
By (74), there exists d00  I such that aI 6= d00 , (d00 , d0 )  r0I , and d00  AI . Observe that
d  N 0I by (76) and aI 6 DI . Define a new interpretation J by modifying I as follows:
 d is removed from N 0I ;
 let aI  B 0J and d00 6 B 0J ;
 let DJ = I .
Clearly J <CP I. To obtain a contradiction it is thus sufficient to show that J is a model
of AP . Clearly, all assertion in AP containing neither D, B 0 , nor N 0 are satisfied in J . For
the remaining assertions except (75), it follows from DJ = I that they are satisfied in J .
Finally, for (75), observe that N 0I  {aI }  {e | (aI , e)  r0I } because a 6 DI and assertions
(76). Thus, by definition of N 0J , we only have to consider the point d removed from N 0I .

J

s.r0 .(A u B 0 )
by definition of J .
But d  (A u B 0 ) t r0 .(A u B 0 ) u

t

s=x,y

Now one can use the assertions (73) to construct a solution  of P in the same way as
in the proof of Lemma 27.
o
We have thus proved the following result.
Theorem 30 In ALCI, satisfiability w.r.t. role-minimizing cKBs with empty TBox is undecidable.

7. Related Work
We have already pointed out in the introduction that circumscription is just one of several
possible approaches to nonmonotonic DLs and that, in order to achieve decidability, each
of these approaches has to adopt a suitable restriction on the expressive power of the DL
component, on the non-monotonic features, or on the interaction of the DL and its nonmonotonic features. In this section, we survey the existing approaches, discuss the adopted
restrictions, and relate them to DLs with circumscription whenever possible. However, we
point out that a full-fledged formal comparison of the different approaches is a serious research endeavor of its own and outside the scope of this paper. The main approaches to
nonmonotonic DLs (excluding those relying on the integration of DLs and logic programming) are summarized in Table 1, where n.a. stands for not analyzed and the specificity
column states whether a formalism is equipped with a priority mechanism based on the the
specificity (i.e., subsumption) of concepts.
We start with two early approaches based on circumscription. In the work by Brewka
(1987), a frame system is given a nonmonotonic semantics based on circumscription. The
focus is on showing the appropriateness of the proposed semantics, and the decidability and
complexity of reasoning is not analyzed. Cadoli et al. (1990), apply circumscription to a DL
754

fiThe Complexity of Circumscription in DLs

Ref
(Brewka, 1987)
(Cadoli, Donini, &
Schaerf, 1990)
(Padgham & Zhang,
1993)
(Straccia, 1993)
(Baader & Hollunder, 1995a)
(Baader & Hollunder, 1995b)
(Lambrix,
Shahmehri, & Wahlloef,
1998)
(Donini et al., 1997)

DL
frame lang.
< ALE

NM features
Circ
Circ

Complexity
n.a.
in p2

Specificity
Y
N

AL with concrete domains
ALC

inheritance
networks
prioritized
default logic
default logic

n.a.

Y

decidable

Y

decidable

N

prioritized
default logic
prioritized
default logic

decidable

Y

n.a.

Y

MKNF with
restrictions
MKNF with
restrictions
maximized
typicality

depends on DL

N

in 3-ExpTime

N

in co-NExpNP

N

ALCF
ALC
ALQO+feature
agreement
any decidable DL

(Donini et al., 2002)

ALC

(Giordano, Gliozzi,
Olivetti, & Pozzato,
2008)

ALC

Table 1: Some approaches to nonmonotonic DLs

in the same way as we do here. The authors consider only non-prioritized circumscription
and apply it to a fragment of the description logic ALE. Decidability of reasoning is shown
by a reduction to propositional reasoning under the Extended Closed World Assumption
(ECWA), which is in p2 . To the best of our knowledge, this was the first effective reasoning
method for a nonmonotonic description logic.
In another early approach by Padgham and Zhang (1993), a nonmonotonic DL is obtained by an adaptation of the inheritance networks approach (Horty, 1994) where the
underlying DL is essentially AL extended with concrete data values. The main contribution is the definition of the formalism and a discussion of applications, decidability and
complexity are not analyzed.
A recent approach that is similar in spirit to circumscription has been taken by Giordano
et al. (2008). The authors extend ALC with a modal operator T representing typicality,
and maximize T s extension to achieve nonmonotonic inferences. Decidability is proved via
a tableau algorithm that also establishes a co-NExpNP upper bound for subsumption. A
lower bound is not given.
We now turn to approaches based on default logic (Reiter, 1980). The nonmonotonic
DLs by Baader and Hollunder (1995a, 1995b), Straccia (1993), and Lambrix et al. (1998)
share a common restriction: default rules can be applied to an individual only if it has
a name, that is, if it is denoted by an individual constant that occurs explicitly in the
knowledge base. This restriction is motivated by the observation that, when defaults are also
applied to implicit (anonymous) individuals, then reasoning becomes undecidable (Baader &
755

fiBonatti, Lutz, & Wolter

Hollunder, 1995a). Since the models of DL knowledge bases usually include a large number
of anonymous individuals due to existential quantification, this restriction introduces a
strong asymmetry in the treatment of individuals.
Another line of nonmonotonic DLs (Donini et al., 1998, 1997, 2002) is based on first-order
autoepistemic logics whose interpretation domains are restricted to a fixed and denumerable
set of constants. The use of a unique domain resolves several issues related to quantification
in modal logics (such as whether the Barcan formula should hold, and whether different
worlds of the same Kripke structure should be allowed to have different domains). It also
avoids the asymmetry of the approaches based on default logic because, by definition, all
individuals have a name. The other side of the coin is that domains with finite or varying
cardinality and knowledge bases that do not satisfy the unique name assumption can only
be dealt with using rather technical encodings (such as an explicit axiomatization of the
finite domain represented by a concept name D).
In the first paper mentioned above (Donini et al., 1998), decidability results apply only to
monotonic knowledge bases4 as the autoepistemic operator can be used in a nonmonotonic
fashion only in queries. This restriction has been lifted in the subsequent publications.
They make use of the logic of minimal knowledge and negation as failure (MKNF), which
is equipped with two (auto)epistemic operators K and A (Donini et al., 1997, 2002).
In the former paper (Donini et al., 1997), the underlying monotonic fragment can be any
description logic with a decidable instance checking problem. The price payed for this
generality is that decidability results apply only to so-called simple knowledge bases, where
quantifying-in (that is, quantification across modal operators, as in R.K C) is not allowed.
Nonetheless, such KBs are expressive enough to model default rules. A different restriction is
explored by Donini et al. (2002). The underlying DL is restricted to ALC while limited forms
of quantifying-in are allowed, in so-called subjectively quantified ALCKN F knowledge bases.
Decidability results are obtained for the subclass of simple subjectively quantified knowledge
bases, whose nonmonotonic part is restricted to inclusions of the form KC v D such that
> v C is can not be inferred from the knowledge base. This restriction is incompatible
with the traditional embedding of (priority-free) circumscription into autoepistemic logic,
which is based on prerequisite-free default rules that would be equivalent to inclusions of
the form K> v C.
A recent line of research on integrating DLs and logic programming rules introduces
further nonmonotonic extensions of DLs based on negation-as-failure. Some approaches
(Eiter et al., 2004) use a loosely coupled integration of logic programs and DLs, where the
interpretations of the DL component are not restricted while the logic program variables
range only over the named DL individuals. Thus, these approaches are somewhat similar
to the classical extensions of DLs based on defaults in that nonmonotonic inferences are
limited to named individuals. A more recent approach (Motik & Rosati, 2007) is based on
MKNF and shares with the MKNF-DLs discussed above pros and cons of adopting a fixed
denumerable domain. If the complexity of reasoning in the underlying DL is C 6 NP, then
the data complexity of entailment is bounded by C C . Finally, we mention a 3-valued variant
of this approach (Knorr, Alferes, & Hitzler, 2007) based on the well-founded semantics.
4. The autoepistemic operator can be used only in restricted contexts that suffice to encode so-called
procedural rules, which are monotonic.

756

fiThe Complexity of Circumscription in DLs

ALC

Concept circ.
Minim. roles
Fixed roles

#M  n, #F  n
(unrestricted)
TBox= 
TBox6= 

ALCQO
ALCI ALCIO
NExp
NP
NExpNP even if = , and either TBox= or ABox=
NExpNP even if #M  1, #F  0
Undecidable
Undecidable
Highly undecidable, even if TBox= , = 

Table 2: Summary of complexity results for satisfiability w.r.t. cKBs
A common limitation of the nonmonotonic extensions of DLs based on MKNF is that
they provide no support for specificity and priorities. In particular, defeasible inheritance
is not mentioned in the expressiveness analysis for autoepistemic approaches (Donini et al.,
1997, 2002) and it does not appear to be a goal of any MKNF-based approach. As pointed
out in the introduction, it is well-known that, in the propositional case, nonmonotonic logics
cannot modularly encode specificity-based priorities such as those needed by inheritance
mechanisms (Horty, 1994).

8. Conclusions and Perspectives
We have shown that circumscription provides an elegant approach to defining nonmonotonic
DLs, that the resulting formalisms have an appealing expressive power and are decidable
if appropriate restrictions are adopted. The main such restriction, which leads to rather
robust decidability results, is that only concept names are minimized and fixed whereas all
role names vary. With empty TBoxes, decidability is retained if roles are allowed to be
minimized, but not when they are fixed. The decidability and complexity results obtained
in this paper are listed in more detail in Table 2. By the results of Section 3, all bounds
with TBox 6=  apply to both general and acyclic TBoxes.
We view this paper as a promising step towards establishing circumscribed DLs as a
major family of nonmonotonic DLs to be used in practical applications. To reach this goal,
some additional research topics have to be addressed, of which we mention two. First, the
algorithms presented in this paper are based on massive non-deterministic guessing and
thus do not admit an efficient implementation. Ideally, one would like to have algorithms
which are well-behaved extensions of the tableau algorithms that underly state-of-the-art
DL reasoners (Baader & Sattler, 2000). A crucial issue is whether the sophisticated optimization techniques implemented in such reasoners (tableaux caching, dependency-directed
backtracking etc.; cf. Baader et al., 2003, Chap. 9) can be adapted to circumscribed DLs.
Some first steps have been made by Grimm and Hitzler (2008). Second, it seems necessary
to develop a design methodology for modelling defeasible inheritance. The examples given
in this paper indicate that the main challenge is to find rules of thumb to determine which
predicates should be fixed, varied, and minimized. It may be appealing to hide abnormality
predicates behind explicit syntax for defeasible inclusions, and trade some generality for
simplicity and usability.
Also from a theoretical perspective, our initial investigation leave open at least some
interesting questions. For example, our current techniques are limited to circumscribed DLs
757

fiBonatti, Lutz, & Wolter

that have the finite model property. It would be desirable to overcome this limitation and
obtain decidability results for even more expressive DLs such as SHIQ or OWL. It is also
possible to follow the opposite approach and consider circumscribed versions of inexpressive
DLs such as those of the EL or DL-Lite family (Baader, Brandt, & Lutz, 2005a; Calvanese,
Giacomo, Lembo, Lenzerini, & Rosati, 2007), which are currently very popular in a large
number of applications. First steps have been made by Bonatti, Faella, and Sauro (2009),
who investigated circumscribed versions of EL and DL-lite.
Finally, it is worth mentioning that our complexity results for circumscription can be
used to prove complexity bounds for other, seemingly unrelated, reasoning problems in
description logic. For example, certain reasoning services for conservative extensions and
modularity in description logic and the satisfiability problem w.r.t. concept-circumscribed
knowledge bases are mutually reducible to each other in polynomial time (Konev, Lutz,
Walther, & Wolter, 2008). As there are not many problems that are known to be NExpNP complete, circumscription thus provides a new class of problems that can potentially be
employed to give NExpNP lower bound proofs.

Acknowledgments
The first author was partially supported by the network of excellence REWERSE, IST-2004506779. The third author was partially supported by UK EPSRC grant no. GR/S63182/01.

Appendix A. Missing Proofs in Section 3
Lemma 5. In ALC, satisfiability w.r.t. (concept-)circumscribed KBs with empty TBox and
without fixed roles can be polynomially reduced to satisfiability w.r.t. (concept-)circumscribed KBs with empty TBox and without fixed predicates.
Proof. In the proof of Lemma 4, we have used TBox axioms to state that some fresh
concept names are interpreted as the complement of fixed concept names. In general, this
cannot be done using ABox assertions only. Instead, we construct ABox assertions which
force this to be the case only for objects which are relevant for the truth of the given ABox.
Some care is required to do this using ABox assertions of polynomial size. The first part of
the proof deals with this problem. The second part is then a straighforward modification
of the proof of Lemma 4.
The first part of the proof consists of introducing some notation and proving a central
technical claim. For w = r1    rn  NR , an interpretation I, and d, e  I , we write
I
(d, e)  wI iff there are d0 , . . . , dn  I with d = d0 , e = dn , and (di , di+1 )  ri+1
for all
i < n.
Let N be a set of individual names and Paths a mapping from N to the powerset of NR .
An interpretation I is well-behaved for the mapping Paths if for every d  I , there is an
a  N and a w  Paths(a) such that (aI , d)  wI . With each ALC-concept C, we associate
a set P(C) of pairs (w, D) with w  NR and D a subconcept of C as follows:
 if C  NC , then P(C) = {(, C)};
 if C = D, then P(C) = {(, C)}  P(D);
758

fiThe Complexity of Circumscription in DLs

 if C = D1 u D2 or C = D1 t D2 , then P(C) = {(, C)}  P(D1 )  P(D2 );
 if C = r.D or C = r.D, then P(C) = {(, C)}  {(rw, E) | (w, E)  P(D)}.
For a set of ABox assertions S and an individual name a, we use P(S, a) to denote the set
S
C(a)S P(C). We write Paths(S, a) for {w | D : (w, D)  P(S, a)}. We now formulate
the announced claim.
Claim 1. Suppose CircCP (, A) 6|= C0 (a0 ), where CP does not contain fixed role names and A
and C0 (a) are formulated in ALC. Let S = A  {C0 (a0 )} and let N be the set of individual
names in S. Let I 0 be the restriction of I to those d  I such that, for some a  N
and some w  Paths(S, a), we have (aI , d)  wI . Then I 0 is a model of CircCP (, A) and
C0 (a0 ) which is well-behaved for the mapping Paths(a) = Paths(S, a), a  N .
We now prove the claim. Let I be a model of CircCP (, A) with aI0  (C0 )I . Note that
0
for all a  N , we have   Paths(S, a) and thus aI  I . Clearly, I 0 is well-behaved for
Paths. One can prove by induction on C that
0

() for all a  N , (w, C)  P(S, a), and d  I with (aI , d)  wI , we have d  C I iff
0
d  CI .
We show only the case C = r.D, and leave the other cases to the reader. Let d  C I . Then
there is an e  DI with (d, e)  rI . Since (w, C)  P(S, a), we have (wr, D)  P(S, a).
0
Since (aI , d)  wI , we have (aI , e)  (wr)I . Thus, e  I and the induction hypothesis
0
0
0
yields e  DI . By definition of I 0 and the semantics, d  C I . Now let d  C I . Then there
0
0
is an e  DI with (d, e)  rI . By definition of I 0 , (d, e)  rI . Since (w, C)  P(S, a), we
have (wr, D)  P(S, a). Since (aI , d)  wI , we have (aI , e)  (wr)I . Thus, the induction
hypothesis yields e  DI .
Thus, () is established. Using () and the facts that aI0  (C0 )I and that I is a model
0
0
of A, it is not hard to verify that aI0  (C0 )I and that I 0 is a model of A. We show that
I 0 is also a model of CircCP (, A). Assume to the contrary that there is a model J 0 of A
with J 0 <CP I 0 . Define an interpretation J as follows:
 J = I ;
 AJ = AI for all A  F ;
0

 AJ = AJ for all A  V  M ;
0

 rJ = rJ for all r  NC ;
 bJ = bI for all b  NI .
Using the assumption that CP does not contain fixed role names, it is not hard to verify
that J <CP I. To obtain a contradiction to the fact that I is a model of CircCP (, A), it
thus remains to show that J is a model of A. To this end, we prove by induction on C that
0

() for all a  N , (w, C)  P(S, a), and d  J with (aJ , d)  wJ , we have d  C J iff
0
d  CJ .
Since the induction step is as in the proof of (), we only do the induction start. Thus, let
C = A  NC . If A  V  M , we are done by definition of J . Now let A  F . Since I 0 is
759

fiBonatti, Lutz, & Wolter

0

0

0

0

a restriction of I and AJ = AI , the definition of J yields AJ  J = AJ , as required.
This finishes the proof of the claim.
To prove Lemma 5, we consider instance checking instead of satisfiability. Since we
have provided polynomial reductions from satisfiability to (non)-instance checking and vice
versa in Section 2, we nevertheless obtain the desired result. Let CircCP (, A) be a cKB
with CP = (, M, F, V ) and F = {A1 , . . . , Ak }. Take a concept assertion C0 (a0 ). Let
S = A  {C0 (a0 )} and N be the set of individual names in S. Define
 M 0 = M  {A1 , . . . , Ak , A01 , . . . , A0k }, where the A0i are fresh concept names;
 A0 = A  {w.(A0i  Ai )(a) | w  Paths(S, a), a  N , i  k};
 CP0 = (, M 0 , , V ).
Then CircCP (, A) |= C0 (a0 ) iff CircCP0 (, A0 ) |= C0 (a0 ) follows immediately from Claim 1
and the fact that Paths(S, a) = Paths(S 0 , a), for S 0 = A0  C0 (a0 ).
o
Lemma 6 C0 is satisfiable w.r.t. CircCP (T , A) iff C0 u B 0 is satisfiable w.r.t. CircCP0 (T 0 , A).
Proof. Suppose I is a model of C0 and CircCP (T , A). Expand I to an interpretation I 0 by
setting
0
0
0
0
0
AI = B 0I = I , B I = A0I = , uI = .
Clearly, I 0 is a model of C0 u B 0 and (T 0 , A). We show that I 0 is a model of CircCP0 (T 0 , A).
Assume to the contrary that there is a model J of (T 0 , A) with J <CP0 I 0 . Then A0J = ,
AJ = I , B J = , and B 0 J = I . Since u is varying and J <CP0 I 0 , it is thus easy to
show that J <CP I. This contradicts the fact that I is a model of CircCP (T , A).
Conversely, suppose I is a model of C0 u B 0 and CircCP0 (T 0 , A). We show that I is also
a model of C0 and CircCP (T , A). First observe that AI = I . For suppose that this is not
the case. Define a new interpretation J in the same way as I except that uJ = I  I ,
B J = I , and B 0J = . Then J <CP0 I (since B 0I 6= ) and J is a model of (T 0 , A). Thus
we have derived a contradiction. It follows that C I = I and hence I is a model of (T , A)
and C0 . It remains to show that there is no J <CP I such that J is a model of (T , A).
Assume such a J exists. Then C J = I . Define a model J 0 by expanding J as follows:
0

0

AJ = B 0J = I ,

0

0

B J = A0J = ,

0

uJ = .

Note that A, B, A0 , B 0 , and u are interpreted by I in the same way, then J 0 <CP0 I.
Moreover, J 0 is a model of (T 0 , A). We have derived a contradiction.
o
Lemma 8 For all L  DL, simultaneous satisfiability w.r.t. (concept) circumscribed KBs
CircCP1 (T1 , A1 ), . . . CircCPk (Tk , Ak ), such that CircCPi (Ti , Ai ) and CircCPj (Tj , Aj ) share no
role names for 1  i < j  k, can be reduced to satisfiability w.r.t. single (concept)
circumscribed KBs in polynomial time.
Proof. It suffices to reduce simultaneous satisfiability without shared role names to the complement of instance checking w.r.t. single cKBs. As a generalization is straightforward, we
only give a proof for the case k = 2. Thus, let L  DL and CircCP1 (T1 , A1 ), CircCP2 (T2 , A2 )
760

fiThe Complexity of Circumscription in DLs

be cKBs formulated in L that share no role names, and C0 an L-concept. Moreover, let
A0 , . . . , An1 be the concept names shared by the two cKBs, R the role names used in at
least one of the two cKBs together with a fresh role name r0 , and CPi = (i , Mi , Fi , Vi ) for
i  {1, 2}. We obtain a new TBox T20 from T2 by replacing each concept name Ai , i < n,
with a new concept name A0i . Let A02 be obtained from A2 and CP02 = (02 , M20 , F20 , V20 ) from
CP2 in the same way. Define a TBox T  as follows, where P is a fresh concept name:
Ai u A0i v P for all i < n
Ai u A0i v P for all i < n
P
r.P

v r.P for all r  R
v P for all r  R

Now set:
T

:= T1  T20  T 

A := A1  A02  {r0 (b1 , b2 ) | b1 , b2 occur in A1  A2  T1  T2 }
 := 1  02
M

:= M1  M20

F

:= F1  F20

V

:= V1  V20  {P, r0 }

CP := (, M, F, V )
Let a0 be an individual name from A1 (clearly, we may assume that A1 6= ). It remains
to show the following:
Claim. C0 is simultaneously satisfiable w.r.t. CircCP1 (T1 , A1 ) and CircCP2 (T2 , A2 ) iff a0 is
not an instance of (P u r0 .C0 ) w.r.t. CircCP (T , A).
If. Assume that a0 is not an instance of (P u r0 .C0 ) w.r.t. CircCP (T , A). Then there
is a model I of CircSCP (T , A) with aI0  (P u r0 .C0 )I . We call I connected if the directed
graph GI = (I , rR rI  (r )I ) is connected. A connected component I 0 of I is the
0
0
restriction of I to domain I such that I is a (maximal) connected component in GI .
We may assume without loss of generality that the chosen model I is connected: if it is
not, then the use of the role r0 ensures that there is a connected component I 0 of I that
contains bI for all individual names b in A1  A2  T1  T2 . It is easy to see that I 0 is a
0
0
model of CircCP (T , A) and aI0  (P u r0 .C0 )I , thus we may simply replace I by I 0 .
We have to show that C0 is simultaneously satisfiable with respect to CircCP1 (T1 , A1 )
and CircCP2 (T1 , A2 ). Clearly, I is a model of C0 . By construction of CircCP (T , A), it is
a model of T1 , and A1 . To show that I is also a model of CircCP1 (T1 , A1 ), assume to the
contrary that this is not the case. Then there exists a model J of T1 and A1 such that
J <CP1 I. Define a model J 0 as follows:
0

 J = J ;
 all predicates used in T1 and A1 are interpreted as in J ;
 all predicates used in T20 and A02 are interpreted as in I.
761

fiBonatti, Lutz, & Wolter

(
 P

J0

:=

0

I

if ((Ai u A0i ) t (Ai u A0i ))J 6=  for some i < n



otherwise

0

0

 r0J = J  J .
It is readily checked that J 0 is a model of T and A, and that J 0 <CP I. Thus, we have
derived a contradiction to the fact that I is a model of CircCP (T , A), and it follows that I
is a model of CircCP (T1 , A1 ).
It remains to show that I is a model of CircCP (T2 , A2 ). Since I is connected, a model
of T  , and satisfies aI0 
/ P I , we have that AIi = (A0i )I for all i < n. Therefore, I is also a
model of T2 and A2 . Analogously to the case of CircCP1 (T1 , A1 ), we can now show that I is
a model of CircCP2 (T2 , A2 ).
Only if. Assume that C0 is simultaneously satisfiable w.r.t. the cKBs CircCP1 (T1 , A1 )
and CircCP2 (T2 , A2 ). Then there exists a model I of C0 that is a model of CircCP1 (T1 , A1 )
and CircCP2 (T2 , A2 ). We modify I to a new model I 0 by setting
0

 (A0i )I := AIi for all i < n;
0

 P I := ;
0

 r0I := I  I .
0

0

It is easy to see that I 0 is a model of T and A, and that aI  (P u r0 .C0 )I . To show
that a0 is not an instance of (P u r0 .C0 ) w.r.t. CircCP (T , A), it thus remains to prove
that I 0 is also model of CircCP (T , A). To do this, we first show the following:
(a) I 0 is a model of CircCP1 (T1 , A1 ). This is the case since any model J of T1 and A1
with J <CP1 I 0 satisfies J <CP1 I. Thus, the existence of such a model contradicts
the fact that I is a model of CircCP1 (T1 , A1 ).
(b) I 0 is a model of CircCP02 (T20 , A02 ). Assume to the contrary that there is a model J of T20

:= (A0i )J
and A02 with J <CP02 I 0 . Convert J into an interpretation J  by setting AJ
i


for all i < n. Then, J is a model of T2 and A2 and satisfies J <CP2 I. This is a
contradiction to the fact that I is a model of CircCP2 (T2 , A2 ).
Now, assume to the contrary of what is to be shown that there is a model J 0 of T and
A with J 0 <CP I 0 . By definition of CP, J 0 <CP I 0 implies that either J 0 <CP1 I 0 or
J 0 <CP02 I 0 hold. Since J 0 clearly satisfies T1 , A1 , T20 , and A02 , we obtain a contradiction to
(a) and (b).
o

Appendix B. Missing Proofs in Section 4
Lemma 14 G is a yes-instance of co-3CERTCOLS iff CG is satisfiable w.r.t. CircCPG (, AG ),
where CPG = (, M, F, V ) with  = , M = {Root, Leaf, Clash},
F = {LeafFix, Tr, X0 , . . . , Xn1 , Y0 , . . . , Yn1 , },
and V the set of all remaining predicates in AG .
762

fiThe Complexity of Circumscription in DLs

Proof. If. Suppose that CG is satisfiable w.r.t. CircCPG (, AG ) and let I be a model of
I 6= . We have to show that G is a yes-instance of co-CERT3COL .
CircCPG (, AG ) with CG
S
To start, we show that
I.
(I) aI0  CG
I with d 6= aI .
Assume to the contrary that this is not the case. Then there is a d  CG
0
I , we have d  RootI . Let J be the interpretation obtained from I by setting
Since d  CG
RootJ = {aI0 }. By definition of AG , we have aI0  RootI , and thus J CPG I. Moreover,
it is easily seen that J is a model of AG . We have thus established a contradiction to the
fact that I is a model of CircCPG (, AG ), which proves (I).
By Lines (1)-(4) (Fig. 2), there are elements di,w  I (the nodes of the tree) for i  2n
and w  {0, 1}i such that

 aI0 = d0, ;
 di,w  XjI iff the j + 1-st bit of w is 1, for all i  2n and j  min{i, n  1};
 di,w  YjI iff the n + j + 1-st bit of w is 1, for all i, j with n < i  2n and j  i  n;
 (di,w , di+1,w0 ), (di,w , di+1,w1 )  rI , for all i < 2n;
 d2n,w  Leaf I , for all w  {0, 1}2n .
For i, j < 2n , we use `i,j to denote the element d2n,w such that w  {0, 1}2n denotes the
binary encoding of i followed by that of j. We now show that
(II) Leaf I = {`i,j | i, j < 2n }.
Assume to the contrary that this is not the case, i.e., that there is a d  Leaf I such that
d 6= `i,j for all i, j < 2n . Let id , jd > 0 be integers such that the truth values of X0 , . . . , Xn1
at d encode id and the truth values of Y0 , . . . , Yn1 encode jd . Starting from I, we construct
an interpretation J by setting
Leaf J
rJ

:= Leaf I \ {d}
:= (rI \ (I  d))  {(e, `id ,jd ) | (e, d)  rI }

Further modify J into J 0 by setting
PJ

0

:= (r2n .var1.Leaf)J 
(r2n .var2.Leaf)J 
(r2n .col1.Leaf)J 
(r2n .col2.Leaf)J

By going through Lines (1) to (26), it is straightforward to check that J 0 is a model of AG .
Moreover, we clearly have J 0 <CPG I, and thus obtain a contradiction to the fact that I is
a model of CircCPG (, AG ). We have thus shown (II).
The following is an easy consequence of (I), the fact that P is a conjunct of CG , and
Lines (8), (9), (20), and (21):
(III) (`i,j , d)  rI implies d  Leaf I for all i, j < 2n , d  I , and r  {var1, var2, col1, col2}.
763

fiBonatti, Lutz, & Wolter

Now suppose to the contrary of what we aim to prove that G is not a yes-instance. Then,
for all truth assignments t, the subgraph t(G) is 3-colorable. In particular, this holds for
the assignment t defined by setting, for all i, j < 2n ,

t(Vij ) := 1 iff `i,j  TrI .

Let c : {0, . . . , 2n  1}  {R, G, B} be a 3-coloring of t(G) and construct an interpretation
J by starting from I and applying the following modifications:

CJ
ClashJ

= {`i,0 | i < 2n , c(i) = C} for all C  {R, G, B}
= .

Clearly, J <CPG I: the minimized predicate Clash is empty in J , but non-empty in I since
I is non-empty. To obtain a contradiction, it thus suffices to show that J is a model
CG
of AG .
Since I and J agree on all predicates but R, G, B, and Clash, all inclusions that do not
mention these concepts are satisfied in J . These are Lines (1) to (21). Lines (22) and (23)
2n J
are satisfied by construction of J and since, due to Line (5) and (II), (aJ
0 , d)  (r )
n
implies d = `i,j for some i, j < 2 . It thus remains to consider Lines (24) to (26). We first
show that
(IV) for all i, j < 2n , (i, j) is an edge of t(G) iff `i,j 
/ ElimJ .
Let i, j < 2n and let the potential edge (i, j) be labeled with Vk1 ,k2  Vk3 ,k4 (since the
(i)
(i)
circuits cS and cj deliver an output for any input, we can assume that also potential,
but non-existing edges have a label). By (II) and (III) together with Lines (8) and (9),
var1J = var1I = {`k1 ,k2 } and var2J = var2I = {`k3 ,k4 }. Thus, the definition of t together
with Lines (12) to (16) yields that (i, j) is an edge of t(G) iff `i,j 
/ ElimI . To prove (IV), it
remains to note that I and J interpret the concept name Elim in the same way.
2n J
Now, we prove that (24) to (26) are satisfied in J . Let (aJ
0 , d)  (r ) . By Line 5
J
n
and (II), d = `i,j for some i, j < 2 . Let `i,j 
/ Elim . By (IV) and since c is a 3-coloring
of t(G), we get c(i) 6= c(j). Thus, by construction of J , `i,0 
/ C J or `j,0 
/ C J for all
C  {R, G, B}. By (II) and (III) together with Lines (18) and (19), col1J = col1I = {`i,0 }
and col2J = col2I = {`j,0 }. Therefore, `i,j 
/ (col1.C u col2.C)J for all C  {R, G, B}.
J
Since this holds for any `i,j 
/ Elim , the preconditions of the implications in Lines (24) to
(26) are never satisfied. Thus, the implications are satisfied.

Only if. Suppose that G is a yes-instance and let t be a truth assignment such that
t(G) is not 3-colorable. Let c : {0, . . . , 2n  1}  {R, G, B} be a color assignment that
minimizes (w.r.t. set inclusion) the set {(i, j) | (i, j) an edge in G with c(i) = c(j)}. Define
an interpretation I as follows (here and in the following, we do not distinguish between a
number and its binary encoding as a string):
764

fiThe Complexity of Circumscription in DLs

I
RootI

= {di,w | i  2n , w  {0, 1}i }
= {d0, }

I

= {d2n,w | w  {0, 1}2n }

LeafFixI

= {d2n,w | w  {0, 1}2n }

Leaf

XjI

= {di,w | the j + 1-st bit of w is 1, i  2n, and j  min{i, n  1}};

YjI
I

= {di,w | the n + j + 1-st bit of w is 1, n < i  2n, and j  i  n};

Tr

= {d2n,ij | t(Vij ) = 1}

TrI`

= {d2n,ij | t(Vij )  cS (i, j)}

(`)

(` = 1, 2)

Elim

I

= {d2n,ij | (i, j) is not an edge of t(G)}

C

I

= {d2n,i0 | c(i) = C} (C = R, G, B)

I

= {d2n,ij | (i, j) is an edge of t(G) and c(i) = c(j)}

r

I

= {(di,w , di+1,w0 ), (di,w , di+1,w1 ) | i < 2n}

var1

I

= {(d2n,ij , d2n,kl ) | the first variable in the label of (i, j) is Vkl }

var2

I

= {(d2n,ij , d2n,kl ) | the second variable in the label of (i, j) is Vkl }

I

col1

= {(d2n,ij , d2n,i0 ) | i < 2n }

col2I

= {(d2n,ij , d2n,j0 ) | i < 2n }

Clash

PI

= 

aI0

= d0, .

For each Boolean circuit c, the corresponding output concept name Outc is interpreted
as OutIc := {d2n,ij | i, j < 2n and c(i, j) is true}.
I and
To show that CG is satisfiable w.r.t. CircCPG (, AG ), it suffices to show that aI0  CG
I is a model of CircCPG (, AG ). The former is easy: recall that CG = RootuP ur2n .Clash.
By definition of I, aI0  (Root u P )I . Since c is not a 3-coloring, aI0  (r2n .Clash)I . It
thus remains to show that I is a model of CircCPG (, AG ). Since it is easy to verify that I is
a model of AG , this boils down to showing that there is no model J of AG with J <CPG I.
Assume to the contrary that there is such a J . By Lines (1)(5) and since J is a model
of AG , we have #Leaf J  22n . Since #Leaf I = 22n and J <CPG I, we get Leaf J = Leaf I .
For similar but simpler reasons, RootJ = RootI . Thus, J <CPG I implies ClashJ ( ClashI .
By Lines (1) to (5) and since I and J are models of AG with Leaf J = Leaf I and #Leaf I =
#Leaf J = 22n , we have
I
J
2n J
(I) {d  I | (aI0 , d)  (r2n )I } = {d  J | (aJ
0 , d)  (r ) } = Leaf = Leaf

Thus, Lines (24) to (26) and the fact that J is a model of AG ensure that
S
(II) C{R,G,B} (Leaf u Elim u col1.C u col2.C)J  ClashJ .
Define a coloring c0 by setting
c0 (i) = C iff d2n,i0  C J
Suppose that
765

(C = R, G, B).

fiBonatti, Lutz, & Wolter

(III) (a) ElimI  Leaf I = ElimJ  Leaf I ,
(b) col1I  (Leaf I  Leaf I ) = col1J  (Leaf J  Leaf J ), and
(c) col2I  (Leaf I  Leaf I ) = col2J  (Leaf J  Leaf J ).
Then (II) guarantees that if (i, j) is an edge in G with c0 (i) = c0 (j), then d2n,ij  ClashJ .
Since ClashJ ( ClashI , we get that
1. if c0 (i) = c0 (j), then c(i) = c(j);
2. there are i, j with c0 (i) 6= c0 (j), but c(i) = c(j).
This contradicts our initial minimality assumption on the coloring c.
It thus remains to prove (III). We start with (a). Assume that
(d) var1I  (Leaf I  Leaf I ) = var1J  (Leaf J  Leaf J ) and
(e) var2I  (Leaf I  Leaf I ) = var2J  (Leaf J  Leaf J ).
Then, Lines (12) to (16) together with (I) and the fact that TrI = TrJ implies (a). It thus
remains to prove (b) to (e). We concentrate on (b) as the other cases are analogous. Take
(d, d0 )  col1I  (Leaf I  Leaf I ). Then d = d2n,ij and d0 = d2n,i0 j 0 for some i, j, i0 , j 0 < 2n .
By Line (18), i0 = i and j 0 = 0. By (I) and Lines (17) and (18) and since I and J
agree on the interpretation of X0 , . . . , Xn1 , Y0 , . . . , Yn1 , there is an e  LeafFixJ such
that (d2n,ij , e)  col1J , the value encoded by X0 , . . . , Xn1 at e in J is i, and the value
encoded by Y0 , . . . , Yn1 at e in J is 0. Since LeafFixI = LeafFixJ , we have LeafFixJ =
Leaf J . However, there is only a single element of Leaf J where X0 , . . . , Xn1 encodes i and
Y0 , . . . , Yn1 encodes 0 and this is d2n,i0 = d0 . The converse direction is analogous.
o
Corollary 16 In ALC, satisfiability w.r.t. concept-circumscribed KBs is NExpNP -hard
even if the TBox is acyclic, the ABox and preference relations are empty, and there are no
fixed predicates.
Proof. The ABox AG from the reduction given in Section 4.2.1 is of the form {C0 (a0 )}
and the circumscription pattern CPG has an empty preference relation. It thus suffices to
show that there is a polynomial reduction of satisfiability w.r.t. concept-circumscribed KBs
of this form to satisfiability w.r.t. concept-circumscribed KBs with an acyclic TBox, empty
ABox and preference relation, and no fixed predicates.
Let CircCP (, A) be a concept-circumscribed KB with A = {C0 (a0 )} and CP = (
, M, V, F ) with = , and let C be an ALC concept. Define T = {A v u.C0 }, where
A is a concept name that does not occur in A and C and u is a role name that does not
occur in A and C. Also define CP0 = (, M, V  {u}, F  {A}). Then C is satisfiable w.r.t.
CircCP (, A) iff A u C is satisfiable w.r.t. CircCP0 (T , ):
If. If A u C is satisfiable w.r.t. CircCP0 (T , ), then there is a model I of CircCP0 (T , )
and a d0  (A u C)I . Thus, there is an e0  C0I . Modify I to obtain a new interpretation
J by setting aJ
0 = e0 . Clearly, J is a model of A and C. To show that it is also a model of
CircCP (, A), assume to the contrary that there is a model J 0 of A with J 0 <CP J . Modify
0
0
J 0 into an interpretation I 0 by setting AI = AI and uI = I  I . It is readily checked
that I 0 is a model of T and I 0 <CP0 I, thus we have obtained a contradiction to the fact
that I is a model of CircCP0 (T , ).
766

fiThe Complexity of Circumscription in DLs

Only if. If C is satisfiable w.r.t. CircCP (, A), then there is a model I of CircCP (, A)
and a d0  C I . Let J be defined as I, except that AJ = {d0 } and uJ = I  I . Clearly,
J is a model of T and A u C. To show that J is also a model of CircCP (T , ), assume to the
0
contrary that there is a model J 0 of T with J 0 <CP0 J . Since A is fixed in CP0 , d0  AI ,
0
0
thus d0  (u.C0 )J and there is an e0  C0J . Modify J 0 into a new interpretation I 0 by
0
setting aI0 = e0 . It is readily checked that I 0 is a model of A and I 0 <CP I, thus we have
obtained a contradiction to the fact that I is a model of CircCP0 (, A). To get rid of fixed
predicates, it suffices to apply Lemma 5.
o

Appendix C. Missing Proofs in Section 5
We show that the semantic consequence problem can be reduced to instance checking
w.r.t. role-fixing cKBs in ALC. We have already proved that for ALC extended with the
universal role. In fact, the only remaining problem is to approximate concepts u.C using ALC concepts that state that the extension of C contains all points within a certain,
sufficiently large neighbourhood.
To construct such an approximation, we first introduce a local version of the notion of
frame validity of concepts. A pointed R-frame is a pair (F, d) such that d  F and F is
an R-frame. A concept C is valid in a pointed R-frame (F, d), in symbols (F, d) |= C, iff
d  C I for every interpretation I based on F. For m  and R a finite set of role names,
m R.C denotes C if m = 0, and

N

m1 R.C u

u r.

m1

rR

R.C

if m > 0. In what follows, we will use concepts of the form m R.C as approximations of
u.C. We remind the reader of some correspondence results of modal logic. Let transA =
s.A t s.s.A and contA = s.A t r.A. Then it is well known (Blackburn & van
Benthem, 2007) and easy to prove that for every {r, s}-frame F, the following holds:
 transA is valid in F if, and only if, sF is transitive;
 contA is valid in F if, and only if, rF  sF .
Say that d0  F is {r, s}-reachable from d in F if (d, d0 )  (rF  sF ) and call d  F a
root of F if every d0  F is {r, s}-reachable from d in F. If F is an {r, s}-frame with root
d, then the following conditions are equivalent:
 1 {r, s}.(transA u contA ) is valid in (F, d);
 sF is transitive and rF  sF .
These observations are used in the proof of Lemma 31 below. As before, we sometimes write
concept assertions C(a) in the form a : C. Recall that the role depth rd(C) of a concept C
is defined as the nesting depth of the constructors r.D and r.D, r  R, in C.
Lemma 31 Let C and D be ALC {r} -concepts not sharing any concept names and let A be
a fresh concept name. Let CP = (, M, {r, s}, V ) be a circumscription pattern, where M
consists of A and the concept names in C and V consists of the concept names in D. Let
a be an individual name. Then the following conditions are equivalent:
767

fiBonatti, Lutz, & Wolter

1. for all {r, s}-frames F with rF  sF and sF transitive: if F |= C, then F |= D;
2. for all pointed {r, s}-frames (F, d):
(F, d) |= 1 {r, s}.(transA u contA u C)



(F, d) |= D

3. a is an instance of 1 {r, s}.(transA u contA u C) t D w.r.t. CircCP (, A), where
A = {a : (1 {r, s}.(transA u contA u C) t 1+max {2,rd(C)} {r, s}.

u B)}.

BM

Proof. Point 1 implies Point 2. Suppose Point 2 does not hold. Let (F, d) be a pointed
{r, s}-frame such that (F, d) |= 1 {r, s}.(transA u contA u C) and (F, d) 6|= D. We may
assume that d is a root of F. From (F, d) |= 1 {r, s}.(transA u contA ) we obtain rF  sF
and sF transitive. Therefore, from (F, d) |= 1 {s}.C we obtain F |= C. It follows that F is
a frame refuting Point 1.
In what follows we use, for every I and d  I , d,I to denote the set of all e  I
which are {r, s}-reachable from d in at most 1 + max {2, rd(C)} steps.
Point 2 implies Point 3. Suppose Point 3 does not hold. Let I be a model of CircCP (, A)
such that
aI  (1 {r, s}.(transA u contA u C) u D)I .

(77)

Let I be based on F and set d := aI . We show (F, d) |= 1 {r, s}.(transA u contA u C) and
(F, d) 6|= D. The latter is easy as it is witnessed by the interpretation I. To show the former,
let J be an interpretation based on F. We show that d  (1 {r, s}.(transA u contA u C))J .
By (77) and since I is a model of CircCP (, A), aI  (1+max {2,rd(C)} {r, s}.
B)I . It

u

BM

follows immediately that
B I = d,I ,

(78)

for all B  M . We now distinguish two cases:
 B J  d,I , for all B  M . Since I and J are based on the same frame and all concept
names in contA , transA , and C are in M , the truth of 1 {r, s}.(transA u contA u C) at
d depends on the truth value of concept names from M in d,I only. From (78) we
obtain B I  d,I = B J  d,I , for all B  M . Hence, by (77), d  (1 {r, s}.(transA u
contA u C))J , as required.
 B J 6 d,I , for at least one B  M .
0

Let J 0 be the modification of J where B J = B J  d,I , for B  M . By (78), J 0 <CP
0
I. If d  (1 {r, s}.(transA u contA u C))J , then J 0 is a model of A and we have a
contradiction to the fact that I is a model of CircCP (, A). Thus, d  (1 {r, s}.(transA u
0
contA u C))J . Since, again, the truth of 1 {r, s}.(transA u contA u C) at d depends on
the truth value of B  M on d,I only, we have d  (1 {r, s}.(transA u contA u C))J ,
as required.
768

fiThe Complexity of Circumscription in DLs

Point 3 implies Point 1. Suppose Point 1 does not hold. Consider a frame F such that sF
is transitive, rF  sF , F |= C, and F 6|= D. It follows that F |= transA u contA . Let I be an
interpretation based on F such that d  (D)I . We may assume that d is a root of F. We
may also assume that B I = d,I for all B  M (since no such B occurs in D) and aI = d.
Then aI  (1 {r, s}.(transA u contA u C) u D))I and I is a model of A. It remains to show
that there does not exist an I 0 <CP I such that
0

aI  (1 {r, s}.(transA u contA u C) t 1+max {2,rd(C)} {r, s}.

u B)

I0

BM

.

This is straightforward: from (F, d) |= 1 {r, s}.C, we obtain that there does not exist any
0
0
I 0 such that d  (1 {r, s}.C)I and clearly there does not exist any B  M with B I  B I
0
such that d  (1+max {2,rd(C)} {r, s}.B)I .
o
We are in a position now to prove the reduction for ALC.
Theorem 22 The logical consequence problem of MSO(r) is effectively reducible to the
instance problem w.r.t. role-fixing cKBs formulated in ALC. This even holds when the
TBox and preference relation are empty.
Proof. By Theorem 20, the logical consequence problem of MSO(r) is effectively reducible
to the modal consequence problem for ALC {r} -concepts. Hence, it suffices to reduce the
modal consequence problem for ALC {r} -concepts. Let ALC {r} -concepts C and D be given.
We may assume that C and D have no concept names in common (if they have, then replace
every concept name B in D by a new concept name B 0 and denote the resulting concept
by D0 ; as noted above, C  D iff C  D0 .) Let CP = (, M, {s, r}, V ) where  = , M
consists of A and all concept names in C, and V consists of all concept names in D. Let
A = {a : (1 {r, s}.(transA u contA u C) t 1+max {2,rd(C)} {r, s}.

u B)}

BM

and C0 = 1 {r, s}.(transA u contA u C) t D. By the equivalence of Point 1 and Point 3
in Lemma 31, CircCP (, A) |= C0 (a) if, and only if, for all frames F with rF  sF and sF
transitive, from F |= C follows F |= D. As C and D do not contain s,
CircCP (, A) |= C0 (a)



C  D.
o

References
Areces, C., Blackburn, P., & Marx, M. (1999). A road-map on complexity for hybrid logics.
In Proceedings of the Eighth Annual Conference of the EACSL (CSL99), No. 1683 in
Lecture Notes in Computer Science, pp. 307321. Springer-Verlag.
Areces, C., Blackburn, P., & Marx, M. (2000). The computational complexity of hybrid
temporal logics. Logic Journal of the IGPL, 8 (5), 653679.
Baader, F., Brandt, S., & Lutz, C. (2005a). Pushing the EL envelope. In Kaelbling, L. P.,
& Saffiotti, A. (Eds.), Proceedings of the Nineteenth International Joint Conference
on Artificial Intelligence (IJCAI05), pp. 364369. Professional Book Center.
769

fiBonatti, Lutz, & Wolter

Baader, F., Milicic, M., Lutz, C., Sattler, U., & Wolter, F. (2005b). Integrating description logics and action formalisms for reasoning about web services. LTCSreport LTCS-05-02, Chair for Automata Theory, Institute for Theoretical Computer Science, Dresden University of Technology, Germany. See http://lat.inf.tudresden.de/research/reports.html.
Baader, F., & Hollunder, B. (1995a). Embedding defaults into terminological knowledge
representation formalisms.. Journal of Automated Reasoning, 14 (1), 149180.
Baader, F., & Hollunder, B. (1995b). Priorities on defaults with prerequisites, and their application in treating specificity in terminological default logic.. Journal of Automated
Reasoning, 15 (1), 4168.
Baader, F., McGuiness, D. L., Nardi, D., & Patel-Schneider, P. (2003). The Description
Logic Handbook: Theory, implementation and applications. Cambridge University
Press.
Baader, F., & Sattler, U. (2000). Tableau algorithms for description logics. In Dyckhoff,
R. (Ed.), Proceedings of the International Conference on Automated Reasoning with
Tableaux and Related Methods (Tableaux2000), Vol. 1847 of Lecture Notes in Artificial
Intelligence, pp. 118. Springer-Verlag.
Berger, R. (1966). The undecidability of the dominoe problem. Memoirs of the American
Mathematical Society, 66.
Blackburn, P., & van Benthem, J. (2007). Modal logic: a semantic perspective. In Handbook
of Modal Logic. Elsevier.
Blackburn, P., de Rijke, M., & Venema, Y. (2001). Modal Logic. Cambridge University
Press.
Bonatti, P., Faella, M., & Sauro, L. (2009). Defeasible inclusions in low-complexity DLs:
Preliminary notes. In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI09). AAAI Press.
Bonatti, P., Lutz, C., & Wolter, F. (2006). Expressive non-monotonic description logics
based on circumscription. In Proceedings of the Tenth International Conference on
Principles of Knowledge Representation and Reasoning (KR06), pp. 400410. AAAI
Press.
Bonatti, P. A., & Eiter, T. (1996). Querying disjunctive databases through nonmonotonic
logics.. Theoretical Computer Science, 160 (1&2), 321363.
Bonatti, P. A., & Samarati, P. (2003). Logics for authorization and security. In Logics for
Emerging Applications of Databases, pp. 277323. Springer-Verlag.
Borgida, A. (1996). On the relative expressiveness of description logics and predicate logics.
Artificial Intelligence, 82 (1 - 2), 353367.
Brewka, G. (1987). The logic of inheritance in frame systems. In Proceedings of the 10th
International Joint Conference on Artificial Intelligence (IJCAI87), pp. 483488. Morgan Kaufmann.
770

fiThe Complexity of Circumscription in DLs

Brewka, G. (1994). Adding priorities and specificity to default logic.. In Proceedings of
Logics in Artificial Intelligence (JELIA94), Vol. 838 of Lecture Notes in Computer
Science, pp. 247260. Springer-Verlag.
Cadoli, M., Donini, F., & Schaerf, M. (1990). Closed world reasoning in hybrid systems.
In Proceedings of the 6th International Symposium on Methodologies for Intelligent
Systems (ISMIS90), pp. 474481. Elsevier.
Calvanese, D., Giacomo, G. D., Lembo, D., Lenzerini, M., & Rosati, R. (2007). Tractable
reasoning and efficient query answering in description logics: The DL-lite family. Journal of Automated Reasoning, 39 (3), 385429.
Cote, R., Rothwell, D., Palotay, J., Beckett, R., & Brochu, L. (1993). The systematized
nomenclature of human and veterinary medicine. Tech. rep., SNOMED International,
Northfield, IL: College of American Pathologists.
de Kleer, J., & Konolige, K. (1989). Eliminating the fixed predicates from circumscription.
Artificial Intelligence, 39 (3), 391398.
Donini, F. M., Lenzerini, M., Nardi, D., Nutt, W., & Schaerf, A. (1998). An epistemic
operator for description logics.. Artificial Intelligence, 100 (1-2), 225274.
Donini, F. M., Nardi, D., & Rosati, R. (1997). Autoepistemic description logics. In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence (IJCAI97), pp. 136141. Morgan Kaufmann.
Donini, F. M., Nardi, D., & Rosati, R. (2002). Description logics of minimal knowledge and
negation as failure. ACM Transactions on Computational Logic, 3 (2), 177225.
Eiter, T., Gottlob, G., & Mannila, H. (1997). Disjunctive Datalog. ACM Transactions on
Database Systems, 22 (3), 364418.
Eiter, T., Lukasiewicz, T., Schindlauer, R., & Tompits, H. (2004). Combining answer set
programming with description logics for the semantic web. In Proceedings of the
Ninth International Conference on the Principles of Knowledge Representation and
Reasoning (KR 2004), pp. 141151.
Giordano, L., Gliozzi, V., Olivetti, N., & Pozzato, G. L. (2008). Reasoning about typicality
in preferential description logics. In Proceedings of Logics in Artificial Intelligence
(JELIA08), Vol. 5293 of Lecture Notes in Computer Science, pp. 192205. SpringerVerlag.
Goldblatt, R. (2003). Mathematical modal logic: A view of its evolution. Journal of Applied
Logic, 1, 309392.
Gradel, E., Otto, M., & Rosen, E. (1997). Two-Variable Logic with Counting is Decidable.
In Proceedings of Twelfth IEEE Symposium on Logic in Computer Science (LICS97),
pp. 306317. IEEE Computer Society Press.
Grimm, S., & Hitzler, P. (2008). Defeasible inference with circumscriptive OWL ontologies.
In Proceedings of the Workshop on Advancing Reasoning on the Web: Scalability and
Commonsense, No. 350 in CEUR-WS (http://ceur-ws.org/).
Horrocks, I., Sattler, U., & Tobies, S. (2000). Practical reasoning for very expressive description logics. Logic Journal of the IGPL, 8 (3), 239264.
771

fiBonatti, Lutz, & Wolter

Horty, J. F. (1994). Some direct theories of nonmonotonoc inheritance. In Handbook of
Logic in Artificial Intelligence and Logic Programming-Nonmonotonic Reasoning and
Uncertain Reasoning(Volume 3), pp. 111187. Clarendon Press.
Janhunen, T. (1999). On the intertranslatability of non-monotonic logics. Annals of Mathematics in Artificial Intelligence, 27 (1-4), 79128.
Kagal, L., Finin, T., & Joshi, A. (2003). A policy language for a pervasive computing
environment. In Fourth IEEE International Workshop on Policies for Distributed
Systems and Networks (POLICY2003).
Knorr, M., Alferes, J. J., & Hitzler, P. (2007). A well-founded semantics for hybrid MKNF
knowledge bases. In Proceedings of the 2007 International Workshop on Description
Logics (DL2007), No. 250 in CEUR-WS (http://ceur-ws.org/).
Konev, B., Lutz, C., Walther, D., & Wolter, F. (2008). Semantic modularity and module extraction in description logics. In Proceedings of 18th European Conference on
Artificial Intelligence (ECAI), pp. 5559.
Lambrix, P., Shahmehri, N., & Wahlloef, N. (1998). A default extension to description
logics for use in an intelligent search engine. In : Proceedings of the Thirty-First
Annual Hawaii International Conference on System Sciences (HICSS98)-Volume 5,
p. 2835. IEEE Computer Society.
Lifschitz, V. (1985). Computing circumscription. In Proceedings of the Ninth International Joint Conference on Artificial Intelligence (IJCAI85), pp. 121127. Morgan
Kaufmann.
Lifschitz, V. (1993). Circumscription. In The Handbook of Logic in AI and Logic Programming 3, pp. 298352. Oxford University Press.
Lifschitz, V. (1995). Nested abnormality theories. Artificial Intelligence, 74 (2), 351365.
McCarthy, J. (1980). Circumscription: a form of nonmonotonic reasoning. Artificial Intelligence, 13, 2739.
McCarthy, J. (1986). Applications of circumscription in formalizing common sense knowledge. Artificial Intelligence, 28, 89116.
Minsky, M. (1975). A framework for representating knowledge. In Winston, P. H. (Ed.),
The Psychology of Computer Vision, pp. 211277. McGraw-Hill.
Moore, R. C. (1985). Semantical considerations on nonmonotonic logics. Artificial Intelligence, 25, 7594.
Motik, B., & Rosati, R. (2007). A Faithful Integration of Description Logics with Logic
Programming. In Proceedings of the Twentieth International Joint Conference on
Artificial Intelligence (IJCAI2007), pp. 477482. Morgan Kaufmann.
Pacholski, L., Szwast, W., & Tendera, L. (2000). Complexity results for first-order twovariable logic with counting. SIAM Journal on Computing, 29 (4), 10831117.
Padgham, L., & Zhang, T. (1993). A terminological logic with defaults: A definition and
an application. In Proceedings of the Thirteenth International Joint Conference on
Artificial Intelligence (IJCAI93), pp. 662668. Morgan Kaufmann.
772

fiThe Complexity of Circumscription in DLs

Pratt-Hartmann, I. (2005). Complexity of the two-variable fragment with counting quantifiers. Journal of Logic, Language, and Information, 14 (3), 369395.
Quillian, M. R. (1968). Semantic memory. In Semantic Information Processing, pp. 227270.
MIT Press.
Rector, A. (2004). Defaults, context, and knowledge: Alternatives for OWL-indexed knowledge bases. In Proceedings of the Pacific Symposium on Biocomputing (PSB04), pp.
226237. World Scientific.
Rector, A., & Horrocks, I. (1997). Experience building a large, re-usable medical ontology
using a description logic with transitivity and concept inclusions. In Proceedings of
the Workshop on Ontological Engineering, AAAI Spring Symposium. AAAI Press.
Reiter, R. (1980). A logic for default reasoning. Artificial Intelligence, 13, 81132.
Stevens, R., Aranguren, M. E., Wolstencroft, K., Sattler, U., Drummond, N., Horridge,
M., & Rector, A. (2005). Using OWL to model biological knowledge. International
Journal of Man-Machine Studies, 65 (7), 583594.
Stewart, I. A. (1991). Complete problems involving Boolean labelled structures and projection transactions. Journal of Logic and Computation, 1 (6), 861882.
Straccia, U. (1993). Default inheritance reasoning in hybrid KL-ONE-style logics.. In
Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence
(IJCAI93), pp. 676681. Morgan Kaufmann.
Thomason, S. (1975a). The logical consequence relation of propositional tense logic.
Zeitschrift fur Mathematische Logik und Grundlagen der Mathematik, 21, 2940.
Thomason, S. (1975b). Reduction of second-order logic to modal logic. Zeitschrift fur
Mathematische Logik und Grundlagen der Mathematik, 21, 107114.
Tobies, S. (2000). The complexity of reasoning with cardinality restrictions and nominals in
expressive description logics. Journal of Artificial Intelligence Research, 12, 199217.
Tonti, G., Bradshaw, J. M., Jeffers, R., Montanari, R., Suri, N., & Uszok, A. (2003). Semantic web languages for policy representation and reasoning: A comparison of KAoS,
Rei, and Ponder. In Proceedings of the Second International Semantic Web Conference
(ISWC03), Vol. 2870 of Lecture Notes in Computer Science, pp. 419437. SpringerVerlag.
Uszok, A., Bradshaw, J. M., Johnson, M., Jeffers, R., Tate, A., Dalton, J., & Aitken, S.
(2004). KAoS policy management for semantic web services. IEEE Intelligent Systems,
19 (4), 3241.
Wolter, F., & Zakharyaschev, M. (2007). Modal decision problems. In Handbook of Modal
Logic. Elsevier.
Y. Ding, V. H., & Wu, J. (2007). A new mapping from ALCI to ALC. In In Proceedings of
the 2007 International Workshop on Description Logics (DL2007), No. 250 in CEURWS (http://ceur-ws.org/).

773

fiJournal of Artificial Intelligence Research 35 (2009) 193-234

Submitted 4/08; published 6/09

Transductive Rademacher Complexity and its Applications
Ran El-Yaniv
Dmitry Pechyony

rani@cs.technion.ac.il
pechyony@cs.technion.ac.il

Department of Computer Science
Technion - Israel Institute of Technology
Haifa, 32000, Israel

Abstract
We develop a technique for deriving data-dependent error bounds for transductive
learning algorithms based on transductive Rademacher complexity. Our technique is based
on a novel general error bound for transduction in terms of transductive Rademacher complexity, together with a novel bounding technique for Rademacher averages for particular
algorithms, in terms of their unlabeled-labeled representation. This technique is relevant
to many advanced graph-based transductive algorithms and we demonstrate its effectiveness by deriving error bounds to three well known algorithms. Finally, we present a new
PAC-Bayesian bound for mixtures of transductive algorithms based on our Rademacher
bounds.

1. Introduction
Alternative learning models that utilize unlabeled data have received considerable attention
in the past few years. Two prominent models are semi-supervised and transductive learning. The main attraction of these models is theoretical and empirical evidence (Chapelle,
Scholkopf, & Zien, 2006) indicating that they can often allow for more efficient and significantly faster learning in terms of sample complexity. In this paper we support the theoretical
evidence by providing risk bounds for a number of state-of-the-art transductive algorithms.
These bounds utilize both labeled and unlabeled examples and can be much tighter than
the bounds relying on labeled examples alone.
Here we focus on distribution-free transductive learning. In this setting we are given a
labeled training sample as well as an unlabeled test sample. The goal is to guess the labels of
the given test points as accurately as possible1 . Rather than generating a general hypothesis
capable of predicting the label of any point, as in inductive learning, it is advocated by
Vapnik (1982) that we should aim in transduction to solve an easier problem by transferring
knowledge directly from the labeled points to the unlabeled ones.
Transductive learning was already proposed and briefly studied more than thirty years
ago by Vapnik and Chervonenkis (1974), but only lately has it been empirically recognized
that transduction can often facilitate more efficient or accurate learning than the traditional supervised learning approach (Chapelle et al., 2006). This recognition has motivated
a flurry of recent activity focusing on transductive learning, with many new algorithms
1. Many papers refer to this model as semi-supervised learning. However, the setting of semi-supervised
learning is different from transduction. In semi-supervised learning the learner is given randomly drawn
training set consisting of labeled and unlabeled examples. The goal of the learner is to generate a
hypothesis providing accurate predictions on the unseen examples.
c
2009
AI Access Foundation. All rights reserved.

fiEl-Yaniv & Pechyony

and heuristics being proposed. Nevertheless, issues such as the identification of universally effective learning principles for transduction remain unresolved. Statistical learning
theory provides a principled approach for attacking such questions through the study of
error bounds. For example, in inductive learning such bounds have proven instrumental in
characterizing learning principles and deriving practical algorithms (Vapnik, 2000).
In this paper we consider the classification setting of transductive learning. So far,
several general error bounds for transductive classification have been developed by Vapnik (1982), Blum and Langford (2003), Derbeko, El-Yaniv, and Meir (2004), El-Yaniv and
Pechyony (2006). We continue this fruitful line of research and develop a new technique
for deriving explicit data-dependent error bounds. These bounds are less tight than implicit ones, developed by Vapnik and by Blum and Langford. However the explicit bounds
may potentially be used for model selection and guide the development of new learning
algorithms.
Our technique consists of two parts. In the first part we develop a novel general error
bound for transduction in terms of transductive Rademacher complexity. While this bound
is syntactically similar to known inductive Rademacher bounds (see, e.g., Bartlett & Mendelson, 2002), it is fundamentally different in the sense that the transductive Rademacher complexity is computed with respect to the hypothesis space that can be chosen after observing
unlabeled training and test examples. This opportunity is unavailable in the inductive
setting where the hypothesis space must be fixed before any example is observed.
The second part of our bounding technique is a generic method for bounding Rademacher
complexity of transductive algorithms based on their unlabeled-labeled representation (ULR).
In this representation the soft-classification vector generated by the algorithm is a product
U , where U is a matrix that depends on the unlabeled data and  is a vector that may
depend on all given information, including the labeled training set. Any transductive algorithm has infinite number of ULRs, including a trivial ULR, with U being an identity
matrix. We show that many state-of-the-art algorithms have non-trivial ULR leading to
non-trivial error bounds. Based on ULR representation we bound Rademacher complexity
of transductive algorithms in terms of the spectrum of the matrix U in their ULR. This
bound justifies the spectral transformations, developed by Chapelle, Weston, and Scholkopf
(2003), Joachims (2003), Johnson and Zhang (2008), that are commonly done to improve
the performance of transductive algorithms. We instantiate the Rademacher complexity
bound for the consistency method of Zhou et al. (2004), the spectral graph transducer
(SGT) algorithm of Joachims (2003) and the Tikhonov regularization algorithm of Belkin,
Matveeva, and Niyogi (2004). The bounds obtained for these algorithms are explicit and
can be easily computed.
We also show a simple Monte-Carlo scheme for bounding the Rademacher complexity of
any transductive algorithm using its ULR. We demonstrate the efficacy of this scheme for the
consistency method of Zhou et al. (2004). Our final contribution is a PAC-Bayesian bound
for transductive mixture algorithms. This result, which is stated in Theorem 4, is obtained
as a consequence of Theorem 2 using the techniques of Meir and Zhang (2003). This result
motivates the use of ensemble methods in transduction that are yet to be explored in this
setting.
The paper has the following structure. In Section 1.1 we survey the results that are
closely related to our work. In Section 2 we define our learning model and transductive
2

fiTransductive Rademacher Complexity and its Applications

Rademacher complexity. In Section 3 we develop a novel concentration inequality for functions over partitions of the finite set of points. This inequality and transductive Rademacher
complexity are used in Section 4 to derive uniform risk bound, which depends on transductive Rademacher complexity. In Section 5 we introduce a generic method for bounding
Rademacher complexity of any transductive algorithm using its unlabeled-labeled representation. In Section 6 we exemplify this technique to obtain explicit risk bounds for several
known transductive algorithms. Finally, in Section 7 we instantiate our risk bound to
transductive mixture algorithms. We discuss directions for future research in Section 8.
The technical proofs of our results are presented in Appendices A-I.
Preliminary (and shorter) version of this paper has appeared in the Proceedings of the
20th Annual Conference on Learning Theory, page 157171, 2007.
1.1 Related Work
Vapnik (1982) presented the first general 0/1 loss bounds for transductive classification.
His bounds are implicit in the sense that tail probabilities are specified in the bound as
the outcome of a computational routine. Vapniks bounds can be refined to include prior
beliefs as noted by Derbeko et al. (2004). Similar implicit but somewhat tighter bounds
were developed by Blum and Langford (2003) for the 0/1 loss case. Explicit PAC-Bayesian
transductive bounds for any bounded loss function were presented by Derbeko et al. (2004).
Catoni (2004, 2007) and Audibert (2004) developed PAC-Bayesian and VC dimensionbased risk bounds for the special case when the size of the test set is a multiple of the
size of the training set. Unlike our PAC-Bayesian bound, the published transductive PACBayesian bounds hold for deterministic hypotheses and for Gibbs classifiers. The bounds of
Balcan and Blum (2006) for semi-supervised learning also hold in the transductive setting,
making them conceptually similar to some transductive PAC-Bayesian bounds. General
error bounds based on stability were developed by El-Yaniv and Pechyony (2006).
Effective applications of the general bounds mentioned above to particular algorithms
or learning principles is not automatic. In the case of the PAC-Bayesian bounds several
such successful applications were presented in terms of appropriate priors that promote
various structural properties of the data (see, e.g., Derbeko et al., 2004; El-Yaniv & Gerzon,
2005; Hanneke, 2006). Ad-hoc bounds for particular algorithms were developed by Belkin
et al. (2004) and by Johnson and Zhang (2007). Unlike other bounds (including ours)
the bound of Johnson and Zhang does not depend on the empirical error but only on the
properties of the hypothesis space. If the size of the training and test set increases then
their bound converges to zero2 . Thus the bound of Johnson and Zhang effectively proves the
consistency of transductive algorithms that they consider. However this bound holds only
if the hyperparameters of those algorithms are chosen w.r.t. to the unknown test labels.
Hence the bound of Johnson and Zhang cannot be computed explicitly.
Error bounds based on Rademacher complexity were introduced by Koltchinskii (2001)
and are a well-established topic in induction (see Bartlett & Mendelson, 2002, and references
therein). The first Rademacher transductive risk bound was presented by Lanckriet et al.
(2004, Theorem 24). This bound, which is a straightforward extension of the inductive
2. in all other known explicit bounds the increase of training and test sets decreases only the slack term
but not the empirical error.

3

fiEl-Yaniv & Pechyony

Rademacher techniques of Bartlett and Mendelson (2002), is limited to the special case
when training and test sets are of equal size. The bound presented here overcomes this
limitation.

2. Definitions
In Section 2.1 we provide a formal definition of our learning model. Then in Section 2.2 we
define transductive Rademacher complexity and compare it with its inductive counterpart.
2.1 Learning Model
In this paper we use a distribution-free transductive model, as defined by Vapnik (1982,
M
Section 10.1, Setting 1). Consider a fixed set Sm+u = {(xi , yi )}m+u
i=1 of m + u points xi
in some space together with their labels yi . The learner is provided with the (unlabeled)
M
full-sample Xm+u = {xi }m+u
i=1 . A set consisting of m points is selected from Xm+u uniformly
at random among all subsets of size m. These m points together with their labels are given
to the learner as a training set. Re-numbering the points we denote the unlabeled training
M
M
set points by Xm = {x1 , . . . , xm } and the labeled training set by Sm = {(xi , yi )}m
i=1 . The
M
set of unlabeled points Xu = {xm+1 , . . . , xm+u } = Xm+u \ Xm is called the test set. The
learners goal is to predict the labels of the test points in Xu based on Sm  Xu .
Remark 1 In our learner model each example xi has unique label yi . However we allow
that for i 6= j, xi = xj but yi 6= yj .
The choice of the set of m points as described above can be viewed in three equivalent
ways:
1. Drawing m points from Xm+u uniformly without replacement. Due to this draw, the
points in the training and test sets are dependent.
2. Random permutation of the full sample Xm+u and choosing the first m points as a
training set.
3. Random partitioning of m + u points into two disjoint sets of m and u points.
To emphasize different aspects of the transductive learning model, throughout the paper
we use interchangeably these three views on the generation of the training and test sets.
This paper focuses on binary learning problems where labels y  {1}. The learning
algorithms we consider generate soft classification vectors h = (h(1), . . . h(m + u)) 
Rm+u , where h(i) (or h(xi )) is the soft, or confidence-rated, label of example xi given by
the hypothesis h. For actual (binary) classification of xi the algorithm outputs sgn(h(i)).
We denote by Hout  Rm+u the set of all possible soft classification vectors (over all possible
tranining/test partitions) that are generated by the algorithm.
Based on the full-sample Xm+u , the algorithm selects an hypothesis space H  Rm+u
of soft classification hypotheses. Note that Hout  H. Then, given the labels of training
points the algorithm outputs one hypothesis h from Hout  H for classification. The goal
M
of the transductive learner is to find a hypothesis h minimizing the test error Lu (h) =
4

fiTransductive Rademacher Complexity and its Applications

1 Pm+u
i=m+1 `(h(i), yi ) w.r.t.
u
1 Pm
i=1 `(h(i), yi ) and the
m

M
the 0/1 loss function `. The empirical error of h is Lbm (h) =
P
M
m+u
1
full sample error of h is Lm+u (h) = m+u
i=1 `(h(i), yi ). In
this work we also use the margin loss function ` . For a positive real , ` (y1 , y2 ) = 0 if
y1 y2   and ` (y1 , y2 ) = min{1, 1  y1 y2 /} otherwise. The empirical (margin) error of
M 1 Pm

h is Lbm (h) = m
i=1 ` (h(i), yi ). We denote by Lu (h) the margin error of the test set and

by Lm+u (h) the margin full sample error.
We denote by Irs , r < s, the set of natural numbers {r, r + 1, . . . , s}. Throughout the
paper we assume that the vectors are column ones. We mark all vectors with the boldface.

2.2 Transductive Rademacher Complexity
We adapt the inductive Rademacher complexity to our transductive setting but generalize
it a bit to also include neutral Rademacher values.
Definition 1 (Transductive Rademacher complexity) Let V  Rm+u and p  [0, 1/2].
Let  = (1 , . . . , m+u )T be a vector of i.i.d. random variables such that


1
M
i = 1


0

with probability
with probability
with probability

p;
p;
1  2p.

(1)

The transductive Rademacher complexity with parameter p is




1
1
M
T
Rm+u (V, p) =
+
 E sup   v .
m u
vV
The need for this novel definition of Rademacher complexity is technical. Two main
issues that lead to the new definition are:
P
1. The need to bound the test error Lu (h) = u1 m+u
i=m+1 `(h(i), yi ). Notice that in inductive risk bounds the standard definition of Rademacher complexity (see Definition 2
below), with binary values of i , is used to bound the generalization
error, which is
1 Pm+u
an inductive analogue of the full sample error Lm+u (h) = m+u
`(h(i),
yi ).
i=1
2. Different sizes (m and u respectively) of training and test set.
See Section 4.1 for more technical details that lead to the above definition of Rademacher
complexity.
For the sake of comparison we also state the inductive definition of Rademacher complexity.
Definition 2 (Inductive Rademacher complexity, Koltchinskii, 2001) Let D be a
probability distribution over X . Suppose that the examples Xn = {xi }ni=1 are sampled independently from X according to D. Let F be a class of functions mapping X to R. Let
 = {i }ni=1 be an independent uniform {1}-valued random variables, i = 1 with probability 1/2 and i = 1 with the same probability. The empirical Rademacher complex5

fiEl-Yaniv & Pechyony

(ind)
Rn (F)



Pn
2
 f (xi )
nnE supf F
o i=1 i
M
(ind)
bn (F) .
= EXn Dn R

M
bn(ind) (F) =
ity is3 R



and the Rademacher complexity of F is

M
b(ind) (V).
For the case p = 1/2, m = u and n = m + u we have that Rm+u (V) = 2R
m+u
Whenever p < 1/2, some Rademacher variables will attain (neutral) zero values and reduce
the complexity (see Lemma 1). We use this property to tighten our bounds.
Notice that the transductive complexity is an empirical quantity that does not depend
on any underlying distribution, including the one over the choices of the training set. Since
in distribution-free transductive model the unlabeled full sample of training and test points
is fixed, in transductive Rademacher complexity we dont need the outer expectation, which
appears in the inductive definition. Also, the transductive complexity depends on both the
(unlabeled) training and test points whereas the inductive complexity only depends only
on the (unlabeled) training points.
The following lemma, whose proof appears in Appendix A, states that Rm+u (V, p) is
monotone increasing with p. The proof is based on the technique used in the proof of
Lemma 5 in the paper of Meir and Zhang (2003).

Lemma 1 For any V  Rm+u and 0  p1 < p2  1/2, Rm+u (V, p1 ) < Rm+u (V, p2 ).
In the forthcoming results we utilize the transductive Rademacher complexity with
M
M
mu
p0 = (m+u)
2 . We abbreviate Rm+u (V) = Rm+u (V, p0 ). By Lemma 1, all our bounds also

apply to Rm+u (V, p) for all p > p0 . Since p0 < 21 , the Rademacher complexity involved in
our results is strictly smaller than the standard inductive Rademacher complexity defined
over Xm+u . Also, if transduction approaches the induction, namely m is fixed and u  ,
b(ind) (V)  2Rm+u (V).
then R
m+u

3. Concentration Inequalities for Functions over Partitions
In this section we develop a novel concentration inequality for functions over partitions
and compare it to the several known ones. Our concentration inequality is utilized in the
derivation of the forthcoming risk bound.
M
M
Let Z = Zm+u
= (Z1 , . . . , Zm+u ) be a random permutation vector where the variable
1
Zk , k  I1m+u , is the kth component of a permutation of I1m+u that is chosen uniformly at
random. Let Zij be a perturbed permutation vector obtained by exchanging the values of Zi
and Zj in Z. Any function f on permutations of I1m+u is called (m, u)-permutation symmetM
ric if f (Z) = f (Z1 , . . . , Zm+u ) is symmetric on Z1 , . . . , Zm as well as on Zm+1 , . . . , Zm+u .
In this section we present a novel concentration inequality for (m, u)-permutation symmetric functions. Note that an (m, u)-permutation symmetric function is essentially a function over the partition of m + u items into sets of sizes m and u. Thus, the forthcoming
inequalities of Lemmas 2 and 3, while being stated for (m, u)-permutation symmetric functions, also hold in exactly the same form for functions over partitions. Conceptually it is
3. The original definition of Rademacher complexity,P
as given by Koltchinskii
(2001),P
is slightly different

n

from the one presented here, and contains supf F  n
i=1 i f (xi ) instead of supf F
i=1 i f (xi ). However, from the conceptual point of view, Definition 2 and the one given by Koltchinskii are equivalent.

6

fiTransductive Rademacher Complexity and its Applications

more convenient to view our results as concentration inequalities for functions over partitions. However, from a technical point of view we find it more convenient to consider
(m, u)-permutation symmetric functions.
The following lemma (that will be utilized in the proof of Theorem 1) presents a concentration inequality that is an extension of Lemma 2 of El-Yaniv and Pechyony (2006).
The proof (appearing in Appendix B) relies on McDiarmids inequality (McDiarmid, 1989,
Corollary 6.10) for martingales.
m+u
Lemma 2 Let Z be a random permutation
an (m, u) vector over
I1 . Let f (Z) be
m+u
ij


permutation symmetric function satisfying f (Z)  f (Z )   for all i  I1m , j  Im+1
.
Then



22 (m + u  1/2)
1
PZ {f (Z)  EZ {f (Z)}  }  exp 
1
.
(2)
mu 2
2 max(m, u)



2  1
1
The right hand side of (2) is approximately exp  2
+
. A similar, but less tight
2
m
u

inequality can be obtained by reduction of the draw of random permutation to the draw
of min(m, u) independent random variables and application of the bounded difference inequality of McDiarmid (1989):
Lemma 3 Suppose that the conditions of Lemma 2 hold. Then

PZ {f (Z)  EZ {f (Z)}  }  exp 

22
 2 min(m, u)


.

(3)

The proof of Lemma 3 appears in Appendix C.
Remark 2 The inequalities developed in Section 5 of Talagrand (1995) imply a concentration inequality that is similar to (3), but with worse constants.
The inequality (2) is defined for any (m, u)-permutation symmetric function f . By
specializing f we obtain the following two concentration inequalities:
P
1 Pm
Remark 3 If g : I1m+u  {0, 1} and f (Z) = u1 m+u
i=m+1 g(Zi )  m
i=1 g(Zi ), then
m+u
1
EZ {f (Z)} = 0. Moreover, for any i  I1m , j  Im+1
, |f (Z)  f (Zij )|  m
+ u1 . Therefore,
by specializing (2) for such f we obtain
(
PZ

m+u
m
1 X
1 X
g(Zi ) 
g(Zi )  
u
m
i=m+1

i=1

)

 2

 mu(m + u  1/2) 2 max(m, u)  1
 exp 

.
(m + u)2
max(m, u)

(4)

The right hand side of (4) is approximately exp
. The inequality (4) is an explicit (and looser) version of Vapniks absolute bound (see El-Yaniv & Gerzon, 2005). We
note that using (2) we were unable to obtain an explicit version of Vapniks relative bound
(inequality 10.14 of Vapnik, 1982).


7

2 mu
 2m+u

fiEl-Yaniv & Pechyony

1 Pm
1 Pm+u
Remark 4 If g : I1m+u  {0, 1}, f (Z) = m
i=1 g(Zi ), then EZ {f (Z)} = m+u
i=1 g(Zi ).
m+u
1
m
ij
Moreover, for any i  I1 , j  Im+1 , |f (Z)  f (Z )|  m . Therefore, by specializing (2)
for such f we obtain
(
)
 2

m
m+u
X
1 X
1
 (m + u  1/2)m 2 max(m, u)  1
g(Zi ) 
g(Zi )    exp 

PZ
.
m
m+u
u
max(m, u)
i=1
i=1
(5)


22 (m+u)m
. This bound is asymptotically
The right hand side of (5) is approximately exp 
u
the same as following bound, which was developed by Serfling (1974):
(
)


m
m+u
X
1 X
1
22 (m + u)m
PZ
g(Zi ) 
g(Zi )    exp 
.
m
m+u
u+1
i=1

i=1

4. Uniform Rademacher Error Bound
In this section we develop a transductive risk bound, which is based on transductive
Rademacher complexity (Definition 1). The derivation follows the standard two-step scheme,
as in induction4 :
1. Derivation of a uniform concentration inequality for a set of vectors (or functions).
This inequality depends on the Rademacher complexity of the set. After substituting
to the vectors (or functions) the values of the loss functions, we obtain an error bound
depending on the Rademacher complexity of the values of the loss function. This step
is done in Section 4.1.
2. In order to bound the Rademacher complexity in terms of the properties of the hypothesis space, the Rademacher complexity is translated, using its contraction property (Ledoux & Talagrand, 1991, Theorem 4.12), from the domain of loss function
values to the domain of soft hypotheses from the hypothesis space. This step is done
in Section 4.2.
As we show in Sections 4.1 and 4.2, the adaptation of both these steps to the transductive
setting is not immediate and involves several novel ideas. In Section 4.3 we combine the
results of these two steps and obtain a transductive Rademacher risk bound. We also
provide a thorough comparison of our risk bound with the corresponding inductive bound.
4.1 Uniform Concentration Inequality for a Set of Vectors
As in induction (Koltchinskii & Panchenko, 2002), our derivation of a uniform concentration
inequality for a set of vectors consists of three steps:
1. Introduction of the ghost sample.
2. Bounding the supremum suphH g(h), where g(h) is some random real-valued function, with its expectation using a concentration inequality for functions of random
variables.
4. This scheme was introduced by Koltchinskii and Panchenko (2002). The examples of other uses of this
technique can be found in the papers of Bartlett and Mendelson (2002) and Meir and Zhang (2003).

8

fiTransductive Rademacher Complexity and its Applications

3. Bounding the expectation of the supremum using Rademacher variables.
While we follow these three steps as in induction, the establishment of each of these steps can
not be achieved using inductive techniques. Throughout this section, after performing the
derivation of each step in transductive context we discuss its differences from its inductive
counterpart.
We introduce several new definitions. Let V be a set of vectors in [B1 , B2 ]m+u , B1 
M
0, B2  0 and set B = B2  B1 , Bmax = max(|B1 |, |B2 |). Consider two independent
permutations of I1m+u , Z and Z0 . For any v  V denote by
M

v(Z) = (v(Z1 ), v(Z2 ), . . . , v(Zm+u )) ,
the vector v permuted according to Z. We use the following abbreviations for averages of
M 1 Pm+u
M 1 Pk
v over subsets of its components: Hk {v(Z)} = m
i=1 v(Zi ), Tk {v(Z)} = u
i=k+1 v(Zi )
(note that H stands for head and T, for tail). In the special case where k = m we set
M
M
H{v(Z)} = Hm {v(Z)}, and T{v(Z)} = Tm {v(Z)}. The uniform concentration inequality
that we develop shortly states that for any  > 0, with probability at least 1 over random
permutation Z of I1m+u , for any v  V,
s
!
1
1
T{v(Z)}  H{v(Z)} + Rm+u (V) + O
ln
.
min(m, u) 

Step 1: Introduction of the ghost sample.
M
1 Pm+u
We denote by v = m+u
i=1 v(i) the average component of v. For any v  V and
m+u
any permutation Z of I1
we have

T{v(Z)} = H{v(Z)} + T{v(Z)}  H{v(Z)}
h
i
 H{v(Z)} + sup T{v(Z)}  v + v  H{v(Z)}
vV
h
i
= H{v(Z)} + sup T{v(Z)}  EZ0 T{v(Z0 )} + EZ0 H{v(Z0 )}  H{v(Z)}
vV
h
i
 H{v(Z)} + EZ0 sup T{v(Z)}  T{v(Z0 )} + H{v(Z0 )}  H{v(Z)} . (6)
vV
|
{z
}
M

=(Z)

Remark 5 In this derivation the ghost sample is a permutation Z0 of m + u elements
drawn from the same distribution as Z. In inductive Rademacher-based risk bounds the
ghost sample is a new training set of size m, independently drawn from the original one.
Note that in our transductive setting the ghost sample corresponds to the independent draw
of training/test set partition, which is equivalent to the independent draw of random permutation Z0 .
Remark 6 In principle we could avoid the introduction of the ghost sample Z0 and consider
m elements in H{v(Z)} as ghosts of u elements in T{v(Z)}. This approach would lead to
9

fiEl-Yaniv & Pechyony

a new definition of Rademacher averages (with i = 1/m with probability m/(m + u) and
1/u with probability u/(m + u)). With this definition we can obtain Corollary 1. However,
since the distribution of alternative Rademacher averages is not symmetric around zero,
technically we do not know how to prove the Lemma 5 (the contraction property).
Step 2: Bounding the supremum with its expectation.
M

m+u
Let S = (m+u1/2)(11/(2
max(m,u))) . For sufficiently large m and u, the value of S is almost 1. The function (Z) is (m, u)-permutation symmetric in Z. It can be verified that
1

1

M
|(Z)  (Zij )|  B m
+ u1 . Therefore, we can apply Lemma 2 with  = B m
+ u1 to
(Z). We obtain, with probability of at least 1   over random permutation Z of I1m+u ,
for all v  V:
s 

S 1
1
1
T{v(Z)}  H{v(Z)} + EZ {(Z)} + B
+
ln .
(7)
2 m u


Remark 7 In induction this step is performed using an application of McDiarmids bounded
difference inequality (McDiarmid, 1989, Lemma 1.2). We cannot apply this inequality in
our setting since the function under the supremum (i.e. (Z)) is not a function over independent variables, but rather over permutations. Our Lemma 2 replaces the bounded
difference inequality in this step.
Step 3: Bounding the expectation over the supremum using Rademacher random variables.
Our goal is to bound the expectation EZ {(Z)}. This is done in the following lemma.
Lemma 4 Let Z be a random permutation of

I1m+u .


EZ {(Z)}  Rm+u (V) + c0 Bmax

q

M

Let c0 =

1
1
+
u m



p

32 ln(4e)
3

< 5.05. Then

min(m, u) .

Proof: The proof is based on ideas from the proof of Lemma 3 from Bartlett and Mendelson
(2002). For technical convenience we use the following definition of pairwise Rademacher
variables.
Definition 3 (Pairwise Rademacher variables) Let v = (v(1), . . . , v(m + u))  Rm+u .
m+u
Let V be a set of vectors from Rm+u . Let  = {i }i=1
be a vector of i.i.d. random variables
defined as:
 1

mu
 m ,  u1
with probability (m+u)

2 ;





m2
 1, 1
with probability (m+u)2 ;
(8)
i = (i,1 , i,2 ) =  1 m1 m
mu

,
with
probability
;

2
u m
(m+u)



 1
1
u2
,

with
probability
.
u
u
(m+u)2
We obtain Definition 3 from Definition 1 (with p =
Rademacher variable i = 1 then we split it to i =
10

mu
2)
(m+u)
1 1 
u, m .

in the following way. If the
If the Rademacher variable

fiTransductive Rademacher Complexity and its Applications

 1

1
i = 1 then we split
m, 
u . If the Rademacher variable i = 0 then we
 it1 to1 i =  

split it randomly to  m , m or u1 ,  u1 . The first component of i indicates if the ith
component of v is in the first elements of v(Z) or in the last u elements of v(Z). If the
1
former case the value of i is  m
and in the latter case the value of i is u1 . The second
component of i has the same meaning as the first one, but with Z replaced by Z0 .
1
The values  m
and  u1 are exactly the coefficients appearing inside T{v(Z)}, T{v(Z0 )},
0
H{v(Z )} and H{v(Z)} in (6). These coefficients are random and their distribution is
induced by the uniform distribution over permutations. In the course of the proof we will
1
establish the precise relation between the distribution of  m
and  u1 coefficients and the
distribution (8) of pairwise Rademacher variables.
It is easy to verify that
(
)
m+u
X
Rm+u (V) = E sup
(i,1 + i,2 )v(i) .
(9)
vV i=1

 1

Let n1 , n2 and n3 be the number of random variables i realizing the value  m
,  u1 ,
 1 1  1 1 
M
M
 m , m , u , m , respectively. Set N1 = n1 + n2 and N2 = n2 + n3 . Note that the ni s
and Ni s are random variables. Denote by Rad the distribution of  defined by (8) and by
Rad(N1 , N2 ), the distribution Rad conditioned on the events n1 +n2 = N1 and n2 +n3 = N2 .
We define
(
)
m+u
X
M
s(N1 , N2 ) = ERad(N1 ,N2 ) sup
(i,1 + i,2 ) v(i) .
vV i=1

The rest of the proof is based on the following three claims:
Claim 1. Rm+u (V) = EN1 ,N2 {s(N1 , N2 )}.
Claim 2. EZ {(Z)} = s (E N1 , E N2 ).
Claim 3. s (E N1 , E N2 )  EN1 ,N2 {s(N1 , N2 )}  c0 Bmax

1

u

+

1
m


m.

Having established these three claims we immediately obtain


1
1 
EZ {g(Z)}  Rm+u (V) + c0 Bmax
+
m .
u m

(10)

The entire development is symmetric in m and u and, therefore, we also obtain the same


result but with u instead of m. By taking the minimum of (10) and the symmetric

bound (with u) we establish the theorem.
The proof of the above three claims appears in Appendix D.

Remark 8 The technique we use to bound the expectation of the supremum is more complicated than the technique of Koltchinskii and Panchenko (2002) that is commonly used
in induction. This is caused by the structure of the function under the supremum (i.e.,
g(Z)). From a conceptual point of view, this step utilizes our novel definition of transductive Rademacher complexity.
By combining (7) and Lemma 4 we obtain the next concentration inequality, which is
the main result of this section.
11

fiEl-Yaniv & Pechyony

Theorem 1 Let B1  0, B2  0 and V be a (possibly infinite) set of real-valued vectors

M
M
M
M 
1
in [B1 , B2 ]m+u . Let B = B2  B1 and Bmax = max(|B1 |, |B2 |). Let Q = u1 + m
, S =
q
M
32 ln(4e)
m+u
< 5.05. Then with probability of at least 1  
3
(m+u1/2)(11/2(max(m,u))) and c0 =
m+u
over random permutation Z of I1 , for all v  V,
p
T{v(Z)}  H{v(Z)} + Rm+u (V) + Bmax c0 Q min(m, u) + B

r

1
S
Q ln .
(11)
2

q
p
We defer the analysis of the slack terms Bmax c0 Q min(m, u) and B S2 Q ln 1 to Section 4.3. We now instantiate the inequality (11) to obtain our first risk bound. The idea
is to apply Theorem 1 with an appropriate instantiation of the set V so that T{v(Z)} will
correspond to the test error and H{v(Z)} to the empirical error. For a true (unknown)
labeling of the full-sample y and any h  Hout we define
M

`y (h) = (`(h(1), y1 ), . . . , `(h(m + u), ym+u ))
and set LH = {v : v = `y (h), h  Hout }. Thus `y (h) is a vector of the values of the
0/1 loss over all full sample examples, when transductive algorithm is operated on some
training/test partition. The set LH is the set of all possible vectors `y (h), over all possible
M
M
training/test partitions. We apply Theorem 1 with V = LH , v = `(h), Bmax = B = 1 and
obtain the following corollary:
Corollary 1 Let Q, S and c0 be as defined in Theorem 1. For any  > 0, with probability
of at least 1   over the choice of the training set from Xm+u , for all h  Hout ,
r
p
1
S
Q ln .
(12)
Lu (h)  Lbm (h) + Rm+u (LH ) + Bmax c0 Q min(m, u) +
2

q
p
We defer the analysis of the slack terms Bmax c0 Q min(m, u) and B S2 Q ln 1 to Section 4.3.
While the bound (12) is obtained by a straightforward application of the concentration
inequality (11), it is not convenient to deal with. Thats because it is not clear how to bound
the Rademacher complexity Rm+u (LH ) of the 0/1 loss values in terms of the properties of
transductive algorithm. In the next sections we eliminate this deficiency by utilizing margin
loss function.
4.2 Contraction of Rademacher Complexity
The following lemma is a version of the well-known contraction principle of the theory of
Rademacher averages (see Theorem 4.12 of Ledoux & Talagrand, 1991, and Ambroladze,
Parrado-Hernandez, & Shawe-Taylor, 2007). The lemma is an adaptation, which accommodates the transductive Rademacher variables, of Lemma 5 of Meir and Zhang (2003). The
proof is provided in Appendix E.
Lemma 5 Let V  Rm+u be a set of vectors. Let f and g be real-valued functions. Let
 = {i }m+u
i=1 be Rademacher variables, as defined in (1). If for all 1  i  m + u and any
12

fiTransductive Rademacher Complexity and its Applications

v, v0  V, |f (vi )  f (vi0 )|  |g(vi )  g(vi0 )|, then
"m+u
#
"m+u
#
X
X
E sup
i f (vi )  E sup
i g(vi ) .
vV

vV

i=1

i=1

Let y = (y1 , . . . , ym+u )  Rm+u be a true (unknown) labeling of the full-sample. Similarly to what was done in the derivation of Corollary 1, for any h  Hout we define
M
`y (h(i)) = ` (h(i), yi ) and
M

`y (h) = (`y (h(1)), . . . , `Y (h(m + u)))
and set LH = {v : v = `y (h), h  Hout }. Noting that `y satisfies the Lipschitz condition
M
M
|`y (h(i))  `y (h0 (i))|  1 |h(i)  h0 (i)|, we apply Lemma 5 with V = LH , f (vi ) = `y (h(i))
M

and g(vi ) = h(i)/, to get
(
E

sup

m+u
X

hHout i=1

)
i `y (h(i))

It follows from (13) that
Rm+u (LH ) 

1
 E


(
sup

m+u
X

hHout i=1

1
Rm+u (Hout ) .


)
i h(i)

.

(13)

(14)

4.3 Risk Bound and Comparison with Related Results
M

M

Applying Theorem 1 with V = LH , v = ` (h), Bmax = B = 1, and using the inequality
(14) we obtain5 :
Theorem 2 Let Hout be the set of full-sample soft labelings of the algorithm, generated
by operating it on all possible training/test q
set partitions. The choice of Hout can de
M
M 1
32 ln(4e)
1
pend on the full-sample Xm+u . Let c0 =
<
5.05,
Q
=
+
3
u
m and S =
m+u
(m+u1/2)(11/(2 max(m,u))) . For any fixed , with probability of at least 1   over the choice
of the training set from Xm+u , for all h  Hout ,
r
p
Rm+u (Hout )
SQ 1


b
+ c0 Q min(m, u) +
ln .
(15)
Lu (h)  Lu (h)  Lm (h) +

2

For large enough valuesqof m and u the value of S is close 
to 1. Therefore the slack
p
p
S
1
term c0 Q min(m, u) + 2 Q ln  is of order O 1/ min(m, u) . The convergence rate of

 p
O 1/ min(m, u) can be very slow if m is very small or u  m. Slow rate for small m
is not surprising, but a latter case of u  m is somewhat surprising. However note that if
u  m then the mean  of u elements, drawn from m + u elements, has a large variance.
Hence, in this case any high-confidence interval for the estimation of  will be large. This
confidence interval is reflected in the slack term of (15).
5. This bound holds for any fixed margin parameter . Using the technique of the proof of Theorem 18 of
Bousquet and Elisseeff (2002), we can also obtain a bound that is uniform in .

13

fiEl-Yaniv & Pechyony

We now compare the bound (15) with the Rademacher-based inductive risk bounds.
We use the following variant of Rademacher-based inductive risk bound of Meir and Zhang
(2003):
Theorem 3 Let D be a probability distribution over X . Suppose that a set of examples
Sm = {(xi , yi )}m
i=1 is sampled i.i.d. from X according to D. Let F be a class of functions
(ind)
bm
each maps X to R and R
(F) be the empirical Rademacher
complexity of F (Defini1 Pm
tion 2). Let L(f ) = E(x,y)D {`(f (x), y)} and Lb (f ) = m
`
i=1  (f (xi ), yi ) be respectively
the 0/1 generalization error and empirical margin error of f . Then for any  > 0 and
 > 0, with probability of at least 1   over the random draw of Sm , for any f  F,
r
(ind)
bm
R
(F)
2 ln(2/)

L(f )  Lb (f ) +
+
.
(16)

m

The slack term in the bound (16) is of order O(1/ m). The bounds (15) and (16) are
not quantitatively comparable. The inductive bound holds with high probability over the
random selection of m examples from some distribution D. This bound is on average
(generalization) error, over all examples in D. The transductive bound holds with high
probability over the random selection of a training/test partition. This bound is on the test
error of some hypothesis over a particular set of u points.
A kind of meaningful comparison can be obtained as follows. Using the given full
(transductive) sample Xm+u , we define a corresponding inductive distribution Dtrans as
the uniform distribution over Xm+u ; that is, a training set of size m will be generated
by sampling from Xm+u m times with replacements. Given an inductive hypothesis space
F = {f } of function we define the transductive hypothesis space HF as a projection of F
into the full sample Xm+u : HF = {h  Rm+u : f  F, 1  i  m + u, h(i) = f (xi )}.
By such definition of HF , L(f ) = Lm+u (h).
Our final step towards a meaningful comparison would be to translate a transductive
bound of the form Lu (h)  Lbm (h)+slack to a bound on the average error of the hypothesis6
h:


bm (h) + u Lbm (h) + slack


m
L
b
mLm (h) + uLu (h)

Lm+u (h)  Lm+u (h) =
m+u
m+u
u

 slack
= Lbm (h) +
(17)
m+u
We instantiate (17) to the bound (15) and obtain
Lm+u (h) 

Lbm (h)

"
#
r
p
u Rm+u (HF )
u
SQ 1
+
+
c0 Q min(m, u) +
ln
. (18)
m+u

m+u
2


6. Alternatively, to compare (15) and (16), we could try to express the bound (16) as the bound on the
error of f on Xu (the randomly drawn subset of u examples). The bound (16) holds for the setting of
random draws with replacement. In this setting the number of unique training examples can be smaller
than m and thus the number of the remaining test examples is larger than u. Hence the draw of m
training examples with replacement does not imply the draw of the subset of u test examples, as in
transductive setting. Thus we cannot express the bound (16) as the bound on the randomly drawn Xu

14

fiTransductive Rademacher Complexity and its Applications

Now given a transductive problem we consider the corresponding inductive bound obtained
from (16) under the distribution Dtrans and compare it to the bound (18).
Note that in the inductive bound (16) the sampling of the training set is done with
replacement, while in the transductive bound (18) it is done without replacement. Thus, in
the inductive case the actual number of distinct training examples may be smaller than m.
The bounds (16) and (18) consist of three terms: empirical error term (first summand
in (16) and (18)), the term depending on the Rademacher complexity (second summand in
(16) and (18)) and the slack term (third summand in (16) and third and fourth summands
in (18)). The empirical error terms are the same in both bounds. It is hard to compare
analytically the Rademacher complexity terms. This is because the inductive bound is
derived for the setting of sampling with replacement and the transductive bound is derived
for the setting of sampling without replacement. Thus, in the transductive Rademacher
complexity each example xi  Xm+u appears in Rm+u (Hout ) only once and is multiplied
by i . In contrast, due to the sampling with replacement, in the inductive Rademacher
b(ind) (F), multiplied by different
term the example xi  Xm+u can appear several times in R
m+u
values of the Rademacher variables.
Nevertheless, in transduction we have a full control over the Rademacher complexity
(since we can choose Hout after observing the full sample Xm+u ) and can choose an hypothesis space Hout with arbitrarily small Rademacher complexity. In induction we choose F
b(ind) (F)
before observing any data. Hence, if we are lucky with the full sample Xm+u then R
m+u
b(ind) (F) can be large. Thus, under these
is small, and if we are unlucky with Xm+u then R
m+u
provisions we can argue that the transductive Rademacher term is not larger than the
inductive counterpart.
Finally, we compare the slack terms in (16) and (18). If m  u or m  u then the slack

term of (18) is of order O (1/ m), which is the same as the corresponding term in (16).

But if m  u then the slack term of (18) is of order O (1/(m u)), which is much smaller

than O(1/ m) of the slack term in (16).
Based on the comparison of the corresponding terms in (16) and (18) our conclusion
is that in the regime of u  m the transductive bound is significantly tighter than the
inductive one.7

5. Unlabeled-Labeled Representation (ULR) of Transductive Algorithms
Let r be any natural number and let U be an (m + u)  r matrix depending only on Xm+u .
Let  be an r  1 vector that may depend on both Sm and Xu . The soft classification
output h of any transductive algorithm can be represented by
h=U  .

(19)

We refer to (19) as an unlabeled-labeled representation (ULR). In this section we develop
bounds on the Rademacher complexity of algorithms based on their ULRs. We note that
any transductive algorithm has a trivial ULR, for example, by taking r = m + u, setting U
7. The regime of u  m occurs in the following class of applications. Given a large library of tagged
objects, the goal of the learner is to assign the tags to a small quantity of the newly arrived objects. The
example of such application is the organization of daily news.

15

fiEl-Yaniv & Pechyony

to be the identity matrix and assigning  to any desired (soft) labels. We are interested in
non-trivial ULRs and provide useful bounds for such representations.8
In a vanilla ULR, U is an (m + u)  (m + u) matrix and  = (1 , . . . , m+u ) simply
specifies the given labels in Sm (where i = yi for labeled points, and i = 0 otherwise).
From our point of view any vanilla ULR is not trivial because  does not encode the
final classification of the algorithm. For example, the algorithm of Zhou et al. (2004)
straightforwardly admits a vanilla ULR. On the other hand, the natural (non-trivial) ULR
of the algorithms of Zhu et al. (2003) and Belkin and Niyogi (2004) are not of the vanilla
type. For some algorithms it is not necessarily obvious how to find non-trivial ULRs. In
Sections 6 we consider two such cases  in particular, the algorithms of Joachims (2003)
and Belkin et al. (2004).
The rest of this section is organized as follows. In Section 5.1 we present a generic
bound on the Rademacher complexity of any transductive algorithm based on its ULR. In
Section 5.2 we consider a case when the matrix U is a kernel matrix. For this case we
develop another bound on the transductive Rademacher complexity. Finally, in Section 5.3
we present a method of computing high-confidence estimate of the transductive Rademacher
complexity.
5.1 Generic Bound on Transductive Rademacher Complexity
We now present a bound on the transductive Rademacher complexity of any transductive
algorithm based on its
ULR. Let {i }ri=1 be the singular values of U . We use the well-known
qP
qP
M
r
2 , where kU k
2

=
fact that kU kFro =
Fro
i=1 i
i,j (U (i, j)) is the Frobenius norm of
M

U . Suppose that kk2  1 for some 1 . Let Hout = Hout (U ) be the set of all possible
outputs of the algorithm when operated on all possible training/test set partitions of the
M 1
+ u1 . Using the abbreviation U (i, ) for the ith row of U and
full-sample Xm+u . Let Q = m
following the proof idea of Lemma 22 of Bartlett and Mendelson (2002), we have that
(
)
(
)
m+u
m+u
X
X
Rm+u (Hout ) = Q  E
sup
i h(xi ) = Q  E
sup
i h, U (i, )i
(
= Q  E

hHout i=1

sup
:kk2 1

h,

m+u
X

)

:kk2 1 i=1

i U (i, )i

i=1

 )
(m+u
X



= Q1 E 
i U (i, )


i=1
2
v

u
m+u
u X

= Q1 E t
i j hU (i, ), U (j, )i


i,j=1
v
u m+u
uX
 Q1 t
E {i j hU (i, ), U (j, )i}

(20)

(21)

i,j=1

8. For the trivial representation where U is the identity matrix multiplied by constant we show in Lemma 6
that the risk bound (15), combined with the forthcoming Rademacher complexity bound (22), is greater
than 1.

16

fiTransductive Rademacher Complexity and its Applications

v
v
r
um+u
u
r
uX 2
u 2 X
2
2
t
hU (i, ), U (i, )i = 1
kU kFro = 1 t
2i .
= 1
mu
mu
mu
i=1

(22)

i=1

where (20) and (21) are obtained using, respectively, the Cauchy-Schwarz and Jensen inequalities. Using the bound (22) in conjunction with Theorem 2 we immediately get a
data-dependent error bound for any algorithm, which can be computed once we derive an
upper bound on the maximal length of possible values of the  vector, appearing in its
ULR. Notice that for any vanilla ULR (and thus for the consistency method of Zhou

et al. (2004)), 1 = m. In Section 6 we derive a tight bound on 1 for non-trivial ULRs
of SGT of Joachims (2003) and of the consistency method of Zhou et al. (2004).
The bound (22) is syntactically similar in form to a corresponding inductive Rademacher
bound for kernel machines (Bartlett & Mendelson, 2002). However, as noted above, the
fundamental difference is that in induction, the choice of the kernel (and therefore Hout )
must be data-independent in the sense that it must be selected before the training examples
are observed. In our transductive setting, U and Hout can be selected after the unlabeled
full-sample is observed.
The Rademacher bound (22), as well as the forthcoming Rademacher bound (25), depend on the spectrum of the matrix U . As we will see in Section 6, in non-trivial ULRs
of some transductive algorithms (the algorithms of Zhou et al., 2004 and of Belkin et al.,
2004) the spectrum of U depends on the spectrum of the Laplacian of the graph used by the
algorithm. Thus by transforming the spectrum of Laplacian we control the Rademacher
complexity of the hypothesis class. There exists strong empirical evidence (see Chapelle
et al., 2003; Joachims, 2003; Johnson & Zhang, 2008) that such spectral transformations
improve the performance of the transductive algorithms.
The next lemma (proven in Appendix F) shows that for trivial ULRs the resulting
risk bound is vacuous.
M

Lemma 6 Let   Rm+u be a vector depending on both Sm and Xu . Let c  R, U = c  I
and A be transductive algorithm generating soft-classification vector h = U  . Let {i }ri=1
be the singular values of U and 1 be the upper bound on kk2 . For the algorithm A the
bound (22) in conjunction with the bound (15) is vacuous; namely, for any   (0, 1) and
any h generated by A it holds that
v
r
u
k
p
1
1 u
2 X 2
S

t
b
Q ln  1 .
Lm (h) +
i + c0 Q min(m, u) +

mu
2

i=1

5.2 Kernel ULR
If r = m + u and the matrix U is a kernel matrix (this holds if U is positive semidefinite),
then we say that the decomposition is a kernel-ULR. Let G  Rm+u be the reproducing
kernel Hilbert space (RKHS), corresponding to U . We denote by h, iG the inner product in
G. Since U is a kernel matrix, by the reproducing property9 of G, U (i, j) = hU (i, ), U (j, )iG .
9. This means that for all h  G and i  I1m+u , h(i) = hU (i, ), hiG .

17

fiEl-Yaniv & Pechyony


Suppose that the vector  satisfies T U   2 for some 2 . Let {i }m+u
i=1 be the eigenvalues of U . By similar arguments used to derive (22) we have:


m+u


X
X m+u
i h(xi ) = Q  E sup
i
j U (i, j)
Q  E
sup

 
hHout i=1
j=1
i=1


m+u


X
X m+u
i
j hU (i, ), U (j, )iG
Q  E sup

 
j=1
i=1

*m+u
+ 
m+u


X
X
i U (i, ),
j U (j, )
Q  E sup

 
i=1
j=1
G


 

 
 

m+u
 m+u
X
X


 
Q  E sup 
i U (i, )  
j U (j, )
(23)
 
  
 

i=1
j=1
G
G



m+u
 
X

Q2 E 
i U (i, )

 
i=1
G
v*
+ 
u
m+u
u m+u

X
X
i U (i, ),
j U (j, )
Q2 E t


i=1
j=1
G

v
v
u m+u

u
X
uX
u m+u
t
i j U (i, j)  Q2 t
E {i j U (i, j)}
(24)
Q2 E


i,j=1
i,j=1
v
v
r
um+u
u
X
uX 2
u 2 m+u
2  trace(U)
t
2
U (i, i) = 2
= 2 t
i .
(25)
mu
mu
mu
(

Rm+u (Hout ) =

=

=



=

=

=

=

)

m+u
X

i=1

i=1

The inequalities (23) and (24) are obtained using, respectively, Cauchy-Schwarz and Jensen
inequalities. Finally, the first equality in (25) follows from the definition of Rademacher
variables (see Definition 1).
If transductive algorithm has kernel-ULR then we can use both (25) and (22) to bound
its Rademacher complexity. The kernel bound (25) can be tighter than its non-kernel
counterpart (22) when the kernel matrix has eigenvalues larger than one and/or 2 < 1 .
In Section 6 we derive a tight bound on 1 for non-trivial ULRs of consistency method
of Zhou et al. (2004) and of the Tikhonov regularization method of Belkin et al. (2004).
5.3 Monte-Carlo Rademacher Bounds
We now show how to compute Monte-Carlo Rademacher bounds with high confidence for
any transductive algorithm using its ULR. Our empirical examination of these bounds
(see Section 6.3) shows that they are tighter than the analytical bounds (22) and (25).
The technique, which is based on a simple application of Hoeffdings inequality, is made
particularly simple for vanilla ULRs.
18

fiTransductive Rademacher Complexity and its Applications

M

1
Let V  Rm+u be a set of vectors, Q = m
+ u1 ,   Rm+u to be a Rademacher vector
(1), and g() = supvV  T  v. By Definition 1, Rm+u (V) = Q  E {g()}. Let 1 , . . . , n
be an i.i.d. sample of Rademacher vectors.
P We estimate Rm+u (V) with high confidence
by applying the Hoeffding inequality on ni=1 n1 g(i ). To apply the Hoeffding inequality
we need a bound on sup |g()|, which is derived for the case where V = Hout . Namely
we assume that V is a set of all possible outputs of the algorithm (for a fixed Xm+u ).
Specifically, suppose that v  V is an output of the algorithm, v = U , and assume that
kk2  1 .
M 
By Definition 1, for all , kk2  b = m + u. Let 1  . . .  k be the singular
values of U and u1 , . . . , uk and w1 , . . . , wk be their corresponding unit-length right and left
singular vectors10 . We have that


k
 X



sup |g()| =
sup
| T U | =
sup
i ui wiT   b1 k .
 T


kk2 b, kk2 1
kk2 b, kk2 1 
i=1

Applying the one-sided Hoeffding inequality on n samples of g() we have, for any given ,
that with probability of at least 1 over the random i.i.d. choice of the vectors 1 , . . . , n ,

s



n
1
X

2 ln 
1
1
1
 .
Rm+u (V) 
+

sup iT U  + 1 k m + u
(26)
m u
n
n
:kk2 1
i=1

To use the bound (26), the value of sup:kk2 1 iT U  should be computed for each randomly drawn i . This computation is algorithm-dependent and in Section 6.3 we show how
to compute it for the algorithm of Zhou et al. (2004).11 In cases where we can compute the
supremum exactly (as in vanilla ULRs; see below) we can also get a lower bound using the
symmetric Hoeffding inequality.

6. Applications: Explicit Bounds for Specific Algorithms
In this section we exemplify the use of the Rademacher bounds (22), (25) and (26) to
particular transductive algorithms. In Section 6.1 we instantiate the generic ULR bound
(22) for the SGT algorithm of Joachims (2003). In Section 6.2 we instantiate kernel-ULR
bound (25) for the algorithm of Belkin et al. (2004). Finally, in Section 6.3 we instantiate
all three bounds (22), (25) and (26) for the algorithm of Zhou et al. (2004) and compare
the resulting bounds numerically.
6.1 The Spectral Graph Transduction (SGT) Algorithm of Joachims (2003)
We start with a description of a simplified version of SGT that captures the essence of the
algorithm.12 Let W be a symmetric (m + u)  (m + u) similarity matrix of the full-sample
10. These vectors can be found from the singular value decomposition of U .
11. An application of this approach in induction seems to be very hard, if not impossible. For example, in
the case of RBF kernel machines we will need to optimize over (typically) infinite-dimensional vectors
in the feature space.
12. We omit a few heuristics that are optional in SGT. Their exclusion does not affect the error bound we
derive.

19

fiEl-Yaniv & Pechyony

Xm+u . The (i, j)th entry of W represents the similarity between xi and xj . The matrix W
can be constructed in various ways, for example, it can be a k-nearest neighbors graph. In
such graph each vertex represents example from the full sample Xm+u . There is an edge
between a pair of vertices if one of the corresponding examples is among k most similar
examples to the other. The weights of the edges are proportional to the similarity of the
adjacent vertices (points). The examples of commonly used measures of similarity are cosine
similarity and RBF kernel. Let D be a diagonal matrix, whose (i, i)th entry is the sum of
the ith row in W . An unnormalized Laplacian of W is L = D  W .
Let r  {1, . . . , m + u  1} be fixed, {i , vi }m+u
be eigenvectors and eigenvalues of L
Pr+1 2i=1 T
e
such that 0 = 1  . . .  m+u and L = i=2 i vv . Let  = (1 , . . . , m+u ) be a vector
that specifies the given labels in Sm ; that is, i  {1} for labeled points, and i = 0
otherwise. Let c be a fixed constant and 1 be an (m + u)  1 vector whose entries are 1 and
let C be a diagonal matrix such that C(i, i) = 1/m iff example i is in the training set (and
zero otherwise). The soft classification h produced by the SGT algorithm is the solution
of the following optimization problem:
min

hRm+u

e + c(h  ~ )T C(h  ~ )
hT Lh

s.t. hT 1 = 0,

hT h = m + u.

(27)
(28)

It is shown by Joachims (2003) that h = U , where U is an (m + u)  r matrix whose
columns are vi s, 2  i  r + 1, and  is an r  1 vector. While  depends on both the
training and test sets, the matrix U depends only on the unlabeled full-sample. Substituting
h = U  for the second constraint in (28) and using the orthonormality
of the columns of

U , weget m + u = hT h = T U T U  = T . Hence, kk2 = m + u and we can take
1 = m + u. Since U is an (m + u)  r matrix with orthonormal columns, kU k2Fro = r. We
conclude from (22) the following bound on transductive Rademacher complexity of SGT
s 

1
1
+
,
(29)
Rm+u (Hout )  2r
m u
where r is the number of non-zero eigenvalues of L. Notice that the bound (29) is oblivious
to the magnitude of these eigenvalues. With the small value of r the bound (29) is small,
but, as shown by Joachims (2003) the test error of SGT is bad. If r increases then the bound
(29) increases but the test error improves. Joachims shows empirically that the smallest
value of r achieving nearly optimal test error is 40.
6.2 Kernel-ULR of the Algorithm of Belkin et al. (2004)
By defining the RKHS induced by the graph (unnormalized) Laplacian, as it was done by
Herbster, Pontil, and Wainer (2005), and applying a generalized representer theorem of
Scholkopf, Herbrich, and Smola (2001), we show that the algorithm of Belkin et al. (2004)
has a kernel-ULR. Based on this kernel-ULR we derive an explicit risk bound for this. We
also derive an explicit risk bound based on generic ULR. We show that the former (kernel)
bound is tighter than the latter (generic) one. Finally, we compare our kernel bound with
the risk bound of Belkin et al. (2004). The proofs of all lemmas in this section appear in
Appendix G.
20

fiTransductive Rademacher Complexity and its Applications

The algorithm of Belkin et al. (2004) is similar to the SGT algorithm, described in
Section 6.1. Hence in this appendix we use the same notation as in the description of SGT
(see Section 6.1). The algorithm of Belkin et al. is formulated as follows.
min

hRm+u

hT Lh + c(h  ~ )T C(h  ~ )

(30)

hT 1 = 0

(31)

s.t.

The difference between (30)-(31) and (27)-(28) is in the constraint (28), which may change
the resulting hard classification. Belkin et al. developed a stability-based error bound for
the algorithm based on a connected graph. In the analysis that follows we also assume that
the underlying graph is connected, but as shown at the end of this section, the argument
can be also extended to unconnected graphs.
We represent a full-sample labeling as a vector in the Reproducing Kernel Hilbert Space
(RKHS) associated with the graph Laplacian (as described by Herbster et al., 2005) and
derive a transductive version of the generalized representer theorem of Scholkopf et al.
(2001). Considering (30)-(31) we set H = {h | hT 1 = 0, h  Rm+u }. Let h1 , h2  H be
two soft classification vectors. We define their inner product as
M

hh1 , h2 iL = hT1 Lh2 .

(32)

We denote by HL the set H along with the inner product (32). Let 1 , . . . , m+u be the
eigenvalues of L in the increasing order. Since L is a Laplacian of the connected graph,
1 = 0 and for all 2  i  m + u, i 6= 0. Let ui be an eigenvector corresponding to i .
Since L is symmetric, the vectors {ui }m+u
i=1 are orthogonal. We assume also w.l.o.g. that
1
1. Let
the vectors {ui }m+u
are
orthonormal
and
u1 = m+u
i=1
M

U=

m+u
X
i=2

1
ui uTi .
i

(33)

Note that the matrix U depends only on the unlabeled full-sample.
Lemma 7 (Herbster et al., 2005) The space HL is an RKHS with a reproducing kernel
matrix U .
A consequence of Lemma 7 is that the algorithm (30)-(31) performs the regularization in the
RKHS HL with the regularization term khk2L = hT Lh (this fact was also noted by Herbster
et al., 2005). The following transductive variant of the generalized representer theorem
of Scholkopf et al. (2001) concludes the derivation of the kernel-ULR of the algorithm of
Belkin et al. (2004).
Lemma 8 Let h  H be the solution of the optimization problem (30)-(31), and let U be
defined as above. Then, there exists   Rm+u such that h = U .
Remark 9 We now consider the case of an unconnected graph. Let t be the number of
connected components in the underlying graph. Then the zero eigenvalue of the Laplacian
L has multiplicity t. Let u1 , . . . , ut be the eigenvectors corresponding to the zero eigenvalue of L. Let ut+1 , . . . , um+u be the eigenvectors corresponding to non-zero eigenvalues
21

fiEl-Yaniv & Pechyony

t+1 , . . . , m+u of L. We replace constraint (31) with t constraints hT ui = 0 and define the
M P
1
T
kernel matrix as U = m+u
i=t+1 i ui ui . The rest of the analysis is the same as for the case
of the connected graph.
To obtain the explicit bounds on the transductive
Rademacher complexity of the algo
T
rithm of Belkin et al. it remains to bound  U  and kk2 . We start with bounding

T U .
We substitute h = U  into (30)-(31). P
Since u2 , . . . , um+u are orthogonal to u1 =
m+u 1
T
T
T
T
T
 1
1, we have that h 1 =  U 1 = 
i=2 i ui ui 1 = 0. Moreover, we have that
m+u


1
hT Lh = T U T LU  = T I  m+u
1  1T U  = T U . Thus (30)-(31) is equivalent to
solving
min T U  + c(U   ~ )T C(U   ~ )
(34)
Rm+u

and outputting h = U out , where out is the solution of (34). Let 0 be the (m + u)  1
vector consisting of zeros. We have
Tout U out  Tout U out + c(U out  ~ )T C(U out  ~ )
 0T U 0 + c(U 0  ~ )T C(U 0  ~ ) = c .
Thus

q
Tout U out 

 M
c = 2 .

(35)

Let 1 , . . . , m+u be the eigenvalues of U , sorted in the increasing order. It follows from
1
, where 1 , . . . , m+u are the
(33) that 1 = 0 and for any 2  i  m + u, i = m+ui+2
eigenvalues of L sorted in the increasing order.
We substitute the bound (35) into (25), and obtain that the kernel bound is
v
v
u
u
X
X 1
u 2c m+u
u 2c m+u
t
.
i = t
mu
mu
i
i=2

i=2

P
1
Suppose that13 m+u
i=2 i = O(m + u). We substitute the kernel bound into (15) and
obtain that with probability at least 1   over the random training/test partition,

!
1

b
.
(36)
Lu (h)  Lm (h) + O p
min(m, u)
We briefly compare this bound with the risk bound for the algorithm (30)-(31) given by
Belkin et al. (2004). Belkin et al. provide the following bound for their algorithm14 . With
probability of at least 1   over the random draw of m training examples from Xm+u ,


1

b
Lm+u (h)  Lm (h) + O 
.
(37)
m
13. This assumption is not restricting since we can define the matrix L and its spectrum after observing the
unlabeled full-sample. Thus we can set L in a way that this assumption will hold.
14. The original bound of Belkin et al. is in terms of squared loss. The equivalent bound in terms of 0/1
and margin loss can be obtained by the same derivation as in the paper of Belkin et al. (2004).

22

fiTransductive Rademacher Complexity and its Applications

Similarly to what was done in Section 4.3, to bring the bounds to common denominator,
we rewrite the bound (36) as

!
u
1
Lu (h)  Lbm (h) +
O p
.
(38)
m+u
min(m, u)
If m  u or m  u then the bounds (37) and (38) have the same convergence rate. However

if m  u then the convergence rate of (38) (which is O(1/(m u))) is much faster than the

one of (37) (which is O(1/ m)).
6.3 The Consistency Method of Zhou et al. (2004)
In this section we instantiate the bounds (22), (25) and (26) to the consistency method
of Zhou et al. (2004) and provide their numerical comparison.
We start with a brief description of the Consistency Method (CM) algorithm of Zhou
et al. (2004). The algorithm has a natural vanilla ULR (see definition at the beginning
of Section 5), where the matrix U is computed as follows. Let W and D be matrices as
M
in SGT (see Section 6.1). Let L = D1/2 W D1/2 and  be a parameter in (0, 1). Then,
M
U = (1  )(I  L)1 and the output of CM is h = U  , where  specifies the given

labels. Consequently kk2 = m. The following lemma, proven in Appendix H, provides
a characterization of the eigenvalues of U :
Lemma 9 Let max and min be, respectively, the largest and smallest eigenvalues of U .
Then max = 1 and min > 0.
It follows from Lemma 9 that U is a positive definite matrix and hence is also a kernel
matrix. Therefore, the decomposition with the
 above U is a kernel-ULR. To apply the kernel
bound (25) we compute the bound 2 on T U . By the Rayleigh-Ritz theorem (Horn
T
& Johnson, 1990), we have that TU  max . Since by the definition of the vanilla ULR,
p


T =
T  = m, we obtain that T U   max

max m.


We obtained that 1 = m and 2 = max m, where max is the maximal eigenvalue
of U . Since by Lemma 9 max = 1, for the CM algorithm the bound (22) is always tighter
than (25).
It turns out that for CM, the exact value of the supremum in (26) can be analytically
derived. Recall that the vectors , which induce the CM hypothesis space for a particular
U , have exactly m components with values in {1}; the rest of the components are zeros.
M
Let  be the set of all possible such s. Let t(i ) = (t1 , . . . , tm+u ) = iT U  R1(m+u)
M
and |t(i )| = (|t1 |, . . . , |tm+u |). Then, for any fixed i , sup iT U  is the sum of the m
largest elements in |t(i )|. This derivation holds for any vanilla ULR.
To demonstrate the Rademacher bounds discussed in this paper we present an empirical
comparison of the bounds over two datasets (Voting, Pima) from the UCI repository15 . For
each dataset we took m + u to be the size of the dataset (435 and 768 respectively) and we
took m to be 1/3 of the full-sample size. The matrix W is the 10-nearest neighbors graph
computed with the cosine similarity metric. We applied the CM algorithm with  = 0.5. The
Monte-Carlo bounds (both upper and lower) were computed with  = 0.05 and n = 105 .
15. We also obtained similar results for several other UCI datasets.

23

fiEl-Yaniv & Pechyony

Pima Dataset
Bound on Transductive Rademacher

Bound on Transductive Rademacher

Voting Dataset
1.4
1.2
1
0.8
0.6
Kernel ULR bound

0.4

Generic ULR bound
Upper Monte Carlo bound

0.2
0
0

Lower Monte Carlo
50

100

150

200

250

300

350

1.4
1.2
1
0.8
0.6
Kernel ULR bound
0.4

Upper Monte Carlo bound
0.2
0
0

400

Generic ULR bound

Lower Monte Carlo
100

200

300

400

500

600

700

Number of Eigenvalues/Singular values

Number of Eigenvalues/Singular values

Figure 1: A comparison of transductive Rademacher bounds.
We compared upper and lower Mote-Carlo bounds with the generic ULR bound (22)
and the kernel-ULR bound (25). The graphs in Figure 1 compare these four bounds for
each of the datasets as a function of the number of non-zero eigenvalues of U . Specifically,
each point t on the x-axis corresponds to bounds computed with a matrix Ut that approximates U using only the smallest t eigenvalues of U . In both examples the lower and upper
Monte-Carlo bounds tightly sandwich the true Rademacher complexity. It is striking
that generic-ULR bound is very close to the true Rademacher complexity. In principle,
with our simple Monte-Carlo method we can approximate the true Rademacher complexity
up to any desired accuracy (with high confidence) at the cost of drawing sufficiently many
Rademacher vectors.

7. PAC-Bayesian Bound for Transductive Mixtures
In this section we adapt part of the results of Meir and Zhang (2003) to transduction. The
proofs of all results presented in this section appear in Appendix I.
|B|
Let B = {hi }i=1 be a finite set of base-hypotheses. The class B can be formed after
observing the full-sample Xm+u , but before obtaining the training/test set partition and
P|B|
the labels. Let q = (q1 , . . . , q|B| )  R|B| be a probability vector, i.e. i=1 qi = 1 and qi  0
for all 1  i  |B|. The vector q can be computed after observing training/test partition
and the training labels. Our goal is to find the posterior vector
P q such that
 the mixture
P
P
M
|B|
|B|
m+u
1
eq =
e
hypothesis h
j=m+1 `
i=1 qi hi (j), yj .
i=1 qi hi minimizes Lu (hq ) = u
In this section we derive a uniform risk bound for a set of qs. This bound depends on
the KL-divergence (see the definition below) between q and the prior probability vector
p  R|B| , where the vector p is defined based only on the unlabeled full-sample. Thus
our forthcoming bound (see Theorem 4) belongs to the family of PAC-Bayesian bounds
(McAllester, 2003; Derbeko et al., 2004), which depend on prior and posterior information.
Notice that our bound, is different
from the PAC-Bayesian bounds for Gibbs classifiers that
1 Pm+u
bound EhB(q) Lu (h) = u j=m+1 EhB(q) `(h(j), yj ), where h  B(q) is a random draw of
the base hypothesis from B according to distribution q.
24

fiTransductive Rademacher Complexity and its Applications

e q )  EhB(q) Lu (h).
Remark 10 As by one of the reviewers noted, by Jensen inequality Lu (h
Hence any risk bound for transductive Gibbs classifier holds true also for transductive mixture classifier. Currently known risk bound for transductive Gibbs classifiers (Theorem 18
in the paper of Derbeko et al., 2004) diverges when u  . Our forthcoming risk bound
(41) has no such deficiency.
We assume that q belongs to domain g,A = {q | g(q)  A}, where g : R|B| 
R is a predefined function and A  R is a constant. The domain g,A and the set B
M
M
e q . Recalling that Q =
induce the class Beg,A of all possible mixtures h
(1/m + 1/u), S =
p
M
m+u
32 ln(4e)/3 < 5.05, we apply Theorem 2 with Hout =
(m+u0.5)(10.5/ max(m,u)) and c0 =
Beg,A and obtain that with probability of at least 1   over the training/test partition of
e q  Beg,A ,
Xm+u , for all h
r
p
Rm+u (Beg,A )
S
1
 e
e
b
Lu (hq )  Lm (hq ) +
+ c0 Q min(m, u) +
Q ln .
(39)

2

q
M
Let Q1 = S2 Q (ln(1/) + 2 ln logs (sg(q)/g0 )). It is straightforward to apply the technique
used in the proof of Theorem 10 of Meir and Zhang (2003) and obtain the following bound,
which eliminates the dependence on A.
Corollary 2 Let g0 > 0, s > 1 and g(q) = s max(g(q), g0 ). For any fixed g and  > 0,
eq,
with probability of at least 1   over the training/test set partition, for all16 h
e q )  Lb (h
e
Lu (h
m q) +

p
Rm+u (Beg,g(q) )
+ c0 Q min(m, u) + Q1 .


(40)

We now instantiate Corollary 2 for g(q) being
  the KL-divergence and derive a PAC-Bayesian
P|B|
M
bound. Let g(q) = D(qkp) = i=1 qi ln pqii be KL-divergence between p and q. Adopting
Lemma 11 of Meir and Zhang (2003) to the transductive Rademacher variables, defined in
(1), we obtain the following bound.
Theorem 4 Let g0 > 0, s > 1,  > 0. Let p and q be any prior and posterior distribution
M
M
over B, respectively. Set g(q) = D(qkp) and g(q) = s max(g(q), g0 ). Then, with probability
eq,
of at least 1   over the training/test set partition, for all h
r
p
e q )  Lb (h
e q ) + Q 2g(q) sup khk2 + c0 Q min(m, u) + Q1 .
Lu (h
(41)
m
2

hB
Theorem 4 is a PAC-Bayesian result, where the prior p can depend on Xm+u and the posterior can be optimized adaptively, based
p also on Sm . As our general bound (15), the bound
(41) has the convergence rate of O(1/ min(m, u)). The bound (41) is syntactically similar
to inductive PAC-Bayesian bound for mixture hypothesis (see Theorem 10 and Lemma 11

in the paper of Meir & Zhang, 2003), having similar convergence rate of O(1/ m). However
the conceptual difference between inductive and transductive bounds is that in transduction
we can define the prior vector p after observing the unlabeled full-sample and in induction
we should define p before observing any data.
eg,eg(q) ) is as follows:
16. In the bound (40) the meaning of Rm+u (B
M
Rm+u (Beg,g(q) ) = Rm+u (Beg,A ).

25

for any q, let A = ge(q) and

fiEl-Yaniv & Pechyony

8. Concluding Remarks
We studied the use of Rademacher complexity analysis in the transductive setting. Our
results include the first general Rademacher bound for soft classification algorithms, the
unlabeled-labeled representation (ULR) technique for bounding the Rademacher complexity
of any transductive algorithm and a bound for Bayesian mixtures. We demonstrated the
usefulness of these results and, in particular, the effectiveness of our ULR framework for
deriving error bounds for several advanced transductive algorithms.
It would be nice to further improve our bounds using, for example, the local Rademacher
approach of Bartlett, Bousquet, and Mendelson (2005). However, we believe that the main
advantage of these transductive bounds is the possibility of selecting a hypothesis space
based on a full-sample. A clever data-dependent choice of this space should provide sufficient
flexibility to achieve a low training error with low Rademacher complexity. In our opinion
this opportunity can be explored and exploited much further. In particular, it would be
interesting to develop an efficient procedure for the choice of hypothesis space if the learner
knows the properties of the underlying distribution (e.g., if the clustering assumption holds).
This work opens up new avenues for future research. For example, it would be interesting
to optimize the matrix U in the ULR explicitly (to fit the data) under a constraint of low
Rademacher complexity. Also, it would be nice to find low-Rademacher approximations
of particular U matrices. The PAC-Bayesian bound for mixture algorithms motivates the
development and use of transductive mixtures, an area that has yet to be investigated.
Finally, it would be interesting to utilize our bounds in model selection process.

Acknowledgments
We are grateful to anonymous reviewers for their insightful comments. We also thank
Yair Wiener and Nati Srebro for fruitful discussions. Dmitry Pechyony was supported in
part by the IST Programme of the European Community, under the PASCAL Network of
Excellence, IST-2002-506778.

Appendix A. Proof of Lemma 1
The proof is based on the technique used in the proof of Lemma 5 in the paper of Meir
and Zhang (2003). Let  = (1 , . . . , m+u )T be the Rademacher random variables of
Rm+u (V, p1 ) and  = (1 , . . . , m+u )T be the Rademacher random variables of Rm+u (V, p2 ).
For any real-valued function g(v), for any n  I1m+u and any v0  V,

)


sup [g(v)] = En
 n 6= 0 .

vV
(42)
M
M
We useP
the abbreviation 1s = 1 , . . . , s . We apply (42) with a fixed 1n1 and g(v) =
f (v) + n1
i=1 i vi , and obtain that

)
(


n vn0 + sup [g(v)]  n 6= 0  En sup [n vn + g(v)]

vV
vV

(

sup
vV

"n1
X
i=1

#
i vi + f (v)  En

(
sup
vV

26

" n
X
i=1

)
# 


i vi + f (v)  n 6= 0 .


(43)

fiTransductive Rademacher Complexity and its Applications

To complete the proof of the lemma, we prove a more general claim: for any real-valued
function f (v), for any 0  n  m + u,
(
" n
#)
(
" n
#)
X
X
E sup
i vi + f (v)
 E sup
i vi + f (v)
.
(44)
vV

vV

i=1

i=1

The proof is by induction on n. The claim trivially holds for n = 0 (in this case (44) holds
with equality). Suppose the claim holds for all k < n and all functions f (v). We use the
M
abbreviation 1s = 1 , . . . , s . For any function f 0 (v) have
" n
#
X
0
i vi + f (v)
E1n sup
vV

(

i=1

"n1
#
"n1
#)
X
X
1
1
= 2p1
i vi + vn + f 0 (v) + En1 sup
i vi  vn + f 0 (v)
E n1 sup
2 1 vV
2 1 vV
i=1
i=1
"n1
#
X
+ (1  2p1 ) En1 sup
i vi + f 0 (v)
1

(
 2p1

vV

"n1
X

1
E n1 sup
2 1 vV

1
+ E n1 sup
2 1 vV
(
(

i=1

#

i vi + vn + f 0 (v)

i=1
"n1
X

(45)
#)

0

i vi  vn + f (v)

i=1

# 


i vi + f 0 (v) 
= E n1 2p1 En sup
1

vV i=1
" n
#
(

(
X
i vi + f 0 (v)
= E n1 2p1 En sup
1

" n
X

vV

+ sup
vV

"n1
X
i=1

i=1

+ (1  2p1 ) E n1 sup
1

)
n 6= 0

vV

+ (1  2p1 ) sup
vV

"n1
X

#
i vi + f (v)

i=1

"n1
X

#)
i vi + f 0 (v)

i=1


)
"n1
#!

X

0
i vi + f (v)
 n 6= 0  sup

vV
i=1

#)

i vi + f 0 (v)

# 
)
"n1
#!

X

0
2p2 En sup
i vi + f (v)  n =
6 0  sup
i vi + f (v)

vV i=1
vV i=1
"n1
#)
X
+ sup
i vi + f 0 (v)

(
 E n1
1

1

= E1n sup
vV

vV

(

i=1

" n
X

0

)
# 


0
2p2 En sup
i vi + f (v)  n 6= 0

vV i=1
"n1
#)
X
+ (1  2p2 ) sup
i vi + f 0 (v)

(
= E n1



" n
X

(

0

" n
X

vV

#

i=1

i vi + f 0 (v) .

i=1

27

(46)

fiEl-Yaniv & Pechyony

The inequality (45) follow from the inductive hypothesis, applied thrice with f (v) = vn +
f 0 (v), f (v) = vn + f 0 (v) and f (v) = f 0 (v). The inequality (46) follows from (43) and the
fact that p1 < p2 .

Appendix B. Proof of Lemma 2
M

We require the following standard definitions and facts about martingales.17 Let Bn1 =
M
(B1 , . . . , Bn ) be a sequence of random variables and bn1 = (b1 , . . . , bn ) be their respective
M
w.r.t.
values. The sequence W0n = (W0 , W1 , . . . , Wn ) is called a martingale

 the underlying
sequence Bn1 if for any i  I1n , Wi is a function of Bi1 and EBi Wi |B1i1 = Wi1 .
M

Let f (Xn1 ) = f (X1 , . . . , Xn ) be an arbitrary function of n (possibly dependent) random


M
M
variables. Let W0 = EXn1 {f (Xn1 )} and Wi = EXn1 f (Xn1 )|Xi1 for any i  I1n . An elementary fact is that W0n is a martingale w.r.t. the underlying sequence Xn1 . Thus we can obtain
a martingale from any function of (possibly dependent) random variables. This routine of
obtaining a martingale from an arbitrary function is called Doobs martingale process. By
the definition of Wn we have Wn = EXn1 {f (Xn1 )|Xn1 } = f (Xn1 ). Consequently, to bound
the deviation of f (Xn1 ) from its mean it is sufficient to bound the difference Wn  W0 . A
fundamental inequality, providing such a bound, is McDiarmids inequality (McDiarmid,
1989).
Lemma 10 (McDiarmid, 1989, Corollary 6.10) Let W0n be a martingale w.r.t. Bn1 .
Let bn1 = (b1 , . . . , bn ) be the vector of possible values of the random variables B1 , . . . , Bn .
Let




M
i1
i1
ri (bi1
= bi1
= b1i1 , Bi = bi .
1 ) = sup Wi : B1
1 , Bi = bi  inf Wi : B1
bi

bi

M

Let r2 (bn1 ) =

Pn

i1 2
i=1 (ri (b1 ))

M

and rb2 = supbn1 r2 (bn1 ). Then,



22
PBn1 {Wn  W0 > } < exp  2
.
rb

(47)

The inequality (47) is an improved version of the Hoeffding-Azuma inequality (Hoeffding,
1963; Azuma, 1967).
The proof of Lemma 2 is inspired by McDiarmids proof of the bounded difference
inequality for permutation graphs (McDiarmid, 1998, Section 3). Let W0m+u be a martingale


M
) and
obtained from f (Z) by Doobs martingale process, namely W0 = EZm+u f (Zm+u
1
1


M
i . We compute the upper bound on r
2 and apply Lemma 10.
)|Z
b
Wi = EZm+u f (Zm+u
1
1
1

Fix i, i  I1m . Let  m+u
= 1 , . . . , m+u be a specific permutation of I1m+u and i0 
1




M
M
m+u
mi
m
{i+1 , . . . , m+u }. Let p1 = PjI m+u j  Ii+1
= m+ui
and p2 = PjI m+u j  Im+1
=
i+1

i+1

17. See, e.g., Chapter 12 of Grimmett and Stirzaker (1995), and Section 9.1 of Devroye et al. (1996) for more
details.

28

fiTransductive Rademacher Complexity and its Applications

1  p1 =

u
m+ui .

We have





 1i1 ) = sup Wi : Bi1
Wi : B1i1 =  1i1 , Bi = i
ri (
=  i1
1
1 , Bi = i  inf
i
i





i1
i1
= sup EZ f (Z) | Z1 =  1 , Zi = i  EZ f (Z) | Zi1
=  1i1 , Zi = i0
1
i ,i0

n


sup EjI m+u EZ f (Z) | Zi1
=  1i1 , Zi = i , Zj = i0
1

=

=
=

i ,i0

i+1

i ,i0

i+1


o
 EjI m+u EZ f (Zij ) | Zi1
=  i1
, Zi = i , Zj = i0
1
1
i+1
n

o
0
sup EjI m+u EZ f (Z)  f (Zij ) | Z1i1 =  i1
1 , Zi = i , Zj = i

(48)

n


0
m
sup p1  EZ,jIi+1
f (Z)  f (Zij ) | Z1i1 =  i1
1 , Zi = i , Zj = i

(49)

i ,i0


o
0
+ p2  EZ,jI m+u f (Z)  f (Zij ) | Z1i1 =  i1
1 , Zi = i , Zj = i
m+1

Since f (Z) is (m, u)-permutation symmetric function, the expectation in (49) is zero. Therefore,
 i1
ri (
1 ) =


n

o
sup p2  EZ,jI m+u f (Z)  f (Zij ) | Z1i1 =  1i1 , Zi = i , Zj = i0
m+1

i ,i0

u
.
m+ui

m+u
Since f (Z) is (m, u)-permutation symmetric, it also follows from (48) that for i  Im+1
,
R
j+1/2 1
i1
1
 1 ) = 0. It can be verified that for any j > 1/2, j 2  j1/2 t2 dt, and therefore,
ri (

2

rb

=

sup

m+u
X

 m+u
i=1
1

Z

 u2  2

m
X


i1 2
1 ) 
ri (

m+u1/2

u1/2

i=1



u
m+ui

2

2 2

=u 

m+u1
X
j=u

1
j2

mu2  2

1
dt =
.
t2
(u  1/2)(m + u  1/2)

(50)

By applying Lemma 10 with the bound (50) we obtain


22 (u  1/2)(m + u  1/2)
PZ {f (Z)  EZ {f (Z)}  }  exp 
.
mu2  2

(51)

The entire derivation is symmetric in m and u. Therefore, we also have


22 (m  1/2)(m + u  1/2)
PZ {f (Z)  EZ {f (Z)}  }  exp 
.
m2 u 2

(52)

By taking the tightest bound from (51) and (52) we obtain the statement of the lemma.
29

fiEl-Yaniv & Pechyony

Appendix C. Proof of Lemma 3
We consider the following algorithm18 (named RANDPERM) for drawing the first m elements
m+u
{Zi }m
:
i=1 of the random permutation Z of I1
Let Zi = i for any i  I1m+u .
2: for i = 1 to m do
3:
Draw di uniformly from Iim+u .
4:
Swap the values of Zi and Zdi .
5: end for
Algorithm 1: RANDPERM - draw the first m elements of the random permutation of m + u
elements.
1:

The algorithm RANDPERM is an abridged version of the procedure of drawing a random
permutation of n elements by drawing n1 non-identically distributed independent random
variables, presented in Section 5 of the paper of Talagrand (1995) (which according to
Talagrand is due to Maurey, 1979).
Lemma 11 The algorithm RANDPERM performs a uniform draw of the first m elements
Z1 , . . . , Zm of the random permutation Z.
Proof: The proof is by induction on m. If m = 1, then a single random variable d1 is
uniformly drawn among Im+u , and therefore, Z1 has a uniform distribution over I1m+u . Let
M
dm
1 = d1 , . . . , dm . Suppose the claim holds for all m1 < m. For any two possible values
M
0m M 0
0
m
1 = 1 , . . . , m and  1 = 1 , . . . , m of Z1 , . . . , Zm , we have
m1
m
Pdm
{Zm
=  m1
}  Pdm {Zm = m | Zm1
=  m1
}
1 =  1 } = Pdm1 {Z1
1
1
1
1
1

1
(53)
u+1
0
=  0m1
}  Pdm {Zm = m
| Zm1
=  0m1
}
1
1
1

= Pdm1 {Zm1
=  0m1
}
1
1
1

= Pdm1 {Zm1
1
1

0m
= Pdm
{Zm
1 = 1 } .
1

The equality (53) follows from the inductive assumption and the definition of dm .



Consider any (m, u)-permutation symmetric function f = f (Z) over random permutations Z. Using the algorithm RANDPERM we can represent any random permutation Z as a
function g(d) of m independent random variables. The value of the function g(d) is the
output of the algorithm RANDPERM operated with the values of random draws given by d.
The next lemma relates the Lipschitz constant of the function f (g(d)) to the Lipschitz
constant of f (Z):
18. Another algorithm for generating random permutation from independent draws was presented in Appendix B of Lanckriet et al. (2004). This algorithm draws a random permutation by means of drawing
m + u independent random variables. Since we only deal with (m, u)-permutation symmetric functions,
we are only interested in the first m elements of the random permutation. The algorithm of Lanckriet
et al. needs m + u draws of independent random variables to define the above m elements. The algorithm RANDPERM, presented in this section, needs only m draws. If we use the algorithm of Lanckriet
et al. instead of RANDPERM, the forthcoming bound (55) would have the term m + u instead of m. This
change, in turn, would result in a non-convergent risk bound being derived using our techniques.

30

fiTransductive Rademacher Complexity and its Applications

Lemma 12 Let f (Z) be an (m, u)-permutation symmetric function of random permutation
m+u
Z. Suppose that for all i  I1m , j  Im+1
, |f (Z)  f (Zij )|  . Let d0i be an independent
draw of the random variable di . Then for any i  I1m ,
|f (g(d1 , . . . , di1 , di , di+1 , . . . , dm ))  f (g(d1 , . . . , di1 , d0i , di+1 , . . . , dm ))|   .
M

(54)

M

Proof: The values of d = (d1 , . . . , di , . . . , dm ) and d0 = (d1 , . . . , d0i , . . . , dm ) induce, re0m
0
0
spectively, the first m values19 Zm
1 = {Z1 , . . . , Zm } and Z1 = {Z1 , . . . , Zm } of the two
m+u
dependent permutations of I1 . Since f is (m, u)-permutation symmetric, its value is
0
uniquely determined by the value of Zm
1 . We prove that the change of di by di results in a
m
ij
change of a single element in Z1 . Combined with the property of |f (Z)  f (Z )|  , this
will conclude the proof of (54).
We refer to d and d0 as, respectively, old and new draws. Consider the operation
of RANDPERM with the draws d and d0 . Let i , di and d0i be the values of, respectively,
Zi , Zdi and Zd0i just before the ith iteration of RANDPERM. Note that di  i and d0i  i.
In the old permutation, after the ith iteration Zi = di , Zdi = i and Zd0i = d0i . In the
new permutation, after the ith iteration Zi = d0i , Zdi = di and Zd0i = i . After the ith
iteration of RANDPERM the value of Zi remains intact. However the values of Zdi and Zd0i
may change. In particular the values of di and i may be among Zi+1 , . . . , Zm at the end
of the run of RANDPERM. We have four cases:
0m
m
/ Z0m
/ Z0m
Case 1 If d0i 
/ Zm
/ Zm
1 , i 
1 and Z1 = Z1 \{di }  {d0i }.
1 and i 
1 then di 
m
0m
0m
0m
m
Case 2 If d0i  Zm
1 and i  Z1 then di  Z1 , i  Z1 and Z1 = Z1 .
0m
0m
m
Case 3 If i  Zm
/ Zm
/ Z0m
1 and d0i 
1 then di  Z1 , i 
1 and Z1 = Z1 \{i }  {d0i }.
0m
m
0m
/ Z0m
Case 4 If d0i  Zm
/ Zm
1 and Z1 = Z1 \{di }  {i }.
1 and i 
1 then i  Z1 , di 


We apply a bounded difference inequality of McDiarmid (1989) to f (g(d)) and obtain


22
Pd {f (g(d))  Ed {f (g(d))}  }  exp  2
.
(55)
 m
Since f (Z) is a (m, u)-permutation symmetric, it follows from (55) that


22
.
PZ {f (Z)  EZ {f (Z)}  }  exp  2
 m
Since the entire derivation is symmetric in m and u we also have


22
PZ {f (Z)  EZ {f (Z)}  }  exp  2
.
 u

(56)

(57)

The proof of Lemma 3 is completed by taking the minimum of the bounds (56) and (57).
19. For notational convenience in this section, we refer to Zm
1 as a set of values and not as a vector of values
(as is done in other sections).

31

fiEl-Yaniv & Pechyony

Appendix D. Proof of Claims in Lemma 4
Proof of Claim 1. Note that N1 and N2 are random variables whose distribution is
induced by the distribution of . We have by (9) that
Rm+u (V) = EN1 ,N2 ERad(N1 ,N2 ) sup

m+u
X

vV i=1

(i,1 + i,2 ) v(i) = EN1 ,N2 s(N1 , N2 ) .

Proof of Claim 2. By the definitions of Hk and Tk (appearing at the start of Section 4.1),
for any N1 , N2  I1m+u we have
h
i
EZ,Z0 sup TN1 {v(Z)}  TN2 {v(Z0 )} + HN2 {v(Z0 )}  HN1 {v(Z)} =
vV

#
N2
N1
m+u
m+u
X
X
1 X
1
1
1 X
v(Zi ) 
v(Zi0 ) +
v(Zi0 ) 
v(Zi ) . (58)
EZ,Z0 sup
u
m
m
vV u i=N +1
i=1
i=1
i=N
+1
1
2
|
{z
}
"

M

=r(v,Z,Z0 ,N1 ,N2 )

The values of N1 and N2 , and the distribution of Z and Z0 , with respect 
to which we take

1 1
1
the expectation in (58), induce a distribution of assignments of coefficients m
, m
, u ,  u1
to the components of v. For any N1 , N2 and realizations of Z and Z0 , each component v(i),
i  I1m+u , is assigned to exactly two coefficients, one for each of the two permutations (Z
M
M
and Z0 ). Let a = (a1 , . . . , am+u ), where ai = (ai,1 , ai,2 ) is a pair of coefficients. For any
m+u
i  I1 , the pair (ai,1 , ai,2 ) takes the values of the coefficients of v(i), where the first
1
or u1 ) and the second
component is induced by the realization Z (i.e., ai,1 is either  m
1
1
0
component by the realization of Z (i.e., ai,2 is either m or  u ).
Let A(N1 , N2 ) be the distribution of vectors a, induced by the distribution of Z and Z0 ,
for particular N1 , N2 . Using this definition we can write
" m+u
#
X
(58) = EaA(N1 ,N2 ) sup
(ai,1 + ai,2 )v(i) .
(59)
vV

i=1

Let Par(k) be the uniform distribution over partitions of m+u elements into two subsets,
of
k
 and m
 + u  k elements, respectively. Clearly, Par(k) is a uniform distribution over
m+u
elements. The distribution of the random vector (a1,1 , a2,1 , . . . , am+u,1 ) of the
k
first elements of pairs in a is equivalent to Par(N1 ). That is, this vector is obtained by
1
to the corresponding
taking the first N1 indices of the realization of Z and assigning  m
1
components. The other components are assigned to u . Similarly, the distribution of the
random vector (a1,2 , a2,2 , . . . , am+u,2 ) is equivalent to Par(N2 ). Therefore, the distribution
A(N1 , N2 ) of the entire vector a is equivalentto the product
of Par(N1 ) and
  distribution

m+u
m+u
Par(N2 ), which is a uniform distribution over

elements, where each
N1
N2
element is a pair of independent permutations.
We show that the distributions Rad(N1 , N2 ) and A(N1 , N2 ) are identical. Given N1 and
N2 and setting  = (m+u)2 , the probability of drawing a specific realization of  (satisfying
32

fiTransductive Rademacher Complexity and its Applications

n1 + n2 = N1 and n2 + n3 = N2 ) is


m2


n2 

mu N1 n2  mu N2 n2





u2


m+uN1 N2 +n2
=

mN1 +N2 u2(m+u)N1 N2
. (60)
(m + u)2(m+u)

Since (60) is independent of the ni s, the distribution Rad(N1 , N2 ) is uniform over all
possible Rademacher assignments satisfying the constraints N1 and N2 . It is easy to see
that the support size of Rad(N1 , N2 ) is the same as the support size of A(N1 , N2 ). Moreover,
the support sets of these distributions are identical; hence these distributions are identical.
Therefore, it follows from (59) that
(
(58) = ERad(N1 ,N2 )

" m+u
#)
X
sup
(i,1 + i,2 )v(i)
= s(N1 , N2 ) .

vV

i=1

It is easy to see that E N1 = E {n1 + n2 } = m and that E N2 = E {n2 + n3 } = m. Since
EZ {(Z)} is (58) with N1 = m and N2 = m, we have
(
EZ {(Z)} = ERad(m,m)

sup
vV

"m+u
X

#)
(i,1 + i,2 ) v(i)

= s (E N1 , E N2 ) .

i=1

Proof of Claim 3.
We bound the differences |s(N1 , N2 )  s (N10 , N2 ) | and |s(N1 , N2 )  s (N1 , N20 ) | for any
1  N1 , N2 , N10 , N20  m + u. Suppose w.l.o.g. that N10  N1 . Recalling the definition of
r() in (58) we have
"
#
s(N1 , N2 ) = EZ,Z0 sup r(v, Z, Z0 , N1 , N2 )
vV

"



s(N10 , N2 ) = EZ,Z0 sup r(v, Z, Z0 , N1 , N2 ) +
vV

1
1
+
u m

 X
N1

#
v(Zi ) .

(61)

i=N10 +1

The expressions under the supremums in s(N1 , N2 ) and s(N10 , N2 ) differ only in the two
terms in (61). Therefore, for any N1 and N10 ,






s(N1 , N2 )  s(N10 , N2 )  Bmax N1  N10  1 + 1
.
(62)
u m
Similarly we have that for any N2 and N20 ,




s(N1 , N2 )  s(N1 , N20 )  Bmax N2  N20 



1
1
+
u m


.

(63)

We use the following Bernstein-type concentration inequality (see Devroye et al., 1996,
Problem
 8.3)
 for the binomial random variable X  Bin(p, n): P
X {|X  EX|
 > t} <
M 1
m
3t2
1
2 exp  8np . Abbreviate Q = m + u . Noting that N1 , N2  Bin m+u , m + u , we use
33

fiEl-Yaniv & Pechyony

M

M

(62), (63) and the Bernstein-type inequality (applied with n = m + u and p =
obtain

m
m+u )

to

PN1 ,N2 {|s(N1 , N2 )  s(E {N1 } , E {N2 })|  }
 PN1 ,N2 {|s(N1 , N2 )  s(N1 , E N2 )| + |s(N1 , E N2 )  s(E N1 , E N2 )|  }
n
o
 PN1 ,N2 |s(N1 , N2 )  s(N1 , E N2 )| 
2
n
o
+PN1 ,N2 |s(N1 , E N2 )  s(E N1 , E N2 )| 
2
n
n
o
o
 PN2 |N2  E N2 | Bmax Q 
+ PN1 |N1  E N1 | Bmax Q 
2 !
2



2
2
3
3
 4 exp 
= 4 exp 
.
m
2
2
2 Q2
32(m + u) m+u Bmax Q
32mBmax
Next we use the following fact (see Devroye et al., 1996, Problem 12.1): if a nonnegative
random variable X satisfies P{X > t}  c  exp(kt2 ) for some c  1 and k > 0, then
p
M
M
EX  ln(ce)/k. Using this fact, along with c = 4 and k = 3/(32mQ2 ), we have
|EN1 ,N2 {s(N1 , N2 )}  s(E N1 , E N2 )|  EN1 ,N2 |s(N1 , N2 )  s(E N1 , E N2 )|
s


32 ln(4e)
1
1 2
2

mBmax
+
.
3
u m

Appendix E. Proof of Lemma 5
The proof is a straightforward extension of the proof of Lemma 5 from Meir and Zhang
(2003) and is also similar to the proof of our Lemma 1 in Appendix A. We prove a stronger
claim: if for all i  I1m+u and v, v0  V, |f (vi )f (vi0 )|  |g(vi )g(vi0 )|, then for any function
e
c : Rm+u  R.
"m+u
#
"m+u
#
X
X
i f (vi ) + e
c(v)  E sup
i g(vi ) + e
c(v) .
E sup
vV

vV

i=1

i=1

M

We use the abbreviation 1n = 1 , . . . , n . The proof is by induction on n, such that
0  n  m + u. The lemma trivially holds for n = 0. Suppose the lemma holds for n  1.
In other words, for any function c(v),
"
En1 sup c(v) +
1

M

Let p =

mu
.
(m+u)2

vV

n1
X

#

"

i f (vi )  En1 sup c(v) +
1

i=1

vV

n1
X

#
i g(vi )

.

i=1

We have
"

M

A = E1n sup c(v) +
vV

n
X

#

"

i f (vi ) = En En1 sup c(v) +
1

i=1

34

vV

n
X
i=1

#
i f (vi )

(64)

fiTransductive Rademacher Complexity and its Applications

(
= pEn1

"
sup c(v) +

1

vV

n1
X

#

"

i f (vi ) + f (vn ) + sup c(v) +
vV

i=1

n1
X

#)
i f (vi )  f (vn )

i=1

"

+(1  2p)En1 sup c(v) +
1

n1
X

vV

(65)
#

i f (vi )

.

(66)

i=1

We apply the inductive hypothesis three times: on the first and second summands in (65)
M
M
M
with c(v) = c(v)+f (vn ) and c(v) = c(v)f (vn ), respectively, and on (66) with c(v) = c(v).
We obtain
(
"
#
"
#)
n1
n1
X
X
A  pEn1 sup c(v) +
i g(vi ) + f (vn ) + sup c(v) +
i g(vi )  f (vn )
1

vV

|

i=1

vV

{z

i=1

}

M

=B

"
+ (1  2p)En1 sup c(v) +
1

|

vV

#

n1
X

i g(vi )

i=1

{z

.
}

M

=C

The expression B can be written as follows.
"
#)
"
#
(
n1
n1
X
X
0
0
0
i g(vi )  f (vn )
i g(vi ) + f (vn ) + sup c(v ) +
B = pEn1 sup c(v) +
1

vV

c(v) + c(v0 ) +

= pEn1 sup
1

v,v0 V

"
0

= pEn1 sup
1

v0 V

i=1

"

c(v) + c(v ) +

v,v0 V

i=1

n1
Xh

i
i (g(vi ) + g(vi0 )) + (f (vn )  f (vn0 ))

i=1
n1
Xh

i

i (g(vi ) +

g(vi0 ))



+ f (vn )  f (vn0 )

#
#
.

(67)

i=1

P
0
The equality (67) holds since the expression c(v)+c(v0 )+ n1
i=1 i (g(vi )+g(vi )) is symmetric
0
0
in v and v . Thus, if f (v) < f (v ) then we can exchange the values of v and v0 and this
will increase the value of the expression under the supremum. Since |f (vn )  f (vn0 )| 
|g(vn )  g(vn0 )| we have
"
#
n1
i
Xh
0
0
0
B  pEn1 sup c(v) + c(v ) +
i (g(vi ) + g(vi )) + |g(vn )  g(vn )|
1

v,v0 V

"
c(v) + c(v0 ) +

= pEn1 sup
1

v,v0 V

(
= pEn1
1

n1
X

#

i

i (g(vi ) + g(vi0 )) + (g(vn )  g(vn0 ))

i=1

"

sup c(v) +
vV

i=1
n1
Xh

#

"

n1
X

i g(vi ) + g(vn ) + sup c(v) +
vV

i=1

Therefore, using the reverse argument of (64)-(66),
"
A  C + D = E1n sup c(v) +
vV

35

n
X
i=1

i=1

#
i g(vi )

.

#)
i g(vi )  g(vn )

M

= D.

fiEl-Yaniv & Pechyony

Appendix F. Proof of Lemma 6
M

Let c  R, U = c  I. If c = 0, then the soft classification generated by A is a constant zero.
In this case, for any h generated by A, we have Lbm (h) = 1 and the lemma holds.
Suppose c 6= 0. Then
1
= h .
(68)
c
Since the (m + u)  (m + u) matrix U has m + u singular values, each one is precisely c, by
(22) the Rademacher complexity of the trivial ULR is bounded by
s 
r

2
1
1
2
.
(69)
1
(m + u)c = c1 2
+
mu
m u
We assume w.l.o.g. that the training points have indices from 1 to m. Let A = {i 
I1m | yi h(i) > 0 and |h(i)| > } be a set of indices of training examples with zero margin
loss. Let B = {i  I1m | |h(i)|  [, ]} and C = {i  I1m | yi h(i) < 0 and |h(i)| > }.
By (68) and the definition of the sets A, C, for any i  A  C, |i | > c . Similarly, for any
i  B, |i | = |h(i)|
c . We obtain that the bound (69) is at least
s
r
 2 X h(i)2 1
c (|A| + |C|) 2 +
.
c
c2
m
iB

Therefore, the risk bound (15) is bounded from below by
r
s
X
2
2
2
(|A| + |C|) +
h(i) 
m
iB
s
r
P
X h(i)2
2
iB (1  |h(i)|/) + |C|
+ |A| + |C| +

2
m

m
iB
r
P
s
X
|B| + |C|  iB ri
2
+ |A| + |C| +
ri2 
m
m
iB
r
P
s
X
m  |A|  iB ri
2
2
+ |A| + |C| +
ri 
m
m
1
Lbm (h) +




=
=
M

= D ,

iB

where ri = |h(i)|
 . We prove that D  1. Equivalently, it is sufficient to prove that for
ri1 , . . . , ri|B|  [0, 1]|B| it holds that


f ri1 , . . . , ri|B| =

P
(|A| + iB ri )2
P
m .
|A| + |C| + iB ri2

We claim that the stronger statement holds:

 (|A| + |C| + P
ri )2
PiB 2  m .
f ri1 , . . . , ri|B| =
|A| + |C| + iB ri
36

(70)

fiTransductive Rademacher Complexity and its Applications

To prove (70) we use the Cauchy-Schwarz inequality, stating that for any two vectors a, b 
M
Rm , ha, bi  kak2  kbk2 . We set bi = 1 for all i  I1m . The vector a is set as follows: ai = ri
if i  B and ai = 1 otherwise. By this definition of a and b, we have that ha, bi  0 and
thus (ha, bi)2  kak22  kbk22 . The application of this inequality with the defined vectors a
and b results in the inequality (70).

Appendix G. Proofs from Section 6.2
Proof of Lemma 7: Let ei be an (m + u)  1 vector whose ith entry equals 1 and other
entries are zero. According to the definition of RKHS, we need to show that for any
1  i  m + u, h(i) = hU (i, ), hiL . We have
hU (i, ), hiL = U (i, )Lh = ei U Lh
! m+u
!
m+u
!
m+u
X
X
X 1
T
T
T
T
T
ui ui
i ui ui h = ei
ui ui h
= ei
i
i=2
i=1
i=2


1
= eTi (I  u1 uT1 )h = eTi I 
1  1T h = h(i) .
m+u

Lemma 13 For any 1  i  m + u, U (i, )  HL .
Proof: Since L is a Laplacian matrix, u1 = 1. Since the vectors {ui }m+u
i=1 are orthonormal
Pm+u 1
T
1 = 0. Therefore, for any 1  i  m + u,
and u1 = 1, we have U  1 =
i=2 i ui ui
U (i, )  1 = 0.


p
M
Proof of Lemma 8: Let khkL = hh, hiL = hT Lh be a norm in GL . The optimization
problem (30)-(31) can be stated in the following form:
min

hHL

khk2L + c(h  ~ )T C(h  ~ ) .

(71)
M

Let U  HL be a vector space spanned by the vectors {U (i, )}m+u
i=1 . Let hk =
(i,)iL
i  m + u, i = hh,U
kU (i,)kL .
It can be verified that h

be a projection of h onto U. For any 1 
be a part of h that is perpendicular to U.
1  i  m + u, hh , U (i, )iL = 0. For any 1  i  m + u we have
m+u
X

h(i) = hh, U (i, )iL = h

Pm+u
i=1

i U (i, )

Let h = h  hk
 HL and for any

j U (j, ), U (i, )iL + hh , U (i, )iL

j=1

=

m+u
X

j hU (j, ), U (i, )iL =

j=1

m+u
X

j U (i, j) = hk (i) .

(72)

j=1

The second equation in (72) holds by Lemma 13. As a consequence of (72), the empirical
error (the second term in (71)) depends only on hk . Furthermore,
hT Lh = hh, hiL = khk2L = k

m+u
X

i U (i, )k2L + kh k2L  k

i=1

m+u
X
i=1

37

i U (i, )k2L .

fiEl-Yaniv & Pechyony

Therefore, for an h  H that minimizes (71), h = 0 and h = hk =


Pm+u
i=1

i U (i, ) = U .

Appendix H. Proof of Lemma 9
M

Let LN = I  L = I  D1/2 W D1/2 be a normalized Laplacian of W . The eigenvalues
0
{0i }m+u
i=1 of LN are non-negative and the smallest eigenvalue of LN , denoted here by min ,
is zero (Chung, 1997). The eigenvalues of the matrix I  L = (1  )I + LN are
{1   + 0i }m+u
 L are strictly positive.
i=1 . Since 0 <  < 1, all the eigenvalues of I
om+u
n
1
. Finally, the
Hence the matrix I  L is invertible and its eigenvalues are 1+
0
i i=1
n
om+u
1
eigenvalues of the matrix U are 1+
. Since 0min = 0, the largest eigenvalue of
0
i i=1
U is 1. Since all eigenvalues of LN are non-negative, we have that min > 0.

Appendix I. Proofs from Section 7

Proof of Corollary 2: Let {Ai }
i=1 and {pi }i=1 be a set of positive numbers such that
P

i=1 pi  1. By the weighted union bound argument we have from (39) that with probability of at least 1   over the training/test set partitions, for all Ai and q  g,Ai ,

eq) 
Lu (h

eq)
Lbm (h

p
Rm+u (Beg,Ai )
+
+ c0 Q min(m, u) +


s
S
1
Q ln
.
2
pi 

(73)

P
M
M
1
We set Ai = g0 si and pi = i(i+1)
. It can be verified that 
i=1 pi  1. For each q let iq be
the smallest index for which Aiq  g(q). We have two cases:
Case 1 iq = 1. In this case iq = logs (g(q)/g0 ) = 1.
Case 2 iq  2. In this case Aiq 1 = g0 siq 1 < g(q)  g(q)s1 , and therefore, iq 
logs (g(q)/g0 ).
Thus we always have that iq  logs (g(q)/g0 ). It follows from the definition of Aiq and g(q)
that Aiq  g(q). We have that ln(1/piq )  2 ln(iq + 1)  2 ln logs (sg(q)/g0 ). Substituting
these bounds into (73) and taking into account the monotonicity of Rm+u (Beg,Ai ) (in Ai ),
we have that with probability of at least 1  , for all q, the bound (40) holds.

Proof of Theorem 4: We require several definitions and facts from the convex analysis
(Rockafellar, 1970). For any function f : Rn  R the conjugate function f  : Rn  R
is defined as f  (z) = supxRn (hz, xi  f (x)). The domain of f  consists of all values of z
for which the value of the supremum is finite. A consequence of the definition of f  is the
so-called Fenchel inequality:
hx, zi  f (x) + f  (z) .
(74)
P|B|
It can be verified that the conjugate function of g(q) = D(qkp) is g  (z) = ln j=1 pj ezj .
M
e =
Let h(i)
(h1 (i), . . . , h|B| (i)). In the derivation that follows we use the following inequality
38

fiTransductive Rademacher Complexity and its Applications

(Hoeffding, 1963): if X is a random variable such that a  X  b and c is a constant, then

EX exp(cX)  exp

c2 (b  a)2
8


.

(75)

For any  > 0 we have,
*
e q i = QE sup
Rm+u (Beg,A ) = QE sup h, h
qg,A

=







=

q,

qg,A

*

m+u
X

m+u
X

+
e
i h(i)

i=1

+

Q
e
E sup
q, 
i h(i)

qg,A
i=1
!!

 m+u
X
Q

e
sup g(q) + E g 
i h(i)
 qg,A
i=1

" m+u
#
|B|
X
X
Q
A + E ln
pj exp 
i hj (i) 

j=1
i=1

" m+u
#!
X
Q
A + sup E ln exp 
i h(i)

hB
i=1

" m+u
#!
X
Q
A + sup ln E exp 
i h(i)

hB
i=1

" m+u
#!
2
X

Q
A + sup ln exp
h(i)2

2
hB
i=1


A 
Q
+ sup khk22 .

2 hB
M

(76)

(77)

(78)
(79)
(80)

M

Inequality (76) is obtained by applying (74) with f = g and f  = g  . Inequality (77) follows
from the definition of g and g  . Inequality (78) is obtained by an application of the Jensen
inequality and inequality (79) is obtained by applying m + u times (75). By minimizing
(80) w.r.t.  we obtain
r
Rm+u (Beg,A )  Q 2A sup khk2 .
hB

2

Substituting this bound into (39) we get that for any fixed A, with probability at least 1,
for all q  Bg,A
p
Qr
e q )  Lb (h
e
Lu (h
2A sup khk22 + c0 Q min(m, u) +
m q) +

hB

r

1
S
Q ln .
2


Finally, by applying the weighted union bound technique, as in the proof of Corollary 2, we
obtain the statement of the theorem.


39

fiEl-Yaniv & Pechyony

References
Ambroladze, A., Parrado-Hernandez, E., & Shawe-Taylor, J. (2007). Complexity of pattern
classes and the Lipschitz property. Theoretical Computer Science, 382 (3), 232246.
Audibert, J.-Y. (2004). A better variance control for PAC-Bayesian classification. Tech.
rep. 905, Laboratoire de Probabilites et Modeles Aleatoires, Universites Paris 6 and
Paris 7.
Azuma, K. (1967). Weighted sums of certain dependent random variables. Tohoku Mathematical Journal, 19, 357367.
Balcan, M., & Blum, A. (2006). An augmented PAC model for semi-supervised learning. In
Chapelle, O., Scholkopf, B., & Zien, A. (Eds.), Semi-Supervised Learning, chap. 22,
pp. 383404. MIT Press.
Bartlett, P., Bousquet, O., & Mendelson, S. (2005). Local Rademacher complexities. Annals
of Probability, 33 (4), 14971537.
Bartlett, P., & Mendelson, S. (2002). Rademacher and Gaussian complexities: risk bounds
and structural results. Journal of Machine Learning Research, 3, 463482.
Belkin, M., Matveeva, I., & Niyogi, P. (2004). Regularization and semi-supervised learning
on large graphs. In Shawe-Taylor, J., & Singer, Y. (Eds.), Proceedings of the 17th
Annual Conference on Learning Theory, pp. 624638. Springer-Verlag.
Belkin, M., & Niyogi, P. (2004). Semi-supervised learning on Riemannian manifolds. Machine Learning, 56, 209239.
Blum, A., & Langford, J. (2003). PAC-MDL bounds. In Scholkopf, B., & Warmuth, M.
(Eds.), Proceedings of the 16th Annual Conference on Learning Theory, pp. 344357.
Springer-Verlag.
Bousquet, O., & Elisseeff, A. (2002). Stability and generalization. Journal of Machine
Learning Research, 2, 499526.
Catoni, O. (2004). Improved Vapnik-Cervonenkis bounds. Tech. rep. 942, Laboratoire de
Probabilites et Modeles Aleatoires, Universites Paris 6 and Paris 7.
Catoni, O. (2007). PAC-Bayesian supervised classification, Vol. 56 of IMS Lecture Notes Monograph Series. Institute of Mathematical Statistics.
Chapelle, O., Scholkopf, B., & Zien, A. (Eds.). (2006). Semi-Supervised Learning. MIT
Press, Cambridge, MA.
Chapelle, O., Weston, J., & Scholkopf, B. (2003). Cluster kernels for semi-supervised learning. In Becker, S., Thrun, S., & Obermayer, K. (Eds.), Advances in Neural Information
Processing Systems 15, pp. 585592. MIT Press, Cambridge, MA.
Chung, F. R. (1997). Spectral graph theory, Vol. 92 of CBMS Regional Conference Series
in Mathematics. American Mathematical Society.
Derbeko, P., El-Yaniv, R., & Meir, R. (2004). Explicit learning curves for transduction and
application to clustering and compression algorithms. Journal of Artificial Intelligence
Research, 22, 117142.
40

fiTransductive Rademacher Complexity and its Applications

Devroye, L., Gyorfi, L., & Lugosi, G. (1996). A Probabilistic Theory of Pattern Recognition.
Springer-Verlag.
El-Yaniv, R., & Gerzon, L. (2005). Effective transductive learning via objective model
selection. Pattern Recognition Letters, 26, 21042115.
El-Yaniv, R., & Pechyony, D. (2006). Stable transductive learning. In Lugosi, G., & Simon,
H. (Eds.), Proceedings of the 19th Annual Conference on Learning Theory, pp. 3549.
Springer-Verlag.
Grimmett, G., & Stirzaker, D. (1995). Probability and Random Processes. Oxford Science
Publications. Second edition.
Hanneke, S. (2006). An analysis of graph cut size for transductive learning. In Proceedings
of the 23rd International Conference on Machine Learning, pp. 393399. ACM Press.
Herbster, M., Pontil, M., & Wainer, L. (2005). Online learning over graphs. In Proceedings
of the 22nd International Conference on Machine Learning, pp. 305312. ACM Press.
Hoeffding, W. (1963). Probability inequalities for sums of bounded random variables. Journal of the American Statistical Association, 58, 1330.
Horn, R., & Johnson, C. (1990). Matrix Analysis. Cambridge University Press.
Joachims, T. (2003). Transductive learning via spectral graph partitioning. In Proceedings
of the 20th International Conference on Machine Learning, pp. 290297. ACM Press.
Johnson, R., & Zhang, T. (2007). On the effectiveness of Laplacian normalization for graph
semi-supervised learning. Journal of Machine Learning Research, 8, 14891517.
Johnson, R., & Zhang, T. (2008). Graph-based semi-supervised learning and spectral kernel
design. IEEE Transactions on Information Theory, 54.
Koltchinskii, V. (2001). Rademacher penalties and structural risk minimization. IEEE
Transactions on Information Theory, 47 (5), 19021915.
Koltchinskii, V., & Panchenko, D. (2002). Empirical margin distributions and bounding
the generalization error of combined classifiers. Annals of Statistics, 30 (1), 150.
Lanckriet, G., Cristianini, N., Bartlett, P., Ghaoui, L. E., & Jordan, M. (2004). Learning the
kernel matrix with semidefinite programming. Journal of Machine Learning Research,
5, 2772.
Ledoux, M., & Talagrand, M. (1991). Probability in Banach spaces. Springer-Verlag.
Maurey, B. (1979). Construction de suites symetriques. Comptes Rendus Acad. Sci. Paris,
288, 679681.
McAllester, D. (2003). PAC-Bayesian stochastic model selection. Machine Learning, 51 (1),
521.
McDiarmid, C. (1989). On the method of bounded differences. In Siemons, J. (Ed.), Surveys
in Combinatorics, pp. 148188. London Mathematical Society Lecture Note Series 141,
Cambridge University Press.
McDiarmid, C. (1998). Concentration. In Habib, M., McDiarmid, C., Ramirez, J., & Reed,
B. (Eds.), Probabilistic methods for algorithmic discrete mathematics, pp. 195248.
Springer-Verlag.
41

fiEl-Yaniv & Pechyony

Meir, R., & Zhang, T. (2003). Generalization error bounds for Bayesian mixture algorithms.
Journal of Machine Learning Research, 4, 839860.
Rockafellar, R. (1970). Convex Analysis. Princeton University Press, Princeton, N.J.
Scholkopf, B., Herbrich, R., & Smola, A. (2001). A generalized representer theorem. In
Helmbold, D., & Williamson, B. (Eds.), 14th Annual Conference on Computational
Learning Theory and 5th European Conference on Computational Learning Theory,
pp. 416426. Springer-Verlag.
Serfling, R. (1974). Probability inequalities for the sum in sampling without replacacement.
The Annals of Statistics, 2 (1), 3948.
Talagrand, M. (1995). Concentration of measure and isoperimetric inequalities in product
spaces. Publications Mathematiques de lI.H.E.S., 81, 73203.
Vapnik, V. (1982). Estimation of Dependences Based on Empirical Data. Springer-Verlag.
Vapnik, V. (2000). The nature of statistical learning theory (2nd edition). Springer-Verlag.
Vapnik, V., & Chervonenkis, A. (1974). The Theory of Pattern Recognition. Moscow:
Nauka.
Zhou, D., Bousquet, O., Lal, T., Weston, J., & Scholkopf, B. (2004). Learning with local
and global consistency. In Thrun, S., Saul, L., & Scholkopf, B. (Eds.), Advances in
Neural Information Processing Systems 16. MIT Press, Cambridge, MA.
Zhu, X., Ghahramani, Z., & Lafferty, J. (2003). Semi-supervised learning using gaussian
fields and harmonic functions. In Proceedings of the 20th International Conference on
Machine Learning, pp. 912919. ACM Press.

42

fiJournal of Artificial Intelligence Research 35 (2009) 485-532

Submitted 08/08; published 07/09

How Hard Is Bribery in Elections?
Piotr Faliszewski

faliszew@agh.edu.pl

Department of Computer Science
AGH University of Science and Technology
Krakow, Poland

Edith Hemaspaandra

eh@cs.rit.edu

Department of Computer Science
Rochester Institute of Technology
Rochester, NY 14623 USA

Lane A. Hemaspaandra

lane@cs.rochester.edu

Department of Computer Science
University of Rochester
Rochester, NY 14627 USA

Abstract
We study the complexity of influencing elections through bribery: How computationally complex is it for an external actor to determine whether by paying certain voters
to change their preferences a specified candidate can be made the elections winner? We
study this problem for election systems as varied as scoring protocols and Dodgson voting,
and in a variety of settings regarding homogeneous-vs.-nonhomogeneous electorate bribability, bounded-size-vs.-arbitrary-sized candidate sets, weighted-vs.-unweighted voters, and
succinct-vs.-nonsuccinct input specification. We obtain both polynomial-time bribery algorithms and proofs of the intractability of bribery, and indeed our results show that the
complexity of bribery is extremely sensitive to the setting. For example, we find settings
in which bribery is NP-complete but manipulation (by voters) is in P, and we find settings in which bribing weighted voters is NP-complete but bribing voters with individual
bribe thresholds is in P. For the broad class of elections (including plurality, Borda, kapproval, and veto) known as scoring protocols, we prove a dichotomy result for bribery of
weighted voters: We find a simple-to-evaluate condition that classifies every case as either
NP-complete or in P.

1. Introduction
This paper studies the complexity of bribery in elections, that is, the complexity of computing whether it is possible, by modifying the preferences of a given number of voters, to
make some preferred candidate a winner.
Election systems provide a framework for aggregating voters preferencesideally
(though there is no truly ideal voting system, see Duggan & Schwartz, 2000; Gibbard,
1973; Satterthwaite, 1975) in a way that is satisfying, attractive, and natural. Societies use
elections to select their leaders, establish their laws, and decide their policies, but practical
applications of elections are not restricted to people and politics. Many parallel algorithms
start by electing leaders. Multiagent systems sometimes use voting for the purpose of
planning (Ephrati & Rosenschein, 1997). Web search engines can aggregate results using
methods based on elections (Dwork, Kumar, Naor, & Sivakumar, 2001). With such a wide
c
2009
AI Access Foundation. All rights reserved.

fiFaliszewski, Hemaspaandra, & Hemaspaandra

range of applications, it is not surprising that elections vary tremendously. For example,
one might think at first that typical elections have many voters and very few candidates.
However, in fact, they may have a very wide range of voter-to-candidate proportions: In
typical presidential elections there are relatively few candidates but there may be millions
of voters. In the context of the web, one may consider web pages as voting on other pages
by linking to them, or may consider humans to be voting on pages at a site by the time
they spend on each. In such a setting we may have both a large number of voters and a
large number of candidates. On the other hand, Dwork et al. (2001) suggest designing a
meta search engine that treats other search engines as voters and web pages as candidates.
This yields very few voters but many candidates. To summarize this paragraph, elections
have a great variety of sizes in terms of numbers of candidates and numbers of voters. So,
surely, one should not simply say Elections tend to be small, and so we can always solve
by brute-force the issues related to them.
With the principles of democracy in mind, we also tend to think that each vote is equally
important. However, all the above scenarios make just as much sense in a setting in which
each voter has a different voting power. For example, U.S. presidential elections are in
some sense weighted (different states have different voting powers in the Electoral College);
shareholders in a company have votes weighted by the number of shares they own; and
search engines in the above example could be weighted by their quality. Weighted voting is
a natural choice in many other settings as well.
The importance of election systems naturally inspired questions regarding their resistance to abuse, and several potential dangers were identified and studied. For example,
an elections organizers can make attempts to control the outcome of the elections by procedural tricks such as adding or deleting candidates or encouraging/discouraging people
from voting. Classical social choice theory is concerned with the possibility or impossibility of such procedural control. However, recently it was realized that even if control is
possible, it may still be difficult to find what actions are needed to effect control, e.g., because the computational problem is NP-complete. The complexity of controlling who wins
the election was studied first by Bartholdi, Tovey, and Trick (1992) and later on by many
other authors (Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2007; Hemaspaandra,
Hemaspaandra, & Rothe, 2007; Erdelyi, Nowak, & Rothe, 2008a, 2008b; Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2008; Meir, Procaccia, Rosenschein, & Zohar, 2008).
Elections are endangered not only by the organizers but also by the voters (manipulation),
who might be tempted to vote strategically (that is, not according to their true preferences)
to obtain their preferred outcome. This is not desirable as it can skew the result of the
elections in a way that is arguably not in the best interest of the society. The Gibbard
Satterthwaite/DugganSchwartz Theorems (Gibbard, 1973; Satterthwaite, 1975; Duggan &
Schwartz, 2000) show that essentially all election systems can be manipulated, and so it is
important to discover for which systems manipulation is computationally difficult to execute.
This line of research was started by Bartholdi, Tovey, and Trick (1989a) and was continued
by many researchers (as a few varied examples, we mention the work of Elkind & Lipmaa, 2005b, 2005a; Conitzer, Sandholm, & Lang, 2007; Hemaspaandra & Hemaspaandra,
2007; Procaccia & Rosenschein, 2007; Brelsford, Faliszewski, Hemaspaandra, Schnoor, &
Schnoor, 2008; Faliszewski, Hemaspaandra, & Schnoor, 2008; and Zuckerman, Procaccia, &
Rosenschein, 2008; readers interested in manipulation will be able to reach a broader collec486

fiHow Hard Is Bribery in Elections?

tion of papers through the standard process of recursive bibliography search). Faliszewski,
Hemaspaandra, Hemaspaandra, and Rothe (2009b) provide a relatively nontechnical survey
of some complexity issues related to altering the outcomes of elections.
Surprisingly, nobody seems to have addressed the issue of (the complexity of) bribery,
i.e., attacks where the person interested in the success of a particular candidate picks a
group of voters and convinces them to vote as he or she says. Bribery seems strongly
motivated by both real-life and computational agent-based settings, and shares some of the
flavor of both manipulation (changing voters (reported) preferences) and control (deciding
which voters to influence). This paper (in this version and its conference precursor) initiates
the study of the complexity of bribery in elections.
There are many different settings in which bribery can be studied. In the simplest one
we are interested only in the least number of voters we need to bribe to make our favored
candidate win. A natural extension is to consider prices for each voter. In this setting,
each voter is willing to change his or her true preferences to anything we say, but only if
we can meet his or her price. In an even more complicated setting it is conceivable that
voters would have different prices depending on how we want to affect their vote (however,
it is not clear how to succinctly encode a voters price scheme). We mainly focus on the
previous two scenarios but we do point the reader to our results on approval voting and to
the work of Faliszewski (2008) for a discussion of bribery when prices are represented more
flexibly.
We classify election systems with respect to bribery by seeking in each case to either (a)
prove the complexity is low by giving a polynomial-time algorithm or (b) argue intractability
via proving the NP-completeness of discovering whether bribery can affect a given case. We
obtain a broad range of results showing that the complexity of bribery depends closely on
the setting. For example, for weighted plurality elections bribery is in P (Theorem 3.3) but
jumps to being NP-complete if voters have price tags (Theorem 3.2). As another example,
for approval voting the manipulation problem is easily seen to be in P, but in contrast we
prove that the bribery problem is NP-complete (Theorem 4.2). Yet we also prove that when
the bribery cost function is made more local, the complexity of approval voting falls back to
P (Theorem 4.4). But if more constraints are added, the problem goes up to NP-complete
again (Theorem 4.5). For scoring protocols we obtain complete characterizations of the
complexity of bribery for all possible voter types, i.e., with and without weights and with
and without price tags. In particular, via dichotomy theorems (Theorems 4.8 and 4.9) and
algorithmic constructions (Theorems 4.13 and 4.15) we provide for each voter type a simple
condition that partitions all scoring protocols into ones with NP-complete bribery problems
and ones with P bribery problems. We point the reader to Tables 1 and 2 (they appear near
the end of this paper) for a summary of some of the complexity results regarding bribery
in elections.
The paper is organized as follows. In Section 2 we describe the election systems and
bribery problems we are interested in and we cover some complexity background and preliminaries. In Section 3, we provide a detailed study of plurality elections. After that
we study connections between manipulation and bribery, and obtain dichotomy results for
bribery under scoring protocols in Section 4. In Section 5, we study the case of succinctly
represented elections with a fixed number of candidates.

487

fiFaliszewski, Hemaspaandra, & Hemaspaandra

2. Preliminaries
This section introduces the notions and notations that we use in the paper.
2.1 Election Systems
We describe elections by providing a set C = {c1 , . . . , cm } of candidates, a set V of n voters
specified by their preferences, and a rule for selecting winners. A voter vs preferences are
represented as a list ci1 > ci2 > . . . > cim , {i1 , i2 , . . . , im } = {1, 2, . . . , m}, where ci1 is the
most preferred candidate and cim is the most despised one. We assume that preferences
are transitive, complete (for every two candidates each voter knows which one he or she
prefers), and strict (no ties). Sometimes authors also allow ties in the preference lists, but
ties do not have a clear interpretation for some election rules and so for simplicity and
uniformity we do not consider them.
Given a list of votes (i.e., of voters preference lists), an election rule determines which
candidates are winners of the elections. We now briefly describe the election systems that
we analyze in this paper, all of which are standard in the literature on social choice theory.1
Winners of plurality elections are the candidate(s) who are the top choice of the largest
number of voters (of course, these will be different voters for different winners). In approval
voting each voter selects candidates he approves of; the candidate(s) with the most approvals
win. Unlike all the other systems discussed in this paper, under approval voting the input
is not a preference order but rather is a bit-vector of approvals/disapprovals. A scoring
protocol for m candidates is described by a vector  = (1 , . . . , m ) of nonnegative integers
such that 1  2 . . .  m . (We do not require 1 > m , as we wish to classify the
broadest class of cases possible, including the usually easy boundary case when all i s
are equal.) Each time a candidate appears in the ith position of a voters preference list,
that candidate gets i points; the candidate(s) who receive the most points win. Wellknown examples of scoring protocols include the Borda count, plurality, k-approval, and
veto voting systems, where for m-candidate elections Borda uses  = (m  1, m  2, . . . ,
k

mk

z }| { z }| {
0), plurality uses  = (1, 0, . . . , 0, 0), k-approval uses  = (1, . . . , 1, 0, . . . , 0), and veto uses
 = (1, 1, . . . , 1, 0). Note that by selecting a scoring protocol we automatically select the
number of candidates we have within elections. Though some scoring protocols can easily
and naturally be generalized to arbitrary candidate sets, formally each individual scoring
protocol deals with only a fixed number of candidates. Thus all our results regarding scoring
protocols automatically talk about a fixed number of candidates.
A Condorcet winner is a candidate who (strictly) beats all other candidates in pairwise
contests, that is, a Condorcet winner beats everyone else in pairwise plurality elections.
Clearly, there can be at most one Condorcet winner, but sometimes there are none (as is
the case in the Condorcet Paradox, Condorcet, 1785). There are many voting systems that
1. In the social choice literature, often voting systems are assumed to have at least one winner, or exactly
one winner, but at least in terms of the basic definition of a voting system, we do not require such a
restriction, since one can imagine wanting to study elections in whichperhaps due to tie effects or
symmetry effects or perhaps even due to having zero candidatesthere is not always exactly one winner.
Indeed, in practice, in such elections as those on Hall of Fame induction worthiness or on who should be
hired at a given academic department, it is quite possible that a real-world election system might give
the answer No one this year.

488

fiHow Hard Is Bribery in Elections?

choose the Condorcet winner if one exists and use some compatible rule otherwise. One
such systemdeveloped in the 1800sis that of Charles Lutwidge Dodgson (a.k.a. Lewis
Carroll). In Dodgsons system a winner is the person(s) who can become a Condorcet
winner by the smallest number of switches in voters preference lists. (A switch changes the
order of two adjacent candidates on a list.2 ) Thus, if a Condorcet winner exists, he or she
is also the unique winner of Dodgsons election. See the work of Dodgson (1876)and also
the work of Bartholdi, Tovey, and Trick (1989b)for details regarding Dodgsons voting
rule, under which it is now known that winner testing is complete for parallel access to NP
(Hemaspaandra, Hemaspaandra, & Rothe, 1997). A different election rule was introduced
more recently by Young (1977). In Young elections a winner is a person who can become
a Condorcet winner by removing the smallest number of voters. By way of contrast, note
that plurality rule has the property that it elects those candidates who, after removing
the least number of votes, are preferred by everyone. The work of Rothe, Spakowski, and
Vogel (2003), see also the expository presentation of Rothe (2005), proves that the winner
problem in Young elections is extremely difficultcomplete for parallel access to NP.
Another election rule is that of Kemeny (1959), see also the work of Kemeny and Snell
(1960). A Kemeny consensus is a preference order that maximizes the number of agreements
with voters preference lists, where for each voter and for each two candidates a and b we
say that a preference order agrees with a voters preference list if both place a below b or
both place b below a. Naturally, many different Kemeny consensuses may be possible. A
candidate is a winner in a Kemeny election if he or she is the most preferred candidate
in some Kemeny consensus of that election. (The original work of Kemeny allowed voters
to have nonstrict preference orders, but like, e.g., Saari & Merlin, 2000, we use Kemeny
elections to refer to just the case where input orderings are strict.) Note that the winner
testing problem for Kemeny elections is known to be complete for parallel access to NP,
and this is known to hold both in the case when input preference orders must be strict, and
in the case when nonstrict input preference orders are allowed (Hemaspaandra, Spakowski,
& Vogel, 2005, and see in particular the comments in the footnote on page 383 of that
paper). The Kemeny rule might at first sound as if it were the same as the Dodgson rule,
but in fact they are very different. Dodgsons elections are based on making the minimum
number of local changes, but Kemenys elections hinge on the overall closeness of the voters
preference orders to certain consensus orderingswhich themselves possibly may not be
the preferences of any of the voters.
2.2 Bribery Problems
Informally, the bribery problem is the following: Given the description of an election (i.e.,
the set of candidates, the preferences of the voters, etc.), a number k, and some distinguished
candidate p, can we make p a winner by changing the preference lists of at most k voters.
More formally, for an election rule (i.e., election system) E we define the E-bribery problem
to be the following. We assume a standard encoding of mathematical objects such as finite
2. We mention, since this can be a source of confusion, that in his seminal paper Dodgson did not explicitly
state that switches were limited to adjacent candidates. However, the mathematics of his examples is
consistent with only that reading, and so it is clear that that is his intended meaning.

489

fiFaliszewski, Hemaspaandra, & Hemaspaandra

sets and lists (e.g., see Garey & Johnson, 1979). Also, all our numbers will be nonnegative
integers and, unless otherwise specified, will be represented in binary.
Name: E-bribery.
Given: A set C of candidates, a collection V of voters specified via their preference lists.
A distinguished candidate p  C and a nonnegative integer k.
Question: Is it possible to make p a winner of the E election by changing the preference
lists of at most k voters?
We will speak both of the unweighted case (all voters are equal; in this paper that always
holds unless weighted is in the problem name) and the weighted case (voters are weighted).
Essentially all our results apply both to the case in which we want to make the preferred
candidate a winner and to the case in which we want to make the preferred candidate
the unique winner, and so we have not explicitly put a nonunique/unique setting into the
problem names. For clarity and specificity, we focus on the nonunique case in our discussions
and proofs, and all our problem statements and theorems by default refer to the nonunique
case. However, in most settings the differences between the proofs for the unique case and
the nonunique case are very minor and amount to a couple of small tweaks, e.g., changing
weak inequalities to strong ones, adding a special voter who already prefers p, etc., and we
often at the end of a proof briefly note that the theorem also holds for the unique case.
In the E-$bribery family of problems we assume that each voter has a price for changing
his or her preference list. In such a case we ask not whether we can bribe at most k people,
but whether we can make p a winner by spending at most k dollars. For example, the
plurality-weighted-$bribery problem can be described as follows.
Name: plurality-weighted-$bribery.
Given: A set C of candidates. A collection V of voters specified via their preference
lists (prefs 1 , . . . , prefs m ), their (nonnegative, integer) weights (w1 , . . . , wm ), and their
(nonnegative, integer) prices (p1 , . . . , pm ). A distinguished candidate p  C and a
nonnegative integer k (which we will sometimes refer to as the budget).
P
Question: Is there a set B  {1, . . . , m} such that iB pi  k and there is a way to bribe
the voters from B in such a way that p becomes a winner?
Regarding the fact that in these models voters are assumed to vote as the bribes dictate,
we stress that by using the term bribery we do not intend to necessarily imply any moral
failure on the part of bribe recipients or bribe givers: Bribes are simply payments. Although in human, political elections, such payments are typically considered morally wrong
(perhaps because each voter is supposed to be thinking of the overall social welfare), in
electronic/web/multiagent systems settings, such morality issues often do not apply. A
voter may simply be an electronic entity trying to maximize its utility, and the bribe price
of that entity may crisply reflect that fact.
Throughout this paper we use the term bribery both in its regular sense and in the
nonstandard sense of a collection of bribes. We will when using the latter sense often
speak of a bribery, by which we thus mean a collection of bribes. So, for example, if
490

fiHow Hard Is Bribery in Elections?

Alice can end up a winner by a bribery that does not ask anyone to vote for Alice, we mean
if there is a pattern/scheme of bribes (e.g., give two dollars to Bob to make the change
FOO in his vote and give five dollars to Carol to make change BAR in her vote) none of
which asks anyone to vote for Alice yet that make Alice the overall winner.
As we will be dealing with a variety of settings, we need some common format to speak
of the instances of bribery problems. We adopt the following convention (and we view the
already specified problems to be implicitly recast into this form): An instance of a bribery
problem is a 4-tuple E = (C, V, p, k), where
1. C is a list of candidates,
2. V is a list of voters (see below),
3. p  C is the candidate that we want to make a winner (for problems about making a
candidate a unique winner, the a winner here is replaced with a unique winner),
and
4. k is the bribe limit (either the amount of money we can spend on bribing or the
maximum number of voters we can bribe, depending on the flavor of the bribery
problem).
The list of voters contains tuples describing the votes that are cast. Each voter is a 3-tuple
(prefs, , ), where
1. prefs is the preference list of the voter (or, in the case of approval voting, his or her
preference vector),
2.  is the price for changing this voters preference list, and
3.  is the weight of the voter.
Each tuple in V describes precisely one voter. We drop the price and/or the weight field
if in the given election the voters have no prices/weights. (However, we do assume that
dropped prices and weights have unit values, so that we can refer to them. Some of our
proofs handle two cases, one with priced voters and one with weighted voters, at the same
time and need to be able to uniformly refer to both weights and prices.) If v  V is a voter
then we refer to his or her price and weight as (v) and (v). In the same manner, if U  V
then
X
(U ) =
(v) and
vU

(U ) =

X

(v).

vU

We will often refer to (U ) either as the vote weight of U  or as the total weight of U .
Note that throughout this paper V , though input as a list, typically functions as a multiset, and so summations such as those above do have an additive term for each appropriate
occurrence in the multisetthe multiplicities carry into such sums, and also into set-like
491

fiFaliszewski, Hemaspaandra, & Hemaspaandra

operations, e.g., {v  V | . . .} will itself be a multiset, with multiplicities appropriately
preserved. And we when dealing with V use set/subset to mean multiset/submultiset.
In Section 5 we deal with succinct representations. When we are dealing with succinct
representations, V will consist of 4-tuples (prefs, , , m), where m is the multiplicity of the
vote, that is, a number of voters of identical preferences, price, and weight that this entry
in V is standing for. m(v) will denote the m value of a v  V . Note that here single entry
in V often represents multiple voters.
This notation will help us speak of bribery problems in a uniform fashion. Note that in
addition to specifying E = (C, V, p, k) we always need to explicitly state what election rule
we are using.
Positive results regarding more demanding bribery problems imply positive results about
weaker ones. For example, if weighted bribery is in P for some election system E then clearly
we have that unweighted bribery is also easy for E. Conversely, hardness results regarding
simpler models imply hardness results about the more involved ones. We often mention
such implied results separately if they are interesting (e.g., if an algorithm for a simpler
case provides insights for understanding the more complicated case), but we omit them if
they are not enlightening.
2.3 Reductions and NP-completeness
Before we proceed with the study of bribery, let us briefly review some notions of computational complexity and some standard NP-complete problems that we will use in our
proofs.
As usual, kSk denotes the cardinality of the set S. We fix our alphabet to be  = {0, 1}
and we assume standard encodings of mathematical entities involved in our problems. In
particular, all integers are represented in binary unless specified otherwise. (For example,
see Garey & Johnson, 1979, for a discussion of these issues.) By NP-completeness we as is
standard mean completeness with respect to many-one (polynomial-time) reductions.
Definition 2.1 A pm B (A many-one reduces to B) if there is a polynomial-time computable function f such that
(x   )[x  A  f (x)  B].
In one of our results relating manipulation and bribery we also need disjunctive truth-table
reductions.
Definition 2.2 We say that A pdtt B (A disjunctively truth-table reduces to B) if there is
a polynomial-time procedure that on input x outputs a list of strings y1 , . . . , ym such that
x  A if and only if at least one of yi , 1  i  m, is in B.
Both of the above definitions are standard and commonly used within the field of complexity theory. Detailed treatment of various reduction types including these can be found,
e.g., in the work of Ladner, Lynch, and Selman (1975).
A standard way of showing that a problem is NP-complete is by proving it is in NP and
reducing some known NP-complete problem to it. The former is easy for most of the bribery
problems that we deal with: If we can compute the winners of the elections in polynomial
time, then we can just nondeterministically guess a bribe and test whether it yields the
492

fiHow Hard Is Bribery in Elections?

desired outcome. For the latter issue we use reductions from either the partition problem
or the exact cover by 3-sets problem (e.g., see Garey & Johnson, 1979; Papadimitriou, 1994,
for general background on these problems and on proving NP-completeness).
The problem Partition asks whether it is possible to split a sequence of integers into two
subsequences that have equal sums.
Name: Partition.
P
Given: A sequence s1 , . . . , sn of nonnegative integers satisfying ni=1 si  0 (mod 2).3
P
P
Question: Is there a set A  {1, . . . , n} such that iA si = i{1,...,n}A si ?

To prove our main dichotomy result in Section 4 we need a more restrictive version
of
the
Pn partition problem. Let s1 , . . . , sn be a sequence of nonnegative integers such that
i=1 si  0 (mod 2). In Partition we assume that for each i, 1  i  n, it holds that
n

si 

1 X
si
2+n

(1)

i=1

P
(reminder: footnote 3 of courseP
applies regarding the handling of both ni=1 si  0 (mod 2)
n
1
and (i  {1, . . . , n})[si  2+n
i=1 si ]), and we ask whether there exists an A  {1, . . . , n}
P
P
n
1
such that
i=1 si . For the sake of completeness we include a proof that
iA si = 2
Partition remains NP-complete.
Lemma 2.3 Partition is NP-complete.

Proof. Clearly, Partition is in NP. We will show, by a reduction from the standard
partition problem, that Partition is also NP-hard.
P
Let q = s1 , . . . , sn be a sequence of nonnegative integers and let 2S = ni=1 si . First, we
construct a sequence q  = s1 , o1 , . . . , sn , on of 2n nonnegative integers that has the following
two properties. (1) q  can be partitioned if and only if q can be. (2) Each partition of q 
splits q  into two sequences of the same cardinality. We define si and oi , for 1  i  n, as
follows.
si = 3i1 + 3n si .
oi = 3i1 .
Any partition of s1 , o1 , . . . , sn , on splits q  into two subsequences that each sum up to S  ,
where S  is defined as
n
n
X
1X 
3n  1


n
S =
.
3i1 = 3n S +
(si + oi ) = 3 S +
2
2
i=1

i=1

Pn

3. If for a given input it holds that i=1 si 6 0 (mod 2), we consider the input to be syntactically illegal
and thus consider that input not to be a member of Partition. For the rest of this paper we assume, when
reducing from Partition to some other problem (Q), that if some syntactic constraint is violated by
the input, then our reduction will not do whatever the reduction we give states, but rather will instantly
map to a fixed element of Q. We (often tacitly) make the same assumptionthat syntactically (by
which we mean both true conditions of syntax and other polynomial-time constraints on a problem via
the Given assumes apply to its inputs) illegal inputs are not handled via the reductions operation on
the inputs components, but rather are mapped to a fixed element of the complement of the set being
reduced to.

493

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Clearly, any partition of s1 , o1 , . . . , sn , on splits q  into two halves such that if si belongs to
one then oi belongs to the other. It is also immediate that q can be partitioned if and only
if q  can.
To satisfy condition (1) we add a constant to each si and oi . Define qb to be a sequence
of numbers sb1 , ob1 , . . . , sbn , obn such that for each i, 1  i  n,
sbi = si + S  and

obi = oi + S  .

Clearly, any partition of q  still is a partition of qb, since any partition of q  splits q  into
two subsequences of the same cardinality. The converse holds because any partition of qb
has to split it into subsequences that each sum up to Sb = S  + nS  and this is only possible
if each subsequence contains exactly n elements. (A sum of more than n elements would
be greater than (n + 1)S  and that would be more than the other subsequence could sum
up to.) It remains to show that (1) holds for qb. This is the case because each sbi and obi is
2 b
S. (Note that sequence qb has 2n elements.) Since qb can be
greater than S  and S  = 2+2n
computed in polynomial time, the proof is completed.

The exact cover by 3-sets problem (X3C) asks about a way to pick, from a given list,
three-element subsets of some set B so as to cover the whole set without ever introducing
the same element more than once.
Name: X3C.
Given: A set B = {b1 , . . . , b3t } and a family of three-element subsets of B, S =
{S1 , . . . , Sm }.
S
Question: Is there a set A  {1, . . . , m} such that kAk = t and iA Si = B?

These two problemsPartition and X3Chave been useful tools for proving NPcompleteness of control and manipulation problems, and in this paper we will see that
they are very powerful when used for bribery problems. Specifically, Partition will be very
useful when we are dealing with weighted elections and X3C will be particularly useful in
the unweighted cases.

3. Plurality
In this section we determine the complexity of bribery for plurality-rule elections. Plurality
rule is perhaps the most popular election system in practical use; from the point of view
of democracy it is very natural and appealing to make a decision that many people prefer.
However, there are also downsides to plurality rule. Plurality rule may slight the voices
of minorities and does not take into account full information about voters preferences.
In particular, if there is some candidate that all voters rank as second best and no other
candidate is the top choice of many rankings, it might seem natural to elect this second
best person. However, plurality is blind to this. In fact, we will typically view a vote
in plurality-rule elections as a vote for a particular candidate, namely, the most preferred
candidate according to the preference order that is the actual vote; for the purposes of
this paper that is the only thing that matters about the voter, though we mention that in
494

fiHow Hard Is Bribery in Elections?

other contexts, such as control problems allowing deletion of candidates (Bartholdi et al.,
1992; Hemaspaandra et al., 2007; Hemaspaandra, Hemaspaandra, & Rothe, 2009), the full
ordering might be important. The simplicity and widespread use of plurality-rule elections
make the results of this section of particular relevance.
We in the previous section somewhat carelessly mentioned plurality as a scoring rule
with the vector  = (1, 0, . . . , 0). Of course, formally speaking, what really holds is that
for each number of candidates k there is a notion of a plurality-of-k-candidates scoring-rule
election, which has the vector that is a 1 followed by k  1 0s. But one can also consider the
system that takes as input any number of candidates and then applies the plurality scoring
rule (for that inputs number of candidates). This is what most people think of when
speaking of plurality elections, and throughout this section, our results about plurality
are of course about not just fixed numbers of candidates, but are about this case.
The simplest bribery scenario is when the voters are unweighted and each voter is as
expensive to bribe as each other voter. Not surprisingly, bribery is easy in such a setting.
Theorem 3.1 plurality-bribery is in P.
Proof.
The proof of this theorem is simple, but we describe it in detail as a simple
introduction to our proofs regarding bribery. We will give a polynomial-time algorithm
that given an instance of bribery E = (C, V, p, k) decides whether it is possible to make p a
winner by bribing at most k voters.
Our algorithm works in the following way. Initially we have bribed zero voters. We
check whether p currently is a winner. If so, we accept. Otherwise, until doing so will
exceed the bribe limit, we pick any current winner, bribe one of his or her voters (recall, as
mentioned earlier in this section, that by his or her [i.e., the selected winners] voters we
mean those voters having that particular selected winner as their most preferred candidate)
to vote for p, and jump back to testing whether p is a winner. If we reach the bribe limit
(i.e., in the above we have the until doing so will exceed the bribe limit break us out of
the loop) without making p a winner then we reject.
If this algorithm accepts then obviously bribery is possible. We now show that if it
is possible to ensure that p is a winner via at most k bribes then our algorithm accepts.
Our proof follows by induction on k. For the base case it is enough to note that the
algorithm works correctly for k = 0. For the induction step, let us assume that on each
input E  = (C  , V  , p, k  ) such that k  < k, where k is some positive integer, the algorithm
accepts exactly if it is possible to ensure that p is a winner via at most k  bribes. Now, let
E = (C, V, p, k) be an arbitrary input such that p can become a winner via at most k bribes.
We will show that our algorithm accepts this input. We consider two cases. If there is a
bribery of up to k voters that ensures ps victory but that never involves any of the voters of
any of the current winners of election (C, V ) then it is clear that our algorithm accepts. (Let
Vp  V be the set of all voters who do not vote for p. In this case any bribery of min(k, ||Vp ||)
voters ensures that p becomes a winner.) Thus, let us assume that the only briberies that
make p a winner involve bribing at least one voter of one of the current winners. Let c1
be one of the winners of (C, V ) (note that c1 6= p) and let E  = (C, V  , p, k  1) be an
instance of plurality-bribery obtained from E by bribing one of c1 s voters. Clearly, after
executing a single iteration of the loop, our algorithm transforms its input into one that

495

fiFaliszewski, Hemaspaandra, & Hemaspaandra

is isomorphic to E  . By our assumptions and by the inductive hypothesis the algorithm
accepts its transformed input.
The algorithm works in polynomial time as at most kV k bribes suffice to make p a
winner and each of the iterations can be executed in polynomial time. The theorem is
proven. We mention that the same approach clearly also works for the unique case. 
The ease of obtaining the above algorithm might fool us into thinking that bribery
within the plurality system is always easy. However, that is not the case.
Theorem 3.2 plurality-weighted-$bribery is NP-complete, even for just two candidates.
Proof. Recall that the nonunique version of the problem is our default case, and so we
are addressing that here.
plurality-weighted-$bribery is in NP: We can guess the voters to bribe and test whether
such a bribe both makes our designated candidate a winner and does not exceed the budget.
It remains to show that the problem is NP-hard.
To show NP-hardness, we will construct
Pa reduction from Partition. Let s1 , . . . , sn be
a sequence of nonnegative integers and let ni=1 si = 2S. Our goal is to design an election
E = (C, V, p, k) in which p can become a P
winner by bribery of cost at most k if and only
if there is a set A  {1, . . . , n} such that iA si = S. We define the election to have two
candidates, p and c, and exactly n voters, v1 , . . . , vn , with each vi having both weight and
price equal to si . All voters prefer c to p. The budget k is set to S. We claim that p can
become a winner if and only s1 , . . . , sn can be partitioned into two
P equal-sum groups.
Let us assume that there is a set A  {1, . . . , n} such that iA si = S. This means
that for each i  A we can bribe vi to vote for p and get for p a total vote weight (in the
natural sense, as was defined in Section 2) of S. This makes p a winner. On the other hand,
assume that p can be made a winner by bribes of total cost at most k = S. The weight of
each voter is equal to his or her price and so p can obtain at most vote weight k = S. In
fact, p must obtain exactly vote weight S, since from our setup it is clear that if p gains
strictly less than vote weight S then c will be the unique winner. This means that there
is a way of picking some voters whose weights sum up to exactly S, and thus the sequence
s1 , . . . , sn can be partitioned into two subsequences that each sum up to S.
Our reduction can be carried out in polynomial time and so the proof is complete. This
of course regards our default case, namely the nonunique case. The unique case also follows,
namely, by observing that it is enough to add one voter with weight 1 and price 0 who votes
for p. Then the same arguments as above show that this is a correct reduction.

The above theorems show that bribery is easy in the basic case but becomes intractable
if we allow voters with prices and weights. It is natural to ask which of the additional
features (prices? weights?) is responsible for making the problem difficult. It turns out that
neither of them is the sole reason and that only their combination yields enough power to
make the problem NP-complete.4
Theorem 3.3 Both plurality-$bribery and plurality-weighted-bribery are in P.
4. However, it is interesting to compare this to Theorems 4.8, 4.9, 4.13, and 4.15, which suggest that high
weights are often the feature responsible for making the problem NP-complete.

496

fiHow Hard Is Bribery in Elections?

Theorem 3.3 is a special case of a result that we prove later (namely, of Theorem 3.8) and
thus, instead of giving the proof, we provide a very informal discussion of polynomial-time
algorithms for both plurality-$bribery and plurality-weighted-bribery.
A direct greedy algorithm, like the one underpinning Theorem 3.1, fails to prove
Theorem 3.3: The problem is that one has to judge whether it is better to bribe voters
who currently prefer one of the winners or to bribe voters with the highest weights (or
lowest prices). (To see that the former may sometime make sense, consider an election in
which a has two weight-4 voters, b has one weight-5 voter, and p has one weight-2 voter.
Bribing one weight-4 voter is a winning bribery but bribing the one weight-5 voter is not.)
We approach Theorem 3.3s proof as follows. Assume that p will have r votes after the
bribery (or in the weighted case, vote weight r), where r is some number to be specified
later. If this is to make p a winner, we need to make sure that everyone else gets at most r
votes. Thus we carefully choose enough cheapest (heaviest) voters of candidates that defeat
p so that after bribing them to vote for p each candidate other than p has at most r votes.
Then we simply have to make sure that p gets at least r votes by bribing the cheapest (the
heaviest) of the remaining voters. If during this process p ever becomes a winner without
exceeding the budget (the bribe limit) then we know that bribery is possible.
How do we pick the value of r? In the case of plurality-$bribery, we can simply run
the above procedure for all possible values of r, i.e., 0  r  kV k, and accept exactly if it
succeeds for at least one of them. For plurality-weighted-bribery a slightly trickier approach
works. Namely, it is enough to try all values r that can be obtained as a vote weight of
some candidate (other than p) via bribing some number of his or her heaviest voters. There
are only polynomially many such values and so the whole algorithm works in polynomial
time. The intuition for using such values r is the following: (a) When bribing voters of some
candidate one can always limit oneself to the heaviest ones, and (b) after each successful
bribery there is a value r such that ps vote weight is at least r , each other candidates
vote weight is at most r , and there is some candidate c 6= p such that cs vote weight is
exactly r . Our algorithm, in essence, performs an exhaustive search (within our heavily
limited search space) for such a value r .
Note that all of the above algorithms assume that we bribe people to vote for p. This
is a reasonable method of bribing if one wants p to become a winner, but it also has
potential real-world downsides: The more people we bribe, the more likely it may be that
the malicious attempts will be detected and will work against p. To minimize the chances
of that happening we might instead bribe voters to vote not for p but for some other
candidate(s). This way p does not get extra votes but might be able to take away enough
from the most popular candidates to become a winner.
Definition 3.4 plurality-weighted-negative-bribery is defined to be the same as pluralityweighted-bribery, except with the restriction that it is illegal to bribe people to vote for the
designated candidate.
The problem plurality-negative-$bribery is defined analogously. We call this setting
negative-bribery because the motivation of p is not to get votes for him- or herself, but to
take them away from others. Unlike Theorem 3.3, this version of the problem draws a very
sharp line between the complexity of bribing weighted and priced voters.

497

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Theorem 3.5 plurality-weighted-negative-bribery is NP-complete, but plurality-negative$bribery is in P.
Proof. We first give a polynomial-time algorithm for plurality-negative-$bribery. Let
E = (C, V, p, k) be the bribery instance we want to solve. We need to make p a winner by
taking votes away from popular candidates and distributing them among the less popular
ones. (The previous sentence said a winner since we as usual are addressing the nonunique
case. However, it is clear that a similar approach works for the unique case, i.e., the case
in which the goal is to make p the winner.)
We partition the set of all candidates into three sets: candidates that defeat p, from
whom votes need to be taken away, candidates that are defeated by p, to whom we can
give extra votes, and candidates that have the same score as p. In the unweighted case,
by score E (c) we mean the number of voters within E who most prefer candidate c. In the
weighted case, score E (c) means the total vote weight of voters within E who most prefer c.
Cabove = {c | c  C, score E (c) > score E (p)}.
Cbelow = {c | c  C, score E (c) < score E (p)}.
Cequal = {c | c  C, score E (c) = score E (p)}.
Since all voters have the same weight (weight 1) in the current case, plurality-negative$bribery, it is not hard to see that if there is some successful negative bribery then there
will be some successful negative bribery that will bribe no voters into or out of Cequal and
that also wont bribe voters to move within their own group, e.g., bribing a voter to shift
from one Cbelow candidate to another. (However, for the weights case, such crazy bribes
are sometimes needed; see footnote 5.) To make sure that p becomes a winner, for each
candidate c  Cabove we need to bribe as many of cs voters as are needed
to reduce his or
P
her score to at most score E (p). Thus, altogether, we need to bribe cCabove (score E (c) 
score E (p)) voters. The number
P of votes that a candidate c  Cbelow can accept without
preventing p from winning is cCbelow (score E (p)  score E (c)). Thus, it is not hard to see
that a negative bribery is possible exactly if the following inequality holds.
X
X
(score E (c)  score E (p)) 
(score E (p)  score E (c)).
(2)
cCabove

cCbelow

If inequality (2) does not hold then we immediately reject. Otherwise, it remains to check
whether the cost of our negative bribery is within the budget: For every candidate c  Cabove
let
P bc be the cost of bribing cs score E (c)  score E (p) cheapest voters. If it holds that
cCabove bc  k then we accept, as the negative bribery is possible. Otherwise we reject.
Clearly, our algorithm works in polynomial time. The correctness follows from the fact
that we need to make all candidates in Cabove have score at most score E (p) and for each
c  Cabove bc is the lowest possible cost of achieving that. Equation (2) guarantees that the
votes taken from candidates in Cabove can be distributed among those in Cbelow without
preventing p from winning.
Now let us turn to showing the NP-hardness of plurality-weighted-negative-bribery. We
must be careful here. In plurality-negative-$bribery, we argued that one could without
loss of generality ignore Cequal , i.e., one never needs to bribe voters into or out of Cequal ,
and that we can ignore bribing voters from one candidate in a group (Cbelow , Cequal , and
498

fiHow Hard Is Bribery in Elections?

Cabove are our three groups) to another candidate within the same group. It is not too
hard to see that that claim is false for the weights case, essentially due to the fact that,
for example, members of Cequal or Cbelow can be useful in making changethat is, for
splitting large weights into small ones.5 However, in the image of the reduction we are
about to construct, Cequal will contain only p, bribing votes to change to p is forbidden by
our negative setting, and bribing votes to change away from p clearly is never required
for success; so we have a setting in which Cequal in fact will not play any interesting role.
And similarly, kCabove k = kCbelow k = 1 in the image of our reduction, so we will not have
to worry about any within-a-group bribes.
Now, we start our construction to show the NP-hardness of plurality-weighted-negativebribery. In particular, we will construct a reduction from Partition. Let s1 , . . . , sn
be a sequence of nonnegative integers. We will design an instance of the pluralityweighted-negative-bribery such that bribery is possible if and only if s1P
, . . . , sn can be split
into two parts that sum up to the same value. Let S be such that ni=1 si = 2S. Our
elections has three candidates: p, c1 , and c2 , and we have n + 1 weighted voters:
1. v0 with weight S, whose preferences are p > c1 > c2 , and
2. v1 , . . . , vn with weights s1 , . . . , sn , each with preferences c1 > c2 > p.
The goal of the briber is to ensure ps victory via bribing up to k = n + 1 voters (i.e., up to
all the voters). Note that the only reasonable bribes are the ones that transfer votes of vi ,
1  i  n, from c1 to c2 . (Strictly speaking, v0 could legally be bribed to vote for c1 or c2 ,
but that can be safely ignored.) If there is a set A  {1, . . . , n} such that
X
si = S,
(3)
iA

then we could bribe all voters vi , i  A, to vote for c2 and all candidates would be winners.
On the other hand, if p can end up a winner by a bribery that does not ask anyone to vote
for p, then there is a set A that satisfies Equation (3): p is a winner of our election if and
only if each of c1 and c2 have vote weight exactly S. However, at the beginning c1 holds 2S
vote weight and so a successful bribery needs to transfer exactly S vote weight from c1 to
c2 . This is only possible if (3) holds for some A.
To finish the proof, we observe that this reduction can be computed in polynomial
time.

Theorems 3.2 and 3.3 state that plurality-weighted-$bribery is NP-complete but any
attempt to make it simpler immediately pushes it back to the realm of P. In fact, the
5. To see this, consider a setting where candidate Big is the most preferred candidate of one weight-10 voter
and one weight-2 voter, candidate p is the most preferred candidate of one weight-10 voter, candidate
MakeChange is the most preferred candidate of ten weight-1 voters, candidate SmallOne is the most
preferred candidate of one weight-9 voter, candidate SmallTwo is the most preferred candidate of one
weight-9 voter, and the limit on the number of bribes is 3. Cabove = {Big}, Cequal = {p, MakeChange},
and Cbelow = {SmallOne, SmallTwo}. Note that there is no successful negative bribery that leaves
MakeChange uninvolved. However, by moving from Big to MakeChange the weight-2 voter, and then by
moving one weight-1 voter to each of SmallOne and SmallTwo from MakeChange, we have a successful
negative bribery. This example uses Cequal to make change, but one can construct similar examples that
require one to bribe votes from one member of Cbelow to another member of Cbelow .

499

fiFaliszewski, Hemaspaandra, & Hemaspaandra

situation is even more dramatic. In the NP-complete problem plurality-weighted-$bribery
we assume that both prices and weights are encoded in binary. However, if either the prices
or the weights are encoded in unary, then the problem, again, becomes easy. Before we
proceed with a formal proof of this fact, let us discuss the issue in an informal manner.
Why does the unary encoding of either one of the weights or the prices matter? The reason
is that, for example, if the weights are encoded in unary then there trivially are only linearly
many (with respect to the size of the input problem) different total weights of subsets of
voters. Together with some additional tricks this allows us to use dynamic programming to
obtain a solution.
Definition 3.6 plurality-weighted-$briberyunary is defined exactly as is pluralityweighted-$bribery, except the prices are to be encoded in unary. plurality-weightedunary $bribery is plurality-weighted-$bribery except with the weights encoded in unary.
It is tempting to use exactly the same proof approach as the one that we hinted at in
the discussion below Theorem 3.3, i.e., to split the bribery into two parts: demoting others
and promoting p. However, doing so would not be correct. Sometimes the optimal way of
getting the scores of other candidates to be at most at a certain threshold r prevents one
from getting an optimal bribe for the complete problem. Consider an elections with three
candidates, c, d, and p, and three voters v1 , v2 , and v3 such that v1 has both price and weight
equal to 10, v2 has both price and weight equal to 7, and v3 has price 1, 000, 000 and weight
10. Both v1 and v2 prefer c and v3 prefers d. Clearly, an optimal bribe for the problem
requires a threshold of 10. The optimal way of getting c down to vote weight at most 10 is
by bribing v2 . However, at that point making p a winner requires bribing v1 as well. Yet,
bribing just v1 is a cheaper way of making p a winner and getting c below-or-equal-to the
10 threshold.
We will refer to plurality-weighted-$briberyunary as the unary prices case, and to
plurality-weightedunary -$bribery as the unary weights case. We will now give an overview
of how the algorithm works in the unary prices case, on input E = (C, V, p, k). The unary
weights case can be handled analogously. The main idea is that, using the fact that there are
only linearly many possible prices to be paid, we can argue that there exists a polynomialtime computable function Heaviest(E, C  , , r)where C  will be a subset of the candidates,
 will be an integer price, and r will be an integer thresholdthat gives the maximum vote
weight that we can obtain by bribing voters of candidates in C  such that
1. the cost of this bribery is at most ,
2. after the bribery every candidate in C  has vote weight at most r.
To test whether it is possible to make p a winner by spending at most k dollars, we
need to find a threshold r such that score E (p) + Heaviest(E, C  {p}, k, r)  r, i.e., so
that the weight p has originally or via bribed voters is at least as great as the post-bribery
weight of each of the other candidates. Unfortunately, in the case of plurality-weighted$briberyunary we cannot just try all thresholds since there may be exponentially many
of them. Instead we use a strategy similar to the one that we hinted at when discussing
Theorem 3.3. After every successful bribery (in elections with at least two candidates)
there is some candidate c 6= pnamely, the candidate(s) other than p with the greatest
500

fiHow Hard Is Bribery in Elections?

post-bribery total weightthat either is a tied-with-p winner or loses only to p. We can
use the after-bribery vote weight of this candidate to be the threshold for the bribery of
the voters of all the other candidates. Of course, we neither know who this candidate is nor
what vote weight he or she would have after a successful bribery. Nonetheless, we can try
all candidates c 6= p and for each such candidate and each possible sub-budget b  k can
ask what is the maximum amount of additional weight we can get for p from bribing cs
voters when allowed to spend at most b to do so (this will require solving certain instances
of the knapsack problem). Then, using the thus obtained threshold, we can bribe the voters
of the rest of the candidates. There are (at most) linearly many candidates and (at most)
linearly many prices so this yields (at most) polynomially many combinations.
Let us now describe how the above plan can be implemented. We no longer limit
ourselves to the unary prices case, but describe both cases in parallel. Let E = (C, V, p, k)
be our input. For each candidate c  C we define
VEc = {v  V | c is the most preferred candidate of v}.
Since we do not have any additional restrictions it only makes sense to bribe voters to
support p. For a given candidate c  C, we can describe our bribing options either as a
function that gives the highest weight of cs voters we can bribe for b dollars or as a function
that gives the lowest price needed to gain vote weight at least w by bribing cs voters.
heaviest(E, c, b) = max{(U ) | U  VEc and (U )  b}.
cheapest(E, c, w) = min{(U ) | U  VEc and (U )  w}.
If c is not a candidate in E, these functions are undefined. Here and in the rest of the
proof, we take the max and min of the empty set to be undefined. Note that if c is a
candidate in E, then heaviest(E, c, b) is defined for all b  0 and cheapest(E, c, w) is defined
for all w  (VEc ). Also note that heaviest can easily be computed in polynomial time
in the unary prices case and that cheapest can easily be computed in polynomial time in
the unary weights case. In both cases we simply use dynamic programming solutions for
an appropriate optimization variant of the knapsack problem.6 We can further generalize
these functions to give us information about the best bribes regarding sets of candidates.
For each U  V , we define bribed (E, U ) to be the bribery problem exactly like E but with
the voters in U bribed to vote for p. We define
fi


S
c
fi (U 
cC  VE )  ((U )  b)
, and
Heaviest(E, C  , b, r) = max (U ) fifi
(c  C  )[score bribed(E,U ) (c)  r]
fi


S
c
fi (U 
 VE )  ((U )  w)

cC
.
Cheapest(E, C , w, r) = min (U ) fifi
(c  C  )[score bribed(E,U ) (c)  r]
If C  is not a subset of Es candidate set, these functions are undefined.

6. The knapsack problem is the following. Given a set of items, each with a price  and a weight , is it
possible to select items with total weight at least W , but without exceeding total price K? It is well
known that the knapsack problem has a polynomial-time dynamic programming algorithm if either the
prices are encoded in unary or the weights are encoded in unary. (See the work of Martello & Toth,
1990, for background/reference on the knapsack problem.)

501

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Lemma 3.7 We consider now only elections in which each voter has both a price and a
weight. If prices are encoded in unary then there is an algorithm that computes Heaviest in
polynomial time. If weights are encoded in unary then there is an algorithm that computes
Cheapest in polynomial time.
Proof. Note that in the unary prices case there are only linearly many sub-budgets b for
which we need to compute the value of Heaviest, namely 0  b  (V ), and in the unary
weights case there are only linearly many weights w for which we need to evaluate Cheapest,
namely 0  w  (V ). Using this fact we provide dynamic programming algorithms for
computing both functions. For the base case we have the following: If c is not a candidate
of E, then both our functions are undefined. Otherwise,

heaviest(E, c, b) if score E (c)  heaviest(E, c, b)  r,
Heaviest(E, {c}, b, r) =
undefined
otherwise.

cheapest(E, c, w)
if score E (c)  w  r,
Cheapest(E, {c}, w, r) =
cheapest(E, c, score E (c)  r) otherwise.
The following observation allows us to compute Cheapest and Heaviest for larger sets.
We assume that C  does not contain c. If any of the candidates in C  {c} are not candidates
of E, then both our functions are undefined. Otherwise,
Heaviest(E, C   {c}, b, r) = max{Heaviest(E, C  , b , r) + Heaviest(E, {c}, b  b , r) |
0  b  b and Heaviest(E, C  , b , r) and Heaviest(E, {c}, b  b , r) are both defined}.
Cheapest(E, C   {c}, w, r) = min{Cheapest(E, C  , w , r) + Cheapest(E, {c}, w  w , r) |
0  w  w and Cheapest(E, C  , w , r) and Cheapest(E, {c}, w  w , r) are both defined}.
Thus, in the unary prices case we can compute Heaviest(E, C  , b, r) using dynamic programming in polynomial time. The same applies to Cheapest(E, C  , w, r) for the unary
weights case.

Theorem 3.8 Both
$bribery are in P.

plurality-weighted-$briberyunary

and

plurality-weightedunary -

Proof. Algorithms for both of the problems are very similar and we will describe only the
(nonunique) unary prices case in detail. We provide the pseudocode for the (nonunique)
unary weights case, but we omit its proof of correctness, which is analogous to the proof
for the unary prices case. We mention in passing that the two unique cases can easily be
obtained as well, via the natural modifications of our algorithm.
Figure 1 shows our procedure for the unary prices case. The idea of the algorithm is
the following: Suppose that there is a set B of voters such that if we bribe all members
of B to vote for p then p becomes a winner. We can assume that for each candidate c,
cs voters have been bribed optimally, i.e., there is no cheaper way of getting the same (or
greater) vote weight by bribing a different subset of cs voters. There is some candidate
c that has the most votes among the non-p candidates after bribery. Thus, to decide if
bribery is possible it is enough to test whether there is a candidate c 6= p and a sub-budget
b, 0  b  k, such that after bribing cs voters optimally, spending b dollars, it is still
possible to bribe (without, overall, exceeding the budget) voters of the other candidates in
such a way that
502

fiHow Hard Is Bribery in Elections?

procedure UnaryPricesBribery(E = (C, V, p, k))
begin
C  = C  {p};
if k  (V ) then
return(accept);
for c  C  do
for b such that 0  b  k do
begin
w = heaviest(E, c, b);
r = score E (c)  w ;
w = Heaviest(E, C   {c}, k  b, r);
if w is defined and score E (p) + w + w  r then
return(accept);
end
return(reject);
end
Figure 1: The main procedure for plurality-weighted-$briberyunary .
1. each candidate ends up with vote weight not higher than that of c, and
2. enough voters can be bribed so that p becomes a winner.
Our algorithm tests exactly if this is the case and accepts if so. (Though its if-then line
might at first seem to focus just on having the candidates in C  {c} beat p, note that cs
post-bribery score is r, so that line handles c also.) By the above reasoning, if bribery is
possible the algorithm accepts. It should also be clear that if the algorithm accepts then
bribery is indeed possible. Since the functions heaviest and Heaviest can be computed
in polynomial time, we have that the whole algorithm runs in polynomial time. Thus,
plurality-weighted-$briberyunary is in P.
An analogous algorithm works for the unary weights case, see Figure 2. The proof of
correctness is analogous to the unary prices case.

Theorem 3.8 is particularly interesting because it says that plurality-weighted-$bribery
will be difficult only if we choose both weights and bribe prices to be high. However, the
prices are set by the voters, and in many cases one could assume that they would set them
to be fairly low, in some sense rendering the bribery problem easy.
Another possible attack on the complexity of plurality-weighted-$bribery is through
approximation algorithms. In fact, using Theorem 3.8, Faliszewski (2008) obtained a fullypolynomial approximation scheme for plurality-weighted-$bribery. Many researchers ask
about typical-case complexity of practically encountered NP-complete problems (see the
work of Conitzer & Sandholm, 2006; Procaccia & Rosenschein, 2007; Erdelyi, Hemaspaandra, Rothe, & Spakowski, 2007, for discussions of this issue in the context of voting problems;
see also Erdelyi, Hemaspaandra, Rothe, & Spakowski, to appear; Erdelyi, Hemaspaandra,

503

fiFaliszewski, Hemaspaandra, & Hemaspaandra

procedure UnaryWeightsBribery(E = (C, V, p, k))
begin
C  = C  {p};
for c  C  do
for w such that 0  w  (VEc ) do
begin
b = cheapest(E, c, w );
r = score E (c)  w ;
b = Cheapest(E, C   {c}, r  (score E (p) + w ), r);
if b is defined and b + b  k then
return(accept);
end
return(reject);
end
Figure 2: The main procedure for plurality-weightedunary -$bribery.
Rothe, & Spakowski, 2009), and this is clearly an important direction.7 However, it is often
difficult to come up with a distribution of inputs that is both realistic and simple enough
to study. On the other hand, providing a good polynomial-time approximation algorithm
would be a worst-case result: No matter how difficult an instance we would be given, we
could compute a decent answer. Recent papers by Brelsford et al. (2008), Faliszewski (2008),
and Zuckerman et al. (2008) take steps in this interesting direction.
7. There has been much excitement over the recent paper Elections Can Be Manipulated Often (Friedgut,
Kalai, & Nisan, 2008, see also Dobzinski & Procaccia, 2008; Xia & Conitzer, 2008), and indeed a referee
commented to us that that paper proves that (under certain assumptions) elections are manipulable
most of the time. However, one in fact has to be a bit careful as to what one claims. The lower
bound that paper (given its assumptions) establishes for frequency of manipulation is, for a type of
problem that is related to unpriced bribery (but involves choosing a single manipulator after drawing
the votes from ones distribution), (1/kV k), and for the more typical approach to manipulation of
focusing on a single voter, that itself gives a lower bound on frequency of manipulation of (1/kV k2 ).
That isnt most, of the time, but rather goes to zero asymptotically. Even if that lower bound could be
tremendously raised to (1), that still might mean a manipulation frequency of 0.00001 percent of the
timenot a frequency that in itself means election methods are very frequently open to manipulation.
This is an exciting, active research direction in which we suspect that future work will much clarify
the upper and lower bounds that hold on frequency of manipulation (both in the single-manipulator
case and the coalition manipulation case), and what assumptions about election systems are needed to
obtain such results. Changing topics, we mention that in some cases most of the time detours around
NP-hardness election-complexity results have already been obtained. For example, although the winner
problem in Dodgson elections is known to be complete for parallel access to NP, two recent papers, by
McCabe-Dansted, Pritchard, and Slinko (2008) and by Homan and Hemaspaandra (2009), have shown
that (under particular assumptions about distributions and the relationship between the numbers of
candidates and voters) there are heuristic algorithms that in a rigorous sense are correct most of the
time.

504

fiHow Hard Is Bribery in Elections?

4. Bribery Versus Manipulation, and Two Dichotomy Theorems
The previous section provided a detailed discussion of the complexity of bribery for plurality
voting. To obtain its results we carefully hand-crafted and altered various algorithms and
reductions. Designing algorithms and reductions for specific bribery problems is certainly
a reasonable approach, but even better would be to find more general tools for establishing
the complexity of bribery in elections. Such general tools would be especially interesting
if they allowed one to inherit results already existent in the literature on election systems.
In this section we implement the above plan by studying relationships between bribery and
manipulation, and by showing how to obtain results using the relationships we find. In the
next section, by studying some ways in which integer programming can be employed to solve
bribery problems we continue this emphasis on exploring flexible tools for establishing the
complexity of bribery. There, using a theorem of Lenstra we show many bribery problems
regarding elections with fixed-size candidate sets to be in P, even when the voters are
succinctly represented. (Regarding the coming results studying the relationship between
bribery and manipulation, we more generally commend to the reader the issue of finding
even more extensive links between such problems as bribery, manipulation, and control. We
find this a natural and important direction.)
Manipulation is in flavor somewhat similar to bribery, with the difference that in manipulation the set of voters who may change their preference lists is specified by the input.
Formally, if E is some election rule then E-manipulation is the following problem (e.g., see
Bartholdi et al., 1989a; Conitzer et al., 2007).
Name: E-manipulation.
Given: A set C of candidates, a collection V of voters specified via preference lists, a set S
of manipulative voters (without loss of generality, not including any members of V ),
and a candidate p  C.
Question: Is there a way to set the preference lists of the voters in S so that under election
rule E the voters in S  V together choose p as a winner?
Instances of the manipulation problems can be described as tuples (C, V, S, p), where C
is a list of candidates, V is a list of voters (in the same format as in the bribery problems),
S is a list of the manipulative voters, and p is the designated candidate that voters in S
want to be a winner (a unique winner, in the unique case).
Manipulation, just like bribery, comes in many flavors. We may be asked to make p
the unique winner or just a winner, voters may have weights (in which case S is specified
together with weights of voters in S), etc. Bribery can be viewed as manipulation where
the set of manipulators is not fixed in advance and where deciding who to manipulate is a
part of the challenge. Note that to check whether bribery can be successful on a given input
we can simply try all possible manipulations by k voters, where k is the number of bribes
we are willing to allow. In this way, for a fixed k, we can disjunctively truth-table reduce
any bribery problem to the analogous manipulation problem. (Note that having no prices
but a limit of bribing k voters is the same in effect as having unit prices and a budget of k.)
Theorem 4.1 Let k be an arbitrary positive integer. Let B be any of our bribery problems,
but with the following constraints: Voters have no prices (i.e., we do not consider $bribery
505

fiFaliszewski, Hemaspaandra, & Hemaspaandra

problems) and bribing more than k voters is forbidden (that is, we require that in each
yes-instance (C, V, p, k  ) of B we have k   k). Let M be the analogous manipulation
problem, i.e., the manipulation problem for the same election system, with weighted voters
if B allows that, allowing the manipulating set to contain any number of voters between 0
and k. Then it holds that B pdtt M.
Proof. To show that B pdtt M we need to give a polynomial-time procedure that for an
input x outputs a list of strings y1 , . . . , ym such that x  B if and only if at least one of yi ,
1  i  m, is in M. We now describe such a procedure.
Let x be the input string. We first check whether x can be parsed as an instance
of B (reminder: that is, that x meets the syntactic constraints of B). If not then we
output an empty list and terminate; otherwise we decode V , the voter set, and k   k, the
maximum number of voters that can be bribed, from the string x. For every subset W of
k  = min(k  , kV k) elements of V we form an instance of the manipulation problem with
voter set V  W and manipulating set equal to W . After we go through all k  -element
subsets we output the list of all the manipulation instances that we formed. 
This procedure clearly works in polynomial time as there are at most kVk k = O(kV kk )
sets to test and we can form instances of manipulation in polynomial time. If any of the
manipulation instances we output is in M then bribery is possible; it is enough to bribe
exactly the voters selected for the manipulating group. On the other hand, if bribery is
possible, then at least one of the instances we output belongs to M, namely any one that
includes the voters we would bribe.

While simple, this result is still powerful enough to allow the inheritance of some results
from previous papers. Bartholdi et al. (1989a) discuss manipulation by single voters and
Theorem 4.1 translates their results to the bribery case. In particular, this translation says
that bribery for k = 1 is in P for plurality, Borda count, and many other systems.
Can we strengthen Theorem 4.1 from constant-bounded bribery to general bribery? The
answer is no: There are election systems for which bribery is NP-complete but manipulation
is in P. In particular, manipulation for approval voting (both in the weighted and the
unweighted case) is in P for any size of manipulating set: The manipulating group simply
approves just of their favorite candidate and nobody else.8 However, by the following
theorem, bribery for approval voting is NP-complete.
Theorem 4.2 approval-bribery is NP-complete.
Proof. Clearly, approval-bribery is in NP. NP-completeness follows from a reduction
from X3C.
Let B = {b1 , . . . , b3t } and let S = {S1 , . . . , Sm } be a family of three-element subsets of
B. Without loss of generality, we assume that m  t; otherwise an exact cover is impossible.
For each i, 1  i  3t, let i be the number of sets Sj that contain bi . On input (B, S) we
construct approval-bribery instance E = (C, V, p, k), where k = t, the set of candidates C
is equal to B  {p}, and we have the following voters.
1. For each Si  S there is a voter vi who approves of exactly the members of Si .
8. Meir et al. (2008) in a somewhat different and more flexible setting have previously noted that approvalmanipulation is in P if there is only one manipulator.

506

fiHow Hard Is Bribery in Elections?

2. For each bi we have m  i + 1 voters who approve only of bi .
3. We have m  t voters who approve only of p.
Note that p gets m  t approvals and that each bi , 1  i  3t, gets m + 1 approvals. We
claim that p can be made a winner by bribing at most t voters if and only if B has an exact
cover by sets in S.
S
First assume that there is a set A such that kAk = t and iA Si = B. To make p a
winner, bribe each vi such that i  A to approve only of p. As a result p gets m approvals
and each bi loses exactly one approval. Thus, all candidates are winners. On the other hand,
assume there is a bribery of at most t voters that makes p a winner. Each bribed voter
contributes at most one additional approval for p. Thus, p will get at most m approvals.
Each candidate in B has m + 1 approvals, and our bribery needs to take away at least one
approval from each candidate in B. Since we bribe at most t voters, this can only happen
if we bribe t voters vi that correspond to a cover of B.
This reduction can be computed in polynomial time.

Of course, when the number of bribes is bounded by some fixed constant then, by
Theorem 4.1, approval-bribery can be solved in polynomial time.
We mention that bribery in approval elections is actually very easy if we look at a
slightly different model. Our bribery problems allow us to completely modify the approval
vector of a voter, but this may be too demanding. A voter might be willing to change some
of his or her approval vectors entries but not to change it completely.
Definition 4.3 approval-bribery is the problem that takes as input a description of an
approval election along with a designated candidate p and a nonnegative integer k, and asks
whether it is possible to make p a winner by at most k entry changes (total) in the approval
vectors. approval-$bribery is defined analogously, but with the extra twist that now changing
each entry of an approval vector may have a different price.9
Having different prices for flipping different entries in approval-$bribery models the possibility that a voter might be more willing to change his or her approval of some candidates
than of other candidates. These modified problems turn out to be easy. In fact, they are
easy even if we have both weights and prices, provided one of them is encoded in unary.
Theorem 4.4 Both
$bribery are in P.

approval-weighted-$briberyunary

and

approval-weightedunary -

Proof. The polynomial-time algorithm we provide is based on the observation that in
both approval-weighted-$briberyunary and approval-weightedunary -$bribery getting vote
weight for the favorite candidate can be (carefully) treated separately from demoting the
other candidates. (This is basically because in approval voting in the bribery model costs
are linked to entries in voters approval vectors and a candidates point total is by weighted
addition, over all the voters, of that candidates 0-or-1 entry from that voter.)
9. As a referee points out, from a technical perspective one can view the voters in approval-bribery (and
its variants) as broken into multiple plurality voters that can be turned on and off. Partially due
to this similarity, various flavors of approval-bribery have computational properties very similar to the
corresponding variants of plurality-bribery.

507

fiFaliszewski, Hemaspaandra, & Hemaspaandra

We can divide any bribery into two phases: First, we bribe voters to approve of p,
our favorite candidate, and second, we bribe enough voters to retract their approvals of
candidates that still defeat p. There are only polynomially many relevant vote weights that
p may obtain by bribery, so we can try them all.
Let E = (C, V, p, k) be the bribery instance we need to solve. For a candidate c, a price
b, and a subset of voters V  , we define heaviest(V  , c, b) to be the highest vote weight of
voters in V  whose approval of c can be switched by spending at most b dollars. Similarly,
for a candidate c, vote weight w, and a subset of voters V  , we define cheapest(V  , c, w)
to be the lowest price that can switch the approval-of-c of voters in V  that have total
weight at least w. In our proof we only use sets V  where either all voters approve of c
or all voters disapprove of c. Note that heaviest(V  , c, b) is defined for all b  0 and that
cheapest(V  , c, w) is defined for all w  (V  ). As in Section 3, heaviest can easily be
computed in polynomial time in the unary prices case and cheapest can easily be computed
in polynomial time in the unary weights case. In addition, cheapest can be computed in
polynomial time in the unary prices case. Note that
cheapest(V  , c, w) = min{b | heaviest(V  , c, b)  w}.
Since there are only polynomially many prices to try, this can be done in polynomial time.
Figure 3 gives pseudocode for the procedure UnaryPricesApproval, which decides
approval-weighted-$briberyunary  . score E (c) denotes the number of approvals of candidate c in election E. The procedure simply tries all relevant weights that p could obtain
by bribery and tests whether it is possible, for any of them, to bring the other candidates down to vote weight at most that of p without exceeding the budget. The procedure
is correct because of the separation we achieved (as discussed above, and applied within
our proof framework of trying all thresholds) between the issue of bribing voters to approve of p and the issue of bribing them not to approve of some other candidate. Also, as
cheapest and heaviest are computable in polynomial time, the procedure works in polynomial time. An analogous procedure decides the unary weights case: Simply change the line
for b = 0 to k do to for w = 0 to (V  ) do and the line w = heaviest(V  , p, b) to
b = cheapest(V  , p, w).

With both prices and weights encoded in binary, approval-weighted-$bribery becomes
NP-complete.
Theorem 4.5 approval-weighted-$bribery is NP-complete.
Proof. It is immediate that approval-weighted-$bribery is in NP. To show NP-hardness,
we will constructPa reduction from Partition. Let s1 , . . . , sn be a sequence of nonnegative
integers and let ni=1 si = 2S. We construct an election E with candidates p and c and
n + 1 voters, v0 , . . . , vn , with the following properties.
1. v0 has weight S, approves only of p, and changing any of v0 s approvals costs 2S + 1.
2. vi , for 1  i  n, has weight si , approves only of c, changing vi s approval for p costs
si , and changing vi s approval for c costs 2S + 1.
We claim that p can be made a winner
by a bribery of cost at most S if and only if there
P
is a set A  {1, . . . , n} such that iA si = S.
508

fiHow Hard Is Bribery in Elections?

procedure UnaryPricesApproval(E = (C, V, p, k))
begin
if k  (V ) then
return(accept);
V  = {v | v  V and v does not approve of p};
for b = 0 to k do
begin
w = heaviest(V  , p, b);
r = score E (p) + w;
k  = k  b;
for c  C  {p} do
begin
Vc = {v | v  V and v approves of c};
if score E (c) > r then
k  = k   cheapest(Vc , c, score E (c)  r);
end
if k   0 then return(accept);
end
return(reject);
end
Figure 3: The procedure UnaryPricesApproval.
First suppose that p can be made a winner by a bribery of cost at most S. Then we
can only bribe voters v1 , . . . , vn to approve of p. In election E, p has S approvals and c
has 2S approvals, so our bribery needs to give p at least S extra approvals. Since changing
vi s approval of p costs si , and the weight of vi is also si , it follows that p gains exactly S
approvals, and that the weights of the bribed voters in v1 , . . . , vn add up to exactly S. This
implies that the sequence s1 , . . . , sn can be partitioned into two subsequences that each sum
to S.
P
On the other hand, assume there is a set A  {1, . . . , n} such that iA si = S. Then
we can bribe voters vi , i  A, to approve of p. As a result, both p and c will have vote
weight 2S and both of them will be winners. Our reduction can be computed in polynomial
time and thus the theorem is proved.

Which of the above-discussed bribery models for approval is more appropriate depends
on the setting. For example, bribery seems more natural when we look at the web and treat
web pages as voting by linking to other pages. It certainly is easier to ask a webmaster to
add/remove a link than to completely redesign the page. We point the reader to the work
of Faliszewski (2008) for further discussion of bribery scenarios similar to bribery .
After this somewhat lengthy discussion of approval bribery, let us now return to our
central goal of relating bribery and manipulation. In Theorem 4.1 we managed to disjunctively truth-table reduce a restricted version of bribery to manipulation. The discussion and
theorems that follow show that working in the opposite direction, reducing manipulation
to bribery, which at first might seem more difficult, is in fact more fruitful.
509

fiFaliszewski, Hemaspaandra, & Hemaspaandra

The reason why reducing manipulation to bribery appears to be more difficult is that
bribery allows more freedom to the person interested in affecting the elections. To embed
manipulation within bribery, we have to find some way of expressing the fact that only a
certain group of voters should be bribed (or, at least, expressing the fact that if there is any
successful bribery then there is also one that only bribes the manipulators). We can fairly
easily implement this plan, though at the cost of reducing to a stronger bribery model,
namely bribery with prices.
Theorem 4.6 Let M be some manipulation problem and let B be the analogous $bribery
problem (for the same election system). It holds that M pm B.
Proof. Let M = (C, V, S, p) be an instance of M. We design an instance B of B such
that B = (C, V   S  , p, 0), where
1. V  is equal to V , except that each voter has price 1, and
2. S  is equal to S, except that each voter has price 0 and some fixed arbitrary preference
list.
Since the bribery budget is set to zero, the only voters that we may possibly bribe are those
in S  . The preference lists of the voters in S  after any such bribery directly correspond to
a manipulation in M . This reduction can be carried out in polynomial time.

Clearly, Theorem 4.6 holds even for $bribery problems where prices are represented in
unary or are required to come from the set {0, 1}. Theorem 4.6 is very useful as it allows us
to inherit some very powerful results from the theory of manipulation. Hemaspaandra and
Hemaspaandra proved the following dichotomy result (see also Procaccia & Rosenschein,
2007; Conitzer et al., 2007).
Theorem 4.7 (Hemaspaandra & Hemaspaandra, 2007) Let  = (1 , . . . , m ) be a
scoring protocol. If it is not the case that 2 = 3 =    = m , then -weightedmanipulation is NP-complete; otherwise, it is in P. This result holds for both the unique
and nonunique variants.
Combining the two above theorems with Theorem 3.2 we can immediately classify the
complexity of weighted-$bribery for all scoring protocols.
Theorem 4.8 For each scoring protocol  = (1 , . . . , m ), if 1 = m then -weighted$bribery is in P; otherwise it is NP-complete.
Proof. We consider three cases.
1. 1 =    = m .
2. 1 > 2 =    = m .
3. All other settings.
In the first case, 1 =    = m , -weighted-$bribery is trivially in P as all candidates are
always tied. For the remaining two cases, note that -weighted-$bribery is clearly in NP.
It remains to show NP-hardness.
510

fiHow Hard Is Bribery in Elections?

In the second case, 1 > 2 =    = m , we can employ the proof of Theorem 3.2.
Theorem 3.2 shows NP-hardness for (1, 0)-weighted-$bribery. It is easy to see that for all
m  2 we can pad this reduction with m  2 candidates that are never ranked first to
m1
z }| {
obtain NP-hardness for (1, 0, . . . , 0)-weighted-$bribery. Note that our  describes elections
equivalent to plurality (i.e., a candidate is a winner of an  election if and only if he or she
m1

z }| {
would also be a winner of the (1, 0, . . . , 0) election with the same voters and candidates;
see Observation 2.2 in the paper of Hemaspaandra & Hemaspaandra, 2007). Thus, we
get NP-completeness of -weighted-$bribery for this case since we do have at least two
candidates.
The third case follows by combining Theorem 4.6 with Theorem 4.7. Since -weightedmanipulation many-one reduces to -weighted-$bribery and -weighted-manipulation is
NP-complete we have that -weighted-$bribery is NP-hard. This exhausts all cases. 
Theorem 4.8 applies to $bribery, but of course it is also interesting to ask what happens
in the case when voters do not have prices. Does bribery remain NP-complete? Can we
express the constraints of bribery without using such a direct embedding as above? The
following dichotomy theorem shows that the answer is Yes, but in fewer cases.
Theorem 4.9 For each scoring protocol  = (1 , 2 , . . . , m ), if 2 = 3 =    = m then
-weighted-bribery is in P; otherwise it is NP-complete.
If 2 = 3 =    = m then either the -weighted-bribery is trivially in P (if 1 =
   = m ) or can be solved using the algorithm for plurality-weighted-bribery. The core
of the proof is to show NP-hardness. It would be nice to do so by reducing from the
corresponding manipulation problems (which share the characterizations boundary line
regarding the s). This seems not to work, but in Lemma 4.11 we construct such a
reduction that has the right properties whenever its inputs satisfy an additional condition,
namely, that the weight of the lightest manipulating voter is at least double that of the
heaviest nonmanipulator. This would suffice if the thus-restricted manipulation problem
were NP-hard. Lemma 4.12 shows that the thus-restricted manipulation problem is NPhard. It does so by examining the manipulation-dichotomy proof of Hemaspaandra and
Hemaspaandra (2007) and noting that if we apply that papers reduction to Partition (see
Section 2.3) rather than to Partition then we can guarantee the restriction mentioned above.
Definition 4.10 By -weighted-manipulation we mean the manipulation problem weighted-manipulation with the restriction that each manipulative voter has weight at
least twice as high as the weight of the heaviest of the nonmanipulative voters. Each instance where the restriction is violated is considered not to be an element of -weightedmanipulation .
Lemma 4.11 Let  = (1 , . . . , m ) be a scoring protocol. -weighted-manipulation pm
-weighted-bribery.
Proof. Without loss of generality we can assume that m = 0. If m 6= 0 then we can
consider the scoring protocol  = (1  m , 2  m , . . . , m  m ) instead. Given an
instance M = (C, V, S, p) of the manipulation problem, we construct B = (C, V  , p, kSk), a
511

fiFaliszewski, Hemaspaandra, & Hemaspaandra

bribery instance, such that there is a successful manipulation within M if and only if there
is a successful bribery within B. We assume that M fulfills -weighted-manipulation s
requirements regarding relative weights of voters in V and S. If not, we output some fixed
B that has no successful briberies.
The reduction works by constructing V  = V  S  , where S  is the set of voters from S
with a fixed arbitrary preference list that has p as the least preferred candidate. Clearly,
if a manipulation is possible within M then some bribery works for B. We show that the
other direction also holds by arguing that if a successful bribery within B exists, then there
is a successful bribery that affects only voters in S  . This implies that S can be viewed as
being the manipulative group.
Let us assume that there is some way of bribing at most kSk voters in V  so that p
becomes a winner. If all the bribed voters are in S  then the theorem is proven. Otherwise,
select some bribed voter v  V   S  . By bribing v, p gains at most (1 + 1 )  (v) points
over each candidate c 6= p. (The first 1 is because p can get at most 1 additional points
by this bribery, and the second 1 is because c can lose at most 1 votes.) However, if
instead of bribing v we would bribe some voter v  in S  , p would gain at least 1 (v  ) points
over each c. (We would bribe v  to put p as his or her most preferred candidate and shift
all other candidates back.) Since it holds that (v  )  2(v), we might just as well bribe
v  instead of v, and p would still be a winner. Thus, if p can be made a winner, then p can
be made a winner by bribing only voters in S  .
This reduction can easily be computed in polynomial time.

It remains to show that the restricted version of manipulation is NP-complete for all
scoring protocols for which the nonrestricted version is.
Lemma 4.12 If  = (1 , . . . , m ) is a scoring protocol such that it is not the case that
2 = 3 =    = m , then -weighted-manipulation is NP-complete.
Proof. Let  = (1 , . . . , m ) be a scoring protocol such that 2 6= m . We will use Hemaspaandra and Hemaspaandras (2007) proof of their result that is here called Theorem 4.7 to
show the NP-completeness of -weighted-manipulation . Clearly, -weighted-manipulation
is in NP so we only need to prove its NP-hardness.
Hemaspaandra and Hemaspaandras (2007) proof of Theorem 4.7 reduces Partition (restricted to positive integers) to -weighted-manipulation. A close inspection of that proof10
shows that there exist constants c and d  2 that depend
only on  such that for evP
ery sequence of positive integers s1 , . . . , sn such that ni=1 si = 2S, the Hemaspaandra
Hemaspaandra reduction outputs a manipulation problem that has the following properties.
1. Each nonmanipulative voter has weight at most cS, and
2. the weights of the manipulative voters are ds1 , ds2 , . . . , dsn .
We will use these facts to provide a reduction from Partition to -weighted-manipulation .
Our reduction
works as follows. Let s1 , . . . , sn be the input sequence of nonnegative
P
2
integers, ni=1 si = 2S, such that for each i, 1  i  n, it holds that si  2+n
S. (As per
footnote 3, if these conditions do not hold then we return a fixed string not in -weighted10. We do not repeat that proof here. Interested readers are referred to the paper of Hemaspaandra and
Hemaspaandra (2007).

512

fiHow Hard Is Bribery in Elections?

manipulation .) Without loss of generality, we assume that S > 0, and thus s1 , . . . , sn are
positive integers. Let f be the reduction given by the proof of Theorem 4.7 in the paper
of Hemaspaandra and Hemaspaandra (2007). We compute f ((s1 , . . . , sn )) = (C, V, T, p).
(Reduction f works for general Partition and so, since we already checked the special properties required by Partition , it has to work correctly for our input.) That is, s1 , . . . , sn
can be partitioned if and only if there is a successful manipulation of (C, V, T, p). Unfortunately, we cannot just output (C, V, T, p) as it does not necessarily fulfill the condition
on voters weights. Recall that we have to ensure that each manipulative voter has weight
at least twice as high as the weight of the heaviest of the nonmanipulative voters. Let
smin = min{sj | 1  j  n}. In (C, V, T, p), the least weight of a voter in T is exactly dsmin ,
and the highest weight of a voter in V is at most cS. However, we can split each voter v in
V . The weights of the voters who do not participate in the manipulation are irrelevant as
long as the total weight of voters with each given preference order does not change. Thus,
we can replace a voter with high weight by several other voters with the same preference
order but with lower weights. In our case, we need to make sure that each nonmanipulative
voter has at most weight 21 dsmin . Since the heaviest of the nonmanipulative voters has
weight at most cS, we need to replace each voter v  V by at most
&
'
cS
(4)
 21 dsmin 
voters, each of weight at most 12 dsmin . Since d  2, S > 0, smin is a positive integer, and
2
2+n S  smin , we can bound (4) from above by
&

cS
1
 2 dsmin 

'



cS

smin





&

cS
2S
2+n

'

=




c(n + 2)
,
2

which is clearly polynomially bounded in n. Thus, the splitting of voters can easily be
performed in polynomial time, and since it does not change the result of manipulation, the
theorem is proven.

The proof of Theorem 4.9 simply combines Lemmas 2.3, 4.11, and 4.12.
Theorem 4.9 shows that bribery within weighted scoring protocols is, in most cases,
difficult. Though weighted bribery in light of Theorem 4.9 is easy for trivial elections (1 =
m ), plurality, and even pluralitys equivalent clones (all scoring systems with 1 > 2 =
   = m ), if the voters are not only weighted but also have prices then (by Theorem 3.2)
bribery also becomes difficult in the case of plurality and pluralitys equivalent clones. It is
interesting to ask whether having voters who have prices but are not weighted also yields a
dichotomy result. As Theorem 4.13 shows, the behavior of scoring protocols with respect
to priced voters is very different than with respect to weighted ones.
Theorem 4.13 Let  = (1 , . . . , m ) be a scoring protocol. -$bribery is in P.
Proof. We will give a polynomial-time algorithm for -$bribery. Let E = (C, V, p, k)
be an instance of the problem. First, observe that by considering scoring protocol  =
(1 , . . . , m ) we, by definition, limit ourselves to a scenario with m candidates, where m is
a fixed constant. This implies that there are only a constant number of different preference
513

fiFaliszewski, Hemaspaandra, & Hemaspaandra

orders, o1 , . . . , om! , that the voters might have. We partition V into sets V1 , V2 , . . . , Vm!
such that each Vi contains exactly the voters with preference order oi . Some Vi s might be
empty and each Vi has at most n elements, where n = kV k.
A bribery within E can be described by giving two sequences of integers, b1 , . . . , bm! and
d1 , . . . , dm! , such that 0  bi  kVi k and 0  di  n, for 1  i  m!, and
m!
X
i=1

bi =

m!
X

di .

i=1

Each bi says how many voters from Vi we are bribing. It is sufficient to just give the
numbers biPsince we want to bribe only the cheapest members of each Vi . After we bribe
these b = m!
i=1 bi voters, we need to decide what preferences to assign to them. This is
described by the sequence d1 , . . . , dm! : Each di says how many of the b voters will be assigned
to have preferences oi . Since the voters are indistinguishable, specifying these numbers is
enough.
It remains to observe that there are at most nm! sequences b1 , . . . , bm! and there are at
most nm! sequences d1 , . . . , dm! for each b. Thus, there are at most n2(m!) sequences to try
out. For each pair of sequences it is easy to check whether after performing the described
bribery p becomes a winner and whether the budget is not exceeded. Thus, -$bribery is
in P.

The algorithm given in the proof of Theorem 4.13, with almost no changes, can be used
to prove the following corollary.
Corollary 4.14 Let E be an election system such that (a) for each fixed number of candidates its outcome is computable in polynomial time and (b) its outcome does not depend on
the order of the votes. For each fixed number of candidates E-$bribery is in P.
Theorem 4.13 stands in a sharp contrast to Theorem 4.9. It is natural to ask why prices
and weights exhibit such differing behavior. One answer is that in the weighted case the
voters retain their individualitytheir weightsthroughout the whole process of bribery.
On the other hand, in the priced case the voters are disassociated from their prices as
soon as we decide to bribe them. If we decide to bribe a particular priced voter then we
simply need to add his or her price to our total budget, but from then on the voter is
indistinguishable from all the other bribed ones. Precisely this observation facilitated the
proof of Theorem 4.13.
The algorithm given in the proof of Theorem 4.13 has a rather disappointing running
time. While nO(m!) is a polynomial in our setting, one would certainly prefer to have an
algorithm whose time complexity did not depend on m in this way. In particular, it would
be nice to have an algorithm with running time polynomial in n + m. However, if such an
algorithm exists then P = NP. This follows from the proof of the fact that approval-bribery
is NP-complete. In that proof we showed how to reduce X3C to approval-bribery in such
a way that each voter approves of at most 3 candidates. If there were a polynomial p and
an algorithm that ran in time p(kCk + kV k) for every scoring protocol , then we could
solve X3C by reducing it to approval-bribery and then embedding that approval-bribery
problem in an -bribery problem for some  = (1, 1, 1, 0, . . . , 0), possibly adding some
dummy candidates. This embedding is straightforward so we do not describe it in detail.
514

fiHow Hard Is Bribery in Elections?

Let  = (1 , . . . , m ) be a scoring protocol such that it is not the case that 2 =
   = m . By Theorem 4.9 we know that -weighted-bribery is NP-complete. We also
know, by Theorem 4.13, that -$bribery is in P. It clearly holds that -weighted-$bribery
is NP-complete, but it is interesting to ask whether the NP-completeness of -weightedbribery and -weighted-$bribery holds because of the possibly exponentially large values
of the weights, or do these problems remain NP-complete even if the weights are encoded
in unary? It turns out, by the following theorem, that high weight values are necessary for
NP-completeness.
Theorem 4.15 Let  = (1 , . . . , m ) be a scoring protocol. -weightedunary -$bribery is
in P.
Proof. Let  = (1 , . . . , m ) be a scoring protocol. The proof of this theorem cashes
in on the same observation as that made in the proof of Theorem 4.13: There are only
finitely many different preference orders, and there are only polynomially many substantially
different ways of bribing.
Let E = (C, V, p, k) be a bribery problem and let o1 , . . . , om! be all the different possible
preference orders over C. We partition V into m! disjoint sets V1 , . . . , Vm! such that each Vi
contains exactly the voters with preference order oi . A bribery within E can be described
by a sequence of m! vectors bi = (bi,1 , bi,2 , . . . , bi,m! ), 1  i  m!, such that for each i, j,
1  i, j  m!, bi,j is a nonnegative integer and for each i, 1  i  m!, we have
m!
X

bi,j = (Vi ).

j=1

The interpretation of a vector bi is that voters in Vi can be partitioned into m! sets
Vi,1 , . . . , Vi,m! such that (Vi,j ) = bi,j , with the intention of bribing voters in Vi,j to change
their preference lists to oj (recall that Vi is a multiset, and so of course this is a multiset
partition and the Vi,j s will be multisets). When i 6= j this bribery has some price, and
when i = j it is for free as nothing really needs to be done. Note that not all vectors are
realizable; not every splitting of vote weight (Vi ) can be achieved. The rest of this proof is
devoted to developing a method for evaluating whether a given split is possible and what its
minimal cost is. There are only ((V )m! )m! ways of selecting vectors b1 , . . . , bm! so if we can
test whether a given vector is realizable (and compute the minimal price for its realization),
then we can simply try all sequences of vectors and test whether any of them both makes
p a winner (the winner, in the unique case) and has its total cost fall within the budget.
We will now describe an algorithm that checks if a particular vector w = (w1 , . . . , wm! ),
where wi  {0, . . . , (V )} for each i in {1, . . . , m!}, is realizable and computes the minimal
price for ws realization. By Vi (w1 , . . . , wm! ) we mean the following set of m!-element
sequences of subsets of Vi :
S
Vi (w) = {(Vi,1 , . . . , Vi,m! ) | (Vi = m!
j=1 Vi,j )  (1  j  m!)[(Vi,j ) = wj ]}.
For each w we define

P
min{ | ((Vi,1 , . . . , Vi,m! )  Vi (w))[ = j6=i (Vi,j )]}
gi (w) =

515

if Vi (w) 6= ,
otherwise.

fiFaliszewski, Hemaspaandra, & Hemaspaandra

That is, gi (w) gives the lowest price for bribing the voters in Vi according to weight vector
(w1 , . . . , wm! ). We can compute gi (w) in polynomial time using dynamic programming
techniques. Let us rename the candidates so that Vi = {v1 , . . . , vt } and let gi, (w) be the
same as gi (w) except restricted to voters v , . . . , vt . Thus, gi,1 is exactly gi . Naturally, the
following boundary condition holds for gi,t+1 .

0
if w1 = w2 =    = wm! = 0,
gi,t+1 (w1 , . . . , wm! ) =

otherwise.
We can compute values of gi, (w1 , . . . , wm! ) using dynamic programming and the observation
that gi, (w1 , . . . , wm! ) is equal to the minimum of the following:
gi,+1 (w1  (v ), w2 , . . . , wm! ) + (v ),
gi,+1 (w1 , w2  (v ), w3 , . . . , wm! ) + (v ),
...
gi,+1 (w1 , . . . , wm!1 , wm!  (v )) + (v ), and
gi,+1 (w1 , . . . , wi1 , wi  (v ), wi+1 , . . . , wm! ).
Note that the last of the values handles the fact that if we bribe v to report preference
order oi then we actually do not need to pay him or her; v already has preference order
oi . Otherwise, we need to decide which of the m!  1 other preference orders we ask v to
report, and we need to pay for this change. Clearly, using this rule and the above boundary
condition we can compute gi,1 (w), and thus gi (w), in time polynomial in (V ). Since (V )
is polynomial in the size of the input, this completes the proof.

Corollary 4.16 Let E be an election system such that (a) for each fixed number of candidates its outcome is computable in polynomial time and (b) its outcome does not depend on
the order of the votes. For each fixed number of candidates E-weightedunary -$bribery is in
P.
Note that, by Theorem 4.6, it holds that for each scoring protocol ,
-weightedunary -manipulation pm -weightedunary -$bribery, and as the latter is in P,
we have the following corollary.
Corollary 4.17 For any scoring protocol , -weightedunary -manipulation is in P.
Certain scoring protocols have natural generalizations to an arbitrary number of candidates, e.g., the plurality rule, the Borda count, and the veto rule. Our results above do
not imply easiness of bribery for such election systems, as we need a single P algorithm to
work in all cases. For example, for the case of Borda count, recently Brelsford et al. (2008)
have shown that even Borda-bribery is NP-complete. In other cases, easiness results can
be easily obtained by hand. For example, Theorem 4.9 immediately implies that vetoweighted-bribery is NP-complete even for 3 candidates, yet the following result shows that
the difficulty of bribery for veto voting comes purely from the weighted votes.
Theorem 4.18 veto-bribery is in P.
516

fiHow Hard Is Bribery in Elections?

Proof. The proof of this theorem is essentially the same as that of Theorem 3.1. We can
view veto elections as elections in which every voter vetos one candidate, and a candidate
with the least number of vetoes wins. (In the unique case, a candidate is the winner if and
only if no other candidate has as few vetoes as he or she has.)
Thus, given an instance E = (C, V, p, k), we keep on bribing voters that veto p and ask
them to veto a candidate that, at that time, has the least number of vetoes. If after at most
k bribes p is a winner then we accept; otherwise we reject. A simple inductive argument
shows this is a correct strategy, and the algorithm clearly runs in polynomial time.

Interestingly, Brelsford et al. (2008) showed that veto-weightedunary -manipulation is
NP-complete. This immediately gives, by Theorem 4.6, that veto-weightedunary -$bribery
is NP-complete. Using techniques similar to those we used in the proof of Theorem 4.9
(but much simpler) we can modify their reduction to show that even veto-weightedunary bribery is NP-complete. On the other hand, the main result of the paper Faliszewski (2008)
implies that veto-$bribery is in P. As to whether Theorem 4.18 follows immediately from
Theorem 4.13, it does not. Why? Recall that 4.13 covers veto for each fixed number of
candidates, but Theorem 4.18 is covering the protocol that handles veto for all numbers of
candidateswhat people commonly think of when they think of veto as a voting system.
We in spirit obtained Theorem 4.9 by reducing (with much work and adjustment) from
manipulation to bribery, for scoring protocols. Will that work in all other settings? The
answer is no; we have designed an artificial voting system where checking manipulability
even by just one voter is NP-complete, but checking bribability is easy.
Theorem 4.19 There exists a voting system E for which manipulation is NP-complete, but
bribery is in P.
Proof. Let A be an NP-complete set and let B  P be such that
1. A = {x   | (y   )[hx, yi  B]}, and
2. (x, y   )[hx, yi  B  |x| = |y|].
Such sets can easily be constructed from any NP-complete set by padding. The idea of the
proof is to embed a verifier for A within the election rule E. We do this in a way that forces
manipulation to solve arbitrary A instances, while allowing bribery to still be easy.
First, we observe that preference lists can be used to encode arbitrary binary strings.
We will use the following encoding. For C a set of candidates, let c1 , c2 , . . . , cm be those
candidates in lexicographical order. We will view the preference list
ci1 > ci2 > ci3 >    > cim
as an encoding of the binary string b1 b2    bm/2 , where
bj =



0
1

if i2j1 > i2j ,
otherwise.

This encoding is of course not the most efficient one, and a given binary string may have
many preference lists that encode it. However, this encoding is very easy and has the
properties that we need in our construction.
517

fiFaliszewski, Hemaspaandra, & Hemaspaandra

In our reduction, binary strings starting with 1 will encode instances, and binary strings
starting with 0 will encode witnesses. Given this setup, we can describe our election system
E. Let (C, V ) be an election. For each c  C, c is a winner of the election if and only if
kV k = 3 and
Rule 1: all preference lists encode strings starting with 1 or all preference lists encode
strings starting with 0, or
Rule 2: exactly one preference list encodes a string that starts with 1, say 1x, and at least
one other preference list encodes a string 0y such that hx, yi  B.
Thus, either all candidates are winners or none of them are winners. Note that testing
whether a candidate c is a winner of an E election can easily be done in polynomial time.
The following polynomial-time algorithm shows how to perform an optimal bribery. This
implies that E-bribery  P.
1. If c is a winner, we do nothing.
2. Otherwise, if kV k =
6 3, then bribery is impossible.
3. Otherwise, if there is exactly one voter whose preference list encodes a string that
starts with 1, then we bribe that voter to encode a string that starts with 0. By
Rule 1, c is a winner of the election.
4. Otherwise, there is exactly one voter whose preference list encodes a string that starts
with 0 and we bribe that voter so that his or her preference list encodes a string that
starts with 1. By Rule 1, c is a winner of the election.
On the other hand, the ability to solve the manipulation problem for E implies the ability
to solve A. We construct a reduction from A to E-manipulation. Given a string x   ,
we first check whether hx, 0|x| i  B. If so, then clearly x  A and we output some fixed
member of E-manipulation. Otherwise, we output a manipulation problem with candidates
{1, 2, . . . , 2(|x| + 1)} and three voters, v0 , v1 , and v2 , such that v0 s preference list encodes
1x, v1 s preference list encodes 00|x| , and v2 is the only manipulative voter. We claim that
candidate 1 can be made a winner if and only if x  A.
Since hx, 0|x| i 6 B, the only way in which v2 can make 1 a winner is when v2 encodes
a string 0y such that hx, yi  B in which case x  A. For the converse, if x  A, there
exists a string y  |x| such that hx, yi  B. We can encode string 0y as a preference list
over {1, 2, . . . , 2(|x| + 1)}, and let this be the preference list for v2 . This ensures that 1 is a
winner of the election.
Since this reduction can be computed in polynomial time, and the E-manipulations
membership in NP is clear, we have that E-manipulation is NP-complete.
The same result holds for the case of unique winners. In this case we modify E such
that only the lexicographically smallest candidate can win the election and the reduction
will define the distinguished candidate as the lexicographically smallest candidate.

The above election system is not natural, but it does show that unless we restrict our
election rules somehow or prove P = NP, obtaining a general reduction from manipulation
to bribery seems precluded.
518

fiHow Hard Is Bribery in Elections?

5. Succinct Elections
So far we have discussed only nonsuccinct electionsones where voters with the same
preference lists (and weights, if voters are weighted) are given by listing each of them one
at a time (as if given a stack of ballots). It is also very natural to consider the case where
each preference list has its frequency conveyed via a count (in binary), and we will refer to
this as succinct input. The succinct representation is particularly relevant in case when
the number of candidates is bounded by a constant. When there are many candidates, it is
natural to expect that a lot of voters will have preferences that vary in some insignificant
ways. On the other hand, if there are very few candidates then, naturally, there will be
large numbers of voters with the same preferences, and using succinct representation will
save a lot of space.
In this section we provide P membership results (and due to our proofs, these in fact each
are even FPT membership results11 ) regarding bribery in succinctly represented elections
with a fixed number of candidates. Our main tool here is Lenstras (1983) extremely
powerful result that the integer programming feasibility problem is in P if the number of
variables is fixed.
Theorem 5.1 (Lenstra, 1983) Let k be some fixed nonnegative integer. There is a
polynomial-time algorithm that given an m  k integer matrix A and a vector b  Zm
determines whether
{x  Zk | Ax  b} =
6 
holds. That is, integer linear programming is in P for a fixed number of variables.
We mention that Lenstras polynomial-time algorithm is not at all attractive practically
speaking. In particular, although the algorithm uses just a linear number of arithmetic
operations on linear-sized integersand thus it has a theoretically attractive, low-degree
polynomial run-timethe multiplicative constant is very large. To us here this is not a
critical issue since we are mostly interested in polynomial-time computability results and
general tools for obtaining them, rather than in actual optimized or optimal algorithms.
Although Lenstras result applies to the integer linear programming problem when the
number of variables is fixed and achieves P-time in that case, in this section we in fact
11. Regarding the natural issue of which P results can be strengthened to being FPT results, we mention in
passing that every P membership result of this section is clearly (although implicitly), via its proof, even
an FPT membership result. (A problem with some parameter j is in FPT, a class capturing the notion of
being fixed-parameter tractable, if there exists an algorithm whose running time on instances of size n is
bounded by f (j)nO(1) , where f is some function depending only on j; see Niedermeier, 2006, for detailed
coverage of parameterized complexity.) Essentially, this is because Lenstras method is well known to
use a linear number of arithmetic operations on linear-sized variables (Lenstra, 1983, see also Downey,
2003; Niedermeier, 2002). Although the fact that some voting problems are in FPT is implicit in the
seminal work of Bartholdi et al., 1989b (e.g., see Christian, Fellows, Rosamond, & Slinko, 2007; Betzler,
Guo, & Niedermeier, 2008b), we mention that the work of Christian et al. (2007, Section 4), which itself
has a bribery-like flavor to its results, explicitly addresses the issue of FPT, in particular mentioning
that it is well known that the (nonsuccinct) winner and score problems for Kemeny and Dodgson are in
FPT, and we are indebted to an earlier version of their paper as it motivated us to here mention that
this sections P results (even those about succinct elections) are FPT results. Among the other papers
addressing FPT results for election problems (although not regarding bribery problems), we mention as
examples the work of Betzler, Fellows, Guo, Niedermeier, and Rosamond (2008a) on Kemeny voting and
of Faliszewski et al. (2008) on Llull and Copeland voting.

519

fiFaliszewski, Hemaspaandra, & Hemaspaandra

typically only need the special case of his result in which the number of variables and the
number of constraints are both fixed (and so the only parameter that is changing is the
constants within the constraints).
P membership results regarding succinctly represented elections naturally imply analogous results for the nonsuccinct representation. To express the fact that succinctness of
representation is optional in such cases, we put the phrase succinct in curly braces in the
names of the problems. For example, if we say that plurality-{succinct}-bribery is in P,
we mean that both plurality-bribery and plurality-succinct-bribery are in P. (By the way,
Theorem 3.1, by a similar but more careful algorithm than the one in its proof also holds
for the succinct case.)
Before we proceed with the results, let us introduce some notation. Throughout this
section we assume that all bribery problems that we are dealing with have exactly m
candidates, where m is some arbitrary fixed constant. Thus, if E = (C, V, p, k) is a bribery
problem then we may assume that C = {1, . . . , m}, and that o1 , o2 , . . . , om! are all the
possible preference orders over C. Given a set of voters V , by Vi , 1  i  m!, we mean the
set of voters v  V that have preference order oi . For a given i, we define wh(c, i) to be
the index of candidate c within preferences oi (informally, where is c in oi ). This notation
is assumed in each of the proofs of this section.
Using the integer programming approach we obtain polynomial-time algorithms for
bribery under scoring protocols in both the succinct and the nonsuccinct cases. The same
approach yields a similar result for manipulation. (The nonsuccinct case for manipulation
was already obtained in the work of Conitzer et al., 2007.)
Theorem 5.2 For every scoring protocol  = (1 , . . . , m ), both -{succinct}-bribery and
-{succinct}-manipulation are in P.
Proof. Let  = (1 , . . . , m ) be a scoring protocol and let E = (C, V, p, k) be the bribery
problem we want to solve, where C = {1, . . . , m}. A bribery can be described by providing
numbers si,j , 1  i, j  m!, saying how many people should switch from preference order oi
to preference order oj . (The values si,i simply say how many voters with preference order
oi should not switch to anything else. And we do allow superfluous exchanging, e.g., it is
legal, even when i 6= j, to have both si,j and sj,i be strictly greater than zero. However,
note that in this proof, for example, if there is a solution where that happens then there
will be another solution in which it holds that, for each i 6= j, at least one of si,j and
sj,i is zero.) We may express by an integer program the fact that the si,j s describe a
successful bribery, and we do so as follows. Here, our variables, the si,j s, are required
to be integers. We have (m!)2 such variables. Our constants (they are constantsi.e.,
coefficientsfrom the integer linear programming perspective, not all are constants from
the complexity perspective, as in effect k, and ||V1 ||, . . . , ||Vm! || are inputs to the problem)
are k, 1 , 2 , . . . , m , kV1 k, kV2 k, . . . , kVm! k.
1. The number of bribed voters has to be nonnegative. For all i, j, 1  i, j  m!, we
have
si,j  0.
2. We cannot bribe more voters with a given preference than there are. For each i,
1  i  m!, we have the constraint (keeping in mind that the si,i s pick up any
520

fiHow Hard Is Bribery in Elections?

leftover, thus we state this as an equality)
m!
X

si,j = kVi k.

j=1

3. Altogether, we can only bribe at most k people.
m! X
m!
X

si,j 

i=1 j=1

m!
X

s,  k.

=1

4. The score of p is at least as high as anybody elses. For each h, 1  h  m, we have
a constraint that says that candidate h does not defeat p:
!
!
m!
m!
m!
m!
X
X
X
X
wh(h,j)
si,j .
wh(p,j)
si,j 
j=1

j=1

i=1

i=1

We have a constant number of variables, (m!)2 , and a constant number of constraints.
(Of course, on the other hand the size of some of our integer linear programs constants
in particular k, kV1 k, . . . , kVm! kmay increase with the number of voters.) Thus using
Lenstras algorithm we can in polynomial time test whether the above set of constraints
can be satisfied by some legal si,j s. It is clear that these constraints can be satisfied if and
only if there is a bribery of at most k voters that leads to making p a winner. Also, note
that to make this program test whether p can become a unique winner we simply make the
inequalities in the final set of constraints strict.
The case of manipulation can be proved very similarly, only that we would have variables
si that would say how many of the manipulators decide to report preference order oi . We
omit the detailed description as it is clear given the above.

The power of the integer programming approach is not limited to the case of scoring
protocols. In fact, the seminal paper of Bartholdi et al. (1989b) shows that applying this
method to computing the Dodgson score in nonsuccinct elections with a fixed number of
candidates yields a polynomial-time score algorithm (and though the paper of Bartholdi
et al., 1989b, did not address the issue of succinct elections, one can see that there too this
method works perfectly; that is, it is implicit from the Lenstra approach of the paper of
Bartholdi et al., 1989b, that Dodgson score for elections with a fixed number of candidates
is, even for the succinct case, in FPT, see also footnote 11).12 A similar program can be
used to compute the scores within Young elections. Let us recall the definition of both
Dodgson and Young scores.
Definition 5.3 Given a set of candidates C and a set of voters V specified via their preferences, the Dodgson score of a candidate c  C is the minimum number of adjacent switches
within the preferences of voters that make c a Condorcet winner.
The Young score of a candidate c  C is the minimum number of voters that need to be
removed from the elections to make c a Condorcet winner.
12. We mention in passing that some recent work responds to the theoretical complexity of Dodgson scores
from a different direction, namely, by studying the success rate of simple heuristics for the problem (McCabe-Dansted et al., 2008; Homan & Hemaspaandra, 2009).

521

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Applying the integer programming attack for the case of bribery within Dodgson-like
election systems, i.e., the Dodgson system and the Young system, is more complicated.
These systems involve a more intricate interaction between bribing the voters and then
changing their preferences. For Dodgson elections, after the bribery, we still need to worry
about the adjacent switches within voters preference lists that make a particular candidate
a Condorcet winner. For Young elections, we need to consider the voters being removed
from the elections. This interaction seems to be too complicated to be captured by an
integer linear program, but building on the flavor of the Bartholdi et al. (1989b) integer
programming attack we can achieve the following: Instead of making p a winner, we can
attempt to make p have at most a given Dodgson or Young score.
Formally, by DodgsonScore-bribery (and by its succinctly encoded variant,
DodgsonScore-succinct-bribery) we mean the problem that takes as input a Dodgsonbribery instance (C, V, p, k) (with voters encoded succinctly in the succinct variant) and a
nonnegative integer t, and asks if it is possible to ensureby bribing at most k votersthat
ps Dodgson score is at most t. We define YoungScore-bribery and YoungScore-succinctbribery analogously.
Theorem 5.4 For each fixed number of candidates, DodgsonScore-{succinct}-bribery is in
P when restricted to that number of candidates.
Proof. Given a nonnegative integer t and a bribery problem instance E = (C, V, p, k)
for Dodgson elections, where C = {1, . . . , m}, we will give an integer program that tests
whether it is possible to bribe at most k voters in such a way that, after the bribery, p has
Dodgson score at most t. Our program will have only a constant number of variables and a
constant number of constraints. Thus by Lenstras algorithm it can be solved in polynomial
time.
The process of bribery has, in the case of Dodgson elections, two phases: a bribery phase
in which we decide how to bribe voters, and a swapping phase in which we (in effect) allow at
most t adjacent swaps to occur. We will model the first phase with integer variables bi,j and
the second phase with integer variables si,j : For each i, j, 1  i, j  m!, the interpretation
of bi,j and si,j is as follows.
bi,j  the number of voters with preference order oi who are bribed to report preference
order oj .
si,j  the number of voters who, after the bribery, change their preference order from oi to
oj .
The values bi,i say how many voters with preferences oi are not bribed. The values si,i
say how many voters with preferences oi do not change their preferences. We have these
variables bi,i and si,i as they make our equations neater.
Recall that the Dodgson score is the number of adjacent switches within preference lists
that are needed to make a given candidate a Condorcet winner. However, the variables si,j
talk about much more complicated operations, namely transfers from preference order oi to
preference order oj . For each i, j, 1  i, j  m!, define a constant switches i,j which gives
the minimum number of adjacent switches that lead from preference order oi to preference

522

fiHow Hard Is Bribery in Elections?

order oj .13 For every preference order oi and every two candidates r and q we define
who(r, q, i) to be 1 if r strictly defeats q in the preference order oi and to be 1 otherwise.
who(r, r, i) = 1, but we will never invoke this fact. Our integer linear program has the
following constraints.
1. The number of bribes and switches has to be nonnegative. For each i, j, 1  i, j  m!,
we have
bi,j

 0, and

si,j

 0.

2. We cannot bribe more voters than there are. For each i, 1  i  m!, we require
m!
X

bi,j = kVi k.

j=1

3. Altogether, we can bribe at most k people.
m!
m! X
X

bi,j 

i=1 j=1

m!
X

b,  k.

=1

4. The number of voters who switch from preference order oi in the swapping phase
needs to be equal to the number of voters who, after the bribery, had preference order
oi . For each i, 1  i  m!,
m!
m!
X
X
si,k .
bj,i =
j=1

k=1

5. After the swapping phase, p is a Condorcet winner. For every q  C  {p},
m!
m! X
X

who(p, q, j )  si,j > 0.

i=1 j=1

6. The swapping phase involves at most t adjacent switches within preference lists.
m!
m! X
X

switches i,j  si,j  t.

i=1 j=1

13. The astute reader will note that to seek to meet or beat a given score for p under a given amount of
bribery, one would never need to in the Dodgson score calculation invoke any exchanges that do anything
except move p ahead some number of slots. This is true, and thus rather than our (m!)2 variables si,j ,
one could define an integer linear program that replaced the si,j s with (m!)(m1) variables that capture
just such shifting. We define things in the current more general way since the current approach removes
the dependence on a we can get away with just shifts of this sort argument of the type just made
(which would work fine here but might not hold in sharply different settings), and the current approach
also leads to quite simple, uncluttered constraint equations.

523

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Clearly, this program contains a constant number of variables and a constant number
of constraints. Thus in light of Lenstras algorithm the theorem is proven.

Theorem 5.5 For each fixed number of candidates, YoungScore-{succinct}-bribery is in P
when restricted to that number of candidates.
Proof. The proof is very similar to the proof of Theorem 5.4. Let t be a nonnegative
integer and let E = (C, V, p, k) be a bribery instance where C = {1, . . . , m}. We want to
provide an algorithm that tests whether it is possible to ensure that p has Young score at
most t by bribing at most k voters. We will do so by providing an integer linear program.
The workings of the integer linear program are be divided into two phases: the bribery
phase and the removal phase. The bribery is described by variables bi,j , 1  i, j  m!,
which say how many voters with preferences oi are bribed to have preferences oj . The
removal is described by variables ri , 1  i  m!, which say how many of the voters who
have preferences oi after the bribery are being removed. To enforce the above, we use the
following constraints:
1. The number of bribes and removals has to be nonnegative. For each i, j, 1  i, j  m!,
we have
 0, and

bi,j

ri  0.
2. We cannot bribe more voters than there are. For each i, 1  i  m!, we have
m!
X

bi,j = kVi k.

j=1

3. Altogether, we can only bribe at most k people.
m!
m! X
X

bi,j 

i=1 j=1

m!
X

b,  k.

=1

4. The number of voters with preference order oi who are removed from the election
during the removal phase has to be bounded by the number of voters who after the
bribery have preference order oi . For each i, 1  i  m!, we have
ri 

m!
X

bj,i .

j=1

5. After the removal phase, p is a Condorcet winner. For every q  C  {p},
!
!
m!
m!
X
X
bi,j  rj  who(p, q, j ) > 0.
j=1

i=1

524

fiHow Hard Is Bribery in Elections?

6. The removal phase removes at most t voters.
m!
X

ri  t.

i=1

Clearly, there are a constant number of variables and constraints, so the integer linear
program can be solved using Lenstras algorithm in polynomial time.

The above two theorems say that we can test in polynomial time whether a given bribe
suffices to obtain or beat a given Dodgson or Young score. Thus using binary search we
can in fact find the optimal bribe for obtaining a particular score.
The issue of actually making a candidate p a winner (a unique winner, if we are studying
the unique winner case) of Dodgson elections is, as already indicated, much more difficult
and a direct attack using integer linear programming seems to fail. Nonetheless, combining
the integer programming method with a brute-force algorithm resolves the issue for the
nonsuccinct case.
Theorem 5.6 For each fixed number of candidates, Dodgson-bribery, Dodgson-$bribery,
Young-bribery, and Young-$bribery are all in P.
Proof. As in Theorem 4.13, there are only polynomially many briberies we need to check.
For each of them we test whether our favorite candidate becomes a winner, using Bartholdi
et al.s (1989b) integer linear program for Dodgson score-testing or a similar one for Young
score-testing.

The above discussions of bribery with respect to Dodgson elections lead to an observation
that a small change in the voting system does allow us to resolve a natural bribery-related
winner problem. Note that bribes allow us to completely change a given voters preference
listand this goes far beyond the switches allowed by Dodgson score-counting. It is interesting to observe that one can define a Dodgson-like voting system based on bribes: Instead
of counting how many switches are needed to make a given candidate the Condorcet winner,
we count how many bribes (where each bribe is a complete overwrite, at unit cost, of one
voters preference list) suffice to guarantee such an outcome. We call this election system
Dodgson . By the above comments, for a fixed number of candidates computing winners of
Dodgson elections can be done in polynomial time.
Theorem 5.7 For each fixed number of candidates, the winner problem for succinct
Dodgson elections is in P.
Proof. This follows immediately from Theorem 5.4. For each candidate c we simply need
to binary search for the smallest bribe that makes him or her a Condorcet winner (i.e.,
gives c Dodgson score zero). The winners are those candidates for whom the least number
of bribes is needed.

Clearly, like Dodgson, Dodgson elects the Condorcet winner whenever one exists.
Theorem 5.7 shows that for each fixed number of candidates the winner problem in succinct
Dodgson elections is in P, and just before Definition 5.3 we noted that the same holds
for succinct Dodgson elections. As to which is more attractive, that will depend on what
one feels the more natural model is for counting distancecounting each adjacent switch
or counting each voter who had any change. In settings in which the latter seems more
525

fiFaliszewski, Hemaspaandra, & Hemaspaandra

attractive, of course Dodgson seems preferable to Dodgson. Nonetheless, before jumping
on any Dodgson bandwagon, one should probably first carefully study the properties of
the new election system. Note that even though computing Dodgson winners for a fixed
number of candidates is a polynomial-time procedure, this does not immediately imply that
the bribery problem is easy for Dodgson , and we conjecture that it is not.
In light of the above discussion, it might seem that for Dodgson-like election rules getting
polynomial-time bribery results (in the succinct model) is very difficult using integer linear
programming. However, this is not always the case. In particular, the following theorem
states that bribery in the Kemeny system is easy if we fix the number of candidates. Recall
that a candidate c is a winner of the Kemeny elections if there exists a preference order oh
that lists c on top and that agrees most strongly with the votes. (See Section 2.1.)
Theorem 5.8 For each fixed number of candidates, Kemeny-{succinct}-bribery is in P
when restricted to that number of candidates.
Proof. The proof employs integer linear programming, but this time we need more than
just one program. Very informally put, this is because integer linear programs seemingly
can express only conjunctions, but not disjunctions, and in the case of Kemeny elections
we need to express the fact that at least one of the preference orders that lists our favorite
candidate on top disagrees with the least number of voters preferences.14
Let E = (C, V, p, k) be a bribery instance for Kemeny elections, where C = {1, . . . , m}.
For each preference order oh , 1  h  m!, such that p is the top candidate in oh , we construct
a separate integer linear program that has a feasible solution if and only if there is a bribery
of at most k candidates after which oh is an ordering that maximizes (compared against all
other orders) the number of agreements with voters reported preferences. By agree i,j we
mean the number of agreements between preference orders oi and oj (see Section 2.1).
Let us consider an arbitrary h such that p is the top candidate in preference order oh .
We describe the bribery using variables bi,j , 1  i, j  m!, each saying how many voters
with preference order oi are bribed to have preference order oj . We employ the following
constraints.
1. The number of bribes has to be nonnegative. For each i, j, 1  i, j  m!, we have
bi,j  0.
2. We cannot bribe more voters than there are. For each i, 1  i  m!,
m!
X

bi,j = kVi k.

j=1

3. Altogether, we can only bribe at most k people.
m!
m! X
X

bi,j 

i=1 j=1

m!
X

b,  k.

=1

14. A natural way of expressing this disjunction within a single integer program is to use boolean variables
indicating which preference order we are concentrating on. However, this leads to an integer quadratic
program.

526

fiHow Hard Is Bribery in Elections?

bribery problem
E-bribery
E-$bribery
E-weightedunary -$bribery
E-weighted-bribery
E-weighted-$briberyunary
E-weighted-$bribery

plurality
P
P
P
P
P
NP-complete

election system E
approval
veto
NP-complete
P
NP-complete
P (Faliszewski, 2008)
NP-complete NP-complete (Brelsford et al., 2008)
NP-complete
NP-complete
NP-complete
NP-complete
NP-complete
NP-complete

Table 1: The complexity of bribery in plurality, approval, and veto (in the setting where
the number of candidates is not bounded). The results attributed to the work
of Brelsford et al. (2008) and Faliszewski (2008) follow via simple arguments from
results in those papers.

4. Each preference order o disagrees with voters preferences at least as many times as
oh . For each , 1    m!, we have




m!
m!
m!
m!
X
X
X
X
agree i,h 
bj,i  
agree i, 
bj,i  .
i=1

j=1

i=1

j=1

Clearly, each such integer program has a constant number of constraints and a constant
number of variables. Thus each can be solved separately, using Lenstras algorithm, in
polynomial time. And since there are just a constant numberm!of such integer linear
programs regarding a given input, by m! applications of Lenstras algorithm we can solve
all of them. If any one of them has a feasible solution then bribery is possible and otherwise
it is not.

It is interesting to consider which features of Kemeny elections allow us to employ the
above attack, given that the same approach does not seem to work for either Dodgson or
Young elections. One of the reasons is that the universal quantification implicit in Dodgson
and Young elections is over an exponentially large search space, but the quantification in
Kemeny is, in the case of a fixed candidate set, over a fixed number of options.

6. Conclusions
Our paper provides a study of bribery with respect to plurality rule and provides tools and
results regarding many other election systems, such as scoring protocols, approval voting,
and Condorcet-winner based elections. Bribery seems as important an issue as manipulation and control; our paper addresses this gap in our knowledge about the complexity of
voting systems. Tables 1 and 2 collect some of the main results of this paper regarding
the complexity of bribery in scoring protocols and related election systems. (However, of
course, the paper contains many other results which cannot easily be presented in a form
of a table, e.g., Theorem 4.19 and most of the results of Section 5.)
One of the important contributions of this paper is pointing out, by concrete examples,
that NP-completeness results may not guarantee the difficulty of the most natural problem
instances. In particular, Theorem 3.2 says that plurality-weighted-$bribery is NP-complete,
527

fiFaliszewski, Hemaspaandra, & Hemaspaandra

bribery problem
-bribery
-$bribery
-weightedunary -$bribery
-weighted-bribery
-weighted-$briberyunary
-weighted-$bribery

Scoring protocol  = (1 , . . . , m ).
1 > 2 and
not true that
1 =    = m 2 =    = m 2 =    = m
P
P
P
P
P
P
P
P
P
P
P
NP-complete
P
P
NP-complete
P
NP-complete
NP-complete

Table 2: The complexity of bribery within scoring protocols.
but Theorem 3.8 observes that if either the weights or the prices are small enough, the
problem can be solved efficiently.
Another contribution of this paper is to relate manipulation and bribery, thus making result transfer from the former to the latter a reasonable line of attackand one that is already
exploited in spirit in the proof approach of our central dichotomy result (Theorem 4.9).
As to suggested future work, we believe that studying approximation algorithms for
control (by voter/candidate addition/deletion) and bribery problems currently known to be
NP-complete would be an attractive next step and we point the reader to the recent papers
regarding approximation for manipulation, bribery, and control (Brelsford, 2007; Brelsford
et al., 2008; Faliszewski, 2008; Zuckerman et al., 2008). It would also be interesting to study
the complexity of bribery in other settings, such as with incomplete information, multiple
competing bribers, or more complicated bribe structures (see the work of Faliszewski, 2008,
for preliminary results on bribery with more involved pricing schemes).

Acknowledgments
We are very grateful to Samir Khuller for helpful conversations about the Bartholdi et al.
(1989b) integer programming attack on fixed-candidate Dodgson elections. We are also very
grateful to anonymous referees and Preetjot Singh for helpful comments. This work was
supported in part by grants NSF-CCR-0311021, NSF-CCF-0426761, NSF-IIS-0713061, and
AGH-UST 11.11.120.777, by Friedrich Wilhelm Bessel Research Awards to Edith Hemaspaandra and Lane A. Hemaspaandra, and by the Alexander von Humboldt Foundations
TransCoop program. This work was done in part while Piotr Faliszewski was at the University of Rochester. An early version of this paper, titled The Complexity of Bribery in
Elections, appeared in the proceedings of AAAI-06 (Faliszewski, Hemaspaandra, & Hemaspaandra, 2006) and was also presented at COMSOC-06 and NESCAI-07.

References
Bartholdi, III, J., Tovey, C., & Trick, M. (1989a). The computational difficulty of manipulating an election. Social Choice and Welfare, 6 (3), 227241.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989b). Voting schemes for which it can be
difficult to tell who won the election. Social Choice and Welfare, 6 (2), 157165.

528

fiHow Hard Is Bribery in Elections?

Bartholdi, III, J., Tovey, C., & Trick, M. (1992). How hard is it to control an election?
Mathematical and Computer Modeling, 16 (8/9), 2740.
Betzler, N., Fellows, M., Guo, J., Niedermeier, R., & Rosamond, F. (2008a). Fixedparameter algorithms for Kemeny scores. In Proceedings of the 4th International Conference on Algorithmic Aspects in Information and Management, pp. 6071. SpringerVerlag Lecture Notes in Computer Science #5034.
Betzler, N., Guo, J., & Niedermeier, R. (2008b). Parameterized computational complexity of
Dodgson and Young elections. In Proceedings of the 11th Scandinavian Workshop on
Algorithm Theory, pp. 402413. Springer-Verlag Lecture Notes in Computer Science
#5124.
Black, D. (1958). The Theory of Committees and Elections. Cambridge University Press.
Brelsford, E. (2007). Approximation and elections. Masters thesis, Rochester Institute of
Technology, Rochester, NY.
Brelsford, E., Faliszewski, P., Hemaspaandra, E., Schnoor, H., & Schnoor, I. (2008). Approximability of manipulating elections. In Proceedings of the 23rd AAAI Conference
on Artificial Intelligence, pp. 4449. AAAI Press.
Christian, R., Fellows, M., Rosamond, F., & Slinko, A. (2007). On complexity of lobbying
in multiple referenda. Review of Economic Design, 11 (3), 217224.
Condorcet, J. (1785). Essai sur lApplication de LAnalyse a la Probabilite des Decisions
Rendues a la Pluralite des Voix. Facsimile reprint of original published in Paris, 1972,
by the Imprimerie Royale.
Conitzer, V., & Sandholm, T. (2006). Nonexistence of voting rules that are usually hard to
manipulate. In Proceedings of the 21st National Conference on Artificial Intelligence,
pp. 627634. AAAI Press.
Conitzer, V., Sandholm, T., & Lang, J. (2007). When are elections with few candidates
hard to manipulate? Journal of the ACM, 54 (3), Article 14.
Dobzinski, S., & Procaccia, A. (2008). Frequent manipulability of elections: The case of two
voters. In Proceedings of the 4th International Workshop On Internet And Network
Economics, pp. 653664. Springer-Verlag Lecture Notes in Computer Science #5385.
Dodgson, C. (1876). A method of taking votes on more than two issues. Pamphlet printed
by the Clarendon Press, Oxford, and headed not yet published (see the discussions
in (McLean & Urken, 1995; Black, 1958), both of which reprint this paper).
Downey, R. (2003). Parameterized complexity for the skeptic. In Proceedings of the 18th Annual IEEE Conference on Computational Complexity, pp. 147168. IEEE Computer
Society Press.
Duggan, J., & Schwartz, T. (2000). Strategic manipulability without resoluteness or shared
beliefs: GibbardSatterthwaite generalized. Social Choice and Welfare, 17 (1), 8593.
Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methods for
the web. In Proceedings of the 10th International World Wide Web Conference, pp.
613622. ACM Press.

529

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Elkind, E., & Lipmaa, H. (2005a). Hybrid voting protocols and hardness of manipulation.
In Proceedings of the 16th Annual International Symposium on Algorithms and Computation, pp. 206215. Springer-Verlag Lecture Notes in Computer Science #3872.
Elkind, E., & Lipmaa, H. (2005b). Small coalitions cannot manipulate voting. In Proceedings
of the 9th International Conference on Financial Cryptography and Data Security, pp.
285297. Springer-Verlag Lecture Notes in Computer Science #3570.
Ephrati, E., & Rosenschein, J. (1997). A heuristic technique for multi-agent planning.
Annals of Mathematics and Artificial Intelligence, 20 (14), 1367.
Erdelyi, G., Hemaspaandra, L., Rothe, J., & Spakowski, H. Generalized juntas and NP-hard
sets. Theoretical Computer Science. To appear.
Erdelyi, G., Hemaspaandra, L., Rothe, J., & Spakowski, H. (2007). On approximating optimal weighted lobbying, and frequency of correctness versus average-case polynomial
time. In Proceedings of the 16th International Symposium on Fundamentals of Computation Theory, pp. 300311. Springer-Verlag Lecture Notes in Computer Science
#4639.
Erdelyi, G., Hemaspaandra, L., Rothe, J., & Spakowski, H. (2009). Frequency of correctness
versus average polynomial time. Information Processing Letters, 109 (16), 946949.
Erdelyi, G., Nowak, M., & Rothe, J. (2008a). Sincere-strategy preference-based approval
voting broadly resists control. In Proceedings of the 33rd International Symposium on
Mathematical Foundations of Computer Science, pp. 311322. Springer-Verlag Lecture
Notes in Computer Science #5162.
Erdelyi, G., Nowak, M., & Rothe, J. (2008b). Sincere-strategy preference-based approval
voting fully resists constructive control and broadly resists destructive control. Tech.
rep. arXiv:0806.0535 [cs.GT], arXiv.org. A precursor appears as (Erdelyi et al., 2008a).
Faliszewski, P. (2008). Nonuniform bribery (short paper). In Proceedings of the 7th International Conference on Autonomous Agents and Multiagent Systems, pp. 15691572.
International Foundation for Autonomous Agents and Multiagent Systems.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2006). The complexity of bribery
in elections. In Proceedings of the 21st National Conference on Artificial Intelligence,
pp. 641646. AAAI Press.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Llull and
Copeland voting broadly resist bribery and control. In Proceedings of the 22nd AAAI
Conference on Artificial Intelligence, pp. 724730. AAAI Press. Journal version available as (Faliszewski, Hemaspaandra, Hemaspaandra, & Rothe, 2009a).
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2008). Copeland voting
fully resists constructive control. In Proceedings of the 4th International Conference on
Algorithmic Aspects in Information and Management, pp. 165176. Springer-Verlag
Lecture Notes in Computer Science #5034.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009a). Llull and
Copeland voting broadly resist bribery and control. Journal of Artificial Intelligence
Research, 35, 275341.
530

fiHow Hard Is Bribery in Elections?

Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009b). A richer understanding of the complexity of election systems. In Ravi, S., & Shukla, S. (Eds.), Fundamental Problems in Computing: Essays in Honor of Professor Daniel J. Rosenkrantz,
pp. 375406. Springer.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: Ties matter.
In Proceedings of the 7th International Conference on Autonomous Agents and Multiagent Systems, pp. 983990. International Foundation for Autonomous Agents and
Multiagent Systems.
Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections can be manipulated often. In Proceedings of the 49rd IEEE Symposium on Foundations of Computer Science, pp. 243249.
IEEE Computer Society.
Garey, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory of
NP-Completeness. W. H. Freeman and Company.
Gibbard, A. (1973). Manipulation of voting schemes. Econometrica, 41 (4), 587601.
Hemaspaandra, E., & Hemaspaandra, L. (2007). Dichotomy for voting systems. Journal of
Computer and System Sciences, 73 (1), 7383.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (1997). Exact analysis of Dodgson
elections: Lewis Carrolls 1876 voting system is complete for parallel access to NP.
Journal of the ACM, 44 (6), 806825.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Anyone but him: The complexity
of precluding an alternative. Artificial Intelligence, 171 (5-6), 255285.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). Hybrid elections broaden
complexity-theoretic resistance to control. Mathematical Logic Quarterly, 55 (4), 397
424.
Hemaspaandra, E., Spakowski, H., & Vogel, J. (2005). The complexity of Kemeny elections.
Theoretical Computer Science, 349 (3), 382391.
Homan, C., & Hemaspaandra, L. (2009). Guarantees for the success frequency of an algorithm for finding Dodgson-election winners. Journal of Heuristics, 15 (4), 403423.
Kemeny, J. (1959). Mathematics without numbers. Daedalus, 88, 577591.
Kemeny, J., & Snell, L. (1960). Mathematical Models in the Social Sciences. Ginn.
Ladner, R., Lynch, N., & Selman, A. (1975). A comparison of polynomial time reducibilities.
Theoretical Computer Science, 1 (2), 103124.
Lenstra, Jr., H. (1983). Integer programming with a fixed number of variables. Mathematics
of Operations Research, 8 (4), 538548.
Martello, S., & Toth, P. (1990). Knapsack Problems: Algorithms and Computer Implementations. John Wiley and Sons.
McCabe-Dansted, J., Pritchard, G., & Slinko, A. (2008). Approximability of Dodgsons
rule. Social Choice and Welfare, 31 (2), 311330.
McLean, I., & Urken, A. (1995). Classics of Social Choice. University of Michigan Press.

531

fiFaliszewski, Hemaspaandra, & Hemaspaandra

Meir, R., Procaccia, A., Rosenschein, J., & Zohar, A. (2008). The complexity of strategic
behavior in multi-winner elections. Journal of Artificial Intelligence Research, 33,
149178.
Niedermeier, R. (2002). Invitation to fixed-parameter algorithms. Habilitation thesis, University of Tubingen.
Niedermeier, R. (2006). Invitation to Fixed-Parameter Algorithms. Oxford University Press.
Papadimitriou, C. (1994). Computational Complexity. Addison-Wesley.
Procaccia, A., & Rosenschein, J. (2007). Junta distributions and the average-case complexity
of manipulating elections. Journal of Artificial Intelligence Research, 28, 157181.
Rothe, J. (2005). Complexity Theory and Cryptology: An Introduction to Cryptocomplexity.
Springer-Verlag.
Rothe, J., Spakowski, H., & Vogel, J. (2003). Exact complexity of the winner problem for
Young elections. Theory of Computing Systems, 36 (4), 375386.
Saari, D., & Merlin, V. (2000). A geometric examination of Kemenys rule. Social Choice
and Welfare, 17 (3), 403438.
Satterthwaite, M. (1975). Strategy-proofness and Arrows conditions: Existence and correspondence theorems for voting procedures and social welfare functions. Journal of
Economic Theory, 10 (2), 187217.
Xia, L., & Conitzer, V. (2008). A sufficient condition for voting rules to be frequently
manipulable. In Proceedings of the 9th ACM Conference on Electronic Commerce,
pp. 99108. ACM Press.
Young, H. (1977). Extending Condorcets rule. Journal of Economic Theory, 16 (2), 335
353.
Zuckerman, M., Procaccia, A., & Rosenschein, J. (2008). Algorithms for the coalitional
manipulation problem. Artificial Intelligence, 173 (2), 392412.

532

fiJournal of Artificial Intelligence Research 35 (2009) 623-675

Submitted 10/08; published 08/09

Compiling Uncertainty Away in Conformant Planning
Problems with Bounded Width
Hector Palacios

hlp@ldc.usb.ve

Universitat Pompeu Fabra
Roc Boronat, 138
08018 Barcelona, SPAIN

Hector Geffner

hector.geffner@upf.edu

ICREA & Universitat Pompeu Fabra
Roc Boronat, 138
08018 Barcelona, SPAIN

Abstract
Conformant planning is the problem of finding a sequence of actions for achieving a goal
in the presence of uncertainty in the initial state or action effects. The problem has been
approached as a path-finding problem in belief space where good belief representations and
heuristics are critical for scaling up. In this work, a different formulation is introduced for
conformant problems with deterministic actions where they are automatically converted
into classical ones and solved by an off-the-shelf classical planner. The translation maps
literals L and sets of assumptions t about the initial situation, into new literals KL/t that
represent that L must be true if t is initially true. We lay out a general translation scheme
that is sound and establish the conditions under which the translation is also complete. We
show that the complexity of the complete translation is exponential in a parameter of the
problem called the conformant width, which for most benchmarks is bounded. The planner
based on this translation exhibits good performance in comparison with existing planners,
and is the basis for T0 , the best performing planner in the Conformant Track of the 2006
International Planning Competition.

1. Introduction
Conformant planning is a form of planning where a goal is to be achieved when the initial
situation is not fully known and actions may have non-deterministic effects (Goldman &
Boddy, 1996; Smith & Weld, 1998). Conformant planning is computationally harder than
classical planning, as even under polynomial restrictions on plan length, plan verification
remains hard (Haslum & Jonsson, 1999; Baral, Kreinovich, & Trejo, 2000; Turner, 2002;
Rintanen, 2004). While few practical problems are purely conformant, the ability to find
conformant plans is needed in contingent planning where conformant situations are a special
case and where relaxations into conformant planning yield useful heuristics (Hoffmann &
Brafman, 2005).
The problem of conformant planning can be formulated as a path-finding problem in
belief space where a sequence of actions that map a given initial belief state into a target
belief is sought (Bonet & Geffner, 2000). A belief state represents the set of states that
are deemed possible, and actions, whether deterministic or not, map one belief state into
c
2009
AI Access Foundation. All rights reserved.

fiPalacios & Geffner

another. This formulation, that underlies most current conformant planners (Hoffmann &
Brafman, 2006; Bryce, Kambhampati, & Smith, 2006; Cimatti, Roveri, & Bertoli, 2004)
must address two problems: the problem of representing beliefs in a compact way, and the
problem of obtaining effective heuristics over beliefs. The first problem has been approached
through logical representations that make use of SAT or OBDD technology, that while
intractable in the worst case, scale up better than plain state representations. The second
problem, on the other hand, has been more complex, with heuristics for searching in belief
space not being as successful so far as the heuristics developed for classical planning (Bonet
& Geffner, 2001; Hoffmann & Nebel, 2001).
In this work, we introduce a different approach to conformant planning where problems
are automatically compiled into classical problems and solved by a classical planner. The
translation maps sets of literals t about the initial situation and literals L into new literals
KL/t that express that if t is true in the initial situation, L must be true. We lay out first a
general translation scheme that is sound and then establish the conditions under which the
translation is also complete. Also, we show that the complexity of the complete translation
is exponential in a parameter of the problem that we call the conformant width, which
for most benchmark domains is bounded, implying that the complete translation in those
cases is polynomial. The planner based on this translation exhibits good performance in
comparison with existing conformant planners and is the basis for T0 , the best performing
planner in the Conformant Track of the 2006 International Planning Competition.
The translation-based approach provides a solution to the two problems faced by conformant planners that search in belief space: the belief representation and the heuristic over
beliefs. In the translation-based approach, the beliefs are represented by the literals KL/t
that stand for conditionals, a representation that is polynomial and complete for conformant problems with bounded width. In addition, and since belief states are represented as
plain states, the heuristic over beliefs is a classical heuristic. From a computational point
of view, though, there is no explicit search in belief-space: conformant problems P are
converted into classical problems K(P ) at the knowledge-level (Petrick & Bacchus, 2002),
whose solutions, computed by a classical planner, encode the conformant solutions for P .
Our formulation is limited to conformant problems that are deterministic and where
all uncertainty lies in the initial situation. We address nonetheless the issues that must be
handled in order to generalize the translation-based approach to non-deterministic domains
and report empirical results over non-deterministic domains as well.
The paper is organized as follows. We define first the syntax and semantics of conformant
planning problems P (Section 2), and consider a simple sound but incomplete translation
K0 (Section 3). We then consider a more general translation scheme KT,M where T and
M are two parameters, a set of tags t encoding assumptions about the initial situation,
and a set of merges m encoding valid disjunctions of tags (Section 4), and analyze several
instances of this scheme that follow from particular choices of the sets of tags and merges:
a complete but exponential translation KS0 where tags are associated with the possible
initial states of the problem (Section 5), and a polynomial translation Ki for a fixed integer
i  0 that is complete for problems with conformant width bounded by i (Section 6).
We provide then an alternative explanation for this compact but complete translation by
showing that in problems with bounded width, the exponential number of possible initial
states S0 includes always a polynomial number of critical initial states S00 such that plans
624

fiCompiling Uncertainty Away in Conformant Planning Problems

that conform with S00 conform also with S0 (Section 7). We finally present the conformant
planner T0 (Section 8), an empirical evaluation of the planner (Section 9), an extension to
non-deterministic actions (Section 10), and a discussion of related work (Section 11). This
is followed by a brief summary (Section 12) and the formal proofs (Appendix).
This work is a revision and extension of the formulation presented by Palacios and
Geffner (2007), which in turn is based on ideas first sketched also by Palacios and Geffner
(2006).

2. The Conformant Problem P
We define next the syntax and semantics of the conformant planning problems considered.
2.1 Syntax
Conformant planning problems P are represented as tuples of the form P = hF, I, O, Gi
where F stands for the fluent symbols in the problem, I is a set of clauses over F defining
the initial situation, O stands for a set of (ground) operators or actions a, and G is a set of
literals over F defining the goal. Every action a has a precondition P re(a) given by a set
of fluent literals, and a set of conditional effects C  L where C is a set of fluent literals
and L is a fluent literal.
All actions are assumed to be deterministic and hence all uncertainty lies in the initial
situation. Thus, the language for the conformant problem P excluding the uncertainty in
the initial situation, is Strips extended with conditional effects and negation. Moreover, if
there is no uncertainty in the initial situation, as when all fluents appear in unit clauses in
I, P is equivalent to a classical planning problem.
We refer to the conditional effects C  L of an action a as the rules associated with
a, and sometimes write them as a : C  L. When convenient, we also join several effects
associated with the same action and condition as in a : C  L  L0 and write C  L as
true  L when C is empty. Finally, for a literal L, L denotes the complement of L.
2.2 Semantics
A state s is a truth assignment over the fluents F in P = hF, I, O, Gi and a possible initial
state s of P is a state that satisfies the clauses in I.
For a state s, we write I(s) to refer to the set of atoms (positive literals) that are true
in s, and write P/s to refer to the classical planning problem P/s = hF, I(s), O, Gi which
is like the conformant problem P except for the initial state that is fixed to s.
An action sequence  = {a0 , a1 , . . . , an } is a classical plan for P/s if the action sequence
 is executable in the state s and results in a goal state sG ; i.e., if for i = 0, . . . , n, the
preconditions of the action ai are true in si , si+1 is the state that results from doing action
ai in the state si , and all goal literals are true in sn+1 .
Finally, an action sequence  is a conformant plan for P iff  is a classical plan for P/s
for every possible initial state s of P .
Conformant planning is computationally harder than classical planning, as plan verification remains hard even under polynomial restrictions on plan length (Haslum & Jonsson,
1999; Baral et al., 2000; Turner, 2002; Rintanen, 2004). The most common approach to
625

fiPalacios & Geffner

conformant planning is based on the belief state formulation (Bonet & Geffner, 2000). A
belief state b is the non-empty set of states that are deemed possible in a given situation,
and every action a executable in b, maps b into a new belief state ba . The conformant
planning task becomes a path-finding problem in a graph where the nodes are belief states
b, the source node b0 is the belief state corresponding to the initial situation, and the target
belief states bG are those where the goals are true.
We assume throughout that I is logically consistent, so that the set of possible initial
states is not empty, and that P itself is consistent, so that the bodies C and C 0 of conflicting
effects a : C  L and a : C 0  L associated with the same action a are mutually exclusive
or mutex. For further details on this; see Part B of the Appendix.

3. A Basic Translation K0
A simple translation of the conformant problem P into a classical problem K(P ) can be
obtained by replacing the literals L by literals KL and KL aimed at capturing whether
L is known to be true and known to be false respectively.
Definition 1 (Translation K0 ). For a conformant planning problem P = hF, I, O, Gi, the
translation K0 (P ) = hF 0 , I 0 , O0 , G0 i is a classical planning problem with
 F 0 = {KL, KL | L  F }
 I 0 = {KL | L is a unit clause in I}
 G0 = {KL | L  G}
 O0 = O but with each precondition L for a  O replaced by KL, and each conditional
effect a : C  L replaced by a : KC  KL and a : KC  KL,
where the expressions KC and KC for C = L1 , L2 . . . are abbreviations of the formulas
KL1 , KL2 . . . and KL1 , KL2 . . . respectively.
The intuition behind the translation is simple: first, the literal KL is true in the initial
state I 0 if L is known to be true in I; otherwise it is false. This removes all uncertainty
from K0 (P ), making it into a classical planning problem. In addition, for soundness, each
rule a : C  L in P is mapped into two rules: a support rule a : KC  KL, that ensures
that L is known to be true when the condition is known to be true, and a cancellation
rule a : KC  KL that guarantees that KL is deleted (prevented to persist) when
action a is applied and C is not known to be false. The use of support and cancellation rules
for encoding the original rules at the knowledge-level is the only subtlety in the translation.
The translation K0 (P ) is sound as every classical plan that solves K0 (P ) is a conformant
plan for P , but is incomplete, as not all conformant plans for P are classical plans for K(P ).
The meaning of the KL literals follows a similar pattern: if a plan achieves KL in K0 (P ),
then the same plan achieves L with certainty in P , yet a plan may achieve L with certainty
in P without making the literal KL true in K0 (P ).1
Proposition 2 (Soundness of K0 (P )). If  is a classical plan for K0 (P ), then  is a
conformant plan for P .
1. Formal proofs can be found in the appendix.

626

fiCompiling Uncertainty Away in Conformant Planning Problems

As an illustration, consider the conformant problem P = hF, I, O, Gi with F = {p, q, r},
I = {q}, G = {p, r}, and actions O = {a, b} with effects
a : q  r , a : p  p , b : q  p .
For this problem, the action sequence  = {a, b} is a conformant plan for P while the action
sequence  0 = {a} is not. Indeed,  is a classical plan for P/s for any possible initial state
s, while  0 is not a classical plan for the possible initial state s0 where p is true (recall that
s is a possible initial state of P if s satisfies I so that neither p nor r are assumed to be
initially false in this problem).
From Definition 1, the translation K0 (P ) = hF 0 , I 0 , O0 , G0 i is a classical planning problem
with fluents F 0 = {Kp, Kp, Kq, Kq, Kr, Kr}, initial situation I 0 = {Kq}, goals G0 =
{Kp, Kr}, and actions O0 = {a, b} with effects
a : Kq  Kr , a : Kp  Kp , b : Kq  Kp,
that encode supports, and effects
a : Kq  Kr , a : Kp  Kp , b : Kq  Kp,
that encode cancellations.
Proposition 2 implies, for example, that  0 = {a}, which is not a conformant plan for
P , cannot be a classical plan for K(P ) either. This is easy to verify, as while the support
a : Kq  Kr achieves the goal Kr as Kq is true in I 0 , the cancellation a : Kp  Kp
associated with the same action, preserves Kp false for the other goal p.
While the translation K0 is not complete, meaning that it fails to capture all conformant plans for P as classical plans, its completeness can be assessed in terms of a weaker
semantics. In the so-called 0-approximation semantics (Baral & Son, 1997), belief states b
are represented by 3-valued states where fluents can be true, false, or unknown. In this incomplete belief representation, checking whether an action a is applicable in a belief state b,
computing the next belief state ba , and verifying polynomial length plans are all polynomial
time operations. In particular, a literal L is true it the next belief state ba iff a) action a
has some effect C  L such that all literals in C are true in b, or b) L is true in b and for all
effects C 0  L of action a, the complement of some literal L0  C 0 is true in b. An action
sequence  is then a conformant plan for P according to the 0-approximation semantics if
the belief sequence generated by  according to the 0-approximation semantics makes the
action sequence applicable and terminates in a belief state where the goals are true. It is
possible to prove then that:
Proposition 3 (K0 (P ) and 0-Approximation). An action sequence  is a classical plan for
K0 (P ) iff  is a conformant plan for P according to the 0-approximation semantics.
This correspondence is not surprising though as both the 0-approximation semantics
and the K0 (P ) translation throw away the disjunctive information and restrict the plans to
those that make no use of the uncertain knowledge. Indeed, the states s0 , s1 , . . . generated
by the action sequence  = {a0 , a1 , . . .} over the classical problem K0 (P ) encode precisely
627

fiPalacios & Geffner

the literals that are known to be true according to the 0-approximation; namely, L is true
at time i according to the 0-approximation iff the literal KL is true in the state si .
Proposition 3 does not mean that the basic translation K0 and the 0-approximation
semantics are equivalent but rather that they both rely on equivalent belief representations.
The translation K0 delivers also a way to get valid conformant plans using a classical
planner. The translation-based approach thus addresses both the representational and the
heuristic issues that arise in conformant planning.
As an illustration of Proposition 3, given a conformant problem P with I = {p, r} and
actions a and b with effects a : p  q, a : r  v, and b : q  v, the plan  = {a, b} is valid
for achieving the goal G = {q, v} according to both K0 (P ) and the 0-approximation, while
the plan  = {b} is not valid according to either. At the same time, if the initial situation
is changed to I = {p  q}, neither approach sanctions the plan  = {a} for G = {q}, even if
it is a valid conformant plan. For this, some ability to reason with disjunctions is needed.
An extension of the basic translation K0 that allows a limited form of disjunctive reasoning is presented by Palacios and Geffner (2006). The extension is based on the introduction
of new literals L/Xi used for encoding the conditionals Xi  L. Below, the basic translation
K0 is extended in a different manner that ensures both tractability and completeness over
a large class of problems.

4. General Translation Scheme KT,M
The basic translation K0 is extended now into a general translation scheme KT,M where T
and M are two parameters: a set of tags t and a set of merges m. We will show that for
suitable choices of these two parameters, the translation KT,M , unlike the translation K0 ,
can be both sound and complete.
A tag t  T is a set (conjunction) of literals L from P whose truth value in the initial
situation is not known. The tags t are used to introduce a new class of literals KL/t in
the classical problem KT,M (P ) that represent the conditional if t is true initially, then L is
true, an assertion that could be written as K(t0  L) in a temporal modal logic. We use
the notation KL/t rather than L/t as used by Palacios and Geffner (2006), because there
is a distinction between KL/t and KL/t: roughly KL/t means that the conditional
K(t0  L) is not true, while KL/t means that the conditional K(t0  L) is true.
Likewise, a merge m is a non-empty
W collection of tags t in T that stands for the Disjunctive Normal Form (DNF) formula tm t. A merge m is valid when one of the tags t  m
must be true in I; i.e., when
_
I |=
t .
tm

A merge m for a literal L in P will translate into a merge action with a single effect
^
KL/t  KL
tm

that captures a simple form of reasoning by cases.
While a valid merge can be used for reasoning about any literal L in P , computationally
it is convenient (although not logically necessary) to specify that certain merges are to be
used with some literals L and not with others. Thus, formally, M is a collection of pairs
628

fiCompiling Uncertainty Away in Conformant Planning Problems

(m, L), where m is a merge and L is a literal in P . Such a pair means that m is a merge for
L. We group all the merges m for a literal L in the set ML , and thus, M can be understood
as the collection of such sets ML for all L in P . For simplicity, however, except when it
may cause a confusion, we will keep referring to M as a plain set of merges.
We assume that the collection of tags T always includes a tag t that stands for the
empty collection of literals, that we call the empty tag and denote it as . If t is the empty
tag, we denote KL/t simply as KL.
The translation KT,M (P ) is the basic translation K0 (P ) conditioned with the tags t in
T and extended with the actions that capture the merges in M :
Definition 4 (Translation KT,M ). Let P = hF, I, O, Gi be a conformant problem, then
KT,M (P ) is the classical planning problem KT,M (P ) = hF 0 , I 0 , O0 , G0 i with
 F 0 = {KL/t, KL/t | L  F and t  T }
 I 0 = {KL/t | I, t |= L}
 G0 = {KL | L  G}
 O0 = {a V
: KC/t  KL/t, a : KC/t  KL/t | a : C  L in P } 
{am,L : [ tm KL/t]  KL  XL | L  P, m  ML }
where KL is a precondition of action a in KT,M (P ) if L is a precondition of a in P , KC/t
and KC/t stand for KL1 /t, KL2 /t,
V . . . , and KL1 /t, KL2 /t, . . . respectively, when
C = L1 , L2 , . . ., and XL stands for L0 KL0 with L0 ranging over the literals L0 mutex
with L in P .
The translation KT,M (P ) reduces to the basic translation
K0 (P ) when M is empty and
V
T contains only the empty tag. The extra effects XL = L0 KL0 in the merge actions am,L
are needed only to ensure that the translation KT,M (P ) is consistent when P is consistent,
and otherwise can be ignored. Indeed, if L and L0 are mutex in a consistent P , the invariant
KL/t  KL0 /t holds in KT,M (P ) for non-empty tags t, and hence a successful merge for
L can always be followed by a successful merge for L0 . In the rest of the paper we will
thus assume that both P and KT,M (P ) are consistent, and ignore such extra merge effects,
but we will come back to them in Appendix B for proving the consistency of KT,M (P ) from
the consistency of P .
For suitable choices of T and M , the translation KT,M (P ) will be sound and complete.
Before establishing these results, however, let us make these notions precise.
Definition 5 (Soundness). A translation KT,M (P ) is sound if for any classical plan  that
solves the classical planning problem KT,M (P ), the plan  0 that results from  by dropping
the merge actions is a conformant plan for P .
Definition 6 (Completeness). A translation KT,M (P ) is complete if for any conformant
plan  0 that solves the conformant problem P , there is a classical plan  that solves the
classical problem KT,M (P ) such that  0 is equal to  with the merge actions removed.
The general translation scheme KT,M is sound provided that all merges are valid and
all tags are consistent (literals in a tag are all true in some possible initial state):
629

fiPalacios & Geffner

Theorem 7 (Soundness KT,M (P )). The translation KT,M (P ) is sound provided that all
merges in M are valid and all tags in T are consistent.
Unless stated otherwise, we will assume that all merges are valid and all tags consistent,
and will call such translations, valid translations.
As a convention for keeping the notation simple, in singleton tags like t = {p}, the curly
brackets are often dropped. Thus, literals KL/t for t = {p} are written as KL/p, while
merges m = {t1 , t2 } for singleton tags t1 = {p} and t2 = {q}, are written as m = {p, q}.
Example. As an illustration, consider the problem of moving an object from an origin to a
destination using two actions: pick(l), that picks up an object from a location if the hand is
empty and the object is in that location, and drop(l), that drops the object at a location if
the object is being held. For making the problem more interesting, let us also assume that
the action pick(l) drops the object being held at l if the hand is not empty. These are all
conditional effects and there are no action preconditions. Assuming that there is a single
object, these effects can be written as:
pick(l) : hold, at(l)  hold  at(l)
pick(l) : hold  hold  at(l)
drop(l) : hold  hold  at(l) .
Consider now an instance P of this domain, where the hand is initially empty and the
object, initially at either l1 or l2 , must be moved to l3 ; i.e., P = hF, I, O, Gi with
I = {hold , at(l1 )  at(l2 ) , at(l1 )  at(l2 ) , at(l3 )}
and
G = {at(l3 )} .
The action sequence
1 = {pick(l1 ), drop(l3 ), pick(l2 ), drop(l3 )}
is a conformant plan for this problem, where an attempt to pick up the object at location
l1 is followed by a drop at the target location l3 , ensuring that the object ends up at l3 if
it was originally at l1 . This is then followed by an attempt to pick up the object at l2 and
a drop at l3 .
On the other hand, the action sequence 2 that results from 1 by removing the first
drop action
2 = {pick(l1 ), pick(l2 ), drop(l3 )}
is not a conformant plan, since if the object was originally at l1 , it would end up at l2 after
the action pick(l2 ). In the notation introduced above, 1 is a classical plan for the classical
problem P/s for the two possible initial states s, while 2 is a classical plan for the problem
P/s but only for the state s where the object is initially at l2 .
630

fiCompiling Uncertainty Away in Conformant Planning Problems

Consider now the classical problem KT,M (P ) = hF 0 , I 0 , O0 , G0 i that is obtained from P
when T = {at(l1 ), at(l2 )}2 and M contains the merge m = {at(l1 ), at(l2 )} for the literals
hold and at(l3 ). From its definition, the fluents F 0 in KT,M (P ) are of the form KL/t and
KL/t for L  {at(l), hold}, l  {l1 , l2 }, and t  T , while the initial situation I 0 is
I 0 = {Khold, Khold/at(l), Kat(l3 ), Kat(l3 )/at(l), Kat(l)/at(l), Kat(l0 )/at(l)}
for l, l0  {l1 , l2 } and l0 6= l, and the goal G0 is
G0 = {Kat(l3 )} .
The effects associated to the actions pick(l) and drop(l) in O0 are the support rules
pick(l) : Khold, Kat(l)  Khold  Kat(l)
pick(l) : Khold  Khold  Kat(l)
drop(l) : Khold  Khold  Kat(l)
for each one of the three locations l = li , that condition each rule in O with the empty tag,
along with the support rules:
pick(l) : Khold/at(l0 ), Kat(l)/at(l0 )  Khold/at(l0 )  Kat(l)/at(l0 )
pick(l) : Khold/at(l0 )  Khold/at(l0 )  Kat(l)/at(l0 )
drop(l) : Khold/at(l0 )  Khold/at(l0 )  Kat(l)/at(l0 )
that condition each rule in O with the tags at(l0 )  T , for l0  {l1 , l2 }. The corresponding
cancellation rules are:
pick(l) : Khold, Kat(l)  Khold  Kat(l)
pick(l) : Khold  Khold  Kat(l)
drop(l) : Khold  Khold  Kat(l)
and
pick(l) : Khold/at(l0 ), Kat(l)/at(l0 )  Khold/at(l0 )  Kat(l)/at(l0 )
pick(l) : Khold/at(l0 )  Khold/at(l0 )  Kat(l)/at(l0 )
drop(l) : Khold/at(l0 )  Khold/at(l0 )  Kat(l)/at(l0 ) .
In addition, the actions in O0 include the merge actions am,hold and am,at(l3 ) that follow
from the merge m = {at(l1 ), at(l2 )} in M for the literals hold and at(l3 ):
am,hold : Khold/at(l1 ), Khold/at(l2 )  Khold
am,at(l3 ) : Kat(l3 )/at(l1 ), Kat(l3 )/at(l2 )  Kat(l3 ) .
2. The empty tag is assumed in every T and thus it is not mentioned explicitly.

631

fiPalacios & Geffner

It can be shown then that the plan
10 = {pick(l1 ), drop(l3 ), pick(l2 ), drop(l3 ), am,at(l3 ) }
solves the classical problem KT,M (P ) and hence, from Theorem 7, that the plan 1 obtained
from 10 by dropping the merge action, is a valid conformant plan for P (shown above). We
can see how some of the literals in KT,M (P ) evolve as the actions in 10 are executed:
0:
1:
2:
3:
4:
5:

Kat(l1 )/at(l1 ), Kat(l2 )/at(l2 )
Khold/at(l1 ), Kat(l2 )/at(l2 )
Kat(l3 )/at(l1 ), Kat(l2 )/at(l2 )
Kat(l3 )/at(l1 ), Khold/at(l2 )
Kat(l3 )/at(l1 ), Kat(l3 )/at(l2 )
Kat(l3 )

true
true
true
true
true
true

in I 0
after
after
after
after
after

pick(l1 )
drop(l3 )
pick(l2 )
drop(l3 )
merge am,at(l3 ) .

We can also verify in the same manner that the action sequence 20
20 = {pick(l1 ), pick(l2 ), am,hold , drop(l3 )}
is not a classical plan for KT,M (P ), the reason being that the atom Khold/at(l1 ) holds after
the first pick up action but not after the second. This is due to the cancellation rule:
pick(l2 ) : Khold/at(l1 )  Khold/at(l1 )  Kat(l2 )/at(l1 )
that expresses that under the assumption at(l1 ) in the initial situation, hold and at(l2 )
are not known to be true after the action pick(l2 ), if under the same assumption, hold
was not known to be true before the action.

5. A Complete Translation: KS0
A complete instance of the translation scheme KT,M can be obtained in a simple manner
by setting the tags to the possible initial states of the problem P and by having a merge
for each precondition and goal literal L that includes all these tags. We call the resulting
exhaustive translation KS0 :
Definition 8 (Translation KS0 ). For a conformant problem P , the translation KS0 (P ) is
an instance of the translation KT,M (P ) where
 T is set to the union of the empty tag and the set S0 of all possible initial states of P
(understood as the maximal sets of literals that are consistent with I), and
 M is set to contain a single merge m = S0 for each precondition and goal literal L in
P.
The translation KS0 is valid and hence sound, and it is complete due the correspondence
between tags and possible initial states:
Theorem 9 (Completeness of KS0 ). If  is a conformant plan for P , then there is a
classical plan  0 for KS0 (P ) such that  is the result of dropping the merge actions from  0 .

632

fiCompiling Uncertainty Away in Conformant Planning Problems

#S0
Problem
adder-01
blocks-02
blocks-03
bomb-10-1
bomb-10-5
bomb-10-10
bomb-20-1
coins-08
coins-09
coins-10
coins-11
comm-08
comm-09
comm-10
corners-square-16
corners-square-24
corners-square-28
corners-square-116
corners-square-120
square-center-16
square-center-24
log-2-10-10
log-3-10-10
ring-5
ring-6
safe-50
safe-70
safe-100
sortnet-07
sortnet-08
sortnet-09
sortnet-10
uts-k-08
uts-k-10

18
18
231
1k
1k
1k
1M
1k
1k
1k
1M
512
1k
2k
4
4
4
4
4
256
576
1k
59k
1,2k
4,3k
50
70
100
256
512
1k
2k
16
20

KS0
time
len
> 2h
0,2
23
59,2
80
5,9
19
11,3
15
18,3
10
> 2.1GB
20,2
27
19,9
25
21,5
31
> 2.1GB
18,3
61
77,7
68
> 2.1GB
0,2
102
0,7
202
1,2
264
581,4 3652
> 2.1GB
13,1
102
> 2.1GB
183,5
85
> 2h
12,6
17
> 2.1GB
0,5
50
1,4
70
6
100
2,9
28
9,8
36
77,7
45
> 2.1GB
0,6
46
1,2
58

POND
time len
0,4
26
0,4
26
126,8 129
1
19
3
15
8
10
4139
39
2
28
5
26
5
28
> 2h
1
53
1
59
1
65
1131
67
> 2h
> 2h
> 2h
> 2h
1322
61
> 2h
> 2h
> 2h
6
20
33
27
9
50
41
70
> 2.1GB
480
25
> 2h
> 2h
> 2h
24
47
2219
67

CFF
time
len
> 2h
> 2h
> 2h
0
19
0
15
0
10
0
39
0
28
0
26
0,1
38
1
78
0
53
0
59
0
65
13,1
140
321
304
> 2h
> 2h
> 2h
> 2h
> 2h
1,6
83
4,7
108
4,3
31
93,6
48
29,4
50
109,9
70
1252,4 100
SNH
SNH
SNH
SNH
4,4
46
16,5
58

Table 1: KS0 translation fed into FF planner compared with POND and Conformant FF
(CFF) along both times and reported plan lengths. #S0 stands for number of
initial states, SNH means goal syntax not handled (by CFF). Times reported in
seconds and rounded to the closest decimal.

633

fiPalacios & Geffner

For problems P whose actions have no preconditions, the argument is simple: if  is
a conformant plan for P then  must be a classical plan for P/s for each possible initial
state s, but then if  achieves the (goal) literal Gi in P/s for each s,  must achieve the
literal KGi /s in KS0 (P ) for each s as well, so that  followed by the merge action for Gi ,
must achieve the literal KGi . In the presence of action preconditions, this argument must
be applied inductively on the plan length, but the idea remains the same (see the proof
in the appendix for details): a correspondence can be established between the evolution of
the fluents L in each problem P/s and the evolution of the fluents KL/s in the problem
KS0 (P ).
The significance of the exhaustive KS0 translation is not only theoretical. There are
plenty of conformant problems that are quite hard for current planners even if they involve
a handful of possible initial states. An example of this is the Square-Center-n task (Cimatti
et al., 2004), where an agent has to reach the center of an empty square grid with certainty,
not knowing its initial location. There are four actions that move the agent one unit in each
direction, except when in the border of the grid, where they have no effects. In the standard
version of the problem, the initial position is fully unknown resulting in n2 possible initial
states, yet the problem remains difficult, and actually beyond the reach of most planners,
for small values of n, even when the uncertainty is reduced to a pair of possible initial states.
The reason is that the agent must locate itself before heading for the goal. The domain
Corners-Square-n in Table 1 is a variation of Square-Center-n where the possible initial
states are the four corners of the grid.
Table 1 shows results for a conformant planner based on the KS0 (P ) translation that
uses FF (Hoffmann & Nebel, 2001) for solving the resulting classical problem, and compares
it with two of the planners that entered the Conformant track of the 2006 Int. Planning
Competition (Bonet & Givan, 2006): POND (Bryce et al., 2006) and Conformant FF
(Hoffmann & Brafman, 2006) (the other two planners in the competition were translationbased: T0 , based on the formulation developed in this paper, and K(P ), based on an earlier
and more restricted formulation due to Palacios & Geffner, 2006). Clearly, the approach
based on the KS0 (P ) translation does not scale up to problems with many possible initial
states, yet when the number of such states is small, it does quite well.

6. Complete Translations that May be Compact Too
In order to have complete translations that are polynomial, certain assumptions about the
formulas in the initial situation I need to be made. Otherwise, just checking whether a
goal is true in I is intractable by itself, and therefore a polynomial but complete translation
would be impossible (unless P = NP). We will thus assume that I is in prime implicate (PI)
form (Marquis, 2000), meaning that I includes only the inclusion-minimal clauses that it
entails but no tautologies. It is known that checking whether a clause follows logically from
a formula I in PI form reduces to checking whether the clause is subsumed by a clause in
I or is a tautology, and hence is a polynomial operation. The initial situations I in most
benchmarks is in P I form or can easily be cast into PI form as they are normally specified
by means of a set of non-overlapping oneof (X1 , . . . , Xn ) expressions that translate into
clauses X1      Xn and binary clauses Xi  Xj for i 6= j where any resolvent is a
tautology.
634

fiCompiling Uncertainty Away in Conformant Planning Problems

6.1 Conformant Relevance
The translation KS0 (P ) is complete but introduces a number of literals KL/t that is exponential in the worst case: one for each possible initial state s0 . This raises the question: is
it possible to have complete translations that are not exhaustive in this sense? The answer
is yes and in this section we provide a simple condition that ensures that a translation
KT,M (P ) is complete. It makes use of the notion of relevance:3
Definition 10 (Relevance). The conformant relevance relation L  L0 in P , read L is
relevant to L0 , is defined inductively as
1. L  L
2. L  L0 if a : C  L0 is in P with L  C for some action a in P
3. L  L0 if L  L00 and L00  L0
4. L  L0 if L  L00 and L00  L0 .
The first clause stands for reflexivity, the third for transitivity, the second captures conditions that are relevant to the effect, and the fourth, the conditions under which L preempts
conditional effects that may delete L0 . If we replace 4 by
4 L  L0 if L  L0
which is equivalent to 4 in the context of 13, the resulting definition is the one by Son and
Tu (2006), where the notion of relevance is used to generate a limited set of possible partial
initial states over which the 0-approximation is complete (see Section 11 for a discussion on
the relation between tags and partial initial states).
Notice that according to the definition, a precondition p of an action a is not taken to
be relevant to an effect q. The reason is that we want the relation L  L0 to capture the
conditions under which uncertainty about L is relevant to the uncertainty about L0 . This is
why we say this is a relation of conformant relevance. Preconditions must be known to be
true in order for an action to be applied, so they do not introduce nor propagate uncertainty
into the effects of an action.
If we let CI stand for the set of clauses representing uncertainty about the initial situation, namely, the non-unit clauses in I along with the tautologies L  L for complementary
literals L and L not appearing as unit clauses in I, the notion of (conformant) relevance
can be extended to clauses as follows:
Definition 11 (Relevant Clauses). A clause c  CI is relevant to a literal L in P if all
literals L0  c are relevant to L. The set of clauses in CI relevant to L is denoted as CI (L).
Having a representation of the uncertainty in the initial situation that is relevant to a
literal L, it is possible to analyze the completeness of a translation KT,M in terms of the
relation between the merges m for the literals L, on one hand, and the sets of clauses CI (L)
that are relevant to L on the other.
3. While we follow an earlier account (Palacios & Geffner, 2007), many of the definitions and theorems
differ in a number of details (for example, the notion of relevance depends on the rules in P but not on
the clauses in the initial situation). The changes are aimed at making the resulting formulation simpler
and cleaner.

635

fiPalacios & Geffner

6.2 Covering Translations
It may appear that a translation KT,M would be complete when
W the merges m for precondition and goal literals L, understood as the DNF formulas tm t, contain as much
information, and thus are equivalent to the CNF formula CI (L) that captures the fragment
of the initial situation I that is relevant to L. This intuition is partially correct, but misses
one important point; namely that not every DNF formula equivalent to CI (L) will do: the
DNF representation captured by the merges must be vivid enough. For example, if CI (L)
is the single clause x  x, completeness requires a tag for x, a tag for x, and a merge
m = {x, x} for L containing the two tags, even if the clause x  x is a tautology and is
thus equivalent to the DNF formula true.
For defining the types of tags and merges that are required for completeness then,
let us first define the closure S  of a set of literals S, relative to a conformant problem
P = hF, I, O, Gi, as the set of literals that follow from S and I:
S  = {L | I, S |= L} .
Let us also say that S is consistent if S  does not contain a pair of complementary literals.
The type of merges m required for precondition and goal literals L are then those that
do not only imply CI (L) but that satisfy it as well. The notion of satisfaction associates a
consistent set of literals S with the partial truth assignment that is implicit in the closure
S  of S, and is extended to account for the conditions under which a DNF formula (e.g., a
merge for L) satisfies a CNF formula (e.g., CI (L)).
Definition 12 (Satisfaction).
1. A consistent set of literals S satisfies a clause L1 L2 

    Lm if S contains one of the literals Li , i = 1, . . . , m.
2. A consistent set of literals S satisfies a collection of clauses C if S satisfies each clause
in C.
3. A collection S of consistent sets of literals satisfies a collection of clauses C if each set
S in S satisfies C.
The type of merges required for completeness are then simply the valid merges m that
satisfy the set of clauses CI (L). We call them covering merges:
Definition 13 (Covering Merges). A valid merge m in a translation KT,M (P ) covers a
literal L if m satisfies CI (L).
For example, if CI (L) is given by the clauses that result from a oneof (x1 , . . . , xn ) expression, i.e. x1  x2      xn and xi  xj for all i and j, 1  i, j  n, i 6= j, then the
merge m = {x1 , . . . , xn } covers the literal L, as each xi not only includes xi but also xj
for all j 6= i, and thus xi satisfies CI (L).
W
If for a merge m = {t1 , . . . , tn }, we denote by m the DNF formula ti m ti , where each
tag ti is replaced by its closure ti , then it is simple to prove that if m covers the literal L,
m entails CI (L). A merge m that covers L is thus a DNF formula that is strong enough
to imply the CNF formula CI (L) (through the closure), weak enough to be entailed by I,
and vivid enough to satisfy CI (L).
636

fiCompiling Uncertainty Away in Conformant Planning Problems

As a further illustration, if CI (L) is given by the tautologies p  p and q  q, and
I = CI (L), the merge m1 = {p, p} implies CI (L) but does not satisfy CI (L). Likewise, the
merge m2 = {{p, q}, {p, q}} satisfies CI (L) but is not entailed by I. Finally, the merge
m3 = {{p, q}, {p, q}, {p, q}, {p, q}} satisfies CI (L) and is entailed by I, and thus is a
valid merge that covers L.
If a valid translation KT,M (P ) contains a merge m that covers L for each precondition
and goal literal L in P , we say that the translation covers P or just that it is a covering
translation:
Definition 14 (Covering Translation). A covering translation is a valid translation
KT,M (P ) that includes one merge that covers L, for each precondition and goal literal L
in P .
A central result of the paper is that covering translations are complete:
Theorem 15 (Completeness). Covering translations KT,M (P ) are complete; i.e., if  is a
conformant plan for P , then there is a classical plan  0 for KT,M (P ) such that  is  0 with
the merge actions removed.
In other words, complete translations KT,M (P ) result when the tags and merges in T
and M capture the information in the initial situation that is relevant to each precondition
and goal literal in a suitable manner.
Theorem 15 can be used in two ways: for proving the completeness of a translation, by
checking that the covering condition holds, and for constructing complete translations, by
enforcing the covering condition. In addition, while our interest in this paper is on conformant planning with no optimality guarantees, the theorem is useful for optimal conformant
planning as well, whether the cost of plans is defined as their length (action costs equal to
1) or as the sum of non-uniform action costs. In both cases, the theorem ensures that the
problem of optimal conformant planning gets mapped into a problem of optimal classical
planning provided that the cost of the merge actions in KT,M (P ) is made sufficiently small.
As an illustration of Theorem 15, consider the conformant problem P with initial situation I = {x1      xm }, goal G = L, and actions ai , i = 1, . . . , m, each with effect xi  L.
The number of possible initial states for this problem is exponential in m, as the disjunction
among the xi s is not exclusive. So, the translation KS0 (P ) is complete but exponential in
size. On the other hand, consider the translation KT,M (P ) where T = {x1 , . . . , xm } and
M contains the single valid merge m = {x1 , . . . , xm } for L. It is simple to verify that this
merge covers the goal L (satisfies CI (L) = I), and hence that the translation KT,M (P ) is
covering, and by Theorem 15, complete, while being polynomial in m.
Notice that testing whether a valid translation KT,M (P ) is a covering translation can
be done in polynomial time, as in particular, computing the set of literals t from every tag
t in T is a tractable operation provided that I is in PI form; indeed, I, t |= L0 iff I |= t  L0
iff t  L0 is a tautology or is subsumed by a clause in I.
6.3 Translation Kmodels
It is straightforward to show that the exponential translation KS0 considered in Section 3,
where (non-empty) tags stand for the possible initial states, is covering and hence complete
637

fiPalacios & Geffner

according to Theorem 15. It is possible, however, to take further advantage of Theorem 15
for devising a complete translation that is usually more compact. We call it Kmodels.
Definition 16. The translation Kmodels(P ) is obtained from the general scheme KT,M (P )
by defining
 M to contain one merge m for each precondition and goal literal L given by the models
of CI (L) that are consistent with I,4 and
 T to contain the tags in all such merges along with the empty tag.
The translation Kmodels is equivalent to KS0 when for all the precondition and goal
literals L, CI (L) = I; i.e., when all the clauses in I are relevant to L. Yet, in other cases,
the first translation is exponential in the number of variables appearing in one such CI (L)
set (the one with the largest number of such variables), while the second is exponential in
the number of unknown variables in I. For example, if there are n precondition and goal
literals Li , i = 1, . . . , n in P such that for each one, CI (Li ) is a unique oneof (xi1 , . . . , xim )
expression, the merge for the literal Li in KS0 (P ) will contain the mn models of the n one-of
expressions in I, while the merge for Li in Kmodels(P ) will just contain the m models of
the single oneof (xi1 , . . . , xim ) expression in CI (Li ). The translation Kmodels can thus be
exponentially more compact than the exhaustive KS0 translation while remaining sound
and complete:
Theorem 17. The translation Kmodels(P ) is sound and complete.
In the worst case, however, Kmodels is also an exponential translation. We thus consider
next polynomial translations and the conditions under which they are complete.
6.4 Conformant Width
We address now the conditions under which a compact, covering translation can be constructed in polynomial time. For this, we define a structural parameter that we call the
conformant width of a problem P , that in analogy to the notion of width used in graphical
models (Dechter, 2003), will provide an upper bound on the time and space complexity
required for generating a covering translation. More precisely, the complexity of this construction will be exponential in the conformant width of the problem P that cannot exceed
the number of fluents in P but can be much lower.
In principle, we would like to define the width w(P ) as the maximum tag size required
in a translation KT,M (P ) to be a covering translation. Such a definition, however, would
not give us the complexity bounds that we want, as just checking the validity of a merge
with tags of bounded size is an intractable operation, whether the initial situation I is in
prime implicate form or not.5 So we need to define width in a different way. First, let the
cover of a set of clauses be defined as follows:
4. The models of CI (L) are to be understood as conjuntions of literals.
5. The problem of checking whether I entails a DNF formula whose terms may have more than 2 literals
is coNP-hard even if I is equivalent to true. Indeed, if  is a 3-CNF formula;  is contradictory iff its
negation  (which is in 3-DNF) is valid, which in turn is true iff  is implied by I. Actually, for a
general I in prime implicate form, the problem remains coNP-hard even if the terms of the DNF formula
contain at most 2 literals. We thank Pierre Marquis for pointing these results to us.

638

fiCompiling Uncertainty Away in Conformant Planning Problems

Definition 18 (Cover). The cover c(C) of a set of clauses C, relative to a conformant
problem P with initial situation I, is the collection of all minimal sets of literals S consistent
with I such that S contains a literal of each clause in C.
Two important properties of the cover c(C) of a set of clauses C are that c(C) stands for
a DNF formula that is logically equivalent to the CNF formula C given I, and that c(C) can
be computed in polynomial time if the size of C is bounded by a constant. Moreover, c(C)
not only implies C but satisfies C as well. Thus in particular, if C is the collection of clauses
CI (L) that are relevant to the literal L, the cover c(CI (L)) of CI (L) is a valid merge that
covers L. From this and the completeness of covering translations, it follows that a complete
translation KT,M (P ) can be constructed in polynomial time if the size |CI (L)| of the sets of
clauses CI (L) for all precondition and goal literals L in P is bounded. Unfortunately, this
condition rarely seems to hold, yet there is a weaker sufficient condition that does: namely,
it is often possible to find a subset C of clauses that are either in CI (L) or are tautologies
such that c(C) satisfies CI (L) and thus covers the literal L. We thus define the width of
the literal L as the size of the smallest such set (cardinality-wise). For this, we denote by
CI (L) the set of clauses CI (L) extended with tautologies of the form p  p for fluents p
such that either p or p appears in CI (L) (if both appear in CI (L) then p  p is in CI (L)
from its definition).
Definition 19 (Width of Literal). The conformant width of a literal L in P , written w(L),
is the size of the smallest (cardinality-wise) set of clauses C in CI (L) such that c(C) satisfies
CI (L).
A consequence of this definition is that the width of a literal must lie in the interval
0  w(L)  n, where n is the number of fluents in P whose status in the initial situation
is not known. Indeed, if CI (L) is empty, w(L) = 0, while for any set of clauses CI (L), the
cover c(C) of the set C of tautologies in CI (L) must satisfy CI (L), and thus w(L)  |C|  n.
Similarly, if CI (L) contains a single clause x1      xm or the clauses x1      xm and
xi  xj that correspond to the oneof (x1 , . . . , xm ) expression, it is simple to prove that
w(L) = 1 with the singleton C = {x1   xm } generating the cover c(C) = {{x1 }, . . . , {xn }}
that satisfies CI (L). Finally, if CI (L) contains the two tautologies pp and qq, w(L) = 2
as the smallest C in CI (L) whose cover satisfies CI (L) is CI (L) itself.
The width of a problem is the width of the precondition or goal literal with maximum
width:
Definition 20 (Width of Problem). The conformant width of a problem P , written as
w(P ), is w(P ) = maxL w(L), where L ranges over the precondition and goal literals in P .
We show below that for problems with bounded width, complete translations can be
constructed in polynomial time, and moreover, that almost all existing conformant benchmarks have bounded width, and more precisely, width equal to 1. In such a case, the
resulting translations will use tags that are never greater in size than w(P ), so that for
problems with width 1, tags will be single literals.
Like for the (tree)width of graphical models, computing the width of a problem P is
exponential in w(P ), so the recognition of problems with small width can be carried out
quite efficiently:
639

fiPalacios & Geffner

Proposition 21 (Determining Width). The width w(P ) of P can be determined in time
that is exponential in w(P ).
In particular, we can test if w(P ) = 1 by considering one by one each of the sets C
that includes a single clause from CI (L), verifying whether c(C) satisfies CI (L) or not. If
w(P ) 6 1, then the same verification must be carried out by setting C to each set of i
clauses in CI (L) for increasing values of i. For a fixed value of i, there is a polynomial
number of such clause sets C and the verification of each one can be done in polynomial
time. Moreover, from the arguments above regarding w(L), w(P ) can never exceed the
number of unknown fluents in the problem:
Proposition 22 (Bounds on Width). The width of P is such that 0  w(P )  n, where n
is the number of fluents whose value in the initial situation is not known.
6.5 Polynomial Translation Ki
The translation Ki , where the parameter i is a non-negative integer, is an instance of
the general KT,M scheme designed to be sound, polynomial for a fixed i, and complete for
problems with width w(P )  i. Thus, for example, the translation K1 is sound, polynomial,
and complete for problems with width 1.
Definition 23 (Translation Ki ). The translation Ki (P ) is obtained from the general
scheme KT,M (P ) where
 M is set to contain one merge m = c(C) for each precondition and goal literal L in P
if there is a set C of at most i clauses in CI (L) such that m covers L. If no such set
exists, one merge m = c(C) for L is created for each set C of i clauses in CI (L), and
no merges are created for L if CI (L) is empty;
 T is the collection of tags appearing in those merges and the empty tag.
The translation Ki (P ) applies to problems P of any width, remaining in all cases exponential in i but polynomial in the number of fluents, actions, and clauses in P . In addition,
the translation Ki (P ) is sound, and for problems with width bounded by i, complete.
Theorem 24 (Properties Ki ). For a fixed i, the translation Ki (P ) is sound, polynomial,
and if w(P )  i, covering and complete.
Soundness is the result of the merges being all valid by construction, as the covers c(C)
for any C in CI (L) are entailed by C and hence by I. The complexity is polynomial for a fixed
i, because there is a polynomial number of clause sets C of size i in CI (L), and constructing
the cover c(C) for each one of them, is a polynomial operation. Finally, completeness follows
from the definition of width: if w(P )  i, then there is a set of clauses C in CI (L) with
size |C| no greater than i whose cover satisfies CI (L), and thus M in Ki (P ) must contain a
merge m = c(C) for L that covers L.
Notice that for i = 0, the translation Ki (P ) reduces to the basic K0 (P ) translation
introduced in Section 3 that has no tags (other than the empty tag) and no merges. Before,
we assessed the completeness of this translation in terms of the 0-approximation semantics.
Theorem 24 provides an alternative interpretation: the translation K0 (P ) is complete for
640

fiCompiling Uncertainty Away in Conformant Planning Problems

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

Domain-Parameter
Safe-n combinations
UTS-n locs
Ring-n rooms
Bomb-in-the-toilet-n bombs
Comm-n signals
Square-Center-n  n grid
Cube-Center-n  n  n cube
Grid-n shapes of n keys
Logistics n pack m locs
Coins-n coins m locs
Block-Tower-n Blocks
Sortnet-n bits
Adder n pairs of bits
Look-and-Grab m objs from n  n locs
1-dispose m objs from n  n locs

# Unknown Fluents
n
n
4n
n
n
2n
3n
nm
nm
nm
n  (n  1) + 3n + 1
n
2n
nnm
nnm

Width
1
1
1
1
1
1
1
1
1
1
n  (n  1) + 3n + 1
n
2n
m
m

Table 2: Width of parameterized domains
problems P with zero width. These are the problems for which the set of clauses CI (L)
relevant to a precondition or goal literal L is empty. This makes precise the intuition
mentioned above that the K0 (P ) translation is complete for problems where the uncertain
information in I is not relevant. In such cases, none of the clauses in the initial situation I
make it into the sets of relevant clauses CI (L) for preconditions and goal literals L.
As an illustration of Theorem 24, consider again the conformant problem P with initial
situation I = {x1      xm }, goal G = {L}, and actions ai , i = 1, . . . , m, each with
effect xi  L. For this problem, the singleton set of clauses C = CI (L) = I is such that
c(C) = {{x1 }, . . . , {xm }} covers CI (L). Then, since there is no other precondition or goal
literal, K1 (P ) includes the single merge m = c(C) for L with the singleton tags ti = {xi },
that we write simply as m = {x1 , . . . , xm }. The translation K1 (P ) is polynomial in m,
and since w(P ) = 1, by Theorem 24 it is complete. Notice that for this same example, the
translations KS0 (P ) and Kmodels(P ) are identical and exponential in m (the number of
models of I and CI (L)).
6.6 Width of Conformant Benchmarks
The practical value of the notion of width becomes apparent when the width of existing
benchmarks is considered. Table 2 summarizes the width of many of the existing benchmark
domains for conformant planning. The domains all depend on certain parameters n or m
that capture the size of the instances (e.g., size of a grid, number of objects, etc).6 A domain
has a bounded width when its width does not grow with the size of its instances, and has
width equal to i when all of its instances have width i regardless of the parameter values.
As it can be seen from the table, the width of most existing benchmarks is 1. In all
these cases, this means that the sets CI (L) of clauses that are relevant to a precondition or
6. The names of the parameterized domains in the table do not coincide with the names of the instances
as currently used. E.g. Comm-n in IPC5 refers to a Communication instance but not necessarily to an
instance with n signals.

641

fiPalacios & Geffner

goal literal L contain a single clause (often a tautology p  p or a disjunction x1  . . .  xm )
or a single oneof (x1 , . . . , xm ) expression (that translates into the disjunction x1      xm
and clauses xi  xk ). As shown above, w(L), and therefore, w(P ), is equal to 1 in theses
cases.
On the other extreme are domains such as Blocks, Sortnet, and Adder, all of which
have maximal widths; i.e., widths that are equivalent to the number of fluents whose status in the initial situation is not known. This is because all fluents interact through the
action conditions (not the preconditions). The numbers for Blocks in Table 2, thus follow
from the number of fluents involved; namely, the fluents on(x, y), clear(x), ontable(x), and
holding(x).
Finally, the domains 1-dispose and Look-and-Grab (Palacios & Geffner, 2006, 2007)
where m objects with unknown locations in a grid of n by n must be collected by a robot
whose gripper can hold one object at a time, have width equal to m, meaning that the
width of these domains grows with the number of objects but not with the size of the grid.
This is because in this case, the clauses about the possible locations of the m objects are
all relevant to the condition hand empty of the pick up actions.
Let us point out that the completeness of the translation Ki (P ) for problems P with
width w(P ) bounded by i, establishes a correspondence between the conformant plans
for P and the classical plans for KT,M (P ). For solving P , however, this correspondence
is not needed; it suffices for Ki (P ) to be solvable; a plan for Ki (P ) will then encode a
conformant plan for P , even if Ki (P ) does not capture all conformant plans for P . From
this perspective, it makes sense to refer to the smallest value of the i parameter for which
the classical problem Ki (P ) is solvable, as the effective width of P , denoted we (P ). It turns
out that while we (P ) cannot be larger than w(P ), it may be much smaller. An interesting
example of this comes from the Sortnet-n domain (Bonet & Geffner, 2000). Sortnet-n is
considered a challenging domain in conformant planning with very few planners able to
scale up to even small values of n (the number of entries to be sorted in a sorting network).
The domain has width n, and in the compact encoding used in IPC5, the input vector is
represented by a set of bits, exploiting the fact that sorting vectors of numbers reduces to
sorting vector of bits (0s and 1s). The domain cannot be solved by the K1 translation that
FF reports correctly as unsolvable after a brief unsuccessful search. On the other hand,
it is possible to reformulate the domain, replacing the unary high(i) and low(i) predicates
by binary predicates less(i, j) that compare two vector entries. We call this reformulation
Sort-2-n. While the encoding Sort-n is linear in n, the encoding Sort-2-n is quadratic in n,
and in both cases, the problem width is maximum, given by the number of fluents whose
status in the initial situation is unknown. Yet, while the more compact Sort-n encoding is
not solvable by the K1 translation, K1 suffices to solve the problem over the expanded Sort2-n encoding that actually can also be solved by K0 . Thus the effective width of Sort-2-n
is 0. Interestingly, provided the K0 translation of Sort-2-n, instances can be solved with up
to 20 entries. On the other hand, conformant planners such as Conformant-FF and POND
can solve Sort-2-n instances for n no greater than 3.
642

fiCompiling Uncertainty Away in Conformant Planning Problems

7. Tags and Initial States
A deeper understanding of the results above can be obtained by relating tags with possible
initial states. By looking more closely at this relation in the context of covering translations,
we will be able to answer the question of how a polynomial number of contexts (tags) can
play the role of an exponential number of possible initial states in problems with bounded
width.
For this, let us first recall a notation introduced in Section 2.2, where for a state s, we
wrote I(s) to refer to the set of atoms encoding s (i.e, p  I(s) iff p is true in s) and P/s
to refer to the classical planning problem P/s = hF, I(s), O, Gi that is like the conformant
problem P = hF, I, O, Gi but with the initial state fixed to s.
Let us now extend this notation and say that an action sequence  conforms with a set
of states S given the conformant problem P iff  is a plan for the classical problem P/s for
each s  S. Clearly, a conformant plan for P is nothing else but an action sequence that
conforms with the set S0 of possible initial states of P , yet the notion of conforms allows
us to abstract away the initial situation I and make precise the notion of a basis:
Definition 25 (Basis for P ). A set of states S 0 is a basis for a conformant problem P =
hF, I, O, Gi if S 0 is a subset of the set S0 of possible initial states of P and every plan that
conforms with S 0 conforms with the set of possible initial states S0 .
In words, if S 0 is a basis for P , it is not necessary to consider all the states in S0 for
computing the conformant plans for P ; it suffices to consider just the states in S 0 . We aim
to show that if the width of P is bounded, then P has a polynomial basis S 0 even if S0 has
exponential size. Moreover, the states s in such a basis are in close correspondence with
the tags appearing in a covering translation.
As an illustration, consider a problem P with actions ai , i = 1, . . . , n, and effects
ai : xi  L. Let G = {L} be the goal and I = {x1      xn } the initial situation. The
set S0 of all possible initial states are the truth valuations over the xi atoms where at least
one of these atoms is true. There are 2n  1 such states. On the other hand, one can show
that the set S00 of n valuations in which exactly one of these atoms is true provides a basis
for P ; i.e., the plans that conform with these n possible initial states, are exactly the plans
that conform with the complete set of 2n  1 possible initial states in S0 .
The reduction in the number of possible initial states that must be considered for computing conformant plans results from two monotonicity properties that we formulate using
the notation rel(s, L) to refer to the set of literals L0 that are true in the state s and are
relevant to the literal L:
rel(s, L) = {L0 | L0  s and L0 is relevant to L} .
Proposition 26 (Monotonicity 1). Let s and s0 be two states and let  be an action sequence
applicable in the classical problems P/s and P/s0 . Then if  achieves a literal L in P/s0
and rel(s0 , L)  rel(s, L),  achieves the literal L in P/s.
Proposition 27 (Monotonicity 2). If S and S 0 are two collections of states such that for
every state s in S and every precondition and goal literal L in P , there is a state s0 in S 0
such that rel(s0 , L)  rel(s, L), then if  is a plan for P that conforms with S 0 ,  is a plan
for P that conforms with S.
643

fiPalacios & Geffner

From these properties, it follows that
Proposition 28. S 0 is a basis for P if for every possible initial state s of P and every
precondition and goal literal L in P , S 0 contains a state s0 such that rel(s0 , L)  rel(s, L).
This proposition allows us to verify the claim made in the example above that the set S00 ,
that contains a number of states that is linear in n, is a basis for P that has an exponential
number of possible initial states. Indeed, such a problem has no precondition and a single
goal literal L, and for every state s that makes more than one atom xi true (these are the
literals relevant to L), there is a state s0 in S00 that makes only one of those atoms true, and
hence for which the relation rel(s0 , L)  rel(s, L) holds.
The question that we address now is how to build a basis that complies with the condition
in Proposition 28 given a covering translation KT,M (P ). For this, let m = {t1 , . . . , tn } be
a merge in M that covers a precondition or goal literal L, and let S[ti , L] denote the set of
possible initial states s of P such that rel(s, L)  ti ; i.e., S[ti , L] contains the possible initial
states of P that make all the literals L0 that are relevant to L false, except for those in the
closure ti of ti . We show first that if I is in prime implicate form, S[ti , L] is a non-empty
set:7
Proposition 29. If the initial situation I is in prime implicate form and m = {t1 , . . . , tn }
is a valid merge that covers a literal L in P , then the set S[ti , L] of possible initial states s
of P such that rel(s, L)  ti is non-empty.
Let then s[ti , L] stand for an arbitrary state in S[ti , L]. We obtain the following result:
Theorem 30. Let KT,M (P ) be a covering translation for a problem P with an initial
situation in PI form, and let S 0 stand for the collection of states s[ti , L] where L is a
precondition or goal literal of P and ti is a tag in a merge that covers L. Then S 0 is a basis
for P .
This is an important result for three reasons. First, it tells us how to build a basis for P
given the tags ti in a covering translation KT,M (P ). Second, it tells us that the size of the
resulting basis is linear in the number of precondition and goal literals L and tags ti . And
third, it makes the role of the tags ti in the covering translation KT,M (P ) explicit, providing
an intuition for why it works: each tag ti in a merge that covers a literal L represents one
possible initial state; namely, a state s[ti , L] that makes false all the literals L0 that are
relevant to L except those in ti . If a plan conforms with those critical states, then it will
conform with all the possible initial states by monotonicity (Proposition 27). It follows then
in particular that:
Theorem 31. If P is a conformant planning problem with bounded width, then P admits
a basis of polynomial size.
Namely, conformant problems P with width bounded by a non-negative integer i admit
polynomial translations that are complete, because the plans that conform with the possibly
exponential number of initial states of P correspond with the plans that conform with
7. Recall that we are assuming throughout that the initial situation I is logically consistent and that the
tags t are consistent with I.

644

fiCompiling Uncertainty Away in Conformant Planning Problems

a subset of critical initial states that are polynomial in number (namely, those in the
polynomial basis). Thus, one complete polynomial translation for such problems is the
Ki translation; another one, is the KS0 translation but with the tags associated with those
critical initial states only rather than with all the initial states.
As an illustration, for the problem P above with actions ai and effects ai : xi  L,
goal G = {L}, and initial situation I = {x1      xn }, the K1 (P ) translation with tags xi ,
i = 1, . . . , n, and the merge m = {x1 , . . . , xn } for the goal literal L, is a covering translation.
Theorem 30 then states that a basis S 0 for P results from the collection of states si that
make each tag xi true, and all the literals that are relevant to L that are not in xi false (i.e.,
all xk atoms for k 6= i). This is precisely the basis for P that we had above that includes
the states that make a single atom xi true for i = 1, . . . , n: the plans that conform with this
basis are then exactly the plans that conform with the whole collection of possible initial
states of P . This basis has a size that is polynomial in m though, while the number of
possible initial states of P is exponential in m.

8. The Planner T0
The current version of the conformant planner T0 is based on two instances of the general
translation scheme KT,M (P ) whose outputs are fed into the classical planner FF v2.3.8 One
instance is polynomial but not necessarily complete; the other is complete but not necessarily
polynomial. For the incomplete translation, T0 uses K1 that is complete for problems with
width no greater than 1, and as argued above, can result in solvable instances for problems
of larger widths. For the complete translation, the Kmodels translation is used instead
with a simple optimization: if the K1 translation produces a single merge m that covers L,
then this merge m is used for L instead of the potentially more complex one determined by
Kmodels. This is a mere optimization as the resulting translation remains complete. The
other merges in Kmodels, that result from the models of the set of clauses CI (L) that are
consistent with I, are computed using the SAT solver relsat v2.20 (Bayardo Jr. & Schrag,
1997). In the current default mode in T0 , which is the one used in the experiments below,
the two translations K1 and Kmodels are used in sequence: FF is called first upon the
output of K1 and if this fails, it is called upon the output of Kmodels. In the experiments
below, we indicate the cases when Kmodels was invoked.
The translations used in T0 accommodate certain simplifications and two additional
actions that capture other types of deductions. The simplifications have to do with the fact
that the translations considered are all uniform in the sense that all literals L in P and
all rules C  L are conditioned by each of the tags t in T . From a practical point of
view, however, this is not needed. The simplifications address this source of inefficiency. In
particular:
 literals KL/t are not created when the closure t contains no literal relevant to L.
In such a case, the invariance KL/t  KL holds, and thus, every occurrence of the
literal KL/t in KT,M (P ) is replaced by KL.
8. The conformant planner T0 along with all the benchmarks considered in the paper are available at
http://www.ldc.usb.ve/hlp/software.

645

fiPalacios & Geffner

 support rules a : KC/t  KL/t for non-empty tags t are not created when L is not
relevant to a literal L0 with a merge that contains t, as in such a case, the literal
KL/t cannot contribute to establish a precondition or goal. Similarly, cancellation
rules a : KC/t  KL/t for non-empty tags t are not created when L is not
relevant to a literal L0 with a merge that contains t.
 support and cancellation rules a : KC/t  KL/t and a : KC/t  KL/t are
grouped as a : KC/t  KL/t  KL/t when for every fluent L0 relevant to L, either
L0 or L0 is entailed by I and t. In such a case, there is no incomplete information
about L given t in the initial situation, and thus the invariant KL/t or KL/t holds,
and KC/t is equivalent to KC/t.
Two other types of sound deductive rules are included in the translations:
 a rule a : KC  KL is added if a : C, L  L is a rule in P for an action a, and no
rule in P has the form a : C 0  L,
 rules KL1 , . . . , KLi1 , KLi+1 , . . . , KLn  KLi for i = 1, . . . , n are added to a
new unique action with no precondition, when L1      Ln is a static clause in P (a
clause in P is static if true in the initial situation and provably true after any action).
These rules are versions of the action compilation and static disjunctions rules (Palacios &
Geffner, 2006, 2007), and they appear to help in certain domains without hurting in others.
The version of T0 reported below does not assume that the initial situation I of P is
in prime implicate form but it rather renders it in PI form by running a version of Tisons
algorithm (1967), a computation that in none of the benchmarks solved took more than 48
seconds.
The translators in T0 are written in OCaml while the code for parsing the PDDL files
is written in C++.

9. Experimental Results
We considered instances from three sources: the Conformant-FF distribution, the conformant track of the 2006 International Planning Competition (IPC5), and relevant publications (Palacios & Geffner, 2006, 2007; Cimatti et al., 2004). The instances were run on a
cluster of Linux boxes at 2.33 GHz with 8GB. Each experiment had a cutoff of 2h or 2.1GB
of memory. Times for T0 include all the steps, in particular, computation of prime implicates, translation, and search (done by FF). We also include results from the Conformant
Track of the recent 2008 International Planning Competition (IPC6).
Goals that are not sets of literals but sets of clauses are transformed in T0 in a standard
way: each goal clause C : L1      Lm is modeled by a new goal atom GC , and a new
action that can be executed once is added with rules Li  GC , i = 1, . . . , m.9
9. An alternative way to represent such CNF goals is by converting them into DNF first and having an
action End map each of its non-mutex terms into a dummy goal LG . This alternative encoding pays
off in some cases, such as in the Adder-01 instance that does not get solved in the default CNF goal
encoding (see below).

646

fiCompiling Uncertainty Away in Conformant Planning Problems

Problem
bomb-100-100
square-center-96
sortnet-09
blocks-03
dispose-16-1
look-and-grab-8-1-1
sgripper-30

P
#Acts #Atoms #Effects
10100
404
40200
4
196
760
46
68
109
32
30
152
1217
1479
2434
352
358
2220
487
239
1456

Time
2
35,1
8,3
4
163,6
6,9
21,5

K1 (P )
PDDL
#Acts #Atoms #Effects Size
10201
1595
50500
2,9
7
37248
75054
3,8
56
29707
154913
5,1
37
11370
35232
0,7
1218 133122
3458
0,3
353
8708
118497
7,8
860
1127
12769
1

Table 3: Translation data for selected instances: #Acts, #Atoms, and #Effects stand for
the number of actions, fluents, and conditional effects. Time is the translation
time in seconds rounded to the closest decimal, and PDDL Size is the size of the
PDDL file in Megabytes.

Table 3 shows data concerning the translation of a group of selected instances. As it can
be seen, the number of conditional effects grows considerably in all cases, and sometimes
the translation may take several seconds.
Tables 4, 5, 6, 7, and 8, show the plan times and lengths obtained on a number of
benchmarks by T0 , POND 2.2 (Bryce et al., 2006), Conformant FF (Hoffmann & Brafman,
2006), MBP (Cimatti et al., 2004) and KACMBP (Bertoli & Cimatti, 2002). These last
two planners do not accept problems in the standard syntax (based on PDDL), so only a
limited number of experiments were performed on them. The general picture is that T0
scales up well in most domains, the exceptions being Square-Center and Cube-Center in
Table 5, where KACMBP scales up better, Sortnet in Table 6, where KACMBP and MBP
scale up better; and Adder in Table 6, where POND is the only planner able to solve one
instance.
The problems in Table 4 are encodings from the Conformant-FF repository: Bomb-x-y
refers to the Bomb-in-the-toilet problem with x packages, y toilets, and clogging; Logistics-ij-k is a variation of the classical version with uncertainty about initial location of packages;
Ring-n is about closing and locking windows in a ring of n rooms without knowing the
current room; and Safe-n is about opening a safe with n possible combinations. All these
problems have width 1. T0 does clearly best on the last two domains, while in the first two
domains, Conformant-FF does well too.
Table 5 reports experiments on four grid domains: Cube-Center-n refers to the problem
of reaching the center of a cube of size n3 from a completely unknown location; SquareCenter-n is similar but involves square with n2 possible locations; Corners-Cube-n and
Corners-Square-n are variations of these problems where the set of possible initial locations
is restricted to the Cube and Square corners respectively. MBP and KACMBP appear to be
effective in these domains, although KACMBP doesnt scale up well in the corner versions.
T0 solves most of the problems, but in the corner versions, the quality of the plans is poor.
These problems have also width 1.
Table 6 reports experiments over problems from the 2006 International Planning Competition (Bonet & Givan, 2006). The domains Coins, Comm and UTS have all width 1.
The others have max width given by the number of unknown fluents in the initial situation.
647

fiPalacios & Geffner

Problem
bomb-20-1
bomb-20-5
bomb-20-10
bomb-20-20
bomb-100-1
bomb-100-5
bomb-100-10
bomb-100-60
bomb-100-100
logistics-4-3-3
logistics-2-10-10
logistics-3-10-10
logistics-4-10-10
ring-4
ring-5
ring-6
ring-7
ring-8
ring-30
safe-10
safe-30
safe-50
safe-70
safe-100

T0
time
0,1
0,1
0,1
0,1
0,5
0,7
1,1
4,25
9,4
0,1
1
1,5
2,5
0,1
0,1
0,1
0,1
0,1
13,4
0,1
0,1
0,4
1,12
2,5

len
49
35
30
20
199
195
190
140
100
35
84
108
125
13
17
20
30
39
121
10
30
50
70
100

POND
time len
4139 39
> 2h
> 2h
> 2h





56
40
> 2h
> 2h
> 2h
1
18
6
20
33
27
444
33
> 2h

0
10
2
30
9
50
41
70
> 2.1GB

CFF
time
len
0
39
0
35
0
30
0
20
56,7
199
52,9
195
46,8
190
9,4
140
1
100
0
37
1,6
83
4,7
108
4,4
121
0,4
18
4,3
31
93,6
48
837
71
> 2h

0
10
1,4
30
29,4
50
109,9
70
1252,4 100

MBP
time len
> 2h
> 2h
> 2h
> 2h





> 2h
> 2h
> 2h
> 2h
0
11
0,1
14
0,6
17
3,8
20
40
23
> 2h
0,1
10
> 2h
> 2h
> 2h
> 2h

KACMBP
time len
0
40
0,2
40
0,5
40
2
40
1,9
200
4,3
200
16,4 200
> 2h
> 2h
> 2.1GB
> 2.1GB
> 2.1GB
> 2.1GB
0
26
0,1
58
0,2
99
0,5
204
2
432
> 2.1GB
0
10
0,2
30
0,7
50
2,4
70
8,6
100

Table 4: Experiments over well known benchmarks. Times reported in seconds and rounded
to the closest decimal.  means time or memory out for smaller instances.

648

fiCompiling Uncertainty Away in Conformant Planning Problems

Problem
square-center-8
square-center-12
square-center-16
square-center-24
square-center-92
square-center-96
square-center-100
square-center-120
cube-center-5
cube-center-7
cube-center-9
cube-center-11
cube-center-15
cube-center-19
cube-center-63
cube-center-67
cube-center-87
cube-center-91
cube-center-119
corners-square-12
corners-square-16
corners-square-20
corners-square-24
corners-square-28
corners-square-36
corners-square-40
corners-square-72
corners-square-76
corners-square-80
corners-square-120
corners-cube-15
corners-cube-16
corners-cube-19
corners-cube-20
corners-cube-23
corners-cube-24
corners-cube-27
corners-cube-52
corners-cube-55

T0
time
len
0,2
21
0,2
33
0,3
44
0,8
69
45,3
273
50,2
285
> 2.1GB
> 2.1GB
0,1
18
0,1
27
0,2
33
0,3
45
0,5
63
0,8
81
28,5
279
41,6
297
137,5 387
> 2.1GB
> 2.1GB
0,1
64
0,2
102
0,3
148
0,5
202
0,7
264
1,7
412
2,5
498
26,1 1474
30,5 1632
38,2 1798
223,6 3898
0,8
147
0,9
174
2,5
225
2,7
258
6,3
319
6,7
358
14,6
429
448
1506
> 2.1GB

POND
time len
2
41
12
52
1322 61
> 2h
> 2h



1
22
2
43
3
47
29
87
880 109
> 2h
> 2h




11
44
1131 67
> 2h
> 2h







907 105
3168 115
> 2h
> 2h






CFF
time
len
70,6
50
> 2h
> 2h





8,2
45
> 2h
> 2h








1,7
82
13,1
140
73,7
214
321
304
MPL






134,5 284
439,4 214
868,4 456
3975,6 332
MPL





MBP
time
len
0
24
0
36
0
48
0
72
0,9
276
0,9
288
1,1
300
1,9
360
0
28
0
33
0,1
54
0,2
59
0,2
69
1,6
111
28
285
> 2.1GB
> 2.1GB


0
36
0
48
0,3
60
0,6
72
1,1
84
1,5
108
7,8
120
118,8 216
371
228
649,6 240
> 2.1GB
3,7
69
12,5
72
549,5 111
1061,9 90
> 2h
> 2h




KACMBP
time
len
0
28
0
42
0
56
0
84
0,3
322
0,3
336
0,3
350
0,4
420
0
25
0
35
0
45
0
55
0
75
0,1
95
0,5
315
0,7
335
1,2
435
1,2
455
2,1
595
0,2
106
0,6
158
3
268
7,5
346
20,7
502
3308,8 808
> 2h
> 2h



174,1 391
270,5 316
1503,1 488
2759
625
6265,9 899
> 2h
> 2h



Table 5: Experiments over grid problems. Times reported in seconds and rounded to the
closest decimal. MPL for CFF means that plan exceeds maximal plan length
(500 actions).  means time or memory out for smaller instances.

649

fiPalacios & Geffner

Problem
adder-01
adder-02
blocks-01
blocks-02
blocks-03
coins-10
coins-12
coins-15
coins-16
coins-17
coins-18
coins-19
coins-20
coins-21
comm-07
comm-08
comm-09
comm-10
comm-15
comm-16
comm-20
comm-25
sortnet-06
sortnet-07
sortnet-08
sortnet-09
sortnet-10
sortnet-11
uts-k-04
uts-k-05
uts-k-06
uts-k-07
uts-k-08
uts-k-09
uts-k-10
uts-l-07
uts-l-08
uts-l-09
uts-l-10

T0
time len
> 2h
> 2h
0,1
5
0,3
23
82,6
80
0,1
26
0,1
67
0,1
79
0,3
113
0,2
96
0,2
97
0,2
105
0,2
107
> 2h
0,1
54
0,1
61
0,1
68
0,1
75
0,1
110
0,2
138
0,8
278
2,3
453
0,6
21
2,5
28
9,6
36
76,8
45
> 2.1GB
> 2.1GB
0,1
23
0,1
29
0,2
35
0,4
41
0,6
47
0,9
53
1,3
59
0,2
70
0,3
80
0,6
93
0,7
97

POND
time len
1591
5
> 2h
0,1
4
0,4
26
126,8 129
5
28
> 2h
> 2h






0
47
1
53
1
59
1
65
6
95
> 2h
> 2.1GB

18
20
480
25
> 2h
> 2h


2
22
4
28
10
34
13
40
24
47
> 2h
2219
67
201
58
937
67
> 2h
> 2h

CFF
time len
SNH
SNH
0
6
> 2h
> 2h
0,1
38
0,8
72
3
89
33,3 145
1,4
94
6,2
118
16,5 128
20,6 143
> 2h
0
47
0
53
0
59
0
65
0,2
95
0,4
119
6,4
239
56,1 389
SNH
SNH
SNH
SNH
SNH
SNH
0,1
22
0,3
28
0,8
34
1,9
40
4,4
46
8,6
52
16,5
58
0,2
41
0,4
47
0,8
53
1,6
59

MBP
time
len
NR
NR
NR
NR
NR
> 2h
> 2h







0,2
55
0,2
71
0,2
77
0,3
85
0,9
115
1,6
151
50,9
340
> 2h
0
17
0
20
0
28
0
36
0,1
37
0,1
47
5,4
32
1247,3 38
1704,8 50
> 2h
> 2h


10,5
89
41,1
106
1176
137
> 2h

KACMBP
time
len
NR
NR
NR
NR
NR
4,2
106
3654,7 674
> 2h
> 2h





63,6
53
1966,8 53
> 2h
> 2h




0
21
0
28
0
36
0
45
0,1
55
0,1
66
1,5
30
195,4
42
> 2h
> 2h



> 2h
> 2h



Table 6: Experiments over problems from IPC5. Times reported in seconds and rounded
to the closest decimal. SNH for CFF means that goal syntax not handled, while
NR for MBP and KACMBP that these planners were not run due to lack of
translations from PDDL.  means time or memory out for smaller instances.

650

fiCompiling Uncertainty Away in Conformant Planning Problems

Problem
dispose-4-1
dispose-4-2
dispose-4-3
dispose-8-1
dispose-8-2
dispose-8-3
dispose-12-1
dispose-12-2
dispose-12-3
dispose-16-1
dispose-16-2
look-and-grab-4-1-1
look-and-grab-4-1-2
look-and-grab-4-1-3
look-and-grab-4-2-1
look-and-grab-4-2-2
look-and-grab-4-2-3
look-and-grab-4-3-1
look-and-grab-4-3-2
look-and-grab-4-3-3
look-and-grab-8-1-1
look-and-grab-8-1-2
look-and-grab-8-1-3
look-and-grab-8-2-1
look-and-grab-8-2-2
look-and-grab-8-2-3
look-and-grab-8-3-1
look-and-grab-8-3-2
look-and-grab-8-3-3

T0
time
len
0,1
59
0,1
110
0,3
122
2,7
426
18,4
639
197,1 761
78
1274
2555 1437
> 2.1GB
382
1702
> 2.1GB
0,3
30
0,5
4
0,61
4
35
12
49,41
4
60,02
4
> 2.1GB
213,3
4
> 2.1GB
58,2
242
75,3
90
55,89
58
> 2h
> 2h
> 2h
> 2h
> 2h
> 2h

POND
time len
9
55
36
70
308 102
> 2.1GB
> 2.1GB






3098 16
> 2h
> 2h
> 2.1GB
> 2h
> 2h
> 2.1GB












CFF
time
len
0,1
39
0,2
56
0,6
73
339,1 227
2592,1 338
> 2h
ME
> 2.1GB



> 2h
Mcl
Mcl
> 2h
Mcl
Mcl
> 2h
> 2h
> 2h










MBP
time len
> 2h
> 2h









> 2h
0,02
5
0,01
5
> 2h
0,02
5
0,02
5
> 2h
0,02
5
0,02
5
> 2h
> 2h
> 2h
> 2h
> 2h
> 2h
> 2h
> 2h
> 2h

KACMBP
time len
17,1
81
> 2h
> 2h








0,6
54
0,0
6
0,0
6
0,63
40
0,01
6
0,01
6
0,98
60
0,02
6
0,01
6
> 2h
> 2h
> 2h
> 2h
> 2h
1195 178
> 2h
> 2h
17,9
58

Table 7: Problems from Palacios and Geffner (2006, 2007): Times reported in seconds and
rounded to the closest decimal.  means time or memory out for smaller instances.
ME and Mcl mean too many edges and too many clauses respectively.

T0 dominates in all these domains except in Adder where POND is the only planner able
to solve an instance, and Sortnet, where MBP and KACMBP do very well, possibly due to
use of the cardinality heuristic and OBDD representations. T0 fails on Adder because FF
gets lost in the search. Looking at this problem more closely, we found that FF could solve
the (translation of the) first instance in less than a minute provided that the CNF goal for
this problem is encoded in DNF as explained in footnote 9, page 646. The domains Adder,
Blocks, and Sortnet in the table, along with the domain Look-and-Grab in the next table,
are the only domains considered where FF run on the K1 translation reports no solution
after a brief search, triggering then the use of the complete Kmodels translation. In all the
other cases where Kmodels was used, the K1 translation had an unreachable goal fluent and
there was no need to try FF on it.
651

fiPalacios & Geffner

Problem
push-to-4-1
push-to-4-2
push-to-4-3
push-to-8-1
push-to-8-2
push-to-8-3
push-to-12-1
push-to-12-2
push-to-12-3
1-dispose-8-1
1-dispose-8-2
1-dispose-8-3

T0
time
len
0,2
78
0,3
85
0,6
87
81,8
464
457,9
423
1293,1 597
> 2h
> 2h
> 2.1GB
82,2
1316
> 2.1GB
> 2.1GB

POND
time len
5
50
171
58

> 2h
> 2h
> 2h



> 2.1GB
> 2.1GB


CFF
time len
0,3
46
0,7
47
1,6
48
> 2.1GB
> 2.1GB
> 2.1GB



> 2h
> 2h


Table 8: Other problems from Palacios and Geffner (2006, 2007). MBP and KACMBP
were not tried on these problems as they use a different syntax. Times reported
in seconds and rounded to the closest decimal.  means time or memory out for
smaller instances.

The problems reported in Table 7 and Table 8 are variations of a family of grid problems
(Palacios & Geffner, 2006, 2007). Dispose is about retrieving objects whose initial location is
unknown and placing them in a trash can at a given, known location; Push-to is a variation
where objects can be picked up only at two designated positions in the grid to which all
objects have to be pushed to: pushing an object from a cell into a contiguous cell moves
the object if it is in the cell. 1-Dispose is a variation of Dispose where the robot hand being
empty is a condition for the pick up actions to work. As a result, a plan for 1-Dispose has to
scan the grid, performing pick ups in every cell, followed by excursions to the trash can, and
so on. The plans can get very long (a plan is reported with 1316 actions). Look-and-Grab
has an action that picks up the objects that are sufficiently close if any, and after each pickup must dump the objects it collected into the trash before continuing. For the problem
P-n-m in the table, n is the grid size and m is the number of objects. For Look-n-Grab,
the third parameter is the radius of the action: 1 means that the hand picks up all the
objects in the 8 surrounding cells, 2 that that the hand picks up all the objects in the 15
surrounding cells, and so on. The domains in Tables 7 and 8 have width 1 except 1-Dispose
and Look-n-Grab. This is because, the hand being empty is a fluent that is relevant to
the goal, and clauses about the location of objects are all relevant to hand empty. In all
these domains T0 appears to do better than the other planners. The Kmodels translation
was triggered only in the instances Look-and-Grab-n-m-r for m > 1 (the width of these
instances, as mentioned in Section 6.6, is m, independent of grid size).
We also report some additional data in Table 9, comparing the search that results from
the use of the FF planner over the classical translations in T0 , to the search carried out
by Conformant-FF over the original conformant problems. Conformant-FF is a conformant
planner built on top of FF that searches explicitly in belief space. The table illustrates the
two problems faced by belief-space planners mentioned in the introduction and the handle
652

fiCompiling Uncertainty Away in Conformant Planning Problems

Problem
bomb-100-1
bomb-100-100
Safe-100
logistics-4-10-10
square-center-8
square-center-12
cube-center-5
cube-center-7
blocks-01
blocks-02
coins-20
comm-25
uts-k-10
dispose-8-1
dispose-8-2
dispose-8-3
look-and-grab-4-1-1

Nodes
5149
100
100
356
4634
39000
2211
81600
46
1420
1235
517
58
1107
1797
2494
4955

CFF
Time
32,9
0,8
1747,4
4,42
59,3
>5602,5
8,2
>5602,5
0,0
>5602,5
20,6
56,1
16,5
339,1
2592,1
>5602,5
>5602,5

Nodes/sec
156,5
125
0,1
80,5
78,1
7
269,6
14,6
4600
0,3
60
9,2
3,5
3,3
0,7
0,4
0,9

Nodes
5250
201
102
774
46
72
74
105
47
86
783
1777
62
11713
87030
580896
79

FF in T0
Time Nodes/sec
0,41
12804,9
7,53
26,7
0
25500
0,47
1646,8
0,05
920
0,03
2400
0,01
7400
0,0
5250
0
11750
0,0
4300
0,04
19575
0,43
4132,6
0,34
182,4
0,78
15016,7
14,32
6077,5
190,2
3054,1
0,1
790

Table 9: CFF over Conformant Problems vs. FF over Translations: Nodes stand for number
of nodes evaluated, Time is expressed in seconds, and Nodes/sec stands for average
number of nodes per second. Numbers shown in bold when either CFF or FF
evaluate significantly less nodes (an order-of-magnitude reduction or more). Times
preceded by > are time outs.

653

fiPalacios & Geffner

over them that results from the translation-based approach. The belief representation and
update problem appears in the overhead of maintaining and evaluating the beliefs, and
shows in the number of nodes that are evaluated per second: while CFF evaluates a few
hundred nodes per second; FF evaluates several thousands. At the same time, the heuristic
used in CFF in the conformant setting, appears to be less informed that the heuristic used
by FF over the classical translations. In domains like Square-Center-n, Cube-Center-n,
Blocks, and Look-and-Grab, FF needs orders-of-magnitude less nodes than CFF to find a
plan, while the oppositive is true in Dispose-n-m where FF evaluates many more nodes
than CFF. Nonetheless, even then, due to the overhead involved in carrying the beliefs, FF
manages to solve problems that CFF cannot solve. For example, the instance Dispose-8-3
is solved by T0 after evaluating more than half a million nodes, but times out in CFF after
evaluating less than three thousand nodes.
Tables 10 and 11 provide details on the results of the Conformant Track of the 2008
International Planning Competition (IPC6) (Bryce & Buffet, 2008), held almost at the time
where the original version of this paper was submitted, with planner binaries submitted to
the organizers a few months before. The version of T0 in IPC6 was different from the
version of T0 used in IPC5, where it was the winning entry, and different also from the
version reported in this paper. In relation, to the former, T0 IPC6 was a cleaner but
complete reimplementation; in relation to the latter, T0 IPC6 handled problems with width
greater than 1 in a different way. As explained in the previous section, the current version
of T0 , uses K1 as the basic translation regardless of the width of the problem, switching to
Kmodels when the search over K1 fails. In the version of T0 at IPC6, the basic translation
was a combination of K0 and K1 ; more precisely, merges for literals L with width w(L) = 1,
were generated according to K1 , but merges for literals L with width w(L) 6= 1 were not
generated at all. The result was that the basic translation in T0 in IPC6 was lighter than
the basic translation of the current version of T0 but could fail on problems with width
higher than 1 that the latter can solve. Retrospectively, this was not a good choice, but it
didnt have much of an impact on the results. There was however a bug in the program
that prevented two width-1 domains, Forest and Dispose, to be recognized as such, and
thus resulted in the use of the Kmodels translation, that is complete for all widths, but does
not scale up that well.
The other two conformant planners entered into IPC6 where CpA(H) and CpA(C);
these are belief-space planners that represent beliefs as DNF formulas, and use simple
belief-state heuristics for guiding the search (Tran, Nguyen, Pontelli, & Son, 2008, 2009).
The belief progression in these planners is done quite effectively, by progressing each term
in turn, according to the 0-approximation semantics. The potential blow up comes from the
number of terms in the DNF formula encoding the initial belief state. Rather than choosing
the terms of the initial belief state as the possible initial states, these planners limit the
terms in the DNF formula to a collection of partial initial states that do not assign any
truth value to the literals that are deemed irrelevant. The resulting belief representation is
complete but may still result in an exponential number of terms (Son & Tu, 2006). In order
to reduce further the number of terms in this initial DNF formula, independent one-of
expressions are combined. For example, two independent one-of clauses oneof (x1 , x2 ) and
oneof (y1 , y2 ) which would give rise to 4 possible initial states and DNF terms, are combined
into the single one-of expression oneof (x1  y1 , x2  y2 ), that results into 2 possible initial
654

fiCompiling Uncertainty Away in Conformant Planning Problems

Domain
Blocks
Adder
UTS Cycle
Forest
Raos keys
Dispose

# Instances
4
4
27
9
29
90

CpA(H)
4
1
2
1
2
76

CpA(C)
3
1
2
1
2
59

T0 IPC6
3
1
3
8
1
20

Table 10: Data from the Conformant Track of the recent IPC6 Competition: Number of
problems solved by each of the conformant planners, with time out of 20 mins.
In bold, entry for planner that performed best in each domain. The data is from
Bryce and Buffet (2008)

states and terms. These one-of expressions are independent when they can be shown not
to interact in the problem. The technique appears to be related to the notion of critical
initial states considered in Section 7, where it was shown that plans that conform with all
critical initial states must conform also with all possible initial states. The heuristics used
by CpA(H) and CpA(C) are combinations of the cardinality heuristic, that measures the
number of states in a belief state, the total sum heuristic, that adds the heuristic distances
to the goal from each possible state, and the number of satisfied goals, that counts the
number of top goals achieved. These heuristics are all very simple, yet they work well on
some benchmarks.
Tables 10 and 11 show data obtained from the IPC6 organizers from the planner logs.
The first table appears in the IPC6 report (Bryce & Buffet, 2008), where the new domains
Forest and Raos keys are explained, and shows the number of problems solved by each
planner, displaying in bold the planner that did best in each domain. The planner CpA(H),
was declared the winner, as it was declared best in three domains (Blocks, Raos keys,
Dispose), with T0 doing best in two domains (UTS Cycle and Forest), and CpA(C) doing
best in one (Adder).
Table 11 shows additional details on some of the instances; in particular, the total time
taken to solve the instance and the length of the plans for each of the three planners.
In terms of domain coverage, the planners do similarly on most domains, except in
Forest, where T0 solved most of the instances and CPA(H) solved few (8/9 vs. 1/9), and
Dispose, where CPA(H) solved most of the instances and T0 solved few (76/90 vs. 20/90).
In terms of time and plan quality, CpA(H) and CpA(C) appear to be slightly faster
than T0 on Blocks, but produce much longer plans. In Dispose, T0 scales up better than
CpA(H) and CpA(C) over the size of the grids, and worse on the number of objects.
Indeed, only T0 manages to solve the largest grid but for a single object (Dispose-10-01),
and only CpA(H) and CpA(C) solve instances with more than 2 objects in the largest grids.
As in most cases, plan lengths produced by T0 are shorter; e.g., the plan for Dispose-04-03
contains 125 actions for T0 , 314 for CpA(H), and 320 for CpA(C).
Dispose is actually a domain where the cardinality heuristic does very well in the generation of plans, even if the plans tend to be rather long. As discussed above, in this domain,
an agent has to scan a grid collecting a set of objects at unknown locations, and each time
655

fiPalacios & Geffner

the action of picking up an object from a cell that may contain the object is made (except
for the first time), the cardinality of the belief state is reduced. Indeed, if initially an object
may be at positions p1 , p2 , . . . , pn , after a pick up at p1 , the object can be in positions
p2 , . . . , pn or in the gripper, after a pick up at p2 , the object can be in positions p3 , . . . , pn or
in the gripper, and so on, each pick up action decreasing the cardinality of the belief state,
until becoming a singleton belief where the object must be in the gripper with certainty.
The problem with the version of T0 used in IPC6 in the Dispose domain, was not only
that FF explores too many states in the search, but as explained above, that it used the
expensive Kmodels translation instead of the lighter K1 translation that is complete for
this domain that has width 1. With this bug fixed, T0 solves 60 rather than 20 of the 90
Dispose instances, still failing on some of the larger grids with many objects, but producing
much shorter plans. For example, Dispose-06-8 is solved with a plan with 470 actions, while
CpA(H) and CpA(C) solve it with plans with 2881 and 3693 actions respectively. The
same bug surfaced in the Forest domain, but it just prevented the solution of one instance
only. Forest, Dispose, and UTS Cycle have all conformant widths equal to 1, while the
other domains have all larger widths (see Table 2 for the widths of Blocks and Adder).
The second domain in IPC6 where FF got lost in the search was Adder, where indeed, T0
did not solve any instance. The instance that is shown to be solved by T0 in the competition
report, appears to be a mistake. Similarly, the fourth instance of blocks, that is reported as
solved by CPA(H), may be a mistake too; indeed, no plan for such an instance can be found
in the logs, and T0 reports that the goal is unreachable in the Kmodels translation that
is complete. According to T0 , instance four of Raos key is unsolvable too. On the other
hand, T0 failed on the larger UTS Cycle and Raos key instances during the translation.
In the the first, the resulting PDDLs are too large and cant be loaded into FF; in the
second, the number of init clauses turns out to be quite large (above 300), giving rise to
a still larger set of prime implicates (above 5000) that caused the translator to run out of
memory. The second instance of Raos keys, however, is rather small and T0 didnt solve it
due to a different bug. With this bug fixed, T0 solves it in 0.3 seconds, producing a plan
with 53 actions, which compares well with the solutions produced by CpA(H) and CpA(C)
in 0.7 and 1.9 seconds, with 85 and 99 steps, respectively.

10. Non-Deterministic Actions
The translation schemes considered are all limited to problems with deterministic actions
only. Nonetheless, as we illustrate below, these schemes can be applied to non-deterministic
actions as well provided suitable transformations are included. We cover these transformations briefly as a matter of illustration only.
Consider a conformant problem P with non-deterministic action effects a : C  oneof (S1 ,
S2 , . . . , Sm ), where each Si is a set (conjunction) of literals, and the transformed problem
P 0 , where these effects are mapped into deterministic rules of the form a : C, hi  Si , with
the expression oneof (h1 , . . . , hm ) added to the initial situation of P 0 . In P 0 , the hidden hi
variables are used for encoding the uncertainty on the possible outcomes Si of the action a.
It is easy to show that the non-deterministic conformant problem P and the deterministic conformant problem P 0 are equivalent provided that only plans for P and P 0 are
considered where the non-deterministic action a from P are executed at most once. Namely,
656

fiCompiling Uncertainty Away in Conformant Planning Problems

Problem

Instance

Blocks

1
2
3
4
1
1
2
3
1
2
3
4
5
6
7
8
1
2
4,1
4,2
4,3
4,4
6,1
6,2
6,3
6,4
8,1
8,2
8,3
10,1
10,2

Adder
UTS Cycle

Forest

Raos keys
Dispose

CpA(H)
time
len
0
4
0,1
28
5,9
411
143,9 257
8,5
3
0,8
3
25,3
6

CpA(C)
time
len
0
7
0,1
35
6,3
157
8,3
0,6
24,7

3
3
6

3,6

24

11,6

18

0,1
0,7
0,3
0,7
1,3
2
4,7
10,4
17,7
27,6
40,1
86,7
86,7

28
85
80
197
314
431
270
643
1016
1389
753
1851
1851

0
1,9
0,4
0,9
1,8
2,8
4,5
42,2
97,9
172,5
40,3
524,6

29
99
88
206
320
434
187
735
1228
1721
518
1962

T0 IPC6
time len
0,1
5
0,1
23
17,8
83

0,1
0,7
5,4
0,2
1,3
2,2
12,1
14,4
69,7
355,1

3
7
10
16
45
78
129
115
200
256

0

16

0,1
3,6
528,3

77
110
125

0,9
217,7

204
329

7,4

326

45

683

Table 11: Running time and plan length from IPC6 logs. Time in seconds. Blanks stand
for time or memory out. Only 13 of the 90 Dispose-n-m instances shown, At
IPC6, size n of grid ranged from 2 to 10, while number m of objects, from 1 to
10. T0 scales up best on n and worst on m.

657

fiPalacios & Geffner

a correspondence exists between the conformant plans for P that use such actions at most
once with the conformant plans for P 0 that use the same actions at most once too. On the
other hand, a conformant plan for P 0 where these actions are done many times will not
necessarily represent a conformant plan for P . Indeed, if a non-deterministically moves an
agent up or right in a square grid n  n, starting in the bottom left corner, n actions a in
a row would leave the agent at either the top left corner or the bottom right corner in P 0 ,
and anywhere at Manhattan distance n from the origin in P. The divergence between P
and P 0 , however, does not arise if non-deterministic actions are executed at most once.
Building on this idea, a non-deterministic conformant planner can be obtained from a
deterministic conformant planner in the following way. For the non-deterministic problem
P , let P1 be the problem P 0 above, with the additional constraint that the actions a in
P1 arising from the non-deterministic actions in P can be executed at most once. This
is easily achieved by adding a precondition enabled(a) to a that is true initially and that
a sets to false. Let then P2 represent the deterministic conformant problem where each
non-deterministic action a in P is mapped into 2 deterministic actions, each executable
only once, and each having its own hidden fluents h1 , . . . , hm with the oneof (h1 , . . . , hm )
expression in the initial situation. Similarly, let Pi be the deterministic problem that results
from encoding each non-deterministic action in P with i deterministic copies.
From this encoding, a simple iterative conformant planner for non-deterministic problems P can be defined in terms of a conformant planner for deterministic problems by
invoking the latter upon P1 , P2 , P3 , and so on, until a solution is reported. The reported
solution uses each copy of a non-deterministic action at most once, and thus encodes a
solution to the original problem.
We have implemented this strategy on top of T0 with an additional refinement that
takes advantage of the nature of the KT,M translation, where assumptions about the initial
situation are maintained explicitly in tags. Basically, non-deterministic actions a in Pi are
allowed to be executed more than once provided that all the literals KL/hi that depend
on a particular outcome of these actions (Si ) are erased. This is implemented by means
of an additional reset(a) action in Pi whose unconditional effect is enabled(a) (i.e., the
action a can then be done again) and whose conditional effects are KL  KL/hi and
KL  KL/hi for i = 1, . . . , m. Namely, literals KL/hi where the truth of L depends
on a particular non-deterministic outcome (Si ) are erased, except when L is true with no
assumptions; i.e. when KL is true. Then non-deterministic actions a can be executed more
than once in a plan provided that each occurrence of a, except for the first one, is preceded
by a reset(a) action.
Table 12 compares the resulting non-deterministic planner with MBP and KACMBP
on a number of non-deterministic problems considered in the MBP and KACMBP papers.
We have just added an additional domain, Slippery Gripper (sgripper), that is similar to
classical Gripper where a number of balls have to be moved from room A to B, except
that the robot cannot move from A to B directly, but has a non-deterministic move action
move(A, C, D) that moves the robot from A to either C or D. A typical plan for moving
two balls from A to B is to pick them at A, move to C or D, move from C to B, and from
D to B, finally dropping the balls at B.
For the deterministic conformant planner (T0 ) used in the non-deterministic setting we
added the following modification: merges are not introduced only for precondition and goal
658

fiCompiling Uncertainty Away in Conformant Planning Problems

Problem
sgripper-10
sgripper-20
sgripper-30
btuc-100
btuc-150
btuc-200
btuc-250
btuc-300
bmtuc-10-10
bmtuc-20-10
bmtuc-20-20
bmtuc-50-10
bmtuc-50-50
bmtuc-100-10
bmtuc-100-50
bmtuc-100-100
nondet-ring-5
nondet-ring-10
nondet-ring-15
nondet-ring-20
nondet-ring-50
nondet-ring-1key-5
nondet-ring-1key-10
nondet-ring-1key-15
nondet-ring-1key-20
nondet-ring-1key-25
nondet-ring-1key-30

T0
time len
1,4
48
16,7
93
90
138
2,9
200
9,2
300
23
400
44,6 500
82
600
0,1
20
0,1
40
0,3
40
0,9
100
3,3
100
4,9
200
14,9 200
30,2 200
18,3
19
> 2h
> 2h


> 2h
> 2.1GB





MBP
time
len
> 2h
> 2h

> 2h
> 2h



65,9
29
> 2h
> 2h





0
18
2,1
38
1298,9 58
> 2h

0,1
33
11,2
122
5164,4 87
> 2.1GB



KACMBP
time
len
0,6
68
5,4
148
23,3
228
2
200
7,9
300
16,9
400
33,2
500
62,1
600
0,2
20
0,6
40
2,2
40
3,6
100
2722,4 100
25,1
200
> 2h
> 2h
0,1
32
0,5
112
2,4
242
7,3
422
603,1 2552
0,2
42
4
197
33,7
375
246,5 1104
1417,5 2043
> 2h

Table 12: Non-deterministic problems. All problems except sgripper are from MBP and
KACMBP. These problems were modified to render a simple translation into
PDDL; in particular, complex preconditions were moved in as conditions. Times
reported in seconds and rounded to the closest decimal.  means time or memory
out for smaller instances.

literals but for all literals. The reason is that in this setting it pays to remove the uncertainty
of all literals when the reset mechanism is used. Indeed, provided with this simple change
and the reset mechanism, in none of the problems we had to move beyond P1 (a single copy
of each non-deterministic action) even if in all the domains non-deterministic actions are
required many times in the plans (e.g., if there are more than 2 balls in room A).
As it can be seen from the table, T0 does better than MBP on these collection of nondeterministic domains, although not as well as KACMBP, in particular, in the NonDetRing and Non-Det-Ring-1Key domains. In any case, the results obtained with T0 on these
domains are quite meaningful. In all cases where T0 failed to solved a problem, the reason
was that the classical planner (FF) got lost in the search for plans, something that may
improve with further advances in classical planning technology.

659

fiPalacios & Geffner

11. Related Work
Most recent conformant planners such as CFF, POND, and MBP cast conformant planning
as an heuristic search problem in belief space (Bonet & Geffner, 2000). Compact belief
representations and informed heuristic functions, however, are critical for making these approach work. As an effective belief representation, these planners use SAT and OBDDs
techniques that while intractable in the worst case often exhibit good behavior on average.
As heuristics, on the other hand, they use fixed cardinality heuristics that count the number
of states that are possible for a given belief state (a tractable operation on OBDD representations) or heuristics obtained from a relaxed planning graph suitably extended to take
uncertain information into account. These heuristics appear to work well in some domains
but not in others. From this perspective, the translation-based approach provides a handle
on the two problems: belief states in P become plain states in the translation KT,M (P ),
that is then solved using classical heuristics. We have also established the conditions under
which this belief representation is compact and complete.
A sound but incomplete approach to planning with incomplete information is advanced
by Petrick and Bacchus (2002) that represent belief states as formulas. In order to make
belief updates efficient though, several approximations are introduced, and in particular,
while existing disjunctions can be carried from one belief to the next, no new disjunctions
are added. This imposes a limitation on the type of problems that can be handled. The
two other limitations of this approach are that domains must be crafted by hand, and that
no control information is derived from the domains so that the search for plans is blind.
Our approach can be understood as providing a solution to these two problems too: on
the one hand, the move to the knowledge-level is done automatically, on the other, the
problem lifted to the knowledge-level is solved by classical planners able to search with
control information derived automatically from the new representation.
A third thread of work related to our approach arises from the so-called 0-approximation
semantics (Baral & Son, 1997). In the 0-approximation semantics, belief states b are represented not by sets of states but by a single 3-valued state where fluents can be true, false, or
unknown. In Proposition 3 above, a correspondence was established between the plans for
P that are conformant according to the 0-approximation semantics and the classical plans
for the translation K0 (P ), which in turns is an instance of the more general translation
Ki (P ) that is complete for problems with width i = 0. The semantics of the translation
K0 is thus related to the 0-approximation semantics, yet the K0 translation delivers something more: a computational method for obtaining conformant plans that comply with the
0-approximation semantics using a classical planner.
The 0-approximation and the basic K0 translation are too weak for dealing with the
existing benchmarks. The translations Ki extend K0 for problems of higher width by
replacing the set of fluents KL by fluents KL/t where the tags t encode assumptions about
the initial situation. The extensions of the 0-approximation semantics in the context of
conformant planning have taken a different form: switching from a single 3-valued state
for representing beliefs to sets of 3-valued states, each 3-valued state progressed efficiently
and independently of the others (Son, Tu, Gelfond, & Morales, 2005). The initial set of
3-valued states is obtained by forcing states to assign a boolean truth-value (true or false)
to a number of fluents. Crucial for this approach to work is the number of such fluents;
660

fiCompiling Uncertainty Away in Conformant Planning Problems

belief representation and update are exponential in it. The conditions that ensure the
completeness of this extension of the 0-approximation semantics can be expressed in terms
of a relevance analysis similar to the one underlying our analysis of width (Son & Tu,
2006): the fluents that must be set to true or false in each initial 3-valued state are those
appearing in a clause in CI (L) for a precondition or goal literal L. In particular, if in the
initial situation there are n tautologies pi pi , each relevant to a precondition or goal literal
L, then the number of initial 3-valued states required for completeness is exponential in n, as
each has to make each fluent pi true or false. The difference with our approach can be seen
when each of the tautologies pi  pi is relevant to a unique precondition or goal literal Li .
In such a case, the number of 3-valued or partial states required for completeness remains
exponential in n, while the resulting problem has width 1 and thus can be solved with the
K1 translation that involves tags with a single literal. In other words, while the tags used
in our translation scheme encode the local contexts required by the different literals in the
problem, the initial 3-valued states (Son & Tu, 2006) encode their possible combinations in
the form of global contexts. These global contexts correspond to the consistent combinations
of such local contexts, which may thus be exponential in number even if the problem has
bounded width. The planners CpA(H) and CpA(C), discussed above in the context of
the Conformant Track of the recent 2008 Int. Planning Competition (IPC6), build on this
approach, but reduce the number of partial initial states required using a technique that can
replace many one-of expressions by a single one (Tran et al., 2008, 2009); a simplification
related to the notion of critical initial states discussed in Section 7.
Another difference with the 3-valued approach (Son et al., 2005; Son & Tu, 2006), is
that the translation approach not only addresses the representation of beliefs but also the
computation of conformant plans: once a conformant problem P is translated into a problem
KT,M (P ), it can be solved by a classical planner. The approaches that have been defined on
top of the 0-approximation semantics, like the knowledge-level approach to planning with
incomplete information by Petrick and Bacchus (2002), need a way to guide the search for
plans in the simplified belief space. While the search by Petrick and Bacchus (2002) is blind
(iterative deepening), the search by Son et al. (2005), Son and Tu (2006) is guided by a
combination of simple heuristics such as cardinality or subgoal counting.

12. Summary
While few practical problems are purely conformant, the ability to find conformant plans is
needed in contingent settings where conformant situations are an special case. In this paper,
we have introduced a new approach to conformant planning where conformant problems P
are converted into classical planning problems KT,M (P ) that are then solved by a classical
planner. We have also studied the conditions under which this general translation is sound
and complete. The translation depends on two parameters: a set of tags, referring to local
contexts in the initial situation, and a set of merges that stand for valid disjunctions of
tags. We have seen how different translations, such as KS0 and Kmodels, can be obtained
from suitable choices of tags and merges, and have introduced a measure of complexity in
conformant planning called conformant width, and a translation scheme Ki that is polynomial for a fixed i and complete for problems with width bounded by i. We have also shown
that most conformant benchmarks have width 1, have developed a conformant planner T0
661

fiPalacios & Geffner

based on these translations, and have shown that this planner exhibits a good performance
in comparison with existing conformant planners. Recently, we have explored the use of
these ideas in the more general setting of contingent planning (Albore, Palacios, & Geffner,
2009).

Acknowledgments
We thank Alex Albore for help with the syntax of MBP and KACMBP, and Pierre Marquis
for kindly answering a question about the complexity of a deductive task. We also thank
the anonymous reviewers for useful comments. H. Geffner is partially supported by grant
TIN2006-15387-C03-03.

Appendix A. Proofs
P below stands for a conformant planning problem P = hF, I, O, Gi and KT,M (P ) =
hF 0 , I 0 , O0 , G0 i for its translation. Propositions and theorems in the body of the paper
appear in the appendix with the same numbers; while new lemmas and propositions have
numbers preceded by the letters A and B (for Appendix A and B). The conformant problem
P and the classical problems P/s and KT,M (P ) that arise from P are all assumed to be
consistent. Consistency issues are important, and they are addressed in more detail in the
second part of this appendix where it is shown that if P is consistent, KT,M (P ) is consistent
too (Appendix B). For a consistent classical problem P 0 , the standard progression lemma
applies; namely, a literal L is achieved by an applicable action sequence +1 = , a, where
 is an action sequence and a is an action iff A)  achieves C for a rule a : C  L in P 0 ,
or B)  achieves L and the negation L0 of a literal L0 in the body C 0 of each rule in P 0 of
the form a : C 0  L (see Theorem B.2 below).
Lemma A.1. Let  be an action sequence applicable in both P and K0 (P ). Then if 
achieves KL in K0 (P ),  achieves L in P .
Proof. By induction on the length of . If  is empty and  achieves KL in K0 (P ), then
KL must be in I 0 , and hence L must be in I, so that  achieves L in P .
Likewise, if +1 = , a achieves KL in K0 (P ) then A) there is rule a : KC  KL in
K0 (P ), such that  achieves KC in K0 (P ); or B)  achieves KL in K0 (P ) and for each
rule a : KC 0  KL in K0 (P ),  achieves KL0 in K0 (P ) for some L0 in C 0 .
If A) is true, then P must contain a rule a : C  L, and by inductive hypothesis, 
must achieve C in P , and therefore, +1 = , a must achieve L in P . If B) is true, by
inductive hypothesis,  must achieve L in P along with L0 for some literal L0 in the body
C 0 of each rule a : C 0  L, and thus +1 = , a must achieve L in P too.
Lemma A.2. If an action sequence  is applicable in K0 (P ), then  is applicable in P .
Proof. If  is empty, this is trivial. Likewise, if +1 = , a is applicable in K0 (P ),  is
applicable in K0 (P ), and thus by inductive hypothesis,  is applicable in P . Also since,
, a is applicable in K0 (P ),  must achieve the literals KL in K0 (P ) for each precondition
L of a, but then from Lemma A.1,  must achieve the literals L for the same preconditions
in P , and thus, the sequence +1 = , a is applicable in P .
662

fiCompiling Uncertainty Away in Conformant Planning Problems

Proposition 2 If  is a classical plan for K0 (P ), then  is a conformant plan for P .
Proof. Direct from Lemma A.2 once we consider a problem P 0 similar to P but with a new
dummy action aG whose preconditions are the goals G of P . Then if  is a plan for K0 (P ),
, aG is applicable in K0 (P 0 ), and by Lemma A.2, , aG is applicable in P 0 , which implies
that  is applicable in P and achieves G, and thus, that  is a plan for P .
Proposition 3 An action sequence  is a classical plan for K0 (P ) iff  is a conformant
plan for P according to the 0-approximation semantics.
Proof. Let us say that an action sequence  = a0 , . . . , an is 0-applicable in P and 0-achieves
a literal L in P if the belief sequence b0 , . . . , bn+1 generated according to the 0-approximation
semantics is such that the preconditions of the actions ai in  are true in bi , and the goals
are true in bn+1 respectively. From the definition of the 0-approximation semantics (and
the consistency of P ), an applicable action sequence  thus 0-achieves a literal L in P iff 
is empty and L  I, or  =  0 , a and A) a : C  L is an effect of P and  0 0-achieves each
literal L0 in C, or B)  0 0-achieves L and for all effects a : C 0  L in P ,  0 0-achieves L0
for some L0  C 0 . These, however, are the conditions under which  achieves the literal KL
in K0 (P ) once a sequence 0-achieving a literal L in P  is replaced by a sequence achieving
the literal KL in K0 (P ). Thus, an action sequence  that is applicable in K0 (P ) and
0-applicable in P achieves a literal KL in K0 (P ) iff  0-achieves the literal L in P , while 
is applicable to K0 (P ) iff it is 0-applicable to P , with the last part following from the first
using induction on the plan length.
Definition A.3. For an action a in P , define a to be the action sequence where a is
followed by all merges in KT,M (P ) in arbitrary order. Similarly, if  = a0 , . . . , ai is an
action sequence in P , define   to be the action sequence   = a0 , . . . , an in KT,M (P ).
Lemma A.4. Let  be an action sequence such that  is applicable in P and   is applicable
in a valid translation KT,M (P ). If   achieves KL/t in KT,M (P ), then  achieves L in
P/s for all possible initial states s that satisfy t.
Proof. For an empty , if   achieves KL/t, from the definition of KT,M (P ) and since
I |= t  L, L must be in any such s, and thus  must achieve L in P/s.

Likewise, if +1 = , a and t is not the empty tag, +1
=   , a achieves KL/t in

KT,M (P ) iff A)  achieves KC/t in KT,M (P ) for a rule a : KC/t  KL/t in KT,M (P ),
or B)   achieves KL/t, and for any rule a : KC 0 /t  KL/t,   achieves KL0 /t in
KT,M (P ) for some L0 in C 0 (merge actions do not delete positive literals KL/t).
If A, by inductive hypothesis,  achieves C in P/s for each possible initial state s that
satisfies t, and hence +1 = , a achieves L in P/s from the rule a : C  L that must be in
P . If B, by inductive hypothesis,  achieves L and L0 in P/s, for some L0 in the body of
each rule a : C 0  L in P , and thus +1 = , a achieves L in P/s.
V
For the empty tag t = , a third case must be considered: a merge action t0 m KL/t0 
 =   , a achieving KL in K
KL in a may be the cause for the action sequence +1
T,M (P ).



In such a case, the sequence  , a, and hence  , a , must achieve KL/t0 for each (nonempty) t0  m in KT,M (P ), and hence from the inductive hypothesis and the two cases
above, the sequence , a must achieve L in P/s for each possible initial state s that satisfies
663

fiPalacios & Geffner

any such t0 . Yet, since the merge m is valid, all possible initial states s must satisfy one
such t0 , and thus  must achieve L in P/s for all possible initial states s, that are the initial
states that satisfy t = .
Lemma A.5. If   is applicable in a valid translation KT,M (P ), then  is applicable in P .
 =   , a is applicable in K
Proof. If  is empty, this is direct. For +1 = , a, if +1
T,M (P ),

then  is applicable in KT,M (P ), achieving KL for each precondition L of a, and hence
from the inductive hypothesis,  is applicable in P , and from Lemma A.4,  must achieve
L for each precondition L of a, and thus +1 = , a is applicable in P .

Theorem 7 The translation KT,M (P ) is sound provided that all merges in M are valid
and all tags in T are consistent.
Proof. Consider the problem P 0 that is similar to P but with a new dummy action aG
whose preconditions are the goals G of P . We have then that   is a plan for KT,M (P ) iff
1 , aG is applicable in KT,M (P 0 ), which from Lemma A.5 implies that , aG is applicable
in P 0 , which means that  is a plan for P .
Lemma A.6. Let  be an action sequence such that  is applicable in P and   is applicable
in KS0 (P ). If  achieves L in P/s for some possible initial state s,   achieves KL/s in
KS0 (P ).
Proof. If  is empty and  achieves L in P/s, then L  s, and since I |= s  L, KL/s must
be in I 0 and thus   achieves KL/s in KS0 (P ).
Likewise, if +1 = , a achieves L in P/s then A) there is rule a : C  L such that
 achieves C in P/s; or B)  achieves L and for any rule a : C 0  L,  achieves L0 in
KS0 (P ) for some L0  C 0 .
If A), by inductive hypothesis,   achieves KC/s in KS0 (P ) and, from rule a : KC/s 
 =   , a achieves KL/s (merges in a do
KL/s,   , a must achieve KL/s, and thus, +1
not delete positive literals KL/t).
If B), by inductive hypothesis,   achieves KL/s and KL0 /s in KS0 (P ) for some L0
in the body of each rule a : C 0  L in P , and therefore   , a achieves KL/s, and so does
 =   , a .
+1
Lemma A.7. If  is applicable in P ,   is applicable in KS0 (P ).
Proof. If  is empty, this is trivial. If +1 = , a is applicable in P , then  must be
applicable in P and must achieve each precondition L of a in P/s for every possible initial
state s, s  S0 . From the inductive hypothesis,   must then be applicable in KS0 (P ),
and from Lemma A.6, it V
must achieve the literals KL/s for all s  S0 , and then, the last
merge action with effect sS0 KL/s  KL in   must achieve KL, and so does   , and
therefore,   , a is applicable in KS0 (P ).
Theorem 9 If  is a conformant plan for P , then there is a classical plan  0 for KS0 (P )
such that  is the result of dropping the merge actions from  0 .
664

fiCompiling Uncertainty Away in Conformant Planning Problems

Proof. Direct from Lemma A.7 if we consider a problem P 0 similar to P but with a new
action aG whose preconditions are the goals G of P . If  is a plan for P , the sequence , aG
is applicable in P 0 , and from Lemma A.7,   , aG is applicable in KS0 (P 0 ), and thus   is a
plan for KS0 (P ).
Definition A.8. rel(s, L) stands for the set of literals L0 in s that are relevant to L in P :
rel(s, L) = {L0 | L0  s and L0 is relevant to L} .
Definition A.9. t stands for the deductive closure of t under I:
t = { L | I, t |= L} .
Theorem A.10. Let m = {t1 , . . . , tn } be a covering merge for a literal L in a valid translation KT,M (P ) for a problem P whose initial situation is in prime implicate form. Then
for each tag ti in m there must be a possible initial state s of P such that rel(s, L)  ti .
Proof. Assume otherwise that each state s satisfying I makes true a literal Ls relevant to
L such that Ls 6 ti . If we then take c to be the disjunction of such literals Ls over all the
states s that satisfy I, we obtain that I entails c, which since I is in prime implicate form,
means that c contains a tautology c0 or is subsumed by a clause c00 in I. But, in either case,
this is a contradiction, as all the literals in c0 or c00 are relevant to L, and hence ti , where ti
is part of the covering merge m, must contain a literal in either c0 or c00 , and hence in c.
Lemma A.11. Let  be an action sequence such that  is applicable in P and   is applicable in a covering translation KT,M (P ). Then, if  achieves L in P/s for some possible
initial state s and there is a tag t in T such that rel(s, L)  t ,   achieves KL/t in
KT,M (P ).
Proof. If  is empty and  achieves L in P/s, then L is in s and thus, in rel(s, L). Since
rel(s, L)  t , then L  t , and thus KL/t is in the initial situation I 0 of KT,M (P ), and
  achieves KL/t in KT,M (P ). Likewise, if +1 = , a achieves L in P/s, then A) there
is a rule a : C  L in P such that  achieves C in P/s, or B)  achieves L in P/s and
for each rule a : C 0  L,  achieves L0 in P/s for some L0 in C 0 . If A, by inductive
hypothesis,   achieves KC/t, and from the support rule a : KC/t  KL/t in KT,M (P ),
 =   , a , as the merges in a cannot
  , a must achieve KL/t in KT,M (P ), and so must +1
delete a positive literal KL/t. If B, by inductive hypothesis,   achieves KL/t, and for each
cancellation rule a : KC 0 /t  KL/t arising from the rule a : C 0  L in P ,   must
 =   , a ,
achieve KL0 /t for some literal L0  C 0 . This means that   , a, and therefore, +1
must achieve KL/t.
Lemma A.12. Let KT,M (P ) be a covering translation of P . Then if  is applicable in P ,
  is applicable in KT,M (P ).
Proof. If  is empty, this is direct. Else, if +1 = , a is applicable in P , then  must be
applicable in P where it must achieve each literal L in P re(a), and therefore, by inductive
hypothesis   must be applicable in KT,M (P ). Then, let m = {t1 , . . . , tn } be a covering
merge for L  P re(a) in KT,M (P ). From Theorem A.10, for each ti  m there must be a
665

fiPalacios & Geffner

possible initial state s such that rel(s, L)  ti , and then from Lemma A.11,  achieving L in
P/s implies   achieving KL/ti in KT,M (P ). Since this is true for all ti  m and  achieves
L  P re(a) in P/s for all possible initial states s, then it follows that   achieves KL/ti
for all ti  m in KT,M (P ), and therefore that   achieves KL in KT,MV(P ) as   ends with
a sequence of merges that include the action merge am,L with effect ti m KL/ti  KL.
 =   , a is applicable in K
As a result, +1
T,M (P ).
Theorem 15 Covering translations KT,M (P ) are complete; i.e., if  is a conformant plan
for P , then there is a classical plan  0 for KT,M (P ) such that  is  0 with the merge actions
removed.
Proof. The theorem follows trivially from Lemma A.12 by having a problem P 0 that is like
P but with an additional, dummy action aG such that the goals G of P are the preconditions
of aG . The action sequence  is a plan for P iff the action sequence , aG is applicable in P 0 ,
which due to Lemma A.12 implies that the action sequence   , aG is applicable in KT,M (P 0 )
which in turn is true iff the action sequence   is a plan for KT,M (P ). The sequence , in
turn, is the sequence   with all the merge actions removed.
Theorem 17 The translation Kmodels(P ) is sound and complete.
Proof. Direct from the merges m generated by Kmodels for each precondition and goal
literals L. Clearly these merges are all valid, their tags are consistent with I, and they
cover L (the models of CI (L) all satisfy CI (L)). Thus the result follows from Theorems 7
and 15.
Proposition 21 The width w(P ) of P can be determined in time that is exponential in
w(P ).
Proof. If m is the number of clauses in CI (L), then there are at most mi sets of clauses C in
CI (L) such that |C| = i. Each clause in one such set must have at most n literals, where n is
the number of fluents in P , and hence, if one literal from each clause in C is collected, we end
up with at most ni sets of literals of size no greater than i, some of which are inconsistent
with I and some of which are consistent and minimal (no other consistent set in the collection
is properly included); both tests being polynomial given that I is in prime implicate form.
Thus constructing the cover c(C) for a set of clauses C with |C| = i is exponential in i,
while checking whether one such cover satisfies CI (L) is a polynomial operation provided
that I is in prime implicate form. Indeed, if c(C) = {t1 , . . . , tn }, computing the closures
ti for each ti  c(C), when I is in PI, and testing whether each ti intersects each clause
in CI (L) are polynomial operations (the former reducing to checking for each literal L0
whether I |= ti  L0 ). Thus for computing width(L), we generate all sets C of clauses
in CI (L) with |C| = i, starting with i = 0, increasing i one by one until for one such set,
c(C) satisfies CI (L). This computation is exponential in w(L), and the computation over
all preconditions and goal literals in P is exponential in w(P ).
Proposition 22 The width of P is such that 0  w(P )  n, where n is the number of
fluents whose value in the initial situation is not known.
666

fiCompiling Uncertainty Away in Conformant Planning Problems

Proof. The inequality 0  w(P ) is direct as w(L) is defined as the size |C| of the minimal set
of clauses C in CI (L) such that c(C) satisfies CI (L), and w(P ) = w(L) for some precondition
and goal literal L. The inequality w(P )  n follows by noticing that for the set C of clauses
given by the tautologies L0  L0 in CI (L), c(C) must satisfy each clause c in CI (L), as each
t  c(C) must assign a truth value to each literal in c, and if inconsistent with c, it will be
inconsistent with I and thus pruned from c(C). Finally, the max number of such tautologies
in CI (L) is the number of fluents L0 such that neither L0 nor L0 are unit clauses in I.
Theorem 24 For a fixed i, the translation Ki (P ) is sound, polynomial, and if w(P )  i,
covering and complete.
Proof. For soundness, we just need to prove that all merges m in Ki (P ) are valid and that
all tags t in Ki (P ) are consistent. The soundness follows from Theorem 7. The merges
m for a literal L in Ki (P ) are given by the covers c(C) of collections C of i or less clauses
in Ci (L) and clearly since
each model M of I must satisfy CI (L), it must satisfy some
W
t  c(C) so that I |= tm t for m = c(C). At the same time, from the definition of the
cover c(C), each of these tags t must be consistent with I.
For proving that Ki is polynomial for a fixed i, we follow ideas similar to the ones used
in the proof of Proposition 21 above, where we have shown that the width of P can be
determined in time that is exponential in w(P ) and polynomial in the number of clauses
and fluents in P . For a fixed i, the number of sets of clauses C in CI (L) with size |C|  i is
polynomial, and the complexity of computing the covers c(C) for such sets, and hence, the
merges m for L in Ki (P ) is polynomial too. Thus, the whole translation Ki (P ) for a fixed
i is polynomial in the number of clauses, fluents, and rules in P .
Finally, for proving completeness, if w(P )  i, then w(L)  i for each precondition and
goal literal L in P . Therefore, for each such literal L, there is a set C of clauses in CI (L)
such that c(C) satisfies CI (L). The translation Ki (P ) will then generate a unique merge
for L that covers L. Since Ki (P ) is a valid translation, this means that Ki (P ) is a covering
translation, that is then complete, by virtue of Theorem 15.
Lemma A.13. If L0 is relevant to L and rel(s, L)  rel(s0 , L), then rel(s, L0 )  rel(s0 , L0 ).
Proof. If L00 is in rel(s, L0 ), then L00 is relevant to L0 , and since L0 is relevant to L and the
relevance relation is transitive, L00 is relevant to L. Thus, L00 is in rel(s, L) and therefore,
since rel(s, L)  rel(s0 , L), L00 is in rel(s0 , L). But then L00 is in s0 and since it is relevant
to L0 , L00 is in rel(s0 , L0 ).
Proposition 26 Let s and s0 be two states and let  be an action sequence applicable in
the classical problems P/s and P/s0 . Then if  achieves a literal L in P/s0 and rel(s0 , L) 
rel(s, L),  achieves the literal L in P/s.
Proof. By induction on the length of . If  is empty, and  achieves a literal L in P/s0 , L
must be in s0 , and since L is relevant to itself, L  rel(s0 , L). Then as rel(s0 , L)  rel(s, L),
L must be in s, and thus  achieves L in P/s.
667

fiPalacios & Geffner

Likewise, if +1 = , a achieves L in P/s0 then A) there is rule a : C  L such that 
achieves C in P/s0 ; or B)  achieves L in P/s0 and for any rule a : C 0  L,  achieves
L0 in P/s0 for some L0  C 0 .
If A,  must achieve each literal Li  C in P/s0 . Since Li is relevant to L and rel(s0 , L) 
rel(s, L), by Lemma A.13, rel(s0 , Li )  rel(s, Li ). Then, by inductive hypothesis, the plan
 must achieve Li in P/s for each Li  C, and thus +1 = , a must achieve L in P/s
If B, since each such L0 is relevant to L (as L0 is relevant to L), and rel(s0 , L) 
rel(s, L), by Lemma A.13, rel(s0 , L0 )  rel(s, L0 ), and thus by inductive hypothesis, 
must achieve L0 in P/s and also L, so that +1 = , a must achieve L in P/s.
Lemma A.14. If S and S 0 are two collection of states such that for every state s in S and
every precondition and goal literal L in P , there is a state s0 in S 0 such that rel(s0 , L) 
rel(s, L), then if  is applicable in P/S 0 ,  is applicable in P/S.
Proof. By induction on the length of . If  is empty, it is obvious. If +1 = , a is applicable
in P/S 0 , then  is applicable in P/S 0 and, by inductive hypothesis,  is applicable in P/S.
We need to prove that  achieves the preconditions of action a in P/S.
For any L  P rec(a) and any s  S, from the hypothesis, there is a state s0  S 0 such
that rel(s0 , L)  rel(s, L). From Proposition 26, and since  achieves L in P/s0 ,  must
achieve L in P/s. Since the argument applies to any s  S,  achieves L in P/S, and thus
+1 = , a must be applicable in P/S.
Proposition 27 If S and S 0 are two collections of states such that for every state s in S
and every precondition and goal literal L in P , there is a state s0 in S 0 such that rel(s0 , L) 
rel(s, L), then if  is a plan for P that conforms with S 0 ,  is a plan for P that conforms
with S.
Proof. From Lemma A.14, we consider a problem P 0 similar to P but with a new action
aG whose preconditions are the goals G of P . If  is a plan for P that conforms with S 0 ,
then the action sequence , aG is applicable in P 0 /S 0 , and then from the lemma, , aG is
applicable in P 0 /S, and thus  must be a plan for P/S
Proposition 28 S 0 is a basis for P if for every possible initial state s of P and every
precondition and goal literal L in P , S 0 contains a state s0 such that rel(s0 , L)  rel(s, L).
Proof. Direct from Proposition 27, by considering S to be the set of possible initial states
of P .
Proposition 29 If the initial situation I is in prime implicate form and m = {t1 , . . . , tn }
is a merge that covers a literal L in P , then the set S[ti , L] of possible initial states s of P
such that rel(s, L)  ti is non-empty.
Proof. Direct from Theorem A.10.
Theorem 30 Let KT,M (P ) be a covering translation and let S 0 stand for the collection of
states s[ti , L] where L is a precondition or goal literal of P and ti is a tag in a merge m
that covers L. Then S 0 is a basis for P .
668

fiCompiling Uncertainty Away in Conformant Planning Problems

Proof. We show that for every possible initial state s and any precondition and goal literal
L, S 0 in the theorem contains a state s0 such that rel(s0 , L)  rel(s, L). The result then
follows from Proposition 28. Indeed, any such state s must satisfy a tag ti in a covering
merge m = {t1 , . . . , tn } for L, as these merges are valid. But from Theorem A.10, there must
be a possible initial state s0 such that rel(s0 , L)  ti , and therefore, rel(s0 , L)  rel(s, L) as
s must satisfy ti and possibly other literals L0 that are relevant to L.
Theorem 31 If P is a conformant planning problem with bounded width, then P admits
a basis of polynomial size.
Proof. If w(P )  i for a fixed i, Ki (P ) is a covering translation with a polynomial number
of merges and tags, and in such case, the basis S 0 for P defined by Theorem 30 contains a
polynomial number of states, regardless of the number of possible initial states.

Appendix B. Consistency
We have been assuming throughout the paper that the conformant planning problems P
and their translations KT,M (P ) are consistent. In this section we make this notion precise,
explain why it is needed, and prove that KT,M (P ) is consistent if P is. For the proof, we
take into account that the heads KL of the merge actions am,L in KT,M (P ), are extended
with the literals KL0 for the literals L0 that are mutex with L in P (see Definition 4).
We start at the beginning assuming that states are not truth-assignments but sets of
literals over the fluents of the language. A state is complete if for every literal L, L or L is
in s, and consistent if for no literal both L and L are in s. Complete and consistent
states represent truth-assignments over the fluents F and the consistency of P and of
the translation KT,M (P ) ensures that all applicable action sequences  map complete and
consistent states s into complete and consistent states s0 . Once this is guaranteed, complete
and consistent states can be referred to simply as states which is what we have done in the
paper.
Given a complete state s and an action a applicable in s, the next state sa is
sa = (s \ Del(a, s))  Add(a, s)
where
Add(a, s) = {L | a : C  L in P and C  s}
and
Del(a, s) = {L | L  Add(a, s)} .
It follows from this that sa is a complete state if s is a complete state, as the action a
only deletes a literal L in s if L is added by a in s. On the other hand, s may be consistent
and sa inconsistent, as for example, when there are rules a : C  L and a : C 0  L such
that both C and C 0 are in s. In order to exclude this possibility, ensuring that all reachable
states are complete and consistent, and thus represent genuine truth assignments over the
fluents in F , a consistency condition on P is needed:
Definition B.1 (Consistency). A classical or conformant problem P = hF, I, O, Gi is consistent if the initial situation I is logically consistent and every pair of complementary
literals L and L is mutex in P .
669

fiPalacios & Geffner

In a consistent classical problem P , all the reachable states are complete and consistent,
and the standard progression lemma used in the preceding proofs holds:
Theorem B.2 (Progression). An action sequence +1 = , a applicable in the complete and
consistent state s achieves a literal L in a consistent classical problem P iff A)  achieves
the body C of a rule a : C  L in P , or B)  achieves L and for every rule a : C 0  L,
 achieves L0 for a literal L0 in C 0 .
We will see below that if a conformant problem P is consistent in this sense, so will be
any valid translation KT,M (P ). We have tested all the benchmarks considered in this paper
for consistency and found all of them to be consistent except for two domains that we have
introduced elsewhere: 1-Dispose and Look-and-Grab. In these cases, since the consistency
of the classical problem KT,M (P ) cannot be inferred from the consistency of P , it can
be checked explicitly using Definition B.1, or similarly, the plans that are obtained from
KT,M (P ) can be checked for consistency as indicated in Section 8: the soundness of these
plans is ensured provided that they never trigger conflicting effects KL/t and KL/t.10
Proof. The proof of Theorem B.2 does not rest on a particular definition of mutexes, just
that mutex atoms are not both true in a reachable state. In a consistent problem P , an
applicable action sequence  maps s into a complete and consistent state s0 that represents
a truth assignment. Then, the action sequence +1 = , a achieves L iff C) L  Add(a, s0 )
or D) L  s0 and L 6 Del(a, s0 ). Condition A in the theorem, however, is equivalent to C,
and Condition B in the theorem, is equivalent to D. Indeed, L 6 Del(a, s0 ) iff for each rule
a : C 0  L there is a literal L0  C 0 such that L0 6 s0 , which, given that s0 is complete and
consistent, is true iff L0  s0 (this is precisely where consistency is needed; else L0  s0
would not imply L0 6 s0 ).
The notion of mutex used in the definition of consistency expresses a guarantee that
a pair of literals is not true in a reachable state. Sufficient and polynomial conditions for
mutual exclusivity and other type of invariants have been defined in various papers, here
we follow the definition by Bonet and Geffner (1999).
Definition B.3 (Mutex Set). A mutex set is a collection R of unordered literals pairs
(L, L0 ) over a classical or conformant problem P such that:
1. for no pair (L, L0 ) in R, both L and L0 are in a possible initial state s,
2. if a : C  L and a : C 0  L0 are two rules for the same action where (L, L0 ) is a pair
in R, then P re(a)  C  C 0 is mutex in R, and
3. if a : C  L is a rule in P for a literal L in a pair (L, L0 ) in R, then either a) L0 = L,
b) P re(a)  C is mutex with L0 in R, or c) P re(a)  C implies C 0 in R for a rule
a : C 0  L0 in P ;
10. The consistency of the two domains, 1-Dispose and Look-and-Grab, can be established however if a
definition of mutexes slightly stronger than the one below is used. It actually suffices to change the
expression P re(a)  C in clause 3c) of the definition of mutex sets below by P re(a)  C  {L0 }.

670

fiCompiling Uncertainty Away in Conformant Planning Problems

In this definition, a pair is said to be mutex in R if it belongs to R, a set of literals S is
said to be mutex in R if S contains a pair in R, and a set of literals S is said to imply a set
of literals S 0 in R when S is mutex in R with the complement L of each literal L in S 0 \ S.
It easy to verify that if R1 and R2 are mutex sets, their union R1  R2 is a mutex set,
and thus that there is a maximal mutex set for P that we denote as R . The pairs in R
are just called mutexes.
For simplicity and without loss of generality, we will assume that preconditions P re(a)
are empty. Indeed, it is simple to show that the mutexes of a problem P remain the same
if preconditions are pushed in as conditions. We also assume that no condition C in a rule
C  L in P is mutex, as these rules can be simply pruned. In addition, we assume that no
literal L is mutex with a pair of complementary literals L0 and L0 , as then L cannot be
true in a reachable state, and thus, can be pruned as well.
The definition of mutexes is sound, meaning that no pair in a mutex set can be true in
a reachable state:
Theorem B.4. If (L, L0 ) is a pair in a mutex set R of a classical or conformant problem
P , then for no reachable state s in P , {L, L0 }  s.
Proof. We proceed inductively. Clearly, L and L0 cannot be part of a possible initial state, as
this is ruled out by the definition of mutex sets. Thus, let us assume as inductive hypothesis
that L and L0 are not part of any state s reachable in less than i steps, and let us prove
that the same is true for the states s0 = sa that are reachable from s in one step. Clearly if
L and L0 belong to s0 , then either A) both L and L0 belong to Add(a, s), or B) L belongs
to Add(a, s) and L0 belongs to s but not to Del(a, s). We show that this is not possible.
For A, P must comprise rules a : C  L and a : C 0  L0 such that C  C 0  s, yet from
the definition of mutex sets, C  C 0 must be mutex, and from the inductive hypothesis then
C  C 0 6 s. For B, there must be a rule a : C  L with C  s, but then from L0  s
and the inductive hypothesis, it follows that L0 is not mutex with C in R, and thus, from
the mutex set definition, that either L0 = L or C implies C 0 for a rule a : C 0  L0 . In
the first case, however, due to the rule a : C  L and C  s, L0  Del(a, s), while in the
second case, from the completeness of all reachable states, we must have C 0  s, and hence
L0  Del(a, s), contradicting B in both cases.
Provided that the initial situation I of a conformant planning problem P is in prime
implicate form, computing the largest mutex set R and testing the consistency of P are
polynomial time operations. For the former, one starts with the set of literal pairs and
then iteratively drops from this set the pairs that do not comply with the definition until
reaching a fixed point (Bonet & Geffner, 1999).
We move on now to prove that if a conformant problem P is consistent, so is a valid
translation KT,M (P ). The consistency of the classical problems P/s for possible initial
states s is direct, as the set of mutexes in P is a subset of the set of mutexes in P/s where
the initial situation is more constrained.
Proposition B.5 (Mutex Set RT ). For a valid translation KT,M (P ) of a consistent conformant problem P , define RT to be the set of (unordered) literals pairs (KL/t, KL0 /t0 ) and
(KL/t, KL0 /t) where (L, L0 ) is a mutex in P , and t and t0 are two tags jointly satisfiable
with I (I 6|= (t  t0 )). Then RT is a mutex set in KT,M (P ).
671

fiPalacios & Geffner

It follows from this that KT,M (P ) is consistent if P is consistent, as then L0 = L is
mutex with L in P , and so (KL/t, KL/t) must be a mutex in RT .
Theorem B.6 (Consistency KT,M (P )). A valid translation KT,M (P ) is consistent if P is
consistent.
The consistency of the translation K0 (P ) follows as a special case, as K0 (P ) is KT,M (P )
with an empty set of merges M and a set of tags T containing only the empty tag. We are
left to prove Proposition B.5.
Proof of Proposition B.5. We must show that the set RT comprised of the pairs (KL/t, KL0 /t0 )
and (KL/t, KL0 /t) for L0 mutex with L in P , and tags t and t0 jointly satisfiable with
I, is a set that complies with clauses 1, 2, and 3 of Definition B.3. We go one clause at a
time.
1. No pair in RT can be true initially in KT,M (P ) = hF 0 , I 0 , O0 , G0 i for jointly satisfiable
I, t, and t0 . Indeed, if both KL/t and KL0 /t0 are in I 0 there must be a possible initial
state satisfying t and t0 where L and L0 are true in contradiction with L and L0 being
mutex in P . Similarly, if KL/t is in I 0 but KL0 /t not, it must be the case that
I |= t  L and I 6|= t  L0 , so that there must be some possible initial state of P
where t, L, and L0 hold, a contradiction with L and L0 being mutex in P too.
2. If there is an action a with rules for KL/t and KL0 /t0 then the rules must be support
rules of the form a : KC/t  KL/t and a : KC 0 /t0  KL0 /t0 arising from rules
a : C  L and a : C 0  L0 in P .11 Then since L and L0 are mutex in P , C and C 0
must contain literals L1  C and L2  C 0 such that (L1 , L2 ) is a mutex in P , and
hence (KL1 /t, KL2 /t0 ) belongs to RT , so that KC/t and KC 0 /t0 are mutex in RT as
well.
Similarly, if there is an action with rules for KL/t and KL0 /t for a literal L0
mutex with L in P , the rules must be support and cancellation rules of the form
a : KC/t  KL/t a : KC 0 /t  KL0 /t, arising from rules a : C  L and
a : C 0  L0 in P . Since L and L0 are mutex in P , C and C 0 must contain literals
L1  C and L2  C 0 that are mutex in P , and hence RT must contain the pair
(KL1 /t, KL2 /t), so that KC/t and KC 0 /t must be mutex in RT .
3. We are left to show that the set RT given by the pairs (KL/t, KL0 /t0 ) and (KL/t,
KL0 /t) complies with clause 3 in the definition of mutex sets as well. Consider the
first class of pairs (KL/t, KL0 /t0 ) and a rule a : KC/t  KL/t for KL/t arising from
a rule a : C  L in P . Since L is mutex with L0 in P , then one of the conditions 3a,
3b, or 3c must hold for the rule a : C  L and L0 . If 3a, then L0 = L, and KC/t
must imply the body KC/t0 of the cancellation rule a : KC/t0  KL/t0 , as
for each literal L1 in C, RT must contain the pair (KL1 /t, KL1 /t0 ) so that KL1 /t
implies KL1 /t0 , and KC/t implies KC/t0 (case 3c). If 3b, then C and L0 are
11. The action a cannot be a merge for a literal L00 mutex with both L and L0 , as in such case, L00 implies
that L and L0 that are mutex. Similarly, a cannot be a merge for L as in such a case, L will be mutex
with both L0 and L0 . For the same reason, a cannot be a merge for L0 either. Thus, the action a above
cannot be a merge and must be an action from P .

672

fiCompiling Uncertainty Away in Conformant Planning Problems

mutex in P , and thus C contains a literal L1 mutex with L0 in P . This means that
the pair (KL1 /t, KL0 /t0 ) is in RT and hence that KC/t is mutex with KL0 /t0 in RT
(case 3b). Last, if 3c, C implies C 0 in P for a rule a : C 0  L0 , but then KC/t must
imply the body KC 0 /t0 of the cancellation rule a : KC 0 /t0  KL0 /t0 . Indeed,
for each literal L1 in both C and C 0 , we had above that KL1 /t implies KL1 /t0 ,
while if L2 is a literal in C 0 but not in C, then some literal L3  C must be mutex with
L2 in P , and hence the pair (KL3 /t, KL2 /t0 ) must be in RT and KL3 /t implies
then KL2 /t0 (case 3c)
0 0
Consider
V now the same pair (KL/t, KL /t ) along with a merge action am,L with a
rule ti m KL/ti  KL for KL/t = KL (thus t is the empty tag). In this case, since
the merge m is valid and t0 is consistent, there must be some ti  m such that ti and
t0 are jointly consistent with I. It follows then that (KL/ti , KL0 /t0 ) is a pair in RT
and thus that the body of the merge is mutex with KL0 /t0 in RT (case 3b).

There is no need to consider the pair (KL/t, KL0 /t0 ) along with the rules for KL0 /t0 ,
as the literals KL/t and KL0 /t0 have the same structure, and thus the same argument
above applies, replacing t with t0 and L with L0 .
We switch now to the second class of pairs (KL/t, K/L0 /t) and the rules a :
KC/t  KL/t for KL/t. Since L and L0 are mutex in P , then conditions 3a, 3b, or
3c must hold. If a, then L0 = L, and in such a case, condition 3c holds in KT,M (P )
as KC/t implies the body KC/t of the rule a : KC/t  KL0 (L0 = L). If b, C
is mutex with L0 , and thus there is a literal L1 in C such that L1 and L0 are mutex
in P , and therefore KC/t and KL0 /t are mutex in RT (case 3b). Finally, if c, C
implies C 0 for a rule a : C 0  L0 in P , then KC/t must imply KC 0 /t in RT for a
rule a : KC 0 /t  KL0 /t (case 3c).
For the empty tag t, the rule for KL/t may also be a merge, but then due to the extra
effects KL0 in the merge action for L, the merge for KL is also a merge for KL0 ,
and then case 3c holds.
Last, for the same class of pairs, the only rules for KL0 /t are cancellation rules of
the form a : KC 00 /t  KL0 /t for a rule a : C 00  L0 in P . Since L0 is mutex with
L in P , then conditions 3a, 3b, or 3c must hold for the rule a : C 00  L0 and L0 in P . If
a, then L = L0 , and the cancellation rule is then a : KC 00 /t  KL (case 3c). If
b, C 00 is mutex with L, and thus there is a literal L2 in C 00 such that (L2 , L) is a mutex
in P , and therefore KL/t implies KL2 /t in RT , and hence KL2 /t and KC 00 /t
imply KL/t in RT (case 3b). Finally, if c, C 00 implies C 0 for a rule a : C 0  L in P ,
and then KC 00 /t must imply KC 0 /t for a rule a : KC 0 /t  KL/t in RT .
Indeed, if LA implies LB in P , LB implies LA in P , and KLB /t implies KLA /t
in RT , and KLA /t implies KLB /t.

References
Albore, A., Palacios, H., & Geffner, H. (2009). A translation-based approach to contingent
planning. In Proc. 21st Int. Joint Conference on AI (IJCAI-09), pp. 16231628.
673

fiPalacios & Geffner

Baral, C., Kreinovich, V., & Trejo, R. (2000). Computational complexity of planning and
approximate planning in the presence of incompleteness. Artificial Intelligence, 122 (12), 241267.
Baral, C., & Son, T. C. (1997). Approximate reasoning about actions in presence of sensing
and incomplete information. In Proc. ILPS 1997, pp. 387401.
Bayardo Jr., R., & Schrag, R. (1997). Using CSP look-back techniques to solve real-world
sat instances. In Proc. AAAI, pp. 203208.
Bertoli, P., & Cimatti, A. (2002). Improving heuristics for planning as search in belief space.
In Ghallab, M., Hertzberg, J., & Traverso, P. (Eds.), Proc. AIPS-2002, pp. 143152.
AAAI Press.
Bonet, B., & Geffner, H. (1999). Planning as heuristic search: New results. In Proceedings
of ECP-99, pp. 359371. Springer.
Bonet, B., & Geffner, H. (2000). Planning with incomplete information as heuristic search
in belief space. In Proc. of AIPS-2000, pp. 5261. AAAI Press.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129 (1
2), 533.
Bonet, B., & Givan, B. (2006). Results of the conformant track of the 5th int. planning
competition. At http://www.ldc.usb.ve/bonet/ipc5/docs/results-conformant.pdf.
Bryce, D., & Buffet, O. (2008). International planning competition uncertainty part: Benchmarks and results. At http://ippc-2008.loria.fr/wiki/images/0/03/Results.pdf.
Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics for belief
space search. Journal of Artificial Intelligence Research, 26, 3599.
Cimatti, A., Roveri, M., & Bertoli, P. (2004). Conformant planning via symbolic model
checking and heuristic search. Artificial Intelligence, 159, 127206.
Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
Goldman, R. P., & Boddy, M. S. (1996). Expressive planning and explicit knowledge. In
Proc. AIPS-1996, pp. 110117.
Haslum, P., & Jonsson, P. (1999). Some results on the complexity of planning with incomplete information. In Proc. ECP-99, Lect. Notes in AI Vol 1809, pp. 308318.
Springer.
Hoffmann, J., & Brafman, R. (2005). Contingent planning via heuristic forward search with
implicit belief states. In Proc. 15th Int. Conf. on Automated Planning and Scheduling
(ICAPS 2005), pp. 7180. AAAI.
Hoffmann, J., & Brafman, R. (2006). Conformant planning via heuristic forward search: A
new approach. Artificial Intelligence, 170 (6-7), 507541.
Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through
heuristic search. Journal of Artificial Intelligence Research, 14, 253302.
Marquis, P. (2000). Consequence finding algorithms. In Gabbay, D., & Smets, P. (Eds.),
Handbook on Defeasible Reasoning and Uncertainty Management Systems, Vol. 5, pp.
41145. Kluwer.
674

fiCompiling Uncertainty Away in Conformant Planning Problems

Palacios, H., & Geffner, H. (2006). Compiling uncertainty away: Solving conformant planning problems using a classical planner (sometimes). In Proc. AAAI-06, pp. 900905.
Palacios, H., & Geffner, H. (2007). From conformant into classical planning: Efficient translations that may be complete too. In Proc. ICAPS-07, pp. 264271.
Petrick, R., & Bacchus, F. (2002). A knowledge-based approach to planning with incomplete
information and sensing. In Proc. AIPS-02, pp. 212221.
Rintanen, J. (2004). Complexity of planning with partial observability. In Proc. ICAPS2004, pp. 345354.
Smith, D., & Weld, D. (1998). Conformant graphplan. In Proceedings AAAI-98, pp. 889
896. AAAI Press.
Son, T. C., Tu, P. H., Gelfond, M., & Morales, A. (2005). Conformant planning for domains
with constraints: A new approach. In Proc. AAAI-05, pp. 12111216.
Son, T. C., & Tu, P. H. (2006). On the completeness of approximation based reasoning and
planning in action theories with incomplete information.. In Proc. 10th Int. Conf. on
Principles of KR and Reasoning (KR-06), pp. 481491.
Tison, P. (1967). Generalized consensus theory and applications to the minimization of
boolean circuits. IEEE Transactions on Computers, EC-16 (4), 446456.
Tran, D., Nguyen, H., Pontelli, E., & Son, T. C. (2008). CPA(C)/(H): Two approximationbased conformant planners. At http://ippc-2008.loria.fr/wiki/images/5/57/Team2CPA.pdf.
Tran, D., Nguyen, H., Pontelli, E., & Son, T. C. (2009). Improving performance of conformant planners: Static analysis of declarative planning domain specifications. In Practical Aspects of Declarative Languages, 11th International Symposium, PADL 2009,Proceedings, Vol. 5418 of Lecture Notes in Computer Science, pp. 239253. Springer.
Turner, H. (2002). Polynomial-length planning spans the polynomial hierarchy. In JELIA
02: Proc. of the European Conference on Logics in AI, pp. 111124. Springer-Verlag.

675

fiJournal of Artificial Intelligence Research 35 (2009) 449-484

Submitted 1/09; published 7/09

Efficient Markov Network Structure Discovery
Using Independence Tests
Facundo Bromberg

fbromberg@frm.utn.edu.ar

Departamento de Sistemas de Informacion,
Universidad Tecnologica Nacional,
Mendoza, Argentina

Dimitris Margaritis
Vasant Honavar

dmarg@cs.iastate.edu
honavar@cs.iastate.edu

Dept. of Computer Science,
Iowa State University,
Ames, IA 50011

Abstract
We present two algorithms for learning the structure of a Markov network from data:
GSMN and GSIMN. Both algorithms use statistical independence tests to infer the structure by successively constraining the set of structures consistent with the results of these
tests. Until very recently, algorithms for structure learning were based on maximum likelihood estimation, which has been proved to be NP-hard for Markov networks due to the
difficulty of estimating the parameters of the network, needed for the computation of the
data likelihood. The independence-based approach does not require the computation of
the likelihood, and thus both GSMN and GSIMN can compute the structure efficiently
(as shown in our experiments). GSMN is an adaptation of the Grow-Shrink algorithm
of Margaritis and Thrun for learning the structure of Bayesian networks. GSIMN extends GSMN by additionally exploiting Pearls well-known properties of the conditional
independence relation to infer novel independences from known ones, thus avoiding the performance of statistical tests to estimate them. To accomplish this efficiently GSIMN uses
the Triangle theorem, also introduced in this work, which is a simplified version of the set
of Markov axioms. Experimental comparisons on artificial and real-world data sets show
GSIMN can yield significant savings with respect to GSMN , while generating a Markov
network with comparable or in some cases improved quality. We also compare GSIMN to
a forward-chaining implementation, called GSIMN-FCH, that produces all possible conditional independences resulting from repeatedly applying Pearls theorems on the known
conditional independence tests. The results of this comparison show that GSIMN, by the
sole use of the Triangle theorem, is nearly optimal in terms of the set of independences
tests that it infers.

1. Introduction
Graphical models (Bayesian and Markov networks) are an important subclass of statistical models that possess advantages that include clear semantics and a sound and widely
accepted theoretical foundation (probability theory). Graphical models can be used to
represent efficiently the joint probability distribution of a domain. They have been used
in numerous application domains, ranging from discovering gene expression pathways in
bioinformatics (Friedman, Linial, Nachman, & Peer, 2000) to computer vision (e.g. Geman

c
2009
AI Access Foundation. All rights reserved.

fiBromberg, Margaritis, & Honavar

Figure 1: Example Markov network. The nodes represent variables in the domain V =
{0, 1, 2, 3, 4, 5, 6, 7}.

& Geman, 1984, Besag, York, & Mollie, 1991, Isard, 2003, Anguelov, Taskar, Chatalbashev,
Koller, Gupta, Heitz, & Ng, 2005). One problem that naturally arises is the construction of
such models from data (Heckerman, Geiger, & Chickering, 1995, Buntine, 1994). A solution
to this problem, besides being theoretically interesting in itself, also holds the potential of
advancing the state-of-the-art in application domains where such models are used.
In this paper we focus on the task of learning Markov networks (MNs) from data in
domains in which all variables are either discrete or continuous and distributed according
to a multidimensional Gaussian distribution. MNs are graphical models that consist of two
parts: an undirected graph (the model structure), and a set of parameters. An example
Markov network is shown in Figure 1. Learning such models from data consists of two interdependent tasks: learning the structure of the network, and, given the learned structure,
learning the parameters. In this work we focus on the problem of learning the structure of
the MN of a domain from data.
We present two algorithms for MN structure learning from data: GSMN (Grow-Shrink
Markov Network learning algorithm) and GSIMN (Grow-Shrink Inference-based Markov
Network learning algorithm). The GSMN algorithm is an adaptation to Markov networks
of the GS algorithm by Margaritis and Thrun (2000), originally developed for learning the
structure of Bayesian networks. GSMN works by first learning the local neighborhood
of each variable in the domain (also called the Markov blanket of the variable), and then
using this information in subsequent steps to improve efficiency. Although interesting and
useful in itself, we use GSMN as a point of reference of the performance with regard to
time complexity and accuracy achieved by GSIMN, which is the main result of this work.
The GSIMN algorithm extends GSMN by using Pearls theorems on the properties of the
conditional independence relation (Pearl, 1988) to infer additional independences from a
set of independences resulting from statistical tests and previous inferences, thus avoiding
the execution of these tests on data. This allows savings in execution time and, when data
are distributed, communication bandwidth.
The rest of the paper is organized as follows: In the next section we present previous
research related to the problem. Section 3 introduces notation, definitions and presents
some intuition behind the two algorithms. Section 4 contains the main algorithms, GSMN
and GSIMN, as well as concepts and practical details related to their operation. We evaluate
GSMN and GSIMN and present our results in Section 5, followed by a summary of our
450

fiEfficient Markov Network Structure Discovery Using Independence Tests

work and possible directions of future research in Section 6. Appendices A and B contain
proofs of correctness of GSMN and GSIMN.

2. Related Work
Markov networks have been used in the physics and computer vision communities (Geman &
Geman, 1984, Besag et al., 1991, Anguelov et al., 2005) where they have been historically
called Markov random fields. Recently there has been interest in their use for spatial
data mining, which has applications in geography, transportation, agriculture, climatology,
ecology and others (Shekhar, Zhang, Huang, & Vatsavai, 2004).
One broad and popular class of algorithms for learning the structure of graphical models
is the score-based approach, exemplified for Markov networks by Della Pietra, Della Pietra,
and Lafferty (1997), and McCallum (2003). Score-based approaches conduct a search in the
space of legal structures in an attempt to discover a model structure of maximum score.
Due to the intractable size of the search space i.e., the space of all legal graphs, which is
super-exponential in size, score-based algorithms must usually resort to heuristic search.
At each step of the structure search, a probabilistic inference step is necessary to evaluate
the score (e.g., maximum likelihood, minimum description length, Lam & Bacchus, 1994, or
pseudo-likelihood, Besag, 1974). For Bayesian networks this inference step is tractable and
therefore several practical score-based algorithms for structure learning have been developed
(Lam & Bacchus, 1994, Heckerman, 1995, Acid & de Campos, 2003). For Markov networks
however, probabilistic inference requires the calculation of a normalizing constant (also
known as partition function), a problem known to be NP-hard (Jerrum & Sinclair, 1993,
Barahona, 1982). A number of approaches have considered a restricted class of graphical
models (e.g. Chow & Liu, 1968, Rebane & Pearl, 1989, Srebro & Karger, 2001). However,
Srebro and Karger (2001) prove that finding the maximum likelihood network is NP-hard
for Markov networks of tree-width greater than 1.
Some work in the area of structure learning of undirected graphical models has concentrated on the learning of decomposable (also called chordal) MNs (Srebro & Karger,
2001). An example of learning non-decomposable MNs is presented in the work of Hofmann and Tresp (1998), which is an approach for learning structure in continuous domains
with non-linear relationships among the domain attributes. Their algorithm removes edges
greedily based on a leave-one-out cross validation log-likelihood score. A non-score based
approach is in the work of Abbeel, Koller, and Ng (2006), which introduces a new class of efficient algorithms for structure and parameter learning of factor graphs, a class of graphical
models that subsumes Markov and Bayesian networks. Their approach is based on a new
parameterization of the Gibbs distribution in which the potential functions are forced to be
probability distributions, and is supported by a generalization of the Hammersley-Clifford
theorem for factor graphs. It is a promising and theoretically sound approach that may
lead in the future to practical and efficient algorithms for undirected structure learning.
In this work we present algorithms that belong to the independence-based or constraintbased approach (Spirtes, Glymour, & Scheines, 2000). Independence-based algorithms exploit the fact that a graphical model implies that a set of independences exist in the distribution of the domain, and therefore in the data set provided as input to the algorithm (under
assumptions, see next section); they work by conducting a set of conditional independence
451

fiBromberg, Margaritis, & Honavar

tests on data, successively restricting the number of possible structures consistent with the
results of those tests to a singleton (if possible), and inferring that structure as the only
possible one. A desirable characteristic of independence-based approaches is the fact that
they do not require the use of probabilistic inference during the discovery of the structure.
Also, such algorithms are amenable to proofs of correctness (under assumptions).
For Bayesian networks, the independence-based approach has been mainly exemplified
by the SGS (Spirtes et al., 2000), PC (Spirtes et al., 2000), and algorithms that learn the
Markov blanket as a step in learning the Bayesian network structure such as Grow-Shrink
(GS) algorithm (Margaritis & Thrun, 2000), IAMB and its variants (Tsamardinos, Aliferis,
& Statnikov, 2003a), HITON-PC and HITON-MB (Aliferis, Tsamardinos, & Statnikov,
2003), MMPC and MMMB (Tsamardinos, Aliferis, & Statnikov, 2003b), and max-min hill
climbing (MMHC) (Tsamardinos, Brown, & Aliferis, 2006), all of which are widely used in
the field. Algorithms for restricted classes such as trees (Chow & Liu, 1968) and polytrees
(Rebane & Pearl, 1989) also exist.
For learning Markov networks previous work has mainly focused on learning Gaussian
graphical models, where the assumption of a continuous multivariate Gaussian distribution
is made; this results in linear dependences among the variables with Gaussian noise (Whittaker, 1990, Edwards, 2000). More recent approaches are included in the works of Dobra,
Hans, Jones, Nevins, Yao, and West (2004), (Castelo & Roverato, 2006), Pena (2008), and
Schafer and Strimmer (2005), that focus on applications of Gaussian graphical models in
Bioinformatics. While we do not make the assumption of continuous Gaussian variables
in this paper, all algorithms we present are applicable to such domains with the use of
an appropriate conditional independence test (such as partial correlation). The GSMN
and GSIMN algorithms presented apply to any case where an arbitrary faithful distribution can be assumed and a probabilistic conditional independence test for that distribution
is available. The algorithms were first introduced by Bromberg, Margaritis, and Honavar
(2006); the contributions of the present paper include extending these results by conducting
an extensive evaluation of their experimental and theoretical properties. More specifically,
the contributions include an extensive and systematic experimental evaluation of the proposed algorithms on (a) data sets sampled from artificially generated networks of varying
complexity and strength of dependences, as well as (b) data sets sampled from networks
representing real-world domains, and (c) formal proofs of correctness that guarantee that
the proposed algorithms will compute the correct Markov network structure of the domain,
under the stated assumptions.

3. Notation and Preliminaries
We denote random variables with capitals (e.g., X, Y, Z) and sets of variables with bold
capitals (e.g., X, Y, Z). In particular, we denote by V = {0, . . . , n  1} the set of all n
variables in the domain. We name the variables by their indices in V; for instance, we
refer to the third variable in V simply by 3. We denote the data set as D and its size
(number of data points) by |D| or N . We use the notation (XY | Z) to denote the
proposition that X is independent of Y conditioned on Z, for disjoint sets of variables X,
Y, and Z. (X 6Y | Z) denotes conditional dependence. We use (XY | Z) as shorthand
for ({X}{Y } | Z) to improve readability.
452

fiEfficient Markov Network Structure Discovery Using Independence Tests

A Markov network is an undirected graphical model that represents the joint probability
distribution over V. Each node in the graph represents one of the random variables in
the domain, and absences of edges encode conditional independences among them. We
assume the underlying probability distribution to be graph-isomorph (Pearl, 1988) or faithful
(Spirtes et al., 2000), which means that it has a faithful undirected graph. A graph G is
said to be faithful to some distribution if its graph connectivity represents exactly those
dependencies and independences existent in the distribution. In detail, this means that that
for all disjoint sets X, Y, Z  V, X is independent of Y given Z if and only if the set of
vertices Z separates the set of vertices X from the set of vertices Y in the graph G (this is
sometimes called the global Markov property, Lauritzen, 1996). In other words, this means
that, after removing all vertices in Z from G (including all edges incident to each of them),
there exists no (undirected) path in the remaining graph between any variable in X to some
variable in Y. For example, in Figure 1, the set of variables {0, 5} separates set {4, 6} from
set {2}. More generally, it has been shown (Pearl, 1988; Theorem 2, page 94 and definition
of graph isomorphism, page 93) that a necessary and sufficient condition for a distribution
to be graph-isomorph is for its set of independence relations to satisfy the following axioms
for all disjoint sets of variables X, Y, Z, W and individual variable :

(Symmetry)
(Decomposition)
(Intersection)
(Strong Union)
(Transitivity)

(XY | Z)
(XY  W | Z)
(XY | Z  W)
 (XW | Z  Y)
(XY | Z)
(XY | Z)




(YX | Z)
(XY | Z)  (XW | Z)

=
=
=

(XY  W | Z)
(XY | Z  W)
(X | Z)  (Y | Z)

(1)

For the operation of the algorithms we also assume the existence of an oracle that can
answer statistical independence queries. These are standard assumptions that are needed
for formally proving the correctness of independence-based structure learning algorithms
(Spirtes et al., 2000).
3.1 Independence-Based Approach to Structure Learning
GSMN and GSIMN are independence-based algorithms for learning the structure of the
Markov network of a domain. This approach works by evaluating a number of statistical
independence statements, reducing the set of structures consistent with the results of these
tests to a singleton (if possible), and inferring that structure as the only possible one.
As mentioned above, in theory we assume the existence of an independence-query oracle
that can provide information about conditional independences among the domain variables.
This can be viewed as an instance of a statistical query oracle (Kearns & Vazirani, 1994).
In practice such an oracle does not exist; however, it can be implemented approximately
by a statistical test evaluated on the data set D. For example, for discrete data this
can be Pearsons conditional independence chi-square (2 ) test (Agresti, 2002), a mutual
information test etc. For continuous Gaussian data a statistical test that can be used to
measure conditional independence is partial correlation (Spirtes et al., 2000). To determine
conditional independence between two variables X and Y given a set Z from data, the
453

fiBromberg, Margaritis, & Honavar

statistical test returns a p-value. The p-value of a test equals the probability of obtaining a
value for the test statistic that is at least as extreme as the one that was actually observed
given that the null hypothesis is true, which corresponds to conditional independence in
our case. Assuming that the p-value of a test is p(X, Y | Z), the statistical test concludes
dependence if and only if p(X, Y | Z) is less than or equal to a threshold  i.e.,
(X 6Y | Z)  p(X, Y | Z)  .
The quantity 1   is sometimes referred to as the tests confidence threshold. We use
the standard value of  = 0.05 in all our experiments, which corresponds to a confidence
threshold of 95%.
In a faithful domain, it can be shown (Pearl & Paz, 1985) that an edge exists between
two variables X 6= Y  V in the Markov network of that domain if an only if they are
dependent conditioned on all remaining variables in the domain, i.e.,
(X, Y ) is an edge iff (X 6Y | V  {X, Y }).
Thus, to learn the structure, theoretically it suffices to perform only n(n  1)/2 tests i.e.,
one test (X, Y | V  {X, Y }) for each pair of variables X, Y  V, X 6= Y . Unfortunately,
in non-trivial domains this usually involves a test that conditions on a large number of
variables. Large conditioning sets produce sparse contingency tables (count histograms)
which result in unreliable tests. This is because the number of possible configurations of
the variables grows exponentially with the size of the conditioning setfor example, there
are 2n cells in a test involving n binary variables, and to fill such a table with one data point
per cell we would need a data set of at least exponential size i.e., N  2n . Exacerbating
this problem, more than one data point per cell is typically necessary for a reliable test: As
recommended by Cochran (1954), if more than 20% of the cells of the contingency table
have less than 5 data points the test is deemed unreliable. Therefore both GSMN and
GSIMN algorithms (presented below) attempt to minimize the conditioning set size; they
do that by choosing an order of examining the variables such that irrelevant variables are
examined last.

4. Algorithms and Related Concepts
In this section we present our main algorithms, GSMN and GSIMN, and supporting concepts required for their description. For the purpose of aiding the understanding of the
reader, before discussing these we first describe the abstract GSMN algorithm in the next
section. This helps in showing the intuition behind the algorithms and laying the foundation
for them.
4.1 The Abstract GSMN Algorithm
For the sake of clarity of exposition, before discussing our first algorithm GSMN , we
describe the intuition behind it by describing its general structure using the abstract GSMN
algorithm which deliberately leaves a number of details unspecified; these are filled-in in the
concrete GSMN algorithm, presented in the next section. Note that the choices for these

454

fiEfficient Markov Network Structure Discovery Using Independence Tests

Algorithm 1 GSMN algorithm outline: G = GSMN (V, D).
1: Initialize G to the empty graph.
2: for all variables X in the domain V do
3:
/* Learn the Markov Blanket BX of X using the GS algorithm. */
4:
BX  GS (X, V, D)
5:
Add an undirected edge in G between X and each variable Y  BX .
6: return G

Algorithm 2 GS algorithm. Returns the Markov Blanket BX of variable X  V: BX =
GS (X, V, D).
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:

BX  
/* Grow phase. */
for each variable Y in V  {X} do
if (X 6Y | BX ) (estimated using data D) then
BX  BX  {Y }
goto 3 /* Restart grow loop. */
/* Shrink phase. */
for each variable Y in BX do
if (XY | BX  {Y }) (estimated using data D) then
BX  BX  {Y }
goto 8 /* Restart shrink loop. */
return BX

details are a source of optimizations that can reduce the algorithms computational cost.
We make these explicit when we discuss the concrete GSMN and GSIMN algorithms.
The abstract GSMN algorithm is shown in Algorithm 1. Given as input a data set D
and a set of variables V, GSMN computes the set of nodes (variables) BX that are adjacent
to each variable X  V; these completely determine the structure of the domain MN. The
algorithm consists of a main loop in which it learns the Markov blanket BX of each node
(variable) X in the domain using the GS algorithm. It then constructs the Markov network
structure by connecting X with each variable in BX .
The GS algorithm was first proposed by Margaritis and Thrun (2000) and is shown in
Algorithm 2. It consists of two phases, a grow phase and a shrink phase. The grow phase
of X proceeds by attempting to add each variable Y to the current set of hypothesized
neighbors of X, contained in BX , which is initially empty. BX grows by some variable Y
during each iteration of the grow loop of X if and only if Y is found dependent with X
given the current set of hypothesized neighbors BX . Due to the (unspecified) ordering that
the variables are examined (this is explicitly specified in the concrete GSMN algorithm,
presented in the next section), at the end of the grow phase some of the variables in BX
might not be true neighbors of X in the underlying MNthese are called false positives.
This justifies the shrink phase of the algorithm, which removes each false positive Y in BX
by testing for independence with X conditioned on BX  {Y }. If Y is found independent of
X during the shrink phase, it cannot be a true neighbor (i.e., there cannot be an edge X Y ),
and GSMN removes it from BX . Assuming faithfulness and correctness of the independence
query results, by the end of the shrink phase BX contains exactly the neighbors of X in
the underlying Markov network.
455

fiBromberg, Margaritis, & Honavar

In the next section we present a concrete implementation of GSMN, called GSMN .
This augments GSMN by specifying a concrete ordering that the variables X are examined
in the main loop of GSMN (lines 25 in Algorithm 1), as well as a concrete order that the
variables Y are examined in the grow and shrink phases of the GS algorithm (lines 36 and
811 in Algorithm 2, respectively).
4.2 The Concrete GSMN Algorithm
In this section we discuss our first algorithm, GSMN (Grow-Shrink Markov Network
learning algorithm), for learning the structure of the Markov network of a domain. Note
that the reason for introducing GSMN in addition to our main contribution, the GSIMN
algorithm (presented later in Section 4.5), is for comparison reasons. In particular, GSIMN
and GSMN have identical structure, following the same order of examination of variables,
with their only difference being the use of inference by GSIMN (see details in subsequent
sections). Introducing GSMN therefore makes it possible to measure precisely (through
our experimental results in Section 5) the benefits of the use of inference on performance.
The GSMN algorithm is shown in Algorithm 3. Its structure is similar to the abstract
GSMN algorithm. One notable difference is that the order that variables are examined is
now specified; this is done in the initialization phase where the so-called examination order
 and grow order X of each variable X  V is determined.  and all X are priority
queues and each is initially a permutation of V (X is a permutation of V  {X}) such
that the position of a variable in the queue denotes its priority e.g.,  = [2, 0, 1] means that
variable 2 has the highest priority (will be examined first), followed by 0 and finally by 1.
Similarly, the position of a variable in X determines the order it will be examined during
the grow phase of X.
During the initialization phase the algorithm computes the strength of unconditional
dependence between each pair of variable X and Y , as given by the unconditional p-value
p(X, Y | ) of an independence test between each pair of variables X 6= Y , denoted by
pXY in the algorithm. (In practice the logarithm of the p-values is computed, which allows
greater precision in domains where some dependencies may be very strong or very weak.)
In particular, the algorithm gives higher priority to (examines earlier) those variables with
a lower average log p-value (line 5), indicating stronger dependence. This average is defined
as:
X
1
avg log(pXY ) =
log(pXY ).
|V|  1
Y
Y 6=X

For the grow order X of variable X, the algorithm gives higher priority to those variables
Y whose p-value (or equivalently the log of the p-value) with variable X is small (line 8).
This ordering is due to the intuition behind the folk-theorem (as Koller & Sahami, 1996,
puts it) that states that probabilistic influence or association between attributes tends to
attenuate over distance in a graphical model. This suggests that a pair of variables X and Y
with high unconditional p-value are less likely to be directly linked. Note that this ordering
is a heuristic and is not guaranteed to hold in general. For example, it may not hold
if the underlying domain is a Bayesian network e.g., two spouses may be independent
unconditionally but dependent conditional on a common child. Note however that this
example does not apply to faithful domains i.e., graph-isomorph to a Markov network. Also
456

fiEfficient Markov Network Structure Discovery Using Independence Tests

Algorithm 3 GSMN , a concrete implementation of GSMN: G = GSMN  (V, D).
1:
2:
3:
4:
5:

Initialize G to the empty graph.
/* Initialization. */
for all X, Y  V, X 6= Y do
pXY  p(X, Y | )


Initialize  such that i, i  {0, . . . , n  1}, i < i  avg log(pi j ) < avg log(pi j ) .
j

j

6: for all X  V do
7:
BX  


8:
Initialize X such that j, j   {0, . . . , n  1}, j < j   pXX < pXX .
j

j

9:
Remove X from X .
10: /* Main loop. */
11: while  is not empty do
12:
X  dequeue()
13:
/* Propagation phase. */
14:
T  {Y : Y was examined and X  BY }
15:
F  {Y : Y was examined and X 
/ BY }
16:
for all Y  T, move Y to the end of X .
17:
for all Y  F, move Y to the end of X .
18:
/* Grow phase. */
19:
S
20:
while X not empty do
21:
Y  dequeue(X )
22:
if pXY   then
23:
if IGSMN (X, Y, S, F, T) then
24:
S  S  {Y }
25:
/* Change grow order of Y . */
26:
Move X to the beginning of Y .
27:
for W = S|S|2 to S0 do
28:
Move W to the beginning of Y .
29:
/* Change examination order. */
30:
for W = S|S|1 to S0 do
31:
if W   then
32:
Move W to the beginning of .
33:
break to line 34
34:
/* Shrink phase. */
35:
for Y = S|S|1 to S0 do
36:
if IGSMN (X, Y, S  {Y } , F, T) then
37:
S  S  {Y }
38:
BX  S
39:
Add an undirected edge in G between X and each variable Y  BX .
40: return G

note that the correctness of all algorithms we present does not depend on it holding i.e.,
as we prove in Appendices A and B, both GSMN and GSIMN are guaranteed to return
the correct structure under the assumptions stated in Section 3 above. Also note that the
computational cost for the calculation of pXY is low due to the empty conditioning set.
The remaining of the GSMN algorithm contains the main loop (lines 1039) in which
each variable in V is examined according to the examination order , determined during
457

fiBromberg, Margaritis, & Honavar

Algorithm 4 IGSMN (X, Y, S, F, T): Calculate independence test (X, Y | S) by propagation, if possible, otherwise run a statistical test on data.
1:
2:
3:
4:
5:
6:
7:
8:
9:

/* Attempt to infer dependence by propagation. */
if Y  T then
return false
/* Attempt to infer independence by propagation. */
if Y  F then
return true
/* Else do statistical test on data. */
t  1(p(X,Y |Z)>) /* t = true iff p-value of statistical test (X, Y | S) > . */
return t

the initialization phase. The main loop includes three phases: the propagation phase (lines
1317), the grow phase (lines 1833), and the shrink phase (lines 3437). The propagation
phase is an optimization in which all variables Y for which BY has already been computed
(i.e., all variables Y already examined) are collected in two sets F and T. Set F (T) contains
all variables Y such that X 
/ BY (X  BY ). Both sets are passed to the independence
procedure IGSMN , shown in Algorithm 4, for the purpose of avoiding the execution of any
tests between X and Y by the algorithm. This is justified by the fact that, in undirected
graphs, Y is in the Markov blanket of X if and only if X is in the Markov blanket of Y .
Variables Y already found not to contain X in their blanket BY (set F) cannot be members
of BX because there exists some set of variables that has rendered them conditionally
independent of X in a previous step, and independence can therefore be inferred easily.
Note that in the experiments section of the paper (Section 5) we evaluate GSMN with
and without the propagation phase, in order to measure the effect that this propagation
optimization has on performance. Turning off propagation is accomplished simply by setting
sets T and F (as computed in lines 14 and 15, respectively) to the empty set.
Another difference of GSMN from the abstract GSMN algorithm is in the use of condition pXY   (line 22). This is an additional optimization that avoids an independence test
in the case that X and Y were found (unconditionally) independent during the initialization
phase, since in that case this would imply X and Y are independent given any conditioning
set by the axiom of Strong Union.
A crucial difference between GSMN and the abstract GSMN algorithm is that GSMN
changes the examination order  and the grow order Y of every variable Y  X . (Since
X 
/ X , this excludes the grow order of X itself.) These changes in ordering proceed as
follows: After the end of the grow phase of variable X, the new examination order  (set
in lines 3033) dictates that the next variable W to be examined after X is the last to be
added to S during the growing phase that has not yet been examined (i.e., W is still in ).
The grow order Y of all variables Y found dependent with X is also changed; this is done
to maximize the number of optimizations by the GSIMN algorithm (our main contribution
in this paper) which shares the algorithm structure of GSMN . The changes in grow order
are therefore explained in detail in Section 4.5 when GSIMN is presented.
A final difference between GSMN and the abstract GSMN algorithm is the restart
actions of the grow and shrink phases of GSMN whenever the current Markov blanket is
modified (lines 6 and 11 of Algorithm 2), which are not present in GSMN . The restarting

458

fiEfficient Markov Network Structure Discovery Using Independence Tests

Figure 2: Illustration of the operation of GSMN using an independence graph. The figure
shows the growing phase of variable 5. Variables are examined according to its
grow order 5 = [3, 4, 1, 6, 2, 7, 0].

of the loops was necessary in the GS algorithm due to its original usage in learning the
structure of Bayesian networks. In that task, it was possible for a true member Y of the
blanket of X to be found initially independent during the grow loop when conditioning on
some set S but to be found dependent later when conditioned on a superset S  S. This
could happen if Y was an unshielded spouse of X i.e., if Y had one or more common
children with X but there existed no direct link between Y and X in the underlying Bayesian
network. However, this behavior is impossible in a domain that has a distribution faithful
to a Markov network (one of our assumptions): any independence between X and Y given
S must hold for any superset S of S by the axiom of Strong Union (see Eqs. (1)). The
restart of the grow and shrink loops is therefore omitted from GSMN in order to save
unnecessary tests. Note that, even though it is possible that this behavior is impossible in
faithful domains, it is possible in unfaithful ones, so we also experimentally evaluated our
algorithms in real-world domains in which the assumption of Markov faithfulness may not
necessarily hold (Section 5).
A proof of correctness of GSMN is presented in Appendix A.
4.3 Independence Graphs
We can demonstrate the operation of GSMN graphically by the concept of the independence
graph, which we now introduce. We define an independence graph to be an undirected
graph in which conditional independences and dependencies between single variables are
represented by one or more annotated edges between them. A solid (dotted) edge between
variables X and Y annotated by Z represents the fact that X and Y have been found
dependent (independent) given Z. If the conditioning set Z is enclosed in parentheses then
this edge represents an independence or dependence that was inferred from Eqs. (1) (as
opposed to computed from statistical tests). Shown graphically:
459

fiBromberg, Margaritis, & Honavar

X
X
X
X

Z
Y

(X 6Y | Z)

Y

(XY | Z)

Y

(X 6Y | Z) (inferred)

Y

(XY | Z) (inferred)

Z
(Z)
(Z)

For instance, in Figure 2, the dotted edge between 5 and 1 annotated with 3, 4 represents
the fact that (51 | {3, 4}). The absence of an edge between two variables indicates the
absence of information about the independence or dependence between these variables under
any conditioning set.
Example 1. Figure 2 illustrates the operation of GSMN using an independence graph in
the domain whose underlying Markov network is shown in Figure 1. The figure shows the
independence graph at the end of the grow phase of the variable 5, the first in the examination
order . (We do not discuss in this example the initialization phase of GSMN ; instead, we
assume that the examination () and grow () orders are as shown in the figure.) According
to vertex separation on the underlying network (Figure 1), variables 3, 4, 6, and 7 are found
dependent with 5 during the growing phase i.e.,
I(5, 3 | ),
I(5, 4 | {3}),
I(5, 6 | {3, 4}),
I(5, 7 | {3, 4, 6})
and are therefore connected to 5 in the independence graph by solid edges annotated by sets
, {3}, {3, 4} and {3, 4, 6} respectively. Variables 1, 2, and 0 are found independent i.e.,
I(5, 1 | {3, 4}),
I(5, 2 | {3, 4, 6}),
I(5, 0 | {3, 4, 6, 7})
and are thus connected to 5 by dotted edges annotated by {3, 4}, {3, 4, 6} and {3, 4, 6, 7}
respectively.
4.4 The Triangle Theorem
In this section we present and prove a theorem that is used in the subsequent GSIMN
algorithm. As will be seen, the main idea behind the GSIMN algorithm is to attempt to decrease the number of tests done by exploiting the properties of the conditional independence
relation in faithful domains i.e., Eqs. (1). These properties can be seen as inference rules
that can be used to derive new independences from ones that we know to be true. A careful
study of these axioms suggests that only two simple inference rules, stated in the Triangle
theorem below, are sufficient for inferring most of the useful independence information that
can be inferred by a systematic application of the inference rules. This is confirmed in our
experiments in Section 5.
460

fiEfficient Markov Network Structure Discovery Using Independence Tests

Figure 3: Independence graph depicting the Triangle theorem. Edges in the graph are
labeled by sets and represent conditional independences or dependencies. A solid
(dotted) edge between X and Y labeled by Z means that X and Y are dependent
(independent) given Z. A set label enclosed in parentheses means the edge was
inferred by the theorem.

Theorem 1 (Triangle theorem). Given Eqs. (1), for every variable X, Y , W and sets Z1
and Z2 such that {X, Y, W }  Z1 = {X, Y, W }  Z2 = ,
(X 6W | Z1 )  (W 6Y | Z2 )

=

(X 6Y | Z1  Z2 )

(XW | Z1 )  (W 6Y | Z1  Z2 )

=

(XY | Z1 ).

We call the first relation the D-triangle rule and the second the I-triangle rule.
Proof. We are using the Strong Union and Transitivity of Eqs. (1) as shown or in contrapositive form.
(Proof of D-triangle rule):
 From Strong Union and (X 6W | Z1 ) we get (X 6W | Z1  Z2 ).
 From Strong Union and (W 6Y | Z1 ) we get (W 6Y | Z1  Z2 ).
 From Transitivity, (X 6W | Z1 Z2 ), and (W 6Y | Z1 Z2 ), we get (X 6Y | Z1 Z2 ).
(Proof of I-triangle rule):
 From Strong Union and (W 6Y | Z1  Z2 ) we get (W 6Y | Z1 ).
 From Transitivity, (XW | Z1 ) and (W 6Y | Z1 ) we get (XY | Z1 ).

We can represent the Triangle theorem graphically using the independence graph construct of Section 4.2. Figure 3 depicts the two rules of the Triangle theorem using two
independence graphs.
The Triangle theorem can be used to infer additional conditional independences from
tests conducted during the operation of GSMN . An example of this is shown in Figure 4, which illustrates the application of the Triangle theorem to the example presented
in Figure 2. The independence information inferred from the Triangle theorem is shown by
curved edges (note that the conditioning set of each such edge is enclosed in parentheses).

461

fiBromberg, Margaritis, & Honavar

Figure 4: Illustration of the use of the Triangle theorem on the example of Figure 2. The set
of variables enclosed in parentheses correspond to tests inferred by the Triangle
theorem using the two adjacent edges as antecedents. For example, the result
(17 | {3, 4}), is inferred from the I-triangle rule, independence (51 | {3, 4})
and dependence (5 67 | {3, 4, 6}).

For example, independence edge (4, 7) can be inferred by the D-triangle rule from the adjacent edges (5, 4) and (5, 7), annotated by {3} and {3, 4, 6} respectively. The annotation
for this inferred edge is {3}, which is the intersection of the annotations {3} and {3, 4, 6}.
An example application of the I-triangle rule is edge (1, 7), which is inferred from edges
(5, 1) and (5, 7) with annotations {3, 4} and {3, 4, 6} respectively. The annotation for this
inferred edge is {3, 4}, which is the intersection of the annotations {3, 4, 6} and {3, 4}.
4.5 The GSIMN Algorithm
In the previous section we saw the possibility of using the two rules of the Triangle
theorem to infer the result of novel tests during the grow phase. The GSIMN algorithm
(Grow-Shrink Inference-based Markov Network learning algorithm), introduced in this section, uses the Triangle theorem in a similar fashion to extend GSMN by inferring the value
of a number of tests that GSMN executes, making their evaluation unnecessary. GSIMN
and GSMN work in exactly the same way (and thus the GSIMN algorithm shares exactly
the same algorithmic description i.e., both follow Algorithm 3), with all differences between
them concentrated in the independence procedure they use: instead of using independence
procedure IGSMN of GSMN , GSIMN uses procedure IGSIMN , shown in Algorithm 5. Procedure IGSIMN , in addition to attempting to propagate the blanket information obtained
from the examination of previous variables (as IGSMN does), also attempts to infer the
value of the independence test that is provided as its input by either the Strong Union
axiom (listed in Eqs. (1)) or the Triangle theorem. If this attempt is successful, IGSIMN
returns the value inferred (true or false), otherwise it defaults to a statistical test on the
data set (as IGSMN does). For the purpose of assisting in the inference process, GSIMN and
462

fiEfficient Markov Network Structure Discovery Using Independence Tests

Algorithm 5 IGSIMN (X, Y, S, F, T): Calculate independence test result by inference (including propagation), if possible. Record test result in the knowledge base.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:

/* Attempt to infer dependence by propagation. */
if Y  T then
return false
/* Attempt to infer independence by propagation. */
if Y  F then
return true
/* Attempt to infer dependence by Strong Union. */
if  (A, false)  KXY such that A  S then
return false
/* Attempt to infer dependence by the D-triangle rule. */
for all W  S do
if  (A, false)  KXW such that A  S   (B, false)  KW Y such that B  S then
Add (A  B, false) to KXY and KY X .
return false
/* Attempt to infer independence by Strong Union. */
if  (A, true)  KXY such that A  S then
return true
/* Attempt to infer independence by the I-triangle rule. */
for all W  S do
if  (A, true)  KXW s.t. A  S   (B, false)  KW Y s.t. B  A then
Add (A, true) to KXY and KY X .
return true
/* Else do statistical test on data. */
t  1(p(X,Y |Z)>) /* t = true iff p-value of statistical test (X, Y | S) > . */
Add (S, t) to KXY and KY X .
return t

IGSIMN maintain a knowledge base KXY for each pair of variables X and Y , containing the
outcomes of all tests evaluated so far between X and Y (either from data or inferred). Each
of these knowledge bases is empty at the beginning of the GSIMN algorithm (the initialization step is not shown in the algorithm since GSMN does not use it), and is maintained
within the test procedure IGSIMN .
We now explain IGSIMN (Algorithm 5) in detail. IGSIMN attempts to infer the independence value of its input triplet (X, Y | S) by applying a single step of backward
chaining using the Strong Union and Triangle rules i.e., it searches the knowledge base
K = {KXY : X, Y  V} for antecedents of instances of rules that have the input triplet
(X, Y | S) as consequent. The Strong Union rule is used in its direct from as shown in
Eqs. (1) and also in its contrapositive form. The direct form can be used to infer independences, and therefore we refer to it as the I-SU rule from here on. In its contrapositive form,
the I-SU rule becomes (X 6Y | S  W) = (X 6Y | S), referred to as the D-SU rule
since it can be used to infer dependencies. According to the D-Triangle and D-SU rules,
the dependence (X 6Y | S) can be inferred if the knowledge base K contains
1. a test (X 6Y | A) with A  S, or
2. tests (X 6W | A) and (W 6Y | B) for some variable W , with A  S and B  S,
463

fiBromberg, Margaritis, & Honavar

Figure 5: Illustration of the operation of GSIMN. The figure shows the grow phase of two
consecutively examined variables 5 and 7. The figure shows how the variable
examined second is not 3 but 7, according to the change in the examination order
 in lines 3033 of Algorithm 3. The set of variables enclosed in parentheses
correspond to tests inferred by the Triangle theorem using two adjacent edges as
antecedents. The results (7 63 | ), (7 64 | {3}), (7 66 | {3, 4}), and (7 65 |
{3, 4, 6}) in (b), shown highlighted, were not executed but inferred from the tests
done in (a).

respectively. According to the I-Triangle and I-SU rules, the independence (XY | S) can
be inferred if the knowledge base contains
3. a test (XY | A) with A  S, or
4. tests (XW | A) and (W 6Y | B) for some variable W , with A  S and B  A,
respectively.
The changes to the grow orders of some variables occur inside the grow phase of the
currently examined variable X (lines 2528 of GSIMN i.e., Algorithm 3 with IGSMN replaced by IGSIMN .). In particular, if, for some variable Y , the algorithm reaches line 24,
i.e., pXY   and IGSIMN (X, Y, S) = false, then X and all the variables that were found
dependent with X before Y (i.e., all variables currently in S) are promoted to the beginning
of the grow order Y . This is illustrated in Figure 5 for variable 7, which depicts the grow
phase of two consecutively examined variables 5 and 7. In this figure, the curved edges
show the tests that are inferred by IGSIMN during the grow phase of variable 5. The grow
order of 7 changes from 7 = [2, 6, 3, 0, 4, 1, 5] to 7 = [3, 4, 6, 5, 2, 0, 1] after the grow phase
of variable 5 is complete because the variables 5, 6, 4 and 3 were promoted (in that order)
to the beginning of the queue. The rationale for this is the observation that this increases
the number of tests inferred by GSIMN at the next step: The change in the examination
and grow orders described above was chosen so that the inferred tests while learning the
blanket of variable 7 match exactly those required by the algorithm in some future step. In
464

fiEfficient Markov Network Structure Discovery Using Independence Tests

particular, note that in the example the set of inferred dependencies between each variable
found dependent with 5 before 7 are exactly those required during initial part of the grow
phase of variable 7, shown highlighted in Figure 5(b) (the first four dependencies). These
independence tests were inferred (not conducted), resulting in computational savings. In
general, the last dependent variable of the grow phase of X has the maximum number of
dependences and independences inferred and this provides the rationale for its change in
grow order and its selection by the algorithm to be examined next.
It can be shown that under the same assumptions as GSMN , the structure returned
by GSIMN is the correct one i.e., each set BX computed by the GSIMN algorithm equals
exactly the neighbors of X. The proof of correctness of GSIMN is based on correctness of
GSMN and is presented in Appendix B.
4.6 GSIMN Technical Implementation Details
In this section we discuss a number of practical issues that subtly influence the accuracy and
efficiency of an implementation of GSIMN. One is the order of application of the I-SU, D-SU,
I-Triangle and D-Triangle rules within the function IGSIMN . Given an independence-query
oracle, the order of application should not matterassuming there are more than one rules
for inferring the value of an independence, all of them are guaranteed to produce the same
value due to the soundness of the axioms of Eqs. (1) (Pearl, 1988). In practice however,
the oracle is implemented by statistical tests conducted on data which can be incorrect, as
previously mentioned. Of particular importance is the observation that false independences
are more likely to occur than false dependencies. One example of this is the case where the
domain dependencies are weakin this case any pair of variables connected (dependent) in
the underlying true network structure may be incorrectly deemed independent if all paths
between them are long enough. On the other hand, false dependencies are much more rare
the confidence threshold of 1   = 0.95 of a statistical test tells us that the probability of a
false dependence by chance alone is only 5%. Assuming i.i.d. data for each test, the chance
of multiple false dependencies is even lower, decreasing exponentially fast. This practical
observation i.e., that dependencies are typically more reliable than independences, provide
the rationale for the way the IGSIMN algorithm works. In particular, IGSIMN prioritizes the
application of rules whose antecedents contain dependencies first i.e., the D-Triangle and
D-SU rules, followed by the I-Triangle and I-SU rules. In effect, this uses statistical results
that are typically known with greater confidence before ones that are usually less reliable.
The second practical issue concerns efficient inference. The GSIMN algorithm uses a onestep inference procedure (shown in Algorithm 5) that utilizes a knowledge base K = {KXY }
containing known independences and dependences for each pair of variables X and Y . To
implement this inference efficiently we utilize a data structure for K for the purpose of
storing and retrieving independence facts in constant time. It consists of two 2D arrays,
one for dependencies and another for independencies. Each array is of n  n size, where n
is the number of variables in the domain. Each cell in this array corresponds to a pair of
variables (X, Y ), and stores the known independences (dependences) between X and Y in
the form of a list of conditioning sets. For each conditioning set Z in the list, the knowledge
base KXY represents a known independence (XY | Z) (dependence (X 6Y | Z)). It is
important to note that the length of each list is at most 2, as there are no more than two

465

fiBromberg, Margaritis, & Honavar

tests done between any variable X and Y during the execution of GSIMN (done during
the growing and shrinking phases). Thus, it always takes a constant time to retrieve/store
an independence (dependence), and therefore all inferences using the knowledge base are
constant time as well. Also note that all uses of the Strong Union axion by the IGSIMN
algorithm are constant time as well, as they can be accomplished by testing the (at most
two) sets stored in KXY for subset or superset inclusion.

5. Experimental Results
We evaluated the GSMN and GSIMN algorithms on both artificial and real-world data sets.
Through the experimental results presented below we show that the simple application of
Pearls inference rules in GSIMN algorithm results in a significant reduction in the number
of tests performed when compared to GSMN without adversely affecting the quality of the
output network. In particular we report the following quantities:
 Weighted number of tests. The weighted number of tests is computed by the
summation of the weight of each test executed, where the weight of test (X, Y | Z) is
defined as 2+|Z|. This quantity reflects the time complexity of the algorithm (GSMN
or GSIMN) and can be used to assess the benefit in GSIMN of using inference instead
of executing statistical tests on data. This is the standard method of comparison of
independence-based algorithms and it is justified by the observation that the running
time of a statistical test on triplet (X, Y | Z) is proportional to the size N of the data
set and the number of variables involved in it i.e., O(N (|Z|+2)) (and is not exponential
in the number of variables involved as a nave implementation might assume). This
is because one can construct all non-zero entries in the contingency table used by the
test by examining each data point in the data set exactly once, in time proportional to
the number of variables involved in the test i.e., proportional to |{X, Y }Z| = 2+|Z|.
 Execution time. In order to assess the impact of inference in the running time
(in addition to the impact of statistical tests), we report the execution time of the
algorithm.
 Quality of the resulting network. We measure quality in two ways.
 Normalized Hamming distance. The Hamming distance between the output
network and the structure of the underlying model is another measure of the
quality of the output network, when the actual network that was used to generate
the data is known. The Hamming distance is defined as the number of reversed
edges between these two network structures, i.e., the number of times an actual
edge in the true network is missing in the returned network or an edge absent
from the true network exists in the algorithms output network. A value zero
means that the output network has the correct structure. To be able to compare
domains
of different dimensionalities (number of variables n) we normalize it by

n
2 , the total number of node pairs in the corresponding domain.
 Accuracy. For real-world data sets where the underlying network is unknown,
no Hamming distance calculation is possible. In this case it is impossible to know
the true value of any independence. We therefore approximate it by a statistical
test on the entire data set, and use a limited, randomly chosen subset (1/3 of
the data set) to learn the network. To measure accuracy we compare the result
466

fiEfficient Markov Network Structure Discovery Using Independence Tests

(true or false) of a number of conditional independence tests on the network
output (using vertex separation), to the same tests performed on the full data
set.
In all experiments involving data sets we used the 2 statistical test for estimation of
conditional independences. As mentioned above, rules of thumb exist that deem certain
tests as potentially unreliable depending on the counts of the contingency table involved;
for example, one such rule Cochran (1954) deems a test unreliable if more than 20% of the
cells of the contingency table have less than 5 data points the test. Due to the requirement
that an answer must be obtained by an independence algorithm conducting a test, we used
the outcomes of such tests as well in our experiments. The effect of these possibly unreliable
tests on the quality of the resulting network is measured by our accuracy measures, listed
above.
In the next section we present results for domains in which the underlying probabilistic
model is known. This is followed by real-world data experiments where no model structure
is available.
5.1 Known-Model Experiments
In the first set of experiments the underlying model, called the true model or true network, is
a known Markov network. The purpose of this set of experiments is to conduct a controlled
evaluation of the quality of the output network through a systematic study of the algorithms
behavior under varying conditions of domain size (number of variables) and amount of
dependencies (average node degree in the network).
Each true network that contains n variables was generated randomly as follows: the
network was initialized with n nodes and no edges. A user-specified parameter of the
network structure is the average node degree  that equals the average number of neighbors
per node. Given  , for every node its set of neighbors was determined randomly and
uniformly by selecting the first  n2 pairs in a random permutation of all possible pairs. The
factor 1/2 is necessary because each edge contributes to the degree of two nodes.
We conducted two types of experiments using known network structure: Exact learning
experiments and sample-based experiments.
5.1.1 Exact Learning Experiments
In this set of known-model experiments, we assume that the result of all statistical queries
asked by the GSMN and GSIMN algorithms were available, which assumes the existence
of an oracle that can answer independence queries. When the underlying model is known,
this oracle can be implemented through vertex separation. The benefits of querying the
true network for independence are two: First, it ensures faithfulness and correctness of
the independence query results, which allows the evaluation of the algorithms under their
assumptions for correctness. Second, these tests can be performed much faster than actual
statistical tests on data. This allowed us to evaluate our algorithms in large networkswe
were able to conduct experiments of domains containing up to 100 variables.
We first report the weighted number of tests executed by GSMN with and without
propagation and GSIMN. Our results are summarized in Figure 6, which shows the ratio
between the weighted number of tests of GSIMN and the two versions of GSMN . One
467

fiWC(GSIMN) / WC(GSMN* with propagation)

Ratio of weighted cost of GSIMN vs. GSMN* without propagation
1
0.9
0.8
0.7
0.6
=1
=2
=4
=8

0.5
0.4
0.3
0.2
0.1
0
0

10

20

30
40
50
60
70
80
Domain size (number of variables)

90

100

WC(GSIMN) / WC(GSMN* without propagation)

Bromberg, Margaritis, & Honavar

Ratio of weighted cost of GSIMN vs. GSMN* with propagation
1
0.9
0.8
0.7
0.6
0.5
0.4
=1
=2
=4
=8

0.3
0.2
0.1
0
0

10

20

30
40
50
60
70
80
Domain size (number of variables)

90

100

Figure 6: Ratio of the weighted number of tests of GSIMN over GSMN without propagation (left plot) and with propagation (right plot) for network sizes (number of
nodes) up to n = 100 of average degree  = 1, 2, 4, and 8.
Algorithm 6 IFCH (X, Y, S, F, T). Forward-chaining implementation of independence test
IGSIMN (X, Y, S, F, T).
1:
2:
3:
4:
5:
6:
7:

/* Query knowledge base. */
if  (S, t)  KXY then
return t
t  result of test (X, Y | S) /* t = true iff test (X, Y | S) returns independence. */
Add (S, t) to KXY and KY X .
Run forward-chaining inference algorithm on K, update K.
return t

hundred true networks were generated randomly for each pair (n,  ), and the figure shows
the mean value. We can see that the limiting reduction (as n grows large) in weighted
number of tests depends primarily on the average degree parameter  . The reduction of
GSIMN for large n and dense networks ( = 8) is approximately 40% compared to GSMN
with propagation and 75% compared to GSMN without the propagation optimization,
demonstrating the benefit of GSIMN vs. GSMN in terms of number of tests executed.
One reasonable question about the performance of GSIMN is to what extent its inference
procedure is complete i.e., from all those tests that GSIMN needs during its operation, how
does the number of tests that it infers (by applying a single step of backward chaining on
the Strong Union axiom and the Triangle theorem, rather than executing a statistical test
on data) compare to the number of tests that can be inferred (for example using a complete
automated theorem prover on Eqs. (1))? To measure this, we compared the number of tests
done by GSIMN with the number done by an alternative algorithm, which we call GSIMNFCH (GSIMN with Forward Chaining). GSIMN-FCH differs from GSIMN in function
IFCH , shown in Algorithm 6, which replaces function IGSIMN of GSIMN. IFCH exhaustively
produces all independence statements that can be inferred through the properties of Eqs. (1)
using a forward-chaining procedure. This process iteratively builds a knowledge base K
containing the truth value of conditional independence predicates. Whenever the outcome
of a test is required, K is queried (line 2 of IFCH in Algorithm 6). If the value of the test is
468

fiEfficient Markov Network Structure Discovery Using Independence Tests

Ratio of Number of tests GSIMN-FCH and GSIMN

=1
=2
=4
=8

1.4
1.2

Ratio

1
0.8
0.6
0.4
0.2
0

2

3

4

5

6

7

8

9

10 11 12

Number of variables (n)

Figure 7: Ratio of number of tests of GSIMN-FCH over GSIMN for network sizes (number
of variables) n = 2 to n = 13 and average degrees  = 1, 2, 4, and 8.

found in K, it is returned (line 3). If not, GSIMN-FCH performs the test and uses the result
in a standard forward-chaining automatic theorem prover subroutine (line 6) to produce all
independence statements that can be inferred by the test result and K, adding these new
facts to K.
A comparison of the number of tests executed by GSIMN vs. GSIMN-FCH is presented
in Figure 7, which shows the ratio of the number of tests of GSIMN over GSIMN-FCH.
The figure shows the mean value over four runs, each corresponding to a network generated
randomly for each pair (n,  ), for  = 1, 2, 4 and 8 and n up to 12. Unfortunately, after two
days of execution GSIMN-FCH was unable to complete execution on domains containing
13 variables or more. We therefore present results for domain sizes up to 12 only. The
figure shows that for n  9, and every  the ratio is exactly 1 i.e., all tests inferable were
produced by the use of the Triangle theorem in GSIMN. For smaller domains, the ratio is
above 0.95 with the exception of a single case, (n = 5,  = 1).
5.1.2 Sample-based Experiments
In this set of experiments we evaluate GSMN (with and without propagation) and GSIMN
on data sampled from the true model. This allows a more realistic assessment of the
performance of our algorithms. The data were sampled from the true (known) Markov
network using Gibbs sampling.
In the exact learning experiments of the previous section only the structure of the true
network was required, generated randomly in the fashion described above. To sample data
from a known structure however, one also needs to specify the network parameters. For each
random network, the parameters determine the strength of dependencies among connected
variables in the graph. Following Agresti (2002), we used the log-odds ratio as a measure of
the strength of the probabilistic influence between two binary variables X and Y , defined
as
Pr(X = 0, Y = 0) Pr(X = 1, Y = 1)
XY = log
.
Pr(X = 0, Y = 1) Pr(X = 1, Y = 0)

469

fiBromberg, Margaritis, & Honavar

Hamming distance for sampled data
n = 50,  = 1,  = 1.5

GSMN* without propagation
GSMN* with propagation
GSIMN

0.6
0.4
0.2
0
4

6

8

10

12

14

16

18

0.4
0.2
0

20

0

2

Data set size (thousands of data points)

GSMN* without propagation
GSMN* with propagation
GSIMN

0.6
0.4
0.2
0
2

4

6

8

10

12

14

16

18

0.2
0
10

12

14

16

18

2

0.2
0
10

12

14

16

18

Data set size (thousands of data points)

8

10

12

14

16

18

0.2
0
6

8

10

12

14

16

18

20

0.4
0.2
0
4

6

8

10

12

14

16

18

Data set size (thousands of data points)

16

18

20

0.4
0.2
0
0

2

4

6

8

10

12

14

16

18

20

1
GSMN* without propagation
GSMN* with propagation
GSIMN

0.8
0.6
0.4
0.2
0
0

2

4

6

8

10

12

14

16

18

20

Hamming distance for sampled data
n = 50,  = 8,  = 2.0

0.6

2

14

Data set size (thousands of data points)

GSMN* without propagation
GSMN* with propagation
GSIMN

0

12

0.6

20

1
0.8

10

Hamming distance for sampled data
n = 50,  = 4,  = 2.0

0.4

4

8

Data set size (thousands of data points)

0.6

2

6

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

20

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

0

Normalized Hamming distance

Normalized Hamming distance

0.4

8

6

4

1

Hamming distance for sampled data
n = 50,  = 8,  = 1.5

0.6

6

2

Data set size (thousands of data points)

GSMN* without propagation
GSMN* with propagation
GSIMN

4

4

1

Hamming distance for sampled data
n = 50,  = 8,  = 1.0

2

0

Hamming distance for sampled data
n = 50,  = 2,  = 2.0

0

20

1

0

0

Data set size (thousands of data points)

0.2

Data set size (thousands of data points)

0.8

0.2

20

0.4

0

Normalized Hamming distance

Normalized Hamming distance

0.4

8

18

0.4

Hamming distance for sampled data
n = 50,  = 4,  = 1.5

0.6

6

16

0.6

Data set size (thousands of data points)

GSMN* without propagation
GSMN* with propagation
GSIMN

4

14

0.6

Hamming distance for sampled data
n = 50,  = 4,  = 1.0

2

12

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

20

1

0

10

1

Data set size (thousands of data points)

0.8

8

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

Hamming distance for sampled data
n = 50,  = 2,  = 1.5
Normalized Hamming distance

Normalized Hamming distance

Hamming distance for sampled data
n = 50,  = 2,  = 1.0

0

6

1

Data set size (thousands of data points)

1
0.8

4

Normalized Hamming distance

2

0.6

Normalized Hamming distance

0

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

Normalized Hamming distance

0.8

Hamming distance for sampled data
n = 50,  = 1,  = 2.0

1

Normalized Hamming distance

Normalized Hamming distance

Normalized Hamming distance

Hamming distance for sampled data
n = 50,  = 1,  = 1.0
1

20

1
GSMN* without propagation
GSMN* with propagation
GSIMN

0.8
0.6
0.4
0.2
0
0

2

4

6

8

10

12

14

16

18

20

Data set size (thousands of data points)

Figure 8: Normalized Hamming distances between the true network and the network output
by GSMN (with and without propagation) and GSIMN for domain size n = 50
and average degrees  = 1, 2, 4, 8.

The network parameters were generated randomly so that the log-odds ratio between every
pair of variables connected by an edge in the graph has a specified value. In this set of
experiments, we used values of  = 1,  = 1.5 and  = 2 for every such pair of variables in
the network.
Figures 8 and 9 show plots of the normalized Hamming distance between the true
network and that output by the GSMN (with and without propagation) and GSIMN for
domain sizes of n = 50 and n = 75 variables, respectively. These plots show that the
Hamming distance of GSIMN is comparable to the ones of the GSMN algorithms for both

470

fiEfficient Markov Network Structure Discovery Using Independence Tests

Hamming distance for sampled data
n = 75,  = 1,  = 1.5

GSMN* without propagation
GSMN* with propagation
GSIMN

0.6
0.4
0.2
0
4

6

8

10

12

14

16

18

0.4
0.2
0

20

0

2

Data set size (thousands of data points)

GSMN* without propagation
GSMN* with propagation
GSIMN

0.6
0.4
0.2
0
2

4

6

8

10

12

14

16

18

0.2
0
10

12

14

16

18

2

0.2
0
10

12

14

16

18

Data set size (thousands of data points)

8

10

12

14

16

18

0.2
0
6

8

10

12

14

16

18

20

0.4
0.2
0
4

6

8

10

12

14

16

18

Data set size (thousands of data points)

16

18

20

0.4
0.2
0
0

2

4

6

8

10

12

14

16

18

20

1
GSMN* without propagation
GSMN* with propagation
GSIMN

0.8
0.6
0.4
0.2
0
0

2

4

6

8

10

12

14

16

18

20

Hamming distance for sampled data
n = 75,  = 8,  = 2.0

0.6

2

14

Data set size (thousands of data points)

GSMN* without propagation
GSMN* with propagation
GSIMN

0

12

0.6

20

1
0.8

10

Hamming distance for sampled data
n = 75,  = 4,  = 2.0

0.4

4

8

Data set size (thousands of data points)

0.6

2

6

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

20

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

0

Normalized Hamming distance

Normalized Hamming distance

0.4

8

6

4

1

Hamming distance for sampled data
n = 75,  = 8,  = 1.5

0.6

6

2

Data set size (thousands of data points)

GSMN* without propagation
GSMN* with propagation
GSIMN

4

4

1

Hamming distance for sampled data
n = 75,  = 8,  = 1.0

2

0

Hamming distance for sampled data
n = 75,  = 2,  = 2.0

0

20

1

0

0

Data set size (thousands of data points)

0.2

Data set size (thousands of data points)

0.8

0.2

20

0.4

0

Normalized Hamming distance

Normalized Hamming distance

0.4

8

18

0.4

Hamming distance for sampled data
n = 75,  = 4,  = 1.5

0.6

6

16

0.6

Data set size (thousands of data points)

GSMN* without propagation
GSMN* with propagation
GSIMN

4

14

0.6

Hamming distance for sampled data
n = 75,  = 4,  = 1.0

2

12

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

20

1

0

10

1

Data set size (thousands of data points)

0.8

8

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

Hamming distance for sampled data
n = 75,  = 2,  = 1.5
Normalized Hamming distance

Normalized Hamming distance

Hamming distance for sampled data
n = 75,  = 2,  = 1.0

0

6

1

Data set size (thousands of data points)

1
0.8

4

Normalized Hamming distance

2

0.6

Normalized Hamming distance

0

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8

Normalized Hamming distance

0.8

Hamming distance for sampled data
n = 75,  = 1,  = 2.0

1

Normalized Hamming distance

Normalized Hamming distance

Normalized Hamming distance

Hamming distance for sampled data
n = 75,  = 1,  = 1.0
1

20

1
GSMN* without propagation
GSMN* with propagation
GSIMN

0.8
0.6
0.4
0.2
0
0

2

4

6

8

10

12

14

16

18

20

Data set size (thousands of data points)

Figure 9: Normalized Hamming distance results as in Figure 8 but for domain size n = 75.

domain sizes n = 50 and n = 75, all average degrees  = 1, 2, 4, 8 and log-odds ratios  = 1,
 = 1.5 and  = 2. This reinforces the claim that inference done by GSIMN has a small
impact on the quality of the output networks.
Figure 10 shows the weighted number of tests of GSIMN vs. GSMN (with and without
propagation) for a sampled data set of 20,000 points for domains n = 50, and n = 75,
average degree parameters  = 1, 2, 4, and 8 and log-odds ratios  = 1, 1.5 and 2. GSIMN
shows a reduced weighted number of tests with respect to GSMN without propagation in
all cases and compared to GSMN with propagation in most cases (with the only exceptions
of ( = 4,  = 2) and ( = 8,  = 1.5)). For sparse networks and weak dependences i.e.,
 = 1, this reduction is larger than 50% for both domain sizes, a reduction much larger

471

fiBromberg, Margaritis, & Honavar

Weighted cost for sampled data
 = 1,  = 1.0, 20,000 data points

Weighted cost for sampled data
 = 1,  = 1.5, 20,000 data points

200000
150000
100000
50000
0

250000

GSMN* without propagation
GSMN* with propagation
GSIMN

200000
150000
100000
50000
0

50

75

Weighted cost for sampled data
 = 2,  = 1.0, 20,000 data points

100000
50000
0

250000

GSMN* without propagation
GSMN* with propagation
GSIMN

200000
150000
100000
50000

75

GSMN* without propagation
GSMN* with propagation
GSIMN

200000
150000
100000
50000

75

50

Weighted cost for sampled data
 = 4,  = 1.5, 20,000 data points

Weighted cost for sampled data
 = 4,  = 2.0, 20,000 data points

200000
150000
100000
50000
0

250000

300000
GSMN* without propagation
GSMN* with propagation
GSIMN

Weighted number of tests

GSMN* without propagation
GSMN* with propagation
GSIMN

200000
150000
100000
50000
0

75

250000

GSMN* without propagation
GSMN* with propagation
GSIMN

200000
150000
100000
50000
0

50

Number of variables

75

50

Number of variables

Weighted cost for sampled data
 = 8,  = 1.0, 20,000 data points

Weighted cost for sampled data
 = 8,  = 2.0, 20,000 data points

300000
Weighted number of tests

GSMN* without propagation
GSMN* with propagation
GSIMN

200000
150000
100000
50000
0

250000

300000
GSMN* without propagation
GSMN* with propagation
GSIMN

200000
150000
100000
50000
0

75

75
Number of variables

Weighted cost for sampled data
 = 8,  = 1.5, 20,000 data points

300000

75
Number of variables

300000
Weighted number of tests

Weighted number of tests

250000

Number of variables

Weighted cost for sampled data
 = 4,  = 1.0, 20,000 data points

Weighted number of tests

Weighted cost for sampled data
 = 2,  = 2.0, 20,000 data points

0
50

300000

75

300000

Number of variables

Number of variables

50000

Number of variables

0

50

100000

50

Weighted number of tests

150000

250000

150000

Weighted cost for sampled data
 = 2,  = 1.5, 20,000 data points
Weighted number of tests

Weighted number of tests

GSMN* without propagation
GSMN* with propagation
GSIMN

50

200000

75

300000

200000

250000

GSMN* without propagation
GSMN* with propagation
GSIMN

Number of variables

300000

50

250000

0
50

Number of variables

250000

Weighted number of tests

GSMN* without propagation
GSMN* with propagation
GSIMN

300000

Weighted number of tests

250000

Weighted cost for sampled data
 = 1,  = 2.0, 20,000 data points

300000
Weighted number of tests

Weighted number of tests

300000

250000

GSMN* without propagation
GSMN* with propagation
GSIMN

200000
150000
100000
50000
0

50

75
Number of variables

50

75
Number of variables

Figure 10: Weighted number of tests executed by GSMN (with and without propagation)
and GSIMN for |D| = 20, 000, for domains sizes n = 50 and 75, average degree
parameters  = 1, 2, 4, and 8, and log-odds ratios  = 1, 1, 5, and 2.

than the one observed for the exact learning experiments. The actual execution times for
various data set sizes and network densities are shown in Figure 11 for the largest domain
of n = 75, and  = 1, verifying the reduction in cost of GSIMN for various data set sizes.
Note that the reduction is proportional to the number of data points; this is reasonable as
each test executed must go over the entire data set once to construct the contingency table.
This confirms our claim that the cost of inference of GSIMN is small (constant time per
test, see discussion in Section 4.6) compared to the execution time of the tests themselves,
and indicates increasing cost benefits of the use of GSIMN for even large data sets.

472

fiEfficient Markov Network Structure Discovery Using Independence Tests

Execution times for sampled data sets
n = 75 variables,  = 1,  = 1

Execution times for sampled data sets
n = 75 variables,  = 2,  = 1

300

300
GSMN* without propagation
GSMN* with propagation
GSIMN

GSMN* without propagation
GSMN* with propagation
GSIMN

250
Execution time (sec)

Execution time (sec)

250
200
150
100
50

200
150
100
50

0

0
0

2000 4000 6000 8000 10000 12000 14000 16000 18000 20000

0

Execution times for sampled data sets
n = 75 variables,  = 4,  = 1

Execution times for sampled data sets
n = 75 variables,  = 8,  = 1

300

300
GSMN* without propagation
GSMN* with propagation
GSIMN

GSMN* without propagation
GSMN* with propagation
GSIMN

250
Execution time (sec)

250
Execution time (sec)

2000 4000 6000 8000 10000 12000 14000 16000 18000 20000

200
150
100
50

200
150
100
50

0

0
0

2000 4000 6000 8000 10000 12000 14000 16000 18000 20000

0

2000 4000 6000 8000 10000 12000 14000 16000 18000 20000

Figure 11: Execution times for sampled data experiments for  = 1,  = 1, 2 (top row)
and  = 4, 8 (bottom row) for a domain of n = 75 variables.

5.1.3 Real-World Network Sampled Data Experiments
We also conducted sampled data experiments on well-known real-world networks. As there
is no known repository of Markov networks drawn from real-world domains, we instead
utilized well-known Bayesian networks that are widely used in Bayesian network research
and are available from a number of repositories.1 To generate Markov networks from these
Bayesian network structures we used the process of moralization (Lauritzen, 1996) that
consists of two steps: (a) connect each pair of nodes in the Bayesian network that have
a common child with an undirected edge and (b) remove directions of all edges. This
results in a Markov network in which the local Markov property is valid i.e., each node is
conditionally independent of all other nodes in the domain given its direct neighbors. During
this procedure some conditional independences may be lost. This, however, does not affect
the accuracy results because we compare the independencies of the output network with
those of the moralized Markov network (as opposed to the Bayesian network).
We conducted experiments using 5 real-world domains: Hailfinder, Insurance, Alarm,
Mildew, and Water. For each domain we sampled a varying number of data points from its
corresponding Bayesian network using logic sampling (Henrion, 1988), and used it as input
to the GSMN (with and without propagation) and GSIMN algorithms. We then compared
the network output from each of these algorithms to the original moralized network using
the normalized Hamming distance metric previously described. The results are shown in
1. We used http://compbio.cs.huji.ac.il/Repository/. Accessed on December 5, 2008.

473

fiBromberg, Margaritis, & Honavar

Hamming distance for hailfinder data set

Hamming distance for insurance data set

Hamming distance for alarm data set

GSMN* without propagation
GSMN* with propagation
GSIMN

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0

2

4

6

8

10 12 14 16

1
GSMN* without propagation
GSMN* with propagation
GSIMN

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

18 20 22

0

Data set size (thousands of data points)

2

4

6

8

10 12 14 16

Normalized Hamming distance

Normalized Hamming distance

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

18 20 22

0

2

4

6

8

10 12 14 16

18 20 22

Data set size (thousands of data points)

Hamming distance for Water data set

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8
0.7

GSMN* without propagation
GSMN* with propagation
GSIMN

0.9
0.8

Data set size (thousands of data points)

Hamming distance for Mildew data set
1
0.9

Normalized Hamming distance

1
Normalized Hamming distance

Normalized Hamming distance

1

0.6
0.5
0.4
0.3
0.2
0.1
0

1
0.9

GSMN* without propagation
GSMN* with propagation
GSIMN

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

2

4

6

8

10 12 14 16

18 20 22

0

Data set size (thousands of data points)

2

4

6

8

10 12 14 16

18 20 22

Data set size (thousands of data points)

Figure 12: Normalized Hamming distance of the network output by GSMN (with and
without propagation) and GSIMN with the true Markov networks network using
varying data set sizes sampled from Markov networks for various real-world
domains modeled by Bayesian networks.

Fig. 12 and indicate that the distances produced from the three algorithms are similar.
In some cases (e.g., Water and Hailfinder) the network resulting from the use of GSIMN
is actually better (of smaller Hamming distance) than the ones output by the GSMN
algorithms.
We also measured the weighted cost of the three algorithms for each of these domains,
shown in Fig. 13. The plots show a significant decrease in the weighted number of tests for
GSIMN with respect to both GSMN algorithms: the cost of GSIMN is 66% of the cost of
GSMN without propagation on average, a savings of 34%, while the cost of GSIMN is 28%
of the cost of GSMN without propagation on average, a savings of 72%.
5.2 Real-World Data Experiments
While the artificial data set studies of the previous section have the advantage of allowing a
more controlled and systematic study of the performance of the algorithms, experiments on
real-world data are necessary for a more realistic assessment of their performance. Real data
are more challenging because they may come from non-random topologies (e.g., a possibly
irregular lattice in many cases of spatial data) and the underlying probability distribution
may not be faithful.
We conducted experiments on a number of data sets obtained from the UCI machine
learning data set repository (Newman, Hettich, Blake, & Merz, 1998). Continuous variables
in the data sets were discretized using a method widely recommended in introductory statistics texts (Scott, 1992); it dictates that the optimal number of equally-spaced discretization
bins for each continuous variable is k = 1 + log2 N , where N is the number of points in the
474

fiEfficient Markov Network Structure Discovery Using Independence Tests

GSMN* without propagation
GSMN* with propagation
GSIMN

70000
60000
50000
40000
30000
20000

GSMN* without propagation
GSMN* with propagation
GSIMN

8000

Weighted cost of tests

Weighted cost of tests

80000

Weighted cost of tests for insurance data set
9000
7000
5000
4000
3000
2000

14000
12000
10000
8000
6000
4000
2000

1000

0

0
0

5

10

15

20

0
0

5

Data set size (thousands of data points)

10

15

0

5

10

15

GSMN* without propagation
GSMN* with propagation
GSIMN

25000

8000
6000
4000
2000

20000
15000
10000
5000

0

0
0

5

10

15

20

0

Data set size (thousands of data points)

5

10

15

20

Data set size (thousands of data points)

Figure 13: Weighted cost of tests conducted by the GSMN (with and without propagation)
and GSIMN algorithms for various real-world domains modeled by Bayesian
networks.
Weighted cost and accuracy for real-world data sets
1
acc(GSIMN) - acc(GSMN* without propagation)
acc(GSIMN) - acc(GSMN* with propagation)
wc(GSIMN) / wc(GSMN* without propagation)
wc(GSIMN) / wc(GSMN* with propagation)

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
-0.1
-0.2

19 1

2 14 6

7 12 8

3 13 15 4
Data set index

5 10 11 18 17 9 16

Figure 14: Ratio of the weighted number of tests of GSIMN versus GSMN and difference
between the accuracy of GSIMN and GSMN on real data sets. Ratios smaller
that 1 and positive bars indicate an advantage of GSIMN over GSMN . The
numbers in the x-axis are indices of the data sets as shown in Table 1.

data set. For each data set and each algorithm, we report the weighted number of conditional independence tests conducted to discover the network and the accuracy, as defined
below.

475

20

Data set size (thousands of data points)

Weighted cost of tests for Water data set

GSMN* without propagation
GSMN* with propagation
GSIMN

Weighted cost of tests

Weighted cost of tests

20

Data set size (thousands of data points)

Weighted cost of tests for Mildew data set
10000

GSMN* without propagation
GSMN* with propagation
GSIMN

16000

6000

10000

Weighted cost of tests for alarm data set

Weighted cost of tests

Weighted cost of tests for hailfinder data set

fiBromberg, Margaritis, & Honavar

Table 1: Weighted number of tests and accuracy for several real-world data sets. For each
evaluation measure, the best performance between GSMN (with and without
propagation) and GSIMN is indicated in bold. The number of variables in the
domain is denoted by n and the number of data points in each data set by N .

#
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

Data set
Name
echocardiogram
ecoli
lenses
hayes-roth
hepatitis
cmc
balance-scale
baloons
flag
tic-tac-toe
bridges
car
monks-1
haberman
nursery
crx
imports-85
dermatology
adult

n

N

14
9
5
6
20
10
5
5
29
10
12
7
7
5
9
16
25
35
10

61
336
24
132
80
1473
625
20
194
958
70
1728
556
306
12960
653
193
358
32561

Weighted number of tests
GSMN
GSMN
GSIMN
(w/o prop.) (w/ prop.)
1311
1050
604
425
309
187
60
40
20
102
72
30
1412
980
392
434
292
154
82
47
29
60
40
20
5335
2787
994
435
291
119
520
455
141
194
140
67
135
93
42
98
76
42
411
270
123
1719
999
305
4519
3064
1102
9902
6687
2635
870
652
418

GSMN
(w/o prop.)
0.244
0.353
0.966
0.852
0.873
0.746
0.498
0.932
0.300
0.657
0.814
0.622
0.936
0.308
0.444
0.279
0.329
0.348
0.526

Accuracy
GSMN
(w/ prop.)
0.244
0.394
0.966
0.852
0.912
0.767
0.797
0.932
0.674
0.657
0.635
0.677
0.936
0.308
0.793
0.556
0.460
0.541
0.537

GSIMN
0.244
0.411
0.966
0.852
0.968
0.794
0.698
0.932
0.929
0.704
0.916
0.761
0.936
0.308
0.755
0.892
0.847
0.808
0.551

Because for real-world data the structure of the underlying Bayesian network (if any)
is unknown, it is impossible to measure the Hamming distance of the resulting network
structure. Instead, we measured the estimated accuracy of a network produced by GSMN
or GSIMN by comparing the result (true or false) of a number of conditional independence
tests on the network learned by them (using vertex separation) to the result of the same tests
performed on the data set (using a 2 test). This approach is similar to estimating accuracy
in a classification task over unseen instances but with inputs here being triplets (X, Y, Z)
and the class attribute being the value of the corresponding conditional independence test.
We used 1/3 of the real-world data set (randomly sampled) as input to GSMN and GSIMN
and the entire data set to the 2 test. This corresponds to the hypothetical scenario that
a much smaller data set is available to the researcher, and approximates the true value
of the test by its outcome on the entire data set. Since the number of possible tests is
exponential, we estimated the independence accuracy by sampling 10,000 triplets (X, Y, Z)
randomly, evenly distributed among all possible conditioning set sizes m  {0, . . . , n  2}
(i.e., 10000/(n  1) tests for each m). Each of these triplets was constructed as follows:
First, two variables X and Y were drawn randomly from V. Second, the conditioning set
was determined by picking the first m variables from a random permutation of V  {X, Y }.
Denoting by T this set of 10,000 triplets, by t  T a triplet, by Idata (t) the result of a test
performed on the entire data set and by Inetwork (t) the result of a test performed on the

476

fiEfficient Markov Network Structure Discovery Using Independence Tests

network output by either GSMN or GSIMN, the estimated accuracy is defined as:
fi
ofifi
1 fifin
t  T | Inetwork (t) = Idata (t) fifi.
accuracy
\ =
|T | fi

For each of the data sets, Table 1 shows the detailed results for accuracy and the weighted
number of tests for the GSMN and GSIMN algorithms. These results are also plotted in
Figure 14, with the horizontal axis indicating the data set index appearing in the first column
of Table 1. Figure 14 plots two quantities in the same graph for these real-world data sets:
the ratio of the weighted number of tests of GSIMN versus the two GSMN algorithms
and the difference of their accuracies. For each data set, an improvement of GSIMN over
GSMN corresponds to a number smaller than 1 for the ratios and a positive histogram bar
for the accuracy differences. We can observe that GSIMN reduced the weighted number of
tests on every data set, with maximum savings of 82% over GSMN without propagation
(for the crx data set) and 60% over GSMN with propagation (for the crx data set as
well). Moreover, in 11 out of 19 data sets GSIMN resulted in improved accuracy, 6 in a tie
and only 2 in somewhat reduced accuracy compared to GSMN with propagation (for the
nursery and balance-scale data sets).

6. Conclusions and Future Research
In this paper we presented two algorithms, GSMN and GSIMN, for learning efficiently
the structure of a Markov network of a domain from data using the independence-based
approach (as opposed to NP-hard algorithms based on maximum likelihood estimation) We
evaluated their performance through measurement of the weighted number of tests they
require to learn the structure of the network and the quality of the networks learned from
both artificial and real-world data sets. GSIMN showed a decrease in the vast majority
of artificial and real-world domains in an output network quality comparable to that of
GSMN , with some cases showing improvement. In addition, GSIMN was shown to be
nearly optimal in the number of tests executed compared to GSIMN-FCH, which uses an
exhaustive search to produce all independence information that can inferred from Pearls
axioms. Some directions of future research include an investigation into the way the topology
of the underlying Markov network affects the number of tests required and quality of the
resulting network, especially for commonly occurring topologies such as grids. Another
research topic is the impact on number of tests of other examination and grow orderings of
the variables.

Acknowledgments
We thank Adrian Silvescu for insightful comments on accuracy measures and general advice
on the theory of undirected graphical models.

Appendix A. Correctness of GSMN
For each variable X  V examined during the main loop of the GSMN algorithm (lines
1039), the set BX of variable X  V is constructed by growing and shrinking a set S,
477

fiBromberg, Margaritis, & Honavar

starting from the empty set. X is then connected to each member of BX to produce the
structure of a Markov network. We prove that this procedure returns the actual Markov
network structure of the domain.
For the proof of correctness we make the following assumptions.
 The axioms of Eqs. (1) hold.
 The probability distribution of the domain is strictly positive (required for Intersection
axiom to hold).
 Tests are conducted by querying an oracle, which returns its true value in the underlying model.
The algorithm examines every variable Y  X for inclusion to S (and thus to BX )
during the grow phase (lines 18 to 33) and, if Y was added to S during the grow phase, it
considers it for removal during the shrinking phase (lines 34 to 37). Note that there is only
one test executed between X and Y during the growing phase of X; we call this the grow
test of Y on X (line 23). Similarly, there is one or no tests executed between X and Y
during the shrinking phase; this test (if executed) is called the shrink test of Y on X (line
36).
The general idea behind the proof is to show that, while learning the blanket of X,
variable Y is in S by the end of the shrinking phase if and only if the dependence (X 6Y |
V  {X, Y }) between X and Y holds (which, according to Theorem 2 at the end of the
Appendix, implies there is an edge between X and Y ). We can immediately prove one
direction.
Lemma 1. If Y 
/ S at the end of the shrink phase, then (XY | V  {X, Y }).
Proof. Let us assume that Y 
/ S by the end of the shrink phase. Then, either Y was
not added to set S during the grow phase (i.e., line 24 was never reached), or removed
from it during the shrink phase (i.e., line 37 was reached). The former can only be true if
(pXY > ) in line 22 (indicating X and Y are unconditionally independent) or Y was found
independent of X in line 23. The latter can only be true if Y was found independent of X
in line 36. In all cases then A  V  {X, Y } such that (XY | A), and by Strong Union
then (XY | V  {X, Y }).
The opposite direction is proved in Lemma 6 below. However, its proof is more involved,
requiring a few auxiliary lemmas, observations, and definitions. The two main auxiliary
Lemmas are 4 and 5. Both use the lemma presented next (Lemma 2) inductively to extend
the conditioning set of dependencies found by the grow and shrink tests between X and Y ,
to all the remaining variables V{X, Y }. The Lemma shows that, if a certain independence
holds, the conditioning set of a dependence can be increased by one variable.
Lemma 2. Let X, Y  V, Z  V  {X, Y }, and Z  Z. Then  W  V,
(X 6Y | Z) and (XW | Z  {Y }) = (X 6Y | Z  {W }).

478

fiEfficient Markov Network Structure Discovery Using Independence Tests

Proof. We prove by contradiction, and make use of the axioms of Intersection (I), Strong
Union (SU), and Decomposition (D). Let us assume that (X 6Y | Z) and (XW | Z {Y })
but (XY | Z  {W }). Then
(XY | Z  {W }) and (XW | Z  {Y })
SU

=

(XY | Z  {W }) and (XW | Z  {Y })

I

(X{Y, W } | Z)

D

=

(XY | Z)  (XW | Z)

=

(XY | Z).

=

This contradicts the assumption (X 6Y | Z).
We now introduce notation and definitions and prove auxiliary lemmas.
We denote by SG the value of S at the end of the grow phase (line 34) i.e., the set of
variables found dependent of X during the grow phase, and by SS the value of S at the end
of the shrink phase (line 39). We also denote by G the set of variables found independent
of X during the grow phase and by U = [U0 , . . . , Uk ] the sequence of variables shrunk from
BX , i.e., found independent of X during the shrink phase. The sequence U is assumed
ordered as follows: if i < j then variable Ui was found independent from X before Uj
during the shrinking phase. A prefix of the first i variables [U0 , . . . , Ui1 ] of U is denoted
by Ui . For some test t performed during the algorithm, we define k(t) as the integer such
that Uk(t) is the prefix of U containing the variables that were found independent of X in
this loop before t. Furthermore, we abbreviate Uk(t) by Ut .
From the definition of U and the fact that in the grow phase the conditioning set
increases by dependent variables only, we can immediately make the following observation:
Observation 1. For some variable Ui  U, if t denotes the shrink test performed between
X and Ui then Ut = Ui1 .
We can then relate the conditioning set of the shrink test t with Ut as follows:
Lemma 3. If Y  SS and t = (X, Y | Z) is the shrink test of Y , then Z = SG  Ut  {Y }.
Proof. According to line 36 of the algorithm, Z = S  {Y }. At the beginning of the shrink
phase (line 34) S = SG , but variables found independent afterward and until t is conducted
are removed from S in line 37. Thus, by the time t is performed, S = SG  Ut and the
conditioning set becomes SG  Ut  {Y }.
Corollary 1. (XUi | SG  Ui ).
Proof. The proof follows immediately from Lemma 3, Observation 1, and the fact that
Ui = Ui1  {Ui }.
The following two lemmas use Lemma 2 inductively to extend the conditioning set of
the dependence between X and a variable Y in SS . The first lemma starts from the shrink
test between X and Y (a dependence), and extends its conditioning set from SS  {Y } (or
equivalently SG  {Y }  Ut according to Lemma 3) to SG  {Y }.
479

fiBromberg, Margaritis, & Honavar

Lemma 4. If Y  SS and t is the shrink test of Y , then (X 6Y | SG  {Y }).
Proof. The proof proceeds by proving
(X 6Y | SG  {Y }  Ui )
by induction on decreasing values of i, for i  {0, 1, . . . , k(t)}, starting at i = k(t). The
lemma then follows for i = 0 by noticing that U0 = .
 Base case (i = k(t)): From Lemma 3, t = (X, Y | SG  {Y }  Ut ), which equals
(X, Y | SG  {Y }  Uk(t) ) by definition of Ut . Since Y  SS , it must be the case that
t was found dependent, i.e., (X 6Y | SG  {Y }  Uk(t) ).
 Inductive step: Let us assume that the statement is true for i = m, 0 < m  k(t)1:
(X 6Y | SG  {Y }  Um ).

(2)

We need to prove that this is also true for i = m  1:
(X 6Y | SG  {Y }  Um1 ).
By Corollary 1, we have
(XUm | SG  Um )
and by Strong Union,
(XUm | (SG  Um )  {Y })
or
(XUm | (SG  Um  {Y })  {Y }).

(3)

From Eqs. (2), (3) and Lemma 2 we get the desired relation:
(X 6Y | (SG  {Y }  Um )  {Um }) = (X 6Y | SG  {Y }  Um1 ).

Observation 2. By definition of SG , we have that for every test t = (X, Y | Z) performed
during the grow phase, Z  SG .
The following lemma completes the extension of the conditioning set of the dependence
between X and Y  SS into the universe of variables V  {X, Y }, starting from SG  {Y }
(where Lemma 4 left off) and extending it to SG  G  {Y }.
Lemma 5. If Y  SS , then (X 6Y | SG  G  {Y }).
Proof. The proof proceeds by proving
(X 6Y | SG  Gi  {Y })
by induction on increasing values of i from 0 to |G|, where Gi denotes the first i elements
of an arbitrary ordering of set G.
480

fiEfficient Markov Network Structure Discovery Using Independence Tests

 Base Case (i = 0): Follows directly from Lemma 4 for i = 0, since G0 = .
 Inductive Step: Let us assume that the statement is true for i = m, 0  m < |G|:
(X 6Y | SG  Gm  {Y }).

(4)

We need to prove that it is also true for i = m + 1:
(X 6Y | SG  Gm+1  {Y }).

(5)

From Observation 2 the grow test of Gm results in the independence:
(XGm | Z), where Z  SG .
By the Strong Union axiom this can become:
(XGm | Z  {Y }), where Z  SG

(6)

(XGm | (Z  {Y })  {Y }), where Z  SG .

(7)

or equivalently
Since Z  SG  SG  Gm , we have that Z  {Y }  SG  Gm , and so from Eq. (4)
and Lemma 2 we get the desired relation:
(X 6Y | (SG  Gm  {Y })  Gm ) = (X 6Y | SG  Gm+1  {Y }).

Finally, we can prove that X is dependent with every variable Y  SS given the universe
V  {X, Y }.
Lemma 6. If Y  SS , then (X 6Y | V  {X, Y }).
Proof. From Lemma 5,
(X 6Y | SG  G  {Y })
It suffices then to prove that SG  G  {Y } = V  {X, Y }. In loop 69 of GSMN , the
queue X is populated with all elements in V  {X}, and then, in line 21, Y is removed
from X . The grow phase then partitions X into variables dependent of X (set SG ) and
independent of X (set G).
Corollary 2. Y  SS  (X 6Y | V  {X, Y }).
Proof. Follows directly from Lemmas 1 and 6.
From the above Corollary we can now immediately show that the graph returned by
connecting X to each member of BX = SS is exactly the Markov network of the domain
using the following theorem, first published by Pearl and Paz (1985).
Theorem 2. (Pearl & Paz, 1985) Every dependence model M satisfying symmetry, decomposition, and intersection (Eqs. (1)) has a unique Markov network G = (V, E) produced by
deleting from the complete graph every edge (X, Y ) for which (XY | V  {X, Y }) holds
in M , i.e.,
(X, Y ) 
/ E  (XY | V  {X, Y }) in M .
481

fiBromberg, Margaritis, & Honavar

Appendix B. Correctness of GSIMN
The GSIMN algorithm differs from GSMN only by the use of test subroutine IGSIMN
instead of IGSMN (Algorithms 5 and 4, respectively), which in turn differs by a number
of additional inferences conducted to obtain the independencies (lines 8 to 22). These
inferences are direct applications of the Strong Union axiom (which holds by assumption)
and the Triangle theorem (which was proven to hold in Theorem 1). Using the correctness
of GSMN (proven in Appendix A) we can therefore conclude that the GSIMN algorithm
is correct.

References
Abbeel, P., Koller, D., & Ng, A. Y. (2006). Learning factor graphs in polynomial time and
sample complexity. Journal of Machine Learning Research, 7, 17431788.
Acid, S., & de Campos, L. M. (2003). Searching for Bayesian network structures in the
space of restricted acyclic partially directed graphs. Journal of Artificial Intelligence
Research, 18, 445490.
Agresti, A. (2002). Categorical Data Analysis (2nd edition). Wiley.
Aliferis, C. F., Tsamardinos, I., & Statnikov, A. (2003). HITON, a novel Markov blanket
algorithm for optimal variable selection. In Proceedings of the American Medical
Informatics Association (AMIA) Fall Symposium.
Anguelov, D., Taskar, B., Chatalbashev, V., Koller, D., Gupta, D., Heitz, G., & Ng, A.
(2005). Discriminative learning of Markov random fields for segmentation of 3D range
data. In Proceedings of the Conference on Computer Vision and Pattern Recognition
(CVPR).
Barahona, F. (1982). On the computational complexity of Ising spin glass models. Journal
of Physics A: Mathematical and General, 15 (10), 32413253.
Besag, J. (1974). Spacial interaction and the statistical analysis of lattice systems. Journal
of the Royal Statistical Society, Series B, 36, 192236.
Besag, J., York, J., & Mollie, A. (1991). Bayesian image restoration with two applications
in spatial statistics.. Annals of the Institute of Statistical Mathematics, 43, 159.
Bromberg, F., Margaritis, D., & Honavar, V. (2006). Efficient Markov network structure discovery from independence tests. In Proceedings of the SIAM International Conference
on Data Mining.
Buntine, W. L. (1994). Operations for learning with graphical models. Journal of Artificial
Intelligence Research, 2, 159225.
Castelo, R., & Roverato, A. (2006). A robust procedure for Gaussian graphical model search
from microarray data with p larger than n. Journal of Machine Learning Research,
7, 26212650.
Chow, C., & Liu, C. (1968). Approximating discrete probability distributions with dependence trees. IEEE Transactions on Information Theory, 14 (3), 462  467.

482

fiEfficient Markov Network Structure Discovery Using Independence Tests

Cochran, W. G. (1954). Some methods of strengthening the common 2 tests. Biometrics,
10, 417451.
Della Pietra, S., Della Pietra, V., & Lafferty, J. (1997). Inducing features of random fields.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 19 (4), 390393.
Dobra, A., Hans, C., Jones, B., Nevins, J. R., Yao, G., & West, M. (2004). Sparse graphical
models for exploring gene expression data. Journal of Multivariate Analysis, 90, 196
212.
Edwards, D. (2000). Introduction to Graphical Modelling (2nd edition). Springer, New
York.
Friedman, N., Linial, M., Nachman, I., & Peer, D. (2000). Using Bayesian networks to
analyze expression data. Computational Biology, 7, 601620.
Geman, S., & Geman, D. (1984). Stochastic relaxation, gibbs distributions, and the bayesian
relation of images.. IEEE Transactions on Pattern Analysis and Machine Intelligence,
6, 721741.
Heckerman, D. (1995). A tutorial on learning bayesian networks. Tech. rep. MSR-TR-95-06,
Microsoft Research.
Heckerman, D., Geiger, D., & Chickering, D. M. (1995). Learning Bayesian networks: The
combination of knowledge and statistical data. Machine Learning, 20, 197243.
Henrion, M. (1988). Propagation of uncertainty by probabilistic logic sampling in Bayes
networks. In Lemmer, J. F., & Kanal, L. N. (Eds.), Uncertainty in Artificial Intelligence 2. Elsevier Science Publishers B.V. (North Holland).
Hofmann, R., & Tresp, V. (1998). Nonlinear Markov networks for continuous variables. In
Neural Information Processing Systems, Vol. 10, pp. 521529.
Isard, M. (2003). Pampas: Real-valued graphical models for computer vision. In IEEE
Conference on Computer Vision and Pattern Recognition, Vol. 1, pp. 613620.
Jerrum, M., & Sinclair, A. (1993). Polynomial-time approximation algorithms for the Ising
model. SIAM Journal on Computing, 22, 10871116.
Kearns, M. J., & Vazirani, U. V. (1994). An Introduction to Computational Learning Theory.
MIT Press, Cambridge, MA.
Koller, D., & Sahami, M. (1996). Toward optimal feature selection. In International Conference on Machine Learning, pp. 284292.
Lam, W., & Bacchus, F. (1994). Learning Bayesian belief networks: an approach based on
the MDL principle. Computational Intelligence, 10, 269293.
Lauritzen, S. L. (1996). Graphical Models. Oxford University Press.
Margaritis, D., & Thrun, S. (2000). Bayesian network induction via local neighborhoods. In
Solla, S., Leen, T., & Muller, K.-R. (Eds.), Advances in Neural Information Processing
Systems 12, pp. 505511. MIT Press.
McCallum, A. (2003). Efficiently inducing features of conditional random fields. In Proceedings of Uncertainty in Artificial Intelligence (UAI).

483

fiBromberg, Margaritis, & Honavar

Newman, D. J., Hettich, S., Blake, C. L., & Merz, C. J. (1998). UCI repository of machine
learning databases. Tech. rep., University of California, Irvine, Dept. of Information
and Computer Sciences.
Pena, J. M. (2008). Learning Gaussian graphical models of gene networks with false discovery rate control. In Proceedings of the 6th European Conference on Evolutionary
Computation, Machine Learning and Data Mining in Bioinformatics, pp. 165176.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers, Inc.
Pearl, J., & Paz, A. (1985). Graphoids: A graph-based logic for reasoning about releveance
relations. Tech. rep. 850038 (R-53-L), Cognitive Systems Laboratory, University of
California.
Rebane, G., & Pearl, J. (1989). The recovery of causal poly-trees from statistical data.
In Kanal, L. N., Levitt, T. S., & Lemmer, J. F. (Eds.), Uncertainty in Artificial
Intelligence 3, pp. 175182, Amsterdam. North-Holland.
Schafer, J., & Strimmer, K. (2005). An empirical bayes approach to inferring large-scale
gene association networks. Bioinformatics, 21, 754764.
Scott, D. W. (1992). Multivariate Density Estimation. Wiley series in probability and
mathematical statistics. John Wiley & Sons.
Shekhar, S., Zhang, P., Huang, Y., & Vatsavai, R. R. (2004) In Kargupta, H., Joshi, A.,
Sivakumar, K., & Yesha, Y. (Eds.), Trends in Spatial Data Mining, chap. 19, pp.
357379. AAAI Press / The MIT Press.
Spirtes, P., Glymour, C., & Scheines, R. (2000). Causation, Prediction, and Search (2nd
edition). Adaptive Computation and Machine Learning Series. MIT Press.
Srebro, N., & Karger, D. (2001). Learning Markov networks: Maximum bounded tree-width
graphs. In ACM-SIAM Symposium on Discrete Algorithms.
Tsamardinos, I., Aliferis, C. F., & Statnikov, A. (2003a). Algorithms for large scale Markov
blanket discovery. In Proceedings of the 16th International FLAIRS Conference, pp.
376381.
Tsamardinos, I., Aliferis, C. F., & Statnikov, A. (2003b). Time and sample efficient discovery of Markov blankets and direct causal relations. In Proceedings of the 9th ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining, pp.
673678.
Tsamardinos, I., Brown, L. E., & Aliferis, C. F. (2006). The max-min hill-climbing Bayesian
network structure learning algorithm. Machine Learning, 65, 3178.
Whittaker, J. (1990). Graphical Models in Applied Multivariate Statistics. John Wiley &
Sons, New York.

484

fiJournal of Artificial Intelligence Research 35 (2009) 275-341

Submitted 09/08; published 06/09

Llull and Copeland Voting Computationally Resist
Bribery and Constructive Control
Piotr Faliszewski

FALISZEW @ AGH . EDU . PL

Department of Computer Science, AGH University of Science and Technology
Krakow, Poland

Edith Hemaspaandra

EH @ CS . RIT. EDU

Department of Computer Science, Rochester Institute of Technology
Rochester, NY 14623 USA

Lane A. Hemaspaandra

LANE @ CS . ROCHESTER . EDU

Department of Computer Science, University of Rochester
Rochester, NY 14627 USA

Jorg Rothe

ROTHE @ CS . UNI - DUESSELDORF. DE

Institut fur Informatik, Heinrich-Heine-Universitat Dusseldorf
40225 Dusseldorf, Germany

Abstract
Control and bribery are settings in which an external agent seeks to influence the outcome of
an election. Constructive control of elections refers to attempts by an agent to, via such actions as
addition/deletion/partition of candidates or voters, ensure that a given candidate wins. Destructive
control refers to attempts by an agent to, via the same actions, preclude a given candidates victory.
An election system in which an agent can sometimes affect the result and it can be determined in
polynomial time on which inputs the agent can succeed is said to be vulnerable to the given type
of control. An election system in which an agent can sometimes affect the result, yet in which it is
NP-hard to recognize the inputs on which the agent can succeed, is said to be resistant to the given
type of control.
Aside from election systems with an NP-hard winner problem, the only systems previously
known to be resistant to all the standard control types were highly artificial election systems created by hybridization. This paper studies a parameterized version of Copeland voting, denoted by
Copeland , where the parameter  is a rational number between 0 and 1 that specifies how ties are
valued in the pairwise comparisons of candidates. In every previously studied constructive or destructive control scenario, we determine which of resistance or vulnerability holds for Copeland
for each rational  , 0    1. In particular, we prove that Copeland0.5 , the system commonly
referred to as Copeland voting, provides full resistance to constructive control, and we prove
the same for Copeland , for all rational  , 0 <  < 1. Among systems with a polynomial-time
winner problem, Copeland voting is the first natural election system proven to have full resistance
to constructive control. In addition, we prove that both Copeland0 and Copeland1 (interestingly,
Copeland1 is an election system developed by the thirteenth-century mystic Llull) are resistant to
all standard types of constructive control other than one variant of addition of candidates. Moreover, we show that for each rational  , 0    1, Copeland voting is fully resistant to bribery
attacks, and we establish fixed-parameter tractability of bounded-case control for Copeland .
We also study Copeland elections under more flexible models such as microbribery and extended control, we integrate the potential irrationality of voter preferences into many of our results,
and we prove our results in both the unique-winner model and the nonunique-winner model. Our
vulnerability results for microbribery are proven via a novel technique involving min-cost network
flow.
c
2009
AI Access Foundation. All rights reserved.

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

1. Introduction
This section gives some history and an outline of our results.
1.1 Some Historical Remarks: Llulls and Copelands Election Systems
Elections have played an important role in human societies for thousands of years. For example,
elections were of central importance in the democracy of ancient Athens. There citizens typically
could only agree (vote yes) or disagree (vote no) with the speaker, and simple majority-rule was in
effect. The mathematical study of elections, give or take a few discussions by the ancient Greeks
and Romans, was until recently thought to have been initiated only a few hundred years ago, namely
in the breakthrough work of Borda and Condorcetlater in part reinvented by Dodgson (see, e.g.,
McLean and Urken, 1995, for reprints of these classic papers). One of the most interesting results of
this early work is Condorcets (1785) observation that if one conducts elections with more than two
alternatives then even if all voters have rational (i.e., transitive) preferences, the society in aggregate
can be irrational (indeed, can have cycles of strict preference). Nonetheless, Condorcet believed
that if there exists a candidate c such that c defeats each other candidate in head-to-head contests
then c should win the election (see, e.g., page 114 of McLean and Urken, 1995). Such a candidate
is called a Condorcet winner. Clearly, there can be at most one Condorcet winner in any election,
and there might be none.
This understanding of history has been reconsidered during the past few decades, as it has been
discovered that the study of elections was considered deeply as early as the thirteenth century (see
Hagele and Pukelsheim, 2001, and the citations therein regarding Ramon Llull and the fifteenthcentury figure Cusanus, especially the citations that in Hagele and Pukelsheim, 2001, are numbered
3, 5, and 2427). Ramon Llull (b. 1232, d. 1315), a Catalan mystic, missionary, and philosopher
developed an election system that (a) has an efficient winner-determination procedure and (b) elects
a Condorcet winner whenever one exists and otherwise elects candidates that are, in a certain sense,
closest to being Condorcet winners.
Llulls motivation for developing an election system was to obtain a method of choosing
abbesses, abbots, bishops, and perhaps even the pope. His election ideas never gained public acceptance in medieval Europe and were long forgotten.
It is interesting to note that Llull allowed voters to have so-called irrational preferences. Given
three candidates, c, d, and e, it was perfectly acceptable for a voter to prefer c to d, d to e, and e
to c. On the other hand, in modern studies of voting and election systems each voters preferences
are most typically modeled as a linear order over all candidates. (In this paper, as is common
when discussing elections, linear order implies strictness, i.e., no tie in the ordering; that is,
by linear order we mean a strict, complete order, i.e., an irreflexive, antisymmetric, complete,
transitive relation.) Yet allowing irrationality is very tempting and natural. Consider Bob, who
likes to eat out but is often in a hurry. Bob prefers diners to fast food because he is willing to
wait a little longer to get better food. Also, given a choice between a fancy restaurant and a diner
he prefers the fancy restaurant, again because he is willing to wait somewhat longer to get better
quality. However, given the choice between a fast-food place and a fancy restaurant Bob might
reason that he is not willing to wait so much longer to be served at the fancy restaurant and so
will choose fast food instead. Thus regarding catering options, Bobs preferences are irrational in
our sense, i.e., intransitive. When voters make their choices based on multiple criteriaa very
common and natural occurrence both among humans and software agentssuch irrationalities can
276

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

occur. Another example where irrationality might naturally occur, as suggested by a referee, is
the case when each voter is a delegate of some group (having an odd number of members), and
between each pair of alternatives each delegate votes for whichever alternative a majority of his or
her constituents prefers among that pair.
Llulls election system is remarkably similar to what is now known as Copeland elections (Copeland, 1951), a more than half-century old voting procedure that is based on pairwise
comparisons of candidates: The winner (by a majority of votesin this paper majority always,
as is standard, means strict majority) of each such head-to-head contest is awarded one point and
the loser is awarded zero points; in ties, both parties are (in the most common interpretation of
Copelands meaning) awarded half a point; whoever collects the most points over all these contests (including tie-related points) is the elections winner. In fact, the point value awarded for ties
in such head-to-head majority-rule contests is treated in two ways in the literature when speaking
of Copeland elections: half a point (most common) and zero points (less common). To provide a
framework that can capture both those notions, as well as capturing Llulls system and the whole
family of systems created by choices of how we value ties, we propose and introduce a parameterized version of Copeland elections, denoted by Copeland , where the parameter  is a rational
number, 0    1, and in the case of a tie both candidates receive  points. So the system widely
referred to in the literature as Copeland elections is Copeland0.5 , where tied candidates receive
half a point each (see, e.g., Saari and Merlin, 1996, and Merlin and Saari, 1997; the definition used
by Conitzer, Sandholm, & Lang, 2007, can be scaled to be equivalent to Copeland0.5 ). Copeland0 ,
where tied candidates come away empty-handed, has sometimes also been referred to as Copeland
elections (see, e.g., Procaccia, Rosenschein, and Kaminka, 2007, and Faliszewski, Hemaspaandra,
Hemaspaandra, and Rothe, 2007, an early version of this paper). The above-mentioned election
system proposed by Ramon Llull in the thirteenth century is in this notation Copeland1 , where tied
candidates are awarded one point each, just like winners of head-to-head contests.1 The group stage
1
of the FIFA World Cup finals is in essence a collection of Copeland 3 tournaments.
At first glance, one might be tempted to think that the definitional perturbation due to the parameter  in Copeland elections is negligible. However, it in fact can make the dynamics of Llulls
system quite different from those of, for instance, Copeland0.5 or Copeland0 . Specific examples
witnessing this claim, both regarding complexity results and regarding their proofs, are given at the
end of Section 1.3.
Finally, we mention that a probabilistic variant of Copeland voting (known as the Jech method)
was defined already in 1929 by Zermelo (1929) and later on was reintroduced by several other researches (see, e.g., Levin and Nalebuff, 1995, for further references and a description of the Jech
method). We note in passing that the Jech method is applicable even when it is fed incomplete information. In the present paper, however, we do not consider incomplete-information or probabilistic
scenarios, although we commend such settings as interesting for future work.
1. Page 23 of Hagele and Pukelsheim 2001 indicates in a way we find deeply convincing (namely by a direct quote of
Llulls in-this-case-very-clear words from his Artifitium Electionis Personarumwhich was rediscovered by those
authors in the year 2000) that at least one of Llulls election systems was Copeland1 , and so in this paper we refer to
the both-candidates-score-a-point-on-a-tie variant as Llull voting.
In some settings Llull required the candidate and voter sets to be identical and had an elaborate two-stage tiehandling rule ending in randomization. We disregard these issues here and cast his system into the modern idiom
for election systems. (However, we note in passing that there do exist some modern papers in which the voter and
candidate sets are taken to be identical, see for example the work of and references in Altman and Tennenholtz, 2007.)

277

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

1.2 Computational Social Choice
In general it is impossible to design a perfect election system. Arrow (1963) famously showed that
there is no social choice system that satisfies a certain small set of arguably reasonable requirements,
and later Gibbard (1973), Satterthwaite (1975), and Duggan and Schwartz (2000) showed that any
natural election system can sometimes be manipulated by strategic voting, i.e., by a voter revealing
different preferences than his or her true ones in order to affect an elections result in his or her
favor. Also, no natural election system with a polynomial-time winner-determination procedure
has yet been shown to be resistant to all types of control via procedural changes. Control refers to
attempts by an external agent (called the chair) to, via such actions as addition/deletion/partition
of candidates or voters, make a given candidate win the election (in the case of constructive control,
Bartholdi, Tovey, and Trick, 1992) or preclude a given candidates victory (in the case of destructive
control, Hemaspaandra, Hemaspaandra, and Rothe, 2007a).
These obstacles are very discouraging, but the field of computational social choice theory grew
in part from the realization that computational complexity provides a potential shield against manipulation/control/etc. In particular, around 1990, Bartholdi, Tovey, and Trick (1989a), Bartholdi
and Orlin (1991), and Bartholdi et al. (1992) brilliantly observed that while we perhaps might not
be able to make manipulation (i.e., strategic voting) and control of elections impossible, we could
at least try to make such manipulation and control so computationally difficult that neither voters
nor election organizers will attempt it. For example, if there is a way for a committees chair to set
up an election within the committee in such a way that his or her favorite option is guaranteed to
win, but the chairs computational task would take a million years, then for all practical purposes
we may feel that the chair is prevented from finding such a set-up.
Since the seminal work of Bartholdi, Orlin, Tovey, and Trick, a large body of research has been
dedicated to the study of computational properties of election systems. Some topics that have received much attention are the complexity of manipulating elections (Conitzer & Sandholm, 2003,
2006; Conitzer et al., 2007; Elkind & Lipmaa, 2005; Hemaspaandra & Hemaspaandra, 2007; Procaccia & Rosenschein, 2007; Meir, Procaccia, Rosenschein, & Zohar, 2008) and of controlling
elections via procedural changes (Hemaspaandra et al., 2007a; Hemaspaandra, Hemaspaandra, &
Rothe, 2007b; Meir et al., 2008; Erdelyi, Nowak, & Rothe, 2008b). Recently, Faliszewski, Hemaspaandra, and Hemaspaandra (2006a) introduced the study of the complexity of bribery in elections.
Bribery shares some features of manipulation and some features of control. In particular, the briber
picks the voters he or she wants to affect (as in voter control problems) and asks them to vote as he
or she wishes (as in manipulation). (For additional citations and pointers, see the recent survey Faliszewski, Hemaspaandra, Hemaspaandra, and Rothe, 2009.)
In this paper we study Copeland elections with respect to the computational complexity of
bribery and procedural control; see Faliszewski, Hemaspaandra, and Schnoor 2008 for a study of
manipulation within Copeland .
The study of election systems and their computational properties, such as the complexity of
their manipulation, control, and bribery problems, is an important topic in multiagent systems.
Agents/voters may have different, often conflicting, individual preferences over the given alternatives (or candidates) and voting rules (or, synonymously, election systems) provide a useful method
for agents to come to a reasonable decision on which alternative to choose. Thus elections can be
employed in multiagent settings and also in other contexts to solve many practical problems. As just
a few examples, we mention that Ephrati and Rosenschein (1997) use elections for planning, Ghosh,

278

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

Mundhe, Hernandez, and Sen (1999) develop a recommender system for movies that is based on
voting, and Dwork, Kumar, Naor, and Sivakumar (2001) use elections to aggregate results from
multiple web-search engines. In a multiagent setting we may have hundreds of elections happening
every minute and we cannot hope to carefully check in each case whether the party that organized
the election attempted some procedural change to skew the results. However, if it is computationally
hard to find such procedural changes then we can hope it is practically infeasible for the organizers
to undertake them.
A standard technique for showing that a particular election-related problem (for example, the
problem of deciding whether the chair can make his or her favorite candidate a winner by influencing
at most k voters not to cast their votes) is computationally intractable is to show that it is NP-hard.
This approach is taken in almost all the papers on computational social choice cited above, and
it is the approach that we take in this paper. One of the justifications for using NP-hardness as a
barrier against manipulation and control of elections is that in multiagent settings any attempts to
influence the elections outcome are made by computationally bounded software agents that have
neither human intuition nor the computational ability to solve NP-hard problems.
Recently, Conitzer and Sandholm (2006), Procaccia and Rosenschein (2007), Homan and
Hemaspaandra (to appear), and McCabe-Dansted, Pritchard, and Slinko (2008) have studied the
frequency (or sometimes, probability weight) of correctness of heuristics for voting problems. Although this is a fascinating and important direction, it does not at this point remove the need to study
worst-case hardness. Indeed, we view worst-case study as a natural prerequisite to a frequency-ofhardness attack: After all, there is no point in seeking frequency-of-hardness results if the problem
at hand is in P to begin with. And if one cannot even prove worst-case hardness for a problem,
then proving average-case hardness is even more beyond reach. Also, current frequency results
have debilitating limitations (for example, being locked into specific distributions; depending on unproven assumptions; and adopting tractability notions that declare undecidable problems tractable
and that are not robust under even linear-time reductions). These models are arguably not ready for
prime time and, contrary to some peoples impression, do not imply (and do not have the goal of
implying, since they are studying frequency of hardness) average-case polynomial runtime claims.
Erdelyi, Hemaspaandra, Rothe, and Spakowski (2007) and Homan and Hemaspaandra (to appear)
provide discussions of some of these issues. Regarding the recent work of Friedgut, Kalai, and
Nisan (2008) (see also Xia and Conitzer, 2008a, 2008b), that very interesting work is not on control, and the lower bounds proven there do not show that one can manipulate most of the time,
but rather that work provides lower bounds that unfortunately go to zero as the number of voters
increases, for the case there studied. Of course, the limitations of current results on frequency of
hardness surely do not mean that the direction is not interesting; clearly, the field should do its best
to go beyond those limitations.
1.3 Outline of Our Results
The goal of this paper is to study Copeland elections from the point of view of computational social
choice theory, in the setting where voters are rational and in the setting where voters are allowed
to have irrational preferences. (Note: When we henceforward say irrational voters, we mean that
the voters may have irrational preferences, not that they each must.) We study the issues of bribery
and control and we point the reader to Faliszewski et al. 2008 for work on manipulation. (Very
briefly summarized, the work of Faliszewski et al., 2008, on manipulation of Copeland elections

279

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

shows that for all rational  , 0 <  < 1,  6= 12 , the coalitional manipulation problem in unweighted
Copeland elections, even for coalitions of just two manipulators, is NP-complete. Some of the
constructions of the present paper have been adopted or adapted in that paper in order to prove
results about manipulation.)
Bribery and control problems have some very natural real-life interpretations. For example,
during presidential elections a candidate might want to encourage as many of his or her supporters
as possible to vote (get-out-the-vote efforts): control via addition of voters; elections can be held
at an inconvenient date for a group of voters (e.g., a holiday) or at a hard-to-reach location (e.g.,
requiring one to own a car, or such that getting to the location involves passing dangerous areas):
control via deleting voters; one can choose voting districts in a way favorable to a particular candidate or party (gerrymandering): control via partitioning voters; one can introduce a new candidate
to the election in the hope that he or she will steal votes away from the opponents of ones favorite
candidate without affecting the favorite candidates performance: control via adding candidates. All
the other control scenarios that we study also have natural interpretations.
Similarly, bribery is a natural and important issue in the context of elections. We stress, however, that bribery problems do not necessarily need to correspond to cheating or any sort of illegal
action. One could view bribery problems as, for example, problems of finding the minimum number of voters who can switch the result of the election and, thus, as problems of finding coalitions,
especially if one assigns prices to voters to measure the difficulty of convincing a particular voter to
join the coalition (see, e.g., Faliszewski, 2008, for an example of a bribery problem where such an
interpretation is very natural).
It is quite natural to study control and bribery both in constructive settings (where we want to
make our favorite candidate a winner) and in destructive settings (where we try to prevent a candidate from winning). In the context of real-life elections, one often hears voters speaking of which
candidate they hope will win, but one also often hears voters expressing the sentiment Anyone but
him. The constructive and destructive settings correspond to actions that agents belonging to these
groups might be interested in.
One of the main achievements of this paper is to classify which of resistance or vulnerability holds for Copeland in every previously studied control scenario for each rational value of  ,
0    1. In doing so, we provide an example of a control problem where the complexity of
Copeland0.5 (which is the system commonly referred to as Copeland) differs from that of both
Copeland0 and Copeland1 : While the latter two problems are vulnerable to constructive control
by adding (an unlimited number of) candidates, Copeland0.5 is resistant to this control type (see
Section 2 for definitions and Theorem 4.10 for this result).
In fact, Copeland (i.e., Copeland0.5 ) is the first natural election system (with a polynomial-time
winner problem) proven to be resistant to every type of constructive control that has been proposed
in the literature to date. This result closes a 15-year quest for a natural election system fully resistant
to constructive control.2
2. A referee wondered whether (and speculated that) virtually every common rule (other than plurality and Condorcet,
said the referee, although actually plurality displays breathtakingly many resistances itself, albeit not all the constructive resistances) would display just as broad resistance to control as does Copeland, were one to obtain results for
those rules. This of course is an open issue, but we see no reason to think it will be the case (and approval voting
already provides a counterexample, see Hemaspaandra et al., 2007a). And even if that were the case and most other
rules resisted as many control types, we suspect that the pattern of which types are resisted will differ among the
rules, although it is the case that the four quadrants (of constructive/destructive and voter/candidate do seem to
often stand or fall as a block). That pattern seems to us something that is of natural importance, since ones choice

280

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

We also show that Copeland is resistant to both constructive and destructive bribery, for both
the case of rational voters and the case of irrational voters. Our hardness proofs work for the case
of unweighted voters without price tags (see Faliszewski et al., 2006a) and thus, naturally, apply
as well to the more involved scenarios of weighted unpriced voters, unweighted priced voters, and
weighted priced voters.
To prove our bribery results, we introduce a method of controlling the relative performances of
certain voters in such a way that, if one sets up other restrictions appropriately, the legal possibilities
for bribery actions are sharply constrained. We call our approach the UV technique, since it is
based on dummy candidates u and v. The proofs of Theorems 3.2 and 3.4 are particular applications
of this method. We feel that the UV technique will be useful, even beyond the scope of this paper,
for the analysis of bribery in other election systems based on head-to-head contests.
We also study Copeland elections under more flexible models such as microbribery (see Section 3.2) and extended control (see Section 4.3). We show that Copeland (with irrational voters
allowed) is vulnerable to destructive microbribery and to destructive candidate control via providing
fairly simple greedy algorithms. In contrast, our polynomial-time algorithms for constructive microbribery are proven via a technique involving min-cost network flows. To the best of our knowledge,
this is the first application of min-cost flows to election problems. We believe that the range of applicability of flow networks to election problems extends well beyond microbribery for Copeland
elections and we point the reader to a recent, independent paper by Procaccia, Rosenschein, and
Zohar (2008)3 and to a paper by Faliszewski (2008) for examples of such applications.
We also mention that during our study of Copeland control we noticed that the proof of an
important result of Bartholdi et al. (1992, Theorem 12), namely, that Condorcet voting is resistant
to constructive control by deleting voters, is invalid. The invalidity is due to the proof centrally
using nonstrict voters, in violation of Bartholdi et al.s (1992) (and our) model, and the invalidity
seems potentially daunting or impossible to fix with the proof approach taken there. We note also
that Theorem 14 of the same paper has a similar flaw. In Section 5 we validly reprove their claimed
results using our techniques.
As mentioned in Section 1.1, Copeland elections may behave quite differently depending on
the value of the tie-rewarding parameter  . We now give concrete examples to make this case.
Specifically, proofs of results for Copeland occasionally differ considerably for distinct values
of  , and in some cases even the computational complexity of various control and manipulation
problems (for the manipulation case see Faliszewski et al., 2008) may jump between P membership
and NP-completeness depending on  . Regarding control, we have already noted that Theorem 4.10
shows that some control problem (namely, control by adding an unlimited number of candidates)
for Copeland is NP-complete for each rational  with 0 <  < 1, yet Theorem 4.11 shows that
same control problem to be in P for   {0, 1}. To give another example involving a different
of election rule should probably (along with many other factors that should influence rule choice) be shaped by the
strength of the rule with respect to resisting the types of attacks one expects the system to be faced with. For example, Copeland is exceedingly strongin fact, perfectwith respect to the constructive control types studied here. In
contrast, plurality, Condorcet, and approval are not (Bartholdi et al., 1992; Hemaspaandra et al., 2007a), and we cant
speak to the issue of as yet unstudied systems. And as to what holds for other rules, we suspect that the dream-case
path would be to find broad results that in one stroke reveal the control-resistance patterns of whole classes of election
systems. For example, see Hemaspaandra and Hemaspaandra 2007, which does essentially that for manipulation of
scoring systems.
3. Procaccia et al. (2008) independently of our work in Faliszewski et al. 2007 used a similar technique in their work
regarding the complexity of achieving proportional representation.

281

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

control problem, namely control by partition of candidates with the ties-eliminate tie-handling rule
(see Section 2), we note that the proofs of Theorem 4.15 (which applies to  = 1 for this control
problem within Copeland ) and of Theorem 4.16 (which applies to all rational  with 0   < 1
for the same problem) differ substantially. Regarding constructive microbribery, the vulnerability
constructions for  = 0 (see Lemma 3.13) and  = 1 (see Lemma 3.15) significantly differ from
each other, and neither of them works for tie-rewarding values other than 0 and 1. The above
remarks notwithstanding, for most of our results we show that it is possible to obtain a unified
though due to this uniformity sometimes rather involvedconstruction that works for Copeland
for every rational  , 0    1.
1.4 Organization
This paper is organized as follows. In Section 2, we formalize the notion of elections and in particular of Copeland elections, we introduce some useful notation, and we formally define the control
and bribery problems we are interested in. In Section 3, we show that for each rational  , 0    1,
Copeland elections are fully resistant to bribery, both in the case of rational voters and in the case
of irrational voters. On the other hand, if one changes the bribery model to allow microbribes of
voters (a fine-grained approach to bribery, in which the more one changes a voters vote, the more
one has to pay the voter), we prove vulnerability for each rational  , 0    1, in the irrationalvoters destructive case and for some specific values of  in the irrational-voters constructive case. In
Sections 4.1 and 4.2, we present our results on procedural control for Copeland elections for each
rational  with 0    1. We will see that very broad resistance holds for the constructive-control
cases. Section 4.3 presents our results on fixed-parameter tractability of bounded-case control for
Copeland . Section 5 provides valid proofs for several control problems for Condorcet elections
(studied by Bartholdi et al., 1992) whose original proofs were invalid due to being at odds with the
model of elections used in Bartholdi et al. 1992. We conclude the paper with a brief summary in
Section 6 and by stating some open problems.
If every proof were included in this paper, it would be extremely long and difficult to read.
Nonetheless, it is of course important to make proofs available for our claims. We have handled this as follows. We have made available as Faliszewski, Hemaspaandra, Hemaspaandra, and
Rothe 2008b a full technical report version of this paper, with complete and detailed proofs of essentially every result. And in the current article, for proofs that would be repetitive or tedious relative
to other proofs that we do include here, we simply have not included those proofs here and have
instead included in their place a pointer to the detailed proof of the result in the full technical report
version.

2. Preliminaries
This section defines many of the notions we use in this paper, such as various election systems,
election problems, and hardness notions.
2.1 Elections: The Systems of Llull and Copeland
An election E = (C,V ) consists of a finite candidate set C = {c1 , . . . , cm } and a finite collection V of
voters, where each voter is represented (individually, except later when we discuss succinct inputs)

282

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

via his or her preferences over the candidates. An election system (or an election rule) is a rule that
determines the winner(s) of each given election, i.e., a mapping from pairs (C,V ) to subsets of C.
We consider two ways in which voters can express their preferences. In the rational case (our
default case), each voters preferences are represented as a linear order over the set C,4 i.e., each
voter vi has a preference list ci1 > ci2 >    > cim , with {i1 , i2 , . . . , im } = {1, 2, . . . , m}. In the irrational case, each voters preferences are represented as a preference table that for every unordered
pair of distinct candidates ci and c j in C indicates whether the voter prefers ci to c j (i.e., ci > c j ) or
prefers c j to ci (i.e., c j > ci ).
Some well-known election rules for the case of rational voters are plurality, Borda count, and
Condorcet. Plurality elects the candidate(s) that are ranked first by the largest number of voters.
Borda count elects the candidate(s) that receive the most points, where each voter vi gives each
candidate c j as many points as the number of candidates c j is preferred to with respect to vi s
preferences. A candidate ci is a Condorcet winner if for every other candidate c j it holds that ci
is preferred to c j by a majority of voters. Note that each election instance will have at most one
Condorcet winner.
In this paper, we introduce a parameterized version of Copelands (1951) election system, which
we denote by Copeland , where the parameter  is a rational number between 0 and 1 that specifies
how ties are rewarded in the head-to-head majority-rule contests between any two distinct candidates.
Definition 2.1 Let  , 0    1, be a rational number. In a Copeland election, for each head-tohead contest between two distinct candidates, if some candidate is preferred by a majority of voters
then he or she obtains one point and the other candidate obtains zero points, and if a tie occurs then
both candidates obtain  points. Let E = (C,V ) be an election. For each c  C, scoreE (c) is (by
definition) the sum of cs Copeland points in E. Every candidate c with maximum scoreE (c) (i.e.,
every candidate c satisfying (d  C)[scoreE (c)  scoreE (d)]) wins.
Let CopelandIrrational denote the same election system but with voters allowed to be irrational.
As mentioned earlier, in the literature the term Copeland elections is most often used for the
system Copeland0.5 (e.g., Saari and Merlin, 1996, Merlin and Saari, 1997, and a rescaled version
of Conitzer et al., 2007), but has occasionally been used for Copeland0 (e.g., Procaccia et al., 2007,
and Faliszewski et al., 2007, an early version of this paper). As mentioned earlier, the system
Copeland1 was proposed by Llull in the thirteenth century (see the literature pointers given in the
introduction) and so is called Llull voting.
We now define some notation to help in the discussion of Copeland elections. Informally put,
if E = (C,V ) is an election and if ci and c j are any two candidates in C then by vsE (ci , c j ) we mean
the surplus of votes that candidate ci has over c j . Formally, we define this notion as follows.
Definition 2.2 Let E = (C,V ) be an election and let ci and c j be two arbitrary candidates from C.
Define the relative vote-score of ci with respect to c j by

0
if ci = c j
vsE (ci , c j ) =
k{v  V | v prefers ci to c j }k  k{v  V | v prefers c j to ci }k otherwise.
4. In this paper, we take linear order to mean a strict total order. This is a common convention within voting theory,
see, e.g., the book Austen-Smith and Banks 2000. However, we mention that in the field of mathematics the term
linear order is typically taken to allow nonstrictness, i.e., to allow ties.

283

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

So, if ci defeats c j in a head-to-head contest in E then vsE (ci , c j ) > 0, if they are tied then
vsE (ci , c j ) = 0, and if c j defeats ci then vsE (ci , c j ) < 0. (Throughout this paper, defeats excludes
the possibility of a tie, i.e., defeats means (strictly) defeats. We will say ties-or-defeats when
we wish to allow a tie to suffice.) Clearly, vsE (ci , c j ) = vsE (c j , ci ). We often speak, in the plural,
of relative vote-scores when we mean a group of results of head-to-head contests between particular
candidates.
Let  , 0    1, be a rational number. Definition 2.1 introduced scoreE (c), the Copeland
score of candidate c in election E. Note that for each candidate ci  C,
scoreE (ci ) = k{c j  C | ci 6= c j and vsE (ci , c j ) > 0}k
+  k{c j  C | ci 6= c j and vsE (ci , c j ) = 0}k.
In particular, we have score0E (ci ) = k{c j  C | ci 6= c j and vsE (ci , c j ) > 0}k, and score1E (ci ) = k{c j 
C | ci 6= c j and vsE (ci , c j )  0}k. Note further that the highest possible Copeland score in any
election E = (C,V ) is kCk  1.
Recall that a candidate ci  C is a Copeland winner of E = (C,V ) if for all c j  C it holds
that scoreE (ci )  scoreE (c j ). (Clearly, some elections can have more than one Copeland winner.)
A candidate ci is a Condorcet winner of E if score0E (ci ) = kCk  1, that is, if ci defeats all other
candidates in head-to-head contests.
In many of our constructions to be presented in the upcoming proofs, we use the following
notation for rational voters.
Notation 2.3 Within every election we fix some arbitrary order over the candidates. Any occurrence
of a subset D of candidates in a preference list means the candidates from D are listed with respect


to that fixed order. Occurrences of D mean the same except that the candidates from D are listed in
the reverse order.
For example, if C = {a, b, c, d, e}, with the alphabetical order being used, and D = {a, c, e} then


b > D > d means b > a > c > e > d, and b > D > d means b > e > c > a > d.
2.2 Bribery and Control Problems
We now describe the computational problems that we study in this paper. Our problems come in two
flavors: constructive and destructive. In the constructive version the goal is to determine whether,
via the bribery or control action type under study, it is possible to make a given candidate a winner
of the election. In the destructive case the goal is to determine whether it is possible to prevent a
given candidate from being a winner of the election.
Let E be an election system. In our case, E will be either Copeland or CopelandIrrational , where
 , 0    1, is a rational number. The bribery problem for E with rational voters is defined as
follows (Faliszewski et al., 2006a).
Name: E -bribery and E -destructive-bribery.
Given: A set C of candidates, a collection V of voters specified via their preference lists over C, a
distinguished candidate p  C, and a nonnegative integer k.
Question (constructive): Is it possible to make p a winner of the E election resulting from (C,V )
by modifying the preference lists of at most k voters?
284

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

Question (destructive): Is it possible to ensure that p is not a winner of the E election resulting
from (C,V ) by modifying the preference lists of at most k voters?
The version of this problem for elections with irrational voters allowed is defined exactly like
the rational one, with the only difference being that voters are represented via preference tables
rather than preference lists, and the briber may completely change a voters preference table at unit
cost. At the end of the present section, Section 2.2, we will describe the variants based on seeking to
make p be (or to preclude p from being) a unique winner. Later in the paper we will study another
variant of bribery problemsa variant in which one is allowed to perform microbribes: bribes for
which the cost depends on each preference-table entry change, and the briber pays separately for
each such change.
Bribery problems seek to change the outcome of elections via modifying the reported preferences of some of the voters. In contrast, control problems seek to change the outcome of an election
by modifying the elections structure via adding/deleting/partitioning either candidates or voters.
When formally defining these control types, we use the following naming conventions for the corresponding control problems. The name of a control problem starts with the election system used
(when clear from context, it may be omitted), followed by CC for constructive control or by DC
for destructive control, followed by the acronym of the type of control: AC for adding (a limited
number of) candidates, ACu for adding (an unlimited number of) candidates, DC for deleting
candidates, PC for partition of candidates, RPC for run-off partition of candidates, AV for
adding voters, DV for deleting voters, and PV for partition of voters. All the partitioning
cases (PC, RPC, and PV) are two-stage elections, and we here use both tie-handling rules of Hemaspaandra et al. (2007a) for first-stage subelections in these two-stage elections. In particular, for all
the partitioning cases, the acronym PC, RPC, and PV, respectively, is followed by the acronym of
the tie-handling rule used in first-stage subelections, namely TP for ties promote (i.e., all winners
of first-stage subelections are promoted to the final round of the election) and TE for ties eliminate
(i.e., only unique winners of first-stage subelections are promoted to the final round of the election,
so if there is more than one winner in a given first-stage subelection or there is no winner in a given
first-stage subelection then that subelection does not move any of its candidates forward).
We now formally define our control problems. These definitions are due to Bartholdi et al.
(1992) for constructive control and to Hemaspaandra et al. (2007a) for destructive control.
Let E be an election system. Again, E will here be either Copeland or CopelandIrrational , where
 , 0    1, is a rational number. We describe our control problems as if they were for the case of
rational preferences, but the irrational cases are perfectly analogous, except for replacing preference
lists with preference tables.
C ONTROL VIA A DDING C ANDIDATES
We start with two versions of control via adding candidates. In the unlimited version the goal of the
election chair is to introduce candidates from a pool of spoiler candidates so as to make his or her
favorite candidate a winner of the election (in the constructive case) or prevent his or her despised
candidate from being a winner (in the destructive case). As suggested by the name of the problem,
in the unlimited version the chair can introduce any subset of the spoiler candidates (none, some, or
all are all legal options) into the election.
Name: E -CCACu and E -DCACu (control via adding an unlimited number of candidates).
285

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Given: Disjoint sets C and D of candidates, a collection V of voters specified via their preference
lists over the candidates in the set C  D, and a distinguished candidate p  C.
Question (E -CCACu ): Is there a subset E of D such that p is a winner of the E election with voters
V and candidates C  E?
Question (E -DCACu ): Is there a subset E of D such that p is not a winner of the E election with
voters V and candidates C  E?
The definition of E -CCACu was (using different notation) introduced by Bartholdi et al. (1992).
In contrast with the other control problems involving adding or deleting candidates or voters, in the
adding candidates problem Bartholdi, Tovey, and Trick did not introduce a nonnegative integer k
that bounds the number of candidates (from the set D) the chair is allowed to add. We feel this
asymmetry in their definitions is not well justified,5 and thus we define a with-change-parameter
version of the control-by-adding-candidates problems, which we denote by ACl (where the l
stands for the fact that part of the problem instance is a limit on the number of candidates that can
be added, in contrast with the model of Bartholdi et al., 1992, which we denote by ACu with the u
standing for the fact that the number of added candidates is unlimited, at least in the sense of not
being limited via a separately input integer). The with-parameter version is the long-studied case
for AV, DV, and DC, and we in this paper will use AC as being synonymous with ACl , and will thus
use the notation AC for the rest of this paper when speaking of ACl . We suggest this as a natural
regularization of the definitions and we hope this version will become the normal version of the
adding-candidates problem for further study. However, we caution the reader that in earlier papers
AC is used to mean ACu .
In the present paper, we will obtain results not just for ACl but also for the ACu case, in order
to allow comparisons between the results of this paper and those of earlier works.
Turning now to what we mean by AC (equivalently, ACl ), as per the above definition in E -CCAC
(i.e., E -CCACl ) we ask whether it is possible to make the distinguished candidate p a winner of
some E election obtained by adding at most k candidates from the spoiler candidate set D. (Note that
k is part of the input.) We define the destructive version, E -DCAC (i.e., E -DCACl ), analogously.
Name: E -CCAC and E -DCAC (control via adding a limited number of candidates).
Given: Disjoint sets C and D of candidates, a collection V of voters specified via their preference
lists over the candidates in the set C  D, a distinguished candidate p  C, and a nonnegative
integer k.
Question (E -CCAC): Is there a subset E of D such that kEk  k and p is a winner of the E election
with voters V and candidates C  E?
Question (E -DCAC): Is there a subset E of D such that kEk  k and p is not a winner of the E
election with voters V and candidates C  E?
5. Bartholdi et al. (1992) are aware of this asymmetry. They write: To a certain extent the exact formalization of
a problem is a matter of taste. [. . . ] we could equally well have formalized [the problem of control via adding
candidates] to be whether there are K or fewer candidates to be added [. . . ] It does not much matter for the problems
we discuss, since both versions are of the same complexity (Bartholdi et al., 1992). In contrast, the complexity of
the problems studied here crucially hinges on which formalization is used, and we thus define both versions formally.

286

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

C ONTROL VIA D ELETING C ANDIDATES
In constructive control via deleting candidates, the chair seeks to ensure that his or her favorite
candidate p is a winner of the election by suppressing at most k candidates. In the destructive variant
of this problem, the chairs goal is to block p from winning by suppressing at most k candidates other
than p.6
Name: E -CCDC and E -DCDC (control via deleting candidates).
Given: A set C of candidates, a collection V of voters represented via preference lists over C, a
distinguished candidate p  C, and a nonnegative integer k.
Question (E -CCDC): Is it possible to by deleting at most k candidates ensure that p is a winner of
the resulting E election?
Question (E -DCDC): Is it possible to by deleting at most k candidates other than p ensure that p
is not a winner of the resulting E election?
C ONTROL VIA PARTITION AND RUN -O FF PARTITION OF C ANDIDATES
Bartholdi et al. (1992) gave two types of control of elections via partition of candidates. In both
cases the candidate set C is partitioned into two groups, C1 and C2 (i.e., C1 C2 = C and C1 C2 = 0),
/
and the election is conducted in two stages. For control via run-off partition of candidates, the
elections first stage is conducted separately on each group of candidates, C1 and C2 , and the group
winners that survive the tie-handling rule compete against each other in the second stage. In control
via partition of candidates, the first-stage election is performed on the candidate set C1 and those of
that elections winners that survive the tie-handling rule compete against all candidates from C2 in
the second stage.
In the ties-promote (TP) model, all first-stage winners within a group are promoted to the final
round. In the ties-eliminate (TE) model, a first-stage winner within a group is promoted to the final
round if and only if he or she is the unique winner within that group.
Although these only loosely correspond to real-world settings, let us give a rough example regarding the case of run-off partition of candidates. Consider a department, with a powerful director,
that is trying to decide among a collection of alternatives. It is certainly plausible that the director might announce that she had divided the candidates into two groups, that the entire department
would vote separately among the candidates in each group, and that then only those candidates who
moved forward from those votes (under whatever tie-handling rule was being used, if there were
ties) would compete in the final election, in which the entire department would again vote. (How
6. A referee asked whether control by adding candidates, if redefined to require adding not at most a certain number
of candidates but instead at least a certain number of candidates, can cover the forthcoming notion (which is the
standard notion) of control by deleting (at most a certain number of) candidates. The answer is that that seems not to
be the case. Consider an election with thirty candidates in which we ask whether a certain constructive control goal
can be reached via deleting at most five candidates. Note that reframing this as a twenty-candidate election in which
one tries to reach some goal by adding at least five candidates from a ten-candidate spoiler set doesnt make sense,
as there is no one particular twenty-candidate election from which to start; there are far too many possibilities. The
referee similarly asked about representing addition of candidates by a new notion of deleting candidates that put a
lower bound on the number of deletions, but that attempt seems also to fail, in that case for the different reason that
in the deletion case one might delete not just what originally were spoiler candidates but one might delete candidates
from the core election of the addition case, and that is not allowed.

287

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

convincingly the director could do this would of course depend on the directors power and how
well the director could think up a justification for her partition of the candidates. Clearly some partitions may be easy to justify, e.g., Lets regarding whom to hire in our academic computer science
department first vote separately among the fresh-Ph.D. candidates and among the more senior hiring
candidates, and some may be harder to justify except as executive fiat.)
Name: E -CCRPC and E -DCRPC (control via run-off partition of candidates).
Given: A set C of candidates, a collection V of voters represented via preference lists over C, and
a distinguished candidate p  C.
Question (E -CCRPC): Is there a partition of C into C1 and C2 such that p is a winner of the twostage election where the winners of subelection (C1 ,V ) that survive the tie-handling rule
compete against the winners of subelection (C2 ,V ) that survive the tie-handling rule? Each
subelection (in both stages) is conducted using election system E .
Question (E -DCRPC): Is there a partition of C into C1 and C2 such that p is not a winner of the
two-stage election where the winners of subelection (C1 ,V ) that survive the tie-handling rule
compete against the winners of subelection (C2 ,V ) that survive the tie-handling rule? Each
subelection (in both stages) is conducted using election system E .
The above description defines four computational problems for a given election system E :
E -CCRPC-TE, E -CCRPC-TP, E -DCRPC-TE, and E -DCRPC-TP. Note that it is in concept possible in the TE case for all candidates, due to ties, to be eliminated in the first round here, in which
case the overall election would have no winner.
Name: E -CCPC and E -DCPC (control via partition of candidates).
Given: A set C of candidates, a collection V of voters represented via preference lists over C, and
a distinguished candidate p  C.
Question (E -CCPC): Is there a partition of C into C1 and C2 such that p is a winner of the two-stage
election where the winners of subelection (C1 ,V ) that survive the tie-handling rule compete
against all candidates in C2 ? Each subelection (in both stages) is conducted using election
system E .
Question (E -DCPC): Is there a partition of C into C1 and C2 such that p is not a winner of the
two-stage election where the winners of subelection (C1 ,V ) that survive the tie-handling rule
compete against all candidates in C2 ? Each subelection (in both stages) is conducted using
election system E .
This description defines four computational problems for a given election system E :
E -CCPC-TE, E -CCPC-TP, E -DCPC-TE, and E -DCPC-TP.
C ONTROL VIA A DDING VOTERS
In the scenario of control via adding voters, the chairs goal is to either ensure that p is a winner (in
the constructive case) or ensure that p is not a winner (in the destructive case) via causing up to k
288

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

additional voters to participate in the election. The chair can draw the voters to add to the election
from a prespecified collection of voters (with given preferences).
This can very loosely model such real-world situations as get-out-the-vote efforts. For example,
suppose a campaign has enough money and volunteers to drive up to one hundred from a set of a
thousand car-less elderly people to the polling place, and has to decide which ones to choose.
Name: E -CCAV and E -DCAV (control via adding voters).
Given: A set C of candidates, two disjoint collections of voters, V and W , represented via preference lists over C, a distinguished candidate p, and a nonnegative integer k.
Question (E -CCAV): Is there a subset Q, kQk  k, of voters in W such that the voters in V  Q
jointly elect p  C as a winner according to system E ?
Question (E -DCAV): Is there a subset Q, kQk  k, of voters in W such that the voters in V  Q do
not elect p as a winner according to system E ?
The reason we do not have an unlimited control notion here, or anywhere else except for
ACu , is that ACu is historically a special case. The seminal paper Bartholdi et al. 1992 defined all
addition/deletion problems in (only) the limited version, in which there is number k limiting the
additions/deletions, except that their paper, describing this as a matter of individual taste, defined
addition of candidates in (only) the unlimited version. We consider the limited versions of all the
addition/deletion problems by far the more natural, and so we study those, as did Bartholdi, Tovey,
and Trick in every case other than addition of candidates. However, to allow comparison with earlier
papers, we keep as a defined control type the case of ACu .
C ONTROL VIA D ELETING VOTERS
In the control via deleting voters case the chair seeks to either ensure that p is a winner (in the
constructive case) or prevent p from being a winner (in the destructive case) via blocking up to k
voters from participating in the election.
This very loosely models vote suppression. For example, consider the case where a given campaign can afford to send to the doors of at most k voters a smooth-talking operative who will so
demoralize them that they wont bother to vote.
Name: E -CCDV and E -DCDV (control via deleting voters).
Given: A set C of candidates, a collection V of voters represented via preference lists over C, a
distinguished candidate p  C, and a nonnegative integer k.
Question (E -CCDV): Is it possible to by deleting at most k voters ensure that p is a winner of the
resulting E election?
Question (E -DCDV): Is it possible to by deleting at most k voters ensure that p is not a winner of
the resulting E election?

289

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

C ONTROL VIA PARTITION OF VOTERS
In the case of control via partition of voters, the following two-stage election is performed. First,
the voter set V is partitioned into two subcommittees, V1 and V2 . The winners of election (C,V1 )
that survive the tie-handling rule compete against the winners of (C,V2 ) that survive the tie-handling
rule. Again, our tie-handling rules are TE and TP (ties-eliminate and ties-promote).
This control type is a bit harder than most others to imagine in the real world, but as a somewhat
contrived example, consider the following case. In a given organization, the director splits her
workers into two study groups (and let us say she can choose the partition as she likes, either because
she is a powerful director, or because she is a good enough manager to make up a justification for
any division) to each study a problem and to each propose what it thinks is the best alternative.
And then the entire organization comes together to vote among those alternatives chosen in the first
round (that survive the tie-handling rule in the case of ties).
Name: E -CCPV and E -DCPV (control via partition of voters).
Given: A set C of candidates, a collection V of voters represented via preference lists over C, and
a distinguished candidate p  C.
Question (E -CCPV): Is there a partition of V into V1 and V2 such that p is a winner of the twostage election where the winners of election (C,V1 ) that survive the tie-handling rule compete
against the winners of (C,V2 ) that survive the tie-handling rule? Each subelection (in both
stages) is conducted using election system E .
Question (E -DCPV): Is there a partition of V into V1 and V2 such that p is not a winner of the twostage election where the winners of election (C,V1 ) that survive the tie-handling rule compete
against the winners of (C,V2 ) that survive the tie-handling rule? Each subelection (in both
stages) is conducted using election system E .
U NIQUE W INNERS

AND I RRATIONALITY

Our bribery and control problems were each defined above only for rational voters and in the
nonunique-winner model, i.e., asking whether a given candidate can be made, or prevented from
being, a winner. Nonetheless, we have proven all our control results both for the case of nonunique
winners and (to be able to fairly compare them with existing control results, which are in the uniquewinner model) unique winners (a candidate is a unique winner if he or she is a winner and is the only
winner). Similarly, all our bribery results are proven both in the unique-winner model and (to be
able to fairly compare them with existing bribery results in the literature) in the nonunique-winner
model. In addition to the rational-voters case, we also study these problems for the case of voters
who are allowed to be irrational. As mentioned earlier, in the case of irrational voters, voters are
represented via preference tables rather than preference lists.
2.3 Graphs
An undirected graph G is a pair (V (G), E(G)), where V (G) is the set of vertices and E(G) is the
set of edges and each edge is an unordered pair of distinct vertices.7 A directed graph is defined
7. In this paper, the symbols E and V are generally reserved for elections and voters, except the just-introduced overloading of them to mean sets of edges and vertices in a given graph. The intended meaning of E and V will be clear
from the context, even when our proofs involve multiple elections and graphs.

290

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

analogously, except that the edges are represented as ordered pairs. For example, if u and v are
distinct vertices in an undirected graph G then G either has an edge e = {u, v} that connects u and v
or it doesnt. On the other hand, if G is a directed graph then G either has an edge e = (u, v) from
u to v, or an edge e = (v, u) from v to u, or both e and e , or neither e nor e .
For a directed graph G, the indegree of a vertex u  V (G) is the number of Gs edges that enter u
(i.e., the number of edges of the form (v, u) in E(G)). Similarly, the outdegree of u  V (G) is the
number of edges that leave u (i.e., the number of edges of the form (u, v) in E(G)).
2.4 NP-Complete Problems and Reductions
Without loss of generality, we assume that all problems that we consider are encoded in a natural,
efficient way over the alphabet  = {0, 1}. We use the standard notion of NP-completeness, defined
via polynomial-time many-one reductions. We say that a computational problem A polynomial-time
many-one reduces to a problem B if there exists a polynomial-time computable function f such that
(x   )[x  A  f (x)  B].
A problem is NP-hard if all members of NP polynomial-time many-one reduce to it. Thus, if
an NP-hard problem A polynomial-time many-one reduces to a problem B, then B is NP-hard as
well. A problem is NP-complete if it is NP-hard and is a member of NP. When clear from context
we will use reduce and reduction as shorthands for polynomial-time many-one reduce and
polynomial-time many-one reduction.
Our NP-hardness results typically follow via a reduction from either the exact-cover-by-3-sets
problem or from the vertex cover problem (see, e.g., Garey and Johnson, 1979). These are wellknown NP-complete problems, but we define them here for the sake of completeness.
Name: X3C (exact cover by 3-sets).
Given: A set B = {b1 , . . . , b3k }, k  1, and a family of sets S = {S1 , . . . , Sn } such that for each i,
1  i  n, it holds that Si  B and kSi k = 3.
Question: Is there a set A  {1, . . . , n}, kAk = k, such that

S

iA Si

= B?

The set A about which we ask in the above problem is called an exact cover of B. It is a cover
because every member of B belongs to some Si such that i  A, and it is exact because each
member of B belongs to exactly one Si such that i  A.
Whenever we consider instances of the X3C problem, we assume that they are well-formed, that
is, we assume that they follow the syntactic requirements stated in the above Given field (e.g., the
cardinality of the set B is indeed a multiple of three). We apply this convention of considering only
syntactically correct inputs to all other problems as well. Let A be some computational problem
and let x be an instance of A. When we consider an algorithm for A, and input x is malformed,
then we can immediately reject. When we are building a reduction from A to some problem B, then
whenever we hit a malformed input x we can output a fixed y not in B. (In our reductions B is never
 , so this is always possible.)
Copeland elections can often be considered in terms of appropriate graphs. This representation
is particularly useful when we face control problems that modify the structure of the candidate
set, since in this case operations on an election directly translate into suitable operations on the
291

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

corresponding graph. For candidate control problems, weinstead of using reductions from X3C
construct reductions from the vertex cover problem. A vertex cover of an undirected graph G is a
subset of Gs vertices such that each edge of G is adjacent to at least one vertex from that subset.
Name: VertexCover.
Given: An undirected graph G and a nonnegative integer k.
Question: Is there a set W such that W  V (G), kW k  k, and for every edge e  E(G) it holds
that e W 6= 0?
/
2.5 Resistance and Vulnerability
Not all election systems can be affected by each control type; if not, the system is said to be immune
to this type of control. For example, if a candidate c is not a Condorcet winner then it is impossible
to make him or her a Condorcet winner by adding candidates (see Bartholdi et al., 1992, and Hemaspaandra et al., 2007a, for more such immunity results). However, for Copeland elections it is easy
to see that for each type of control defined in Section 2.2 there is a scenario in which the outcome of
the election can indeed be changed via conducting the corresponding control action. If an election
system is not immune to some type of control (as witnessed by such a scenario), the election system
is said to be susceptible to that control type.
Proposition 2.4 For each rational number  , 0    1, Copeland is susceptible to each type of
control defined in Section 2.2.
We say that an election system (Copeland or CopelandIrrational , in our case) is resistant to a
particular attack (be it a type of control or of bribery) if the appropriate computational problem is
NP-hard and susceptibility holds.8 On the other hand, if the computational problem is in P and
susceptibility holds, then we say the system is vulnerable to this attack. Because of how our bribery
and control problems are defined, the vulnerability definition merely requires that there exist a
polynomial-time algorithm that determines whether a successful bribe or control action exists on a
given input. However, in every single one of our vulnerability proofs we will provide something
far stronger. We will provide a polynomial-time algorithm that actually finds a successful bribe or
control action on each input for which a successful bribe or control action exists, and on each input
where no successful bribe or control action exists will announce that fact.
The notions of resistance and vulnerability (and of immunity and susceptibility) for control
problems in election systems were introduced by Bartholdi et al. (1992), and we here follow the
definition alteration of Hemaspaandra et al. (2007b) of resistance from NP-complete to NPhard, as that change is compelling (because under the old definition, NP-completeness, things could
8. It is true that for some unnatural election systems immunity to bribery holds, e.g., the election system Every candidate is a winner is immune to all types of bribery. However, our Copeland -type systems are all susceptible to all
the bribery types we look at in this paper, so we wont further explicitly discuss or state susceptibility for the bribery
cases.
A referee asked whether the definition of resistance could be equivalently stated as simply requiring the appropriate computational problem to be NP-hard. That seems not to yield the same notion, both because P 6= NP is not yet
a known result, and so one doesnt know that NP-hard problems cannot possibly be in P, and more subtly because susceptibility is defined in terms of changing outcomes while the corresponding control problems NP-hardness (which
in part determines its resistance) is related to what the outcome is (regardless of what it started as).

292

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

actually become nonresistant by being too hard, which is not natural). However, for all resistance
claims in this paper NP-membership is clear, and so NP-completeness in fact does hold.

3. Bribery
In this section we present our results on the complexity of bribery for the Copeland election systems, where  is a rational number with 0    1. Our main result, which will be presented in
Section 3.1, is that each such system is resistant to bribery, regardless of voters rationality and of
our mode of operation (constructive versus destructive). In Section 3.2, we will provide vulnerability results for Llull and Copeland0 with respect to microbribery.
3.1 Resistance to Bribery
Theorem 3.1 For each rational  , 0    1, Copeland and CopelandIrrational are resistant to both
constructive and destructive bribery, in both the nonunique-winner model and the unique-winner
model.
We prove Theorem 3.1 via Theorems 3.2, 3.4, and 3.5 below. Our proofs employ an approach
that we call the UV technique. For the constructive cases, this technique proceeds by constructing
bribery instances where the only briberies that could possibly ensure that our favorite candidate p
is a winner involve only voters who rank a group of special candidates (often the group will contain
exactly two candidates, u and v) above p. The remaining voters, the bystanders so to speak, can be
used to create appropriate padding and structure within the election. The destructive cases follow
via a cute observation regarding the dynamics of our constructive cases.
The remainder of this section is devoted to proving Theorem 3.1. We start with the case of
rational voters in Theorems 3.2 and 3.4 below and then argue that the analogous results for the case
of irrational voters follow via, essentially, the same proof.
Theorem 3.2 For each rational number  , 0    1, Copeland is resistant to constructive
bribery in the unique-winner model and to destructive bribery in the nonunique-winner model.
Proof. Fix an arbitrary rational number  with 0    1. Our proof provides reductions from
the X3C problem to, respectively, the unique-winner variant of constructive bribery and to the
nonunique-winner variant of destructive bribery. Our reductions will differ regarding only the specification of the goal (i.e., regarding which candidate we attempt to make a unique winner or which
candidate we prevent from being a winner) and thus we describe them jointly as, essentially, a single
reduction.
Our reduction will produce an instance of an appropriate bribery problem with an odd number
of voters, and so we will never have ties in head-to-head contests. Thus our proof works regardless
of which rational number  with 0    1 is chosen.
Let (B, S ) be an instance of X3C, where B = {b1 , b2 , . . . , b3k }, S is a collection {S1 , S2 , . . . , Sn }
S
of three-element subsets of B with nj=1 S j = B, and k  1. If our input does not meet these conditions then we output a fixed instance of our bribery problem having a negative answer.
Construct a Copeland election E = (C,V ) as follows. The candidate set C is {u, v, p}  B,
where none of u, v, and p is in B. The voter set V contains 2n + 4k + 1 voters of the following types.

293

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

1. For each Si , we introduce one voter of type (i) and one voter of type (ii):
(i) u > v > Si > p > B  Si ,



(ii) B  Si > p > u > v > Si .
2. We introduce k voters for each of the types (iii)-1, (iii)-2, (iv)-1, and (iv)-2:
(iii)-1
(iii)-2
(iv)-1
(iv)-2

u > v > p > B,
v > u > p > B,


u > B > p > v,


v > B > p > u.

3. We introduce a single type (v) voter:
(v) B > p > u > v.
We have the following relative vote-scores:
1. vsE (u, v) = 2n + 1  2k + 1, where the inequality follows from our assumption
(which implies n  kBk/3 = k),

Sn

j=1 S j

=B

2. vsE (u, p) = vsE (v, p) = 2k  1,
3. for each i  {1, 2, . . . , 3k}, vsE (u, bi ) = vsE (v, bi )  2k + 1,
4. for each i  {1, 2, . . . , 3k}, vsE (bi , p) = 1, and
5. for each i, j  {1, 2, . . . , 3k} with i 6= j, |vsE (bi , b j )| = 1.
For example, to see that vsE (u, bi )  2k + 1 for each i  {1, 2, . . . , 3k}, note that each bi is in
S
at least one S j because of nj=1 S j = B, so the voters of types (i) and (ii) give u an advantage of at
least two votes over bi . Furthermore, the voters of types (iii)-1, (iii)-2, (iv)-1, and (iv)-2 give u an
advantage of 2k additional votes over each bi , and the single type (v) voter gives each bi a one-vote
advantage over u. Summing up, we obtain vsE (u, bi )  2 + 2k  1 = 2k + 1. The other relative
vote-scores are similarly easy to verify.
These relative vote-scores yield the following Copeland scores or upper bounds on such scores:
1. scoreE (u) = 3k + 2,
2. scoreE (v) = 3k + 1,
3. for each i  {1, 2, . . . , 3k}, scoreE (bi )  3k, and
4. scoreE (p) = 0.
To prove our theorem, we need the following claim.
Claim 3.3 The following three statements are equivalent:
1. (B, S )  X3C.
294

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

2. Candidate u can be prevented from winning via bribing at most k voters of E.
3. Candidate p can be made a unique winner via bribing at most k voters of E.
Proof of Claim 3.3. (1) implies (2): It is easy to see that if (B, S )  X3C then there is a bribe
involving k or fewer voters that prevents u from being a winner: It is enough to bribe those type (i)
voters that correspond to a cover of size k to report p as their top choice (while not changing
anything else in their preference lists): p > u > v > Si > B  Si . Call the resulting election E  . In E 
the following relative vote-scores change: vsE  (p, u) = vsE  (p, v) = n + k  (n  k)  2k + 1 = 1 and
vsE  (p, bi )  1 for each i  {1, 2, . . . , 3k}, while all other relative vote-scores remain unchanged.
Thus scoreE  (p) = 3k + 2, scoreE  (u) = 3k + 1, scoreE  (v) = 3k, and scoreE  (bi ) < 3k for each
i  {1, 2, . . . , 3k}, so p defeats all other candidates and is the unique winner. In particular, this bribe
(of at most k voters in E) ensures that u is not a winner.
(2) implies (3): Suppose that there is a bribe involving k or fewer voters that prevents u from
being a winner. Note that u defeats everyone except p by more than 2k votes in E. This means that
via bribery of at most k voters us score can decrease by at most one. Thus, to prevent u from being
a winner via such a bribery, we need to ensure that u receives a Copeland score of 3k + 1 and some
candidate other than u gets a Copeland score of 3k + 2, that is, that candidate defeats everyone.
Neither v nor any of the bi s can possibly obtain a Copeland score of 3k + 2 via such a bribery,
since bribery of at most k voters can affect only head-to-head contests where the relative vote-scores
of the participants are at most 2k. Thus, via such a bribery, u can be prevented from winning only if
p can be made a (in fact, the unique) winner of our election.
(3) implies (1): Let W be a set of at most k voters whose bribery ensures that p is a unique
winner of our election. Thus we know that kW k = k and that W contains only voters who rank
both u and v above p (as otherwise p would not defeat both u and v), which is the case only for
voters of types (i), (iii)-1, and (iii)-2. Furthermore, a bribery that makes p the unique winner has to
ensure that p defeats all members of B; note that the type (iii)-1 and (iii)-2 voters in E already rank
p above all of B. Thus, via a simple counting argument, W must contain exactly k type (i) voters
that correspond to a size-k cover of B.
 Claim 3.3
Since our reduction is computable in polynomial time, Claim 3.3 completes the proof of
Theorem 3.2.

Theorem 3.4 For each rational  , 0    1, Copeland is resistant to constructive bribery in the
nonunique-winner model and to destructive bribery in the unique-winner model.
The proof of Theorem 3.4, which follows the same general structure as the proof of
Theorem 3.2,9 for reasons of space and nonrepetitiveness is not included here but can be found
in the full TR version (Faliszewski et al., 2008b).
9. Since the proof of Theorem 3.4 is slightly more involved, let us briefly mention its key differences from the proof of
Theorem 3.2. Starting from an X3C instance (B, S ) with kBk = 3k, we in this case construct an election E = (C,V )
with two more candidates (i.e., C = {p, s,t, u, v}  B) and with V having, in addition to the voter types similar to
those in the proof of Theorem 3.2, 20k normalizing voters of eight subtypes. The unique winner of E is s, and the
only candidate who is able to prevent s from being the unique winner via at most k voters being bribed is p. The
construction ensures that (B, S )  X3C exactly if at most k voters can be bribed such that p and s tie for winner,
which simultaneously handles the nonunique-winner constructive case and the unique-winner destructive case.

295

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

The proofs of the above theorems have an interesting feature. When we discuss bribery, we
never rely on the fact that the voters are rational. Thus we can allow the voters to be irrational and
form CopelandIrrational -bribery and CopelandIrrational -destructive-bribery instances simply by deriving the voters preference tables from the voters preference lists given in the above proofs. It is
easy to see that the proofs remain valid after this change; in the proofs we assume that each bribed
voter, after the bribery, prefers p to all other candidates, but we do not make any further assumptions
(and, in particular, we do not use linearity of the preferences). Thus we have the following corollary
to the proofs of Theorems 3.2 and 3.4.
Theorem 3.5 For each rational number  , 0    1, CopelandIrrational is resistant to both constructive bribery and destructive bribery, in both the nonunique-winner model and the uniquewinner model.
Theorems 3.2, 3.4, and Theorem 3.5 together constitute a proof of Theorem 3.1 and establish
that for each rational  , 0    1, Copeland and CopelandIrrational possess broadessentially
perfectresistance to bribery regardless of whether we are interested in constructive or destructive
results. However, the next section shows that this perfect picture is, in fact, only near-perfect when
we consider microbribes, which dont allow changing the complete preferences of voters at once but
rather change the results of head-to-head contests between candidates in the voters preferences. We
will show that there is an efficient way of finding optimal microbriberies for the case of irrational
voters in Copeland elections.
3.2 Vulnerability to Microbribery for Irrational Voters
In this section we explore the problems related to microbribery of irrational voters. In standard
bribery problems, which were considered in Section 3.1, we ask whether it is possible to ensure that
a designated candidate p is a winner (or, in the destructive case, to ensure that p is not a winner)
via modifying the preference tables of at most k voters. That is, we can at unit cost completely
redefine the preference table of each voter bribed. So in this model, we pay for a service (namely,
the modification of the reported preference table) and we pay for it in bulk (when we buy a voter,
we have secured his or her total obedience). However, sometimes it may be far more reasonable
to adopt a more local approach in which we have to pay separately for each preference-table entry
flipto pay more the more we alter a vote.
Throughout the remainder of this section we will use the term microbribe to refer to flipping
an entry in a preference table, and we will use the term microbribery to refer to bribing possibly
irrational voters via microbribes. Recall that by irrational voters we simply mean that they are
allowed to have, but not that they must have, irrational preferences.
For the study of microbribery, we consider irrational voters to clearly be the natural model to
study. After all, one is changing (and measuring the overall change in terms of the number of
changes in) pairwise preferences, and such changes can easily move one from a rational preference
to an irrational preference. (We mention in passing that one could define versions of this problem
for the case of rational voters in various ways, e.g., allowing only changes that stay on rational
profiles. But that seems a far less natural model to use for the microbribery problem.)
For each rational  , 0    1, we define the following two problems.
Name: CopelandIrrational -microbribery and CopelandIrrational -destructive-microbribery.
296

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

Given: A set C of candidates, a collection V of voters specified via their preference tables over C,
a distinguished candidate p  C, and a nonnegative integer k.
Question (constructive): Is it possible, by flipping at most k entries in the preference tables of
voters in V , to ensure that p is a winner of the resulting election?
Question (destructive): Is it possible, by flipping at most k entries in the preference tables of voters
in V , to guarantee that p is not a winner of the resulting election?
We can flip multiple entries in the preference table of the same voter, but we have to pay separately for each flip. The microbribery problems for CopelandIrrational are very similar in flavor to
the so-called bribery problems for approval voting that were studied by Faliszewski et al. (2006a),
where unit cost for flipping approvals or disapprovals of voters are paid. However, the proofs for
CopelandIrrational seem to be much more involved than their counterparts for approval voting. The
reason is that CopelandIrrational elections allow for very subtle and complicated interactions between
the candidates scores.
Before we proceed with our results, let us define some notation that will be useful throughout
this section. Let E be an election with candidate set C = {c1 , c2 , . . . , cm } and voter collection V =
{v1 , v2 , . . . , vn }. We define two functions, wincostE and tiecostE , that describe the costs of ensuring
a victory or a tie of a given candidate in a particular head-to-head contest.
Definition 3.6 Let E = (C,V ) be an election and let ci and c j be two distinct candidates in C.
1. By wincostE (ci , c j ) we mean the minimum number of microbribes that ensure that ci defeats
c j in their head-to-head contest. If ci already wins this contest then wincostE (ci , c j ) = 0.
2. By tiecostE (ci , c j ) we mean the minimum number of microbribes that ensure that ci ties with
c j in their head-to-head contest, or  if E has an odd number of voters and thus ties are
impossible.
Our first result regarding microbribery is that destructive microbribery is easy for
CopelandIrrational . Since this is the papers first vulnerability proof, we take this opportunity to
remind the reader (recall Section 2.5) that although the definition of vulnerability requires only that
there be a polynomial-time algorithm to determine whether a successful action (in the present case, a
destructive microbribery) exists, we will in each vulnerability proof provide something far stronger,
namely a polynomial-time algorithm that both determines whether a successful action exists and
that, when so, finds a successful action (e.g., for our flow algorithms later on, the successful action
will be implicit in the flow computed).
Theorem 3.7 For each rational  , 0    1, CopelandIrrational is vulnerable to destructive microbribery in both the nonunique-winner model and the unique-winner model.
Proof.
Fix an arbitrary rational number  with 0    1. We give an algorithm for
CopelandIrrational , for destructive microbribery in the nonunique-winner model. (We omit the analogous algorithm for the unique-winner case.)
Let E = (C,V ) be the input election where C = {p, c1 , c2 , . . . , cm } and V = {v1 , v2 , . . . , vn },
and let k be the number of microbribes that we are allowed to make. We define the predicate
297

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

M(E, p, ci , k) to be true if and only if there is a microbribery of cost at most k that ensures that ci s
score is higher than that of p. Our algorithm computes M(E, p, ci , k) for each ci  C and accepts if
and only if it is true for at least one of them. We now describe how to compute M(E, p, ci , k).10
By applying appropriate minimum-cost microbriberies to E, we obtain elections E1 , E2 , and E3
that are identical to E except that
1. in E1 , p defeats ci in their head-to-head contest,
2. in E2 , p loses to ci in their head-to-head contest, and
3. in E3 , p ties ci in their head-to-head contest (we disregard E3 if the number of voters is odd
and thus ties are impossible).
Let k1 , k2 , and k3 be the minimum costs of microbriberies that transform E to E1 , E to E2 , and E to
E3 , respectively. Such microbriberies involve only the head-to-head contest between p and ci . We
define the predicate M  (E  , p, ci , k ), where E   {E1 , E2 , E3 } and where k is an integer, to be true if
and only if there is a microbribery of cost at most k that does not involve the head-to-head contest
between p and ci but that ensures that ci s CopelandIrrational score is higher than ps. It is easy to see
that

M(E, p, ci , k)  M  (E1 , p, ci , k  k1 )  M  (E2 , p, ci , k  k2 )  M  (E3 , p, ci , k  k3 ) .

Thus it is enough to focus on the problem of computing M  (E  , p, ci , k ).
Let (E  , k ) be one of (E1 , k  k1 ), (E2 , k  k2 ), and (E3 , k  k3 ). Define promoteE  (ci , w , w ,t),
where ci  C is a candidate and w , w , and t are nonnegative integers, to be the minimum cost of a
microbribery that, when applied to E  , increases ci s CopelandIrrational score by w + (1   )w +  t
via ensuring that
1. ci wins an additional w head-to-head contests against candidates in C  {p} that used to
defeat ci originally,
2. ci wins an additional w head-to-head contests against candidates in C  {p} with whom ci
used to tie originally, and
3. ci ties an additional t head-to-head contests with candidates in C  {p} that used to defeat ci
originally.

If such a microbribery does not exist then we set promoteE  (ci , w , w ,t) to be . It is an easy
exercise to see that promoteE  is computable in polynomial time by a simple greedy algorithm.
We define demoteE  (ci ,  ,  ,t) to be the minimum cost of a microbribery that, when applied to
election E  , decreases ps score by  +   + (1   )t via ensuring that
1. p loses an additional  head-to-head contests to candidates in C  {ci } whom p used to defeat
originally,
2. p loses an additional  head-to-head contests to candidates in C  {ci } with whom p used to
tie originally, and
10. We stress that we have optimized our algorithm for simplicity rather than for performance.

298

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

3. p ties an additional t head-to-head contests with candidates in C  {ci } whom p used to defeat
originally.
If such a microbribery does not exist then we set demoteE  (ci ,  ,  ,t) to be . Note that demoteE 
can be computed in polynomial time using an algorithm similar to that for promoteE  .
Naturally, the microbriberies used implicitly within promoteE  (ci , w , w ,t  ), within
demoteE  (ci ,  ,  ,t  ), and within transforming E to E  are disjoint, i.e., they never involve
the same pair of candidates. Thus M  (E  , p, ci , k ) is true if and only if there exist integers
w , w ,  ,  ,t  ,t   {0, 1, . . . , m} such that
scoreE  (ci ) + (w +  + (1   )(t  + w ) +  (t  +  ))  scoreE  (p) > 0
and
promoteE  (ci , w , w ,t  ) + demoteE  (ci ,  ,  ,t  )  k.
There are only polynomially many combinations of such w , w ,  ,  ,t  , and t  , and we can try them
all. Thus we have given a polynomial-time algorithm for M  (E  , p, ci , k ). Via the observations given
at the beginning of our proof this implies that M(E, p, ci , k) is computable in polynomial time and
the proof is complete.

The above destructive-case algorithm and approach is fairly straightforward; in the destructive
case we do not need to worry about any side effects of promoting c and demoting p. The constructive
case is more complicated, but we still are able to obtain polynomial-time algorithms via a fairly
involved use of flow networks to model how particular points shift between candidates. In the
remainder of this section we restrict ourselves to the values   {0, 1} or settings where the number
of voters is odd and so ties never happen. We remind the reader that Copeland1 and Copeland1Irrational ,
respectively, refer to Llull voting.
A flow network is a network of nodes with directed edges through which we want to transport
some amount of flow from the source to the sink (these are two designated nodes). Each edge e
can carry up to c(e) units of flow, and transporting each unit of flow through e costs a(e). In the
min-cost-flow problem we have a target flow value F, and the goal is to find a way of transporting F
units of flow from the source to the sink, while minimizing the cost. (If there is no way of achieving
target flow F, the cost in effect is infinite.)
We now define the notions related to flow networks more formally. Let N = {0, 1, 2, . . .} and
Z = {. . . , 2, 1, 0, 1, 2, . . .}.
Definition 3.8
1. A flow network is a quintuple (K, s,t, c, a), where K is a set of nodes that
includes the source s and the sink t, c : K 2  N is the capacity function, and a : K 2  N is
the cost function. We assume that c(u, u) = a(u, u) = 0 for each node u  K, and that at most
one of c(u, v) and c(v, u) is nonzero for each pair of distinct nodes u, v  K. We also assume
that if c(u, v) = 0 then a(u, v) = 0 as well.
2. Given a flow network (K, s,t, c, a), a flow is a function f : K 2  Z that satisfies the following
conditions:
(a) For each u, v  K, we have f (u, v)  c(u, v), i.e., capacities limit the flow.

299

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

(b) For each u, v  K, we have f (u, v) =  f (v, u).11
(c) For each u  K  {s,t}, we have vK f (u, v) = 0, i.e., the flow is conserved in all nodes
except the source and the sink.
3. The value of flow f is:
flowvalue( f ) =

 f (s, v).

vK

The particular flow network we have in mind will always be clear from the context and so
we will not indicate it explicitly (we will not write it explicitly as a subscript to the function flowvalue).
4. The cost of flow f is defined as:
flowcost( f ) =



a(u, v) f (u, v).

u,vK

That is, we pay the price a(u, v) for each unit of flow that passes from node u to node v.
Given a flow network (K, s,t, c, a) we will often use the term edges to refer to pairs of distinct
nodes (u, v)  K 2 for which c(u, v) > 0.
Below we define the min-cost-flow problem, which is well known from the literature. The
definition we employ here is not the most general one but will suffice for our needs. (Readers
seeking a broader discussion of the problem may wish to see, for example, the monograph Ahuja,
Magnanti, and Orlin, 1993.)
Definition 3.9 We define the min-cost-flow problem as follows: Given a flow network (K, s,t, c, a)
and a target flow value F, find a flow f that has value F (if one exists) and has minimum cost among
all such flows, or otherwise indicate that no such flow f exists.
The min-cost-flow problem has a polynomial-time algorithm.12 There is a large body of work
devoted to flow problems and we will not even attempt to provide a complete list of references
here. Instead, we again point the reader to the excellent monograph Ahuja et al. 1993, which
provides descriptions of polynomial-time algorithms, theoretical analysis, and numerous references
to previous work on flow-related problems. We also mention that the issue of flows is so prevalent in
the study of algorithms that the textbook Cormen, Leiserson, Rivest, and Stein 2001, on its page 787,
contains an exposition of the min-cost-flow problem.
Coming back to the study of constructive microbribery for Llull and Copeland0 , with irrational
voters allowed, we now present the following result.
Theorem 3.10 For   {0, 1}, CopelandIrrational is vulnerable to constructive microbribery, in both
the nonunique-winner model and the unique-winner model.
11. Note that each flow is fully defined via its nonnegative values. Whenever we speak of a flow (e.g., when defining
some particular flows) we will just speak of its nonnegative part.
12. The min-cost-flow problem is often defined in terms of capacity and cost functions that are not necessarily limited
to nonnegative integer values and so the corresponding flows are not restricted to integer values either. However,
crucially for us, it is known that if the capacity and cost functions have integral values (as we have assumed) then
there exist optimal solutions to the min-cost-flow problem that use only integer-valued flows and that can be found in
polynomial time.

300

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

Edge
e = (s, ci ),
where ci  C
e = (ci , c j ),
where ci , c j  C and vsE (ci , c j ) > 0
e = (c0 ,t)
e = (ci ,t),
where i > 0 and ci  C
every other edge e

Parameters
c(e) = scoreE (ci )
a(e) = 0
c(e) = 1
a(e) = wincostE (c j , ci )
c(e) = T
a(e) = 0
c(e) = T
a(e) = B
c(e) = 0
a(e) = 0

Figure 1: Edge capacities and costs for min-cost-flow instance I(T ), built from election E.
We prove Theorem 3.10 via Lemmas 3.11 through 3.16 below, which cover three cases: (a) an
odd number of voters, where all CopelandIrrational elections with 0    1 are identical due to the
lack of ties, (b) Copeland1Irrational with an even number of voters, and (c) Copeland0Irrational with an
even number of voters. These lemmas only discuss the nonunique-winner model but in each case it
is easy to see how to change the algorithms and proofs to make them work for the unique-winner
model.
Lemma 3.11 For each rational  with 0    1, there is a polynomial-time algorithm that solves
the constructive microbribery problem for CopelandIrrational elections with an odd number of voters
(in the nonunique-winner model).
Proof. Our input is a nonnegative integer k (the budget) and an election E = (C,V ), where the
candidate set C is {c0 , c1 , . . . , cm }, the number of voters is odd, and p = c0 is the candidate whose
victory we want to ensure via at most k microbribes. Note that we interchangeably use p and c0 to
refer to the same candidate, since it is sometimes convenient to be able to speak of p and all other
candidates uniformly. As the number of voters is odd, ties never occur. Thus any candidate ci has
the same CopelandIrrational score for each rational value of  , 0    1. Fix an arbitrary such  .
We give a polynomial-time algorithm for the constructive microbribery problem. A high-level
overview is that we try to find a threshold value T such that there is a microbribery of cost at most
k that transforms E into E  such that (a) p has scoreE  exactly T , and (b) every other candidate has
scoreE  at most T .
Let B be a number that is greater than the cost of any possible microbribery within E (e.g.,
B = kV k  kCk2 + 1). For each possible threshold T , we consider a min-cost-flow instance I(T ) with
node set K = C  {s,t}, where s is the source and t is the sink, the edge capacities and costs are
specified in Figure 1, and the target flow value is
F=

 scoreE (ci ) =

ci C

301

kCk(kCk  1)
.
2

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Voter 1 :
Voter 2 :
Voter 3 :

vsE (ci , c j )
c0
c1
c2
c3

c0 > c1 > c2 > c3
c3 > c2 > c1 > c0
c2 > c0 > c3 > c1

c0
0
1
1
1

c1
1
0
1
1

c2
1
1
0
1

c3
1
1
1
0

Figure 2: Sample election E for Example 3.12 in the proof of Lemma 3.11.

(2, 0)
(0, 0)
s

c0

(T, 0)

(1, 1)
(1, 1)

(1, 1)
c1

(T, 49)
(1, 1)

(3, 0)

t
(T, 49)
c2

(1, 1)
(1, 0)

(1, 1)
c3

(T, 49)

Figure 3: Flow network I(T ) corresponding to the instance (E, c0 , k) of Example 3.12.
Example 3.12 For illustration, consider the following example. Suppose the given election E has
four candidates and three voters, and the preference tables of the voters (who each happen to be
rational in this example) can be obtained from their preference orders that are shown in Figure 2,
which also gives the corresponding values of vsE (ci , c j ) for each pair of candidates. Thus we have
scoreE (c0 ) = 2, scoreE (c1 ) = 0, scoreE (c2 ) = 3, and scoreE (c3 ) = 1. Suppose further that we are
allowed to perform one microbribe, so k = 1. Clearly, one microbribe that changes the preference
of the third voter from c2 > c0 to c0 > c2 will flip the outcome of their head-to-head contest from c2
winning to c0 winning, which is enough to reach our goal of making c0 win the election, and this is
of course the cheapest possible successful microbribery. Finally, note that in this example we have
B = 49.
For each threshold T with 0  T  3, the flow network I(T ) corresponding to this instance
(E, c0 , k) of the constructive microbribery problem is shown in Figure 3, and we have a target flow
value of F = 6. Every edge e in this flow network is labeled by the pair (c(e), a(e)) of numbers that
give the capacity and the cost of edge e, respectively.
To continue the proof of Lemma 3.11, note that with an odd number of voters, constructive
microbribery in CopelandIrrational simply requires us to choose for which pairs of distinct candidates
we want to flip the outcome of their head-to-head contest in order to ensure ps victory. Thus it
is sufficient to represent a microbribery M as a collection of pairs (ci , c j ) of distinct candidates for
whom we need to flip the result of their head-to-head contest from ci winning to c j winning. Clearly,
302

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

given such a collection M, the cheapest way to implement it costs



wincostE (c j , ci ).

(ci ,c j )M

A crucial observation for our algorithm is that we can directly translate flows to microbriberies
using the following interpretation. Let f be a flow (as per Definition 3.8 with all edge flows being integers) of value F within instance I(T ). The units of flow that travel through the network correspond
to CopelandIrrational points. For each ci  C, we interpret the amount of flow that goes directly from
s to ci as the number of CopelandIrrational points that ci has before any microbribery is attempted,13
and the amount of flow that goes directly from ci to t as the number of CopelandIrrational points that
ci has after the microbribery (defined by the flow). The units of flow that travel between distinct ci s
(i.e., through edges of the form (ci , c j ), i 6= j) correspond to the microbribes exerted: A unit of flow
traveling from node ci to c j corresponds to changing the result of the head-to-head contest between
ci and c j from ci winning to c j winning. In this case, the CopelandIrrational point moves from ci to
c j and the cost of the flow increases by a(ci , c j ) = wincost(c j , ci ), exactly the minimum cost of a
microbribery that flips this contests result. Let M f be the microbribery defined, as just described,
by flow f . It is easy to see that
flowcost( f ) = B  (F  f (c0 ,t)) +



wincostE (c j , ci ).

(ci ,c j )M f

Thus we can easily extract the cost of microbribery M f from the cost of flow f .
Our algorithm crucially depends on this correspondence between flows and microbriberies.
(Also, in the proofs of Lemmas 3.14 and 3.16 that cover the case of an even number of voters
we simply show how to modify the instances I(T ) to handle ties, and we show correspondences
between the new networks and microbriberies; the rest of these proofs is the same as here.)
Note that for small values of T no flow of value F exists for I(T ). The reason for this is that
the edges coming into the sink t might not have enough capacity so as to hold a flow of value F. In
such a situation it is impossible to guarantee that every candidate gets at most T points; there are
too many CopelandIrrational points to distribute.
Figure 4 gives our algorithm for constructive microbribery in CopelandIrrational . This algorithm
runs in polynomial time since, as we have already mentioned, the min-cost-flow problem is solvable
in polynomial time.
Let us now prove that this algorithm is correct. We have presented above how a flow f of value
F within the flow network I(T ) (with 0  T  F) defines a microbribery. Based on this, it is clear
that if our algorithm accepts then there is a microbribery of cost at most k that ensures ps victory.
On the other hand, suppose now that there exists a microbribery of cost at most k that ensures
ps victory in the election. We will show that our algorithm accepts in this case.
Let M be a minimum-cost bribery (of cost at most k) that ensures ps victory. As pointed out
above, M can be represented as a collection of pairs (ci , c j ) of distinct candidates for whom we flip
the result of the head-to-head contest from ci winning to c j winning. The cost of M is



wincostE (c j , ci ).

(ci ,c j )M

13. Note that for each ci  C any flow of value F within I(T ) needs to send exactly scoreE (ci ) units from s to ci .

303

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

procedure CopelandIrrational -odd-microbribery(E = (C,V ), k, p)
begin
if p is a winner of E then accept;
;
F = ci C scoreE (ci ) = kCk(kCk1)
2
for T = 0 to kCk  1 do
begin
build an instance I(T ) of min-cost-flow;
if I(T ) has no flow of value F then
restart the for loop with the next value of T ;
f = a minimum-cost flow for I(T );
if f (c0 ,t) < T then restart the loop;
 = flowcost( f )  B  (F  T );
if   k then accept;
end;
reject;
end

Figure 4: The constructive microbribery algorithm for CopelandIrrational elections with an odd number of voters.

Since applying microbribery M ensures that p is a winner, we have that each candidate among
c1 , c2 , . . . , cm has at most as many CopelandIrrational points as p does. Let E  be the election that
results from E after applying microbribery M to E (i.e., after flipping the results of the contests
specified by M in an optimal way, as given by wincostE ). Let T  be scoreE  (p), ps CopelandIrrational
score after implementing M. Clearly, 0  T   kCk  1.
Consider instance I(T  ) and let fM be the flow that corresponds to the microbribery M. In this
flow each edge of the form (s, ci ) carries flow of its maximum capacity, scoreE (ci ), each edge of
the form (ci , c j ) carries one unit of flow exactly if e is listed in M and carries zero units of flow
otherwise, and each edge of the form (ci ,t) carries scoreE  (ci ) units of flow. It is easy to see that
this is a legal flow. The cost of fM is
flowcost( fM ) = B  (F  T  ) +



wincostE (c j , ci ).

(ci ,c j )M

After applying M, p gets T  CopelandIrrational points that travel to the sink t via edge (c0 ,t) with cost
a(c0 ,t) = 0, and all the remaining F  T  points travel via edges (ci ,t), i  {1, 2, . . . , m}, with cost
a(ci ,t) = B. The remaining part of flowcost( fM ) is the cost of the units of flow traveling through the
edges (ci , c j ) that directly correspond to the cost of microbribery M.
Now consider some minimum-cost flow fmin for I(T  ). Since fM exists, a minimum-cost flow
must exist as well. Clearly, we have
flowcost( fmin )  flowcost( fM ).
T 

Let T  be the number of units of flow that fmin assigns to travel over the edge (c0 ,t), i.e.,
= fmin (c0 ,t). The only edges with nonzero cost for sending flow through them are those in the
304

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

set {(ci , c j ) | ci , c j  C  vsE (ci , c j ) > 0}  {(ci ,t) | i  {1, . . . , m}} and thus the cost of fmin can be
expressed as (recall that vsE (ci , c j ) > 0 implies i 6= j)



flowcost( fmin ) = B  (F  T  ) +

fmin (ci , c j )  wincostE (c j , ci ).

ci ,c j CvsE (ci ,c j )>0

It holds that (1) B > i, j,i6= j wincostE (ci , c j ), (2) for each ci , c j  C such that vsE (ci , c j ) > 0 we have
fmin (ci , c j )  {0, 1}, and (3) flowcost( fmin )  flowcost( fM ). So T  = T  must hold14 and it must
hold that





fmin (ci , c j )  wincostE (c j , ci ) 

wincostE (c j , ci ).

(ci ,c j )M

ci ,c j CvsE (ci ,c j )>0

Thus flow fmin corresponds to a microbribery that guarantees ps victory and has cost at most as
high as that of M. Since M was chosen to have minimum cost among all such microbriberies, flow
fmin corresponds to a microbribery of minimum cost and our algorithm correctly accepts within the
for loop of Figure 4, at the very latest when in the for loop T is set to T  .

We now turn to the algorithms showing that Llull and Copeland0 , with irrational voters allowed,
are vulnerable to constructive microbribery when the number of voters is even. Here we need to
take into account that it sometimes is more desirable to have some candidates tie each other in a
head-to-head contest than to have one of them win the contest. We handle the cases of Llull and
Copeland0 separately, but in each case our proofs follow the same general structure. In each case
we first provide a lemma that restricts the set of microbriberies to model, and then we use a slightly
modified version of the algorithm from Theorem 3.11, on a modified set of min-cost-flow instances,
to solve the thus limited microbribery problem. We omit the proofs of the remaining four lemmas
of this section as they are somewhat lengthy and repetitive. However, these proofs can be found in
the full TR version of this paper (Faliszewski et al., 2008b).
Lemma 3.13 Let E = (C,V ) be an election with candidate set C = {c0 , c1 , . . . , cm } and with an
even number of voters, specified via preference tables over C. If the election is conducted using Copeland0Irrational then no minimum-cost microbribery that ensures victory for c0 involves either
(a) flipping a result of a head-to-head contest between any two distinct candidates ci , c j  C  {c0 }
from ci winning to c j winning, or (b) changing a result of a head-to-head contest between any two
distinct candidates in C  {c0 } from a tie to one of them winning.
14. Let us explain why T  = T  . In I(T  ), by definition, c(c0 ,t) = T  , so we know that T  = fmin (c0 ,t)  T  . We will
now show that T  = T  . For the sake of contradiction, let us assume that T  < T  . We have
flowcost( fmin )

=



B  (F  T  ) +

fmin (ci , c j )  wincostE (c j , ci )

ci ,c j CvsE (ci ,c j )>0



B  (F  T  ) + B +



fmin (ci , c j )  wincostE (c j , ci )

ci ,c j CvsE (ci ,c j )>0

>

B  (F  T  ) +



wincostE (c j , ci )

(ci ,c j )M

=

flowcost( fM ),

where the last inequality follows from the fact that B is greater than the cost of any microbribery within E. We have
reached a contradiction, since fmin is a minimum-cost flow in I(T  ). Thus T  = T  .

305

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Lemma 3.14 There is a polynomial-time algorithm that solves the constructive microbribery problem for Copeland0Irrational elections with an even number of voters (in the nonunique-winner model).
Lemma 3.15 Let E = (C,V ) be an election with candidate set C = {c0 , c1 , . . . , cm } and with an
even number of voters, specified via preference tables over C. If the election is conducted using
Copeland1Irrational then no minimum-cost microbribery that ensures victory for c0 involves obtaining
a tie in a head-to-head contest between any two distinct candidates in C  {c0 }.
Lemma 3.16 There is a polynomial-time algorithm that solves the constructive microbribery problem for Copeland1Irrational elections with an even number of voters (in the nonunique-winner model).
Together, Theorem 3.7 and Lemmas 3.11, 3.14, and 3.16 show that, in particular, both
Copeland1Irrational and Copeland0Irrational are vulnerable to microbribery, both in the constructive and
the destructive settings. It is interesting to note that all our microbribery proofs would work just as
well if we considered a slight twist on the definition of the microbribery problem, namely, if instead
of saying that each flip in a voters preference table has unit cost we would allow each voter to have
a possibly different price for flipping each separate entry in his or her preference table. This change
would affect only the computing of the values of the functions wincost and tiecost (or, strictly speaking, their analogues in the priced setting). (Technically, we would also have to modify Lemmas 3.13
and 3.15, which in our unit-cost setting say that an optimal microbribery never involves certain specified pairs of candidates, whereas in the priced setting we would need to rephrase them to state that
there exist optimal microbriberies that do not involve those specified pairs of candidates.)
An interesting direction for further study of the complexity of bribery within Copeland systems
is to consider a version of the microbribery problem for the case of rational voters. There, one would
pay unit cost for a switch of two adjacent candidates on a given voters preference list.
For CopelandIrrational , we would also like to know the complexity of constructive microbribery
when  is a rational number strictly between 0 and 1. Our network-flow-based approach does not
seem to generalize easily to values of  strictly between 0 and 1 (when the number of voters is even)
because in a flow network it is hard to split a unit of flow in a tie. A promising approach would be
to have several units of flow model one CopelandIrrational point (e.g., for the case of  = 12 we could
try to use two units of flow to model a single Copeland0.5 point), but then it seems very difficult
(if not impossible) to find edge costs that appropriately model the microbribery. (It is possible to
do so in a very restricted setting, namely where  = 12 and there are exactly two voters that can be
bribed.) Also, the results regarding hardness of manipulation of Faliszewski et al. (2008) suggest
that microbribery for  strictly between 0 and 1 might be NP-hard. However, again, it is nontrivial
to translate their reduction to the world of microbribery.
On a related note, Kern and Paulusma (2001) have shown that the following problem, which
they call SC(0,  , 1), is NP-complete. Let  be a rational number such that 0 <  < 1 and  6= 21 .
We are given an undirected graph G = (V (G), E(G)), where each vertex u  V (G) is assigned a
rational value cu of the form i + j , for nonnegative integers i and j. The question, which we
have rephrased to state in terms of (a variant of) our notion of Copeland , is whether it is possible
to (possibly partially) orient the edges of G such that for each vertex u  V (G) it holds that us
Copeland score is at most cu . Here, by Copeland score of a vertex u we mean, as is natural, the
number of vertices u defeats (i.e., the number of vertices v such that there is a directed edge from
u to v) plus  times the number of vertices that u ties with (i.e., the number of vertices such that
there is an undirected edge between u and v).
306

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

Problem SC(0,  , 1) is very closely related to our microbribery problem. However, we do not
see an immediate reduction from SC(0,  , 1) to microbribery. A natural approach would be to
embed graph G into an election (in the sense that will be explored in Section 4) in such a way that
our preferred candidate p can become a winner, via a microbribery, if and only if it is possible
to orient the edges of G in a way respecting the constraints defined by the values cu (for each u
in V (G)). We would, of course, have to set the budget of our microbribery high enough to allow
modifying each of the edges in G and none of the edges outside of G. However, this is difficult.
The proof of Kern and Paulusma uses values cu that can be implemented only via using tied headto-head contests. The agent performing microbribery could, potentially, affect those head-to-head
contests, thus spoiling our reduction.

4. Control
In this section we focus on the complexity of control in Copeland elections. In control problems
we are trying to ensure that our preferred candidate p is a winner (or, in the destructive case, that our
despised candidate is not a winner) of a given election via affecting this elections structure (namely,
via adding, deleting, or partitioning either candidates or voters). In contrast with bribery problems,
in control problems we are never allowed to change any of the votes and, consequently, the issues
that we encounter and the proof techniques we use are quite different from those presented in the
previous section. For the same reason as previously for each standard type of control a resistance
result in the rational-voters case implies an analogous resistance result in the irrational-voters case,
and a vulnerability result in the irrational-voters case implies an analogous vulnerability result in
the rational-voters case.
The literature regarding the complexity of control problems is not large. To the best of our
knowledge, the only election systems for which a comprehensive analysis has been conducted previously are plurality, Condorcet, and (variants of) approval voting (see Bartholdi et al., 1992; Hemaspaandra et al., 2007a, 2007b; Betzler and Uhlmann, 2008; Erdelyi et al., 2008b; see also Meir et al.,
2008, for some results on (variants of) approval voting, single nontransferable vote, and cumulative
voting with respect to constructive control via adding voters). Among plurality, Condorcet, and (the
standard variant of) approval voting, plurality appears to be the least vulnerable to control and so
it is natural to compare our new results with those for plurality. However, we mention in passing
that Hemaspaandra et al. (2007b) show how to construct hybrid election systems that are resistant to
all standard types of control (including both AC and ACu ; AC is not discussed or proven in Hemaspaandra et al., 2007bthe AC there is our ACu but we mention that the techniques clearly
can handle it without any problem). (It should also be noted that these hybrid systems were not
designed as natural systems to be applied in real-world elections but rather their purpose was to
prove a certain impossibility theorem impossible.)
Our main result in this section is Theorem 4.1.
Theorem 4.1 Let  be a rational number with 0    1. Copeland elections are resistant and
vulnerable to control types as indicated in Table 1 in both the nonunique-winner model and the
unique-winner model, for both the rational and the irrational voter model.
In particular, we will prove in this section that the notion widely referred to in the literature
simply as Copeland elections, which we here for clarity call Copeland0.5 , possesses all ten of
our basic types (see Table 1) of constructive resistance (and in addition, even has constructive ACu
307

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Control type
ACu
AC
DC
RPC-TP
RPC-TE
PC-TP
PC-TE
PV-TE
PV-TP
AV
DV

Copeland
 =0
0< <1
CC DC CC DC
V
V
R
V
R
V
R
V
R
V
R
V
R
V
R
V
R
V
R
V
R
V
R
V
R
V
R
V
R
R
R
R
R
R
R
R
R
R
R
R
R
R
R
R

Plurality

 =1
CC DC
V
V
R
V
R
V
R
V
R
V
R
V
R
V
R
R
R
R
R
R
R
R

CC
R
R
R
R
R
R
R
V
R
V
V

DC
R
R
R
R
R
R
R
V
R
V
V

Table 1: Comparison of control results for Copeland elections, where  with 0    1 is a
rational number, and for plurality-rule elections. R means resistance to a particular control
type and V means vulnerability. The results regarding plurality are due to Bartholdi et al.
(1992) and Hemaspaandra et al. (2007a). (Note that CCAC and DCAC resistance results
for plurality, not handled explicitly in Bartholdi et al., 1992, or Hemaspaandra et al., 2007a,
follow immediately from the respective CCACu and DCACu results.)

resistance). (As to why we consider AC more basic than ACu , see the discussion in the Control via
Adding Candidates subpart of Section 2.2. Nonetheless, we do obtain ACu results, and so fans of
the naturalness of ACu will know how things fare under that control type.) And we will establish
that the other notion that in the literature is occasionally referred to as Copeland elections, namely
Copeland0 , as well as Llull elections, which are here denoted by Copeland1 , both possess all ten of
our basic types of constructive resistance. However, we will show that Copeland0 and Copeland1
are vulnerable to an eleventh type of constructive control, the incongruous but historically resonant
notion of constructive control by adding an unlimited number of candidates (i.e., CCACu ).
Note that Copeland0.5 has a higher number of constructive resistances, by three, than even
plurality, which was before this paper the reigning champ among natural election systems with
a polynomial-time winner-determination procedure. (Although the results regarding plurality in
Table 1 are stated for the unique-winner version of control, for all the tables Copeland cases,
0    1, our results hold both in the cases of unique winners and of nonunique winners, so that
regardless of which of the two winner models one finds more natural, one will know what holds in
that model.) Admittedly, plurality does perform better with respect to destructive candidate control
problems, but still our study of Copeland makes significant steps forward in the quest for a fully
control-resistant natural election system with an easy winner problem.
Among the systems with a polynomial-time winner problem, Copeland0.5 and indeed all
Copeland , 0 <  < 1have the most resistances currently known for any natural election system whose voters vote by giving preference lists. We mention that after our work, Erdelyi et al.
(2008b) have shown that their variant of a variant of approval voting proposed by Brams and Sanver (2006)a certain rather subtle election system with a richer voter preference type (each voter
308

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

specifies both a permutation and a set) that combines approval with preference-based votinghas
nineteen (out of a possible twenty-two) control resistances.
This section is organized as follows. The next two sections are devoted to proving Theorem 4.1,
and Section 4.3 considers the case of control in elections with a bounded number of candidates or
voters. In particular, Section 4.1 focuses on the upper part of Table 1 and studies control problems
that affect the candidate structure. Section 4.2 is devoted to voter control and covers the lower part
of Table 1. Finally, in Section 4.3 we study the fixed-parameter complexity of control problems. In
particular, we take the role of someone who tries to solve in-general-resistant control problems and
we devise some efficient algorithms for the case where the number of candidates or the number of
voters is bounded.
All our resistance results regarding candidate control follow via reductions from vertex cover
and all our vulnerability results follow via greedy algorithms. Our resistance results for the case of
control by modifying voter structure follow from reductions from the X3C problem.
4.1 Candidate Control
We start our discussion of candidate control for Copeland with our results on destructive control. It
is somewhat disappointing that for each rational  , 0    1, Copeland is vulnerable to each type
of destructive candidate control. On the positive side, our vulnerability proofs follow via natural
greedy algorithms and will allow us to smoothly get into the spirit of candidate-control problems.
4.1.1 D ESTRUCTIVE C ANDIDATE C ONTROL
The results for destructive control by adding and deleting candidates use the following observation.
Observation 4.2 Let (C,V ) be an election, and let  be a rational number such that 0    1.
For every candidate c  C it holds that
score(C,V ) (c) =



score({c,d},V ) (c).

dC{c}

Theorem 4.3 For each rational number  with 0    1, Copeland is vulnerable to destructive
control via adding candidates (both limited and unlimited, i.e., DCAC and DCACu ), in both the
nonunique-winner model and the unique-winner model, for both the rational and the irrational
voter model.
Proof. Our input is a set C of candidates, a set D of spoiler candidates, a collection V of voters
with preferences (either preference lists or preference tables) over C  D, a candidate p  C, and a
nonnegative integer k (for the unlimited version of the problem we let k = kDk). We ask whether
there is a subset D of D such that kD k  k and p is not a winner (is not a unique winner) of
Copeland election E  = (C  D ,V ). Note that if k = 0, this amounts to determining whether p is
not a winner (is not a unique winner) of election E, which can easily be done in polynomial time.
For the remainder of this proof we will assume that k > 0. Let c be any candidate in (C  D) 
{p}. We define a(c) to be the maximum value of the expression
score(CD ,V ) (c)  score(CD ,V ) (p)

309

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

under the conditions that D  D, c  C  D , and kD k  k. From Observation 4.2 it follows that
a(c) is the maximum value of


score(C{c},V ) (c)  score(C{c},V ) (p) + 
score({c,d},V ) (c)  score({p,d},V ) (p)
dD {c}

under the conditions that D  D, c  C  D , and kD k  k.
Clearly, p can be prevented from being a winner (a unique winner) if and only if there exists a
candidate c  (C  D)  {p} such that a(c) > 0 (such that a(c)  0).
Given a candidate c  (C  D)  {p}, it is easy to construct in polynomial time a set D  D,

kD k  k, that yields the value a(c). We start with D = 0.
/ If c  D, we add c to D . Then we add
those candidates d  D  D to D such that score({c,d},V ) (c)  score({p,d},V ) (p) is positive, starting
with those for whom this value is highest, until kD k = k or no more such candidates exist.

Theorem 4.4 For each rational number  with 0    1, Copeland is vulnerable to destructive control via deleting candidates (DCDC), in both the nonunique-winner model and the uniquewinner model, for both the rational and the irrational voter model.
The proof of Theorem 4.4 is similar to that of Theorem 4.3, so we do not include it here but
instead refer to the full TR version (Faliszewski et al., 2008b).
Destructive control via partitioning of candidates (with or without run-off) is also easy. Since
the arguments of that proof are more involved, we present it here.
Theorem 4.5 For each rational number  with 0    1, Copeland is vulnerable to destructive
control via partitioning of candidates and via partitioning of candidates with run-off (in both the
TP and TE model, i.e., DCPC-TP, DCPC-TE, DCRPC-TP, and DCRPC-TE), in both the nonuniquewinner model and the unique-winner model, for both the rational and the irrational voter model.
Proof. It is easy to see that in the TP model, p can be prevented from being a winner via partitioning of candidates (with or without run-off) if and only if there is a set C  C such that p  C
and p is not a winner of (C ,V ). It follows that p can be prevented from being a winner if and only
if p can be prevented from being a winner by deleting at most kCk  1 candidates, which can be
determined in polynomial time by Theorem 4.4. We will show how to handle the unique-winner
variants of DCPC-TP and DCRPC-TP later in this proof.
For the TE model, it is easy to see that if there is a set C  C such that p  C and p is not a
unique winner of (C ,V ) then p can be prevented from being a unique winner via partitioning of
candidates (with or without run-off). One simply partitions the candidates into C and C  C and
thus p fails to advance to the final stage. On the other hand, if p can be prevented from being a
winner (a unique winner) via partitioning of candidates (with or without run-off) in the TE model,
then there exists a set C  C such that p  C and p is not a unique winner of (C ,V ). This is so
because then either p does not advance to the final stage (and this means that p is not a unique
winner of his or her first-stage election) or p is not a winner (not a unique winner) of the final stage
(note that not being a winner implies not being a unique winner).
Thus, p can be prevented from being a winner (a unique winner) via partitioning of candidates
(with or without run-off) in the TE model if and only if there is a set C  C such that p  C and p
310

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

is not a unique winner of (C ,V ). Clearly, such a set exists if and only if p can be prevented from
being a unique winner via deleting at most kCk  1 candidates, which by Theorem 4.4 can be tested
in polynomial time.
It remains to show that Copeland is vulnerable to destructive control via partitioning of candidates (with or without run-off), in both the rational and the irrational voter model, in the uniquewinner model with the TP tie-handling rule. In the argument below we focus on the DCRPC-TP
case but it is easy to see that essentially the same reasoning works for DCPC-TP.
First we determine whether p can be precluded from being a winner in our current control
scenario. This can be done in polynomial time as explained above. If p can be precluded from
being a winner, p can certainly be precluded from being a unique winner, and we are done. For
the remainder of the proof, suppose that p cannot be precluded from being a winner in our current
control scenario, i.e., for every set D  C such that p  D, p is a winner of (D,V ). Let
D1 = {c  C  {p} | p defeats c in a head-to-head contest}
and let D2 = D  (D1  {p}). Note that for all c  D2 , p ties c in a head-to-head contest, since
otherwise p would not be a winner of ({c, p},V ). If D2 = 0,
/ then p is a Condorcet winner and
no partition (with or without run-off) can prevent p from being a unique winner (Hemaspaandra
et al., 2007a). For the remainder of the proof, we assume that D2 6= 0.
/ We will show that p can be
precluded from being a unique winner in our current control scenario.
If  < 1, we let the first subelection be (D1  {p},V ). Note that p is the unique winner of this
subelection. The final stage of the election involves p and one or more candidates from D2 . Note
that every pair of candidates in D2  {p} is tied in a head-to-head election (since if c would defeat
d in a head-to-head election, c would be the unique winner of ({c, d, p},V ), which contradicts the
assumption that p is a winner of every subelection it participates in). It follows that all candidates
that participate in the final stage of the election are winners, and so p is not a unique winner.
Finally, consider the case that  = 1. Then score(C,V ) (p) = kCk  1. If there is a candidate
d  C  {p} such that score(C,V ) (d) = kCk  1, then d will always (i.e., in every subelection containing d) be a winner, and thus p will not be a unique winner of the final stage of the election,
regardless of which partition of C was chosen. Now suppose that score(C,V ) (d) < kCk  1 for
all d  C  {p}. Then score(C,V ) (d)  kCk  2 for all d  C  {p}. Let c be a candidate in D2
and let the first subelection be (C  {c},V ). Let C be the set of winners of (C  {c},V ). Since
score(C{c},V ) (p) = kCk  2, it holds that p  C and for every d  C  {p}, score(C{c},V ) (d) =
kCk  2. Since score(C,V ) (d)  kCk  2, it follows that c defeats d in a head-to-head election. The
final stage of the election involves candidates C  {c}. Note that score(C {c},V ) (c) = kC k, and thus
c is a winner of the election, and we have precluded p from being a unique winner.

The above vulnerability results for the case of destructive candidate control should be contrasted
with the essentially perfect resistance to constructive candidate control (with the exception of constructive control via adding an unlimited number of candidates for Copeland with   {0, 1}) that
will be shown in Section 4.1.3. But first, in Section 4.1.2, we will provide some technical prerequisites.

311

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

4.1.2 C ONSTRUCTING I NSTANCES OF E LECTIONS
Many of our proofs in the next section require constructing fairly involved instances of Copeland
elections. In this section we provide several lemmas and observations that simplify building such
instances.
We first note that each election E = (C,V ) induces a directed graph G(E) whose vertices are
Es candidates and whose edges correspond to the results of the head-to-head contests in E. That
is, for each two distinct vertices of G(E) (i.e., for each two distinct candidates), a and b, there
is an edge from a to b if and only if a defeats b in their head-to-head contest (i.e., if and only if
vsE (a, b) > 0). Clearly, G(E) does not depend on the value of  . The following fundamental result
is due to McGarvey. This result allows us to basically identify elections with their election graphs
in the proofs of resistance for candidate control. In effect, Copeland candidate-control problems
often can be viewed (with some care regarding ties) as graph-theoretic problems.
Lemma 4.6 (McGarvey, 1953) There is a polynomial-time algorithm that given as input an antisymmetric directed graph G outputs an election E such that G = G(E).
Proof. For the sake of completeness, we give the algorithm. Let G be an antisymmetric directed
graph. The algorithm computes the election E = (C,V ), where C = V (G) and for each edge (a, b) in
G there are exactly two voters, one with preference list a > b > C  {a, b} and one with preference

list C  {a, b} > a > b. Since G is antisymmetric, it is easy to see that G = G(E).

The above basic construction of McGarvey was improved upon by Stearns (1959). While McGarveys construction requires twice as many voters as there are edges in G, the construction of
Stearns needs at most kV (G)k + 2 voters. Stearns also provides a lower bound on the number of
voters that are needed to represent an arbitrary graph via an election. (It is easy to see that any such
graph can be modeled via two irrational voters but the lower bound for the case of rational votes is
somewhat harder.)
We will often construct complicated elections via combining simpler ones (see, in particular,
the rather involved proofs of Theorems 4.12 through 4.16 that can be found in the full TR version,
Faliszewski et al., 2008b). Whenever we speak of combining two elections, say E1 = (C1 ,V1 ) and
E2 = (C2 ,V2 ), we mean building, via the algorithm from Lemma 4.6, an election E = (C,V ) whose
election graph is a disjoint union of the election graphs of E1 and E2 with, possibly, some edges
added between the vertices of G(E1 ) and G(E2 ) (in each case we will explicitly state which edges,
if any, are added). In particular, we will often want to add some padding candidates to an election,
without affecting the original election much. In order to do so, we will typically combine our
main election with one of the following padding elections. Note that this construction, which we
originally developed for use in the study of control for Copeland voting, has also proven useful in
the study of manipulation for Copeland (Faliszewski et al., 2008).
Lemma 4.7 Let  be a rational number such that 0    1. For each positive integer n, there is
a polynomial-time (in n) computable election Padn = (C,V ) such that kCk = 2n + 1 and for each
candidate ci  C it holds that scorePadn (c) = n.
Proof. Fix a positive integer n. By Lemma 4.6 it is enough to construct (in polynomial time in n)
a directed, antisymmetric graph G with 2n + 1 vertices, each with its indegree and outdegree equal
312

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

to n. We set Gs vertex set to be {0, 1, . . . , 2n} and we put an edge from vertex i to vertex j (i 6= j)
if and only if ( j  i) mod (2n + 1)  n. As a result there is exactly one directed edge between every
two distinct vertices and for each vertex i we have edges going out from i to exactly the vertices
(i + 1) mod (2n + 1), (i + 2) mod (2n + 1), . . . , (i + n) mod (2n + 1). Thus, both the indegree and
the outdegree of each vertex is equal to n and the proof is complete.

Lemma 4.6 (McGarvey, 1953) is very useful when building an election in which we need direct
control over the results of all head-to-head contests. However, in many cases explicitly specifying the results of all head-to-head contests would be very tedious. Instead it would be easier to
specify the results of only the important head-to-head contests and require all candidates to have
certain suitable scores. In the next lemma we show how to construct elections specified in such a
way via combining a small election containing the important head-to-head contest with a large
padding election. We mention that a generalized version of this lemma has since been used to study
manipulation for Copeland (Faliszewski et al., 2008).
Lemma 4.8 Let E = (C,V ) be an election where C = {c1 , . . . , cn }, let  be a rational number such
that 0    1, and let n  n be an integer. For each candidate ci we denote the number of headto-head ties of ci in E by ti . Let k1 , . . . , kn be a sequence of n nonnegative integers such that for
each ki we have 0  ki  n. There is an algorithm that in polynomial time in n outputs an election
E  = (C ,V  ) such that:
1. C = C  D, where D = {d1 , . . . , d2n2 },
2. E  restricted to C is E,
3. the only ties in head-to-head contests in E  are between candidates in C,
4. for each i, 1  i  n , scoreE  (ci ) = 2n2  ki + ti  , and
5. for each i, 1  i  2n2 , scoreE  (di )  n2 + 1.
Proof. We build E  via combining E with a padding election F (see Lemma 4.7 and the paragraph
just before it). F = (D,W ), where D = {d1 , . . . , d2n2 }, is essentially the election Padn2 with one
arbitrary candidate removed. We partition the candidates in D into n groups, D1 , . . . , Dn , each with
exactly 2n candidates and we set the results of head-to-head contests between each ci  C and the
candidates in D according to the following scheme. For each j  {1, . . . , n } such that i 6= j, ci
defeats all members of D j and ci defeats exactly as many candidates in Di (and loses to all the
remaining ones) as needed to ensure that
scoreE  (ci ) = 2n2  ki + ti  .
It is easy to see that this is possible: ci s score in (C  Di ,V  ) is 2n2  2n + k + ti  for some k
such that 0  k  n  ti . There are 2n candidates in Di and so ci can reach any score of the form
2n2  k + ti  , where k is an integer between 0 and n, via defeating in head-to-head contests an
appropriate number of candidates in Di and losing to all the remaining ones.
Finally, since F is Padn2 with one candidate removed, each di gets at most n2 points from
defeating other members of D and at most one point from possibly defeating some member of C.

Thus, for each di  D, it holds that scoreE  (di )  n2 + 1. This completes the proof.
313

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Instead of invoking Lemma 4.8 directly, we will often simply describe an election in terms of
the results of important head-to-head contests and the scores of the important candidates and then
mention that such an election can be built, possibly with adding extra padding candidates that do
not affect the general structure of the election, using Lemma 4.8. In each such case it will be clear
that Lemma 4.8 can indeed be used to build the election we describe.
4.1.3 C ONSTRUCTIVE C ANDIDATE C ONTROL
Let us now turn to the case of constructive candidate control. Here we show that resistance holds
for Copeland in all cases (i.e., for all rational values of  with 0    1 and for all constructive candidate control scenarios), except for CCACu for   {0, 1} where vulnerability holds (see
Theorem 4.11).
All our resistance proofs in this section follow via reductions from the vertex cover problem.
Recall that in the vertex cover problem our input is (G, k) where G is an undirected graph and k a
nonnegative integer and we accept if and only if G has a vertex cover of size at most k. Without
the loss of generality, we assume that V (G) = {1, . . . , n} and E(G) = {e1 , . . . , em }. Note that if
either m = 0, n = 0, or k  min(n, m) then the instance has a trivial solution and so in our proofs
we will always assume that both n and m are nonzero and that k is less than min(n, m). In each
case, if the input to our reduction does not meet these requirements (or is otherwise malformed) the
reduction outputs a fixed yes instance or a fixed no instance depending on the (easily obtained)
solution to (G, k) or the malformation of the input. Also note that for every input (G, k) that meets
our requirements, G has a vertex cover of size less than or equal to k if and only if G has a vertex
cover of size k.
Theorem 4.9 Let  be a rational number such that 0    1. Copeland is resistant to constructive control via adding candidates (CCAC), in both the nonunique-winner model and the uniquewinner model, for both the rational and the irrational voter model.
Proof. We give a reduction from the vertex cover problem. Let (G, k) be an instance of the vertex
cover problem, where G is an undirected graph, k is a nonnegative integer, V (G) = {1, . . . , n},
E(G) = {e1 , . . . , em }, n 6= 0, m 6= 0, and k < min(n, m). We construct an instance of CCAC for
Copeland such that a designated candidate p can become a winner after adding at most k candidates
if and only if G has a vertex cover of size at most k.
Our reduction works as follows. Via Lemma 4.8, we build an election E  = (C ,V  ) such that:
1. {p, e1 , . . . , em }  C ,
2. scoreE  (p) = 22  1 in the nonunique-winner case (scoreE  (p) = 22 in the unique-winner
case);  is a sufficiently large (but polynomially bounded) integer that takes the role of
Lemma 4.8s n,
3. for each ei  C , scoreE  (ei ) = 22 , and
4. the scores of all candidates in C  {p, e1 , . . . , em } are at most 22  n  2.
We form election E = (C,V ) by combining E  with candidates D = {1, . . . , n} (corresponding
to the vertices of G). The results of the head-to-head contests within D are set arbitrarily, and
the head-to-head contests between the members of C and the members of D are set as follows: All
314

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

candidates in C {e1 , . . . , em } defeat all members of D, and for each i  D and each e j  {e1 , . . . , em },
candidate i defeats e j if e j is an edge incident to i and loses otherwise. Our reduction outputs an
instance (C, D,V, p, k) of CCAC and the question is whether it is possible to choose a subset D  D,
kD k  k, such that p is a winner (the unique winner) of Copeland election (C  D ,V ). It is clear
that this reduction is computable in polynomial time. We will now show that it is correct.
If G does have a vertex cover of size k then add the candidates in D that correspond to the cover.
Adding these candidates increases the score of p by k, while the scores of the ei s can increase only
by k  1 each, since each edge is incident with at least one member of the vertex cover. Clearly,
candidates in C  {p, e1 , . . . , em } can never become winners by adding at most k candidates from D,
and thus p becomes a winner (the unique winner).
For the converse, assume that p can become a winner (the unique winner) via adding at most k
candidates from the set D. In order for p to become a winner (the unique winner), it must be the
case that via adding candidates each ei gets at least one point less than p. However, this is possible
only if we add candidates that correspond to a cover.

Interestingly, when the parameter  is strictly between 0 and 1 (i.e., 0 <  < 1) then Copeland
is resistant to constructive control via adding candidates even if we allow adding an unlimited number of candidates (the CCACu case). The reason for this is that for each rational  strictly between
0 and 1 our construction will ensure, via its structure, that we can add at most k candidates. On
the other hand, both Copeland0 and Copeland1 are vulnerable to constructive control via adding an
unlimited number of candidates (CCACu , see Theorem 4.11).
Theorem 4.10 Let  be a rational number such that 0 <  < 1. Copeland is resistant to constructive control via adding an unlimited number of candidates (CCACu ), in both the nonunique-winner
model and the unique-winner model, for both the rational and the irrational voter model.
Proof. We give a reduction from the vertex cover problem.
For the unique-winner case, we will need to specify one of the candidates scores in terms of a
number  > 0 such that 1     . Let t1 and t2 be two positive integers such that  = tt12 and such
that their greatest common divisor is 1. Clearly, two such numbers exist because  is rational and
greater than 0. We set  to be t12 . By elementary number-theoretic arguments, there are two positive
integer constants, k1 and k2 , such that k1  = k2   .
Let (G, k) be an instance of the vertex cover problem, where G is an undirected graph and k is a
nonnegative integer. Let {e1 , . . . , em } be Gs edges and let {1, . . . , n} be Gs vertices. As before, we
assume that both n and m are nonzero and that k < min(n, m). Using Lemma 4.8, we can build an
election E  = (C,V  ) with the following properties:
1. {p, r, e1 , . . . , em }  C (the remaining candidates in C are used for padding),
2. scoreE  (p) = 22  1,
3. scoreE  (r) = 22 1k +k in the nonunique-winner case (scoreE  (r) = 22 1k +k  
in the unique-winner case15 ),
15. Note that via the second paragraph of the proof it is easy to build an election where r has a score of this form. To
obtain the  part of rs score we could, for example, have r tie with k1 padding candidates to obtain k2   points.
The k2 points could be accounted for as part of 22  1.

315

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

4. for each ei  C, scoreE  (ei ) = 22  1 +  in the nonunique-winner case (scoreE  (ei ) = 22  1
in the unique-winner case), and
5. the scores of all candidates in C  {p, r, e1 , . . . , em } are at most 22  n  2.
We form election E = (C  D,V ) via combining E  with candidates D = {1, . . . , n} and appropriate voters such that the results of the head-to-head contests are:
1. p ties with all candidates in D,
2. for each e j , if e j is incident with some i  D then candidate i defeats candidate e j , and otherwise they tie, and
3. all other candidates in C defeat each of the candidates in D.
We will now show that G contains a vertex cover of size at most k if and only if there is a set
D  D such that p is a winner (the unique winner) of Copeland election (C  D ,V ). It is easy to
see that if D corresponds to a vertex cover of size at most k then p is a winner (the unique winner)
of Copeland election (C  D ,V ). The reason is that adding any member of D increases ps score
by  and increases rs score by one, and for each e j , adding i  D increases e j s score by  if and
only if e j is not incident with i. Thus, via a simple calculation of the scores of the candidates, it is
easy to see that p is a winner (the unique winner) of this election.
On the other hand, assume that p can become a winner (the unique winner) of Copeland
election (C  D ,V ) via adding some subset D of candidates from D. First, note that kD k  k,
since otherwise r would end up with more points than (at least as many points as) p and so p would
not be a winner (would not be a unique winner). We claim that D corresponds to a vertex cover
of G. For the sake of contradiction, assume that there is some edge e j incident to vertices u and v
such that neither u nor v is in D . However, if this were the case then candidate e j would have more
points than (at least as many points as) p and so p would not be a winner (would not be a unique
winner). Thus, D must form a vertex cover of size at most k.

Note that in the above proof it is crucial that  is neither 0 nor 1. If  were 0 then the proof
would fall apart because we would not be able to ensure that D is a vertex cover, and if  were
1 then we would not be able to limit the size of D . In fact, we will now show, as Theorem 4.11,
that both Copeland0 and Copeland1 are vulnerable to control via adding an unlimited number of
candidates (CCACu ).
Theorem 4.11 Let   {0, 1}. Copeland is vulnerable to constructive control via adding an unlimited number of candidates (CCACu ), in both the nonunique-winner model and the unique-winner
model, for both the rational and the irrational voter model.
Proof. Our input is candidate set C, spoiler candidate set D, a collection of voters with preferences
(either preference lists or preference tables) over C  D, and a candidate p  C. Our goal is to check
whether there is some subset D  D such that p is a winner (the unique winner) of (C  D ,V )
within Copeland . We will show that we can find such a set D , if it exists, by the following simple
algorithm.

316

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

Let D1 = {d  D | score({p,d},V ) (p) = 1}. Initialize D to be D1 , and delete every d  D
for which score(CD ,V ) (p) < score(CD ,V ) (d). For the unique-winner problem, delete
every d  D for which score(CD ,V ) (p)  score(CD ,V ) (d).
Clearly, this algorithm runs in polynomial time. To show that the algorithm works, first note
b  D, if p is a winner (the unique winner) of (C  D,V
b ), then p is a winner (the unique
that for all D
b
winner) of (C  (D  D1 ),V ). This is so because, by Observation 4.2,

score(CD,V
b ) (p) = score(C(DD
b

1 ),V )

=

(p) +

score(C(DD
b 1 ),V ) (p).



score({p,d},V ) (p)

b
dDD
1

b  D1 , p is a winner (the unique winner) of (C  D,V
b ), but that the
Now suppose that for some D

algorithm computes a set D such that p is not a winner (not a unique winner) of (C  D ,V ). We first
b  D . Since p is not a winner (not a unique winner) of (C  D ,V ), it follows
consider the case that D
by the construction of D that there exists a candidate d  C  {p} such that score(CD ,V ) (p) <
score(CD ,V ) (d) (such that score(CD ,V ) (p)  score(CD ,V ) (d)). However, in the nonunique-winner
model we then have

b
score(CD ,V ) (p) = score(CD,V
b ) (p) + kD k  kDk



b
 score(CD,V
b ) (d) + kD k  kDk  score(CD ,V ) (d),

which is a contradiction. In the unique-winner model, the first  in the above inequality becomes
a > and we reach a contradiction as well.
b 6 D . Let d be the first candidate in D
b that is deleted from D in
Finally, consider the case that D
b  D  D1 and score  (p) < score  (d)
the algorithm. Then there is a set D such that D
(CD ,V )
(CD ,V )
in the nonunique-winner case (score(CD ,V ) (p)  score(CD ,V ) (d) in the unique-winner case).
b  D  D1 , we have
Since D




b
b
1. score(CD,V
b ) (p) = score(CD ,V ) (p)  (kD k  kDk) < score(CD ,V ) (d)  (kD k  kDk) 

score(CD,V
b ) (d) in the nonunique-winner case, and





b
b
2. score(CD,V
b ) (p) = score(CD ,V ) (p)  (kD k  kDk)  score(CD ,V ) (d)  (kD k  kDk) 

score(CD,V
b ) (d) in the unique-winner case.

b ). This is again a contradicIt follows that p is not a winner (not a unique winner) of (C  D,V
tion.


The remainder of this section is dedicated to showing that for any rational  such that 0    1,
Copeland is resistant to constructive control via deleting candidates and to constructive control via
partitioning candidates (with or without run-off and in both the TE and the TP model). For reasons
of space and nonrepetitiveness, the proofs of these results are not included here but can be found in
the full TR version (Faliszewski et al., 2008b), where we first handle the case of constructive control
via deleting candidates (CCDC) and then, using our proof for the CCDC case as a building block,
handle the constructive partition-of-candidates cases.
317

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Theorem 4.12 Let  be a rational number such that 0    1. Copeland is resistant to constructive control via deleting candidates (CCDC), in both the nonunique-winner model and the
unique-winner model, for both the rational and the irrational voter model.
The proof of Theorem 4.13 (which, as mentioned above, is presented in Faliszewski et al.,
2008b) employs both the construction used for proving Theorem 4.12 and a construction that combines suitable elections such that the combined election has properties useful for proving various
partition-of-candidates cases (with or without run-off). In particular, this construction not only is
applied in the proof of Theorem 4.13, but also is designed to be general enough to serve as a key
ingredient in proving Theorems 4.14, 4.15, and 4.16 below.
Theorem 4.13 Let  be a rational number such that 0    1. Copeland is resistant to constructive control via run-off partition of candidates in both the ties-promote model (CCRPC-TP)
and the ties-eliminate model (CCRPC-TE), in both the nonunique-winner model and the uniquewinner model, for both the rational and the irrational voter model.
Copeland is also resistant to constructive control via partition of candidates (without run-off)
for each rational value of  between (and including) 0 and 1. However, the proofs for the TP and TE
cases (which, again, can be found in the full TR version, Faliszewski et al., 2008b) are not as uniform
as in the CCRPC scenario and soto stay in sync with the structure of Faliszewski et al. 2008b,
where the proofs arewe treat these cases separately as Theorems 4.14, 4.15, and 4.16.
Theorem 4.14 Let  be a rational number such that 0    1. Copeland is resistant to constructive control via partition of candidates with the ties-promote tie-handling rule (CCPC-TP), in both
the nonunique-winner model and the unique-winner model, for both the rational and the irrational
voter model.
Theorem 4.15 Copeland1 is resistant to constructive control via partition of candidates with the
ties-eliminate tie-handling rule (CCPC-TE), in both the nonunique-winner model and the uniquewinner model, for both the rational and the irrational voter model.
Theorem 4.16 Let  be a rational number, 0   < 1. Copeland is resistant to constructive
control via partition of candidates with the ties-eliminate tie-handling rule (CCPC-TE), in both
the nonunique-winner model and the unique-winner model, for both the rational and the irrational
voter model.
4.2 Voter Control
In this section, we show that for each rational  , 0    1, Copeland is resistant to all types
of voter control. Table 2 lists for each type of voter control, each rational  , 0    1, and
each winner model (i.e., the nonunique-winner model and the unique-winner model) the theorem in
which each given case is handled. We start with control via adding voters.
Theorem 4.17 Let  be a rational number such that 0    1. Copeland is resistant to both
constructive and destructive control via adding voters (CCAV and DCAV), in both the nonuniquewinner model and the unique-winner model, for both the rational and the irrational voter model.

318

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

unique
CCAV
DCAV
CCDV
DCDV
CCPV-TP
DCPV-TP
CCPV-TE
DCPV-TE

 =0
nonunique

0< <1
unique
nonunique

unique

 =1
nonunique

Thm. 4.17
Thm. 4.19
Thm. 4.20

Thm. 4.20
Thm. 4.19

Thm. 4.19
Thm. 4.20

Thm. 4.20
Thm. 4.19

Thm. 4.19
Thm. 4.18

Thm. 4.18
Thm. 4.19

Thm. 4.21
Thm. 4.23
Thm. 4.26

Thm. 4.24
Thm. 4.25

Table 2: Table of theorems covering all resistance results for voter control for Copeland . Each
theorem covers both the case of rational voters and the case of irrational voters.

Proof. Our result follows via reductions from the X3C problem. We will first show how to handle
the nonunique-winner constructive case and later we will argue that the construction can be easily
modified for each of the remaining cases.
Let (B, S ) be an X3C instance where B = {b1 , . . . , b3k } and S = {S1 , . . . , Sn } is a finite collection of three-element subsets of B. Without loss of generality, we assume that k is odd (if it is even,
we simply add b3k+1 , b3k+2 , b3(k+1) to B and Sn+1 = {b3k+1 , b3k+2 , b3(k+1) } to S , and add 1 to k).
S
The question is whether one can pick k sets Sa1 , . . . , Sak such that B = kj=1 Sa j .
We build a Copeland election E = (C,V ) as follows. The candidate set C contains candidates p
(the preferred candidate), r (ps rival), s, all members of B, and some number of padding candidates.
We select the voter collection V such that in their head-to-head contests, s defeats p, r defeats each
bi , and such that we have the following Copeland scores for these candidates, where  is some
sufficiently large (but polynomially bounded in n) nonnegative integer:
1. scoreE (p) =   1,
2. scoreE (r) =  + 3k, and
3. all other candidates have Copeland scores below   1.
It is easy to see that E can be constructed in polynomial time by Lemma 4.8. In addition, we ensure
that we have the following results of head-to-head contests between the candidates in C:
1. vsE (s, p) = k  1,
2. for each i  {1, . . . , k}, vsE (r, bi ) = k  3, and
3. for all other pairs of candidates c, d, we have |vsE (c, d)|  k + 1.
This can be done since we can add 2 to vsE (c, d) and leave all other relative vote scores the same by

adding two voters, c > d > C  {c, d} and C  {c, d} > c > d (see Lemma 4.6). Since k is odd and
the number of voters is even (see Lemma 4.8), it is easy to see that we can fulfill these requirements.

319

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

We also specify the set W of voters that the chair can potentially add. For each set Si  S we
have a single voter wi  W with preference list
p > B  Si > r > Si >   
(all unmentioned candidates follow in any fixed arbitrary order). We claim that S contains a kelement cover of B if and only if p can become a winner of the above election via adding at most k
voters selected from W .
If S contains a k-element cover of B, say Sa1 , . . . , Sak , then we can make p a winner via adding
the voters from U = {wa1 , . . . , wak }. Adding these k voters increases ps score by one, since p now
defeats s in their head-to-head contest. Since voters in U correspond to a cover, the score of r goes
down by 3k points. Why? For each bi  B, adding the k  1 voters in U that correspond to the
sets in the cover not containing bi increases the relative performance of bi versus r by k  1 votes,
thus giving bi two votes of advantage over r. Adding the remaining voter from U decreases this
advantage to 1, but still bi wins the head-to-head contest with r.
We now show that if we can make p a winner by adding at most k voters then S contains a kelement cover of B. Note that p is the only candidate that can possibly become a winner by adding
at most k voters, that p can at best obtain Copeland score , that p will obtain this score only if we
add exactly k voters, and that r can lose at most 3k points via losing his or her head-to-head contests
with each of the bi s. Thus the only way for p to become a winner by adding at most k voters from
W is that we add exactly k voters such that r loses his or her head-to-head contest with each bi .
Assume that U  W is such a set of voters that does not correspond to a cover of B. This means that
there is some candidate bi such that at least two voters in U prefer r to bi . However, if this is the
case then bi cannot defeat r in their head-to-head contest and p is not a winner. U corresponds to a
cover. This completes the proof of the nonunique-winner constructive case of the theorem.
For the constructive unique-winner case, we modify election E so that scoreE (p) = . All other
listed properties of the relative vote scores and absolute Copeland scores are unchanged. As in
the previous case, it is easy to see that p can become the unique winner via adding k voters that
correspond to a cover of B. For the converse, we will show that we still need to add exactly k voters
if p is to become the unique winner.
If we added fewer than k  1 voters then p would not get any extra points and so it would be
impossible for p to become the unique winner. Let us now show that adding exactly k  1 voters
cannot make p the unique winner. If we added exactly k  1 voters then p would get  points extra
from the tie with s. Now consider some candidate bi  S j , where S j corresponds to one of the added
voters, w j . Since w j prefers r to bi , adding w j to the election increases the relative performance of r
versus bi to k  2. Thus adding the remaining k  2 voters can result in bi either tieing or losing his
or her head-to-head contest with r. In either case p would not have a high enough score to become
the unique winner. Thus we know that exactly k candidates must be added if we want p to become
the unique winner and, via the same argument as in the previous case, we know that they have to
correspond to a cover.
For the destructive cases it suffices to note that the proof for the constructive nonunique-winner
case works also as a proof for the destructive unique-winner case (where we are preventing r from
being the unique winner) and the constructive unique-winner case works also as a proof for the
destructive nonunique-winner case (where we are preventing r from being a winner).

Let us now turn to the case of control via deleting voters. Unfortunately, the proofs here are not
as uniform as before and we need in some cases to handle  = 1 separately from the case where
320

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

0   < 1. Also, we cannot use the construction lemma (Lemma 4.8) anymore to so conveniently
build our elections. In the case of deleting voters (or partitioning voters) we need to have a very
clear understanding of how each voter affects the election and the whole point of introducing the
construction lemma was to abstract away from such low-level details.
Analogously to the case of candidate control, the resistance proofs for deleting voters are reused
within the resistance proofs for partitioning voters. For reasons of space and nonrepetitiveness,
we again do not include all proofs. In particular, the proofs of Theorems 4.18 and 4.20 are not
included here but can be found in the full TR version (Faliszewski et al., 2008b). The proofs of
Theorems 4.19 and 4.21, however, will be presented here. We mention that the construction given
in the proof of Theorem 4.19 will be used later in the proof of Theorem 5.1, and the construction
given in the proof of Theorem 4.21 will be used later in the proof of Theorem 5.2.
Theorem 4.18 Copeland1 is resistant to constructive control via deleting voters (CCDV) in the
nonunique-winner model and to destructive control via deleting voters (DCDV) in the uniquewinner model, for both the rational and the irrational voter model.
Theorem 4.19 Let  be a rational number such that 0    1. Copeland is resistant to constructive control via deleting voters (CCDV) in the unique-winner model and to destructive control
via deleting voters (DCDV) in the nonunique-winner model, for both the rational and the irrational
voter model.
Proof. Let (B, S ) be an instance of X3C, where B = {b1 , . . . , b3k } and S = {S1 , . . . , Sn } is a
finite family of three-element subsets of B. Without loss of generality, we assume that n  k and
that k > 2 (if n < k then S does not contain a cover of B, and if k  2 then we can solve the problem
by brute force). We build an election E = (C,V ) such that:
1. If S contains a k-element cover of B, then the preferred candidate p can become the unique
Copeland winner of E by deleting at most k voters, and
2. if r can become a nonwinner by deleting at most k voters, then S contains a k-element cover
of B.
Let the candidate set C be {p, r, b1 , . . . , b3k } and let V be the following collection of 4n  k + 1
voters:
1. We have n  1 voters with preference B > p > r,
2. we have n  k + 2 voters with preference p > r > B, and
3. for each Si  S we have two voters, vi and vi , such that
(a) vi has preference r > B  Si > p > Si , and
(b) vi has preference r > Si > p > B  Si .
It is easy to see that for all bi  B, vsE (r, bi ) = 2n  k + 3, vsE (bi , p) = k  3, and vsE (r, p) = k  1.
If S contains a k-element cover of B, say {Sa1 , . . . , Sak }, then we delete voters va1 , . . . , vak . In
the resulting election, p defeats every other candidate in their head-to-head contests, and thus p is
the unique winner.
321

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

To prove the second statement, suppose that there is a subset W of at most k voters such that
r is not a winner of Eb = (C,V  W ). Since vsE (r, bi ) = 2n  k + 3 and n  k, it is immediate that
b In order for r not to be a winner of E,
b
r defeats every bi  B in their head-to-head contests in E.
p must certainly defeat r and tie-or-defeat every bi  B in their head-to-head contests. But p can
defeat r in their head-to-head contest only if kW k = k and every voter in W prefers r to p. It follows
that W is a size-k subset of {v1 , v1 , . . . , vn , vn }.
Let bi  B. Recall that vsE (bi , p) = k  3 and that p needs to at least tie bi in their head-to-head
b Since kW k = k, it follows that W can contain at most one voter that prefers p to bi .
contest in E.
Since k > 2, it follows that W contains only voters from the set {v1 , . . . , vn } and that the voters in W
correspond to a k-element cover of B.

Theorem 4.20 Let  be a rational number such that 0   < 1. Copeland is resistant to constructive control via deleting voters (CCDV) in the nonunique-winner model and to destructive control
via deleting voters (DCDV) in the unique-winner model, for both the rational and the irrational
voter model.
Theorem 4.21 Let  be a rational number such that 0    1. Copeland is resistant to both
constructive and destructive control via partitioning voters in the TP model (CCPV-TP and DCPVTP), in both the nonunique-winner model and the unique-winner model, for both the rational and
the irrational voter model.
Proof. Let (B, S ) be an instance of X3C, where B = {b1 , . . . , b3k } and S = {S1 , . . . , Sn } is a
finite family of three-element subsets of B. Without loss of generality, we assume that n  k and
that k > 2 (if n < k then S does not contain a cover of B, and if k  2 then we can solve the problem
by brute force). We build an election E = (C,V ) such that:
1. If S contains a k-element cover of B, then the preferred candidate p can become the unique
Copeland winner of E via partitioning voters in the TP model, and
2. if r can be made to not uniquely win E via partitioning voters in the TP model, then S
contains a k-element cover of B.
Note that this implies that Copeland is resistant to both constructive and destructive control via
partitioning voters in the TP model, in both the nonunique-winner model and the unique-winner
model.
Our construction is an extension of the construction from Theorem 4.19. We let the candidate
set C be {p, r, s, b1 , . . . , b3k } and we let V be the following collection of voters:
1. We have k + 1 voters with preference s > r > B > p,
2. we have n  1 voters with preference B > p > r > s,
3. we have n  k + 2 voters with preference p > r > B > s, and
4. for each Si  S we have two voters, vi and vi , such that
(a) vi has preference r > B  Si > p > Si > s, and
322

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

(b) vi has preference r > Si > p > B  Si > s.
Let Vb  V be the collection of all the voters in V except for the k + 1 voters with preference s > r >
B > p. Note that Vb is exactly the voter collection used in the proof of Theorem 4.19 with candidate s
added as the least desirable candidate. Since s does not influence the differences between the scores
of the other candidates, the following claim follows immediately from the proof of Theorem 4.19.
Claim 4.22 If r can become a nonwinner of (C, Vb ) by deleting at most k voters, then S contains a
k-element cover of B.
Recall that we need to prove that if S contains a k-element cover of B, then p can be made the
unique Copeland winner of E via partitioning voters in the TP model, and that if r can be made to
not uniquely win E via partitioning voters in the TP model, then S contains a k-element cover of
B.
If S contains a k-element cover of B, say {Sa1 , . . . , Sak }, then we let the second subelection
consist of the k + 1 voters with preference s > r > B > p and voters va1 , . . . , vak . Then p is the
unique winner of the first subelection, s is the unique winner of the second subelection, and p
uniquely wins the final run-off between p and s.
To prove the second statement, suppose there is a partition of voters such that r is not a unique
winner of the resulting election in model TP. Note that in at least one of the subelections, without
loss of generality say the second subelection, a majority of the voters prefers r to all candidates in
{p, b1 , . . . , b3k }. Since r is the unique winner of every run-off he or she participates in, r cannot be
a winner of either subelection. Since r defeats every candidate in {p, b1 , . . . , b3k } in their head-tohead contests in the second subelection, in order for r not to be a winner of the second subelection,
it must certainly be the case that s defeats r in their head-to-head contest in the second subelection.
This implies that at most k voters from Vb can be part of the second subelection.
Now consider the first subelection. Note that r cannot be a winner of the first subelection. Then,
clearly, r cannot be a winner of the first subelection restricted to voters in Vb .16 By Claim 4.22 it
follows that S contains a k-element cover of B.

We now turn to the TE variant of control via partitioning voters. None of the remaining proofs
of Section 4.2 (i.e., none of the proofs of Theorems 4.23 through 4.26) is included here but they
each can be found in the full TR version (Faliszewski et al., 2008b). In particular, the proof of
Theorem 4.23 uses the exact same construction as in the proof of Theorem 4.21 and the proofs of
Theorems 4.24 and 4.25 use modifications thereof. To stay in sync with the structure of Faliszewski
et al. 2008b, the proof-providing full TR (where the proof structure, as mentioned above, depends
on the value of  ), we state each of Theorems 4.23 through 4.26 separately.
Theorem 4.23 Let  be a rational number such that 0   < 1. Copeland is resistant to constructive control via partitioning voters in the TE model (CCPV-TE), in both the nonunique-winner
model and the unique-winner model, for both the rational and the irrational voter model.
16. If r were a winner of the first subelection restricted to voters in Vb then r would certainly be a winner of the first
subelection without any restrictions: The voters in V  Vb prefer r to everyone except s, and (by the discussion in the
proof) s cannot be a winner of the first subelection. (Note that s can be a winner of at most one of the two subelections
and s is a winner of the second subelection.)

323

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Theorem 4.24 Copeland1 is resistant to constructive control via partitioning voters in the TE model
(CCPV-TE), in both the nonunique-winner model and the unique-winner model, for both the rational
and the irrational voter model.
Theorem 4.25 Copeland1 is resistant to destructive control via partitioning voters in the TE model
(DCPV-TE), in both the nonunique-winner model and the unique winner model, for both the rational
and the irrational voter model.
Finally, Theorem 4.26 states the resistance of Copeland , where  is a rational number with
0   < 1, to destructive control by partition of voters in the TE model. The proof of this result
(see Faliszewski et al., 2008b) extends the construction from the proof of Theorem 4.20 (see also
Faliszewski et al., 2008b) in the same way the proof of Theorem 4.21 extended the construction
from the proof of Theorem 4.19.
Theorem 4.26 Let  be a rational number such that 0   < 1. Copeland is resistant to destructive control via partitioning voters in the TE model (DCPV-TE), in both the nonunique-winner
model and the unique-winner model, for both the rational and the irrational voter model.
4.3 FPT Algorithm Schemes for Bounded-Case Control
Resistance to control is generally viewed as a desirable property in system design. However, suppose one is trying to solve resistant control problems. Is there any hope?
Bartholdi, Tovey, and Trick (1989b), in their seminal paper on NP-hard winner-determination
problems, suggested considering hard election problems for the cases of a bounded number of candidates or a bounded number of voters, and they obtained efficient-algorithm results for such cases.
Within the study of elections, this same approachseeking efficient fixed-parameter algorithms
has, for example, also been used (although somewhat tacitlysee the coming discussion in the second paragraph of Footnote 17) within the study of bribery (Faliszewski et al., 2006a; Faliszewski,
Hemaspaandra, & Hemaspaandra, 2006b). To the best of our knowledge, this bounded-case approach to finding the limits of resistance results has not been previously used to study control problems. In this section we do precisely that.
In particular, we obtain for resistant-in-general control problems a broad range of efficient algorithms for the case when the number of candidates or voters is bounded. Our algorithms are
not merely polynomial time. Rather, we give algorithms that prove membership in FPT (fixedparameter tractability, i.e., the problem is not merely individually in P for each fixed value of the
parameter of interest (voters or candidates), but indeed has a single P algorithm having degree
that is bounded independently of the value of the fixed number of voters or candidates) when the
number of candidates is bounded, and also when the number of voters is bounded. And we prove
that our FPT claims hold even under the succinct input modelin which the voters are input via
(preference-list, binary-integer-giving-frequency-of-that-preference-list) pairsand even in the
case of irrational voters. (One can imagine the succinct-representation case holding after some initial preprocessing of an elections ballots to compute the number of people casting each preference
that occurred.)
We obtain such algorithms for all the voter-control cases, both for bounded candidates and for
bounded voters, and for all the candidate-control cases with bounded candidates. On the other
hand, we show that for the resistant-in-general irrational-voter, candidate-control cases, resistance
still holds even if the number of voters is limited to being at most two.
324

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

We structure this section as follows. We first start by briefly stating our notions and notations.
We next state, and then prove, our fixed-parameter tractability results. Regarding those, we first
address FPT results for the (standard) constructive and destructive cases. We then show that in
many cases we can assert FPT results that are more general stillin particular, we will look at
extended control: completely pinpointing whether under a given type of control we can ensure
that at least one of a specified collection of Copeland Outcome Tables (to be defined later) can be
obtained. Finally, we give our resistance results.
4.3.1 N OTIONS

AND

N OTATIONS

The study of fixed-parameter complexity (see, e.g., Niedermeier, 2006) has been expanding explosively since it was parented as a field by Downey, Fellows, and others in the late 1980s and the 1990s.
Although the area has built a rich variety of complexity classes regarding parameterized problems,
for the purpose of the current paper we need focus only on one very important class, namely, the
class FPT. Briefly put, a problem parameterized by some value j is said to be fixed-parameter
tractable (equivalently, to belong to the class FPT) if there is an algorithm for the problem whose
running time is f ( j)nO(1) . (Note in particular that there is some particular constant for the big-oh
that holds for all inputs, regardless of what j value the particular input has.)
In our context, we will consider two parameterizations: bounding the number of candidates
and bounding the number of voters. We will use the same notations used throughout this paper to
describe problems, except we will postpend a -BV j  to a problem name to state that the number of
voters may be at most j, and we will postpend a -BC j  to a problem name to state that the number
of candidates may be at most j. In each case, the bound applies to the full number of such items
involved in the problem. For example, in the case of control by adding voters, the j must bound the
total of the number of voters in the election added together with the number of voters in the pool of
voters available for adding.
Typically, we have been viewing input votes as coming in each on a ballot. However, one can
also consider the case of succinct inputs, in which our algorithm is given the votes as (preferencelist, binary-integer-giving-frequency-of-that-preference-list) pairs. (We mention in passing that for
the adding voter cases, when we speak of succinctness we require that not just the always-voting
voters be specified succinctly but also that the pool of voters-available-to-be-added be specified
succinctly.) Succinct inputs have been studied extensively in the case of bribery (Faliszewski et al.,
2006a, 2006b), and speaking more broadly, succinctness-of-input issues are often very germane to
complexity classification (see, e.g., Wagner, 1986). Note that proving an FPT result for the succinct
case of a problem immediately implies an FPT result for the same problem (without the requirement
of succinct inputs being in place), and indeed is a stronger result, since succinctness can potentially
exponentially compress the input.
Finally, we would like to be able to concisely express many results in a single statement. To
do so, we borrow a notational approach from transformational grammar,
 It  h and iuse square brackets
runs
as an independent choice notation. So, for example, the claim She walks is a shorthand for
He

six assertions: It runs; She runs; He runs; It walks; She walks; and He walks. A special case is
the symbol 0
/ which, when it appearsin such a bracket, means that when unwound it should be
viewed as no text at all. For example,  Succinct
Copeland is fun asserts both Succinct Copeland
0/
is fun and Copeland is fun.

325

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

4.3.2 F IXED -PARAMETER T RACTABILITY R ESULTS
We immediately state our main results, which show that for all the voter-control cases FPT schemes
hold for both the bounded-voter and bounded-candidate cases, and for all the candidate-control
cases FPT schemes hold for the bounded-candidate cases.
Theorem 4.27 For each rational  , 0    1, and each choice from the independent choice brackets below, the specified parameterized (as j varies over N) problem is in FPT:


AV
  



 
DV 
C 
BV j
succinct
Copeland


.
C
D PV-TE BC j
0/
CopelandIrrational
PV-TP
Theorem 4.28 For each rational  , 0    1, and each choice from the independent choice brackets below, the specified parameterized (as j varies over N) problem is in FPT:


ACu
 AC 



 
    DC 



succinct
Copeland
C 
C  PC-TE 

 -BC j .
0/
D 
CopelandIrrational

PC-TP


RPC-TE
RPC-TP
Readers not interested in a discussion of those results and their proofs can at this point safely
skip to the next labeled section header.
Before proving the above theorems, let us first make a few observations about them. First, for
cases where under a particular set of choices that same case is known (e.g., due to the results of
Sections 4.1 and 4.2) to be in P even for the unbounded case, the above results are uninteresting
as they follow from the earlier results (such cases do not include any of the succinct cases, since
those were not treated earlier). However, that is a small minority of the cases. Also, for clarity as
to what cases are covered, we have included some items that are not formally needed. For example,
since FPT for the succinct case implies FPT for the no-succinctness-restriction case, and since FPT
for the irrationality-allowed case implies FPT for the rational-only case, the first two choice brackets
in each of the theorems could, without decreasing the results strength, be removed by eliminating
their 0
/ and Copeland  choices.
We now turn to the proofs. Since proving every case would be uninterestingly repetitive, we
will at times (after carefully warning the reader) prove the cases of one or two control types when
that is enough to make clear how the omitted cases proofs go.
Let us start with those cases that can be done simply by appropriately applied brute force.
We first prove Theorem 4.28.
Proof of Theorem 4.28. If we are limited to having at most j candidates, then for each of the
cases mentioned, the total number of ways of adding/deleting/partitioning candidates is simply a
(large) constant. For example, there will be at most (at most rather than exactly since j is
merely an upper bound on the number of candidates) 2 j possible run-off partitions and there will
be at most 2 j1 relevant ways of deleting candidates (since we cant (destructive case) or would
326

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

never (constructive case) delete the distinguished candidate). So we can brute-force try all ways of
adding/deleting/partitioning candidates, and for each such way can see whether we get the desired
outcome. This works in polynomial time (with a fixed degree independent of j and  ) even in the
succinct case, and even with irrationality allowed.
 Theorem 4.28
A brute-force approach similarly works for the case of voter control when the number of voters
is fixed. In particular, we prove the following subcase of Theorem 4.27.
Lemma 4.29 For each rational  , 0    1, and each choice from the independent choice brackets
below, the specified parameterized (as j varies over N) problem is in FPT:


AV
  

 
DV 
C 
succinct
Copeland
 -BV j .
C


CopelandIrrational
PV-TE
D
0/
PV-TP
When considering BV j  casesnamely in this proof and in the resistance section starting on
page 334we will not even discuss succinctness. The reason is that if the number of voters is
bounded, say by j, then succinctness doesnt asymptotically change the input sizes interestingly,
since succinctness at very best would compress the vote description by a factor of about jwhich
in this case is a fixed constant (relative to the value of the parameterization, which itself is j).
Proof of Lemma 4.29. If we are limited to having at most j voters, note that we can, for each
of these four types of control, brute-force check all possible approaches to that type of control. For
example, for the case of control by deleting voters, we clearly have no more than 2 j possible vote
deletion choices, and for the case of control by partitioning of voters, we again have at most 2 j
partitions (into V1 and V V1 ) to consider. And 2 j is just a (large) constant. So a direct brute-force
check yields a polynomial-time algorithm, and by inspection one can see that its run-times degree
is bounded above independently of j.
 Lemma 4.29
We now come to the interesting cluster of FPT cases: the voter-control cases when the number of
candidates is bounded. Now, at first, one might think that we can handle this, just as the above cases,
via a brute-force approach. And that is almost correct: One can get polynomial-time algorithms
for these cases via a brute-force approach. However, for the succinct cases, the degrees of these
algorithms will be huge, and will not be independent of the bound, j, on the number of candidates.
For example, even in the rational case, one would from this approach obtain run-times with terms
such as nkCk! . That is, one would obtain a family of P-time algorithms, but one would not have an
FPT algorithm.
To overcome this obstacle, we will employ Lenstras (1983) algorithm for bounded-variablecardinality integer programming. Although Lenstras algorithm is truly amazing in its power, even
it will not be enough to accomplish our goal. Rather, we will use a scheme that involves a fixed
(though very large) number of Lenstra-type programs each being focused on a different resolution
path regarding the given problem.
What we need to prove, to complete the proof of Theorem 4.27, is the following lemma.
Lemma 4.30 For each rational  , 0    1, and each choice from the independent choice brackets
below, the specified parameterized (as j varies over N) problem is in FPT:
327

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE



AV

 



succinct
Copeland
DV 
C 
 -BC j .
C

0/
D PV-TE
CopelandIrrational
PV-TP
Let us start by recalling that, regarding the first choice bracket, the succinct case implies the
0
/ case, so we need only address the succinct case. Recall also that, regarding the second choice
bracket, for each rational  , 0    1, the CopelandIrrational  case implies the Copeland  case,
so we need only address the CopelandIrrational case.
So all that remains is to handle each pair of choices from the third and forth choice brackets. To
prove every case would be very repetitive. So we will simply prove in detail a difficult, relatively
representative case, and then will for the other cases either mention the type of adjustment needed
to obtain their proofs, or will simply leave it as a simple but tedious exercise that will be clear, as to
how to do, to anyone who reads this section.
So, in particular, let us prove the following result.
Lemma 4.31 For each rational  , 0    1, the following parameterized (as j varies over N)
problem is in FPT: succinct-CopelandIrrational -CCPV-TP-BC j .
Proof. Let  , 0    1, be some arbitrary, fixed rational number. In particular, suppose that 
can be expressed as b/d, where b  N, d  N+ , b and d share no common integer divisor greater
than 1, and if b = 0 then d = 1. We wont explicitly invoke b and d in our algorithm, but each time
we speak of evaluating a certain set of pairwise outcomes with respect to  , one can think of it as
evaluating that with respect to a strict pairwise win giving d points, a pairwise tie giving b points,
and a strict pairwise loss giving 0 points.
We need a method of specifying the pairwise outcomes among a set of candidates. To do this,
we will use the notion of a Copeland outcome table over a set of candidates. This will not actually
be a table, but rather will be a function (a symmetric oneit will not be affected by the order of
its two arguments) that, when given a pair of distinct candidates as inputs, will say which of the
three possible outcomes allegedly happened: Either there is a tie, or one candidate won, or the other
candidate won. Note that a COT is simply a representation of an election graph (see Section 4.1.2).
j
So, in a j-candidate election, there are exactly 3(2) such functions. (We will not care about the names
of the candidates, and so will assume that the tables simply use the names 1 through j, and that we
match the names of the actual candidates with those integers by linking them lexicographically, i.e.,
the lexicographically first candidate will be associated with the integer 1 and so on.) Let us call a
j-candidates Copeland outcome table a j-COT.
We
need
to
build
our
algorithm
that
shows
that
the
problem
succinct-CopelandIrrational -CCPV-TP-BC j , j  N, is in FPT. So, let j be some fixed integer
bound on the number of candidates.17
17. We will now seem to specify the algorithm merely for this bound. However, it is important to note that we do enough
to establish that there exists a single algorithm that fulfills the requirements of the definition of FPT. In particular,
the specification we are about to give is sufficiently uniform that one can simply consider a single algorithm that, on
a given input, notes the value of j, the number of candidates, and then does what the  j algorithm we are about to
specify does.
We take this moment to mention in passing that our earlier work, Faliszewski et al. 2006a and (this is an expanded, full version of that) Faliszewski et al. 2006b, that gives P-time algorithms for the fixed parameter (fixed

328

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

For each j -COT, T1 ,
For each j -COT, T2 ,
Do
If
when we have a CopelandIrrational election (involving all the input voters), with respect to  , between all the candidates who win under T1 with respect to  , and all
the candidates who win under T2 with respect to  , the preferred candidate of the
input problem is a winner,
then
create and run the integer linear program constraint feasibility problem that checks
whether there exists a partition of the voters such that the first subelection has j COT T1 and the second subelection has j -COT T2 , and if so, then accept.

Figure 5: The top-level code for the case succinct-CopelandIrrational -CCPV-TP-BC j .
Let us suppose we are given an input instance. Let j  j be the number of candidates in this
instance (recall that j is not the number of candidates, but rather is an upper bound on the number
of candidates).
The top level of our algorithm is specified by the pseudocode in Figure 5. (Although this algorithm seemingly is just trying to tell whether the given control is possible for the given case, rather
than telling how to partition to achieve that control, note that which iteration through the double
loop accepts and the precise values of the variables inside the integer linear program constraint feasibility problem that made that iteration be satisfied will in fact tell us precisely what the partition
is that makes the preferred candidate win.)
Now, note that the total number of j -COTs that exist (we do not need to care whether all can
j
j
be realized via actual votes) is 3( 2 ) . So the code inside the two loops executes at most 9( 2 ) times,
which is constant-bounded since j  j, and we have fixed j.
So all that remains is to give the integer linear program constraint feasibility problem mentioned
inside the inner loop. The setting here can sometimes be confusing, e.g., when we speak of constants
that can grow without limit. It is important to keep in mind that in this integer linear program
constraint feasibility problem, the number of variables and constraints is constant (over all inputs),
and the integer linear program constraint feasibility problems constants (one may prefer the word
candidate and fixed voters) cases in fact, in all such claims we have in that work, implicitly is giving FPT algorithms, even though those papers dont explicitly note that. The reason is generally the same as why that is true in
this papernamely, the Lenstra technique is not just powerful but is also ideally suited for FPT algorithms and for
being used inside algorithms that are FPT algorithms. Most interestingly, the Lenstra approach tends to work even on
succinct inputs, and so the FPT comment we made applies even to those results in our abovementioned earlier papers
that are about the succinct-inputs case of fixed-number-of-candidates and fixed-number-of-voters claims. (The fixednumber-of-candidates and fixed-number-of-voters Dodgson winner/score work of Bartholdi et al., 1989b, is known
to be about FPT algorithmsdue to the proof of Bartholdi et al., 1989b, itself, see the discussion in Faliszewski et al.,
2006a, see also Betzler, Guo, and Niedermeier, 2008. Although the paper of Bartholdi et al., 1989b, doesnt address
the succinct input model, Faliszewski et al., 2006a, notes that their approach works fine even in the succinct cases of
the winner problem. That is true not just for the P-ness of their algorithms even in the succinct case, but also for the
FPT-ness of their algorithms even in the succinct case.)

329

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

coefficients, if that makes things clearer) are the only things that change with respect to the input.
This is the framework that allows us to invoke Lenstras powerful algorithm.
We first specify the set of constants of the integer linear program constraint feasibility problem.
j
In particular, for each i, 1  i  2( 2 ) , we will have a constant, n ,18 that is the number of input voters
i



j
whose vote is of the ith type (among the 2( 2 ) possible vote possibilities; keep in mind that voters
j
are allowed to be irrational, thus the value 2( 2 ) is correct). Note that the number of these constants

that we have is itself constant-bounded (for fixed j), though of course the values that these constants
(of the integer linear program constraint feasibility problem) take on can grow without limit.
In addition, let us define some constants that will not vary with the input but rather are simply a
notational shorthand that we will use to describe how the integer linear program constraint feasibility
problem is defined (what constraints occur in it). In particular, for each i and  such that 1  i  j ,
1    j , and i 6= , let val1i, be 1 if T1 asserts that (in their head-to-head contest) i ties or defeats
, and let it be 0 if T1 asserts that (in their head-to-head contest) i loses to . Let val2i, be identically
defined, except with respect to T2 . Informally put, these values will be used to let our integer linear
program constraint feasibility problem seek to enforce such a win/loss/tie pattern with respect to the
given input vote numbers and the given type of allowed control action.
The integer linear program constraint feasibility problems variables, which of course are all
j
j
integer variables, are the following 2( 2 ) variables. For each i, 1  i  2( 2 ) , we will have a variable,


j
mi , that represents how many of the ni voters having the ith among the 2( 2 ) possible vote types go
into the first subelection.
Finally, we must specify the constraints of our integer linear program constraint feasibility problem. We will have three groups of constraints.
The first constraint group is enforcing that plausible numbers are put in the first partition. In
j
particular, for each i, 1  i  2( 2 ) , we have the constraints 0  m and m  n .

i

i

i

The second constraint group is enforcing that after the partitioning we really do have in the first
subelection a situation in which all the pairwise contests come out exactly as specified by T1 . In
particular, for each i and  such that 1  i  j , 1    j , and i 6= , we do the following. Consider
the equation
(




ma ) OP (


j
{a | 1  a  2( 2 ) and in votes of type
a it holds that i is preferred to }



ma ),

(4.a)

j
{a | 1  a  2( 2 ) and in votes of type
a it holds that  is preferred to i}



j
where a in each sum varies over the 2( 2 ) possible preferences. If val1(i, ) = 1 we will have a
constraint of the above form with OP set to . If val1(, i) = 1 we will have a constraint of the
above form with OP set to . Note that this means that if val1(i, ) = val1(, i) = 1, i.e., those
two voters are purported to tie, we will add two constraints.
The third constraint group has the same function as the second constraint group, except it regards
the second subelection rather than the first subelection. In particular, for each i and  such that

18. Again, as discussed in the immediately previous paragraph, when we say that, for example, the ni are constants of the
integer linear program constraint feasibility problem, we do not mean that they are constants in any complexity sense,
but rather that they are the constantsin the sense of being the coefficientsof the integer linear program constraint
feasibility problem. By saying that, we do not mean to imply that the number of voters is bounded by some global
value over all cases.

330

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

1  i  j , 1    j , and i 6= , we do the following. Consider again equation (4.a) from above,
except with each of the two occurrences of ma replaced by na  ma . If val2(i, ) = 1 we will have
a constraint of that form with OP set to . If val2(, i) = 1 we will have a constraint of that
form with OP set to . As above, this means that if val2(i, ) = val2(, i) = 1, we will add two
constraints.
This completes the specification of the integer linear programming constraint feasibility problem.
Note that our top-level code, from Figure 5, clearly runs within polynomial time relative to
even the succinct-case input to the original CCPV-TP problem, and that that polynomials degree
is bounded above independently of j. Note in particular that our algorithm constructs at most a
large constant (for j fixed) number of integer linear programming constraint feasibility problems,
and each of those is itself polynomial-sized relative to even the succinct-case input to the original
CCPV-TP problem, and that polynomial sizes degree is bounded above independently of j. Further, note that the integer linear programming constraint feasibility problems clearly do test what
they are supposed to testmost importantly, they test that the subelections match the pairwise
outcomes specified by j -COTs T1 and T2 . Finally and crucially, by Lenstras (1983) algorithm (see
also Downey, 2003, and Niedermeier, 2002, which are very clear regarding the linears later in this
sentence), since this integer linear programming constraint feasibility problem has a fixed number of
constraints (and in our case in fact also has a fixed number of variables), it can be solvedrelative to
its size (which includes the filled-in constants, such as our ni for example, which are in effect inputs
to the integer programs specification)via a linear number of arithmetic operations on linear-sized
integers. So, overall, we are in polynomial time even relative to succinctly specified input, and the
polynomials degree is bounded above independently of j. Thus we have established membership
in the class FPT.

We now describe very briefly how the above proof of Lemma 4.31 can be
adjusted
cases
from Lemma 4.30, namely, the cases

to handle all the
  partition
 

succinct
Copeland
C
PV-TE
C
-BC j . As noted before, the first two brack0/
CopelandIrrational
D
PV-TP
ets can be ignored, as we have chosen the more demanding choice for each. Let us discuss the other
variations. Regarding changing from constructive to destructive, in Figure 5 change is a winner
to is not a winner. Regarding changing from PV-TP to PV-TE, in the if block in Figure 5
change each all the candidates who win to the candidate who wins (if there is a unique candidate
who wins).
    

 
C
AV
succinct
Copeland
C
-BC j .
The only remaining cases are the cases
CopelandIrrational
D
DV
0/
However, these cases are even more straightforward than the partition cases we just covered, so for
space reasons we will not write them out, but rather will briefly comment on these cases. Basically,
j
ones top-level code for these cases loops over all j -COTs, and for each (there are 3( 2 ) ) checks
whether the right outcome happens under that j -COT (i.e., the distinguished candidate either is
(constructive case) or is not (destructive case) a winner), and if so, it runs Lenstras algorithm on
an integer linear programming constraint feasibility problem to see whether we can by the allowed
action (adding/deleting) get to a state where that particular j -COT matches our (after addition or
deletion of voters) election. In the integer program, the variables will be the obvious ones, namely,
j
for each i, 1  i  2( 2 ) , we will have a variable, m , that describes how many voters of type i to
i

331

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

add/delete. As our key constants (of the integer linear program constraint feasibility problem), we
j
will have, for each i, 1  i  2( 2 ) , a value, n , for the number of type i voters in the input. Also,
i



j
if this is a problem about addition of voters, we will have additional constants, nbi , 1  i  2( 2 ) ,
representing the number of type i voters among the pool, W , of voters available for addition. And
if our problem has an internal k (a limit on the number of additions or deletions), we enforce that
with the natural constraints, as do we also with the natural constraints enforce the obvious relationships between the mi , ni , nbi , and so on. Most critically, we have constraints ensuring that after the
additions/deletions specified by the mi , each pairwise outcome specified by the j -COT is realized.
Finally, although everything in Section 4.3 (both the part so far and the part to come) is written
for the case of the nonunique-winner model, all the results hold analogously in the unique-winner
model, with the natural, minor proof modifications. (Also, we mention in passing that due to the
connection, found in Footnote 5 of Hemaspaandra et al., 2007a, between unique-winner destructive
control and nonunique-winner constructive control, one could use some of our nonunique-winner
constructive-case results to indirectly prove some of the unique-winner destructive-case results.)

4.3.3 FPT

AND

E XTENDED C ONTROL

In this section, we look at extended control. By that we do not mean changing the ten standard
control notions of adding/deleting/partitioning candidates/voters. Rather, we mean generalizing past
merely looking at the constructive (make a distinguished candidate a winner) and the destructive
(prevent a distinguished candidate from being a winner) cases. In particular, we are interested in
control where the goal can be far more flexibly specified, for example (though in the partition cases
we will be even more flexible than this), we will allow as our goal region any (reasonablethere
are some time-related conditions) subcollection of Copeland outcome tables (specifications of
who won/lost/tied each head-to-head contest). Since from a Copeland outcome table, in concert
with the current  , one can read off the CopelandIrrational scores of the candidates, this allows us a
tremendous range of descriptive flexibility in specifying our control goals, e.g., we can specify a
linear order desired for the candidates with respect to their CopelandIrrational scores, we can specify
a linear-order-with-ties desired for the candidates with respect to their CopelandIrrational scores, we
can specify the exact desired CopelandIrrational scores for one or more candidates, we can specify that
we want to ensure that no candidate from a certain subgroup has a CopelandIrrational score that ties
or defeats the CopelandIrrational score of any candidate from a certain other subgroup, etc.19 Later in
this section we will give a list repeating some of these examples and adding some new examples.
All the FPT algorithms given in the previous section regard, on their surface, the standard control
problem, which tests whether a given candidate can be made a winner (constructive case) or can be
precluded from being a winner (destructive case). We now note that the general approaches used in
that section in fact yield FPT schemes even for the far more flexible notions of control mentioned
19. We mention up front that that initial example list applies with some additional minor technical caveats. Those
examples were speaking as if in the final election we have all the candidates receiving CopelandIrrational scores in the
final election. But in fact in the partition cases this is not (necessarily) so, and so in those cases we will focus on
the Copeland outcome tables most natural to the given case. For example, in control by partition of voters, we will
focus on subcollections of pairs of Copeland outcome tables for the two subelections. Also, though our Copeland
outcome tables as defined below are not explicitly labeled with candidate names, but rather use a lexicographical
correspondence with the involved candidates, in some cases we wouldthough we dont repeat this in the discussion
belowneed to allow the inclusion in the goal specification of the names of the candidates who are in play in a given
table or tables, most particularly, in the cases of addition and deletion of candidates, and in some partition cases.

332

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

above. In fact, one gets, for all the FPT cases covered in the previous section, FPT algorithms for the
extended-control problem for those casesvery loosely put, FPT algorithms that test, for virtually
any natural collection of outcome tables (as long as that collection itself can be recognized in a way
that doesnt take too much running time, i.e., the checking time is polynomial and of a degree that
is bounded independently of j), whether by the given type of control one can reach one of those
outcome tables.
Let us discuss this in a bit more detail. A key concept used inside the proof of Lemma 4.31
was that of a Copeland outcome tablea function that for each distinct pair of candidates specifies
either a tie or specifies who is the (not tied) winner in their pairwise contest. Let us consider the
control algorithm given in the proof of that lemma, and in particular let us consider the top-level
code specified in Figure 5. That code double-loops over size j Copeland outcome tables (a.k.a. j COTs), regarding the subpartitions, and for each case when the outcome tables subelection cases,
followed by the final election that they imply, correspond to the desired type of constructive (the
distinguished person wins) or destructive (the distinguished person does not win) outcome, we check
whether those two j -COTs can be made to hold via the current type of control (for the case being
discussed, PV-TP).
However, note that simply by easily varying that top-level code we can obtain a natural FPT
algorithm (a single algorithm, see Footnote 17 the analogue of which applies here) for any question
of whether via the allowed type of control one can reach any run-time-quick-to-recognize collection
of pairs of j -COTs (in the subelection), or even whether a given candidate collection and one of a
given (run-time-quick-to-recognize) j -COT collection over that candidate collection ( j being the
size of that final-round candidate collection) can be reached in the final election. This is true not
just for the partition cases (where, informally put, we would do this by, in Figure 5, changing the
condition inside the if to instead look for membership in that collection of j -COTs20 ) but also for
all the cases we attacked via Lenstras method (though for the nonpartition cases we will typically
single-loop over Copeland outcome tables that may represent the outcome after control is exerted;
also, for some of these cases, the caveat at the end of Footnote 19 will apply). And it is even easier
to notice that for those cases we attacked by direct brute force this also holds.
So, as just a few examples (some echoing the start of this section, and some new), all the following have (with the caveats mentioned above about needed names attached, e.g., in cases of candidate
addition/deletion/partition, and regarding the partition cases focusing not necessarily directly on the
20. Let us discuss this a bit more formally, again using PV-TP as an example. Consider any family of boolean functions
Fj , j  N, such that each Fj is computable, even when its first argument is succinctly specified, in polynomial time
with the polynomial degree bounded independently of j. Now, consider changing Figure 5s code to:
For each j -COT, T1 ,
For each j -COT, T2 ,
If (Fj (input, T1 , T2 ))
then    .
Note that this change gives an FPT control scheme for a certain extended control problem. In particular, it does so
for the extended control problem whose goal is to ensure that we can realize at least one of the set of (T1 , T2 ) such
that Fj ( j being the number of candidates in the particular input), given as its inputs the problems input, T1 , and T2
evaluates to true. That is, the Fj functions are recognizing (viewed a bit differently, are defining) the goal set of the
extended control problem.
From the input, T1 , and T2 we can easily tell the scores in the final election. So this approach can be used to
choose as our extended-control goals natural features of the final election.

333

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

final table) FPT extended control algorithms for all the types of control and boundedness cases for
which the FPT results of the previous section are stated.
1. Asking whether under the stated action one can obtain in the final election (simply in the
election in the case when there is no partitioning) the outcome that all the CopelandIrrational system scores of the candidates precisely match the relations of the lexicographic names of
the candidates.
2. More generally than that, asking whether under the stated action one can obtain in the final
election (simply in the election in the case when there is no partitioning) a certain linearorder-without-ties regarding the CopelandIrrational -system scores of the candidates.
3. More generally still, asking whether under the stated action one can obtain in the final election
(simply in the election in the case when there is no partitioning) a certain linear-order-withties regarding the CopelandIrrational -system scores of the candidates.
4. Asking whether under the stated action one can obtain in the final election (simply in the
election in the case when there is no partitioning) the situation that exactly 1492 candidates
tie as winner regarding their CopelandIrrational -system scores.
5. Asking whether under the stated action one can obtain in the final election (simply in the
election in the case when there is no partitioning) the situation that no two candidates have
the same CopelandIrrational -system scores as each other.
Again, these are just a very few examples. Our point is that the previous section is flexible enough to
address not just constructive/destructive control, but also to address far more general control issues.
4.3.4 R ESISTANCE R ESULTS
Theorems 4.27 and 4.28 give FPT schemes for all voter-control cases with bounded voters, for all
voter-control cases with bounded candidates, and for all candidate-control cases with bounded candidates. This might lead one to hope that all the cases admit FPT schemes. However, the remaining
type of case, the candidate-control cases with bounded voters, does not follow this pattern. In fact,
we note that for CopelandIrrational all the candidate-control cases that we showed earlier in this paper (i.e., without bounds on the number of voters) to be resistant remain resistant even for the case
of bounded voters. This resistance holds even when the input is not in succinct format, and so it
certainly also holds when the input is in succinct format.
The reason for this is that, for the case of irrational voters, with just two voters (with preferences
over j candidates) any given j-COT can be achieved. To do this, for each distinct pair of candidates
i and , to have i preferred in their pairwise contest have both voters prefer i to , to have  preferred
in their pairwise contest have both voters prefer  to i, and to have a tie in the pairwise contest have
one voter prefer  to i and one voter prefer i to . Since in the proofs of resistance for candidate
control, we identified elections with their election graphs, i.e., with their COTs, it is not hard to see
that all these resistance proofs carry over even to the case of two irrational voters.
The only open cases remaining regard the rational-voter, candidate-control, bounded-voter
cases. We note that Betzler and Uhlmann (2008) have recently resolved some of these open issues.

334

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

5. Control in Condorcet Elections
In this section we show that Condorcet elections are resistant to constructive control via deleting
voters (CCDV) and via partition of voters (CCPV). These results were originally claimed in the
seminal paper of Bartholdi et al. (1992), but the proofs there were based on the assumption that
a voter can be indifferent between several candidates. Their model of elections did not allow that
(and neither does ours). Here we show how one can obtain these results in the case when the voters
preference lists are linear orderswhich is both their model and ours.
Recall that a candidate c of election E = (C,V ) is a Condorcet winner of E if he or she defeats
all other candidates in their head-to-head contests. Alternatively, one could say that a candidate c
is a Condorcet winner of election E if and only if he or she has Copeland0 score of kCk  1. Since
each election can have at most one Condorcet winner, it doesnt make sense here to differentiate
between the unique-winner and the nonunique-winner models. (We pass on to the reader a referees
comment that in the very different system known as weak Condorcet elections, whose winners are
all candidates who beat or tie each other candidate in head-to-head elections, one can have more
than one winner.)
Theorem 5.1 Condorcet elections are resistant to constructive control via deleting voters.
Proof. This follows immediately from the proof of Theorem 4.19. Note that a Condorcet winner
is always a unique Copeland winner, for each rational  with 0    1, and note that in the proof
of Theorem 4.19, if S contains a k-element cover of B, then we can delete k voters such that in the
resulting election p defeats every other candidate in their head-to-head contest, i.e., p is a Condorcet
winner in the resulting election.

Before we proceed with our proof of resistance for the case of constructive control via partition
of voters (CCPV), we have to mention a slight quirk of Bartholdi, Tovey, and Tricks model of voter
partition. If one reads their paper carefully, it becomes apparent that they have a quiet assumption
that each given set of voters can only be partitioned into subelections that each elect exactly one
winner, thus severely restricting the chairs partitioning possibilities. That was why Hemaspaandra
et al. (2007a) replaced Bartholdi, Tovey, and Tricks convention with the more natural ties-promote
and ties-eliminate rules (see the discussion in Hemaspaandra et al., 2007a), but for this current
section of our paper we go back to Bartholdi, Tovey, and Tricks model, since our goal here is to
reprove their results without breaking their model.
Theorem 5.2 Condorcet elections are resistant to constructive control via partitioning voters
(CCPV) in Bartholdi, Tovey, and Tricks model (see the paragraph above).
Proof. The proof follows via a reduction from the X3C problem. In fact, we use exactly the
construction from the proof of Theorem 4.21. Let E = (C,V ) be the election constructed in that
proof.
Since s is the only candidate that p defeats in a head-to-head contest, the only way for p to
become a winner via partitioning voters is to guarantee that p wins within his or her subelection and
that s wins within the other one. (Note that since p is not a Condorcet winner, p cannot win in both
subelections.)
If S contains a k-element cover, say, {Sa1 , . . . , Sak }, then letting Vp = Vb  {va1 , . . . , vak } and
Vs = V Vp will make p the Condorcet winner in this CCPV scenario.
335

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

For the converse, let (Vp ,Vs ) be a partition of the collection of voters such that p is the global
Condorcet winner in the CCPV scenario where we use two subelections, one with voters Vp and
one with voters Vs . Via the above paragraph we can assume, without loss of generality, that p is the
Condorcet winner in (C,Vp ) and that s is the Condorcet winner in (C,Vs ). Since the k + 1 voters in
V  Vb rank s first and rank p last, we can assume that Vs contains these k + 1 voters (i.e., the voters
with preference s > r > B > p). Also, Vs contains at most k voters from Vb , as otherwise s would
certainly not be a Condorcet winner in (C,Vs ).
As a result, p can be made the Condorcet winner of (C, Vb ) by deleting at most k voters. It
follows from Claim 4.22 that S contains a k-element cover of B.


6. Conclusions
We have shown that from the computational point of view the election systems of Llull and Copeland
(i.e., Copeland0.5 ) are broadly resistant to bribery and constructive procedural control, regardless of
whether the voters are required to have rational preferences. It is rather charming that Llulls 700year-old system shows perfect resistance to bribery and more resistances to (constructive) control
than any other natural system (even far more modern ones) with an easy winner-determination
procedureother than Copeland , 0 <  < 1is known to possess, and this is even more remarkable when one considers that Llulls system was defined long before control of elections was even
explicitly studied. Copeland0.5 voting matches Llulls perfect resistance to bribery and in addition
has perfect resistance to (constructive) control.
A natural open direction would be to study the complexity of control for additional election
systems. It would be particularly interesting to find existing, natural voting systems that have
polynomial-time winner determination procedures but that are resistant to all standard types of both
constructive and destructive control. It would also be extremely interesting to find single results that
classify, for broad families of election systems, precisely what it is that makes control easy or hard,
i.e., to obtain dichotomy meta-results for control (see Hemaspaandra and Hemaspaandra, 2007, for
some discussion regarding work of that flavor for manipulation).

Acknowledgments
We thank Nadja Betzler, Felix Brandt, Preetjot Singh, Frieder Stolzenburg, Dietrich Stoyan, the
anonymous AAAI-07, AAIM-08, COMSOC-08, and JAIR referees, and JAIR handling editor Jeff
Rosenschein for helpful comments, suggestions, and guidance. This work was supported in part
by AGH-UST grant 11.11.120.777, DFG grants RO-1202/{9-3, 11-1, 12-1}, NSF grants CCR0311021, CCF-0426761, and IIS-0713061, the Alexander von Humboldt Foundations TransCoop
program, the European Science Foundations EUROCORES program LogICCC, and Friedrich Wilhelm Bessel Research Awards to Edith Hemaspaandra and Lane A. Hemaspaandra. This work was
done in part during visits by Piotr Faliszewski, Edith Hemaspaandra, and Lane A. Hemaspaandra to
Heinrich-Heine-Universitat Dusseldorf, during visits by Jorg Rothe to the University of Rochester,
and while Piotr Faliszewski was at the University of Rochester. This paper combines and extends
University of Rochester Computer Science Department Technical Reports TR-913 and TR-923,
and some of this papers results have been presented at the 22nd AAAI Conference on Artificial
Intelligence (AAAI-07) in Faliszewski et al. 2007, at the October 2007 Dagstuhl Seminar on Computational Issues in Social Choice, at the 4th International Conference on Algorithmic Aspects
336

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

in Information and Management (AAIM-08) in Faliszewski, Hemaspaandra, Hemaspaandra, and
Rothe 2008a, and at the 2nd International Workshop on Computational Social Choice (COMSOC08).

References
Ahuja, R., Magnanti, T., & Orlin, J. (1993). Network Flows: Theory, Algorithms, and Applications.
Prentice-Hall.
Altman, A., & Tennenholtz, M. (2007). An axiomatic approach to personalized ranking systems. In
Proceedings of the 20th International Joint Conference on Artificial Intelligence, pp. 1187
1192. AAAI Press.
Arrow, K. (1951 (revised editon, 1963)). Social Choice and Individual Values. John Wiley and
Sons.
Austen-Smith, D., & Banks, J. (2000). Positive Political Theory I: Collective Preference. University
of Michigan Press.
Bartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social Choice
and Welfare, 8(4), 341354.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989a). The computational difficulty of manipulating an
election. Social Choice and Welfare, 6(3), 227241.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989b). Voting schemes for which it can be difficult to tell
who won the election. Social Choice and Welfare, 6(2), 157165.
Bartholdi, III, J., Tovey, C., & Trick, M. (1992). How hard is it to control an election? Mathematical
and Computer Modeling, 16(8/9), 2740.
Betzler, N., Guo, J., & Niedermeier, R. (2008). Parameterized computational complexity of Dodgson and Young elections. In Proceedings of the 11th Scandinavian Workshop on Algorithm
Theory, pp. 402413. Springer-Verlag Lecture Notes in Computer Science #5124.
Betzler, N., & Uhlmann, J. (2008). Parameterized complexity of candidate control in elections and
related digraph problems. In Proceedings of the 2nd Annual International Conference on
Combinatorial Optimization and Applications, pp. 4353. Springer-Verlag Lecture Notes in
Computer Science #5156.
Brams, S., & Sanver, R. (2006). Critical strategies under approval voting: Who gets ruled in and
ruled out. Electoral Studies, 25(2), 287305.
Condorcet, J. (1785). Essai sur lApplication de LAnalyse a la Probabilite des Decisions Rendues a
la Pluralite des Voix. Facsimile reprint of original published in Paris, 1972, by the Imprimerie
Royale.
Conitzer, V., & Sandholm, T. (2003). Universal voting protocol tweaks to make manipulation hard.
In Proceedings of the 18th International Joint Conference on Artificial Intelligence, pp. 781
788. Morgan Kaufmann.
Conitzer, V., & Sandholm, T. (2006). Nonexistence of voting rules that are usually hard to manipulate. In Proceedings of the 21st National Conference on Artificial Intelligence, pp. 627634.
AAAI Press.
337

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Conitzer, V., Sandholm, T., & Lang, J. (2007). When are elections with few candidates hard to
manipulate? Journal of the ACM, 54(3), Article 14.
Copeland, A. (1951). A reasonable social welfare function. Mimeographed notes from a Seminar
on Applications of Mathematics to the Social Sciences, University of Michigan.
Cormen, T., Leiserson, C., Rivest, R., & Stein, C. (2001). Introduction to Algorithms (second
edition). MIT Press/McGraw Hill.
Downey, R. (2003). Parameterized complexity for the skeptic. In Proceedings of the 18th Annual
IEEE Conference on Computational Complexity, pp. 147168. IEEE Computer Society Press.
Duggan, J., & Schwartz, T. (2000). Strategic manipulability without resoluteness or shared beliefs:
GibbardSatterthwaite generalized. Social Choice and Welfare, 17(1), 8593.
Dwork, C., Kumar, R., Naor, M., & Sivakumar, D. (2001). Rank aggregation methods for the web.
In Proceedings of the 10th International World Wide Web Conference, pp. 613622. ACM
Press.
Elkind, E., & Lipmaa, H. (2005). Small coalitions cannot manipulate voting. In Proceedings of the
9th International Conference on Financial Cryptography and Data Security, pp. 285297.
Springer-Verlag Lecture Notes in Computer Science #3570.
Ephrati, E., & Rosenschein, J. (1997). A heuristic technique for multi-agent planning. Annals of
Mathematics and Artificial Intelligence, 20(14), 1367.
Erdelyi, G., Hemaspaandra, L., Rothe, J., & Spakowski, H. (2007). On approximating optimal
weighted lobbying, and frequency of correctness versus average-case polynomial time. In
Proceedings of the 16th International Symposium on Fundamentals of Computation Theory,
pp. 300311. Springer-Verlag Lecture Notes in Computer Science #4639.
Erdelyi, G., Nowak, M., & Rothe, J. (2008a). Sincere-strategy preference-based approval voting
broadly resists control. In Proceedings of the 33rd International Symposium on Mathematical
Foundations of Computer Science, pp. 311322. Springer-Verlag Lecture Notes in Computer
Science #5162.
Erdelyi, G., Nowak, M., & Rothe, J. (2008b). Sincere-strategy preference-based approval voting fully resists constructive control and broadly resists destructive control. Tech. rep.
arXiv:0806.0535 [cs.GT], arXiv.org. A precursor appears as (Erdelyi, Nowak, & Rothe,
2008a). Journal version to appear in Mathematical Logic Quarterly.
Faliszewski, P. (2008). Nonuniform bribery (short paper). In Proceedings of the 7th International
Conference on Autonomous Agents and Multiagent Systems, pp. 15691572. International
Foundation for Autonomous Agents and Multiagent Systems.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. The complexity of bribery in elections.
Journal of Artificial Intelligence Research. To appear.
Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2006a). The complexity of bribery in elections. In Proceedings of the 21st National Conference on Artificial Intelligence, pp. 641646.
AAAI Press. Journal version to appear as (Faliszewski, Hemaspaandra, & Hemaspaandra, to
appear).

338

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

Faliszewski, P., Hemaspaandra, E., & Hemaspaandra, L. (2006b). How hard is bribery in elections?
Tech. rep. TR-895, Department of Computer Science, University of Rochester, Rochester,
NY. Revised, September 2006.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007). Llull and Copeland
voting broadly resist bribery and control. In Proceedings of the 22nd AAAI Conference on
Artificial Intelligence, pp. 724730. AAAI Press.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2008a). Copeland voting fully
resists constructive control. In Proceedings of the 4th International Conference on Algorithmic Aspects in Information and Management, pp. 165176. Springer-Verlag Lecture Notes in
Computer Science #5034.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2008b). Llull and Copeland
voting computationally resist bribery and control. Tech. rep. arXiv:0809.4484 [cs.GT], Computing Research Repository, http://www.acm.org/repository/.
Faliszewski, P., Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2009). A richer understanding of
the complexity of election systems. In Ravi, S., & Shukla, S. (Eds.), Fundamental Problems
in Computing: Essays in Honor of Professor Daniel J. Rosenkrantz, pp. 375406. Springer.
Faliszewski, P., Hemaspaandra, E., & Schnoor, H. (2008). Copeland voting: Ties matter. In Proceedings of the 7th International Conference on Autonomous Agents and Multiagent Systems,
pp. 983990. International Foundation for Autonomous Agents and Multiagent Systems.
Friedgut, E., Kalai, G., & Nisan, N. (2008). Elections can be manipulated often. In Proceedings
of the 49rd IEEE Symposium on Foundations of Computer Science, pp. 243249. IEEE Computer Society.
Garey, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory of NPCompleteness. W. H. Freeman and Company.
Ghosh, S., Mundhe, M., Hernandez, K., & Sen, S. (1999). Voting for movies: The anatomy of
recommender systems. In Proceedings of the 3rd Annual Conference on Autonomous Agents,
pp. 434435. ACM Press.
Gibbard, A. (1973). Manipulation of voting schemes. Econometrica, 41(4), 587601.
Hagele, G., & Pukelsheim, F. (2001). The electoral writings of Ramon Llull. Studia Lulliana,
41(97), 338.
Hemaspaandra, E., & Hemaspaandra, L. (2007). Dichotomy for voting systems. Journal of Computer and System Sciences, 73(1), 7383.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007a). Anyone but him: The complexity of
precluding an alternative. Artificial Intelligence, 171(5-6), 255285.
Hemaspaandra, E., Hemaspaandra, L., & Rothe, J. (2007b). Hybrid elections broaden complexitytheoretic resistance to control. In Proceedings of the 20th International Joint Conference on
Artificial Intelligence, pp. 13081314. AAAI Press. Journal version to appear in Mathematical Logic Quarterly.
Homan, C., & Hemaspaandra, L. Guarantees for the success frequency of an algorithm for finding
Dodgson-election winners. Journal of Heuristics. To appear. Full version available as (Homan
& Hemaspaandra, 2005).
339

fiFALISZEWSKI , H EMASPAANDRA , H EMASPAANDRA , & ROTHE

Homan, C., & Hemaspaandra, L. (2005). Guarantees for the success frequency of an algorithm
for finding Dodgson-election winners. Tech. rep. TR-881, Department of Computer Science,
University of Rochester, Rochester, NY. Revised, June 2007.
Kern, W., & Paulusma, D. (2001). The new FIFA rules are hard: Complexity aspects of sports
competitions. Discrete Applied Mathematics, 108(3), 317323.
Lenstra, Jr., H. (1983). Integer programming with a fixed number of variables. Mathematics of
Operations Research, 8(4), 538548.
Levin, J., & Nalebuff, B. (1995). An introduction to vote-counting schemes. The Journal of Economic Perspectives, 9(1), 326.
McCabe-Dansted, J., Pritchard, G., & Slinko, A. (2008). Approximability of Dodgsons rule. Social
Choice and Welfare, 31(2), 311330.
McGarvey, D. (1953). A theorem on the construction of voting paradoxes. Econometrica, 21(4),
608610.
McLean, I., & Urken, A. (1995). Classics of Social Choice. University of Michigan Press.
Meir, R., Procaccia, A., Rosenschein, J., & Zohar, A. (2008). The complexity of strategic behavior
in multi-winner elections. Journal of Artificial Intelligence Research, 33, 149178.
Merlin, V., & Saari, D. (1997). Copeland method II: Manipulation, monotonicity, and paradoxes.
Journal of Economic Theory, 72(1), 148172.
Niedermeier, R. (2002). Invitation to fixed-parameter algorithms. Habilitation thesis, University of
Tubingen.
Niedermeier, R. (2006). Invitation to Fixed-Parameter Algorithms. Oxford University Press.
Procaccia, A., & Rosenschein, J. (2007). Junta distributions and the average-case complexity of
manipulating elections. Journal of Artificial Intelligence Research, 28, 157181.
Procaccia, A., Rosenschein, J., & Kaminka, G. (2007). On the robustness of preference aggregation in noisy environments. In Proceedings of the 6th International Joint Conference on
Autonomous Agents and Multiagent Systems, pp. 416422. ACM Press.
Procaccia, A., Rosenschein, J., & Zohar, A. (2008). On the complexity of achieving proportional
representation. Social Choice and Welfare, 30(3), 353362.
Saari, D., & Merlin, V. (1996). The Copeland method I: Relationships and the dictionary. Economic
Theory, 8(1), 5176.
Satterthwaite, M. (1975). Strategy-proofness and Arrows conditions: Existence and correspondence theorems for voting procedures and social welfare functions. Journal of Economic
Theory, 10(2), 187217.
Stearns, R. (1959). The voting problem. The American Mathematical Monthly, 66(9), 761763.
Wagner, K. (1986). The complexity of combinatorial problems with succinct input representations.
Acta Informatica, 23(3), 325356.
Xia, L., & Conitzer, V. (2008a). Generalized scoring rules and the frequency of coalitional manipulability. In Proceedings of the 9th ACM Conference on Electronic Commerce, pp. 109118.
ACM Press.
340

fiL LULL AND C OPELAND VOTING R ESIST B RIBERY AND C ONSTRUCTIVE C ONTROL

Xia, L., & Conitzer, V. (2008b). A sufficient condition for voting rules to be frequently manipulable.
In Proceedings of the 9th ACM Conference on Electronic Commerce, pp. 99108. ACM Press.
Zermelo, E. (1929). Die Berechnung der Turnier-Ergebnisse als ein Maximumproblem der Wahrscheinlichkeitsrechnung. Mathematische Zeitschrift, 29(1), 436460.

341

fiJournal of Artificial Intelligence Research 35 (2009) 557-591

Submitted 11/08; published 07/09

Optimal Value of Information in Graphical Models
Andreas Krause

KRAUSEA @ CALTECH . EDU

California Institute of Technology,
1200 E California Blvd.,
Pasadena, CA 91125 USA

Carlos Guestrin

GUESTRIN @ CS . CMU . EDU

Carnegie Mellon University,
5000 Forbes Ave.,
Pittsburgh, PA 15213 USA

Abstract
Many real-world decision making tasks require us to choose among several expensive observations. In a sensor network, for example, it is important to select the subset of sensors that is
expected to provide the strongest reduction in uncertainty. In medical decision making tasks, one
needs to select which tests to administer before deciding on the most effective treatment. It has
been general practice to use heuristic-guided procedures for selecting observations. In this paper,
we present the first efficient optimal algorithms for selecting observations for a class of probabilistic
graphical models. For example, our algorithms allow to optimally label hidden variables in Hidden
Markov Models (HMMs). We provide results for both selecting the optimal subset of observations,
and for obtaining an optimal conditional observation plan.
Furthermore we prove a surprising result: In most graphical models tasks, if one designs an
efficient algorithm for chain graphs, such as HMMs, this procedure can be generalized to polytree graphical models. We prove that the optimizing value of information is NPPP -hard even for
polytrees. It also follows from our results that just computing decision theoretic value of information objective functions, which are commonly used in practice, is a #P-complete problem even on
Naive Bayes models (a simple special case of polytrees).
In addition, we consider several extensions, such as using our algorithms for scheduling observation selection for multiple sensors. We demonstrate the effectiveness of our approach on several
real-world datasets, including a prototype sensor network deployment for energy conservation in
buildings.

1. Introduction
In probabilistic reasoning, where one can choose among several possible but expensive observations,
it is often a central issue to decide which variables to observe in order to most effectively increase
the expected utility (Howard, 1966; Howard & Matheson, 1984; Mookerjee & Mannino, 1997;
Lindley, 1956). In a medical expert system, for example, multiple tests are available, and each test
has a different cost (Turney, 1995; Heckerman, Horvitz, & Middleton, 1993). In such systems,
it is thus important to decide which tests to perform in order to become most certain about the
patients condition, at a minimum cost. Occasionally, the cost of testing can even exceed the value
of information for any possible outcome, suggesting to discontinue any further testing.
The following running example motivates our research and is empirically evaluated in Section 6.
Consider a temperature monitoring task, where wireless temperature sensors are distributed across a

c
2009
AI Access Foundation. All rights reserved.

fiK RAUSE & G UESTRIN

building. The task is to become most certain about the temperature distribution, whilst minimizing
energy expenditure, a critically constrained resource (Deshpande, Guestrin, Madden, Hellerstein, &
Hong, 2004). Such fine-grained building monitoring is required to obtain significant energy savings
(Singhvi, Krause, Guestrin, Garrett, & Matthews, 2005).
Many researchers have suggested the use of myopic (greedy) approaches to select observations (Scheffer, Decomain, & Wrobel, 2001; van der Gaag & Wessels, 1993; Dittmer & Jensen,
1997; Bayer-Zubek, 2004; Kapoor, Horvitz, & Basu, 2007). Unfortunately, in general, this heuristic does not provide any performance guarantees. In this paper, we present efficient algorithms,
which guarantee optimal nonmyopic value of information in chain graphical models. For example,
our algorithms can be used for optimal active labeling of hidden states in Hidden Markov Models (HMMs, Baum & Petrie, 1966). We address two settings: subset selection, where the optimal
subset of observations is obtained in an open-loop fashion, and conditional plans, a sequential,
closed-loop plan where the observation strategy depends on the actual value of the observed variables (c.f., Figure 1). To our knowledge, these are the first optimal and efficient algorithms for
observation selection and diagnostic planning based on value of information for this class of graphical models. For both settings, we address the filtering and the smoothing versions: Filtering is
important in online decision making, where our decisions can only utilize observations made in the
past. Smoothing arises for example in structured classification tasks, where there is no temporal
dimension in the data, and hence all observations can be taken into account. We call our approach
VO IDP as the algorithms use Dynamic Programming to optimize Value of Information. We evaluate our VO IDP algorithms empirically on three real-world datasets, and also show that they are
well-suited for interactive classification of sequential data.
Most inference problems in graphical models, such as computing marginal distributions and
finding the most probable explanation, that can be solved efficiently for chain-structured graphs,
can also be solved efficiently for polytrees. We prove that the problem of selecting the best k
observations for maximizing decision theoretic value of information is NPPP -complete even for
discrete polytree graphical models, giving a complexity theoretic classification of a core artificial
intelligence problem. NPPP -complete problems are believed to be significantly harder than NPcomplete or even #P-complete problems commonly arising in the context of graphical models. We
furthermore prove that just evaluating decision-theoretic value of information objective functions is
#P-complete even in the case of Naive Bayes models, a simple special case of polytree graphical
models that is frequently used in practice (c.f., Domingos & Pazzani, 1997).
Unfortunately, these hardness results show that, while the problem of scheduling a single sensor can be optimally solved using our algorithms, the problem of scheduling multiple, correlated
sensors is wildly intractable. Nevertheless, we show how our VO IDP algorithms for single sensor
scheduling can be used to approximately optimize a multi-sensor schedule. We demonstrate the
effectiveness of this approach on a real sensor network testbed for building management.
In summary, we provide the following contributions:
 We present the first optimal algorithms for nonmyopically computing and optimizing value
of information on chain graphical models.
 We show that optimizing decision theoretic value of information is NPPP -hard for discrete
polytree graphical models. Just computing decision theoretic value of information is #Phard even for Naive Bayes models.

558

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

no

Tmorn =high?

Tnoon =high?

yes

Teve =high?

Figure 1: Example of a conditional plan.
 We present several extensions of our algorithms, e.g., to tree graphical models with few
leaves, and to multiple correlated chains (for multi-sensor scheduling).
 We extensively evaluate our algorithms on several real-world problems, including sensor
scheduling on a real sensor testbed and active labeling in bioinformatics and Natural Language Processing.

2. Problem Statement
We will assume that the state of the world is described by a collection of random variables
XV = (X1 , . . . , Xn ), where V is an index set. For example, V could denote a set of locations, and Xi
models the temperature reading of a sensor placed at location i  V. For a subset
A = {i1 , . . . , ik }  V, we use the notation XA to refer to the random vector XA = (Xi1 , . . . , Xik ).
While some of our algorithms extend to continuous distributions, we generally assume that the variables XV are discrete. We take a Bayesian approach, and assume a prior probability distribution
P (XV ) over the outcomes of the variables. Suppose we select a subset of the variables, XA (for
A  V), and observe XA = xA . For example, A is the set of locations where we place sensors,
or a set of medical tests we decide to perform. After observing the realization of these variables
XA = xA , we can compute the posterior distribution over all variables P (XV | XA = xA ). Based
on this posterior probability we obtain a reward R(P (XV | XA = xA )). For example, this reward function could depend on the uncertainty (e.g., measured by the entropy) of the distribution
P (XV | XA = xA ). We will describe several examples in more detail below.
In general, when selecting observation, we will not know ahead of time what observations we
will make. Instead, we only have a distribution over the possible observations. Hence, we will be
interested in the expected reward, where we take the expectation over the possible observations.
When optimizing the selection of variables, we can consider different settings: In subset selection, our goal is to pick a subset A  V of the variables, maximizing
X
A = argmax
P (XA = xA )R(P (XV | XA = xA )),
(1)
A

xA

where we impose some constraints on the set A we are allowed to pick (e.g., on the number of
variables that can be selected, etc.). In the subset selection setting, we commit to the selection of
the variables before we get to see their realization.
Instead, we can also sequentially select one variable after the other, letting our choice depend
on the observations made in the past. In this setting, we would like to find a conditional plan  

559

fiK RAUSE & G UESTRIN

that maximizes
  = argmax


X

P (xV )R(P (XV | X(xV ) = x(xV ) )).

(2)

xV

Hereby,  is a conditional plan that can select a different set of variables for each possible state of
the world xV . We use the notation (xV )  V to refer to the subset of variables selected by the
conditional plan  in state XV = xV . Figure 1 presents an example of a conditional plan for the
temperature monitoring example. We will define the notion of conditional planning more formally
in Section 4.2.
This general setup of selecting observations goes back in the decision analysis literature to
the notion of value of information by Howard (1966) and in the statistical literature to the notion
of Bayesian Experimental Design by Lindley (1956). In this paper, we refer to the Problems (1)
and (2) as the problems of optimizing value of information.
In this paper, we show how the complexity of solving these value of information problems depend on the properties of the probability distribution P . We give the first algorithms for optimally
solving value of information for an interesting and challenging class of distributions including Hidden Markov Models. We also present hardness results showing that optimizing value of information
is wildly intractable (NPPP -complete) even for probability distributions for which efficient inference is possible (even for Naive Bayes models and discrete polytrees).
2.1 Optimization Criteria
In this paper, we will consider a class of local reward1 functions Ri , which are defined on the
marginal probability distributions of the variables Xi . This class has the computational advantage
that local rewards can be evaluated using probabilistic inference techniques. The total reward will
then be the sum of all local rewards.
Let A be a subset of V. Then P (Xj | XA = xA ) denotes the marginal distribution of variable Xj conditioned on observations XA = xA . For example, in our temperature monitoring
application, Xj models the temperature at location j  V. The conditional marginal distribution
P (Xj = xj | XA = xA ) then models the conditional distribution of the temperature at location j
after observing the temperature at locations A  V.
For classification purposes, it can be more appropriate to consider the max-marginals
P max (Xj = xj | XA = xA ) = max P (XV = xV , Xj = xj | XA = xA ),
xV

that is, for Xj set to value xj , the probability of the most probable assignment XV = xV to all
other random variables (including Xj for simplicity of notation) conditioned on the observations
XA = xA .
The local reward Rj is a functional on the probability distribution P or P max over Xj . That
is, Rj takes an entire distribution over the variable Xj and maps it to a reward value. Typically, the
reward functions will be chosen such that certain or peaked distributions obtain higher reward.
To simplify notation, we write
Rj (Xj | xA ) , Rj (P (Xj | XA = xA ))
1. Local reward functions are also widely used in additively independent utility models, (c.f., Keeney & Raiffa, 1976).

560

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

to denote the reward for variable Xj upon observing XA = xA , and
X
Rj (Xj | XA ) ,
P (XA = xA )Rj (Xj | xA )
xA

to refer to expected local rewards, where the expectation is taken over all assignments xA to the
observations A. Important local reward functions include:
Residual entropy. If we set
Rj (Xj | xA ) = H(Xj | xA ) =

X

P (xj | xA ) log2 P (xj | xA ),

xj

the objective in the optimization problem becomes to minimize the sum of residual entropies. Optimizing this reward function attempts to reduce the uncertainty in predicting the marginals Xi . We
choose this reward function in our running example to measure the uncertainty about the temperature distribution.
P
Joint entropy. Instead of minimizing the sum of residual entropies i H(Xi ), we can also attempt to minimize the joint entropy of the entire distribution,
X
H(XV ) = 
P (xV ) log2 P (xV ).
xV

Note, that the joint entropy depends on the full probability distribution P (XV ), rather than on the
marginals P (Xi ), and hence it is not local. Nevertheless, we can exploit the chain rule for the joint
entropy H(XB ) of a set of random variables B = {1, . . . , m} (c.f., Cover & Thomas, 1991),
H(XB ) = H(X1 ) + H(X2 | X1 ) + H(X3 | X1 , X2 ) +    + H(Xm | X1 , . . . , Xm1 ).
Hence, if we choose the local reward functions Rj (Xj | XA ) = H(Xj | X1 , . . . , Xj1 , XA ), we
can optimize a non-local reward function (the joint entropy) using only local reward functions.
Decision-theoretic value of information. The concept of local reward functions also includes
the concept of decision theoretic value of information. The notion of value of information is widely
used (c.f., Howard, 1966; Lindley, 1956; Heckerman et al., 1993), and is formalized, e.g., in the
context of influence diagrams (Howard & Matheson, 1984) and Partially Observable Markov Decision Processes (POMDPs, Smallwood & Sondik, 1973). For each variable Xj , let Aj be a finite set
of actions. Also, let Uj : Aj  dom Xj  R be a utility function mapping an action a  Aj and an
outcome x  dom Xj to a real number. The maximum expected utility principle states that actions
should be selected as to maximize the expected utility,
X
EUj (a | XA = xA ) =
P (xj | xA )Uj (a, xj ).
xj

The more certain we are about Xj , the more economically we can choose our action. This idea is
captured by the notion of value of information, where we choose our local reward function
Rj (Xj | xA ) = max EUj (a | xA ).
a

561

fiK RAUSE & G UESTRIN

Margin for structured prediction. We can also consider the margin of confidence:
Rj (Xj | xA ) = P max (xj | xA )  P max (xj | xA ),
where
xj = argmax P max (xj | xA ) and xj = argmax P max (xj | xA ),
xj 6=xj

xj

which describes the margin between the most likely outcome and the closest runner up. This reward
function is very useful for structured classification purposes, as shown in Section 6.
Weighted mean-squared error. If the variables are continuous, we might want to minimize the
mean squared error in our prediction. We can do this by choosing
Rj (Xj | xA ) = wj Var(Xj | xA ),
where
Z
Var(Xj | xA ) =


P (xj | xA ) xj 

Z

x0j P (x0j

|

xA )dx0j

2
dxj

is the conditional variance of Xj given XA = xA , and wj is a weight indicating the importance of
variable Xj .
Monitoring for critical regions (Hotspot sampling). Suppose we want to use sensors for detecting fire. More generally, we want to detect, for each j, whether Xj  Cj , where Cj  dom Xj is a
critical region for variable Xj . Then the local reward function
Rj (Xj | xA ) = P (Xj  Cj | xA )
favors observations A that maximize the probability of detecting critical regions.
Function optimization (Correlated bandits). Consider a setting where we have a collection of
random variables XV taking numerical
P values in some interval [m, m], and, after selecting some
of the variables, we get the reward i xi . This setting arises if we want to optimize an unknown
(random) function, where evaluating the function is expensive. In this setting, we are encouraged to
only evaluate the function where it is likely to obtain high values. We can maximize our expected
total reward if we choose the local reward function
Z
Rj (Xj | xA ) = xj P (xj | xA )dxj ,
i.e., the expectation of variable Xj given observations xA . This setting of optimizing a random
function can also be considered a version of the classical k-armed bandit problem with correlated
arms. More details about the relationship with bandit problems are given in Section 8.
These examples demonstrate the generality of our notion of local reward. Note that most examples apply to continuous distributions just as well as for discrete distributions.

562

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

2.2 Cost of Selecting Observations
We also want to capture the constraint that observations are expensive. This can mean that each
observation Xj has an associated positive penalty Cj that effectively decreases the reward. In our
example, we might be interested in trading off accuracy with sensing energy expenditure. Alternatively, it is also possible to define a budget B for selecting observations, where each one is associated
with an integer cost j . Here, we want to select observations whose sum cost is within the budget,
but these costs do not decrease the reward. In our running example, the sensors could be powered
by solar power, and regain a certain amount of energy per day, which allows a certain amount of
sensing. Our formulation of the optimization
both for penalties and budgets. To
P problems allows P
simplify notation we also write C(A) = jA Cj and (A) = jA j to extend C and  to sets.
Instead of fixed penalties and costs per observation, both can also depend on the state of the
world. For example, in the medical domain, applying a particular diagnostic test can bear different
risks for the health of the patient, depending on the patients illness. The algorithms we will develop
below can be adapted to accommodate such dependencies in a straight-forward manner. We will
present details only for the conditional planning algorithm in Section 4.2.

3. Decomposing Rewards
In this section, we will present the key observation that allows us to develop efficient algorithms
for nonmyopically optimizing value of information in the class of chain graphical models. The
algorithms will be presented in Section 4.
The set of random variables XV = {X1 , . . . , Xn } forms a chain graphical model (a chain), if
Xi is conditionally independent of XV\{i1,i,i+1} given Xi1 and Xi+1 . Without loss of generality
we can assume that the joint distribution is specified by the prior P (X1 ) of variable X1 and the
conditional probability distributions P (Xi+1 | Xi ). The time series model for the temperature
measured by one sensor in our example can be formulated as a chain graphical model. Note that the
transition probabilities P (Xi+1 | Xi ) are allowed to depend on the index i (i.e., the chain models
are allowed to be nonstationary). Chain graphical models have been extensively used in machine
learning and signal processing.
Consider for example a Hidden Markov Model unrolled for n time steps, i.e., V can be partitioned into the hidden variables {X1 , . . . , Xn } and the emission variables {Y1 , . . . , Yn }. In HMMs,
the Yi are always observed and the variables Xi form a chain. In many applications, some of which
are discussed in Section 6, we can observe some of the hidden variables Xi as well, e.g., by asking
an expert, in addition to observing the emission variables. In these cases, the problem of selecting
expert labels also belongs to the class of chain graphical models addressed by this paper, since the
variables Xi form a chain conditional on the observed values of the emission variables Yi . This idea
can be generalized to the class of Dynamic Bayesian Networks where the separators between time
slices have size one, and only these separators can be selected for observation. This formulation
also includes certain conditional random fields (Lafferty, McCallum, & Pereira, 2001) which form
chains, conditional on the emission variables (the features).
Chain graphical models originating from time series have additional, specific properties: In a
system for online decision making, only observations from the past and present time steps can be
taken into account, not observations which will be made in the future. This is generally referred
to as the filtering problem. In this setting, the notation P (Xi | XA ) will refer to the distribution
of Xi conditional on observations in XA prior to and including time i. For structured classification
563

fiK RAUSE & G UESTRIN

Figure 2: Illustration of the decomposing rewards idea. The reward for chain 1:7 when observing
variables X1 , X4 and X7 decomposes as the sum of chain 1:4 plus the reward for chain
4:7 plus the immediate reward for observing XP
4 minus the cost of observing X4 . Hereby
for brevity we use the notation Rew(a : b) = bj=a Rj (Xj | X1 , X4 , X7 ).

problems as discussed in Section 6, in general observations made anywhere in the chain must be
taken into account. This situation is usually referred to as the smoothing problem. We will provide
algorithms both for filtering and smoothing.
We will now describe the key insight, which allows for efficient optimization in chains. Consider
a set of observations A  V. If the j variable is observed, i.e., j  A, then the local reward
is simply R(Xj | XA ) = R(Xj | Xj ). Now consider j 
/ A, and let Aj be the subset of A
containing the closest ancestor (and for the smoothing problem also the closest descendant) of Xj
in XA . The conditional independence property of the graphical model implies that, given XAj , Xj
is independent of the rest of the observed variables, i.e., P (Xj | XA ) = P (Xj | XAj ). Thus, it
follows that R(Xj | XA ) = R(Xj | XAj ).
These observations imply that the expected reward of some set of observations decomposes
along the chain. For simplicity of notation, we add two independent dummy variables X0 and Xn+1 ,
where R0 = C0 = 0 = Rn+1 = Cn+1 = n+1 = 0. Let A = {i0 , . . . P
, im+1 } where il < il+1 ,
i0 = 0 and im+1 = n + 1. Using this notation, the total reward R(A) = j Rj (Xj | XA ) for the
smoothing case is given by:


iv+1 1
m
X
X
Riv (Xiv | Xiv )  Civ +
Rj (Xj | Xiv , Xiv+1 ) .
v=0

j=iv +1

In filtering settings, we simply replace Rj (Xj | Xiv , Xiv+1 ) by Rj (Xj | Xiv ). Figure 2 illustrates
this decomposition.

4. Efficient Algorithms for Optimizing Value of Information
In this section, we present algorithms for efficiently and nonmyopically optimizing value of information in chain graphical models.
4.1 Efficient Algorithms for Optimal Subset Selection in Chain Models
In the subset selection problem, we want to find a most informative subset of the variables to observe
in advance, i.e., before any observations are made. In our running example, we would, before
deploying the sensors, identify k time points that are expected to provide the most informative
sensor readings according to our model.

564

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

First, define the objective function L on subsets of V by
L(A) =

n
X

Rj (Xj | XA )  C(A).

(3)

j=1

The subset selection problem is to find the optimal subset
A =

argmax L(A)
AV,(A)B

maximizing the sum of expected local rewards minus the penalties, subject to the constraint that the
total cost must not exceed the budget B.
We solve this optimization problem using a dynamic programming algorithm, where the chain
is broken into sub-chains using the insight from Section 3. Consider a sub-chain from variable Xa
to Xb . We define Lsm
a:b (k) to represent the expected total reward for the sub-chain Xa , . . . , Xb , in the
lt
smoothing setting where Xa and Xb are observed, and with a budget level of k. Lfa:b
(k) represents
the expected reward in the filtering setting where only Xa is observed. More formally:
lt
(k)
Lfa:b

=

b1
X

max

A{a+1...b1}
j=a+1
(A)k

Rj (Xj | XA , Xa )  C(A),

for the filtering version, and
Lsm
a:b (k) =

b1
X

max

Rj (Xj | XA , Xa , Xb )  C(A),

A{a+1...b1}
j=a+1
(A)k

for the smoothing version. Note that in both cases, L0:n+1 (B) = maxA:(A)B L(A), as in Equation (3), i.e., by computing the values for La:b (k), we compute the maximum expected total reward
for the entire chain.
f lt
We can compute Lsm
a:b (k) and La:b (k) using dynamic programming. The base case is simply:
lt
Lfa:b
(0) =

b1
X

Rj (Xj | Xa ),

j=a+1

for filtering, and
b1
X

Lsm
a:b (0) =

Rj (Xj | Xa , Xb ),

j=a+1

for smoothing. The recursion for La:b (k) has two cases: we can choose not to spend any more of the
budget, reaching the base case, or we can break the chain into two sub-chains, selecting the optimal
observation Xj , where a < j < b. In both filtering and smoothing we have


La:b (k) = max La:b (0),
max
{Rj (Xj | Xj )  Cj + La:j (0) + Lj:b (k  j )} .
j:a<j<b,j k

565

fiK RAUSE & G UESTRIN

Input: Budget B, rewards Rj , costs j and penalties Cj
Output: Optimal selection A of observation times
begin
for 0  a < b  n + 1 do compute La:b (0);
for k = 1 to B do
for 0  a < b  n + 1 do
sel(1) := La:b (0);
for j = a + 1 to b  1 do sel(j) := Rj (Xj | Xj )  Cj + La:j (0) + Lj:b (k  j );
La:b (k) = maxj{a+1,...,b1,1} sel(j);
a:b (k) = argmaxj{a+1,...,b1,1} sel(j);
end
end
a := 0; b := n + 1; k := B; A := ;
repeat
j := a:b (k);
if j  0 then A := A  {j}; a := j; k := k  j ;
until j = 1 ;
end
Algorithm 1: VO IDP algorithm for optimal subset selection (for both filtering and smoothing).
At first, it may seem that this recursion should consider the optimal split of the budget between the
two sub-chains. However, since the subset problem is open-loop and the order of the observations
is irrelevant, we only need to consider split points where the first sub-chain receives zero budget.
A pseudo code implementation for this dynamic programming approach, which we call VO IDP
for subset selection is given in Algorithm 1. The algorithm fills the dynamic programming tables in
two loops, the inner loop ranging over all pairs (a, b), a < b, and the outer loop increasing k. Within
the inner loop, when computing the best reward for the sub-chain from a to b, it fills out a table sel,
where sel(j) is the reward that could be obtained by making an observation at j, and sel(1) is the
reward if no observation is made.
In addition to computing the optimal rewards La:b (k) that could be achieved for sub-chain a : b
and budget k, the algorithm also stores the choices a:b (k) that realize this maximum score. Here,
a:b (k) is the index of the next variable that should be selected for sub-chain a : b with budget
k, or 1 if no variable should be selected. In order to recover the optimal subset for budget k,
Algorithm 1 uses the quantities a:b to recover the optimal subset by tracing the maximal values
occurring in the dynamic programming equations. Using an induction proof, we obtain:
Theorem 1 (Subset Selection). The dynamic programming algorithm described above computes
the optimal subset with budget B in ( 61 n3 + O(n2 ))B evaluations of expected local rewards.
Note that if we do not consider different costs  for each variable, we would simply choose j =
1 for all variables and compute La:b (N ). Further note that if the variables Xi are continuous,
our algorithm is still applicable when the integrations and inferences necessary for computing the
expected rewards can be performed efficiently. This is the case, for example, in a Gaussian linear
model (i.e., the variables Xi are normally distributed) and the local reward functions are the residual
entropies or the residual variances for each variable.

566

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

4.2 Efficient Algorithms for Optimal Conditional Planning in Chain Models
In the conditional plan problem, we want to compute an optimal sequential querying policy : We
observe a variable, pay the penalty, and depending on all values observed in the past, select the next
query, proceeding as long as our budget suffices. The objective is to find the plan with the highest
expected reward, where, for each possible sequence of observations, the budget B is not exceeded.
For filtering, we can only select observations in the future, whereas in the smoothing case, the next
observation can be anywhere in the chain. In our running example, the filtering algorithm would be
most appropriate: The sensors would sequentially follow the conditional plan, deciding on the most
informative times to sense based on the previous observations. Figure 1 shows an example of such
a conditional plan.
4.2.1 F ROM S UBSET S ELECTION TO C ONDITIONAL P LANNING
Note that in contrast to the subset selection setting that we considered in Section 4.1, in conditional planning, the set of variables depends on the state of the world XV = xV . Hence, for each
such state, the conditional plan  could select a different set of variables, (xV )  V. As an example, consider Figure 1, where the set of possible observations is V = {morn, noon, eve}, and
XV = {Tmorn , Tnoon , Teve }. If the world is in state xV = (high, low, high), then the conditional
plan  presented in Figure 1 would select (xV ) = {morn, eve}, whereas, if
xV = (low, low, high), it would select (xV ) = {morn, noon}. Since the conditional plan is
a function of the (random) state of the world, it is a set-valued random variable. In order to optimize
Problem (2), we define the objective function2
J() =

X

P (xV )

xV

n
X



Rj (Xj | x(xV ) )  C((xV )) ,

j=1

i.e., the expected sum of local rewards given the observations made by plan (xV ) in state XV = xV
minus the penalties of the selected variables, where the expectation is taken with respect to the
distribution P (XV ). In addition to defining the value of a policy J(), we also define the cost ()
() = max ((xV )),
xV

as maximum cost (A) (as defined in Section 2.2) of any set A = (xV ) that could be selected by
the policy , in any state of the world XV = xV .
Based on this notation, our goal is to find a policy   such that
  = argmax J() such that ()  B,


i.e., a policy that has maximum value, and is guaranteed to never have cost exceeding our budget
B. Hereby  is the class of sequential policies (i.e., those, where the observations are chosen
sequentially, only based on observations that have been previously made).
It will be useful to introduce the following notation:
J(xA ; k) = max J( | XA = xA ) such that ()  k,


(4)

2. Recall that, in the filtering setting, R(Xj | x(xV ) ) , R(Xj | xA0 ), where A0 = {t  (xV ) s.t. t  j}, i.e., only
observations from the past are taken into account.

567

fiK RAUSE & G UESTRIN

where
J( | XA = xA ) =

X

n
X


P (xV | XA = xA )
Rj (Xj | x(xV ) )  C((xV )) .

xV

j=1

Hence, J(xA ; k) is the best possible reward that can be achieved by any sequential policy with cost
at most k, after observing XA = xA . Using this notation, our goal is to find the optimal plan with
reward J(; B).
The value function J satisfies the following recursion. The base case considers the exhausted
budget:
X
J(xA ; 0) =
Rj (Xj | xA )  C(A).
jV

For the recursion, it holds that





X
J(xA ; k) = max J(xA ; 0), max
,
P (xj | xA )J(xA , xj ; k  j )


j A
/ 

(5)

xj

i.e., the best one can do in state XA = xA with budget k is to either stop selecting variables, or
chose the best next variable and act optimally thereupon.
Note that we can easily allow the cost j depend on the state xj of variable Xj . In this case, we
would simply replace j by j (xj ), and define J(XA , r) =  whenever r < 0. Equivalently, we
can let the penalty C(A) depend on the state by replacing C(A) by C(xA ).
Relationship to finite-horizon Markov Decision Processes (MDPs). Note that the function
J(xA ; k) defined in (4) is analogous to the concept of a value function in Markov Decision Processes (c.f., Bellman, 1957): In finite-horizon MDPs, the value function V (s; k) models the maximum expected reward obtainable when starting in state s and performing k actions. For this value
function it holds that
X
V (s; k) = R(s, k) + max
P (s0 | s, a)V (s0 ; k  1),
a

s0

where P (s0 | s, a) is the probability of transiting to state s0 when performing action a in state s,
and R(s, k) is the immediate reward obtained in state s if k steps are still left. This recursion,
which is similar to Eq. (5), is exploited by the value iteration algorithm for solving MDPs. The
conditional planning problem with unit observation cost (i.e., (A) = |A|) could be modeled as a
finite-horizon MDP, where states correspond to observed evidence XA = xA , actions correspond
to observing variables (or not making any observation) and transition probabilities are given by the
probability of observing a particular instantiation of the selected variable. The immediate reward is
R(s, k) = 0 for k > 0, and R(s, 0) is the expected reward (in the value of information problem) of
observing assignment s (i.e., R(P (XV | s))  C(s)). If all observations have unit cost, then for this
MDP, it holds that V (xA ; k) = J(xA ; k). Unfortunately, in the conditional planning problem, since
the state of the MDP is uniquely determined by the observed evidence XA = xA , the state space is
exponentially large. Hence, existing algorithms for solving MDPs exactly (such as value iteration)
cannot be applied to solve large value of information problems. In Section 4.2.2, we develop an
efficient dynamic programming algorithm for conditional planning in chain graphical models that
avoids this exponential increase in complexity.
568

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

4.2.2 DYNAMIC P ROGRAMMING FOR O PTIMAL C ONDITIONAL P LANNING IN C HAINS
We propose a dynamic programming algorithm for obtaining the optimal conditional plan that is
similar to the subset algorithm presented in Section 4.1. Again, we utilize the decomposition of
rewards described in Section 3. The difference here is that the observation selection and budget
allocation now depend on the actual values of the observations. In order to compute the value
function J(xA ; k) for the entire chain, we will compute the value functions Ja:b (xA ; k) for subchains Xa , . . . , Xb .
The base case of our dynamic programming approach deals with the zero budget setting:
f lt
Ja:b
(xa ; 0)

=

b1
X

Rj (Xj | Xa = xa ),

j=a+1

for filtering, and
sm
(xa , xb ; 0) =
Ja:b

b1
X

Rj (Xj | Xa = xa , Xb = xb ),

j=a+1

for smoothing. The recursion defines Ja:b (xa ; k) (or Ja:b (xa , xb ; k) for smoothing), the expected
reward for the problem restricted to the sub-chain Xa , . . . , Xb conditioned on the values of Xa = xa
(and Xb = xb for smoothing), and with budget limited by k. To compute this quantity, we again
iterate through possible split points j, such that a < j < b. Here we observe a notable difference
between the filtering and the smoothing case. For smoothing, we now must consider all possible
splits of the budget between the two resulting sub-chains, since an observation at time j might
require us to make an additional, earlier observation:
X

n
sm
sm
P (Xj = xj | Xa = xa , Xb = xb )
Ja:b (xa ,xb ; k) = max Ja:b (xa , xb ; 0), max
a<j<b

Rj (Xj | xj )  Cj (xj ) +

max
0lkj (xj )

xj



sm
Ja:j
(xa , xj ; l)

+

sm
(xj , xb ; k
Jj:b


o
.
 l  j (xj ))

Looking back in time is not possible in the filtering case, hence the recursion simplifies to

X
n
f lt
f lt
Ja:b (xa ; k) = max Ja:b (xa ; 0),
max
P (Xj = xj | Xa = xa )
a<j<b:j (xj )k

Rj (Xj | xj )  Cj (xj ) +

xj

f lt
Ja:j
(xa ; 0)

+

f lt
Jj:b
(xj ; k

o
 j (xj ))
.

For both J f lt and J sm , the optimal reward is obtained by J0:n+1 (; B) = J(; B) = J(  ).
Algorithm 2 presents a pseudo code implementation for the smoothing version  the filtering case
is a straight-forward modification. We call Algorithm 2 the VO IDP algorithm for conditional planning. The algorithm will fill the dynamic programming tables using three loops, the inner loop
ranging over all assignments xa , xb , the middle loop ranging over all pairs (a, b) where a < b, and
the outer loop covers increasing values of k  B. Within the innermost loop, the algorithm again
computes a table sel such that sel(j) is the optimal reward achievable by selecting variable j next.
569

fiK RAUSE & G UESTRIN

This value is now an expectation over any possible observation that variable Xj can make. Note that
for every possible instantiation Xj = xj a different allocation of the remaining budget k  j (xj )
to the left and right sub-chain (a : j and j : b respectively) can be chosen. The quantity (j, xj )
tracks this optimal budget allocation.
Input: Budget B, rewards Rj , costs j and penalties Cj
Output: Optimal conditional plan (a:b , a:b )
begin
sm (x , x ; 0);
for 0  a < b  n + 1, xa  dom Xa , xb  dom Xb do compute Ja:b
a b
for k = 1 to B do
for 0  a < b  n+1, xa  dom Xa , xb  dom Xb do
sm (0);
sel(1) := Ja:b
for a < j < b do
sel(j) := 0;
for xj  dom Xj do
for 0  l  k  j (xj ) do
sm (x , x ; l) + J sm (x , x ; k  l   (x ));
bd(l) := Ja:j
j
j j
a j
b
j:b
end
sel(j) := sel(j) + P (xj | xa , xb )  [Rj (Xj | xj )  Cj (xj ) + maxl bd(j)];
(j, xj ) = argmaxl bd(j);
end
end
sm (k) = max
Ja:b
j{a+1,...,b1,1} sel(j);
a:b (xa , xb ; k) = argmaxj{a+1,...,b1,1} sel(j);
for xj  dom Xa:b (k) do a:b (xa , xb , xj ; k) = (a:b (k), xj );
end
end
end
Algorithm 2: VO IDP algorithm for computating an optimal conditional plan (for the smoothing
setting).
Input: Budget k, observations Xa = xa , Xb = xb , , 
begin
j := a:b (xa , xb ; k);
if j  0 then
Observe Xj = xj ;
l := a:b (xa , xb , xj ; k);
Recurse with k := l, Xa = xa and Xj = xj instead of Xb = xb ;
Recurse with k := k  l  j , Xj = xj instead of Xa = xa , and Xb = xb ;
end
end
Algorithm 3: Observation selection using conditional planning.
The plan itself is compactly encoded in the quantities a:b and a:b . Hereby, a:b (xa , xb ; k)
determines the next variable to query after observing Xa = xa and Xb = xb , and with remaining budget k. a:b (xa , xb , xj ; k) determines the allocation of the budget after the new observation
Xj = xj has been made. Considering the exponential number of possible sequences of observations,
570

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

it is remarkable that the optimal plan can be represented using only polynomial space. Algorithm 3
indicates how the computed plan can be executed. The procedure is recursive, requiring the parameters a := 0, xa := 1, b := n + 1, xb := 1 and k := B for the initial call. In our temperature
monitoring example, we could first collect some temperature timeseries as training data, and then
learn the chain model from this data. Offline, we would then compute the conditional plan (for the
filtering setting), and encode it in the quantities a:b and a:b . We would then deploy the computed
plan on the actual sensor node, together with an implementation of Algorithm 3. While computation of the optimal plan (Algorithm 2) is fairly computationally expensive, the execution of the plan
(Algorithm 3) is very efficient (selecting the next timestep for observation requires a single lookup
in the a:b and a:b tables) and hence well-suited for deployment on a small, embedded device.
We summarize our analysis in the following Theorem:
Theorem 2 (Conditional Planning). The algorithm for smoothing presented above computes an
optimal conditional plan in d3  B 2  ( 61 n3 + O(n2 )) evaluations of local rewards, where d is
the maximum domain size of the random variables X1 , . . . , Xn . In the filtering case, the optimal plan can be computed using d3  B  ( 61 n3 + O(n2 )) evaluations, or, if no budget is used, in
d3  ( 16 n4 + O(n3 )) evaluations.
The faster computation for the filtering / no-budget case is obtained by observing that we do not
require the third maximum computation, which distributes the budget into the sub-chains.
Also, note that contrary to the algorithm for computing optimal subsets in Section 4.1, Algorithm 2 only requires evaluations of the form R(Xj | XA = xA ), which can in general be computed
d2 times faster than the expectations R(Xj | XA ). Under this consideration, the subset selection
algorithm is in general only a factor d  B faster, even though the conditional planning algorithm has
more nested loops.
4.3 Efficient Algorithms for Trees with Few Leaves
In Sections 4.1 and 4.2 we have presented dynamic programming-based algorithms that can optimize value of information on chain graphical models. In fact, the key observations of Section 3 that
local rewards decompose along chains holds not just in chain graphical models, but also in trees.
More formally, a tree graphical model is a joint probability distribution P (XV ) over a collection
of random variables XV if P (XV ) factors as
P (XV ) =

1 Y
i,j (Xi , Xj ),
Z
(i,j)E

where i,j is a nonnegative potential function, mapping assignments to xi and xj to the nonnegative
real numbers, E  V  V is a set of edges that form an undirected tree over the index set V, and Z
is a normalization constant enforcing a valid probability distribution.
The dynamic programming algorithms presented in the previous sections can be extended to
such tree models in a straightforward manner. Instead of identifying optimal subsets and conditional
plans for sub-chains, the algorithms would then select optimal subsets and plans for sub-trees of
increasing size. Note however that the number of sub-trees can grow exponentially in the number
of leaves of the tree: A star on n leaves for example has a number of subtrees that is exponential
in n. In fact, counting the number of subtrees of an arbitrary tree with n vertices is believed to
be intractable (#P-complete, Goldberg & Jerrum, 2000). However, for trees that contain only a
571

fiK RAUSE & G UESTRIN

small (constant) number of leaves, the number of subtrees is polynomial, and the optimal subset
and conditional plans can be computed in polynomial time.

5. Theoretical Limits
Many problems that can be solved efficiently for discrete chain graphical models can also be efficiently solved for discrete polytrees3 . Examples include probabilistic inference and the most probable explanation (MPE).
In Section 4.3 however we have seen that the complexity of the dynamic programming algorithms for chains increases dramatically when extended to trees: The complexity increases exponentially in the number of leafs of the tree.
We prove that, perhaps surprisingly, for the problem of optimizing value of information, this
exponential increase in complexity cannot be avoided, under reasonable complexity theoretic assumptions. Before making this statement more formal, we briefly review the complexity classes
used in our results.
5.1 Brief Review of Relevant Computational Complexity Classes
We briefly review the complexity classes used in the following statements by presenting a complete
problem for each of the class. For more details see, e.g., the references by Papadimitriou (1995)
or Littman, Goldsmith, and Mundhenk (1998). The class NP contains decision problems which
have polynomial-time verifiable proofs. A well-known complete problem is 3SAT for which the
instances are Boolean formulas  in conjunctive normal form containing at most three literals per
clause (3CNF form). The complexity class #P contains counting problems. A complete problem
for the class #P is #3SAT which counts the number of satisfying instances to a 3CNF formula.
PP is a decision version of the class #P: A complete problem is M AJSAT , which decides
whether a given 3CNF formula  is satisfied by the majority, i.e., by more than half of all its
possible assignments. If A and B are Turing machine based complexity classes, then AB is the
complexity class derived by allowing the Turing machines deciding instances of A oracle calls to
Turing machines in B. We can intuitively think of the problems in class AB as those that can be
solved by a Turing Machine for class A, that has a special command which solves any problem in B.
PP is similar to #P in that PPP = P#P , i.e., if we allow a deterministic polynomial time Turing
machine to have access to a counting oracle, we cannot solve more complex problems than if we give
it access to a majority oracle. Combining these ideas, the class NPPP is the class of problems that
can be solved by nondeterministic polynomial time Turing machines that have access to a majority
(or a counting) oracle. A complete problem for NPPP is EM AJSAT which, given a 3CNF on
variables X1 , . . . , X2n , it decides whether there exists an assignment to X1 , . . . , Xn such that 
is satisfied for the majority of assignments to Xn+1 , . . . , X2n . NPPP has been introduced and
found to be a natural class for modeling AI planning problems in the seminal work by Littman et al.
(1998). As an example, the MAP assignment problem is NPPP -complete for general graphical
models, as shown by Park and Darwiche (2004).
The complexity classes satisfy the following set of inclusions (where the inclusions are assumed,
but not known to be strict):
P  NP  PP  PPP = P#P  NPPP .
3. Polytrees are Bayesian Networks that form trees if the edge directions are dropped.

572

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

5.2 Complexity of Computing and Optimizing Value of Information
In order to solve the optimization problems, we will most likely have to evaluate the objective
function, i.e., the expected local rewards. Our first result states that, even if we specialize to decision theoretic value of information objective functions as defined in Section 2.1, this problem is
intractable even for Naive Bayes models, a special case of discrete polytrees. Naive Bayes models
are often used in classification tasks (c.f., Domingos & Pazzani, 1997), where the class variable is
predicted from noisy observations (features), that are assumed to be conditionally independent given
the class variable. In a sense, Naive Bayes models are the next simplest (from the perspective of
inference) class of Bayesian networks after chains. Note that Naive Bayes models correspond to the
stars referred to in Section 4.3, that have a number of subtrees that is exponential in the number
of variables.
Theorem 3 (Hardness of computation for Naive Bayes models). The computation of decision
theoretic value of information functions is #P-complete even for Naive Bayes models. It is also
hard to approximate to any factor unless P = NP.
We have the immediate corollary that the subset selection problem is PP-hard for Naive Bayes
models:
Corollary 4 (Hardness of subset selection for Naive Bayes models). The problem of determining,
given a Naive Bayes model, constants c and B, cost function  and a set of decision-theoretic value
of information objective functions Ri , whether there is a subset of variables A  V such that
L(A)  c and (A)  B is PP-hard.
In fact, we can show that subset selection for arbitrary discrete polytrees (that are more general
than Naive Bayes models, but inference is still tractable) is even NPPP -complete, a complexity
class containing problems that are believed to be significantly harder than NP or #P complete
problems. This result provides a complexity theoretic classification of value of information, a core
AI problem.
Theorem 5 (Hardness of subset selection computation for polytrees). The problem of determining, given a discrete polytree, constants c and B, cost function  and a set of decision-theoretic
value of information objective functions Ri , whether there is a subset of variables A  V such that
L(A)  c and (A)  B is NPPP -complete.
For our running example, this implies that the generalized problem of optimally selecting k sensors
from a network of correlated sensors is most likely computationally intractable without resorting to
heuristics. A corollary extends the hardness of subset selection to the hardness of conditional plans.
Corollary 6 (Hardness of conditional planning computation for polytrees). Computing conditional plans is PP-hard for Naive Bayes models and NPPP -hard for discrete polytrees.
All proofs of results in this section are stated in the Appendix. They rely on reductions of complete
problems in NP, #P and NPPP involving boolean formulae to problems of computing / optimizing value of information. The reductions are inspired by the works of Littman et al. (1998) and Park
and Darwiche (2004), but require the development of novel techniques, such as new reductions of
Boolean formulae to Naive Bayes and polytree graphical models associated with appropriate reward
functions, ensuring that observation selections lead to feasible assignments to the Boolean formulae.
573

fiK RAUSE & G UESTRIN

Percent improvement

10

1

Optimal conditional plan

8

Mean margin of optimal subset
Mean margin of greedy heuristic

1
0.98

0.9

Mean F1 score

0.96

6

0.94

0.8

4
2

0.7
Optimal subset
Greedy heuristic

0
1

4

8
12
16
20
Number of observations

24

(a) Sensor scheduling

0.6

0.9

Mean accuracy of
greedy heuristic
1

2
3
4
5
Number of observations

(b) CpG island detection

Mean margin

0.92

Mean accuracy of
optimal subset

6

0.88
0.86
0

10
20
30
40
Number of observations

50

(c) Part of Speech Tagging

Figure 3: Experimental results. (a) Temperature data: Improvement over the uniform spacing
heuristic. (b) CpG island data set: Effect of increasing the number of observations on
margin and classification accuracy. (c) Part-of-Speech tagging data set: Effect of increasing the number of observations on margin and F1 score.

6. Experiments
In this section, we evaluate our algorithms on several real world data sets. A special focus is on the
comparison of the optimal methods with the greedy heuristic and other heuristic methods for selecting observations, and on how the algorithms can be used for interactive structured classification.
6.1 Temperature Time Series
The first data set consists of temperature time series collected from a sensor network deployed at
Intel Research Berkeley (Deshpande et al., 2004) as described in our running example. Data was
continuously collected for 19 days, linear interpolation was used in case of missing samples. The
temperature was measured once every 60 minutes, and it was discretized into 10 bins of 2 degrees
Kelvin. To avoid overfitting, we used pseudo counts  = 0.5 when learning the model. Using
parameter sharing, we learned four sets of transition probabilities: from 12 am - 7am, 7 am - 12 pm,
12 pm - 7 pm and 7 pm - 12 am. Combining the data from three adjacent sensors, we got 53 sample
time series.
The goal of this task was to select k out of 24 time points during the day, during which sensor
readings are most informative. The experiment was designed to compare the performance of the
optimal algorithms, the greedy heuristic, and a uniform spacing heuristic, which distributed the k
observations uniformly over the day. Figure 3(a) shows the relative improvement of the optimal algorithms and the greedy heuristic over the uniform spacing heuristic. The performance is measured
in decrease of expected entropy, with zero observations as the baseline. It can be seen that if k is less
than about the half of all possible observations, the optimal algorithms decreased the expected uncertainty by several percent over both heuristics. The improvement gained by the optimal plan over
the subset selection algorithms appears to become more drastic if a large number of observations
(over half of all possible observations) is allowed. Furthermore, for a large number of observations,
the optimal subset and the subset selected by the greedy heuristic were almost identical.

574

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

6.2 CpG-Island Detection
We then studied the bioinformatics problem of finding CpG islands in DNA sequences. CpG islands
are regions in the genome with a high concentration of the cytosine-guanine sequence. These areas
are believed to be mainly located around the promoters of genes, which are frequently expressed in
the cell. In our experiment, we considered the gene loci HS381K22, AF047825 and AL133174, for
which the GenBank annotation listed three, two and one CpG islands each. We ran our algorithm
on a 50 base window at the beginning and end of each island, using the transition and emission
probabilities from Durbin, Eddy, Krogh, and Mitchison (1999) for our Hidden Markov Model, and
we used the sum of margins as reward function.
The goal of this experiment was to locate the beginning and ending of the CpG islands more
precisely by asking experts, whether or not certain bases belong to the CpG region or not. Figure 3(b) shows the mean classification accuracy and mean margin scores for an increasing number
of observations. The results indicate that, although the expected margin scores are similar for the
optimal algorithm and the greedy heuristic, the mean classification performance of the optimal algorithm was still better than the performance of the greedy heuristic. For example, when making 6
observations, the mean classification error obtained by the optimal algorithm is 25% lower than the
error obtained by the greedy heuristic.
6.3 Part-of-Speech Tagging
In our third experiment, we investigated the structured classification task of part-of-speech (POS)
tagging (CoNLL, 2003). Problem instances are sequences of words (sentences), where each word
is part of an entity (e.g., European Union), and each entity belongs to one of five categories:
Location, Miscellaneous, Organization, Person or Other. Imagine an application, where automatic
information extraction is guided by an expert: Our algorithms compute an optimal conditional plan
for asking the expert, trying to optimize classification performance while requiring as little expert
interaction as possible.
We used a conditional random field for the structured classification task, where each node corresponds to a word, and the joint distribution is described by node potentials and edge potentials.
The sum of margins was used as reward function. Measure of classification performance was the F1
score, the geometric mean of precision and recall. The goal of this experiment was to analyze how
the addition of expert labels increases the classification performance, and how the indirect, decomposing reward function used in our algorithms corresponds to real world classification performance.
Figure 3(c) shows the increase of the mean expected margin and F1 score for an increasing number of observations, summarized over ten 50 word sequences. It can be seen that the classification
performance can be effectively enhanced by optimally incorporating expert labels. Requesting only
three out of 50 labels increased the mean F1 score from by more than five percent. The following
example illustrates this effect: In one scenario both words of an entity, the sportsman P. Simmons,
were classified incorrectly  P. as Other and Simmons as Miscellaneous. The first request of the
optimal conditional plan was to label Simmons. Upon labeling this word correctly, the word P.
was automatically labeled correctly also, resulting in an F1 score of 100 percent.

575

fiK RAUSE & G UESTRIN

7. Applying Chain Algorithms for More General Graphical Models
In Section 4 we have seen algorithms that can be used to schedule a single sensor, assuming the time
series of sensor readings (e.g., temperature) form a Markov chain. This is a very natural assumption
for sensor networks (Deshpande et al., 2004). When deploying sensor networks however, multiple
sensors need to be scheduled. If the time series for all the sensors were independent, we could use
our algorithms to schedule all the sensors independently of each other. However, in practice, the
measurements will be correlated across the different sensors  in fact, this dependence is essential
to allow generalization of measurements to locations where no sensor has been placed. In the following, we will describe an approach for using our single-sensor scheduling algorithm to coordinate
multiple sensors.
More formally, we are interested in monitoring a spatiotemporal phenomenon at a set of locations S = {1, . . . , m}, and time steps T = {1, . . . , T }. With each locationtime pair s, t, we
associate a random variable Xs,t that describes the state of the phenomenon at that location and
time. The random vector XS,T fully describes the relevant state of the world and the vector XS,t
describes the state at a particular time step t. As before, we make the Markov assumption, assuming
conditional independence of XS,t from XS,t0 given XS,t1 for all t0 < t  1.
Similarly as in the single-chain case, we consider reward functions Rs,t that are associated with
each variable Xs,t . Our goal is then to select, for each timestep, a set At  S of sensors to activate,
in order to maximize the sum of expected rewards. Letting A1:t = A1      At , the expected total
reward is then given as
X
Rs,t (Xs,t | XA1:t )
s,t

for the filtering setting (i.e., only observations in the past are taken into account for evaluating the
rewards), and
X
Rs,t (Xs,t | XA1:T )
s,t

for the smoothing setting (where all observations are taken into account). The generalization to
conditional planning is done as described in Section 2.
Note that in the case of a single sensor (` = 1), the problem of optimal sensor scheduling can
be solved using Algorithm 1. Unfortunately, the optimization problem is wildly intractable even for
the case of two sensors, ` = 2:
Corollary 7 (Hardness of sensor selection for two chains). Given a model with two dependent
chains, constants c and B, a cost function  and a set of decision theoretic value of information
functions Rs,t , it is NPPP -complete to determine whether there is a subset A1:T of variables such
that L(A1:T )  c and (A1:T )  B.
In the following, we will develop an approximate algorithm that uses our optimal single-chain algorithms and performs well in practice.
7.1 Approximate Sensor Scheduling by Lower Bound Maximization
The reason for the sudden increase in complexity in the case of multiple chains is that the decomposition of rewards along sub-chains (as described in Section 3) does not extend to the case of multiple

576

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

S(1)1

S(1)2

S(1)3

S(1)4

S(1)5

S(2)1

S(2)2

S(2)3

S(2)4

S(2)5

Figure 4: Scheduling multiple correlated sensors in dynamic processes.
sensors, since influence can flow across chains. Figure 4 visualizes this problem  there, the distri(1)
(1)
(2)
bution for sensor (2) depends on all three observations S1 and S4 from sensor (1) and S2 from
sensor (2).
We address this complexity issue using an (approximate) extension of the decomposition approach used for single chains. We will focus on the decision-theoretic value of information objective (as described in Section 2.1), but other local reward functions, such as residual entropy, can be
used as well.
Considering only recent observations. As a first approximation, we only allow a sensor to take
into account the most recent observations. Intuitively, this appears to be a reasonable approximation,
especially if the potential scheduling times in T are reasonably far apart. Formally, when evaluating
the local rewards at time t, we replace the set of observations up to time t, A1:t  T by a subset
A01:t  A1:t such that

	
A01:t = (s, t)  A1:t : t  t0 for all (s, t0 )  A1:t ,
i.e, for each sensor s, only the last observation (with largest time index t) is kept. We then
approximate Rs,t (Xs,t | A1:t ) by Rs,t (Xs,t | A01:t ). In Figure 4 for example, where A1:5 =
{(s1 , 1), (s2 , 2), (s1 , 4)}, the total expected utility at time t5 would be computed using only observations A01:5 = {(s2 , 2), (s1 , 4)}, i.e., using time t4 for sensor one, and time t2 for sensor two,
(1)
ignoring influence originating from observation S1 and flowing through the chains as indicated by
the dashed arrow. The following proposition proves that this approximation is a lower bound to the
true value of information:
Proposition 8 (Monotonicity of value of information). The decision-theoretic value of information Rs,t (A) of a set A of sensors is monotonic in A,
Rs,t (A0 )  Rs,t (A)
for all A0  A.
Proposition 8 proves that conditioning only on the most recent observations can only decrease our
objective function, hence maximizing this approximate objective implies maximizing a lower bound
on the true objective.
A coordinate ascent approach. We propose the following heuristic for maximizing the lower
bound on the expected utility. Instead of jointly optimizing over all schedules (timesteps selected
for each sensor), the algorithm will repeatedly iterate over all sensors. For all sensors s, it will
optimize the selected observations As1:T , holding the schedules for all other sensors fixed. This
577

fiK RAUSE & G UESTRIN

procedure resembles a coordinate ascent approach, where each coordinate ranges over all possible
schedules for a fixed sensor s.
When optimizing for sensor s, the algorithm finds a schedule As1:T such that


[
X
As1:T = argmax
Rs,t Xs,t | XA01:t
XA0s0 such that (As1:T )  B,
(6)
A1:T

s0 6=s

s,t

1:t

i.e., that maximizes, over all schedules A1:T , the sum of expected rewards for all time steps and
0
sensors, given the schedules As1:T for all non-selected sensors s0 .
Solving the single-chain optimization problem. In order to solve the maximization problem
(6) for the individual sensors, we use the same dynamic programming approach as introduced in
lt
Section 4. The recursive case Lfa:b
(k) for k > 0 is exactly the same. However, the base case is
computed as
b1 X


X
[
f lt
La:b (0) =
Rs,j Xs,j | Xa
XA0s0 ,
s0 6=s

j=a+1 s

1:j

i.e., it takes into account the most recent observation for all non-selected sensors s0 .
lt
(0). First of all, in
Several remarks need to be made about the computation of the base case Lfa:b
a naive implementation, the computation of the expected utility


[
Rs,j Xs,j | Xa
XA0s0
s0 6=s

1:j

requires time exponential in the number of chains. This is the case since, in order to compute the
reward Rs,t , for each chain, all possible observations XA0s
= xA0s
that could be made need to be
1:t
1:t
taken into account. This computation requires computing the expectation over the joint distribution
P (XA01:t ), which is exponential in size. This increase in complexity can be avoided using a sampling
approximation: Hoeffdings inequality can be used to derive polynomial bounds on sample complexity for approximating the value of information up to arbitrarily small additive error , similarly
as done in the approach of Krause and Guestrin (2005a)4 . In practice, a small number of samples
appears to provide reasonable performance. Secondly, inference itself becomes intractable with an
increasing number of sensors. Approximate inference algorithms such as the algorithm proposed
by Boyen and Koller (1998) provide a viable way around this problem.
Analysis. Since all sensors maximize the same global objective L(A1:T ), the coordinated ascent
approach is guaranteed to monotonically increase the global objective with every iteration (ignoring
possible errors due to sampling or approximate inference). Hence it must converge (to a local
optimum) after a finite number of steps. The procedure is formalized in Algorithm 4.
Although we cannot in general provide performance guarantees for the procedure, we are building on an algorithm that provides an optimal schedule for each sensor in isolation, which should
benefit from observations provided by the remaining sensors. Also, note that if the sensors are all
independent, Algorithm 4 will obtain the optimal solution. Even if the sensors are correlated, the
obtained solution will be at least as good as the solution obtained when scheduling all sensors independently of each other. Algorithm 4 will always converge, and always compute a lower bound on
4. An absolute error of at most  when evaluating each reward Rs,t can accumulate to a total error of at most |T ||S|
for all variables and hence to the error of the optimal schedule.

578

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

Input: Budget B
Output: Selection A1 , . . . , A` of observation times for each sensor
begin
Select Ai , 1  i  ` at random;
repeat
for i = 1 to ` do
Use Algorithm 1 to select observations Ai for sensor i, but conditioning on current
sensor scheduling Aj , j 6= i, for remaining sensors;
end
Compute improvement  in total expected utility;
until  small enough ;
end
Algorithm 4: Multi-Sensor scheduling.
the expected total utility. Considering the intractability of the general problem even for two chains
(c.f., , Corollary 7), these properties are reassuring. In our experiments, the coordinated sensor
scheduling performed very well, as discussed in Section 7.2.
7.2 Proof of Concept Study on Real Deployment
In the work by Singhvi et al. (2005), we presented an approach for optimizing light control in
buildings, with the purpose of satisfying building occupants preferences about lighting conditions,
and simultaneously minimizing energy consumption. In our approach, a wireless sensor network
is deployed that monitors the building for environmental conditions (such as the sunlight intensity
etc.). The sensors feed their measurements to a building controller that actuates the lighting system
(lamps, blinds, etc.) accordingly. At every timestep t  T , the building controller can choose
an action that affects the lighting conditions at all locations S in the building. Utility functions
Ut (a, xS,t ) are specified that map the chosen actions and the current lighting levels to a utility
value. This utility is chosen to capture both users preferences about light levels, as well as the
energy consumption of the lighting system. Details on the utility functions are described in detail
by Singhvi et al..
We evaluated our multi-sensor scheduling approach in a real building controller testbed, as
described in detail by Singhvi et al.. In our experiments, we used Algorithm 4 to schedule three
sensors, allowing each sensor to choose a subset out of ten time steps (in one-hour intervals during
daytime). We varied the number of timesteps during which each sensor is activated, and computed
the total energy consumption and total user utility (as defined by Singhvi et al.). Figure 5(a) shows
the mean user utility and energy savings achieved, for a number of observations varying from no
observations to continuous sensing (10 observations in our discretization)5 . These results imply that
using the predictive model and our active sensing strategy, even a very small number of observations
achieves results approximately as good as the results achieved by continuous sensing.
Figure 5(b) presents the mean total utility achieved using no observations, one observation or ten
observations per sensor each day. It can be seen that even a single observation per sensor increases
the total utility close to the level achieved by continuous sensing. Figure 5(c) shows the mean energy
5. Note that in Figure 5(a), energy cost and utility are plotted in different units and should not be directly compared.

579

fiK RAUSE & G UESTRIN

6

12
Energy cost

10

1 Observ./
sensor

15

10 Observ./
sensor
Energy cost

8

Total utility

User utility and energy cost

14

4
No observ.

2

8

No observ.

10

5

0

1 Observ./
sensor

Measured user utility
6

0

1

2 3
Number of observations

10

2

(a) Sensing scheduling evaluation

10

12
14
Hour of day

16

18

0

(b) Total utility

10

10 Observ./
sensor

12
14
Hour of day

16

18

(c) Energy cost

Figure 5: Active sensing results.
consumption required for the same experiment. Here, the single sensor observation strategy comes
even closer to the power savings achieved for continuous sensing.
Since the sensor network battery lifetime is in general inversely proportional to the amount of
power expended for sensing and communication, we conclude that our sensor scheduling strategy
promises to lead to drastic increases in sensor network lifetime, deployment permanence and reduced maintenance cost. In our testbed, the network lifetime could be increased by a factor of 3
without significant reduction in user utility and increase in energy cost.

8. Related Work
In this section, we review related work in a number of different areas.
8.1 Optimal Experimental Design
Optimal experimental design is a general methodology for selecting informative experiments to infer
about aspects of the state of the world (such as the parameters of a particular nonlinear function,
etc.). There is a large literature about different approaches to experimental design (c.f., Chaloner &
Verdinelli, 1995; Krause, Singh, & Guestrin, 2007).
In Bayesian experimental design, a prior distribution over possible states of the world is assumed, and experiments are chosen, e.g., to reduce the uncertainty in the posterior distribution. In
its general form, Bayesian experimental design was pioneered by Lindley (1956). The users encode
their preferences in a utility function U (P (), ? ), where the first argument, P (), is a distribution
over states of the world (i.e., the parameters) and the second argument, ? , is the true state of the
world. Observations xA are collected, and the change in expected utility under the prior P () and
posterior P ( | XA = xA ) can be used as a design criterion. In this sense, the value of observation problems considered in this paper can be considered instances of Bayesian experimental design
problems. Typically, Bayesian Experimental Design is employed for continuous distributions, often
the multivariate normal distribution. By choosing different utility functions, different notions of
optimality are defined, including A- and D- optimality can be developed (Chaloner & Verdinelli,
1995). If we have the posterior covariance matrix |A , whose
maximum

 eigenvalue is max , then
Bayesian A-, D-, and E- optimality minimizes tr |A , det |A , and max |A , respectively. In the terminology of Section 2.1, D-optimality corresponds to choosing the total entropy,
and A-optimality corresponds to the (weighted) mean-squared error criteria.

580

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

Even for multivariate normal distributions, optimal Bayesian Experimental design is NP-hard
(Ko, Lee, & Queyranne, 1995). In some applications of experimental design, the number of experiments to be selected is often large compared to the number of design choices. In these cases, one can
find a fractional design (i.e., a non-integral solution defining the proportions by which experiments
should be performed), and round the fractional solutions. In the fractional formulation, A-, D-, and
E-optimality criteria can be solved exactly using a semi-definite program (Boyd & Vandenberghe,
2004). There are however no known bounds on the integrality gap, i.e., the loss incurred by this
rounding process.
The algorithms presented in Section 4.1 can be used to optimally solve non-fractional Bayesian
Experimental Design problems for chain graphical models, even for continuous distributions, as
long as inference in these distributions is tractable (such as normal distributions). This paper hence
provides a new class of combinatorial algorithms for an interesting class of Bayesian experimental
design problems.
8.2 Value of Information in Graphical Models
Decision-theoretic value of information has been frequently used for principled information gathering (c.f., Howard, 1966; Lindley, 1956; Heckerman et al., 1993), and popularized in decision
analysis in the context of influence diagrams (Howard & Matheson, 1984). In a sense, value of
information problems are special cases of Bayesian experimental design problems, where the prior
distribution has a particular structure, typically given by a graphical model as considered in this
paper.
Several researchers (Scheffer et al., 2001; van der Gaag & Wessels, 1993; Dittmer & Jensen,
1997; Kapoor et al., 2007) suggested myopic, i.e., greedy approaches for selectively gathering
evidence in graphical models, as considered in this paper, which, unlike the algorithms presented
in this paper. While these algorithms are applicable to much more general graphical models, they
do not have theoretical guarantees. Heckerman et al. (1993) propose a method to compute the
maximum expected utility for specific sets of observations. While their work considers more general
graphical models than this paper (Naive Bayes models and certain extensions), they provide only
large sample guarantees for the evaluation of a given sequence of observations, and use a heuristic
without guarantees to select such sequences. Bilgic and Getoor (2007) present a branch and bound
approach towards exactly optimizing value of information in more complex probabilistic models.
In contrast to the algorithms described in this paper however, their approach has running time that
is worst-case exponential. Munie and Shoham (2008) present algorithms and hardness results for
optimizing a special class of value of information objective functions that are motivated by optimal
educational testing problems. Their algorithms apply to a different class of graphical models than
chains, and only apply for specific objective functions, rather than general local reward functions as
considered in this paper. Radovilsky, Shattah, and Shimony (2006) extended the previous version
of our paper (Krause & Guestrin, 2005a) to obtain approximation algorithms with guarantees in the
case of noisy observations (i.e., selecting a subset of the emission variables to observe, rather than
selecting among the hidden variables as considered in this paper).
8.3 Bandit Problems and Exploration / Exploitation
An important class of sequential value of information problems is the class of Bandit problems. In
the classical k-armed bandit problem, as formalized by Robbins (1952), a slot machine is given
581

fiK RAUSE & G UESTRIN

with k arms. A draw from arm i results in a reward with success probability pi that is fixed for each
arm, but different (and independent) across each arm. When selecting arms to pull, an important
problem is to trade off exploration (i.e., estimation of the success probabilities of the arms) and
exploitation (i.e., repeatedly pulling the best arm known so far). A celebrated result by Gittins
and Jones (1979) shows that for a fixed number of draws, an optimal strategy can be computed in
polynomial time, using a dynamic programming based algorithm. While similar in the sense that
an optimal sequential strategy can be computed in polynomial time, Gittins algorithm however has
different structure from the dynamic programming algorithms presented in this paper.
Note that using the function optimization objective function described in Section 2.1, our
approach can be used to solve a particular instance of bandit problems, where the arms are not
required to be independent, but, in contrary to the classical notion of bandit problems, can not be
chosen repeatedly.
8.4 Probabilistic Planning
Optimized information gathering has been also extensively studied in the planning community.
Bayer-Zubek (2004) for example proposed a heuristic method based on the Markov Decision Process framework. However, her approach makes approximations without theoretical guarantees.
The problem of optimizing decision theoretic value of information can be naturally formalized
as a (finite-horizon) Partially Observable Markov Decision Process (POMDP, Smallwood & Sondik,
1973). Hence, in principle, algorithms for planning in POMDPs, such as the anytime algorithm by
Pineau, Gordon, and Thrun (2006), can be employed for optimizing value of information. Unfortunately, the state space grows exponentially with the number of variables that are considered in
the selection problem. In addition, the complexity of planning in POMDPs grows exponentially in
the cardinality of the state space, hence doubly-exponentially in the number of variables for selection. This steep increase in complexity makes application of black-box POMDP solvers infeasible.
Recently, Ji, Parr, and Carin (2007) demonstrated the use of POMDP planning on a multi-sensor
scheduling problem. While presenting promising empirical results, their approach however uses
approximate POMDP planning techniques without theoretical guarantees.
In the robotics literature, Stachniss, Grisetti, and Burgard (2005), Sim and Roy (2005) and
Kollar and Roy (2008) have presented approaches to information gathering in the context of Simultaneous Localization and Mapping (SLAM). None of these approaches however provide guarantees
about the quality of the obtained solutions. Singh, Krause, Guestrin, Kaiser, and Batalin (2007)
present an approximation algorithm with theoretical guarantees for the problem of planning an informative path for environmental monitoring using Gaussian Process models. In contrast to the
algorithms presented in this paper, while dealing with more complex probabilistic models and more
complex cost functions arising from path planning, their approach requires submodular objective
functions (a property that does not hold for value of information as we show in Proposition 9).
8.5 Sensor Selection and Scheduling
In the context of wireless sensor networks, where sensor nodes have limited battery and can hence
only enable a small number of measurements, optimizing the value of information from the selected
sensors plays a key role. The problem of deciding when to selectively turn on sensors in order to
conserve power was first discussed by Slijepcevic and Potkonjak (2001) and Zhao, Shin, and Reich
(2002). Typically, it is assumed that sensors are associated with a fixed sensing region, and a spatial
582

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

domain needs to be covered by the regions associated with the selected sensors. Abrams, Goel,
and Plotkin (2004) present an efficient approximation algorithm with theoretical guarantees for this
problem. Deshpande, Khuller, Malekian, and Toossi (2008) present an approach for this problem
based on semidefinite programming (SDP), handling more general constraints and providing tighter
approximations. The approaches described above do not apply to the problem of optimizing sensor schedules for more complex utility functions such as, e.g., the increase in prediction accuracy
and other objectives considered in this paper. To address these shortcomings, Koushanfary, Taft,
and Potkonjak (2006) developed an approach for sensor scheduling that guarantees a specified prediction accuracy based on a regression model. However, their approach relies on the solution of
a Mixed Integer Program, which is intractable in general. Zhao et al. (2002) proposed heuristics
for selectively querying nodes in a sensor network in order to reduce the entropy of the prediction. Unlike the algorithms presented in this paper, their approaches do not have any performance
guarantees.
8.6 Relationship to Machine Learning
Decision Trees (Quinlan, 1986) popularized the value of information as a criterion for creating
conditional plans. Unfortunately, there are no guarantees on the performance of this greedy method.
The subset selection problem as an instance of feature selection is a central issue in machine
learning, with a vast amount of literature (see Molina, Belanche, & Nebot, 2002 for a survey).
However, we are not aware of any work providing similarly strong performance guarantees than the
algorithms considered in this paper.
The problem of choosing observations also has a strong connection to the field of active learning
(c.f., Cohn, Gharamani, & Jordan, 1996; Tong & Koller, 2001) in which the learning system designs
experiments based on its observations. While sample complexity bounds have been derived for
some active learning problems (c.f., Dasgupta, 2005; Balcan, Beygelzimer, & Langford, 2006), we
are not aware of any active learning algorithms that perform provably optimal (even for restricted
classes of problem instances).
8.7 Previous Work by the Authors
A previous version of this paper appeared in the work by Krause and Guestrin (2005b). Some of
the contents of Section 7 appeared as part of the work by Singhvi et al. (2005). The present version
is much extended, with new algorithmic and hardness results and more detailed discussions.
In light of the negative results presented in Section 5, we cannot expect to be able to optimize value of information in more complex models than chains. However, instead of attempting
to solve for the optimal solution, one might wonder whether it is possible to obtain good approximations. The authors showed (Krause & Guestrin, 2005a; Krause et al., 2007; Krause, Leskovec,
Guestrin, VanBriesen, & Faloutsos, 2008) that a large number of practical objective functions satisfy an intuitive diminishing returns property: Adding a new observation helps more if we have few
observations so far, and less if we have already made many observations. This intuition can be formalized using the combinatorial concept called submodularity. A fundamental result by Nemhauser
et al. proves that when optimizing a submodular utility function, the myopic greedy algorithm in
fact provides a near-optimal solution, that is within a constant factor of (11/e)  63% of optimal.
Unfortunately, decision theoretic value of information does not satisfy submodularity.

583

fiK RAUSE & G UESTRIN

Proposition 9 (Non-submodularity of value of information). Decision-theoretic value of information is not submodular, even in Naive Bayes models.
Intuitively, value of information can be non-submodular, if we need to make several observations in
order to convince ourselves that we need to change our action.

9. Conclusions
We have described novel efficient algorithms for optimal subset selection and conditional plan computation in chain graphical models (and trees with few leaves), including HMMs. Our empirical
evaluation indicates that these algorithms can improve upon commonly used heuristics for decreasing expected uncertainty. Our algorithms can also effectively enhance performance in interactive
structured classification tasks.
Unfortunately, the optimization problems become wildly intractable for even a slight generalization of chains. We presented surprising theoretical limits, which indicate that even the class of
decision theoretic value of information functions (as widely used, e.g., in influence diagrams and
POMDPs) cannot be efficiently computed even in Naive Bayes models. We also identified optimization of value of information as a new class of problems that are intractable (NPPP -complete)
for polytrees.
Our hardness results, along with other recent results for polytree graphical models, the NPcompleteness of maximum a posteriori assignment (Park & Darwiche, 2004) and NP-hardness
of inference in conditional linear Gaussian models (Lerner & Parr, 2001), suggest the possibility of
developing a generalized complexity characterization of problems that are hard in polytree graphical
models.
In light of these theoretical limits for computing optimal solutions, it is a natural question to ask
whether approximation algorithms with non-trivial performance guarantees can be found. Recent
results by Krause and Guestrin (2005a), Radovilsky et al. (2006) and Krause et al. (2007) show that
this is the case for interesting classes of value of information problems.

Acknowledgments
We would like to thank Ben Taskar for providing the part-of-speech tagging model, and Reuters
for making their news archive available. We would also like to thank Brigham Anderson and Andrew Moore for helpful comments and discussions. This work was partially supported by NSF
Grants No. CNS-0509383, CNS-0625518, ARO MURI W911NF0710287 and a gift from Intel.
Carlos Guestrin was partly supported by an Alfred P. Sloan Fellowship, an IBM Faculty Fellowship and an ONR Young Investigator Award N00014-08-1-0752 (2008-2011). Andreas Krause was
partially supported by a Microsoft Research Graduate Fellowship.

Appendix A
Proof of Theorem 3. Membership in #P for arbitrary discrete polytrees is straightforward since
inference in such models is in P. Let  be an instance of #3SAT , where we have to count
the number of assignments to X1 , . . . , Xn satisfying . Let C = {C1 , . . . , Cm } be the set of
clauses. Now create a Bayesian network with 2n + 1 variables, X1 , . . . , Xn , U1 , . . . , Un and Y,
where the Xi are conditionally independent given Y. Let Y be uniformly distributed over the values
584

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

Y
U1

U2

Un


X1

X2

Xn

Figure 6: Graphical model used in the proof of Theorem 3.
{n, (n  1), . . . , 1, 1, . . . , m  1, m}, and each Ui have Bernoulli prior with p = 0.5. Let the
observed variables Xi have CPTs defined the following way:

1, if Xi = u satisfies clause Cj ;
Xi | [Y = +j, Ui = u] 
0, otherwise.

0, if i = j;
Xi | [Y = j, Ui = u] 
u, otherwise.
In this model, which is presented in Figure 6, it holds that X1 = X2 =    = Xn = 1 iff U1 , . . . , Un
encode a satisfying assignment of , and Y > 0. Hence, if we observe X1 = X2 =    = Xn = 1,
we know that Y > 0 with certainty. Furthermore, if at least one Xi = 0, we know that
P (Y > 0 | X = x) < 1. Let all nodes have zero reward, except for Y, which is assigned a
reward function with the following properties (we will show below how we can model such a local
reward function using the decision-theoretic value of information):
 (n+m)2n
, if P (Y > 0 | XA = xA ) = 1;
m
R(Y | XA = xA ) =
0,
otherwise.
By the above argument, the expected reward
X
R(Y | X1 , . . . , Xn ) =
P (Y = y)P (U = u)P (x| u)R(Y | X = x)
u,y,x

=

X

P (Y > 0)P (u)

u sat 

X
(n + m)2n
=
1
m
u sat 

is exactly the number of satisfying assignments to . Note that the model defined above is not yet a
Naive Bayes model. However, it can easily be turned into one by marginalizing out U.
We will now show how we can realize a reward function with the above properties in the maximum expected utility sense. Let D = {d1 , d2 } be a set of two decisions. Define a utility function
with the property:

(n+m)2n

,
if d = d1 and y > 0;

m
(n+m)22n+1
u(y, d) =
, if d = d1 and y < 0;

 0, n
otherwise.
The reward R(Y | XA ) is then given as the decision-theoretic value of information:
X
X
R(Y | XA ) =
P (xA ) max
P (y | xA )u(y, d).
xA

d

585

y

fiK RAUSE & G UESTRIN

Figure 7: Graphical model used in proof of Theorem 5.
The utility function u is based on the following consideration. Upon observing a particular instantiation of the variables X1 , . . . , Xn we make a decision d about variable Y. Our goal is to achieve
that the number of times action d1 is chosen exactly corresponds to the number of satisfying assignments to . This is accomplished in the following way. If all Xi are 1, then we know that the Ui had
encoded a satisfying assignment, and Y > 0 with probability 1. In this case, action d1 is chosen.
Now we need to make sure that whenever at least one Xi = 0 (which indicates either that Y < 0
or U is not a satisfying assignment) decision d2 is chosen. Now, if at least one Xi = 0, then either
Y = j > 0 and clause j was not satisfied, or Y < 0. The utilities are designed such that unless
n
P (Y > 0 | XA = xA )  1  n22m , the action d2 gives the higher expected reward of 0. Hereby,
n2n
2m is a lower bound on the probability of misclassification P (Y < 0 | XA = xA ).
Note that the above construction immediately proves the hardness of approximation: Suppose
there were a polynomial time algorithm which computes an approximation R that is within any
factor  > 1 (which can depend on the problem instance) of R = R(Y | X1 , . . . , Xn ). Then R > 0
implies that R > 0, and R = 0 implies that R = 0. Hence, the approximation R can be used to
decide whether  is satisfiable or not, implying that P = NP.
Proof of Corollary 4. Let  be a 3CNF formula. We convert it into a Naive Bayes model over variables X1 , . . . , Xn and Y as in the construction of Theorem 3. The function L(V) where
V = {1, . . . , n} is the set of all variables Xi counts the number of satisfying assignments to .
Note that the function L(A) for A  V = {1, . . . , n} is monotonic, i.e., L(A)  L(V) for all
A  V, as shown in Proposition 8. Hence the majority of assignments satisfies  if and only if
L(V) > 2n1 .
Proof of Theorem 5. Membership follows from the fact that inference in polytrees is in P for discrete polytrees: A nondeterministic Turing machine with #P oracle can first guess the selection
of variables, then compute the value of information using Theorem 3 (since such computation is
#P-complete for arbitrary discrete polytrees), and compare against constant c.
To show hardness, let  be an instance of EM AJSAT , where we have to find an instantiation
of X1 , . . . , Xn such that (X1 , . . . , X2n ) is true for the majority of assignments to Xn+1 , . . . , X2n .
Let C = {C1 , . . . , Cm } be the set of 3CNF clauses. Create the Bayesian network shown in Figure 7,
with nodes Ui , each having a uniform Bernoulli prior. Add bivariate variables Yi = (seli , pari ),
0  i  2n, where seli takes values in {0, . . . , m} and pari is a parity bit. The CPTs for Yi are

586

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

defined as: sel0 uniformly varies over {1, . . . , m}, par0 = 0, and for Y1 , . . . , Y2n :

0, if j = 0, or ui satisfies Cj ;
seli | [seli1 = j, Ui = ui ] 
j, otherwise;
pari | [pari1 = bi1 , Ui ]  bi1  Ui ,
where  denotes the parity (XOR) operator. We now add variables ZiT and ZiF for 1  i  n and
let

Uniform({0, 1}), if ui = 1;
T
Zi | [Ui = ui ] 
0,
otherwise;
where Uniform denotes the uniform distribution. Similarly, let

Uniform({0, 1}), if ui = 0;
ZiF | [Ui = ui ] 
0,
otherwise.
Intuitively, ZiT = 1 guarantees us that Ui = 1, whereas ZiT = 0 leaves us uncertain about Ui . The
case of ZiF is symmetric.
We use the subset selection algorithm to choose the Zi s that encode the solution to EM AJSAT .
If ZiT is chosen, it will indicate that Xi should set to true, similarly ZiF indicates a false assignment
to Xi . The parity function is going to be used to ensure that exactly one of {ZiT , ZiF } is observed
for each i.
We first assign penalties  to all nodes except ZiT , ZiF for 1  i  n, and Uj for
n + 1  j  2n, which are assigned zero penalty. Let all nodes have zero reward, except for
Y2n , which is assigned the following reward:
 n
 4 , if P (sel2n = 0 | XA = xA ) = 1 and
[P (par2n = 1 | XA = xA ) = 1 or P (par2n = 0 | XA = xA ) = 1];
R(Y2n | XA = xA ) =

0,
otherwise.
Note that sel2n = 0 with probability 1 iff U1 , . . . , U2n encode a satisfying assignment of . Furthermore, we get positive reward only if we are both certain that sel2n = 0, i.e., the chosen observation
set must contain a proof that  is satisfied, and we are certain about par2n . The parity certainty
will only occur if we are certain about the assignment U1 , . . . , U2n . It is only possible to infer the
value of each Ui with certainty by observing one of Ui , ZiT or ZiF . Since, for i = 1, . . . , n, the cost
of observing Ui is , to receive any reward we must observe at least one of ZiT or ZiF . Assume
that we compute the optimal subset O for budget 2n, then we can only receive positive reward by
observing exactly one of ZiT or ZiF .
We interpret the selection of ZiT and ZiF as an assignment to the first n variables of EM AJSAT .
Let R = R(Y2n | O). We claim that   EM AJSAT if and only if R > 0.5. First let
  EM AJSAT , with assignment x1 , . . . , xn to the first n variables. Now add Un+1 , . . . , U2n
to O and add ZiT to O iff xi = 1 and ZiF to O iff xi = 0. This selection guarantees R > 0.5.
Now assume R > 0.5. We call an assignment to U1 , . . . , U2n consistent if for any 1  i  n,
if ZiT  O, then Ui = 1 and if ZiF  O then Ui = 0. For any consistent assignment, the chance
that the observations Zi prove the consistency is 2n . Hence R > 0.5 implies that the majority of
all provably consistent assignments satisfy  and hence   EM AJSAT . This proves that subset
selection is NPPP complete.
Note that we can realize the local reward function R in the sense of maximum expected utility
similarly as described in the Proof of Theorem 3.
587

fiK RAUSE & G UESTRIN

Proof of Corollary 6. The constructions in the proof of Theorem 4 and Theorem 5 also prove that
computing conditional plans is PP-hard and NPPP -hard respectively, since, in these instances,
any plan with positive reward must observe variables corresponding to valid instantiations (i.e., all
X1 , . . . , Xn in Corollary 4, and all Un+1 , . . . , U2n and one each of the Z1 , . . . , Zn to satisfy the
parity condition in Theorem 5). In these cases, the order of selection is irrelevant, and, hence, the
conditional plan effectively performs subset selection.
Proof of Corollary 7. The proof follows from the observation that polytree construction from the
proof of Theorem 5 can be arranged into two dependent chains. For this transformation, we revert
the arc between ZiT and Ui by applying Bayes rule. To make sure there are the same number of
nodes for each sensor in each timeslice, we triple the variables Yi , calling the copies Yi0 and Yi00 .
The conditional probability tables are given as equality constraints, Yi0 = Yi and Yi00 = Yi0 . After
this transformation, the variables associated with timesteps 3i  2 (for i  1) are given by the sets
00 , Z T }. timesteps 3i  1 are associated with the sets {U , Y }, and timesteps 3i are associated
{Yi1
i
i
i
with {ZiF , Yi0 }.
Proof of Proposition 8. This bound follows from the fact that maximization over a is convex, and
an application of Jensens inequality. Using an induction argument, we simply need to show that
L(A)  L().
!
X
X
L(A) =
P (XA = xA )
max EU (a, t, x | XA1:t = xA1:t )
xA

a

tV

!


X
tV

=

X
tV

max
a

X

P (XA = xA )EU (a, t, x | XA1:t = xA1:t )

xA

max EU (a, t, x) = L()
a

where
EU (a, t, x | XA1:t = xA1:t ) =

X

P (xt | XA1:t = xA1:t )Ut (a, xt )

xt

is the expected utility of action a at time t after observing XA1:t = xA1:t .
Proof of Proposition 9. Consider the following binary classification problem with assymetric cost.
We have one Bernoulli random variable Y (the class label) with P (Y = 1) = 0.5 and
P (Y = 1) = 0.5. We also have two noisy observations X1 , X2 , which are conditionally independent given Y. Let P (Xi = Y) = 3/4 (i.e., the observations agree with the class label with
probability 3/4, and disagree with probability 1/4. We have three actions, a1 (classifying Y as 1),
a1 (classifying Y as -1) and a0 (not assigning any label). We define our utility functon U such that
we gain utility 1 if we assign the label correctly (U (a1 , 1) = U (a1 , 1) = 1), 3 is we misassign
the label (U (a1 , 1) = U (a1 , 1) = 3), and 0 if we choose a0 , i.e., not assign any label. Now,
2
2
6
> 0.
we can verify that L() = L({X1 }) = L({X2 }) = 0, but L({X1 , X2 }) = 43  3 14 = 16
Hence, adding X2 to X1 increases the utility more than adding X2 to the empty set, contradicting
submodularity.

588

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

References
Abrams, Z., Goel, A., & Plotkin, S. (2004). Set k-cover algorithms for energy efficient monitoring
in wireless sensor networks.. In IPSN.
Balcan, N., Beygelzimer, A., & Langford, J. (2006). Agnostic active learning. In ICML.
Baum, L. E., & Petrie, T. (1966). Statistical inference for probabilistic functions of finite state
Markov chains. Ann. Math. Stat, 37, 15541563.
Bayer-Zubek, V. (2004). Learning diagnostic policies from examples by systematic search. In UAI.
Bellman, R. (1957). A Markovian decision process. Journal of Mathematics and Mechanics, 6.
Bilgic, M., & Getoor, L. (2007). Voila: Efficient feature-value acquisition for classification. In
Twenty-Second Conference on Artificial Intelligence (AAAI).
Boyd, S., & Vandenberghe, L. (2004). Convex Optimization. Cambridge UP.
Boyen, X., & Koller, D. (1998). Tractable inference for complex stochastic processes. In Uncertainty in Artificial Intelligence (UAI).
Chaloner, K., & Verdinelli, I. (1995). Bayesian experimental design: A review. Statistical Science,
10(3), 273304.
Cohn, D. A., Gharamani, Z., & Jordan, M. I. (1996). Active learning with statistical models. J AI
Research, 4, 129145.
CoNLL (2003).
Conference on computational natural language learning shared task.
http://cnts.uia.ac.be/conll2003/ner/.
Cover, T. M., & Thomas, J. A. (1991). Elements of Information Theory. Wiley Interscience.
Dasgupta, S. (2005). Coarse sample complexity bounds for active learning. In NIPS.
Deshpande, A., Guestrin, C., Madden, S., Hellerstein, J., & Hong, W. (2004). Model-driven data
acquisition in sensor networks. In VLDB.
Deshpande, A., Khuller, S., Malekian, A., & Toossi, M. (2008). Energy efficient monitoring in
sensor networks. In LATIN.
Dittmer, S., & Jensen, F. (1997). Myopic value of information in influence diagrams. In UAI, pp.
142149, San Francisco.
Domingos, P., & Pazzani, M. (1997). On the optimality of the simple Bayesian classifier under
zero-one loss. Machine Learning, 29, 103137.
Durbin, R., Eddy, S. R., Krogh, A., & Mitchison, G. (1999). Biological Sequence Analysis : Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press.
Gittins, J. C., & Jones, D. M. (1979). A dynamic allocation index for the discounted multiarmed
bandit problem. Biometrika, 66(3), 561565.
Goldberg, L. A., & Jerrum, M. (2000). Counting unlabelled subtrees of a tree is #p-complete. LMS
J Comput. Math., 3, 117124.
Heckerman, D., Horvitz, E., & Middleton, B. (1993). An approximate nonmyopic computation for
value of information. IEEE Trans. Pattern Analysis and Machine Intelligence, 15, 292298.

589

fiK RAUSE & G UESTRIN

Howard, R. A. (1966). Information value theory. In IEEE Transactions on Systems Science and
Cybernetics (SSC-2).
Howard, R. A., & Matheson, J. (1984). Readings on the Principles and Applications of Decision
Analysis II, chap. Influence Diagrams, pp. 719762. Strategic Decision Group, Menlo Park.
Reprinted 2005 in Decision Analysis 2(3) 127-143.
Ji, S., Parr, R., & Carin, L. (2007). Non-myopic multi-aspect sensing with partially observable
Markov decision processes. IEEE Transactions on Signal Processing, 55(6), 27202730.
Kapoor, A., Horvitz, E., & Basu, S. (2007). Selective supervision: Guiding supervised learning with
decision-theoretic active learning. In International Joint Conference on Artificial Intelligence
(IJCAI).
Keeney, R. L., & Raiffa, H. (1976). Decisions with Multiple Objectives: Preferences and Value
Trade-offs. Wiley.
Ko, C., Lee, J., & Queyranne, M. (1995). An exact algorithm for maximum entropy sampling.
Operations Research, 43(4), 684691.
Kollar, T., & Roy, N. (2008). Efficient optimization of information-theoretic exploration in slam. In
AAAI.
Koushanfary, F., Taft, N., & Potkonjak, M. (2006). Sleeping coordination for comprehensive sensing
using isotonic regression and domatic partitions. In Infocom.
Krause, A., & Guestrin, C. (2005a). Near-optimal nonmyopic value of information in graphical
models. In Proc. of Uncertainty in Artificial Intelligence (UAI).
Krause, A., & Guestrin, C. (2005b). Optimal nonmyopic value of information in graphical models
- efficient algorithms and theoretical limits. In Proc. of IJCAI.
Krause, A., Leskovec, J., Guestrin, C., VanBriesen, J., & Faloutsos, C. (2008). Efficient sensor
placement optimization for securing large water distribution networks. Journal of Water Resources Planning and Management, 136(6).
Krause, A., Singh, A., & Guestrin, C. (2007). Near-optimal sensor placements in Gaussian processes: Theory, efficient algorithms and empirical studies. In JMLR.
Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional random fields: Probabilistic models
for segmenting and labeling sequence data. In ICML.
Lerner, U., & Parr, R. (2001). Inference in hybrid networks: Theoretical limits and practical algorithms. In UAI.
Lindley, D. V. (1956). On a measure of the information provided by an experiment. Annals of
Mathematical Statistics, 27, 9861005.
Littman, M., Goldsmith, J., & Mundhenk, M. (1998). The computational complexity of probabilistic
planning. Journal of Artificial Intelligence Research, 9, 136.
Molina, L., Belanche, L., & Nebot, A. (2002). Feature selection algorithms: A survey and experimental evaluation. In ICDM.
Mookerjee, V. S., & Mannino, M. V. (1997). Sequential decision models for expert system optimization. IEEE Trans. Knowl. Data Eng., 9(5), 675687.

590

fiO PTIMAL VALUE OF I NFORMATION IN G RAPHICAL M ODELS

Munie, M., & Shoham, Y. (2008). Optimal testing of structured knowledge. In Twenty-Third Conference on Artificial Intelligence (AAAI).
Papadimitriou, C. H. (1995). Computational Complexity. Addison-Wesley.
Park, J. D., & Darwiche, A. (2004). Complexity results and approximation strategies for map
explanations. Journal of Aritificial Intelligence Research, 21, 101133.
Pineau, J., Gordon, G., & Thrun, S. (2006). Anytime point-based approximations for large pomdps.
JAIR, 27, 335380.
Quinlan, J. R. (1986). Induction of decision trees. Machine Learning, 1, 81106.
Radovilsky, Y., Shattah, G., & Shimony, S. E. (2006). Efficient deterministic approximation algorithms for non-myopic value of information in graphical models. In IEEE International
Conference on Systems, Man and Cybernetics (SMC), Vol. 3, pp. 25592564.
Robbins, H. (1952). Some aspects of the sequential design of experiments. Bulletin of the American
Mathematical Society, 58, 527535.
Scheffer, T., Decomain, C., & Wrobel, S. (2001). Active learning of partially hidden Markov models
for information extraction. In ECML/PKDD Workshop on Instance Selection.
Sim, R., & Roy, N. (2005). Global a-optimal robot exploration in slam. In IEEE International
Conference on Robotics and Automation (ICRA).
Singh, A., Krause, A., Guestrin, C., Kaiser, W. J., & Batalin, M. A. (2007). Efficient planning of
informative paths for multiple robots. In International Joint Conference on Artificial Intelligence (IJCAI), pp. 22042211, Hyderabad, India.
Singhvi, V., Krause, A., Guestrin, C., Garrett, J., & Matthews, H. (2005). Intelligent light control
using sensor networks. In Proc. of the 3rd ACM Conference on Embedded Networked Sensor
Systems (SenSys).
Slijepcevic, S., & Potkonjak, M. (2001). Power efficient organization of wireless sensor networks.
In ICC.
Smallwood, R., & Sondik, E. (1973). The optimal control of partially observable Markov decision
processes over a finite horizon. Operations Research, 21, 10711088.
Stachniss, C., Grisetti, G., & Burgard, W. (2005). Information gain-based exploration using raoblackwellized particle filters. In Robotics Science and Systems (RSS).
Tong, S., & Koller, D. (2001). Active learning for parameter estimation in Bayesian networks. In
NIPS.
Turney, P. D. (1995). Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision
tree induction algorithm. Journal of Artificial Intelligence Research, 2, 369409.
van der Gaag, L., & Wessels, M. (1993). Selective evidence gathering for diagnostic belief networks.
AISB Quart., 86, 2334.
Zhao, F., Shin, J., & Reich, J. (2002). Information-driven dynamic sensor collaboration for tracking
applications. IEEE Signal Processing, 19(2), 6172.

591

fiJournal of Artificial Intelligence Research 35 (2009) 1-47

Submitted 01/09; published 05/09

Complex Question Answering: Unsupervised Learning
Approaches and Experiments
Yllias Chali

chali@cs.uleth.ca

University of Lethbridge
Lethbridge, AB, Canada, T1K 3M4

Shafiq R. Joty

rjoty@cs.ubc.ca

University of British Columbia
Vancouver, BC, Canada, V6T 1Z4

Sadid A. Hasan

hasan@cs.uleth.ca

University of Lethbridge
Lethbridge, AB, Canada, T1K 3M4

Abstract
Complex questions that require inferencing and synthesizing information from multiple
documents can be seen as a kind of topic-oriented, informative multi-document summarization where the goal is to produce a single text as a compressed version of a set of
documents with a minimum loss of relevant information. In this paper, we experiment
with one empirical method and two unsupervised statistical machine learning techniques:
K-means and Expectation Maximization (EM), for computing relative importance of the
sentences. We compare the results of these approaches. Our experiments show that the
empirical approach outperforms the other two techniques and EM performs better than
K-means. However, the performance of these approaches depends entirely on the feature
set used and the weighting of these features. In order to measure the importance and
relevance to the user query we extract different kinds of features (i.e. lexical, lexical semantic, cosine similarity, basic element, tree kernel based syntactic and shallow-semantic)
for each of the document sentences. We use a local search technique to learn the weights
of the features. To the best of our knowledge, no study has used tree kernel functions
to encode syntactic/semantic information for more complex tasks such as computing the
relatedness between the query sentences and the document sentences in order to generate
query-focused summaries (or answers to complex questions). For each of our methods of
generating summaries (i.e. empirical, K-means and EM) we show the effects of syntactic
and shallow-semantic features over the bag-of-words (BOW) features.

1. Introduction
The vast increase in the amount of online text available and the demand for access to different types of information have led to a renewed interest in a broad range of Information
Retrieval (IR) related areas that go beyond the simple document retrieval. These areas
include question answering, topic detection and tracking, summarization, multimedia retrieval, chemical and biological informatics, text structuring, text mining, genomics, etc.
Automated Question Answering (QA)the ability of a machine to answer questions, simple
or complex, posed in ordinary human languageis perhaps the most exciting technological development of the past six or seven years (Strzalkowski & Harabagiu, 2008). The
c
2009
AI Access Foundation. All rights reserved.

fiChali, Joty, & Hasan

expectations are already tremendous, reaching beyond the discipline (a subfield of Natural
Language Processing (NLP)) itself.
As a tool for finding documents on the web, search engines are proven to be adequate.
Although there is no limitation in the expressiveness of the user in terms of query formulation, certain limitations exist in what the search engine does with the query. Complex
question answering tasks require multi-document summarization through an aggregated
search, or a faceted search, that represents an information need which cannot be answered
by a single document. For example, if we look for the comparison of the average number of
years between marriage and first birth for women in the U.S., Asia, and Europe, the answer
is likely contained in multiple documents. Multi-document summarization is useful for this
type of query and there is currently no tool on the market that is designed to meet this
kind of information need.
QA research attempts to deal with a wide range of question types including: fact, list,
definition, how, why, hypothetical, semantically-constrained, and cross-lingual questions.
Some questions, which we will call simple questions, are easier to answer. For example, the
question: Who is the president of Bangladesh? asks for a persons name. This type of
question (i.e. factoid) requires small snippets of text as the answer. Again, the question:
Which countries has Pope John Paul II visited? is a sample of a list question, asking only
for a list of small snippets of text.
After having made substantial headway in factoid and list questions, researchers have
turned their attention to more complex information needs that cannot be answered by
simply extracting named entities (persons, organizations, locations, dates, etc.) from documents. Unlike informationally simple factoid questions, complex questions often seek multiple different types of information simultaneously and do not presuppose that one single
answer can meet all of its information needs. For example, with a factoid question like:
How accurate are HIV tests? it can be safely assumed that the submitter of the question is looking for a number or a range of numbers. However, with complex questions like:
What are the causes of AIDS? the wider focus of this question suggests that the submitter
may not have a single or well-defined information need and therefore may be amenable to
receiving additional supporting information that is relevant to some (as yet) undefined informational goal (Harabagiu, Lacatusu, & Hickl, 2006). These questions require inferencing
and synthesizing information from multiple documents.
A well known QA systems is the Korean Navers Knowledge iN search1 , who were the
pioneers in community QA. This tool allows users to ask just about any question and get
answers from other users. Navers Knowledge iN now has roughly 10 times more entries
than Wikipedia. It is used by millions of Korean web users on any given day. Some people
say Koreans are not addicted to the internet but to Naver. As of January 2008 the Knowledge Search database included more than 80 million pages of user-generated information.
Another popular answer service is Yahoo! Answers which is a community-driven knowledge market website launched by Yahoo!. It allows users to both submit questions to be
answered and answer questions from other users. People vote on the best answer. The site
gives members the chance to earn points as a way to encourage participation and is based
on the Naver model. As of December 2006, Yahoo! Answers had 60 million users and 65
1. http://kin.naver.com/

2

fiComplex Question Answering: Unsupervised Approaches

million answers. Google had a QA system2 based on paid editors which was launched in
April 2002 and fully closed in December 2006.
However, from a computational linguistics point of view information synthesis can be
seen as a kind of topic-oriented informative multi-document summarization. The goal is to
produce a single text as a compressed version of a set of documents with a minimum loss
of relevant information. Unlike indicative summaries (which help to determine whether a
document is relevant to a particular topic), informative summaries must attempt to find
answers.
In this paper, we focus on an extractive approach of summarization where a subset of
the sentences in the original documents are chosen. This contrasts with abstractive summarization where the information in the text is rephrased. Although summaries produced by
humans are typically not extractive, most of the state of the art summarization systems are
based on extraction and they achieve better results than the automated abstraction. Here,
we experimented with one empirical and two well-known unsupervised statistical machine
learning techniques: K-means and EM and evaluated their performance in generating topicoriented summaries. However, the performance of these approaches depends entirely on the
feature set used and the weighting of these features. In order to measure the importance
and relevance to the user query we extract different kinds of features (i.e. lexical, lexical
semantic, cosine similarity, basic element, tree kernel based syntactic and shallow-semantic)
for each of the document sentences. We have used a gradient descent local search technique
to learn the weights of the features.
Traditionally, information extraction techniques are based on the BOW approach augmented by language modeling. But when the task requires the use of more complex semantics, the approaches based on only BOW are often inadequate to perform fine-level textual
analysis. Some improvements on BOW are given by the use of dependency trees and syntactic parse trees (Hirao, , Suzuki, Isozaki, & Maeda, 2004; Punyakanok, Roth, & Yih, 2004;
Zhang & Lee, 2003b), but these too are not adequate when dealing with complex questions
whose answers are expressed by long and articulated sentences or even paragraphs. Shallow
semantic representations, bearing more compact information, could prevent the sparseness
of deep structural approaches and the weakness of BOW models (Moschitti, Quarteroni,
Basili, & Manandhar, 2007). As pinpointing the answer to a question relies on a deep understanding of the semantics of both, attempting an application of syntactic and semantic
information to complex QA seems natural. To the best of our knowledge, no study has used
tree kernel functions to encode syntactic/semantic information for more complex tasks such
as computing the relatedness between the query sentences and the document sentences in
order to generate query-focused summaries (or answers to complex questions). For all of
our methods of generating summaries (i.e. empirical, K-means and EM) we show the effects
of syntactic and shallow-semantic features over the BOW features.
Over the past three years, complex questions have been the focus of much attention in
both the automatic question-answering and Multi Document Summarization (MDS) communities. Typically, most current complex QA evaluations including the 2004 AQUAINT
Relationship QA Pilot, the 2005 Text Retrieval Conference (TREC) Relationship QA Task,
and the TREC definition (and others) require systems to return unstructured lists of can2. http://answers.google.com/

3

fiChali, Joty, & Hasan

didate answers in response to a complex question. However recently, MDS evaluations (including the 2005, 2006 and 2007 Document Understanding Conference (DUC)) have tasked
systems with returning paragraph-length answers to complex questions that are responsive,
relevant, and coherent.
Our experiments based on the DUC 2007 data show that including syntactic and semantic features improves the performance. Comparison among the approaches are also shown.
Comparing with DUC 2007 participants, our systems achieve top scores and there is no
statistically significant difference between the results of our system and the results of DUC
2007 best system.
This paper is organized as follows: Section 2 focuses on the related work, Section 3
gives a brief description of our intended final model, Section 4 describes how the features
are extracted, Section 5 discusses the learning issues and presents our learning approaches,
Section 6 discusses how we remove the redundant sentences before adding them to the final
summary, and Section 7 describes our experimental study. We conclude and discuss future
directions in Section 8.

2. Related Work
Researchers all over the world working on query-based summarization are trying different
directions to see which methods provide the best results.
There are a number of sentence retrieval systems based on IR (Information Retrieval)
techniques. These systems typically dont use a lot of linguistic information, but they still
deserve special attention. Murdock and Croft (2005) propose a translation model specifically
for monolingual data, and show that it significantly improves sentence retrieval over query
likelihood. Translation models train on a parallel corpus and they used a corpus of question/answer pairs. Losada (2005) presents a comparison between multiple-Bernoulli models
and multinomial models in the context of a sentence retrieval task and shows that a multivariate Bernoulli model can really outperform popular multinomial models for retrieving
relevant sentences. Losada and Fernandez (2007) propose a novel sentence retrieval method
based on extracting highly frequent terms from top retrieved documents. Their results reinforce the idea that top retrieved data is a valuable source to enhance retrieval systems.
This is specially true for short queries because there are usually few query-sentence matching terms. They argue that this method improves significantly the precision at top ranks
when handling poorly specified information needs.
The LexRank method addressed by Erkan and Radev (2004) was very successful in
generic multi-document summarization. A topic-sensitive LexRank is proposed by Otterbacher, Erkan, and Radev (2005). As in LexRank, the set of sentences in a document cluster
is represented as a graph where nodes are sentences, and links between the nodes are induced by a similarity relation between the sentences. The system then ranks the sentences
according to a random walk model defined in terms of both the inter-sentence similarities
and the similarities of the sentences to the topic description or question.
Concepts of coherence and cohesion enable us to capture the theme of the text. Coherence represents the overall structure of a multi-sentence text in terms of macro-level
relations between clauses or sentences (Halliday & Hasan, 1976). Cohesion, as defined by
Halliday and Hasan (1976), is the property of holding text together as one single grammat4

fiComplex Question Answering: Unsupervised Approaches

ical unit based on relations (i.e. ellipsis, conjunction, substitution, reference, and lexical
cohesion) between various elements of the text. Lexical cohesion is defined as the cohesion
that arises from the semantic relations (collocation, repetition, synonym, hypernym, hyponym, holonym, meronym, etc.) between the words in the text (Morris & Hirst, 1991).
Lexical cohesion among words are represented by lexical chains which are the sequences of
semantically related words. The summarization methods based on lexical chain first extract the nouns, compound nouns and named entities as candidate words (Li, Sun, Kit, &
Webster, 2007). Then using WordNet3 the systems find the semantic similarity between
the nouns and compound nouns. After that lexical chains are built in two steps:
1. Building single document strong chains while disambiguating the senses of the words.
2. Building a multi-chain by merging the strongest chains of the single documents into
one chain.
The systems rank sentences using a formula that involves a) the lexical chain, b) keywords from the query and c) named entities. For example, Li et al. (2007) uses the following
formula:
Score = P (chain) + P (query) + P (namedEntity)
where P (chain) is the sum of the scores of the chains whose words come from the
candidate sentence, P (query) is the sum of the co-occurrences of key words in a topic and
the sentence, and P (namedEntity) is the number of name entities existing in both the topic
and the sentence. The three coefficients ,  and  are set empirically. The top ranked
sentences are then selected to form the summary.
Harabagiu et al. (2006) introduce a new paradigm for processing complex questions
that relies on a combination of (a) question decompositions; (b) factoid QA techniques;
and (c) Multi-Document Summarization (MDS) techniques. The question decomposition
procedure operates on a Markov chain. That is, by following a random walk with a mixture
model on a bipartite graph of relations established between concepts related to the topic
of a complex question and subquestions derived from topic-relevant passages that manifest
these relations. Decomposed questions are then submitted to a state-of-the-art QA system
in order to retrieve a set of passages that can later be merged into a comprehensive answer by a MDS system. They show that question decompositions using this method can
significantly enhance the relevance and comprehensiveness of summary-length answers to
complex questions.
There are approaches that are based on probabilistic models (Pingali, K., & Varma,
2007; Toutanova, Brockett, Gamon, Jagarlamudi, Suzuki, & Vanderwende, 2007). Pingali
et al. (2007) rank the sentences based on a mixture model where each component of the
model is a statistical model:
Score(s) =   QIScore(s) + (1  )  QF ocus(s, Q)

(1)

3. WordNet (http://wordnet.princeton.edu/) is a widely used semantic lexicon for the English language.
It groups English words (i.e. nouns, verbs, adjectives and adverbs) into sets of synonyms called synsets,
provides short, general definitions (i.e. gloss definition), and records the various semantic relations
between these synonym sets.

5

fiChali, Joty, & Hasan

Where Score(s) is the score for sentence s. Query-independent score (QIScore) and
query-dependent score (QFocus) are calculated based on probabilistic models. Toutanova
et al. (2007) learns a log-linear sentence ranking model by maximizing three metrics of
sentence goodness: (a) ROUGE oracle, (b) Pyramid-derived, and (c) Model Frequency.
The scoring function is learned by fitting weights for a set of feature functions of sentences
in the document set and is trained to optimize a sentence pair-wise ranking criterion. The
scoring function is further adapted to apply to summaries rather than sentences and to take
into account redundancy among sentences.
Pingali et al. (2007) reduce the document-sentences by dropping words that do not
contain any important information. Toutanova et al. (2007), Vanderwende, Suzuki, and
Brockett (2006), and Zajic, Lin, Dorr, and Schwartz (2006) heuristically decompose the
document-sentences into smaller units. They apply a small set of heuristics to a parse
tree to create alternatives after which both the original sentence and (possibly multiple)
simplified versions are available for selection.
There are approaches in multi-document summarization that do try to cluster sentences
together. Guo and Stylios (2003) use verb arguments (i.e. subjects, times, locations and
actions) for clustering. For each sentence this method establishes the indices information
based on the verb arguments (subject is first index, time is second, location is third and
action is fourth). All the sentences that have the same or closest subjects index are put
in a cluster and they are sorted out according to the temporal sequence from the earliest
to the latest. Sentences that have the same spaces/locations index value in the cluster
are then marked out. The clusters are ranked based on their sizes and top 10 clusters are
chosen. Then, applying a cluster reduction module the system generates the compressed
extract summaries.
There are approaches in Recognizing Textual Entailment, Sentence Alignment, and
Question Answering that use syntactic and/or semantic information in order to measure
the similarity between two textual units. This indeed motivated us to include syntactic and
semantic features to get the structural similarity between a document sentence and a query
sentence (discussed in Section 4.1). MacCartney, Grenager, de Marneffe, Cer, and Manning
(2006) use typed dependency graphs (same as dependency trees) to represent the text and
the hypothesis. They try to find a good partial alignment between the typed dependency
graphs representing the hypothesis (contains n nodes) and the text (graph contains m
nodes) in a search space of O((m + 1)n). They use an incremental beam search combined
with a node ordering heuristic to do approximate global search in the space of possible
alignments. A locally decomposable scoring function was chosen such that the score of an
alignment is the sum of the local node and edge alignment scores. The scoring measure
is designed to favor alignments which align semantically similar subgraphs, irrespective of
polarity. For this reason, nodes receive high alignment scores when the words they represent
are semantically similar. Synonyms and antonyms receive the highest score and unrelated
words receive the lowest. Alignment scores also incorporate local edge scores which are based
on the shape of the paths between nodes in the text graph which correspond to adjacent
nodes in the hypothesis graph. In the final step they make a decision about whether or
not the hypothesis is entailed by the text conditioned on the typed dependency graphs as
well as the best alignment between them. To make this decision they use a supervised
6

fiComplex Question Answering: Unsupervised Approaches

statistical logistic regression classifier (with a feature space of 28 features) with a Gaussian
prior parameter for regularization.
Hirao et al. (2004) represent the sentences using Dependency Tree Path (DTP) to incorporate syntactic information. They apply String Subsequence Kernel (SSK) to measure
the similarity between the DTPs of two sentences. They also introduce Extended String
Subsequence Kernel (ESK) to incorporate semantics in DTPs. Kouylekov and Magnini
(2005) use the tree edit distance algorithms on the dependency trees of the text and the
hypothesis to recognize the textual entailment. According to this approach, a text T entails
a hypothesis H if there exists a sequence of transformations (i.e. deletion, insertion and
substitution) applied to T such that we can obtain H with an overall cost below a certain
threshold. Punyakanok et al. (2004) represent the question and the sentence containing
answer with their dependency trees. They add semantic information (i.e. named entity,
synonyms and other related words) in the dependency trees. They apply the approximate
tree matching in order to decide how similar any given pair of trees are. They also use the
edit distance as the matching criteria in the approximate tree matching. All these methods
show the improvement over the BOW scoring methods.

3. Our Approach
To accomplish the task of answering complex questions we extract various important features for each of the sentences in the document collection to measure its relevance to the
query. The sentences in the document collection are analyzed in various levels and each
of the document sentences is represented as a vector of feature-values. Our feature set
includes lexical, lexical semantic, statistical similarity, syntactic and semantic features, and
graph-based similarity measures (Chali & Joty, 2008b). We reimplemented many of these
features which are successfully applied to many related fields of NLP.
We use a simple local search technique to fine-tune the feature weights. We also use
the statistical clustering algorithms: EM and K-means to select the relevant sentences for
summary generation. Experimental results show that our systems perform better when
we include the tree kernel based syntactic and semantic features though summaries based
on only syntactic or semantic feature do not achieve good results. Graph-based cosine
similarity and lexical semantic features are also important for selecting relevant sentences.
We find that the local search technique outperforms the other two and the EM performs
better than the K-means based learning. In the later sections we describe all the subparts
of our systems in details.

4. Feature Extraction
In this section, we will describe the features that will be used to score the sentences. We
provide detailed examples4 to show how we get the feature values. We will first describe
the syntactic and semantic features that we are introducing in this work. We follow with
a detailed description of the features more commonly used in the question answering and
summarization communities.
4. All the query and document sentences used in the examples are taken from the DUC 2007 collection.

7

fiChali, Joty, & Hasan

4.1 Syntactic and Shallow Semantic Features
For the task like query-based summarization that requires the use of more complex syntactic
and semantics, the approaches with only BOW are often inadequate to perform fine-level
textual analysis. The importance of syntactic and semantic features in this context is
described by Zhang and Lee (2003a), Moschitti et al. (2007), Bloehdorn and Moschitti
(2007a), Moschitti and Basili (2006) and Bloehdorn and Moschitti (2007b).
An effective way to integrate syntactic and semantic structures in machine learning algorithms is the use of tree kernel functions (Collins & Duffy, 2001; Moschitti & Quarteroni,
2008) which has been successfully applied to question classification (Zhang & Lee, 2003a;
Moschitti & Basili, 2006). Syntactic and semantic information are used effectively to measure the similarity between two textual units by MacCartney et al. (2006). To the best
of our knowledge, no study has used tree kernel functions to encode syntactic/semantic
information for more complex tasks such as computing the relatedness between the query
sentences and the document sentences. Another good way to encode some shallow syntactic
information is the use of Basic Elements (BE) (Hovy, Lin, Zhou, & Fukumoto, 2006) which
uses dependency relations. Our experiments show that including syntactic and semantic
features improves the performance on the sentence selection for complex question answering
task (Chali & Joty, 2008a).
4.1.1 Encoding Syntactic Structures
Basic Element (BE) Overlap Measure Shallow syntactic information based on dependency relations was proved to be effective in finding similarity between two textual
units (Hirao et al., 2004). We incorporate this information by using Basic Elements that
are defined as follows (Hovy et al., 2006):
 The head of a major syntactic constituent (noun, verb, adjective or adverbial phrases),
expressed as a single item.
 A relation between a head-BE and a single dependent, expressed as a triple:
(head|modifier|relation).
The triples encode some syntactic information and one can decide whether any two units
match or not- more easily than with longer units (Hovy et al., 2006). We extracted BEs for
the sentences (or query) by using the BE package distributed by ISI5 .
Once we get the BEs for a sentence, we computed the Likelihood Ratio (LR) for each BE
following Zhou, Lin, and Hovy (2005). Sorting BEs according to their LR scores produced
a BE-ranked list. Our goal is to generate a summary that will answer the users questions.
The ranked list of BEs in this way contains important BEs at the top which may or may not
be relevant to the users questions. We filter those BEs by checking whether they contain
any word which is a query word or a QueryRelatedWords (defined in Section 4.3). For
example, if we consider the following sentence we get the BE score of 0.77314.
Query: Describe steps taken and worldwide reaction prior to introduction of the Euro on
January 1, 1999. Include predictions and expectations reported in the press.
5. BE website:http://www.isi.edu/ cyl/BE

8

fiComplex Question Answering: Unsupervised Approaches

Sentence: The Frankfurt-based body said in its annual report released today that it has
decided on two themes for the new currency: history of European civilization and
abstract or concrete paintings.
BE Score: 0.77314
Here, the BE decided|themes|obj is not considered as it does not contain any word
from the query words or query relevant words but BE report|annual|mod is taken as it
contains a query word report. In this way, we filter out the BEs that are not related to
the query. The score of a sentence is the sum of its BE scores divided by the number of BEs
in the sentence. By limiting the number of the top BEs that contribute to the calculation
of the sentence scores we can remove the BEs with little importance and the sentences with
fewer important BEs. If we set the threshold to 100 only the topmost 100 BEs in the ranked
list can contribute to the normalized sentence BE score computation. In this paper, we did
not set any threshold we took all the BEs counted when calculating the BE scores for the
sentences.
Tree Kernels Approach In order to calculate the syntactic similarity between the query
and the sentence we first parse the sentence as well as the query into a syntactic tree
(Moschitti, 2006) using a parser like Charniak (1999). Then we calculate the similarity
between the two trees using the tree kernel. We reimplemented the tree kernel model as
proposed by Moschitti et al. (2007).
Once we build the trees, our next task is to measure the similarity between the trees. For
this, every tree T is represented by an m dimensional vector v(T ) = (v1 (T ), v2 (T ),    vm (T )),
where the i-th element vi (T ) is the number of occurrences of the i-th tree fragment in tree
T . The tree fragments of a tree are all of its sub-trees which include at least one production
with the restriction that no production rules can be broken into incomplete parts (Moschitti
et al., 2007). Figure 1 shows an example tree and a portion of its subtrees.

Figure 1: (a) An example tree (b) The sub-trees of the NP covering the press.
Implicitly we enumerate all the possible tree fragments 1, 2,    , m. These fragments are
the axis of this m-dimensional space. Note that this could be done only implicitly since
the number m is extremely large. Because of this, Collins and Duffy (2001) define the tree
kernel algorithm whose computational complexity does not depend on m.
The tree kernel of two trees T1 and T2 is actually the inner product of v(T1 ) and v(T2 ):
9

fiChali, Joty, & Hasan

T K(T1 , T2 ) = v(T1 ).v(T2 )

(2)

We define the indicator function Ii (n) to be 1 if the sub-tree i is seen rooted at node n
and 0 otherwise. It follows:

vi (T1 ) =

X

X

Ii (n1 ), vi (T2 ) =

n1 N1

Ii (n2 )

(3)

n2 N2

Where N1 and N2 are the set of nodes in T1 and T2 respectively. So, we can derive:
T K(T1 , T2 ) = v(T1 ).v(T2 ) =

X

vi (T1 )vi (T2 )

i

X

=

X X

n1 N1 n2 N2

X

=

X

Ii (n1 )Ii (n2 )

i

C(n1 , n2 )

(4)

n1 N1 n2 N2

where we define C(n1 , n2 ) = i Ii (n1 )Ii (n2 ). Next, we note that C(n1 , n2 ) can be
computed in polynomial time due to the following recursive definition:
P

1. If the productions at n1 and n2 are different then C(n1 , n2 ) = 0
2. If the productions at n1 and n2 are the same, and n1 and n2 are pre-terminals, then
C(n1 , n2 ) = 1
3. Else if the productions at n1 and n2 are not pre-terminals,
nc(n1 )

C(n1 , n2 ) =

Y

(1 + C(ch(n1 , j), ch(n2 , j)))

(5)

j=1

where nc(n1 ) is the number of children of n1 in the tree; because the productions at n1
and n2 are the same we have nc(n1 ) = nc(n2 ). The i-th child-node of n1 is ch(n1 , i).
In cases where the query is composed of two or more sentences we compute the similarity
between the document sentence (s) and each of the query-sentences (qi ) then we take the
average of the scores as the syntactic feature value.
Syntactic similarity value =

Pn

i=1 T K(qi , s)

n

Where n is the number of sentences in the query q and s is the sentence under consideration. TK is the similarity value (tree kernel) between the sentence s and the query
sentence q based on the syntactic structure. For example, for the following sentence s and
query q we get the score:
10

fiComplex Question Answering: Unsupervised Approaches

Figure 2: Example of semantic trees
Query (q): Describe steps taken and worldwide reaction prior to introduction of the Euro
on January 1, 1999. Include predictions and expectations reported in the press.
Sentence (s): Europes new currency, the euro, will rival the U.S. dollar as an international
currency over the long term, Der Spiegel magazine reported Sunday.
Scores: 90, 41
Average Score: 65.5
4.1.2 Semantic Features
Though introducing syntactic information gives an improvement on BOW, by the use of
syntactic parses, this too is not adequate when dealing with complex questions whose answers are expressed by long and articulated sentences or even paragraphs. Shallow semantic
representations, bearing more compact information, could prevent the sparseness of deep
structural approaches and the weakness of BOW models (MacCartney et al., 2006; Moschitti
et al., 2007).
Initiatives such as PropBank (PB) (Kingsbury & Palmer, 2002) have made the design of
accurate automatic Semantic Role Labeling (SRL) systems like ASSERT (Hacioglu, Pradhan, Ward, Martin, & Jurafsky, 2003) possible. Hence, attempting an application of SRL
to QA seems natural as pinpointing the answer to a question relies on a deep understanding
of the semantics of both. For example, consider the PB annotation:
[ARG0 all][TARGET use][ARG1 the french franc][ARG2 as their currency]
Such annotation can be used to design a shallow semantic representation that can be
matched against other semantically similar sentences, e.g.
[ARG0 the Vatican][TARGET use][ARG1 the Italian lira][ARG2 as their currency]
In order to calculate the semantic similarity between the sentences we first represent the
annotated sentence (or query) using the tree structures like Figure 2 called Semantic Tree
(ST) as proposed by Moschitti et al. (2007). In the semantic tree arguments are replaced
with the most important wordoften referred to as the semantic head. We look for a noun
first, then a verb, then an adjective, then adverb to find the semantic head in the argument.
If none of these is present we take the first word of the argument as the semantic head.
11

fiChali, Joty, & Hasan

Figure 3: Two STs composing a STN
However, sentences rarely contain a single predicate, rather typically propositions contain one or more subordinate clauses. For instance, let us consider a slight modification of
the second sentence: the Vatican, located wholly within Italy uses the Italian lira as their
currency. Here, the main predicate is uses and the subordinate predicate is located.
The SRL system outputs the following two annotations:
(1) [ARG0 the Vatican located wholly within Italy][TARGET uses][ARG1 the Italian
lira][ARG2 as their currency]
(2) [ARG0 the Vatican][TARGET located] [ARGM-LOC wholly][ARGM-LOC within
Italy] uses the Italian lira as their currency
giving the STs in Figure 3. As we can see in Figure 3(A), when an argument node
corresponds to an entire subordinate clause we label its leaf with ST (e.g. the leaf of
ARG0). Such ST node is actually the root of the subordinate clause in Figure 3(B). If
taken separately, such STs do not express the whole meaning of the sentence. Hence, it
is more accurate to define a single structure encoding the dependency between the two
predicates as in Figure 3(C). We refer to this kind of nested STs as STNs.
Note that the tree kernel (TK) function defined in Section 4.1.1 computes the number of
common subtrees between two trees. Such subtrees are subject to the constraint that their
nodes are taken with all or none of the children they have in the original tree. Though this
definition of subtrees makes the TK function appropriate for syntactic trees, it is not well
suited for the semantic trees (ST). For instance, although the two STs of Figure 2 share
most of the subtrees rooted in the ST node, the kernel defined above computes no match.
The critical aspect of steps (1), (2), and (3) of the TK function is that the productions
of two evaluated nodes have to be identical to allow the match of further descendants. This
means that common substructures cannot be composed by a node with only some of its
children as an effective ST representation would require. Moschitti et al. (2007) solve this
problem by designing the Shallow Semantic Tree Kernel (SSTK) which allows portions of
an ST to match.
Shallow Semantic Tree Kernel (SSTK) We reimplemented the SSTK according to
the model given by Moschitti et al. (2007). The SSTK is based on two ideas: first, it changes
12

fiComplex Question Answering: Unsupervised Approaches

the ST, as shown in Figure 4 by adding SLOT nodes. These accommodate argument labels
in a specific order with a fixed number of slots, possibly filled with null arguments that
encode all possible predicate arguments. Leaf nodes are filled with the wildcard character *
but they may alternatively accommodate additional information. The slot nodes are used
in such a way that the adopted TK function can generate fragments containing one or more
children like for example those shown in frames (b) and (c) of Figure 4. As previously
pointed out, if the arguments were directly attached to the root node the kernel function
would only generate the structure with all children (or the structure with no children, i.e.
empty) (Moschitti et al., 2007).

Figure 4: Semantic tree with some of its fragments
Second, as the original tree kernel would generate many matches with slots filled with
the null label we have set a new step 0 in the TK calculation:
(0) if n1 (or n2 ) is a pre-terminal node and its child label is null, C(n1 , n2 ) = 0;
and subtract one unit to C(n1 , n2 ), in step 3:
nc(n1 )

(3) C(n1 , n2 ) =

Y

j=1

(1 + C(ch(n1 , j), ch(n2 , j)))  1

(6)

The above changes generate a new C which, when substituted (in place of original C )
in Eq. 4, gives the new SSTK.
For example, for the following sentence s and query q we get the semantic score:
Query (q): Describe steps taken and worldwide reaction prior to introduction of the Euro
on January 1, 1999. Include predictions and expectations reported in the press.
Sentence (s): The Frankfurt-based body said in its annual report released today that it
has decided on two themes for the new currency history of European civilization and
abstract or concrete paintings.
Scores: 6, 12
Average Score: 9
13

fiChali, Joty, & Hasan

4.2 Lexical Features
Here, we will discuss the lexical features that are most commonly used in the QA and
summarization communities. We reimplemented all of them in this research.
4.2.1 N-gram Overlap
N-gram overlap measures the overlapping word sequences between the candidate document
sentence and the query sentence. With the view to measure the overlap scores, a query pool
and a sentence pool are created. In order to create the query (or sentence) pool, we took
the query (or document) sentence and created a set of related sentences by replacing its
content words6 by their first-sense synonyms using WordNet. For example, given a stemmed
document-sentence: John write a poem, the sentence pool contains: John compose a
poem, John write a verse form along with the given sentence.
We measured the recall based n-gram scores for a sentence P using the following formula:
N gramScore(P ) = maxi (maxj N gram(si , qj ))
P
gram S Countmatch (gramn )
N gram(S, Q) = P n
gramn S Count (gramn )

(7)
(8)

Where n stands for the length of the n-gram (n = 1, 2, 3, 4), and Countmatch (gramn ) is
the number of n-grams co-occurring in the query and the candidate sentence, qj is the j-th
sentence in the query pool, and si is the i-th sentence in the sentence pool of sentence P .
1-gram Overlap Measure
A 1-gram overlap score measures the number of words common in the sentence in hand
and the query related words. This can be computed as follows:
1gram Overlap Score =

P

Countmatch (w1 )
w1 S Count (w1 )

w1 S

P

(9)

Where S is the set of content words in the candidate sentence and Countmatch is the
number of matches between the sentence content words and query related words. Count (gramn )
is the number of w1 .
Note that in order to measure the 1-gram score we took the query related words instead
of the exact query words. The motivation behind this is the sentence which has word(s)
that are not exactly the query words but their synonyms, hypernyms, hyponym or gloss
words, will get counted.
Example:
Query Describe steps taken and worldwide reaction prior to introduction of the Euro on
January 1, 1999. Include predictions and expectations reported in the press.
Sentence The Frankfurt-based body said in its annual study released today that it has
decided on two themes for the new currency: history of European civilization and
abstract or concrete paintings.
6. hence forth content words are the nouns, verbs, adverbs and adjectives.

14

fiComplex Question Answering: Unsupervised Approaches

1-gram Score 0.06666 (After normalization7 ).
Note that the above sentence has a 1-gram overlap score of 0.06666 even though it has
no exact word common with the query words. It got this score because the sentence word
study is a synonym of the query word report.
Other N-gram Overlap Measures
As above, we can calculate the other n-gram overlap scores. For example, considering
the following query sentence and document sentence (From DUC 2007 collection), we have 4
matching 2-grams: (1 1999,of Euro, on January and January 1). Hence, employing
the formula given above, we get the following 2-gram score after normalization. 3-gram score
is also found accordingly.
Query Sentence: Describe steps taken and worldwide reaction prior to introduction of
the Euro on January 1, 1999. Include predictions and expectations reported in the
press.
Document Sentence: Despite skepticism about the actual realization of a single European currency as scheduled on January 1, 1999, preparations for the design of the
Euro note have already begun.
2-gram: 0.14815
3-gram: 0.0800
4.2.2 LCS and WLCS
A sequence W = [w1 , w2 , ..., wn ] is a subsequence of another sequence X = [x1 , x2 , ..., xm ] ,
if there exists a strict increasing sequence [i1 , i2 , ..., in ] of indices of X such that for all
j = 1, 2, ..., n we have xij = wj (Cormen, Leiserson, & Rivest, 1989). Given two sequences
S1 and S2 , the longest common subsequence (LCS) of S1 and S2 is a common subsequence
with maximum length (Lin, 2004).
The longer the LCS of two sentences is, the more similar the two sentences are. We
used LCS-based F-measure to estimate the similarity between the document sentence S of
length m and the query sentence Q of length n as follows:
LCS(S, Q)
m
LCS(S, Q)
Plcs (S, Q) =
n
Flcs (S, Q) = (1  )  Plcs (S, Q) +   Rlcs (S, Q)
Rlcs (S, Q) =

(10)
(11)
(12)

Where LCS(S, Q) is the length of a longest common subsequence of S and Q, and  is
a constant that determines the importance of precision and recall. While computing the
LCS measure each document sentence and query sentence are viewed as a sequence of words.
7. We normalize each of the feature values corresponding to a sentence with respect to the entire context
of a particular document.

15

fiChali, Joty, & Hasan

The intuition is that the longer the LCS of these two is the more similar they are. Here
the recall (Rlcs (S, Q)) is the ratio of the length of the longest common subsequence of S and
Q to the document sentence length that measures the completeness. Whereas the precision
(Plcs (S, Q)) is the ratio of the length of the longest common subsequence of S and Q to the
query sentence length which is a measure of exactness. To obtain the equal importance
to precision and recall we set the value of  as 0.5. Equation 12 is called the LCS-based
F-measure. Notice that Flcs is 1 when, S=Q; and Flcs is 0 when there is nothing in
common between S and Q.
One advantage of using LCS is that it does not require consecutive matches but insequence matches that reflect sentence level word order as n-grams. The other advantage is
that it automatically includes longest in-sequence common n-grams. Therefore, no predefined n-gram length is necessary. Moreover, it has the property that its value is less than or
equal to the minimum of the unigram (i.e. 1-gram) F-measure of S and Q. Unigram recall
reflects the proportion of words in S that are also present in Q; while unigram precision
is the proportion of words in Q that are also in S. Unigram recall and precision count all
co-occurring words regardless of their orders; while LCS counts in-sequence co-occurrences.
By only awarding credit to in-sequence unigram matches, LCS measure also captures
sentence level structure in a natural way. Consider the following example:
S1 John shot the thief
S2 John shot the thief
S3 the thief shot John
Using S1 as reference sentence, and S2 and S3 as the sentences under consideration S2
and S3 would have the same 2-gram score since they both have one bigram (i.e. the thief)
in common with S1. However, S2 and S3 have very different meanings. In case of LCS S2
has a score of 3/4=0.75 and S3 has a score of 2/4=0.5 with  = 0.5. Therefore, S2 is better
than S3 according to LCS.
However, LCS suffers one disadvantage in that it only counts the main in-sequence
words; therefore, other alternative LCSes and shorter sequences are not reflected in the
final score. For example, given the following candidate sentence:
S4 the thief John shot
Using S1 as its reference, LCS counts either the thief or John shot but not both;
therefore, S4 has the same LCS score as S3 while 2-gram would prefer S4 over S3.
In order to measure the LCS score for a sentence we took a similar approach as the previous section using WordNet (i.e. creation of sentence pool and query pool). We calculated
the LCS score using the following formula:

LCS score = maxi (maxj Flcs (si , qj ))

(13)

Where qj is the j-th sentence in the query pool, and si is the i-th sentence in the
sentence pool.
16

fiComplex Question Answering: Unsupervised Approaches

The basic LCS has a problem in that it does not differentiate LCSes of different spatial
relations within their embedding sequences (Lin, 2004). For example, given a reference
sequence S and two candidate sequences Y1 and Y2 as follows:
S: A B C D E F G
Y1 : A B C D H I K
Y2 : A H B K C I D
Y1 and Y2 have the same LCS score. However, Y1 should be better choice than Y2 because
Y1 has consecutive matches. To improve the basic LCS method we can store the length of
consecutive matches encountered so far to a regular two dimensional dynamic program table
computing LCS. We call it weighted LCS (WLCS) and use k to indicate the length of the
current consecutive matches ending at words xi and yj . Given two sentences X and Y,
the WLCS score of X and Y can be computed using the similar dynamic programming
procedure as stated by Lin (2004). We use WLCS as it has the advantage of not measuring
the similarity by taking the words in a higher dimension like string kernels which indeed
reduces the time complexity. As before, we computed the WLCS-based F-measure in the
same way using both the query pool and the sentence pool.
W LCS score = maxi (maxj Fwlcs (si , qj ))

(14)

Example:
Query Sentence: Describe steps taken and worldwide reaction prior to introduction of
the Euro on January 1, 1999. Include predictions and expectations reported in the
press.
Document Sentence: Despite skepticism about the actual realization of a single European currency as scheduled on January 1, 1999, preparations for the design of the
Euro note have already begun.
We find 6 matching strings: (of on 1 Euro 1999 January) in the longest common
subsequence considering this sentence and related sentences. For WLCS we set the
weight as 1.2. After normalization, we get the following LCS and WLCS scores for
the sentence applying the above formula.
LCS Score: 0.27586
WLCS Score: 0.15961
4.2.3 Skip-Bigram Measure
A skip-bigram is any pair of words in their sentence order allowing for arbitrary gaps. Skipbigram measures the overlap of skip-bigrams between a candidate sentence and a query
sentence (Lin, 2004). We rely on the query pool and the sentence pool as before using
WordNet. Considering the following sentences:
17

fiChali, Joty, & Hasan

S1 John shot the thief
S2 John shoot the thief
S3 the thief shoot John
S4 the thief John shot
we get that each sentence has C(4,2)=6 skip-bigrams8 . For example, S1 has the following
skip-bigrams: (John shot, John the, John thief, shot the, shot thief and the
thief) S2 has three skip bi-gram matches with S1 (John the, John thief, the thief),
S3 has one skip bi-gram match with S1 (the thief), and S4 has two skip bi-gram matches
with S1 (John shot, the thief).
The skip bi-gram score between the document sentence S of length m and the query
sentence Q of length n can be computed as follows:
SKIP2 (S, Q)
C(m, 2)
SKIP2 (S, Q)
Pskip2 (S, Q) =
C(n, 2)
Fskip2 (S, Q) = (1  )  Pskip2 (S, Q) +   Rskip2 (S, Q)
Rskip2 (S, Q) =

(15)
(16)
(17)

Where SKIP2 (S, Q) is the number of skip bi-gram matches between S and Q, and
 is a constant that determines the importance of precision and recall. We set the value
of  as 0.5 to associate the equal importance to precision and recall. C is the combination
function. We call the equation 17 the skip bigram-based F-measure. We computed the skip
bigram-based F-measure using the formula:

SKIP BIGRAM = maxi (maxj Fskip2 (si , qj ))

(18)

For example, given the following query and the sentence, we get 8 skip-bigrams: (on 1,
January 1, January 1999, of Euro, 1 1999, on 1999, on January and of on).
Applying the equations above, we get skip bi-gram score of 0.05218 after normalization.
Query Describe steps taken and worldwide reaction prior to introduction of the Euro on
January 1, 1999. Include predictions and expectations reported in the press.
Sentence Despite skepticism about the actual realization of a single European currency
as scheduled on January 1, 1999, preparations for the design of the Euro note have
already begun.
Skip bi-gram Score: 0.05218
8. C(n, r) =

n!
r!(nr)!

18

fiComplex Question Answering: Unsupervised Approaches

Note that skip bi-gram counts all in-order matching word pairs while LCS only counts
one longest common subsequence. We can put the constraint on the maximum skip distance,
dskip , between two in-order words to form a skip bi-gram which avoids the spurious matches
like the the or of from. For example, if we set dskip to 0 then it is equivalent to bi-gram
overlap measure (Lin, 2004). If we set dskip to 4 then only word pairs of at most 4 words
apart can form skip bi-grams. In our experiment we set dskip = 4 in order to ponder at
most 4 words apart to get the skip bi-grams.
Modifying the equations: 15, 16, and 17 to allow the maximum skip distance limit is
straightforward: following Lin (2004) we count the skip bi-gram matches, SKIP2 (S, Q),
within the maximum skip distance and replace the denominators of the equations with
the actual numbers of within distance skip bi-grams from the reference sentence and the
candidate sentence respectively.
4.2.4 Head and Head Related-words Overlap
The number of head words common in between two sentences can indicate how much they
are relevant to each other. In order to extract the heads from the sentence (or query), the
sentence (or query) is parsed by Minipar9 and from the dependency tree we extract the
heads which we call exact head words. For example, the head word of the sentence: John
eats rice is eat.
We take the synonyms, hyponyms, and hypernyms10 of both the query-head words and
the sentence-head words and form a set of words which we call head-related words. We
measured the exact head score and the head-related score as follows:
P

w1 HeadSet Countmatch (w1 )

(19)

w1 HeadRelSet Countmatch (w1 )

(20)

ExactHeadScore =
HeadRelatedScore =

P

P

P

w1 HeadSet Count (w1 )

w1 HeadRelSet Count (w1 )

Where HeadSet is the set of head words in the sentence and Countmatch is the number
of matches between the HeadSet of the query and the sentence. HeadRelSet is the set of
synonyms, hyponyms, and hypernyms of head words in the sentence and Countmatch is
the number of matches between the head-related words of the query and the sentence. For
example, below we list the head words for a query and a sentence and their measures:
Query: Describe steps taken and worldwide reaction prior to introduction of the Euro on
January 1, 1999. Include predictions and expectations reported in the press.
Heads for Query: include, reaction, step, take, describe, report, Euro, introduction, press,
prediction, 1999, expectation
Sentence: The Frankfurt-based body said in its annual report released today that it has
decided on two themes for the new currency: history of European civilization and
abstract or concrete paintings.
9. http://www.cs.ualberta.ca/ lindek/minipar.htm
10. hypernym and hyponym levels are restricted to 2 and 3 respectively.

19

fiChali, Joty, & Hasan

Heads for Sentence: history, release, currency, body, report,painting, say, civilization,
theme, decide.
Exact Head Score:

1
11

= 0.09

Head Related Score: 0
4.3 Lexical Semantic Features
We form a set of words which we call QueryRelatedWords by taking the content words from
the query, their first-sense synonyms, the nouns hypernyms/hyponyms, and the nouns
gloss definitions using WordNet.
4.3.1 Synonym Overlap
The synonym overlap measure is the overlap between the list of synonyms of the content
words extracted from the candidate sentence and query related words. This can be computed
as follows:
Synonym Overlap Score =

P

w1 SynSet Countmatch (w1 )
w1 SynSet Count (w1 )

P

(21)

Where SynSet is the synonym set of the content words in the sentence and Countmatch is
the number of matches between the SynSet and query related words.
4.3.2 Hypernym/Hyponym Overlap
The hypernym/hyponym overlap measure is the overlap between the list of hypernyms (level
2) and hyponyms (level 3) of the nouns extracted from the sentence in consideration and
query related words. This can be computed as follows:
Hypernym/hyponym overlap score =

P

h1 HypSet Countmatch (h1 )
h1 HypSet Count (h1 )

P

(22)

Where HypSet is the hyponym/hyponym set of the nouns in the sentence and Countmatch is
the number of matches between the HypSet and query related words.
4.3.3 Gloss Overlap
The gloss overlap measure is the overlap between the list of content words that are extracted
from the gloss definition of the nouns in the sentence in consideration and query related
words. This can be computed as follows:
Gloss Overlap Score =

P

g1 GlossSet Countmatch (g1 )

P

g1 GlossSet Count (g1 )

(23)

Where GlossSet is the set of content words (i.e. nouns, verbs and adjectives) taken from
the gloss definition of the nouns in the sentence and Countmatch is the number of matches
between the GlossSet and query related words.
20

fiComplex Question Answering: Unsupervised Approaches

Example:
For example, given the query the following sentence gets synonym overlap score of
0.33333, hypernym/hyponym overlap score of 0.1860465 and gloss overlap score of 0.1359223.
Query Describe steps taken and worldwide reaction prior to introduction of the Euro on
January 1, 1999. Include predictions and expectations reported in the press.
Sentence The Frankfurt-based body said in its annual report released today that it has
decided on two themes for the new currency: history of European civilization and
abstract or concrete paintings.
Synonym Overlap Score: 0.33333
Hypernym/Hyponym Overlap Score: 0.1860465
Gloss Overlap Score: 0.1359223
4.4 Statistical Similarity Measures
Statistical similarity measures are based on the co-occurrence of similar words in a corpus.
Two words are termed as similar if they belong to the same context. We used the thesaurus
provided by Dr. Dekang Lin11 for these purpose. We have used two statistical similarity
measures:
Dependency-based similarity measure
This method uses the dependency relations among words in order to measure the similarity (Lin, 1998b). It extracts the dependency triples and then uses a statistical approach
to measure the similarity. Using the given corpus one can retrieve the most similar words
for a given word. The similar words are grouped into clusters.
Note that for a word there can be more than one cluster. Each cluster represents the
sense of the word and its similar words for that sense. So, selecting the right cluster for a
word is itself a problem. Our goals are: i) to create a bag of similar words to the query
words and ii) once we get the bag of similar words (dependency based) for the query words
to measure the overlap score between it and the sentence words.
Creating Bag of Similar Words:
For each query-word we extract all of its clusters from the thesaurus. Now in order
to determine the right cluster for a query word we measure the overlap score between the
query related words (i.e. exact words, synonyms, hypernyms/hyponyms and gloss) and the
clusters. The hypothesis is that the cluster that has more words in common with the query
related words is the right cluster under the assumption that the first synonym is the correct
sense. We choose the cluster for a word which has the highest overlap score.

Overlap scorei =

P

w1 QueryRelatedW ords Countmatch (w1 )

(24)

Cluster = argmaxi (Overlap Scorei )

(25)

w1 QueryRelatedW ords Count (w1 )

P

11. http://www.cs.ualberta.ca/ lindek/downloads.htm

21

fiChali, Joty, & Hasan

where QueryRelatedWords is the set of exact words, synonyms, hyponyms/hypernyms,
and gloss words for the words in the query (i.e query words) and Countmatch is the number
of matches between the query related words and the ith cluster of similar words.
Measuring Overlap Score:
Once we get the clusters for the query words we measured the overlap between the
cluster words and the sentence words which we call dependency based similarity measure:

DependencyM easure =

w1 SenW ords Countmatch (w1 )

P

P

w1 SenW ords Count (w1 )

(26)

Where SenWords is the set of words for the sentence and Countmatch is the number
of matches between the sentence words and the cluster of similar words.
Proximity-based similarity measure
This similarity is computed based on the linear proximity relationship between words
only (Lin, 1998a). It uses the information theoretic definition of similarity to measure the
similarity. The similar words are grouped into clusters. We took the similar approach to
measure this feature as the previous section except that we used a different thesaurus.
Example:
Considering the following query and sentence we get the following measures:
Query: Describe steps taken and worldwide reaction prior to introduction of the Euro on
January 1, 1999. Include predictions and expectations reported in the press.
Sentence: The Frankfurt-based body said in its annual report released today that it has
decided on two themes for the new currency: history of European civilization and
abstract or concrete paintings.
Dependency-based Similarity Score: 0.0143678
Proximity-based Similarity Score: 0.04054054
4.5 Graph-based Similarity Measure
Erkan and Radev (2004) used the concept of graph-based centrality to rank a set of sentences
for producing generic multi-document summaries. A similarity graph is produced for the
sentences in the document collection. In the graph each node represents a sentence. The
edges between nodes measure the cosine similarity between the respective pair of sentences.
The degree of a given node is an indication of how important the sentence is. Figure 5
shows an example of a similarity graph for 4 sentences.
Once the similarity graph is constructed, the sentences are ranked according to their
eigenvector centrality. The LexRank performed well in the context of generic summarization. To apply LexRank to query-focused context a topic-sensitive version of LexRank is
proposed by Otterbacher et al. (2005). We followed a similar approach in order to calculate
this feature. The score of a sentence is determined by a mixture model of the relevance of
the sentence to the query and the similarity of the sentence to other high-scoring sentences.
22

fiComplex Question Answering: Unsupervised Approaches

Figure 5: LexRank similarity
Relevance to the Question
We first stem out all the sentences in the collection and compute the word IDFs (Inverse
Document Frequency) using the following formula:
N +1
idfw = log
0.5 + sfw




(27)

Where N is the total number of sentences in the cluster, and sfw is the number of
sentences that the word w appears in.
We also stem out the questions and remove the stop words. The relevance of a sentence
s to the question q is computed by:
rel(s|q) =

X

wq

log (tfw,s + 1)  log (tfw,q + 1)  idfw

(28)

Where tfw,s and tfw,q are the number of times w appears in s and q, respectively.
Mixture Model
In the previous section we measured the relevance of a sentence to the question but a
sentence that is similar to the high scoring sentences in the cluster should also have a high
score. For instance, if a sentence that gets a high score based on the question relevance
model is likely to contain an answer to the question then a related sentence, which may
not be similar to the question itself, is also likely to contain an answer (Otterbacher et al.,
2005).
We capture this idea by the following mixture model:

p(s|q) =

(

X
sim(s, v)
rel(s|q)
P
+ (1  d) 
d P
zC rel(z|q)
zC sim(z, v)
vC

)

 p(v|q)

(29)

Where p(s|q), the score of a sentence s given a question q, is determined as the sum
of its relevance to the question and the similarity to the other sentences in the collection.
C is the set of all sentences in the collection. The value of the parameter d which we call
23

fiChali, Joty, & Hasan

bias is a trade-off between two terms in the equation and is set empirically. For higher
values of d we prefer the relevance to the question to the similarity to other sentences.
The denominators in both terms are for normalization. Although it is computationally
expensive, equation 29 calculates the sum over the entire collection since it is required for
the model to sense the global impact through the voting of all sentences. We measure the
cosine similarity weighted by word IDFs as the similarity between two sentences in a cluster:

sim(x, y) = qP

P

wx,y

tfw,x  tfw,y  (idfw )2

2
xi x (tfxi ,x  idfxi ) 

qP

2
yi y (tfyi ,y  idfyi )

(30)

Equation 29 can be written in matrix notation as follows:
p = [dA + (1  d)B]T p

(31)

A is the square matrix such that for a given index i, all the elements in the i-th column
are proportional to rel(i|q). B is also a square matrix such that each entry B(i,j) is
proportional to sim(i,j). Both matrices are normalized so that row sums add up to 1.
Note that as a result of this normalization all rows of the resulting square matrix Q =
[dA + (1  d)B] also add up to 1. Such a matrix is called stochastic and defines a Markov
chain. If we view each sentence as a state in a Markov chain then Q(i,j) specifies the
transition probability from state i to state j in the corresponding Markov chain. The
vector p we are looking for in Eq. 31 is the stationary distribution of the Markov chain.
An intuitive interpretation of the stationary distribution can be understood by the concept
of a random walk on the graph representation of the Markov chain. With probability d a
transition is made from the current node to the nodes that are similar to the query. With
probability (1-d) a transition is made to the nodes that are lexically similar to the current
node. Every transition is weighted according to the similarity distributions. Each element
of the vector p gives the asymptotic probability of ending up at the corresponding state in
the long run regardless of the starting state. The stationary distribution of a Markov chain
can be computed by a simple iterative algorithm called power method (Erkan & Radev,
2004). It starts with a uniform distribution. At each iteration the eigenvector is updated
by multiplying with the transpose of the stochastic matrix. Since the Markov chain is
irreducible and aperiodic the algorithm is guaranteed to terminate.

5. Ranking Sentences
We use several methods in order to rank sentences to generate summaries applying the
features described in Section 4. In this section we will describe the systems in detail.
5.1 Learning Feature-weights: A Local Search Strategy
In order to fine-tune the weights of the features, we have used a local search technique. Initially we set all the feature-weights, w1 ,    , wn , as equal values (i.e. 0.5) (see Algorithm 1).
Then we train the weights using the DUC 2006 data set. Based on the current weights we
score the sentences and generate summaries accordingly. We evaluate the summaries using
24

fiComplex Question Answering: Unsupervised Approaches

Input: Stepsize l, Weight Initial Value v
Output: A vector w
~ of learned weights
Initialize the weight values wi to v.
for i  1 to n do
rg1 = rg2 = prev = 0
while (true) do
scoreSentences(w)
~
generateSummaries()
rg2 = evaluateROUGE()
if rg1  rg2 then
prev = wi
wi + = l
rg1 = rg2
else
break
end
end
end
return w
~
Algorithm 1: Tuning weights using Local Search technique
the automatic evaluation tool ROUGE (Lin, 2004) (described in Section 7) and the ROUGE
value works as the feedback to our learning loop. Our learning system tries to maximize the
ROUGE score in every step by changing the weights individually by a specific step size (i.e.
0.01). That means, to learn weight wi we change the value of wi keeping all other weight
values (wj j6=i ) stagnant. For each weight wi the algorithm achieves the local maximum
(i.e. hill climbing) of ROUGE value.
Once we have learned the feature-weights we compute the final scores for the sentences
using the formula:
scorei = x~i .w
~

(32)

Where x~i is the feature vector for i-th sentence, w
~ is the weight vector, and scorei is the
score of i-th sentence.
5.2 Statistical Machine Learning Approaches
We experimented with two unsupervised statistical learning techniques with the features
extracted in the previous section for the sentence selection problem:
1. K-means learning
2. Expectation Maximization (EM) learning
5.2.1 The K-means Learning
K-means is a hard clustering algorithm that defines clusters by the center of mass of their
members. We start with a set of initial cluster centers that are chosen randomly and go
25

fiChali, Joty, & Hasan

through several iterations of assigning each object to the cluster whose center is closest.
After all objects have been assigned we recompute the center of each cluster as the centroid
) of its members. The distance function we use is squared Euclidean distance
or mean (
instead of the true Euclidean distance.
Since the square root is a monotonically growing function squared Euclidean distance
has the same result as the true Euclidean distance but the computation overload is smaller
when the square root is dropped.
Once we have learned the means of the clusters using the K-means algorithm our next
task is to rank the sentences according to a probability model. We have used Bayesian
model in order to do so. Bayes law says:

x|qk , )P (qk |)
p(x
x|)
p(x
x|qk , )P (qk |)
p(x
PK
x|qk , )p(qk |)
k=1 p(x

x, ) =
P (qk |x
=

(33)

where qk is a cluster, x is a feature vector representing a sentence, and  is the parameter
set of all class models. We set the weights of the clusters as equiprobable (i.e. P (qk |) =
x|qk , ) using the gaussian probability distribution. The gaussian
1/K). We calculated p(x
probability density function (pdf) for the d-dimensional random variable x is given by:

x) =
p(,
 ) (x

e

1
x
 )T  1 (x
x
)
(x
2

 dp
)
2 det(

(34)

where  , the mean vector, and  , the covariance matrix, are the parameters of the
) from the K-means algorithm and we calculate
gaussian distribution. We get the means (
the covariance matrix using the unbiased covariance estimation procedure:

j =

N
1 X
xi  j )(x
x i  j )T
(x
N  1 i=1

(35)

5.2.2 The EM Learning
The EM algorithm for gaussian mixture models is a well known method for cluster analysis.
A useful outcome of this model is that it produces a likelihood value of the clustering model
and the likelihood values can be used to select the best model from a number of different
models providing that they have the same number of parameters (i.e. same number of
clusters).
26

fiComplex Question Answering: Unsupervised Approaches

x) each represented by a feature vector of length
Input: A sample of n data-points (x
L
Input: Number of Clusters K
Output: An array S of K-means-based Scores
Data: Array dnK , K , K
Data: Array C K , y nK
Randomly choose K data-points as K initial means:  k , k = 1,    , K.
repeat
for i  1 to n do
for j  1 to K do
xi   j k2 = (x
xi   j )T (x
xi   j )
d ij = kx
end
if d ik < d il , l 6= k then
assign x i to C k .
end
end
for i  P
1 to K do
C
x C

xj

j
i
i =
C i|
|C
end
until no further change occurs ;
/* calculating the covariances for each cluster
for i  1 to K do
C i|
m = |C
for j  1 to m do
C ij   i )  (C
C ij   i )T
 i + = (C
end
 i  = (1/(m  1))
end
/* calculating the scores for sentences
for i  1 to n do
for j  1 to K do
T 1
1


2 (x i  j )  j (x i  j )
yij = e  d 

2

*/

*/

j )
det(

end
for j  1 to K do
P
// where, wj = 1/K
zij = (yij  wj )/ K
j=1 yij  wj ;
end
k ) k
m = max(
Push zim to S
end
return S
Algorithm 2: Computing K-means based similarity measure

27

fiChali, Joty, & Hasan

A significant problem with the EM algorithm is that it converges to a local maximum
of the likelihood function and hence the quality of the result depends on the initialization.
This problem along with a method for improving the initialization is discussed later in this
section.
EM is a soft version of the K-means algorithm described above. As with K-means we
start with a set of random cluster centers c1    ck . In each iteration we do a soft assignment
of the data-points to every cluster by calculating their membership probabilities. EM is
an iterative two step procedure: 1. Expectation-step and 2. Maximization-step. In the
expectation step we compute expected values for the hidden variables hi,j which are cluster
membership probabilities. Given the current parameters we compute how likely it is that
an object belongs to any of the clusters. The maximization step computes the most likely
parameters of the model given the cluster membership probabilities.
The data-points are considered to be generated by a mixture model of k-gaussians of
the form:

P (x) =

k
X

P (C = i)P (x|C = i) =

i=1

k
X

i ,  i )
P (C = i)P (x|

(36)

i=1

where the total likelihood of model  with k components, given the observed data points
X = x 1 ,    , x n , is:

L(|X)

=


n X
k
Y

i=1 j=1

x i |j ) =
P (C = j)P (x

n
X

k
X

i=1

log

j=1

n X
k
Y

i=1 j=1

xi |
j ,  j )
wj P (x

xi |
 j ,  j ) ( taking the log likelihood )
wj P (x

(37)
(38)

where P is the probability density function (i.e. eq 34).  j and  j are the mean and
covariance matrix of component j, respectively. Each component contributes a proportion,
P
wj , of the total population such that: K
j=1 wj = 1.
Log likelihood can be used instead of likelihood as it turns the product into a sum. We
describe the EM algorithm for estimating a gaussian mixture.
Singularities The covariance matrix  above must be non-singular or invertible. The
EM algorithm may converge to a position where the covariance matrix becomes singular
| = 0) or close to singular, that means it is not invertible anymore. If the covariance
(|
matrix becomes singular or close to singular then EM may result in wrong clusters. We
restrict the covariance matrices to become singular by testing these cases at each iteration
of the algorithm as follows:
q

| > 1e9 ) then update 
if ( |
else do not update 
28

fiComplex Question Answering: Unsupervised Approaches

Discussion: Starting values for the EM algorithm
The convergence rate and success of clustering using the EM algorithm can be degraded
by a poor choice of starting values for the means, covariances, and weights of the components. We experimented with one summary (for document number D0703A from DUC
2007) in order to test the impact of these initial values on the EM algorithm. The cluster
means are initialized with
p a heuristic that spreads them randomly around M ean(DAT A)
with standard deviation Cov(DAT A)  10. Their initial covariance is set to Cov(DAT A)
and the initial values of the weights are wj = 1/K where K is the number of clusters.
That is, for d-dimensional data-points the parameters of j th component are as follows:

~j = rand(1,    , d) 
j = (DAT A)
wj

q

 (DAT A)  10 + ~(DAT A)

= 1/K

The highly variable nature of the results of the tests is reflected in the very inconsistent values for the total log likelihood and the results of repeated experiments indicated
that using random starting values for initial estimates of the means frequently gave poor
results. There are two possible solutions to this problem. In order to get good results
from using random starting values (as specified by the algorithm) we will run the EM algorithm several times and choose the initial configuration for which we get the maximum
log likelihood among all configurations. Choosing the best one among several runs is a very
computer intensive process. So, to improve the outcome of the EM algorithm on gaussian
mixture models, it is necessary to find a better method of estimating initial means for the
components.
The best starting position for the EM algorithm, in regard to the estimates of the means,
would be to have one estimated mean per cluster which is closer to the true mean of that
cluster.
To achieve this aim we explored the widely used K-means algorithm as a cluster
(means) finding method. That is, the means found by the K-means clustering above will
be utilized as the initial means for the EM and we calculate the initial covariance matrices
using the unbiased covariance estimation procedure (Equation 35).
Ranking the Sentences
Once the sentences are clustered by the EM algorithm, we identify the sentences which
xi , ) where qr denotes the clusare question-relevant by checking their probabilities, P (qr |x
x i , ) > 0.5 then x i is considered to
ter question-relevant. If for a sentence x i , P (qr |x
be question-relevant. The cluster which has the mean values greater than the other one is
considered as the question-relevant cluster.
Our next task is to rank the question-relevant sentences in order to include them in the
summary. This can be done easily by multiplying the feature vector x~i with the weight
vector w
~ that we learned by applying the local search technique (Equation 32).
29

fiChali, Joty, & Hasan

Input: A Sample of n data-points ( x ) each represented by a feature vector of length
L
Input: Number of Clusters K
Output: An array S of EM-based Scores
k , k ) k = 1,    , K, with equal priors set
Start with K initial Gaussian models: N (
to P (qk ) = 1/K.
repeat
(i)
x j , (i) ) for each
/* Estimation step: compute the probability P (qk |x
(i)

data point xj , j = 1,    , n, to belong to the class qk
for j  1 to n do
for k  1 to K do
(i)
x j , (i) ) =
P (qk |x

(i)

(i)

xj |qk , (i) )
P (qk |(i) )p(x
xj |(i) )
p(x
(i)

=
end
end
/* Maximization step:
for k  1 to K do
for j  1 to n do
// update the means:
 i+1
k

=

(i)

(i)

x j |
k ,  k )
P (qk |(i) )p(x

(i)
(i)
(i)
x j |
(i)
k=1 P (qk | )p(x
k , k )

PK

*/

=

// update the variances:
(i+1)
k

*/

(i)
xj , (i) )
j=1 x j P (qk |x
Pn
(i)
xj , (i) )
j=1 P (qk |x

Pn

(i)
xj
xj , (i) )(x
xj   (i+1)
)(x
j=1 P (qk |x
k
PN
(i)
xj , (i) )
j=1 P (qk |x

Pn

(i+1) T
)

 k

// update the priors:

P (qk (i + 1)|(i+1) ) =

n
1X
(i)
x j , (i) )
P (qk |x
n j=1

end
end
until the total likelihood increase falls under some desired threshold ;
return S
Algorithm 3: Computing EM-based similarity measure

30

fiComplex Question Answering: Unsupervised Approaches

6. Redundancy Checking and Generating Summary
Once the sentences are scored the easiest way to create summaries is just to output the
topmost N sentences until the required summary length is reached. In that case, we are
ignoring other factors: such as redundancy and coherence.
As we know that text summarization clearly entails selecting the most salient information and putting it together in a coherent summary. The answer or summary consists of
multiple separately extracted sentences from different documents. Obviously, each of the
selected text snippets should individually be important. However, when many of the competing sentences are included in the summary the issue of information overlap between parts
of the output comes up and a mechanism for addressing redundancy is needed. Therefore,
our summarization systems employ two levels of analysis: first a content level where every
sentence is scored according to the features or concepts it covers, and second a textual level,
when, before being added to the final output, the sentences deemed to be important are
compared to each other and only those that are not too similar to other candidates are included in the final answer or summary. Goldstein, Kantrowitz, Mittal, and Carbonell (1999)
observed this in what the authors called Maximum-Marginal-Relevance (MMR). Following Hovy et al. (2006) we modeled this by BE overlap between an intermediate summary
and a to-be-added candidate summary sentence.
We call this overlap ratio R, where R is between 0 and 1 inclusively. Setting R = 0.7
means that a candidate summary sentence, s, can be added to an intermediate summary,
S, if the sentence has a BE overlap ratio less than or equal to 0.7.

7. Experimental Evaluation
This section describes the results of experiments conducted using DUC12 2007 dataset
provided by NIST 13 . Some of the questions these experiments address include:
 How do the different features affect the behavior of the summarizer system?
 Which one of the algorithms (K-means, EM and Local Search) performs better for
this particular problem?
We used the main task of DUC 2007 for evaluation. The task was:
Given a complex question (topic description) and a collection of relevant documents,
the task is to synthesize a fluent, well-organized 250-word summary of the documents that
answers the question(s) in the topic.
The documents of DUC 2007 came from the AQUAINT corpus comprising newswire
articles from the Associated Press and New York Times (1998-2000) and Xinhua News
Agency (1996-2000). NIST assessors developed topics of interest to them and choose a set
of 25 documents relevant (document cluster) to each topic. Each topic and its document
cluster were given to 4 different NIST assessors including the developer of the topic. The
assessor created a 250-word summary of the document cluster that satisfies the information
12. http://www-nlpir.nist.gov/projects/duc/
13. National Institute of Standards and Technology

31

fiChali, Joty, & Hasan

need expressed in the topic statement. These multiple reference summaries are used in
the evaluation of summary content.
The purpose of our experiments is to study the impact of different features. To accomplish this we generated summaries for the 45 topics of DUC 2007 by each of our seven
systems defined as below:
 The LEX system generates summaries based on only lexical features (Section 4.2):
n-gram (n=1,2,3,4), LCS, WLCS, skip bi-gram, head, head synonym and BE overlap.
 The LEXSEM system considers only lexical semantic features (Section 4.3): synonym, hypernym/hyponym, gloss, dependency-based and proximity-based similarity.
 The SYN system generates summary based on only syntactic feature (Section 4.1.1).
 The COS system generates summary based on the graph-based method (Section 4.5).
 The SYS1 system considers all the features except the syntactic and semantic features
(All features except section 4.1).
 The SYS2 system considers all the features except the semantic feature (All features
except section 4.1.2) and
 The ALL system generates summaries taking all the features (Section 4) into account.
7.1 Automatic Evaluation
ROUGE We carried out automatic evaluation of our summaries using the ROUGE (Lin,
2004) toolkit, which has been widely adopted by DUC for automatic summarization evaluation. ROUGE stands for Recall-Oriented Understudy for Gisting Evaluation. It is a
collection of measures that determines the quality of a summary by comparing it to reference summaries created by humans. The measures count the number of overlapping units
such as n-gram, word-sequences, and word-pairs between the system-generated summary to
be evaluated and the ideal summaries created by humans. The available ROUGE measures
are: ROUGE-N (N=1,2,3,4), ROUGE-L, ROUGE-W and ROUGE-S. ROUGE-N is n-gram
recall between a candidate summary and a set of reference summaries. ROUGE-L measures
the longest common subsequence (LCS) which takes into account sentence level structure
similarity naturally and identifies longest co-occurring insequence n-grams automatically.
ROUGE-W measures the weighted longest common subsequence (WLCS) providing an improvement to the basic LCS method of computation to credit the sentences having the
consecutive matches of words. ROUGE-S is the overlap of skip-bigrams between a candidate summary and a set of reference summaries where skip-bigram is any pair of words in
their sentence order allowing for arbitrary gaps. Most of these ROUGE measures have been
applied in automatic evaluation of summarization systems and achieved very promising
results (Lin, 2004).
For all our systems, we report the widely accepted important metrics: ROUGE-2 and
ROUGE-SU. We also present the ROUGE-1 scores since this has never been shown to not
correlate with human judgement. All the ROUGE measures were calculated by running
32

fiComplex Question Answering: Unsupervised Approaches

ROUGE-1.5.5 with stemming but no removal of stopwords. ROUGE run-time parameters
were set as the same as DUC 2007 evaluation setup. They are:
ROUGE-1.5.5.pl -2 -1 -u -r 1000 -t 0 -n 4 -w 1.2 -m -l 250 -a
We also show 95% confidence interval of the important evaluation metrics for our systems
to report significance for doing meaningful comparison. We use the ROUGE tool for this
purpose. ROUGE uses a randomized method named bootstrap resampling to compute the
confidence interval. We used 1000 sampling points in the bootstrap resampling.
We report the evaluation scores of one baseline system (The BASE column) in each of
the tables in order to show the level of improvement our systems achieve. The baseline
system generates summaries by returning all the leading sentences (up to 250 words) in the
hT EXT i field of the most recent document(s).
While presenting the results we highlight the top two F-scores and bottom one F-score
to indicate significance at a glance.
7.1.1 Results and Discussion
The K-means Learning Table 1 shows the ROUGE-1 scores for different combinations
of features in the K-means learning. It is noticeable that the K-means performs best for
the graph-based cosine similarity feature. Note that including syntactic feature does not
improve the score. Also, including syntactic and semantic features increases the score
but not by a significant amount. Summaries based on only lexical features give us good
ROUGE-1 evaluation.
Scores
Recall
Precision
F-score

LEX
0.366
0.397
0.381

LEXSEM
0.360
0.393
0.376

SYN
0.346
0.378
0.361

COS
0.378
0.408
0.393

SYS1
0.376
0.403
0.389

SYS2
0.365
0.415
0.388

ALL
0.366
0.415
0.389

BASE
0.312
0.369
0.334

Table 1: ROUGE-1 measures in K-means learning

Table 2 shows the ROUGE-2 scores for different combinations of features in the K-means
learning. Just like ROUGE-1 graph-based cosine similarity feature performs well here. We
get a significant improvement in ROUGE-2 score when we include syntactic feature with all
other features. Semantic features do not affect the score much. Lexical Semantic features
perform well here.

Scores
Recall
Precision
F-score

LEX
0.074
0.080
0.077

LEXSEM
0.076
0.084
0.080

SYN
0.063
0.069
0.065

COS
0.085
0.092
0.088

SYS1
0.074
0.080
0.077

SYS2
0.077
0.107
0.090

ALL
0.076
0.109
0.090

Table 2: ROUGE-2 measures in K-means learning

33

BASE
0.060
0.072
0.064

fiChali, Joty, & Hasan

As Table 3 shows: ROUGE-SU scores are the best for all features without syntactic and
semantic. Including syntactic/semantic features with other features degrades the scores.
Summaries based on only lexical features achieve good scores.
Scores
Recall
Precision
F-score

LEX
0.131
0.154
0.141

LEXSEM
0.127
0.152
0.138

SYN
0.116
0.139
0.126

COS
0.139
0.162
0.149

SYS1
0.135
0.176
0.153

SYS2
0.134
0.174
0.152

ALL
0.134
0.174
0.152

BASE
0.105
0.124
0.112

Table 3: ROUGE-SU measures in K-means learning
Table 4 shows the 95% confidence interval (for F-measures in K-means learning) of the
important ROUGE evaluation metrics for all our systems in comparison to the confidence
interval of the baseline system. It can be seen that our systems have performed significantly
better than the baseline system in most of the cases.
Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

ROUGE-1
0.326680 - 0.342330
0.362976 - 0.400498
0.357154 - 0.395594
0.345512 - 0.377525
0.372804 - 0.413440
0.367817 - 0.408390
0.358237 - 0.400000
0.350756 - 0.404275

ROUGE-2
0.060870 - 0.068840
0.064983 - 0.090981
0.069909 - 0.091376
0.056041 - 0.076337
0.075127 - 0.104377
0.063284 - 0.095170
0.065219 - 0.093733
0.066281 - 0.095393

ROUGE-SU
0.108470 - 0.116720
0.128390 - 0.157784
0.126157 - 0.151831
0.116191 - 0.136799
0.134971 - 0.164885
0.132061 - 0.162509
0.123703 - 0.153165
0.124157 - 0.159447

Table 4: 95% confidence intervals for K-means system

The EM learning Table 5 to Table 7 show different ROUGE measures for the feature
combinations in the context of the EM learning. It can be easily noticed that for all these
measures we get significant amount of improvement in ROUGE scores when we include
syntactic and semantic features along with other features. We get 3-15% improvement over
SYS1 in F-score when we include syntactic feature and 2-24% improvement when we include
syntactic and semantic features. The cosine similarity measure does not perform as well as
it did in the K-means experiments. Summaries considering only the lexical features achieve
good results.
Table 8 shows the 95% confidence interval (for F-measures in EM learning) of the important ROUGE evaluation metrics for all our systems in comparison to the confidence
interval of the baseline system. We can see that our systems have performed significantly
better than the baseline system in most of the cases.
Local Search Technique The ROUGE scores based on the feature combinations are
given in Table 9 to Table 11. Summaries generated by including all features perform the
34

fiComplex Question Answering: Unsupervised Approaches

Scores
Recall
Precision
F-score

LEX
0.383
0.415
0.398

LEXSEM
0.357
0.390
0.373

SYN
0.346
0.378
0.361

COS
0.375
0.406
0.390

SYS1
0.379
0.411
0.395

SYS2
0.399
0.411
0.405

ALL
0.398
0.399
0.399

BASE
0.312
0.369
0.334

ALL
0.090
0.138
0.109

BASE
0.060
0.072
0.064

ALL
0.143
0.185
0.161

BASE
0.105
0.124
0.112

Table 5: ROUGE-1 measures in EM learning

Scores
Recall
Precision
F-score

LEX
0.088
0.095
0.092

LEXSEM
0.079
0.087
0.083

SYN
0.063
0.069
0.065

COS
0.087
0.094
0.090

SYS1
0.084
0.091
0.088

SYS2
0.089
0.116
0.100

Table 6: ROUGE-2 measures in EM learning

Scores
Recall
Precision
F-score

LEX
0.145
0.171
0.157

LEXSEM
0.128
0.153
0.139

SYN
0.116
0.139
0.126

COS
0.138
0.162
0.149

SYS1
0.143
0.167
0.154

SYS2
0.145
0.186
0.163

Table 7: ROUGE-SU measures in EM learning

Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

ROUGE-1
0.326680 - 0.342330
0.382874 - 0.416109
0.352610 - 0.395048
0.345512 - 0.377525
0.366364 - 0.410020
0.378068 - 0.413658
0.360319 - 0.414068
0.378177 - 0.412705

ROUGE-2
0.060870 - 0.068840
0.075084 - 0.110454
0.070816 - 0.095856
0.056041 - 0.076337
0.076088 - 0.104243
0.077480 - 0.099739
0.073661 - 0.112157
0.077515 - 0.115231

ROUGE-SU
0.108470 - 0.116720
0.144367 - 0.172449
0.125276 - 0.154562
0.115713 - 0.136599
0.133251 - 0.164110
0.141550 - 0.168759
0.130022 - 0.171378
0.141345 - 0.164849

Table 8: 95% confidence intervals for EM system

35

fiChali, Joty, & Hasan

best scores for all the measures. We get 7-15% improvement over SYS1 in F-score when
we include syntactic feature and 8-19% improvement over SYS1 in F-score when we include
syntactic and semantic features. In this case also lexical features (LEX) perform well but
not better than all features (ALL).
Scores
Recall
Precision
F-score

LEX
0.379
0.411
0.394

LEXSEM
0.358
0.390
0.373

SYN
0.346
0.378
0.361

COS
0.375
0.406
0.390

SYS1
0.382
0.414
0.397

SYS2
0.388
0.434
0.410

ALL
0.390
0.438
0.413

BASE
0.312
0.369
0.334

Table 9: ROUGE-1 measures in local search technique

Scores
Recall
Precision
F-score

LEX
0.085
0.092
0.088

LEXSEM
0.079
0.087
0.083

SYN
0.063
0.069
0.065

COS
0.087
0.094
0.090

SYS1
0.086
0.093
0.090

SYS2
0.095
0.114
0.104

ALL
0.099
0.116
0.107

BASE
0.060
0.072
0.064

Table 10: ROUGE-2 measures in local search technique

Scores
Recall
Precision
F-score

LEX
0.143
0.168
0.155

LEXSEM
0.128
0.153
0.139

SYN
0.116
0.139
0.126

COS
0.138
0.162
0.149

SYS1
0.145
0.170
0.157

SYS2
0.148
0.195
0.169

ALL
0.150
0.196
0.170

BASE
0.105
0.124
0.112

Table 11: ROUGE-SU measures in local search technique
Table 12 shows the 95% confidence interval (for F-measures in local search technique)
of the important ROUGE evaluation metrics for all our systems in comparison to the confidence interval of the baseline system. We find that our systems have performed significantly
better than the baseline system in most of the cases.
7.1.2 Comparison
From the results reported above we can see for all three algorithms our systems clearly outperform the baseline system. Table 13 shows the F-scores of the reported ROUGE measures
while Table 14 reports the 95% confidence intervals for the baseline system, the best system
in DUC 2007, and our three techniques taking all features (ALL) into consideration. We
can see that the method based on local search technique outperforms the other two and the
EM algorithm performs better than the K-means algorithm. If we analyze deeply, we find
that in all cases but ROUGE-SU with local search the confidence intervals do not overlap
with the best DUC 2007 system.
36

fiComplex Question Answering: Unsupervised Approaches

Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

ROUGE-1
0.326680 - 0.342330
0.380464 - 0.409085
0.353458 - 0.394853
0.345512 - 0.377525
0.366364 - 0.410020
0.381544 - 0.414534
0.370310 - 0.415768
0.384897 - 0.416301

ROUGE-2
0.060870 - 0.068840
0.078002 - 0.100107
0.070845 - 0.096261
0.056041 - 0.076337
0.076088 - 0.104243
0.079550 - 0.101246
0.078760 - 0.114175
0.084181 - 0.114753

ROUGE-SU
0.108470 - 0.116720
0.143851 - 0.166648
0.125342 - 0.154729
0.115713 - 0.136599
0.133251 - 0.164110
0.144551 - 0.170047
0.141043 - 0.174575
0.146302 - 0.171736

Table 12: 95% confidence intervals for local search system

Algorithms
Baseline
Best System
K-means
EM
Local Search

ROUGE-1
0.334
0.438
0.389
0.399
0.413

ROUGE-2
0.064
0.122
0.089
0.109
0.107

ROUGE-SU
0.112
0.174
0.152
0.161
0.170

Table 13: ROUGE F-scores for different systems

Algorithms
Baseline
Best System
K-means
EM
Local Search

ROUGE-1
0.326680 - 0.342330
0.431680 - 0.445970
0.350756 - 0.404275
0.378177 - 0.412705
0.384897 - 0.416301

ROUGE-2
0.060870 - 0.068840
0.118000 - 0.127680
0.066281 - 0.095393
0.077515 - 0.115231
0.084181 - 0.114753

ROUGE-SU
0.108470 - 0.116720
0.169970 - 0.179390
0.124157 - 0.159447
0.141345 - 0.164849
0.146302 - 0.171736

Table 14: 95% confidence intervals for different systems

37

fiChali, Joty, & Hasan

7.2 Manual Evaluation
For a sample of 105 summaries14 drawn from our different systems generated summaries
we conduct an extensive manual evaluation in order to analyze the effectiveness of our
approaches. The manual evaluation comprised a Pyramid-based evaluation of contents and
a user evaluation to get the assessment of linguistic quality and overall responsiveness.
7.2.1 Pyramid Evaluation
In the DUC 2007 main task, 23 topics were selected for the optional community-based
pyramid evaluation. Volunteers from 16 different sites created pyramids and annotated
the peer summaries for the DUC main task using the given guidelines15 . 8 sites among
them created the pyramids. We used these pyramids to annotate our peer summaries to
compute the modified pyramid scores16 . We used the DUCView.jar17 annotation tool for
this purpose. Table 15 to Table 17 show the modified pyramid scores of all our systems for
the three algorithms. A baseline systems score is also reported. The peer summaries of the
baseline system are generated by returning all the leading sentences (up to 250 words) in
the hT EXT i field of the most recent document(s). From these results we see that all our
systems perform better than the baseline system and inclusion of syntactic and semantic
features yields better scores. For all three algorithms we can also notice that the lexical
semantic features are the best in terms of modified pyramid scores.
7.2.2 User Evaluation
10 university graduate students judged the summaries for linguistic quality and overall
responsiveness. The given score is an integer between 1 (very poor) and 5 (very good) and
is guided by consideration of the following factors: 1. Grammaticality, 2. Non-redundancy,
3. Referential clarity, 4. Focus and 5. Structure and Coherence. They also assigned a
content responsiveness score to each of the automatic summaries. The content score is an
integer between 1 (very poor) and 5 (very good) and is based on the amount of information
in the summary that helps to satisfy the information need expressed in the topic narrative.
These measures were used at DUC 2007. Table 18 to Table 20 present the average linguistic
quality and overall responsive scores of all our systems for the three algorithms. The same
baseline systems scores are given for meaningful comparison. From a closer look at these
results, we find that most of our systems perform worse than the baseline system in terms
of linguistic quality but achieve good scores in case of overall responsiveness. It is also
obvious from the tables that the exclusion of syntactic and semantic features often causes
lower scores. On the other hand, lexical and lexical semantic features show good overall
responsiveness scores for all three algorithms.
14. We have 7 systems for each of the 3 algorithms, cumulatively we have 21 systems. Randomly we chose
5 summaries for each of these 21 systems.
15. http://www1.cs.columbia.edu/ becky/DUC2006/2006-pyramid-guidelines.html
16. This equals the sum of the weights of the Summary Content Units (SCUs) that a peer summary matches,
normalized by the weight of an ideally informative summary consisting of the same number of contributors
as the peer.
17. http://www1.cs.columbia.edu/ ani/DUC2005/Tool.html

38

fiComplex Question Answering: Unsupervised Approaches

Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

Modified Pyramid Scores
0.13874
0.44984
0.51758
0.45762
0.50368
0.42872
0.41666
0.49900

Table 15: Modified pyramid scores for K-means system

Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

Modified Pyramid Scores
0.13874
0.51894
0.53226
0.45058
0.48484
0.47758
0.44734
0.49756

Table 16: Modified pyramid scores for EM system

Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

Modified Pyramid Scores
0.13874
0.49760
0.53912
0.43512
0.49510
0.46976
0.46404
0.47944

Table 17: Modified pyramid scores for local search system

39

fiChali, Joty, & Hasan

Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

Linguistic Quality
4.24
3.08
4.08
3.24
4.00
2.72
3.12
3.56

Overall Responsiveness
1.80
3.20
3.80
3.60
3.60
2.20
2.80
3.80

Table 18: Linguistic quality and responsive scores for K-means system

Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

Linguistic Quality
4.24
4.08
3.56
4.20
3.80
3.68
4.20
3.36

Overall Responsiveness
1.80
4.40
3.40
3.80
4.00
3.80
3.60
3.40

Table 19: Linguistic quality and responsive scores for EM system

Systems
Baseline
LEX
LEXSEM
SYN
COS
SYS1
SYS2
ALL

Linguistic Quality
4.24
3.24
3.12
2.64
3.40
3.40
3.12
3.20

Overall Responsiveness
1.80
2.40
4.20
2.00
3.40
3.60
3.80
3.20

Table 20: Linguistic quality and responsive scores for local search system

40

fiComplex Question Answering: Unsupervised Approaches

8. Conclusion and Future Work
In this paper we presented our works on answering complex questions. We extracted eighteen important features for each of the sentences in the document collection. Later we used
a simple local search technique to fine-tune the feature weights. For each weight, wi , the
algorithm achieves the local maximum of the ROUGE value. In this way, once we learn
the weights we rank the sentences by multiplying the feature-vector with the weight-vector.
We also experimented with two unsupervised learning techniques: 1) EM and 2) K-means
with the features extracted. We assume that we have two clusters of sentences: 1. queryrelevant and 2. query-irrelevant. We learned the means of the clusters using the K-means
algorithm then we used Bayesian model in order to rank the sentences. The learned means
in the K-means algorithm are used as the initial means in the EM algorithm. We applied the EM algorithm to cluster the sentences into two classes : 1) query-relevant and 2)
query-irrelevant. We take out the query-relevant sentences and rank them using the learned
weights (i.e. in local search). For each of our methods of generating summaries we filter
out the redundant sentences using a redundancy checking module and generate summaries
by taking the top N sentences.
We also experimented with the effects of different kinds of features. We evaluated our
systems automatically using ROUGE and report the significance of our results through
95% confidence intervals. We conducted two types of manual evaluation: 1) Pyramid and
2) User Evaluation to further analyze the performance of our systems. Our experimental
results mostly show the following: (a) our approaches achieve promising results, (b) the
empirical approach based on a local search technique outperforms the other two learning
techniques and EM performs better than the K-means algorithm, (c) our systems achieve
better results when we include the tree kernel based syntactic and semantic features, and
(d) in all cases but ROUGE-SU with local search the confidence intervals do not overlap
with the best DUC 2007 system.
We are now experimenting with the supervised learning techniques (i.e. SVM, MAXENT, CRF etc) and analyzing how they perform for this problem. Prior to that, we produced huge amount of labeled data automatically using similarity measures such as ROUGE
(Toutanova et al., 2007).
In the future we plan to decompose the complex questions into several simple questions
before measuring the similarity between the document sentence and the query sentence.
This will certainly serve to create more limited trees and subsequences which might increase
the precision. Thus, we expect that by decomposing complex questions into the sets of
subquestions that they entail systems can improve the average quality of answers returned
and achieve better coverage for the question as a whole.

Acknowledgments
We thank the anonymous reviewers for their useful comments on the earliest version of this
paper. Special thanks go to our colleagues for proofreading the paper. We are also grateful
to all the graduate students who took part in the user evaluation process. The research
reported here was supported by the Natural Sciences and Engineering Research Council
(NSERC) research grant and the University of Lethbridge.
41

fiChali, Joty, & Hasan

Appendix A. Stop Word List

reuters
may
nov
tue
a
accordingly
against
alone
am
another
anyway
appropriate
ask
awfully
becomes
being
better
by
cant
certainly
comes
containing
currently
didnt
dont
each
else
etc
everyone
except
followed
forth
get
goes
h
hasnt

ap
jun
dec
wed
as
across
aint
along
amid
any
anyways
are
asking
b
becoming
believe
between
c
cannot
changes
concerning
contains
d
different
done
edu
elsewhere
etc.
everything
f
following
four
gets
going
had
have

jan
jul
tech
thu
able
actually
all
already
among
anybody
anywhere
arent
associated
be
been
below
beyond
cmon
cant
clearly
consequently
corresponding
definitely
do
down
eg
enough
even
everywhere
far
follows
from
getting
gone
hadnt
havent

42

feb
aug
news
fri
about
after
allow
also
amongst
anyhow
apart
around
at
became
before
beside
both
cs
cause
co
consider
could
described
does
downwards
e.g.
entirely
ever
ex
few
for
further
given
got
happens
having

mar
sep
index
sat
above
afterwards
allows
although
an
anyone
appear
as
available
because
beforehand
besides
brief
came
causes
com
considering
couldnt
despite
doesnt
during
eight
especially
every
exactly
fifth
former
furthermore
gives
gotten
hardly
he

apr
oct
mon
s
according
again
almost
always
and
anything
appreciate
aside
away
become
behind
best
but
can
certain
come
contain
course
did
doing
e
either
et
everybody
example
five
formerly
g
go
greetings
has
hes

fiComplex Question Answering: Unsupervised Approaches

hello
hereafter
hi
how
im
immediate
indicated
inward
its
keep
l
less
likely
m
mean
most
my
nearly
nevertheless
non
nothing
of
old
onto
our
overall
perhaps
probably
r
regarding

help
hereby
him
howbeit
ive
in
indicates
is
its
keeps
lately
lest
little
mainly
meanwhile
mostly
myself
necessary
new
none
novel
off
on
or
ours
own
placed
provides
rather
regardless

hence
herein
himself
however
ie
inasmuch
inner
isnt
itself
kept
later
let
look
many
merely
mr.
n
need
next
noone
now
often
once
other
ourselves
p
please
q
rd
regards

her
hereupon
his
i
i.e.
inc
insofar
it
j
know
latter
lets
looking
may
might
ms.
namely
needs
nine
nor
nowhere
oh
one
others
out
particular
plus
que
re
relatively

43

here
hers
hither
id
if
indeed
instead
itd
just
knows
latterly
like
looks
maybe
more
much
nd
neither
no
normally
o
ok
ones
otherwise
outside
particularly
possible
quite
really
respectively

heres
herself
hopefully
ill
ignored
indicate
into
itll
k
known
least
liked
ltd
me
moreover
must
near
never
nobody
not
obviously
okay
only
ought
over
per
presumably
qv
reasonably
right

fiChali, Joty, & Hasan

s
says
seemed
sensible
shall
so
sometime
specified
sup
tell
thanx
theirs
theres
thereupon
theyve
those
thus
towards
twice
unless
us
usually
via
was
were
werent
whenever
wherein
whither
whose
within
wouldnt
youd
yourself

said
second
seeming
sent
she
some
sometimes
specify
sure
tends
that
them
thereafter
these
think
though
to
tried
two
unlikely
use
uucp
viz
wasnt
weve
what
where
whereupon
who
why
without
x
youll
yourselves

same
secondly
seems
serious
should
somebody
somewhat
specifying
t
th
thats
themselves
thereby
they
third
three
together
tries
u
until
used
v
vs
way
welcome
whats
wheres
wherever
whos
will
wont
y
youre
z

saw
see
seen
seriously
shouldnt
somehow
somewhere
still
ts
than
thats
then
therefore
theyd
this
through
too
truly
un
unto
useful
value
w
we
well
whatever
whereafter
whether
whoever
willing
wonder
yes
youve
zero

44

say
seeing
self
seven
since
someone
soon
sub
take
thank
the
thence
therein
theyll
thorough
throughout
took
try
under
up
uses
various
want
wed
went
when
whereas
which
whole
wish
would
yet
your

saying
seem
selves
several
six
something
sorry
such
taken
thanks
their
there
theres
theyre
thoroughly
thru
toward
trying
unfortunately
upon
using
very
wants
well
were
whence
whereby
while
whom
with
would
you
yours

fiComplex Question Answering: Unsupervised Approaches

References
Bloehdorn, S., & Moschitti, A. (2007a). Combined syntactic and semantic kernels for text
classification. In 29th European Conference on IR Research, ECIR 2007, pp. 307318
Rome, Italy.
Bloehdorn, S., & Moschitti, A. (2007b). Structure and semantics for expressive text kernels.
In CIKM-2007, pp. 861864.
Chali, Y., & Joty, S. R. (2008a). Improving the performance of the random walk model
for answering complex questions.. In Proceedings of the 46th Annual Meeting of the
ACL-HLT. Short Paper Section, pp. 912 OH, USA.
Chali, Y., & Joty, S. R. (2008b). Selecting sentences for answering complex questions. In
Proceedings of EMNLP, pp. 304313 Hawaii, USA.
Charniak, E. (1999). A Maximum-Entropy-Inspired Parser. In Technical Report CS-99-12
Brown University, Computer Science Department.
Collins, M., & Duffy, N. (2001). Convolution Kernels for Natural Language. In Proceedings
of Neural Information Processing Systems, pp. 625632 Vancouver, Canada.
Cormen, T. R., Leiserson, C. E., & Rivest, R. L. (1989). Introduction to Algorithms. The
MIT Press.
Erkan, G., & Radev, D. R. (2004). LexRank: Graph-based Lexical Centrality as Salience
in Text Summarization. Journal of Artificial Intelligence Research, 22, 457479.
Goldstein, J., Kantrowitz, M., Mittal, V., & Carbonell, J. (1999). Summarizing Text Documents: Sentence Selection and Evaluation Metrics. In Proceedings of the 22nd International ACM Conference on Research and Development in Information Retrieval,
SIGIR, pp. 121128 Berkeley, CA.
Guo, Y., & Stylios, G. (2003). A New Multi-document Summarization System. In Proceedings of the Document Understanding Conference. NIST.
Hacioglu, K., Pradhan, S., Ward, W., Martin, J. H., & Jurafsky, D. (2003). Shallow
Semantic Parsing Using Support Vector Machines. In Technical Report TR-CSLR2003-03 University of Colorado.
Halliday, M., & Hasan, R. (1976). Cohesion in English. Longman, London.
Harabagiu, S., Lacatusu, F., & Hickl, A. (2006). Answering complex questions with random
walk models. In Proceedings of the 29th annual international ACM SIGIR conference
on Research and development in information retrieval, pp. 220  227. ACM.
Hirao, T., , Suzuki, J., Isozaki, H., & Maeda, E. (2004). Dependency-based sentence
alignment for multiple document summarization. In Proceedings of Coling 2004, pp.
446452 Geneva, Switzerland. COLING.
45

fiChali, Joty, & Hasan

Hovy, E., Lin, C. Y., Zhou, L., & Fukumoto, J. (2006). Automated Summarization Evaluation with Basic Elements. In Proceedings of the Fifth Conference on Language
Resources and Evaluation Genoa, Italy.
Kingsbury, P., & Palmer, M. (2002). From Treebank to PropBank. In Proceedings of the
international conference on Language Resources and Evaluation Las Palmas, Spain.
Kouylekov, M., & Magnini, B. (2005). Recognizing textual entailment with tree edit distance
algorithms. In Proceedings of the PASCAL Challenges Workshop: Recognising Textual
Entailment Challenge.
Li, J., Sun, L., Kit, C., & Webster, J. (2007). A Query-Focused Multi-Document Summarizer Based on Lexical Chains. In Proceedings of the Document Understanding
Conference Rochester. NIST.
Lin, C. Y. (2004). ROUGE: A Package for Automatic Evaluation of Summaries. In Proceedings of Workshop on Text Summarization Branches Out, Post-Conference Workshop
of Association for Computational Linguistics, pp. 7481 Barcelona, Spain.
Lin, D. (1998a). An Information-Theoretic Definition of Similarity. In Proceedings of
International Conference on Machine Learning, pp. 296304 Madison, Wisconsin.
Lin, D. (1998b). Automatic Retrieval and Clustering of Similar Words. In Proceedings
of the International Conference on Computational Linguistics and Association for
Computational Linguistics, pp. 768774 Montreal, Canada.
Losada, D. (2005). Language modeling for sentence retrieval: A comparison between
multiple-bernoulli models and multinomial models. In Information Retrieval and Theory Workshop Glasgow, UK.
Losada, D., & Fernandez, R. T. (2007). Highly frequent terms and sentence retrieval. In
Proc. 14th String Processing and Information Retrieval Symposium, SPIRE07, pp.
217228 Santiago de Chile.
MacCartney, B., Grenager, T., de Marneffe, M., Cer, D., & Manning, C. D. (2006). Learning to recognize features of valid textual entailments. In Proceedings of the Human
Language Technology Conference of the North American Chapter of the ACL, p. 4148
New York, USA.
Morris, J., & Hirst, G. (1991). Lexical cohesion computed by thesaural relations as an
indicator of structure of text. Computational Linguistics, 17 (1), 2148.
Moschitti, A. (2006). Efficient convolution kernels for dependency and constituent syntactic
trees. In Proceedings of the 17th European Conference on Machine Learning Berlin,
Germany.
Moschitti, A., & Basili, R. (2006). A Tree Kernel approach to Question and Answer Classification in Question Answering Systems. In Proceedings of the 5th international
conference on Language Resources and Evaluation Genoa, Italy.
46

fiComplex Question Answering: Unsupervised Approaches

Moschitti, A., & Quarteroni, S. (2008). Kernels on linguistic structures for answer extraction. In Proceedings of the 46th Conference of the Association for Computational
Linguistics (ACL08). Short Paper Section Columbus, OH, USA.
Moschitti, A., Quarteroni, S., Basili, R., & Manandhar, S. (2007). Exploiting Syntactic and
Shallow Semantic Kernels for Question/Answer Classificaion. In Proceedings of the
45th Annual Meeting of the Association of Computational Linguistics, pp. 776783
Prague, Czech Republic. ACL.
Murdock, V., & Croft, W. B. (2005). A translation model for sentence retrieval. In HLT 05:
Proceedings of the conference on Human Language Technology and Empirical Methods
in Natural Language Processing, pp. 684691 Morristown, NJ, USA. ACL.
Otterbacher, J., Erkan, G., & Radev, D. R. (2005). Using Random Walks for Questionfocused Sentence Retrieval. In Proceedings of Human Language Technology Conference
and Conference on Empirical Methods in Natural Language Processing, pp. 915922
Vancouver, Canada.
Pingali, P., K., R., & Varma, V. (2007). IIIT Hyderabad at DUC 2007. In Proceedings of
the Document Understanding Conference Rochester. NIST.
Punyakanok, V., Roth, D., & Yih, W. (2004). Mapping dependencies trees: An application
to question answering. In Proceedings of AI & Math Florida, USA.
Strzalkowski, T., & Harabagiu, S. (2008). Advances in Open Domain Question Answering.
Springer.
Toutanova, K., Brockett, C., Gamon, M., Jagarlamudi, J., Suzuki, H., & Vanderwende,
L. (2007). The pythy summarization system: Microsoft research at duc 2007. In
proceedings of the Document Understanding Conference Rochester. NIST.
Vanderwende, L., Suzuki, H., & Brockett, C. (2006). Microsoft Research at DUC2006:
Task-Focused Summarization with Sentence Simplification and Lexical Expansion. In
Proceedings of the Document Understanding Conference Rochester. NIST.
Zajic, D. M., Lin, J., Dorr, B. J., & Schwartz, R. (2006). Sentence Compression as a Component of a Multi-Document Summarization System. In Proceedings of the Document
Understanding Conference Rochester. NIST.
Zhang, A., & Lee, W. (2003a). Question Classification using Support Vector Machines. In
Proceedings of the Special Interest Group on Information Retrieval, pp. 2632 Toronto,
Canada. ACM.
Zhang, D., & Lee, W. S. (2003b). A Language Modeling Approach to Passage Question
Answering. In Proceedings of the Twelfth Text REtreival Conference, pp. 489495
Gaithersburg, Maryland.
Zhou, L., Lin, C. Y., & Hovy, E. (2005). A BE-based Multi-dccument Summarizer with
Query Interpretation. In Proceedings of Document Understanding Conference Vancouver, B.C., Canada.

47

fiJournal of Artificial Intelligence Research 35 (2009) 813857

Submitted 03/09; published 08/09

Modularity Aspects of Disjunctive Stable Models
Tomi Janhunen
Emilia Oikarinen

Tomi.Janhunen@tkk.fi
Emilia.Oikarinen@tkk.fi

Helsinki University of Technology
Department of Information and Computer Science
P.O. Box 5400, FI-02015 TKK, Finland

Hans Tompits
Stefan Woltran

tompits@kr.tuwien.ac.at
woltran@dbai.tuwien.ac.at

Technische Universitt Wien
Institut fr Informationssysteme
Favoritenstrae 911, A-1040 Vienna, Austria

Abstract
Practically all programming languages allow the programmer to split a program into
several modules which brings along several advantages in software development. In this
paper, we are interested in the area of answer-set programming where fully declarative and
nonmonotonic languages are applied. In this context, obtaining a modular structure for
programs is by no means straightforward since the output of an entire program cannot in
general be composed from the output of its components. To better understand the effects
of disjunctive information on modularity we restrict the scope of analysis to the case of
disjunctive logic programs (DLPs) subject to stable-model semantics. We define the notion
of a DLP-function, where a well-defined input/output interface is provided, and establish
a novel module theorem which indicates the compositionality of stable-model semantics
for DLP-functions. The module theorem extends the well-known splitting-set theorem and
enables the decomposition of DLP-functions given their strongly connected components
based on positive dependencies induced by rules. In this setting, it is also possible to split
shared disjunctive rules among components using a generalized shifting technique. The
concept of modular equivalence is introduced for the mutual comparison of DLP-functions
using a generalization of a translation-based verification method.

1. Introduction
Practically all programming languages used in software development allow the programmer
to split a program into several modules which interact through well-dened input/output
interfaces. Given this, the entire program can be viewed as a composition of its component modules which are typically linked together in the respective run-time environment.
The expected benets of modular program development are manifold. First, it imposes a
good programming style to be followed by the programmer. A complex software system
is much easier to develop as a set of interacting components rather than a monolithic program. Second, a modular architecture allows for additional exibility as regards delegating
programming tasks amongst a team of programmers. In this setting, the goal of each programmer is to implement desired input/output behavior(s) in terms of concrete module(s)
which together implement the software system being developed. Third, modular program
c
2009
AI Access Foundation. All rights reserved.

fiJanhunen, Oikarinen, Tompits & Woltran

design can also be exploited in order to boost the execution of programs. Program optimization is also facilitated by structural information encompassed by module interfaces.
Answer-set programming (ASP) (Marek & Truszczyski, 1999; Niemel, 1999; Gelfond
& Leone, 2002) is a paradigm for declarative problem solving in which solutions of problems
are described in terms of rules subject to a nonmonotonic semantics based on stable models
(Gelfond & Lifschitz, 1988). In typical problem representations, a tight correspondence
between solutions and stable models is sought for, and default negation is fully exploited
in order to obtain concise encodings of relations involved in such problem descriptions.
Furthermore, recursive denitions enable, e.g., the representation of closures of relations
in a very natural way. Due to ecient implementations and emerging applications, the
paradigm has received increasing attention during the past two decades.1 In the meantime,
a number of extensionssuch as disjunctions, weight constraints, and aggregateshave been
proposed to the basic syntax of normal logic programs. In this paper, we concentrate on the
class of disjunctive logic programs (DLPs) which is appropriate for solving search problems
residing up to the second level of the polynomial-time hierarchy. The semantical account
of DLPs is based on the respective generalization of stable-model semantics (Gelfond &
Lifschitz, 1991).
In this paper, our goal is to investigate modularity in the context of DLPs and stablemodel semantics. Since stable models are dened only over complete programs, they do not
lend themselves to modular programming prima facie. Perhaps for this reason, the concept
of a module has not yet raised too much attention in the realm of answer-set programming.
Except for a few dedicated papers (Gaifman & Shapiro, 1989; Eiter, Gottlob, & Veith, 1997b;
Baral, Dzifcak, & Takahashi, 2006), modules mostly appeared as a by-product in studies
of formal properties like stratication, splitting, or, more lately, in work on equivalence
relations between programs (Lifschitz & Turner, 1994; Eiter, Gottlob, & Mannila, 1997a;
Eiter, Ianni, Lukasiewicz, Schindlauer, & Tompits, 2008). In a recent approach of Oikarinen
and Janhunen (2008a), the modular architecture put forth by Gaifman and Shapiro (1989)
is accommodated for the classes of normal and smodels programs. The main result is
a module theorem which links stable models associated with individual modules to those
of their composition. Such a result is signicant as it indicates that stable models are
compositional in very much the same sense as classical models are in propositional logic.
The only major restriction implied by the module theorem is that the denition of any set
of positively interdependent atoms must be given within the same module.
Besides the general benets of modular program development discussed above, we are
also looking for potential computational advantages of modularizing reasoning tasks in ASP.
In this context, the search for stable models is probably the most central reasoning task.
Results like the module theorem discussed above provide the basis for modularizing the
search task. Extra care, however, is required because the computation of stable models
for modules in separation is not necessarily ecient. More sophisticated methods, such as
identifying cones of influence in Boolean circuits (Junttila & Niemel, 2000), can be devised
to identify modules which are relevant for the search of stable modelsthe rest is only used
to expand a qualied stable model to one for the entire program. This strategy alleviates the
treatment of extremely large program instances and it is also amenable to query evaluation.
1. The 20th anniversary of stable-model semantics was celebrated at ICLP08 which was held in Udine,
Italy, in December 2008.

814

fiModularity Aspects of Disjunctive Stable Models

Unfortunately, contemporary disjunctive answer-set solvers, such as claspd (Drescher
et al., 2008), cmodels (Giunchiglia, Lierler, & Maratea, 2006), dlv (Leone et al., 2006), and
gnt (Janhunen, Niemel, Seipel, Simons, & You, 2006), exhibit little support for modular
reasoning although related techniques like strongly connected components are exploited internally. There are also other reasoning tasks that can be boosted with a modular approach.
For instance, the optimization of answer-set programs gives rise to the problem of verifying
whether dierent versions of programs have the same answer sets. As demonstrated by
Oikarinen and Janhunen (2009), such verication tasks may benet from modularization,
and, in particular, if approximation techniques based on modular equivalence are introduced.
Following this idea, the rst modular o-line optimizer of answer-set programs, called modopt, has recently been implemented (Janhunen, 2008b).
There are also other interesting applications of modules in sight: Gebser et al. (2008a)
propose an incremental technique for answer-set solving. The idea is to gradually extend a
program instance in terms of additional modules, e.g., when solving AI planning problems.
Moreover, theoretical results like the splitting-set theorem (Lifschitz & Turner, 1994) and the
module theorem can be directly exploited in correctness proofs. For instance, it is proved
by Oikarinen and Janhunen (2008b) that the models of a prioritized circumscription can
be captured with disjunctive stable models using a particular translation. A similar proof
strategy is adopted in Theorem 8.5 of this paper.
We anticipate that compositional semantics can also prove useful if one tries to boost the
search for stable models via parallelization, e.g., by computing stable models for modules in
parallel. However, in order to avoid excessive communication costs, extra caution is needed
when stable models computed in separation are linked together and potentially rejected.
One possibility is to identify mutually independent modules as the basis for distribution.
Besides this aspect, modularization may also lead to novel methods for the (non-parallelized)
computation of stable models, other than the traditional ones.
Structure and Preview of Results In this paper, we concentrate on the formal underpinnings of modular programming in the context of disjunctive logic programs under
stable-model semantics. We proceed as follows. Our rst goal is to generalize the theory
developed for normal programs and smodels programs (Oikarinen & Janhunen, 2008a) to
the case of disjunctive programs. To this end, we rst introduce the notion of a DLPfunction in Section 2. The term goes back to Gelfond and Gabaldon (1999) who introduced
LP-functions as (partial) denitions of new relations in terms of old, known ones. To enable such a functional view of disjunctive programs, they are endowed with a well-dened
input/output interface. The idea is to partition the signature of a program encapsulated in
this way into input atoms, output atoms, and hidden (or local ) atoms. These distinctions
provide the basis for the systematic composition of larger disjunctive logic programs out
of program modules. However, arbitrary combinations of program modules are not meaningful and, rst of all, we adopt syntactic restrictions introduced by Gaifman and Shapiro
(1989) from the context of negation/disjunction-free logic programs. The interplay of default negation and disjunctions brings along new factors which lead to a relaxation of the
restrictions in the sense that program modules are allowed to share rules. Then, having
the basic syntactic issues of DLP-functions laid out, we concentrate on their semantics in
Section 3. In this respect, we follow a strict model-theoretic approach and, in particular,
815

fiJanhunen, Oikarinen, Tompits & Woltran

address the role of input atoms when it comes to viewing DLP-functions as mathematical
functions. We proceed step by step and assign three dierent classes of models to each
DLP-function, viz. classical models, minimal models, and stable models. The last provides
an appropriate generalization of disjunctive stable models (Gelfond & Lifschitz, 1991) in the
presence of input atoms.
Our second objective is to establish the adequacy of the concept of a DLP-function in
view of a compositional semantics. This will be witnessed by the main result of the paper,
viz. the module theorem which shows how stable models of a DLP-function, , can be
alternatively obtained as unions of compatible stable models for the modules constituting
. The proof of the theorem is based on the notions of completion (Clark, 1978) and loop
formulas (Lin & Zhao, 2004; Lee & Lifschitz, 2003) which are rst lifted to the case of DLPfunctions in Section 4 as a preparatory step. The proof of the module theorem follows as the
main topic of Section 5. The result is non-trivial because the underlying semantics based on
stable models is inherently nonmonotonic. This feature was already recognized by Gaifman
and Shapiro (1989) in a much simpler setting of denite programsneither involving default
negation nor disjunctions. As observed by them, too, syntactic restrictions on program
composition are necessary in order to guarantee compositionality properties for the semantics
based on Herbrand models.2 In the current paper, we strive for analogous results but in
the case of programs permitting both default negation and disjunctions. It turns out that
strongly connected components of positive dependency graphs provide a key criterion when
it comes to conning program composition. The compositionality properties of disjunctive
programs under stable-model semantics have also arisen in the context of the so-called
splitting-set theorem (Lifschitz & Turner, 1994; Eiter et al., 1997a, 2008). In fact, the
module theorem established herein is a proper generalization of its predecessor (Oikarinen &
Janhunen, 2008a). We illustrate the potential of our modular architecture by the evaluation
of quantied Boolean formulas (QBFs), which serve as canonical representatives of the classes
of the polynomial-time hierarchy (PH). Due to basic complexity results established by Eiter
and Gottlob (1995), it is natural from our perspective to concentrate on the second level of
the PH in the case of disjunctive programs.
The third aim of this paper is to have a look at some particular applications of the module theorem in disjunctive logic programming. In Section 6, we take an opposite view to
the modular construction of DLP-functions and consider possibilities for their decomposition
even in the absence of any other structural information. It turns out that strongly connected
components can also be exploited in this respect but, in addition, the occurrences of hidden
atoms must be taken into account when splitting a DLP-function into its components. As
demonstrated in Section 7, our results open new prospects as regards unwinding disjunctions
using the principle of shifting (Gelfond, Przymusinska, Lifschitz, & Truszczyski, 1991; Dix,
Gottlob, & Marek, 1996; Eiter, Fink, Tompits, & Woltran, 2004). A proper generalization
of this principle that partially covers also programs involving head-cycles is formulated and
proved correct. Moreover, due to the modular nature of DLP-functions, it makes perfect
sense to compare them as modules. The notion of modular equivalence is introduced for this
purpose in Section 8. Interestingly, modular equivalence supports substitutions of equivalent
programs and it also lends itself for translation-based verification as put forth by Oikarinen
2. The main concern of Gaifman and Shapiro (1989) is modularity with respect to the logical consequences
of a definite program and hence the intersection of its Herbrand models.

816

fiModularity Aspects of Disjunctive Stable Models

and Janhunen (2004, 2009) in the related cases of ordinary equivalence and smodels programs. Section 9 contrasts our approach with related work. Finally, Section 10 provides a
brief summary of results and concludes this paper.

2. The Class of DLP-Functions
The topic of this section is the syntax of DLP-functions as well as syntactic restrictions
imposed on composition of DLP-functions. A disjunctive rule is an expression of the form
a1      an  b1 , . . . , bm , c1 , . . . , ck ,

(1)

where n, m, k  0, and a1 , . . . , an , b1 , . . . , bm , and c1 , . . . , ck are propositional atoms. Since
the order of atoms is considered insignicant, we write A  B, C as a shorthand for rules of
form (1), where A = {a1 , . . . , an }, B = {b1 , . . . , bm }, and C = {c1 , . . . , ck } are the respective
sets of atoms. The basic intuition behind a rule A  B, C is that if each atom in the
positive body B can be inferred and none of the atoms in the negative body C, then some
atom in the head A can be inferred. When both B and C are empty, we have a disjunctive
fact, written A . If A is empty, then we have a constraint, written   B, C.
A disjunctive logic program (DLP) is conventionally formed as a nite set of disjunctive
rules. Additionally, we want a distinguished input and output interface for each DLP. To this
end, we extend a denition originally proposed by Gaifman and Shapiro (1989) to the case
of disjunctive programs.3 It is natural that such an interface imposes certain restrictions on
the rules allowed in a module. Given a set R of disjunctive rules, we write At(R) for the
signature of R, i.e., the set of (ground) atoms eectively appearing in the rules of R.
Definition 2.1 A DLP-function, , is a quadruple hR, I, O, Hi, where I, O, and H are
pairwise distinct sets of input atoms, output atoms, and hidden atoms, respectively, and R
is a DLP such that for each rule A  B, C  R,
1. A  B  C  I  O  H, and
2. if A 6= , then A  (O  H) 6= .
A DLP-function  = hR, I, O, Hi is occasionally identied with R and, by a slight abuse
of notation, we write A  B, C   to denote A  B, C  R. By the rst condition
of Denition 2.1, the rules in a DLP-function  must obey the interface specication of ,
i.e., At(R)  I  O  H. As regards the sets of atoms I, O, and H involved in the module
interface, the atoms in I  O are considered to be visible and hence accessible to other
DLP-functions conjoined with ; either to produce input for  or to utilize the output of
. On the other hand, the hidden atoms in H are used to formalize some auxiliary concepts
of  which may not make sense in the context of other DLP-functions but may save space
substantially as demonstrated, e.g., by Janhunen and Oikarinen (2007, Example 4.5). The
second condition of Denition 2.1 is concerned with the set of atoms O  H defined by the
rules of R. The principle is that each non-empty disjunctive head must involve at least one
atom from O  H. This is just to ensure that a DLP-function  must not interfere with
3. Similar approaches within the area of ASP have previously been introduced by Gelfond and Gabaldon
(1999), Janhunen (2006), and Oikarinen and Janhunen (2008a).

817

fiJanhunen, Oikarinen, Tompits & Woltran

the denitions of its input atoms I in terms of rules A  B, C satisfying A  I. But
otherwise, the rules of  may be conditioned by input atoms.4 Given a set S of atoms, we
distinguish the set of rules that dene the atoms of S in R, i.e., the set of defining rules
Def R (S) = {A  B, C  R | A  S 6= }.

(2)

Our next objective is to specify the conditions on which the composition of DLP-functions
may take place. Roughly speaking, the idea is that larger DLP-functions can be formed in
a modular fashion using smaller DLP-functions as components. As observed already by
Gaifman and Shapiro (1989), syntactic restrictions on program composition are necessary in
order to guarantee compositionality properties for the semantics based on Herbrand models, even for the simple case of denite programs. Thus, program union as operator for
composition without further restrictions is not satisfactory with respect to compositionality.
We start by adapting the construction of Gaifman and Shapiro (1989) to the case of
disjunctive programs.
Definition 2.2 Two DLP-functions 1 = hR1 , I1 , O1 , H1 i and 2 = hR2 , I2 , O2 , H2 i respect the input/output interfaces of each other if and only if
1. (I1  O1  H1 )  H2 = ,
2. (I2  O2  H2 )  H1 = ,
3. O1  O2 = ,
4. Def R1 (O1 ) = Def R1 R2 (O1 ), and
5. Def R2 (O2 ) = Def R1 R2 (O2 ).
The rst three of the conditions above are due to Gaifman and Shapiro (1989) and
they imply that the sets O1 , H1 , O2 , and H1 are mutually pairwise distinct. Violations
with respect to the rst two conditions can be circumvented by a renaming strategy. For
instance, if an atom a  H1 appears in I2  O2  H2 , hence violating the second condition,
it is possible to replace all occurrences of a in 1 by a new atom a 6 I2  O2  H2 not
appearing in 2 . This removes the conict with respect to a and so forth.5
On the other hand, the last two conditions of Denition 2.2 concern the distribution
of rules involved in the definitions (2) of sets of atoms O1 and O2 , i.e., the sets of rules
Def R1 (O1 ) and Def R2 (O2 ), in R1 and R2 , respectively. As regards disjunctive rules, the
principle is that these sets of dening rules must remain intact when the union R1  R2
is formed which means that each module is supposed to have copies of all rules that form
the denition of its output atoms. In spite of this, two modules 1 and 2 subject to
the conditions of Denition 2.2 may eectively share disjunctive rules A  B, C with a
non-empty head A such that A  O1 6=  and A  O2 6= , as to be demonstrated next.
4. In particular, input atoms in the head A of a rule act very much like atoms in the negative body C.
5. An opposite view to program composition is considered in Section 6, where possibilities for decomposing a disjunctive program into smaller DLP-functions are studied. As a counterpart to renaming, a
revealing operator introduced in Definition 7.3 can be used for circumventing the first two conditions in
Definition 2.2.

818

fiModularity Aspects of Disjunctive Stable Models

Example 2.3 Consider the following two DLP-functions:6
{b}
a  b  c;
d  a, d
{a, c}

and

{a}
a  b  c;
e  a, e
{b, c}

More formally, we have 1 = hR1 , {a, c}, {b}, {d}i and 2 = hR2 , {b, c}, {a}, {e}i such that
R1  R2 = {a  b  c}. We show that 1 and 2 respect the input/output interfaces of
each other: First, both hidden atoms d and e occur in exactly one of the two programs and
thus the first two conditions in Definition 2.2 are satisfied. Second, we have disjoint output
atoms, viz. atom b in 1 and atom a in 2 . Finally, we have Def R1 ({b}) = Def R1 R2 ({b}) =
Def R2 ({a}) = Def R1 R2 ({a}) = {a  b  c}, which shows that also the final two conditions
in Definition 2.2 are satisfied, and as far as syntax is concerned, it makes sense to compose
a larger DLP-function which is obtained as a kind of a union of 1 and 2 ; see (4) below.
In contrast to disjunctive programs, shared rules do not arise in the context of normal
logic programs since only one head atom is allowed in each rule. The same can be stated
about smodels programs (Simons, Niemel, & Soininen, 2002) although such programs
may contain, among other rule types, choice rules of the form
{a1 , . . . , an }  B, C

(3)

with heads of cardinality greater than one. As observed by Oikarinen and Janhunen (2008a),
the heads of choice rules possessing multiple atoms can be freely split without aecting
their semantics. When splitting such rules into n dierent rules {ai }  B, C where
1  i  n, the only concern is the creation of n copies of the rule body B, C which could
reserve a quadratic space in the worst case. A new atom can be introduced to circumvent
this. But the nature of proper disjunctive rules (1), the subject of study in this paper, is
somewhat dierent. Unlike choice rules, disjunctive rules may interact through rule heads.
In Example 2.3, the denition of a depends on b and vice versa. However, given a choice rule
{a, b}  c for instance, the choices regarding a and b are independent of each other: if c is
true, both atoms can have any truth value. This is quite dierent from the interpretation of
ab  c which makes either a or b true given that c is true. To grasp the interaction of a and
b it is natural to have b as an input to the denition of a and, conversely, a as input to that of
b. As to be demonstrated in Section 7, shared rules can be rewritten so that input atoms are
removed from the rule head but as a drawback of the rewriting technique, the compactness
of the representation is partly lost. Therefore, we appreciate the extra exibility provided
by shared rules and interpret them to reect the true nature of disjunctive rules.
In general, DLP-functions are composed according to the following principle:

6. Here and henceforth we make use of a tabular format to represent DLP-functions: the output signature
is given on the top, the input signature at the bottom, and the rules are listed in between. Thus, the
declaration of the hidden signature remains implicit.

819

fiJanhunen, Oikarinen, Tompits & Woltran

O2
L

I1
H1

H2
I2

=

O1

I1  O2

O2

H2

I1

I1  I2

I2

H1

O1

O1  I2

Figure 1: Treatment of signatures by the composition operator .
Definition 2.4 (Composition) Let 1 = hR1 , I1 , O1 , H1 i and 2 = hR2 , I2 , O2 , H2 i be
two DLP-functions that respect the input/output interfaces of each other. Then, the composition of 1 and 2 is defined and determined by
1  2 = hR1  R2 , (I1 \ O2 )  (I2 \ O1 ), O1  O2 , H1  H2 i.

(4)

The treatment of atom types under Denitions 2.2 and 2.4 is summarized in Figure 1.
The two symmetric gures on the left-hand side illustrate the signatures of DLP-functions
1 = hR1 , I1 , O1 , H1 i and 2 = hR2 , I2 , O2 , H2 i subject to composition. Input signatures
and output signatures are emphasized by light gray and dark gray shadings, respectively.
The superposition of the two gures yields the diagram given on the right which represents
the resulting nine categories of atoms. Only three of them may involve shared atoms that
originate from both 1 and 2 . The interface conditions introduced above should be intuitive
to readers acquainted with the principles of object-oriented programming:
1. Although 1 and 2 must not share hidden atoms, they may share input atoms, i.e.,
I1  I2 6=  is allowed. Output atoms are treated dierently as O1  O2 =  is assumed.
2. An input atom of 1 becomes an output atom in 1  2 if it appears as an output
atom in 2 , i.e., 2 provides the input for 1 in this setting. The input atoms of 2
are treated in a symmetric fashion.
3. The hidden atoms of 1 and 2 retain their status in 1  2 .
Example 2.5 Recall Example 2.3 in which we showed that DLP-functions 1 and 2 respect
the input/output interfaces of each other. Thus, the composition of 1 and 2 is defined, and
1  2 is hR1  R2 , I, O, Hi where the set I of input atoms is ({a, c} \ {a})  ({b, c} \ {b}) =
{c}, the set O of output atoms is {a}  {b} = {a, b}, and the set H of hidden atoms is
{d}  {e} = {d, e}, i.e., using our tabular format to represent modules, we have
{b}
a  b  c;
d  a, d
{a, c}



{a}
a  b  c;
e  a, e
{b, c}

=

{a, b}
a  b  c;
d  a, d;
e  a, e
{c}

The definitions of a and b in 1  2 share the rule a  b  c. Thanks to the flexibility of
Definition 2.4, we are also able to split 1  2 into its components whenever appropriate.
820

fiModularity Aspects of Disjunctive Stable Models

Following previous approaches (Gelfond & Gabaldon, 1999; Oikarinen & Janhunen,
2008a), we dene the signature At() of a DLP-function  = hR, I, O, Hi as I  O  H.7
For notational convenience, we distinguish the visible and hidden parts of At() by setting
Atv () = I  O and Ath () = H = At() \ Atv (), respectively. Moreover, Ati () and
Ato () are used to refer to the sets of input and output atoms of , respectively. These
notations provide us a way to access the module interface when it is left implicit, e.g., to
neglect the internal structure of modules. Lastly, for any set S  At() of atoms, we denote the projections of S on Ati (), Ato (), Atv (), and Ath () by Si , So , Sv , and Sh ,
respectively.
In formal terms, a DLP-function  = hR, I, O, Hi is designed to provide a mapping
from subsets of I to a set of subsets of O  H in analogy to LP-functions formalized by
Gelfond and Gabaldon (1999). However, the exact denition of this mapping is deferred
until Section 3 where the semantics of DLP-functions will be anchored. In the sequel, the
(syntactic) class of DLP-functions is denoted by D. It is assumed, for the sake of simplicity,
that D spans over a xed (at most denumerable) signature At(D)8 so that At()  At(D)
holds for each DLP-function   D. Given DLP-functions 1 , 2 , and 3 that pairwise
respect the input/output interfaces of each other, it holds that
 1  2  D (closure),
 1   =   1 = 1 , for the empty DLP-function  = h, , , i (identity),
 1  2 = 2  1 (commutativity), and
 1  (2  3 ) = (1  2 )  3 (associativity).
The theory of modules put forth by Oikarinen and Janhunen (2008a) is based on a more
restrictive operator for program composition, viz. the join . The idea behind this operator
is to forbid positive dependencies between programs which is to be explicated next.
Technically speaking, we dene the positive dependency graph DG+ () of a DLP-function
 = hR, I, O, Hi using only positive dependenciesfollowing the denition by Ben-Eliyahu
and Dechter (1994). However, we exclude input atoms from the graph as their denitions
are external to  anyway. Thus, we let DG+ () = hO  H, 1 i where b 1 a holds for a
pair of atoms a, b  O  H if and only if there is a rule A  B, C  R such that a  A
and b  B. The reexive and transitive closure of 1 gives rise to the dependency relation
 over Ato ()  Ath (). A strongly connected component (SCC) S of the graph DG+ () is
a maximal set S  Ato ()  Ath () such that b  a for every pair a, b  S of atoms. Given
that 1  2 is dened, we say that 1 and 2 are mutually dependent i DG+ (1  2 )
has an SCC S such that S  Ato (1 ) 6=  and S  Ato (2 ) 6=  (Oikarinen & Janhunen,
2008a), i.e., the component S is shared by the DLP-functions 1 and 2 in this way. If 1
and 2 are not mutually dependent, we also call them mutually independent.
Definition 2.6 (Joins) Given two DLP-functions 1 and 2 , if the composition 1  2
is defined and 1 and 2 are mutually independent, then the join, 1  2 , of 1 and 2
is defined and it coincides with 1  2 .
7. Consequently, the length of  in symbols, denoted by kk, gives an upper bound for |At()| which is
important when one considers the computational cost of translating programs (Janhunen, 2006).
8. In practice, this set could be the set of all identifiers (names for propositions or similar objects).

821

fiJanhunen, Oikarinen, Tompits & Woltran

In case that 1  2 is dened, and thus 1 and 2 are mutually independent, exactly
one of the following conditions holds for each SCC S of DG+ (1  2 ):
S  Ato (1 )  Ath (1 ); or

(5)

S  Ato (2 )  Ath (2 ).

(6)

Example 2.7 Recall the programs 1 and 2 from Example 2.5 for which we obtain the
positive dependency graph DG+ (1  2 ) = h{a, b, d, e}, {ha, di, ha, ei}i. Hence, the SCCs of
the graph are simply singletons {a}, {b}, {d}, and {e}. Together with the observation that
Ato (1 ) and Ato (2 ) are disjoint, we derive that 1 and 2 are not mutually dependent.
Thus, the join 1  2 = 1  2 is defined since the composition 1  2 is defined on the
basis of the analysis performed in Example 2.5.
Example 2.8 As an example of two DLP-functions which have their composition defined
yet which are ineligible for a join, consider the following situation:
{b}
a  b  c;
b  a, c
{a, c}



{a}
a  b  c;
a  b, c
{b, c}

=

{a, b}
a  b  c;
a  b, c;
b  a, c
{c}

Here, the result of composition involves an SCC S = {a, b} in the respective positive dependency graph, which has a non-empty intersection with the output signatures of the programs
subject to composition. Hence, the respective join of the modules in question is not defined.

3. Model Theory and Stable-Model Semantics
Having the syntax of DLP-functions dened, we now turn to their semantics. We proceed
in three steps and introduce, correspondingly, three kinds of models, viz. classical models,
minimal models, and, nally, stable models for each DLP-function. The last provide the
intended semantics for a DLP-function whereas the rst two serve as auxiliary concepts.
As usual, an interpretation for a DLP-function  is dened as an arbitrary subset of
At(). Given a particular interpretation M  At(), an atom a  At() is true under M ,
denoted M |= a, i a  M , otherwise a is false under M , denoted M 6|= a. For a negative
literal a, we dene M |= a i M 6|= a. A set L of literals is satisfied by M , denotedWby
M |= L, i M |= l, for everyWliteral l  L. We also dene the disjunctive interpretation L
of a set L of literals: M |= L i M |= l for some literal l  L.
To begin with, we cover DLP-functions with a pure classical semantics, which treats
disjunctive rules as classical implications. It should be emphasized that classical models of
a DLP-function  are specic interpretations as dened above and hence subsets of At().
Definition 3.1 An interpretation M  At() is a (classical) model of a DLP-function
 = hR, I, O, Hi, denoted M |= , iff M |= R, i.e., for every rule A  B, C  R,
W
M |= B  C implies M |= A.
822

fiModularity Aspects of Disjunctive Stable Models

The set of all classical models of  is denoted by CM().
Classical models provide an appropriate level of abstraction to address the role of input
atoms in DLP-functions. Given a DLP-function  and an interpretation M  At(), the
projection Mi can be viewed as the actual input for  which may (or may not) produce the
respective output Mo , depending on the semantics assigned to . The treatment of input
atoms in the sequel will be based on partial evaluation: the idea is to pre-interpret input
atoms appearing in  with respect to Mi .
Definition 3.2 For a DLP-function  = hR, I, O, Hi and an actual input Mi  I for ,
the instantiation of  with respect to Mi , denoted by /Mi , is the quadruple hR , , O, Hi
where R contains a reduced rule
(A \ I)  (B \ I), (C \ I)

(7)

for each rule A  B, C  R such that Mi |= Ai  Bi  Ci .
Example 3.3 Consider the following DLP-function :
{a, b}
a  b  c;
a  c, b;
b  c, a
{c}
For the actual input {c}  Ati (), the reduct /{c} is the DLP-function
h{a  b; b  a}, , {a, b}, i.
On the other hand, with the actual input   Ati (), we obtain the reduct
/ = h{a  b}, , {a, b}, i.
The rules of form (7) are free of input atoms which indicates that the reduct /Mi is a
DLP-function without input. Atoms in Ato ()  Ath () are not aected in /Mi .
Proposition 3.4 Let  be a DLP-function and M  At() an interpretation that defines
an actual input Mi  Ati () for . For all interpretations N  At() such that Ni = Mi ,
N |=   No  Nh |= /Mi .
Proof. Consider any N  At() such that Ni = Mi .
(=) Suppose that N |= . Assume that No  Nh does not satisfy (7) for some rule
A  B, C in . It follows that Mi |= Ai  Bi  Ci , and therefore Ni |= Ai  Bi  Ci .
Thus, N 6|= A  B, C, a contradiction. It follows that No  Nh |= /Mi .
(=) Let No  Nh |=W/Mi hold. Assuming N 6|= A  B, C for a rule of  implies
N |= B  C and N 6|= A. It follows that Ni |= Ai  Bi  Ci and the corresponding
rule (7) is included in /Mi as Ni = Mi . But this rule is not satised by No  Nh since
823

fiJanhunen, Oikarinen, Tompits & Woltran

W
N 6|= A  B, C implies No  Nh |= (B \ I)  (C \ I) and No  Nh 6|= (A \ I), a
contradiction. Hence, we have that N |= .

Thus, the input reduction, as given in Denition 3.2, is fully compatible with classical
semantics and we can characterize the semantic operator CM also in terms of the equation
[
{Mi  N | N  CM(/Mi )}.
(8)
CM() =
Mi Ati ()

Recall that the models of any DLP-function  are subsets of At(). Hence, we have here
that each N  CM(/Mi ) is a subset of At(/Mi ) and thus Mi N =  for each Mi  Ati ()
since no atom from Ati () occurs in /Mi by denition.
Handling input atoms is slightly more complicated in the case of minimal models but
the primitives of parallel circumscription (Lifschitz, 1985; McCarthy, 1986) provide us with
a straightforward way to address them. The rough idea is to keep the interpretation of input
atoms fixed while minimizing (i.e., falsifying) others as far as possible.
Definition 3.5 Let  = hR, I, O, Hi be a DLP-function. A model M  At() of  is
I-minimal iff there is no model N of  such that Ni = Mi and N  M .
In the sequel, the set of I-minimal models of  = hR, I, O, Hi is denoted by MM() and
we treat input atoms by stipulating I-minimality of models. Using this idea, Proposition 3.4
lifts for minimal models given the fact that Ati (/Mi ) = .
Proposition 3.6 Let  be a DLP-function and M  At() an interpretation that defines
an actual input Mi  Ati () for . For all interpretations N  At() such that Ni = Mi ,
N  MM()  No  Nh  MM(/Mi ).
Proof. Consider any N  At() such that Ni = Mi .
(=) Let N  MM(). It follows by Proposition 3.4 that No  Nh |= /Mi . Assume
that No  Nh 
/ MM(/Mi ). Recall that Ati (/Mi ) = . Thus, there is an interpretation
S  No  Nh such that S |= /Mi . It follows by Proposition 3.4 that N  |=  for an
interpretation N  = Mi  S. But then Ni = Ni and N   N jointly contradict N  MM().
(=) Suppose that No  Nh  MM(/Mi ). So, No  Nh |= /Mi , and N |=  follows
by Proposition 3.4. Let us then assume that N 6 MM(), i.e., there is a model N  |= 
with Ni = Ni and N   N . Thus, we have (No  Nh )  (No  Nh ), and since Ni = Ni = Mi
it follows that No  Nh |= /Mi by Proposition 3.4. Then, however, No  Nh |= /Mi is in
contradiction with No  Nh  MM(/Mi ).

The set MM() of Ati ()-minimal models is sucient to determine the semantics of
a positive DLP-function , i.e., whose rules are of the form A  B. Recall that for such
rules A \ Ati () 6=  holds whenever A 6= . In order to cover arbitrary DLP-functions, we
interpret negative body literals in the way proposed by Gelfond and Lifschitz (1991).
Definition 3.7 Given a DLP-function  = hR, I, O, Hi and an interpretation M  At(),
the reduct of  with respect to M is the positive DLP-function M = hRM , I, O, Hi where
RM = {A  B | A  B, C  R and M |= C}.
824

(9)

fiModularity Aspects of Disjunctive Stable Models

Definition 3.8 An interpretation M  At() is a stable model of a DLP-function  with
an input signature Ati () iff M  MM(M ), i.e., M is an Ati ()-minimal model of M .
Hidden atoms play no special role in Denition 3.8. In contrast to this, they will aect
possibilities for program decomposition, as to be presented in Section 6, and their status
will be nally explicated when the notion of modular equivalence is introduced in Section 8.
Denition 3.8 covers also the case of an ordinary disjunctive logic program, which is simply
a DLP-function  = hR, , O, i: a model M  At() = O of  is stable i M is a
minimal model of RM . The denition of stable models gives rise to a semantic operator
At(D)
SM : D  22
for DLP-functions:
SM() = {M  At() | M  MM(M )}.

(10)

Proposition 3.6 provides us a way to dismiss Ati ()-minimality in the denition of stable
models if desirable. Given a stable model M of , the projection N = Mo  Mh is a minimal
model of (/Mi )N and hence a stable model of /Mi . In other words, we have
(/Mi )M = (/Mi )Mo Mh = M /Mi .
Thus, we can derive the following result:
Corollary 3.9 For any DLP-function , we have
SM() = {M  At() | Mo  Mh  SM(/Mi )}.
Example 3.10 Recall the DLP-function  from Example 3.3, having no hidden atoms,
given as follows:
{a, b}
a  b  c;
a  c, b;
b  c, a
{c}
 has four stable models in total: M1 = {a}, M2 = {b}, M3 = {a, c}, and M4 = {b, c},
which are the {c}-minimal models of the respective reducts of :
M1
M2
M3
M4

= h{a  b ; a  c}, {c}, {a, b}, i,
= h{a  b ; b  c}, {c}, {a, b}, i,
= h{a  c}, {c}, {a, b}, i, and
= h{b  c}, {c}, {a, b}, i.

Now, it is easy to verify that each Mj is a {c}-minimal model of the reduct Mj .
For illustrating Corollary 3.9, recall the reducts
/{c} = h{a  b; b  a}, , {a, b}, i and
/ = h{a  b}, , {a, b}, i.
Then, we have that SM(/{c}) = {{a}, {b}} and SM(/) = {{a}, {b}}.
825

fiJanhunen, Oikarinen, Tompits & Woltran

An immediate observation is that we loose the general antichain property of stable
models when input signatures are introduced. For instance, we have M1  M3 and M2  M4
in Example 3.10. However, since the interpretation of input atoms is xed by the semantics,
we perceive antichains locally, i.e., the set {N  SM() | Ni = Mi } of stable models forms an
antichain, for each input Mi  Ati (). In Example 3.10, the sets of stable models associated
with actual inputs  and {c} are {M1 , M2 } and {M3 , M4 }, respectively.

4. Characterizations using Classical Logic
It is well known how the set of stable models of an ordinary disjunctive logic program, i.e., a
DLP-function  of the form hR, , O, i, can be characterized via classical propositional logic,
using the concepts of completion (Clark, 1978) and loop formulas (Lin & Zhao, 2004; Lee &
Lifschitz, 2003). In this section, we generalize these concepts to arbitrary DLP-functions. To
this end, the main concern is the role of input atoms and how to incorporate them into these
concepts. Furthermore, we extend the tightness property of programs (Erdem & Lifschitz,
2003) to DLP-functions by introducing the notion of I-tightness in Section 4.2.
4.1 Program Completion and Loop Formulas
Given a DLP-function , a loop of  is any non-empty subset of a strongly connected
component of the positive dependency graph DG+ (). Recall that DG+ () has only the
atoms of Ato ()  Ath () as its nodes. In particular, each singleton {a} with a  Ato () 
Ath () is thus a loop.
Example 4.1 Consider DLP-functions 1 and 2 defined as follows:

1 :

{b, c}
a  c  b;
ba
{a}

2 :

{a, b}
a  c  b;
ba
{c}

Here, 1 has only singleton loops {b} and {c}. In particular, {a, b} is not a loop as it
contains the input atom a. On the other hand, for 2 we have loops {a}, {b}, and {a, b}.
In what follows,
we use,Wfor a set S of propositional
W formulas (or atoms), S to denote
V
a conjunction sS s and S as a shorthand for sS s. Moreover, if appearing within a
formula, a set S is implicitly understood as a conjunction of its elements. For a DLP-function
 and an atom a  Ato ()  Ath (), we dene the set of supporting formulas
SuppF(a, ) = {B  C  (A \ {a}) | A  B, C   and a  A}
and for a loop L  Ato ()  Ath () of , the set of externally supporting formulas
ESuppF(L, ) = {B  C  (A \ L) | A  B, C  , A  L 6= , and B  L = }.
Clarks completion procedure and (conjunctive) loop formulas can be generalized for DLPfunctions in the following way:
Definition 4.2 For a DLP-function , the completion of  is the set of formulas
826

fiModularity Aspects of Disjunctive Stable Models

W
Comp() = {B  C
W  A | A  B, C  } 
{a  SuppF(a, ) | a  Ato ()  Ath ()}

and the set of loop formulas for  is
W
LF() = {L  ESuppF(L, ) | L  Ato ()  Ath () is a loop of }.9

Observe that in the case of Ati () = , i.e., Ato ()  Ath () = At(), the completion
Comp() reduces to the denition provided by Lee and Lifschitz (2003) and the same holds
for the set LF() of loop formulas. Generally speaking, the propositional theories Comp()
and LF() characterize the set SM() of stable models in the following sense:

Theorem 4.3 For a DLP-function  and an interpretation M  At(),
M  SM() if and only if M |= Comp() and M |= LF().
Proof. We rst relate the sets SuppF(a, ) and ESuppF(L, ), as introduced above for
a DLP-function , with the respective sets of complementary rules
SuppCR(a, ) = {A \ {a}  B, C | A  B, C   and a  A} and
ESuppCR(L, ) = {A \ L  B, C | A  B, C  , A  L 6= , and B  L = }.
First, it is straightforward that, for each interpretation M  At(), we have M |= Comp()
i jointly M |=  and for each a  M  (Ato ()  Ath ()), M 6|= SuppCR(a, ). Quite
similarly, it holds that M |= LF() i, for each loop L  M  (Ato ()  Ath ()) of ,
M 6|= ESuppCR(L, ). On the other hand, by viewing SuppCR(a, ) and ESuppCR(L, )
as DLP-functions having the same signatures as , we can apply Proposition 3.4 in order
to evaluate input atoms. Thus, we obtain the following relationships for each DLP-function
, interpretation M  At(), atom a  Ato ()  Ath (), and loop L  Ato ()  Ath ()
of :
1. M |=  i Mo  Mh |= /Mi ,
2. M |= SuppCR(a, ) i Mo  Mh |= SuppCR(a, /Mi ), and
3. M |= ESuppCR(L, ) i Mo  Mh |= ESuppCR(L, /Mi ).
Finally, recall that for each interpretation M  At(), we have Ato () = Ato (/Mi ) and
Ath () = Ath (/Mi ). Inspecting the denition of Comp() and LF() again, we can
conclude for each interpretation M  At() that M |= Comp()  LF() i Mo  Mh |=
Comp(/Mi )  LF(/Mi ). In turn, we know that Mo  Mh |= Comp(/Mi )  LF(/Mi ) i
Mo  Mh is a stable model of the program /Mi by the results of Lee and Lifschitz (2003);
recall that /Mi is an ordinary disjunctive program without any input atoms. Finally, we
have SM() = {M  At() | Mo  Mh  SM(/Mi )} by Corollary 3.9. This equality shows
the claim.

Example 4.4 Let us demonstrate the functioning of program completion and loop formulas on the DLP-functions from Example 4.1, i.e., on 1 = hR, {a}, {b, c}, i and 2 =
hR, {c}, {a, b}, i, where R = {a  c  b; b  a}. The completions are
9. Although it may seem that the case of a singleton loop L = {a} is somewhat redundant, this is not so,
since some tautological rules such as a  b  a make a difference.

827

fiJanhunen, Oikarinen, Tompits & Woltran

Comp(1 ) = {b  a  c, a  b}  {b  a, c  b  a} and
Comp(2 ) = {b  a  c, a  b}  {b  a, a  b  c}.
Furthermore, the sets of loop formulas are
W
W
LF(1 ) = {b  ESuppF({b}, 1 ), c  ESuppF({c}, 1 )}
= {b  a,
W c  b  a} and
W
LF(2 ) = {b  ESuppF({b},
2 ), a  ESuppF({a}, 2 ),
W
a  b  ESuppF({a, b}, 2 )}
= {b  a, a  b  c, a  b  }.
In the last formula, the W
occurrence of  is in view of ESuppF({a, b}, 2 ) = , which
yields an empty disjunction ESuppF({a, b}, 2 ) =  as usual.
Computing the classical models of Comp(1 )  LF(1 ) = Comp(1 ) yields two such
models, M1 = {a, b} and M2 = . One can check that these are indeed the stable models of
1 by recalling that Ati (1 ) = {a}. Thus, M1 relates to an actual input M1  Ati (1 ) = {a}
whereas M2 is based on M2  Ati (1 ) = . On the other hand, the classical models of
Comp(2 )  LF(2 ) are M1 = {c} and M2 = , which again relate to the two possible
inputs over Ati (2 ) = {c}. Finally, we note that {a, b} is also a model of Comp(2 ) but
ruled out by LF(2 ).
4.2 Tight DLP-functions
We now extend the well-known concept of tightness (Erdem & Lifschitz, 2003) to DLPfunctions. This is of interest since we can exploit the fact that the positive dependency
graph DG+ () is reduced modulo input atoms. In other words, since the dependency graph
DG+ () has only the atoms of Ato ()  Ath () as its nodes, tightness for DLP-functions
can be dened with respect to the input signature.
In the beginning of Section 4, loops were dened as arbitrary non-empty subsets of
strongly connected components in DG+ (). Thus, if DG+ () is acyclic then  has only
singleton loops. However, the converse is not necessarily true, since, for a program  having
only singleton loops, DG+ () may have edges ha, ai, i.e., cycles of length one.
Definition 4.5 A DLP-function  is Ati ()-tight (or tight, for short), if the positive dependency graph DG+ () is acyclic.
Example 4.6 Recall DLP-functions 1 = hR, {a}, {b, c}, i and 2 = hR, {c}, {a, b}, i
based on R = {a  c  b; b  a} from Example 4.1. Here, 1 is {a}-tight since the potential
non-singleton loop {a, b} contains the input atom a. On the other hand, 2 is not {c}-tight.
It is worth mentioning that the ordinary variant of 1 , viz. DLP-function hR, , {a, b, c}, i,
is not -tightin particular, since R is not tight in the usual sense.
We note that the last observation, viz. that a DLP-function hR, I, O, Hi may be I-tight
although R is not a tight program, relies on the use of disjunctions in the program. In fact,
for DLP-functions hR, I, O, Hi, where R is a set of normal rules of the form a  B, C, we
have that a DLP-function  = hR, I, O, Hi is I-tight i R is tight. To verify this, note that
the second item of Denition 2.1 implies that the head atom of a normal rule a  B, C
must not appear in I, and thus no loop of  may involve atoms from I.
828

fiModularity Aspects of Disjunctive Stable Models

We now show that the notion of tightness introduced in Denition 4.5 enables us to
characterize the stable models of a DLP-function by the classical models of its completion.
Since each ordinary program can be represented as a DLP-function, we thus properly
generalize the well-known completion semantics (Clark, 1978). The following lemma is
already sucient for this result in view of Denition 4.2 and Theorem 4.3.
Lemma 4.7 For any tight DLP-function , LF()  Comp().
W
Proof. Recall that for each a  Ato ()  Ath (), a  SuppF(a, ) is contained in
Comp(). Moreover,Wsince  is tight,  has only singleton loops, and thus LF() contains
only formulas a  ESuppF({a}, ), again for each a  Ato ()  Ath (). It remains
to show that, for each atom a, SuppF(a, ) is equivalent to ESuppF({a}, ) whenever the
positive dependency graph DG+ () is acyclic. We repeat the denition of SuppF(a, ) and
give the denition for ESuppF(L, ), simplied for the case L = {a}:
SuppF(a, ) = {B  C  (A \ {a}) | A  B, C   and a  A};
ESuppF({a}, ) = {B  C  (A \ {a}) | A  B, C  , a  A, and B  {a} = }.
Now it is easy to see that for an acyclic dependency graph DG+ (), a  A implies B{a} = 
for every rule A  B, C  . Thus, we conclude that SuppF(a, ) = ESuppF({a}, )
holds for each a  Ato ()  Ath (). Hence, the claim follows.

Example 4.8 Recalling the DLP-function 1 = hR, {a}, {b, c}, i from Example 4.4 with
R = {a  c  b; b  a}, we obtain
Comp(1 ) = {b  a
W c, a  b}  {b  a, cW b  a} and
LF(1 ) = {b  ESuppF({b}, 1 ), c  ESuppF({c}, 1 )}
= {b  a, c  b  a}.
Now, 1 is tight and we observe that LF(1 )  Comp(1 ) as expected.
The observations presented so far lead us to the following result:
Theorem 4.9 For a tight DLP-function  and an interpretation M  At(),
M  SM() if and only if M |= Comp().
In particular, this result is compatible with an existing characterization of stable models
in the case of Ati () = , i.e., if Ato ()  Ath () = At(). Then, the notion of Ati ()tightness coincides with ordinary tightness, and the denition of the completion Comp()
reduces to the one provided by Lee and Lifschitz (2003).

5. Compositional Semantics
In what follows, our objective is to establish the main result of this paper, i.e., to show
that stable-model semantics, as given by Denition 3.8, is fully compositional when larger
DLP-functions  are formed as joins 1  . . .  n of DLP-functions. More precisely, the
interconnection of SM() and SM(1 ), . . . , SM(n ) is explicated in Section 5.1. In analogy
829

fiJanhunen, Oikarinen, Tompits & Woltran

to Section 3, we follow a quite rigorous approach and consider such a relationship for classical
models rst, then for minimal models, and eventually cover the case of stable models which
comprises our module theorem. Then, in Section 5.2, we use quantied Boolean formulas
from the second level of polynomial hierarchy and their modular representation in terms
of DLP-functions to illustrate the module theorem. Finally, we devote Section 5.3 to a
comparison with the splitting set theorem proven by Lifschitz and Turner (1994).
5.1 Module Theorem
To begin with, we formalize the criteria for combining interpretations as well as models.
Definition 5.1 Given two DLP-functions 1 and 2 , interpretations M1  At(1 ) and
M2  At(2 ) are mutually compatible (with respect to 1 and 2 ), or just compatible, if
M1  Atv (2 ) = M2  Atv (1 ).

(11)

According to (11), any two compatible interpretations M1 and M2 for 1 and 2 , respectively, agree about the truth values of their joint visible atoms in Atv (1 )  Atv (2 ). A
quick inspection of Figure 1 reveals the three cases that may arise when the join  = 1 2
is dened and joint output atoms for 1 and 2 are thereafter disallowed: There may exist
1. joint input atoms in Ati () = Ati (1 )  Ati (2 ), or
2. atoms in Ato (1 )  Ati (2 ) that are output atoms in 1 and input atoms in 2 , or
3. by symmetry, atoms in Ati (1 )  Ato (2 ).
Recall that according to Denition 2.6, atoms in the last two categories end up in Ato ()
when  = 1  2 is formed. Atoms in Atv (1 )  Atv (2 ) provide the basis to combine
compatible interpretations for 1 and 2 .
Definition 5.2 Let 1 and 2 be two DLP-functions such that  = 1  2 is defined.
Given any sets of interpretations A1  2At(1 ) and A2  2At(2 ) , the natural join of A1 and
A2 with respect to Atv (1 )  Atv (2 ), denoted by A1 
 A2 , is the set of interpretations
A1 
 A2 = {M1  M2 | M1  A1 , M2  A2 , and M1 and M2 are compatible}.

(12)

Our rst modularity result is formulated for DLP-functions under classical semantics as
dened in Section 3. The combination of classical models is understood as in (12).
Proposition 5.3 For all positive DLP-functions 1 and 2 such that 1  2 is defined,
CM(1  2 ) = CM(1 ) 
 CM(2 ).

(13)

Proof. Consider an interpretation M  At(1 2 ) and its projections M1 = M At(1 )
and M2 = M  At(2 ) with respect to 1 = hR1 , I1 , O1 , H1 i and 2 = hR2 , I2 , O2 , H2 i. It
follows that M1 and M2 are compatible and M = M1  M2 so that
830

fiModularity Aspects of Disjunctive Stable Models

M  CM(1  2 ) 




M |= R1  R2
M1 |= R1 and M2 |= R2
M1  CM(1 ) and M2  CM(2 )
M  CM(1 ) 
 CM(2 ).



Generalizing Proposition 5.3 for stable models of DLP-functions is much more elaborate.
We will cover the case of positive DLP-functions under minimal models rst. The proof of
Theorem 5.5 exploits program completion, loop formulas, as well as the characterization of
stable and minimal models from Section 4 as follows:
Lemma 5.4 For all DLP-functions 1 and 2 such that 1  2 is defined, the following
conditions hold:
Comp(1  2 ) = Comp(1 )  Comp(2 );
LF(1  2 ) = LF(1 )  LF(2 ).

(14)
(15)

Proof. We begin the proof by analyzing how formulas introduced by Clarks completion
and loop formulas are related with joins of DLP-functions. To this end, we will now establish
that the sets of formulas associated with 1  2 are directly obtained as unions of sets
of formulas associatedWwith 1 = hR1 , I1 , O1 , H1 i and 2 = hR2 , I2 , O2 , H2 i: First, an
implication B  C  A belongs to Comp(1  2 ) if and only if it belongs to Comp(1 ),
Comp(2 ), or both in case of a shared rule. Second, let us consider any atom a  O  H,
where O = O1  O2 and H = H1  H2 are disjoint because 1  2 is dened. For the same
reason, either a  O1 H1 or a  O2 H2 , i.e., the atom a is dened either by 1 or 2 . Thus,
we have either Def R1 (a) = Def R1 R2 (a) or Def R2 (a) = Def R1 R2 (a) by Denition 2.2, which
implies that either SuppF(a, 1 2 )W= SuppF(a, 1 ) or SuppF(a, 1 2 ) = SuppF(a, 2 ).
It follows that the implication
1  2 ) if
W a  SuppF(a, 1  2 ) is a member of Comp(
W
and only if either (i) a  SuppF(a, 1 ) belongs to Comp(1 ) or (ii) a  SuppF(a, 2 )
belongs to Comp(2 ). Thus, we may conclude (14) for the completions involved.
Third, recall that each loop L  At(1  2 ) of 1  2 is contained in some SCC S of
1  2 . It follows by (5), (6), and Denition 2.2 that either
1. L  O1  H1 is a loop of 1 and Def R1 (L) = Def R1 R2 (L), or
2. L  O2  H2 is a loop of 2 and Def R2 (L) = Def R1 R2 (L).
In the cases above, we have either ESuppF(L, 1 2 ) = ESuppF(L,W
1 ) or ESuppF(L, 1 
2 ) = ESuppF(L, 2 ). Thus, the respective loop formula L 
ESuppF(L, 1  2 )
belongs to LF(1  2 ) if and only if it is contained in LF(1 )  LF(2 ).

Theorem 5.5 For all positive DLP-functions 1 and 2 such that 1  2 is defined,
MM(1  2 ) = MM(1 ) 
 MM(2 ).

(16)

Proof. Consider any M  At(1  2 ) and the respective projections M1 = M  At(1 )
and M2 = M  At(2 ) which are compatible and, moreover, M = M1  M2 . We obtain the
following chain of equivalences:
831

fiJanhunen, Oikarinen, Tompits & Woltran

M  MM(1  2 )  M
 |= Comp(1  2 ) and M |= LF(1  2 )
M1 |= Comp(1 ) and M1 |= LF(1 )

M2 |= Comp(2 ) and M2 |= LF(2 )
 M1  MM(1 ) and M2  MM(2 )
 M  MM(1 ) 
 MM(2 ).

[Theorem 4.3]
[(14) and (15)]
[Theorem 4.3]
[Denition 5.2]


Example 5.6 Let us demonstrate the result of Theorem 5.5 in a practical setting using DLPfunctions 1 and 2 as visualized below and their composition  = hR, , {a, b, c, d, e}, i.

1 :

{a, b, c}
a  b ;
a  b;
b  a;
a  c;
c  d  e  a, b
{d, e}

2 :

{d, e}
d  c;
e  d;
d  e;
c  d  e  a, b
{a, b, c}

The join 1  2 is defined because the SCCs of the composition  are S1 = {a, b, c}
and S2 = {d, e}. The Ati (1 )-minimal models of 1 are {a, b, c}, {a, b, d}, {a, b, e}, and
{a, b, d, e}. Likewise, calculating MM(2 ), we get
MM(2 ) = {, {a}, {b}, {c, d, e}, {a, b, d, e}, {a, c, d, e}, {b, c, d, e}, {a, b, c, d, e}}.
Hence, the only minimal model of  is M = {a, b, d, e} and the compatibility condition
underlying (16) correctly excludes N = {a, b, c, d, e} 6 MM(). Note that there is no support
to c being true in 1 when d and e are true. Accordingly, c  d  e  a, b is not active.
We are now prepared to present our central result:
Theorem 5.7 (Module Theorem) For all DLP-functions 1 and 2 such that 1  2
is defined,
SM(1  2 ) = SM(1 ) 
 SM(2 ).
(17)
Proof. Again, we take an interpretation M  At(1  2 ) and the respective compatible
projections M1 = M  At(1 ) and M2 = M  At(2 ) into consideration. The proof of (17)
can be based on (16) once a number of preliminary facts has been established:
M2
1
1. The composition M
is dened.
1  2

Since 1  2 is dened, we know that 1  2 is dened. This indicates that 1 and
1
and
2 respect the input/output interfaces of each other. The construction of M
1
M2
M1
M2
2 does not aect this property which implies that 1  2 is dened.
M2
1
is dened.
2. The join M
1  2
M2
1
By the preceding item, the positive dependency graph DG+ (M
1  2 ) is dened.
M1
M2
Let us assume that 1 and 2 are mutually dependent, i.e., there is an SCC S
M2
1
of the graph above such that S  Ato (M
1 ) 6=  and S  Ato (2 ) 6= . Since
the dependency graph has potentially fewer dependencies than the respective graph

832

fiModularity Aspects of Disjunctive Stable Models

DG+ (1 2 ) for 1 and 2 , it follows that S is contained in some SCC S  of the latter.
M2

1
Since Ato (M
1 ) = Ato (1 ) and Ato (2 ) = Ato (2 ), we obtain S  Ato (1 ) 6=  and
S   Ato (2 ) 6= . Thus, 1 and 2 are mutually dependent, a contradiction.
M2
1
3. The reduct (1  2 )M coincides with M
1  2 .

A rule A  B belongs to (1  2 )M if and only if there is a rule A  B, C in 1 ,
2 , or both such that C  M = . Equivalently, there is a rule A  B, C in 1 such
that C  M1 = , or there is a rule A  B, C in 2 such that C  M2 = , i.e.,
1
2
A  B  M
or A  B  M
1
2 .
We therefore get the following chain of equivalences:
M  SM(1  2 ) 






M  MM((1  2 )M )
M2
1
M  MM(M
1  2 )
1
2
M  MM(M
 MM(M
1 )
2 )
M2
1
M1  MM(M
1 ) and M2  MM(2 )
M1  SM(1 ) and M2  SM(2 )
M  SM(1 ) 
 SM(2 ).

[Denition 3.8]
[Item 3 above]
[Theorem 5.5]
[Denition 5.2]
[Denition 3.8]
[Denition 5.2]



The moral of Theorem 5.7 and Denition 2.6 is that stable semantics supports modularization as long as positively interdependent atoms are enforced in the same module.
Example 5.8 Let 1 and 2 be DLP-functions as defined below and  = 1  2 their
join (which is clearly defined):
{b}
a  b ;
bc
{a, c}



{c}
a  c ;
bc
{a, b}

=

{b, c}
a  b ;
a  c ;
bc
{a}

It is straightforward to verify that SM(1 ) = {{b}, {a, b}, {a, c}, {b, c}} and SM(2 ) =
{{c}, {a, b}, {a, c}, {b, c}}. Since Atv (1 )  Atv (2 ) = {a, b, c}, we obtain
SM(1 ) 
 SM(2 ) = SM(1 )  SM(2 ) = {{a, b}, {a, c}, {b, c}}.
A simple cross-check confirms that SM() is indeed given by this set.
Example 5.9 Consider the DLP-functions 1 and 2 from Example 2.8. Then, SM(1 ) =
{, {a, b}, {b, c}} and SM(2 ) = {, {a, b}, {a, c}}. As shown in Example 2.8, the join of 1
and 2 is undefined. Thus, Theorem 5.7 is not applicable. Concerning the composition
1  2 , we note that SM(1  2 ) = {, {a, c}, {b, c}} =
6 {, {a, b}} = SM(1 ) 
 SM(2 ).
Theorem 5.7 can be easily extended for DLP-functions consisting of more than two
modules. In view of this, we say that a nite sequence M1 , . . . , Mn of stable models for
modules 1 , . . . , n , respectively, is compatible, i Mi and Mj are pairwise compatible, for
all 1 
S i, j  n. This property guarantees that each Mi can be recovered from the union
M = ni=1 Mi by taking the respective projection M  At(i ) = Mi .
833

fiJanhunen, Oikarinen, Tompits & Woltran

Corollary 5.10 Let 1 , . . . , n be a sequence of DLP-functions such that the join 1   
n is defined. Then,
SM(1      n ) = SM(1 ) 
  
 SM(n ).

(18)

Example 5.11 The following example simply extends Example 5.8:
{b}
a  b ;
bc
{a, c}



{c}
a  c ;
bc
{a, b}

{a}
a  b ;
ac
{b, c}



=

{a, b, c}
a  b ;
a  c ;
bc


Now we have SM(1 ) = {{b}, {a, b}, {a, c}, {b, c}}, SM(2 ) = {{c}, {a, b}, {a, c}, {b, c}},
and SM(3 ) = {{a}, {a, b}, {a, c}, {b, c}}. Thus, we learn from Corollary 5.10 that
SM(1  2  3 ) = SM(1 ) 
 SM(2 ) 
 SM(3 ) = {{a, b}, {a, c}, {b, c}}.
5.2 Modular Representation of Quantified Boolean Formulas
Our next objective is to illustrate the theory developed so far in terms of a more extensive
unsat as depicted
example. To this end, we consider the pair of DLP-functions sat
n and n
in Figure 2. Their purpose is the evaluation of quantified Boolean formulas (QBFs) of the
form
n
_
XY
(Ai  Bi  Ci  Di ),
(19)
i=1

where each Aj , Bj , Cj , and Dj is a set of Boolean variables, and the parameter n gives
the number of disjuncts in the matrix which is a Boolean formula  inSdisjunctive normal
form (DNF).10 Without loss of generality, we may assume that X = ni=1 (Ai  Bi ), Y =
S
n
i=1 (Ci  Di ), and X  Y =  hold for the sets X and Y of Boolean variables in (19).
It is important to point out that in general the evaluation of QBFs of the form (19) constitutes a p2 -complete decision problem which perfectly matches the complexity of checking
the existence of stable models for a disjunctive program. Given this completeness property,
it follows that in principle any decision problem in p2 can be turned into a QBF of the form
(19), albeit more direct representations can be obtained for particular problem domains. In
this respect, let us address three specic domains prior to detailing the generic approach.
1. The strategic companies domain is identied by Leone et al. (2006) as one of the rst
practical domains involving decision problems on the second level of the polynomialtime hierarchy and solved using ASP techniques. The simplied encoding provided by
Koch, Leone, and Pfeifer (2003) is based on two kinds of disjunctive rules:
strat(x1 )  strat(x2 )  strat(x3 )  strat(x4 )  prod(y, x1 , x2 , x3 , x4 ),

(20)

strat(x)  ctrl(x, x1 , x2 , x3 , x4 ), strat(x1 ), strat(x2 ), strat(x3 ), strat(x4 ),

(21)

10. Also, recall the shorthands S =

V

sS

s and S =

V

834

sS

s introduced right after Example 4.1.

fiModularity Aspects of Disjunctive Stable Models

Function sat
n :

Function unsat
:
n

X
For 1  i  n and x  Ai :  x, act(i);
For 1  i  n and x  Bi : x  act(i);
For 1  i  n: Ai  Bi , act(i)
{act(1), . . . , act(n)}

Ci  {u}  Di , act(i);
y  u;
u  u
{act(1), . . . , act(n)}

For 1  i  n:
For y  Y :

unsat
Figure 2: DLP-functions sat
n and n Wfor the evaluation of a quantied Boolean formula
XY  having a matrix  = ni=1 (Ai  Bi  Ci  Di ).

where predicates strat(x), prod(y, x1 , x2 , x3 , x4 ), and ctrl(x, x1 , x2 , x3 , x4 ), respectively,
denote that a company x is strategic, a product y is produced by companies x1 , . . . , x4 ,
and a company x is controlled by companies x1 , . . . , x4 . Obviously, instances of the
predicate strat arising from the rules of the forms (20) and (21) create positive dependencies in such a program . The resulting SCCs can be used to split the program into
modules 1 , . . . , n so that  = 1  . . .  n is dened. By Theorem 5.7, the status
of a specic company x can be decided using the module i which denes strat(x)
rather than the entire encoding .
2. The model-based diagnosis of digital circuitry provides another interesting application
area. Quite recently, Oikarinen and Janhunen (2008b) presented an ecient encoding
of prioritized circumscription as a disjunctive program (and thus, as a special case, of
parallel circumscription as well)enabling a concise representation of minimal diagnoses in the sense of Reiter (1987). The resulting disjunctive rules involve head-cycles
(see Section 7 for details) which typically pre-empt a polynomial-time translation into
a computationally easier normal logic program. This observation suggests completeness on the second level of the polynomial-time hierarchy although we are not aware of
an exact hardness result. The correctness proof of the encoding exploits two modules
and the module theorem.
3. Finally, let us mention that Gebser, Schaub, Thiele, Usadel, and Veber (2008b) identify
minimal inconsistent cores in large biological networks with disjunctive programs. The
decision problem in question is Dp -complete which also indicates the appropriateness
of disjunctive logic programs for the representation of this domain. Since any Dp complete decision problem can be described as an independent combination of an NPcomplete decision problem P1 and a coNP-complete decision problem P2 , we foresee a
representation in the form of a join sat  unsat , where sat has a stable model i P1
has a succinct certicate, and unsat has a unique stable model i P2 has no succinct
835

fiJanhunen, Oikarinen, Tompits & Woltran

{x1 , x2 }
x1  act(1);
 x1 , act(1);
 x2 , act(2); x2  act(2);
x1  act(3);
 x1 , act(3);
x1  act(4);
 x2 , act(4);
x2  x1 , act(4)
{act(1), act(2), act(3), act(4)}


u  y1 , y2 , act(1);
u  y2  y1 , act(2);
u  y1  y2 , act(3);
u  y1  y2  act(4);
y1  u; y2  u; u  u
{act(1), act(2), act(3), act(4)}

unsat .
Figure 3: Particular instances of sat
4 and 4

certicates. The required DLPs can be worked out via reductions into propositional
(un)satisability. In particular, the test for unsatisability can be realized in analogy
to unsat
analyzed below.
n
In the general case, we use Boolean variables and propositional atoms interchangeably
in order to describe how the validity problem of (19) is captured by DLP-functions from
unsat is based on the explanatory approach from Janhunen
Figure 2. The design of sat
n and n
et al. (2006), where (19) is equivalently viewed as a formula XY  having the matrix
 in conjunctive normal form (CNF). A clause 11 Ai  Bi  Ci  Di in  is active
whenever Ai  Bi is false and the truth of the clause becomes dependent on Ci  Di ; or
to put it dually, Ai  Bi is true and the truth of Ai  Bi  Ci  Di depends on Ci  Di .
The validity of the formula XY  is captured as follows: Given an input interpretation
Mi  {act(1), . . . , act(n)}, the upper DLP-function sat
n from Figure 2 tries to explain the
activation statuses of the clauses in  by checking that the respective theory {Ai  Bi |
act(i)  Mi }  {Ai  Bi | act(i) 6 Mi } is satisable. The lower DLP-function, unsat
, plays
n
the role of a coNP-oracle: it captures a test for the theory {Ci  Di | act(i)  Mi } being
unsatisable. The correctness of the representation provided by these DLP-functions will
be addressed soon, but it is enough to understand their syntax and intuitive meaning for
the moment. A concrete QBF instance is evaluated as follows.
unsat from Figure 2 in the case of QBF
Example 5.12 Consider DLP-functions sat
n and n

x1 x2 y1 y2 [(x1 y1 y2 )(x2 y1 y2 )(x1 y1 y2 )(x1 x2 y1 y2 )]. (22)
Thus, the parameter for this instance is n = 4, and the input signature is {act(1), . . . , act(4)}
unsat , as illustrated in Figure 3. The output signature of the former DLPfor both sat
4 and 4
function is {x1 , x2 } and all other atoms, i.e., y1 , y2 , and u, remain hidden in the latter.
The joint input signature is used to specify the active part of the matrix in (22). The DLPfunction sat
provides an explanation, i.e., an assignment to variables x1 and x2 as its
4
output, whereas unsat
is only responsible for the respective unsatisfiability check. As regards
4
the validity of the QBF given in (22), the input interpretation {act(1), act(2), act(3), act(4)}
yields a positive answer. The respective explanation, i.e., the output interpretation found by
sat
4 , is {x1 }. It is easy to check that when x1 is true and x2 is false then the remainder of
the matrix is true whatever values are assigned to y1 and y2 . Hence, the QBF (22) is valid.
11. For the purposes of this section, we interpret disjunctions A  B of sets A and B = {b | b  B} of
positive and negative literals, respectively, as disjunctions of their elements.

836

fiModularity Aspects of Disjunctive Stable Models

unsat in Figure 2, they have identical
As regards the general DLP-functions sat
n and n
sat
input signatures, only n has output atoms, and the hidden atoms of unsat
are fully
n
sat
unsat
respected. Hence, the composition n  n
is dened. Moreover, the atoms appearing
in rules that involve positive dependencies belong to disjoint sets X and Y  {u}. It is
unsat ) cannot have an SCC S such that S  X 6=  and
therefore clear that DG+ (sat
n  n
unsat is dened regardless of the QBF (19) in
S  (Y  {u}) 6= . This implies that sat
n  n
question. Let us exploit this fact in the context of specic DLP-functions of Example 5.12.

Example 5.13 There are four stable models for the DLP-function sat
4 :
{act(1), act(2), act(3), act(4), x1 }, {act(1), act(3), x1 , x2 }, {act(2)}, and {x2 },
listed in decreasing level of activation. On the other hand, the DLP-function unsat
has a
4
unique stable model {act(1), act(2), act(3), act(4), y1 , y2 , u}, i.e., the interpretation {y1 , y2 , u}
/{act(1), act(2), act(3), act(4)} where the set of rules is
is the unique stable model of unsat
4
given by
{ u  y1 , y2 ; u  y2  y1 ; u  y1  y2 ; u  y1  y2 ; y1  u; y2  u; u  u },
/Mi has no stable models for any other input interpretation Mi . Moreover, we
and unsat
4
unsat ) by combining compatible pairs
may apply the module theorem to calculate SM(sat
4  4
of models. There is only one such pair:
{act(1), act(2), act(3), act(4), x1 }  SM(sat
4 ) and
{act(1), act(2), act(3), act(4), y1 , y2 , u}  SM(unsat
).
4
Thus, {act(1), act(2), act(3), act(4), x1 , y1 , y2 , u} is the unique stable model of the join sat
4 
sat  unsat ) is non-empty, we conclude that (22) is indeed valid.
unsat
.
Since
SM(
4
4
4
It is natural to ask what can be stated about the stable models of the general DLPfunctions unsat
and sat
n
n associated with the QBF XY  given in (19). If M is a stable
sat
model of n , then the respective projection MX = X M determines M , i.e., it holds for all
1  i  n in the matrix  that act(i)  M if and only if MX |= Ai Bi . Moreover, the model
MX is minimal in the sense that there is no strictly smaller interpretation N  MX with
this property. This is an additional feature brought along the minimality of stable models.
As a consequence, the DLP-function sat
n does not capture all possible truth assignments to
variables in X but no relevant truth assignments are lost. On the other hand, any stable
indicates that the respective theory
model M of unsat
n
{Ci  Di | 1  i  n, act(i)  M }
W
is inconsistent, or alternatively, the formula 1in,act(i)M Ci  Di is valid.
Concerning the correctness of the representation given in Figure 2, due to an existing
proof by Janhunen et al. (2006), we only present the main stepsfully exploiting the benets
from our modular approach.
unsat ) is non-empty.
Theorem 5.14 A QBF XY  of the form (19) is valid iff SM(sat
n n

Proof sketch. Consider any QBF XY  of the form (19). The following are equivalent:
837

fiJanhunen, Oikarinen, Tompits & Woltran

1. The formula XY  is valid.
2. There is a minimal interpretation N  X such that, for the set I = {1  i  n |
N 6|= Ai  Bi } of indices determined by N with N |= {Ai  Bi | i  I}{Ai  Bi |
i 6 I}, the theory {Ci  Di | i  I} is unsatisable.
unsat have compatible stable models M = N  {act(i) |
3. The DLP-functions sat
1
n and n
i  I} and M2 = {act(i) | i  I}  Y  {u}, respectively.
unsat has a stable model
4. The DLP-function sat
n  n

M = M1  M2 = N  {act(i) | i  I}  Y  {u}.
In the second item, the minimality of N means that there is no N   N such that {1  i  n |
N  6|= Ai  Bi } = I. This can be assumed without loss of generality.

Theorem 5.14 and the module theorem suggest an approximation strategy for verifying
unsat ) is empty, we know
the validity of QBFs of the form (19). If either SM(sat
n ) or SM(n
unsat ) = .
directly that the formula is not valid. Otherwise, we check whether SM(sat
n  n
5.3 Splitting Sets
For the sake of comparison, we formulate the splitting-set theorem (Lifschitz & Turner,
1994) for a DLP-function  = hR, , O, i, which essentially forms an ordinary disjunctive
program. Splitting sets are sets of atoms that are closed in the following sense:
Definition 5.15 Given a DLP-function  = hR, , O, i, a set U  O of atoms is a splitting set for  if and only if, for every rule A  B, C  R,
A  U 6=  implies A  B  C  U .
By Denitions 2.1 and 5.15, the sets  and O are always splitting sets for . However,
one is mostly interested in other non-trivial splitting sets   U  O for , but such sets
need not exist. Nevertheless, any splitting set U divides the respective set of rules R in two
parts. The bottom, bU (R), of R with respect to U contains all rules A  B, C  R such
that A  B  C  U , whereas the top, tU (R), of R is R \ bU (R). The splitting of R into
bU (R) and tU (R) becomes a proper one, i.e., bU (R) 6=  and tU (R) 6= , if
1. U is non-trivial and
2. every atom a  O has at least one dening rule A  B, C  R such that a  A.
According to Lifschitz and Turner (1994), a solution to R with respect to U  O is a pair
hX, Y i where X  U , Y  O \U , X  SM(bU (R)), and Y  SM(tU (R)/X). Here, tU (R)/X
denotes the partial evaluation of tU (R) in the sense of Denition 3.2 using X  U as an
input interpretation. Using a similar idea, let us introduce DLP-functions corresponding to
bU (R) and tU (R). Given a splitting set U for , the join  = B  T , where
B = hbU (R), , U, i and T = htU (R), U, O \ U, i
is dened. Then, the following result is implied by Theorem 5.7.
838

fiModularity Aspects of Disjunctive Stable Models

Corollary 5.16 (Splitting-Set Theorem from Lifschitz & Turner, 1994) For every
DLP-function  = hR, , O, i corresponding to a set R of disjunctive rules, every splitting
set U  O for , and every interpretation M  At() = O, the following conditions are
equivalent:
1. M is a stable model of .
2. M  U  SM(B ) and M  SM(T ).
3. hM  U , M \ U i is a solution to R with respect to U .
In fact, Theorem 5.7 is strictly stronger than the splitting-set theorem. As previously
demonstrated by Oikarinen and Janhunen (2008a), splitting sets are applicable to DLPfunctions like  = h{a  b; b  a}, , {a, b}, i only in the trivial way, i.e., only U1 = 
are U2 = {a, b} are splitting sets for . In contrast, Theorem 5.7 applies to the preceding
DLP-function in more versatile ways, i.e., 1 2 is dened for 1 = h{a  b}, {b}, {a}, i
and 2 = h{b  a}, {a}, {b}, i. As a consequence of 1  2 being dened, it is possible
to determine the sets of stable models SM(1 ) = {{a}, {b}} = SM(2 ) in separation, if
appropriate, and then conclude that SM() = SM(1 ) 
 SM(2 ) = {{a}, {b}} holds as
well. Yet another generality aspect of splitting concerns the role of input atomsthey are
assumed nonexistent above. Theorem 5.7, however, enables us to treat them as well.

6. Decomposing DLP-Functions
The objectives of this section are contrary to the construction of a DLP-function as a join of
modules. The idea is to exploit the strongly connected components of DG+ (), for a DLPfunction , in order to decompose  into smaller components, e.g., when there is no a priori
information about the internal structure of . For simplicity, we will rst consider DLPfunctions  having no hidden atoms, i.e., where Ath () = . The eects of hidden atoms on
the decomposition of DLP-functions will be addressed thereafter. As dened in conjunction
with Denition 2.6, the SCCs in DG+ () are induced by the positive dependency relation
 which is reexive and transitive, i.e., a preorder by denition. In the sequel, the set of
SCCs in DG+ () is denoted by SCC+ (). The positive dependency relation  lifts for the
elements of SCC+ () as follows: S1  S2 if and only if there are atoms a1  S1 and a2  S2
such that a1  a2 . To this end, it does not matter which pair of atoms is inspected.
Lemma 6.1 For any DLP-function  and any components S1 , S2  SCC+ (), S1  S2 if
and only if a1  a2 for every a1  S1 and a2  S2 .
Proof. (=) If S1  S2 , there are b1  S1 and b2  S2 such that b1  b2 . Consider any
a1  S1 and a2  S2 . It follows that a1  b1 and b2  a2 by the denition of SCCs. Thus,
a1  a2 as  is transitive.
(=) This holds trivially as SCCs are non-empty.

Proposition 6.2 The relation  over SCC+ () is reflexive, transitive, and antisymmetric.
839

fiJanhunen, Oikarinen, Tompits & Woltran

Proof. The relation  over SCC+ () is reexive and transitive by denition. For antisymmetry, consider any S1 , S2  SCC+ () such that S1  S2 and S2  S1 . It follows by
Lemma 6.1 that, for every a1  S1 and a2  S2 , a1  a2 and a2  a1 . Thus, S1 = S2 by the
maximality of components in SCC+ ().

+
Consequently, we may conclude that hSCC (), i is a partially ordered set. Since  is
nite by denition, hSCC+ (), i has maxima and minima but these elements need not be
unique. In particular, for each S  SCC+ () there is a minimum element S1  SCC+ ()
such that S1  S and S2  S1 implies S2 = S1 , for any S2  SCC+ (). Thus, we may
apply the principle of well-founded induction using the minima of hSCC+ (), i as basis.
Given the structure hSCC+ (), i, the DLP-function  = hR, I, O, i can be decomposed in the following way: The set of rules associated with S  SCC+ () is Def R (S)
from (2), i.e., the set of defining rules for S in R. In general, the head of an arbitrary rule
A  B, C  R may coincide in the sense of (2) with several SCCs, which implies that
the rule is included in Def R (S) for several S  SCC+ (). However, such a distribution of
rules is in perfect harmony with the last two conditions of Denition 2.2. We must also
bear in mind integrity constraints   B, C which are not included in Def R (S) for any
S  SCC+ (). To access the integrity constraints of any set R of rules, we dene
IC(R) = {A  B, C  R | A = }.

(23)

We are now ready to present a decomposition of  based on SCC+ ().
Definition 6.3 Given a DLP-function  = hR, I, O, i, the decomposition induced by
SCC+ () includes a DLP-function
0 = hIC(R), At(IC(R))  (I \ At(R)), , i

(24)

and, for each S  SCC+ (), a DLP-function
S = hDef R (S), At(Def R (S)) \ S, S, i.

(25)

The purpose of the extra module 0 is to keep track of integrity constraints as well
as input atoms that are not mentioned by the rules of R. The other modules involved
in the decomposition  are induced by SCCs. Each S refers to other modules using
At(Def R (S)) \ S as its input signature and provides the dening rules (if any) for every
atom in S. Recall that an output atom having no dening rules will be falsied by default.
Proposition 6.4 For a DLP-function  = hR, I, O, i and its decomposition based on
SCC+ (), the join
F
(26)
0  ( SSCC+ () S )
is defined and equal to .

Proof. Let us consider 0 and S for any S  SCC+ (). The composition 0  S
is dened because these modules involve no hidden atoms, Ato (0 ) = , and we have
Def R1 () =  = Def R1 R2 () and Def R2 (S) = Def R (S) = Def R1 R2 (S) for the sets of rules
R1 = IC(R) and R2 = Def R (S). The join 0  S is dened as the respective composition
is and the integrity constraints in 0 do not create any dependencies in DG+ (0  S ).
840

fiModularity Aspects of Disjunctive Stable Models

Let us perform a similar analysis for S1 and S2 based on two dierent components
S1 , S2  SCC+ (). It is clear that S1  S2 is dened since these modules involve no
hidden atoms, S1  S2 = , and we have that Def R1 (S1 ) = Def R (S1 ) = Def R1 R2 (S1 ) and
Def R2 (S2 ) = Def R (S2 ) = Def R1 R2 (S2 ), for R1 = Def R (S1 ) and R2 = Def R (S2 ).
Since all pairwise joins are dened, also the overall join (26) is dened. By Denition 2.4
and the denition of SCC+ (), the outcome is equal to  because
S
1. IC(R)  SSCC+ () Def R (S) = R,
S
2. SSCC+ () S = O, and
S

3. (At(IC(R)) \ O)  ((I \ At(R)) \ O)  SSCC+ () (At(Def R (S)) \ O) = I.
Corollary 6.5 For a DLP-function  with Ath () =  and its decomposition based on
SCC+ (),
SM() = SM(0 ) 
 ( SSCC+ () SM(S )).




Example 6.6 Consider the following DLP-function :
{a, b, c, d}
a  b  c  d ;
 a, c;  b, c;
 a, d;  b, d;
a  b;
c  d;
b  a;
d  c.

So, Ati () = , Ato () = {a, b, c, d}, and Ath () = . There are two SCCs in DG+ (),
viz. S1 = {a, b} and S2 = {c, d}. The resulting decomposition of  consists of
0 = h{ a, c;  a, d;  b, c;  b, d}, {a, b, c, d}, , i,
S1 = h{a  b  c  d ; a  b; b  a}, {c, d}, {a, b}, i, and
S2 = h{a  b  c  d ; c  d; d  c}, {a, b}, {c, d}, i.
The respective sets of stable models are
SM(0 )
SM(S1 )
SM(S1 )
SM()

=
=
=
=

{{a, b}, {c, d}, {a}, {b}, {c}, {d}, },
{{a, b}, {c}, {d}, {c, d}},
{{c, d}, {a}, {b}, {a, b}}, and
{{a, b}, {c, d}}.

Next, we address the case of DLP-functions involving hidden atoms, i.e., for which
Ath () 6=  holds. Then, the components in DG+ () are subsets of Ato ()  Ath () and
we have to revise (25) accordingly. For a DLP-function  = hR, I, O, Hi and S  SCC+ (),
S = hDef R (S), At(Def R (S)) \ S, S  O, S  Hi.

(27)

Unfortunately, a decomposition based on modules of the form (27) is likely to be too negrained. For certain components S1 , S2  SCC+ () such that S1 6= S2 , the respective
841

fiJanhunen, Oikarinen, Tompits & Woltran

modules S1 and S2 conforming to (27) might not respect hidden atoms of each other. A
similar setting may arise with 0 and an individual module S based on some S  SCC+ ()
if the integrity constraints of  refer to hidden atoms of S . The problem would disappear
if all hidden atoms of  were revealed but this is hardly appropriatethere are good reasons
to hide certain atoms from a knowledge representation perspective.
A way to approach this problem is to distinguish components S1  SCC+ () and
S2  SCC+ () for which the respective modules S1 and S2 would not respect the hidden
atoms of each other, i.e., a hidden atom dened by one would be referred by the othereither
positively or negatively. Similar conicts could also arise due to integrity constraints packed
into the module 0 distinguished in Denition 6.3. At rst sight, we should amalgamate 0
with any other module whose hidden atoms occur in the integrity constraints of 0 . But,
in order to avoid fusions of this kind as far as possible, it is worth redistributing integrity
constraints referring to hidden atoms. This is clearly possible for integrity constraints referring to hidden atoms involved in a single component only. To formalize the ideas presented
so far, we distinguish a precise relation among the components of SCC+ () as follows.
Definition 6.7 Given a DLP-function , components S1 , S2  SCC+ () do not respect
the hidden atoms of each other, denoted by S1 !h S2 , if and only if S1 6= S2 and there is
1. a hidden atom h  Ath (S1 ) such that h  Ati (S2 ), or
2. a hidden atom h  Ath (S2 ) such that h  Ati (S1 ), or
3. there are hidden atoms h1  Ath (S1 ) and h2  Ath (S2 ) which both have an occurrence in some integrity constraint  B, C of .
It is clear that !h is irreexive and symmetric for the components of SCC+ () for
any DLP-function . Moreover, the transitive closure of !h , denoted by !+
h , gives rise
+
to a repartitioning of SCC (). Each maximal block S1 , . . . , Sn of components such that
Si !+
h Sj holds for every i 6= j induces a module S as determined by (27) for the union
S = S1  . . .  Sn . The key observation is that modules associated with dierent blocks
of components respect hidden atoms of each other which makes Theorem 5.7 applicable at
that level of abstraction. To summarize the treatment of DLP-functions involving hidden
atoms in their rules, we revise Denition 6.3 accordingly.
Definition 6.8 Given a DLP-function  = hR, I, O, Hi, the decomposition induced by
SCC+ () and !+
h includes a DLP-function
0 = hIC0 (R), At(IC0 (R))  (I \ At(R)), , i

(28)

where IC0 (R) = { B, C  R | (B  C)  H = } and, for each maximal block S1 , . . . , Sn
of components of SCC+ () such that Si !+
h Sj for every i 6= j, a DLP-function
S = hDef R (S)  ICS (R), At(Def R (S)  ICS (R)) \ S, S  O, S  Hi

(29)

where S = S1  . . .  Sn and ICS (R) = { B, C  R | (B  C)  (S  H) 6= }.
As regards Example 6.6, Denitions 6.3 and 6.8 yield identical decompositions for the
DLP-function in question. The eects of hiding are demonstrated by the following example:
842

fiModularity Aspects of Disjunctive Stable Models

Example 6.9 Consider a DLP-function  = hR, , O, Hi, for
R = { a, c; a  b ; b  c  d ; c  d; d  c, b}
and O  H = {a, b, c, d}, where the exact partitioning of atoms in O and H varies from case
to case as analyzed below. The SCCs in SCC+ () are S1 = {a}, S2 = {b}, and S3 = {c, d}.
1. If we take all atoms visible in , i.e., if H = , the decomposition of  yields three modules, S1 = h{a  b }, {b}, {a}, i, S2 = h{a  b ; b  c  d }, {a, c, d}, {b}, i,
and S3 = h{b  c  d ; c  d; d  c, b}, {b}, {c, d}, i, in addition to the module
0 = h{ a, c}, {a, c}, , i encompassing integrity constraints.
2. If we hide H = {a} in , we obtain S1 !h S2 by the disjunctive rule a  b . Therefore, components S1 and S2 must be placed in the same block which is also maximal
giving rise to a module S = h{ a, c; a  b ; b  c  d }, {c, d}, {b}, {a}i where
S = S1  S2 = {a, b}. The other modules are 0 =  and S3 listed above.
3. Finally, if we set H = {a, c} for , we obtain S2 !h S3 by b  c  d  and S1 !h S3
by  a, c in addition to S1 !h S2 as stated above. Since 0 = , the decomposition
of  effectively collapses to a single module S  =  where S  = S1  S2  S3 .
We note about the non-trivial modules mentioned above that
SM(S1 )
SM(S2 )
SM(S3 )
SM(0 )
SM(S )

=
=
=
=
=

{{a}, {b}},
{{b}, {a, b}, {b, c}, {a, c}, {b, d}, {a, d}, {b, c, d}, {a, c, d}},
{{b}, {c, d}},
{, {c}, {a, c}}, and
{{b}, {a, c}, {b, c}, {b, d}, {a, c, d}, {b, c, d}}.

But, regardless of the decomposition obtained, it holds for the respective joins that
SM() =
=
=
=

SM(S1 ) 
 SM(S2 ) 
 SM(S3 ) 
 SM(0 )
SM(S ) 
 SM(S3 ) 
 SM()
SM(S  ) 
 SM()
{{a, c, d}, {b}}.

In the calculations involving 
 it is important to notice that the allowed combinations
of stable models are determined in terms of joint visible atoms of the modules involved.
For instance, we have Atv (S1 )  Atv (S3 ) = {a, b}  {b, c, d} = {b} so that SM(S1 ) 

SM(S3 ) is {{a}  {c, d}, {b}  {b}} = {{a, c, d}, {b}} by Denition 5.2. Thus, interestingly,
the role of the remaining two modules S2 and 0 is merely to approve upon these two
models. Recalling the discussion from the introduction, this suggests a strategy which gives
precedence to
1. an evaluation of modules having only few stable models, and
2. a combination of stable models for modules that have only few visible atoms in common.
843

fiJanhunen, Oikarinen, Tompits & Woltran

7. Shifting Disjunctions
In this section, we continue the pursuit of applications for the module theorem established in
Section 5. We now generalize the principle of shifting disjunctive rules (Gelfond et al., 1991;
Dix et al., 1996) by applying the results of this paper. Roughly speaking, the idea behind
shifting is to translate a disjunctive rule A  B, C into several normal (non-disjunctive)
rules by shifting head atoms h  A to negative literals h in the body. For instance, a
simple disjunctive rule a  b  c  is captured by normal rules
a  b, c,

b  a, c,

and

c  a, b.

As shown by Eiter et al. (2004), such a local shifting transformation preserves ordinary
equivalence, i.e., stable models.12 The application of this technique is, however, pre-empted
in the presence of head-cycles (Ben-Eliyahu & Dechter, 1994). Such a cycle is provided by
an SCC S that intersects with the head A of some disjunctive rule A  B, C of  such
that |S  A| > 1. For instance, local shifting is no longer applicable to the rule a  b  c  in
the presence of a  b and b  a which create a strongly connected component S = {a, b}.
As a consequence, the respective DLP-functions
1 = h{a  b  c ; a  b; b  a}, , {a, b, c}, i,

(30)

2 = h{a  b, c; b  a, c; c  a, b; a  b; b  a}, , {a, b, c}, i

(31)

have dierent stable models: SM(1 ) = {{a, b}, {c}} and SM(2 ) = {{c}}. Such a discrepancy of stable models can be settled by applying the decomposition technique from
Section 6. In fact, it leads to a proper generalization of the local shifting transformation
which is formalized below for DLP-functions and their strongly connected components.
Definition 7.1 Let  = hR, I, O, Hi be a DLP-function and SCC+ () the respective set
of SCCs. The general shifting of  is the DLP-function GSH() = hIC(R)  R , I, O, Hi,
where R is the set of rules
{(A  S)  B, C, (A \ S) | A  B, C  R, S  SCC+ () and A  S 6= }.

(32)

Hence, the idea is to project the head A of the rule with respect to each component S,
and atoms in the dierence A \ S are shifted to the negative body. This can be viewed as
the contribution of a disjunctive rule A  B, C for a particular component S.
Example 7.2 For 1 from (30), we have SCC+ (1 ) = {{a, b}, {c}}, so that
GSH(1 ) = h{a  b  c; c  a, b; a  b; b  a}, , {a, b, c}, i.
Most importantly, we have SM(GSH(1 )) = {{a, b}, {c}} = SM(1 ), in contrast to the set
SM(2 ) = {{c}} of stable models for 2 from (31).
12. In addition to ordinary equivalence, also uniform equivalence (Eiter & Fink, 2003) is preserved by local
shifting but not strong equivalence (Lifschitz, Pearce, & Valverde, 2001).

844

fiModularity Aspects of Disjunctive Stable Models

We now prove the correctness of the general shifting principle from Denition 7.1. The
aim is to exploit the decomposition of  from Denition 6.3 together with the modular
reconstruction of  from Proposition 6.4 and the compositionality of stable semantics from
Corollary 6.5. To extend the coverage of Corollary 6.5, we introduce explicit operators for
revealing and hiding atoms of DLP-functions as follows:
Definition 7.3 Let  = hR, I, O, Hi be a DLP-function. Then,
1. Reveal(, A) = hR, I, O  A, H \ Ai, for a set A  H of hidden atoms, and
2. Hide(, A) = hR, I, O \ A, H  Ai, for a set A  O of output atoms.
Since the denition of stable models does not make a dierence between output atoms
and hidden atoms, the following properties are easy to verify. The role of hidden atoms
becomes important in Section 8 when DLP-functions are compared with each other.
Proposition 7.4 Let  be any DLP-function.
1. For any A  Ath (), SM() = SM(Reveal(, A)).
2. For any A  Ato (), SM() = SM(Hide(, A)).
Lemma 7.5 Let  be a DLP-function with Ath () = , S a component in SCC+ (), and
S the respective module in the decomposition of  according to Definition 6.3. Then,
SM(S ) = SM(GSH(S )).

(33)

Proof. Recall that S = hDef R (S), I, S, i, where the input signature I = At(Def R (S)) \
S. Notice that S is the only component in SCC+ (S ) and hence GSH(S ) has a set of rules
R = {(A  S)  B, C, (A \ S) | A  B, C  Def R (S)}.
Consider any interpretation M  I  S, where I and S are the input and output signatures
of S , respectively. Thus, Mi = M  I and Mo = M  S. Then, the following equivalences
hold:






A  B  (Def R (S)/Mi )Mo
A  B, C  Def R (S)/Mi such that Mo |= C
A  B  , C   Def R (S) such that A = Ao , B = Bo , C = Co ,
Mi |= Ai  Bi  Ci , and Mo |= Co
A  B  , C  , Ai  R such that A = Ao , B = Bo , C = Co ,
Mi |= Ai  Bi  Ci , and Mo |= Co
A  B, C  R /Mi such that Mo |= C
A  B  (R /Mi )Mo .

Thus, we conclude that (Def R (S)/Mi )Mo coincides with (R /Mi )Mo , and, consequently, Mo 
MM((Def R (S)/Mi )Mo ) if and only if Mo  MM((R /Mi )Mo ). Therefore, SM(S /Mi ) =
SM(GSH(S )/Mi ). Since M and, in particular, Mi were arbitrarily chosen in the beginning,
we obtain the equality of stable models stated in (33) directly by Corollary 3.9.

845

fiJanhunen, Oikarinen, Tompits & Woltran

Theorem 7.6 For any DLP-function  = hR, I, O, Hi, SM() = SM(GSH()).
Proof. Since  may have hidden atoms, Corollary 6.5 is not applicable to its decomposition based on SCC+ (). Thus, we have to start with  = Reveal(, H) = hR, I, O  H, i
rather than  itself. Since SCCs are independent of hiding, we have SCC+ ( ) = SCC+ ()
and GSH( ) = Reveal(GSH(),
H). Since Ath ( ) =  by construction, we know by
F

Proposition 6.4 that 0  ( SSCC+ () S ) =  . Applying GSH() to this equation yields
F
GSH( ) = 0  ( SSCC+ () GSH(S )).

(34)

As regards the respective sets of stable models, we obtain
SM( )

=



 (
SM( ) 


=

SM(GSH( )).

=

SM(0 ) 
(

0

SSCC+ ( )

SM(S ))

[Corollary 6.5]

SSCC+ ( )

SM(GSH(S )))

[Lemma 7.5]
[Corollary 6.5 and (34)]

It follows by Proposition 7.4 that SM(Hide( , H)) = SM( ) = SM(GSH( )) =
SM(Hide(GSH( ), H)). Since Hide( , H) =  and Hide(GSH( ), H) = GSH(), we
have established that SM() = SM(GSH()) as desired.

According to Denition 6.3, decompositions of DLP-functions create multiple copies of
disjunctive rules whose heads intersect with several SCCs. The introduction of such copies
can be circumvented by applying the general shifting technique from Denition 7.1.
Example 7.7 For the DLP-function  from Example 6.6, we obtain R1 = {ab  c, d;
a  b; b  a} and R2 = {c  d  a, b; c  d; d  c} as the sets of rules associated with 1 = hR1 , {c, d}, {a, b}, i and 2 = hR2 , {a, b}, {c, d}, i, for which 1  2 =
hR1  R2 , , {a, b, c, d}, i is defined.

These observations enable us to view disjunctive rules which are shared by the modules
associated with SCCs as syntactic sugar. However, a clever implementation can save space
using shared rules. In the worst case, unwinding a rule a1      an  B, C that coincides
with the respective SCCs S1 , . . . , Sn such that a1  S1 , . . . , an  Sn may create n copies of
the body B  C. Such a quadratic blow-up can be partly alleviated by introducing a new
atom b as a name for the body. Thus the result of shifting a1  S1 , . . . , an  Sn becomes
a1  b, a2 , . . . , an ;
..
.
ai  b, a1 , . . . , ai1 , ai+1 , . . . , an ;
..
.
an  b, a1 , . . . , an1
together with the dening rule b  B, C for b. There is an implementation of the general
shifting principle called dencode.13 If requested to do so, it calculates beforehand whether
it pays o to introduce a new atom for the body for each disjunctive rule or not.
13. Available at http://www.tcs.hut.fi/Software/asptools/ for experimenting.

846

fiModularity Aspects of Disjunctive Stable Models

8. Equivalence of DLP-Functions
The concept of visible equivalence was originally introduced in order to neglect hidden atoms
when logic programs, or other theories of interest, are compared on the basis of their models (Janhunen, 2006). Oikarinen and Janhunen (2008a) extended this idea to the level of
logic program modulesgiving rise to the notion of modular equivalence for logic programs.
In this section, we generalize the concept of modular equivalence for DLP-functions and
introduce a translation-based method for checking modular equivalence of DLP-functions
following analogous approaches of Oikarinen and Janhunen (2004, 2009).
8.1 Modular Equivalence
Module interfaces must be taken properly into account when DLP-functions are compared.
For this reason, we consider two DLP-functions 1 and 2 to be compatible if and only if
Ati (1 ) = Ati (2 ) and Ato (1 ) = Ato (2 ).
Definition 8.1 DLP-functions 1 and 2 are modularly equivalent, denoted by 1 m 2 ,
if and only if
1. 1 and 2 are compatible and
2. there is a bijection f : SM(1 )  SM(2 ) such that for all interpretations M 
SM(1 ), M  Atv (1 ) = f (M )  Atv (2 ).
The proof that m is congruent for  lifts from the case of normal programs (Oikarinen
& Janhunen, 2008a) to the disjunctive case using Theorem 5.7.
Proposition 8.2 Let 1 , 2 , and  be DLP-functions. If 1 m 2 and both 1   and
2   are defined, then 1   m 2  .
Proof. Let 1 = hR1 , I1 , O1 , H1 i and 2 = hR2 , I2 , O2 , H2 i be DLP-functions such that
1 m 2 , and  = hR, I, O, Hi a DLP-function acting as an arbitrary context for 1 and
2 such that 1   and 2   are dened. Consider any M  SM(1  ). Theorem 5.7
implies that M1 = M  At(1 )  SM(1 ) and N = M  At()  SM(). Since 1 m 2 ,
we have I1 = I2 , O1 = O2 , and there is a bijection f : SM(1 )  SM(2 ) such that
M1  (I1  O1 ) = f (M1 )  (I2  O2 )

(35)

holds for M1 . Dene M2 = f (M1 ). Since M1 and N are compatible by denition and (35)
holds, the models M2 and N are compatible as I1 = I2 and O1 = O2 . Thus, M2  N 
SM(2  ) by Theorem 5.7 and we have eectively described how M is mapped to a model
in SM(2  ) by a function g : SM(1  )  SM(2  ) dened by
g(M ) = f (M  At(1 ))  (M  At()).
Clearly, g maps the set of visible atoms in M to itself, that is,
M  (I1  I  O1  O) = g(M )  (I2  I  O2  O).
The justications for g being a bijection are as follows:
847

fiJanhunen, Oikarinen, Tompits & Woltran

 g is an injection: M 6= N implies g(M ) 6= g(N ) for all M, N  SM(1  ), since
f (M  At(1 )) 6= f (N  At(1 )) or M  At() 6= N  At().
 g is a surjection: for any N  SM(2  ), M = f 1 (N  At(2 ))  (N  At()) 
SM(1  ) and g(M ) = N , since f is a surjection.
The inverse function g 1 : SM(2  )  SM(1  ) of g can be dened by setting
= f 1 (N  At(2 ))  (N  At()). Thus, 1   m 2  .

Note that  m GSH() follows directly from Theorem 7.6. Applying Proposition 8.2 in
the context of Theorem 7.6 indicates that shifting can be localized to a particular component
1 in a larger DLP-function 1   since 1   m GSH(1 )  .

g 1 (N )

8.2 Verifying Modular Equivalence
Oikarinen and Janhunen (2004) proposed a translation-based method for the verication
of weak equivalence of disjunctive logic programs. Two logic programs are weakly equivalent i they have exactly the same set of stable models. Thus, weak equivalence can
be seen as a special case of modular equivalence for DLP-functions 1 and 2 where
Ati (1 )  Ath (1 ) = Ati (2 )  Ath (2 ) = . This motivates us to adjust the translationbased technique for the verication of modular equivalence. As observed in previous work
(Janhunen & Oikarinen, 2007; Oikarinen & Janhunen, 2008a), the verication of visible/modular equivalence involves a counting problem in general. A reduction of computational time complexity can be achieved for programs that have enough visible atoms,
referred to as the EVA property for short, (Janhunen & Oikarinen, 2007). For any DLPfunction  = hR, I, O, Hi, we dene the hidden part of  as the restricted DLP-function
h = hDef R (H), I  O, H, i which enables the evaluation of hidden atoms in H given
arbitrary truth values for all other atoms in I  O. Recalling Denition 3.2, we use an
instantiation of h with respect to an interpretation Mv  Ati (h ), i.e., h /Mv , to dene
the EVA property for the DLP-function .
Definition 8.3 A DLP-function  = hR, I, O, Hi has enough visible atoms iff h /Mv has
a unique stable model for each Mv  Atv () = Ati (h ).
The idea behind the translation-based method of Oikarinen and Janhunen (2004) is
that ordinary disjunctive programs R1 and R2 are weakly equivalent i their translations
TR(R1 , R2 ) and TR(R2 , R1 ) have no stable models. In the following, we propose a modied
version of the translation function adjusted to verication of modular equivalence. In order
to be able to verify modular equivalence, we need to take the semantics of the atoms in the
input signature into account as well as the role of hidden atoms when modular equivalence
of programs is under consideration. In the case of DLP-functions, we transform any pair 1
and 2 of compatible DLP-functions into a DLP-function EQT(1 , 2 ) that has a stable
model i there is some stable model M  SM(1 ) for which there is no stable model
N  SM(2 ) with M  Atv (1 ) = N  Atv (2 ). We form the translation as a composition
of DLP-functions in order to fully exploit the compositionality of the stable model semantics
when justifying the correctness of the method.
In what follows, we use new atoms a , a , and a not appearing in At(1 )  At(2 )
for any atom a, and we use the shorthand A = {a | a  A} for any set A of atoms, and
848

fiModularity Aspects of Disjunctive Stable Models

analogously dened shorthands A and A . Moreover, diff, unsat, unsat , and ok are new
atoms not appearing in At(1 )  At(2 ). The translation EQT(1 , 2 ), which is to be
summarized by Denition 8.4 below, consists of the following three parts:
(i) The DLP-function 1 naturally captures a stable model M  SM(1 ).
(ii) The DLP-function hidden(2 ) = hRh , I  O, H  , i provides a representation for the
hidden part of 2 = hR, I, O, Hi evaluated with respect to the visible part of M . The
input signature of hidden(2 ) consists of the visible atoms in Atv (2 ) = Atv (1 ) = I 
O. The set Rh contains a rule Ah  Bv Bh , (Av Cv Ch ) for each A  B, C  R
such that Ah 6= , i.e., A  B, C  Def R (H). The hidden parts of rules are renamed
systematically using atoms from Ath (2 ) . This is to capture the unique stable model
N for (2 )h /Mv expressed in Ath (2 ) rather than Ath (2 ). Note that the existence
and uniqueness of such an N is guaranteed by the EVA property.
(iii) Finally, the DLP-function
TR(2 ) = hRTR , I  O  H  , O  H   {unsat, unsat , diff, ok}, O  H  i
provides a minimality check. The set RTR contains
1. a rule unsat  Bv  Bh , (Av  Ah  Cv  Ch ) for each rule A  B, C  R,
2. rules a  a, a , unsat and a  a, a , unsat for each a  O, and rules
a  a , a , unsat and a  a , a , unsat for each a  H,
3. a rule unsat  Bi  Bo  Bh , (Ai  Ao  Ah  Cv  Ch ), unsat for each rule
A  B, C  R,
4. a rule diff  a, a , unsat for each a  O, and a rule diff  a , a , unsat for
each a  H, and
5. the following rules:
ok  unsat,

ok  diff, unsat, unsat ,

and   ok.

The intuition behind the translation TR(2 ) is as follows. The rules in the rst
item check whether an interpretation L  At(2 ) corresponding to the actual input
K = (L  (I  O))  {a | a  L  H}  Atv (2 )  Ath (2 ) for TR(2 ) satises the
rules in 2 . If the rules of 2 are satised, then the rules in items 24 are activated
by the literals unsat in their bodies. The rules in the second item are used to
generate a subset L of L such that L  Ati (2 ) = L  Ati (2 ). This is achieved by
introducing a new atom a for each a  Ato (2 )  Ath (2 ). The rules in the third
item check whether the representation of L in Ati (2 )  Ato (2 )  Ath (2 ) , i.e.,
K  = (L  I)  {a | a  L  (O  H)}, satises the rules in L
2 . The rules in the
fourth item check whether L is a proper subset of L. Finally, the rules in the fth
item summarize the reasons why L cannot be a stable model of 2 , i.e., either the
rules in 2 are not satised in L, or L is not a minimal model of L
2 . As the net eect
of this construction, TR(2 )/K has a stable model i L is not a stable model of 2 .
849

fiJanhunen, Oikarinen, Tompits & Woltran

Definition 8.4 Let 1 and 2 = hR, I, O, Hi be compatible DLP-functions having enough
visible atoms. Then, the translation EQT(1 , 2 ) is given by 1  hidden(2 )  TR(2 ).
The translation TR(2 ) for the minimality check essentially contains the same rules as
TR(R1 , R2 ) \ R1 , where TR(R1 , R2 ) is the translation dened by Oikarinen and Janhunen
(2004) for sets R1 and R2 of disjunctive rules. There are two further aspects, however.
First, occurrences of hidden atoms from H are additionally represented using their counterparts from H  . Second, we only need renamed versions of atoms in O  H because the
interpretation of atoms in the input signature I is kept xed. Finally, we note that for
DLP-functions 1 and 2 which correspond to ordinary disjunctive logic programs, i.e.,
for 1 = hR1 , , O, i and 2 = hR2 , , O, i, the translation EQT(1 , 2 ) coincides with
TR(R1 , R2 ).
Theorem 8.5 Let 1 and 2 be compatible DLP-functions having enough visible atoms.
Then, 1 m 2 iff both SM(EQT(1 , 2 )) =  and SM(EQT(2 , 1 )) = .
Proof sketch. Let 1 and 2 = hR, I, O, Hi be compatible DLP-functions having enough
visible atoms. By Theorem 5.7, given compatible interpretations M1  At(1 ), M2 
At(hidden(2 )), and M3  At(TR(2 )), M = M1 M2 M3 is a stable model of the translation EQT(1 , 2 ) i M1  SM(1 ), M2  SM(hidden(2 )), and M3  SM(TR(2 )). Given
any interpretation M1  At(1 ), there is a unique stable model M2  SM(hidden(2 ))
compatible with M1 , since 2 has the EVA property. Hence, hidden(2 ) does not constrain
stable models in the composition EQT(1 , 2 ). Whenever M3 is compatible with both M1
and M2 , it holds that M3 (I OH  ) = (M1 M2 )(I OH  ) and M3  SM(TR(2 )) i
the interpretation M3 (I O){a  H | a  M3 } is not a stable model of 2 as established
by Oikarinen and Janhunen (2004, Theorem 1).

When verifying modular equivalence of DLP-functions of the forms 1   and 2  ,
it is possible to further streamline the translations involved in the verication task.
Theorem 8.6 Let 1 and 2 be compatible DLP-functions having enough visible atoms,
and  a DLP-function such that 1   and 2   are defined. Then, 1   m 2  
iff both SM(EQT(1 , 2 )  ) =  and SM(EQT(2 , 1 )  ) = .
The context  can be an arbitrary DLP-function, i.e., it is not necessary for  to have the
EVA property, as long as 1   and 2   are dened. To prove Theorem 8.6, notice
that due to the structure of the translation, EQT(1 , 2 )   is dened whenever 1   is
dened, and then Theorems 5.7 and 8.5 can be applied.

9. Related Work
Eiter et al. (1997a) consider the use of disjunctive datalog programs as query programs over
relational databases. In their approach, query programs are formalized as triples h, R, Si
where  is a set of disjunctive rules and R and S are the signatures for the input and output
relations, respectively, whereas auxiliary (hidden) predicates are left implicit. Hence, in the
propositional case, the only notable dierence with respect to Denition 2.1 is that input
atoms are not allowed to occur in the heads of disjunctive rules. As regards semantics, the
850

fiModularity Aspects of Disjunctive Stable Models

program  is reduced with respect to a complete input database D specied in terms of
R, yielding the instantiation [D], and, among others, stable-model semantics is applied to
[D] in analogy to Denition 3.2. However, in contrast to our modular architecture, Eiter
et al. (1997a) take both positive and negative dependencies into account and no recursion
between modules is tolerated. The resulting hierarchy of complete components admits a
straightforward generalization of the splitting sequences (Lifschitz & Turner, 1994). The
essential dierence is that a partial order rather than a total order of modules is assumed.
In this respect, it is worth pointing out that partial orders of DLP-functions are permitted
by .
Modularity has gained more attention in the context of conventional (monotonic) logic
programming; see the work of Bugliesi, Lamma, and Mello (1994) for a survey. Two mainstream approaches are identied: The rst is called programming-in-the-large in which algebraic operators are introduced for the construction of logic programs out of modules. The
approach of our paper falls into this categorythe join  being an example of such operators.
The other, and quite dierent programming-in-the-small approach, is to extend the underlying logical language in terms of abstraction mechanisms. In the approach of Eiter et al.
(1997b), for instance, logic program modules are viewed as generalized quantifiers which are
allowed to nest but only in a hierarchical fashion. To give an idea of this approach, consider
a module that formalizes the transitive closure of a relation denoted by a predicate rel(, ):
tclo(x, y)  rel(x, y);

tclo(x, y)  tclo(x, z), rel(z, y).

Here, tclo(, ) acts as the output predicate of the module tclo[rel] whereas rel(, ) is its only
input predicate. The module can be invoked to create the transitive closure of any binary
relation substituted for rel(, ) above. Consider, for instance, the rule
loop(x)  tclo[edge](x, y), tclo[edge](y, x)
which captures nodes involved in the loops of a directed graph whose edges are supposed to
be represented with the predicate edge(, ). In our approach, the call tclo[edge] would result
in one module as part of the respective ground program with input and output signatures
In = {edge(x, y) | 1  x, y  n} and On = {tclo(x, y) | 1  x, y  n}
in the case of n vertices. However, in the architecture of Eiter et al. (1997b), the module
tclo[rel] can be invoked several times to form transitive closures of dierent relations. In our
eectively propositional approach, each invocation of tclo[rel] would map to a new module.
Although these modules could be obtained by straightforward renaming of predicates, this
aspect illustrates the power of the programming-in-the-small approach. Here, tclo[rel] acts
as a new parameterized connective which the programmer can concisely refer to as a new
relation, viz. the transitive closure of rel in this case. But, in spite of succinctness at this
point, such relations may have to be unwound in an actual implementation. This aspect is
made explicit in the modular action description (MAD) language proposed by Lifschitz and
Ren (2006): a modular action description is turned into a single-module description in a
recursive fashion. The outcome determines the meaning of the modular description via an
embedding into ASP (Lifschitz & Turner, 1999).
Faber, Greco, and Leone (2007) apply the magic-set method in the evaluation of datalog
programs with negation. Their notion of a module is based on the concept of an independent
851

fiJanhunen, Oikarinen, Tompits & Woltran

set. For a non-disjunctive logic program  = hR, , O, i, such a set S  O satises, for any
a  S, the following two conditions:
1. if there is a rule h  B, C  R such that h = a, then B  C  S, and
2. if a  B  C for some dangerous rule h  B, C  R, then {h}  B  C  S.
We skip the exact denition of dangerous rules which, roughly speaking, may interfere with
the existence of stable models. It is clear that independent sets are splitting sets in the sense
of Denition 5.15, but not vice versa in general. Hence, the module theorem provided by
Faber et al. (2007) can be viewed as a special case of the splitting-set theorem and, therefore,
observations presented in Section 5.3 apply to independent sets as well.

10. Conclusion and Discussion
In this paper, we introduced a formal framework for modular programming in the context
of disjunctive logic programs under stable-model semantics. The framework is based on the
notion of a DLP-function which puts into eect appropriate input/output interfacing for
disjunctive logic programs. Analogous module concepts have already been studied in the
cases of normal logic programs and smodels programs (Oikarinen & Janhunen, 2008a) and
even propositional theories (Janhunen, 2008a), but the special characteristics of disjunctive
rules are properly taken into account in the syntactic and semantic denitions of DLPfunctions presented herein. In this respect, we would like to draw the readers attention to
Denition 2.1 (item 2), Denition 2.2 (items 45), as well as Denition 3.2.
Undoubtedly, the main result of this paper is the module theorem, i.e., Theorem 5.7,
which is proved for DLP-functions in generalthus covering the class of disjunctive programs. The module theorem is important as it provides a compositional semantics for
disjunctive programs and it generalizes existing approaches such as those based on splitting sets (Lifschitz & Turner, 1994) and magic sets (Faber et al., 2007). Although our
approach is based on a number of design decisions, e.g., as regards the denition of module
composition, it nevertheless brings out the limits of modular programming in the context
of a nonmonotonic declarative language. The module theorem can be exploited in a number of ways in ASP based on disjunctive logic programs. As demonstrated in Section 6, it
provides the basis for decomposing disjunctive programs into their components and hence
the localization of reasoning tasks. Moreover, as established in Section 7, the technique of
shifting disjunctive rules can be generalized for disjunctive programs involving head-cycles.
Actually, the generalized form enables us to remove shared disjunctive rules altogether but
this might not be desirable due to higher space requirements. Finally, the theory of modular
equivalence is fully applicable to DLP-functions as demonstrated in Section 8.
In addition to the results discussed above, we anticipate further applications of the module theorem in the future. We strongly believe that research in this direction not only yields
results of theoretical interest but also leads to the development of practicably useful software
engineering methods for ASP. In fact, rst tools for decomposing and linking programs have
already been implemented in the context of the smodels system.14 The results of Section 6 enable the development of analogous tools to be used with disjunctive solvers such as
14. See modlist and lpcat in the ASP tools collection at http://www.tcs.hut.fi/Software/asptools/.

852

fiModularity Aspects of Disjunctive Stable Models

claspD, cmodels, dlv, and GnT. There is also an implementation of the general shifting
principle, called dencode, in the ASP tool collection. The results of Section 8 pave the way
for extending a translation-based verication tool, dlpeq (Janhunen & Oikarinen, 2004),
for the verication of modular equivalence. Such an extension is already available in the
respective tool, lpeq, for smodels programs (Oikarinen & Janhunen, 2009).15
Acknowledgments This work was partially supported by the Academy of Finland under projects #211025 (Advanced Constraint Programming Techniques for Large Structured Problems) and #122399 (Methods for Constructing and Solving Large Constraint
Models), and by the Austrian Science Foundation (FWF) under projects P18019 (Formal Methods for Comparing and Optimizing Nonmonotonic Logic Programs) and P21698
(Methods and Methodologies for Developing Answer-Set Programs). The authors would
like to thank the anonymous referees for their constructive comments as well as Martin Gebser and Torsten Schaub for their suggestion to exploit program completion and loop formulas
in the proof of the module theorem. A preliminary version of this paper appeared in the
proceedings of the 9th International Conference on Logic Programming and Nonmonotonic
Reasoning (LPNMR07), Vol. 4483 of LNCS, pp. 175187, Tempe, AZ, USA, Springer.

References
Baral, C., Dzifcak, J., & Takahashi, H. (2006). Macros, macro calls and use of ensembles in
modular answer set programming. In Etalle, S., & Truszczyski, M. (Eds.), Proceedings
of the 22nd International Conference on Logic Programming (ICLP06 ), Vol. 4079 of
LNCS, pp. 376390, Seattle, WA, USA. Springer.
Ben-Eliyahu, R., & Dechter, R. (1994). Propositional semantics for disjunctive logic programs. Annals of Mathematics and Artificial Intelligence, 12 (12), 5387.
Bugliesi, M., Lamma, E., & Mello, P. (1994). Modularity in logic programming. Journal of
Logic Programming, 19/20, 443502.
Clark, K. L. (1978). Negation as failure. In Gallaire, H., & Minker, J. (Eds.), Logic and
Data Bases, pp. 293322. Plenum Press, New York.
Dix, J., Gottlob, G., & Marek, V. W. (1996). Reducing disjunctive to non-disjunctive
semantics by shift-operations. Fundamenta Informaticae, 28 (1-2), 87100.
Drescher, C., Gebser, M., Grote, T., Kaufmann, B., Knig, A., Ostrowski, M., & Schaub,
T. (2008). Conict-driven disjunctive answer set solving. In Brewka, G., & Lang, J.
(Eds.), Proceedings of the 11th International Conference on Principles and Knowledge
Representation and Reasoning, pp. 170176, Sydney, Australia. AAAI Press.
Eiter, T., & Fink, M. (2003). Uniform equivalence of logic programs under the stable model
semantics. In Palamidessi, C. (Ed.), Proceedings of the 19th International Conference
on Logic Programming (ICLP03), Vol. 2916 of LNCS, pp. 224238, Mumbay, India.
Springer.
15. Verification tools mentioned here are available at http://www.tcs.hut.fi/Software/lpeq/.

853

fiJanhunen, Oikarinen, Tompits & Woltran

Eiter, T., Fink, M., Tompits, H., & Woltran, T. (2004). Simplifying logic programs under
uniform and strong equivalence. In Lifschitz, V., & Niemel, I. (Eds.), Proceedings of
the 7th International Conference on Logic Programming and Nonmonotonic Reasoning
(LPNMR04 ), Vol. 2923 of LNAI, pp. 8799, Fort Lauderdale, FL, USA. Springer.
Eiter, T., & Gottlob, G. (1995). On the computational cost of disjunctive logic programming:
Propositional case. Annals of Mathematics and Artificial Intelligence, 15 (3-4), 289
323.
Eiter, T., Gottlob, G., & Mannila, H. (1997a). Disjunctive datalog. ACM Transactions on
Database Systems, 22 (3), 364418.
Eiter, T., Gottlob, G., & Veith, H. (1997b). Modular logic programming and generalized
quantiers. In Dix, J., Furbach, U., & Nerode, A. (Eds.), Proceedings of the 4th
International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR97 ), Vol. 1265 of LNCS, pp. 290309, Dagstuhl, Germany. Springer.
Eiter, T., Ianni, G., Lukasiewicz, T., Schindlauer, R., & Tompits, H. (2008). Combining
answer set programming with description logics for the Semantic Web. Artificial
Intelligence, 172 (1213), 14951539.
Erdem, E., & Lifschitz, V. (2003). Tight logic programs. Theory and Practice of Logic
Programming, 3 (4-5), 499518.
Faber, W., Greco, G., & Leone, N. (2007). Magic sets and their application to data integration. Journal of Computer and System Sciences, 73, 584609.
Gaifman, H., & Shapiro, E. (1989). Fully abstract compositional semantics for logic programs. In Proceedings of the 16th Annual ACM Symposium on Principles of Programming Languages, pp. 134142, Austin, TX, USA. ACM Press.
Gebser, M., Kaminski, R., Kaufmann, B., Ostrowski, M., Schaub, T., & Thiele, S. (2008a).
Engineering an incremental ASP solver. In de la Banda, M., & Pontelli, E. (Eds.),
Proceedings of the 24th International Conference on Logic Programming (ICLP08),
Vol. 5366 of LNCS, pp. 190205, Udine, Italy. Springer.
Gebser, M., Schaub, T., Thiele, S., Usadel, B., & Veber, P. (2008b). Detecting inconsistencies in large biological networks with answer set programming. In de la Banda,
M., & Pontelli, E. (Eds.), Proceedings of the 24th International Conference on Logic
Programming (ICLP08), Vol. 5366 of LNCS, pp. 130144, Udine, Italy. Springer.
Gelfond, M., & Gabaldon, A. (1999). Building a knowledge base: An example. Annals of
Mathematics and Artificial Intelligence, 25 (3-4), 165199.
Gelfond, M., & Leone, N. (2002). Logic programming and knowledge representation  the
A-Prolog perspective. Artificial Intelligence, 138 (1-2), 338.
Gelfond, M., & Lifschitz, V. (1988). The stable model semantics for logic programming. In
Kowalski, R. A., & Bowen, K. A. (Eds.), Proceedings of the 5th International Conference on Logic Programming (ICLP88), pp. 10701080, Seattle, WA, USA. MIT
Press.
854

fiModularity Aspects of Disjunctive Stable Models

Gelfond, M., & Lifschitz, V. (1991). Classical negation in logic programs and disjunctive
databases. New Generation Computing, 9, 365385.
Gelfond, M., Przymusinska, H., Lifschitz, V., & Truszczyski, M. (1991). Disjunctive defaults. In Allen, J. F., Fikes, R., & Sandewall, E. (Eds.), Proceedings of the 2nd International Conference on Principles and Knowledge Representation and Reasoning, pp.
230237, Cambridge, MA, USA. Morgan Kaufmann.
Giunchiglia, E., Lierler, Y., & Maratea, M. (2006). Answer set programming based on
propositional satisability. Journal of Automated Reasoning, 36 (4), 345377.
Janhunen, T. (2006). Some (in)translatability results for normal logic programs and propositional theories. Journal of Applied Non-Classical Logics, 16 (12), 3586.
Janhunen, T. (2008a). Modular equivalence in general. In Ghallab, M., Spyropoulos, C.,
Fakotakis, N., & Avouris, N. (Eds.), Proceedings of the 18th European Conference on
Artificial Intelligence (ECAI08), pp. 7579, Patras, Greece. IOS Press.
Janhunen, T. (2008b). Removing redundancy from answer set programs. In de la Banda,
M., & Pontelli, E. (Eds.), Proceedings of the 24th International Conference on Logic
Programming (ICLP08), Vol. 5366 of LNCS, pp. 729733, Udine, Italy. Springer.
Janhunen, T., Niemel, I., Seipel, D., Simons, P., & You, J.-H. (2006). Unfolding partiality
and disjunctions in stable model semantics. ACM Transactions on Computational
Logic, 7 (1), 137.
Janhunen, T., & Oikarinen, E. (2004). lpeq and dlpeq  translators for automated equivalence testing of logic programs. In Lifschitz, V., & Niemel, I. (Eds.), Proceedings of
the 7th International Conference on Logic Programming and Nonmonotonic Reasoning
(LPNMR04 ), Vol. 2923 of LNAI, pp. 336340, Fort Lauderdale, FL, USA. Springer.
Janhunen, T., & Oikarinen, T. (2007). Automated verication of weak equivalence within
the smodels system. Theory and Practice of Logic Programming, 7 (6), 697744.
Junttila, T., & Niemel, I. (2000). Towards an ecient tableau method for boolean circuit
satisability checking. In Lloyd, J. W., et al. (Eds.), Proceedings of the First International Conference on Computational Logic (CL 2000), Vol. 1861 of LNCS, pp. 553567,
London, UK. Springer.
Koch, C., Leone, N., & Pfeifer, G. (2003). Enhancing disjunctive logic programming systems
by SAT checkers. Artificial Intelligence, 151 (1-2), 177212.
Lee, J., & Lifschitz, V. (2003). Loop formulas for disjunctive logic programs. In Palamidessi,
C. (Ed.), Proceedings of the 19th International Conference on Logic Programming
(ICLP03 ), Vol. 2916 of LNCS, pp. 451465, Mumbay, India. Springer.
Leone, N., Pfeifer, G., Faber, W., Eiter, T., Gottlob, G., & Scarcello, F. (2006). The DLV
system for knowledge representation and reasoning. ACM Transactions on Computational Logic, 7 (3), 499562.
855

fiJanhunen, Oikarinen, Tompits & Woltran

Lifschitz, V. (1985). Computing circumscription. In Joshi, A. K. (Ed.), Proceedings of the
9th International Joint Conference on Artificial Intelligence (IJCAI85 ), pp. 121127,
Los Angeles, CA, USA. Morgan Kaufmann.
Lifschitz, V., Pearce, D., & Valverde, A. (2001). Strongly equivalent logic programs. ACM
Transactions on Computational Logic, 2 (4), 526541.
Lifschitz, V., & Ren, W. (2006). A modular action description language. In Proceedings
of the 21st National Conference on Artificial Intelligence (AAAI06), pp. 853859,
Boston, MA, USA. AAAI Press.
Lifschitz, V., & Turner, H. (1994). Splitting a logic program. In Hentenryck, P. V. (Ed.),
Proceedings of the 11th International Conference on Logic Programming (ICLP94 ),
pp. 2337, Santa Margherita Ligure, Italy. MIT Press.
Lifschitz, V., & Turner, H. (1999). Representing transition systems by logic programs. In
Gelfond, M., Leone, N., & Pfeifer, G. (Eds.), Proceedings of the 6th International
Conference on Logic Programming and Nonmonotonic Reasoning, (LPNMR99 ), Vol.
1730 of LNAI, pp. 92106, El Paso, TX, USA. Springer.
Lin, F., & Zhao, Y. (2004). ASSAT: computing answer sets of a logic program by SAT
solvers. Artificial Intelligence, 157 (1-2), 115137.
Marek, V. W., & Truszczyski, M. (1999). Stable models and an alternative logic programming paradigm. In Apt, K. R., Marek, V. W., Truszczyski, M., & Warren,
D. S. (Eds.), The Logic Programming Paradigm: a 25-Year Perspective, pp. 375398.
Springer.
McCarthy, J. (1986). Applications of circumscription to formalizing commonsense knowledge. Artificial Intelligence, 28, 89116.
Niemel, I. (1999). Logic programs with stable model semantics as a constraint programming
paradigm. Annals of Mathematics and Artificial Intelligence, 25 (34), 241273.
Oikarinen, E., & Janhunen, T. (2004). Verifying the equivalence of logic programs in the
disjunctive case. In Lifschitz, V., & Niemel, I. (Eds.), Proceedings of the 7th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR04 ),
Vol. 2923 of LNAI, pp. 180193, Fort Lauderdale, FL, USA. Springer.
Oikarinen, E., & Janhunen, T. (2008a). Achieving compositionality of the stable model
semantics for smodels programs. Theory and Practice of Logic Programming, 8 (56),
717761.
Oikarinen, E., & Janhunen, T. (2008b). Implementing prioritized circumscription by computing disjunctive stable models. In Dochev, D., Pistore, M., & Traverso, P. (Eds.),
Artificial Intelligence: Methodology, Systems, and Applications, 13th International
Conference (AIMSA08), Vol. 5253 of LNCS, pp. 167180, Varna, Bulgaria. Springer.
Oikarinen, E., & Janhunen, T. (2009). A translation-based approach to the verication of
modular equivalence. Journal of Logic and Computation, 19 , 591613.
856

fiModularity Aspects of Disjunctive Stable Models

Reiter, R. (1987). A theory of diagnosis from rst principles. Artificial Intelligence, 32 (1),
5795.
Simons, P., Niemel, I., & Soininen, T. (2002). Extending and implementing the stable
model semantics. Artificial Intelligence, 138 (12), 181234.

857

fiJournal of Artificial Intelligence Research 35 (2009) 677-716

Submitted 11/08; published 08/09

Variable Forgetting in Reasoning about Knowledge
Kaile Su

sukl@pku.edu.cn

School of Electronics Engineering and Computer Science
Peking University
Beijing, P.R. China

Abdul Sattar

a.sattar@griffith.edu.au

Institute for IIS
Griffith University
Brisbane, Qld 4111, Australia

Guanfeng Lv

lvgf@yahoo.com

School of Computer Science
Beijing University of Technology
Beijing, P.R. China

Yan Zhang

yan@cit.uws.edu.au

School of Computing and Information Technology
University of Western Sydney
Penrith South DC NSW 1797, Australia

Abstract
In this paper, we investigate knowledge reasoning within a simple framework called
knowledge structure. We use variable forgetting as a basic operation for one agent to reason
about its own or other agents knowledge. In our framework, two notions namely agents
observable variables and the weakest sufficient condition play important roles in knowledge
reasoning. Given a background knowledge base  and a set of observable variables Oi for
each agent i, we show that the notion of agent i knowing a formula  can be defined as a
weakest sufficient condition of  over Oi under . Moreover, we show how to capture the
notion of common knowledge by using a generalized notion of weakest sufficient condition.
Also, we show that public announcement operator can be conveniently dealt with via
our notion of knowledge structure. Further, we explore the computational complexity
of the problem whether an epistemic formula is realized in a knowledge structure. In
the general case, this problem is PSPACE-hard; however, for some interesting subcases,
it can be reduced to co-NP. Finally, we discuss possible applications of our framework
in some interesting domains such as the automated analysis of the well-known muddy
children puzzle and the verification of the revised Needham-Schroeder protocol. We believe
that there are many scenarios where the natural presentation of the available information
about knowledge is under the form of a knowledge structure. What makes it valuable
compared with the corresponding multi-agent S5 Kripke structure is that it can be much
more succinct.

1. Introduction
Epistemic logics, or logics of knowledge are usually recognized as having originated in the
work of Jaakko Hintikka - a philosopher who showed how certain modal logics could be
used to capture intuitions about the nature of knowledge in the early 1960s (Hintikka,
c
2009
AI Access Foundation. All rights reserved.

fiSu, Sattar, Lv, & Zhang

1962). In the mid of 1980s, Halpern and his colleagues discovered that S5 epistemic logics
could be given a natural interpretation in terms of the states of processes (commonly called
agents) in a distributed system. This model now is known as the interpreted system model
(Fagin, Halpern, Moses, & Vardi, 1995). It was found that this model plays an important
role in the theory of distributed systems and has been applied successfully in reasoning
about communication protocols (Halpern & Zuck, 1992). However, the work on epistemic
logic has mainly focused on theoretical issues such as variants of modal logic, completeness,
computational complexity, and derived notions like distributed knowledge and common
knowledge.
In this paper, we explore knowledge reasoning within a more concrete model of knowledge. Our framework of reasoning about knowledge is simple and powerful enough to
analyze realistic protocols such as some widely used security protocols.
To illustrate the problem investigated in this paper, let us consider the communication
scenario that Alice sends Bob a message and Bob sends Alice an acknowledgement when
receiving the message. We assume Alice and Bob commonly have the following background
knowledge base CS :
Bob recv msg  Alice send msg
Bob send ack  Bob recv msg
Alice recv ack  Bob send ack
where Bob recv msg and Bob send ack are observable variables to Bob, while Alice send msg
and Alice recv ack are observable to Alice.
The problem we are concerned with is how to verify that Alice or Bob knows a statement
. Intuitively, we should be able to prove that for a statement observable to Alice (Bob),
Alice (Bob) knows the statement if and only if the statement itself holds. As for the
knowledge of non-observable statements, the following should hold:
1. Alice knows Bob recv msg if Alice recv ack holds; on the other hand, if Alice knows
Bob recv msg, then Alice recv ack holds, which means that, in the context of this
example, the only way that Alice gets to know Bob recv msg is that Alice receives
the acknowledgement from Bob.
2. Bob knows Alice send msg if Bob recv msg holds; moreover, if Bob knows Alice send msg,
then Bob recv msg holds. The latter indicates that the only way that Bob gets to
know Alice send msg is that Bob receives the message from Alice.
3. Finally, Bob does not know Alice recv ack.
The idea behind the presented knowledge model for those scenarios demonstrated above
is that an agents knowledge is just the agents observations or logical consequences of the
agents observations under the background knowledge base.
One of the key notions introduced in this paper is agents observable variables. This
notion shares a similar spirit of those of local variables in the work of van der Hoek and
Wooldridge (2002) and local propositions in the work of Engelhardt, van der Meyden and
Moses (1998) and in the work of Engelhardt, van der Meyden and Su (2003). Informally
speaking, local propositions are those depending only upon an agents local information;
and an agent can always determine whether a given local proposition is true. Local variables
678

fiVariable Forgetting in Reasoning about Knowledge

are those primitive propositions that are local. Nevertheless, the notion of local propositions
(Engelhardt et al., 1998, 2003) is a semantics property of the truth assignment function in a
Kripke structure, while the notion of local variables (van der Hoek & Wooldridge, 2002) is a
property of syntactical variables. In this paper, we prefer to use the term observable variable in order to avoid any confusion with the term local variable used in programming,
where non-local variables such as global variables may often be observable.
Our knowledge model is also closely related to the notion of weakest sufficient condition,
which was first formalized by Lin (2001). Given a background knowledge base  and a set
of observable variables Oi for each agent i, we show that the notion of agent i knowing a
formula  can be defined as the weakest sufficient condition of  over Oi under , which can
be computed via the operation of variable forgetting (Lin & Reiter, 1994) or eliminations
of middle terms (Boole, 1854). Moreover, we generalize the notion of weakest sufficient
condition and capture the notion of common knowledge.
Now we briefly discuss the role of variable forgetting in our knowledge model. Let us
examine the scenario described above again. Consider the question: how can Alice figure
out Bobs knowledge when she receives the acknowledgement from Bob? Note that Alices
knowledge is the conjunction of the background knowledge base CS and her observations
Alice recv ack etc. Moreover, all Alice knows about Bobs knowledge is the conjunction
of the background knowledge base CS and all she knows about Bobs observations. Thus,
Alice gets Bobs knowledge by computing all she knows about Bobs observations. In our
setting, Alice gets her knowledge on Bobs observations simply by forgetting Bobs nonobservable variables in her own knowledge.
There is a recent trend of extending epistemic logics with dynamic operators so that the
evolution of knowledge can be expressed (van Benthem, 2001; van Ditmarsch, van der Hoek,
& Kooi, 2005a). The most basic extension is public announcement logic (PAL), which is
obtained by adding an operator for truthful public announcements (Plaza, 1989; Baltag,
Moss, & Solecki, 1998; van Ditmarsch, van der Hoek, & Kooi, 2005b). We show that public
announcement operator can be conveniently dealt with via our notion of knowledge structure. This makes the notion of knowledge structure genuinely useful for those applications
like the automated analysis of the well-known muddy children puzzle.
From the discussion above, we can see that our framework of reasoning about knowledge is appropriate in those situations where every agent has a specified set of observable
variables. To further show the significance of our framework, we investigate some of its
interesting applications to the automated analysis of the well-known muddy children puzzle
and the verification of the revised Needham-Schroeder protocol (Lowe, 1996).
We believe that there are many scenarios where the natural presentation of the available
information about knowledge is under the form of a knowledge structure. What makes it
valuable compared with the corresponding multi-agent S5 Kripke structure is that it can
be much more succinct. Of course, the price to pay is that determining whether a formula
holds in a knowledge structure is PSPACE-hard in the general case, while it is in PTIME
when the corresponding S5 Kripke structure is taken as input. However, the achieved
trade-off between time and space can prove computationally valuable. In particular, the
validity problem from a knowledge structure can be addressed for some instances for which
generating the corresponding Kripke structure would be unfeasible. The muddy children
puzzle shows this point clearly: generating the corresponding Kripke structure is impossible
679

fiSu, Sattar, Lv, & Zhang

from a practical point of view, even for the least number of children considered in the
experiments.
The organization of this paper is as follows. In the next section, we briefly introduce the
concept of forgetting and the notion of weakest sufficient and strongest necessary conditions.
In Section 3, we define our framework of reasoning about knowledge via variable forgetting.
In Section 4, we generalize the notion of weakest sufficient condition and strongest necessary
condition to capture common knowledge within our framework. In Section 5, we show
that public announcement operator can also be conveniently dealt with via our notion of
knowledge structure. Section 6 discusses the computational complexity issue about the
problem of whether an epistemic formula is realized in a knowledge structure. In the
general case, this problem is PSPACE-hard; however, for some interesting subcases, it can
be reduced to co-NP. In Section 7, we consider a case study by applying our framework
to model the well known muddy children puzzle; and further more to security protocol
verification in Section 8. Finally, we discuss some related work and conclude the paper with
some remarks.

2. Preliminaries
In this section, we provide some preliminaries about the notions of variable forgetting and
weakest sufficient condition, and epistemic logic.
2.1 Forgetting
Given a set of propositional variables P , we identify a truth assignment over P with a subset
of P . We say a formula  is a formula over P if each propositional variable occurring in 
is in P . For convenience, we define true as an abbreviation for a fixed valid propositional
formula, say p  p, where p is primitive proposition in P . We abbreviate true by false.
We also use |= to denote the usual satisfaction relation between a truth assignment and
a formula. Moreover, for a set of formulas  and a formula , we use  |=  to denote that
for every assignment , if  |=  for all   , then  |= .
p
)
Given a propositional formula , and a propositional variable p, we denote by ( true
p
the result of replacing every p in  by true. We define ( false ) similarly.
The notion of variable forgetting (Lin & Reiter, 1994), or eliminations of middle terms
(Boole, 1854), can be defined as follows:
Definition 1 Let  be a formula over P , and V  P . The forgetting of V in  , denoted
as V , is a quantified formula over P , defined inductively as follows:
1.  = ;
2. {p} = 



p 
true





p 
false ;

3. (V  {p}) = V ({p}).
For convenience, we use V  to denote V ().
Example 2: Let  = (p  q)  (p  r). We have {p}  (q  r) and {q}  (p  r).
2
680

fiVariable Forgetting in Reasoning about Knowledge

Many characterizations of variable forgetting, together with complexity results, are reported in the work of Lang and Marquis (1998). In particular, the notion of variable
forgetting is closely related to that of formula-variable independence (Lang, Liberatore, &
Marquis, 2003).
Definition 3 Let  be a propositional formula, and V a set of propositional variables. We
say  is independent from V if and only if  is logically equivalent to a formula in which
none of the variables in V appears.
The following proposition was given in the work of Lang, Liberatore and Marquis (2003).
Proposition 4 Let  be a propositional formula, and V a set of propositional variables.
Then V  is the logically strongest consequence of  that is independent from V (up to
logical equivalence).
2.2 Weakest Sufficient Conditions
The formal definitions of weakest sufficient conditions and strongest necessary conditions
were first formalized via the notion of variable forgetting by Lin (2001), which in turn play
an essential role in our approach.
Definition 5 Let V be a set of propositional variables and V 0  V . Given a set of formulas
 over V as a background knowledge base and a formula  over V .
 A formula  over V 0 is called a sufficient condition of  over V 0 under  if  |=   .
It is called a weakest sufficient condition of  over V 0 under  if it is a sufficient
condition of  over V 0 under , and for any sufficient condition 0 of  on V 0 under
, we have  |= 0  .
 A formula  over V 0 is called a necessary condition of  over V 0 under  if  |=   .
It is called a strongest necessary condition of  over V 0 under  if it is a necessary
condition of  over V 0 under , and for any necessary condition 0 of  over V 0 under
, we have  |=   0 .
The notions given above are closely related to theory of abduction. Given an observation,
there may be more than one abduction conclusion that we can draw. It should be useful
to find the weakest one of such conclusions, i.e., the weakest sufficient condition of the
observation (Lin, 2001). The notions of strongest necessary and weakest sufficient conditions
of a proposition also have many potential applications in other areas such as reasoning about
actions. The following proposition, which is due to Lin (2001), shows how to compute the
two conditions.
Proposition 6 Given a background knowledge base {} over V , a formula  over V , and
a subset V 0 of V . Let SN C  and W SC  be a strongest necessary condition and a weakest
sufficient condition of  over V 0 under {} respectively. Then
 W SC  is equivalent to (V  V 0 )(  ); and
 SN C  is equivalent to (V  V 0 )(  ).
681

fiSu, Sattar, Lv, & Zhang

2.3 Epistemic Logic and Kripke Structure
We now recall some standard concepts and notations related to the modal logics for multiagents knowledge.
Given a set V of propositional variables. Let L(V ) be the set of all propositional formulas
on V . The language of epistemic logic, denoted by Ln (V ), is L(V ) augmented with modal
operator Ki for each agent i. Ki  can be read agent i knows  . Let LC
n (V ) be the
language of Ln (V ) augmented with modal operator C for each set of agents . A formula
C  indicates that it is common knowledge among agents in  that  holds. We omit the
argument V and write Ln and LC
n , if it is clear from context.
According to the paper by Halpern and Moses (1992), semantics of these formulas can be
given by means of Kripke structure (Kripke, 1963), which formalizes the intuition behind
possible worlds. A Kripke structure is a tuple (W, , K1 ,    , Kn ), where W is a set of
worlds,  associates with each world a truth assignment to the propositional variables, so
that (w)(p)  {true, false} for each world w and propositional variable p, and K1 ,    , Kn
are binary accessibility relations. By convention, W M , KiM and  M are used to refer to the
set W of possible worlds, the Ki relation and the  function in the Kripke structure M ,
respectively. We omit the superscript M if it is clear from context. Finally, let C be the
S
transitive closure of i Ki .
A situation is a pair (M, w) consisting of a Kripke structure and a world w in M . By
using situations, we can inductively give semantics to formulas as follows: for primitive
propositions p,
(M, w) |= p iff  M (w)(p) = true.
Conjunctions and negations are dealt with in the standard way. Finally,
(M, w) |= Ki  iff for all w0  W such that wKiM w0 , we have that (M, w0 ) |= ; and
M w 0 , we have that (M, w 0 ) |= .
(M, w) |= C  iff for all w0  W such that wC

We say a formula  is satisfiable in Kripke structure M if (M, w) |=  for some possible
world w in Kripke structure M .
A Kripke structure M is called an S5n Kripke structure if, for every i, KiM is an equivalence relation. A Kripke structure M is called a finite Kripke structure if the set of possible
worlds is finite. According to the work of Halpern and Moses (1992), we have the following
lemma.

Lemma 7 If a formula is satisfiable in an S5n Kripke structure, then so is in a finite S5n
Kripke structure.

3. Knowledge and Weakest Sufficient Conditions
In our framework, a knowledge structure is a simple model of reasoning about knowledge.
The advantage of this model is, as will be shown later, that agents knowledge can be
computed via the operation of variable forgetting.
682

fiVariable Forgetting in Reasoning about Knowledge

3.1 Knowledge Structure
Definition 8 A knowledge structure F with n-agents is a (n + 2)-tuple (V, , O1 ,    , On )
where (1) V is a set of propositional variables; (2)  is a consistent set of propositional
formulas over V ; and (3) for each agent i, Oi  V .
The variables in Oi are called agent is observable variables. An assignment that satisfies
 is called a state of knowledge structure F. Given a state s of F, we define agent is local
state at state s as s  Oi . Two knowledge structures are said to be equivalent if they have
the same set of propositional variables, the same set of states and, for each agent i, the
same set of agent is observable variables.
A pair (F, s) of knowledge structure F and a state s of F is called a scenario.
Given a knowledge structure (V, , O1 ,    , On ) and a set V of subsets of V , we use EV
to denote a relation between two assignments s, s0 on V satisfying  such that (s, s0 )  EV
iff there exists a P  V with s  P = s0  P . We use EV to denote the transitive closure of
EV .
Let V = {Oi | i  }. We then have that (s, s0 )  EV iff there exists an i   with
s  Oi = s0  Oi .
A simple instance of knowledge structure is F0 = ({p, q}, {p  q}, {p}, {q}), where p, q
are propositional variables. There are two agents for knowledge structure F0 . Variables p
and q are observable to agents 1 and 2, respectively. We have that V{1,2} = {{p}, {q}}; and
for any two subsets s and s0 of {p, q} that satisfy p  q, we have that (s, s0 )  EV{1,2} .
We now give the semantics of language LC
n based on scenarios.
Definition 9 The satisfaction relationship |= between a scenario (F, s) and a formula  is
defined by induction on the structure of .
1. For each propositional variable p, (F, s) |= p iff s |= p.
2. For any formulas  and , (F, s) |=    iff (F, s) |=  and (F, s) |= ; and
(F, s) |=  iff not (F, s) |= .
3. (F, s) |= Ki  iff for all s0 of F such that s0  Oi = s  Oi , (F, s0 ) |= .
4. (F, s) |= C  iff (F, s0 ) |=  for all s0 of F such that (s, s0 )  EV .
We say that a proposition formula in L(V ) is i-local if it is over Oi . Clearly, agent i
knows an i-local formula  in F iff  |= .
Let F = (V, , O1 ,    , On ) be a knowledge structure. We say that a formula  is realized
in knowledge structure F, if for every state s of F, (F, s) |= . For convenience, by F |= ,
we denote formula  is realized in knowledge structure F.
We conclude this subsection by the following lemma, which will be used in the remains
of this paper.
Lemma 10 Let V be a finite set of variables, F = (V, , O1 ,    , On ) be a knowledge structure, and s be a state of F. Also suppose that   {1,    , n}, and V = {Oi | i  }.
Then
683

fiSu, Sattar, Lv, & Zhang

1. for any objective formula  (i.e., propositional formula over V ), (F, s) |=  iff s |= ;
2. for any formula   , (F, s) |= ;
3. for any i-local formula , (F, s) |= Ki   ;
4. for any formula , if there exists, for each i  , an i-local formula logically equivalent
to  under , then (F, s) |= C   ;
5. for any formulas 1 and 2 , (F, s) |= Ki (1  2 )  (Ki 1  Ki 2 );
6. for any formulas 1 and 2 , (F, s) |= C (1  2 )  (C 1  C 2 );
7. for any formula  and i  , (F, s) |= C   Ki C .
Proof:
1. The first item of this proposition can be proved by induction on the structure of .
When  is a primitive proposition, it is done by the first item of Definition 9. When
 is of the form of negation or conjunction, the conclusion also follows immediately
by the first item of Definition 9.
2. The second item of this proposition can be proved by the first item and the fact s
satisfies .
3. Given an i-local formula , it suffices to show (F, s) |= Ki  iff (F, s) |= . By the
first item of this proposition, we have that (F, s) |=  iff s |= . Moreover, as  is
i-local or over Oi , for all assignments s0 with s0  Oi = s  Oi , we have that s0 |= 
iff s |= . Therefore, we get the following three iffs: (F, s) |= Ki  iff, for all state
s0 of F with s0  Oi = s  Oi , we have that (F, s0 ) |=  iff, for all state s0 of F with
s0  Oi = s  Oi , we have that s0 |=  iff s |= . Thus, (F, s) |= Ki  iff (F, s) |= .
4. Suppose that, for each i  , there exists an i-local formula logically equivalent to 
under . We need to show (F, s) |= C   . First, because (s, s)  EV  EV , for
all formula , we have that (F, s) |= C  implies (F, s) |= . Therefore, it suffices to
prove that (F, s) |=   C . Assume (F, s) |= . To prove that (F, s) |= C , we
need to show that for every assignment s0 such that (s, s0 )  EV , (F, s0 ) |= . From
the definition of EV , it suffices to show that for every finite sequence of assignments
s0 ,    , sk with s0 = s and (sj , sj+1 )  EV (0  j < k), we have that for every j  k,
(F, sj ) |= . We show this by induction on j. When j = 0, the result is clearly true.
Assume (F, sj ) |= . Now we prove (F, sj+1 ) |= . Because (sj , sj+1 )  EV , there is
an i   such that Oi  sj = Oi  sj+1 . On the other hand, we have that sj |=  iff
sj+1 |=  because  is equivalent under  to an i-local formula. Hence, (F, sj+1 ) |= 
as desired.
5. It suffice to show that if (F, s) |= Ki (1  2 ) and (F, s) |= Ki 1 , then (F, s) |=
Ki 2 . Assume that (F, s) |= Ki (1  2 ) and (F, s) |= Ki 1 , by item 3 of Definition 9 we get that, for all s0 of F with s0  Oi = s  Oi , we have (F, s0 ) |= (1  2 )
and (F, s0 ) |= 1 . However, by item 2 of Definition 9, we get (F, s0 ) |= 2 from
(F, s0 ) |= (1  2 ) and (F, s0 ) |= 1 . Therefore, we get that, for all s0 of F with
s0  Oi = s  Oi , we have (F, s0 ) |= 2 . It follows immediately that (F, s) |= Ki 2 .
684

fiVariable Forgetting in Reasoning about Knowledge

6. This item can be shown in the same way as in the proof of item 5.
7. It suffices to prove that for those state s00 such that there is a state s0 with s  Oi =
s0  Oi and s0 EV s00 , we can get sEV s00 , which follows immediately from the fact that
EV is the transitive closure of EV . 2
3.2 Relationship with S5 Kripke Structure
Given a knowledge structure F = (V, , O1 ,    , On ), let M (F) be Kripke structure
(W, , K1 ,    , Kn ), where
1. W is the set of all states of F;
2. for each w  W , the assignment (w) is the same as w; and
3. for each agent i and assignments w, w0  W , we have that wKi w0 iff w  Oi = w0  Oi .
The following proposition indicates that a knowledge structure can be viewed as a specific Kripke structure.
Proposition 11 Given a knowledge structure F, a state s of F, and a formula  in LC
n (V ),
we have that (F, s) |=  iff (M (F), s) |= .
Proof: Immediately by the definition of the satisfaction relationship between a scenario
and a formula and that between a situation and a formula. 2
From Proposition 11, we conclude that if a formula in LC
n is satisfiable in some knowledge
structure, then the formula is also satisfiable in some Kripke structure. From the following
proposition and Lemma 7, we can get that if a formula in LC
n is satisfiable in some Kripke
structure, then the formula is also satisfiable in some knowledge structure.
Proposition 12 For a finite S5n Kripke structure M with the propositional variable set V
and possible world w in M , there exists a knowledge structure FM and a state sw of F such
that, for every formula   LC
n (V ), we have that (FM , sw ) |=  iff (M, w) |= .
Proof: Let M = (W, , R1 ,    , Rn ), where W is a finite set and R1 ,    , Rn are equivalence
relations. Let O1 ,    , On be sets of new propositional variables such that
1. O1 ,    , On are finite and pairwise disjoint; and
2. for each i (0 < i  n), the number of all subsets of Oi is not less than that of all
equivalence classes of Ri .
By the latter condition, there is, for each i, a function gi : W 7 2Oi such that for all
w1 , w2  W , gi (w1 ) and gi (w2 ) are the same subset of Oi iff w1 and w2 are in the same
equivalence class of Ri .
S
0
Let V 0 = V  0<in Oi . We define a function g : W 7 2V as follows. For each possible
world w in W ,
[
g(w) = {v  V | (w)(v) = true} 
gi (w).
0<in

The following two claims hold:
685

fiSu, Sattar, Lv, & Zhang

C1 For all w1 , w2  W , and i (0 < i  n), we have that g(w1 )  Oi = g(w2 )  Oi iff
w1 Ri w2 .
C2 For all w  W and v  V , we have that v  g(w) iff (w)(v) = true.
Let
M = { |  is over V 0 , and g(w) |=  for all w  W }.
We then get the knowledge structure
FM = (V 0 , M , O1 ,    , On ).
We now show the following claim:
C3 For every s  V 0 , s is a state of FM iff s = g(w) for some w  W.
The if part of claim C3 is easy to prove. If s = g(w0 ) for some w0  W , then by the
definition of M , we have that g(w0 ) |= M and hence g(w0 ) is a state of FM . To show
the only if part, assume that for every w  W , s 6= g(w). Then, for every w  W ,
V
there exists w over V 0 such that s |= w but g(w) |= w . Therefore, s |= wW w .
W
W
Moreover, we have that, for every w0  W , g(w0 ) |= wW w , and hence wW w 
M . Consequently, we have that s 6|= M and hence s is not a state of FM .
To complete the proof, it suffices to show, for every   LC
n (V ), that (FM , g(w)) |= 
iff (M, w) |= . With conditions C1, C2 and C3, we can do so by induction on . For the
base case, we assume  is a propositional variable, say p. Then, by condition C2, we have
that (FM , g(w)) |= p iff p  g(w) iff (w)(p) = true iff (M, w) |= p.
Suppose that  is not a propositional variable and the claim holds for every subformula
of . There are three cases:
1.  is of form  or   . This case can be dealt with by the definitions of satisfaction
relations directly.
2.  is of form Ki . In this case, we have (FM , g(w)) |= Ki  iff (FM , s) |=  for all states
s of FM with g(w)  Oi = s  Oi . By condition C3, we have that (FM , g(w)) |= Ki 
iff (FM , g(w0 )) |=  for all w0  W with g(w)  Oi = g(w0 )  Oi . By condition C1,
we then have (FM , g(w)) |= Ki  iff (FM , g(w0 )) |=  for all w0  W with wRi w0 .
Therefore, by the induction assumption, we have (FM , g(w)) |= Ki  iff (M, w0 ) |= 
for all w0  W with wRi w0 . The right part is just (M, w) |= Ki .
3.  is of form C . Recall that, for arbitrary two states s and s0 of FM , (s, s0 )  EV
iff there exists an i   with s  Oi = s0  Oi . By condition C1, for all w1 , w2  W ,
(g(w1 ), g(w2 ))  EV iff (w1 , w2 ) 

[

Ri .

i

S

M is that of
As EV is the transitive closure of EV , and C
i Ri , by condition C3
we get that
M
(g(w1 ), g(w2 ))  EV iff (w1 , w2 )  C

for all w1 , w2  W .
686

fiVariable Forgetting in Reasoning about Knowledge

We want to show that (FM , g(w)) |= C  iff (M, w) |= C . On one hand, (FM , g(w)) |=
C  iff for all states s of FM with (g(w), s)  EV , (FM , s) |= . By condition C3,
we have that (FM , g(w)) |= C  iff for all w0  W with (g(w), g(w0 ))  EV . On
M . Therefore, we
the other hand, (M, w) |= C  iff for all w0  W with (w, w0 )  C
conclude that (FM , g(w)) |= C  iff (M, w) |= C  by the above discussion. 2
Propositions 11 and 12 show that the satisfiability issue for a formula in the language
of multi-agent S5 with the common knowledge modality is the same whatever satisfiability
is meant w.r.t. a standard Kripke structure or w.r.t. a knowledge structure.
3.3 Knowledge as Weakest Sufficient Conditions
The following theorem establishes a bridge between the notion of knowledge and the notion
of weakest sufficient and strongest necessary conditions.
Theorem 13 Let V be a finite set of variables, F = (V, , O1 ,    , On ) a knowledge structure,  a propositional formula in L(V ), and for an agent i, W SCi and SN Ci a weakest
sufficient condition and a strongest necessary condition of  over Oi under  respectively.
Then, for each state s of F,
(F, s) |= Ki   W SCi
and
(F, s) |= Ki   SN Ci .
Proof: We only show (F, s) |= Ki   W SCi , while the other part comes in a straightforward way by duality between WSCs and SNCs. Because W SCi is a sufficient condition
of  under , we have  |= W SCi  . Let  be the conjunction of all formulas in
, then we have |=   (W SCi  ), which leads to (F, s) |= Ki W SCi  Ki  (by
item 5 of Lemma 10.) Because W SCi is i-local, by Lemma 10 (item 3) again, we have
(F, s) |= W SCi  Ki W SCi . Hence, (F, s) |= W SCi  Ki .
To show the other direction (F, s) |= Ki   W SCi , we consider the formula (V 
Oi )(  ), where  is the same as above. By Proposition 6, we have  |= (V  Oi )( 
)  W SCi . On the other hand, we know that (F, s) |= Ki   (V  Oi )(  ) by the
definition of Ki . This proves (F, s) |= Ki   W SCi . 2
The following corollary characterizes the subjective formulas Ki  (where  is objective)
which are satisfied in a given knowledge structure.
Corollary 14 Let V be a finite set of variables, F = (V, {}, O1 ,    , On ) a knowledge
structure with n agents, and  a formula over V . Then, for every state s of F,
(F, s) |= Ki   (V  Oi )(  ).
Proof:

Immediately by Theorem 13 and Proposition 6. 2

Now we consider the communication scenario between Alice and Bob
Example 15 :
addressed in section 1 once again. To show how our system can deal with the knowledge
reasoning issue in this scenario, we define a knowledge structure F as follows:
F = (V, {}, OA , OB ),
687

fiSu, Sattar, Lv, & Zhang

where
 OA = {Alice send msg, Alice recv ack},
 OB = {Bob recv msg, Bob send ack},
 V = OA  OB , and
  is the conjunction of the following three formulas:
Bob recv msg  Alice send msg,
Bob send ack  Bob recv msg,
Alice recv ack  Bob send ack,
Now given a state of F
s=




Alice send msg, 



 Alice recv ack, 


Bob recv msg,




Bob send ack






,

we would like to know whether Alice knows that Bob received the message. Consider the
formula
(
)
Bob recv msg,

(  Bob recv msg).
Bob send ack
From Definition 1, the above formula is simplified as Alice recv ack, which, obviously, is
satisfied in the scenario (F, s), i. e. ,
(F, s) |= Alice recv ack.
Then from Corollary 14, we have
(F, s) |= KA Bob recv msg.
From item 3 of lemma 10, it follows that
(F, s) |= KA Alice send msg
and
(F, s) |= KA Alice recv ack,
which indicates that Alice knows that she sent the message and she knows that she received
acknowledgement from Bob. 2
Given a set of states S of a knowledge structure F and a formula , by (F, S) |= , we
mean that for each s  S, (F, s) |= . The following proposition presents an alternative
way to compute an agents knowledge.
688

fiVariable Forgetting in Reasoning about Knowledge

Proposition 16 Let V be a finite set of variables, F = (V, , O1 ,    , On ) a knowledge

structure with n agents,  a formula over V , and  a formula in LC
n . Suppose that SN Ci
is a strongest necessary condition of  over Oi under , S denotes the set of those states s
of F such that (F, s) |= , and SSN C  denotes the set of those states s such that (F, s) |=
i

SN Ci . Then, for each agent i, we have that
(F, S ) |= Ki  iff (F, SSN C  ) |= .
i

Proof: Let S1 be the set of all states s satisfying (F, s) |= (V  Oi )(  ). Because
 |= SN Ci  (V  Oi )(  ), we have S1 = SSN C  . Also it is easy to see that for state s
i

of F, s  S1 iff there is a state s0 of F such that s0 |=  and s  Oi = s0  Oi . Therefore we
have (F, S ) |= Ki  iff S1  {s | (F, s) |= }. This leads to (F, S ) |= Ki  iff (F, S1 ) |= 
iff (F, SSN C  ) |= . 2
i

The intuitive meaning behind Proposition 16 is that if all we know about the current
state is , then all we know about agent is knowledge (or agent is observations) is the
strongest necessary condition of  over Oi .
The following proposition provides a method to determined whether a formula with the
nested depth of knowledge operators (like Ki1    Kik , where  is a propositional formula)
is always true in those states, where a given proposition formula  is true.
Proposition 17 Let V be a finite set of variables, F = (V, {}, O1 ,    , On ) a knowledge
structure with n agents,  and  two formulas over V , and S denotes the set of states s
of F such that (F, s) |= . Then, for each group of agents i1 ,    , ik , we have (F, S ) |=
Ki1    Kik  holds iff
|=   k  
where k is defined inductively as follows:
1 = (V  Oi1 )(  );
and for each j < k,
j+1 = (V  Oij+1 )(  j ).
Proof: We show this proposition by induction on the nested depth of knowledge operations. The base case is implied directly by Proposition 16. Assume that the claim holds for
those cases with nested depth k, we want to show it also holds when the nested depth is
k + 1, i. e. ,
(F, S ) |= Ki1    Kik+1  iff |=   k+1  .
By Proposition 16, we have
(F, S ) |= Ki1    Kik+1  iff (F, S1 ) |= Ki2    Kik+1 .
By the inductive assumption, we have that
(F, S1 ) |= Ki2    Kik+1  iff |=   k+1  .
689

fiSu, Sattar, Lv, & Zhang

Combining two assertions above, we get
(F, S ) |= Ki1    Kik+1  iff |=   k+1  .
2
When we consider the case where the nested depth of knowledge operators is no more
than 2, we get the following corollary.
Corollary 18 Let V, F, ,  and S be as in Proposition 17. Then, for each agent i and
each agent j, we have
1. (F, S ) |= Ki  holds iff
|= (  (V  Oi )(  ))  ;
2. (F, S ) |= Kj Ki  holds iff
|= (  (V  Oi )(  (V  Oj )(  )))  .
Proof:

Immediately from Proposition 17. 2

As will be illustrated in our analysis of security protocols (i.e. Section 6), the part 2 of
Corollary 18 is useful for verifying protocol specifications with nested knowledge operators.
Given a background knowledge base , when we face the task of testing whether Kj Ki  holds
in those states satisfying , by part 2 of Corollary 18, we can first get 1 = (V Oj )( ),
which is a strongest necessary condition of  over Oj . This is all we know about what agent
j observes from . Then we compute 2 = (V  Oi )(  1 ), i. e. , the strongest necessary
condition of 1 over Oi which is, from the viewpoint of agent j, about what agent i observes.
In this way, the task of checking Kj Ki  is reduced to a task of checking   2  .
The following corollary gives two methods to check the truth of Ki  (where  is a
propositional formula) in all those states where a given formula  is true. One is via the
strongest necessary condition of  and the other is via the weakest sufficient condition of
.
Corollary 19 Let V be a finite set of propositional variables and F = (V, {}, O1 ,    , On )
a knowledge structure with n agents,  and  two formulas over V . Suppose that S denotes
the set of all states s of F such that (F, s) |= , and SN Ci and W SCi are a strongest
necessary condition of  over Oi and a weakest sufficient condition of  over Oi under {}
respectively. Then
1. (F, S ) |= Ki  iff |= (  )  W SCi ; and
2. (F, S ) |= Ki  iff |= (  SN Ci )  .
Proof: The first part of the corollary follows from Theorem 13 and Lemma 10, while the
second part follows immediately by Proposition 16. 2
In our analysis of security protocols, we observe that very often, it seems more efficient
to check an agents knowledge via the second part of Corollary 19 rather than via the first
part. But this may not be always true for some other applications (e.g. see the example of
the muddy children puzzle in the next section).
690

fiVariable Forgetting in Reasoning about Knowledge

4. Common Knowledge
Common knowledge is a special kind of knowledge for a group of agents, which plays an
important role in reasoning about knowledge (Fagin et al., 1995). A group of agents 
commonly know  when all the agents in  know , they all know that they know , they
all know that they all know that they know , and so on ad infinitum. We recall that
common knowledge can be characterized in terms of Kripke structures. Given a Kripke
structure M = (W, , K1 ,    , Kn ), a group  of agents commonly know  ( or in modal
logic language, C  is true ) in a world w iff  is true in all worlds w0 such that (w, w0 )  C ,
S
where C denotes the transitive closure of i Ki .
In this section, we generalize the concept of weakest sufficient and strongest necessary
conditions so that they can be used to compute common knowledge.
4.1 Generalized Weakest Sufficient and Strongest Necessary Conditions
The following gives a generalized notion of weakest sufficient conditions and strongest necessary conditions.
Definition 20 Given a set of formulas  over V as a background knowledge base. Let 
be a formula over V , and V a nonempty set of subsets of V .
 A formula  is called V-definable under  (or simply called V-definable if there is no
confusion in the context), if for each P  V, there is a formula P over P such that
 |=   P .
 A formula  is called a V-sufficient condition of  under  if it is V-definable and
 |=   . It is called a weakest V-sufficient condition of  under  if it is a
V-sufficient condition of  under , and for any other V-sufficient condition 0 of 
under , we have  |= 0  .
 Similarly, formula  is called a V-necessary condition of  under  if it is V-definable
and  |=   . It is called a strongest V-necessary condition of  under  if it is a
V-necessary condition of  under , and for any other V-necessary condition 0 of 
under , we have  |=   0 .
We notice that the notion of V-definability introduced here is a simple elaboration of the
notion of V-definability as given in the work of Lang and Marquis (1998):  is V-definable
under  iff  is V -definable under  for each V  V. Moreover, it is easy to see that the
formulas implied by  or inconsistent with it are exactly the formulas -definable under ,
and that definability exhibits a monotonicity property: if  is V -definable under , then 
is V 0 -definable under  for each superset V 0 of V (Lang & Marquis, 1998). Observe also
that  is V -definable under  iff  is V -definable under , and this extends trivially to
V-definability.
The following lemma says that the notions of weakest V-sufficient conditions and strongest
V-necessary ones are dual to each other.
Lemma 21 Given a set of formulas  over V as a background knowledge base, and V a
set of subsets of V . Let  and  be formulas over V . Then, we have that  is a weakest
691

fiSu, Sattar, Lv, & Zhang

V-sufficient condition of  under  iff  is a strongest V-necessary condition of  under
.
Proof:

Straightforward by the duality between WSCs and SNCs. 2

To give some intuition and motivation of the above definition, let us consider the following example.
Example 22: Imagine that there are two babies, say Marry and Peter, playing with a
dog. Suppose the propositions The dog is moderately satisfied (denoted by m, for short)
and The dog is full(f ) are understandable to Marry, and the propositions The dog is
hungry (h) and The dog is unhappy(u) are understandable to Peter.
Let  = {h  u, (m  f ), (m  f )  h}, V1 = {m, f }, V2 = {h, u}, and V = {V1 , V2 }.
We will show that
1. h is V-definable under ;
2. h is a weakest V-sufficient condition of u under ; and
3. h is a strongest V-necessary condition of u under .
The first claim is easy to check by the definition. The last two claims follow immediately if
we can prove that all the V-definable propositions under  are f alse, true, h and h (up
to logical equivalence under ). There are 8 propositions over V1 up to logical equivalence.
The 8 propositions are: true, f alse, m, m, f, f, m  f, m  f . Similarly, there are 8
propositions over V2 up to logical equivalence under , i.e., true, f alse, h, h, u, u, h 
u, h  u. However, we can find, between the two classes of propositions, only 4 pairs of
equivalence relations under , i.e.,  |= true  true,  |= f alse  f alse,  |= (m  f ) 
h,  |= (m  f )  h. Therefore, all the V-definable propositions under  are f alse,
true, h and h (up to logical equivalence under ). 2
Example 23: Now we recall the background knowledge CS about the communication
scenario between Alice and Bob in the introduction section. CS is the set of the following
three formulas:
Bob recv msg  Alice send msg
Bob send ack  Bob recv msg
Alice recv ack  Bob send ack
Let
OA = {Alice send msg, Alice recv ack},
OB = {Bob recv msg, Bob send ack},
VAB = {OA , OB }.
Clearly, if a formula  is logically implied by CS or inconsistent with CS , then  is
VAB -definable under CS . Moreover, as in Example 22, we are able to check that there
are no VAB -definable formulas other than those implied by CS or inconsistent with CS .
Therefore, given a formula , a weakest VAB -sufficient condition of  under CS is implied
by CS if CS |= , or inconsistent with CS . 2
692

fiVariable Forgetting in Reasoning about Knowledge

Let  be a set of formulas, V a set of propositional variables, and V a set of subsets
of V . The following proposition gives the existence of weakest V-sufficient and strongest
V-necessary conditions. For a given formula  over V , a weakest V-sufficient condition 1 of
 and a strongest V-necessary condition 2 of  can be obtained in the proposition. Indeed,
the set of assignments satisfying 1 and that of assignments satisfying 2 can be given in
terms of relation EV .
Proposition 24 Given a finite set V of propositional variables, a set  of formulas over V
as a background knowledge base, a formula  over V , and a set V of subsets of V . Denote by

0
SW
SC the set of assignments s over V such that s |= , and for all assignments s satisfying
0

0

 with (s, s )  EV , s |= . Also denote by SSN C the set of assignments s over V such that
s |= , and there exists an s0 such that s0 |= , s0 |=  and (s, s0 )  EV . Then, the following
two points hold.

 If a formula is satisfied exactly by those assignments in SW
SC , then the formula is a
weakest V-sufficient condition of  under ; and

 If a formula is satisfied exactly by those assignments in SSN
C , then the formula is a
strongest V-necessary condition of  under .

Proof: We first prove the former point, and then show the other by Lemma 21. Let 1

be a propositional formula over V such that, for all assignments s, s |= 1 iff s  SW
SC .


Then, for every assignment s  SW SC , we have s |=  because (s, s)  EV . Thus, 1 |= .
We remark that for arbitrarily given formula  over V and assignment s over V , s |=
(V  P ) iff for all assignments s0 over V such that s  P = s0  P , we have s0 |= .
To prove that 1 is V-definable, we show that, for each P  V, 1 |= (V  P )1 , which
implies that 1 is equivalent to the formula (V  P )1 over P . To prove 1 |= (V  P )1 ,

0
in a semantical way, it suffices to show that, for every assignment s  SW
SC and s |= , if
0
0

0
s  P = s  P , then s  SW SC . Let s and s be given as above and suppose s  P = s0  P .
Then, (s, s0 )  EV . Given an assignment t such that t |= , if (s0 , t)  EV , then (s, t)  EV

by (s, s0 )  EV . Thus, s0  SW
SC . This proves that 1 is V-definable.
Now we show that 1 is a weakest V-sufficient condition under . Suppose  is a Vdefinable and sufficient condition of  under , we want to prove that  |=   1 . The
semantical argument of such a proof is as follows. Let s be an assignment with s |= 

0
0
and , we must show that s  SW
SC , i.e., for every assignment s with s |=  such that
0

0
0
(s, s )  EV , s |= . Because  |=   , it suffices to show that s |= . By the condition
(s, s0 )  EV , there is a finite sequence of assignments s0 ,    , sk such that sj |=  with s0 = s
and sk = s0 , and for every j < k, (sj , sj+1 )  EV . By the V-definability of , we know that
for every j < k, sj |=  implies sj+1 |= . Thus, we have s0 |=  by induction.
Now we prove the second point of this proposition by Lemma 21. Let 2 be a proposi
tional formula over V such that, for all assignments s, s |= 2 iff s  SSN
C . Let  be the
conjunction of formulas in . Then, s |= 2   iff for all assignments s0 with s0 |=  such
that sEV s0 , we have s0 |= . Thus, by the first point of this proposition, we have that
2   is a weakest V-sufficient condition of . Thus, 2   and hence 2 is a strongest
V-necessary condition of  according to Lemma 21. 2
The above proposition can be thought of as a semantical characterization of weakest
V-sufficient and strongest V-necessary conditions.
693

fiSu, Sattar, Lv, & Zhang

4.2 Characterizations with Least and Greatest Fixed Points
We investigate the computation of the weakest V-sufficient and strongest V-necessary conditions by using the notions of a least and a greatest fixed points of an operator, which is
introduced as follows. Let V be a set of propositional variables, and  be an operator (or a
mapping) from the set of propositional formulas over V to the set of propositional formulas
over V . We say a  is a fixed point of , if |= ()  . We say a 0 is a greatest fixed
point of , if 0 is a fixed point of  and for every fixed point  of , we have |=   0 .
Clearly, any two greatest fixed points are logically equivalent to each other. Thus, we denote
a greatest fixed point of  by gfpZ(Z). Similarly, we say a 0 is a least fixed point of ,
if 0 is a fixed point of  and for every fixed point  of , we have |= 0  . We denote
a least fixed point of  by lfpZ(Z). We say  is monotonic, if for every two formulas 1
and 2 such that |= 1  2 , we have |= (1 )  (2 ). For a finite set V of propositional
variables if  is monotonic, then there exists a least fixed point and a greatest fixed point
(Tarski, 1955).
Theorem 25 Let V be a finite set of variables, F = (V, {}, O1 ,    , On ) a knowledge
structure,  a formula over V ,   {1,    , n}, V = {Oi | i  }. Assume that 1 and
2 are two operators such that
1 (Z) =

^

(x  Oi )(  Z)

i

and
2 (Z) =

_

(x  Oi )(  Z).

i

Then,
 a weakest V -sufficient condition of  under {} is equivalent to gfp Z(  1 (Z));
and
 a strongest V -necessary condition of  under {} is equivalent to lfp Z(  2 (Z)).
 be a weakest V -sufficient condition of  under {}. Note that the
Proof: Let W SC

operator (  1 (Z)) is monotonic and thus there exists a greatest fixed point of it. Let
1 = gfp Z(  1 (Z)). To prove the first point of this theorem, we must show that
  .
 |= W SC
1
   . For this purpose, we only need to prove
We first show that  |= W SC
1
  (   (true)); and
1.  |= W SC
1
  , then  |= W SC   (   ()).
2. for all formulas  on V , if  |= W SC
1

 is a
The first point is trivially true because 1 (true) is equivalent to true and W SC

sufficient condition of  under {}. To show the second point, suppose  |= W SC  .
   . Then,  |=   .
For i  , let i be the formula over Oi such that  |= W SC
i
i
It follows that |= i  (  ) and hence |= i  (V  Oi )(  ) because i does
 
not depend on the variables in (V  Oi ). So, we have that, for all i  ,  |= W SC
(V  Oi )(  ). The conclusion of the second point follows immediately.
 , or  |= (   )  W SC  . It suffices to show
We now show that  |= 1  W SC
1

that   1 is V -sufficient condition of  under {}, that is,

694

fiVariable Forgetting in Reasoning about Knowledge

1.   1 is V -definable; and
2.  |= (  1 )  .
By the fact that 1 is a fixed point of the operator (  1 (Z)), we have that
|= 1  ( 

^

(x  Oi )(  1 )).

i

It follows that |= 1  , and hence  |= (  1 )  . To show the other point, for
i  , we need to prove that   1 is equivalent to a formula over Oi . By the above, we
have that 1  (V  Oi )(  1 ). It follows that  |= (  1 )  (V  Oi )(  1 ),
and hence
 |= (  1 )  (V  Oi )(  1 )
because |= (V  Oi )(  1 )  (  1 ) holds trivially. Thus (  1 ) is equivalent
under  to (V  Oi )(  1 ), which is over Oi . This completes the first point of the
conclusion of the theorem.
We now show the second point of this theorem by using the first point and Lemma 21.
 be a strongest V -necessary condition of  under {}. By Lemma 21,
Let SN C


SN C is a weakest V -sufficient condition of  under {}. Thus, by the first point
 is equivalent to gfp Z(   (Z)) under . Hence, SN C  is
of this theorem, SN C
1

equivalent to gfp Z(  1 (Z)) under . However, gfp Z(  1 (Z)) is logically
equivalent to lfp Z((  1 (Z))), which is in turn equivalent to lfp Z(  2 (Z)). This
completes the second point of the theorem. 2
4.3 Common Knowledge as Weakest V-sufficient Conditions
Given a set  of agents and a family V of observable variable sets of these agents, we
investigate the relationship between common knowledge and the weakest V -sufficient and
strongest V -necessary conditions.
Theorem 26 Let V be a finite set of variables, F = (V, , O1 ,    , On ) a knowledge struc and SN C 
ture,   {1,    , n}, V = {Oi | i  },  a formula over V , and W SC

a weakest V -sufficient condition and a strongest V -necessary condition of  under 
respectively. Then, for every state s of F,

(F, s) |= C   W SC

and

(F, s) |= C   SN C
.
 , by
Proof: We only show the first part of this theorem, i.e., (F, s) |= C   W SC
 is a sufficient
which and Lemma 21 we can get the other part immediately. Because W SC

condition of , we have that  |= W SC  . Let  be the conjunction of all formulas
  ), which leads to (F, s) |= C W SC   C  (by
in , we have that |=   (W SC



 is V -definable, we have, by point 4 of Lemma 10,
point 6 of Lemma 10). Because W SC

  C W SC  . Hence, (F, s) |= W SC   C .
(F, s) |= W SC





695

fiSu, Sattar, Lv, & Zhang

 , we consider the formula  in the
To show the other direction (F, s) |= C   W SC
1
proof of Theorem 25, i.e., the greatest fixed point of the operator

(Z) =  

^

(V  Oi )(  Z).

i
 by Theorem 25, it suffices to show (F, s) |=
Because we already have (F, s) |= 1  W SC
C   1 . Because the greatest fixed point 1 of the operator  can be obtained by a
finite iteration of the operator with the starting point (true), we only need to prove that

1. F |= C   (true); and
2. for an arbitrary propositional formula  over V , if F |= C   , then F |= C  
().
The first point is trivially true because (true) is equivalent to . To prove the second,
suppose F |= C   . Then, for each i  , F |= Ki (C   ). Thus, we have that
F |= C   Ki  by points 5 and 7 of Lemma 10. Hence, F |= C   (V  Oi )(  )
V
(by Corollary 14). It follows that F |= C   i (V  Oi )(  ) and hence F |=
C   (). We thus get F |= C   1 . This completes the proof. 2
Proposition 27 Given V , F, , V ,  as defined in Theorem 26. Let  be a formula

. Denote by S the
over V . Assume that a strongest V -necessary condition of  is SN C
set of those states s of F such that (F, s) |= , and by SSN C  the set of those states s such



. Then, we have
that (F, s) |= SN C

(F, S ) |= C  iff (F, SSN C  ) |= .


Proof: Let S1 be the set of all states s such that there is a state s0 with s0 |=  and
(s0 , s)  V . We have that (F, S ) |= C  iff for every s  S1 , (F, s) |= . This leads
to (F, S ) |= C  iff (F, S1 ) |= . On the other hand, by Proposition 24, we have that
S1 = SSN C  . Then the conclusion of the proposition follows immediately. 2


Note that, in Proposition 27, if  is a propositional formula, we have that (F, S ) |= C 

iff  |= SN C
 . Moreover, by Theorem 26, we have (F, S ) |= C  iff  |=  

 is a weakest V -sufficient of .
W SC , where W SC


5. Adding Public Announcement Operator
There is a recent trend of extending epistemic logic with dynamic operators so that the evolution of knowledge can be expressed. The most basic such extension is public announcement
logic (PAL), which is obtained by adding an operator for truthful public announcements.
The original version of PAL was proposed by Plaza (1989). In this section, we show that
public announcement operator can be conveniently dealt with via our notion of knowledge
structure.
696

fiVariable Forgetting in Reasoning about Knowledge

5.1 Public Announcement Logic
Given a set of agents A = {1, . . . , n} and a set V of propositional variables. The language
of public announcement logic (P ALn ) is inductively defined as
 ::= p||  |Ki |C |[]
where p  V , i  A and   A.
In other words, P ALn is obtained from epistemic logic LC
n (V ) by adding public announcement operator [] for each formula . Formula [] means that after public announcement of , formula  is true.
We now give the semantics of public announcement logic under Kripke model. Given a
Kripke structure M = (W, , K1 , . . . , Kn ), the semantics of the new operators is defined as
follows.
M, w |= [] iff M, w |=  implies M | , w |= , where M | is a Kripke structure such
that M | = (W 0 ,  0 , K10 , . . . , Kn0 ) and
 W 0 = {w  W |M, w |= },
  0 (w0 )(p) = (w0 )(p) for each w0  W 0 and each p  V , and
 Ki0 = Ki  (W 0  W 0 ) for each i  A.
There are some sentences that become false immediately after the announcement of
them. Consider, for example, the sentence p is true but was not commonly known to be
true . By the announcement of the sentence all agents learn that p and therefore p is
commonly known. This can be modelled in public announcement logic by valid formula
[], where  = p  C p. To see its validity, let (M, w) be an arbitrary situation. If
M, w |= ,then M, w |= p, which implies that M | , w |= C p, and therefore M | , w |= .
5.2 Semantics under Knowledge Structure
The semantics of public announcement logic can be conveniently characterized by our notion
of knowledge structure. We define the satisfaction relationship |= between a scenario (F, s)
and a formula in P ALn . We need only consider those formulas of the form []; other cases
are the same as in Definition 9.
Let V be a finite set of propositional variables and F = (, V, O1 ,    , On ). The semantics
definition for the new operators is as follows. First, let F| be the knowledge structure
({}, V, O1 ,    , On ), where  is a propositional formula on V such that (F, s) |=  iff s
satisfies . As V is a finite set, such a propositional formula  always exists.
Then, we set that (F, s) |= [] iff (F, s) |=  implies that (F| , s) |= .
We remark that if formula  is equivalent to propositional one 0 in knowledge structure
F, i.e., F |=   0 for some propositional formula 0 , then we can simply define F| as
(  {0 }, V, O1 ,    , On ).
The following proposition indicates that the semantics of public announcement logic
under knowledge structure coincides with that under Kripke model.

697

fiSu, Sattar, Lv, & Zhang

Proposition 28 (1) Let V be a finite set of propositional variables and F = (, V, O1 ,    , On ).
For every state s of F and every formula   P ALn , we have that (F, s) |=  iff the situation (M (F), s) |= . (2) For a finite S5n Kripke structure M and possible world w in
M , there is a knowledge structure FM and a state sw of F such that, for every formula
  P ALn , we have that (FM , sw ) |=  iff (M, w) |= .
Proof: (1) Let us proceed by induction on the structure of formula . We consider only
the case that  is of the form []; other cases are straightforward by the definitions.
By the definition, we have that (F, s) |= [] iff (F, s) |=  implies that (F| , s) |= .
Thus, by the inductive assumption, we have that (F, s) |= [] iff (M (F), s) |=  implies
that (M (F| ), s) |= . We want to show that (F, s) |= [] iff (M (F), s) |= []. It suffices
to show that M (F| ) equals M (F)| because (M (F), s) |= [] iff (M (F), s) |=  implies
that (M (F)| , s) |= .
First, the set of possible states of M (F| ) equals to the set of those states s0 of F with
(F, s0 ) |= . By the inductive assumption, (F, s0 ) |=  iff (M (F), s0 ) |= . Thus, the set
of possible states of M (F| ) equals to the set of those states s0 of F with (M (F), s0 ) |= ,
hence equals to the set of possible states of M (F)| . Second, we have that for each s0 of F
with (M (F), s0 ) |= ,  M (F| ) (s0 ) = s0 and  M (F )| (s0 ) =  M (F ) (s0 ) = s0 . Hence  M (F | ) =
 M (F )| . Finally, for all states s1 and s2 of F with (M (F), s1 ) |=  and (M (F), s2 ) |= ,
M (F| )
M (F )
we have that (s1 , s2 )  Ki
iff (s1 , s2 )  Ki
iff s1  Oi = s2  Oi . Moreover,
M (F )|
M (F | )
M (F )|
. This completes the
(s1 , s2 )  Ki
iff s1  Oi = s2  Oi . Therefore, Ki
= Ki
proof for M (F| ) = M (F)| .
(2) Suppose M = (W0 , 0 , R1 ,    , Rn ), where W0 is a finite set and R1 ,    , Rn are
equivalence relations. We assume also that the set of propositional variables is V0 .
Let O1 ,    , On be sets of new propositional variables such that
1. O1 ,    , On are finite and pairwise disjoint; and
2. for each i (0 < i  n), the number of all subsets of Oi is not less than that of all
equivalence classes of Ri .
By the latter condition, there is, for each i, a function gi : W0 7 2Oi such that for all
w1 , w2  W0 , gi (w1 ) and gi (w2 ) are the same subset of Oi iff w1 and w2 are in the same
equivalence class of Ri .
S
Let V = V0  0<in Oi . We define a function g : W0 7 2V as follows. For each possible
world w in W0 ,
[
g(w) = {v  V | (w)(v) = true} 
gi (w).
0<in

The following two claims hold:
C1 For all w1 , w2  W0 , and i (0 < i  n), we have that g(w1 )  Oi = g(w2 )  Oi iff
w1 Ri w2 .
C2 For all w  W0 and v  V0 , we have that v  g(w) iff (w)(v) = true.
For any W  W0 , let
W = { |  is over V, and g(w) |=  for all w  W }.
698

fiVariable Forgetting in Reasoning about Knowledge

We then get a knowledge structure
FW = (V, W , O1 ,    , On ).
We now show that following claim:
C3 For every s  V , s is a state of FW iff s = g(w) for some w  W.
The if part of claim C3 is easy to prove. If s = g(w0 ) for some w0  W , then by the
definition of W , we have that g(w0 ) |= W and hence g(w0 ) is a state of FM . To show the
only if part, assume that for every w  W , s 6= g(w). Then, for every w  W , there exists
V
w over V such that s |= w but g(w) |= w . Therefore, s |= wW w . Moreover, we have
W
W
that, for every w0  W , g(w0 ) |= wW w , and hence wW w  W . Consequently,
we have that s 6|= W and hence s is not a state of FW .
To complete the proof of the second part, it suffices to show, for every   P ALn , that
(FW , g(w)) |=  iff (M |W , w) |= , where M |W is a Kripke structure such that M | =
(W, , R10 , . . . , Rn0 ) and
 (w)(p) = 0 (w)(p) for each w  W and each p  V0 , and
 Ri0 = Ri  (W 0  W 0 ) for each i with 0 < i  n.
With claims C1, C2 and C3, we can do so by induction on . Again, we consider only
the case that  is of the form []; other cases can be dealt with in the same way as the
proof of Proposition 12.
We first show that knowledge structure FW | is equivalent to FW 0 , where
W 0 = {w0  W | MW , w |= }.
As the two knowledge structures have the same set V of propositional variables and, for
each agent i, the same set Oi of observable variables to agent i, we need only to prove that
they have the same set of states. An assignment s on V is a state of FW | iff s is a state of
FW and FW , s |= . Thus, by claim C3, s is a state of FW | iff s = g(w0 ) for some w0  W
with FW , g(w0 ) |= . On the other hand, we have, by claim C3 again, that assignment s is
a state of FW 0 iff s = g(w0 ) for some w0  W 0 , i.e., w0  W and MW , w0 |= . However, by
the induction assumption, FW , g(w0 ) |=  iff MW , w0 |= . Therefore, knowledge structures
FW | and FW 0 have the same set of states.
To show (FW , g(w)) |= [] iff (M |W , w) |= [], we have, by the induction assumption, that (FW , g(w)) |=  iff (M |W , w) |= . Also, by the claim we just proved
above, we have that (FW | , g(w)) |=  iff (FW 0 , g(w)) |= . By the induction assumption again, (FW 0 , g(w)) |=  iff MW 0 , w |= . By the definition of W 0 , we have that
MW | , w |= . Hence, (FW | , g(w)) |=  iff MW | , w |= . Therefore, by the semantics
of the announcement operators in Kripke structure and knowledge structure, we have that
(FW , g(w)) |= [] iff (M |W , w) |= []. 2
The above proposition is a generalization of Propositions 11 and 12 to PALn , which
shows that the satisfiability issue for a formula in the language of multi-agent S5 with
the announcement operators is the same whatever satisfiability is meant w.r.t. a standard
Kripke structure or w.r.t. a knowledge structure.
Notice that, for every formula in P ALn , we can get an equivalent propositional formula.
More specifically, we have the following:
699

fiSu, Sattar, Lv, & Zhang

Remark 29 Let V be a finite set of propositional variables and F = ({}, V, O1 ,    , On ).
Given a formula   P ALn , we define a propositional formula be by induction on the
structure of :
 If  is a propositional formula, then be = .
 b  e = be  be .
 bKi e = (V  Oi )(  be ).
 Let   {1,    , n}, V = {Oi | i  }. Then
be

bC e = W SC
be

where W SC

is a weakest V -sufficient condition be under .

 b[]e = bebe



Then, for every   P ALn , we have that F |=   be .

6. Complexity Results
We are interested in the following problem: given a knowledge structure F and a formula 
in the language of epistemic logic, whether formula  is realized in structure F. This kind of
problem is called the realization problem. In this section, we examine the inherent difficulty
of the realization problem in terms of computational complexity. In the general case, this
problem is PSPACE-Complete; however, for some interesting subset of the language, it can
be reduced to co-NP.
Let L be some epistemic logic (or language). The realization problem for L is, given a
knowledge structure F and a formula   L, to determine whether F |=  holds.
The realization problem here is closely related to the model checking problem: given an
epistemic formula  and a Kripke structure M , to determine whether M |= . By checking
the definition of Kripke structure semantics for epistemic logic, we can see that the model
checking problem can be solved in polynomial time (with respect to the input size (| M |
+ |  |). We can determine whether a formula  is realized in a knowledge structure F by
first translating knowledge structure F into a Kripke structure M then checking M |= .
However, the resulting algorithm will be exponential in space. This is because the size of
the corresponding Kripke structure M is exponential with respect to knowledge structure
F.
A number of algorithms for model checking epistemic specifications and the computational complexity of the related realization problems were studied in (van der Meyden,
1998). However, like Kripke structure, the semantics framework they adopt is to list all
global states explicitly. As a result, the size of the input of the concerned decision problem
can be very large.
Proposition 30 The realization problem for Ln is PSPACE-complete.
700

fiVariable Forgetting in Reasoning about Knowledge

Proof: The proposition is of two parts: the PSPACE-easiness and the PSPACE-hardness.
The PSPACE-easiness part means that there is an algorithm that determines in polynomial
space whether an epistemic formula   Ln is realized in a knowledge structure F. The
PSPACE-completeness indicates that there is a PSPACE-hard problem, say the satisfiability
problem for quantified propositional formulas (QBF) (Stockmeyer & Meyer, 1973), can be
effectively reduced to the realization problem we consider.
It is not difficult to see the PSPACE-easiness. Given a knowledge structure and epistemic
formula , by Corollary 14, we can replace knowledge modalities by propositional quantifiers
in formula . So, the problem of whether  is realized in F is reduced to determine
whether a quantified Boolean formulas is valid. The latter can be done in polynomial space
(Stockmeyer & Meyer, 1973).
As for the PSPACE-hardness, it suffices to show that for every QBF formula
p1 q2 p2 q3    pm1 qm A(p1 , q2 , p2 , q3    , pm1 , qm ),
we can construct a knowledge structure F such that
` p1 q2 p2 q3    pm1 qm A(p1 , q2 , p2    , pm1 , qm )
iff
F |= d1  d2  (K1 K2 )m1 (dm  A(p1 , q2 , p2 , q3    , pm1 , qm )).
Let F = (V, {}, O1 , O2 ), where
1. V = {c}  {d1 ,    , dm }  {d01 ,    , d0m }  {p1 ,    , pm }  {q1 ,    , qm }
2.  is the conjunction of the following formulas
(a)

^

(dj+1  dj )  (d0j+1  d0j )

j<m

(b)


^


^

dj  dj+1 

j<m

(pi  qi )

i6=j

(c)

^

c

(dj  d0j )

j<m+1

(d)



c   (dm1  dm )  d0m 

^
j<m1

3. O1 = {c}  {d1 ,    , dm }  {q1 ,    , qm }
4. O2 = {d01 ,    , d0m }  {p1 ,    , pm }
701







(dj  dj+1 )  (d0j+1  d0j+2 ) 

fiSu, Sattar, Lv, & Zhang

In our picture, we have only two agents: agents 1 and 2. We assign every state an
integer number, called the depth of the state for convenience. For every j, dj expresses
that the depth of the state is at least j. Propositions d1 ,    , dm are observable to agent
1, but not to agent 2. Nevertheless, agent 2 can observe d01 ,    , d0m , which are closely
related to d1 ,    , dm . The formula in item 2c indicates that d01 ,    , d0m are the same as
d1 ,    , dm if c holds, while the formula in item 2d says that, if c does not hold, the depth
expressed by d1 ,    , dm is less than that by d01 ,    , d0m and the difference is 1. The formula
in item 2b implies that, under the condition that the depth of the state is exactly j, only
pj is unobservable to agent 1 and only qj is unobservable to agent 2.
In order to show that
` p1 q2 p2 q3    pm1 qm A(p1 , q2 , p2    , pm1 , qm )
implies
F |= d1  d2  (K1 K2 )m1 (dm  A(p1 , q2 , p2 , q3    , pm1 , qm )),
it suffices to prove that, for every j  m and propositional formula  over p1 ,    , pm ,
q1 ,    , q m ,
F |= dj  dj+1  pj qj+1   K1 K2 (dj+1  dj+2  )
To do so, we need only to show that
F |= dj  dj+1  pj   K1 (dj  dj+1  )
and
F |= dj  dj+1  qj+1   K2 (dj+1  dj+2  ).
As for the other direction, we notice that, for each l < m  1,
F |= d1  d2  (K1 K2 )l dl+2 .
We also notice that, for each 1 < m0  m,
F |= K1 K2 dm0  dm0 1
and
F |= dm0 1  dm0  K1 K2 (dm0  )  pm0 1 qm0 .
By applying the above three claims repeatedly, we can obtain that
F |= d1  d2  (K1 K2 )m1 (dm  )  p1 q2 p2 q3    pm1 qm .
Therefore, if
F |= d1  d2  (K1 K2 )m1 (dm  )
then we have that p1 q2 p2 q3    pm1 qm  is satisfiable in F because so is d1  d2 .
However, as the QBF formula p1 q2 p2 q3    pm1 qm  does not contain any free variable, we immediately conclude that the QBF formula is valid from that QBF formula is
satisfiable in F. 2
702

fiVariable Forgetting in Reasoning about Knowledge

By Remark 29, we can see that, for the language of formulas in P ALn without common
knowledge operators, the realization problem can be reduced to the problem of validness
problem of quantified Boolean formulas, and hence is PSPACE-complete by Proposition 30.
We conjecture that the realization problem is also PSPACE-complete for LC
n and P ALn .
Proposition 30 indicates that the realization problem in the general case is hard for a
computer to solve. Thus, it is interesting to give some special cases with lower computational
complexity. Let L+K
be the fragment of positive formulas in Ln . It consists of those formulas
n
such that the negation can be applied only to propositional formulas and the modalities are
restricted to K1 ,    , Kn . For instance, formula K1 K2 pK1 K2 p (where p is a propositional
formula) belongs to L+K
n , but formula K1 K2 p  K1 K2 p does not.
The sublanguage L+K
is interesting in that it is sufficient to represent most important
n
security properties for security protocols. Moreover, as shown in the following proposition,
the complexity of the realization problem for L+K
is co-NP-complete.
n
Proposition 31 The realization problem for L+K
is co-NP-complete.
n
Proof: It is well-known that the validity problem for propositional formulas is co-NPcomplete. We can easily get the co-NP-hardness of the realization problem for L+K
n , because
the validity problem for propositional formulas can be reduced to the realization problem
for propositional formulas (considering the case where background knowledge base is a
tautology).
is in co-NP, we show it can
On the other hand, to show the realization problem for L+K
n
be reduced to the validity problem of propositional formulas. Given a knowledge structure
F and formula  in L+K
n , we will translate  into a propositional formula kkF (which will
be define below), so that  is realized in F iff   kkF is valid, where  is the background
knowledge base of knowledge structure F.
Suppose F = (V, {}, O1 ,    , On ). For every subformula Ki  of , we introduce a set
Vi of new propositional variables such that | Vi |=| V  Oi |.
The propositional translation kkF is inductively given as follows.
1. If  is a propositional formula, then kkF = .
2. If  is of the conjunction form 1  2 , then
kkF = k1 kF  k2 kF .
3. If  is of the disjunction form 1  2 , then
kkF = k1 kF  k2 kF .
4. If  is of the form Ki , then
kkF = (  kkF )(

V  Oi
),
Vi

i
where (  kkF )( V VO
i ) is the formula obtained from (  kkF ) by replacing


variables in V  Oi by the new ones in Vi .
703

fiSu, Sattar, Lv, & Zhang

The idea behind the above translation is that we first translate formula  into a quantified
propositional formula, where all the quantifiers are universal ones, and then eliminate those
universal quantifiers by introducing new variables.
Let V be the set of new variables in kkF . To show the correctness of the translation,
it suffices to show that F |=   V kkF .
We prove this claim by induction on .
 It is trivial, if  is a propositional formula.
 If  is of the form 1  2 , the claim can be obtained immediately by the induction
assumption.
 If  is of the form 1  2 , we have that V (k1 kF  k2 kF ) is logically equivalent
to V1 k1 kF  V2 k2 kF , as the variables in V1 do not appear in V2 k2 kF and
those in V2 do not in V1 k1 kF . Thus, the claim holds by the induction assumption.
 Finally, if  is of the form Ki , then
kkF = (  kkF )(

V  Oi
).
Vi

i
Therefore, V = V Vi and V kkF is logically equivalent to (  Vi V kkF )( V VO
i ).


Thus, by the induction assumption, we have that
F |= V kkF  (  Vi (

V  Oi
)
Vi

and hence
F |= V kkF  (  (V  Oi )).
Therefore, we have F |= V kkF  Ki . 2
Proposition 31 implies that, for an arbitrary formula  in L+K
and a knowledge structure
n
F with background knowledge base ,
F |=  iff   kkF is unsatisfiable.
Thus, we can solve the realization problem for formulas in L+K
by using a propositional
n
satisfiability solver.

7. A Case Study: the Muddy Children Puzzle
In this section, we demonstrate how our framework can be applied to practical problems by
using the example of the muddy children puzzle.
704

fiVariable Forgetting in Reasoning about Knowledge

7.1 Muddy Children Puzzle
The muddy children puzzle is a well-known variant of the wise men puzzle. The story goes
as follows (Fagin et al., 1995): Imagine n children playing together. Some of the children,
say k of them, get mud on their foreheads. Each can see the mud on others but not on
his/her own forehead. Along comes the father, who says, at least one of you has mud on
your forehead. The father then asks the following question, over and over: Does any of
you know whether you have mud on your own forehead?
Assuming that all children are perceptive, intelligent, truthful, and they answer simultaneously, what we want to show is that the first (k  1) times the father asks the question,
they will say No but the k th time the children with muddy foreheads will all answer Yes.
7.2 Modeling the Muddy Children Puzzle
To model the muddy children puzzle, let mi be a propositional variable, which means that
child i is muddy (i < n). Denote by V the set {mi | i < n}. Suppose the assignment
s0 = {mi | i < k} represents the actual state: child 0,   , child k  1 have mud on their
foreheads; and the other children have not. This can be captured by the scenario (F0 , s0 ),
where F0 = (V, 0 , O0 ,    , On1 ) with
 V = {mi | i < n};
 0 = ;
 and Oi = V  {mi } for each i < n.
V

Let  = i<n Ki mi , which indicates that every child does not know whether he has
mud on his own forehead. For convenience, we introduce, for all natural number l, the
notations []l  so that []0  =  and []l+1  = [][]l . The properties we want to show
is then formally expressed in P ALn :
W

 [

W

 [

j
i<n mi ][] 

for every 0  j < k  1, and

k1 V
i<n mi ][]
i<k

Ki mi .

W

Formula [ i<n mi ][]j  means that the children will all say No for the j + 1th time the
father asks the question. In particular, when j = 0, the condition 0  j < k  1 is simplified
W
W
as k > 1; and the resulting formula [ i<n mi ] says that after the father announces i<n mi
W
V
every child says No. Formula [ i<n mi ][]k1 i<k Ki mi indicates that the k th time the
children with muddy foreheads will all answer Yes.
Therefore, what we want to prove is that


(F0 , s0 ) |= 


^

[

_





mi ][]j   [

0j<k1 i<n

_

i<n

mi ][]k1

^

K i mi  .

i<k

To check the above, we basically follow the definition of P AL semantics under knowledge
structure. During the checking process, a series Fj (0 < j  k) of knowledge structures are
constructed so that F1 = F0 |W mi and, for every j (0 < j < k), Fj+1 = Fj | .
i<n

705

fiSu, Sattar, Lv, & Zhang

Figure 1: Performances of the two algorithms for the muddy children puzzle
Specifically, we have that, for each step j  k, we get
Fj = (V, j , O0 ,    , On1 )
where Oi = V  {mi } for each i < n, and j is defined as follows:
W

 At step 1: 1 = {

i<n mi }.

V

 At step j + 1: Let b = i<n mi (j  mi ). As for each i < n, Fj |=nKi m
oi 
b
b
mi (j  mi ), we have that Fj |=    . Thus, we may set j+1 = j   .
Therefore, it suffices to verify, for 0 < j < k and i < n, (Fj , s0 ) |= Ki mi , and for i < k,
(Fk , s0 ) |= Ki mi .
7.3 Experimental Results
Our framework of knowledge structure has been implemented by using the BDD library
(CUDD) developed by Fabio Somenzi at Colorado University. Notice that BDD-based
QBF solvers for satisfiability problems are not among the best solvers nowadays. However,
in the experiments here we need to compute and represent a serial of Boolean functions
(say j ), which are not decision problems and can not be solved by a general QBF solver.
To check agents knowledge, we implemented two different algorithms in terms of Part
1 and 2 of Corollary 19 in Section 3, respectively. Algorithm 1, which is based on part
1 of Corollary 19, seems much more efficient than Algorithm 2, which is based on part 2
of Corollary 19, for this particular example. The reason is as follows. It is clear that the
main task of both algorithms is to check whether (Fj , s0 ) |= Ki mi . However, Algorithm 1s
method is to compute s0 |= mi (j  mi ), while Algorithm 2 is to compute |= mi (j 
s0 )  mi . Now the main reason why Algorithm 1 is much more efficient for this particular
i
problem is clear: mi (j  mi ) is simply equivalent to j ( f m
alse ). Assuming half of the
children are muddy, Fig. 1 gives the performances for a Pentium IV PC at 2.4GHz, with
512RAM. In the figure, the x-axis is for the number of children, and the y-axis for the CPU
run time in seconds.
706

fiVariable Forgetting in Reasoning about Knowledge

The muddy children puzzle as a famous benchmark problem of reasoning about knowledge can be resolved by both proof-theoretic and semantical approaches (Baltag et al., 1998;
Gerbrandy, 1999; Lomuscio, 1999). Proof-theoretic approaches depend on efficient provers
for multi-modal logics; and semantical ones may suffer from the state-explosion problem.
Our approach is essentially a semantic one, but we give a syntactical and compact way
to represent Kripke structures by using knowledge structures, and hence may avoid the
state-explosion problem to some extent.

8. Application to Verification of Security Protocols
In this section, we apply our knowledge model to security protocol verification. Security
protocols that set up credits of the parties and deal with the distribution of cryptographic
keys are essential in communication over vulnerable networks. Authentication plays a key
role in security protocols. Subtle bugs that lead to attack are often found when the protocols
have been used for many years. This presents a challenge of how to prove the correctness
of a security protocol. Formal methods are introduced to establish and prove whether a
secure protocol satisfies a certain authentication specification.
8.1 Background on Authentication Protocols
Authentication protocols aim to coordinate the activity of different parties (usually referred
to as principals) over a network. They generally consist of a sequence of message exchanges
whose format is fixed in advance and must be conformed to. Usually, a principal can take
part into a protocol run in different ways, as the initiator or the responder ; we often call
the principal has different roles. Very often a principal can take part into several protocol
runs simultaneously with different roles.
The designers of authentication protocols must have the conscious in mind that the
message may be intercepted and someone with malicious intention can impersonate an
honest principal. One of the key issues in authentication is to ensure the confidentiality, that
is, to prevent private information from being disclosed to unauthorized entities. Another
issue is to avoid intruder impersonating other principals. In general, a principal should
ensure that the message he receives was created recently and sent by the principal who
claims to have sent it.
Cryptography is a fundamental element in authentication. A message transmitted over
a channel without any cryptographic converting is called plaintext. The intention of cryptography is to transform a given message to some form that is unrecognizable by anyone
except the intended receiver. The procedure is called encryption and the corresponding
parameter is known as encryption key. The encoded message is referred to as ciphertext.
The reverse procedure is called decryption and uses the corresponding decryption key. The
symmetric-key cryptography, which is also called secret-key cryptography, uses the same key
for both encryption and decryption. The asymmetric-key cryptography, which is also called
public-key cryptography, uses different keys for encryption and decryption. The one for the
encryption is the public key that is generally available for anyone. Corresponding to the
public key is the private key, which is for the decryption and only owned by one principal.
707

fiSu, Sattar, Lv, & Zhang

8.2 The Dolev-Yao Intruder Model
The standard adversary model for the analysis of security protocols was introduced by
Dolev and Yao in 1983 and is commonly known as Dolev-Yao model (Dolev & Yao, 1983).
According to this model, a set of conservative assumptions are made as follows:
1. Messages are considered as indivisible abstract values instead of sequences of bits.
2. All the messages from one principal to any other principals must pass through the
adversary and the adversary acts as a general router in the communication.
3. The adversary can read, alter and redirect any message.
4. The adversary can only decrypt a message if he has the right keys, and can only
compose new messages from keys and messages that he already possesses.
5. The adversary can not perform any statistical or other cryptanalytic attacks.
Although this model has the drawback of finding implementation dependent attacks, it
simplifies the protocol analysis. It has been proved to be the most powerful modeling of
the adversary (Cervesato, 2001) because it can simulate any other possible attackers.
8.3 The Revised Needham-Schroeder Protocol
As Lowe (1996) pointed out, the Needham-Schroeder protocol has the problem of lacking
the identity of the responder and can be fixed by a small modification. However, it is not
clear if the revised version is correct. Our approach provides a method to automatically
prove the correctness of security protocols instead of just finding bugs as usual analysis
tools do for security protocols.
In the cryptography literature, the revised Needham-Schroeder protocol is described as
follows:
1. A  B: {N a, A}Kb
2. B  A: {B, N a, N b}Ka
3. A  B: {N b}Kb
where A  B : M is a notation for A sends B the message M  or B receives the message
M from A. The notation {M }K means the encryption of M with the key K. Also, A, B
denote the principal identifiers; and Ka, Kb indicate, respectively, As and Bs public keys.
Moreover, N a and N b are the nonces which are newly generated unguessable values by A
and B, respectively, to guarantee the freshness of messages.
Two informal goals or specifications of the protocol are A knows that B knows A said
N a and N a is fresh, and B knows that A knows B said N b and N b is fresh .
To analyze the protocol, we introduce A and B local histories for the protocol: If A
plays the role of the initiator in the protocol, and assumes that B be the responsor, then
As local history is that
1. A said {N a, A}KbA
708

fiVariable Forgetting in Reasoning about Knowledge

2. A sees {B A , N a, N bA }Ka
3. A said {N bA }KbA
where A said M  means that A sent the message M , or other message containing M ;
A sees M  indicates that A receives M or got M by some received messages; B A is the
responsor of the protocol from As local view; KbA and N bA are, from As local view, the
responsors public key and nonce, respectively.
If B plays the role of the responsor in the protocol, and assumes A be the initiator, then
As local history is that
1. B sees {N aB , AB }Kb
2. B said {B, N aB , N b}Ka
3. B sees {N b}Kb
where AB is the initiator of the protocol from Bs local observations; KaB and N aB are,
from Bs local view, the initiators public key and nonce, respectively.
The main point of our analysis is that if an agent is involved in the protocol, then the
agents real observations should be compatible with the so-called local history. For example,
if A is the initiator of the protocol, and A sees {B, N aB , N b}Ka , then according to As local
history for the protocol we have that A assumes that B is the responsor of the protocol,
the responsors nonce is N b, and from the responsors view, the initiators nonce is N a (see
the 4th formula of the background knowledge  below).
Let us see how our framework of reasoning about knowledge can be applied to this
protocol.
The variable set VRN S consists of the following atoms:
 f resh(N a): Nonce N a is fresh.
 f resh(N b): Nonce N b is fresh.
 role(Init, A): A plays the role of the initiator of the protocol.
 role(Resp, B): B plays the role of the responder of the protocol.
 RespA = B: A assumes that the responder of the protocol is B.
 InitB = A: B assumes that the initiator of the protocol is A.
 N aB = N a: B assumes that the partners nonce in the execution of the protocol is
N a.
 N bA = N b: A assumes that the partners nonce in the execution of the protocol is
N b.
 said(B, N a): B said N a by sending a message containing N a.
 said(A, N b): A said N b.
709

fiSu, Sattar, Lv, & Zhang

 sees(B, {N a, A}Kb ): B sees {N a, A}Kb (possibly by decrypting the messages received.)
 sees(A, {B, N aB , N b}Ka ): A sees {B, N aB , N b}Ka .
The background knowledge RN S consists of the following formulas:




sees(B, {N a, A}Kb )


1.  said(B, N a)
  role(Resp, B)
f resh(N a)




sees(A, {B, N aB , N b}Ka )


2.  said(A, N b)
  role(Init, A)
f resh(N b)



3. 




4. 



5.


6.
7.

role(Resp, B)
sees(B, {N a, A}Kb )
said(B, N a)
f resh(N a)









InitB = A
N aB = N a

!




role(Init, A)
RespA = B
sees(A, {B, N aB , N b}Ka ) 
   N aB = N a 

said(A, N b)
N bA = N b
f resh(N b)
!

!

role(Init, A)
RespA = B
role(Resp, B)
InitB = A

sees(B, {N a, A}Kb )
said(B, N a)








sees(A, {B, N aB , N b}Ka )
said(A, N b)



(role(Init, A)  f resh(N a))
(role(Resp, B)  f resh(N b))

Notice that the first two formulas are required for the rationality of the agents A and B.
The other formulas in  can be obtained automatically by some fixed set of meta rules. We
obtain the third and fourth formulas by comparing their local history for the protocols to
the conditions appearing in the formulas. To get the fifth formula informally, consider As
local history under the conditions role(Init, A) and RespA = B, which should be that
1. A said {N a, A}Kb
2. A sees {B, N a, N bA }Ka
3. A said {N bA }Kb .
According to As local history, A sees the nonce N a generated by A itself. Because N a is
only said in the message {N a, A}Kb , thus B, who has the inverse key of Kb, must see this
message and said N a. Similarly, we can see that the sixth formula holds. The last formula
follows immediately by the definition of the protocol.
710

fiVariable Forgetting in Reasoning about Knowledge

The set OA of the observable variables to A is
{f resh(N a), role(Init, A), RespA = B}.
The set OB of the observable variables to B is
{f resh(N b), role(Resp, B), InitB = A}.
Now consider the knowledge structure
F = (VRN S , RN S , OA , OB ).
Let SpecA be the formal specification:





!
f resh(N a)
said(A, N a)


 role(Init, A)   KA KB
f resh(N a)
RespA = B

and SpecB be the formal specification:





!
f resh(N b)
said(B, N b)


.
 role(Resp, B)   KB KA
f resh(N b)
InitB = A

It is easy to show that, for all states s of F,
(F, s) |= SpecA  SpecB
as desired.
We should mention that, in the original Needham-Schroeder protocol (Needham &
Schroeder, 1978), the second message is B  A: {N a, N b}Ka instead of B  A: {B, N a, N b}Ka .
Therefore, the fourth formula in  would be changed to



role(Init, A)


 sees(A, {N aB , N b}Ka ) 
N aB = N a


 said(A, N b)

N bA = N b
f resh(N b)

Thus, RespA = B does not necessarily hold under the condition
role(Init, A)  sees(A, {N aB , N b}Ka )  said(A, N b)  f resh(N b).
This is why the specifications SpecA and SpecB do not hold for the original NeedhamSchroeder protocol.
8.4 Discussion
BAN logic (Burrows, Abadi, & Needham, 1990) is one of the most successful logical tools
to reason about security protocols. However, the semantics of BAN is always arguable, and
it is not clear under what assumption the rules of BAN logic is sound and complete. This
711

fiSu, Sattar, Lv, & Zhang

motivated the research of seeking more adequate frameworks (models). Providing a modeltheoretic semantics for BAN logic has been a central idea in the development of BAN-like
logics such as AT (Abadi & Tuttle, 1991) and SVO (Syversion & van Oorschot, 1996). The
advantage of our approach is that we use knowledge structures as semantic models to verify
the correctness of epistemic goals for security protocols.
An important problem is that, given a security protocol, where and how the corresponding knowledge structure comes from. To get the knowledge structure corresponding to a
security protocol, we have developed a semantic model, and the background knowledge base
of the corresponding knowledge structure consists of those formulas valid in the semantic
model. Moreover, we can generate the background knowledge systematically. The ongoing
work is to implement our approach into a promising automatic security protocol verifier.

9. Related Work
There are a number of approaches dealing with the concept of variable forgetting or eliminations of middle terms (Boole, 1854) in several contexts. The notion of variable forgetting
was formally defined in propositional and first order logics by Lin and Reiter (1994). In
recent years, theories of forgetting under answer set programming semantics were proposed
(Zhang & Foo, 2006; Eiter & Wang, 2008). Forgetting was also generalized to description
logics (Kontchakov, Wolter, & Zakharyaschev, 2008; Wang, Wang, Topor, & Pan, 2008;
Kontchakov, Walther, & Wolter, 2009).
In the context of epistemic logic, the notion of forgetting was studied in a number of
ways. Baral and Zhang (2006) treated knowledge forgetting as a special form of update
with the effect K  K: after knowledge forgetting , the agent would neither know
 nor . Ditmarsch, Herzig, Lang and Marquis (2008) proposed a dynamic epistemic
logic with an epistemic operator K and a dynamic modal operator [F g(p)] so that formula
[F g(p)] means that after the agent forgets his knowledge about p,  is true. (Zhang &
Zhou, 2008) modeled forgetting via bisimulation invariance except for the forgotten variable.
This notion of variable forgetting is closely related to quantified modal logics, where the
existential variable quantification can be modeled via bisimulation invariance except for the
quantified variable (Engelhardt et al., 2003).
The notion of variable forgetting has various applications in knowledge representation
and reasoning. For example, Weber (1986) applied it to updating propositional knowledge
bases. Lang and Marquis (2002) used it for merging a set of knowledge bases when simply
taking their union may result in inconsistency. The notion of variable forgetting is also
closely related to that of formula-variable independence, because the result of forgetting the
set of variables V in a formula  can be defined as the strongest consequence of  being
independent from V (Lang et al., 2003). More recently, Liu and Lakemeyer (2009) applied
the notion of forgetting into the situation calculus, and obtained some interesting results
about the first-order definability and computability of progression for local-effect actions.

10. Conclusion
The main contribution of this paper is as follows. First, we have investigated knowledge
reasoning within a simple framework called knowledge structure, which consists of a global
712

fiVariable Forgetting in Reasoning about Knowledge

knowledge base and a set of observable variables for each agent. The notion of knowledge
structure can be used as a semantic model for a multi-agent logic of knowledge and common
knowledge. In this model, the computation of knowledge and common knowledge can be
reduced to the operation of variable forgetting; moreover, an objective formula  is known
by agent i at state s when any of its weakest sufficient condition on Oi holds at state s.
Second, to capture the notion of common knowledge in our framework, we have generalized the notion of weakest sufficient conditions and obtained, for a set V of sets of propositional variables, the notion of the weakest V-sufficient conditions. Given a set  of agents
and a family V of observable variable sets of these agents, we have shown that an objective
formula  is common knowledge for agents in  iff the weakest {Oi | i  }-sufficient of 
holds. Also, we have shown that public announcement operator can be conveniently dealt
with via our notion of knowledge structure.
Third, the relationship between S5 Kripke structure and knowledge structure has been
explored. Specifically, the satisfiability issue for a formula in the language of multi-agent
S5 with public announcement operator is the same as what satisfiability is meant w.r.t. a
standard Kripke structure or w.r.t. a knowledge structure.
Fourth, we have examined the computational complexity of the problem whether a
formula  is realized in structure F. In the general case, this problem is PSPACE-hard;
however, there are some interesting subcases in which it can be reduced to co-NP.
Finally, we have shown the strength of the concept of knowledge structure from the practical side by some empirical results about the satisfiability problem for knowledge structures
based on the instances of the muddy children puzzle, since even for the smallest instances
considered in the experiments generating the corresponding S5 Kripke structure would be
out of reach. we have also discussed the automated analysis and verification of the corrected
Needham-Schroeder protocol via knowledge structures.
Our work presented in this paper can be further extended in several directions. First,
we will investigate whether our knowledge structures can be extended and used as a basis
for knowledge based programming (Fagin et al., 1995). Secondly, in our current framework
of knowledge structures, we have not considered the issue of only knowing which has been
extensively studied in other knowledge reasoning models (Halpern & Lakemeyer, 1996;
van der Hock, Jaspars, & Thijsse, 2003; Levesque, 1990). It will be an interesting topic of
how our knowledge model handles only knowing in reasoning about knowledge. Thirdly,
the notions and methods in this work can be extended to investigate the extension of the
variable forgetting operator to multi-agent logics of beliefs. Finally, recent research has
shown that knowledge update has many important applications in reasoning about actions
and plans and dynamic modeling of multi-agent systems (Zhang, 2003). A first step in
this direction (in mono-agent S5) can be found in the work of Herzig, Lang and Marquis
(2003). Baral and Zhang have proposed a general model for performing knowledge update
based on the standard single agent S5 modal logic (Baral & Zhang, 2001). We believe that
their work can be extended to multi-agent modal logics by using the knowledge structure
defined in this paper and therefore to develop a more general system for knowledge update.
Along this direction, an interesting research issue is to explore the underlying relationship
between knowledge forgetting - a specific type of knowledge update, and variable forgetting
as addressed in this paper.
713

fiSu, Sattar, Lv, & Zhang

Acknowledgments
The authors thank Ron van der Meyden, Fangzheng Lin and the anonymous reviewers for
their valuable comments on an earlier version of this paper. This work was partially supported by the Australian Research Council grant DP0452628, the National Basic Research
973 Program grants (Nos. 2010CB328103, 2009CB320701 and 2005CB321902), and National Natural Science Foundation of China grants (Nos. 60725207 and 60763004). This
paper is the revised and extended version of a paper which appeared in Proceedings of KR
2004 (Su, Lv, & Zhang, 2004)

References
Abadi, M., & Tuttle, M. (1991). A semantics for a logic of authentication. In Proceedings
of the Tenth Annual ACM Symposium on Principles of Distributed Computing, pp.
201216.
Baltag, A., Moss, L., & Solecki, S. (1998). The logic of public announcements and common
knowledge for distributed applications (extended abstract). In Proceedings of TARKVII, pp. 4356.
Baral, C., & Zhang, Y. (2001). On the semantics of knowledge update. In Proceedings
of the 17th International Joint Conference on Artificial Intelligence (IJCAI-01), pp.
97102.
Baral, C., & Zhang, Y. (2006). Knowledge updates: semantic and complexity issues. Artificial Intelligence, 164, 209243.
Boole, G. (1854). An Investigation of the Laws of Thought. Walton, London.
Burrows, M., Abadi, M., & Needham, R. M. (1990). A logic of authentication. ACM
Transactions on Computer Systems, 8 (1).
Cervesato, I. (2001). The Dolev-Yao intruder is the most powerful attacker. In Proc. 16th
Annual Int. Symp on Logic in Computer Science.
Dolev, D., & Yao, A. (1983). On the security of public-key protocols. Communications of
the ACM, 29 (8), 198208.
Eiter, T., & Wang, K. (2008). Semantic forgetting in answer set programming. Artificial
Intelligence, 172, 16441672.
Engelhardt, K., van der Meyden, R., & Moses, Y. (1998). Knowledge and the logic of local
propositions. In Proceedings of TARK VII.
Engelhardt, K., van der Meyden, R., & Su, K. (2003). Modal logics with a hierarchy of local
propositional quantifiers. In Advance in Modal Logic, Vol. 4, pp. 930. Kings College
Publications.
Fagin, R., Halpern, J., Moses, Y., & Vardi, M. (1995). Reasoning about knowledge. MIT
Press, Cambridge, MA.
Gerbrandy, J. (1999). Bisimulation on Plant Kripke. Ph.D thesis, Institute for Logic,
Language and Computation, University of Amsterdam.
714

fiVariable Forgetting in Reasoning about Knowledge

Halpern, J., & Moses, Y. (1992). A guide to completeness and complexity for modal logics
of knowledge and belief. Artificial Intelligence, 54, 319379.
Halpern, J., & Zuck, L. (1992). A little knowledge goes a long way: Simple knowledge based
derivations and correctness proofs for a family of protocols. Journal of the ACM,
39 (3), 449478.
Halpern, J. Y., & Lakemeyer, G. (1996). Multi-agent only knowing. In Proceedings of TARK
VI, pp. 251265.
Herzig, A., Lang, J., & Marquis, P. (2003). Action representation and partially observable
planning using epistemic logic. In Proceedings of IJCAI-03, pp. 10671072.
Hintikka, J. (1962). Knowledge and Belief. Cornell University Press, Ithaca, NY.
Kontchakov, R., Walther, D., & Wolter, F. (2009). Forgetting and uniform interpolation in
large-scale description logic terminologies. In Proc. of IJCAI09.
Kontchakov, R., Wolter, F., & Zakharyaschev, M. (2008). Can you tell the difference
between dl-lite ontologies. In Proc. of KR08.
Kripke, S. (1963). A semantical analysis of modal logic. i: Normal modal propositional
calculi. Z. Math. Logik Grundl. Math., 9, 6796.
Lang, J., Liberatore, P., & Marquis, P. (2003). Propositional independence: Formulavariable independence and forgetting. Journal of Artificial Intelligence Research, 18,
391443.
Lang, J., & Marquis, P. (1998). Complexity results for independence and definability. In
Proc. the 6th International Conference on Knowledge Representation and Reasoning,
pp. 356367.
Lang, J., & Marquis, P. (2002). Resolving inconsistencies by variable forgetting. In Proc.
of KR2002, pp. 239250.
Levesque, H. (1990). All I know: a study in autoepistemic logic. Artificial Intelligence, 42,
263309.
Lin, F. (2001). On the strongest necessary and weakest sufficient conditions. Artificial
Intelligence, 128, 143159.
Lin, F., & Reiter, R. (1994). Forget it!. In Greiner, R., & Subramanian, D. (Eds.), Working
Notes of AAAI Fall Symposium on Relevance, pp. 154159, New Orleans.
Liu, Y., & Lakemeyer, G. (2009). On first-order definability and computability of progression
for local-effect actions and beyond. In Proc. of IJCAI09.
Lomuscio, A. (1999). Knowledge Sharing among Ideal Agents. Ph.D thesis, School of
Computer Science, University of Birmingham.
Lowe, G. (1996). Breaking and fixing the Needham-Schroeder public-key protocol using
FDR. In Margaria, & Steffen (Eds.), Tools and Algorithms for the Construction and
Analysis of Systems, Vol 1055 of Lecture Notes in Computer Science, pp. 147166.
Springer Verlag.
Needham, R. M., & Schroeder, M. D. (1978). Using encryption for authentication in large
networks of computers. Communication of the ACM, 21 (12), 993999.
715

fiSu, Sattar, Lv, & Zhang

Plaza, J. (1989). Logics of public communications. In Proceedings of the 4th International
Symposium on Methodologies for Intelligent Systems, pp. 201216346.
Stockmeyer, L., & Meyer, A. (1973). Word problem requiring exponential time: prelimnary
report. In Proc. 5th ACM Symp. on Theory of Computing, pp. 19.
Su, K., Lv, G., & Zhang, Y. (2004). Reasoing about knowledge by variable forgetting. In
Proceedings of KR-04, pp. 576586.
Syversion, P. F., & van Oorschot, P. (1996). An unified cryptographic protocol logic. Tech.
rep. NRL Publication 5540-227, Naval Research Lab.
Tarski, A. (1955). A lattice-theoretical fixpoint theorem ans its applications. Pacific J.
Math., 5, 285309.
van Benthem, J. (2001). Logics for information update. In Proceedings of TARK-VIII, pp.
5158.
van der Hock, W., Jaspars, J., & Thijsse, E. (2003). Theories of knowledge and ignorance.
In S. Rahman, J. Symons, D. G., & van Bendegem, J. (Eds.), Logic, Epistemology and
the Unity of Science. Kluwer.
van der Hoek, W., & Wooldridge, M. (2002). Model checking knowledge and time. In Proc.
19th Workshop on SPIN (Model Checking Software), pp. 95111, Grenoble.
van der Meyden, R. (1998). Common knowledge and update in finite environments. Information and Computation, 140 (2), 115157.
van Ditmarsch, H., Herzig, A., Lang, J., & Marquis, P. (2008). Introspective forgetting. In
Wobcke, W., & Zhang, M. (Eds.), AI 2008: Advances in Artificial Intelligence, Vol.
5360.
van Ditmarsch, H., van der Hoek, W., & Kooi, B. (2005a). Dynamic epistemic logic with
assignment. In Proceedings of AAMAS-05, pp. 141148.
van Ditmarsch, H., van der Hoek, W., & Kooi, B. (2005b). Public announcements and belief
expansion. In Advances in Modal Logic, Volume 5, pp. 335346.
Wang, Z., R., Wang, K., Topor, R., & Pan, J. (2008). Forgetting in dl-lite. In Proc. of
ESWC08.
Weber, A. (1986). Updating propositional formulas. In Proc. First Conference on Expert
Database Systems, pp. 487500.
Zhang, Y. (2003). Minimal change and maximal coherence for epistemic logic program
updates. In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI-03), pp. 112117.
Zhang, Y., & Foo, N. (2006). Solving logic program conflict through strong and weak
forgettings. Artificial Intelligence, 170, 739778.
Zhang, Y., & Zhou, Y. (2008). Properties of knowledge forgetting.. In Proceedings of the
20th International Workshop on Non-monoronic Reasoning ( NMR08), pp. 6875.

716

fiJournal of Artificial Intelligence Research 35 (2009) 775-811

Submitted 03/09; published 08/09

Enhancing QA Systems with Complex Temporal
Question Processing Capabilities
Estela Saquete
Jose L. Vicedo
Patricio Martnez-Barco
Rafael Munoz
Hector Llorens

stela@dlsi.ua.es
vicedo@dlsi.ua.es
patricio@dlsi.ua.es
rafael@dlsi.ua.es
hllorens@dlsi.ua.es

Natural Language Processing and Information System Group
Department of Software and Computing Systems
University of Alicante
Apartado de Correos 99, E-03080 Alicante, Spain

Abstract
This paper presents a multilayered architecture that enhances the capabilities of current
QA systems and allows different types of complex questions or queries to be processed.
The answers to these questions need to be gathered from factual information scattered
throughout different documents. Specifically, we designed a specialized layer to process the
different types of temporal questions. Complex temporal questions are first decomposed
into simple questions, according to the temporal relations expressed in the original question.
In the same way, the answers to the resulting simple questions are recomposed, fulfilling
the temporal restrictions of the original complex question. A novel aspect of this approach
resides in the decomposition which uses a minimal quantity of resources, with the final
aim of obtaining a portable platform that is easily extensible to other languages. In this
paper we also present a methodology for evaluation of the decomposition of the questions
as well as the ability of the implemented temporal layer to perform at a multilingual level.
The temporal layer was first performed for English, then evaluated and compared with:
a) a general purpose QA system (F-measure 65.47% for QA plus English temporal layer
vs. 38.01% for the general QA system), and b) a well-known QA system. Much better
results were obtained for temporal questions with the multilayered system. This system was
therefore extended to Spanish and very good results were again obtained in the evaluation
(F-measure 40.36% for QA plus Spanish temporal layer vs. 22.94% for the general QA
system).

1. Introduction
Nowadays, it is a fact that there is a huge amount of digital information available (mainly
in textual form) and also a large number of users who want the easiest possible access
to this information. This situation continuously fosters research on the development of
information systems that make it possible to analyze, locate, manage, access and process
all this information automatically. Commonly, these systems are referred to as search
engines.
A search engine is especially useful to obtain a specific piece of information without
the need to manually go through all the available documentation related to the search
topic. Search engines are currently evolving towards a new generation of engines capable of
c
2009
AI Access Foundation. All rights reserved.

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

understanding user needs better (the necessity behind every query) and offering specific
services or interfaces, depending on the domain or context. The new generation of search
engines will be able to not only offer a list of ordered web pages, but also discover pieces of
information scattered throughout different information sources or even summaries (Barzilay,
Elhadad, & McKeown, 2002). That is, they will integrate information from text search (web
pages, documents), multimedia search (images, video, audio) and database search (tourist,
biomedicine, etc.) into comprehensible answers to be delivered to users. In addition, they
will correctly process questions formulated in free natural language as opposed to keyword
queries or fixed templates, as in information extraction scenarios (Michelson & Knoblock,
2008). Question answering systems (QA) are one of the best examples of this new generation
of search engines, allowing users to formulate questions in free natural language (NL) and
providing them with exactly the information required, also in NL form.
However, QA is not a mature technology and current systems are mainly focused on the
treatment of questions that require very specific items of data as an answer such as dates,
names of entities or quantities. What is the capital of Brazil? is an example of the so
called factual questions. In this case, the answer is the name of a city.
On the long road towards the next generation systems, the work presented here takes
a new step forward. It defines a layer that, installed on top of current NL-based search
engines or QA systems, enhances their capabilities of processing different types of complex
temporal questions.
The specific case of temporal QA is not a trivial task due to the potential complexity
of temporal questions. Current search engines, such as operational QA systems can deal
with simple factual temporal questions, that is, questions requiring a date as an answer
(When did Bob Marley die?) or questions that involve simple temporal expressions in
their formulation (Who won the U.S. Open in 1999?). Processing these kinds of questions
is usually accomplished by identifying explicit temporal expressions in questions and the
relevant documents that contain these temporal expressions in order to answer the questions.
However, the system described in this paper also processes complex temporal questions.
That is, questions whose complexity is related to the temporal properties of the entities
enquired about and the relative ordering of events mentioned in the question. The following
are examples of these complex temporal questions:
 Who was the spokesman of the Soviet Embassy in Baghdad during the invasion of
Kuwait?
 Is Bill Clinton currently the President of the United States?
The approach we present in this work tries to imitate the temporal reasoning of a human
when solving these types of questions. For example, a person trying to answer the question:
Who was the spokesman of the Soviet Embassy in Baghdad during the invasion of Kuwait?
would proceed as follows:
1. First, the complex question would be decomposed into two simple ones: Who was
the spokesman of the Soviet Embassy in Baghdad? and When did the invasion of
Kuwait occur?.
776

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

2. He/She would look for all the possible answers to the first simple question: Who was
spokesman of the Soviet Embassy in Baghdad?.
3. After that, he/she would look for the answer to the second question: When did the
invasion of Kuwait occur?
4. Finally, he/she would give as a final answer one of the answers for the first question (if
there is any) that have temporal compatibility with the answer to the second question.
In this case, the answer to the first question must be temporally compatible with the
period of dates associated with the invasion of Kuwait (during).
Therefore, a logical approach for the treatment of complex questions should be based on the
decomposition of these questions into simple ones that can be resolved using conventional
QA systems. Finally, answers to simple questions, fulfilling the temporal constraints, would
be used to construct the answer to the original complex question.
This study presents the development and evaluation of a tool that processes complex
NL-temporal questions for information retrieval purposes. Apart from the fact that the tool
is capable of processing this type of complex questions, it has the following advantages:
 It can be incorporated as a layer on top of one or more already existing QA systems.
 It can contain and integrate into an answer different data obtained from different types
of information sources (web pages, databases, documents, etc.) that are retrieved
using different types of search engines (QA, NLIDB1 , etc.).
 The layer is a portable platform since the language-dependent features of the process
are easily extended to other languages.
 All the information necessary to process the complex question is obtained directly
from it, no extra auxiliary questions or annotations are required.
In this paper, our main aim is to demonstrate how the temporal layer can improve
a general purpose QA system when questions are not simple or factual, but of a higher
degree of complexity. Specifically, we implemented the temporal layer in order to deal
with questions with different levels of temporal complexity. Furthermore, the proposed
treatment of questions uses a minimum quantity of linguistic resources in order to obtain a
very portable platform, which can be easily extended to different languages.
The paper has been structured in the following way: first of all, section 2 briefly introduces the current situation of temporal reasoning and QA; section 3 depicts our proposal
for classifying temporal questions into four groups, depending on the features of the question; section 4 explains the concept of a Multilayered QA system; section 5 describes the
different modules of the temporal layer in more detail; and in section 6, decomposition of
the question and the Multilayered QA system are evaluated for English. The portability of
the system to other languages is then described, and the procedure repeated and evaluated
for Spanish. Finally, some conclusions and comments on future work will be made.
1. Natural Language Interfaces to Databases

777

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

2. Background
As explained in the introduction, one of the aims of this paper is to process complex questions. Complex questions in general have been dealt with in previous studies using different
approaches to decompose them. Harabagiu, Lacatusu and Hickl (2006) presented a procedure in which a question produces lots of queries that are semantically related to the original
question, with the main aim of obtaining more information about the answers. This approach requires a significant amount of semantic information. The question decomposition
presented by Katz, Borchardt and Felshin (2005) involves three decomposition techniques:
a) a syntactic decomposition using linguistic knowledge and language-based descriptions
of resource content, b) a semantic decomposition using domain-motivated explanation patterns and language-based annotations of resource content, and c) a semantic decomposition
of both questions and resource content into lower-level assertions. This approach makes use
of a considerable amount of linguistic knowledge and in order to move to new domains, new
sets of parameterized language-based annotations need to be composed. In addition to these
studies dealing with single focus complex questions, Lin and Lui (2008) propose processing
complex questions with multiple foci by obtaining one subquestion for each focus of the
original question. This approach determines four possible relations between the subquestions derived from the original question. However, the temporal relation is not considered
in this approach.
Apart from complex questions treatment, the motivation for the temporal aspect of this
work is due to the great importance in the question answering field of relating questions
and information to the temporal dimension in order to find a correct answer. Take, for
example, the following two similar questions:
 Who is the president of the USA?
 Who was the president of the USA in 1975?
There is an obvious dependency of answers on time, so in order to obtain the right answer
to these two questions, temporal information needs to be extracted and processed, because
the first question refers to the current president of the USA (the exact point in time when
the question is formulated), whereas the second one refers to the president in 1975. When
the temporal information is not explicit, the questions are considered complex temporal
questions.
The importance of the temporal dimension of data in information search processes is
corroborated by the recent interest shown by the major evaluation forums on QA like Text
REtrieval Conference - TREC (2008) and Cross Language Evaluation Forum - CLEF (2008),
see also the works by Voorhees (2002) and Magnini et al. (2005), in including different types
of temporal questions as part of their evaluation benchmarks.
Furthermore, CLEF has explicitly fostered research into complex temporal questions by
organizing a specific pilot task for such questions (Herrera, Penas, & Verdejo, 2005) and
including in CLEF (Magnini et al., 2006) the temporal dimension of questions and answers
as part of its main QA task.
A temporal question can be appropriately processed by: (1) relating the available information to its temporal dimension and (2) adapting the search to link this temporal
information with the information search process.
778

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

Concerning the first task, the analysis of time is a challenging problem, as the needs of
applications based on information extraction techniques expand to include varying degrees
of time stamping (identification and reasoning) of events or expressions within a narrative
or question. Interest in temporal representation and reasoning has been evolving throughout the years and has resulted in a growing number of meetings related to this topic. We
present here, in descending chronological order, the most important ones: TIME (2008) is
an annual symposium on Temporal Representation and Reasoning (Demri & Jensen, 2008),
it involves different areas including Time in Natural Language; TempEval 2007 (Verhagen
et al., 2007) is a workshop held within SemEval-2007 for the evaluation of systems performing Time-Event Temporal Relation Identification; ARTE 2006 is a new workshop focused on
Annotating and Reasoning about Time and Events (Ahn, 2006; Dalli & Wilks, 2006; Mani &
Wellner, 2006) and was part of the relevant conference COLING-ACL (2006) (Pan, Mulkar,
& Hobbs, 2006a); Dagstuhl 2005 was a seminar about annotating, extracting and reasoning
time and events (Katz, Pustejovsky, & Schilder, 2005); TERN (2004) was an international
competition in which different systems that identify and normalize temporal expressions
were evaluated and compared; TANGO 2003 was specialized in developing an appropriate infrastructure for annotation (Pustejovsky & Mani, 2008); LREC (2002) dedicated a
workshop to Annotation Standards for Temporal Information in Natural Language (Mani
& Wilson, 2002; Setzer & Gaizauskas, 2002; Saquete, Martnez-Barco, & Munoz, 2002);
ACL (2001) included the Temporal and Spatial Information Processing workshop (Setzer &
Gaizauskas, 2001; Filatova & Hovy, 2001; Katz & Arosio, 2001; Moia, 2001; Schilder & Habel, 2001; Wilson, Mani, Sundheim, & Ferro, 2001) and finally, COLING (2000), in which
some papers were related to temporal expression identification or temporal databases. It
is important to emphasize that all these meetings led to the development of a standard for
a specification language for events and temporal expressions and their ordering (TimeML,
2008). Nowadays, there is also a growing number of automatic systems extracting temporal
expression information2 , such as: ATEL (2008), Chronos (Negri, 2007), TempEx (2008),
GUTime (Mani & Wilson, 2000a), DANTE (Mazur & Dale, 2007), TimexTag (Ahn, 2006)
and TERSEO (Saquete, Munoz, & Martnez-Barco, 2006).
Regarding the second task, significant progress has been made in temporal analysis applied to IE and QA tasks as presented in the TERQAS workshop (Pustejovsky, 2002; Radev
& Sundheim, 2002). The purpose of the TERQAS workshop was to address the problem of
how to enhance natural language question answering systems to answer temporally-based
questions about the events and entities in news articles. Besides, a temporal question corpus
was developed. As far as we know, one of the first systems that treated temporal information for QA purposes was described by Breck et al. (2000) and it used temporal expression
identification applying the temporal tagger developed by Mani and Wilson (2000b). Another important study related to temporal constraints in question answering is presented by
Prager, Chu-Carroll and Czuba (2004). They presented a method to improve the accuracy
of a QA system by asking auxiliary questions related to the original question whose answers are used to temporally verify and restrict the original answer. This method is called
QA-by-Dossier with Constraints and is very suitable for TREC-style factoid questions, but
it has the inconvenience of requiring the generation of a set of auxiliary questions. Besides,
2. http://timexportal.wikidot.com/systems

779

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

recently, researchers have also focused on other important features in temporal reasoning
for final applications, such as: a) event detection: Evita (Saur, Knippen, Verhagen, &
Pustejovsky, 2005) is an application for recognizing events in natural language texts, and
this recognition is applied to QA, b) event extension: Pan, Mulkar and Hobbs (2006b) describe a method to automatically learn durations from event descriptions, and c) temporal
relations between temporal expressions and events, as described by Lapata and Lascarides
(2006).
However, those strategies that implied a complex temporal processing of the question,
using only information extracted from the original question and a small amount of linguistic
resources for the temporal reasoning were beyond the scope of these investigations.
Our proposal is focused on temporal reasoning for complex temporal questions and so it
is necessary to add a new layer to existing systems, thereby allowing these complex questions
to be processed (Saquete, Martnez-Barco, Munoz, & Vicedo, 2004). The decomposition
performed by the temporal layer is based only on the temporal relation between the events
of the original question, and no other linguistic information is required in the decomposition.
In addition, a system that identifies and normalizes temporal expressions was used as a part
of the processing layer (Negri, Saquete, Martnez-Barco, & Munoz, 2006), taking advantage
of the multilingual feature of this system in order to use it for cross-lingual tasks.
However, not all the temporal questions need to be treated in the same way since they
may have different characteristics, and for this reason, a classification of the different types
of temporal questions is also proposed.

3. Temporal Questions Taxonomy
Before explaining how to answer temporal questions, they must be classified into different
categories since the way to solve them will differ depending on the type of question involved.
The temporality of a question depends on two levels of complexity: a) the number of events
in the question: Questions formed by a single event and whose answers can be found in
a document (simple questions), and questions formed by more than one event that are
temporally related and whose answers could be found in multiple documents (complex
questions), and b) the temporal information appearing in the question, like implicit or
explicit temporal expressions, that needs to be recognized and normalized. The combination
of these two features results in four different types of temporal questions.
Simple Temporal Questions:
Type 1: Single event temporal questions without a temporal expression (TE). These are
questions that require a temporal expression as an answer and do not contain any temporal
expression in their formulation. These questions are formed by a single event and no
temporal reasoning is required, because they are resolved by a QA system directly without
a pre or postprocessing of the question. For example: When did Jordan close the port of
Aqaba to Kuwait?. However, since this taxonomy is a temporal question taxonomy, this
type of basic temporal questions need to be considered.
Type 2: Single event temporal questions with a temporal expression. These are questions
that require a temporal reasoning of the temporal expression contained in the formulation
of the question. There is a single event in the question, but there are one or more temporal
expressions that need to be identified, normalized and annotated. All this temporal infor780

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

mation is necessary to search for the correct answer, due to the fact that it is establishing
temporal constraints for the candidate answers. For example: Who won the 1988 New
Hampshire Republican primary?. Temporal Expression: 1988
Complex Temporal Questions:
Type 3: Multiple event temporal questions with a temporal expression. Questions that
contain more than one event, related by a temporal signal. This signal establishes the order
between the events in the question. Moreover, there are one or more temporal expressions in
the question. These temporal expressions need to be identified, normalized and annotated,
and they establish temporal constraints in the answers to the question. For example: What
did George Bush do after the U.N. Security Council ordered a global embargo on trade with
Iraq in August 90? In this example, the temporal signal is after and the temporal
constraint is between 8/1/1990 and 8/31/1990. This question consists of these two events:
 Event 1: George Bush did something
 Event 2: the U.N. Security Council ordered a global embargo on trade with Iraq
(Temporal constraint: August 1990)
Type 4: Multiple event temporal questions without a temporal expression. Like Type 3,
these questions consist of more than one event, related by a temporal signal, but in this
case, the questions do not contain temporal expressions. The temporal signal establishes
the order between the events in the question. For example: Who was the president of
US when the AARP was founded?. In this example, the temporal signal is when and the
question would be decomposed into:
 Event 1: someone was the president of US
 Event 2: the AARP foundation
How to process each type of question will be explained in detail in the following sections.

4. Architecture of a Multilayered QA System
In order to process special types of questions which are beyond the scope of currently QA
systems, this work proposes a multilayered architecture that increases the functionality of
these QA systems, allowing them to solve any type of complex question. In this work, the
temporal layer has been implemented. Moreover, this architecture enables different layers
to be added to cope with questions that need other kinds of complex processing and are
not temporally oriented, such as script questions (How do I assemble a bicycle?) or
template-based questions (What is the main biographical data of Nelson Mandela?).
Complex questions have in common the need for additional processing of the question
in order to solve it adequately. The architecture presented in this paper enables different
types of complex questions to be dealt with by superposing additional processing layers,
one for each type, on the top of an existing general purpose QA system, as shown in Figure
1. These layers will:
 decompose the question into simple events to generate simple questions (sub-questions)
that are ordered according to the original question,
781

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

 send simple questions to a general purpose QA system,
 receive the answers to the simple questions from the general purpose QA system,
 filter, compare and validate the sub-answers, according to the relation detected between sub-questions, in order to construct the final complex answer.

Complex Question

Complex Answer

INTERFACE
TEMPORAL
QUESTION
LAYER

SCRIPT
QUESTION
LAYER

TEMPLATE
QUESTION
LAYER

Simple Questions

...

Simple Answers
SEARCH ENGINE

Text

Multimedia

Databases

Figure 1: Multi-layered Architecture of a QA system
This architecture has a large number of advantages, of which the following should be
mentioned:
 It allows researchers to use any existing general purpose QA system.
 Since complex questions are processed by a superior layer, it is not necessary to modify
the current QA system when you want to deal with more complex questions. The layer
enhances the capabilities of an existing QA system without changing it in any way.
 Each additional processing layer works independently from the others and only processes the questions accepted by that layer.
 It is possible to have more than one type of QA system working in parallel, each of
them specialized in searching for a specific type of information (text,multimedia,databases).
Next, a layer oriented to processing temporal questions according to the taxonomy shown
in section 3 is presented.
782

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

5. Temporal Layer
The temporal layer proposed here consists of two units, the Question Decomposition Unit
and the Answer Recomposition Unit, which will be superposed over a general purpose QA
system, as shown in Figure 2.
Complex
Question

Complex
Answer
INTERFACE
TEMPORAL LAYER

QUESTION
DECOMPOSITION UNIT

ANSWER
RECOMPOSITION UNIT

TE
tags

TE Identification and
Normalization

Individual Answer
Filtering

Type Identification
Answer Comparison
and Composition

Signal
Question Splitter

Q-Focus

Q-Restriction

Q-Focus
Answers

Q-Rest.
Answer

SEARCH ENGINE

Text

Multimedia

Databases

Figure 2: Architecture of the temporal layer
These components all work together in order to obtain a final answer as follows:
 Question Decomposition Unit is a preprocessing unit which performs three main tasks.
First of all, temporal expressions in the question are identified and normalized. Secondly, following the taxonomy shown in section 3, there are different types of questions
and each type must be treated in a different way. For this reason, the type needs to
be identified. After that, complex questions (Type 3 and 4) are split into simple
ones using the temporal signal as a reference. The first sub-question is defined as the
question focus (Q-Focus) and it specifies the type of information the user needs to
find. The second sub-question is called the question restriction (Q-Restriction) and
the answer to this sub-question establishes the temporal restrictions on the list of
answers to the Q-Focus. The Q-Focus and the Q-Restriction are the input of the QA
system. For example, the question Where did Bill Clinton study before going to Oxford University?, is divided into two sub-questions that are related by the temporal
signal before: Q-Focus: Where did Bill Clinton study? and Q-Restriction:When
did Bill Clinton go to Oxford University?.
783

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

 General purpose QA system. The simple questions generated are processed by a general purpose QA system. Any QA system could be used here (QA systems, Multimedia
search engines or NLIDB). For the example above, a current QA system returns the
following answers:
 Q-Focus Answers:
 Georgetown University (1964-68)
 Oxford University (1968-70)
 Yale Law School (1970-73)
 Q-Restriction Answer: 1968
 Answer Recomposition Unit. This unit constructs the answer to the original question from the answers to the Q-Focus and the Q-Restriction using all the temporal
constraints, such as temporal signals (which are fully explained later) or temporal
expressions, available in the original question. The temporal signal establishes the
appropriate order between the answers to the Q-Focus and the Q-Restriction in the
question. Finally, this unit returns the appropriate answer by analyzing the temporal compatibility between the list of possible Q-Focus answers and the Q-Restriction
answer.
An example of how the temporal layer operates is shown in Figure 3.
Where did Bill Clinton study before going to Oxford University?
Q-Focus

Q-Restriction

Where did Bill Clinton study?

When did Bill Clinton go to
Oxford University?

ANSWERS:
Georgetown University
(1964-1968)
 Oxford University
(1968-1970)
 Yale Law School
(1970-1973)

ANSWER:

Temporal
Signal

1968-1970

<

Temporal Compatible
Answer
Georgetown University

Figure 3: Example of performance of the Temporal Layer
It is important to emphasize that the temporal layer is a language dependent platform
(it uses lexical and syntactic patterns) and English was the language chosen initially to
develop the layer; however, it can be easily extended to other languages, as will be seen in
section 6.3. The units that integrate the temporal layer are described in more detail in the
following sections.
784

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

5.1 Question Decomposition Unit
The main task of this unit, which is divided into three main modules, is the temporal
reasoning of the temporal information of the question and the decomposition of the question
(only required in Type 3 and 4 questions). The temporal expression identification and
normalization module detects and resolves the temporal expressions in the question. The
type identification module classifies the question according to the taxonomy proposed in
section 3. Finally, the question splitter module splits the complex question into simple
ones.
Thus, the output of the Question Decomposition unit consists of:
 two sub-questions (Q-Focus and Q-Restriction), which will be processed by a QA
system in order to obtain an answer for each of them,
 temporal tags, containing concrete dates returned by the TERSEO system (Saquete
et al., 2006), these tags are part of the input of the Answer Recomposition Unit and
they are used by this unit as temporal constraints in order to filter the individual
answers, and
 the temporal signal, which is part of the input of the Answer Recomposition Unit
as well, because this information is needed in order to compose the final answer and
determine the temporal compatibility between the answers to the Q-Focus and the
answer to the Q-Restriction.
The modules of the decomposition unit are fully explained in the following subsections.
5.1.1 Temporal Expression Identification and Normalization
This module uses the TERSEO system (Saquete et al., 2006) to identify, annotate and
normalize temporal expressions in the question.
With this system, implicit and explicit temporal expressions can be annotated. Expressions like 12/06/1975 are explicit, while those like two days before are implicit and
need the location of another complete temporal expression (TE) to be understood. For the
specific purposes of the temporal layer, TERSEO simply returns the text of the temporal
expression in a string and the normalization or resolution value of the temporal expression
using the ISO standard format for concrete dates or periods.
In this work, TERSEO does not use a complete text as input, but only a question. The
temporal tags (TE tag with a value attribute) obtained from the questions are the output
of this module and they are used in the Answer Recomposition Unit in order to filter
the individual answers obtained by the QA system. The TE tag is necessary in order to
determine the temporal compatibility between the answers to the Q-Focus and the answer
to the Q-Restriction. For example, in a question like: Which U.S. ship was attacked by
Israeli forces during the Six Day war in the sixties?, the temporal constraint that must be
fulfilled is: the date of Q-Focus answers should be between 1960-01-01 and 1969-12-31 
(196 in ISO format). This means that only the answers whose dates are within the range
of dates in the question are temporally compatible.
It is very important to emphasize that, initially, the TERSEO was developed for Spanish,
but a platform to automatically extend the system to other languages was developed as
785

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

well. Therefore, the system was evaluated for three different languages: Spanish, English
and Italian. For Spanish the results were 91% precision and 73% recall. The system was
evaluated for English using the TERN (2004) corpus and the results obtained for the Fmeasure were 86% for identification and about 65% for normalization. For the Italian
evaluation, the I-CAB corpus was used. This corpus consists of 525 news documents taken
from the local newspaper LAdige 3 . Ita-TERSEO obtained an F-measure of around 77%
for identification. The results are quite good because the extension to English and Italian
was completely automatic and therefore, also very fast.
The multilingual capabilities of TERSEO are very interesting in various NLP fields, in
particular its application to Crosslingual QA systems, and therefore in the Temporal Layer
as well.
5.1.2 Type Identification
The Type Identification module classifies the question into one of the four types in the
taxonomy proposed above. This identification is necessary because each type of question
produces a different behavior (scenario) in the system. Type 1 and Type 2 questions are
classified as simple, and the answer can be obtained without splitting the original question.
On the other hand, Type 3 and Type 4 questions need to be split into a set of simple
sub-questions. These types of sub-questions are always Type 1, Type 2 or a non-temporal
question, which are considered simple questions.
The question type is established according to the rules in Figure 4. There are four
possibilities: (a) if there is no Temporal Expression and no Temporal Signal, the question
is classified as Type 1 ; (b) if there is no Temporal Expression but a Temporal Signal, the
question is classified as Type 4 ; (c) if there is a Temporal Expression but no Temporal
Signal, the question is classified as Type 2 ; (d) if there is a Temporal Expression and a
Temporal signal, the question is classified as Type 3.
5.1.3 Question Splitter
This task is only necessary when, according to the type identification module, the question
is Type 3 or Type 4. These questions are considered complex questions and need to be
divided into simple ones (Type 1, Type 2 or non-temporal questions). The decomposition
of a complex question is based on the identification of temporal signals, which link simple
events to form complex questions (see Table 1).
As explained before, using the temporal signal as a referent, the two events related by
it will be transformed into two simple questions: Question-Focus (Q-Focus) and QuestionRestriction (Q-Restriction).
The Q-Focus is a question that specifies the information that the user is searching
for. This question is very simple to obtain, because no syntactic changes are required to
construct it, only the question mark must be added. When the Q-Focus is processed by a
QA system, the system will return a list of possible answers.
The Q-Restriction is constructed using the part of the complex question that follows
the temporal signal. This question is always transformed to a When question using a set
3. http://www.adige.it

786

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

QUESTION
(Q)

QUESTION
ANALYSIS

NO

NO

YES

TEMPORAL
EXPRESSION?

YES

NO

TEMPORAL
SIGNAL?

TYPE 1

YES
TEMPORAL
SIGNAL?

TYPE 4

TYPE 2

TYPE 3

Figure 4: Decision tree for Type Identification
of lexical and syntactic patterns defined in the layer. When the Q-Restriction is processed
by a QA system, only one appropriate answer is expected.
In addition, temporal signals denote an ordering between the events being linked. Assuming that F1 is the date associated with the answers to the Q-Focus and F2 is the date
associated with the answer to the Q-Restriction4 , the signal will establish a certain order
between the answers, which is called the ordering key. An example of some ordering keys
are shown in Table 1.
Table 1: Example of signals and ordering keys
SIGNAL
After
When
Before
During
From F2 to F3
About F2  F3
On / in
While
For
At the time of
Since

ORDERING KEY
F1 > F2
F1 = F2
F1 < F2
F2i <= F1 <= F2f
F2 <= F1 <= F3
F2 <= F1 <= F3
F1 = F2
F2i <= F1 <= F2f
F2i <= F1 <= F2f
F1 = F2
F1 > F2

Using the list of answers to the Q-Focus, the answer to the Q-Restriction and the
temporal signal, the Answer Recomposition Unit determines the temporal compatibility
4. F2:Q-Restriction concrete date / [F2i-F2f]:Q-Restriction period dates

787

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

between the answers and composes the final answer to the original complex question. This
process will be fully explained in the following subsection.
5.2 Answer Recomposition Unit
The main task of the Answer Recomposition Unit is to obtain the final answer to the
complex question using all the available inputs of the Decomposition Unit and the answers
obtained from the QA system. The Recomposition Unit is divided into two modules. The
Individual Answer Filtering module filters the possible answers to the Q-Focus, avoiding
the non-temporally compatible ones, and the Answer Comparison and Composition module,
which composes the answer to the original question by using the ordering key established
by the temporal signal.
Once the complex questions have been split by the Decomposition Unit into the Q-Focus
and the Q-Restriction and the answers to these questions have been obtained by a QA
system, the Recomposition Unit determines from the list of all the potential answers to the
Q-Focus which one is compatible with all the temporal constraints obtained in the process:
temporal expressions, temporal signal and answer to the Q-Restriction. The answers to the
Q-Focus that fulfill the temporal constraints will be considered the answer to the initial
complex question.
5.2.1 Individual Answer Filtering
The list of possible answers to the Q-Focus and the answer to the Q-Restriction given by
the QA system are the input of the Individual Answer Filtering module. For a Q-Focus
or Q-Restriction with a temporal expression, it selects only those answers that satisfy the
temporal constraints obtained by the TE Identification and Normalization Unit. The date
of the answer should be temporally compatible with the temporal tag, that is, the date of
the answer must lie within the date values of the tag. If not, it will be rejected. Only the
answers that fulfill the constraints go to the Answer Comparison and Composition module.
5.2.2 Answer Comparison and Composition
Finally, once the answers have been filtered using the signals and the ordering key, the
results for the Q-Focus are compared with the answer to the Q-Restriction in order to
determine if they are temporally compatible. Temporal signals denote the relationship of
order between the date of the answer to the Q-Focus and the date of the answer to the
Q-Restriction.
Only the answers that fulfill the compatibility established by the temporal signal can be
possible answers to the original question. The answer selected is considered by this module
to be the answer to the complex question. Hence, the system is able to solve complex
temporal questions.

6. Evaluation Experiments
The evaluation experiments performed in this paper were done initially for English, and
after porting the system to Spanish, the same evaluation procedure was carried out for this
new language.
788

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

This evaluation has a dual aim: on the one hand, to determine if the Decomposition
Unit is able to process each type of question properly in order to obtain appropriate simple
factual questions that can be answered by any kind of general purpose QA system, and on
the other hand, to show to what extent the general purpose QA system could be improved
when these techniques are applied.
6.1 Test Environment
First of all, a corpus of English questions that contains as many simple and complex temporal questions as possible was necessary. The first idea was to use already existing resources,
such as TREC (2008) and CLEF (2008) question corpora, due to the large number of
questions they contain. Unfortunately, after studying these corpora, they were discarded
because they do not contain complex temporal questions. Thus, using the initial TERQAS
question corpus proposal (Radev & Sundheim, 2002; Pustejovsky, 2002) as a model, a new
question corpus was manually developed collecting questions from a group of volunteers
unacquainted with this work. The instructions given to the volunteers were: 1) answers to
the questions proposed must be found on the Internet, 2) the questions must be constructed
according to the temporal question taxonomy described in Section 3, and 3) the questions
must expect a fact as an answer (factual questions). In the case of complex questions, two
factual questions must be related to a temporal signal5 . This last instruction was necessary
in order to make the evaluation procedure more straightforward since open-ended questions
usually require long answers, which makes them more difficult to judge. In order to have
a balanced corpus, some questions were discarded and finally the corpus developed contains a balanced number (50) of each type of temporal question (Types 1,2,3 and 4), which
resulted in 200 temporal questions for English6 . For the Spanish evaluation, the English
question corpus was manually translated into this language. Therefore, the distribution of
the questions by type is the same as in English.
Once the question corpus for English and Spanish were developed, the following step
was to construct the testbeds for both languages in order to allow for rigorous, transparent
and replicable evaluation tests. The testbed annotation was performed using an XML
schema and was developed by three independent annotators. In the case of doubts or
disagreement, the annotation was reviewed by a referee, who made the final decision. The
interannotator agreement was calculated for every attribute, resulting 100% for all cases
except the temporal signal (98%) due to the complexity of some temporal signals.
In the testbed annotation, every question is annotated with a Q tag, and this tag has
an id attribute that identifies every question. The question string is annotated using the
QUESTION tag. Furthermore, for every question, there are five items that must be annotated:
1. Identification and Normalization of the temporal expressions in the question. The
annotation for this item is done using a TE tag, and its content stores the string text
of the TE. The tag also has an attribute value, which stores the resolution of the
expression using the ISO format,
5. It is important to emphasize that Type 3 questions contain two events and a temporal expression, which
is used as an extra time constraint in the answering procedure, limiting the number of potential answers,
speeding the answering step, and refining the final answer
6. http://gplsi.dlsi.ua.es/corpus/CTQ

789

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

2. the type of question according to the classification proposed in this paper. This type
is annotated using the tag TYPE and it must be a value between 1 and 4. Since the
questions were manually built using the temporal question taxonomy as a reference,
3. the temporal signal. The tag used to annotate this item is called SIGNAL and it stores
the exact string text of the temporal signal of the question,
4. the two possible sub-questions in the case of complex questions (Type 3 and 4): the
first sub-question is annotated using the tag Q-FOCUS and the second using the tag
Q-REST, and,
5. the answer to the complex question: the answer is annotated using an ANSWER tag and
contains the correct answer to the complex question. One example of the annotation
format for a question is:
<Q id="107">
<QUESTION>Who won the best actress Oscar award when James Dean died in the 50s?< /QUESTION>
<TE value="195">the 50s< /TE>
<TYPE>3< /TYPE>
<SIGNAL>when< /SIGNAL>
<Q-FOCUS>Who won the best actress Oscar award?< /Q-FOCUS>
<Q-REST>When did James Dean die in the 1950s?< /Q-REST>
<ANSWER>Anna Magnani< /ANSWER>
< /Q>

In the case of the Decomposition Unit, the following five aspects are evaluated:
 TE Identification and Normalization: are the temporal expressions in the question
correctly detected and normalized?
 Type Identification: is the type of question correctly identified according to the classification presented previously in this paper?
 Signal Detection: are any temporal signals in the question correctly detected?
 Question Splitter: are the complex questions correctly split into simple factual questions, which can be answered by a general purpose QA system?
 DECOMPOSITION UNIT as a whole: has the system correctly undertaken all the
sub-tasks previously defined, since these sub-tasks as a whole compose the decomposition unit?
However, not all the evaluation aspects explained above need to be considered for all the
questions. Table 2 determines if an aspect must be evaluated or ignored for each particular
type of question. The decomposition unit as a whole is only taking into consideration the
evaluated sub-tasks for every question.
Having determined what aspects are evaluated in the decomposition and in what cases
they must be evaluated, depending on the type of question, the next step is to establish
how these aspects are evaluated. For this purpose, the criteria matrix, containing the rules
followed in the evaluation in order to determine when the elements are treated (ACT) and
which of them are correct (CORR), is shown in Table 3.
790

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

Table 2: Aspects evaluated for Decomposition Unit depending on the Q-type
Type
1
2
3
4

TE Id.Norm.

Yes
Yes


Type
Yes
Yes
Yes
Yes

Signal


Yes
Yes

Q Splitter


Yes
Yes

DECOMP.
Yes
Yes
Yes
Yes

Table 3: ACT and CORR criteria matrix for Decomposition Unit evaluation
TE
Ident.Norm.

ACT
The TE is annotated by the system

Type
Signal
Q Splitter

The type is returned by the system
The temporal signal is annotated by the system
Complex Q is divided into two sub-Qs

DECOMP.

All previous aspects ACT

CORR
-Exact agreement with TE tag content
-Exact agreement with value attribute content
within TE tag
Exact agreement with TYPE tag content
Exact agreement with SIGNAL tag content
Sub-Qs agreement of Q-FOCUS and Q-REST tag
in:
-Interrogative particle
-Main verb correctly detected and tensed
-All keywords appear and only keywords from
the original Q, except stopwords
All previous aspect CORR

In the case of QA evaluation, we are using the current CLEF evaluation criteria7
as starting point, determining correct and inexact answers. The use of these evaluation
criteria is possible since our corpus only contains factual questions. Therefore, determining
the correctness of an answer is very straightforward. The other CLEF judgments are not
specified in this evaluation because the measure of incorrectness may be calculated directly
by subtracting the number of correct answers from the total number of questions. In
addition, the unknown judgement is also omitted since two human assessors must evaluate
all the answers. And finally, we do not consider unsupported judgement neither, since our
corpus consisted of data obtained from the Internet, where all correct answers can be found.
The criteria matrix for QA, shown in Table 4, describes the rules followed in the evaluation in order to determine treated (ACT), correct (CORR) and inexact (INE) answers.
Table 4: ACT and CORR criteria matrix for QA system
QA

ACT
An anwer is returned by
the system

CORR (CLEF R)
-Exact agreement with one
of the answers contained in
ANSWER tag content

INE (CLEF X)
The answer contains a correct answer, but it is incomplete or longer
than the minimum amount of information required

For all the evaluations performed in this work, the following measures were used:
 POS:Total number of items
7. http://www.clef-campaign.org/

791

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

 ACT: Number of items treated by the system
 CORR: Number of items properly treated (Correct)(CLEF R)
 PREC: Precision ( CORR
ACT ) percentage of items in the output of the system that are
properly treated
 REC: Recall ( CORR
P OS ) percentage of items treated by the system (CLEF Accuracy)
2

)(P R)
) Combination of precision and recall in a single value.  = 1
 F: ( (1+
( 2 P +R)

 Only for QA evaluation purposes:
1
 MRR: For an ordered list of possible answers of a question is ( CorrectAnswerP
osition ).
The final MRR is the average of every individual MRR obtained.

 INE: Is the number of answers judged inexact by human assessors (CLEF X).
6.2 Evaluation Results
This section presents the results of the decomposition unit and an analysis of its influence
in QA systems for English.
6.2.1 Evaluating the Decomposition Unit for English
In this section, the decomposition unit8 for the processing of simple and complex temporal
questions in English is evaluated, based on the testbed defined previously. In this evaluation,
in addition to the decomposition unit efficiency, some aspects of temporal expressions and
their influence on complex questions were analyzed.
The evaluation results are very good with an F-measure of 89.5%. All the results
are shown in Table 5. In the evaluation, 176 of a total of 200 questions were correctly
preprocessed. Since the decomposition unit not only divides the complex questions but also
determines the type of the question and performs the temporal reasoning if necessary, the
whole set of questions is considered in the global measure of the decomposition unit. It is
obvious that in the case of Type 1 questions the decomposition unit simply determines the
type of question, but we were interested in evaluating the performance of the unit in this
respect.
Table 5: Evaluation of the decomposition unit for English
POS

ACT

CORR

PREC

REC

F

TE Identification and Normalization

100

93

80

86.0%

80.0%

82.9%

Type Identification

200

200

194

97.0%

97.0%

97.0%

Signal Detection

100

100

96

96.0%

96.0%

96.0%

Question Splitter

100

100

92

92.0%

92.0%

92.0%

200

193

176

91.1%

88.0%

89.5%

DECOMPOSITION UNIT

8. http://gplsi.dlsi.ua.es/demos/TQA/

792

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

Next, a detailed analysis of the results for each evaluation aspect is shown (see Appendix
A for detailed error examples):
 Identification and normalization of Temporal Expressions: In this corpus, there were
100 temporal expressions and our system detected 93, of which 80 were correctly
resolved. As we said previously, this module uses the TERSEO system to identify
and normalize the temporal expressions in the question. There were three types of
errors: (1) expressions that were treated by TERSEO as temporal expressions but
were not in fact temporal; (2) expressions that were identified wrongly because: a)
the expression is outside the scope of the TERSEO system, or b) the identification
extent is not exact; and (3) expressions that: a) were normalized wrongly because the
normalization rule in TERSEO was not appropriate for these expressions, or b) were
not normalized because the normalization rule does not exist.
 Type Identification: There were 200 temporal questions in the corpus, all of them were
processed by this module, and 194 were correctly identified according to the taxonomy
proposed in section 3. The errors in this module were due to the fact that some TE
were not detected by TERSEO, as shown in Appendix A. However, this type of error
does not usually affect the question splitting and in most cases the complex question
is split correctly.
 Signal Detection: In the corpus, there were 100 questions that were considered complex (Type 3 and Type 4). Our system was able to treat and recognize correctly the
temporal signal of 96 of these questions. The main error detected in this module arose
when a temporal expression was part of a signal, denoting a complex signal, such as:
EVENT1 a year after EVENT2. This type of complex signal is outside the scope
of the system. The system also fails when a preposition, classified as a signal in the
system, is part of a TE, like during the 18 century and therefore during is wrongly
considered a temporal signal.
 Question Splitter: From this set of 100 complex questions, the system was able
to process and split 92 of them properly. The errors in this unit are due to: a)
wrong signal identification; or b) syntactic problems, obtaining a tensed verb or the
subject of the Q-Focus to construct the Q-Restriction properly. For instance, in the
question Which language was invented when Berliner patented the Gramophone?,
the POSTagger did not identify patented as a past tense verb and the Q-Restriction
was wrongly generated as: When did Berliner patented the Gramophone happen?.
One possible problem that can appear in complex questions, and is not yet treated by
our system, are questions that contain anaphoric co-references. Therefore, when splitting
the complex question into two separate simple questions, the question that contains the
anaphoric co-reference can not be treated directly by a QA system and needs to be processed
by a module that performs anaphora resolution first. For example: In which studies did
Ms. Whitman graduate before she got her MBA? . The Q-Restriction obtained is: When
did she get her MBA?. In this case, she is referring to Ms. Whitman. In our case,
this type of question is outside our scope. However, just by adding a module that adapts
anaphora resolution techniques for dialogs and texts (Palomar et al., 2001; Palomar &
793

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

Martnez-Barco, 2001) to questions, the situation will be solved. Moreover, applying this
module to the question does not affect the decomposition process in any case.
6.2.2 Evaluating the influence of the temporal processing in QA systems
for English
The QA system used for this evaluation is a general purpose one that uses Internet data
as the corpus (Moreda, Llorens, Saquete, & Palomar, 2008a). This is a very simple opendomain QA system, whose main feature is that the Answer Extraction Unit is able to look
for possible answers in two ways: performing a mapping with the type of name entity that
the question requires (NE-based), or with the type of semantic role that the question needs
as an answer (SR-based)9 .
Due to the modularity of the QA system, in this evaluation, only the NE-based answer extraction is used. As a baseline, using a subset of factual questions, extracted from
TREC1999 and TREC2000 that are NE oriented, the authors evaluated the system and
found 87.50% precision, 84% recall, 85.70% F and 87.25% MRR (Moreda, Llorens, Saquete,
& Palomar, 2008b).
The evaluation performed in this work is divided into two experiments:
1. Base QA system evaluation: First the QA system is evaluated without using the
temporal layer.
2. Multilayered QA system evaluation: Then the QA system is evaluated when it performs with the temporal layer.
The main aim of this evaluation is to compare the results of the two experiments and
determine if the temporal layer enhances a general purpose QA system like the one used
in this case. Besides, for both experiments, the 200 temporal question corpus created for
this purpose containing simple (Type 1 and Type 2) and complex (Type 3 and Type 4)
questions is used.
The results obtained by the general purpose QA system without the temporal layer are
shown in Table 6.
Table 6: Evaluation of the QA system for English temporal questions
POS

ACT

CORR

INE

PREC

REC

F

MRR

Type 1

50

50

35

0

70.00%

70.00%

70.00%

77.60%

Type 2

50

45

23

1

51.11%

46.00%

48.42%

48.00%

Type 3

50

8

1

0

12.50%

2.00%

3.45%

3.00%

Type 4

50

18

2

0

11.11%

4.00%

5.88%

5.00%

GLOBAL

200

121

32

1

50.41%

30.50%

38.01%

33.40%

The results obtained by the system enhanced with the temporal layer are shown in Table
7.
9. http://gplsi.dlsi.ua.es/demos/TMQA/

794

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

Table 7: Evaluation of QA system plus temporal layer for English temporal questions
POS

ACT

CORR

INE

PREC

REC

F

MRR

Type 1

50

50

35

0

70.00%

70.00%

70.00%

77.60%

Type 2

50

47

38

1

80.85%

76.00%

78.35%

78.00%

Type 3

50

48

29

2

60.42%

58.00%

59.18%

63.66%

Type 4

50

46

26

2

56.52%

52.00%

54.17%

55.66%

GLOBAL

200

191

128

5

67.02%

64.00%

65.47%

68.73%

As shown in both tables, the QA system enhanced with the temporal layer offers better
results in all measures (72.24% improvement in F and 33.58% error reduction in F). The
most outstanding improvements occur in complex temporal questions, due to the extra
reasoning that the temporal layer applies to find a candidate answer. Moreover, an extra
experiment, with manually corrected temporal expression identification and normalization,
is performed. Obviously, only questions Type 3 and 4 are affected and improved. Results
are shown in Table 8.
Table 8: Evaluation of QA system plus temporal layer for English temporal questions with
manually corrected TERN
POS

ACT

CORR

INE

PREC

REC

F

MRR

Type 1

50

50

35

0

70.00%

70.00%

70.00%

77.60%

Type 2

50

48

40

1

83.33%

80.00%

81.63%

82.00%

Type 3

50

48

30

2

62.50%

60.00%

61.22%

65.66%

Type 4

50

46

26

2

56.52%

52.00%

54.17%

55.66%

GLOBAL

200

192

131

5

68.22%

65.50%

66.83%

70.23%

A graphical comparison of the results for each type of question is shown in Figure 5. It is
very clear that the Multilayered QA system enhances the performance of the QA system in
all the types of questions except Type 1 (simple factual temporal questions), since this type
of question is processed in the same way by both systems. For the other types, precision,
recall, F-measure and MRR are improved, especially in the case of Type 3 and Type 4
questions, in which the base QA system is almost incapable of answering these questions
properly. The system gave very few inexact answers since the questions need short answers
consisting only of an NE or TE.
Some interesting examples that have been analyzed are shown in Figure 6.
In the first example, the question is a Type 2 question, which contains an implicit
temporal expression 16 years ago. The question is processed by both systems, but with
the important difference that the Multilayered QA system is able to process the temporal
expression and normalize the expression to a concrete date, in this case 1992. Once this
preprocessing of the temporal expression is done, the question is processed by the Base QA
system as Where were the Olympics held in 1992?, allowing the system to find the correct
answer. Without this preprocessing of the temporal layer, the Base QA system returns the
795

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

F

MRR

80%

80%

70%

70%

60%

60%

50%

50%

40%

Q.A.

40%

Q.A.

30%

M.Q.A

30%

M.Q.A.

20%

20%

10%

10%

0%

0%
Type 1

Type 2

Type 3

Type 4

Type 1

(a) F-measure comparison

Type 2

Type 3

Type 4

(b) MRR comparison

Figure 5: Comparative graphics between Base QA system and Multilayered QA system
Who was the Indian Prime Minister
when the Black Panthers was founded?

Where were the Olympics held 16 years ago?
Type 2

Base Q.A.
system

Type 4

Multilayered
Q.A. system

Base Q.A.
system

16 years ago
= 1992

Beijing
(Wrong)

Multilayered
Q.A. system
Q-R=1996
T.S.=when

Barcelona
(OK)

H.Rap Brown
(Wrong)

(a) Example 1

Indira Gandhi
(OK)

(b) Example 2

Figure 6: Examples of Multilayered QA system performance
most popular answer, which corresponds to the last Olympic games in Beijing, and therefore
fails to answer the question correctly.
In the second example, the question is a Type 4 complex question and is again processed
by both systems. Since the Base QA system is not able to reason the second part of the
question and simply uses the keywords in the question, only the Multilayered QA system
returns a correct answer, taking as a restriction the date when the event in the second part
of the questions occurred.
To conclude, this study demonstrates that including this type of layer can help general purpose QA systems to resolve questions that are more complex than simple factual
questions, without changing the implementation of the general QA system.
6.2.3 Comparison with other QA systems
In order to compare our results with those of another QA system, we carried out the above
test with the widely known START QA system (Katz, 1990, 1997), which is available on
the Internet10 . The results obtained with the START system and those obtained by our
10. http://start.csail.mit.edu/

796

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

QA system enhanced with the temporal layer are shown and compared in Table 9. Both
are general purpose QA systems using Internet as corpus.
Table 9: Our QA system plus temporal layer compared to START QA system
QA + temp layer

START

PREC

REC

F

MRR

PREC

REC

F

MRR

Type 1

70.00%

70.00%

70.00%

77.60%

85.71%

24.00%

37.50%

24.00%

Type 2

80.85%

76.00%

78.35%

78.00%

75.00%

6.00%

11.11%

7.00%

Type 3

60.42%

58.00%

59.18%

63.66%

00.00%

00.00%

00.00%

00.00%

Type 4

56.52%

52.00%

54.17%

55.66%

00.00%

00.00%

00.00%

00.00%

GLOBAL

67.02%

64.00%

65.47%

68.73%

83.33%

7.50%

13.76%

7.75%

The START QA system was only able to answer Types 1 and Type 2 questions. Although, the precision achieved by this system with these types of questions is high, the recall
is lower, specially for Type 2 questions (6.00%). Focusing on complex temporal questions
(Types 2, 3 and 4), our QA system, which uses temporal information, can be seen to obtain
better results than the START QA, which does not use a temporal layer. In conclusion,
these results show that the application of a temporal layer improves QA results for complex
temporal questions. Concretely, considering the overall results, the QA system using the
temporal layer exceeds the START system by a 375.79% as regards the F-measure (48.36%
error reduction).
6.3 Portability to Other Languages: The Spanish Approach
As said before, the system was initially developed for English but was extended to Spanish
as well. Since the task performed by the layer that processes complex questions is language
dependent, some adaptation of the system was required: (1) TERSEO for Spanish was
used, (2) all the temporal signals stored in the system were translated into Spanish, (3) the
question splitter module was adapted to build grammatically correct Spanish Cuando
(When) questions.
6.3.1 Decomposition Unit Evaluation for Spanish
The results of the evaluation are shown in Table 10.

Table 10: Evaluation of the system for Spanish
POS

ACT

TE Identification and Normalization

100

90

82

91.1%

82.0%

86.3%

Type Identification

200

200

189

94.5%

94.5%

94.5%

Signal Detection

100

99

97

97.9%

97.0%

97.4%

Question Splitter

100

100

93

93.0%

93.0%

93.0%

200

190

174

91.5%

87.0%

89.2%

DECOMPOSITION UNIT

797

CORR

PREC

REC

F

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

Briefly, in the evaluation for Spanish, 174 out of a total of 200 questions were properly
processed and decomposed in all aspects (TE identification, type identification, temporal
signal detection and splitting, if necessary), which means an F-measure of 89.2% for the
whole decomposition process. The best results were obtained by the Signal Detection module (F-measure almost 100%), but the results for Question Splitting and Type Identification
(F-measure around 93-94%) and TE Identification and Normalization were also quite good
(F-measure around 86%).
The main errors were very similar to the English ones. However, some new problems
appeared in Spanish (see Appendix B for details), principally produced by:
 Grammatical errors in the transformation of the second question due to the ambiguity
of some words that produces an incorrect POS-tagging. For example: in the expression
el cometa Hale (the Hale comet), the POSTAGGER classifies cometa (comet) as
a verb rather than a noun, which would be the appropriate tag in this case.
 Temporal expressions like el ano 99 or el 99 (year 99), which in Spanish refer
to 1999 in this case, are detected but not resolved. The same problem appears other
expressions containing non explicit numeric temporal expressions, i.e. el siglo XIX
(XIX century), el segundo milenio (second millennium) or the less common
word-spelled dates mil novecientos noventa y ocho (one thousand nine hundred
ninety eight) are not successfully processed by the temporal layer.
 Finally, in questions where the temporal signal is complex, such as: un ano despues
de que...(a year after...), both signal detection and question splitting are wrong
because this type of complex signal is outside the scope of the system.
6.3.2 Evaluating the influence of the temporal processing in QA systems
for Spanish
For this evaluation, the QA system described (Moreda et al., 2008a) was adapted to the
Spanish language. As in English, we used the NE-based answer extraction module.
We divided the Spanish evaluation into two experiments, as in the English evaluation:
1. Base QA system evaluation: First the adapted QA system is evaluated without using
the temporal layer.
2. Multilayered QA system evaluation: Then the adapted QA system is evaluated when
it performs with the temporal layer.
The main aim of this evaluation is to analyze whether the temporal layer can be successfully extended to other languages and deal with other language QA system, like the
Spanish-adapted QA system in this case. The 200 temporal question corpus created for the
English test were manually translated into Spanish and used in both experiments.
The results obtained by the general purpose Spanish QA system without the temporal
layer are shown in Table 11.
The results obtained by the system that has been enhanced with the temporal layer are
shown in Table 12.
798

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

Table 11: Evaluation of QA system for Spanish temporal questions
POS

ACT

CORR

INE

PREC

REC

F

MRR

Type 1

50

35

20

1

57.14%

40.00%

47.06%

45.34%

Type 2

50

37

12

0

32.43%

24.00%

27.59%

29.06%

Type 3

50

3

0

0

0.00%

0.00%

0.00%

0.00%

Type 4

50

4

0

0

0.00%

0.00%

0.00%

0.00%

GLOBAL

200

79

32

1

40.51%

16.00%

22.94%

18.60%

Table 12: Evaluation of QA system plus temporal layer for Spanish temporal questions
POS

ACT

CORR

INE

PREC

REC

F

MRR

Type 1

50

35

20

1

57.14%

40.00%

47.06%

45.34%

Type 2

50

40

19

0

47.50%

38.00%

42.22%

45.96%

Type 3

50

31

15

1

48.39%

30.00%

37.04%

37.00%

Type 4

50

31

14

1

45.16%

28.00%

34.57%

34.00%

GLOBAL

200

137

68

3

49.64%

34.00%

40.36%

40.58%

These results for Spanish show, as expected and already proven in the English case,
that: a) the QA system enhanced with the temporal layer gives better results in all measures (79.42% improvement in F and 22.60% error reduction in F), and b) the temporal layer
is easily extensible to other languages. The final global results are worst than the English
approach with this QA system, but this is due to the fact that the baseline results for the
Spanish QA system are also worst compared with the English QA system (F-English 38%
compared to F-Spanish 23%). In addition, as in the English experiments, an extra experiment with manually corrected Spanish temporal expression identification and normalization
is performed and results are shown in Table 13.
Table 13: Evaluation of QA system plus temporal layer for Spanish temporal questions with
manually corrected TERN
POS

ACT

CORR

INE

PREC

REC

F

MRR

Type 1

50

35

20

1

57.14%

40.00%

47.06%

45.34%

Type 2

50

43

22

0

51.16%

44.00%

47.31%

51.96%

Type 3

50

31

15

1

48.39%

30.00%

37.04%

37.00%

Type 4

50

31

14

1

45.16%

28.00%

34.57%

34.00%

GLOBAL

200

140

71

3

50.71%

35.50%

41.76%

42.08%

Despite this fact, the Multilayered QA system enhances the performance of the Spanish
QA system in all the types of questions, even in the case of complex questions, for which the
Base Spanish QA system is unable to find any correct answer. There are very few inexact
799

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

answers for Spanish as well, thus proving that the system usually obtains exact answers for
both languages.
To conclude this second evaluation analysis, extension of the evaluation to Spanish
corroborates the conclusions obtained in the English evaluation and also demonstrates that
the temporal layer improves the system in the same way regardless of the language.

7. Conclusions and Further Work
This study presents a multilayered temporal QA architecture that performs on a multilingual level, in this case English and Spanish. This system processes complex temporal
questions by splitting them into simple questions that can be answered by different types
of general purpose QA systems. In addition, the system performs a temporal reasoning of
the questions with temporal information.
The proposal consists in adding a new layer, on top of a current QA system, which has
two main features:
 Complex question decomposition. Questions are decomposed into simple events which
generate simple questions (sub-questions) by using the temporal signal that relates
the events. The first sub-question (Q-Focus) specifies the type of information the user
needs to find. The answer to the second sub-question (Q-Restriction) establishes the
temporal restrictions on the list of answers to the Q-Focus. The Q-Focus and the
Q-Restriction are the input of a QA system (any type of QA system could be used
here).
 Question recomposition. Answers to the Q-Focus and Q-Restriction, obtained from
the QA system, are filtered and compared in order to determine their temporal compatibility and construct the final complex answer.
Since the layer that processes complex questions uses lexical and syntactic rules (a
grammar), this task is language dependent. Initially, the decomposition unit was prepared
for English, but in a very general way. Extension of the system to Spanish was therefore very
simple (only some small changes were required), and the same applies to other languages.
In addition, the temporal reasoning of the system is performed by TERSEO, which is a
multilingual system (now working in Spanish, English, Catalan and Italian) that is easily
extensible to any European language.
For evaluation purposes, there were two aims: a) to determine if the decomposition unit
processes each type of question properly in order to obtain the appropriate simple factual
questions, and b) show how these techniques enhance a general purpose QA system. In order
to accomplish these aims, a test bed for English and Spanish was constructed, annotating
the question corpus with the correct results for both decomposition and QA tasks, and
determining the criteria establishing when a question has been properly decomposed and
answered.
The decomposition unit evaluation results for English and Spanish were very good for
complex questions (F-measure 89.5% for English and 89.2% for Spanish). When evaluating
the performance of the whole multilayered architecture, these results were compared with
those obtained by the base QA system without the temporal layer. Great improvement
800

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

was found, especially in the case of complex questions (Type 3 and 4), in which the base
system was not able to answer them at all (4.66% average F-measure for English and 0.00%
for Spanish). The multilayered QA system obtained an overall F-measure of approximately
65% for English and 40% for Spanish for all types of questions. Besides, the temporal layer
QA system was also compared with an online general purpose QA system called START,
demonstrating the difficulty encountered by these general purpose QA systems in answering
questions with complex temporal information or temporal relations.
Further work will be done along three main lines of research: 1) resolving the problems
detected in the temporal layer after the evaluation process, 2) adding a module to resolve
anaphoric co-reference in questions, 3) integrating the event and link information from
TIMEML schema (TimeML, 2008) in our system in order to extract a deeper understanding
of complex questions, 4) taking into consideration techniques to determine event durations
in case of open-ended questions, such as: What happened to world oil prices after the Iraqi
annexation of Kuwait?. For this task, previous work in the field will be considered (Pan
et al., 2006b), and 5) applying the layer procedure to other types of complex questions,
as well as studying the new features that need to be added to the system to enable it to
perform with other languages like Chinese.

Acknowledgments
This paper has been partially supported by the Spanish government, project TIN-200615265-C06-01, and by the framework of the project QALL-ME, which is a 6th Framework
Research Programme of the European Union (EU), contract number: FP6-IST-033860.

Appendix A. Question Decomposition Error Analysis for English
This appendix gives detailed information on the decomposition errors detected in the test
for the English language. As shown in Table 5 we distinguish TE identification and normalization, type identification, signal detection and question splitter errors. In Table 14
we specify which questions in the English testbed correspond to which error types. The
questions in bold correspond to more than one type of error.
Table 14: Question Decomposition Error Analysis for English
Error type
TE Identification and Normalization

testbed question
81, 83, 89, 92, 97, 98, 99, 102, 108, 112, 114, 115, 116, 117,
126, 129, 133, 135, 142, 148

Type Identification

97, 98, 108, 129, 135, 148

Signal Detection

101, 114, 116, 129

Question Splitter

101, 110, 114, 116, 129, 142, 179, 192

The questions implied are listed below. Only erroneous elements are listed and the correct
values are indicated in brackets.
<Q id=81> (ACT: Yes CORR: No)

801

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

<QUESTION>Who won the Nobel Peace Prize in 91?</QUESTION>
<TE value=>91</TE> (CORR value=1991)
</Q>
<Q id=83> (ACT: Yes CORR: No)
<QUESTION>What tennis player did win Wimbledon women singles in the second millennium year?</QUESTION>
<TE value=>year</TE>(CORR <TE value=2000>second millennium year</TE>)
</Q>
<Q id=89> (ACT: Yes CORR: No)
<QUESTION>How many planes crashed into Twin Towers in 01?</QUESTION>
<TE value=>01</TE> (CORR value=2001)
</Q>
<Q id=92> (ACT: Yes CORR: No)
<QUESTION>What organization was founded in 75 by Bill Gates?</QUESTION>
<TE value=>75 by</TE> (CORR <TE value=1975>75</TE>)
</Q>
<Q id=97> (ACT: No CORR: No)
<QUESTION>What city was the capital of Nicaragua in eighteen fifty-five?</QUESTION>
<TE value=></TE> (CORR <TE value=1855>eighteen fifty-five</TE>)
<TYPE>1</TYPE> (CORR <TYPE>2</TYPE>)
</Q>
<Q id=98> (ACT: No CORR: No)
<QUESTION>What was the largest city in Italy in the 17th century?</QUESTION>
<TE value=></TE> (CORR <TE value=16>the 17th century</TE>)
<TYPE>1</TYPE> (CORR <TYPE>2</TYPE>)
</Q>
<Q id=99> (ACT: Yes CORR: No)
<QUESTION>Where was Eurovision held in 68?</QUESTION>
<TE value=>68</TE> (CORR value=1968)
</Q>
<Q id=101> (ACT: Yes CORR: No)
<QUESTION>Who was the Prime Minister of Spain four years after Jose Maria Aznar presided Spain between
2000 and 2004?</QUESTION>
<SIGNAL>after</SIGNAL> (CORR <SIGNAL>four years after</SIGNAL>)
<Q-FOCUS>Who was the Prime Minister of Spain four years?</Q-FOCUS>
(CORR <Q-FOCUS>Who was the Prime Minister of Spain?</Q-FOCUS>)
</Q>
<Q id=102> (ACT: No CORR: No)
<QUESTION>Who was the king of Spain after Charles III died in the 1780s?</QUESTION>
<TE value=></TE> (CORR <TE value=178>the 1780s</TE>)
</Q>
<Q id=108> (ACT: No CORR: No)
<QUESTION>Who was the president of the US when the AARP was founded five decades ago?</QUESTION>
<TE value=></TE>(CORR <TE value=195>five decades ago</TE>)
<TYPE>4</TYPE> (CORR <TYPE>3</TYPE>)
</Q>
<Q id=110> (ACT: Yes CORR: No)
<QUESTION>Who was the Prime Minister of Spain just after the Columbia first flight in the 1980s?</QUESTION>
<Q-FOCUS>Who was the Prime Minister of Spain just?</Q-FOCUS>
(CORR <Q-FOCUS>Who was the Prime Minister of Spain?</Q-FOCUS>)
</Q>
<Q id=112> (ACT: Yes CORR: No)
<QUESTION>How many members had the European Union when Gladiator was released in 00?</QUESTION>
<TE value=>00</TE> (CORR <TE value=2000>00</TE>)

802

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

</Q>
<Q id=114> (ACT: Yes CORR: No)
<QUESTION>What company introduced onto the market a seat with adjustable shoulder support a year before
Mariah Carey was born in the 1960s?</QUESTION>
<TE value=>the 1960s</TE> (CORR <TE value=196>the 1960s</TE>)
<SIGNAL>before</SIGNAL> (CORR <SIGNAL>a year before</SIGNAL>)
<Q-FOCUS>What company introduced onto the market a seat with adjustable shoulder support a year?</QFOCUS>
(CORR <Q-FOCUS>What company introduced onto the market a seat with adjustable shoulder support?</QFOCUS>)
</Q>
<Q id=115> (ACT: Yes CORR: No)
<QUESTION>Which language was forbidden in Spain during Francos Dictatorship period 1939-1975?</QUESTION>
<TE value=1975>1939-1975</TE>
(CORR <TE value=1939-1975>1939-1975</TE>)
</Q>
<Q id=116> (ACT: Yes CORR: No)
<QUESTION>When did Indurain win the Tour a year after the Shawshank Redemption film was released in the
1990s?</QUESTION>
<TE value=>the 1990s</TE> (CORR <TE value=199>the 1990s</TE>)
<SIGNAL>after</SIGNAL> (CORR <SIGNAL>a year after</SIGNAL>)
<Q-FOCUS>When did Indurain win the Tour a year?</Q-FOCUS>
(CORR <Q-FOCUS>When did Indurain win the Tour?</Q-FOCUS>)
</Q>
<Q id=117> (ACT: Yes CORR: No)
<QUESTION>When did Vesuvius erupt before Sinclair Lewis won Literature Nobel Prize in 1930s?</QUESTION>
<TE value=>1930s</TE> (CORR <TE value=193>1930s</TE>)
</Q>
<Q id=126> (ACT: Yes CORR: No)
<QUESTION>Who died on a plane crash when Vietnam war was started in late 1960s?</QUESTION>
<TE value=>1960s</TE> (CORR <TE value=1965-1969>late 1960s</TE>)
</Q>
<Q id=129> (ACT: No CORR: No)
<QUESTION>Who was the king of Spain after Charles IV reigned Spain during the eighteenth century?</QUESTION>
<TE value=></TE> (CORR <TE value=17>eighteenth century</TE>)
<TYPE>4</TYPE> (CORR <TYPE>3</TYPE>)
<SIGNAL>during</SIGNAL> (CORR <SIGNAL>after</SIGNAL>)
<Q-FOCUS>Who was the king of Spain after Charles IV reigned Spain?</Q-FOCUS>
(CORR <Q-FOCUS>Who was the king of Spain?</Q-FOCUS>)
<Q-REST>When did the eighteenth century happen?</Q-REST>
(CORR <Q-REST>When did Charles IV reign Spain during the eighteenth century?</Q-REST>)
</Q>
<Q id=133> (ACT: Yes CORR: No)
<QUESTION>What person won the Literature Nobel Prize when James Dean was born in 31?</QUESTION>
<TE value=>31</TE> (CORR value=1931)
</Q>
<Q id=135> (ACT: No CORR: No)
<QUESTION>Who was the prime minister of the United Kingdom when the AARP was founded five decades
ago?</QUESTION>
<TE value=></TE> (CORR <TE value=195>five decades ago</TE>)
<TYPE>4</TYPE> (CORR <TYPE>3</TYPE>)
</Q>
<Q id=142> (ACT: Yes CORR: No)
<QUESTION>Which language was invented by Zamenhof when Berliner patented the Gramophone in the 1880s?</QUESTION>
<TE value=>the 1880s</TE> (CORR <TE value=188>the 1880s</TE>)

803

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

<Q-REST>When did Berliner patented the Gramophone in the 1880s happen?</Q-REST>
(CORR <Q-REST>When did Berliner patent the Gramophone in the 1880s?</Q-REST>)
</Q>
<Q id=148> (ACT: No CORR: No)
<QUESTION>Where was the Woodstock Festival held on August 15 when Unix was developed?</QUESTION>
<TE value=></TE> (CORR <TE value=XXXX-08-15>August 15</TE>)
<TYPE>4</TYPE> (CORR <TYPE>3</TYPE>)
</Q>
<Q id=179> (ACT: Yes CORR: No)
<QUESTION>Who was the king of Spain after Charles IV reigned Spain?</QUESTION>
<Q-REST>When did Charles IV reign Spain happen?</Q-REST>
(CORR <Q-REST>When did Charles IV reign Spain?</Q-REST>)
</Q>
<Q id=192> (ACT: Yes CORR: No)
<QUESTION>Which language was invented by Zamenhof when Berliner patented the Gramophone?</QUESTION>
<Q-REST>When did Berliner patented the Gramophone happen?</Q-REST>
(CORR <Q-REST>When did Berliner patent the Gramophone?</Q-REST>)
</Q>

Appendix B. Question Decomposition Error Analysis for Spanish
This appendix gives detailed information on the decomposition errors detected in the test
for the Spanish language (see table 10)
. In Table 15 we specify which questions correspond to which error types. The questions in
bold correspond to more than one type of error.
Table 15: Question decomposition error analysis for Spanish
Error type

testbed question

TE Identification and Normalization

81, 83, 89, 92, 97, 98, 99, 108, 114, 116, 129, 130, 133, 135,
142, 143, 145, 148

Type Identification

2, 6, 9, 31, 45, 81, 97, 98, 108, 129, 135

Signal Detection

114, 116, 129

Question Splitter

105, 110, 114, 116, 129, 133, 155

The questions implied are listed below. Only erroneous elements are listed and the correct
values are indicated in brackets.
<Q id=2> (ACT: Yes CORR: No)
<QUESTION>Durante que decada fue inventado el test del polgrafo?</QUESTION>
<TYPE>2</TYPE> (CORR <TYPE>1</TYPE>)
</Q>
<Q id=6> (ACT: Yes CORR: No)
<QUESTION>En que ano fue lanzado el submarino Nautilus?</QUESTION>
<TYPE>2</TYPE> (CORR <TYPE>1</TYPE>)
</Q>
<Q id=9> (ACT: Yes CORR: No)

804

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

<QUESTION>En que ano entro en vigor la enmienda 18?</QUESTION>
<TYPE>2</TYPE> (CORR <TYPE>1</TYPE>)
</Q>
<Q id=31> (ACT: Yes CORR: No)
<QUESTION>Que ano volaron los Wright Brothers por primera vez?</QUESTION>
<TYPE>2</TYPE> (CORR <TYPE>1</TYPE>)
</Q>
<Q id=45> (ACT: Yes CORR: No)
<QUESTION>Que ano fue el gran Incendio de Londres?</QUESTION>
<TYPE>2</TYPE> (CORR <TYPE>1</TYPE>)
</Q>
<Q id=81> (ACT: No CORR: No)
<QUESTION>Quien gano el Nobel de la Paz en el 91?</QUESTION>
<TE value=></TE> (CORR <TE value=1991>el 91</TE>)
<TYPE>1</TYPE> (CORR <TYPE>2</TYPE>)
</Q>
<Q id=83> (ACT: Yes CORR: No)
<QUESTION>Que jugador de tenis gano Wimbledon mujeres individuales en el ano del segundo milenio?</QUESTION>
<TE value=>el ano</TE>
(CORR <TE value=2000>en el ano del segundo milenio</TE>)
</Q>
<Q id=89> (ACT: Yes CORR: No)
<QUESTION>Cuantos aviones chocaron en las Torres Gemelas en el 01?</QUESTION>
<TE value=>el 01</TE> (CORR value=2001)
</Q>
<Q id=92> (ACT: Yes CORR: No)
<QUESTION>Que empresa fue fundada en el 75 por Bill Gates?</QUESTION>
<TE value=2008>el 75</TE> (CORR value=1975)
</Q>
<Q id=97> (ACT: No CORR: No)
<QUESTION>Que ciudad fue la capital de Nicaragua en mil ochocientos cincuenta y cinco?</QUESTION>
<TE value=></TE> (CORR <TE value=1855>mil ochocientos cincuenta y cinco</TE>)
<TYPE>1</TYPE> (CORR <TYPE>2</TYPE>)
</Q>
<Q id=98> (ACT: No CORR: No)
<QUESTION>Cual fue la ciudad mas grande de Italia en el siglo XVII?</QUESTION>
<TE value=></TE> (CORR <TE value=16>el siglo XVII</TE>)
<TYPE>1</TYPE> (CORR <TYPE>2</TYPE>)
</Q>
<Q id=99> (ACT: Yes CORR: No)
<QUESTION>Donde se celebro Eurovision en el ano 68?</QUESTION>
<TE value=2008>el ano 68</TE> (CORR value=1968)
</Q>
<Q id=105> (ACT: Yes CORR: No)
<QUESTION>Quien gano el Nobel de Fsica cuando el cometa Hale Bopp fue descubierto hace 13 anos?</QUESTION>
<Q-REST>Cuando cometio el Hale Bopp fue descubierto hace 13 anos?</Q-REST>
(CORR <Q-REST>Cuando fue descubierto el cometa Hale Bopp hace 13 anos?</Q-REST>)
</Q>
<Q id=108> (ACT: No CORR: No)
<QUESTION>Quien fue el presidente de los Estados Unidos cuando se fundo AARP hace cinco decadas?</QUESTION>
<TE value=></TE> (CORR <TE value=195>hace cinco decadas </TE>)
<TYPE>4</TYPE> (CORR <TYPE>3</TYPE>)
</Q>

805

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

<Q id=110> (ACT: Yes CORR: No)
<QUESTION>Quien fue el Presidente de Espana justo despues de que se produjera el primer vuelo del Columbia
en los anos 80?</QUESTION>
<Q-REST>Cuando se produjo se el primer vuelo del Columbia en los anos 80?</Q-REST>
(CORR <Q-REST>Cuando se produjo el primer vuelo del Columbia en los anos 80?</Q-REST>)
</Q>
<Q id=114> (ACT: No CORR: No)
<QUESTION>Que empresa introdujo en el mercado el primer asiento con respaldo regulable un ano antes de
que naciera Mariah Carey en los anos 60?</QUESTION>
<TE value=>un ano antes</TE> (CORR <TE value=196>los anos 60</TE>)
<SIGNAL>antes de que</SIGNAL>
(CORR <SIGNAL>un ano antes de que</SIGNAL>)
<Q-FOCUS>Que empresa introdujo en el mercado el primer asiento con respaldo regulable un ano?</Q-FOCUS>
(CORR <Q-FOCUS>Que empresa introdujo en el mercado el primer asiento con respaldo regulable?</QFOCUS>)
</Q>
<Q id=116> (ACT: No CORR: No)
<QUESTION>Cuando gano Indurain el Tour un ano despues de que se estrenara Cadena Perpetua en los anos
90?</QUESTION>
<TE value=>un ano despues</TE> (CORR <TE value=199>los anos 90</TE>)
<SIGNAL>despues de que</SIGNAL>
(CORR <SIGNAL>un ano despues de que</SIGNAL>)
<Q-FOCUS>Cuando gano Indurain el Tour un ano?</Q-FOCUS>
(CORR <Q-FOCUS>Cuando gano Indurain el Tour?</Q-FOCUS>)
</Q>
<Q id=129> (ACT: No CORR: No)
<QUESTION>Quien fue el Rey de Espana despues de que Carlos IV reinara Espana durante el siglo XVIII?</QUESTION>
<TE value=></TE> (CORR <TE value=17>el siglo XVIII</TE>)
<TYPE>4</TYPE> (CORR <TYPE>3</TYPE>)
<SIGNAL>durante</SIGNAL> (CORR <SIGNAL>despues</SIGNAL>)
<Q-REST>Cuando fue el siglo XVIII?</Q-REST>
(CORR <Q-REST>Cuando reino Carlos IV Espana durante el siglo XVIII?</Q-REST>)
</Q>
<Q id=130> (ACT: Yes CORR: No)
<QUESTION>Quien gano Wimbledon femenino individuales antes de que Rafa Nadal ganara Wimbledon este
ano?</QUESTION>
<TE value=>este ano</TE> (CORR <TE value=2008>este ano</TE>)
</Q>
<Q id=133> (ACT: Yes CORR: No)
<QUESTION>Que persona gano el premio Nobel de Literatura cuando James Dean nacio en el ano 31?</QUESTION>
<TE value=>el ano 31</TE> (CORR value=1931)
<Q-REST>Cuando jamo Dean nacio en el ano 31?</Q-REST>
(CORR <Q-REST>Cuando nacio James Dean en el ano 31?</Q-REST>)
</Q>
<Q id=135> (ACT: No CORR: No)
<QUESTION>Quien fue el Presidente de Reino Unido cuando AARP fue fundada hace cinco decadas?</QUESTION>
<TE value=></TE> (CORR <TE value=195>hace cinco decadas</TE>)
<TYPE>3</TYPE> (CORR <TYPE>4</TYPE>)
</Q>
<Q id=142> (ACT: Yes CORR: No)
<QUESTION>Que lengua fue inventada por Zamenhof cuando Berliner patento el disco de vinilo en la decada
de 1880?</QUESTION>
<TE value=1880>1880</TE>
(CORR <TE value=188>la decada de 1880</TE>)
</Q>

806

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

<Q id=143> (ACT: No CORR: No)
<QUESTION>Donde se celebraran las Olimpiadas cuando Polonia adopte el Euro en la decada de 2010?</QUESTION>
<TE value=></TE> (CORR <TE value=201>la decada de 2010</TE>)
</Q>
<Q id=145> (ACT: Yes CORR: No)
<QUESTION>Cuando gano Gary Becker el premio Nobel de Economa antes de que Zapatero fuera elegido
Presidente de Espana en los ultimos anos?</QUESTION>
<TE value=>los ultimos anos</TE> (CORR value=[2003-2008])
</Q>
<Q id=148> (ACT: No CORR: No)
<QUESTION>Donde se celebro el Festival de Woodstock el 15 de agosto cuando el Unix fue desarrollado?</QUESTION>
<TE value=></TE> (CORR <TE value=XXXX-08-15>el 15 de agosto</TE>)
</Q>
<Q id=155> (ACT: Yes CORR: No)
<QUESTION>Quien gano el Nobel de Fsica cuando el cometa Hale Bopp fue descubierto?</QUESTION>
<Q-REST>Cuando cometio el Hale Bopp fue descubierto?</Q-REST>
(CORR <Q-REST>Cuando fue descubierto el cometa Hale Bopp?</Q-REST>)
</Q>

References
ACL (2001). Association for computational linguistics. http://www.aclweb.org/.
Ahn, D. (2006). The stages of event extraction. In for Computational Linguistics, A.
(Ed.), ARTE: Workshop of 44th Annual Meeting of the Association for Computational
Linguistics, pp. 18, Sydney, Australia.
ATEL (2008). Computational Language and Education Research. University of Colorado.
http://timex2.mitre.org/taggers/timex2 taggers.html.
Barzilay, R., Elhadad, N., & McKeown, K. (2002). Inferring strategies for sentence ordering
in multidocument news summarization. J. Artif. Intell. Res. (JAIR), 17, 3555.
Breck, E., Burger, J., Ferro, L., Greiff, W., Light, M., Mani, I., & Rennie, J. (2000). Another
Sys Called Quanda. In Ninth Text REtrieval Conference, Vol. 500-249 of NIST Special
Publication, pp. 369378. National Institute of Standards and Technology.
CLEF (2008). Cross Language Evaluation Forum. http://www.clef-campaign.org/.
COLING (2000).
18th international
http://coling.dfki.de/.

conference

on

computational

linguistics.

COLING-ACL (2006). 44th annual meeting of the association for computational linguistics.
http://www.aclweb.org/mirror/acl2006/.
Dalli, A., & Wilks, Y. (2006). Annotating Dating of Documents and Temporal Text Classification. In for Computational Linguistics, A. (Ed.), ARTE: Workshop of 44th Annual
Meeting of the Association for Computational Linguistics, pp. 1122, Sydney, Australia.
Demri, S., & Jensen, C. S. (Eds.). (2008). 15th International Symposium on Temporal
Representation and Reasoning, Vol. 15 of TIME symposium. IEEE Computer Society.
807

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

Filatova, E., & Hovy, E. (2001). Assigning Time-Stamps to Event-Clauses. In Proceedings of
the 2001 ACL Workshop on Temporal and Spatial Information Processing, pp. 8895.
Harabagiu, S., Lacatusu, F., & Hickl, A. (2006). Answering complex questions with random
walk models. In Proceedings of the 29th Annual International ACM SIGIR Conference
on Research and Development in Information Retrieval, pp. 220227.
Herrera, J., Penas, A., & Verdejo, F. (2005). Question answering pilot task at CLEF 2004.
In Peters, C., Clough, P., Gonzalo, J., Jones, G. J., Kluck, M., & Magnini, B. (Eds.),
Berlin Heidelberg New York, Vol. 3491 of Lecture Notes in Computer Science, pp.
581590. Springer-Verlag.
Katz, B. (1990). Using English for indexing and retrieving. Artificial intelligence at MIT
expanding frontiers, 1, 134165.
Katz, B. (1997). Annotating the World Wide Web using Natural Language. In Proceedings
of the 5th RIAO Conference on Computer Assisted Information Searching on the
Internet.
Katz, B., Borchardt, G., & Felshin, S. (2005). Syntactic and semantic decomposition strategies for question ansering from multiple resources. In Proceedings of the AAAI 2005
Workshop on Inference for Textual Question Answering, pp. 3541.
Katz, G., & Arosio, F. (2001). The Annotation of Temporal Information In Natural Language Sentences. In Proceedings of the 2001 ACL Workshop on Temporal and Spatial
Information Processing, pp. 104111.
Katz, G., Pustejovsky, J., & Schilder, F. (2005). Annotating, Extracting and Reasoning
about
Time
and
Events.
http://www.dagstuhl.de/en/programm/kalender/semhp/?semnr=05151.
Lapata, M., & Lascarides, A. (2006). Learning Sentence-internal Temporal Relations. Journal of Artificial Intelligence Research, 27, 85117.
Lin, C.-J., & Liu, R.-R. (2008). An Analysis of Multi-Focus Questions. In Proceedings of
the SIGIR 2008 Workshop on Focused Retrieval, pp. 3036.
LREC (2002). Proceedings of the LREC Workshop on Temporal Annotation Standards.
http://www.lrec-conf.org/lrec2002/.
Magnini, B., Giampiccolo, D., Forner, P., Ayache, C., Jijkoun, V., Osenova, P., Penas,
A.,
Rocha,
P.,
Sacaleanu,
B.,
& Sutcliffe, R. (2006). Overview of the CLEF 2006 Multilingual Question Answering
Track. http://www.clef-campaign.org/2006/working notes/workingnotes2006/
magniniOCLEF2006.pdf.
Magnini, B., Vallin, A., Ayache, C., Erbach, G., Penas, A., de Rijke, M., Rocha, P., Simov,
K., & Sutcliffe, R. (2005). Overview of the CLEF 2004 Multilingual Question Answering Track. In Peters, C., Clough, P., Gonzalo, J., Jones, G. J., Kluck, M., & Magnini,
B. (Eds.), Berlin Heidelberg New York, Vol. 3491 of Lecture Notes in Computer Science, pp. 371391. Springer-Verlag.
Mani, I., & Wellner, B. (2006). A Pilot Study on Acquiring Metric Temporal Constraints
for Events. In for Computational Linguistics, A. (Ed.), ARTE: Workshop of 44th
808

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

Annual Meeting of the Association for Computational Linguistics, pp. 2329, Sydney,
Australia.
Mani, I., & Wilson, G. (2000a). Processing of news. In Proceedings of the 38th Annual
Meeting of the Association for Computational Linguistics (ACL2000), pp. 6976.
Mani, I., & Wilson, G. (2000b). Robust temporal processing of news. In ACL (Ed.),
Proceedings of the 38th Meeting of the Association of Computational Linguistics (ACL
2000), Hong Kong.
Mani, I., & Wilson, G. (2002). Annotation Standards for Temporal Information in Natural
Language. In Proceedings of the LREC Workshop on Temporal Annotation Standards.
Mazur, P., & Dale, R. (2007). The DANTE temporal expression tagger. In Proceedings of
the 3rd Language and Technology Conference.
Michelson, M., & Knoblock, C. A. (2008). Creating Relational Data from Unstructured and
Ungrammatical Data Sources. J. Artif. Intell. Res. (JAIR), 31, 543590.
Moia, T. (2001). Telling apart temporal locating adverbials and time-denoting expressions.
In Proceedings of the 2001 ACL Workshop on Temporal and Spatial Information Processing.
Moreda, P., Llorens, H., Saquete, E., & Palomar, M. (2008a). Automatic generalization
of a QA answer extraction module based on semantic roles. In 11th edition of the
Ibero-American Conference on Artificial Intelligence (IBERAMIA 2008), Advances
in Artificial Intelligence. Springer-Verlag LNAI.
Moreda, P., Llorens, H., Saquete, E., & Palomar, M. (2008b). The influence of Semantic
Roles in QA: A comparative analysis. In XXIV edicion del Congreso Anual de la
Sociedad Espanola para el Procesamiento del Lenguaje Natural 2008 (SEPLN 08) .
Negri, M. (2007). Dealing with italian temporal expressions: The ITA-Chronos system. In
Proceedings of EVALITA 2007, Workshop held in conjunction with AI*IA.
Negri, M., Saquete, E., Martnez-Barco, P., & Munoz, R. (2006). Evaluating Knowledgebased Approaches to the Multilingual Extension of a Temporal Expression Normalizer.
In for Computational Linguistics, A. (Ed.), ARTE: Workshop of 44th Annual Meeting
of the Association for Computational Linguistics, pp. 3037, Sydney, Australia.
Palomar, M., Ferrandez, A., Moreno, L., Martnez-Barco, P., Peral, J., Saiz-Noeda, M., &
Munoz, R. (2001). An algorithm for anaphora resolution in Spanish text. Computational Linguistics, 27 (4), 545567.
Palomar, M., & Martnez-Barco, P. (2001). Computational approach to anaphora resolution
in Spanish dialogues. Journal of Artificial Intelligence Research, 15 (4), 263287.
Pan, F., Mulkar, R., & Hobbs, J. (2006a). Learning Event Durations from Event Descriptions. In 44th Annual Meeting of the Association for Computational Linguistics, pp.
393400.
Pan, F., Mulkar-Mehta, R., & Hobbs, J. R. (2006b). Learning Event Durations from Event
Descriptions. In ACL. The Association for Computer Linguistics.
Prager, J. M., Chu-Carroll, J., & Czuba, K. (2004). Question Answering Using Constraint
Satisfaction: QA-By-Dossier-With-Contraints. In ACL, pp. 574581.
809

fiSaquete, Vicedo, Martnez-Barco, Munoz, & Llorens

Pustejovsky, J. (2002). TERQAS: Time and Event Recognition for Question Answering
Systems. www.timeml.org/terqas/.
Pustejovsky, J., & Mani, I. (2008). TANGO: TimeML Annotation Graphical Organizer.
http://www.timeml.org/site/tango/index.html.
Radev,
D.,
&
Sundheim,
B. (2002). Using TimeML in question answering. http://www.cs.brandeis.edu/~
jamesp/arda/time/documentation/ TimeML-use-in-qa-v1.0.pdf.
Saquete, E., Martnez-Barco, P., & Munoz, R. (2002). Recognising and Tagging Temporal
Expressions in Spanish. In Proceedings of the LREC Workshop on Temporal Annotation Standards, pp. 4451.
Saquete, E., Martnez-Barco, P., Munoz, R., & Vicedo, J. (2004). Splitting Complex Temporal Questions for Question Answering systems. In ACL (Ed.), 42nd Annual Meeting
of the Association for Computational Linguistics, pp. 566573, Barcelona, Espana.
Saquete, E., Munoz, R., & Martnez-Barco, P. (2006). Event Ordering using TERSEO
system. Data and Knowledge Engineering Journal, 58 (1), 7089.
Saur, R., Knippen, R., Verhagen, M., & Pustejovsky, J. (2005). EVITA: a robust event
recognizer for QA systems. In HLT 05: Proceedings of the conference on Human
Language Technology and Empirical Methods in Natural Language Processing, pp.
700707, Morristown, NJ, USA. Association for Computational Linguistics.
Schilder, F., & Habel, C. (2001). From Temporal Expressions to Temporal Information:
Semantic Tagging of News Messages. In Proceedings of the 2001 ACL Workshop on
Temporal and Spatial Information Processing, pp. 6572.
Setzer, A., & Gaizauskas, R. (2001). A Pilot Study On Annotating Temporal Relations In
Text. In Proceedings of the 2001 ACL Workshop on Temporal and Spatial Information
Processing.
Setzer, A., & Gaizauskas, R. (2002). On the Importance of Annotating Event-Event Temporal Relations in Text. In Proceedings of the LREC Workshop on Temporal Annotation
Standards, pp. 5260.
TempEx
(2008).
MITRE
http://timex2.mitre.org/taggers/timex2 taggers.html.
TERN
(2004).
Time
Expression
http://timex2.mitre.org/tern.html.

Recognition

Corporation.
and

Normalization.

TIME (2008). International Symposium on Temporal Representation and Reasoning.
http://time.dico.unimi.it/.
TimeML (2008).
Markup Language for Temporal
http://www.timeml.org/site/index.html.

and

Event

Expressions.

TREC (2008). Text REtrieval Conference. http://trec.nist.gov/.
Verhagen, M., Gaizauskas, R., Schilder, F., Hepple, M., Katz, G., & Pustejosvky, J. (2007).
Temeval-2007 task 15: Tempeval temporal relation identification. In Proceedings of
the 4th International Workshop of SemEval-2007, pp. 7580.
810

fiEnhancing QA Systems with Complex Temporal Question Processing Capabilities

Voorhees, E. M. (2002). Overview of the TREC 2002 Question Answering Track. In Eleventh
Text REtrieval Conference, Vol. 500-251 of NIST Special Publication, pp. 115123.
National Institute of Standards and Technology.
Wilson, G., Mani, I., Sundheim, B., & Ferro, L. (2001). A Multilingual Approach To
Annotating And Extracting Temporal Information. In Proceedings of the 2001 ACL
Workshop on Temporal and Spatial Information Processing, pp. 8187.

811

fiJournal of Artificial Intelligence Research 35 (2009) 391 447

Submitted 09/08; published 06/09

Learning Bayesian Network Equivalence Classes with
Ant Colony Optimization
Rnn Daly

RDALY @ DCS . GLA . AC . UK

Department of Computing Science
University of Glasgow
Sir Alwyn Williams Building
Glasgow, G12 8QQ, UK

Qiang Shen

QQS @ ABER . AC . UK

Department of Computer Science
Aberystwyth University
Penglais Campus
Aberystwyth, SY23 3DB, UK

Abstract
Bayesian networks are a useful tool in the representation of uncertain knowledge. This paper
proposes a new algorithm called ACO-E, to learn the structure of a Bayesian network. It does this
by conducting a search through the space of equivalence classes of Bayesian networks using Ant
Colony Optimization (ACO). To this end, two novel extensions of traditional ACO techniques are
proposed and implemented. Firstly, multiple types of moves are allowed. Secondly, moves can be
given in terms of indices that are not based on construction graph nodes. The results of testing
show that ACO-E performs better than a greedy search and other state-of-the-art and metaheuristic
algorithms whilst searching in the space of equivalence classes.

1. Introduction
The task of learning Bayesian networks from data has, in a relatively short amount of time, become a
mainstream application in the process of knowledge discovery and model building (Aitken, JirapechUmpai, & Daly, 2005; Heckerman, Mamdani, & Wellman, 1995). The reasons for this are many. For
one, the model built by the process has an intuitive feel  this is because a Bayesian network consists
of a directed acyclic graph (DAG), with conditional probability tables annotating each node. Each
node in the graph represents a variable of interest in the problem domain and the arcs can (with some
caveats) be seen to represent causal relations between these variables (Heckerman, Meek, & Cooper,
1999)  the nature of these causal relations is governed by conditional probability tables associated
with each node/variable. An example Bayesian network is shown in Figure 1.
Another reason for the popularity of Bayesian networks is that aside from the visual attractiveness
of the model, the underlying theory is quite well understood and has a solid foundation. A Bayesian
network can be seen as a factorization of a joint probability distribution, with the conditional
probability distributions at each node making up the factors and the graph structure making up
their method of combination. Because of this equivalence, the network can answer any probabilistic
question regarding the variables modeled.
In addition, the popularity of Bayesian networks has been increased by the accessibility of methods to query the model and learn both the structure and parameters of the network
c
2009
AI Access Foundation. All rights reserved.

fiDALY & S HEN

Figure 1: An example Bayesian network
(Daly, Shen, & Aitken, 2009). It has been shown that inference in Bayesian networks is NP-complete
(Dagum & Luby, 1993; Shimony, 1994), but approximate methods have been found to perform
this operation in an acceptable amount of time. Learning the structure of Bayesian networks is also
NP-complete (Chickering, 1996a), but here too, methods have been found to render this operation
tractable. These include greedy search, iterated hill climbing and simulated annealing (Chickering,
Geiger, & Heckerman, 1996). Recently however, other heuristics have become popular with the
problem of combinatorial optimization in high dimensional spaces. These include approaches such
as tabu search (Glover, 1989, 1990), genetic algorithms (Mitchell, 1996) and  the approach that
this paper will investigate  Ant Colony Optimization (ACO).
ACO is a fairly recent, so called metaheuristic, that is used in the solution of combinatorially hard
problems (Dorigo & Sttzle, 2004). It is an iterated, stochastic technique that is biased by the results
of previous iterations (Birattari, Caro, & Dorigo, 2002). The method is modeled on the behavior of
real-life ants foraging for food.
Many ants secrete a pheromone trail that is recognizable by other ants and which positively biases
them to follow that trail, with a stronger trail meaning it is more likely to be biased towards it. Over
time this pheromone trail evaporates. When hunting for food, an ants behavior is to randomly walk
about, perhaps by following a pheromone trail, until it finds some food. It then returns in the direction
from whence it came. Because the strength of the trail is a factor in choosing to follow it, if an ant is
faced with two or more pheromone trails to choose from, it will tend to choose the trails with the
highest concentration of pheromone.
With these characteristics, in a situation where there are multiple paths to a food source, ants
generally follow the shortest path. This can be explained as follows. Assuming ants start from a nest
and no pheromone trails are present, they will randomly wander until they reach a food source and
then return home, laying pheromone on the way back. The ant that chooses the shortest path to the
food source will return home the quickest, which means their pheromone trail will have the highest
concentration, as more pheromone is laid per unit of time. This stronger trail will cause other ants to

392

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

prefer it over longer trails. These ants will then leave their own pheromone on this short trail, thereby
providing a reinforcing behavior to choose this trail over others.
As a computing technique, ACO is roughly modeled on this behavior. Artificial ants walk around
a graph where the nodes represent pieces of a solution. They continue this until a complete solution is
found. At each node, a choice of the next edge to traverse is made, depending on a pheromone value
associated with the edge and a problem specific heuristic. After a number of ants have performed
a traversal of the graph, one of the best solutions is chosen and the pheromone on the edges that
were taken is increased, relative to the other edges. This biases the ants towards choosing these edges
in future iterations. The search stops when a problem specific criterion is reached. This could be
stagnation in the quality of solutions or the passage of a fixed amount of time.
This paper will seek to use the ACO technique in learning Bayesian networks. Specifically, it
will be used to learn an equivalence class of Bayesian network structures. To this end, the rest of
this paper will be structured in the following fashion. Firstly, there will be a more in-depth study of
the problem of searching for an optimum Bayesian network, in both the space of Bayesian networks
themselves and of equivalence classes of Bayesian networks. Then, a new method of formulating
a search for a Bayesian network structure in terms of the ACO metaheuristic will be introduced.
This method is based in part on earlier work done on this topic (Chickering, 2002a; de Campos,
Fernndez-Luna, Gmez, & Puerta, 2002). Next, results of tests against previous techniques will be
discussed and finally, conclusions and possible future directions will be stated.

2. Searching for a Bayesian Network Structure
There are, in general, three different methods used in learning the structure of a Bayesian network
from data. The first finds conditional independencies in the data and then uses these conditional
independencies to produce the structure (Spirtes, Glymour, & Scheines, 2000). Probably the most
well known algorithms that use this method are the PC algorithm by Spirtes and Glymour (1990) and
the CI and FCI algorithms of Spirtes, Meek, and Richardson (1995) that are able to identify latent
variables and selection bias. The second uses dynamic programming and optionally, clustering, to
construct a DAG (Ott, Imoto, & Miyano, 2004; Ott & Miyano, 2003). The third method  which
is to be dealt with here  defines a search on the space of Bayesian networks. This method uses a
scoring function defined by the implementer, which says relatively how good a network is compared
to others.
Although the classification into three different methods as noted above is useful in differentiating
their applicability, the boundaries between them are often not as clear as they may seem. E.g. the
score and search approach and the dynamic programming approach are both similar in that they
use scoring functions. Indeed, there is a view by Cowell (2001) that the conditional independence
approach is equivalent to minimizing the Kullback-Leibler (KL) divergence (Kullback & Leibler,
1951) using the score and search approach. Before discussing how the score and search method
works, some definitions and notation will be introduced.
A graph G is given as a pair (V, E), where V = {v1 , . . . , vn } is the set of vertices or nodes in the
graph and E is the set of edges or arcs between the nodes in V . A directed graph is a graph where all
the edges have an associated direction from one node to another. A directed acyclic graph or DAG, is
a directed graph without any cycles, i.e. it is not possible to return to a node in the graph by following
the direction of the arcs. For illustration, the graph in Figure 2 is a DAG. The parents of a node vi ,
Pa (vi ), are all the nodes v j such that there is an arrow from v j to vi (v j  vi ). The descendants of vi ,
393

fiDALY & S HEN

Figure 2: A directed acyclic graph

Figure 3: The skeleton of the DAG in Figure 2

D (vi ), are all the nodes (not including vi ) reachable from vi by following the arrows in a forwards
direction repeatedly. The non-descendants of vi , ND (vi ), are all the nodes (not including vi ) that are
not descendants of vi .
Let there be a graph G = (V, E) and a joint probability distribution P over the nodes in V . Let
IP (X,Y |Z) mean that each of the variables in set X is conditionally independent of each of the
variables in set Y under probability distribution P given the variables in set Z. Say also that the
following is true
v  V. IP ({v} , ND (v) |Pa (v)) .
That is, each node is conditionally independent of its non-descendants, given its parents. Then it is
said that G satisfies the Markov condition with P, and that (G, P) is a Bayesian network. Notice the
conditional independencies implied by the Markov condition. They allow the joint distribution P to
be written as the product of conditional distributions; P (v1 |Pa (v1 )) P (v2 |Pa (v2 ))    P (vn |Pa (vn )) =
P (v1 , v2 , . . . , vn ). However, more importantly, the reverse can also be true. Given a DAG G and
either discrete conditional distributions or certain types of continuous conditional distributions (e.g.
Gaussians), of the form P (vi |Pa (vi )) then there exists a joint probability distribution
P (v1 , v2 , . . . , vn ) = P (v1 |Pa (v1 )) P (v2 |Pa (v2 ))    P (vn |Pa (vn )) .
This means that if we specify a DAG  known as the structure  and conditional probability distributions for each node given its parents, which are often parameterised, we have a Bayesian network,
which is a representation of a joint probability distribution.
In learning a Bayesian network from data, both the structure G and parameters of the conditional
probability distributions  must be learned, normally separately. In the case of complete multinomial
data, the problem of learning the parameters is easy given certain reasonable assumptions, with a
simple closed form formula for  (Heckerman, 1995). However, in the case of learning the structure,
no such formula exists and other methods are needed. In fact, learning the optimal structure with
discrete variables is an NP-hard problem in almost all circumstances and consequently enumeration
and test of all network structures is not likely to succeed (Chickering, 1996a; Chickering, Heckerman,
& Meek, 2004). With just ten variables there are roughly 1018 possible DAGs. Whilst there exist
dynamic programming methods that can handle roughly 30 variables as discussed above, in general,
non-exact and heuristic methods are possibly the only tractable solution to anything above this.
394

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

In order to create a space in which to search through, three components are needed. Firstly all
the possible solutions must be identified as the set of states in the space. Secondly a representation
mechanism for each state is needed. Finally a set of operators must be given, in order to move from
state to state in the space.
Once the search space has been defined, two other pieces are needed to complete the search
algorithm, a scoring function which evaluates the goodness of fit of a structure with a set of data
and a search procedure that decides which operator to apply, normally using the scoring function
to see how good a particular operator application might be. An example of a search procedure is
greedy search, which at every stage applies the operator that produces the best change in the structure,
according to the scoring function. As for the scoring function, various formul have been found to
see how well a DAG matches a data sample.
One of these functions is given by computing the relative posterior probability of a structure G
given a sample of data D, i.e.
S(G, D) = P(G, D) = P(D|G)P(G).
The likelihood term above can take many forms. One popular method is called the Bayesian Dirichlet
(BD) metric. Here,
ri (N 0 + N )
n qi
(Ni0j )
i jk
i jk
P(D|G) =  

(1)

0
0
(Ni jk )
i=1 j=1 (Ni j + Ni j ) k=1
In this formula, there are n variables in the graph, so the first product is over each variable. There
are qi configurations of the parents of node i, so the second product is over all possible parent
configurations, i.e. the Cartesian product of the number of possible values each parent variable can
take. Each variable i can take on one of ri possible values. The value Ni jk is the number of times
that variable i = k and the parents of i are in configuration j in the data sample D. Ni j is given as
ri
i
Ni jk , i.e. the sum of Ni jk over all possible values that i can take on. With Ni0j = ri=1
Ni0jk , the
k=1
values Ni0jk are given as parameters that give different variants of the BD metric. E.g. if Ni0jk is set to 1
the K2 metric results, as given by Cooper and Herskovits (1992). With Ni0jk set to N 0 /(ri  qi ) (where
N 0 , known as the equivalent sample size is a measure of the confidence in the prior network), the
BDeu metric results which was proposed by Buntine (1991) and further generalised by Heckerman,
Geiger, and Chickering (1995).
The prior value P(G) is a measure of how probable a particular structure is before any data is
seen. These values can often be hard to estimate because of the massive numbers of graphs, each
of them needing a probability. Therefore, the values are often given as uniform over all possible
network structures or possibly favouring structures with less arcs.
Other forms used for the scoring function are S(G, D) = log P(D|G, )  d2 log N, known as the
Bayesian information criterion (BIC) (Schwarz, 1978) and S(G, D) = log P(D|G, )  d, known as
the Akaike Information Criterion (AIC) (Akaike, 1974). In these models, the parameters  give the
maximum likelihood estimate of the likelihood, d is the number of free parameters in the structure
and N is the number of samples in the data D.
Traditionally, in searching for a Bayesian network structure, the set of states is the set of possible
Bayesian network structures, the representation is a DAG and the set of operators are various small
local changes to a DAG, e.g. adding, removing or reversing an arc, as illustrated in Table 1. This type

395

fiDALY & S HEN

Operator

Before

After

Insert_Arc(X,Y)

Delete_Arc(X,Y)

Reverse_Arc(X,Y)

Table 1: Basic modification operators
of search is convenient because of the decomposition properties of score functions,
n

S(G, D) =  s vi , PaG (vi ) , D ,
i=1

where s is a scoring function that takes a node vi and the parents of this node in graph G, PaG (vi ).
Popular scoring functions such as the BD metric are decomposable in this manner. Successful
application of the operators is also dependent on the changed graph being a DAG, i.e. that no cycle is
formed in applying the operator.

3. Searching in the Space of Equivalence Classes
According to many scoring criteria, there are DAGs that are equivalent to one another, in the sense
that they will produce the same score as each other. It has been known for some time that these DAGs
are equivalent to one another, in that they entail the same set of independence constraints as each
other, even though the structures are different. According to a theorem by Verma and Pearl (1991),
two DAGs are equivalent if and only if they have the same skeletons and the same set of v-structures.
The skeleton is the undirected graph that results in undirecting all edges in a DAG (see Figure
3) and a v-structure (sometimes referred to as a morality), is a head-to-head meeting of two arcs,
where the tails of the arcs are not joined. These concepts are illustrated in Figure 4. From this notion
of equivalence, a class of DAGs that are equivalent to each other can be defined, notated here as
Class(G).
3.1 Representation of Equivalence Classes
Because of this apparent redundancy in the space of DAGs, attempts have been made to conduct
the search for Bayesian network structures in the space of equivalence classes of DAGs (Acid &
de Campos, 2003; Chickering, 1996b, 2002a; Munteanu & Bendou, 2001). The search set of this
space is the set of equivalence classes of DAGs and will be referred to as E-space. To represent the
members of this equivalence class, a different type of structure is used, known as a partially directed
acyclic graph (PDAG). A PDAG (an example of which is shown in Figure 5) is a graph that may
contain both undirected and directed edges and that contains no directed cycles and will be notated
396

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

(a) (X,Y, Z) is a v-structure

(b) (X,Y, Z) is not a v-structure

Figure 4: V-Structures

Figure 5: A partially directed acyclic graph

Figure 6: A PDAG for which there exists no consistent extension

herein as P. The equivalence class of DAGs corresponding to a PDAG is denoted as Class(P), with
a DAG G  Class(P) if and only if G and P have the same skeleton and same set of v-structures.
Related to this is the idea of a consistent extension. If a DAG G has the same skeleton and the
same set of v-structures as a PDAG P then it is said that G is a consistent extension of P. Not all
PDAGs have a DAG that is a consistent extension of itself. If a consistent extension exists, then it is
said that the PDAG admits a consistent extension. Only PDAGs that admit a consistent extension
can be used to represent an equivalence class of DAGs and hence a Bayesian network. An example
of a PDAG that does not have a consistent extension is shown in Figure 6. In this figure, directing
the edge x  y either way will create a v-structure that does not exist in the PDAG and hence no
consistent extension can exist.
Directed edges in a PDAG can be either: compelled, or made to be directed that way; or reversible,
in that they could be undirected and the PDAG would still represent the same equivalence class. From
this idea, a completed PDAG (CPDAG) can be defined, where every undirected edge is reversible in
the equivalence class and every directed edge is compelled in the equivalence class. Such a CPDAG
will be denoted as as P C . It can be shown that there is a one-to-one mapping between a CPDAG
P C and Class(P C ). Therefore, by supplying a CPDAG, one can uniquely denote a set of conditional
independencies. For a more in-depth look at this topic, see the papers of Andersson, Madigan, and
Perlman (1997) and Chickering (1995).

397

fiDALY & S HEN

3.2 Techniques for Searching through Equivalence Classes
Note that below, a move is referred to as an application of an operator to a particular state in the
search space.
To be able to conduct a search through the space of equivalence classes, a method must be able
to find out whether a particular move is valid and if valid, how good that move is. These tasks are
relatively easy whilst searching through the space of DAGs  a check whether a move is valid is
equivalent to a check whether a move keeps a DAG acyclic. The goodness of such a move is found
out by using the scoring function, but rather than scoring each neighboring DAG in the search space,
the decomposability of most scoring criteria can be taken advantage of, with the result that only
nodes whose parent sets have changed need to be scored.
However, this task of checking move validity and move score is not as easy in the space of
equivalence classes. These classes are often represented by PDAGs, as discussed in the previous
section. For one, instead of just checking for cycles, checks also have to be made so that unintended
v-structures are not created in a consistent extension of a PDAG. Scoring a move also creates
difficulties, as it is hard to know what extension and hence what changes in parent sets of nodes will
occur, without actually performing this extension. Also, a local change in a PDAG might make a
non-local change in a corresponding consistent extension and so force unnecessary applications of
the score function.
These problems were voiced as concerns by Chickering (1996b). In that paper, validity checking
of moves is performed by trying to obtain a consistent extension of the resulting PDAG  if none
exists then the move is not valid. Scoring the move was achieved by scoring the changed nodes in the
consistent extension given. These methods were very generic, but resulted in a significant slowdown
in algorithm execution, compared to search in the space of DAGs.
To alleviate this problem, authors proposed improvements that would allow move validity and
move score to be computed without needing to obtain a consistent extension of the PDAG (Acid &
de Campos, 2003; Chickering, 2002a; Munteanu & Bendou, 2001). This was done by defining an
explicit set of operators, with each operator having a validity test and corresponding score change
function, that could be calculated on the PDAG. These changes led to a speedup of the execution
time of the algorithm, with the result that search in the space of equivalence classes of Bayesian
networks became competitive with search in the space of Bayesian networks. An example of one set
of these operators is given in Table 2. In this table, the variables x and y refer to nodes in a graph. As
an example, the InsertU operator takes two nodes as arguments, x and y. It can be seen that all the
operators take two arguments, except MakeV, which takes three arguments. Each operator also has a
set of validity tests that must be passed in order for the application of the operator with its particular
arguments to be valid. Finally, the score difference between the old and new PDAGs is given in the
last column.
Note that in this table:
x is the parent set of node x, i.e. the set of nodes that have directed arcs going to node x;
Nx is the neighbor set of node x, i.e. the set of nodes that have undirected arcs going to node x;
Nx,y is the set of shared neighbors of nodes x and y, i.e. Nx  Ny ; and
x,y is the set of parents of x that are neighbors of y, i.e. x  Ny .

398

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Operator

Effect

InsertU
xy

Add an
undirected arc
between x and y

DeleteU
xy

Delete an
undirected arc
between x and y

Validity Tests

Change in Score

1. Every undirected path from x
to y contains a node in Nx,y

2. x = y

Nx,y is a clique


+x  
s y, Nx,y
y
 s (y, Nx,y  y )

s (y, Nx,y  y )

+x  
 s y, Nx,y
y

1. Every semi-directed path
InsertD
xy

Add a directed
arc from x to y

from y to x contains a node
in x,y

2. x,y is a clique


s y, x,y  +x
y
 s (y, x,y  y )

3. x 6= y
DeleteD
xy

Delete a directed
arc from x to y

Ny is a clique

1. Every semi-directed path
ReverseD
xy

Reverse a
directed arc from
x to y

from x to y that does not
include the edge x  y
contains a node in y,x  Ny

2. y,x is a clique

MakeV
xzy

Direct undirected
arcs from x and y
to z

Every undirected path
between x and y
contains a node in Nx,y


s y, Ny  x
y
 s (y, Ny  y )
s y, x
y



+ s x, +y
x  y,x
 s (y, y )
 s (x, x  y,x )


z+x
s z, +y
z  Nx,y

z
+ s y, y  Nx,y

z+x
 s z, z  Nx,y
 s (y, y  Nx,y )

Table 2: Validity conditions and change in score for each operator

399



fiDALY & S HEN

Also, as a convenience, M +x is notation for M  {x} and M x is notation for M \ {x}.
This notation and the set of operators in Table 2 come from those proposed by Chickering (2002a).
Other definitions include: an undirected path is a path from one node to another that only follows
undirected edges; a semi-directed path is a path from one node to another that only follows undirected
edges or directed edges from tail to head; and a set of nodes N is a clique, if it is a completely
connected subgraph of a graph, (i.e. every node is connected to every other in the subgraph).
3.3 Advantages of Searching in E-space
With this representation of equivalence classes of Bayesian network structures and a set of operators
that modify the CPDAGs which represent them (e.g. insert an undirected arc, insert a directed arc
etc.), a search procedure can proceed. However, what reasons are there for pursuing this type of
search? Chickering (2002a) gives a list of reasons, some of which are discussed here.
For one, an equivalence class can represent many different DAGs in a single structure. With a
DAG representation, time can be wasted rescoring DAGs that are in the same equivalence class. And
with a search in the space of DAGs, the connectivity of the search space can mean that the ability to
move to a particular neighboring equivalence class can be constrained by the particular representation
given by a DAG. There is also the problem given by the prior probability used in the scoring function.
Whilst searching through the space of DAGs, certain equivalence classes can be over represented by
this prior, because there are many more DAGs contained in the class. An example can be given in
the case of networks with two nodes. In B-space there are 3 possible structures, which with equal
priors give P (G) = 1/3, for each DAG G. However, the two DAGs that are connected represent the
same equivalence class, giving it an effective prior of 2/3. In E-space there are 2 possible structures,
which with equal priors give P (P) = 1/2, for each PDAG P. This is not necessarily a problem when
performing model selection, but becomes much more of an issue when performing model averaging.
These concerns have motivated researchers. In particular, recent implementations of algorithms
that search through the space of equivalence classes have produced results that show a marked
improvement in execution time and a small improvement in learning accuracy, depending on the type
of data set (Chickering, 2002a,b).

4. Ant Colony Optimization
Ant colony optimization is a global optimization technique generally used in the area of combinatorial
problems, i.e. problems where the set of solutions is discrete. Since the inception of its present form
by Dorigo (1992), ACO has been successfully applied to many combinatorially hard problems
including the sequential ordering problem (Gambardella & Dorgio, 2000), the vehicle routing
problem (Bullnheimer, Hartl, & Strauss, 1999), the bin-packing problem (Levine & Ducatelle, 2004)
and many more (Costa & Hertz, 1997; Gambardella & Dorgio, 2000; Maniezzo & Colorni, 1999;
Sttzle, 1998). Such a diverse range of applications must ask the question as to what is the nature of
the system that can solve them.
The particular form of ACO is of a metaheuristic in the field of swarm intelligence (Bonabeau,
Dorigo, & Theraulaz, 1999), that is based on the behavior of real-life ants as they forage for food.
A metaheuristic is a general purpose heuristic that guides other, more problem specific heuristics,
whilst swarm intelligence may be defined as:

400

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

algorithms or distributed problem-solving devices inspired by the collective behaviour of social insect colonies and other animal societies (Bonabeau, Dorigo et al.,
1999).
It is in this conceptual framework that ACO is defined.
4.1 Ant Colony Optimization
Ant colony optimization is a swarm intelligence technique that is based on the foraging behavior of
real-life ants. In particular, it uses the principle of stigmergy (the indirect communication of agents
through the environment) as a communication mechanism. Real-life ants leave a chemical trail behind
them as they explore their environment. This trail is known as pheromone. In moving around, ants
are more likely to follow a path with more pheromone, than a path with less (or no) pheromone.
This behavior was investigated by Deneubourg, Aron, Goss, and Pasteels (1990), who designed an
experiment with a nest of Argentine ants, a food source and two trails between them that could be set
to different length. Ants would leave the nest, find the food source and return back with food. When
the trails were of the same length, it was found that the ants would eventually settle on a single trail
for travel to and from the nest. This behavior can be explained as follows.
When the experiment begins, ants initially choose one of the trails at random. Whilst traversing
this trail, they deposit pheromone. This causes following ants to choose the trail the initial ants took
more often, and deposit more pheromone on that trail. Again, this causes more ants to choose the
initially chosen trail, to a greater degree than the first set of ants. Put another way, each ant that
chooses a certain trail reinforces the probability that following ants will choose that trail. The trail
that initially gets chosen by more ants has more pheromone deposited per unit time and hence a
positive feedback or autocatalytic process is created, where eventually all ants converge to a single
trail.
When the trails start out at different lengths, it is found that ants converge on the shorter trail
more often than the longer. This can be explained by more ants being able to traverse the shorter
trail to the food source and return to the nest in the same amount of time it would take to traverse the
longer trail. With more ants traversing the trail, more pheromone is deposited, and the ants eventually
converge to that path.
It is the behavior of the ants when faced with trails of different lengths that ACO is modeled upon.
Instead of real-life ants, artificial ants are conceived as a computing unit. Instead of trails, these ants
traverse a construction graph. The paths the ants take on this graph are solutions to the problem being
looked at  the idea is to reinforce the pheromone on better solutions. However, the fundamental idea
of laying down pheromone is kept, with ants depositing it on arcs as they traverse from node to node.
Also, ants are programmed to follow arcs with stronger pheromone more often than arcs with weaker
pheromone.
Artificial ants can be more useful than real-life ants in that they can be given a memory. This
can stop ants looping around and helps when laying pheromone on the return journey. Also they
can be programmed to use problem dependent heuristics, which can guide the search towards better
solutions. All of these ideas and more will now be discussed.
4.2 The ACO Metaheuristic
Nowadays, ACO algorithms tend to be defined in terms of the ACO metaheuristic (Dorigo & Di
Caro, 1999). A metaheuristic is a general purpose heuristic that guides other, more problem specific
401

fiDALY & S HEN

heuristics. Examples of metaheuristics include simulated annealing (Kirkpatrick, Gelatt, & Vecchi,
1983), tabu search (Glover, 1989, 1990), evolutionary computation etc.
In the ACO metaheuristic, a problem is represented by a triple (S, f , ), where S is a set of
candidate solutions, f : S  T is an objective or scoring function that measures a solutions quality at
a particular time t  T and  : T is a set of constraints at time t  T , used in a solutions construction.
The range of f and  is dependent on the particular instance of the metaheuristic. In trying to map a
combinatorial optimization problem onto this representation, the following framework is used.
 There should be a finite set of solution components C = {c1 , c2 , . . . , cNc }. These are the building
blocks of candidate solutions.


ff
 The problem states are represented by sequences of solution components x = ci , c j , . . . . The
set of all possible sequences is given as X .
 S  the set of candidate solutions as mentioned above  is a subset of X , i.e. S  X .
 There is a set of feasible states X , with X  X . A feasible state x  X is a state where it is
possible to add components from C to x to create a solution satisfying the constraints .
 Each candidate solution s  S has a cost g(s,t). Normally g(s,t)  f (s,t), s  S, where
S = S  X is the set of feasible candidate solutions. However, this might not always be the
case; if f is very expensive to compute, g might be an easier to compute function that is broadly
similar to f and that can be used in the generation of solutions.
 The set of optimal solutions S  should be non-empty, with S   S.
 Sometimes it may also be possible to associate a cost J(x,t) to a state x  X that is not a
candidate solution.
With this framework, solutions to the problem (S, f , ) can be generated by having artificial ants
perform a random walk on the complete graph G defined on the components in C. This graph G is
known as the construction graph. A random walk on a graph is a series of moves from node to node
of the graph, with each move being random to some degree. If the walk is Markovian, then the next
move is always completely random; if not then then next move is influenced by the previous moves.
Hence, using this terminology ACO is non-Markovian. The walk that the ant makes is generally
biased by two things  a heuristic value  (i if the heuristic is associated with the individual nodes
of G, i j if it is associated with the edges of G) and a pheromone trail  (again, i if the pheromone
is associated with the individual nodes of G, i j if the pheromone is associated with the edges of
G). The way the heuristic and pheromone are implemented are problem dependent, but in general
the heuristic  is a measure of the goodness of taking a particular move on the construction graph
as defined by some local measure. The pheromone  is a measure of the goodness of taking a
particular move as defined by the aggregate behavior of ants selecting that move and the quality of
solutions that these ants generate.
Finally, each artificial ant k has the following properties in order to fully specify how the random
walk will proceed:
Memory  Each ant k has a memory Mk that stores information about the path it has so far followed.
Start State  Each ant k has a start state xsk and a non-empty set of termination conditions ek .
402

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Termination Criteria  When an ant is in a state x, it checks if one of the termination criteria in ek
is satisfied. If not, it moves to a node j  N k (x). N k is a function that returns the neighborhood
of a node x, i.e. all the nodes on the construction graph G that can be reached from the current
state, given the constraints .
Decision Rule  An ant chooses the node j according to a probabilistic decision rule, which is a
function of the pheromone  and the heuristic . The specification of these rules is problem
dependent, but is usually a random choice biased towards moves with a higher heuristic and
pheromone value.
Pheromone Update  The pheromone of a path can be modified by an ant as it is traversing it, or on
the return journey, when it returns to the start. Again, this is problem dependent, but a standard
formulation is to increase the pheromone on good solutions and decrease the pheromone on
bad solutions, good and bad being given by the specific formulation.
In terms of algorithmic actions, an ACO algorithm can normally be broken down into three parts.
These are:
ConstructAntsSolutions This part of the algorithm is concerned with sending ants around the
construction graph according to the rules given above.
UpdatePheromones This part is concerned with changing the values of the pheromones, by both
depositing and evaporating. Parts of this task might be performed during an ants traversal of
the graph, when an ants traversal is finished or after an iteration of all the ants traversals.
DaemonActions This part of the algorithm performs tasks not directly related to the ants. E.g. a
local search procedure might be performed after each ant finishes its traversal.
Given the above framework, multiple artificial ants are released to perform a random walk. This
procedure is repeated a number of times, with the pheromone gradually increasing on the best parts
of the solution.
There have been many implementations of the above metaheuristic. The first was the original
ACO system designed by Dorigo, Maniezzo, and Colorni (1996) known as Ant System. This was used
to study the traveling salesman problem, with the construction graph defined by the distances between
cities. Another extension to Ant System is the Ant Colony System (ACS) (Dorigo & Gambardella,
1997). Here, the search is biased towards the best-so-far path, with a pseudo-random proportional
decision rule that takes the best solution component most of the time and the normal random
proportional decision rule the rest of the time. Also, only the best-so-far ant deposits pheromone.
ACS is based on a system known as ANT-Q designed by Gambardella and Dorigo (1995), that is
itself inspired by the reinforcement learning technique of Q-learning (Sutton & Barto, 1998). The
ACS is particularly interesting in this context, as it is the system on which the new work described
in later sections has been modeled. This is because this work is inspired by a previous approach to
learning Bayesian networks using ACO (described in Section 5.1) which used ACS as its form of
ACO.

5. Using Ant Colony Optimization in Learning an Equivalence Class
To date, many state-based search algorithms that create a Bayesian network structure have relied on
simple techniques such as greedy-based searches. These can produce good results, but have the ever
403

fiDALY & S HEN

prevalent problem of getting caught at local minima. More sophisticated heuristics have been applied,
such as iterated hill climbing and simulated annealing (Chickering, Geiger et al., 1996), but so far,
none of these have been applied to E-space. A related approach, by Acid and de Campos (2003)
applied tabu search to a space of restricted partially directed acyclic graphs (RPDAGs), a halfway
house between the spaces given by DAGs and CPDAGs.
This paper seeks to apply the ACO metaheuristic to E-space, the space of equivalence classes of
DAGs. To this end, two extensions are made to the basic metaheuristic. The first is to allow multiple
types of moves. This is to allow more than one operator to be used in traversing the state space. This
is needed, because in general, more than one type of operator is used whilst searching in E-space.
The second is to allow the pheromone to be accessed by arbitrary values  normally it is accessed by
a single index or two indices. Again this is needed because of the operators used in E-space  the
MakeV operator takes three nodes as arguments.
The proposed algorithm, ACO-E, is based in large part on the work of de Campos, FernndezLuna et al. (2002), which is described in the next section.
5.1 Other ACO Algorithms for Learning Bayesian Network Structures
Whilst ACO has been applied to many problems in the area of combinatorial optimization, to date
there has not been much research on using the technique to learn Bayesian network structures. Two
alternate methods have been defined by de Campos, Fernndez-Luna et al. (2002) and de Campos,
Gmez, and Puerta (2002). The first conducts a search in the space of orderings of DAGs, whilst
the second searches in the space of DAGs. Since a main topic of this work is on this problem, a
description of both of these will be given here, in order to examine the early work done on the subject
and see how it can inform future studies.
5.1.1 ACO-K2SN
In the first technique, known as ACO-K2SN, searching over the space of orderings of DAGs, the
various problem components, as taken from Section 4.2 can be defined as follows:
Construction Graph There is one node for each attribute in the data, with an extra dummy node
from which the search starts.
Constraints The only constraints are that the tour is a Hamiltonian path.
Pheromone Trails The pheromone is associated with each arc on the graph. Each arc in the graph
is intialised to a initial small value.
Heuristic Information The heuristic on each arc is set to the inverse of the negative log likelihood
score that is explained below.
Solution Construction The ants work on a system very similar to the ACS system. Beginning at
the dummy node, the ants construct a complete path that defines an ordering of the nodes.
Pheromone Update This works exactly as in ACS, with local pheromone updates and global update
on the best-so-far solution.
Local Search A version of local search on orderings known as HCSN (de Campos & Puerta, 2001a).
This is used on the last iteration of the run.
404

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Given the above components, the search for an ordering proceeds as follows. Starting at the dummy
node an ant decides which node to go to next. This will be the first node in the ordering. To choose a
node, heuristic information and pheromone is used. The heuristic for the arc from i to j is given by
1
fi,
i j = fifi
f (x j, Pa (x j ))fi
where f is the scoring metric being used and Pa (x j ), the parents of x j are found by the K2 algorithm,
with possible parents being the nodes already visited. The initial pheromone value 0 is given by
0 =

1
,
n | f (SK2SN )|

where SK2SN is the structure given by the K2SN algorithm of de Campos and Puerta (2001b). The
update value for the pheromone is given by
i j =

1
,
| f (S+ )|

where S+ is the best-so-far structure.
5.1.2 ACO-B
The second algorithm given by de Campos, Fernndez-Luna et al. (2002) is the ACO-B algorithm.
The components for this algorithm are:
Construction Graph There is one node for each possible directed arc between each pair of attributes
(excluding self directed arcs). There is also a dummy node that the ants start from.
Constraints The only constraints are that the DAG must be acyclic at each step.
Pheromone Trails The pheromone is associated with each node on the graph. The pheromone at
node (i, j) corresponds to the directed arc j  i.
Heuristic Information The heuristic on each node (i, j) is the gain in score that would occur in
adding an arc j  i.
Solution Construction The ants work on a system very similar to the ACS system. Beginning at
the dummy node, the ants construct a path that defines which arcs are added to the DAG. This
process ends when there is no gain in score.
Pheromone Update This works exactly as ACS, with local pheromone updates and global update
on the best so far solution.
Local Search A standard greedy search with arc addition, deletion and reversal is carried out on the
current candidate DAG. This is done every 10 iterations.
As opposed to the ACO-K2SN algorithm given in Section 5.1.1, the search is over the space of
DAGs, not orderings of DAGs. Otherwise, there are some similarities in the definitions of parts of
the algorithm. The heuristic is given by
 	
i j = f xi , Pa (xi )  x j  f (xi , Pa (xi )) ,
405

fiDALY & S HEN

that is, the change in score by adding an arc from j to i in the candidate DAG. The initial pheromone
is given by
1
,
0 =
n | f (SK2SN )|
i.e. it is the same as the heuristic in ACO-K2SN. Also, the pheromone update value is the same as in
ACO-K2SN, i.e.
1
i j =
| f (S+ )|
5.1.3 P ERFORMANCE C OMPARISON
In the results given by both de Campos, Gmez et al. (2002) and de Campos, Fernndez-Luna et al.
(2002), the ACO-B algorithm performs slightly better in terms of accuracy than ACO-K2SN across
the ALARM (Beinlich, Suermondt, Chavez, & Cooper, 1989) and INSURANCE (van der Putten &
van Someren, 2004) gold-standard networks. It also contains an order of magnitude less statistical
tests and so should always be faster. There are more comparisons of ACO-B against other algorithms
by de Campos, Fernndez-Luna et al. (2002). Here, it is compared against ILS, an iterative local
search algorithm with random perturbations of a local maximum and two estimation of distribution
(EDA) genetic algorithms, the univariate marginal distribution algorithm (UMDA) by Mhlenbein
(1997) and the population-based incremental learning algorithm (PBIL) by Baluja (1994). Compared
across the ALARM, INSURANCE and BOBLO (Rasmussen, 1995) networks, ACO-B performed
better than the other methods.
5.2 Relation of ACO-E to the ACO Metaheuristic
The proposed algorithm, ACO-E, is based in large part, on the work of de Campos, Fernndez-Luna
et al. (2002). In that work, an ACO algorithm called ACO-B was applied to learning Bayesian
networks. This current work differs in that it searches in E-space, uses more than one operator (add
an arc) and does not constrain itself to using matrices to store pheromone. The algorithm is shown in
Algorithm 1.
In this section, the relation of the various parts of the algorithm to the ACO framework will be
given. The problem of learning a Bayesian network structure can be stated as the triple (S, f , ),
where
 S, the set of all candidate solutions, is the set of all CPDAGs on the nodes of the Bayesian
network. This set has a massive cardinality, being super-exponential in the number of nodes.
 f , the objective function is the function used to score a candidate DAG. This function would
generally be one of the scoring criteria mentioned in Section 2.
 , the set of constraints, makes sure that only PDAGs that have consistent extensions are
generated as solutions. An explanation of the idea of a consistent extension of a PDAG is given
in Section 3.1. In the formulation being presented, the constraints are implicit in the operators
that will be used to move from state to state.
Given this statement of the problem, the ACO-E algorithm can be described by the following
properties. These properties relate to the ACO metaheuristic described in Section 4.2.

406

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Algorithm 1 ACO-E
Input: Operators O, tmax , tstep , m, , q0 ,  , n
Output: PDAG P +
(P + , Path+ )  GREEDY- E(P empty , Pathempty )
0  1/n |SCORE (P + )|
for each operator o in O do
for each possible move m in o on P empty do
m  0
end for
end for
for t  1 to tmax do
for k  1 to m do
P k , Pathk  ANT- E(O, q0 , ,  , 0 )
if (t mod tstep = 0) then

P k , Pathk  GREEDY- E P k , Pathk
end if
end for

k
b  arg maxm
SCORE
P
k=1

if SCORE P b > SCORE (P + ) then
P+  Pb
Path+  Pathb
end if
for each move m in Path+ do
m  (1  ) m + / |SCORE (P + )|
end for
end for
return P +
5.2.1 T HE C ONSTRUCTION G RAPH
The construction graph in an ACO algorithm describes the mechanism by which solutions can be
assembled. It is specified as the complete graph given over the solution components. As such, these
components play a crucial part in the viability of the algorithm.
In the ACO-E algorithm, the components C of the construction graph are the various moves that
may be made, i.e. each move is an instantiation of a supplied operator; in the experiments presented
in this paper, the six operators in Table 2 are used. These operators are used as they have been verified
to work correctly and effectively by Chickering (2002a). Designing correct operators is difficult, as
Chickering showed by finding counter examples to the validity of the operators of Munteanu and
Cau (2000). Each ant constructs a solution by walking the construction graph. This corresponds to
applying a sequence of moves to a CPDAG. In order for the procedure to begin, a starting state must
be specified. In ACO-E this is given as the empty graph.
As usual, the states of the problem are sequences of moves. However, because every state can be
a candidate solution, S = X in the ACO metaheuristic framework. This does not imply that all states
are feasible candidate solutions, but only that candidate solutions can be of any length. This also
means that S = X . Another way to view the state of an ant is to consider the empty graph P (the
407

fiDALY & S HEN



ff
starting state) and the current state as a sequence of moves (components) x = ci , . . . , c j . Applying
each move c  x in order to P will give a CPDAG that is another representation of the current state.
It should be noted that the constraints  are implicitly taken care of by the operators, i.e. the
validity tests on the operators satisfy the constraint that each state is a valid PDAG. It should also be
stated that the usual definition of
g(s,t)  f (s,t), s  S
applies, and that there is no function J(x,t), since all x are candidate solutions and adding a solution
component can decrease the cost.
5.2.2 T HE P ROBLEM H EURISTIC
In an ACO algorithm, the heuristic is used to guide the search to good solutions. It often does this
implicitly in terms of a cost associated with choosing a particular component to add to the current
state; adding a component with the least cost is often a useful way of proceeding in constructing a
solution.
In ACO-E, the heuristic is used in the same manner, with the addition that the cost for adding a
component can be negative, i.e. adding a component to the current state can improve the cost function
g. The heuristic is dynamic in that it depends on the current state of the ant. Also, it is associated
with each component c  C as opposed to the arcs ci  c j between components.
The value of the heuristic i is given by the score gain for each move ci  C that is possible given
the current state. In essence it corresponds to the change in score given by performing a particular
move on the current CPDAG. For the operators being used in this article, this means the values in
Table 2.
5.2.3 T HE P ROBLEM P HEROMONE
The pheromone in an ACO algorithm guides the search based on the results of previous searches. In
many instances, it is associated with the arcs on the construction graph, but in ACO-E it is associated
with the nodes of the construction graph. This gives pheromone values i for each ci  C.
The pheromone for each i is initialised to a value 0 given by
0 =

1
n |SCORE (P + )|

.

(2)

In this formula, n is the number of variables that are in the data, SCORE is the objective function
f , as defined in Section 5.2 and P + is the best-so-far solution. At the start of the algorithm, this is
initialised to that found by a greedy search starting from the empty graph.
In order that the pheromone may change to reflect the tours of ants, pheromone update rules are
given. Similar to ACS, there is a local evaporation rule, whereby pheromone is removed from a path
as an ant traverses it
m  (1  ) m + 0
This shows the effect of the parameter , which is the pheromone evaporation and deposition rate.
With this formula, there are implicit bounds on how high and low the pheromone at each component
can get. Also similar to ACS, there is a global pheromone update rule that deposits new pheromone
on the best-so-far path
fi
fi
m  (1  ) m + / fiSCORE P + fi
408

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

This occurs at the end of a run of ants. Again, SCORE and P + are defined as in Equation 2. Also
again, this formula implements implicit limits on the values that pheromone can take.
5.2.4 P ROBABILISTIC T RANSITION RULE
In choosing which component to visit next given a particular state, an ACO algorithm utilises a
probabilistic transition rule. This rule normally uses values given by the heuristic and pheromone to
inform the choice of which node to pick. The actual choice is random and is based on a distribution
given by the heuristic and pheromone of each possible choice. In ACO-E, the probabilistic choice
rule is given by a pseudo random proportional choice rule, very similar to the one used in ACS. This
type of rule allows the balance between exploration and exploitation to be varied. Being able to
change this balance is important, as it has been shown to produce quite different results (Dorigo &
Sttzle, 2004). An ant chooses component cm , where m is given by
(
arg maxmN (x) m [m ] , if q  q0
m
random proportional,
otherwise.
In this formula, N (x) is the set of components that an ant at state x can move to, given the problem
constraints . The rule is pseudo-random proportional, because it sometimes behaves in a manner
that is not random. A random number q is drawn uniformly in the range [0, 1]. If this number is
less than or equal to a parameter q0 , then the rule behaves greedily; the best move possible is taken
dependent on the value of m [m ] for each component cm . Here, m and m are the pheromone and
heuristic as explained previously and  is a parameter that says how much to favour the heuristic
over the pheromone.
If the number q is greater than q0 than a random proportional rule is used to select which
component to visit next. The probability that the ant will visit component cm is given by pm , where
pm =

m [m ]
  ,
N (x)  

m  N (x).

(3)

It can be seen that the probability that an ant moves to component cm is directly given by m [m ] ,
normalised over the other possible moves so that it is in the range [0, 1].
5.2.5 P ROPERTIES OF A NTS
In terms of the ants used to construct solutions, the following properties of ant k should be noted:
 The memory Mk can be equated to the current state of the problem given by ant k. From this,
the current CPDAG can be constructed in order to implement the constraints , compute the
heuristic values , evaluate the current solution and lay pheromone on the tour. In practice, the
current CPDAG is normally kept in order to avoid having to recompute it at every step.
 The start state xsk is given by the empty sequence hi, i.e. the empty CPDAG.
 The single termination condition ek , is to stop the tour when no improvement in score is
possible.
 The neighborhood N k (x) is the set of all valid moves given the current CPDAG.
409

fiDALY & S HEN

5.2.6 L OCAL S EARCH P ROCEDURE
As is often the case with ACO algorithms, ACO-E can use a local search procedure at intermediate
points throughout the run of the algorithm and at the end. This local search procedure can be used
to quickly bring a solution to a local maximum. With the current heuristic and the standard local
search that would be used in these circumstances  greedy search with the operators defined in Table
2, known here as GREEDY-E  local search would provide no additional benefit over the solution
found by an ant. Nevertheless, the local search was put in the algorithm in the case that the problem
heuristic was implemented differently. An example of this would be a static heuristic obtained by
scoring operations on an empty graph. Since this is invariant over the algorithm run, it would only
need to be calculated once at the start of the run.
5.3 Description of ACO-E
This section will focus on giving an algorithmic description of ACO-E. This is done in conjunction
with the pseudo code given in Algorithms 1 and 2. ACO-E takes as input a number of parameters and
returns the best PDAG found, according to a scoring criterion SCORE , that is defined as the objective
function f . It is assumed that scoring criteria generally give negative values; the higher the value,
the better the model. This is the case of most of the standard criteria as discussed in Section 2. The
meaning of the parameters is as follows:
O This is a set of operators that can modify the current PDAG state in the search. Examples of these
are the ones given in Table 2, e.g. InsertU, DeleteU, etc. However, other operators could be
used, e.g. those of Munteanu and Cau (2000) and Munteanu and Bendou (2001).
tmax This is the number of iterations of the algorithm to run. At each iteration, a number of ants
construct solutions. Pheromone deposition happens after all the ants have finished their tours.
tstep This is the gap, in iterations, between which local search procedures are run. If set so that
tstep > tmax , then local search only happens at the end of the algorithm run.
m This is the number of ants that run at each iteration.
 This, a value in [0, 1], is the rate at which pheromone evaporates and is deposited. It is used in
both the pheromone evaporation and pheromone deposition rules in Section 5.2.3.
q0 This, a value in [0, 1], gives the preference of exploitation over exploration. It is used in the
pseudo-random probabilistic transition rule as explained in Section 5.2.4.
 This exponent gives the relative importance of the heuristic over the pheromone levels in deciding
the chance that a particular trail will be followed. It is used in the pseudo-random probabilistic
transition rule in Section 5.2.4.
n This is the number of nodes in the PDAG.
There are also other variables in the algorithm. These include:
P + the best-so-far PDAG;
Path+ the best-so-far path;
410

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Algorithm 2 ANT-E
Input: Operators O, , q0 , 
Output: PDAG P, Path Path
Empty PDAG P, Empty path Path
while true do
M  All possible moves from P using O
if |M| = 0  maxlM TOTAL - SCORE(l,  )  0 then
return (P, Path)
end if
q  random number in [0, 1)
if q  q0 then
l  arg maxlM TOTAL - SCORE(l)
else
l  random according to Equation 3
end if
m  (1  ) l + 0
P  apply l to P
Path  append l to Path
end while
P empty the empty PDAG; and
Pathempty the empty path, i.e. the path with no entries.
In starting the algorithm, a greedy search (called GREEDY-E) is performed. This is a search through
the space of equivalence classes using the framework and operators given by Chickering (2002a) and
shown in Table 2. It gives a starting best-so-far graph and path from which the search can proceed.
Pheromone levels for each solution component are then initialised to 0 = 1/n |SCORE (P + )|. The
main loop of the algorithm then begins for tmax iterations. At each iteration, m ants perform a search,
given by algorithm ANT-E, shown in Algorithm 2. Also, for every tstep iterations, a local search is
performed on the PDAGs returned from ANT-E, to try and improve results. Using local search as
part of an ACO algorithm is a very common technique (Dorigo & Sttzle, 2004), as it is a easy way
to obtain good results with little effort. After the m ants have traversed the graph, the best graph
Algorithm 3 TOTAL - SCORE
Input: Move l, 
Output: Score s
(
l (l )
return s such that s =
0

if l > 0
otherwise

and path are selected from the best-so-far graph and path and the ones found by each of the ants in
the current iteration. Finally, the global pheromone update lays and evaporates pheromone on the
best-so-far path.
The ANT-E algorithm creates a PDAG by examining the various states that may be proceeded to
from the current state, given a set of operators that may act on the current PDAG. It then selects a
411

fiDALY & S HEN

Figure 7: Bayesian network used in sample trace
new state based on a random-proportional choice rule. The parameters to the function have the same
description as the ones to the ACO-E function.
Starting out, the algorithm constructs an empty PDAG. Then at each stage a move is made to
a new PDAG, which can be reached by applying one of the operators in O. Initially, a number is
given to each move by TOTAL - SCORE, shown in Algorithm 3. This number represents a weight given
to each move l depending on the current pheromone associated with making that move l , and the
heuristic associated with making the move l . This heuristic is given by the increase in score obtained
by taking that move, higher overall scores meaning better solutions. If there can be no increase in the
score, the ant stops and returns the solution P and the path followed. Otherwise there is a possible
move and the ant decides how to make it. Firstly a random number q is obtained. If it is less than a
specified value q0 , then the best move is taken. If it is greater than q0 , then a random proportional
choice is made, with the probability of better moves being higher. After this, a local pheromone
update is applied to the path just taken, the path is updated with the new location at the end and the
current state is updated to become the new state given by l. Note that applying a move to a CPDAG
to change state implies that the resulting PDAG will be extended to a DAG by a suitable method
(e.g., that of Dor & Tarsi, 1992) and this DAG be changed back to a CPDAG. Details can be found in
the article of Chickering (2002a).
5.4 Trace of Algorithm Execution
As a simple example of the execution of the ACO-E algorithm, a trace of its behavior during an
actual execution will be given during this section. Consider the Bayesian network in Figure 7. This
network is fully specified, with a DAG structure and parameters given in the form of conditional
412

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION



q0



tmax

m

0.1

0.1

1.0

1

2

Table 3: Parameters for sample trace
Move





1

InsertU(0,1)
InsertU(0,2)
InsertU(1,2)

0.00312
0.00312
0.00312

-0.21565
34.6527
11.2204

2

InsertU(0,1)
InsertU(1,2)
DeleteU(0,2)

0.00312
0.00312
0.00312

-0.21565
11.2204
-34.6527

3

InsertU(0,1)
DeleteU(0,2)
DeleteU(1,2)
MakeV(0,1,2)

0.00312
0.00312
0.00312
0.00312

0.37742
-34.6527
-11.2204
0.59307

Move





4 (Ant 1)

InsertU(0,1)
DeleteD(0,2)
DeleteD(1,2)
ReverseD(0,2)
ReverseD(1,2)

0.00312
0.00312
0.00312
0.00312
0.00312

-0.21565
-35.2457
-11.8134
-0.59306
-0.59307

4 (Ant 2)

DeleteU(0,1)
DeleteU(0,2)
DeleteU(1,2)

0.00312
0.00312
0.00312

-0.47742
-35.2457
-11.8134

Table 4: Values corresponding to the moves in Figure 8
probability tables. As can be seen, the variable 0 can take on the values a and b, the variable 1 can
take on the values c and d and the variable 2 can take on the values e, f and g.
For the purposes of this demonstration, 90 data were sampled from this Bayesian network. The
ACO-E algorithm was then started with the parameters set as in Table 3. The PDAG found from the
initial GREEDY-E run was the same as the sample Bayesian network structure. P + was then set to
this PDAG. The score of this PDAG was 106.918. 0 was then set to 0.00312. Because tmax was set
to 1, there was only one iteration of the algorithm. On this iteration, two ants constructed solutions
using the ANT-E procedure. The trace of how these ants proceeded is shown in Figure 8 and Table
4. In the diagram, the sequence of moves can be seen along with the value of q at each step. The
score of the final network for each ant is also shown. In the table, the possible moves at each point
for each ant are shown, along with the pheromone  and heuristic value . It should be noted that
the pheromone is the same for all moves, as this was the very start of the ACO-E algorithm and no
pheromone deposition had occurred. At each move, pheromone evaporation occurs, but once more,
no difference is found because all the pheromone values are equal to 0 .
After the two ants finish their run, the best solution is chosen as variable b. In this case it is that of
Ant 1, with a score of -106.918. This is then compared to the score of P + . Because the two structures
are the same, there is no score difference and hence no change occurs. Pheromone deposition then
occurs on the moves that made up P + , i.e. the moves in Path+ . In this case, the pheromone for
InsertU(0,2), InsertU(1,2) and MakeV(0,1,2) got updated to (1  0.1)  0.00312 + 0.1/ |106.918| =
0.00374. Since tmax was set to 1, there are no more iterations and the algorithm returns P + .

413

fiDALY & S HEN

Figure 8: Trace of progress in ANT-E
414

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

5.5 Implementation Issues
In implementing the algorithms given in this paper, care must be taken to avoid long run times.
Firstly, caching the score of a node given its parents is a simple technique that can greatly improve
performance. Secondly, caching the results of the validity tests needed to check which moves are
applicable at a certain state, can again increase performance dramatically. However this technique is
not as easy to implement as it might appear (Daly, Shen, & Aitken, 2006).
Care must also be taken in implementing the pheromone for the moves. Traditionally, matrices of
values are used, which allow fast access and updating. However in the case of the MakeV operator,
which takes three indices, a three dimensional matrix would be needed. This would quickly become
infeasible as the problem size grew, especially as only some of the entries would be used. This would
be due to the algorithm never getting to those states. Instead a structure such as a map can store this
information. A map can scale linearly with the number of elements actually being used. If the map is
implemented as a tree, entries can be accessed in logarithmic time and if a hash table is used, access
can be in constant time.

6. Experimental Methodology
This section is concerned with testing the ACO-E algorithm presented in Section 5 and the evaluation
of the results produced. In order to facilitate understanding of the experimental methodology used,
the section will be structured as follows.
Firstly, an account will be given of the objects on which the testing will be performed. These
objects are six gold-standard Bayesian networks that are well known in the field. The various
properties of the networks will be discussed. From these networks data can be sampled and it is this
data that can be used as input to the algorithms.
Then, experiments using the ACO-E algorithm will be shown. The methodology used in running
the experiments will be defined, along with a description of the various evaluation criteria. These
involve criteria well known in the field. Two different sets of experiments will be presented, one
focused on the comparison of ACO-E against similar algorithms, the other a comparison of ACO-E
against state-of-the-art algorithms. Also, the behavior of the ACO-E algorithm for different parameters
will be shown.
6.1 Standard Bayesian Networks
In this section a set of six gold-standard Bayesian networks will be presented. These networks will be
the basis of the testing that will be showcased later. Various properties of the networks will be given,
covering: the number of nodes of the structure, the number of edges in the structure, the average
number of in edges etc.
6.1.1 S IX G OLD -S TANDARD N ETWORKS
In the experiments shown in the next section, six gold-standard networks are used. These are the
ALARM (Beinlich, Suermondt et al., 1989), Barley (Kristensen & Rasmussen, 2002), Diabetes
(Andreassen, Hovorka, Benn, Olesen, & Carson, 1991), HailFinder (Abramson, Brown, Edwards,
Murphy, & Winkler, 1996), Mildew (Jensen, 1995) and Win95pts networks (Microsoft Research,
1995). These networks were chosen because they covered a wide range of domains, were easily

415

fiDALY & S HEN

Nodes
Edges
Mean In-Degree
V-Structures
V-Struct/Nodes

Alarm

Barley

Diabetes

HailFinder

Mildew

Win95pts

37
46
1.24
26
0.70

48
84
1.75
66
1.38

36
48
1.33
21
0.58

56
66
1.18
37
0.66

35
46
1.31
37
1.06

76
112
1.47
135
1.78

Table 5: Bayesian network properties
available and all contained discrete attributes. The last property was important because the scoring
criterion that would be used in the experiments is implemented over multinomial random variables.
Various properties of these Bayesian networks are shown in Table 5. In this table, Nodes and
Edges specify the number of nodes and edges respectively in the graph. The Mean In-Degree is the
average number of arcs coming into a node in the graph. This is equal to the Mean Out-Degree and
the number of edges divided by the number of nodes. Finally, V-Structures and V-Struct/Nodes show
the amount of v-structures in the graph and the amount of v-structures divided by the number of
nodes.
6.2 Methodology
This section contains details of the experiments performed using the ACO-E algorithm described in
Section 5. Firstly, the methodology used in running the experiments will be presented. This includes
an analysis of the needed outcomes, the design of five experimental conditions and an explanation of
the evaluation criteria.
6.2.1 E XPERIMENTAL D ESIGN
In designing an experimental methodology to test the efficacy of the ACO-E algorithm, three different
outcomes were desired.
 The first was to analyze the behavior of the algorithm as a function of the parameters and
the test networks. This is needed in order to try and understand the range of values in which
parameters might be useful and to show the effect of the ACO behavior on outcomes.
 The next desired outcome was to test ACO-E against other similar algorithms. To this end,
ACO-E was tested against another ACO algorithm and algorithms that searched in the space of
equivalence classes.
 Finally the last desired outcome was to test ACO-E against state-of-the-art algorithms from
the literature. These tests would show the comparative usefulness of ACO-E against other
well-known and good-performing methods.
In order to obtain these outcomes, various experimental conditions were designed, which will be
explained below.
The Scoring Function For these experiments, it was decided to use the BDeu criterion invented by
Buntine (1991) and described in Section 2. According to the study by Shaughnessy and Livingston
416

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

(2005), BDeu had the best tradeoff between precision and recall of edges (confusingly BDeu is
called BAYES in their study, with BDeu in their study meaning the K2 metric). This criterion gives a
fully Bayesian score, with the assumption of Dirichlet parameter priors and a uniform prior over all
possible states of the joint distribution given the prior network.To fully specify the BDeu criterion,
two pieces of information are needed. First is a prior on structures P (G). This could be a uniform
prior, such that all structures have the same P (G). Another method shown by Heckerman, Geiger
et al. (1995) was to have an expert specify a structure, and have a method that penalises differences
between the experts structure and a candidate structure.
The second piece of information needed is the equivalent sample size, N 0 , a parameter that
encodes the confidence in the prior parameters and prior structure. Selecting this value can be
troublesome (Silander, Kontkanen, & Myllymaki, 2007; Steck & Jaakkola, 2003), but reasonable
values in the range [1, 10] often work well.
In recognition that simpler structures are often more appealing, the prior was specified by the
method shown by Heckerman, Geiger et al. (1995). In their formulation, two objects are specified; a
prior structure G prior and the prior distribution given as:
P (G) = c  ,
where c is a normalisation constant that can be ignored,  is a parameter that needs to be specified
and  is given by the formula
n

 =  i ,
i=1

where i is the symmetric difference of the parent set for node i between G prior and G.
Condition 1 Experimental condition 1 was designed to analyze the behavior of ACO-E across
different parameters and to compare against other similar algorithms. These algorithms were ACOB (de Campos, Fernndez-Luna et al., 2002), EPQ (Cotta & Muruzbal, 2004; Muruzbal &
Cotta, 2004) and a greedy search in the space of equivalence classes using Chickerings operators
(Chickering, 2002a) (called GREEDY-E here). A description of these will now be given.
ACO-B ACO-E is based in part on the construction of this algorithm and so there are some similarities. ACO-B is an ACO based algorithm that provides a search through the space of DAGs,
with each of its moves being the addition of a directed arc to the current DAG. A more detailed
description is given in Section 5.1.2.
EPQ This method uses an evolutionary programming algorithm that performs a search over the
space of equivalence classes of DAGs. Like Chickering (2002a), they explicitly use CPDAGs
(defined in Section 3.1) to represent the individuals, i.e. equivalence classes of DAGs. At each
generation, from a population of P, members of the population are selected using a binary
tournament and mutated using the operators of Chickering. The best P out of the 2P selected
are then put forward into the next round, for T rounds.
GREEDY-E This algorithm uses the operators of Chickering to perform a greedy search in the space
of CPDAGs. The results of tests performed by Chickering showed that the search generally
performed better than search in the space of DAGs.

417

fiDALY & S HEN

Parameter

Value

N0

4
0.2
200
5, 7, 10, 12, 15, 20
0.0, 0.1, 0.2, 0.3, 0.4, 0.5
0.7, 0.75, 0.8, 0.85, 0.9, 0.95
0.0, 0.5, 1.0, 1.5, 2.0, 2.5


tmax
m

q0


Table 6: Parameter values for testing ACO-E
For the experiments in this section, testing involved the six standard networks presented in Section
6.1.1. The BDeu scoring criterion was used, and as suggested by Kayaalp and Cooper (2002) and by
Heckerman, Geiger et al. (1995), an equivalent sample size of 4 was used for the parameter priors.
Also an empty structure prior with  as defined by Heckerman, Geiger et al. (1995) was used. For
each individual run, 10,000 data were sampled from the network and used to construct the scoring
function. Then for each combination of values for the parameter settings of , q0 ,  and m, a run of
the experiment was made for both the ACO-E and ACO-B algorithms. The range of values that these
parameters were taken from are shown in Table 6.
In total this gave 1296 runs for each algorithm, for each network. As a consequence, this gave
a total of 216 results for each setting of a parameter. In order to match this number of runs, the
EPQ and GREEDY-E algorithm were also run 216 times each. It should be stressed that each run
of ACO-E using a particular combination of parameters and each run of EPQ and GREEDY-E was
done with a different data set sampled from the network. This technique guards against overfitting
the parameters to a particular data set. It should also be noted that for each algorithm, a limit of 5
parents was allowed for a node, in order to speed up algorithm execution.
Condition 2 Experimental condition 2 was designed to test ACO-E against other state-of-the-art
Bayesian network structure learning algorithms. For these purposes the results found in the study
conducted by Tsamardinos, Brown, and Aliferis (2006) was used. This study produced a thorough
comparison of many different algorithms and made the results available, which allows the results
for ACO-E to be compared against all of the algorithms used in the study. The various parameters
used for ACO-E (that had equivalent parameters in other algorithms) were kept as close as possible
to those used by Tsamardinos, Brown et al. The various algorithms that were compared against
were: the max-min hill-climbing algorithm (MMHC) (Tsamardinos, Brown et al., 2006), the optimal
reinsertion algorithm (OR) (Moore & Wong, 2003), the sparse candidate algorithm (SC) (Friedman,
Nachman, & Peer, 1999), a greedy search using the three standard operators as in Table 1 (GS), the
PC algorithm (PC) (Spirtes, Glymour et al., 2000), the three phase dependency analysis algorithm
(TPDA) (Cheng, Greiner, Kelly, Bell, & Liu, 2002) and the greedy equivalent search algorithm
(GES) (Chickering, 2002b).
For these experiments, testing involved four of the six standard networks presented in Section
6.1.1; Alarm, Barley, HailFinder and Mildew. These networks were used as the experiments of
Tsamardinos, Brown et al. did not use the other two (Diabetes and Win95pts). The other networks
shown in the paper of Tsamardinos, Brown et al. were not used as they were not available in a usable

418

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Parameter
Value

N0
10


0.09

tmax
200

m
20


0.4

q0
0.75


0.75

Table 7: Parameter values for testing ACO-E


q0


Alarm

Barley

Diabetes

HailFinder

Mildew

Win95pts

0.4
0.8
0.5

0.4
0.8
1.0

0.4
0.7
1.0

0.2
0.8
1.0

0.4
0.7
0.5

0.2
0.95
2.5

Table 8: Tuned parameters for ACO-E
format. For each run of the algorithm, 5000 data were generated by sampling the particular networks
in question. This was chosen as opposed to the 10,000 data in Condition 1, as this was the amount
chosen by Tsamardinos, Brown et al.
As in Condition 1, the BDeu scoring function was used. The parameter values of this function
and the ACO-E parameters are shown in Table 7. The ACO-E parameter values were chosen as they
represented reasonable values that should perform well on most instances. Each experiment was run
100 times for each network.
Condition 3 Condition 3 was designed with a number of objectives in mind. These were:
 examine the effect of different sample sizes on ACO-E output;
 use a separate test sample in scoring networks output from ACO-E; and
 examine the complexity of ACO-E by noting the number of statistics computed during a run.
In order to achieve these objectives, new experiments were run. In these experiments, the parameters
were set by examining the output of the experiments of Condition 1  these outputs can be seen
in Section 7.1. The optimum value for the parameters was chosen by finding the best combination
from Condition 1 (note that Table 10 shows the average BDeu score for each parameter setting). The
experiments were performed across the six standard networks, with five different sample sizes  100,
500, 1000, 5000 and 10000. The various parameters were set as in Table 8.
Each combination of network and sample size was run 100 times. The various other parameters
were set as m = 20 and tmax = 200. The BDeu scoring criterion was used, with an empty structure
prior, an equivalent sample size N 0 of 4 and a value of  = 0.05. The meaning of the BDeu parameters
has been described above.
Condition 4  Tuned Metaheuristics In order to be able to compare ACO-E to the other metaheuristics described in Condition 1, experiments were run with tuned parameters. The experiments
were performed across the six standard networks, with a sample size of 10000. For ACO-B, the
various parameters were set as in Table 9. These combination of parameters gave the best BDeu
score for ACO-B in Condition 1. GREEDY-E and EPQ have no meaningful parameters to tune.
Each experiment was run 100 times. For ACO-B, the various other parameters were set as m = 20
and tmax = 200. Similar to Condition 3, the BDeu scoring criterion was used, with an empty structure
419

fiDALY & S HEN


q0


Alarm

Barley

Diabetes

HailFinder

Mildew

Win95pts

0.1
0.85
2.0

0.5
0.7
2.0

0.5
0.8
2.0

0.4
0.9
2.0

0.4
0.7
2.5

0.1
0.95
2.5

Table 9: Tuned parameters for ACO-B
prior, and equivalent sample size N 0 of 4 and a value of  = 0.05. In these runs, a limit of 7 parents
was allowed for a node, as opposed to the 5 of Condition 1.
Condition 5  Examining the Applicability of ACO-E Experimental Condition 5 was designed
to test the applicability of ACO-E to given data sets. To achieve this, a simple procedure was designed
to indicate to what level the ACO-E algorithm would perform better than a simple greedy search.
This procedure is based on the GREEDY-E algorithm mentioned in Condition 1. The procedure is as
follows.
An original data set is sampled with replacement and the GREEDY-E algorithm is run. For the
purposes of these experiments, this original data set was sampled from a Bayesian network. When
the algorithm terminates, the number of v-structures in the returned structure is counted and divided
by the number of variables in the data set. This statistic is noted and the procedure starts again, with
a new set of resampled data. The whole procedure is repeated until a confident prediction of the
normalized v-structure mean can be made. The mean value obtained can be used as a measure of
the complexity of the search space. A higher value indicates more v-structures and hence a more
complicated space.
For the purposes of this paper, the BDeu scoring function with an equivalent sample size N 0 of 4
and equal structure priors was used. Test were performed across each of the six standard networks
and at sample sizes of 100, 500, 1000, 5000 and 10000. 100 resamplings were used in each case.
6.2.2 E VALUATION C RITERIA
In the running of these experiments, various scoring metrics were picked to ascertain how well certain
algorithms behaved. These were: the scoring function used in running the experiments, a test scoring
function that was based on a different sample, the structural Hamming distance (SHD), the number
of scoring function evaluations and the number of distinct scoring function evaluations. These are
explained below.
The Scoring Function For all experiments, the BDeu scoring function was used with differing
parameters, depending on the experimental condition. Because these parameters were uniform given
the condition, the score value of a Bayesian network structure could be used to compare the results
of different algorithms. In terms of the BDeu score, this means that the higher the average score
achieved, the better the results.
Test Scoring Function As well as the scoring function used in the running of the algorithm, a
separate BDeu scoring function was defined, using an independent, same-size sample from the
network being used.

420

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Structural Hamming Distance In order to provide an objective measure of network structure
reconstruction behavior and to compare results against the work of Tsamardinos, Brown et al.
(2006), the value of the structural Hamming distance (SHD) metric is given. This measures the
difference between the learned network and the gold-standard generating network. Both networks
are transformed from DAG to CPDAG (if not already in this representation) and penalties are given
for the number of missing and extra edges and for incorrectly directed arcs.
Score Function Evaluations In order to estimate the complexity of running the ACO-E algorithm,
two statistics were measured. The first statistic is the number of times the scoring function has been
evaluated up to a particular point in time.
Distinct Score Function Evaluations The next statistic is the number of times a distinct scoring
function evaluation has occurred, i.e. the number of times the arguments to the scoring function are
different. This statistic is often wildly different to the total number of scoring function evaluations
and is often a better measure of complexity, as caching of evaluations is a standard technique to speed
up algorithm runs.

7. Experimental Results
In this section the results of experiments performed according to the methodologies given in Section
6.2 will be presented. In 6.2, five experimental conditions were given. The first dealt with analyzing
the behavior of ACO-E with respect to its parameters and in comparison to other metaheuristic
algorithms that shared similar behavior. The second condition dealt with comparing ACO-E to other
state-of-the-art Bayesian network structure learning algorithms. The third condition focused on the
effect of sample sizes on output quality, the behavior of a scoring function defined on a separate
test set and the computational complexity of the algorithm. The fourth looked at the behavior of the
metaheuristic algorithms with tuned behavior. Finally the fifth condition dealt with the situations
when ACO-E should be used. These results will be presented in this order, followed by a discussion
and interpretation of these results.
7.1 Condition 1
The results of the runs using experimental condition 1 are shown in two sets, which reflect how they
will be analyzed later. Firstly, detailed results for ACO-E are shown in Tables 10 and 11. In these
tables, the figures given are the results over all other parameters; e.g. the figure for  = 0.1 is given
by calculating the mean and standard deviation over all results with  = 0.1. In this case, the size
of the samples will be 216, and will be calculated over all combinations of the other parameters. It
should be noted that the specific values of  = 0 and  = 0 are special cases. When  = 0, there is no
pheromone evaporation and no pheromone deposition on the graph; i.e. pheromone plays no part in
the algorithm. With  = 0, there is no heuristic used whilst the ants traverse the construction graph.
The comparative results involving ACO-E, ACO-B, GREEDY-E and EPQ are shown in Table
12 and Figures 9 and 10. These show the behavior of ACO-E against other algorithms, both as a
function of the algorithm iteration and as a final value. In these results, the iterations figure is that for
ACO-E and ACO-B. The EPQ iteration number is three times that of the shown iteration. As such,
whilst ACO-E and ACO-B were run for 200 iterations, EPQ was run for 600 and the results scaled
to 200. This can be done, as the concept of an iteration in one framework does not translate well in
terms of time to another framework.
421

fiDALY & S HEN

7.2 Condition 2
The results of the experiments conducted to experimental Condition 2 are illustrated here. The second
set of comparisons involved ACO-E against other state-of-the-art Bayesian network structure learning
algorithms.
The results of this comparison are shown in Table 13. The acronyms specified are as given by
Tsamardinos, Brown et al. (2006) and were discussed before in Section 6.2.1. Some of the results as
supplied by Tsamardinos, Brown et al. are missing and are marked by N/A in Table 13. If a result is
out of the range of most others, it is represented as a number stating the median.
7.3 Condition 3
The results of the experiments conducted according to Condition 3 are shown here. This set of
experiments was designed to show the effects of sample size on ACO-E output and also provide a
measure of the computational complexity of the algorithm.
The SHD results of the runs after 200 iterations can be seen in Table 14, whilst the score results
after 200 iterations are in Table 15. Table 16 shows the score results from a different test sample.
The remaining results from these experiments are shown in Figures 11 and 12. These show the
total number of score evaluations and distinct number of score evaluations respectively, for runs of
the ACO-E algorithm.
7.4 Condition 4
Experimental Condition 4 was used to compare ACO-E against the metaheuristic algorithms used in
Condition 1 when the parameters had been tuned to the best combinations from Condition 1. The
other algorithms were ACO-B, EPQ and GREEDY-E. These results are consolidated into Table 17
which show the results after the runs have finished.
7.5 Condition 5
The results of the experiments under Condition 5 are shown in Table 18. With these experiments,
multiple searches were performed using the GREEDY-E algorithm, with data being resampled for
each experiment. Experiments were performed 100 times across all combination of the test networks
and sample sizes.

422

fi
Alarm
Barley (105 )
Diabetes (105 )
HailFinder (105 )
Mildew (105 )
Win95pts (104 )

0.0

0.1

0.2

0.3

0.4

0.5

1.0383  0.0037
5.0756  0.0136
1.9394  0.0032
4.9207  0.0039
4.5426  0.0096
9.4322  0.0448

1.0385  0.0036
5.0697  0.0039
1.9391  0.0034
4.9206  0.0038
4.5412  0.0091
9.4169  0.0433

1.0387  0.0035
5.0702  0.0096
1.9394  0.0029
4.9204  0.0042
4.5417  0.0101
9.4086  0.0452

1.0385  0.0037
5.0696  0.0039
1.9386  0.0034
4.9210  0.0034
4.5401  0.0094
9.4125  0.0454

1.0388  0.0037
5.0699  0.0041
1.9395  0.0034
4.9202  0.0040
4.5388  0.0083
9.4154  0.0457

1.0380  0.0038
5.0699  0.0041
1.9393  0.0035
4.9207  0.0037
4.5395  0.0090
9.4210  0.0468

q0
(105 )

423

Alarm
Barley (105 )
Diabetes (105 )
HailFinder (105 )
Mildew (105 )
Win95pts (104 )

0.7

0.75

0.8

0.85

0.9

0.95

1.0385  0.0035
5.0703  0.0066
1.9391  0.0035
4.9207  0.0039
4.5362  0.0069
9.4200  0.0453

1.0388  0.0035
5.0704  0.0065
1.9391  0.0033
4.9208  0.0035
4.5378  0.0074
9.4183  0.0441

1.0383  0.0035
5.0705  0.0060
1.9393  0.0032
4.9208  0.0038
4.5389  0.0084
9.4199  0.0462

1.0382  0.0035
5.0708  0.0057
1.9393  0.0035
4.9205  0.0038
4.5410  0.0098
9.4192  0.0481

1.0386  0.0039
5.0710  0.0073
1.9393  0.0035
4.9204  0.0040
4.5430  0.0097
9.4160  0.0468

1.0383  0.0040
5.0720  0.0126
1.9390  0.0030
4.9204  0.0040
4.5472  0.0092
9.4130  0.0439

0.0

0.5

1.0

1.5

2.0

2.5

1.0387  0.0036
5.0775  0.0121
1.9389  0.0033
4.9212  0.0039
4.53780.0075
9.4515  0.0505

1.0378  0.0038
5.0694  0.0043
1.9390  0.0034
4.9205  0.0037
4.5371  0.0075
9.4092  0.0404

1.0383  0.0036
5.0689  0.0035
1.9394  0.0034
4.9203  0.0040
4.5392  0.0090
9.4135  0.0420

1.0386  0.0035
5.0696  0.0040
1.9393  0.0032
4.9206  0.0038
4.5404  0.0094
9.4101  0.0385

1.0387  0.0040
5.0697  0.0055
1.9394  0.0032
4.9205  0.0038
4.5440  0.0102
9.4116  0.0444

1.0387  0.0034
5.0698  0.0097
1.9391  0.0035
4.9205  0.0040
4.5456  0.0090
9.4106  0.0427


(105 )

Alarm
Barley (105 )
Diabetes (105 )
HailFinder (105 )
Mildew (105 )
Win95pts (104 )

m
(105 )

Alarm
Barley (105 )
Diabetes (105 )
HailFinder (105 )
Mildew (105 )
Win95pts (104 )

5

7

10

12

15

20

1.0383  0.0036
5.0721  0.0120
1.9392  0.0031
4.9202  0.0041
4.5440  0.0097
9.4201  0.0452

1.0386  0.0036
5.0707  0.00061
1.9392  0.0036
4.9209  0.0037
4.5427  0.0097
9.4190  0.0452

1.0381  0.0037
5.0709  0.0083
1.9391  0.0032
4.9201  0.0039
4.5409  0.0093
9.4178  0.0457

1.0389  0.0037
5.0704  0.0066
1.9392  0.0032
4.9210  0.0040
4.5392  0.0092
9.4188  0.0458

1.0384  0.0039
5.0704  0.0061
1.9391  0.0033
4.9204  0.0036
4.5386  0.0082
9.4164  0.0462

1.0384  0.0036
5.07050.0060
1.9394  0.0034
4.9210  0.0037
4.5385  0.0085
9.4145  0.0467

Table 10: Mean and standard deviation of the BDeu score for ACO-E for each parameter setting

L EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

(105 )

fiDALY & S HEN


0.0

0.1

0.2

0.3

0.4

0.5

Alarm

6.9  4.9

5.6  3.1

6.0  3.2

5.6  3.3

5.9  3.0

5.5  3.0

Barley

56.4  10.8

52.8  3.9

53.0  4.1

53.2  4.4

52.6  4.0

52.9  4.8

Diabetes

63.5  5.8

65.5  5.3

65.0  5.4

65.1  5.6

64.2  5.4

63.7  4.8

HailFinder

50.6  6.9

50.5  6.8

51.0  7.8

51.8  7.8

51.8  6.7

51.1  7.9

Mildew

25.7  5.8

22.6  5.0

22.8  5.1

22.0  4.9

21.4  4.7

21.9  4.8

Win95pts

94.6  27.7

83.3  24.3

81.7  20.3

81.9  22.9

81.9  24.2

83.5  21.9

0.85

0.9

0.95

q0
0.7

0.75

0.8

Alarm

5.2  2.5

5.6  3.1

5.4  3.0

6.1  3.7

6.4  4.2

6.7  4.1

Barley

53.9  5.9

53.6  5.8

53.35.4

53.4  5.9

53.1  5.8

53.6  7.2
68.1  4.7

Diabetes

62.1  4.8

62.6  4.9

63.4  4.9

64.7  5.4

66.1  5.3

HailFinder

52.1  7.3

51.9  7.5

51.5  8.2

50.7  7.1

50.6  7.7

50.0  5.9

Mildew

20.2  3.8

21.1  4.7

21.5  4.8

22.6  5.1

24.3  5.4

26.6  4.9

Win95pts

90.3  23.5

88.1  24.5

84.9  22.6

83.2  22.5

81.0  22.2

79.3  27.1

1.5

2.0

2.5


0.0

0.5

1.0

Alarm

7.4  5.1

4.3  1.1

4.9  2.4

5.4  2.8

6.2  3.6

7.2  3.7

Barley

61.4  9.0

52.0  3.9

51.93.0

51.7  3.3

51.9  3.3

52.0  3.7

Diabetes

64.3  4.9

64.3  5.5

64.2  5.5

64.7  5.1

64.6  5.9

64.8  5.5

HailFinder

52.2  7.0

52.0  6.5

51.5  6.7

50.1  8.0

50.3  8.0

50.5  7.5

Mildew

20.9  4.9

20.9  4.0

21.9  5.0

22.4  5.1

24.6  5.4

25.7  5.2

Win95pts

109.1  28.6

89.6  23.9

79.8  17.9

77.0  17.2

77.1  19.3

74.4  15.5

12

15

20

m
5

7

10

Alarm

7.1  4.3

6.6  3.8

5.9  3.5

5.2  2.8

5.7  3.6

5.1  2.4

Barley

54.3  7.3

52.8  5.3

53.8  6.6

53.2  5.7

53.7  5.8

53.15.1

Diabetes

66.2  5.1

65.8  5.9

64.1  5.4

64.5  5.6

63.5  5.4

62.8  4.7

HailFinder

50.5  7.2

50.5  6.7

51.0  6.5

51.8  7.0

51.4  8.5

51.6  7.9

Mildew

24.6  5.3

23.9  5.6

22.7  5.5

22.2  4.9

21.6  4.7

21.4  4.7

Win95pts

83.3  23.3

83.0  21.9

85.6  26.2

85.5  22.1

85.5  25.0

84.0  25.5

Table 11: Mean and standard deviation of the SHD for ACO-E for each parameter setting

424

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

ACO-E
Alarm

Barley

HailFinder

Mildew

Win95pts

ACO-B

EPQ

SHD

5.9  3.5

21.9  9.0

11.9  11.9

26.1  13.4

Score (105 )

1.0385  0.0037

1.0389  0.0039

1.0388  0.0038

1.0415  0.0045

SHD

53.5  6.0

104.8  9.7

67.3  21.6

101.4  14.4

5.0708  0.0078

5.2449  0.0124

5.0944  0.0423

5.2354  0.0628

64.5  5.4

69.2  3.0

70.7  8.5

77.2  7.1

1.9392  0.0033

1.9394  0.0033

1.9406  0.0041

1.9457  0.0048

Score

Diabetes

GREEDY-E

(105 )

SHD
Score

(105 )

SHD

51.1  7.3

49.1  0.8

74.1  19.7

82.8  18.2

Score (105 )

4.9206  0.0038

4.9213  0.0036

4.9248  0.0058

4.9481  0.0177

SHD

22.7  5.3

29.3  0.7

36.1  14.0

50.3  13.8

Score (105 )

4.5407  0.0093

4.5531  0.0039

4.5548  0.0170

4.6148  0.0369

SHD

84.5  24.1

104.9  15.5

178.9  58.8

220.1  31.6

Score (104 )

9.4178  0.0457

9.4649  0.0466

9.4589  0.0717

9.9181  0.0970

Table 12: Mean and standard deviation for metaheuristic algorithms from Condition 1 results

ACO-E
MMHC
OR1 k = 5
OR1 k = 10
OR1 k = 20
OR2 k = 5
OR2 k = 10
OR2 k = 20
SC k = 5
SC k = 10
GS
PC
TPDA
GES

Alarm

Barley

HailFinder

Mildew

16.4  4.7
9.6  7.0
27.8  10.0
31.2  11.1
37.8  9.4
21.2  4.6
33.2  5.4
39.4  6.5
34.2  3.6
20.4  11.8
58.8  6.5
15.2  1.5
9.6  1.5
N/A

80.9  5.3
102.6  9.2
109.6  9.5
113.6  15.6
136.4  2.9
120.0  4.5
109.2  16.2
116.8  18.4
129.6  13.1
N/A
143.3  7.3
610.0  10.6
207.2  4.0
159.0  0.0

55.0  5.3
208.0  1.6
190.8  14.1
183.2  14.9
184.6  17.2
184.6  14.5
187.0  15.7
200.8  9.2
194.2  2.5
N/A
204.2  9.9
385.6  12.5
255.4  3.4
154.6  54.3

31.0  3.6
58.4  7.4
70.6  4.2
75.6  6.3
75.0  4.8
69.2  3.3
64.0  4.4
67.4  3.4
N/A
N/A
62.2  12.2
421.2  10.7
97.8  6.8
38.8  0.8

Table 13: SHD mean and standard deviation for state-of-the-art algorithms

425

fiDALY & S HEN

5

x 10
5.05

5

x 10
1.038

5.1
1.04

5.15
1.042

5.2
1.044
1.046

Score

Score

5.25

1.048

5.3
5.35

1.05

5.4

1.052

5.45
ACOE
ACOB
EPQ
GREEDYE

1.054
1.056
0

20

40

60

80

100
120
Iterations

140

160

180

ACOE
ACOB
EPQ
GREEDYE

5.5
5.55
0

200

20

40

60

(a) Alarm

80

100
120
Iterations

140

160

180

200

(b) Barley
5

x 10
4.92

5

x 10
1.938

4.93
1.94

4.94
1.942

4.95

Score

Score

1.944

1.946

4.96
4.97
4.98

1.948

4.99
ACOE
ACOB
EPQ
GREEDYE

1.95

1.952
0

20

40

60

80

100
120
Iterations

140

160

180

ACOE
ACOB
EPQ
GREEDYE

5
5.01
0

200

20

40

(c) Diabetes
5

100
120
Iterations

140

160

180

200

5

x 10
0.94

4.55

0.96

4.6

0.98

Score

Score

80

(d) HailFinder

x 10
4.5

4.65

4.7

1

1.02

ACOE
ACOB
EPQ
GREEDYE

4.75

4.8
0

60

20

40

60

80

100
120
Iterations

140

160

180

ACOE
ACOB
EPQ
GREEDYE

1.04

1.06
0

200

(e) Mildew

20

40

60

80

100
120
Iterations

(f) Win95pts

Figure 9: Scores for metaheuristic algorithm comparison
426

140

160

180

200

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

70

140
ACOE
ACOB
EPQ
GREEDYE

60

ACOE
ACOB
EPQ
GREEDYE

130

Structural Hamming Distance

Structural Hamming Distance

120
50

40

30

20

110
100
90
80
70

10
60
0
0

20

40

60

80

100
120
Iterations

140

160

180

50
0

200

20

40

60

(a) Alarm

80

100
120
Iterations

140

160

180

200

(b) Barley

82

110
ACOE
ACOB
EPQ
GREEDYE

80

ACOE
ACOB
EPQ
GREEDYE

100

Structural Hamming Distance

Structural Hamming Distance

78
76
74
72
70

90

80

70

60

68
50
66
64
0

20

40

60

80

100
120
Iterations

140

160

180

40
0

200

20

40

(c) Diabetes

80

100
120
Iterations

140

160

180

200

(d) HailFinder

80

300
ACOE
ACOB
EPQ
GREEDYE

ACOE
ACOB
EPQ
GREEDYE

280
260
Structural Hamming Distance

70

Structural Hamming Distance

60

60

50

40

240
220
200
180
160
140
120

30

100
20
0

20

40

60

80

100
120
Iterations

140

160

180

80
0

200

(e) Mildew

20

40

60

80

100
120
Iterations

(f) Win95pts

Figure 10: SHD for metaheuristic algorithm comparison
427

140

160

180

200

fiNetwork

Sample Size

100
500
1000
5000
10000

Alarm

Barley

Diabetes

HailFinder

Mildew

Win95pts

49.32  8.37
23.30  5.32
17.73  4.58
6.45  2.71
4.33  1.74

145.62  2.62
132.25  5.32
106.05  3.85
66.30  5.15
51.49  2.82

78.24  5.28
70.95  5.92
68.13  7.65
67.15  4.30
61.01  3.18

98.54  7.28
79.99  11.60
69.61  8.00
58.50  5.99
52.64  6.85

84.49  1.34
74.84  2.46
55.53  2.78
36.68  5.21
18.96  0.79

164.34  17.49
91.45  21.75
77.10  15.77
56.29  14.53
50.84  11.19

Table 14: Structural Hamming distance for different sample sizes


Barley 105

0.0138  0.0005
0.0568  0.0010
0.1092  0.0015
0.5228  0.0029
1.0388  0.0037

0.0774  0.0006
0.3263  0.0041
0.5833  0.0028
2.6028  0.0024
5.0695  0.0035

Network


Diabetes 105
HailFinder 105

Mildew 105



Win95pts 104

0.0316  0.0009
0.1135  0.0028
0.2102  0.0013
0.9810  0.0027
1.9399  0.0032

0.0667  0.0006
0.2946  0.0019
0.5576  0.0022
2.4178  0.0037
4.5338  0.0043

0.1507  0.0006
0.5446  0.0012
1.0198  0.0016
4.7468  0.0035
9.3794  0.0043

Network


Diabetes 105
HailFinder 105

Mildew 105



Win95pts 104

0.0316  0.0007
0.1136  0.0028
0.2104  0.0012
0.9811  0.0025
1.9394  0.0037

0.0668  0.0006
0.2947  0.0015
0.5581  0.0021
2.4181  0.0038
4.5350  0.0045

0.1669  0.0007
0.5564  0.0011
1.0238  0.0014
4.7535  0.0031
9.3883  0.0040

0.0596  0.0003
0.2687  0.0012
0.5189  0.0023
2.4807  0.0027
4.9205  0.0037



Table 15: Training score for different sample sizes

Sample Size

100
500
1000
5000
10000


Alarm 105


Barley 105

0.0143  0.0005
0.0571  0.0009
0.1092  0.0014
0.5229  0.0027
1.0387  0.0039

0.0778  0.0007
0.3272  0.0042
0.5835  0.0026
2.6031  0.0030
5.0702  0.0030

0.0604  0.0004
0.2690  0.0012
0.5192  0.0019
2.4811  0.0030
4.9214  0.0036

Table 16: Test score for different sample sizes



DALY & S HEN

428

Sample Size

100
500
1000
5000
10000


Alarm 105

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

8

4

8

x 10

5
100 samples
500 samples
1000 samples
5000 samples
10000 samples

3.5

100 samples
500 samples
1000 samples
5000 samples
10000 samples

4.5
4
Score Function Evaluations

Score Function Evaluations

3

x 10

2.5

2

1.5

3.5
3
2.5
2
1.5

1
1
0.5

0

0.5

0

20

40

60

80

100
120
Iterations

140

160

180

0

200

0

20

40

60

(a) Alarm

140

160

180

200

140

160

180

200

140

160

180

200

8

x 10

6
100 samples
500 samples
1000 samples
5000 samples
10000 samples

14

x 10

100 samples
500 samples
1000 samples
5000 samples
10000 samples

5

Score Function Evaluations

12
Score Function Evaluations

100
120
Iterations

(b) Barley

7

16

80

10

8

6

4

3

2

4
1
2

0

0

20

40

60

80

100
120
Iterations

140

160

180

0

200

0

20

40

60

(c) Diabetes
9

x 10

2.5
100 samples
500 samples
1000 samples
5000 samples
10000 samples

x 10

100 samples
500 samples
1000 samples
5000 samples
10000 samples

2
Score Function Evaluations

Score Function Evaluations

2

1.5

1

0.5

0

100
120
Iterations

(d) HailFinder

8

2.5

80

1.5

1

0.5

0

20

40

60

80

100
120
Iterations

140

160

180

0

200

(e) Mildew

0

20

40

60

80

100
120
Iterations

(f) Win95pts

Figure 11: Score function evaluations for different sample sizes

429

fiDALY & S HEN

4

4

x 10

8
100 samples
500 samples
1000 samples
5000 samples
10000 samples

Distinct Score Function Evaluations

10

x 10

100 samples
500 samples
1000 samples
5000 samples
10000 samples

7
Distinct Score Function Evaluations

12

8

6

4

6

5

4

3

2

2
1

0

0

20

40

60

80

100
120
Iterations

140

160

180

0

200

0

20

40

60

(a) Alarm

10
100 samples
500 samples
1000 samples
5000 samples
10000 samples

2.5
2
1.5
1

200

140

160

180

200

140

160

180

200

7
6
5
4
3
2

0.5

1

0

20

40

60

80

100
120
Iterations

140

160

180

0

200

0

20

40

60

(c) Diabetes

80

100
120
Iterations

(d) HailFinder

4

5

x 10

3.5
100 samples
500 samples
1000 samples
5000 samples
10000 samples

x 10

100 samples
500 samples
1000 samples
5000 samples
10000 samples

3
Distinct Score Function Evaluations

2.5
Distinct Score Function Evaluations

180

100 samples
500 samples
1000 samples
5000 samples
10000 samples

8

3

2

1.5

1

0.5

0

160

x 10

9

Distinct Score Function Evaluations

Distinct Score Function Evaluations

3.5

3

140

4

x 10

4

0

100
120
Iterations

(b) Barley

4

4.5

80

2.5

2

1.5

1

0.5

0

20

40

60

80

100
120
Iterations

140

160

180

0

200

(e) Mildew

0

20

40

60

80

100
120
Iterations

(f) Win95pts

Figure 12: Distinct score function evaluations for different sample sizes

430

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

SHD
Score
Alarm

Barley

Diabetes

Test Score (105 )

Mildew

Win95pts

GREEDY-E

ACO-B

EPQ

4.33  1.74

24.17  9.16

5.98  4.63

16.09  9.92

1.0388  0.0037

1.0396  0.0038

1.0388  0.0040

1.0389  0.0037

1.0387  0.0039

1.0395  0.0044

1.0391  0.0038

1.0396  0.0037

Score Eval.

3.7e8  2.7e7

6.8e4  7.3e3

1.7e7  1.9e5

3.2e7  1.3e6

Dist. Score Eval.

1.2e5  5.6e3

2.9e3  2.1e2

7.2e4  2.3e3

2.7e4  2.3e3

SHD

51.49  2.82

106.58  8.95

52.95  3.71

91.18  17.36

Score (105 )

5.0695  0.0035

5.2415  0.0114

5.0698  0.0033

5.1677  0.0740

Test Score (105 )

5.0702  0.0030

5.2413  0.0116

5.0702  0.0034

5.1673  0.0734

Score Eval.

4.7e8  1.5e7

1.3e5  5.7e3

3.1e7  1.5e5

4.5e7  2.1e6

Dist. Score Eval.

6.2e4  1.3e3

4.1e3  1.3e2

5.8e4  1.0e3

4.3e4  2.7e3

SHD

61.01  3.18

68.71  3.13

66.97  4.88

77.13  7.10

Score (105 )

1.9399  0.0032

1.9397  0.0033

1.9392  0.0039

1.9451  0.0047

Test Score (105 )

1.9394  0.0037

1.9395  0.0030

1.9398  0.0032

1.9449  0.0044

Score Eval.

1.4e8  7.5e6

2.7e4  1.6e3

1.6e7  1.0e5

2.7e7  2.7e6

Dist. Score Eval.

4.1e4  1.8e3

2.2e3  3.1e1

3.3e4  1.0e3

1.6e4  1.6e3

SHD

52.64  6.85

49.20  0.89

61.59  11.63

78.81  16.32

4.9205  0.0037

4.9212  0.0039

4.9213  0.0036

4.9293  0.0073

4.9214  0.0036

4.9209  0.0038

4.9214  0.0038

4.9296  0.0080

Score
HailFinder

(105 )

ACO-E

(105 )

Test Score (105 )
Score Eval.

5.3e8  3.3e7

1.0e5  2.7e3

4.0e7  2.9e5

6.1e7  3.7e6

Dist. Score Eval.

8.9e4  3.2e3

5.4e3  8.7e1

6.9e4  2.2e3

5.5e4  3.9e3

SHD

18.96  0.79

29.22  0.77

19.41  3.83

43.59  11.79

Score (105 )

4.5338  0.0043

4.5527  0.0038

4.5348  0.0058

4.5982  0.0292

Test Score (105 )

4.5350  0.0045

4.5526  0.0044

4.5350  0.0052

4.5989  0.0299

Score Eval.

2.1e8  9.8e6

4.2e4  1.1e3

1.6e7  1.6e5

2.8e7  2.4e6

Dist. Score Eval.

2.2e4  5.4e2

2.2e3  3.7e1

1.5e4  2.6e2

1.5e4  1.2e3

SHD

50.84  11.19

85.75  16.44

91.08  18.52

231.25  42.46

Score (104 )

9.3794  0.0043

9.4121  0.0043

9.3890  0.0036

9.6061  0.0075

Test Score (104 )

9.3883  0.0040

9.4153  0.0045

9.3897  0.0042

9.6058  0.0080

Score Eval.

2.2e9  2.4e8

5.2e5  8.9e4

8.5e7  8.6e5

1.2e8  4.6e6

Dist. Score Eval.

3.2e5  1.9e4

1.5e4  7.9e2

2.7e5  1.2e4

1.9e5  5.4e3

Table 17: Mean and standard deviation for tuned metaheuristic algorithms

Sample Size

100
500
1000
5000
10000

Alarm

Barley

Diabetes

HailFinder

Mildew

Win95pts

0.25
0.40
0.46
0.57
0.58

0.01
0.12
0.32
0.72
0.93

0.06
0.32
0.34
0.36
0.30

0.06
0.18
0.28
0.44
0.45

0.00
0.02
0.12
0.71
0.82

0.53
1.30
1.53
1.96
2.11

Table 18: Mean number of v-structures divided by number of nodes on greedy searches
431

fiDALY & S HEN

8. Discussion
This section will discuss the results presented in the previous section. In general, the discussion
will involve looking at the score and SHD values (as defined in Section 6.2.2) obtained by the
algorithms. It should be noted that a better score does not necessarily mean a better SHD value and
vice-versa. This can occur because of small sample sizes and because of the parameters given to
the scoring function (such as the equivalent sample size and  value), which have been shown to
produce differences in scoring function behavior (Kayaalp & Cooper, 2002). In general, different
data sets have different parameter values at which they behave optimally. There does not seem to
be a general method to find the optimum values. This problem has been looked at in some depth by
Silander, Kontkanen et al. (2007).
The first figures to be examined will be those in Tables 10 and 11 from Condition 1. These
presented the results of experiments that varied the parameter values of the ACO-E algorithm.
Looking at these figures, there is evidence that the ACO-E algorithm provides useful behavior for
reasonable values of the parameters.
Next, the results from experimental Condition 5 will be examined, particularly Table 18 in the
context of the Bayesian network properties given in Table 5. Along with the results which show
behavior of ACO-E as a function of sample size in Condition 3 (Tables 14, 15 and 16), this discussion
will seek to characterize ACO-E performance from the perspective of the generating network and
sample. Evidence will be presented that shows ACO-E performs better with more complicated
networks, i.e. networks with more v-structures.
The previous discussion focuses on the behavior of ACO-E as a function of its various parameters.
The next results that will be looked at are intended to provide a comparison against other Bayesian
network structure learning algorithms. These include Figures 9 and 10 and Table 12 from Condition
1 and Table 17 from Condition 4. These present ACO-E against other metaheuristic algorithms that
are similar. In these results there is strong evidence that ACO-E is performing well against the other
algorithms.
Also from a comparative perspective, the results given in Table 13 will be discussed. These
present a series of tests comparing ACO-E to other state-of-the-art Bayesian network structure
learning algorithms. Again, looking at the figures, there is strong evidence that ACO-E is competitive
in its performance.
Finally, the complexity results from Condition 3 will be shown in the form of Figures 11 and 12.
In order to perform a comparison, statistical tests will be needed. Because of the non-normality
of the distributions of some of the results, tests others than ones which rely on the normality of the
data will be used. These are mentioned below.
8.1 ACO-E Behavior
In this section the behavior of ACO-E as its parameters are varied will be analyzed. As shown in
Tables 10 and 11 there is evidence that there is a difference in the behavior of the ACO-E algorithm
depending on the input parameters. These differences will be analyzed using the two-tailed MannWhitney U test or Students T test. The particular test used depends on the normality of the data,
which can be tested with the Jarque-Bera test.
In order to perform this comparison, the best figures from Tables 10 to 11 will be compared to
the situation where that particular part of the ACO-E algorithm has been turned off. E.g. in Table 10
on the Alarm row, the best figure is at  = 0.5. This is compared to the value at  = 0.0, as at this
432

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

value no pheromone deposition or evaporation is occurring. The values at which the various parts
of the ACO-E algorithm have been turned off are  = 0.0, q0 = 1 and  = 0.0. For the value of
q0 = 1, the algorithm behaves purely in a greedy fashion. Therefore for the purposes of testing, the
value of the GREEDY-E algorithm in Table 12 will be used for comparison, as these results would be
exactly the same as the case where q0 = 1. The results of these comparisons are shown in Table 19.
This table shows p-values for each comparison.
8.1.1 T HE B EHAVIOR OF 
Looking at Table 19 the results for  that seem most certain are those for Barley, Mildew and
Win95pts. Looking at Tables 10 and 11 for these networks, the values of  are in the 0.2  0.4 range.
Also looking at the features of these networks in Table 5 there is a correspondence of  = 0.2 to
76 nodes (Win95pts),  = 0.3 to 48 nodes (Barley) and  = 0.4 to 35 nodes (Mildew). Whilst not
conclusive, this suggests that  behaves well in the region 0.2  0.4 (for those data sets that it works
at all). The fact that there is not much variance in this range for these networks means this range is
quite robust. There also is a suggestion that datasets with more nodes would use smaller values of .
This makes sense, as larger networks would probably need to spend more time following the best
solutions, as a low value of  would provide.
8.1.2 T HE B EHAVIOR OF q0
The parameter q0 appears to have an effect on most of the networks, with the possible exception of
HailFinder. For some of the networks (Alarm and Barley) the parameter has a large effect over a
wide range, whereas for others (Diabetes, Mildew and Win95pts), the effect depends to a large extent
on the value for q0 . The largest effects from a scoring function point of view appear to be on the
Barley, Mildew and Win95pts networks.
Looking at these networks, the large variations in behavior across different values of q0 make it
difficult to predict what the best value of the parameter might be for a particular data set. One rule of
thumb might be that smaller values of q0 create more exploration and so might be useful for smaller
data sets, whereas larger data sets need more exploitation in order to get to a reasonable answer.
8.1.3 T HE B EHAVIOR OF 
From Table 19, the networks for which the parameter  plays the most role appear to be Alarm,
Barley and Win95pts. Because of the differences of the best values between the scoring function and
the SHD it is difficult to predict the best value for  . In the case of Barley, the behavior is quite robust
to values of  in the range 0.5  2.5. However, for Alarm and Win95pts, the behavior depends on the
value of the parameter with a smaller value being better for Alarm and a larger value for Win95pts.
As a rule of thumb it appears that networks with less numbers of nodes need smaller values of  to
help avoid local minima, whereas networks with more nodes need larger values of  in order to focus
the search more effectively.
8.1.4 T HE B EHAVIOR OF m
Looking at Tables 10 and 11 it can be seen that the value of m can sometimes have a small effect on
the effectiveness of ACO-E. In this case, the effect is most pronounced on the Alarm, Diabetes and
Mildew networks, with higher values of m giving a smaller SHD. Indeed in all cases, higher values

433

fiDALY & S HEN

of m never produce statistically worse results, as is to be expected. However, it is important to bear in
mind the increased running times with larger values of m.
8.1.5 G ENERAL D ISCUSSION
The reason for the strange behavior of the HailFinder results can possibly be explained by examining
its graphs of score function and SHD against time (Figures 9 and 10). It can be seen that as the score
is improving over iterations, the SHD value is deteriorating. This might lead one to the conclusion
that there is a problem with the scoring function for the HailFinder case, perhaps with its parameters.
Another plausible reason for the HailFinder and Win95pts results being out of sync with the others
is that they are larger networks, which might favour more aggressive exploitation of the best-so-far
solution than the smaller ones. In this case, this would correspond to lower values of  and higher
values of q0 . Also heuristic information might be more useful with large numbers of variables, leading
to the better results with large values of  . Note that these problems with the HailFinder network
have also been seen by de Campos and Castellano (2007).
8.2 Behavior of ACO-E with Respect to Test Network and Sample
In the previous section, it was seen that ACO-E can be a useful algorithm in learning the structure
of Bayesian networks. It was also seen that the values of the parameters that produced the best
behavior depended on the network that was being tested. Some rules of thumb that consolidate the
characteristics observed in the previous section were:
 For data with more variables, have lower values of , higher values of q0 and higher values of
.
 For data with less variables, have higher values of , lower values of q0 and lower values of  .
However, it was also seen that ACO-E is not always very successful in learning. This was because
little difference was seen when certain parameters were turned off with certain networks. Looking
again at Table 19, it seems that the networks for which the effect was most felt were the Barley,
Mildew and Win95pts networks. But why is this?
Looking at Table 5 there does not seem to be any discernible pattern between the network
properties and the suitability of the algorithm. However, the values of the number of v-structures
normalised by the number of nodes in the graph show a more definite reason. The networks with
which ACO-E performed well all have a larger number of nodes that have a higher in-degree and
hence a larger number of v-structures. As a result of this, data sampled from these networks is better
going to match a similar network in the scoring function, i.e. one that is similar to the standard
network. Because the search starts from the empty graph, it is more likely that the search would get
trapped in a local minimum in trying to add enough arcs to get to the needed number. Due to ACO-E
being a stochastic algorithm, it is able to avoid these local minima.
The upshot of this is that ACO-E would be a good candidate algorithm for data sampled from
networks with a large number of v-structures. However, in the real world a generating network does
not exist. Therefore, the experiments of Condition 5 were designed to try and estimate this quantity.
The results of these experiments are shown in Table 18. It can be seen that there is some association
between the results when the number of samples is at 10000 and the average number of v-structures
per node. Indeed, the value of the correlation coefficient between the values is r = 0.94, which

434

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

indicates a linear relationship with a p-value of 0.006. However, the results are not quite the same
when the number of samples decrease. For example, at 100 samples the correlation is not visible.
This makes sense, as the low number of samples would not be able to support many v-structures. As
such, the estimate might only be valid in the large sample limit.
However, the procedure employed in Condition 5 does indicate a way in seeing how effective of
the ACO-E algorithm would be on arbitrary set of data. If the value calculated by the resampling
method was low (towards 0), then ACO-E would probably not be particularly effective and a simpler
algorithm would perform well. However, as the value rises, the probable number of v-structures also
rises and hence ACO-E (and other methods designed to avoid local maxima) would fare better.
These ideas seem to be borne out by examining Table 14. It appears that high expected values of
v-structures per node imply good performance of the ACO-E algorithm, i.e. there is an obvious large
improvement in SHD. On the contrary, low expected values of v-structures per node are associated
with small improvements in the SHD as the algorithm progresses.
8.3 Metaheuristic Algorithm Comparison
Figures 9 and 10 and Table 12 show the results of comparing ACO-E against other metaheuristic
algorithms. It can be seen that ACO-E performs better than the other algorithms shown except in the
case of the HailFinder network, where GREEDY-E gives a better result for the SHD. However, in
this case, ACO-E gives a better score value. This is the same as the problem discussed in Section 8.1,
that gave a better score for a worse structure.
These statements can be backed up by looking at Table 20 which gives p-values for a two-tailed
unpaired Mann-Whitney-U test comparing ACO-E results against the other algorithms after runs had
ended. With this statistic, the smaller the number, the more significant the test. Since the results from
each of the runs comes from a separate sample of the network, the correct tests would be unpaired.
The data used in the tests were those from the metaheuristic algorithm comparison, i.e. over all
combinations of the parameters for ACO-E and ACO-B. It seems that in most cases, the results are
highly significant, which supports the assumption that ACO-E performs well. In the cases where the
significance is not so high (ACO-E score compared to GREEDY-E score with the Alarm network and
ACO-E score compared to GREEDY-E score with the Diabetes network), it should be noted that tiny
changes to the score value can lead to large structural changes as an algorithm converges towards the
optimum (generating) network. In these cases, the SHD p-values show a highly significant difference.
Comparisons were also made between the variances of the results as seen in Table 21, which
gives p-values for Conovers (1999) Squared Ranks one-tailed test. From this table can be seen that
ACO-E generally has a lower standard deviation in its results after finishing its run compared to
ACO-B and EPQ. Whilst the standard deviation of results compared to GREEDY-E are significantly
lower with respect to the Alarm and Barley networks, in the other cases GREEDY-E seems to be the
most consistent with regard to its final results.
It should be noted that non-parametric tests were used, as the results in general had non-normal
distributions. It should also be noted that some of the results in the tables might seem incorrect.
E.g. in Table 20, in the Win95pts-Score row, the test for ACO-B is more significant than that for
GREEDY-E, even though the mean of GREEDY-E is further from ACO-E than that of ACO-B in
Table 12. This is because of the larger sample size for the ACO-B test, which had 1296 samples,
compared to the 216 samples for GREEDY-E.

435

fiDALY & S HEN



q0



Alarm

SHD
Score

8.0  104
1.7  101

4.3  1091
2.1  102

1.3  1016
9.1  103

Barley

SHD
Score

1.3  106
1.3  109

4.2  10230
2.9  1072

6.9  1041
2.5  1026

Diabetes

SHD
Score

1.0  100
9.2  103

3.6  1042
2.8  101

8.7  101
1.0  100

HailFinder

SHD
Score

9.3  101
1.9  101

3.3  102
1.1  102

5.5  103
2.7  102

Mildew

SHD
Score

5.1  1016
1.4  105

3.6  10125
8.0  1063

1.0  100
3.5  101

Win95pts

SHD
Score

4.9  108
1.3  107

9.0  1041
2.0  1026

5.3  1044
2.2  1018

Table 19: Comparisons of parameter behavior

GREEDY-E

ACO-B

EPQ

Alarm

SHD
Score

1.1  10113
4.3  102

1.6  1031
6.0  103

1.9  10118
1.8  1018

Barley

SHD
Score

9.6  10124
5.0  10123

1.8  1092
5.9  1096

9.3  10123
7.0  10123

Diabetes

SHD
Score

3.1  1034
2.5  101

4.7  10104
2.3  1018

1.5  1088
4.5  1069

HailFinder

SHD
Score

3.8  1012
4.4  103

2.7  10237
2.2  1093

1.8  1099
4.6  10113

Mildew

SHD
Score

2.3  1050
7.4  1062

4.7  10160
5.7  10114

7.5  10115
5.3  10118

Win95pts

SHD
Score

1.5  1042
3.0  1037

0
4.1  1053

4.8  10123
5.0  10123

Table 20: p-values for Mann-Whitney U test, 10,000 samples

436

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Further results from Condition 4 confirm these findings. In those experiments, the same algorithms
were run with the parameters tuned. The results of these experiments can be seen in Table 17. The
findings from these results are similar to the ones discussed above, with some differences. ACO-E
outperforms the other algorithms with the SHD and test score measures in all cases except for the
HailFinder network, where GREEDY-E is better, as above. The differences between ACO-E and
ACO-B, its main competitor, are not as pronounced, but still exist. With the Alarm, Barley and
Mildew networks the practical difference is quite small, whereas with the Diabetes, HailFinder and
Win95pts networks it is still quite large. However, even with this, ACO-E can be said to perform
better in three areas:
 ACO-E is more robust with respect to the parameter values input. Comparing the tunedparameter-value results to the results across all parameter values, it can be seen that ACO-E is
not as sensitive to the values as ACO-B. This implies that ACO-E could be used in a learning
problem without a long parameter optimization stage. Note that reasonable parameter values
are still important, as discussed in Section 8.1.
 ACO-E converges faster to optimum values than ACO-B, in terms of the number of iterations.
For example, in the Barley, Mildew and Win95pts cases, ACO-E reaches its best SHD value
in 20 iterations, whereas ACO-B takes about 200 iterations.
 ACO-E generally provides a smaller variance in output values than the other algorithms. This
can be important in situations where a robust output is needed.
8.4 State-of-the-Art Algorithm Comparison
In this section, the comparison of ACO-E against other state-of-the-art Bayesian network structure
learning algorithms will be analyzed. As shown in Table 13, ACO-E appears to have good performance against these other algorithms. The results of statistical comparisons of ACO-E against these
algorithms are shown in Table 22.
In this table are shown p-values for individual comparisons of ACO-E against the other algorithms.
The test used for all these comparisons was the Mann-Whitney U test. This test was used, as the
distributions were found to be not normal. At the foot of the table is the combined p-value found
from the individual p-values above it. This is the total p-value for comparing ACO-E against all the
other algorithms. The method of combining these values was
n

pcombined = 1   1  pi ,
i=1

where pi is the p-value of entry i in the table, there being n values in total. This method of combining
the p-values is needed because of the chance of causing a Type I error otherwise. A Type I error is a
false positive result, i.e. the null hypothesis is rejected when it should not be. This can occur in this
case because if an experiment with a small chance of failing is repeated enough times, there will be a
large chance that at least one of them will fail. It should be noted that the value at the foot of Alarm
does not combine all the p-values above it. Instead it leaves out those of SC k = 10, PC and OR2
k = 5. This was because the median results for these figures were close to that of ACO-E and would
have pushed the p-value very high. Therefore, the overall test is only valid for the tests that do not
include the three just mentioned.
437

fiDALY & S HEN

Alarm

Barley

Diabetes

HailFinder

Mildew

Win95pts

SHD
ESHD
Score
SHD
ESHD
Score
SHD
ESHD
Score
SHD
ESHD
Score
SHD
ESHD
Score
SHD
ESHD
Score

GREEDY-E
3.6  1084
4.1  10103
8.0  102
1.3  1061
6.2  1044
1.5  1066
1
1
4.8  101
1
1
9.1  101
1
1
1
1
1
5.8  101

ACO-B
2.4  10252
0
1.3  101
1.5  10274
7.6  10277
0
1.5  103
1.2  1013
2.1  104
2.0  10153
2.5  10169
4.3  1023
1.5  10111
1.3  1077
1.5  1085
5.7  10209
8.7  10210
2.6  1026

EPQ
5.3  10104
7.3  10117
5.0  105
2.3  1066
1.6  1069
4.6  10146
1.0  104
3.1  105
7.3  108
2.6  1062
2.0  1058
1.3  10143
9.3  1054
1.9  1049
8.3  1079
5.4  1012
1.4  1013
3.2  1038

Table 21: p-values for Conovers squared ranks test, 10,000 samples

Alarm

Barley

HailFinder

Mildew

MMHC
OR1 k = 5
OR1 k = 10
OR1 k = 20
OR2 k = 5
OR2 k = 10
OR2 k = 20
SC k = 5
SC k = 10
GS
PC
TPDA
GES

3.2  102
5.9  104
1.9  105
4.1  108
3.5  102
1.4  107
2.1  108
2.1  108
8.1  101
2.1  108
4.0  101
6.5  104
N/A

2.1  108
2.1  108
2.1  108
2.1  108
2.1  108
1.1  105
3.8  106
2.1  108
N/A
4.3  107
2.1  108
2.1  108
2.1  108

2.1  108
2.1  108
2.1  108
2.1  108
2.1  108
2.1  108
2.1  108
2.1  108
N/A
2.1  108
2.1  108
2.1  108
2.1  108

2.1  108
2.1  108
2.1  108
2.1  108
2.1  108
2.1  108
2.1  108
N/A
N/A
2.1  108
2.1  108
2.1  108
2.1  106

Total

3.3  102

1.6  105

2.5  107

2.3  106

Table 22: p-values comparing ACO-E against state-of-the-art algorithms

438

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

The results given in Table 13 appear to be indicative of the results as given in Section 8.1. As
discussed there, ACO-E had some effect with learning in the Alarm network, especially against a
straight greedy search. However, most of this effectiveness appeared to come from the randomness
of the search, and did not make much use of the  and  parameters.
On the networks which ACO-E performed well, Barley and Mildew, this performance is reflected
across to the current results as it also performed well here. The results for the HailFinder network
seem odd, as the ACO-E algorithm did no better than a search using GREEDY-E. However, in this
figure, the performance of GES can also seen to be doing well. As GES works in the space of
equivalence classes of Bayesian networks, it is postulated that ACO-E performs well because of the
structure of the search space.
As ever, comparisons must be taken tentatively, especially in this case, as the results given by
Tsamardinos, Brown et al. only have five samples.
8.5 Computational Complexity of ACO-E
The results of experimental Condition 3 show two figures (11 and 12) related to the computational
complexity of ACO-E. The first shows that total number of score function evaluations during the
algorithm run, the second shows the number of distinct score function evaluations. Both of these are
counted, as score function evaluations are usually cached in order to improve running times.
It can be surmized that in general, larger sample sizes imply more evaluations. This makes sense,
as larger samples can support networks with more arcs. Since the algorithm starts as the empty graph,
it would take more moves and hence more evaluations to get to a maximum. It can also be seen that
the total number of evaluations is in general, linear with respect to the number of iterations passed.
Looking at the plots of Figure 12, it can be seen that the number of distinct function evaluations
is many magnitudes less than the total number of evaluations. It can also be noted that most of the
distinct function evaluations take place within the first twenty to thirty iterations and gradually tails
off in a logarithmic fashion. This is to be expected, as at the beginning, the algorithm will explore
many new paths when the pheromone is more evenly distributed. The scores for these paths will be
cached and so not have to be computed again. This means that over time, less and less new score
function applications will be needed. However, it is worthwhile noticing that in many cases the plots
do not level out. This implies that new paths are being taken and that the algorithm is not stagnating.
To finish up, it is worthwhile comparing the complexity of ACO-E to the other metaheuristic algorithms that were tested. Looking at Table 17, it appears that ACO-E has a much higher computational
complexity than the other algorithms. However, it can be seen that most of these evaluations are not
distinct. Since evaluations are normally cached and cache lookup can proceed in constant time, the
total score evaluation results are not too important. Focusing instead on distinct score evaluation
results, it can be seen that there is not much difference between ACO-E and the other algorithms
in terms of actual score function evaluations. Since this is often the dominant factor in algorithm
running time, the complexity of the algorithms can be observed as quite similar.

9. Conclusions and Future Directions
The main results in this paper were on the development of the ACO-E algorithm as an implementation
of the ACO metaheuristic to the problem of learning a Bayesian network structure that provides a
good fit to a set of data. In a nutshell, ACO-E performed well in reconstructing test networks, from

439

fiDALY & S HEN

which data was sampled. A more detailed look at the behavior of ACO-E depending on its parameters,
the type of test network and compared to other algorithms will now be given.
9.1 ACO-E Behavior as its Parameters are Varied
In analyzing the behavior of ACO-E as a function of its parameters, the best and worst performing
figures were compared, across each range of parameter. The best result was found when the parameter
setting produced either the highest score or the smallest difference from the test network. The worst
result was found when the parameter was switched off, i.e. when it had no effect on the algorithms
behavior.
For all parameters, there was a difference between the behavior of the best and the worst settings.
Whether this difference was significant or not depended on the particular network being used as a
test; some networks responded better to the algorithm than others. For those networks that ACO-E
worked well with, the following trends were noticed:
 For data with more features, lower values of , higher values of q0 and higher values of 
worked better; and
 For data with less features, higher values of , lower values of q0 and lower values of  worked
better;
where  is the rate of pheromone deposition/evaporation, q0 is the balance between exploration and
exploitation and  is the power of the heuristic in the probabilistic transition rule.
9.2 The Utility of ACO-E as a Function of the Test Network and Sample
It was noticed that ACO-E performed better on some of the test networks than others. The networks
that it fared best with were Barley, Mildew and Win95pts, described in Section 6.1.1. On closer
examination of these networks it was found that they had a large average v-structure (as discussed in
Section 6.1.1) per node value.
The reason that this might make a difference is because nodes with a large number of v-structures
imply more possible local maxima in the search space. Greedy methods would run into these maxima,
whereas ACO-E is able to find its way around them because of its stochastic nature of not always
choosing the best move. Experiments were run to estimate the average v-structure per node value and
a correspondence was found in the large sample case. In general, the method used in the experiment
could be used to estimate the usefulness of ACO-E in particular situations.
9.3 ACO-E Performance Compared to Similar Algorithms
The results of Sections 7.1 and 7.4 show that ACO-E performs well against other algorithms that are
similar in nature. These other algorithms were:
 GREEDY-E, which performs a greedy search in the space of equivalence classes of Bayesian
network structures (Chickering, 2002a);
 EPQ, which performs an evolutionary programming search in the space of equivalence classes
(Cotta & Muruzbal, 2004; Muruzbal & Cotta, 2004); and
 ACO-B, which performs a search using ACO in the space of DAGs (de Campos, FernndezLuna et al., 2002).
440

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

In all cases, the BDeu score of ACO-E was better than the score of the other algorithms, at every
iteration. In the case of the structural differences, it was better in all cases, except that of the HailFinder
network, where the odd behavior of the scoring function meant better BDeu scores implied worse
structural differences. Concurring with the discussion above in 9.2, the networks for which ACO-E
performed best were the Barley, Mildew and Win95pts networks.
ACO-E was also shown to be comparable in computational complexity to the other metaheuristic
algorithms.
9.4 ACO-E Performance Compared to Alternative State-of-the-Art Algorithms
Similar to the section above, ACO-E performed well in comparison to other state-of-the-art Bayesian
network structure learning algorithms, performing better in 3 out the 4 tested: Barley, Mildew and
HailFinder. The first two are networks in which it performed well in the self test. With the HailFinder
network it is postulated that the results are good because of the search space; good results were also
shown for the greedy equivalent search (GES) algorithm, which also searches through the space of
equivalence classes.
Whilst ACO-E did not perform best with the Alarm network, it did not perform badly either,
coming joint third in the rankings. The reasons for the performance on the Alarm network are
discussed in Section 8.2.
9.5 Extending ACO-E to Increase Performance and Scalability
Since validity checking is the slowest part of the ACO-E algorithm, it currently remains the first issue
which must be dealt with, in order to improve running times. However, if that problem is solved then
the focus will turn back to the other parts of the algorithm, particularly the scoring function.
Reducing the Number of Scoring Function Evaluations One very easy way in cutting down the
number of score evaluations would be to have a static heuristic defined that could say, e.g. what
would be the benefit of adding an arc to the empty graph. In this way, scoring functions would only
have to be evaluated once per move and hence lead to a speeding up of the algorithm. With a situation
like this, local search would become more important in order to finish off traversals to the best
possible positions.
Pruning the Search Space Recently, hybrid learning algorithms have shown good success in
learning Bayesian network structures, whilst cutting down on running time, sometimes dramatically.
They generally work by using a conditional independence test to discover nodes that would likely be
connected to a given node and remove the rest of them from consideration. This has the effect of
requiring less scoring function evaluations, thus speeding up the algorithm and requiring less memory
to store the results of evaluations. With no bound on the number of possible parents, the number of
cached values would grow at least quadratically with the number of variables and eventually exhaust
the computers memory.
Applying ACO-E with Different Search Operators to Better Avoid Local Maxima According
to Castelo and Kocka (2003), there are certain operators that are able to avoid local maxima in a
search space, provided that the sample size tends to infinity. An example of these are the operators
given by Chickering (2002b) that are used in a greedy search in the space of equivalence classes of
structures (GES).

441

fiDALY & S HEN

However, at small sample sizes these guarantees are not strictly true and search algorithms can
still get caught in maxima. An example of a method that tries to avoid these is the KES algorithm of
Nielsen, Kocka, and Pea (2003), which uses the operators in GES, but has a parameter that controls
how often the algorithm acts greedily; when the algorithm does not act greedily, it chooses a move
that is not necessarily the best. Experiments show that KES behaves better than GES most of the
time.
This procedure bears some similarities to ACO-E. If the randomness was augmented by pheromone
and heuristics, there is a possibility that performance would improve even more.

Acknowledgments
The authors are grateful to the Associate Editor and reviewers for their comments, which were very
helpful in guiding the revision of this research.

References
Abramson, B., Brown, J., Edwards, W., Murphy, A., & Winkler, R. L. (1996). Hailfinder: A
Bayesian system for forecasting severe weather. International Journal of Forecasting, 12(1),
5771. doi:10.1016/0169-2070(95)00664-8.
Acid, S., & de Campos, L. M. (2003). Searching for Bayesian network structures in the space of
restricted acyclic partially directed graphs. Journal of Artificial Intelligence Research, 18, 445490.
Aitken, S., Jirapech-Umpai, T., & Daly, R. (2005). Inferring gene regulatory networks from classified
microarray data: Initial results. BMC Bioinformatics, 6(Suppl 3), S4. doi:10.1186/1471-2105-6S3-S4.
Akaike, H. (1974). A new look at the statistical model identification. IEEE Transactions on Automatic
Control, 19(6), 716723. doi:10.1109/TAC.1974.1100705.
Andersson, S. A., Madigan, D., & Perlman, M. D. (1997). A characterization of Markov
equivalence classes for acyclic digraphs.
The Annals of Statistics, 25(2), 505541.
doi:10.1214/aos/1031833662.
Andreassen, S., Hovorka, R., Benn, J., Olesen, K. G., & Carson, E. (1991). A model-based approach
to insulin adjustment. In Proceedings of the Third Conference on Artificial Intelligence in Medicine
(AIME 91), volume 44 of Lecture Notes in Medical Informatics, (pages 239249).
Baluja, S. (1994). Population-based incremental learning: A method for integrating genetic search
based function optimization and competitive learning. Technical Report CMU-CS-94-163, School
of Computer Science, Carnegie Mellon University.
Beinlich, I., Suermondt, H., Chavez, R., & Cooper, G. (1989). The ALARM monitoring system:
A case study with two probabilistic inference techniques for belief networks. In Proceedings of
the Second European Conference on Artificial Intelligence in Medicine (AIME 89), volume 38 of
Lecture Notes in Medical Informatics, (pages 247256). Springer.
Birattari, M., Caro, G. D., & Dorigo, M. (2002). Toward the formal foundation of ant programming.
In Proceedings of the Third International Workshop on Ant Algorithms, volume 2463 of Lecture
442

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Notes in Computer Science, (pages 188201). Springer-Verlag.
Bonabeau, E., Dorigo, M., & Theraulaz, G. (1999). Swarm Intelligence: From Natural to Artificial
Systems. Studies in the Sciences of Complexity. Oxford University Press.
Bullnheimer, B., Hartl, R. F., & Strauss, C. (1999). An improved ant system algorithm for the vehicle
routing problem. Annals of Operations Research, 89, 319328. doi:10.1023/A:1018940026670.
Buntine, W. (1991). Theory refinement on Bayesian networks. In B. DAmbrosio, & P. Smets (Eds.),
Proceedings of the Seventh Annual Conference on Uncertainty in Artificial Intelligence (UAI 91),
(pages 5260). Morgan Kaufmann.
Castelo, R., & Kocka, T. (2003). On inclusion-driven learning of Bayesian networks. Journal of
Machine Learning Research, 4, 527574.
Cheng, J., Greiner, R., Kelly, J., Bell, D., & Liu, W. (2002). Learning Bayesian networks from data: An
information-theory based approach. Artificial Intelligence, 137(12), 4390. doi:10.1016/S00043702(02)00191-1.
Chickering, D. M. (1995). A transformational characterization of equivalent Bayesian network structures. In P. Besnard, & S. Hanks (Eds.), Proceedings of the Eleventh Conference on Uncertainty in
Artificial Intelligence (UAI-95), (pages 8798). Morgan Kaufmann.
Chickering, D. M. (1996a). Learning Bayesian networks is NP-complete. In D. Fisher, & H.-J. Lenz
(Eds.), Learning from Data: Artificial Intelligence and Statistics V, volume 112 of Lecture Notes
in Statistics, (pages 121130). Springer.
Chickering, D. M. (1996b). Learning equivalence classes of Bayesian network structures. In
E. Horvitz, & F. Jensen (Eds.), Proceedings of the Twelfth Conference on Uncertainty in Artificial
Intelligence (UAI-96), (pages 150157). Morgan Kaufmann.
Chickering, D. M. (2002a). Learning equivalence classes of Bayesian-network structures. Journal of
Machine Learning Research, 2, 445 498.
Chickering, D. M. (2002b). Optimal structure identification with greedy search. Journal of Machine
Learning Research, 3, 507554.
Chickering, D. M., Geiger, D., & Heckerman, D. (1996). Learning Bayesian networks: Search
methods and experimental results. In D. Fisher, & H.-J. Lenz (Eds.), Learning from Data: Artificial
Intelligence and Statistics V, volume 112 of Lecture Notes in Statistics, (pages 112128). Springer.
Chickering, D. M., Heckerman, D., & Meek, C. (2004). Large-sample learning of Bayesian networks
is NP-hard. Journal of Machine Learning Research, 5, 12871330.
Conover, W. J. (1999). Practical Nonparametric Statistics. John Wiley & Sons, Third edition.
Cooper, G. F., & Herskovits, E. (1992). A Bayesian method for the induction of probabilistic networks
from data. Machine Learning, 9(4), 309347. doi:10.1007/BF00994110.
Costa, D., & Hertz, A. (1997). Ants can colour graphs. Journal of the Operational Research Society,
48(3), 295305. doi:10.1057/palgrave.jors.2600357.

443

fiDALY & S HEN

Cotta, C., & Muruzbal, J. (2004). On the learning of Bayesian network graph structures via
evolutionary programming. In P. Lucas (Ed.), Proceedings of the Second European Workshop on
Probabilistic Graphical Models, (pages 6572).
Cowell, R. (2001). Conditions under which conditional independence and scoring methods lead to
identical selection of Bayesian network models. In J. Breese, & D. Koller (Eds.), Proceedings
of the Seventeenth Conference on Uncertainty in Artificial Intelligence (UAI-01), (pages 9197).
Morgan Kaufmann.
Dagum, P., & Luby, M. (1993). Approximating probabilistic inference in Bayesian belief networks
is NP-hard. Artificial Intelligence, 60(1), 141154. doi:10.1016/0004-3702(93)90036-B.
Daly, R., Shen, Q., & Aitken, S. (2006). Speeding up the learning of equivalence classes of Bayesian
network structures. In A. P. del Pobil (Ed.), Proceedings of the Tenth IASTED International
Conference on Artificial Intelligence and Soft Computing, (pages 3439). ACTA Press.
Daly, R., Shen, Q., & Aitken, S. (2009). Learning Bayesian networks: Approaches and issues. The
Knowledge Engineering Review. In press.
de Campos, L. M., & Castellano, J. G. (2007). Bayesian network learning algorithms using structural restrictions. International Journal of Approximate Reasoning, 45(2), 233254.
doi:10.1016/j.ijar.2006.06.009.
de Campos, L. M., Fernndez-Luna, J. M., Gmez, J. A., & Puerta, J. M. (2002). Ant colony
optimization for learning Bayesian networks. International Journal of Approximate Reasoning,
31(3), 291311. doi:10.1016/S0888-613X(02)00091-9.
de Campos, L. M., Gmez, J. A., & Puerta, J. M. (2002). Learning Bayesian networks by ant colony
optimisation: Searching in two different spaces. Mathware & Soft Computing, 9(23).
de Campos, L. M., & Puerta, J. M. (2001a). Stochastic local algorithms for learning belief networks:
Searching in the space of the orderings. In S. Benferhat, & P. Besnard (Eds.), Proceedings of
the Sixth European Conference on Symbolic and Quantitative Approaches to Reasoning with
Uncertainty (ECSQARU 2001), volume 2143 of Lecture Notes in Artificial Intelligence, (pages
228239). Springer. doi:10.1007/3-540-44652-4_21.
de Campos, L. M., & Puerta, J. M. (2001b). Stochastic local and distributed search algorithms
for learning belief networks. In Proceedings of the Third International Symposium on Adaptive Systems: Evolutionary Computation and Probabilistic Graphical Models, (pages 109115).
ICIMAF.
Deneubourg, J. L., Aron, S., Goss, S., & Pasteels, J. M. (1990). The self-organizing exploratory
pattern of the argentine ant. Journal of Insect Behavior, 3(2), 159168. doi:10.1007/BF01417909.
Dor, D., & Tarsi, M. (1992). A simple algorithm to construct a consistent extension of a partially
oriented graph. Technical Report R-185, Cognitive Systems Laboratory, Department of Computer
Science, UCLA.
Dorigo, M. (1992). Ottimizzazione, apprendimento automatico, ed algoritmi basati su metafora
naturale. Ph.D. thesis, Politecnico di Milano, Italy.

444

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Dorigo, M., & Di Caro, G. (1999). The ant colony optimization meta-heuristic. In D. Corne,
M. Dorigo, & F. Glover (Eds.), New Ideas in Optimization, (pages 1132). McGraw-Hill.
Dorigo, M., & Gambardella, L. M. (1997). Ant colony system: A cooperative learning approach to
the traveling salesman problem. IEEE Transactions on Evolutionary Computation, 1(1), 5366.
doi:10.1109/4235.585892.
Dorigo, M., Maniezzo, V., & Colorni, A. (1996). The Ant System: Optimization by a colony of
cooperating agents. IEEE Transactions on Systems, Man, and Cybernetics Part B: Cybernetics,
26(1), 2941. doi:10.1109/3477.484436.
Dorigo, M., & Sttzle, T. (2004). Ant Colony Optimization. The MIT Press.
Friedman, N., Nachman, I., & Peer, D. (1999). Learning Bayesian network structure from massive
datasets: The Sparse Candidate algorithm. In H. Prade, & K. Laskey (Eds.), Proceedings of the
Fifteenth Conference on Uncertainty in Artificial Intelligence (UAI-99), (pages 206215). Morgan
Kaufmann.
Gambardella, L. M., & Dorgio, M. (2000). An ant colony system hybridized with a new local
search for the sequential ordering problem. INFORMS Journal on Computing, 12(3), 237255.
doi:10.1287/ijoc.12.3.237.12636.
Gambardella, L. M., & Dorigo, M. (1995). Ant-Q: A reinforcement learning approach to the travelling
salesman problem. In A. Prieditis, & S. J. Russell (Eds.), Proceedings of the Twelfth International
Conference on Machine Learning (ICML 1995), (pages 252260). Morgan Kaufmann.
Glover, F. (1989). Tabu searchPart I. ORSA Journal on Computing, 1(3), 190206.
Glover, F. (1990). Tabu searchPart II. ORSA Journal on Computing, 2(1), 432.
Heckerman, D. (1995). A tutorial on learning with Bayesian networks. Technical Report MSR-TR95-06, Microsoft Research.
Heckerman, D., Geiger, D., & Chickering, D. M. (1995).
Learning Bayesian networks:
The combination of knowledge and statistical data. Machine Learning, 20(3), 197243.
doi:10.1023/A:1022623210503.
Heckerman, D., Mamdani, A., & Wellman, M. P. (1995). Real-world applications of Bayesian
networks. Communications of the ACM, 38(3), 2426. doi:10.1145/203330.203334.
Heckerman, D., Meek, C., & Cooper, G. (1999). A Bayesian approach to causal discovery. In
C. Glymour, & G. F. Cooper (Eds.), Computation, Causation, & Discovery, (pages 141165).
AAAI Press.
Jensen, A. L. (1995). A probabilistic model based decision support system for mildew management
in winter wheat. Ph.D. thesis, Dina Foulum, Research Center Foulum, Aalborg University.
Kayaalp, M., & Cooper, G. F. (2002). A Bayesian network scoring metric that is based on globally
uniform parameter priors. In A. Darwiche, & N. Friedman (Eds.), Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence (UAI-02), (pages 251258). Morgan
Kaufmann.

445

fiDALY & S HEN

Kirkpatrick, S., Gelatt, C. D., Jr., & Vecchi, M. P. (1983). Optimization by simulated annealing.
Science, 220(4598), 671680. doi:10.1126/science.220.4598.671.
Kristensen, K., & Rasmussen, I. A. (2002). The use of a Bayesian network in the design of a decision
support system for growing malting barley without use of pesticides. Computers and Electronics
in Agriculture, 33(3), 197217. doi:10.1016/S0168-1699(02)00007-8.
Kullback, S., & Leibler, R. A. (1951). On information and sufficiency. The Annals of Mathematical
Statistics, 22(1), 7986. doi:10.1214/aoms/1177729694.
Levine, J., & Ducatelle, F. (2004). Ant colony optimisation and local search for bin packing
and cutting stock problems. Journal of the Operational Research Society, 55(7), 705716.
doi:10.1057/palgrave.jors.2601771.
Maniezzo, V., & Colorni, A. (1999). The ant system applied to the quadratic assignment problem.
IEEE Transactions on Knowledge and Data Engineering, 11(5), 769778. doi:10.1109/69.806935.
Microsoft Research (1995). Win95pts. A model for printer troubleshooting in Microsoft Windows
95.
Mitchell, M. (1996). An Introduction to Genetic Algorithms. MIT Press.
Moore, A., & Wong, W.-K. (2003). Optimal reinsertion: A new search operator for accelerated and
more accurate Bayesian network structure learning. In T. Fawcett, & N. Mishra (Eds.), Proceedings
of the Twentieth International Conference on Machine Learning, (pages 552559). AAAI Press.
Mhlenbein, H. (1997). The equation for response to selection and its use for prediction. Evolutionary
Computation, 5(3), 303346. doi:10.1162/evco.1997.5.3.303.
Munteanu, P., & Bendou, M. (2001). The EQ framework for learning equivalence classes of Bayesian
networks. In Proceedings of the 2001 IEEE International Conference on Data Mining, (pages
417424). IEEE Computer Society. doi:10.1109/ICDM.2001.989547.
Munteanu, P., & Cau, D. (2000). Efficient score-based learning of equivalence classes of Bayesian
networks. In D. A. Zighed, H. J. Komorowski, & J. M. Zytkow (Eds.), Proceedings of the Fourth
European Conference on the Principles of Data Mining and Knowledge Discovery (PKDD 2000),
volume 1910 of Lecture Notes in Computer Science, (pages 96105). Springer. doi:10.1007/3-54045372-5_10.
Muruzbal, J., & Cotta, C. (2004). A primer on the evolution of equivalence classes of Bayesiannetwork structures. In X. Yao, E. Burke, J. A. Lozano, J. Smith, J. J. Merelo-Guervs, J. A.
Bullinaria, J. Rowe, P. Tino, A. Kabn, & H.-P. Schwefel (Eds.), Proceedings of the 8th International Conference on Parallel Problem Solving from Nature - PPSN VIII, volume 3242 of Lecture
Notes in Computer Science, (pages 612621). Springer. doi:10.1007/b100601.
Nielsen, J. D., Kocka, T., & Pea, J. (2003). On local optima in learning Bayesian networks. In
C. Meek, & U. Kjrulff (Eds.), Proceedings of the Ninteenth Conference on Uncertainty in
Artificial Intelligence, (pages 435444). Morgan Kaufmann.
Ott, S., Imoto, S., & Miyano, S. (2004). Finding optimal models for small gene networks. In
Proceedings of the Ninth Pacific Symposium on Biocomputing, (pages 557567). World Scientific.
446

fiL EARNING BAYESIAN N ETWORK E QUIVALENCE C LASSES WITH A NT C OLONY O PTIMIZATION

Ott, S., & Miyano, S. (2003). Finding optimal gene networks using biological constraints. Genome
Informatics, 14, 124133.
Rasmussen, L. K. (1995). Bayesian Network for Blood Typing and Parentage Verification of Cattle.
Ph.D. thesis, Dina Foulum, Research Center Foulum.
Schwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics, 6(2), 461464.
doi:10.1214/aos/1176344136.
Shaughnessy, P., & Livingston, G. (2005). Evaluating the causal explanatory value of Bayesian
network structure learning algorithms. Research Paper 2005-013, Department of Computer Science,
University of Massachusetts Lowell.
Shimony, S. E. (1994). Finding maps for belief networks is NP-hard. Artificial Intelligence, 68(2),
399410. doi:10.1016/0004-3702(94)90072-8.
Silander, T., Kontkanen, P., & Myllymaki, P. (2007). On sensitivity of the MAP Bayesian network
structure to the equivalent sample size parameter. In Proceedings of the Twenty-Third Conference
on Uncertainty in Artificial Intelligence (UAI-07).
Spirtes, P., & Glymour, C. (1990). An algorithm for fast recovery of sparse causal graphs. Report
CMU-PHIL-15, Department of Philosophy, Carnegie Mellon University.
Spirtes, P., Glymour, C., & Scheines, R. (2000). Causation, Prediction, and Search. Adaptive
Computation and Machine Learning. The MIT Press, 2nd edition.
Spirtes, P., Meek, C., & Richardson, T. (1995). Causal inference in the presence of latent variables
and selection bias. In P. Besnard, & S. Hanks (Eds.), Proceedings of the Eleventh Conference on
Uncertainty in Artificial Intelligence (UAI-95), (pages 499506). Morgan Kaufmann.
Steck, H., & Jaakkola, T. S. (2003). On the Dirichlet prior and Bayesian regularization. In
S. Becker, S. Thrun, & K. Obermayer (Eds.), Advances in Neural Information Processing Systems
15 (NIPS*2002), (pages 697704). The MIT Press.
Sttzle, T. (1998). An ant approach to the flow shop problem. In Proceedings of the Sixth European
Congress on Intelligent Techniques and Soft Computing (EUFIT 98), volume 3, (pages 1560 
1564). Aachen, Germany: ELITE Foundation.
Sutton, R. S., & Barto, A. G. (1998). Reinforcement Learning: An Introduction. MIT Press.
Tsamardinos, I., Brown, L. E., & Aliferis, C. F. (2006). The max-min hill-climbing Bayesian network
structure learning algorithm. Machine Learning, 65(1), 3178. doi:10.1007/s10994-006-6889-7.
van der Putten, P., & van Someren, M. (2004). A bias-variance analysis of a real world
learning problem: The CoIL challenge 2000.
Machine Learning, 57(1-2), 177195.
doi:10.1023/B:MACH.0000035476.95130.99.
Verma, T., & Pearl, J. (1991). Equivalence and synthesis of causal models. In P. Bonissone,
M. Henrion, L. Kanal, & J. Lemmer (Eds.), Uncertainty in Artificial Intelligence 6, (pages 255
268). North-Holland.

447

fiJournal of Artificial Intelligence Research 35 (2009) 119-159

Submitted 11/08; published 06/09

Trust-Based Mechanisms for Robust and Efficient Task Allocation in
the Presence of Execution Uncertainty
Sarvapali D. Ramchurn

SDR @ ECS . SOTON . AC . UK

Intelligence, Agents, Multimedia
School of Electronics and Computer Science
University of Southampton, Southampton, UK

Claudio Mezzetti

C . MEZZETTI @ WARWICK . AC . UK

Department of Economics
University of Warwick, Coventry, UK

Andrea Giovannucci

AGIOVANNUCCI @ IUA . UPF. EDU

SPECS Laboratory
Pompeu Fabra University
Barcelona, Spain

Juan A. Rodriguez-Aguilar

JAR @ IIIA . CSIC . ES

Artificial Intelligence Research Institute
Spanish Council for Scientific Research
Barcelona, Spain

Rajdeep K. Dash
Nicholas R. Jennings

RKD @ ECS . SOTON . AC . UK
NRJ @ ECS . SOTON . AC . UK

Intelligence, Agents, Multimedia
School of Electronics and Computer Science
University of Southampton, Southampton, UK

Abstract
Vickrey-Clarke-Groves (VCG) mechanisms are often used to allocate tasks to selfish and rational
agents. VCG mechanisms are incentive compatible, direct mechanisms that are efficient (i.e., maximise social utility) and individually rational (i.e., agents prefer to join rather than opt out). However, an important assumption of these mechanisms is that the agents will always successfully complete their allocated tasks. Clearly, this assumption is unrealistic in many real-world applications,
where agents can, and often do, fail in their endeavours. Moreover, whether an agent is deemed to
have failed may be perceived differently by different agents. Such subjective perceptions about an
agents probability of succeeding at a given task are often captured and reasoned about using the
notion of trust. Given this background, in this paper we investigate the design of novel mechanisms
that take into account the trust between agents when allocating tasks.
Specifically, we develop a new class of mechanisms, called trust-based mechanisms, that can
take into account multiple subjective measures of the probability of an agent succeeding at a given
task and produce allocations that maximise social utility, whilst ensuring that no agent obtains
a negative utility. We then show that such mechanisms pose a challenging new combinatorial
optimisation problem (that is NP-complete), devise a novel representation for solving the problem,
and develop an effective integer programming solution (that can solve instances with about 2  105
possible allocations in 40 seconds).
c
2009
AI Access Foundation. All rights reserved.

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

1. Introduction
Task allocation is an important and challenging problem within the field of multi-agent systems.
The problem involves deciding how to assign a number of tasks to a set of agents according to some
allocation protocol. For example, a number of computational jobs may need to be allocated to agents
that run high performance computing data centres (Byde, 2006), a number of network maintenance
tasks may need to be performed by communications companies for a number of business clients
(Jennings, Faratin, Norman, OBrien, Odgers, & Alty, 2000), or a number of transportation tasks
may need to be allocated to a number of delivery companies (Sandholm, 1993). In the general case,
the agents performing these jobs or asking for these jobs to be performed will be trying to maximise
their own gains (e.g., companies owning data centres or servers will be trying to minimise the
number of servers utilised, communications companies will try to minimise the number of people
needed to complete the tasks demanded, and transportation companies will try to use the minimum
number of vehicles). Given this, Mechanism Design (MD) techniques can be employed to design
these task allocation protocols since these techniques can produce solutions that have provable and
desirable properties when faced with autonomous and utility maximising actors (Dash, Parkes, &
Jennings, 2003). In particular, the Vickrey-Clarke-Groves (VCG) class of mechanisms has been
advocated in a number of problem domains (Walsh & Wellman, 1998; Hershberger & Suri, 2001;
Dash et al., 2003) because they maximise social welfare (i.e., they are efficient) and guarantee a nonnegative utility to the participating agents (i.e., they are individually rational). In such mechanisms,
agents typically reveal their costs for performing the tasks or their valuation of the requested tasks to
a centre and the centre then computes the allocation of tasks to each agent and the payments they all
need to make and receive. However, an important underpinning assumption that such mechanisms
make is that an agent always successfully completes every task that is assigned to it by the centre.
The result of this assumption is that an allocation (i.e., an assignment of tasks that are asked for
by requester agents and executed by task performer agents) is selected by the centre based only
on the costs or valuations provided by the agents. This ensures that the centre always chooses the
performers that are the cheapest and the requesters that are ready to pay the most. However, the
agents chosen by the centre may ultimately not be successful in completing their assignment. For
example, an agent providing access to a data centre with a cost of 10, but with a success rate of
100%, might be preferable to one providing the same service with a cheaper cost of 5 but with a
10% chance of being successful. Thus, in order to make efficient allocations in such circumstances,
we need to design mechanisms that consider both the task performers costs for the service and their
probability of success (POS). Now, this probability may be perceived differently by different agents
because they typically have different standards or means of evaluating the performance of their
counterparts. For example, different customers might evaluate the performance of a data centre in
different ways such as timeliness, security, or quality of the output. Given this, we turn to the notion
of trust to capture such subjective perceptions (Ramchurn, Huynh, & Jennings, 2004). To take into
account the agents trust in other agents, as well as their costs, when allocating tasks requires the
design of a new class of mechanisms that we have previously termed trust-based (Dash, Ramchurn,
& Jennings, 2004).
To date, however, existing work on trust-based mechanisms (TBMs) ignores a number of important aspects of the task allocation problem which makes them less robust to uncertainty (see Section
2 for more details). First, Porter, Ronen, Shoham, and Tennenholtz (2008) only allow POS reports
to come from the task performer, rather than any other agent. This means the task requester can
2

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

be misled by the task performers opinion (even if it is truthfully revealed) since the task requester
may believe, at times, that the task performer failed while the task performer believes it has succeeded. Second, in our previous work (Dash et al., 2004), we presented a trust-based mechanism
that could result in inefficient allocations as agents had strong incentives to over-report their POS.
Even more importantly, however, existing trust-based mechanisms completely ignore the computational cost associated with including the POS and computing the optimal allocation and payments.
Thus, while previous work highlights the economic benefits, they do not specify how the new problem can be effectively represented and efficiently solved. By ignoring these issues, previous work
has failed to prove that such mechanisms can actually be implemented, solved, and whether they
scale up to reasonable numbers of agents.
Against this background, this paper provides economically efficient and individually rational
mechanisms for scenarios in which there exists uncertainty about agents successfully completing
their assigned tasks. This execution uncertainty can generally be modelled as follows. First, potential task performers are assessed by a task requester that uses both its individual experience of their
performance and information gathered from its environment (such as reports by other agents about
their performance) to construct its estimation of their POS. Often these sources are called confidence and reputation respectively (Ramchurn et al., 2004; Dasgupta, 1998), and when combined
they give the notion of trust in an agent performing a particular task. This combined view of trust
is used here because it is a more robust measure of POS than any single estimate (especially one
originating from the task performer). This is evident from the fact that each agent is only likely to
have a partial view of the performance of a task performer because it is derived from a finite subset
of its interactions. For example, a task requester having ten tasks performed by an agent may benefit
from the experience acquired from another requesters fifty interactions with that same agent. However, incorporating trust in the decision mechanism of the requester introduces two major issues.
First, when agents use reports from other agents to build trust, it introduces the possibility of interdependent valuations. This means that the value that is generated by one agent in the system can be
affected by another agents report to the mechanism (Jehiel & Moldovanu, 2001; Mezzetti, 2004).
This, in turn, makes it much harder than in standard VCG-based techniques to incentivise agents to
reveal their private information truthfully. Second, using trust to find the optimal allocation involves
a significant computational cost and we show that solving the optimisation problem of trust-based
mechanisms is NP-complete.
To tackle the issue of interdependence, we build upon the work by Mezzetti (2004, 2007) to
construct a novel mechanism that incentivises agents to reveal their private information. Moreover, to help combat the computational complexity generated by trust, we go on to develop a novel
representation for the optimisation problem posed by trust-based mechanisms and provide an implementation based on Integer Programming (IP). Given this, we show that the main bottleneck of
the mechanism lies in searching through a large set of possible allocations, but demonstrate that our
IP solution can comfortably solve small and medium instances within minutes (e.g., for 6 tasks and
50 agents) or hours (e.g., for 8 tasks and 70 agents).1 In so doing, we provide the first benchmark
for algorithms that aim to solve such optimisation problems.
In more detail, this paper advances the state of the art in the following ways:

1. Though the time taken to find the optimal solution grows exponentially with the number of tasks, our mechanism sets
the baseline performance in solving the optimisation problem posed by trust-based mechanisms.

3

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

1. We design novel TBMs that can allocate tasks when there is uncertainty about their completion. Our TBMs are non-trivial extensions to the paper by Porter et al. (2008) because they
are the first to consider the reputation of a task performer within the system, in addition to its
self-report. This allows us to build greater robustness into the mechanism since it takes into
account the subjective perceptions of all agents (task requesters in particular) about the POS
of task performers.
2. We prove that our TBMs are incentive compatible, efficient and individually rational.
3. We develop a novel representation for the optimisation problem posed by TBMs and, given
this, cast the problem as a special matching problem (Berge, 1973). We show that solving
the generalised version of TBMs is NP-complete and provide the first Integer Programming
solution for it. This solution can solve instances of 50 agents and 6 tasks within one minute
and even larger instances within hours.
The rest of the paper is structured as follows. We start by providing an overview of the related
work in Section 2. We then provide the contributions listed above in a step-wise manner. First,
a simple task allocation model is detailed in Section 3, where we introduce the TBM for a single
requester, single task scenario. Section 4 then develops the generalised TBM for multiple requesters
and multiple tasks and we prove its economic properties. Having dealt with the economic aspects,
we then turn to the computational problem of implementing TBMs in Section 5. Specifically, we
develop a new representation for the optimisation problem posed by the generalised TBM, study
the computational costs associated with solving the problem, and provide an IP-based solution to it.
Section 6 then discusses a number of broader issues related to the development of future trust-based
mechanisms.

2. Related Work
In associating uncertainty to mechanism design, we build upon work in both areas. With regards to
capturing uncertainty in multi-agent interactions, most work has focused on devising computational
models of trust and reputation (see papers by Teacy, Patel, Jennings, & Luck, 2006, and Ramchurn
et al., 2004, for reviews). These models mostly use statistical methods to estimate the reliability of
an opponent from other agents reports and direct interactions with the opponent. Some of these
models also try to identify false or inaccurate reports by checking how closely each report matches
an agents direct experience with the opponent (Teacy et al., 2006; Jurca & Faltings, 2006). Now,
while these models can help in choosing the most successful agents, they are not shown to generate
efficient outcomes in any given mechanism. In contrast, in this paper we provide the means to use
such models in order to do just this.
In the case of MD, there has been surprisingly little work on achieving efficient, incentive compatible and individually rational mechanisms that take into account uncertainty in general. The
approaches adopted can be separated into work on reputation mechanisms and mechanisms for
task or resource allocation. The former mainly aim at eliciting honest feedback from reputation
providers. Examples of such mechanisms include papers by Dellarocas (2002), Miller, Resnick,
and Zeckhauser (2005), and Jurca and Faltings (2003, 2006). In particular, Miller et al. (2005) recently developed the peer prediction model, which incentivises agents to report truthfully about their
experience. Their mechanism operates by rewarding reporters according to how well their reports
4

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

coincide with the experience of their peers. Specifically, it assigns scores to the distance between
a given agents report and other selected reference reporters reports on a given task performer. In
a similar way, Jurca and Faltings (2007) have also attempted to solve the same problem by placing
more importance on the repeated presence of agents in the system in order to induce truthful reporting. However, given that they focus on eliciting honest feedback, their mechanism is silent as to
what this feedback is actually used for. In particular, it cannot be employed in the task allocation
scenario we study in this paper because in our case the objective is to maximise the overall utility
of the society that, therefore, considers the value and POS of agents. For example, a car repair has
a lower value than building a bridge. Hence, the feedback on the car repairer is less critical than the
feeback on the bridge builder in terms of its impact on the social welfare. Interestingly, their mechanism is shown to have truth-telling as a (non-unique) Nash equilibrium and it is budget balanced,
but not individually rational (see Section 6 on how these social desiderata interplay).
In terms of MD for task allocation, type uncertainty is taken into account by Bayesian mechanisms such as dAGVA (dAspremont & Gerard-Varet, 1979; Arrow, 1979). This considers the
case when the payoffs to the agents are determined via a probability distribution of types which is
common knowledge to all agents. However, this mechanism cannot deal with our problem in which
there is uncertainty about task completion, and each agent has information about the POS of all
other agents, but there is no common knowledge of the type distributions. Porter et al. (2008) have
also considered this task allocation problem and their mechanism is the one that is most closely
related to ours. However, they limit themselves to the case where agents can only report on their
own POS. This is a serious drawback because it assumes the agents can measure their own POS
accurately and it does not consider the case where the agents may have different perceptions on the
POS (e.g., a performer believes that it performs better or worse than what the requester perceives).
Moreover, they only consider a single requester setting, while the mechanisms we develop here
deal with multiple tasks and multiple requesters. Thus, our mechanisms can be considered to be
a two-way generalisation of theirs. First, we allow multiple reports of uncertainty that need to be
fused appropriately to give a precise POS as perceived by the requester. Second, we generalise their
mechanism to the case of multiple requesters where the agents can provide combinatorial valuations
on multiple tasks. In our earlier work on this problem (Dash et al., 2004), we proposed a preliminary TBM where the agents could have followed the risky, but potentially profitable strategy, of
over-reporting their costs or under-reporting their valuations since payments are not made according to whether they succeed or fail in the allocated task (which we do in our new mechanism). In
contrast, in this work, the payment scheme ensures that such a strategy is not viable and thus this
mechanism is more robust. Moreover, our previous work assumed trust functions that were monotonically increasing in POS reports and (similar to Porter et al.) did not develop the algorithms that
are needed to actually solve the optimisation problem posed by a TBM. In this paper, we present a
mechanism that applies to more general trust functions and also develop algorithms to solve TBMs.
Finally, our work is a case of interdependent, multidimensional allocation schemes. With interdependent payoffs, Jehiel and Moldovanu (2001) have shown that is impossible to achieve efficiency
with a one-stage mechanism. Mezzetti (2004), however, has shown that it is possible to achieve efficiency with an elegant two-stage mechanism under very reasonable assumptions. Our mechanism
achieves efficiency without needing two reporting stages because, in the setting we consider, payments can be contingent on whether or not tasks are successful and because agents do not derive a
direct payoff from the allocation of a task to another agent or the other agents assessments about
the completion probabilities. In our setting, there exists a specific function that captures the interde5

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

pendence that exists among the agents through their assessments of each others POS. This function
is, in our case, the agents trust model.

3. Single Requester, Single Task Allocation Mechanisms
In this section, we first present the basic VCG mechanism for a simple task allocation model (a
single task being requested by a single agent) where the allocated task is guaranteed to be completed
(i.e., all agents POS are equal to 1). We then briefly describe Porter et al.s (2008) extension
which considers task performers that have a privately known objective probability that they finish
the assigned task. Finally, we consider the case where the POS of a task performer is a function
of privately known variables held by each task performer in the system. This ensures that the
choice made by the task requester is better informed (drawing data from various sources) about
the POS of task performers. We show how Porter et al.s mechanism would fail to produce the
efficient allocation in such settings and then go on to provide a non-trivial extension of their model
to cater for this. In so doing, we define a new trust-based mechanism for the single requester,
single task scenario (as a prelude to the generalised mechanism that we will develop in the next
section). We then go on to prove the economic properties of this simple TBM. Throughout this
section, a running example task allocation problem is employed to demonstrate the workings of the
mechanisms discussed.
3.1 Allocation with Guaranteed Task Completion
In this task allocation scenario, a single agent derives a value when a certain task is performed. To
this end, that agent needs to allocate the task to one of the available task performers, which will
charge a certain amount to execute the task. We start by considering the following simple example:
Example 1. MoviePictures.com, a computer graphics company, has an image rendering task that
it wishes to complete for a new movie. Hence, MoviePictures.com publicly announces its intention
to all companies owning data centres that can execute the task. Given the interest shown by many
of these companies, MoviePictures.com needs to decide on the mechanism to allocate the contract
and how much to pay the chosen contractor, given that MoviePictures.com does not know all the
contractors costs to execute the job (i.e., it does not know how much it actually costs each company
to process the images and render them to the required quality).
The above example can be captured by the following model. There is a set of agents (data
centre agents in the example), I = {1, 2, . . . , i, . . . , I}, who each have a privately-known cost
ci ( )  R+  {0} of performing the rendering task  . Furthermore, let MoviePictures.com be
represented by a special agent 0, who has a value v0 ( )  R+  {0} for the rendering task and a
cost of c0 ( ) > v0 ( ) to perform the task (c0 ( ) =  in case agent 0 cannot execute the task).
Hence, MoviePictures.com can only get the task performed by another agent in the set I who has a
cost ci ( )  v0 ( ).
Now, MoviePictures.com needs to decide on the procedure to award the contract, and hence,
acts as the centre that will invite offers from the other agents to perform the task. In devising such
a mechanism for task allocation, we focus on incentive-compatible direct revelation mechanisms
(DRMs) by invoking the revelation principle which states that any mechanism can be transformed
into a DRM (Krishna, 2002). In this context, direct revelation means the strategy space (i.e., all
possible actions) of the agents is restricted to reporting their type (i.e., their private information, for
6

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

example their cost or valuation of a task) and incentive-compatible means the equilibrium strategy
(i.e., best strategy under a certain equilibrium concept) is truth-telling.
Thus, in a DRM, the designer has control over two parts: 1) the allocation rule that determines who wins the contract, and 2) the payment rule that determines the transfer of money between the centre (i.e., MoviePictures.com) and the agents (i.e., the data centres). Let K denote
a particular allocation within the space of possible allocations K and  i0 represent that agent
i gets allocated task  from agent 0. Then, in this setting, the space of all possible allocations
are K = {,  10 ,  20 , . . . ,  I0 } where  denotes the case where the task is not allocated.
Moreover, we abuse notation slightly to define the cost of an allocation K to agent i, as being
ci (K) = ci ( ) if K =  i0 and ci (K) = 0 otherwise. Similarly, for the centre, the value of a
non empty allocation is simply the value it has for the task, i.e., v0 (K) = v0 ( ) if K 6=  and
v0 (K) = 0 if K = . Finally, let ri ()  R be the payment by the centre to agent i. In case ri () is
negative, agent i has to pay |ri ()| to the centre.
Within the context of task allocation, direct mechanisms take the form of sealed-bid auctions
where task performers report their costs to a centre (or auctioneer). Agents may not wish to report
their true costs if reporting these falsely leads to a preferable outcome for them. We will therefore
distinguish between the actual costs and the reported ones by superscripting the latter with b.
The task allocation problem then consists of choosing the allocation and payment rules such that
certain desirable system objectives (some of which are detailed below) are satisfied. An allocation
rule is a mapping from reported costs to the set of allocations, with K(b
ci , b
ci ) being the allocation
chosen when agent i reports b
ci and all other agents report the vector b
ci . Similarly, a payment rule
is a mapping from reported costs to payments for each agent, with ri (b
ci , b
ci ) being the payment to
agent i when agent i reports b
ci and all other agents report the vector b
ci .
Following the task execution and payments, an agent i derives a utility given by its utility function ui : K  R  R. As is common in this domain, we assume that an agent is rational (expected
utility maximiser) and has a quasi-linear utility function (MasColell, Whinston, & Green, 1995):
Definition 1. A quasi-linear utility function is one that can be expressed as:
ui (K, ri ) = ri  ci (K)

(1)

where K  K is a given allocation.
Having modelled the problem as above, MoviePictures.com would like to use a protocol that
possesses the desirable properties of efficiency and individual rationality. It also needs to make sure
that the protocol is incentive compatible: agents must find it optimal to report their true costs. These
desiderata can be formally defined as follows:
Definition 2. Efficiency: the allocation mechanism is said to achieve efficiency if the outcome it
generates maximises the total utility of all the agents in the system (without considering transfers).
That is, for all vectors of reports b
c, it calculates K  such that:
"
#
X
b
ci (K)
(2)
K  (b
c) = arg max v0 (K) 
KK

iI

Definition 3. Individual Rationality: the allocation mechanism is said to achieve individual rationality if agents derive higher utility when participating in the mechanism than when opting out of it.
7

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

Assuming that the utility that an agent obtains when opting out is zero, then an individually rational
allocation K is one in which (Krishna, 2002):
ui (K, ri )  0 , i  I

(3)

Definition 4. Incentive compatibility: the allocation mechanism is said to achieve incentive compatibility if an agents true type is its optimal report no matter what other agents report. That
is:
ri (ci , b
ci )  ci (K(ci , b
ci ))  ri (b
ci , b
ci )  ci (K(b
ci , b
ci )) ci , b
ci , b
ci .

Note that incentive compatibility implies that for each vector of reports of the other agents b
ci
the payments to agent i must depend on is own report only through the chosen allocation. Incentive
compatibility requires that telling the truth be a (weakly) dominant strategy. It is also important to
note that incentive compatibility in dominant strategies is the strongest possible form of incentive
compatibility. The VCG mechanism has this property.
MoviePictures.com then decides to employ a Vickrey auction (also known as a second-price
sealed bid auction) since this protocol possesses the desired properties of incentive compatibility,
efficiency, and individual rationality (Krishna, 2002). In more detail, after having received the
sealed bids (reports b
c) from all the agents, the centre calculates the allocation K  (b
c) according to
Equation (2), while the transfer ri () to the winner i is given by:


X
v0 (K  ) 
ri (b
c) = v0 (K  (b
c))  max
b
cj (K  )
(4)

K Ki

jI\i

where Ki is the set of all allocations that do not involve i as a task performer.
3.2 Allocation with Execution Uncertainty

In the mechanism presented in the previous section, it is assumed that once the allocation K  is
decided, its value v0 (K  ) will be obtained by the centre (either v0 ( ) if the task has been allocated
or 0 otherwise). Thus, there is an implicit assumption that once allocated a task, an agent will
always perform it successfully. However, this is unrealistic, as illustrated by the following example:
Example 2. Many of the previous rendering tasks required by MoviePictures.com were allocated
to PoorRender Ltd because of its very competitive prices. Unfortunately, PoorRender Ltd could
not complete the task in many cases because of lack of staff and other technical problems (which
it knew about before even bidding for the task). As a result, MoviePictures.com incurred severe
losses. Hence, MoviePictures.com decides to alter the allocation mechanism in such a way that
the agents POS in completing the tasks can be factored into the selection of the cheapest agent.
MoviePictures.com assumes each contractor knows its own POS and cost privately and needs the
mechanism to elicit this information truthfully in order to choose the best allocation.
The above problem was studied by Porter et al. (2008) and we briefly describe, in our own terms,
their mechanism in order to extend and generalise it later (see Sections 3.3 and 4). We first introduce
the boolean indicator variable  that will denote whether the task has been completed ( = 1) or
not ( = 0). Thus,  is only observable after the task has been allocated. Moreover, we extend
8

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

our notation here to capture the centres valuation of the task execution such that v0 () = v0 (K  )
if  = 1 and v0 () = 0 if  = 0. In this setting, we assume that  is commonly observed (i.e.,
if agent i believes that  = 1, then all agents i  I  {0} believe the same). In our rendering
example,  might denote whether the images are rendered up to the appropriate resolution which
will allow its usage or not. Furthermore, the probability that  = 1 once the task is allocated to
agent i is dependent upon another privately known variable, pi ( )  [0, 1], which is the POS of
agent i in executing task  . Note that this variable is privately known to the task performer i itself,
and so there is a single observation within the system, carried out by the task performer, about its
own POS. Also note that the task performer incurs the cost ci ( ) as soon as it attempts the task 
and irrespective of whether it is successful or not.
As can be seen, the value that the centre (MoviePictures.com) will derive, v0 (), is not known
before the allocation is calculated. Hence, the notions of efficiency and individual rationality introduced in section 3.1 need to be adjusted to this new setting. Given the probability that the task will
be executed by a given agent, we have to consider the expected value of an allocation, v 0 (K, p),
which is calculated as:
v 0 (K, p) = v0 (K)  pi ( )

(5)

where i is the agent chosen to perform the task in allocation K and p = hp1 ( ), . . . , pI ( )i is
the vector of POS values of all the agents (the list of assessments by each contractor of its own
probability that it will complete the rendering task as in our example). We now need to require
b the vector of reported POS values
agents to report their POS, in addition to the cost. We denote as p
hb
p1 ( ), . . . , pbI ( )i.
The following modified desiderata need to be considered now:

Definition 5. Efficiency: a mechanism is said to achieve efficiency if it chooses the allocation that
maximises the sum of expected utilities (without considering the transfers):
#
"
X
b) 
b) = arg max v 0 (K, p
b
ci (K)
(6)
K  (b
c, p
KK

iI

b are reported by the agents and are key to computing the efficient
Note here that both b
ci (K) and p
allocation.
Definition 6. Individual Rationality: a mechanism achieves individual rationality if a participating
agent i derives an expected utility, ui , which is always non-negative:
ui (c, p) = ri (c, p)  ci (K)  0

where ri (c, p) is the expected payment that agent i receives.
In order to achieve these desiderata, one could suppose that a nave extension of the standard
Vickrey mechanism presented above would be sufficient. In such a mechanism, the centre would
ask the agents to report their extended types (b
ci , pbi ( )). The allocation chosen would then be the one
maximising the expected utility of the agents and the payment rule would be conditioned according
to Equation (4) with v 0 (K  , p) replacing v0 (K  ). However, such a mechanism would fail in these
settings, as illustrated in the next section.
9

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

3.2.1 NA IVE A PPLICATION OF THE V ICKREY AUCTION
Example 3. Consider the case where MoviePictures.com derives a value of v0 ( ) = 300 when
the rendering task is completed and let there be three contractors whose costs ci ( ) to render the
images are given by (c1 ( ), c2 ( ), c3 ( )) = (100, 150, 200). Furthermore, assume each contractor
has a POS given by (p1 ( ), p2 ( ), p3 ( )) = (0.5, 0.9, 1). This information is represented in Table
1.
The efficient allocation in this case (shaded line in Table 1) involves assigning the task to agent
2 with an expected social utility of 300  0.9  150 = 120. The payment to agent 2 using the
(reverse) Vickrey auction with expected values is 300  0.9  (300  200) = 170 (from Equation
(4)). However, such a mechanism is not incentive-compatible. For example, if agent 1 reveals that
pb1 ( ) = 1, then the centre will implement K  =  10 and will pay agent 1, r1 = 300120 = 180.
Thus, the agents in such a mechanism are always better off reporting pbi ( ) = 1, no matter what
their actual POS is! Hence, the centre will not be able to implement the efficient allocation.
Agent
1
2
3

ci ( )
100
150
200

pi ( )
0.5
0.9
1

Table 1: Costs of performing task  and each agents own perceived probability of successfully completing
the task.

This type extension (i.e., including the POS) is non-trivial because the POS report of an agent
affects the social value expected by the centre, but not the agents cost under an allocation. As
a result, reporting a higher POS will only positively affect an agents probability of winning the
allocation and thus will positively affect its utility. To rectify this, we need a means by which this
gain in utility is balanced by a penalty so that only on truthfully reporting its type, will an agent
maximise its utility. This is achieved in Porter et al.s (2008) mechanism, which we briefly detail in
the next section.
3.2.2 P ORTER ET AL . S M ECHANISM
This mechanism is based around payments being applied after the completion of tasks. Specifically,
the mechanism finds the marginal contribution that an agent has made to the expected welfare of
other agents depending on whether it completes its assigned task or not. Intuitively, this works since
the payment scheme punishes an agent that is assigned a task but does not complete it (i.e.,  = 0).
As a result, the agent is not incentivised to reveal a higher POS value than its real POS since if it is
then allocated the task, it is more likely to reap a punishment rather than the reward which it obtains
when it successfully completes the task (i.e.,  = 1).
In more detail, the allocation is determined by the centre according to Equation (6). The payment rule for an agent i to which the task  is allocated is similar to that of the VCG in that the
marginal contribution of the agent to the system is extracted by comparing the efficient allocation
b, ) = 0 if it is not allowith the second best allocation, excluding the agent (the agent gets ri (b
c, p
cated the task). The difference is that it is the expected marginal contribution that is extracted (i.e.,
10

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

taking into account the agents real probability of success). This is achieved as follows:



P
 (b
)
, p

b
b
v
(K
c
,
p
))

max
b
c
(K
, if  = 1
v
(K
)


0
0
jI\i j

K  Ki

b, ) =
ri (b
c, p



P


b) 
b
cj (K  )
, if  = 0
 max v 0 (K  , p


(7)

jI\i

K  Ki

where Ki is the set of allocations excluding agent i.
The mechanism would work with the example provided in Table 1 since if, for example, agent
1 reports pb1 ( ) = 1, it will then be allocated the task and will be paid 300  120 = 180 with a
probability of 0.5 and 120 with a probability of 0.5. Thus, on average, agent 1 will be paid 30
but each time it will incur a cost of 100, thereby making an expected utility of 70. Clearly, then,
a rational agent will not overstate its POS. In fact, the incentive compatibility of this mechanism
arises because an agent is expected utility, given it is allocated the task, is:


b) = pi ( ) v0 (K  (b
b))  ci (K  (b
b))  max
ui (b
c, p
c, p
c, p


K Ki



b))  max
+ (1  pi ( )) ci (K  (b
c, p


K Ki



b), p)  ci (K  (b
b))  max
c, p
c, p
= v 0 (K  (b


K Ki



b) 
v 0 (K  , p

b) 
v 0 (K  , p



X

jI\i

b) 
v 0 (K  , p

X

jI\i



b
cj (K  ) 



b
cj (K  ) 

X

jI\i

(8)


b
cj (K  )

Note that the expected utility within this mechanism is the same as what would have been
derived by agents in the nave extension of the VCG if they were truthful in reporting p. However,
in Porter et al.s mechanism, agents do not have an incentive to lie. This is because, if pbi ( ) > pi ( )
(i.e., the agent over-reports its POS), then the agent might be allocated the task even though:
h
i
i 6= arg max v0 (K x )px ( )  cx (K x )
xI

where

Kx

=

 x0 ,

which means it could be that:

b), p)  ci (K  (b
b)) < max
v 0 (K  (b
c, p
c, p


K Ki



X
b) 
b
cj (K  )
v 0 (K  , p
jI\i

This results in the agent deriving a negative utility as per Equation (8). Hence, an agent will not
report higher POS values. A more complete treatment of the proof of the incentive-compatibility
of the mechanism is given in the paper by Porter et al. (2008). Furthermore, the mechanism is also
proven to be individually rational and efficient.
3.3 Allocation with Multiple Reports of Execution Uncertainty
In the previous section, we considered a mechanism in which each agent has only its privately known
estimation of its own uncertainty in task completion. This mechanism considers that the centre can
11

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

only receive a single estimate of each agents POS. We now turn our attention to the previously
unconsidered, but more general, case where several agents may have such an estimate. For example,
a number of agents may have interacted with a given data centre provisioning company on many
occasions in the past and therefore acquired a partial view on the POS of that company. Using such
estimates, the centre can obtain a more accurate picture of a given agents likely performance if
it combines these different estimates together. This combination results in a better estimate for a
number of reasons, including:
1. Accuracy of estimation: The accuracy of an estimation is typically affected by noise. Thus,
combining a number of observations should lead to a more refined estimate than obtaining a
single point estimate.
2. Personal Preferences: Each agent within the system may have different opinions as to what
constitutes success when attempting a task. As a result, the centre may be willing to assign
more weight to an agents estimate if it believes this agents perspective is more similar to its
own.
We illustrate the above points by considering the following example:
Example 4. MoviePictures.com is still not satisfied with the solution chosen so far. This is because
PoorRender Ltd still reports that it has a high POS, even though MoviePictures.com has noticed
that they have failed their task on a number of occasions. This is because PoorRender Ltd believes
the images it rendered were of a high enough quality to be used in a feature film while MoviePictures.com believed they were not. MoviePictures.com therefore cannot rely on the agents own
perception of their POS to decide on the allocation. Rather, MoviePictures.com wants to ask all
agents to submit their perception about each others POS. In so doing, MoviePictures.com aims to
capture the knowledge that agents might have about each other either from previous sub-contracted
tasks or simple observations. To this end, MoviePictures.com needs to devise a mechanism that will
capture all the agents perceptions (including its own) into measures of POS for each agent and use
these fused measures in the selection process.
The above example can be modelled by introducing a new variable, the Expected Quality of
Service (EQOS), noted as ij ( ), which is the perception of each agent i about the POS of agent j
on task  . Now, the vector of agent is EQOS of all agents (including itself) within the system is
noted as  i = hi1 ( ), . . . , iI ( )i. Furthermore, we shall denote as  j the EQOS that all agents
within the system (including itself) have about agent j. Thus, in our image rendering example, ij ( )
might denote the probability as perceived by agent i that the rendering task is completed according
to a certain level of quality of the computer graphics (which is perceived differently by the different
agents). Then, MoviePictures.com needs a function in order to combine the EQOS of all the agents
so as to give it a resultant POS that the movie is rendered up to its own graphic requirements.
In more detail, given is previous personal interaction with j, i can compute, based on the frequency of good and bad interactions, a probability, termed its confidence, in j as the POS. Second,
i can also take into account other agents (i) opinions about j, known as js reputation in the society, in order to compute the POS of j (Ramchurn et al., 2004). The combination of both measures
is generally captured by the concept of trust, which is defined as the aggregate expectation, derived
from the history of direct interactions and information from other sources, that j will complete the
12

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

task assigned to it. The aggregate trust that agent j will successfully complete task  for agent 0 is
a function tr0j : [0, 1]|I|  [0, 1].
There are multiple ways in which the trust function could be computed, but it is often captured
as follows:
tr0j () =

X

wl  lj

(9)

lI

P
where wl  [0, 1] and wl = 1. This function generates trust as a weighted sum of EQOS values.
In some cases, the s are actually considered to be probability distributions and the trust function is
the expected value of the joint distribution constructed from the individually reported distributions
(Teacy et al., 2006; Jurca & Faltings, 2007). Much work exists in the literature that deals with
different ways of combining these distributions such that biases or incompatibilities between agents
perceptions are taken into account. Essentially, however, they all assign weights to different reports
of the agents and choose the expected value of these reports as the trust in an agent. However, to
date, none of these models actually studies how to get self-interested agents to generate such reports
truthfully along with maximising the social welfare.
Now, a direct mechanism in this case elicits from each agent i, its cost and EQOS vector,
{ci ( ),  i }, after which the centre decides on the allocation and payments to the agents. In computing its expected utility in a mechanism, an agent must evaluate the trust, or probability of success,
by the agent who is allocated the task. This raises a conceptual difficulty. How should an agent
treat the other agents POS reports in assessing the probability of task completion (as opposed to
computing its best response to their type reports)? The approach we will take in this paper is that
an agent assumes the reported POS of the other agents is truthful in computing the trust in another
agent; more precisely, an agent computes the value of the trust function by using his true EQOS and
the reported EQOS of the other agents. Thus, the trust of agent i that agent j will be able to comb i ). As we have already seen, in general a payment to an agent depends
plete the task is tr0j ( i , 
b)
on the reported types of all agents and on whether the task succeeds or fails. To this end, let i(b
c, 
b ). Then, define
be the agent who is allocated the task when the vector of reported types is (b
c, 
b ) as
the expected payment to agent i when the true types are (c, ) and the reported types are (b
c, 
follows:
h
i
b ,
b)
b ,
b)
i(c
i(c
b ; c, ) = ri (b
b ,  = 1)tr0
b i ) + ri (b
b ,  = 0) 1  tr0
b i )
Eri (b
c, 
c, 
( i , 
c, 
( i , 
We should point out that the type of an agent (EQOS plus cost) is multidimensional and, as is
common in a multidimensional world, there could be several type reports that generate the same
expected payment to an agent. We are now ready to define the modified notion of incentive compatibility we will use.2

Definition 7. Incentive compatibility (in Dominant Strategies): the allocation mechanism is said
to achieve incentive compatibility in dominant strategies if an agents true type is its optimal report
no matter what the other agents report. That is: c, , b
ci , b
 i , b
ci , b
 i ,
b i ; c, )  ci (K(ci , b
bi, 
b i ; c, )  ci (K(b
Eri (ci , b
ci ,  i , 
ci ))  Eri (b
ci , b
ci , 
ci , b
ci ))

2. That an agent uses the reported POS of the other agents in computing the value of the trust function seems a natural
assumption when an agent can rely on the other agents truthfully reporting their types. This is the case, for example,
when the history of interactions between the POS reporters is publicly known (e.g., on eBay or Amazon).

13

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

Now, in the case where agents do not view the EQOS reports of the other agents as being
truthful, the trust of agent i that agent j will be able to complete the task may depend on both
true and reported types of all agents; in such a case we could relax the incentive compatibility
requirement from dominant strategy to (ex-post) Nash equilibrium (MasColell et al., 1995), which
means that if all the other agents report truthfully, then it is optimal for an agent always to report its
true type, no matter what the true types of the other agents are. After replacing the new trust function
in the definition of the expected payment to agent i, the definition of incentive compatibility would
change to:
Definition 8. Incentive compatibility (in Nash Equilibrium): the allocation mechanism is said to
achieve incentive compatibility in (ex-post) Nash equilibrium if an agents true type is its optimal
report provided other agents report their type truthfully. That is: ci , b
ci ,  i , b
 i , ci ,  i ,
b i ,  i ; c, )  ci (K(b
Eri (ci , ci ,  i ,  i ; c, )  ci (K(ci , ci ))  Eri (b
ci , ci , 
ci , ci ))

We next demonstrate why Porter et al.s mechanism would not work in this setting by extending
example 1.
3.3.1 FAILURE OF P ORTER ET.

AL S

M ECHANISM

Example 5. Two agents have costs for performing a task  requested by the centre and have formed
perceptions on the set of agents I given in Table 2. Suppose that tr0i () = [1i ( ) + 2i ( )]/2, and
v0 ( ) = 1.
Agent
1
2
i
tr0 ()

ci ( i )
0
0

i1 ( )
0.6
0.8
0.7

i2 ( )
1
0.6
0.8

Table 2: Costs and EQOS reports of agents in a single task scenario. The trust of the requester is calculated
assuming truthful reports.

Porter et al. do not specify a procedure that deals with EQOS reports. However, a natural
 ) instead of pbi ( ), and to ignore
extension of their technique would be to allocate according to tr0i (b
all reports of agent i in the computation of its payment. We implement this in the above example.
Agent 2 should be the winner since it generates an expected social utility of 0.8, while agent 1 would
generate a utility of 0.7. The expected utility to the agent allocated the task is then (according to
Equation (8)):
b i )  ci (K  (b
b ))  max
b ) = v0 (K  (b
b ))  tr0i ( i , 
c, 
ui (b
c, 
c, 


K Ki

h

i

 i )  b
cj (K  )
v0 (K  )  tr0j (b

(10)
b i excludes all  reports by agent i, Ki is the set of allocations excluding agent i, and
where 
j  is the agent that is allocated the task under allocation K  . Unfortunately, this extension breaks
incentive compatibility in the following way. Given that the efficient allocation is computed using
b values of all agents (using tr0 (b
b in Equation (6)), the value of the best
the reported 
 ) instead of p
14

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

allocation obtained by removing one agent could be arbitrarily lower. In the example above, if agent
1 reports 12 = 0, the efficient allocation becomes agent 1 with an expected social utility of 0.7 and
agent 1 gets an expected utility of 0.1 because the systems utility drops to 0.6 when its reports are
removed and the allocation recomputed. If agent 1 is truthful it will obtain 0 utility since agent 2
would be the winner in this case. In effect, the removal of an agent from the system breaks the
mechanism because of the interdependence between the valuations introduced by the trust model.
We elaborate further on this issue and show how to solve it in the next section.
We thus need to develop a mechanism that is incentive-compatible when agents are reporting
about their perceptions of other agents POS. In order to do so, however, we now need to additionally
consider the effect that reporting the EQOS vector has on an agents expected utility. Specifically,
we need to develop a trust-based mechanism in which the EQOS reports of an agent do not provide
it with a way of increasing its overall expected utility (as per the intuition behind the VCG). Then,
with the true value of the EQOS, the mechanism will result in the selection of the optimal allocation
of tasks.
3.3.2 T HE S INGLE R EQUESTER S INGLE TASK T RUST-BASED M ECHANISM
Intuitively, the following mechanism works by ascertaining that an agent derives a positive utility
when it successfully completes a task and its EQOS report does not change the allocation in its
favour (thus, the mechanism we develop can be regarded as a generalisation of the paper by Porter
et al., 2008).
In more detail, let i(K) be the agent performing the task under allocation K; the centre first
determines the allocation according to:
#
X
i(K)
b ) = arg max v0 (K)  tr0 (b
K  (b
c, 
) 
b
ci (K)
KK

"

(11)

iI

Having computed the efficient allocation as above, we adopt a similar approach to Porter et
al.s to compute the payments after tasks have been executed (see section 3.2.2). However, the
novelty of our mechanism lies in the use of all agents EQOS reports in the computation of the
efficient allocation (as we showed above). Moreover, we have additional payments for the losers to
incentivise all agents to select the efficient allocation.
Thus, we apply different payments to the cases where the agent winning the allocation succeeds
(i.e.,  = 1) and when it fails (i.e.,  = 0). So if agent i is allocated the task (i.e., K  = { i0 })
the payment is:

b , ) =
ri (b
c, 


b ))  Bi (b
b i ) , if  = 1
c, 
ci , 
 v0 (K  (b


b i )
Bi (b
ci , 

(12)

, if  = 0

where Bi ()  0 is a term independent from is report (a constant from is point of view) that
reduces the payment that needs to be made to the agent. We briefly discuss how the value of Bi ()
could be set to reduce the payout made by the centre later in this section, and we provide greater
detail in section 4.4.
In addition to paying the winner, we also reward the losers k  I \ i in the following way,
depending on whether i succeeds or not:
15

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

b , ) =
rk (b
c, 


b ))  b
b ))  Bk (b
b k ) , if  = 1
c, 
ci (K  (b
c, 
ck , 
 v0 (K  (b


b ))  Bk (b
b k )
b
ci (K  (b
c, 
ck , 

(13)

, if  = 0

Intuitively, the payment scheme aims to incentivise all agents to reveal their type so that the
most efficient allocation is chosen. Let K0i be the allocation assigning the task to agent i. Suppose
b i ) and all other agents report (b
b i ). When
agent i with type (ci ,  i ) reports its type as (b
ci , 
ci , 
agent i wins the task, it will derive the following expected utility:




b i = v0 K0i  tr0i  i , 
b i  ci K0i  Bi (b
b i )
ui K0i ,  i , 
ci , 
(14)

b i reflects the true POS of agent i. When agent k 6= i is assigned the task,
Note that tr0i  i , 
agent i obtains the following expected utility by participating in the mechanism:

 

 

b i = v0 K0k  tr0k  i , 
b i  b
b i )
ui K0k ,  i , 
ck K0k  Bi (b
ci , 
(15)

The only difference between Equations (14) and (15) is the identity of the winner. Hence, by
falsely reporting, agent i can only influence the identity of the winner. Agent is expected utility
in the mechanism is equal to the expected social utility in the system minus a constant independent
of is report. Hence, if agent i is rational it should report its true type, so that the efficient agent
(outcome) is chosen. This shows that the single task trust-based mechanism is incentive compatible
and efficient.3
Proposition 1. The mechanism described by Equations (11), (12), and (13) is incentive compatible.
Proposition 2. The mechanism described by Equations (11), (12), and (13) is efficient.

Proof. Since agent ks report about  k affects the expected utility of all other agents (see Equations
(14) and (15)), we have interdependence between agents payoffs, or valuations. However, no agent
can influence its own transfer through its report, because the computation of agent is payment is
b i (and b
independent of its report 
ci ) and is only dependent on the actual execution of the task and
therefore on the true  i value. It is this feature that permits the implementation of the efficient
allocation with a single-stage mechanism.
To exemplify the payments in our mechanism, consider the following extension of Example 5.
Example 6. Two agents have zero cost for performing a task  requested by the centre and have
EQOS ij ( )  {0.6, 0.7, 0.8} for i, j = 1, 2. Suppose that tr0i () = [1i ( ) + 2i ( )]/2, and
v0 ( ) = 1.
By setting Bi = 0.6 in the above example, we have that the payment to each agent when the
task is completed successfully is 0.4, while the payment when the task fails is 0.6. Hence, the
centre profits from implementing the mechanism. Agents have an incentive to report truthfully, so
that the agent most likely to succeed is allocated the task. Furthermore, all agents are willing to
participate, because the probability of success is at least 0.6 (it is 0.6 in the worst case scenario)
3. We provide a more detailed proof for the generalised case in Section 4.3.

16

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

and hence, agents expect to obtain at least zero from participating: the mechanism is individually rational. Also note that the total expected payment from the centre to all agents is at most
0.8  0.4  2  0.2  0.6  2 = 0.4, but could be as low as 0.6  0.4  2  0.4  0.6  2 = 0. As
we now show, Bi can always be chosen so that individual rationality is satisfied.
Proposition 3. For an appropriate choice of Bi (), the mechanism described by Equations (11),
(12), and (13) is individually rational.
Proof. By not participating in the mechanism, an agent can only obtain 0 utility. However, if an
agent decides to participate, and by virtue of the selection of the efficient allocation (which returns
no allocation if the social welfare generated is less than 0), it is guaranteed, as a winner, to obtain
the utility ui described in Equation (14) or, as a loser, the utility uk in Equation (15). Since in both
cases ui  Bi () when the efficient allocation is chosen, and Bi can be set to 0, the mechanism is
individually rational.
Obviously, since all agents utilities are tied to that of the winning agent, they also lose out if
the winning agent fails but, in expectation, all agents make a profit of at least 0 in case Bi is set to
0. As Example 6 shows, if the centre is trying to minimise payments (and increase its own profits),
it could set Bi to be greater than zero and still satisfy individual rationality. In Section 4.4, we
show how to set Bi to a value that maintains individual rationality while minimising payments in
the general model.
Here we note that sometimes it may be preferable for the centre to give up individual rationality.
Consider, for example, if we modify Example 6 to allow for an additional EQOS value ij ( ) = 0.3
for i, j = 1, 2. To induce type ij ( ) = 0.3 to participate, the centre could set Bi () = 0.3,
so that the payment following success is 0.7 and the payment after failure is 0.3. In the worst
case scenario for the centre (i.e., when the centres profit is the lowest), the total expected payment
in this mechanism is 0.8  0.7  2  0.2  0.3  2 = 1 (in the best case scenario, the total
expected payment is zero). As we shall see in Section 4.4, the centre could substantially reduce
its payments by making Bi () depend on the report of the other agents (i.e., other than i). Still, it
may be preferable for the centre to set Bi () = 0.6, giving up on the participation of agents with
EQOS values ii ( ) = ij ( ) = 0.3. In general, when there are low EQOS types, the centre faces
a trade off between efficient task allocation and payments minimisation. We leave the study of this
trade-off to future work (see Section 6 for some initial thoughts).

4. The Generalised Trust-Based Mechanism
The mechanisms we presented in the previous section dealt with the basic task allocation problem
in which there is one requester, one task, and several performers. Here, we aim to efficiently solve
the more general problem of trust-based interactions in which more than one agent requests or
performs (or both) more than one task. To this end, we extend the single requester single task
setting to the more general one of multiple requesters and multiple tasks in our Generalised TrustBased Mechanism (GTBM). This extension needs to consider a number of complex features on
top of those dealt with previously. First, we need to consider multiple requesters that can each
make requests for sets of tasks and task performers that can each perform sets of tasks as well.
Thus, the centre now acts as a clearing house, determining the allocation and payments from the
17

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

multiple bids from the task requesters and multiple asks from the task performers. This significantly
complicates the problem of incentivising agents to reveal their types since we now have to make
sure that the agents reveal their costs, valuations, and EQOS truthfully over more than one task.
Second, the computation of the efficient allocation and payments will have to consider a much larger
space than previously. Thus, we believe it is important to show how the problem can be modelled,
implemented, and solved to demonstrate how our mechanism scales with increasing numbers of
agents and tasks (the computability aspects are dealt with in Section 5).
The following example illustrates this more general setting.
Example 7. After using the trust-based mechanism for a few months, MoviePictures.com made
significant profits and expanded into several independent business units, each performing rendering
tasks or having rendering tasks performed for certain clients. Now, MoviePictures.com would like
to find ways in which its business units can efficiently allocate tasks amongst themselves. However,
some companies have uncertainties about each others performance of the rendering tasks. For
example, while some business units, such as HighDefFilms.com, believe PoorRender Ltd (now part
of MoviePictures.com) is inefficient, some others, such as GoodFilms.com, believe it is not so bad,
having recently had a large set of animations rendered very well for a very cheap price. To cater for
these differences in opinion while maximising the overall utility, MoviePictures.com needs to extend
the single task trust-based mechanism and implement the generalised mechanism efficiently.
In order to deal with this more complex setting, we extend our task allocation model in the next
subsection, before describing the allocation rule and payment scheme in Section 4.2 and proving
the economic properties of the mechanism in Section 4.3.
4.1 The Extended Task Allocation Setting
Let T = {1 , 2 , ..., M } denote the set of tasks which can be requested or performed (compared
to the single task before). We use the notation  .i to specify that the subset of tasks   T is
performed specifically for agent i.4 Similarly, by adding the superscript to the task,  i.  K
denotes a subset of tasks that agent i performs. Note that there is nothing in our model that restricts
an agent to be only a task performer or requester.
A selected allocation K in this multiple task, multiple requester model then generates a matching problem that involves finding agents that will perform the tasks that are requested by some other
II }). Let the set of all possible allocations be
agents (e.g., K = {111 , 112 , . . . , 1I1I , . . . , M
denoted as K. Note that not all requested tasks need to be allocated: that is, the matching in K need
not be perfect.
In the multiple task case, agents may express valuations and costs for sets of tasks as well as
subsets of these sets of tasks. For example, agent i may have vi (1 , 2 , 3 ) = 100 and vi (1 , 2 ) =
10 and vi (3 ) = 0. Then, if agent i gets 1 , 2 and 3 executed it gets a value of 100, while if
only 1 and 2 get executed and 3 fails, agent i still obtains a value of 10. Similarly, agent i may
have task execution costs ci (4 , 5 , 6 ) = 100 and ci (4 , 5 ) = 40 and ci (6 ) = 10. To capture
such inter-relationships between valuations, let Kij be the set of tasks within the allocation K which
have to be performed by agent j for agent i (Kij could be the empty set). Note that each task is
specific to a task requester. This means that if agents 1 and 2 request task m , then a task performer
4. In this paper, we will not consider agents requesting the performance of multiple units of tasks. Although our model
is easily extensible to this case, the explanation is much more intricate.

18

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

(putting in one bid for m ) matched to m for agent 1, only performs it for agent 1 and not for agent
2. We will abuse notation slightly and define K = {Ki , K i }iI where Ki = (Ki1 , ..., KiI ) and
K i = (K1i , ..., KIi ). An agent i has a value (assuming all the tasks in K will be completed) and cost
for an allocation K, vi (K)  +  {0} and ci (K)  +  {0} respectively, whereby:5
vi (K) = vi (Ki )
ci (K) = ci (K i )
Kh K
that
Moreover, within our model, each agent i has an EQOS vector,  i = {ij (Kh )}j,hI
represents its belief in how successful all agents within the system are at completing the tasks Kh
for agent h. Thus, at the most general level, agent is type is now given by i = {v i , ci ,  i }. For any
j
e j  K j and for any EQOS
given set of tasks Ki
thatfij mustperform for i, for any subset of tasks K
i
i
e j will be completed by
e j fifi K j ,  be the trust that exactly the set of tasks K
vector , we let trj K
i

i

i

i

j. The trust can be computed as we have shown in Section 3.3 by simply replacing agent 0 with
agent i and replacing the single task by the set of tasks T . As in the single requester case, the trust
function represents the aggregate belief that agents have about a given task performer and hence all
task requesters form the same probability
(give all agents EQOS reports) about a given

 fi of success
Q j  e j fifi j 
fi
e
tri Ki fi Ki ,  .
task performer. Finally, we let tri Ki fi Ki ,  =
jI

We are now ready to present the generalised trust-based mechanism.

4.2 The Allocation Rule and Payment Scheme
In our generalised mechanism (GTBM), the task requesters first provide the centre with a list of
tasks they require to be performed, along with their valuation vector associated with each set of
tasks, whereas the task performers provide their costs for performing sets of tasks.6 All agents
also submit their EQOS vector to the centre. Thus, each agent provides the centre with reports
bi = {b
b = (
b1 , ..., 
bI ) is the report profile. Given this, the centre applies the
b i }, so that 

vi, b
ci , 
rules of the mechanism in order to find the allocation K  and net payments ri to each agent i. In
more detail:
1. The centre computes the allocation according to the following:
 
b =
K 

arg max

X

K={Ki ,K i }iI K iI




X

e i Ki
K

e i )  tri
vbi (K




fi

e i fifi Ki , 
b b
ci (K)
K

(16)

Thus, the centre uses the reports of the agents in order to find the allocation that maximises
the expected utility of all agents within the system.
 
b .
2. The agents carry out the tasks allocated to them in the allocation vector K  

5. As a result of this setup, an agent i may not want some sets of tasks to be performed or it may be unable to perform
such tasks. In such cases, we then assign a default value of 0 and cost of  to those sets of tasks.
6. As noted before, task performers can also be task requesters at the same time (and vice versa).

19

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

3. The centre computes the payments to the agents, conditional on completion of the tasks allocated. Let (Ki ) be an indicator function that takes the value one if Ki is the set of all the
tasks (requested by agent i from all agents) that are completed, and takes the value of zero
otherwise. The payment to agent i is as follows:

ri





X 
b () =
,

jI\i

X

e j K  (b)
K
j









ej  b
ej   K
cj
vbj K




 
b 
bi )
K 
  Bi (

(17)

bi )  0 is a constant from is point of view (i.e., it is computed independently
where Bi (
of agent is reports, but it may depend on the reports of the other agents), that can be used to
reduce the payout that the centre has to make.
As we discussed in Section 3.3.2, the centre faces a trade-off. By reducing the value of Bi ()
it induces participation by a larger set of types (i.e., types with low EQOS), but it increases the
centres payments to agents, making the mechanism less profitable for the centre. Thus, the
scale of the payments one might expect from application of the GTBM depends on whether
the centre decides to satisfy the individual rationality constraint, thus making sure that every
type wants to participate. As we shall see in Section 4.4, if the centre decides to satisfy the
individual rationality constraint, then the scale of payments to agent i increases with the lower
bound on trust values that could be derived using is EQOS report.
It should also be noted that the computation of the payments requires solving several optimisation problems (i.e., finding the optimal allocation with and without several reports). As
the number of agents increases, the difficulty of computing payments will increase and it is
important to show how such payments can be efficiently computed. We elaborate on our
solution to this in Section 5. Before doing so, however, we detail and prove the economic
properties of our mechanism in what follows.
4.3 Economic Properties
Here, we provide the proofs of the incentive compatibility7 and efficiency of the mechanism. We
also prove that there are values of Bi which make the mechanism individually rational.
Proposition 4. The GTBM is incentive compatible.
Proof. In order to prove incentive-compatibility, we will analyse agent is best response ( i.e., its
bi = {b
bi . We first calculate the expected
b i } )) when all other agents report 
best report of 
vi, b
ci , 
utility that an agent i will derive given the above mechanism.
7. Again, we place the same caveat on the notion of incentive compatibility we use here as we do in in Section 3.3 (i.e.,
Dominant Strategy or (ex-post) Nash equilibrium depending on whether an agent computes the trust functions by
using the other agents POS reports as if they were true or not).

20

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

by:

b and the true types are  is given
The expected utility of an agent i when the reported types are 


b  =
ui ;

X



b b
e i K  
K
i , i
i









bi , 
bi ,  , 
e i |Ki 
e i )  tri K
b
vi (K
i
i

bi , 
bi
 ci K  





b 
+ Eri ;



(18)

where Eri is the expectation of ri taken with respect to the likelihood of task completion. The
e j ) being equal to one (i.e., all tasks K
e j being
probability attached by i to the indicator variable (K
completed), given
fi that the set
 of tasks requested by j is Kj and all agents different from i report
fi
b
e
b i . Hence, we can now use the formula for the payments to obtain:
 i , is trj Kj fi Kj ,  i , 




 fi
 
bi , 
bi ,  , 
e j fifi Kj 
e j  trj K
b
vbj K
i
i



X 

 Ke j K  b i ,b i 
bi )
b
Eri ;  =
j
  Bi (






jI\i
bi , 
bi
b
cj K  
(19)
If we replace the expression above into the formula for ui we can observe that an agent can only
b The key point to note is that the agent computes
affect its utility with its report by changing K  ().
b i ).
the value of the trust function using the true value of  i ( rather than its reported value 
Now, Equation (16) implies that for all allocations K:




bi , 
bi ;  ,
bi ;   ui 
(20)
ui  i , 


X

because the efficient allocation, computed by taking into account is true type  i and the reported
bi is better than or equal to any other allocation.
types of all other agents 
Given the above condition and since Equation (20) applies to all possible realisations of , the
mechanism is incentive compatible.
Proposition 5. The GTBM is efficient.

Proof. Given the incentive compatibility of the mechanism, the centre will receive truthful reports
from all the agents. As a result, it will compute the allocation according to Equation (16), thereby
leading to an efficient outcome.
Proposition 6. There exist values of Bi () such that the GTBM is individually rational.
Proof. We again begin by making the standard assumption that the agent derives ui = 0, when not
participating in the mechanism. Then, it remains to be shown that the agent derives non-negative
utility from the mechanism. Since the efficient allocation is chosen (and is at worst a null allocation),
the expected utility of each agent is always greater than or equal to Bi () according to Equation
(18). Since Bi () can be set to 0, the mechanism is individually rational.
Note that there are possibly many other values of Bi ( i ), besides Bi = 0, that guarantee individual
rationality.
21

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

Speaking more generally, it can easily be seen that the GTBM mechanism of the multiple task,
multiple requester scenario is a generalisation of the GTBM mechanism with a single requester and
a single task. It is also a generalisation of the mechanism of Porter et al. where they simply assume
that each agent only has an EQOS about its own probability of success. Moreover, in the paper by
Porter et al. for example, Bi is specified as follows:


X

bi ) = max v0 (K  )  pbi ( ) 
Bi (
b
c
(K
)
j

K Ki

jI\i

where pbi ( ) is the reported probability of completion of the agent assigned the task in allocation
K  and Ki is the set of allocations excluding agent i.
4.4 Extracting the Minimum Marginal Contribution

Up to now, we have considered that Bi ( i ) could be set to arbitrary values to try and reduce
the payments made by the centre to all the agents. More interestingly, it should be possible, as
in the standard VCG mechanism, to only pay an agent its marginal contribution to the system.
However, in our case, due to the interdependence of valuations, it is not as simple as comparing the
social welfare with and without a given agent in the system as is commonly done in VCG-based
mechanisms (Porter et al., 2008 is an obvious example of this). This is because, in our case, when
an agent is removed from the domain used to compute the efficient allocation, the remaining EQOS
reports can arbitrarily change the allocation value. This could, in turn, be exploited by other agents
to improve their utility. The example in Section 3.3.1 showing the failure of a simple extension of
Porter et al.s mechanism illustrates this point.
Assuming that the centre wants to induce participation by all agent types, here we propose a
novel approach to extracting the marginal contribution of an agent, by taking into account EQOS
reports of other agents and possible reports that the agent could make. Let Ki be the set of possible
allocations when agent i is excluded from society. The value of Bi () can be chosen such that it is
equivalent to the social utility of the mechanism when agent i is excluded and its EQOS reports are
chosen so as to minimise social utility, that is:



 fi
 
X
X
bi ) =
e j fifi Kj ,  i , 
e j  trj K

b i  b
cj (K) (21)
Bi (
min
max
vbj K
|I||T
|
KKi
 i [0,1]
jI\i e
Kj Kj

It is to be noted that Bi is computed using the lowest trust values that could be derived using is
EQOS reports.
Then, the generalised payment scheme is:



 
   


X  X
 b
b (.) =
ej  b
ej   K

K
 
c
K
v
b
ri ,
j
j


 
b
jI\i K
e j K  
j


 fi

 
X
X
e j fifi Kj ,  i , 
e j  trj K

b i  b
cj (K)
vbj K

min
max
 i [0,1]|I||T | KKi jI\i e
Kj Kj

(22)

22

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

The point to note here is that incentive compatibility (and hence efficiency of the mechanism)
still holds given that the payment scheme is still independent of is reports. In fact, ri rewards i with
the maximum difference that agent i could make by setting all elements in  i to different values in
[0, 1]|I||T | .8
This procedure reduces the payments made by the centre, while keeping individual rationality
since the value of the efficient allocation (given incentive compatibility as proven earlier) is always
higher than or equal to the value of Bi , which means that:
ui (K  (), ) =



X

jI



X

e j K  ( )
K
j





e j  trj
vj K
X






fi

e j fifi Kj () ,   cj (K  ())
K



min
max
 i [0,1]|I||T | KKi jI\i e

X

Kj Kj





e j  trj
vj K




fi

fi
e j fi Kj ,  i ,  i  cj (K)  0;
K

It is also to be noted that the above equation implies that there is no restriction placed on the
functional form of the trust function tr for the payment scheme to work and for the properties of
the mechanism to hold. This is an improvement on previous mechanisms (see Section 2) which had
considered trust functions that are only monotonically increasing in  i for each i.
Now, the choice of Bi determines whether the centre runs the mechanism at a profit or not.
Hence, to understand what the scale of payments may be in the GTBM discussed in this section,
consider the following example.
Example 8. There are n agents, I = {1, ..., n}, each requiring that a single task be performed
for them. All agents have value 1 for the task to be performed for them and have zero cost for
performing all tasks. The EQOS of agent h about agent is probability of succeeding
at the task for
P
i
i
i
agent j is h (Kj )  [x, 1] for all h, i, j = 1, ..., n. Suppose that trj () =
hI h (Kj ) /n.

In the above example, the EQOS of each agent are in the interval [x, 1], so that x can be viewed
as the lower bound on the expected probability of success at each task. From Equation (21) we can
compute the value of Bi :
"P
#
 (K ) + x
X

j
hI\i h
Bi ( i ) =
max
I
n
jI\i

Note that, depending on the value of  i , Bi ( i ) could be any value between (n  1)x and
(n  1)(n  1 + x)/n; Bi increases with the lower bound x on agents EQOS. The actual payment
to agent i will depend on the success or failure of each task (e.g., the payment is Bi if all tasks
fail). From Equation (19), we can calculate the value of the expected payment to agent i as:
"
#
X   (Kj )
X
h
Eri () =
max
 Bi ( i )
I
n
hI
jI\i
" 
#
X   (j)  x
i

n
jI\i

8. This minimisation takes place over the domain of trust values which could be other than [0, 1] in the general case.

23

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

where  (j) is the agent allocated the task for agent j under the efficient allocation rule. Let EV be
the total expected value from all tasks:
"P
#
 (j)
X
iI i
EV () =
n
jI

Note that the total expected value of all tasks is greater than the sum of the expected payments
over all agents, that is:

"  (j)
#
#
"P
 (j)
X
X
X
i
x 
iI i

>
n
n
jI

iI

jI\i

Thus, the centre always profits from the mechanism. A lower bound on the difference between total
P
 (i)
+ (n  1)x]/n. Note also that the lower
expected value and total expected payments is [ iI i
bound on the centres profit from the mechanism increases with the lower bound on EQOS x.
As we pointed out in the discussion of Example 6 in Section 3.3.2, if the centre is trying to minimise payments, it could give up on individual rationality, by increasing Bi , at the cost of inducing
some agent types not to participate in the mechanism. This may be appealing when the probability
of task failure is high; in such cases, the centre may prefer to avoid paying an amount almost as large
as the total value of the tasks. On the other hand, in a number of practical applications the centre
may want to use the mechanism that induces participation by all types, described in this section.
This is certainly the case, for example, if the lower bound on EQOS (i.e., the lower bound on the
probability that tasks are successful) is high. Moreover, our mechanism with participation by all
types is appropriate when the centre mainly seeks to maximise social welfare. Consider, for example, a government that is trying to boost the economy through major public infrastructure projects.
In order to do so, it may be willing to invest in the trust-based mechanism to get the best infrastructures built at the cheapest cost. Moreover, the government may be willing to make a low profit in
order to ensure the survivability of the construction companies by guaranteeing them some payoff
if they participate in the mechanism. Another example where a company might want to involve all
task performers would be a company trying to acquire as much information as possible about all
task performers in order to maximise the returns on its future decisions. Following from our running scenario, say MovePictures.com needs to contract a video editing company to add computer
graphics to a movie that may become a blockbuster if the graphics are well done. In case the task
is successful, MoviePictures.com is likely to get many contracts in the future. It is therefore critical
that all the available information is collected from agents in order to choose the most reliable video
editing company. In this case, MoviePictures.com may accept a smaller short-run profit by running
our mechanism with full participation, in order to guarantee that the selected agent is the best one
and that future contracts will be obtained.
To summarise, in this section we have devised a mechanism that is incentive compatible, individually rational and efficient for task allocation under uncertainty when multiple distributed reports
are used in order to judge this uncertainty. It is to be noted that we did not need two-stage mechanisms, as in the work of Mezzetti (2004), because in our settings we can condition payments on the
completion of the tasks (the indicator function  () captures this dependence of payments on task
completion). So far, we have just considered the economic properties of the mechanisms, but as we
argued earlier, this is only part of the picture. In the next section, we report on its implementation.
24

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

5. Implementing the Generalised Trust-Based Mechanism
As shown above, the addition of trust to the basic task allocation problem not only complicates the
payment scheme, but also requires a larger number of important optimisation steps than the normal
VCG. In more detail, trust-based mechanisms require that agents specify an expected value for a set
of tasks depending on the performer of such tasks which, in turn, means that the space of solutions to
be explored is significantly larger than in common task allocation problems. Moreover, the payment
scheme of trust-based mechanisms requires finding the efficient allocation multiple times with and
without the agents reports. With this added level of complexity, it is important to show that the
mechanisms are actually implementable and that solutions can be found for usefully sized problems
in reasonable time.9
Against the above background, in this section we describe the first formulation and implementation of the GTBM. In particular, in the GTBM, we tackle the main optimisation problem posed
by Equation (16) (which is then repeated several times in the payment scheme). This is commonly
referred to as the winner determination problem in combinatorial auctions. In order to solve it,
we take insight from solutions to combinatorial exchanges which often map the problem to a well
studied matching problem (Kalagnanam & Parkes, 2004; Engel, Wellman, & Lochner, 2006). In
so doing, we develop a novel representation of the optimisation problem by using hypergraphs to
describe the relationships between valuations, trust, and bids by task performers and then cast the
problem as a special hypergraph matching problem. Given this representation, we are then able
to solve the problem using Integer Programming techniques through a concise formulation of the
objective function and constraints.
5.1 Representing the Search Space
It is important to define the search space in such a way that relationships between valuations, bids,
trust, and tasks can be clearly and concisely captured. In particular, our representation aims to map
the GTBM optimisation problem to a matching problem that has been well studied in the literature.
To do this, the representation must allow us to define the whole space of feasible task allocations,
and, subsequently, define how to select them as valid solutions to the GTBM optimisation problem.
Now, to allow bidders (task performers) and askers (task requesters) to express their bids and valuations in a consistent and implementable way, we choose the XOR bidding language. Such a bidding
language requires that an auctioneer can accept at most one bid out of each XOR bid and that each
XOR bid can belong to only one agent. We choose this particular bidding language because it has
been shown that any valuation can be expressed using it (Nisan, 2006).10 An example of an XOR
bid in our context would be {ci (1 , 2 ) XOR ci (1 , 3 ) XOR ci (1 , 2 , 3 )} which means that agent
i would only go for one of these three bids over tasks 1 , 2 and 3 (ci could also be replaced by
vi for task requesters). In terms of our running example, such a bid would express PoorRender
Ltds cost for performing a sound editing task (i.e., 1 ), a movie production task (i.e., 2 ), or both in
combination (i.e., 1 , 2 ).
9. It is already known that computing the efficient allocation and payments for VCG mechanisms is NP-hard (Sandholm,
Suri, Gilpin, & Levine, 2002). Therefore, finding efficient solutions to VCG mechanisms is already a significant
challenge in its own right.
10. Other bidding languages (such as those describing Atomic or OR bids, as in Nisan, 2006) could equally well be used
in our model and would only require minor changes to the constraints that we need to apply.

25

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS


" 
V
H


  

  
 



 

+

fi
ff

$

fi
(

%

fi
)

'

&

"#"
A

(
(

!

H


!"
C
	  

$    
	
%    
	


(
)

&   


(*

'


  

Figure 1: Graphical representation of the GTBM search space. Nodes of the same colour represent valuation
or cost nodes that belong to the same agent (here nodes with v1 belong to agent 1 and those with c4 belong
to agent 4). Edges of the same colour either originate from the same node or end up at the same node.

To build the overall representation of the problem, we first focus on representing expected valuations and costs as well as their relationships. These are depicted in Figure 1. In more detail, we
specify three types of nodes: (1) valuations (along the V column); (2) bids (under the C column);
and (3) task-per-bidder nodes (under the A column). Each node vi ( ) in the V column stands for a
valuation submitted by agent i over a set of tasks   T . Each node cj ( ) in the C column stands
j.
for a bid issued by agent j over tasks   T . Each element of A represents the allocation m
of
a single task m  T to task performer (bidder) j by a task requester yet to be determined (represented by a dot). In other words, the elements in A represent patterns for single-task allocations.
We term such elements task-per-bidder nodes.
Note that it is possible that different valuations come from the same requester. If so they are
labelled by the same subscript. Moreover, since we have opted for an XOR bidding language,
valuations belonging to the very same requester are mutually exclusive.
26

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

5.1.1 D EFINING R ELATIONSHIPS

BETWEEN

VALUATIONS , TASKS ,

AND

B IDS

j.
in A to a node vi (..., m , ...) in V
Given the nodes defined by A, V, and C, by relating a node m
we define the assignment of task m by i to j through the specific valuation vi (..., m , ...). Similarly,
j.
in A to a node cj (..., m , ...) in C we define the assignment of the task to the
by relating a node m
j.
j.
specific bid cj (..., m , ...) by agent j. Therefore, a triple (v, m
, c) where v  V, m
 A, c  C
fully characterises an allocation for task m , namely a single-task allocation. Hence, as can be seen
in Figure 1, we define two types of relationships: between valuations and task-per-bidder nodes
(noted by edges e1 , e2 , ...), and between bids and task-per-bidder nodes (noted by edges e1 , e2 , ...).11
Using these relationships, a valuation can then be related to a set of task-per-bidder nodes if and
only if these fully cover the performance of the task(s) in the valuation. For instance, we can relate
v1 (1 , 2 ) to nodes 14. (agent 4 performs task 1 ) and 22. (agent 2 performs task 2 ) because
they guarantee the performance of tasks 1 and 2 . Similar to valuation relationships, each node C
is only related to the set of task-per-bidder nodes in A into which each bid splits. Thus, in Figure 1,
bid c4 (1 ) is only related to 14. , whereas bid c2 (2 , 3 ) is related to nodes 22. and 32. .
Thus, we can identify the task performers for each task in a given valuation. This is critical since
the GTBM, contrary to common task allocation mechanisms (such as VCG or Mth price auctions),
requires that we identify exactly who performs a task in order to determine the POS of that task (by
virtue of the requesters trust in the performer) and hence the expected value of the task.
As can be seen, our representation allows us to capture all tasks and performers of such tasks
since each valuation node in V can be potentially related to multiple nodes in A; and, likewise, each
bid in the C column can be potentially related to multiple nodes in A. To capture these related relationships precisely, we define special edges that can connect several nodes (e.g., the ones depicted as
e1 , e2 ,   ,e1 , e2 ,... in Figure 1). Such edges are termed hyperedges because they combine a number
of singleton edges. Hence, Figure 1 can be best described as a hypergraph (Berge, 1973). In order
to precisely define the matching problem that the GTBM poses, we elaborate on the formalism of
hypergraphs since this will help in concisely expressing the problem later on. More specifically, the
formal notion of hypergraphs, as introduced in the paper by Berge (1973), is:

Definition 9. Hypergraph. Let X = {x1 , x2 , . . . , xn } be a finite set of n elements, and let E =
{ej |j  J} be a family of subsets of X where J = {1, 2, ...}. The family E is said to be a hypergraph
on X if:
1. ej 6=  (j  J)
2. jJ ej = X.
The pair H = (X, E) is called a hypergraph. The elements x1 , x2 , . . . , xn are called the vertices
and the sets e1 , e2 , . . . , ej are called the hyperedges.
We say that a hypergraph is weighted if we associate to each hyperedge e  E a real number,
w(e), called the weight of e. This is used to give more or less importance to some edges.
From the formal definition of hypergraphs, we observe that Figure 1 results from the overlapping of two separate hypergraphs: (i) the valuation hypergraph that occurs from linking valuations
11. Figure 1 only depicts a sample of all possible relationships for ease of illustration.

27

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

to task-per-bidder nodes; and (ii) the bid hypergraph that occurs from linking each bid to the corresponding task-per-bidder nodes. In what follows, we formally define both hypergraphs from valuations and bids so that later on we can structurally characterise the notions of feasible and optimal
allocations.
5.1.2 T HE VALUATION H YPERGRAPH
The valuation hypergraph highlights the main difference between the GTBM and the common combinatorial exchanges (e.g., those based on traditional VCG or Mth -price auctions). In particular, in
the GTBM valuations need to take into account the trust of the task requester in the task performer
while, in normal combinatorial exchanges, task requesters are indifferent to task performers. This
means the weight of each hyperedge in a valuation hypergraph is dependent on trust and a large
number of edges need to be generated (one per task performer) which is not the case in normal
combinatorial exchanges.
To define the valuation hypergraph, we need to define hyperedges that emanate from each node
in V to one or more nodes in A. To this end, let V = {vi ( ) 6= 0|  T , i  I} and C = {cj ( ) 6=
|  T , j  I} be the sets of all valuations and all bids respectively. Let  j. = {  T |
   T : cj ( ) 6=  and     } be the set of tasks over which agent j submits bids. Hence,
A = {kj. |k   j. , j  I, cj ( )  C} is the set containing all the tasks bid by each bidder.12
Furthermore, we need to define some auxiliary sets as follows. Given a valuation over a set of
tasks  , a set of nodes A  A fulfils it if and only if:
[

{kj. } =  and | | = |A|

kj. A

For instance, the set of nodes A = {14. , 22. } fulfils any valuation over {1 , 2 }. Hence, the
subsets of A that fulfil a valuation over a set of tasks  are expressed using A which is defined as:
[
A = {A  A |
{kj. } =  and | | = |A|}
kj. A

For instance, considering the example in Figure 1,
A{1 ,2 } = {{14. , 24. }, {14. , 22. }, {14. , 25. }}
A{1 ,3 } = {{14. , 34. }, {14. , 32. }}
Given the above definitions, we can now define the set of all hyperedges connected to a valuation
vi ( )  V as:
Eiv ( ) = aA {{vi ( )}  a}
For instance, from Figure 1:
E1v (1 , 2 ) = {e1 , e2 , e3 } and E1v (3 ) = {e4 , e5 },
where e1 = {v1 (1 , 2 ), 14. , 24. }, e2 = {v1 (1 , 2 ), 14. , 22. }, . . . , and so on.
12. Recall that since the mechanism has been proven to be incentive-compatible we can use the agents true valuations
and costs instead of their reported counterparts.

28

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

The set of all hyperedges containing valuations of the very same agent i is defined as:
[
Eiv =
Eiv ( )
 T
Then, the set of hyperedges connecting nodes in V to nodes in A is defined as:
[
Ev =
Eiv
iI

Given this, we define the valuation hypergraph as a pair:
Hv = (V  A, E v )
Thus, each hyperedge in Hv consists of a single valuation vertex corresponding to an element in V
along with a complete task allocation for the valued tasks out of the task-per-bidder nodes in A.
The valuation hypergraph Hv partly defines the space within which a solution needs to be found.
However, in order to define the quality of the solution found, it is important to define the weight
attached to each hyperedge of the hypergraph Hv . The weight of a hyperedge is actually equal to
the expected value of the allocation of the tasks to a set of task performers (bidders). Consider,
for instance, valuation v1 (1 , 2 ). All the possible matchings that fulfil it are represented by all the
pairs (1.1 , 2.1 ). For example, the hyperedge e2 involving the pairing (141 , 221 ) denotes that
agent 4 performs task 1 for agent 1 and agent 2 performs task 2 for agent 1. The expected valuation
associated to this allocation depends on the POS of agents 4 and 2 when performing tasks 1 and 2
respectively.
In this case, the expected valuation associated to e2 is assessed as:
v 1 (141 , 221 ) = v1 (1 , 2 )  p4 (141 )  p2 (221 )+
v1 (1 )  p4 (141 )  (1  p2 (221 ))+
v1 (2 )  (1 

p4 (141 ))



(23)

p2 (221 )

where p is a function that returns the POS of the agent that is assigned a given task (computed using
confidence, reputation, or trust). Notice that the value (1  pi (kij )) represents the probability of
agent i failing to perform task k for agent j. Since no requests are submitted for 1 and 2 alone,
v(1 ) = v(2 ) = 0. Thus, the expected valuation associated to the particular allocation represented
by arc e2 becomes v 1 (141 , 221 ) = v1 (1 , 2 )  p4 (141 )  p2 (221 ). With a similar argument,
we obtain v 1 (141 , 251 ) = v1 (1 , 2 )  p4 (141 )  p5 (251 ) 6= v 1 (141 , 221 ), corresponding
to hyperedge e3 .
Generalising, given a hyperedge e  E v with valuation vi ( ), we can readily build an allocation
for the tasks in  from the elements in e and vi ( ). If p is a function that returns the POS (be it
confidence, reputation, or trust) of a given task performer from each requesters point of view, then
we can compute the expected valuation of the allocation defined by hyperedge e as follows:


X 
Y
Y


v i ( ) =
pj (lji )
1  pj (wji ) 
(24)
vi ( )
  
lj. e,l  
lj. e,w  \ 
29

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

In other words, given a hyperedge e  E v , its weight is assessed using Equation (24) which is
equivalent to the expected value computed in Equation (16) (i.e., the sum of expected values over
all allocations from agent i). Now, given that each edge of the valuation hypergraph is assigned a
weight, Hv is termed a weighted hypergraph.
5.1.3 T HE B ID H YPERGRAPH
To define the bid hypergraph we need to determine the hyperedges that connect bids to task-perbidder nodes. In more detail, given a bid cj ( )  C, we relate it to the task-per-bidder nodes in A
by constructing hyperedge Ejc ( ) = {cj ( )}  {kj. |k   }. This hyperedge is assigned a weight
which is equal to the cost of cj ( ). Then the set of all hyperedges containing all the bids of agent i
can be defined as:
[
Eic =
Eci ( )
 T
Given this, the set of all hyperedges connecting nodes in C to nodes in A can be defined as:
[
Ec =
Eic
iI

Finally, we define the bid hypergraph as a pair:
Hc = (A  C, E c )
In other words, each hyperedge in Hc consists of a single bid vertex corresponding to an element in
C along with the corresponding task-per-bidder nodes in A. Notice that our definitions of valuation
and bid hypergraphs ensure that each hyperedge in H v contains a single valuation from V and each
hyperedge in H c contains a single bid from C.
5.1.4 D EFINING THE M ATCHING P ROBLEM FOR THE GTBM
Having defined the valuation and bid hypergraphs, we can now structurally characterise the notions
of feasible and optimal allocations (these are needed to determine the computational complexity of
the problem and define the objective function in particular). For this purpose, we must firstly recall
some notions of hypergraph theory. In a hypergraph, two hyperedges are said to be adjacent if their
intersection is not empty. Otherwise they are said to be disjoint. For a hypergraph H = (X, E), a
family E   E is defined to be a matching if the hyperedges of E  are pairwise disjoint. With respect
to a given matching E  , a vertex xi is said to be matched or covered if there is a hyperedge in E 
incident to xi . If a vertex is not matched, it is said to be unmatched or exposed. A matching that
leaves no vertices exposed is said to be complete.
Based on the definitions above, we can characterise feasible allocations in the GTBM as follows.
First, we must find a matching for the valuation hypergraph that is not necessarily complete (some
valuations may remain exposed). Second, we must find another matching for the bid hypergraph
that is not necessarily complete either. The two matchings must be related in the following manner:
the task-per-bidder nodes in both matchings should be the same. In other words, given a task-perbidder node, it must be related to some valuation node and to some bid node, or else be excluded
from both matchings. In this way, valuations and bids are linked to create single-task allocations.
For instance, in Figure 1, if e2 belongs to the matching for the valuation hypergraph, then e4 must
30

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

be part of the matching for the bid hypergraph to ensure that there is a bid for 22. and that either
e1 , e2 , or e3 are part of the matching for the bid hypergraph to ensure that there is a bid for 14. .
More formally:




Definition 10. Feasible allocation. We say that a pair (E v , E c ) defines a feasible allocation iff:


 E v is a matching for Hv .


 E c is a matching for Hc .




   A: ( is matched by E v )  ( is matched by E c ).




Given a feasible allocation (E v , E c ) as defined above, it is straightforward to assess the expected utility of all agents within the system as follows:
X

eE v

w(e) 



X

w(e )


e E c

since the weights of the hyperedges in the valuation hypergraph stand for expected valuations and
the weights of the hyperedges in the bid hypergraph stand for costs. Solving Equation (16) in the
GTBM amounts to finding the feasible allocation that maximises the expected utility of all agents
within the system. Therefore, the following definition naturally follows.
Definition 11. GTBM Task Allocation Problem The problem of assessing the task allocation that
maximises the expected utility of all agents within the system amounts to solving:
arg max
(E


v


,E c )

X

eE

wv (e) 

X

wc (e )

(25)


e E c

v



where (E v , E c ) stands for a feasible allocation.
Having defined the matching problem for the GTBM, we next describe our solution to this
problem using Integer Programming techniques that are commonly used to solve such problems
(Cerquides, Endriss, Giovannucci, & Rodrguez-Aguilar, 2007).13
5.2 An Integer Programming Solution
In this section we show how to map the problem posed by Equation (25) into an integer program
(Papadimitriou & Steiglitz, 1982) so that it can be efficiently implemented and solved. Given this
translation, the resulting program can be solved by powerful commercial solvers such as ILOG
CPLEX14 or LINGO.15
13. Other special purpose algorithms (e.g., using dynamic programming or search trees) could also be designed to solve
this combinatorial problem. However, to understand the magnitude of the problem and to compare the difficulty of
solving this problem against other similar problems, we believe it is better to first attempt to find the solution using
standard techniques such as IP.
14. http://www.ilog.com
15. http://www.lindo.com

31

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

5.2.1 O BJECTIVE F UNCTION

AND

S IDE C ONSTRAINTS

The translation of Equation (25) into an IP is reasonably straightforward given our representation.
Thus, solving the GTBM task allocation problem amounts to maximising the following objective
function:
X

xe  wv (e) 

X

ye  wc (e )

(26)

e E c

eE v

where xe  {0, 1} is a binary decision variable representing whether the valuation in hyperedge
e is selected or not, and ye  {0, 1} is a binary decision variable representing whether the bid in
hyperedge e is selected or not. Thus, xe is a decision variable that selects a given valuation with a
given task-bidder matching, and ye selects a given bid.
However, some side constraints must be fulfilled in order to obtain a valid solution. First, the
semantics of the bidding language must be satisfied. Second, if a hyperedge containing a set of taskper-bidder nodes in A is selected, we must ensure that the bids covering such nodes are selected too.
Moreover, as we employ the XOR bidding language, the auctioneer  the centre in our case  can
only select at most one bid per bidder and at most one valuation per asker. Thus, as for bidders, this
constraint translates into:
X
ye  1 i  I
(27)
e Eic

For instance, in Figure 1 this constraint ensures the auctioneer selects one hyperedge out of e1 , e2 ,
and e3 , since they all belong to agent 4 (they all come from nodes labelled with the same subscript
c4 (.)).
For the valuations, the XOR constraints involving them are collected in the following expression:
X
xe  1 i  I
(28)
eEiv

For instance, in Figure 1 this constraint forces the auctioneer to select one hyperedge out of e1 , e2 ,
e3 , e4 , and e5 since they all belong to agent 1 (they all come from nodes labelled with the same
subscript v1 (.)).
If a valuation hyperedge e  E v is selected, the set of task-per-bidder nodes in A connected
to e must be performed by the corresponding bidder agent. For instance, in Figure 1, if hyperedge
e5 is selected, the task-per-bidder nodes 141 and 341 must be covered by some bid of agent 4.
In this case, bid c4 (1 , 3 ) is the one covering those tasks. Thus, if we select hyperedge e5 we are
forced to select bid c4 (1 , 3 ) by selecting hyperedge e3 . Thus, in terms of hyperedges, we must
ensure that the number of valuation hyperarcs containing a given task-per-bidder node is less than
or equal to the number of bid hyperarcs containing it. Graphically, this means that the number of
incident valuation hyperedges in a given node a  A must be less than the number of incident bid
hyperedges in a.
X

eE v ,kj. e

xe 

X

ye

kj.  A

(29)

e E c ,kj. e

In case of no free-disposal (i.e., if we do not allow agents to execute tasks without them being asked
for) we simply have to replace  with =. To summarise, solving the GTBM task allocation problem
32

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

amounts to maximising the objective function defined by expression (26) subject to the constraints
in expressions (27), (28), and (29). Next, we determine the complexity results for this problem.
5.2.2 C OMPLEXITY R ESULTS
Having represented the GTBM task allocation problem and defined the corresponding IP formulation, we analyse its computational complexity in order to show the difficulty in solving the GTBM.
We also identify the main parameters that affect the computational costs of finding the optimal allocation. These parameters should then allow us to determine in which settings the GTBM can be
practically used.
Proposition 7. The GTBM task allocation problem is N P-complete and cannot be approximated
to a ratio n1 in polynomial time unless P = ZPP, where n is the total number of bids and
valuations.
Proof. Notice that our optimisation model, as formalised by Equation (26), naturally translates to a
combinatorial exchange (Kalagnanam, Davenport, & Lee, 2000). This translation can be achieved
using our representation by taking the goods (in a combinatorial exchange) to be the dummy tasks
  T , the bids the elements in C, and the asks the weights of the hyperedges in Hv . Thus, while
bids remain the same in the exchange, the number of valuations may significantly increase. The
reason being that the introduction of trust in our theoretical model makes the initial valuations (asks),
the elements in V, allocation-dependent. Hence, every single valuation in V causes several asks to
be originated for the exchange when considering the bidder to which each task may be allocated
(see examples in Section 5.1.2). As shown by Sandholm et al. (2002), the decision problem for a
binary single-unit combinatorial exchange winner determination problem is N P-complete and the
optimisation problem cannot be approximated to a ratio n1 in polynomial time unless P = ZPP,
where n is the number of bids. Therefore, the optimisation problem is N P-hard, and so it is in
GTBM.
From the above proof, it can be understood that the search space in the GTBM task allocation
problem is significantly larger than in traditional combinatorial exchanges because of the dependency of valuations on the bidders performing tasks. In what follows, we provide a formula that
allows us to calculate exactly how big this search space is. This allows us to determine whether
the instance to be solved can actually be handled by the solver (which will have its own limits on
memory requirements and computation time).
In more detail, say that Ak is the subset of A containing the task-per-bidder nodes referring
to the same tasks. More formally, Ak = {kj.  A | j  I}. From the example in Figure 1,
A2 = {24. , 22. , 25. }. Thus, the expression to assess the number of feasible allocations is:
|E v | =

X X

Y

|Ak |

(30)

iI vi ( )6=0 k 

Observe that the number of possible allocations can be computed as the cardinality of E v (i.e., the
number of valuation hyperarcs) since it exactly determines the number of ways the valuations can
be satisfied by the provided bids. The total number of decision variables of the Integer Program is
thus |E v | + |E c |. Since the number of expected valuations is several times larger than the number of
bids, we expect the number of decision variables associated to bid hyperedges to be much less than
33

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

the number of valuation hyperedges. Hence, assuming that |E c |  |E v |, the number of decision
variables will be of the order of |E v |.
In order to understand the implications of these parameters, consider the case in which all task
performers bid over all tasks and all requesters submit a single valuation over all tasks. Specifically,
consider a scenario with 15 task performers, 20 requesters, and 5 tasks. Given that in this case
|Ak = 5|, the number of allocations is |Ev | = 20  155 = 15187500. In reality, agents may not be
able to submit bids and asks over all tasks and this would result in a significantly lower number of
allocations (given the possible matchings). Hence, to see whether such instances can be practically
solved, in Appendix A, we report the running times of the solver, showing that instances with less
than 2  105 variables can be comfortably solved within 40 seconds (in the worst case). When taken
together, our empirical results and our formula to compute the size of the input (i.e., Equation 30)
allow us to affirm that, even if the computational cost associated to the GTBM has the potential to
be rather high, our solution can handle small and medium sized problems in reasonable time (see
table 3). However, as can be seen, the time to complete grows exponentially with the number of
Set
1
2
3

Tasks
5
8
10

Task Requesters
20
20
20

Task Performers
15
15
15

Worst Case Running Time
34 s
40 mins
3 days

Table 3: Average running times for different numbers of tasks and agents (taken over 300 sample runs for set
1, 50 sample runs for sets 2 and 3).

tasks. During our experimental analysis, we also found that the impact of increasing the number of
task performers and task requesters was not as significant as increasing the number of tasks. This
can be explained by the fact that, given our setup, a larger number of tasks allows significantly more
matchings between bids and asks than a larger number of bids and asks. Hence, many more task
requesters and performers can be accommodated for small numbers of tasks. It should also be noted
that we expect these worst case results to occur fairly rarely on average (much less than half of the
instances generated from the same parameters), as shown in Figure 2 in Appendix A.
Having described the complete picture of the GTBM and its implementation, we next discuss
some important issues that may arise when trying to use a GTBM for task allocation.

6. Discussion
In this paper we have developed task allocation mechanisms that operate effectively when agents
cannot reliably complete tasks assigned to them. Specifically, we have designed a novel Generalised
Trust-Based Mechanism that is efficient and individually rational. This mechanism deals with the
case where task requesters form their opinions about task performers using reports from their environment and their own direct interactions with the performers. In addition to studying the economic
properties of the allocation mechanisms, we provided the optimisation model that generates the solutions that guarantee the efficiency of our mechanism. This optimisation model is the first solver
for trust-based mechanisms (and other mechanisms in which the value of an allocation depends on
the performer of the allocation) and is based on Integer Programming. As a result, we have shown
that the input explodes combinatorially due to the huge number of possible allocations that must
be enumerated. Nevertheless, while the computational cost associated to the GTBM is shown to be
34

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

rather high, given our implementation, we are still able to manage small to medium-sized problems
in reasonable time.
Speaking more generally, our work on trust-based mechanisms has a number of broader implications. First, the GTBM shows how to explicitly blend work on trust models with work on
mechanism design. Since the mechanism guarantees that certain properties hold for task allocation
problems, it can be used as a new, well-founded testbed within which trust models can be evaluated. Up to now, trust models have mainly been tested with randomly generated scenarios and
interactions that obey somewhat ad hoc market rules such as those used in the ART testbed (Fullam,
Klos, Muller, Sabater, Topol, Barber, Rosenschein, & Vercouter, 2005). Second, our work is the
first single-stage interdependent valuations mechanism that is efficient and individually rational (as
opposed to Mezzettis two-stage mechanism). This has been made achievable in the settings we
consider by capturing the interdependence between types through the trust function and making the
payments to the agents contingent on the actual execution of tasks. Another novelty of our approach
is that we are able to extract the (maximum) marginal contribution of an agent despite the valuations being interdependent (as we have shown in Section 4.4). Third, our implementation of GTBM
highlights the importance of considering the computational aspects of any new mechanism, since
these determine whether the mechanism is implementable for realistic scenarios and can indeed
bring about its claimed benefits. Our work is a strong statement in this direction since we provide
the complete picture of the problem, starting from its representation, through its implementation
and sample results, to its complexity analysis.
In practical terms, the GTBM is a step towards building robust multi-agent systems for uncertain
environments. In such environments, it is important to aggregate the agents preferences, while
taking into account the uncertainty in order to ensure that the solutions chosen result in the best
possible outcome for the whole system. Prior to the GTBM, it was not possible to come up with
an efficient solution that would maximise this expected utility. Moreover, the fact that agents can
express their perception of the task performers POS is a new way of building more expressive
interactions between buyers and sellers of services (Sandholm, 2007). We believe that the more
such perceptions are expressed, the better is the ensuing matching between buyers and sellers and
our results are proof of the gain in efficiency this better matching brings about (see sections 3.2.1,
3.3.1, and 4.3).
By introducing GTBM as a new class of mechanisms, this work lays the foundations for several
areas of inquiry. To this end, we outline some of the main areas below.
 Budget Balance: An important economic property of mechanisms in some contexts is budget
balance.16 However, as mentioned in Section 3.3.2, we have designed our TBMs without
considering budget balance. In fact, the GTBM is not budget balanced similar to the VCG and
Porter et al.s mechanism. Now, one possible way of overcoming this problem is to sacrifice
either efficiency or individual rationality. In fact, the dAGVA mechanism is a counterpart of
the VCG which does indeed sacrifice individual rationality for budget balance (see Section
2). Moreover, Parkes, Kalagnanam, and Eso (2001) develop mechanisms where a number
of budget balancing schemes are proposed and near-incentive compatibility is attained by
making the payments by the agents as close as possible to those of the VCG ones. Their
16. If a mechanism is budget balanced, it computes transfers in each allocation such that the overall transfer in the system
is zero (MasColellP
et al., 1995). Thus, in a budget balanced mechanism, for each allocation K and associated transfer
vector r, we have ri  r ri = 0.

35

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

most effective scheme, the Threshold rule, results in a low loss of incentive-compatibility
and it has a relatively high efficiency (around 80%). Such budget balance may be useful in
situations where the centre cannot run the risk of incurring a loss in generating the efficient
outcome for the set of agents in the system. For example, MoviePictures.com may not find
it worth injecting money into the system to find the efficient outcome if all its subunits are
all nearly equally competitive (both in price and POS). Instead MoviePictures.com might
prefer a mechanism that generates a near-efficient outcome by increasing Bi as discussed in
Section 4.4. By doing this, the set of agents that participate might be reduced because it is
not individually rational for all of them to participate in the mechanism, but, nevertheless,
MoviePictures.com may obtain a better outcome. In the future, we will study such trade-offs
between the efficiency achieved in the system against the profit made by the centre.
 Trust in Task Requesters: One other potential criticism of mechanisms such as ours is that
the task requesters (and the centre) must be trusted to reveal the observed execution of the task
(Mezzetti, 2004). However, in our setting, task requesters have a strong incentive to reveal
their observations (in case these are not publicly visible) since they would prefer their chosen
task performer to be available the next time the mechanism is run. To this end, they must
ensure that the task performer does not go bankrupt. As noted in Equations (12) and (17), the
task performer would have to pay a significant amount to the centre in case it is reported to
fail at its task. Hence, the task requester is better off revealing a successful execution if the
task performer is indeed successful.
Another issue with the trust function used is that weights given to each agents EQOS report
may be uncertain. Thus, in this case, agents may have to learn these weights over multiple
interactions. Given this, it is important to develop learning and search techniques that will
be able to deal with the large number of possible weights that could be used in these trust
functions. These techniques will have to take into account the fact that agents may lose out
significantly while exploring the search space.
 Iterative Mechanisms: The GTBM is a one-shot mechanism in which the allocation and
the payments are calculated given the type of the agents {v, c, } using their trust models.
However, in some cases the participants may be engaged in repeated interactions that can be
exploited by their trust models in order to build accurate trust values of their counterparts.
In such situations, the introduction of multiple rounds can compromise the properties of the
mechanism by allowing for a greater range of strategies (e.g., cornering the market by consistently offering low prices in initial rounds or accepting losses in initial rounds by providing
false and damaging information about competitors). However, the explosion in the strategy
space also implies that agents might not be able to compute their optimal strategy due to the
intractability of such a process. Now, one way of solving this problem is to constrain the
strategies of the agents to be myopic (i.e., best response to the current round) as shown by
Parkes and Ungar (2000) using proxy bidding. Another is to allow the agents to learn the trust
models without participating in the allocation problem. Then, once the agents have an accurate representation of the trust functions and POS values, the mechanism can be implemented
as a one-shot encounter. Note that this problem arises in any one-shot mechanism which is
implemented in an iterative context and is not solely in the realm of the GTBM.
36

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

 Computational Cost: As discussed in Section 5, the algorithms we developed to compute
the efficient allocation have to be run multiple times to compute the individual payments to
the agents for TBMs. Hence, the time needed to compute the allocation and pay the agents
may be impractical if the agents have a very limited time to find a solution, put forward a large
number of bids, or ask for a large number of tasks to be performed. Hence, it is important
that either less complex mechanisms such as those described by Nisan and Ronen (2007)
or approximate (and computationally less expensive) algorithms be developed to solve such
problems (Archer, Papadimitriou, Talwar, & Tardos, 2003). This will require more work in
developing local approximation algorithms and the approximate mechanisms that preserve
some of the properties we seek. In this vein, this paper provides a point of departure for these
future mechanisms since it provides the efficient mechanisms against which the approximate
ones can be compared.
Acknowledgments
We thank the anonymous reviewers for their highly valuable comments; they have allowed us to
improve upon the previous version of this paper, which had a more restrictive mechanism, and
also helped rework the proofs. We are grateful to Juuso Valimaki for initial comments on the
mechanism, and Ioannis Vetsikas, Enrico Gerding, and Archie Chapman for checking the proofs and
discussing the ideas. Juan A. Rodriguez-Aguilar thanks IEA (TIN2006-15662-C02-01), Agreement
Technologies (CONSOLIDER CSD2007-0022, INGENIO 2010) and the Jose Castillejo programme
(JC2008-00337) of the Spanish Ministry of Science and Innovation. Andrea Giovannucci is funded
by a Juan De La Cierva Contract (JCI-2008-03006) and by the EU funded Synthetic Forager project
(ICT-217148-SF). Claudio Mezzetti thanks the Fondazione Cassa di Risparmio di Padova e Rovigo
for support. The research in this paper was also undertaken as part of the ALADDIN (Autonomous
Learning Agents for Decentralised Data and Information Systems) project and is jointly funded
by a BAE Systems and EPSRC (Engineering and Physical Research Council) strategic partnership
(EP/C548051/1).

Appendix A. Analysing the Performance of the IP Solution
In this section we analyse the computational performance of the Integer Programming solution we
detailed in Section 5 in order to gauge the sizes of problems that can be solved in reasonable time. To
this end, it is important to recall that (as was shown in Section 5) the number of input variables to the
optimization problem is nearly equal to the number of valuation hyperedges |Ev |, since |Ec |  |Ev |.
Given this, we can assume that the performance of the solver is directly related to the number of
possible allocations approximated as |Ev |.
Therefore, our test set is composed of several instances of the GTBM Task Allocation Problem
characterised by the number of possible allocations. In more detail, to produce such allocations, bids
and valuations are generated so that the number of bids submitted by a single bidder and the number
of valuations submitted by a single requester follow a geometric distribution with the p parameter
set to 0.23 (Milton & Arnold, 1998) (in order to randomly generate relatively large numbers of
bids/asks per agent).17 A medium-sized problem is set as follows. The number of negotiated tasks
is set to 5. The number of task performers is set to 15 and the number of task requesters is set to 20.
17. Setting p higher would result in fewer bids/asks per agent.

37

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

The average number of generated valuations for each instance is 88 and the average number of bids
is 65. Finally, the number of runs of the experiments is 300. Our experiments were performed on a
Xeon dual processor machine with 3Ghz CPUs, 2 GB RAM and the commercial software employed
to solve the Integer Program is ILOG CPLEX 9.1.

35

Clock time to find optimal solution (seconds)

30

25

20

15

10

5

0

0

0.2

0.4

0.6

0.8
1
1.2
No. of possible allocations

1.4

1.6

1.8

2
5

x 10

Figure 2: Performance of the IP solution.

The results are shown in Figure 2. Specifically, the x-axis represents the number of allocations
of a given problem instance and the y-axis represents the time in seconds elapsed in solving the
corresponding problem instance. Notice that the dependence of the difficulty of the problem on the
number of allocations is quite clear. Moreover, as can be seen, it is possible to solve a problem with
less than 2  105 variables within 40 seconds. It is important to note that the performance of the
solver used is critical in this case and future advancements to Mixed Integer Programming (MIP)
solvers and CPU clock speeds can only improve our results.
Given these results and since we provide a general formula (see Equation (30)) to compute
a priori the number of generated allocations, it is possible to estimate the feasibility of a general
problem before performing it. This means that the system designer can ask task requesters and
performers to constrain the number of tasks they ask for or the number of bids they issue to come
up with an input that can be solved by the program in a reasonable time. It will be more important,
however, to design special purpose algorithms that can deal with larger inputs and this is left as
future work.

References
Archer, A., Papadimitriou, C., Talwar, K., & Tardos, E. (2003). An approximate truthful mechanism
for combinatorial auctions with single parameter agent. Internet Mathematics, 1(2), 129150.
38

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

Arrow, K. J. (1979). The property rights doctrine and demand revelation under incomplete information. In Boskin, M. (Ed.), Economics and Human Welfare. Academic Press.
Berge, C. (1973). Graphs and Hypergraphs. North-Holland Publishing Company.
Byde, A. (2006). A comparison between mechanisms for sequential compute resource auctions. In
Proceedings of the Fifth International Joint Conference on Autonomous Agents and MultiAgent systems (AAMAS-06), pp. 11991201. ACM Press.
Cerquides, J., Endriss, U., Giovannucci, A., & Rodrguez-Aguilar, J. A. (2007). Bidding languages
and winner determination for mixed multi-unit combinatorial auctions. In Proceedings of the
Twentieth International Joint Conference on Artificial Intelligence, pp. 12211226.
Dasgupta, P. (1998). Trust as a commodity. In Gambetta, D. (Ed.), Trust: Making and Breaking
Cooperative Relations, pp. 4972. Blackwell.
Dash, R. K., Parkes, D. C., & Jennings, N. R. (2003). Computational mechanism design: A call to
arms. IEEE Intelligent Systems, 18(6), 4047.
Dash, R. K., Ramchurn, S. D., & Jennings, N. R. (2004). Trust-based mechanism design. In
Proceedings of the Third International Joint Conference on Autonomous Agents and MultiAgent Systems (AAMAS-04), Vol. 2, pp. 726753.
dAspremont, C., & Gerard-Varet, L. A. (1979). Incentives and incomplete information. Journal of
Public Economics, 11(1), 2545.
Dellarocas, C. (2002). Goodwill hunting: An economically efficient online feedback mechanism
for environments with variable product quality. In Proceedings of the (AAMAS-02) Workshop
on Agent-Mediated Electronic Commerce, pp. 238252.
Engel, Y., Wellman, M. P., & Lochner, K. (2006). Bid expressiveness and clearing algorithms in
multi-attribute double auctions. In Proceedings of the Seventh ACM Conference on Electronic
Commerce (EC-06), pp. 110119.
Fullam, K., Klos, T., Muller, G., Sabater, J., Topol, Z., Barber, K. S., Rosenschein, J., & Vercouter,
L. (2005). The agent reputation and trust (ART) testbed architecture. In Proceedings of the
(AAMAS-05) Workshop on Trust in Agent Societies, pp. 5062.
Hershberger, J., & Suri, S. (2001). Vickrey pricing in network routing: Fast payment computation.
In Proceedings of the Forty-Second IEEE Symposium on Foundations of Computer Science,
pp. 252259.
Jehiel, P., & Moldovanu, B. (2001). Efficient design with interdependent valuations. Econometrica,
69(5), 123759.
Jennings, N. R., Faratin, P., Norman, T. J., OBrien, P., Odgers, B., & Alty, J. L. (2000). Implementing a business process management system using adept: A real-world case study. International Journal of Applied Artificial Intelligence, 14(5), 421465.
Jurca, R., & Faltings, B. (2003). An incentive compatible reputation mechanism. In Proceedings of
the IEEE Conference on E-Commerce (CEC-03), pp. 285292.
Jurca, R., & Faltings, B. (2006). Minimum payments that reward honest reputation feedback. In
Proceedings of the Seventh ACM conference on Electronic commerce (EC-06), pp. 190199.
39

fiR AMCHURN , M EZZETTI , G IOVANNUCCI , RODRIGUEZ , DASH , AND J ENNINGS

Jurca, R., & Faltings, B. (2007). Obtaining reliable feedback for sanctioning reputation mechanisms.
Journal of Artificial Intelligence Research (JAIR), 29, 391419.
Kalagnanam, J., Davenport, A. J., & Lee, H. S. (2000). Computational aspects of clearing continuous double auctions with assignment constraints and indivisible demand. Tech. rep., IBM
Research RC21660(97613).
Kalagnanam, J., & Parkes, D. C. (2004). Auctions, bidding and exchange design. In Simchi-Levi,
D., Wu, S. D., & Shen, M. (Eds.), Handbook of Quantitative Supply Chain Analysis: Modeling
in the E-Business Era, International Series in Operations Research and Management Science,
chap. 5. Kluwer.
Krishna, V. (2002). Auction Theory. Academic Press.
MasColell, A., Whinston, M., & Green, J. (1995). Microeconomic Theory. Oxford University Press.
Mezzetti, C. (2004). Mechanism design with interdependent valuations: Efficiency. Econometrica,
72(5), 16171626.
Mezzetti, C. (2007). Mechanism design with interdependent valuations: Surplus extraction. Economic Theory, 31(3), 473488.
Miller, N., Resnick, P., & Zeckhauser, R. (2005). Eliciting honest feedback: The peer prediction
method. Management Science, 51(9), 13591373.
Milton, J., & Arnold, J. C. (1998). Introduction to Probability and Statistics. Principles and Applications For Engineering and the Computing Sciences. McGraw-Hill Inc.
Nisan, N. (2006). Bidding languages for combinatorial auctions. In Cramton, P., Shoham, Y., &
Steinberg, R. (Eds.), Combinatorial Auctions, pp. 215231. MIT Press.
Nisan, N., & Ronen, A. (2007). Computationally feasible VCG mechanisms. Journal of Artificial
Intelligence Research (JAIR), 29, 1947.
Papadimitriou, C. H., & Steiglitz, K. (1982). Combinatorial optimization: algorithms and complexity. Prentice-Hall, Inc., Upper Saddle River, NJ, USA.
Parkes, D. C., Kalagnanam, J. R., & Eso, M. (2001). Achieving budget-balance with vickreybased payment schemes in exchanges. In Proceedings of Seventeenth International Joint
Conference on Artificial Intelligence (IJCAI-01), pp. 11611168.
Parkes, D. C., & Ungar, L. H. (2000). Preventing strategic manipulation in iterative auctions: Proxy
agents and price-adjustment. In Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on Innovative Applications of Artificial Intelligence, pp. 8289.
Porter, R., Ronen, A., Shoham, Y., & Tennenholtz, M. (2008). Fault tolerant mechanism design.
Artificial Intelligence, 172(15), 17831799.
Ramchurn, S. D., Huynh, D., & Jennings, N. R. (2004). Trust in multi-agent systems. The Knowledge Engineering Review, 19, 125.
Sandholm, T. (2007). Expressive commerce and its application to sourcing: How we conducted 35
billion of generalized combinatorial auctions. AI Magazine, 28(3), 4558.
40

fiT RUST-BASED M ECHANISMS FOR ROBUST AND E FFICIENT TASK A LLOCATION

Sandholm, T., Suri, S., Gilpin, A., & Levine, D. (2002). Winner determination in combinatorial
auction generalizations. In Proceedings of the First International Joint Conference on Autonomous Agents and Multi-Agent Systems (AAMAS-02), pp. 6976.
Sandholm, T. W. (1993). An implementation of the contract net protocol based on marginal cost
calculations. In Proceedings of the Twelfth International Workshop on Distributed Artificial
Intelligence, pp. 295308.
Teacy, W. T. L., Patel, J., Jennings, N. R., & Luck, M. (2006). Travos: Trust and reputation in
the context of inaccurate information sources. Autonomous Agents and Multi-Agent Systems,
12(2), 183198.
Walsh, W., & Wellman, M. (1998). A market protocol for decentralized task allocation. In Proceedings of the Third International Conference on Multi-Agent Systems (ICMAS-98).

41

fiJournal of Artificial Intelligence Research 35 (2009) 235-274

Submitted 08/08; published 06/09

A Bilinear Programming Approach for Multiagent Planning
Marek Petrik

petrik@cs.umass.edu

Shlomo Zilberstein

shlomo@cs.umass.edu

Department of Computer Science
University of Massachusetts, Amherst, MA 01003, USA

Abstract
Multiagent planning and coordination problems are common and known to be computationally hard. We show that a wide range of two-agent problems can be formulated
as bilinear programs. We present a successive approximation algorithm that significantly
outperforms the coverage set algorithm, which is the state-of-the-art method for this class
of multiagent problems. Because the algorithm is formulated for bilinear programs, it is
more general and simpler to implement. The new algorithm can be terminated at any time
andunlike the coverage set algorithmit facilitates the derivation of a useful online performance bound. It is also much more efficient, on average reducing the computation time
of the optimal solution by about four orders of magnitude. Finally, we introduce an automatic dimensionality reduction method that improves the effectiveness of the algorithm,
extending its applicability to new domains and providing a new way to analyze a subclass
of bilinear programs.

1. Introduction
We present a new approach for solving a range of multiagent planning and coordination
problems using bilinear programming. The problems we focus on represent various extensions of the Markov decision process (MDP) to multiagent settings. The success of MDP
algorithms for planning and learning under uncertainty has motivated researchers to extend
the model to cooperative multiagent problems. One possibility is to assume that all the
agents share all the information about the underlying state. This results in a multiagent
Markov decision process (Boutilier, 1999), which is essentially an MDP with a factored
action set. A more complex alternative is to allow only partial sharing of information
among agents. In these settings, several agentseach having different partial information
about the worldmust cooperate with each other in order to achieve some joint objective. Such problems are common in practice and can be modeled as decentralized partially
observable MDPs (DEC-POMDPs) (Bernstein, Zilberstein, & Immerman, 2000). Some refinements of this model have been studied, for example by making certain independence
assumptions (Becker, Zilberstein, & Lesser, 2003) or by adding explicit communication
actions (Goldman & Zilberstein, 2008). DEC-POMDPs are closely related to extensive
games (Rubinstein, 1997). In fact, any DEC-POMDP represents an exponentially larger
extensive game with a common objective. Unfortunately, DEC-POMDPs with just two
agents are intractable in general, unlike MDPs that can be solved in polynomial time.
Despite recent progress in solving DEC-POMDPs, even state-of-the-art algorithms are
generally limited to very small problems (Seuken & Zilberstein, 2008). This has motivated
the development of algorithms that either solve a restricted class of problems (Becker,
c
2009
AI Access Foundation. All rights reserved.

fiPetrik & Zilberstein

Lesser, & Zilberstein, 2004; Kim, Nair, Varakantham, Tambe, & Yokoo, 2006) or provide
only approximate solutions (Emery-Montemerlo, Gordon, Schneider, & Thrun, 2004; Nair,
Roth, Yokoo, & Tambe, 2004; Seuken & Zilberstein, 2007). In this paper, we introduce
an efficient algorithm for several restricted classes, most notably decentralized MDPs with
transition and observation independence (Becker et al., 2003). For the sake of simplicity,
we denote this model as DEC-MDP, although this is usually used to denote the model
without the independence assumptions. The objective in these problems is to maximize the
cumulative reward of a set of cooperative agents over some finite horizon. Each agent can
be viewed as a single decision-maker operating on its own local MDP. What complicates
the problem is the fact that all these MDPs are linked through a common reward function
that depends on their states.
The coverage set algorithm (CSA) was the first optimal algorithm to solve efficiently
transition and observation independent DEC-MDPs (Becker, Zilberstein, Lesser, & Goldman, 2004). By exploiting the fact that the interaction between the agents is limited
compared to their individual local problems, CSA can solve problems that cannot be solved
by the more general exact DEC-POMDP algorithms. It also exhibits good anytime behavior. However, the anytime behavior is of limited applicability because solution quality is
only known in hindsight, after the algorithm terminates.
We develop a new approach to solve DEC-MDPsas well as a range of other multiagent
planning problemsby representing them as bilinear programs. We also present an efficient
new algorithm for solving these kinds of separable bilinear problems. When the algorithm
is applied to DEC-MDPs, it improves efficiency by several orders of magnitude compared
with previous state-of the art algorithms (Becker, 2006; Petrik & Zilberstein, 2007a). In
addition, the algorithm provides useful runtime bounds on the approximation error, which
makes it more useful as an anytime algorithm. Finally, the algorithm is formulated for
general separable bilinear programs and therefore it can be easily applied to a range of
other problems.
The rest of the paper is organized as follows. First, in Section 2, we describe the basic
bilinear program formulation and how a range of multiagent planning problems can be
expressed within this framework. In Section 3, we describe a new successive approximation
algorithm for bilinear programs. The performance of the algorithm depends heavily on the
number of interactions between the agents. To address that, we propose in Section 4 a
method that automatically reduces the number of interactions and provides a bound on
the degradation in solution quality. Furthermore, to be able to project the computational
effort required to solve a given problem instance, we develop offline approximation bounds
in Section 5. In Section 6, we examine the performance of the approach on a standard
benchmark problem. We conclude with a summary of the results and a discussion of future
work that could further improve the performance of this approach.

2. Formulating Multiagent Planning Problems as Bilinear Programs
We begin with a formal description of bilinear programs and the different types of multiagent
planning problems that can be formulated as such. In addition to multiagent planning
problems, bilinear programs can be used to solve a variety of other problems such as robotic
manipulation (Pang, Trinkle, & Lo, 1996), bilinear separation (Bennett & Mangasarian,
236

fiA Bilinear Programming Approach for Multiagent Planning

1992), and even general linear complementarity problems (Mangasarian, 1995). We focus on
multiagent planning problems where this formulation turns out to be particularly effective.
Definition 1. A separable bilinear program in the normal form is defined as follows:
maximize
w,x,y,z

T
T
T
T
f (w, x, y, z) = sT
1 w + r1 x + x Cy + r2 y + s2 z

subject to A1 x + B1 w = b1

(1)

A2 y + B2 z = b2
w, x, y, z  0

The size of the program is the total number of variables in w, x, y and z. The number of
variables in y determines the dimensionality of the program1 .
Unless otherwise specified, all vectors are column vectors. We use boldface 0 and 1
to denote vectors of zeros and ones respectively of the appropriate dimensions. This program specifies two linear programs that are connected only through the nonlinear objective
function term xT Cy. The program contains two types of variables. The first type includes
the variables x, y that appear in the bilinear term of the objective function. The second
type includes the additional variables w, z that do not appear in the bilinear term. As we
show later, this distinction is important because the complexity of the algorithm we propose
depends mostly on the dimensionality of the problem, which is the number of variables y
involved in the bilinear term.
The bilinear program in Eq. (1) is separable because the constraints on x and w are
independent of the constraints on y and z. That is, the variables that participate in the
bilinear term of the objective function are independently constrained. The theory of nonseparable bilinear programs is much more complicated and the corresponding algorithms
are not as efficient (Horst & Tuy, 1996). Thus, we limit the discussion in this paper to
separable bilinear programs and often omit the term separable. As discussed later in
more detail, a separable bilinear program may be seen as a concave minimization problem
with multiple local minima. It can be shown that solving this problem is NP-complete,
compared to polynomial time complexity of linear programs.
In addition to the formulation of the bilinear program shown in Eq. (1), we also use the
following formulation, stated in terms of inequalities:
maximize
x,y

xT Cy

subject to A1 x  b1

x0

A2 y  b2

y0

(2)

The latter formulation can be easily transformed into the normal form using standard
transformations of linear programs (Vanderbei, 2001). In particular, we can introduce slack
1. It is possible to define the dimensionality in terms of x, or the minimum of dimensions of x and y. The
issue is discussed in Appendix B.

237

fiPetrik & Zilberstein

variables w, z to obtain the following identical bilinear program in the normal form:
xT Cy

maximize
w,x,y,z

subject to A1 x  w = b1
A2 y  z = b2

(3)

w, x, y, z  0
We use the following matrix and block matrix notation in the paper. Matrices are
denoted by square brackets, with columns separated by commas and rows separated by
semicolons. Columns haveprecedence
over rows. For example, the notation [A, B; C, D]

corresponds to the matrix

A
C

B
.
D

As we show later, the presence of the variables w, z in the objective function may prevent
a crucial function from being convex. Since this has an unfavorable impact on the properties
of the bilinear program, we introduce a compact form of the problem.
Definition 2. We say that the bilinear program in Eq. (1) is in a compact form when s1
and s2 are zero vectors. It is in a semi-compact form if s2 is a zero vector.
The compactness requirement is not limiting because any bilinear program in the form
shown in Eq. (1) can be expressed in a semi-compact form as follows:
maximize
w,x,y,z,x,y

sT
1w

+

r1T x

+

xT

subject to A1 x + B1 w = b1
x = 1 y =

 

 C 0
y
x
+ r2T y
y
0 1
A2 y + B2 z = b2

(4)

sT
2z

w, x, y, z  0
Clearly, feasible solutions of Eq. (1) and Eq. (4) have the same objective value when y is set
appropriately. Notice that the dimensionality of the bilinear term in the objective function
increases by 1 for both x and y. Hence, this transformation increases the dimensionality of
the program by 1.
The rest of this section describes several classes of multiagent planning problems that can
be formulated as bilinear programs. Starting with observation and transition independent
DEC-MDPs, we extend the formulation to allow a different objective function (maximizing
average reward over an infinite horizon), to handle interdependent observations, and to find
Nash equilibria in competitive settings.
2.1 DEC-MDPs
As mentioned previously, any transition-independent and observation-independent DECMDP (Becker et al., 2004) may be formulated as a bilinear program. Intuitively, a DECMDP is transition independent when no agent can influence the other agents transitions. A
DEC-MDP is observation independent when no agent can observe the states of other agents.
These assumptions are crucial since they ensure a lower complexity of the problem (Becker
238

fiA Bilinear Programming Approach for Multiagent Planning

et al., 2004). In the remainder of the paper, we use simply the term DEC-MDP to refer to
transition and observation independent DEC-MDP.
The DEC-MDP model has proved useful in several multiagent planning domains. One
example that we use is the Mars rover planning problem (Bresina, Golden, Smith, & Washington, 1999), first formulated as a DEC-MDP by Becker et al. (2003). This domain
involves two autonomous rovers that visit several sites in a given order and may decide to
perform certain scientific experiments at each site. The overall activity must be completed
within a given time limit. The uncertainty about the duration of each experiment is modeled by a given discrete distribution. While the rovers operate independently and receive
local rewards for each completed experiment, the global reward function also depends on
some experiments completed by both rovers. The interaction between the rovers is thus
limited to a relatively small number of such overlapping tasks. We return to this problem
and describe it in more detail in Section 6.
A DEC-MDP problem is composed of two MDPs with state-sets S1 , S2 and action sets
A1 , A2 . The functions r1 and r2 define local rewards for action-state pairs. The initial
state distributions are 1 and 2 . The MDPs are coupled through a global reward function
defined by the matrix R. Each entry R(i, j) represents the joint reward for the state-action
i by one agent and j by the other. Our definition of a DEC-MDP is based on the work of
Becker et al. (2004), with some modifications that we discuss below.
Definition 3. A two-agent transition and observation independent DEC-MDP with extended reward structure is defined by a tuple hS, F, , A, P, Ri:
 S = (S1 , S2 ) is the factored set of world states
 F = (F1  S1 , F2  S2 ) is the factored set of terminal states.
  = (1 , 2 ) where i : Si 7 [0, 1] are the initial state distribution functions
 A = (A1 , A2 ) is the factored set of actions
 P = (P1 , P2 ), Pi : Si  Ai  Si 7 [0, 1] are the transition functions. Let a  Ai
be an action, then Pia : Si  Si 7 [0, 1] is a stochastic transition matrix such that
Pi (s, a, s0 ) = Pia (s, s0 ) is the probability of a transition from state s  Si to state
s0  Si of agent i, assuming it takes action a. The transitions from the final states
have 0 probability; that is Pi (s, a, s0 ) = 0 if s  Fi , s0  Si , and a  Ai .
 R = (r1 , r2 , R) where ri : Si  Ai 7 R are the local reward functions and
R : (S1  A1 )  (S2  A2 ) 7 R is the global reward function. Local rewards ri are
represented as vectors, and R is a matrix with (s1 , a1 ) as rows and (s2 , a2 ) as columns.
Definition 3 differs from the original definition of transition and observation independent DEC-MDP (Becker et al. 2004, Definition 1) in two ways. The modifications allow
us to explicitly capture assumptions that are implicit in previous work. First, the individual MDPs in our model are formulated as stochastic shortest-path problems (Bertsekas &
Tsitsiklis, 1996). That is, there is no explicit time horizon, but instead some states are
terminal. The process stops upon reaching a terminal state. The objective is to maximize
the cumulative reward received before reaching the terminal states.
The second modification of the original definition is that Definition 3 generalizes the
reward structure of the DEC-MDP formulation, using the extended reward structure. The
joint rewards in the original DEC-MDP are defined only for the joint states (s1  S1 , s2  S2 )
239

fiPetrik & Zilberstein

s11

s21

s12

s22

s13

s23

s31

t1

s1

s2

s3
t2

s32

t3

s33

Figure 1: An MDP and its stochastic shortest path version with time horizon 3. The dotted
circles are terminal states.

visited by both agents simultaneously. That is, if agent 1 visits states s11 , s12 and agent 2
visits states s21 , s22 , then the reward can only be defined for joint states (s11 , s21 ) and (s12 , s22 ).
However, our DEC-MDP formulation with extended reward structure also allows the reward
to depend on (s11 , s22 ) and (s12 , s21 ), even when they are not visited simultaneously. As a result,
the global reward may depend on the history, not only on the current state. Note that this
reward structure is more general than what is commonly used in DEC-POMDPs.
We prefer the more general definition because it has been already implicitly used in
previous work. In particular, this extended reward structure arises from introducing the
primitive and compound events in the work of Becker et al. (2004). This reward structure
is necessary to capture the characteristics of the Mars rover benchmark. Interestingly,
this extension does not complicate our proposed solution methods in any way. Note that
the stochastic shortest path formulation (right side of Figure 1) inherently eliminates any
loops because time always advances when an action is taken. Therefore, every state in that
representation may be visited at most once. This property is commonly used when an MDP
is formulated as a linear program (Puterman, 2005).
The solution of a DEC-MDP is a deterministic stationary policy  = (1 , 2 ), where
i : Si 7 Ai is the standard MDP policy (Puterman, 2005) for agent i. In particular, i (si )
represents the action taken by agent i in state si . To define the bilinear program, we use
variables x(s1 , a1 ) to denote the probability that agent 1 visits state s1 and takes action a1
and y(s2 , a2 ) to denote the same for agent 2. These are the standard dual variables in MDP
formulation. Given a solution in terms of x for agent 1, the policy is calculated for s  S1
as follows, breaking ties arbitrarily.
1 (s) = arg max x(s, a)
aA1

The policy 2 is similarly calculated from y. The correctness of the policy calculation follows
from the existence of an optimal policy that is deterministic and depends only on the local
states of that agent (Becker et al., 2004).
The objective in DEC-MDPs in terms of x and y is then to maximize:
X
X
X X
r1 (s1 , a1 )x(s1 , a1 ) +
R(s1 , a1 , s2 , a2 )x(s1 , a1 )y(s2 , a2 ) +
r2 (s2 , a2 )y(s2 , a2 ).
s1 S1
a1 A1

s1 S1 s2 S2
a1 A1 a2 A2

s2 S2
a2 A2

The stochastic shortest path representation is more general because any finite-horizon MDP
can be represented as such by keeping track of time as part of the state, as illustrated
240

fiA Bilinear Programming Approach for Multiagent Planning

s11

s21

s12

r1

s13

s22

s14

s23
s24

s25

Figure 2: A sample DEC-MDP.

in Figure 1. This modification allows us to apply the model directly to the Mars rover
benchmark problem. Actions in the Mars rover problem may have different durations,
while all actions in finite-horizon MDPs take the same amount of time.
A DEC-MDP problem with an extended reward structure can be formulated as a bilinear mathematical program as follows. Vector variables x and y represent the state-action
probabilities for each agent, as used in the dual linear formulation of MDPs. Given the transition and observation independence, the feasible regions may be defined by linear equalities
A1 x = 1 and x  0, and A2 y = 2 and y  0. The matrices A1 and A2 are the same
as for the dual formulation of total expected reward MDPs (Puterman, 2005), representing
the following equalities for agent i:
X
a0 Ai

X X

x(s0 , a0 ) 

Pi (s, a, s0 )x(s, a) = i (s0 ),

sSi aAi

for every s0  Si . As described above, variables x(s, a) represent the probabilities of visiting
the state s and taking action a by the appropriate agent during plan execution. Note that
for agent 2, the variables are y(s, a) rather than x(s, a). Intuitively, these equalities ensure
that the probability of entering each non-terminal state, through either the initial step or
from other states, is the same as the probability of leaving the state. The bilinear problem
is then formulated as follows:
maximize
x,y

r1T x + xT Ry + r2T y

subject to A1 x = 1

x0

A2 y =  2

y0

(5)

In this formulation, we treat the initial state distributions i as vectors, based on a fixed
ordering of the states. The following simple example illustrates the formulation.
Example 4. Consider a DEC-MDP with two agents, depicted in Figure 2. The transitions
in this problem are deterministic, and thus all the branches represent actions ai , ordered for
each state from left to right. In some states, only one action is available. The shared reward
r1 , denoted by a dotted line, is received when both agents visit the state. The local rewards
are denoted by the numbers above next to the states. The terminal states are omitted. The
241

fiPetrik & Zilberstein

agents start in states s11 and s21 respectively. The bilinear formulation of this problem is:
maximize
subject to

x(s14 , a1 )  r1  y(s24 , a1 )
x(s11 , a1 )
1
1
x(s2 , a1 ) + x(s2 , a2 )  x(s11 , a1 )
x(s13 , a1 )  x(s12 , a1 )
x(s14 , a1 )  x(s12 , a2 )

=1
=0
=0
=0

y(s21 , a1 ) + y(s21 , a2 )
y(s22 , a1 )  y(s21 , a1 )
y(s23 , a1 )  y(s22 , a1 )
y(s24 , a1 )  y(s22 , a1 )
y(s25 , a1 )  y(s23 , a1 )

=1
=0
=0
=0
=0

While the results in this paper focus on two-agent problems, our approach can be extended to DEC-MDPs with more than two agents in two ways. The first approach requires
that each component of the global reward depends on at most two agents. The DEC-MDP
then may be viewed as a graph with vertices representing agents and edges representing
the immediate interactions or dependencies. To formulate the problem as a bilinear program, this graph must be bipartite. Interestingly, this class of problems has been previously
formulated (Kim et al., 2006). Let G1 and G2 be the indices of the agents in the two
partitions of the bipartite graph. Then the problem can be formulated as follows:
X
T
maximize
riT xi + xT
i Rij yj + rj yj
x,y

iG1 ,jG2

subject to Ai xi = 1

x i  0 i  G1

Aj yj = 2

yj  0 j  G2

(6)

Here, Rij denotes the global reward for interactions between agents i and j. This program is bilinear and separable because the constraints on the variables in G1 and G2 are
independent.
The second approach to generalize the framework is to represent the DEC-MDP as a
multilinear program. In that case, no restrictions on the reward structure are necessary.
An algorithm to solve, say a trilinear program, could be almost identical to the algorithm
we propose, except that the best response would be calculated using bilinear, not linear
programs. However, the scalability of this approach to more than a few agents is doubtful.
2.2 Average-Reward Infinite-Horizon DEC-MDPs
The previous formulation deals with finite-horizon DEC-MDPs. An average-reward problem may also be formulated as a bilinear program (Petrik & Zilberstein, 2007b). This
is particularly useful for infinite-horizon DEC-MDPs. For example, consider the infinitehorizon version of the Multiple Access Broadcast Channel (MABC) (Rosberg, 1983; Ooi &
Wornell, 1996). In this problem, which has been used widely in recent studies of decentralized decision making, two communication devices share a single channel, and they need to
periodically transmit some data. However, the channel can transmit only a single message
at a time. When both agents send messages at the same time, this leads to a collision, and
the transmission fails. The memory of the devices is limited, thus they need to send the
messages sooner rather than later. We adapt the model from the work of Rosberg (1983),
which is particularly suitable because it assumes no sharing of local information among the
devices.
242

fiA Bilinear Programming Approach for Multiagent Planning

The definition of average-reward two-agent transition and observation independent DECMDP is the same as Definition 3, with the exception of the terminal states, policy, and objective. There are no terminal states in average-reward DEC-MDPs, and the policy (1 , 2 )
may be stochastic. That is, i (s, a) 7 [0, 1] is the probability of agent i taking an action
a in state s. The objective is to find a stationary infinite-horizon policy  that maximizes
the average reward, or gain, defined as follows.
Definition 5. Let  = (1 , 2 ) be a stochastic policy, and Xt and Yt be random variables
that represent the probability distributions over the state-action pairs at time t of the two
agents respectively according to . The gain G of the policy  is then defined for states
s1  S1 and s2  S2 as:
"N 1
#
X
1
G(s , s ) = lim
E(s1 ,1 (s1 )),(s2 ,2 (s2 ))
r1 (Xt ) + R(Xt , Yt ) + r2 (Yt ) ,
N  N
1

2

t=0

where i (si ) is the distribution over the actions in state si . Note that the expectation is
with respect to the initial states and action distributions (s1 , 1 (s1 )), (s2 , 2 (s2 )).
The actual gain of a policy depends on the agents initial state distributions 1 , 2
and may be expressed as 1T G2 , with G represented as a matrix. Puterman (2005), for
example, provides a more detailed discussion of the definition and meaning of policy gain.
To simplify the bilinear formulation of the average-reward DEC-MDP, we assume that
r1 = 0 and r2 = 0. The bilinear program follows.
maximize
p1 ,p2 ,q1 ,q2

 (p1 , p2 , q1 , q2 ) = pT
1 Rp2

subject to pX
1 , p2  0
s0  S1
p1 (s0 , a) 
s0  S1
s0  S2
s0  S2

aA
X1
aA
X1
aA
X2
aA2

p1 (s0 , a) +
p2 (s0 , a) 
p2 (s0 , a) +

X


p1 (s, a)P1a s, s0 = 0

sS
X1 ,aA1

q1 (s0 , a) 

aAX
1

X


q1 (s, a)P1a s, s0 = 1 (s0 )

sS1 ,aA1

p2 (s, a)P2a s, s0

sS
X2 ,aA2

q2 (s0 , a) 

aA2

X

(7)

=0


q2 (s, a)P2a s, s0 = 2 (s0 )

sS2 ,aA2

The variables in the program come from the dual formulation of the average-reward MDP
linear program (Puterman, 2005). The state sets of the MDPs is divided into recurrent
and transient states. The recurrent states are expected to be visited infinitely many times,
while the transient states are expected to be visited finitely many times. Variables p1 and
p2 represent the limiting distributions of each MDP, which is non-zero for all recurrent
states. The (possibly stochastic) policy i of agent i is defined in the recurrent states by
the probability of taking action a  Ai in state s  Si :
pi (s, a)
.
0
a0 Ai pi (s, a )

i (s, a) = P

243

fiPetrik & Zilberstein

a11

a12

b12

b11

b11

b12

a21

a22

a21

a22

a23

a24

a23

a24

r1

r2

r3

r4

r5

r1

r7

r8

Figure 3: A tree form of a policy for a DEC-POMDP or an extensive game. The dotted
ellipses denote the information sets.

The variables pi are 0 in transient states. The policy in the transient states is calculated
from variables qi as:
qi (s, a)
i (s, a) = P
.
0
a0 Ai qi (s, a )
The correctness of the constraints follows from the dual formulation of optimal average
reward (Puterman 2005, Equation 9.3.4). Petrik and Zilberstein (2007b) provide further
details of this formulation.
2.3 General DEC-POMDPs and Extensive Games
The general DEC-POMDP problem and extensive-form games with two agents, or players,
can also be formulated as bilinear programs. However, the constraints may not be separable
because actions of one agent influence the other agent. The approach in this case may be
similar to linear complementarity problem formulation of extensive games (Koller, Megiddo,
& von Stengel, 1994), and integer linear program formulation of DEC-POMDPs (Aras
& Charpillet, 2007). The approach we develop is closely related to event-driven DECPOMDPs (Becker et al., 2004), but it is in general more efficient. Nevertheless, the size of
the bilinear program is exponential in the size of the DEC-POMDP. This can be expected
since solving DEC-POMDPs is NEXP-complete (Bernstein et al., 2000), while solving
bilinear programs is NP-complete (Mangasarian, 1995). Because the general formulation in
this case is somewhat cumbersome, we only illustrate it using the following simple example.
Aras (2008) provides the details of a similar construction.
Example 6. Consider the problem depicted in Figure 3, assuming that the agents are
cooperative. The actions of the other agent are not observable, as denoted by the information
sets. This approach can be generalized to any problem with any observable sets as long as
the perfect recall condition is satisfied. Agents satisfy the perfect recall condition when
they remember the set of actions taken in the prior moves (Osborne & Rubinstein, 1994).
Rewards are only collected in the leaf-nodes in this case. The variables on the edges represent
the probability of taking the action. Here, variables a denote the actions of one agent, and
244

fiA Bilinear Programming Approach for Multiagent Planning

variables b of the other. The total common reward received in the end is:
r = a11 b11 a21 r1 + a11 b11 a22 r2 + a11 b12 a21 r3 + a11 b12 a22 r4 +
a12 b11 a23 r5 + a12 b11 a24 r6 + a12 b12 a23 r7 + a12 b12 a24 r8 .
The constraints in this problem are of the following form: a11 + a12 = 1.
Any DEC-POMDP problem can be represented using the approach used above. It is
also straightforward to extend the approach to problems with rewards in every node. However, the above formulation is clearly not bilinear. To apply our algorithm to this class
of problems, we need to reformulate the problem in a bilinear form. This can be easily
accomplished in a way similar to the construction of the dual linear program for an MDP.
Namely, we introduce variables:
c11 = a11
c12 = a12
c21 = a11 a21
c22 = a11 a22
and so on for every set of variables on any path to a leaf node. Then, the objective may be
reformulated as follows:
r = c21 b11 r1 + c22 b11 r2 + c23 b12 r3 + c24 b12 r4 +
c25 b11 r5 + c26 b11 r6 + c27 b12 r7 + c28 b12 r8 .
Variables bij are replaced in the same fashion. This objective function is clearly bilinear.
The constraints may be reformulated as follows. The constraint a21 + a22 = 1 can be
multiplied by a11 and then replaced by c21 + c22 = c11 , and so on. That is, the variables in
each level have to sum to the variable that is their least common parent in the level above
for the same agent.
2.4 General Two-Player Games
In addition to cooperative problems, some competitive problems with 2 players may be
formulated as bilinear programs. It is known that the problem of finding an equilibrium for
a bi-matrix game may be formulated as a linear complementarity problem (Cottle, Pang,
& Stone, 1992). It has also been shown that a linear complementarity problem may be
formulated as a bilinear problem (Mangasarian, 1995). However, a direct application of
these two reductions results in a complex problem with a large dimensionality. Below, we
demonstrate how a general game can be directly formulated as a bilinear program. There
are many ways to formulate a game, thus we take a very general approach. We simply
assume that each agent optimizes a linear program, as follows.
maximize
x

maximize

d1 (x) = r1T x + xT C1 y

subject to A1 x = b1

y

(8)

d2 (y) = r2T y + xT C2 y

subject to A2 y = b2
y0

x0
245

(9)

fiPetrik & Zilberstein

In Eq. (8), the variable y is considered to be a constant and similarly in Eq. (9) the
variable x is considered to be a constant. For normal form games, the constraint matrices
A1 and A2 are simply rows of ones, and b1 = b2 = 1. For competitive DEC-MDPs, the
constraint matrices A1 and A2 are the same as in Section 2.1. Extensive games may be
formulated similarly to DEC-POMDPs, as described in Section 2.3.
The game specified by linear programs Eq. (8) and Eq. (9) may be formulated as a
bilinear program as follows. First, define the reward vectors for each agent, given a policy
of the other agent.
q1 (y) = r1 + C1 y
q2 (x) = r2 + C2T x.

These values are unrelated to those of Eq. (7). The complementary slackness values (Vanderbei, 2001) for the linear programs Eq. (8) and Eq. (9) are:


k1 (x, y, 1 ) = q1 (y)T  T
1 A1 x


k2 (x, y, 2 ) = q2 (x)T  T
A
2 2 y,
where 1 and 2 are the dual variables of the corresponding linear programs. For any
primal feasible x and y, and dual feasible 1 and 2 , we have that k1 (x, y, 1 )  0 and
k2 (x, y, 2 )  0. The equality is attained if and only if x and y are optimal. This can
be used to write the following optimization problem, in which we implicitly assume that
x,y,1 ,2 are feasible in the appropriate primal and dual linear programs:
0
=
=
=
=

min k1 (x, y, 1 ) + k2 (x, y, 2 )

x,y,1 ,2

T
T
min (q1 (y)T  T
1 A1 )x + (q2 (x)  2 A2 )y

x,y,1 ,2

T T
T
min ((r1 + C1 y)T  T
1 A1 )x + ((r2 + C2 x)  2 A2 )y

x,y,1 ,2

T T
min r1T x + r2T y + xT (C1 + C2 )y  xT AT
1  1  y A2  2

x,y,1 ,2

T
min r1T x + r2T y + xT (C1 + C2 )y  bT
1 1  b2 2 .

x,y,1 ,2

Therefore, any feasible x and y that set the right hand side to 0 solve both linear programs
in Eq. (8) and Eq. (9) optimally. Adding the primal and dual feasibility conditions to the
above, we get the following bilinear program:
minimize
x,y,1 ,2

T
r1T x + r2T y + xT (C1 + C2 )y  bT
1 1  b2 2

subject to A1 x = b1

A2 y = b2

r1 + C1 y  AT
1 1  0
r2 + C2T x  AT
2 2  0
x0

y0
246

(10)

fiA Bilinear Programming Approach for Multiagent Planning

Algorithm 1: IterativeBestResponse(B)
x0 , w0  rand ;
i1;
while yi1 6= yi or xi1 6= xi do
(yi , zi )  arg maxy,z f (wi1 , xi1 , y, z) ;
(xi , wi )  arg maxx,w f (w, x, yi , zi ) ;
6
ii+1

1
2
3
4
5

7

return f (wi , xi , yi , zi )

The optimal solution of Eq. (10) is 0 and it corresponds to a Nash equilibrium. This
is because both the primal variables x, y and dual variables 1 , 2 are feasible and the
complementary slackness condition is satisfied. The open question in this example are the
interpretation of an approximate result and a formulation that would select the equilibrium.
It is not clear yet whether it is possible to formulate the program so that the optimal solution
will be a Nash equilibrium that maximizes a certain criterion. The approximate solutions
of the program probably correspond to -Nash equilibria, but this remain an open question.
The algorithm in this case also relies on the number of shared rewards being small
compared to the size of the problem. But even if this is not the case, it is often possible
that the number of shared rewards may be automatically reduced as described in Section 4.
In fact, it is easy to show that a zero-sum normal form game is automatically reduced to
two uncoupled linear programs. This follows from the dimensionality reduction procedure
in Section 4.

3. Solving Bilinear Programs
One simple method often used for solving bilinear programs is the iterative procedure shown
in Algorithm 1. The parameter B represents the bilinear program. While the algorithm
often performs well in practice, it tends to converge to a suboptimal solution (Mangasarian,
1995). When applied to DEC-MDPs, this algorithm is essentially identical to JESP (Nair,
Tambe, Yokoo, Pynadath, & Marsella, 2003)one of the early solution methods. In the
following, we use f (w, x, y, z) to denote the objective value of Eq. (1).
The rest of this section presents a new anytime algorithm for solving bilinear programs.
The goal of the algorithm to is to produce a good solution quickly and then improve the
solution in the remaining time. Along with each approximate solution, the maximal approximation bound with respect to the optimal solution is provided. As we show below, our
algorithm can benefit from results produced by suboptimal algorithms, such as Algorithm 1,
to quickly determine tight approximation bounds.
3.1 The Successive Approximation Algorithm
We begin with an overview of a successive approximation algorithm for bilinear problems
that takes advantage of a low number of interactions between the agents. It is particularly
suitable when the input problem is large in comparison to its dimensionality, as defined in
Section 2. We address the issue of dimensionality reduction in Section 4.
247

fiPetrik & Zilberstein

We begin with a simple intuitive explanation of the algorithm, and then show how it
can be formalized. The bilinear program can be seen as an optimization game played by
two agents, in which the first agent sets the variables w, x and the second one sets the
variables y, z. This is a general observation that applies to any bilinear program. In any
practical application, the feasible sets for the two sets of variables may be too large to
explore exhaustively. In fact, when this method is applied to DEC-MDPs, these sets are
infinite and continuous. The basic idea of the algorithm is to first identify the set of best
responses of one of the agents, say agent 1, to some policy of the other agent. This is
simple because once the variables of agent 2 are fixed, the program becomes linear, which
is relatively easy to solve. Once the set of best-response policies of agent 1 is identified,
assuming it is of a reasonable size, it is possible to calculate the best response of agent 2.
This general approach is also used by the coverage set algorithm (Becker et al., 2004).
One distinction is that the representation used in CSA applies only to DEC-MDPs, while
our formulation applies to bilinear programsa more general representation. The main
distinction between our algorithm and CSA is the way in which the variables y, z are chosen.
In CSA, the values y, z are calculated in a way that simply guarantees termination in
finite time. We, on the other hand, choose values y, z greedily so as to minimize the
approximation bound on the optimal solution. This is possible because we establish bounds
on the optimality of the solution throughout the calculation. As a result, our algorithm
converges more rapidly and may be terminated at any time with a guaranteed performance
bound. Unlike the earlier version of the algorithm (Petrik & Zilberstein, 2007a), the version
described in this paper calculates the best response using only a subset of the values of y, z.
As we show, it is possible to identify regions of y, z in which it is impossible to improve the
current best solution and exclude these regions from consideration.
We now formalize the ideas described above. To simplify the notation, we define feasible
sets as follows:
X = {(x, w) A1 x + B1 w = b1 }
Y

= {(y, z) A2 y + B2 z = b2 }.

We use y  Y to denote that there exists z such that (y, z)  Y . In addition, we assume that
the problem is in a semi-compact form. This is reasonable because any bilinear program
may be converted to semi-compact form with an increase in dimensionality of one, as we
have shown earlier.
Assumption 7. The sets X and Y are bounded, that is, they are contained in a ball of a
finite radius.
While Assumption 7 is limiting, coordination problems under uncertainty typically have
bounded feasible sets because the variables correspond to probabilities bounded to [0, 1].
Assumption 8. The bilinear program is in a semi-compact form.
The main idea of the algorithm is to compute a set X  X that contains only those
elements that satisfy a necessary optimality condition. The set X is formally defined as
follows:




 
X  (x , w ) (y, z)  Y f (w , x , y, z) = max f (w, x, y, z) .
(x,w)X

248

fiA Bilinear Programming Approach for Multiagent Planning

As described above, this set may be seen as a set of best responses of one agent to the
variable settings of the other. The best responses are easy to calculate since the bilinear
program in Eq. (1) reduces to a linear program for fixed w, x or fixed y, z. In our algorithm,
we assume that X is potentially a proper subset of all necessary optimality points and
focus on the approximation error of the optimal solution. Given the set X, the following
simplified problem is solved.
maximize
w,x,y,z

f (w, x, y, z)

subject to (x, w)  X

(11)

A2 y + B2 z = b2
y, z  0

Unlike the original continuous set X, the reduced set X is discrete and small. Thus the
elements of X may be enumerated. For a fixed w and x, the bilinear program in Eq. (11)
reduces to a linear program.
To help compute the approximation bound and to guide the selection of elements for
X, we use the best-response function g(y), defined as follows:
g(y) =

max

{w,x,z (x,w)X,(y,z)Y }

f (w, x, y, z) =

max

{x,w (x,w)X}

f (w, x, y, 0),

with the second equality for semi-compact programs only and feasible y  Y . Note that
g(y) is also defined for y 
/ Y , in which case the choice of z is arbitrary since it does
not influence the objective function. The best-response function is easy to calculate using
a linear program. The crucial property of the function g that we use to calculate the
approximation bound is its convexity. The following proposition holds because g(y) =
max{x,w (x,w)X} f (w, x, y, 0) is a maximum of a finite set of linear functions.
Proposition 9. The function g(y) is convex when the program is in a semi-compact form.
Proposition 9 relies heavily on the separability of Eq. (1), which means that the constraints on the variables on one side of the bilinear term are independent of the variables on
the other side. The separability ensures that w, x are valid solutions regardless of the values
of y, z. The semi-compactness of the program is necessary to establish convexity, as shown
in Example 23 in Appendix C. The example is constructed using the properties described
in the appendix, which show that f (w, x, y, z) may be expressed as a sum of a convex and
a concave function.
We are now ready to describe Algorithm 2, which computes the set X for a bilinear
problem B such that the approximation error is at most 0 . The algorithm iteratively adds
the best response (x, w) for a selected pivot point y into X. The pivot points are selected
hierarchically. At an iteration j, the algorithm keeps a set of polyhedra S1 . . . Sj which
represent the triangulation of the feasible space Y , which is possible based on Assumption 7.
For each polyhedron Si = (y1 . . . yn+1 ), the algorithm keeps a bound i on the maximal
difference between the optimal solution on the polyhedron and the best solution found so
far. This error bound on a polyhedron Si is defined as:
i = e(Si ) =

max

{w,x,y|(x,w)X,ySi }

f (w, x, y, 0) 

max
{w,x,y|(x,w)X,ySi }

249

f (w, x, y, 0),

fiPetrik & Zilberstein

Algorithm 2: BestResponseApprox(B, 0 ) returns (w, x, y, z)
1

2
3
4
5
6
7

8
9
10
11
12

13

14

// Create the initial polyhedron S1 .
S1  (y1 . . . yn+1 ), Y  S1 ;
// Add best-responses for vertices of S1 to X
X  {arg max(x,w)X f (w, x, y1 , 0), ..., arg max(x,w)X f (w, x, yn+1 , 0)} ;
// Calculate the error  and pivot point  of the initial polyhedron
(1 , 1 )  P olyhedronError(S1 ) ;
// Section 3.2,Section 3.3
// Initialize the number of polyhedra to 1
j1;
// Continue until reaching a predefined precision 0
while maxi=1,...,j i  0 do
// Find the polyhedron with the largest error
i  arg maxk=1,...,j k ;
// Select the pivot point of the polyhedron with the largest error
y  i ;
// Add the best response to the pivot point y to the set X
X  X  {arg max(x,w)X f (w, x, y, 0)} ;
// Calculate errors and pivot points of the refined polyhedra
for k = 1, . . . , n + 1 do
j j+1 ;
// Replace the k-th vertex by the pivot point y
Sj  (y, y1 . . . yk1 , yk+1 , . . . yn+1 ) ;
(j , j )  P olyhedronError(Sj ) ;
// Section 3.2,Section 3.3
// Take the smaller of the errors on the original and the refined
polyhedron. The error may not increase with the refinement,
although the bound may
j  min{i , j } ;
// Set the error of the refined polyhedron to 0, since the region is
covered by the refinements
i  0 ;

(w, x, y, z)  arg max{w,x,y,z
16 return (w, x, y, z) ;

15

(x,w)X,(y,z)Y }

f (w, x, y, 0) ;

where X represents the current, not final, set of best responses.
Next, a point y0 is selected as described below and n + 1 new polyhedra are created
by replacing one of the vertices by y0 to get: (y0 , y2 , . . .), (y1 , y0 , y3 , . . .), . . . , (y1 , . . . , yn , y0 ).
This is depicted for a 2-dimensional set Y in Figure 4. The old polyhedron is discarded
and the above procedure is then repeatedly applied to the polyhedron with the maximal
approximation error.
For the sake of clarity, the pseudo-code of Algorithm 2 is simplified and does not address
any efficiency issues. In practice, g(yi ) could be cached, and the errors i could be stored in
a prioritized heap or at least in a sorted array. In addition, a lower bound li and an upper
bound ui is calculated and stored for each polyhedron Si = (y1 . . . yn+1 ). The function e(Si )
calculates their maximal difference on the polyhedron Si and the point where it is attained.
The error bound i on the polyhedron Si may not be tight, as we describe in Remark 13.
As a result, when the polyhedron Si is refined to n polyhedra S10 . . . Sn0 with online error
250

fiA Bilinear Programming Approach for Multiagent Planning

y3

y0
y1

y2

Figure 4: Refinement of a polyhedron in two dimensions with a pivot y0 .
bounds 01 . . . 0n , it is possible that for some k: 0k > i . Since S10 . . . Sn0  Si , the true error
on Sk0 is less than on Si and therefore 0k may be set to i .
Conceptually, the algorithm is similar to CSA, but there are some important differences.
The main difference is in the choice of the pivot point y0 and the bounds on g. CSA does not
keep any upper bound and it evaluates g(y) on all the intersection points of planes defined
by the current solutions in X. That guarantees that g(y) is eventually known precisely
(Becker et al., 2004). A similar approach was also taken for POMDPs (Cheng, 1988). The
|X| 
upper bound on the number of intersection points in CSA is dim
Y . The principal problem
is that the bound is exponential in the dimension of Y , and experiments do not show a
slower growth in typical problems. In contrast, we choose the pivot points to minimize
the approximation error. This is more selective and tends to more rapidly reduce the error
bound. In addition, the error at the pivot point may be used to determine the overall
error bound. The following proposition states the soundness of the triangulation, proved
in Appendix A. The correctness of the triangulation establishes that in each iteration the
approximation error over Y is equivalent to the maximum of the approximation errors over
the current polyhedra S1 . . . Sj .
Proposition 10. In the proposed triangulation, the sub-polyhedra do not overlap and they
cover the whole feasible set Y , given that the pivot point is in the interior of S.

3.2 Online Error Bound
The selection of the pivot point plays a key role in the performance of the algorithm, in both
calculating the error bound and the speed of convergence to the optimal solution. In this
section we show exactly how we use the triangulation in the algorithm to calculate an error
bound. To compute the approximation bound, we define the approximate best-response
function g(y) as:
g(y) =
max
f (w, x, y, 0).
{x,w (x,w)X}

Notice that z is not considered in this expression, since we assume that the bilinear program is in the semi-compact form. The value of the best approximate solution during the
execution of the algorithm is:
max

f (w, x, y, 0) = max g(y).
yY

{w,x,y,z (x,w)X,yY }

251

fiPetrik & Zilberstein

This value can be calculated at runtime when each new element of X is added. Then the
maximal approximation error between the current solution and the optimal one may be
calculated from the approximation error of the best-response function g(), as stated by the
following proposition.
Proposition 11. Consider a bilinear program in a semi-compact form. Then let w, x, y
be an optimal solution of Eq. (11) and let w , x , y  be an optimal solution of Eq. (1). The
approximation error is then bounded by:
f (w , x , y  , 0)  f (w, x, y, 0)  max (g(y)  g(y)) .
yY

Proof.
f (w , x , y  , 0)  f (w, x, y, 0) = max g(y)  max g(y)  max g(y)  g(y)
yY

yY

yY

Now, the approximation error is maxyY g(y)  g(y), which is bounded by the difference
between an upper bound and a lower bound on g(y). Clearly, g(y) is a lower bound on
g(y). Given points in which g(y) is the same as the best-response function g(y), we can use
Jensens inequality to obtain the upper bound. This is summarized by the following lemma.
Lemma
12.Let yi  Y for i = 1, . . . , n + 1 such that g(yi ) = g(yi ). Then
P
Pn+1
Pn+1
n+1
g
i=1 ci yi 
i=1 ci g(yi ) when
i=1 ci = 1 and ci  0 for all i.
The actual implementation of the bound relies on the choice of the pivot points. Next
we describe the maximal error calculation on a single polyhedron defined by S = (y1 . . . yn ).
Let matrix T have yi as columns, and let L = {x1 . . . xn+1 } be the set of the best responses
for its vertices. The matrix T is used to convert any y in absolute coordinates to a relative
representation t that is a convex combination of the vertices. This is defined formally as
follows:


...
y = T t = y1 y2 . . . t
...
1 = 1T t
0  t
where the yi s are column vectors.
We can represent a lower bound l(y) for g(y) and an upper bound u(y) for g(y) as:
l(y) = max rT x + xT Cy
xL

u(y) = [g(y1 ), g(y2 ), . . .]T t = [g(y1 ), g(y2 ), . . .]T



T
1T

1  
y
,
1

The upper bound correctness follows from Lemma 12. Notice that u(y) is a linear function,
which enables us to use a linear program to determine the maximal-error point.
252

fiA Bilinear Programming Approach for Multiagent Planning

Algorithm 3: PolyhedronError(B, S)
P  one of Eq. (12), or (13), or (14), or (20) ;
t  the optimal solution of P ;
  the optimal objective value of P ;
// Coordinates t are relative to the vertices of S, convert them to absolute
values in Y
4   Tt ;
5 return (, ) ;

1
2
3

Remark 13. Notice that we use L instead of X in calculating l(y). Using all of X would
lead to a tighter bound, as it is easy to show in three-dimensional examples. However, this
also would substantially increase the computational complexity.
Now, the error on a polyhedron S may be expressed as:
e(S)  max u(y)  l(y) = max u(y)  max rT x + xT Cy
yS

yS

T

xL

T

= max min u(y)  r x  x Cy.
yS xL

We also have


y  S  y = T t  t  0  1T t = 1 .
As a result, the point with the maximal error bound may be determined using the following
linear program in terms of variables t, :
maximize
t,



subject to   u(T t)  rT x  xT CT t

x  L

(12)

1T t = 1 t  0
Here x is not a variable. The formulation is correct because all feasible solutions are
bounded below the maximal error and any maximal-error solution is feasible.
Proposition 14. The optimal solution of Eq. (12) is equivalent to maxyS |u(y)  l(y)|.
We thus select the next pivot point to greedily minimize the error. The maximal difference is actually achieved in points where some of the planes meet, as Becker et al. (2004)
have suggested. However, checking these intersections is very similar to running the simplex
algorithm. In general, the simplex algorithm is preferable to interior point methods for this
program because of its small size (Vanderbei, 2001).
Algorithm 3 shows a general way to calculate the maximal error and the pivot point on
the polyhedron S. This algorithm may use the basic formulation in Eq. (12), or the more
advanced formulations in Eqs. (13), (14), and (20) defined in Section 3.3.
In the following section, we describe a more refined pivot point selection method that
can in some cases dramatically improve the performance.
253

fiPetrik & Zilberstein

20

15

h10
5
6

Yh

4

2

0

2

4

Yh

6

Figure 5: The reduced set Yh that needs to be considered for pivot point selection.
3.3 Advanced Pivot Point Selection
As described above, the pivot points are chosen greedily to both determine the maximal
error in each polyhedron and to minimize the approximation error. The basic approach
described in Section 3.1 may be refined, because the goal is not to approximate the function
g(y) with the least error, but to find the optimal solution. Intuitively, we can ignore those
regions of Y that will not guarantee any improvement of the current solution, as illustrated
in Figure 5. As we show below, the search for the maximal error point could be limited to
this region as well.
We first define a set Yh  Y that we will search for the maximal error, given that the
optimal solution f   h.
Yh = {y g(y)  h, y  Y }.
The next proposition states that the maximal error needs to be calculated only in a superset
of Yh .
Proposition 15. Let w, x, y, z be the approximate optimal solution and w , x , y  , z  be the
optimal solution. Also let f (w , x , y  , z  )  h and assume some Yh  Yh . The approximation error is then bounded by:
f (w , x , y  , z  )  f (w, x, y, z)  max g(y)  g(y).
yYh

Proof. First, f (w , x , y  , z  ) = g(y  )  h and thus y   Yh . Then:
f (w , x , y  , z  )  f (w, x, y, z) = max g(y)  max g(y)
yYh

yY

 max g(y)  g(y)
yYh

 max g(y)  g(y)
yYh

Proposition 15 indicates that the point with the maximal error needs to be selected only
from the set Yh . The question is how to easily identify Yh . Because the set is not convex in
general, a tight approximation of this set needs to be found. In particular, we use methods
254

fiA Bilinear Programming Approach for Multiagent Planning

that approximate the intersection of a superset of Yh with the polyhedron that is being
refined, using the following methods:
1. Feasibility [Eq. (13)]: Require that pivot points are feasible in Y .
2. Linear bound [Eq. (14)]: Use the linear upper bound u(y)  h.
3. Cutting plane [Eq. (20)]: Use the linear inequalities that define YhC , where
YhC = R|Y | \ Yh is the complement of Yh .
Any combination of these methods is also possible.
Feasibility The first method is the simplest, but also the least constraining. The linear
program to find the pivot point with the maximal error bound is as follows:
maximize
,t,y,z



subject to   u(T t)  rT x + xT CT t

x  L

1T t = 1 t  0

(13)

y = Tt
A2 y + B2 z = b2
y, z  0

This approach does not require that the bilinear program is in the semi-compact form.
Linear Bound The second method, using the linear bound, is also very simple to implement and compute, and it is more selective than just requiring feasibility. Let:
Yh = {y u(y)  h}  {y g(y)  h} = Yh .
This set is convex and thus does not need to be approximated. The linear program used to
find the pivot point with the maximal error bound is as follows:
maximize
,t



subject to   u(T t)  rT x + xT CT t

x  L

1T t = 1 t  0

(14)

u(T t)  h
The difference from Eq. (12) is the last constraint. This approach requires that the bilinear
program is in the semi-compact form to ensure that u(y) is a bound on the total return.
Cutting Plane The third method, using the cutting plane elimination, is the most computationally intensive one, but also the most selective one. Using this approach requires
additional assumptions on the other parts of the algorithm, which we discuss below. The
method is based on the same principle as -extensions in concave cuts (Horst & Tuy, 1996).
We start with the set YhC because it is convex and may be expressed as:


T
T T
T
max sT
w
+
r
x
+
y
C
x
+
r
y
 h
(15)
1
1
2
w,x

255

A1 x + B1 w = b1

(16)

w, x  0

(17)

fiPetrik & Zilberstein

y3

f1
y1
y2
f2

Y  Yh

Figure 6: Approximating Yh using the cutting plane elimination method.
To use these inequalities in selecting the pivot point, we need to make them linear. But
there are two obstacles: Eq. (15) contains a bilinear term and is a maximization. Both
of these issues can be addressed by using the dual formulation of Eq. (15). The corresponding linear program and its dual for fixed y, ignoring constants h and r2T y, are:
maximize
w,x

T
T T
sT
1 w + r1 x + y C x

subject to A1 x + B1 w = b1

minimize
(18)



bT
1

subject to AT
1   r1 + Cy

w, x  0

(19)

B1T   s1

Using the dual formulation, Eq. (15) becomes:


T
T
min b1  + r2 y
 h


AT
1   r1 + Cy
B1T   s1
Now, we use that for any function  and any value  the following holds:
min (x)    (x) (x)  .
x

Finally, this leads to the following set of inequalities.
r2T y  h  bT
1
Cy  AT
1   r1
s1  B1T 
The above inequalities define the convex set YhC . Because its complement Yh is not
necessarily convex, we need to use its convex superset Yh on the given polyhedron. This
is done by projecting YhC , or its subset, onto the edges of each polyhedron as depicted in
Figure 6 and described in Algorithm 4. The algorithm returns a single constraint which
cuts off part of the set YhC . Notice that only the combination of the first n points fk is
256

fiA Bilinear Programming Approach for Multiagent Planning

Algorithm 4: PolyhedronCut({y1 , . . . , yn+1 }, h) returns constraint  T y  
1
2

3
4
5
6
7
8
9

// Find vertices of the polyhedron {y1 , . . . , yn+1 } inside of YhC
I  {yi yi  YhC } ;
// Find vertices of the polyhedron outside of YhC
O  {yi yi  Yh } ;
// Find at least n points fk in which the edge of Yh intersects an edge of
the polyhedron
k1;
for i  O do
for j  I do
fk  yj + max { (yi  yj )  (YhC )} ;
k k+1 ;
if k  n then
break ;

Find  and  , such that [f1 , . . . , fn ] =  and 1T  = 1 ;
// Determine the correct orientation of the constraint to have all y in Yh
feasible
11 if yj  O, and  T yj >  then
// Reverse the constraint if it points the wrong way
12
   ;
13
   ;
10

14

return  T y  

used. In general, there may be more than n points, and any subset of points fk of size n can
be used to define a new cutting plane that constraints Yh . This did not lead to significant
improvements in our experiments. The linear program to find the pivot point with the
cutting plane option is as follows:
maximize
,t,y



subject to   u(T t)  rT x + xT CT t
1T t = 1 t  0

x  L
(20)

y = Tt
Ty  
Here, , and  are obtained as a result of running Algorithm 4.
Note that this approach requires that the bilinear program is in the semi-compact form
to ensure that g(y) is convex. The following proposition states the correctness of this
procedure.
Proposition 16. The resulting polyhedron produced by Algorithm 4 is a superset of the
intersection of the polyhedron S with the complement of Yh .
Proof. The convexity of g(y) implies that YhC is also convex. Therefore, the intersection
Q = {y  T y   }  S
257

fiPetrik & Zilberstein

is also convex. It is also a convex hull of points fk  YhC . Therefore, from the convexity of
YhC , we have that Q  YhC , and therefore S  Q  Yh .

4. Dimensionality Reduction
Our experiments show that the efficiency of the algorithm depends heavily on the dimensionality of the matrix C in Eq. (1). In this section, we show the principles behind automatically
determining the necessary dimensionality of a given problem. Using the proposed procedure, it is possible to identify weak interactions and eliminate them. Finally, the procedure
works for arbitrary bilinear programs and is a generalization of a method we have previously
introduced (Petrik & Zilberstein, 2007a).
The dimensionality is inherently part of the model, not the problem itself. There may be
equivalent models of a given problem with very different dimensionality. Thus, procedures
for reducing the dimensionality are not necessary when the modeler can create a model
with minimal dimensionality. However, this is nontrivial in many cases. In addition, some
dimensions may have little impact on the overall performance. To determine which ones
can be discarded, we need a measure of their contribution that can be computed efficiently.
We define these notions more formally later in this section.
We assume that the feasible sets have bounded L2 norms, and assume a general formulation of the bilinear program, not necessarily in the semi-compact form. Given Assumption 7,
this can be achieved by scaling the constraints when the feasible region is bounded.
Assumption 17. For all x  X and y  Y , their norms satisfy kxk2  1 and kyk2  1.
We discuss the implications of and problems with this assumption after presenting Theorem 18. Intuitively, the dimensionality reduction removes those dimensions where g(y) is
constant, or almost constant. Interestingly, these dimensions may be recovered based on
the eigenvectors and eigenvalues of C T C. We use the eigenvectors of C T C instead of the
eigenvectors of C, because our analysis is based on L2 norm of x and y and thus of C.
The L2 norm kCk2 is bounded by the largest eigenvalue of C T C. In addition, a symmetric
matrix is required to ensure that the eigenvectors are perpendicular and span the whole
space.
Given a problem represented using Eq. (1), let F be a matrix whose columns are all the
eigenvectors of C T C with eigenvalues greater than some . Let G be a matrix with all the
remaining eigenvectors as columns. Notice that together, the columns of the matrices span
the whole space and are real-valued, since C T C is a symmetric matrix. Assume without
loss of generality that the eigenvectors are unitary. The compressed version of the bilinear
program is then the following:
maximize
w,x,y1 ,y2 ,z

T
T
f(w, x, y1 , y2 , z) = r1T x + sT
2 w + x CF y1 + r2 F

subject to A1 x + B1 w = b
 
 y1
A2 F G
+ B2 z = b2
y2
w, x, y1 , y2 , z  0
258

 
 y1
G
+ sT
2z
y2
(21)

fiA Bilinear Programming Approach for Multiagent Planning

Notice that the program is missing the element xT CGy2 , which would make its optimal
solutions identical to the optimal solutions of Eq. (1). We describe a more practical approach
to reducing the dimensionality in Appendix B. This approach is based on singular value
decomposition and may be directly applied to any bilinear program. The following theorem
quantifies the maximum error when using the compressed program.
Theorem 18. Let f  and f be optimal solutions of Eq. (1) and Eq. (21) respectively. Then:
p
 = |f   f |  .
Moreover, this is the maximal linear dimensionality reduction possible with this error without
considering the constraint structure.

Proof. We first show that indeed the error is at most  and that any linearly compressed
problem with the given error has at least f dimensions. Using a mapping that preserves
the feasibility of both programs, the error is bounded by:
fi 
  

 fi fi
fi
fi
fi fi T
 y1
y
fi = fix CGy2 fifi .
  fifif w, x, F G
, z  f w, x, y1 , 2
fi
y2
z
Denote the feasible region of y2 as Y2 . From the orthogonality of [F, G], we have that
ky2 k2  1 as follows:
 
 y1
y = F G
y2
 
 T
y1
F
y =
y2
GT
GT y = y2
kGT yk2 = ky2 k2
Then we have:
fi
fi
fi
fi
max max fixT CGy2 fi  max kCGy2 k2
y2 Y2 xX
y2 Y2
q
q
p

 max y2T GT C T CGy2  max y2T Ly2 

 

y2 Y2

y2 Y2

The result follows from Cauchy-Schwartz inequality, the fact that C T C is symmetric, and
Assumption 17. The matrix L denotes a diagonal matrix of eigenvalues corresponding to
eigenvectors of G.
Now, let H be an arbitrary matrix that satisfies the preceding error inequality for G.
Clearly, H  F = , otherwise y, kyk2 = 1, such that kCHyk2 > . Therefore, we have
|H|  n  |F |  |G|, because |H| + |F | = |Y |. Here |  | denotes the number of columns of
the matrix.
Alternatively, the bound can be proved by replacing the equality A1 x + B1 w = b1 by
kxk2 = 1. The bound can then be obtained by Lagrange necessary optimality conditions. In
these bounds we use L2 -norm; an extension to a different norm is not straightforward. Note
259

fiPetrik & Zilberstein

Y

y

kyk2  1

Figure 7: Approximation of the feasible set Y according to Assumption 17.
also that this dimensionality reduction technique ignores the constraint structure. When
the constraints have some special structure, it might be possible to obtain an even tighter
bound. As described in the next section, the dimensionality reduction technique generalizes
the reduction that Becker et al. (2004) used implicitly.
The result of Theorem 18 is based on an approximation of the feasible set Y by kyk2  1,
as Assumption 17 states. This approximation may be quite loose in some problems, which
may lead to a significant multiplicative overestimation of the bound in Theorem 18. For
example, consider the feasible set depicted in Figure 7. The bound may be achieved in a
point y, which is far from the feasible region. In specific problems, a tighter bound could be
obtained by either appropriately scaling the constraints, or using a weighted L2 with a better
precision. We partially address this issue by considering the structure of the constraints.
To derive this, consider the following linear program and corresponding theorem:
maximize
x

cT x

subject to Ax = b

(22)

x0

Theorem 19. The optimal solution of Eq. (22) is the same as when the objective function
is modified to
cT (I  AT (AAT )1 A)x,
where I is the identity matrix.
Proof. The objective function is:
max

{x Ax=b, x0}

cT x =
=

max

{x Ax=b, x0}

cT (I  AT (AAT )1 A)x + cT AT (AAT )1 Ax

= cT AT (AAT )1 b +

max

{x Ax=b, x0}

cT (I  AT (AAT )1 A)x.

The first term may be ignored because it does not depend on the solution x.
260

fiA Bilinear Programming Approach for Multiagent Planning

The following corollary shows how the above theorem can be used to strengthen the
dimensionality reduction bound. For example, in zero-sum games, this stronger dimensionality reduction splits the bilinear program into two linear programs.
Corollary 20. Assume that there are no variables w and z in Eq. (1). Let:
T 1
Qi = (I  AT
i (Ai Ai ) Ai )),

i  {1, 2},

where Ai are defined in Eq. (1). Let C be:
C = Q1 CQ2 ,
where C is the bilinear-term matrix from Eq. (1). Then the bilinear programs will have
identical optimal solutions with either C or C.
Proof. Using Theorem 19, we can modify the original objective function in Eq. (1) to:
T 1
T
T 1
T
f (x, y) = r1T x + xT (I  AT
1 (A1 A1 ) A1 ))C(I  A2 (A2 A2 ) A2 ))y + r2 y.

For the sake of simplicity we ignore the variables w and z, which do not influence the bilinear
T 1
term. Because both (I  AT
i (Ai Ai ) Ai ) for i = 1, 2 are orthogonal projection matrices,
none of the eigenvalues in Theorem 18 will increase.
The dimensionality reduction presented in this section is related to the idea of compound events used in CSA. Allen, Petrik, and Zilberstein (2008a, 2008b) provide a detailed
discussion of this issue.

5. Offline Bound
In this section we develop an approximation bound that depends only on the number of
points for which g(y) is evaluated and the structure of the problem. This kind of bound
is useful in practice because it provides performance guarantees without actually solving
the problem. In addition, the bound reveals which parameters of the problem influence the
algorithms performance. The bound is derived based on the maximal slope of g(y) and the
maximal distance among the points.
Theorem 21. To achieve an approximation error of at most , the number of points to be
evaluated in a regular grid with k points in every dimension must satisfy:

 n
kCk2 n
n
k 
,

where n is the number of dimensions of Y .
The theorem follows using basic algebraic manipulations from the following lemma.
Lemma 22. Assume that for each y1  Y there exists y2  Y such that ky1  y2 k2   and
g(y2 ) = g(y2 ). Then the maximal approximation error is:
 = max g(y)  g(y)  kCk2 .
yY

261

fiPetrik & Zilberstein

Proof. Let y1 be a point where the maximal error is attained. This point is in Y , because
this set is compact. Now, let y2 be the closest point to y1 in L2 norm. Let x1 and x2 be
the best responses for y1 and y2 respectively. From the definition of solution optimality we
can derive:
T
T
T
r1T x1 + r2T y2 + xT
1 Cy2  r1 x2 + r2 y2 + x2 Cy2

r1T (x1  x2 )  (x1  x2 )T Cy2 .
The error now can be expressed, using the fact that kx1  x2 k2  1, as:
T
T
T
 = r1T x1 + r2T y1 + xT
1 Cy1  r1 x2  r2 y1  x2 Cy1

= r1T (x1  x2 ) + (x1  x2 )T Cy1
 (x1  x2 )T Cy2 + (x1  x2 )T Cy1
 (x1  x2 )T C(y1  y2 )
(x1  x2 )T
(y1  y2 )
 ky1  y2 k2
C
k(x1  x2 )k2 ky1  y2 k2
 ky1  y2 k2

max

max

{x kxk2 1} {y kyk2 1}

xT Cy

 kCk2
The above derivation follows from Assumption 17, and the bound reduces to the matrix
norm using Cauchy-Schwartz inequality.
Not surprisingly, the bound is independent of the local rewards and transition structure
of the agents. Thus it in fact shows that the complexity of achieving a fixed approximation
with a fixed interaction structure is linear in the problem size. However, the bounds are
still exponential in the dimensionality of the space. Notice also that the bound is additive.

6. Experimental Results
We now turn to an empirical analysis of the performance of the algorithm. For this purpose
we use the Mars rover problem described earlier. We compared our algorithm with the
original CSA and with a mixed integer linear program (MILP), derived for Eq. (1) as Petrik
and Zilberstein (2007b) describe. Although Eq. (1) can also be modeled as a linear complementarity problem (LCP) (Murty, 1988; Cottle et al., 1992), we do not evaluate that
option experimentally because LCPs are closely related to MILPs (Rosen, 1986). We expect
these two formulations to exhibit similar performance. We also do not compare to any of
the methods described by Horst and Tuy (1996) and Bennett and Mangasarian (1992) due
to their very different nature and high complexity, and because some of these algorithms
do not provide any optimality guarantees.
In our experiments, we applied the algorithm to randomly generated problem instances
with the same parameters that Becker et al. (2003, 2004) used. Each problem instance
includes 2 rovers and 6 sites. At each site, the rovers can decide to perform an experiment
or to skip the site. Performing experiments takes some time, and all the experiments must
be performed in 15 time units. The time required to perform an experiment is drawn from
a discrete normal distribution with the mean uniformly chosen from 4.0-6.0. The variance
262

fiA Bilinear Programming Approach for Multiagent Planning

Algorithm 5: MPBP: Multiagent Planning with Bilinear Programming

6

Formulate DEC-MDP M as a bilinear program B ;
// [Section 2.1]
B 0  ReduceDimensionality(B) with   104 ;
// [Section 4, Appendix B]
Convert B 0 to a semi-compact form ;
// [Definition 2]
h   ;
// Presolve step: run Algorithm 1  times with random initialization
for i  {1 . . . } do
h  max{h, IterativeBestResponse(B 0 )} ;
// [Algorithm 1]

7

BestResponseApprox(B 0 , 0 ) ;

1
2
3
4

5

// [Algorithm 2]

is 0.4 of the mean. The local reward for performing an experiment is selected uniformly
from the interval [0.1,1.0] for each site and it is identical for both rovers. The global reward,
received when both rovers perform an experiment on a shared site, is super-additive and is
1/2 of the local reward. The experiments were performed with sites {1, 2, 3, 4, 5} as shared
sites. Typically, the performance of the algorithm degrades with the number of shared sites.
Because the problem with fewer than 5 shared sitesas used in the original CSA paperwere
too easy to solve, we only present results for problems with 5 shared sites. Note that CSA
was used on this problem with an implicit dimensionality reduction due to the use of the
compound events.
In these experiments, the naive dimensionality of Y in Eq. (5) is 6  15  2 = 180.
This dimensionality can be reduced to be one per each shared site using the automatic
dimensionality reduction procedure. Each dimension then represents the probability that
an experiment on a shared site is performed regardless of the time. Therefore, the dimension
represents the sum of the individual probabilities. Becker et al. (2004) achieved the same
compression using compound events, where each compound event represents the fact that
an experiment is performed on some site regardless of the specific time.
The complete algorithmMultiagent Planning with Bilinear Programming (MPBP)is
summarized in Algorithm 5. The automatic dimensionality reduction reduces Y to 5 dimensions. Then, reformulating the problem to a semi-compact form increases the dimensionality
to 6. We experimented with different configurations of the algorithm that differ in the way
the refinements of the pivot point selection is performed. The different methods, described
in Section 3.3, were used to create six configurations as shown in Figure 8. The configuration
C1 corresponds to an earlier version of the algorithm (Petrik & Zilberstein, 2007a).
We executed the algorithm 20 times with each configuration on every problem, randomly
generated according to the distribution described above. The results represent the average
over the random instances. The maximum number of iterations of the algorithm was 200.
Due to rounding errors, we considered any error less than 104 to be 0. The algorithm
is implemented in MATLAB release 2007a. The linear solver we used is MOSEK version
5.0. The hardware configuration was Intel Core 2 Duo 1.6 GHz Low Voltage with 2GB
RAM. The time to perform the dimensionality reduction is negligible and not included in
the result.
A direct comparison with CSA was not possible because CSA cannot solve problems
with this dimensionality within a reasonable amount of time. However, in a very similar
263

fiPetrik & Zilberstein

Configuration

Feasible
[Eq. (13)]

C1

Linear bound
[Eq. (14)]

Cutting plane
[Eq. (20)]

0



C2



C3

0





C4

0





C6

0





C5

Presolve []

10



10

Figure 8: The six algorithm configurations that were evaluated. Feasible, linear bound, and
cutting plane refer to methods used to determine the optimal solution.

problem setup with at most 4 shared sites, CSA solved only 76% of the problems, and
the longest solution took approximately 4 hours (Becker et al., 2004). In contrast, MPBP
solved all 200 problems with 4 shared sites optimally in less than 1 second on average, about
10000 times faster. In addition, MPBP returns solutions that are guaranteed to be close to
optimal in the first few iterations. While CSA also returns solutions close to optimal very
rapidly, it takes a very long time to confirm that.
Figure 9 shows the average guaranteed ratio of the optimal solution, achieved as a
function of the number of iterations, that is, points for which g(y) is evaluated. This figure,
as all others, shows the result of the online error bound. This value is guaranteed and is not
based on the optimal solution. This compares the performance of the various configurations
of the algorithm, without using the presolve step. While the optimal solution was typically
discovered in the first few iterations, it takes significantly longer to prove its optimality.
The average of absolute errors in both linear and log scale are shown in Figure 10. These
results indicate that the methods proposed to eliminate the dominated region in searching
for the pivot point can dramatically improve performance. While requiring that the new
pivot points are feasible in Y improves the performance, it is much more significant with
1

Fraction Optimal

C1
0.95

C2

0.9

C3
C4

0.85
0.8
0.75
0.7
0.65
0.6
0

50

100
Iteration

150

200

Figure 9: Guaranteed fraction of optimality according to the online bound.
264

fiA Bilinear Programming Approach for Multiagent Planning

1

5

10

C1

C1

C2

4

C

2

0

10

C

C3

C4
3

2

Absolute Error

Absolute Error

3

4

2

10

3

1

0
0

C
1

10

10

4

50

100
Iteration

150

10

200

0

50

100
Iteration

150

200

Figure 10: Comparison of absolute error of various region elimination methods.

a better approximation of Yh . As expected, the cutting plane elimination is most efficient,
but also most complex.
To evaluate the tradeoffs in the implementation, we also show the average time per
iteration and the average total time in Figure 11. These figures show that the time per
iteration is significantly larger when the cutting plane elimination is used. Overall, the
algorithm is faster when the simpler linear bound is used.

0.03

12

0.025

10

0.02

8

Total Seconds

Seconds per Iteration

This trend is most likely problem specific. In problems with higher dimensionality, the
more precise cutting plane algorithm may be more efficient. Implementation issues play a
significant role in this problem too, and it is likely that the implementation of Algorithm 4
can be further improved.

0.015
0.01

4
2

0.005
0

6

C1

C2

C3

0

C4

C1

C2

C3

C4

Figure 11: Time per iteration and the total time to solve. With configurations C1 and C2 ,
the optimal value is not reached with 200 iterations . The figure only shows the
time to compute up to 200 iterations.

265

fiPetrik & Zilberstein

1

10

C3
C

4

C5
Absolute Error

2

C6

10

3

10

4

10

0

10

20
Iteration

30

40

Figure 12: Influence of the presolve method.
Figure 12 shows the influence of using the presolve method. The plots of C3 and C4 are
identical to the plots of C5 and C6 respectively, indicating that the presolve method does
not have any significant influence. This also indicates that a solution that is very close to
optimal is obtained when the values of the initial points are calculated.
We also performed experiments with CPLEXa state-of-the-art MILP solver on the direct MILP formulation of the DEC-MDP. CPLEX was not able to solve any of the problems
within 30 minutes, no matter how many of the sites were shared. The main reason for this
is that it does not take any advantage of the limited interaction. Nevertheless, it is possible
that some specialized MILP solvers may perform better.

7. Conclusion and Further Work
We present an algorithm that significantly improves the state-of-the-art in solving two-agent
coordination problems. The algorithm takes as input a bilinear program representing the
problem, and solves the problem using a new successive approximation method. It provides
a useful online performance bound that can be used to decide when the approximation is
good enough. The algorithm can take advantage of the limited interaction among the agents,
which is translated into a small dimensionality of the bilinear program. Moreover, using
our approach, it is possible to reduce the dimensionality of such problems automatically,
without extensive modeling effort. This makes it easy to apply our new method in practice.
When applied to DEC-MDPs, the algorithm is much faster than the existing CSA method,
on average reducing computation time by four orders of magnitude. We also show that a
variety of other coordination problems can be treated within this framework.
Besides multiagent coordination problems, bilinear programs have been previously used
to solve problems in operations research and global optimization (Sherali & Shetty, 1980;
White, 1992; Gabriel, Garca-Bertrand, Sahakij, & Conejo, 2005). Global optimization
deals with finding the optimal solutions to problems with multi-extremal objective function.
Solution techniques often share the same idea and are based on cutting plane methods. The
main idea is to iteratively restrict the set of feasible solutions, while improving the incumbent
266

fiA Bilinear Programming Approach for Multiagent Planning

solution. Horst and Tuy (1996) provide an excellent overview of these techniques. These
algorithms have different characteristics and cannot be directly compared to the algorithm
we developed. Unlike these traditional algorithms, we focus on providing quickly good
approximate solutions with error bounds. In addition, we exploit the small dimensionality
of the best-response space Y to get tight approximation bounds.
Future work will address several interesting open questions with respect to the bilinear
formulation as well as further improvement of the efficiency of the algorithm. With regard to
the representation, it is yet to be determined whether the anytime behavior can be exploited
when applied to games. That is, it is necessary to verify that an approximate solution to
the bilinear program is also a meaningful approximation of the Nash equilibrium. It is also
important to identify the classes of extensive games that can be efficiently formulated as
bilinear programs.
The algorithm we present can be made more efficient in several ways. In particular, a
significant speedup could be achieved by reducing the size of the individual linear programs.
The programs are solved many times with the same constraints, but a different objective
function. The objective function is always from a small-dimensional space. Therefore, the
problems that are solved are all very similar. In the DEC-MDP domain, one option would
be to use a procedure similar to action elimination. In addition, the performance could be
significantly improved by starting with a tight initial triangulation. In our implementation,
we simply use a single large polyhedron that covers the whole feasible region. A better
approach would be to start with something that approximates the feasible region more
tightly. A tighter approximation of the feasible region could also improve the precision of
the dimensionality reduction procedure. Instead of the naive ellipsis used in Assumption 7,
it is possible to use one that approximates the feasible region as tightly as possible. It is
however very encouraging to see that even without these improvements, the algorithm is
very effective compared with existing solution techniques.

Acknowledgments
We thank Chris Amato, Raghav Aras, Alan Carlin, Hala Mostafa, and the anonymous
reviewers for useful comments and suggestions. This work was supported in part by the
Air Force Office of Scientific Research under Grants No. FA9550-05-1-0254 and FA955008-1-0181, and by the National Science Foundation under Grants No. IIS-0535061 and
IIS-0812149.

Appendix A. Proofs
Proof of Proposition 10 The proposition states that in the proposed triangulation, the
sub-polyhedra do not overlap and they cover the whole feasible set Y , given that the pivot
point is in the interior of S.
Proof. We prove the theorem by induction on the number of polyhedron splits that were
performed. The base case is trivial: there is only a single polyhedron, which covers the
whole feasible region.
For the inductive case, we show that for any polyhedron S the sub-polyhedra induced
by the pivot point y cover S and do not overlap. The notation we use is the following: T
267

fiPetrik & Zilberstein

denotes the original polyhedron and y = T c is the pivot point, where 1T c = 1 and c  0.
Note that T is a matrix and c, d, y are vectors, and  is a scalar.
We show that the sub-polyhedra cover the original polyhedron S as follows. Take any
a = T d such that 1T d = 1 and d  0. We show that there exists a sub-polyhedron that
contains a and has y as a vertex. First, let
 
T
T =
1T
This matrix is square and invertible, since the polyhedron is non-empty. To get a representation of a that contains y, we show that there is a vector o such that for some i,
o(i) = 0:
 

a
= T d = T o +  y
1
o  0,
for some  > 0. This will ensure that a is in the sub-polyhedron with y with vertex i
replaced by y. The value o depends on  as follows:
 
1 y
.
o = d   T
1
This can be achieved by setting:
 = min
i

d(i)
(T 1 y)(i)

.

Since both d and c = T 1 y are non-negative. This leaves us with an equation for the
sub-polyhedron containing the point a. Notice that the resulting polyhedron may be of a
smaller dimension than n when o(j) = 0 for some i 6= j.
To show that the polyhedra do not overlap, assume there exists a point a that is common to the interior of at least two of the polyhedra. That is, assume that a is a convex
combination of the vertices:
a = T3 c1 + h1 y + 1 y1
a = T3 c2 + h2 y + 2 y2 ,
where T3 represents the set of points common to the two polyhedra, and y1 and y2 represent
the disjoint points in the two polyhedra. The values h1 , h2 , 1 , and 2 are all scalars, while
c1 and c2 are vectors. Notice that the sub-polyhedra differ by at most one vertex. The
coefficients satisfy:
c1  0

c2  0

h1  0

h2  0

1  0

2  0

T

T

1 c1 + h1 + 1 = 1

1 c2 + h2 + 2 = 1
268

fiA Bilinear Programming Approach for Multiagent Planning

Since the interior of the polyhedron is non-empty, this convex combination is unique.
First assume that h = h1 = h2 . Then we can show the following:
a = T3 c1 + hy + 1 y1 = T3 c2 + hy + 2 y2
T3 c1 + 1 y1 = T3 c2 + 2 y2
1 y1 = 2 y2
1 = 2 = 0
This holds since y1 and y2 are independent of T3 when the polyhedron is nonempty and
y1 6= y2 . The last equality follows from the fact that y1 and y2 are linearly independent.
This is a contradiction, since 1 = 2 = 0 implies that the point a is not in the interior of
two polyhedra, but at their intersection.
Finally, assume WLOG that h1 > h2 . Now let y = T3 c + 1 y1 + 2 y2 , for some scalars
1  0 and 2  0 that represent a convex combination. We get:
a = T3 c1 + h1 y + 1 y1 = T3 (c1 + h1 c) + (h1 1 + 1 )y1 + h1 2 y2
a = T3 c2 + h2 y + 2 y2 = T3 (c2 + h2 c) + h2 1 y1 + (h2 2 + 2 )y2 .
The coefficients sum to one as shown below.
1T (c1 + h1 c) + (h1 1 + 1 ) + h1 2 = 1T c1 + 1 + h1 (1T c + 1 + 2 ) = 1T c1 + 1 + h1 = 1
1T (c2 + h2 c) + 1 + (h2 2 + 2 ) = 1T c2 + 2 + h2 (1T c + 1 + 2 ) = 1T c2 + 2 + h2 = 1
Now, the convex combination is unique, and therefore the coefficients associated with each
vertex for the two representations of a must be identical. In particular, equating the coefficients for y1 and y2 results in the following:
h1 1 + 1 = h2 1

h1 2 = h2 2 + 2

1 = h2 1  h1 1

2 = h1 2  h2 2

1 = 1 (h2  h1 ) > 0

2 = 2 (h1  h2 ) < 0

We have that 1 > 0 and 2 > 0 from the fact that y is in the interior of the polyhedron S.
Then, having 2  0 is a contradiction with a being a convex combination of the vertices
of S.

Appendix B. Practical Dimensionality Reduction
In this section we describe an approach to dimensionality reduction that is easy to implement. Note that there are at least two possible approaches to take advantage of reduced
dimensionality. First, it is possible to use the dimensionality information to limit the algorithm to work only in the significant dimensions of Y . Second, it is possible to modify the
bilinear program to have a small dimensionality. While changing the algorithm may be more
straightforward, it limits the use of the advanced pivot point selection methods described
in Section 3.3. Here, we show how to implement the second option in a straightforward way
using singular value decomposition.
269

fiPetrik & Zilberstein

The dimensionality reduction is applied to the following bilinear program:
maximize
w,x,y,z

T
T
T
r1T x + sT
1 w + x Cy + r2 y + s2 z

subject to A1 x + B1 w = b1
A2 y + B2 z = b2

(23)

w, x, y, z  0
Let C = SV T T be a singular value decomposition. Let T = [T1 , T2 ], such that the
singular value of vectors ti in T2 is less than the required . Then, a bilinear program with
reduced dimensionality may be defined as follows:
maximize
w,x,y,y,z

T
T
T
r1T x + sT
1 w + x SV T1 y + r2 y + s2 z

subject to T1 y = y
A1 x + B1 w = b1

(24)

A2 y + B2 z = b2
w, x, y, z  0
Note that y is not constrained to be non-negative. One problematic aspect of reducing the
dimensionality is how to define the initial polyhedron that needs to encompass all feasible
solutions. One option is to make it large enough to contain the set {y kyk2 = 1}, but this
may be too large. Often in practice, it may be more efficient to first triangulate a rough
approximation of the feasible region, and then execute the algorithm on this triangulation.

Appendix C. Sum of Convex and Concave Functions
In this section we show that the best-response function g(y) may not be convex when the
program is not in a semi-compact form. The convexity of the best-response function is
crucial in bounding the approximation error and in eliminating the dominated regions.
We show that when the program is not in a semi-compact form, the best-response
function can we written as a sum of a convex function and a concave function. To show
that consider the following bilinear program.
maximize
w,x,y,z

T
T
T
f = r1T x + sT
1 w + x Cy + r2 y + s2 z

subject to A1 x + B1 w = b1
A2 y + B2 z = b2
w, x, y, z  0
This problem may be reformulated as:
f

=
=

max

max

max

g 0 (y) + sT
2 z,

{y,z (y,z)Y } {x,w (x,w)X}
{y,z (y,z)Y }

T
T
T
r1T x + sT
1 w + x Cy + r2 y + s2 z

270

(25)

fiA Bilinear Programming Approach for Multiagent Planning

where
g 0 (y) =

max

{x,w (x,w)X}

T
T
r1T x + sT
1 w + x Cy + r2 y.

Notice that function g 0 (y) is convex, because it is a maximum of a set of linear functions.
Since f = max{y (y,z)Y } g(y), the best-response function g(y) can be expressed as:
g(y) =

max

{z (y,z)Y }
0

0
g 0 (y) + sT
2 z = g (y) +

max

{z (y,z)Y }

sT
2z

= g (y) + t(y),
where
t(y) =

max

{z A2 y+B2 z=b2 , y,z0}

sT
2 z.

Function g 0 (y) does not depend on z, and therefore could be taken out of the maximization.
The function t(y) corresponds to a linear program, and its dual using the variable q is:
(b2  A2 y)T q

minimize
q

subject to B2T q  s2

(26)

Therefore:
t(y) =

(b2  A2 y)T q,

min

{q B2T qs2 }

which is a concave function, because it is a minimum of a set of linear functions. The
best-response function can now be written as:
g(y) = g 0 (y) + t(y),
which is a sum of a convex function and a concave function, also known as a d.c. function (Horst & Tuy, 1996). Using this property, it is easy to construct a program such that
g(y) will be convex on one part of Y and concave on another part of Y , as the following
example shows. Note that in semi-compact bilinear programs t(y) = 0, which guarantees
the convexity of g(y).
Example 23. Consider the following bilinear program:
maximize
x,y,z

x + xy  2z

subject to 1  x  1
yz 2
z0
A plot of the best response function for this program is shown in Figure 13.

271

(27)

fiPetrik & Zilberstein

2

maxx f(x,y)

1.5
1
0.5
0
0.5
1
1

0

1

2

3

4

y

Figure 13: A plot of a non-convex best-response function g for a bilinear program, which is
not in a semi-compact form.

References
Allen, M., Petrik, M., & Zilberstein, S. (2008a). Interaction structure and dimensionality in
decentralized problem solving. In Conference on Artificial Intelligence (AAAI), pp.
14401441.
Allen, M., Petrik, M., & Zilberstein, S. (2008b). Interaction structure and dimensionality
in decentralized problem solving. Tech. rep. 08-11, Computer Science Department,
University of Massachussetts.
Aras, R. (2008). Mathematical programming methods for decentralized POMDPs. Ph.D.
thesis, Universite Henri Poincare, Nancy, France.
Aras, R., & Charpillet, F. (2007). A mixed integer linear programming method for the finitehorizon Dec-POMDP problem. In International Conference on Automated Planning
and Scheduling (ICAPS), pp. 1825.
Becker, R. (2006). Exploiting Structure in Decentralized Markov Decision Processes. Ph.D.
thesis, University of Massachusetts Amherst.
Becker, R., Lesser, V., & Zilberstein, S. (2004). Decentralized Markov decision processes
with event-driven interactions. In International Joint Conference on Autonomous
Agents and Multi Agent Systems (AAMAS), pp. 302309.
Becker, R., Zilberstein, S., & Lesser, V. (2003). Transition-independent decentralized
Markov decision processes. In International Joint Conference on Autonomous Agents
and Multi Agent Systems (AAMAS), pp. 4148.
Becker, R., Zilberstein, S., Lesser, V., & Goldman, C. V. (2004). Solving transition independent decentralized Markov decision processes. Journal of Artificial Intelligence
Research, 22, 423455.
Bennett, K. P., & Mangasarian, O. L. (1992). Bilinear separation of two sets in n-space.
Tech. rep., Computer Science Department, University of Wisconsin.
Bernstein, D. S., Zilberstein, S., & Immerman, N. (2000). The complexity of decentralized control of Markov decision processes. In Conference on Uncertainty in Artificial
Intelligence (UAI), pp. 3237.
272

fiA Bilinear Programming Approach for Multiagent Planning

Bertsekas, D. P., & Tsitsiklis, J. N. (1996). Neuro-dynamic programming. Athena Scientific.
Boutilier, C. (1999). Sequential optimality and coordination in multiagent systems. In
International Joint Conference on Artificial Intelligence, pp. 478485.
Bresina, J. L., Golden, K., Smith, D. E., & Washington, R. (1999). Increased fexibility
and robustness of Mars rovers. In International Symposium on AI, Robotics, and
Automation in Space, pp. 167173.
Cheng, H. T. (1988). Algorithms for Partially Observable Markov Decision Processes. Ph.D.
thesis, University of British Columbia.
Cottle, R. W., Pang, J.-S., & Stone, R. E. (1992). The Linear Complementarity Problem.
Academic Press.
Emery-Montemerlo, R., Gordon, G., Schneider, J., & Thrun, S. (2004). Approximate solutions for partially observable stochastic games with common payoffs. In International
Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS), pp. 136
143.
Gabriel, S. A., Garca-Bertrand, R., Sahakij, P., & Conejo, A. J. (2005). A practical approach
to approximate bilinear functions in mathematical programming problems by using
Schurs decomposition and SOS type 2 variables. Journal of the Operational Research
Society, 57, 9951004.
Goldman, C. V., & Zilberstein, S. (2008). Communication-based decomposition mechanisms
for decentralized MDPs. Journal of Artificial Intelligence Research, 32, 169202.
Horst, R., & Tuy, H. (1996). Global optimization: Deterministic approaches. Springer.
Kim, Y., Nair, R., Varakantham, P., Tambe, M., & Yokoo, M. (2006). Exploiting locality
of interaction in networked distributed POMDPs. In AAAI Spring Symposium on
Distributed Planning and Scheduling, pp. 4148.
Koller, D., Megiddo, N., & von Stengel, B. (1994). Fast algorithms for finding randomized
strategies in game trees. In ACM Symposium on the Theory of Computing, pp. 750
759.
Mangasarian, O. L. (1995). The linear complementarity problem as a separable bilinear
program. Journal of Global Optimization, 12, 17.
Murty, K. G. (1988).
Helderman-Verlag.

Linear complementarity, linear and nonlinear programming.

Nair, R., Tambe, M., Yokoo, M., Pynadath, D., & Marsella, S. (2003). Taming decentralized POMDPs: Towards efficient policy computation for multiagent settings.. In
International Joint Conference on Artificial Inteligence, pp. 705711.
Nair, R., Roth, M., Yokoo, M., & Tambe, M. (2004). Communication for improving policy
computation in distributed pomdps. In International Joint Conference on Agents and
Multiagent Systems (AAMAS), pp. 10981105.
Ooi, J. M., & Wornell, G. W. (1996). Decentralized control of a multiple access broadcast
channel: performance bounds. In Proceeding of the IEEE Conference on Decision and
Control, Vol. 1, pp. 293298.
273

fiPetrik & Zilberstein

Osborne, M. J., & Rubinstein, A. (1994). A course in game theory. The MIT Press.
Pang, J.-S., Trinkle, J. C., & Lo, G. (1996). A complementarity approach to a quasistatic
rigid body motion problem. Journal of Computational Optimization and Applications,
5 (2), 139154.
Petrik, M., & Zilberstein, S. (2007a). Anytime coordination using separable bilinear programs. In Conference on Artificial Intelligence, pp. 750755.
Petrik, M., & Zilberstein, S. (2007b). Average reward decentralized Markov decision processes. In International Joint Conference on Artificial Intelligence, pp. 19972002.
Puterman, M. L. (2005). Markov decision processes: Discrete stochastic dynamic programming. John Wiley & Sons, Inc.
Rosberg, Z. (1983). Optimal decentralized control in a multiaccess channel with partial
information. IEEE Transactions on Automatic Control, 28, 187193.
Rosen, J. B. (1986). Solution of general LCP by 0-1 mixed integer programming. Tech. rep.
Computer Science Tech. Report 8623, University of Minnesota, Minneapolis.
Rubinstein, A. (1997). Modeling bounded rationality. MIT Press.
Seuken, S., & Zilberstein, S. (2007). Memory bounded dynamic programming for DECPOMDPs. In International Joint Conference on Artificial Intelligence, pp. 20092016.
Seuken, S., & Zilberstein, S. (2008). Formal models and algorithms for decentralized decision
making under uncertainty. Autonomous Agents and Multiagent Systems, 17 (2), 190
250.
Sherali, H. D., & Shetty, C. M. (1980). A finitely convergent algorithm for bilinear programming problems using polar cuts and disjunctive face cuts. Mathematical Programming,
19 (1), 1431.
Vanderbei, R. J. (2001). Linear Programming: Foundations and Extensions (2nd edition).
Springer.
White, D. J. (1992). A linear programming approach to solving bilinear programmes.
Mathematical Programming, 56 (1), 4550.

274

fiJournal of Artificial Intelligence Research 35 (2009) 533-555

Submitted 12/08; published 07/09

Solving Weighted Constraint Satisfaction Problems with
Memetic/Exact Hybrid Algorithms
Jose E. Gallardo
Carlos Cotta
Antonio J. Fernandez

pepeg@lcc.uma.es
ccottap@lcc.uma.es
afdez@lcc.uma.es

Dept. Lenguajes y Ciencias de la Computacion
Universidad de Malaga, ETSI Informatica
Campus de Teatinos, 29071  Malaga, Spain

Abstract
A weighted constraint satisfaction problem (WCSP) is a constraint satisfaction problem
in which preferences among solutions can be expressed. Bucket elimination is a complete
technique commonly used to solve this kind of constraint satisfaction problem. When the
memory required to apply bucket elimination is too high, a heuristic method based on
it (denominated mini-buckets) can be used to calculate bounds for the optimal solution.
Nevertheless, the curse of dimensionality makes these techniques impractical on large scale
problems. In response to this situation, we present a memetic algorithm for WCSPs in
which bucket elimination is used as a mechanism for recombining solutions, providing the
best possible child from the parental set. Subsequently, a multi-level model in which this
exact/metaheuristic hybrid is further hybridized with branch-and-bound techniques and
mini-buckets is studied. As a case study, we have applied these algorithms to the resolution
of the maximum density still life problem, a hard constraint optimization problem based
on Conways game of life. The resulting algorithm consistently finds optimal patterns for
up to date solved instances in less time than current approaches. Moreover, it is shown
that this proposal provides new best known solutions for very large instances.

1. Introduction
Many real problems can be formulated as constraint satisfaction problems (CSPs) in which
solutions are assignments to a set of variables (each variable taking values from a certain
domain), and in which there exists a collection of constraints that restrict the assignment of
particular values or combination of values; solving a CSP means finding a feasible assignment
of values to variables, i.e., one where all the constraints are satisfied. However, a wide range
of problems cannot be posed this way, either because the problem is over-constrained (and
thus there is no solution) or because the problem has multiple solutions and the objective is
to find the best one according to some optimality criterion. In both cases, the problem might
be handled from an optimization point of view by associating preferences to the constraints.
This kind of CSP in which preferences among constraints/solutions can be expressed are
called weighted constraint satisfaction problems (WCSPs) (Schiex, Fargier, & Verfaillie,
1995; Bistarelli, Montanari, & Rossi, 1997). Solving a WCSP means optimally satisfying
a set of weighted constraints. This clearly enlarges the scope of CSPs: many practical
problems can be modeled as WCSPs, such as for instance, radio frequency assignment,
scheduling and cellular manufacturing, among others (Cabon, de Givry, Lobjois, Schiex, &
Warners, 1999; Khemmoudj & Bennaceur, 2007; Nonobe & Ibaraki, 2001).
c
2009
AI Access Foundation. All rights reserved.

fiGallardo, Cotta, & Fernandez

Complete methods, like branch-and-bound (Lawler & Wood, 1966) and bucket elimination (Dechter, 1999), a technique which originated in the early work of Bertele and
Brioschi (1972) on nonserial dynamic programming, are two of the most popular ways to
attack WCSPs. However, although the picture of a CSP is very general, it should be noted
that the inclusion of preferences in its constraints makes a particular WCSP very specific
and as a consequence WCSPs have to be tackled using very specialized algorithms that
were specifically designed (Freuder & Wallace, 1992; Verfaillie, Lematre, & Schiex, 1996;
Kask & Detcher, 2001; Lematre, Verfaillie, Bourreau, & Laburthe, 2001; Larrosa & Schiex,
2004; Gelain, Pini, Rossi, & Venable, 2007; Khemmoudj & Bennaceur, 2007; Marinescu
& Dechter, 2007). Moreover, general techniques require a very large computational effort
(in time, memory or both) to solve many WCSPs, due to their size and complexity, and
therefore are impractical in many cases. This can be alleviated using heuristic methods,
e.g., beam search (BS) (Barr & Feigenbaum, 1981) and mini-buckets (Dechter, 1997), for
branch-and-bound and bucket elimination respectively. However, in large scale problems,
the high computational cost is still evident.
In this context the use of alternative techniques must be considered to overcome the
limitations of general techniques; for instance, evolutionary algorithms (Back, 1996; Back,
Fogel, & Michalewicz, 1997) are powerful heuristics for optimization problems based on
the principles of natural evolution, which are flexible enough to be deployed in a wide
range of problems. However, this generality reduces their competitiveness, unless domain
knowledge is also incorporated. This need for exploiting domain knowledge in optimization
methods has been repeatedly shown (Wolpert & Macready, 1997; Culberson, 1998), and
memetic algorithms (Moscato & Cotta, 2003, 2007; Krasnogor & Smith, 2005) represent
one of the most successful responses to this need (Hart, Krasnogor, & Smith, 2005). This
paper explores different ways of hybridizing branch-and-bound/bucket elimination (and
their corresponding heuristic methods) and memetic algorithms, combining their search
capabilities in a synergetic way.
The hybrid techniques proposed here can be used as general problem solvers for WCSPs.
Note that they are essentially heuristic in nature and hence they cannot provide optimality
proofs for the solutions they obtain. Notice however that they can probably provide optimal
or near-optimal solutions to a wide range of WCSPs. Furthermore, these hybrid techniques
are less time-consuming than the general methods involved in them, and can thus be applied
to larger problem instances. In order to experimentally evaluate the hybrid techniques, we
have tackled the Maximum Density Still Life Problem, a very hard combinatorial optimization problem which is also a prime example of a weighted constraint optimization problem.
No polynomial-time algorithm is known to solve this problem, although, to the best of our
knowledge, the problem has not yet been proven to be NP-hard. For these reasons, it is
not surprising that this problem has attracted the interest of the constraint-programming
community, and has been central in the development and assessment of sophisticated techniques such as bucket elimination. Indeed, it constitutes an excellent test bed for different
optimization techniques, and has been included in the CSPLib1 repository. A web page2
keeps record of up-to-date results.
1. http://www.csplib.org
2. http://www.ai.sri.com/~nysmith/life

534

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

2. Preliminaries
In this section, we briefly introduce concepts and techniques that will be used in the rest
of the paper. To this end, we first define weighted constraint satisfaction problems, as well
as the techniques of bucket elimination and mini-buckets. Subsequently, we describe beam
search, a heuristic tree search algorithm derived from branch-and-bound. Finally, memetic
algorithms are presented. For the sake of notational simplicity, where appropriate we stick
to the notation of Larrosa et al. (2003, 2005).
2.1 Weighted Constraint Satisfaction Problems
A weighted constraint satisfaction problem (WCSP) (Schiex et al., 1995; Bistarelli et al.,
1997) is a constraint satisfaction problem (CSP) in which preferences among solutions can be
expressed. Formally, a WCSP can be defined by a tuple (X , D, F), where D = {D1 ,    , Dn }
is a set of finite domains, X = {x1 ,    , xn } is a set of variables taking values from their finite
domains (Di is the domain of variable xi ) and F is a set of cost functions (also called soft
constraints or weighted constraints) used to declare preferences among possible solutions.
Variable correctly assigned receive finite costs that express their degree of preference (the
lower the value the better the preference) and variables not correctly assigned receive cost
. Note that each f  F is defined over a subset of variables, var(f )  X , called
P its scope.
The objective function F is defined as the sum of all functions in F, i.e., F = f F f .
The assignment of value vi  Di to variable xi is noted xi = vi . A partial assignment
of m < n variables is a tuple t = (xi1 = v1 , xi2 = v2 ,    , xim = vm ) where ij  {1, . . . , n}
are all different. A complete assignment of all variables with values in their domains that
satisfies every soft constraint (i.e., with a finite valuation for F ) represents a solution to the
WCSP. The optimization goal is to find a solution that minimizes this objective function.
2.2 Bucket Elimination
Bucket elimination (BE) (Dechter, 1999) is a generic technique suitable for many automated
reasoning and optimization problems and, in particular, for solving WCSP. The functioning
of BE is based upon the following two operators over functions (Larrosa et al., 2005):
 the sum of two functions f and g, denoted (f + g), is a new function with scope
var(f )var(g) which returns for each tuple the sum of costs of f and g, i.e., (f +g)(t) =
f (t) + g(t).
 The elimination of variable xi from f , denoted f  xi , is a new function with scope
var(f )  {xi } which returns for each tuple t the minimum cost extension of t to xi ,
(f  xi )(t) = minvDi {f (t  (xi = v))}, where t  (xi = v) means the extension of the
assignment t with the assignment of value v to variable xi . Observe that when f is a
unary function (i.e., it has arity one), a constant is obtained upon elimination of the
only variable in its scope.
Without losing of generality, let us assume a lexicographic ordering for the variables in
X , i.e., o = (x1 , x2 ,    , xn ). Figure 1 shows pseudo-code of the BE algorithm for solving
a WCSP instance, which returns the optimal cost in F and one optimal assignment in
535

fiGallardo, Cotta, & Fernandez

Bucket Elimination for a WCSP (X , D, F )
1:
2:
3:
4:
5:
6:
7:
8:
9:
10 :
11 :

function BE(X , D, F)
for i := n downto 1 do
Bi := {f
P  F | xi  var(f )}
gi := ( S
f Bi f )  xi
F := (F {gi })  Bi
end for
t := 
for i := 1 to n do P
v := argminaDi {( f Bi f )(t  (xi = a))}
t := t  (xi = v)
end for
return(F, t)
end function

Figure 1: The general template, adapted from Larrosa and Morancho (2003), of bucket
elimination for a WCSP (X , D, F ).

t. Observe that, initially, BE eliminates in decreasing order one variable xi  X in each
iteration of the loop comprising lines 1-5. This is done by computing firstly the bucket Bi of
variable xi as the set of all cost functions in F having xi in their scope. Then, a new function
gi is defined as the sum of all these functions in Bi in which variable xi has been eliminated.
Finally, F is updated by removing the functions involving xi (i.e., those in Bi ) and adding
the new function that does not contain xi . The consequence is that xi does not exist in F
but the value of the optimal cost is preserved. The elimination of x1 produces a function
with an empty scope (i.e., a constant) which is the optimal cost of the problem. Then, in
lines 6-10, BE generates an optimal assignment of variables by considering these in the order
imposed by o: this is done by starting from an empty assignment t and assigning to xi the
best value of the extension of t, with respect to the sum of functions in Bi (argmina {f (a)}
represents the value of a producing the minimum f (a)).
Note that BE has exponential space complexity because, in general, the result of summing functions or eliminating variables cannot be expressed intensionally by algebraic expressions and, as a consequence, intermediate results have to be collected extensionally in
tables. To be precise, the complexity of BE depends on the problem structure (as captured
by its constraint graph G) and the ordering o. According to Larrosa and Morancho (2003),


the complexity of BE along ordering o is time (Q  n  dw (o)+1 ) and space (n  dw (o) ),
where d is the largest domain size, Q is the cost of evaluating cost functions (usually assumed (1)), and w (o) is the induced width of the graph along ordering o, which describes
the largest clique created in the graph by bucket elimination, and which corresponds to
the largest scope of a function recorded by the algorithm. Although finding the optimal
ordering is NP-hard (Arnborg, 1985), heuristics and approximation algorithms have been
developed for this task  check the work of Dechter (1999) for details.
536

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

2.3 Mini-Buckets
The main drawback of BE is that it requires exponential space to store functions extensionally. When this complexity is too high, the solution can be approximated using the
mini-bucket (MB) approach presented by Dechter (1997) and Detcher and Rish (2003). Recall that, in order to eliminate variable xi , with
P its corresponding bucket Bi = {fi1 , . . . , fim },
BE calculates a new cost function gi = ( f Bi f )  xi , whose time and space complexity increases with the cardinality of gi , i.e., with the size of the set f Bi var(f )  {xi }.
This complexity can be decreased by approximating the function gi with a set of smallerarity functions. The basic idea is to partition bucket Bi into k so called mini-buckets
Bi1 , . . . , Bik , such that the number of variables in the scope of each Bij is bounded by
a parameter. Afterwards,
a set of k cost functions with the reduced arity sought can be
P
defined as gij = ( f Bi f )  xi , j = 1 . . . k, and the required approximation to gi can be
j
P
P
P
computed as the sum gi0 = 16j6k gij = 16j6k (( f Bi f )  xi ).
j
Note that the minimization computed in gi by the  operator has been migrated inside
the sum. Since, in general, for any two non-negative functions f1 (x) and f2 (x), minx (f1 (x)+
f2 (x)) > minx f1 (x) + minx f2 (x), it follows that gi0 is a lower bound on gi . Therefore, if
variable elimination is performed using approximated cost functions, it provides a lower
bound for the optimal cost requiring less computation than BE. Notice that the described
approach provides a family of under-estimating heuristic functions whose complexity and
accuracy is parameterized by the maximum number of variables allowed in each mini-bucket.
2.4 Beam Search
Branch-and-bound (BB) (Lawler & Wood, 1966) is a general tree search method for solving
combinatorial optimization problems. Tree search methods are constructive, in the sense
that they work on partial solutions. In this way, tree search methods start with an empty
solution that is incrementally extended by adding components to it. The way that partial
solutions can be extended depends on the constraints imposed by the problem being solved.
The solution construction mechanism maps the search space to a tree structure, in such a
way that a path from the root of the tree to a leaf node corresponds to the construction
of a solution. In order to efficiently explore this search tree, BB algorithms maintain an
upper bound and estimate lower bounds for partially constructed solutions. Assuming a
minimization problem, the upper bound corresponds to the cost of the best solution found
so far. During the search process, a lower bound is computed for any partial solution
generated, estimating the cost of the best solution that can be constructed by extending
it. If this lower bound is greater than the current upper bound, solutions constructed by
extending it will not lead to an improvement, and thus all nodes descending from it can
be pruned from the search tree. Clearly, the capability of the algorithm for pruning the
search tree depends on the existence of an accurate lower bound, which should also be
computationally inexpensive in order to be practical.
Beam search (BS) (Barr & Feigenbaum, 1981) algorithms are incomplete derivates of BB
algorithms, and are thus heuristic methods. Essentially, BS works by extending every partial
solution from a set B (called the beam) in at most kext possible ways. Each new partial
solution so generated is stored in a set B. When all solutions in B have been processed, the
algorithm constructs a new beam by selecting the best up to kbw (called the beam width)
537

fiGallardo, Cotta, & Fernandez

solutions from B. Clearly, a way of estimating the quality of partial solutions, such as a
lower bound, is needed for this.
An interesting peculiarity of BS is the way it extends in parallel a set of different partial
solutions in several possible ways, making it a particularly suitable tree search method to
be used in a hybrid collaborative framework (it can be used to provide periodically promising partial solutions to a population-based search method such as a memetic algorithm).
Gallardo, Cotta, and Fernandez (2007) have shown that this kind of hybrid algorithms
can provide excellent results for some combinatorial optimization problems. We will subsequently present a hybrid tree search/memetic algorithm for WCSPs based on this idea.
2.5 Memetic Algorithms
Evolutionary algorithms (EAs) are population-based metaheuristic optimization methods
inspired by biological evolution (Back et al., 1997). In order to explore the search space, the
EA maintains a set of solutions known as the population of individuals. These are usually
randomly initialized across the search space, although heuristics may also be used. After the
initialization, three different phases are iteratively performed until a termination condition
is reached: selection, reproduction (which encompasses recombination and mutation) and
replacement. In the context of EAs, the objective function assigning values to each solution
is termed a fitness function, and is used to guide the search.
Note that EAs are black box optimization procedures in the sense that no knowledge
of the problem (apart from the fitness function) is used. The need to exploit problemknowledge has been repeatedly shown (Wolpert & Macready, 1997; Culberson, 1998) however. Different attempts have been made to answer this need; Memetic algorithms (Moscato
& Cotta, 2003, 2007; Krasnogor & Smith, 2005) (MAs) are one of the most successful approaches to date (Hart et al., 2005). Like EAs, MAs are also population based metaheuristics. The main difference is that the components of the population (sometimes termed
agents in MA terminology) are not passive entities. Rather, they are active entities that
cooperate and compete in order to find improved solutions.
There are many possible ways to implement MAs. The most common implementation
consists of combining an EA with a procedure to perform a local search on some or all
solutions in the population during the main generation loop (cf. Krasnogor & Smith, 2005).
Figure 2 shows the general outline of such a MA; pX , pm and arity respectively refer to
the recombination probability, mutation probability and recombination arity  i.e., number
of parents involved in recombination. It must be noted however that the MA paradigm
does not simply reduce itself to this particular scheme and there are different places (e.g.,
population initialization, genotype to phenotype mapping, evolutionary operators, etc.)
where problem specific knowledge can be incorporated. In this work, in addition to using
tabu search (Glover, 1989, 1990) (TS) as a local search procedure within the MA, we have
designed an intelligent recombination operator that uses a relaxation of bucket elimination
in order to find the best solution that can be constructed from a set of parents without
introducing implicit mutation (i.e., exogenous information).
538

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

Memetic Algorithm
1:
2:
3:
4:
5:
6:
7:
8:
9:
10 :
11 :
12 :
13 :
14 :
15 :
16 :
17 :
18 :
19 :
20 :
21 :
22 :
23 :

function MA (pX , pm , arity)
for i := 1 to popsize do
pop[i] := Random solution(n)
pop[i] := Local Search(pop[i])
Evaluate(pop[i])
end for
while no timeout do
for i := 1 to offsize do
if recombination is performed (under pX ) then
for j := 1 to arity do
parentj := Select(pop)
end for
offspring[i ] := Recombine(parent1 , parent2 , . . . , parentarity )
else
offspring[i ] := Select(pop)
end if
if mutation is performed (under pm ) then
offspring[i ] := Mutate(offspring[i ])
end if
offspring[i ] := Local Search(offspring[i ])
Evaluate(offspring[i ])
end for
pop := Replace(pop, offspring)
end while

Figure 2: Pseudo code of a memetic algorithm (MA). Although different variants are possible with respect to this scheme, it broadly captures a typical algorithmic structure
of MAs.

3. A Multi-Level Memetic/Exact Hybrid Algorithm for WCSPs
WCSPs are very suitable for being tackled with evolutionary metaheuristics. Obviously,
the quality of the results will greatly depend on how well knowledge of the problem is
incorporated into the search mechanism. Our final goal is to present an algorithmic model
based on the hybridization of MAs with exact techniques at two levels: within the MA (as
an embedded operator), and outside it (in a cooperative model). Firstly, we will focus in the
next subsection on the first level of hybridization, which incorporates an exact technique
(namely BE) within the MA as an embedded recombination operator. Subsequently, we
will proceed to a second level of hybridization, in which the MA cooperates with a branchand-bound based beam search algorithm that further uses the technique of mini-buckets as
a lower bound (see Figure 3).
539

fiGallardo, Cotta, & Fernandez

MA

Promising Regions

BS
GA
TS
Local
Search

BE

MB

Crossover

Lower
Bound

Upper Bound

Figure 3: Schematic description of the proposed hybrid algorithm.
3.1 Optimal recombination with BE
As previously mentioned, one of the phases that constitutes a typical MA is recombination
(i.e., lines 9-14 in Figure 2), in which some individuals in the population are combined with
the aim of obtaining improved individuals. For this purpose, different standard recombination operators have been proposed in the literature (see Back et al., 1997). Although those
blind operators are feasible from a computational point of view, they would perform poorly,
as no problem knowledge is being used. In the context of WCSPs, we can resort to BE in
order to achieve a sensible recombination of information.
Even though the performance of BE as an exact method for the resolution of WCSPs
may be better than basic search-based approaches, the corresponding time and space complexity can still be very high, making this technique unsuitable for large instances. In the
following, we explain how BE can be used to implement an intelligent recombination operator for WCSPs. Such operator will implicitly explore the possible children of the solutions
being recombined, providing the best solution that can be constructed without introducing
implicit mutation, i.e., exogenous information (cf. Cotta & Troya, 2003). Note that this
use of bucket elimination is related to what is usually referred to as Large Neighborhood
Search (Ahuja, Ergun, Orlin, & Punnen, 2002).
For the sake of simplicity, let us assume that all variables in WCSP (X , D, F ) have the
same domain (i.e., D1 =    = Dn ), and let x = (x1 , x2 ,    , xn ) and y = (y1 , y2 ,    , yn )
be two solutions to be recombined, and [zi ] will be the value of variable zi . Our operator will calculate the best solution that can be obtained by combining variables from
x and y without introducing information not present in any of the parents. This can
be achieved by restricting the domain of variables in BE to values appearing in the configurations being recombined. The recombination operator becomes BE(X , D, F), where
D = {[x1 ],    , [xn ], [y1 ],    , [yn ]}. Applying this approach to a WCSP in which variables
may have different domains would require previously separating the set of variables X into
subsets of variables sharing the same domain.
3.2 A Beam Search/MA Hybrid Algorithm
In this subsection, we describe a hybrid tree search/memetic algorithm for WCSPs. This
algorithm combines, in a collaborative way (Puchinger & Raidl, 2005), a BS algorithm and a
MA. As noted previously, BS works by extending in parallel a set of different partial solutions
in several possible ways, and thus can be used to provide promising partial solutions to a
540

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

Hybrid algorithm for a WCSP
1:
2:
3:
4:
5:
6:
7:
8:
9:
10 :
11 :
12 :
13 :
14 :
15 :
16 :
17 :

function BS-MA (X , D, kbw , kM A )
sol := 
B := { () }
for i := 1 to n do
B0 := {}
for s  B do
for a  Di do
B 0 := B 0  {s  (xi = a)}
end for
end for
B := select best kbw nodes from B 0
if (i > kM A ) then
initialize MA population with best popsize nodes from B 0
run MA
sol := min (sol, MA solution)
end if
end for
return sol
end function
Figure 4: Hybrid algorithm for a WCSP.

population based search method such as a MA. The goal is to exploit the capability of BS
for identifying potentially good regions of the search space, and also to exploit the MA to
explore these regions, synergistically combining these two different approaches.
The proposed hybrid algorithm, that executes BS and the MA in an interleaved way, is
depicted in Figure 4. In the pseudo-code, a (possibly partial) solution for a WCSP instance
is represented by a vector of variables s = (x1 , x2 , . . . , xi ), i 6 n, where s  (xi = a) stands
for the extension of partial solution s by assigning value a to its i-th variable as noted
previously. The hybrid algorithm constructs a search tree, such that its leaves consist of
complete solutions and internal nodes at level i represent partially specified (up to the i-th
variable) solutions. This tree is heuristically traversed in a breadth first way using a BS
algorithm with beam width kbw (i.e., maintaining only the best kbw nodes at each level of
the tree). For the beam selection (line 10), a heuristic quality measure has to be defined for
partial solutions, whose value must be  if the partial solution is unfeasible. The algorithm
starts (line 2) with a totally unspecified solution. Initially, only the BS part of the algorithm
is executed. During each iteration of BS (lines 3-17), a new variable is assigned for every
solution in the beam (line 7). The interleaved execution of the MA starts only when partial
solutions in the beam have at least kM A variables (line 11). For each iteration of BS, the
best popsize solutions in the beam are selected (using the quality measure described above)
to initialize the population of the MA (line 12). Since these are partial solutions, they must
be first converted into full solutions, e.g., by completing remaining variables randomly.
541

fiGallardo, Cotta, & Fernandez

After running the MA, its solution is used to update the incumbent solution (sol), and this
process is repeated until the search tree is exhausted.
3.3 Computing Tight Bounds with Mini-Buckets
The performance of the BS component of the algorithm described in the previous section
will depend on the quality of the heuristic function used to estimate partial solutions (line
10 of Figure 4). In order to compute a tight, yet computationally inexpensive, lower bound
for the remanning part of the solution we can resort to Mini-Buckets (MB). As described by
Kask and Detcher (2001), the intermediate functions created by applying the MB scheme
can be used as a general mechanism to compute heuristic functions that estimate the best
cost of yet unassigned variables in partial solutions. To this end, MB must be run as a
preprocessing stage, using the reverse order in which the search will instantiate variables.
The set of augmented buckets computed during this process can be used as estimations of
the best cost extension to partial solutions (check the work of Kask & Detcher, 2001, for
details).

4. Tackling the Maximum Density Still Life Problem
Previously proposed algorithms are general enough to be used in many WCSPs in which
BE can be executed. In this section we present an application case study on the maximum
density still life problem (MDSLP). This problem is defined in the context of the game of life
proposed by John H. Conway in the 60s and divulged by Martin Gardner (Gardner, 1970),
so let us first describe this game. It is played on an infinite checkerboard in which the only
player places checkers on some of its squares. Each square on the board is called a cell and
has eight neighbors; the eight cells that share one or two corners with it. A cell is alive if
there is a checker on it, and is dead otherwise. The contents of the board evolve iteratively,
in such a way that the state at time t determines the state at time t + 1 according to some
simple rules: (1) a live cell remains alive if it has two or three live neighbors, otherwise it
dies, and (2) a dead cell becomes alive it is has exactly three live neighbors.
The simple rules of the game of life can nevertheless generate an incredibly complex
dynamics. To better understand the MDSLP, let us define a stable pattern (also called a
still life) as a board configuration that does not change over time, and let the density of a
region be its percentage of living cells. The MDSLP in an nn grid consists of finding a still
life of maximum density. Elkies (1998) has shown that, for infinite boards, the maximum
density is 1/2 (for finite size, no exact formula is known). In this paper, we are concerned
with the MDSLP and finite patterns, that is, finding maximal n  n still lifes.
4.1 Related Work
The MDSLP has been tackled in the literature using different approaches. Bosch and Trick
(2002) compared different formulations for the MDSLP using integer programming (IP) and
constraint programming (CP). Their best results were obtained with a hybrid algorithm
mixing the two approaches. They were able to solve the cases for n = 14 and n = 15
in about 6 and 8 days of CPU time respectively. Smith (2002) used a pure constraint
programming approach to address the problem. However, only instances up to n = 10
542

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

Table 1: Best experimental results reported by Bosch and Trick (2002) (CP/IP), Larrosa
and Morancho (2003) (BE) and Larrosa et al. (2005) (HYB-BE) for solving the
MDSLP. Time is indicated in seconds.

optimum
CP/IP
BE
HYB-BE

12
68
11536
1638
1

13
79
12050
13788
2

14
92
5  105
105
2

15
106
7  105

16
120

17
137

18
153

19
171

20
190

58

7

1091

2029

56027

2  105

could be solved. The best results for this problem were reported by Larrosa and Morancho
(2003) and Larrosa et al. (2005), showing the usefulness of bucket elimination (BE), an
exact technique based on variable elimination and commonly used for solving constraint
satisfaction problems described in detail in Section 2.2. Their basic approach could solve
the problem for n = 14 in about 105 seconds. Further improvements increased the boundary
to n = 20 in about twice as much time. Recently, Cheng and Yap (2005, 2006) have tackled
the problem via the use of ad-hoc global case constraints, but their results are comparable
to IP/CP hybrids, and thus cannot be compared to the ones obtained previously by Larrosa
et al.
Table 1 summarizes experimental results for current approaches used to tackle the MDSLP, reporting the computational times of the hybrid IP/CP algorithm of Bosch and Trick
(2002), the BE approach of Larrosa and Morancho (2003) and the BE/search hybrid of
Larrosa et al. (2005). Although different computational platforms may have been used for
these experiments, the trends are very clear and give a clear indication of the potential of
the different approaches. It should be noted that all these techniques applied to the MDSLP
are exact approaches. They are inherently limited for increasing problem sizes and their
capabilities as anytime algorithms are unclear. To tackle this problem, we recently proposed
the use of hybrid methods combining exact and metaheuristic approaches. We considered
the hybridization of BE with evolutionary algorithms (a stochastic population-based search
method) endowed with tabu search (a local search method)(Gallardo, Cotta, & Fernandez,
2006a). The resulting algorithm was a memetic algorithm (MA; see Section 2.5). It used
BE as a mechanism for recombining solutions, providing the best possible child from the
parental set. Experimental tests indicated that the algorithm provided optimal or nearoptimal results at an acceptable computational cost. Subsequently, we studied extended
multi-level models in which our previous hybrid algorithm was further hybridized with
a branch-and-bound derivative, namely beam search (BS)(Gallardo, Cotta, & Fernandez,
2006b). Studies on the influence that variable clustering and multi-parent recombination
have on the performance of the algorithm were also conducted. The results indicated that
variable clustering was detrimental for this problem but also that multi-parent recombination improves the performance of the algorithm. To the best of our knowledge, these are
the only heuristic approaches applied to this problem to date.
In this section, our previous research on this problem is included and extended. As
new contributions, we have redone all the experiments using an improved implementation
543

fiGallardo, Cotta, & Fernandez

of the bucket elimination crossover operator, described in Section 3.1. Additionally, we
present a more extensive experimental analysis of our BS/MA hybrid described in (Gallardo
et al., 2006b), analyzing the sensitivity of its parameters. We also propose a new hybrid
algorithm that uses the technique of mini-buckets to further improve the lower bounds of
the partial solutions considered in the BS part of the hybrid algorithm. This new algorithm
is obtained from the hybridization, at different levels, of complete solving techniques (BE),
incomplete deterministic methods (BS and MB) and stochastic algorithms (MAs). An
experimental analysis shows that this new proposal consistently finds optimal solutions for
MDSLP instances up to n = 20 in considerably less time than all the previous approaches
reported in the literature. Finally, in order to test the scalability of our approach, this novel
hybrid algorithm has been run on very large instances of the MDSLP for which an optimal
solution is currently unknown. The results were very successful, as the algorithm performed
at the state-of-the-art level, providing solutions that are equal or better than the best
ones reported to date in the literature. For readability reasons, many particular technical
details of the different algorithms for the MDSLP are omitted, but are fully described in an
accompanying report (Gallardo, Cotta, & Fernandez, 2008). At any rate, a model of the
MDSLP as a WCSP is presented in Appendix A.
4.2 A Memetic Algorithm for the MDSLP
First of all, we develop a MA for the MDSLP. In this MA, an n  n board is represented as
a binary n  n matrix. Based on the stratified gradient provided by a penalty based fitness
function that measures the number of violated constraints and their distance to feasibility
(prioritizing the former over the latter), an efficient local search strategy that explores the
set of solutions obtained by flipping exactly one cell in a configuration was devised. In order
to escape from local optima, a tabu-search scheme is used (line 19 in Figure 2).
The MA uses BE as a crossover operation as described in Section 3.1 (line 12 in Figure 2).
One interesting property of the operator described is that it is not limited to recombining
only two board configurations, but can instead be generalized to recombine any number of
them by considering domains consisting of all the values a variable has in any of the parents.
This multi-parental capability has also been explored in the rest of this paper.
To evaluate the usefulness of the described hybrid recombination operator, a set of experiments for problem sizes from n = 12 up to n = 20 has been realized (recall that optimal
solutions to the MDSLP are known up to n = 20). The experiments have been performed
using a steady-state evolutionary algorithm (popsize = 100, pm = 1/n2 , pX = 0.9, binary
tournament selection). With the aim of maintaining diversity, duplicated individuals are
not allowed in the population. Algorithms were run until an optimal solution was found or
a time limit exceeded. This time limit was set to 3 minutes for problem instances of size 12
and was gradually increased by 60 seconds for each size increment. For each algorithm and
each instance size, 20 independent runs have been made. All experiments in this paper have
been performed on a Pentium IV PC (2400MHz and 512MB RAM) under SuSE Linux.
The base algorithm is a MA using a two-dimensional version of SPX (single-point
crossover) for recombination, and endowed with tabu search for local improvement. This
algorithm is termed MATS , and has been shown to be capable of finding feasible solutions systematically, solving to optimality instances with n < 15 (see MATS in Figure 5a).
544

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

10
9.5
9
8.5
8
7.5
7
6.5
6
5.5
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0

25
MABE
MABE1F
MABE2F
MATS

Arity=2
Arity=4
Arity=8
Arity=16

22.5
20

% distance to optimum

% distance to optimum

Although the performance of the algorithm degrades for larger instances, it provides distributions for the solutions whose average relative distance to the optimum is less than 5.29%
in all cases. This contrasts with the case of plain EAs, which are incapable of finding even
a feasible solution in most runs (Gallardo et al., 2006a).

17.5
15
12.5
10
7.5
5
2.5

12

13

14

15

16

17

18

19

0

20

12

13

14

15

16

17

18

19

20

instance size

instance size

(a)

(b)

Figure 5: Relative distances to optimum for different (a) algorithms and (b) arities for sizes
ranging from 12 up to 20. In this and in all subsequent figures, each box summarizes 20 runs, boxes comprise the second and third quartiles of the distribution
(i.e., the inner 50%), a horizontal line marks the median, a plus sign indicates
the mean, and circles indicate results further from the median than 1.5 times the
interquartile-distance.
MATS is firstly compared with MAs endowed with BE for performing recombination.
Since the use of BE for recombination has a higher computational cost than a simple blind
recombination, and there is no guarantee that recombining two infeasible solutions will
result in a feasible solution, we have defined three variants of the MAs:
 In the first one, called MA-BE, BE is always used to perform recombination.
 In the second, termed MA-BE1F , we require that at least one of the parents be feasible
in order to apply BE; otherwise blind recombination is used.
 In the last variant, identified as MA-BE2F , we require the two parents to be feasible,
thus being more restrictive in the application of BE.
By evaluating these variants, we intend to explore the computational tradeoffs involved
in the application of BE as an embedded component of the MA. For these algorithms,
mutation is performed prior to recombination in order to take advantage of good solutions
provided by BE. Figure 5a shows the empirical performance of the different algorithms.
Results show that MA-BE returns significantly better results than MATS . MA-BE2F can
find slightly better solutions than MA-BE on smaller instances (n  {13, 15, 16}), but on
545

fiGallardo, Cotta, & Fernandez

larger instances the winner is MA-BE. It seems that the effort saved by not recombining
unfeasible solutions does not further improve the performance of the algorithm. Note also
that, for larger instances, MA-BE1F is better than MA-BE2F . This correlates well with the
fact that BE is used more frequently in the former than in the latter.
As mentioned in Section 3.1, the optimal recombination scheme we use can be readily extended to multi-parent recombination (Eiben, Raue, & Ruttkay, 1994): an arbitrary number
of solutions can contribute their constituent rows for constructing a new solution. Additional experiments were done to explore the effect of this capability of MA-BE. Figure 5b
shows the results obtained by MA-BE for a different number of parents being recombined
(arities 2, 4, 8 and 16). For arity = 2, the algorithm was able to find the optimum solution
for all instances except for n = 18 and n = 20 (the relative distance to the optimum for
the best solution found is less than 1.04% in these cases). Runs with arity = 4 cannot find
optimum solutions for the remaining instances, but note that the distribution improves in
some cases. Clearly, the performance of the algorithm deteriorates when combining more
than 4 parents due to the higher computational cost of BE. Variable clustering could be
used to alleviate this higher computational cost, but this results in performance degradation
since the coarser granularity of the pieces of information hinders information mixing (Cotta
& Troya, 2000; Gallardo et al., 2006b).
4.3 A BS/MA Hybrid Algorithm for the MDSLP
In this section we evaluate an instantiation of the BS and MA hybrid algorithm described in
Section 3.2 for the MDSLP, called BS-MA-BE. For the beam selection (line 10 in Figure 4),
a simple quality measure is defined for partial solutions, whose value is either  if the
partial configuration is unstable, or its number of dead cells otherwise. The methodology
is the same as in Section 4.2 (20 executions are performed for each algorithm and instance
size), but arities for the MA are in {2, 3, 4}. The setting of the remaining parameters
is kbw = 2000 (preliminary tests indicated that this value was reasonable), and kM A 
{0.3  n, 0.5  n, 0.75  n}, i.e., the best 2000 nodes were kept on each level of the BS algorithm,
and 30%, 50% or 75% of the levels of the BS tree were initially descended before the MA
was run. With respect to termination conditions, each execution of the MA within the
hybrid algorithm consists of 1000 generations, and no time limits are imposed for the hybrid
algorithms, which are run for n iterations of the BS.
Figure 6a shows the results for different values of parameter kM A . In order to better
compare the distributions, the number of optimal solutions obtained by each algorithm
(out of 20 executions) is shown above each box plot. For kM A = 0.3  n, the performance of
the resulting algorithm improves significantly over the original MA. Note that BS-MA-BE,
using an arity of 2 parents, is able to find the optimum for all cases except for n = 18
(this instance is solved with arity = 4). All distributions for different instance sizes are
significantly improved. For n < 17 and arity  {2, 3, 4}, the algorithm consistently finds
the optimum in all runs. For other instances, the solution provided by the algorithm is
always within 1.05% of the optimum, except for n = 18, for which the relative distance to
the optimum for the worst solution is 1.3%. The other two charts show that, in general,
the performance of the algorithm deteriorates with increasing values of the kM A parameter.
This may be due to the low quality of the bounds used in the BS part.
546

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

750
Arity=2
Arity=3
Arity=4

500

k

MA

= 0.75  n

250

0
1500
kMA = 0.50  n

1250
Arity=2
Arity=3
Arity=4

2

0

1

kMA = 0.75  n

1.5

0 0 0
0

1

1 1 0
3 9 10

0.5

Time to best solution(s)

2.5

1000

750

500

250

20 20 20 20 20 20 20 20 20 20 20 20 20 20 20

0

% distance to optimum

2.5

0

2

2000
k

0 5

kMA = 0.50  n

1.5

MA

0 0 0

= 0.30  n

1750
1

1

2 0 1

1500

10 7 10

0.5

1250

20 20 20 20 20 20 20 20 20 20 20 20 20 20 20

0
2.5

1000

2

750
kMA = 0.30  n

1.5

0 0 3
4 2 6

1

500

2 2 1
11 13 14

250

0.5
20 20 20 20 20 20 20 20 20 20 20 20 20 20 20

0

12

13

14

15

16

17

18

19

0

20

(a)

12

13

14

15

16

17

18

19

20

instance size

instance size

(b)

Figure 6: (a) Relative distances to optimum and (b) time to best solution for different
arities for BS-MA-BE and KM A  {0.3  n, 0.5  n, 0.75  n}, for sizes ranging from
12 up to 20. The numbers above each box indicate how many times the optimal
solution was found.

Regarding execution times, Figure 6b shows time distributions (in seconds) to reach
the best solution needed by the algorithms. Although BS-MA-BE requires more time than
MA-BE, the time needed remains reasonable for these instances, and is always less than
2000 seconds. Note also how the execution time increases with the arity, as more time is
needed by the MA to perform BE in the crossover operator. On the other hand, execution
time decreases for larger values of kM A as the number of executions of the MA decreases,
although, as we have already remarked, the quality of the solutions worsens.
4.4 Improving the Lower Bound using MB for the MDSLP
The simple quality measure for beam selection used in the previous section depends solely on
the part of the solution that is already constructed. In this section, we will experimentally
study the use of the MB technique to compute a tight, yet computationally inexpensive,
547

fiGallardo, Cotta, & Fernandez

lower bound for the remanning part of the configuration with the aim of improving the
performance of the BS part of the hybrid algorithm. Basically, the idea is to cluster all cells
in the same row of the board in a metavariable. These metavariables can be partitioned
into M columns with  n/M cells each. Finally, we can resort to MB to estimate best cost
extensions to a partial board configuration by considering only each of the columns. By
summing estimations for all column extensions, a bound on the best board extension to a
partial solution is obtained. In this section, we have experimented with M = 3 (i.e., three
columns for each row), although if the complexity is still too high, the same approach can
be used to reduce it further, by considering more columns.
2.5
2.5

% distance to optimum

2
kMA = 0.30  n

1.5

16 18

1

18

13 19

6 13 19

0.5
20 20 20 20 20 20 20 20 20 20 20 20 20 20 20

0

12

13

14

15

20 20

16

17

20

18

20

19

2
kMA = 0.50  n

1.5

19

1

16

13 18 19

4 13 16

0.5

20

20 20 20 20 20 20 20 20 20 20 20 20 20 20 20

instance size

20 20

20 20

0

(a)

(b)

2.5

1.5

Arity=2
Arity=3
Arity=4

750

Time to b. sol(s)

2

kMA = 0.75  n
19

1

16 14 16

14 13 18

3 12 19

Arity=2
Arity=3
Arity=4

500

k

MA

= 0.75  n

250

0.5
20 20 20 20 20 20 20 20 20 20 20 20 20 20 20

20

0

20

(c)

12

13

14

15

16

17

18

19

20

instance size

0

(d)

Figure 7: (a)-(c) Relative distances to the optimum using different arities for
BS-MA-BE-MB and KM A  {0.3  n, 0.5  n, 0.75  n}, for sizes ranging from
12 up to 20. (d) Time (in seconds) to best solution for different arities for
BS-MA-BE-MB and kM A = 0.75  n, for sizes ranging from 12 up to 20.
Experiments were repeated for the hybrid algorithm equipped with the new lower bound,
BS-MA-BE-MB. Figure 7a-7c shows the results of these experiments for values of kM A 
{0.3  n, 0.5  n, 0.75  n}. The algorithm finds the optimum for all instances and arities and
the relative distance to the optimum for the worst solution found is less than 1.05% in all
cases. The best results are obtained with arity = 4, although this requires slightly more
execution time. Note also how BS-MA-BE-MB is less sensitive to the setting of parameter
kM A , which means that execution times can be reduced considerably using a large value for
this parameter (see Figure 7d). The particular combination of parameters kM A = 0.75  n
and arity = 4 provides excellent results at a lower computational cost, as execution times
are always below 570 seconds for n 6 20. As a comparison, recall that the only approach in
the literature that can solve these instances  described by Larrosa et al. (2005)  requires
over 33 minutes for n = 18, 15 hours for n = 19 and 2 days for n = 20, and that other
approaches are unaffordable for n > 15. Note however that these times correspond to a
computational platform different to ours. In order to make a fairer comparison, we executed
548

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

the algorithm of Larrosa et al. 3 in our platform. In this case, it required 1867 seconds
(i.e., more than 31 minutes) in order to solve the n = 18 instance, and more than 1 day and
18 hours to solve the n = 20 instance. These values are very close to the times reported
by Larrosa et al. (2005), and hence indicate that the computational platforms are fairly
comparable.
1.5

% distance

1

Arity=2
Arity=3
Arity=4

0.5
0
0.5
1

22

24

26

28

instance size

Figure 8: Relative distances to best known solutions using different arities for
BS-MA-BE-MB and kM A = 0.3  n, for very large instances (i.e., sizes of 22,
24, 26, and 28). Note the improvement of best known solutions for sizes 24 and
26.

Figure 9: New best known maximum density still lifes for n  {24, 26}.

Table 2: Optimal solutions for the SMDLP.
n
opt

12 13
68 79

14
92

15
106

16
120

17
137

18
154

19
172

20
192

22
232

24 26
276 326

28
378

4.5 Results on Very Large Instances
As already mentioned, there is currently no approach available to tackle the MDSLP for
n > 20. Larrosa et al. (2005) tried their algorithm for n = 21 and n = 22, but they could
3. Available at http://www.lsi.upc.edu/~larrosa/publications/LIFE-SOURCE-CODE.tar.gz . Time for
n = 19 could not be obtained as the code provided by Larrosa et al. can only be used with even sized
instances.

549

fiGallardo, Cotta, & Fernandez

not solve any of those instances within a week of CPU. For these very large instances, only
solutions to some relaxations of the problem are known. One of these relaxations, known
as the symmetrical maximum density still life problem (SMDSLP), was proposed by Bosch
and Trick (2002), and consists of considering only symmetric boards (either horizontally or
2
vertically) which reduces the search space from 2n to 2ndn/2e .
BE alone can find vertically symmetric still lifes, by considering as variable domains
sets that contain only symmetric rows. Larrosa and Morancho (2003) and Larrosa et al.
(2005) used this algorithm to solve the SMDSLP for the instances considered so far in this
paper (i.e., for n  {12 . . 20}), as well as for very large instances (i.e., n  {22, 24, 26, 28}).
The results are summarized in Table 2, which shows for each instance size the optimal
symmetrical solution (as the number of dead cells). Clearly, the cost of optimal symmetric
still lifes are upper bounds for the MDSLP, which can additionally be observed to be very
tight for n 6 20. Results for n > 20 are currently the best known solutions for these
instances.
We also run our algorithm (BS-MA-BE-MB) for these very large instances (i.e., n 
{22, 24, 26, 28}), and compare our results to symmetrical solutions for these instances. Results (displayed in Figure 8) show that our algorithm is able to find two new best known
solutions for the MDSLP, namely for n = 24 and n = 26. There are 275 and 324 dead
cells respectively in the new solutions. These solutions are pictured in Figure 9. It is
also worth noting that our algorithm could also find a solution with 325 dead cells for the
n = 26 instance. For the other instances, our algorithm could reach the best known solutions consistently. The computation of mini-Buckets for these very large instances is done
by considering four clustered cost functions for variables in each row of the board, as the
complexity when using three cost functions was still too high.

5. Conclusions
Many problems can be modeled as WCSPs. One exact technique that has been used to
tackle such problems is BE. However, the high space complexity of BE as an exact technique,
makes this approach impractical for large instances. In this case, one can resort to minibuckets to get an approximate solution, although the complexity can again be large. In
this work, we have presented several proposals for the hybridization of BE and MB with
memetic algorithms and beam search in order to get effective heuristics and have shown
that they represent very promising models.
We have experimentally evaluated our model with the MDSLP, an excellent example of
WCSP. Its highly constrained nature is typical in many optimization scenarios. The difficulty of solving this problem illustrates the limitations of classical optimization approaches,
and highlights the capabilities of the proposed approaches. Indeed, the experimental results have been very positive, solving large instances of the MDSLP to optimality. Among
the different models presented, we must distinguish a new algorithm resulting from the
hybridization, at different levels, of complete solving techniques (i.e., bucket elimination),
incomplete deterministic methods (i.e., beam search and mini-buckets) and stochastic algorithms (i.e., memetic algorithms). This algorithm empirically produces good-quality results,
not only solving to optimality very large instances of the constrained problem in a relatively
short time, but also providing new best known solutions in some large instances.
550

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

As future work, we plan to consider complete versions of the hybrid algorithm. This
involves the use of appropriate data structures to store not yet considered but promising
branch-and-bound nodes. While the memory requirements will of course grow enormously
with the size of the problem instance considered, it will be interesting to analyze the computational tradeoffs of the algorithm as an anytime technique.

Acknowledgments
We would like to thank Javier Larrosa for his valuable comments, which helped us to improve
significantly a preliminary version of this paper. Thanks are also due to the reviewers for
their constructive comments. This work has been partially supported by Spanish MCInn
under grant TIN2008-05941 (Nemesis).

Appendix A. The MDSLP as a WCSP
As shown by Larrosa and Morancho (2003) and Larrosa et al. (2005), the MDSLP can be
well formulated as a WCSPs. To this end, an n  n board configuration can be represented
by an n-dimensional vector (r1 , r2 , . . . , rn ). Each vector component encodes (as a binary
string) a row, so that the j-th bit of row ri (noted rij ) represents the state of the j-th cell
of the i-th row (a value of 1 represents a live cell and a value of 0 a dead cell).
Two functions over rows will be useful to describe the constraints that must be satisfied
by a valid configuration. The first one,
X
zeroes(a) =
(1  ai ),
(1)
1 6i6n

returns the number of dead cells in a row (i.e., the number of zeroes in binary string a).
The second one,
Adjs(a) = Adjs 0 (a, 1 , 0 )

l,
0
Adjs (a, i , l ) = Adjs 0 (a, i + 1 , l + 1 ),

max(l, Adjs 0 (a, i + 1 , 0 )),

(2)
i>n
ai = 1
ai = 0,

computes the maximum number of adjacent living cells in row a. We also introduce a ternary
predicate, Stable(ri1 , r , ri+1 ), which takes three consecutive rows in a board configuration
and is satisfied if, and only if, all cells in the central row are stable (i.e., all cells in row r
will remain unchanged in the next iteration of the game):
Stable(a, b, c) =

V

16i6n S(a, b, c, i)

2 6 (a, b, c, i) 6 3, bi = 1
S(a, b, c, i) =
(a, b, c, i) 6= 3,
bi = 0
P
(a, b, c, i) = max(1,i1)6j6min(n,i+1) (aj + bj + cj )  bi ,

(3)

where (a, b, c, i) is the number of living neighbors of cell bi , assuming a and c are the rows
above and below row b.
551

fiGallardo, Cotta, & Fernandez

The MDSLP can now be formulated as a WCSP using n cost functions fi , i  {1 . . n}.
Accordingly, fn is binary with scope the last two rows of the board (var(fn ) = {rn1 , rn })
and is defined as:

,
Stable(a, b, 0 )  Adjs(b) > 2
fn (a, b) =
(4)
zeroes(b), otherwise.
The first line checks that all cells in row rn are stable, whereas the second one checks that
no new cells are produced below the nn board. Note that any pair of rows representing an
unstable configuration is assigned a cost of , whereas a stable one is assigned its number
of dead cells (to be minimized).
For i  {2 . . n  1}, corresponding fi cost functions are ternary with scope var(fi ) =
{ri1 , ri , ri+1 } and are defined as:

,
fi (a, b, c) =
zeroes(b),

Stable(a, b, c)  (a1 = b1 = c1 = 1 )  (an = bn = cn = 1 )
(5)
otherwise.

In this case, boundary conditions are checked to the left and right of the board. As regards
cost function f1 , it is binary with scope the first two rows of the board (var(f1 ) = {r1 , r2 })
and is specified similarly to fn :

,
Stable(0 , b, c)  Adjs(b) > 2
(6)
f1 (b, c) =
zeroes(b), otherwise.

References
Ahuja, R. K., Ergun, O., Orlin, J. B., & Punnen, A. P. (2002). A survey of very large-scale
neighborhood search techniques. Discrete Appl. Math., 123 (1-3), 75102.
Arnborg, S. (1985). Efficient algorithms for combinatorial problems on graphs with bounded
decomposability - a survey. BIT, 2, 223.
Back, T. (1996). Evolutionary Algorithms in Theory and Practice. Oxford University Press,
New York NY.
Back, T., Fogel, D., & Michalewicz, Z. (1997). Handbook of Evolutionary Computation.
Oxford University Press, New York NY.
Barr, A., & Feigenbaum, E. (1981). Handbook of Artificial Intelligence. Morhan Kaufmann,
New York NY.
Bertele, U., & Brioschi, F. (1972). Nonserial Dynamic Programming. Academic Press, New
York NY.
Bistarelli, S., Montanari, U., & Rossi, F. (1997). Semiring-based constraint satisfaction and
optimization. Journal of the ACM, 44 (2), 201236.
Bosch, R., & Trick, M. (2002). Constraint programming and hybrid formulations for three
life designs. In International Workshop on Integration of AI and OR Techniques in
Constraint Programming for Combinatorial Optimization Problems, CP-AI-OR02, pp.
7791.
552

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

Cabon, B., de Givry, S., Lobjois, L., Schiex, T., & Warners, J. P. (1999). Radio link
frequency assignment. Constraints, 4 (1), 7989.
Cheng, K. C. K., & Yap, R. H. C. (2005). Ad-hoc global constraints for life. In van Beek,
P. (Ed.), Principles and Practice of Constraint Programming  CP2005, Vol. 3709 of
Lecture Notes in Computer Science, pp. 182195, Berlin Heidelberg. Springer.
Cheng, K. C. K., & Yap, R. H. C. (2006). Applying ad-hoc global constraints with the case
constraint to still-life. Constraints, 11, 91114.
Cotta, C., & Troya, J. (2000). On the influence of the representation granularity in heuristic
forma recombination. In Carroll, J., Damiani, E., Haddad, H., & Oppenheim, D.
(Eds.), ACM Symposium on Applied Computing 2000, pp. 433439. ACM Press.
Cotta, C., & Troya, J. (2003). Embedding branch and bound within evolutionary algorithms.
Applied Intelligence, 18(2), 137153.
Culberson, J. (1998). On the futility of blind search: An algorithmic view of no free lunch.
Evolutionary Computation, 6 (2), 109128.
Dechter, R. (1997). Mini-buckets: A general scheme for generating approximations in automated reasoning. In 15th International Joint Conference on Artificial Intelligence,
pp. 12971303, Nagoya, Japan.
Dechter, R. (1999). Bucket elimination: A unifying framework for reasoning. Artificial
Intelligence, 113 (1-2), 4185.
Detcher, R., & Rish, I. (2003). Mini-buckets: A general scheme for bounded inference.
Journal of the ACM, 50 (2), 107153.
Eiben, A., Raue, P.-E., & Ruttkay, Z. (1994). Genetic algorithms with multi-parent recombination. In Davidor, Y., Schwefel, H.-P., & Manner, R. (Eds.), Parallel Problem
Solving From Nature III, Vol. 866 of Lecture Notes in Computer Science, pp. 7887,
Berlin Heidelberg. Springer.
Elkies, N. D. (1998). The still-life problem and its generalizations. In Engel, P., & Syta, H.
(Eds.), Voronois Impact on Modern Science, Book 1, pp. 228253. Institute of Math,
Kyiv.
Freuder, E. C., & Wallace, R. J. (1992). Partial constraint satisfaction. Artificial Intelligence, 58 (1-3), 2170.
Gallardo, J. E., Cotta, C., & Fernandez, A. J. (2008). Finding still lifes with memetic/exact
hybrid algorithms. CoRR, Available at http://arxiv.org/abs/0812.4170.
Gallardo, J., Cotta, C., & Fernandez, A. (2007). On the hybridization of memetic algorithms with branch-and-bound techniques. IEEE Transactions on Systems, Man and
Cybernetics, part B, 37 (1), 7783.
Gallardo, J. E., Cotta, C., & Fernandez, A. J. (2006a). A memetic algorithm with bucket
elimination for the still life problem. In Gottlieb, J., & Raidl, G. (Eds.), Evolutionary
Computation in Combinatorial Optimization, Vol. 3906 of Lecture Notes in Computer
Science, pp. 7385, Berlin Heidelberg. Springer.
553

fiGallardo, Cotta, & Fernandez

Gallardo, J. E., Cotta, C., & Fernandez, A. J. (2006b). A multi-level memetic/exact hybrid
algorithm for the still life problem. In Runarsson, T. P., et al. (Eds.), Parallel Problem
Solving from Nature IX, Vol. 4193 of Lecture Notes in Computer Science, pp. 212221,
Berlin Heidelberg. Springer.
Gardner, M. (1970). The fantastic combinations of John Conways new solitaire game.
Scientific American, 223, 120123.
Gelain, M., Pini, M. S., Rossi, F., & Venable, K. B. (2007). Dealing with incomplete preferences in soft constraint problems. In Bessiere, C. (Ed.), Principles and Practice of
Constraint Programming  CP 2007, Vol. 4741 of Lecture Notes in Computer Science,
pp. 286300, Berlin Heidelberg. Springer.
Glover, F. (1989). Tabu search  part I. ORSA Journal on Computing, 1 (3), 190206.
Glover, F. (1990). Tabu search  part II. ORSA Journal on Computing, 2 (1), 432.
Hart, W., Krasnogor, N., & Smith, J. (2005). Recent Advances in Memetic Algorithms, Vol.
166 of Studies in Fuzziness and Soft Computing. Springer, Berlin Heidelberg.
Kask, K., & Detcher, R. (2001). A general scheme for automatic generation of search
heuristics from specification dependencies. Artificial Intelligence, 129, 91131.
Khemmoudj, M. O. I., & Bennaceur, H. (2007). Valid inequality based lower bounds for
WCSP. In Bessiere, C. (Ed.), Principles and Practice of Constraint Programming
 CP 2007, Vol. 4741 of Lecture Notes in Computer Science, pp. 394408, Berlin
Heidelberg. Springer.
Krasnogor, N., & Smith, J. (2005). A tutorial for competent memetic algorithms: model,
taxonomy, and design issues. IEEE Transactions on Evolutionary Computation, 9 (5),
474488.
Larrosa, J., & Morancho, E. (2003). Solving still life with soft constraints and bucket
elimination. In Principles and Practice of Constraint Programming  CP2003, Vol.
2833 of Lecture Notes in Computer Science, pp. 466479, Berlin Heidelberg. Springer.
Larrosa, J., Morancho, E., & Niso, D. (2005). On the practical use of variable elimination
in constraint optimization problems: still life as a case study. Journal of Artificial
Intelligence Research, 23, 421440.
Larrosa, J., & Schiex, T. (2004). Solving weighted CSP by maintaining arc consistency.
Artificial Intelligence, 159 (1-2), 126.
Lawler, E., & Wood, D. (1966). Branch and bounds methods: A survey. Operations Research,
4 (4), 669719.
Lematre, M., Verfaillie, G., Bourreau, E., & Laburthe, F. (2001). Integrating algorithms
for weighted CSP in a constraint programming framework. In International Workshop
on Modelling and Solving Problems with Soft Constraints, Paphos, Cyprus.
Marinescu, R., & Dechter, R. (2007). Best-first and/or search for graphical models. In
Twenty-Second AAAI Conference on Artificial Intelligence, pp. 11711176, Vancouver, Canada. AAAI Press.
Moscato, P., & Cotta, C. (2003). A gentle introduction to memetic algorithms. In Handbook
of Metaheuristics, pp. 105144. Kluwer Academic Press, Boston, Massachusetts, USA.
554

fiSolving WCSPs with Memetic/Exact Hybrid Algorithms

Moscato, P., & Cotta, C. (2007). Memetic algorithms. In Gonzalez, T. (Ed.), Handbook
of Approximation Algorithms and Metaheuristics, chap. 27. Chapman & Hall/CRC
Press.
Nonobe, K., & Ibaraki, T. (2001). An improved tabu search method for the weighted
constraint satisfaction problem. INFOR, 39 (2), 131151.
Puchinger, J., & Raidl, G. (2005). Combining metaheuristics and exact algorithms in
combinatorial optimization: a survey and classification. In Mira, J., & Alvarez, J.
(Eds.), Artificial Intelligence and Knowledge Engineering Applications: a Bioinspired
Approach, Vol. 3562 of Lecture Notes in Computer Science, pp. 4153, Berlin Heidelberg. Springer.
Schiex, T., Fargier, H., & Verfaillie, G. (1995). Valued constraint satisfaction problems: hard
and easy problems. In 14th International Joint Conference on Artificial Intelligence,
pp. 631637, Montreal, Canada.
Smith, B. M. (2002). A dual graph translation of a problem in life. In Hentenryck, P. V.
(Ed.), Principles and Practice of Constraint Programming - CP2002, Vol. 2470 of
Lecture Notes in Computer Science, pp. 402414, Berlin Heidelberg. Springer.
Verfaillie, G., Lematre, M., & Schiex, T. (1996). Russian doll search for solving constraint
optimization problems. In Thirteenth National Conference on Artificial Intelligence
and Eighth Innovative Applications of Artificial Intelligence Conference, AAAI / IAAI
96, pp. 181187. AAAI Press / The MIT Press.
Wolpert, D., & Macready, W. (1997). No free lunch theorems for optimization. IEEE
Transactions on Evolutionary Computation, 1 (1), 6782.

555

fiJournal of Artificial Intelligence Research 35 (2009) 343-389

Submitted 08/08; published 06/09

Automated Reasoning in Modal and Description Logics via
SAT Encoding: the Case Study of Km /ALC-Satisfiability
Roberto Sebastiani

roberto.sebastiani@disi.unitn.it

Michele Vescovi

michele.vescovi@disi.unitn.it

DISI, Universita di Trento
Via Sommarive 14, I-38123, Povo, Trento, Italy

Abstract
In the last two decades, modal and description logics have been applied to numerous
areas of computer science, including knowledge representation, formal verification, database
theory, distributed computing and, more recently, semantic web and ontologies. For this
reason, the problem of automated reasoning in modal and description logics has been
thoroughly investigated. In particular, many approaches have been proposed for efficiently
handling the satisfiability of the core normal modal logic Km , and of its notational variant,
the description logic ALC. Although simple in structure, Km /ALC is computationally very
hard to reason on, its satisfiability being PSpace-complete.
In this paper we start exploring the idea of performing automated reasoning tasks in
modal and description logics by encoding them into SAT, so that to be handled by stateof-the-art SAT tools; as with most previous approaches, we begin our investigation from
the satisfiability in Km . We propose an efficient encoding, and we test it on an extensive
set of benchmarks, comparing the approach with the main state-of-the-art tools available.
Although the encoding is necessarily worst-case exponential, from our experiments we
notice that, in practice, this approach can handle most or all the problems which are at
the reach of the other approaches, with performances which are comparable with, or even
better than, those of the current state-of-the-art tools.

1. Motivations and Goals
In the last two decades, modal and description logics have provided an essential framework
for many applications in numerous areas of computer science, including artificial intelligence, formal verification, database theory, distributed computing and, more recently, semantic web and ontologies. For this reason, the problem of automated reasoning in modal
and description logics has been thoroughly investigated (e.g., Fitting, 1983; Ladner, 1977;
Baader & Hollunder, 1991; Halpern & Moses, 1992; Baader, Franconi, Hollunder, Nebel, &
Profitlich, 1994; Massacci, 2000). In particular, the research in modal and description logics
has followed two parallel routes until the seminal work of Schild (1991), which proved that
the core modal logic Km and the core description logic ALC are one a notational variant of
the other. Since then, analogous results have been produced for a bunch of other logics, so
that, nowadays the two research lines have mostly merged into one research flow.
Many approaches have been proposed for efficiently reasoning in modal and description
logics, starting from the problem of checking the satisfiability in the core normal modal
logic Km and in its notational variant, the description logic ALC (hereafter simply Km ).
We classify them as follows.
c
2009
AI Access Foundation. All rights reserved.

fiSebastiani & Vescovi

 The classic tableau-based approach (Fitting, 1983; Baader & Hollunder, 1991; Massacci, 2000) is based on the construction of propositional tableau branches, which are
recursively expanded on demand by generating successor nodes in a candidate Kripke
model. Kris (Baader & Hollunder, 1991; Baader et al., 1994), Crack (Franconi,
1998), LWB (Balsiger, Heuerding, & Schwendimann, 1998) were among the main
representative tools of this approach.
 The DPLL-based approach (Giunchiglia & Sebastiani, 1996, 2000) differs from the
previous one mostly in the fact that a Davis-Putnam-Logemann-Loveland (DPLL)
procedure, which treats the modal subformulas as propositions, is used instead of
the classic propositional tableaux procedure at each nesting level of the modal operators. KSAT (Giunchiglia & Sebastiani, 1996), ESAT (Giunchiglia, Giunchiglia,
& Tacchella, 2002) and *SAT (Tacchella, 1999), are the representative tools of this
approach.
These two approaches merged into the modern tableaux-based approach, which has been
extended to work with more expressive description logics and to provide more sophisticate
reasoning functions. Among the tools employing this approach, we recall FaCT/FaCT++
and DLP (Horrocks & Patel-Schneider, 1999), and Racer (Haarslev & Moeller, 2001). 1
 In the translational approach (Hustadt & Schmidt, 1999; Areces, Gennari, Heguiabehere,
& de Rijke, 2000) the modal formula is encoded into first-order logic (FOL), and the
encoded formula can be decided efficiently by a FOL theorem prover (Areces et al.,
2000). Mspass (Hustadt, Schmidt, & Weidenbach, 1999) is the most representative
tool of this approach.
 The CSP-based approach (Brand, Gennari, & de Rijke, 2003) differs from the tableauxbased and DPLL-based ones mostly in the fact that a CSP (Constraint Satisfaction
Problem) engine is used instead of tableaux/DPLL. KCSP is the only representative
tool of this approach.
 In the Inverse-method approach (Voronkov, 1999, 2001), a search procedure is based
on the inverted version of a sequent calculus (which can be seen as a modalized
version of propositional resolution). KK (Voronkov, 1999) is the only representative
tool of this approach.
 In the Automata-theoretic approach, (a symbolic representation based on BDDs 
Binary Decision Diagrams  of) a tree automaton accepting all the tree models of the
input formula is implicitly built and checked for emptiness (Pan, Sattler, & Vardi,
2002; Pan & Vardi, 2003). KBDD (Pan & Vardi, 2003) is the only representative tool
of this approach.
1. Notice that there is not an universal agreement on the terminology tableaux-based and DPLL-based.
E.g., tools like FaCT, DLP, and Racer are most often called tableau-based, although they use
a DPLL-like algorithm instead of propositional tableaux for handling the propositional component of
reasoning (Horrocks, 1998; Patel-Schneider, 1998; Horrocks & Patel-Schneider, 1999; Haarslev & Moeller,
2001).

344

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

 Pan and Vardi (2003) presented also an encoding of K-satisfiability into QBF-satisfiability
(which is PSpace-complete too), combined with the use of a state-of-the-art QBF
(Quantified Boolean Formula) solver. We call this approach QBF-encoding approach.
To the best of our knowledge, the last four approaches so far are restricted to the satisfiability
in Km only, whilst the translational approach has been applied to numerous modal and
description logics (e.g. traditional modal logics like Tm and S4m , and dynamic modal
logics) and to the relational calculus.
A significant amount of benchmarks formulas have been produced for testing the effectiveness of the different techniques (Halpern & Moses, 1992; Giunchiglia, Roveri, & Sebastiani, 1996; Heuerding & Schwendimann, 1996; Horrocks, Patel-Schneider, & Sebastiani,
2000; Massacci, 1999; Patel-Schneider & Sebastiani, 2001, 2003).
In the last two decades we have also witnessed an impressive advance in the efficiency
of propositional satisfiability techniques (SAT), which has brought large and previouslyintractable problems at the reach of state-of-the-art SAT solvers. Most of the success of SAT
technologies is motivated by the impressive efficiency reached by current implementations
of the DPLL procedure, (Davis & Putnam, 1960; Davis, Longemann, & Loveland, 1962),
in its most-modern variants (Silva & Sakallah, 1996; Moskewicz, Madigan, Zhao, Zhang, &
Malik, 2001; Een & Sorensson, 2004). Current implementations can handle formulas in the
order of 107 variables and clauses.
As a consequence, many hard real-world problems have been successfully solved by
encoding into SAT (including, e.g., circuit verification and synthesis, scheduling, planning,
model checking, automatic test pattern generation , cryptanalysis, gene mapping). Effective
encodings into SAT have been proposed also for the satisfiability problems in quantifier-free
FOL theories which are of interest for formal verification (Strichman, Seshia, & Bryant,
2002; Seshia, Lahiri, & Bryant, 2003; Strichman, 2002). Notably, successful SAT encodings
include also PSpace-complete problems, like planning (Kautz, McAllester, & Selman, 1996)
and model checking (Biere, Cimatti, Clarke, & Zhu, 1999).
In this paper we start exploring the idea of performing automated reasoning tasks in
modal and description logics by encoding them into SAT, so that to be handled by state-ofthe-art SAT tools; as with most previous approaches, we begin our investigation from the
satisfiability in Km .
In theory, the task may look hopeless because of worst-case complexity issues: in fact,
with few exceptions, the satisfiability problem in most modal and description logics is not in
NP, typically being PSpace-complete or even harder PSpace-complete for Km (Ladner,
1977; Halpern & Moses, 1992) so that the encoding is in worst-case non polynomial. 2
In practice, however, a few considerations allow for not discarding that this approach
may be competitive with the state-of-the-art approaches. First, the non-polynomial bounds
above are worst-case bounds, and formulas may have different behaviors from that of the
pathological formulas which can be found in textbooks. (E.g., notice that the exponentiality
is based on the hypothesis of unboundedness of some parameter like the modal depth;
Halpern & Moses, 1992; Halpern, 1995.) Second, some tricks in the encoding may allow
for reducing the size of the encoded formula significantly. Third, as the amount of RAM
2. We implicitly make the assumption NP 6= PSpace.

345

fiSebastiani & Vescovi

memory in current computers is in the order of the GBytes and current SAT solvers can
successfully handle huge formulas, the encoding of many modal formulas (at least of those
which are not too hard to solve also for the competitors) may be at the reach of a SAT solver.
Finally, even for PSpace-complete logics like Km , also other state-of-the-art approaches are
not guaranteed to use polynomial memory.
In this paper we show that, at least for the satisfiability Km , by exploiting some smart
optimizations in the encoding the SAT-encoding approach becomes competitive in practice
with previous approaches. To this extent, the contributions of this paper are manyfold.
 We propose a basic encoding of Km formulas into purely-propositional ones, and prove
that the encoding is satisfiability-preserving.
 We describe some optimizations of the encoding, both in form of preprocessing and
of on-the-fly simplification. These techniques allow for significant (and in some cases
dramatic) reductions in the size of the resulting Boolean formulas, and in performances
of the SAT solver thereafter.
 We perform a very extensive empirical comparison against the main state-of-the-art
tools available. We show that, despite the NP-vs.-PSpace issue, this approach can
handle most or all the problems which are at the reach of the other approaches, with
performances which are comparable with, and sometimes even better than, those
of the current state-of-the-art tools. In our perspective, this is the most surprising
contribution of the paper.
 As a byproduct of our work, we obtain an empirical evaluation of current tools for Km satisfiability available, which is very extensive in terms of both amount and variety of
benchmarks and of number and representativeness of the tools evaluated. We are not
aware of any other such evaluation in the recent literature.
We also stress the fact that with our approach the encoder can be interfaced with every
SAT solver in a plug-and-play manner, so that to benefit for free of every improvement in
the technology of SAT solvers which has been or will be made available.
Content. The paper is structured as follows. In Section 2 we provide the necessary
background notions on modal logics and SAT. In Section 3 we describe the basic encoding
from Km to SAT. In Section 4 we describe and discuss the main optimizations, and provide
many examples. In Section 5 we present the empirical evaluation, and discuss the results.
In Section 6 we present some related work and current research trends. In Section 7 we
conclude, and describe some possible future evolutions.
A six-page preliminary version of this paper, containing some of the basic ideas presented
here, was presented at SAT06 conference (Sebastiani & Vescovi, 2006). For the readers
convenience, an online appendix is provided, containing all plots of Section 5 in full size.
Moreover, in order to make the results reproducible, the encoder, the benchmarks and the
random generators with the seeds used are also available in the online appendix.
346

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

2. Background
In this section we provide the necessary background on the modal logic Km (Section 2.1)
and on SAT and the DPLL procedure (Section 2.2).
2.1 The Modal Logic Km
We recall some basic definitions and properties of Km . Given a non-empty set of primitive
propositions A = {A1 , A2 , . . .}, a set of m modal operators B = {21 , . . . , 2m }, and the constants True and False (that we denote respectively with > and ) the language of
Km is the least set of formulas containing A, closed under the set of propositional connectives {, , , , } and the set of modal operators in B  {31 , . . . , 3m }. Notationally, we
use the Greek letters , , , , ,  to denote formulas in the language of Km (Km -formulas
hereafter). Notice that we can consider {, } together with B as the group of the primitive connectives/operators, defining the remaining in the standard way, that is: 3r 
for 2r , 1  2  for (1  2 ), 1  2  for (1  2 ), 1  2 
for (1  2 )  (2  1 ). (Hereafter formulas like  are implicitly assumed to
be simplified V
into , so
.) Notationally,
we
V
W we mean V
W by 
W that, if  is , then
often write ( i li )  jVlj Wfor the clause  j li  j lj , and ( i li )  ( j lj ) for the
conjunction of clauses  j ( i li  lj ). Further, we often write 2r or 3r meaning one
specific/generic modal operator, where it is assumed that r = 1, . . . , m; and we denote by
i
2ir the nested application of the 2r operator i times: 20r  :=  and 2i+1
r  := 2r 2r . We
call depth of , written depth(), the maximum number of nested modal operators in .
We call a propositional atom every primitive proposition in A, and a propositional literal
every propositional atom (positive literal) or its negation (negative literal). We call a modal
atom every formula which is either in the form 2r  or in the form 3r .
In order to make our presentation more uniform, and to avoid considering the polarity
of subformulas, we adopt the traditional representation of Km -formulas (introduced, as far
as we know, by Fitting, 1983 and widely used in literature, e.g. Fitting, 1983; Massacci,
2000; Donini & Massacci, 2000) from the following table:

(1  2 )
(1  2 )
(1  2 )

1
1
1
1

2
2
2
2


(1  2 )
(1  2 )
(1  2 )

1
1
1
1

2
2
2
2

r
3r 1
2r 1

0r
1
1

r
2r 1
3r 1

0r
1
1

in which non-literal Km -formulas are grouped into four categories: s (conjunctive), s
(disjunctive), s (existential), s (universal). Importantly, all such formulas occur in the
main formula with positive polarity only. This allows for disregarding the issue of polarity
of subformulas.
The semantic of modal logics is given by means of Kripke structures. A Kripke structure
for Km is a tuple M = hU, L, R1 , . . . , Rm i, where U is a set of states, L is a function
L : A  U 7 {T rue, F alse}, and each Rr is a binary relation on the states of U. With an
abuse of notation we write u  M instead of u  U. We call a situation any pair M, u,
M being a Kripke structure and u  M. The binary relation |= between a modal formula
347

fiSebastiani & Vescovi

 and a situation M, u is defined as follows:
M, u |= >;
M, u 6|= ;
M, u |= Ai , Ai  A
M, u |= Ai , Ai  A
M, u |= 
M, u |= 
M, u |=  r
M, u |=  r








L(Ai , u) = T rue;
L(Ai , u) = F alse;
M, u |= 1 and M, u |= 2 ;
M, u |= 1 or M, u |= 2 ;
M, w |= 0r for some w  U s.t. Rr (u, w) holds in M;
M, w |= 0r for every w  U s.t. Rr (u, w) holds in M.

M, u |=  should be read as M, u satisfy  in Km  (alternatively, M, u Km -satisfies
). We say that a Km -formula  is satisfiable in Km (Km -satisfiable henceforth) if and only
if there exist M and u  M s.t. M, u |= . (When this causes no ambiguity, we sometimes
drop the prefix Km -.) We say that w is a successor of u through Rr iff Rr (u, w) holds in
M.
The problem of determining the Km -satisfiability of a Km -formula  is decidable and
PSPACE-complete (Ladner, 1977; Halpern & Moses, 1992), even restricting the language to
a single Boolean atom (i.e., A = {A1 }; Halpern, 1995); if we impose a bound on the modal
depth of the Km -formulas, the problem reduces to NP-complete (Halpern, 1995). For a
more detailed description on Km  including, e.g., axiomatic characterization, decidability
and complexity results  we refer the reader to the works of Halpern and Moses (1992),
and Halpern (1995).
A Km -formula is said to be in Negative Normal Form (NNF) if it is written in terms of
the symbols 2r , 3r , ,  and propositional literals Ai , Ai (i.e., if all negations occur only
before propositional atoms in A). Every Km -formula  can be converted into an equivalent
one NNF () by recursively applying the rewriting rules: 2r =3r , 3r =2r ,
(1  2 )=(1  2 ), (1  2 )=(1  2 ), =.
A Km -formula is said to be in Box Normal Form (BNF) (Pan et al., 2002; Pan & Vardi,
2003) if it is written in terms of the symbols 2r , 2r , , , and propositional literals Ai ,
Ai (i.e., if no diamonds are there, and all negations occur only before boxes or before
propositional atoms in A). Every Km -formula  can be converted into an equivalent one
BNF () by recursively applying the rewriting rules: 3r =2r , (1  2 )=(1 
2 ), (1  2 )=(1  2 ), =.
2.2 Propositional Satisfiability with the DPLL Algorithm
Most state-of-the-art SAT procedures are evolutions of the DPLL procedure (Davis &
Putnam, 1960; Davis et al., 1962). A high-level schema of a modern DPLL engine, adapted
from the one presented by Zhang and Malik (2002), is reported in Figure 1. The Boolean
formula  is in CNF (Conjunctive Normal Form); the assignment  is initially empty, and
it is updated in a stack-based manner.
In the main loop, decide next branch(, ) chooses an unassigned literal l from 
according to some heuristic criterion, and adds it to . (This operation is called decision,
l is called decision literal and the number of decision literals in  after this operation is
called the decision level of l.) In the inner loop, deduce(, ) iteratively deduces literals l
348

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

SatValue DPLL (formula , assignment ) {
while (1) {
decide next branch(, );
while (1) {
status = deduce(, );
if (status == sat)
return sat;
else if (status == conflict) {
blevel = analyze conflict(, );
if (blevel == 0) return unsat;
else backtrack(blevel,, );
}
else break;
}}}

Figure 1: Schema of a modern SAT solver engine based on DPLL.
deriving from the current assignment and updates  and  accordingly; this step is repeated
until either  satisfies , or  falsifies , or no more literals can be deduced, returning sat,
conflict and unknown respectively. (The iterative application of Boolean deduction steps in
deduce is also called Boolean Constraint Propagation, BCP.) In the first case, DPLL returns
sat. If the second case, analyze conflict(, ) detects the subset  of  which caused
the conflict (conflict set) and the decision level blevel to backtrack. If blevel == 0,
then a conflict exists even without branching, so that DPLL returns unsat. Otherwise,
backtrack(blevel, , ) adds the clause  to  (learning) and backtracks up to blevel
(backjumping), updating  and  accordingly. In the third case, DPLL exits the inner loop,
looking for the next decision.
Notably, modern DPLL implementations implement techniques, like the two-watchedliteral scheme, which allow for extremely efficient handling of BCP (Moskewicz et al., 2001;
Zhang & Malik, 2002). Old versions of DPLL used to implement also the Pure-Literal Rule
(PLR) (Davis et al., 1962): when one proposition occurs only positively (resp. negatively) in
the formula, it can be safely assigned to true (resp. false). Modern DPLL implementations,
however, often do not implement it anymore due to its computational cost. For a much
deeper description of modern DPLL-based SAT solvers, we refer the reader to the literature
(e.g., Zhang & Malik, 2002).

3. The Basic Encoding
We borrow some notation from the Single Step Tableau (SST) framework (Massacci, 2000;
Donini & Massacci, 2000). We represent uniquely states in M as labels , represented as
non empty sequences of integers 1.nr11 .nr22 . ... .nrkk , s.t. the label 1 represents the root state,
and .nr represents the n-th Rr -successor of  (where r  {1, . . . , m}). With a little abuse
of notation, hereafter we may say a state  meaning a state labeled by . We call a
labeled formula a pair h, i, such that  is a state label and  is a Km -formula, and we
349

fiSebastiani & Vescovi

call labeled subformulas of a labeled formula h, i all the labeled formulas h, i such that
 is a subformula of .
Let Ah , i be an injective function which maps a labeled formula h, i, s.t.  is not
in the form , into a Boolean variable Ah, i . We conventionally assume that Ah, >i is
> and Ah, i is . Let Lh, i denote Ah, i if  is in the form , Ah, i otherwise.
Given a Km -formula , the encoder Km 2SAT builds a Boolean CNF formula as follows: 3
def

Km 2SAT () = Ah1,

i

(1)

 Def (1, )

def

(2)

def

(3)

def

(4)

def

(5)

Def (, >) = >
Def (, ) = >
Def (, Ai ) = >
Def (, Ai ) = >
def

Def (, ) = (Lh,

i

 (Lh,

1 i

 Lh,

2 i ))

 Def (, 1 )  Def (, 2 )

(6)

i

 (Lh,

1 i

 Lh,

2 i ))

 Def (, 1 )  Def (, 2 )

(7)

def

Def (, ) = (Lh,
r,j

0r,j )

def

Def (,  ) = (Lh, r,j i  Lh.j, r,j i )  Def (.j,
0
^ 
def
r
Def (,  ) =
((Lh,  r i  Lh, r,i i )  Lh.i,


r
r
)

Def
(.i,

)
.
0 i
0

(8)
(9)

for every
h, r,i i

Here by  r,j  we mean that  r,j is the j-th distinct  r formula labeled by . Notice
Nn that
(6) and (7) generalize to the case of n-ary  and  in the obvious way: if  is
i=1 i
V
N
N
def
s.t.
 {, }, then Def (, ) = (Lh, i  ni=1 Lh, i i )  ni=1 Def (, i ). Although
conceptually
trivial, this fact has an important practical consequence: in order to encode
Nn

one
needs
adding only one Boolean variable rather than up to n1, see Section 4.2.
i=1 i
Notice also that in rule (9) the literals of the type Lh, r,i i are strictly necessary; in fact, the
SAT problem must consider and encode all the possibly occuring states, but it can be the
case, e.g., that a  r,i formula occurring in a disjunction is assigned to false for a particular
state label  (which, in SAT, corresponds to assign Lh, r,i i to false). In this situation all
the labeled formulas regarding the state label .i are useless, in particular those generated
by the expansion of the  formulas interacting with  r,i . 4
We assume that the Km -formulas are represented as DAGs (Direct Acyclic Graphs),
so that to avoid the expansion of the same Def (, ) more than once. Then the various
Def (, ) are expanded in a breadth-first manner wrt. the tree of labels, that is, all
the possible expansions for the same (newly introduced)  are completed before starting
the expansions for a different state label  0 , and different state label are expanded in the
order they are introduced (thus all the expansions for a given state are always handled
before those of any deeper state). Moreover, following what done by Massacci (2000), we
assume that, for each , the Def (, )s are expanded in the order: /, , . Thus, each
Def (,  r ) is expanded after the expansion of all Def (,  r,i )s, so that Def (,  r ) will
3. We say that the formula is in CNF because we represent clauses as implications, according to the notation
described at the beginning of Section 2.
4. Indeed, (9) is a finite conjunction. In fact the number of -subformulas is obviously finite and Km
benefits of the finite-tree-model property (see, e.g., Pan et al., 2002; Pan & Vardi, 2003).

350

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

generate one clause ((Lh,  r i  Lh, r,i i )  Lh.i, 0r i ) and one novel definition Def (.i, 0r )
for each Def (,  r,i ) expanded. 5
Intuitively, it is easy to see that Km 2SAT () mimics the construction of an SST tableau
expansion (Massacci, 2000; Donini & Massacci, 2000). We have the following fact.
Theorem 1. A Km -formula  is Km -satisfiable if and only if the corresponding Boolean
formula Km 2SAT () is satisfiable.
The complete proof of Theorem 1 can be found in Appendix A.
Notice that, due to (9), the number of variables and clauses in Km 2SAT () may grow
exponentially with depth(). This is in accordance to what was stated by Halpern and
Moses (1992).
Example 3.1 (NNF). Let nnf be (3A1  3(A2  A3 ))  2A1  2A2  2A3 . 6 It
is easy to see that nnf is K1 -unsatisfiable: the 3-atoms impose that at least one atom Ai
is true in at least one successor of the root state, whilst the 2-atoms impose that all atoms
Ai are false in all successor states of the root state. Km 2SAT (nnf ) is: 7
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.













(
(
(
(
(
(
(
(
(
(
(

Ah1, nnf i
Ah1, nnf i  (Ah1, 3A1 3(A2 A3 )i  Ah1, 2A1 i  Ah1,
Ah1, 3A1 3(A2 A3 )i  (Ah1, 3A1 i  Ah1, 3(A2 A3 )i ) )
Ah1, 3A1 i  Ah1.1, A1 i )
Ah1, 3(A2 A3 )i  Ah1.2, A2 A3 i )
(Ah1, 2A1 i  Ah1, 3A1 i )  Ah1.1, A1 i )
(Ah1, 2A2 i  Ah1, 3A1 i )  Ah1.1, A2 i )
(Ah1, 2A3 i  Ah1, 3A1 i )  Ah1.1, A3 i )
(Ah1, 2A1 i  Ah1, 3(A2 A3 )i )  Ah1.2, A1 i )
(Ah1, 2A2 i  Ah1, 3(A2 A3 )i )  Ah1.2, A2 i )
(Ah1, 2A3 i  Ah1, 3(A2 A3 )i )  Ah1.2, A3 i )
Ah1.2, A2 A3 i  (Ah1.2, A2 i  Ah1.2, A3 i ) )

(1)
2A2 i  Ah1,

2A3 i ) )

(6)
(7)
(8)
(8)
(9)
(9)
(9)
(9)
(9)
(9)
(7)

After a run of Boolean constraint propagation (BCP), 3. reduces to the implicate disjunction. If the first element Ah1, 3A1 i is assigned to true, then by BCP we have a conflict on 4.
and 6. If it is set to false, then the second element Ah1, 3(A2 A3 )i is assigned to true, and
by BCP we have a conflict on 12. Thus Km 2SAT (nnf ) is unsatisfiable.
3

4. Optimizations
The basic encoding of Section 3 is rather naive, and can be much improved to many extents,
in order to reduce the size of the output propositional formula, or to make it easier to solve
by DPLL, or both. We distinguish two main kinds of optimizations:
5. In practice, even if the definition of Km 2SAT is recursive, the Def expansions are performed grouped by
states. More precisely, all the Def (.n, ) expansions, for any formula  and every defined n, are done
together (in the /, ,  order above exposed) and necessarily after that all the Def (, ) expansions
have been completed.
6. For K1 -formulas we omit the box and diamond indexes, i.e., we write 2, 3 for 21 , 31 .
7. In all examples we report at the very end of each line, i.e. after each clause, the number of the Km 2SAT
encoding rule applied to generate that clause. We also drop the application of the rules (2), (3), (4)
and (5).

351

fiSebastiani & Vescovi

Preprocessing steps, which are applied on the input modal formula before the encoding.
Among them, we have Pre-conversion into BNF (Section 4.1), Atom Normalization
(Section 4.2), Box Lifting (Section 4.3), and Controlled Box Lifting (Section 4.4).
On-the-fly simplification steps, which are applied to the Boolean formula under construction. Among them, we have On-the-fly Boolean Simplification and Truth Propagation Through Boolean Operators (Section 4.5) and Truth Propagation Through
Modal Operators (Section 4.6), On-the-fly Pure-Literal Reduction (Section 4.7), and
On-the-fly Boolean Constraint Propagation (Section 4.8).
We analyze these techniques in detail.
4.1 Pre-conversion into BNF
Many systems use to pre-convert the input Km -formulas into NNF (e.g., Baader et al.,
1994; Massacci, 2000). In our approach, instead, we pre-convert them into BNF (like, e.g.,
Giunchiglia & Sebastiani, 1996; Pan et al., 2002). For our approach, the advantage of the
latter representation is that, when one 2r  occurs both positively and negatively (like, e.g.,
in (2r   ...)  (2r   ...)  ...), then both occurrences of 2r  are labeled by the same
Boolean atom Ah, 2r i , and hence they are always assigned the same truth value by DPLL.
With NNF, instead, the negative occurrence 2r  is rewritten into 3r (nnf ()), so that
two distinct Boolean atoms Ah, 2r (nnf ())i and Ah, 3r (nnf ())i are generated; DPLL can
assign them the same truth value, creating a hidden conflict which may require some extra
Boolean search to reveal. 8
Example 4.1 (BNF). We consider the BNF variant of the nnf formula of Example 3.1,
bnf = (2A1  2(A2  A3 ))  2A1  2A2  2A3 . As before, it is easy to
see that bnf is K1 -unsatisfiable. Km 2SAT (bnf ) is: 9
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.













(
(
(
(
(
(
(
(
(
(
(

Ah1, bnf i
Ah1, bnf i  (Ah1, (2A1 2(A2 A3 ))i  Ah1, 2A1 i  Ah1, 2A2 i  Ah1,
Ah1, (2A1 2(A2 A3 ))i  (Ah1, 2A1 i  Ah1, 2(A2 A3 )i ) )
Ah1, 2A1 i  Ah1.1, A1 i )
Ah1, 2(A2 A3 )i  Ah1.2, (A2 A3 )i )
(Ah1, 2A1 i  Ah1, 2A1 i )  Ah1.1, A1 i )
(Ah1, 2A2 i  Ah1, 2A1 i )  Ah1.1, A2 i )
(Ah1, 2A3 i  Ah1, 2A1 i )  Ah1.1, A3 i )
(Ah1, 2A1 i  Ah1, 2(A2 A3 )i )  Ah1.2, A1 i )
(Ah1, 2A2 i  Ah1, 2(A2 A3 )i )  Ah1.2, A2 i )
(Ah1, 2A3 i  Ah1, 2(A2 A3 )i )  Ah1.2, A3 i )
Ah1.2, (A2 A3 )i  (Ah1.2, A2 i  Ah1.2, A3 i ) )

(1)
2A3 i )) (6)
(7)
(8)
(8)
(9)
(9)
(9)
(9)
(9)
(9)
(7)

Unlike with the NNF formula nnf in Example 3.1, Km 2SAT (bnf ) is found unsatisfiable
directly by BCP. In fact, the unit-propagation of Ah1, 2A1 i from 2. causes Ah1, 2A1 i in
8. Notice that this consideration holds for every representation involving both boxes and diamonds; we
refer to NNF simply because it is the most popular of these representations.
9. Notice that the valid clause 6. can be dropped. See the explanation in Section 4.5.

352

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

3. to be false, so that one of the two (unsatisfiable) branches induced by the disjunction
is cut a priori. With nnf , Km 2SAT does not recognize 2A1 and 3A1 to be one the
negation of the other, so that two distinct atoms Ah1, 2A1 i and Ah1, 3A1 i are generated.
Hence Ah1, 2A1 i and Ah1, 3A1 i cannot be recognized by DPLL to be one the negation of
the other, s.t. DPLL may need exploring one Boolean branch more.
3
In the following we will assume the formulas are in BNF (although most of the optimizations which follow work also for other representations).
4.2 Normalization of Modal Atoms
One potential source of inefficiency for DPLL-based procedures is the occurrence in the
input formula of semantically-equivalent though syntactically-different modal atoms  0 and
 00 (e.g., 21 (A1  A2 ) and 21 (A2  A1 )), which are not recognized as such by Km 2SAT .
This causes the introduction of duplicated Boolean atoms Ah, 0 i and Ah, 00 i and much
worse of duplicated subformulas Def (,  0 ) and Def (,  00 ). This fact can have very
negative consequences, in particular when  0 and  00 occur with negative polarity, because
this causes the creation of distinct versions of the same successor states, and the duplication
of whole parts of the output formula.
Example 4.2. Consider the Km -formula (1  21 (A2  A1 ))  (2  21 (A1  A2 ))  3 ,
s.t. 1 , 2 , 3 are possibly-big Km -formulas. Then Km 2SAT creates two distinct atoms
Ah1, 21 (A2 A1 )i and Ah1, 21 (A1 A2 )i and two distinct formulas Def (1, 21 (A2  A1 )) and
Def (1, 21 (A1  A2 )). The latter will cause the creation of two distinct states 1.1 and 1.2.
Thus, the recursive expansion of all 21 -formulas occurring positively in 1 , 2 , 3 will be
duplicated for these two states.
3
In order to cope with this problem, as done by Giunchiglia and Sebastiani (1996), we
apply some normalization steps to modal atoms with the intent of rewriting as many as
possible syntactically-different but semantically-equivalent modal atoms into syntacticallyidentical ones. This can be achieved by a recursive application of some simple validitypreserving rewriting rules.
Sorting: modal atoms are internally sorted according to some criterion, so that atoms
which are identical modulo reordering are rewritten into the same atom (e.g., 2i (2 
1 ) and 2i (1  2 ) are both rewritten into 2i (1  2 )).
Flattening: the associativity of  and  is exploited and combinations of s or s are
flattened into n-ary s or s respectively (e.g., 2i (1  (2  3 )) and 2i ((1 
2 )  3 ) are both rewritten into 2i (1  2  3 )).
Flattening has also the advantage of reducing the number of novel atoms introduced in the
encoding, as a consequence of the fact noticed in Section 3. One possible drawback of this
technique is that it can reduce the sharing of subformulas (e.g., with 2i ((1  2 )  3 )
and 2i ((1  2 )  4 ), the common part is no more shared). However, we have empirically
experienced that this drawback is negligible wrt. the advantages of flattening.
353

fiSebastiani & Vescovi

4.3 Box Lifting
As second preprocessing the Km -formula can also be rewritten by recursively applying the
Km -validity-preserving box lifting rules:
(2r 1  2r 2 ) = 2r (1  2 ),

(2r 1  2r 2 ) = 2r (1  2 ).

(10)

This has the potential benefit of reducing the number of  r formulas, and hence the number
of labels .i to take into account in the expansion of the Def (,  r )s (9). We call lifting
this preprocessing.
Example 4.3 (Box lifting). If we apply the rules (10) to the formula of Example 4.1,
then we have bnf lift = 2(A1  A2  A3 )  2(A1  A2  A3 ). Consequently,
Km 2SAT (bnf lift ) is:
1.
2.
3.
4.
5.
6.







Ah1, bnf lift i
( Ah1, bnf lift i  (Ah1, 2(A1 A2 A3 )i  Ah1, 2(A1 A2 A3 )i ) )
( Ah1, 2(A1 A2 A3 )i  Ah1.1, (A1 A2 A3 )i )
(( Ah1, 2(A1 A2 A3 )i  Ah1, 2(A1 A2 A3 )i )  Ah1.1, (A1 A2 A3 )i )
( Ah1.1, (A1 A2 A3 )i  (Ah1.1, A1 i  Ah1.1, A2 i  Ah1.1, A3 i ) )
( Ah1.1, (A1 A2 A3 )i  (Ah1.1, A1 i  Ah1.1, A2 i  Ah1.1, A3 i ) ).

(1)
(6)
(8)
(9)
(7)
(6)

Km 2SAT (bnf lift ) is found unsatisfiable directly by BCP on clauses 1. and 2.. Only one
successor state (1.1) is considered. Notice that 3., 4., 5. and 6. are redundant, because 1.
and 2. alone are unsatisfiable. 10
3
4.4 Controlled Box Lifting
One potential drawback of applying the lifting rules is that, by collapsing the formula
(2r 1  2r 2 ) into 2r (1  2 ) and (2r 1  2r 2 ) into 2r (1  2 ), the possibility of
sharing box subformulas in the DAG representation of the input Km -formula is reduced.
In order to cope with this problem we provide an alternative policy for applying box
lifting, that is, to apply the rules (10) only when neither box subformula occurring in the
implicant in (10) has multiple occurrences. We call this policy controlled box lifting.
Example 4.4 (Controlled Box Lifting). We apply Controlled Box Lifting to the formula of
Example 4.1, then we have bnf clift = (2A1  2(A2  A3 ))  2A1  2(A2  A3 )
since the rules (10) are applied among all the box subformulas except for 2A1 , which is
10. In our actual implementation, trivial cases like bnf lift are found to be unsatisfiable directly during the
construction of the DAG representations, so their encoding is never generated.

354

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

shared. It follows that Km 2SAT (bnf clift ) is:
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.













(
(
(
(
(
(
(
(
(
(
(

Ah1, bnf clift i
Ah1, bnf clift i  (Ah1, (2A1 2(A2 A3 ))i  Ah1, 2A1 i  Ah1, 2(A2 A3 )i )
Ah1, (2A1 2(A2 A3 ))i  (Ah1, 2A1 i  Ah1, 2(A2 A3 )i ) )
Ah1, 2A1 i  Ah1.1, A1 i )
Ah1, 2(A2 A3 )i  Ah1.2, (A2 A3 )i )
(Ah1, 2A1 i  Ah1, 2A1 i )  Ah1.1, A1 i )
(Ah1, 2(A2 A3 )i  Ah1, 2A1 i )  Ah1.1, (A2 A3 )i )
(Ah1, 2A1 i  Ah1, 2(A2 A3 )i )  Ah1.2, A1 i )
(Ah1, 2(A2 A3 )i  Ah1, 2(A2 A3 )i )  Ah1.2, (A2 A3 )i )
Ah1.1, (A2 A3 )i  (Ah1.1, A2 i  Ah1.1, A3 i ) )
Ah1.2, (A2 A3 )i  (Ah1.2, A2 i  Ah1.2, A3 i ) )
Ah1.2, (A2 A3 )i  (Ah1.2, A2 i  Ah1.2, A3 i ) )

(1)
(6)
(7)
(8)
(8)
(9)
(9)
(9)
(9)
(6)
(7)
(6)

Km 2SAT (bnf clift ) is found unsatisfiable directly by BCP on clauses 1., 2. and 3.. Notice
that the unit propagation of Ah1, 2A1 i and Ah1, 2(A2 A3 )i from 2. causes the implicate
disjunction in 3. to be false.
3
4.5 On-the-fly Boolean Simplification and Truth Propagation
A first straightforward on-the-fly optimization is that of applying recursively the standard
rewriting rules for the Boolean simplification of the formula like, e.g.,
h, i  h, i
h, 1 i  h, (1  2 )i
h, i  h, i
...,

= h, i,
= h, 1 i,
= h, i,

h, i  h, i
h, 1 i  h, (1  2 )i
h, i  h, i

= h, i,
= h, 1 i,
= h, >i,

and for the propagation of truth/falsehood through Boolean operators like, e.g.,
h, i
h, i  h, >i
h, i  h, >i
....

= h, >i,
= h, i,
= h, >i,

h, >i
h, i  h, i
h, i  h, i

= h, i,
= h, i,
= h, i,

Example 4.5. If we consider the Km -formula bnf lift = 2(A1  A2  A3 ) 
2(A1  A2  A3 ) of Example 4.3 and we apply the Boolean simplification rule h, i 
h, i = h, i, then h, bnf lift i is simplified into h, i.
3
One important subcase of on-the-fly Boolean simplification avoids the useless encoding
of incompatible  r and  r formulas. In BNF, in fact, the same subformula 2r  may occur
in the same state  both positively and negatively (like  r = 2r  and  r = 2r ). If
so, Km 2SAT labels both those occurrences of 2r  with the same Boolean atom Ah, 2r i ,
and produces recursively two distinct subsets of clauses in the encoding, by applying (8)
to 2r  and (9) to 2r  respectively. However, the latter step (9) generates a valid clause
(Ah, 2r i  Ah, 2r i )  Ah.i, i , so that we can avoid generating it. Consequently, if
355

fiSebastiani & Vescovi

Ah.i, i no more occurs in the formula, then Def (.i, ) should not be generated, as there
is no more need of defining h.i, i. 11
Example 4.6. If we apply this observation in the construction of the formulas of Examples
4.1 and 4.4, we have the following facts:
 In the formula Km 2SAT (bnf ) of Example 4.1, clause 6. is valid and thus it is dropped.
 In the formula Km 2SAT (bnf clift ) of Example 4.4, both valid clauses 6. and 9. are
dropped, so that 12. is not generated.
3
Hereafter we assume that on-the-fly Boolean simplification is applied also in combination
with the techniques described in the next sections.
4.6 On-the-fly Truth Propagation Through Modal Operators
Truth and falsehood which can derive by the application of the techniques in Section 4.5,
Section 4.7 and Section 4.8 may be propagated on-the-fly also though modal operators.
First, for every , both positive and negative instances of h, 2r >i can be safely simplified
by applying the rewriting rule h, 2r >i = h, >i.
Second, we notice the following fact. When we have a positive occurrence of h, 2r i
for some  (we suppose wlog. that we have only that  r -formula for ), 12 by definition of
(8) and (9) we have
Def (, 2r ) = (Lh,

2r i

Def (, 2r ) = ((Lh,

2r i

 Ah.j,
 Lh,

>i )

 Def (.j, >),

(11)

 Lh.j,

(12)

2r i )

i )

 Def (.j, )

for some new label .j and for every 2r  occurring positively in . Def (, 2r ) reduces
to > because both Ah.j, >i and Def (.j, >) reduce to >. If at least another distinct formula 2r  occurs positively in , however, there is no need for the .j label in (11) and
(12) to be a new label, and we can re-use instead the label .i introduced in the expansion
of Def (, 2r ), as follows:
Def (, 2r ) = (Lh,

2r i

 Lh.i,

i )

 Def (.i, ).

(13)

Thus (11) is dropped and, for every h, 2r i occurring positively, we write:
Def (, 2r ) = ((Lh,

2r i

 Lh,

2r i )

 Lh.i,

i )

 Def (.i, )

(14)

instead of (12). (Notice the label .i introduced in (13) rather than the label .j of (11).)
This is motivated by the fact that Def (, 2r ) forces the existence of at least one
successor of  but imposes no constraints on which formulas should hold there, so that
we can use some other already-defined successor state, if any. This fact has the important
benefit of eliminating useless successor states from the encoding.
11. Here the if is due to the fact that it may be the case that Ah.i, i is generated anyway from the
expansion of some other subformula, like, e.g., 2r (  ). If this is the case, Def (.i, ) must be
generated anyway.
12. E.g., 2r  may result from applying the steps of Section 4.1 and of Section 4.5 to 2r (2r A1  3r A1 ).

356

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

Example 4.7. Let  be the BNF K-formula:
(A1  2A2 )  (A1  2)  (A1  A3 )  (A1  A3 )  (A1  2A4 )  2A4 .
 is K-inconsistent, because the only possible assignment is {A1 , 2, 2A4 , 2A4 }, which
is K-inconsistent. Km 2SAT () is encoded as follows:
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.

Ah1, i
 (Ah1, i  (Ah1, (A1 2A2 )i  Ah1, (A1 2)i  Ah1,
Ah1, (A1 2A4 )i  Ah1, 2A4 i ))
 (Ah1, (A1 2A2 )i  (Ah1, A1 i  Ah1, 2A2 i ))
 (Ah1, (A1 2)i  (Ah1, A1 i  Ah1, 2i ))
 (Ah1, (A1 A3 )i  (Ah1, A1 i  Ah1, A3 i ))
 (Ah1, (A1 A3 )i  (Ah1, A1 i  Ah1, A3 i ))
 (Ah1, (A1 2A4 )i  (Ah1, A1 i  Ah1, 2A4 i ))
 (Ah1, 2A2 i  Ah1.1, A2 i )
 ((Ah1, 2A4 i  Ah1, 2A2 i )  Ah1.1, A4 i )
 ((Ah1, 2A4 i  Ah1, 2A2 i )  Ah1.1, A4 i )
 (Ah1, 2i  Ah1.1, i )

12.
13.

 ((Ah1,
 ((Ah1,

 Ah1, 2i )  Ah1.1, A4 i )
2A4 i  Ah1, 2i )  Ah1.1, A4 i )
2A4 i

(1)
(A1 A3 )i 
(6)
(7)
(7)
(7)
(7)
(7)
(8)
(9)
(9)
(8)
(9)
(9)

Clause 11. is then simplified into >. (In a practical implementation it is not even generated.)
Notice that in clauses 11., 12. and 13. it is used the label 1.1 of clauses 8., 9. and 10. rather
than a new label 1.2. Thus, only one successor label is generated.
When DPLL is run on Km 2SAT (), by BCP 1. and 2. are immediately satisfied and the
implicants are removed from 3., 4., 5., 6.. Thanks to 5. and 6., Ah1, A1 i can be assigned only
to false, which causes 3. to be satisfied and forces the assignment of the literals Ah1, 2i ,
Ah1, 2A4 i by BCP on 3. and 7. and hence of Ah1.1, i , Ah1.1, A4 i and Ah1.1, A4 i by BCP
on 12. and 13., causing a contradiction.
3
It is worth noticing that (14) is strictly necessary for the correctness of the encoding
even when another -formula occurs in . (E.g., in Example 4.7, without 12. and 13. the
formula Km 2SAT () would become satisfiable because Ah1, 2A2 i could be safely be assigned
to true by DPLL, which would satisfy 8., 9. and 10..)
Hereafter we assume that this technique is applied also in combination with the techniques described in Section 4.5 and in the next sections.
4.7 On-the-fly Pure-Literal Reduction
Another technique, evolved from that proposed by Pan and Vardi (2003), applies PureLiteral Reduction (PLR) on-the-fly during the construction of Km 2SAT (). When for a
label  all the clauses containing atoms in the form Ah, i have been generated, if some of
them occurs only positively [resp. negatively], then it can be safely assigned to true [resp.
to false], and hence the clauses containing Ah, i can be dropped. 13 As a consequence,
13. In our actual implementation this reduction is performed directly within an intermediate data structure,
so that these clauses are never generated.

357

fiSebastiani & Vescovi

some other atom Ah,
is reached.

0 i

can become pure, so that the process is repeated until a fixpoint

Example 4.8. Consider the formula bnf of Example 4.1. During the construction of
Km 2SAT (bnf ), after 1.-8. are generated, no more clause containing atoms in the form
Ah1.1, i is to be generated. Then we notice that Ah1.1, A2 i and Ah1.1, A3 i occur only negatively, so that they can be safely assigned to false. Therefore, 7. and 8. can be safely
dropped. Same discourse applies lately to Ah1.2, A1 i and 9.. The resulting formula is found
inconsistent by BCP. (In fact, notice from Example 4.1 that the atoms Ah1.1, A2 i , Ah1.1, A3 i ,
and Ah1.2, A1 i play no role in the unsatisfiability of Km 2SAT (bnf ).)
3
We remark the differences between PLR and the Pure-Literal Reduction technique proposed by Pan and Vardi (2003). In KBDD (Pan et al., 2002; Pan & Vardi, 2003), the
Pure-Literal Reduction is a preprocessing step which is applied to the input modal formula,
either at global level (i.e. looking for pure-polarity primitive propositions for the whole formula) or, more effectively, at different modal depths (i.e. looking for pure-polarity primitive
propositions for the subformulas at the same nesting level of modal operators).
Our technique is much more fine-grained, as PLR is applied on-the-fly with a single-state
granularity, obtaining a much stronger reduction effect.
Example 4.9. Consider again the BNF Km -formula bnf discussed in Examples 4.1 and
4.8: bnf = (2A1  2(A2  A3 ))  2A1  2A2  2A3 . It is immediate to see
that all primitive propositions A1 , A2 , A3 occur at every modal depth with both polarities,
so that the technique of Pan and Vardi (2003) produces no effect on this formula.
3
4.8 On-the-fly Boolean Constraint Propagation
One major problem of the basic encoding of Section 3 is that it is purely-syntactic, that
is, it does not consider the possible truth values of the subformulas, and the effect of their
propagation through the Boolean and modal connectives. In particular, Km 2SAT applies
(8) [resp. (9)] to every -subformula [resp. -subformula], regardless the fact that the truth
values which can be deterministically assigned to the labeled subformulas of h1, i may
allow for dropping some labeled -/-subformulas, and thus prevent the need of encoding
them.
One solution to this problem is that of applying Boolean Constraint Propagation (BCP)
on-the-fly during the construction of Km 2SAT (), starting from the fact that Ah1, i must
be true. If a contradiction is found, then Km 2SAT () is unsatisfiable, so that the formula is
not expanded any further, and the encoder returns the formula . 14 When BCP allows
for dropping one implication in (6)-(9) without assigning some of its implicate literals,
namely Lh, i i , then h, i i needs not to be defined, so that Def (, i ) must not be
expanded. 15 Importantly, dropping Def (,  r,j ) for some -formula h,  r,j i prevents
generating the label .j (8) and all its successor labels .j. 0 (corresponding to the subtree
of states rooted in .j), so that all the corresponding labeled subformulas are not encoded.
14. For the sake of compatibility with standard SAT solvers, our actual implementation returns the formula
A1  A1 .
15. Here we make the same consideration as in Footnote 11: if Lh.j, i is generated also from the expansion
of some other subformula, (e.g., 2r (  )), then (another instance of) Def (.i, ) must be generated
anyway.

358

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

Example 4.10. Consider Example 4.1, and suppose we apply on-the-fly BCP. During the
construction of 1., 2. and 3. in Km 2SAT (bnf ), the atoms Ah1, bnf i , Ah1, (2A1 2(A2 A3 ))i ,
Ah1, 2A1 i , Ah1, 2A2 i and Ah1, 2A3 i are deterministically assigned to true by BCP. This
causes the removal from 3. of the first-implied disjunct Ah1, 2A1 i , so that there is no need
to generate Def (1, 2A1 ), and hence label 1.1. is not defined and 4. is not generated.
While building 5., Ah1.2, (A2 A3 )i , is unit-propagated. As label 1.1. is not defined, 6.,
7. and 8. are not generated. Then during the construction of 5., 9., 10., 11. and 12., by
applying BCP a contradiction is found, so that Km 2SAT () is .
An analogous situation happens with bnf lift in Example 4.3: while building 1. and 2.
a contradiction is found by BCP, s.t. Km 2SAT returns  without expanding the formula
any further. Same discourse holds for bnf clift in Example 4.4: while building 1., 2. and 3.
a contradiction is found by BCP, s.t. Km 2SAT returns  without expanding the formula
any further.
3
4.9 A Paradigmatic Example: Halpern & Moses Branching Formulas.
Among all optimizations described in this Section 4, on-the-fly BCP is by far the most
effective. In order to better understand this fact, we consider as a paradigmatic example
the branching formulas K
h by Halpern and Moses (1992, 1995) (also called k branch n
in the set of benchmark formulas proposed by Heuerding and Schwendimann, 1996) and
their unsatisfiable version (called k branch p in the above-mentioned benchmark suite).
Given a single modality 2, an integer parameter h, and the primitive propositions
16
D0 , . . . , Dh+1 , P1 , . . . , Ph , the formulas K
h are defined as follows:
K
h

def

= D0  D1 

h
^

2i (depth  determined  branching),

(15)

i=0
def

depth =

h+1
^

(Di  Di1 ),

i=1
h
^


( Pi  2(Di  Pi )) 
determined =
Di 
,
(Pi  2(Di  Pi ))
i=1

h1
^
3(Di+1  Di+2  Pi+1 ) 
def
branching =
(Di  Di+1 ) 
3(Di+1  Di+2  Pi+1 )
def



(16)



(17)

. (18)

i=0

A conjunction of the formulas depth, determined and branching is repeated at every
nesting level of modal operators (i.e. at every depth): depth captures the relation between
the Di s at every level; determined states that, if Pi is true [false] in a state at depth  i,
then it is true [false] in all the successor states of depth  i; branching states that, for every
node at depth i, it is possible to find two successor states at depth i + 1 such that Pi+1 is
true in one and false in the other. For each value of the parameter h, K
h is K-satisfiable,
and every Kripke model M that satisfies it has at least 2h+1  1 states. In fact, K
h is build
in such a way to force the construction of a binary-tree Kripke model of depth h + 1, each of
16. For the sake of better readability, here we adopt the description given by Halpern and Moses (1992)
without converting the formulas into BNF. This fact does not affect the discussion.

359

fiSebastiani & Vescovi

whose leaves encodes a distinct truth assignment to the primitive propositions P1 , . . . , Ph ,
whilst each Di is true in all and only the states occurring at a depth  i in the tree (and
thus denotes the level of nesting).
The unsatisfiable counterpart formulas proposed by Heuerding and Schwendimann (1996)
(whose negations are the valid formulas called k branch p in the previously-mentioned
benchmark suite, which are exposed in more details in Section 5.1.1) are obtained by conjoining to (15) the formula:
2h Pb h c+1
(19)
3

(where bxc is the integer part of x) which forces the atom Pb h c+1 to be true in all depth-h
3
states of the candidate Kripke model, which is incompatible with the fact that the remaining
specifications say that it has to be false in half depth-h states. 17
These formulas are very pathological for many approaches (Giunchiglia & Sebastiani,
2000; Giunchiglia, Giunchiglia, Sebastiani, & Tacchella, 2000; Horrocks et al., 2000). In particular, before introducing on-the-fly BCP, they used to be the pet hate of our Km 2SAT approach, as they caused the generation of huge Boolean formulas. In fact, due to branching
(18), K
h contains 2h 3-formulas (i.e., -formulas) at every depth. Therefore, the Km 2SAT
encoder of Section 3 has to consider 1 + 2h + (2h)2 + ... + (2h)h+1 = ((2h)h+2  1)/(2h  1)
distinct labels, which is about hh+1 times the number of those labeling the states which
are actually needed. (None of the optimizations of Sections 4.1-4.7 is of any help with
these formulas, because neither BNF encoding nor atom normalization causes any sharing
of subformulas, the formulas are already in lifted form, and no literal occurs pure. 18 )
This pathological behavior can be mostly overcome by applying on-the-fly-BCP, because
some truth values can be deterministically assigned to some subformulas of K
h by on-thefly-BCP, which prevent encoding some or even most 2/3-subformulas.
In fact, consider the branching and determined formulas occurring in K
h at a generic
depth d  {0...h}, which determine the states at level d in the tree. As in these states
D0 , ..., Dd are forced to be true and Dd+1 , ..., Dh+1 are forced to be false, then all but the
d-th conjunct in branching (all conjuncts if d = h) are forced to be true and thus they
could be dropped. Therefore, only 2 3-formulas per non-leaf level could be considered
instead, causing the generation of 2h+1  1 labels overall. Similarly, in all states at level d
the last h  d conjuncts in determined are forced to be true and could be dropped, reducing
significantly the number of 2-formulas to be considered.
It is easy to see that this is exactly what happens by applying on-the-fly-BCP. In fact,
suppose that the construction of Km 2SAT (K
h ) has reached depth d (that is, the point
where for every state  at level d, the Def (, )s and Def (, )s are expanded but no
Def (, ) and Def (, ) is expanded yet). Then, BCP deterministically assigns true to the
literals Lh, D0 i , ..., Lh, Dd i and false to Lh, Dd+1 i , ..., Lh, Dh+1 i , which removes all but one
conjuncts in branching, so that only two Def (, )s out of 2h ones are actually expanded;
similarly, the last h  d conjuncts in determined are removed, so that the corresponding
Def (, )s are not expanded.
17. Heuerding and Schwendimann do not explain the choice of the index b h3 c + 1. We understand that
also other choices would have done the job.
18. More precisely, only one literal, Dh+1 , occurs pure in branching, but assigning it plays no role in
simplifying the formula.

360

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

1e+08

1e+07

1e+08

BNF-lift-plr
BNF-nolift-plr

1e+07

1000

BNF-lift-plr
BNF-nolift-plr
100

1e+06

1e+06

BNF-lift
BNF-nolift
BNF-lift-bcp
BNF-nolift-bcp
BNF-lift-plr-bcp
BNF-nolift-plr-bcp

100000

10000

BNF-lift
BNF-nolift
BNF-lift-bcp
BNF-nolift-bcp
BNF-lift-plr-bcp
BNF-nolift-plr-bcp

100000

10000

1000

1000

100

100

10

10

10

BNF-lift
BNF-nolift
BNF-lift-plr
BNF-nolift-plr

1

0.1

1

1
5

10

15

20

(a) k branch n, var#

0.01
5

10

15

20

5

(b) k branch n, clause#

1e+08

1e+07

BNF-lift-bcp
BNF-nolift-bcp
BNF-lift-plr-bcp
BNF-nolift-plr-bcp

1e+07

15

20

(c) k branch n, cpu time

1e+08

BNF-lift-plr
BNF-nolift-plr

10

1000

BNF-lift-plr
BNF-nolift-plr
100

1e+06

1e+06

BNF-lift
BNF-nolift

100000

BNF-lift
BNF-nolift

100000
10

10000

10000

1000

1000

100

100

BNF-lift
BNF-nolift
BNF-lift-plr
BNF-nolift-plr

1

0.1
BNF-lift-bcp
BNF-nolift-bcp
BNF-lift-plr-bcp
BNF-nolift-plr-bcp

10

1

BNF-lift-bcp
BNF-nolift-bcp
BNF-lift-plr-bcp
BNF-nolift-plr-bcp

BNF-lift-bcp
BNF-nolift-bcp
BNF-lift-plr-bcp
BNF-nolift-plr-bcp

10

1
5

10

15

(d) k branch p, var#

20

0.01
5

10

15

(e) k branch p, clause#

20

5

10

15

20

(f) k branch p, cpu time

Figure 2: Empirical analysis of Km 2SAT on Halpern & Moses formulas wrt. the depth
parameter h, for different options of the encoder. 1st row: k branch n, corresponding to Km 2SAT (K
h ), formulas (satisfiable); 2nd row: k branch p, correh
sponding to Km 2SAT (K
h  2 Pb h
c+1 ), formulas (unsatisfiable). Left: number
3
of Boolean variables; center: number of clauses; right: total CPU time requested
to encoding+solving (where the solving step has been performed through Rsat).
See Section 5 for more technical details.

361

fiSebastiani & Vescovi

h
As far as the unsatisfiable version Km 2SAT (K
h  2 Pb h
c+1 ) is concerned, when the
3
expansion reaches depth h, thanks to (19), Lh, P h i is generated and deterministically
b 3 c+1

assigned to true by BCP for every depth-h label ; thanks to determined and branching,
BCP assigns all literals Lh, P1 i , ..., Lh, Ph i deterministically, so that Lh, P h i is assigned
b 3 c+1

to false for 50% of the depth-h labels . This causes a contradiction, so that the encoder
stops the expansion and returns .
Figure 2 shows the growth in size and the CPU time required to encode and solve
K
h
Km 2SAT (K
h ) (1st row) and Km 2SAT (h  2 Pb h
c+1 ) (2nd row) wrt. the parameter h,
3
for eight combinations of the following options of the encoder: with and without box-lifting,
with and without on-the-fly PLR, with and without on-the-fly BCP. (Notice the log scale
of the y axis.) In Figure 2(d) the plots of the four versions -xxx-bcp (with on-the-fly
BCP) coincide with the line of value 1 (i.e, one variable) and in Figure 2(e) they coincide
with an horizontal line of value 2 (i.e, two clauses), corresponding to the fact that the
1-variable/2-clause formula A1  A1 is returned (see Footnote 14).
We notice a few facts. First, for both formulas, the eight plots always collapse into two
groups of overlapping plots, representing the four variants with and without on-the-fly BCP
respectively. This shows that box-lifting and on-the-fly PLR are almost irrelevant in the
encoding of these formulas, causing just little variations in the time required by the encoder
(Figures 2(c) and 2(f)); notice that enabling on-the-fly PLR alone permits to encode (but
not to solve) only one problem more wrt. the versions without both on-the-fly PLR and
BCP. Second, the four versions with on-the-fly-BCP always outperform of several orders
magnitude these without this option, in terms of both size of encoded formulas and of CPU
time required to encode and solve them. In particular, in the case of the unsatisfiable
variant (Figure 2, second row) the encoder returns the  formula, so that no actual work
is required to the SAT solver (the plot of Figure 2(f) refers only to encoding time).

5. Empirical Evaluation
In order to verify empirically the effectiveness of this approach, we have performed a veryextensive empirical test session on about 14,000 Km /ALC formulas. We have implemented
the encoder Km 2SAT in C++, with some flags corresponding to the optimizations exposed in the previous section: (i) NNF/BNF, performing a pre-conversion into NNF/BNF
before the encoding; (ii) lift/ctrl.lift/nolift, performing respectively Box Lifting,
Controlled Box Lifting or no Box Lifting before the encoding; (iii) plr if on-the-fly Pure
Literal Reduction is performed and (iv) bcp if on-the-fly Boolean Constraint Propagation
is performed. The techniques introduced in Section 4.2, Section 4.5 and Section 4.6 are
hardwired in the encoder. Moreover, as pre-conversion into BNF almost always produces
smaller formulas than NNF, we have set the BNF flag as a default.
In combination with Km 2SAT we have tried several SAT solvers on our encoded formulas (including Zchaff 2004.11.15, Siege v4, BerkMin 5.6.1, MiniSat v1.13, SATElite v1.0, SAT-Elite GTI 2005 submission 19 , MiniSat 2.0 061208 and Rsat 1.03).
19. In the preliminary evaluation of the available SAT solvers we have also tried SAT-Elite as a preprocessor
to reduce the size of the SAT formula generated by Km 2SAT without the bcp option before to solve it.
However, even if the preprocessing can signinificantly reduce the size of the formula, it has turned out

362

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

After a preliminary evaluation and further intensive experiments we have selected Rsat 1.03
(Pipatsrisawat & Darwiche, 2006), because it produced the best overall performances on
our benchmark suites (although the performance gaps wrt. other SAT tools, e.g. MiniSat
2.0, were not dramatic).
We have downloaded the available versions of the state-of-the-art tools for Km -satisfiability.
After an empirical evaluation 20 we have selected Racer 1-7-24 (Haarslev & Moeller, 2001)
and *SAT 1.3 (Tacchella, 1999) as the best representatives of the tableaux/DPLL-based
tools, Mspass v 1.0.0t.1.3 (Hustadt & Schmidt, 1999; Hustadt et al., 1999) 21 as the
best representative of the FOL-encoding approach, KBDD (unique version) (Pan et al.,
2002; Pan & Vardi, 2003) 22 as the representative of the automata-theoretic approach. No
representative of the CSP-based and of the inverse method approaches could be used. 23
Notice that all these tools but Racer are experimental tools, as far as Km 2SAT which is
a prototype, and many of them (e.g. *SAT and KBDD) are no longer maintained.
Finally, as representative of the QBF-encoding approach, we have selected the K-QBF
translator (Pan & Vardi, 2003) combined with the sKizzo version 0.8.2 QBF solver
(Benedetti, 2005), which turned out to be by far 24 the best QBF solver on our benchmarks among the freely-available QBF solvers from the QBF2006 competition (Narizzano,
Pulina, & Tacchella, 2006). (In our evaluation we have considered the tools : 2clsQ, SQBF,
preQuantori.e. preQuel +Quantor Quantor 2.11, and Semprop 010604.)
All tests presented in this section have been performed on a two-processor Intel Xeon
3.0GHz computer, with 1 MByte Cache each processor, 4 GByte RAM, with Red Hat
Linux 3.0 Enterprise Server, where four processes can run in parallel. When reporting the
results for one Km 2SAT +Rsat version, the CPU times reported are the sums of both

20.

21.

22.
23.

24.

that this preprocessing is too time-expensive and that the overall time spent for preprocessing and then
solving the reduced problem is higher than that solving directly the original encoded SAT formula.
As we did for the selection of the SAT solver, in order to select the tools to be used in the empirical
evaluation, we have performed a preliminary evaluation on the smaller benchmark suites (i.e. the LWB
and, sometimes, the TANCS 2000 ones; see later). Importantly, from this preliminary evaluation Racer
turned out to be definitely more efficient than FaCT++, being able to solve more problems in less time.
Also, in order to meet the reviewers suggestions, we repeated this preliminary evaluation with the latest
versions of FaCT++ (v1.2.3, March 5th, 2009) and the same version of Racer used in this paper.
In this evaluation Racer solves ten more problems than FaCT++ on the LWB benchmark, and over
than one hundred of problems more than FaCT++ on the whole TANCS 2000 suite. Also on 2m -CNF
random problems Racer outperforms FaCT++. (We include in the online appendix the plots of this
comparison between Racer and FaCT++.)
We have run Mspass with the options -EMLTranslation=2 -EMLFuncNary=1 -Sorts=0
-CNFOptSkolem=0 -CNFStrSkolem=0 -Select=2 -Split=-1 -DocProof=0 -PProblem=0 -PKept=0
-PGiven=0, which are suggested for Km -formulas in the Mspass README file. We have also tried
other options, but the former gave the best performances.
KBDD has been recompiled to be run with an increased internal memory bound of 1 GB.
At the moment KK is not freely available, and we failed in the attempt of obtaining it from the authors.
KCSP is a prolog piece of software, which is difficult to compare in performances wrt. other optimized
tools on a common platform; moreover, KCSP is no more maintained since 2005, and it is not competitive wrt. state-of-the-art tools (Brand, 2008). Other tools like leanK, 2KE, LWB, Kris are not
competitive with the ones listed above (Horrocks et al., 2000). KSAT (Giunchiglia & Sebastiani, 1996,
2000; Giunchiglia et al., 2000) has been reimplemented into *SAT.
Unlike with the choice of SAT solver, the performance gaps from the best choice and the others were
very significant: e.g., in the LWB benchmark (see later), sKizzo was able to solve nearly 90 problems
more than its best QBF competitor.

363

fiSebastiani & Vescovi

the encoding and Rsat solving times. When reporting the results for K-QBF +sKizzo,
the CPU times reported are only due to sKizzo because the time spent by the K-QBF
converter is negligible.
We anticipate that, for all formulas of all benchmark suites, all tools under test i.e.
all the variants of Km 2SAT +Rsat and all the state-of-the-art Km -satisfiability solvers
agreed on the satisfiability/unsatisfiability result when terminating within the timeout.
Remark 1. Due to the big number of empirical tests performed and to the huge amount
of data plotted, and due to limitations in size, and in order to to make the plots clearly
distinguishable in the figures, we have limited the number of plots included in the following
part of the paper, considering only the most meaningful ones and those regarding the most
challenging benchmark problems faced. For the sake of the readers convenience, however,
full-size versions of all plots and many other plots regarding the not-exposed results (also
on the easier problems), are available in the online appendix, together with the files with
all data. When discussing the empirical evaluation we may include in our considerations
also these results.
5.1 Test Description
We have performed our empirical evaluation on three different well-known benchmarks
suites of Km /ALC problems: the LWB (Heuerding & Schwendimann, 1996), the random 2m -CNF (Horrocks et al., 2000; Patel-Schneider & Sebastiani, 2003) and the TANCS
2000 (Massacci & Donini, 2000) benchmark suites. We are not aware of any other publiclyavailable benchmark suite on Km /ALC-satisfiability from the literature. These three groups
of benchmark formulas allow us to test the effectiveness of our approach on a large number
of problems of various sizes, depths, hardness and characteristics, for a total amount of
about 14,000 formulas.
In particular, these benchmark formulas allow us to fairly evaluate the different tools
both on the modal component and on the Boolean component of reasoning which are intrinsic in the Km -satisfiability problem, as we discuss later in Section 5.4.
In the following we describe these three benchmark suites.
5.1.1 The LWB Benchmark Suite
As a first group of benchmark formulas we used the LWB benchmark suite used in a
comparison at Tableaux98 (Heuerding & Schwendimann, 1996). It consists of 9 classes of
parametrized formulas (each in two versions, provable  p or not-provable  n 25 ), for a
total amount of 378 formulas. The parameter allows for creating formulas of increasing size
and difficulty.
The benchmark methodology is to test formulas from each class, in increasing difficulty,
until one formula cannot be solved within a given timeout, 1000 seconds in our tests. 26
The result from this class is the parameters value of the largest (and hardest) formula that
can be solved within the time limit. The parameter ranges only from 1 to 21 so that, if a
25. Since all tools check Km -(un)satisfiability, all formulas are negated, so that the negations of the provable
formulas are checked to be unsatisfiable, whilst the negation of the other formulas are checked to be
satisfiable.
26. We also set a 1 GB file-size limit for the encoding produced by Km 2SAT .

364

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

system can solve all 21 instances of a class, the result is given as 21. For a discussion on this
benchmark suite, we refer the reader to the work of Heuerding and Schwendimann (1996)
and of Horrocks et al. (2000).
5.1.2 The Random 2m -CNF Benchmark Suite
As a second group of benchmark formulas, we have selected the random 2m -CNF testbed
described by Horrocks et al. (2000), and Patel-Schneider and Sebastiani (2003). This is
a generalization of the well-known random k-SAT test methods, and is the final result of
a long discussion in the communities of modal and description logics on how to to obtain
significant and flawless random benchmarks for modal/description logics (Giunchiglia &
Sebastiani, 1996; Hustadt & Schmidt, 1999; Giunchiglia et al., 2000; Horrocks et al., 2000;
Patel-Schneider & Sebastiani, 2003).
In the 2m -CNF test methodology, a 2m -CNF formula is randomly generated according
to the following parameters:
 the (maximum) modal depth d;
 the number of top-level clauses L;
 the number of literal per clause clauses k;
 the number of distinct propositional variables N ;
 the number of distinct box symbols m;
 the percentage p of purely-propositional literals in clauses occurring at depth < d, s.t.
each clause of length k contains on average p  k randomly-picked Boolean literals and
k  p  k randomly-generated modal literals 2r , 2r . 27
(We refer the reader to the works of Horrocks et al., 2000, and Patel-Schneider & Sebastiani,
2003 for a more detailed description.)
A typical problem set is characterized by fixed values of d, k, N , m, and p: L is
varied in such a way as to empirically cover the 100% satisfiable / 100% unsatisfiable
transition. In other words, many problems with the same values of d, k, N, m, and p but an
increasing number of clauses L are generated, starting from really small, typically satisfiable
problems (i.e. with a probability of generating a satisfiable problem near to one) to huge
problems, where the increasing interactions among the numerous clauses typically leads
to unsatisfiable problems (i.e. it makes the probability of generating satisfiable problems
converging to zero). Then, for each tuple of the five values in a problem set, a certain
number of 2m -CNF formulas are randomly generated, and the resulting formulas are given
in the input to the procedure under test, with a maximum time bound. The fraction of
formulas which were solved within a given timeout, and the median/percentile values of
CPU times are plotted against the ratio L/N . Also, the fraction of satisfiable/unsatisfiable
formulas is plotted for a better understanding.
27. More precisely, the number of Boolean literals in a clause is bp  kc (resp. dp  ke) with probability
dp  ke  p  k (resp. 1  (dp  ke  p  k)). Notice that typically the smaller is p, the harder is the
problem (Horrocks et al., 2000; Patel-Schneider & Sebastiani, 2003).

365

fiSebastiani & Vescovi

Following the methodology proposed by Horrocks et al. (2000), and by Patel-Schneider
and Sebastiani (2003), we have fixed m = 1, k = 3 and 100 samples per point in all tests,
and we have selected two groups: an easier one, with d = 1, p = 0.5, N = 6, 7, 8, 9,
L/N = 10..60, and a harder one, with d = 2, p = 0.6, 0.5, N = 3, 4, L/N = 30..150 with
p = 0.6 and L/N = 50..140 with p = 0.5, varying the L/N ratio in steps of 5, for a total
amount of 13,200 formulas.
In each test, we imposed a timeout of 500 seconds per sample 28 and we calculated the
number of samples which were solved within the timeout, and the 50%th and 90%th percentiles of CPU time. 29 In order to correlate the performances with the (un)satisfiability of
the sample formulas, in the background of each plot we also plot the satisfiable/unsatisfiable
ratio.

5.1.3 The TANCS 2000 Benchmark Suite
Finally, as a third group of benchmark formulas, we used the MODAL PSPACE division
benchmark suite used in the comparison at TANCS 2000 (Massacci & Donini, 2000). It
contains both satisfiable and unsatisfiable formulas, with scalable hardness. In this benchmark suite, which we call TANCS 2000, the formulas are constructed by translating QBF
formulas into K using three translation schemas, namely the Schmidt-Schauss-Smolka translation (240 problems with many different depths, from 19 to 112), the Ladner translation
(240 problems, again with depths in the same range 19  112), and the Halpern translation
(56 problems of depth among: 20, 28, 40, 56, 80 or 112) (Massacci & Donini, 2000). As
done by Massacci and Donini, we call these classes easy, medium and hard respectively.
All formulas from each class are tested within a timeout of 1000 seconds. 30 For each
class, we report the number of solved formulas (X axis) and the total (cumulative) CPU
time spent for solving these formulas (Y axes). For each class the results are plotted sorting
the solved problems from the easiest one to the hardest one.

5.2 An Empirical Comparison of the Different Variants of Km 2SAT
We have first evaluated the various variants of the encoding in combination with Rsat. In
order to avoid considering too many combinations of the flags, we have considered the BNF
format, and we have grouped plr and bcp into one parameter plr-bcp, restricting thus
our investigation to 6 combinations: BNF, lift/ctrl.lift/nolift, and plr-bcp on/off.
(We recall that the techniques introduced in Section 4.2, Section 4.5 and Section 4.6 are
hardwired in the encoder.) Here we expose and analyze the results wrt. the three different
suites of benchmark problems.

28. With also a 512 MB file-size limit for the encoding produced by Km 2SAT .
29. Due to the lack of space and for the sake of clarity we wont include in the paper the 90%th percentiles
plots. Further, for the same reasons, well skip to report the plots regarding some of the easiest class of
the benchmark suite (e.g. those with d = 1 and lower values of N ). All of these plots, however, can be
found in the online appendix.
30. We also set a 1 GB file-size limit for the encoding produced by Km 2SAT .

366

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

5.2.1 Results on the LWB Benchmark Suite
The results on the LWB benchmark suite are summarized in Table 1 and Figure 3.
Table 1(a) reports in the left block the indexes of the hardest formulas encoded within
the file-size limit and, in the right block, those of the hardest formulas solved within the
timeout by Rsat; Table 1(b) reports the numbers of variables and clauses of Km 2SAT (),
referring to the hardest formulas solved within the timeout by Rsat (i.e., those reported
in the right block of Table 1(a)). For instance, the BNF-ctrl.lift-plr-bcp encoding of
k dum n(21) contains 11106 variables and 14106 clauses; it is the hardest k dum n problem
solved by Rsat with BNF-ctrl.lift-plr-bcp and it is the first which is not solved with
BNF-ctrl.lift.
Looking at the numbers of cases solved in Table 1(a), we notice that the introduction of
the on-the-fly Pure Literal Reduction and Boolean Constraint Propagation optimizations
is really effective and produces a consistent performance enhancement (the effect of these
optimizations is eye-catching in the branching formulas k branch *  see Section 4.9  and
in the k path * formulas). We also notice that lift sometimes introduces some slight
further improvement.
The view of Tables 1(a) and 1(b) hides the actual CPU times required to encode and
solve the problems. Small gaps in the numbers of Table 1(a) may correspond to big gaps in
CPU time. In order to analyze also this aspect, in Figure 3 we plotted the total cumulative
amount of CPU time spent by all the variants of Km 2SAT +Rsat to solve all the problems
of the LWB benchmark, sorted by hardness. For this plot, we also considered three more
options BNF, lift/ctrl.lift/nolift, with plr on and bcp off so that to evaluate
also the effect of plr and bcp separately. We notice that the plots are clearly clustered
into three groups of increasing performance: BNF-*, BNF-*-plr, and BNF-*-plr-bcp., *
representing the three options lift/ctrl.lift/nolift. This highlights the fact that on
this suite on-the-fly Pure Literal Reduction significantly improves the performances, that
on-the-fly Boolean Constraint Propagation introduces drastic improvements, and that the
variations due to Box Lifting are minor wrt. the other two optimizations.
Overall, the configuration BNF-lift-plr-bcp turns out to be the best performer on this
suite, with a tiny advantage wrt. BNF-ctrl.lift-plr-bcp.
5.2.2 Results on the Random 2m -CNF Benchmark Suite
The results on the random 2m -CNF benchmark suite are reported in Figures 4 and 5.
In Figure 4 we report the 50%-percentile CPU times required to encode and solve the
formulas by the different Km 2SAT +Rsat variants for the hardest benchmarks problems.
We dont report the percentage of solved problems since it is always 100%, i.e. Km 2SAT
+Rsat terminates within the timeout for every problem in the benchmark suite.
The tests with depth d = 1 (see the results on the hardest problems of the class in the
first row of Figure 4) are simply too easy for Km 2SAT +Rsat (but not for its competitors,
see Section 5.3) which solved every sample formula in less than 1 second. Although the
tests exposed in the second and third row of Figure 4 are more challenging, they are all
solved within the timeout as well. We have noticed also that the results are rather regular,
since there are no big gaps between 50%- and 90%-percentile values.
367

fiSebastiani & Vescovi

k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k

lifting
branch n
branch p
d4 n
d4 p
dum n
dum p
grz n
grz p
lin n
lin p
path n
path p
ph n
ph p
poly n
poly p
t4p n
t4p p

no
4
4
8
14
20
19
21
21
21
21
7
8
21
21
21
21
6
11

Km 2SAT , encoded
plr-bcp
yes ctrl
no yes
4
4
18
18
4
4
18
18
8
8
8
9
14 14
14
14
20
20
21
21
19
19
21
21
21 21
21
21
21 21
21
21
21 21
21
21
21 21
21
21
7
7
14
15
8
8
15
16
21 21
21
21
21 21
21
21
21 21
21
21
21 21
21
21
6
6
6
6
11 11
11
11

ctrl
18
18
8
14
21
21
21
21
21
21
14
15
21
21
21
21
6
11

Km 2SAT + Rsat, solved
plr-bcp
no yes ctrl
no yes
4
4
4
17
17
4
4
4
18
18
8
8
8
8
8
14
14 14
14
14
20
20
20
21
21
18
18
18
21
21
21
21 21
21
21
21
21 21
21
21
21
21 21
21
21
21
21 21
21
21
7
7
7
13
14
8
8
8
15
16
21
21 21
21
21
10
11
10
10
10
21
21 21
21
21
21
21 21
21
21
5
6
5
6
6
10
10
10
11
11

ctrl
17
18
8
14
21
21
21
21
21
21
13
15
21
11
21
21
6
11

(a) Indexes of the hardest problems encoded (left)
and of the hardest problems solved (right).

k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k
k

lifting
branch n
branch p
d4 n
d4 p
dum n
dum p
grz n
grz p
lin n
lin p
path n
path p
ph n
ph p
poly n
poly p
t4p n
t4p p

no
1000
1000
12000
19000
19000
11000
10
8
30
0
11000
11000
50
3
200
200
4000
12000

number of variables (103 )
plr-bcp
yes
ctrl
no
yes
ctrl
1000 1000 20000 20000 20000
1000 1000
0
0
0
6000 12000 10000 26000 10000
18000 19000
0
0
0
19000 19000 11000 11000 11000
11000 11000 20000 19000 20000
10
10
5
5
5
8
8
0.2
0.1
0.2
30
20
20
10
20
0
0
0
0
0
12000 11000 10000 7000 10000
12000 11000 26000 16000 26000
300
50
50
300
50
13
3
3
8
4
20
20
200
20
20
20
20
200
20
20
21000 4000 17000 14000 17000
10000 12000 20000 18000 20000

no
1000
1000
17000
28000
23000
14000
10
8
50
0
13000
13000
50
3
200
200
4000
12000

number of clauses (103 )
plr-bcp
yes
ctrl
no
yes
ctrl
1000 1000 23000 23000 23000
1000 1000
0
0
0
9000 17000 16000 43000 16000
25000 28000
0
0
0
23000 23000 14000 14000 14000
13000 14000 26000 25000 26000
10
10
6
6
6
8
8
0.3
0.2
0.2
50
20
30
30
30
0
0
0
0
0
14000 13000 14000 9000 13000
14000 13000 35000 20000 35000
300
50
50
600
50
14
3
3
14
5
20
20
200
20
20
20
20
200
20
20
22000 4000 20000 17000 20000
11000 12000 24000 21000 24000

(b) # of variables and # of clauses of the hardest problems solved.
Note: Here 0 means that the formula is simplified into  by Km 2SAT .

Table 1: Comparison of the variants of Km 2SAT +Rsat on the LWB benchmarks.

368

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

10000
BNF-lift (Rsat)
BNF-nolift (Rsat)
BNF-ctrl.lift (Rsat)
BNF-lift-plr (Rsat)
BNF-nolift-plr (Rsat)
BNF-ctrl.lift-plr (Rsat)
BNF-lift-plr-bcp (Rsat)
BNF-nolift-plr-bcp (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

1000

100

10

1

0.1
50

100

150

200

250

300

Figure 3: Comparison of different variants of Km 2SAT +Rsat on the LWB problems.
X axis: number of solved problems; Y axis: total CPU time spent (sorting
problems from the easiest to the hardest).

In general, we do not have relevant performance gaps between the various configurations
on this benchmark suite; it seems that in the majority of cases ctrl.lift slightly beats
nolift and nolift slightly beats lift. These gaps are even more relevant if we consider
the size of the formulas generated (Figure 5). We believe that this may be due to the fact
that random 2m -CNF formulas may contain lots of shared subformulas 2r , so that lifting
may cause a reduction of such sharing (see Section 3). Further, plr-bcp does not seem to
introduce relevant improvements here. We believe that this is due to the fact that these
random formulas produce pure and unit literals with very low or even zero probability.
Overall, the configuration BNF-nolift turns out to be the best performer on this suite,
with a slight advantage wrt. BNF-ctrl.lift-plr-bcp.
Finally, from some plots of Figure 4 we notice that for Km 2SAT +Rsat the problems
tend to be harder within the satisfiability/unsatisfiability transition area. (This fact holds
especially for Racer and *SAT, see Section 5.3.) This seems to confirm the fact that the
easy-hard-easy pattern of random k-SAT extends also to 2m -CNF, as already observed in
literature (Giunchiglia & Sebastiani, 1996, 2000; Giunchiglia et al., 2000; Horrocks et al.,
2000; Patel-Schneider & Sebastiani, 2003).
369

fiSebastiani & Vescovi

1000

100

500

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

100

1000

100

500

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)

80

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

100

50

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)

80

50

10

60

10

5

60

5

1

40

1

0.5

40

0.5

0.1

20

0.1

0.05

20

0.05

0.01

0
10

20

30

40

50

0.01

60

1000

100

500

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

100

0
10

20

40

50

60

1000

100

500

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)

30

80

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

100

50

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)

80

50

10

60

10

5

60

5

1

40

1

0.5

40

0.5

0.1

20

0.1

0.05

20

0.05

0.01

0
40

60

80

100

120

1000

0.01

140
100

500

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

100

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)

0
40

60

80

100

120

1000

140
100

500

80

100

50

80

50

10

60

10

5

60

5

1

40

1

0.5

40

0.5

0.1

20

0.1

0.05

0.05

0.01
60

80

100

120

0
140

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)

20

0.01
60

80

100

120

0
140

Figure 4: Comparison among different variants of Km 2SAT +Rsat on random problems.
X axis: #clauses/N . Y axis: median (50th percentile) CPU time, 100 samples/point. 1st row: d = 1, p = 0.5, N = 8, 9; 2nd row: d = 2, p = 0.6, N = 3, 4;
3rd row: d = 2, p = 0.5, N = 3, 4. Background: % of satisfiable instances.

370

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

180000
160000

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

180000
160000

140000

140000

120000

120000

100000

100000

80000

80000

60000

60000

40000

40000

20000

20000

0

0
10

20

30

40

50

60

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

1.2e+06

10

20

1e+06

800000

800000

600000

600000

400000

400000

200000

200000

0

40

50

60

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

1.2e+06

1e+06

30

0
40

60

80

100

120

140

40

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

2e+06

1.5e+06

1e+06

1e+06

500000

500000

0

80

100

120

140

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

2e+06

1.5e+06

60

0
60

80

100

120

140

60

80

100

120

140

Figure 5: Comparison among different variants of Km 2SAT on random problems. X axis:
#clauses/N . Y axis: 1st column: #variables in the SAT encoding (90th percentiles), 100 samples/point; 2nd column: #clauses in the SAT encoding (90th
percentiles), 100 samples/point. 1st row: d = 1, p = 0.5, N = 9; 2nd row: d = 2,
p = 0.6, N = 4; 3rd row: d = 2, p = 0.5, N = 4.

371

fiSebastiani & Vescovi

5.2.3 Results on the TANCS 2000 Benchmark Suite
The comparison among the Km 2SAT variants on the TANCS 2000 benchmark is presented
in Figures 6 and 7, where different BNF variants of Km 2SAT are compared both enabling
or disabling lift/ctrl.lif and plr-bcp.
In Figure 6, from top-left to bottom, we present the cumulative CPU times spent by
Km 2SAT +Rsat on the easy, medium and hard categories respectively (the corresponding
plots reporting the non-cumulative CPU times are included in the online appendix). In
Figure 7 we present the plots of the number of variables and clauses of the formulas solved
for the more challenging cases of the medium and hard problems. 31 We notice that there
are only slight differences among the different variants of Km 2SAT ; BNF with lift is the
best option which allows for solving more problems in the hard class and requiring less CPU
time.
We remark that, despite the expected exponential growth of the encoded formulas wrt.
the modal depth, in this benchmark Km 2SAT +Rsat allows for encoding and solving
problems of modal depth greater than 100 for the easy class and greater than 50 for the
medium and hard classes, producing and solving SAT-encoded formulas with more than 107
variables and 1.4  107 clauses.
5.3 An Empirical Comparison wrt. the Other Approaches
We proceed with the comparison of our approach wrt. the current state-of-the-art evaluating Km 2SAT +Rsat against the other Km -satisfiability solvers listed above. In more
details, we chose to compare the performance of the other solvers against both the best
local Km 2SAT +Rsat variant for the single benchmark suite and the best global
Km 2SAT +Rsat variant among all the benchmark suites, which we have identified in
BNF-ctrl.lift-plr-bcp.
5.3.1 Comparison on the LWB Benchmark Suite
The results on the LWB benchmark suite are summarized numerically and graphically in
Table 2. From Table 2(a) we notice a few facts: Racer and *SAT are the best performers
(confirming the analysis done by Horrocks et al., 2000) with a significant gap wrt. the others;
then, K-QBF +sKizzo solves a few more problems than Km 2SAT +Rsat; then follows
KBDD which outperforms Mspass, which is the worst performer. In detail, Km 2SAT
+Rsat is (one of) the worst performer(s) on k d4 * and k t4 *, the fourth best performer
on k path n, the third best performer on k path p and k branch p, and it is (one of) the
best performer(s) on k branch n, k dum *, k grz *, k lin *, k ph * and k poly *; it is the
absolute best performer on k branch n and k ph p.
In Table 2(b) we give a graphical representation of this comparison, plotting the number
of solved problems by each approach against the total cumulative amount of CPU time
spent. We notice that, even if Km 2SAT +Rsat solves a few problems less than K-QBF
+sKizzo, Km 2SAT +Rsat is mostly faster than K-QBF +sKizzo.
31. The same plots for the easy problems are included in the online appendix.

372

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

2000

2000

1000

1000

100

100

10

10

1

1
BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

0.1
20

40

60

80

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)

100

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

0.1

120

140

10

20

30

40

50

60

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
70

80

90 100

1000

100

10

1
BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

0.1
5

10

15

(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
(Rsat)
20

25

30

Figure 6: Comparison among different variants of Km 2SAT +Rsat on TANCS 2000 problems. X axis: number of solved problems. Y axis: total cumulative CPU time
spent. 1st (top-left) to 3th (bottom) plot: easy, medium, hard problems. (Problems are sorted from the easiest to the hardest).

373

fiSebastiani & Vescovi

1e+08

1e+08

1e+07

1e+07

1e+06

1e+06

100000

100000
BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

10000
10

20

30

40

50

60

70

10000
80

90 100

10

1e+08

1e+08

1e+07

1e+07

1e+06

1e+06

100000

100000
BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

10000
5

10

15

20

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp
20

30

40

50

60

70

80

90 100

BNF-lift
BNF-nolift
BNF-ctrl.lift
BNF-lift-plr-bcp
BNF-nolift-plr-bcp
BNF-ctrl.lift-plr-bcp

10000
25

30

5

10

15

20

25

30

Figure 7: Comparison among different variants of Km 2SAT on TANCS 2000 problems. X
axis: number of the harder solved problem. Y axis: 1st column: #variables in
the SAT encoding of the problem; 2nd column: #clauses in the SAT encoding
of the problem. 1st to 2th row: medium, hard problems.

374

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

other tools
K-QBF
+ sKizzo KBDD Mspass Racer *SAT
4
8
10
15
14
16
8
10
21
21
8
21
21
21
21
21
21
21
21
21
21
21
21
21
21
21
21
21
21
21
19
21
21
21
21
21
21
21
21
21
20
21
21
21
21
21
21
3
21
21
9
21
4
21
21
13
17
5
21
21
21
4
12
21
13
10
4
8
9
9
21
8
7
21
21
21
8
7
21
21
21
21
12
21
21
21
21
21
21
21

test
k branch n
k branch p
k d4 n
k d4 p
k dum n
k dum p
k grz n
k grz p
k lin n
k lin p
k path n
k path p
k ph n
k ph p
k poly n
k poly p
k t4p n
k t4p p

Km 2SAT + Rsat
BNF-plr-bcp
-ctrl.lift
-lift
17
17
18
18
8
8
14
14
21
21
21
21
21
21
21
21
21
21
21
21
13
14
15
16
21
21
11
10
21
21
21
21
6
6
11
11

(a) Indexes of the hardest problems solved.

10000
kQBF+sKizzo
*SAT
Racer
kBDD
1000
MSpass
BNF-lift-plr-bcp (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)
100

10

1

0.1
50

100

150

200

250

300

350

(b) X axis: # of problems solved; Y axis: total (cumulative) CPU time spent.

Table 2: Comparison of Km 2SAT +Rsat against the other tools on the LWB benchmarks.

375

fiSebastiani & Vescovi

100

100

90

90

80

80

70

70

60

60

50

50

40

40

30

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

30
kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

20

10

20

10

0

0
10

20

30

40

50

60

10

100

100

90

90

80

80

70

70

60

20

30

40

50

60

60
kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

50

40

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

50

40

30

30

20

20

10

10

0

0
40

60

80

100

120

140

40

100

100

90

90

80

80

70

70

60

60

80

100

120

140

60
kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

50

40

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

50

40

30

30

20

20

10

10

0

0
60

80

100

120

140

60

80

100

120

140

Figure 8: Comparison against other approaches on random problems. X axis: #clauses/N .
Y axis: % of problems solved within the timeout, 100 samples/point. 1st row:
d = 1, p = 0.5, N = 8, 9; 2nd row: d = 2, p = 0.6, N = 3, 4; 3rd row: d = 2,
p = 0.5, N = 3, 4.

376

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

1000

100

1000

500

100

500

100

80

100

50

80

50

10

60

10

5

60

5

1

40

1

0.5

40

0.5

0.1

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

0.05

20

0.1

0.01

0
10

20

30

40

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

0.05

50

0.01

60

1000

20

0
10

100

20

30

40

50

60

1000

500

100

500

100

80

100

50

80

50

10

60

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

5

1

10

60

5

40

1

0.5

40

0.5

0.1

20

0.1

0.05

0.01

0
40

60

80

100

120

1000

20

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

0.05

0.01

140

0
40

100

60

80

100

120

1000

500

140
100

500

100

80

100

50

80

50

10

60

10

5

60

5

1

40

1

0.5

40

0.5

0.1

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

0.05

0.01
60

80

100

120

20

0.1

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-nolift (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

0.05

0
140

0.01
60

80

100

120

20

0
140

Figure 9: Comparison against other approaches on random problems. X axis: #clauses/N .
Y axis: median (50th percentile) CPU time, 100 samples/point. 1st row: d = 1,
p = 0.5, N = 8, 9; 2nd row: d = 2, p = 0.6, N = 3, 4; 3rd row: d = 2, p = 0.5,
N = 3, 4. Background: % of satisfiable instances.

377

fiSebastiani & Vescovi

5.3.2 Comparison on the Random 2m -CNF Benchmark Suite
In the random 2m -CNF benchmark suite the results are dominated by Km 2SAT +Rsat.
For the hardest categories among the three groups of problems used in the evaluation, we
report in Figure 8 the number of problems solved by each tool within the timeout, and in
Figure 9 the median CPU time (i.e. the 50%th percentile).
Looking at Figure 8 we notice that Km 2SAT +Rsat (in both versions) is the only tool
which always terminates within the timeout, whilst *SAT and Racer sometimes do not
terminate in the hardest problems, K-QBF +sKizzo very often does not terminate, and
Mspass and KBDD do not terminate for most values.
In Figure 9 we notice that Km 2SAT +Rsat is most often the best performer (in particular with the hardest problems), followed by *SAT and Racer. (This is even much more
evident if we consider the 90%th percentile of CPU time, whose plots are included in the
online appendix.) In all these tests, K-QBF +sKizzo, Mspass and KBDD are drastically
outperformed by the others.
5.3.3 Comparison on the TANCS 2000 Benchmark Suite
The results of the TANCS 2000 benchmark are summarized in Figure 10, from the easy
category (top-left) to the hard category (bottom).
From the plots we notice that the relative performances of the tools under test vary
significantly with the category: Racer and *SAT are among the best performers in all
categories; K-QBF +sKizzo behaves well on the easy and medium categories but solves
very few problems on the hard one; KBDD behaves very well on the easy category, but solves
very few problems in the medium and hard ones. Mspass is among the worst performers
in all categories: in particular, it does not solve any problem in the hard category; finally,
Km 2SAT +Rsat is the worst performer on the easy category, it outperforms all competitors
but *SAT and Racer on the medium category, and competes head-to-head with both
Racer and *SAT for the first position on the hard category: the local-best configuration
BNF-lift beats both competitors; the global-best configuration BNF-ctrl.lift-prl-bcp
solves as many problems as Racer, with one-order-magnitude CPU-time performance gap,
and two problems less than *SAT.
Notice that the classification of the benchmark problems in easy, medium and
hard given by Massacci and Donini (2000) is based on the translation schema used to
produce every modal problem and refers to its reasoning component, but it is not necessarily related to other components (like, e.g., the modal depth) which affect the size of our
encoding and, hence, the efficiency of our approach. This may explain the fact, e.g., that
the easy problems are not so easy for our approach, and viceversa.
5.4 Discussion
As highlighted by Giunchiglia et al. (2000), and Horrocks et al. (2000), the satisfiability
problem in modal logics like Km is characterized by the alternation of two orthogonal
components of reasoning: a Boolean component, performing Boolean reasoning within each
state, and a modal component, generating the successor states of each state. The latter
must cope with the fact that the candidate models may be up to exponentially big wrt.
depth(), whilst the former must cope with the fact that there may be up to exponentially
378

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

10000

1e+05

10000
1000

1000
100
100
10
10

1

0.1

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-lift-plr-bcp (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)
50

100

150

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-lift-plr-bcp (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

1

0.1
200

20

40

60

80

100

120

10000

1000

100

10

kQBF+sKizzo
*SAT
Racer
kBDD
MSpass
BNF-lift-plr-bcp (Rsat)
BNF-ctrl.lift-plr-bcp (Rsat)

1

0.1
5

10

15

20

25

30

Figure 10: Comparison against other approaches on TANCS 2000 problems. X axis: number of solved problems. Y axis: total cumulative CPU time spent. 1st (top-left)
to 3th (bottom) plot: easy, medium, hard problems. (Problems are sorted from
the easiest to the hardest).

379

fiSebastiani & Vescovi

many candidate (sub)models to explore. In the Km 2SAT +DPLL approach the encoder
has to handle the whole modal component (rules (8) and (9)), whilst the handling of the
whole Boolean component is delegated to an external SAT solver.
From the results displayed in Section 5.3 we notice that the relative performances of
the Km 2SAT +DPLL approach wrt. other state-of-the-art tools range from cases where
Km 2SAT +Rsat is much less efficient than other state-of-the-art approaches (e.g., the k d4
and k t4p formulas) up to formulas where it is much more efficient (e.g., the k ph p or the
2m -CNF formulas with d = 1). In the middle stands a large majority of formulas in which
the approach competes well against the other state-of-the art tools; in particular, Km 2SAT
+Rsat competes very well or even outperforms the other approaches based on translations
into different formalisms (the translational approach, the automata-theoretic approach and
the QBF-encoding approach).
A simple explanation of the former fact could be that the Km 2SAT +DPLL approach
loses on problems with high modal depth, or where the modal component of reasoning
dominates (like, e.g., the k d4 and k t4p formulas), and wins on problems where the Boolean
component of reasoning dominates (like, e.g., the k ph n or the 2m -CNF formulas with
d = 1), and it is competitive for formulas in which both components are relevant.
We notice, however, that Km 2SAT +Rsat wins in the hard category of TANCS 2000
benchmarks, with modal depths greater than 50, and on k branch n, where the search
is dominated by the modal component. 32 In fact, we recall that reducing the Boolean
component of reasoning may produce a reduction also of the modal reasoning effort, because
it may reduce the number of successor states to analyze (e.g. Sebastiani, 2007, 2007). Thus,
e.g., techniques like on-the-fly BCP, although exploiting only purely-Boolean properties,
may produce not only a drastic pruning of the Boolean search, but also a drastic reduction
in the size of the model investigated, because they cut a priori the amount of successor
states to expand.

6. Related Work and Research Trends
In the last fifteen years one main research line in description logic has focused on investigating increasingly expressive logics, with the goal of establishing the theoretical boundaries
of decidability and of allowing for more expressive power in the languages defined (Baader,
Calvanese, McGuinness, Nardi, & Patel-Schneider, 2003). Consequently, very expressive 
though very hard description logics have today notable application in the field of Semantic
Web. For example, the SHOIN (D) logic (which has NExpTime complexity) captures the
sub-language OWL DL of the full OWL (Web Ontology Language) language (Bechhofer,
van Harmelen, Hendler, Horrocks, McGuinness, Patel-Schneider, & Stein, 2004), that is the
recommended standard language for the semantic web proposed by the W3C consortium.
In contrast, the recent quest for tractable description logic-based languages arising from
the field of bio-medical ontologies (e.g., Spackman, Campbell, & Cote, 1997; Sioutos,
de Coronado, Haber, Hartel, Shaiu, & Wright, 2007; The Gene Ontology Consortium, 2000;
32. The k branch n formulas are very hard from the perspective of modal reasoning, because they require
finding one model M with 2d+1 1 states (Halpern & Moses, 1992), but no Boolean reasoning within each
state is really required (Giunchiglia et al., 2000; Horrocks et al., 2000): e.g., *SAT solves k branch n(d)
with 2d+1  1 calls to its embedded DPLL engine, one for each state of M, each call solved by BCP only.

380

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

Rector & Horrocks, 1997) has stimulated the opening of another research line on tractable
description logics (also called lightweight description logics), which are suitable for reasoning
on these very big bio-medical ontologies. In particular, Baader et al. (2005, 2006, 2007, 2008)
have spent a considerable effort in the attempt of defining a small but maximal subset of
logical constructors, expressive enough to cover the needs of these practical applications,
but whose inference problems must remain tractable. For example, simple and tractable
description logics like EL, EL+ and EL++ (Baader et al., 2005) are expressive enough to
describe several important bio-medical ontologies such as SNoMed (Spackman et al., 1997),
NCI (Sioutos et al., 2007), the Gene Ontology (The Gene Ontology Consortium, 2000) and
the majority of Galen (Rector & Horrocks, 1997).
Reasoning on these ontologies represents not only an important application of lightweight
description logics, but also a challenge due to the required efficiency and the huge dimensions of the ontologies. In this perspective, it is important to face efficiently not only the
basic reasoning services (e.g., satisfiability, subsumption, queries) on logics like EL, EL+ and
EL++ , but also more sophisticated reasoning problems like e.g., axiom pinpointing (Baader
et al., 2007; Baader & Penaloza, 2008) and logical difference between terminologies (Konev,
Walther, & Wolter, 2008).

7. Conclusions and Future Work
In this paper we have explored the idea of encoding Km /ALC-satisfiability into SAT, so
that to be handled by state-of-the-art SAT tools. We have showed that, despite the intrinsic
risk of blowup in the size of the encoded formulas, the performances of this approach are
comparable with those of current state-of-the-art tools on a rather extensive variety of
empirical tests. Furthermore, we remark that our approach allows for directly benefitting
for free from current and future enhancements in SAT solver technology.
We see many possible directions to explore in order to enhance and extend our approach.
An important open research line is to explore the feasibility of SAT encodings for other and
more expressive modal and description logics (e.g., whilst for logics like Tm the extension
should be straightforward, logics like S4m , or more elaborated description logics than ALC,
should be challenging) and for more complex form of reasoning (e.g., including TBoxes and
ABoxes).
Our current investigation, however, focuses on the lightweight logics of Baader et al.
(2005). We have investigated (and we are currently enhancing) an encoding of the main
reasoning services in EL and EL+ into Horn-SAT, which allows for reasoning efficiently
on the (often huge) bio-medical ontologies mentioned in Section 6, and for handling the
more sophisticated inference problems mentioned there (e.g., we currently handle axiom
pinpointing), by exploiting some of the advanced functionalities which can be implemented
on top of a modern SAT solver (Sebastiani & Vescovi, 2009).

8. Acknowledgments
The authors are partly supported by SRC/GRC under Custom Research Project 2009-TJ1880 WOLFLING, and by MIUR under PRIN project 20079E5KM8 002.
381

fiSebastiani & Vescovi

Appendix A. The Proof of Correctness & Completeness
A.1 Some Further Notation
Let  be a Km -formula. We denote by  the representation of  in the current formalism:
def
def
def
def
def
in NNF, 3r  = 2r , 2r  = 3r , 1  2 = 1  2 , 1  2 = 1  2 , Ai = Ai ,
def
def
def
def
def
Ai = Ai ; in BNF, 2r  = 2r , 2r  = 2r , 1  2 = 1  2 , 1  2 = 1  2 ,
def
def
Ai = Ai , Ai = Ai .
We represent a truth assignment  as a set of literals, with the intended meaning that a
positive literal Ai (resp. negative literal Ai ) in  means that Ai is assigned to true (resp.
false). We say that  assigns a literal l if either l   or l  . We say that a literal l
occurs in a Boolean formula  iff the atom of l occurs in .
Let M denote a Kripke model, and let  be the label of a generic state u in M. We
label (and denote) by 1 the root state of M. By h : i  M we mean that u  M
and M, u |= . Thus, for every  s.t. u  M, either h : i  M or h : i  M.
For convenience, instead of (9) sometimes we use the equivalent definition:
^
^
def
(Lh, r,i i  Lh.i, 0r i )) 
Def (.i, 0r ). (20)
Def (,  r ) = (Lh,  r i 
for every
h, r,i i

for every
h, r,i i

Notice that each Def (, ) in (6), (7), (8), (20) is written in the general form
^
(Lh, i  h,i ) 
Def ( 0 ,  0 ).

(21)

h 0 , 0 i

We call definition implication for Def (, ) the expressions (Lh,

i

 h,i ).

A.2 Soundness and Completeness of Km 2SAT
Let  be a Km -formula. We prove the following theorem, which states the soundness and
completeness of Km 2SAT .
Theorem 1. A Km -formula  is Km -satisfiable if and only if the corresponding Km 2SAT ()
is satisfiable.
Proof. It is a direct consequence of the following Lemmas 2 and 3.

Lemma 2. Given a Km -formula , if Km 2SAT () is satisfiable, then there exists a Kripke
model M s.t. M, 1 |= .
Proof. Let  be a total truth assignment satisfying Km 2SAT (). We build from  a Kripke
model M = hU, L, R1 , . . . , Rm i as follows:
U

def

= { : Ah, i occurs in Km 2SAT () f or some }

T rue if Lh, Ai i  
def
L(, Ai ) =
F alse if Lh, Ai i  
Rr

def

= {h, .ii : Lh,

 r,i i

382

 }.

(22)
(23)
(24)

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

We show by induction on the structure of  that, for every h, i s.t. Lh,
Km 2SAT (),
h : i  M if Lh, i  .

i

occurs on
(25)

Base
 = Ai or  = Ai . Then (25) follows trivially from (23).
Step
 = . Let Lh,

i

 .

As  satisfies (6), Lh,

  for every i  {1, 2}.

i i

By inductive hypothesis, h : i i  M for every i  {1, 2}.
Then, by definition, h : i  M.
Thus, h : i  M if Lh,
 = . Let Lh,

i

i

 .

 .

As  satisfies (7), Lh,

i i

  for some i  {1, 2}.

By inductive hypothesis, h : i i  M for some i  {1, 2}.
Then, by definition, h : i  M.
Thus, h : i  M if Lh,
 =  r,j . Let Lh,

 r,j i

i

 .

 .

As  satisfies (8), Lh.j,

0r,j i

 .

By inductive hypothesis, h.j : 0r,j i  M.
Then, by definition and by (24), h :  r,j i  M.
Thus, h :  r,j i  M if Lh,
 =  r . Let Lh,

ri

 r,j i

 .

 .

As  satisfies (9), for every h,  r,i i s.t. Lh,

 r,i i

 , we have that Lh.i,

0r i

By inductive hypothesis, we have that h :  r,i i  M and h.i : 0r i  M.
Then, by definition and by (24), h :  r i  M.
Thus, h :  r i  M if Lh,
If  |= Km 2SAT (), then Ah1,

r i

i

 .

 . Thus, by (25), h1 : i  M, i.e., M, 1 |= .

383

 .

fiSebastiani & Vescovi

Lemma 3. Given a Km -formula , if there exists a Kripke model M s.t. M, 1 |= , then
Km 2SAT () is satisfiable.
Proof. Let M be a Kripke model s.t. M, 1 |= . We build from M a truth assignment 
for Km 2SAT () recursively as follows: 33
def

 = M  M

(26)

M

def

M

def

=     A

(28)



def

(29)



def

= {Lh,


i

{Lh,

= {Lh,


{Lh,

 Km 2SAT () : h, i  M}

i

 Km 2SAT () : h, i  M}

 r,i i

r i

(27)

 Km 2SAT () :  6 M}

 Km 2SAT () :  6 M}

= {Lh,

i  Km 2SAT ()

:  6 M and Lh,

i i  M

for some i  {1, 2}} (30)



i  Km 2SAT ()

:  6 M and Lh,

i i  M

for every i  {1, 2}}.

{Lh,

where A is a consistent truth assignment for the literals Lh,

Ai i

s.t. Ai  A and  6 M.

By construction, for every Lh, i in Km 2SAT (),  assigns Lh, i to true iff it assigns
Lh, i to false and vice versa, so that  is a consistent truth assignment.
First, we show that M satisfies the definition implications of all Def (, )s and
Def (, ) s.t.   M. Let   M. We distinguish four cases.
 = . Thus  =  s.t. 1 = 1 and 2 = 2 .
 If h : i  M (and hence h : i 6 M), then for both is h : i i  M and
h : i i 6 M. Thus, by (27), {Lh, 1 i , Lh, 2 i , Lh, i }  M , so that M
satisfies the definition implications of both Def (, ) and Def (, ).
 If h : i 6 M (and hence h, i  M), then for some i h : i i 6 M and
h : i i  M. Thus, by (27), {Lh, i , Lh, i i }  M , so that M satisfies the
definition implications of both Def (, ) and Def (, ).
 = . Like in the previous case, inverting  and .
 =  r,j . Thus  =  r s.t. 0r = 0r,j .
 If h :  r,j i  M (and hence h :  r i 6 M), then h.j : 0r,j i  M. Thus, by (27),
{Lh.j, r,j i , Lh,  r i }  M , so that M satisfies the definition implications of
0

both Def (,  r,j ) and Def (,  r ).
33. We assume that M ,  and  are generated in order, so that  is generated recursively starting
from  . Intuitively, M assigns the literals Lh, i s.t.   M in such a way to mimic M; M assigns
the other literals in such a way to mimic the fact that no state outside those in M is generated (i.e., all
Lh, i s are assigned false and the Lh, i s, Lh, i s, Lh, i s are assigned consequently).

384

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

 If h :  r,j i 6 M (and hence h :  r i  M), then by (27) Lh, r,j i  M , so
that M satisfies the definition implications of Def (,  r,j ).
As far as Def (,  r ) is concerned, we partition the clauses in (9):
((Lh,

r i

 Lh,

 r,i i )

 Lh.i,

0r i )

(31)

into two subsets. The first is the set of clauses (31) for which h :  r,i i  M. As
h :  r i  M, we have that h.i : 0r i  M. Thus, by (27), Lh.i, 0r i  M , so that
M satisfies (31). The second is the set of clauses (31) for which h :  r,i i 6 M.
By (27) we have that Lh, r,i i  M , so that M satisfies (31). Thus, M
satisfies the definition implications also of Def (,  r ).
 =  r . Like in the previous case, inverting  and .
Notice that, if  6 M, then .i 6 M for every i. Thus, for every Def (, ) s.t.  6 M, all
atoms in the implication definition of Def (, ) are not assigned by M .
Second, we show by induction on the recursive structure of M that M satisfies the
definition implications of all Def (, )s and Def (, )s s.t.  6 M. Let  6 M.
As a base step, by (29),  satisfies the definition implications of all Def (,  r,i )s and
Def (,  r )s because it assigns false to all Lh, r,i i s. Indeed, A assigns every literal of
the type Lh, Ai i s.t Ai  A and  6 M (notice that all the Def (, Ai )s definitions are
trivially satisfied and dont contain any definition implications).
As inductive step, we show on the inductive structure of  that  satisfies the
definition implications of all Def (, )s and Def (, )s
def
Let  =  and  =  s.t. i = i (or vice versa). Then we have that:
 if both Lh, i i s (respectively at least one Lh, i i ) are assigned true by M , then
the definition implications of Def (, ) (respectively Def (, )) is already trivially
satisfied;
 if at least one Lh, i i (respectively both Lh, i i s) is assigned false by M , then by
(30) Lh, i (respectively Lh, i ) is assigned false by  , which satisfies the definition
implication of Def (, ) (respectively Def (, )).
Thus M satisfies the definition implications of all the Def (, )s and Def (, )s s.t.
 6 M.
On the whole,  |= Def (, ) for every Def (, ). By construction, M |= Ah1,
since h1 : i  M. Therefore  |= Km 2SAT ().

385

i

fiSebastiani & Vescovi

References
Areces, C., Gennari, R., Heguiabehere, J., & de Rijke, M. (2000). Tree-based heuristics in
modal theorem proving. In Proc. of ECAI00, pp. 199203. IOS Press.
Baader, F., Brandt, S., & Lutz, C. (2005). Pushing the EL envelope. In Proc. of IJCAI05,
pp. 364369. Morgan-Kaufmann Publishers.
Baader, F., Franconi, E., Hollunder, B., Nebel, B., & Profitlich, H. (1994). An Empirical
Analysis of Optimization Techniques for Terminological Representation Systems or:
Making KRIS get a move on. Applied Artificial Intelligence. Special Issue on Knowledge Base Management, 4, 109132.
Baader, F., & Hollunder, B. (1991). A Terminological Knowledge Representation System
with Complete Inference Algorithms. In Proc. of First International Workshop on
Processing Declarative Knowledge, Vol. 572 of LNCS, pp. 6785. SpringerVerlag.
Baader, F., Lutz, C., & Suntisrivaraporn, B. (2006). CELa polynomial-time reasoner
for life science ontologies. In Proc. of IJCAR06, Vol. 4130 of LNAI, pp. 287291.
SpringerVerlag.
Baader, F., Brandt, S., & Lutz, C. (2008). Pushing the EL envelope further. In Proc. of
the OWLED 2008 DC Workshop.
Baader, F., Calvanese, D., McGuinness, D., Nardi, D., & Patel-Schneider, P. F. (Eds.).
(2003). The Description Logic Handbook: Theory, Implementation, and Applications.
Cambridge University Press.
Baader, F., & Penaloza, R. (2008). Automata-Based Axiom Pinpointing. In Proc. of
IJCAR08, Vol. 5195 of LNAI, pp. 226241. Springer.
Baader, F., Penaloza, R., & Suntisrivaraporn, B. (2007). Pinpointing in the description
logic EL+ . In Proc. of KI 2007, Vol. 4667 of LNCS, pp. 5267. Springer.
Balsiger, P., Heuerding, A., & Schwendimann, S. (1998). Logics workbench 1.0. In Proc. of
Tableaux98, Vol. 1397 of LNCS, pp. 3537. Springer.
Bechhofer, S., van Harmelen, F., Hendler, J., Horrocks, I., McGuinness, D. L., PatelSchneider, P. F., & Stein, L. A. (2004). OWL Web Ontology Language reference.
W3C Recommendation. Available at http://www.w3.org/TR/owl-ref/.
Benedetti, M. (2005). sKizzo: A Suite to Evaluate and Certify QBFs. In Proc. of CADE-20,
Vol. 3632 of LNCS, pp. 369376. Springer.
Biere, A., Cimatti, A., Clarke, E. M., & Zhu, Y. (1999). Symbolic Model Checking without
BDDs. In Proc. of TACAS99, Vol. 1579 of LNCS, pp. 193207. Springer.
Brand, S. (2008). Personal communication.
Brand, S., Gennari, R., & de Rijke, M. (2003). Constraint Programming for Modelling and
Solving Modal Satisfability. In Proc. of CP 2003, Vol. 2833 of LNCS, pp. 795800.
Springer.
Davis, M., Longemann, G., & Loveland, D. (1962). A machine program for theorem-proving.
Journal of the ACM, 5 (7), 394397.
386

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

Davis, M., & Putnam, H. (1960). A computing procedure for quantification theory. Journal
of the ACM, 7, 201215.
Donini, F., & Massacci, F. (2000). EXPTIME tableaux for ALC. Artificial Intelligence,
124 (1), 87138.
Een, N., & Sorensson, N. (2004). An Extensible SAT-solver. In Proc. of SAT03, Vol. 2919
of LNCS, pp. 502518. Springer.
Fitting, M. (1983). Proof Methods for Modal and Intuitionistic Logics. D. Reidel Publishing.
Franconi, E. (1998). CRACK. In Proc. of Description Logics 98, Vol. 11 of CEUR Workshop
Proceedings. CEUR-WS.org.
Giunchiglia, E., Giunchiglia, F., Sebastiani, R., & Tacchella, A. (2000). SAT vs. Translation
based decision procedures for modal logics: a comparative evaluation. Journal of
Applied Non-Classical Logics, 10 (2), 145172.
Giunchiglia, E., Giunchiglia, F., & Tacchella, A. (2002). SAT-Based Decision Procedures
for Classical Modal Logics. Journal of Automated Reasoning, 28 (2), 143171.
Giunchiglia, F., & Sebastiani, R. (1996). Building decision procedures for modal logics from
propositional decision procedures - the case study of modal K. In Proc. of CADE-13,
Vol. 1104 of LNAI, pp. 583597. Springer.
Giunchiglia, F., & Sebastiani, R. (2000). Building decision procedures for modal logics from
propositional decision procedures - the case study of modal K(m). Information and
Computation, 162 (1/2), 158178.
Giunchiglia, F., Roveri, M., & Sebastiani, R. (1996). A new method for testing decision
procedures in modal and terminological logics. In Proc. of Description Logics 96,
Vol. WS-96-05 of AAAI Technical Reports, pp. 119123. AAAI Press.
Haarslev, V., & Moeller, R. (2001). RACER System Description. In Proc. of IJCAR01,
Vol. 2083 of LNAI, pp. 701706. Springer.
Halpern, J. Y. (1995). The effect of bounding the number of primitive propositions and
the depth of nesting on the complexity of modal logic. Artificial Intelligence, 75 (3),
361372.
Halpern, J., & Moses, Y. (1992). A guide to the completeness and complexity for modal
logics of knowledge and belief. Artificial Intelligence, 54 (3), 319379.
Heuerding, A., & Schwendimann, S. (1996). A benchmark method for the propositional
modal logics K, KT, S4. Tech. rep. IAM-96-015, University of Bern, Switzerland.
Horrocks, I. (1998). Using an expressive description logic: FaCT or fiction?. In Proc. of
KR98, pp. 636647. Morgan Kaufmann.
Horrocks, I., & Patel-Schneider, P. F. (1999). Optimizing Description Logic Subsumption.
Journal of Logic and Computation, 9 (3), 267293.
Horrocks, I., Patel-Schneider, P. F., & Sebastiani, R. (2000). An Analysis of Empirical
Testing for Modal Decision Procedures. Logic Journal of the IGPL, 8 (3), 293323.
387

fiSebastiani & Vescovi

Hustadt, U., Schmidt, R. A., & Weidenbach, C. (1999). MSPASS: Subsumption Testing with
SPASS. In Proc. of Description Logics 99, Vol. 22 of CEUR Workshop Proceedings,
pp. 136137. CEUR-WS.org.
Hustadt, U., & Schmidt, R. (1999). An empirical analysis of modal theorem provers. Journal
of Applied Non-Classical Logics, 9 (4), 479522.
Kautz, H., McAllester, D., & Selman, B. (1996). Encoding Plans in Propositional Logic. In
Proc. of KR96, pp. 374384. AAAI Press.
Konev, B., Walther, D., & Wolter, F. (2008). The Logical Difference Problem for Description
Logic Terminologies. In Proc. of IJCAR08, Vol. 5195 of LNAI, pp. 259274. Springer.
Ladner, R. (1977). The computational complexity of provability in systems of modal propositional logic. SIAM Journal on Computing, 6 (3), 467480.
Massacci, F. (1999). Design and Results of Tableaux-99 Non-Classical (Modal) System Competition. In Proc. of Tableaux99, Vol. 1617 of LNCS, pp. 1418. SpringerVerlang.
Massacci, F. (2000). Single Step Tableaux for modal logics: methodology, computations,
algorithms. Journal of Automated Reasoning, 24 (3), 319364.
Massacci, F., & Donini, F. (2000). Design and results of TANCS-2000, Automated Reasoning with Analytic Tableaux and Related Methods. In Proc. of Tableaux 2000, Vol.
1847 of LNCS, pp. 5256. Springer.
Moskewicz, M. W., Madigan, C. F., Zhao, Y., Zhang, L., & Malik, S. (2001). Chaff: Engineering an efficient SAT solver. In Proc. of DAC01, pp. 530535. ACM.
Narizzano, M., Pulina, L., & Tacchella, A. (2006).
The QBFEVAL Web Portal. In Proc. of JELIA06, Vol. 4160 of LNCS, pp. 494497. Springer. See:
http://www.qbflib.org/index eval.php.
Pan, G., Sattler, U., & Vardi, M. Y. (2002). BDD-Based Decision Procedures for K. In
Proc. of CADE-18, Vol. 2392 of LNCS, pp. 1630. Springer.
Pan, G., & Vardi, M. Y. (2003). Optimizing a BDD-based modal solver. In Proc. of
CADE-19, Vol. 2741 of LNAI, pp. 7589. Springer.
Patel-Schneider, P. F. (1998). DLP system description. In Proc. of Tableaux98, pp. 8789.
Patel-Schneider, P. F., & Sebastiani, R. (2001). A new system and methodology for generating random modal formulae. In Proc. of IJCAR01, Vol. 2083 of LNAI, pp. 464468.
Springer-Verlag.
Patel-Schneider, P. F., & Sebastiani, R. (2003). A New General Method to Generate Random Modal Formulae for Testing Decision Procedures. Journal of Artificial Intelligence Research, (JAIR), 18, 351389.
Pipatsrisawat, T., & Darwiche, A. (2006). SAT Solver Description: Rsat. Available at:
http://fmv.jku.at/sat-race-2006/descriptions/9-rsat.pdf.
Rector, A., & Horrocks, I. (1997). Experience building a large, re-usable medical ontology
using a description logic with transitivity and concept inclusions. In Proc. of Workshop
on Ontological Engineering, AAAI Spring Symposium (AAAI97). AAAI Press.
388

fiAutomated Reasoning in Modal and Description Logics via SAT Encoding

Schild, K. D. (1991). A correspondence theory for terminological logics: preliminary report.
In Proc. of IJCAI91, pp. 466471.
Sebastiani, R. (2007). Lazy Satisfiability Modulo Theories. Journal on Satisfiability, Boolean
Modeling and Computation (JSAT), 3, 141224.
Sebastiani, R., & Vescovi, M. (2006). Encoding the Satisfiability of Modal and Description
Logics into SAT: The Case Study of K(m)/ALC. In Proc. of SAT06, Vol. 4121 of
LNCS, pp. 130135. Springer.
Sebastiani, R., & Vescovi, M. (2009). Axiom Pinpointing in Lightweight Description Logics
via Horn-SAT Encoding and Conflict Analysis. In Proc. of CADE-22, Vol. 5663 of
LNAI. Springer. In print.
Sebastiani, R. (2007). From KSAT to Delayed Theory Combination: Exploiting DPLL
Outside the SAT Domain. In Proc. of FroCoS07, Vol. 4720 of LNCS, pp. 2846.
Springer. Invited talk.
Seshia, S. A., Lahiri, S. K., & Bryant, R. E. (2003). A Hybrid SAT-Based Decision Procedure
for Separation Logic with Uninterpreted Functions. In Proc. of DAC03, pp. 425430.
ACM.
Silva, J. P. M., & Sakallah, K. A. (1996). GRASP - A new Search Algorithm for Satisfiability.
In Proc. of ICCAD96, pp. 220227. IEEE Computer Society.
Sioutos, N., de Coronado, S., Haber, M. W., Hartel, F. W., Shaiu, W., & Wright, L. W.
(2007). NCI Thesaurus: A semantic model integrating cancer-related clinical and
molecular information. Journal of Biomedical Informatics, 40 (1), 3043.
Spackman, K. A., Campbell, K., & Cote, R. (1997). SNOMED RT: A reference terminology
for healt care. Journal of American Medical Informatics Association (Fall Symposium
Supplement), 640644.
Strichman, O. (2002). On Solving Presburger and Linear Arithmetic with SAT. In Proc. of
FMCAD02, Vol. 2517 of LNCS, pp. 160170. SpringerVerlag.
Strichman, O., Seshia, S., & Bryant, R. (2002). Deciding separation formulas with SAT. In
Proc. of CAV02, Vol. 2404 of LNCS, pp. 209222. Springer.
Tacchella, A. (1999). *SAT system description. In Proc. of Description Logics 99, Vol. 22
of CEUR Workshop Proceedings, pp. 142144. CEUR-WS.org.
The Gene Ontology Consortium (2000). Gene ontology: Tool for the unification of biology.
Nature Genetics, 25, 2529.
Voronkov, A. (1999). KK: a theorem prover for K. In Proc. of CADE-16, Vol. 1632 of
LNAI, pp. 383387. Springer.
Voronkov, A. (2001). How to optimize proof-search in modal logics: new methods of proving
redundancy criteria for sequent calculi. ACM Transactions on Computational Logic,
2 (2), 182215.
Zhang, L., & Malik, S. (2002). The quest for efficient boolean satisfiability solvers. In Proc.
of CAV02, Vol. 2404 of LNCS, pp. 1736. Springer.

389

fiJournal of Artificial Intelligence Research 35 (2009) 161-191

Submitted 05/08; published 06/09

Eliciting Single-Peaked Preferences
Using Comparison Queries
Vincent Conitzer

conitzer@cs.duke.edu

Departments of Computer Science
and Economics, Duke University
Durham, NC, USA

Abstract
Voting is a general method for aggregating the preferences of multiple agents. Each
agent ranks all the possible alternatives, and based on this, an aggregate ranking of the
alternatives (or at least a winning alternative) is produced. However, when there are many
alternatives, it is impractical to simply ask agents to report their complete preferences.
Rather, the agents preferences, or at least the relevant parts thereof, need to be elicited.
This is done by asking the agents a (hopefully small) number of simple queries about
their preferences, such as comparison queries, which ask an agent to compare two of the
alternatives. Prior work on preference elicitation in voting has focused on the case of
unrestricted preferences. It has been shown that in this setting, it is sometimes necessary
to ask each agent (almost) as many queries as would be required to determine an arbitrary
ranking of the alternatives. In contrast, in this paper, we focus on single-peaked preferences.
We show that such preferences can be elicited using only a linear number of comparison
queries, if either the order with respect to which preferences are single-peaked is known, or
at least one other agents complete preferences are known. We show that using a sublinear
number of queries does not suffice. We also consider the case of cardinally single-peaked
preferences. For this case, we show that if the alternatives cardinal positions are known,
then an agents preferences can be elicited using only a logarithmic number of queries;
however, we also show that if the cardinal positions are not known, then a sublinear number
of queries does not suffice. We present experimental results for all elicitation algorithms. We
also consider the problem of only eliciting enough information to determine the aggregate
ranking, and show that even for this more modest objective, a sublinear number of queries
per agent does not suffice for known ordinal or unknown cardinal positions. Finally, we
discuss whether and how these techniques can be applied when preferences are almost
single-peaked.

1. Introduction
In multiagent systems, a group of agents often has to make joint decisions even when the
agents have conflicting preferences over the alternatives. For example, agents may have
different preferences over possible joint plans for the group, allocations of tasks or resources
among members of the group, potential representatives (e.g., presidential candidates), etc.
In such settings, it is important to be able to aggregate the agents individual preferences.
The result of this aggregation can be a single alternative, corresponding to the groups
collective decision, or a complete aggregate (compromise) ranking of all the alternatives
(which can be useful, for instance, if some of the alternatives later turn out not to be
feasible). The most general framework for aggregating the agents preferences is to have
c
2009
AI Access Foundation. All rights reserved.

fiConitzer

the agents vote over the alternatives. That is, each agent announces a complete ranking
of all alternatives (the agents vote), and based on these votes an outcome (i.e., a winning
alternative or a complete aggregate ranking of all alternatives) is chosen according to some
voting rule.1
One might try to create an aggregate ranking as follows: for given alternatives a and b,
if more votes prefer a to b than vice versa (i.e., a wins its pairwise election against b), then
a should be ranked above b in the aggregate ranking. Unfortunately, when the preferences
of the agents are unrestricted and there are at least three alternatives, Condorcet cycles
may occur. A Condorcet cycle is a sequence of alternatives a1 , a2 , . . . , ak such that for each
1  i < k, more agents prefer ai to ai+1 than vice versa, and more agents prefer ak to
a1 than vice versa. In the presence of a Condorcet cycle, it is impossible to produce an
aggregate ranking that is consistent with the outcomes of all pairwise elections. Closely
related to this phenomenon are numerous impossibility results that show that every voting
rule has significant drawbacks in this general setting. For example, when there are at least
three alternatives, Arrows impossibility theorem (Arrow, 1963) shows that any voting rule
for which the relative order of two alternatives in the aggregate ranking is independent of
how agents rank alternatives other than these two (i.e., any rule that satisfies independence
of irrelevant alternatives) must either be dictatorial (i.e., the rule simply copies the ranking
of a fixed agent, ignoring all other agents) or conflicting with unanimity (i.e., for some
alternatives a and b, the rule sometimes ranks a above b even if all agents prefer b to a).
As another example, when there are at least three alternatives, the Gibbard-Satterthwaite
theorem (Gibbard, 1973; Satterthwaite, 1975) shows that for any voting rule that is onto (for
every alternative, there exist votes that would make that alternative win) and nondictatorial,
there are instances where an agent is best off casting a vote that does not correspond to
the agents true preferences (i.e., the rule is not strategy-proof).
1.1 Single-Peaked Preferences
Fortunately, these difficulties can disappear if the agents preferences are restricted, i.e., they
display some structure. The best-known, and arguably most important such restriction is
that of single-peaked preferences (Black, 1948). Suppose that the alternatives are ordered
on a line, from left to right, representing the alternatives positions. For example, in a
political election, a candidates position on the line may indicate whether she is a left-wing
or a right-wing candidate (and how strongly so). As another example, the alternatives may
be numerical values: for example, agents may vote over the size of a budget. As yet another
example, the alternatives may be locations along a road (for example, if agents are voting
over where to construct a building, or where to meet for dinner, etc.). We say that an agents
preferences are single-peaked with respect to the alternatives positions if, on each side of the
agents most preferred alternative (the agents peak), the agent prefers alternatives that are
closer to its peak. For example, if the set of alternatives is {a, b, c, d, e, f }, their positions
may be represented by d < b < e < f < a < c, in which case the vote f  e  b  a  c  d
1. One may argue that this approach is not fully general because it does not allow agents to specify their
preferences over probability distributions over alternatives. For example, it is impossible to know from
an agents vote whether that agent prefers its second-ranked alternative to a 1/2 - 1/2 probability
distribution over its first-ranked and third-ranked alternatives. In principle, this can be addressed by
voting over these probability distributions instead, although in practice this is usually not tractable.

162

fiEliciting Single-Peaked Preferences Using Comparison Queries

is single-peaked, but the vote f  e  a  d  c  b is not (b and d are on the same side of f
in the positions, and b is closer to f , so d should not be ranked higher than b if f is the peak).
(Throughout, we assume that all preferences are strict, that is, agents are never indifferent
between two alternatives.) Preferences are likely to be single-peaked if the alternatives
positions are of primary importance in determining an agents preferences. For example, in
political elections, if voters preferences are determined primarily by candidates proximity
to their own stance on the left-to-right spectrum, preferences are likely to be single-peaked.
If other factors are also important, such as the perceived amicability of the candidates, then
preferences are not necessarily likely to be single-peaked.
Formally, if an agent with single-peaked preferences prefers a1 to a2 , one of the following
must be true:
 a1 is the agents peak,
 a1 and a2 are on opposite sides of the agents peak, or
 a1 is closer to the peak than a2 .
When all agents preferences are single-peaked (with respect to the same positions for the
alternatives), it is known that there can be no Condorcet cycles. If, in addition, we assume
that the number of agents is odd, then no pairwise election can result in a tie. Hence,
our aggregate ranking can simply correspond to the outcomes of the pairwise elections.
In this case, there is also no incentive for an agent to misreport its preferences, since by
reporting its preferences truthfully, it will, in each pairwise election, rank the alternative
that it prefers higher.
1.2 How Important Are Single-Peaked Preferences?
Before we start developing techniques that deal specifically with single-peaked preferences,
we should consider whether this restricted class of preferences is of any interest. The
concept of single-peaked preferences has been extremely influential in political science: it
is presumably the best-known restriction of preferences there, and it lies at the basis of
much of the analytical work in political science. A thorough discussion is given in the book
Analytical Politics by Hinich and Munger (1997). This book almost immediately jumps
into single-peaked preferences, and argues that, in some form, these models date back to
Aristotle.
In spite of the importance of single-peaked preferences in the (analytical) political science
literature, we are not aware of any empirical studies of how often voters preferences are
actually single-peaked. Some reflection reveals that the answer is probably highly dependent
on the particular election. For example, in an election with a clear left-wing candidate,
a clear centrist candidate, and a clear right-wing candidate, it seems likely that voters
preferences will in fact be single-peaked: in this case, single-peakedness is equivalent to
not ranking the centrist candidate last. However, it is easy to imagine other scenarios
where preferences are not single-peaked. For example, the candidates may lie not on a
one-dimensional spectrum, but in a two-dimensional spacefor instance, a candidate may
be a left-wing candidate in terms of social issues but a right-wing candidate in terms of
economic issues. Unfortunately, it turns out that multidimensional analogues of singlepeaked preferences no longer have the nice properties listed above: Condorcet cycles can
occur once again, and strategic misreporting of preferences again becomes an issue.
163

fiConitzer

It seems that in a political context, there will be some settings where preferences are in
fact single-peaked, some settings in which they are very close to single-peaked (for example,
there may be some voters that take the physical attractiveness of the candidates into account
and as a result have preferences that are not quite single-peaked), and some settings in
which they are really not single-peaked (for example, because it is a truly multidimensional
setting with multiple unrelated issues). We will discuss the generalization of our techniques
to almost single-peaked preferences in Section 6; multidimensional settings are left for
future research.
However, political elections are by no means the only setting of interest, especially
from an AI perspective; and in fact, some other important settings seem to fit the singlepeaked preference model much better. For example, let us again consider the case where the
alternatives are numerical values, such as potential sizes of a budget on which the agents are
deciding. Here, it seems quite reasonable that every agent has a most preferred budget size,
and always prefers sizes closer to her ideal one. In fact, single-peaked preferences seem more
reasonable here than in a political election, where the left-to-right spectrum is merely an
approximation of more complex phenomena; in the case of numerical alternatives, however,
the order on the alternatives is absolute, and this is likely to be reflected in the preferences.
Even in settings where preferences are not necessarily single-peaked, we could simply
require the agents to report single-peaked preferences. The merits of this are somewhat
debatable, because we are now forcing non-single-peaked agents to misreport their preferences. On the other hand, this does have the benefit of avoiding Condorcet cycles (at
least in the reported preferences) so that there is a natural aggregate ranking.2 A related
approach that is sometimes suggested is to frame the issue on which the agents are voting
(that is, choose the set of possible alternatives) in such a way as to make single-peaked
preferences likely; again, the merits of this are debatable.
1.3 Preference Elicitation
A key difficulty in aggregating the preferences of multiple agents is the elicitation of the
agents preferences. In many settings, particularly those with large sets of alternatives,
having each agent communicate all of its preferences is impractical. For one, it can take
up a large amount of communication bandwidth. Perhaps more importantly, in order for
an agent to communicate all of its preferences, it must first determine exactly what those
preferences are. This can be a complex task, especially when no guidance is provided to the
agent as to what the key questions are that it needs to answer to determine its preferences.
An alternative approach is for an elicitor to sequentially ask the agents certain natural
queries about their preferences. For example, the elictor can ask an agent which of two alternatives it prefers (a comparison query). Three natural goals for the elicitor are to (1) learn
enough about the agents preferences to determine the winning alternative, (2) learn enough
to determine the entire aggregate ranking, and (3) learn each agents complete preferences.
(1) and (2) have the advantage that in general, not all of each agents preferences need to be
determined. For example, for (1), the elicitor does not need to elicit an agents preferences
2. Analogously, in combinatorial auctions (where agents can bid on bundles of items instead of just on
individual items) (Cramton et al., 2006), there are often some bundles on which agents are not allowed
to bid, for a variety of reasons. Presumably, this still leads to better results than having a separate
auction for each item.

164

fiEliciting Single-Peaked Preferences Using Comparison Queries

among alternatives for which we have already determined (from the other agents preferences) that they have no chance of winning. But even (3) can have significant benefits over
not doing any elicitation at all (i.e., having each agent communicate all of its preferences
on its own). First, the elicitor provides the agent with a systematic way of assessing its
preferences: all that the agent needs to do is answer simple queries. Second, and perhaps
more importantly, once the elicitor has elicited the preferences of some agents, the elicitor
will have some understanding of which preferences are more likely to occur (and, perhaps,
some understanding of why this is so). The elicitor can then use this understanding to guide
the elicitation of the next agents preferences, and learn these preferences more rapidly.
In this paper, we study the elicitation of single-peaked preferences using only comparison
queries. We mostly focus on approach (3), i.e., learning each agents complete preferences
though we will show in Section 5 that, at least in the worst case, we cannot do much better
if we pursue approach (2), i.e., learning enough about the preferences to determine the
aggregate ranking. In this paper, we do not devote much space to (1), i.e., learning enough
about the preferences to determine the winning alternative. It should be noted that (1) is
a significantly easier objective: it is well known that the (Condorcet) winner is always the
median of the agents most preferred alternatives, so that it suffices to find each agents
most preferred alternative (see the note at the end of Section 5). For most of the paper, we
assume that preferences are always single-peaked (the exception is Section 6 in which we
discuss the case where preferences are usually, but not always, single-peaked).
In Section 3, we study single-peaked preferences in their general form as described in
Subsection 1.1 (also known as ordinally single-peaked preferences, in contrast to the cardinally single-peaked preferences studied later in the paper). We study both the setting where
the elicitor knows the positions of the alternatives (Subsection 3.1), and the setting where
the elicitor (at least initially) does not (Subsection 3.2). Experimental results for this section are provided in Appendix A. Then, in Section 4, we study the more restricted setting
where preferences are cardinally single-peakedthat is, each alternative and each agent has
a cardinal position in R, and agents rank alternatives by distance to their own cardinal position. (To prevent confusion, we emphasize that before Section 4, an alternatives position
only refers to its place in the order of alternatives, not to a real number.) Again, we study
both the setting where the elicitor knows the positions of the alternatives (Subsection 4.1),
and the setting where the elicitor (at least initially) does not (Subsection 4.2). Experimental results for this section are provided in Appendix B. All our elicitation algorithms
completely elicit one agents preferences before moving on to the next agent (as opposed
to going back and forth between agents). This gives the algorithms a nice online property:
if agents arrive over time, then we can elicit an agents preferences when it arrives, after
which the agent is free to leave (as opposed to being forced to wait until the arrival of the
next agent). Especially in the case where our goal is just to find the aggregate ranking,
one may wonder if it can be more efficient to go back and forth between agents. It turns
out that, at least in the worst case, this cannot help (significantly), by a result presented
in Section 5.
The following tables summarize the results in this paper (with the exception of the
experimental results in Appendices A and B, which illustrate how the algorithms perform
on random instances, and the results in Section 6 for preferences that are almost singlepeaked).
165

fiConitzer

ordinal
cardinal

positions known
(m) (Subsection 3.1)
(log m) (Subsection 4.1)

positions unknown
(m) (Subsections 3.1, 3.2)
(m) (Subsections 3.2, 4.2)

Table 1: Number of comparison queries required to fully elicit one agents single-peaked
preferences over m alternatives, in the worst case. For the upper bounds in the positions
unknown column, at least one other agents preferences must be known (otherwise, there
is no restriction on the current agents preferences and hence the answer is (m log m)).

ordinal
cardinal

positions known
(nm) (Subsection 3.1, Section 5)
O(n log m) (Subsection 4.1)

positions unknown
(nm) (Subsection 3.2, Section 5)
(nm) (Subsection 3.2, Section 5)

Table 2: Number of comparison queries required to find the aggregate ranking of m
alternatives for n agents with single-peaked preferences, in the worst case. For the upper
bounds in the positions unknown column, at least one agents preferences must be
known (otherwise, the first agents preferences can be elicited using O(m log m) queries).

2. Related Research and the Case of Unrestricted Preferences
In this section, we first discuss related research; then, we make some basic observations
about eliciting general (not necessarily single-peaked) preferences, which will serve as a
useful baseline for comparison.
2.1 Related Research
Voting techniques are drawing increasing interest from the artificial intelligence community,
especially from multiagent systems researchers. Voting has been used in applications such
as collaborative filtering, for example, by Pennock, Horvitz, and Giles (2000); and planning
among multiple automated agents, for example, by Ephrati and Rosenschein (1991, 1993).
Some key research topics include voting rules that are computationally hard to execute,
for example, by Bartholdi, Tovey, and Trick (1989), Hemaspaandra, Hemaspaandra, and
Rothe (1997), Cohen, Schapire, and Singer (1999), Rothe, Spakowski, and Vogel (2003),
and Conitzer (2006); voting rules that are computationally hard to manipulate by strategic
agents, for example, by Bartholdi and Orlin (1991), Hemaspaandra and Hemaspaandra
(2007), Procaccia and Rosenschein (2007), and Conitzer, Sandholm, and Lang (2007); and
concisely representing preferences in voting (Lang, 2007). Single-peaked preferences have
also been studied from a computational-complexity viewpoint (Walsh, 2007).
166

fiEliciting Single-Peaked Preferences Using Comparison Queries

Preference elicitation is also an important research topic in artificial intelligence; prominent examples of such research include the work of Vu and Haddawy (1997), Chajewska,
Getoor, Norman, and Shahar (1998), Vu and Haddawy (1998), Chajewska, Koller, and Parr
(2000), Boutilier (2002), and Braziunas and Boutilier (2005), and this list is by no means
exhaustive. As for preference elicitation in multiagent systems, a significant body of work focuses on combinatorial auctionsfor an overview of this work, see the chapter by Sandholm
and Boutilier (2006). Much of this work focuses on elicitation approach (1), i.e., learning
enough about the bidders valuations to determine the optimal allocation. Sometimes, additional information must be elicited from the bidders to determine the payments that they
should make according to the Clarke (1971), or more generally, a Groves (1973), mechanism. Example elicitation approaches include ascending combinatorial auctionsfor an
overview, see the chapter by Parkes (2006)as well as frameworks in which the auctioneer
can ask queries in a more flexible way (Conen & Sandholm, 2001). A significant amount of
the research on preference elicitation in combinatorial auctions is also devoted to elicitation
approach (3), i.e. learning an agents complete valuation function. In this research, typically valuation functions are assumed to lie in a restricted class, and given this it is shown
that an agents complete valuation function can be elicited using a polynomial number of
queries of some kind. Various results of this nature have been obtained by Zinkevich, Blum,
and Sandholm (2003), Blum, Jackson, Sandholm, and Zinkevich (2004), Lahaie and Parkes
(2004), and Santi, Conitzer, and Sandholm (2004). The work by Lahaie and Parkes (2004)
also includes results where the goal is only to determine the outcome.

There has also already been some work on preference elicitation in voting (the setting
of this paper). All of the earlier work has focused on elicitation approach (1), eliciting
enough information from the agents to determine the winner, without any restriction on
the space of possible preferences. Conitzer and Sandholm (2002) studied the complexity of
deciding whether enough information has been elicited to declare a winner, as well as the
complexity of choosing which votes to elicit given very strong suspicions about how agents
will vote. They also studied what additional opportunities for strategic misreporting of
preferences elicitation introduces, as well as how to avoid introducing these opportunities.
(Strategic misreporting is not a significant concern in the setting of this paper: under the
restriction of single-peaked preferences, reporting truthfully is a dominant strategy when
agents simultaneously report their complete preferences, and hence responding truthfully
to the elicitors queries is an ex-post equilibrium. As such, in this paper we will make no
distinction between an agents vote and its true preferences.) Conitzer and Sandholm (2005)
studied elicitation algorithms for determining the winner under various voting rules (without
any suspicion about how agents will vote), and gave lower bounds on the worst-case amount
of information that agents must communicate. Most recentlyafter the AAMAS-07 version
of this paper (Conitzer, 2007)the communication complexity of determining the winner
or aggregate ranking in domains with single-peaked preferences has been studied (Escoffier
et al., 2008). The communication-complexity part of that work (which is not the main
contribution of that paper) considers only the ordinal case with known positions, and its
results build on the AAMAS-07 version of this paper, as well as on the communication
complexity paper mentioned above (Conitzer & Sandholm, 2005).
167

fiConitzer

2.2 Eliciting General Preferences
As a basis for comparison, let us first analyze how difficult it is to elicit arbitrary (not
necessarily single-peaked) preferences using comparison queries. We recall that our goal is
to extract the agents complete preferences, i.e., we want to know the agents exact ranking
of all m alternatives. This is exactly the same problem as that of sorting a set of m elements,
when only binary comparisons between elements can be used to do the sorting. This is an
extremely well-studied problem, and it is well-known that it can be solved using O(m log m)
comparisons, for example using the MergeSort algorithm (which splits the set of elements
into two halves, solves each half recursively, and then merges the solutions using a linear
number of comparisons). It is also well-known that (m log m) comparisons are required
(in the worst case). One way to see this is that there are m! possible orders, so that an
order encodes log(m!) bits of informationand log(m!) is (m log m). Hence, in general,
any method for communicating an order (not just methods based on comparison queries)
will require (m log m) bits (in the worst case).
Interestingly, for some common voting rules (including Borda, Copeland, and Ranked
Pairs), it can be shown using techniques from communication complexity theory that even
just determining whether a given alternative is the winner requires the communication of
(nm log m) bits (in the worst case), where n is the number of agents (Conitzer & Sandholm,
2005). That is, even if we do not try to elicit agents complete preferences, (in the worst
case) it is impossible to do more than a constant factor better than having each agent
communicate all of its preferences! These lower bounds even hold for nondeterministic
communication, but they do assume that preferences are unrestricted. In contrast, by
assuming that preferences are single-peaked, we can elicit an agents complete preferences
using only O(m) queries, as we will show in this paper. Of course, once we know the agents
complete preferences, we can execute any voting rule. This shows how useful it can be for
elicitation to know that agents preferences lie in a restricted class.

3. Eliciting Ordinally Single-Peaked Preferences
In this section, we study the elicitation of ordinally single-peaked preferences (the general
form of single-peaked preferences as described in Subsection 1.1, in contrast to cardinally
single-peaked preferences, which we study in Section 4). We first study the case where the
alternatives positions are known (Subsection 3.1), and then the case where they are not
known (Subsection 3.2). Experimental results for the algorithms in this section are given in
Appendix A; these results give some idea of how the algorithms behave on randomly drawn
instances, rather than in the worst case.
3.1 Eliciting with Knowledge of Alternatives Ordinal Positions
In this subsection, we focus on the setting where the elicitor knows the positions of the
alternatives. Let p : {1, . . . , m}  A denote the mapping from positions to alternatives,
i.e., p(1) is the leftmost alternative, p(2) is the alternative immediately to the right of
p(1), . . ., and p(m) is the rightmost alternative. Our algorithms make calls to the function
Query(a1 , a2 ), which returns true if the agent whose preferences we are currently eliciting
168

fiEliciting Single-Peaked Preferences Using Comparison Queries

prefers a1 to a2 , and false otherwise. (Since one agents preferences are elicited at a time,
we need not specify which agent is being queried.)
The first algorithm serves to find the agents peak (most preferred alternative). The
basic idea of this algorithm is to do a binary search for the peak. To do so, we need to
be able to assess whether the peak is to the left or right of a given alternative a. We can
discover this by asking whether the alternative immediately to the right of a is preferred to
a: if it is, then the peak must be to the right of a, otherwise, the peak must be to the left
of, or equal to, a.

FindPeakGivenPositions(p)
l1
rm
while l < r {
m1  (l + r)/2
m2  m1 + 1
if Query(p(m1 ), p(m2 ))
r  m1
else
l  m2
}
return l

Once we have found the peak, we can continue to construct the agents ranking of the
alternatives as follows. We know that the agents second-ranked alternative must be either
the alternative immediately to the left of the peak, or the one immediately to the right. A
single query will settle which one is preferred. Without loss of generality, suppose the left
alternative was preferred. Then, the third-ranked alternative must be either the alternative
immediately to the left of the second-ranked alternative, or the alternative immediately to
the right of the peak. Again, a single query will sufficeetc. Once we have determined the
ranking of either the leftmost or the rightmost alternative, we can construct the remainder of
the ranking without asking any more queries (by simply ranking the remaining alternatives
according to proximity to the peak). The algorithm is formalized below. It uses the function
Append(a1 , a2 ), which makes a1 the alternative that immediately succeeds a2 in the current
ranking (i.e., the current agents preferences as far as we have constructed them). In the
pseudocode, we will omit the (simple) details of maintaining such a ranking as a linked list.
The algorithm returns the highest-ranked alternative; this is to be interpreted as including
the linked-list structure, so that effectively the entire ranking is returned. c is always the
alternative that is ranked last among the currently ranked alternatives.
169

fiConitzer

FindRankingGivenPositions(p)
t  FindPeakGivenPositions(p)
s  p(t)
l t1
r t+1
cs
while l  1 and r  m {
if Query(p(l), p(r)) {
Append(p(l), c)
c  p(l)
l l1
} else {
Append(p(r), c)
c  p(r)
r r+1
}
}
while l  1 {
Append(p(l), c)
c  p(l)
l l1
}
while r  m {
Append(p(r), c)
c  p(r)
r r+1
}
return s

Theorem 1 FindRankingGivenPositions correctly determines an agents preferences, using
at most m  2 + log m comparison queries.
Proof: Correctness follows from the arguments given above. FindPeakGivenPositions requires at most log m comparison queries. Every query after this allows us to add an
additional alternative to the ranking, and for the last alternative we will not need a query,
hence there can be at most m  2 additional queries. 
Thus, the number of queries that the algorithm requires is linear in the number of
alternatives. It is impossible to succeed using a sublinear number of queries, because an
agents single-peaked preferences can encode a linear number of bits, as follows. Suppose
the alternatives positions are as follows: am1 < am3 < am5 < . . . < a4 < a2 < a1 <
a3 < a5 < . . . < am4 < am2 < am . Then, any vote of the form a1  {a2 , a3 } 
{a4 , a5 }  . . .  {am1 , am } (where the set notation indicates that there is no constraint on
170

fiEliciting Single-Peaked Preferences Using Comparison Queries

the preference between the alternatives in the set, that is, {ai , ai+1 } can be replaced either
by ai  ai+1 or ai+1  ai ) is single-peaked with respect to the alternatives positions. The
agents preference between alternatives ai and ai+1 (for even i) encodes a single bit, hence
the agents complete preferences encode (m  1)/2 bits. Since the answer to a comparison
query can communicate only a single bit of information, it follows that a linear number of
queries is in fact necessary.
3.2 Eliciting without Knowledge of Alternatives Ordinal Positions
In this subsection, we study a more difficult question: how hard is it to elicit the agents
preferences when the alternatives positions are not known? Certainly, it would be desirable to have elicitor software that does not require us to enter domain-specific information
(namely, the positions of the alternatives) before elicitation begins, for two reasons: (1) this
information may not be available to the entity running the election, and (2) entering this
information may be perceived by agents as unduly influencing the process, and perhaps the
outcome, of the election. Rather, the software should learn (relevant) information about
the domain from the elicitation process itself.
It is clear that this learning will have to take place over the process of eliciting the
preferences of multiple agents. Specifically, without any knowledge of the positions of the
alternatives, the first agents preferences could be any ranking of the alternatives, since any
ranking is single-peaked with respect to some positions. Hence, eliciting the first agents
preferences will require (m log m) queries. Once the elicitor knows the first agents preferences, though, some ways in which the alternatives may be positioned will be eliminated
(but many will remain).
Can the elicitor learn the exact positions of the alternatives? The answer is no, for several
reasons. First of all, we can invert the positions of the alternatives, making the leftmost
alternative the rightmost, etc., without affecting which preferences are single-peaked with
respect to these positions. This is not a fundamental problem because the elicitor could
choose either one of the positionings. More significantly, the agents preferences may simply
not give the elicitor enough information to determine the positions. For example, if all
agents turn out to have the same preferences, the elicitor will never learn anything about
the alternatives positions beyond what was learned from the first agent. In this case,
however, the elicitor could simply try to verify that the next agent whose preferences are
to be elicited has the same preferences, which can be done using only a linear number of
queries. More generally, one might imagine an intricate elicitation scheme which either
requires few queries to elicit an agents preferences, or learns something new and useful
from these preferences that will shorten the elicitation process for later agents. Then, one
might imagine a complex accounting scheme, in the spirit of amortized analysis, showing
that the total elicitation cost over many agents cannot be too large.
Fortunately, it turns out that we do not need anything so complex. In fact, knowing even
one agents (complete) preferences is enough to elicit any other agents preferences using
only a linear number of queries! (And a sublinear number will not suffice, since we already
showed that a linear number is necessary even if we know the alternatives positions. Hence,
no matter how many agents preferences we already know, we will always require linearly
many queries for the next agent.) To prove this, we will give an elicitation algorithm that
171

fiConitzer

takes as input one (the first) agents preferences (not the positions of the alternatives), and
elicits another agents preferences using a linear number of queries. Of course, the algorithm
can still be applied when we already know the preferences of more than one agent; in that
case, we can use the preferences of any one of those agents as input. In the worst case,
knowing the preferences of more than one agent will not help us, because it may be that
all of those agents have the same preferences, in which case this does not teach us anything
about the alternatives positions beyond what we learned from the first agent. In general
(not in the worst case), we may be able to learn something from the additional agents
preferences; however, at best, we learn the alternatives positions exactly, and even in that
case we still need a linear number of queries. Hence, in this paper, we do not investigate
how we can use the known preferences of multiple agents.
First, we need a subroutine for finding the agents peak. We cannot use the algorithm
FindPeakGivenPositions from the previous subsection, since we do not know the positions.
However, even the trivial algorithm that examines the alternatives one by one and maintains
the most preferred alternative so far requires only a linear number of queries, so we will
simply use this algorithm.

FindPeak()
s  a1
for all a  {a2 , . . . , am }
if Query(a, s)
sa
return s

Once we have found the agents peak, we next find the alternatives that lie between
this peak, and the peak of the known vote (i.e., the peak of the agent whose preferences we
know). The following lemma is the key tool for doing so.
Lemma 1 Consider votes v1 and v2 with peaks s1 and s2 , respectively. Then, an alternative
a
/ {s1 , s2 } lies between the two peaks if and only if both a v1 s2 and a v2 s1 .
Proof: If a lies between the two peaks, then for each i, a lies closer to si than s3i (the
other votes peak) lies to si . Hence a v1 s2 and a v2 s1 . Conversely, a vi s3i implies
that a lies on the same side of s3i as si (otherwise, vi would have ranked s3i higher). But
since this is true for both i, it implies that a must lie between the peaks.

Thus, to find the alternatives between the peak of the known vote and the peak of the
current agent, we simply ask the current agent, for each alternative that the known vote
prefers to the peak of the current agent, whether it prefers this alternative to the known
votes peak. If the answer is positive, we add the alternative to the list of alternatives
between the peaks.
The two votes must rank the alternatives between their peaks in the exact opposite
order. Thus, at this point, we know the current agents preferences over the alternatives
172

fiEliciting Single-Peaked Preferences Using Comparison Queries

that lie between its peak and the peak of the known vote (including the peaks themselves).
The final and most complex step is to integrate the remaining alternatives into this ranking.
(Some of these remaining alternatives may be ranked higher than some of the alternatives
between the peaks.) The strategy will be to integrate these alternatives into the current
ranking one by one, in the order in which the known vote ranks them, starting with the
one that the known vote ranks highest. When integrating such an alternative, we first have
the current agent compare it to the worst-ranked alternative already in the ranking. We
note that the known vote must prefer the latter alternative, because this latter alternative
is either the known votes peak, or an alternative that we integrated earlier and that was
hence preferred by the known vote. If the latter alternative is also preferred by the current
agent, we add the new alternative to the bottom of the current ranking and move on to
the next alternative. If not, then we learn something useful about the positions of the
alternatives, namely that the new alternative lies on the other side of the current agents
peak from the alternative currently ranked last. The following lemma proves this. In it, v1
takes the role of the known vote, v2 takes the role of the agent whose preferences we are
currently eliciting, a1 takes the role of the alternative currently ranked last by the current
agent, and a2 takes the role of the alternative that we are currently integrating.
Lemma 2 Consider votes v1 and v2 with peaks s1 and s2 , respectively. Consider two alternatives a1 , a2 6= s2 that do not lie between s1 and s2 . Suppose a1 v1 a2 and a2 v2 a1 .
Then, a1 and a2 must lie on opposite sides of s2 .
Proof: If a1 and a2 lie on the same side of s2 without loss of generality, the left side
then, because neither lies between s1 and s2 , they must also both lie on the left side of s1
(possibly, one of them is equal to s1 ). But then, v1 and v2 cannot disagree on which of a1
and a2 is ranked higher.

For the purpose of integrating this new alternative, knowing that it is on the other side
from the alternative currently ranked last is not that helpful. In fact, if we reach this point
in the algorithm, we will simply start comparing the new alternative to the alternatives
that are already in the ranking, one by one. The benefit of knowing that it is on the other
side is that it will make later alternatives easier to integrate: specifically, once we have
integrated the new alternative, we know that all alternatives that we integrate later must
end up ranked below this alternative. This is because of the following lemma, in which v1
takes the role of the known vote, v2 takes the role of the agent whose preferences we are
currently eliciting, a1 takes the role of the alternative currently ranked last by the current
agent, a2 takes the role of the alternative that we are currently integrating, and a3 takes
the role of an alternative to be integrated later.
Lemma 3 Consider votes v1 and v2 with peaks s1 and s2 , respectively. Consider three
alternatives a1 , a2 , a3 6= s2 that do not lie between s1 and s2 . Suppose a1 v1 a2 v1 a3 ,
and a2 v2 a1 . Then, a2 v2 a3 .
Proof: By Lemma 2, we know that a1 and a2 must lie on opposite sides of s2 . Moreover,
because they do not lie between s1 and s2 , and are not equal to s2 , they must also lie on
opposite sides of s1 (with the additional possibility that a1 = s1 ). Because a1 v1 a2 v1 a3 ,
173

fiConitzer

it follows that either a3 lies on the same side of the peaks as a2 , but further away; or on the
same side as a1 , but further away. In the former case, we immediately obtain a2 v2 a3 ; in
the latter case, we have a1 v2 a3 , which implies a2 v2 a3 because a2 v2 a1 .

Based on this observation, in the algorithm, we let c1 be the alternative for which we
know that all later alternatives that we integrate will end up ranked below it. (In a sense,
c1 takes the role of a2 in the above lemmas.) We also keep track of c2 , the alternative
currently ranked last. (In a sense, c2 takes the role of a1 in the above lemmas.) Then, when
we integrate a new alternative, first we compare it to c2 ; if it is ranked below c2 , then we
place it below c2 , and make it the new c2 . If it is ranked above c2 , then we compare it to
the successor of c1 ; if it is ranked below that, then we compare it to the successor of the
successor; and so on, until we find its place; finally, we make it the new c1 . While this last
stage may require up to a linear number of queries, the key observation is that each time
we ask such a query, c1 moves down in the ranking by one place. Hence, the total number
of such queries that we can ask (summing over all alternatives that we integrate) is at most
m  1, because c1 can move down at most m  1 times; and this is why we can get the linear
bound on the number of queries.
Example 1 Suppose the alternatives positions are e < c < b < f < a < d. Also suppose
that the known vote is a  d  f  b  c  e, and the preferences of the agent that we
are currently eliciting are c  e  b  f  a  d. The algorithm will proceed as follows.
First, FindPeak will identify c as the current agents peak. Now, the alternatives that the
known vote prefers to c are a (the known votes peak), as well as d, f, b. For each of the last
three alternatives, the algorithm queries the current agent whether it is preferred to a. The
answer will be positive (only) for b and f , so we know that these two alternatives must lie
between the peaks a and c on the line (and hence must be ranked oppositely by the known
vote and the current agent). At this point, we know that the current agent must prefer
c  b  f  a, and the algorithm must integrate d and e into this ranking. We set c1 = c
and c2 = a. The algorithm first integrates d since it is ranked higher than e in the known
vote. The algorithm queries the agent with d and c2 = a, and a is preferred. Now we know
that the current agent must prefer c  b  f  a  d, and the algorithm sets c2 = d.
Finally, the algorithm must integrate e. The algorithm queries the agent with e and c2 = d,
and e is preferred. The algorithm then queries the agent with e and the successor of c1 ,
which is b. e is preferred, so the algorithm inserts e between c1 = c and b, and sets c1 = e.
At this point we know the entire ranking c  e  b  f  a  d.
We now present the algorithm formally. The algorithm again uses the function
Append(a1 , a2 ), which makes a1 the alternative that immediately succeeds a2 in the current
ranking. It also uses the function InsertBetween(a1 , a2 , a3 ), which inserts a1 between a2 and
a3 in the current ranking. The algorithm will (eventually) set m(a) to true if a lies between
the peaks of the current agent and the known vote v, or if a is the peak of v; otherwise,
m(a) is set to false. v(i) returns the alternative that the known vote ranks ith (and hence
v 1 (a) returns the ranking of alternative a in the known vote, and v 1 (a1 ) < v 1 (a2 ) means
that v prefers a1 to a2 ). n(a) returns the alternative immediately following a in the current
ranking. Again, only the peak is returned, but this includes the linked-list structure and
hence the entire ranking.
174

fiEliciting Single-Peaked Preferences Using Comparison Queries

FindRankingGivenOtherVote(v)
s  FindPeak()
for all a  A
m(a)  false
for all a  A  {s, v(1)}
if v 1 (a) < v 1 (s)
if Query(a, v(1))
m(a)  true
c1  s
c2  s
m(v(1))  true
for i = m to 1 step 1 {
if m(v(i)) = true {
Append(v(i), c2 )
c2  v(i)
}
}
for i = 1 to m
if not (m(v(i)) or v(i) = s)
if Query(c2 , v(i)) {
Append(v(i), c2 )
c2  v(i)
} else {
while Query(n(c1 ), v(i))
c1  n(c1 )
InsertBetween(v(i), c1 , n(c1 ))
c1  v(i)
}
return s

Theorem 2 FindRankingGivenOtherVote correctly determines an agents preferences, using
at most 4m  6 comparison queries.
Proof: Correctness follows from the arguments given above. FindPeak requires m  1
comparison queries. The next stage, discovering which alternatives lie between the current
agents peak and the known votes peak, requires at most m  2 queries. Finally, we
must count the number of queries in the integration step. This is more complex, because
integrating one alternative (which we may have to do up to m  2 times) can require
multiple queries. Certainly, the algorithm will ask the agent to compare the alternative
currently being integrated to the current c2 . This contributes up to m  2 queries in
total. However, if the current alternative is preferred over c2 , we must ask more queries,
comparing the current alternative to the alternative currently ranked immediately behind
the current c1 (perhaps multiple times). But every time that we ask such a query, c1
175

fiConitzer

changes to another alternative, and this can happen at most m  1 times in total. It follows
that the total number of such queries that we ask (summed over all the alternatives that
we integrate) is at most m  1. Adding up all of these bounds, we get a total bound of
(m  1) + (m  2) + (m  2) + (m  1) = 4m  6.

Of course, it is impossible to succeed with a sublinear number of queries, for the same
reason as in Subsection 3.1. In practice, the algorithm ends up requiring on average roughly
3m queries, as can be seen in Appendix A.

4. Eliciting Cardinally Single-Peaked Preferences
In this section, we restrict the space of allowed preferences slightly further. We assume
that each alternative a has a cardinal position r(a)  R (as opposed to the merely ordinal
positions that we have considered up to this point in the paper, which do not provide a
distance function over the alternatives). We have already mentioned some examples for
which this is reasonable: agents can be voting over a budget, or over a location along a
road (in which case an alternatives cardinal position equals its distance from the beginning
of the road). Even when the alternatives are political candidates, it may be reasonable for
them to have cardinal positions: for example, if the candidates have voting records, then
a candidates cardinal position can be the percentage of times that she cast a right-wing
vote. Additionally, we assume that every agent also has a cardinal position r, and that it
ranks the alternatives in order of proximity to its own position. That is, the agent sorts the
alternatives according to |r  r(a)| (preferring the closer ones). Such preferences are known
as cardinally single-peaked preferences (again, as opposed to the ordinally single-peaked
preferences that we have considered up to this point) (Brams et al., 2002, 2005).3
Cardinally single-peaked preferences are always ordinally single-peaked as well (with
respect to the order < defined by a < a  r(a) < r(a )), but the converse does not hold:
it is possible for agents preferences to be ordinally single-peaked, but not cardinally singlepeaked. That is, it is possible that all agents preferences are consistent with a single order of
the alternatives, but that there is no way to assign cardinal positions to the alternatives and
the agents so that the agents preferences are given by ranking the alternatives according
to proximity to their own cardinal position. The following example shows this:
Example 2 Suppose agent 1 prefers a  b  c  d, agent 2 prefers b  c  d  a, agent
3 prefers c  b  a  d. These preferences are all consistent with the order a < b < c < d,
so they are ordinally single-peaked. Nevertheless, there are no cardinal positions with which
they are consistent. We prove this by contradiction: let us suppose there were such cardinal
positions. a and d are both sometimes ranked last, which implies they must be the leftmost
and rightmost alternatives (without loss of generality, suppose a is the leftmost alternative).
Agent 1s preferences then imply that the order must be a < b < c < d. For i  {1, 2, 3}, let
r(i) be agent is cardinal position. By the agents preferences, we must have |r(2)  r(d)| <
|r(2)  r(a)| and |r(3)  r(d)| > |r(3)  r(a)|. Therefore, it must be that r(2) > r(3). On
3. To be precise, Brams, Jones, and Kilgour (2002; 2005) consider settings where the agents and the
alternatives coincide, so that each agent has the exact same position as one of the alternatives; but the
above extension to where this is not the case is quite obvious. In fact, Brams et al. (2002) explicitly
mention separating the agents and alternatives as an extension.

176

fiEliciting Single-Peaked Preferences Using Comparison Queries

the other hand, we must have |r(2)  r(b)| < |r(2)  r(c)| and |r(3)  r(b)| > |r(3)  r(c)|.
Therefore, it must be that r(2) < r(3)but now we have a contradiction. Hence the above
profile of preferences is not cardinally single-peaked.
A similar example is given by Brams et al. (2002)in fact, the preferences in the above
example are a proper subset of the ones used in their examplealthough in their proof that
the examples preferences are not cardinally single-peaked, they make use of the fact that
agents and alternatives coincide in their model, which simplifies the argument somewhat.
So, the restriction to cardinally single-peaked preferences does come at a loss in what
preferences we can represent. In particular, it should be emphasized that even if alternatives
correspond to numerical values, it may very well still be the case that preferences are
ordinally, but not cardinally, single-peaked. For example, if agents are voting over a budget
for a project, then one agents preferences might be that the budget should definitely not
go above 500 (perhaps because then it starts coming at the cost of another project that
the agent cares about); but as long as this constraint is met, then the budget should be as
large as possible. Hence, the agents preferences would be 500  499  498  . . .  1 
0  501  502  . . ., so they would be ordinally, but not cardinally, single-peaked. Thus,
cardinally single-peaked preferences are strictly less likely to occur in practice than ordinally
single-peaked preferences; nevertheless, cardinally single-peaked preferences (or something
very close to it) may well occur in practice. For example, when the agents are voting over
the location of a project along a road, they are likely to rank the locations simply by the
distance to their own positions along the road. A more detailed discussion of the symmetry
assumption inherent in cardinally single-peaked preferences is given by Hinich and Munger
(1997).
Just as we did for ordinally single-peaked preferences, we first study the case where
the alternatives cardinal positions are known (Subsection 4.1), and then the case where
they are not known (Subsection 4.2). Experimental results for known cardinal positions
are given in Appendix B; these results give some idea of how the algorithm behaves on
randomly drawn instances, rather than in the worst case. (We have no experimental results
for unknown cardinal positions, because we only have a negative result there.)
4.1 Eliciting with Knowledge of Alternatives Cardinal Positions
In this subsection, we show that if preferences are cardinally single-peaked, and in addition
the cardinal positions of the alternatives are known, then there is a preference elicitation
algorithm that uses only a logarithmic number of comparison queries per agent. At a high
level, the algorithm works as follows. For each pair of alternatives a, a (r(a) < r(a )),
consider their midpoint m(a, a ) = (r(a) + r(a ))/2. Now, if an agent prefers a to a , that
agents position r must be smaller than m(a, a ); otherwise, r > m(a, a ). (As before, we
assume that there are no ties, so r 6= m(a, a ).) So, using a single comparison query, we can
determine whether an agents position is to the left or to the right of a particular midpoint.
This allows us to do a binary search on the midpoints. (As an aside, if we know that each
agents position coincides with the position of one of the alternatives, then we can do a
binary search on the alternatives to find the agents position, using FindPeakGivenPositions.
But because this is not the case in general, we need to do a binary search over the midpoints instead.) In the end, we will know the two adjacent midpoints between which the
177

fiConitzer

agents position lies, which is sufficient to determine its preferences. The following example
illustrates this.
Example 3 Suppose that the alternatives cardinal positions (which are known to the algorithm) are as follows: r(a) = .46, r(b) = .92, r(c) = .42, r(d) = .78, r(e) = .02. Also suppose
that the agent whose preferences we are eliciting has cardinal position r = .52 (which is not
known to the algorithm), so that its preferences are a  c  d  b  e. The midpoints are,
in order: m(c, e) = .22, m(a, e) = .24, m(d, e) = .40, m(a, c) = .44, m(b, e) = .47, m(c, d) =
.60, m(a, d) = .62, m(b, c) = .67, m(a, b) = .69, m(b, d) = .85. Since the 5th midpoint (out
of 10) is m(b, e) = .47, the algorithm first queries the agent whether it prefers b to e. The
agent prefers b, so the algorithm can conclude r > .47 (since r(b) > r(e)). The 7th midpoint
is m(a, d) = .62, so the algorithm next queries the agent whether it prefers a to d. The agent
prefers a, so the algorithm can conclude r < .62. Finally, the 6th midpoint is m(c, d) = .60,
so the algorithm next queries the agent whether it prefers c to d. The agent prefers c, so
the algorithm can conclude r < .60. Now the algorithm knows that .47 < r < .60, and since
there are no midpoints in this range, this is sufficient to deduce that the agents preferences
are a  c  d  b  e.
The precise algorithm follows.

FindRankingGivenCardinalPositions(r)
S
for all a, a such that r(a) < r(a )
S  S  {(a, a , (r(a) + r(a ))/2)}
sort S by the 3rd entry to obtain S = {(ai , ai , mi )}1i(m)
2
l0 
u m
2 +1
while l + 1 < u {
h  (l + u)/2
if Query(ah , ah )
uh
else
lh
}
r  (ml + mu )/2
return alternatives sorted by |r(a)  r|

Theorem 3 FindRankingGivenCardinalPositions correctly determines an agents preferences,
using at most 2log(m) comparison queries.
Proof: Correctness follows from the arguments given above. Let us consider the expression
u  l  1, the number of midpoints strictly between the lth and the uth. This expression starts out at m
2 , and is (at least) halved by each query. Once it reaches 0, no
178

fiEliciting Single-Peaked Preferences Using Comparison Queries


more queries
will be asked. Therefore, at most log( m
2 ) + 1 queries are required. But

2
log( m
2 ) = log(m(m  1)/2) = log(m(m  1))  1 < log(m )  1 = 2 log(m)  1. Hence
FindRankingGivenCardinalPositions requires at most 2log(m) comparison queries.


This algorithm does require us to store and manage all m
2 midpoints, and because of
this it does not scale computationally to extremely large numbers of alternatives, unlike the
previous algorithms. It is important to remember here that elicitation cost (as measured
by the number of comparison queries) is a different type of cost from computational cost.
Typically, the constraints on elicitation are much more severe than those on computation.
If the agent is a human, then the number of queries that she is willing to answer is likely
to be very low. Even if the agent is a software agent, to answer a query, it may have to
solve a hard computational problem. There are also other reasons why agents (human or
software) may wish to keep the number of queries that they answer to a minimum: for
example, if they are concerned about privacy, they may worry that answering more queries
leaves them more exposed to a malevolent party intercepting their answers. Therefore, it
is typically much more important for an elicitation algorithm to ask few queries than it is
for it to be computationally very efficient. Nevertheless, in the rare settings where queries
are very easily answered (presumably by a software agent), other (privacy) issues do not
come into play, and the number of alternatives is very large, the computational constraint
may be binding. In this case, the earlier FindRankingGivenPositions may be the preferred
algorithm.
There is also an (log m) lower bound: for example, even if the agents positions coincide with the alternatives positions, and even without any restrictions on the type of
communication (queries), an agent needs to communicate (log m) bits to identify which
of the m alternatives is her most preferred alternative.
4.2 Eliciting without Knowledge of Alternatives Cardinal Positions
We now consider the case in which preferences are cardinally single-peaked, but the alternatives cardinal positions are not known (at the beginning). Just as in the case of
ordinally single-peaked preferences, if we do not know the alternatives positions, then the
first agents preferences can be arbitrary and will hence require (m log m) queries to elicit.
On the other hand, if we already know one agents preferences, then we can use the algorithm for ordinally single-peaked preferences to elicit the next agents preferences using only
O(m) queries, because cardinally single-peaked preferences are a special case of ordinally
single-peaked preferences. However, since we are now considering cardinally single-peaked
preferences, we may hope to do better than an O(m) bound: after all, we saw that if the
cardinal positions are known, then only O(log m) queries are required per agent. So, we
might hope that after eliciting some number of agents preferences, we will have learned
enough about the cardinal positions of the alternatives that we can elicit the next agents
preferences using only O(log m) queries, or at the very least using a sublinear number of
queries. Unfortunately, it turns out that this is not possible: the following result gives an
(nm) lower bound on the number of queries necessary to elicit n agents preferences. (The
result is phrased so that it also applies to ordinally single-peaked preferences, in that case
even if the (ordinal) positions are known.)
179

fiConitzer

Theorem 4 Suppose there are n agents and m alternatives (where m is even), and the
agents preferences are known to be cardinally single-peaked, but the alternatives positions
are not known. Then, to elicit all the agents preferences exactly, in the worst case, at least
nm/2 comparison queries are necessary.
Remarks: This remains true even if the alternatives ordinal positions are known at the beginningmore
specifically, even if each alternatives cardinal position is known at the beginning to lie in a certain interval,
and these intervals do not overlap. It also remains true if (in addition) agents do not need to be queried in
orderthat is, it is possible to ask agent 1 some queries first, then agent 2, and then return to agent 1, etc.

Proof: Suppose that alternative ai (with i  {1, . . . , m}) is known (from the beginning) to
lie in the interval [ki  1, ki + 1], where ki = 10  (1)i (i + 1)/2. That is, k1 = 10, k2 =
10, k3 = 20, k4 = 20, k5 = 30, etc. Moreover, suppose that each agents position is
known (from the beginning) to lie in the interval [1, 1]. It is then clear that each agent js
preferences will have the form {a1 , a2 } j {a3 , a4 } j {a5 , a6 } j . . . j {am1 , am } (where
the set notation indicates that it is not clear which of the two is preferred). Certainly, it
is sufficient to ask each agent, for every i  {1, 3, 5, . . . , m  1}, whether ai is preferred
to ai+1 . The total number of queries would then be nm/2 (and we can ask them in any
order). What we need to show, however, is that in the worst case, all of these queries are
also necessary. To see why, suppose that the answer to every one of these queries that we
ask is ai j ai+1 (the odd-numbered alternative is preferred). (This is certainly possible:
for example, it may be that every alternative ai is at position ki , and every agent is at
1.) Then, to be absolutely sure about every agents complete preferences, we must ask
every one of these queries, for the following reason. Suppose we have asked all queries but
one: for some j and odd i, we have not yet asked agent j whether j prefers ai or ai+1 .
We must show that it is still possible that ai+1 j ai . To see how this is possible, suppose
that every agent j  with j  6= j is at position 1; j is at position 0.1; every alternative
ai for i 6= i is at position ki ; and ai is at position ki  1. It is easy to see that with
these positions, for any i  {1, 3, 5, . . . , m  1} \ {i}, for any agent j  (including j), we
have ai j  ai +1 . Moreover, even for i, for any agent j  6= j, we have ai j  ai+1 : this
is because |(ki  1)  (1)| = 10(i + 1)/2, and |ki+1  (1)| = 10(i + 1)/2 + 1. That
means that these positions are consistent with all the answers to queries so far. However,
with these positions, ai+1 j ai : this is because |(ki  1)  (0.1)| = 10(i + 1)/2 + .9, and
|ki+1  (0.1)| = 10(i + 1)/2 + 0.1. Hence, we must ask the last query.


5. Determining the Aggregate Ranking Only
So far, our goal has been to determine each agents complete preferences. While it is
desirable to have all this preference information, it is not always necessary. For example, our
goal may simply be to determine the aggregate ranking of the alternatives. (We recall from
the introduction that for single-peaked preferences, there will be no Condorcet cycles, so
that the natural aggregate ranking is determined by the outcomes of the pairwise elections
assuming the number of agents is odd.) For this purpose, it is certainly sufficient to elicit
each agents preferences completely, but it is not clear that it is necessary. So, while
Theorem 4 gives us an (nm) lower bound for elicting all agents preferences completely
180

fiEliciting Single-Peaked Preferences Using Comparison Queries

in the unknown cardinal positions case (and also in the known ordinal positions case), it
is not immediately clear that such a lower bound also holds when we are merely trying to
determine the aggregate ranking. Unfortunately, it turns out that there is still an (nm)
lower bound in this case (under the same conditions as in Theorem 4). Hence, it is not
possible to get away with o(nm) querieswith the exception of the case of known cardinal
positions, which is the only case to which this lower bound does not apply, and where we in
fact only need O(n log m) queries to determine all agents preferences completely (by using
the algorithm from Subsection 4.1 for each agent).
Theorem 5 Suppose there are n agents and m alternatives (where n is odd and m is even),
and the agents preferences are known to be cardinally single-peaked, but the alternatives
positions are not known. Then, to determine the aggregate ranking, in the worst case, at
least (n + 1)m/4 comparison queries are necessary.
Remarks: This remains true even if the alternatives ordinal positions are known at the beginningmore
specifically, even if each alternatives cardinal position is known at the beginning to lie in a certain interval,
and these intervals do not overlap. It also remains true if (in addition) agents do not need to be queried in
orderthat is, it is possible to ask agent 1 some queries first, then agent 2, and then return to agent 1, etc.

Proof: The proof reuses much of the structure of the proof of Theorem 4. Again, we
suppose that alternative ai (with i  {1, . . . , m}) is known (from the beginning) to lie in
the interval [ki  1, ki + 1], where ki = 10  (1)i (i + 1)/2. That is, k1 = 10, k2 = 10, k3 =
20, k4 = 20, k5 = 30, etc. Moreover, again, we suppose that each agents position is
known (from the beginning) to lie in the interval [1, 1]. Again, it is clear that each agent
js preferences will have the form {a1 , a2 } j {a3 , a4 } j {a5 , a6 } j . . . j {am1 , am }
(where the set notation indicates that it is not clear which of the two is preferred). More
relevantly for this theorem, the aggregate ranking must also have this form. Hence, all that
we need to determine is, for every i  {1, 3, 5, . . . , m  1}, whether more agents prefer ai
to ai+1 , or vice versa. We will show that in the worst case, for each of these m/2 pairwise
elections, we need to query at least (n+1)/2 agents, thereby proving the theorem. As in the
proof of Theorem 4, we suppose that the answer to every one of these queries that we ask
is ai j ai+1 (the odd-numbered alternative is preferred). Then, certainly it is sufficient to,
for every i  {1, 3, 5, . . . , m  1}, query (any) (n + 1)/2 agents about ai vs. ai+1 , which will
result in a majority for ai . But it is also necessary to ask this many queries for each of these
pairwise elections, for the following reasons. Suppose that for some i  {1, 3, 5, . . . , m  1},
we have queried only (n  1)/2 agents about ai vs. ai+1 . Then, even if for all of the other
pairwise elections, we have asked all queries, it is still possible that ai+1 defeats ai in the
pairwise election. The reason is similar to that in the proof of Theorem 4: let J be the set
of agents that have already been asked about ai vs. ai+1 . Suppose that every agent j  with
j   J is at position 1; every j 
/ J is at position 0.1; every alternative ai for i 6= i is at
position ki ; and ai is at position ki  1. It is easy to see that with these positions, for any
i  {1, 3, 5, . . . , m  1} \ {i}, for any agent j  (including agents both in J and outside J),
we have ai j  ai +1 . Moreover, even for i, for any agent j   J, we have ai j  ai+1 : this is
because |(ki  1)  (1)| = 10(i + 1)/2, and |ki+1  (1)| = 10(i + 1)/2 + 1. That means that
these positions are consistent with all the answers to queries so far. However, with these
181

fiConitzer

positions, for any j 
/ J, ai+1 j ai : this is because |(ki  1)  (0.1)| = 10(i + 1)/2 + .9,
and |ki+1  (0.1)| = 10(i + 1)/2 + 0.1. Hence, for these positions, ai+1 defeats ai in the
pairwise election. So, to rule this out, we need to ask at least one more query.

In contrast, if we are even less ambitious and our only goal is to determine the winner
(the top-ranked alternative in the aggregate ranking), then we only need to know each
agents peak: it is well known that the winner will be the median of these peaks (if the
same alternative is the peak for multiple agents, then this alternative is counted multiple
times in the calculation of the median). If we know at least the ordinal positions, then we
can use FindPeakGivenPositions to do this using O(log m) queries per agent.

6. Robustness to Slight Deviations from Single-Peakedness
So far, we have assumed that the agents preferences are always (at least ordinally, and in
some cases cardinally) single-peaked. In this section, we consider the possibility that the
agents preferences are close to single-peaked, but not quite. This is easy to imagine in a
political election: for example, if one of the candidates happens to be a close friend of the
agent, then the agent might place this candidate high in her ranking even if they are on
opposite ends of the political spectrum.
Before we get into detail on this, we should keep in mind that the case where all agents
preferences are (completely) single-peakedthe case studied before this sectionis still
important. While in a political election, it is likely that there are some deviations from
single-peakedness (due to, for example, candidates charisma or their positions on issues
unrelated to the left-right spectrum), in other settings this seems significantly less likely.
For example, if the agents are voting over numerical alternatives, such as the size of a
budget, it seems likely that preferences will in fact be single-peaked.
Another issue is that many of the nice properties of single-peaked preferences will not
hold for almost single-peaked preferences. For example, we may get Condorcet cycles
again, so it is no longer clear how preferences should be aggregated. In this context, any rule
for aggregating preferences is also likely to be manipulable (by declaring false preferences).
If we know the alternatives positions, then one simple solution is to simply require
each agent to submit single-peaked preferences (thereby forcing the agents without singlepeaked preferences to manipulate, by definition). An analogous approach is often taken
in combinatorial auctions, by restricting the set of valuation functions that the agents
can report, for the purpose of making the winner determination problem or the elicitation
problem easier. The reasoning is that the result is likely still better than not running
a combinatorial auction at all. One may wonder if requiring reported preferences to be
single-peaked could have some desirable effects. For example, one might argue that this
forces voters in a political election to ignore the candidates charisma (which one may argue
could be desirable). A precise analysis of this is beyond the scope of this paper.
Still, it is interesting and potentially important to be able to elicit almost singlepeaked preferences, so in this section, we study the extent to which this can be done. We
can interpret the idea of the agents preferences being close to single-peaked in multiple
ways.
182

fiEliciting Single-Peaked Preferences Using Comparison Queries

1. It may be the case that there are only a few agents that do not have single-peaked
preferences (e.g., few agents know any of the candidates personally, and the ones that
do not will rank the candidates according to their positions on the political spectrum).
2. It may be the case that for each individual agent, that agents preferences are close to
single-peaked (e.g., while an agent may know one or two of the candidates personally,
there are many other candidates, and the agent will rank those remaining candidates
according to their positions on the political spectrum).
In this section, we will consider mostly the first interpretation (an example illustrating
why the second interpretation seems more difficult to deal with is given below). Let us
suppose that a fraction  of the agents have preferences that are not single-peaked. One
straightforward strategy is the following. Let us suppose, for now, that we know the alternatives positions. For each agent j, elicit the preferences of the agent as if they are
single-peaked. As a result, we obtain a ranking a1  a2  . . .  am of the alternatives,
which we know must be js ranking if js preferences are in fact single-peaked. We then
verify whether these are indeed js preferences, by asking j to compare a1 and a2 , a2 and
a3 , . . ., and am1 and am . If all of these m  1 queries result in the expected answer
(ai j ai+1 ), then we know agent js preferences. Otherwise, we start again from the beginning, and elicit js preferences without any single-peakedness assumption, using a standard
O(m log m) sorting algorithm. (Of course, in practice, we do not actually have to start
completely from the beginningwe can still use the answers to the queries that we have
already asked.) This leads to the following propositions.
Proposition 1 If a fraction  of the agents have preferences that are not (ordinally or cardinally) single-peaked, and the (ordinal or cardinal) positions of the alternatives are known,
then we can elicit an agents preferences using (on average) O(m + m log m) queries.
Proof: FindRankingGivenPositions requires O(m) queries; so does the verification step. 
of the time the verification step fails, and we need another O(m log m) queries in that case.

We note that with this approach, there is no longer a significant advantage to having
cardinally single-peaked preferences: whereas O(log m) queries are enough if we are sure
that preferences are cardinally single-peaked (and we know the alternatives positions), if
we are not sure, we need the m  1 queries for the verification step.
It may be tempting to think that if an agents preferences are almost single-peaked
(in the sense of the second interpretation above), then most of the verification queries will
turn out the way that we expect, so that we already know most of the agents preferences.
To see that this is not the case, suppose that the alternatives positions are (from left to
right) a1 < a2 < . . . < a8 . Now consider a very left-wing voter who is nevertheless friends
with a5 , resulting in the very-close-to-single-peaked preferences a1  a2  a3  a5  a4 
a6  a7  a8 . FindRankingGivenPositions will start by running FindPeakGivenPositions,
whose first query will result in the answer a5  a4 . As a result, FindPeakGivenPositions will
conclude that the agent is a right-wing voter, and will eventually conclude that a5 is the
peak. FindRankingGivenPositions will then return that the preferences are a5  a4  a3 
183

fiConitzer

a2  a1  a6  a7  a8 . Then, roughly half of the verification queries will not turn out the
way we expect. (This example is easily generalized to any number of alternatives.)
So, let us return to the first interpretation, but now let us consider the case where the
alternatives positions are not known. For this case, we have the algorithm FindRankingGivenOtherVote, which uses O(m) queries but requires us to know another agents preferences, which we will have to elicit first. Now, if we consider the case where not all agents
preferences are single-peaked, there are two ways in which we can get in trouble with the
algorithm FindRankingGivenOtherVote: the current agents preferences may not be singlepeaked, or the earlier agents preferences that we are using in the algorithm may not be
single-peaked. In either case, the algorithm may fail to identify the current agents preferences correctly. Again, we can address this by asking the verification queries for the current
agent, and if necessary reverting to a standard sorting algorithm.
Assuming independence, the probability that both the current and the earlier agents
preferences are single-peaked is (1  )2 . If we are eliciting many agents preferences, we
have to be a little bit careful: if we always use the same agents preferences as the known
preferences, we run the risk that that agents preferences are not actually single-peaked, and
hence the verification step might fail for (almost) every agent. A more conservative approach
is to always use the previous agents preferences. If we assume that whether one agents
preferences are single-peaked is independent of whether this was the case for the previous
agent, then indeed, (1  )2 of the time both agents preferences will be single-peaked. This
leads to the following proposition.

Proposition 2 If a fraction  of the agents have preferences that are not (ordinally or
cardinally) single-peaked (and this is independent from one agent to the next), and the
(ordinal or cardinal) positions of the alternatives are unknown, then we can elicit an agents
preferences using (on average) O(m + (2  2 )m log m) queries (with the exception of the
first agent).

Proof: FindRankingGivenOtherVote requires O(m) queries; so does the verification step.
The verification step can only fail if either the previous or the current agents preferences
are not single-peaked, and the probability of this is 1  (1  )2 = 2  2 ; we need another
O(m log m) queries in that case.

(In practice, we may not want to use a different known vote every time. Rather, we
may want to use the same one for a while and see if the verification step fails too often; if
so, we switch to another known vote, otherwise not.)
While Propositions 1 and 2 seem to provide a good solution for the first interpretation of
almost single-peaked preferences, it is less clear what to do for the second interpretation (the
example above illustrates the difficulty). Still, it would be desirable to design algorithms
that efficiently elicit preferences that are almost single-peaked under the second interpretation. More generally, there is a large amount of other work in preference elicitation that
assumes that the preferences lie in a particular class, and it would be interesting to see if
those algorithms can be generalized to deal with preferences close to those classes.
184

fiEliciting Single-Peaked Preferences Using Comparison Queries

7. Conclusions
Voting is a general method for aggregating the preferences of multiple agents. Each agent
ranks all the possible alternatives, and based on this, an aggregate ranking of the alternatives
(or at least a winning alternative) is produced. However, when there are many alternatives,
it is impractical to simply ask agents to report their complete preferences. Rather, the
agents preferences, or at least the relevant parts thereof, need to be elicited. This is done
by asking the agents a (hopefully small) number of simple queries about their preferences,
such as comparison queries, which ask an agent to compare two of the alternatives. Prior
work on preference elicitation in voting has focused on the case of unrestricted preferences.
It has been shown that in this setting, it is sometimes necessary to ask each agent (almost)
as many queries as would be required to determine an arbitrary ranking of the alternatives.
In contrast, in this paper, we focused on single-peaked preferences. The agents preferences
are said to be single-peaked if there is some fixed order of the alternatives, the alternatives
positions (representing, for instance, which alternatives are more left-wing and which are
more right-wing), such that each agent prefers alternatives that are closer to the agents
most preferred alternative to ones that are further away. We first showed that if an agents
preferences are single-peaked, and the alternatives positions are known, then the agents
(complete) preferences can be elicited using a linear number of comparison queries. If the
alternatives positions are not known, then the first agents preferences can be arbitrary
and therefore cannot be elicited using only a linear number of queries. However, we showed
that if we already know at least one other agents preferences, then we can elicit the (next)
agents preferences using a linear number of queries (albeit a larger number of queries than
the first algorithm). We also showed that using a sublinear number of queries will not
suffice. We also considered the case of cardinally single-peaked preferencesthat is, each
alternative and each agent has a cardinal position in R, and agents rank alternatives by
distance to their own position. For this case, we showed that if the alternatives cardinal
positions are known, then an agents preferences can be elicited using only a logarithmic
number of queries; however, we also showed that if the cardinal positions are not known,
then a sublinear number of queries does not suffice. We presented experimental results for all
elicitation algorithms. We also considered the problem of only eliciting enough information
to determine the aggregate ranking, and showed that even for this more modest objective,
a sublinear number of queries per agent does not suffice for known ordinal or unknown
cardinal positions. Finally, we discussed whether and how these techniques can be applied
when preferences are almost single-peaked. We showed how the algorithms presented earlier
in the paper can be used when most agents preferences are (completely) single-peaked. The
case where each agents preferences are almost single-peaked seems more difficult; we gave
an example illustrating why.
Future research includes studying elicitation in voting for other restricted classes of
preferences. The class of single-peaked preferences (over single-dimensional domains) was
a natural one to study first, due to both its practical relevance and its useful theoretical
properties (no Condorcet cycles and, as a result, the ability to aggregate preferences in a
strategy-proof manner). Classes that are practically relevant but do not have these nice
theoretical properties are still of interest, though. For example, one may consider settings
where alternatives take positions in two-dimensional rather than single-dimensional space.
185

fiConitzer

It is well-known that in this generalization, Condorcet cycles can occur once again. The
same is true for the almost single-peaked settings discussed above. Nevertheless, this
does not imply that efficient elicitation algorithms do not exist for these settings. Nor does
it imply that such elicitation algorithms would be useless, since it is still often necessary to
vote over alternatives in such settings. However, if we use a voting rule that is not strategyproof, then we must carefully evaluate the strategic effects of elicitation. Specifically, from
the queries that agents are asked, they may be able to infer something about how other
agents answered queries before them; this, in turn, may affect how they (strategically)
choose to answer their own queries, since the rule is not strategy-proof. This phenomenon
is studied in more detail by Conitzer and Sandholm (2002).

Acknowledgments
I thank both the AAMAS and the JAIR reviewers for their valuable feedback (the JAIR
reviewers provided especially detailed and helpful feedback). Conitzer is supported under
NSF award number IIS-0812113 and an Alfred P. Sloan Research Fellowship.

Appendix A. Experimental Results for Ordinally Single-Peaked
Preferences
The following experiment compares FindRankingGivenPositions, FindRankingGivenOtherVote,
and MergeSort. As discussed in Subsection 2.2, MergeSort is a standard sorting algorithm
that uses only comparison queries, and can therefore be used to elicit an agents preferences
without any knowledge of the alternatives positions or of other votes. Conversely, any
algorithm that elicits general preferences using only comparison queries can be used to solve
the sorting problem. So, effectively, if we want to compare to an algorithm that does not
use the fact that preferences are single-peaked, then we cannot compare to anything other
than a sorting algorithm. It is conceivable that other sorting algorithms perform slightly
better than MergeSort on this problem, but they all require (m log m) comparisons.
In each run, first a random permutation of the m alternatives was drawn to represent the
positions of the alternatives. Then, two random votes (rankings) that were single-peaked
with respect to these positions were drawn. For each vote, this was done by randomly
choosing a peak, then randomly choosing the second-highest ranked alternative from the
two adjacent alternatives, etc. Each algorithm then elicited the second vote; FindRankingGivenPositions was given (costless) access to the positions, and FindRankingGivenOtherVote
was given (costless) access to the first vote. (For each run, it was verified that each algorithm
produced the correct ranking.) Figure 1 shows the results (please note the logarithmic scale
on the x-axis). FindRankingGivenPositions outperforms FindRankingGivenOtherVote, which
in turn clearly outperforms MergeSort.
One interesting observation is that FindRankingGivenOtherVote sometimes repeats a
query that it has asked before. Thus, by simply storing the results of previous queries,
the number of queries can be reduced. However, in general, keeping track of which queries
have been asked imposes a significant computational burden, as there are m
2 possible com186

fiEliciting Single-Peaked Preferences Using Comparison Queries

1.6e+06
MergeSort
FindRankingGivenOtherVote
FindRankingGivenPositions
1.4e+06

# comparison queries

1.2e+06

1e+06

800000

600000

400000

200000

0
1000

10000
# alternatives

100000

Figure 1: Experimental comparison of MergeSort, FindRankingGivenOtherVote, and FindRankingGivenPositions. Please note the logarithmic scale on the x-axis. Each
data point is averaged over 5 runs.

parison queries. Hence, in the experiment, the results of previous queries were not stored.
FindRankingGivenPositions and MergeSort never repeat a query.

Appendix B. Experimental Results for Cardinally Single-Peaked
Preferences
Next, we experimentally compare FindRankingGivenCardinalPositions to FindRankingGivenPositions. Since the former requires cardinally single-peaked preferences, we must generate
preferences in a different way from Appendix A. We generate preferences in each run by
drawing a cardinal position uniformly at random from [0, 1] for each alternative, as well as for
the agent. The agent then ranks the alternatives according to proximity to its own cardinal
position. (For each run, it was verified that each algorithm produced the correct ranking.)
We note that computationally, the algorithm does not scale to such large numbers of alternatives as the previous algorithms, because of the reasons mentioned earlier (managing
all the midpoints). Figure 2 shows the results, clearly contrasting FindRankingGivenCardinalPositionss logarithmic nature to FindRankingGivenPositionss linear (and somewhat less
predictable) nature. (Please note the logarithmic scale on the x-axis.)
187

fiConitzer

800
FindRankingGivenPositions
FindRankingGivenCardinalPositions
700

# comparison queries

600

500

400

300

200

100

0
10

100
# alternatives

1000

Figure 2: Experimental comparison of FindRankingGivenPositions and FindRankingGivenCardinalPositions. Please note the logarithmic scale on the x-axis. Each data point
is averaged over 5 runs.

References
Arrow, K. (1963). Social choice and individual values (2nd edition). New Haven: Cowles
Foundation. 1st edition 1951.
Bartholdi, III, J., & Orlin, J. (1991). Single transferable vote resists strategic voting. Social
Choice and Welfare, 8 (4), 341354.
Bartholdi, III, J., Tovey, C., & Trick, M. (1989). Voting schemes for which it can be difficult
to tell who won the election. Social Choice and Welfare, 6, 157165.
Black, D. (1948). On the rationale of group decision-making. Journal of Political Economy,
56 (1), 2334.
Blum, A., Jackson, J., Sandholm, T., & Zinkevich, M. (2004). Preference elicitation and
query learning. Journal of Machine Learning Research, 5, 649667.
Boutilier, C. (2002). A POMDP formulation of preference elicitation problems. In Proceedings of the National Conference on Artificial Intelligence (AAAI), pp. 239246, Edmonton, AB, Canada.
Brams, S. J., Jones, M. A., & Kilgour, D. M. (2002). Single-peakedness and disconnected
coalitions. Journal of Theoretical Politics, 14 (3), 359383.
188

fiEliciting Single-Peaked Preferences Using Comparison Queries

Brams, S. J., Jones, M. A., & Kilgour, D. M. (2005). Forming stable coalitions: The process
matters. Public Choice, 125, 6794.
Braziunas, D., & Boutilier, C. (2005). Local utility elicitation in GAI models. In Proceedings
of the 21st Annual Conference on Uncertainty in Artificial Intelligence (UAI), pp. 4249,
Edinburgh, UK.
Chajewska, U., Getoor, L., Norman, J., & Shahar, Y. (1998). Utility elicitation as a
classification problem. In Proceedings of the Conference on Uncertainty in Artificial
Intelligence (UAI), pp. 7988, Madison, WI, USA.
Chajewska, U., Koller, D., & Parr, R. (2000). Making rational decisions using adaptive
utility elicitation. In Proceedings of the National Conference on Artificial Intelligence
(AAAI), pp. 363369, Austin, TX, USA.
Clarke, E. H. (1971). Multipart pricing of public goods. Public Choice, 11, 1733.
Cohen, W., Schapire, R., & Singer, Y. (1999). Learning to order things. Journal of Artificial
Intelligence Research, 10, 213270.
Conen, W., & Sandholm, T. (2001). Preference elicitation in combinatorial auctions: Extended abstract. In Proceedings of the ACM Conference on Electronic Commerce (EC),
pp. 256259, Tampa, FL, USA.
Conitzer, V. (2006). Computing Slater rankings using similarities among candidates. In
Proceedings of the National Conference on Artificial Intelligence (AAAI), pp. 613619,
Boston, MA, USA.
Conitzer, V. (2007). Eliciting single-peaked preferences using comparison queries. In Proceedings of the International Conference on Autonomous Agents and Multi-Agent Systems
(AAMAS), pp. 408415, Honolulu, HI, USA.
Conitzer, V., & Sandholm, T. (2002). Vote elicitation: Complexity and strategy-proofness.
In Proceedings of the National Conference on Artificial Intelligence (AAAI), pp. 392397,
Edmonton, AB, Canada.
Conitzer, V., & Sandholm, T. (2005). Communication complexity of common voting rules.
In Proceedings of the ACM Conference on Electronic Commerce (EC), pp. 7887, Vancouver, BC, Canada.
Conitzer, V., Sandholm, T., & Lang, J. (2007). When are elections with few candidates
hard to manipulate? Journal of the ACM, 54 (3), Article 14, 133.
Cramton, P., Shoham, Y., & Steinberg, R. (2006). Combinatorial Auctions. MIT Press.
Ephrati, E., & Rosenschein, J. S. (1991). The Clarke tax as a consensus mechanism among
automated agents. In Proceedings of the National Conference on Artificial Intelligence
(AAAI), pp. 173178, Anaheim, CA, USA.
189

fiConitzer

Ephrati, E., & Rosenschein, J. S. (1993). Multi-agent planning as a dynamic search for social
consensus. In Proceedings of the Thirteenth International Joint Conference on Artificial
Intelligence (IJCAI), pp. 423429, Chambery, France.
Escoffier, B., Lang, J., & Ozturk, M. (2008). Single-peaked consistency and its complexity.
In Proceedings of the DIMACS-LAMSADE Workshop on Algorithmic Decision Theory,
pp. 101114, Paris, France.
Gibbard, A. (1973). Manipulation of voting schemes: a general result. Econometrica, 41,
587602.
Groves, T. (1973). Incentives in teams. Econometrica, 41, 617631.
Hemaspaandra, E., & Hemaspaandra, L. A. (2007). Dichotomy for voting systems. Journal
of Computer and System Sciences, 73 (1), 7383.
Hemaspaandra, E., Hemaspaandra, L. A., & Rothe, J. (1997). Exact analysis of Dodgson
elections: Lewis Carrolls 1876 voting system is complete for parallel access to NP. Journal
of the ACM, 44 (6), 806825.
Hinich, M. J., & Munger, M. C. (1997). Analytical Politics. Cambridge University Press.
Lahaie, S., & Parkes, D. (2004). Applying learning algorithms to preference elicitation. In
Proceedings of the ACM Conference on Electronic Commerce (EC), pp. 180188, New
York, NY, USA.
Lang, J. (2007). Vote and aggregation in combinatorial domains with structured preferences.
In Proceedings of the Twentieth International Joint Conference on Artificial Intelligence
(IJCAI), pp. 13661371, Hyderabad, India.
Parkes, D. (2006). Iterative combinatorial auctions. In Cramton, P., Shoham, Y., & Steinberg, R. (Eds.), Combinatorial Auctions, chap. 2, pp. 4177. MIT Press.
Pennock, D. M., Horvitz, E., & Giles, C. L. (2000). Social choice theory and recommender
systems: Analysis of the axiomatic foundations of collaborative filtering. In Proceedings
of the National Conference on Artificial Intelligence (AAAI), pp. 729734, Austin, TX,
USA.
Procaccia, A. D., & Rosenschein, J. S. (2007). Junta distributions and the average-case
complexity of manipulating elections. Journal of Artificial Intelligence Research, 28,
157181.
Rothe, J., Spakowski, H., & Vogel, J. (2003). Exact complexity of the winner problem for
Young elections. In Theory of Computing Systems, Vol. 36(4), pp. 375386. SpringerVerlag.
Sandholm, T., & Boutilier, C. (2006). Preference elicitation in combinatorial auctions. In
Cramton, P., Shoham, Y., & Steinberg, R. (Eds.), Combinatorial Auctions, chap. 10, pp.
233263. MIT Press.
190

fiEliciting Single-Peaked Preferences Using Comparison Queries

Santi, P., Conitzer, V., & Sandholm, T. (2004). Towards a characterization of polynomial
preference elicitation with value queries in combinatorial auctions. In Conference on
Learning Theory (COLT), pp. 116, Banff, Alberta, Canada.
Satterthwaite, M. (1975). Strategy-proofness and Arrows conditions: Existence and correspondence theorems for voting procedures and social welfare functions. Journal of
Economic Theory, 10, 187217.
Vu, H., & Haddawy, P. (1997). Problem-focused incremental elicitation of multi-attribute
utility models. In Proceedings of the Conference on Uncertainty in Artificial Intelligence
(UAI), pp. 215222, San Francisco, CA, USA.
Vu, H., & Haddawy, P. (1998). Towards case-based preference elicitation: Similarity measures on preference structures. In Proceedings of the Conference on Uncertainty in Artificial Intelligence (UAI), pp. 193201.
Walsh, T. (2007). Uncertainty in preference elicitation and aggregation. In Proceedings
of the National Conference on Artificial Intelligence (AAAI), pp. 38, Vancouver, BC,
Canada.
Zinkevich, M., Blum, A., & Sandholm, T. (2003). On polynomial-time preference elicitation
with value queries. In Proceedings of the ACM Conference on Electronic Commerce (EC),
pp. 176185, San Diego, CA, USA.

191

fiJournal of Artificial Intelligence Research 35 (2009) 49-117

Submitted 10/08; published 05/09

Message-Based Web Service Composition, Integrity Constraints, and
Planning under Uncertainty: A New Connection
Jorg Hoffmann

JOE . HOFFMANN @ SAP. COM

SAP Research
Karlsruhe, Germany

Piergiorgio Bertoli

BERTOLI @ FBK . EU

Fondazione Bruno Kessler
Trento, Italy

Malte Helmert

HELMERT @ INFORMATIK . UNI - FREIBURG . DE

Albert-Ludwigs-Universitat Freiburg
Freiburg, Germany

Marco Pistore

PISTORE @ FBK . EU

Fondazione Bruno Kessler
Trento, Italy

Abstract
Thanks to recent advances, AI Planning has become the underlying technique for several applications. Figuring prominently among these is automated Web Service Composition (WSC) at
the capability level, where services are described in terms of preconditions and effects over ontological concepts. A key issue in addressing WSC as planning is that ontologies are not only formal
vocabularies; they also axiomatize the possible relationships between concepts. Such axioms correspond to what has been termed integrity constraints in the actions and change literature, and
applying a web service is essentially a belief update operation. The reasoning required for belief
update is known to be harder than reasoning in the ontology itself. The support for belief update is
severely limited in current planning tools.
Our first contribution consists in identifying an interesting special case of WSC which is both
significant and more tractable. The special case, which we term forward effects, is characterized
by the fact that every ramification of a web service application involves at least one new constant
generated as output by the web service. We show that, in this setting, the reasoning required for
belief update simplifies to standard reasoning in the ontology itself. This relates to, and extends,
current notions of message-based WSC, where the need for belief update is removed by a strong
(often implicit or informal) assumption of locality of the individual messages. We clarify the
computational properties of the forward effects case, and point out a strong relation to standard notions of planning under uncertainty, suggesting that effective tools for the latter can be successfully
adapted to address the former.
Furthermore, we identify a significant sub-case, named strictly forward effects, where an actual
compilation into planning under uncertainty exists. This enables us to exploit off-the-shelf planning tools to solve message-based WSC in a general form that involves powerful ontologies, and
requires reasoning about partial matches between concepts. We provide empirical evidence that
this approach may be quite effective, using Conformant-FF as the underlying planner.

c
2009
AI Access Foundation. All rights reserved.

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

1. Introduction
Since the mid-nineties, AI Planning tools have become several orders of magnitude more scalable,
through the invention of automatically generated heuristic functions and other search techniques
(see McDermott, 1999; Bonet & Geffner, 2001; Hoffmann & Nebel, 2001; Gerevini, Saetti, &
Serina, 2003; Helmert, 2006; Chen, Wah, & Hsu, 2006). This has paved the way to the adoption
of planning as the underlying technology for several applications. One such application area is
web service composition (WSC), by which in this paper we mean the automated composition of
semantic web services (SWS). SWS are pieces of software advertised with a formal description
of what they do. Composing SWS means to link them together so that their aggregate behavior
satisfies a complex user requirement. The ability to automatically compose web services is the key
to reducing human effort and time-to-market when constructing integrated enterprise applications.
As a result, there is a widely recognized economic potential for WSC.
In the wide-spread SWS frameworks OWL-S1 and WSMO2 , SWS are described at two distinct
levels. One of these addresses the overall functionality of the SWS, and the other details precisely
how to interact with the SWS. At the former level, called service profile in OWL-S and service
capability in WSMO, SWS are described akin to planning operators, with preconditions and effects. Therefore, planning is a prime candidate for realizing WSC at this level. This is the approach
we follow in our paper.
In such a setting, a key aspect is that SWS preconditions and effects are described relative to
an ontology which defines the formal (logical) vocabulary. Indeed, ontologies are much more than
just formal vocabularies introducing a set of logical concepts. They also define axioms which constrain the behavior of the domain. For instance, an ontology may define a subsumption relationship
between two concepts A and B, stating that all members of A are necessarily members of B. The
natural interpretation of such an axiom, in the context of WSC, is that every state that can be encountered  every possible configuration of domain entities  must satisfy the axiom. In that sense,
ontology axioms correspond to integrity constraints as discussed in the actions and change literature
(Ginsberg & Smith, 1988; Eiter & Gottlob, 1992; Brewka & Hertzberg, 1993; Lin & Reiter, 1994;
McCain & Turner, 1995; Herzig & Rifi, 1999).3 Hence WSC as considered here is like planning in
the presence of integrity constraints. Since the constraints affect the outcome of action executions,
we are facing the frame and ramification problems, and execution of actions corresponds closely to
complex notions such as belief update (Lutz & Sattler, 2002; Herzig, Lang, Marquis, & Polacsek,
2001). Unsurprisingly, providing such support for integrity constraints in the modern scalable planning tools mentioned above poses serious challenges. To the best of our knowledge, it has yet to be
attempted at all.
Regarding the existing WSC tools, or planning tools employed for solving WSC problems, the
situation isnt much better. Most tools ignore the ontology, i.e., they act as if no constraints on the
domain behavior were given (Ponnekanti & Fox, 2002; Srivastava, 2002; Narayanan & McIlraith,
2002; Sheshagiri, desJardins, & Finin, 2003; Pistore, Traverso, & Bertoli, 2005b; Pistore, Marconi, Bertoli, & Traverso, 2005a; Agarwal, Chafle, Dasgupta, Karnik, Kumar, Mittal, & Srivastava,
2005a). Other approaches tackle the full generality of belief update by using general reasoners, and
1. For example, see the work of Ankolekar et al. (2002) and Burstein et al. (2004).
2. For example, see the work of Roman et al. (2005) and Fensel et al. (2006).
3. Integrity constraints are sometimes also called state constraints or domain constraints.

50

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

suffer from the inevitable performance deficiencies (Eiter, Faber, Leone, Pfeifer, & Polleres, 2003;
Giunchiglia, Lee, Lifschitz, McCain, & Turner, 2004).
is a planningbased
formalization of

WSC Formalism

is a variant of

is a restriction of
is a rich version of

Forward Effects

WSC

is a planningbased
formalization of

Messagebased WSC

is a restriction of

Conformant Planning

can be
tackled by

Strictly Forward Effects

Figure 1: An overview of the planning and WSC frameworks addressed in this paper. Special cases
identified herein shown in red / boldface.
Our work addresses the middle ground between these two extremes, i.e., the trade-off between
expressivity and scalability in WSC. We do so via the identification of special cases that can be
tackled more efficiently. Figure 1 gives an overview of the WSC and planning frameworks involved.
In brief, the forward effects case requires that every effect and ramification of a web service
affects at least one new constant that was generated as the web services output. In this situation,
the frame problem trivializes, making the planning problem more similar to common notions of
conformant planning (Smith & Weld, 1998; Bonet & Geffner, 2000; Cimatti, Roveri, & Bertoli,
2004; Hoffmann & Brafman, 2006). We will discuss how existing tools for the latter, in particular
Conformant-FF (Hoffmann & Brafman, 2006), can be extended to deal with WSC under forward
effects. With strictly forward effects, where action effects are required to affect only outputs, we
devise an actual compilation into conformant planning. We thus obtain a scalable tool for interesting
WSC problems with integrity constraints. In particular we are able to exploit (some of) the heuristic
techniques mentioned above (Hoffmann & Nebel, 2001; Hoffmann & Brafman, 2006).
In what follows, we will explain the various parts of Figure 1 in a little more detail. Our starting
point is a WSC formalism, addressing WSC in terms of planning in the presence of integrity constraints, as discussed above. The formalism is essentially an enriched form of conformant planning.
Its distinguishing aspects are:
 The initial state description is a conjunction of literals (possibly not mentioning some of the
logical facts in the task, and hence introducing uncertainty).
 Actions have a conditional effects semantics, meaning they can be executed in any state, but
have an effect only if they are applicable.
 Actions may have output variables, i.e., they may create new constants.
 There is a set of integrity constraints, each of which is a universally quantified clause.
 The semantics of action execution is defined in terms of a belief update operation.
Section 2 below provides more details on these choices, and motivates them with an example and
results from the literature. As we will show, planning in the formalism is very hard. Particularly,
51

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

even just testing whether a given action sequence is a plan is p2 -complete. This is in contrast to the
more common notions of conformant planning, where plan testing is only coNP-complete.
As we will see, forward effects remove the additional complexity. Intuitively, the forward effects
case covers the situation where a web service outputs some new constants, sets their characteristic
properties relative to the inputs, and relies on the ontology axioms to describe any ramifications
concerning the new constants. This case is syntactically characterized as follows:
(1) Every effect literal contains at least one output variable.
(2) Within each integrity constraint, every literal has the same set of variables in its arguments.
This definition is best understood with an example. Consider the following variant of the widespread virtual travel agency (VTA). Web services that book travel and accommodation must
be linked. These web services generate new constants corresponding to tickets and reservations.
For example, there are integrity constraints stating subsumption, such as z : trainTicket(z) 
ticket(z). A web service bookTicket may have the input variable x, the precondition train(x ), the
output variable y, and the effect trainTicket(y)  ticketFor (y, x). This is a forward effects task:
every effect literal contains the output variable y, and the integrity constraint has the single variable
z which provides the arguments of all literals in the constraint. Say one instantiates the input of
bookTicket with a constant c and its output with a new constant d. When applying the resulting
ground action to a state where train(c) holds true, the constant d gets created, and its characteristic
properties relative to the inputs  trainTicket(d)  ticketFor (d, c)  are set directly by the action.
The integrity constraint takes care of the ramification, establishing that ticket(d) holds. Note that
the status of c  apart from its relation to d  is not affected in any way. 4
The forward effects case is closely related to a wide-spread notion of WSC problems, which
we refer to as message-based WSC. In such approaches, the composition semantics is based on
chaining over input and output messages of web services, in one or the other sense. Inferences from
ontology axioms can be made in many of these approaches, but only in a restricted way limited by an
assumption of locality of the individual messages, where the interferences affect only a particular
message transfer, and any implications for other transfers are ignored. This locality assumption is
usually made in an informal way, and often not stated explicitly at all. One contribution of our work
is to shed some light on this issue, via the identification of the forward effects case which lies in
between message-based WSC and a full planning framework with belief update semantics.
Both message-based WSC and the forward effects case share the focus on output constants.
There are two important differences. First, the forward effects case is more restricted than messagebased WSC in terms of the ontology axioms allowed. Essentially, forward effects correspond to
a special case of WSC where the locality assumption of message-based WSC is actually justified,
within a full planning framework. Second, that full framework comes with the benefit of increased
flexibility in the combination of services, because locality is not enforced (e.g. the output of one
service may be reused at several points in a plan).
From a computational point of view, the key property of the forward effects case is that it
removes the need for belief update. In a nutshell, the reason is that actions affect only new propositions, i.e., propositions involving at least one output constant. (Recall here the point made about
4. The latter would not be the case if the effect of bookTicket included a literal affecting only x (example:
train(x)), or if there was an integrity constraint capable of mixing old and new constants (example: x, y :
trainTicket(y)  train(x)).

52

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

the unchanged status of c, in the VTA example above.) The output constant (d, in the example) does
not exist prior to the application of the action, and hence the previous belief carries no knowledge
about it and need not be revised. Consider the characterization of forward effects, as given above.
Condition (1) ensures that the immediate effect of the action affects only new propositions. Condition (2) ensures that any changes on new propositions only propagate to new propositions. Since
all literals in a constraint share the same variables, the output constant in question is copied to all of
them. As we will see, by virtue of these properties the complexity of plan testing is coNP-complete,
rather than p2 -complete, in the forward effects case.
This complexity reduction is critical because the reduced complexity is the same as in the more
common notions of conformant planning under initial state uncertainty. Therefore it should be feasible to adapt conformant planning tools to address WSC with forward effects. Scalable planning
tools for conformant planning have already been developed (Cimatti et al., 2004; Bryce, Kambhampati, & Smith, 2006; Hoffmann & Brafman, 2006; Palacios & Geffner, 2007). Hence this is a
promising line of research. As an example, we will focus on the Conformant-FF tool (Hoffmann
& Brafman, 2006) (short CFF) and outline the main steps that need to be taken in adapting CFF to
handle WSC with forward effects.
We then identify a case where an actual compilation into conformant planning under initial
state uncertainty exists. For that, one must fix a set of constants a priori. In a manner that is
fairly standard (see, e.g., the Settlers domain of Long & Fox, 2003), we simply include in that set
a subset of potential constants that can be used to instantiate outputs. The more subtle idea we
put forward is to identify a condition on the actions under which we can predict which properties
will be assigned to which potential constants, in case they are created. This enables us to design
a compilation that moves all action effects into the initial state formula, and uses actions only to
modify the set of constants that already exist. In this way, reasoning about the initial state formula
in the compiled task is the same as reasoning about output constants in the original task, and the
reasoning mechanisms included in tools such as CFF can be naturally used to implement the latter.
Our trick for predicting output properties is to require that all actions are compatible in the sense
that they either produce different outputs, or have the same effects. It turns out that this condition is
naturally given in a restriction of forward effects, which we call strictly forward effects, where the
web service effects concern only new constants.
Clearly, not being able to reference the inputs is a limitation. For example, we can no longer
say, in the above VTA example, that the output y is a ticket for the input x. Still, the strictly forward
effects case describes an interesting class of WSC problems. That class corresponds to web services
modeled as in the early versions of OWL-S, for example, where there was no logical connection
between inputs and outputs. Further, this class of WSC problems allows powerful ontologies 
universally quantified clauses  and makes it possible to combine services very flexibly. Using
our compilation, this class of problems can be solved by off-the-shelf tools for planning under
uncertainty.
We validate the compilation approach empirically by running a number of tests using CFF as
the underlying planner. We use two test scenarios, both of which are scalable in a variety of parameters, covering a range of different problem structures. We examine how CFF reacts to the various
parameters. Viewed in isolation, these results demonstrate that large and complex WSC instances
can be comfortably solved using modern planning heuristics.
A comparison to alternative WSC tools is problematic due to the widely disparate nature of
what kinds of problems these tools can solve, what kinds of input languages they understand, and
53

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

what purpose the respective developers had in mind. To nevertheless provide some assessment of
the comparative benefits of our approach we run tests with the DLVK tool by Eiter et al. (2003)
and Eiter, Faber, Leone, Pfeifer, and Polleres (2004). DLVK is one of the few planning tools that
deals with ontology axioms  called static causal rules  directly, without the need to restrict
to forward effects and without the need for a compilation. Since, in the context of our work, the
main characteristic of WSC is the presence of ontology axioms, this means that DLVK is one of
the few existing native WSC tools. By comparison, our forward effects compilation approach
solves a similar problem, but sacrifices some expressivity. The question is, can we in principle
gain anything from this sacrifice? Absolutely, the answer is yes. DLVK is much slower than
compilation+CFF, solving only a small fraction of our test instances even when always provided
with the correct plan length bound. We emphasize that we do not wish to over-state these results,
due to the above-mentioned differences between the tools. The only conclusion we draw is that the
trade-off between expressivity and scalability in WSC is important, and that the forward effects case
seems to constitute an interesting point in that trade-off.
The paper is organized as follows. First, Section 2 provides some further background necessary
to understand the context and contribution of our work. Section 3 introduces our WSC planning
formalism. Section 4 defines and discusses forward effects. Section 5 introduces our compilation to
planning under uncertainty, and Section 6 presents empirical results. We discuss the most closely
related work at the relevant points during the text, and Section 7 provides a more complete overview.
Finally, Section 8 concludes and discusses future work. To improve readability, most proofs are
moved into Appendix A and replaced in the text by proof sketches.

2. Background
The context of our work is rather intricate. WSC as such is a very new topic posing many different
challenges to existing techniques, with the effect that the field is populated by disparate works differing considerably in their underlying purpose and scope. In other words, the common ground is
fairly thin in this area. Further, our work actually involves three fields of research  WSC, planning,
and reasoning about actions and change  which are all relevant to understanding our contribution.
For these reasons, we now explain this background in some detail. We first discuss WSC in general,
and WSC as Planning in particular. We then state the relevant facts about belief update. We finally
consider message-based WSC.
2.1 WSC, and WSC as Planning
Composition of semantic web services has received considerable attention in the last few years. A
general formulation of the problem, shared by a large variety of works, focuses on the capability
level, where each web service is conceived as an atomic operator that transforms concepts. More
specifically, a service is defined via an IOPE description: the service receives as input a set I
of typed objects, and, provided some precondition P on I holds, produces as output a set O of
typed objects for which some effect E is guaranteed to hold. The typing of the objects exchanged
by the services is given in terms of their membership in concepts. Concepts are classes defined
within ontologies, which exploit Description Logics (DL), or some other form of logic, to formally
define the universe of concepts admitted in the discourse. An ontology can express complex relationships among concepts, like a subsumption hierarchy, or the way objects belonging to a concept
are structured into parts referring to other concepts.
54

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

This general setting can be instantiated in various ways depending on the kind of conditions
admitted as preconditions/effects of services, and on the kind of logics underlying the ontology
definitions. Independent of this, the problem of semantic web service composition can be stated
as one of linking appropriately a set of existing services so that their aggregate behavior is that
of a desired service (the goal). To illustrate this problem, consider the following example, which
is inspired by the work of Thakkar, Ambite, and Knoblock (2005) on e-services for bioinformatics
(and relies on the actual structure of proteins, see for example Petsko & Ringe, 2004; Branden &
Tooze, 1998; Chasman, 2003; Fersht, 1998):
Example 1 Say we want to compose a web service that provides information about different classes
of proteins. The ontology states which classes of proteins exist, and which structural characteristics
may occur. We have available an information service for every structural characteristic, and a
presentation service that combines a range of information. Given a particular protein class, the
composed web service should run the relevant information services, and present their output.
Concretely, classes of proteins are distinguished by their location (cell, membrane, intermembrane, . . . ). This is modeled by predicates protein(x), cellProtein(x), membraneProtein(x),
intermembraneProtein(x), along with sub-concept relations such as x : cellProtein(x) 
protein(x). An individual protein is characterized by the following four kinds of structures:
1. The primary structure states the proteins sequence of amino-acids, e.g., 1kw3(x) (a protein called Glyoxalase) and 1n55(x) (a protein called Triosephosphate Isomerase).
2. The secondary structure states the proteins external shape in terms of a DSSP (Dictionary of Secondary Structure for Proteins) code, admitting a limited set of possible values.
For example, G indicates a 3-turn helix, B a -sheet, and so on. The total set of values is
G,H,I,T,E,B,S.
3. The tertiary structure categorizes the proteins 3-D shape.
4. For a subset of the proteins, a quaternary structure categorizes the proteins shape when
combined in complexes of proteins (amounting to about 3000 different shapes, see for example
3DComplex.org, 2008).
There are various axioms that constrain this domain, apart from the mentioned subconcept
relations. First, some obvious axioms specify that each protein has a value in each of the four
kinds of structures (i.e., the protein has a sequence of amino-acids, an external shape, etc). However,
there are also more complex axioms. Particular kinds of proteins come only with particular structure
values. This is modeled by axioms such as:
x : cellProtein(x)  G(x)  1n55(x)
x : cellProtein(x)  B(x)  1kw3(x)  complexBarrel(x)
For each DSSP code Z there is an information service, named getInfoDSSPZ , whose precondition
is Z(x) and whose effect is InfoDSSP(y) where y is an output of the service. Similarly, we have information services for amino-acids, 3-D shapes, and shapes in complexes. The presentation service,
named combineInfo, requires that information on all four kinds of structures has been created, and
has the effect combinedPresentation(y) (where y is an output of combineInfo).
55

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

The input to the composed web service is a protein c (a logical constant) and its class. The
goal is x : combinedPresentation(x). A solution is to reason about which characteristics may
occur, to apply the respective information services, and then to run combineInfo. In a variant of
the problem, an additional requestInfo service is used to initiate the information request, i.e., the
output of requestInfo is the protein c and its class.
This example shows how ontology axioms play a crucial role in our form of WSC, formulating
complex dependencies between different concepts. Note that applying a web service may have indirect consequences implied by the ontology axioms. In the example, the output of the requestInfo
service has implications for which kinds of information services are required.
Another interesting aspect of Example 1 is that it requires what the SWS community calls partial matches, as opposed to plug-in matches (Paolucci, Kawamura, Payne, & Sycara, 2002; Li
& Horrocks, 2003; Kumar, Neogi, Pragallapati, & Ram, 2007).5 Consider the situation where one
wants to connect a web service w to another web service w . That is, w will be executed prior to
w , and the output of w will be used to instantiate the input of w . Then w and w are said to have
a partial match if, given the ontology axioms, the output of w sometimes suffices to provide the
necessary input for w . By contrast, w and w are said to have a plug-in match if, given the ontology
axioms, the output of w always suffices to provide the necessary input for w .
Plug-in matches are tackled by many approaches to WSC, whereas partial matches are tackled
only by few. Part of the reason probably is that plug-in matches are easier to handle, in many types
of WSC algorithms. Indeed most existing WSC tools support plug-in matches only (see a detailed
discussion of WSC tools in Section 7). Example 1 cannot be solved with plug-in matches because
each of the information services provides the necessary input for the combineInfo service only in
some particular cases.
We base our work on a planning formalism that allows to specify web services (i.e., actions)
with outputs, and that allows to specify ontology axioms. The axioms are interpreted as integrity
constraints, and the resulting semantics corresponds closely to the common intuitions behind WSC,
as well as to the existing formal definitions related to WSC (Lutz & Sattler, 2002; Baader, Lutz,
Milicic, Sattler, & Wolter, 2005; Liu, Lutz, Milicic, & Wolter, 2006b, 2006a; de Giacomo, Lenzerini, Poggi, & Rosati, 2006). Since one of our main aims is to be able to exploit existing planning
techniques, we consider a particular form of ontology axioms, in correspondence with the representations that are used by most of the existing tools for planning under uncertainty. Namely, the axioms
are universally quantified clauses. An example is the subsumption relation x : trainTicket(x) 
ticket(x) mentioned above, where as usual A  B is an abbreviation for A  B. A planning task
specifies a set of such clauses, interpreted as the conjunction of the clauses. Note that this provides
significant modeling power. The meaning of the universal quantification in the clauses is that the
clauses hold for all planning objects  logical constants  that are known to exist. In that sense, the
interpretation of formulas is closed-world as is customary in planning tools. However, in contrast
to most standard planning formalisms including PDDL, we do not assume a fixed set of constants.
Rather, the specification of actions with outputs enables the dynamic creation of new constants. The
quantifiers in the ontology axioms range over all constants that exist in the respective world. In a
similar fashion, the planning goal may contain variables, which are existentially quantified. The
constants used to instantiate the goal may have pre-existed, or they may have been generated as
5. The terminology in these works is slightly different from what we use here, and they also describe additional kinds
of matches. Some details are given in Section 7.

56

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

the outputs of some of the web services that were applied on the path to the world. Consider for
illustration the goal x : combinedPresentation(x) in Example 1, where the goal variable x will
have to be instantiated with an output created by the combineInfo service.
Another important aspect of our planning formalism is that we allow incomplete initial state
descriptions. The initial state corresponds to the input that the user provides to the composed web
service. Certainly we cannot assume that this contains complete information about every aspect
of the world. (In Example 1, the initial state tells us which class of proteins we are interested
in, but leaves open what the consequences are regarding the possible structural characteristics.)
We consider the case where there is no observability, i.e., conformant planning. The outcome of
WSC is a sequence of web services that satisfies the user goal in all possible situations.6 As is
customary in conformant planning, the actions have a conditional effects semantics, i.e., they fire if
their precondition holds true, and otherwise they do nothing. Note that, this way, we obtain a notion
of partial matches: the solution employs different actions depending on the situation.
The main difference between our planning formalism and the formalisms underlying most current planning tools is the presence of integrity constraints, and its effect on the semantics of executing actions. That semantics is defined as a belief update operation.
2.2 Belief Update
The correspondence of web service applications to belief update was first observed by Lutz and
Sattler (2002), and followed by Baader et al. (2005), Liu et al. (2006b, 2006a) and de Giacomo
et al. (2006). In the original statement of the belief update problem, we are given a belief ,
i.e., a logical formula defining the worlds considered possible. We are further given a formula ,
the update. Intuitively,  corresponds to some observation telling us that the world has changed
in a way so that, now,  is true. We want to obtain a formula  defining the worlds which are
possible given this update. Certainly, we need to have that  |= . Ensuring this corresponds
to the well-known ramification problem. At the same time, however, the world should not change
unnecessarily. That is, we want  to be as close as possible to , among the formulas which
satisfy . This corresponds to the frame problem.
Say we want to apply an action a in the presence of integrity constraints.  describes the
worlds that are possible prior to the application of a.  is the resulting set of possible worlds.
The integrity constraints correspond to a formula IC which holds in , and which we require to
hold in  . The update formula  is given as the conjunction of the action effect with IC , i.e.,
we have  = effa  IC . This means that we update our previous belief with the information that,
after a, effa is a new formula required to hold, and IC is still true. For example, we may have an
action effect A(c) and a subsumption relation between concepts A and B, formulated as a clause
x : A(x)  B(x). Then the update formula A(c)  x : A(x)  B(x) ensures that B(c) is true
in  .
Belief update has been widely considered in the literature on AI and databases (see for example
Fagin, Kuper, Ullman, & Vardi, 1988; Ginsberg & Smith, 1988; Winslett, 1988, 1990; Katzuno
& Mendelzon, 1991; Herzig, 1996; Herzig & Rifi, 1999; Liu et al., 2006b; de Giacomo et al.,
2006). The various approaches differ in exactly how  should be defined. The best consensus is
that there is no one approach that is most adequate in every application context. All approaches
6. Of course, more generally, observability is partial and web service effects are also uncertain. We do not consider
these generalizations here. Extending our notions accordingly should be straightforward, and is future work.

57

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

agree that  should hold in the updated state of affairs,  |= . Major differences lie in what
exactly it should be taken to mean that  should be as close as possible to . Various authors, for
example Brewka and Hertzberg (1993), McCain and Turner (1995), Herzig (1996), and Giunchiglia
and Lifschitz (1998), argue that a notion of causality is needed, in addition to (or even instead of) a
notion of integrity constraints, to model domain behavior in a natural way. We do not counter these
arguments, but neither do we follow a causal approach in our work. The reason is that ontologies
in the context of WSC, for example ontologies formulated in the web ontology language OWL
(McGuinness & van Harmelen, 2004), do not incorporate a notion of causality. All we are given is a
set of axioms, made with the intention to describe the behavior of the domain itself, rather than the
behavior it exhibits when changed by some particular web services. Our idea in this work is to try
to leverage on what we have (or what we are reasonably close to having). Consideration of causal
approaches in WSC is left for future work.
Belief update is a computationally very hard problem. Eiter and Gottlob (1992) and Liberatore
(2000) show that, for the non-causal approaches to defining  , reasoning about  is typically
harder than reasoning in the class of formulas used for formulating  and . Specifically, deciding
whether or not a particular literal is true in  is 2p -hard even if  is a complete conjunction of
literals (corresponding to a single world state) and  is a propositional CNF formula. The same
problem is coNP-hard even if  is a single world state and  is a propositional Horn formula. We
use these results to show that, in our planning formalism, checking a plan  testing whether or
not a given action sequence is a plan  is 2p -complete, and deciding polynomially bounded plan
existence is 3p -complete.
Given this complexity, it is perhaps unsurprising that the support for integrity constraints in current planning tools is severely limited. The only existing planning tools that do support integrity
constraints, namely those by Eiter et al. (2003) and Giunchiglia et al. (2004), are based on generic
deduction, like satisfiability testing or answer set programming. They hence lack the planningspecific heuristic and search techniques that are the key to scalability in the modern planning tools
developed since the mid-nineties. It has not even been investigated yet if and how integrity constraints could be handled in the latter tools. The only existing approach that ventures in this direction implements so-called derived predicates in some of the modern planning tools (Thiebaux,
Hoffmann, & Nebel, 2005; Gerevini, Saetti, Serina, & Toninelli, 2005; Chen et al., 2006). This
approach postulates a strict distinction between basic predicates that may be affected by actions,
and derived predicates that may be affected by integrity constraints taking the form of logic programming rules. If a predicate appears in an action effect, then it is not allowed to appear in the
head of a rule. This is not a desirable restriction in the context of WSC, where web services are
bound to affect properties that are constrained by ontology axioms.
The existing work connecting WSC with belief update (Lutz & Sattler, 2002; Baader et al.,
2005; Liu et al., 2006b, 2006a; de Giacomo et al., 2006) is of a theoretical nature. The actual implemented WSC tools make severe simplifying assumptions. Most often, that assumption is to ignore
the ontology axioms (Ponnekanti & Fox, 2002; Srivastava, 2002; McIlraith & Son, 2002; Sheshagiri
et al., 2003; Sirin, Parsia, Wu, Hendler, & Nau, 2004; Pistore et al., 2005b, 2005a). Sometimes,
the ontology constraints are restricted to subsumption hierarchies, which makes the update problem
easy (Constantinescu & Faltings, 2003; Constantinescu, Faltings, & Binder, 2004b, 2004a). Sirin
and Parsia (2004) and Sirin, Parsia, and Hendler (2006) discuss the problem of dealing with ontology axioms in WSC, but do not make a connection to belief update, and describe no alternative
solution. Finally, some authors, for example Meyer and Weske (2006), do deal with ontology ax58

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

ioms during composition, but do not provide a formal semantics and do not specify exactly how
action applications are handled. It seems that these not fully formalized WSC approaches implicitly
assume a message-based framework. Those frameworks are closely related to the forward effects
special case identified herein.
2.3 Message-Based WSC
In message-based approaches to WSC, the composition semantics is based on chaining over input
and output messages of web services. The word message is not a standard term in this context.
Most authors use their own individual vocabulary. As far as we are aware, the first appearance of the
word message in a WSC paper title is in the work by Liu, Ranganathan, and Riabov (2007). This
work describes message-based WSC as follows. A solution is a directed acyclic graph (DAG) of
web services, where the input needed for web service (DAG graph node) w must be provided by the
outputs of the predecessors of w in the graph. That is, the plan determines fixed connections between
the actions. Reasoning, then, only takes place within these connections. Any two connections
between different output and input messages, i.e., any two graph edges ending in a different node,
are assumed to be mutually independent. Consider the following example for illustration. Say a web
service w has the effect hasAttributeA(c, d) where d is an output constant and c is an input (i.e., c
existed already prior to application of w). Say there is an axiom x, y : hasAttributeA(x, y) 
conceptB(x) expressing an attribute domain restriction. If x has y as a value of attribute A,
then x must be of concept B. Given this, ws effect implies conceptB(c). Now, suppose that our
belief prior to applying w did not constrain c to be of concept B. Then applying w leads to new
knowledge about c. Hence we need a non-trivial belief update taking into account the changed
status of c, and any implications that may have. Message-based WSC simply acts as if the latter is
not the case. It only checks whether w correctly supplies the inputs of the web services w that w
is connected to. That is, the new fact hasAttributeA(c, d) may be taken as part of a proof that the
effect of w implies the precondition of a connected web service w . But it is not considered at all
what implications hasAttributeA(c, d) may have with respect to the previous state of affairs. In
that sense, message-based WSC ignores the need for belief update.
The intuitions underlying message-based WSC are fairly wide-spread. Many papers use them
in a more or less direct way. There are many approaches that explicitly define WSC solutions to be
DAGs with local input/output connections as above (Zhan, Arpinar, & Aleman-Meza, 2003; Lecue
& Leger, 2006; Lecue & Delteil, 2007; Kona, Bansal, Gupta, & Hite, 2007; Liu et al., 2007; Ambite
& Kapoor, 2007). In various other works (Constantinescu & Faltings, 2003; Constantinescu et al.,
2004b, 2004a; Meyer & Weske, 2006), the message-based assumptions are more implicit. They
manifest themselves mainly in the sense that ontology axioms are only used to infer the properties
of output messages, and often only for checking whether the inferences imply that a desired input
message is definitely given.
Previous work on message-based WSC does not address at all how message-based WSC relates
to the various notions, like belief update, considered in the literature. One contribution of our work
is to shed some light on this issue, via the identification of the forward effects case which lies in
between message-based WSC and a full planning framework with belief update semantics.
Both message-based WSC and the forward effects case share the focus on outputs. Indeed,
the output constants generated by our actions can be viewed as messages. An output constant
represents an information object which is created by one web service, and which will form the

59

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

input of some other web service. In the forward effects case, due to the restriction on axioms, the
individual messages do not interact. This is much like message-based WSC. The main difference is
this: while message-based WSC ignores any possible interactions, in forward effects there actually
arent any interactions, according to a formal planning-based execution semantics. In that sense,
forward effects correspond to a special case of WSC where the assumptions of message-based WSC
are justified.
Reconsider our example from above, featuring a web service w with an effect implying that
conceptB(c) where c is a pre-existing constant. As explained above, message-based WSC will
simply ignore the need for updating the knowledge about c. In contrast, the forward effects case
disallows the axiom x, y : hasAttributeA(x, y)  conceptB(x) because it may lead to new
conclusions about the old belief (note that the literals in the axiom refer to different sets of variables).
The forward effects case also differs significantly from most approaches to message-based WSC
in terms of the flexibility with which it allows to combine actions into plans. In the messagebased approach using DAGs, a solution DAG ensures that the inputs of each service w can always
be provided by ws predecessors. That is, we have a plug-in match between the set W of ws
predecessors in the DAG, and w itself. Note that this is slightly more general than the usual notion
of plug-in matches, in that |W | may be greater than 1, and hence each single service in W may have
only a partial match with w. This is the notion used, amongst others, by Liu et al. (2007). Other
authors, for example Lecue and Leger (2006) and Lecue and Delteil (2007), are more restrictive in
that they consider every individual input x of w in turn and require that there exists a w  W so that
w has a plug-in match with x (i.e., w guarantees to always provide x). Even in the more generous
of these two definitions, partial matches are restricted to appear locally, on DAG links. Every
action/web service is required to be always executable at the point where it is applied. In other
words, the services are used in a fixed manner, not considering the dynamics of actual execution.
In Example 1, this would mean using the same information services regardless of the class of the
protein, hence completely ignoring what is relevant and what is not.
The forward effects case incorporates a much more general notion of partial matches. This happens in a straightforward way, exploiting the existing notions from planning, in the form of a conditional effects semantics. The standard notion of a conformant solution defines how partial matches
must work together on a global level, to accomplish the goal. To the best of our knowledge, there
is only one other line of work on WSC, by Constantinescu et al. (Constantinescu & Faltings, 2003;
Constantinescu et al., 2004b, 2004a), that incorporates a comparable notion of partial matches. In
that work, web services are characterized in terms of input and output types. To handle partial
matches, so-called switches combine several web services in a way that ascertains all relevant
cases can be covered. The switches are designed relative to a subsumption hierarchy over the types.
Note that subsumption hierarchies are a special case of the much more general integrity constraints
 universally quantified clauses  that we consider in our work.

3. Formalizing WSC
As a solid basis for addressing WSC, we define a planning formalism featuring integrity constraints,
on-the-fly creation of output constants, incomplete initial state descriptions, and actions with a conditional effects semantics. The application of actions is defined as a belief update operation, following the possible models approach by Winslett (1988). That definition of belief update is somewhat
canonical in that it is very widely used and discussed. In particular it underlies all the recent work

60

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

relating to formalizations of WSC (Lutz & Sattler, 2002; Baader et al., 2005; Liu et al., 2006b,
2006a; de Giacomo et al., 2006; de Giacomo, Lenzerini, Poggi, & Rosati, 2007). As we will show
further below (Section 4.3), most belief update operations are equivalent anyway as soon as we
are in the forward effects case. Recall here that the forward effects case is the central object of
investigation in this paper.
We first give the syntax of our formalism, which we denote with WSC, then we give its semantics. We conclude with an analysis of its main computational properties.
3.1 Syntax
We denote predicates with G, H, I, variables with x, y, z, and constants with c, d, e. Literals are possibly negated predicates whose arguments are variables or constants. If all arguments are constants,
the literal is ground. We refer to positive ground literals as propositions. Given a set P of predicates
and a set C of constants, we denote by P C the set of all propositions that can be formed from P
and C. Given a set X of variables, we denote by LX the set of all literals l which use only variables
from X. Note here that l may use arbitrary predicates and constants.7 If l is a literal, we write
l[X] to indicate that l has the variable arguments X. If X = {x1 , . . . , xk } and C = (c1 , . . . , ck ),
then by l[c1 , . . . , ck /x1 , . . . , xk ] we denote the respective substitution, abbreviated as l[C]. In the
same way, we use the substitution notation for any construct involving variables. Slightly abusing
notation, we use a vector of constants also to denote the set of constants appearing in it. Further, if
a function a assigns constants to the variables X, then by l[a/X] we denote the substitution where
each argument x  X was replaced with a(x). We are only concerned with first-order logic, that is,
whenever we write formula we mean a first-order formula. We denote true as 1 and false as 0.
A clause, or integrity constraint, is a disjunction of literals with universal quantification on the
outside. The variables quantified over are exactly those that appear in at least one of the literals. For
example, x, y : G(x, y)  H(x) is an integrity constraint but x, y, z : G(x, y)  H(x) and x :
G(x, y)H(x) are not. An operator o is a tuple (Xo , preo , Yo , effo ), where Xo , Yo are sets of variables, preo is a conjunction of literals from LXo , and effo is a conjunction of literals from LXo Yo .8
The intended meaning is that Xo are the inputs and Yo the outputs, i.e., the new constants created by
the operator. For an operator o, an action a is given by (prea , effa )  (preo , effo )[Ca /Xo , Ea /Yo ]
where Ca and Ea are vectors of constants. For Ea we require that the constants are pairwise different  it makes no sense to output the same new constant twice. Given an action a, we will refer
to as inputs and outputs by Ca and Ea , respectively. We will also use the notations prea , effa with
the obvious meaning.
A WSC task, or planning task, is a tuple (P, IC , O, C0 , 0 , G ). Here, P is a set of predicates.
IC is a set of integrity constraints. O is a set of operators and C0 is a set of constants, the initial
constants supply. 0 is a conjunction of ground literals, describing the possible initial states. G
is a conjunction of literals with existential quantification on the outside, describing the goal states,
e.g., x, y : G(x)  H(y). All predicates are taken from P, and all constants are taken from C0 .
All constructs (e.g., sets and conjunctions) are finite. We will sometimes identify IC with the
conjunction of the clauses it contains. Note that the existential quantification of the goal variables
7. One could of course introduce more general notations for logical constructs using some set of predicates or constants.
However, herein the two notations just given will suffice.
8. As stated, we do not address disjunctive or non-deterministic effects. This is a topic for future work.

61

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

provides the option to instantiate the goal with constants created during planning  obtaining objects
as requested by the goal may be possible only through the use of outputs.
The various formulas occurring in (P, IC , O, C0 , 0 , G ) may make use of constants from C0 .
Specifically, this is the case for clauses in IC and for the goal formula G . Allowing such use of
constants does not have any effect on our complexity or algorithmic results. It is conceivable that
the feature may be useful. As a simple example, in the VTA domain the user may wish to select a
particular train. Say the train company provides a table of trains with their itineraries. That table can
be represented in 0 , possibly with help from IC stating constraints that hold for particular trains.
The user can then select a train, say ICE107, and pose as a goal that y : ticketFor (y, ICE107).
Constraining the produced ticket in this way would not be possible without the use of pre-existing
constants (or would at least require a rather dirty hack, e.g., encoding the desired train in terms of a
special predicate).
Operator descriptions, that is, preconditions and effects, may also use constants from C0 . The
value of this is more benign than for IC and G because one can always replace a constant c in
the precondition/effect with a new input/output variable x, and instantiate x (during planning) with
c. Note, however, that this would give the planner the option to (uselessly) instantiate x with some
other constant, and may hence affect planning performance. In our above example, there might be a
special operator booking a ticket for ICE107 (e.g., if that train has particular ticketing regulations).
The correspondence of a WSC task to a web service composition task is fairly obvious. The
set P of predicates is the formal vocabulary used in the underlying ontology. The set IC of
integrity constraints is the set of axioms specified by the ontology, i.e., domain constraints such as
subsumption relations. The set O of operators is the set of web services. Note that our formalization
corresponds very closely to the notion of IOPE descriptions: inputs, outputs, preconditions, and
effects (Ankolekar et al., 2002; Burstein et al., 2004). An action corresponds to a web service call,
where the web services parameters are instantiated with the call arguments.
The constructs C0 , 0 , and G are extracted from the user requirement on the composition.
We assume that such requirements also take the form of IOPE descriptions. Then, C0 are the
user requirement inputs, and 0 is the user requirement precondition. In other words, C0 and 0
describe the input given to the composition by the user. Similarly, G is the user requirement effect
 the condition that the user wants to be accomplished  and the user requirement outputs are the
(existentially quantified) variables in G .
3.2 Semantics
In what follows, assume we are given a WSC task (P, IC , O, C0 , 0 , G ). To be able to model
the creation of constants, states (also called world states) in our formalism are enriched with the set
of constants that exist in them. A state s is a pair (Cs , Is ) where Cs is a set of constants, and Is is a
Cs -interpretation, i.e., a truth value assignment Is : P Cs 7 {0, 1}. Quantifiers are taken to range
over the constants that exist in a state. That is, if I is a C-interpretation and  is a formula, then by
writing I |=  we mean that I |= C where C is the same as  except that all quantifiers were
restricted to range over C. To avoid clumsy notation, we will sometimes write s |=  to abbreviate
Is |= .
The core definition specifies how the application of an action affects a state. This is defined
through a form of belief update. Let us first define the latter. Assume a state s, a set of constants
C   Cs , and a formula . We define update(s, C  , ) to be the set of interpretations that result

62

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

from creating the constants C  \ Cs , and updating s with  according to the semantics proposed by
Winslett (1988).
Say I1 and I2 are C  -interpretations. We define a partial order over such interpretations, by
setting I1 <s I2 if and only if
{p  P Cs | I1 (p) 6= Is (p)}  {p  P Cs | I2 (p) 6= Is (p)}.

(1)

In words, I1 is ordered before I2 iff it differs from s in a proper subset of values. Given this, we can
now formally define update(s, C  , ). Let I be an arbitrary C  -interpretation. We define
I  update(s, C  , ) : I |=  and {I  | I  |= , I  <s I} = .

(2)

Hence, update(s, C  , ) is defined to be the set of all C  -interpretations which satisfy , and which
are minimal with respect to the partial order <s . Put in different terms, update(s, C  , ) contains
all interpretations that differ from s in a set-inclusion minimal set of values.
Now, assume an action a. We say that a is applicable in s, short appl(s, a), if s |= prea ,
Ca  Cs , and Ea  Cs = . That is, on top of the usual precondition satisfaction we require that
as inputs exist and that as outputs do not yet exist. The result of executing a in s is:

{(C  , I  ) | C  = Cs  Ea , I   update(s, C  , IC  effa )} appl(s, a)
(3)
res(s, a) :=
{s}
otherwise
Note that a can be executed in s even if it is not applicable. In that case, the outcome is the singleton
set containing s itself, i.e., the action does not affect the state. This is an important aspect of our
formalism, which we get back to below. If IC  effa is unsatisfiable, then obviously we get
res(s, a) = . We say in this case that a is inconsistent.9
The overall semantics of WSC tasks is now easily defined via a standard notion of beliefs. These
model our uncertainty about the true state of the world. A belief b is the set of world states that are
possible at a given point in time. The initial belief is
b0 := {s | Cs = C0 , s |= IC  0 }.

(4)

An action a is inconsistent with a belief b if it is inconsistent with at least one s  b. In the latter
case, res(b, a) is undefined. Otherwise, it is defined by
[
res(s, a).
(5)
res(b, a) :=
sb

This is extended to action sequences in the obvious way. A plan is a sequence ha1 , . . . , an i so that
s  res(b0 , ha1 , . . . , an i) : s |= G .

(6)

For illustration, consider the formalization of our example from Section 2.
Example 2 Reconsider Example 1. For the sake of conciseness, we formalize only a part of the
example, with simplified axioms. The WSC task is defined as follows:
9. Unless IC mentions any constants, if a is based on operator o and a is inconsistent, then any action based on o is
inconsistent. Such operators can, in principle, be filtered out in a pre-process to planning.

63

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

 P = {protein, cellProtein, G, H, I, 1n55, 1kw3, InfoDSSP, Info3D, combinedPresentation},
where all the predicates are unary.
 IC consists of the clauses:
 x : cellProtein(x)  protein(x)  [subsumption]
 x : protein(x)  G(x)  H(x)  I(x)  [at least one DSSP value]
 x : protein(x)  1n55(x)  1kw3(x)  [at least one 3-D shape]
 x : cellProtein(x)  G(x)  1n55(x)  [dependency]
 x : cellProtein(x)  H(x)  1n55(x)  [dependency]
 O consists of the operators:
 getInfoDSSPG : ({x}, G(x), {y}, InfoDSSP(y))
 getInfoDSSPH : ({x}, H(x), {y}, InfoDSSP(y))
 getInfoDSSPI : ({x}, I(x), {y}, InfoDSSP(y))
 getInfo3D1n55 : ({x}, 1n55(x), {y}, Info3D(y))
 getInfo3D1kw3 : ({x}, 1kw3(x), {y}, Info3D(y))
 combineInfo: ({x1 , x2 }, InfoDSSP(x1 )  Info3D(x2 ), {y}, combinedPresentation(y))
 C0 = {c}, 0 = cellProtein(c)
 G = x : combinedPresentation(x)
To illustrate the formalism, we now consider a plan for this example task.
The initial belief b0 consists of all states s where Cs = {c} and s |= IC  cellProtein(c). Say
we apply the following sequence of actions:
1. Apply getInfoDSSPG (c, d) to b0 . Then we get to the belief b1 which is the same as b0 except
that, from all s  b0 where s |= G(c), new states are generated that have the constant d and
InfoDSSP(d).
2. Apply getInfoDSSPH (c, d) to b1 . We get the belief b2 where new states with d and
InfoDSSP(d) are generated from all s  b1 where s |= H(c).
3. Apply getInfo3D1n55 (c, e) to b2 , yielding b3 .
4. Apply getInfo3D1kw3 (c, e) to b3 . This yields b4 , where we get e and Info3D(e) from all s  b2
where s |= 1n55(c) or s |= 1kw3(c).
5. Apply combineInfo(d, e, f ) to b4 . This brings us to b5 which is like b4 except that from all
s  b4 where d, e  Cs new states are generated that have f and combinedPresentation(f ).
From the dependencies in IC (the last two clauses), we get that any s  b0 satisfies either G(c) or
H(c). From the subsumption clause and the clause regarding 3-D shapes (first and third clauses)
we get that any s  b0 satisfies either 1n55(c) or 1kw3(c). Hence, as is easy to verify, b5 |=
G and so hgetInfoDSSPG (c, d), getInfoDSSPH (c, d), getInfo3D1n55 (c, e), getInfo3D1kw3 (c, e),
combineInfo(d, e, f )i is a plan.
64

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

Note that this plan does not make use of getInfoDSSPI (c, d). To obtain a plan, in this domain
one can always just apply all information services. However, this plan is trivial and does not take
into account what is relevant and what is not. Reasoning over IC enables us to find better plans.
Our semantics for executing non-applicable actions is vital for the workings of Example 2. As
pointed out above, below the definition of res(s, a) (Equation (3)), a can be executed in s even if it
is not applicable. This realizes partial matches: a web service can be called as soon as it might match
one of the possible situations. In planning terms, our actions have a conditional effects semantics.10
The contrasting notion would be to enforce preconditions, i.e., to say that res(s, a) is undefined if
a is not applicable to s. This would correspond to plug-in matches.
In Example 2, the partial match semantics is necessary in order to be able to apply actions that
cover only particular cases. For example, consider the action getInfoDSSPG (c, d), which is applied
to the initial belief in the example plan. The precondition of that action is G(c). However, there
are states in the initial belief which do not satisfy that precondition. The initial belief allows any
interpretation satisfying IC  0 (cf. Equation (4)), and some of these interpretations satisfy H(c)
rather than G(c). Due to the partial match semantics, getInfoDSSPG (c, d) does not affect such
states  its match with the initial belief is partial.
Clarification is also in order regarding our understanding of constants. First, like every PDDLlike planning formalism (we are aware of), we make a unique name assumption, i.e., different
constants refer to different objects. Second, our understanding of web services is that any output
they create is a separate individual, i.e., a separate information object.
The latter directly raises the question why we allow actions to share output constants. The
answer is that we allow the planner to treat two objects as if they were the same. This makes
sense if the two objects play the same role in the plan. Consider again Example 2. The actions
getInfoDSSPG (c, d) and getInfoDSSPH (c, d) share the same output constant, d. This means that
d is one name for two separate information objects. These two objects have the same properties,
derived from InfoDSSP(d). The only difference between them is that they are created in different
cases, namely from states that satisfy G(c) and H(c) respectively. Having a single name for the
two objects is useful because we can take that name as a parameter of actions that do not need to
distinguish between the different cases. In the example, combineInfo(d, e, f ) is such an action.
As hinted, the cases in the above correspond to different classes of concrete execution traces.
Importantly, on any particular execution trace, each output constant is created at most once. To see
this, consider an execution trace s0 , a0 , s1 , a1 , . . . , ak , sk+1 , i.e., an alternating sequence of states
and actions where s0  b0 , and si+1  res(si , ai ) for all 0  i  k. Say that ai and aj share
an output constant, d. Say further that ai is applicable in si , and hence d  Csi+1 . Then, quite
obviously, we have d  Csl for all i + 1  l  k + 1. In particular, aj is not applicable in sj : the
intersection of its output constants with Csj is non-empty (cf. the definition of appl(s, a)). So, due
to our definition of action applicability, it can never happen that the same constant is created twice.
In other words, there can never be a reachable state where a single constant name refers to more
than one individual information object. In that sense, the use of one name for several objects occurs
only at planning time, when the actual execution trace  the actual case which will occur  is not
known. For illustration, consider getInfoDSSPG (c, d) and getInfoDSSPH (c, d), and their shared
10. An obvious generalization is to allow several conditional effects per action, in the style of the ADL language (Pednault, 1989). We omit this here for the sake of simplifying the discussion. An extension in this direction is straightforward.

65

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

output d, in Example 2. Even if the concrete state s0  b0 in which the execution starts satisfies
both G(c) and H(c), only one of the actions will fire  namely the one that comes first.
We remark that we initially experimented with a definition where actions instantiate only their
inputs, and when they are applied to a state s their outputs are, by virtue of the execution semantics,
instantiated to constants outside of Cs . In such a framework, one can never choose to share output
constants, i.e., to use the same name for two different outputs. The notion we have settled for is
strictly richer: the planner can always choose to instantiate the outputs with constants outside of Cs .
The question is, when does it make sense to share outputs? Answering this question in a domainindependent planner may turn out to be quite non-trivial. We get back to this when we discuss a
possible adaptation of CFF in Section 4.5. In the experiments reported herein (Section 6), we use a
simple heuristic. Outputs are shared iff the operator effects are identical (giving an indication that
the respective outputs may indeed play the same role in the plan).
We conclude this sub-section with a final interesting observation regarding modeling in our
framework. Negative effects are not an essential part of the WSC formalism: they can be compiled
away. We simply replace any negative effect G(x1 , . . . , xk ) with notG(x1 , . . . , xk ) (introducing
a new predicate) and state in the integrity constraints that the two are equivalent. That is, we introduce the two new clauses x1 , . . . , xk : G(x1 , . . . , xk )  notG(x1 , . . . , xk ) and x1 , . . . , xk :
G(x1 , . . . , xk )  notG(x1 , . . . , xk ). While this is a simple compilation technique, the formal
details are a little intricate, and are moved to Appendix A. If a is an action in the original task, then
a+ denotes the corresponding action in the compiled task, and vice versa. Similarly, if s is an action
in the original task, then s+ denotes the corresponding state in the compiled task. We get:
Proposition 1 (Compilation of Negative Effects in WSC) Assume a WSC task (P, IC , O, C0 ,
+
0 , G ). Let (P + , +
IC , O , C0 , 0 , G ) be the same task but with negative effects compiled away.
Assume an action sequence ha1 , . . . , an i. Let b be the result of executing ha1 , . . . , an i in (P, IC ,
+
+
+
+
O, C0 , 0 , G ), and let b+ be the result of executing ha+
1 , . . . , an i in (P , IC , O , C0 , 0 , G ).
Then, for any state s, we have that s  b iff s+  b+ .
This can be proved by straightforward application of the relevant definitions. The most important aspect of the result is that the new clauses introduced are allowed in the forward effects and
strictly forward effects special cases identified later. Hence, any hardness results transfer directly to
tasks without negative effects and dropping negative effects cannot make the algorithms any easier.
3.3 Computational Properties
We now perform a brief complexity analysis of the WSC formalism in its most general form as
introduced above. In line with many related works of this kind (Eiter & Gottlob, 1992; Bylander,
1994; Liberatore, 2000; Eiter et al., 2004), we consider the propositional case. In our context, this
means that we assume a fixed upper bound on the arity of predicates, on the number of input/output
parameters of each operator, on the number of variables appearing in the goal, and on the number of
variables in any clause. We will refer to WSC tasks restricted in this way as WSC tasks with fixed
arity.
We consider the problems of checking plans  testing whether or not a given action sequence is a
plan  and of deciding plan existence. For the latter, we distinguish between polynomially bounded
plan existence, and unbounded plan existence. We deem these to be particularly relevant decision
problems in the context of plan generation. Certainly, plan checks are an integral part of plan gen66

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

eration. Indeed, if a planning tool is based on state space search, then the tool either performs such
checks explicitly for (potentially many) plan candidates generated during search, or this complexity
is inherent in the effort that underlies the computation of state transitions. Polynomially bounded
plan existence is relevant because, in most commonly used planning benchmark domains, plans are
of polynomial length (it is also a very wide-spread intuition in the SWS community that composed
web services will not contain exceedingly large numbers of web services). Finally, unbounded plan
existence is the most general decision problem involved, and thus is of generic interest.
All the problems turn out to be very hard. To prove this, we reuse and adapt various results from
the literature. We start with the complexity of plan checking, for which hardness follows from a
long established result (Eiter & Gottlob, 1992) regarding the complexity of belief update. For all
the results, detailed proofs are available in Appendix A.
Theorem 1 (Plan Checking in WSC) Assume a WSC task with fixed arity, and a sequence
ha1 , . . . , an i of actions. It is p2 -complete to decide whether ha1 , . . . , an i is a plan.
Proof Sketch: Membership can be shown by a guess-and-check argument. Guess the proposition
values along ha1 , . . . , an i. Then check whether these values comply with res, and lead to an
inconsistent action, or to a final state that does not satisfy the goal. ha1 , . . . , an i is a plan iff this is
not the case for any guess of proposition values. Checking goal satisfaction is polynomial, checking
compliance with res is in coNP, checking consistency is in NP.
Hardness follows by a simple adaptation of the proof of Lemma 6.2 from Eiter and Gottlob
(1992). That proof uses a reduction from checking validity of a QBF formula X.Y.[X, Y ]. The
lemma considers the case where a propositional belief  is updated with an arbitrary (propositional)
formula , and the decision problem is to ask whether some other formula  is implied by the
updated belief. In the proof,  is a complete conjunction of literals, i.e.,  corresponds to a single
world state.  is a single propositional fact r which is true in . The semantics of X.Y.[X, Y ]
are encoded in a complicated construction defining the update . In a nutshell,  is a CNF telling
us that for every assignment to X (which will yield a world state s in the updated belief), we either
have to find an assignment to Y so that [X, Y ] holds (completing s ), or we have to falsify r.
The difference in our setting lies in our very restricted update formulas  action effects  and
in the fact that the integrity constraints are supposed to hold in every belief. We adapt the above
proof by, first, taking the integrity constraints to be the clauses in Eiter and Gottlobs CNF formula
. We then modify the constraints so that they need only be true if a new fact t holds  i.e., we insert
t into every clause. The initial belief has t false, and otherwise corresponds exactly to  as above.
The only action of the plan makes t true. The goal is Eiter and Gottlobs fact r.
2
We remark that membership in Theorem 1 remains valid when allowing actions with multiple
conditional effects, when allowing parallel actions, and even when allowing their combination. On
the other hand, by virtue of the proof argument as outlined, hardness holds even if the initial state
literals 0 are complete (describe a single world state), the plan consists of a single action with a
single positive effect literal, and the goal is a single propositional fact that is initially true.
We next consider polynomially bounded plan existence. For this, membership follows directly
from Theorem 1. To prove hardness, we construct a planning task that extends Eiter and Gottlobs
construction from above with actions that allow to choose a valuation for a third, existentially quantified, set of variables, and hence reduces validity checking of a QBF formula X.Y.Z.[X, Y, Z].

67

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

Theorem 2 (Polynomially Bounded Plan Existence in WSC) Assume a WSC task with fixed arity, and a natural number b in unary representation. It is p3 -complete to decide whether there exists
a plan of length at most b.
Proof: For membership, guess a sequence of at most b actions. By Theorem 1, we can check with
a p2 oracle whether the sequence is a plan.
For hardness, validity of a QBF formula X.Y.Z.[X, Y, Z], where  is in CNF, is reduced
to testing plan existence. Say X = {x1 , . . . , xn }. In the planning task, there are n actions (operators
with empty input/output parameters) oxi and oxi of which the former sets xi to true and the latter
sets xi to false. Further, there is an action ot which corresponds to the action used in the hardness
proof of Theorem 1. The actions are equipped with preconditions and effects ensuring that any
plan must first apply, for all 1  i  n, either oxi or oxi , and thereafter must apply ot (of course
enforcing the latter also requires a new goal fact that can be achieved only by ot ). Hence, choosing
a plan candidate in this task is the same as choosing a value assignment aX for the variables X.
In our construction, after all the oxi and oxi actions have been executed, one ends up in a belief
that contains a single world state, where the value assignment aX for the variables X corresponds
to the chosen actions. This world state basically corresponds to the belief  as in the hardness proof
of Theorem 1. The only difference is that the construction has been extended to cater for the third
set of variables. This is straightforward. Then, the belief that results from executing ot satisfies the
goal iff Eiter and Gottlobs fact r holds in all its world states. By virtue of similar arguments to
those of Eiter and Gottlob, the latter is the case iff Y.Z.[aX /X, Y, Z], i.e., the substitution of
X.Y.Z.[X, Y, Z] with aX , is valid. From this, the claim follows.
2
Our final result regards unbounded plan existence in WSC. The result is relatively easy to
obtain from the generic reduction described by Bylander (1994) to prove PSPACE-hardness of plan
existence in STRIPS. Somewhat shockingly, it turns out that plan existence in WSC is undecidable
even without any integrity constraints, and with a complete initial state description. The source of
undecidability is, of course, the ability to generate new constants on-the-fly.
Theorem 3 (Unbounded Plan Existence in WSC) Assume a WSC task. The decision problem
asking whether a plan exists is undecidable.
Proof Sketch: By a modification of the proof by Bylander (1994) that plan existence in propositional STRIPS planning is PSPACE-hard. The original proof proceeds by a generic reduction,
constructing a STRIPS task for a Turing Machine with polynomially bounded space. The latter restriction is necessary to model the machines tape: tape cells are pre-created for all positions within
the bound. Exploiting the ability to create constants on-the-fly, we can instead introduce simple
operators that allow to extend the tape, at both ends.
2
Not being able to decide plan existence is, of course, a significant limitation in principle. However, this limitation is probably of marginal importance in practice, because most planning tools
just assume that there is a plan, and they try to find it  rather than trying to prove that there is
no plan. In that sense, most planning tools are, by their nature, semi-decision procedures anyway.
What matters more than decidability in such a setting is the question whether one can find a plan

68

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

quickly enough, i.e., before exhausting time or memory.11 This is also the most relevant question in
web service composition.

4. Forward Effects
The high complexity of planning in WSC motivates the search for interesting special cases. We
define a special case, called forward effects, where every change an action makes to the state involves
a newly generated constant.
We start the section by defining the forward effects case and making a core observation about
its semantics. We then discuss the modeling power of this special case. Next, we discuss forward effects from a more general perspective of belief update. We analyze the main computational
properties of forward effects, and we conclude the section with an assessment of how an existing
planning tool could be adapted to handle forward effects.
4.1 WSC|f wd and its Semantics
The forward effects special case of WSC is defined as follows.
Definition 1 Assume a WSC task (P, IC , O, C0 , 0 , G ). The task has forward effects iff:
1. For all o  O, and for all l[X]  effo , we have X  Yo 6= .
2. For all clauses   IC , where  = x1 , . . . , xk : l1 [X1 ]      ln [Xn ], we have X1 =
   = Xn .
The set of all WSC tasks with forward effects is denoted with WSC|f wd .
The first condition says that the variables of every effect literal contain at least one output variable. This implies that every ground effect literal of an action contains at least one new constant. The
second condition says that, within every integrity constraint, all literals share the same arguments.
This implies that effects involving new constants can only affect literals involving new constants.
Note that, since x1 , . . . , xk are by definition exactly the variables occurring in any of the literals,
for each Xi we have Xi = x1 , . . . , xk . Note further that we may have k = 0, i.e., the literals
in the clause may be ground. This is intentional. The constants mentioned in the clause must be
taken from C0 , cf. the discussion in Section 3.1. Therefore, such clauses have no interaction with
statements about the new constants generated by a WSC|f wd action.
We will discuss the modeling power of WSC|f wd below (Section 4.2). First, we observe that
the semantics of WSC|f wd is much simpler than that of general WSC. One no longer needs the
notion of minimal change with respect to the previous state. To state this more precisely, assume a

WSC task with predicates P. Say I  is an interpretation over P C , where C  is a set of constants.
Say that C  C  . We denote by I  |C the restriction of I  to P C , i.e., the interpretation of P C that
coincides with I  on all these propositions. Given a state s and an action a, we define:

{(C  , I  ) | C  = Cs  Ea , I  |Cs = Is , I  |= IC  effa } appl(s, a)
(7)
res|f wd (s, a) :=
{s}
otherwise
11. Indeed the planning community is generally rather unconcerned by undecidability, cf. the numeric track of the international planning competitions, and Helmerts (2002) results on the decidability of numerical planning problems.

69

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

Compare this to Equation (3), where I  is defined to be a member of update(s, C  , IC  effa ),
which returns all interpretations that satisfy IC  effa and that differ minimally from Is . In Equation (7), I  is simply set to be identical to Is , on the constants (on the propositions over the constants)
that existed beforehand. In other words, the set of new states we get is the cross-product of the old
state with all satisfying assignments to IC  effa .
Lemma 1 (Semantics of WSC|f wd ) Assume a WSC|f wd task, a reachable state s, and an action
a. Then res(s, a) = res|f wd (s, a).
Proof Sketch: In WSC|f wd , if s differs minimally from s, then it follows that s agrees totally with
s, on the set of propositions P Cs interpreted by s. To see this, denote as before with P Cs +Ea the
set of all propositions with arguments in Cs  Ea , and with at least one argument in Ea , and denote
with IC [Cs + Ea ] the instantiation of IC with all constants from Cs  Ea , where in each clause
at least one variable is instantiated from Ea . The key argument is that s |= IC  effa is equivalent
to s |= IC [Cs  Ea ]  effa , which in turn is equivalent to s |= IC [Cs ]  IC [Cs + Ea ]  effa .
In the last formula, IC [Cs ] only uses the propositions P Cs , whereas IC [Cs + Ea ]  effa only
uses the propositions P Cs +Ea . Since s is reachable, we have s |= IC [Cs ]. Therefore, to satisfy
IC  effa , there is no need to change any of the values assigned by s.
2
4.2 Modeling Power
Intuitively, WSC|f wd covers the situation where a web service outputs some new constants, sets
their characteristic properties relative to the inputs, and relies on the ontology axioms to describe any
ramifications concerning the new constants. As was detailed in Section 2, this closely corresponds
to the various notions of message-based WSC explored in the literature. In that sense, the modeling
power of WSC|f wd is comparable to that of message-based WSC, one of the most-widespread
approaches in the area.
A simple concrete way of assessing the modeling power of WSC|f wd is to consider the allowed
and disallowed axioms. Examples of axioms that are not allowed by WSC|f wd are: attribute domain
restrictions, taking the form x, y : G(x, y)  H(x); attribute range restrictions, taking the form
x, y : G(x, y)  H(y); and relation transitivity, taking the form x, y, z : G(x, y)  G(y, z) 
G(x, z). Note that, for all these axioms, it is easy to construct a case where an action effect, even
though it involves a new constant, affects the old belief. For example, if constants c and e existed
beforehand, and an action outputs d and sets G(c, d)  G(d, e), then the axiom x, y : G(x, y) 
G(y, z)  G(x, z) infers that G(c, e)  a statement that does not involve the new constant d.
Typical ontology axioms that are allowed by WSC|f wd are: subsumption relations, taking
the form x : G(x)  H(y); mutual exclusion, taking the form x : G(x)  H(y); relation reflexivity, taking the form x : G(x, x); and relation symmetry, taking the form x, y :
G(x, y)  G(y, x). We can also express that a concept G is contained in the union of concepts
H1 , . . . , Hn , and more generally we can express any complex dependencies between concepts, taking the form of clausal constraints on the allowed combinations of concept memberships.
One example where complex dependencies are important is the domain of proteins as illustrated
in Example 1. Capturing the dependencies is important here in order to be able to select the correct web services. Similar situations arise in many domains that involve complex interdependencies
and/or complex regulations. An example for the latter is the Virtual Travel Agency which we discussed before. For example, in the German rail system there are all kinds of regulations regarding
70

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

which train may be booked with which kind of discount under which conditions. Modeling these
regulations would enable a WSC algorithm to select the appropriate booking services. Another interesting case is the hospital domain described by de Jonge, van der Linden, and Willems (2007).
There, the problem of hospital asset tracking is handled by means of a set of tracking, logging and
filter services, which transform logs to extract various kinds of information. In this setting, it would
make sense to model complex dependencies so that the web service composer may determine which
hospital assets need to be tracked and retrieved. Namely, the latter depends on the type of operation
in question, and on the kind of examinations which that operation requires. Accordingly, what we
need to model is a categorization of operations, their mapping to sets of required examinations, and
how those examinations are associated with hospital assets. Further complications arise since the
required examinations/assets may depend on particular circumstances. Clearly, we can express the
categorization and dependencies in terms of clauses. While this of course captures only a fraction
of what is relevant in a hospital, it is considerably more informed than a composer which always
just tracks all the assets.
The main weakness of WSC|f wd is that it does not allow us to express changes regarding preexisting objects. This is best illustrated when considering the case of negative effects.12 In the
planning community, these are commonly used to model how previous properties of objects are
invalidated by an action. For illustration, reconsider Example 1. Say there is an additional operator
dropCoffeeIn3Dmachine, with effect Info3D(y). One would normally expect that, when this
operator is applied, the fact Info3D(y) is deleted and must be re-established. This is not so in
WSC|f wd . According to the restrictions this special case imposes, the variable y in Info3D(y)
must be an output of dropCoffeeIn3Dmachine. That is, dropping coffee into the machine creates a
new object, whose characteristic property happens to be Info3D(y) rather than Info3D(y). Clearly,
this is not the intended semantics of the operator.
To model the intended semantics, we would need to instantiate y with a pre-existing constant.
Say that, as in belief b3 in Example 1, a constant e with Info3D(e) was previously created by
getInfo3D1n55 (c, e). Then WSC|f wd does allow us to instantiate dropCoffeeIn3Dmachine with
e, so that we have the effect Info3D(e). However, by virtue of the definition of action applicability,
that action will be applicable only in states where e does not yet exist  corresponding to execution
paths where getInfo3D1n55 (c, e) was not executed. Hence the property Info3D(e) does not get
deleted from any state, and e as used by dropCoffeeIn3Dmachine is still regarded as a newly
created object whose characteristic property is Info3D(y). The only difference the new action
makes is that, now, the plan uses the same name (e) to refer to two different information objects
(output of getInfo3D1n55 (c, e) vs. output of dropCoffeeIn3Dmachine) that do not play the same
role in the plan, cf. the discussion in Section 3.2.
An interesting workaround is to let the operators output time steps, in a spirit reminiscent of
the situation calculus (McCarthy & Hayes, 1969; Reiter, 1991). Every operator obtains an extra
output variable t, which is included into every effect literal. The new time step t is stated to stand
in some relation to the previous time steps, e.g., next(tprev, t) where tprev is an input variable
instantiated to the previous time step. In such a setting, we can state how the world changes over
time. In particular we can state that some object property is different in t than in tprev. For
example, if an action moves a file f from RAEDME to README then we could state that
name(f, RAEDME, tprev) and name(f, README, t). The problem with such a construction
12. Or, in WSC, positive effects triggering negative effects via IC , cf. Proposition 1.

71

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

is that the time steps have no special interpretation, they are just ordinary objects.13 This causes at
least two difficulties. (1) If we want to refer to an object property, we have to know the time step
in the first place  that is, we have to know whether the actual time step is t or tprev. Note here
that we cannot maintain a predicate actualTime(x) because this would require us to invalidate a
property of tprev. (2) There is no solution to the frame problem. The operators must explicitly state
every relevant property of the previous time step, and how each property is changed in the new time
step.14
To conclude this sub-section, let us consider how WSC|f wd can be generalized without losing
Lemma 1. Most importantly, instead of requiring that every effect literal involves a new constant,
one can postulate this only for literals that may actually be affected by the integrity constraints. In
particular, if a predicate does not appear in any of the clauses, then certainly an effect literal on
that predicate is not harmful even if it does not involve an output constant. One obtains a potentially stronger notion by considering ground literals, rather than predicates. Note that this kind of
generalization solves difficulty (1) of the time-step construction, presuming that time steps are not
constrained by the clauses. (The frame problem, however, persists.)
Another possibility, deviating somewhat from the way WSC and WSC|f wd are currently defined, is to define the integrity constraints in terms of logic programming style rules, along the lines
of Eiter et al. (2003, 2004). The requirement on WSC|f wd can then be relaxed to postulate that the
effect literals without new constants do not appear in the rule heads.
We remark that the latter observation suggests a certain strategic similarity with the aforementioned derived predicates (Thiebaux et al., 2005) previously used in AI Planning to manage the
complexity of integrity constraints. There, the integrity constraints take the form of stratified logic
programming style derivation rules, and the predicates appearing in rule heads are not allowed to
appear in operator effects. This is an overly restricted solution, in the WSC context. The effects
of web services are indeed very likely to affect concepts and relations appearing in the ontology
axioms. They may do so in WSC|f wd , as long as output constants are involved.
4.3 Belief Update
Lemma 1 is specific to the possible models approach (Winslett, 1988) that underlies our semantics
of action applications. It is interesting to consider the semantics of WSC|f wd from a more general
perspective of belief update. Recall that such an update involves a formula characterizing the current
belief, and a formula describing the update. We seek a formula that characterizes the updated belief.
A wide variety of definitions has been proposed as to how the updated belief should be defined.
However, some common ground exists. Katzuno and Mendelzon (1991) suggest eight postulates,
named (U1) . . . (U8), which every sensible belief update operation should satisfy. Herzig and Rifi
(1999) discuss in detail to what degree the postulates are satisfied by a wide range of alternative
belief update operators. In particular they call a postulate uncontroversial if all update operators
under investigation satisfy them. We will take up these results in the following. We examine to what
extent we can draw conclusions about the updated belief,  , in the setting of the forward effects
case, when relying only on Herzig and Rifis uncontroversial postulates.
13. Note that here the similarity to the situation calculus ends. Whereas time steps are assigned a specific role in the
formulas used in the situation calculus, here they are just ordinary objects handled by actions, as if they were packages
or blocks.
14. Despite these difficulties, Theorem 6 below shows that a time step construction can be used to simulate an Abacus
machine, and hence to prove undecidability of plan existence in WSC|f wd .

72

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

We assume that a planning task with predicates P is given. We need the following notations:
 If  and  are formulas, then    denotes the formula that results from updating the belief
 with the update , under some semantics for the belief update operator .
 Given disjoint sets of constants C and E, P C+E denotes the set of all propositions formed
from predicates in P, where all arguments are contained in C  E and there exists at least one
argument contained in E. (Recall that P C denotes the set of all propositions formed from
predicates in P and arguments from C.)
 Given a set of constants C, IC [C] denotes the instantiation of IC with C. That is, IC [C]
is the conjunction of all clauses that result from replacing the variables of a clause   IC ,
 = x1 , . . . , xk : l1 [X1 ]      ln [Xn ], with a tuple (c1 , . . . , ck ) of constants in C.
 Given disjoint sets of constants C and E, IC [C + E] is the conjunction of all clauses that
result from replacing the variables of a clause   IC ,  = x1 , . . . , xk : l1 [X1 ]     
ln [Xn ], with a tuple (c1 , . . . , ck ) of constants in C  E, where at least one constant is taken
from E.15
 If  is a ground formula then by P () we denote the set of propositions occurring in .
We will denote the current belief by  and the update by . As another convention, given a set of
constants C, by writing  C we indicate that P ()  P C . Similarly, given disjoint sets of constants
C and E, by writing  C+E we indicate that P ()  P C+E . If s is a state, then by s we denote
the conjunction of literals satisfied by s.
We first consider the case where, similar to the claim of Lemma 1,  corresponds to a single
concrete world state s. We want to apply an action a. We wish to characterize the set of states
res(s, a), i.e., we wish to construct the formula   . For simplicity of notation, denote C := Cs
and E := Ea . If a is not applicable to s, there is nothing to do. Otherwise, we have that:
(I)   IC [C]   C where P ( C )  P C .
For example, we can set  C := s . Since s |= IC , we get the desired equivalence. Further, we
have that:
(IIa)   IC [C]  IC [C + E]  effa ;
(IIb) P (IC [C + E])  P C+E and P (effa )  P C+E .
(IIa) holds trivially:  is defined as IC  effa , which is equivalent to IC [C  E]  effa which is
equivalent to IC [C]  IC [C + E]  effa . As for (IIb), this is a consequence of the forward effects
case. Every effect literal contains at least one output constant, hence effa contains only propositions
from P C+E . For IC [C + E], we have that at least one variable in each clause is instantiated with
a constant e  E. Since, by definition, all literals in the clause share the same variables, e appears
in every literal and therefore IC [C + E] contains only propositions from P C+E .
As an illustration, consider our simple VTA example. There are four predicates, train(x),
ticket(x), trainTicket(x), and ticketFor (x, y). The set of integrity constraints IC consists of
15. If no clause in IC contains any variable, then IC [C + E] is empty. As is customary, an empty conjunction is
taken to be true, i.e., 1.

73

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

the single axiom x : trainTicket(x)  ticket(x). In our current state s, we have Cs = {c},
and Is sets all propositions to 0 except for train(c). We consider the application of the action
a = bookTicket(c, d), whose precondition is train(c), whose set E of output constants is {d},
and whose effect effa is trainTicket(d)  ticketFor (d, c). In this setting, we have: IC [C] =
(trainTicket(c)  ticket(c));  C = (train(c)ticket(c)trainTicket(c)ticketFor (c, c));
and IC [C + E] = (trainTicket(d)  ticket(d)).
We will derive in the following that:
(III)     (IC [C]   C )  (IC [C + E]  effa ).
That is, we can characterize the updated belief simply by the conjunction of the previous belief
with the action effect and the extended instantiation of the ontology axioms. This corresponds
exactly to Lemma 1. To illustrate, we will continue the VTA example. The left hand side of (III)
refers to the four propositions based only on c, and sets them according to s. The right hand side
refers to propositions based only on d  trainTicket(d) and ticket(d)  as well as the proposition
ticketFor (d, c) which links c and d.
As one prerequisite of our derivation of (III), we have to make an assumption which, to the best
of our knowledge, is not discussed anywhere in the belief update literature:
(IV) Let 1 , 1 , 2 , 2 be formulas where P (1 )  P (1 ) = , P (1 )  P (2 ) = , P (2 ) 
P (1 ) = , and P (2 )  P (2 ) = . Then (1  1 )  (2  2 )  (1  2 )  (1  2 ).
This assumption postulates that formulas talking about disjoint sets of variables can be updated
separately. Since formulas with disjoint variables essentially speak about different aspects of the
world, this seems a reasonable assumption.
Now, we start from the formula   . We make replacements according to (I) and (IIa), leading
to the equivalent formula (IC [C]   C )  (IC [C]  IC [C + E]  effa ). We can map this
formula onto (IV) by taking 1 to be IC [C]   C , 1 to be 1, 2 to be IC [C], and 2 to be
IC [C + E]  effa . Hence, we can separate our update into two parts as follows:
(A) (  )C := (IC [C]   C )  IC [C]
(B) (  )C+E := 1  (IC [C + E]  effa )
According to (IV), we then obtain our desired formula    by     (  )C  (  )C+E .
Illustrating this with the VTA example, we simply separate the parts of the update that talk
only about c from those that talk only about d or the combination of both constants. The (A) part
of the update is trainTicket(c)  ticket(c) conjoined with s , updated with trainTicket(c) 
ticket(c). The (B) part of the update is 1  representing the (empty) statement that the previous state
s makes about d  updated with (trainTicket(d)  ticket(d))  trainTicket(d)  ticketFor (d, c).
It remains to examine (  )C and (  )C+E . We need to prove that:
(C) (  )C  IC [C]   C , and
(D) (  )C+E  IC [C + E]  effa .
Essentially, this means to prove that: (C) updating a formula with something it already implies does
not incur any changes; (D) updating 1 with some formula yields a belief equivalent to that formula.
To see this, compare (A) with (C) and (B) with (D).
74

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

While these two statements may sound quite trivial, it is in fact far from trivial to prove them for
the wide variety of, partly rather complex, belief update operations in the literature. Here we build
on the works by Katzuno and Mendelzon (1991) and Herzig and Rifi (1999). We need two of the
postulates made by Katzuno and Mendelzon (1991), namely:
(U1) For any 1 and 2 : (1  2 )  2 .
(U2) For any 1 and 2 : if 1  2 then (1  2 )  1 .
Herzig and Rifi (1999) prove that (U1) is uncontroversial, meaning it is satisfied by all belief
update operators they investigated (cf. above). They also prove that (U2) is equivalent to the conjunction of two weaker statements, of which only one is uncontroversial, namely:
(U2a) For any 1 and 2 : (1  2 )  (1  2 ).
The other statement is not uncontroversial. However, it is proved to be satisfied by all non-causal
update operators under investigation, except the so-called Winsletts standard semantics (Winslett,
1990). The latter semantics is not useful in our context anyway. The only restriction it makes on
the states in res(s, a) is that they differ from s only on the propositions mentioned in the update
formula. In our case, these include all propositions appearing in IC [C  E], which is bound to be
quite a lot. So, if we were to use Winsletts standard semantics, then res(s, a) would be likely to
retain hardly any information from s.
Consider now the formula (  )C as specified in (A), (  )C = (IC [C]   C )  IC [C].
We will now prove (C). This is indeed quite simple. We have that (IC [C]   C )  IC [C],
so we can instantiate 1 in (U2) with IC [C]   C , and 2 in (U2) with IC [C]. We obtain
(IC [C]   C )  IC  IC [C]   C , and hence (  )C  IC [C]   C as desired. With
what was said above, this result is not uncontroversial, but holds for all non-causal update operators
(except Winsletts standard semantics) investigated by Herzig and Rifi (1999). In terms of the VTA
example, (U2) allowed us to conclude that the update trainTicket(c)  ticket(c) does not make
any change to the previous belief, which already contains that property.
Next, consider the formula ()C+E as specified in (B), ()C+E = 1(IC [C +E]effa ).
We now prove (D). By postulate (U1), we get that (  )C+E  IC [C + E]  effa , because
IC [C +E]effa is the update formula 2 . For the other direction, we exploit (U2a). We instantiate
1 in (U2a) with 1, and get that 1  (IC [C + E]  effa )  1  (IC [C + E]  effa ), which is the
same as 1  (IC [C + E]  effa )  (  )C+E , which is equivalent to IC [C + E]  effa 
(  )C+E . This proves the claim. Note that we have used only postulates that are uncontroversial
according to Herzig and Rifi (1999). Reconsidering the VTA example, we have IC [C +E]effa =
(trainTicket(d)  ticket(d))  trainTicket(d)  ticketFor (d, c). The previous state does not say
anything about these propositions, and is thus represented as 1. The postulates allow us to conclude
that (for all belief update operators investigated by Herzig & Rifi, 1999) the resulting belief will be
equivalent to (trainTicket(d)  ticket(d))  trainTicket(d)  ticketFor (d, c).
So far, we were restricted to the case where , the belief to be updated, corresponds to a single
world state s. Consider now the more general case where  characterizes a belief b, and we want
to characterize the set of states res(b, a). At first glance, it seems that not much changes, because
Katzuno and Mendelzon (1991) also make this following postulate:
(U8) For any 1 , 2 , and : (1  2 )    (1  )  (2  ).

75

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

This means that, if  consists of two alternate parts, then updating  is the same as taking the union
of the updated parts. In other words, we can compute the update on a state-by-state basis. The
statement (I) from above is still true, its just that now  C is the disjunction over s for all states
s  b, rather than only the single s . The rest of the argumentation stays exactly the same. Herzig
and Rifi (1999) prove that (U8) is uncontroversial and leave it at that.
However, matters are not that simple. The source of complications is our use of a partial
matches/conditional effects semantics. The update formula  is different for the individual states
s  b. Hence we cannot directly apply (U8). Obviously, states s1  b where a is applicable are updated differently from states s2  b where a is not applicable  the latter are not updated at all.16 A
somewhat more subtle distinction between states in b is which constants exist in them: for different
sets of constants, the integrity constraints in the update are different. Hence, to obtain a generic
update of , we have to split  into equivalence classes 1 , . . . , n where the states within each
i cannot be distinguished based on prea and based on the existing constants. Then, (U8) and the
argumentation from above can be used to show the equivalent of (III) for each i . The last step,
defining the final    to be the disjunction of the individual i  i , appears sensible. But it does
not follow immediately from Katzuno and Mendelzon (1991).
For illustration, consider a variant of the VTA example where we have two preceding states, one
state s where we have train(c) as before, and a new state s where we have ticket(c) instead. In s ,
bookTicket(c, d) is not applicable, and hence the update is different for s and s . The s part is as
above, yielding the result s  (trainTicket(d)  ticket(d))  trainTicket(d)  ticketFor (d, c).
The update to s is trivial, and yields s as its result. The final outcome is the disjunction of these
two beliefs.
We point out that the situation is much easier if we consider plug-in matches (i.e., forced preconditions) instead of partial matches. There, a is applicable to all states, and it is also easy to
see that every state in b has the same constants. Therefore, for plug-in matches, (III) follows immediately with (U8). In the above VTA example, an update would not be computed at all since
bookTicket(c, d) would not be considered to be applicable to the preceding belief. If s satisfies
train(c) but disagrees in some other aspect, e.g. (quite nonsensically) that also ticket(c) holds, then
the updated belief is equivalent to (s  s )  (trainTicket(d)  ticket(d))  trainTicket(d) 
ticketFor (d, c).
4.4 Computational Properties
Paralleling our analysis for general WSC from Section 3.3, we now perform a brief complexity
analysis of the WSC|f wd special case. As before, we consider the propositional case which
assumes a fixed upper bound on the arity of predicates, on the number of input/output parameters
of each operator, on the number of variables appearing in the goal, and on the number of variables
in any clause. Also as before, we consider the decision problems of checking plans, of deciding
polynomially bounded plan existence, and of deciding unbounded plan existence, in that order.
In contrast to before, we cannot reuse results from the literature as much because, of course, the
particular circumstances of WSC|f wd have not been investigated before. We include proof sketches
here, and refer to Appendix A for the detailed proofs.
16. One might speculate that the common update would be prea  , but that is not the case. For example, under the
possible models approach that we adopt in WSC, updating s where s |= prea with prea   gives rise to result
states that change s to violate prea instead of changing it to satisfy .

76

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

Thanks to the simpler semantics as per Lemma 1, plan checking is much easier in WSC|f wd
than in WSC.
Theorem 4 (Plan Checking in WSC|f wd ) Assume a WSC|f wd task with fixed arity, and a sequence ha1 , . . . , an i of actions. It is coNP-complete to decide whether ha1 , . . . , an i is a plan.
Proof Sketch: Hardness is obvious, considering an empty sequence. Membership can be shown
by a guess-and-check argument. Say C is the union of C0 and all output constants appearing in
ha1 , . . . , an i. We guess an interpretation I of all propositions over P and C. Further, for each
1  t  n, we guess a set Ct of constants. I needs not be time-stamped because, once an action has
generated its outputs, the properties of the respective propositions remain fixed forever. Thanks to
Lemma 1, we can check in polynomial time whether (a) I and the Ct correspond to an execution of
ha1 , . . . , an i. Also, we can check in polynomial time whether (b) I and Cn satisfy G . ha1 , . . . , an i
is a plan iff there is no guess where the answer to (a) is yes and the answer to (b) is no.
2
Membership in Theorem 4 remains valid when allowing parallel actions and multiple conditional effects  provided one imposes restrictions ensuring that the effects/actions applied simultaneously (in one step) can never be self-contradictory. Otherwise, checking plans also involves a
consistency test for each plan step, which is an NP-complete problem. Note that it is quite reasonable to demand that simultaneous actions/effects do not contradict each other. Widely used
restrictions imposed to ensure this are mutually exclusive effect conditions, and/or non-conflicting
sets of effect literals.
We next consider polynomially bounded plan existence. Membership follows directly from Theorem 4. To prove hardness, we reduce from validity checking of a QBF formula X.Y.[X, Y ].
The constructed planning task allows to choose values for X, and thereafter to apply actions evaluating  for arbitrary values of Y . The goal is accomplished iff a setting for X exists that works for
all Y .
Theorem 5 (Polynomially Bounded Plan Existence in WSC|f wd ) Assume a WSC|f wd task with
fixed arity, and a natural number b in unary representation. It is p2 -complete to decide whether
there exists a plan of length at most b.
Proof Sketch: For membership, guess a sequence of at most b actions. By Theorem 4, we can
check with an NP oracle whether the sequence is a plan.
Hardness can be proved by reduction from
Wk validity checking of a QBF formula X.Y.[X, Y ]
where  is in DNF normal form, i.e.,  = j=1 j . The key idea is to use outputs for the creation
of time steps, and hence ensure that the operators adhere to the restrictions of WSC|f wd . Setting
xi is allowed only at time step i. That is, for each xi we have operators oxi 1 and oxi 0 . These take
as input a set of time steps {t0 , . . . , ti1 } which are required to be successive, by the precondition
start(t0 ) next(t0 , t1 )      next(ti2 , ti1 ). They output a new time step ti which they attach
as a successor of ti1 , and they set xi to 1 and 0, respectively, at time step i. That is, they have an
effect literal of the form xi (ti ) and xi (ti ), respectively. The rest of the planning task consists of:
operators ot that allow extending a sequence of time steps until step B, for a suitable value B (see
below); and of operators oj which allow achieving the goal, given j is true at the end of a time
step sequence of length B. There are no integrity constraints (IC is empty). The values of the yi
are not specified, i.e., those variables can take on any value in the initial belief.

77

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

If X.Y.[X, Y ] is valid then obviously one can construct a plan for the task simply by setting
the xi accordingly, using the ot for stepping on to time B, and applying all the oj . What necessitates
our complicated construction is the other direction of the proof: namely, the plan may cheat by
setting a xi to both 1 and 0. The construction ensures that this is costly, because such a plan is
forced to maintain two parallel sequences of time steps, starting from the faulty xi . We can choose a
sufficiently large value for B, together with a sufficiently small plan length bound b, so that cheating
is not possible.
2
Our final result regards unbounded plan existence. Somewhat surprisingly, it turns out that this
is still undecidable in WSC|f wd . Similar to the above, the key idea again is to let actions output a
new time step, thereby ensuring membership of the constructed task in WSC|f wd .
Theorem 6 (Unbounded Plan Existence in WSC|f wd ) Assume a WSC|f wd task. The decision
problem asking whether a plan exists is undecidable.
Proof Sketch: By reduction from the halting problem for Abacus machines, which is undecidable.
An Abacus machine consists of a tuple of integer variables v1 , . . . , vk (ranging over all positive
integers including 0), and a tuple of instructions I1 , . . . , In . A state is given by the content of
v1 , . . . , vk plus the index pc of the active instruction. The machine stops iff it reaches a state where
pc = n. All vi are initially 0, and pc is initially 0. The instructions either increment a variable
and jump to another instruction, or they decrement a variable and jump to different instructions
depending on whether or not the variable was already 0.
It is not difficult to encode an Abacus machine as a WSC|f wd task. The two key ideas are: (1)
design an operator that outputs the next successor to an integer; (2) design operators simulating
the instructions, by stepping to successors or predecessors of integer values. In the latter kind of
operators, membership in WSC|f wd is ensured by letting the operators output a new time step to
which the new variable values are associated. The goal asks for the existence of a time step where
the active instruction is In .
2
As argued at the end of Section 3.3 already, we dont deem undecidability of unbounded plan
existence a critical issue in practice. Most planning tools are by nature semi-decision procedures,
anyway. In particular, web service composition is typically expected to occur in a real-time setting,
where severe time-outs apply.
4.5 Issues in Adapting CFF
In our view, the most crucial observation about WSC|f wd is that we can now test plans in coNP,
rather than in p2 as for general WSC. Standard notions of planning under uncertainty have the same
complexity of plan testing, and research has already resulted in a sizable number of approaches and
(comparatively) scalable tools (Cimatti et al., 2004; Bryce et al., 2006; Hoffmann & Brafman,
2006; Palacios & Geffner, 2007). We will show in the next section that, under certain additional
restrictions on WSC|f wd , these tools can be applied off-the-shelf. Regarding general WSC|f wd , the
match in the complexity of plan testing suggests that the underlying techniques can be successfully
adapted. In the following, we consider in some detail the CFF tool (Hoffmann & Brafman, 2006).
Other promising options would be to extend MBP (Cimatti et al., 2004) or POND (Bryce et al.,
2006), or to look into the compilation techniques investigated by Palacios and Geffner (2007).
CFF can be characterized as follows:
78

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

(1) Search is performed forward in the space of action sequences.
(2) For each sequence a, a CNF formula (a) is generated that encodes the semantics of a, and
SAT reasoning over (a) checks whether a is a plan.
(3) Some reasoning results  namely the literals that are always true after executing a  are cached
to speed up future tests.
(4) Search is guided by an adaptation of FFs (Hoffmann & Nebel, 2001) relaxed plan heuristic.
(5) Relaxed planning makes use of a strengthened variant of the CNF formulas (a) used for
reasoning about action sequences, where most of the clauses are projected onto only 2 of
their literals (i.e., all but 2 of the literals are removed from each respective clause).
All of these techniques should be self-explanatory, except possibly the last one. Projecting the CNF
formulas ensures that the relaxed planning remains an over-approximation of the real planning,
because the projected formulas allow us to draw more conclusions. At the same time, the projected
formulas can be handled sufficiently runtime-efficiently.17 The method for 2-projecting most of
the clauses is, in a nutshell, to ignore all but one of the condition literals of each conditional effect
in the relaxed planning graph.
It is fairly obvious that the basic answers given by CFF, i.e., the techniques (1)  (5), also apply
in WSC|f wd . Note that, indeed, the main enabling factor here is that we can check plans in coNP,
rather than in p2 as for general WSC. This enables us to design the desired CNF formulas (a)
in a straightforward fashion. If plan checking is p2 -hard, then we either need to replace the CNF
formulas with QBF formulas, or we have to create worst-case exponentially large CNF formulas.
Both are, at the least, technically quite challenging.
The adaptation of CFF to WSC|f wd is of more immediate promise, but is not trivial. It involves
technical challenges regarding the on-the-fly creation of constants as well as the computation of
the heuristic function. The latter also brings significant new opportunities in the WSC context,
pertaining to the exploitation of typical forms of ontology axioms. Let us consider these issues in a
little detail.
First, like most of todays planning tools, CFF pre-instantiates PDDL into a purely propositional
representation, based on which the core planning algorithms are implemented. If one allows on-thefly creation of constants, then pre-instantiation is no longer possible, and hence the adaptation to
WSC|f wd involves re-implementing the entire tool. While this is a challenge in itself, there are
more difficult obstacles to overcome. A sloppy formulation of the key question is: How many
constants should we create? One can, of course, create a new tuple of constants for (the outputs of)
each and every new action application. However, it seems likely that such an approach would blow
up the representation size very quickly, and would hence be infeasible. So one should instead share
output constants where reasonable. But how does one recognize the reasonable points? This issue
is especially urgent inside the heuristic function. Namely, it is easy to see that, in the worst case,
the relaxed planning graph grows exponentially in the number of layers. Just imagine an example
where web service w1 takes an input of type A and generates an output of type B, whereas w2 takes
an input of type B and generates an output of type A. Starting with one constant of type A and
one of type B, we get 2 constants of each type in the next graph layer. Then, each of w1 and w2
17. Inside the heuristic function, the formulas come from relaxed planning graphs which can be quite big. So handling
them without further approximations seems hopeless. This is discussed in detail by Hoffmann and Brafman (2006).

79

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

can be applied two times, and we get 4 constants of each type in the next graph layer, and so forth.
This dilemma probably cannot be handled without making further approximations in the relaxed
planning graph.
One a more positive note, it seems possible to exploit the most typical structures of ontologies
in practice. In particular, most practical ontologies make extensive use of subsumption relations,
structuring the domain of interest into a concept hierarchy. Additional ontology axioms often come
in the form of constraints on relations (reflexivity, symmetry, transitivity) or on the typing or number
of relation arguments. It may make sense to exploit some of these structures for optimizing the
formulas (a) and the associated SAT reasoning. Certainly, it makes sense to exploit these structures
inside the heuristic function. One can include specialized analysis and sub-solver techniques that
recognize these structures and solve them separately in order to obtain more precise relaxed plans.
One can even try to take into account only these structures inside the relaxed planning, and hence
(potentially) obtain a very fast heuristic function.

5. Compilation to Initial State Uncertainty
We now show that, under certain additional restrictions, off-the-shelf scalable tools for planning
under uncertainty can be exploited to solve WSC|f wd . The main limiting factors are: (1) These
tools do not allow the generation of new constants. (2) These tools allow the specification of a
clausal formula only for the initial state, not for all states. Our approach to deal with (1) considers
a set of constants fixed a priori, namely the initially available constants plus additional potential
constants that can be used to instantiate outputs. Our more subtle observation is that, within a special
case of WSC|f wd , where the dynamics of states become predictable a priori, one can also deal with
(2) in a natural way.
In what follows, we first introduce our core observation of a case where the state space becomes
predictable, in a certain sense. We then observe that predictability is naturally given in a special
case of forward effects, which we term strictly forward effects. We discuss the strengths and limitations of this new special case. We finally provide a compilation of strictly forward effects into
planning under initial state uncertainty.
5.1 Predictable State Spaces
Our core observation is based on a notion of compatible actions. Assume a WSC|f wd task (P, IC ,
O, C0 , 0 , G ). Two actions a, a are compatible if either Ea  Ea = , or effa = effa . That is,
a and a either have disjunct outputs  and hence affect disjunct sets of literals since we are in
WSC|f wd  or their effects agree completely. A set A of actions is compatible if Ea  C0 =  for
all a  A, and every pair of actions in A is compatible.
Lemma 2 states that, given the used actions are compatible, every state that can ever be reached
satisfies all action effects, modulo the existing constants.
Lemma 2 (Predictable State Spaces in WSC|f wd ) Assume a WSC|f wd task, a compatible set of
actions A, and a state s that can be reached with actions from A. Then s |= 0 and, for all a  A,
if Ea  Cs then s |= effa .
Proof: The proof is by induction. In the base case, for s  b0 , the claim holds by definition since
Cs  Ea =  for all a  A. Say s is reached from s by an action a  A. If a is not applicable

80

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

to s, with induction assumption there is nothing to prove. Otherwise, because we are in WSC|f wd ,
by Lemma 1 we have that res(s, a) = {(C  , I  ) | C  = Cs  Ea , I  |Cs = Is , s |= IC  effa }.
With V
induction assumption applied to s, we have res(s, a) = {(C  , I  ) | C  = Cs  Ea , s |=
0  a A,E  Cs effa  IC  effa }. Now, if any a  A has Ea  Cs  Ea but Ea 6 Cs , then
a
2
we have Ea  Ea 6=  and hence effa = effa by prerequisite. This concludes the argument.
By virtue of this lemma, the possible configurations of all constants
that can be generated by
V
actions from A are characterized by the formula IC  0  aA effa . Since all parts of this
formula are known prior to planning, the set of possible configurations is predictable. Before
we even begin to plan, we already know how the constants will behave if they are generated. So
we can list the possible behaviors of all potential constants in our initial belief, and let the actions
affect only those constants which actually exist. In other words, we can compile into initial state
uncertainty. We will detail this further below. First, we need to identify a setting in which Lemma 2
can actually be applied.
5.2 Strictly Forward Effects
Given a WSC|f wd task, we must settle for a finite set A of compatible actions that the planner
should try to compose the plan from. One option is to simply require every action to have its own
unique output constants. This appears undesirable since planning tasks often contain many actions,
and so the set of potential constants would be huge. Further, to enable chaining over several actions,
the potential constants should be allowed to instantiate the input parameters of every operator, hence
necessitating the creation of a new action and, with that, more new potential constants. It is unclear
where to break this recursion, in a sensible way.
Herein, we focus instead on a restriction of WSC|f wd where it suffices to assign unique output
constants to individual operators, rather than to individual actions.
Definition 2 Assume a WSC task (P, IC , O, C0 , 0 , G ). The task has strictly forward effects
iff:
1. For all o  O, and for all l[X]  effo , we have |X| > 0 and X  Yo .
2. For all clauses   IC , where  = x1 , . . . , xk : l1 [X1 ]      ln [Xn ], we have X1 =
   = Xn .
The set of all WSC tasks with strictly forward effects is denoted with WSC|sf wd .
The second condition is identical to the corresponding condition for WSC|f wd . The first condition is strictly stronger. While WSC|f wd requires that at least one effect literal variable is taken
from the outputs, WSC|sf wd requires that all these variables are taken from the outputs. Therefore,
obviously, WSC|sf wd  WSC|f wd . Note that the WSC task formulated in Example 2 is a member
of WSC|sf wd .
The key property of WSC|sf wd is that, without input variables in the effect, all actions based
on the operator will have the same effect. So, for the action set to be compatible, all we need is to
choose a set of unique output constants for every operator. Indeed, we can do so for every set of
operators whose effects are pairwise identical. We can also choose several sets of output constants
for each such group of operators.
81

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

5.3 Modeling Power
The limitations of WSC|f wd , discussed in Section 4.2, are naturally inherited by WSC|sf wd . Moreover, unlike WSC|f wd , we cannot state any properties in the effect that connect the inputs to the
outputs. This is a serious limitation. For illustration, consider the small VTA example we have
been using. The operator bookTicket has an effect ticketFor (y, x), relating the produced ticket y
to the train x given as input. Clearly, the notion of a ticket is rather weak if we cannot state
what the ticket is actually valid for. Another interesting case is the one where we extend Example 2 by considering two proteins rather than just one. That is, we set C0 = {c, c }, 0 =
cellProtein(c)  cellProtein(c ). We wish to encode that we need the combined presentation for both
of those, i.e., G = y : combinedPresentation(y, c)  combinedPresentation(y, c ). In WSC|f wd ,
we can solve this by including, for every information providing operator, the input variable x into
the effect literal. For example, we set getInfo3D1n55 := ({x}, 1n55(x), {y}, Info3D(y, x)). This is
not possible in WSC|sf wd .
To some extent, these difficulties can be overcome by encoding the relevant inputs into predicate names. To handle composition for the two proteins c and c , this would essentially mean
making a copy of the entire model and renaming the part for c . The goal would be G = y, y  :
combinedPresentation(y)  combinedPresentation (y  ), and the operator preconditions would make
sure that combinedPresentation(y) is generated as before, while combinedPresentation (y  ) is generated using the new operators. Note that this a rather dirty hack, and that it depends on knowing the
number of copies needed, prior to planning. The equivalent solution for the VTA would introduce
a separate ticketFor-x predicate for every entity x for which a ticket may be bought. At the very
least, this would result in a rather oversized and unreadable model. A yet more troublesome case is
the time-step construction outlined in Section 4.2, where we added a new output variable t into each
effect and related that via an effect literal next(prevt, t) to a previous time step prevt provided as
input. In WSC|sf wd , we can no longer relate t to prevt so there is no way of stating which time
step happens after which other one. Trying to encode this information into predicate names, we
would have to include one predicate per possible time step. This necessitates assuming a bound on
the number of time steps, a clear limitation with respect to the more natural encoding.
Despite the above, WSC|sf wd is far from a pathological and irrelevant special case. An example
where it applies is the domain of proteins as shown in Example 1. Similarly, the hospital domain
discussed in Section 4.2 can be naturally modeled in WSC|sf wd . More generally, there is in fact a
wealth of WSC formalisms which do not encode any connections between inputs and outputs. For
example, that category contains all formalisms which rely exclusively on specifying the types of
input and output parameters. The information modeled with such types is only what kind of input
a service requires, and what kind of output it produces  for example, input is a train and output
is a ticket. Examples of such formalisms are various notions of message-based composition (Zhan
et al., 2003; Constantinescu et al., 2004a; Lecue & Leger, 2006; Lecue & Delteil, 2007; Kona
et al., 2007; Liu et al., 2007). In fact, the early versions of OWL-S regarded inputs and outputs as
independent semantic entities, using a Description Logic formalization of their types.
Thus, the existence of a compilation from WSC|sf wd into planning under uncertainty is quite
interesting. It shows how a composition model similar to the early versions of OWL-S, in a general
form with partial matches and powerful background ontologies, can be attacked by off-the-shelf
planning techniques. This opens up a new connection between WSC and planning.

82

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

5.4 Compilation
We compile a WSC|sf wd task into a task of conformant planning under initial state uncertainty,
which takes the form (P, A, 0 , G ). P is the finite set of propositions used. A is a finite set of
actions, where each a  A takes the form (pre(a), eff(a)) of a pair of sets of literals over P. 0 is
a CNF formula over P, G is a conjunction of literals over P. These notions are given a standard
belief state semantics. A state is a truth value assignment to P. The initial belief is the set of states
satisfying 0 . The result of executing an action a in a state s is res(s, a) := s if s 6|= pre(a),18 and
otherwise res(s, a) := (sadd(a))\del(a). Here we use the standard notation that gives s in terms
of the set of propositions that it makes true, uses add(a) to denote the positive literals in eff(a), and
del(a) to denote the negative literals in eff(a). Extension of res to beliefs and the definition of a
plan remain unchanged.
Assume a WSC|sf wd task (P, IC , O, C0 , 0 , G ). The compiled task (P  , A, 0 , G ) makes
use of a new unary predicate Ex that expresses which constants have yet been brought into existence. The compilation is obtained as follows. For each operator o  O, with outputs
Yo =
S
{y1 , . . . , yk }, we create a set of new constants Eo = {e1 , . . . , ek }. Then, C := C0  oO Eo will
be the set of constants fixed a priori. Initialize A := . For each operator o  O,
V include into A
the
preo  ( xXo Ex(x)) 
V
V set of actions resulting from using C to instantiate the precondition
( eEo Ex(e)). Give each of these actions the same effect, eEo Ex(e). In words, we instantiate os outputs with Eo , we enrich os precondition by saying that all inputs exist and that all
outputs do not yet exist, and we replace os effect with a statement simply bringing the outputs into
existence.
Replacing the effects in this way, where do the original effects go? They are included into the
initial state formula. That is, we initialize 0 as the conjunction of effo [Eo /Yo ] for all operators
o  O. Then, we instantiate all clauses inVIC with C andV
conjoin this with 0 . We obtain our final
0 by further conjoining this with 0  ( cC0 Ex(c))  cC\C0 Ex(c))  Goal. Here, Goal
is a new proposition. It serves to model the goal. Namely, we have to introduce a set of artificial
goal achievement actions. The goal has the form G = x1 , . .V
. , xk .[x1 , . . . , xk ]. The new actions
are obtained by instantiating the operator ({x1 , . . . , xk },   ki=1 Ex(xi ), , Goal) with C. That
is, the goal achievement actions instantiate the existentially quantified variables in the goal with all
possible constants. Those actions are added to the set A. The overall compiled task now takes the
form (P  , A, 0 , Goal), where P  is simply the set of mentioned propositions.
In summary, we compile a WSC|sf wd task (P, IC , O, C0 , 0 , G ) into a conformant planning
task (P  , A, 0 , G ) as follows:
 For each operator o  O, create a uniqueSset of new constants Eo = {e1 , . . . , ek } where
Yo = {y1 , . . . , yk }. We denote C := C0  oO Eo .

 P  contains all instantiations, with C, of P plus two new predicates, Ex and Goal. Ex has
arity 1 and expresses which constants have yet been brought into existence. Goal has arity 0
and forms the new goal, i.e., G = Goal.

 The actions A are the instantiations of all o  O, where XV
o is instantiated with
VC, and Yo is inEx(x))

(
stantiated with Eo . The preconditions
are
enriched
with
(
eEo Ex(e)),
xXo
V
the effects are replaced by eEo Ex(e).

18. As before, we give the actions a conditional effects semantics, rather than the more usual distinction between forced
preconditions, and non-forced effect conditions.

83

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

 Further, A contains goal achievement actions, achieving Goal under preconditions instantiating G with C.
 The original action effects, i.e., the conjunction of effo [Eo /Yo ] for all operators
o  O, is
V
 . Further,  contains  , 
moved
into

instantiated
with
C,
and
(
0
IC
0
0
cC0 Ex(c)) 
V
cC\C0 Ex(c))  Goal.

In the terminology of Section 5.1, this means that we choose the set A of actions as all actions
that can be obtained from an operator o  O by instantiating the inputs with constants from C,
and the outputs with Eo . As suggested by Lemma 2, the initial state formula 0 of the compiled
task describes the possible configurations of the constants C, and the only effect of applying an
action is to bring the respective output constants into existence. Note that, although the effects of
the compiled actions are all positive, planning is still hard (coNP-complete, to be precise) due to the
uncertainty. (If we allow WSC operators to also delete constants, then we have negative effects 
deleting constants  in the compiled task.)
According to the above strategy, we create only one set of output constants per operator, and
we do not take into account sets of operators that have identical effects. This is only to simplify
the presentation. Our results carry over immediately to more complicated strategies that create
more than one set of output constants per operator, as well as to strategies that share sets of output
constants between operators with identical effects. It should be noted, however, that operators
whose effects are not identical can not, in general, share their outputs. In particular, if the two
effects are in conflict, e.g., InfoDSSP(d) and InfoDSSP(d), then the initial state formula 0 as
above is unsatisfiable. The compiled planning task is then trivially solved by the empty plan, and,
of course, does not encode solutions in the original problem.
Example 3 Re-consider the planning task defined in Example 2. We specify a compiled task. We set
C = {c, d, e, f } where c is the only initially available constant, and d, e, f are potential constants
for operator outputs. The compiled planning task (P  , A, 0 , G ) is the following:
 P  = {protein, cellProtein, G, H, I, 1n55, 1kw3, combinedPresentation, InfoDSSP,
Info3D, Ex, Goal}, where all the predicates except Goal are unary (have one argument).
 A consists of all instantiations of:
 getInfoDSSPG [d/y]: ({x}, G(x)  Ex(x)  Ex(d), Ex(d))
 getInfoDSSPH [d/y]: ({x}, H(x)  Ex(x)  Ex(d), Ex(d))
 getInfoDSSPI [d/y]: ({x}, I(x)  Ex(x)  Ex(d), Ex(d))
 getInfo3D1n55 [e/y]: ({x}, 1n55(x)  Ex(x)  Ex(e), Ex(e))
 getInfo3D1kw3 [e/y]: ({x}, 1kw3(x)  Ex(x)  Ex(e), Ex(e))

 combineInfo[f /y]: ({x1 , x2 }, InfoDSSP(x1 )  Info3D(x2 )  Ex(x1 )  Ex(x2 ) 
Ex(f ), Ex(f ))
 GoalOp: ({x}, combinedPresentation(x)  Ex(x), Goal)
 0 is the conjunction of:
 all instantiations of IC  [consisting of the five axioms given in Example 2]
84

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

 cellProtein(c)  [0 ]
 InfoDSSP(d) Info3D(e) combinedPresentation(f )  [original action effects]
 Ex(c) Ex(d) Ex(e) Ex(f )  [constants existence]
 Goal  [goal not yet achieved]
 G = Goal
Now consider again the plan for the original task (see Example 2): hgetInfoDSSPG (c, d),
getInfoDSSPH (c, d), getInfo3D1n55 (c, e), getInfo3D1kw3 (c, e), combineInfo(d, e, f )i.
To illustrate, we now verify that this plan yields a plan for the compiled task. In that task,
the initial belief b0 consists of all states s where c is the only existing constant, d, e, f satisfy the
respective effects, and s |= IC  cellProtein(c). Now we apply the action sequence:
1. Apply getInfoDSSPG (c, d) to b0 . We get to the belief b1 which is the same as b0 except that,
in all s  b0 where s |= G(c), d now also exists.
2. Apply getInfoDSSPH (c, d) to b1 . We get to the belief b2 which is the same as b1 except that,
in all s  b1 where s |= H(c), d exists.
3. Apply getInfo3D1n55 (c, e) to b2 , yielding b3 .
4. Apply getInfo3D1kw3 (c, e) to b3 . This brings us to b4 where we have Ex(e) for all s  b2
with s |= 1n55(c) or s |= 1kw3(c).
5. Apply combineInfo(d, e, f ) to b4 . This brings us to b5 which is like b4 except that all s  b4
where both d and e exist now also have Ex(f ).
6. Apply GoalOp(f ) to b5 , yielding b6 .
The same reasoning over IC used in Example 2 to show that b5 satisfies the original goal, can
now be used to show that GoalOp(f ) is applicable in all s  b5 and hence the resulting belief b6
satisfies the goal. So we obtain a plan for the compiled task simply by attaching a goal achievement
action to the original plan.
To prove soundness and completeness of the compilation, we need to rule out inconsistent
operators, i.e., operators whose effects are in conflict with the background theory (meaning that
IC  Xo , Yo : effo is unsatisfiable). For example, this is the case if x : A(x)  B(x) is
contained in IC , and effo = A(y)  B(y). In the presence of such an operator, the initial belief
of the compiled task is empty, making the task meaningless. Note that inconsistent operators can
never be part of a plan, and hence can be filtered out as a pre-process. Note also that, in WSC|sf wd ,
an operator is inconsistent iff all actions based on it are inconsistent.
Non-goal achievement actions in A correspond to actions in the original task, in the obvious
way. With this connection, we can transform plans for the compiled task directly into plans for the
original task, and vice versa.
Theorem 7 (Soundness of Compilation) Consider the WSC|sf wd task (P, IC , O, C0 , 0 , G )
without inconsistent operators and a plan ha1 , . . . , an i for the compiled task (P  , A, 0 , G ).
Then the sub-sequence of non-goal achievement actions in ha1 , . . . , an i is a plan for the task
(P, IC , O, C0 , 0 , G ).
85

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

Proof Sketch: For an arbitrary sequence of non-goal achievement actions, denote by b the belief
after execution in the original task, and by b the belief after execution in the compiled task. For a
state sSin the original task, denote by [s] the class of all compiled-task states s overVthe constants
C0  oO Eo so that {c
S | s(Ex(c)) = 1} = Cs , s|Cs = Is , and s |= IC  0  oO effo [Eo ].
One can prove that b = sb [s]. The claim follows directly from that.
2

Theorem 8 (Completeness of Compilation) Consider the WSC|sf wd task (P, IC , O, C0 , 0 ,
G ) without inconsistent operators and a plan ha1 , . . . , an i where every operator o appears with at
most one instantiation Eo of the outputs. Then ha1 , . . . , an i can be extended with goal achievement
actions to form a plan for the compiled task (P  , A, 0 , G ) obtained using the outputs Eo .
S
Proof Sketch: Follows immediately from b = sb [s] as shown for the proof of Theorem 7. Say
one executes ha1 , . . . , an i in the compiled task, ending in a belief b. From there, a plan for the
compiled task can be obtained simply by attaching one goal achievement action for every tuple of
constants satisfying G in a world state from b.
2

The reader may have noticed that the number of instantiations of the goal achievement operator
is exponential in the arity of the goal. In the worst case, all these instantiations must be included
in the plan for the compiled task. In particular, this may happen in the plan constructed as per the
proof of Theorem 8. However, for practical purposes it appears reasonable to assume a fixed upper
bound on the number of goal variables.
As indicated, the proofs of Theorems 7 and 8 remain valid when allowing more than one Eo
per operator, and/or when operators with identical effects share output constants. Note that operators have identical effects if several web services provide alternative ways of achieving something.
Example 3 illustrates such a situation (cf. our earlier discussion in Section 3.2). In our experiments
as described in the next section, all groups of operators with identical effects are assigned the same
output constants.

6. Empirical Results
To show that the compilation approach has merits, we now report on a number of empirical experiments using CFF as the underlying planner. We start with a discussion of the general experimental
setup and then discuss the results for two different test scenarios.
6.1 Experiments Setup
We implemented the compilation from WSC|sf wd into planning under uncertainty as described
above, and connected it to the CFF tool. It should be noted here that, although the compiled planning
tasks do not have delete effects, they are not solved by CFFs relaxed-plan-based heuristic function.
That function makes a further relaxation ignoring all but one of the conditions of each effect (see
the earlier discussion of CFF in Section 4.5). Ignoring all but one condition significantly affects the
compiled tasks because their effects typically involve many conditions, particularly those conditions
stating that all inputs exist and all outputs do not yet exist.
One problematic point in evaluating planning-based WSC is the choice of test cases. The field
is still rather immature, and due to the widely disparate nature of existing WSC tools, there is

86

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

no common set of benchmarks.19 In fact, because web service composition is such a new topic
posing so many challenges to existing techniques, the different works differ widely in terms of both
their underlying purpose, and the specific aspect of WSC they address. A detailed discussion of
existing WSC tools is given below in Section 7. The method we choose for evaluation is to design
two test scenarios that reflect what are intuitively relevant kinds of problem structures in potential
applications of planning-based WSC, and that are scalable in a number of interesting parameters.
We test the reaction of our approach to these parameters.
While our test scenarios are artificial benchmarks, and cannot lead to broad conclusions of significance for practice, they do allow us to draw conclusions about planning behavior in differently
structured test problems. Our solution method scales quite well in most of the tested cases, efficiently finding solutions that involve many web service calls, and that successfully employ only
those services that are really necessary. Viewing these results in isolation, one can conclude that
representation techniques and heuristic functions from planning under uncertainty may be useful to
attack large and complex planning-like WSC instances.
A comparison to alternative WSC tools is, again, problematic, due to the broad range of problems the tools can solve, the different kinds of solutions they find, and the different kinds of input
syntax/language they read. To obtain at least some notion of empirical comparison to these tools,
in the following we consider only expressivity (How general is the input language of a tool?) and
scalability (How quickly can the tool compose?). Each of the existing WSC tools constitutes a
separate point in the trade-off between these two. The question then is whether our compilation
approach, restricting to WSC|sf wd and using CFF to solve the compiled tasks, is a sensible point in
that trade-off.
In terms of expressivity, our approach is located in between very general planning methods (like
Eiter et al., 2003, 2004; Giunchiglia et al., 2004), inspired by the actions and change literature, and
the more restricted methods that have been applied to WSC so far. The question is whether we gain
scalability in comparison to the more expressive methods.
We confirm in our experiments that the answer is, as expected, yes. We run the DLVK tool
(Eiter et al., 2003, 2004), which handles a powerful planning language based on logic programming.
That language in particular features static causal rules which are similar to the integrity constraints
in fully general WSC.20 In that sense, from our perspective DLVK is a native WSC tool that
handles ontology axioms directly rather than via restricting their expressivity and compiling them
away. In particular, we encoded our WSC test problems directly in DLVKs input language, without
the compilation that we use for CFF.
DLVK relies on answer set programming, instead of relaxed plan heuristics, to find plans. Further, in the style of many reasoning-based planners, DLVK requires as input a length bound on the
plan, and can hence be used to find optimal plans by running it several times with different bounds.
In all cases, we ran DLVK only once, with the bound corresponding to the optimal plan length.
Even so, DLVK is much slower than CFF, solving only a small fraction of our test instances. We do
not wish to over-interpret these results. All we conclude is that WSC|sf wd constitutes an interesting
point in the trade-off between expressivity and scalability in WSC.
19. While the VTA example could be considered one such benchmark, essentially every individual approach defines its
own particular version of that example.
20. The similarity lies in that both static causal rules and fully general integrity constraints can, as a side effect of applying
an action, yield ramifications affecting the properties inherited from the previous state.

87

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

When running some first tests with the compilation approach, we noticed that the encoding as
per Section 5.4 is unnecessarily generous about the set of initial states. Observe that our compiled
tasks are always easier to solve if more propositions are true in the initial state. This is, simply, because all literals in operator preconditions, effects, and the goal are positive. Hence, if a proposition
p does not appear positively in any initial state clause, then one can set p to 0 initially, and thereby
reduce the number of initial states, without introducing any new plans.21 Setting a proposition to
0 may cause unit propagations, setting other propositions to 1 or 0. We iterate these steps until a
fixpoint occurs. The resulting initial state description is stricter than before, and yields better performance both for CFF and for DLVK. We use this optimized encoding in all the experiments reported
below.
We also experimented with another optimization. That optimization makes the assumption that
the constants requested by the goal will be generated in a step-wise fashion, where each intermediate
constant is generated with certainty before generating the next constant. RecallVthat in the encoding
as per Section 5.4, the existence of the inputs of operators, i.e., the condition xXo exists(x), is
part of the operator precondition and is thus interpreted under a conditional effects semantics. However, both CFF and DLVK offer a distinction between effect conditions and forced preconditions
that must hold in the entire belief
for the action to be applicable. We can exploit that distinction to
V
postulate that the condition xXo exists(x) is forced. This reduces the state space, but may cut
out solutions. The reduction is quite beneficial both for CFF and for DLVK. Since the optimization
affects the set of plans, we switch it on only in part of the test cases, to point out the possible speedup. The tests where the optimization is switched on are discussed in the text, and indicated by the
keyword forced in the name of the test case.
We use two versions of CFF. One is CFFs default configuration which makes use of FFs enforced Hill-climbing search algorithm as well as its helpful actions pruning technique (Hoffmann
& Nebel, 2001). In the other configuration, CFF helpful actions pruning is turned off, and the search
proceeds in standard greedy best-first fashion, with an open queue ordered by increasing heuristic
values. We henceforth denote the former configuration with CFF-def and the latter configuration
with CFF-std.
All results were obtained on a 2.8GHz Pentium IV PC running Linux. All tests were run with a
time-out of 600 seconds CPU, and limiting memory usage to 1 GB.
6.2 Subsumption Hierarchies
We first investigate how well our approach can deal with scaling subsumption hierarchies, and with
building chains of successively created entities (outputs). For that purpose, we design a test scenario
called SH, which demands the composition of web services realizing a chain of generation steps,
where every generation step has to deal with a subsumption hierarchy.
The scenario is depicted in Figure 2. There are n top-level concepts T L1 , . . . , T Ln , depicted
with TL in Figure 2. The goal input is T L1 , the goal output is T Ln . Beneath each T Li , there
is a tree-shaped hierarchy of sub-concepts. More precisely, the tree is perfectly balanced with
branching factor b, and has depth d. The inner nodes of the tree are called intermediate-level
(or simply intermediate) concepts, depicted with IL in Figure 2. The leaf nodes of the tree
are called basic-level (or simply basic) concepts, depicted with BL in Figure 2. For every
non-leaf concept C in the tree, with children C1 , . . . , Cb , we have the axioms x : Ci (x)  C(x)
21. Of course, reducing the set of initial states does not invalidate any old plans, either.

88

fiTL

W EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

IL

IL

BL

BL

BL

BL

BL

BL

SWS

SWS

SWS

SWS

SWS

SWS

TL

IL

BL

IL

BL

BL

BL

BL

BL

Figure 2: Schematic illustration of the SH scenario.
expressing subsumption, as well as an axiom x : C(x)  C1 (x)      Cb (x) expressing that the
parent is covered by its children.
The available web services are defined as follows. For each top level concept T Li , and for
each leaf BLi,j of the corresponding tree structure, there is a web service available that takes
BLi,j as input and that outputs T Li+1 . The corresponding WSC operator takes the form oi,j =
({x}, BLi,j (x), {y}, T Li+1 (y)). Then, by applying, for each 1  i < n in order, all services oi,j ,
it is possible to make sure that a constant of concept T Li+1 is created in all possible cases. Hence,
sequencing all these steps is a plan, of length (n  1)  bd . Note here that, as we already stated
in Section 5.4, in our experiments groups of operators with identical effects are assigned the same
output constants. For the SH scenario, this means that for each 1  i < n, all the oi,j share the
same output constant. Hence the total number of output constants generated, i.e., the number of
potential constants in the initial state, is equal to the number of top-level concepts, n.
Although the SH scenario is of an abstract nature, it is representative for a variety of relevant
situations. Specifically, the scenario can model situations where sets of different services must be
used to address a request which none of them can handle alone. The role of each single service is
then to handle some particular possible case. In our example, the set of different services is the
set of services oi,j assembled for each T Li . Given a constant c which is a member of T Li , i.e.,
T Li (c) holds, the particular possible case handled by service oi,j is the case where c happens to
be a member of leaf BLi,j  one of those cases must hold due to the coverage clauses in the tree.
89

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

Similar situations arise, e.g., for geographically located (regional) services when the composition
request is not location-specific or addresses locations at a higher (inter-regional) level. A similar
pattern can also be found in e-government scenarios where a clear-cut classification of activities
leads to establishing several parallel services that serve different departmental areas.
Orthogonal to this horizontal composition, the scenario can model vertical composition,
where one function has to be pursued by concatenating existing functions. This is the case for most
complex procedures in such diverse areas as e-government or e-commerce.
The scenario can be instantiated to study different aspects of the scalability of our approach.
Our empirical tests measure scalability in both the horizontal and the vertical direction. Further,
we consider two extreme cases of the possible shapes of the individual concept trees in the chain,
giving us instances with identical numbers of leaves. We set up the test scenario SH-broad, where
d = 1 and b scales over 2, 4, 8, 16, 32. We set up the test scenario SH-deep, where b = 2 and d
scales over 1, 2, 3, 4, 5. In both scenarios, n scales from 2 to 20.
Further, we designed a SH-trap variant where a second chain of n concepts can be linked,
but is completely irrelevant for the goal service. This variant is suitable for testing to what extent
the composition techniques are affected by irrelevant information. Finally, recall that the encoding
method
comes in two versions as explained above, where the default method treats input existence
V
 xXo exists(x)  by a conditional effects semantics, whereas the non-default method, forced,
compromises completeness for efficiency by treating input existence as a forced precondition.
All in all, we have the following choices: 3 different planners (CFF-def, CFF-std, DLVK);
2 different encoding methods; SH with or without the trap; SH-broad or SH-deep. The crossproduct of these choices yields 24 experiments, within each of which there are 19 possible values
for n and 5 possible values for b or d, i.e., 95 test instances. For CFF, we measured 3 performance
parameters: total runtime, number of search states inserted into the open queue, and number of
actions in the plan. For DLVK, we measured total runtime and number of actions in the plan. Of
course, not all of this large amount of data is interesting. In what follows, we summarize the most
important observations. Figure 3 shows the data we selected for this purpose. Part (a) of the figure
shows CFF-std on SH-broad; (b) shows CFF-std on SH-deep; (c) shows CFF-def on SH-forcedbroad; (d) shows DLVK on SH-broad and SH-deep; (e) shows DLVK on SH-forced-broad and
SH-forced-deep; (f) shows DLVK and CFF-std on SH-trap. The vertical axes all show log-scaled
runtime (sec). The horizontal axes show n in (a), (b) and (c). In (d), (e) and (f), n is fixed to n = 2
and the horizontal axes show the number of leaves in the concept hierarchy.
Consider first Figure 3 (a) and (b). These plots point out how efficiently CFF can handle this
kind of WSC problem, even with no forced optimization. Comparing the two plots points out the
difference between handling broad and deep concept hierarchies. In both plots, CFF-std runtime
is shown over n, the length of the chain to be built. In (a), we show 5 curves for the 5 different
values of b (the number of leaves in a hierarchy of depth 1), and in (b) we show 5 curves for the 5
different values of d (the depth of a hierarchy with branching factor 2). In both cases, the scaling
behavior is fairly good. With small concept hierarchies (b = 2 or d = 1), chains of almost arbitrary
length can be built easily. As the hierarchies grow, runtime becomes exponentially worse. Note,
however, that from one curve to the next the size of the hierarchies doubles, so that growth is itself
exponential. With concept hierarchies of 16 leaves, i.e., 16 alternative cases to be handled in each
step, we can still easily build chains of 6 steps, where the solution involves 96 web services. The
most interesting aspect of comparing the two plots, (a) and (b), is that the underlying search spaces
are actually identical: the open queues are the same. The only difference in performance stems
90

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

100

100

10

10

1

1

b=2
b=4
b=8
b=16
b=32

0.1

0.01
2

4

6

8

10

12

14

d=1
d=2
d=3
d=4
d=5

0.1

0.01

16

18

20

2

4

6

(a) CFF-std on SH-broad

8

10

12

14

16

18

20

(b) CFF-std on SH-deep
10000
SH-broad
SH-deep
1000

100

100

10
10

1
1

0.1
0.1

0.01
2

4

6

8

10

12

14

16

18

20

0.01
2

3

(c) CFF-def on SH-forced-broad

4

5

6

(d) DLVK on SH-broad and SH-deep

10000

10000
SH-forced-broad
SH-forced-deep

DLVK SH-trap-broad
DLVK SH-forced-trap-broad
CFF-std SH-trap-broad

1000

1000

100

100

10

10

1

1

0.1

0.1

0.01

0.01
2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

2

(e) DLVK on SH-forced-broad and SH-forced-deep

4

6

8

10

12

14

16

18

20

22

24

26

30

(f) DLVK and CFF-std on SH-trap

Figure 3: Selected results for SH scenario. See detailed explanation in text.

91

28

32

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

from an overhead in CFFs reasoning techniques, which consume more runtime in the case of deep
concept hierarchies. Hence the slightly worse behavior in (b).
If we run CFF-def on the test suites of Figure 3 (a) and (b), then we obtain much worse behavior.
For example, with b = 8 we only get up to n = 3. The reason seems to be that FFs helpful actions
pruning and enforced hill-climbing are too greedy in this domain. A simple way to overcome this is
to use a standard heuristic search algorithm instead, as done by CFF-std shown in Figure 3 (a) and
(b). On the other hand, if the forced optimization is switched on, then helpful actions pruning and
enforced hill-climbing work much better, and we obtain a significant performance boost when using
CFF-def. The latter is pointed out by Figure 3 (c), showing data for CFF-def on SH-forced-broad.
Like Figure 3 (a) for CFF-std on SH-broad, this plot shows 5 curves, one for each of the 5 values
of b (legend omitted from the plot because it would overlap the curves). We see that, in this case,
we can easily build arbitrarily long chains even for b = 16, giving us a solution involving 320 web
services for n = 20. Even for b = 32, we still get up to n = 9.
Figure 3 (d) and (e) show what one gets when trying to solve the same examples, encoding them
directly for DLVK instead of using the compilation and solving them with CFF. As expected, the
performance is much worse. Since hardly any test instance is solved for n > 2, we fixed n to its
minimum value 2 in these plots, unlike (a), (b) and (c). Each of (d) and (e) shows data for both the
broad and deep variants, showing the number of leaves on the horizontal axis. In order to obtain a
more fine-grained view, for the broad variant we increase that number by steps of 1 rather than by
a multiplicative factor of 2 as before. We see that, without the forced optimization  Figure 3 (d) 
performance is poor, and the largest case we can solve is n = 2, b = 6 where the solution involves
6 web services. As we switch forced on  Figure 3 (e)  performance is dramatically improved but
is still on a different level than what we obtain by compilation+CFF.
Figure 3 (f), finally, exemplifies the results we get in the trap scenario. We show data for
the broad version, on the default encoding with CFF-std, and on both the default and the forced
encoding with DLVK. DLVK is quite affected by the irrelevant chain of concepts, now solving only
the single instance n = 2, b = 2 for the default encoding, and getting up to n = 2, b = 16 for
the forced encoding, instead of n = 2, b = 20 without the trap. This behavior is expected since
DLVK does not make use of heuristic techniques that would be able to detect the irrelevance of the
second chain of concepts. The question then is whether CFFs techniques are better at that. Figure 3
(f) shows that CFF-std is largely unaffected for n = 2  one can see this by comparing that curve
with the points on the vertical axis in Figure 3 (a). However, for n > 2 the performance of CFF-std
drastically degrades: the only instances solved are n = 3, b = 2 and n = 4, b = 2. The reason
seems to be that the additional actions yield a huge blow-up in the open queue used by the global
heuristic search algorithm in CFF-std. Indeed, the picture is very different when using CFF-def and
the forced encoding instead: the search spaces are then identical to those explored with no trap, and
the behavior we get is identical to that shown in Figure 3 (c).
All plans found in the SH scenario are optimal, i.e., the plans returned contain only those web
services that are needed. The single exception is DLVK in trap, where the solutions include some
useless web services from the trap chain.22
22. Note here that DLVKs plans are parallel. Their parallel length is optimal (because we provided the correct plan
length bound, cf. Section 6.1. However, each parallel step may contain unnecessary actions, on top of the necessary
ones. Thats what happens in trap.

92

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

6.3 Complex Concept Dependencies
The two variants of the SH scenario feature tightly structured relationships between the involved
concepts, and allow the investigation of scalability issues by varying the size of the structure. We
now consider a more advanced scenario, where the way top-level concepts are covered by lowerlevel concepts is subject to complex concept dependencies, similar to the axioms constraining protein classes and their characteristics in Example 1. Therefore we investigate how performance is
impacted by more complex concept structures than just subsumption hierarchies.
TL

TL

IL

IL

IL

IL

BL

BL

BL

BL

BL

BL

BL

BL

BL

BL

BL

BL

SWS

SWS

SWS

SWS

SWS

SWS

SWS

SWS

SWS

SWS

SWS

SWS

TL

TL

IL

BL

BL

IL

IL

BL

BL

BL

BL

BL

BL

IL

BL

BL

BL

BL

Figure 4: Schematic illustration of the CD scenario vs. the SH scenario.
Our new scenario is called CD, for concept dependencies. Figure 4 illustrates this scenario, and
contrasts it with the SH scenario. Similarly to what we had in SH, we have top-level concepts,
of which each one is associated to a set of basic sub-concepts. There are b basic concepts for
every top-level concept. There are n top-level concepts T L1 , . . . , T Ln , and the goal is to achieve
T Ln starting from T L1 . As before, this is done through combining web services that cover all
possibilities. Namely, for every top-level concept T Li and for every basic concept BLi,j associated
with it, we have the operator oi,j = (({x}, BLi,j (x), {y}, T Li+1 (y)).23
The difference lies in the connection between the basic concepts and the top-level concepts.
In SH, this was rigidly given in terms of a tree structure of subsumption and coverage axioms
over intermediate concepts. Every basic concept  i.e., every operator oi,j corresponding to such a
concept  had to be included in the plan in order to cover all possible cases. In CD, we use instead a
complex set of axioms to connect the basic concepts to the top-level. Each top-level concept has m
intermediate concepts ILi,1 , . . . , ILi,m , for which as before we have axioms stating that each ILi,j
23. Note here again that, for the same i, all these operators are assigned the same output constant by our compilation
technique.

93

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

is a sub-concept of T Li , as well as the axiom x : T Li (x)  ILi,1 (x)      ILi,m (x) stating
that T Li is covered by ILi,1 , . . . , ILi,m . For the connection between the intermediate concepts and
the basic concepts, complex dependencies are used. Each intermediate subconcept is constrained to
be covered by some non-empty set of combinations of the basic subconcepts. Precisely, we create a
random DNF, of only positive literals, using the basic concepts as the predicates. We then take that
DNF to imply ILi,j . Note here that, in the implication, the DNF is negated and hence becomes a
CNF, which we can directly encode into our formalism. We do this for every ILi,j .
In such a setting, it is interesting to control how many combinations are required to cover the
top-level concept T Li . This directly corresponds to the total number of random combinations (random DNF disjuncts) that are generated, for all of the intermediate concepts ILi,j taken together.
We control this via what we call the coverage factor, c, ranging in (0, 1]. From the 2b  1 possible
combinations of basic concepts, we pick a random subset of size c  (2b  1). Each such combination is associated to the DNF of a randomly chosen intermediate concept. Note that the CNF
formulas generated this way may be enormous. To minimize the size of the encoding, we use the
formula minimization software Espresso (Brayton, Hachtel, McMullen, & Sangiovanni-Vincentelli,
1984; McGeer, Sanghavi, Brayton, & Sangiovanni-Vincentelli, 1993).
If  hypothetically  c is set to 0 then the task is unsolvable. In the experiments reported below,
whenever we write c = 0% this means that exactly one combination was selected, and associated
with every intermediate concept.
By escaping from the rigid schema of relationships presented by SH, the CD scenario is suitable to test whether the performance of our approach is tied to the specific structure of the SH
problem. Moreover, the way CD is designed allows us to determine to what degree the planners
react intelligently to different concept structures. In particular, the scenario allows the analysis of:
1. The ability of our approach, and in particular of the selected underlying planner CFF, to identify plans that contain only relevant actions. Especially when the coverage factor c is low,
some basic subconcepts may never appear in any partition of intermediate concepts, and thus,
the plan does not need to include the respective operators. Still, due to the conditional effects/partial matches semantics, plans that include those operators are valid plans. Evaluating
plan length performance over varying c is therefore interesting.
2. The ability of our approach to deal with complex axiomatizations. This can be measured in
terms of the impact of the coverage factor on runtime performance. The randomization of
the choice of combinations of basic factors, in different settings of c, may induce significant
differences in the CNF axiomatizations, and as a result, subject the underlying reasoning
engine to very different situations.
In summary, the CD scenario is representative for situations where complex dependencies must be
taken into account in order to select the correct services. Examples of such domains were discussed
in Sections 4.2 and 5.3. In particular, the CD scenario corresponds closely to (a scalable version of)
our protein domain example. The different values for the DSSP code correspond to different basic
concepts, and the respective getInfoDSSP services are the operators taking them to an intermediate
concept, InfoDSSP(y). This is similar for amino-acids, 3-D shapes, and shapes in complexes. The
top level concept combinedPresentation(y) can be achieved once constants for every intermediate
concept have been created. So, the only difference to CD lies in that, rather than having just a single
top-level concept generated from its intermediates, CD has a sequence of top-level concepts that
need to be generated in turn.
94

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

As with the SH scenario, the total data of our experiments is extensive, even more so since we
now have 4 scenario parameters rather than 2 as before, and since individual instances now contain
a random element. In Figure 5, we report selected results pointing out the main observations. Part
(a)/(b) of the figure show CFF-std runtime/plan length over n for m = 4, b = 5; (c)/(d) show CFFstd runtime/search nodes over c for n = 5, m = 3, b = 7; (e) shows DLVK and CFF-std runtime
over b in CD for n = 2, c = 100%; (f) show the latter data for CFF-def and CD-forced.
Figure 5 (a) and (b) consider the scalability and solution lengths of the test varying the size of
the scenario, and representing different coverage factors as different lines. We report data for CFFstd. Results are very similar for CD-forced and CFF-def, i.e., contrary to SH, in CD this setting of
options does not bring a significant performance gain. We see in Figure 5 (a) that CFF scales up
pretty well, though not as well as in SH, being easily able to solve tasks with 7 top level concepts of
which each has 4 intermediate concepts and 5 basic concepts. Tasks with minimum coverage factor,
c = 0%, are solved particularly effortlessly. For higher c values, one can observe somewhat of an
easy-hard-easy pattern, where, for example, the curve for c = 100% lies significantly below the
curves for c = 40% and c = 60%. We examine this easy-hard-easy pattern in more detail below.
In Figure 5 (b), an obvious and expected observation is that plan length grows linearly with
n, i.e., with the number of top level concepts. A likewise obvious, but much more important,
observation is that plan length grows monotonically with the coverage factor c. As reported above,
a lower coverage factor opens up the opportunity to employ less basic services, namely only the
relevant ones. Figure 5 (b) clearly shows that CFF-std is effective at determining which of the
services are relevant and which are not.
Let us get back to the intriguing observation from Figure 5 (a), the easy-hard-easy pattern over
growing c. Figure 5 (c) and (d) examine this phenomenon in more detail. Both plots scale c on
the horizontal axis, for a fixed setting of n, m and b. Runtime is shown in (c), while (d) shows
the number of search states inserted into the open queue. For each value of c, the plots give the
average and standard deviation of the results for 30 randomized instances. We clearly see the easyhard-easy pattern in (c) for runtime, with high variance particularly for c = 80%. In (d), we
see that there is no such pattern for the number of search states, and that the variance is much less
pronounced. This shows that the easy-hard-easy pattern is not due to differences in the actual search
performed by CFF, but due to the effort spent in the search nodes. We traced the behavior of CFF
in detail, and found that the reason for the easy-hard-easy pattern lies in the runtime CFF spends
in its SAT reasoning for state transitions, i.e., in the reasoning it uses to determine which facts
are definitely true/false in each belief. For high but non-100 values of c, the CNF encodings of the
concept dependency structures take on a rather complex form. In the cases where CFF takes a lot
of runtime, almost all of the runtime is spent within a single call to the SAT solver. That is, it seems
that CFFs SAT solver exhibits a kind of heavy-tailed behavior on these formulas, a phenomenon
well known in the SAT and CP community, see for example the work of Gomes, Selman, Crato, and
Kautz (2000). It should be noted here that, in typical planning benchmarks, the CNFs have a much
simpler structure, which motivates the use of a fairly naive SAT solver in CFF, using neither clause
learning nor restarts, in order to save overhead on formulas that are simple anyway. It seems likely
that the addition of advanced SAT techniques to the solver could ameliorate the observed problem.
Finally, Figure 5 (e) and (f) compare the performances of compilation+CFF and DLVK (with
no compilation). Both plots fix n = 2, i.e., data is shown for only 2 top level concepts. The only
instances that DLVK solves for n > 2 are the ones where the forced optimization is used and n = 3,
m = 2, b = 2. Further, in both plots c is fixed to c = 100%. The reason for this is that we did
95

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

1000

35

c=0%
c=20%
c=40%
c=60%
c=80%
c=100%

100

c=0%
c=20%
c=40%
c=60%
c=80%
c=100%

30

25

10

20

15

1

10
0.1
5

0.01

0
2

3

4

5

6

7

2

3

(a) CFF-std runtime over n

4

5

6

7

(b) CFF-std plan length over n
250

100

200

10

150

1

100

0.1

50

0.01

0
0

20

40

60

80

100

0

(c) CFF-std runtime over c
10000

40

60

1000

DLVK m=2
DLVK m=4
DLVK m=6
CFF-std m=2
CFF-std m=4
CFF-std m=6

1000

20

80

100

(d) CFF-std plan length over c
DLVK m=2
DLVK m=4
DLVK m=6
CFF-def m=2
CFF-def m=4
CFF-def m=6

100

100
10
10
1
1

0.1
0.1

0.01

0.01
2

4

6

8

10

12

2

(e) DLVK and CFF-std runtime over b

4

6

8

10

12

(f) DLVK and CFF-def runtime over b

Figure 5: Selected results for CD scenario. See detailed explanation in text.
not find a significant difference in the performance of DLVK for different values of c. DLVK was
unable to exploit lower c for lower runtime, and neither did it show an easy-hard-easy pattern. We
speculate that DLVKs answer set programming solver tends to perform exhaustive search anyway
and is accordingly not as affected by different structures as the heuristic techniques employed by
CFF. However, like CFF, DLVK was able to exploit lower coverage factors c for shorter plans.
96

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

Figure 5 (e) shows the default setting without the forced optimization. We see that the performance of DLVK explodes quickly while CFF does not experience as much trouble. CFF fails at the
upper ends of its curves, both in Figure 5 (e) and (f), only because the problem files, i.e., the CNFs
describing the complex concept dependencies, become too large to parse (> 4 MB). That notwithstanding, CFFs runtime behavior is clearly exponential. Note, however, that the actual encodings,
i.e., the problem instances to be solved, also grow exponentially over c.
We can further observe that DLVK exhibits quite some variance, particularly across different
settings of m: the curves cross in Figure 5 (e). This is even more pronounced in Figure 5 (f), where
we can also observe, as before for SH, that the forced optimization brings a huge advantage for
DLVK. For m = 2 and m = 6 in Figure 5 (f), DLVK fails on the first unsolved problem instance
due to running out of memory shortly after parsing the problem.
Concluding this section, we observe that the empirical behavior of CFF in the SH and CD scenarios is promising. These results should not be over-interpreted, though. While the test scenarios
do capture problem structure typical of a variety of potential applications of WSC technology, our
approach has yet to be put to the test of actual practice. The same, however, can be said of essentially
all current planning-based WSC technology, since the field as a whole is still rather immature.

7. Related Work
The relation of our work to the belief update literature has been covered in detail already in Sections 2.2 and 4.3. As for the relation to planning, our formalism basically follows all the commonly
used frameworks. Our notions of operators, actions, and conditional effects are exactly as used in
the PDDL framework (McDermott et al., 1998; Bacchus, 2000; Fox & Long, 2003), except for the
extension with outputs. Regarding the latter, it has been recognized for some time in the planning
community, for example by Golden (2002, 2003) and Edelkamp (2003), that on-the-fly creation of
constants is a relevant feature for certain kinds of planning problems. However, attempts to actually
address this feature in planning tools are scarce. In fact the only attempt we are aware of is the work
by Golden (2002, 2003) and Golden, Pand, Nemani, and Votava (2003). Part of the reason for this
situation is probably that almost all current state of the art tools employ pre-processing procedures
that compile the PDDL task into a fully grounded description. The core algorithms are then implemented based on a propositional representation. Lifting such algorithms to a representation that
involves variables and on-the-fly instantiations requires a major (implementation) effort. In the work
herein, we circumvent that effort by using potential constants and feeding the resulting problem
to CFF, which like most planners employs the said pre-processing. Extending CFF for WSC|f wd
will involve dealing with non-propositional representations as a sub-problem.
Our notion of initial state uncertainty and conformant plans closely follows the related literature
from planning under uncertainty (Smith & Weld, 1998; Cimatti et al., 2004; Hoffmann & Brafman,
2006). The formalization in terms of beliefs is adapted from the work by Bonet and Geffner (2000).
There are some related works in planning which allow a domain axiomatization, i.e., some form of
axioms constraining the possible world states (Eiter et al., 2003; Giunchiglia et al., 2004). To the
best of our knowledge, no work in planning exists, apart from the work presented herein, which
considers the combination of domain axioms and outputs.
A few words are in order regarding our notions of partial and plug-in matches. This terminology originates from work on service discovery in the SWS community (see for example Paolucci
et al., 2002; Li & Horrocks, 2003; Kumar et al., 2007). In service discovery, one is concerned with

97

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

matching service advertisements against service requests. The discovery result is the set of services
whose advertisement matches the request. The descriptions of services and requests are similar to
the functional-level service descriptions, i.e., the planning operators that we use here. However, the
terminology in these works is slightly different from ours, and they also describe additional kinds
of matches. The notions given by Li and Horrocks (2003) have the closest relation to ours. Service
descriptions are defined in terms of constructed Description Logic concepts. Say A is the concept
describing the advertisement, and R is the concept describing the request. Then Li and Horrocks
say that A and R have: an exact match if A  R; a plug-in match if A  R; a subsume match
if A  R; and an intersection match if A  R 6 . To compare this to our setting, consider the
situation where A is the effect of action a, and R is the precondition of action r. Exact matches
are a special case of plug-in matches which we do not distinguish herein. Intersection matches
correspond to what we call partial matches. Concerning plug-in and subsume matches, matters are
more subtle. The intuitive meaning of plug-in match is that the advertisement fully suffices to
fulfill the request. In planning terms, this means that the effect of a implies the precondition of r.
However, in service discovery this is traditionally taken to mean that every requested entity is being
provided, i.e., A  R. The latter notion  where the precondition of r implies the effect of a  is
not meaningful in planning. Hence we use only one of the two notions, in correspondence to Li and
Horrockss subsume matches.
In contrast to the work of Li and Horrocks (2003), and to our work, Paolucci et al. (2002) and
Kumar et al. (2007) define matches for individual input/output parameters in service descriptions,
rather than for service descriptions on a more global level (precondition/effect for us, constructed
concept for Li & Horrocks, 2003). On the level of individual parameters, Paolucci et al. (2002)
suggest the same notions as Li and Horrocks (2003) except that they do it in a less formal notation,
and they do not define intersection matches. The same is true of Kumar et al. (2007). The latter
authors also define notions of contains and part-of matches, relating to the building blocks of
constructed concepts. Obviously, such notions do not make sense in our framework, where there
arent any constructed concepts. Finally, Kumar et al. define some ways of aggregating matches for
individual parameters to matches for entire service descriptions. Again, this is not applicable in our
case since we work on a more global level in the first place.
A brief survey of the existing works on WSC is as follows. There is a variety of works that compile composition into more or less standard deterministic planning formalisms (Ponnekanti & Fox,
2002; Srivastava, 2002; Sheshagiri et al., 2003). Some other works (Agarwal, Dasgupta, Karnik,
Kumar, Kundu, Mittal, & Srivastava, 2005b; Agarwal et al., 2005a) additionally focus on end-to-end
integration of SWS composition in the larger context. Akkiraju, Srivastava, Anca-Andreea, Goodwin, and Syeda-Mahmood (2006) investigate techniques to disambiguate concept names. McIlraith
and Fadel (2002) achieve composition with particular forms of non-atomic services, by modeling the
latter as atomic actions that take the meaning of a kind of macro-actions. Narayanan and McIlraith
(2002) obtain a composition ability as a side-effect of verifying SWS properties using Petri Nets.
Kuter, Sirin, Nau, Parsia, and Hendler (2005), Au, Kuter, and Nau (2005), and Au and Nau (2006)
focus on information gathering at composition time, rather than at plan execution time. McDermott
(2002) treats the actual interaction (communication) with a web service as a planning problem.
Mediratta and Srivastava (2006) design an approach to WSC based on conditional planning, i.e.,
a form of planning under uncertainty. While this suggests a close relation to our work, the focus
of Mediratta and Srivastavas work is actually quite different from ours. Mediratta and Srivastava
do not consider output variables, and neither do they consider any domain axiomatizations. The
98

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

only overlap with our formalism lies in that they allow incomplete initial state descriptions, i.e.,
initial states that assign a value to only a subset of the propositions. They handle observation
actions which allow observing the value of any unspecified proposition. To ameliorate the need
for complete modeling, they consider a definition of user acceptable plans, where only a subset
of the plan branches, as specified by the user, are guaranteed to lead to the goal. The latter may be
an interesting option to look into when extending our framework to handle partial observability.
Two approaches explore how to adapt formalisms from so-called hand-tailored planning for
SWS composition. The approaches are based on Golog (McIlraith & Son, 2002) and HTN planning (Sirin et al., 2004), respectively. These frameworks enable the human user to provide control
information. However, non-deterministic action choice is allowed. If no control information is
given, then planning is fully automatic. Hence, in this sense, these frameworks are strictly more
powerful than planning without such control information. Further, both approaches are capable of
handling advanced plan constructs such as loops and branches. In Golog, the possible plans  the
possible composition solutions  are described in a kind of logic where high-level instructions are
given by the programmer, and the planner will bind these instructions to concrete actions as part
of the execution. In HTN, the programmer supplies the planning algorithm with a set of so-called
decomposition methods, specifying how a certain task can be accomplished in terms of a combination of sub-tasks. Recursively, there are decomposition methods for those sub-tasks. Thus the
overall task can be decomposed in a step-wise fashion, until atomic actions are reached. Neither
McIlraith and Son (2002) nor Sirin et al. (2004) are concerned with handling ontology axioms, as
we do in this paper. Hence, combining the insights of both directions has synergetic potential, and
is an interesting topic for future work.
Another approach capable of handling advanced plan constructs (loops, branches) is described
by Pistore et al. (2005b), Pistore, Traverso, Bertoli, and Marconi (2005c), Pistore et al. (2005a), and
Bertoli, Pistore, and Traverso (2006). In this work, process level composition is implemented, as
opposed to the profile/capability level composition as addressed in this paper. At the process level,
the semantic descriptions detail precisely how to interact with the SWS, rather than characterizing
them only in terms of preconditions and effects. Pistore et al. (2005b, 2005c, 2005a) and Bertoli
et al. (2006) exploit BDD (Binary Decision Diagram) based search techniques to obtain complex
solutions fully automatically. However, ontology axioms are not handled and input/output types are
matched based on type names.
There are only a few approaches where ontology axioms are used and the requirements on the
matches are relaxed. One of those is described by Sirin, Hendler, and Parsia (2003), Sirin, Parsia,
and Hendler (2004), Sirin and Parsia (2004), and Sirin et al. (2006). In the first two papers of
this series (Sirin et al., 2003, 2004), a SWS composition support tool for human programmers is
proposed: at any stage during the composition process, the tool provides the user with a list of
matching services. The matches are found by examining the subconcept relation. An output A
is considered a match of input B if A  B. This corresponds to plug-in matches. In later work
(Sirin & Parsia, 2004; Sirin et al., 2006), the HTN approach (Sirin et al., 2004) mentioned above
is adapted to not work on the standard planning semantics, but on the description logics semantics
of OWL-S. The difficulties inherent in updating a belief are observed, but the connection to belief
update as studied in the literature is not made, and it remains unclear which solution is adopted.
As far as we are aware, all other methods with more relaxed matches follow what we have here
termed a message-based approach to WSC. These approaches were already discussed in some depth
in Section 2.3. Next, we give a few more details on the ones most closely related to our work. The
99

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

approach by Liu et al. (2007) was discussed in sufficient detail already in Section 2.3, so we do not
reconsider this here.
Meyer and Weske (2006) handle ontology axioms in their WSC tool, but do not provide a
semantics for action applications. Reasoning is only used to determine whether a particular output
can be used to establish a particular input, so the approach can be classified as message-based,
in our terms. The kind of matches handled is said to be plug-in. To the best of our knowledge,
this tool is the only existing WSC tool that employs a relaxed plan based heuristic function, like
CFF. However, through various design decisions, the authors sacrifice scalability. They explicitly
enumerate all world states in every belief, and hence suffer from exponentially large beliefs. They
search forward with parallel actions and consequently suffer from a huge branching factor. They
take their heuristic to be relaxed planning graph length (rather than relaxed plan length) and thus
suffer from the fact that, most of the time, hmax is a much less informative heuristic than h+ (Bonet
& Geffner, 2001; Hoffmann, 2005).
An approach rather closely related to ours, in that it can handle partial matches, is described
by Constantinescu and Faltings (2003) and Constantinescu et al. (2004a, 2004b). In this work the
ontology is assumed to take the form of a tree of concepts, where edges indicate the subconcept
relation. Such a tree is compiled into intervals, where each interval represents a concept and the
contents are arranged to correspond to the tree. The intervals are used for efficient implementation
of indexing in service lookup (discovery), as well as for matching during composition. The latter
searches forward in a space of switches. Starting at the initial input, if the current input is of type
A, then a service with input Ai matches if A  Ai 6= . Such services are collected until the set
of the collected Ai covers A (that is, until the union of the intervals for the various Ai contains the
interval for A). The collected services form a switch, and in the next step of the search, each of their
outputs becomes a new input that must be treated (i.e., the switch is an AND node). Composition
is interleaved with discovery, i.e., in every search state discovery is called to find the services that
match this state. The search proceeds in a depth-first fashion. Major differences to our work are
the following. First, the formalization is very different, using intervals vs. using standard notions
from planning based on logics. Second, the approach interleaves discovery and composition, which
are separate steps in our framework (web service discovery is needed to determine the operators
of a WSC task). Third, the approach considers concept trees vs. clausal integrity constraints. Last,
the approach uses depth-first search, whereas one of the main points we are making is that one can
exploit the heuristic techniques implemented in standard planning tools for scalable WSC.
Finally, an interesting approach related to planning is described by Ambite and Kapoor (2007).
To capture the dependencies between different input variables of a web service, the input is described in terms of a relation between those variables. The same is done for the outputs. The
relations are formulated in terms of logical formulas relative to an ontology. The underlying formalism is first-order logic, so the modeling language is quite expressive.24 Reasoning is performed
in order to establish links (messages, in our terms) between inputs and outputs. The algorithmic
framework in which that happens is inspired by partial-order planning (Penberthy & Weld, 1992),
starting from the goal relation and maintaining a set of open links. The solution is a DAG of web
services where links correspond to different kinds of data exchanges (selection, projection, join,
union). Automatic insertion of mediator services, e.g., for converting a set of standard formats, is
also supported.
24. At the cost of undecidable reasoning, which according to the authors is not a major issue in practice.

100

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

To some extent, our preconditions/effects and clausal integrity constraints can be used to model
relations in the sense of Ambite and Kapoor (2007). Say r is a k-ary relation with definition
, describing the input of a web service. We set the corresponding operators precondition to
r(x1 , . . . , xk ), and we transform  into a set of universally quantified clauses. As long as the
latter can be done, and as long as the ontology axioms can be likewise transformed, we obtain a
model equivalent to that of Ambite and Kapoor. In that sense, the main modeling advantage of the
approach of Ambite and Kapoor over WSC|f wd is existential quantification. It is an open question
whether such quantification can be accommodated in our framework. Insertion of mediator services
can be supported in WSC|f wd , but only in the limited sense of recognizing, via particular preconditions, that a particular kind of mediator is required. Modeling the actual data flow is bound to be
awkward. In summary, the work of Ambite and Kapoor is more advanced than ours from a data description and transformation point of view. On the other hand, Ambite and Kapoor neither consider
belief update, nor do they place their work in the context of a fully-fledged planning formalism, and
they are less concerned with exploiting the heuristic technologies of recent planners. Combining
the virtues of both approaches  within either framework  is an interesting direction for further
research.

8. Discussion
We have suggested a natural planning formalism for a significant notion of web service composition
at the profile / capability level, incorporating on-the-fly creation of constants to model outputs, incomplete initial states to model incomplete user input, conditional effects semantics to model partial
matches, and, most importantly, clausal integrity constraints to model ontology axioms. We have
identified an interesting special case, forward effects, where the semantics of action applications
is simpler than in the general case. We have demonstrated how this relates to the belief update
literature, and we have shown how it results in reduced computational complexity. Forward effects
relate closely to message-based WSC, and our results serve both to put this form of WSC into context, and to extend it towards a more general notion of partial matches. Further, we have identified a
compilation into planning under (initial state) uncertainty, opening up an interesting new connection
between the planning and WSC areas.
Our empirical results are encouraging, but should not be over-interpreted. While our test scenarios serve to capture some structural properties that are likely to appear in applications of WSC
technology, our approach has yet to be put to the test of actual practice. The same, however, can be
said of essentially all current planning-based WSC technology, since that field is still rather immature. In that sense, a more thorough evaluation of our approach, and of planning-based WSC as a
whole, is a challenge for the future.
Apart from such evaluation, there are several directions for research improving and extending
the technology introduced herein. A line of research that we find particularly interesting is to adapt
modern planning tools for WSC, starting from our special cases, where the complications incurred
by integrity constraints are more manageable. We have already outlined a few ideas for adapting
CFF, and pointed out that new challenges arise. It appears particularly promising to tailor generic
heuristic functions, originating in planning, to exploit the typical forms of ontology axioms as occur
in practice. Considering the wealth of heuristic functions available by now, this topic alone provides
material for a whole family of subsequent work.

101

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

Acknowledgments
We thank the anonymous reviewers, as well as the managing editor Derek Long, for their comments,
which were of significant help for improving the paper.
Jorg Hoffmann performed part of this work while being employed at the University of Innsbruck, Austria. His work was partly funded through the European Unions 6th Framework Programme under the SUPER project (IST FP6-026850, http://www.ip-super.org).
Piergiorgio Bertolis and Marco Pistores work was partly supported by the project Software
Methodology and Technology for Peer-to-Peer Systems (STAMPS).
Malte Helmerts work was partly supported by the German Research Council (DFG) as part of
the Transregional Collaborative Research Center Automatic Verification and Analysis of Complex
Systems (SFB/TR 14 AVACS). See www.avacs.org for more information.

Appendix A. Proofs
We first formally prove Proposition 1, stating that negative effects can be compiled away in WSC.
Before we do so, we first need to introduce the compilation formally. Assume a WSC task (P,
+
IC , O, C0 , 0 , G ). We construct a second WSC task (P + , +
IC , O , C0 , 0 , G ), where initially
+
P + , IC and O+ are the same as P, IC and O, respectively. We proceed as follows. Let G 
P be a predicate with arity k, so that there exists o  O, o = (Xo , preo , Yo , effo ) where effo
contains a negative literal G(x1 , . . . , xk ). We introduce a new predicate notG into P + , and we
introduce the two new clauses x1 , . . . , xk : G(x1 , . . . , xk )  notG(x1 , . . . , xk ) and x1 , . . . , xk :
G(x1 , . . . , xk )  notG(x1 , . . . , xk ). For every operator o whose effect contains a negation of
G, we replace, in effo , G(a1 , . . . , ak ) with notG(a1 , . . . , ak ).25 We continue doing so until no
negative effect literals remain in O+ .
If a is an action in (P, IC , O, C0 , 0 , G ) then we denote by a+ the corresponding action
+
+
in (P + , +
IC , O , C0 , 0 , G ). We also use this notation vice versa, i.e., if a is an action in
+
+
+
(P , IC , O , C0 , 0 , G ) then a denotes the corresponding action in (P, IC , O, C0 , 0 , G ). If
s = (Cs , Is ) is a state using the predicates P, then we denote by s+ a state using the predicates P + ,
with the following properties: Cs+ = Cs ; for all p  P Cs we have Is+ (p) = Is (p); for all notp
where p  P Cs we have Is+ (notp) = 1 iff Is (p) = 0. Since there is, obviously, exactly one such
s+ , we will also use this correspondence vice versa.
+
Proposition 1 Assume a WSC task (P, IC , O, C0 , 0 , G ). Let (P + , +
IC , O , C0 , 0 , G ) be
the same task but with negative effects compiled away. Assume an action sequence ha1 , . . . , an i.
Let b be the result of executing ha1 , . . . , an i in (P, IC , O, C0 , 0 , G ), and b+ is the result of
+
+
+
+
executing ha+
1 , . . . , an i in (P , IC , O , C0 , 0 , G ). Then, for any state s, we have that s  b iff
s+  b+ .

Proof: By induction over the length of the action sequence in question. If the sequence is empty,
then we have to consider the initial beliefs of the two tasks, for which the claim follows directly by
definition. For the inductive step, say that the claim holds for b and b+ , and a is an action. We need
to show that, for any state s, we have that s  res(b, a) iff s+  res(b+ , a+ ).
For the direction from right to left, say s+  res(b+ , a+ ). By definition we have s+ 
+
+
+
res(s+
0 , a ) for a state s0  b . By induction hypothesis, s0  b. It therefore suffices to show that
25. The arguments ai here may be either variables or constants.

102

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

s  res(s0 , a). We need to show that (1) s |= IC  effa and (2) s differs from s0 in a set-inclusion
minimal set of values. (1) is obvious from the definitions. Assume to the contrary of (2) that there
exists s1 so that s1 |= IC  effa and s1 is identical to s except that there exists at least one propo+
sition p where s1 (p) = s0 (p) but s(p) 6= s0 (p). By definition, we get that s+
1 |= IC  effa+ .
+
+
+
+
Further, we get that s1 (p) = s0 (p) but s+ (p) 6= s0 (p), and altogether that s1 <s+ s+ . This is a
0
contradiction to s+  res(s+ , a+ ), and hence proves that s  res(s0 , a) as desired.
The direction from left to right proceeds in the same fashion. Say s  res(b, a). By definition
+
we have s  res(s0 , a) for a state s0  b. By induction hypothesis, s+
0  b . It then suffices to
+
+
+
+
+
show that s+  res(s+
0 , a ). We need to show that (1) s |= IC  effa and (2) s differs from s0
in a set-inclusion minimal set of values. (1) is obvious from the definitions. Assume to the contrary
+
+
+
+
of (2) that there exists s+
1 so that s1 |= IC  effa+ and s1 is identical to s except that there
+
+
+
exists at least one proposition p where s+
1 (p) = s0 (p) but s (p) 6= s0 (p). By definition, we get
C
s
that s1 |= IC  effa . Further, if p  P 0 then we get that s1 (p) = s0 (p) but s(p) 6= s0 (p). If
p = notq 6 P Cs0 then we get the same property for q. Altogether, we get that s1 <s0 s. This is a
+
contradiction to s  res(s, a), and hence proves that s+  res(s+
2
0 , a ) as desired.
Theorem 1 Assume a WSC task with fixed arity, and a sequence ha1 , . . . , an i of actions. It is
p2 -complete to decide whether ha1 , . . . , an i is a plan.
Proof: Membership is proved by a guess-and-check argument. First, observe that, for arbitrary s, s ,
and A, we can decide within coNP whether s  res(s, A). Guess a state s where Cs = Cs  Ea .
Check whether s |= IC  effa . Check whether Is 6s Is . Then s  res(s, a) iff no guess
succeeds. Further, for an action a, deciding whether a is inconsistent is, obviously, equivalent
to a satisfiability test, so this is contained in NP. With these instruments at hand, we can design
a guess-and-check procedure to decide whether ha1 , . . . , an i is a plan. We guess the proposition
values along ha1 , . . . , an i. We then check whether these values comply with res, and lead to an
inconsistent action, or to a final state that does not satisfy the goal. In detail, the checking proceeds
as follows. First, check whether the initial proposition values satisfy IC  0 . If not, stop without
success. Otherwise, iteratively consider each action ai , with pre-state s and post-state s . Check
with an NP oracle whether a is inconsistent. If yes, stop with success. If not, test with an NP oracle
whether s  res(s, a). If not, stop without success. Otherwise, if i < n, then go on to ai+1 . If
i = n, then test whether s |= G . Stop with success if s 6|= G , stop without success if s |= G .
ha1 , . . . , an i is a plan iff no guess of proposition values is successful.
Hardness follows by the following adaptation of the proof of Lemma 6.2 from Eiter and Gottlob
(1992). Validity of a QBF formula X.Y.[X, Y ], where  is in CNF, is reduced to plan testing
for a single action a. We use the 0-ary predicates X = {x1 , . . . , xm }, Y = {y1 , . . . , yn }, and
new 0-ary predicates {z1 , . . . , zm , r, t}. The set of operators contains the single operator o with
empty in/out parameters, empty precondition, and effect t. The initial constants are empty; 0 is the
conjunction of all xi , all yi , all zi , r, and t; G is r. The theory is:
(

m
^

i=1

(t  xi  zi ))  (

m
^

(t  xi  zi ))  (

i=1

^

(t  r  C))  (

C

103

n
^

i=1

(t  yi  r))

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

where  is viewed as a set of clauses C. More readably, the theory is equivalent to:
t  [(

m
^

xi  zi )  (r  )  ((

n
_

yi )  r)]

i=1

i=1

We refer to the initial belief as b. The plan to test contains the single action a based on (equal to, in
fact) o. We refer to the resulting belief as b . Obviously, b contains a single state s where everything
except t is true. Also, a is consistent: any interpretation that sets r and all yi to 0 satisfies IC effa .
The theory conjuncts xi  zi make sure that each w  b makes exactly one of xi , zi true.
In particular, the different assignments to X are incomparable with respect to set inclusion. Hence,
we have that for every assignment aX of truth values to X, there exists a state s  b that complies
with aX : aX is satisfiable together with IC  effa , and any other assignment aX is more distant
from s in at least one variable (e.g., if aX (xi ) = 1 and aX (xi ) = 0 then aX is closer to s than aX
regarding the interpretation of zi ).
We now prove that, if a is a plan, then X.Y.[X, Y ] is valid. Let aX be a truth value assignment to X. With the above, we have a state s  b that complies with aX . Since a is a plan, we
have s |= r. Therefore, due to the theory conjunct r  , we have s |= . Obviously, the values
assigned to Y by s satisfy  for aX .
For the other direction, say X.Y.[X, Y ] is valid. Assume that, contrary to theW
claim, a is not
a plan. Then we have s  b so that s 6|= r. But then, due to the theory conjunct ( ni=1 yi )  r,
we have that s sets all yi to false. Now, because X.Y.[X, Y ] is valid, there exists a truth value
assignment aY to Y that complies with the setting of all xi and zi in s. Obtain s by modifying s
to comply with aY , and setting r to 1. We have that s |= IC  effa . But then, s is closer to s
than s , and hence s 6 b in contradiction. This concludes the argument.
2
Theorem 2. Assume a WSC task with fixed arity, and a natural number b in unary representation.
It is p3 -complete to decide whether there exists a plan of length at most b.
Proof: For membership, guess a sequences of actions containing at most b actions (note that the
size of such a sequence is polynomial in the size of the input representation). By Theorem 1, we
can check with a p2 oracle whether the sequence is a plan.
Hardness follows by an extension of the proof of Lemma 6.2 of Eiter and Gottlob (1992). Validity of a QBF formula X.Y.Z.[X, Y, Z], where  is in CNF, is reduced to testing plan existence.
We use the 0-ary predicates X = {x1 , . . . , xn }, Y = {y1 , . . . , ym }, Z = {z1 , . . . , zk }, and new
0-ary predicates {q1 , . . . , qm , r, t, f1 , . . . fn , h, g}. The set of operators is composed of:
 ot := (, f1      fn  h, , t  g  h)
 For 1  i  n: oxi := (, h, , xi  fi )
 For 1  i  n: oxi := (, h, , xi  fi )
The initial constants are empty. The initial literal conjunction 0 is composed of all yi , all zi , all qi ,
r, t, all fi , h, and g. That is, the yi , zi , and qi as well as r and h are true, while the fi as well
as t and g are false. No value is specified (only) for the xi . The goal G is r  g. The theory is:
(

m
^

i=1

(t  yi  qi ))  (

m
^

(t  yi  qi ))  (

i=1

^

(t  r  C))  (

C

104

n
^

i=1

(t  zi  r))

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

where  is viewed as a set of clauses C. More readably, the theory is equivalent to:
t  [(

m
^

yi  qi )  (r  )  ((

i=1

n
_

zi )  r)]

i=1

First, note a few obvious things about this construction:
 ot must be included in any plan.
 Once ot is applied, no action can be applied anymore.
 Before ot is applied, either oxi or oxi must be applied, for every 1  i  n.
 The theory is switched off, i.e., made irrelevant because t is false, up to the point where ot
is applied.
That is, any plan for this task must first apply oxi or oxi , for every 1  i  n, thereby choosing a
value for every xi . Then, ot must be applied and the plan must stop. Before applying ot , no changes
are made to the states except that the values of xi are set and that the fi are made true one after
the other. Hence, the belief b in which ot is applied contains a single state s which corresponds to
an extension of 0 with a value assignment for X, where the values of the fi have been flipped.
We denote the value assignment for X in s with aX . We further denote b := res(b, ot ). Note that
ot is consistent: any interpretation that sets r and all zi to 0, besides setting the immediate effects
t  g  h, satisfies IC  effot . Obviously, all of the applications of oxi and oxi are consistent as
well.
The theory conjuncts yi  qi make sure that each w  b makes exactly one of yi , qi true. In
particular, the different assignments to Y are incomparable with respect to set inclusion. Hence, we
have that for every assignment aY of truth values to Y , there exists a state s  b that complies with
aY : aY is satisfiable together with IC  effot , and any other assignment aY is more distant from s
in at least one variable (e.g., if aY (yi ) = 1 and aY (yi ) = 0 then aY is closer to s than aY regarding
the interpretation of qi ).
We now prove that, if there exists a plan ~a yielding assignment aX , then X.Y.Z.[X, Y, Z]
is valid. Let aY be an arbitrary truth value assignment to Y . Then we have a state s  b that
complies with aX and aY . aX and aY are satisfiable together with IC  effot . With the above, any
other assignment aY is more distant from s in at least one variable. And, of course, if one deviates
from aX then one is more distant from s in the respective variable. Since ~a is a plan, we have s |= r.
Therefore, due to the theory conjunct r  , we have s |= . Obviously, the values assigned to Z
by s satisfy  for aX and aY . This proves the claim because aY can be chosen arbitrarily.
For the other direction, say X.Y.Z.[X, Y, Z] is valid. Let aX be an assignment to X so that
Y.Z.[aX /X, Y, Z] is valid. Let ~a be the corresponding plan, i.e., ~a first applies, for 1  i  n,
either oxi or oxi according to aX . Thereafter, ~a applies ot . Assume
Wn that ~a is not a plan. Then we



have s  b so that s 6|= r. But then, due to the theory conjunct ( i=1 zi )  r, we have that s sets
all zi to false. Now, because Y.Z.[aX /X, Y, Z] is valid, there exists a truth value assignment
aZ to Z that complies with the setting of all xi , yi , and qi in s. Obtain s by modifying s to comply
with aZ , and setting r to 1. We have that s |= IC  effot . But then, s is closer to s than s , and
hence s 6 b in contradiction. This concludes the argument.
2

105

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

Theorem 3. Assume a WSC task. The decision problem asking whether there exists a plan is
undecidable.
Proof: This result holds even with an empty background theory, a complete specification of the
initial state, predicates of arity at most 2, operators of arity at most 2, a goal with no variables at all
(arity 0), and only positive literals in preconditions and the goal. The result follows with a minor
modification of Tom Bylanders proof (Bylander, 1994) that plan existence in propositional STRIPS
planning is PSPACE-complete.26 The original proof proceeds by a generic reduction, constructing a
STRIPS task for a Turing Machine (TM) with polynomially bounded space. The latter restriction is
necessary to model the machines tape: tape cells are pre-created for all positions within the bound.
What makes the difference between PSPACE-membership and undecidability is the ability to create
constants. We can introduce simple operators that allow us to extend the tape, at both ends.
In detail, say the TM has (a finite number of) states q and tape alphabet symbols a (where b is the
blank);  is the transition function, q0 is the initial state, and F is the set of accepting states;  is the
input word. Our planning encoding contains the following predicates. State(q) indicates that the
current TM state is q. In(a, c) indicates that the current content of tape cell c is a. N eighbors(c, c )
is true iff c is the (immediate) right neighbor of c. At(c) indicates that the current position of the
TM head is c. Rightmost(c) (Lef tmost(c)) is true iff c currently has no right (left) neighbor. The
set of initial constants contains all states q, all alphabet symbols a, and tape cells c corresponding
to . By the initial literals, all the propositions over these constants are assigned truth values as
obvious. For every transition (q, a, q  , a , R)   we include an operator:
({x, x }, State(q)  In(x, a)  N eighbors(x, x )  At(x),
, State(q  )  State(q)  In(x, a )  In(x, a)  At(x )  At(x)).
Obviously, this encodes exactly that transition. We do likewise for transitions (q, a, q  , a , L)  .
To model the final states, we introduce a 0-ary predicate G, and include for each q  F an operator:
(, State(q), , G)
We finally include the operators:
({x}, Rightmost(x), {x }, N eighbors(x, x )  In(b, x )  Rightmost(x )  Rightmost(x))
and
({x }, Lef tmost(x ), {x}, N eighbors(x, x )  In(b, x)  Lef tmost(x)  Lef tmost(x ))
With these definitions, it is easy to verify that there exists a plan iff the TM can reach an accepting
state on .
2
Lemma 1. Assume a WSC|f wd task, a reachable state s, and an action a. Then res(s, a) =
res|f wd (s, a).
26. Propositional STRIPS is like our framework, but with an empty background theory, a complete specification of
the initial state, a goal with no variables, only positive literals in preconditions and the goal, and with no output
parameters in the operators.

106

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

Proof: If a is not applicable to s, then the claim holds trivially. Consider the other case. By
Equation 3, res(s, a) is defined as

{(C  , I  ) | C  = Cs  Ea , I   min(s, C  , IC  effa )} appl(s, a)
res(s, a) :=
{s}
otherwise
where min(s, C  , IC  effa ) is the set of all C  -interpretations that satisfy IC  effa and that are
minimal with respect to the partial order defined by I1 s I2 :iff for all propositions p over Cs , if
I2 (p) = Is (p) then I1 (p) = Is (p).
It is obvious that res|f wd (s, a)  res(s, a)  if Is satisfies IC  effa and Is is identical to Is
on the propositions over Cs , then in particular Is is minimal according to s .
For the other direction, let s  res(s, a). Assume that Is (p) 6= Is (p) for some proposition p
over Cs . Define s to be equal to s except that Is (p) := Is (p). Obviously, Is 6s I2 . It now
suffices to show that s |= IC  effa : then, we get Is 6 min(s, C  , IC  effa ) in contradiction,
hence Is agrees with Is on all propositions p over Cs , hence s  res|f wd (s, a).
As before, denote with P Cs +Ea the set of all propositions with arguments in Cs  Ea , and
with at least one argument in E, and denote with IC [Cs + Ea ] the instantiation of IC with all
constants from Cs  Ea , where in each clause at least one variable is instantiated from Ea . To see
that s |= IC  effa , consider first that this is equivalent to s |= IC [Cs  Ea ]  effa , which in
turn is equivalent to s |= IC [Cs ]  IC [Cs + Ea ]  effa . In the last formula, because the task is in
WSC|f wd , IC [Cs ] speaks only over the propositions P Cs , whereas IC [Cs +Ea ]effa speaks only
over the propositions P Cs +Ea . So we can treat these two parts separately. We have s |= IC [Cs ]
because s |= IC [Cs ] by prerequisite since s is reachable. We have s |= IC [Cs + Ea ]  effa by
definition. This concludes the argument.
2
Theorem 4. Assume a WSC|f wd task with fixed arity, and a sequence ha1 , . . . , an i of actions. It
is coNP-complete to decide whether ha1 , . . . , an i is a plan.
Proof: Hardness is obvious, considering an empty sequence. Membership can be shown by the
following guess-and-check argument. Say C is the union of C0 and all output constants appearing
in hA1 , . . . , An i. We guess an interpretation I of all propositions over P and C. Further, for each
1  t  n, we guess a set Ct of constants. We can then check in polynomial time whether I
and the Ct correspond to an execution of hA1 , . . . , An i. For 1  t  n and a  At , say that a
is applicable if I |= prea , Ca  Ct , and Ea  Ct = . First, we assert I |= IC . Second, for
all t and for all a  At , assert that, if a is applicable, then I |= effa . Third, assert that Ct+1 =
Ct  {Ea | a  At , a is applicable}. Using Lemma 1, it is easy to see that I and the Ct correspond
to an execution iff all three assertions hold. Note that I needs not be time-stamped because once
an action has generated its outputs then the properties of the respective propositions remain fixed
forever. The claim follows because, with fixed arity, we can also test in polynomial time whether I
and Cn satisfy G . A guess of I and Ct is successful if it corresponds to an execution and does not
satisfy G . Obviously, hA1 , . . . , An i is a plan iff there is no such guess of I and Ct .
2
Theorem 5. Assume a WSC|f wd task with fixed arity, and a natural number b in unary representation. It is p2 -complete to decide whether there exists a plan of length at most b.
Proof: For membership, guess a sequence of at most b actions. By Theorem 1, we can check with
a p2 oracle whether the sequence is a plan.
107

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

To prove hardness, assume a QBF formula X.Y.[X, Y ] where  is in DNF normal form.
(This formula class is complete for p2 .) Say X = x1 , . . . , xn , Y = y1 , . . . , ym , and  = 1     
k . We design a WSC|f wd task which has a plan iff X.Y.[X, Y ] is true. The key construction
is to use outputs for the creation of time steps, and to allow setting xi only at time step i. The
yi can take on arbitrary values. Once all xi are set, one operator per k allows to achieve the goal
given k is true. The main property we need to ensure in the construction is that each xi can be set
at most once, i.e., either to 1 or to 0. Then there is a plan for the task iff one can set X so that, for
all Y , at least one i is true  which is the case iff X.Y.[X, Y ] is true.
The predicates for our task are P = {x1 (.), . . . , xn (.), y1 (), . . . , ym (), time(.), start(.),
next(..), goal(.)}. We indicate predicate arity here by the number of points in the parentheses.
For example, the predicate next(..) has arity 2. The theory IC is empty. The initial constants are
C0 = {t0 }. The initial literals are 0 = time(t0 ). The goal is y.goal(y). The operators are as
follows:
 For all 1  i  n, we have: oxi 1 = ({t0 , . . . , ti1 }, start(t0 ) next(t0 , t1 )     
next(ti2 , ti1 ), {ti }, time(ti )next(ti1 , ti )xi (ti )). Such an operator allows generating
time step i, and setting xi to 1 at that step.
 For all 1  i  n, we have: oxi 0 = ({t0 , . . . , ti1 }, start(t0 ) next(t0 , t1 )     
next(ti2 , ti1 ), {ti }, time(ti )  next(ti1 , ti )  xi (ti )). Such an operator allows generating time step i, and setting xi to 0 at that step.
 We will define a value B below. For all n  j < n + B, we have: otj = ({t0 , . . . , tj1 },
start(t0 ) next(t0 , t1 )      next(tj2 , tj1 ), {tj }, time(tj )  next(tj1 , tj )). These
operators allow increasing the time step from n to n + B.
 For 1  i  k, say i = xlxj1      xlxjxn  ylyj1      ylyjyn where xlj  {xj , xj }
and ylj  {yj , yj }. We have: oi = ({t0 , . . . , tn+B }, start(t0 ) next(t0 , t1 )     
next(tn+B1 , tn+B ) xlxj1 (txj1 )      xlxjxn (txjxn ) ylyj1 ()      ylyjyn (), {c},
goal(c)). Such an operator allows to achieve the goal after time step n + B, provided the
respective i is true. Note here that the xj precondition literals refer to time step tj , i.e., the
value set for xj at an earlier time step, while the yj precondition literals have no arguments
and refer to the initial values of yj , which are arbitrary.
Assume we choose any value for B (polynomial in the input size). If X.Y.[X, Y ] is true,
then, obviously, we can find a plan of size n + B + k. We apply an oxi 1 or oxi 0 operator for each xi ,
depending on whether xi must be set to 1 or 0. We apply B operators otj . We apply all operators
oi . The respective input parameter instantiations are all obvious.
The opposite direction  proving truth of X.Y.[X, Y ] based on a plan  is more problematic.
The plan might cheat by setting some xi to both 1 and 0. The reason why our construction is so
complicated is to be able to avoid precisely this case, based on specifying a strict enough plan length
bound b. The key property is that, in order to cheat for xi , the plan has to generate two sequences
of time steps ti , . . . , tn+B . Therefore, a lower bound on the length for a cheating plan is n + 2B.
As we have already seen, an upper bound on the length of a non-cheating plan is n + B + k. To
determine our plan length bound b, we now simply choose a B so that any cheating plan will have to
use too many steps: n+2B > n+B +k is the case iff B > k. So we can set B := k +1, and obtain
b := n + 2k + 1. With this bound b, any plan will proceed by setting each xi to a value (n actions),
108

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

increasing the time step to n + B = n + k + 1 (k + 1 actions), and applying a sufficient subset of the
oi (at most k actions). If the plan cheats, then it needs to apply at least n+2B = n+2k +2 actions
before being able to apply oi actions exploiting different value settings for a xi . This concludes
the argument.
2
Theorem 6. Assume a WSC|f wd task. The decision problem asking whether there exists a plan is
undecidable.
Proof: We reduce from the halting problem for Abacus machines, which is undecidable. An Abacus machine consists of a tuple of integer variables v1 , . . . , vk (ranging over all positive integers
including 0), and a tuple of instructions I1 , . . . , In . A state is given by the content of v1 , . . . , vk plus
the index pc of the active instruction. The machine stops iff it reaches a state where pc = n. All vi
are initially 0, and pc is initially 0. There are two kinds of instructions. Ii : INC j; GOTO Ii increments the value of vj and jumps to pc = i . Ii : DEC j; BRANCH Ii+ /Ii0 asks whether vj = 0. If
so, it jumps to pc = i0 . Otherwise, it decrements the value of vj and jumps to pc = i+ .
We map an arbitrary abacus program to a WSC|f wd instance as follows:
 Predicates: number(v), zero(v), succ(v  , v), value1 (v, t), . . . , valuek (v, t), instruction1 (t),
. . . , instructionn (t)
 Background theory: none (i.e., the trivial theory)
 Operators:
 An operator h{v}, {number(v)}, {v  }, {number(v  ), succ(v  , v)}i
 For instructions of the form Ii : INC j; GOTO Ii , the operator
h{v1 , . . . , vk , t},
{instructioni (t), value1 (v1 , t), . . . , valuek (vk , t), succ(v  , vj )},
{t },
{instructioni (t ), value1 (v1 , t ), . . . , valuej1 (vj1 , t ), valuej (v  , t ),
valuej+1 (vj+1 , t ), . . . , valuek (vk , t )}i.
 For instructions of the form Ii : DEC j; BRANCH Ii+ /Ii0 , the operators
h{v1 , . . . , vk , t},
{instructioni (t), value1 (v1 , t), . . . , valuek (vk , t), succ(vj , v  )},
{t },
{instructioni+ (t ), value1 (v1 , t ), . . . , valuej1 (vj1 , t ), valuej (v  , t ),
valuej+1 (vj+1 , t ), . . . , valuek (vk , t )}i.
and
h{v1 , . . . , vk , t},
{instructioni (t), value1 (v1 , t), . . . , valuek (vk , t), zero(vj )},
{t },
{instructioni0 (t ), value1 (v1 , t ), . . . , valuej1 (vj1 , t ), valuej (vj , t ),
valuej+1 (vj+1 , t ), . . . , valuek (vk , t )}i.
109

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

 Initial constants: v0 , t0
 Initial literals: number(v0 )zero(v0 )value1 (v0 , t0 )  valuek (v0 , t0 )instruction1 (t0 )
 Goal condition: t.instructionn (t)
We now describe the intuitive meaning of the constants and predicates. There are two kinds of constants: numbers, which represent natural numbers (including 0), and time points, which represent
computation steps of the Abacus machine. Variables that refer to time points are denoted as t or t
above. All other variables represent numbers.
Three predicates refer to numbers exclusively: number(v) is true iff v encodes a natural number
(and not a time point); zero(v) is true iff v encodes the number 0; and succ(v  , v) is true iff v 
encodes the number that is one larger than the number encoded by v. The reduction does not
enforce that every number is uniquely represented (e.g., there may be several representations of the
number 3), but such a unique representation is not necessary. It is guaranteed that the number 0 is
uniquely represented, though.
The remaining predicates encode configurations of the Abacus machine: valuei (v, t) is true iff,
at time point t, the i-th Abacus variable holds the number represented by v, and instructionj (t) is
true iff the current instruction at time point t is Ij .
Obviously, from an accepting run of the Abacus machine we can extract a plan for the task, and
vice versa. This proves the claim.
2
To prove Theorems 7 and 8, we first establish a core lemma from which both theorems follow
relatively easily. We need a few notations. We denote beliefs (states) in (P, IC , O, C0 , 0 , G )
with b (s), and we denote beliefs (states) in (P  , A, 0 , G ) with b (s). Assume a sequence ha1 , . . . ,
ai i of non-goal achievement actions. Then we denote b := res(b0 , ha1 , . . . , ai i) and b := res(b0 ,
ha1 , . . . , ai i). Note here that we overload the res function to also denote state transitions in the
compiled task formalism. Further, for a state s, by C(s) := {c | s(Ex(c)) = 1} we denote
the constants that exist in s. We denote by C the relation over states s and s that is true iff
C(s) = C(s ) and s|C(s) = s |C(s) . C is an equivalence relation, where equivalent states agree on
which constants exist and howVthey are interpreted. Note that every state s reachable
in the compiled
V
task satisfies s |= IC  0  oO effo [Eo ]. Note further that IC  0  oO effo [Eo ] is actually
satisfiable be prerequisite, unless IC  0 is unsatisfiable, because the outputs are instantiated with
unique constants and the operators are consistent. For a state s, we define [s] :=
^
[
{s | s defined over C0 
effo [Eo ]}
Eo , C(s) = Cs , s|Cs = Is , s |= IC  0 
oO

oO

That is, [s] is the equivalence class of states s reachable in the compiled task that agree with s on
which constants exist and how they are interpreted.
Lemma 3 Assume a WSC|sf wd task without inconsistent operators. Let ha1 , . . . , ai i consist of
non-goal achievement
actions, and let b := res(b0 , ha1 , . . . , ai i) and b := res(b0 , ha1 , . . . , ai i).
S
Then b = sb [s].

Proof: The proof is by induction over i. In the base case, we have i = 0, i.e., b = b0 and b = b0 .
We have b0 =
{s | Cs = C0 , Is |= IC  0 }
110

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

On the other hand, we have b0 =
{s | C(s) = C0 , s |= IC  0 

^

effo [Eo ]}

oO

Obviously, the latter is comprised of one equivalence class for each possibility to assign the propositions over C0 in a way compliant with IC  0 . This is exactly the claim.
In theS
inductive case, say we add another action aS
to ha1 , . . . , ai i. By induction assumption, we
have b = sb [s]. We need to prove that res(b, a) = s res(b,a) [s ]. Obviously, it suffices to prove
S
that, for every s  b, we have res([s], a) = s res(s,a) [s ]. First, say a is not applicable to s. Then
S
s is neither applicable in any s  [s], and we have res([s], a) = [s] = s res(s,a) [s ]. Second, say
a is applicable to s. Then by Lemma 1 we have res(s, a) =
{(Cs  Ea , I  ) | I  |Cs = Is , I  |= IC  effa }
On the other hand, we have res([s], a) =
{s | ex. s  [s], C(s ) = C(s)  Ea , s |C(s) = s, s |= IC  0 

^

effo [Eo ]}

oO

We can re-write the latter into
{s | C(s ) = Cs  Ea , s |Cs = Is , s |= IC  0 

^

effo [Eo ]}

oO

Obviously, as desired, the latter set is comprised of one equivalence class for each possibility to
assign the propositions over Cs  Ea in a way compliant with s and IC  effa . This concludes the
argument.
2
Theorem 7. Assume a WSC|sf wd task (P, IC , O, C0 , 0 , G ) without inconsistent operators,
and a plan ha1 , . . . , an i for the compiled task (P  , A, 0 , G ). Then the sub-sequence of non-goal
achievement actions in ha1 , . . . , an i is a plan for (P, IC , O, C0 , 0 , G ).
Proof: If IC  0 is unsatisfiable, there is nothing to prove, because the start belief of the original
task is empty. For the non-trivial case, first note that, in any plan for the compiled task, the goal
achievement actions can be moved to the back of the plan. Hence, without loss of generality, we can
assume that ha1 , . . . , ai i consist entirely of non-goal achievement actions, and hai+1 , . . . , ai i consist
entirely of goal achievement actions.
S Denote b := res(b0 , ha1 , . . . , ai i) and b := res(b0 , ha1 , . . . ,
ai i). By Lemma 3, we have b = sb [s]. Since ha1 , . . S
. , an i is a plan for the compiled task, every
s  b has a tuple of constants satisfying G . With b = sb [s], it follows that every s  b satisfies
G .
2
Theorem 8. Assume a WSC|sf wd task (P, IC , O, C0 , 0 , G ) without inconsistent operators,
and a plan ha1 , . . . , an i where every operator o appears with at most one instantiation Eo of the
outputs. Then ha1 , . . . , an i can be extended with goal achievement actions to form a plan for the
compiled task (P  , A, 0 , G ) obtained using the outputs Eo .
Proof:
S Denote b := res(b0 , ha1 , . . . , an i) and b := res(b0 , ha1 , . . . , an i). By
S Lemma 3, we have
b = sb [s]. Since ha1 , . . . , an i is a plan, every s  b satisfies G . With b = sb [s], it follows that
every s  b has a tuple of constants satisfying G . Attaching all the respective goal achievement
actions yields a plan for the compiled task.
2
111

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

References
3DComplex.org (2008). A web server to browse protein complexes of known 3d structures.
http://supfam.mrc-lmb.cam.ac.uk/elevy/3dcomplex/data/hierarchy 1/root.html.
Agarwal, V., Chafle, G., Dasgupta, K., Karnik, N., Kumar, A., Mittal, S., & Srivastava, B. (2005a).
Synthy: A system for end to end composition of web services. Journal of Web Semantics,
3(4).
Agarwal, V., Dasgupta, K., Karnik, N., Kumar, A., Kundu, A., Mittal, S., & Srivastava, B. (2005b).
A service creation environment based on end to end composition of web services. In 14th
International Conference on the World Wide Web (WWW05), pp. 128137.
Akkiraju, R., Srivastava, B., Anca-Andreea, I., Goodwin, R., & Syeda-Mahmood, T. (2006). Semaplan: Combining planning with semantic matching to achieve web service composition. In
4th International Conference on Web Services (ICWS06).
Ambite, J., & Kapoor, D. (2007). Automatically composing data workflows with relational descriptions and shim services. In 6th International Semantic Web Conference (ISWC07).
Ankolekar, A., Burstein, M., Hobbs, J., Lassila, O., Martin, D., McDermott, D., McIlraith, S.,
Narayanan, S., Paolucci, M., Payne, T., & Sycara, K. (2002). DAML-S: Web service description for the semantic web. In 1st International Semantic Web Conference (ISWC02).
Au, T.-C., Kuter, U., & Nau, D. (2005). Web service composition with volatile information. In 4th
International Semantic Web Conference (ISWC05).
Au, T.-C., & Nau, D. (2006). The incompleteness of planning with volatile external information. In
17th European Conference on Artificial Intelligence (ECAI06).
Baader, F., Lutz, C., Milicic, M., Sattler, U., & Wolter, F. (2005). Integrating description logics
and action formalisms: First results. In 20th National Conference on Artificial Intelligence
(AAAI05).
Bacchus, F. (2000). Subset of PDDL for the AIPS2000 Planning Competition. The AIPS-00 Planning Competition Committee.
Bertoli, P., Pistore, M., & Traverso, P. (2006). Automated web service composition by on-the-fly
belief space search. In 16th International Conference on Automated Planning and Scheduling
(ICAPS06).
Bonet, B., & Geffner, H. (2000). Planning with incomplete information as heuristic search in belief
space. In 5th International Conference on Artificial Intelligence Planning Systems (AIPS00),
pp. 5261.
Bonet, B., & Geffner, H. (2001). Planning as heuristic search. Artificial Intelligence, 129(12),
533.
Branden, C., & Tooze, J. (1998). Introduction to Protein Structure: Second Edition. Garland Publishing Company, New York. ISBN 0815323050.
Brayton, R., Hachtel, G., McMullen, C., & Sangiovanni-Vincentelli, A. (1984). Logic Minimization
Algorithms for VLSI Synthesis. Kluwer Academic Publishers.
Brewka, G., & Hertzberg, J. (1993). How to do things with worlds: On formalizing actions and
plans. J. Logic and Computation, 3(5), 517532.
112

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

Bryce, D., Kambhampati, S., & Smith, D. E. (2006). Planning graph heuristics for belief space
search. Journal of Artificial Intelligence Research, 26, 3599.
Burstein, M., Hobbs, J., Lassila, O., McDermott, D., McIlraith, S., Narayanan, S., Paolucci, M.,
Parsia, B., Payne, T., Sirin, E., Srinivasan, N., Sycara, K., & Martin, D. (2004). OWL-S:
Semantic Markup for Web Services. OWL-S 1.1. http://www.daml.org/services/owl-s/1.1/.
Version 1.1.
Bylander, T. (1994). The computational complexity of propositional STRIPS planning. Artificial
Intelligence, 69(12), 165204.
Chasman, D. (Ed.). (2003). Protein Structure Determination, Analysis and Applications for Drug
Discovery. Marcel Dekker Ltd. 0-8247-4032-7.
Chen, Y., Wah, B., & Hsu, C. (2006). Temporal planning using subgoal partitioning and resolution
in SGPlan. Journal of Artificial Intelligence Research, 26, 323369.
Cimatti, A., Roveri, M., & Bertoli, P. (2004). Conformant planning via symbolic model checking
and heuristic search. Artificial Intelligence, 159(12), 127206.
Constantinescu, I., & Faltings, B. (2003). Efficient matchmaking and directory services. In 2nd
International Conference on Web Intelligence (WI03).
Constantinescu, I., Faltings, B., & Binder, W. (2004a). Large scale, type-compatible service composition. In 2nd International Conference on Web Services (ICWS04).
Constantinescu, I., Faltings, B., & Binder, W. (2004b). Typed Based Service Composition. In 13th
International Conference on the World Wide Web (WWW04).
de Giacomo, G., Lenzerini, M., Poggi, A., & Rosati, R. (2006). On the update of description
logic ontologies at the instance level. In 21st National Conference on Artificial Intelligence
(AAAI06).
de Giacomo, G., Lenzerini, M., Poggi, A., & Rosati, R. (2007). On the approximation of instance
level update and erasure in description logics. In 22nd National Conference of the American
Association for Artificial Intelligence (AAAI07).
de Jonge, M., van der Linden, W., & Willems, R. (2007). eServices for hospital equipment. In 6th
International Conference on Service-Oriented Computing (ICSOC07), pp. 391397.
Edelkamp, S. (2003). Promela planning. In 10th International SPIN Workshop on Model Checking
of Software (SPIN03).
Eiter, T., Faber, W., Leone, N., Pfeifer, G., & Polleres, A. (2003). A logic programming approach to
knowledge-state planning, II: The DLVK system. Artificial Intelligence, 144(1-2), 157211.
Eiter, T., Faber, W., Leone, N., Pfeifer, G., & Polleres, A. (2004). A logic programming approach to
knowledge-state planning: Semantics and complexity. Transactions on Computational Logic,
5(2), 206263.
Eiter, T., & Gottlob, G. (1992). On the complexity of propositional knowledge base revision, updates, and counterfactuals. Artificial Intelligence, 57(2-3), 227270.
Fagin, R., Kuper, G., Ullman, J., & Vardi, M. (1988). Updating logical databases. Advances in
Computing Research, 3, 118.

113

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

Fensel, D., Lausen, H., Polleres, A., de Bruijn, J., Stollberg, M., Roman, D., & Domingue, J. (2006).
Enabling Semantic Web Services  The Web Service Modeling Ontology. Springer-Verlag.
Fersht, A. (1998). Structure and Mechanism in Protein Science: A Guide to Enzyme Catalysis and
Protein Folding. MPS. ISBN-13 9780716732686.
Fox, M., & Long, D. (2003). PDDL2.1: An extension to PDDL for expressing temporal planning
domains. Journal of Artificial Intelligence Research, 20, 61124.
Gerevini, A., Saetti, A., & Serina, I. (2003). Planning through stochastic local search and temporal
action graphs. Journal of Artificial Intelligence Research, 20, 239290.
Gerevini, A., Saetti, A., Serina, I., & Toninelli, P. (2005). Fast planning in domains with derived
predicates: An approach based on rule-action graphs and local search. In 20th National Conference of the American Association for Artificial Intelligence (AAAI05).
Ginsberg, M., & Smith, D. (1988). Reasoning about action I: A possible worlds approach. Artificial
Intelligence, 35(2), 165195.
Giunchiglia, E., Lee, J., Lifschitz, V., McCain, N., & Turner, H. (2004). Nonmonotonic causal
theories. Artificial Intelligence, 153(1-2), 49104.
Giunchiglia, E., & Lifschitz, V. (1998). An action language based on causal explanation: Preliminary report. In 15th National Conference on Artificial Intelligence (AAAI98).
Golden, K. (2002). DPADL: An action language for data processing domains. In Proc. of the 3rd
International NASA Planning and Scheduling Workshop.
Golden, K. (2003). A domain description language for data processing. In Proc. of the Workshop
on the Future of PDDL at ICAPS03.
Golden, K., Pand, W., Nemani, R., & Votava, P. (2003). Automating the processing of earth observation data. In Proceedings of the 7th International Symposium on Artificial Intelligence,
Robotics and Automation for Space.
Gomes, C., Selman, B., Crato, N., & Kautz, H. (2000). Heavy-tailed phenomena in satisfiability
and constraint satisfaction problems. Journal of Automated Reasoning, 24(1/2), 67100.
Helmert, M. (2002). Decidability and undecidability results for planning with numerical state variables. In 6th International Conference on Artificial Intelligence Planning Systems (AIPS02).
Helmert, M. (2006). The Fast Downward planning system. Journal of Artificial Intelligence Research, 26, 191246.
Herzig, A. (1996). The PMA revisited. In 5th International Conference on Principles of Knowledge
Representation and Reasoning (KR96).
Herzig, A., Lang, J., Marquis, P., & Polacsek, T. (2001). Updates, actions, and planning. In 17th
International Joint Conference on Artificial Intelligence (IJCAI01), pp. 119124.
Herzig, A., & Rifi, O. (1999). Propositional belief base update and minimal change. Artificial
Intelligence, 115(1), 107138.
Hoffmann, J. (2005). Where ignoring delete lists works: Local search topology in planning benchmarks. Journal of Artificial Intelligence Research, 24, 685758.
Hoffmann, J., & Brafman, R. (2006). Conformant planning via heuristic forward search: A new
approach. Artificial Intelligence, 170(67), 507541.
114

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

Hoffmann, J., & Nebel, B. (2001). The FF planning system: Fast plan generation through heuristic
search. Journal of Artificial Intelligence Research, 14, 253302.
Katzuno, H., & Mendelzon, A. (1991). On the difference between updating a knowledge base and
revising it. In 2nd International Conference on Principles of Knowledge Representation and
Reasoning (KR91).
Kona, S., Bansal, A., Gupta, G., & Hite, D. (2007). Automatic composition of semantic web services. In 5th International Conference on Web Services (ICWS07).
Kumar, A., Neogi, A., Pragallapati, S., & Ram, J. (2007). Raising programming abstraction from
objects to services. In 5th International Conference on Web Services (ICWS07).
Kuter, U., Sirin, E., Nau, D., Parsia, B., & Hendler, J. (2005). Information gathering during planning
for web service composition. Journal of Web Semantics, 3(2-3), 183205.
Lecue, F., & Delteil, A. (2007). Making the difference in semantic web service composition. In
22nd National Conference of the American Association for Artificial Intelligence (AAAI07).
Lecue, F., & Leger, A. (2006). A formal model for semantic web service composition. In 5th
International Semantic Web Conference (ISWC06).
Li, L., & Horrocks, I. (2003). A software framework for matchmaking based on semantic web
technology. In 12th International Conference on the World Wide Web (WWW03).
Liberatore, P. (2000). The complexity of belief update. Artificial Intelligence, 119(1-2), 141190.
Lin, F., & Reiter, R. (1994). State constraints revisited. Journal of Logic and Computation, 4(5),
655678.
Liu, H., Lutz, C., Milicic, M., & Wolter, F. (2006a). Reasoning about actions using description
logics with general TBoxes. In 10th European Conference on Logics in Artificial Intelligence
(JELIA 2006).
Liu, H., Lutz, C., Milicic, M., & Wolter, F. (2006b). Updating description logic ABoxes. In 10th International Conference on Principles of Knowledge Representation and Reasoning (KR06).
Liu, Z., Ranganathan, A., & Riabov, A. (2007). A planning approach for message-oriented semantic
web service composition. In 22nd National Conference of the American Association for
Artificial Intelligence (AAAI07).
Long, D., & Fox, M. (2003). The 3rd international planning competition: Results and analysis.
Journal of Artificial Intelligence Research, 20, 159.
Lutz, C., & Sattler, U. (2002). A proposal for describing services with DLs. In International
Workshop on Description Logics 2002 (DL02).
McCain, N., & Turner, H. (1995). A causal theory of ramifications and qualifications. In 14th
International Joint Conference on Artificial Intelligence (IJCAI-95), pp. 19781984.
McCarthy, J., & Hayes, P. (1969). Some philosophical problems from the standpoint of artificial
intelligence. Machine Intelligence, 4, 463502.
McDermott, D. (2002). Estimated-regression planning for interactions with web services. In 6th
International Conference on Artificial Intelligence Planning Systems (AIPS02).
McDermott, D., et al. (1998). The PDDL Planning Domain Definition Language. The AIPS-98
Planning Competition Committee.
115

fiH OFFMANN , B ERTOLI , H ELMERT & P ISTORE

McDermott, D. V. (1999). Using regression-match graphs to control search in planning. Artificial
Intelligence, 109(1-2), 111159.
McGeer, P., Sanghavi, J., Brayton, R. K., & Sangiovanni-Vincentelli, A. (1993). ESPRESSOSignature: A new exact minimizer for logic functions. In Proceedings of the 30th ACM/IEEE
Design Automation Conference (DAC-93).
McGuinness, D. L., & van Harmelen, F. (2004). OWL Web Ontology Language Overview (W3C
Recommendation). online at http://www.w3.org/TR/owl-features/.
McIlraith, S., & Fadel, R. (2002). Planning with complex actions. In 9th International Workshop
on Non-Monotonic Reasoning (NMR02), pp. 356364.
McIlraith, S., & Son, T. C. (2002). Adapting Golog for composition of semantic Web services. In
8th International Conference on the Principles of Knowledge Representation and Reasoning
(KR02).
Mediratta, A., & Srivastava, B. (2006). Applying planning in composition of web services with a
user-driven contingent planner. Tech. rep. RI 06002, IBM Research.
Meyer, H., & Weske, M. (2006). Automated service composition using heuristic search. In 4th
International Conference on Business Process Management (BPM06).
Narayanan, S., & McIlraith, S. (2002). Simulation, verification and automated composition of web
services. In 11th International Conference on the World Wide Web (WWW02).
Palacios, H., & Geffner, H. (2007). From conformant into classical planning: Efficient translations
that may be complete too. In 17th International Conference on Automated Planning and
Scheduling (ICAPS07).
Paolucci, M., Kawamura, T., Payne, T., & Sycara, K. (2002). Semantic matching of web services
capabilities. In 1st International Semantic Web Conference (ISWC02).
Pednault, E. P. (1989). ADL: Exploring the middle ground between STRIPS and the situation
calculus. In 1st International Conference on the Principles of Knowledge Representation and
Reasoning (KR89).
Penberthy, J., & Weld, D. (1992). UCPOP: A sound, complete, partial order planner for ADL. In
3rd International Conference on the Principles of Knowledge Representation and Reasoning
(KR92), pp. 103114.
Petsko, G. A., & Ringe, D. (2004). Protein Structure and Function. New Science Press. ISBN
1405119225, 9781405119221.
Pistore, M., Marconi, A., Bertoli, P., & Traverso, P. (2005a). Automated composition of web services by planning at the knowledge level. In 19th International Joint Conference on Artificial
Intelligence (IJCAI05).
Pistore, M., Traverso, P., & Bertoli, P. (2005b). Automated composition of web services by planning
in asynchronous domains. In 15th International Conference on Automated Planning and
Scheduling (ICAPS05).
Pistore, M., Traverso, P., Bertoli, P., & Marconi, A. (2005c). Automated synthesis of composite
BPEL4WS web services. In 3rd International Conference on Web Services (ICWS05).

116

fiW EB S ERVICE C OMPOSITION AND P LANNING UNDER U NCERTAINTY: A N EW C ONNECTION

Ponnekanti, S., & Fox, A. (2002). SWORD: A developer toolkit for web services composition. In
11th International Conference on the World Wide Web (WWW02).
Reiter, R. (1991). The frame problem in the situation calculus: a simple solution (sometimes) and a
completeness result for goal regression. In Artificial intelligence and mathematical theory of
computation: papers in honour of John McCarthy, pp. 359380.
Roman, D., Keller, U., Lausen, H., de Bruijn, J., Lara, R., Stollberg, M., Polleres, A., Feier, C.,
Bussler, C., & Fensel, D. (2005). Web Service Modeling Ontology. Applied Ontology, 1(1),
77106.
Sheshagiri, M., desJardins, M., & Finin, T. (2003). A planner for composing services described in
DAML-S. In Third Symposium on Adaptive Agents and Multi-Agent Systems (AAMAS03).
Sirin, E., Parsia, B., Wu, D., Hendler, J., & Nau, D. (2004). HTN planning for web service composition using SHOP2. Journal of Web Semantics, 1(4).
Sirin, E., Hendler, J., & Parsia, B. (2003). Semi-automatic composition of web services using
semantic descriptions. In Workshop Web Services at ICEIS03.
Sirin, E., & Parsia, B. (2004). Planning for semantic web services. In Workshop Semantic Web
Services at ISWC04.
Sirin, E., Parsia, B., & Hendler, J. (2004). Composition-driven filtering and selection of semantic
web services. In AAAI Fall Symposium on Semantic Web Services.
Sirin, E., Parsia, B., & Hendler, J. (2006). Template-based composition of semantic web services.
In AAAI Fall Symposium on Agents and Search.
Smith, D. E., & Weld, D. (1998). Conformant Graphplan. In 15th National Conference of the
American Association for Artificial Intelligence (AAAI-98).
Srivastava, B. (2002). Automatic web services composition using planning. In Knowledge Based
Computer Systems (KBCS02), pp. 467477.
Thakkar, S., Ambite, J. L., & Knoblock, C. (2005). Composing, optimizing, and executing plans for
bioinformatics web services. VLDB Journal, Special Issue on Data Management, Analysis
and Mining for Life Sciences, 14(3), 330353.
Thiebaux, S., Hoffmann, J., & Nebel, B. (2005). In defense of PDDL axioms. Artificial Intelligence,
168(12), 3869.
Winslett, M. (1988). Reasoning about actions using a possible models approach. In 7th National
Conference of the American Association for Artificial Intelligence (AAAI88).
Winslett, M. (1990). Updating Logical Databases. Cambridge University Press.
Zhan, R., Arpinar, B., & Aleman-Meza, B. (2003). Automatic composition of semantic web services. In 1st International Conference on Web Services (ICWS03).

117

fi