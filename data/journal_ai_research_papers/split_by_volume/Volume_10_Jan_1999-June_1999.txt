Journal of Artificial Intelligence Research 10 (1999) 399-434

Submitted 10/98; published 6/99

Extensible Knowledge Representation: the Case of
Description Reasoners
Alex Borgida

borgida@cs.rutgers.edu

Dept. of Computer Science
Rutgers University
New Brunswick, NJ 08904 USA

Abstract
This paper offers an approach to extensible knowledge representation and reasoning for
the Description Logic family of formalisms. The approach is based on the notion of adding
new concept constructors, and includes a heuristic methodology for specifying the desired
extensions, as well as a modularized software architecture that supports implementing
extensions. The architecture detailed here falls in the normalize-compared paradigm, and
supports both intentional reasoning (subsumption) involving concepts, and extensional
reasoning involving individuals after incremental updates to the knowledge base.
The resulting approach can be used to extend the reasoner with specialized notions
that are motivated by specific problems or application areas, such as reasoning about
dates, plans, etc. In addition, it provides an opportunity to implement constructors that
are not currently yet sufficiently well understood theoretically, but are needed in practice.
Also, for constructors that are provably hard to reason with (e.g., ones whose presence
would lead to undecidability), it allows the implementation of incomplete reasoners where
the incompleteness is tailored to be acceptable for the application at hand.

1. Introduction and Motivation
Description Logics (DLs) are a family of object-centered formalisms for representing knowledge about and reasoning with individuals grouped into classes (here called concepts) and
related by binary relations (here called roles). Descriptions usually have a term-like notation that uses concept constructors and identifiers to build definitions of more complex
concepts from simpler ones. For example, the description in Figure 1 is supposed to capture
the noun phrase A collection of objects that are books and that are written by two or more
authors, who are all Venusians.
and(
BOOK
at-least(2,authoredBy)
all(authoredBy, VENUSIAN) )
Figure 1: An example description.
This is accomplished by using the concept constructor and to conjoin terms that represent
component notions:
c
1999
AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiBorgida

BOOK: objects that are books  a concept declared elsewhere, probably as a primitive;
at-least(2,authoredBy): objects that are related to at least 2 other objects by the authoredBy role; the concept constructor is at-least here;
all(authoredBy, VENUSIAN): objects that are related by the authoredBy role only to objects that are in the concept VENUSIAN; the concept constructor here is all.
The concept VENUSIAN might itself be defined as a being whose address includes the planet
value Venus: and(BEING, all(address, fills(planet, Venus))). (Note that descriptions
can be nested.) A more precise introduction to DLs is presented in Section 2.
Description logics reason both about intensional notions such as concepts, and about
extensional aspects having to do with individuals that can be ascribed descriptions and
participate in specific relationships. DLs have found a variety of applications in areas
such as data management (Borgida, 1995), software engineering (Devanbu & Jones, 1997),
configuration management (Wright et al., 1993), as well as general AI.
A particular description language is characterized, among others, by the choice of term
constructors in it, and the significant features of DLs are clear, precise semantics and terminating reasoning algorithms for tasks such as determining whether a concept is coherent,
or whether it is more general than another one.
A common difficulty faced both by designers and users of knowledge-base management
systems (KBMSs) based on DLs (or any other logic, for that matter) is that many applications need to keep information about specialized kinds of data, including strings, dates,
pictures, sequences of values of various kinds, etc., and it is practically impossible to anticipate all of these as part of language design.
A related problem is that if reasoning is to be complete and efficient, or even decidable,
then what can be expressed in the language must be limited. For example, if in Figure 1 we
also wanted to say that the authors speak the language in which the book is written, there
is a concept constructor already discussed in the literature, called subset-of, with which
one could express such a constraint as subset-of( [writtenIn] [authoredBy,speaks] ).
Unfortunately, reasoning in a language that supports constructors and, all and subset-of is
known to be undecidable (Schmidt-Schauss, 1989). This means that the selection of concept
constructors in the language is a matter of very careful consideration for the system designer,
who is faced with several choices: (a) Select a particular subset of constructors for which
a sound and complete reasoning algorithm is known; if the language is sufficiently limited,
this procedure is guaranteed to be fast (e.g., in polynomial time); otherwise, its worst case
complexity is non-polynomial, though in practice the algorithm may behave well. Living
with limited languages is however not always easy (Doyle & Patil, 1991). (b) Choose
a larger set of constructors (possibly one which is even undecidable), and implement an
incomplete reasoner; this however requires having to explain to the user which inferences will
or will not be made. Both alternatives have different shortcomings, but, from our viewpoint,
a significant common problem is that in all cases it is the designer of the DL system who
makes these decisions ahead of time, leaving the user to sort out the consequences later on.
We propose to attack the above problems by starting with a relatively small, kernel
language and system, and then providing facilities to extend it by adding new concept constructors. Such extensions are not to be undertaken lightly, since they provide opportunities
400

fiExtensible DL Representation and Reasoning

for errors. Some of the extensions will be standard DL constructors for which complete reasoning can be implemented. Such extensions could be readily available in a library1 . Other
extensions will involve standard DL constructors which are known to be hard to reason
with, and for which only an incomplete reasoning algorithm is provided, because, for example, the problem is undecidable or because the only algorithms currently known involve
combinatorial search. In this second case, consultation with the user may help determine
which inferences the implementation should make. For example, in classic, for the sake
of a clearer semantics the system designers chose to draw no inferences about an individual
based on its presence in a concept (Borgida & Patel-Schneider, 1994), although some of
these inferences are not hard to implement. Finally, new concept constructors can be added
for notions that are either domain specific (e,g,. plans, time), or which are of great practical utility but whose interaction with the full spectrum of DL constructors is not yet fully
understood theoretically; such notions include keys/unique identifiers (Borgida & Weddell,
1997) and part-whole relationships (Padgham & Lambrix, 1994).
To support this, we develop a well-modularized architecture for DL-KBMSs that are
implemented using the normalize-compare approach (see Section 2.4); this architecture
expects a set of procedures to be filled in for each new concept constructor extending the
original language. In addition, we propose methodological heuristics for specifying what
these procedures need to do. Note that our goal is to obtain close to the same efficiency as
would have been offered by a custom-built DL reasoner.
Of course, the approach presented here is not a panacea for knowledge representation
and reasoning. First of all, to the extent that normalize-compare algorithms are unable to
reason in a complete manner with DL constructors involving incomplete knowledge such as
disjunction, the present system is also likely to suffer the same deficiencies. Second, the
present work has not yet addressed DL notions such as role constructors, recursive concepts,
and general constraints (to be described later). Finally, there are many other notions in
knowledge representation, such as the full spectrum of epistemic and other non-monotonic
reasoning, abduction, case-based reasoning, etc., which are likely to require a thorough
overhaul of the entire reasoning architecture, and hence are likely not to be accommodated
properly by the present approach.
The outline of the rest of the paper is as follows: Section 2 provides an introduction to
DLs, their syntax and semantic description, and the services provided by KBMSs concerning
reasoning with concepts, especially the subsumption relationship. Section 3 introduces
the architecture of the proposed protodl approach to DL reasoning, provides an overview
of the methodology for extending it, and illustrates it with constructors involving dates; it
terminates by discussing successes and limitations of the proposed protodl approach to
extension, an its relationship to one particular other approach that is directly relevant.
In Sections 4 and 5 we repeat the above process, but considering this time reasoning
about individuals, and focusing on how to support efficiently incremental updates to the
knowledge base.
We conclude by discussing relevant related work and summarizing the contributions and
limitations of the protodl approach.
1. It is important to clarify from the beginning that the addition of constructors is often not a simple
incremental process: some constructors may behave well independently, but cause problems when brought
into the same language.

401

fiBorgida

2. Description Logics: An Introduction
DLs are used to describe situations using various kinds of individuals, related by roles, and
grouped into concepts. Roles that are restricted to be (partial) functions are distinguished,
and are called attributes.
In this section we present the syntax and semantics of DLs, as well as outlining the
interaction with a typical DL-based KBMS, and some implementation strategies.
2.1 Syntax and Semantics
As illustrated in Figure 1, DLs provide a compositional and structured language for
talking about these kinds of things. Composite concepts are obtained according to the
syntax presented in Table 1, which includes the concept constructors mentioned in this
paper. The meta-symbols have the following referents: CN is a concept name, p is an
atomic role (including an attribute), f is an attribute, C and D are general concepts, b is
an individual, while n is an integer; subscripts may occasionally be added to the above.
RoleChain ::= [p1, . . . , pn]
AttributeChain ::= [f1 , . . . , fn ]
C ::= thing | nothing | CN
| and( C1 , . . . , Cn ) | at-least(n,p) | at-most(n,p)
| all(p,C) | some(p,C) | fills(p,b) | one-of(b1 , . . . bn )
| same-as(AttributeChain1 , AttributeChain2 )
| subset-of(RoleChain1 , RoleChain2 )
Table 1: Syntax of Concept Constructors Used.
To give meaning to the above syntactic terms, one can give descriptions a denotational
semantics using an interpretation I=(I ,I ). I starts by assigning to each concept name
a subset of the domain I , to each role a subset of I  I , to each attribute an element
of I  I restricted to be functional, and to each individual some element of I . The
interpretation is then extended to composite terms as follows. First, role chains (resp.
attribute chains) are interpreted as mappings resulting from relation composition:
I

[p1,    , pn] = {x 7 Sx | Sx = {y | z1 , ..., zn+1. z1 = x  zn+1 = y 

n
^

(zi , zi+1 )  pIi }}

i=1

Table 2 then presents the interpretation of complex terms using the interpretation of their
components.
Alternatively, by noting that concepts are like unary predicates, and roles are like binary
predicates, we can offer translation schemes from descriptions to Predicate Calculus. For
example, and(AMERICAN,OLD) corresponds to the formula AMERICAN()OLD(), where  is
a free variable, while all(authoredBy,VENUSIAN) corresponds to y.authoredBy(, y) 
VENUSIAN(y).
The connection between these two kinds of specifications is that interpretations can be
applied to both predicate calculus formulas as well as concepts (Baader, 1996; Borgida,
402

fiExtensible DL Representation and Reasoning

TERM
thing
nothing
and( C1 , . . ., Cn )
at-least(n, p)
at-most(n, p)
all(p, C)
some(p, C)
fills(p, b)
one-of(b1 ,...,bm)
same-as(F C1 , F C2)
subset-of(RC1 , RC2)

INTERPRETATION
I

C1I  . . .  CnI
{ d  I | |pI (d)|  n }
{ d  I | |pI (d)|  n }
{ d  I | pI (d)  C I }
{ d  I | pI (d)  C I 6=  }
{ d  I | bI  pI (d) }
{ bI1 , . . . , bIm }
{ d  I | F C1I (d) = F C2I (d)  F C1I (d) 6=  }
{ d  I | RC1I (d)  RC2I (d) }

Table 2: Interpretation of DL Constructors.
1996): given a description C, with corresponding logical formula C (), and an interpretation I, the denotation C I is identical to the set of values d  I for which C ()I is true,
when I is extended to map  to d.
Finally, we remark that many DLs also allow role constructors; for example, isAuthorOf
can be defined as the converse of the authoredBy relation, by writing inverse(authoredBy).
In this paper we do not consider role constructors (hence equating roles with role names).
2.2 Subsumption Reasoning with Concepts
The real significance of DLs is that one can reason about descriptions. Traditionally, the
standard question one asks is whether one description is more general than (subsumes)
another. For example, we would expect that the description in Figure 1 subsumes the
following description, which requires in addition that the books be published in at most the
four countries enumerated, and that there be at least three (rather than two) authors, who
are to be married to earthlings:
and(
BOOK
all(publishedIn, one-of(Usa,France,Germany,Italy))
at-least(3,authoredBy)
all(authoredBy, and( VENUSIAN,
all(marriedTo, TERRESTRIAL)))
)
Formally, subsumption between concepts C and D, written as C = D, holds iff C I  DI
for all interpretations I. In addition, we say that a description C is incoherent iff its
denotation C I is the empty set in all interpretations I. Note that this is the case iff
C = nothing.
The semantics of concept constructors, and especially the deductions performed by a
particular system can also be specified using proof theory. A proof-theoretic specification in
403

fiBorgida

the natural semantics style (Borgida, 1992a), would indicate, among others, that greater
bounds on the number of role fillers for role p lead to more specialized concepts:
mn
at-least(m, p) = at-least(n, p)

This rule can be paraphrased as IF one can prove m  n THEN one can write as the next
line of a proof that at-least(m, p) = at-least(n, p). Such a rule allows us to prove that
at-least(2,authoredBy) = at-least(1,authoredBy).
As usual, it is possible (and desirable) to demonstrate that the rules of inference are
sound and complete with respect to the denotational semantics. Rules of inference are useful
in characterizing reasoners that are incomplete with respect to the standard denotational
semantics, by describing either the inferences performed, or the ones missing. Also, as
we shall argue below, rules of inference can form a good starting point for developing
implementations.
2.3 DL Concept KBMS
A concept knowledge base CKB (also known as a T-box) records constraints on concept
names, including definitions (such as the concept VENUSIAN mentioned in our examples) and
necessary conditions for primitive concepts (e.g., a BOOK would be required to have at least
one author). In some DLs it is possible to state general subsumption constraints between
arbitrary descriptions, but this will not be permitted in this paper.
Formally, CKB is a tuple (R, F , C, O, N , D) where R, F , C, O are respectively the sets
of role, attribute, concept and individual object identifiers declared. Concept names are
either primitive/atomic concept names, P N , which have associated a necessary condition
 C in the set N of necessary conditions; or defined concept names, DN , which have
PN 
.
associated a definition DN = C in the set D of definitions. An interpretation I is a model
.
 C iff P N I  C I , and is a model of DN =
of P N 
C iff DN I = C I . An interpretation is
a model of CKB if it is a model of all conditions in N and D.
C is said to subsume D in the presence of a knowledge base CKB (written CKB
|= C = D), iff C I  DI for all models I of CKB.
In this paper we are restricting ourselves to non-recursive knowledge bases, where definitions and necessary conditions are given at the same time as the name is declared, and
they can only involve previously declared identifiers.
A DL-based knowledge base management system supports certain update operations,
which affect the CKB (R, F , C, O, N , D) as follows:
Operation
declare-primitive-role(p)
declare-primitive-attribute(f )
declare-individual(b)
declare-primitive-concept(P N ,D)
declare-defined-concept(CN ,D)

Effect
p is added to R
f is added to F
b is added to O
 D to N
P N is added to C, and P N 
.
CN is added to C, and CN = D to D

In return, we expect the KBMS to respond to inquiries, which include retrieving the declarations entered and at least the following operations:
404

fiExtensible DL Representation and Reasoning

Question
ask-subsumes?(C, D)
ask-ancestors(C)
ask-is-incoherent?(C)

Answer type
Boolean
SET(ConceptName)
Boolean

Response
true iff CKB |= C = D
{CN C | CKB |= C = CN }
true iff CKB |= C = nothing

A number of other operations on concepts have been found to be useful, including
(i) computing the least common subsumer of two concepts (Cohen, Borgida, & Hirsh,
1992) (useful for machine learning), (ii) matching concepts against patterns (Borgida &
McGuinness, 1996) (useful in large KBs for viewing only relevant aspects of concepts), (iii)
finding what additional information has been deduced about a concept or especially an
individual given the information in the KB (see Section 4.2).
To facilitate answering the above questions, and others like them, the DL-KBMS almost
always performs concept classification: named concepts (classes) are organized into the
so-called IsA hierarchy, finding for each class the most specific other classes that subsume
it. The classification algorithm relies on the = relationships, treating it as a subroutine,
and as such is largely DL-independent. Interesting previous work in this area has been
reported by Baader et al (Baader et al., 1994).
The KBMS is also charged with a number of clerical tasks, including keeping a symbol
table of the declarations, maintaining and accessing efficiently the precomputed IsA hierarchy, signaling definitions/declarations that are redundant (i.e., a concept which is equivalent
to a previously defined one) or are incoherent.
DL-KBMS perform inferences on individuals, as well as concepts. The operations involved will be described in Section 5.
2.4 Reasoning Strategies
There are two general approaches to answering the fundamental subsumption question
underlying the DL-KBMS operations.
One approach is based on theorem proving techniques specially adapted for descriptions,
particularly variants of tableau techniques that determine the subsumption A = B by
checking for the unsatisfiability of AB; systems such as kris (Baader et al., 1994),crack
(Bresciani, Franconi, & Tessaris, 1995), FaCT (Horrocks, 1998) and DLP (Patel-Schneider,
1998) follow this approach. Such systems have the advantage of being provably complete.
Although the worst-case complexity bounds of the subsumption problems are sometimes
quite high (EXPTIME complete), recent empirical evidence shows that their performance
for computing subsumption on large realistic KBs is quite effective (Horrocks & PatelSchneider, 1998).
All the implemented DL KBMS systems that have had wide distribution and use, such
as back (von Luck et al., 1987), classic (Borgida et al., 1989), and loom (MacGregor, 1986), follow a so-called normalize-compare paradigm, where most of the reasoning
work is performed in an initial normalization phase, whose goal is to find a normal
form for concepts which explicates implicit facts, eliminates redundancies and detects incoherencies. Once this is done, when, for example, it comes to comparing two concepts for
subsumption, it is often (but not always) a matter of comparing only structurally similar elements  ones built with the same constructor. For example, since the descriptions
405

fiBorgida

all(pet,nothing) and at-most(0,pet) are equivalent (subsume each other), in a normal form both would appear, so that subsumption comparison with all(pet,DOG) would
only require looking at all(pet,nothing), while comparison with at-most(3,pet) would
locate at-most(0,pet).
The present work was carried out over a period of several years within this normalizecompare paradigm. The original reasons for this choice included the following features,
which were only available for this paradigm: having a sizable user base; supporting additional KBMS operations, such as least common subsumer, pattern matching, explanation;
reasoning with large knowledge bases of individuals, and especially doing so incrementally
in an environment where one needs the logical completion of an individual.
We remark that the tableau technology has recently become competitive on sizable
knowledge bases of concepts. The promise of provably complete and effective reasoners for
expressive languages is very enticing, and therefore the study of extensibility in tableaux
approaches (Baader & Hanschke, 1991; Bresciani et al., 1995) is of great interest.

3. Concept Reasoning in protodl
Our approach to extensible KBMSs is based on the idea that in a case when the current
KBMS does not meet the users representation and reasoning needs, one can extend it
by adding one or more new description constructors  what would be considered logical
connectives.
Although this approach is clearly restrictive, it has the advantage of being very specific
and directed; it allows us to develop an implementation architecture and accompanying
methodology to support the process of extension. The approach is also supported by empirical evidence from the use of the classic system in many applications: the test-defined
concepts of classic have been crucial in escaping the expressive limitations of the basic
language, and each such test function acts essentially as a new concept constructor2.
3.1 The Modularized Implementation Architecture
As previously described, the concept reasoning services of our DL-KBMS are delivered by
operations which rely on the = relationship, to be computed by the function Subsumes?.
In our implementation paradigm, this function takes as arguments two normalized concepts.
Hence we need some way to take input and convert it into normalized concepts. This means
parsing the concept (function Parse) and normalizing it (function Normalize).
Because of the uniform prefix nature of DL syntax, parsing is easily performed by recursive descent with a single token look-ahead; so we associate with every concept constructor
Q, a function Q::Parse.
After examining earlier implementations and applications, a key decision underlying the
protodl implementation is that a normalized concept is viewed as the conjunction of a
collection of component concepts, which are either concept identifiers or are normalized
terms built with concept constructors Q other than and. Therefore, it is possible to view
a normalized concept as a data abstraction that encapsulates the way in which the various
2. Note however that reasoning with test-concepts in classic was minimal: no subsumption reasoning
other than identity checking was performed, and individual reasoning was limited to recognition.

406

fiExtensible DL Representation and Reasoning

components are stored and accessed thru a set of functions put Q(value) and get Q() 
one for each concept constructor Q. For example, the put one-of operation stores a set of
individuals S, while get one-of returns this set3. On the other hand, for the constructor
fills, the (normalized) value stored is a set of terms of type <Role  SET(Individual)>,
since for each role, we need to store the set of current fillers. For constructors such as
fills, which are associated with a single role, we overload the put and get functions so
they accept a separate role argument, allowing us to access each value independently (e.g.,
get fills(p:<Role>) returns <SET(Individual)>). In fact, for such constructors it is
more efficient to group them by the role identifier, but to simplify the exposition we shall
not pursue this distinction in the rest of this section.
As mentioned earlier, the ideal normalized concept would have the property that subsumption could be determined by comparing, using Q::Subsumes?, only components built
with the same constructor. In other words, Subsumes? would have the pseudo-code
Subsumes?(hiNC, lowNC: <NormalizedConcept>) returns <Bool>
;; structural subsumption
{For every Q(T) in getComponents(hiNC) do
{ lowComponent := get Q(lowNC);
if not Q::Subsumes?(T,lowComponent)
return false; }
return true; }
As we shall see in Section 3.3, this is too restrictive however, so we will pass as parameter
the entire normalized lower concept, lowNC, rather than just the lowComponent. Therefore,
for every constructor Q we expect a function
Q::Subsumes?(<NormalizedQ-term>,<NormalizedConcept>) .

In order to normalize a concept, we will normalize each component separately, and then
combine them. Since a normalized concept represents a conjunction, the combinator function will be named Conjoin. Here are then the remaining functions that are provided ahead
of time by the core implementation:
Normalize(pC : <ParsedConcept> )

returns <NormalizedConcept>
throws IncoherentExn;
/* Start ND to be a data structure having no constraints  i.e.like thing */
ND := copy of NormalFormthing;
{ /* Normalize each component and conjoin it onto ND */
For every Q(T) in pC do {
T norm := Q::Normalize(T);
Q::Conjoin(T norm,ND); }
/* Replace concept ids by normalized form (saved by declare ) */
For every concept identifier N in pC do {
N norm := look up normalized form of N;
Conjoin(N norm,ND); }

3. The type of a parameter will be indicated by enclosing it in angle-brackets. Thus, we would have referred
to put one-of(s: <SET(Individual)>).

407

fiBorgida

/* if any Normalize or Conjoin detects an incoherence, propagate it up,
since the whole conjunct is incoherent. */
}
catch IncoherentExn { throw IncoherentExn }
return ND;

Conjoin(fromNC, ontoNC: <NormalizedConcept>) throws IncoherentExn
/* Take each component of fromNC and conjoin it to ontoNC;
modifies ontoNC. */
{For every Q(T) in getComponents(fromNC) do
{Q::Conjoin( T, ontoNC)
} catch IncoherentExn {throw IncoherentExn }
}
Therefore, for every constructor Q, we also expect corresponding functions Q::Normalize
and Q::Conjoin . Note that the software architecture treats incoherent concepts (ones
equivalent to nothing) in a special manner: whenever they are encountered, a special exception IncoherentExn is raised. Conjunction propagates these exceptions, but other constructors may trap them and handle them in their own way. For example, all::Normalize
accepts the restriction being incoherent, but must ensure that at-most(0) is also added to
the normalized concept for the same role.
In retrospect, the above three functions (Subsumes?, Normalize and Conjoin) really
represent the semantics of the constructor and (and hence can be appropriately called
and::Subsumes?, etc.) as well as the expansion of necessary conditions/definitions for
named concepts (inheritance), and parts of the meaning of the built-in concepts nothing and thing. To make this more complete, we can add to the beginning of the Subsumes?
function the statement: if equal(hiNC,NormalFormthing) or equal(lowNC,NormalForm nothing) then return true;
In this sense, protodl starts from a minimal, core language specified by the syntax
C ::= thing | nothing | CN | (and C1 , . . . , Cn )
This is not to say that everyone must start from this minimalist language, which is hardly
useful. But it will have the advantage that all constructors (even the most useful ones,
like all, at-least, etc.) will be implemented as extensions, according to the same uniform
paradigm as the more esoteric extensions. This will be essential if we are to be able to
easily modify the implementation of standard constructors (like all) when called upon to
implement non-standard ones (like dates), which may interact with them.
3.2 An Overview of the Process of Extension.
Suppose we want to extend the system at some particular stage with a new concept constructor. The following is a suggested methodology for accomplishing this, illustrated with
a familiar concept constructor, all.
408

fiExtensible DL Representation and Reasoning

(1) Determine a syntax for the extension. If concepts will have a LISP-like syntax (as in
classic and loom), the constructor all might be given the syntax (:all Role Concept).
The terms following the constructor are called its arguments, and a version of them will
eventually be stored in the internal representation of our normalized concepts. One can
now implement the function all::Parse, which in this case would invoke Role::parse and
Concept::parse.
(2) Determine a semantics for the new concept constructor.
First, this requires settling on a domain of values from which its denotation will come. This
might be the set of ordinary objects with unique intrinsic identity  instances of a special
class any-object, which is a built-in direct subclass of thing. The denotation might also
be some new kind of value (e.g., triples for dates, or lists of objects), in which case it is
necessary to introduce (possibly as a new concept constructor, which takes no argument) a
top class for these kinds of values (e.g., any-date for dates).
It is now time to clarify the intended meaning of the new constructors. One alternative,
not explored here, is to express the semantics using First Order Predicate Calculus. Another
is to assign a denotation of values to concepts built with the new constructor. For all, this
is just the usual interpretation
all(p, C)I = { d  I | pI (d)  C I }
Rather than move on to implementation right away, our experience indicates that it is
easier to first describe the deductions to be performed in a more concise manner: through
rules of inference. Based on empirical evidence, we see these rules of inference as being
naturally grouped into several categories4
 Rules dealing with just one constructor, Q.
 Normalizing the arguments of Q, if these are themselves composite objects.
C  D
all(p, C)  all(p, D)

 Reasoning only with concepts of the form Q(args).
 When is such a concept incoherent by itself?
all(p, C) is never incoherent.
 When is such a concept equivalent to the entire domain of values?
all(p, thing)  any-object
 When does Q(arg1) subsume Q(arg2) in terms of arg1 and arg2? (The socalled structural subsumption relationship.)
C = D
all(p, C) = all(p, D)
4. In each case, we give a general description of what is desired for a new constructor Q, and then illustrate
it with the specific constructor all.

409

fiBorgida

 When does Q(arg) entail some description built with some other constructor?
all(p, nothing)  at-most(0, p)
 Reasoning with conjunctions of descriptions built with Q only. This usually
results in a normal-form that either combines the arguments into a single one,
or keeps the arguments as a list, set or multi-set.
and(all(p, C), all(p, D))  all(p, and(C, D))
 Rules of inference dealing with combinations of several concept constructors. These
rules can be grouped into similar families as above, except that they will involve two
or more kinds of constructors.
Since there is no such rule involving all, we offer an alternative example:
and(at-most(n, p), at-least(m, p))  nothing if n<m
The augmented set of inference rules should be proven sound and complete with respect
to the semantics specified earlier. As with any logic, soundness is relatively easy to show, but
completeness is much harder. Royer and Quantz propose one approach (Royer & Quantz,
1992) for generating inference rules that are complete, based on translation to First Order
Logic, but the technique is not easy to apply.
(3) Extend the implementation. This requires first determining an appropriate normal
form for the argument of constructor Q, declaring a data structure to hold the information,
and completing the put Q and get Q procedures to access them from a normalized concept.
For simplicity, we will not address detailed data structure issues here; instead, we use a
simple notation based on terms in the style of Prolog to represent data structures. In the
case of all, the representation is just a pair all(<Role>,<NormalizedConcept>). We
note that if we wanted to keep track of the original form of the concept (so it can be printed
out to users as entered), this could be added as an extra field of the data structure. We
emphasize that the normalized form of the description (e.g., a finite automaton) might not
even resemble the original syntax (e.g., a regular expression), though in our examples this
will not be the case.
Next, we need to implement the three procedures: Q::Normalize,Q::Conjoin, and
Q::Subsumes?, whose invocation is orchestrated by the corresponding functions for the
and constructor.
By analyzing the normalization algorithms for numerous constructors, we have arrived at
a more refined understanding of the prototypical Q::Conjoin procedure. This is presented
in the Appendix A as Figure 3, and uses the following other, smaller functions
Q::Universal? , Q::Incoherent? , Q::SubsumesSame? , Q::ConjoinToSame ,
Q::IncoherentWDifferent? , Q::SubsumesDifferent? , Q::ConjoinToDifferent ,
Q::FindOtherImplications .
These functions correspond to the categories of inference rules we have mentioned above.
When this decomposition can be applied, it provides two advantages: improved chances of
correct implementation by making smaller, specialized modules; and independent reuse, as
in
410

fiExtensible DL Representation and Reasoning

Q::Subsumes?(T:<NormalizedQ-Term>, lower:<NormalizedConcept>)

returns <Bool>
{if not Q::SubsumesSame?(T,get Q(lower)) then return false;
if not Q::SubsumesDifferent?(T,lower) then return false;
return true; }
Of course, if a specific constructor does not need to implement some of these subprocedures, the corresponding lines from the generic implementations are omitted, in order
to avoid the cost of useless function invocations.
For our simple example, when Q=all, all::Normalize(all(role,vr)) returns
all(role, and::Normalize(vr)).
If the only other constructor is at-most, the following functions used by all:Conjoin
and all::Subsumes? are needed:
 Q::Universal?(T): Is T equivalent to the top of the hierarchy for that set of values?
all::Universal?(all(role,vr)) returns true when vr is NormalFormthing.
 Q::SubsumesSame?(T,OldTs): Is T implied by the Q-constructed terms already seen
in oldTs? This is basically the structural subsumption algorithm.
all::SubsumesSame?(all(role,vr1),all(role,vr2)) would return true iff
and::Subsumes?(vr1,vr2) returns true.
 Q::ConjoinToSame(T,OldTs): Merge T with any preceding terms built with Q.
all::ConjoinToSame(all(role,vr1),all(role,vr2)) returns
all(role,and::Conjoin(vr1,vr2)).
 Q::FindOtherImplications(T,This,ImplicationsToDoList): If any additional
constructors have to be added because of Q, put them onto the ImplicationsToDoList.
all::FindOtherImplications adds to ImplicationsToDoList the description
at-most(0,role) if its first argument is all(role,nothing).
Once the Conjoin, Normalize and Subsumes? functions are implemented for the new
constructor Q, the corresponding functions for and need to have lines added to invoke
them according to the pattern presented in the preceding section (unless the programming
language is highly polymorphic).
Next, we use reasoning about dates, an extension desired in some classic applications,
to give a more complex example of the methodology for building extensions of protodl.
3.3 Dates: An Example Concept-Level Extension
We imagine an application where there will be individual dates as values of attributes or
even roles, and that concepts will describe collections of dates, specified in various ways
(e.g., as ranges or periods).
To begin with, it is important to clarify what the individuals look like about which
information will be kept. In the case of dates, we know that we wish to treat them as
temporal points, which have associated information about the year, month and day when
that date occurs. Given a date d, the above components will be referred to as year(d),
411

fiBorgida

month(d), day(d). There are two different ways of thinking of a date: as an abstract
mathematical value (e.g., a triple of integers) or as an individual object with attributes for
year, month, day. The last approach has the disadvantage that we need to develop a
separate theory of identity for dates (two dates are supposed to be identical if they have
the same components), although it has the advantage of allowing incomplete information
about the exact occurrence of a time point. Since this feature is not desired, we will adopt
the first approach, for convenience writing date individuals as 1996/7/25. In addition, we
will have the usual total (reflexive) order  on dates, as well as two special date constants,
BeginTime and EndTime, such that BeginTime  d  EndTime for all dates d.
We are now ready to introduce concept-forming operators for dates which are useful for
our application. First, when introducing a new kind of value, it is useful to define a top
concept, which will contain all such values. In our case, let us call it any-date.
One obvious grouping of dates is by ranges: between June 1st and August 31, 1996.
We might thus propose a concept constructor dateRange, which takes as argument a pair of
dates, denoting the ends of the range, e.g., dateRange(1996/6/1,1996/8/31). But since
the base language does not support disjunction, and we want to allow descriptions such as
the summers of 1995 and 1996, we will in fact have dateRange take as argument a set
of date pairs, as in dateRange({(1995/6/1,1995/8/31) , (1996/6/1,1996/8/31)}).
Having established the syntax of the concept constructors, and then implemented dateRange::Parse, we present its denotational semantics:
dateRange(SD)I = { d | b, e.(b, e)  SD such that b  d  e }
Next, we look for inference rules describing the desired reasoning for dateRange. Following the heuristics in Section 3.2, we come up with Table 3.
To implement the inferences for dateRange, we must find a normal form and write functions dateRange::Normalize, dateRange::Conjoin and dateRange::Subsumes?, or
their components.
It is useful to determine first the structural subsumption function, dateRange::SubsumesSame?, since this drives the requirements for the others. In our case, the obvious
representation works fine: a date is some data structure, such as a list of three values or
a record with three fields; a single date-pair is a list of two values or a record with two
fields; and the set of date-pairs making up the disjunction is just a list of date-pairs. It is
best to encapsulate the above implementation choices using abstract data types for Date,
DatePair and DateRange, with appropriate accessor functions and constructors. We must
also extend the representation of normalized concepts to implement put dateRange and
get dateRange.
Returning to dateRange::SubsumesSame?, this function now simply implements the
subsumption inference rules above
dateRange::SubsumesSame?(high,low : <SET(DateDate)> ): returns <Bool>
{for every (b,e) in low
find (b,e) in high such that b  b  e  e;
}

412

fiExtensible DL Representation and Reasoning

Universal

dateRange({(BeginTime,EndTime)})  any-date

Incoherent

dateRange({})  nothing

Subsumption

b1  b2  e2  e1
dateRange({(b2,e2)}) = dateRange({(b1,e1)})
dateRange(1 ) = dateRange(2)
dateRange(1) = dateRange(2 )
dateRange(1  1) = dateRange(2  2)

Conjunction

and(dateRange({(b2,e2)}), dateRange({(b1,e1)})) 
dateRange({ (max(b1,b2),min(e1,e2))})
and(dateRange(),dateRange(1))  dateRange(1)
and(dateRange(),dateRange(2))  dateRange(2)
and( dateRange(), dateRange(1  2))  dateRange(1  2)

Normalize

e  (b + 1 day)
dateRange({(b,e),})  dateRange({})
b1  b2  (e1 + 1 day)  e2
dateRange({(b1,e1),(b2,e2)})  dateRange({(b1,e2)})

Table 3: Inference rules for dateRange.

dateRange::Normalize verifies (if not already done so) that the dates b and e in
each pair (b,e) are valid according to our usual calendar, and that b  e. Any pairs not
satisfying these conditions are eliminated. It also needs to merge overlapping or adjacent
intervals into maximally long ones, since otherwise the above subsumption algorithm will not
recognize that dateRange({(1996/1/2,1996/1/4), (1996/1/5,1996/1/6)}) subsumes
dateRange({1996/1/2, 1996/1/6}).
The function dateRange::Conjoin has the standard implementation (see Appendix
A), but only functions dateRange::Universal?, dateRange::Incoherent?, dateRange::ConjoinToSame and dateRange::SubsumesSame? need to be implemented, performing
exactly the actions specified by the rules of inference.
Consider now adding another concept constructor for dates, to help represent periodic
time, such as every summer or every Christmas. A single period is just a range constraint on the possible values for the components of a date, other than year. So, summer
days would be represented by [(6 . 8) (1 . 31)], while Christmas would be [(12 . 12)
(25 . 25)]. For the sake of brevity, this new period constructor will take as argument
only a single period (rather than a set of them, interpreted disjunctively) and we will only
sketch the implementation extensions. Also not presented here, is a very useful extension to
413

fiBorgida

Universal

period([(1 . 12) (1 . 31)])  any-date

Incoherent

not( bm  em and bd  ed )
period([(bm.em) (bd.ed)])  nothing

Subsumption

bm1  bm2  em2  em1 and bd1  bd2  ed2  ed1
period([(bm2.em2)(bd2.ed2)]) = period([(bm1.em1)(bd1.ed1)])

Conjunction

and(period([(bm1.em1)(bd1.ed1)]), period([(bm2.em2)(bd2.ed2)]))

period([(max(bm1,bm2) . min(em1,em2))
(max(bd1,bd2) . min(ed1,ed2))])

Table 4: Inference rules for period.
periods allowing constraints on the days of the week, such as every Saturday to Sunday,
or even every 3rd Sunday.
The denotation of period terms is also quite simple:
period([(m1.m2)(d1.d2)])I = {e | m1  month(e)  m2, d1  day(e)  d2}
The rules of inference for reasoning about period concepts alone, presented in Table 4
are also straightforward. The implementation of most functions follows immediately from
the rules of inference.
The interesting reasoning involves the conjunction of ranges with periods. These rules,
appearing in Figure 5, can be expressed most succinctly by showing how certain periods
are either eliminated or retained unchanged, and then relying on the dateRange normalization rule, applied in reverse, to cut up a range into appropriate strips. These inference
rules imply that we need to also implement period::ConjoinToDifferent (p:<Period>,
other:<NormalizedConcept>), which basically uses the period as a cookie cutter to
create the sub-interval ranges that satisfy the periods restriction. Of course, this will
be done procedurally in a manner more efficient than suggested by the rules of inference.
Moreover, we must now revisit the implementation of dateRange, to put in a similar dateRange::ConjoinToDifferent function, since a concept with a range may be conjoined
onto one that already has a period in it.
Finally, in the presence of both dateRange and period constructors, structural subsumption is not enough, since we want period([(4 . 4) (1 . 31)]) to subsume dateRange((1988/4/1, 1988/4/21)), but not dateRange((1990/4/1, 1992/4/1)), and
there is no finite normal form which would list all the ranges satisfying a period. So we need
to also write the function period::Subsumes Different?(p:<Period>, lower:<NormalizedConcept>), which checks every interval (b,e) in get dateRange(lower) to make
sure that year(b)=year(e) and that the month and day meet the conditions of the period.
An interesting complication arises because dates are discrete, and hence one can count
the number of dates in a dateRange. If dateRange can appear as the value restriction
414

fiExtensible DL Representation and Reasoning

and(dateRange(  ), period())

and(and(dateRange(), period()), and(dateRange(), period()))
bm  month(dt1) = month(dt2)  em and
bd  day(dt1)  day(dt2)  ed
and( dateRange({ (dt1,dt2) }) , period([(bm.em),(bd.ed)]) )

dateRange({ (dt1,dt2) })
month(dt1)=month(dt2) and
not (bm  month(dt1)  em and bd  day(dt1)  day(dt2)  ed )
and( dateRange({(dt1,dt2)}) , period([(bm.em),(bd.ed)]) )  nothing

Table 5: Inference rules for conjoining period and dateRange.
of general roles, as in all(freeForMeeting, dateRange({(1995/6/1,1996/6/5)})) attributes, there is no problem. Otherwise, we can however infer cardinality constraints on
the number of fillers: dateRange({(1995/6/1,1996/6/5)}) allows only 5 different values. In a language that supports constructor at-most, we would therefore have to conclude
at-most(5,freeForMeeting). The implementation achieves this by introducing a helper
function dateRange::countDays, which can be applied to a normalized dateRange object; then, function all::FindOtherImplications needs to be modified, so that it invokes
dateRange::countDays on its value restriction if it is of date type, and a normalized
at-most restriction is posted for that role on the ImplicationsToDoList. Later processing of that list will remove the at-most constraint and conjoin it onto the concept.
3.4 Experience with Extensions
As part of the development of the above architecture, we have considered extending the
original core with the constructors of classic (all, at-least, at-most, fills, one-of, integer
ranges), as well as primitive concept negation, and the negation of fills. In these cases we
have reproduced the inferences of classic and almost exactly the internal actions of the
classic implementation; i.e., we perform only a few more checks despite the fact that our
implementation is made up of standard modules for each constructor.
Two kinds of concept constructors seem difficult to add to a normalize-compare algorithm in a way that preserves completeness of reasoning and the architecture of the system.
Disjunction would most naturally be handled if there was a disjunctive normal form, where
each disjunct is purely conjunctive. This is difficult to achieve with nested disjunctions
(inside all restrictions say). Note that we had no problem with the one-level disjunction in
dateRange.
A second kind of construct that is difficult to add efficiently and completely is same-as.
The reason here is that same-as interacts with all in a way that generates a potentially infinite number of all restrictions; therefore, the implementation of same-as is best combined
415

fiBorgida

with that of all, resulting in a non-tree data structure (Borgida & Patel-Schneider, 1994).
A speculative way to preserve structural subsumption might be to allow all to apply to
chains of a attributes represented by regular expressions. (In general, the complications of
implementing same-as are the reason it does not appear in C-classic and neo-classic.)
Finally, as mentioned earlier, we do not currently cover role constructors and recursive
concept constraints. Furthermore, constructors that require entirely new deductive mechanism (e.g., epistemic reasoning, defaults, forward-chaining rules) will also have difficulty
being integrated properly into this framework.
On the positive side, we have considered extensions supporting strings (Borgida, Isbell,
& McGuinness, 1996), and most elaborately, a reconstruction of the clasp reasoner about
actions and plans (Borgida, 1992b). To summarize this success briefly, clasp (Devanbu &
Litman, 1996) was a system built on top of classic for reasoning about actions (which were
represented in propositional STRIPS-style, having concepts for pre- and post-conditions, as
well as add and delete lists); plans were represented by regular expressions of actions, as
illustrated below. Our goal was to apply the protodl approach to clasp, hoping to
be able to reproduce the original, custom-made implementation discussed by Devanbu and
Litman (Devanbu & Litman, 1996). First, we introduced a concept constructor for actions,
act(P reC, P ostC, AddC, DeleteC), with the expected logical properties expressed as rules
of inference in the various categories (e.g., if P reC was incoherent, then the action was also
incoherent). The implementation then followed immediately.
The more interesting problem was dealing with plans. The constructors single, seq,
loop, and altern can be used to build complex plans from actions, as in seq( single(DIAL),
loop(single(RING))). These plans denote sequences of action instances (e.g., in the above
example, a dialing action followed by any number of rings). Although we provided rules
of inference for plans too, it turns out that there is no normal form for regular expressions! Instead, in the implementation, Normalize for seq, altern and loop built a nondeterministic finite automaton, which then had to be made deterministic, and in which
certain chains of arcs had to be removed (if the post-condition of the action on the incoming edge was inconsistent with the pre-condition of the action on the outgoing edge).
Moreover, the containment algorithm for these finite automata had to take into account
the fact that actions on transitions (e.g., MOVE) may represent generalizations of others (e.g., MOVE-FAST). This implementation was achieved in protodl by introducing a
hidden concept constructor, top-plan-exp, which enclosed the top plan. It was then
top-plan-exp::Normalize that made the automaton deterministic and removed some
transitions, and top-plan-exp::Subsumes? that implemented the special subsumption algorithm. Moreover, the requirement to implement top-plan-exp::Conjoin, which was not
present in the original clasp system, made us realize that without this, clasp plans could
not appear in other concepts, because expressions like and(all(p,PLAN1), all(p,PLAN2))
could not be normalized. As a result we believe we reconstructed and improved the original
clasp proposal, by characterizing the inferences performed through rules of inference, and
by allowing plans to be first-class values, which could appear in ordinary roles.
416

fiExtensible DL Representation and Reasoning

3.5 Relationship to Concrete Domain Extensions
Although we shall address general work on extensible KR&R in the conclusion, there is
one specific approach involving description logics that deserves closer scrutiny at this stage,
while the details of the present work are still fresh.
Baader and Hanschkes proposal (Baader & Hanschke, 1991) for extending DLs with
concrete domains allows concepts to consist of arbitrary predicates involving values from
some domain other than ordinary objects (i.e., other than elements of I ), as long as
these values are fillers of attributes of ordinary objects. For example, suppose the concrete
domain is that of dates; as above, we have predicates like BEF ORE, corresponding to
 ; then, if we had two date-valued attributes arrival and departure, we could define
the concept BEFORE(arrival,departure), denoting ordinary objects (not sets of dates!)
whose attributes have appropriately related date values.
In order to keep reasoning decidable, this mechanism requires the concrete domain to
be admissible: (i) there must be a predicate denoting the universe of all values in that
concrete domain; (ii) the set of predicates must be closed under negation; and (iii) it must
be possible to decide the satisfiability of any finite conjunction of such predicates. It is
interesting to note that these requirements match in part our heuristics for new concept
constructors: we also argued for the need to add a top concept to the hierarchy of new values
(and its negation, the bottom of this hierarchy), and for the need to be able to compute
the conjunction of descriptions.
The admissibility of a concrete domain ensures that the protodl approach can implement any such extension as follows: Syntactically, a domain corresponds to a concept
constructor. Therefore, a concept like BEFORE(arrival,departure) in the domain DATE,
would be represented in protodl as DATE(BEFORE,arrival,departure). Then, the
necessary protodl functions are programmed as follows: DATE::Normalize tests that
the predication is satisfiable (otherwise signaling IncoherentExn), and creates a singleton
list containing the predication; DATE::Conjoin concatenates the list of predications of
its arguments, checking for the consistency of their conjunction; DATE::Subsumes?(C,D)
creates the conjunction of all the predicates in C, and their negation in D, and returns true
if the result is unsatisfiable.
Conversely, Baader and Hanschkes approach could well be applied to date ranges, since
these are essentially closed under negation. And since it is offered in the context of the
tableau theorem-proving technique mentioned in Section 2.4, this continues to have the
advantages of elegance and complete reasoning, as long as the concrete domain reasoner is
proven complete. In our case, the entire system would have to be proven complete.
We believe though that protodl is somewhat more general, since it allows concrete
domains to be value of roles, not just attributes (see our earlier discussion of dates as values
of roles). Also, there is some advantage to being able to deal with non-admissible domains
in cases when negation is not absolutely needed, but its addition would cause an increase in
computational complexity; for example, adding negation/complement to regular expressions
makes the containment problem non-elementary (Stockmeyer, 1974).
417

fiBorgida

4. Processing of Individuals in DLs: An Introduction
Concept descriptions, as introduced above, are intensional objects, suited for capturing
generic information about a domain, such as the ontology of terms. DL-KBMSs must also
manage extensional/factual information about individual objects  the so-called A-box5 .
4.1 Inferences Involving Individuals
Normally, one can assert information such as the fact that some object Anni is known to
be an instance of a concept CHILD (written as Anni:CHILD), or that it has some other
object, Lego as a filler for its hasToys role (written as (Anni,Lego):hasToys). Based
on this information, the KBMS can deduce information about the individuals membership in other descriptions (written using  ); for example, in this case we know Anni
 at-least(1,hasToys). Because DL-KBMS usually do not make the closed-world assumption, it is also necessary to record when some set of fillers is complete for an individuals
role. This is done using an (auto-epistemic) assertion like
Anni:allFillersKnown(hasToys,{Lego,Barbie}). As a result of such an assertion, we
can then deduce that Anni  at-most(2,hasToys). (Note that we have distinguished
the three kinds of assertions in A, namely b : C, (b, e) : p, b : allFillersKnown(p, S), from
the corresponding judgements that can be deduced in the logic: b  C, b  fills(p,e),
b  closedFillers(p,S).)
Information about fillers and roles being closed (i.e., all fillers being known) can also be
deduced, as in the case of the KB that contains A={Lori:all(hasToys,one-of(Lego45)),
Lori:at-least(1, hasToys)}, from which we can conclude that Lego45 is a toy owned by
Lori (written as Lori  fills(hasToys,Lego45)) and that the complete set of fillers for
hasToys is { Lego45 } (written as Lori  closedFillers(hasToys,{ Lego45 })). We
note that an elegant formalization of these notions has been obtained by adding an epistemic
modal constructor K to DLs (Donini et al., 1998). This constructor has a number of other
uses, but to shorten the presentation we have not introduced it here explicitly.
Formally, we define a knowledge base KB to be a concept knowledge base CKB, extended
with a set A of assertions of the form b : C, (b, e) : p and b : allFillersKnown(p, S),
where S is some set of individuals. An interpretation I is said to be a model for b : C if
bI  C I , a model for (b, e) : p if eI  pI (bI ), and a model for b : allFillersKnown(p, S) if
(eI  pI (bI )  e  S)6.
The judgment KB |= b  C holds iff for every model I of KB, bI  C I ; the judgement KB |= b  fills(p, e) holds iff for every model I of KB, (bI , eI )  pI ; finally,
KB |= b  closedFillers(p, S) holds iff KB |= b  fills(p, bi) for every bi  S, and
for every other individual e not in S, there is some interpretation I of KB such that
6 KB |= b  fills(p, e) . Because our concept language may not have negation, and because
we have the open world assumption, we also need to be able to talk about non-membership
in a concept: b 6 C; naturally, KB |= b 6 C iff for some model I of KB, bI 6 C I . As
usual, a KB will be called inconsistent iff it has no models.
5. The most thorough theoretical investigation of individual reasoning has been presented in Andrea
Schaerfs PhD thesis and derived publications (Schaerf, 1994). We note however that for some of the
most expressive DLs proposed recently, individual reasoning has not yet been addressed.
6. As usual, we make the unique-name assumption, and in fact include named individuals in the domain

418

fiExtensible DL Representation and Reasoning

The specification of reasoning about individuals can again be represented by inference
rules (Borgida, 1992a). For example, for the constructor all, we proffer the following three
rules of inference, which describe the structural membership/non-membership rules, as
well as a kind of inference called propagation, where information about some individual
b results in new information being deduced about another individual e:
KB ` b  closedFillers(p,S)
KB ` bi  C
KB ` b  all(p,C)

S = {b1,    , bn}, n  0

KB ` b  fills(p,e)
KB ` e 6 C
KB ` b 6 all(p,C)
KB ` b  all(p,C)
KB ` b  fills(p,e)
KB ` e  C

Note that for an inconsistent KB, we can have KB ` b  nothing, or we can deduce
information from fillers (e.g., KB ` b  at-least(3,pets)) that contradicts information
asserted or deduced from descriptors (e.g., KB ` b  at-most(2,pets)).
4.2 DL-KBMS Operations on Individuals
The point of living with the open-world assumption is to allow information to be accumulated incrementally, as in the case of designing some artifact (one of the most successful
applications of classic).
From the functional point of view, the DL-KBMS therefore supports the following update operations for incrementally adding information about individuals:
Operation
assert-member(b, C)
assert-fills(b, p, b1)
assert-closed(b, p)

Effect
b : C is added to A
(b, b1) : p is added to A
b:allFillersKnown(p,S) is added to A, where S is
the set of individuals returned in the current KB by the
operation ask-for-fillers(b, p), defined below.

If as a result of the update, the KB is inconsistent, then the update is rejected and the
state of the KB is supposed to remain unchanged.
At any point, the KBMS is able to respond to inquiry operations about relationships
involving individuals:
Question
ask-member?(b, C)
ask-non-member?(b, C)
ask-for-fillers(b, p)

Answer type
Boolean
Boolean
SET(Individual)

ask-closed?(b, p)

Boolean

Response
true iff KB |= b  C
true iff KB |= b 6 C
{ e | KB |= b  fills(p, e) }
true iff for some set S
KB |= b  closedFillers(p, S)

As with concepts, many DL-KBMS pre-compute the b  C judgment, for all individual
and concept names, by finding the most specific named descriptions to which the individual
b provably belongs. Similarly, the DL-KBMS pre-computes and caches the fillers and closed
419

fiBorgida

information for each individuals roles. This is done in order to detect inconsistencies at the
time of the update, to decrease the amortized cost in case queries are much more frequent
than updates, and to support queries of the form What additional information can you
deduce about v?. The utility of such queries has been shown, among others, in applications
involving information discovery in software development (Devanbu, 1994).

5. Individuals in protodl
Reasoning about individuals The goal of our implementation is to support efficiently the
update operations, which are incremental, so that most of the inferences are precomputed:
for each individual, we know the least classes it is an instance of, all the fillers it can have
for each role, and whether the role is closed or not for that individual. The architecture
below describes an extension and rationalization of the individual processing that is usually
carried out in normalize-compare DL-KBMS such as classic. The novelty will be the
systematic separation of the interaction between various kinds of updates and various kinds
of inferences, and the concomitant use of truth-maintenance links.
5.1 The Basic Architecture of Individual Reasoning
In some systems, one can try to reduce individual reasoning to concept reasoning by associating some single, maximally complete description with each individual. However, this is
not always possible, as shown by Schaerf (Schaerf, 1994).
Instead, our data structure for every individual includes both a concept description (to
be called Descriptor), which may be an existing class or an unnamed complex description, and individual role-filler information recording the specific values assigned so far, and
whether the role is closed or not. (This information is accessed with built-in functions
add filler, put closed, get fillers and is closed?.)
In processing an update about some individual b, we must therefore resort to two
kinds of reasoning: (i) subsumption/incoherence reasoning involving only the description
Descriptor(b) and other concepts; (ii) reasoning specific to the individual and especially
its role fillers.
The former kind of reasoning is motivated by general inference rules connecting membership and subsumption (e.g., if b  C and C = D then b  D). Since subsumption
and its extensibility has been described in the preceding section, henceforth we concentrate
on the second aspect of individual reasoning.
To understand the tasks involved, let us illustrate what kinds of reasoning need to be
performed whenever any fact is asserted (or inferred) about an individual b
 The KB may become inconsistent, because of a conflict between the individual descriptor and the filler information either on b or some other individual. For example,
more fillers might be added to a role than permitted by an at-most restriction. This
requires the entire update to be rejected. Note that an update may result in several
individuals with inconsistent information on them. The system is only required to
detect one of them, before rejecting the update.
420

fiExtensible DL Representation and Reasoning

 The individual b may end up being re-classified. In a monotonic system, such as the
present one, this means that the individual may now belong to some more specialized
class(es) in the hierarchy.
 New information about the roles of individual b can be inferred. For example, learning
that a role is closed allows us to now count its fillers and hence obtain an exact upper
bound recordable by at-most.
 New assertions can be inferred about other individuals, usually ones related to b via
roles. For example, if an all(friends,HAPPY) description applies to some individual
x, and now y is asserted to be a friends-filler for x, then we can infer that y is an
instance of HAPPY.
To support the first task above, protodl might use the function ConsistentW?7, which
returns true to indicate that information to be added to an individual is consistent. For
the second task, we use function Recognizes?. For the third and fourth tasks, which
involve individuals other than the one on which the update has occured, we use function
InferFrom.
These functions are used to implement the various assert KBMS operations, as well
as the ClassifyIndividual function, which is used by protodl to find the lowest classes
in the hierarchy to which this individual belongs.
As in the case of concept reasoning, we use the and constructor to drive the processing,
and we modularize the implementation so each kind of constructor Q has its own set of functions: Q::Recognizes? , Q::ConsistentW? , Q::InferFrom . It now becomes more
important to distinguish constructors, like all and at-most, that have an associated single
role, in contrast to generic constructors such as one-of (which has no roles associated) and
same-as (which has many roles, none of which is special). For the former, so called branch
constructors, the above functions will have arguments that include not just the individual
and the normalized representation of Q-terms, but also the fillers and closed information
about the role. (This is done to prevent repeated retrieval of these values by each such
constructor.) Therefore, the general form of and::Recognizes?, provided in protodl, is
and::Recognizes?(b:<Individual>,NC:<NormalizedConcept>)returns <Bool>
{ For every Q(T) in getNonbranchComponents(NC) do
if not Q::Recognizes?(b,Q(T)) then return false;
For every role p in getRestrictedRoles(NC) do
{F:= get fillers(b,p);
clsd? := is closed?(b,p);
For every Q(T) in getBranchComponents(NC,p)
{if not Q::Recognizes?(b,Q(T),F,clsd?)
then return false};};
return true; }
7. Later, when we introduce incremental reasoning, we will identify a number of variants of this function.

421

fiBorgida

The functions and::ConsistentW? and and::InferFrom are similar in structure, and
are not presented due to space limitations. It is important to note that the ConsistentW?
functions return false only to indicate that they are unable to prove conclusively that the
individual is consistent or inconsistent; if an inconsistency is found, an InconsistentExcn
is raised. Also, after an update there may be several individuals about which incompatible
information will be asserted. The system only guarantees to find one such case, and then
rejects the update.
The following is an example of a specialized function for the case Q=all, which implements the first inference rule presented earlier
all::Recognizes?(b:<Individual>, all(r:<Role>,vr:<NormalizedConcept>),
fillers:<SET(Individual)>, clsd?:<Bool>) returns <Bool>
{if not clsd? then return false
/*More fillers might come later*/
else for every f in fillers do
{if not and::Recognizes?(f,vr)
then return false;}
return true }

5.2 Reasoning with Incremental Updates
Since updates to individuals are incremental in nature, in order to improve efficiency we
want to take into account the fact that the KBMS had already performed all the inferences
up to, but not including, the current update. For example, if some individual Tintin has
been asserted to be an instance of all(pet,DOG), and already has pet-fillers d1 and d2, then
if the current update is assert-fills(Tintin,pet,Fido), then we only need to propagate
the information that pet-fillers are DOGs to Fido, since the others would have been processed
earlier. And, if the current update is assert-closed(Tintin,pet), then no new role-filler
information can be inferred from this because of the all restriction, so we should not even
bother calling all::InferFrom. We will therefore distinguish the following three variants
of Q::InferFrom:
Q::InferFromFilling(<Individual>,<NormalizedQ-term>,<Role>,<Individual>)
Q::InferFromClosing(<Individual>,<NormalizedQ-term>,<Role>) , and
Q::InferFromAsserting(<Individual>,<NormalizedQ-Term>)

plus similar variants of Q::ConsistentW?. For example
 all:ConsistentWFilling?(ind, all(r,vr), r, newfiller) invokes and::ConsistentWAsserting?(newfiller,vr) to check that the new filler does not contradict the
role restriction vr;
 all::ConsistentWClosing?(ind,all(r,vr),r) just returns true, and hence is hopefully eliminated by the compiler;
422

fiExtensible DL Representation and Reasoning

 all::ConsistentWAsserting?(ind,all(r,vr)) verifies that all r-fillers y of ind are
consistent with vr by invoking and::ConsistentWAsserting?(y,vr).
One might also consider variants of Q::Recognizes?, but, as we shall see, in our case
these are of limited use since we do not propose to keep information on which parts of the
recognition test had succeeded already, and therefore we need to start from the beginning.
5.3 Dependency Links
Clearly, the results of function calls, such as Recognizes?, on some individual Bob might
change after an update to Bob itself. However, the membership of Bob in a class or Bobs
consistency may depend on facts asserted about other individuals in the database. For
example, if all of Bobs friends are known (i.e., the role friends is closed), and all but
one of them was MARRIED, and now that holdout, Larry, is also asserted or inferred to be
MARRIED, then Bob itself can be reclassified as an instance of all(friends,MARRIED).
This means that without some special data structure, after every update of some individual an unsophisticated implementation has to reconsider every other individual in the
KB.
One alternative, used in loom (MacGregor, 1986), is to keep track of all questions asked
about an individual as part of the previous processing (hits and misses), and if answers
to these do not change as a result of the update then no re-processing is needed. Another
alternative is to use an elaborate truth-maintenance system (as available in kl-two (Vilain,
1985)), for each kind of judgment. In our opinion, both these approaches might however
become very expensive in terms of space and often computation time, because they maintain
too many details.
We follow an intermediate stance, first suggested by Peter Patel-Schneider for the classic implementation, which is intended to reduce needless re-testing while incurring relatively less dependency maintenance overhead. Essentially, we have a coarse-grained
dependency structure, where one individual e may point to another, b, if the result of
a decision about the latter may change as a result of some (unspecified) additional information being added to the former. For example, in the presence of the definition
.
CanineLover=all(pet,DOG), if Tintin has Fido as a pet filler, and neither Recognizes?(Fido,DOG) nor not ConsistentW?(Fido,DOG) return true, then we add a link
 Tintin. Thereafter, any change of status of Fido will
of the form: Fido RecognizeDependsOnMe
cause Tintins classification (with respect to CanineLover, as well as other pending classes)


to be re-done. Similarly, we will have 
ConsistentDependsOnMe and InferDependsOnMe links between
objects.
Note that when following such dependency links back, we do know that only properties
of the fillers of some role might have changed, so that once again we could have variants
and::RecheckConsistentW? and and::RedoInferFrom, which perform less work by omitting the checks involving constructors that are known not to be affected by such aspects
(e.g., at-most only cares about the count of the fillers, not their properties).
In order to set dependency links, every function such as Q::Recognizes? needs to
keep track of the list of individuals whose modification might change the result of the
function. These values must eventually be appropriately linked with dependencies either
by the functions themselves or by the calling environment.
423

fiBorgida

5.4 Coordinating the Components
As should be clear from the above examples, the task of the top-level KBMS update operations (asserts) will include not just invoking the appropriate functions on the individual
being updated, but also setting appropriate dependency links, gathering into queues other
objects whose dependency links have been tickled by the latest update, and then repeating these operations on the other individuals brought into focus by inferences or dependency
links.
An appropriate software architecture for representing this processing seems to be a
blackboard model, where we have 5 lists to which functions can post tasks to be carried
out:
 Two lists, ToRecheckConsistencyList, ToRedoInferFromList, for objects that are
reached from individual x via a corresponding kind of dependency link as a result of
a change to x.
 A list, ToPerformUpdateList, which collects the additional inferences to be made that
are found by the InferFrom and RedoInferFrom function calls. For simplicity, these
are recorded as additional calls to versions of the three kinds of assert functions.
 A list, ToReclassifyList, which receives objects that need to be checked in case
they can be classified further down the hierarchy; these objects come not just from
dependency links but also from any additional asserts that had been triggered.
 Finally, a list ToAddDependencyList, that keeps track of dependency links that need
to be added to the knowledge base; this list is augmented by the various functions, as
mentioned in the previous section.
Because, for example, re-classification may cause new inferences, which may cause reclassification due to some other constructor, there is no linear order in which these lists
can be processed. We may therefore have a loop where a demon removes an arbitrary
object from a list, invokes the required function, and then repeat the process. The only
requirement is that dependencies on ToAddDependencyList be also considered as having
been installed, whenever chasing objects that may have been affected by an update. Note
that, not surprisingly, it is hard to make any general statements about the termination of
the above algorithm skeleton, since the various functions, especially InferFrom. are free to
do whatever they want, including increasingly longer descriptions..
Several policies can help the performance of the system:
 In all cases, it is helpful to eliminate duplicates from the lists.
 Locality of context may improve performance; therefore grouping together operations
to be performed on one object is advisable (e.g., gather together all the dependencies
from object y on ToAddDependencyList).
 If we expect inconsistencies to arise infrequently, then the ToRecheckConsistencyList can be processed at the end.
424

fiExtensible DL Representation and Reasoning

assert-fills(ind, role, filler)
{if redundant information then signal RedundantExn;
add filler(ind,role,filler); /* this may be rolled back by an error */
initialize the blackboard lists to empty;
ind-descr := Descriptor(ind);
/* deal with consistency issues involving ind */
and::ConsistentWFilling?(ind, ind-descr, role, filler);
/* the preceding function will post dependencies if
the answer is not a definite TRUE */
ToRecheckConsistencyList += getConsistentDependsOnMe(ind);
/* this puts up for reconsideration objects
dependent on ind */
/* check for inferences */
and::InferFromFilling(ind,ind-descr,role,filler);
/* this may post new updates and/or dependencies */
ToRedoInferFromList += getInferDependsOnMe(ind)
/* reclassify at least this individual */
Reclassify(ind);
ToReclassifyList += getRecognizeDependsOnMe(ind);
/* Process tasks left on the blackboard */
ProcessBlackBoard;
}
catch InconsistentExcn
{roll back update; print error msg; }

Figure 2: protodl pseudo-code for assert-fills.
Figure 2 contains the pseudo-code for assert-fills, which is offered by protodl. Notice
the advantage in the above program of using exception handling and propagation up the
dynamic function call hierarchy as a way of dealing with inconsistency: wherever it is
detected by ConsistentW?, the exception passes up through levels of function calls, all of
which are interrupted, until a handler is encountered  usually by an external or internal
assert operation; this issues appropriate error messages, resets local changes made, and
then re-raises/propagates the exception further up, until the top level is reached.
5.5 Extending Individual Reasoning  An Example
Let us consider the extensions needed for a rather complex new concept constructor:
same-as. The semantics of same-as([f1 ,   , fn ],[g1,    , gm]), as introduced earlier, is
that it denotes individuals for which the two attribute chains [f1 ,    , fn ] and [g1,    , gm]
have the same known filler. (The attributes must each have exactly one filler.)
This constructor is very useful in representing the relationship between actions and subactions. For example, suppose we try to define the action of BUYing in terms of two GIVEs:
425

fiBorgida

we would assert that BUY is subsumed by and(all(giving1,GIVE),all(giving2,GIVE)),
and then add further constraints about the attributes of BUY (such as buyer and seller)
and those of GIVE (such as giver and receiver), including same-as([buyer],[giving1
giver]) and same-as( [seller],[giving1 receiver]).
The procedures that need to be written to extend the implementation are: same-as::Recognize, same-as::InferFromFilling, same-as::InferFromClosing, same-as::InferFromAsserting, same-as::ConsistentWFilling?, same-as::ConsistentW Closing?, and same-as::ConsistentWAsserting?. In addition, some previously written procedures may need to be augmented.
Rules of inference for  and 6 can be presented as a way of describing the tasks
performed by the above functions. However, in this case, the functions also need to worry
about dependency pointers, so the mapping is less direct.
The following inference rule describes the standard recognition procedure for individuals
(there are additional rules for subsumption of course):
KB ` b  fills([f1,    , fn ], e)
KB ` b  fills([g1,    , gm], e)
KB ` b  same-as([f1,    , fn ], [g1,    , gm])
If the recognition function can only follow a chain up to an individual e, which is missing
the filler of the next attribute in the chain, then a dependency from e must be recorded.
same-as::Recognizes?(b, same-as(chain1,chain2))
{ (e1,p) := follow chain1 from b, returning the furthest
individual e1 reached, and the remainder of the chain p
which was not possible to follow;
if not(p=nil)
 b; return false;}
then { post dependency e1 RecognizeDependsOnMe
(e2,q) := follow chain2 from b, as above;
if not(q=nil)
 b; return false;}
then { post dependency e2 RecognizeDependsOnMe
if (e1=e2) & p=q then return true else return false.
}
This function will be called from inside and::Recognizes?(b,C) as follows:
...
for every same-as(chn1,chn2) in get sameas(C)
if not same-as::Subsumes?(same-as(chn1,chn2), Descriptor(b))
then if not same-as::Recognizes?(b,same-as(chn1,chn2))
then return false.
...
Reasoning with same-as concerning individuals is actually more complex, because there
are additional rule of inference, such as
KB ` b  fills(chain1, e)
KB ` b  same-as(chain1, chain2)
KB ` e  same-as(chain3, chain4)
KB ` b  same-as(chain1  chain3, chain2  chain4)
426

fiExtensible DL Representation and Reasoning

Applying this rule straightforwardly to verify whether some b  same-as([f1,    , fn ],
[g1,    , gm]) requires one to try all possible ways of dividing up the chain [f1,    , fn ] into
subchains, and for each, one needs to try to derive the subchain equalities alternately from
individual fillers along the chain, or from explicit assertions of same-as descriptions on
individuals. In this cases, the implementor, in consultation with the knowledge engineer
who is to use the extended system, would make a judgment on the necessity of implementing
this more expensive inference. The rules of inference can be used to describe the deductions
that have been implemented and those that have not.
In order to check consistency, we need to consider the three kinds of updates: assertions,
fillers, and closings. When an equality is first asserted of an individual, we would invoke:
same-as:: ConsistentWAsserting?(ind, same-as(chain1,chain2))
{ (e1,p) := follow chain1 from ind;
if not(p=nil)
 ind; return true;}
then { post dependency e1 ConsistentDependsOnMe
(e2,q) := follow chain2 from ind;
if not(q=nil)
 ind; return true;}
then { post dependency e2 ConsistentDependsOnMe
if e1=e2 then return true else signal InconsistentExcn;
}
Since the attributes can have at most one value, these attributes get closed automatically
when a filler is provided, so there is usually no explicit closing of the role that can affect
same-as, and there is no need for same-as::ConsistentWClosing?.
Finally, if C includes as a conjunct same-as(chain1,chain2), then and::ConsistentWFilling?(ind,C,p,newfiller) will have to invoke
same-as::ConsistentWFilling?(ind,same-as(chain1,chain2),p,newfiller)
{if (member(p,chain1) OR member(p,chain2) )
then same-as:ConsistentWAsserting?(ind,same-as(chain1,chain2))}
Equalities can lead to inferences when one of the chains is completely known, and all
values but that of the last attribute on the second chain are known, as illustrated by the
following example:
{ a : same-as([q] , [p, r]), (a, e) : q, (a, b) : p } |= b  fills(r, e)
 links to watch for cases when we have
This inference requires us to set up InferDependsOnMe
sufficient information to make the inference.
We point out that same-as presents one example of a situation where a performance
penalty is paid for separating out consistency checking, recognition and inference: each of
these functions attempts to traverse the individuals along the two chains of the equality in
an effort to reach the ends. This price is negligible if there are relatively few individuals with
same-as conditions attached, or if the chains are usually only one or two attributes long, as
is the case for the application of same-as illustrated earlier. Otherwise, we can introduce
427

fiBorgida

caching to speed up the code: associate with every equality and individual b two pairs (e1,r1)
and (e2 ,r2) representing the ends ei reached on each chain, and the remainder of the chains
ri left to be traversed. (So if the chain is completely known, r = nil.) A final alternative is
to add the code for same-as::InferFrom into same-as::ConsistentW? function, so the
latter performs all the deductions involving same-as. The disadvantage of this approach,
as of many optimizations, is the loss of modularity.
Finally, we mention that other extensions of reasoning at the individual level that we
have considered include database aggregate functions like sum (e.g., sum([departments
budget], totalBudget) can be used to model that totalBudget is the sum of the values
for budget fillers for all department fillers); and epistemic constructors that allow one to
query the state of knowledge (Donini et al., 1998) (e.g., known-all(friends, knownat-most(1,pets)) recognizes individuals all of whose known friend fillers have at most
one pet recorded in the KB, without having to have the roles be closed).

6. Conclusions
We began from the hypothesis that no perfect DL will ever be built, because of the
need for application-specific reasoning, and potential incompleteness of reasoning due to
the expressiveness-(tractability/decidability) trade-off. We argued that some of these issues
are best attacked on a per-application basis. To resolve this problem, we proposed the use
of an extensible DL-KBMS, where one tries to go as far as possible with an initial set of wellunderstood concept constructors, and then, when encountering unsolvable expressiveness
problems (Doyle & Patil, 1991), add new concept constructors to overcome them.
We have also pointed out the limitations of this approach, which include not being
conducive to including new forms of reasoning such as abduction, contexts, etc., and having
difficulties with complete inferences for useful concept constructors that require reasoning
by contradiction, and are best handled in the alternative DL reasoning paradigm  tableaux.
6.1 Implementation Status
Prototype implementations of aspects of both concept and individual reasoning in protodl
have been carried out at Rutgers. However, experience with all fielded systems indicates
that there is an order of magnitude more work to be done in making a system usable by
others than their developers. For this reason, our goal is to add the results of the protodl
research to an existing DL-reasoner. In fact, several ideas have been transfered, with the
collaboration of Charles Isbell, to the newest version of the classic system released by
AT&T Research. In particular, classic supports test-defined concepts  ones which allow
the recognition of individuals through the use of an arbitrary LISP function. (This function
can be seen as the combination of the Recognizes? and ConsistentW? functions discussed
in the present paper.) In the newest version of classic, one can simulate the addition of
new concept constructors by using them after the keyword test-c. For example, the concept
all(vacation,dateRange(1996/6/1,1996/8/31)) would be represented as
(test-concept dateRange vacation ( (1996 6 1) (1996 8 31)) )
428

fiExtensible DL Representation and Reasoning

Although not all aspects of the protodl system have been implemented, the current
extensions (Borgida et al., 1996) allow significant subsumption reasoning to be done for test
extensions, and thus provide classic with the bases for extensible reasoning.
6.2 Related Work
In order to incorporate new concept constructors into a reasoner, we need to extend the
implementation. One approach to this would be to offer some form of declarative description of the inferences to be performed, and then have a meta-interpreter which executes
them. In fact, such approaches have been tried in the past for other kinds of representation formalisms (Greiner & Lenat, 1980; Genesereth, 1983). Except for cycl (Lenat &
Guha, 1990), which allows the addition of new forms of inference rule schemas in First
Order Predicate Calculus, we see little evidence that such a meta-interpreter has a chance
of being nearly as efficient as custom-built implementations, so we have opted for a different
approach.
Joshua (Rowley, Shrobe, & Cassels, 1986) is also an effort at providing extensible reasoning, which allows the user (knowledge system engineer) the ability to change at compile-time
the implementation of any or all of the elements of the protocol of inference, which describes
the reasoning of the system. Joshua is close in spirit to our work in the sense that it tries to
maintain a uniform knowledge level view of the system, and because it identifies, in the
protocol of inference, the specific aspects of the system that can be customized through
(re)programming of Lisp functions. Our efforts differ from Joshua in that we are interested
in DLs (Joshuas protocol was concerned mostly with rule triggering and truth maintenance), we wish to support incrementing the syntax of the knowledge-level interface, and
we also care about the semantics of the extension.
Gaines has also advocated the utility of a declarative specification and of a clean, extensible modularization for a DL-reasoner (Gaines, 1993). At the concept level, one difference
between our approaches seems to be that protodl only assumes that the concepts will
form an upper-semilattice (the and constructor is built-in), so that a wider variety of inferences can be implemented for new constructors. At the individual-reasoning level, protodl
starts from a much more restricted basis, and uses its extensibility to deal with such aspects
as propagations (e.g., our example dealing with same-as reasoning appears to be built-in
in KRSn). On the other hand, KRSn has built-in support for rules and exceptions to them,
which are an important component for any knowledge-based environment.
Finally, it has been suggested that the tableau-based approach, such as that of crack,
is essentially extensible through the addition of new completion rules (Bresciani et al.,
1995), which are traditionally used to build a model of a certain knowledge base, or prove its
inconsistency. These tableau completion rules can also implement incomplete reasoners by
using only a subset of the inferences. As with concrete domain extensions (Section 3.5), the
advantages of extensible tableau techniques lie in a clean formalism that can lead to complete
reasoning, while the disadvantages involve language extensions that do not have negation
(e.g., clasp  see Section 3.4), and, for the moment, the lack of experience with large
A-boxes and incremental updates. One of the most exciting (though very likely difficult)
future prospects is combining the two implementation paradigms, and their extensibility
features.
429

fiBorgida

6.3 Summary
We have advocated an approach to extensible DL reasoning and implementation, for the
normalize-compare paradigm, which has two components: a declarative specification and
a modularized implementation framework.
The specification is offered using rules of
inference in the natural semantics style, and a heuristic methodology suggests various
categories of rules to be looked for. These rules often correlate well with the implementations of the various functions, but protodl offers the implementor the opportunity to
use a very different implementation. The later is needed in the case of constructors whose
argument is for example some regular expression  as in the case of plans or strings, when
the implementation needs to use some kind of finite automaton representation, since regular
expressions have no normal form.
We have modularized the software architecture of protodl reasoner, so that for every
new concept constructor added to the language, there is a well-defined set of functions that
need to be implemented. These, in turn, sometime have detailed skeletons composed of
other, smaller functions, which we have abstracted after analyzing a variety of implementations. The invocation of these functions is organized by the built-in functions of protodl,
usually involving the constructor and. We have paid particular attention to supporting
efficient implementations, by offering the implementor quite a lot of freedom within the
confines of our major functions. For individual reasoning, this is the first paper to consider
the need to be efficient in the face of incremental updates of DL-KBMSs, which live with
the open-world assumption, and which use concept descriptions to infer new properties,
rather than just verify the correctness of individual facts. Our solutions involved proposing
function variants based on the form of the update, and the use of various kinds of associated
dependency links.
The major open areas involve adding to this framework role constructors, epistemic
rules (like those in classic, characterized by Donini et al (Donini et al., 1998)), the ability
to express at least simple recursive declarations for primitive concepts (e.g., the parents
of a person are persons), and connections with the tableau-based implementations for DL
reasoning.

Acknowledgements
I am very grateful to Ron Brachman, who, among others, joined me in the initial explorations of the protodl idea; to Daniel Kudenko, who implemented a significant part of
the individual reasoning; to Charles Isbell, who implemented the extensibility features of
classic 2.3; and to Peter Patel-Schneider, for years of discussion on the subtleties of the
classic language and implementation. Extremely useful comments on the presentation
and organization were provided by Peter Clark and the anonymous reviewers.
This work was supported in part by NSF grants IRI-91-19310 and IRI-9619979.

Appendix A. A Generic Conjunction Function.
The following pseudo-code for Q::Conjoin shows how one can construct this function from
several, smaller functions.
430

fiExtensible DL Representation and Reasoning

/* Conjoin the new term Q(T) onto the already-normalized description This*/
Q::Conjoin(T:<NormalizedQ-term>,This:<NormalizedConcept>){

old := get Q(This) /* find the part of This dealing with constructor Q*/
if not(old=nil)
then if Q::SubsumesSame?(T,old)
then signal RedundantExn;
T := Q::ConjoinToSame(T,old); /* combine T with old*/
if Q::SubsumesDifferent?(T,This) /* T is implied by other constructors */
then signal RedundantExn;
T:= Q::ConjoinToDifferent(T,This) /* obtain a possibly stronger T*/
if (type(T) 6= Q) /* the stronger description might use another constructor*/
then {post T to ImplicationsToDoList; /* for later processing*/
return; }
Q::ConsistentWithDifferent?(T,This) /* Check if T is coherent with the rest
of This; if not, an exception is raised.*/
put Q(T,This) /* add the description to the normalized descriptor This*/
Q::FindOtherImplications(T,This,ImplicationsToDoList)
/* add any additional constructors implied by T and This */
Figure 3: Pseudo-code of a generic conjunction function.
Before we consider the individual functions introduced above, we remark that if the constructor Q implies terms built with other constructors (i.e., it adds entries to the ImplicationsToDoList), then the and::Conjoin function needs to be augmented with a loop at
the end, which conjoins to ontoNC all the normalized terms on the ImplicationsToDoList:
while notEmpty(ImplicationsToDoList)
{ another := removeAnElement(ImplicationsToDoList);
suppose type(another)=Q;
Q::conjoin(another,ontoNC)
Note that this processing may itself add new entries to the ImplicationsToDoList. In
the case that there are many additions being done to the ImplicationsToDoList, a useful
optimization might be to test for and remove redundancies from ImplicationsToDoList. If
there are very few constructors making additions, a different optimization might be applied:
add the above code only to the end of the corresponding constructors Conjoin program.
The following is the intended purpose of the component functions used in the
Q::Conjoin function in Figure 3. Note that for any particular constructor (e.g., all),

not every such function needs to be implemented. When using a good optimizing compiler,
default programs for these could be provided, which return constant values. Otherwise,
Conjoin itself should be edited.
431

fiBorgida

 Q::Universal?(T): Is T equivalent to the top of the hierarchy for that set of
values?
For example, at-least::Universal?
returns true when processing
at-least(0,players). This is used to eliminate unnecessary constructs from the
normal form.
 Q::Incoherent?(T): Is T incoherent by itself ?
For example, some(players ,nothing) is incoherent since nothing has no instances.
 Q::IncoherentWithDifferent(T,This): Is there an inconsistency if we consider
conjoining with other constructors? For example, when Q=at-least, conjoining
at-least(3,players) to a concept already containing at-most(1,players) would
lead to inconsistency.
 Q::SubsumesSame?(T,oldTs): Is T implied by the Q-constructed terms already seen
in oldTs? This is basically the structural subsumption part. For example, if
Q=at-least, and oldTs has at-least(4,players), then at-least(3,players) is redundant
 Q::SubsumesDifferent?(T,This): Is T implied by other constructors? For example,
at-least(1,players) is implied by some(players, OLD).
 Q::ConjoinToSame(T,OldTs): Merge T with any preceding terms built with K. For
example, when we combine all(players,GENTLEMAN) with all(players,SCHOLAR),
we obtain all(players,and(GENTLEMAN, SCHOLAR)).
 Q::ConjoinToDifferent(T,This): Produce a stronger T by using information from
other constructors. For example, if we are processing some(player, TALL),then if
the concept This already has all(player,OLD), then some::ConjoinToDifferent
returns the description of some(players,and(TALL,OLD)).
 Q::FindOtherImplications(T,This,ImplicationsToDoList): Add constructors
which are implied because of Q(T), possibly in conjunction with the rest of
the concept, This.
For example, when adding all(players,TALL) to a
concept with at-least(3,players), all::FindOtherImplications would add
some(players,TALL) to the list of constructors to be conjoined to This.

References
Baader, F. (1996). A formal definition for the expressive power of terminological knowledge
representation languages. J. of Logic and Computation, 6, 3354.
Baader, F., & Hanschke, P. (1991). A scheme for integrating concrete domains into concept
languages. In Proceedings of IJCAI91.
Baader, F., Hollunder, B., Nebel, B., Profitlich, H.-J., & Franconi, E. (1994). An empirical
analysis of optimization techniques for terminological representation systems - or making kris get a move on. Applied Intelligence, 4, 109132.
432

fiExtensible DL Representation and Reasoning

Borgida, A. (1992a). From type systems to knowledge representation: Natural semantics
specifications for description logics. Int. J. of Intelligent and Cooperative Information
Systems, 1, 259269.
Borgida, A. (1992b). Towards the systematic development of terminological reasoners:
clasp reconstructed. In Proceedings of KR92.
Borgida, A. (1995). Description logics in data management. IEEE Trans. on Knowledge
and Data Engineering, 7, 671682.
Borgida, A. (1996). On the relative expressiveness of description logics and predicate logics.
Artificial Intelligence, 82, 353367.
Borgida, A., Brachman, R. J., McGuinness, D. L., & Resnick, L. A. (1989). classic: A
structural data model for objects. In Proceedings of SIGMOD89.
Borgida, A., Isbell, C., & McGuinness, D. (1996). Reasoning with black boxes: Handling
test concepts in Classic. In Proceedings of Intern. Workshop on Description Logics
(DL96).
Borgida, A., & McGuinness, D. L. (1996). Asking queries about frames. In Proceedings of
KR96.
Borgida, A., & Patel-Schneider, P. F. (1994). A semantics and complete algorithm for subsumption in the classic description logic. Journal of Artificial Intelligence Research,
1, 277308.
Borgida, A., & Weddell, G. (1997). Uniqueness constraints in description logics. In Proceedings of Conf. on Deductive and Object-Oriented Databases (DOOD97).
Bresciani, P., Franconi, E., & Tessaris, S. (1995). Implementing and testing expressive
description logics: a preliminary report. In Proceedings of KRUSE95 Symposium.
Cohen, W., Borgida, A., & Hirsh, H. (1992). Computing least common subsumers in
description logics. In Proceedings of AAAI92.
Devanbu, P. (1994). Software Information Systems. Ph.D. thesis, Rutgers University, New
Brunswick, NJ, USA.
Devanbu, P., & Jones, M. (1997). The use of description logics in kbse systems. ACM
Transactions on Software Engineering and Methodology, 6.
Devanbu, P., & Litman, D. (1996). Taxonomic plan reasoning. Artificial Intelligence, 84,
135.
Donini, F., Lenzerini, M., Nardi, D., Nutt, W., & Schaerf, A. (1998). An epistemic operator
for description logics. Artificial Intelligence, 100, 225274.
Doyle, J., & Patil, R. (1991). Two theses of knowledge representation: language restrictions, taxonomic classification, and the utility of representation services. Artificial
Intelligence, 48, 261298.
433

fiBorgida

Gaines, B. (1993). A class library implementation of a principled open architecture knowledge representation server with plug-in data types. In Proceedings of IJCAI93.
Genesereth, M. (1983). An overview of meta-level architecture. In Proceedings of AAAI83.
Greiner, R., & Lenat, D. (1980). rll: A representation language language. In Proceedings
of KR94.
Horrocks, I. (1998). Using an expressive description logic: Fact or fiction?. In Proceedings
of KR98.
Horrocks, I., & Patel-Schneider, P. (1998). DL systems comparison. In Proceedings of of
the International Workshop on Description Logics - DL98.
Lenat, D., & Guha, R. (1990). Building Large Knowledge-Based Systems. Addison Wesley.
MacGregor, R. (1986). A deductive pattern matcher. In Proceedings of AAAI86.
Padgham, L., & Lambrix, P. (1994). A framework for part-of hierarchies in terminological
logics. In Proceedings of KR94.
Patel-Schneider, P. (1998). dlp system description. In Proceedings of of the International
Workshop on Description Logics (DL98).
Rowley, S., Shrobe, H., & Cassels, R. (1986). Joshua: Uniform access to heterogeneous
knowledge structures. In Proc AAAI86.
Royer, V., & Quantz, J. (1992). Deriving inference rules for terminological logics. In
Proceedings of JELIA92.
Schaerf, A. (1994). Reasoning with individuals in concept languages. Data and Knowledge
Engineering, 12, 141176.
Schmidt-Schauss, M. (1989). Subsumption in KL-ONE is undecidable. In Proceedings of
KR89.
Stockmeyer, L. (1974). The Complexity of Decision Problems in Automata Theory and
Logic. Ph.D. thesis, MIT, Cambridge, MA. Project MAC TR 138.
Vilain, M. (1985). The restricted language architecture of a hybrid representation system.
In Proceedings of IJCAI85.
von Luck, K., Nebel, B., Peltason, C., & Schmiedel, A. (1987). The anatomy of the back
system. KIT 41, Technical University of Berlin, Berlin, Germany.
Wright, J., Weixelbaum, E., Vesonder, G., Brown, K., Palmer, S., Berman, J., & Moore, H.
(1993). A knowledge-based configurator that supports sales, engineering, and manufacturing at AT&T network systems. AI Magazine, 14, 6980.

434

fiJournal of Artificial Intelligence Research 10 (1999) 117-167

Submitted 2/98; published 3/99

Modeling Belief in Dynamic Systems
Part II: Revision and Update
Nir Friedman

nir@cs.huji.ac.il

Institute of Computer Science
Hebrew University, Jerusalem, 91904, ISRAEL



http://www.cs.huji.ac.il/ nir

Joseph Y. Halpern

halpern@cs.cornell.edu

Computer Science Department
Cornell University, Ithaca, NY 14853
http://www.cs.cornell.edu/home/halpern

Abstract

The study of belief change has been an active area in philosophy and AI. In recent years
two special cases of belief change, belief revision and belief update, have been studied in
detail. In a companion paper (Friedman & Halpern, 1997), we introduce a new framework
to model belief change. This framework combines temporal and epistemic modalities with a
notion of plausibility, allowing us to examine the change of beliefs over time. In this paper,
we show how belief revision and belief update can be captured in our framework. This
allows us to compare the assumptions made by each method, and to better understand the
principles underlying them. In particular, it shows that Katsuno and Mendelzon's notion
of belief update (Katsuno & Mendelzon, 1991a) depends on several strong assumptions
that may limit its applicability in artificial intelligence. Finally, our analysis allow us to
identify a notion of minimal change that underlies a broad range of belief change operations
including revision and update.

1. Introduction
The study of belief change has been an active area in philosophy and artificial intelligence.
The focus of this research is to understand how an agent should change her beliefs as a result
of getting new information. Two instances of this general phenomenon have been studied
in detail. Belief revision (Alchourron, Gardenfors, & Makinson, 1985; Gardenfors, 1988)
focuses on how an agent should change her (set of) beliefs when she adopts a particular
new belief. Belief update (Katsuno & Mendelzon, 1991a), on the other hand, focuses on
how an agent should change her beliefs when she realizes that the world has changed. Both
approaches attempt to capture the intuition that an agent should make minimal changes
in her beliefs in order to accommodate the new belief. The difference is that belief revision
attempts to decide what beliefs should be discarded to accommodate a new belief, while
belief update attempts to decide what changes in the world led to the new observation.1
1. Throughout the paper we use \revision" to refer to AGM's proposal for revision (Alchourron et al., 1985)
not as a generic term for the general approach initiated by AGM; similarly, we use \update" to refer to
KM's proposal for update (Katsuno & Mendelzon, 1991a).

c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiFriedman & Halpern

Belief revision and belief update are two of many possible ways of modeling belief change.
In (Friedman & Halpern, 1997), we introduce a general framework for modeling belief
change. We start with the framework for analyzing knowledge in multi-agent systems,
introduced in (Halpern & Fagin, 1989), and add to it a measure of plausibility at each
situation. We then define belief as truth in the most plausible situations. The resulting
framework is very expressive; it captures both time and knowledge as well as beliefs. Having
time allows us to reason in the framework about changes in the beliefs of the agent. It also
allows us to relate the beliefs of the agent about the future with her actual beliefs in the
future. Knowledge captures in a precise sense the non-defeasible information the agent has
about the world, while belief captures the defeasible assumptions implied by her plausibility
assessment. The framework allows us to represent a broad spectrum of notions of belief
change. In this paper, we focus on how, in particular, belief revision and update can be
represented.
We are certainly not the first to provide semantic models for belief revision and update.
For example, (Alchourron et al., 1985; Grove, 1988; Gardenfors & Makinson, 1988; Rott,
1991; Boutilier, 1992; de Rijke, 1992) deal with revision, and (Katsuno & Mendelzon, 1991a;
del Val & Shoham, 1992) deal with update. In fact, there are several works in the literature
that capture both using the same machinery (Katsuno & Satoh, 1991; Goldszmidt & Pearl,
1996; Boutilier, 1998), and others that simulate belief revision using belief update (Grahne,
Mendelzon, & Rieter, 1992; del Val & Shoham, 1994). Our approach is different from most
in that we do not construct a specific framework to capture one or both of these belief
change paradigms. Instead, we start from a natural framework to model how an agent's
knowledge changes over time and add to it machinery that captures a defeasible notion of
belief.
We believe that our representation offers a number of advantages, and gives a deeper
understanding of both revision and update. For one thing, we show that both revision and
update can be viewed as proceeding by conditioning on initial prior plausibilities. Thus,
our representation emphasizes the role of conditioning as a way of understanding minimal
change. Moreover, it shows that that the major differences between revision and update
can be understood as corresponding to differences in initial beliefs. For example, revision
places full belief on the assumption that the propositions used to describe the world are
static, and do not change their truth value over time. By way of contrast, update allows for
the possibility that propositions change their truth value over time. However, the family of
prior plausibilities that we use to capture update in our framework have the property that
they prefer sequences of events where abnormal events occur as late as possible. Because of
this property, conditioning in update always \explains" observations by recent changes. The
fact that time appears explicitly in our framework allows us to make these issues precise.
In the literature, revision has been viewed as dealing with static worlds (although an
agent's beliefs may change, the underlying world about which the agent is reasoning does
not) while update has been viewed as dealing with dynamic worlds (see, for example, (Katsuno & Mendelzon, 1991a)). We believe that the distinction between static and dynamic
worlds is somewhat misleading. In fact, what is important for revision is not that the world
is static, but that the propositions used to describe the world are static. For example, \At
time 0 the block is on the table" is a static proposition, while \The block is on the table" is
not, since it implicitly references the current state of affairs. (Note that the assumption that
118

fiModeling Belief in Dynamic Systems. Part II.

the propositions are static is not unique to belief revision. Bayesian updating, for example,
makes similar assumptions.) Because we model time explicitly in our framework, we can
examine this issue in more detail. In fact, in Section 7, we show how we relate these two
viewpoints. More precisely, given a system, we replace each proposition p used in the system
by a family of propositions \p is true at time m", one for each time m. The resulting system
describes exactly the same process as the original system, but from a different linguistic perspective. As we show, if the original system corresponds to KM update, then the resulting
system is very close to satisfying the requirements of AGM revision. The only requirement
that is not met is that the prior is totally ordered, or ranked. This requirement, however,
has been relaxed in several variants of revision (Katsuno & Mendelzon, 1991b; Rott, 1992).
Thus, a large part of the difference between revision and update can be understood as a
difference in the language used to describe what is happening.
The generality of our framework forces us to be clear about the assumptions we make
in the process of capturing revision and update. As a consequence, we have to deal with
issues that have been largely ignored by previous semantic accounts. One of these issues
is the status of observations. As we show below, to capture either revision or update, we
have to assume that observations are minimally informative|the only information carried
by an observation of ' is that ' should be believed. This is a strong assumption, since
most observations carry additional information. For example, when trekking in Nepal,
one does not expect to observe the weather in Boston. If an agent observes that it is in
fact raining in Boston, then this \observation" might well provide extra information about
the world (for example, that cable television is available in Nepal). We remark that in
(Boutilier, Friedman, & Halpern, 1998) there is a treatment of revision in our framework
where observations are allowed to convey additional information.
Finally, our representation makes it clear how the intuitions of revision and update
can be applied in settings where the postulates used to describe them are not sound. For
example, we consider situations where they may be irreversible changes (such as death,
or breaking a glass vase), and where the agent may perform actions beyond just making
observations. Revision and update, as they stand, cannot handle such situations. As we
show, our framework allows us to extend them in a natural way so they do.
The rest of the paper is organized as follows. In Section 2, we give an overview of the
framework we introduced in (Friedman & Halpern, 1997). In Section 3, we give a brief review
of belief revision and belief update. In Section 4, we define a specific class of structures
that embody assumptions that are common to both update and revision. In Section 5,
we describe additional assumptions that are required to capture revision. In Section 6, we
describe the assumptions that are required to capture update. In Section 7, we reexamine
the differences and similarities between belief revision and update. In Section 8, we consider
possible extensions to the setup of revision and update, and discuss how these extensions
can be handled in our framework. Finally, in Section 9, we conclude with a discussion of
related and future work.
119

fiFriedman & Halpern

2. The Framework
We now review the framework of Halpern and Fagin (1989) for modeling knowledge, and our
extension of it for dealing with belief change. The reader is encouraged to consult (Fagin,
Halpern, Moses, & Vardi, 1995) for further details and motivation.

2.1 Modeling Knowledge

The framework of Halpern and Fagin was developed to model knowledge in distributed
(i.e., multi-agent) systems (Halpern & Fagin, 1989; Fagin et al., 1995). In this paper, we
restrict our attention to the single agent case. The key assumption in this framework is that
we can characterize the system by describing it in terms of a state that changes over time.
Formally, we assume that at each point in time, the agent is in one of a possibly infinite
set of (local) states. At this point, we do not put any further structure on these states
(although, as we shall see from our examples, when we model situations in a natural way,
states typically do have a great deal of meaningful structure). Intuitively, this local state
encodes the information the agent has observed thus far. There is also an environment,
whose state encodes relevant aspects of the system that are not part of the agent's local
state.
A global state is a pair (se ; sa ) consisting of the environment state se and the local state
sa of the agent. A run of the system is a function from time (which, for ease of exposition,
we assume ranges over the natural numbers) to global states. Thus, if r is a run, then
r(0); r(1); : : : is a sequence of global states that, roughly speaking, is a complete description
of what happens over time in one possible execution of the system. Given a run r, we can
define two functions re and ra that map from time to states of the environment and the
agent, respectively, by taking re (m) to be the state of the environment in the global state
r(m) and ra(m) to be the agent's local state in r(m). We can thus identify run r with the
pair of functions hre; rai. We take a system to consist of a set of runs. Intuitively, these
runs describe all the possible behaviors of the system, that is, all the possible sequences of
events that could occur in the system over time.
Given a system R, we refer to a pair (r; m) consisting of a run r 2 R and a time m
as a point. We say two points (r; m) and (r0; m0) are indistinguishable to the agent, and
write (r; m) a (r0; m0), if ra(m) = ra0 (m0), i.e., if the agent has the same local state at both
points. Finally, an interpreted system I is a tuple (R;  ) consisting of a system R together
with a mapping  that associates with each point a truth assignment to a set  of primitive
propositions. In an interpreted system we can talk about an agent's knowledge: the agent
knows ' at a point (r; m) if ' holds in all points (r0; m0) such that (r; m) a (r0; m0).
Intuitively, an agent knows ' at (r; m) if ' is implied by the information in the local state
ra(m). We give formal semantics for a language of knowledge (and time and plausibility)
in Section 2.3.

Example 2.1: The circuit diagnosis problem has been well studied in the literature (see
(Davis & Hamscher, 1988) for an overview). Consider a circuit that contains n logical
components c1; : : :; cn and k lines l1; : : :; lk . The agent can set the values on the input lines
of the circuit and observe the values on the output lines. The agent then compares the actual
output values to the expected output values and attempts to locate faulty components.
120

fiModeling Belief in Dynamic Systems. Part II.

Since a single test is usually insucient to locate the problem, the agent might perform a
sequence of such tests.
We want to model diagnosis using an interpreted system. To do so, we need to describe
the agent's local state, the state of the environment, and some appropriate propositions
for reasoning about diagnosis. Intuitively, the agent's state is the sequence of input-output
relations observed, while the environment's state describes the current state of the circuit.
This consists of the failure set , that is, the set of faulty components of the circuit and the
values on all the lines in the circuit. Each run describes the results of a specific series of
tests the agent performs and the results she observes. We make two additional assumptions:
(1) the agent does not forget what tests were performed and their results, and (2) the faults
are persistent and do not change over time.
To make this precise, we define the environment state at a point (r; m) to consist of
the failure set at (r; m), which we denote fault(r; m), as well as the values of all the lines
in the circuit. We require that the environment state be consistent with the description
of the circuit. Thus, for example, if c1 is an AND gate with input lines l1 and l2 and
output line l3, then if re (m) says that c1 is not faulty, then we require that there is a
1 on l3 if and only if there is a 1 on both l1 and l2.2 We capture the assumption that
faults are persistent by requiring that fault(r; m) = fault(r; 0). For our later results, it is
useful to describe the agent's observations using our logical language. Consider the set
diag = ff1 ; : : :; fn ; h1; : : :; hk g of primitive propositions, where fi denotes that component
i is faulty and hi denotes that there is a 1 on line i (that is, line i in a \high" state). An
observation is a conjunction of literals of the form hi and :hi . The agent's state at time
m is a sequence of m such observations. Formally, we define the agent's state ra(m) to
be ho1 ; : : :; omi, where, intuitively, ok is the formula describing the input-output relation
observed at time k. We use the notation io(r; k) to denote the formula describing the
observation made by the agent at the point (r; k). Given this language, we can define the
interpretation diag in the obvious way. We say that an observation o is consistent with an
environment state re (m) if the states of the input/output lines in re (m) agree with these in
o. The system Rdiag consists of all runs r satisfying these requirements in which io(r; m) is
consistent with re (m) for all times m.
Given the system (Rdiag ; diag ), we can examine the agent's knowledge after making a
sequence of observations o1; : : :; om . It is easy to see that the agent knows that the fault set
must be one with which all the observations are consistent. However, the agent cannot rule
out any of these fault sets. Thus, even if all the observations are consistent with the circuit
being fault-free, the agent does not know that the circuit is fault-free, since there might be
a fault that manifests itself only in configurations that have not yet been tested. Of course,
the agent might strongly believe that the circuit is fault-free, but we cannot (yet) express
this fact in our formalism. The next section rectifies this problem. ut
2. Note that this means that we can recover the behavior of the circuit (although not necessarily its exact
description) by simply looking at the environment state at a point where there are no failures. Of course,
if we could have a yet richer environment state that encodes the actual description of the circuit, but
this is unnecessary for the analysis we do here.

121

fiFriedman & Halpern

2.2 Plausibility Measures

Most non-probabilistic approaches to belief change require (explicitly or implicitly) that
the agent has some ordering over possible alternatives. For example, the agent might
have a preference ordering over possible worlds (Boutilier, 1994b; Grove, 1988; Katsuno &
Mendelzon, 1991b) or an entrenchment ordering over formulas (Gardenfors & Makinson,
1988). This ordering dictates how the agent's beliefs change. For example, in (Grove, 1988),
the new beliefs are characterized by the most preferred worlds that are consistent with the
new observation, while in (Gardenfors & Makinson, 1988), beliefs are discarded according
to their degree of entrenchment until it is consistent to add the new observation to the
resulting set of beliefs. We represent this ordering using plausibility measures , which were
introduced in (Friedman & Halpern, 1995, 1998b). We briey review the relevant definitions
and results here.
Recall that a probability space is a tuple (W; F ; Pr), where W is a set of worlds, F is
an algebra of measurable subsets of W (that is, a set of subsets closed under union and
complementation to which we assign probability), and Pr is a probability measure, that is, a
function mapping each set in F to a number in [0; 1] satisfying the well-known probability
axioms (Pr(;) = 0, Pr(W ) = 1, and Pr(A [ B ) = Pr(A) + Pr(B ), if A and B are disjoint).
Plausibility spaces are a direct generalization of probability spaces. We simply replace
the probability measure Pr by a plausibility measure Pl, which, rather than mapping sets in
F to numbers in [0; 1], maps them to elements in some arbitrary partially ordered set. We
read Pl(A) as \the plausibility of set A". If Pl(A)  Pl(B ), then B is at least as plausible
as A. Formally, a plausibility space is a tuple S = (W; F ; Pl), where W is a set of worlds, F
is an algebra of subsets of W , and Pl maps sets in F to some domain D of plausibility values
partially ordered by a relation D (so that D is reexive, transitive, and anti-symmetric).
We assume that D is pointed : that is, it contains two special elements >D , and ?D such
that ?D D d D >D for all d 2 D; we further assume that Pl(W ) = >D and Pl(;) =?D .
As usual, we define the ordering <D by taking d1 <D d2 if d1 D d2 and d1 6= d2 . We omit
the subscript D from D , <D , >D , and ?D whenever it is clear from context.
Since we want a set to be at least as plausible as any of its subsets, we require
A1 If A  B, then Pl(A)  Pl(B).
Some brief remarks on this definition: We have deliberately suppressed the domain D
from the tuple S , since for the purposes of this paper, only the ordering induced by  on
the subsets in F is relevant. The algebra F also does not play a significant role in this
paper. Unless we say otherwise, we assume F contains all subsets of interest and suppress
mention of F , denoting a plausibility space as a pair (W; Pl).
Clearly plausibility spaces generalize probability spaces. In (Friedman & Halpern, 1998b,
1995) we show that they also generalize belief function (Shafer, 1976), fuzzy measures (Wang
& Klir, 1992), possibility measures (Dubois & Prade, 1990), ordinal ranking (or -ranking )
(Goldszmidt & Pearl, 1996; Spohn, 1988), preference orderings (Kraus, Lehmann, & Magidor, 1990; Shoham, 1987), and parameterized probability distributions (Goldszmidt, Morris,
& Pearl, 1993) that are used as a basis for Pearl's -semantics for defaults (Pearl, 1989).
Our goal is to describe the agent's beliefs in terms of plausibility. To do this, we describe
how to evaluate statements of the form B' given a plausibility space. In fact, we use a
richer logical language that also allows us to describe how the agent compares different
122

fiModeling Belief in Dynamic Systems. Part II.

alternatives. This is the logic of conditionals. Conditionals are statements of the form
' , read \given ', is plausible" or \given ', then by default ". The syntax of the
logic of conditionals is simple: we start with primitive propositions and close off under
conjunction, negation and the modal operator . The resulting language is denoted LC .
A plausibility structure is a tuple PL = (W;Pl;  ), where W is a set of possible worlds,
Pl is a plausibility measure on W , and  (w) is a truth assignment to primitive propositions.
Given a plausibility structure PL = (W;Pl;  ), we define [ '] PL = fw 2 W :  (w) j= 'g to
be the set of worlds that satisfy '. We omit the subscript PL, when it is clear from the
context. Conditionals are evaluated according to a rule that is essentially the same as the
one used by Dubois and Prade (1991) to evaluate conditionals using possibility measures:
 PL j= ' if either Pl([['] ) =? or Pl([[' ^ ] ) > Pl([[' ^ : ] ).
Intuitively, '
holds vacuously if ' is impossible; otherwise, it holds if ' ^ is more
plausible than ' ^ : . As we show in (Friedman & Halpern, 1998b), this semantics of
conditionals also generalizes the semantics of conditionals in -ranking (Goldszmidt & Pearl,
1996), and PPD structures (Goldszmidt et al., 1993). As we also show in (Friedman &
Halpern, 1998b), this semantics for conditionals generalizes the semantics of preferential
structures. As this relationship plays a role in the discussion below, we review the necessary
definitions here. A preferential structure is a tuple (W; ;  ), where  is a partial order
on W . Roughly speaking, w  w0 holds if w is preferred to w0 .3 The intuition (Shoham,
1987) is that a preferential structure satisfies a conditional '
if all the most preferred
worlds (i.e., the minimal worlds according to ) in [ '] satisfy . However, there may be
no minimal worlds in [ '] . This can happen if [ '] contains an infinite descending sequence
: : :  w2  w1. What do we do in these structures? There are a number of options: the first
is to assume that, for each formula ', there are minimal worlds in [ '] ; this is the assumption
actually made in (Kraus et al., 1990), where it is called the smoothness assumption. A yet
more general definition|one that works even if  is not smooth|is given in (Lewis, 1973;
Boutilier, 1994a). Roughly speaking, '
is true if, from a certain point on, whenever '
is true, so is . More formally,
(W; ;  ) satisfies ' , if for every world w1 2 [ '] , there is a world w2 such
that (a) w2  w1 (so that w2 is at least as normal as w1), (b) w2 2 [ ' ^ ] , and
(c) for all worlds w3  w2 , we have w3 2 [ ' ) ] (so any world more normal
than w2 that satisfies ' also satisfies ).
It is easy to verify that this definition is equivalent to the earlier one if  is smooth.

!

!

!
!

!

!

!

Proposition 2.2: (Friedman & Halpern, 1998b) If  is a preference ordering on W ,
then there is a plausibility measure Pl on W such that (W; ;  ) j= '! if and only if
(W; Pl ;  ) j= '! .
We briey describe the construction of Pl here, since we use it in the sequel. Given
a preference order  on W , let D0 be the domain of plausibility values consisting of one
3. We follow the standard notation for preference here (Kraus et al., 1990), which uses the (perhaps confusing) convention of placing the more likely (or less abnormal) world on the left of the  operator.
Unfortunately, when translated to plausibility, this will mean w  w0 holds iff Pl(fwg > Pl(fw0 g).

123

fiFriedman & Halpern

element dw for every element w 2 W . We define a partial order on D0 using : dv < dw
if w  v . (Recall that w  w0 denotes that w is preferred to w0.) We then take D to be
the smallest set containing D0 that is closed under least upper bounds (so that every set
of elements in D has a least upper bound in D). For a subset A of W , we can then define
Pl (A) to be the least upper bound of fdw : w 2 Ag. Since D is closed under least upper
bounds, Pl(A) is well defined. As we show in (Friedman & Halpern, 1998b), this choice of
Pl satisfies Proposition 2.2.
The results of (Friedman & Halpern, 1998b) show that this semantics for conditionals
generalizes previous semantics for conditionals. Does this semantics capture our intuitions
about conditionals? In the AI literature, there has been little consensus on the \right"
properties for defaults (which are essentially conditionals). However, there has been some
consensus on a reasonable \core" of inference rules for default reasoning. This core is usually
known as the KLM properties (Kraus et al., 1990), and includes such properties as
AND From ' 1 and ' 2 infer ' 1 ^ 2
OR From '1 and '2 infer '1 _ '2
What constraints on plausibility spaces gives us the KLM properties? Consider the following
two conditions:
A2 If A, B, and C are pairwise disjoint sets, Pl(A[B) > Pl(C ), and Pl(A[C ) >
Pl(B ), then Pl(A) > Pl(B [ C ).
A3 If Pl(A) = Pl(B) =?, then Pl(A [ B) =?.
A plausibility space (W; Pl) is qualitative if it satisfies A2 and A3. A plausibility structure (W; Pl;  ) is qualitative if (W; Pl) is a qualitative plausibility space. In (Friedman &
Halpern, 1998b), we show that, in a very general sense, qualitative plausibility structures
capture default reasoning. More precisely, we show that the KLM properties are sound
with respect to a class of plausibility structures if and only if the class consists of qualitative plausibility structures. (We also provide a weak condition that we show is necessary
and sucient for the KLM properties to be complete.) These results show that plausibility
structures provide a unifying framework for the characterization of default entailment in
these different logics.

!
!

!
!

!

2.3 Plausibility and Knowledge

!

In (Friedman & Halpern, 1997) we show how plausibility measures can be incorporated into
the multi-agent system framework of (Halpern & Fagin, 1989). This allows us to describe
the agent's assessment of the possible states the system is in at each point in time. At the
same time we also introduce conditionals into the logical language in order to reason about
these plausibility assessments. We now review the relevant details.
An (interpreted) plausibility system is a tuple (R; ; P ) where, as before, R is a set
of runs and  maps each point to a truth assignment, and where P is a plausibility assignment function mapping each point (r; m) to a qualitative plausibility space P (r; m) =
(W(r;m); Pl(r;m)). Intuitively, the plausibility space P (r; m) describes the relative plausibility of events from the point of view of the agent at (r; m). In this paper, we restrict our
attention to plausibility spaces that satisfy two additional assumptions:
124

fiModeling Belief in Dynamic Systems. Part II.

 W(r;m) = f(r0; m0)j(r; m) a (r0; m0)g. Thus, the agent considers plausible only situa-

tions that are possible according to her knowledge.
 if (r; m) a (r0; m0) then P (r; m) = P (r0; m0). This means that the plausibility space
is a function of the agent's local state.4
We define a logical language to reason about interpreted systems. The syntax of the logic
is simple; we start with primitive propositions and close off under conjunction, negation,
the K modal operator (K' says that the agent knows '), the  modal operator (' says
that ' is true at the next time step), and the modal operator. The resulting language
is denoted LKPT .5 We recursively assign truth values to formulas in LKPT at a point (r; m)
in a plausibility system I . The truth of primitive propositions is determined by  , so that
(I ; r; m) j= p if  (r; m)(p) = true.
Conjunction and negation are treated in the standard way, as is knowledge: The agent
knows ' at (r; m) if ' holds at all points that she cannot distinguish from (r; m). Thus,
(I ; r; m) j= K' if (I ; r0; m0) j= ' for all (r0; m0) a (r; m).
' is true at (r; m) if ' is true at (r; m + 1). Thus,
(I ; r; m) j= ' if (I ; r; m + 1) j= '.
Finally, we define the conditional operator to describe the agent's plausibility assessment
at the current time. Let [ '] (r;m) = f(r0; m0) 2 W(r;m) : (I ; r; m) j= 'g.

!

!

!

(I ; r; m) j= '

if either Pl(r;m) ([['] (r;m)) = ? or Pl(r;m)([[' ^ ] (r;m)) > Pl(r;m) ([[' ^ : ] (r;m)).

We now define a notion of belief. Intuitively, the agent believes ' if ' is more plausible
than not. Formally, we define B' , (true ').
In (Friedman & Halpern, 1997) we prove that, in this framework, knowledge is an S5
operator, the conditional operator satisfies the usual axioms of conditional logic (Burgess,
1981), and  satisfies the usual properties of temporal logic (Manna & Pnueli, 1992). In
addition, these properties imply that belief is a K45 operator, and the interactions between
knowledge and belief are captured by the axioms K' ) B' and B' ) KB'.

!

!

Example 2.3: (Friedman & Halpern, 1997) We add a plausibility measure to the system
defined in Example 2.1. We define Idiag = (Rdiag ; diag ; Pdiag ), where Pdiag is the plausi-

bility assignment we now describe. We assume that failures of individual components are
independent of one another. If we also assume that the likelihood of each component failing
is the same, and also that this likelihood is small (i.e., failures are exceptional), then we
can construct a plausibility measure as follows. If (r0; m) and (r00; m) are two points in
W(r;m), we say that (r0; m) is more plausible than (r00; m) if jfault(r0; m)j < jfault(r00; m)j,
4. The framework presented in (Friedman & Halpern, 1997) is more general than this, dealing with multiple
agents and allowing the agent to consider several plausibility spaces in each local state. The simplified
version we present here suces to capture belief revision and update.
5. It is easy to add other temporal modalities such as until, eventually, since , etc. These do not play a role
in this paper.

125

fiFriedman & Halpern

that is, if the failure set at (r0; m) consists of fewer faulty components than at (r00; m). We
extend these comparisons to sets: Pl(r;m) (A)  Pl(r;m)(B ) if min(r0 ;m)2A (jfault(r0; m)j) 
min(r0 ;m)2B (jfault(r0; m)j); that is, A is less plausible if all the points in A have failure sets
of larger cardinality then the minimal one in B . With this plausibility measure, if all of
the agent's observations up to time m are consistent with there being no failures, then
the agent believes that all components are functioning correctly. On the other hand, if
the observations do not match the expected output of the circuit, then the agent considers
minimal failure sets that are consistent with her observations. Thus, if the observations are
consistent with a failure of c1, or a failure of c3 , or the combined failure of c2 and c7, then
the agent believes that either c1 or c3 is faulty, but not both.
We now make this more precise. A failure set (i.e., a diagnosis) is characterized by a
complete formula over f1 ; : : :; fn |that is, one that determines the truth values all these
propositions. For example, if n = 3, then f1 ^:f2 ^:f3 characterizes the failure set fc1g. We
define D(r;m) to be the set of failure sets (i.e., diagnoses) that the agent considers possible
at (r; m); that is D(r;m) = ff 2 F : (Idiag ; r; m) j= :B :f g where F is the set of all possible
failure sets.
Belief change in Idiag is characterized by the following proposition.

Proposition 2.4: If there is some f 2 D(r;m) that is consistent with the new observation

io(r; m + 1), then D(r;m+1) consists of all the failure sets in D(r;m) that are consistent with
io(r; m +1). If all f 2 D(r;m) are inconsistent with io(r; m +1), then D(r;m+1) consists of all
failure sets of cardinality j that are consistent with io(r; 1); : : :; io(r; m + 1), where j is the
least cardinality for which there is at least one failure set consistent with these observations.

Thus, in Idiag , a new observation consistent with the current set of most likely explanations
reduces this set (to those consistent with the new observation). On the other hand, a
surprising observation (one inconsistent with the current set of most likely explanations)
has a rather drastic effect. It easily follows from Proposition 2.4 that if io(r; m + 1) is
surprising, then D(r;m) \ D(r;m+1) = ;, so the agent discards all her current explanations
in this case. Moreover, an easy induction on m shows that if D(r;m) \ D(r;m+1) = ;, then
the cardinality of the failure sets in D(r;m+1) is greater than the cardinality of failure sets
in D(r;m). Thus, in this case, the explanations in D(r;m+1) are more complicated than those
in D(r;m). ut

2.4 Conditioning

In an interpreted system, the agent's beliefs change from point to point as her plausibility
space changes. The general framework does not put any constraints on how the plausibility
space changes. If we were thinking probabilistically, we could imagine the agent starting
with a prior on the runs in the system. Since a run describes a complete history over
time, this means that the agent puts a prior probability on the possible sequences of events
that could happen. We would then expect the agent to modify her prior by conditioning
on whatever information she has learned. As we show below, this notion of conditioning is
closely related to belief revision and update. We remark that we are not the first to applying
conditioning in the context of belief change (cf. (Goldszmidt & Pearl, 1996; Spohn, 1988));
the details are a little more complex in our framework, because we model time explicitly.
126

fiModeling Belief in Dynamic Systems. Part II.

We start by making the simplifying assumption that we are dealing with synchronous
systems where agents have perfect recall (Halpern & Vardi, 1989). Intuitively, this means
that the agent knows what the time is and does not forget the observations she has made.
Formally, a system is synchronous if (r; m) a (r0; m0) only if m = m0 . In synchronous
systems, the agent has perfect recall if (r0; m + 1) a (r; m + 1) implies (r0; m) a (r; m).
Thus, the agent considers run r possible at the point (r; m + 1) only if she also considers
it possible at (r; m). This means that any runs considered impossible at (r; m) are also
considered impossible at (r; m + 1): the agent does not forget what she knew.
Just as with probability, we assume that the agent has a prior plausibility measure on
runs that describes her prior assessment on the possible executions of the system. As the
agent gains knowledge, she updates her prior by conditioning. More precisely, at each point
(r; m), the agent conditions her previous assessment on the set of runs considered possible
at (r; m). This results in an updated assessment (posterior) of the plausibility of runs. This
posterior induces, via a projection from runs to points, a plausibility measure on points.
We can think of the agent's posterior at time m as simply her prior conditioned on her
knowledge at time m.
Formally, the prior plausibility of the agent is a plausibility measure Pa = (R; Pla ) over
the runs in the system. If A is a set of points, we define R(A) = fr : 9m((r; m) 2 A)g to be
the set of runs on which the points in A lie. The agent updates plausibilities by conditioning
in I if the following condition is met:
PRIOR There is prior Pa = (R; Pla) such that for all runs r 2 R, times m,
and sets A; B  W(r;m), Pl(r;m) (A)  Pl(r;m) (B ) if and only if Pla (R(A)) 
Pla (R(B )).
This definition implies that the agent's plausibility assessment at each point is determined,
in a straightforward fashion, by her prior.
As shown in (Friedman & Halpern, 1997), in synchronous systems that satisfy PRIOR
where agent have perfect recall, we can say even more: the agent's plausibility measure at
time m + 1 is determined by her plausibility measure at time m. To make this precise, if A
is a set of points, let prev(A) = f(r; m) : (r; m + 1) 2 Ag.

Theorem 2.5: (Friedman & Halpern, 1997). Let I be a synchronous system satisfying
PRIOR where agents have perfect recall. Then Pl(r;m+1)(A)  Pl(r;m+1) (B ) if and only if
Pl(r;m)(prev(A))  Pl(r;m)(prev(B )), for all runs r, times m, and sets A; B  W(r;m+1).
Thus, in synchronous systems where agents have perfect recall PRIOR implies a \local"
rule for update that incrementally changes the agent's plausibility at each step. This local
rule consists of two steps. First, the agent's plausibility at time m is projected to time
m + 1 points. Second, time m + 1 points that are inconsistent with the agent knowledge at
(r; m + 1) are discarded. This procedure implies that the relative plausibility of two sets of
runs does not change unless one of them is incompatible with the new knowledge.

Example 2.6: It is easy to verify that the system Idiag we consider in Example 2.3 satisfies
PRIOR. The prior Pa is determined by the failure set in each run in a manner similar to
the construction of Pl(r;m) . That is, R1 is more plausible than R2 if there is a run in R1
with a smaller failure set than all the runs in R2 . ut
127

fiFriedman & Halpern

3. Review of Revision and Update
We now present a brief review of belief revision and update.
Belief revision attempts to describe how a rational agent incorporates new beliefs. As
we said earlier, the main intuition is that as few changes as possible should be made. Thus,
when something is learned that is consistent with earlier beliefs, it is just added to the set of
beliefs. The more interesting situation is when the agent learns something inconsistent with
her current beliefs. She must then discard some of her old beliefs in order to incorporate
the new belief and remain consistent. The question is which ones?
The most widely accepted notion of belief revision is defined by the AGM theory (Alchourron et al., 1985; Gardenfors, 1988). This theory was originally developed in philosophy
of science, where one attempts to understand when a scientist changes her beliefs (e.g., theory of physical laws) in a rational manner. In this context, it seems reasonable to assume
that the world is static ; that is, the laws of physics do not change while the scientist is
performing experiments.
Formally, this theory assumes a logical language Le over a set e of primitive propositions with a consequence relation `L that contains the propositional calculus and satisfies
the deduction theorem. The AGM approach assumes that an agent's epistemic state is
represented by a belief set, that is, a set K of formulas in the language Le .6 There is also
assumed to be a revision operator  that takes a belief set A and a formula ' and returns a
new belief set A  ', intuitively, the result of revising A by '. The following AGM postulates
are an attempt to characterize the intuition of \minimal change":
e

(R1)
(R2)
(R3)
(R4)
(R5)
(R6)
(R7)
(R8)

A  ' is a belief set
'2A'
A  '  Cl(A [ f'g)7
If :' 62 A then Cl(A [ f'g)  A  '
A  ' = Cl(false) if and only if `L :'
If `L ' , then A  ' = A 
A  (' ^ )  Cl(A  ' [ f g)
If : 62 A  ' then Cl(A  ' [ f g)  A  (' ^ ).
e

e

The essence of these postulates is the following. After a revision by ' the belief set
should include ' (postulates R1 and R2). If the new belief is consistent with the belief set,
then the revision should not remove any of the old beliefs and should not add any new beliefs
except these implied by the combination of the old beliefs with the new belief (postulates
R3 and R4). This condition is called persistence . The next two conditions discuss the
coherence of beliefs. Postulate R5 states that the agent is capable of incorporating any
consistent belief and postulate R6 states that the syntactic form of the new belief does
not affect the revision process. The last two postulates enforce a certain coherency on the
6. For example, Gardenfors (1988, p. 21) says \A simple way of modeling the epistemic state of an individual
is to represent it by a set of sentences."
7. Cl(A) = f'jA `Le 'g is the deductive closure of a set of formulas A.

128

fiModeling Belief in Dynamic Systems. Part II.

outcome of revisions by related beliefs. Basically, they state that if is consistent with
A  ' then A  (' ^ ) is just A  '  .
The notion of belief update originated in the database community (Keller & Winslett,
1985; Winslett, 1988). The problem is how a knowledge base should change when something
is learned about the world. For example, suppose that a transaction adds to the knowledge
base the fact \Table 7 is in Oce 2", which contradicts the previous belief that \Table 7
is in Oce 1". What else should change? The intuition that update attempts to capture
is that such a transaction describes a change that has occurred in the world. Thus, in our
example, by applying update we might conclude that the reason that the table is in Oce
2 is that it was moved, not that our earlier beliefs were false. This example shows that,
unlike revision, update does not assume that the world is static.
Katsuno and Mendelzon (1991a) suggest a set of postulates that an update operator
should satisfy. The update postulates are expressed in terms of formulas, not belief sets.
That is, an update operator  maps a pair of formulas, one describing the agent's current
beliefs and the other describing the new observation, to a new formula that describes the
agent's updated beliefs. This is not unreasonable, since we can identify a formula ' with
the belief set Cl('). Indeed, if  is finite (which is what Katsuno and Mendelzon assume)
every belief set A can be associated with some formula 'A such that Cl('A) = A, and
every formula ' corresponds to a belief set Cl('). Thus, any update operator induces an
operator that maps a belief state and an observation to a new belief state. We slightly
abuse notation and use the same symbol to denote both types of mappings. We say that
a belief set A is complete if, for every ' 2 Le , either ' 2 A or :' 2 A. A formula  is
complete if Cl() is complete.
The KM postulates are:
(U1) `L   ' ) '
(U2) If `L  ) ', then `L   ' , 
(U3) `L :  ' if and only if `L : or `L :'
(U4) If `L 1 , 2 and `L '1 , '2 then `L 1  '1 , 2  '2
(U5) `L (  ') ^ )   (' ^ )
(U6) If `L   '1 ) '2 and `L   '2 ) '1, then `L   '1 ,   '2
(U7) If  is complete then `L (  '1 ) ^ (  '2) )   ('1 _ '2)
(U8) `L (1 _ 2 )  ' , (1  ') _ (2  ').
The essence of these postulates is as following. After learning ', the agent believes '
(postulate U1, which is analogous to R2). If ' is already believed, then updating by ' does
not change the agent's beliefs (postulate U2, which is a weaker version of R3 and R4). The
next two postulates (U3 and U4) deal with coherence of the belief change process. They
are analogous to R5 and R6, respectively, with minor differences. Postulates U5 and U6
deal with observations that are related to each other. U5 states that beliefs after learning
' that are consistent with are also believed after learning ' ^ . U6 states that if '2 is
believed after learning '1 and '1 is believed after learning '2, then learning either '1 or
'2 leads to the same belief set. Finally, U7 and U8 deal with decomposition properties of
the update operation. U7 states that if  is essentially a truth assignment to L, then if
e

e

e

e

e

e

e

e

e

e

e

e

e

e

e

129

fiFriedman & Halpern

is believed after learning '1 and is also believed after learning '2 then it is believed after
learning '1 _ '2 . U8 states that the update of the knowledge base can be computed by
independent updates on each sub-part of the knowledge. That is, if  = 1 _ 2 , then we
can apply update to each of 1 and 2 , and then combine the results.

4. Belief Change Systems

We want to model belief change|particularly belief revision and belief update|in the
framework of systems. To do so, we consider a particular class of systems that we call
belief change systems. In belief change systems, the agent makes observations about an
external environment. Just as is (implicitly) assumed in both revision and update, we
assume that these observations are described by formulas in some logical language. We
then make other assumptions regarding the plausibility measure used by the agent. We
formalize our assumptions as conditions BCS1{BCS5, described below, and say that a
system I = (R; ; P ) is a belief change system if it satisfies these conditions. We denote by
C BCS the set of belief change systems.
Assumption BCS1 formalizes the intuition that our language includes propositions for
reasoning about the environment, whose truth depends only on the environment state.

BCS1 The language L includes a propositional sublanguage Le over a set e
of primitive propositions. Le contains the usual propositional connectives and
comes equipped with a consequence relation `L . The interpretation  (r; m)
e

assigns truth to propositions in e in such a way that

(a)  (r; m) is consistent with `L , that is, fp : p 2 e ;  (r; m)(p) = trueg [
f:p : p 2 e; (r; m)(p) = falseg is `L consistent, and
(b)  (r; m)(p) depends only on re (m) for propositions in e ; that is,  (r; m)(p) =
(r0; m0)(p) whenever re (m) = re0 (m0 ).
e

e

Part (b) of BCS1 implies that we can evaluate formulas in Le with respect to environment
states; that is, if ' 2 Le and re (m) = re0 (m0), then (I ; r; m) j= ' if and only if (I ; r0; m0) j= '.
Since the environment is all that is relevant for formulas in Le , if ' 2 Le , we write se j= '
if (I ; r; m) j= ' for some point (r; m) such that re (m) = se .
BCS2 is concerned with the form of the agent's local state. Recall that, in our framework,
the local state captures the relevant aspects of the agent's epistemic state. The functional
form of the revision and update operators suggests that all that matters regarding how an
agent changes her beliefs are the agent's current epistemic state (which is taken by both
AGM and KM to be a belief set) and what is learned. In terms of our framework, this
suggests that agent's local state at time m + 1 should be a function of her local state of
time m and the observation made at time m. We in fact make the stronger assumption
here that the agent's state consists of the sequence of observations made by the agent. This
means that the agent remembers all her past observations. Note that this surely implies
that the agent's local state at time m + 1 is determined by her state at time m and the
observation made at time m. We make the further assumption that the observations made
by the agent can be described by formulas in Le . Although this is quite a strong assumption
on the expressive power of Le , it is standard in the literature: both revision and update
130

fiModeling Belief in Dynamic Systems. Part II.

assume that observations can be expressed as formulas in the language (see Section 3).
These assumptions are formalized in BCS2:
BCS2 For all r 2 R and for all m, we have ra(m) = ho(r;1); : : :; o(r;m)i where
o(r;k) 2 Le for 1  k  m.
Intuitively, o(r;k) is the observation the agent makes immediately after the transition from
time k , 1 to time k in run r. Thus, it represents what the agent observes about the new
state of the system at time k. Note that BCS2 implies that the agent's state at time 0 is the
empty sequence in all runs. Moreover, it implies that ra(m + 1) = ra(m)  o(r;m+1), where 
is the append operation on sequences. That is, the agent's state at (r; m + 1) is the result
of appending to her previous state the latest observation she has made about the system.
It is not too hard to show that belief change systems are synchronous and agents in them
have perfect recall. (We remark that the agents' local states are modeled in a similar way
in the model of knowledge bases presented in (Fagin et al., 1995).)
Clearly we want to reason in our language about the observations the agent makes.
Thus, we assume that the language includes propositions that describe the observations
made by the agent.
BCS3 The language L includes a set obs of primitive propositions disjoint
from e such that obs = flearn(') : ' 2 Le g. Moreover,  (r; m)(learn(')) =
true if and only if o(r;m) = ' for all runs r and times m.
In a system satisfying BCS1{BCS3, we can talk about belief change. The agent's state
encodes observations, and we have propositions that allow us to talk about what is observed.
The next assumption is somewhat more geared to situations where observations are always
\accepted", so that after the agent observes ', she believes '. While this is not a necessary
assumption, it is made by both belief revision and belief update. We capture this assumption
here in what is perhaps the simplest possible way: by assuming that observations are
reliable, so that the agent observes ' only if the current state of the environment satisfies
'. This is certainly not the only way of enforcing the assumption that observations are
accepted, but it is perhaps the simplest, so we focus on it here. As we shall see, this
assumption is consistent with both revision and update, in the sense that we can capture
both in systems satisfying it.
BCS4 (I ; r; m) j= o(r;m) for all runs r and times m.
Note that BCS4 implies that the agent never observes false. Moreover, it implies that after
observing ', the agent knows that ' is true. In (Boutilier et al., 1998), we consider an
instance of our framework in which observations are unreliable (so that BCS4 does not hold
in general), and examine the status of R2, the acceptance postulate, in this case.
Finally, we assume that belief change proceeds by conditioning. While there are certainly
other assumptions that can be made, as we have tried to argue, conditioning is a principled
approach that captures the intuitions of minimal change, given the observations. And, as
we shall see, conditioning (as captured by PRIOR) is consistent with both revision and
update.
BCS5 I satisfies PRIOR.
131

fiFriedman & Halpern

Many interesting systems can be viewed as BCS's.

Example 4.1: Consider the systems Idiag;1 and Idiag;2 of Example 2.1. Are these systems

BCSs? Not quite, since diag is not defined on primitive propositions of the form learn('),
but we can easily embed both systems in a BCS. Let Ldiag the propositional language defined
over diag , and let +diag consist of diag together with all the primitive propositions of the
+ be the obvious extension of 
form learn(') for ' 2 Ldiag . Let diag
diag to +
diag , defined so
+
that BCS3 holds. Then in it is easy to see that (Rdiag ; diag ; Pdiag;i ) is a BCS: we take the
e of BCS1 to be diag , and define `Ldiag so that it enforces the relationships determined
by the circuit layout. Thus, for example, if c1 is an AND gate with input lines l1 and l2
and output line l3, then we would have `Ldiag :f1 ) (h3 , h1 ^ h2 ). It is then easy to see
that BCS2{BCS5 hold by our construction. ut
These definitions set the background for our presentation of belief revision and belief
update.

5. Capturing Revision

Revision can be captured by restricting to BCSs that satisfy several additional assumptions. Before describing these assumptions, we briey review a well-known representation
of revision that will help motivate them.
While there are several representation theorems for belief revision, the clearest is perhaps
the following (Grove, 1988; Katsuno & Mendelzon, 1991b). We associate with each belief
set A a set WA of possible worlds that consists of those worlds where A is true. Thus, an
agent whose belief set is A believes that one of the worlds in WA is the real world. An agent
that performs belief revision behaves as though in each belief state A she has a ranking ,
i.e., a total preorder, over all possible worlds such that the minimal (i.e., most plausible)
worlds in the ranking are exactly those in WA . When revising by ', the agent chooses the
minimal worlds satisfying ' in the ranking and constructs a belief set from them. It is easy
to see that this procedure for belief revision satisfies the AGM postulates. Moreover, in
(Grove, 1988; Katsuno & Mendelzon, 1991b), it is shown that any belief revision operator
can be described in terms of such a ranking.
This representation suggests how we can capture belief revision in our framework. We
define C R  C BCS to be the set of belief change systems I = (R; ; P ) that satisfy the
conditions REV1{REV4 that we define below.
Revision assumes that the world does not change during the revision process. Formally this implies that propositions in e do not change their truth value along a run,
i.e., (I ; r; m) j= p if and only if (I ; r; m + 1) j= p for all p 2 e . This says that the state of
the world is the same with respect to the properties that the agent reasons about (i.e., the
propositions in e ).

REV1 (r; m)(p) = (r; 0)(p) for all p 2 e and points (r; m).
Note that REV1 does not necessarily imply that re (m) = re (m + 1). That is, REV1 allows
for a changing environment. The only restriction is that the truth value of propositions
that describe the environment does not change. We return to this issue in Section 7.
132

fiModeling Belief in Dynamic Systems. Part II.

The representation of (Grove, 1988; Katsuno & Mendelzon, 1991a) requires the agent
to totally order possible worlds. We put a similar requirement on the agent's plausibility
assessment. Recall that BCS5 says that the agent's plausibility is induced by a prior Pla;
REV2 strengthens this assumption.
REV2 The prior Pla of BCS5 is ranked; that is, for all A; B  R, either
Pla (A)  Pla(B ) or Pla (B )  Pla (A), and Pl(A [ B ) = max(Pl(A); Pl(B )).
The representation of (Grove, 1988; Katsuno & Mendelzon, 1991a) also requires that
the agent considers all truth assignments possible. We need a similar condition, except that
we want not only that all truth assignments be considered possible, but that they have
nontrivial plausibility (i.e., are more plausible than ?) as well.
To make this precise, it is helpful to introduce some notation that will be useful for our
later definitions as well. Given a system I and two sequences '1 ; : : :; 'k and o1; : : :; ok0
of formulas in Le , let R['1; : : :; 'k ; o1; : : :; ok0 ] consist of all runs r where for each i with
1  i  k, the formula 'i is true at (r; i) and the agent observes o1 ; : : :; ok0 . That is,
R['0; : : :; 'k ; o1; : : :; ok0 ] = fr 2 I : (I ; r; i) j= 'i; i = 0; : : :; k; and ra(k0) = ho1; : : :; ok0 ig.
We allow either sequence of formulas to be empty, so, for example, R['; ] consists of all
runs for which ' is true at the initial state. (Note that if REV1 holds, this means that ' is
true in all subsequent states as well.) We use the notation R['1; : : :; 'm] as an abbreviation
for R['1; : : :; 'm; ].
REV3 If ' 2 Le is consistent, then Pla(R[']) > ?.
It might seem that REV1{REV3 capture all of the assumptions made by the representation of (Grove, 1988; Katsuno & Mendelzon, 1991a). However, there is another assumption
implicit in the way revision is performed in these representations that we must make explicit
in our representation, because of the way we have distinguished observing ' (captured by
the formula learn(')) from ' itself. Intuitively, when the agent observes ', she updates her
plausibility assessment by conditioning on '. This is essentially what we can think of the
earlier representations as doing. However, in our representation, the agent does not condition on ', but on the fact that she has observed '. Although we do require that ' must
be true if the agent observes it (BCS4), the agent may in general gain extra information by
observing '.
To understand this issue, consider the following example. Suppose that R is such that
the agent observes p1 at time (r; m) only if p2 and q are also true at (r; m), and she observes
p1 ^ p2 at (r; m) only if q is false. It is easy to construct a BCS satisfying REV1{REV3
that also satisfies these requirements. In this system, after observing p1 , the agent believes
p2 and q. According to AGM's postulate R7 (and also KM's postulate U5) the agent must
believe q after observing p1 ^ p2 . To see this, note that our assumptions about R can
be phrased in the AGM language as p2 ^ q 2 K  p1 and :q 2 K  (p1 ^ p2 ). Postulate
R7 states that K  (p1 ^ p2 )  Cl(K  p1 [ fp2g). Since p2 2 K  p1, we have that
Cl(K  p1 [fp2g) = K  p1. Thus, R7 implies in this case that q 2 K  (p1 ^ p2). However, in
R, the agent believes (indeed knows) :q after observing p1 ^ p2.8 Thus, revision and update
8. We stress this does not mean that p1 ^ p2 implies :q in R. There may well be points in R at which
p1 ^ p2 ^ q is true. However, at such points, the agent would not observe p1 ^ p2 , since the agent observes
p1 ^ p2 only if q is false.

133

fiFriedman & Halpern

both are implicitly assuming that the observation of ' does not provide such additional
knowledge. The following assumption ensures that this is the case for revision (a more
general version will be required for update; see Section 6).
REV4 Pla(R['; o1; : : :; om])  Pla(R[ ; o1; : : :; om]) if and only if Pla(R[' ^
o1 ^ : : : ^ om ])  Pla (R[ ^ o1 ^ : : : ^ om ]).
This assumption captures the intuition that observing o1; : : :; ok provides no more information than just the fact that o1 ^ : : : ^ om is true. That is, the agent compares the
plausibility of ' and in the same way after conditioning by the observations o1 ; : : :; om
as after conditioning by the fact that o1 ^ : : : ^ om is true. It easily follows from REV4 and
PRIOR that the agent believes after observing o1 ^ : : : ^ om exactly if o1 ^ : : : ^ om ^
was initially considered more plausible than o1 ^ : : : ^ om ^ : . Thus, the agent believes
after observing o1 ^ : : : ^ om exactly if initially, she believed conditional on o1 ^ : : : ^ om :
the observations provide no extra information beyond the fact that each of the oi 's are true.
REV4 is quite a strong assumption. Not only does it say that observations do not
give the agent any additional information (beyond the fact that they are true), it also says
that all consistent observations can be made (since if ' ^ o is consistent, we must have
Pla(R['; o]) = Pla (R[' ^ o]) > ?, by REV3 and REV4). We might instead consider using
a weaker version of REV4 that says that, provided an observation can be made, it gives no
additional information. Formally, this would be captured as
REV40 If Pla(R['; o1; : : :; om]) > 0, then Pla(R['; o1; : : :; om])  Pla(R[ ; o1; : : :; om])
if and only if Pla(R[' ^ o1 ^ : : : ^ om ])  Pla (R[ ^ o1 ^ : : : ^ om ]).
The following examples suggests that REV40 may be more reasonable in practice than
REV4. We used REV4 only because it comes closer to the spirit of the requirement of
revision that all observations are possible.

Example 5.1: Consider the system Idiag;1 described in Example 2.1. As discussed in Ex-

ample 4.1, this system can be viewed as a BCS. Is it a revision system? It is easy to see that
Idiag;1 satisfies REV2 and REV3. It clearly does not satisfy REV1, since propositions that
describe input/output lines can change their values from one point to the next. However,
as we are about to show, a slight variant of Idiag;1 does satisfy REV1. A more fundamental
problem is that Idiag;1 does not satisfy REV4. This is inherent in our assumption that the
agent never directly observes faults, so that, for example, we have Pldiag;1(R[; f1]) = ?,
while Pldiag;1 (R[f1]) > ?. It does, however, satisfy REV40 .
To see how to modify Idiag;1 so as to satisfy REV1, recall that in the diagnosis task, the
agent is mainly interested in her beliefs about faults. Since faults are static in Idiag;1 , we can
satisfy REV1 if we ignore all propositions except f1 ; : : :; fn . Let 0diag = ff1 ; : : :; fn g and let
L0diag be the propositional language over 0diag . For every observation o made by the agent
regarding the value of the lines, there corresponds a formula in L0diag that characterizes all
the fault sets that are consistent with o. Thus, for every run r in Idiag;1 , we can construct
0 be the
a run r0 where the agent's local state is a sequence of formulas in L0diag . Let Idiag
0
system consisting of all such runs r . We can clearly put a plausibility assignment on these
0 are isomorphic in an obvious sense. In particular, the agent
runs so that Idiag;1 and Idiag
has the same beliefs about formulas in L0diag at corresponding points in the two systems.
134

fiModeling Belief in Dynamic Systems. Part II.

0 ; r; m) j= ' if and only if (Idiag;1; r; m) j= ' for all
More precisely, if ' 2 L0diag , then (Idiag
0 satisfies REV1{REV3 and REV40,
points (r; m) in Idiag;1. It is easy to verify that Idiag
although it still does not satisfy REV4.
0 instead of Idiag |Idiag seems to us a perfectly
We are not advocating here here using Idiag
reasonable way of modeling the situation. Rather, the point is that if we want a BCS to
satisfy properties that validate the AGM postulates, we must make some strong, and not
always natural, assumptions. ut

We want to show that a revision operator corresponds to a system in C R and vice
versa. To do so, we need to examine the beliefs of the agent at each point (r; m). First
we note that if (r; m) a (r0; m0) then (I ; r; m) j= B' if and only if (I ; r0; m0) j= B';
this is a consequence of the requirement that, as we have defined interpreted systems, the
agent's plausibility assessment is a function of her local state. Thus, we think of the agent's
beliefs as a function of her local state. We use the notation (I ; sa) j= B' as shorthand for
(I ; r; m) j= B' for some (r; m) such that ra(m) = sa . Let sa be some local state of the
agent. We define the agent's belief state at sa as
Bel(I ; sa) = f' 2 Le : (I ; sa) j= B'g:
Since the agent's state is a sequence of observations, the agent's state after observing ' is
simply sa  ', where  is the append operation. Thus, Bel(I ; sa  ') is the belief state after
observing '. We adopt the convention that if the agent can never attain the local state sa
in I , then Bel(I ; sa) = Le . With these definitions, we can compare the agent's belief state
before and after observing ', that is Bel(I ; sa) and Bel(I ; sa  ').
We start by showing that every AGM revision operator can be represented in C R.

Theorem 5.2: Let  be an AGM revision operator and let K  Le be a consistent belief
state. Then there is a system I;K 2 C R such that Bel(I;K ; hi) = K and
Bel(I;K ; hi)  ' = Bel(I;K ; h'i)
for all ' 2 Le .
Proof: See Appendix A.1. ut
Thus, Theorem 5.2 says that we can represent a revision operator  in the sense that we
have a family of systems I;K 2 C R , one for each consistent belief state K , such that K is
the agent's initial belief state in I;K , and for each formula ' in Le , the agent's belief state
after learning ' is K  '. Notice that we restrict attention to consistent belief states K .
The AGM postulates allow the agent to \escape" from an inconsistent state, so that K  '

may be consistent even if K is inconsistent. We might thus hope to extend the theorem so
that it also applies to the inconsistent belief state, but this is impossible in our framework.
If false 2 Bel(I;K ; sa) for some state sa , and ra(m) = sa , then Pl(r;m) (W(r;m)) = ?. Since
we update by conditioning, we must have Pl(r;m+1)(W(r;m+1) ) = ?, so the agent's belief
state will remain inconsistent no matter what she learns. Although we could modify our
framework to allow the agent to escape from inconsistent states, we actually consider this
to be a defect in the AGM postulates, not in our framework. To see why, suppose that the
135

fiFriedman & Halpern

agent's belief set is inconsistent at sa , and ra(m) = sa . Thus, the agent considers all states
in W(r;m) to be completely implausible (since Pl(r;m) (W(r;m)) = ?). On the other hand, to
escape inconsistency, she must have a plausibility ordering over the worlds in W(r;m). These
two requirements seem somewhat inconsistent.9
Not surprisingly, this inconsistency creates problems for other semantic representations
in the literature. For example, Boutilier's representation theorem (1992) states that for
every revision operator  and belief state K , there is a ranking R such that 2 K  ' if and
only if is believed in the minimal '-worlds according to R. If we examine this theorem, we
note that he does not state that the minimal (i.e., most preferred) worlds in R correspond
to the belief state K (in the sense that the minimal worlds are precisely those where the
formulas in K hold); this would be the analogue of our requiring that Bel(I;K ; hi) = K .
In fact, if K is `L -consistent, the minimal worlds do correspond to K . However, if K is
inconsistent, they cannot, since any nonempty ranking induces a consistent set of beliefs.
We could state a weaker version of Theorem 5.2 that would correspond exactly to Boutilier's
theorem. We presented the stronger result (that does not apply to inconsistent belief states)
to bring out what we believe to be a problem with the AGM postulates. See (Friedman &
Halpern, 1998a) for further discussion of this issue.
Theorem 5.2 shows that, in a precise sense, we can map AGM revision operations to
C R. What about the other direction? The next theorem shows that the first belief change
step in systems in C R satisfies the AGM postulates.
Theorem 5.3: Let I be a system in C R. Then there is an AGM revision operator I such
that
Bel(I ; hi) I ' = Bel(I ; h'i)
for all ' 2 Le .
Proof: See Appendix A.1. ut
We remark that if we used REV40 instead of REV4, then we would be able to prove this
result only for those formulas ' that are observable (i.e., for which Pl(R[']) > ?).
Both Theorems 5.2 and 5.3 apply to one-step revision, starting from the initial (empty)
state. What happens once we allow iterated revision? In our framework, observations are
taken to be known, so if the agent makes an inconsistent sequence of observations, then her
belief state will be inconsistent, and (as we observed above) will remain inconsistent from
then on, no matter what she observes. This creates a problem if we try to get analogues to
Theorems 5.2 and 5.3 for iterated revision. As the following theorem demonstrates, we can
already see the problem if we consider one-step revisions from a state other than the initial
state.
Theorem 5.4: Let I be a system in C R and let sa = h'1; : : :; 'ki be a local state in I .
Then there is an AGM revision operator I ;s such that
e

a

Bel(I ; sa) I ;s ' = Bel(I ; sa  ')
a

9. One strength of the AGM framework is that it can deal with an inconsistent sequence of observations,
that is, it can cope with an observation sequence of the form hp; :p; p; :p; : : :i. We stress that being able
to cope with such an inconsistent sequence of observations does not require allowing the agent to escape
from inconsistent belief sets. These are two orthogonal issues.

136

fiModeling Belief in Dynamic Systems. Part II.

for all formulas ' 2 Le such that '1 ^ : : : ^ 'k ^ ' is consistent.

Proof: See Appendix A.1. ut

We cannot do better than this. If '1 ^ : : : ^ 'k ^ ' is inconsistent then, because of
our requirements that all observations must be true of the current state of the environment
(BCS4) and that propositions are static (REV1), there cannot be any global state in I
where the agent's local state in sa  '. Thus, Bel(I ; sa  ') is inconsistent, contradicting R5.
There is another problem with trying to get an analogue of Theorem 5.3 for iterated
revision, a problem that seems inherent in the AGM framework. Our framework makes a
clear distinction between the agent's epistemic state at a point (r; m) in I , which we can
identify with her local state sa = ra(m), and the agent's belief set at (r; m), Bel(I ; sa),
which is the set of formulas she believes. In a system in C R, the agent's belief set does
not in general determine how the agent's beliefs will be revised; her epistemic state does.
On the other hand, the AGM postulates assume that revision is a function of the agent's
belief set and observations. Now suppose we have a system I and two points (r; m) and
(r; m0) on some run r 2 I such that (1) the agent's belief set is the same at (r; m) and
(r; m0), that is Bel(I ; ra(m)) = Bel(I ; ra(m0)), (2) the agent observes ' at both (r; m) and
(r; m0), (3) Bel(I ; ra(m + 1)) 6= Bel(I ; ra(m0 + 1). It is not hard to construct such a system
I . However, there cannot be an analogue of Theorem 5.3 for I , even if we restrict to
consistent sequences of observations. For suppose there were a revision operator  such
Bel(I ; hi))  '1      'k = Bel(I ; h'1; : : :; 'k i) for all '1 ; : : :; 'k such that '1 ^ : : : ^ 'k is
consistent. Then we would have Bel(I ; ra(m +1)) = Bel(I ; ra(m))  ' = Bel(I ; ra(m0))  ' =
Bel(I ; ra(m0 + 1)), contradicting our assumption.
The culprit here is the assumption that revision depends only on the agent's belief set.
To see why this is an unreasonable assumption, consider a situation where at time 0 the
agent believes both p and q , but her belief in q is stronger than her belief in p (i.e., the
plausibility of q is greater than that of p). We can well imagine that after observing :p _:q
at time 1, she would believe :p and q . However, if she first observed p at time 1 and then
:p _:q at time 2, she would believe p and :q, because, as a result of observing p, she would
assign p greater plausibility than q . Note, however, that the AGM postulates dictate that
after an observation that is already believed, the agent does not change her beliefs. Thus,
the AGM setup would force the agent to have the same beliefs after learning :p _ :q in
both situations.
There has been a great deal of work on the problem of iterated belief revision (Boutilier,
1996a; Darwiche & Pearl, 1997; Freund & Lehmann, 1994; Lehmann, 1995; Levi, 1988;
Nayak, 1994; Williams, 1994)). Much of the recent work moves away from the assumption
that belief revision depends solely on the agent's belief set. For example the approaches
of Boutilier (1996a) and Darwiche and Pearl (1997) define revision operators that map
(rankings  formulas) to rankings. Because our framework makes such a clear distinction
between epistemic states and belief states, it gives us a natural way of maintaining the
spirit of the AGM postulates while assuming that revision is a function of epistemic states.
Rather than taking  to be a function from (belief states  formulas) to belief states, we
take it  to be a function from (epistemic states  formulas) to epistemic states.
This leaves open the question of how to represent epistemic states. Boutilier and Darwiche and Pearl use rankings to represent epistemic states. In our framework, we represent
137

fiFriedman & Halpern

epistemic states by local states in interpreted systems. That is, a pair (I ; sa) denotes the
agent's state in an interpreted system, and the pair determines the agent's relevant epistemic attitudes, such as her beliefs, how her beliefs changed given particular observations,
her plausibility assessment over runs, and so on. When the system is understood, we simply
use sa as a shorthand representation of an epistemic state.
We can easily modify the AGM postulates to deal with such revision operators on
epistemic states. We start by assuming that there is a set of epistemic states and a function
Bel() that maps epistemic states to belief states. We then have analogues to each of the
AGM postulates, obtained by replacing each belief set by the beliefs in the corresponding
epistemic state. For example, we have

(R10) E  ' is an epistemic state
(R20) ' 2 Bel(E  ')
(R30) Bel(E  ')  Cl(Bel(E ) [ f'g)
and so on, with the obvious transformation.10
We can get strong representation theorems if we work at the level of epistemic states.
Given a language Le (with an associated consequence relation `L ), let EL consist of all
finite sequences of formulas in Le . Note that we allow EL to include sequences of formulas
whose conjunction is inconsistent. We define revision in EL in the obvious way: if E 2 EL ,
then E  ' = E  '.
e

e

e

e

e

Theorem 5.5: Let I be a system in C R whose local states are EL . There is a function

BelI that maps epistemic states to belief states such that

e

 if sa is a local state of the agent in I , then Bel(I ; sa) = BelI (sa), and
 (; BelI ) satisfies R10{R80 .
Proof: Roughly speaking, we define BelI (sa) = Bel(I ; sa) when sa is a local state in I . If
sa is not in I , then we set BelI (sa) = Bel(I ; s0), where s0 is the longest consistent sux of
sa. See Appendix A.1 for details. ut
Notice that, by definition, we have BelI (I ; hiI '1 I : : : I 'k ) = BelI (I ; h'1; : : :; 'k i),

so, at the level of epistemic states, we get an analogue to Theorem 5.3. We remark that to
ensure that R50 holds for (; BelI ), we need to define BelI (E ) appropriately for sequences
E 2 EI whose conjunction is inconsistent.
Theorem 5.5 shows that any system in C R corresponds to a revision operator over
epistemic states that satisfies the generalized AGM postulates. We would hope that the
converse also holds. Unfortunately, this is not quite the case. There are revision operators
on epistemic states that satisfy the generalized AGM postulates but do not correspond to
a system in C R. This is because systems in C R satisfy an additional postulate:

(R90) If 6`L :(' ^ ) then Bel(E  '  ) = Bel(E  ' ^ ).
e

10. The only problematic postulate is R6. The question is whether R60 should be \If `Le ' , then
Bel(E  ') = Bel(E  )" or \If `Le ' , then E  ' = E  ". Dealing with either version is
straightforward. For definiteness, we adopt the first alternative here.

138

fiModeling Belief in Dynamic Systems. Part II.

We show that R90 is sound in C R by proving the following strengthening of Theorem 5.5.
Proposition 5.6: Let I be a system in C R whose local states are EL . There is a function
BelI that maps epistemic states to belief states such that
 if sa is a local state of the agent in I , then Bel(I ; sa) = BelI (sa), and
 (; BelI ) satisfies R10{R90 .
Proof: We show that the function BelI defined in the proof of Theorem 5.5 satisfies R90.
See Appendix A.1 for details. ut
We can prove the converse to Proposition 5.6: a revision system on epistemic states that
satisfies the generalized AGM postulates and R90 does correspond to a system in C R .
Theorem 5.7: Given a function BelL mapping epistemic states in EL to belief sets over
Le such that BelL (hi) is consistent and (BelL ; ) satisfies R10{R90, there is a system I 2 C R
whose local states are in EL such that BelL (sa) = Bel(sa ) for each local state sa in I .
Proof: According to Theorem 5.2, there is a system I such that Bel(I ; hi) = BelL (hi)
and Bel(I ; h'i) = BelL (h'i) for all ' 2 Le . We show that Bel(I ; sa) = BelL (sa ) for local
states sa in I . See Appendix A.1. ut
Notice that, by definition, for the system I of Theorem 5.7, we have Bel(hi'1: : :'k ) =
Bel(h'1; : : :; 'k i) as long as '1 ^ : : : ^ 'k is consistent.
e

e

e

e

e

e

e

e

e

e

6. Capturing Update

Update tries to capture the intuition that there is a preference for runs where all the
observations made are true, and where changes from one point to the next along the run
are minimized.
We start by reviewing Katsuno and Mendelzon's semantic representation of update. To
characterize an agent beliefs, Katsuno and Mendelzon consider the set of \worlds" the agent
considers possible. In their representation, they associate a world with a truth assignment to
the primitive propositions. (In our terminology, we can think of a world as an environment
state.) To capture the notion of \minimal change from world to world", Katsuno and
Mendelzon use a distance function d on worlds. Given two worlds w and w0 , d(w; w0)
measures the distance between them. Intuitively, the larger the distance, the larger the
change required to get from world w to w0 . (Note that that distances are not necessarily
symmetric, that is, it might require a smaller change to get from w to w0, than from w0
to w.) Distances might be incomparable, so we require that d map pairs of worlds into a
partially ordered domain with a unique minimal element 0 and that d(w; w0) = 0 if and only
if w = w0.
Katsuno and Mendelzon show that there is a close relationship between update operators
and distance functions. To make this relationship precise, we need to introduce some
definitions. An update structure is a tuple U = (W; d;  ), where W is a finite set of worlds,
d is a distance function on W , and  is a mapping from worlds to truth assignments for Le
such that
 (w) is `L consistent,
e

139

fiFriedman & Halpern

 if 6`L :', then there is some w 2 W with (w)(') = true, and
 if w 6= w0 then (w) 6= (w0) for all w; w0 2 W .
Given an update structure U = (W; d;  ), we define [ '] U = fw :  (w)(') = trueg. Kate

suno and Mendelzon use update structures as semantic representations of update operators.
Given an update structure U = (W; d;  ) and sets A; B  W , Katsuno and Mendelzon define minU (A; B ) to be the set of worlds in B that are closest to worlds in A, according to
d. Formally, minU (A; B ) = fw 2 B : 9w0 2 A8w0 2 B d(w0; w0) 6< d(w0; w)g.

Theorem 6.1: (Katsuno & Mendelzon, 1991b) A belief change operator  satisfies U1{U8
if and only if there is an update structure U = (W; ; d) such that
[ '  ] U = minU ([['] U ; [ ] U ):

Thus the worlds the agent believes possible after updating with are these worlds that are
closest to some world considered possible before learning .
Katsuno and Mendelzon's account of update is \static" in the sense that it describes a
single belief change. Nevertheless, there is a clear intuition that each world w0 2 [ '  ] U
is the result of considering a minimal change from some world w 2 [ '] U . However, in
Katsuno and Mendelzon's representation, we do not keep track of the worlds that \lead to"
the worlds in the current belief set.
We now try to capture behavior similar to Katsuno and Mendelzon's semantics in our
framework. We define systems where each run describes the sequence of changes, so that the
most plausible runs, given a set of observations, correspond the worlds that define the belief
set in Katsuno and Mendelzon's semantics. More precisely, given a sequence of observations
1; : : :; n, each world in [ '  1  : : : n ] U can be \traced" back through a series of minimal
changes to a world in [ '] U . In our model, each such trace corresponds to one of the most
plausible runs, where the environment state at time m is the mth world in the trace. We
can capture this intuition by using a family of priors with a particular form.
We start with some preliminary definitions. Let I be a BCS, and let s0 ; : : :; sn be a
set of environment states in I . We define [s0; : : :; sn ] as the set of runs where re (i) = si
for all 0  i  n. Thus, [s0 ; : : :; sn ] describes a set of runs that share a common prefix of
environment states. A prior plausibility space Pa = (R; Pla ) is consistent with a distance
measure d if the following holds:
Pla ([s0; : : :; sn ]) < Pla ([s00; : : :; s0n ]) if and only if there is some j < n such that
sk = s0k for all 0  k  j , sj+1 6= s0j +1, and d(sj ; sj +1) < d(sj ; s0j+1).
Intuitively, we compare events of the form [s0 ; : : :; sn ] using a lexicographic ordering based
on d. Notice that this ordering focuses on the first point of difference. Runs with a smaller
change at this point are preferred, even if later there are abnormal changes. This point is
emphasized in the borrowed car example below.
Pla is prefix-defined if the plausibility of an event is uniquely defined by the plausibility
of run-prefixes that are contained in it, so that
Pla (R['0; : : :; 'm])  Pla (R[ 0; : : :; m]) if and only if for all [s0 ; : : :; sm ] 
R[ 0; : : :; m] , R['0; : : :; 'm] there is some [s00; : : :; s0m]  R['0; : : :; 'm] such
that Pla([s00 ; : : :; s0m]) > Pla ([s0; : : :; sm ]).
140

fiModeling Belief in Dynamic Systems. Part II.

Roughly speaking, this requirement states that we compare events by properties of dominance. This property is similar to one satisfied by the plausibility measures that we get
from preference ordering using the construction of Proposition 2.2.
We define the set C U to consist of BCSs I = (R; ; P ) that satisfy the following four
requirements UPD1{UPD4. UPD1 says that there are only finitely many possible truth
assignments, and that there is a one-to-one map between environment states and truth
assignments.
UPD1 The set e of propositions (of BCS1) is finite and  is such that for
all environment states s, s0 , if s 6= s0 , then there is a formula ' 2 Le such that
s j= ' and s0 j= :'.
UPD2{UPD4 are analogues to REV2{REV4. Like REV2, UPD2 puts constraints on
the form of the prior, but now we consider lexicographic priors of the form described above.
UPD2 The prior of BCS5 is prefix defined and consistent with some distance
measure.
Recall that REV3 requires only that all truth assignments initially have nontrivial plausibility. In the case of revision, the truth assignment does not change over time, since
we are dealing with static propositions. In the case of update, the truth assignment may
change over time, so UPD3 requires that all consistent sequences of truth assignments have
nontrivial plausibility.
UPD3 If 'i 2 Le , i = 0; : : :; k, are consistent formulas, then Pl(R['0; : : :; 'k]) >
?.
Finally, like REV4, UPD4 requires that the agent gain no information from her observations beyond the fact that they are true.
UPD4 Pla(R['0; : : :; 'k+1; o1; : : :; ok])  Pla(R[ 0; : : :; m+1; o1; : : :; om]) if
and only if Pla (R['0; '1 ^ o1 ; : : :; 'm ^ om ; 'm+1 ])  Pla (R[ 0; 1 ^ o1 ; : : :; m ^
om; m+1])
We remark that in the presence of REV1, UPD4 is equivalent to REV4. We might consider
generalized versions of UPD4, where the two sequences of formulas can have arbitrary
relative lengths; this version suces for our purposes. We can also define an analogue
UPD40 in the spirit of REV40 , which applies only if Pl(R['0; : : :; 'm+1; o1; : : :; om ]) > ?.
We now show that C U corresponds to (KM) update. Recall that Katsuno and Mendelzon
define an update operator as mapping a pair of formulas (; '), where  describes the agent's
beliefs and ' describes the observation, to a new formula   ' that describes the agent's
new beliefs. However, as we discussed in Section 3, when e is finite, we can also treat 
mapping a belief state and a formula to a new belief state. Also recall that Bel(I ; sa) is the
agent's belief set when her local state is sa .
Theorem 6.2: A belief change operator  satisfies U1{U8 if and only if there is a system
I 2 C U such that
Bel(I ; sa)  = Bel(I ; sa  )
for all epistemic states sa and formulas 2 Le .
141

fiFriedman & Halpern

Proof: Roughly speaking, we show that any system in C U corresponds to a Katsuno and
Mendelzon update structure. Suppose that I =2 C U is such that the set of environment
states is Se and the prior of BCS5 is consistent with distance function d. We define an
update structure UI . We then show that belief change in I corresponds to belief change in

UI in the sense of Theorem 6.1. Since Theorem 6.1 states that any belief change operation
defined by an update structure satisfies U1{U8, this will suce to prove the \if" direction
of the theorem. To prove the \only if" direction of the theorem, we show that that for any
update structure U , there is a system I 2 C U such that UI = U .
See Appendix A.2 for details. ut
This result immediately generalizes to sequences of updates.

Corollary 6.3: A belief change operator  satisfies U1{U8 if and only if there is a system
I 2 C U such that for all 1; : : :; k 2 Le , we have
Bel(I; sa )  1  : : :  k = Bel(I; sa  1  : : :  k ):
These results show that for update, unlike revision, the systems we consider are such that
the belief state does determine the result of the update, i.e., if Bel(I ; sa ) = Bel(I ; s0a), then
for any ' we get that Bel(I ; sa  ') = Bel(I ; s0a  '). Roughly speaking, the reason is that the
distance measure that determines the prior does not change over time. While this allows
us to get an elegant representation theorem, it also causes problems for the applicability of
update, as we shall see below.
Note that, since the world is allowed to change, there is no problem if we update by a
sequence 1; : : :; k of consistent formulas such that 1 ^ : : : ^ k is inconsistent. There
is no requirement that the formulas 1; : : :; k be true simultaneously. All that matters is
that i is true at time i. Also note that an update by an inconsistent formula does not pose
a problem for our framework. It follows from postulates U1 and U2 that once the agent
learns an inconsistent formula (i.e., false), she believes false from then on.
How reasonable is the notion of update? As the discussion of UPD2 above suggests, it
has a preference for deferring abnormal events. This makes it quite similar to Shoham's
chronological ignorance (1988), and it suffers from some of the same problems. Consider
the following story, that we call the borrowed-car example.11 At time 1, the agent parks her
car in front of her house with a full fuel tank. At time 2, she is in her house. At time 3,
she returns outside to find the car still parked where she left it. Since the agent does not
observe the car while she is inside the house, there is no reason for her to revise her beliefs
regarding the car's location. Since she finds it parked at time 3, she still has no reason
to change her beliefs. Now, what should the agent believe when, at time 4, she notices
that the fuel tank is no longer full? The agent may want to consider a number of possible
explanations for her time-4 observation, depending on what she considers to be the most
likely sequence(s) of events between time 1 and time 4. For example, if she has had previous
gas leaks, then she may consider leakage to be the most plausible explanation. On the other
hand, if her spouse also has the car keys, she may consider it possible that he used the car
in her absence. Update, however, prefers to defer abnormalities, so it will conclude that the
11. This example is based on Kautz's stolen car story (1986), and is due to Boutilier, who independently
observed this problem [private communication, 1993].

142

fiModeling Belief in Dynamic Systems. Part II.

fuel must have disappeared, for inexplicable reasons, between times 3 and 4. To see this,
note that runs where the car has been taken on a ride have an abnormality at time 2, while
runs where the car did not move at time 2 but the fuel suddenly disappeared, have their
first abnormality at time 4, and thus are preferred!
Suppose we formalize the example using propositions such as car-parked-outside, fueltank-full, etc. Let the agent's belief set at time i be i , i = 1; : : :; 4. Notice that 1 includes
the belief that the car is parked in front of the house with a full fuel tank. (That is,
`L 1 ) fuel-tank-full ^ car-parked-outside.) At time 2 the agent makes no observations
since she is in her house, so 2 = 1  true = 1 by U2. At time 3 the agent observes
the car outside her house, so 3 = 2  car-parked-outside = 1 , again by U2. Finally,
4 = 3  :fuel-tank-full. The observation of :fuel-tank-full at time 4 must be explained
by some means. In our semantics, the answer is clear. The most plausible runs are these
where the car was parked until time 3, and somewhere between time 3 and 4 some change
occurred.
Is this counterintuitive conclusion an artifact of our representation? To some extent
it is. This issue cannot be formally addressed within Katsuno and Mendelzon's semantic
framework, since that framework does not provide an account of sequences of changes.
Moreover, one might argue that within out framework there might be other families of priors
that satisfy U1{U8, which will offer alternative explanations of the surprising observation
at time 4. Nevertheless, we claim that our semantics captures, in what we believe to
be the most straightforward way, the intuition embedded in the Katsuno and Mendelzon's
representation. In particular, condition UPD2, which enforces the delay of abnormal events,
was needed in order to capture the \pointwise" nature of the update. It would be interesting
to know whether there is a natural way of capturing update in our framework that does not
suffer from these problems.
Does this way of capturing update semantically ever lead to reasonable results? Of
course, that depends on how we interpret \reasonable". We briey consider one approach
here.
In a world w, the agent has some beliefs that are described by, say, the formula '. These
beliefs may or may not be correct (where we say a belief ' is correct in a world w if ' is true
of w). Suppose something happens and the world changes to w0 . As a result of the agent's
observations, she has some new beliefs, described by '0 . Again, there is no reason to believe
that '0 is correct. Indeed, it may be quite unreasonable to expect '0 to be correct, even if
' is correct. Consider the borrowed-car example. Suppose that while the agent was sitting
inside the house, the car was, in fact, taken for a ride. Nevertheless, the most reasonable
belief for the agent to hold when she observes that the car is still in the parked after she
leaves the house is that it was there all along.
The problem here is that the information the agent obtains at times 2 and 3 is insucient
to determine what happened. We cannot expect all the agent's beliefs to be correct at this
point. On the other hand, if she does obtain sucient information about the change and
her beliefs were initially correct, then it seems reasonable to expect that her new beliefs will
be correct. But what counts as sucient information?
We say that ' provides sucient information about the change from w to w0 if there
is no world w00 satisfying ' such that d(w; w00) < d(w; w0). In other words, ' is sucient
information if, after observing ' in world w, the agent will consider the real world (w0) one
e

143

fiFriedman & Halpern

of the most likely worlds. Note that this definition is monotonic, in that if ' is sucient
information about the change, then so is any formula that implies ' (as long as it holds at
w0). Moreover, this definition depends on the agent's distance function d. What constitutes
sucient information for one agent might not for another. We would hope that the function
d is realistic in the sense that the worlds judged closest according to d really are the most
likely to occur.
We can now show that update has the property that if the agent has correct beliefs and
receives sucient information about a change, then she will continue to have correct beliefs.

Theorem 6.4: Let I 2 C U . If the agent's beliefs at (r; m) are correct and o(r;m) provides

sucient information about the change from re (m) to re (m + 1), then the agent's beliefs at
(r; m + 1) are correct.

Proof: Straightforward; left to the reader. ut
As we observed earlier, we cannot expect the agent to always have correct beliefs. Nevertheless, we might hope that if the agent does (eventually) receive suciently detailed
information, then she should realize that her beliefs were incorrect. But this is precisely
what does not happen in the borrowed-car example. Intuitively, once the agent observes
that the fuel tank is not full, this should be sucient information to eliminate the possibility that the car remained in the parking lot. However, it is not. Roughly speaking, this
is because update focuses only on the current state of the world, and thus cannot go back
and revise beliefs about the past.
The problem here is again due to the fact that belief update is determined only by the
agent's belief state and not her epistemic state. Thus, update can only take into account
the agent's current beliefs and not other information, such as the sequence of observations
that led to these beliefs. In our example, if we limit our attention to beliefs about the car's
whereabouts and the fuel tank, then since the agent has the same belief state at time 1
and 3, she must change her beliefs in the same manner at both times. This implies that the
observation the fuel tank is not full at time 4 cannot be sucient information about the
past, since a fuel leak might be the most plausible explanation of missing fuel at time 2.12
Our discussion of update shows that update is guaranteed to be safe only in situations
where there is always enough information to characterize the change that has occurred.
While this may be a plausible assumption in database applications, it seems somewhat less
reasonable in AI examples, particularly in cases involving reasoning about action.13

7. Synthesis

In previous sections we analyzed belief revision and belief update separately. We provided
representation theorems for both notions and discussed issues specific to each notion. In
this section, we try to identify some common themes and points of difference.
12. In this example the usual intuition is that, given the observation that the tank is not full, the agent
should revise her belief in some manner instead of performing update. This immediately raises the
question of how the agent knows what the right belief change operation should be here. We return to
this issue below.
13. Similar observations were independently made by Boutilier (1996b), although his representation is quite
different from ours.

144

fiModeling Belief in Dynamic Systems. Part II.

Restriction on
Environment changes
Initial plausibility
Belief change

Revision
No change
(Static propositions)
Total preorder
Conditioning

Update
All possible sequences
Lexicographic
Conditioning

Table 1: A summary of the restrictions we impose to capture revision and update.
Katsuno and Mendelzon (1991a) focused on the following three differences between AGM
revision and KM update:
1. Revision deals with static propositions, while update allows propositions that are not
static.
2. Revision and update treat inconsistent belief states differently. Revision allows an
agent to \recover" from an inconsistent state after observing a consistent formula.
Update dictates that once the agent has inconsistent beliefs, she will continue to have
inconsistent beliefs. As we noted above, it seems that revision's ability to recover from
an inconsistent belief set leads to several technical anomalies in iterated revision.
3. Revision considers only total preorders, while update allows partial preorders.
Our framework suggests a different approach to categorizing the differences between
revision and update (and other approaches to belief change): focusing on the restrictions
that have to be added to basic BCSs to obtain systems in C R and C U , respectively. In
particular, we focus on three aspects of a system:

 How does the environment state change?
 How does the agent form her initial beliefs? What regularities appear in the agent's

beliefs at the initial state?
 How does the agent change her beliefs?

Table 1 summarizes the answers to these questions for revision and update; it highlights
the different restrictions imposed by each. Revision puts a severe restriction on changes
of the environment (more precisely, on how we describe the environment in the language)
and a rather mild restriction on the agent's prior beliefs (they must form a total preorder).
On the other hand, update allows all sequences of environment states, but requires the
agent's prior beliefs to have a specific form. These formal properties match the intuitive
description of revision and update given in (Alchourron et al., 1985; Katsuno & Mendelzon,
1991b). However, the explicit representation of time in our framework allows us to make
these intuitions precise. Moreover, our framework makes explicit other assumptions made
by revision and update. For example, the lexicographic nature of update is not immediately
evident from the presentation in (Katsuno & Mendelzon, 1991b).
145

fiFriedman & Halpern

The key point to notice in this table is that belief change in both revision and update
is done by conditioning. This observation, and the naturalness of conditioning as a notion
of change, support our claim that conditioning should be adopted as semantic foundations
for minimal change.
How significant are the differences between revision and update? We claim that some
of these differences are a result of different ways of modeling the same underlying process.
Recall that in the introduction we noted that the restriction to static propositions is not such
a serious limitation of belief revision, since we can always convert a dynamic proposition
to a static one by adding timestamps. More precisely, we can replace a proposition p by a
family of propositions pm that stand for \p is true at time m". This makes it possible to
use revision to reason about a changing world. We now show how revision and update can
be related under this viewpoint.
To make this discussion precise, we need to introduce some formal definitions. Let
I = (R; ; P ) be a BCS. We \statify" I into a system I  = (R; ; P ) by replacing the
underlying language with static propositions.
Let e = fpm : p 2 e ; m 2 N g be a set of timestamped propositions and let Le be the
logical language based on these propositions. We can easily \timestamp" every formula in L.
We define timestamp('; m) recursively as follows. The base case is timestamp(p; m) = pm
for p 2 e . For standard logical connectives, we simply apply the transformation recursively,
for example timestamp(' ^ ) = timestamp('; m) ^ timestamp( ; m).
Next, we define the set of runs in the \statified" system. For each run r 2 R, we
define a r in R as follows. The environment states in r are defined to be the whole
sequence of environment states in r, that is, re(m) = re . If ra(m) = ho(r;1); : : :; o(r;m)i, we
define ra(m) = htimestamp(o(r;1); 1); : : :; timestamp(o(r;m); m)i. We define the interpretation   in the obvious way:  (r; m)(pm0 ) = true if and only if  (r; m0)(p) = true and
 (r; m)(learn(')) = true if and only if o(r ;m) = '.
Finally, we need to define the prior plausibility Pla . We define this prior to be isomorphic
to Pla under the transformation r 7! r. That is, for each set of runs R  R, we define
Pla(R ) = Pla (fr 2 R : r 2 R g).
It is clear that the two systems I and I  describe the same underlying process. Perhaps
the most significant difference is that the environment state in a run of I  encodes the
future of the run. This was necessary so that the environment state could determine the
truth of all propositions of the form pm , so as to satisfy BCS1. Without this requirement,
we could have simply changed  and left R and P unchanged.
Because different base languages are used in I and I , the agent has different beliefs
in the two systems. It is easy to show that, for all ' 2 Le , we have (I ; r; m) j= B' iff
(I  ; r; m) j= B (timestamp('; m)). However, at (r; m) the agent also has beliefs about
propositions that describe past and future times. Thus, the set of beliefs of the agent in I 
can be viewed as a superset of her beliefs in I at the corresponding points.
The following result makes precise the relationship between I and I  in terms of the
properties we have been considering.
Proposition 7.1: Let I be a BCS and let I  the transformed system defined above. Then
 I  is a BCS, that is, it satisfies BCS1{BCS5.
 I  satisfies REV1.
146

fiModeling Belief in Dynamic Systems. Part II.

 If I satisfies UPD3, then I  satisfies REV3.
 If I satisfies UPD4, then I  satisfies REV40.

Proof: Straightforward; left to the reader. ut
Thus, if I is a BCS, so is I  . Moreover, if I 2 C U , then I  satisfies all but two of the
requirements for C R. First, I  does not necessarily satisfy REV2, since the prior of systems
in C U is, in general, not ranked. Second, I  satisfies REV40, the weaker version of REV4.
The reason for this is that runs I  do not allow all sequences of possible observations.
Remember that in the language of Le , the agent can observe the proposition p2 (i.e., that
p is true at time 2) at time 1. However, in the original system, the agent only observes
properties of the current time. Thus, o(r ;m) involves only propositions that deal with time
m.

Neither of these shortcomings is serious. First, variants of AGM revision that involve
partial orders were discussed in the literature (Katsuno & Mendelzon, 1991b; Rott, 1992).
It is fairly straightforward to show that these can captured in our systems using BCSs that
satisfy REV1, REV3, and REV4. Second, it is easy to add to I  runs so as to get a system
that satisfies REV4. Moreover, we can do this is a way that does not change the agent's
beliefs for sequences of observations that can be observed in I . Thus, the \statified" version
of a system in C U displays behavior much in the spirit of belief revision.
This result may seem somewhat surprising in light of the significant differences between
the AGM postulates and KM postulates. In part, it shows how much is bound up in our
choice of language. (Recall that similar issues arose in Example 5.1.) This highlights the
sensitivity of the postulate approach to the modeling assumptions we make. Unfortunately,
these modeling assumptions are rarely discussed in the belief change literature. (See (Friedman & Halpern, 1998a) for a more detailed discussion of this point.)
Table 1 emphasizes that, despite the well-known differences between revision and update,
they can be viewed as sharing one very important feature: they both use conditioning to do
belief change. Thus, we have a common mechanism both for understanding and extending
them. To a certain extent, our results show that revision is more general than update, in
the sense that we can view the statified version of any system in C U as performing revision
(possibly with unranked prior) over runs.

8. Extensions
In the preceding sections, we introduced several assumptions that were needed to capture
revision and update. Of course, there are other ways of capturing these notions that require
somewhat different assumptions. Nevertheless, these assumptions give insight into the underlying choices made, either explicitly or implicitly, in the definition of revision and update.
In addition, thinking in terms of such restrictions makes it straightforward to extend the
intuitions of revision and update beyond the context where they were originally applied. In
this section, we consider a number of such extensions, to illustrate our point.
147

fiFriedman & Halpern

8.1 Knowledge
In many domains of interest, the agent knows that some sequences of observations are
impossible. We already saw in the circuit-diagnosis problem that observing failures was
impossible. In the context of update, we know that we cannot observe a person die and
then be alive, despite the fact that both being dead and being alive are consistent states.
We can easily maintain what we regard as the defining properties of revision and update,
as discussed in the previous section: no change in the environment state and a ranked prior
in the case of revision, and a lexicographic prior in the case of update, with belief change
proceeding by conditioning in both cases. We simply drop REV3 and replace REV4 by
REV40 (resp., drop UPD3 and replace UPD4 and UPD40 ). We remark that this change
affects the postulates. For example, consider update. Suppose that the agent considers
the possibility that Mr. Bond is dead. If she then observes Mr. Bond alive and well then,
according to update, she must account for the new observation by some change from the
worlds she previously considered possible. However, there is no transition from worlds
in which Mr. Bond is dead that can account for the new observation. Thus, once the
agent knows that certain transitions are impossible, some observations (e.g., observing that
Mr. Bond is alive) require her to remove from consideration some of the worlds that she
previously considered possible. As a consequence, postulate U8 does not hold, since the
agent's new beliefs are not determined by a pointwise update at each of the worlds she
previously considered possible. (Boutilier (1998) uses a related semantic framework to
draw similar conclusions in his analysis of update.)

8.2 Language of Beliefs
In our analysis of revision and update, we focused on the agent's beliefs about the current
state of the environment. Often we are also interested in how the agent changes her beliefs
about other types of statements, such as beliefs about future states of the environment,
beliefs about other agents' beliefs, and introspective beliefs about her own beliefs. Again,
it is straightforward in our framework to deal with an enriched language that lets us express such statements. For example, in (Friedman & Halpern, 1994) we examine Ramsey
conditionals. These are formulas of the form ' > , which can be read as saying \after
learning ', the agent believes ". This formula can be expressed as learn(') ) B in the
language LKPT . As is well known, if belief sets include Ramsey conditionals (and not just
propositional formulas), then the AGM postulates become inconsistent (at least, provided
we have at least three mutually exclusive consistent formulas in the language) (Gardenfors,
1986). Similar inconsistency results arise when one tries to add other forms of introspective
beliefs (Fuhrmann, 1989). In our setting, it is easy to see why the problem arises. Even
if we allow belief sets to include nonpropositional formulas, it still seems quite clear that
we want to distinguish the propositional formulas from formulas that talk explicitly about
an agent's beliefs. For example, it is not clear that we should allow an observation of a
formula such as ' > . What would it mean to observe such a formula? It clearly seems
quite different from observing a propositional formula. Nor does it make sense to extend an
assumption such as REV1 to arbitrary formulas. While it may be reasonable to restrict to
static propositions if we are viewing these as making statements about a relatively stable
148

fiModeling Belief in Dynamic Systems. Part II.

environment, it seems far less reasonable to assume that formulas that talk about an agent's
beliefs will be static, especially when we are trying to model belief change!
Of course, if we allow only propositional formulas to be learned (or observed), and
restrict REV1 to propositional formulas, then it is easy to see that all of our results still
hold, even if the full language is quite rich; we avoid the triviality result completely.

8.3 Observations
One of the strongest assumptions made by revision and update involves the treatment of
observations. This assumption seems unreasonable in most domains. REV4 and UPD4
essentially assume that the observation that the agent makes is chosen randomly among
all formulas consistent with the current state of the world. Suppose that ' says that the
agent is outdoors, says that the agent is in the basement, and o1 says that the basement
light is on. We may well have Pla (R[' ^ o1 ]) > Pla (R[ ^ o1 ]). For example, the agent
may hardly ever go to the basement and frequently go outdoors, but her children may often
leave the basement light on. Nevertheless, we may also have Pla (R['; o1]) < Pla (R[ ; o1]),
contradicting REV4. Indeed, it may well be impossible for the agent to observe that the
basement light is on when she is outdoors, so that Pla (R['; o1]) = ?, but this is not
permitted according to REV4 or UPD4.
In many domains it is useful to reason about hidden quantities that simply cannot be
observed. For example, the event that component ci is faulty in Example 5.1 is a basic
event in our description of the problem, yet it cannot be observed. Similarly, the event
where a patient has a disease X or the opponent is planning to capture the queen are useful
in reasoning about medical diagnosis and game strategy, yet are not directly observable in
practice. Thus, the requirement that all formulas in the language can be observed seems
quite unnatural. We note that explicitly modeling sensory input is a standard practice in
control theory and stochastic processes (e.g., in hidden Markov chains). In these fields,
one models the probability of an observation in various situations. Making an observation
increases the probability of situations where that observation is likely to be observation and
decreases the probability of situations where it is unlikely. Again, it is straightforward to
consider a more detailed model of the observation process in our framework; see (Friedman,
1997, Chapter 6) and (Boutilier et al., 1998).

8.4 Actions
Our definition of belief change systems essentially assumes that the agent is passive. The
situation is more complex when the agent can inuence the environment. The agent's choice
of action interacts with her beliefs. It is clear that after performing an action, the agent
should change her beliefs.14 Moreover, the information content of observations depends on
the action the agent has just performed. For example, the agent might consider hearing a
loud noise to be surprising. However, it would be expected after the agent pulls the trigger
of her gun.
14. Indeed, an alternative interpretation of the update postulates is that they describe how the agent should
update her beliefs after doing the action \achieve '" (Goldszmidt & Pearl, 1996; del Val & Shoham, 1992,
1993). However, as these works show, the update postulates are problematic under this interpretation.

149

fiFriedman & Halpern

8.5 Summary

This list of possible extensions is clearly not exhaustive; there are many others that we
may want to consider. Nevertheless, these are extensions that seem to be of interest. The
main points we want to make here are (1) it is easy to accommodate these extensions in
our framework while still maintaining the main characteristics of revision and update, and
(2) it is dicult to deal with such extensions if we focus on postulates.

9. Conclusion

We have shown how the framework introduced in (Friedman & Halpern, 1997) can be used
to capture belief revision and update. Modeling revision and update in the framework also
gives us a great deal of further insight into their properties, and emphasizes the role of
conditioning as a way of capturing minimal change.
Of course, revision and update are but two points in a wide spectrum of possible types of
belief change. Our ultimate goal is to use this framework to understand the whole spectrum
better and to help us design belief change operations that overcome some of the diculties
we have observed with revision and update. In particular, we want belief change operations
that can handle dynamic propositions, while still being able to revise information about the
past.
Our framework suggests how to construct such belief change operations. In this framework, belief change operations can be determined by choosing a plausibility measure that
captures the agent's preferences among sequences of worlds. This is the agent's prior plausibility, and captures her initial beliefs about the relative likelihood of runs. As the agent
receives information, she changes her beliefs using conditioning. In this paper we show that
revision and update correspond to two specific families of priors. Clearly, however, there
are prior plausibilities that, when conditioned on a surprising observation, allow the agent
to revise some earlier beliefs and to assume that some change has occurred. One obvious
problem is that, even if there are only two possible states, there are uncountably many
possible runs. How can an agent describe a prior plausibility over such a complex space?
One approach to doing this is based on intuition from the probabilistic settings. In
these settings, the standard solution to this problem is to assume that state transitions are
independent of when they occur, that is, that the probability of the system going from state
s to state s0 is independent of the sequence of transitions that brought the system to state
s. This Markov assumption significantly reduces the complexity of the problem. All that
is necessary is to describe the probability of state transitions. In (Friedman & Halpern,
1996; Friedman, 1997) we define a notion of plausibilistic independence, and show how to
describe priors that satisfy the Markov assumption and the consequences for belief change.
See also (Boutilier, 1998; Boutilier et al., 1998) for recent proposals along these lines.
Whether or not this particular approach turns out to be a useful one, it is clear that
these are the types of questions we should be asking. As these works show, our framework
provides a useful basis for answering them.
Finally, we note that our approach is quite different from the traditional approach to
belief change (Alchourron et al., 1985; Gardenfors, 1988; Katsuno & Mendelzon, 1991a).
Traditionally, belief change was viewed as an abstract process. Our framework, on the other
hand, models the agent and the environment she is situated in, and how both change in time.
150

fiModeling Belief in Dynamic Systems. Part II.

This allows us to model concrete agents in concrete settings (for example, diagnostic systems
are analyzed in (Friedman & Halpern, 1997) and throughout this paper), and to reason
about the beliefs and knowledge of such agents. We can then investigate what plausibility
ordering induces beliefs that match our intuitions. By gaining a better understanding of
such concrete situations, we can better investigate more abstract notions of belief change.
More generally, we believe that, when studying belief change, it is important to specify the
underlying ontology: that is, exactly what scenario underlies the belief-change process. We
have specified one such scenario here. While others are certainly possible, we view it as a
defect in the literature on belief change that the underlying scenario is so rarely discussed.
The framework we have introduced here provides a way of making formal what the scenario
is. (See (Friedman & Halpern, 1998a) for further discussion of this issue.)

Acknowledgments
The authors are grateful to Craig Boutilier, Ronen Brafman, Adnan Darwiche, Moises Goldszmidt, Adam Grove, Alberto Mendelzon, Alvaro del Val, and particularly Daphne Koller
and Moshe Vardi, for comments on drafts of this paper and useful discussions relating to
this work. Some of this work was done while both authors were at the IBM Almaden Research Center. The first author was also at Stanford while much of the work was done. IBM
and Stanford's support are gratefully acknowledged. The work was also supported in part
by the Air Force Oce of Scientific Research (AFSC), under Contract F49620-91-C-0080
and grant F94620-96-1-0323 and by NSF under grants IRI-95-03109 and IRI-96-25901. The
first author was also supported in part by an IBM Graduate Fellowship and by Rockwell
Science Center. A preliminary version of this paper appears in J. Doyle, E. Sandewall, and
P. Torasso (Eds.), Principles of Knowledge Representation and Reasoning: Proc. Fourth International Conference , 1994, pp. 190{201, under the title \A knowledge-based framework
for belief change, Part II: revision and update."

Appendix A. Proofs

A.1 Proofs for Section 5

We start with the proof of Theorems 5.2 and 5.3. To do this, we need some preliminary
definitions and lemmas. Figure 1 shows the general outline of the intermediate representations we use in these proofs. Roughly speaking, we show how to map from a revision
operator  and a consistent belief set K to a ranking, and similarly how to map from a
ranking to an AGM revision operator. These rankings correspond, in a direct way, to priors
in systems in C R , and thus have close connection to the beliefs of the agent in various states.
These mapping between AGM revision operators and rankings are related to the representation theorems of Boutilier (1994b), Grove (1988), and Katsuno and Mendelzon (1991a).
However, the exact details of our representations are different than those of Boutilier, Grove,
and Katsuno and Mendelzon. Thus, for completeness we provide the full proofs here.
We start with the mapping from revision operator applied to a specific belief set to a
ranking. As an intermediate step we construct a set of defaults as follows. We then will use
the results from (Friedman & Halpern, 1998b) to construct a ranked plausibility structure
that satisfies these defaults.
151

fiFriedman & Halpern

Lemma A.1

AGM
Revision
K;



Set of
Defaults

X
X





X
X

Lemma A.2

X
X



Ranked
Structure

Lemma A.3
C
 C

C 
C

Bel(I a)
;s



X
X

Lemma A.4

X
X



Characteristic
Structure
PLI

Figure 1: Schematic description of the entities and lemmas involved in the proof of Theorems 5.2 and 5.3.

Lemma A.1: Let  be an AGM revision operator, let K  Le be a consistent belief set,

and let

!

(;K ) = f'
Then the following is true:
(a)
(b)
(c)

: '; 2 Le ; 2 K  'g:

(;K ) is closed under the rules of system P,
' false 62 (;K) for all consistent ' 2 Le , and
(;K ) satisfies rational monotonicity; that is, if '
then ' ^ 
2 (;K).

!

!

!

2 (;K) and '!: 62 (;K),

Proof: We start with part (a):
LLE Assume that `L '  '0 and that '! 2 (;K ). Thus, 2 K  '. From R5, it
follows that 2 K  '0, and thus '0 ! 2 (;K ).
RW Assume that `L ) 0 and that '! 2 (;K ). Thus, 2 K  '. Since K  ' is a
belief set, it is closed under logical consequence. In particular, 0 2 K  ', and hence
'! 0 2 (;K).
REF By R2, ' 2 K  ', and thus, '!' 2 (;K ).
AND Assume that '! 1; '! 2 2 (;K ). Thus, 1; 2 2 K  '. Since K  ' is a belief
set, 1 ^ 2 2 K  '. Thus, '! 1 ^ 2 2 (;K ).
OR Assume that '1 ! ; '2! 2 (;K ). There are two cases. If K  ('1 _ '2 ) is
inconsistent, then 2 K  ('1 _ '2) and thus '1 _ '2 ! 2 (;K ). If K  ('1 _ '2) is
e

e

152

fiModeling Belief in Dynamic Systems. Part II.

consistent, then, by R2, '1 _ '2 2 K  ('1 _ '2 ). Thus, we cannot have both :'1 and
:'2 in K  ('1 _ '2). Without loss of generality, assume that :'1 62 K  ('1 _ '2).
Using R7 and R8, we get that K  (('1 _ '2 ) ^ '1) = Cl(K  ('1 _ '2 ) [ f'1g).
Using R6, we get that K  (('1 _ '2) ^ '1) = K  '1. Thus, we conclude that
K  '1 = Cl(K  ('1 _ '2 ) [ f'1g). Since '1 ! 2 (;K ), we have that 2 K  '1.
Thus, we get that '1 ) 2 K  ('1 _ '2 ). If :'2 62 K  ('1 _ '2), by similar arguments
we get that '2 ) 2 K  ('1 _ '2 ). This implies that ('1 _ '2) ) 2 K  ('1 _ '2 ),
and thus 2 K  ('1 _ '2). On the other hand, if :'2 2 K  ('1 _ '2 ), then, since
'1 _ '2 2 K  ('1 _ '2), we get that '1 2 K  ('1 _ '2), and thus 2 K  ('1 _ '2).
CM Assume that '! 1 ; '! 2 2 (;K ). If K  ' is inconsistent, then using R5 we get
that ' is inconsistent. Thus, ' ^ 1 is inconsistent, so 2 2 K  (' ^ 1 ). Now assume
that K  ' is consistent. Since '! 1, we have that 1 2 K  '. Since K  ' is
consistent, we get that : 1 62 K  '. Applying R8, we get that K  '  K  (' ^ 1 ).
Since '! 2 2 (;K ), we have that 2 2 K  '. Thus, 2 2 K  (' ^ 1 ). This
implies that (' ^ 1 )! 2 2 (;K ).
We now prove part (b). Let ' 2 Le be a consistent formula. Then, using R5, we get
that K  ' is consistent. Thus, '!false 62 (;K ).
Finally we prove part (c). Assume that '! 2 (;K ), and ' ^  ! 62 (;K ). Since
'! 2 (;K), we have that 2 K  '. Now if : 62 K  ', then, using R8, we have that
Cl(K  ' [fg)  K  (' ^ ). This implies that 2 K  (' ^  ). However, since we assumed
that ' ^  ! 62 (;K ), we have that 62 K  (' ^  ); thus, we get a contradiction. We
conclude that : 2 K  '. Thus, '!: 2 (;K ). ut

We now use this result to show that there exists a plausibility structure that corresponds
to  applied to K .
Lemma A.2: Let  be an AGM revision operator, and let K  Le be a consistent belief set.
Then there is a plausibility structure PL = (W; Pl;  ) such that Pl is ranked, PL j= '
if
and only if 2 K  ', and Pl([['] ) > ? for all `L -consistent formulas ' 2 Le .
Proof: We use the basic techniques described in the proof of (Friedman & Halpern, 1998b,
Theorem 8.2). Let (;K ) be the set of defaults defined by Lemma A.1. We now construct
a plausibility space PL0 = (W; Pl0 ;  ) such that PL0 j= '
if and only if '
2 (;K).
We define PL0 as follows:
 W = fwV : V  Le is a maximal `L -consistent setg,
 (wV )(p) = true if p 2 V , and
 Pl0([['] )  Pl0([[ ] ) if and only if (' _ ) ' 2 (;K).
Using (Friedman & Halpern, 1998b, Lemma 4.1), we get that PL0 j= '
if and only if
' 2 (;K). From Lemma A.1 (c) and and results of (Friedman & Halpern, 1998b), it
follows that there is a ranked plausibility measure Pl that is default-isomorphic to Pl0 , that
is (W; Pl;  ) satisfies precisely the same defaults as (W; Pl0;  ). Let PL = (W; Pl;  ).
Since PL is default-isomorphic to PL0, we have that PL j= '
if and only if '
2
(;K ). Moreover, using Lemma A.1, we have that '
2 (;K) if and only if 2 K  '.
Thus, PL j= '
if and only if 2 K  '. Finally, let ' be a `L -consistent formula. From

!

e

!

!

e

!

!

!

!

!

!

e

153

!

fiFriedman & Halpern

!

Lemma A.1 (b), we get that ' false 62 (;K ). Since (;K ) is closed under the rules of
system P, we conclude that (' _ false) false 62 (;K ). Thus, Pl0 ([['] ) 6 ? = Pl0([[false] ),
and thus Pl0 ([['] ) > ?. Since Pl is default-isomorphic to Pl0 , we conclude that Pl([['] ) > ?.

!

ut

We now prove the converse to Lemma A.2.

Lemma A.3: Let PL = (W; Pl; ) be a ranked plausibility structure such that (w) is `L consistent for all worlds w, and PL 6j= '!false for all `L -consistent formulas ' 2 Le ;
let K = f' 2 Le : PL j= true!'g. Then there is an AGM revision operator  such that
2 K  ' if and only if PL j= '! .
Proof: Let  be some belief change operation such that K  ' = f : PL j= '! g. Since
this requirement constrains only the result of applying  to K , we can assume without loss
of generality that  satisfies the AGM postulates when applied to belief sets other than K .
Thus, we need prove only that  satisfies the AGM postulates for revision applied to K .
e

e

(Note that the proofs for R3 and R4 follow from the proofs for R7 and R8, respectively.)

R1 Since PL is qualitative, we have that f : PL j= '! g is a belief set, that is, closed
R2
R5

under logical consequences.
Axiom C1 implies that PL j= ' '. Thus, ' 2 K  '.
By our assumptions, if ' is `L -consistent, then Pl([['] ) > ?, and thus PL 6j= ' false.
On the other hand, if ' is not `L -consistent, then [ '] = ;, and thus Pl([['] ) = ?.
We conclude that Pl([['] ) = ? if and only if `L :'. This implies that PL j= ' false
if and only if `L :'. Thus, K  ' = Cl(false) if and only if `L :'.
Assume that `L ' , '0 . Then, by our assumption,  (w)(') =  (w)('0). Thus,
[ ' ^ ] = [ '0 ^ ] for all formulas 2 Le . We conclude that PL j= '
if and only
if PL j= '0 . This implies that K  ' = K  '0.
There are two cases: either Pl([[' ^ ] ) = ? or Pl([[' ^ ] ) > ?. If Pl([[' ^ ] ) =
?, then ' ^ is inconsistent. According to R2, we have that ' 2 K  '. Thus,
' ^ 2 Cl(K  ' [ f g). This implies that Cl(K  ' [ f g) contains false, and thus
K  (' ^ )  Cl(K  ' [ f g). If Pl([[' ^ ] ) > ?, let  2 K  (' ^ ). We now show
that  2 Cl(K  ' [ f g). This will show that K  (' ^ )  Cl(K  ' [ f g). Since
 2 K  (' ^ ), we get that PL j= (' ^ ) . Since Pl([[' ^ ] ) > ?, we get that
Pl([['^ ^ ] ) > Pl([['^ ^: ] ). Then we have that Pl([['^( )  )]]) > Pl([['^:( )
 ))]]), since (' ^ ^ ) ) (' ^ ( ) )) and (' ^ :( )  )) ) (' ^ ^ : ). This
also implies that Pl([['] ) > ?. Thus, PL j= ' ( )  ). So, ( )  ) 2 K  ', and
thus  2 Cl(K  ' [ f g).
Assume that : 62 K  '. Let  2 Cl(K  ' [ f g). We now show that  2 K  (' ^ ).
This will show that Cl(K  ' [f g)  K  (' ^ ). Let A = [ ' ^: ] , B = [ ' ^ ^  ] ,
and C = [ ' ^ ^ : ] . It is easy to verify that these sets are pairwise disjoint. Since
' ^ ( ) )  (' ^ : ) _ (' ^ ^ ) and (' ^ :( )  ))  (' ^ ^ : ), we conclude
that [ ' ^ ( )  )]] = A [ B , and [ ' ^ :( )  )]] = C . Since  2 Cl(K  ' [ f g),
we have that ( )  ) 2 K  '. This means that PL j= ' ( )  ). Thus, either

!

!
!

e

e

e

R6
R7

e

!

e

!

e

!

!

R8

!

154

fiModeling Belief in Dynamic Systems. Part II.

Pl([['] ) = ? or Pl(A [ B ) > Pl(C ). If Pl([['] ) = ?, then according to A1, we get that
Pl([[' ^ ] ) = ?. Thus, PL j= (' ^ )  vacuously, and  2 K  (' ^ ) as desired.
Now assume that Pl(A [ B ) > Pl(C ). Since Pl is ranked, it satisfies A40 and A50.
According to A50, we get that either Pl(A) > Pl(C ) or Pl(B ) > Pl(C ). Assume that
Pl(A) > Pl(C ) and Pl(B ) 6> Pl(C ). Then, using A40, we get that Pl(A) > Pl(B ).
Applying A2, we get that Pl(A) > Pl(B [ C ). However since A = [ ' ^ : ] and
B [ C = [ ' ^ ] , this implies that : 2 K  ', which contradicts our assumption.
Thus, we conclude that Pl(B ) > Pl(C ). Since B = [ ' ^ ^  ] and C = [ ' ^ ^ : ] ,
we get that PL j= (' ^ )  , and thus  2 K  (' ^ ).
R3 and R4 Our definition of  implies that K  true = K . According to R6, we have that
K  (true ^ ') = K  '. Combining these two facts, we get that R3 and R4 are special
cases of R7 and R8, respectively.

!

!

ut
These results show how to map between ranked plausibility structures and AGM revision
operators. We now relate systems in C R and ranked plausibility structures. Let I =
(R; ; P ) 2 C R. Recall that REV2 requires that the prior of I be a ranking. Thus, we
can construct a ranked plausibility structure where worlds are runs in R. We define the
characteristic structure of I to be PLI = (R; Pla ; PlI ), where Pla is the agent's prior over
runs and PlI (r)(p) =  (r; 0)(p) for all p 2 e . Note that [ '] PLI = R['].
We now use PLI to describe the beliefs of the agent in each local state.

LemmaVA.4: Let I 2 C R and let sa = ho1; : : :; omi. Then
; sa) if and only if
Vm 'o2) toBelbe(Itrue
PLI j= ( m
o
)
!
'
.
(By
convention,
if
m
=
0
,
we
take
(
.)
i=1 i
i=1 i
Proof: Let I 2 C R and let sa = ho1; : : :; omi. There are two cases: either sa is a local state
in I , or it is not.
If sa is a local state in I , suppose that ra(m) = sa . Note that ' 2 Bel(I ; sa) if and
only if Pl(r;m)([['] (r;m)) > Pl(r;m)([[:'] (r;m)). Recall that, according to the definition of
conditioning, Pl(r;m) () is isomorphic to Pla (jR[; o1; : : :; om]). Thus, Pl(r;m)([['] (r;m)) >
Pl(r;m)([[:'] (r;m)) if and only if Pla (R['] j R[; o1; : : :; om ]) > Pla (R[:'] j R[; o1; : : :; om]).
Using C1, this is true if and only if Pla (R['V; o1; : : :; om ]) > Pla (R[:V'; o1; : : :; om ]). Using
REV4, this is true if and only if Pla (RV
[' ^ mi=1 oi ]) > Pla (R[:V' ^ mi=1 oi ]). We get that
' 2 Bel(I ; sa) if and only if Pla(R['V^ mi=1 oi ]) > Pla(R[:' ^ mi=1 oi ]). This implies that
' 2 Bel(I ; sa) if and only if PLI j= ( mi=1 oi )!'.
If sa is not a local state in I , then R[; o1; : : :; om] = ;, and by definition Pla (R[; o1; : : :; om ]) =
?. Using C1 and REV4, we get that PLa(R[Vmi=1 oi]) = ?, and thus PLI j= (Vmi=1 oi)!'
for all ' 2 Le . Since sa is not a local state in I , by definition
Bel(I ; sa) = Le . Hence, we
V
m
can conclude that ' 2 Bel(I ; sa) if and only if PLI j= ( i=1 oi )!'. ut
We now show that given a ranked plausibility structure PL we can construct a system
whose characteristic structure is default-isomorphic to PL.

Lemma A.5: Let PLK = (WK ; PlK ; K ) be a plausibility space that satisfies the conditions
of Lemma A.3. Then there is a system I 2 C R such that PLI = PLK .
155

fiFriedman & Halpern

Proof: Let PLK = (WK ; PlK ; K ) be a plausibility space that satisfies the conditions of
Lemma A.3. For each world w 2 WK and sequence of observations o1 ; o2; : : :, let rw;o ;o ;:::
be the run defined so that rew;o ;o ;:::(m) = w and raw;o ;o ;:::(m) = ho1 ; : : :; om i for all m. Let
R = frw;o ;o ;::: : k (w)(oi) = true for all ig. Define  so that (r; m)(p) = K (re(m))(p)
for p 2 e , and so that  (r; m)(learn(')) = true if o(r;m) = ' for ' 2 Le . Finally, define
the prior plausibility Pla so that Pla (R) = PlK (fw : 9r 2 R(w = re (0))g. It is easy to check
that this definition implies that Pla (R[']) = PlK ([['] PL ). Thus, PLI = PLK . Since PlK
is a ranking, Pla is also a ranking and thus qualitative.
We now verify that the resulting interpreted system is indeed in C R. It is easy to
check that I is a belief change system; that is, it satisfies BCS1{BCS5. The construction
is such that re (m) = re (0) for all runs r and times m. Thus, I satisfies REV1. Since
the prior Pla is a ranking, this system also satisfies REV2. Lemma A.2 implies that if '
is a consistent formula, then PlK ([['] PL ) > ?. This implies that Pla (R[']) > ?, and
thus the system satisfies REV3. Finally, it is easy to show that Pla (R['; o1; : : :; om ]) =
Pla(R[' ^ o1 ^ : : : ^ om ]) = PlK ([[' ^ o1 ^ : : : ^ om ] PL ). Thus, the system satisfies REV4.
1

1

1

2

1

2

2

2

K

K

ut

K

We are finally ready to prove Theorem 5.2.
Theorem 5.2: Let  be an AGM revision operator and let K  Le be a consistent belief
set. Then there is a system I(;K ) 2 C R such that Bel(I(;K ); hi) = K and
Bel(I(;K ); hi)  ' = Bel(I(;K ); h'i)
for all ' 2 Le .
Proof: Let  be an AGM revision operator and let K  Le be a consistent belief set. By
Lemmas A.2 and A.5, there is a system I(;K ) = (R(;K ); (;K ); P(;K )) 2 C R such that
PLI  j= '
if and only if 2 K  '. Our construction is such that 2 K  ' if and
only if PLI  j= ' . Using Lemma A.4, we get that PLI  j= '
if and only if
2 Bel(I(;K); h'i). Thus, K  ' = Bel(I(;K); h'i).
Finally, we show Bel(I(;K ); hi) = K . We start by showing that K  true = K . Using R3,
we get that K  true  Cl(K [ftrueg) = K . Since K is consistent, by R4, Cl(K [ftrueg) 
K  true. Thus, K  true = K . By Lemma A.4, we have that Bel(I ; hi) = Bel(I ; htruei).
Since Bel(I ; htruei) = K  true, we conclude that Bel(I(;K ); hi) = K . ut
We next prove Theorem 5.3.
Theorem 5.3: Let I be a system in C R. Then there is an AGM revision operator I such
that
Bel(I ; hi) I ' = Bel(I ; h'i)
for all ' 2 Le .
Proof: Let I = (R; ; P ) be a system in C R. It is easy to verify that PLI satisfies the
conditions of Lemma A.3 with K = Bel(I ; hi). This lemma implies that there is a revision
operator I such that 2 K I ' if and only if PLI j= ' . Using Lemma A.4, we have
that 2 Bel(I ; h'i) if and only if PlI j= ' . Thus, we have that K I ' = Bel(I ; h'i)
for all formulas '. ut
(

!

;K )

(

;K )

!

(

!

156

!

;K )

!

fiModeling Belief in Dynamic Systems. Part II.

Theorem 5.4: Let I be a system in C R and sa = ho1; : : :; omi be a local state in I . Then
there is an AGM revision operator I ;s such that
Bel(I ; sa) I ;s ' = Bel(I ; sa  ')
for all formulas ' 2 Le such that o1 ^ : : :om ^ ' is consistent.
Proof: The structure of the proof is similar to that of Theorem 5.3. As in that proof,
a

a

we construct a ranked plausibility structure and use Lemma A.3 to find an AGM revision
operator. The main difference is that after observing '1 ; : : :; 'k , some events are considered
impossible. Lemma A.3, however, requires that all possible formulas are assigned a positive
plausibility. We overcome this problem by assigning a \fictional" positive plausibility to all
non-empty events that are ruled out by the previous observations.
We proceed as follows. Let d0 be a new plausibility value that is less plausible than
all positive plausibilities in Pla; that is, if Pla (A) > ?, then Pla (A) > d0 . Let I =
(R; ; P ) 2 C R ; let sa = hoV1 ; : : :; om i. We define PL = (R; Pl; PLI ), where Pl is such that
m o ]); d ) for all consistent formulas '. This definition implies
Pl([['] ) = max(Pla (R[' ^ V
0
i=1 i
V
that if ' is consistent with mi=1 oi , then Pl([['] PLV) = Pla (R['1 ^ mi=1 oi ]).
We now Vprove that if ' is consistent with mi=1 oi , then PL j= '
if and only if
PLI j= (' ^ m
o
)
.
i
i=1
V
Vm o
For the \if" part, assume that PLI j=V('^ mi=1 oi ) . Since ' is consistent
with
i=1 i
m o ])) > ?. Thus, Pl (R[(' ^ (Vm o )) ^ ]) >
it follows, from
REV3,
that
Pl
(
R
[
'
^
(
a
i
a
i
i
=1
i
=1
V
V o . This implies
Pla(R[(' ^ ( mi=1 oi )) ^ : ])  ?V. Thus, ' ^ is consistent with mi=1
V i
that Pl([[' ^ ] ) = Pla (R[(' ^ ( mi=1 oi )) ^ ] > max(d0; Pla (R[(' ^ ( mi=1 oi )) ^ : ]) =
Pl([[' ^ : ] ). We conclude that PL j= ' .
Vm o )) . This implies that
For the \only
if"
part,
assume
that
PL
j
6
=
(
'
^
(
I
i=1 i
V
V
Pla(R[(' ^ ( mi=1 oi )) ^ V]) 6> Pla (R[(' ^ ( mi=1 oi ))V ^ : ]). Since Pla is a ranking, it
follows
that Pla(R[(' ^ ( mi=1 oiV)) ])  Pla (R[(' ^ ( mi=1 oi ))V ^ : ]). Since ? < Pla (R[' ^
V
m
( i=1 oi )]) =Vmax(Pla (R[(' ^ ( mi=1 oi )) ^ ]); Pla (R[(' ^ ( mi=1 oi )) ^ : ])), we have that
Pla(R[(' ^ ( mi=1 oi )) ^ : ]) > ?. We conclude that Pl([[' ^ : ] )  Pl([[' ^ ] ). Thus,
PL 6j= ' .
It is easy to verify that PL is ranked, and satisfies the requirements of Lemma A.3. Thus,
there exists a revision operator I ;s such that 2 K I ;s ' if and only Vif PL j= ' ,
where K = f' : PL j= true 'g. Moreover,Vsince for all ' consistent with mi=1 oi we have
thatPL j= '
if and only if PLI j= (' ^ ( mi=1 oi )) V , then, from Lemma A.4, it follows
that K = Bel(I ; sa) and that if ' is consistent with mi=1 oi , then PL j= '
if and only
if 2 Bel(I ; sa  '). ut

!

!

!

!

!

!

!

!

a

!

!

a

!

Theorem 5.5: Let I be a system in C R whose local states are EL . There is a function
e

BelI that maps epistemic states to belief states such that
 if sa is a local state of the agent in I , then Bel(I ; sa) = BelI (sa), and
 (; BelI ) satisfies R10{R80 .

Proof: As we said earlier, roughly speaking, we define BelI (sa) = Bel(I ; sa) when sa is a
local state in I . If sa is not in I , then we set BelI (sa) = Bel(I ; s0), where s0 is the longest
157

fiFriedman & Halpern

consistent sux of sa . We now make this definition precise, and show that the resulting
BelI satisfies R10 {R80 .
We proceed as follows. We define a function f () that maps sequences of observations
to suxes as follows: 8
><> hi
if m = 0,
i
if m > 0 and om is inconsistent,
f (ho1; : : :; omi) = > hhfalse
o
;
:
:
:;
o
i
otherwise, with k  m the minimal index
k
m
>:
s. t. 6`L :(ok ^ : : : ^ om ).
Aside from the special case where om is inconsistent, we simply choose the longest sux of
sa that is still consistent. We define BelI (sa) = Bel(I ; f (sa)). Clearly, if sa is a local state
in I , then f (sa ) = sa , so BelI (sa ) = Bel(I ; sa).
We now have to show that (; BelI ) satisfies R10 {R80. The proof outline is as follows.
Given a particular state sa , we construct a ranked plausibility structure that corresponds,
in the sense of Lemma A.2, to belief change from sa . We then use Lemma A.3 to show that
belief changes from sa satisfies the AGM postulates, i.e., R1{R8. Since this is true from
any sa , we get that BelI satisfies R10 {R80 .
Let sa = ho1; : : :; om i. We define a ranked plausibility space that has the following
structure. The most plausible events are the ones consistent with o1 ^ : : : ^ om . They are
ordered according to the prior ranking conditioned on o1 ^ : : : ^ om . The next tier of events
are those that are inconsistent with o1 ^ : : : ^ om but are consistent o2 ^ : : : ^ om . Again,
these are ordered according to the prior ranking conditioned on o2 ^ : : : ^ om . We continue
this way; the last tier consists of all events that are inconsistent with om .
V Formally, let PL = (RV; Pl; PLI ), where Pl is such that Pl([['] )  Pl([[ ] ) if Pla(R[' ^
( mi=k oi ]))  Pla (R[ ^ ( mi=k oi ])) where k V m + 1 is the greatest integer such that for all
j < k, ' and are both inconsistent with mi=j oi. It is easy to see that PL is ranked, and
that if ' is consistent, then Pl([['] ) > ?.
Let ' 2 Le . We now show that PL j= '
if and only if 2 BelI (sa  '). If ' is
inconsistent, then PL j= ' for all . Moreover, since ' is inconsistent, f (sa  ') = hfalsei,
and thus BelI (sa  ') = Le . We conclude that '
if and only if 2 BelI (sa  '). If ' is
consistent,
then
let
k

m
+1
be
the
greatest
integer
such
that for all j < k, ' is inconsistent
V
m
with i=j oi . It is easy to verify that f (sa  ') = hok ; : : :; om ; 'i. From Lemma
V A.4, it follows
that 2 BelVI (sa  ') = Bel(I ; hok ; : : :; om ; 'i) if and only if Pla (R[(' ^ ( mi=k oi )) ^ ]) >
Pla(R[(' ^ ( mi=k oi )) ^ : ]).VWe now show that this is the Vcase if and only if PL j= ' .
Suppose thatVPLa (R[(' ^ ^( mi=k oi )) ^ ]) > PLa (R[(' ^ ( mi=k oi )) ^ : ]). Then, clearly,
Pla(R[(' ^ ( mi=k oi )) ^ ]) > ?, and thus ' ^ is consistent with ok ; : : :; om . Since both
' ^ and ' ^ : are inconsistent with oj ; : : V:; om for all j < k, we have that
V Pl([[' ^ ] ) >
Pl([[' ^ : ] ). On other hand, if Pla (R[(' ^V( mi=k oi )) ^ ]) 6> Pla (R[(' ^ (V mi=k oi )) ^ : ]),
then since Pla is a ranking PLa(R[(' ^ ( mi=k oi )) ^ ])  PLa (R[(' ^ ( miV=k oi )) ^ : ]).
Moreover, since ' is consistent Vwith ok ^ : : : ^ om , we have that Pla (R[' ^ ( mi=k oi )]) > ?.
This implies that Pla (R[(' ^ ( mi=k oi )) ^ : ]) > ? and thus Pl([[' ^ ] )  Pl([[' ^ : ] ).
We conclude that PL j= '
if and only if 2 BelI (sa  ').
By Lemma A.3, there is a revision operator s that satisfies R1{R8 such that 2 K  '
if and only if PL j= ' . It is not hard to check that this implies that the change from
BelI (sa ) to BelI (sa  ') satisfies R10 {R80 . ut
e

!

!
!

!

!

!

a

158

fiModeling Belief in Dynamic Systems. Part II.

Proposition 5.6: Let I be a system in C R whose local states are EL . There is a function
e

BelI that maps epistemic states to belief states such that
 if sa is a local state of the agent in I , then Bel(I ; sa) = BelI (sa), and
 (; BelI ) satisfies R10{R90 .
Proof: As we said in the main text, we show that the function BelI defined in the proof of
Theorem 5.5 satisfies R90 . Let sa = ho1; : : :; om i, and let '; 2 Le be formulas such that
6`L :(' ^ ). Since ' is consistent with , we get that f (sa  '  ) = hok ; : : :; om; '; i,
where k  m is the least integer such that ' ^ is consistent with ok ; : : :; om . For the same
reason, we get that f (sa  ' ^ ) = hok ; : : :; om; ' ^ i. Using Lemma A.4 we immediately
get that Bel(I ; hok ; : : :; om ; '; i) = Bel(I ; hok ; : : :; om ; ' ^ i). Thus, we conclude that
BelI (sa  '  ) = BelI (sa  ' ^ ). ut
e

Theorem 5.7: Given a function BelL mapping epistemic states in EL to belief sets over
Le such that BelL (hi) is consistent and (BelL ; ) satisfies R10{R90, there is a system I 2 C R
whose local states are in EL such that BelL (sa) = Bel(I ; sa) for each local state sa in I .
Proof: We show that Bel(I ; sa) = BelL (sa) for local states sa in I , where I is the system
guaranteed to exist by Theorem 5.2 such that Bel(I ; hi) = BelL (hi) and Bel(I ; h'i) =
BelL (h'i) for all ' 2 Le . We prove this by induction on the length m of sa . For
m  1, this is true by our choice of I . For the induction case, let sa = ho1; : : :; omi
be a local state in I . Thus,, o1 ^ : : : ^ om is consistent. From R90 , it follows that
BelL (ho1; : : :; om i) = BelL (ho1; : : :; om,2; om,1 ^ om i). Using the induction hypothesis,
we have that BelL (ho1; : : :; om,2; om,1 ^ om i) = Bel(I ; ho1; : : :; om,2 ; om,1 ^ om i). Using
Lemma A.4, we get that Bel(I ; ho1; : : :; om,2 ; om,1 ^ om i) = Bel(I ; ho1; : : :; omi). Thus, we
conclude that BelL (ho1 ; : : :; om i) = Bel(I ; ho1; : : :; om i). ut
e

e

e

e

e

e

e

e

e

e

e

e

e

A.2 Proofs for Section 6

In this section we prove Theorem 6.2. We now show that any system in C U corresponds to
an update structure. Suppose that I = (R; ; P ) 2 C U is such that the set of environment
states is Se and the prior of BCS5 is consistent with distance function d. Define an update
structure UI = (Se ; e; d), where for p 2 e , e (se )(p) =  ((se; sa ))(p) for some choice of
sa. By BCS1, the choice of sa does not matter. It is easy to see that UPD1 ensures that
Se and e satisfy the requirements of the definition of update structures. We want to show
that belief change in I corresponds to belief change in UI in the sense of Theorem 6.1.
Since Theorem 6.1 states that any belief change operation defined by an update structure
satisfies U1{U8, this will suce to prove the \if" direction of Theorem 6.2. To prove the
\only if" direction of Theorem 6.2, we show that that for any update structure U , there is
a system I 2 C U such that UI = U .
We start with preliminary definitions and lemmas for the \if" direction of Theorem 6.2.
Let sa = ho1; : : :; omi. We define States (I ; sa) = fs 2 Se : s j=  for all  2 Bel(I ; sa)g.
Clearly, if ' is such that Bel(I ; sa) = Cl('), then States (I ; sa) = [ '] UI . To show that
belief change in I corresponds to belief change in UI we have to show that
States (I ; sa  ) = minUI (States (I ; sa); [ ] UI ):
159

fiFriedman & Halpern

This is proved in Lemma A.8. To prove this lemma, we need some preliminary lemmas.

Lemma A.6: Let I 2 C U , and let sa = ho1; : : :; omi. Then ' 2 Bel(I ; sa) if and only if
(I ; r; 0) j= (o1 ^ : : : ^ m om )!m ' for some run r in R.
Proof: The proof of this lemma is analogous to the proof of Lemma A.4, using UPD3 and
UPD4 instead of REV3 and REV4. We do not repeat the argument here. ut
We now provide an alternative characterization of States (I ; sa) in terms of the agent's
prior on run-prefixes.

Lemma A.7: Let I 2 C U and let sa = ho1; : : :; omi. Then sm 2 States (I ; sa) if and only if
there is a sequence of states [s0 ; : : :; sm]  R[true; o1; : : :; om] such that Pla ([s0; : : :; sm ]) <
6
Pla(R[true; o1; : : :; om] , [s0 ; : : :; sm]).
Proof: For the \if" direction, assume that there is a sequence s0; : : :; sm such that
[s0 ; : : :; sm ]  R[true; o1; : : :; om], and Pla ([s0; : : :; sm ]) <
6 Pla(R[true; o1; : : :; om] ,
[s0 ; : : :; sm ]). By way of contradiction, assume that sm 62 States (I ; m). Thus, there is a formula  2 Bel(I ; m) such that sm j= : . From Lemma A.6 it follows that since  2 Bel(I ; sa),
(I ; r; 0) j= (o1 ^ : : : ^ m om )!m  for some run r in R. From the definition of conditioning it follows that Pla (R[true; o1; : : :; om,1 ; om ^  ]) > Pla (R[true; o1; : : :; om,1; om ^ : ]).
Since sm j= : , we get that [s0; : : :; sm ]  R[true; o1; : : :; om,1 ; om ^ : ] and that
R[true; o1; : : :; om,1; om ^ ]  R[true; o1; : : :; om] , [s0; : : :; sm]. From A1, it follows that
Pla([s0 ; : : :; sm]) < Pla (R[true; o1; : : :; om ] , [s0; : : :; sm ]), which contradicts our starting
assumption. We conclude that sm 2 States (I ; sa).
For the \only if" direction, assume that sm 2 States (I ; a). Since Se is finite and e
assigns a different truth assignment to each state in Se , there is a formula  2 Le that
characterizes sm ; that is, s j=  if and only if s = sm . Since sm 2 States (I ; sa), we have that
: 62 Bel(I ; sa). Using Lemma A.6, we get that (I ; r; 0) 6j= (o1 ^ : : : ^ m om)!m :
for all runs r 2 R. By BCS5, this is true if and only if Pla (R[true; o1; : : :; om ]) > ?
and Pla(R[true; o1; : : :; om,1; om ^  ]) <
6 Pla(R[true; o1; : : :; om,1; om ^ :]). By UPD2,
there is a sequence [s0 ; : : :; sm]  R[true; o1; : : :; om,1 ; om ^  ] such that Pla ([s0; : : :; sm ]) <
6
Pla([s00 ; : : :; s0m]) for all [s00 ; : : :; s0m]  R[true; o1; : : :; om,1 ; om ^: ]. Moreover, without loss
of generality, we can assume that Pla ([s0; : : :; sm]) <
6 Pla([s00; : : :; s0m]) for all [s00; : : :; s0m] 
R[true; o1; : : :; om,1; om ^ ], since there are only finitely many such sequences. Thus, by
UPD2, Pla ([s0; : : :; sm ]) <
6 Pla(R[true; o1; : : :; om] , [s0; : : :; sm]). ut
We can now prove that belief change in I corresponds to belief change in UI .
Lemma A.8: Let I = (R; ; P ) 2 C U Then
States (I ; sa  ) = minUI (States (I ; sa); [ ] UI )
for all local states sa and formulas 2 Le .
Proof: Let Pla be the prior in I ; assume that Pla consistent with a distance function d.
Let sa = ho1 ; : : :; om i.
160

fiModeling Belief in Dynamic Systems. Part II.

To show that minUI (States (I ; sa); [ ] UI )  States (I ; sa  ), suppose that s 2
minUI (States (I ; sa); [ ] UI ). Thus, there is a state sm 2 States (I ; sa) such that d(sm ; s0) 6<
d(sm ; s) for all states s0 that satisfy . We want to show that s 2 States (I ; sa 
). From Lemma A.7, it follows that, since sm 2 States (I ; sa), there is a sequence
s0 ; : : :; sm,1 such that [s0; : : :; sm ] 2 R[true; o1; : : :; om,1 ; om] and Pla ([s0; : : :; sm]) 6<
Pla(R[true; o1; : : :; om,1; om ] , [s0 ; : : :; sm ]). We now show that Pla ([s0; : : :; sm; s]) 6<
Pla(R[true; o1; : : :; om; ] , [s0 ; : : :; sm ; s]). By Lemma A.7, this suces to show that
s 2 States (I ; sa  ). Suppose that [s00 ; : : :; s0m+1]  R[true; o1; : : :; om ; ] , [s0; : : :; sm; s].
If [s0; : : :; sm ] = [s00 ; : : :; s0m ], then we have that d(s0m ; s0m+1 ) 6< d(sm ; s). Since Pla is consistent with d, it follows that Pla ([s0; : : :; sm ; s]) 6< Pla ([s00; : : :; s0m ; s0m+1]). If [s0 ; : : :; sm] 6=
[s00 ; : : :; s0m ], then, since Pla ([s0 ; : : :; sm ]) 6< Pla ([s00; : : :; s0m]) and Pla is consistent with d,
we have that Pla ([s0; : : :; sm ; s]) 6< Pla ([s00 ; : : :; s0m ; s0m+1 ]).
Since
Pla ([s0; : : :; sm ; s])
6<
Pla ([s00; : : :; s0m ; s0m+1 ])
0
0
for all [s0; : : :; sm+1 ]  R[true; o1; : : :; om ; ] , [s0 ; : : :; sm ; s] and Pla is prefix-defined, we
have that Pla([s0 ; : : :; sm; s]) 6< Pla (R[true; o1; : : :; om ; ] , [s0; : : :; sm ; s]. By Lemma A.7,
s 2 States (I ; sa  ), as desired.
To show that States (I ; sa  )  minUI (States (I ; sa); [ ] UI ), suppose that s 2
States (I ; sa  ). By Lemma A.7, there is a sequence s0 ; : : :; sm such that [s0 ; : : :; sm ; s]) 
R[true; o1; : : :; om; ] and Pla([s0; : : :; sm; s]) 6< Pla(R[true; o1; : : :; om; ] , [s0; : : :; sm; s]).
We want to show that sm 2 States (I ; sa) and that d(sm ; s0) 6< d(sm ; s) for all s0 that satisfy
. This suces to prove that s 2 minUI (States (I ; sa); [ ] UI ).
To show that sm 2 States (I ; sa), by Lemma A.7, it suces to show that Pla ([s0; : : :; sm ]) 6<
Pla(R[true; o1; : : :; om] , [s0; : : :; sm ]). Let s00 ; : : :; s0m be a sequence such that [s00 ; : : :; s0m] 
R[true; o1; : : :; om]. By definition, [s00; : : :; s0m; s]  R[true; o1; : : :; om; ]. Thus, from our
choice of s0 ; : : :; sm , it follows that Pla ([s0; : : :; sm ; s]) 6< Pla ([s00; : : :; s0m; s]). Since Pla is
consistent with d, it follows that Pla ([s0; : : :; sm]) 6< Pla ([s00; : : :; s0m ]). Thus, by Lemma A.7,
sm 2 States (I ; sa). To see that d(sm; s0 ) 6< d(sm ; s) for all s0 that satisfy , let s0 6= s be such
that s0 j= . Thus, [s0 ; : : :; sm ; s0]  [true; o1; : : :; om; ]. From our choice of s0 ; : : :; sm,
it follows that Pla ([s0 ; : : :; sm ; s]) 6< Pla([s0 ; : : :; sm; s0 ]). Since Pla is consistent with d, it
follows that d(sm ; s0) 6< d(sm ; s). We conclude that s 2 minUI (States (I ; sa); [ ] UI ). ut
We now have the tools to prove the \if" direction of Theorem 6.2.

Lemma A.9: If I = (R; ; P ) 2 C U , then there is a belief change operator  that satisfies
U1{U8 such that

Bel(I ; sa)  = Bel(I ; sa  )
for all local states sa and formulas 2 Le .

Proof: Let I 2 C U . Using the arguments we presented above, it easy to check that UI
is an update structure. By Theorem 6.1, there is a belief change operator  that satisfies
U1{U8 such that [ '  ] UI = minUI ([['] UI ; [ ] UI ) for all '; 2 Le . From Lemma A.8, it
follows that Bel(I ; sa)  = Bel(I ; sa  ): ut
We now prove the \only if" direction of Theorem 6.2. Suppose that  is a belief change
operator that satisfies U1{U8. According to Theorem 6.1, there is an update structure U
that corresponds to . Thus, it suces to show that there is a system I such that UI = U.
161

fiFriedman & Halpern

Lemma A.10: Let U = (W; d; U ) be an update structure. Then there is a system I 2 C U
such that UI = U .

Proof: Given the sequences w0; w1; : : : 2 W and o1; o2; : : : 2 Le, let rw ;w ;:::;o ;o ;::: be the
run defined so that rew ;w ;:::;o ;o ;:::(m) = wm and raw ;w ;:::;o ;o ;:::(m) = ho1; : : :; om i. Let
R = frw ;w ;:::;o ;o ;::: : U (wm)(om) = true for all mg. Define  such that (r; m)(p) =
U (re(m))(p) for p 2 e and  (r; m)(learn(')) = true if o(r;m) = ' for ' 2 Le.
It is clear that (R;  ) satisfies BCS1{BCS4 and UPD1. Thus, all that remains to show
0

0

0

1

1

1

1

2

0

1

1

1

1

2

2

2

is that there is a prior plausibility measure Pla that satisfies UPD2{UPD4. This will ensure
that (R; ; P ) 2 C U .
We proceed as follows. We define a preferential space (R; ) where r  r0 if and only
if there is some m such that re (k) = re0 (k) for all 0  k  m, re (m + 1) 6= re0 (m + 1), and
d(re(m); re(m +1)) < d(re0 (m); re0 (m +1)). Recall that r  r0 denotes that r is preferred over
r0. Thus, this ordering is consistent with the comparison of events of the form [s0 ; : : :; sn ]
according to UPD2.
Using the construction of Proposition 2.2, there is a plausibility space (R; Pla ) such that
Pla(A)  Pla (B ) if and only if for all r 2 B , A, there is a run r0 2 A such that r0  r and
there is no r00 2 B , A such that r00  r0. By (Friedman & Halpern, 1998b, Theorem 5.5),
Pla is a qualitative plausibility measure. We now show that it satisfies UPD2{UPD4.
We start with UPD2. To show that PlA is consistent with d, we need to show that
Pla([s0 ; : : :; sn ]) < Pla ([s00; : : :; s0n ]) if and only if there is some m < n such that sk = s0k
for all 0  k  m, and d(sm ; sm+1) > d(s0m ; s0m+1 ). Suppose that Pla ([s0; : : :; sn ]) <
Pla([s00 ; : : :; s0n ]). Let r be some run in [s0 ; : : :;0n ]. Without loss of generality we can assume
that re (m) = re (n) for all m > n. Since Pla ([s0; : : :; sn ]) < Pla ([s00 ; : : :; s0n ]), there is a run
r0 2 [s00 ; : : :; s0n] such that r0  r. By definition, this implies that there is an m such that
re(k) = re0 (k) for all 0  k  m, and d(re0 (m); re0 (m + 1)) < d(re(m); re(m + 1)). We claim
that m < n. For if m  n, then re (m +1) = re (m) by construction, so d(re(m); re(m +1)) =
d(re(m); re(m))  d(re0 (m); re0 (m + 1)) and r0 6 r, a contradiction. Thus, sk = s0k for all
0  k  m, d(s0m ; s0m+1 ) < d(sm ; sm+1 ).
For the converse, suppose that there is an m < n such that sk = s0k for all 0  k  m,
and d(s0m ; s0m+1) < d(sm ; sm+1 ). Let r0 be the run where re0 (k) = s0k for k  n, re0 (k) = s0n
for k  n, and o(r0 ;k) = true for all k. It follows r0  r for all runs r0 2 [s0 ; : : :; sn ]. Thus,
Pla([s0 ; : : :; sn ]) < Pla ([s00; : : :; s0n ]).
To show that Pla is prefix-defined, we must show that Pla (R['0; : : :; 'n ])  Pla (R[ 0; : : :; n])
if and only if for all [s0; : : :; sn ]  R[ 0; : : :; n] ,R['0; : : :; 'n], there is some [s00 ; : : :; s0n ] 
R['0; : : :; 'n] such that Pla([s00; : : :; s0n]) > Pla([s0; : : :; sn]). Suppose that Pla(R['0; : : :; 'n]) 
Pla(R[ 0; : : :; n ]). Let [s0; : : :; sn ]  R[ 0; : : :; n ] , R['0; : : :; 'n ]. Let r 2 [s0 ; : : :; sn ] be
a run such that re (m) = re (n) for all m  n. Since Pla (R['0; : : :; 'n])  Pla(R[ 0; : : :; n ])
there is a run r0 2 R['0; : : :; 'n] such that r0  r. This implies that there is an m such
that re (k) = re0 (k) for all 0  k  m, and d(re0 (m); re0 (m + 1)) < d(re(m); re(m + 1)).
As before, we have that m < n, and thus Pla([re0 (0); : : :; re0 (n)]) > Pla ([s0 ; : : :; sn ]). Since
r0 2 R['0; : : :; 'n], we also have that [re0 (0); : : :; re0 (n)]  R['0; : : :; 'n ], as desired.
For the converse, assume that for all [s0 ; : : :; sn ]  R[ 0; : : :; n ] , R['0; : : :; 'n] there
is some [s00; : : :; s0n ]  R['0; : : :; 'n] such that Pla([s00 ; : : :; s0n ]) > Pla ([s0; : : :; sn ]). This implies that Pla (R['0; : : :; 'n]) > Pla ([s0; : : :; sn ]) for all for all [s0 ; : : :; sn ]  R[ 0; : : :; n ] ,
162

fiModeling Belief in Dynamic Systems. Part II.

R['0; : : :; 'n]. Since there are only finitely many sequences of states of length m, we can apply A2, and conclude that Pla(R['0; : : :; 'n ]) > Pla(R[ 0; : : :; n ] , R['0; : : :; 'n ]). Thus,
Pla(R['0; : : :; 'n ])  Pla ((R[ 0; : : :; n])).
For UPD3, recall that the construction of Proposition 2.2 is such that Pla(R) > ? for
all non-empty R  R. Since, by our construction, the set R['0; : : :; 'n] is non-empty for
all sequences '0 ; : : :; 'n of consistent formulas, UPD3 must hold.
Finally, we consider UPD4. We have to show that Pla(R['0; : : :; 'n+1 ; o1; : : :; on]) 
Pla(R[ 0; : : :; n+1 ; o1; : : :; on ]) if and only if Pla (R['0; '1^o1 ; : : :; 'n^on ; 'n+1 ])  Pla (R[ 0; 1^
o1 ; : : :; n ^on; n+1 ]). By construction, R['0; : : :; 'n+1; o1; : : :; on ]  R['0; '1^o1 ; : : :; 'n ^
on ; 'n+1]. On the other hand, for each run r 2 R['0; '1 ^ o1; : : :; 'n ^ on ; 'n+1 ] there is
a run r0 2 R['0; : : :; 'n+1 ; o1; : : :; on ] such that re0 (m) = re (m) for all m, and o(r;m) = om
for 1  m  n. Since the preference ordering on runs is a function only of the environment states, it is clear that r and r0 are compared in the same manner; that is for all
r00, r00  r if and only if r00  r0, and r  r00 if and only if r0  r00. Thus, we conclude
that for the purposes of the preference ordering, both R['0; '1 ^ o1 ; : : :; 'n ^ on ; 'n+1 ] and
R['0; : : :; 'n+1; o1; : : :; on] are compared in the same manner to other sets. It easy to see
that this suces to show that Pla satisfies UPD4. ut
Finally, we can prove Theorem 6.2.
Theorem 6.2: A belief change operator  satisfies U1{U8 if and only if there is a system
I 2 C U such that
Bel(I ; sa)  = Bel(I ; sa  )
for all epistemic states sa and formulas 2 Le .
Proof: The \if" direction follows from Lemma A.9. For the \only if" direction, assume that
 satisfies U1{U8. By Theorem 6.1, there is an update structure U such that [ '  ] UI =
minUI ([['] UI ; [ ] UI ) for all '; 2 Le . By Lemma A.10, there is a system I 2 C U such that
UI = U. From Lemma A.8, it follows that Bel(I ; sa)  = Bel(I ; sa  ) for all local states
sa and formulas 2 Le . ut

References

Alchourron, C. E., Gardenfors, P., & Makinson, D. (1985). On the logic of theory change:
partial meet functions for contraction and revision. Journal of Symbolic Logic, 50,
510{530.
Boutilier, C. (1992). Normative, subjective and autoepistemic defaults: adopting the Ramsey test. In Principles of Knowledge Representation and Reasoning: Proc. Third
International Conference (KR '92), pp. 685{696. Morgan Kaufmann, San Francisco,
Calif.
Boutilier, C. (1994a). Conditional logics of normality: a modal approach. Artificial Intelligence, 68, 87{154.
Boutilier, C. (1994b). Unifying default reasoning and belief revision in a modal framework.
Artificial Intelligence, 68, 33{85.
163

fiFriedman & Halpern

Boutilier, C. (1996a). Iterated revision and minimal change of conditional beliefs. Journal
of Philosophical Logic, 25, 262{305.
Boutilier, C. (1996b). Abduction to plausible causes: An event-based model of belief update.
Artificial Intelligence, 83, 143{166.
Boutilier, C. (1998). A unified model of qualitative belief change: A dynamical systems
perspective. Artificial Intelligence, 98, 281{316.
Boutilier, C., Friedman, N., & Halpern, J. Y. (1998). Belief revision with unreliable observations. In Proceedings, Fifteenth National Conference on Artificial Intelligence
(AAAI '96), pp. 127{134.
Burgess, J. (1981). Quick completeness proofs for some logics of conditionals. Notre Dame
Journal of Formal Logic, 22, 76{84.
Darwiche, A., & Pearl, J. (1997). On the logic of iterated belief revision. Artificial Intelligence, 89, 1{29.
Davis, R., & Hamscher, W. (1988). Model-based reasoning: troubleshooting. In Shrobe,
H., & for Artificial Intelligence, T. A. A. (Eds.), Exploring AI, pp. 297{346. Morgan
Kaufmann, SF.
de Rijke, M. (1992). Meeting some neighbors. Research report LP-92-10, University of
Amsterdam.
del Val, A., & Shoham, Y. (1992). Deriving properties of belief update from theories of
action. In Proceedings, Tenth National Conference on Artificial Intelligence (AAAI
'92), pp. 584{589. AAAI Press, Menlo Park, CA.
del Val, A., & Shoham, Y. (1993). Deriving properties of belief update from theories of action
(II). In Proc. Thirteenth International Joint Conference on Artificial Intelligence
(IJCAI '93), pp. 732{737 San Francisco. Morgan Kaufmann.
del Val, A., & Shoham, Y. (1994). A unified view of belief revision and update. Journal of
Logic and Computation, 4.
Dubois, D., & Prade, H. (1990). An introduction to possibilistic and fuzzy logics. In
Shafer, G., & Pearl, J. (Eds.), Readings in Uncertain Reasoning, pp. 742{761. Morgan
Kaufmann, San Francisco, Calif.
Dubois, D., & Prade, H. (1991). Possibilistic logic, preferential models, non-monotonicity
and related issues. In Proc. Twelfth International Joint Conference on Artificial Intelligence (IJCAI '91), pp. 419{424. Morgan Kaufmann, San Francisco.
Fagin, R., Halpern, J. Y., Moses, Y., & Vardi, M. Y. (1995). Reasoning about Knowledge.
MIT Press, Cambridge, Mass.
Freund, M., & Lehmann, D. (1994). Belief revision and rational inference. Tech. rep. TR
94-16, Hebrew University.
164

fiModeling Belief in Dynamic Systems. Part II.

Friedman, N. (1997). Modeling Beliefs in Dynamic Systems. Ph.D. thesis, Stanford.
Friedman, N., & Halpern, J. Y. (1994). Conditional logics of belief change. In Proc. National
Conference on Artificial Intelligence (AAAI '94), pp. 915{921. AAAI Press, Menlo
Park, CA.
Friedman, N., & Halpern, J. Y. (1995). Plausibility measures: a user's manual. In Besnard,
P., & Hanks, S. (Eds.), Proc. Eleventh Conference on Uncertainty in Artificial Intelligence (UAI '95), pp. 175{184. Morgan Kaufmann, San Francisco.
Friedman, N., & Halpern, J. Y. (1996). A qualitative Markov assumption and its implications for belief change. In Proc. Twelfth Conference on Uncertainty in Artificial
Intelligence (UAI '96), pp. 263{273.
Friedman, N., & Halpern, J. Y. (1997). Modeling belief in dynamic systems. part I: foundations. Artificial Intelligence, 95 (2), 257{316.
Friedman, N., & Halpern, J. Y. (1998a). Belief revision: A critique. Journal of Logic,
Language and Information, To appear. Also available at http://www.cs.huji.ac.
il/~nir. A preliminary version appeared in L. C. Aiello, J. Doyle, and S. C. Shapiro
(eds.) Principles of Knowledge Representation and Reasoning: Proc. 5'th International Conference, pp. 421{431, 1996.
Friedman, N., & Halpern, J. Y. (1998b). Plausibility measures and default reasoning.
Journal of the ACM, To appear. Also available at http://www.huji.ac.il/~nir. A
preliminary version appeared in Proc., 13'th National Conference on Artificial Intelligence, pp. 1297{1304, 1996.
Fuhrmann, A. (1989). Reective modalities and theory change. Synthese, 81, 115{134.
Gardenfors, P. (1986). Belief revision and the Ramsey test for conditionals. Philosophical
Review, 91, 81{93.
Gardenfors, P. (1988). Knowledge in Flux. MIT Press, Cambridge, Mass.
Gardenfors, P., & Makinson, D. (1988). Revisions of knowledge systems using epistemic
entrenchment. In Proc. Second Conference on Theoretical Aspects of Reasoning about
Knowledge, pp. 83{95. Morgan Kaufmann, San Francisco, Calif.
Goldszmidt, M., Morris, P., & Pearl, J. (1993). A maximum entropy approach to nonmonotonic reasoning. IEEE Transactions of Pattern Analysis and Machine Intelligence,
15 (3), 220{232.
Goldszmidt, M., & Pearl, J. (1996). Qualitative probabilities for default reasoning, belief
revision, and causal modeling. Artificial Intelligence, 84, 57{112.
Grahne, G., Mendelzon, A., & Rieter, R. (1992). On the semantics of belief revision systems.
In Moses, Y. (Ed.), know92, pp. 132{142. Morgan Kaufmann, San Francisco, Calif.
Grove, A. (1988). Two modelings for theory change. Journal of Philosophical Logic, 17,
157{170.
165

fiFriedman & Halpern

Halpern, J. Y., & Fagin, R. (1989). Modelling knowledge and action in distributed systems.
Distributed Computing, 3 (4), 159{179. A preliminary version appeared in Proc. 4th
ACM Symposium on Principles of Distributed Computing, 1985, with the title \A
formal model of knowledge, action, and communication in distributed systems: preliminary report".
Halpern, J. Y., & Vardi, M. Y. (1989). The complexity of reasoning about knowledge and
time, I: lower bounds. Journal of Computer and System Sciences, 38 (1), 195{237.
Katsuno, H., & Mendelzon, A. (1991a). On the difference between updating a knowledge base and revising it. In Principles of Knowledge Representation and Reasoning:
Proc. Second International Conference (KR '91), pp. 387{394. Morgan Kaufmann,
San Francisco, Calif.
Katsuno, H., & Mendelzon, A. (1991b). Propositional knowledge base revision and minimal
change. Artificial Intelligence, 52 (3), 263{294.
Katsuno, H., & Satoh, K. (1991). A unified view of consequence relation, belief revision
and conditional logic. In Proc. Twelfth International Joint Conference on Artificial
Intelligence (IJCAI '91), pp. 406{412.
Kautz, H. A. (1986). Logic of persistence. In Proceedings, Fifth National Conference on
Artificial Intelligence (AAAI '86), pp. 401{405. AAAI Press, Menlo Park, CA.
Keller, A. M., & Winslett, M. (1985). On the use of an extended relational model to handle
changing incomplete information. IEEE Transactions on Software Engineering, SE11 (7), 620{633.
Kraus, S., Lehmann, D., & Magidor, M. (1990). Nonmonotonic reasoning, preferential
models and cumulative logics. Artificial Intelligence, 44, 167{207.
Lehmann, D. (1995). Belief revision, revised. In Proc. Fourteenth International Joint
Conference on Artificial Intelligence (IJCAI '95), pp. 1534{1540. Morgan Kaufmann,
San Francisco.
Levi, I. (1988). Iteration of conditionals and the Ramsey test. Synthese, 76, 49{81.
Lewis, D. K. (1973). Counterfactuals. Harvard University Press, Cambridge, Mass.
Manna, Z., & Pnueli, A. (1992). The Temporal Logic of Reactive and Concurrent Systems,
Vol. 1. Springer-Verlag, Berlin/New York.
Nayak, A. C. (1994). Iterated belief change based on epistemic entrenchment. Erkenntnis,
41, 353{390.
Pearl, J. (1989). Probabilistic semantics for nonmonotonic reasoning: a survey. In Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proc. First International Conference
on Principles of Knowledge Representation and Reasoning (KR '89), pp. 505{516.
Reprinted in Readings in Uncertain Reasoning, G. Shafer and J. Pearl (eds.), Morgan
Kaufmann, San Francisco, Calif., 1990, pp. 699{710.
166

fiModeling Belief in Dynamic Systems. Part II.

Rott, H. (1991). Two methods of constructing contractions and revisions of knowledge
systems. Journal of Philosophical Logic, 20, 149{173.
Rott, H. (1992). Two methods of constructing contraction and revisions of knowledge
systems. Journal of Logic, Language and Information, 1, 45{78.
Shafer, G. (1976). A Mathematical Theory of Evidence. Princeton University Press, Princeton, N.J.
Shoham, Y. (1987). A semantical approach to nonmonotonic logics. In Proc. 2nd IEEE
Symp. on Logic in Computer Science, pp. 275{279. Reprinted in M. L. Ginsberg (Ed.),
Readings in Nonmonotonic Reasoning, Morgan Kaufman, San Francisco, Calif., 1987,
pp. 227{250.
Shoham, Y. (1988). Chronological ignorance: experiments in nonmonotonic temporal reasoning. Artificial Intelligence, 36, 271{331.
Spohn, W. (1988). Ordinal conditional functions: a dynamic theory of epistemic states.
In Harper, W., & Skyrms, B. (Eds.), Causation in Decision, Belief Change, and
Statistics, Vol. 2, pp. 105{134. Reidel, Dordrecht, Netherlands.
Wang, Z., & Klir, G. J. (1992). Fuzzy Measure Theory. Plenum Press, New York.
Williams, M. (1994). Transmutations of knowledge systems. In Principles of Knowledge
Representation and Reasoning: Proc. Fourth International Conference (KR '94), pp.
619{629. Morgan Kaufmann, San Francisco, Calif.
Winslett, M. (1988). Reasoning about action using a possible models approach. In Proceedings, Seventh National Conference on Artificial Intelligence (AAAI '88), pp. 89{93.
AAAI Press, Menlo Park, CA.

167

fi
	ff
fi 
			 ! #"$ % 
'&)( *,+( ---/.1020435062

789:;  <)( */=
->!?A@9	%&<B6/=
--

CEDGFIH1JKMLINOJQP8FIRSCEDGFITUP
JVP/DWFIXZY\[]Y/XZFIH_^a`bXdcEeIfgDGKVfihkjl[mKVDinWfgK

oMprqsqstvuwt'xysz1x#{|x

}~1$G~$}g~O$1~$)

l
  )
 8A   $  g/8/    
 
O'  

sA

GgMMv

g

vsV
)! !A

ssslA$A 8
)s4 Ws4;44gl/4s
Zl/sa/4!ZA;ff;!sa;48l!4
s
ss!BAO4
Alas
I$4s48s4 WsW4U !8WABs
4GAs

4ZsA;lIs)A
GAZs
/W!AV/44a 
A8I
4IV#  4G4s8Vi!4Ms$Z4! 8V4isrsaGl8 5
A !A

$vs O
rsv4v|4O5m4i4B a8;/s4 s5
AaOs4|
WrA!AOgA4
GsslAAB5mvff;sV4MVaA4A8Wff
4Gl GA#44 lAss44g/s48A1sB1
Al 4/sl4AA
45GAIl slAssa58sI88AIAB4/sa44A
a4As8Q48sO
Ags4AsB)s8Offs8s)5Gss
4/4485s4A!4BAg/ssrAsZs8Offs8s5GAsQAl
48;/4a8
A484s4A!;UGs4W'4s!
V ;,i 
ZW1/
	fffi	ff

	fffififffiff fffiff !"#
	 	$"#%#&'(!*)+,)
)  
fi /-.	/0	1%Q	802$34	5fiff6Q05	fffi5+ff/	ff/	78	'0ff+9:	ff 
fffi))020ff/$!Z/!ff !;	'<-=5$3O)fiff+%	 />?	@ff/Afiff+AB
	55 0C 	5>(DE1
 	69 lF $ ;= Q05	fffiD6/ff 	ffG	/|H  ff U
 !ff !	!&I
ff/+/ 0!1
- 50*3C4	6$/ff 6(DJ	// LK'0 #ff6!&!/ff )M5G
) 0/
	 =	AG0	55
ffMN
 = 0ff !
& /ff 	% +	A7L*)+O"P	/ff )|H  ff !?$/ff G	'	!)M	*&Pfiff 	5ff /ff 
 	
 Qfiff 	ff 3
R Sff@	T8 	 BU/ff V)DW0	WQ
% /ff U1ff@	TX	ff B	Z
Y ff  	
|
H  ff !1	,7P*)+@.	2Z	 "/ff fifffi8/ff /I
 	
 	;fffiQ
% ,I  05	[3\]C/ff Iff 	fi7
$fffiT*2 M%L^ ff
_Q"*/ff 	ff
`, #baG
I PdcP"fffi/	;fffiD	/ 0	$"/ff N 0D	ff !O/ff 	ff
	  02 
ff/I	
 Q?./ff ,ff 	=P0	ff !@C_Q$
3 Z0/,;A 5 T F  
 Q05	ff !/ff 	ff
	  02 6/ff M	Q%e/ff 80	/ 036)
f  B	5ff 9/ff B	
 	2 ;fffiIQ
% !ff 	#ff  #ff
:	ff gN/ff h)M5$3I_ =	1/ff 	ff,	  02 g/ff $8	65	&Lg/ff 	ffg-5fiffTifffii #ja"O6%L
^ ff,_
gffg/ff 0/hifffi. PkcPM
" 5\
7 l/ff h%L^ ff0"e-=m	ifffi5	/ l0	$"O	l  l/ff h%L^ ff,m!ff03
R .X!*)/h/ff B
 	$" Pnch;2L !ff i!&'!C%L^ ff+_offi5#pa3
q fiff./ff $m rff.)M 7sW!ff !	G
 	 	i
% t0	 DU ff.s/ff $l5 	fiffvu
AAff 
 rff;=	 ff 	<uw5$0v=	
 	5	!."P/ff  0D!&P 	8C)
) 8  	B
 Q0ff	 
%QfiffOQ
% 
 |H 0	ff QI/ff i	;	!5!/ff yxezh{N|~} q 0_T fiff 06+ r%=!fffiff0"LaLa*Dg
3 Z
	!5/ff fiff 	 ff g)+!/ff m	l
 = 0ff =	m/ff 	ffI fiff TM  5ff !/ff h	6	m/ff 
ff 	efiff 	ff 3;4N	;	X i%P&?%=	 7Pfffi5	 7L? 	5Ov
3 Z$, /i6	AL i/ff $ 	58



( ---O %%=!<4Z
<B/
MV
!fi:g
N9!	%&%		s&/%1%/ <

fi+!=

fi 0 ;05fiPLfig ;!0fiM$9Lfi !C5 fie8fiIX<=
i 9PBrfi L0.0Ee05 !m,fi  ? ,lL  ?0D !lgfimfi
:<=9!06 P1efir NL= e0M0e05 !#A5.fifi5r Q
 !;D05
B !;V!D! A@ghN:C0@L! $gS/C*0`O`$
:G5+JM0=MLfii5 <w508!5! AM M=iL! !
0m+?0fi05A p8! !! Gfi fi '50 fi#fih0Dfi58 
*/fi005=!fi05 + GNA 55?h fiT!5! A6 L0G! /L
 != !5 r =ie05fi;+ ?A g ig ,#fi L'fi
!0fi$V@#fiP85  Q!I! !!1,$T
 0 8 8!fi05 !Q 0e5l0 5r/C 01P.0o/5l+ 1
<e0 #Ge  fieTfi, +!fi0D ! A0G;6!0fi++
00 i`@ e+! .$fi rfiL/eiX<=!O
 s =0?Mm50i! !X  lfifi5?er',L!0,
 fifi@9LfiALfi A!D! A; + L,L! eQP!0dL
! e/BfiAfim fiA fi=!. !005M i1=
PhT 0@vDL8 M=Q:fi 5$L*DP8Q5r6M h=
Pi5 v=!i!5 A:,fihPA$
PCD   fi@G AA0 .05
X50M !' i5fivw50 0fi.!''VPA?!NM@5#fi@V? 
 '0!# !L   ?XA 0 fi# l! !=1 V fifi5fi
fi*@efir ;('0!#A!Ar  !O+i'0! P! #fi0 0'+! 
 ,5r+50 ;6  fi=!D! A;.0  0$=?:,fi8bPAOO
Mh fiN 6fi5  g ofi 9e! P+fi,fi0 G=X58
 ' e ! !N! =@ !G=,Pm  v==!]m!D! 
Mie, fi!IifiA L0$N/*M00= ; DfiI ,0fi
 .  QL!0+1! G.hm  v==!]B5!8(5!!
 ?+ A / fifi5 fi8N ge!LA!  / !b$fifi 8 
fifiIC! !fi;0  !'P;e!8fi I!!]'0 ;TC
N.P  fi=V    fi5 mB0fi'~:mfiP?e05Z
 !+mie!LA<w ,0D<=0 !l g e05 gm hl50 h
+mfi   'X  h! `fi fiQM !$=*M00O#!gfifi5 
B~vX 1 X1==g 5 T.'Q !+# 0!iXL0fiB X
VL0 !l Q5!0, [g!fi0D !l## <0DI#$B ! !
8  gTC
 , efiT1 DifiA! !== M i.fi5  !?fiAh
  $ =! /05! !@6  v=!'C e ! !eX58M
 =!We G0 gPfiD Lwe#r <=IP!(586g# <IMP!
X5Q55fi05!0? '0,; 'e!PA6!0D55#:M$ Gh  Gg5 
M!+ e ! !(DQ/55fi05!0g T AN g!!A0 TCP
!O 8fiD lMP# <lM#V(DQ8/! m  rI.0fi 
!(8 ?!!0 h6 m/QM'+6 ,60fi05A.fifi?fi ,X
 !9?I   5$AM0fihl0Ifi 5L!]rw 0 0 A 5
 !. 0 h+?e!LA$ fi5  !1(  !O=fi? e ! !
  fi=!/+/(5!!,fi?fi!8!+P@1!D!  +=   (LA 5!# 
9 e ! X58


fi
	fiff
ff

ff


	

"!#%$
&'$(#)+*,+-.)0/&.1*2#435&.,+67-88-9:,;=<>1@?A#4BDC0*-15EF9G#=3*,0BH
,0,IC0!#J)fi#4,0H8C0,K-1LC0!#MBD-N%$
HO
C0&'C0*-1&.8PBD-NQ$
8#DR*CTS=-.6UBD-1
3*C0*-1&.8($8&.11*1/VA9W!*Bfi!X&')0#+C0!#YNQ-.C0*Z'&'C0*-1F67-.):C0!#[&'$$)0-&.B\!F9#
!&]Z.#YBfi!-,^#41_;:?A#4BDC0*-1X`J$)0#4,0#41aC0,W3*b(#)0#41aC:C^)fi&.1,08&'C0*-1,c-.6dBD-13*C0*-1&.8_$
8&.1
1*1/[C^-MeAH&.1C0*f
#43
g --8#4&.16h-.)fiN[H8&'#.;i"!#cNQ-.)fi#G/.#41#)\&.86h)fi&.N%#9G-.)0jY-.6BD-13
*C0*-1&.8$
8&.11
*1/:&.88-]9:,iNQ-.)0#c3#/.)fi##4,
-.6U67)0##43-Nk*1lBfi!-A-,0*1/=9:!&'CWjA*m13F-.6U$8&.1,:&=$
8m&.11#):$
)0-A3
HBD#4,;"n#QBD-1,0*m3#)o&M/.#41#)fi&.8p67-.)^O
N%&.8*24&'C0*-1Q*1[9:!*B\!*1aC^#)\1&.8,^C0&'C^#"C^)fi&.1,fi*C0*-1,p-.6(&I$
8&.1&')0#"3#4,0BD)\*q(#43[&.,pfr1*C^#c&.HC^-N%&'C0&V&.13
8#4,0,"/.#41#)fi&.8_67-.)fiN%&.8*24&'C0*-1,s9:*C0!tN%-.)0#u)0#4,^C^)\*BDC^#43tC^)fi&.1,fi*C0*-1v6wH1BDC0*-1,4;ix-.)W&.88(67-.)fiN%&.8*24&'C0*-1,
9#+$)0#4,0#41aCWC^)fi&.1,08&'C0*-1,"-.6d$)fi-.q
8#4Ny*1
,^C0&.1BD#4,WC^-MeAH&.1aC0*f
#43 g -A-8#4&.1X67-.)fiN[H8&'#.;"z{eAH&.1C0*f
#43
g --8#4&.1L67-.)fiN[H8&tC0!&'C[*88H
,^C^)fi&'C^#4,IC0!#MC^)fi&.1,08&'C0*-1,u*,+/*Z.#41L*1|?A#4BDC0*-15}A;tn#v!&]Z.#M,^-8Z.#43|&
1AHN+q(#)c-.6d,0*N%$
8#o$)0-.q
8#4NJ,c*1tBD-13*C0*-1&.8($
8&.11
*1/[qSvH,0*1/&%C0!#-.)0#4NO~$)fi-]Z.#):67-.)I g x|9#
!&]Z.#3#Z.#48-.$(#43_;W"!#+C0!#-.)0#4NQO~$)0-]Z.#)u*m,:q)\*#D
St3*,0BH
,0,^#43X*m1?A#4BDC0*-1M&.13lC0!#Y#DR$(#)fi*NQ#41C0,
*1X?A#4BDC0*-1l;xi*1&.88S.V*m1X?A#4BDC0*-1l[9#+3*m,0BH,0,s#4&')fi8m*#)c9G-.)fij=C0!
&'C"*,c)0#48&'C^#43FC^-%-H)fi,;
iQM
TU(a

 H&.1C0*f
#43 g -A-8#4&.1t67-.)fiNYH
8&'#u&')0#K-.6pC0!#K6h-.)\N'^04ifi4a
l9:!#)0#u*,s&.1FH1eAH&.1C0*f
#43
I
$)0-.$(-,0*C0*-1&.86h-.)\NYH8m&&.1
3C0!#t$)0#Df
R|BD-1,0*m,^C0,Q-.6IH1*Z.#)fi,fi&.8G&.13#DR*,^C^#41C0*&.8:@eAH&.1aC0*f
#)fi,
 ]   &.1
3XC0!#[$)0-.$(-,0*C0*-1&.8Z'&')fi*&'q8#4," D   C0!&'Co-BBH)K*1lP;IW#Dfr1#i c&.,oC0!#

67-.)fiNYH
8&IC0!&'C*,U-.qC0&.*1#43Q67)0-N=qAS[)0#$
8&.B*1/o-BBH)0)fi#41BD#4, -.6rC0!#"$)fi-.$r-,fi*C0*-1&.8AZ'&')fi*&'q
8#cMqS
C0!#[6h-.)\NYH8m&JW;u"!#+C^)\HC0!-.6eH
&.1aC0*f#43 g -A-8#4&.16h-.)\NYH8m&'#[*,o3#Df1#43X)0#4BH)fi,0*Z.#48SF&.,I67-88-9:,;
"!#C^)fiHC0![-.6r&I6h-.)fiN[H8&WC0!&'Cd3-A#4,d1-.CdBD-1aC0&.*m1Z&')fi*m&'q
8#4,V'C0!&'CU*,4VC0!
&'CiBD-1
,0*,^C0,i-.6C0!#cBD-1,^C0&.1C0,
C^)fiH#J&.1
367&.8,0#%&.1
3BD-11#4BDC0*Z.#4,Vp*,K3#Df1#43*m1lC0!#Q-.qZ*-H,I9s&4SqASXC^)fiHC0!O~C0&'q
8#4,I67-.)uC0!#
BD-11#4BDC0*Z.#4,;cz67-.)fiN[H8&JA(*,cC^)fiH#u*6p&.1
3F-18Sv*6diup-.)oiup*,"C^)fiH#.;Gz6h-.)\NYH8m&Yr
*,C^)fiH#v*6W&.13@-18S5*6Wiu
W&.13iu
:&')0#tC^)fiH#.;dR&.NQ$
8#4,-.6:C^)fiH#FeAH&.1C0*f
#43 g -A-8#4&.1
67-.)fiNYH
8&'#[&')fi#+r(A_7W&.13A(A_7Jt\;u"!#[67-.)fiNYH
8&'#Q_7W&.13Xr(7%t
&')0#W67&.8,0#.;Gs!&.1/*1/KC0!#:-.)fi3#)G-.6_CT9G-BD-1,^#4BHC0*Z.#WZ'&')fi*&'q
8#4,eAH&.1aC0*f
#43%qASC0!#o,fi&.NQ#WeAH&.1C0*f
#)
3-A#4,K1-.Cu&b(#4BDCuC0!#QC^)fiHC0!O~Z&.8H#[-.6C0!#Q67-.)fiN[H8&;+<>Cu*,I-.67C^#41H,^#6wH8pC^-F*/1-.)fi#QC0!#-.)fi3#)fi*1/=-.6
BD-1,^#4BHC0*Z.#IZ&')fi*m&'q
8#4,&.1
3JZ*#9#4&.Bfi!teAH&.1aC0*f
#)G&.,seAH&.1aC0*6hS*1/[&Y,^#C-.667-.)fiN[H8&'#.VA6h-.)#DR&.N%$
8#
A        ;="!#J,0*2#%-.6c&leH&.1C0*f
#43 g -A-8#4&.156h-.)\NYH8m&tB&.1Lq(#J3#Dfr1#43&.,uC0!#M1AHN+q(#)u-.6
-BBH)0)0#41BD#4,"-.6p$
)0-.$(-,0*C0*-1&.8rZ'&')fi*&'q
8#4,c*1t*C;
"!#=*1C^#)0#4,^C*15eH&.1C0*f
#43 g --8#4&.1567-.)fiN[H8&'#v*1C0!#MC0!#-.)fiS-.6:BD-NQ$
HC0&'C0*-1&.8sBD-NQ$
8#DRAO
*CTS,^C^#4N%,u67)0-NC0!#%6w&.BDCYC0!
&'CY8*j.#J$)0-.$(-,0*C0*-1
&.8d,0&'C0*,f&'q*8*CTSlBfi!
&')fi&.BDC^#)fi*2#4,C0!#J$)0-.q
8#4NJ,u*1
o VeAH&.1C0*f
#43 g -A-8#4&.1t67-.)fiNYH
8&'#I9:*C0!t3*b(#)0#41Cs$)0#DfR#4,cBfi!&')\&.BDC^#)fi*2#+3*br#)0#41C"B8&.,0,0#4,c*1vC0!#
$(-8S1-N%*&.8i!*#)\&')fiBfi!S g &.8mB_'& 24&')Y#C[&.8;VG4..}\;F"!#%BD-NQ$
8#DR*CSB8&.,fi,  BD-1
,0*,^C0,K-.6c3#4B*m,0*-1
$)0-.q8#4N%,IC0!&'C+&')fi#J,^-8Z'&'q
8#%*1$r-8SA1-NJ*&.8pC0*NQ#QqAS&X3#C^#)fiN%*1
*,^C0*BpH)fi*1/tN%&.B\!*1#.; W *,
C0!#%B8&.,fi,I-.63#4B*m,0*-1$)0-.q
8#4N%,oC0!&'C+&')0#%,^-8Z&'q
8#[*1$(-8S1-N%*m&.8C0*N%#[qAS&t1-13#C^#)fiNJ*1*,^C0*mB
pH)fi*1/N%&.B\!*1#.;U"!#oB8&.,fi,cBD-'O W BD-1,0*,^C0,s-.6PC0!-,^#K$)fi-.q
8#4N%,C0!#KBD-NQ$
8#4NQ#41aC0,s-.6p9:!*mBfi!v&')0#
*1 W ;(<1l/.#41#)fi&.8V(C0!#B8&.,0,IBD-'O>BD-1,0*m,^C0,:-.6G$)0-.q
8#4N%,"9:!-,^#QBD-NQ$
8#4NQ#41C0,I&')0#Q*1lC0!#[B8m&.,0,
o;
:!#u$(-8S1-N%*&.8_!*#)fi&')fiBfi!S  *,:&.1l*1f1*C^#K!*#)\&')fiBfi!Sv-.6UBD-NQ$
8#DR*CStB8&.,fi,^#4,oi .VrG .Vr&.13
  K67-.):&.88(GC0!&'C:*,:3#Df1#43vqAS=H
,0*1/-.)fi&.B8#YPH)\*1/QN%&.Bfi!
*1#4,"*1vC0!#K6h-88-]9:*1/[9s&4S.;
  
i   

oG

  
G   


BD-'Od  

  
    

i\cP~'fiw~^o\~'>~]sfi4\~"~p~\cd\fi~\\
]


  

fi:










ff
	



fi

	












fi

fi





















fi

	



"
	

!

fi


$

%
#






&


!


'
(


	


)



&





fi
fi
$


*
$





"
	

	




	



+









/
,

.
+


!


0
8
7

>
1
+
!
fi/?"	@ +	2
.fiff-3,/
.4+
!+
093
5+
2!&fi
<-!	;6
>! 
+
 +85
.3fiA9!
fiff	ff
C4
BD,: .-+!&!'
0)-;,/
.++!!0Afi:<-
!+	!&=.fi	
$!fiT*$S/UWVY	(X 	Zff[] \J	E<)	FG>^_FHIF`IJ
L+Ka-b/	ffcdfiff$	 fiEefaJ
b6(L
99
gFh1
fi"!	M!HBC
fi<)fiff!fiA	H!&`$=	fiffL	
IN=	)FY$==fiff	?!OP
/!
+% +1RgFQ i
!j

%k
fiQ|j;} fi)!M		4L
!filfi+fil>^m~. $9	!I==`Fn N=j	!&
 I		!L
`;IoLX $p=qrLUffs p.tL	ffZff`t+[ !uhvwyIx$=zt-Fn	ffG=!	{%!
	k	!	L!fic%=5`
l	
 
	fffi+!
;fi+
( 	!!	=fi!J=.D	AQ
|Y	ff Q)gW?2\JOi4}
Q_%!E
!fiAS/=Uv1s Fo-%!8ztft"}!%Q!	/| I?M=H0=fifi2	ffFA		 (		
fi>fi8J^.
$	!=!fi^8 Nef8 !&fi+ ?
J	
8a,(	ff1b8.m		ff+j.
 	3cYJ


+>9Y.<).
! N	;	!#<)!$	A#8*4Y%=$ #
*95g
 + 4	.  !fiA<)8
!%$	ef$=D	L!fi8$=	ff$G#L*!"Y	 	ffJ>
 8 $ ;ef!fida)mb8$m="
 	ff?j+	ff; 0
	!=
fiA+

 c
Y.
g	!#+fic
  ef$=L	ffAJ
(+$#*Yfi)N  <)!	TdA
	ff1 	!=fi?
2G>:8yydL>:y=ykI)>fI"W


	Fn!&fifi>!fiEfiff!&fi3$		ff!l=ff.fiff<8	!`JF>


TFY
		!r` 	ff$=L	$ *n!	WF+=

+T$=	ff>$!=	!=!
	!)=

%%!&
0?m!,(09<8h
.
I=	fiff? ]
A	
#%

T=Oi

 	fi).+N	ff
]FMn	ff
+h

fi=0

 
+	ff+L!		ffA+
$=	 !		!!	ff=fifffiff		

fi)Y	$&
9filfi	ff M!	!50-fiff
#%<"+ 4=..!!4 	fFGL!
3hj	ff	J
L=I=fi<
!	IA!==fi
!.
		ff!I=E5


+/4;.
Y0=!
 ;?Ecd

T`\fi	

Y<  c
	J
+ 9	E.	 !&AfiE
4=L
1fiT.n>!fiE!
g	E	EJ0

fi!1

?/!	fFHMJ

(!	!=+fiffcY=g.	!&E0Lfi$.=	fiE!!	!=!
 I	ffl
	 	(!&Y0.? 
N	!#M8Y=

	ff9

b"NfidFL

a-Ib!=ef$Fn0=LN=Ffi! 
	ff	g-!&fifi#%! 

c
!I&!	fDFL=!!fiL0=fikI
	ff=fiffFn	>8==;$=!	L
Y%	!~$
*n$
!	"	f?2F	O ;
	3afi+fi:bj
aeffi$b/fi+=!c 

&		ff
)+!
5
0cg3<)
J4
I+<-fiff	ff	ff+!+
+!$	fffi+	>	ff	ff

0=A! fiff?
1

.	ff$>
!TNY	)
!`fi+!=\G

=niE$fi.<	fiE! fi3	3		ff+A
fifi&	 !fi	#%! 0%!!
	WFLfifi
!:
J
+4&
. !A0!H	ff4	J
+4
.I =lfi!!	G!=	
 

fifi
!I0==fiL!	!=N	fiE

2
	0=!l!fiEfiff
	ffI+=
fi!0=!	g!=	ffJ

<35 
++4?".Y=A.!&	M!=N;.%fi
	!=fi3 ? 
	
!M
fi(fi 	!fiffJFn!04	ff+.	ney 
.
$=
	I%Hfiff=fi	ff>0H<!	ff	MfiE		# +	9fiff	($<)=!	
y?	iL$*>,(!	fF`!&fiEfiff	ffL+
!&fi$fiA	
!a=fi(b		ff]\~
	)fiIfi+=	.Fn!9=0H !&	
j fi	!	I=LFn&I
==fiAFY$!&==
ey	!!
!L	/!=!	ff
++j
 +fi1&&
g Fh	!=!Y0Hfi3fiAJY=
 fi	
$fiff	ff=+
!0=!	g!	ff=J

<3n +
T	ff+!
0fi	ff 	!=
fifiEfi+! +
$*n
=!g0	!

y?	ff,(A
I!N=	fi.!	!	!=!

nfi
 fiff	=!&fiT#%J
)!&$!	f=F
?/!	
!=
	%(fi
!fi!
0 
I	!0
=.1!	5fiFn!!30Ha!b`I!fi2=	Fn	j=!

:	!;Lfi/L!&	4a 	b!	

$	.E
fiff=F`
!fiMNF9fiff=0=&..	!fi=fi!?L0l

#%!! 0>	ffETfiff=$=.	!=!	L!=

 



=	2!(90

L0=.+
YfifiII
J
!+L 	ff39!A&
I=Fn.	2=	fffiff!	
!=	0!L	
 c=	
fi/		E3N
.9<8I
k'n
fi.!+2
g&	/!!++..fifi		

$$fifi
!	(!fiEF>!&IHl0
$*YI=+
kN	
!	E
I5=
Mfi!	A	fffi!lI
:J
	+$=
!	R!=!
fiff	

$
?!,(04NfiffFH$=fi fi	!!fiff#%1  	!!=!	fF;fiE
fi.0
0

0
1!	fi	EM	?  	
(
,


M


	













I








<

fi




<
L
fi

	




	

	


M



















l





ff
	


+



&
!



!


h
0
)
<





	




L


	


T



0
=




(








I


87 
cN1
;;J	=J

E+F!
!	F!
n!'
fiff	 F	ffl!fij=
	(
LI	9)IL=
fiffI	8	$=L$=L$*$*
!%	fFL
fifi+!fi"a	b/)?N,($=L)$
*+!	WF %!&
!	WfiF fi

/	0
=
J=
!!	!
fiff	 	fffi-!fi3Y.! 
g	3	ffL	$*!fiff	ff$
/$=!	!=

fi"=F;J


u







fi8%+NNn%%=
n
GL$Lgffffh4$$$nLn
ff3T+$]$
=l
A
ff%==+
" /ff
hk
$=`&
$

=+)
]
%
&;
j5
2>


/(ffL 
ff;
ff`Eff1ff$ ffff;nY
ff;A

k+>$N=
=~l 
+
8=N8ff
 
 +8 
f3+

$n ff
4$>

; ffj ff>ff $I;
(g :

+($
=+%ff;
AJn

 
ff; ff LN;4A 

$=$+ 4+
TgM "GH
4$(nff  8$

T$=)= I
dN&)
)+J
l$ffn

$- ff->G`$=-=
l
I=
T%ff  
8
Y)$
$ )
(=A
2A$=N(
EN
+  
$

ATff==










	




fiff



ff
ff

ff

ff





 "!$#

	
%&('*)+& ,	%-.%/)+& 0+132 10+&4&4%&56%7809-.:;%<2 1>=?.@4A;BCA;DfiEGFHI=J:K=L@M%7
0M7N=-O)QP61R%-S=:Q0	1<7UT'HV0+:W0X'N-S=:;%>YJ%&5$-HI=Z%&4%-.%/0+1[7-\0X-S=7S]^8_G=J_G`;=J:;7Z)WPBa0+:K=b2I0	%:;7dcfe
ghTS-HI=
);2i=:Q0X-\)+:*7]bFHi=J:K=jc(0	& ,Cg0+:K=fi7=-7)WPk1l%.-S=J:W0+1l7*^m0+& ,CDn%o7081R%-S=:Q0+1pTS-HI=q5)N0+1 ]+r
# 2 :W)s`1=_t%&i7-\0	& ';=
u% PmP)+:b=Jv	=J:wx%&4%-.%/0+1y7J-\0	-S=6Tz0C2{:Q);2i)|7;%.-.%.)	& 0+1m_O)N,s=1 ]8}
7;~4'H-HV0	-y}
 h@-HI=J:K=d%7L0b7N=KN~4=& ';=sNAAK|)QPC);2i=J:W0	-\)+:b0;2X2 1R%.';0	-.%/)+&i7O-HV0	--.:W0+&i7PJ)	:;_-Hi=
%&4%-.%/0+1y7J-\0	-S=L}
-\)90x7J-\0	-S=L}"7;~4'JH-HV0	-}"p DOr3HI=0;2X2 1R%/'*0	-.%/)+&u)QPmceg%&6}k_G=K0+&i7
-HV0	-}   cU0	& ,PJ)+:-HI=jPJ)	11)+Fy%&587-\0	-S=} > [ g0+& ,[P)+:0	11I2{:Q);2i)|7;%.-.%.)	& 0+1yv|0	:;%/0s`J1>=7Z-HI0	,X)8& )	-m)N';'~I:k%&xg+^3}   $% Pfi0+&{,)+&41RwG% P} >  r

( 



+




P





(

J








N


Y





N








8
Y

=








T

J




+

4






)




H








G






+





E
















$$>L
l$=G===
jA

ATN1
g % ]4J
+>45
+>4ff ]4Affff++ ;JE
A

:=ff+ y8 
>J
  
ff
+
2 ] + N
NA 
AJff
 +4LI`=+
 ffff];
ff+=ff+ff
+  yr
&Tl
ff];`$ffnffffg
r +
&  I

4 I  ffI

ffJ+=L )
 ~
(ff
;
9
+
+
j  +& 
/A ff$;
ffI>=
ff]ff ~
I$9T N>$

3j
ff ff1> = 
 (
+=8M
lN$nY&ffff
gN& 
%  8+N =%
8ff+5
+ 4y 
8 ( 
l N)
g% ;KJ
$=+4+ff9ff+
 

`
ff= = 8$==ffffffff+1$$>   
 LIff=
Y$= K

h&L+H = M 
-ff+
 L 
(h=4 ) 4R
 
ff)ff+ ;4$n&ffff$4
ff==)$==
d
-" f +  %
)

4 =T


TI+ ff
&+ 
ff ff
 I(r$ n+& ffG ff T
-  
+9 
%NM r
&ff+

 ])r )+&ff + 
k 
4ff
~)
ff
 (
 
I -
&1; ff Y+;Y$n$-l

=I
d+d ff

I+ 
ffE glff2+

 ( Nrl 
+&I +  ff
A 3GffL+
g3
~ 
Iff
J
+9 - -I 3EffJ
+E 
nI

 =Lg8
:Yff+y 

8ff






l

J




+

4










ff +

  / 

NGM&ff 
ff ff %   ) &   -4 4ffIff$+
ff+3
Tyr

+=)LJ
 N3
:ff1
L V|V

2 10+&4&4%&5%7

3Hi=82 :W)s`J1>=J_)QP=KX%o7J-S=J& '=Z)QP97J)	1l~i-.%/)+&i7CPJ)	:G2{:Q)s`1=_%&i7-\0	& ';=J79%&';)+& ,+%.-.%.)	& 0+1
+ HV0+:W,Xr

 :W)N)QP

ff



+






x

C




I






ff

dff

I

+
U



+

O
q


ff

	

	
	

+

Z C


J 8





I

M
	

d

9

N
4

x 3KiVI{;	[fff


ff


 
ff

 J Lf?.@4A;BdA;DE

Dh"70	-.



|j7J0	-\A;  ANA;  A;y  AA;WA*	XA



[eIAA*[e	A.NAAK  e70	-.

@

B

   eW	A;V \36|o
+





[e 





JAA*;



m 

[ANqUj X
+

8

+

m 



 

j b
	
fi.  ANAK  e7J0	

+ 
	
clcqG c  
9\ ce  A\ec  Al ce   A.  AK e70	- 
I
CAAW
CVI{*	q
}
Q m@  ff}
I
    ANA*  
b3AAW
i
qIJAAW	
me|A;y



fii 4X

	biW*O>4N((C38K	8xWNViN4J9JX4K>WKoiZ	qI	J>UiXW{;+W	*
   !>#"pN8VG4XWq{;+W	*$ &%(' )  K4*b4++$  
fi 	4
	ff
fi K48+fi
 fi,- 		$  ) 
fi 	4. fi0/132546 	487 ! % N %9:
41 <;[>=VX  K	K3?	N
ifio4K>{WK+WA@
WGOKK+WA@B*4*+<@CED B41 GF+4K	*IHJ4	OK >iKX
K KK4OIHL4	OW >iK>XGF3?			*KX4CNM*Nb	W;iPOQ=+>iNmWSR3NN(RN{
T@
U4*{X*KX44OVi6{K4G+V@
D 0W 	48	XZY \[^] (_a`b@
D  R fi dce fi 
Wi@BK4x4+j@CaD k41 
-Z fg""i*>GWNViN4JLsK+	y*+W	*K3?Voih@
l 	L!mY n[^] (o`8	KKX - W 
fi  Sp
fi Vi;k>6NNK		*Ciq7*Wb$ fiV
% '	)   	4 /12546 	i*">W	Vr>mN	WWbi#""4+4fi	KKXCNsWhR  (R N  
   
s
K+K>(7NMt[uF+4K	*kf>mK+Kov7 +	
w

x X
 4KX4>	4>ib>q>Wi84+*i	4K	NGX6iOKNJX4y=	6	piq{ >^O
iXOoz4*+*s	 l 	JX44>KX4{>		 IiXO>{K}|k>>N	WWGig"4+7{44>id
>	o>ikJX~I>S>	Kj: F+ib4KV	 omJX4WW;4JK>iOO4X4iW*Oo4>WK>jFi*>i
O	4>i4+*44> IiXO>{K>Ok	44WN	x	*	k	q4K	N>8fj F+iIFi*>i
O	4>i87 *WCXiNKKN8y IiXOoNi	UWW;>i4+8K4KNWNKG	44>+W>	F+i
	*	iNO*4N?I"Miioi	W4+444WXC;4OWK	4JNi	X>j	4i	
KN	iN:F+ij	*	>3*4KNWNWNLkqiX44W*O>4oWK>:Fi*>iO	*4oi4+XiNKKN W;iPO
=+>iN	!JXK>i	Nj.	JKb.>G4X4iW*Oo4>WK>T IiXOoIK>Cg  	4G4NOINiWNi
>	.>4W*O>4oWK>A{ >ViXG>3KoCg[	4	J4K	XKK+WS"p	fii	KN	*4N~F+i
JX~4K+KXb	i	;	[ojN+O>hfj K pXiTF i;>ifiO	4>i*44j>biX4iW*G>4>WKo
 IiXO>{K>Cb"	fjU	*	  ib4K	NW }=	N>>a |
F+4bJX~I>SZ	o	KK>>	4>i>A?Ii#"M>iK	!/ypP>	4i8 ]6 Lig"L4+
>	K*>z>	4>iC>7 WkiXO	>>+TP K xT OSJX~W	 X*K!oS8	W;	JK+>	44>4
444KVK	JK>mKNKW*>JKX4XOi>	d*+W	*G4	yNC>=	NWKX+WNOVqjP>	44	4d
b	
 ?IWWgX 	4f6 ]6 ;+F *	JK+!oS	k	4=	NXZ"8=	KxK=	KWIK	JK>
KNWW;>JKX4
u~~GP:u8EqiGGQ QG{MizGGunzuz mQZzk:E^GQ{


 46=	mi=I>WNLW=	*VW*	>+KX43	JX44>KX4>	44oimW[V4	Kd7NUp N	L	*LZ>+	

F+i*6+*94KW+*+WZ>*KiN>i6W*	4o+KX	JX44>KX4j>	4>iZWUV4	Kd7N
p >N	$	*LZ>+	JF<i7 *W  4+xo8i(4}c{KNbKXW*	>+K>iM>	K*><>	44>4ZW
4KXK>KX4V	X>  >d4bNJV4oi6	INiKX4C	M>	4NF+iJ	KKN{XiN4J"pN
>	INiKX4C	4o	4d>4	d	C>XW	C>M>	KK>Vo	44>i  	dXi>	O4#=	
W=	*[4dcKNOINiKX40F+iWNJX4>KKixoCi*4KNWNK+KXU	b>	4nG>	48+K
	PWNJK4+kO3ZKK+WOWid*+W	*WdVN4WN	bKV4>ibK4JNKW	kKK+W	
F+im*d>KK4  (Nd7 pWU	 l  >imK4KNKNsK+KXG	{V4	Kd7 +KXO#=	!i>4KoVKK+WN
	4	444JKK	osKNN:rzeINJKX4  5V ] 	4  5V5~"pI4*{XK"pS"pV	iX>iC4o
 Z>}?	xoU>	KKo>	4>i."<iK8o	4OK>S(NMZWNViN4Jx	q*+W	*G4+
+KkINiWN9JX4WNiK!=	6x	4iWK+W	ifiN^=IKX4ONs+W[N	*{;+KXx>4	qO
X4X4~?Ii#"b>KN	i8+m4j>	44>4fiK>C  JX4KX4>	4T4#=	WCq+WC64#=	
4dcKN4ik4dcKNk*4GWK	4JN l 	I	S  iGN^=IKX4ONskO6{C4}c{KN
X4dcKNjINiKX4	3i	>	b	4G4KON8{qiX44W*O>4oWK>=	NKc{NJKoiq>	
INiKX:F+i4dcKNsy*N(X4WNyKNV4*NKX JX44KXP>	4y	G{+	4ZNdVCi7 PO
>i8JX44KXz>	4		QNJKj"	osW*WK+Wd4+*NJK[ii*KNs[	4xN+>

g6

fiV*}yPZd!q g

(3(6	A6P} Z~6	!ei}6MP(6^b(Z3b*6j{*3(be{U>6Z(6z
6SP!!Zjb*Z6(63} SG Z}} Z>!<6X} Zm(I{+S+ *hg
I!(*Zz3( }6MZ*!ZAXiP6} EZgb{*3(*+(S{b>6(6e3
(*h!6>iA!^(Zz(3(
 ZqX6hT ZZ!} Z!Z		P(6b<}y!(*Zm(3(h3*!}*6(Ig
j} Sz!*!Z!ZuZ Z!q{+P(6Z6z  Z< ZZ}! ZP!ZGZ!Z*(6S!iP6} 
 5>!IP!X}}~Z*6(6^Z(3(Iaq!8+( S3( 3<S36+(Z}} (6
 q(*3} : Z*Z!ZjZ6^P} ZS6^  (3(++( S3( h3:6*SX~T X^
(*h!6V<Z!3(*+3bP6(6zV!~}STm Z}} Z!V3*bZ6(6(6
!>6! Z  5>5S  5>5>
 Z.*hUZ!bA}}}.!Z}XM(3(6Z Z(S!Z!*8<3y{
!~{uZiZ3*!!A3*!<!SS~3Z!X3} Za<g#>*!~!X}A6(63} 
VG{ (({ uVZ!} 	 Z6(6!M Z(*h!Z!0(I>6}      Zb*( Z*!
 Z}iZ!6,!Z(Z6+<}8(*!Z}X3(6
 }6,!(Z6Q~iqmT Z*!(




3<~Z}(b(ja3(*+mI*
><h(<


	fiff	ff





 

b<* eZ

A3	Z!(I(:!}(*X

VZ3<(S!Ig!P6} ZP6Z

><S*UZ!h*Z3*( 6!~A!Z}!{(3(66Z
 <S*UZ!~*Z3(* 6!hb (3(66

$#%&')(* )+-,.
#/0ff1)(*$2)+3,4 5!
 6ff789':( ;+
=<?>A@ #%&'0(CB+@ED
@ #/0ff1(CBF+@@ BHG JI
K
LM
NLO
LP -#QRR0(ST+ #/0ff1)(S:+ USVGWLM
X! ZYJ[,\@ ]@
^
/_
ZK
H`
Na/bdcfe;a/gJh
]b
ie
ig
-h

_


"!

ZSZ3e>ZA{h3( SXX~Z!( M
Z
 j<M 
Q aEITz3(*G<

  *Z~Z3U6*{*3(~Z ~!*} 6eZ >S!(6
 I+mX^(*M} Z6(S{*3(*<X6(68>
VZ3a<
VZZ8Z3+
(*3!	
{
MZ
+
Z6~U>>} jS6Z!  
(6!6}i8{*3(M<~+<}8!+!Z{ j
 
 ZZ}} u!(*h!6A~!T!Z!!u(3(6S A!Z3! ZU+S !
6Z}6je>6! Z3M6*Z6jh a(3(  ZX+!6SX+A!<:6(63} 
 ZZ}! Z:!Z!8 >Zd6 V> }6*UZ!3
j<
!b(
Z{ !} Z{33*!3}6<Z3jZ6(6<!ZZ33*!3}6<! J*Z6(6<U!Z}Xz(3(6bZ
I !6Z!6EZ.3!3}6	!
6(6MP6} Z	!Z6  U*UZ!
!	
 ZZ} :AZX3IZ3<*SX A} !m Z6} Z<{V6e{ }} ZT*Z
(6!~X>6! ZZXZZ!}!Z8 3(6
 ZZ* *}} Z3!3}6mZ(6q!U6ZPZ!j ZZ}! Z>!ZZX<36}{6A!  3}

3
UZ6(63} T!X!ZZ!Zi!e~*~V I SZ >6XS v >

Z(6:Z<33*!3}6V 
 Z}
Z{ }} P3*X3}
6(6uM(*
:!}(* :3M!SI{ !^ - jh{ }}I!!(*

uM T!U!Z 
Z8<SZ 3}!}(

v
}\!n!Z! >*3!v3X!}
I
>6!hzA  I!ZZZX} Z{
 ZZee**h!S Z! ~!m(8iZ6 QZgI<}e q*A!P  Z!M!j{6Z(
~Z*}6 6ZPZ! b{6Z. yZ~!y ZS!bZ8P} Zb	{ ZZ.
}  hZi*6 QZgS!I*(!!6 <! e*UZ!Z3U6Z>Z6AZh!}6(
!(6(!ZeXz:Z Z* X*Z!}\!6(6Z^Xe!!A Zz  !  

lFlFm+


ts

j &
Vno p ]bqnro p ^
Z(Cs1+Ep
vu w
xsq,y z(Cs1+Ep{,"btno p |S
fsf,~}Q t(Cs1+Epz,"}{bqno p
(Cj &W
lFl +
_

_

)

k( lFl
%


fi )Q
qr'  
  
  
   fi
   
  
V 
 r 

V R R 
V 66CFFV'&F&'3Zv/R&66CV FR|-66RCR :FQ|R RQ:QFQ E* F*
 $&R&Z'RFR Ri  | R Q&  ;RR&F&R&F
V |'R&FFz&R&;5 q  ZR -6Cfi
V |'R&FFz&R&;5 q  ZR -{
V 6QF-V-RR&|VR6
V 6F'&F3v -VR661/R -AVF-&R&;U1ARvA
FV -A%   Vv/&q  RvR RvR6&'F
6F'&F3VdVfi  Vv f RvR RR
&'FQF-&|FX RV%RR R '|F&F
 Q FFzRFRR F%0 vN  |/

]  'F&' ?Ai   F  FV R|/R  ZR/rFH   AZ|FV&'F3&R&J 
9%f]3F/&&F'R&U& &' / Fv ]AFR H
FHF';- 
A&R fFy -F?RR&
&kA -&' FFdRFR RF3'Q J 
R'&vQFN 
R
 -R&'&Z  &'FRR %
&' F  JR&
RR F5  /d   
FU/N -RQ ;Q A'AU F'RF  -  V RR] $ /R/x= Fd V 
 /R/J %? RQ ]F? &F?F F JQ A'Q RRV& 
; ;R' 
Z&| |FRJ1  qA|qRF&qF1'Zq 'R|QFWAd 6 /R/V-
)FFR% N
 6 )VF'&F'
 AdV9 'R41 ZvAd9RR
6A69 'R1
'v/Z9 '&
1 |9 'RAdvRF&vF1'
1 9RR4A|vRF&ZvQ1'
x
z0
/%90r% x 	x0r%t]
 fffit
  F y&AFCRRNFF'&F-&'A?F F F4 RFV&R&FU  
/R F  FF F|R/-R
FvRR&F;&R&z   ]F&6F   
 ]$FF&R&F R' &ZF/R ; WrF'J] ; ''  
RF&R&5FZ'A3FzF &R&vURR&FX&R& XFR'&q& vQR 
F  F'&F'Z&'
i  Q Ff  HFRRFX F  F/ R FZ 
&dF5F'&F'&N%ZA&dF/  
VF5RFQ  RFd R Ft F 
&dFXF'&F'U -i&'  FF5CFRFd 
&'FtRR&;F5  ZFx   
'RU F'J ;&' F'&F 'Z&$A&?&|&FF ;  
 R
vrFF R F{ R F%FFV ZrF'VN- Z&&
F/R 5'R'&&] FVFR'FFUF3|'R:Q ZRF   ZF&
 A]FfV F V JJF&-yFRRFQF$F      

/R ] %F  RN &AJF;C&RF|F'&F'3F/R R rFF ?F
F';$ &R& $R R Fk&R RF6F'&F'iCR ] 9]F


fi
"!$#&%
'&!$()
*+',.-
(!$(/$0
1324150



687"9:<;=9?>$@)A4:CBEDGF.9HDIBG9JLKF$;MN689OPDGB7G;QDG9@/MRDGF$;@/7EDS7"T$DGF,UWVH9X/T$;BYB"O"F$;:C9[ZH\^]4_`\
YaZHb/Z_cd8e f5ghYSYiWjk_lfmonQnQn?m+Yiqp,_lfrmsYi8tj _lfquvjwmonQnQn?m+Yi8p5t x _lfquvjP_
68A79X/X~}+,QbQbQb?S}S$~Z?
YaZHb^]4_=YiW_ fy YiW_ fquvjwy c p&zae fy nQnQn y c pH{|e f
 A7A~;Q7"9HDSA7"BE@qM[BGO`F$;:C9oZH\/ZHrS"5Y8a_EiWjQbQbQbGiqp.<9M.R$?kWHY8_Ei8tj QbQbQb5Gi8p?t x 4\F$;
687"9:<;<9?>,@/A4:BG9J,BDGF.9HD@)6X/@)DS;Q7"9Xi@qBI69X/BS;<9HD}9M.oDS7"T$;<9HD}ZHDGF$;MsA4M$;3A6DGF.;<Ar;Q7`9HDSA7"B
 j QbQbQb  DGF
9HD:C9H;iDS7"T.;=@/BE;P>,;OQT$DS;[9HD}k\
 6K;N9X/X)A5KhDGF$;L;P>;OQT$DG@/A4MA6IBS;QV;Q7`9XEA~;Q7"9HDSA7"B<BG@/:T.X)DG9M.;QA4T.BGX)JK;NM$;Q;68A7":T
X/9H;LDGF.9HD
BSDG9HDS;DGF.9HDDKAA~;Q7"9HDSA7"B9H7G;M$AD;P>,;OQT$DS;9HDDGF.;IBG9:<;IDG@/:<;@)6~DGF$;QJC9H7G;I.;Qr;M
$;M	DQDGF.9HD@/BQ&@/6
9.7GA~A4BG@)DG@/A4M.9X$VH9H7"@/9H
X);@/MDGF$;rA4BGDGOPA4M..@)DG@)A4MA6A4M$;A,OQOQT$7"B@/MDGF$;.7G;OPA4M..@/DG@)A4MCA6vDGF$;IADGF.;Q7\
 6vM$A3
9H7"9XqX);X/@/BG:@/B9X/X)A5K;$K;=F.9V;6A7":T.X/9H;EYWc d8e f mLc e f _|68A7E}+,QbQbQb5S}G$
Z?9M.68A7
9X/XG$BGT.O"FNDGF.9HD
 .\
F.;oBG@/Q;A6=DGF.;sBG;QDA66A7":T.X/9H;oA.DG9@/M.;687GA4:BGO"F.;:C9HDG9ZH\/Zs9M.ZH\^]@qBA6DGF$;A7`$;Q7
YG Qk)5GaQYWc_S_l}G,G\

8[  MDGF$;
X)A,OG,BKA7"Xq;P>$9:<
X/;DGF.;68A7":T.X/9H;$;BGOP7`@)
@/M$DGF$;.7G;OPA4M.
@)DG@)A4M.B9M.
DGF$;=~A4BSDGOPA4M
.@)DG@)A4M.BA6wDGF$;A~;Q7"9HDSA7"BI9H7G;=DGF$;68A4X/X)A5K@/M$368A7}+,Z?4\
cI e f ghYSH,I f m+)"HS f m+HW	P/" fquvj mNEI fquvj ms)"HS fquvj _
c jSe f5ghYSH,fm+)"HSfmH
W	Q)`fquvjmNEHEfquvjm+Q/GHGfquvjk_
=
c  e f ghYSHW	P/" f m+)"HS f m+I fquvj mNQ/GHG fquvj mNEHW	P/" qf uvj _
cI e f ghYSHW	P/" f m+)"HG f m+ fquvj mNQ/GHG fquvj m[EH
W	Q)` qf uvj _
F$;687"9:<;=9?>$@)A4:CB9H7G;9B68A4X/X)A5KB68A7},Z?4\
EHf y Hfquvj y c  e f
H fy EH fquvjy c  e f
H
W	Q)` fy EH
W	Q)` fquvjy 
c  ef
EH
W&P/" fy H
W	Q)` fquvjy c  e f
Q/GHG fy EQ/GS fquvjy c jSe f
Q/GHG fy E)"HS fquvjy c e f

EH,f y Hfquvj y c=jSe f
H fy EH, fquvjy cI e f
H
W&P/" fy E
W	P/" fquvjy c jSe f
EHW	P/" fy HW	P/" fquvjy cI e f
E)"HS fy )"HS fquvjy cI e f
E)"HS fy )"HG fquvjy c  e f

F$;BG@/:T.X)DG9M$;QA4T
BI9H.X/@/OQ9HDG@)A4M[A6|DKALAr;Q7`9HDSA7"B@/BIM.AD9X/X/AK;~KF.@/O`F[@/BI7G;Q.7G;BG;M	DS;oJNDGF$;
68A4X/X)AKI@/M$36A7`:T.Xq9H;6A79XqXG,3  ,ZH"]"&CBGT.O`FRDGF.9HD
 9M
R6A7I9X/X~}s,Z?4\
EYWc d8e f mNc e f _

vA7";Q.7G;BS;M&DOQXq9BGBG@/OQ9X
X/9M
M.@/M$9Bw9BG9HDG@/BS9H
@/X/@/DJ.7GA
X/;:R9Bv
7GA~A4BS;J9T$DS9M
<,;X/:C9M
YaZ]$Z4_`	@/M=9
.@)DG@)A4MDSADGF$;9H~A5V;68A7":T.X/9H;@/DBGT,OP;BDSAI4@/V;9BG;QDA6.X/@)DS;Q7`9X/BDGF.9HDw$;BGOP7"@/r;
9Mo@/M.@)DG@/9XBGDG9HDS;9M.9C68A7":T.X/9<DGF.9HD$;BGOP7`@)~;BEDGF$;A49XqBQ\F$;M9BG9HDG@/BS9H
@/X/@/DJL9X)A7"@)DGF.:OQ9M
~;=T.BS;R68A7rM..@/M$<9<DS7`T$DGF,UWVH9X/T$;=9BGBG@/4M.:<;M&DEDGF.9HDIBG9HDG@qBa
;BEDGF$;.7GA~A4BG@)DG@)A4M
9X~6A7":T.X/9H;\F$;
DS7"T$DGF$UWV?9X/T.;Bw6A7.7"ArA4B"@)DG@)A4M.9X&V?9H7`@/9H
X);B|cd8e fSSNS}s,S} $ NZ?@/M
.@/OQ9HDS;KF.@/O`F3Ar;Q7`9HDSA7"B
BGF$A4T
X/r;=9H

X/@);DSAC7G;9O`F[DGF.;A49X/BQ\
?".a^"W8Qk^5WSk`4?55WkWk5 	ff
fi5W	^$fi5~H5"	v)"S
r?"`fifi5~5W5
  "!$#%	
 W fi?w? Ea"$ fi?`Wa5` 5 ?

&'&)(

fi*,+-/.102-43)-

5687:9<;ff=>;ff?@;AB'C/BDFEAGE2HJIKEAMLNDFB1DOE2A%CQPSRTPOCQA%?
USV)W4XQYZ[YV)W4\"]^Q]_\"WQ`\ba[cJV"defc@ghZ[`,Z[i4\bZjk\b^lZ[i/cTg m/aa[c@WnZ\"WQXo^Q\"`fZV"dQ`[c a[p\bZ[Y_V)W4`ZfVqZ[i/cTV"^c a\bZfV"a`
ZfVrdsctchuvc@g m4Zfc@XwGxSyzZ[i4c{U|ivm/agi/}~%m/aY_W/{Z[i/c@`[Y_` jV)`fZq"c@W/c a\"]ghV)j^Qm/Z[\bd2]clW/V"Z[YV)W4`V"`[m4gi
jq\b^4^2Y_W/)`t\ba[cc@ffmQYp\"]_c@WnZtZfV~m/aY_W/jq\"gi4Y_W/c@` w:,V1c p"c a'YZoY_`oW/V"ZoW/c@ghc@`[`[\bayZfVghV)W4`Y_X/c a
jq\b^4^2Y_W/)`FaV)j\ba[dQYZfa\ba[yTV"dQ`[c a[p\bZ[Y_V)W4`ZfVT`fc@vm/c@W4ghc@`V"V"^sc a\bZ[Y_V)W4` wc,ghV)W4`[Y_X4c aV)W4]y`fyv`[Zfc@jq`
Z[i4\bZJ\ba[ca[c ^4ac@`fc@WnZfc@Xdvyo2WQYZfc`[c Z[`V"$\"ghZ[` \"W4Xi/c@W4ghcZ[i/c^Q]_\"WQ`X/VtW/V"ZJi4\'p"cZfV<dsc\bdQ]cZfV
a[c@`f^sV)W4XtZfV\ba[dQYZfa\baY_]yqghV)j^Q]_chu<dsc@i4\'pvYV"a,V"%Z[i/cTc@WnpYa[V)W4jqc@WnZ w
cghV)W4`Y_X/c aNghV)W4X4YZ[YV)WQ\"])^Q]_\"WQ`MZ[i4\bZ\ba[c2W4Y_Zfc`fZ[\bZfc"ffZ[i4\bZY_` "Y_W\"X4X4YZ[YV)WTZfVZ[i/cY_W/OV"ajq\bZ[YV)W
V"d4Z[\"Y_W4c@X\"`V"dQ`fc a[pb\bZ[YV)W4`@ffV)W4]_yq\J2W4Y_Zfc\"jV)m4WffZ$V"%Y_W/OV"ajq\bZ[YV)WY_WnZfc aW4\"]4ZfVZ[i/c,^2]_\"WkY_`Sm4`fc@XY_W
X/c Zfc ajkY_W4Y_W/,i4Y_giV"^sc a\bZ[Y_V)W4`ZfVt^c aFV"aj\"W4Xi/V1Z[i/cY_WffZfc aW4\"]`fZ[\bZfcqc p"V)]p"c@` w~i/cghV)WnZfaV)]
QV1Y_WZ[i4Y_`Y_W4XQ`V"S^Q]_\"WQ`Y8`J`[Y_jqY_]8\baZfVlZ[iQ\bZV"$W4YZfc\"m/ZfV)jq\bZ[\V"ac@vm4Ypb\"]c@WnZ[]_ylZfVlZ[i4\bZV"
^4a[V""a\"jq`|Y_W\`[Y8j^Q]c^4a[V""a\"jqjkY_W/K]8\"W/)m4\b"c,YZ[i<YZfc a\bZ[YV)W<V"a\"V"ZfVb}`fZ[\bZfc@jc@WffZ\"WQX<`Y_j^Q]c
YF}Z[i/c@W}c@]_`[clghV)W4X4YZ[YV)WQ\"]_` w~i/ctW4YZfcl\"jV)m4WffZqV"JY_W/OV"ajq\bZ[Y_V)W$Z[i4\bZY_`Z[i/cY8WnZfc aWQ\"]`fZ[\bZfcV"
Z[i/c^Q]8\"W{XQm/aY_W/chuvc@g m4Z[YV)WMg \"WdscgiQ\ba\"ghZfc aY c@Xdffy{\o`fZ[\bZfcqpb\baY_\bdQ]cZ[i4\bZghV"a[ac@`f^sV)W4X4`ZfV\
^4a[V""a\"jghV)m4WffZfc a@w
USV)WQX4YZ[YV)W4\"],^Q]_\"W4`<,Y_Z[im4W4a[c@`fZfaY_ghZfc@XZfa\"WQ`[YZ[YV)WOmQW4ghZ[YV)W4`<\ba[cp"c a[yGchu^4a[c@``[Yp"cdQm/Z<Z[i/c
Wvm4jTdsc aV"s^Q]_\"WQ`N,YZ[ic p"c@Wk\T`[jq\"]_]/Wvm4jKdc a$V"`fZ[\bZfc@`S\"W4XV"d2`fc a[pb\bdQ]c\"ghZ[`$Y_`p"c ayiQY)i",i4Y8gi
jq\b"c@`^Q]_\"W`fc@\bagi{XQYg m4]Z w`Z[i/c a[cY_` 2Y8Wl"c@W/c a\"]\Zfa\"X/ch}Vbdsc Zc c@W{Z[i/cchuv^Qa[c@`[`[YpYZy<V"
Z[i/cac ^4a[c@`fc@WffZ[\bZ[YV)Wk\"WQXqZ[i/c,XQYg m4]ZyTV"2W4XQY_W/^Q]_\"W4`@)c\"]_`fVTghV)W4`Y_X/c a$jV"aca[c@`fZfaY8ghZfc@XqOV"ajq`
V"ghV)W4X4YZ[Y_V)W4\"]^Q]_\"W4`Y_Wc@ghZ[YV)W4`/wvwk\"W4Xo/wvwvw
 82ff%kOGTM2@O4J FGS2%
~i/cQa`[ZMOV"ajq\"]_Y@\bZ[Y_V)WTV"QghV)WQX4YZ[YV)W4\"]n^Q]_\"W4`m4`fc@`M2W4Y_Zfc\"m/ZfV)jq\bZ[\OV"aNa[c ^4a[c@`[c@WnZ[Y_W4,Z[i/c|Y_WffZfc aW4\"]
`fZ[\bZfcJZfa\"WQ`[YZ[YV)W4`$Z[i/c^Q]_\"W<jq\b"c@` w$~,i/c`[mQg ghc@`[`fV"a`fZ[\bZfcJV"M\`fZ[\bZfcJY_`|X/c Zfc ajqY_W/c@XdffykZ[i/cZfam/Z[i}
pb\"]_m/cSV"Q\"WV"dQ`fc a[pb\bdQ]cO\"ghZ\"`[`fVg Y_\bZfc@X,YZ[iKZ[i/c|`fZ[\bZfc"),iQY_giKcg \"]_]ObbObV"QZ[i/cS`[Z[\bZfc"w
~i/cZfa\"W4`[YZ[YV)Wm4W4ghZ[YV)WQ`NV"2Z[i/c\"m4ZfV)jq\bZ[\Tjq\'ydcghyg ]_Y_gY_WZ[i4c`fc@W4`fcZ[i4\bZ\"Wq\"m/ZfV)jq\bZfV)Wjq\@y
a[c Z[m/aWtZfVk\q`fZ[\bZfcYZi4\"`V)W4ghcK]c FZ w
 \"gi`fZ[\bZfcV"S\<ghV)WQX4YZ[YV)W4\"]%^Q]_\"Wi4\"`\"W\"`[`[Vvg Y_\bZfc@X`[c ZV"V"^sc a\bZfV"a` wc`[\'yZ[iQ\bZOV"a\
)Yp"c@Wo`fZ[\bZfc"/Z[i4c@`fcV"^c a\bZfV"a`\ba[ckh2ffh_[Y_W<YZ wM\"W<V"^c a\bZfV"aY_`Sc@W4\bdQ]c@X<Y_WZ[i/cJg m/a[a[c@WffZS`[Z[\bZfc"
YZY_`|chuc@g m/Zfc@X{Y%Y_Z[`^4a[c@ghV)W4XQYZ[YV)W4`|\ba[cZfam/c"w
WX/V)jk\"Y_W4`Y_Wr,i4Y_giV)W4]y{^Q]_\"Wchuc@g m/Z[YV)Wzjq\@yrg \"mQ`fcgi4\"W/"c@`Y_WZ[i/cqc@WffpYa[V)W4jc@WffZ Z[i4Y_`
OV"ajV"T^Q]8\"W4`tY_`t`[mg Yc@WffZ ,i/c@W/c p"c al\^4aV"dQ]c@jY_W4`fZ[\"WQghcY8WghV)WQX4YZ[YV)W4\"]^Q]8\"W4W4Y_W/zi4\"`l\
`fV)]_m4Z[YV)W4Z[i4\bZY_` 4Z[i4c a[cKY_`,^Q]_\"Wl\"g ghV"aX4Y_W/qZfVt`fV)jcKa[c@\"`fV)W4\bd2]cTW/V"Z[YV)WV"ghV)W4X4YZ[Y_V)W4\"]^Q]_\"WQ` 4YZ
i4\"`S\K`[V)]_m/Z[YV)W\"`Z[i4cY_W4XkV"^Q]_\"WkXQY_`[g m4`[`[c@XkY_WkZ[i4Y_`S`fc@ghZ[YV)Ww/V"a|Z[i/c`[Y_jq^Q]c a$W/V"Z[Y_V)W4`$V"^2]_\"W4`
Y_Wvc@ghZ[Y_V)W4`/wvwq\"WQXo/wvwZ[i4Y8`Y_`W/V"ZZ[i4cg \"`fc<`fc c  u/\"j^Q]c/wqY8Wvc@ghZ[YV)Wo/wvwvw
~i4cSWvm4jKdc aV"Q\"m/ZfV)jk\bZ[\,YZ[iKc p"c@W\`jq\"]_]vWffm4jKdsc a%V"2`fZ[\bZfc@`Y_`%O\"Y_a]yi4Y)i\"W4XKZ[i/c a[cY_`W/V
\^4aY_V"aYQm/^Q^c aSdsV)m4W4X<V)WtZ[i/cJWvm4jTdsc a|V"%`[Z[\bZfc@`,W/c c@X/c@X`[V^2\ba\"jc Zfc aY@Y8W/Z[i/cc@W4ghVvXQY_W/,YZ[i
a[c@`f^sc@ghZZfVZ[i/cWvm4jKdsc a|V"N`fZ[\bZfc@`Y_`W/c@ghc@`[`[\bay"w|vV)]_m4Z[YV)W4`|\ba[cQa`[Z|`[V)m/)inZOV"advykamQW4W4Y_W/\
Z[i/c V"a[c@j}^4a[V'p"c a,YZ[i<c@W4ghVX4Y_W/)`S,Y_Z[i<\`jq\"]_]sWffmQjTdsc a|V"`[Z[\bZfc@`,\"W4Xt^sV)Y_WffZ[`SV"%Z[Y_jqc"\"WQXtZ[i/c@W
"a\"X4mQ\"]_]yY8W4gha[c@\"`[Y_W4Z[i4cJp\"]_m4c@`V"NZ[i/c@`fcJ^Q\ba\"jqc Zfc a` w
~i4cFV"ajm4]_\bc,FV"aOV"ajq\"]8Y@Y_W/JghV)W4X4Y_Z[YV)W4\"]^Q]_\"WQ`V"sZ[i4Y_`NOV"aj\ba[c)Yp"c@WqY_WqNY)m4a[cbwch2W/c
@ b   '[   wgi4c@jq\bZ[\vw_\"W4XGvwz`fZ[\bZfcZ[iQ\bZkOV"akc p"c a[y`fZ[\bZfcZ[i/c a[c{Y_`chu/\"ghZ[]yV)W/c
ghV)W4X4Y_Z[YV)WwKgi/c@jq\bZ[\lvw_}vw`fZ[\bZfckZ[i4\bZFV"aJc p"c a[y{`fZ[\bZfcqZ[i/c acY8`chu/\"ghZ[]yV)W/c`[m4g ghc@`[`fV"aK`fZ[\bZfc
OV"aTdsV"Z[iZ[i/cZfam/ck\"W4XrZ[i/ck\"]_`fcpb\"]_m/cqV"|Z[i/c<ghV)W4X4YZ[Y_V)Wwk~i4Y8`Y_`W/c c@X4c@XrZfVc@WQ`[m/a[cZ[i4\bZKZ[i/c
'1

fiS2Q/ffQff/Q24Q/_2/Q)1QQ
KOM4
	ffMfiM2
 !#"$  %
&' (*),+- (/.0+2131314+5 (/6

Y
78:9;:<<ff=?>5@BA!CEDGF'CIHJLKM@BNP33ORQTSGUWVRUT;/VF5X H!Z
;:[T\-;:[W]B[QT^_]39G;/VR`a8'[Wb0c3C Cdbfeg8:7h@BN
KOM4
@,	ff	i!jkmlT!KFn!opjflM, 2q,	!M
rs!sTEtu#"?s!s % t
Y
r&'s!sTBvw#"?s!s % v
A ORQiSIUWVRUT;/V{F-X H

7
:
8
x
9
:
;
y
<

<
B
D
R
=
z
C
:
F
I
C

H

J
n
K
@
r&r's!s tq+Ws!|sff}Gtq+2131314+-sffsf~dt
r*s!s c vM+-s!|sff}EvM+2131314+5s!s~  v
78:9;:<<ff=?>5@BA
c
 *lj8,mlT!
s  
c
KOM4
	2jfjf4,B*lT!
s! #"$sI 

33
Y
7 8:9;:<<ff{>pDC CdRJ'CEDB=RCzFJ_Kn@BAWOIQTSIUWVRUi;/V=X F
 jfl fPln@,	ff	jmlT!
s! -   % u
  %  5s!sTtu#sI y
&'s   -   %  "0 %  -s  s  vw#s R yc 
LTT 	lTMPp  ijflTffj

c

33

78:9x;:<<>
DC Cddff J'Z
DB=ICzFJ>5@ A CIHu>5@ N

|* -sTR ip !w13131/py(:#x 
33>5
 @BAffCd=?>w@B ?Z
|*&' dx -s c  z+2131314+ ~  Wsf~   d 78:9x;:<<TF
{>pDC Cd    Y J  33 y(
c
c
;:[T\WU]39R]RR =
D cBC C J
/?

`a'Q9R]
[TSE8\T`[8:7hSE8'[T\T`aVR`8'[T;:<!i<;:[TOx`VRUWQT[9R]BOdVd9G`SEVd]B\uVd9I;:[TOR`VR`a8'[u7Qi[TSEVR`a8'[TO
 
Vd9I;:[TOI`aVR`a8'[_7QT[TSEVR`a8'[iO$@BAD4LCG J
@BA8:7ffi<y;:[TO$;/9R]]B<<az\]E[]B\f  8:9I^LQT<;  OdVR;/Vd]BO{VRUT;/VVRU]
i<;:[]E]BS3QVR`a8'[uOdVR;/9RVRO`[OdVR;/Vd] ;/VVR`^_ ] U]SGU8'`SE]78:9ORVR;/Vd] `O;/9R`aVd9I;/9R:Z;:[T\8:*`a8'QTOR<
\8]BO[T8:V{OR;:SE9G`SE]x:]B[T]39I ;: <`aV:SI U ]B^;  OdVR;/Vd]BO{VRUT;/V{VRU]i<;:[S3;:[i[8:Vff]`[V8_OdVR;/Vd]BO;/V{VRU]
OR;:^_]VR`y^_]:SIUT]B^;/VR;  ;:[T\  SIUT8*8'Od]VRUT]OIQTS3SE]BOROd8:9xORVR;/Vd ] 8'[uVRU] i ;:OR`O{8:7VRU]Vd9IQVRU|/;:<Q]
8:7VRU]2SE8'[T\T`aVR`a8'[n;:[T\nVRUT]5Vd9I;:[TOI`aVR`a8'[P9R]B<y;/VR`a8'[fgSIUT]B^;/VR;  ;:[T\  ;/T<aq]E;:SEVR<aPVRUT8'Od]
8:ff]39I;/Vd8:9IOxVRUT;/V;/9R]]B[T;/<a]B\-`[uVRU]S3QT9R9R]B[*VOdVR;/Vd];:[T\-78:9UT`SIUu VRUT]T9R]B SE8'[T\i`aVR`a8'R[T O;/ } 9R]Vd 9G-Q]:! 
}
}
}
}
 
9Ri]3
 VRU]WORSG U]B^;/WVR;
 `y[  `a'QT9R] ;/9I|]

   
UTW
]OI`a 3]BO 8:7VRU]7:8:W
9I^L QT<;/]
T9R ]BOR]B[mVd]B\u
   
 
    R  
R  G I
R G  d
 
]B[TSE]VRU]OI`a3]8:70VRU]xU8'<a]OR]3V8:7,78:9I^LQT<;/]`O8:7,8:9I\T]39
}  -
 
 W } 

|

 
 
 
R  3G I
d




fixaT'

i5y:RiaRx{:I5E:_a:i{TITiERBiETy:iy:TxaR5z{
dR/dB3
 TIIB/R
  	ff 
fiaBwR_'yaxy:ILT/:
 '
 p:RRi_RT/
R:ER
  "!#%$&')
 (*$+&!,-' :T.
 /'10n/I:id33 2//ia:

465-7ff8:9<;>=@?+A BDC)EGFH465-7ffIA BJ=:KDC
465-7ff8:9<;>=@?+A BDC)EGFH465-7ff8:9	CZY
465-7ffIA B]=:KDC)EGFR46537ff8:9<;>=@?+A B]C
465-7ffIA B]=:KDC)EGFR46537ff8:9	CZY
465-7ff8:9	CY[EGFR46537ffI+A B]=:KDC
4 5-7ff8:9	CY EGFR4 537ff8:9	;>=@?A B]C
465-7ffIA B]=:KDCbUW46537ff8:9	;>=@?A B]CcUa465-7ff8:9	CY

LNML)MPOQEGFRL)MLTSO
LNMLTSXOQEGFRL)ML)M-O
L[S^L)MPOQEGFRLTS\LTSO
L[S^LTSXOQEGFRLTS\L)M-O
LNML)M3_EGFRL)MXLTS%_
L M L S _EGFRL M L M _
L[S^L)M3_EGFRLTS*LTS%_
L[S^LTS%_EGFRLTS*L)M3_

LNMLNM<OVUWL)MXLTSO
L[S\LNM<OVUWLTS*LTSO

LNMLNM-_`UaL)MLTS%_
L S L M _`UaL S L S _

,IRd"2/:_:RR'T_B*RRT/R/Rd:fi2RBd_:Ii/R3TRBdB*dI:TIaRa'2iTERa'T:E'd
TaR'T:fi:i3eTRB:i_:Ii/BREGaff R:-3d3IBxiI5:!3G/d:I
/REB3dBf:b
 fgh^id*Z_RIB/Rj
 
 :T
 k lfiaBR'ax:Ii/:

L)M-7 m
L)M-7 noEpFRLTS7 nqL[S7 n*EpFRL)M-7 n
r GB/Rjs:Tas>LRT/BREGaffdR/ddG:TRaRa'iHfi aB:co^tuvw:Txfey^id*Z

R'axL:Ii/:

Lz5-7 n {a46537ffI+A B]=:KDC1{ (\$&3!,3' n|{L[5L 5~} OQEGL 5"}u7 nu)M
Lz5-7 n {a46537ffI+A B]=:KDC1{F (\$&3!,3' n|{aL[5XL 5~} _EpL 5"}u7 nu)M
Lz5-7 n {a46537ff8:9	;>=@?A B]Cc{  "!#\$+&X' n|{L[5L 5 } OQEGL 5 } 7 nu)M
Lz5-7 n {a46537ff8:9	;>=@?A B]Cc{aF  "!#\$+&X' n|{aL[5XL 5~} _EpL 5"}u7 nu)M
Lz5-7 n {a46537ff8:9~CY{ /'10 n|{WL[5L 5"} OaEGL 5~}7 nu)M
Lz5-7 n {a46537ff8:9~CY{WF d'b0 n|{aL[5L 5 } _EGL 5 } 7 nu)M
r GB/Rx*:T*>fi aBu:fg^id*Z:iWlR'ax:Ii/:
 m7 5N{WL[537 n { /'10 n{ (\$&3!,3' n"Epm7 n
bm7 noE - m7ffMN{WL)M-7 n~zU  m7 SH{aLTS7 n	-
 M-7 5N{WL[537 n { /06' n{ (\$&3!,30 n	EGlM-7 n
lM-7 noE - M-7ffMN{WL)M-7 n~zU  M-7 SH{aLTS7 n	-
 S7 5N{WL[537 n {  "!#\$+&X' n|{ (\$&3!,30 n~EGbS7 nbS7 noE - S7ffMN{WL)M-7 n~zU  S7 SH{aLTS7 n	-
 7 5 {WL 537 n {  "!#\$+&X0 n { (\$&3!,3' n EG  7 n   7 n E -b 7ffM {WL M-7 n zU b 7 S {aL S7 n -


  RT:G:+B/Ra' E'TiaRa'T:i:i/RT3d3IB /finRh2/:T/Ra' :24/Iy/iaB
L"LO  TL @L*_  4e:7  :i  37  ,k/:2Ei3aRw_B:i ::TRT3Rw/R
/uaB:d
z{uff'RRaiyaRaB3
 +:2 L:I:%iaRa'W:?E'iTaRa'T:i:Tx:E:_iaL:iR::I:
-Ry_iaTR::G:-y:'T/:xRpE'TTaRa'i::T d3I/Ra'f,:'+:2 5_BIT:iR :
EB3RRT$i:Tfy_i3R+
fi R3TRBRBmdBfi RR/2 :T/R'Tf:R?/:R%z _B*Ra'B42 /Iy/iaB3
pG'dRy/dd3x:ad3IT/R:2 ffB3:Tdax_:RddI:'md:R/If
r :RRi_{T*:2 /2 :T/Ra' E ZX RT/:RIa'TdIRd"/2 :BdRd3 :
TR:ff'RRa'T:|24/Iy/iaBRT/xy_i3R+fiR3TRBdB*_E'TTRa'T:!i:f:T-Ri/I:_3d3f- =
RT/xyRaB:R-:RTi:uEB3Ra'fHxTREBTRyW'RL
 EB3dBxRT_iy3aR+fi
^*

fig|  + d| D| o  
Jd
 J
xb-)e-H
6H-
%/*\  3 3 \+  [T\  Xe3    : Rw
Q l3*%    +  gT\       
 J H3    " 3  R
P J e   "[cw
3 J H3X   T"[XT:Hw
-    b    1H  J P eNd  J 3 
J1
H1
 3l e 3/%  3c%/*\        
3\*-      [ e  3u 3 \3+d3\:\    *3*   x h-  
T\  g     3*%       : XRw     1       T\:3  j  -
T\    3%d*\   [       /      *33X* 3  	/ff
a l6  3 	fi     
z   *+    \    / 
 "!#$%!&'!()*!,+-(%)/.0+"!&1&+"!&24365&!&1&+(%1%
 1   g  c87/+ g3*  + a 397\3  \   fi x   :T\6 87  *  ;7*+  
   a  T<7\3  + fi X  >= *?            \j      y  %    %
     @x\ \A %    +        3B *j  73  +    bj3*      
%  3 +  +x+*3%dT  3;7:j6    
      u3\3-   a -*      7    \    3  =   l   6  387d+

-* +  fi    X  3 u  3-d\        -  eT\  X  +   h j 3  fi  c 
 3     3  +    333*  X   [l     3 /     3   +    -j
 T\  1       1 3   u  +     fi  c+      \3     +  T\  
 3*%    +  bRu  3    3  T  %        3  - 9C    \3
 3  j3W\   fi    %          3   Q     uc3\%*-b 3    
  e 3B +*   3 %*      7  3  +         X  3\ 3-   ED *  + 

     7  -  + Q        l:  u3\3-   Q  -*  + z
FHGI,JLKNMPORQ%SUTWV   3  \  l:+o  T\   
 HXZY8[]\_^>`0[baZcdcdc*9egfihRHXZY8[]\_^>`0[baZcdcdc*9ekjXHXZYl[nmpo,[rqtsdXBuvX
 HXZY8[]\_^>`0[baZcdcdc*9egfihRHXZY8[]\_^>`0[baZcdcdc*9ekjXHXZYl[nmpo,[rwx^>y0mp`
 {z X{X{|>[nmPo&[rqtsdXBuvXZjXHXZYl[nmPo&[rqtsdXBuvXdjXHXZYl[	\_^}`[~^9efhRHXZY8[]\_^>`0[b~^9e/j0hRHXZYl[	\Zody0s
{z X{X{|>[nmPo&[rwx^>ym`ljXHXZYl[nmpo,[rwx^>y0mp`0jXHXZY8[]\^}`0[b~^9efhRHXZYl[	\_^}`[~^9e<j0hRHXZYl[	\ZoBys
      %    +  a  Q     z XX{|>[nmpo&[vqtsdXBuvX /z X{X|>[	mPo&[vw^>ymp` u  X fi  6  a    
HXZYl[	\_^}`[acdcdc*9ekjXXYl[	\_^}`0[b~^9e  HXZYl[	\ZoBys  3   fi ` 3*          3
  - R   ) hRHXZY8[]\_o_Bys 
C   h   b  :  \3-   kD *  + k
     R  T   +87   :+o 
       x     +  x      \   ) 3 *l < c   fi  \T    j  X


fix;&d
6&%p"P%/&,ZP%Z<%&&&%
r_UxP 
br	/88}kU	?bP 	/88><P}  		bxPff?b /88}kP  0bb
PBxBU< 88 bp } bR{&x8H"b        88     n}v     P  88  P  
  N8p"{LZ&"
r_U"P :b %88}9l "Ub  PBxBUR{< 88 b p  }
r_d"P <b N88}9   0B"P 
  "Z&"
  UHb 
tP%&%%&L{&"
B>UH"P   PBxBU< 88 b p  l{]  {?&?,>x  
 & &P&"P%%<&,&%%
{_Ut P  R b      88>    bp   /88}kp}    bB P 
{_dtb  	/88>< }  		B P 
{_ dtbv P   ?  n  88}<v p  N     bB P 
PBxBU< 88 b p  } bR   
	fiff:R{&
	?8H     v  88  ,
 
	 }v     P  88  P  
   &l 	    Bl 
	     &B ,U &Bxb & &l{B  b8>b 	R "80>bB

8{!#"$&%('dBv
	fil{)*+"
-,/.>0p  b&1324*>b  & 8>bB6
	  >E&5,;	  
b>b    8>bB  $	  176859  d&:B_  dB  B  ;9B	  ?BU=<{8  &BN&>,U?1
 BRpBA@ BB, U& C	  8,b	     b{l  8  C*bdU&  b   D&5,;@E1
24    BUF: t" 80>bB9 
	  >
,   8,5 ;1/6B& :  tB{b6 8>bBH8G5,5,;	
5 {8B&b

	 8Eb
&	 >A	H B  4
 BI	 ; 
&	 & =: ;: >J	 ; 
	  8
	 &l/  
=< {8    K, >BU;{  L B{UNMO	 =PQ& 	?1SHR $@  8>bB  & ,5 ;	 $-	  8>bB   L B
 B88B  T:@U@ 8b    d$	 88PB 8>bB  
,   	VP b;1xW   8 {!+"
&%(d' Bv
X
  BUb
	Ul {)*+"
-,/>. 0p   bB&  dB8
 B/5 B0  ;B9 	?1
 BYt@ &><&>& l	 J, U& >  B9       1ZR [<    >:\>9 >  ,5 ;{ P  &	 =PQ 	
  0@   1  =<& {6&>-&E& {l
	    & tBH & 5 ;	 " 80>bB >?b?>-
	
b@  B  > dbl
	    &  > BUb1]	2  p    PBb-pB6BU 8>bB:&k BU
   8,5 ;
 8>bBH&B9 K5 8R
 $,   	 $R	 Eb&      b &^ =< >b  8@ 	 ^ =<   0@   1  


	 B8  ?=_< {8  4 l   _ {   @ Rb>b  @   1  1   BA6@ &U  1  >b{
&>&U, U
 =< {8  L b>  k b>b  >  -@  N
*	 @  B 1  b>b{t&>], U
8
 B_5 9  6@ &; 8d,:   ]U	 N` 8 b>b{;1R8
  8>bB   
,   	 x&    , ,5 ;	
a)a)b

fic7dQe$fAg[hji$kjg[le$mnkdQe
o$lNg[lFdQe[p$qKrqsp$e$f
tFuwvx[y{z;|
}}yujv3~TvvTy8tv~C
}yz=u

tFvtu
~]}AyGvT}A|
yGu
H~TDy{Itv~C~Tvz=u

tvtFu
~]}y{F~Ty
 ~zYx[yUF!vx
y~TyUz=u

tvtFu
~B}yUu[v>|
NQFFy?Qvx
yDy;}YvT}ItF~Bu[vV
$ty  ~zAx[y]v
Vu$fiK8u]|[
y;}|
u
K+}Lvx[y~At;y/vx[y/+}A(|$Fy/tFuUt|[}Ay>tF~0s4 - !K[#)
^0KT[#)nQ  G/  KA*#{0s4 - !K[#){0s4 - *[#sE^=^TT[#?x$tFzAxUt~}Y[y;}
   #Q(0KT#$HYF)T - !^T[#4
8$S+ [}(vx[yD$z~>7}AFJvx[y]yu
z=$tFu[EtF~V~>+Fs~>+}VVH)fizAx[y]F
 tyF
~vx[y>+FstFu[K+}A^|
Fy>vx
vtu

tFz;vTyBx[yufiy;}YvT}A~/}yI$$FtFz;$Fy
0   8 Q;  Q  $-  Y QE 8 Qn;   
 T 0  T ?   0     ? TT
 T      ;   fi  Q-  A  fi   n A  
 T T  T ?   T     ? TT
      $-  Y  J A  fi  8  fi_ AT  fi $-  Y  
 T ST ?      ? TT
     $-  Y  n;   fi    fi_ AT    fi  $-  A  
 T  ST ?         ? TT
!u[y;}AvT}VtF~>
QFtFz;$yvT}Au
~AtvtuGvTEvx[yU~|
z;z=y~~}V~TvvTy]tF~BU[y  ~zYx[yUF)YSu

vx[y;}tF~Ty>vx[yV~TvvTy^~Tv  ~/vx
yI~Dy  ~AzAx[yUC
 T  E 0  fi T  E    fi8  j    
T Q  80   IT              ST 
       0    T                
zYx[yUv;F(u
nF  tyFvx
y>#FF)tFu
^+}A^|
Fy
 T 
T   L        LT 
zYx[yU{F tyF
~
#}BFSKAj?vx
yI+F)tFu[U+}A^|
FyIvx$v[y~z=}YtyVx[yuy;}YvT}A~
}yI$$Fty? 
 0  E     8  n; T  fi  Q-  A  E   n AT  T   0 
 T  E   $  Qn; T Qfi  $-  Y 
  Qn;   T   T 
    E     $-j  A  J;   fi    fi/;   fi $-j  A  T     
    E     $-j  A  n AT  fi    fi/;    $-  Y  T     
8u
3Qu
F  ~zYx[yUv]u
nU~A  x[yuEy;}AvT}Y~/}yIu[v
$Fty
 $-  A  fi   n A      0  T   0  L T       0   L    T    0 
 $-  A     ;       T  T   T  L T       T   L    T    T 
  Qfi/;  Qfi $-j  A         T      LST           L    T      
   fi/;    $-  Y         T      L T           L    T      

 x
y3F|
vtFuvx[y
}~tvtFu
L}AtF$Fy~   D[y;vTy;}AUtu[y~(nz=u$
tvtu
$Fu  x[y

}z=y
|[}AyBtuEStF|[}y>Uy=yz;|[vTy~vx[yVtFD$tFz;tv  }y;$}y~TyujvTyE$Fu?
)

fi[sQ

>

  
	ff
fi

 "!  ($ #&%'!)( $ *,+ "-.!
/(10 * (&(2-,34"5 * -,5Y76$!8/9  9 *;:=<?>A@CB DFELHGI*,+)J
 9385$ - +)J #  #&- +  -,K-,34"5 * -,56 * 5$  5L! *,+)J
 -.%M-,K  9)3=-  - +)J #  #1- +  * 5$NK * (F 
O  9)"5$P#F + -Q-,3="5 * -,5A6$ !8/9  9 *;:=<?>A@CB DFELHG
*,+)J 385$ - +)J #  #&- +  -,K6 * 5$  5/!) *,+)J -.%R-,K  934-  - +8J #  #1- + 
S ff  
>  T   F T
U

* 5/NK * (

V #&W.!5$YX ffZ $5 - J !5$YK-,5; "!  # + W * 38( *,+

>
	ff
fi

 "!  ($ #&%'!)( $ *,+ "-.!
/(10 * (&(2-,34"5 * -,5Y76$!8/9  9 *;:=<?> @CB [ EL\G
*,+)J
+)J  +
* *  
>  T 9)N 3)5$ - # #1- ]-,K^-,34"5 -,5A6 5/ 5/!
U

V #&W.!5$N_ ffZ $5 - J !5$YK-,5; "!  # + W * 38( *,+

`2acbda1egf7hjilkmnimQo=pdqlrsp)ktdpdmnulvwodp8x2mRusvzyn{)p)|2i)x2us|sm
} 0,  $#c%R38(1"5lKC-,5/%~-,K)38( *,+ # J  +  #18   97# j+  "5 +)* (  $*  -,K * 38( *,+ #  9  9"!5$5$ +jS #&%R]3=-.# +"
-,5 !)#1 * (1 +  (&0 .*   * /9  #&%M]34-.# j+ S 9738( *,+ % *   *,+ ! + - +)J #  #&- +)* (  5 *,+ $#  #1- +^ - * $!)"A-,5
 $* *  ,*]  * 
!* $  9# j+ + " 5 +)j+ *  L(  $+)* *  $-.* # + "# J    *,# +  9  *,#&+)%RJ  S   9"5$+ #F J + + - + " J * KC-, 5($"3 * * 5 *  $*  
 5/# (1  9 5$"3)5$ $ # "5 7(   n-,KA38( 
9 - # W#P3 5 #&"!)( 5/(&0J/#&%R38(1
+

+
+
*
+
- $#  # Wn-,K^- V $L9 % - (10,
4<  F E;;@CB [<?>;@B [8<?FE[d""<?cE[d7<<?C E[d""<?C  E[EE
KC-,5 * (&(,6  *,+)J   """ $  9"5/^d$$ < 6 LE    """$&8]*,+)J F < 6 E     """ $    
 9D $#&"'-,K  9D   -,KKC-,5/%'!)( * nKC5$-.% $/9 % n
*     F# U-,K-,5 J "5nL&$ <E     9'3)5$- J !5$
+# V #1W.!5/P_n "!     9N3d( *,+ 5$"3)5$ $ +   J 0  9  5/!  9 * (&!) -,K  9) * 5/# * (1  >;@B [ 
Ul8Csc V -,5  9  (1-    -,5/( J  * %R38(1  9)NK-,5L%!)( *  * 5$ * 7KC-.(&(1-  7KC-,5  z   
FB [<?>;FB [= ,  [d  1/$ [dA< 8"1L [d   [d "&$  [EE
NB [<?>B [= ,   [d  1/  [d7< 8j&  [d    [d  1/ [EE
FB [<?>;FB [= ,8&/ [d  1/  [d7<   [d "&$,  [d ,8&/ [EE
FB [<?>;FB [= ,8&  [d "&$$ [d7<    [d "&$, [d d&  [EE



fi]d8/j8j18d)8&d8n.88
l&Q8=Cdfij=j==?sdC
~.))1$1.8,dd&," Mc 	
 ,&2ff fid&)$1.
,)
A$,4ff$1$1.),/
fi81 ] ) $" /  Y&)&$&, $ 7,8, ) .j$& , 8"1 M,!   $1. ) $ ,"  A
,.,#
 $
 $%&)'  ($" /  
   ))  *+ )A
 ,*+),j$ -8 .0/21435.06879 /A & -: *+),0 
$ -8 ]; , ;8&, $" $ j <
 fi>= ?  L& fi81 & @ "A /CB D  .8E , ,c=.j$& , 8"1 
3FB,)R  )G /n;
 , !  $&. 6	$:H=n ;  0! -=)1$1.n
 4*+),$G -8 I H]j.& ,	 C
 J)&
 B
C

  ," d&,K
 / ,&  0, P
 $G . R j L  /& fi8& ;&M
 3NJ) fi=4ff $G fi8&
 $O )' 

 /& fi81 &P
 3QJ2 fi4P1
 .&",& =&)"4 ) j $R P
 M,> ="
  B4; 7ff , EB2 P ) 0,'  ;
 
.j$& , j2 ?, Y $n"4 ) j;. ,  ,  E$2S
 Y!
R81n& 5 fid1 T+)7]
 /&4 B4G (Ug .
 fi4P.M
 U$D%L T,"" )5  /& fi8& ;&W
 3 1
 .&",&G =c)"4 ) j B7] &  U",8,
V B V ",),2
*+),$ X=E
 , AN.j$& , jA ?, A)G $ $ =M
 A7ff@ 8 ,NM"&
 $G Y=Q
 $G . R  L 3 R )ff 
)L $" $ jQ,&&E 7]  ff fid&)$1. M
   0,  R,)fiw ff $ ))z, B7,) .) =
$*+)G $ )P!  )
 !   $&. & ,)& MI ,.,Z $J 
 U C
 R E$[n) / Afi4, 

^  N,1 L)$G , &fi4 1; 7@$
 ]?_<fi4 `
 
 "5)cW
 
 &81$&,A $P
 7;1  ,c7 $,4ff $1$&. Cfi/! /1) a
 7;& cb0B
\ "^

g
X
h
i
,)e
 d,fXghXiI$ Q&& /G=w K
 C
 J)&W
 C
 Q`
 ,.,) fi$! /&) a
 7;1 kj $ \ "<
 lmfi4n
 C
 J)&
$" / $c R8&, 7,8!   $&. ;
 A8 $ $ &K
 o $1. &p$qN,)<
 p$sr+$
t4uGvwuyx{zJ|,}~#'+'~ZcD|,'X},+c}4'}

 D -"A,1 /)$ ,@ 7ff5 N
 0&&& =IL&fi81A;F
9.&&E79$:%9D
"5)c	] _ 
/,
M NY,N*+)G,1 
"5)c)]?_ cN)Y))$, 
M,
$R$ff'sA$,4ff$1$1.
  &	 ] _ fi   , " ]&RN)y)8(B0^)
@fi4A$"8c, Ifi+=)Y))
  )ff"
  ,)<
 5	  $ ) J $81 B , =)' Y8))
"/ )]
s!,$G=)?/
R?/cfi81$
   {fi4 ') Y)) 
 ] _ $%9P+ fi4 &w
  
 0c&& =L /c fi81 A A 5 Q,&1 
\ "?
&j , &
$  A
;*>),4M&
 wWBn )A C
 7, =) Y))ff  $N R) 4 $ j  0, 
 $ . R j   
 0&&& =P /& fid1 $MR9  n,n4E 7] R
A 7] Bff! -=^


 DC
 R,&
$ \ "?
 fi4 D C
 58&
M mqEr
R

 
  
 
 
$$
$
 

 ^  P^ 0
  
  ^  M^ 0
   
  (  M^ 0
 
  
  (  ` 
 
  
Z(  `<F>4ZF 


   

 /" $  j$$1.
R/
fi81 &$,8N&)A"
$P

%& D  

.0/21,3.0  k^d fXg0hXi l 

 / .$
ALL&fi815    ,)	/&fi8&@C
'.j$&, )"&571ff
" $ );&K]?_B),) '"A
$,4ff$&$1.),#L&fi817,&</e3C$
79  ^3


 Cs  /" $  j ) ),j$ d"$1.  ,  ) /"&81$&,&$ ^7]P "  7]
 &&&  L& 81
, 8
4 " 
 N 8 ,& $G=aq 1
>
r+$%&
 P*+
E  

2 Z
 %   

 `
C

0
=  fi @ 
n  fi

 Lr
r B 
 *> G
EE

fi9G;ff


G
!@K>DYffGE)FX
"5'YX
&
Yff+!Gffs+s+
 9 ?D D) D9 ?99@9999

w9C
,+2  0 C   I    
  !    G  
	) 
	D 
	) 
	) fiff5


















^

C


2








W



  ! 9W ! A
+)&+A 


  
 C    2
  G  
 !A G )n G W+2!A+9 
  
 ^C   G  )
  G  
 n
  G 9& G A+2W+9 
  
 C #"@
&+2  $ 
% 2ffIff'&0
)(+
>+*,(>
+*2
wffGGff
-"G!@
.

A/-

0(>
>+*(+
>+*Z1-
AG
>.+
JAIff'&>
2(+
23
+ *,
 (+
>+ *?
4
 -G>' &+Gff
2
X
A
-
A
Z5 -

6
 (>
+ *7
 -'G
8
9;:5<):>=#?A@BDCDEGF>H0IDF>CJLKfiMDCDEGF>CNJDOPCDERQB;SGE;TVUAFXW;OSGEYZI
% I!ff

 G"5-
[(+
>+*D\-
J
'-
'D
I
#ffGGff
]>@


^3_-

Y
!9	?'G
`,fi-
A
<G
.DJ
wI
n'&0Gff 
I
M50!D<
ff

 % C>Gffn
A
G

!@^A
5A
9XffE9
2a? ] 2b _c  edDfXg2hXi !$ 
! ff?
F
#ffGGff
-G?
@' alk ]F % FY
J^0D
AF'
L)^+!C
ff
,@)^D'&0Gff&^
^
@G'

m &0Gff!
wffna2
 3_-
P
GffIn
 ] <a
L><G

o
 c  I
9Z
 -
	
KD
ff

j 

b

p4qrsutvxw!yDzx{|% DG0}0
'<'&0
IG@^'A
A>
&YffG;9

09 ?@ D9 ?9 D)9D&99)
  9  I G )I G F
+)C09
 
 	   	   	   	   ff +@E+2&5+? G  ? G  95
 ! @ 
  !   W
  !   A
+)  A
+  
          M
  9
  G  
 &
  G &
 M
  ! 
 W
+)A
+& 
~  
    
 W

  ! 9
 A

  ! 
 &+2
 W
+&  
+) 
~   G  9
$ 

8
yz5ywtwZw2G1r^XGnNNw1w0sRNx1s
% 5Gff^<5-0GffA!ff&!LffG^ff}0^
:!
>.@wff3
GGL
-

(
, j ;-
Z.ff?X
I
}`
?L

GD22LG>

Y
A>J
,}0
!
>G.5}
?ff"IA
w
A
^ff3
IML
 -0GffC % I"

55L!ff! 	Y
C	
 &GffI5

Z\

fi ^^52P+^/^\

^x /Po^Z' 5)^PZ'PP/5P4P)'PP5/P)  ooP/ PZ
/!0Z'/^/4/)^X AP/o ZV/PP)Z'Z;
 /^!) 5PZ'P55P!1>|l|5 P5'GZ'



x \x
   P1ux  1x
 \ ^/ L/ ^Z|^^ V/////^^2


^ 6/P//^'2Z^5/4G
o/A)/fi>fiPZZZ0/5
 P
/fiPVP6PP5/5!0P+Z / /Z^) >fi'0Z^ZuoP
 P5  /4/  ^Z^')Z'
/oZA^
 /4 ^  ^Z^) fi^'GZ'  
 5o'GZ'4/,025P
 Z^ >5Z5VP
/P[5 
PAx ^5VoPPX AP/^Z ' 5/  )
 'PP/5P4)  
PZ)
5Z 'Z'o^^P^V/P/ PP  ZoVPA')Z''P55PN^
 /5   D!Z 0 1  Z  P 2'_ 1  \     

     		
 /P   
fiff   7      		
       '


 '^fi  

 x    		
 x    

  V ^5V/  Z^ 0 ^^X   _   _     		  XP>  PZZ
^ )55PZXP P  ,Gx	! Z  #
"  60Z'5^/ ^ P5
G 55
PZ ^ P///PP) N 6 P ^%L
$ PZ^/  ^P^ 6/P/>
 '^/1
 '^ 

)  P6G^P   4>V^Z25PVZ  
 ^4Zx  P  Z)Z'fi
'>/Z;  P>^^[X V[^5
xA/5  
 P2^ /Z \ ^[,^

&



P





o



/

,



P



/

P

^

'





N



^






G



Z 0P 
*)


/1  ^Z   / ^ ^/'PP'
&P^ 6 /P/>AP  )V2^Z5Z0 P5Z+-, 
. ZVP
/5V^^
('

P/ P'

/7PoX V25

/

V///)  o'^'PPoP^[5 P5')Z'ZA)Z'Z
 ^5 Z2

+
0+

^ZV^PZ'P55 / ^PXP>^Z' //  ^')Z'G/2/P) P/Z
005 P
 ^! >/5Z P
 ^!fi^A^'0)//
^Z!6 >5 

	/

P ZZ>  PfiPP^ V>P/ /^  P^fi ^1^Z  //^o'P P
5[x ^5Vx>5 //[ P7Z/0+ZV///6^44N^P^ 6/P/>
)  



'


'

/5G /  
 ^oX2/'/P/ PP'P/ P' P'5
 P  PRx>5 / Z
 [^Z)Z'57X^5VPP/ P'P/A^
' PP'57 



1+

'

2+



('

3%46587:9<;1=0>@?ACB
ED/ZXP>
x

^fi'/P+Z

Fff

^ \_52'254PZ5)Z>[P4Z'Z2

/  Z'/P/  / Z^'2P/ x  AP/'P>,XV/5Z5N>7'0Z^/P,x
0Z'5^/  X AP
 /x V>5Z/  ^[/Pfix
2Z'5^ 0  Px AP/Vx0P+P
5X
0Z'5^ 0/7^P Z'PP554^V)'P55Pfi^V)  

fi

^Z'5)Z[07^ox/51/ 

fiff fi

G

XP>oX 2Z  

IH   !J*KIL     MK  !J ONP QK 
 !J*LK   ML !J ON	 L

 
 !J  ONP QK    MLVRJSKIL

IW 
    UKVRJSLTK,
  !J  ONP QL 





Y[ZO\






 ,RJSKIL      ML   

,!JSLTK,     UK 
    UL   ,!J ONP QK
    U,K   X,!J ON	 L




fi]^`_bac_edf_
gihbjlkmQnRopjFn
qbr`sfo6tikusRmivw8xy*z[{
|pn!mUj}nRt~ksf`st	
~!SV8!SI# 
~!*i!STFM 
!S  ~!S  I  
!ST  ~!*  I  
!VCO	`  X~!VCO	`  X #  !VCPQ  ~RVCOPQ   M 
~!VCPQ  8!VCO	`  X   ~!COPQ  !COPQ  I  
 U!U    URM   M 
  `Q!M    `Q!M  I  
 U!U  `Q!MX# 
  `Q!M  `Q!U   
gihbjRsfnR%rtiMshen[RjUhbjV`s*UsfMsRsRk1V`s*Un!kuMj	mUhbjjPqSj[	bUrsfsRk1UhejVnRigihertIrt
mUj	emQj[tMj[OMj[XUhbjn!Msfo6rlksRmQo<en !*I ghbjFrer`UrnR2tUUn!Mj[tIrUhbjFemUsR`j[oPsfetUrtMUt~sRk1nR
Uhbjl0sftUtUrV`jIn!mQmQnRbRj[opj[Ut~UhbjlVsSQSt~:nRe@	nR0jr1rtTsfertTsfbsRmi0sRUhn!mUj
sfUhbjUn!V`jRghertemUsRVj[ohenRt~nptUsfbUr`sfErnR2UhbmUj	jksRmQo6tTsRknRetTrSj[PUr`sfbfiSVnReEj
etMjlUhejFsfbjlkmUsfoSj[PUr`sfbfiSfiS8jFRj	IUhbjFksf`srb<kusRmoen!jlkusRmIvwxy*z[{
|f
 # (# 2 RSI   `Q!U    !VCO	`  ~!S   U!U M
 M (lM 2 RST   `Q!U    !VCPQ  ~!*   `Q!M M
I  (   2 RVCOPQ   `Q!U    !S    URM  ~RVCOPQ M
    (     RVCOPQ   U!U    !STi    URMi  ~!COPQ M
gsXmUj	emQj[tMj[OUhbjSenRUr	n!Ur`sfsRj	mUhbjrer`UrnR1tMUn!Mj[t<jbj	j[snRbq*rrn!mUX!n!mQrn!`j[tF 
nRe  ghbjFrer`UrnR2tUUn!Mj[tn!mUjFmQj	emUj[tMj[Mj[SEUhejlkusfsre<ksRmQo<en!jR
      R  U!U   URM  RVCOPQ  !COPQ  ~RSI  i!ST 
       R  URMI    `Q!U  ~!VCO	`i  !VCO	`  !S  ~!ST 
      R   `Q!M   `Q!M  !VCO	`  i!VCO	` 1 ~!S  !ST 	
       R
gihbjsfbMj	mQo6sftMTjPq*rtUMj[OUrnR0SenRUrVj	m~VnROUrj[tUhejVmUsR0sftUr`Ur`sfenRV
n!mrn!V`j[tbj[tUPmQrVrbFnRet	
Uhbjeer`Rj	mtUnRVSenRUrVj	mTenRUrVj[tsRj	m~UhejrVr`UrnRetMUn!Mj[t[enReUhejrVbj	mQopsftMjPq*rtUMj[OUrnR!n!mQr
n!V`jFSenRUrVj[t~UhejFmUj[tMisRk%Uhbj}
n!mQrn!V`j[tTUhen!imQj	emUj[tMj[ijPq*j[	bUr`sfetsRkUhejFVnRksRmVn!mQUr	en!m
!nRbj[t~sRkUhbj}eVr`Rj	mQtUnRVnROUrj[
n!mQrn!V`j[t	
 I# lM l      l#lMi    
    
 RSI6!ST  U!U  U!U6!VCO	`IRVCOPQ}I# }FM }   }   l		
gihejSenRUrVj[<sSsf`j[nR<ksRmQoVnirUh}UhbjTPsf
UeePUr`sf<sRkeUhejksRmQo<en!jTbj[tUPmQr`0j[}j[n!mQr`j	m%nRt
Uhbj0sSe6nReUhejn!0sRjFenRUrVj	mtnRtTUhbjemQjPeq2*rtMmQbjr`knReEsfe6r`kUhbjemUsRVj[orVtMUnRePj
rSbj[tMUr`sfhenRtlntMsfeUr`sfXIr`UhnRjPqSj[	bUrsfsRkUhbmUj	j0sfrUtsRkUropjRgihbjptMsfbUrsf	nR80j
ksfeepS6nlUhbj	sRmUj[opCemUsRj	mTksRmTT8UhVn!mUj	UbmetnlMmbUh*C!nRbjnRtUtQr`feopj[Ms<UhbjisfbMj	mQo6sftM
jPqbrtMMj[UrnR`pSenROUr`Vj[6!n!mQrn!Vj[t #  z FM  z     z     kusRmvw8xy*z[{
|lUhen!mQj	emUj[tMj[VnRet	bj
tMsfeUr`sfXnRtUtQr`fet (V Ms  M  nRV    0nRe Rfi[ MsnRsRUhbj	m!n!mQrn!V`j[t i   IIj[ePjRn!Uropj
yUhbjlVsSQrt~opsRj[kumQsfoMsRsRksfMspUhbjlUn!V`jFr`kr`irtsfMsRsRkn!iy*VnRVn!~Uropj6{
UhbjF`sSQ:rtiopsRj[kmUsfoUn!V`j}sfUhbjFMsRsRk%V`s*Ur`k%:rt~sfUhbj}Un!V`j}n!iUropj{!Tgihert
sRSSr`sfVtU`mQj[nRQhbj[tUhbjFRsfnRMrtTsfXMsRsRk1T6tMUn!mUUrepkumUsfonR0UhbmUj	j}rer`UrnR2tMUn!Mj[t	
[


fiVQbVb`V8*eVbbVfVV
F	ff
fiffffff	  !#"
$T&
 %')(

!+*-,/.101
324!#" 5
')6798:!<;>I
= ?( i#;@A(CBDFEfiG)F5
')6H!I,J7;>I
= ?( i#;@A(C2)KL.F5
K	MONQPFRDFEfiE>PDKL
fiDSTE3	GU0NF2A
fi0!VBWKNMX	5
')6  ,C7Y;>I
= ?( i#;@ Z(C	ff
[0NF2ZF  ffffffQ    !R" 5
*
]
,
^
D
O
M
	

#
M
_
S
ffKANFB`a	5
\
ab*-,/ cd	egf5
')6:;>
= (
')6Y1	ff
fiFaffffff	1  !ahid	egfj"
;>I
= ?( i#;@ A(C2)KL.F5
km*l 
')6Y01NF2Z	ff
fi  ffffffQ    !ah:d	enfj"
;>I
= ?( i#;@ A(CBDFEfiG)F5
i#;@ A(C	ff
fiQffffffo  !phdjq`enfj"
?(@
rm
3s.KRtu*?vw1	ff
fiG
3N0yx1KLNuz	1.1KbBWNFKZ{u.1DF0|2
~}	NuNE3	DF0BNFKLM.1EfiD
m^H1nTzTg1
Y1DPFffPF	E3NFx_	JDH2ffNFK	MO4x1KNPFffKiBWNFK{u.1DF0|2
~}	N|NEfi	DF0JBWNFK M#.1E[D@
fi0|2DF0	0>9	FF"
DFGyDF0a \ 2)	01G
fiN0NFBR2ibD	Po
fiG?.201DFMx1KNoz	1.KLBNFK2GD2
fiG)}TDS
fiEfi
fi2NFB&BWNFK M#.1E[Di
fi02
x1KNFx_NG
fi2
3N01DFE`E3NFs
fibD	Po
fiGffgNFsF	M^DF010>`nNPF	E[DF01>	FtF" ^2&
fiGbG)2)KLDF
fis2)BNFKDKL2)N \ 2)	01
2DPu
[G.20DFMx1KNoz	1.KL&2)N1DF01E3&.101
fiPFffKLGDFEn{u.1DF0|2
~}ffKLGff5N0RG.1  \ 2)	01G
fiN0DF01iG)NMO

fiMOxKNPF	MO	0|2GDK	GzK 
3S_	aSupDFNE[
@ff2DFE	FF" +rm
3KLG22PDKL
fiDSEfi	G{u.1DF0|2
~}	pS|
2N.2)ffKLMONG)29{u.1DF02
3}ffK#DKyzN01G
[ffK	>2	0Y21PDKL
fiDSE3	GRS|21G)	zN01H{u.1DF0|2
~}ffK	mDF01
G)NN0n \ 
fiG)2)	0|2
fiDFEPDKL
fiDSEfi	GzNFKK	G)x_N012)NNFK)0No	G&
fi02G)	DKLL2)KffF`.101
3PFffKLGLDFEmPjDKL
[DSE3	G
zNFKK	GxN02)NDF0o0No	GffUA&STDFG
fiRDFEfisFNFKL
321M
[GAs
3PF	0:
fi0rm
3s.1K#tuAAR}KLG)2ZxDKLDFMOff2)ffKb
fiG
1 
3Bm2RN.2)ffKLMONG)2b{u.1DF02
3}ffKZZ
fi2DFz2
3PFPjDKL
[DSE3	GZ
[GU \ 
[G)2)	02
[DFEDF01zF  NF21ffKZ
fiG)FT2
G)	zN01:xDK DFMOff2)ffKKffx1K	G	02G2O{u.1DF02
3}ffKLGff_DF01:2921
3KLi
fiG@2OM^D2)KL
 \ NFB29BWNFKLM.1EfiD
fi0
ffEfiDF.1GLDFEBNFKLMmrNFK2BNFKLM#.EfiDue  e LTo) ueTF)e Fo "	&e | e	")"n21DFE3sFNFK 
321Mw
fiGmffDFEfiE3	
Z
32DKs.MO	02G^  d	eg)eTjfzd  	  Qfzd	e  fj zd	en  ff)e    e  fj" #A1G.1S1x1KNoz	1.K
o1 xffKLBWNFKLMG`.01
32mK	G)NEfi.12
3N09DF01O.101
32G.1SG.1MOx2
3N0>gA1STDFG
fiDFE3sFNFKL
32M]Z
3292AG)2DF01DKL
zff
3	0|2#
[MOxE3	MO	0|2D2
3N02)	 101
fi{u.	GBNFKR21bD	Po
fiG?.201DFMxKNuz	.K^
fiG&DSTE3^2)NiGNE3PFN01Efi
G
fiM^xE3xEfiDF010
fi0sYxKNFSE3	M^G	DF01C?YD	PF1ffPF	E3NFx_	C0ff2)	 101
fi{u.	GBNFKG)x_ff	1
fi01sH.1xC2
DFE3sFNFKL
fi21M9.Kb2ffNFK	M94x1KLNPFffKR@
32:2^0ff]2)	L10
fi{|.1	G1
fiGDSEfi	:ffDF00NF2&G)NE3PFODF0|iNFB2
S_	01LM^DKoGU
fi0DSTE3RO
fi0E3	GLGU21DF01N.KLG&zFFG)	zN011Gff-"
A12)	L01
fi{u.	GRBNFK9
fiMOx1KNQPu
[0s2NFS|Po
3N.1G#DFE3sFNFKL
321M<DKSDFG)	N0YBDF
fiE3	Efi
32)ffKLDFE?ff2)	
2
3N0VrKff	MDF0>	FFu5#g
v0|S.1EfiDsDF0>#	FF" bDF0BNFKyBWNFK M#.1E[Du  N0px_ffKBNFKLM^
fi0s
zNMOx.12D2
3N0@
322.101
3PFffKLGLDFE_PjDKL
[DSE3	G  S_ffBNFKRDFEfiEgPjDKL
[DSE3	GA
fi0D	PFSff	0iDFGG
3s01	D
2)KL.24PjDFEfi.1F#rm
3KLG)2ff_S_ffBNFK9xffKLBWNFKLM
fi0s \ 1DF.1G2
3PF^G)	DKL N0DFEfiE`x_NGG
3SEfiR2)KL.24PjDFEfi.1DFGGL
3s0o
MO	0|2GU2)N^PDKL
fiDSEfi	GU
fi0YDFGGL
3s01
fi0s9DF0|2)K .2o4PDFEfi.	G2)NG)NMORNFB2PDKL
fiDSTE3	G
fi0  DF0y2	0
x_ffKBNFKLM^
fi0s.101
fi2#K	GNEfi.2
3N0HNFB2)	0o
3	Efi1G2)KL.24PjDFEfi.1	G92)NG)NMONFB2PDKL
fiDSE3	G9
fi0HA
	Q

fiZ3QT1
)L4jFfi1	RF1F[	L	#1O1)R_F3	):)yj fi3	ffu	z1>OF
oFZ)	L )ffFfiZF3fi:)L)yCJF1HF)Lo4Ffi	))^F@
Lfi3	U[
 +F1y	
 ffLWFLfi9113	)fi13yufi	fi1Oz) F1fiz3>1	91FU)^_
Ffi	Ffi)F
 A1fiL>ff)	z[Ffi3	:fi3)ff FfiAu11fiA	)fi13iffFFfi_
 _ffFLO	
Lfi3	1@ffF1FU_L)	iFU& oU1LFL1fi1#LfifiFuZfiLfi3	

 	u1F|fi ff	
u)^&FffZF&ffL	A1)ffLO)
 	u1F|fi ffff	
 fi _FF|@L	)	LL) fi	F)1[ @3
 
fib VWF&y) #FL1fi
 Z3
 
11fiFffLFfi3
 	u1F|fi ff	HLfifi	ffFfi1FfiFb
 )Lo4FfiFfi1O	|^ffF
_^	Ffi1	>
 1	|313:)	L11 	|
 ^	
 T3fi
 L331fi1yff[F1)^)ff"
 !:R	F 
oFg)	L )ff#
 !)91U9$ )ffU	FLfi3	fiz^On% FA)O"
 TfiF11fi1
1FT3	^ffT& 
afi' fifiA))ffFffLFfffiF1#)ff Zfii3( Vu1#ffF13FffLFgjL[3	
offffLfi1y[	FL>mF1fi"
 	u1#ffRFFL31O	|&1#1	F)_^z1fiffL	fi
1Lfi	U1F
 

)+*,.-0/2143658791;:=<?>
@ i	FZ L3))	A1LFFLF 1)LF1fi)	z1133F
fiF11[F3	^9)B
?F1
_ffFLO	z fi1FCff fiO	|fiDZ1fi z1133F+TfiF11F^_ff	W1|:
ffF	OE1 Fffb1fiLff1)	yfiu	zfiFu
 fi|?) F1fi3gUF)^[ffFfi3F	ffL)	9 )ffmF1_ ffL)FLmF1#?FLo
fi1m	zL3_?[13fiFFRFFo))	ffGZ
 1fiH FFLFwfi1fffi11	nF)^fiF	ff 3
F?[LfiF|bWF1. F3	fi1)FzFIA
 O1Ffi|jL[FJEK ffffofi1GL o |1ffLffGMONNPRQ
S [F	nCMONNP?`T F#L	fi)	)	L11 |	 	`FU1 L11[A)	L O' Fz	mfiF11fi)fi11fi1[
		&F	z	|#fffiFLfiffF0 [F1ffLff
 fiLfiF|" O	FYWFL1fiOR^)L1^fiFfi
	F 13))	UFI F3	+fi1)FzF0V |j fiFff)ff ^fi	|b ff )FLUF1
fi1fifiF_))	ffF1ff	WX fiF	LLiFfi)^fiz1331FY [F11fi
@ 	F 1$ )ffLfi	9F@_	1 1^[oZ ff\A ff  )9	L1^]
Z 	O))L)	^T fiF11fi1
111ff%
 fi__ 	1	|)Lz	?Fg11zffLFfiO1zF	'_ 11)`1 LF3	/fi)F1z	aZ 3o
^1zffFfi|FbA
  1[_ )yF@1[#_	1 1^[
Z fi9)Y	^1))L)13OffF_OF
1 F`F:1 	F3ffb))3F9`Z
 fiz1331F+ fiF1fi^1 LF3	 1zFgfi1)	FiF
)3ofi&zFL	'_ 11fifffiF[ffF; F3	fi1F1z	U)_ L)	fiF%A
 )	z1y_	1 1^[Z fi
Ofiu]uZ "
 FLfiD@ 3)ffFffLF?fi13fiFm))		 @ 3ff1&ffF	9E FffTff 1z1331F
fiF1ZL	FL	b3F	FF`))O)[ffFffL_ 3fi&))FcA fiU_	1L^[
Z fi
LF^ff)ffLWffd 	u^u1#_ffF3o[oZ ffgFD? ^ffF3FO1 FT3	eZ 3g
f 3o[oZ fi
	F)39fiOF. FIuh +y
F F1i fiu]uZ b`1 LF3	 1Fb	'_ 	z3F	fihkjlM =f?j?hC^M Fm?ikFmm
fi1fifiF|)	ffuF9)LF1[)F1F1W
n ff133	`fi9)LFfifi
:
 _1 L	)	fiOFT1	)
))	@)fffiF1LF_WFL
A1o ffL@z	1 3z1Lfi)@F)O	u	1z#Fu^cZ3F3@FuFL@z	zfizo
)	fffiF#u^ff#
 p0Fz39uF@F	F D
 F3bfiA _	>_F1i_ffWF# u	ff1fiI
 TfiF3fi
@
Fo
 Zo Z
 ZfiL>
 A^FF?fi&)FiWL
 ffTL)u)ifiF)ff  F1fi_	1 o
^[ ZZ3i9	1zo1fiWL o	z3D
 fq uq muI
 V:1fibffF)OffL9[@3`
 LF^ff)ff1
fifiz	F)	11Lfi
 fiF)	 L>`^3	FF?&
 fiF>
 r@	1z^^1ffF	9E 1QFff#fi"
 ffL)
ffFfi3	
 Z3WFL1fiyR	1zo	o
 TfiF1t sQ o	ff31&FA3	Fb
 M`	
 @3FL1fiyF
3	Fu
 u`FY)i>X
 <^
 ff )WF #1[1#[W1)i)L
 fiF1#	FL1	
&FF`ffF_ o)LFz)	>

 V
 T3
 &3F)fi)fiffA&ffFfi1fiFmWF #1["
 Z3

vOw(w

fixzy;{}|]~l}~lW{}ACy;{4}fi~ly;{l}`?}{}|
[R?^
O

O
O
(
O
O
k
C





'[k'O _4'O kt ] 4[ lClO
??
6 
C q 
O
CO
6 _?k
Cq 
O
O
6 O
Cq 

?k
6 6
C 
O

 OC(
C 
O
OC_6k
 Ok
Cq 
(
C O6 k?
Cq 
O
6 O?? 
Cq 
O
_k6?k 6?k kl
k 
k
k??RO O ?k
k 
C
4O6kk (k klO
kq 

k? O k
kq 

k}W R% 46[ O
[l  R?^2}[} WO

[lO4C4lDbRO[W? lqRqR\ z[ltI4 kk]'tlX4\[[O'Y?4'A[l[4['O'
}AOl[4"o4 ]'? l[W?4l'[ &  0_'O_[l^]4[Oo_k4k[4X[l^'
]I}kc[}k
][O'Y?4'[l['_2} WO4[4
k["[^W_  4c;]'a? 4^[l[k}W
?WOz[l}Y_%=[?&_[4#'O?}&[lR4Y_zH4W[ 4'[k'O_l[l#[4Wt^[l#4IY_a
_4[Oz [4R4[fi}Oz?O].4CC[l?l[[[l"R4Y_z=4]?]W[W?4}k] k}WO
D[4k].4C=[l`}[A[l]4[H}A[l&[WR[D[l^R4IY_"
4?C$WOka4RlOD[l
'Ok]t']_  0[4^]44oa_[?l4#W'] [ z[R[[k[W?cW[ c }[RO]' 
 l"t46[ O
W[[lO4R}l`]?RO[W? lqRq k[?;k]k}W 
 k}W  ?[4'[k[ '[_X?[l[?l[W?`'?A}WC[Cz]4[}O^  l}W
'?4[W?&;4%k]#?O   4YO44fi IC lc?Y[lO'4]}WO^az'I[k"[l}R]Ra'
"_[[&?C}?l]k[?o'[[?[44 C[l2}WC[Ct+[?l4[?l}?l]k[W?}  
O]G[l[fi}[}WOe4'[}O_YW[[l[_`?l}R]R4g?l.%[l`[l]_.}[}WO
O4C4l?c4[O[O6'OgOk]_O;z`4O`Ol_]k'O].4kI"'__t+;k]_'_"klOc[4k
]}k]'_]  D[lD[  Oo[lD'?4[W?4  lg[[k['[_?WO  k}  k[D[lg']l
]I}k[4ka[_4[O'O%I'?l[W?'%^O]'_G].4kt}^[l'].4k[4k
[[O[?}'^[l4?lO'
}k]_'_c lO24t[l_[k]l^'?4[W?}4 
 #[lI]4420[4[l_[OE4[(_Ot].4`z?W.[lo?Wl^ lt^k[W? 
 l.}t'"?4^D?WOo[l^'O[W? D4t[4O4R}lX"lO[tWYOY[l^'O?4? 4^
[l#4IY_GY}WC[C_6[4[4Wt`[lcR4I_%Y 4W[l'[k'OOR[4?4[[^[lcWOl[^H?lO'
CO_l[W?Al_OlOH[4I;[g[l`}Y_a'[k'O" [4I} B%'_}k]k'`[?e[l}Y_
U[oY?[tt4[4[fiC[[lI4IY_0_4'OcX[l].4C}[l'_O[g[lR4Y_
4[Y?[[W?4ktk}WO_=[l&OW?[A[l4IY_o2'O?44IW"[kO.?l[l_]O`E4[_
'_k4k'"[l]I}CC[l"4[&[loR4IY_aUl?C$WOk+lR4Oz [4[Ok]]X']_44[l
'O[^[l'tl[CEkl2Y[l].4  W[^[lO4C4l"[?CO[W? lqR [l[c]
l;4Oo.OW]k'k["}[_[k;W a [l_
[?4Y4'OX
zOl4[l"]4?
U[c^OXYOY[[lol''O}o+;424X[4o[  o}4 
 4A]4[OX  k}W  [?4?4W9?l}][l lOB[4k[lA;[_4[O[O6[k[W?}
RO[W?} lqR  lqRq 4 lqRq k[lO[O[ l?WA?}l[k[?4WDlO^4}l  l]W?[W
Wa_]4[g4l[ Ok}WbWa_}Y_&IlR4O&[lg[Ok]]9'[_g[l  }WC[
O

fiWl;4?
O4C44 ;WR]R  '[k'O [  '[k'O _4'O kt ]4[ l ClO   l
RlqR

O


 
C 

   '
RlqR

O


  l   C    '
RlqR

O


  R 

't l
RlqRq

O


 	
C 

  '
RlqRq

O



ff 
Cfi 

  '
RlqRq

O


? k
R 
  'tl 
RlqRq

O


6 ?
C 

  ' 
RlqRq

O


 
k 
 
'tl
RlqR

k

 k k Ck 

  '
RlqR

k

 CO   


RlqR

k

    


RlqRq

k

 C  4k 

  '
RlqRq

k

 k	 C Rq 

  '
RlqRq

k

  ? Ckq  O 'tl
RlqRq

k


C k kq 

  '
RlqRq

k


O?  R  ? 'tl
 k}W  4
 [O    
WC[CA] 
 l!}W#"W    $!}O4R}l  [?  O[W? lqRq   %"W    ]!}W_"O}R4 l  [?
 O[W? lqRq ^'&  _[  ["Yo[l(!4t[l    "4*)_[O}+"a?4 '_O '"44"'^    
  kG  W' "R4IY_  '_]4C'[k'O-,  [_/.0.  !}}  [?  O[W? lqRq+ ]O0  0!}
'`'[ && &'?c    c[[k'O  z'__]1!Y?6[%  [ 32 4!}}  ]?  O[? lqRq   _[#
l.[4  [O''] [W?&4  #'_[%  !Y_]k't%O4k;WO&kzO  !Y?G  [&&^Y4*)_[O 
  I?4''][?'?l[?5
 !}4k[o  _[  [.lc[W    c  I[ !}W_2[!}[O'O[k[W?76
4^[o'Ok]  4_OlO  0 8;44 l.9 !} 
W    O'}R]R
 "a] 9 !4[;WO 4[[4OG  #'?l[?    ' !;k]k': !}[}WO^%G_( &
O;&  c  YO'c_ [[_7!;4l_]    k#^kO#  O'<!}[}WO^4>=_4  kc  <!;4
[ !4]O'O6`? !Y?[[W;W^ CO_l[W?4 6G}  ?}''][.?  $ !;4.k[Xl.`[  `
  IO}  ^k]R#  k}W    I'!}ktk'`_ [[_@!}44 lA!4[}WO&  B /"a__'67"  O
?4[ l_]l`  kc  R4I_2  OWO^O6[#  o]O[4W[4 !}42[Ok[WO* &  W  ,C8  '_O
[  o  ;W_+ !4[}O^D .c4D  ^l[?D  !} 4"I}  ]^? !}_k'O  A
_[]_E !}4}lF 6R  o]4[O2k]l4] !G!Y?6[ l 
 ?^%    a}'_[kk[W?4kY?l@ !;o'Ok]  o?lU !G!4]?  k[z 6'_[O[[l I H O  ?l 
  _[Ik[o  [_ JR4[> 8}_] 6l?l  _[O  !4[(_lROl !Y_  ] 'Okt  ?k] k}WO0 JR4 
[> 8}O^	 &  c  W]`?4  ka[ !4[O'O !; CO_l[W?4    G%O_}'  : !}7 6?] !4[O'O'O
&  `?l'_]^?'k] k}WO 6'_  _< "cW    `}4W_][ * &5J4[> 8}Ogkk]k}O    ? 
[lO}_WO 6+}4K JRlO* &l_'_t^l  & RO_l[?  k   ?}4L
 "W  ?4o'Ok] H    "o4OK &





?M
 !;k9 "W   ^ k?44[W?44 !}}4lD`?b 'O?49W_O2    N
 !Y?* &Cl?^
 W_tk]  &6}l2?  "  W]X  
 !4[ 8O5PffQ7P   oO4C4l?2&W  ]lO' 
R U  ' "cI  k;W  6  z]4[O  S
 !}IOl_]k[?._.Y%.4  WO]=  .4Ok='  
R4Y_U  4W[R'[k'O U T ?l2    2Ok]K&I?44[W?4!}4}lc]W  ^0 0k}W
'o   W}W
[&kY  (R VY  k#  6Y   &N!4[C44W !}4c   X!Y?lO6[ +WO4  }  _]  [?4]4
 X!?4O6[4[_O?&[ !}W0!4]}WO^0  O'      (]k}Wc]4[OGk[#4l2'I?l
YZ/[

fi\?]_^O`baFc	dOe	aFf*^OgheX]_^GiOf>aFfK]_^FjOkAlk/jO^O`

m(nFopq(orsutGq(p'voqwxrtOy*oroz	m({m(w*pz7|3}Fpq4o ~F{rtOy*opqUm(nFotGq(p_y*or9?wKzS{Oy*o+FzG{ *voo ~Xm;ozG(wKpzG
p?m(nFo9-{vXwKsGm(zG{rtGq(pX oGFqbom;pL-4} pzO(wKFoq{yKyp?m(nFo
m;qbFm(nXsuv{yKFo{(bw*zGroz	m(-m;p
m(nFoGzGw*voqbb{yKy*#G{z	m(w>Oov
{qbwx{Oy*o(G;mm;p#voqbwKCm(nG{m-{9tOyx{z5m(nG{m-nG{EoozCpGzON{ m(G{yKy*
q(o{DnFo0m(nFop{y7wKz${yKyE{;o|}GGq(m(nFoq0Fovoy*ptOr9ozffm(0wKz#m(nFopq(orsutGq(p'vXwKzFm;obnOzGwKFo?Cpq:-4}
{zG5tOq(ptEp(w*m(w*pzG{yE({m(wx_{OwKyxw*m{qboyKw*oy*#m;pwKrtGqbp'vom(nFo(o+qbGz	m(wKro4Fq(m(nFoq|
LO_O@
?pm(nAIopm3{zGXr9wKm(nS{zGq(pq{zG?pyKyKwKzOItGq(o;oz	mI{yKpqbw*m(nGr9@Cpq3 pzGOw*m(w*pzG{y
tOyK{zOzGwKzFm(nG{m{q(oO{;opzm(nGoy*o{;ms pr9rw*m(roz	mpqtO{qbm(wK{y>supqbFoq3t_yK{zGzGwKzG:tO{qD{Gw*r5|?pm(n
{y*pqbwKm(nGr94?pq($yxw*o+ pq(q(o;tEpzGGwxzFyK{((wK{yEt_yK{zGzGwKzGW{y*pqbwKm(nGr90Gz	m(wKyE{9(FOp{y7wK0Gy>_yKyKo
Wm(nFo0{tGt_yKwK{m(w*pzpE{zptEoqb{m;pqm(nG{mFpo3zFpmnG{'vo{+GzGwx	Fo?pFm( pro	m(nG{mwKm(nFo0ptEoqb{m;pq
wKzFpzOFom;oqbr9wKzOwK;m(wK|4mm(nO{mt1pwxzffmAm(nFoNFovoyKptOroz	mp:m(nFo5 pzGOw*m(w*pzG{y?tOyK{zwx(tOyKw*mm;p{
zGr<Eoqp0;ot_{qb{m;o(FOtGq(pOy*or:m(nO{mW{q(o(py*vo;ot_{qb{m;oy*So{bn pq(q(o;tEpzGGwxzFm;ppzFo9p
m(nFo:pFm( pro?p7m(nFo:zGpzGFom;oqbr9wxzGwK;m(wK4ptEoqb{m;pq'|nFotGqbpOy*orwKm(n9m(nGwKU{tGtGq(p{Dn#wxm(nG{m?m(nFo
(w*oUp pzGGwKm(w*pzG{yFtOyx{zG{q(o:o ~tEpzFoz	m(wK{yOpzm(nFo-zGr<EoqpIGzG oq(m({wKz	m(w*o{zG{?ozFoqD{m(wKzF
{N;pyxFm(w*pzLm({o{m<Eo;myKwKzGo{q+m(wKro9pzhm(nGo(w*o9p?m(nFo(pyKFm(w*pzO(G{yKy*o ~tEpzFoz	m(wK{yCDIm(nGwK
XwKzGp7{y*pqbw*m(nGr3wKzGnFoq(oz	m(y* pzG(Gro{+yKpmp1 pr9tOFm({m(w*pzG{yGq(o;pFqb o|}OFq(m(nFoqbr9pq(offpm;oz
m(nFowKrtGqbp'voroz	mWp/voqm(nFo$m;qbw*vXwK{y pzGGwKm(w*pzG{yt_yK{zGzGwKzGN{y*pqbw*m(nGrm(nG{mA(wKrt_y*qboGG om(nFo
tGq(p_y*orm;p{zGrW1oq7pFyK{b(wK{ytOyx{zGzGwKzFUtGq(pOyKor9Em(nG{m@{q(oU;py*vo<(otO{qb{m;oy*wK(r{yKy|nFo
{q(o<Eom;m;oq-m(nG{zm(nFo<m;qbwKvwK{y@{y*pqbw*m(nGrnFozFovoq+;pr9o<pm(nFo pzffm(wxzFozGw*o{q(oAw*q(q(oy*ov{z	mwKz
q(o{DnGwKzFm(nFo<p{yGpqw*Sm(nFo;ot_{qb{m;o<tOyx{zG0nG{vo<tO{q(m(wKz5 prrpz7|
4wxr9{m;m(wom{y|%WtOq(ptEp;o{z{y*pqbw*m(nGrpq pzGOw*m(w*pzG{ytOyK{zGzGwxzFm(nG{mWozGroqD{m;o
m(nFo$;m({m;o#;t_{ o|m({q(m(wKzF5q(prm(nFop{y?;m({m;om(nFo$;om(<p0;m({m;oq(pr:nGwKbn{Np{y?;m({m;o
wKAq(o{DnG{Oy*ow*m(n;m;otOpq#y*o(9{q(o prtOFm;o7|nFozpq;pr9o5m(nFo;om9wKzOyKGFo
{yKySwKzGw*m(wx{y@;m({m;o{$tOyx{znG{EoozCpOzG7|-GqbwKzF#m(nFoAoz	Gr9oqb{m(w*pz7Eo{bnh(m({m;o9wK:{b;pwx{m;o
w*m(n{zMptEoqb{m(w*pzm(nG{m#wK{y*pzF%{(nFpq(m;o;m#tO{m(nMm;p{p{y;m({m;o|:p'm(nFoNp{yK${zEo
q(o{DnFoCq(pr{z	Np3m(nFoAwKzGw*m(wK{y7(m({m;o-	5q(otEo{m;oGyKN{tGtOy*XwKzFm(nFoptEoqb{m;pq-{(;pXwK{m;ow*m(n
m(nFoFq(q(oz	m#;m({m;o|:#m(nFozGrWEoq9p;m({m;o s{ m(w*pztO{wKqb9wKzm(nFo;ot_yK{zG9wK#{#nOw*n{#m(nFo
zGr<Eoq-p4;m({m;o@tOq(pOy*orwKzG(m({zG o+w*m(nOwK(m({m;o;tO{ o pzO(Grorpq(o9r9orpq(m(nO{zwK
yKw*oyKm;pEo9{'v
{wKyx{Oy*o|9Ip{yKy*ovXwK{m;om(nGwx+tGq(pOyKor4wKr9{m;m(wom{y|9tGq(ptEp;om(nGoG;op4OwKzO{q(
FowKbw*pzGwx{qb{r9+?q({zffmUpq?ozG pOwKzF<m(nGo;m({m;o s{ m(wKpz5m({Oy*o|4--0{q(o-wKzozGoqb{y
zFpm{t_{Oy*o+pSq(otGq(o;oz	m(wKzFo ~XtEpzFoz	m(wK{y7(w*o<O{m({9;m;qbG m(Gq(o0wKz5tEpy*XzFpr9wK{y1;tO{ o|
Xrw*m(nW{zOWhoyxo ~m;ozG$A7GOffL4yKGr}GFqb;mGIm;pnO{zGGy*o?GzG oq(m({wKz	m
{zG;ovoqb{ywKzGwKm(wK{y;m({m;o|+nGo<tOyK{zOtGq(pXGG o	m(nFow*qt_yK{zGzFoq{q(o(o	FozO o:ppt1oqD{m;pqb
yKw*owxzNyK{((wx{y7tOyK{zGzOwKzFFOFm{:m(nFoo Eo m(pptEoqb{m;pqb:r9{Eo< pzGGwKm(w*pzG{yEpz(pro{ m(
m(nFotOyx{zG+r9{h{DnGw*ovo9m(nFop{yxovoz:nFozh;m({q(m(wKzG5m(nFotOyK{zLo ~XoFm(w*pzwxzhGw>Eoq(ozffm(m({m;o
pq<:nFozm(nFoqbo#wKzGpzGFom;oqbr9wxzGwK(r5|Xr9w*m(n{zOhoyK%{yKym(nGwx pzFpqbr9{z	m<tOyK{zOzGwKzFF|$nFow*q
tOyK{zOzGwKzF{y*pqbwKm(nGro ~XtOyKwKw*m(yK9q(otGq(o(ozffm(wKzFpqbr9{m(w*pzpz{yKy7o ~XoFm(w*pzGp{tOyK{z|UnGwx0r9{
EotEp((wKOy*onGoz9m(nFo-z	Or<Eoq?p@wKzGw*m(wx{yG;m({m;o0wK?(r9{yKyu	Ft$m;p{A pFt_y*op@Gpoz#pq0{n	OzGFq(o
pz(r9{yKyUtGq(p_y*orwxzG;m({zG o3_Fm<pq9rpq(o prtOy*o ~%tGq(pOy*orWw*mwKAzFpmCo{(wKOy*oEo{G(o$p
nGw*n5r9orpq( pzG(GrtOm(w*pz7|3otGqbo;ozffm(wxzF9 pzFpqbr9{z	mtOyK{zGzOwKzFAwKzpFqqb{ro?pq(5wK4o{;|
 Gq$?pq({zG({m(wK_{_wKyKw*mt_yK{zGzGwKzG	{Fm;h{zGoyxr9{zW{q(ohy*p;oy*
q(oyK{m;o|r9{/;pqGw>Eoq(ozG o+wK?m(nG{m0?o{zNGwKq(o m(y*{GGq(o(4{rWObn5wxFoqUqD{zFo+pIt_yK{zGzGwKzG
tGq(p_y*or9Aw*m(nzGpzGFom;oqbr9wxzGwK;m(wK$bnO{zFo{zG;ovoqb{ywxzGw*m(wK{y4;m({m;o|?o{G;op-m(nFo{GFo


fi*F/_G

    	


fiff  
       
	 
 
fiff 

 "! # $	   %! 	&

# fiff  
'  
+

*
 
 %! # ' ()!
  
 '  , 
  $	

fiff

 -
# 
 .  / 


0
	 1
 	  )!
2   	
3	 %4  5
' )!
 76  98 	;:
	


=< > 
,?@7A/B 	DCFEHGJIKEL
 	
M , # 
N 

	
 # # O<P  
  ( Q 
2


  



 
  (	 	

 	
 T
	


R
S $ )!
    /
  O U 
V	
fiff $ "

# W 
T
'	
X Q
OY  ' ;
	  fiff   2 O  #
Z ! 	 X $	
$ +
[	


\

/  
 / M
 ]  (	
U
 
 
  	  N

  fiff
  ^
  
 
 
  1 	
[ 
(_  >
'M
 

Fbx*:(FLG(O*
?  ;  GFK Fb-E*F%;(F 9O* F* x
K ; F  W G ((xff%(KKKG; 7 FA;b bK(*
ff(xG*h F ;;	(K
Gff( O ff 9(F ; G	( O U* b GK:(; G X (K :F9(F ( b GK
*(G F3(F G	( O ( (( _O*
F;b (K(K K(G ;  ; ;(Kx ff(x9(F(
OK (G( (ff((*
 G*(*GOK S F<(F  ;$(F$( G*(xF ; 
b GK
( bK9KK0 _K NE  G $ (( __KK**b*(O
O G	( G E( 0E ?(F (( __KK*<*b*(O 
 F  x9
 F(F( uO( 9 W(G(F b9

@S($O ; %K  ; D
F (N*b*(G Wb1; O*%;b; F ; F(  F5 b*G	 A(G (( %(F ;9
K (
?F<1xff (x (F(:< Gb	;:(OUK_ (*G9ff UG E  ( F( 7
 (F( ((F (9*b*(G bAG _O*A G;b9KGxF(F G (( __KK*$  ;
 K (
FD_E  (W*  ; bL*b*(O
F$F XG ;( *$(F( F(F
; D (O _(G OF F;D9KF :*( ((K	(G:   *(N ((KG(E(
F F F ;
*  ; D#Kb*(G  _ 9  G*(*GX_KA F* OF F;D9KF
*
b( (F
*(F F ( ;;( K*  ( FbKFK <OxG(* 0
	(KF K OGK
 G	;( FO* 4(G (F <_K#x ((  E  G
Fb (-0* ;4(F ;-Ob U
*bK(G
  G*(KGGOxGGKF+(O b (G4WOK (( 0G -;WE ( ;;(

`acb;de_f3g5h[ikjPdUe[iTlme[npo+h+qh_rsutvdHrw
\ Gb1(-Gx
 GG(D 5; G	 K(*GEOKOGKFW(G4O;	N(G(;	(KFO(O*
K(( I G
 ff("O! 	0?& *  bG K?	0bKFF ;9;	 (F(Su< G(>   U1! G	 KF
OK$  N G-GG(D -E(L(Fb( K*LL
	 Gb (( K*.? K3(
 ;	  2 GD ( 

(" (*T?
 X;-(F+( 	/x 4 ((9!_OKKK9*bK(Gzy 6 F 980{Z: K7}|~~4 K
 Kb FOKOGKF  N FGbO*  F
	 ;bKGKF+;F (O<P F 3  G ff("O! 	?& *  bG K


3-FDK"8 (* (F0GbO* b()!_OxK*<  Gb1b*(*G  DG
 x  2 +(Fb( 
Y;(%!- (KU " ; O*fiFff *(O*(G0F	 $;;b;9(GK+KLFbF  b*O*
;(X(()!__KK**b*(OK] O
	 *(*G1OKOGKF 
N O/?Q	G%4E#  bbx*V?N
 	G*(KGOxGGKF9x.;xbS((1  ' GK"
(F4OKOGKF*D*(G+ U 	4
 #(F	 by  [{X: 9*(7O|~~M  (+{? KKxO|~~D 
?/	F+F(	 1 	GK(*G	OKGGxF;-(F/(xO*;  _KGGKG/*(FGG$ ((K	(* 
2 +(F^ A	WF 3(F((( GG*O((OS(	 (*=? G 	 E0KK%< 9("
 ;	 *3;K" K
GFE	FF4K<E*XF9x(K  (,(F0!_	GxFOKS;(G(@(	$ (*
9k
 * ( ;(K  4 x9;(  y)|~~W " 5%Kb*(G(GJG 9b;A(FT;(;
;O ?   	G*(*OOKGOKF0G(_*  N FOK$U ;; ;		+(FKI*bK(GfiffXOKK(*
;O K;1D(*
 K(x (u;(;%
	 (G<xGF(	(*h*	W;_*NOK$ Q WF
*/:F(F(F&,R;DGG F0(FGb1(-k<(G  (*_*  V 9O*fiffG(O* 
\ O ;G	 x *Eh
	 G(;EK_*	((*L  (G(=u< G(^   R&
 L
	 fiffM<

N
EbK	;	c
 *(GbM	$ KF $G	 *(*G1Ox*(* G+(G*4(+O(KK9xG(ff-F 4" 
Y;(%!7 (*;9F
 GO(b }[(KOKED G9#
 G(OK?(G/? G 
	 E  ;	O	 %;xG *
 ;9  (F<bx* $G	 *(*G@OKGG#( G X *Q; 
	 K(KW(G-'#FOKKG

W

\
(FJO
 <E< KG*(K_;(;K%(F#O(O*K;(  EK*x #(GWfiXff G(#(KF
 G	 %<
(*GOxGGKF3-(F(=u< O(>X
 KF-(9A9k *(K3;F	 	(  +GbF;b OG F S(G

EFfiO
! (GV ;;#$ (*  O	 *(*GF_Kff$	 ;W;WG	 ff(  ;b GG F (G[ OFUE
 J G*	(*<E	F	 5
	 xO((xG x0(F(=u< Gb>X KF  bx? M 
^

fi,-$#3J$J3"$O-$%3-3$=^$$
33U
MOMJ M 3O
MOMJOO M 
MOMJO3 M 
MOMJJ M 

3JkM
3Jk3M
3Jk3O
3Jk$

3
3
3
3


 
  
  
  



M
M
M
M





33+
MOMJOO M  M  33M3 J 3O M 
MOMJ M 3O 3JkM 3    M 
MOMJ 3    M  M  3Jk O   3 M k33
33_
MOMJ3J M  3Jk
MOMJ M 3O 3JkM
MOMJJ M  3Jk$
MOMJ M  3Jk$
33[
MOMJ M 3O 3JkM
MOMJ M  3Jk$
MOMJ 3    M  M 
MOMJ 3    M  M 

3
3
3
3


 
  
  
  

3   
3   
3Jk O
3Jk O

M
M
M
M







M 
M 
  3 M  kJ
  3 M 
 k33

"3J_[k$"Tmx#k9//#W9k9
c^HM;J$OuM7>
 ('#9k##,0$3
JW33#3#J$39S$#k=3ZJ  =3
9=V(3,9S3;3z(T"#-k"]$T3z(;'x0T3x"fi
XUx99x#HU$""-$xk3mxV"x+"x}M$"V37R'"RM(P#33
_1-__	ff
5fi
}
OS-"/$$_JS3,3xSPx/k#'cm"^X;3'$#9+$$" V";3x
$"OO /Wz;9F  v   3"(/9k9]k'3
7#"$"
fiO$#k"1X3xX-"M#M  30$]fiO13X03fi#7](WMfi"3 M
D"$3=9k9x
 u#Fk9T
M0mx/mx#k9#=kck$"	 =3fi"m
"3=J  X Mx".30$Q9k#V k9 !-$Q3X1##3
kV" 3
 xc7([USR9#"9S=xfi#9/9k9X,3Rc3R$[U93O k3
/ fi$
 #&%!')(*F$k=k#c3fi73M+
 #,%!'-(.*+/ 01%!'-(.*324#5687!91(;:  3;9""$fi"
0   k-"< 3=
 )_ Mx303;$	 9#"X3ST9 >M3fi
!@?) )
 Ac9k9k03
 [9fi#$"(9fi 3$"OOx B ,'$0VX3,fiO3
Mfi"C
 3 M M  3=+9Q ;pD HD }  3S"(9k9k
EFHG

fiIJKMLHNOKQPRK

S1T&UWVQX8YS8YZRV

[\Q]V

^`_ba

c,d!e)fhg

^`_ba

ijc,d!e)fhg

kl_bk

c,d!e)mng

kl_po

ijc,d!e)mng

al_bk

c,d!e)mng

al_bk

ijc,d!e)mng

oh_bk

c,d!e)mng

oh_q^

ijc,d!e)mng

r U!sut]

oMvr T,UWVQX8YS8YZRVwyxQVQzS8YZRV

{}|M~R|M
))-WM- )~R 

M-!QW |M~W    )~R 

))-WM )~R 

M-!Q)W |M~W    )~R 

))-WM )~R 

M-!QRW |M~W    )~R 

))-W )~R 

M-!M)W |M~W    )~R 

))-WM )~R 

M-!MW |M~W    )~R 

))-W- )~R 

M-!MW |M~W    )~R 

))-WQ- )~R 

M-!uW |M~W    )~R 

))-WQ )~R 

M-!uRW |M~W    )~R 

))-WQR )~R 

M-!uWW |M~W    )~R 

))-W)M )~R 

M-!W |M~W    )~R 

))-W) )~R 

M-!)W |M~W    )~R 

))-W)Q )~R 

M-!MW |M~W    )~R 

{}|M~R|M
))-W )~R R )~R 

MWM)MR -~ WM )~R 

))-W |M~W    )~R  )~R 

M-! |~W   M )~R !M

))-W |M~W    )~R  )~R 

M-! |~W   M )~R !uR

{}|M~R|M
))-W |M~W    )~R  )~R 

 YRxMT8]l v

M-! |~W   M )~R !Q-

VQU!sut]3ZW]T&U!S1ZWT,XwZWT]UWz&\.X1S8U!S1]

UWttS8\M]ZRX8X8YsOt]lzZRVuRxQT&U!S8YZRVQXDZWwS8\Q]hwZRxMTsutZz8X

r

\Q]utUWV.\QUWXS8\QT8]]nX1S8U!S1]X

r

\M]]VuU!sut]

ZW]T&U!S1ZWT&XffZWw]UWz&\3X1S8U!S1];U!T8]U!QutY]nT8]]U!S1]QtnxQV-S8YtQVMZhnZWT8]DZW]T&U!S1ZWT&XU!T8]DU!uutYzU!sut]WUWVQ
S8\M]V3UhS1T&UWVQX8YS8YZRVS1ZS8\M];X8xuzz]X8X1ZWTjX1S8U!S1]l
U!T8]RYW]V.YV

 YRxMT8])j\M]V]YS8YVMX1S8U!S1]

^

YX<UWM]W r

\Q]`]VQU!sOt]ZW]T&U!S1ZWT,XwZWT]UWz&\X1S8U!S1]

^ OUWttsutZz8XU!T8]ZRV$S8\M]S8U!sut]WVX1S8U!S1]

k uOT&X1S

YX`nZW]ZRV.S1ZW.ZWwUWVQYX`nZHW]ZRV$S1ZWCZWwhOUWVQ.S8\M]VYX<ZW]wT&ZRZRV.S1ZW.ZWw
D  YVQUWtt

YV=X8S8U!S1]

a uYXjnZHW]ZRV=S1ZWZWwD

H

fiOu&M-u-MuOQuMOMuRHuu

CQQRuffu
;W
 811 R
 =
 Du 

 

WWR,RnO&8Q8ffW` 

  !#"$%&')(( *-,,+-W/.0+WW)

21 3

54 26 879: 1 3W8;




W  ! M 
 & 	


Q= l H



8R -



)

QM	ff
fi


u

=<!u!&M1 >4MWWR,@?ABC&DAEff
fi	#GFH 



CWJIK&M

n)Q&

L M6 ONuM&1P M6WQW,NQW1OCQCffSRM&RRuCuTW&!RluW)&UVAB WX&D
  !#"$%&')Y[Z BI\-R,,-]'.0^__

 a`"5bjW-R,)lR  )R<QuQ!8dcSRWGeM8DeuQ!&feQ8geQLI
 ,W<TUh8ijff
fi	 $"@?ABkHLl 8m/no^R,,-W^/.0^D])
W

CeMqp;WL*-,rpsRM$RnOM8!8QWR<uMWDQ8WR88uWjps`s;EtuCQM
UuAB WX&%o   !#"$%&' )vY BI\R- ,DW+ /.0-_M* 

e

XP

< /w  Ge T 'RQ!8 TPDW]R,x	+W#WW&SRu 1 %w!WQ!1zy)Q-8|{uDe

};~AE
D&BGG0"l
E 9a B' z
	ff
DDAS&'@
dUVAB WX&D
  !#"$%&' UVU	U ' Y@z z ff
DDAS&B
  C
k kUqo&Go
l
EUVA 
 WX&D   !#"$%&'@  U	U ' YHMu-+-/.0-+Q-

 MR   ! Q! u
 )R  W&hQ!W

ls`/wW&sPp &/wW&1MtDW]R,`Q1R<!8  7u7	IuW1DeWDM,!8 W
Q#W
w &8WuQ MIeM1&<u18eMRWQr;ExAE
/&'GG $"l
E z G  
o
ff
D%%AJ%&'
UuAB WX&%o   |"0&B UVU	U ' Y@ % ff
DDAS&'

 
kLkUT[!o&G
Cl}
EVUVA WX&%o  %#"$&'  UVU ' Y} QQC]!Q /.0]] !

!18

7DwP 6WC	<6/wWCe	7+-R,><W'RQMu8W&W
ff
fi}fi9Co&Go
lh
E U8iC8!^WL*L.0^WQ-

SR

W QW8

/w M

u8 

NM8		4MaWWR,  fi	AJ
k%fi% l
dAE
B
Ll'o
V?lWT[ !H?,SAE&%UV"[
AB  $fil
tX	
R h
7 QSMR 8C	u
 #Ww &8 WfftDCQ1#w!Q


<D8%wQal MGR)M8a6W]R,O;EM8&C18!1$Q81&W-8nWeQR<WIeMDCeMD-
OCQ
 CM ;EqAJ
D&''S $"l
J@ @a G% o
ff
D%%AJ%&'
OUVAB WX&D  % 
"0&B UVU	U ' Y f% Off
D%%AJ%&'
  C
kL khUqo&Go
l@
JUVAB WX&D
  !#"$%&'@  U	U ' YH MQuR_ /). D)- 
<D8DD+WR,zuu!8 WSRQW89IQ8Mw)$1u8Wu 8R#w)M;Ed WW57hb

`W81	
 
6 X
P Dbau
e  ,	qAJ
D&''S $"l
E (Ll  ABo
u
@ff
/%%AJ%&'


UuAB WX&%o  !#"$%&' MQ- /.0-W^  WSQ
R W 1
 7"DCW"WQ<	
"WMJ3WQ<	  	W-R,tffCQlWj8!8J{O!uW2;E`Q<	  bae ,CAE
/&'GG 
 $"l
E ([Z qAJ
'Sff
D%%AJ%&'
OUVAB WX&D  %#"$&'Qff^WW/.0^+^D	
DQ11,W
4 RC
  )u
 
"WMJ3W, )<  W+R,utQGRQnSRMhD$wWWOCQCMMQ8WR88uWR!Ce
81)'Q
R W18h1!&'R	q;~fqAJ
D&''S $"lh
E >[ AB' o
ff
DDAS&'
UVAB WX&D
  !#"$%&' }q#"$   C
kk9UT!o&Go
l
JUuAB WX&%o  %|"0&Bzff
D%%A 
%&' QQ	WL*LO
. D-M_ h.
P DQ
 
t !8  WWGu
 0VV;
t &8	}psMR P;Ep
t 8&
M

fi#MC

>	VTg#sV$CED'	DGJS%SDxCCCSS# SSE#\
S#DDEqJD''S $dEf d[ O'%'ffDDSBxVB XD
' !#$%'%CC8C/009	M,[2
%	DJJ%Dus# sSD[#J%V}ED/'  JJDSCCD@CErVD2
 % 	2h	aC%!'$E/'GG $	Es ff
 fi>ffDDS'VVB XD
 La#
' !#$%'%CC8C L0@	 DqG  z  SDS%


%%g#  #2}s>ED'TC#S#C,CDqC5~	DCC%D>	X2!'
E/'GG $Eh a'Bq'Bo	ffDDSB@fV X%o>' |0B|C0
  }'C82
 /D  J%,q#'CzS C  ! %G%


GD# TC%#"9ED'  C h[SCDC%#D$
) (BJVV XD' !#$%'+*B%GJ[-,D00

D%S&%JDgCCS'2

[SD80,ED')xCC#'#C CaJD#SDS#CJDG!82~TC20."}#
 ! 0,%S%$a/
 h#  C#S  V	 XC%!'' D10BE32)4#GD$5*s60J%f
*SL%C $8
 7qJDBGS$hJ   : 9 'Bosff/%%J%'<
 ;	2+*>= 
?@MC8/D0 
S

D

$

J





~

S



#









S






A











C














%

'

%




[SD8C0ED'EhCSCBDhD[SJVTBLS#D0C$S|DFEX0#D'C[E9E)G
BGG0Eu / H 'Bo8 ff/%%J%'uB X%o'%|0BzG
 C   %'%>J@C,DD
sSDCS!CD2  CED/'  J[DG$ #%q,%GSDSIBd~OVDDD  as	X2!'
E/'GG $E KJD d'Boq ffDDSBguB X%off' !#$%'%ffC8
'0>s	J%qG/ LxM
 C2


2}8s#$NLD2$}  ED')q'[O"uG2CEqJD''S $E	 P G 
fioVffDDSBuB X%o)'%#$'A; V	V'GQ
?@ KR% OffD%%J%'
') SLT SU
 080!oGC}EVV X%o'%#$'V
 ; JV	' GW
?@LCC8X
 /Y 0

ZC[\

fififififififififififififiFactorized First Order

Factorized Second Order
300

120
250
200

Frequency

Frequency

100
80

150

60
40

100

20

50

0
0

0.02

0.04

0.06
0.08
absolute error

0.1

0.12

0
0

0.14

0.02

Decimatable First Order

0.04

0.06
0.08
absolute error

0.1

0.12

0.14

0.12

0.14

Decimatable Second Order

150

500
400
Frequency

Frequency

100

300
200

50

100
0
0

0.02

0.04

0.06
0.08
absolute error

0.1

0.12

0.14

0
0

0.02

0.04

0.06
0.08
absolute error

0.1

fiFactorised Paired First and Second Order

Decimatable Paired First and Second Order

60

60
Frequency

80

Frequency

80

40

40

20

0
0

20

0.02

0.04
0.06
absolute error

0.08

0.1

0
0

0.02

0.04
0.06
absolute error

0.08

0.1

fiFactorized First Order estimates of first moments

Factorized Second Order estimates of first moments

150

350
300
250
Frequency

Frequency

100

200
150

50

100
50

0
0

0.02

0.04
0.06
absolute error

0.08

0
0

0.1

Factorized First Order estimates of correlations

0.02

0.04
0.06
absolute error

0.08

0.1

Factorized Second Order estimates of correlations
350

150
300
Frequency

Frequency

250
100

200
150

50

100
50

0
0

0.02

0.04

0.06
0.08
absolute error

0.1

0.12

0
0

0.02

0.04

0.06
0.08
absolute error

0.1

0.12

fifiLearning using second order estimates

Learning using standard MF estimates
2

total pattern likelihood

total pattern likelihood

2

1.5

1

0.5

0
0

10

20
time

30

40

1.5

1

0.5

0
0

50

100
time

150

200

fififififiJournal of Artificial Intelligence Research 10 (1999) 291-322

Submitted 10/98; published 5/99

Variational Probabilistic Inference
and the QMR-DT Network

Tommi S. Jaakkola

tommi@ai.mit.edu

Artificial Intelligence Laboratory,
Massachusetts Institute of Technology,
Cambridge, MA 02139 USA

Michael I. Jordan

Computer Science Division and Department of Statistics,
University of California,
Berkeley, CA 94720-1776 USA

jordan@cs.berkeley.edu

Abstract

We describe a variational approximation method for ecient inference in large-scale
probabilistic models. Variational methods are deterministic procedures that provide approximations to marginal and conditional probabilities of interest. They provide alternatives to approximate inference methods based on stochastic sampling or search. We describe
a variational approach to the problem of diagnostic inference in the \Quick Medical Reference" (QMR) network. The QMR network is a large-scale probabilistic graphical model
built on statistical and expert knowledge. Exact probabilistic inference is infeasible in this
model for all but a small set of cases. We evaluate our variational inference algorithm on a
large set of diagnostic test cases, comparing the algorithm to a state-of-the-art stochastic
sampling method.

1. Introduction
Probabilistic models have become increasingly prevalent in AI in recent years. Beyond
the significant representational advantages of probability theory, including guarantees of
consistency and a naturalness at combining diverse sources of knowledge (Pearl, 1988),
the discovery of general exact inference algorithms has been principally responsible for the
rapid growth in probabilistic AI (see, e.g., Lauritzen & Spiegelhalter, 1988; Pearl, 1988;
Shenoy, 1992). These exact inference methods greatly expand the range of models that can
be treated within the probabilistic framework and provide a unifying perspective on the
general problem of probabilistic computation in graphical models.
Probability theory can be viewed as a combinatorial calculus that instructs us in how
to merge the probabilities of sets of events into probabilities of composites. The key operation is that of marginalization, which involves summing (or integrating) over the values
of variables. Exact inference algorithms essentially find ways to perform as few sums as
possible during marginalization operations. In terms of the graphical representation of
probability distributions|in which random variables correspond to nodes and conditional
independencies are expressed as missing edges between nodes|exact inference algorithms
define a notion of \locality" (for example as cliques in an appropriately defined graph), and
attempt to restrict summation operators to locally defined sets of nodes.
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiJaakkola & Jordan

While this approach manages to stave off the exponential explosion of exact probabilistic
computation, such an exponential explosion is inevitable for any calculus that explicitly
performs summations over sets of nodes. That is, there are models of interest in which
\local" is overly large (see Jordan, et al., in press). From this point of view, it is perhaps
not surprising that exact inference is NP-hard (Cooper, 1990).
In this paper we discuss the inference problem for a particular large-scale graphical
model, the Quick Medical Reference (QMR) model.1 The QMR model consists of a combination of statistical and expert knowledge for approximately 600 significant diseases and
approximately 4000 findings. In the probabilistic formulation of the model (the QMR-DT),
the diseases and the findings are arranged in a bi-partite graph, and the diagnosis problem
is to infer a probability distribution for the diseases given a subset of findings. Given that
each finding is generally relevant to a wide variety of diseases, the graph underlying the
QMR-DT is dense, reecting high-order stochastic dependencies. The computational complexity of treating these dependencies exactly can be characterized in terms of the size of
the maximal clique of the \moralized" graph (see, e.g., Dechter, 1998; Lauritzen & Spiegelhalter, 1988). In particular, the running time is exponential in this measure of size. For the
QMR-DT, considering the standardized \clinocopathologic conference" (CPC) cases that
we discuss below, we find that the median size of the maximal clique of the moralized graph
is 151.5 nodes. This rules out the use of general exact algorithms for the QMR-DT.
The general algorithms do not take advantage of the particular parametric form of the
probability distributions at the nodes of the graph, and it is conceivable that additional
factorizations might be found that take advantage of the particular choice made by the
QMR-DT. Such a factorization was in fact found by Heckerman (1989); his \Quickscore
algorithm" provides an exact inference algorithm that is tailored to the QMR-DT. Unfortunately, however, the run time of the algorithm is still exponential in the number of positive
findings. For the CPC cases, we estimate that the algorithm would require an average of
50 years to solve the inference problem on current computers.
Faced with the apparent infeasibility of exact inference for large-scale models such as
the QMR-DT, many researchers have investigated approximation methods. One general
approach to developing approximate algorithms is to perform exact inference, but to do so
partially. One can consider partial sets of node instantiations, partial sets of hypotheses,
and partial sets of nodes. This point of view has led to the development of algorithms for
approximate inference based on heuristic search. Another approach to developing approximation algorithms is to exploit averaging phenomena in dense graphs. In particular, laws
of large numbers tell us that sums of random variables can behave simply, converging to
predictable numerical results. Thus, there may be no need to perform sums explicitly, either
exactly or partially. This point of view leads to the variational approach to approximate
inference. Finally, yet another approach to approximate inference is based on stochastic
sampling. One can sample from simplified distributions and in so doing obtain information
about a more complex distribution of interest. We discuss each of these methods in turn.
Horvitz, Suermondt and Cooper (1991) have developed a partial evaluation algorithm
known as \bounded conditioning" that works by considering partial sets of node instan1. The acronym \QMR-DT" that we use in this paper refers to the \decision-theoretic" reformulation of
the QMR by Shwe, et al. (1991). Shwe, et al. replaced the heuristic representation employed in the
original QMR model (Miller, Fasarie, & Myers, 1986) by a probabilistic representation.

292

fiVariational Probabilistic Inference and QMR-DT

tiations. The algorithm is based on the notion of a \cutset"; a subset of nodes whose
removal renders the remaining graph singly-connected. Ecient exact algorithms exist for
singly-connected graphs (Pearl, 1988). Summing over all instantiations of the cutset, one
can calculate posterior probabilities for general graphs using the ecient algorithm as a
subroutine. Unfortunately, however, there are exponentially many such cutset instantiations. The bounded conditioning algorithm aims at forestalling this exponential growth by
considering partial sets of instantiations. Although this algorithm has promise for graphs
that are \nearly singly-connected," it seems unlikely to provide a solution for dense graphs
such as the QMR-DT. In particular, the median cutset size for the QMR-DT across the
CPC cases is 106.5, yielding an unmanageably large number of 2106:5 cutset instantiations.
Another approach to approximate inference is provided by \search-based" methods,
which consider node instantiations across the entire graph (Cooper, 1985; Henrion, 1991;
Peng & Reggia, 1987). The general hope in these methods is that a relatively small fraction
of the (exponentially many) node instantiations contains a majority of the probability mass,
and that by exploring the high probability instantiations (and bounding the unexplored
probability mass) one can obtain reasonable bounds on posterior probabilities. The QMRDT search space is huge, containing approximately 2600 disease hypotheses. If, however,
one only considers cases with a small number of diseases, and if the hypotheses involving
a small number of diseases contain most of the high probability posteriors, then it may
be possible to search a significant fraction of the relevant portions of the hypothesis space.
Henrion (1991) was in fact able to run a search-based algorithm on the QMR-DT inference
problem, for a set of cases characterized by a small number of diseases. These were cases,
however, for which the exact Quickscore algorithm is ecient. The more general corpus of
CPC cases that we discuss in the current paper is not characterized by a small number of
diseases per case. In general, even if we impose the assumption that patients have a limited
number N of diseases, we cannot assume a priori that the model will show a sharp cutoff
in posterior probability after disease N . Finally, in high-dimensional search problems it is
often necessary to allow paths that are not limited to the target hypothesis subspace; in
particular, one would like to be able to arrive at a hypothesis containing few diseases by
pruning hypotheses containing additional diseases (Peng & Reggia, 1987). Imposing such a
limitation can lead to failure of the search.
More recent partial evaluation methods include the \localized partial evaluation" method
of Draper and Hanks (1994), the \incremental SPI" algorithm of D'Ambrosio (1993), the
\probabilistic partial evaluation" method of Poole (1997), and the \mini-buckets" algorithm
of Dechter (1997). The former algorithm considers partial sets of nodes, and the latter three
consider partial evaluations of the sums that emerge during an exact inference run. These
are all promising methods, but like the other partial evaluation methods it is yet not clear if
they restrict the exponential growth in complexity in ways that yield realistic accuracy/time
tradeoffs in large-scale models such as the QMR-DT.2
Variational methods provide an alternative approach to approximate inference. They
are similar in spirit to partial evaluation methods (in particular the incremental SPI and
mini-buckets algorithms), in that they aim to avoid performing sums over exponentially
2. D'Ambrosio (1994) reports \mixed" results using incremental SPI on the QMR-DT, for a somewhat
more dicult set of cases than Heckerman (1989) and Henrion (1991), but still with a restricted number
of positive findings.

293

fiJaakkola & Jordan

many summands, but they come at the problem from a different point of view. From the
variational point of view, a sum can be avoided if it contains a sucient number of terms
such that a law of large numbers can be invoked. A variational approach to inference
replaces quantities that can be expected to be the beneficiary of such an averaging process
with surrogates known as \variational parameters." The inference algorithm manipulates
these parameters directly in order to find a good approximation to a marginal probability of
interest. The QMR-DT model turns out to be a particularly appealing architecture for the
development of variational methods. As we will show, variational methods have a simple
graphical interpretation in the case of the QMR-DT.
A final class of methods for performing approximate inference are the stochastic sampling methods. Stochastic sampling is a large family, including techniques such as rejection
sampling, importance sampling, and Markov chain Monte Carlo methods (MacKay, 1998).
Many of these methods have been applied to the problem of approximate probabilistic inference for graphical models and analytic results are available (Dagum & Horvitz, 1993).
In particular, Shwe and Cooper (1991) proposed a stochastic sampling method known as
\likelihood-weighted sampling" for the QMR-DT model. Their results are the most promising results to date for inference for the QMR-DT|they were able to produce reasonably
accurate approximations in reasonable time for two of the dicult CPC cases. We consider
the Shwe and Cooper algorithm later in this paper; in particular we compare the algorithm
empirically to our variational algorithm across the entire corpus of CPC cases.
Although it is important to compare approximation methods, it should be emphasized
at the outset that we do not think that the goal should be to identify a single champion
approximate inference technique. Rather, different methods exploit different structural
features of large-scale probability models, and we expect that optimal solutions will involve
a combination of methods. We return to this point in the discussion section, where we
consider various promising hybrids of approximate and exact inference algorithms.
The general problem of approximate inference is NP-hard (Dagum & Luby, 1993) and
this provides additional reason to doubt the existence of a single champion approximate
inference technique. We think it important to stress, however, that this hardness result,
together with Cooper's (1990) hardness result for exact inference cited above, should not
be taken to suggest that exact inference and approximate inference are \equally hard." To
take an example from a related field, there exist large domains of solid and uid mechanics
in which exact solutions are infeasible but in which approximate techniques (finite element
methods) work well. Similarly, in statistical physics, very few models are exactly solvable,
but there exist approximate methods (mean field methods, renormalization group methods)
that work well in many cases. We feel that the goal of research in probabilistic inference
should similarly be that of identifying effective approximate techniques that work well in
large classes of problems.

2. The QMR-DT Network
The QMR-DT network (Shwe et al., 1991) is a two-level or bi-partite graphical model (see
Figure 1). The top level of the graph contains nodes for the diseases , and the bottom level
contains nodes for the findings .
294

fiVariational Probabilistic Inference and QMR-DT

There are a number of conditional independence assumptions reected in the bi-partite
graphical structure. In particular, the diseases are assumed to be marginally independent.
(I.e., they are independent in the absence of findings. Note that diseases are not assumed
to be mutually exclusive; a patient can have multiple diseases). Also, given the states
of the disease nodes, the findings are assumed to be conditionally independent. (For a
discussion regarding the medical validity and the diagnostic consequences of these and
other assumptions embedded into the QMR-DT belief network, see Shwe et al., 1991).
diseases

d1

f1

dn

fm
findings

Figure 1: The QMR belief network is a two-level graph where the dependencies between
the diseases and their associated findings have been modeled via noisy-OR gates.
To state more precisely the probability model implied by the QMR-DT model, we write
the joint probability of diseases and findings as:

P (f; d) = P (f jd)P (d) =

"

Y

i

3
#2
Y
P (fi jd) 4 P (dj )5

j

(1)

where d and f are binary (1/0) vectors referring to presence/absence states of the diseases
and the positive/negative states or outcomes of the findings, respectively. The conditional
probabilities P (fi jd) are represented by the \noisy-OR model" (Pearl, 1988):
Y
P (fi = 0jd) = P (fi = 0jL) P (fi = 0jdj )
(2)
= (1 , qi0 )



Y

j 2i

(1 , qij )dj

j 2
P i
,
i0 , j2i ij dj
e
;

(3)

(4)
where i is the set of diseases that are parents of the finding fi in the QMR graph, qij =
P (fi = 1jdj = 1) is the probability that the disease j , if present, could alone cause the
finding to have a positive outcome, and qi0 = P (fi = 1jL) is the \leak" probability, i.e.,
the probability that the finding is caused by means other than the diseases included in
the QMR model. In the final line, we reparameterize the noisy-OR probability model
using an exponentiated notation. In this notation, the model parameters are given by
ij = , log(1 , qij ).
295

fiJaakkola & Jordan

3. Inference
Carrying out diagnostic inference in the QMR model involves computing the posterior
marginal probabilities of the diseases given a set of observed positive (fi = 1) and negative
(fi0 = 0) findings. Note that the set of observed findings is considerably smaller than the set
of possible findings; note moreover (from the bi-partite structure of the QMR-DT graph)
that unobserved findings have no effect on the posterior probabilities for the diseases. For
brevity we adopt a notation in which fi+ corresponds to the event fi = 1, and fi, refers
to fi = 0 (positive and negative findings respectively). Thus the posterior probabilities of
interest are P (dj jf + ; f , ), where f + and f , are the vectors of positive and negative findings.
The negative findings f , are benign with respect to the inference problem|they can be
incorporated into the posterior probability in linear time in the number of associated diseases
and in the number of negative findings. As we discuss below, this can be seen from the
fact that the probability of a negative finding in Eq. (4) is the exponential of an expression
that is linear in the dj . The positive findings, on the other hand, are more problematic. In
the worst case the exact calculation of posterior probabilities is exponentially costly in the
number of positive findings (Heckerman, 1989; D'Ambrosio, 1994). Moreover, in practical
diagnostic situations the number of positive findings often exceeds the feasible limit for
exact calculations.
Let us consider the inference calculations in more detail. To find the posterior probability
P (djf + ; f ,), we first absorb the evidence from negative findings, i.e., we compute P (djf ,).
This is just P (f , jd)P (d) with normalization. Since both P (f , jd) and P (d) factorize over
the diseases (see Eq. (1) and Eq. (2) above), the posterior P (djf , ) must factorize as well.
The normalization of P (f , jd)P (d) therefore reduces to independent normalizations over
each disease and can be carried out in time linear in the number of diseases (or negative
findings). In the remainder of the paper, we concentrate solely on the positive findings as
they pose the real computational challenge. Unless otherwise stated, we assume that the
prior distribution over the diseases already contains the evidence from the negative findings.
In other words, we presume that the updates P (dj ) P (dj jf , ) have already been made.
We now turn to the question of computing P (dj jf + ), the posterior marginal probability
based on the positive findings. Formally, obtaining such a posterior involves marginalizing
P (f + jd)P (d) across the remaining diseases:

P (dj jf + ) /

X

dndj

P (f + jd)P (d)

(5)

where the summation is over all the possible configurations of the disease variables other
than dj (we use the shorthand summation index d n dj for this). In the QMR model
P (f + jd)P (d) has the form:

P (f + jd)P (d) =
=

"
"

Y

i

3
#2
Y
P (fi+ jd) 4 P (dj )5

j

3
2
# Y
1 , e ,i0 , j ij dj 4 P (dj )5

Y

i

(6)

P

j

296

(7)

fiVariational Probabilistic Inference and QMR-DT

which follows from Eq. (4) and the fact that P (fi+ jd) = 1 , P (f , jd). To perform the
summation in Eq. (5) over the diseases, we would have to multiply out the terms 1 , efg
corresponding to the conditional probabilities for each positive finding. The number of
such terms is exponential in the number of positive findings. While algorithms exist that
attempt to find and exploit factorizations in this expression, based on the particular pattern
of observed evidence (cf. Heckerman, 1989; D'Ambrosio, 1994), these algorithms are limited
to roughly 20 positive findings on current computers. It seems unlikely that there is sucient
latent factorization in the QMR-DT model to be able to handle the full CPC corpus, which
has a median number of 36 positive findings per case and a maximum number of 61 positive
findings.

4. Variational Methods
Exact inference algorithms perform many millions of arithmetic operations when applied to
complex graphical models such as the QMR-DT. While this proliferation of terms expresses
the symbolic structure of the model, it does not necessarily express the numeric structure
of the model. In particular, many of the sums in the QMR-DT inference problem are sums
over large numbers of random variables. Laws of large numbers suggest that these sums
may yield predictable numerical results over the ensemble of their summands, and this fact
might enable us to avoid performing the sums explicitly.
To exploit the possibility of numerical regularity in dense graphical models we develop
a variational approach to approximate probabilistic inference. Variational methods are a
general class of approximation techniques with wide application throughout applied mathematics. Variational methods are particularly useful when applied to highly-coupled systems. By introducing additional parameters, known as \variational parameters"|which
essentially serve as low-dimensional surrogates for the high-dimensional couplings of the
system|these methods achieve a decoupling of the system. The mathematical machinery
of the variational approach provides algorithms for finding values of the variational parameters such that the decoupled system is a good approximation to the original coupled
system.
In the case of probabilistic graphical models variational methods allow us to simplify a
complicated joint distribution such as the one in Eq. (7). This is achieved via parameterized transformations of the individual node probabilities. As we will see later, these node
transformations can be interpreted graphically as delinking the nodes from the graph.
How do we find appropriate transformations? The variational methods that we consider
here come from convex analysis (see Appendix 6). Let us begin by considering methods for
obtaining upper bounds on probabilities. A well-known fact from convex analysis is that
any concave function can be represented as the solution to a minimization problem:

f (x) = min
f  T x , f  ( ) g


(8)

where f  ( ) is the conjugate function of f (x). The function f  ( ) is itself obtained as the
solution to a minimization problem:
T
f  ( ) = min
x f  x , f (x) g:

297

(9)

fiJaakkola & Jordan

The formal identity of this pair of minimization problems expresses the \duality" of f and
its conjugate f  .
The representation of f in Eq. (8) is known as a variational transformation. The parameter  is known as a variational parameter. If we relax the minimization and fix the the
variational parameter to an arbitrary value, we obtain an upper bound:

f (x)  T x , f  ( ):

(10)

The bound is better for some values of the variational parameter than for others, and for a
particular value of  the bound is exact.
We also want to obtain lower bounds on conditional probabilities. A straightforward
way to obtain lower bounds is to again appeal to conjugate duality and to express functions in terms of a maximization principle. This representation, however, applies to convex
functions|in the current paper we require lower bounds for concave functions. Our concave functions, however, have a special form that allows us to exploit conjugatePduality in a
different way. In particular, we require bounds for functions of the form f (a + j zj ), where
f is a concave function, where zj for i 2 f1; 2; : : :; ng are non-negative variables, and where
a is a constant. The variables zj in this expression are effectively coupled|the impact of
changing one variable is contingent on the settings of the remaining variables. We can use
Jensen's inequality, however, to obtain a lower bound in which the variables are decoupled.3
In particular:

f( a +

X

j

qj zqj )
j
j
X

qj f ( a + zqj )
j
j

zj ) = f ( a +

X

(11)
(12)

where the qj can be viewed as defining a probability distribution over the variables zj . The
variational parameter in this case is theP probability distribution q . The optimal setting
of this parameter is given by qj = zj = k zk . This is easily verified by substitution into
Eq. (12), and demonstrates that the lower bound is tight.

4.1 Variational Upper and Lower Bounds for Noisy-OR

Let us now return to the problem of computing the posterior probabilities in the QMR
model. Recall that it is the conditional probabilities corresponding to the positive findings
that need to be simplified. To this end, we write
P

P (fi+ jd) = 1 , e ,i0 ,

j ij dj

= e log(1,e,x )

(13)

P

where x = i0 + j ij dj . Consider the exponent f (x) = log(1 , e,x ). For noisy-OR, as
well as for many other conditional models involving compact representations (e.g., logistic
regression), the exponent f (x) is a concave function of x. Based on the discussion in the
P

P

3. Jensen's inequality, which states that f (a + j qj xj )  j qj f (a + xj ), for concave
f , where
P
and 0  qj  1, is a simple consequence of Eq. (8), where x is taken to be a + j qj xj .

298

P

qj

= 1,

fiVariational Probabilistic Inference and QMR-DT

previous section, we know that there must exist a variational upper bound for this function
that is linear in x:

f (x)  x , f  ()

(14)

Using Eq. (9) to evaluate the conjugate function f  ( ) for noisy-OR, we obtain:

f  () = , log  + ( + 1) log( + 1)

(15)

The desired
bound is obtained by substituting into Eq. (13) (and recalling the definition
x = i0 + Pj ij dj ):

P (fi+ jd)

=




P

e f (i0 + Pj ij dj )

e i (i0+ j ij dj ),f (i)
P (fi+ jd; i):

(16)
(17)
(18)

Note that the \variational evidence" P (fi+ jd; i) is the exponential of a term that is linear
in the disease vector d. Just as with the negative findings, this implies that the variational
evidence can be incorporated into the posterior in time linear in the number of diseases
associated with the finding.
There is also a graphical way to understand the effect of the transformation. We rewrite
the variational evidence as follows:
P



P (fi+jd; i) = e i(i0 + j ij dj ),f (i)
id
Yh
= e i i0 ,f  (i) e iij j :
j

(19)
(20)

Note that the first term is a constant, and note moreover that the product is factorized
across the diseases. Each of the latter factors can be multiplied with the pre-existing
prior on the corresponding disease (possibly itself modulated by factors from the negative
evidence). The constant term can be viewed as associated with a delinked finding node fi .
Indeed, the effect of the variational transformation is to delink the finding node fi from the
graph, altering the priors of the disease nodes that are connected to that finding node. This
graphical perspective will be important for the presentation of our variational algorithm|
we will be able to view variational transformations as simplifying the graph until a point
at which exact methods can be run.
We now turn
to the lower bounds on the conditional probabilities P (fi+ jd). The expoP
nent f (i0 + j ij dj ) in the exponential representation is of the form to which we applied
Jensen's inequality in the previous section. Indeed, since f is concave we need only identify
the non-negative variables zj , which in this case are ij dj , and the constant a, which is now
i0. Applying the bound in Eq. (12) we have:

P (fi+ jd)

=

P

e f ( i0 + j ij dj )

 e

ij dj 
j qjji f io + qjji

P



299

(21)
(22)

fiJaakkola & Jordan

= e
= e

h

P





ij
j qjji dj f io + qjji +(1,dj ) f ( io )

i

i
ij 
j qjji dj f io + qjji ,f ( io ) +f ( io )

P

h 

(23)

(24)

(25)
where we have allowed a different variational distribution qji for each finding. Note that
once again the bound is linear in the exponent. As in the case of the upper bound, this
implies that the variational evidence can be incorporated into the posterior distribution in
time linear in the number of diseases. Moreover, we can once again view the variational
transformation in terms of delinking the finding node fi from the graph.

P (fi+ jd; qji)

4.2 Approximate Inference for QMR

In the previous section we described how variational transformations are derived for individual findings in the QMR model; we now discuss how to utilize these transformations in
the context of an overall inference algorithm.
Conceptually the overall approach is straightforward. Each transformation involves
replacing an exact conditional probability of a finding with a lower bound and an upper
bound:
P (fi+ jd; qji)  P (fi+ jd)  P (fi+ jd; i):
(26)
Given that such transformations can be viewed as delinking the ith finding node from
the graph, we see that the transformations not only yield bounds, but also yield a simplified graphical structure. We can imagine introducing transformations sequentially until
the graph is sparse enough that exact methods become feasible. At that point we stop
introducing transformations and run an exact algorithm.
There is a problem with this approach, however. We need to decide at each step which
node to transform, and this requires an assessment of the effect on overall accuracy of
transforming the node. We might imagine calculating the change in a probability of interest
both before and after a given transformation, and choosing to transform that node that
yields the least change to our target probability. Unfortunately we are unable to calculate
probabilities in the original untransformed graph, and thus we are unable to assess the effect
of transforming any one node. We are unable to get the algorithm started.
Suppose instead that we work backwards. That is, we introduce transformations for
all of the findings, reducing the graph to an entirely decoupled set of nodes. We optimize
the variational parameters for this fully transformed graph (more on optimization of the
variational parameters below). For this graph inference is trivial. Moreover, it is also easy
to calculate the effect of reinstating a single exact conditional at one node: we choose to
reinstate that node which yields the most change.
Consider in particular the case of the upper bounds (lower bounds are analogous). Each
transformation introduces an upper bound on a conditional probability P (fi+ jd). Thus the
likelihood of observing the (positive) findings P (f + ) is also upper bounded by its variational
counterpart P (f + j ):
X
X
P (f + ) = P (f + jd)P (d)  P (f + jd;  )P (d)  P (f + j )
(27)
d

d

300

fiVariational Probabilistic Inference and QMR-DT

We can assess the accuracy of each variational transformation after introducing and optimizing the variational transformations for all the positive findings. Separately for each
positive finding we replace the variationally transformed conditional probability P (fi+ jd; i)
with the corresponding exact conditional P (fi+ jd) and compute the difference between the
resulting bounds on the likelihood of the observations:

i = P (f + j ) , P (f + j n i )

(28)

where P (f + j n i ) is computed without transforming the ith positive finding. The larger
the difference i is, the worse the ith variational transformation is. We should therefore
introduce the transformations in the ascending order of i s. Put another way, we should
treat exactly (not transform) those conditional probabilities whose i measure is large.
In practice, an intelligent method for ordering the transformations is critical. Figure 2
compares the calculation of likelihoods based on the i measure as opposed to a method
that chooses the ordering of transformations at random. The plot corresponds to a representative diagnostic case, and shows the upper bounds on the log-likelihoods of the observed
findings as a function of the number of conditional probabilities that were left intact (i.e.
not transformed). Note that the upper bound must improve (decrease) with fewer transformations. The results are striking|the choice of ordering has a large effect on accuracy
(note that the plot is on a log-scale).
30

loglikelihood

35
40
45
50
55
60
0

2

4
6
8
10
# of exactly treated findings

12

Figure 2: The upper bound on the log-likelihood for the delta method of removing transformations (solid line) and a method that bases the choice on a random ordering
(dashed line).
Note also that the curve for the proposed ranking is convex; thus the bound improves
less the fewer transformations there are left. This is because we first remove the worst
transformations, replacing them with the exact conditionals. The remaining transformations are better as indicated by the delta measure and thus the bound improves less with
further replacements.
We make no claims for optimality of the delta method; it is simply a useful heuristic
that allows us to choose an ordering for variational transformations in a computationally
ecient way. Note also that our implementation of the method optimizes the variational
parameters only once at the outset and chooses the ordering of further transformations
based on these fixed parameters. These parameters are suboptimal for graphs in which
301

fiJaakkola & Jordan

substantial numbers of nodes have been reinstated, but we have found in practice that this
simplified algorithm still produces reasonable orderings.
Once we have decided which nodes to reinstate, the approximate inference algorithm
can be run. We introduce transformations at those nodes that were left transformed by the
ordering algorithm. The product of all of the exact conditional probabilities in the graph
with the transformed conditional probabilities yields an upper or lower bound on the overall
joint probability associated with the graph (the product of bounds is a bound). Sums of
bounds are still bounds, and thus the likelihood (the marginal probability of the findings)
is bounded by summing across the bounds on the joint probability. In particular, an upper
bound on the likelihood is obtained via:
X
X
P (f + ) = P (f + jd)P (d)  P (f + jd;  )P (d)  P (f + j )
(29)
d

d

d

d

dndj

dndj

and the corresponding lower bound on the likelihood is obtained similarly:
X
X
P (f + ) = P (f +jd)P (d)  P (f + jd; q )P (d)  P (f + jq )

(30)

In both cases we assume that the graph has been suciently simplified by the variational
transformations so that the sums can be performed eciently.
The expressions in Eq. (29) and Eq. (30) yield upper and lower bounds for arbitrary
values of the variational parameters  and q . We wish to obtain the tightest possible bounds,
thus we optimize these expressions with respect to  and q . We minimize with respect to
 and maximize with respect to q. Appendix 6 discusses these optimization problems in
detail. It turns out that the upper bound is convex in the  and thus the adjustment of the
variational parameters for the upper bound reduces to a convex optimization problem that
can be carried out eciently and reliably (there are no local minima). For the lower bound
it turns out that the maximization can be carried out via the EM algorithm.
Finally, although bounds on the likelihood are useful, our ultimate goal is to approximate
the marginal posterior probabilities P (dj jf + ). There are two basic approaches to utilizing
the variational bounds in Eq. (29) and Eq. (30) for this purpose. The first method, which will
be our emphasis in the current paper, involves using the transformed probability model (the
model based either on upper or lower bounds) as a computationally ecient surrogate for the
original probability model. That is, we tune the variational parameters of the transformed
model by requiring that the model give the tightest possible bound on the likelihood. We
then use the tuned transformed model as an inference engine to provide approximations to
other probabilities of interest, in particular the marginal posterior probabilities P (dj jf + ).
The approximations found in this manner are not bounds, but are computationally ecient
approximations. We provide empirical data in the following section that show that this
approach indeed yields good approximations to the marginal posteriors for the QMR-DT
network.
A more ambitious goal is to obtain interval bounds for the marginal posterior probabilities themselves. To this end, let P (f + ; dj j ) denote the combined event that the QMR-DT
model generates the observed findings f + and that the j th disease takes the value dj . These
bounds follow directly from:
X
X
P (f + ; dj ) = P (f + jd)P (d)  P (f + jd;  )P (d)  P (f + ; dj j)
(31)
302

fiVariational Probabilistic Inference and QMR-DT

where P (f + jd;  ) is a product of upper-bound transformed conditional probabilities and
exact (untransformed) conditionals. Analogously we can compute a lower bound P (f + ; dj jq )
by applying the lower bound transformations:

P (f + ; dj ) =

X

dndj

P (f +jd)P (d) 

X

dndj

P (f + jd; q )P (d)  P (f + ; dj jq )

(32)

Combining these bounds we can obtain interval bounds on the posterior marginal probabilities for the diseases (cf. Draper & Hanks 1994):

P (f +; dj j)
P (f + ; dj jq)
+) 

P
(
d
j
f
j
P (f +; dj j) + P (f + ; dj jq )
P (f + ; dj j ) + P (f + ; dj jq) ;
where dj is the binary complement of dj .

(33)

5. Experimental Evaluation

The diagnostic cases that we used in evaluating the performance of the variational techniques were cases abstracted from clinocopathologic conference (\CPC") cases. These cases
generally involve multiple diseases and are considered to be clinically dicult cases. They
are the cases in which Middleton et al. (1990) did not find their importance sampling method
to work satisfactorily.
Our evaluation of the variational methodology consists of three parts. In the first part
we exploit the fact that for a subset of the CPC cases (4 of the 48 cases) there are a
suciently small number of positive findings that we can calculate exact values of the
posterior marginals using the Quickscore algorithm. That is, for these four cases we were
able to obtain a \gold standard" for comparison. We provide an assessment of the accuracy
and eciency of variational methods on those four CPC cases. We present variational
upper and lower bounds on the likelihood as well as scatterplots that compare variational
approximations of the posterior marginals to the exact values. We also present comparisons
with the likelihood-weighted sampler of Shwe and Cooper (1991).
In the second section we present results for the remaining, intractable CPC cases. We
use lengthy runs of the Shwe and Cooper sampling algorithm to provide a surrogate for the
gold standard in these cases.
Finally, in the third section we consider the problem of obtaining interval bounds on
the posterior marginals.

5.1 Comparison to Exact Marginals

Four of the CPC cases have 20 or fewer positive findings (see Table 1), and for these cases
it is possible to calculate the exact values of the likelihood and the posterior marginals
in a reasonable amount of time. We used Heckerman's \Quickscore" algorithm (Heckerman 1989)|an algorithm tailored to the QMR-DT architecture|to perform these exact
calculations.
Figure 3 shows the log-likelihood for the four tractable CPC cases. The figure also shows
the variational lower and upper bounds. We calculated the variational bounds twice, with
differing numbers of positive findings treated exactly in the two cases (\treated exactly"
303

fiJaakkola & Jordan

case # of pos. findings # of neg. findings
1
20
14
2
10
21
3
19
19
4
19
33

20

20

30

30

40

loglikelihood

loglikelihood

Table 1: Description of the cases for which we evaluated the exact posterior marginals.

50

40

50

60
60
70
70

(a)

0

1

2
3
sorted cases

4

(b)

5

0

1

2
3
sorted cases

4

5

Figure 3: Exact values and variational upper and lower bounds on the log-likelihood
log P (f + j ) for the four tractable CPC cases. In (a) 8 positive findings were
treated exactly, and in (b) 12 positive findings were treated exactly.
simply means that the finding is not transformed variationally). In panel (a) there were 8
positive findings treated exactly, and in (b) 12 positive findings were treated exactly. As
expected, the bounds were tighter when more positive findings were treated exactly.4
The average running time across the four tractable CPC cases was 26.9 seconds for
the exact method, 0.11 seconds for the variational method with 8 positive findings treated
exactly, and 0.85 seconds for the variational method with 12 positive findings treated exactly.
(These results were obtained on a 433 MHz DEC Alpha computer).
Although the likelihood is an important quantity to approximate (particularly in applications in which parameters need to be estimated), of more interest in the QMR-DT setting
are the posterior marginal probabilities for the individual diseases. As we discussed in the
previous section, the simplest approach to obtaining variational estimates of these quantities is to define an approximate variational distribution based either on the distribution
P (f + j ), which upper-bounds the likelihood, or the distribution P (f + jq ), which lowerbounds the likelihood. For fixed values of the variational parameters (chosen to provide
a tight bound to the likelihood), both distributions provide partially factorized approximations to the joint probability distribution. These factorized forms can be exploited as
4. Given that a significant fraction of the positive findings are being treated exactly in these simulations, one
may wonder what if any additional accuracy is due to the variational transformations. We address this
concern later in this section and demonstrate that the variational transformations are in fact responsible
for a significant portion of the accuracy in these cases.

304

fiVariational Probabilistic Inference and QMR-DT

1

1

0.8

0.8
variational estimates

variational estimates

ecient approximate inference engines for general posterior probabilities, and in particular
we can use them to provide approximations to the posterior marginals of individual diseases.
In practice we found that the distribution P (f + j ) yielded more accurate posterior
marginals than the distribution P (f + jq ), and we restrict our presentation to P (f + j ). Figure 4 displays a scatterplot of these approximate posterior marginals, with panel (a) corre-

0.6

0.4

0.2

(a)

0
0

0.6

0.4

0.2

0.2

0.4
0.6
exact marginals

0.8

(b)

1

0
0

0.2

0.4
0.6
exact marginals

0.8

1

Figure 4: Scatterplot of the variational posterior estimates and the exact marginals. In
(a) 8 positive findings were treated exactly and in (b) 12 positive findings were
treated exactly.
sponding to the case in which 8 positive findings were treated exactly and panel (b) the case
in which 12 positive findings treated exactly. The plots were obtained by first extracting
the 50 highest posterior marginals from each case using exact methods and then computing
the approximate posterior marginals for the corresponding diseases. If the approximate
marginals are in fact correct then the points in the figures should align along the diagonals
as shown by the dotted lines. We see a reasonably good correspondence|the variational
algorithm appears to provide a good approximation to the largest posterior marginals. (We
quantify this correspondence with a ranking measure later in this section).
A current state-of-the-art algorithm for the QMR-DT is the enhanced version of likelihoodweighted sampling proposed by Shwe and Cooper (1991). Likelihood-weighted sampling is
a stochastic sampling method proposed by Fung and Chang (1990) and Shachter and Peot
(1990). Likelihood-weighted sampling is basically a simple forward sampling method that
weights samples by their likelihoods. It can be enhanced and improved by utilizing \selfimportance sampling" (see Shachter & Peot, 1990), a version of importance sampling in
which the importance sampling distribution is continually updated to reect the current
estimated posterior distribution. Middleton et al. (1990) utilized likelihood-weighted sampling with self-importance sampling (as well as a heuristic initialization scheme known as
\iterative tabular Bayes") for the QMR-DT model and found that it did not work satisfactorily. Subsequent work by Shwe and Cooper (1991), however, used an additional
enhancement to the algorithm known as `Markov blanket scoring" (see Shachter & Peot,
1990), which distributes fractions of samples to the positive and negative values of a node
in proportion to the probability of these values conditioned on the Markov blanket of the
node. The combination of Markov blanket scoring and self-importance sampling yielded
305

fiJaakkola & Jordan

an effective algorithm.5 In particular, with these modifications in place, Shwe and Cooper
reported reasonable accuracy for two of the dicult CPC cases.
We re-implemented the likelihood-weighted sampling algorithm of Shwe and Cooper,
incorporating the Markov blanket scoring heuristic and self-importance sampling. (We did
not utilize \iterative tabular Bayes" but instead utilized a related initialization scheme{
\heuristic tabular Bayes"{also discussed by Shwe and Cooper). In this section we discuss
the results of running this algorithm on the four tractable CPC cases, comparing to the
results of variational inference.6 In the following section we present a fuller comparative
analysis of the two algorithms for all of the CPC cases.
Likelihood-weighting sampling, and indeed any sampling algorithm, realizes a timeaccuracy tradeoff|taking additional samples requires more time but improves accuracy.
In comparing the sampling algorithm to the variational algorithm, we ran the sampling
algorithm for several different total time periods, so that the accuracy achieved by the
sampling algorithm roughly covered the range achieved by the variational algorithm. The
results are shown in Figure 5, with the right-hand curve corresponding to the sampling runs.
The figure displays the mean correlations between the approximate and exact posterior
marginals across ten independent runs of the algorithm (for the four tractable CPC cases).
1

mean correlation

0.98
0.96
0.94
0.92
0.9
0.88
0.86 1
10

0

1

10
10
execution time in seconds

2

10

Figure 5: The mean correlation between the approximate and exact posterior marginals as
a function of the execution time (in seconds). Solid line: variational estimates;
dashed line: likelihood-weighting sampling. The lines above and below the sampling result represent standard errors of the mean based on the ten independent
runs of the sampler.
Variational algorithms are also characterized by a time-accuracy tradeoff. In particular,
the accuracy of the method generally improves as more findings are treated exactly, at
the cost of additional computation. Figure 5 also shows the results from the variational
algorithm (the left-hand curve). The three points on the curve correspond to up to 8, 12 and
5. The initialization method proved to have little effect on the inference results.
6. We also investigated Gibbs sampling (Pearl, 1988). The results from Gibbs sampling were not as good
as the results from likelihood-weighted sampling, and we report only the latter results in the remainder
of the paper.

306

fiVariational Probabilistic Inference and QMR-DT

16 positive findings treated exactly. Note that the variational estimates are deterministic
and thus only a single run was made.
The figure shows that to achieve roughly equivalent levels of accuracy, the sampling
algorithm requires significantly more computation time than the variational method.
Although scatterplots and correlation measures provide a rough indication of the accuracy of an approximation algorithm, they are deficient in several respects. In particular, in
diagnostic practice the interest is in the ability of an algorithm to rank diseases correctly,
and to avoid both false positives (diseases that are not in fact significant but are included
in the set of highly ranked diseases) and false negatives (significant diseases that are omitted from the set of highly ranked diseases). We defined a ranking measure as follows (see
also Middleton et al., 1990). Consider a set of the N highest ranking disease hypotheses,
where the ranking is based on the correct posterior marginals. Corresponding to this set
of diseases we can find the smallest set of N 0 approximately ranked diseases that includes
the N significant ones. In other words, for any N \true positives" an approximate method
produces N 0 , N \false positives." Plotting false positives as a function of true positives
provides a meaningful and useful measure of the accuracy of an approximation scheme.
To the extent that a method provides a nearly correct ranking of true positives the plot
increases slowly and the area under the curve is small. When a significant disease appears
late in the approximate ordering the plot increases rapidly near the true rank of the missed
disease and the area under the curve is large.
We also plot the number of \false negatives" in a set of top N highly ranked diseases.
False negatives refer to the number of diseases, out of the N highest ranking diseases,
that do not appear in the set of N approximately ranked diseases. Note that unlike the
previous measure, this measure does not reveal the severity of the misplacements, only their
frequency.
With this improved diagnostic measure in hand, let us return to the evaluation of the
inference algorithms, beginning with the variational algorithm. Figure 6 provides plots of
60

7

50

6

false negatives

false positives

5
40
30
20

4
3
2

10

(a)

0
0

1

10

20
30
true positives

40

(b)

50

0
0

10

20
30
approximate ranking

40

50

Figure 6: (a) Average number of false positives as a function of true positives for the variational method (solid lines) and the partially-exact method (dashed line). (b) False
negatives in the set of top N approximately ranked diseases. In both figures 8
positive findings were treated exactly.
the false positives (panel a) and false negatives (panel b) against the true positives for the
307

fiJaakkola & Jordan

40

4

35

3.5

(a)

3
false negatives

false positives

30
25
20
15

2.5
2
1.5

10

1

5

0.5

0
0

10

20
30
true positives

40

(b)

50

0
0

10

20
30
approximate ranking

40

50

Figure 7: (a) Average number of false positives as a function of true positives for the variational method (solid line) and the partially-exact method (dashed line). (b) False
negatives in the set of top N approximately ranked diseases. In both figures 12
positive findings were treated exactly.
tractable CPC cases. Eight positive findings were treated exactly in the simulation shown
in this figure. Figure 7 displays the results when 12 positive finding were treated exactly.
As we noted earlier, 8 and 12 positive findings comprise a significant fraction of the
total positive findings for the tractable CPC cases, and thus it is important to verify that
the variational transformations are in fact contributing to the accuracy of the posterior
approximations above and beyond the exact calculations. We did this by comparing the
variational method to a method which we call the \partially-exact" method in which the
posterior probabilities were obtained using only those findings that were treated exactly in
the variational calculations (i.e., using only those findings that were not transformed). If
the variational transformations did not contribute to the accuracy of the approximation,
then the performance of the partially-exact method should be comparable to that of the
variational method.7 Figure 6 and Figure 7 clearly indicate that this is not the case. The
difference in accuracy between these methods is substantial while their computational load
is comparable (about 0.1 seconds on a 433MHz Dec Alpha).
We believe that the accuracy portrayed in the false positive plots provides a good indication of the potential of the variational algorithm for providing a practical solution to
the approximate inference problem for the QMR-DT. As the figures show, the number of
false positives grows slowly with the number of true positives. For example, as shown in
Figure 6 where eight positive findings are treated exactly, to find the 20 most likely diseases
we would only need to entertain the top 23 diseases in the list of approximately ranked
diseases (compared to more than 50 for the partially-exact method).
The ranking plot for the likelihood-weighted sampler is shown in Figure 8, with the
curve for the variational method from Figure 7 included for comparison. To make these
plots, we ran the likelihood-weighted sampler for an amount of time (6.15 seconds) that was
7. It should be noted that this is a conservative comparison, because the partially-exact method in fact
benefits from the variational transformation|the set of exactly treated positive findings is selected on
the basis of the accuracy of the variational transformations, and these accuracies correlate with the
diagnostic relevance of the findings.

308

fiVariational Probabilistic Inference and QMR-DT

40
35

false positives

30
25
20
15
10
5
0
0

10

20
30
true positives

40

50

Figure 8: Average number of false positives as a function of true positives for the likelihoodweighted sampler (dashed line) and the variational method (solid line) with 12
positive findings treated exactly.
comparable to the time allocated to our slowest variational method (3.17 seconds; this was
the case in which 16 positive findings were treated exactly. Recall that the time required
for the variational algorithm with 12 positive findings treated exactly was 0.85 seconds.) As
the plots show, for these tractable CPC cases, the variational method is significantly more
accurate than the sampling algorithm for comparable computational loads.

5.2 The Full CPC Corpus

We now consider the full CPC corpus. The majority of these cases (44 of 48 cases), have
more than 20 positive findings and thus appear to be beyond the reach of exact methods.
An important attraction of sampling methods is the mathematical guarantee of accurate
estimates in the limit of a suciently large sample size (Gelfand & Smith, 1990). Thus
sampling methods have the promise of providing a general methodology for approximate
inference, with two caveats: (1) the number of samples that is needed can be dicult to
diagnosis, and (2) very many samples may be required to obtain accurate estimates. For
real-time applications, the latter issue can rule out sampling solutions. However, long-term
runs of a sampler can still provide a useful baseline for the evaluation of the accuracy of faster
approximation algorithms. We begin by considering this latter possibility in the context of
likelihood-weighted sampling for the QMR-DT. We then turn to a comparative evaluation
of likelihood-weighted sampling and variational methods in the time-limited setting.
To explore the viability of the likelihood-weighted sampler for providing a surrogate for
the gold standard, we carried out two independent runs each consisting of 400,000 samples.
Figure 9(a) shows the estimates of the log-likelihood from the first sampling run for all
of the CPC cases. We also show the variational upper and lower bounds for these cases
(the cases have been sorted according to the lower bound). Note that these bounds are
rigorous bounds on the true log-likelihood, and thus they provide a direct indication of the
accuracy of the sampling estimates. Although we see that many of the estimates lie between
the bounds, we also see in many cases that the sampling estimates deviate substantially
from the bounds. This suggests that the posterior marginal estimates obtained from these
samples are likely to be unreliable as well. Indeed, Figure 9(b) presents a scatterplot of
309

fiJaakkola & Jordan

20
1

40
0.8
sampling estimates 2

loglikelihood

60
80
100
120
140
160

0.6

0.4

0.2

180

(a)

200
0

10

20
30
sorted cases

40

50

(b)

0
0

0.2

0.4
0.6
sampling estimates 1

0.8

1

Figure 9: (a) Upper and lower bounds (solid lines) and the corresponding sampling estimates (dashed line) of the log-likelihood of observed findings for the CPC cases.
(b) A correlation plot between the posterior marginal estimates from two independent sampling runs.
estimated posterior marginals for the two independent runs of the sampler. Although we
see many cases in which the results lie on the diagonal, indicating agreement between the
two runs, we also see many pairs of posterior estimates that are far from the diagonal.
These results cast some doubt on the viability of the likelihood-weighted sampler as a
general approximator for the full set of CPC cases. Even more problematically we appear
to be without a reliable surrogate for the gold standard for these cases, making it dicult
to evaluate the accuracy of real-time approximations such as the variational method. Note,
however, that the estimates in Figure 9(a) seem to fall into two classes|estimates that
lie within the variational bounds and estimates that are rather far from the bounds. This
suggests the possibility that the distribution being sampled from is multi-modal, with some
estimates falling within the correct mode and providing good approximations and with
others falling in spurious modes and providing seriously inaccurate approximations. If the
situation holds, then an accurate surrogate for the gold standard might be obtained by using
the variational bounds to filter the sampling results and retaining only those estimates that
lie between the bounds given by the variational approach.
Figure 10 provides some evidence of the viability of this approach. In 24 out of the 48
CPC cases both of the independent runs of the sampler resulted in estimates of the loglikelihood lying approximately within the variational bounds. We recomputed the posterior
marginal estimates for these selected cases and plotted them against each other in the figure.
The scatterplot shows a high degree of correspondence of the posterior estimates in these
cases. We thus tentatively assume that these estimates are accurate enough to serve as a
surrogate gold standard and proceed to evaluate the real-time approximations.
Figure 11 plots the false positives against the true positives on the 24 selected CPC
cases for the variational method. Twelve positive findings were treated exactly in this
simulation. Obtaining the variational estimates took 0.29 seconds of computer time per
case. Although the curve increases more rapidly than with the tractable CPC cases, the
variational algorithm still appears to provide a reasonably accurate ranking of the posterior
marginals, within a reasonable time frame.
310

fiVariational Probabilistic Inference and QMR-DT

1

sampling estimates 2

0.8

0.6

0.4

0.2

0
0

0.2

0.4
0.6
sampling estimates 1

0.8

1

Figure 10: A correlation plot between the selected posterior marginal estimates from two
independent sampling runs, where the selection was based on the variational
upper and lower bounds.
70
60

false positives

50
40
30
20
10
0
0

10

20
30
true positives

40

50

Figure 11: Average number of false positives as a function of true positives for the variational method (solid line) and the likelihood-weighted sampler (dashed line).
For the variational method 12 positive findings were treated exactly, and for the
sampler the results are averages across ten runs.
To compare the variational algorithm to a time-limited version of the likelihood-weighted
sampler we ran the latter algorithm for a period of time (8.83 seconds per case) roughly comparable to the running time of the variational algorithm (0.29 seconds per case). Figure 11
shows the corresponding plot of false positives against true positives, where we have averaged over ten independent runs. We see that the curve increases significantly more steeply
than the variational curve. To find the 20 most likely diseases with the variational method
we would only need to entertain the top 30 diseases in the list of approximately ranked
diseases. For the sampling method we would need to entertain the top 70 approximately
ranked diseases.

5.3 Interval Bounds on the Marginal Probabilities

Thus far we have utilized the variational approach to produce approximations to the posterior marginals. The approximations that we have discussed originate from upper and lower
311

fiJaakkola & Jordan

bounds on the likelihood, but they are not themselves bounds. That is, they are not guaranteed to lie above or below the true posteriors, as we see in Figure 4. As we discussed in
Section 4.1, however, it is also possible to induce upper and lower bounds on the posterior
marginals from upper and lower bounds on the likelihood (cf. Eq. 33). In this section we
evaluate these interval bounds for the QMR-DT posterior marginals.
Figure 12 displays histogram of the interval bounds for the four tractable CPC cases, the
24 selected CPC cases from the previous section, and all of the CPC cases. These histograms
include all of the diseases in the QMR-DT network. In the case of the tractable cases the
0.8

0.8

0.8

0.6

0.6

0.4

0
0

0.6

0.4

0.2

(a)

Frequency

1

Frequency

1

Frequency

1

0.4

0.2

0.2

0.4

0.6

Interval size

0.8

1

(b)

0
0

0.2

0.2

0.4

0.6

Interval size

0.8

1

(c)

0
0

0.2

0.4

0.6

0.8

Interval size

Figure 12: Histograms of the size of the interval bounds on all of the diseases in the QMRDT network for (a) the four tractable CPC cases, (b) the 24 selected CPC cases
from the previous section, and (c) all of the CPC cases.
variational method was run with 12 positive findings treated exactly. For the remaining
CPC cases the variational method was run with 16 positive findings treated exactly. The
running time of the algorithm was less than 10 seconds of computer time per CPC case.
For the tractable CPC cases, the interval bounds are tight for nearly all of the diseases
in the network. However, (1) few of the positive findings are treated variationally in these
cases, and (2) there is no need in practice to compute variational bounds for these cases.
We get a somewhat better picture of the viability of the variational interval bounds in
Figure 12(b) and Figure 12(c), and the picture is decidedly mixed. For the 24 selected
cases, tight bounds are provided for approximately half of the diseases. The bounds are
vacuous for approximately a quarter of the diseases, and there are a range of diseases in
between. When we consider all of the CPC cases, approximately a third of the bounds are
tight and nearly half are vacuous.
Although these results may indicate limitations in our variational approximation, there
is another more immediate problem that appears to be responsible for the looseness of
the bounds in many cases. In particular, recall that we use the Quickscore algorithm
(Heckerman, 1989) to handle the exact calculations within the framework of our variational
algorithm. Unfortunately Quickscore suffers from vanishing numerical precision for large
numbers of positive findings, and in general we begin to run into numerical problems,
resulting in vacuous bounds, when 16 positive findings are incorporated exactly into the
variational approximation. Thus, although it is clearly of interest to run the variational
algorithm for longer durations, and thereby improve the bounds, we are unable to do so
within our current implementation of the exact subroutine.
312

1

fiVariational Probabilistic Inference and QMR-DT

While it is clearly worth studying methods other than Quickscore for treating the exact findings within the variational algorithm, it is also of interest to consider combining
variational methods with other methods, such as search-based or other partial evaluation
methods, that are based on intervals. These methods may help in simplifying the posterior
and obviating the need for improving the exact calculations.
It is also worth emphasizing the positive aspect of these results and their potential
practical utility. The previous section showed that the variational method can provide accurate approximations to the posterior marginals. Combined with the interval bounds in
this section|which are calculated eciently|the user can obtain guarantees on approximately a third of these approximations. Given the relatively benign rate of increase in false
positives as a function of true positives (Figure 11), such guarantees may suce. Finally,
for diseases in which the bounds are loose there are also perturbation methods available
(Jaakkola, 1997) that can help to validate the approximations for these diseases.

6. Discussion
Let us summarize the variational inference method and evaluate the results that we have
obtained.
The variational method begins with parameterized upper and lower bounds on the individual conditional probabilities at the nodes of the model. For the QMR-DT, these bounds
are exponentials of linear functions, and introducing them into the model corresponds to
delinking nodes from the graph. Sums of products of these bounds yield bounds, and thus
we readily obtain parameterized bounds on marginal probabilities, in particular upper and
lower bounds on the likelihood.
We exploited the likelihood bounds in evaluating the output of the likelihood-weighted
sampling algorithm. Although the sampling algorithm did not yield reliable results across
the corpus of CPC cases, when we utilized the variational upper and lower bounds to select
among the samples we were able to obtain sampling results that were consistent between
runs. This suggests a general procedure in which variational bounds are used to assess the
convergence of a sampling algorithm. (One can also imagine a more intimate relationship
between these algorithms in which the variational bounds are used to adjust the on-line
course of the sampler).
The fact that we have bounds on the likelihood (or other marginal probabilities) is
critical|the bounding property allows us to find optimizing values of the variational parameters by minimizing the upper-bounding variational distribution and maximizing the
lower-bounding variational distribution. In the case of the QMR-DT network (a bipartite noisy-OR graph), the minimization problem is a convex optimization problem and the
maximization problem is solved via the EM algorithm.
Once the variational parameters are optimized, the resulting variational distribution can
be exploited as an inference engine for calculating approximations to posterior probabilities.
This technique has been our focus in the paper. Graphically, the variationally transformed
model can be viewed as a sub-graph of the original model in which some of the finding
nodes have been delinked. If a sucient number of findings are delinked variationally
then it is possible to run an exact algorithm on the resulting graph. This approach yields
approximations to the posterior marginals of the disease nodes.
313

fiJaakkola & Jordan

We found empirically that these approximations appeared to provide good approximations to the true posterior marginals. This was the case for the tractable set of CPC cases
(cf. Figure 7) and|subject to our assumption that we have obtained a good surrogate for
the gold standard via the selected output of the sampler|also the case for the full CPC
corpus (cf. Figure 11).
We also compared the variational algorithm to a state-of-the-art algorithm for the QMRDT, the likelihood-weighted sampler of Shwe and Cooper (1991). We found that the variational algorithm outperformed the likelihood-weighted sampler both for the tractable cases
and for the full corpus. In particular, for a fixed accuracy requirement the variational algorithm was significantly faster (cf. Figure 5), and for a fixed time allotment the variational
algorithm was significantly more accurate (cf. Figure 8 and Figure 11).
Our results were less satisfactory for the interval bounds on the posterior marginals.
Across the full CPC corpus we found that for approximately one third of the disease the
bounds were tight but for half of the diseases the bounds were vacuous. A major impediment
to obtaining tighter bounds appears to lie not in the variational approximation per se but
rather in the exact subroutine, and we are investigating exact methods with improved
numerical properties.
Although we have focused in detail on the QMR-DT model in this paper, it is worth
noting that the variational probabilistic inference methodology is considerably more general.
Specifically, the methods that we have described here are not limited to the bi-partite
graphical structure of the QMR-DT model, nor is it necessary to employ noisy-OR nodes
(Jaakkola & Jordan, 1996). It is also the case that the type of transformations that we
have exploited in the QMR-DT setting extend to a larger class of dependence relations
based on generalized linear models (Jaakkola, 1997). Finally, for a review of applications of
variational methods to a variety of other graphical model architectures, see Jordan, et al.
(1998).
A promising direction for future research appears to be in the integration of various
kinds of approximate and exact methods (see, e.g., Dagum & Horvitz, 1992; Jensen, Kong,
& Kjrulff, 1995). In particular, search-based methods (Cooper, 1985; Peng & Reggia,
1987, Henrion, 1991) and variational methods both yield bounds on probabilities, and, as
we have indicated in the introduction, they seem to exploit different aspects of the structure of complex probability distributions. It may be possible to combine the bounds from
these algorithm|the variational bounds might be used to guide the search, or the searchbased bounds might be used to aid the variational approximation. Similar comments can
be made with respect to localized partial evaluation methods and bounded conditioning
methods (Draper & Hanks, 1994; Horvitz, et al., 1989). Also, we have seen that variational
bounds can be used for assessing whether estimates from Monte Carlo sampling algorithms
have converged. A further interesting hybrid would be a scheme in which variational approximations are refined by treating them as initial conditions for a sampler.
Even without extensions our results in this paper appear quite promising. We have
presented an algorithm which runs in real time on a large-scale graphical model for which
exact algorithms are in general infeasible. The results that we have obtained appear to
be reasonably accurate across a corpus of dicult diagnostic cases. While further work
is needed, we believe that our results indicate a promising role for variational inference in
developing, critiquing and exploiting large-scale probabilistic models such as the QMR-DT.
314

fiVariational Probabilistic Inference and QMR-DT

Acknowledgements
We would like to thank the University of Pittsburgh and Randy Miller for the use of the
QMR-DT database. We also want to thank David Heckerman for suggesting that we attack
QMR-DT with variational methods, and for providing helpful counsel along the way.

Appendix A. Duality
The upper and lower bounds for individual conditional probability distributions that form
the basis of our variational method are based on the \dual" or \conjugate" representations
of convex functions. We present a brief description of convex duality in this appendix, and
refer the reader to Rockafellar (1970) for a more extensive treatment.
Let f (x) be a real-valued, convex function defined on a convex set X (for example,
X = Rn ). For simplicity of exposition, we assume that f is a well-behaved (differentiable)
function. Consider the graph of f , i.e., the points (x; f (x)) in an n + 1 dimensional space.
The fact that the function f is convex translates into convexity of the set f(x; y ) : y  f (x)g
called the epigraph of f and denoted by epi(f ) (Figure 13). It is an elementary property
f(x)
epi(f)

x  - y - f*()  0

x  - y - f*()  0

x-y-0

Figure 13: Half-spaces containing the convex set epi(f ). The conjugate function f  ( )
defines the critical half-spaces whose intersection is epi(f ), or, equivalently, it
defines the tangent planes of f (x).
of convex sets that they can be represented as the intersection of all the half-spaces that
contain them (see Figure 13). Through parameterizing these half-spaces we obtain the dual
representations of convex functions. To this end, we define a half-space by the condition:
all (x; y ) such that xT  , y ,   0

(34)

where  and  parameterize all (non-vertical) half-spaces. We are interested in characterizing the half-spaces that contain the epigraph of f . We require therefore that the points
in the epigraph must satisfy the half-space condition: for (x; y ) 2 epi(f ), we must have
xT  , y ,   0. This holds whenever xT  , f (x) ,   0 as the points in the epigraph have
the property that y  f (x). Since the condition must be satisfied by all x 2 X , it follows
315

fiJaakkola & Jordan

that
max
f xT  , f (x) ,  g  0;
x2X

(35)

as well. Equivalently,

  max
f xT  , f (x) g
x2X

(36)

where the right-hand side of this equation defines a function of  , which is known as the
\dual" or \conjugate" function f ( ). This function, which is also a convex function, defines
the critical half-spaces which are needed for the representation of epi(f ) as an intersection
of half-spaces (Figure 13).
To clarify the duality between f (x) and f  (x), let us drop the maximum and rewrite
the inequality as:

xT   f (x) + f  ( )

(37)

In this equation, the roles of the two functions are interchangeable and we may suspect that
also f (x) can obtained from the dual function f  (x) by an optimization procedure. This is
in fact the case and we have:

f (x) = max
f xT  , f () g
2

(38)

This equality states that the dual of the dual gives back the original function. It provides
the computational tool for calculating dual functions.
For concave (convex down) functions the results are analogous; we replace max with
min, and lower bounds with upper bounds.

Appendix B. Optimization of the Variational Parameters

The variational method that we have described involves replacing selected local conditional
probabilities with either upper-bounding or lower-bounding variational transformations.
Because the product of bounds is a bound, the variationally transformed joint probability
distribution is a bound (upper or lower) on the true joint probability distribution. Moreover, because sums of bounds is a bound on the sum, we can obtain bounds on marginal
probabilities by marginalizing the variationally transformed joint probability distribution.
In particular, this provides a method for obtaining bounds on the likelihood (the marginal
probability of the evidence).
Note that the variationally transformed distributions are bounds for arbitrary values of
the variational parameters (because each individually transformed node conditional probability is a bound for arbitrary values of its variational parameter). To obtain optimizing
values of the variational parameters, we take advantage of the fact that our transformed
distribution is a bound, and either minimize (in the case of upper bounds) or maximize
(in the case of lower bounds) the transformed distribution with respect to the variational
parameters. It is this optimization process which provides a tight bound on the marginal
probability of interest (e.g., the likelihood) and thereby picks out a particular variational
distribution that can subsequently be used for approximate inference.
316

fiVariational Probabilistic Inference and QMR-DT

In this appendix we discuss the optimization problems that we must solve in the case
of noisy-OR networks. We consider the upper and lower bounds separately, beginning with
the upper bound.

Upper Bound Transformations

Our goal isPto compute a tight upper bound on the likelihood of the observed findings:
P (f + ) = d P (f + jd)P (d). As discussed in Section 4.2, we obtain an upper bound on
P (f + jd) by introducing upper bounds for individual node conditional probabilities. We
represent this upper bound as P (f + jd;  ), which is a product across the individual variational transformations and may contain contributions due to findings that are being treated
exactly (i.e., are not transformed). Marginalizing across d we obtain a bound:

P (f + ) 

X

d

P (f + jd;  )P (d)  P (f + j):

(39)

It is this latter quantity that we wish to minimize with respect to the variational parameters
.
To simplify the notation we assume that the first m positive findings have been transformed (and therefore need to be optimized) while the remaining conditional probabilities
will be treated exactly. In this notation P (f + j ) is given by

P (f + j )

=

/

2
X Y
4

3"

#
Y
Y
+
+
P (fi jd; i)5
P (fi jd) P (dj )
i>m
j
d im
8
9
<Y
=
E : P (fi+ jd; i); ;
im

(40)
(41)

where the expectation is taken with respect to the posterior distribution for the diseases
given those positive findings that we plan to treat exactly. Note that the proportionality
constant does not depend on the variational parameters (it is the likelihood of the exactly
treated positive findings). We now insert the explicit forms of the transformed conditional
probabilities (see Eq. (17)) into Eq. (41) and find:

P (f + j) /
=

8
9
< Y  ( +P  d ),f  ( ) =
i
E : e i i0 j ij j
;
im
 P

P

e im (i i0 ,f (i)) E e j; im i ij dj

(42)
(43)

where we have simply converted the products over i into sums in the exponent and pulled
out the terms that are constants with respect to the expectation. On a log-scale, the
proportionality becomes an equivalence up to a constant:
 P

X


d
i
ij
j
+

j;i

m
log P (f j ) = C + (i i0 , f (i)) + log E e
im

317

(44)

fiJaakkola & Jordan

Several observations are in order. Recall that f (i ) is the conjugate of the concave function
f (the exponent), and is therefore also concave; for this reason ,f (i ) is convex. In
Appendix C we prove that the remaining term:
 P

log E e

j;im iij dj



(45)

is also a convex function of the variational parameters. Now, since any sum of convex
functions is convex, we conclude that log P (f + j ) is a convex function of the variational
parameters. This means that there are no local minima in our optimization problem. We
may safely employ the standard Newton-Raphson procedure to solve r log P (f + j ) = 0.
Alternatively we can utilize fixed-point iterations. In particular, we calculate the derivatives
of the variational form and iteratively solve for the individual variational parameters k such
that the derivatives are zero. The derivatives are given as follows:
8

9

@ log P (f + j) =  + log k + E <X  d =
k0
kj j ;
:
@k
1 + k
j

(46)

@ 2 log P (f + j) = 1 , 1 + Var <X  d = ;
: j kj j ;
@ 2 k
k 1 + k

(47)

8

9

where the expectation and the variance are with respect to the posterior approximation
P (djf + ;  ), and both derivatives can be computed in time linear in the number of associated diseases for the finding. The benign scaling of the variance calculations comes from
exploiting the special properties of the noisy-OR dependence and the marginal independence
of the diseases.
Calculating the expectations in Eq. (7) is exponentially costly in the number of exactly
treated positive findings. When there are a large number of positive findings, we can have
recourse to a simplified procedure in which we optimize variational parameters after having
transformed all or most of the positive findings. While the resulting variational parameters
are suboptimal, we have found in practice that the incurred loss in accuracy is typically quite
small. In the simulations reported in the paper, we optimized the variational parameters
after approximately half of the exactly treated findings had been introduced. (To be precise,
in the case of 8, 12 and 16 total findings treated exactly, we optimized the parameters after
4, 8, and 8 findings, respectively, were introduced).

Lower Bound Transformations

Mimicking the case of upper bounds, we replace individual conditional probabilities of
the findings with lower-bounding transformations, resulting in a lower-bounding expression
P (f + jd; q). Taking the product with P (d) and marginalizing over d yields a lower bound
on the likelihood:
X
P (f + )  P (f + jd; q )P (d)  P (f + jq):
(48)
d

We wish to maximize P (f + jq ) with respect to the variational parameters q to obtain the
tightest possible bound.
318

fiVariational Probabilistic Inference and QMR-DT

Our problem can be mapped onto a standard optimization problem in statistics. In
particular, treating d as a latent variable, f as an observed variable, and q as a parameter
vector, the optimization of P (f + jq ) (or its logarithm) can be viewed as a standard maximum
likelihood estimation problem for a latent variable model. It can be solved using the EM
algorithm (Dempster, Laird, & Rubin, 1977). The algorithm yields a sequence of variational
parameters that monotonically increase the objective function log P (f + jq ). Within the EM
framework, we obtain an update of the variational parameters by maximizing the expected
complete log-likelihood:


	

E log P (f + jd; q )P (d) =

X

i

n

o

E log P (fi+ jd; qji) + constant;

(49)

where q old denotes the vector of variational parameters before the update, where the constant term is independent of the variational parameters q and where the expectation is with
respect to the posterior distribution P (djf + ; q old ) / P (f + jd; q old)P (d). Since the variational
parameters associated with the conditional probabilities P (fi+ jd; qji) are independent of one
another, we can maximize each term in the above sum separately. Recalling the form of the
variational transformation (see Eq. (24)), we have:
!

"

#

E
=
qjji E fdjg f io + qij , f ( io )
j ji
j
+f ( io )
(50)
which we are to maximize with respect to qj ji while keeping the expectations E fdj g fixed.
n

log P (fi+ jd; qji)

o

X

This optimization problem can be solved iteratively and monotonically by performing the
following synchronous updates with normalization:

qj ji

!

"

!

E fdj g qjji f io + qij , ij f 0 io + qij , qjji f ( io )
j ji
j ji

#

(51)

where f 0 denotes the derivative of f . (The update is guaranteed to be non-negative).
This algorithm can be easily extended to handle the case where not all the positive
findings have been transformed. The only new feature is that some of the conditional
probabilities in the products P (f + jd; q old) and P (f + jd; q ) have been left intact, i.e., not
transformed; the optimization with respect to the variational parameters corresponding to
the transformed conditionals proceeds as before.

Appendix C. Convexity

The purpose of this appendix is to demonstrate that the function:
 P

log E e

j;im iij dj



(52)

is a convex function of the variational parameters i . We note first that
ane transformaP
tions do not change convexity properties. Thus convexity in X = j;im i ij dj implies
319

fiJaakkola & Jordan

convexity in the variational parameters  . It remains to show that
n

o

log E e X = log

X

i

pi e Xi = f (X~ )

(53)

is a convex function of the vector X~ = fX1 : : :Xn gT ; here we have indicated the discrete
values in the range of the random variable X by Xi and denoted the probability measure
on such values by pi . Taking the gradient of f with respect to Xk gives:

@ f (X~ ) = Ppk e Xk  q
k
@Xk
i pi e Xi

(54)

2
Hkl = @X@ @X f (X~ ) = kl qk , qk ql

(55)

X
X
X
Z~ T HZ~ = qk Zk2 , ( qk Zk )( ql Zl) = VarfZ g  0

(56)

where qk defines a probability distribution. The convexity is revealed by a positive semidefinite Hessian H, whose components in this case are
k

l

To see that H is positive semi-definite, consider
k

k

l

where VarfZ g is the variance of a discrete random variable Z which takes the values Zi
with probability qi .

References

D'Ambrosio, B. (1993). Incremental probabilistic inference. In Proceedings of the Ninth
Conference on Uncertainty in Artificial Intelligence. San Mateo, CA: Morgan Kaufmann.
D'Ambrosio, B. (1994). Symbolic probabilistic inference in large BN20 networks. In Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence. San Mateo,
CA: Morgan Kaufmann.
Cooper, G. (1985). NESTOR: A computer-based medical diagnostic aid that integrates
causal and probabilistic knowledge. Ph.D. Dissertation, Medical Informatics Sciences,
Stanford University, Stanford, CA. (Available from UMI at
http://wwwlib.umi.com/dissertations/main).
Cooper, G. (1990). The computational complexity of probabilistic inference using Bayesian
belief networks. Artificial Intelligence, 42, 393{405.
Dagum, P., & Horvitz, E. (1992). Reformulating inference problems through selective
conditioning. In Proceedings of the Eighth Annual Conference on Uncertainty in
Artificial Intelligence.
Dagum, P., & Horvitz, E. (1993). A Bayesian analysis of simulation algorithms for inference
in Belief networks. Networks, 23, 499{516.
320

fiVariational Probabilistic Inference and QMR-DT

Dagum, P., & Luby, M. (1993). Approximate probabilistic reasoning in Bayesian belief
networks is NP-hard. Artificial Intelligence, 60, 141{153.
Dechter, R. (1997). Mini-buckets: A general scheme of generating approximations in automated reasoning. In Proceedings of the Fifteenth International Joint Conference on
Artificial Intelligence.
Dechter, R. (1998). Bucket elimination: A unifying framework for probabilistic inference.
In M. I. Jordan (Ed.), Learning in Graphical Models. Cambridge, MA: MIT Press.
Dempster, A., Laird, N., & Rubin, D. (1977). Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical Society B, 39, 1{38.
Draper, D., & Hanks, S. (1994). Localized partial evaluation of belief networks. In Proceedings of the Tenth Annual Conference on Uncertainty in Artificial Intelligence.
Fung, R., & Chang, K. C. (1990). Weighting and integrating evidence for stochastic simulation in Bayesian networks. In Proceedings of Fifth Conference on Uncertainty in
Artificial Intelligence. Amsterdam: Elsevier Science.
Gelfand, A., & Smith, A. (1990). Sampling-based approaches to calculating marginal Densities. Journal of the American Statistical Association, 85, 398{409.
Heckerman, D. (1989). A tractable inference algorithm for diagnosing multiple diseases. In
Proceedings of the Fifth Conference on Uncertainty in Artificial Intelligence.
Henrion, M. (1991). Search-based methods to bound diagnostic probabilities in very large
belief nets. In Proceedings of Seventh Conference on Uncertainty in Artificial Intelligence.
Horvitz, E. Suermondt, H., & Cooper, G. (1989). Bounded conditioning: Flexible inference
for decisions under scarce resources. In Proceedings of Fifth Conference on Uncertainty in Artificial Intelligence.
Jaakkola, T. (1997). Variational methods for inference and learning in graphical models.
PhD thesis, Department of Brain and Cognitive Sciences, Massachusetts Institute of
Technology.
Jaakkola, T., & Jordan, M. (1996). Recursive algorithms for approximating probabilities
in graphical models. In Advances of Neural Information Processing Systems 9. Cambridge, MA: MIT Press.
Jensen, C. S., Kong, A., & Kjrulff, U. (1995). Blocking-Gibbs sampling in very large
probabilistic expert systems. International Journal of Human-Computer Studies, 42,
647{666.
Jensen, F. (1996). Introduction to Bayesian networks. New York: Springer.
321

fiJaakkola & Jordan

Jordan, M., Ghaharamani, Z. Jaakkola, T., & Saul, L. (in press). An introduction to
variational methods for graphical models. Machine Learning.
Lauritzen, S., & Spiegelhalter, D. (1988). Local computations with probabilities on graphical structures and their application to expert systems (with discussion). Journal of
the Royal Statistical Society B, 50, 157{224.
MacKay, D. J. C. (1998). Introduction to Monte Carlo methods. In M. I. Jordan (Ed.),
Learning in Graphical Models. Cambridge, MA: MIT Press.
Middleton, B., Shwe, M., Heckerman, D., Henrion, M., Horvitz, E., Lehmann, H., & Cooper,
G. (1990). Probabilistic diagnosis using a reformulation of the INTERNIST-1/QMR
knowledge base II. Evaluation of diagnostic performance. Section on Medical Informatics Technical report SMI-90-0329, Stanford University.
Miller, R. A., Fasarie, F. E., & Myers, J. D. (1986). Quick medical reference (QMR) for
diagnostic assistance. Medical Computing, 3, 34{48.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems. San Mateo, CA: Morgan
Kaufmann.
Peng, Y., & Reggia, J. (1987). A probabilistic causal model for diagnostic problem solving {
Part 2: Diagnostic strategy. IEEE Trans. on Systems, Man, and Cybernetics: Special
Issue for Diagnosis, 17, 395{406.
Poole, D. (1997). Probabilistic partial evaluation: Exploiting rule structure in probabilistic
inference. In Proceedings of the Fifteenth International Joint Conference on Artificial
Intelligence.
Rockafellar, R. (1972). Convex Analysis. Princeton University Press.
Shachter, R. D., & Peot, M. (1990). Simulation approaches to general probabilistic inference
on belief networks. In Proceedings of Fifth Conference on Uncertainty in Artificial
Intelligence. Elsevier Science: Amsterdam.
Shenoy, P. P. (1992). Valuation-based systems for Bayesian decision analysis. Operations
Research, 40, 463{484.
Shwe, M., & Cooper, G. (1991). An empirical analysis of likelihood { weighting simulation
on a large, multiply connected medical belief network. Computers and Biomedical
Research, 24, 453-475.
Shwe, M., Middleton, B., Heckerman, D., Henrion, M., Horvitz, E., Lehmann, H., & G.
Cooper (1991). Probabilistic diagnosis using a reformulation of the INTERNIST1/QMR knowledge base I. The probabilistic model and inference algorithms. Methods
of Information in Medicine, 30, 241{255.

322

fiJournal of Artificial Intelligence Research 10 (1999) 199-241

Submitted 9/98; published 4/99

Probabilistic Deduction with
Conditional Constraints over Basic Events
Thomas Lukasiewicz

Institut fur Informatik, Universitat Gieen
Arndtstrae 2, D-35392 Gieen, Germany

lukasiewicz@informatik.uni-giessen.de

Abstract

We study the problem of probabilistic deduction with conditional constraints over basic
events. We show that globally complete probabilistic deduction with conditional constraints
over basic events is NP-hard. We then concentrate on the special case of probabilistic
deduction in conditional constraint trees. We elaborate very ecient techniques for globally
complete probabilistic deduction. In detail, for conditional constraint trees with point
probabilities, we present a local approach to globally complete probabilistic deduction,
which runs in linear time in the size of the conditional constraint trees. For conditional
constraint trees with interval probabilities, we show that globally complete probabilistic
deduction can be done in a global approach by solving nonlinear programs. We show how
these nonlinear programs can be transformed into equivalent linear programs, which are
solvable in polynomial time in the size of the conditional constraint trees.

1. Introduction
Dealing with uncertain knowledge plays an important role in knowledge representation and
reasoning. There are many different formalisms and methodologies for handling uncertainty.
Most of them are directly or indirectly based on probability theory.
In this paper, we focus on probabilistic deduction with conditional constraints over basic
events (that is, interval restrictions for conditional probabilities of elementary events). The
considered probabilistic deduction problems consist of a probabilistic knowledge base and
a probabilistic query. We give a classical example. As a probabilistic knowledge base, we
may take the probabilistic knowledge that all ostriches are birds, that the probability of
Tweety being a bird is greater than 0.90, and that the probability of Tweety being an ostrich
provided she is a bird is greater than 0.80. As a probabilistic query, we may now wonder
about the entailed greatest lower and least upper bound for the probability that Tweety
is an ostrich. The solution to this probabilistic deduction problem is 0.72 for the entailed
greatest lower bound and 1.00 for the entailed least upper bound.
More generally, probabilistic deduction with conditional constraints over propositional
events can be done in a global approach by linear programming or in a local approach by
the iterative application of inference rules. Note that it is immediately NP-hard, since it
generalizes the satisfiability problem for classical propositional logic (see Section 2.2).
Research on the global approach spread in particular after the important work on probabilistic logic by Nilsson (1986) (see also the work by Paa, 1988). The main focus was
on analyzing the computational complexity of satisfiability and entailment in probabilistic logic and on developing ecient linear programming algorithms for these problems.
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiLukasiewicz

Georgakopoulos et al. (1988) show that the satisfiability problem in probabilistic logic is
NP-complete and propose to apply column generation techniques for its processing. This
approach was further developed by Kavvadias and Papadimitriou (1990), Jaumard et al.
(1991), Andersen and Hooker (1994), and Hansen et al. (1995). In particular, Jaumard et
al. (1991) report promising experimental results on the eciency in special cases of probabilistic satisfiability and entailment. Moreover, Kavvadias and Papadimitriou (1990) and
Jaumard et al. (1991) identify special cases of probabilistic satisfiability that can be solved
in polynomial time. Other work on the global approach concentrates on reducing the number of linear constraints (Luo et al. 1996) and the number of variables (Lukasiewicz, 1997).
Finally, Fagin et al. (1992) present a sound and complete axiom system for reasoning about
probabilities that are expressed by linear inequalities over propositional events. They show
that the satisfiability problem in this quite expressive framework is still NP-complete.
In early work, Dubois and Prade (1988) use inference rules to model default reasoning with imprecise numerical and fuzzy quantifiers. For this reason, subsequent research
on inference rules especially aims at analyzing patterns of human commonsense reasoning
(Dubois et al. 1990, 1993; Amarger et al. 1991; Thone, 1994; Thone et al. 1995). Frisch
and Haddawy (1994) discuss the use of inference rules for deduction in probabilistic logic.
Recent work on inference rules concentrates on integrating probabilistic knowledge into description logics (Heinsohn, 1994) and on analyzing the interplay between taxonomic and
probabilistic deduction (Lukasiewicz 1998a, 1999a).
We now summarize the main characteristics of the global and the local approach.
The global approach can be performed within quite rich probabilistic languages (Fagin
et al., 1992). Crucially, probabilistic deduction by linear programming is globally complete
(that is, it really provides the requested tightest bounds entailed by the whole probabilistic
knowledge base). However, a main drawback of the global approach is that it generally does
not provide useful explanatory information on the deduction process. Finally, results on
the special-case tractability of global approaches are driven by the technical possibilities of
linear programming techniques and not by the needs of artificial intelligence applications.
Hence, they do not seem to be very useful in the artificial intelligence context.
A main advantage of the local approach is that the deduced results can be explained
in a natural way by the sequence of applied inference rules (Amarger et al. 1991; Frisch
& Haddawy, 1994). However, the iterative application of inference rules is generally restricted to quite narrow probabilistic languages. Moreover, it is very rarely and only within
very restricted languages globally complete (Frisch and Haddawy, 1994, give an example
of globally complete local probabilistic deduction in a very restricted framework). Finally,
as far as the computational complexity is concerned, there are very few experimental and
theoretical results on the special-case tractability of local approaches.
The main motivating idea of this paper is to elaborate ecient local techniques for
globally complete probabilistic deduction. Inspired by previous work on inference rules, we
focus our research on the language of conditional constraints over basic events:
Dubois and Prade (1988) study the chaining of two bidirectional conditional constraints
over basic events (\quantified syllogism rule") and some of its special cases. Dubois et
al. (1990) additionally discuss probabilistic deductions about conjunctions of basic events.
Furthermore, they describe the open problem of probabilistic deduction along a chain of
more than two bidirectional conditional constraints over basic events. In later work, Dubois
200

fiProbabilistic Deduction with Conditional Constraints over Basic Events

et al. (1993) use a qualitative version of the \quantified syllogism rule" in an approach to
reasoning with linguistic quantifiers. Amarger et al. (1991) propose to apply the \quantified syllogism rule" and the \generalized Bayes' rule" to sets of bidirectional conditional
constraints over basic events. They report promising experimental results on the global completeness and the computational complexity of the presented deduction technique. However,
this deduction technique is generally not globally complete. Thone (1994) examines trees of
bidirectional conditional constraints over basic events. He presents a linear-time deduction
technique that is based on a system of inference rules and that computes certain logically
entailed greatest lower bounds (in the technical notions of this paper, which will be defined
below, tight lower answers to conclusion-restricted queries are computed).
As a first contribution of this paper, we show that globally complete probabilistic deduction with conditional constraints over basic events is NP-hard. It is surprising that this
quite restricted class of probabilistic deduction problems is still computationally so dicult. Hence, it is unlikely that there is an algorithm that eciently solves all probabilistic
deduction problems with conditional constraints over basic events. However, we can still
hope that there are ecient special-case, average-case, or approximation algorithms.
In this paper, we then elaborate ecient special-case algorithms. In detail, we concentrate on probabilistic deduction in conditional constraint trees. It is an interesting subclass of all probabilistic deduction problems with conditional constraints over basic events.
Conditional constraint trees are undirected trees with basic events as nodes and with bidirectional conditional constraints over basic events as edges between the nodes (that is,
deduction in conditional constraint trees is a generalization of deduction along a chain of
bidirectional conditional constraints over basic events). Like Bayesian networks, conditional
constraint trees represent a well-structured probabilistic knowledge base. Differently from
Bayesian networks, they do not encode any probabilistic independencies.
As a main contribution of this paper, we have the following results. For conditional constraint trees with point probabilities, we present functions for deducing greatest lower and
least upper bounds in linear time in the size of the conditional constraint trees. Moreover, for
conditional constraint trees with interval probabilities, we show that greatest lower bounds
can be deduced in the same way, in linear time in the size of the conditional constraint trees.
However, computing least upper bounds turns out to be computationally more dicult. It
can be done by solving special nonlinear programs. We show how these nonlinear programs
can be transformed into equivalent linear programs. The resulting linear programs have a
number of variables and inequalities linear and polynomial, respectively, in the size of the
conditional constraint trees. Thus, our way of deducing least upper bounds still runs in
polynomial time in the size of the conditional constraint trees, since linear programming
runs in polynomial time in the size of the linear programs.
Another important contribution of this paper is related to the question whether to
perform probabilistic deduction with conditional constraints by the iterative application of
inference rules or by linear programming. On the one hand, the idea of inference rules carries
us to very ecient techniques for globally complete probabilistic deduction in conditional
constraint trees. In particular, the considered deduction problems generalize patterns of
commonsense reasoning. However, on the other hand, the corresponding proofs of soundness
and global completeness are technically quite complex. Hence, it seems unlikely that the
results of this work can be extended to significantly more general probabilistic deduction
201

fiLukasiewicz

problems. Note that a companion paper (1998a, 1999a) reports similar limits of the local
approach in probabilistic deduction under taxonomic knowledge.
The rest of this paper is organized as follows. In Section 2, we formulate the probabilistic deduction problems considered in this work. Section 3 focuses on the probabilistic
satisfiability of conditional constraint trees. Section 4 deals with globally complete probabilistic deduction in exact and general conditional constraint trees. In Section 5, we give a
comparison with Bayesian networks. Section 6 summarizes the main results of this work.

2. Formulating the Probabilistic Deduction Problem

In this section, we introduce the syntactic and semantic notions related to probabilistic
knowledge in general and to conditional constraint trees in particular.

2.1 Probabilistic Knowledge

Before focusing on the details of conditional constraint trees, we give a general introduction
to the kind of probabilistic knowledge considered in this work. We deal with conditional
constraints over propositional events. They represent interval restrictions for conditional
probabilities of propositional events. Note that the formal background introduced in this
section is commonly accepted in the literature (see especially the work by Frisch and Haddawy, 1994, for other work in the same spirit).
We assume a nonempty and finite set of basic events B = fB1 ; B2 ; : : : ; Bn g. The set of
conjunctive events CB is the closure of B under the Boolean operation ^. We abbreviate the
conjunctive event C ^ D by CD . The set of propositional events GB is the closure of B under
the Boolean operations ^ and :. We abbreviate the propositional events G ^ H and :G
by GH and G, respectively. The false event B1 ^ :B1 and the true event :(B1 ^ :B1 ) are
abbreviated by ? and >, respectively. Conditional constraints are expressions of the form
(H jG)[u1 ; u2 ] with real numbers u1 ; u2 2 [0; 1] and propositional events G and H . In the
conditional constraint (H jG)[u1 ; u2 ], we call G the premise and H the conclusion.
To define probabilistic interpretations of propositional events and of conditional constraints, we introduce atomic events and the binary relation ) between atomic and propositional events. The set of atomic events AB is defined by AB = fE1 E2    En j Ei = Bi
or Ei = B i for all i 2 [1: n]g. Note that each atomic event can be interpreted as a possible
world (which corresponds to a mapping from B to ftrue; falseg). For all atomic events A
and all propositional events G, let A ) G iff AG is a propositional contradiction.
A probabilistic interpretation Pr is a mapping from AB to [0; 1] such that all Pr (A) with
A 2 AB sum up to 1. Pr is extended in a well-defined way to propositional events G by:
Pr (G) is the sum of all Pr (A) with A 2 AB and A ) G. Pr is extended to conditional
constraints by: Pr j= (H jG)[u1 ; u2 ] iff u1  Pr (G)  Pr (GH )  u2  Pr (G).
Note that conditional constraints characterize conditional probabilities of events, rather
than probabilities of conditional events (Coletti, 1994; Gilio & Scozzafava, 1994). Note also
that Pr (G) = 0 always entails Pr j= (H jG)[u1 ; u2 ]. This semantics of conditional probability
statements is also assumed by Halpern (1990) and by Frisch and Haddawy (1994).
The notions of models, satisfiability, and logical consequence for conditional constraints
are defined in the classical way. A probabilistic interpretation Pr is a model of a conditional
constraint (H jG)[u1 ; u2 ] iff Pr j= (H jG)[u1 ; u2 ]. Pr is a model of a set of conditional
202

fiProbabilistic Deduction with Conditional Constraints over Basic Events

constraints KB , denoted Pr j= KB , iff Pr is a model of all (H jG)[u1 ; u2 ] 2 KB . KB is
satisfiable iff a model of KB exists. (H jG)[u1 ; u2 ] is a logical consequence of KB; denoted
KB j= (H jG)[u1 ; u2 ], iff each model of KB is also a model of (H jG)[u1 ; u2 ].
For a conditional constraint (H jG)[u1 ; u2 ] and a set of conditional constraints KB , let
u denote the set of all real numbers u 2 [0; 1] for which there exists a model Pr of KB with
u  Pr (G) = Pr (GH ) and Pr (G) > 0. Now, we easily verify that (H jG)[u1 ; u2 ] is a logical
consequence of KB iff u1  inf u and u2  sup u.
This observation yields a canonical notion of tightness for logical consequences of conditional constraints. The conditional constraint (H jG)[u1 ; u2 ] is a tight logical consequence
of KB; denoted KB j=tight (H jG)[u1 ; u2 ], iff u1 = inf u and u2 = sup u.
The set u is a closed interval in the real line (Frisch & Haddawy, 1994). Note that for
u = ;, we canonically define inf u = max [0; 1] = 1 and sup u = min [0; 1] = 0. Thus, u = ;
iff KB j= (Gj>)[0; 0] iff KB j=tight (H jG)[1; 0] iff KB j= (H jG)[u1 ; u2 ] for all u1 ; u2 2 [0; 1].
Based on the just introduced notion of tight logical consequence, probabilistic deduction
problems and their solutions are more formally specified as follows.
A probabilistic knowledge base (B; KB ) consists of a set of basic events B and a set of
conditional constraints KB over GB with u1  u2 for all (H jG)[u1 ; u2 ] 2 KB . A probabilistic
query to a probabilistic knowledge base (B; KB ) is an expression of the form 9(F jE )[x1 ; x2 ]
with E; F 2 GB and two different variables x1 and x2 . Its tight answer is the substitution
 = fx1 =u1 ; x2 =u2 g with u1 ; u2 2 [0; 1] such that KB j=tight (F jE )[u1 ; u2 ] (we call 1 =
fx1 =u1 g the tight lower answer and 2 = fx2 =u2 g the tight upper answer). A correct answer
is a substitution  = fx1 =u1 ; x2 =u2 g with u1 ; u2 2 [0; 1] such that KB j= (F jE )[u1 ; u2 ].
Finally, we define the notions of soundness and of completeness related to inference
rules and to techniques for probabilistic deduction. An inference rule KB ` (H jG)[u1 ; u2 ] is
sound iff KB j= (H jG)[u1 ; u2 ], where (H jG)[u1 ; u2 ] is a conditional constraint and KB is a
set of conditional constraints. It is sound and locally complete iff KB j=tight (H jG)[u1 ; u2 ].
A technique for probabilistic deduction is sound for a set of probabilistic queries Q iff it computes a correct answer to any given query from Q. It is sound and globally complete for Q
iff it computes the tight answer to any given query from Q.

2.2 Computational Complexity

In the framework of conditional constraints over propositional events, the optimization problem of computing the tight answer to a probabilistic query is immediately NP-hard, since it
generalizes the satisfiability problem for classical propositional logic (the NP-complete problem of deciding whether a propositional formula in conjunctive normal form is satisfiable;
see especially the survey by Garey and Johnson, 1979).
Surprisingly, the optimization problem of computing the tight answer to a probabilistic
query remains NP-hard even if we just consider conditional constraints over basic events:

Theorem 2.1 The optimization problem of computing the tight answer to a probabilistic

query over basic events that is directed to a probabilistic knowledge base over basic events
is NP-hard.

Proof. The NP-complete decision problem of graph 3-colorability (Garey & Johnson, 1979)
can be polynomially-reduced to the optimization problem of computing the tight answer
203

fiLukasiewicz

to a probabilistic query over basic events that is directed to a probabilistic knowledge base
over basic events. The proof follows similar lines to the proof of NP-hardness of 2PSAT
given by Georgakopoulos et al. (1988).
Let (V; E ) be a finite undirected graph. We construct a probabilistic knowledge base
(B; KB ) as follows. We initialize (B; KB ) with (fB g; ;). For each node v 2 V , we increase
B by the new basic events Bv1, Bv2, and Bv3. For each node v 2 V and for each i 2 f1; 2; 3g,
we increase KB by (B jBvi )[1; 1] and (Bvi jB )[1=3; 1=3]. For each node v 2 V and for each
i; j 2 f1; 2; 3g with i < j , we increase KB by (Bvj jBvi )[0; 0]. For each edge fu; vg 2 E and for
each i 2 f1; 2; 3g, we increase KB by (Bvi jBui )[0; 0]. It is easy to see that the probabilistic
knowledge base (B; KB ) can be constructed in polynomial time in the size of (V; E ).
Now, we show that (V; E ) is 3-colorable iff fx1 =1; x2 =1g is the tight answer to the
probabilistic query 9(B jB )[x1 ; x2 ] to (B; KB ), or equivalently, iff KB is satisfiable:
If (V; E ) is 3-colorable, then there exists a mapping c1 from V to f1; 2; 3g with c1 (u) 6=
c1 (v) for all edges fu; vg 2 E . Thus, if  is a cyclic permutation of the members in f1; 2; 3g
and if c2 ; c3 : V ! f1; 2; 3g are defined by c2 (v) = (c1 (v)) and c3 (v) = (c2 (v)) for all
nodes v 2 V , then also c2 (u) 6= c2 (v) and c3 (u) 6= c3 (v) for all edges fu; vg 2 E . For
j 2 f1; 2; 3g, let Aj 2 AB such that Aj ) B and Aj ) Bvi iff cj (v) = i for all nodes v 2 V
and i 2 f1; 2; 3g. If Pr : AB ! [0; 1] is defined by Pr (A) = 1=3 for all A 2 fA1 ; A2 ; A3 g and
by Pr (A) = 0 for all A 2 AB n fA1 ; A2 ; A3 g, then Pr is a model of KB .
Conversely, if there is a model Pr of KB , then there is an atomic event A 2 AB with
Pr (A) > 0. Thus, if c : V ! f1; 2; 3g is defined by c(v) = i iff A ) Bvi for all nodes v 2 V ,
then c(u) 6= c(v) for all edges fu; vg 2 E . Hence, (V; E ) is 3-colorable. 2
Hence, it is unlikely that there is an ecient algorithm for computing the tight answer
to all probabilistic queries over basic events that are directed to any given probabilistic
knowledge base over basic events. However, there may still be ecient algorithms for
solving more specialized probabilistic deduction problems.
The rest of this work deals with probabilistic deduction in conditional constraint trees.
The next section provides a motivating example, which gives evidence of the practical
importance of this kind of probabilistic deduction problems.

2.3 Motivating Example
A senior student in mathematics describes her experience about being successful at the university as follows. The success of a student (su) is inuenced by how well-informed (wi) and
how well-prepared (wp) the student is. Well-informedness can be reached by interviewing
professors (pr) or by asking senior students (st). Being well-prepared is inuenced by how
much time is invested in books (bo), exercises (ex), and hobbies (ho).
It is estimated that the probability of a student being successful given she is wellinformed lies between 0.60 and 0.70, that the probability of a student being well-informed
given she is successful is greater than 0.85, that the probability of a student being successful
given she is well-prepared is greater than 0.95, and that the probability of a student being
well-prepared given she is successful is greater than 0.95.
This probabilistic knowledge completed by further probabilistic estimations is given by
the probabilistic knowledge base (B; KB ) in Fig. 1, where B is the set of nodes fsu; wi; wp; pr;
204

fiProbabilistic Deduction with Conditional Constraints over Basic Events

st; bo; ex; hog and KB is the least set of conditional constraints that contains (Y jX )[u1 ; u2 ]
for each arrow from X to Y labeled with u1 ; u2 .
st

ho
.6,.7

.95,1

.35,.4

.6,.7

wi

su
.85,1

.95,1

.35,.4

.95,1

.85,.9

wp
.95,1

.05,.1

.95,1

pr

ex
.85,.9
.95,1

bo

Figure 1: A Conditional Constraint Tree
We may wonder whether it is useful for being successful at the university to interview the
professors, to study on books, to spend the time on one's hobbies, or to do both studying
on books and spending the time on one's hobbies. This can be expressed by the probabilistic queries 9(sujpr)[x1 ; x2 ], 9(sujbo)[x1 ; x2 ], 9(sujho)[x1 ; x2 ], and 9(sujbo ho)[x1 ; x2 ],
which yield the tight answers fx1 =0:00, x2 =1:00g, fx1 =0:90; x2 =1:00g, fx1 =0:30; x2 =0:46g,
and fx1 =0:71; x2 =1:00g, respectively.
We may wonder whether successful students at the university interviewed their professors, whether they studied on books, whether they spent their time with their hobbies, or
whether they both studied on books and spent their time with their hobbies. This can be
expressed by the probabilistic queries 9(prjsu)[x1 ; x2 ], 9(bojsu)[x1 ; x2 ], 9(hojsu)[x1 ; x2 ], and
9(bo hojsu)[x1 ; x2 ], which yield the tight answers fx1=0:00, x2=0:17g, fx1=0:90; x2 =1:00g,
fx1 =0:30; x2 =0:45g, and fx1=0:25; x2 =0:45g, respectively.

2.4 Conditional Constraint Trees

We formally define conditional constraint trees and queries to conditional constraint trees.
We provide some additional examples, which are subsequently used as running examples.
A (general) conditional constraint tree is a probabilistic knowledge base (B; KB ) for
which an undirected tree (a singly connected undirected graph) (B; $) exists such that
KB contains exactly one pair of conditional constraints (B jA)[u1 ; u2 ] and (AjB )[v1 ; v2 ] with
u1 ; v1 > 0 for each pair of adjacent nodes A and B (note that B = fB g implies KB = ;).
A basic event B 2 B is called a leaf in (B; KB ) iff it has exactly one neighbor in (B; $).
A conditional constraint tree is exact iff u1 = u2 for all (B jA)[u1 ; u2 ] 2 KB .
A query to a conditional constraint tree is a probabilistic query 9(F jE )[x1 ; x2 ] with two
conjunctive events E and F that are disjoint in their basic events and such that all paths
from a basic event in E to a basic event in F have at least one basic event in common.
A query 9(F jE )[x1 ; x2 ] to a conditional constraint tree is premise-restricted iff E is a basic
event. It is conclusion-restricted iff F is a basic event. It is strongly conclusion-restricted
iff F is the only basic event that is contained in all paths from a basic event in E to F .
It is complete iff EF contains exactly the leaves of (B; $).
205

fiLukasiewicz

Fig. 2 shows two conditional constraint trees of which the one on the left side is exact.

9(STUjMNQR)[x1 ; x2] is a query, while 9(MSjQU)[x1 ; x2 ] is not a query to the conditional
constraint trees of Fig. 2. Furthermore, 9(STUjM)[x1 ; x2 ] is a premise-restricted query,
9(OjQRSTU)[x1 ; x2] a strongly conclusion-restricted query, and 9(QRSTUjM)[x1 ; x2 ] a prem-

ise-restricted complete query to the conditional constraint trees of Fig. 2.
1)

2)

T
.85

.85

P
1

.85

M

N
.85

.3,.4

M

Q

.9,1

.5,.6

N
.8,.9

.95
.95

.15

1

.8,.9

O

U

.8,.9

.95

1

.8,.9

P

.95

.55

.9,1

.9,1

S

U

.85
.35

.8,.9

.95

.95

S

T

.9,1

O
1
.1,.2

R

Q
.9,1
.9,1

R

Figure 2: Two Conditional Constraint Trees
For conditional constraint trees (B; KB ), conjunctive events C , and basic events B , we
write C ) B iff there exists a path G1 ; G2 ; : : : ; Gk from a basic event G1 in C to the basic
event Gk = B such that (Gi+1 jGi )[1; 1] 2 KB for all i 2 [1 : k , 1]. We write B ) C iff for
all paths G1; G2 ; : : : ; Gk from the basic event G1 = B to a basic event Gk in C , it holds
(Gi+1 jGi )[1; 1] 2 KB for all i 2 [1 : k , 1]. That is, the conditions C ) B and B ) C
immediately entail KB j= (B jC )[1; 1] and KB j= (C jB )[1; 1], respectively.
Note that the restriction u1 ; v1 > 0 for all (B jA)[u1 ; u2 ], (AjB )[v1 ; v2 ] 2 KB is just made
for technical convenience. The deduction technique of Section 4 can easily be generalized
to conditional constraint trees (B; KB ) that satisfy only the restriction u1 > 0 iff v1 > 0 for
all (B jA)[u1 ; u2 ]; (AjB )[v1 ; v2 ] 2 KB (Lukasiewicz, 1996).
The restriction that for each query 9(F jE )[x1 ; x2 ], all paths from a basic event in E
to a basic event in F have at least one basic event in common is crucial for the deduction
technique of Section 4. It assures that the problem of computing the tight answer to a
complete query can be reduced to the problems of computing the tight answer to a premiserestricted complete query and the tight answer to a strongly conclusion-restricted complete
query. Note that this restriction is trivially satisfied by all premise- and conclusion-restricted
queries (for example, by all the queries in Section 2.3).
Especially tight answers to conclusion-restricted queries seem to be quite important in
practice. They may be used to characterize the probability of uncertain basic events given
a collection of basic events that are known with certainty.
206

fiProbabilistic Deduction with Conditional Constraints over Basic Events

3. Probabilistic Satisfiability

In this section, we show that conditional constraint trees have the nice property that they
are always satisfiable. That is, within conditional constraint trees, the user is prevented
from specifying inconsistent probabilistic knowledge.
First, note that conditional constraint trees always have a trivial model in which the
probability of the conjunction of all negated basic events is one and in which the probability
of all the other atomic events is zero.
The next lemma shows that, given a model Pr of a conditional constraint tree and a
real number s from [0; 1], we can construct a new model Pr s by setting Pr s (A) = s  Pr (A)
for all atomic events A that are different from the conjunction of all negated basic events.
Note that Pr 0 coincides with the trivial model and that Pr 1 is identical to Pr . This lemma
is crucial for inductively constructing models of conditional constraint trees.

Lemma 3.1 Let (B; KB ) be a conditional constraint tree with B = fB1 ; B2 ; : : : ; Bng. Let
Pr be a model of KB and let s be a real number from [0; 1].
The mapping Prs : AB ! [0; 1] with Prs (A) = s  Pr (A) for all A 2 AB n fB 1 B 2    B n g
and Prs (B 1 B 2    B n ) = s  Pr (B 1 B 2    B n ) , s + 1 is a model of KB.
Proof. We easily verify that Prs is a probabilistic interpretation. It remains to show that
Prs is also a model of KB . Let (H jG)[u1 ; u2 ] 2 KB . Since Pr is a model of KB , we have
Pr j= (H jG)[u1 ; u2 ], hence u1  Pr (G)  Pr (GH )  u2  Pr (G), and thus also u1 s  Pr (G) 
s  Pr (GH )  u2 s  Pr (G). Since neither B 1 B2    B n ) G nor B 1 B 2    B n ) GH , we get
u1  Prs (G)  Prs (GH )  u2  Prs (G) and thus Prs j= (H jG)[u1 ; u2 ]. 2

Finally, the following theorem shows that conditional constraint trees always have a
nontrivial model in which all the basic events have a probability greater than zero.

Theorem 3.2 Let (B; KB ) be a conditional constraint tree with B = fB1 ; B2 ; : : : ; Bn g.
There is a model Pr of KB with Pr (B1 B2    Bn ) > 0.
Proof. It is sucient to show the claim for exact conditional constraint trees. The claim

is proved by induction on the number of basic events.
Basis: for (B; KB ) = (fB g; ;), a model Pr of KB with Pr (B ) > 0 is given by B; B 7! 0; 1
(note that B; B 7! 0; 1 is an abbreviation for Pr (B ) = 0 and Pr (B ) = 1).
Induction: let (B; KB ) = (B1 [ B2 ; KB 1 [ KB 2 ) with two exact conditional constraint trees
(B1 ; KB 1 ) = (fB; C g; f(C jB )[u; u]; (B jC )[v; v]g) and (B2 ; KB 2 ) = (fC; D1 ; : : : ; Dk g; KB 2 )
such that B1 \ B2 = fC g. A model Pr 1 of KB 1 with Pr 1 (BC ) > 0 is given by:

B C; BC; BC; BC 7!

uv v,uv u,uv uv
u+v ; u+v ; u+v ; u+v

:

By the induction hypothesis, there is a model Pr 2 of KB 2 (that is defined on the atomic
events over B2 ) with Pr 2 (CD1    Dk ) > 0. By Lemma 3.1, we can assume Pr 2 (C ) = Pr 1 (C ).
A probabilistic interpretation Pr on the atomic events over B is now defined by:
Ac )Pr 2 (Ac A2 )
Pr (Ab Ac A2 ) = Pr 1 (AbPr
2 (Ac )

207

fiLukasiewicz

for all atomic events Ab , Ac , and A2 over fB g, fC g, and B2 n fC g, respectively. We easily
verify that Pr (Ab Ac ) = Pr 1 (Ab Ac ) and Pr (Ac A2 ) = Pr 2 (Ac A2 ) for all atomic events
Ab , Ac , and A2 over fB g, fC g, and B2 n fC g, respectively. Hence, Pr is a model of KB .
Moreover, Pr 1 (BC ) > 0 and Pr 2 (CD1    Dk ) > 0 entails Pr (BCD1    Dk ) > 0. 2

4. Probabilistic Deduction

In this section, we present techniques for computing tight answers to queries directed to
exact and general conditional constraint trees, and we analyze their computational complexity. More precisely, the problem of computing the tight answer to a query is reduced to
the problem of computing the tight answer to a complete query. The latter problem is then
reduced to the problems of computing the tight answer to a premise-restricted complete
query and the tight answer to a strongly conclusion-restricted complete query.

4.1 Premise-Restricted Complete Queries
4.1.1 Exact Conditional Constraint Trees

We now focus on the problem of computing tight answers to premise-restricted complete
queries that are directed to exact conditional constraint trees.
Let (B; KB ) be an exact conditional constraint tree and let 9(F jE )[x1 ; x2 ] be a premiserestricted complete query. To compute the tight answer to 9(F jE )[x1 ; x2 ], we start by
defining a directed tree (that is, a directed acyclic graph in which each node has exactly
one parent, except for the root, which does not have any):

A ! B iff A $ B and A is closer to E than B .
This directed tree (B; !) is uniquely determined by the conditional constraint tree and the
premise-restricted complete query. Fig. 3 shows (B; !) for the premise-restricted complete
query 9(QRSTUjM)[x1 ; x2 ] to the exact conditional constraint tree in Fig. 2, left side.

Now, the set of nodes B is partitioned into several strata. The lowest stratum contains
only nodes with no children in (B; !), the highest stratum contains the nodes with no
parents in (B; !) (that is, exactly the node of the premise E of the query). Fig. 3 also
shows the different strata in our example.
At each node of (B; !), we compute certain tightest bounds that are logically entailed
by KB . More precisely, the tightest bounds at a node B are computed locally, by exploiting
the tightest bounds that have previously been computed at the children of B . Hence, we
iteratively compute the tightest bounds at the nodes of each stratum, starting with the
nodes of the lowest stratum and terminating with the nodes of the highest stratum. We
distinguish three different ways of computing tightest bounds at a node:
 initialization of a leaf (Leaf),
 chaining of an arrow and a subtree via a common node (Chaining),
 fusion of subtrees via a common node (Fusion).
Let us consider again the premise-restricted complete query 9(QRSTUjM)[x1 ; x2 ] to the
exact conditional constraint tree in Fig. 2, left side. Fig. 4 illustrates the three different ways
208

fiProbabilistic Deduction with Conditional Constraints over Basic Events

S
P
T
O
M

N

U

Q

R
3

4

1

2

0

strata

Figure 3: Directed Tree (B; !)
of computing tightest bounds at a node (the common nodes for Chaining and Fusion are
filled black). Table 1 shows the greatest lower and the least upper bounds that are computed
at each node B of each stratum. More precisely, these bounds are ff1 = inf Pr (BD )=Pr (B ),
ff2 = sup Pr (BD )=Pr (B ), fi2 = sup Pr (BD )=Pr (B ), and 2 = sup Pr (D )=Pr (B ) subject to
Pr j= KB and Pr (B ) > 0. Table 1 also shows the requested tight answer fx1 =0:02; x2 =0:17g,
which is given by the tightest bounds ff1 and ff2 that are computed at the premise M.
strata B
S
0 T
U
P
1 P
P
P
1 Q
R
O
2 O
O
2 O
3 N
4 M

D

S
T
U
S
T
U
STU
Q
R
STU
Q
R
QRSTU
QRSTU
QRSTU

ff1

1:0000
1:0000
1:0000
0:8500
0:8500
0:8500
0:5500
1:0000
1:0000
0:4474
0:9500
0:9500
0:3474
0:1911
0:0169

ff2

1:0000
1:0000
1:0000
0:8500
0:8500
0:8500
0:8500
1:0000
1:0000
0:7605
0:9500
0:9500
0:7605
0:4183
0:1722

fi2

0:0000
0:0000
0:0000
0:0447
0:0447
0:0000
0:0000
0:0000
0:0000
0:0447
0:0500
5:3833
0:0447
0:0246
0:0719

2

1:0000
1:0000
1:0000
0:8947
0:8947
0:8500
0:8500
1:0000
1:0000
0:7605
1:0000
6:3333
0:7605
0:4183
0:1722

(Leaf)
(Leaf)
(Leaf)
(Chaining)
(Chaining)
(Chaining)
(Fusion)
(Leaf)
(Leaf)
(Chaining)
(Chaining)
(Chaining)
(Fusion)
(Chaining)
(Chaining)

Table 1: Locally Computed Tightest Bounds
209

fiLukasiewicz

S

Initialization of a leaf:
P

T
O
M

Q

N

U

R

S

Chaining of an arrow and a subtree:
P

T
O
M

Q

N

U

R

S

Fusion of subtrees:
P

T
O
M

N

Q

R

Figure 4: Local Computations in (B; !)
210

U

fiProbabilistic Deduction with Conditional Constraints over Basic Events

We now focus on the technical details. We present the functions H1ff , H2ff , H2fi , and H2 ,
which compute the described greatest lower and least upper bounds. For this purpose, we
need the following definitions. Let Pr (C jB ) denote u for all (C jB )[u; u] 2 KB .
A node B is a leaf if it does not have any children. For all leaves B , let B " = B . For all
the other nodes B , let B " be the conjunction of all the children of B . For all leaves C , let
L(C ) = C . For all the other conjunctive events C , let L(C ) be the conjunction of all the
leaves that are in C or that are descendants of a node in C .
In the sequel, let B be a node and let C = B " . The case C = B refers to the initialization
of the leaf B , the case C = B1 with a node B1 6= B to the chaining of the arrow B ! B1
and a subtree via the common node B1 , and the case C = B1 B2 : : : Bk with k > 1 nodes
B1; B2 ; : : : ; Bk to the fusion of k subtrees via the common node B .
We define the function H1ff for computing greatest lower bounds: let H1ff (B; C ) = ff1
(note that ff1 will coincide with the greatest lower bound of Pr (BL(C )) = Pr (B ) subject to
Pr j= KB and Pr (B ) > 0), where ff1 in Leaf (C = B ), Chaining (C = B1 ), and Fusion
(C = B1 B2 : : : Bk with k > 1) is given as follows:
Leaf

:

ff1 = 1
:
ff
"
ff1 = max(0; Pr (C jB )  (1 + H1Pr(C;(BCjC)),1 ))

Chaining

Fusion

:

ff1 = max(0; 1 , k + P H1ff (B; Bi))
k

i=1

To express that H1ff computes greatest lower bounds, we need the following definitions.
Let B(B; C ) comprise B , all nodes in C and all descendants of a node in C . Let KB (B; C )
be the set of all conditional constraints of KB over B(B; C ). Let Mo (B; C ) be the set of all
models of KB (B; C ) that are defined on the atomic events over B(B; C ).
Now, the function H1ff is sound and globally complete with respect to B and C iff
ff
H1 (B; C ) = ff1 is the greatest lower bound of Pr (BL(C )) = Pr (B ) subject to Pr 2 Mo (B; C )
and Pr (B ) > 0. Thus, the next theorem shows soundness and global completeness of H1ff .

Theorem 4.1

a) For all probabilistic interpretations Pr 2 Mo (B; C ), it holds ff1  Pr (B )  Pr (BL(C )).
b) There exists a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0, ff1  Pr (B ) =
Pr (BL(C )), and Pr (BL(C )) = 0 iff L(C ) ) B .

Proof. The proof is given in full detail in Appendix B. 2

Next, we present the functions H2ff , H2fi , and H2 for computing least upper bounds. Note
that H2ff , H2fi , and H2 show the crucial result that for exact conditional constraint trees,
there are local probabilistic deduction techniques that are sound and globally complete.
211

fiLukasiewicz

In detail, let H2ff (B; C ) = ff2 , H2fi (B; C ) = fi2 , and H2 (B; C ) = 2 (note that ff2 , fi2 ,
and 2 will coincide with the least upper bound of Pr (BL(C )) = Pr (B ), Pr (BL(C )) = Pr (B ),
and Pr (L(C )) = Pr (B ), respectively, subject to Pr j= KB and Pr (B ) > 0), where ff2 , fi2 ,
and 2 in Leaf (C = B ), Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1)
are given as follows:
Leaf

:

ff2 = 1
fi2 = 0
2 = 1
:

"
ff
"
ff2 = min(1; Pr (C jB )  HPr2 ((C;BjCC )) ; 1 , Pr (C jB )  (1 , HPr2 ((C;BjCC ) ) );

Chaining

fi

Pr (C jB )  (1 + HPr2 ((C;BjCC ) ) ))
fi

"



H2 (C; C )
fi2 = min(Pr (C jB )  ( H2Pr(C;(BCjC)+1
) , 1); Pr (C jB )  Pr (B jC ) )


"

"

2 = Pr (C jB )  HPr2 ((C;BjCC ))
Fusion

"

:

ff2 = i2min
H ff (B; Bi )
[1:k] 2
fi2 = i2min
H fi (B; Bi )
[1:k] 2

2 = min(i2min
H2 (B; Bi ); min (H2ff (B; Bi ) + H2fi (B; Bj )))
[1:k]
i;j 2[1:k];i6=j
The functions H2ff , H2fi , and H2 are sound and globally complete with respect to B
and C iff H2ff (B; C ) = ff2 , H2fi (B; C ) = fi2 , and H2 (B; C ) = 2 are the least upper bounds
of Pr (BL(C )) = Pr (B ), Pr (BL(C )) = Pr (B ), and Pr (L(C )) = Pr (B ), respectively, subject
to Pr 2 Mo (B; C ) and Pr (B ) > 0. Hence, the following theorem shows soundness and
global completeness of H2ff , H2fi , and H2 (actually, it shows even more to enable a proof by
induction on the recursive definition of H2ff , H2fi , and H2 ).

Theorem 4.2

a) For all probabilistic interpretations Pr 2 Mo (B; C ), it holds Pr (BL(C ))  ff2  Pr (B ),
Pr (BL(C ))  fi2  Pr (B ), and Pr (L(C ))  2  Pr (B ).
b) There exists a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0, Pr (BL(C )) =
ff2  Pr (B ), and Pr (L(C )) = 2  Pr (B ).
c) There exists a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0, Pr (BL(C )) =
fi2  Pr (B ), and Pr (L(C )) = 2  Pr (B ).
212

fiProbabilistic Deduction with Conditional Constraints over Basic Events

Proof. The proof is given in full detail in Appendix B. 2
Note that Theorem 4.2 also shows that H2 (B; Bi )  H2ff (B; Bi ) + H2fi (B; Bi ) for all
i 2 [1: k]. Thus, the expression mini;j 2[1:k];i6=j (H2ff (B; Bi ) + H2fi (B; Bj )) in the definition of

2 in Fusion can be replaced by ff2 + fi2 for an increased eciency in computing 2 by
exploiting the already computed values of ff2 and fi2 .
Briey, by Theorems 4.1 and 4.2, the tight answer to the premise-restricted complete
query 9(F jE )[x1 ; x2 ] is given by fx1 =H1ff (E; E " ); x2 =H2ff (E; E " )g.
4.1.2 Conditional Constraint Trees

We now focus on computing the tight answer to premise-restricted complete queries to
general conditional constraint trees. In the sequel, let (B; KB ) be a conditional constraint
tree and let 9(F jE )[x1 ; x2 ] be a premise-restricted complete query.
We may think that the local deduction technique for exact conditional constraint trees
of Section 4.1.1 can easily be generalized to conditional constraint trees. In fact, this is true
as far as the computation of greatest lower bounds is concerned. However, the computation
of least upper bounds cannot be generalized that easily from exact conditional constraint
trees to conditional constraint trees. More precisely, generalizing the computation of least
upper bounds results in solving nonlinear programs. These nonlinear programs and our way
to solve them are illustrated by the following chaining example.
Let the conditional constraint tree (B; KB ) be given by B = fM; N; O; Pg and KB =
f(NjM)[u1 ; u2 ]; (MjN)[v1 ; v2 ], (OjN)[x1 ; x2 ], (NjO)[y1 ; y2 ], (PjO)[r1 ; r2], (OjP)[s1 ; s2]g. Let us
consider the premise-restricted complete query 9(PjM)[z1 ; z2 ].
By Theorem 4.2 and some straightforward arithmetic transformations, the requested
least upper bound is the maximum of z subject to u 2 [u1 ; u2 ], v 2 [v1 ; v2 ], x 2 [x1 ; x2 ],
y 2 [y1; y2 ], r 2 [r1 ; r2 ], s 2 [s1 ; s2 ], and the nonlinear inequalities in (1) to (5):
(1)
z 1
(2)
z  1 , u + uv , uxv + uxr
vy
uxr
ux
(3)
z  1 , u + v , vy + uxr
vys
uxr + uxr
z  u , uxv + ux
(4)
,
vy
vy
vys
uxr
(5)
z  vys
In this system of nonlinear inequalities, all upper bounds of z are monotonically decreasing
in v, y, and s. Hence, we can equivalently maximize z subject to u 2 [u1 ; u2 ], x 2 [x1 ; x2 ],
r 2 [r1 ; r2 ], and the nonlinear inequalities in (6) to (10):
(6)
z 1
uxr
z  1 , u + vu1 , ux
(7)
v1 + v1 y1
uxr
uxr
(8)
z  1 , u + ux
v1 , v1 y1 + v1 y1 s1
ux
uxr
uxr
(9)
z  u , ux
v1 + v1 y1 , v1 y1 + v1 y1 s1
z  v1uxr
(10)
y1 s1
For example, the requested least upper bound for u1 = u2 = u and x1 = x2 = x is shown in
Fig. 5 for u; x 2 [0; 1], r1 = r2 = 0:15, v1 = 0:8, y1 = 0:8, and s1 2 f0:05; 0:1g. The requested
least upper bound for u1 < u2 or x1 < x2 is the maximum value over [u1 ; u2 ]  [x1 ; x2 ].
213

fiLukasiewicz

s1=0.05

z2
0.99
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

1
0.9
0.8
0.7
0.6
0.1

0.2

0.5
0.3

0.4
0.4

0.5

x

0.3
0.6

u

0.7

0.2
0.8

0.9

0.1
1

s1=0.1

z2
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1

0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
0.9
0.8
0.7
0.6
0.1

0.2

0.5
0.3

0.4
0.4
u

0.5

0.3
0.6

0.7

x

0.2
0.8

0.9

0.1
1

Figure 5: Least Upper Bound z2 in the Chaining Example
214

fiProbabilistic Deduction with Conditional Constraints over Basic Events

We now transform this nonlinear program into an equivalent linear program (by replacing 1, u, ux, and uxr by the new variables xM, xN , xO , and xP , respectively). More
precisely, the maximum of z subject to u 2 [u1 ; u2 ], x 2 [x1 ; x2 ], r 2 [r1 ; r2 ], and the nonlinear inequalities in (6) to (10) coincides with the maximum of z subject to the following
system of linear inequalities over z and xB  0 (B 2 B):

z
z
z
z
z







xM
xM + 1,v1v1  xN , vy1 1y1  xO + v1 ys11 s1  xP
xM , vv11  xN + vy1 1y1  xO + v11,y1ss11  xP
v1  x + 1,y1  x + 1,s1  x
v1 N
v1 y1 O
v1 y1 s1 P
1
v1 y1 s1  xP

1
u1  xM
x1  xN
r1  xO






xM
xN
xO
xP






1

u2  xM
x2  xN
r2  xO

More generally, tight upper answers to premise-restricted complete queries to conditional
constraint trees can be computed by solving similar nonlinear programs, which can similarly
be transformed into linear programs.
For example, let us consider the premise-restricted complete query 9(QRSTUjM)[x1 ; x2 ]
to the conditional constraint tree in Fig. 2, right side. The requested least upper bound
is the maximum of x subject to the system of linear inequalities in Fig. 6 (we actually
generated 72 linear inequalities of which 31 were trivially subsumed by others). Note that
the nine variables xM to xU correspond to the nine nodes M to U.

x
x
x
x
x
x
x
x
x
x
x
x














xM
25 x
18 Q
25 xR
2
25 x
18 S
25 x
18 T
25 x
18 U
xN + 19 xP
xN + 19 xQ
xN + 19 xR
5x + 5 x
4 O 36 P
5x + 5 x
4 O 36 Q
5 x + 45 x
4 O 4 R

x
x
x
x
x
x
x
x
x
x
x













5
5
4 xP + 36 xQ
5
5
36 xP + 4 xQ
5
5
36 xP + 4 xR
5
5
36 xQ + 4 xR
xM , xN + 45 xO + 365 xR
xM + 14 xN , 45 xO + 54 xP
xM + 14 xN , 45 xO + 54 xQ
xM + 14 xN , 45 xO + 54 xR
xM + 14 xN , 45 xP + 25
18 xS
1
5
xM + 4 xN , 4 xP + 25
18 xT
xM + 14 xN , 45 xP + 25
18 xU

1
3
10 xM
1x
2 N
9
10 xO
9
10 xO
4
5 xO
4
5 xP
4
5 xP
4
5 xP











xM
xN
xO
xR
xQ
xP
xS
xT
xU











1

2x
5 M
3x
5 N

xO
xO
9
10 xO
9
10 xP
9
10 xP
9
10 xP

Figure 6: Generated Linear Inequalities in the Chaining Example
Thus, in this example, the tight upper answer is computed by solving a linear program
that has 10 variables and 72 linear inequalities. Note that computing the tight upper answer
by the classical linear programming approach would result in solving a linear program that
has 29 = 512 variables and 4  9 , 2 = 34 linear inequalities (see Section 4.6).
215

fiLukasiewicz

Let us now focus on the technical details. We subsequently generalize the function H1ff
of Section 4.1.1 in a straightforward way to compute greatest lower bounds in conditional
constraint trees. Moreover, we present a linear program for computing the requested least
upper bound in conditional constraint trees.
Let Pr 1 (C jB ) denote u1 for all (C jB )[u1 ; u2 ] 2 KB . In the sequel, let B be a node and
let C = B " . Again, the cases C = B , C = B1 with a node B1 6= B , and C = B1 B2 : : : Bk
with k > 1 nodes B1 ; B2 ; : : : ; Bk refer to Leaf, Chaining, and Fusion, respectively.
We define the generalized function H1ff for computing greatest lower bounds in conditional constraint trees: let H1ff (B; C ) = ff1 (note that ff1 will coincide with the greatest
lower bound of Pr (BL(C )) = Pr (B ) subject to Pr j= KB and Pr (B ) > 0), where ff1 in Leaf
(C = B ), Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1) is given by:
Leaf

:

ff1 = 1
:
ff
"
ff1 = max(0; Pr 1 (C jB )  (1 + H1Pr(C;1 (BCjC),) 1 ))

Chaining

Fusion

:

ff1 = max(0; 1 , k + P H1ff (B; Bi))
k

i=1

H1ff is sound and globally complete with respect to B and C iff H1ff (B; C ) = ff1 is the
greatest lower bound of Pr (BL(C )) = Pr (B ) subject to Pr 2 Mo (B; C ) and Pr (B ) > 0.
Thus, the next theorem shows soundness and global completeness of H1ff .

Theorem 4.3

a) For all probabilistic interpretations Pr 2 Mo (B; C ), it holds ff1  Pr (B )  Pr (BL(C )).
b) There exists a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0, ff1  Pr (B ) =
Pr (BL(C )), and Pr (BL(C )) = 0 iff L(C ) ) B .

Proof. The claims follow from Theorem 4.1. 2

Next, we focus on the requested least upper bound, which is computed by solving a
linear program as described in the two examples.
We start by defining the functions I ff , I fi , and I  over the variables xB (B 2 B). Let
I ff (B; C ) = ff2 , I fi (B; C ) = fi2 , and I  (B; C ) = 2 , where ff2 , fi2 , and 2 in Leaf (C = B ),
Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1) are given as follows:
Leaf

:

ff2 = xB
fi2 = 0
2 = xB
216

fiProbabilistic Deduction with Conditional Constraints over Basic Events

:
I  (C; C " ) ; x + I fi (C; C " ) ; x , x + I ff (C; C " ) )
ff2 = min(xB ; Pr
C Pr 1 (BjC ) B
C Pr 1 (BjC )
1 (B jC )

Chaining

I (C; C ) ;
fi2 = min( 1,PrPr1 (1B(BjCjC) )  xC + Pr
1 (B jC )
fi

2 =
Fusion

I  (C; C " )
Pr 1 (BjC )

"

I  (C; C " )
Pr 1 (BjC ) )

:

ff2 = i2min
I ff(B; Bi )
[1:k]
fi2 = i2min
I fi (B; Bi )
[1:k]

2 = min(i2min
I  (B; Bi ); i;j 2min
(I ff (B; Bi ) + I fi (B; Bj )))
[1:k]
[1:k];i6=j
The system of linear inequalities J (B; C ) is defined as the least set of linear inequalities
over xG  0 (G 2 B(B; C )) that contains 1  xB  1 and u1  xG  xH  u2  xG for all
(H jG)[u1 ; u2 ] 2 KB (B; C ) with G ! H (that is, G is the parent of H ).

The intuition behind these definitions can now be described as follows.
Each xG (G 2 B(B; C )) that satisfies J (B; C ) corresponds to the exact conditional constraint tree (B(B; C ); KB 0 (B; C )), where KB 0 (B; C ) contains the pair (H jG)[xH =xG ; xH =xG ]
and (GjH )[v1 ; v1 ] for each pair (H jG)[u1 ; u2 ]; (GjH )[v1 ; v2 ] 2 KB (B; C ) with G ! H .
We will show that the least upper bound of Pr (BL(C ))=Pr (B ), Pr (BL(C ))=Pr (B ),
and Pr (L(C ))=Pr (B ) subject to Pr j= KB 0 (B; C ) and Pr (B ) > 0 is given by I ff (B; C ),
I fi (B; C ), and I  (B; C ), respectively. It will then follow that the least upper bound of
Pr (BL(C ))=Pr (B ), Pr (BL(C ))=Pr (B ), and Pr (L(C ))=Pr (B ) subject to Pr j= KB (B; C )
and Pr (B ) > 0 is given by the maximum of I ff (B; C ), I fi (B; C ), and I  (B; C ), respectively,
subject to all xG (G 2 B(B; C )) satisfying J (B; C ).
That is, we implicitly performed the variable transformation described in the two examples. This transformation is indeed correct for conditional constraint trees:

Lemma 4.4
a) If xG (G 2 B(B; C )) satisfies J (B; C ), then for all conditional constraints (H jG)[u1 ; u2 ] 2
KB (B; C ) such that G ! H , there exists uH 2 [u1 ; u2 ] with xH = uH  xG .
b) Let uH 2 [u1 ; u2 ] for all (H jG)[u1 ; u2 ] 2 KB (B; C ) such that G ! H . There exists xG
(G 2 B(B; C )) with J (B; C ) and xH = uH  xG for all nodes H with parent G.
Proof. a) For all nodes H with parent G, let uH be defined by uH = xH = xG .
b) Let xB = 1, and for all nodes H with parent G, let xH be defined by xH = uH  xG . 2

We are now ready to formulate an optimization problem for computing the requested
least upper bound.
Theorem 4.5 Let X2 be the maximum of x subject to x  I ff(E; E " ) and J (E; E " ).
a) Pr (EL(E " ))  X2  Pr (E ) for all Pr 2 Mo (E; E " ).
b) There exists Pr 2 Mo (E; E " ) with Pr (E ) > 0 and Pr (EL(E " )) = X2  Pr (E ).
217

fiLukasiewicz

Proof. Let Pr (B jC ) = v1 for all (B jC )[v1 ; v2 ] 2 KB such that B ! C . By Theorem 4.2,
the requested least upper bound is the maximum of x subject to x  H2ff(E; E " ) and
Pr (C jB ) = uC 2 [u1 ; u2 ] for all (C jB )[u1 ; u2 ] 2 KB such that B ! C . By Lemma 4.4, we
can equivalently maximize x subject to x  I ff (E; E " ) and J (E; E " ). 2
We now wonder how to solve the generated optimization problem, since I ff (E; E " ) may
still contain min-operations that cannot be tackled by linear programming. Moreover, given
a method for solving this optimization problem, we are also interested in a rough idea on
the overall time complexity of computing the requested least upper bound this way. Finally,
we are interested in possible improvements to increase eciency. These topics are discussed
in the rest of this section.
If I ff (E; E " ) does not contain any min-operations at all, then the generated optimization
problem is already a linear program. Otherwise, it can easily be transformed into a linear
program. In a first transformation step, all inner min-operations are eliminated. This can
easily be done due to the well-structuredness of I ff (E; E " ). In a second step, the only
remaining outer min-operation is eliminated by introducing exactly one linear inequality
for each contained operand. In these linear inequalities, the operands of the outer minoperation are upper bounds of x.
To get a rough idea on the time complexity of computing the requested least upper
bound this way, we must analyze the size of the generated linear programs. It is given
by the number of variables, the number of linear inequalities in J (E; E " ), and the number of linear inequalities extracted from x  I ff (E; E " ). The latter is quite worrying,
since I  (B; C ) in Fusion seems to produce many min-operands. Moreover, I  (B; C ) in
ff
ff

"
Fusion contains I (B; Bi ), and I (B; C ) in Chaining contains I (C; C ). So, due to
this crossed dependency, the overall number of generated linear inequalities is likely to
`explode' for trees that branch very often.
To avoid these problems, we introduce the auxiliary functions J ff , J fi , and J  over the
variables xB (B 2 B). Let J ff (B; C ) = ff02 , J fi (B; C ) = fi20 , and J  (B; C ) = 20 , where ff02 , fi20 ,
and 20 in Leaf (C = B ), Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1)
are given as follows:
Leaf

:

ff02 = xB
fi20 = 0
20 = xB
Chaining

:
fi

ff

ff02 = min(xB ; xC + JPr(1C;(BCjC )) ; xB , xC + JPr (1C;(BCjC )) )
"

fi
"
fi20 = 1,PrPr1 (1B(BjCjC) )  xC + JPr(1C;(BCjC ))

20 =

J  (C; C " )
Pr 1 (BjC )

218

"

fiProbabilistic Deduction with Conditional Constraints over Basic Events

Fusion

:

ff02 = i2min
J ff(B; Bi )
[1:k]
fi20 = i2min
J fi (B; Bi )
[1:k]

20 = min(i2min
J  (B; Bi ); i;j 2min
(J ff (B; Bi ) + J fi (B; Bj )))
[1:k]
[1:k];i6=j
Note that ff02 in Chaining can be separated into the cases C " = C and C " 6= C . Since
simply ff02 = xC for C " = C , we reduce the number of generated linear inequalities this way.
The next lemma shows that the functions I ff , I fi , and I  can be expressed in terms of
the auxiliary functions J ff , J fi , and J  .

Lemma 4.6 For all xB (B 2 B) that satisfy J (E; E " ):
ff2 = min(ff02 ; 20 ), fi2 = min(fi20 ; 20 ), and 2 = 20 :

Proof sketch. The claim can be proved by induction on the recursive definition of the

functions I ff , I fi , and I  . 2
Briey, by Theorem 4.3, Theorem 4.5, and Lemma 4.6, the tight answer to the premiserestricted complete query 9(F jE )[x1 ; x2 ] is given by fx1 =H1ff (E; E " ); x2 =X2 g, where X2 is
the maximum of x subject to x  J ff (E; E " ), x  J  (E; E " ), and J (E; E " ).
In our example, we get fx1 =0:00; x2 =0:27g as the tight answer to the premise-restricted
complete query 9(QRSTUjM)[x1 ; x2 ] to the conditional constraint tree in Fig. 2, right side.
The time complexity of computing the requested greatest lower bound and especially
the requested least upper bound this way is analyzed in Section 4.5.

4.2 Strongly Conclusion-Restricted Complete Queries

We now focus on computing the tight answer to strongly conclusion-restricted complete
queries to general conditional constraint trees. In the sequel, let (B; KB ) be a conditional
constraint tree and let 9(F jE )[x1 ; x2 ] be a strongly conclusion-restricted complete query.
The tight upper answer to 9(F jE )[x1 ; x2 ] is always given by fx2 =1g. To compute the
tight lower answer to 9(F jE )[x1 ; x2 ], we first compute the tight lower answer fy1 =u1 g to the
premise-restricted complete query 9(E jF )[y1 ; y2 ]. We then distinguish the following cases:
If u1 > 0, then the tight lower answer to 9(F jE )[x1 ; x2 ] is computed locally by a function
H1 (like the tight lower answer to premise-restricted complete queries in Section 4.1.2).
If u1 = 0 and E ) F , then the tight lower answer to 9(F jE )[x1 ; x2 ] is given by fx1 =1g.
Otherwise, the tight lower answer to 9(F jE )[x1 ; x2 ] is given by fx1 =0g.
We now focus on the technical details. Let (B; !) be the directed graph that belongs
to the premise-restricted complete query 9(E jF )[y1 ; y2 ] (see Section 4.1.1). Let Pr 1 (B jC )
denote v1 for all (B jC )[v1 ; v2 ] 2 KB . In the sequel, let B be a node and let C = B " . Again,
the cases C = B , C = B1 with a node B1 6= B , and C = B1 B2 : : : Bk with k > 1 nodes
B1; B2 ; : : : ; Bk refer to Leaf, Chaining, and Fusion, respectively.
We define the function H1 for computing greatest lower bounds in the case H1ff (B; C ) > 0
as follows. Let H1 (B; C ) = 1 (note that 1 will coincide with the greatest lower bound
of Pr (BL(C )) = Pr (L(C )) subject to Pr j= KB and Pr (L(C )) > 0), where 1 in Leaf
219

fiLukasiewicz

(C = B ), Chaining (C = B1 ), and Fusion (C = B1 B2 : : : Bk with k > 1) is given as
follows (note that H1ff (C; C " ) and H1ff (B; Bi ) are defined like in Section 4.1.2):
Leaf:
1 = 1
:
jC ),1 )
1 = H1 (C; C " )  (1 + PrH11ff((BC;C
")

Chaining

:

1,1
0
ff

H (B;Bi )(1=H1 (B;Bi ),1) C
B1 + i2min
[1:k] 1
CA
1 = B
@
Pk

Fusion

1,k+

i=1

H1ff (B;Bi )

By induction on the definition of H1 , it is easy to see that H1ff (B; C ) > 0 entails that 1
is defined and that 1 > 0 (note that H1ff (B; C ) = ff1 in Leaf, Chaining, and Fusion is
defined like in Section 4.1.2). In this case, H1 is sound and globally complete with respect
to B and C iff H1 (B; C ) = 1 is the greatest lower bound of Pr (BL(C )) = Pr (L(C )) subject
to Pr 2 Mo (B; C ) and Pr (L(C )) > 0. Thus, the next theorem shows soundness and global
completeness of H1 . It also shows that, for C = B1 B2 : : : Bk with k > 1, the least upper
bound of Pr (BL(C )) = Pr (L(C )) subject to Pr 2 Mo (B; C ) and Pr (L(C )) > 0 is given by 1.

Theorem 4.7

a) If ff1 > 0, then for all Pr 2 Mo (B; C ), it holds 1  Pr (L(C ))  Pr (BL(C )).
b) If ff1 > 0, then there is a probabilistic interpretation Pr 2 Mo (B; C ) with Pr (B ) > 0,
Pr (L(C )) > 0, 1  Pr (L(C )) = Pr (BL(C )), and ff1  Pr (B ) = Pr (BL(C )).
c) If ff1 > 0 and C = B1 B2 : : : Bk with k > 1, then there is some Pr 2 Mo (B; C ) with
Pr (B ) > 0, Pr (L(C )) > 0, 1  Pr (L(C )) = Pr (BL(C )), and ff1  Pr (B ) = Pr (BL(C )).
d) If ff1 = 0 and C = B1 B2 : : : Bk with k > 1, then for each " > 0 there is some Pr 2 Mo (B; C )
with Pr (B ) > 0, Pr (L(C )) > 0, 1  Pr (L(C )) = Pr (BL(C )), and "  Pr (B )  Pr (BL(C )).

Proof. The proof is given in full detail in Appendix C. 2

We are now ready to give the following characterization of tight answers to strongly
conclusion-restricted complete queries to conditional constraint trees.
Theorem 4.8 Let (B; KB ) be a conditional constraint tree and let 9(F jE )[x1 ; x2 ] be a
strongly conclusion-restricted complete query. Let the tight lower answer to the premiserestricted complete query 9(E jF )[y1 ; y2 ] be given by fy1 =u1 g.
(1) If u1 > 0, then the tight answer to 9(F jE )[x1 ; x2 ] is given by fx1 =H1 (F; F " ); x2 =1g.
(2) If u1 = 0 and E ) F , then the tight answer to 9(F jE )[x1 ; x2 ] is given by fx1 =1; x2 =1g.
(3) Otherwise, the tight answer to 9(F jE )[x1 ; x2 ] is given by fx1 =0; x2 =1g.
Proof. The proof is given in full detail in Appendix C. 2
220

fiProbabilistic Deduction with Conditional Constraints over Basic Events

4.3 Complete Queries

We now show that the problem of computing tight answers to complete queries can be
reduced to the problems of computing tight answers to premise-restricted complete queries
and of computing tight answers to strongly conclusion-restricted complete queries.
In detail, a complete query is premise-restricted, it is strongly conclusion-restricted,
or it can be reduced to premise-restricted complete queries and to strongly conclusionrestricted complete queries. For example, given the complete query 9(STUjMQR)[x1 ; x2 ]
to the conditional constraint tree in Fig. 2, right side, we first compute the tight answer
fy1=u1 ; y2=u2 g to the premise-restricted complete query 9(MQRjO)[y1 ; y2] (directed to the
corresponding subtree) and the tight answer fz1 =v1 ; z2 =v2 g to the strongly conclusion-restricted complete query 9(OjMQR)[z1 ; z2 ] (directed to the corresponding subtree). We then
generate a new conditional constraint tree by replacing the subtree over the nodes M, N,
O, Q, and R by the pair of conditional constraints (BjO)[u1 ; u2 ] and (OjB)[v1 ; v2 ] over the
nodes B and O (note that B represents MQR). Finally, we compute the tight answer to the
premise-restricted complete query 9(STUjB)[x1 ; x2 ] to the new conditional constraint tree.
Note that this reduction can always be done, since for each query 9(F jE )[x1 ; x2 ], all
paths from a basic event in E to a basic event in F have at least one basic event in common.

Theorem 4.9 Let (B; KB ) be a conditional constraint tree and let 9(F jE )[x1 ; x2 ] be a com-

plete query that is not premise-restricted and not strongly conclusion-restricted.
a) There exists a basic event G 2 B and two conditional constraint trees (B1 ; KB 1 ) and
(B2 ; KB 2 ) such that B1 \ B2 = fGg, B1 [ B2 = B, and 9(GjE )[z1 ; z2 ] is a strongly conclusion-restricted complete query to (B1 ; KB 1 ).
b) Let the tight answer to the premise-restricted complete query 9(E jG)[y1 ; y2 ] to (B1 ; KB 1 )
be given by fy1 =u1 ; y2 =u2 g and let the tight answer to the strongly conclusion-restricted
complete query 9(GjE )[z1 ; z2 ] to (B1 ; KB 1 ) be given by fz1 =v1 ; z2 =v2 g.

(1) If u1 > 0, then also v1 > 0 and the tight answer to the complete query 9(F jE )[x1 ; x2 ]
to (B; KB ) coincides with the tight answer to the premise-restricted complete query
9(F jB )[x1 ; x2 ] to (B2 [ fB g; KB 2 [ f(B jG)[u1 ; u2 ]; (GjB )[v1 ; v2 ]g), where B is a new
basic event with B 62 B2 . In particular, for exact conditional constraint trees (B; KB ),
the tight answer to the complete query 9(F jE )[x1 ; x2 ] is given by:

fx1 = max(0; v1 , uv11 + vu1 s11 ); x2 = min(1; 1 , v1 + vu1 s12 ; t2 ,st22+u1 )g ;
where s1 = H1ff (G; G" ), s2 = H2ff (G; G" ), and t2 = H2 (G; G" ) (note that H1ff , H2ff , and
H2 are defined like in Section 4.1.1).

(2) If u1 =0, v1 =1, and G ) F , then the tight answer to the complete query 9(F jE )[x1 ; x2 ]
to (B; KB ) is given by fx1 =1; x2 =1g.
(3) Otherwise, the tight answer to the complete query 9(F jE )[x1 ; x2 ] to (B; KB ) is given
by fx1 =0; x2 =1g.

Proof. The proof is given in full detail in Appendix D. 2
221

fiLukasiewicz

4.4 Queries

The problem of computing tight answers to queries can be reduced to the more specialized
problem of calculating tight answers to complete queries.
More precisely, given a query 9(F jE )[x1 ; x2 ] to a conditional constraint tree (B; KB ),
a complete query 9(F 0 jE 0 )[x1 ; x2 ] to a conditional constraint tree (B0 ; KB 0 ) is generated by:
1. While (B; KB ) contains a leaf B that is not contained in EF : remove B from B and
remove the corresponding pair (C jB )[u1 ; u2 ]; (B jC )[v1 ; v2 ] 2 KB from KB .
2. While EF contains a basic event B that is not a leaf in (B; KB ): increase B by a new
basic event B 0, increase KB by the pair (B 0 jB )[1; 1] and (B jB 0 )[1; 1], and replace each
occurrence of B in 9(F jE )[x1 ; x2 ] by the new basic event B 0 .
It remains to show that the generated probabilistic deduction problem has the same
solution as the original probabilistic deduction problem:
Theorem 4.10 The tight answer to the query 9(F jE )[x1 ; x2 ] to (B; KB ) coincides with the
tight answer to the complete query 9(F 0 jE 0 )[x1 ; x2 ] to (B0 ; KB 0 ).
Proof. Let (B00; KB 00 ) be the conditional constraint tree that is generated in step 1 and let
(F jE )[u1 ; u2 ] be a tight logical consequence of KB 00 . We now show that (F jE )[u1 ; u2 ] is also
a tight logical consequence of KB . First, (F jE )[u1 ; u2 ] is a logical consequence of KB , since
KB 00 is a subset of KB . Moreover, each model Pr 00 of KB 00 (that is defined on all atomic
events over B00 ) can be extended to a model Pr of KB (that is defined on all atomic events
over B) with Pr (A) = s  Pr 00 (A) for all atomic events A over B00 that are different from the
conjunction of all negated basic events in B00 , where s is a real number from (0; 1]. This
model can be constructed inductively like in the proof of Theorem 3.2. Thus, for u 2 [u1 ; u2 ],
Pr 00 (E ) > 0 and u  Pr 00 (E ) = Pr 00 (EF ) entails Pr (E ) > 0 and u  Pr (E ) = Pr (EF ).
Finally, (F jE )[u1 ; u2 ] is a tight logical consequence of KB 00 iff (F 0 jE 0 )[u1 ; u2 ] is a tight
logical consequence of KB 0 , since we just introduce synonyms for basic events in step 2. 2

4.5 Computational Complexity
4.5.1 Exact Conditional Constraint Trees

We now show that for exact conditional constraint trees, our technique to compute the tight
answer to queries runs in linear time in the number of nodes of the tree. In the sequel, let
(B; KB ) be an exact conditional constraint tree and let n denote its number of nodes.

Lemma 4.11 The tight answer to a premise-restricted or strongly conclusion-restricted
complete query can be computed in linear time in n.

Proof. For exact conditional constraint trees, our approach
to compute the tight upper
fi


answer to premise-restricted complete queries by H2ff , H2 , and H2 runs in time O(n):
The directed tree can be computed in time O(n). An initialization of a leaf with a
constant number of assignments is performed exactly for each leaf of the directed tree, a
chaining with a constant number of arithmetic operations is performed exactly for each
arrow of the directed tree. Hence, initializing all leaves and performing all chainings runs
222

fiProbabilistic Deduction with Conditional Constraints over Basic Events

in time O(n). A fusion is done for each branching of the directed tree, using linear time in
the number of branches. Thus, all fusions together run in time O(n).
Even for general conditional constraint trees, the tight lower answer to premise-restricted
complete queries, and hence also the tight answer to strongly conclusion-restricted complete
queries, is analogously computed in time O(n). 2

Theorem 4.12 The tight answer to a query can be computed in linear time in n.
Proof. We assume that the set of basic events B is totally ordered and that the basic events
in the conjunctive events E and F of the query 9(F jE )[x1 ; x2 ] are written in this order.

First, the query is reduced to a complete query according to Section 4.4. This reduction
can be done in time O(n). Now, if the generated complete query is premise-restricted or
strongly conclusion-restricted, then the claim follows immediately from Lemma 4.11.
Otherwise, the generated complete query is reduced to premise-restricted and strongly
conclusion-restricted complete queries according to Section 4.3. Also this reduction can be
done in time O(n), since the basic event G in Theorem 4.9 a) is computable in time O(n).
Hence, the claim follows from Theorem 4.9 and Lemma 4.11. Note that t2 = H2 (G; G" ) in
Theorem 4.9 b) (1) can also be computed in time O(n). 2
4.5.2 Conditional Constraint Trees

For general conditional constraint trees, our technique to compute the tight lower answer
to queries runs still in linear time, while our technique to compute the tight upper answer
to queries runs in polynomial time in the number of nodes of the tree. In the sequel, let
(B; KB ) be a general conditional constraint tree and let n denote its number of nodes.

Lemma 4.13

a) The tight lower answer to a premise-restricted complete query and the tight answer to a
strongly conclusion-restricted complete query can be computed in linear time in n.
b) The tight upper answer to a premise-restricted complete query can be computed in polynomial time in n.

Proof. a) The claim is already shown in the proof of Lemma 4.11.

b) Our linear programming technique to compute the tight upper answer to premiserestricted complete queries runs in polynomial time in n:
Linear programming runs in polynomial time in the size of the linear programs (Papadimitriou & Steiglitz, 1982; Schrijver, 1986), where the size of a linear program is given
by its number of variables and its number of linear inequalities.
We now show that the size of our linear programs in Section 4.1.2 is polynomial in n.
The number of variables is n + 1. The number of linear inequalities in J (E; E " ) is 2n.
By induction on the recursive definition of J ff , J fi , and J  , it can be shown that the
number of min-operands in J ff (B; C ), J fi (B; C ), and J  (B; C ) is limited by jB(B; C )j2 ,
jB(B; C )j, and jB(B; C )j4 , respectively. Hence, the number of linear inequalities extracted
from x  J ff (E; E " ) and x  J  (E; E " ) is limited by jB(E; E " )j2 + jB(E; E " )j4 = n2 + n4 .
Thus, the overall number of generated linear inequalities l is limited by lu = 2n + n2 + n4 .
223

fiLukasiewicz

Finally, note that lu is a very rough upper bound for l, in many conditional constraint
trees (especially in those that branch very rarely), l is much lower than lu . For example,
taking a complete binary tree with n = 127 nodes, we get only l = 19 964 compared to
lu = 260 161 024. In the example of Section 4.1.2 with n = 9 nodes, we get only l = 72
compared to lu = 6 660. Another example is a tree that is degenerated to a chain of basic
events. In this case, we even get l = 5n + 1, that is, the overall number of generated linear
inequalities is linear in n. 2

Theorem 4.14

a) The tight lower answer to a query can be computed in linear time in n.
b) The tight upper answer to a query can be computed in polynomial time in n.

Proof. We assume that the set of basic events B is totally ordered and that the basic events
in the conjunctive events E and F of the query 9(F jE )[x1 ; x2 ] are written in this order.
Like in the proof of Theorem 4.12, the query is reduced to a complete query according
to Section 4.4. This reduction can be done in time O(n). Now, if the generated complete query is premise-restricted or strongly conclusion-restricted, then the claims follow
immediately from Lemma 4.13.
Otherwise, the generated complete query is reduced to premise-restricted and strongly
conclusion-restricted complete queries according to Section 4.3. Again, this reduction can
be done in time O(n), since the basic event G in Theorem 4.9 a) is computable in time O(n).
Thus, the claims follow from Theorem 4.9 and Lemma 4.13. Note that in Theorem 4.9 b) (1),
the tight lower answer to 9(F jB )[x1 ; x2 ] can be computed without u2 and v2 . 2
4.6 Comparison with the Classical Linear Programming Approach

As a comparison, we now briey describe how probabilistic deduction in conditional constraint trees can be done by the classical linear programming approach (Paa, 1988; van
der Gaag, 1991; Amarger et al. 1991; Hansen et al. 1995). In the sequel, let 9(F jE )[x1 ; x2 ]
be a query to an exact or general conditional constraint tree (B; KB ) over n nodes.
The tight answer to 9(F jE )[x1 ; x2 ] can be computed by solving two linear programs. In
detail, the requested greatest lower and least upper bound are given by the optimal values
of the following two linear programs with xA  0 (A 2 AB ) and opt 2 fmin; maxg:
opt

P

A2AB ; A)EF xA

subject to

P
A2AB ; A)E xA = 1
P
P
A2AB ; A)GH xA  u1  A2AB ; A)G xA for all (H jG)[u1 ; u2 ] 2 KB
P
P
A2AB ; A)GH xA  u2  A2AB ; A)G xA for all (H jG)[u1 ; u2 ] 2 KB
That is, the tight answer is computed by solving two linear programs with 2n variables
and 4n , 2 linear inequalities. For example, the tight answer to the premise-restricted
complete query 9(QRSTUjM)[x1 ; x2 ] to the conditional constraint trees in Fig. 2 yields two
linear programs with 29 = 512 variables and 4  9 , 2 = 34 linear inequalities.
224

fiProbabilistic Deduction with Conditional Constraints over Basic Events

Hence, if we now solve these two linear programs by the standard simplex method or
the standard interior-point technique, then we need immediately exponential time in n. It
is still an open question whether column generation techniques can help to solve the two
linear programs in less than exponential time in n in the worst case.

5. Comparison with Bayesian Networks
In this section, we briey discuss the relationship between conditional constraint trees and
Bayesian networks (Pearl, 1988).
A Bayesian network is defined by a directed acyclic graph G over discrete random variables X1 ; X2 ; : : : ; Xn as nodes and by a conditional probability distribution Pr (Xi jpa(Xi ))
for each random variable Xi and each instantiation pa(Xi ) of its parents pa(Xi ). It specifies
a unique joint probability distribution Pr over X1 ; X2 ; : : : ; Xn by:
Pr (X1 ; X2 ; : : : ; Xn ) =

n
Y
i=1

Pr (Xi j pa(Xi )) :

That is, the joint probability distribution Pr is uniquely determined by the conditional
distributions Pr (Xi jpa(Xi )) and certain conditional independencies encoded in G.
Hence, Bayesian trees (that is, Bayesian networks that have a directed tree as associated
directed acyclic graph) with only binary random variables seem to be very close to exact
conditional constraint trees. However, exact and general conditional constraint trees are
associated with an undirected tree that does not encode any independencies! For this reason, exact and general conditional constraint trees describe convex sets of joint probability
distributions rather than single joint probability distributions.
But, would it be possible to additionally assume certain independencies? Of course, with
each exact or general conditional constraint tree (B; KB ), we can associate all probabilistic
interpretations Pr that are models of KB and that have additionally the undirected tree
(B; $) as an I-map (Pearl, 1988). That is, we would have independencies without causal
directionality like in Markov trees (Pearl, 1988). However, this idea does not carry us
to a single probabilistic interpretation (neither for exact conditional constraint trees, nor
for general conditional constraint trees), and it is an interesting topic of future research to
investigate how the computation of tight answers in exact and general conditional constraint
trees changes under this kind of independencies (which yield tighter bounds, since they
reduce the number of models of exact and general conditional constraint trees).
Finally, if we additionally fix the probability of exactly one node, then an exact conditional constraint tree under the described independencies specifies exactly one probabilistic
interpretation (note that, to keep satisfiability, the probability of a node must respect certain
upper bounds, which are entailed by the exact conditional constraint tree). But, such exact
conditional constraint trees are in fact Bayesian trees with only binary random variables.

6. Summary and Conclusions
We showed that globally complete probabilistic deduction with conditional constraints over
basic events is NP-hard. We then concentrated on the special case of probabilistic deduction
225

fiLukasiewicz

in exact and general conditional constraint trees. We presented very ecient techniques for
globally complete probabilistic deduction. More precisely, for exact conditional constraint
trees, we presented a local approach that runs in linear time in the size of the conditional
constraint trees. For general conditional constraint trees, we introduced a global approach
that runs in polynomial time in the size of the conditional constraint trees.
Probabilistic deduction in conditional constraint trees is motivated by previous work
in the literature on inference rules. It generalizes patterns of commonsense reasoning that
have been thoroughly studied in this work. Hence, we presented a new class of tractable
probabilistic deduction problems, which are driven by artificial intelligence applications.
It is also important to note that the deduction process in exact and general conditional
constraint trees can easily be elucidated in a graphical way. For example, the computation
of the tight answer to the premise-restricted complete query 9(QRSTUjM)[x1 ; x2 ] to the
exact conditional constraint tree in Fig. 2, left side, can be illustrated by labeling each node
of the directed tree in Fig. 3 with the corresponding tightest bounds of Table 1.
Like Bayesian networks, conditional constraint trees are well-structured probabilistic
knowledge bases that have an intuitive graphical representation. Differently from Bayesian
networks, conditional constraint trees do not encode any probabilistic independencies. Thus,
they can also be understood as a complement to Bayesian networks, useful for restricted
applications in which well-structured independencies do not hold or are dicult to access.
Conditional constraint trees are quite restricted in their expressive power. However, in
more general probabilistic knowledge bases, probabilistic deduction in conditional contraint
trees may always act as local inference rules. For example, in case we desire explanatory
information on some specific local deductions from a subset of the whole knowledge base
(which could especially be useful in the design phase of a probabilistic knowledge base).
An important conclusion of this paper concerns the question whether to perform probabilistic deduction by the iterative application of inference rules or by linear programming.
The techniques of this paper have been elaborated by following the idea of inference rules in
probabilistic deduction. Hence, on the one hand, this paper shows that the idea of inference
rules can indeed bring us to ecient techniques for globally complete probabilistic deduction
in restricted settings. However, on the other hand, given the technical complexity of the
corresponding proofs, it seems unlikely that these results can be extended to probabilistic
knowledge bases that are significantly more general than conditional constraint trees.
That is, as far as significantly more general probabilistic deduction problems with conditional constraints are concerned, the iterative application of inference rules does not seem
to be very promising for globally complete probabilistic deduction. Note that a similar
conclusion is drawn in a companion paper (1998a, 1999a), which shows the limits of locally
complete inference rules for probabilistic deduction under taxonomic knowledge.
For example, probabilistic deduction from probabilistic logic programs that do not assume probabilistic independencies (Ng & Subrahmanian 1993, 1994; Lukasiewicz, 1998d)
should better not be done by the iterative application of inference rules. Note that much
more promising techniques are, for example, global techniques by linear programming
(Lukasiewicz, 1998d) and in particular approximation techniques based on truth-functional
many-valued logics (Lukasiewicz 1998b, 1999b).
226

fiProbabilistic Deduction with Conditional Constraints over Basic Events

Acknowledgements
I am very grateful to Michael Wellman and the referees for their useful comments. I also
want to thank Thomas Eiter for valuable comments on an earlier version of this paper. This
paper is an extended and revised version of a paper that appeared in Principles of Knowledge
Representation and Reasoning: Proceedings of the 6th International Conference, pp. 380{391.

Appendix A. Preliminaries of the Proofs for Sections 4.1 to 4.3

In this section, we make some technical preparations for the proofs of Theorems 4.1, 4.2,
4.7, 4.8, and 4.9. In the sequel, we use the notation

x1;1 x1;2
x2;1 x2;2
c1 c2

r1
r2

as an abbreviation of the following system of equations:
(11)

x1;1 + x1;2 = r1
x2;1 + x2;2 = r2

x1;1 + x2;1 = c1
x1;2 + x2;2 = c2 :

The next lemma provides the optimal values of two linear programs to be solved in the
proofs of Theorems 4.1, 4.2, 4.7, 4.8, and 4.9.
Lemma A.1 Let r1 ; r2 ; c1 ; c2  0 with r1 + r2 = c1 + c2 . For all i; j 2 f1; 2g:
a) min(ri ; cj ) = max xi;j subject to (11) and xn;m  0 for all n; m 2 f1; 2g.
b) max(0; ri , c3,j ) = min xi;j subject to (11) and xn;m  0 for all n; m 2 f1; 2g.
Proof. The claims can easily be verified (Lukasiewicz, 1996). 2
Let us assume that a conditional constraint tree is the union of two subtrees that have
just one node in common. A model of each subtree and a third model related to the
common node can now be combined to a model of the whole conditional constraint tree.
This important result follows from the next lemma.
Lemma A.2 Let B1 and B2 be sets of basic events with B1 \B2 = ;. Let B0 be a new basic
event that is not contained in B1 [ B2 . Let Pr 1 and Pr 2 be probabilistic interpretations on
the atomic events over B1 [fB0 g and B2 [fB0 g, respectively. Let B1 and B2 be conjunctive
events over B1 and B2 , respectively. Let Pr 0 be a probabilistic interpretation on the atomic
events over fB0 ; B1 ; B2 g with Pr 0 (H0 H1 ) = Pr 1 (H0 H1 ) and Pr 0 (H0 H2 ) = Pr 2 (H0 H2 ) for
all atomic events H0 , H1 , and H2 over fB0 g, fB1 g, and fB2 g, respectively.
There is a probabilistic interpretation Pr on the atomic events over B1 [B2 [fB0 g with:
(12)

Pr (H0 H1 H2 ) = Pr 0 (H0 H1 H2 );
Pr (H0 A1 ) = Pr 1 (H0 A1 ); and Pr (H0 A2 ) = Pr 2 (H0 A2 )
227

fiLukasiewicz

for all atomic events H0 , H1 , H2 , A1 , and A2 over the sets of basic events fB0 g, fB1 g,
fB2 g, B1, and B2, respectively.

Proof. Let the probabilistic interpretation Pr on the atomic events over B1 [ B2 [ fB0 g

be defined as follows:

8
1 (H0 A1 ) Pr 2 (H0 A2 )
<Pr 0(H0 H1 H2 )  Pr
Pr 1 (H0 H1 )  Pr 2 (H0 H2 ) if Pr 1 (H0 H1 )  Pr 2 (H0 H2 ) > 0
Pr (H0 A1 A2 ) = :
0
if Pr 1 (H0 H1 )  Pr 2 (H0 H2 ) = 0
for all atomic events H0 , A1 , and A2 over fB0 g, B1 , and B2 , respectively, with atomic events
H1 over fB1 g and H2 over fB2 g such that A1 ) H1 and A2 ) H2 .

Now, we must show that Pr satisfies (12). Let H0 , H1 , and H2 be atomic events over
fB0 g, fB1 g, and fB2 g, respectively. For Pr 1(H0 H1 ) > 0 and Pr 2 (H0 H2 ) > 0, we get:
Pr (H0 H1 H2 ) =

P

A1 2AB1 ; A1 )H1
A2 2AB2 ; A2 )H2

1 (H0 A1 ) Pr 2 (H0 A2 )
Pr 0 (H0 H1 H2 )  Pr
Pr 1 (H0 H1 )  Pr 2 (H0 H2 ) = Pr 0 (H0 H1 H2 ) :

For Pr 1 (H0 H1 ) = 0 or Pr 2 (H0 H2 ) = 0, we get Pr (H0 H1 H2 ) = 0 = Pr 0 (H0 H1 H2 ).
Let H0 , H1 , and A1 be atomic events over fB0 g, fB1 g, and B1 , respectively, with
A1 ) H1. For Pr 1(H0 H1 ) > 0, Pr 2 (H0 B2 ) > 0, and Pr 2 (H0 B 2 ) > 0, it holds:

P

Pr (H0 A1 ) =

A2 2AB2 ; A2 )B2

+

P

A2 2AB2 ; A2 )B 2

=

Pr 1 (H0 A1 )  Pr 2 (H0 A2 )
Pr 0 (H0 H1 B2 )  Pr
1 (H0 H1 ) Pr 2 (H0 B2 )
1 (H0 A1 ) Pr 2 (H0 A2 )
Pr 0 (H0 H1 B 2 )  Pr
Pr 1 (H0 H1 )  Pr 2 (H0 B 2 )
1 (H0 A1 )
Pr 0 (H0 H1 )  Pr
Pr 1 (H0 H1 )

= Pr 1 (H0 A1 ) :

For Pr 1 (H0 H1 ) > 0, Pr 2 (H0 B2 ) > 0, and Pr 2 (H0 B 2 ) = 0, we get:
Pr (H0 A1 ) =

=

P

A2 2AB2 ; A2 )B2

Pr 1 (H0 A1 )  Pr 2 (H0 A2 )
Pr 0 (H0 H1 B2 )  Pr
1 (H0 H1 ) Pr 2 (H0 B2 )
1 (H0 A1 )
Pr 0 (H0 H1 )  Pr
Pr 1 (H0 H1 )

= Pr 1 (H0 A1 ) :

The proof is similar for Pr 1 (H0 H1 ) > 0, Pr 2 (H0 B2 ) = 0, and Pr 2 (H0 B 2 ) > 0.
For Pr 1 (H0 H1 ) = 0, we get Pr (H0 A1 ) = 0 = Pr 1 (H0 A1 ).
Finally, the proof of Pr (H0 A2 ) = Pr 2 (H0 A2 ) for all atomic events H0 over fB0 g and
A2 over B2 can be done analogously. 2

Appendix B. Proofs for Section 4.1

In this section, we give the proofs of Theorems 4.1 and 4.2. That is, we show the global
soundness and the global completeness of the functions H1ff, H2ff , H2fi , and H2 . The proofs
are done by induction on the recursive definition of H1ff , H2ff , H2fi , and H2 .
228

fiProbabilistic Deduction with Conditional Constraints over Basic Events

To prove global soundness, we just have to show the local soundness of the computations
in Leaf, Chaining, and Fusion. To prove global completeness, we construct two models
of the conditional constraint tree, one related to the greatest lower bound and another one
related to the least upper bound computed in Leaf, Chaining, and Fusion.
For Leaf, such a model is trivially given. For Chaining, we combine a model of the
arrow, a model of the subtree, and a model connected to the common node to a model of the
extended conditional constraint tree. For Fusion, we combine models of the subtrees and
a model connected to the common node to a model of the extended conditional constraint
tree. More precisely, for Chaining and Fusion, the models of the subtrees are related to
previously computed tightest bounds, while the model connected to the common node is
related to the tightest bounds computed in the running Chaining or Fusion.
We need the following technical preparations. The next lemma helps us to show the
global completeness of the functions H2ff , H2fi , and H2 in Chaining and Fusion.
Lemma B.3 a) For all real numbers u; v 2 (0; 1], x2 2 [0; 1], and x2 ; z2 2 [0; 1) with
x2 ; x2  z2 and z2  x2 + x2, there is some x 2 [z2 , x2 ; x2 ] with:
(13)
min(1; uzv 2 ; 1 , u + uxv ; u , uxv + uzv 2 ) = min(1; uzv 2 ; 1 , u + uxv 2 ; u + uxv 2 ) :
b) For v2 ; x2 2 [0; 1] and v2 ; x2 ; w2 ; z2 2 [0; 1) with v2  w2 , v2  w2 , x2  z2 , x2  z2 ,
w2  v2 + v2 , and z2  x2 + x2 , there is v 2 [w2 , v2 ; v2 ] and x 2 [z2 , x2 ; x2 ] with:
min(w2 ; z2 ; v + z2 , x; x + w2 , v) = min(w2 ; z2 ; v2 + x2 ; x2 + v2 )
(14)
min(v; x) = min(v2 ; x2 ) :
Proof. The claims can easily be verified (Lukasiewicz, 1996). 2
The following lemma helps us to prove the local soundness and the local completeness
of the functions H1ff , H2ff, H2fi , and H2 in Chaining and Fusion.
Lemma B.4 a) Let u; v 2 (0; 1], x 2 [0; 1], and x 2 [0; 1). For all probabilistic interpretations Pr with Pr (B ) > 0, the conditions u  Pr (B ) = Pr (BC ), v  Pr (C ) = Pr (BC ),
x  Pr (C ) = Pr (CL(C " )), and x  Pr (C ) = Pr (C L(C " )) are equivalent to:
Pr (B C L(C " ))
Pr (B)
Pr (BC L(C " ))
Pr (B)

Pr (B CL(C " ))
Pr (B)
Pr (BCL(C " ))
Pr (B)

Pr (C L(C " ))
Pr (B)

ux
v

Pr (B C )
Pr (B)

1,u

Pr (BCL(C " ))
Pr (B)
Pr (BC L(C " ))
Pr (B)

Pr (B CL(C " ))
Pr (B)
Pr (BCL(C " ))
Pr (B)

u , ux
v
v

ux
v

u ,u
v

u

b) Let v; x 2 [0; 1] and v; x 2 [0; 1). For all probabilistic interpretations Pr with Pr (B ) > 0,
the conditions v  Pr (B ) = Pr (BL(G )), v  Pr (B ) = Pr (BL(G )), x  Pr (B ) = Pr (BL(H )),
and x  Pr (B ) = Pr (BL(H )) are equivalent to:
Pr (B L(G) L(H ))
Pr (B)
Pr (BL(G)L(H ))
Pr (B)

Pr (B L(G)L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

Pr (B L(H ))
Pr (B)

x

Pr (B L(G))
Pr (B)

v

229

Pr (BL(G) L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

Pr (BL(G)L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

1,x

x

1,v

v

fiLukasiewicz

Proof. The claims can be verified by straightforward arithmetic transformations based on

the properties of probabilistic interpretations. 2
After these preparations, we are now ready to prove the global soundness and the global
completeness of the functions H1ff , H2ff , H2fi , and H2 .
Proof of Theorem 4.1. The claims are proved by induction on the recursive definition
of H1ff . The case C = B1 : : : Bk is tackled by iteratively splitting C into two conjunctive
events. Thus, it is reduced to C = GH with conjunctive events G and H that are disjoint in
their basic events. For C = B1 , we define u = Pr (C jB ), v = Pr (B jC ), and x1 = H1ff (C; C " ).
For C = B1 : : : Bk , hence C = GH , let v1 = H1ff (B; G) and x1 = H1ff (B; H ).
a) All models Pr 2 Mo (B; C ) with Pr (B ) = 0 satisfy the indicated condition. In the sequel,
let Pr 2 Mo (B; C ) with Pr (B ) > 0.
Basis: Let C = B . Since C = L(C ), we get:

ff1  Pr (B ) = 1  Pr (B ) = Pr (BC ) = Pr (BL(C )) :
Induction: Let C = B1 . For all models Pr 2 2 Mo (C; C " ), we get by the induction hypothesis
x1  Pr 2 (C )  Pr 2 (CL(C " )). Thus, Pr satisfies the same conditions. Since L(C " ) = L(C )
and by Lemmata A.1 and B.4 a), we then get:

ff1  Pr (B ) = max(0; u , uv + uxv 1 )  Pr (B )  Pr (BL(C " )) = Pr (BL(C )) :

Let C = GH . For all Pr 1 2 Mo (B; G) and Pr 2 2 Mo (B; H ), we get by the induction
hypothesis v1  Pr 1 (B )  Pr 1 (BL(G)) and x1  Pr 2 (B )  Pr 2 (BL(H )). Thus, Pr satisfies
the same conditions. Since L(G)L(H ) = L(GH ) = L(C ) and by Lemmata A.1 and B.4 b):
max(0; v1 + x1 , 1)  Pr (B )  Pr (BL(G)L(H )) = Pr (BL(C )) :
b)
Basis: Let C = B . A model Pr 2 Mo (B; C ) such that Pr (B ) > 0, 1  Pr (B ) = ff1  Pr (B ) =
Pr (BL(C )), and Pr (BL(C )) = 0 is given by B; B 7! 0; 1.
Induction: Let C = B1 . Let the model Pr 1 of f(C jB )[u; u]; (B jC )[v; v]g with Pr 1 (B ) > 0
and Pr 1 (C ) > 0 be defined like in the proof of Theorem 3.2.
We now choose an appropriate model Pr 2 2 Mo (C; C " ). Let us first consider the
case x1 > 0, v = 1, or not L(C " ) ) C . By the induction hypothesis, there exists a model
Pr 2 2 Mo (C; C " ) with Pr 2 (C ) > 0, x1  Pr 2 (C ) = Pr 2 (CL(C " )), and Pr 2 (CL(C " )) = 0
iff L(C " ) ) C . Let us next assume x1 = 0, v < 1, and L(C " ) ) C . By Theorem 3.2, there
exists a model Pr 002 2 Mo (C; C " ) with Pr 002 (CL(C " )) > 0. By the induction hypothesis,
there exists a model Pr 02 2 Mo (C; C " ) with Pr 02 (C ) > 0 and 0  Pr 02 (C ) = Pr 02 (CL(C " )).
Hence, there exists a model Pr 2 2 Mo (C; C " ) with Pr 2 (C ) > 0 and
min(1 , v; Pr 002 (CL(C " )) = Pr 002 (C ))  Pr 2 (C ) = Pr 2 (CL(C " )) :
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (C ) = Pr 2 (C ) and Pr 1 (B C ) 
Pr 2 (CL(C " )). By Lemmata A.1 and B.4 a), we can choose the probabilistic interpretation
230

fiProbabilistic Deduction with Conditional Constraints over Basic Events

Pr 0 over fB; C; L(C " )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; C g and fC; L(C " )g, respectively, such that:
Pr 0 (BCL(C " )) = max(0; Pr 2 (CL(C " )) , Pr 1 (B C )) = 0
Pr 0 (BCL(C " )) = max(0; Pr 2 (CL(C " )) , Pr 1 (BC )) :

By Lemma A.2 with B1 = fB g, B2 = B(C; C " ) nfC g, B0 = C , B1 = B , and B2 = L(C " ),
there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds Pr 2
Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 a), we get:

ff1  Pr (B ) = max(0; u , uv + uxv 1 )  Pr (B ) = Pr (BL(C " )) = Pr (BL(C )) :
Moreover, it is easy to see that Pr (BL(C )) = 0 iff L(C ) ) B .
Let C = GH . By the induction hypothesis, there are models Pr 1 2 Mo (B; G) and
Pr 2 2 Mo (B; H ) with Pr 1 (B ) > 0, Pr 2 (B ) > 0, v1  Pr 1 (B ) = Pr 1 (BL(G)), x1  Pr 2 (B ) =
Pr 2 (BL(H )), Pr 1 (BL(G)) = 0 iff L(G) ) B , and Pr 2 (BL(H )) = 0 iff L(H ) ) B .
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (B ) = Pr 2 (B ) and Pr 1 (B L(G)) 
Pr 2 (BL(H ). By Lemmata A.1 and B.4 b), we can choose the probabilistic interpretation
Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; L(G)g and fB; L(H )g, respectively, such that:
Pr 0 (BL(G)L(H )) = min(Pr 2 (BL(H )); Pr 1 (BL(G))
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H )) , Pr 1 (BL(G))) :

By Lemma A.2 with B1 = B(B; G) nfB g, B2 = B(B; H ) nfB g, B0 = B , B1 = L(G), and
B2 = L(H ), there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence,
it holds Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 b), we get:
max(0; v1 + x1 , 1)  Pr (B ) = Pr (BL(G)L(H )) = Pr (BL(C )) :
Moreover, it is easy to see that Pr (BL(C )) = 0 iff L(C ) ) B . 2

Proof fiof Theorem
4.2. The claims are proved by induction on the recursive definition of


H2ff , H2 , and H2 . Again, the case C = B1 : : : Bk is tackled by iteratively splitting C into
two conjunctive events. Thus, it is reduced to C = GH with conjunctive events G and H
that are disjoint in their basic events. For C = B1 let u = Pr (C jB ), v = Pr (B jC ), and

x2 = H2ff (C; C " ); x2 = H2fi (C; C " ); z2 = H2 (C; C " ) :
For C = B1 : : : Bk , hence C = GH , we define:
v2 = H2ff(B; G); v2 = H2fi (B; G); w2 = H2 (B; G)
x2 = H2ff (B; H ); x2 = H2fi (B; H ); z2 = H2 (B; H ) :
a) For Pr 2 Mo (B; C ) with Pr (B ) = 0, we get Pr (N ) = 0 for all N 2 B(B; C ). Thus, Pr
satisfies the indicated conditions. Next, let Pr 2 Mo (B; C ) with Pr (B ) > 0.
231

fiLukasiewicz

Basis: Let C = B . Since L(C ) = C , we get:
Pr (BL(C )) = Pr (BC ) = 1  Pr (B ) = ff2  Pr (B )
Pr (BL(C )) = Pr (BC ) = 0  Pr (B ) = fi2  Pr (B )
Pr (L(C )) = Pr (C ) = 1  Pr (B ) = 2  Pr (B ) :
Induction: Let C = B1 . For all models Pr 2 2 Mo (C; C " ), we get by the induction hypothesis
Pr 2 (CL(C " ))  x2  Pr 2 (C ), Pr 2 (CL(C " ))  x2  Pr 2 (C ), and Pr 2 (L(C " ))  z2  Pr 2 (C ).
Hence, Pr satisfies the same conditions. Since L(C ) = L(C " ) and by Lemmata A.1 and
B.4 a), we then get:
Pr (BL(C )) = Pr (BL(C " ))  min(1; uzv 2 ; 1 , u + uxv 2 ; u + uxv 2 )  Pr (B ) = ff2  Pr (B )
Pr (BL(C )) = Pr (BL(C " )) 
min( uxv 2 + uv , u; uzv 2 )  Pr (B ) = fi2  Pr (B )
uz2  Pr (B ) = 2  Pr (B ) :
Pr (L(C )) = Pr (L(C " )) 
v
Let C = GH . For all models Pr 1 2 Mo (B; G) and all models Pr 2 2 Mo (B; H ), we get
by the induction hypothesis:
Pr 1 (BL(G))  v2  Pr 1 (B ); Pr 2 (BL(H ))  x2  Pr 2 (B )
Pr 1 (BL(G))  v2  Pr 1 (B ); Pr 2 (BL(H ))  x2  Pr 2 (B )
Pr 1 (L(G))  w2  Pr 1 (B ); Pr 2 (L(H ))  z2  Pr 2 (B ) :
Thus, Pr satisfies the same conditions. Since L(C ) = L(GH ) = L(G)L(H ) and by Lemmata A.1 and B.4 b), we get:
Pr (BL(C )) = Pr (BL(G)L(H ))  min(v2 ; x2 )  Pr (B )
Pr (BL(C )) = Pr (BL(G)L(H ))  min(v 2 ; x2 )  Pr (B )
Pr (L(C )) = Pr (L(G)L(H ))  min(w2 ; z2 ; v2 + x2 ; x2 + v 2 )  Pr (B ) :
b) and c)
Basis: Let C = B . A model Pr 2 Mo (B; C ) with Pr (B ) > 0 satisfying Pr (BL(C )) =
1  Pr (B ) = ff2  Pr (B ), Pr (BL(C )) = 0  Pr (B ) = fi2  Pr (B ), and Pr (L(C )) = 1  Pr (B ) =
2  Pr (B ) is given by B; B 7! 0; 1.
Induction: Let C = B1 . Let the model Pr 1 of f(C jB )[u; u]; (B jC )[v; v]g with Pr 1 (B ) > 0
and Pr 1 (C ) > 0 be defined like in the proof of Theorem 3.2.
For the proof of c), by the induction hypothesis, there is some Pr 2 2 Mo (C; C " ) with
Pr 2 (C ) > 0, Pr 2 (CL(C " )) = x2  Pr 2 (C ), and Pr 2 (L(C " )) = z2  Pr 2 (C ).
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (C ) = Pr 2 (C ) and Pr 1 (B C ) 
Pr 2 (CL(C " )). By Lemma A.1, we can choose the probabilistic interpretation Pr 0 over
fB; C; L(C " )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0(A2 ) = Pr 2(A2 ) for all atomic events A1
and A2 over fB; C g and fC; L(C " )g, respectively, such that:
Pr 0 (B CL(C " )) = min(Pr 1 (B C ); Pr 2 (CL(C " ))) = Pr 2 (CL(C " ))
Pr 0 (BCL(C " )) = min(Pr 1 (BC ); Pr 2 (CL(C " ))) :
232

fiProbabilistic Deduction with Conditional Constraints over Basic Events

By Lemma A.2 with B1 = fB g, B2 = B(C; C " ) n fC g, B0 = C , B1 = B , and B2 =
L(C "), there is a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds
Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 a), we get:
Pr (BL(C )) = Pr (BL(C " )) = min( uxv 2 + uv , u; uzv 2 )  Pr (B ) = fi2  Pr (B )
uz2  Pr (B ) = 2  Pr (B ) :
Pr (L(C )) = Pr (L(C " )) =
v

For the proof of b), by the induction hypothesis, there are models Pr 1;2 ; Pr 2;2 2
Mo (C; C " ) with Pr 1;2 (C ) > 0, Pr 2;2 (C ) > 0, and
(15)

Pr 1;2 (CL(C " )) = x2  Pr 1;2 (C ); Pr 1;2 (L(C " )) = z2  Pr 1;2 (C )
Pr 2;2 (CL(C " )) = x2  Pr 2;2 (C ); Pr 2;2 (L(C " )) = z2  Pr 2;2 (C ) :

These conditions already entail x2  z2 and x2  z2 . With the results from a), we additionally get z2  x2 + x2 . By Lemma B.3 a), there is x 2 [z2 , x2 ; x2 ] with (13). By (15),
there is Pr 2 2 Mo (C; C " ) with Pr 2 (C ) > 0 and
Pr 2 (CL(C " )) = x  Pr 2 (C ); Pr 2 (L(C " )) = z2  Pr 2 (C ) :
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (C ) = Pr 2 (C ). By Lemma A.1, we
can choose the probabilistic interpretation Pr 0 over fB; C; L(C " )g with Pr 0 (A1 ) = Pr 1 (A1 )
and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic events A1 and A2 over fB; C g and fC; L(C " )g,
respectively, such that:
Pr 0 (BCL(C " )) = min(Pr 1 (BC ); Pr 2 (CL(C " )))
Pr 0 (BCL(C " )) = min(Pr 1 (BC ); Pr 2 (CL(C " ))) :

By Lemma A.2 with B1 = fB g, B2 = B(C; C " ) n fC g, B0 = C , B1 = B , and B2 =
L(C "), there is a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds
Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 a), we get:
Pr (BL(C )) = Pr (BL(C " )) = min(1; uzv 2 ; 1 , u + uxv 2 ; u + uxv 2 )  Pr (B ) = ff2  Pr (B )
uz2  Pr (B ) = 2  Pr (B ) :
Pr (L(C )) = Pr (L(C " )) =
v

Let C = GH . We just show b), the claim in c) can be proved analogously. By the induction hypothesis, there are models Pr 1;1 ; Pr 2;1 2 Mo (B; G) and Pr 1;2 ; Pr 2;2 2 Mo (B; H )
with Pr 1;1 (B ) > 0, Pr 2;1 (B ) > 0, Pr 1;2 (B ) > 0, Pr 2;2 (B ) > 0, and
(16)

Pr 1;1 (BL(G)) = v2  Pr 1;1 (B );
Pr 2;1 (BL(G)) = v 2  Pr 2;1 (B );
Pr 1;2 (BL(H )) = x2  Pr 1;2 (B );
Pr 2;2 (BL(H )) = x2  Pr 2;2 (B );

Pr 1;1 (L(G)) = w2  Pr 1;1 (B )
Pr 2;1 (L(G)) = w2  Pr 2;1 (B )
Pr 1;2 (L(H )) = z2  Pr 1;2 (B )
Pr 2;2 (L(H )) = z2  Pr 2;2 (B ) :

These conditions already entail v2  w2 , v 2  w2 , x2  z2 , and x2  z2 . With the results
from a), we additionally get w2  v2 + v2 and z2  x2 + x2 . By Lemma B.3 b), there is
233

fiLukasiewicz

v 2 [w2 , v2 ; v2 ] and x 2 [z2 , x2; x2 ] with (14). By (16), there is Pr 1 2 Mo (B; G) and
Pr 2 2 Mo (B; H ) with Pr 1 (B ) > 0, Pr 2 (B ) > 0, and
Pr 1 (BL(G)) = v  Pr 1 (B ); Pr 1 (L(G)) = w2  Pr 1 (B )
Pr 2 (BL(H )) = x  Pr 2 (B ); Pr 2 (L(H )) = z2  Pr 2 (B ) :

By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (B ) = Pr 2 (B ). By Lemma A.1,
we can choose the probabilistic interpretation Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) =
Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic events A1 and A2 over fB; L(G)g and
fB; L(H )g, respectively, such that:
Pr 0 (BL(G )L(H )) = min(Pr 1 (BL(G)); Pr 2 (BL(H )))
Pr 0 (BL(G )L(H )) = min(Pr 1 (BL(G)); Pr 2 (BL(H ))) :

By Lemma A.2 with B1 = B(B; G) n fB g, B2 = B(B; H ) n fB g, B0 = B , B1 = L(G),
and B2 = L(H ), there is a probabilistic interpretation Pr over B(B; C ) with (12). Hence,
it holds Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma B.4 b), we get:
Pr (BL(C )) = Pr (BL(G)L(H )) = min(v2 ; x2 )  Pr (B )
Pr (L(C )) = Pr (L(G)L(H )) = min(w2 ; z2 ; v2 + x2 ; x2 + v2 )  Pr (B ) : 2

Finally, note that computing least upper bounds is more dicult than computing greatest lower bounds, since for each edge B ! C , by Lemmata 3.1 and B.4 a), the greatest lower
bound of Pr (BCL(C " ))=Pr (B ) subject to Pr 2 Mo (B; C ) and Pr (B ) > 0 is always 0, but
the least upper bound of Pr (BCL(C " ))=Pr (B ) subject to Pr 2 Mo (B; C ) and Pr (B ) > 0 is
generally not 1.

Appendix C. Proofs for Section 4.2

In this section, we give the proofs of Theorems 4.7 and 4.8.
We need some technical preparations as follows. The next lemma helps us to show the
local soundness of the function H1 in Fusion.

Lemma C.5 For all real numbers u1 ; u; v1 ; v; x1 ; x; y1; y 2 (0; 1] with u1  u, v1  v,
x1  x, y1  y, and u1 + x1 > 1, it holds:
min(u=v , u; x=y , x) = (u + x , 1)  min(u1 =v1 , u1 ; x1 =y1 , x1 ) = (u1 + x1 , 1) :

Proof. The claim can easily be verified (Lukasiewicz, 1996). 2

The following lemma helps us to show the local soundness and the local completeness
of the function H1 in Chaining and Fusion.

Lemma C.6 a) Let u, v, x, and y be real numbers from (0; 1]. For all probabilistic interpretations Pr with Pr (L(C " )) > 0, the conditions u  Pr (B ) = Pr (BC ), v  Pr (C ) = Pr (BC ),
x  Pr (C ) = Pr (CL(C " )), and y  Pr (L(C " )) = Pr (CL(C " )) are equivalent to:
234

fiProbabilistic Deduction with Conditional Constraints over Basic Events

Pr (B C L(C " ))
Pr (L(C " ))
Pr (BC L(C " ))
Pr (L(C " ))

Pr (B CL(C " ))
Pr (L(C " ))
Pr (BCL(C " ))
Pr (L(C " ))

Pr (C L(C " ))
Pr (L(C " ))

1,y

Pr (B C )
Pr (L(C " ))
yv yv
xu , x

Pr (BCL(C " ))
Pr (L(C " ))
Pr (BC L(C " ))
Pr (L(C " ))

Pr (B CL(C " ))
Pr (L(C " ))
Pr (BCL(C " ))
Pr (L(C " ))

y
x ,y

y

y yv
x, x
yv
x

b) Let u, v, x, and y be real numbers from (0; 1]. For all probabilistic interpretations Pr
with Pr (B ) > 0, the conditions u  Pr (B ) = Pr (BL(G )), v  Pr (L(G)) = Pr (BL(G )),
x  Pr (B ) = Pr (BL(H )), and y  Pr (L(H )) = Pr (BL(H )) are equivalent to:
Pr (B L(G) L(H ))
Pr (B)
Pr (BL(G)L(H ))
Pr (B)

Pr (B L(G)L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

Pr (B L(H ))
Pr (B)

x ,x
y

Pr (B L(G))
Pr (B)
u ,u
v

Pr (BL(G) L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

Pr (BL(G)L(H ))
Pr (B)
Pr (BL(G )L(H ))
Pr (B)

1,x

x

1,u

u

Proof. The claims can be verified by straightforward arithmetic transformations based on

the properties of probabilistic interpretations. 2
We are now ready to prove Theorems 4.7 and 4.8.
Proof of Theorem 4.7. The claims are proved by induction on the recursive definition of
H1 . The proof for C = B1B2 : : : Bk with k > 1 is done for k = 2. It can easily be generalized
to k  2. For C = B1 , we define u1 = Pr 1 (C jB ), v1 = Pr 1 (B jC ), x1 = H1ff (C; C " ), and
y1 = H1 (C; C " ). Note that ff1 > 0 entails x1; y1 > 0 and v1 + x1 > 1. For C = B1 B2 ,
we define G = B1 , H = B2 , u1 = H1ff (B; G), v1 = H1 (B; G), x1 = H1ff (B; H ), and
y1 = H1 (B; H ). Note that ff1 > 0 entails u1 ; v1 ; x1 ; y1 > 0 and u1 + x1 > 1.
a) All models Pr 2 Mo (B; C ) with Pr (L(C )) = 0 satisfy the indicated condition. In the
sequel, let Pr 2 Mo (B; C ) with Pr (L(C )) > 0 and thus also Pr (B ) > 0.
Basis: Let C = B . Since C = L(C ), we get:

1  Pr (L(C )) = 1  Pr (L(C )) = Pr (CL(C )) = Pr (BL(C )) :
Induction: Let C = B1 . For all models Pr 2 2 Mo (C; C " ), we get x1 Pr 2 (C )  Pr 2 (CL(C " ))
by Theorem 4.3 a), and y1  Pr 2 (L(C " ))  Pr 2 (CL(C " )) by the induction hypothesis. Thus,
Pr satisfies the same conditions. Since L(C " ) = L(C ) and by Lemmata A.1 and C.6 a):

1 = y1 , xy11 + yx1 v11  Pr (CL(C " )) = Pr (L(C " )) = Pr (CL(C )) = Pr (L(C )) :
Let C = GH . For all models Pr 1 2 Mo (B; G) and Pr 2 2 Mo (B; H ), we get by
Theorem 4.3 a) and by the induction hypothesis, respectively:

u1  Pr 1 (B )  Pr 1(BL(G)); x1  Pr 2 (B )  Pr 2(BL(H ))
v1  Pr 1(L(G))  Pr 1(BL(G)); y1  Pr 2(L(H ))  Pr 2(BL(H )) :
235

fiLukasiewicz

Hence, Pr satisfies the same conditions. Since L(G)L(H ) = L(GH ) = L(C ) and by Lemmata A.1, C.5, and C.6 b), we then get:
(BL(G)L(H ))=Pr (B )
1 = 1 = (1 + min(u1 =vu11,+ux11;,x11 =y1,x1 ) )  1 = (1 + Pr
Pr (BL(G)L(H ))=Pr (B) ) =

Pr (BL(C ))
Pr (L(C ))

:

b)
Basis: Let C = B . A model Pr 2 Mo (B; C ) such that Pr (B ) > 0, Pr (L(C )) > 0,
1  Pr (L(C )) = Pr (BL(C )), and 1  Pr (B ) = Pr (BL(C )) is given by B; B 7! 0; 1.
Induction: Let C = B1 . Let the model Pr 1 of f(C jB )[u1 ; u1 ]; (B jC )[v1 ; v1 ]g with Pr 1 (B ) > 0
and Pr 1 (C ) > 0 be defined like in the proof of Theorem 3.2.
By the induction hypothesis, there is Pr 2 2 Mo (C; C " ) with Pr 2 (C ) > 0, Pr 2 (L(C " )) > 0,
y1  Pr 2 (L(C ")) = Pr 2 (CL(C ")), and x1  Pr 2 (C ) = Pr 2 (CL(C ")). By Lemma 3.1, we can
choose Pr 1 and Pr 2 such that Pr 1 (C ) = Pr 2 (C ) and Pr 1 (B C )  Pr 2 (CL(C " )). By Lemmata A.1 and C.6 a), we can choose the probabilistic interpretation Pr 0 over fB; C; L(C " )g
with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic events A1 and A2 over
fB; C g and fC; L(C " )g, respectively, such that:
Pr 0 (BCL(C " )) = max(0; Pr 2 (CL(C " )) , Pr 1 (B C )) = 0
Pr 0 (BCL(C " )) = max(0; Pr 2 (CL(C " )) , Pr 1 (BC )) :

By Lemma A.2 with B1 = fB g, B2 = B(C; C " ) nfC g, B0 = C , B1 = B , and B2 = L(C " ),
there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds Pr 2
Mo (B; C ), Pr (B ) > 0, and Pr (L(C )) > 0. Moreover, by Lemma C.6 a), we get:

1 = y1 , xy11 + yx1v11 = Pr (CL(C ")) = Pr (L(C " )) = Pr (CL(C )) = Pr (L(C ))
= Pr (CL(C )) = Pr (C ) :
ff1 = u1 , uv11 + u1v1x1 = Pr (CL(C ")) = Pr (C )
Let C = GH . By the induction hypothesis, there are models Pr 1 2 Mo (B; G) and
Pr 2 2 Mo (B; H ) with Pr 1 (B ) > 0, Pr 2 (B ) > 0, Pr 1 (L(G)) > 0, Pr 2 (L(H )) > 0, and

u1  Pr 1 (B ) = Pr 1 (BL(G)); x1  Pr 2(B ) = Pr 2 (BL(H ))
v1  Pr 1(L(G)) = Pr 1 (BL(G)); y1  Pr 2 (L(H )) = Pr 2 (BL(H )) :
By Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (B ) = Pr 2 (B ) and Pr 1 (B L(G)) 
Pr 2 (BL(H ). By Lemmata A.1 and C.6 b), we can choose the probabilistic interpretation
Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; L(G)g and fB; L(H )g, respectively, such that:
Pr 0 (BL(G)L(H )) = min(Pr 2 (BL(H )); Pr 1 (BL(G)))
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H )) , Pr 1 (BL(G))) :

By Lemma A.2 with B1 = B(B; G) nfB g, B2 = B(B; H ) nfB g, B0 = B , B1 = L(G), and
B2 = L(H ), there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence,
236

fiProbabilistic Deduction with Conditional Constraints over Basic Events

it holds Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma C.6 b), we get Pr (L(C )) > 0 and
Pr (BL(G)L(H ))=Pr (B) ) = Pr (BL(C ))
1 = 1 = (1 + min(u1 =vu11,+ux11;,x11=y1 ,x1) ) = 1 = (1 + Pr
(BL(G)L(H ))=Pr (B)
Pr (L(C ))

Pr (BL(G)L(H ))
(BL(C )) :
ff1 =
u1 + x1 , 1
=
= PrPr
Pr (B)
(B )
c) Let C = GH . By Theorem 4.3 b), there exist Pr 1 2 Mo (B; G) and Pr 2 2 Mo (B; H ) with
Pr 1 (B ) > 0, Pr 2 (B ) > 0, u1  Pr 1 (B ) = Pr 1 (BL(G)), and x1  Pr 2 (B ) = Pr 2 (BL(H )). By
Lemma 3.1, we can choose Pr 1 and Pr 2 such that Pr 1 (B ) = Pr 2 (B ) and Pr 1 (B L(G)) 
Pr 2 (BL(H ). By Lemmata A.1 and C.6 b), we can choose the probabilistic interpretation
Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; L(G)g and fB; L(H )g, respectively, such that:
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H ) , Pr 1 (B L(G))) = 0
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H )) , Pr 1 (BL(G))) :
By Lemma A.2 with B1 = B(B; G) nfB g, B2 = B(B; H ) nfB g, B0 = B , B1 = L(G), and
B2 = L(H ), there exists a probabilistic interpretation Pr over B(B; C ) with (12). Hence,
it holds Pr 2 Mo (B; C ) and Pr (B ) > 0. By Lemma C.6 b), we get Pr (L(C )) > 0 and
1 = Pr (BL(G)L(H )) = Pr (L(G)L(H )) = Pr (BL(C )) = Pr (L(C ))
ff1 = Pr (BL(G)L(H )) = Pr (B ))
= Pr (BL(C )) = Pr (B ) :
d) Let C = GH . By Theorem 3.2, there is a model Pr 000 2 Mo (B; C ) with Pr 000 (BL(C )) > 0.
By Theorem 4.3 b), there is a model Pr 00 2 Mo (B; C ) with Pr 00 (B ) > 0 and 0  Pr 00 (B ) =
ff1  Pr 00(B ) = Pr 00 (BL(C )). Hence, there is a model Pr 0 2 Mo (B; C ) with Pr 0 (B ) > 0 and
min("; Pr 000 (BL(C )) = Pr 000 (B ))  Pr 0 (B ) = Pr 0 (BL(C )) :
Let the models Pr 1 2 Mo (B; G) and Pr 2 2 Mo (B; H ) be defined by Pr 1 (A1 ) = Pr 0 (A1 ) and
Pr 2 (A2 ) = Pr 0 (A2 ) for all atomic events A1 and A2 over B(B; G) and B(B; H ), respectively.
By Lemma 3.1, we can choose Pr 1 and Pr 2 such that Pr 1 (B ) = Pr 2 (B ) and Pr 1 (B L(G)) 
Pr 2 (BL(H ). By Lemmata A.1 and C.6 b), we can choose the probabilistic interpretation
Pr 0 over fB; L(G); L(H )g with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic
events A1 and A2 over fB; L(G)g and fB; L(H )g, respectively, such that:
= 0
Pr 0 (BL(G)L(H )) = max(0; Pr 2 (BL(H ) , Pr 1 (B L(G)))
Pr 0 (BL(G)L(H )) = min("; Pr 000 (BL(C )) = Pr 000 (B ))  Pr 0 (B ) :
By Lemma A.2 with B1 = B(B; G) n fB g, B2 = B(B; H ) n fB g, B0 = B , B1 = L(G), and
B2 = L(H ), there is a probabilistic interpretation Pr over B(B; C ) with (12). Hence, it holds
Pr 2 Mo (B; C ), Pr (B ) > 0, Pr (L(C )) > 0, Pr (BL(C )) = 0, and "  Pr (B )  Pr (BL(C )). 2
Proof of Theorem 4.8. For u1 > 0, the claim is immediate by Theorem 4.7 a) to c).
Let u1 = 0 and E ) F . It holds 1  Pr (E ) = Pr (EF ) for all models Pr of KB . Moreover,
by Theorem 3.2, there exists a model Pr of KB with Pr (E ) > 0.
Let u1 = 0 and not E ) F . By Theorem 4.3 b), there exists a model Pr of KB
with Pr (E ) > 0 and Pr (EF ) = 0. By Theorem 4.7 d), there exists a model Pr of KB with
Pr (E ) > 0 and 1  Pr (E ) = Pr (EF ). 2

237

fiLukasiewicz

Appendix D. Proofs for Section 4.3
In this section, we give the proof of Theorem 4.9.
The next lemma will help us to show the global tightness of the computed lower bound
in the case (3) of Theorem 4.9 b).

Lemma D.7 Let x 2 [0; 1] and v; x 2 [0; 1). For all probabilistic interpretations Pr with
Pr (G ) > 0, the conditions Pr (EG ) = 0, v  Pr (G) = Pr (EG ), x  Pr (G) = Pr (GF ), and
x  Pr (G) = Pr (GF ) are equivalent to:
Pr (E G F )
Pr (G)
Pr (EG F )
Pr (G)

Pr (E GF )
Pr (G)
Pr (EGF )
Pr (G)

Pr (G F )
Pr (G)

x

Pr (E G)
Pr (G)

v

Pr (EGF )
Pr (G)
Pr (EG F )
Pr (G)

Pr (E GF )
Pr (G)
Pr (EGF )
Pr (G)

1,x

x

1
0

Proof. The claim can be verified by straightforward arithmetic transformations based on

the properties of probabilistic interpretations. 2
We are now ready to prove Theorem 4.9.
Proof of Theorem 4.9. a) By the definition of queries to conditional constraint trees, all
paths from a basic event in E to a basic event in F have at least one basic event in common.
Hence, we can choose the basic event G from all such basic events in common such that
9(GjE )[z1 ; z2 ] is a strongly conclusion-restricted complete query to a subtree.
b) For u1 > 0, the claim follows from Theorem 4.7 a) to c). For the special case of exact
conditional constraint trees (B; KB ), the claim then follows from Theorems 4.3 and 4:5.
Let u1 = 0, v1 = 1, and G ) F . It holds 1  Pr (E ) = Pr (EF ) for all models Pr of KB .
Moreover, by Theorem 3.2, there exists a model Pr of KB with Pr (E ) > 0.
Let u1 = 0, v1 = 0, and G ) F . It is easy to see that by (1) and Theorem 4.7 d), the
tight upper answer is given by fx2 =1g. We now show that the tight lower answer is given by
fx1 =0g. By Theorem 4.3 b), there exists a model Pr 1 of KB 1 with Pr 1 (E ) > 0, Pr 1 (G) > 0,
and Pr 1 (EG ) = 0. By Theorem 3.2, there exists a model Pr 2 of KB 2 with Pr 2 (G) > 0. By
Lemma 3.1, we can choose Pr 1 and Pr 2 with Pr 1 (G) = Pr 2 (G) and Pr 1 (E G)  Pr 2 (GF ).
By Lemmata A.1 and D.7, we can choose the probabilistic interpretation Pr 0 over fE; G; F g
with Pr 0 (A1 ) = Pr 1 (A1 ) and Pr 0 (A2 ) = Pr 2 (A2 ) for all atomic events A1 and A2 over
fE; Gg and fG; F g, respectively, such that:
Pr 0 (EGF ) = max(0; Pr 2 (GF ) , Pr 1 (E G)) = 0
Pr 0 (EGF ) = 0 :

By Lemma A.2, there exists a probabilistic interpretation Pr over B with (12) for all atomic
events H0 , H1 , H2 , A1 , and A2 over the sets of basic events fGg, fE g, fF g, B1 n fGg, and
B2 n fGg, respectively. Hence, Pr is a model of KB with Pr (E ) > 0 and Pr (EF ) = 0.
For u1 = 0 and not G ) F , the claim follows from (1) and Theorem 4.7 d). 2
238

fiProbabilistic Deduction with Conditional Constraints over Basic Events

References

Adams, E. W. (1975). The Logic of Conditionals, Vol. 86 of Synthese Library. D. Reidel,
Dordrecht, Netherlands.
Amarger, S., Dubois, D., & Prade, H. (1991). Constraint propagation with imprecise
conditional probabilities. In Proceedings of the 7th Conference on Uncertainty in
Artificial Intelligence, pp. 26{34. Morgan Kaufmann.
Andersen, K. A., & Hooker, J. N. (1994). Bayesian logic. Decision Support Systems, 11,
191{210.
Bacchus, F. (1990). Representing and Reasoning with Probabilistic Knowledge: A Logical
Approach to Probabilities. MIT Press, Cambridge, USA.
Bacchus, F., Grove, A., Halpern, J. Y., & Koller, D. (1996). From statistical knowledge
bases to degrees of beliefs. Artificial Intelligence, 87, 75{143.
Carnap, R. (1950). Logical Foundations of Probability. University of Chicago Press, Chicago.
Coletti, G. (1994). Coherent numerical and ordinal probabilistic assessments. IEEE Transactions on Systems, Man, and Cybernetics, 24 (12), 1747{1754.
de Finetti, B. (1974). Theory of Probability. Wiley, New York.
Dubois, D., & Prade, H. (1988). On fuzzy syllogisms. Computational Intelligence, 4 (2),
171{179.
Dubois, D., Prade, H., Godo, L., & de Mantaras, R. L. (1993). Qualitative reasoning with
imprecise probabilities. Journal of Intelligent Information Systems, 2, 319{363.
Dubois, D., Prade, H., & Touscas, J.-M. (1990). Inference with imprecise numerical quantifiers. In Ras, Z. W., & Zemankova, M. (Eds.), Intelligent Systems, chap. 3, pp. 53{72.
Ellis Horwood.
Fagin, R., Halpern, J. Y., & Megiddo, N. (1990). A logic for reasoning about probabilities.
Information and Computation, 87, 78{128.
Frisch, A. M., & Haddawy, P. (1994). Anytime deduction for probabilistic logic. Artificial
Intelligence, 69, 93{122.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the
Theory of NP-Completeness. Freeman, New York.
Georgakopoulos, G., Kavvadias, D., & Papadimitriou, C. H. (1988). Probabilistic satisfiability. Journal of Complexity, 4 (1), 1{11.
Gilio, A., & Scozzafava, R. (1994). Conditional events in probability assessment and revision. IEEE Transactions on Systems, Man, and Cybernetics, 24 (12), 1741{1746.
Halpern, J. Y. (1990). An analysis of first-order logics of probability. Artifical Intelligence,
46, 311{350.
239

fiLukasiewicz

Hansen, P., Jaumard, B., Nguetse, G.-B. D., & de Arag~ao, M. P. (1995). Models and algorithms for probabilistic and Bayesian logic. In Proceedings of the 14th International
Joint Conference on Artificial Intelligence, pp. 1862{1868.
Heinsohn, J. (1994). Probabilistic description logics. In Proceedings of the 10th Conference
on Uncertainty in Artificial Intelligence. Morgan Kaufmann.
Jaumard, B., Hansen, P., & de Arag~ao, M. P. (1991). Column generation methods for
probabilistic logic. ORSA Journal of Computing, 3, 135{147.
Kavvadias, D., & Papadimitriou, C. H. (1990). A linear programming approach to reasoning
about probabilities. Annals of Mathematics and Artificial Intelligence, 1, 189{205.
Lukasiewicz, T. (1996). Precision of Probabilistic Deduction under Taxonomic Knowledge.
Doctoral Dissertation, Universitat Augsburg.
Lukasiewicz, T. (1997). Ecient global probabilistic deduction from taxonomic and probabilistic knowledge-bases over conjunctive events. In Proceedings of the 6th International Conference on Information and Knowledge Management, pp. 75{82. ACM
Press.
Lukasiewicz, T. (1998a). Magic inference rules for probabilistic deduction under taxonomic
knowledge. In Proceedings of the 14th Conference on Uncertainty in Artificial Intelligence, pp. 354{361. Morgan Kaufmann.
Lukasiewicz, T. (1998b). Many-valued first-order logics with probabilistic semantics. In Proceedings of the Annual Conference of the European Association for Computer Science
Logic. To appear.
Lukasiewicz, T. (1998c). Probabilistic deduction with conditional constraints over basic
events. In Principles of Knowledge Representation and Reasoning: Proceedings of the
6th International Conference, pp. 380{391. Morgan Kaufmann.
Lukasiewicz, T. (1998d). Probabilistic logic programming. In Proceedings of the 13th European Conference on Artificial Intelligence, pp. 388{392. J. Wiley & Sons.
Lukasiewicz, T. (1999a). Local probabilistic deduction from taxonomic and probabilistic
knowledge-bases over conjunctive events. International Journal of Approximate Reasoning. To appear.
Lukasiewicz, T. (1999b). Probabilistic and truth-functional many-valued logic programming. In Proceedings of the 29th IEEE International Symposium on Multiple-Valued
Logic. To appear.
Luo, C., Yu, C., Lobo, J., Wang, G., & Pham, T. (1996). Computation of best bounds of
probabilities from uncertain data. Computational Intelligence, 12 (4), 541{566.
Ng, R. T., & Subrahmanian, V. S. (1993). A semantical framework for supporting subjective
and conditional probabilities in deductive databases. Journal of Automated Reasoning,
10 (2), 191{235.
240

fiProbabilistic Deduction with Conditional Constraints over Basic Events

Ng, R. T., & Subrahmanian, V. S. (1994). Stable semantics for probabilistic deductive
databases. Information and Computation, 110, 42{83.
Nilsson, N. J. (1986). Probabilistic logic. Artificial Intelligence, 28, 71{88.
Nilsson, N. J. (1993). Probabilistic logic revisited. Artificial Intelligence, 59, 39{42.
Paa, G. (1988). Probabilistic Logic. In Dubois, D., Smets, P., Mamdani, A., & Prade,
H. (Eds.), Non-Standard Logics for Automated Reasoning, chap. 8, pp. 213{251. Academic Press.
Papadimitriou, C. H., & Steiglitz, K. (1982). Combinatorial Optimization, Algorithms and
Complexity. Prentice-Hall, Englewood Cliffs, NJ.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible
Inference. Morgan Kaufmann, San Mateo, CA.
Pittarelli, M. (1994). Anytime decision making with imprecise probabilities. In Proceedings
of the 10th Conference on Uncertainty in Artificial Intelligence, pp. 470{477. Morgan
Kaufmann.
Schrijver, A. (1986). Theory of Linear and Integer Programming. Wiley, New York.
Thone, H. (1994). Precise Conclusion under Uncertainty and Incompleteness in Deductive
Database Systems. Doctoral Dissertation, Universitat Tubingen.
Thone, H., Kieling, W., & Guntzer, U. (1995). On cautious probabilistic inference and
default detachment. Annals of Operations Research, 55, 195{224.
van der Gaag, L. (1991). Computing probability intervals under independency constraints.
In Uncertainty in Artificial Intelligence 6, pp. 457{466. North-Holland, Amsterdam.
Walley, P. (1991). Statistical Reasoning with Imprecise Probabilities. Chapman and Hall,
New York.

241

fiJournal of Artificial Intelligence Research 10 (1999) 375-397

Submitted 2/99; published 6/99

Ecient Heuristic Hypothesis Ranking
steve.chien@jpl.nasa.gov
andre.stechert@jpl.nasa.gov
darren.mutz@jpl.nasa.gov

Steve Chien
Andre Stechert
Darren Mutz
Jet Propulsion Laboratory
California Institute of Technology
4800 Oak Grove Drive, M/S 126-347
Pasadena, CA 91109-8099

Abstract

This paper considers the problem of learning the ranking of a set of stochastic alternatives based upon incomplete information (i.e., a limited number of samples). We describe
a system that, at each decision cycle, outputs either a complete ordering on the hypotheses
or decides to gather additional information (i.e., observations) at some cost. The ranking
problem is a generalization of the previously studied hypothesis selection problem|in selection, an algorithm must select the single best hypothesis, while in ranking, an algorithm
must order all the hypotheses.
The central problem we address is achieving the desired ranking quality while minimizing the cost of acquiring additional samples. We describe two algorithms for hypothesis
ranking and their application for the probably approximately correct (PAC) and expected
loss (EL) learning criteria. Empirical results are provided to demonstrate the effectiveness
of these ranking procedures on both synthetic and real-world datasets.
1. Introduction

In many applications, the cost of information can be quite high, imposing a requirement
that learning algorithms glean as much usable information as possible with a minimum of
data. For example:



Data may be scarce, making learning the most possible from limited training data
key.



In speedup learning, minimizing processing time is critical. Here, reducing the number
of necessary training examples is key since the expense of processing each example
can be significant (Tadepalli, 1992).



In decision tree learning, the cost of using all available training examples when evaluating potential attributes for partitioning can be computationally expensive (Musick,
Catlett, & Russell, 1993).



In evaluating medical treatment policies, acquiring additional training examples might
imply that human subjects are exposed to an experimental treatment for a longer
period than is necessary.

When one wishes some sort of guarantee on the quality of a solution, a statistical decision
theoretic framework is useful. The framework answers the questions: How much information

c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiChien, Stechert, & Mutz
is enough? At what point do we have adequate information to rank the alternatives with
some requested confidence?
This paper focuses on parametric ranking problems, a general class of statistical machine learning problems in which the goal is to rank a set of alternative hypotheses where
the goodness of a hypothesis is a function of a set of parameters whose values are unknown
(e.g., Chien, Stechert, & Mutz, 1998; Gratch, 1992; Greiner & Jurisica, 1992; Kaelbling,
1993; Moore & Lee, 1994; Musick et al., 1993). The learning system determines and refines estimates of these parameters by using training examples, with a secondary goal of
minimizing learning cost.
The principal contributions of this paper are:



We define two families of hypothesis ranking algorithms, based on recursive selection
and adjacency, respectively. We provide specific details on how to apply them using
the probably approximately correct (PAC) and expected loss (EL) decision criteria.



We provide empirical results demonstrating the effectiveness of these algorithms at
achieving the requested decision criteria on synthetic data.



We provide empirical results showing that these algorithms significantly outperform
existing statistical methods on real-world data from spacecraft design optimization
and image compression applications.

The remainder of this paper is structured as follows. First, we describe the hypothesis ranking problem more formally, including definitions for the probably approximately
correct (PAC) and expected loss (EL) decision criteria. We then define two algorithms for
establishing these criteria for the hypothesis ranking problem|a recursive hypothesis selection algorithm and an adjacent comparison algorithm. Next, we describe empirical tests
demonstrating the effectiveness of these algorithms as well as documenting their improved
performance over a standard algorithm from the statistical ranking literature. Finally, we
describe related work and future extensions to the algorithms.
2. Hypothesis Ranking Problems

Hypothesis ranking problems are an abstract class of learning problems where an algorithm
is given a set of hypotheses to rank. The ranking desired is that which orders the hypotheses
by their expected utility, which is determined by the hypothesis' underlying probability
distribution. These expected utilities are unknown to the algorithm and must be estimated
from the training data.
Hypothesis ranking problems are an extension of hypothesis selection problems (Chien,
Gratch, & Burl, 1995), in which a learning system attempts to select the best alternative
from a set of hypotheses. The distinction between hypothesis ranking and hypothesis selection is that in selection the learning algorithm is interested in a single best hypothesis, while
in ranking the learning algorithm must determine the relative order of all of the hypotheses1 .
Hypothesis selection and ranking is an important aspect of many machine learning
problems. For example, the utility problem in speedup learning can be viewed as a selection
1. The algorithms and results described in this paper extend in a straightforward fashion to hybrid rankingselection problems in which the system must select and rank the top M out of N hypotheses.

376

fiEfficient Heuristic Hypothesis Ranking
problem where a single problem-solving heuristic or strategy is chosen from a larger set of
candidates. In this case, the expected utility is typically defined as the average time to solve
a problem (Gratch, 1992; Greiner & Jurisica, 1992; Minton, 1988). The attribute selection
problem in machine learning can also be viewed as a hypothesis selection problem in which
one must select the best attribute split from a set of possible attribute splits and utility
is often measured by information gain (Musick et al., 1993). In reinforcement learning, a
system must learn the appropriate action for each context, where utility is interpreted as
expected reward (Kaelbling, 1993).2
A key observation regarding each of these problems (and all learning problems, in general) is that each of them could be viewed as an optimization problem, where the utility
is the function being optimized. Then, the application of traditional (or non-traditional)
optimization methods will yield good results within the guarantees provided by the algorithm and depending on the features of the landscape being optimized. However, with the
addition of a model of sampling cost, a new degree of freedom is added to the problem.
Where the cost of samples is very high, traditional optimization algorithms will fare poorly.
Additionally, while in many of the mentioned applications the system chooses a single
alternative and never revisits the decision, there are also many cases for which a system
will want to investigate several prioritized options (either serially or in parallel), and hence
a ranking is useful. Motivation is provided by the following scenarios:



Upper and lower bounds, span: Minimax search algorithms can use metaknowledge

(such as upper and lower bounds of a node) for pruning other parts of the tree. Also,
there are times when knowing the span of the expected utilities of the candidate set is
useful (e.g., when checking for convergence conditions in an adaptive algorithm such
as a GA).



Augmenting external knowledge: Another area in which hypothesis ranking may have



The entire ranking: In some cases, the entire ranking is significant. For instance,

important applications is hypothesis selection with human supervision. When the
stochastic objective function (i.e., the hypothesis) represents only a part of the problem, the ranking can be used to augment external knowledge of the problem. For
example, engineering simulations usually capture the physical properties of the candidate designs, but usually choose to forego the details of manufacturing, logistics, and
economics.
in evolutionary algorithms, the individuals to be propagated to future generations
are often selected with likelihood that is proportionate to their rank in the current
generation (Goldberg, 1989). Another example arises in the case of search algorithms
that take advantage of node ordering heuristics, such as beam search or iterative
broadening (Ginsberg & Harvey, 1992).

In any hypothesis evaluation problem, always achieving a correct ranking is impossible
in practice, because the exact underlying probability distributions are unknown. Thus,
there is always a (perhaps vanishingly) small chance that the algorithms will be unlucky
2. Note that the analogous reinforcement learning problem is the one in which we are learning the appropriate action with immediate feedback rather than delayed feedback.

377

fiChien, Stechert, & Mutz
because only a finite number of samples can be taken. Consequently, rather than always
requiring an algorithm to output a correct ranking, we impose probabilistic criteria on the
rankings to be produced. While several families of such requirements exist, in this paper
we examine two criteria: the probably approximately correct (PAC) model for selecting
a hypothesis function that approximates well a target function (Valiant, 1984) and the
expected loss (EL) requirement frequently used in decision theory and gaming problems
(Russell & Wefald, 1992). Informally, to satisfy the PAC requirement, an algorithm must
produce a result that with high probability is close to correct (e.g., incorrect orderings will
be most likely to occur between hypotheses with similar expected utilities). The satisfy the
EL requirement, on the other hand, a bound must be established on the expected loss of
the result, where loss is the difference in utilities between two incorrectly ordered hypothese
in an incorrect ranking.
The expected utility of a hypothesis can be estimated by observing its values over a
finite set of training examples. However, to satisfy the decision criteria, an algorithm must
also be able to reason about the potential difference between the estimated and true utilities
of each hypotheses. Let Ui denote the true expected utility of hypothesis i and let U^i be
the estimated expected utility of hypothesis i. Without loss of generality, let us presume
that the proposed ranking of hypotheses is U1 > U2 >; :::; > Uk 1 > Uk .
The PAC requirement states that, for some user-specified , with probability 1 :
k^1

[(Ui + ) > MAX (Ui+1 ; :::; Uk )]

(1)

i=1

In the context of the PAC criterion, the number  is called the indifference interval and

 is the overall ranking error or total error rate. 3

The issue of how to allocate the overall ranking error among the many possible pairwise
comparisons of hypotheses is discussed in the next section.
Correspondingly, when selecting a hypothesis H1 to be the best from a set of k hypotheses H1 ; :::; Hk , let the selection loss L be as follows.
L(H1 ; fH1 ; :::; Hk g) = MAX (0; MAX (U2 ; :::; Uk )

U1 )

(2)

Then, the ranking loss RL of a ranking H1 ; :::; Hk would be:
RL(H1 ; :::; Hk ) =

k 1
X

L(Hi ; fHi+1 ; :::; Hk g)

(3)

i=1

3. The distinction betwen the true means and the estimated means (for which we use the sample means)
is a confusing one. When assessing the validity of a ranking produced by an algorithm, one would use
the true means of the distributions (if available, as in test distributions) or the most accurate estimation
possible (such as from an edxtremely large sampling of the distribution). However, a ranking algorithm
uses the estimated parameters (including sample mean) to estimate the error. For estimation of a single
mean the estimate of the mean is normally distributed around the true mean so that this usage is
justified. However, we have not proven (and indeed are unsure) whether using the estimate in more
complex ranking and selection contexts is guaranteed correct (see later section on the heuristic nture of
our algorithms).

378

fiEfficient Heuristic Hypothesis Ranking
A hypothesis ranking algorithm which obeys the expected loss requirement must produce
rankings that on average have less ranking loss than the requested expected loss bound. The
policy for loss allocation is also discussed in the next section.
As an example, consider ranking the hypotheses with expected utilities: U1 = 1:0; U2 =
0:95; U3 = 0:86. The ranking U2 > U1 > U3 is a valid PAC ranking for the indifference
interval  = 0:06 but not for  = 0:01 and the observed ranking loss is 0:05 + 0 = 0:05.
However, while the confidence in a pairwise comparison between two hypotheses is well
understood to be the complement of the probability of the comparison's result being in
error, it is less clear how to define and ensure that a desired confidence is met in the set of
comparisons required for a selection or the even more complex set of comparisons required
for a ranking. Equation 4 defines the confidence that Ui +  > Uj , when the utilities are
normally distributed with unknown and unequal variances.

pn 



 =  (U^i

j + )
^

Si

(4)

j

where  represents the cumulative standard normal distribution function, and n, U^i j ,
and S^i j are the size, sample mean, and sample standard deviation of the blocked differential
distribution4, respectively.
Likewise, computation of the expected loss for asserting an ordering between a pair of
hypotheses is well understood, but the estimation of expected loss for an entire ranking is
less clear. Equation 5 defines the expected loss for drawing the conclusion Ui > Uj , again
under the assumption of normality (see Chien et al., 1995, for further details).
EL[Ui > Uj ] =

S^i

je

U^i j 2
)
j

0:5n( ^
Si

p

2n

+

U^i

p

j

2

Z

1

U^i j pn
S^i j

e

0:5z 2

dz

(5)

In the next two subsections, we describe two interpretations for estimating the likelihood
that an overall ranking satisfies the PAC or EL requirements by estimating and combining
pairwise PAC errors or EL estimates. Each of these interpretations lends itself directly to
an algorithmic implementation as described below.
2.1 Ranking as Recursive Selection

One obvious way to determine a ranking H1 ; :::; Hk is to view ranking as recursive selection
from the set of remaining candidate hypotheses. In this view, the overall ranking error,
as specified by the desired confidence in PAC algorithms and the loss threshold in EL
algorithms, is first distributed among k 1 selection errors which are then further subdivided
into pairwise comparison errors (Figure 1). Data is then sampled until the estimates of the
pairwise comparison error (as dictated by equation 4 or 5) satisfy the bounds set by the
algorithm.
4. Note that in our approach we block, or match, examples to further reduce sampling complexity. Blocking
makes estimates by using the difference in utility between competing hypotheses on each observed example. Blocking can significantly reduce the variance in the data when the hypotheses are not independent.
The differential distribution is formed by taking the differences of the blocked individual samples to form
a new distribution. It is trivial to modify the formulas to address the cases in which it is not possible to
block data (see Moore & Lee, 1994; Chien et al., 1995, for further details).

379

fiChien, Stechert, & Mutz

H1

H2

H3

H4

H5

H2

H3

H4

H5

H3

H4

H5

H4

H5


*

Figure 1: Computing the overall error of a recursive ranking. The per-comparison errors
are summed at each level in the recursion, and the overall sum (across all levels)
is compared with the specified total error,   .

Thus, another degree of freedom in the design of recursive ranking algorithms is the
method by which the overall ranking error is ultimately distributed among individual pairwise comparisons between hypotheses. Two factors inuence the way in which we compute
error distribution. First, our model of error combination determines how the error allocated
for individual comparisons or selections combines into overall ranking error and therefore
how many candidates are available for the distribution of error.
Using Bonferroni's inequality, which asserts that the probability of a union of events is
no greater than the sum of the probabilities of the individual events5 , one would be inclined
to combine the errors additively. However, following a more conservative approach, one
can assert that because the predicted \best" hypothesis may change during sampling in the
worst case, the conclusion might dependon all possible pairwise comparisons and that the
error should be distributed among all n2 pairs of hypotheses.6
Second, our policy with respect to allocation of error among the candidate comparisons
or selections determines how samples will be distributed. For example, in some contexts, the
consequences of early selections far outweigh those of later selections. For these scenarios,
we have implemented ranking algorithms that divide overall ranking error unequally in
5. Note that this is only the simplest of the Bonferonni inequalities, which fall into clean correspondence
with the terms of the expansion of the probability of a union of events according to the principle of
inclusion and exclusion in a natural way.
6. For a discussion of this issue, see pp. 18-20 of (Gratch, 1993).

380

fiEfficient Heuristic Hypothesis Ranking
favor of earlier selections.7 Also, it is possible to divide selection error into pairwise error
unequally based on estimates of hypothesis parameters in order to reduce sampling cost
(for example, Gratch, Chien, & DeJong, 1994, allocates error rationally).
Within the scope of this paper, we only consider algorithms that: (i) combine pairwise
error into selection error additively, (ii) combine selection error into overall ranking error
additively, and (iii) allocate error equally at each level.
One disadvantage of recursive selection is that once a hypothesis has been selected, it is
removed from the pool of candidate hypotheses. This is an issue in rare cases when, while
sampling to increase the confidence of some later selection, the estimate for a hypothesis'
mean changes enough that some previously selected hypothesis no longer dominates it.
However, it remains that the original hypotheses were shown to dominate the others with
a specified level of certainty,   .
These assumptions result in the following formulations (where (U1  fU2 ; :::; Uk g) is
used to denote the error due to the action of selecting hypothesis 1 under Equation 1
from the set fH1 ; :::; Hk g and (U1  fU2 ; :::; Uk g) denotes the error due to selection loss in
situations where Equation 2 applies):
rec (U1 > U2 > ::: > Uk ) =

rec (U2 > U3 > ::: > Uk )
+ (U1  fU2 ; :::; Uk g)

(6)

where rec (Uk ) = 0 (the base case for the recursion) and the selection error is as defined
in (Chien et al., 1995):
 (U1  fU2 ; :::; Uk g) =

k
X

1;i

(7)

i=2

using Equation 4 to compute pairwise confidence.

Algorithmically, we implement this with the following pseudo-code:

ensure there are n0 samples per hypothesis
distribute the error to individual selections
while (stopping criteria has not been met)
take more samples
if (means are ordered differently than ranking)
restart the algorithm
An analogous recursive selection algorithm based on expected loss is defined as follows
ELrec (U1 > U2 > ::: > Uk ) =

ELrec (U2 > U3 > ::: > Uk )
+EL(U1  fU2 ; :::; Uk g)

(8)

where ELrec(Uk ) = 0 and the selection EL is as defined in (Chien et al., 1995):
EL(U1  fU2 ; :::; Uk g) =

k
X
i=2

7. Space constraints preclude their description here.

381

EL(U1 ; Ui )

(9)

fiChien, Stechert, & Mutz

*



1,2

H1

2,3

H2

k-1,k

H3

Hk-1



Hk

Figure 2: Computing the overall error in an adjacent ranking. Per-comparison errors between neighboring hypotheses in the proposed ranking are summed and compared
with the required total error,   .

2.2 Ranking by Adjacency Comparison

Another interpretation of ranking confidence (or loss) is that only adjacent elements in the
ranking need be compared. In this case, the overall ranking error is divided directly into
k 1 pairwise comparison errors (Figure 2). This leads to the following confidence equation
for the PAC criteria:
adj (U1 > U2 > ::: > Uk ) =

k 1
X

i;i+1

(10)

i=1

And the following equation for the EL criteria.
ELadj (U1 > U2 > ::: > Uk ) =

k 1
X

EL(Ui ; Ui+1 )

(11)

i=1

Because ranking by comparison of adjacent hypotheses does not establish dominance
or loss bounds between non-adjacent hypotheses (where the hypotheses are ordered by
observed mean utility), it has the advantage of requiring fewer comparisons than recursive
selection (and thus may require fewer samples than recursive selection). However, for the
same reason, adjacency algorithms may be less likely than the recursive selection algorithms
to bound the probability of a correct ranking (or average loss) correctly. In the case of the
PAC algorithms, this is because -dominance is not necessarily transitive. In the case of the
EL algorithms, it is because expected loss is not necessarily additive when considering two
hypothesis comparisons sharing a common hypothesis.8
8. An example where ranking loss between non-adjacent hypotheses exceeds the desired loss bound for
the ranking, even though the sum of the adjacent losses does not, occurs when the blocked differential
distribution induced by two non-adjacent hypotheses has high variance relative to an hypothesis adjacent

382

fiEfficient Heuristic Hypothesis Ranking
2.3 The Heuristic Nature of the Algorithms

Both the recusrsive selection and adjacency algorithms are heuristic in the sense that they
are not proven to statistically meet the specified decision criteria (i.e., for the PAC criteria
select a ranking that satisfies equation (1) with probability 1  and similarly for the EL
criteria average a ranking loss specified by equation (3) less than the requested bound.
Indeed, several aspects of these algorithms make it extremely dicult to prove that they
would (probabilistically) achieve the corresponding decision criteria. These aspects include:



Sharing of samples: In order to have n1 samples for a differential distribution (i.e.



Heuristic error combination: Both the recursive selection and adjacency error com-



Ignorance of lead switches and multiple comparison paths: During the sampling pro-



blocking) for H1 and H2 , it takes n1 samples of H1 and n1 samples on the the same
problems for H2 . Our algorithms further reduce the sampling cost by reusing these
samples in differential distributions comparing H1 to other hypotheses and H2 to
other hypotheses. This makes the errors derived from these samples not independent.
Hence we have traded accuracy and ease of analysis of the algorithms for heuristic
eciency. Particularly in the recursive selection approach, samples for the lowest
ranking hypothesis would have been used in k 1 differential comparisons.
bination models are heuristic means of combining pairwise errors. This is because
the pairwise errors are not independent (see above). Empirically we have observed
that the pairwise errors tend to be overestimated but the error combination function
tends to under-combine. Overall empirically the combined error estimates tend to be
reasonably accurate, as the remaining sections show.
cess, the ordering of the hypotheses may change (e.g., the ordering of sample means
may change). This means that implicitly, the decision depended on an additional
pairwise comparison that may not be reected in the final set of comparisons contributing a pairwise error. This complexity could be avoided by fixing the order of the
hypotheses after n0 samples. However, this would require more samples as is would
involve showing -dominance of a hypothesis over a higher sample mean hypothesis
(indeed, it may never converge). We choose to ignore this complexity and base the
combined error used in the stopping condition on the final ordering.

Use on non-normal distributions: In many of the applications described in the re-

mainder of this article, the real-world data is distributed in a manner not very simlar
to normal distributions (we further investigate this issue later in the article). The
algorithms we describe are heuristic in that they presume that the data is normally
distributed even though this is not the case.

to both (i.e., currently ranked between them). The variance of the differential distribution makes its
maximum contribution when the sample set is small, so, e.g., with 1 2 = 2, 1 2 = 2, n1 2 = 2,
2 3 = 2, 2 3 = 2, and n2 3 = 2, there exists a configuration for which 1 3 = 4, 1 3 = 8. The
expected losses are EL(H1 ; H2 ) = 2:05, EL(H2 ; H3 ) = 2:05, but EL(H1 ; H3 ) = 4:80 > 4:10.

383

fiChien, Stechert, & Mutz
2.4 Other Relevant Approaches

Most standard statistical ranking/selection approaches make strong assumptions about the
form of the problem (e.g., the variances associated with underlying utility distribution of
the hypotheses might be assumed known and equal). Among these, the method of Turnbull
and Weiss (Turnbull & Weiss, 1984) is most comparable to our PAC-based approach.9
Turnbull and Weiss' algorithm is a sequential interval-based procedure for selecting
the member of a population with the largest mean. They treat hypotheses as normally
distributed random variables of unknown mean that have unknown and possibly unequal
variance. Their algorithm also carries the additional stipulation that the hypotheses be
independent. The procedure consists of taking an initial sample of n0 observations on each
of the hypotheses and then taking samples sequentially according to their stopping criteria.
When the stopping criteria has been satisfied, the hypothesis with the highest sample mean
2
is chosen. The stopping criteria is that the inequality Snii  n1 is satisfied, where Si and
ni are the sample mean and the number of samples of the ith hypothesis and n is chosen
2
according to the indifference
interval  and the confidence level   . In particular, n = d2
R1
and d is chosen to satisfy 1 (F (y + d))k 1f (y)dy =   where F (y) and f (y) are the cumulative
distribution function and probability density function of the standard normal distribution.
While it is still reasonable to use this approach when the candidate hypotheses are not
independent, excessive statistical error or unnecessarily large training set sizes may result. In
the case that the hypotheses are truly independent, Turnbull and Weiss' technique should
be able to exploit this knowledge and outperform our methods which do not adopt this
assumption.
3. Empirical Performance Evaluation

We now turn to empirical evaluation of the hypothesis ranking techniques on both synthetic
and real-world datasets. This evaluation serves three purposes. First, it demonstrates that
the techniques perform as predicted (in terms of bounding the probability of incorrect selection or expected loss). Second, it validates the performance of the techniques as compared
to standard algorithms from the statistical literature. Third, the evaluation demonstrates
the robustness of the new approaches to real-world hypothesis ranking problems.
An experimental trial consists of solving a hypothesis ranking problem with a given
technique and a given set of problem and control parameters. We measure performance
by (1) how well the algorithms satisfy their respective criteria; and (2) the number of
samples taken or, alternatively, the cost (in seconds) of executing the algorithm. Since the
performance of these statistical algorithms on any single trial provides little information
about its overall behavior, each trial is repeated multiple times and the results are averaged
across trials. Synthetic experimental trials were repeated 500 times, while trials on the
real-world data were repeated 100 times. Because the PAC and expected loss criteria are
not directly comparable, the approaches are analyzed separately.
9. PAC-based approaches have been investigated extensively in the statistical ranking and selection literature under the topic of confidence interval based algorithms (see Haseeb, 1985, for a review of the recent
literature).

384

fiEfficient Heuristic Hypothesis Ranking
Hk

H4

H3

H2

H1

-(k-1)

-3

-2

-



utility

Figure 3: The stepped means hypothesis configuration.
3.1 Evaluation on Synthetic Datasets

Evaluation on synthetic data is used to show that: (1) the techniques correctly bound probability of incorrect ranking and expected loss as predicted when the underlying assumptions
are valid even when the underlying utility distributions are inherently hard to rank 10 , and
(2) that the PAC techniques compare favorably to the algorithm of Turnbull and Weiss in
a wide variety of circumstances.
For the synthetic datasets, the utility distributions of the hypotheses were modeled as
random variables defined on some underlying parameterized distribution. Thus, characterizing a ranking problem consists of choosing some number of hypotheses to rank and then
assigning values for parameters representing each utility distributions for these hypotheses. In our case, we model the utilities as independent normal random variables with some
mean and standard deviation. Thus, if we let k be the number of hypotheses, then each hypothesis ranking problem is described by the 2k parameters specifying the expected utility
and utility standard deviation for each hypothesis. In general, while several more parameters may be required to characterize a ranking problem fully11, the number of hypotheses
and the choices for the parameters of the utility distributions underlying these hypotheses
characterize the overall diculty of the ranking problem.
The statistical ranking and selection community uses a standard family of selection
problems with known diculty to analyze the performance of hypothesis selection strategies.
The method, called the least favorable configuration (LFC) of the population means is that
assignment of the parameters to distributions which is most likely to cause a technique to
choose a wrong hypothesis and thus provides the most severe test of the technique's abilities.
Under this configuration, all utilities are independent normally distributed variables of equal
variance. k 1 of the hypotheses have utilities with equal expectation, , and the remaining
hypothesis has expected utility  + .
Because we are interested in hypothesis ranking problems rather than selection problems,
we use a generalization of the LFC that we call stepped means. In this configuration, one
of the hypotheses is assigned expected utility  and successive hypotheses are assigned
expected utility  i for i from 1; :::; k 1 (Figure 3).
In general, problems based on the least favorable configuration become more dicult
(i.e., require more samples) when the number of hypotheses k increases, the common utility
variance 2 increases, or the difference in the means of the utility distributions decreases. In
the standard methodology, a technique is evaluated by its ability to achieve a confidence of
10. Configurations that contain hypotheses with high variance relative to the separation between their means
are more dicult to rank.
11. For instance, when samples are allocated rationally in (Chien et al., 1995), it becomes necessary to assign
parameters to a cost distribution as well, or if only a few of the candidate hypotheses were to be ranked,
the number of hypotheses to rank would be another problem parameter.

385

fiChien, Stechert, & Mutz
correct selection   using several settings for k and  . This last ratio combines  and  into
a single quantity which, as it increases, makes the problem more dicult. This methodology
extends to stepped means directly.
The hypothesis ranking strategies themselves have algorithm control parameters that
govern how they attack a problem. The PAC techniques have three control parameters: an
initial sample size n0 , a desired confidence of correct ranking   and an indifference setting
12 . The expected loss techniques have two control parameters: an initial sample size n0
and a loss threshold H  .
The observed number of samples required and achieved accuracy of the PAC techniques
on the stepped means configuration are shown in Table 3.1. The results indicate that all
systems are roughly comparable in the number of examples required to choose a hypotheses.
As expected, the number of examples increases with k,   , and  . The P ACadj algorithm
required the least number of samples but was inconsistent in meeting the desired accuracy
bound (as indicated by its failure to meet the prescribed error bound in several cases). It is
interesting that the Turnbull and Weiss method did not significantly outperform the PAC
techniques despite the fact that the algorithm assumes that the hypotheses are independent
(as is the case in the stepped means configuration), while the PAC approaches do not make
this assumption. In this comparison, the principal performance metric is the number of
samples required to achieve the requested ranking, both methods were effective at achieving
the requested accuracy.
In the expected loss experiments, we ran the expected loss hypothesis ranking algorithms
on the same stepped means configurations described above with a range of expected loss
bounds. Table 3.1 shows the results of this experiment, displaying the number of samples
required to produce a ranking and the average observed loss for each configuration. These
results show that the ELrec algorithm correctly bounded the loss and that the ELadj algorithm required less samples than the ELrec algorithm, but did not correctly bound the
expected loss (since the observed loss was greater than the loss bound H  .13
3.2 Evaluation on Real Datasets

The test of real-world applicability is based on data drawn from several datasets relating
to spacecraft design and the processing of science data gathered in the context of planetary
exploration. The first two datasets we investigate relate to spacecraft design optimization
problems in which the hypotheses we wish to rank are candidate solutions to the design
problem. The third and last dataset we examine involves ranking various lossless image
compression approaches based on their performance on a large set of terrestrial images collected by the spacecraft Galileo. Cost of evaluation is given in seconds for all empirical data
12. Note that in our formulation of the stepped means test for the PAC approaches,  is both the difference
in the expected mean of successive hypotheses and the indifference interval of the algorithm. Thus, 
plays the roles of both problem parameter and control parameter here.
13. One confusing point is that for identical hypothesis and ranking algorithm settings, one can observe a
lower loss when ranking a larger number of hypotheses. This is because the algorithm first divides the
loss over the number of pirwise comparisons. Thus, for the same overall error (or expected loss bound),
with more hypotheses, the pairwise expected error (or loss) will be smaller if there are more hypotheses.
The ranking loss is defined previously. Thus, it is possible for the observed loss to increase or decrease
compared to the same settings with fewer hypotheses.

386

fiEfficient Heuristic Hypothesis Ranking

k
3
3
3
3
3
3
5
5
5
5
5
5
10
10
10
10
10
10



0.75
0.75
0.90
0.90
0.95
0.95
0.75
0.75
0.90
0.90
0.95
0.95
0.75
0.75
0.90
0.90
0.95
0.95




2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3

TURNBULL
62 (0.88)
117 (0.89)
97 (0.96)
183 (0.99)
130 (0.97)
231 (0.96)
177 (0.83)
321 (0.95)
245 (0.98)
445 (0.98)
299 (0.98)
541 (0.98)
558 (0.92)
1,015 (0.94)
700 (0.97)
1,254 (0.97)
821 (1.00)
1,462 (0.99)

P ACrec

55 (0.95)
101 (0.86)
86 (0.94)
152 (0.96)
122 (0.97)
204 (0.95)
165 (0.95)
314 (0.93)
245 (0.97)
409 (0.91)
294 (0.98)
538 (0.98)
624 (0.91)
1,042 (0.95)
742 (0.96)
1,359 (0.97)
877 (0.97)
1,569 (0.98)

P ACadj

38 (0.78)
49 (0.80)
58 (0.92)
96 (0.89)
89 (0.97)
146 (0.94)
105 (0.87)
161 (0.75)
163 (0.91)
290 (0.92)
216 (1.00)
377 (0.92)
345 (0.85)
635 (0.83)
523 (0.91)
883 (0.90)
661 (0.94)
1,164 (0.93)

Table 1: Estimated expected total number of observations by PAC algorithms in the
stepped means configuration. Achieved probability of correct ranking is shown
in parenthesis.

Parameters
k  H
3 2 1.0
3 2 0.75
3 2 0.5
3 2 0.25
5 2 1.0
5 2 0.75
5 2 0.5
5 2 0.25
10 2 1.0
10 2 0.75
10 2 0.5
10 2 0.25

ELrec

Samples
96
102
139
235
320
343
464
575
1,136
1,325
1,533
1,856

Loss
0.6
0.5
0.2
0.1
0.7
0.4
0.4
0.2
0.5
0.5
0.3
0.1

ELadj

Samples
43
56
73
139
140
169
247
350
572
668
872
1,153

Loss
1.2
1.0
0.6
0.4
1.3
1.2
0.7
0.5
1.4
1.1
0.7
0.4

Table 2: Estimated expected total number of observations of EL algorithms in stepped
means configuration. Observed average loss of produced rankings.

387

fiChien, Stechert, & Mutz
because, unlike the synthetic problems, the cost of sampling a hypothesis is not constant in
these domains. Table 3 gives a summary of the three ranking problems we considered.
Dataset
DS-2 Penetrator

fixed parameters
penetrator diameter
penetrator length

DS-2 Aeroshell

fore body overlap
nose cone angle
bluntness ratio
fillet radius
outer diameter
tail geometry
compression method

Lossless Image Comp.

random variables
impact orientation
impact velocity
soil density
stagnation pressure coef.

optimization criteria
maximize penetration probability
maximize penetration depth

randomly selected test image

maximize compression ratio

minimize weight
achieve target entry velocity

Table 3: Description of datasets used for algorithm evaluation.

3.2.1 DS-2 Penetrator

The goal of the New Millennium Deep Space Two (DS-2) mission is to deliver a pair of
microprobes to the planet Mars for scientific study of the Martian soil. The probes will
be released from orbit, travel through the Martian atmosphere, and embed themselves in
the soil near the southern polar ice cap. The primary science objectives for the mission are
(Balacuit., 1997):





to determine if ice is present below the surface of Mars,
to measure the local atmospheric pressure,
and to characterize the thermal properties of the Martian subsurface soil.

The goal of this spacecraft design problem is to determine a good set of physical dimensions for the penetrator|a small, robust probe designed to impact the surface at extremely
high velocity and to operate in the extreme cold. Specifically, we use design and simulation
data from the DS-2 mission penetrator design.
For our casting of the design problem, we hold the shape of the penetrator constant and
generate design candidates based on different values for the variables of penetrator diameter
and length. For a specific design a sample is taken by acquiring impact orientation, impact
velocity, and soil density from a parameterized multivariate distribution and then calling a
complex physical simulation to determine if and to what depth the penetrator bored into
the Martian surface. The goal of the penetrator design problem is to determine the physical
dimensions of the penetrator that maximize the probability of penetration, and in cases of
penetration, maximize penetration depth.
Tables 4 and 5 show the results of applying the PAC-based, Turnbull, and expected loss
algorithms to a ranking problem in which the system is requested to rank 10 penetrator
designs.14 In this problem the utility function is the depth of penetration of the penetrator,
14. \True" expected utility values were computed by performing 20,000 samples and using the sample mean
for this large sample as ground truth. These expected utilities were then used to compute PAC -validity
of rankings and observed loss using the provided definitions.

388

fiEfficient Heuristic Hypothesis Ranking
with those cases in which the penetrator does not penetrate being assigned zero utility. As
shown in Table 4, both PAC algorithms significantly outperformed the Turnbull algorithm,
which is to be expected because the hypotheses are somewhat correlated (via impact orientations and soil densities). Table 5 shows that the ELrec expected loss algorithm effectively
bounded actual loss but the ELadj algorithm was inconsistent.
k
10
10
10



0.75
0.90
0.95




2
2
2

TURNBULL
534 (0.96)
667 (0.98)
793 (0.99)

P ACrec

144 (1.00)
160 (1.00)
177 (1.00)

P ACadj

92 (0.98)
98 (1.00)
103 (0.99)

Table 4: Estimated expected total number of observations to rank DS-2 spacecraft designs.
Achieved probability of correct ranking is shown in parenthesis.

Parameters
k
H
10
0.10
10
0.05
10
0.02

ELrec

Samples
152
200
378

Loss
0.05
0.03
0.03

ELadj

Samples
77
90
139

Loss
0.14
0.06
0.03

Table 5: Estimated expected total number of observations and expected loss of an incorrect
ranking of DS-2 penetrator designs.

3.2.2 DS-2 Aeroshell Design Ranking

The objective of this problem is to design an aeroshell for the soil penetrator described in
the previous section that gives the appropriate entry velocity with minimum weight. Design
candidates are defined by six continuous variables that represent various geometric quantities: the extent to which the fore body overlaps the aftbody, nose cone angle, bluntness
ratio, fillet radius, outer diameter, and the tail geometry. Candidate designs (hypotheses)
are evaluated by running a simple physical simulation of the aeroshell's behavior. Such a
sample is taken by running the simulation with the fixed design variables of the hypothesis
and a value for the stagnation pressure coecient taken from a normal distribution. The
simulation computes values for the achieved entry velocity and the mass of the aeroshell;
then the weighted sum of the reciprocals of these values is maximized.
We give the results of ranking three, five, and ten hypotheses using the Turnbull, PAC,
and expected loss algorithms in Tables 6 and 7.15
As in the previous experiment, the PAC-based algorithms outperformed the Turnbull
algorithm in all cases. While the P ACadj algorithm represents a significant increase in
15. Again, deep sampling (500 samples) was performed to obtain the \correct" ranking, against which these
algorithms are compared.

389

fiChien, Stechert, & Mutz
performance here, we note that it did not achieve the desired level of confidence in all cases;
both the Turnbull and P ACrec algorithms did achieve the required confidence.

k
3
3
3
3
3
3
5
5
5
5
5
5
10
10
10
10
10
10



0.75
0.75
0.90
0.90
0.95
0.95
0.75
0.75
0.90
0.90
0.95
0.95
0.75
0.75
0.90
0.90
0.95
0.95




2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3

TURNBULL
8.9 (1.00)
22.9 (1.00)
17.1 (1.00)
38.2 (1.00)
22.6 (1.00)
52.0 (1.00)
29.1 (0.92)
69.0 (1.00)
42.4 (0.99)
94.7 (0.99)
51.9 (0.98)
117.9 (0.99)
84.0 (0.99)
196.6 (1.00)
112.0 (0.98)
252.9 (0.99)
129.1 (1.00)
315.7 (1.00)

P ACrec

8.4 (1.00)
11.3 (1.00)
14.0 (1.00)
18.6 (1.00)
21.6 (1.00)
32.1 (1.00)
20.1 (0.94)
33.9 (0.96)
30.0 (0.93)
54.8 (0.96)
43.6 (1.00)
81.5 (0.99)
42.0 (0.94)
57.9 (0.96)
53.8 (0.98)
85.5 (1.00)
61.3 (0.97)
125.7 (1.00)

P ACadj

3.5 (1.00)
3.8 (1.00)
7.1 (1.00)
7.2 (1.00)
7.1 (1.00)
7.3 (1.00)
11.8 (0.91)
11.7 (0.91)
11.7 (0.91)
11.8 (0.84)
11.7 (0.91)
11.5 (0.92)
22.1 (0.92)
22.1 (0.90)
22.6 (0.89)
21.6 (0.91)
20.6 (0.90)
20.4 (0.92)

Table 6: Estimated expected cost (in seconds) to rank aeroshell designs. Achieved probability of correct ranking is shown in parenthesis.

Parameters
k
H
3
20
3
30
3
40
5
20
5
30
5
40
10
20
10
30
10
40

ELrec

Execution Cost
9.5
7.6
7.3
21.7
18.1
15.0
55.3
42.6
38.2

Loss
4.3
3.4
4.1
7.0
12.0
9.3
9.7
8.9
10.4

ELadj

Execution Cost
7.9
7.3
6.9
7.2
6.4
10.5
18.3
14.2
13.1

Loss
3.4
3.7
2.7
8.6
12.4
8.5
7.9
9.8
9.6

Table 7: Estimated expected cost (in seconds) and expected loss of an incorrect ranking of
DS-2 aeroshell designs.

390

fiEfficient Heuristic Hypothesis Ranking
3.2.3 Lossless Image Compression on Galileo Image Data

This problem utilizes a large set of raw image data acquired by the Galileo spacecraft. Each
of the images is 256 by 256 in size and is made up of greyscale pixels ranging from 0 to 255 in
intensity. The goal is to select the lossless compression method16 that performs best on this
class of images. The performance of an image compression algorithm on a particular image
could be measured in a number of ways. For example, execution time, compression ratio,
and image quality (in the case where lossy compression methods are being considered) could
define algorithm performance. In our tests we chose to consider only the compression ratio
achieved by a given compression method as our utility function. To sample each method
(hypothesis), an image is randomly selected, the method is applied to that image, and the
achieved compression ratio is recorded.
Given below (Tables 8 and 9) are the results of ranking three, five, and seven hypotheses
using the Turnbull, PAC, and expected loss algorithms. Ranking correctness was determined
by comparison to a \correct" ranking established by sampling each compression method on
a set of 1500 distinct images.
We again note the substantial performance improvement the PAC-based algorithms
have over the Turnbull algorithm. Although both the Turnbull algorithm and the PAC
algorithms (Table 8) achieved the desired confidence level, the adjacent version of the EL
algorithm (Table 9) failed to bound the loss to the specified level in over half the cases.
It is interesting to consider the results presented in this section in light of the fact that
each of the statistical techniques being used makes some form of normality assumption. In
fact, all three of the problem domains we investigate have some number of hypotheses whose
utility functions are not normally distributed. From past experience it is known that utility
functions in the DS-2 Penetrator domain (Section 3.2.1) are highly non-normal; Figure 4
illustrates the difference between data that is normally distributed and data that is not.
0.08

0.12

0.07
0.1
0.06
0.08
0.05

0.04

0.06

0.03
0.04
0.02
0.02
0.01

0
0.2

0
0.3

0.4

0.5

0.6

0.7

0.8

0

50

100

150

200

250

300

350

400

450

500

Figure 4: A comparison of (a) data that is normally distributed with high likelihood and (b)
data that is very likely not normally distributed. In each case, the histogram of
experimental data is shown in solid boxes; data drawn from a normal distribution
with the same mean and standard deviation is shown with dashed lines.
To determine the extent to which the utilities of hypotheses in the remaining two domains are normally distributed we applied the Kolmogorov-Smirnov test (see Appendix A
16. The seven compression methods we considered were: CALIC, lossless JPEG, GIF, TIFF, pack, gzip, and
compress.

391

fiChien, Stechert, & Mutz

k
3
3
3
3
3
3
5
5
5
5
5
5
7
7
7
7
7
7



0.90
0.90
0.95
0.95
0.99
0.99
0.90
0.90
0.95
0.95
0.99
0.99
0.90
0.90
0.95
0.95
0.99
0.99




2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3
2
3

TURNBULL
62.8 (1.00)
150.8 (1.00)
84.6 (1.00)
206.8 (1.00)
142.0 (1.00)
359.4 (1.00)
134.7 (1.00)
329.9 (1.00)
176.1 (1.00)
399.8 (1.00)
249.3 (1.00)
598.1 (1.00)
210.8 (1.00)
499.3 (1.00)
250.3 (1.00)
608.7 (1.00)
339.6 (1.00)
813.7 (1.00)

P ACrec

30.1 (1.00)
30.5 (1.00)
28.6 (1.00)
29.0 (1.00)
30.1 (1.00)
30.6 (1.00)
39.5 (1.00)
39.9 (1.00)
39.3 (1.00)
39.3 (1.00)
39.2 (1.00)
39.2 (1.00)
35.6 (1.00)
35.7 (1.00)
37.4 (1.00)
36.0 (1.00)
36.5 (1.00)
37.2 (1.00)

P ACadj

14.8 (1.00)
14.8 (1.00)
15.0 (1.00)
20.5 (1.00)
23.3 (1.00)
23.2 (1.00)
29.9 (1.00)
30.0 (1.00)
29.8 (1.00)
29.6 (1.00)
29.9 (1.00)
30.7 (1.00)
37.2 (1.00)
34.5 (1.00)
35.6 (1.00)
35.0 (1.00)
34.5 (1.00)
35.3 (1.00)

Table 8: Estimated expected cost (in seconds) to rank lossless image compression approaches on Galileo image data. Achieved probability of correct ranking is shown
in parenthesis.

Parameters
k
H
3
10
3
5
3
1
5
10
5
5
5
1
7
10
7
5
7
1

ELrec

Execution Cost
31.7
32.5
33.7
80.6
83.5
101.0
99.5
105.7
119.8

Loss
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0
0.0

ELadj

Execution Cost
24.9
24.9
24.9
32.7
33.7
32.3
42.3
33.3
30.4

Loss
0.0
0.0
0.0
17.4
69.4
49.4
17.4
34.7
86.8

Table 9: Estimated expected cost (in seconds) and expected loss of an incorrect ranking of
DS-2 penetrator designs.

392

fiEfficient Heuristic Hypothesis Ranking
for details). The test determined that none of the ten hypotheses from the DS-2 Aeroshell
domain (Section 3.2.2) had normally distributed utility. Additionally, only two of the seven
hypotheses from the image compression domain (Section 3.2.3) were shown to have greater
than 90% likelihood of having normally distributed utility functions17. For these reasons,
evaluating the ranking strategies on these datasets provides a particularly strong test of the
applicability of the techniques.
We draw the reader's attention to the particularly large disparity in performance between
the Turnbull algorithm and the PAC-based algorithms in the image compression domain,
especially apparent when the number of hypotheses, and the confidence level, are high.
Additionally, this problem domain has two hypotheses with normally distributed utility
and five that are non-normal. These observations suggest that the PAC-based algorithms
perform better (in relative terms) when faced with a domain that violates the assumption
of normality.
4. Discussion and Conclusions

There are a number of areas of related work. First, there has been considerable analysis of
hypothesis selection problems. Selection problems have been formalized using a Bayesian
framework (Moore & Lee, 1994; Rivest & Sloan, 1988) that does not require an initial
sample, but uses a rigorous encoding of prior knowledge. Howard (Howard, 1970) also
details a Bayesian framework for analyzing learning cost for selection problems. If one
uses a hypothesis selection framework for ranking, allocation of pairwise errors can be
performed rationally (Gratch et al., 1994). Reinforcement learning work (Kaelbling, 1993)
with immediate feedback can also be viewed as a hypothesis selection problem.
The framework presented invites future work in a number of directions. Currently, the
stopping criteria used are relaxations of the ranking requirement. Another approach that
could be used is to bound the resources available for ranking. Limiting the number of
samples where sample cost is high and limiting the time of computation (so that we have
an anytime algorithm) are two straightforward application areas.
Another area for future work is discovery of composite strategies or hypotheses. Thus
far we have examined ranking (and in other articles, selection) of a hypothesis with highest expected value over an entire distribution. For example, learning a scheduling control
strategy that will do well over a distribution of problems. However, it is likely that for
most distributions of problems, there exists a composite strategy which would outperform
any single strategy. For example, a single strategy might be to apply method A to solve
a problem. A composite strategy would be, test the problem for feature X, if X true apply method A, else apply method B. These composite strategies correspond to algorithm
portfolios as named in Operations Research. Indeed the results of applying methods could
also be viewed as strategies. One might have the composite strategy of trying method A
for 10 CPU seconds, then if that fails trying method B. Of course, in all these composition and portfolio approaches, the diculty iseciently proposing and evaluating plausible
compositions. For even a small set of base strategies the number of copositions is enormous.
17. For reference, the data in Figure 4 (a) was normally distributed with 97.5% likelihood, according to the
Kolmogorov-Smirnov test.

393

fiChien, Stechert, & Mutz
In summary, this paper has described the hypothesis ranking problem, an extension to
the hypothesis selection problem. We defined the application of two decision criteria, probably approximately correct and expected loss, to this problem. We then defined two families of
algorithms, recursive selection and adjacency, for solution of hypothesis ranking problems.
Finally, we demonstrated the effectiveness of these algorithms on both synthetic and realworld datasets, documenting improved performance over existing statistical approaches.
Acknowledgments

This work was performed by the Jet Propulsion Laboratory, California Institute of Technology, under contract with the National Aeronautics and Space Administration.
Appendix A. Applying the K-S Test to Real Datasets

The Kolmogorov-Smirnov Test is a statistical means of accepting, with a certain level of
confidence, the hypothesis that some sampleset fits a parametric distribution with a given
set of parameters. The method compares the CDF generated by the empirical distribution
to that of the corresponding parametric distribution (i.e., with estimated parameters). The
K-S test gives a confidence based on the maximum, D, of the discrepancies between these
two CDFs:
D = maxjF1 (x)

F2 (x)j

For our purposes we wish to determine, for each hypothesis in a given domain, whether
the values of the utility function are normally distributed or not. In each case, half of the
utility samples taken are used to compute the mean and standard deviation of the normal;
the remaining half are used to compute the CDF.
A.1 DS-2 Penetrator

20000 samples taken.
design number
1
2
3
4
5
6
7
8
9
10

maxjF1 (x)

F2 (x)j
0.1415
0.1202
0.1020
0.1261
0.1207
0.1261
0.1020
0.1493
0.1461
0.1261

394

normally distributed?
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely
 90% likely

fiEfficient Heuristic Hypothesis Ranking
A.2 DS-2 Aeroshell Design Ranking

500 samples taken.
design number
1
2
3
4
5
6
7
8
9
10

maxjF1 (x)

F2 (x)j

0.08
0.08
0.08
0.08
0.08
0.08
0.08
0.08
0.08
0.08

normally distributed?
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely
< 90% likely

A.3 Lossless Image Compression on Galileo Image Data

200 samples taken.
compression method
gif
compress
calic
gzip
jpegls
pack
tiff

maxjF1 (x)

F2 (x)j

0.10
0.14
0.19
0.09
0.18
0.12
0.11

normally distributed?
90% likely
< 90% likely
 90% likely
97.5% likely
 90% likely
< 90% likely
< 90% likely

References

Balacuit., C. P. (1997). Deep Space 2 { Mars Microprobe Home Page (mission objectives
statement). Tech. rep. http://nmp.jpl.nasa.gov/ds2, NASA/JPL.
Chien, S. A., Gratch, J. M., & Burl, M. C. (1995). On the Ecient Allocation of Resources
for Hypothesis Evaluation: A Statistical Approach. IEEE Trans. Pattern Analysis
and Machine Intelligence, 17 (7), 652{665.
Chien, S. A., Stechert, A. D., & Mutz, D. H. (1998). Ecient Heuristic Ranking of Hypotheses. In Advances in Neural Information Processing Systems 10 (Jordan, Kearns,
and Solla eds.), pp. 444{450 Denver, Colorado. NIPS.
Ginsberg, M., & Harvey, W. (1992). Iterative Broadening. Artificial Intelligence Journal,
55, 367{383.
395

fiChien, Stechert, & Mutz
Goldberg, D. (1989). Genetic Algorithms in Search, Optimization, and Machine Learning.
Addison-Wesley.
Gratch, J. (1992). COMPOSER: A Probabilistic Solution to the Utility Problem in Speed-up
Learning. In Proceedings of the Tenth National Conference on Artificial Intelligence,
pp. 235{240 San Jose, CA. AAAI.
Gratch, J. (1993). COMPOSER: A Decision-theoretic Approach to Adaptive Problem Solving. Tech. rep. UIUCDCS-R-93-1806, Department of Computer Science, University of
Illinois.
Gratch, J., Chien, S., & DeJong, G. (1994). Improving Learning Performance Through
Rational Resource Allocation. In Proceedings of the Twelfth National Conference on
Artificial Intelligence, pp. 576{582 Seattle, WA. AAAI.
Greiner, R., & Jurisica, I. (1992). A Statistical Approach to Solving the EBL Utility
Problem. In Proceedings of the Tenth National Conference on Artificial Intelligence,
pp. 241{248 San Jose, CA. AAAI.
Haseeb, R. M. (1985). Modern Statistical Selection. American Sciences Press, Columbus,
OH.
Howard, R. A. (1970). Decision Analysis: Perspectives on Inference, Decision, and Experimentation. Proceedings of the IEEE, 58 (5), 823{834.
Kaelbling, L. P. (1993). Learning in Embedded Systems. MIT Press, Cambridge, MA.
Minton, S. (1988). Learning Search Control Knowledge: An Explanation-Based Approach.
Kluwer Academic Publishers, Norwell, MA.
Moore, A. W., & Lee, M. S. (1994). Ecient Algorithms for Minimizing Cross-Validation
Error. In Proceedings of the International Conference on Machine Learning New
Brunswick, MA.
Musick, R., Catlett, J., & Russell, S. (1993). Decision Theoretic Subsampling for Induction on Large Databases. In Proceedings of the International Conference on Machine
Learning, pp. 212{219 Amherst, MA.
Rivest, R. L., & Sloan, R. (1988). A New Model for Inductive Inference. In Proceedings of
the Second Conference on Theoretical Aspects of Reasoning about Knowledge.
Russell, S., & Wefald, E. (1992). Do the Right Thing: Studies in Limited Rationality. MIT
Press, Cambridge, MA.
Tadepalli, P. (1992). A theory of unsupervised speedup learning. In Proc. of the Tenth
National Conference on Artificial Intelligence, pp. 229{234 San Jose, CA. AAAI.
Turnbull, B. W., & Weiss, L. I. (1984). A Class of Sequential Procedures for k-sample
Problems Concerning Normal Means with Unknown Equal Variances. In Santner,
T. J., & Tamhane, A. C. (Eds.), Design of Experiments: Ranking and Selection, pp.
225{240. Marcel Dekker.
396

fiEfficient Heuristic Hypothesis Ranking
Valiant, L. G. (1984). A Theory of the Learnable. Communications of the ACM, 27,
1134{1142.

397

fiJournal of Artificial Intelligence Research 10 (1999) 1-38

Submitted 4/98; published 1/99

Order of Magnitude Comparisons of Distance
Ernest Davis

davise@cs.nyu.edu

Courant Institute
New York, NY 10012 USA

Abstract
Order of magnitude reasoning | reasoning by rough comparisons of the sizes of quantities | is often called \back of the envelope calculation", with the implication that the
calculations are quick though approximate. This paper exhibits an interesting class of constraint sets in which order of magnitude reasoning is demonstrably fast. Specifically, we
present a polynomial-time algorithm that can solve a set of constraints of the form \Points
a and b are much closer together than points c and d." We prove that this algorithm can be
applied if \much closer together" is interpreted either as referring to an infinite difference in
scale or as referring to a finite difference in scale, as long as the difference in scale is greater
than the number of variables in the constraint set. We also prove that the first-order theory
over such constraints is decidable.
1. Introduction
Order of magnitude reasoning | reasoning by rough comparisons of the sizes of quantities |
is often called \back of the envelope calculation", with the implication that the calculations
are quick though approximate. Previous AI work on order of magnitude reasoning, however,
has focussed on its expressive power and inferential structure, not on its computational
leverage (Raiman, 1990; Mavrovouniotis and Stephanopoulos, 1990; Davis, 1990; Weld,
1990).
In this paper we exhibit an interesting case where solving a set of order of magnitude
comparisons is demonstrably much faster than solving the analogous set of simple order
comparisons. Specifically, given a set of constraints of the form \Points a and b are much
closer together than points c and d," the consistency of such a set can be determined in
low-order polynomial time. By contrast, it is easily shown that solving a set of constraints
of the form \The distance from a to b is less than or equal to the distance from c to d" in
one dimension is NP-complete, and in higher dimensions is as hard as solving an arbitrary
set of algebraic constraints over the reals.
In particular, the paper presents the following results:
1. The algorithm \solve constraints(S )" solves a system of constraints of the form \Points
a and b are infinitely closer than points c and d" in polynomial time (Section 5).
2. An improved version of the algorithm runs in time O(max(n2 ff(n)); ne; s) where n is
the number of variables, ff(n) is the inverse Ackermann's function, e is the number of
edges mentioned in the constraint set, and s is the size of the constraint set. (Section
6.1).
3. An extended version of the algorithm allows the inclusion of non-strict constraints of
the form \Points a and b are not infinitely further apart than points c and d." The
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiDavis

running time for this modified algorithm is slower than that of solve constraints, but
still polynomial time. (Section 6.2)
4. A different extension of the algorithm allows the combination of order of magnitude
constraints on distances with order comparisons on the points of the form \Point a
precedes point b." (Section 6.3)
5. The same algorithm can be applied to constraints of the form \The distance from a
to b is less than 1=B times the distance from c to d," where B is a given finite value,
as long as B is greater than the number of variables in the constraint set. (Section 7)
6. The first-order theory over such constraints is decidable. (Section 8)
As preliminary steps, we begin with a small example and an informal discussion (Section
2). We then give a formal account of order-of-magnitude spaces (Section 3) and present
a data structure called a cluster tree, which expresses order-of-magnitude distance comparisons (Section 4). We conclude the paper with a discussion of the significance of these
results (Section 9).

2. Examples
Consider the following inferences:

Example 1: I wish to buy a house and rent oce space in a suburb of Metropolis. For
obvious reasons, I want the house to be close to the school, the house to be close to the
oce, and the oce to be close to the commuter train station. I am told that in Elmville
the train station is quite far from the school, but in Newton they are close together.
Infer that I will not be able to satisfy my constraints in Elmville, but may be able to
in Newton.
Example 2: The Empire State Building is much closer to the Washington Monument than
to Versailles. The Statue of Liberty is much closer both to the Empire State Building and
to Carnegie Hall than to the Washington Monument.
Infer that Carnegie Hall is much closer to the Empire State Building than to Versailles.
Example 3: You have to carry out a collection of computational tasks covering a wide
range of diculty. For instance
a.
b.
c.
d.
e.
f.

Add up a column of 100 numbers.
Sort a list of 10,000 elements.
Invert a 100  100 matrix.
Invert a 1000  1000 matrix.
Given the O.D.E. x = cos(et x), x(0) = 0, find x(20) to 32-bit accuracy.
Given a online collection of 1,000 photographs in GIF format, use state-ofthe-art image recognition software to select all those that show a man on
horseback.

2

fiOrder of Magnitude Comparisons of Distance

g. Do a Web search until you have collected 100 pictures of men on horseback,
using state-of-the-art image recognition software.
h. Using state-of-the-art theorem proving software, find a proof that the medians of a triangle are concurrent.
i. Using state-of-the-art theorem proving software, find a proof of Fermat's
little theorem.
It is plausible to suppose that, in many of these cases, you can say reliably that one
task will take much longer than another, either by a human judgment or using an expert
system. For instance, task (a) is much shorter than any of the others. Task (b) is much
shorter than any of the others except (a) and possibly (h). Task (c) is certainly much
shorter than (d), (f), (g), or (i). However, with certain pairs such as (c) and (h) or (c) and
(e) it would be dicult to guess whether one is much shorter than another, or whether they
are of comparable diculty.
You have a number of independent identical computers, of unknown vintage and characteristics, on which you will schedule tasks of these kinds. Note that, under these circumstances, there is no way to predict the absolute time required by any of these tasks within a
couple of orders of magnitude. Nonetheless, the comparative lengths presumably still stand.
Given: a particular schedule of tasks on machines, infer what you can about the relative
order of completion times. For example, given the following schedule
Machine M1: tasks a,b,h,d.
Machine M2: tasks c,i.
it should be possible to predict that (a) and (b) will complete before (c); that (c) will
complete before (d); and that (d) will complete before (i); but it will not be possible to
predict the order in which (c) and (h) will complete.
In all three examples, the given information has the form \The distance between points
W and X is much less than the distance between Y and Z ". In examples 1 and 2, the
points are geometric. In example 3, the points are the start and completion times of the
various tasks, and the constraints on relative lengths can be put in the form \The distance
from start(a) to end(a) is much less than the distance from start(c) to end(c)", and so on.
In example 3, there is also ordering information: the start of each task precedes its end; the
end of (a) is equal to the start of (b); and so on. The problem is to make inferences based
on this weak kind of constraint.
It should be noted that these examples are meant to be illustrative, rather than serious applications. Example 1 does not extend in any obvious way to a class of natural,
large problems. Example 2 is implausible as a state of knowledge; how does the reasoner
find himself knowing just the order-of-magnitude relations among distances and no other
geometric information? Example 3 is contrived. Nonetheless, these illustrate the kinds of
situations where order-of-magnitude relations on distance do arise; where they express a
substantial part of the knowledge of the reasoner; and where inferences based purely on the
order-of-magnitude comparisons can yield useful conclusions.
The methods presented in this paper involve construing the relation \Distance D is much
shorter than distance E" as if it were \Distance D is infinitesimal as compared to distance
E." As we shall see, under this interpretation, systems of constraints over distances can be

3

fiDavis

solved eciently. The logical foundations for dealing with infinitesimal quantities lie in the
non-standard model of the real line with infinitesimals, developed by Abraham Robinson
(1965). (A more readable account is given by Keisler, 1976.) Reasoning with quantities of
infinitely different scale is known as \order of magnitude" reasoning.
The reader may ask, \Since infinitesimals have no physical reality, what is the value
of developing techniques for reasoning about them?" In none of the examples, after all, is
the smaller quantity truly infinitesimal or the larger one truly infinite. In example 1 and
2, the ratio between successive sizes is somewhere between 10 and 100; in example 3, it
is between 100 and a rather large number dicult to estimate; but one can always give
some kind of upper bound. It is essentially certain, for instance, that the ratio between the
times required for tasks (a) and (i) is less than 10100;000 . Why not use the best real-valued
estimate instead?
The first answer is that this is an idealization. Practically all physical reasoning and
calculation rest on one idealization or another: the idealization in the situation calculus
that time is discrete; the idealization that solid objects are rigid, employed in most mechanics programs; the idealization that such physical properties as density, temperature, and
pressure are continuous rather than local averages over atoms, which underlies most uses of
partial differential equations; the idealization involved in the use of the Dirac delta function;
and so on. Our idealization here that a very short distance is infinitesimally smaller than a
long one simplifies reasoning and yields useful results as long as care is taken to stay within
an appropriate range of application.
The second answer is that this is a technique of mathematical approximation, which we
are using to turn an intractable problem into a tractable one. This would be analogous to
linearizing a non-linear equation over a small neighborhood; or to approximating a sum by
an integral.
There are circumstances where we can be sure that the approximation gives an answer
that is guaranteed exactly correct; namely if the actual ratio implicit in the comparison
\D is much smaller than E " is larger than the number of points involved in the system of
constraints. This will be proven in Section 7. There is also a broader, less well-defined, class
of problems where the approximation, though not guaranteed correct, is more reliable than
some of the other links in the reasoning. For instance, suppose that one were to consider
an instance of example 3 involving a couple of hundred tasks, apply order-of-magnitude
reasoning, and come up with an answer that can be determined to be wrong. It is possible
that the error would be due to the order-of-magnitude reasoning. However, it seems safe
to say that, in most cases, the error is more likely to be due to a mistake in estimating the
comparative sizes.

3. Order-of-magnitude spaces
An order-of-magnitude space, or om-space, is a space of geometric points. Any two points
are separated by a distance. Two distances d and e are compared by the relation d  e,
meaning \Distance d is infinitesimal compared to e" or, more loosely, \Distance d is much
smaller than e."
For example, let < be the non-standard real line with infinitesimals. Let <m be the
corresponding m-dimensional space. Then we can let a point of the om-space be a point in

4

fiOrder of Magnitude Comparisons of Distance

Rm . The distance between two points a; b is the Euclidean distance, which is a non-negative
value in < . The relation d  e holds for two distances d; e, if d=e is infinitesimal.
The distance operator and the comparator are related by a number of axioms, specified
below. The most interesting of these is called the om-triangle inequality: If ab and bc are
both much smaller than xy, then ac is much smaller than xy. This combines the ordinary
triangle inequality \The distance ac is less than or equal to distance ab plus distance bc"
together with the rule from order-of-magnitude algebra, \If p  r and q  r then p+q  r."
It will simplify the exposition below if, rather than talking about distances, we talk about
orders of magnitude. These are defined as follows. We say that two distances d and e have
the same order of magnitude if neither d  e nor e  d. In < this is the condition that d=e
is finite: neither infinitesimal nor infinite. (Raiman, 1990 uses the notation \d Co e" for this
relation.) By the rules of the order-of-magnitude calculus, this is an equivalence relation.
Hence we can define an order of magnitude to be an equivalence class of distances under
the relation \same order of magnitude". For two points a; b, we define the function od(a; b)
to be the order of magnitude of the distance from a to b. For two orders of magnitude p; q,
we define p  q if, for any representatives d 2 p and e 2 q, d  e. By the rules of the orderof-magnitude calculus, if this holds for any representatives, it holds for all representatives.
The advantage of using orders-of-magnitude and the function \od", rather than distances
and the distance function, is that it allows us to deal with logical equality rather than the
equivalence relation \same order of magnitude".
For example, in the non-standard real line, let  be a positive infinitesimal value. Then
values such as f1; 100; 2 50 + 1002 : : :g, are all of the same order of magnitude, o1. The
values f; 1:001; 3 + e 1= : : :g are of a different order of magnitude o2  o1. The values
f1=; 10= + 5 : : :g are of a third order of magnitude o3  o1.
Definition 1: An order-of-magnitude space (om-space) 
 consists of:







A set of points P ;
A set of orders of magnitude D;
A distinguished value 0 2 D;
A function \od(a; b)" mapping two points a; b 2 P to an order of magnitude;
A relation \d  e" over two orders of magnitude d; e 2 D

satisfying the following axioms:
A.1 For any orders of magnitude d; e
e  d, d = e.

2 D, exactly one of the following holds: d  e,

A.2 For d; e; f 2 D, if d  e and e  f then d  f .
(Transitivity. Together with A.1, this means that  is a total ordering on orders of
magnitude.)
A.3 For any d 2 D, not d  0.
(0 is the minimal order of magnitude.)

5

fiDavis

A.4 For points a; b 2 P , od(a; b) = 0 if and only if a = b.
(The function od is positive definite.)
A.5 For points a; b 2 P , od(a; b) = od(b; a).
(The function od is symmetric.)
A.6 For points a; b; c 2 P , and order of magnitude d 2 D,
if od(a; b)  d and od(b; c)  d then od(a; c)  d.
(The om-triangle inequality.)
A.7 There are infinitely many different orders of magnitude.
A.8 For any point a1 2 P and order of magnitude d
a2 ; a3 : : : such that od(ai ; aj ) = d for all i 6= j .

2 D, there exists an infinite set

The example we have given above of an om-space, non-standard Euclidean space, is wild
and woolly and hard to conceptualize. Here are two simpler examples of om-spaces:
I. Let  be an infinitesimal value. We define a point to be a polynomial in  with integer
coecients, such as 3 + 5 85 . We define an order-of-magnitude to be a power of . We
define m  n if m > n; for example, 6  4 . We define od(a; b) to be the smallest power
of  in a b. For example, od(1 + 2 33 ; 1 52 + 44 ) = 2 .
II. Let N be an infinite value. We define a point to be a polynomial in N with integer
coecients. We define an order of magnitude to be a power of N . We define N p  N q if
p < q; for example, N 4  N 6 . We define od(a; b) to be the largest power of N in a b. For
example, od(1 + N 2 3N 3 ; 1 5N 2 + 4N 4 ) = N 4 .
It can be shown that any om-space either contains a subset isomorphic to (I) or a subset
isomorphic to (II). (This is just a special case of the general rule that any infinite total
ordering contains either an infinite descending chain or an infinite ascending chain.)
We will use the notation \de" as an abbreviation for \d  e or d = e".

4. Cluster Trees
Let P be a finite set of points in an om-space. If the distances between different pairs of
points in P are of different orders of magnitude, then the om-space imposes a unique treelike hierarchical structure on P . The points will naturally fall into clusters, each cluster C
being a collection of points all of which are much closer to one another than to any point in
P outside C . The collection of all the clusters over P forms a strict tree under the subset
relation. Moreover, the structure of this tree and the comparative sizes of different clusters
in the tree captures all of the order-of-magnitude relations between any pair of points in P .
The tree of clusters is thus a very powerful data structure for reasoning about points in an
om-space, and it is, indeed, the central data structure for the algorithms we will develop in
this paper. In this section, we give a formal definition of cluster trees and prove some basic
results as foundations for our algorithms.

Definition 2: Let P be a finite set of points in an om-space. A non-empty subset C  P is
called a cluster of P if for every x; y 2 C , z 2 P C , od(x; y)  od(x; z ). If C is a cluster,
the diameter of C , denoted \odiam(C )", is the maximum value of od(x; y) for x; y 2 C .

6

fiOrder of Magnitude Comparisons of Distance

n1
5
n2

n3

4

3

n4

n5

a

d

0

3

0

0

e

g

f

b

c

0

0

0

0

0

Figure 1: Cluster tree
Note that the set of any single element of P is trivially a cluster of P . The entire set P
is likewise a cluster of P . The empty set is by definition not a cluster of P .

Lemma 1: If C and D are clusters of P , then either C
disjoint.

 D, D  C , or C and D are

Proof: Suppose not. Then let x 2 C \ D, y 2 C D, z 2 D C . Since C is a cluster,
od(x; y)  od(x; z ). Since D is a cluster, od(x; z )  od(x; y). Thus we have a contradiction.

2

By virtue of lemma 1, the clusters of a set P form a tree. We now develop a representation of the order of magnitude relations in P by constructing a tree whose nodes correspond
to the clusters of P , labelled with an indication of the relative size of each cluster.

Definition 3: A cluster tree is a tree T such that

 Every leaf of T is a distinct symbol.
 Every internal node of T has at least two children.
 Each internal node of T is labelled with a non-negative value. Two or more nodes
may be given the same value. (For the purposes of Sections 5-7, labels may be taken
to be non-negative integers; in Section 8, it will be useful to allow rational labels.)

 Every leaf of the tree is labelled 0.
 The label of every internal node in the tree is less than the label of its parent.
For any node N of T , the field \N .symbols" gives the set of symbols in the leaves in the
subtree of T rooted at N , and the field \N .label" gives the integer label on node N .

7

fiDavis

Thus, for example, in Figure 1, n3.label=3 and n3.symbols = fa; dg; n1.label = 5 and
n1.symbols = fa; b; c; d; e; f; gg.
As we shall see, the nodes of the tree T represent the clusters of a set of points, and the
labels represent the relative sizes of the diameters of the clusters.

Definition 4: A valuation over a set of symbols is a function mapping each symbol to a
point in an om-space. If T is a cluster tree, a valuation over T is a valuation over T .symbols.
If N is any node in T and is a valuation over T , we will write (N ) as an abbreviation
for (N .symbols).
We now define how a cluster tree T expresses the order of magnitude relations over a
set of points P .
Definition 5: Let T be a cluster tree and let be a valuation over T . Let P = (T ), the
set of points in the image of T under . We say that j=T (read satisfies or instantiates
T ) if the following conditions hold:
i. For any internal node N of T , (N ) is a cluster of P .
ii. For any cluster C of P , there is a node N such that C = (N ).
iii. For any nodes M and N , if M .label < N .label then odiam( (M ))  odiam( (N )).
iv. If label(M ) = 0, then odiam(M ) = 0. (That is, all children of M are assigned the
same value under .)
The following algorithm generates an instantiation
procedure

variable

given a cluster tree T :

instantiate(in T : cluster tree; 
 : an om-space)
return : array of points indexed on the symbols of T

G[N ] : array of points indexed on the nodes of T ;

Let k be the number of internal nodes in T ;
Choose 0 = 0  1  2  : : :  k to be k + 1 different orders of magnitude;
/* Such values can be chosen by virtue of axiom A.7 */
pick a point x 2 
;
G[root of T ] := x;
instantiate1(T; 
; 1 : : : k ; G);
return the restriction of G to the symbols of T .
end instantiate.
instantiate1(in N : a node in a cluster tree; 
 : an om-space; 1 : : : k : orders of magnitude;
in out G : array of points indexed on the nodes of T )
if N is not a leaf then
let C1 : : : Cp be the children of N ;
x1 := G[N ];
q := N .label;
pick points x2 : : : xp such that
for all i; j 2 1 : : : p, if i 6= j then od(xi ; xj ) = q ;
/* Such points can be chosen by virtue of axiom A.8 */
8

fiOrder of Magnitude Comparisons of Distance

for

i = 1 : : : p do
G[Ci ] := xi ;

instantiate1(Ci ; 
; 1 : : : k ; G);

endfor
endif end

instantiate1.

Thus, we begin by picking orders of magnitude corresponding to the values of the labels.
We pick an arbitrary point for the root of the tree, and then recurse down the nodes of the
tree. For each node N , we place the children at points that all lie separated by the desired
diameter of N . The final placement of the leaves is then the desired instantiation.
Lemma 2: If T is a cluster tree and 
 is an om-space, then instantiate(T; 
) returns an
instantiation of T .
The proof is given in the appendix.
Moreover, it is clear that any instantiation of T can be generated as a possible output
of instantiate(T; 
). (Given an instantiation , just pick G[N ] at each stage to be of some
symbol of N .)
Note that, given any valuation over a finite set of symbols S , there exists a cluster
tree T such that T .symbols = S and satisfies T . Such a T is essentially unique up to an
isomorphism over the set of labels that preserves the label 0 and the order of labels.

5. Constraints
In this section, we develop the first of our algorithms. Algorithm solve constraints tests
a collection of constraints of the form \a is much closer to b than c is to d," for consistency. If the set is consistent, then the algorithm returns a cluster tree that satisfies the
constraints. The algorithm builds the cluster tree from top to bottom dealing first with the
large distances, and then proceeding to smaller and smaller distances.
Let S be a system of constraints of the form od(a; b)  od(c; d); and let T be a cluster
tree. We will say that T `S (read \T satisfies S ") if every instantiation of T satisfies S . In
this section, we develop an algorithm for finding a cluster tree that satisfies a given set of
constraints.
The algorithm works along the following lines: Suppose we have a solution satisfying S .
Let D be the diameter of the solution. If S contains a constraint od(a; b)  od(c; d) then,
since od(c; d) is certainly no more than D, it follows that od(a; b) is much smaller than D.
We label ab as a \short" edge.
If two points u and v are connected by a path of short edges, then by the triangle
inequality the edge uv is also short (i.e. much shorter than D). Thus, if we compute the
connected components H of all the edges that have been labelled short, then all these edges
in H can likewise be labelled short. For example, in table 3, edges vz , wx, and xy can all
be labelled \short".
On the other hand, as we shall prove below, if an edge is not in the set H , then there is
no reason to believe that it is much shorter than D. We can, in fact, safely posit that it is
the same o.m. as D. We label all such edges \long".
We can now assume that any connected component of points connected by short edges
is a cluster, and a child of the root of the cluster tree. The root of the cluster tree is then
given the largest label. Its children will be given smaller labels. Each \long" edge now

9

fiDavis

connects symbols in two different children of the root. Hence, any instantiation of the tree
will make any long edge longer than any short edge.
If no edges are labelled \long" | that is, if H contains the complete graph over the
symbols | then there is an inconsistency; all edges are much shorter than the longest edge.
For instance, in table 4, since vw, wx, and xy are all much smaller than zy, it follows
by the triangle inequality that vy is much smaller than zy. But since we also have the
constraints that zy is much smaller than vz and that vz is much smaller than vy, we have
an inconsistency.
The algorithm then iterates, at the next smaller scale. Since we have now taken care of
all the constraints od(a; b)  od(c; d), where cd was labelled \long", we can drop all those
from S . Let D now be the greatest length of all the edges that remain in S . If a constraint
od(a; b)  od(c; d) is in the new S , then we know that od(a; b) is much shorter than D, and
we label it \short". We continue as above. The algorithm halts when all the constraints in
S have been satisfied, and S is therefore empty; or when we encounter a contradiction, as
above.
We now give the formal statement of this algorithm. The algorithm uses an undirected
graph over the variable symbols in S . Given such a graph G, and a constraint C of the
form od(a; b)  od(c; d), we will refer to the edge ab as the \short" of C , and to the edge
cd as the \long" of C . The shorts of the system S is the set of all shorts of the constraints
of S and the longs of S is the set of all the longs of the constraints. An edge may be both a
short and a long of S if it appears on one side in one constraint and on the other in another
constraint.
procedure

type:

solve constraints(in S : a system of constraints of the form od(a; b)  od(c; d))
return either a cluster tree T satisfying S if S is consistent;
or false if S is inconsistent.

A node N of the cluster tree contains
pointers to the parent and children of N ;
the field N.label, holding the integer label;
and the field N.symbols, holding the list of symbols in the leaves of N .

variables:

begin if

m is an integer;
C is a constraint in S ;
H; I are undirected graphs;
N; M are nodes of T ;

S contains any constraint of the form, \od(a; b)  od(c; c)" then return false;

m := the number of variables in S ;
initialize T to consist of a single node N ;
N .symbols:= the variables in S ;
repeat

H := the connected components of the shorts of S ;
if H contains all the edges in S then return(false) endif;
for each leaf N of T do
if not all vertices of N are connected in H then
N .label := m;
for each connected component I of N .symbols in H

10

do

fiOrder of Magnitude Comparisons of Distance

construct node M as a new child of N in T ;
M .symbols:= the vertices of I ;

endfor endif endfor

S := the subset of constraints in S whose long is in H ;
m := m 1;
until
for

S is empty;

each leaf N of T
N .label := 0;
if N .symbols has more than one symbol
then create a leaf of N for each symbol in N .symbols;
label each such leaf 0;
endif endfor end solve constraints.

Tables 3 and 4 give two examples of the working of procedure solve constraints. Table
3 shows how the procedure can be used to establish that the following constraints are
consistent:
The Empire State Building (x) is much closer to the Washington Monument (w)
than to Notre Dame Cathedral (v).
Bunker Hill (y) is much closer to the Empire State Building than to the Eiffel
Tower (z ).
The distance from the Eiffel Tower to Notre Dame is much less than the distance
from the Washington Monument to Bunker Hill.
Table 4 shows that the following inference can be justified:

Given: The distances from the Statue of Liberty (v) to the World Trade Center
(w), from the World Trade Center to the Empire State Building (x), and from
the Empire State Building to the Chrysler Building (y) are all much less than
the distance from the Chrysler Building to the Washington Monument (z ).
Infer: The Washington Monument is not much nearer to the Chrysler Building
than to the Statue of Liberty.
This inference is carried out by asserting the negation of the consequent, \The Washington Monument is much nearer to the Chrysler Building than to the Statue of Liberty," and
showing that that collection of constraints is inconsistent. Note that if we change \much
less" and \much nearer" in this example to \less" and \nearer", then the inference no longer
valid.
Theorem 1 states the correctness of algorithm solve constraints. The proof is given in
the appendix.
Theorem 1: The algorithm solve constraints(S ) returns a cluster tree satisfying S if S is
consistent, and returns false if S is inconsistent.
There may be many cluster trees that satisfy a given set of constraints. Among these,
the cluster tree returned by the algorithm solve constraints has an important property: it
has the fewest possible labels consistent with the constraints. In other words, it uses the
minimum number of different orders of magnitude of any solution. Therefore, the algorithm
can be used to check the satisfiability of a set of constraints in an om-space that violates

11

fiDavis

S contains the constraints
1. od(w; x)  od(x; v).
2. od(x; y)  od(y; z ).
3. od(v; z )  od(w; y).
The algorithm proceeds as follows:
Initialization:
The tree is initializes to a single node with n1.
n1.symbols := f v; w; x; y; z g.
First iteration:
The shorts of S are f wx; xy; vz g.
Computing the connected components, H is set to f wx; xy; wy; vz g.
n1.label := 5;
Two children of n1 are created:
n11.symbols := w; x; y ;
n12.symbols := v; z ;
As xv is not in H , delete constraint #1 from S .
As yz is not in H , delete constraint #2 from S .
S now contains just constraint #3.
Second iteration:
The shorts of S are f vz g.
The connected components H is just fvz g.
n11.label := 4;
Three children of n11 are created:
n111.symbols := w;
n112.symbols := x;
n113.symbols := z ;
As wy is not in H , delete constraint #3 from S .
S is now empty.
Cleanup:
n12.label := 0;
Two children of n12 are created:
n121.symbols := v;
n122.symbols := z ;
(See Figure 2.)
Table 1: Example of computing a cluster tree

12

fiOrder of Magnitude Comparisons of Distance

n1
0th iteration
v,w,x,y,z

n1

1st iteration

5
v,w,x,y,z
n11

n12

w,x,y

v,z

n1
2nd iteration
5
v,w,x,y,z
n11
4

n12
w,x,y
v,z

w

x

y

n1
Cleanup
5
v,w,x,y,z
n11
4

w

x

n12
w,x,y

0

y

v

Figure 2: Building a cluster tree

13

v,z

z

fiDavis

S contains the constraints
od(v; w)  od(z; y).
od(w; x)  od(z; y).
od(x; y)  od(z; y).
od(z; y)  od(v; z ).
The algorithm proceeds as follows:
Initialization:
The tree is initializes to a single node with n1.
n1.symbols := f v; w; x; y; z g.
First iteration:
The shorts of S are f vw; wx; xy; zy; vz g.
H is set to its connected components, which is the complete graph over v; w; x; y; z .
The algorithm exits returning false
Table 2: Example of determining inconsistency
axiom A.7 and has only finitely many different orders of magnitude. If the algorithm returns
T and T has no more different labels than the number of different orders of magnitude in
the space, then the constraints are satisfiable. If T uses more labels than the space has
orders of magnitude, then the constraints are unsatisfiable.
The proof is easier to present if we rewrite algorithm solve constraints in the following
form, which returns only the number of different non-zero labels used, but does not actually
construct the cluster tree.1

num labels(S );

function
if
then return
else return

S is empty

(0)
(1 + num labels(reduce constraints(S )))
function reduce constraints(S )
H := connected components of the shorts of S ;
if H contains all the edges in S then return(false) to top-level
else return(the set of constraints in S whose long is in H )

It is easily verified that the sequence of values of S in successive recursive calls to
num labels is the same as the sequence of values of S in the main loop of solve constraints.
Therefore num labels returns the number of different non-zero labels in the tree constructed
by solve constraints.
1. The reader may wonder why this simpler algorithm was not presented before the more complicated
algorithm solve constraints. The reason is that the only proof we have found that the system of constraints is consistent if num labels does not return
the constructive solve constraints.

14

false

relies on the relation between num labels and

fiOrder of Magnitude Comparisons of Distance

Theorem 2: Out of all solutions to the set of constraints S , the instantiations of
solve constraints(S ) have the fewest number of different values of od(a; b), where a; b range
over the symbols in S . This number is given by num labels(S ).
The proof is given in the appendix.

6. Extensions and Consequences
We next present a number of modifications of the algorithm solve constraints. The first
is a more ecient implementation. The second extends the algorithm to handle non-strict
comparisons. The third extend the algorithm to handle a combination of order-of-magnitude
comparisons on distance with order comparisons, in a one-dimensional space.

6.1 An Ecient Implementation of Solve constraints
It is possible to implement algorithm solve constraints somewhat more eciently than the
naive encoding of the above description. The key is to observe that the graph H of connected
components does not have to be computed explicitly; it suces to compute it implicitly using
merge-find sets (union-find sets). Combining this with suitable back pointers from edges to
constraints, we can formulate a more ecient version of the algorithm.
We use the following data structures and subroutines:

 Each node N of the cluster tree contains pointers to its parents and children; a field

N .label, holding the integer label; a field N .symbols, holding the list of symbols in
the leaves of N ; and a field N .mfsets, holding a list of the connected components of
the symbols in N . As described below, each connected component is implemented as
an merge-find set (MFSET).

 An edge E in the graph over symbols contains its two endpoints, each of which is a

symbol; a field E .shorts, a list of the constraints in which E appears as a short; and
a field E .longs, a list of the constraints in which E appears as a long.

 A constraint C has two fields, C .short and C .long, both of them edges. It also has

pointers into the lists C .short.shorts and C .long.longs, enabling C to be removed in
constant time from the constraint lists associated with the individual edges.

 We will use the disjoint-set forest implementation of MFSETs (Cormen, Leiserson,

and Rivest, 1990, p. 448) with merging smaller sets into larger and path-compression.
Thus, each MFSET is a upward-pointing tree of symbols, each node of the tree being
a symbol. The tree as a whole is represented by the symbol at the root. A symbol A
has then the following fields:

{
{
{
{

A.parent is a pointer to the parent in the MFSET tree.
A.cluster leaf is a pointer to the leaf in the cluster tree containing A.
If A is the root of the MFSET then A.size holds the size of the MFSET.
If A is the root of the MFSET, then A.symbols holds all the elements of the
MFSET.

15

fiDavis

{ If A is the root of the MFSET then A.leaf ptr holds a pointer to the pointer to
A in N .mfsets where N = A.cluster leaf.
We can now describe the algorithm.
procedure

variables:

0.
1.
2.
3.
4.
5.
6.
7.

begin if

8.
9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.
21.
22.
23.
24.
25.
26.
27.
28.
29.
30.
31.

solve constraints1(in S : a system of constraints of the form od(a; b)  od(c; d)).
return either a cluster tree T satisfying S if S is consistent;
or false if S is inconsistent.
m is an integer;
a; b are symbols;
C is a constraint in S ;
H is an undirected graph;
E; F are edges;
P is an MFSET;
N; M are nodes of T ;

S contains any constraint of the form, \od(a; b)  od(c; c)" then return false;

H := ;;

each constraint C in S with short E and long F
add E and F to H ;
add C to E .shorts and to F .longs endfor;
m := the number of variables in S ;
initialize T to contain the root N ;
N .symbols := the variables in S ;
for

do

each leaf N of T , INITIALIZE MFSETS(N );
each edge E = ab in H do
if E .shorts is non-empty and FIND(a) 6= FIND(b) then
MERGE(FIND(a), FIND(b)) endif endfor
if every edge E = ab in H satisfies FIND(a) = FIND(b)

repeat for
for

then return(false) endif

for

each current leaf N of T do
if N .mfsets has more than one element then
for each mfset P in N .mfsets do
construct node M as a new child of N in T ;
M .symbols:= P .symbols;
endfor endif endfor

each edge E = ab in H do
if FIND(a) 6= FIND(b) then
for each constraint C in E .longs do
delete C from S ;
delete C from E .longs;
delete C from C .short.shorts endfor
delete E from H endif endfor
m := m 1;
until S is empty;
for

for

each leaf N of T
N .label := 0;
if N .symbols has more than one symbol
16

fiOrder of Magnitude Comparisons of Distance

32.
33.

create a leaf of N with label 0 for each symbol in N .symbols;
solve constraints1.

then
endif endfor end

INITIALIZE MFSETS(N : node)
: symbol;
N .mfsets := ;;
for A in N .symbols do
A.parent := null;
A.cluster leaf := N ;
A.symbols := fAg;
A.size := 1;
N .mfsets := cons(A,N .mfsets);
A.leaf ptr := N .mfsets;
endfor end INITIALIZE MFSETS.
procedure
var A

MERGE(in A; B : symbol)
.size
.size then swap(A; B );
A.parent := B ;
B .size := B .size + A.size;
B .symbols := B .symbols [ A.symbols;
Using A.leaf ptr, delete A from A.cluster leaf.mfsets;
end MERGE.
procedure
if A
>B

FIND(in A : symbol) return symbol;
: symbol;
.parent = null then return A
:= FIND(A.parent);
A.parent := R; /* Path compression */
return(R)
end FIND.
procedure
var R
if A
else R

Let n be the number of symbols in S ; let e be the number of edges; and let s be the
number of constraints. Note that n=2  e  n(n 1)=2 and that e=2  s  e(e 1)=2.
The running time of solve constraints1 can be computed as follows. As each iteration of the
main loop 8-28 splits at least one of the connected components of H , there can be at most
n 1 iterations. The MERGE-FIND operations in the for loop 9-11 take together time
at most O(max(nff(n); e)) where ff(n) is the inverse Ackermann's function. Each iteration
of the inner for loop lines 16-18 creates one node M of the tree. Therefore, there are
only O(n) iterations of this loop over the entire algorithm. Lines 14, 15 of the outer for
loop require at most n iterations in each iteration of the main loop. The for loop 22-26
is executed exactly once in the course of the entire execution of the algorithm for each
constraint C , and hence takes at most time O(s) over the entire algorithm. Steps 20-21
require time O(e) in each iteration of the main loop. It is easily verified that the remaining
operations in the algorithm take no more time than these. Hence the overall running time
is O(max(n2 ff(n); ne; s)).

17

fiDavis

6.2 Adding Non-strict Comparisons
The algorithm solve constraints can be modified to deal with non-strict comparisons of the
form od(a; b)  od(c; d) by, intuitively, marking the edge ab as \short" on each iteration if
the edge cd has been found to be short.
Specifically, in algorithm solve constraints, we make the following two changes. First,
the revised algorithm takes two parameters: S , the set of strict constraints, and W , the set
of non-strict constraints. Second, we replace the line
H := the connected components of the shorts of S

with the following code:

1.
2.
3.
4.
5.

H := the shorts of S ;
repeat H := the connected components of H ;
for each weak constraint od(a; b)  od(c; d)
if cd is in H then add ab to H endif endfor
until no change has been made to H in the last iteration.

The proof that the revised algorithm is correct is only a slight extension of the proof of
theorem 1 and is given in the appendix.
Optimizing this algorithm for eciency is a little involved, not only because of the new
operations that must be included, but also because there are now four parameters | n, the
number of symbols; e, the number of edges mentioned; s, the number of strict comparison;
and w, the number of non-strict comparisons | and the optimal implementation varies
depending on their relative sizes. In particular, either s or w, though not both, may be
much smaller than n, and each of these cases requires special treatment for optimal eciency.
The best implementation we have found for the case where both s and w are 
(n) has a
running time of O(max(n3 ; nw; s)). The details of the implementation are straightforward
and not of sucient interest to be worth elaborating here.
An immediate consequence of this result is that a couple of problems of inference are
easily computed:

 To determine whether a constraint C is the consequence of a set of constraints S ,
form the set S [ :C and check for consistency. If S [ :C is inconsistent then Sj=C .
Note that the negation of the constraint od(a; b)  od(c; d) is the constraint
od(c; d)  od(a; b).
 To determine whether two sets of constraints are logically equivalent, check that each
constraint in the first is a consequence of the second, and vice versa.

6.3 Adding Order Constraints
Example 3 of Section 2 involves a combination of order-of-magnitude constraints on distances together with simple ordering on points, where the points lie on a one-dimensional
line. We next show how to extend algorithm solve constraints to deal with this more complex situation.

18

fiOrder of Magnitude Comparisons of Distance

In terms of the axiomatics, adding an ordering on points involves positing that the
relation p < q is a total ordering and that the ordering of points is related to order of
magnitude comparisons of distances through the following axiom.
A.9 For points a; b; c 2 P , if a < b < c then od(a; b)  od(a; c).
The following rule is easily deduced: If C and D are disjoint clusters, then either every
point in C is less than all the points in D, or vice versa.
In extending our algorithm, we begin by defining an ordered cluster tree to be a cluster
tree where, for every internal node N , there is a partial order on the children of N . If A
and B are children of N and A is ordered before B , then in an instantiation of the tree,
every leaf of A must precede every leaf of B . Procedure instantiate1 can then be modified
to deal with ordered cluster trees as follows:

instantiate1(in N : a node in a cluster tree; 
 : an om-space; 1 : : : k : orders of magnitude;
in out G : array of points indexed on the nodes of T )
if N is not a leaf then
let C1 : : : Cp be the children of N in topologically sorted order;
x0 := G[N ];
q := N .label;
pick points x1 : : : xp in increasing order such that
for all i; j 2 0 : : : p, if i 6= j then od(xi ; xj ) = q ;
/* Such points can be chosen by virtue of axiom A.8 */
for i = 1 : : : p do
G[Ci ] := xi ;
instantiate1(Ci ; 
; 1 : : : k ; G)
endfor
endif end

instantiate1.

Algorithm solve constraints is modified as follows:
procedure

fNEWg

variables:

begin if

solve constraints2(in S : a system of constraints of the form od(a; b)  od(c; d) ;
O : a system of constraints of the form a < b)
return either an ordered cluster tree T satisfying S
if S is consistent;
or false if S is inconsistent.
m is an integer;
C is a constraint in S ;
H; I are undirected graphs;
M; N; P are nodes of T ;
a; b; c; d are symbols;

S contains any constraint of the form, \od(a; b)  od(c; c)"

then return false

;

fNEWg if O is internally inconsistent (contains a cycle) then return false;
m := the number of variables in S ;
initialize T to consist of a single node N ;
N .symbols:= the variables in S ;
repeat

H := the connected component of the shorts of S ;

19

fiDavis

fNEWg

H := incorporate order(H; O);
if H contains all the edges in S
for

then return false

each leaf N of T do
if not all vertices of N are connected in H then
N .label := m;
for each connected component I of N .symbols in H do
construct node M as a new child of N in T ;
M .symbols:= the vertices of I ;
endfor endif

fNEWg
fNEWg
fNEWg
fNEWg
fNEWg

for

each constraint a < b 2 O
if a is in M .symbols and b is in P .symbols
where M and P are different children of N
then add an ordering arc from M to P ;
endif endfor

endfor

S := the subset of constraints in S whose long is in H ;
m := m 1;
until
for

S is empty;

each leaf N of T
N .label := 0;
if N .symbols has more than one symbol
then create a leaf of N for each symbol in N .symbols;
label each such leaf 0;
endif endfor

end

solve constraints2.

fNEWg

function

incorporate order(in H : undirected graph;
O : a system of constraints of the form a < b)
return undirected graph;

variables:

G : directed graph;
a; b : vertices in H ;
A; B : connected components of H ;
V [A] : array of vertices of G indexed on connected components of H ;
I : subset of vertices of G;

connected component A of H create a vertex V [A] in G;
constraint a < b 2 O
let A and B be the connected components of H containing a and b respectively;
if A 6= B then add an arc in G from V [A] to V [B ] endif endfor;
for each strongly connected component I of G do
for each pair of distinct vertices V [A]; V [B ] 2 I do
for each a 2 A and b 2 B add the edge ab to H endfor endfor

for each
for each

endfor

20

fiOrder of Magnitude Comparisons of Distance

end

incorporate order.

Function incorporate order serves the following purpose. Suppose that we are in the
midst of the main loop of solve constraints2, we have a partially constructed cluster tree,
and we are currently working on finding the sub-clusters of a node N . As in the original
form of solve constraints, we find the connected components of the shorts of the order-ofmagnitude constraints. Let these be C1 : : : Cq ; then we know that the diameter of each Ci
is much smaller than the diameter of N . Now, suppose, for example, that we have in O the
constraints a1 < a5 ; b5 < b2 ; c2 < c1 , where a1 ; c1 2 C1 ; b2 ; c2 2 C2 ; and a5 ; b5 2 C5 . Then
it follows from axiom A.9 that C1 , C2 , and C5 must all be merged into a single cluster,
whose diameter will be less than the diameter of N . Procedure incorporate order finds all
such loops by constructing a graph G whose vertices are the connected components of H
and whose arcs are the ordering relations in O and then computing the strongly connected
components of G. (Recall that two vertices u; v in a directed graph are in the same strongly
connected component if there is a cycle from u to v to u.) It then merges together all of
the connected components of H that lie in a single strongly connected component of G.
The proof of the correctness of algorithm solve constraints2 is again analogous in structure to the proof of theorem 1, and is given in the appendix.
By implementing this in the manner of Section 6.1, the algorithm can be made to run
in time O(max(n2 ff(n); ne; no; s)), where o is the number of constraints in O.

7. Finite order of magnitude comparison
In this section, it is demonstrated that algorithm solve constraints can be applied to systems
of constraints of the form \dist(a; b) < dist(c; d) / B " for finite B in ordinary Euclidean
space as long as the number of symbols in the constraint network is smaller than B .
We could be sure immediately that some such result must apply for finite B . It is
a fundamental property of the non-standard real line that any sentence in the first-order
theory of the reals that holds for all infinite values holds for any suciently large finite
value, and that any sentence that holds for some infinite value holds for arbitrarily large
finite values. Hence, since the answer given by algorithm solve constraints works over a
set of constraints S when the constraint \od(a; b)  od(c; d)" is interpreted as \od(a; b)
< od(c; d)/B for infinite B ", the same answer must be valid for suciently large finite B .
What is interesting is that we can find a simple characterization of B in terms of S ; namely,
that B is larger than the number of symbols in S .
We begin by modifying the form of the constraints, and the interpretation of a cluster
tree. First, to avoid confusion, we will use a four-place predicate \much closer(a; b; c; d)"
rather than the form \od(a; b)  od(c; d)" as we are not going to give an interpretation to
\od" as a function. We fix a finite value B > 1, and interpret \much closer(a; b; c; d)" to
mean \dist(a; b) < dist(c; d) / B ."
We next redefine what it means for a valuation to instantiate a cluster tree:

Definition 6: Let T be a cluster tree and let be a valuation on the symbols in T . We say
that `T if the following holds: For any symbols a; b; c; d in T , let M be the least common
ancestor of a; b and let N be the least common ancestor of c; d. If M .label < N .label then
much closer(a; b; c; d).

21

fiDavis

Procedure \instantiate", which generates an instantiation of a cluster tree, is modified
as follows:
procedure

instantiate(in T : cluster tree; 
 : Euclidean space; B : real);
return : array of points indexed on the symbols of T ;

Let n be the number of nodes in T ;
ff := 2 + 2n + Bn;
Choose 1 ; 2 : : : n such that i < i+1 =ff;
pick a point x 2 
;
G[T ] := x;
instantiate1(T; 
; 1 : : : n ; G);
return the restriction of G to the symbols of T .
end instantiate.
instantiate1(in N : a node in a cluster tree; 
 : a Euclidean space;
1 : : : n : orders of magnitude;
in out G : array of points indexed on the nodes of T )
if N is not a leaf then
let C1 : : : Cp be the children of N ;
x1 := G[N ];
q := N .label;
pick points x2 : : : xp such that
for all i; j 2 1 : : : p, if i 6= j then q  dist(xi ; xj ) < nq
/* This is possible since p  n. */
for i = 1 : : : p do
G[Ci ] := xi ;
instantiate1(Ci ; 
; 1 : : : n ; G)
endfor
endif end

instantiate1.

The analogue of lemma 2 holds for the revised algorithm:
Lemma 22: Any cluster tree T has an instantiation in Euclidean space <m of any dimensionality m.
We can now state theorem 3, which asserts the correctness of algorithm \solve constraints"
in this new setting:

Theorem 3: Let S be a set of constraints over n variables of the form \dist(a; b) <
dist(c; d) / B ", where B > n. The algorithm solve constraints(S ) returns a cluster tree
satisfying S if S is consistent over Euclidean space, and returns false if S is inconsistent.
The proofs of lemma 22 and theorem 3 are given in the appendix.
An examination of the proof of lemma 22 shows that this result does not depend on
any relation between n and B . Therefore, if solve constraints(S ) returns a tree T , then S
is consistent and T satisfies S regardless of the relation between n and B . However, it is
possible for S to be consistent and solve constraints(S ) to return false if n  B . On the
other hand, one can see from the proof of theorem 3 (particularly lemma 23) that if B > n
and solve constraints(S ) returns false then S is inconsistent in any metric space. However,
there are metric spaces other than <m in which the cluster tree returned by solve constraints
may have no instantiation.

22

fiOrder of Magnitude Comparisons of Distance

8. The first-order theory
Our final result asserts that if the om-space is rich enough then the full first-order language
of order-of-magnitude distance comparisons is decidable. Specifically, if the collection of
orders of magnitude is dense and unbounded above, then there is a decision algorithm for
first-order sentences over the formula, \od(W; X )  od(Y; Z )" that runs in time O(4n (n!)2 s)
where n is the number of variables in the sentence and s is the length of the sentence.
The basic reason for this is the following: As we have observed in corollary 4, a cluster
tree T determines the truth value of all constraints of the form \od(a; b)  od(c; d)" where
a; b; c; d are symbols in the tree. That is, any two instantiations of T in any two omspaces agree on any such constraint. If we further require that the om-spaces are dense
and unbounded, then a much stronger statement holds: Any two instantiations of T over
such om-spaces agree on any first-order formula free in the symbols of T over the relation
\od(W; X )  od(Y; Z )". Hence, it suces to check the truth of a sentence over all possible
cluster trees on the variables in the sentence. Since there are only finitely many cluster
trees over a fixed set of variables (taking into account only the relative order of the labels
and not their numeric values), this is a decidable procedure.
Let L be the first-order language with equality with no constant or function symbols,
and the single predicate symbol \much closer(a; b; c; d)". It is easily shown that L is as
expressive as the language with the function symbol \od" and the relation symbol .

Definition 7: An om-space 
 with orders of magnitude
following axiom:

D is dense if it satisfies the

A.9 For all orders of magnitude 1  3 in D, there exists a order of magnitude 2 in D
such that 1  2  3 .

 is unbounded above if it satisfies the following:
A.10 For every order of magnitude 1 in D there exists 2 in D such that 1  2 .
If D is the collection of orders of magnitude in the hyperreal
line, then both of these
p
are satisfied. In axiom [A.9], if 0  1  3 , choose 2 = 1 3 , the geometric mean.
If 0 = 1  3 , choose 2 = 3  where   1. In axiom [A.10] choose 2 = 1 = where
0 <   1.

Definition 8: Let T be a cluster tree. Let l0 = 0; l1 ; l2 : : : lk be the distinct labels in T
in ascending order. An extending label for T is either (a) li for some i; (b) lk + 1 (note that
lk is the label of the root); (c) (li 1 + li )=2 for some i between 1 and k.
Note that if T has k distinct non-zero labels, then there are 2k + 2 different extending
labels for T .

Definition 9: Let T be a cluster tree. Let x be a symbol not in T . The cluster tree
0
T extends T with x if T 0 is formed from T by applying one of the following operations (a
single application of a single operation).
1. T is the null tree and T 0 is the tree containing the single node x.

23

fiDavis

2. T consists of the single node for symbol y. Make a new node M , make both x and y
children of M , and set the label of M to be either 0 or 1.
3. For any internal node N of T (including the root), make x a child of N .
4. Let y be a symbol in T , and let N be its father. If N .label 6= 0, create a new node M
with an extending label for T such that M .label < N .label. Make M a child of N ,
and make x and y children of M .
5. Let C be an internal node of T other than the root, and let N be its father. Create
a new node M with an extending label for T such that C .label < M .label < N .label.
Make M a child of N and make x and C children of M .
6. Let R be the root of T . Create a new node M such that M .label = R.label + 1. Make
R and x children of M . Thus M is the root of the new tree T 0 .
(See Figure 3.)
Note that if T is a tree of n symbols and at most n 1 internal nodes then

 There are n 1 ways to carry out step 3.
 There are n possible ways to choose symbol y in step 4, and at most 2n 2 for the
label on M in each.

 There are at most n 2 different choices for C in step 5, and at most 2n 3 choices
for the label on M in each.

 There is only one way to carry out step 6.
Hence, there are less than 4n2 different extensions of T by x. (This is almost certainly
an overestimate by at least a factor of 2, but the final algorithm is so entirely impractical
that it is not worthwhile being more precise.)

Definition 10: Let T be a cluster tree, and let  be a formula of L open in the variables
of T . T satisfies  if every instantiation of T satisfies .
Theorem 4: Let T be a cluster tree. Let  be an open formula in L, whose free variables
are the symbols of T . Let 
 be an om-space that is dense and unbounded above. Algorithm
decide(T; ) returns true if T satisfies  and false otherwise.

decide(T : cluster tree;  : formula) return boolean
convert  to an equivalent form in which the only logical symbols in  are
: (not), ^ (and), 9 (exists), = (equals) and variable names,
and the only non-logical symbol is the predicate \much closer".
function

case

 has form X = Y : return (distance(X; Y; T ) = 0);
 has form \much closer(W; X; Y; Z )": return distance(W; X; T ) < distance(Y; Z; T ));
 has form : : return not(decide(T; ))
 has form ^ : return(decide(T; ) and decide(T; ))
 has form 9X ff;

24

fiOrder of Magnitude Comparisons of Distance

P

P

P

2

2

2
w

Q

Q

1

w

Q

w

x

1

1

u

u

v

u

v

v

x

Operation 3:

Operation 3:
Original T

N = P

N = Q

P
2
w

Q
1

P

P

2

2
w

Q
1

Operation 4:

Operation 4:
y=v

y=u

M

Q

0/0.5/1/1.5

1
u

v

M

M
0/0.5

0/0.5

u

u

v

x

w

Operation 4:

x

y=w

M
P

3

2
x
M

w

P
2

1.5
Operation 5:
x

w

Q
1

C=Q, N=P

Q
1
u

u

v

v

v
Operation 6:
R=P

Figure 3: Extensions of a cluster tree

25

x

fiDavis

extension

of by , decide(T ; ff) = true

if for some
T0 T X
then return true
else return false endif endcase

end

0

decide

distance(X; Y : symbol; T : cluster tree) return
N := the common ancestor of X and Y in T ;
return(N .label)
function

end

integer

distance

The proof of theorem 4 is given in the appendix.
Running time: As we have remarked above, for a tree T of size k there are at most 4k2
extensions of T to be considered. The total number of cluster trees considered is therefore
bounded by nk=1 4k2 = 4n (n!)2 . It is easily verified that the logical operators other than
quantifiers add at most a factor of s where s is the length of the sentence. Hence the running
time is bounded by O(4n (n!)2 s).
A key lemma, of interest in itself, states the following:
Lemma 28: Let T be a cluster tree. Let  be an open formula in L, whose free variables
are the symbols of T . Let 
 be an om-space that is dense and unbounded above. If one
instantiation of T in 
 satisfies  then every instantiation of T in 
 satisfies .
That is, either  is true for all instantiations of T or for none. The proof is given in the
appendix.
It should be observed that the above conditions on 
 in lemma 28 are necessary, and
that the statement is false otherwise. For example, let 
 be the om-space described in
example I, Section 3, of polynomials over an infinitesimal . Then 
 is not unbounded
above; there is a maximum order-of-magnitude O(1). Let T be the starting tree of Figure
3 (upper-left corner). Let  be the formula \9X od(V; W )  od(W; X )", free in V and W .
Then the valuation fU ! ; V ! 0; W ! 1g satisfies T but not , whereas the valuation
fU ! 2 ; V ! 22 ; W ! g satisfies both T and .

9. Conclusions
The applications of the specific algorithms above are undoubtedly limited; we are not aware
of any practical problems where solving systems of order-of-magnitude relations on distances
is the central problem. However, the potential applications of order-of-magnitude reasoning
generally are very widespread. Ordinary commonsense reasoning involves distances spanning a ratio of about 108 , from a fraction of an inch to thousands of miles, and durations
spanning a ratio of about 1010 , from a fraction of a second to a human lifetime. Scientific
reasoning spans much greater ranges. Explaining the dynamics of a star combines reasoning
about nuclear reactions with reasoning about the star as a whole; these differ by a ratio
of about 1057 . The techniques needed to compute with quantities of such vastly differing
sizes are quite different from the techniques needed to compute with quantities all of similar
sizes. This paper is a small step in the development and analysis of such computational
techniques.
The above results are also significant in the encouragement that they give to the hope
that order-of-magnitude reasoning specifically, and qualitative reasoning generally, may lead

26

fiOrder of Magnitude Comparisons of Distance

to useful quick reasoning strategies in a broader range of problems. It has been often found
in AI that moving from greater to lesser precision in the mode of inference or type of
knowledge does not lead to quick and dirty heuristic techniques, but rather to slow and
dirty techniques. Nonmonotonic reasoning is the most notorious example of this, but it
arises as well in many other types of automated reasoning, including qualitative spatial and
physical reasoning. The algorithms developed in this paper are a welcome exception to
this rule. We are currently studying algorithmic techniques for other order-of-magnitude
problems, and are optimistic of finding similar favorable results.

Acknowledgements
This research has been supported by NSF grant #IRI-9625859. Thanks to Ji-Ae Shin,
Andrew Gelsey, and the reviewers for helpful comments.

Appendix A. Proofs
In this appendix, we give the proofs of the various results asserted in the body of the paper.

Proof of Lemma 2
Lemma 2: If T is a cluster tree and 
 is an om-space, then instantiate(T; 
) returns an
instantiation of T .
Proof: Let 0 = 0. For any node N , if i=N .label, we define (N ) = i . The proof then
proceeds in the following steps:
i. For any nodes M ,N , if M is a descendant of N in T then od(G[M ]; G[N ])  (N ).
Proof: If M is a child of N , then this is immediate from the construction of x2 : : : xp
in instantiate1. Else, let N = N1 ; N2 : : : Nq = M be the path from N to M through
T . By the definition of a cluster tree, it follows that Ni .label < N .label, for i > 1 and
therefore (Ni )  (N ). Thus od(G[M ]; G[N ])  (by the o.m.-triangle inequality)
maxi=1:::q 1 (od(G[Ni+1 ]; G[Ni ]))  maxi=1:::q 1 ((Ni )) (since Ni+1 is the child of
Ni )  (N ).
ii. Let N be a node in T ; let C1 and C2 be two distinct children of N ; and let M1
and M2 be descendants of C1 and C2 respectively. Then od(G[M1 ]; G[M2 ]) = (N ).
Proof: By the construction of x2 : : : xp in instantiate1(N ), od(G[C1 ]; G[C2 ]) = (N ).
By part (i.), od(G[M1 ]; G[C1 ])  (C1 )  (N ) and likewise od(G[M2 ]; G[C2 ]) 
(N ). Hence, by axiom A.6, od(G[M1 ]; G[M2 ]) = (N ).
iii. Let a and b be any two leaves in T , and let N be the least common ancestor in T of
a and b. Then od(G[a]; G[b]) = (N ). Proof: Immediate from (ii).
iv. For any node N , odiam( (N )) = (N ). Proof: From (iii), any two leaves descending
from different children of N are at a distance of order (N ), and no two leaves of N
are at a distance of order greater than (N ).

27

fiDavis

v. For any node N , (N ) is a cluster of (T ). Proof: Let a and b be leaves of N ,
and let c be a leaf of T N . Let I be the common ancestor of a and b in T and
let J be the common ancestor of a and c. Then I is either N or a descendant of N
and J is a proper ancestor of N . Therefore by part (i), (I )  (J ). But by (iii),
od( (a); (b)) = (I )  (J ) = od( (a); (c)).
vi. For any internal nodes N; M if M .label < N .label then odiam( (M ))  odiam( (N )).
Proof: Immediate from (iv) and the construction of .
vii. If C is a cluster of (T ) then there is a node N in T such that C = (N ). Proof: Let
S be the set of symbols corresponding to C and let N be the least common ancestor
of all of S . Let a and b be two symbols in S that are in different subtrees of N . Then
by (iii), od(G[a]; G[b]) = (N ). Let x be any symbol in N .symbols. Then by (iii)
od(G[a]; G[x])  (N ). Hence G[x] 2 C .

2
Proof of Theorem 1
We here prove the correctness of algorithm solve constraints. We will assume throughout
that the two variables in the long of any constraint in S are distinct.
Lemma 3: Let T be a cluster tree and let be an instantiation of T . Let a and b be
symbols of T . Let N be the least common ancestor of a and b in T . Then od( (a); (b)) =
odiam( (N )).
Proof: Since (a) and (b) are elements of (N ), it follows from the definition of odiam that
od( (a); (b))  odiam( (N )). Suppose the inequality were strict; that is, od( (a); (b))
 odiam( (N )). Then let C be the set of all the symbols c of T such that od( (a); (c))
 od( (a); (b)). Then odiam( (C )) = od( (a); (b))  odiam( (N )). It is easily shown
that (C ) is a cluster in (T ). Therefore, by property (ii) of definition 5, there must be
a node M such that M .symbols = C . Now, M is certainly not an ancestor of N , since
odiam( (M ))  odiam( (N )) but M .symbols contains both a and b. But this contradicts
the assumption that N was the least common ancestor of a and b. 2
Corollary 4: Let T be a cluster tree and let be an instantiation of T . Let a; b; c; d be
symbols of T . Let N be the least common ancestor of c and d in T , and let M be the
least common ancestor of a and b in T . Then od( (a); (b))  od( (c); (d)) if and only if
M .label < N .label.
Proof: Immediate from lemma 3 and property (iii) of definition 5 of instantiation. 2

Lemma 5: Let S be any set of constraints of the form od(a; b)  od(c; d). Let H be the
connected components of the shorts of S . If S is consistent, then not every edge of S is in
H.
Proof: Let be a valuation satisfying S . Find an edge pq in S for which od( (p); (q)) is
maximal. Now, if ab is a short of S | that is, there is a constraint od(a; b)  od(c; d) in
S | then od( (a); (b))  od( (c); (d))  od( (p); (q)).

28

fiOrder of Magnitude Comparisons of Distance

Now, let ab be any edge in H , the connected components of the shorts of S . Then there
is a path a1 = a; a2 : : : ak = b such that the edge ai ai+1 is a short of S for i = 1 : : : k 1.
Thus, by the om-triangle inequality, od( (a); (b))  maxi=1::k 1(od( (ai ); (ai+1 ))) 
od( (p); (q)). Hence pq 6= ab, so pq is not in H . 2

Lemma 6: The values of S and H in any iteration are supersets of their values in any later
iteration.

Proof: S is reset to a subset of itself at the end of each iteration. H is defined in terms of
S in a monotonic manner. 2

S cannot be the same in two successive iterations of the main loop.
Proof: by contradiction. Suppose that S is the same in two successive iterations. Then H
will be the same, since it is defined in terms of S . H is constructed to contain all the shorts
of S , Since the resetting of S at the end of the first iteration does not change S , H must
contain all the longs as well. Thus, H contains all the edges in S . But that being the case,
the algorithm should have terminated with failure at the beginning of the first iteration. 2
Lemma 7:

Lemma 8: Algorithm solve constraints always terminates.
Proof: By lemma 7, if the algorithm does not exit with failure, then on each iteration some
constraints are removed from S . Hence, the number of iterations of the main loop is at
most the original size of S . Everything else in the algorithm is clearly bounded. (Note that
this bound on the number of iterations is improved in Section 6.1 to n 1, where n is the
number of symbols.) 2

Lemma 9: If algorithm solve constraints returns false, then S is inconsistent.

Proof: If the algorithm returns false, then the transitive closure of the shorts of S contains
all the edges in S . By lemma 5, S is inconsistent.

Lemma 10: If constraint C of form od(a; b)  od(c; d) is in the initial value of S , and
edge cd is in H in some particular iteration, then constraint C is in S at the start of that
iteration.
Proof: Suppose that C is deleted from S on some particular iteration. Then edge cd, the
long of C , cannot be in H in that iteration. That is, it is not possible for edge cd to persist
in H in an iteration after C has been deleted from S . Note that, by lemma 6, once cd is
eliminated from H , it remains out of H . 2
Lemma 11: The following loop invariant holds: At the end of each loop iteration, the
values of L.symbols, where L is a leaf in the current state of the tree, are exactly the
connected components of H .

Proof: In the first iteration, T is initially just the root R, containing all the symbols, and
a child of R is created for each connected component of H .
Let Ti and Hi be the values of T and H at the end of the ith iteration. Suppose that
the invariant holds at the end of the kth iteration. By lemma 6, Hk+1 is a subset of Hk .
Hence, each connected component of Hk+1 is a subset of a connected component of Hk .

29

fiDavis

Moreover, each connected component J of Hk is either a connected component of Hk+1 or
is partitioned into several connected components of Hk+1 . In the former case, the leaf of
Tk corresponding to J is unchanged and remains a leaf in Tk+1 . In the latter case, the leaf
corresponding to J gets assigned one child for each connected component of Hk+1 that is a
subset of J . Thus, the connected components of Hk+1 correspond to the leaves of Tk+1 . 2

Lemma 12: If procedure solve constraints does not return false, then it returns a wellformed cluster tree T .
Proof: Using lemma 11, and the cleanup section of solve constraints which creates the final
leaves for symbols, it follows that every symbol in S ends up in a single leaf of T . As m is
decremented on each iteration, and as no iteration adds both a new node and children of
that node, it follows that the label of each internal node is less than the label of its father.
Hence the constraints on cluster trees (definition 3) are satisfied. 2
Lemma 13: Let a; b be two distinct symbols in S and let T be the cluster tree returned
by solve constraints for S . Let N be the least common ancestor of a; b in T . Then either N
is assigned its label on the first iteration when the edge ab is not in H , or the edge ab is in
the final value of H when the loop is exited and N is assigned its label in the final cleanup
section.
Proof: As above, let Hi be the value of H in the ith iteration.
If N is the root, then it is assigned its label in the first iteration. Clearly, a and b, being
in different subtrees of N , must be in different connected components of H1 .
Suppose N is assigned its label in the kth iteration of the loop for k > 1. By lemma 11,
at the end of the previous iteration, N .symbols was a connected component of Hk 1 , and it
therefore contained the edge ab. Since N is the least common ancestor of a; b, it follows that
a and b are placed in two different children of N ; hence, they are in two different connected
components of Hk . Thus the edge ab cannot be in Hk .
Suppose N is assigned its label in the cleanup section of the algorithm. Then by lemma
11, N .symbols is a connected component of the final value of H . Hence the edge ab was in
the final value of H . 2
Lemma 14: Let S initially contain constraint C of form od(a; b)  od(c; d). Suppose that
solve constraints(S ) returns a cluster tree T . Let M be the least common ancestor of a; b
in T and let N be the least common ancestor of c; d. Then M .label < N .label.
Proof: Suppose N is given a label in a given iteration. By lemma 13, cd is eliminated
from H in that same iteration. By lemma 10, constraint C must be in S at the start of the
iteration. Hence ab is a short of S in the iteration, and is therefore in H . Hence M is not
given a label until a later iteration, and therefore is given a lower label.
It is easily seen that cd cannot be in H in the final iteration of the loop, and hence N
is not assigned its label in the cleanup section. 2
Lemma 15: Suppose that solve constraints(S ) returns a cluster tree T . Then any instantiation of T satisfies the constraints S .
Proof: Immediate from lemma 14 and corollary 4.

30

fiOrder of Magnitude Comparisons of Distance

Theorem 1: The algorithm solve constraints(S ) returns a cluster tree satisfying S if S is
consistent, and returns false if S is inconsistent.
Proof: If solve constraints(S ) returns false, then it is inconsistent (lemma 9). If it does
not return false, then it returns a cluster tree T (lemma 12). Since T has an instantiation
(lemma 2) and since every instantiation of T is a solution of S (lemma 15), it follows that
S is consistent and T satisfies S . 2
Proof of Theorem 2
Lemma 16: If S1 and S2 are consistent sets of constraints, and S1  S2 then
reduce constraints(S1 )  reduce constraints(S2 ).
Proof: Immediate by construction. The value of H in the case of S1 is a superset of its value
in the case of S2 , and hence reduce constraints(S1 ) is a superset of reduce constraints(S2 ).
Lemma 17: If S1 and S2 are consistent sets of constraints, and S1  S2 then num labels(S1)
 num labels(S2).
Proof by induction on num labels(S2). If num labels(S2) = 0, the statement is trivial.
Suppose that the statement holds for all S 0 , where num labels(S 0) = k.
Let num labels(S2) = k + 1.
Then k + 1 = num labels(S2 ) = 1 + num labels(reduce constraints(S2 )), so
k =num labels(reduce constraints(S2 )). Now, suppose S1  S2 . By lemma 16
reduce constraints(S1 )  reduce constraints(S2 ). But then by the inductive hypothesis
num labels(reduce constraints(S1 ))  num labels(reduce constraints(S2 )), so
num labels(S1)  num labels(S2). 2
Lemma 18: Let S be a set of constraints, and let be a solution of S . For any graph G
over the symbols of S , let nd(G; ) be the number of different non-zero values of od(a; b)
where edge ab is in G. Let edges(S ) be the set of edges in S . Then nd(edges(S ), ) 
num labels(S ).
Proof: by induction on num labels(S ). If num labels(S ) = 0, then the statement is trivial.
Suppose for some k, the statement holds for all S 0 where num labels(S 0) = k, and suppose
num labels(S ) = k + 1. Let pq be the edge in S of maximal length. For any set of edges E ,
let small-edges(E; ) be the set of all edges ab in E for which
od( (a); (b))  od( (p); (q)). Since small-edges(E ) contains edges of every order of
magnitude in E except the order of magnitude of pq, it follows that
nd(small-edges(E; ), ) = nd(E; ) 1. Let G be the complete graph over all the symbols
in S . By the same argument as in lemma 5, small-edges(G; )  H , where H is the connected
components of the shorts of S , as computed in reduce constraints(S ). Let S 0 be the set of
constraints whose longs are in small-edges(G; ). It follows that S 0  reduce constraints(S ).
Now small-edges(G; )  edges(S 0 )  edges(reduce constraints(S )).
Hence nd(edges(S ), ) = nd(G; ) = nd(small-edges(G; ), ) + 1
 nd(edges(reduce constraints(S ))) + 1  (by the inductive hypothesis)
num labels(reduce constraints(S )) + 1 = num labels(S ). 2

31

fiDavis

Theorem 2: Out of all solutions to the set of constraints S , the instantiations of
solve constraints(S ) have the fewest number of different values of od(a; b), where a; b range
over the symbols in S . This number is given by num labels(S ).
Proof: Immediate from lemma 18.
Corollary 19: Let 
 have all the properties of an om-space except that it has only k
different orders of magnitude. A system of constraints S has a solution in 
 if and only if
the tree returned by solve constraints(S ) uses no more than k different labels.
Proof: Immediate from theorems 1 and 2. 2
Proof of Algorithm for Non-strict Comparisons
We now prove that the revised algorithm presented in Section 6.2 for non-strict comparisons
is correct. The proof is only a slight extension of the proof of theorem 1, given above.
Recall that the revised algorithm in Section 6.2 replaces the line of solve constraints
H := the connected components of the shorts of S
with the following code:

1.
2.
3.
4.
5.

H := the shorts of S ;
repeat H := the connected components of H ;
for each weak constraint od(a; b)  od(c; d)
if cd is in H then add ab to H endif endfor
until no change has been made to H in the last iteration.

We need the following new lemmas and proofs:

Lemma 20: Let S be a set of strict comparisons, and let W be a set of non-strict comparisons. Let H be the set of edges output by the above code. If S [ W is consistent, then
there is an edge in S that is not in H .
Proof: As in the proof of lemma 5, let be a valuation satisfying S [ W and let pq be
an edge in S such that od( (p); (q)) is maximal. We wish to show that, for every edge
ab 2 H , od( (a); (b))  od( (p); (q)), and hence ab 6= pq. Proof by induction: suppose
that this holds for all the edges in H at some point in the code, and that ab is now to be
added to H . There are three cases to consider.

 ab is added in step [1]. Then, as in lemma 5, there is a constraint od(a; b)  od(c; d)
in S . Hence od( (a); (b))  od( (c); (d))  od( (p); (q)).
 ab is added in step [2]. Then there is a path a1 = a; a2 : : : ak = b such that the edge
ai ai+1 is in H for i = 1 : : : k 1. By the inductive hypothesis, od( (ai ); (ai+1 )) 
od( (p); (q)). By the om-triangle inequality,
od( (a); (b))  maxi=1::k 1(od( (ai ); (ai+1 )))  od( (p); (q)).

 ab is added in step [4]. Then there is a constraint od(a; b)  od(c; d) in W such that
cd is in H . By the inductive hypothesis, od( (c); (d))  od( (p); (q)).
32

fiOrder of Magnitude Comparisons of Distance

2

Lemma 21: Let W contain the constraint od(a; b)  od(c; d). Suppose that the algorithm
returns a cluster tree T . Let M be the least common ancestor of a and b in T , and let N
be the least common ancestor of c and d. Then M .label  N .label.
Proof: By lemma 13, N is assigned a label in the first iteration where H does not include
the edge cd. In all previous iterations, since cd is in H , ab will likewise be put into H .
Hence M does not get assigned a label before N , so M .label  N .label.
The remainder of the proof of the correctness of the revised algorithm is exactly the
same as the proof of theorem 1.
Validation of Algorithm Solve constraints2
The proof of the correctness of algorithm solve constraints2 is again analogous in structure
to the proof of theorem 1. We sketch it below: the details are not dicult to fill in.
1. (Analogue of lemma 2:) If T is an ordered cluster tree, then the revised version of
instantiate(T ) returns an instantiation of T . The proof is exactly the same as lemma
2, with the additional verification that instantiate2 preserves the orderings in T .
2. (Analogue of lemma 5:) Let S be a set of order-of-magnitude constraints on distances,
and let O be a set of ordering constraints on points. Let H be the graph given by the
two statements

H := the connected components of the shorts of S ;
H := incorporate order(H; O);
If S and O are consistent, then H does not contain all the edges of S .
Proof: As in the proof of lemma 5, choose a valuation satisfying S ; O and let pq be
an edge in S for which od( (p); (q)) is maximal. Following the informal argument
presented in Section 6.3, it is easily shown that pq is longer than any of the edges
added in these two statements, and hence it is not in H .
3. (Analogue of lemma 9:) If solve constraints2 returns false, then S ; O is inconsistent.
Proof: Immediate from (2).
4. (Analogue of lemma 12:) If solve constraints2(S ; O) does not return false, then it
returns a well-formed ordered cluster tree.
Proof: By merging the strongly connected components of G, incorporate order always
ensures that the ordering arcs between connected components of H form a DAG. These
arcs are precisely the same ones that are later added among the children of node N as
ordering arcs. Thus, the ordering arcs over the children of a node in the cluster tree
form a DAG. Otherwise, the construction of the tree T is the same as in lemma 12.
The remainder of the proof is the same as the proof of theorem 1.

33

fiDavis

Proof of Theorem 3
We begin by proving lemma 22, that the revised version of \instantiate", given in Section
6.3, gives an instantiation of a cluster tree in Euclidean space.
Lemma 22: Any cluster tree T has an instantiation in Euclidean space <m of any dimensionality m.
The proof is essentially the same as the proof of Lemma 2, except that we now have
to keep track of real quantities. For any node N , if i=N .label, we define (N ) = i . The
proof then proceeds in the following steps:
i. For any i < j , i < j =ffj i . Immediate by construction.
ii. For any nodes M ,C , if M is a descendant of C in T then
dist(G[M ]; G[C ]) < ffn(C )=(ff 1).
Proof: Let C = C0 ; C1 : : : Cr = M be the path from P
C to M through T . Then
dist(
the triangle inequality) ri=01 dist(G[Ci+1]; G[Ci ]) 
Pr 1G(n[M(];CG)[=ffC ])i) < (by
(ff=(ff 1))(n(C )).
i=0
iii. Let N be a node in T ; let C1 and C2 be two children of N ; and let M1 and M2 be
descendants of C1 and C2 respectively. Then
(N )(1 2n=(ff 1)) < dist(G[M1]; G[M2 ]) < n(N )(1 + 2=(ff 1))
Proof: By the triangle inequality,
dist(G[C1 ]; G[C2 ])  dist(G[C1 ]; G[M1 ]) + dist(G[M1 ]; G[M2 ]) + dist(G[M2 ]; G[C2 ]).
Thus, dist(G[C1]; G[C2 ]) dist(G[C1]; G[M1 ]) dist(G[M2 ]; G[C2 ])  dist(G[M1 ]; G[M2 ]).
Also, by the triangle inequality,
dist(G[M1 ]; G[M2 ])  dist(G[C1]; G[C2 ]) + dist(G[C1]; G[M1 ]) + dist(G[M2 ]; G[C2 ]).
By construction, (N )  dist(G[C1]; G[C2 ]) < n(N ),
and by part (ii), for i = 1; 2, dist(G[Mi]; G[Ci ]) < ffn(C )=(ff 1) < n(N )=(ff 1)
as (C ) < (N )=ff.
iv. For any symbols a; b; c; d in T , let P be the least common ancestor of a; b and let N
be the least common ancestor of c; d. If P .label < N .label then
much closer(G[a]; G[b]; G[c]; G[d]).
Proof: By part (iii), dist(G[a]; G[b]) < n(P )(1 + 2=(ff 1))
and dist(G[c]; G[d]) > (N )(1 2n=(ff 1)). Since (P ) < (N )=ff and since
ff = 2 + 2n + Bn, it follows by straightforward algebra that
dist(G[a]; G[b]) < dist(G[c]; G[d]) / B .

2

We next prove the analogue of lemma 5.

Lemma 23: Let S be a set of constraints over n variables of the form
\dist(a; b) < dist(c; d) / B ", where B > n. If S is consistent, then there is some edge in S
which is not in the connected components of the shorts of S .
Proof: Let be a valuation satisfying S . Let pq be the edge in S for which dist( (p); (q))
is maximal. Now, if ab is a short of S | that is, there is a constraint much closer(a; b; c; d)
in S | then dist( (a); (b)) < dist( (c); (d))/B  dist( (p); (q))/B .

34

fiOrder of Magnitude Comparisons of Distance

Now, let ab be any edge in H , the connected components of the shorts of S . Then
there is a simple path a1 = a; a2 : : : ak = b such that the edge ai ai+1 is a short of S for
i = 1 : : : k 1. Note that k  n. Then, by the triangle inequality,
dist( (a); (b)) 
dist( (a1 ); (a2 )) + dist( (a2 ); (a3 )) + . . . + dist( (ak 1 ); (ak )) 
(k 1)dist( (p); (q)) / B < dist( (p); (q))

Hence pq 6= ab, so pq is not in H . 2

Theorem 3: Let S be a set of constraints over n variables of the form \dist(a; b) < dist(c; d)
/ B ", where B > n. The algorithm solve constraints(S ) returns a cluster tree satisfying S
if S is consistent over Euclidean space, and returns false if S is inconsistent.
Proof: Note that the semantics of the constraints \much closer(a; b; c; d)" enters into the
proof of Theorem 1 only in lemmas 2 and 5. The remainder of the proof of Theorem 1 has to
do purely with the relation between the structure of S and the structure of the tree. Hence,
since we have shown that the analogues of lemmas 2 and 5 hold in a set of constraints of
this kind, the same proof can be completed in exactly the same way. 2
Proof of Theorem 4
Lemma 24: Let T be a cluster tree and let be a valuation over om-space 
 satisfying T .
Let x be a symbol not in T , let a be a point in 
, and let 0 be the valuation [ fx ! ag.
Then there exists an extension T 0 of T by x such that 0 satisfies T 0 .
Proof: If T is the empty tree, the statement is trivial. If T contains the single symbol y,
then if a = (y) then operation (2) applies with M .label=0; if a 6= (y) then operation (2)
applies with M .label=1.
Otherwise, let y be the symbol in T such that od( (y); a) is minimal. (We will deal
with the case of ties in step (D) below.) Let F be the father of y in T .
Let D=od( (y); a). Let V be the set of all orders of magnitude od( (p); (q)), where
p and q range over symbols in T . We define L to be the suitable label for D as follows: If
D 2 V , then L is the label in T corresponding to D. If D is larger than any value in V
then L is the label of the root of T plus 1. If D 62 V , but some value in V is larger than D,
then let D1 be the largest value in V less than D; let D2 be the smallest value in V greater
than D; let L1 , L2 be the labels in T corresponding to D1 , D2 ; and let L = (L1 + L2 )=2.
One of the following must hold:
A. (y) = a, and F .label=0. Then apply operation (3) with N = F .
B. (y) = a and F .label 6= 0. Then apply operation (4) with M .label = 0.
C. (y) 6= a, but od( (y); a) is less than od( (z ); a) for any other symbol z =
6 y in T .
Apply operation (4) with M .label set to the suitable value for D in T .
D. There is more than one value y1 : : : yk for which od( (yi ); a) = D. It is easily shown
that in this case there is an internal node Q such that y1 : : : yk is just the set of symbols
in the subtree of Q. There are three cases to consider:

35

fiDavis

D.i D=odiam( (Q.symbols)). Then apply operation (3) with N = Q.
D.ii D > odiam( (Q.symbols)), and Q is not the root. Then apply operation (5)
with C = Q. Set M .label to be the suitable value for D. (It is easily shown that
D < odiam( (N .symbols)), where N is the father of Q.)
D.iii D > odiam( (Q.symbols)), and Q is the root. Apply operation (6).

2

Lemma 25: Let A = fa1 : : : ak g be a finite set of points whose diameter has order-ofmagnitude D. Then there exists a point u such that, for i = 1 : : : k, od(u; ai ) = D.
Proof: Let b1 = a1 . By axiom A.8 there exists an infinite collection of points b2 ; b3 : : :
such that od(bi ; bj ) = D for i 6= j . Now, for any value ai there can be at most one value bj
such that od(ai ; bj )  D; if there were two such values bj 1 and bj 2, then by the om-triangle
inequality, od(bj 1; bj 2 )  D. Hence, all but k different values of bj are at least D from any
of the ai . Let u be any of these values of bj . Then since od(u; a1 ) = D and od(a1 ; ai )  D
for all i, it follows that od(u; ai )  D for all ai . Thus, since od(u; ai )  D but not od(u; ai )
 D, it follows that od(u; ai) = D. 2
Lemma 26: Let T be a cluster tree; let be a valuation over om-space 
 satisfying T ;
and let T 0 be an extension of T by x. If 
 is dense and unbounded above, then there is a
value a such that the valuation [ fx ! ag satisfies T 0 .
Proof: For operations (1) and (2) the statement is trivial.
Otherwise, let L be an extending label of T . If L = 0, then set D = 0. If L is in T ,
then let D be the order of magnitude corresponding to L in T under . If L1 < L < L2
where L1 and L2 are labels of consecutive values in T , then let D1 and D2 be the orders of
magnitude corresponding to L1 , L2 in T under . Let D be chosen so that D1  D  D2 .
If L is greater than any label in the tree, then choose D to be greater than the diameter of
the tree under .
If T 0 is formed from T by operation (3), then using lemma 25 let a be a point such that
od(a; (y)) = odiam(N ) for all y in N .symbols.
If T 0 is formed from T by operation (4), then let a be a point such that od(a; (y)) =
D.
If T 0 is formed from T by operation (5), then let a be a point such that od(a; (y)) =
D for all y in C .symbols. (Note that, since M .label < N .label, D < odiam(N .symbols).)
If T 0 is formed from T by operation (6), then let a be a point such that od(a; (y)) =
D for all y in R.symbols.
In each of these cases, it is straightforward to verify that [ fx ! ag satisfies T 0 . 2
As we observed in Section 8 regarding lemma 28, the conditions on 
 in lemma 26
are necessary, and the statement is false otherwise. For example, let 
 be the om-space
described in example I, Section 3, of polynomials over an infinitesimal . Then 
 is not
unbounded above; there is a maximum order-of-magnitude O(1). Let T be the starting tree
of Figure 3 (upper-left corner), and let T 0 be the result of applying operation 6 (middle
bottom). Let be the valuation fu ! ; v ! 2; w ! 1g. Then satisfies T , but it cannot
be extended to a valuation that satisfies T 0 , as that would require x to be given a value
such that od(v; w)  od(x; w), and no such value exists within 
. The point of the lemma

36

fiOrder of Magnitude Comparisons of Distance

is that, if 
 is required to be both dense and unbounded above, then we cannot get \stuck"
in this way.

Lemma 27: Let T be a cluster tree. Let X be a variable not among the symbols of T .
Let ff be an open formula in L, whose free variables are the symbols of T and the variable
X . Let  be the formula 9X ff. Let 
 be an om-space that is dense and unbounded above.
Then there exists an instantiation of T in 
 that satisfies  if and only if there exists an
extension T 0 of T and an instantiation 0 of T 0 that extends and satisfies ff.
Proof: Suppose that there exists an instantiation of T that satisfies 9X ff. Then, by
definition, there is a point a in 
 such that satisfies ff(X=a). That is, the instantiation
[ fX ! ag satisfies ff. Let 0 = [ fX ! ag. By lemma 24, the cluster tree T 0
corresponding to 0 is an extension of T .
Conversely, suppose that there exists an extension T 0 of T and an instantiation 0 of T 0
satisfying ff. Let be the restriction of 0 to the symbols of T . Then clearly satisfies the
formula 9X ff. 2
Lemma 28: Let T be a cluster tree. Let  be an open formula in L, whose free variables
are the symbols of T . Let 
 be an om-space that is dense and unbounded above. If one
instantiation of T in 
 satisfies  then every instantiation of T in 
 satisfies .
Proof: We can assume without loss of generality that the only logical symbols in  are :
(not), ^ (and), 9 (exists), = (equals) and variables names, and that the only non-logical
symbol is the predicate \much closer". We now proceed using structural induction on the
form of . Note that an equivalent statement of the inductive hypothesis is, \For any formula
, either is true under every instantiation of T , or is false under every instantiation of
T ."
Base case: If  is an atomic formula \X = Y " or \much closer(W; X; Y; Z )" then this
follows immediately from corollary 4.
Let  have the form : . If  is true under , then is false under . By the inductive hypothesis, is false under every instantiation of T . Hence  is true under every
instantiation of T .
Let  have the form ^ . If  is true under then both and  are true under . By
the inductive hypothesis, both and  are true under every instantiation of T . Hence  is
true under every instantiation of T .
Let  have the form 9X ff. If  is true under then by lemma 27, there exists an
extension T 0 of T and a instantiation 0 of T 0 such that ff is true under 0 . By the inductive
hypothesis, ff is true under every instantiation of T 0 . Now, if 0 is an instantiation of T 0
that satisfies ff, and  is the restriction of 0 to the variables in T , then clearly  satisfies
9X ff. But by lemma 26, every instantiation  of T can be extended to an instantiation 0
of T 0 . Therefore, every instantiation of T satisfies . 2
Theorem 4: Let T be a cluster tree. Let  be an open formula in L, whose free variables
are the symbols of T . Let 
 be an om-space that is dense and unbounded above. Algorithm
decide(T; ) returns true if T satisfies  and false otherwise.
Proof: Immediate from the proof of lemma 28. 2

37

fiDavis

References
Cormen, T.H., Leiserson, C.E., and Rivest. R.L. (1990). Introduction to Algorithms. Cambridge, MA: MIT Press
Davis, E. (1990). Order of Magnitude Reasoning in Qualitative Differential Equations. In
D. Weld and J. de Kleer (Eds.) Readings in Qualitative Reasoning about Physical Systems.
San Mateo, CA: Morgan Kaufmann. 422-434.
Keisler, J. (1976). Foundations of Infinitesimal Calculus. Boston, MA: Prindle, Webber,
and Schmidt.
Mavrovouniotis, M. and Stephanopoulos, G. (1990). \Formal Order-of-Magnitude Reasoning in Process Engineering." In D. Weld and J. de Kleer (Eds.) Readings in Qualitative
Reasoning about Physical Systems. San Mateo, CA: Morgan Kaufmann. 323-336.
Raiman, O. (1990). \Order of Magnitude Reasoning." In D. Weld and J. de Kleer (Eds.)
Readings in Qualitative Reasoning about Physical Systems. San Mateo, CA: Morgan Kaufmann. 318-322.
Robinson, A. (1965). Non-Standard Analysis. Amsterdam: North-Holland Publishing Co.
Weld, D. (1990). \Exaggeration." In D. Weld and J. de Kleer (Eds.) Readings in Qualitative
Reasoning about Physical Systems. San Mateo, CA: Morgan Kaufmann. 417-421.

38

fi
	ff
fi 
			 ! #"$ % 
'&)( *,+( ---/.$0/1/243022

56789  :)((4;
-<!=?>7	%&:A@/;
--

BDC9EFCHGJIHK9LNMPOJQRC
SUTWVYX[Z\Z^]`_ba/]dcfe9gihjRkmloniprqWets
~

Znqprh6qW

lvuwZ^x9Vy]znWuwV|{|V,a}Wj

Z^]VFaj

$$ffr#

$$$

'9,'H

ff6$$$

')FA/
A)!4/U/

 ff)4

w
,,49z64?ffJ4Ayy46F64/\ffm6,
J?F4m 4H46i6f,/46, m
)
/A4! 6#9!/J?4Jyit
#64464
  ff H4m?o46#,64#?i?4W
 	  r4?J6wfi ff/Hff)
JA4?
 	v   4
 
 $/ 
?m  mWff)^
 !9?
 ?6?
 64m!4 6?i/  6?A4 m?J4mFJ
?  
 /JA   ? 44y 
?H4J9? 	  w 94A
 !#"$
964&
 %('*)
+,
A
/44?)?:
 	   ,6 44!zi 646

- .0/2143 ,5+764829

4ffff6W9;4/\?<	4

=<>!?A@ 7B:CDF7EFB @
G HJILKNMPORQTSfiULQU7VfiHJWfiHU7MTOLXLYZULS4[\XO&]^HMP_a`&bcULS:d`Rbfe
U7MK;[gONhjifOLMkWlW5URmnMUoipirqO
WHVWfiqKaMk\[jsKtS

uvwx ULYHJWfiV;[!UnyKNXVtezWfiqTO
W{HVteOLVfiV4HJ|7MT[!KNMkWfiVaULYW5S4\TWfiq}I
OLX\KNVaW5UgHWfiVaIAO
S4H~O
sXJKNVWfiqTO
W{VfiO
WfiHV5YZh]PT{qTHV
QTSfiULsXJKN[ULY4LzkgNqTOLVMz\T[!KtS4U7\TVO
QTQXHtO
WfiHU7MTV v ULWfiq<ePNLL x OLMkh^H[gQULS4WfiOLMW
R QTSfiULsXJKN[gV}SfiKNk\HJSfiKU7\TMWfiH~M|[!UzyTKNXVULY(QTSfiULQU7VfiHWfiHJU7MTOLX{YZULS4[(\TXOLVULScO
SfiKSfiKNy\TtHJsXJKW5UWfiqTHV
QTSfiULsXJKN[  [!U7M|WfiqKNVfiKQTSfiULsXJKN[VO
SfiKL v O x _aU7[!Q\WfiHMT|yKt|LS4KtKULYrsKNXHJKtYrH~MOQSfiULQU7VfiHJWfiHJU7MTOLX
V5WfiO
W5KN[!KNMkWf{irHJWfiqPSfiKNVfiQKNW:W5UOQTSfiULQU7VfiHJWfiHJU7MOLXmnMUoiRXJKNy|LK;sOLV5K{OLVOU7MTyHJWfiHJU7MTOLXzQTSfiULsO
sHXHJWh
ULY|7HJILKNM}  MWfiqKO
sV5KNMTKULYOPVfi\}tHJKNMkWfV5WfiO
WfiH~V5WfiHtVaWfiqTHVfQTS4ULsO
sHXHWh!tOLMsKRKNV5WfiH~[gO
W5KNyskh
 uv 7 x  uv  x   v s x  MYKtS4KNMTK;HMPfOohLKNVfiHOLM!sKNXHKtYMKtWifULSfimnVt  V  ULWfiq v NLL x VfiqTUoifKNy<e
WfiqK;QTS4ULsXJKN[ULY<U7\TMkWfiHM|[!UnyKNXVlULYOQTSfiULQU7VfiHWfiHJU7MTOLXkYULS4[(\TXOtOLMgsK;S4KNyT\TKNy!W5UWfiqTK;QTSfiULsXJKN[ULY
U7[!Q\TWfiHM|(WfiqKQTSfiULsO
sH~XHJWh!WfiqO
WaOPMUnyKHMO!aONhLKNVfiHOLMcsKNX~HJKtYMKtWifULSfimHVfW5S4\KL v  x _fU7[gQ\WfiHM|
WfiqKMz\T[jsKtSULYVfiU7X\WfiHJU7MTV}ULYOU7MV5W5S4OLHMkWVfiO
WfiHV5YOLWfiHJU7MQTSfiULsXJKN[  _a`&b*YULS4[(\TXO w U7M^
I
O
S4HO
sXJKNV (ttt [ONh^sKSfiKt|7O
SyKNyOLVOU7MTV5W5S4OLH~MWVfiO
WfiHVfiYZOLWfiHJU7MQSfiULsXJKN[HM^irqTH~4q^WfiqK
yU7[gOLH~MULYKNOL4qI
O
S4HO
sXJK&HVRo  A7eOLMTy}KNOL4qctX~OL\TV5KHVO(SfiKNX~O
WfiHJU7M}o  A  ULYOLX~XMnFWfi\TQXJKNV
YZULSirqH4qO
WPXJKNOLV5WU7MKXHJW5KtS4OLX:ULYROLVfiV4\T[!KNVWfiqTK}I
OLX\K
{qKNMWfiqTKQTSfiULsXJKN[ULY{U7[!Q\WfiHM|
WfiqKMk\[jsKtSjULY{VfiU7X\WfiHJU7MTVjULYrVfi\TqQSfiULsXJKN[gVHVWfiqTK}U7MKULY{U7[!Q\TWfiHM| uvw(x  v y xj V5WfiH~[gO
WfiHM|
WfiqK\WfiHX~HJWhgULYSfiKNOLV5U7MTH~M|PirHJWfiqO
QTQTSfiUonH[O
W5KWfiqKtULSfih}rHMTVfiW5KNOLy}ULYWfiqKULS4HJ|7H~MTOLXWfiqTKtULSfih{qTHV
\WfiHX~HJWhyKtQKNMTyTVfU7McWfiqKV4HJtKULY  uv { x 
^ uv  x  v ULWfiq<eNLL x 
 MULWfiqKtSlH[!QULSfiWfiOLMkWO
QTQX~HtO
WfiHJU7MjH~VW5UrS4KNOLV5U7MTHM|RirHJWfiqHMTU7[!QXKtW5KHMYZULS4[gO
WfiHJU7M v G&SfiUoILKaKtWlOLXJe
NLAULNHMTV5mnHHe<NLLzeNLL x   MTyKtKNy<eTHYl]yTKNVfiS4HJsKNV;O!SfiKNOLXiULS4X~yYOLHJWfiqY\TXXJhLezWfiqKNM|7HILKNMO
YZULS4[\XOVfi\Tq!WfiqTO
WMTKNHJWfiqKtSMULSa:HVOXJUL|7H~tOLXU7MTV5KNz\KNMTKrULY]ezOSfiKNOLV5U7MTO
sXJK{OLVfiVfi\T[gQTWfiHJU7M
HVaWfiqTO
WrWfiqKj[!ULSfiK[gUzyKNX~V;ULY:]OLVfiV5KtSfiW&eWfiqTKj[!ULSfiKXHmLKNXJh}HV{WfiqTO
WRHV;W5S4\TKHM


( --- %%!:t
:aA/
fw
!fi8y
7!	%&%		&/%%~/ :

fi

RRT

{qTKcQTSfiULsXKN[ULYU7\TMkWfiHM|[gUzyKNX~VHV}!:U7[!QXKtW5KHM|LKNMKtS4OLX vZ OLXHOLMkWteN7
 x eROLMTyV5Ue
OLtULS4yTH~M|rW5UWfiqKQTSfiKNV5KNMkWVfiWfiO
W5KULYTWfiqTKfO
SfiWlHMjWfiqKKNX~y<eAU7[gQ\WfiO
WfiHJU7MTOLX~XJhHMW5SOLWfiO
sXJKaHMWfiqKfifULS4V5W
tOLV5KL{d\sU7HV v NLn x HMkW5SfiUnyT\TKNycOLMOLXJ|LULS4HJWfiq[WfiqTO
WRYULS&OLMhYZULS4[(\TXO}]ULYlIAO
SHO
sXJKNV{OLMyc

tXOL\TVfiKNVtekKNOLqctXOL\TVfiK&U7MkWfiOLHMTHMT|jX~HJ W5KtS4OLXVt ezU7\TMkWfiVf[gUzyKNX~VULY]H~MWfiH[gK v c  x en sKNHM|WfiqK
QU7VfiHJWfiHJILK}SfiUzULW(ULYrWfiqKQU7XhzMU7[HOLX:    ( ttT  v 

     
    A   0
    ttt


OLMTy}XH[ 
	  ff  x   KNKNMWfiXJhLe fiqOLM| v NLL x QTSfiKNV5KNMkW5KNyOLMOLXJ|LULS4HWfiqT[sOLVfiKNygU7MVfiH[gHX~O
SHyKNOLV
OLMTypirHWfiqV4H[gHXO
S(WfiH[!KU7[!QXJKnHWhLp{qKWfiH[!KcU7[!QXJKnHWhOLqTHJKtILKNyszhWfiqKNV5KcOLXJ|LULS4HWfiqT[gVPHV
OLMH[!QULSfiWfiOLMkWRH[gQTSfiUoILKN[gKNMW&UoILKtSWfiqTO
W&ULYOMTOLHJILKPOLXJ|LULS4HJWfiq[ irqH4q4qKN4mzVOLX~XOLVfiVfiH|7MT[!KNMkWfiVRULY
W5S4\WfiqcIAOLX\TKNVaW5UgWfiqKI
O
S4HO
sXKNVaULYlOPYZULS4[(\TXO]HMWfiH[!K v 
  x
UV4O
WfiHV5YZhQTS4OLWfiHtOLXfO
QTQXH~tO
WfiHJU7MTVteU7MKqTOLVjKNHWfiqKtSW5USfiKNV5ULS4WW5UO|LUzUn
y 2 LZ
 7
ULY
&
e
L
U
c
S
T
\
5
V

K
L
O

M
L
O
J
X
L
|
L
U
4
S
J
H
fi
W

q
[
Z
Y
L
U
c
S


7
U
!
[

Q
T
\
fi
W

H

M
|






N







r
i
J
H
fi
W

q

O
fi
S
N
K
L
O
5
V
7
U

M


O

s
J
X
K








 okWfiH[!K
uvwx
uvwx
U7[!QXKnHJWhL
 Kt|7O
S4yTHM|WfiqKS4VfiWOLXJW5KtS4MO
WfiHJILKLe\TskhOLMy  KNX~"H ! mLUoInH  # v NLn x QTSfiKNVfiKNMW5KNypOyKtW5KtS4[gH~MTHV5WfiH
OLXJ|LULS4HWfiqT[YZULSO
QQTSfiUNH[gO
WfiH~M|{WfiqKQTSfiULQULSfiWfiHJU7MULYW5S\WfiqjOLVfiV4HJ|7MT[!KNMkWfiVWfiqO
WVfiO
WfiHVfiYhORd&`&bcYZULS4[(\TXO

]Kt%
W $' & )
w ( yKNMULW5KWfiqTH~VaQTSfiULQULSfiWfiHJU7M v $* & +
w ( ff uvw(x   iRqKtSfiKPH~VaWfiqKMk\[jsKtS;ULYIAO
S4H~O
sXJKNV
ULY] x GHJILKNM}V4[gOLXXTMz\T[sKtSV , / .10 nenWfiqK&OLXJ|LULS4HJWfiq[ U7[!Q\TW5KNVOLM}KNV5WfiH[gO
W53
K 2UL4
Y $' & )
w ( irqTH~4q
VfiO
WfiHV5KNV
v   . x $* & +
w (  ,6587958$* & +
w (;: , 
KtW OLMTysKgWfiqTK}Mz\T[jsKtSULY{tX~OL\TV5KNV(OLMTyI
O
S4HO
sXKNVULYR]eSfiKNVfiQKNWfiHILKNXJhL{qKS\TMTMTHMT|
WfiH[!KULYlWfiqKOLX|LULS4HJWfiqT[H~VaKNV5WfiH[gO
W5KNyskhO!QU7XJhnMU7[gHOLXHMOLMTy [(\TXJWfiHQXHJKNy}skh
=<

/?> +	A@BDC	@EF> .+		;BGC	-F> C	H?> .. 
+

IzUeTWfiqTKS4\TMTMTH~M|WfiH~[!KULYWfiqTKjOLXJ|LULS4HJWfiq[|LSfiUoirVrYZOLVfiW{irHJWfiqWfiqKQSfiKNtHVfiHJU7MS4KNk\THSfiKNy<
HMTHOLXTOLMy}`&HVfiOLM v NL
 x V5Wfi\TyTHKNygWfiqK&QTSfiULsXKN[ULYU7[!Q\WfiHM|WfiqTK&VfiHtKRULYO(\TMTHJU7MULYO|7HJILKNM
YOL[gHXJh}ULYV5KtWfiV+J ( KJ  tt KJ B szh[gKNOLMTV{ULYWfiqK  MTtX\TV4HJU7Mn  tX\TV4HJU7MgYZULS4[(\TXO
B
 L J M ff P
 J M P
 J M'W J U  :
 J MW J UHW J Y (tt
P
P
MO#N (
(RQ*MSQ*B
(RQ*MSTVUQ*B
(RQ*MSTVUXTYZQ*B
: v   x BG#C (  J ( W tt W J B  
g
vx

 qTKthVfiqTUoifKNyWfiqTO
W{WfiqKV4HJtKULYlWfiqK\TMTHJU7MtOLMsKO
QTQSfiUNH[gO
W5KNycOLtt\TS4O
W5KNXJhirqKNMWfiqKV4HJtKNV
{
ULYaU7MTXJhQO
SfiWULYaWfiqKgV5KtWjH~MW5KtS4VfiKNWfiHJU7MTVO
SfiKmzMUirM<[In\TQTQU7V5KPWfiqKgHMkW5KtS4V5KNWfiHJU7MVfiHJtKNVO
SfiK!mnMUirM
YZULS(OLXXVfi\sTYOL[gHX~HJKNVU7MWfiOLH~MTHM|O
WP[!U7V5]
W \V5KtWfiVt  _
Y ^a`9b dv c  x elWfiqKNMWfiqTK}\TMTHU7MVfiHJtKtOLMsK
O
QTQTS4UNH[gO
W5KNyirHWfiqO!SfiKNXO
WfiHJILKKtS4SfiULS{ULY fv e   YhgRi B x 
 V!HMHOLXOLMTyp`&HVfiOLM v NL
 x QU7HMkW5KNyU7\TWteWfiqTHV(SfiKNVfi\XJWtOLMpsKO
QTQXHJKNyW5UO
QTQTSfiUonH~[gO
WfiHM|
WfiqK!Mz\T[jsKtS&ULY[!UnyKNXVRULYOd`&bYZULS4[(\TXOk
] j KNOL4qtXOL\TV5K(ULYa] qTOLVHJWfiVV5KtWULYf[!UzyTKNXVte<OLMTy
W \W5KtS4[gVRULYWfiqK
uvwx HV{KNz\TOLXW5U}WfiqTK(VfiHtKjULYWfiqK(\TMTHJU7MULYOLXXWfiqTU7V5K(VfiKtWfiVtR{qz\TVteU7MTXJhWfiqKjS4V5l
YZULS4[\XO v  x O
SfiKRMTKtKNyKNyYZULSaO|LUzUzyO
QTQTSfiUonH~[gO
WfiHJU7M<ekirqKtSfiK c m
 5n^o5q
 pRUoifKtILKtSNeYZULSfOqTHJ|7q
QTSfiKNtH~VfiHJU7M<re \O
QQTSfiU7OL4qTKNVPbULS&HMTV5WfiOLMTKLeYZULS{ ff tL}OLMTycOLMKtS4SfiULS{ULYat   e ^]sA 
 ifOL[O v NLL x H~MW5SfiUnyT\TKNy!OLMOLXJ|LULS4HJWfiqT[YULSW5KNVfiWfiHM|jVfiO
WfiH~V2O
sHX~HJWhULY<Oj_a`&bYZULS4[\XOj]UILKtS
^IAO
S4H~O
sXJKNV(skhU7\TMWfiH~M|WfiqKW5S4\WfiqpOLVfiVfiHJ|7M[!KNMWfiV(YOLXVfiHJYZhnHM|] OLMyqKNfimnHM|HY;WfiqKNHJS!Mk\[jsKtS
HVXJKNVfiVWfiqOLt
M   {qKU7\TMkWfiHM|HVOLtU7[!QXHVfiqKNy^WfiqS4U7\|7qOLM  MtX\TVfiHJU7M  tX\TVfiHJU7MQTSfiUnKNVfiVte
irqKtS4KWfiqKjVfiHtKjULYlWfiqKVfiKtWrULYlW5S4\WfiqOLVfiVfiHJ|7MT[gKNMWfiVrYZOLXV4HJYhnHM|]HVrU7[!Q\W5KNycirHWfiqWfiqKOLH~yULY:WfiqK
ULsV5KtS4IAO
WfiHJU7MWfiqO
W;WfiqTHV;V5KtW{HVaWfiqTK\MTHJU7MULYWfiqTKV5KtWfiV;ULYW5S\WfiqOLVfiVfiHJ|7M[!KNMWfiVaYOLXVfiHYhnHM|KNOL4qtX~OL\TV5K

uwvXx

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff
ULYR](  iaOL[gOOLMOLXJhktKNyWfiqKOoILKtS4O
|LKS4\TMTMTH~M|WfiH[!KgULY{qTH~VOLXJ|LULS4HJWfiq[ U7MWfiqKVfiOL[!K}YS4OL[gKtiULSfim
OLVifKgyTHyYULSjWfiqK!OLXJ|LULS4HJWfiqT[ ifK!QTSfiKNVfiKNMWHMWfiqKgV5KNz\KNXprKgV4qUoifKNyWfiqTO
WYZULSO_a`&bYZULS4[(\TXO
   :e<irqKtSfiK(HV&WfiqK
VfiO
WfiHVfiYhnHM|WfiqK!U7MTyTHJWfiHU7MWfiqO
W&YZULSOU7MTV5WfiOLMkl
W AeVfi\TqWfiqTO
WX6
M ` X~Ma 
Mz\T[jsKtSULYI
O
S4HO
sXKNVte H~V:WfiqKrMz\T[sKtSULYtXOL\TV5KNVtezOLMTy  HV:WfiqKRQTSfiULsO
sHXHJWhWfiqTO
WOj|7HJILKNMX~HJW5KtS4OLX
O
QTQKNO
S4V{H~MOgtXOL\TV5K v WfiqKjVfiOL[!KjYULS&OLXX<XHJW5KtS4OLX~V x eWfiqKjOoILKtS4O
|LKS\TMTMTHMT|WfiH[gKULYWfiqTKjOLXJ|LULS4HJWfiq[HV
 vK
  C#( x 
ULNHMTV5mnHH v NL  x KN[!QXJUhLKNyOLMOLX|LULS4HJWfiqT[ irqTHqH~V(V4H[gHXO
SW5UWfiqTO
WPQTSfiKNV5KNMkW5KNyskh  iaOL[gO
v NLL x eYZULSPU7\TMWfiH~M|[!UnyKNXVNK
 prKVfiqUiKNyWfiqTO
WP\TMTyKtSSfiKNOLV5U7MTO
sXK}OLVfiVfi\[!QTWfiHJU7MTVNeWfiqKONILKtS4O
|LK
S4\TMMTHM|gWfiH~[!KULYfU7[!Q\WfiH~M|}WfiqTKKOLWMk\[jsKtSULY[!UnyKNXV&ULYOYZULS4[\XOiRHJWfiqtX~OL\TV5KNV&U7Mp
I
O
S4HO
sXJKNV;H~Vr v    x eTirqTKtSfi

K  ff  v XJUL| x 
 MWfiqK&VfiKNk\KNXifKQTSfiKNV5KNMkWfOLMOLX|LULS4HJWfiqT[*irqTHqifKtOLXX_ad v _fU7\TMkWfiHM|(skh}d&OoIzH~V2\WfiMOL[ x
YZULSPU7[gQ\WfiHM| uvwx QTSfiKNtHVfiKNXJhL  XJ|LULS4HJWfiq[ _adHVsOLV5KNyU7MWfiqKdONInHV2\TWfiMTOL[ QTSfiUnKNyT\SfiK
V  \WfiMOL[eNL
 x YULSV5U7XJInHM|WfiqKV4O
WfiHV2O
sH~XHJWhQTSfiULsXJKN[ v I   x  KV5Wfi\TyTh
v d xv dONInHK
YZKNO
Wfi\SfiKNVgULYdefOLMTyVfiqUiqUiHJWfiVgS4\TXJKNVgtOLMsKc[!UzyH KNy<eSfiKNVfi\TXJWfiH~M|HMOLMOLXJ|LULSHJWfiqT[ YZULS
U7\TMkWfiHM|c[!UnyKNXVN  MOLMTOLXJhnVfiHVVfiqTUoirVWfiqO
WYULSOcYULS4[(\TXOc] iRHJWfiqp tXOL\TVfiKNVU7MIAO
S4H~O
sXJKNVte
y HVWfiqK{QTSfiULsO
sHXHJWh
WfiqKrOoILKtS4O
|LKS4\TMTMHM|&WfiH[!K{ULY_adHV v K
  x ekirqKtSfi
K  ff 	  +( ( . ezOLMT



@
WfiqTO
WrOLMkhXHJW5KtS4OLXUntt\S4VrHMOP|7HJILKNMtX~OL\TV5KL
IzKNWfiHU7MpyKNVfiSHJsKNVMz\T[!KtSfiU7\VKnQKtSH[!KNMkWfiVjirHWfiqp_adVfiqTUoirHMT|WfiqTO
W!HJWfiV(OLWfi\TOLXaONILKtS4O
|LK
WfiH[!KcU7[gQXJKHJWhpHVgVfiH|7MTH tOLMkWfiXJhXJUiKtS}WfiqTOLMWfiqK\QTQKtSPsU7\MTyTV(QTSfiUIzHyTKNypskh[gO
WfiqKN[O
WfiHtOLX
OLMTOLXJhnVfiHVH~
M IzKNWfiHJU7
M cOLMTyHMQTS4KtIzHJU7\ViULSfimnV v d\sU7HVteNLn
  iaOL[gOneaNLLzULNHMTVfimzHHFeNL z
fiqTOLMT|eNLL x - KjOLX~V5U!QU7HMW;U7\TW{OLyIAOLMkWfiO
|LKNVRULYWfiqTH~V{MKtiOLXJ|LULS4HWfiqT[ UoILKtSRWfiqKU7MKNV{QTSfiKNV5KNMkW5KNy
HMWfiqKNV5KQTSfiKtInHJU7\TViULSfimnVtblHMTOLX~XJhLeifKRKNVfiWfiH[gO
W5KNyc_adpQKtSfiYULS[gOLMTKrU7M}YZULS4[\XOLViRHJWfio
q X~HJW5KtS4OLX
tXOL\TVfiKNVteOLMTyU7[!QO
SfiKNyWfiqKSfiKNVfi\XJWfiVW5UPWfiqU7VfiK&ULY4qKN4mzH~M|PWfiqKVfiO
WfiHV2O
sHXHJWh(ULYVfi\T4qYZULS4[(\TXOLVskh
dQTSfiKNV5KNMkW5KNycszhHJWfiqKNXX<KtWrOLXF v NL  x 
 BE-
2B}BD
l> 

@ 7E @



B:Cq4


M WfiqKjV5KNz\KNX<ifKjU7MTV4HyKtS;QTSfiULQU7VfiHWfiHJU7MTOLXYULS[\TX~OLV;UoILKtSOgV5KtW ff N (NtttN jULYIAO
SHO
sXJKNVte<
yKNMULW5KNVROgXHJW5KtSOLX v"E N (NtttN    (ttt  x eOLMTy   V5WfiOLMyTV;YZULS{WfiqKMKt|7O
WfiHJU7MULY

 f HHh/i4#^V#

{qKdONInHV2\WfiMTOL[QTS4UzKNyT\TSfiK v d xv dONInHV \TWfiMTOL[ePNL
 x HVHMkW5KNMTyKNy^YULScyTKNtHyTHM|
VfiO
WfiHV5O
sHXHWhULYOQSfiULQU7VfiHJWfiHJU7MTOLXl_a`&bYZULS4[(\TXO] v SfiKt|7O
S4yTKNyOLVOV5KtWULYtXOL\V5KNV x eOLMTytOLMsK
QTSfiKNVfiKNMW5KNycOLVRO!SfiKNt\SVfiHJILKsUkU7XJKNOLMcYZ\TMWfiHJU7M v OLVfiVfi\T[HM|PWfiqTO
WrMUgtX~OL\TV5KULY]HV;OgWfiOL\W5U7XJUL|Lh x 
YZ\TMWfiHJU7Md v ]PQTSfiULQU7VfiHWfiHJU7MTOLX<_a`RbpYZULS4[(\TXO x 

rHY w ~H VaKN[!QTWhWfiqKNM
SfiKtWfi\S4M"#
zrHY:]U7MkWfiOLHMTVROLMKN[!QTWhtXOL\TV5KWfiqKNM
SfiKtWfi\S4
M 
tt
z vd {qKQ\S4KXHJW5KtS4OLXS4\TXK Ax
HYWfiqKtS4KKnHVfiWfiV{O!Q\S4KX~HJW5KtS4OLXllHM] vd V4\T4qWfiqO
W  yUkKNVrMULWrO
QTQKNO
SrHM] A x WfiqKNM
w ( ff A   w  D  (7 dv  yKNXJKtW5KYZSfiU7[]OLX~XtXOL\TV5KNVrU7MWfiOLHMHM| Ax
SfiKtWfi\S4Mcd vw ( x  dv  ]H~V;VfiO
WfiHV2O
sXJKH  w ( HV{VfiU Ax

uwvX

fi

RRT

 dv  {qK\TMTHWatX~OL\TV5KS4\TXK Ax
HY:]U7MkWfiOLHMTVROg\TMTHWatX~OL\TV5KP   vd OgtX~OL\TV5KU7MTVfiH~V5WfiHM|PULY:O!VfiHM|7XKX~HJW5KtS4OLX Ax WfiqKNM
w ( ff A       w  G  (7 vd yKNXJKtW5KYZSfiU7[ ]  OLMycOLXX<tXOL\TVfiKNV{U7MWfiOLH~MTHM| A x
SfiKtWfi\S4Mcd vw ( x  dv  ]H~V;VfiO
WfiHV2O
sXJKH w ( HV{VfiU Ax
z vd {qKV5QX~HJW5WfiHM|(S4\TXJK Ax
qUzU7V5KOPI
O
S4HO
sXl
K cULY](


A






w ( ff
   w     (7


A


N



  w      (7
w ff
S4KtWfi\S4M v d vw ( _
x  d vw  x5x  dv  ]HV;VfiO
WfiH~V2O
sXJKH  vw ( w  x HV;V5U Ax
 WrtOLMcsKV5KtKNMWfiqTO
W{WfiqKjQ\SfiKXHJW5KtSOLXS4\TXJKOLMTycWfiqK\TMTHJW{tX~OL\TV5KS4\TXKO
S4KjOLWfi\TOLXXJhQO
S4WfiHt\TXO
S
tOLV5KNVaULYWfiqTKVfiQXHJW5WfiHMT|S4\TXJKL  YWfiqKtSfiKKHV5WfiVfOQ\SfiKRX~HJW5KtS4OLXHM]enOLMTyWfiqKV5QXHW5WfiHM|S4\XJKRqUkU7VfiKNV
eWfiqKNM w (  w 
eOLMTyqKNMK vw ( w  x HVVfiO
WfiH~V2O
sXJKPH  w ( HVV5U  tULSyTHM|W5UcWfiqK!V5QXHJW5WfiHM|
S4\TXKLez]H~VVfiO
WfiHV5O
sXJKrH  vw ( jw  x HVV5UenOLMTyqKNMKLen]HVVfiO
WfiH~V2O
sXJKRH  w ( H~VV5U{qHV:HVKOLWfiXJh
WfiqKQ\SfiKXHJW5KtS4OLXS\TXJKL
 Y&] U7MkWfiOLHMTV!O\TMTHJW(tXOL\TV5K  7eOLMTyWfiqKV5QX~HJW5WfiHM|cS\TXJK}qUzU7V5KNVeWfiqKNM w  U7MWfiOLH~MTV!OLM
KN[!QTWhtXOL\V5K v WfiqK\TMHJWtXOL\V5K}iRHJWfiqU7\W(HJWfiV(U7MTXJhXHJW5KtSOLX x e:OLMTypV5UeHV(\TMTVfiO
WfiHV5O
sXJKL
 IzUe] HV
VfiO
WfiHV5O
sXJK!H  w ( H~VV5U{qTH~VHVWfiqKg\TMTHWtX~OL\TV5K!S4\TXKL v  MTtH~yKNMWfiOLX~XJhLe<WfiqKV5QXHJW5WfiHM|S4\TXK(W5S4KNO
WfiV
ifKNXXWfiOL\TW5U7XJUL|7HtOLX:tXOL\TVfiKNVrW5UzU  YOtXOL\V5
K ULYf]*U7MWfiOLHMV&OXHW5KtS4OLXOLMyHJWfiVU7[!QXJKN[!KNMkW  e
OLMTyWfiqTKV5QXHJW5WfiH~M|S\TXJKHV{O
QTQXHJKNyW5UceTWfiqKN8
M  irHX~XsKKtS4OLV5KNyYS4U7[ sULWfiq w ( OLMTy w 
 x
{qz\TVteAifKf[gOohU7MTVfiHyTKtSdOLVsKNHM|{sOLVfiKNyU7MWfiqKfVfiQXHJW5WfiHMT|fS\TXJKU7MTXhLeAiRqTHXJK:WfiqKWifUULWfiqKtS
S4\TXKNVV5KtSfiILKOLVf|7\THyTKNVYZULS;4qUzU7VfiHM|(OX~HJW5KtS4OLXK}tHJKNMkWfiXJhL  MyKtKNy<enHJY]U7MWfiOLHMVfO(\TMTHWtXOL\TV5K  
ULSOQ\SfiK{XHJW5KtSOLXe7WfiqTKNMgO
QTQXJhnHM|WfiqK{VfiQXHJW5WfiHMT|&S\TXJKaW5UghzHJKNX~yTVU7MTXJh
RYZULS4[\XOneLs\WqUkU7V4HM|
OgMU7MFQ\SfiKOLMTycMTU7Mn\TMTHJW2tX~OL\TV5KXHJW5KtS4OLX<XJKNOoILKNVrWiU}YULS[\TX~OLVaYULS{Y\SfiWfiqTKtS;QTSfiUnKNVfiVfiHM|
 Y]U7MkWfiOLHMTV:MTKNHJWfiqKtSO\TMTHJWltXOL\TVfiK{MULS:OQ\SfiK;XHJW5KtSOLXe
WfiqKNMPWfiqK{XHJW5KtSOLXYZULSWfiqK;V5QX~HJW5WfiHM|RS4\TXJK
VfiqU7\XysKqU7V5KNMcHMV4\T4qOPiaONhWfiqTO
W;QTS4UzyT\KNV;V5KtWfiV w ( OLMTy w &WfiqTO
WRO
SfiKOLV{Vfi[gOLX~XOLV{QU7V4VfiHJsXJKL
KOLyySfiKNVfiVaWfiqTH~V;HVfiVfi\KH~MWfiqKV5KNz\KNX

 
 

r b

# 

{qTH~MmzH~M|ULYRU7\TMkWfiHM|[!UnyKNXVULYROQTSfiULQU7VfiHJWfiHU7MTOLXYZULS4[(\TXO]elifKMTULWfiHKWfiqTO
WPskhqUzU7VfiHM|O
I
O
S4HO
sXJK)LenWfiqKV5QXHJW5WfiHM|S4\TXJK&OLWfi\TOLXXJhV5QXHWfiVWfiqKV5KtWaULY[!UzyTKNXVfULYl]HMkW5UPWifUgyTHVS5U7HMkWVfi\sV5KtWfiVt
U7MK!HMirqTH
q HV&W5S4\K v MTOL[!KNXhLe<WfiqK([gUzyKNX~VRULY w ( x eOLMyWfiqTKULWfiqKtS v [gUzyKNX~VRULY w  x HMirqTH~4q
PHVRYZOLX~V5KL{qKP4qU7V5KNMI
O
S4HO
sXK O
QTQKNO
S4VMKNHWfiqKtS&H~M w ( MULSHM w 
eOLMyWfiqKtS4KP[ONhcsK(ULWfiqKtS
I
O
S4HO
sXJKNVWfiqTO
WO
QTQKNO
S:HM!]s\WMTULWlH~M w ( v ULSMULW:HM w  x l{qKNV5K;O
SfiKaWfiqKaI
O
S4HO
sXKNVirqH4q(sKNXJU7M|
U7MTXJhW5UWfiqK}tXOL\V5KNVWfiqTO
W(U7MWfiOLH~MWfiqKXHJW5KtS4OLX  v ULS  elSfiKNVfiQKNWfiHILKNXJh x 
 pRKNMTKLelKtILKtSfih[!UnyKNXULY

t

L
O

M

s
j
K


7
U
g
[

Q
J
X
t
K
5
W
N
K
c
y
5
W

U

O
g
[
z
U

y
N
K

X
L
U

Y

]
z
s
c
h
L
O
fi
V
fi
V
J
H
7
|
T
M
~
H

M
c
|

"












t



eSfiKNV5QKNWfiHJILKNXh x W5
U LeOLMTy
w ( vw x
v
" #TRULS hL N&O
SfisHJW5S4O
SHXJhW5UKtILKtSfih!IAO
SHO
sXJKaULY]WfiqO
WyUzKNVMULWO
QQKNO
SHM w ( vw  ekSfiKNV5QKNWfiHJILKNXJh x 
KtW uvw(x VfiWfiOLMTyYULS;WfiqTKMk\T[sKtSaULY[!UnyKNXVfULYl]eTOLMTy ( v  x yKNMULW5KWfiqKMz\T[sKtSaULYIAO
S4H~O
sXJKNV


v ULWfiqKtSRWfiqTOLM x irqTHqUztt\SRHM]s\TW{MULW{HM w ( vw  x eWfiqKNM uvwx ff  > uvw ( 
x :  @ uvw  x 
 VHWqTOLVsKtKNMVfiqTUoirM(H
M InKNWfiHJU7
M z
e7HYT4qKN4mzHMT|&VfiO
WfiH~V2O
sHX~HJWhHVWfiqTK|LU7OLXe7OLMyjORQ\SfiKX~HJW5KtS4OLX
iv rqTH~4q!HVMTULWO\TMTHJWltXOL\TVfiK x HV:4qTU7V5KNMgYZULSV5QX~HJW5WfiHM|e
WfiqKNM!U7MXJh w ( VfiqU7\TX~yPsKaQTS4UzKNVfiVfiKNy!YZ\TSfiWfiqKtSNe
irqTH~XJK w [ONhsKyTHV5S4Kt|7O
S4yKNy<G
 prUiKtILKtSNeYZULSRU7\TMkWfiHM|[gUzyKNX~V;sULWfiq w ( OLMTy w [gO
W5W5KtSN;`RULW5K
WfiqTO
WHMcWfiqHVRtOLVfiK w U7MkWfiOLHMTVRWfiqKPVfiOL[!KPMk\[jsKtSrULYtXOL\TV5KNV&OLV]4
 IzUeHMU7MkW5S4OLV5WW5U4qKN4mzH~M|
VfiO
WfiHV5O
sHXHWhLenWfiqKQ\S4KXHJW5KtS4OLXS4\XJKWfi\S4MTVaU7\W;W5UsKH~MK}tHJKNMkW;YULSRU7\TMWfiH~M|g[!UnyKNXVt

uZ

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff
aOLV5KNyU7MWfiqKNV5KULsV5KtSfiI
O
WfiHJU7MTVteTWfiqTKYU7XXUoirHMT|(Y\TMTWfiHU7M_adU7\TMkWfiV{[!UnyKNXV{ULYO!YZULS4[(\TXO]
UoILKtS(IAO
S4H~O
sXJKNVt
YZ\TMWfiHJU7M_ad v ](QTSfiULQU7VfiHJWfiHJU7MOLX<_;`RbpYZULS4[(\TXOnHMW5Kt|LKtS x 

rHY w H~VaKN[!QTWhWfiqKNM
SfiKtWfi\S4
M  
zrHY:]U7MkWfiOLHMTVROLMKN[!QTWhtXOL\TV5KWfiqKNM
SfiKtWfi\S4Mcn
zrHY:]U7MkWfiOLHMTVROg\TMTHWatX~OL\TV5KP  jWfiqKNM
w ( ff A       w  G  (7
SfiKtWfi\S4M_;d& vw (N    x 
rqUzU7V5KOPI
O
S4HO
sXl
K cULY]
w ( ff A       w     (7
w  ff A  N   w      (7
S4KtWfi\S4M_ad vw (     _
x : _ad vw      x 
 MhHW5KtS4O
WfiHJU7MULY_adyKNXJKtW5KNVWfiqKqU7V5KNMIAO
S4H~O
sXJKLeOLMyjV5UeASfiKNyT\TKNVWfiqKMz\T[sKtSULYnIAO
S4H~O
sXJKNV
ULY] skhO
W{XJKNOLV5W;U7MKLrqTHVf|7\TO
S4OLMkW5KtKNV{WfiqTO
WR_;d&W5KtS4[gHMTO
W5KNV v KNHJWfiqKtS;U7MV5W5KtQULS;U7MVfiW5Kt
Q  x
 =4D
l> 

@@ E @

sE


M WfiqKOLMTOLXhzVfiH~VULYWfiqTK&OoILKtS4O
|LKS4\TMMTHM|WfiH[gKRULYWfiqTK&Y\TMTWfiHU7M_adpifK&YZU7XXJUiGU7XysKtSfi| v N7
 x
OLMTyGU7XysKtSfi|PKtWrOLX v NL x eirqU!V5Wfi\yTHJKNyWfiqKjOoILKtS4O
|LK(S4\TMTMTH~M|jWfiH[gKULYld

 f H;#= + #'

 KtWR OLMTyccyKNMTULW5KrWfiqK&Mk\T[sKtSULYtXOL\V5KNVOLMygI
O
S4HO
sXJKNVULY]ezSfiKNV5QKNWfiHJILKNXhL  VfiVfi\[!KrWfiqTO
WfOLXX

WfiqKPXHJW5KtS4OLX~VRqTOoILKPWfiqK(V4OL[!KPQTSfiULsO
sH~XHJWh]W5UO
QTQKNO
SHMKNOLqtXOL\TV5KULY;] v UV4H[!QXHYhWfiqK
OLMTOLXJhnVfiHVriKPOLXXJUi] W5UU7MWfiOLH~My\QXHtO
W5KtXOL\TV5KNV&OLMTyWfiOL\W5U7XJUL|7HJKNVt x  VfiVfi\T[!K(OLXV5UWfiqTO
W&WfiqKtSfiK
HV&MU}yTKtQKNMyKNMThOL[!U7M|WfiqK(Uztt\S4SfiKNMTKNVRULYyTH KtSfiKNMkWrI
O
S4HO
sXJKNVROLMTyOL[!U7M|WfiqKUntt\SfiS4KNMTKNV
ULYWfiqTK(VfiOL[gK(I
O
S4HO
sXJKHMyTH KtSfiKNMkWtXOL\TV5KNVtbULSO|7HJILKNMyHV5W5S4HJs\WfiHJU7MULE
Y eXJKtW& v    x yTKNMULW5K
WfiqKjOoILKtS4O
|LK(S4\TMTMTH~M|jWfiH[gKULY_;d& vw   x irHWfiq]U7MkWfiOLHMTHM| tXOL\TV5KNVt
 Y] U7MkWfiOLHMTVtX~OL\TV5KNVPU7MI
O
S4HO
sXJKNVteWfiqKNMPsU7\MTyTVWfiqKcVfiHJtKULY]  OL4qV5W5KtQULY
Y\TMTWfiHJU7M_adtOLMcsKOLtU7[!QXH~VfiqKNyyT\SHM|PO
Wr[!U7V5W{WiUQOLVfiV5KNVrUoILKtS]
N LkN#c

 wf #SntSnhfic~K4L#
#ThSL
 a !]4
 L
tPfiLzAjSnPZR(zfitZk
hRL
 #nN
4+%



 W;[gHJ|7qkWsK&WfiqU7\|7qkWteWfiqTO
W;HMULS4yKtSaW5UPULsTWfiOLHMO(|LUkUnysU7\TMTy}U7M}WfiqTKOoILKtS4O
|LKS4\MTMTHM|jWfiH[!K
ULYaYZ\MTWfiHJU7M_adeU7MKg[(\TV5WjV4qUoiWfiqO
WWfiqK\TMHJW&tX~OL\TV5KgS4\XJK!HVO
QTQXHKNyYZSfiKNz\KNMkWfiXJhLeVfiH~MTK!WfiqK
V5QX~HJW5WfiHM|(S4\TXJKHVaWfiqKjU7MKWfiqTO
WrHMkW5SfiUnyT\TKNVfWfiqKQU7VfiVfiHsHXHJWh!ULYKnQU7MKNMkWfiHOLXXJhXU7M|gU7[!Q\WfiO
WfiHU7MTVt
KVfiqUoi^WfiqTO
WKtILKNMHYU7MXJhPWfiqKRV5QXHJW5WfiHM|S4\XJKrHVO
QTQXHJKNye7XJUoi^sU7\TMTyTVO
S4KrULsTWfiOLHMTKNy<:{qKtSfiKtYZULSfiKLe
ifKOLVfiVfi\T[gKgWfiqTO
WjMU\TV5KgULYaWfiqK\MTHJWtXOL\TV5KS4\TXJK!HV[OLyKLeOLMTyOLMTOLXJhztKOI
O
S4HOLMkWULYr_adeHM
irqTH~4qcV5W5Kt3
Q !HVrU7[gHJW5W5KNy<6
 &skInHJU7\TV4XJhLeWfiqTHV{qTOLM|LKPyUzKNV{MULWRwO KNWRKN[g[gO
 K(OLXV5UOLVfiV4\T[!K
WfiqTO
W{WfiqTKjXHJW5KtS4OLXYZULSrWfiqKVfiQXHJW5WfiHMT|S4\XJKHV{4qTU7V5KNMcS4OLMyU7[gXJhL
KtW{sK;WfiqKRXHJW5KtS4OLXnWfiqTO
WfqTOLV:sKtKNMgqU7V5KNMgYZULSWfiqTK{V5QXHJW5WfiH~M|S4\TXJKLq
 InHMTKaWfiqKrQTSfiULsO
sH~XHJWhjWfiqTO
W
  xB  Y 
Untt\S4V:H~M(OtX~OL\TV5K{H=
V ekWfiqKaQTSfiULsO
sH~XHJWhWfiqO
6
W \jU7\WlULY tXOL\TV5KNV:U7MkWfiOLHMHV v BY x  Y v  +

uZ

fi

RRT

{qKVfiOL[gKqU7XyTVfYZULS  {qKMk\[jsKtS;ULYltXOL\TV5KNVaULYYULS[\TX~OLV w ( e w QTSfiUnyT\TKNyskhV5QXHW5WfiHM|g]HV
KNz\TOLXW5U(WfiqKMk\[jsKtSULYOLXXtXOL\V5KNVfULY][HMk\VWfiqKMk\[jsKtSULYtXOL\TV5KNVULY]irqTHqU7MkWfiOLHMWfiqK
XHJW5KtSOLXle  eSfiKNVfiQKNWfiHILKNXJhL

  _t#(nA w  w ]5N
T4Zk] 4L
Z(  ^t
zt]:S
    7
5VZ" v BY x  Y v   x B  Y  (
InH~MTK;KNOL4q}ULY w ( e w {U7MkWfiOLHMTVO
W[!U7V5W  {IAO
S4H~O
sXJKNVteLWfiqKRYU7X~XJUoirH~M|SfiKNt\SfiSfiKNMKrHMKNz\TOLXHJWh
YZULS; v    x qU7X~yTVt
 v  x

 # :
  BYN#( v BY x  Y v   x B  Y 

5   BYNr* v BY x  Y v   x B  Y 


v 
v 

^
^

    Rx :
  x



 m
 ` 


ff ] P ff

v x


 qKgS4V5WW5KtS[ v # x HVjWfiqKgWfiH[gKMKtKNyKNyYULSU7MK}HW5KtS4O
WfiHJU7MULYr_adrqKV5KNU7MTyOLMTyWfiqTHJS4y
{
W5KtS4[gV(O
SfiK}WfiqKKnQKNW5KNyWfiH[gKNVjMKtKNyKNyYZULSU7[!Q\TWfiHM|cWfiqKMk\[jsKtSjULY{[gUzyKNX~VULY w ( OLMTy w 
e
SfiKNV5QKNWfiHJILKNXhL6
 InH~MTKWfiqKX~HJW5KtS4OLXlTO
QTQKNO
S4V{H~M]eHJWrH~V{H[!QU7VfiVfiHsXJK&WfiqTO
WrWfiqKMk\T[sKtS{ULY:tXOL\TV5KNVRHM
irqTH~4qcUntt\S4VfHVneOLMTy}V5UezWfiqKRVfi\[g[gO
WfiHJU7MULYWfiqKRVfiKNU7MTyW5KtS[*V5WfiO
S4WfiVfO
W&
{qK&XHJW5KtS4OLX   [gONh
MULW;O
QTQKNO
S{O
W;OLXXHMc] v HJYHVfQ\SfiK x _fU7MV5KNk\TKNMWfiXJhLenWfiqKVfi\[g[gO
WfiHJU7MULYWfiqTK&WfiqHJS4y}W5KtS4[sKt|7HMTV
O
Wrn
{qTK&SHJ|7qW2qOLMTyVfiHyK&ULY v  x UILKtSfiKNV5WfiH[gO
W5KNV{ v    x VfiHMKLekS4V5WtenWfiqKMk\[jsKtSaULYI
O
S4HO
sXKNVULY
e
V L;gAl  
eOLMTy<e<V5KNU7My<e<YZ\MTWfiHJU7M_ad[gOohV5W5ULQirqTKNM] U7MWfiOLHMVOLMKN[!QTWh
w ( w PH
tXOL\TVfiKLeKtILKNMsKtYZULSfiKP ULSsKNU7[!KNV{n
UgKNV5WfiH[O
W5K v    x eTifKjVfiqTUoieS4V5WteTWfiqTO
WrYULS  ff   ze v    x ff  v    x eOLMTy<eVfiKNU7MTy<e
WfiqTO
W{YZULSrOLMk[
h e v    x ff  v    x irqKtS4

K  ff 	  +( ( . 
@ 
 4  ff
   H[*3#'=ki' 

 
bU7XXUoirHMT|GU7XysKtSfi| v N7
 x eifKV5WfiO
SfiWirHJWfiq^WfiqKOLMOLXJhzV4HVULYWfiqKOoILKtS4O
|LKS\TMTMTHMT|WfiH[!KYZULS
 ff   z  MWfiqTHVatOLV5KLeKNOL4qI
O
S4HO
sXJK&Untt\S4V;HM}KNOL4qctX~OL\TV5KQU7VfiHJWfiHJILKNXJhLenMKt|7O
WfiHJILKNXhULS{MULW;O
W;OLXX
irHJWfiqWfiqTKjVfiOL[!KQTS4ULsO
sHXHWh v    x %IzUeTSfiKNt\TSfiSfiKNMTK v  x WfiO
mLKNVRWfiqKYZULS4[
 v  x

   :
 v  x B  v      xR:

5    BYN#( v BY xv ( x Y v  x B  Y 



H  ]  ff ( <

v  x
S4UkULYlHVa|7HJILKNMHM  QQKNMyTH   

ff

 v   x 

v 

^

  `

  x


ff  A( ff

v x


   H[*3#'=ki' 4r 
{qKOLVfiV4\T[!QTWfiHJU7MULY  ff   
 HVPU7[g[!U7MTXhOLyULQTW5KNyH~MQSfiULsO
sHX~HV5WfiHgOLMOLXJhzV4HV(ULYROLXJ|LULS4HWfiqT[gV
qTOLMTyXHM|c_a`&bULSjd`RbYZULS4[(\TXOLV v bSOLMTU OL\XXeNLz fG&U7X~ysKtSfi|eN7
zG&U7XyTsKtS4|KtWjOLXJe
uZZ

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff
NL  x eLirqTH~4q[!KNOLMTVWfiqTO
WYZULSKNOL4qI
O
S4HO
sXJKLeAHJWfiV<Untt\SfiSfiKNMKHMO{tXOL\V5K:irHJWfiqULSirHJWfiqU7\WMTKt|7O
WfiHJU7M
ULS{MU7MnFUntt\SfiS4KNMTKLeTOLXXqTONILKWfiqTKVfiOL[!KQTSfiULsO
sHXHJWhLpRUoifKtILKtSNeHMSfiKNOLXtOLV5KNV{WfiqTH~Vf[ONhMULW;qU7Xy<e
V5U(iKOLMTOLXJhztKrWfiqTK&OoILKtS4O
|LKS4\TMTMHM|WfiH[!KRULY_adpYULSaOLMkhgQTSfiULsO
sHXHJW

h !ULYO(XHJW5KtS4OLXUztt\S4SfiKNMTK
HMOgtX~OL\TV5KULY]
fKtYZULSfiKOLMTOLXhkNHMT|WfiqKcSfiKNt\S4SfiKNMTKcKNz\TO
WfiHJU7MXJKtW\TVg[O
mLKWfiqKcYZU7XXJUirHM|KNV5WfiH~[gO
WfiHJU7M<^{qK
Y\TMTWfiHJU7M_ad v iRHJWfiqU7\W;WfiqK\MTHJWatXOL\TV5KS4\XJK x [gONhsKSfiKt|7O
S4yKNyOLVROLMOLXJ|LULS4HJWfiqT[iRqTH4qV4tOLMTV
OcsHMTO
SfihW5SfiKtKLc{qKSfiUkULWjULY;WfiqKW5SfiKtK}SfiKtQTSfiKNVfiKNMWfiVWfiqKHMTQ\WYZULS4[\XO]{qTK4qTH~XySfiKNMULY;KNOLq
HMkW5KtS4MTOLXlMUnyKPSfiKtQTSfiKNVfiKNMWWfiqKPYZULS4[(\TXOLVULsTWfiOLHMTKNyOLVOSfiKNVfi\TXWRULYaO
QTQXJhnHM|}WfiqKgV5QX~HJW5WfiHM|}S4\TXJK(W5U
WfiqKYZULS4[(\TXO!O
W{WfiqTO
WRHMW5KtSMTOLX<MUnyKLeTOLMTyWfiqKjXKNONILKNV{ULYlWfiqKW5S4KtKSfiKtQTSfiKNVfiKNMW{KN[gQTWhYULS[\TX~OLV{OLMTy
YZULS4[\XOLVairqTHqcU7MkWfiOLHMcOLMcKN[gQTWhtXOL\TV5KL
 YOLMHMkW5KtS4MTOLXMUnyKSfiKtQTS4KNV5KNMWfiV;OPYZULS4[(\TXO(irHJWfi
q \}tX~OL\TV5KNVtenWfiqKKnQKNW5KNycMk\[jsKtSaULYtXOL\V5KNV
  x :{qK;KnQKNW5KNygqKNHJ|7qkWlULYWfiqK;W5S4Kt)
HM(KNOL4qULYHWfiV:4qTHX~ySfiKNMPHq
V ^ v +
K PH~VlWfiqKtSfiKtYZULSfiK{O
sU7\W:XJULV| z
W HV{O
sU7\
W   e
irqKtS41
K  ff ( ( f{qKjMz\T[sKtS;ULYlMTUzyKNVRHMOU7[gQXJKtW5KsH~MTO
SfihW5SfiKtKULY:qKNHJ|7qk)



OLMTyWfiqHV{HVaWfiqKjKzQKNW5KNyMz\T[sKt6
S ULY:HJW5KtSO
WfiHJU7MTV;ULYlWfiqKY\TMTWfiHU7M_ad IzU*e  ff     ff AK
 Le
(
irqKtS41
K  ff 	  +( . &{qTKjS4\TMMTHM|!WfiH[gKULYKNOLqHJW5KtS4O
WfiHJU7MHV *v     x irqKtSfiK   HVRWfiqKPMk\[jsKtS
ULYtXOL\V5KNVaOLMTy @ 
  HV WfiqKMz\T[jsKtSULYI
O
S4HO
sXJKNVULYWfiqKYZULS4[(\TXOWfiqO
WaH~VW5SfiKNO
W5KNyO
WfWfiqO
WfHJW5KtSO
WfiHJU7M<

 v    x ff  v    x qEhfi+ ff 	  +( ( .  
@ 
S4UkULYlHVa|7HJILKNMHM  QQKNMyTH   
 YZKti SfiKN[gO
S4mzVO
SfiKHMULSyKtSN}blHJSV5WteifKOLVfiVfi\[!KNyWfiqTO
WjWfiqKgQTSfiULsO
sHXHJWhULYaUntt\SfiS4HMT|cHMO
tXOL\TVfiKjHV;WfiqK(VfiOL[!KYULS&OLXXXHJW5KtSOLXVt  YlWfiqTHV{H~V{MULWrWfiqTKjtOLV5KLeWfiqKNM{qTKtULSfiKN
[ qU7XyTV;YZUL6
S sKNHM|
WfiqKjXUoifKNV5W{Untt\SfiSfiKNMTKQSfiULsO
sHX~HJWhOL[gU7M|OLXX<XHW5KtS4OLXVaULY] IzKNU7MTy<eH
Y H~V{OLVfiVfi\T[gKNyU7MTV5WfiOLMkWte
WfiqKNMWfiqKPVfiHJtKPULYtXOL\V5KNVteirqTHqH~VrULYULS4yKt

S   :e<HVRQTSfiULQULSfiWfiHJU7MTOLXW5UWfiqK!Mk\T[sKtSRULYIAO
S4H~O
sXJKNVte
OLMTycqTKNMTKLeHV;Vfi\TQTQU7V5KNyW5U4qTOLMT|LKjirHJWfiq

H 

> 3'

@ E@

vHo

{qTH~V;V5KNWfiHJU7McyKNV4S4HJsKNV;V5U7[!KS4KMKN[!KNMkWfiV;W5U_adH[!QTSfiUIzH~M|!HJWfiVaQKtSfiYULS[gOLMTKL
 ^$$4[Z#'X'#
 f   #w 

{qKYZ\MTWfiHJU7M^_;d&eaXHJmLKcWfiqTKdONInHV2\WfiMTOL[ QTSfiUnKNyT\SfiKLea|7HJILKNVMUSfiKNU7[g[!KNMyTO
WfiHJU7M^qUoi W5U
4qTUkU7V5KOpIAO
S4H~O
sXJKYULScOVfiQXHJWt9
 prUiKtILKtSNeOp|LUkUny4qTU7HKULY(WfiqTHVIAO
SHO
sXJK[gOohSfiKNy\TKWfiqK
S4\TMMTHM|}WfiH[!KPULYWfiqTK!YZ\TMWfiHJU7M<P
h  |LUzUzyqU7HK ifKg[!KNOLMU7MTK!WfiqTO
WtOL\TV5KNVWfiqTK!YULS4[(\TXOLV w (
OLMTy w  W5UgsKOLV{Vfi[OLXX<OLV{QU7VfiVfiHsXJKL
{qTK{VfiHJtKaULYWfiqTKNV5K{YZULS4[\XOLV:HV:yKtW5KtS4[HMKNy(skh(sULWfiq*OLMTy  V[gH~MTH[gHJNH~M|{WfiqK{Mz\T[sKtS:ULY
I
O
S4HO
sXJKNVHM w ( e w tOL\TV5KNVlOLM(\TwM fi\TV5WfiH KNyU7[!Q\WfiO
WfiHU7MjUILKtS4qKNOLy<e7ifKaU7MTKNMW5SO
W5KNyPU7MjSfiKNy\TtHM|
WfiqKaMk\[jsKtSULYtXOL\TV5KNV ( e
cHM w ( e w 
e
KNHJWfiqKtSskhj[HMTH[gHNHM|a ( : c v szhj[!KNOLMTVULYqUkU7V4HM|
OI
O
S4HO
sXJKrO
QTQKNO
S4HMT|jHMO[gOAH[gOLXMz\T[sKtSULYtXOL\TVfiKNVULY] x ezULSszhg[gHMTH~[gHJNHM|&K
 k v  (N c x 
{qKXO
W5W5KtSRtOLMsKOL4qTHJKtILKNyszh[gOAnH~[gHJNHM|PUILKt+
S WfiqKk\TOLMkWfiHJWh
 F v  L v  x   ehv  x5x eiRqKtSfiK
 L v  x&v  ehv  x5x yKNMULW5KNVaWfiqTKMz\T[sKtSfULYtXOL\TV5KNVfULY:]HM}irqTHq cUztt\TS4Va\TMTMKt|7O
W5KNy v MKt|7O
W5KNye
SfiKNV5QKNWfiHJILKNXh x rqKNV5KWiUO
QTQTS4U7OL4qKNVP[gOohsKU7[jsHMKNy<  MTyKtKNy<elKnQKtS4H[!KNMkWfiVSfiKtQULSfiW5KNyHM
IzKNWfiHJU7M}VfiqUoifKNysKNV5WrQKtSfiYZULS4[gOLMTK(HJYlWfiqKPV5QXHJWrIAO
S4H~O
sXJKjqTOLVRsKtKNMqU7V5KNMyT\KW5U}
  v  ( :
c x es\WRHJYWfiqKtSfiKPqTOoILKsKtKNM[gULSfiKjWfiqTOLMU7MK(Vfi\T4qI
O
S4HO
sXJKLeWfiqKNMO}Y\SfiWfiqKtSrqU7HKPOL[!U7M|WfiqK
U7[!QKtWfiHM|!I
O
S4HO
sXJKNV;qTOLV;sKtKNMc[gOLyTKyT\KW5Ug
 F<K
 k v  (t c x 

uZ

fi

RRT

 V;qTOLVasKtKNMVfi\|L|LKNV5W5KNycskhOLMOLMU7Mhn[!U7\TVaS4KtIzHJKtifKtSNeszh}\TV4HM|(QTSfiULQKtS;yTO
WfiO!V5W5S4\TWfi\TSfiKNVtenWfiqK
U7[!Q\TWfiO
WfiHJU7MULY  L v  x OLMTy ehv  x YZULS{OLXXIAO
S4H~O
sXJKNVDctOLMsKyU7MKK}tHJKNMkWfiXJhLetOL\TVfiHMT|U7MTXh}O
Vfi[gOLX~X<U7[!Q\WfiO
WfiHJU7McUoILKtS4qKNOLy

 
  =''=w

'#ff

#$

{qKPY\TMTWfiHJU7M_adVfiW5ULQVirqKNM]U7MkWfiOLHMTVjOLMKN[!QTWhtXOL\TVfiK(ULSiRqKNM]HV&KN[!QTWhL^qTO
WHY
]U7MVfiHV5WfiV;ULYU7MTXJhU7MKtXOL\V5KjU7MkWfiOLHMTHM
| \XHJW5KtS4OLX~V {qKVfiQXHJW5WfiHMT|S4\XJKirHXXsKO
QTQXHKNy}W5U](e
SfiKNO
WfiHMT| w ( OLMTy w Vfi\T4qcWfiqTO
W;U7MKULYWfiqTKN[[gONhsKKN[!QTWhLes\WaWfiqKULWfiqKtSrV5WfiH~XXU7MVfiHV5WfiVaULYU7MK
tXOL\TVfiKHMILU7XIzHMT_
| fi\TV5W;U7MTKIAO
S4H~O
sXJKXJKNVfiV;WfiqOLM]r IzUeTV5QX~HJW5WfiHM|(ULYWfiqTKjVfiHM|7XKtX~OL\TV5KULY]irHX~XsK
SfiKtQKNO
W5KN
y ^WfiH~[!KNVt
 V4H[gHXO
S;QSfiUzKNV4VrULYH~MK}tHJKNMkWRV5QXHJW5WfiHM|!WfiO
mLKNVQXOLKOLXVfiUU7MYULS[\TX~OLVrU7MTVfiH~V5WfiHM|gULYSfiKNXOA
WfiHJILKNXJhYZKti*tXOL\V5KNVt  WjWfi\TS4MTVU7\WWfiqTO
WjWfiqK}OLXJ|LULS4HJWfiqT[QTSfiKNV5KNMkW5KNyszhULNHMTVfimzHH v NL  x HVj[!ULSfiK
K}tHJKNMkWYZULSqTOLMTyXHM|aVfi[gOLXX
V5KtWfiVULYtXOL\TV5KNVt  nQKtS4H[!KNMkWfiVU7MS4OLMTyTU7[gXJhrqU7V5KNMYZULS4[(\TXOLVV4qUoifKNy
WfiqTO
WaYZULSYZULS4[(\TXOLVfirHJWfiq}XJKNVfiVfWfiqTOLMtX~OL\TV5KNVfWfiqKOLXJ|LULS4HJWfiqT[*ULYULNHMTV5mnHH v NL  x QKtSfiYZULS4[gVsKtW5W5KtS
WfiqTOLMYZ\TMWfiHJU7M}_adHMgHJWfiV:ULSHJ|7HMTOLXYZULS4[l{qKtS4KtYULSfiKLekirqKNMWfiqKrMz\T[jsKtSULY<tXOL\V5KNVULY<OYZULS4[(\TXO
sKNHM|PQTSfiUnKNVfiV5KNyHVaSfiKNyT\TKNy\TMTyKtSrze_;d&S4\TMTVaWfiqTKOLXJ|LULS4HJWfiqT[ULYULNHMTV5mnHH v NL  x 

 dn

l>
	fiff $E

@



 JX |LULS4HJWfiqT[_;d&QTSfiKNV5KNMkW5KNyHMWfiqTKQTSfiKtInHJU7\TV<V5KNWfiHU7MTVqTOLV<sKtKNMQTS4UL|LS4OL[g[!KNyH~M !e
OLMTyS4\M}U7Mf_&enirHJWfiqWfiqKQ\SfiQU7V5K&ULYyKtW5KtS[gHMTHMT|OLMK}tHKNMW;iaONhULYqUzU7VfiHM|gOPI
O
S4HO
sXKRYZULS
WfiqKPV5QXHW5WfiHM|gS4\XJKLeTMyTHM|OLMO
QTQTS4ULQTS4HO
W5K(Mk\T[sKtSRULYtXOL\TV5KNVHMOYZULS4[(\TXO}YULSV5irHJWfiqTHM|}WfiqK
Y\TMTWfiHJU7M_adW5UWfiqK(OLX|LULS4HJWfiqT[ ULYULNHMTV5mnHH v NL  x eOLMTyOLVfiV5KNVfiVfiH~M|}WfiqTK(OLWfi\TOLXlS\TMTMTHMT|!WfiH[!K
ULY_ad
 MjWfiqTKfKnQKtS4H[!KNMkWfiVte_adqTOLVsKtKNM(O
QQXHJKNyjW5URS4OLMyU7[gXJhQTS4UzyT\KNyjV5KtWfiVlULYtX~OL\TV5KNVirHJWfiqWfiqK
YZU7XXJUoiRHM|!QO
S4OL[gKtW5KtS4Vtt]
 5^ 5s
Lne:t]
 5^
 5
OLMy  (     o          k7eirqKtSfiK  ( e  
yKNMULW5KWfiqKQTS4ULsO
sHXHWh!ULYO(I
O
S4HO
sXKRW5UPUntt\S{HMOPtXOL\TV5K\TMTMKt|7O
W5KNyULS{MTKt|7O
W5KNy<eTSfiKNV5QKNWfiHJILKNXh
v  ( OLMTy   O
S4KMULWgMKNKNVfiV4O
S4HXJhWfiqKcVfiOL[!K x bTULSgKNOL4q^U7[jsHMTO
WfiHJU7MpULY&WfiqKcQO
SOL[!KtW5KtS4VtetL
S4OLMTyTU7[ HMTV5WfiOLMTKNVULY;]qONILKgsKtKNMQTSfiUnKNVfiV5KNyPKtSfiYZULS4[gOLMKgULY;_;d& qTOLVsKtKNM[!KNOLVfi\TSfiKNyskh
HJWfiV;S\TMTMTHMT|jWfiH[!KOLMyskhWfiqKMz\T[sKtS;ULYS4KNt\S4VfiHJILKtOLXX~V;W5UgWfiqKj[OLHMYZ\MTWfiHJU7M<
K(qTONILKULsV5KtSfiILKNycWfiqO
W{YULSrKNOL4qcQOLHJS;ULYlQTSfiULsO
sH~XHJWfiHJKNV  (t  AeTWfiqKtSfiKH~V{O!WfiqSfiKNV4qU7XyMk\[jsKtS
ULY{tXOL\TVfiKNV 
 elVfi\T4qWfiqTO
WjYZULSj ` 
 WfiqKqTO
S4ytOLV5KNVPXHKgO
SfiU7\TMTyOULSfiSfiKNV5QU7MTyHM|cMz\T[jsKtSULY
I
O
S4HO
sXJKNVNbULS(HMTV5WfiOLMTKLeWfiqK!qTO
S4ytOLV5KNVjYULS  ( ff   ff   gOLMTy   ff 
cO
SfiKgXUztO
W5KNyO
S4U7\TMTy
 ff 
nblHJ|7\S4KNV{rOLMT[
y QTSfiKNV5KNMkWWfiqKRONILKtS4O
|LKMz\T[jsKtSULYSfiKNt\TS4VfiHJILK{tOLXX~V:QKtSfiYULS[!KNy!szh!_adHM
WfiqKqTO
S4y}tOLV5KNVtULSfiKyTO
WfiOO
S4KR|7HJILKNMHMO
sXJKNVR#jULY  QTQKNMTyTH P&nbTU7XXJUoiRHM|jO(Vfi\|L|LKNV5WfiHU7M}ULY
U7MKaULYWfiqTKSfiKtInHJKtifKtS4VteLifK;4qKN4mLKNygWfiqKaV5WfiOLMTyTO
Sy(yTKtIzHO
WfiHU7M(H~MOLXXztOLV5KNV v VfiKtKaO
sXJK{RHM  QQKNMyTH 
 x   XXWfiqKjKnQKtS4H[!KNMkWfiV{S4OLMU7MOQKNMWfiH\[sOLV5KNyf_ v LL
 pR x R{qK(OLWfi\TOLXS4\TMTMTH~M|PWfiH[!K
ULY_adS4OLMT|LKNyYS4U7[XJKNVfiV;WfiqOLMU7MKV5KNU7MTyW5U}!qU7\TS4Vt
b U7X~XJUoirH~M|WfiqKgyTHV4UoILKtSfihULYfqO
S4ytOLV5KNVYZULSI   v HJWfiqKNXX:KtWjOLXFJeNL x eifKgS4OLM_;d&U7M
OVfiKtS4HJKNVRULY:S4OLMTyU7[V5KtWfiV&ULYHXHJW5KtS4OLXtXOL\TV5KNVRirHJWfiqWfiqTKS4O
WfiHUULY:  YZSfiU7[n gW5Uz nRbULSKNOLq
U7[sHMTO
WfiHJU7MULY OLMTy:*e 
LPHMTV5WfiOLMTKNVfifKtSfiKU7MTVfiHyTKtSfiKNy<:blHJ|7\SfiK)|7HJILKNVfWfiqK[!KNyTHOLMMk\[jsKtS
ULYS4KNt\S4VfiHJILKPtOLXXVRQKtSfiYZULS4[!KNyskh_adYULSOVfiOL[!QXJKULY ff 
  7  
nPULSfiKgyO
WfiOH~MO
sXJKg

uZXu

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff
#%
#$
##
#"
'&
'%
1. 8 9 . / '$
5 ) * + ,. / 0 2 113 '#
'"
&

: ; < = > ?= @ AB C D E F G E H G ; IF
J ; < = > ? = @ A B C D E F G E H G ; IH
H ; < = > ?= @ A B C D E F G E H G ; IJ

%
$
#
"
"

#"

$" %"
&" '"" '# " '$ " '%"
( ) * + , - . / 0 12 ) 3 , 3 45 67 , /. - * ) 12

'&"

#""

blHJ|7\SfiKg
  ILKtS4O
|LKPMk\[jsKtS;ULYSfiKNt\S4VfiHILKtOLXXV;YZULSryTHKtSfiKNMkW;IAOLX~\KNVaULY

   

LK
PO
PN
PM
PL
ZW a b W X
^ R S T U V PK
W X Y [ ZZ\
O
N

c d e f g h f i j k l m n o p d q o n r p d qr
s d e f g hf i jk l m n o p d q o n r p d qs
r d e f g h f i j k l m n o p d qr n r p d qs

M
L
K
K

LK

M K N K OK PK K PL K PM K PN K
Q R S T U V W X Y Z[ R \U \ ]^ _` U XW V S R Z[

POK

LKK

blHJ|7\TSfiKlz  ILKtS4O
|LKMz\T[sKtS;ULYlSfiKNt\TS4VfiHJILKtOLXX~VaYULSryHKtS4KNMW;I
OLX\KNV;ULY

   

v U7MWfiHMz\KNy x

ULY  QTQKNMTyH }& v KNyHOLMcMz\T[jsKtS{HV;V4qUoirMW5UKNMTO
sXJKU7[!QO
S4HV5U7MirHWfiqWfiqKSfiKNVfi\TXWfiVaQTSfiKNV5KNMkW5KNy
zs hHJWfi4qTKNXX<KtWrOLXJeNL x 

uZZv

fi

RRT

~    
       
u v }  ~~
uu
ut

            
            
            

yx
yw
yv
yu
yt
x
w
v
u
t
t

y

u

z
v
{
w
} ~         ~    

|

x

blHJ|7\SfiK
zKNyTHOLMMz\T[sKtS;ULYS4KNt\S4VfiHJILKtOLX~XVaYULSXHJW5KtS4OLX<YZULS4[(\TXOLVt
 MOLX~XKnQKtSH[!KNMkWfiV{irHJWfiqU7\TMkWfiHM|}[gUzyKNX~V{ifK(qTOoILKPULsV5KtSfiILKNyOQqKNMU7[!KNMU7MO
mzH~McW5UWfiqTO
W
4 qO
S4OLW5KtS4HV5WfiH~ULY:4qKN4mzH~M|VfiO
WfiHV5O
sHXHWhLeTMTOL[!KNXhLeTYULS&O!|7HJILKNMXJKNM|LWfiqULY:tXOL\TVfiKNV{neTWfiqKS\TMTMTHMT|
WfiH[!K(ULYOLXJ|LULSHJWfiqT[ _adSfiKNOL4qKNVHWfiVR[gOAH[(\T[ O
W&OKtSfiWfiOLHMI
OLX\K(ULYWfiqKPtXOL\TV5KNV2FW5U
FI
O
S4HO
sXJKNV
S4O
WfiHJU:bULS: ff  v blHJ|7\S46
K  x WfiqH
V 5qTO
S4y RS4O
WfiHJUHVa
 zeiRqTHXJKfHJWqOLVlsKtKNM(SfiKtQULSfiW5KNyPHMP[gOLMkhjifULSfimnV
Kv L |JeHWfi4qKNXXTKtWOLXJeNL  x WfiqTO
WfqTO
S4ygtOLVfiKNVUL4
Y  I  XHJK{O
SfiU7\TMy!   ff   z{qHV:VfiqTHJYZW:ULYWfiqK
[gOAH[(\T[ S\TMTMTHMT|&WfiH~[!KRW5U(WfiqKXJKtYZW v YZSfiU7[    ff   W5U   ff    x tOLMsKrKnQXOLHMTKNygszhgWfiqK
YOLWWfiqTO
WirqKNMOcQTSfiUL|LSOL[ YZUL
S I   yTHV4UoILKtS4V(OV4O
WfiHV5YZhzHMT|cOLVfiVfiHJ|7MT[gKNMWte:HJWjVfiW5ULQVjQSfiUzKNV4VfiHM|e
irqTH~XJK!U7\TMWfiH~M|[!UnyKNXVqTOLVjW5U|LUcU7MUoILKtSPOLXXVfiO
WfiH~V5YhnHM|cOLV4VfiHJ|7MT[!KNMkWfiVt
 IzUeWfiqK}qTHJ|7qKtSjH~VWfiqK
QTSfiULsO
sHXHJWhWfiqTO
WOgYZULS4[(\TXOgH~VrVfiO
WfiHV5O
sXJKLeOLMycWfiqK([!ULSfiK[gUzyKNX~V{HJWRH~VrXHJmLKNXh}W5UqTONILK v OLMTyWfiqTHV
HV;iRqTO
W{qTO
QTQKNMTV;HJYWfiqKS4O
WfiHUg  yKNSfiKNOLV5KNV x eWfiqKjXU7M|LKtSr[!UnyKNX<U7\TMkWfiHM|gWfiO
mLKNV&U7[!QO
S4KNyW5U
4qTKNfimnHM|VfiO
WfiH~V2O
sHX~HJWhL
l>

}B @ 'DCE @ 83or9

KPqTONILKQTSfiKNV5KNMkW5KNyOLMOLXJ|LULS4HJWfiq[

v _ad x YULS&U7\TMWfiH~M|}[!UnyKNXV{ULYlOQTSfiULQU7VfiHJWfiHU7MTOLXYULS[\TX~O](
{qKQSfiKtIzHU7\TV!V5KNWfiHJU7MTVU7MTVfiHyKtS4KNy_a`RbYZULS4[(\TXOLVtefqUoifKtILKtSNe{HJWgHVPKNOLVfihW5UU7MTV5W5S4\TW}OyT\TOLX
OLXJ|LULS4HWfiqT[YULS&d`RbpYZULS4[(\TXOLVt
_fU7[gQO
S4HM|ROLXJ|LULS4HJWfiqT[_adirHJWfiqWfiqO
WULY  ifOL[gO v NLL x OLMTy(ULNHMTVfimzHH v NL  x e7iKaMULW5KWfiqTO
W
sULWfiqqTONILKjOPU7[g[gU7McKNMW5SOLXYKNO
Wfi\S4KLWfiqK[!ULSfiKI
O
S4HO
sXKNVqTOoILKsULWfiqMKt|7O
W5KNycOLMTy\TMMKt|7O
W5KNy
Untt\SfiSfiKNMTKNVHMWfiqTKtXOL\TV5KNVULYTO{|7HJILKNMjYULS[\TX~OneWfiqKsKtW5W5KtSHVWfiqKQKtSfiYZULS4[gOLMTK:ULYWfiqTKOLXJ|LULS4HWfiqT[gVt
{qTH~VrYZKNO
Wfi\SfiKgHVOLXVfiUcU7[g[!U7MW5UWfiqKgOLXJ|LULSHJWfiqT[gV&QTSfiKNVfiKNMW5KNyszhd\sU7HV v NLn x OLMysz
h fiqTOLM|

uZ

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff
v NLL x   MU7MkW5S4OLV5WPW5U4qKN4mzHMT|VfiO
WfiH~V2O
sHX~HJWhLeQ\SfiKXHW5KtS4OLXVVfiXUoiyUoirMU7\TMkWfiHM|[gUzyKNX~Vskh
WfiqKNV5KOLXJ|LULS4HJWfiqT[Vt
{qTKgKzQKtS4H~[!KNMWfiVj[gOLyKgirHWfiqOLXJ|LULS4HJWfiqT[ _ad qTOoILK}VfiqTUoirMWfiqTO
WjHJWQKtSfiYZULS4[gVsKtW5W5KtSWfiqTOLM
WfiqTO
WULY<ULNHMTV5mnHH v NL  x H
 pRUoifKtILKtSfWfiqTKr[gOLHM!OLyI
OLMkWfiO
|LKrULY_adHVHMPWfiqKrOL[!U7\MWULYV5W5ULS4O
|LK&HJW
SfiKNz\THJSfiKNVN  M!WfiqK{KnQKtS4H[!KNMkWfiVlWfiqTO
WfqTONILKRsKtKNMgQKtS4YULS4[gKNyPskhPULNHMV5mzH~H v NL  x YZULS 5tLOLMTy
5n
neWfiqKtSfiKifKtSfiKjtOLVfiKNVrirHWfiqWfiqU7\TVfiOLMyTVaULY:tXOL\TV5KNVRV5W5ULSfiKNyy\S4HM|(WfiqKS\TMULYlWfiqKjOLXJ|LULSHJWfiqT[
InHMKgOLXJ|LULS4HJWfiqT[ _adQKtSfiYZULS4[gVOcyTKtQTWfiqnS4VfiWV5KNO
S44qULYaWfiqKV5QX~HJWW5SfiKtKLeOLMyskhKNOLqV5QXHJWO
W
XJKNOLV5WrU7MKIAO
SHO
sXJKHV{yTKNXJKtW5KNy<eWfiqKj[OAnH[OLX<Mk\T[sKtS;ULY:V5W5ULSfiKNyctXOL\V5KNV{HV;sU7\TMyKNyskh:
d\S4H~M|jWfiqKKnQKtS4H[!KNMkWfiVfiK4qTKNfimLKNyOLX~V5UWfiqTK[OAnH[OLXMz\T[sKt
S  ULYV5W5ULSfiKNytXOL\TVfiKNVt:{qK
SfiKNVfi\XJWfiVVfiqUiKNyjWfiqTO

W yUkKNVOLX[!U7V5WMTULWyKtQKNMTyU7MgeAVfi\4qWfiqTO

W  5^N
 2eAirqKtSfi
K G5  {H~VMULW
yKtQKNMTyTH~M|rU7M  ( OLMy   e7irqTHXKrryKtQKNMTyVU7M  ( OLMy   lO
sXJK;yHV5QXOohzV{OLVOY\TMTWfiHJU7MPULY  (
OLMTy  AblHJ|7\S4K{HM  QTQKNMTyTHJ&VfiqTUoirVONILKtS4O
|LKaI
OLX\KNV<ULY  YZULS ff 
   ( ff   ff           z
{qK[OAnH[(\T[UL
Y  HMOLXXU7\S{KnQKtS4H[!KNMkWfiV;iaOLVn v YZULSr ff 
   ff 
L x 



(

n
n
n
n 
n 
n 


n
n 
n 
n 
n 
n 



  A
n 
n 7
n
n 

n 

O
sXJKg
;jOLV{OgYZ\TMWfiHJU7MULY


(

OLMTy




 qTK}OLMTOLXJhnVfiHVjULY{WfiqKS4\TMTMHM|WfiH[!K}ULY&_adYU7X~XJUoirVjWfiqK[!KtWfiqUnyyKtILKNXULQKNyszhG&U7XysKtSfi|
{
v N7
 x OLMTyszhGU7XysKtSfi|KtWOLX v NL x grqTHV&[!KtWfiqUnyiaOLV\TVfiKNyOLX~V5Uskh  iaOL[gO v NLL x !{qK
ifKNXXmzMTUoirMcSHJWfiHtHVfi[VszhbS4OLMTU}OLMTyclOL\TXX v NL  x eOLMTyszhHJWfiqKNXXKtWrOLX v NL  x QU7HMkWfiV;U7\W
WfiqTO
W&WfiqKPHMTV5WfiOLMTKNV&|LKNMKtSO
W5KNyskhWfiqTH~VR[!KtWfiqTUzyO
SfiKP[!U7V5WfiXJhcV4O
WfiHV2O
sXKLeOLMTyWfiqTO
WHV&HMTyKtKNyWfiqK
SfiKNOLV5U7MYULSWfiqTK!|LUkUnyQKtSfiYULS[gOLMTKPULYfV4O
WfiHV2O
sH~XHJWh4qKN4mzHMT|cOLXJ|LULS4HJWfiqT[VtWfiqKgOLXJ|LULS4HJWfiq[gVRMTy
S4O
QH~yTXJhcU7MKg[gUzyKNXlULYfWfiqK!YZULS4[(\TXOn!{qTHVQU7HMkWyUzKNVMULWO
QTQXhirqKNMifKgV5KtKtmMULWU7MTX
h fi\TV5W
U7MKj[gUzyKNXs\W{OLXXWfiqK[!UnyKNXVN
blHMTOLX~XJhLeHJWPVfiqU7\TXysKMULW5KNypWfiqTO
WPWfiqKcOLXJ|LULS4HWfiqT[gVYULSgU7\TMkWfiHM|[!UnyKNXVPyKtILKNXULQKNypV5UYO
S
O
SfiKyKNVfiHJ|7MTKNyYZUL
S 5 n

r 
PYULS4[(\TXOLVN  VHJWqTOLVsKtKNM^[!KNMkWfiHJU7MKNy^HMWfiqKHMkW5SfiUnyT\TWfiHJU7M<e
U7MKO
QTQXHtO
WfiHU7MULYU7\TMWfiH~M|[!UnyKNXVHVgHMS4KNOLV5U7MTHM|irHJWfiqH~MTU7[!QXJKtW5KcH~MYULS[gO
WfiHJU7MHMXJUL|7H
V5hnV5W5KN[gV{\Vfi\TOLXXJhKzQTS4KNVfiV5KNycH[
M r54
 Lg 
JtnzLrqKtSfiKtYZULSfiKLeTyKtILKNXJULQH~M|gU7\TMkWfiHM|gOLXJ|LULS4HWfiqT[gV
YZULS{QTSfiKNyTH~tO
W5KtOLXt\TX\TVaYZULS4[(\TXOLV{H~V;OgMKnW{4qTOLXXKNM|LKULYlO!|LSfiKNO
WRH~[!QULSfiWfiOLMTKL




@ BCqn @



KO
SfiKr|LS4O
W5KtY\TXW5UWfiqTKROLMU7Mkhz[gU7\TVS4KtYKtSfiKtKNVYZULSWfiqKNHS[!U7V5WfO
QTWOLMyHMTVfiQHJS4HMT|&U7[g[gKNMWfiVt{qTHV
SfiKNV5KNO
S4qqTOLV{sKtKNMcQO
SfiWfiXJhVfi\QTQULSfiW5KNyszhWfiqK  V5S4O
KNXEnI tHJKNMTKjbTU7\TMTyTO
WfiHJU7MOLyT[gHMHV5W5S4O
W5KNyszhWfiqK
 V5S4O
KNX  tOLyKN[hULYHnI tHKNMTKNV{OLMTyK&
p \T[gOLMHJWfiHJKNVt
uZ

fi

4
H  ]  ff ( < v    x ff  v    x 
^w bULS  ff ( eWfiqKSfiKNt\TSfiSfiKNMTKHMTKNk\TOLX~HJWh}WfiO
mLKNV{WfiqKYZULS4[
    :
 v  x B  v      xR:
B ( Y  B Y  v  ^  
 v    x 5   q BY#
N
( v Y xv  x v  x 







@ CE ff





RRT

>

7BlB 



  `

x

G&U7XyTsKtS4| v N7
 x VfiqUiKNyeTWfiqTO
W{YZULS{WfiqKYZU7XXJUirHM|PSfiKNt\TSfiSfiKNMTKLeJ v 
  :

J v    x ff   q BYN#( v BY xv ( x Y v  x B  Y J v   ^     x
 




ff A( ff

 x ff  v 

vx

x

  `

ff  A( ff

v x


{qKyHKtS4KNMTKsKtWifKtKNM v  x OLMTy v  x ejWfiqTKSfiKNt\SfiS4KNMTKYULSJ v    x OLMTyWfiqKSfiKNt\TSfiSfiKNMTKYZULS
 v    x eTHVWfiqKKnW5S4OPW5KtS4[ v  x B  v      x H~MWfiqKXO
W5W5KtSoU!U7[!QO
SfiK& v    x OLMTyJ v    x
ifKS4V5W;MKtKNyWfiqKYZU7XXJUoiRHM|PSfiKNVfi\TXWt
 
m
 `
 L
 
ZT`;EJ v    x 5 v  x B  ( #H
  a ]
^w G&U7XysKtSfi| v N7
 x V4qUoifKNyWfiqO
)W J v    x 5s#  :+InHMTK v  x B  ( YULSR `zeWfiqTHV
QTSfiUILKNV&WfiqKXJKN[[gOgYZULSROLXX `}OLMTyOLX~Xk
 `^n&d&HSfiKNWRU7[!Q\WfiO
WfiHJU7MULY J v    x ey\KjW5U v  x e
YZULS{ ff         U7[!QXJKtW5KNVrWfiqKQTS4UkULYYULSrOLX~X<m
 `!OLMTycOLX~X
 `n
`RUoi v    x tOLMsKKNV5WfiH[O
W5KNyOLV;YZU7XXJUirVt
 
 L
 
Z' < v    x 5  J v    x 
    ]
^w hHMyT\TWfiHJU7MU7M
{qKOLV4V5KtSfiWfiHJU7McH~VaW5S4\KYZULS{3
 5

In\QQU7VfiKHWaH~V;W5S4\KYZULS{KtILKtSfih :eWfiqKNM
B B  Y  B Y

 v    x 5 # :v x B  v      4

x : P v Y xv  x v  x   v   ^     x


 tULS4yTHM|!W5U v  x e

YhN#(

5 # :   v  x B J v      x4:
B
   P v BY xv  x Y v  x B  Y J v   ^  
YN#(

 x

B B  Y  B Y



#






:
ff
P v Y xv  x v  x  J v   ^     x 
YN#(

B

V5Uen v    x 5nJ v    x:  v  x J v   
 x  #:bTULSrOLXX 0 neJ v      x 5J v   

OLMTyszhKN[g[gO
eTYULSROLXXlOLMTyOLX~X:Te v  x B J v    x 5n#:{qHVaU7[!QXJKtW5KNVrWfiqKQTSfiUzULY0
InH~MTK-J v    x ff  v    x OLMTy v    x 5  J v    x e
ifK|LKtWYZULS  ff ( eo v    x ff  v   
J

v  x

uZx

xe
x

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff
H   v    x ff  v    x qE hfi + ff 	  +( (  .  
@
 K{OLMTOLXhktKfWfiqKaSfiKNt\SfiS4KNMTKfH~MKNk\OLXHJWhYZULS:OLMh
e7\TVfiH~M|RU7MTV4HyKtS4O
WfiHJU7MVVfiH~[gHXO
SW5U&WfiqTU7V5K
^w  
ULYG&U7XysKtSfi|PKtWrOLXF v NL x 
{qKS4KNt\SfiSfiKNMTKH~MKNk\OLXHJWh}WfiO
mLKNVrWfiqTKYULS4[c
 v  x

 # :
 v   x B  v      xR:

5  q BYN#( v BY x  Y v  K x B  Y 


v 

^

  ` 

  x



v x

ff ] P ff



 W{HV;KNOLV5hW5UVfiqTUoieTszhHMTyT\TWfiHU7M}U7MTeTWfiqTO
W; v    x |LSfiUoirVrirHJWfiqT-prKNMTKLe
 v  x

58# :v    x B

B
 P v BY x  Y v   x B  Y 
YN#(

 v    x4:

^

v 



 x

v x

 V5U7X\WfiHJU7MULY v  x HVaXHMKNO
S;HMTeTV4HMTKWfiqTHVaSfiKNt\TSfiSfiKNMTKHVaXHMTKNO
SaH~M}WfiqTK `RUoiYZULSrOLMkhI
OLX\K
* XJKtW{\TVr4qUzU7V5KjOgU7MV5WfiOLMW}V4\T4qWfiqO
W{YULSROLXX<m5 *


irqKtS4K


ff 	 @  +( (  .

 v    x 58k   
{qKNMYZULSROLXXm5 * e v  x e v  x Hg
[ QXJh

v   v   x B x  v    x

B
5 # :  P v BY x  Y v   x B  Y  v   ^   x
YB N#(
5 #  :  P v BY x  Y v   x B  Y  v   ^ x  
Y#N ( B
^
ff #  : k      P v BY x  Y v   x B  Y v    x  
YN#(

 VRG&U7XysKtSfi|!KtWROLX v N L x V4qUoifKNy<e

OLMTyWfiqTKtSfiKtYULS4KLe

# ff

P v BY x  Y v   x B  Y
Y

v   v   x B x  v    x
 v  x eTOLMycV5Ue
 v  x

^ 
ff

v   x

5# : k  

5 k      v K   B x  : k
v
x

v   x

v

x

uZ

:

v  K x

 v  ( x 

 : k 

Bff+(  

  v

KO
S4K|LU7HM|MUiW5U!MyU7\WrU7MTyTHWfiHJU7MTV;\TMTyTKtSfiRqTH4q
    v   x  k    B ff+(  
v

 B :


v x

(4.

x

  v

(4.

5n  


x

v x


(

x

fi

WfiqTO
WrH~V

RRT

  x
 v 
v x
  xB (
  v K
blHJS4V5Wte<XJKtWyKNMULW5KPWfiqK!Vfi\sKnQTSfiKNVfiV4HJU7McULY v  x H~MV4k\TO
S4KsTSOLfimLKtWfiVt(bULSOLXX;
eHVXJKNVfiV&WfiqTOLMp
e
qKNMTKLe[\V5W;sK|LSfiKNO
W5KtSRWfiqOLMW5U}VfiO
WfiH~V5Yh v  Bff+(   (4. x 5K
 
G
 IzUe
 v

Bff+(  

(4.

 &

5 
x 

 0





v x

v   x B yTH[gH~MTHVfiqKNV:[gU7MULW5U7MTHtOLXXhLezOLMTy}W5KNMTyTVfW5UPPOLV^eqKNMTK
W5U[gO
mLK(QU7VfiHJWfiHJILKLenifKjMKtKNy
 0 XJUL|     K
v x
v   x
{qz\TVteqUzU7VfiHM|g v OLMTy}qKNMTKLez * x Vfi\n}tHJKNMkWfiXJhPXO
Sfi|LK v yKtQKNMTyTHM|U7MWfiqKrI
OLX\K;ULY<WfiqK v   ( x
KnQTSfiKNVfiVfiHU7M}HM v  x5x eTOLMTyyKtW5KtS4[gH~MTHM|WfiqKI
OLX\KNVULY !OLMTyVfiO
WfiHV5YZhnHM|U7MyTHJWfiHJU7MTV v  x e v  x e v  x e
KNV5WfiO
sX~HVfiqKNVf v    x ff  v K
 t x eirqTKtSfi

K  ff 	  +( ( ./ 


IzKNU7MTyekYZULS;
 


e

@

u

fi

y w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff






@ CE ff>

B

  @ 

	fiff $E



`&\T[sKtS;ULY:tXOL\V5KNV
t




7




A




tL
X 

7
N

N


L

7!I
O
S4HO
sXJKNV
N
A
N
L
 LA
NLLL
LA
tN

NLnNL
LL 



LL
t7 L 
NAL7

7LLA
LLTo


 7L




gI
O
S4HO
sXJKNV
N
Nn
X 
 



N LA
 LL
t7 7
AL A
 LnNL


LL
AL
L
 A7
LN A L
ALL77L
LnLN



O
sXJKg
  ILKtS4O
|LKPMk\[jsKtS;ULYSfiKNt\S4VfiHILKtOLXXV;YZULS
`&\T[sKtS;ULY:tXOL\V5KNV
t




7




A




tL
X 

7
N

N


L


!I
O
S4HO
sXJKNV 
gI
O
S4HO
sXJKNV


T
A 
Lt
L
A 
NL


A
A
7
L 
X
 
XA 7
NL
on 

 7L
A 
n XL 
L Ak
L A 
An

 7
Ln 

7n
XL Ln
LnX
NLLL

O
sXJKlz  ILKtS4O
|LKPMk\[jsKtS;ULYSfiKNt\S4VfiHILKtOLXXV;YZULS

u


!I
O
S4HO
sXJKNV
X
N
LL
LLL
LX 7A
LA7

Ak
N LA
nLNLL
 L7zX 
NL7zk
 LL7zX 
t7nX L n

 
 L 
7 LnX 


(ff  ff

 

7!I
O
S4HO
sXJKNV

L


N

LL
 A
 L
nN
X L
NAk
7
n
 L
AL

L
X nN 

(ff  ff

 

fi

RRT

`&\T[jsKtS;ULY:tXOL\TVfiKNV
t




7




A




tL
X 

7
N

N


L


!I
O
S4HO
sXKNV 
gIAO
S4H~O
sXJKNV

o 

N


 

L


L
L
L

o

nN
LL
LA
L


 A



t

XA
o

nN
LL
L 
L



LL

O
sXJKlz  ILKtS4O
|LKPMk\[jsKtS;ULYSfiKNt\S4VfiHILKtOLXXV;YZULS

`&\T[sKtS;ULY:tXOL\V5KNV
t




7




A




tL
X 

7
N

N


L


!I
O
S4HO
sXJKNV
L
L

A 
tL

no

TNL

 7
Lo7
NA 
LLLL
LkL 
L 

t7nXA 
LLL
NL nN

uX

(ff  ff

7gI
O
S4HO
sXJKNV
t


L



oA7
A L
 L

t7nN
o
nN
7
Ak
7
A
t7AL
NLLLL


L 
 L
 

O
sXJK  ILKtS4O
|LK(Mk\T[sKtS;ULYS4KNt\S4VfiHJILKtOLX~XV;YZULS



(ff

 


!I
O
S4HO
sXJKNV



nL
7
X L 
Ak 
 nL


t7LL
N7 A
7A7n
L LA
Lozo


N 


Ln
  
 e  

ff

 

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff

`&\T[sKtS;ULY:tXOL\V5KNV
t




7




A




tL
X 

7
N

N


L


!I
O
S4HO
sXJKNV

n 
T


L 
t

NL 
L

L

nX
LLn
7

nX7 
L7


77L


7gI
O
S4HO
sXJKNV

T
L
L
L7


LLo
oA7
A 
L 

77
t n
N
77
L 
nNL 

O
sXJKjz  ILKtS4O
|LK(Mk\T[sKtS;ULYS4KNt\S4VfiHJILKtOLX~XV;YZULS

`&\T[jsKtS;ULY:tXOL\TVfiKNV
t




7




A




tL
X 

7
N

N


L

(ff


!I
O
S4HO
sXJKNV

L
7

7
Ln
LL


X no
NnN
LLL
L7
 LA
t n
N 7z




  
 e  

ff

 

ff

 


!I
O
S4HO
sXKNV 
gIAO
S4H~O
sXJKNV


A 
n
L 
t
NA
A
7
L

7


LN 
N
7
nNA
LL7
L 

O
sXJKjz  ILKtS4O
|LK(Mk\T[sKtS;ULYS4KNt\S4VfiHJILKtOLX~XV;YZULS

u




XA
NL
LL
L 
Lk
L7
Ln
XL
N n
nNL
7 

(ff

  ze  

fi

SfiULsO
sHXHJWfiHJKNV
 ( ff   ff  

 O
S4HO
sXKNV
7



(ff  ff

 



7

(ff  ff
(ff

 






  
 e  

 

ff

7



(ff

  
 e  

 

ff



7

(ff

  ze  

ff

RRT

 






_aXOL\TV5KNV
X 


L
X 


L
X 


L
X 


L
X 


L
X 


L
X 


L
X 


L
X 


L
X 


L
X 


L
X 


L

 LI KtS4O
|LK
t7L
 7L


AL
LnLN


LAk
NLLL
7
n
X nN 
L 
LL
LL
 A
7
A
 L
 
7A7n


Ln
LLn
77L


77
nNL 
LN
L 
Ln
7 

IzWfiOLMyTO
S4yyKtInHO
WfiHJU7M
TXA 
L n tL 

L TN
7
L7A7L

7
L7
k

77

t7
L

nNA
X Lnoz
Lt7n

7L7
AL
AL
X A
 LA
N
n
X L
L 

O
sXKkGInOL[!QXKNVaULYV5WfiOLMyTO
S4ycyKtInHO
WfiHJU7MULY:Mz\T[sKtS;ULYSfiKNt\SVfiHJILKtOLXXV

uhu

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff

_aXOL\TV5KNV5FW5U
FIAO
S4H~O
sXJKNV;S4O
WfiHU
n 
n 
n 
n 

$

 




 

 

 




!I
O
S4HO
sXJKNV
L
7 
L 
L
X
 
Nn 
L
XL 
XL 
t7


L
LA
LL
L7
AT
X L
L
L
L


z 
z 

z 




z 





 
  
 
 

7IAO
S4H~O
sXJKNV
t7L
oLzN
LX nNL
L 

L

 LLL
 LL7

 LL 

TX LL 


 L
NAk
A
t7
7L

7A
A777
NL7

L7
nN
L
L
N

X L


!I
O
S4HO
sXJKNV

7 
L
L7L7
LN A7A
nX 7
LLL
AA 
 L
LAL LL

L
7AL7
LATNnX A
LAA777
Lo
 Ln
 7L
 L
7 7
LL

7nk
 L
 A7
nX L
L
L
LL
k


O
sXJKjzKNyTHOLMcMz\T[sKtS;ULYSfiKNt\TS4VfiHJILKtOLXX~V;YULSXHJW5KtS4OLX<tXOL\V5KNVteT

uXv

ff 


 7   


fi

RRT

  
  
       
       
       

  
  
  
  
     
       
  

  
  
  
  
  
  
 



 

 

 
 
 
 
 
                     

 

 

  

blHJ|7\SfiKg
  ILKtS4O
|LK(ULY[gOAH[gOLXMz\T[sKtSrULY:tXOL\TV5KNVRV5W5ULSfiKNyyT\S4H~M|PWfiqKjS4\MTMTHM|PULY_ad^YULS

IAO
S4H~O
sXJKNVt

u

fiy w zR{d|,'}RR8|,~$R]wl$'}R3  ~ff
3* $ @ 
dONInHVtezJe\WfiMOL[eVp v NL
 x 
Rj
 Sn  ete
 ;nNz

 U7[!Q\WfiH~M|QTSfiUnKNyT\SfiKaYZULSz\TOLMkWfiH tO
WfiHJU7M!WfiqTKtULSfihLn
#


d\sU7HVteT v NLn x n_fU7\MWfiHMT|;WfiqKMk\[jsKtSULYnV5U7X\WfiHU7MTVYULSHMTV5WfiOLMTKNVULYnV4O
WfiHV2O
sH~XHJWhL=nfi5N

:L_ nNtte v  x ezA
bS4OLMUeJe=lOL\TX~Xe v NL x }SfiULsO
sHXHV5WfiH~OLMTOLXJhnVfiHV&ULYfWfiqKgdONInHV2\TWfiMTOL[ QTSfiUnKNyT\S4KYZULS
VfiU7XJIzH~M|PWfiqKjVfiO
WfiHV5O
sHXHWhgQTS4ULsXJKN[Hj~tfitD4
LSntLte
eLz7k

G&U7XyTsKtS4|e   v N7
 x   ILKtS4O
|LK(tOLVfiKjU7[!QXJKHJWhULYWfiqKjV4O
WfiHV2O
sH~XHJWhQTSfiULsXJKN[c  M62o44
Zk

R jS nTS/\/zLnFL7fiPfi
To
  \V5WfiHM<eKnOLVt

G&U7XyTsKtS4|e  Je\S4yU7[eJefSfiUirM<e_ v NL x   ILKtS4O
|LKjWfiH~[!KOLMTOLXJhnVfiHVfULY:VfiH[!QXH KNy}d&OoIzH~V2
\WfiMTOL[ QSfiUzKNy\SfiKNVt  Xt#7
3D5N4Zkt4#e v  x e<n
z

G&SfiUILKLe  JepROLXQKtSM<eTJeU7XXJKtSNe
d( v NLA x   OLMTyU7[ifULS4XyTVOLMTy([gOAH[\[KNMkW5SfiULQzhLn
#

R N"L  Z z#r#t/5he7ezLz
 ifOL[gOneg v NLL x f
 _;`RbVfiO
WfiHV2O
sHXHJWhPW5KNV5W;skh}U7\TMWfiH~M|!OLMTyQU7XhzMU7[HOLXOoILKtS4O
|LKWfiH[!KL


 #
L :L_nZk7e  v  x eLL;Ln


 

H~MTHOLXel`jJeq`RH~VfiOLM<e` v NL
 x   QTQSfiUNH[gO
W5KHMTtX\VfiHJU7MnFKtX\TVfiHU7M<:
]ZLF#
e v  x e
A ;LLz
ULNH~MTV5mnHHe   v NLL x   TM V5ifKtS4HM|gO
W5U7[gH~jz\KtS4HJKNV{H~McHMTyKMTHJW5KyKNyT\WfiHJILKjyTO
WfiO
sOLVfiKNVt   h#

L
L    ZJktA(e  v  x e7Lz
ULNH~MTV5mnHHe   v NL x _fU7\TMkWfiHM|QTSfiULQU7VfiHWfiHJU7MTOLXz[!UzyTKNXVt  X tL
o62o#ZkNhe
7 ;z
ULNH~MTV5mnHHe   v NLL x   VWfiqKtSfiKOLMOLXJW5KtS4MTO
WfiHJILK&W5U(QO
S4VfiH[gU7MTHJU7\TVVfiKN[gOLMWfiH~tV7
L<R
ZL
 =n4fit/
 ftf
  Z z#eterLn;7
z



v xe

 A	

\TskhLenJe'  KNXH"! mLUoInH
# eT& v NLn x qMyKtW5KtS4[gHMHV5WfiH;O
QTQSfiUNH[gO
WfiHJU7MULYd`Rbf  M62o44
Zk

Rff

fi 

HJWfi4qKNX~Xerd(Je+IzKNX~[gOLM<e{&Je+ KtILKNV4k\KLe+p v NL x  &
p O
S4yOLMTy^KNOLV5h^yTHV5W5S4Hs\WfiHJU7MTVPULYI  
QSfiULsXJKN[gVN  
M 62N#44
z
(    7
 ULWfiqed( v NLL x nMpWfiqKcqO
S4yTMKNVfiV(ULY&O
QTQTSfiUonH[O
W5KSfiKNOLV5U7MTHMT|
7 ;
z

 tf
  Z z#e  7e


 OLXHOLMkWte v N7
 x {qTKU7[!QXJKnHWhULY&U7[!Q\WfiH~M|WfiqTKQKtS4[OLMKNMWt
tF#eLeNL;



=nfifit/L1:
h


fiqTOLMT|e_ v NLL x `&\T[sKtS}ULYP[!UnyKNXVOLMTyVfiO
WfiHV2O
sHXHJWhULYV5KtWfiVULY(tXOL\TV5KNVN = nfi5N

 L_ nNtte v  x e7L;LLz
:
u

fiJournal of Artificial Intelligence Research 10 (1999) 271-289

Submitted 11/98; published 5/99

Issues in Stacked Generalization
Kai Ming Ting

kmting@deakin.edu.au

Ian H. Witten

ihw@cs.waikato.ac.nz

School of Computing and Mathematics
Deakin University, Australia.
Department of Computer Science
University of Waikato, New Zealand.

Abstract

Stacked generalization is a general method of using a high-level model to combine lowerlevel models to achieve greater predictive accuracy. In this paper we address two crucial
issues which have been considered to be a `black art' in classification tasks ever since the
introduction of stacked generalization in 1992 by Wolpert: the type of generalizer that is
suitable to derive the higher-level model, and the kind of attributes that should be used as
its input. We find that best results are obtained when the higher-level model combines the
confidence (and not just the predictions) of the lower-level ones.
We demonstrate the effectiveness of stacked generalization for combining three different
types of learning algorithms for classification tasks. We also compare the performance of
stacked generalization with majority vote and published results of arcing and bagging.

1. Introduction
Stacked generalization is a way of combining multiple models that have been learned for a
classification task (Wolpert, 1992), which has also been used for regression (Breiman, 1996a)
and even unsupervised learning (Smyth & Wolpert, 1997). Typically, different learning
algorithms learn different models for the task at hand, and in the most common form of
stacking the first step is to collect the output of each model into a new set of data. For each
instance in the original training set, this data set represents every model's prediction of that
instance's class, along with its true classification. During this step, care is taken to ensure
that the models are formed from a batch of training data that does not include the instance
in question, in just the same way as ordinary cross-validation. The new data are treated
as the data for another learning problem, and in the second step a learning algorithm is
employed to solve this problem. In Wolpert's terminology, the original data and the models
constructed for them in the first step are referred to as level-0 data and level-0 models,
respectively, while the set of cross-validated data and the second-stage learning algorithm
are referred to as level-1 data and the level-1 generalizer.
In this paper, we show how to make stacked generalization work for classification tasks
by addressing two crucial issues which Wolpert (1992) originally described as `black art'
and have not been resolved since. The two issues are (i) the type of attributes that should
be used to form level-1 data, and (ii) the type of level-1 generalizer in order to get improved
accuracy using the stacked generalization method.
Breiman (1996a) demonstrated the success of stacked generalization in the setting of
ordinary regression. The level-0 models are regression trees of different sizes or linear
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiTing & Witten

regressions using different number of variables. But instead of selecting the single model
that works best as judged by (for example) cross-validation, Breiman used the different level0 regressors' output values for each member of the training set to form level-1 data. Then
he used least-squares linear regression, under the constraint that all regression coecients
be non-negative, as the level-1 generalizer. The non-negativity constraint turned out to be
crucial to guarantee that the predictive accuracy would be better than that achieved by
selecting the single best predictor.
Here we show how stacked generalization can be made to work reliably in classification
tasks. We do this by using the output class probabilities generated by level-0 models to
form level-1 data. Then for the level-1 generalizer we use a version of least squares linear
regression adapted for classification tasks. We find the use of class probabilities to be crucial
for the successful application of stacked generalization in classification tasks. However,
the non-negativity constraints found necessary by Breiman in regression are found to be
irrelevant to improved predictive accuracy in our classification situation.
In Section 2, we formally introduce the technique of stacked generalization and describe
pertinent details of each learning algorithm used in our experiments. Section 3 describes
the results of stacking three different types of learning algorithms. Section 4 compares
stacked generalization with arcing and bagging, two recent methods that employ sampling
techniques to modify the data distribution in order to produce multiple models from a single
learning algorithm. The following section describes related work, and the paper ends with
a summary of our conclusions.

2. Stacked Generalization

Given a data set L = f(y ; x ); n = 1; : : : ; N g, where y is the class value and x is a vector
representing the attribute values of the nth instance, randomly split the data into J almost
equal parts L1 ; : : : ; L . Define L and L(, ) = L , L to be the test and training sets for
the j th fold of a J -fold cross-validation. Given K learning algorithms, which we call level-0
generalizers, invoke the kth algorithm on the data in the training set L(, ) to induce a
model M(, ) , for k = 1; : : : ; K . These are called level-0 models.
For each instance x in L , the test set for the j th cross-validation fold, let z denote
the prediction of the model M(, ) on x . At the end of the entire cross-validation process,
the data set assembled from the outputs of the K models is
n

n

n

J

j

j

n

j

j

j

k

n

j

kn

j

n

k

L = f(y ; z1 ; : : : ; z ); n = 1; : : : ; N g:
CV

n

n

Kn

These are the level-1 data. Use some learning algorithm that we call the level-1 generalizer
~ for y as a function of (z1 ; : : : ; z ). This is the level-1
to derive from these data a model M
model. Figure 1 illustrates the cross-validation process. To complete the training process,
the final level-0 models M , k = 1; : : : ; K , are derived using all the data in L.
Now let us consider the classification process, which uses the models M , k = 1; : : : ; K ,
~ . Given a new instance, models M produce a vector (z1 ; : : : ; z ).
in conjunction with M
~ , whose output is the final classification result for
This vector is input to the level-1 model M
that instance. This completes the stacked generalization method as proposed by Wolpert
(1992), and also used by Breiman (1996a) and LeBlanc & Tibshirani (1993).
K

k

k

k

272

K

fiIssues in Stacked Generalization

~
M

L CV
Level-1
Level-0

(-j)

(-j)

M1

(-j)

Mk

MK

(-j)

L

Figure 1: This figure illustrates the j -fold cross-validation process in level-0; and the level-1
~.
data set L at the end of this process is used to produce level-1 model M
CV

~ , the
As well as the situation described above, which results in the level-1 model M
present paper also considers a further situation where the output from the level-0 models is
a set of class probabilities rather than a single class prediction. If model M(, ) is used to
classify an instance x in L , let P (x) denote the probability of the ith output class, and
the vector
P = (P 1 (x ); : : : ; P (x ); : : : ; P (x ))
gives the model's class probabilities for the nth instance, assuming that there are I classes.
As the level-1 data, assemble together the class probability vector from all K models, along
with the actual class:
L0 = f(y ; P1 ; : : : ; P ; : : : ; P ); n = 1; : : : ; N g:
~ 0 to contrast it with M
~.
Denote the level-1 model derived from this as M
The following two subsections describe the algorithms used as level-0 and level-1 generalizers in the experiments reported in Section 3.
j

k

j

ki

kn

CV

n

k

n

n

ki

kn

n

kI

n

Kn

2.1 Level-0 Generalizers

Three learning algorithms are used as the level-0 generalizers: C4.5, a decision tree learning
algorithm (Quinlan, 1993); NB, a re-implementation of a Naive Bayesian classifier (Cestnik,
1990); and IB1, a variant of a lazy learning algorithm (Aha, Kibler & Albert, 1991) which
employs the p-nearest-neighbor method using a modified value-difference metric for nominal
and binary attributes (Cost & Salzberg, 1993). For each of these learning algorithms we
now show the formula that we use
P for the estimated output class probabilities P (x) for an
instance x (where, in all cases, P (x) = 1).
C4.5: Consider the leaf of the decision tree at which the instance x falls. Let m be the
number of (training) instances with class i at this leaf, and suppose the majority class
i

i

i

i

273

fiTing & Witten

P
at the leaf is I^. Let E = 6= ^ m . Then, using a Laplace estimator,
i

I

i

P ^(x) = 1 , PEm+ +1 2 ;
I

i

i

P (x) = (1 , P ^(x))  mE ; for i 6= I^:
i

i

I

Note that only pruned trees and default settings of C4.5 are used in our experiments.
NB: Let P (ijx) be the posterior probability of class i, given instance x. Then
P (x) = PP P(ij(xij)x) :
i

i

Note that NB uses a Laplacian estimate for estimating the conditional probabilities
for each nominal attribute to compute P (ijx). For each continuous-valued attribute,
a normal distribution is assumed in which case the conditional probabilities can be
conveniently represented entirely in terms of the mean and variance of the observed
values for each class.
IB1: Suppose p nearest neighbors are used; denote them by f(y ; x ); s = 1; : : : ; pg for
instance x. (We use p = 3 in the experiments.) Then
s

s

P f (y )=d(x; x )
P (x) = P=1 1=d(x; x ) ;
p

s

s

i

s

p

=1

s

s

where f (y ) = 1 if i = y and 0 otherwise, and d is the Euclidean distance function.
s

s

In all three learning algorithms, the predicted class of the level-0 model, given an instance
x, is that I^ for which
P ^(x) > P (x) for all i 6= I^:
I

i

2.2 Level-1 Generalizers

We compare the effect of four different learning algorithms as the level-1 generalizer: C4.5,
IB1(using p = 21 nearest neighbors),1 NB, and a multi-response linear regression algorithm,
MLR. Only the last needs further explanation.
MLR is an adaptation of a least-squares linear regression algorithm that Breiman (1996a)
used in regression settings. Any classification problem with real-valued attributes can be
transformed into a multi-response regression problem. If the original classification problem
has I classes, it is converted into I separate regression problems, where the problem for
class ` has instances with responses equal to one when they have class ` and zero otherwise.
The input to MLR is level-1 data, and we need to consider the situation for the model
0
~
M , where the attributes are probabilities, separately from that for the model M~ , where
1. A large value is used following Wolpert's (1992) advice that \ it is reasonable that `relatively global,
smooth ' level-1 generalizers should perform well."
p

:::

:::

274

fiIssues in Stacked Generalization

they are classes. In the former case, where the attributes are already real-valued, the linear
regression for class ` is simply

X
LR (x) = ff
K

`

k`

P (x):
k`

k

In the latter case, the classes are unordered nominal attributes. We map them into binary
values in the obvious way, setting P (x) to 1 if the class of instance x is ` and zero otherwise;
and then use the above linear regression.
Choose the linear regression coecients fff g to minimize
k`

X X
j

(

yn ;xn

)2Lj

k`

(y ,
n

Xff

P (, )(x ))2 :
j

k`

k`

n

k

The coecients fff g are constrained to be non-negative, following Breiman's (1996a) discovery that this is necessary for the successful application of stacked generalization to regression problems. The non-negative-coecient least-squares algorithm described by Lawson
& Hanson (1995) is employed here to derive the linear regression for each class. We show
later that, in fact, the non-negative constraint is unnecessary in classification tasks.
With this in place, we can now describe the working of MLR. To classify a new instance
x, compute LR (x) for all I classes and assign the instance to that class ` which has the
greatest value:2
LR (x) > LR (x) for all `0 6= `:
In the next section we investigate the stacking of C4.5, NB and IB1.
k`

`

`

`0

3. Stacking C4.5, NB and IB1

3.1 When Does Stacked Generalization Work?

The experiments in this section show that
 for successful stacked generalization it is necessary to use output class prob~ 0 rather than M
~;
abilities rather than class predictions|that is, M
 only the MLR algorithm is suitable for the level-1 generalizer, among the four
algorithms used.
We use two artificial datasets and eight real-world datasets from the UCI Repository of
machine learning databases (Blake, Keogh & Merz, 1998). Details of these are given in
Table 1.
For the artificial datasets|Led24 and Waveform|each training dataset L of size 200
and 300, respectively, is generated using a different seed. The algorithms used for the
experiments are then tested on a separate dataset of 5000 instances. Results are expressed
as the average error rate of ten repetitions of this entire procedure.
For the real-world datasets, W -fold cross-validation is performed. In each fold of this
cross-validation, the training dataset is used as L, and the models derived are evaluated
2. The pattern recognition community calls this type of classifier a linear machine (Duda & Hart, 1973).

275

fiTing & Witten

Datasets # Samples # Classes # Attr & Type
Led24
200/5000
10
10N
Waveform 300/5000
3
40C
Horse
368
2
3B+12N+7C
Credit
690
2
4B+5N+6C
Vowel
990
11
10C
Euthyroid
3163
2
18B+7C
Splice
3177
3
60N
Abalone
4177
3
1N+7C
Nettalk(s)
5438
5
7N
Coding
20000
2
15N

N-nominal; B-binary; C-Continuous.

Table 1: Details of the datasets used in the experiment.
on the test dataset. The result is expressed as the average error rate of the W -fold crossvalidation. Note that this cross-validation is used for evaluation of the entire procedure,
whereas the J -fold cross-validation mentioned in Section 2 is the internal operation of
stacked generalization. However, both W and J are set to 10 in the experiments.
~ and
In this section, we present results of model combination using level-1 models M
0
~
M , as well as a model selection method, employing the same J -fold cross-validation procedure. Note that the only difference between model combination and model selection here
is whether the level-1 learning is employed or not.
Table 2 shows the average error rates, obtained using W -fold cross-validation, of C4.5,
NB and IB1, and BestCV, which is the best of the three, selected using J -fold crossvalidation. As expected, BestCV is almost always the classifier with the lowest error rate.3
~ , for which
Table 3 shows the result of stacked generalization using the level-1 model M
~ 0 , for
the level-1 data comprise the classifications generated by the level-0 models, and M
which the level-1 data comprise the probabilities generated by the level-0 models. Results
are shown for all four level-1 generalizers in each case, along with BestCV. The lowest error
rate for each dataset is given in bold.
Table 4 summarizes the results in Table 3 in terms of a comparison of each level-1
~ 0 derived
model with BestCV totaled over all datasets. Clearly, the best level-1 model is M
using MLR. It performs better than BestCV in nine datasets and equally well in the tenth.
~ is derived from NB, which performs better than BestCV in seven
The best performing M
datasets but significantly worse in two (Waveform and Vowel). We regard a difference of
more than two standard errors as significant (95% confidence). The standard error figures
are omitted in this table to increase readability.
The datasets are shown in the order of increasing size. MLR performs significantly
better than BestCV in the four largest datasets. This indicates that stacked generalization
is more likely to give significant improvements in predictive accuracy if the volume of data
is large|a direct consequence of more accurate estimation using cross-validation.
3. Note that BestCV does not always select the same classifier in all folds. That is why its error rate is
not always equal to the lowest error rate among the three classifiers.
W

276

fiIssues in Stacked Generalization

Datasets

Level-0 Generalizers
C4.5 NB
IB1
Led24
35.4 35.4
32.2
Waveform 31.8 17.1
26.2
Horse
15.8 17.9
15.8
Credit
17.4 17.3
28.1
Vowel
22.7 51.0
2.6
Euthyroid 1.9 9.8
8.6
Splice
5.5 4.5
4.7
Abalone
41.4 42.1
40.5
Nettalk(s) 17.0 15.9
12.7
Coding
27.6 28.8
25.0

BestCV
32.8 0.6
17.1 0.3
17.1 1.6
17.4 1.2
2.6 0.2
1.9 0.3
4.5 0.4
40.1 0.6
12.7 0.4
25.0 0.3

Table 2: Average error rates of C4.5, NB and IB1, and BestCV|the best among them
selected using J -fold cross-validation. The standard errors are shown in the last
column.
Datasets

~
Level-1 model, M
C4.5 NB IB1 MLR
34.0 32.4 35.0 33.3
17.7 19.2 18.7 17.2
16.9 14.9 17.6 16.3
18.4 16.1 16.9 17.4
2.6 3.8 3.6
2.6

BestCV
Led24
32.8
Waveform
17.1
Horse
17.1
Credit
17.4
Vowel
2.6
Euthyroid
1.9 1.9 1.9 1.9
Splice
4.5 3.9 3.9 3.8
Abalone
40.1 38.5 38.5 38.2
Nettalk(s)
12.7 12.4 11.9 12.4
Coding
25.0 23.2 23.1 23.2

1.9
3.8

38.1
12.6
23.2

~0
Level-1 model, M
C4.5 NB IB1 MLR
41.7 35.7 32.1 31.3
20.6 17.6 17.8 16.8
18.0 18.5 17.7 15.2
15.4 15.9 14.3 16.2
2.7 7.2 3.3 2.5
2.2 4.3 2.0 1.9
4.0 3.9 3.8 3.8
43.3 37.1 39.2 38.3
14.0 14.6 12.0 11.5
22.3 21.2 21.2 20.7

Table 3: Average error rates for stacking C4.5, NB and IB1.
~
~0
Level-1 model, M
Level-1 model, M
C4.5 NB IB1 MLR C4.5 NB IB1 MLR
#Win vs. #Loss 3-5 2-7 4-5 2-5 7-3 6-4 4-6 0-9
~ and M
~ 0.
Table 4: Summary of Table 3|Comparison of BestCV with M

277

fiTing & Witten

When one of the level-0 models performs significantly much better than the rest, like in
the Euthyroid and Vowel datasets, MLR performs either as good as BestCV by selecting
the best performing level-0 model, or better than BestCV.
MLR has an advantage over the other three level-1 generalizers in that its model can
easily be interpreted. Examples of the combination weights it derives (for the probability~ 0 ) appear in Table 5 for the Horse, Credit, Splice, Abalone, Waveform, Led24
based model M
and Vowel datasets. The weights indicate the relative importance of the level-0 generalizers
for each prediction class. For example, in the Splice dataset (in Table 5(b)), NB is the
dominant generalizer for predicting class 2, NB and IB1 are both good at predicting class
3, and all three generalizers make a worthwhile contribution to the prediction of class 1.
In contrast, in the Abalone dataset all three generalizers contribute substantially to the
prediction of all three classes. Note that the weights for each class do not sum to one
because no such constraint is imposed on MLR.

3.2 Are Non-negativity Constraints Necessary?
Both Breiman (1996a) and LeBlanc & Tibshirani (1993) use the stacked generalization
method in a regression setting and report that it is necessary to constrain the regression
coecients to be non-negative in order to guarantee that stacked regression improves predictive accuracy. Here we investigate this finding in the domain of classification tasks.
To assess the effect of the non-negativity constraint on performance, three versions of
~ 0:
MLR are employed to derive the level-1 model M
i. each linear regression in MLR is calculated with an intercept constant (that is,
I + 1 weights for the I classes) but without any constraints;
ii. each linear regression is derived with neither an intercept constant (I weights
for I classes) nor constraints;
iii. each linear regression is derived without an intercept constant, but with nonnegativity constraints (I non-negative weights for I classes).
The third version is the one used for the results presented earlier. Table 6 shows the
results of all three versions. They all have almost indistinguishable error rates. We conclude
that in classification tasks, non-negativity constraints are not necessary to guarantee that
stacked generalization improves predictive accuracy.
However, there is another reason why it is a good idea to employ non-negativity constraints. Table 7 shows an example of the weights derived by these three versions of MLR on
the Led24 dataset. The third version, shown in column (iii), supports a more perspicuous
interpretation of each level-0 generalizer's contribution to the class predictions than do the
other two. In this dataset, IB1 is the dominant generalizer in predicting classes 4, 5 and 8,
and both NB and IB1 make a worthwhile contribution in predicting class 2, as evidenced
by their high weights. However, the negative weights used in predicting these classes render
the interpretation of the other two versions much less clear.
278

fiIssues in Stacked Generalization

Horse
Credit
Class C4.5 NB IB1 C4.5 NB IB1
1
0.36 0.20 0.42 0.63 0.30 0.04
2
0.39 0.19 0.41 0.65 0.28 0.07
C4.5 for ff1 ; NB for ff2 ; IB1 for ff3 .
~ 0 ) for the Horse and Credit datasets.
Table 5: (a) Weights generated by MLR (model M
Class
1
2
3

C4.5
0.23
0.15
0.08

Splice
NB
0.43
0.72
0.52

IB1
0.36
0.12
0.40

Abalone
C4.5 NB IB1
0.25 0.25 0.39
0.27 0.20 0.25
0.30 0.18 0.39

Waveform
C4.5 NB IB1
0.16 0.59 0.34
0.14 0.72 0.07
0.04 0.65 0.23

~ 0 ) for the Splice, Abalone and Waveform
Table 5: (b) Weights generated by MLR (model M
datasets.
Vowel
C4.5 NB IB1
0.04 0.00 0.96
0.03 0.00 0.97
0.01 0.00 1.00
0.05 0.25 0.86
0.01 0.08 0.97
0.15 0.00 0.92
0.03 0.01 1.02
0.04 0.01 0.96
0.03 0.00 1.02
0.08 0.01 0.93
0.00 0.04 0.96
~ 0 ) for the Led24 and Vowel datasets.
Table 5: (c) Weights generated by MLR (model M
Class
1
2
3
4
5
6
7
8
9
10
11

C4.5
0.46
0.00
0.47
0.00
0.00
0.35
0.15
0.00
0.00
0.00
{

Led24
NB
0.65
0.37
0.00
0.13
0.19
0.14
0.43
0.00
0.38
0.50
{

IB1
0.00
0.43
0.54
0.65
0.64
0.35
0.36
0.68
0.29
0.24
{

279

fiTing & Witten

Datasets

MLR with
No Constraints No Intercept Non-Negativity
Led24
31.4
31.4
31.3
Waveform
16.8
16.8
16.8
Horse
15.8
15.8
15.2
Credit
16.2
16.2
16.2
Vowel
2.4
2.4
2.5
Euthyroid
1.9
1.9
1.9
Splice
3.7
3.8
3.8
Abalone
38.3
38.3
38.3
Nettalk(s)
11.6
11.5
11.5
Coding
20.7
20.7
20.7
Table 6: Average error rates of three versions of MLR.
Class
1
2
3
4
5
6
7
8
9
10

ff0

0.00
0.02
0.00
0.04
0.03
0.01
0.01
0.02
0.04
0.04

ff1

(i)

ff2

ff3

ff1

(ii)

ff2

ff3

ff1

0.45 0.65 0.00 0.46 0.65 0.00 0.46
{0.42 0.47 0.56 {0.40 0.49 0.56 0.00
0.46 {0.01 0.54 0.47 {0.01 0.54 0.47
{0.33 0.15 0.84 {0.29 0.21 0.81 0.00
{0.37 0.26 0.84 {0.32 0.26 0.84 0.00
0.35 0.12 0.35 0.36 0.14 0.35 0.35
0.15 0.43 0.36 0.15 0.43 0.36 0.15
{0.05 {0.25 0.72 {0.03 {0.19 0.72 0.00
{0.08 0.32 0.32 {0.05 0.40 0.30 0.00
{0.06 0.43 0.25 {0.01 0.50 0.24 0.00

(iii)

ff2

0.65
0.37
0.00
0.13
0.19
0.14
0.43
0.00
0.38
0.50

ff3

0.00
0.43
0.54
0.65
0.64
0.35
0.36
0.68
0.29
0.24

Table 7: Weights generated by three versions of MLR: (i) no constraints, (ii) no intercept,
and (iii) non-negativity constraints, for the LED24 dataset.

280

fiIssues in Stacked Generalization

Dataset
#SE BestCV Majority MLR
Horse
0.5
17.1
15.0 15.2
Splice
2.5
4.5
4.0 3.8
Abalone
3.3
40.1
39.0 38.3
Led24
8.7
32.8
31.8 31.3
Credit
8.9
17.4
16.1 16.2
Nettalk(s) 10.8
12.7
12.2 11.5
Coding
12.7
25.0
23.1 20.7
Waveform 18.7
17.1
19.5 16.8
Euthyroid 26.3
1.9
8.1 1.9
Vowel
242.0
2.6
13.0 2.5
~ 0 ), along with
Table 8: Average error rates of BestCV, Majority Vote and MLR (model M
the number of standard error (#SE) between BestCV and the worst performing
level-0 generalizers.

3.3 How Does Stacked Generalization Compare To Majority Vote?
~ 0 , derived from MLR, to that of majority vote,
Let us now compare the error rate of M

a simple decision combination method which requires neither cross-validation nor level1 learning. Table 8 shows the average error rates of BestCV, majority vote and MLR.
In order to see whether the relative performances of level-0 generalizers have any effect
on these methods, the number of standard errors (#SE) between the error rates of the
worst performing level-0 generalizer and BestCV is given, and the datasets are re-ordered
according to this measure. Since BestCV almost always selects the best performing level-0
generalizer, small values of #SE indicate that the level-0 generalizers perform comparably
to one another, and vice versa.
MLR compares favorably to majority vote, with eight wins versus two losses. Out of
the eight wins, six have significant differences (the two exceptions are for the Splice and
Led24 datasets); whereas both losses (for the Horse and Credit datasets) have insignificant
differences. Thus the extra computation for cross-validation and level-1 learning seems to
have paid off.
It is interesting to note that the performance of majority vote is related to the size of
#SE. Majority vote compares favorably to BestCV in the first seven datasets, where the
values of #SE are small. In the last three, where #SE is large, majority vote performs
worse. This indicates that if the level-0 generalizers perform comparably, it is not worth
using cross-validation to determine the best one, because the result of majority vote|which
is far cheaper|is not significantly different. Although small values of #SE are a necessary
condition for majority vote to rival BestCV, they are not a sucient condition|see Matan
(1996) for an example. The same applies when majority vote is compared with MLR. MLR
performs significantly better in the five datasets that have large #SE values, but in only
one of the other cases.
281

fiTing & Witten

M~ versus M~ 0

C4.5 NB IB1 MLR
#Win vs. #Loss 8-2 5-4 3-6 1-7
~ versus M
~ 0 for each generalizer|summarized results from Table 3.
Table 9: M
It is worth mentioning a method that averages P (x) for each i over all level-0 models,
yielding P (x), and then predicts class I^ for which P^(x) > P (x) for all i 6= I^: According to
Breiman (1996b), this method produces an error rate almost identical to that of majority
vote.
i

i

I

i

3.4 Why Does Stacked Generalization Work Best With M~ 0 Generated From
MLR?
We have shown that stacked generalization works best when output class probabilities
(rather than class predictions) are used with the MLR algorithm (rather than C4.5, IB1,
NB). In retrospect, this is not surprising, and can be explained intuitively as follows. The
level-1 model should provide a simple way of combining all the evidence available. This
evidence includes not just the predictions, but the confidence of each level-0 model in
its predictions. A linear combination is the simplest way of pooling the level-0 models'
confidence, and MLR provides just that.
The alternative methods of NB, C4.5, and IB1 each have shortcomings. A Bayesian approach could form the basis for a suitable alternative way of pooling the level-0 models' confidence, but the independence assumption central to Naive Bayes hampers its performance in
some datasets because the evidence provided by the individual level-0 models is certainly not
independent. C4.5 builds trees that can model interaction amongst attributes|particularly
when the tree is large|but this is not desirable for combining confidences. Nearest neighbor methods do not really give a way of combining confidences; also, the similarity metric
employed could misleadingly assume that two different sets of confidence levels are similar.
~ with M
~ 0 for each level-1
Table 9 summarizes the results in Table 3 by comparing M
generalizer, across all datasets. C4.5 is clearly better off with a label-based representation,
because discretizing continuous-valued attributes creates intra-attribute interaction in addition to interactions between different attributes. The evidence from Table 9 is that NB
is indifferent to the use of labels or confidences: the normal distribution assumption that
it embodies in the latter case could be another reason why it is unsuitable for combining
confidence measures. Both MLR and IB1 handle continuous-valued attributes better than
label-based ones, since this is the domain in which they are designed to work.
Summary

We summarize our findings in this section as follows.

 None of the four learning algorithms used to obtain model M~ perform satisfactorily.
282

fiIssues in Stacked Generalization

 MLR is the best of the four learning algorithms to use as the level-1 generalizer for
~ 0.
obtaining the model M
 When obtained using MLR, M~ 0 has lower predictive error rate than the best model
selected by J -fold cross-validation, for almost all datasets used in the experiments.

 Another advantage of MLR over the other three level-1 generalizers is its interpretability.
The weights ff indicate the different contributions that each level-0 model k makes
to the prediction classes `.
k`

 Model M~ 0 can be derived by MLR with or without non-negativity constraints. Such
constraints make little difference to the model's predictive accuracy.

 The use of non-negativity constraints in MLR has the advantage of interpretability. Non-

negative weights ff support easier interpretation of the extent to which each model
contributes to each prediction class.
k`

 When derived using MLR, model M~ 0 compares favorably with majority vote.
 MLR provides a method of combining the confidence generated by the level-0 models into
a final decision. For various reasons, NB, C4.5, and IB1 are not suitable for this task.

4. Comparison With Arcing And Bagging
This section compares the results of stacking C4.5, NB and IB1 with the results of arcing
(called boosting by its originator, Schapire, 1990) and bagging that are reported by Breiman
(1996b; 1996c). Both arcing and bagging employ sampling techniques to modify the data
distribution in order to produce multiple models from a single learning algorithm. To
combine the decisions of the individual models, arcing uses a weighted majority vote and
bagging uses an unweighted majority vote. Breiman reports that both arcing and bagging
can substantially improve the predictive accuracy of a single model derived using a base
learning algorithm.

4.1 Experimental Results

First we describe the differences between the experimental procedures. Our results for
stacking are averaged over ten-fold cross-validation for all datasets except Waveform, which
is averaged over ten repeated trials. Standard errors are also shown. Results for arcing and
bagging are those obtained by Breiman (1996b; 1996c), which are averaged over 100 trials.
In Breiman's experiments, each trial uses a random 9:1 split to form the training and test
sets for all datasets except Waveform. Also note that the Waveform dataset we used has 19
irrelevant attributes, but Breiman used a version without irrelevant attributes (which would
be expected to degrade the performance of level-0 generalizers in our experiments). In both
cases 300 training instances were used for this dataset, but we used 5000 test instances
whereas Breiman used 1800. Arcing and bagging are done with 50 decision tree models
derived from CART (Breiman et al., 1984) in each trial.
283

fiTing & Witten

Dataset
#Samples stacking arcing bagging
Waveform
300
16.8 0.2 17.8
19.3
Glass
214
28.4 2.9 22.0
23.2
Ionosphere
351
9.7 1.5
6.4
7.9
Soybean
683
4.3 1.1
5.8
6.8
Breast Cancer
699
2.7 0.8
3.2
3.7
Diabetes
768
24.2 1.2 26.6
23.9
Table 10: Comparing stacking with arcing and bagging classifiers.
The results on six datasets are given in Table 10, and indicate that the three methods
are very competitive.4 Stacking performs better than both arcing and bagging in three
datasets (Waveform, Soybean and Breast Cancer), and is better than arcing but worse than
bagging in the Diabetes dataset. Note that stacking performs very poorly on Glass and
Ionosphere, two small real-world datasets. This is not surprising, because cross-validation
inevitably produces poor estimates for small datasets.

4.2 Discussion

Like bagging, stacking is ideal for parallel computation. The construction of each level-0
model proceeds independently, no communication with the other modeling processes being
necessary.
Arcing and bagging require a considerable number of member models because they
rely on varying the data distribution to get a diverse set of models from a single learning
algorithm. Using a level-1 generalizer, stacking can work with only two or three level-0
models.
Suppose the computation time required for a learning algorithm is C , and arcing or
bagging needs h models. The learning time required is T = hC . Suppose stacking requires
g models and each model employs J -fold cross-validation. Assuming that time C is needed
to derive each of the g level-0 models and the level-1 model, the learning time for stacking
is T = (g(J + 1) + 1)C . For the results given in Table 10, h = 50, J = 10, and g = 3; thus
T = 50C and T = 34C . However, in practice the learning time required for the level-0
and level-1 generalizers may be different.
Users of stacking have a free choice of level-0 models. They may either be derived from a
single learning algorithm, or from a variety of different algorithms. The example in Section
3 uses different types of learning algorithms, while bag-stacking|stacking bagged models
(Ting & Witten, 1997)|uses data variation to obtain a diverse set of models from a single
learning algorithm. In the former case, performance may vary substantially between the
level-0 models|for example NB performs very poorly in the Vowel and Euthyroid datasets
compared to the other two models (see Table 2). Stacking copes well with this situation.
The performance variation among the member models in bagging is rather small because
they are derived from the same learning algorithm using bootstrap samples. Section 3.3
a

s

a

s

4. The heart dataset used by Breiman (1996b; 1996c) is omitted because it was very much modified from
the original one.

284

fiIssues in Stacked Generalization

shows that a small performance variation among member models is a necessary condition
for majority vote (as employed by bagging) to work well.
It is worth noting that arcing and bagging can be incorporated into the framework of
stacked generalization by using arced or bagged models as level-0 models. Ting & Witten
(1997) show one possible way of incorporating bagged models with level-1 learning, employing MLR instead of voting. In this implementation, L is used as a test set for each
of the bagged models to derive level-1 data rather than the cross-validated data. This is
viable because each bootstrap sample leaves out about 37% of the examples. Ting & Witten
(1997) show that bag-stacking almost always has higher predictive accuracy than bagging
models derived from either C4.5 or NB. Note that the only difference here is whether an
adaptive level-1 model or a simple majority vote is employed
According to Breiman (1996b; 1996c), arcing and bagging can only improve the predictive accuracy of learning algorithms that are `unstable.'5 An unstable learning algorithm
is one for which small perturbations in the training set can produce large changes in the
derived model. Decision trees and neural networks are unstable; NB and IB1 are stable.
Stacking works with both.
While MLR is the most successful candidate for level-1 learning that we have found,
other algorithms might work equally well. One candidate is neural networks. However,
we have experimented with back-propagation neural networks for this purpose and found
that they have a much slower learning rate than MLR. For example, MLR only took 2.9
seconds as compare to 4790 seconds for the neural network in the nettalk dataset; while
both have the same error rate. Other possible candidates are the multinomial logit model
(Jordan & Jacobs, 1994), which is a special case of generalized linear models (McCullagh
& Nelder, 1983), and the supra Bayesian procedure (Jacobs, 1995) which treats the level-0
models' confidence as data that may be combined with prior distribution of level-0 models
via Bayes' rule.

5. Related Work

Our analysis of stacked generalization was motivated by that of Breiman (1996a), discussed
earlier, and LeBlanc & Tibshirani (1993). LeBlanc & Tibshirani (1993) examine the stacking
of a linear discriminant and a nearest neighbor classifier and show that, for one artificial
dataset, a method similar to MLR performs better with non-negativity constraints than
without. Our results in Section 3.2 show that these constraints are irrelevant to MLR's
predictive accuracy in the classification situation.
LeBlanc & Tibshirani (1993) and Ting & Witten (1997) use a version of MLR that
employs all class probabilities from each level-0 model to induce each linear regression. In
this case, the linear regression for class ` is

LR (x) =
`

XXff
K

I

k

i

ki`

P (x):
ki

This implementation requires the fitting of KI parameters, as compared to K parameters
for the version used in this paper (see the corresponding formula in Section 2.2). Both
5. Schapire, R.E., Y. Freund, P. Bartlett, & W.S. Lee (1997) provide an alternative explanation for the
effectiveness of arcing and bagging.

285

fiTing & Witten

versions give comparable results in terms of predictive accuracy, but the version used in
this paper runs considerably faster because it needs to fit fewer parameters.
The limitations of MLR are well-known (Duda & Hart, 1973). For a I -class problem, it
divides the description space into I convex decision regions. Every region must be singly
connected, and the decision boundaries are linear hyperplanes. This means that MLR is
most suitable for problems with unimodal probability densities. Despite these limitations,
MLR still performs better as a level-1 generalizer than IB1, its nearest competitor in deriving
M~ 0. These limitations may hold the key to a fuller understanding of the behavior of stacked
generalization. Jacobs (1995) reviews linear combination methods like that used in MLR.
Previous work on stacked generalization, especially as applied to classification tasks,
has been limited in several ways. Some only applies to a particular dataset (e.g., Zhang,
Mesirov & Waltz, 1992). Others report results that are less than convincing (Merz, 1995).
Still others have a different focus and evaluate the results on just a few datasets (LeBlanc
& Tibshirani, 1993; Chan & Stolfo, 1995; Kim & Bartlett, 1995; Fan et al., 1996).
One might consider a degenerate form of stacked generalization that does not use crossvalidation to produce data for level-1 learning. Then, level-1 learning can be done `on the
y' during the training process (Jacobs et al., 1991). In another approach, level-1 learning
takes place in batch mode, after all level-0 models are derived (Ho et al., 1994).
Several researchers have worked on a still more degenerate form of stacked generalization
without any cross-validation or learning at level 1. Examples are neural network ensembles
(Hansen & Salamon, 1990; Perrone & Cooper, 1993; Krogh & Vedelsby, 1995), multiple
decision tree combination (Kwok & Carter, 1990; Buntine, 1991; Oliver & Hand, 1995), and
multiple rule combination (Kononenko & Kovacic, 1992). The methods used at level 1 are
majority voting, weighted averaging and Bayesian combination. Other possible methods are
distribution summation and likelihood combination. There are various forms of re-ordering
class rank, and Ali & Pazzani (1996) study some of these methods for a rule learner. Ting
(1996) uses the confidence of each prediction to combine a nearest neighbor classifier and a
Naive Bayesian classifier.

6. Conclusions
We have addressed two crucial issues for the successful implementation of stacked generalization in classification tasks. First, class probabilities should be used instead of the single
predicted class as input attributes for higher-level learning. The class probabilities serve as
the confidence measure for the prediction made. Second, the multi-response least squares
linear regression technique should be employed as the high-level generalizer. This technique
provides a method of combining level-0 models' confidence. The other three learning algorithms have either algorithmic limitations or are not suitable for aggregating confidences.
When combining three different types of learning algorithms, this implementation of
stacked generalization was found to achieve better predictive accuracy than both model
selection based on cross-validation and majority vote; it was also found to be competitive with arcing and bagging. Unlike stacked regression, non-negativity constraints in the
least-squares regression are not necessary to guarantee improved predictive accuracy in
classification tasks. However, these constraints are still preferred because they increase the
interpretability of the level-1 model.
286

fiIssues in Stacked Generalization

The implication of our successful implementation of stacked generalization is that earlier
model combination methods employing (weighted) majority vote, averaging, or other computations that do not make use of level-1 learning, can now apply this learning to improve
their predictive accuracy.

Acknowledgment

The authors are grateful to the New Zealand Marsden Fund for financial support for this
research. This work was conducted when the first author was in Department of Computer
Science, University of Waikato. The authors are grateful to J. Ross Quinlan for providing
C4.5 and David W. Aha for providing IB1. The anonymous reviewers and the editor have
provided many helpful comments.

References

Aha, D.W., D. Kibler & M.K. Albert (1991). Instance-Based Learning Algorithms. Machine Learning, 6, pp. 37-66.
Ali, K.M. & M.J. Pazzani (1996). Error Reduction through Learning Multiple Descriptions. Machine Learning, Vol. 24, No. 3, pp. 173-206.
Blake, C., E. Keogh & C.J. Merz (1998). UCI Repository of machine learning databases
[http:// www.ics.uci.edu/ mlearn/MLRepository.html]. Irvine, CA: University of California, Department of Information and Computer Science.
Breiman, L. (1996a). Stacked Regressions. Machine Learning, Vol. 24, pp. 49-64.
Breiman, L. (1996b). Bagging Predictors. Machine Learning, Vol. 24, No. 2, pp. 123-140.
Breiman, L. (1996c). Bias, Variance, and Arcing Classifiers. Technical Report 460. Department of Statistics, University of California, Berkeley, CA.
Breiman, L., J.H. Friedman, R.A. Olshen & C.J. Stone (1984). Classification And Regression Trees. Belmont, CA: Wadsworth.
Cestnik, B. (1990). Estimating Probabilities: A Crucial Task in Machine Learning. In
Proceedings of the European Conference on Artificial Intelligence, pp. 147-149.
Chan, P.K. & S.J. Stolfo (1995). A Comparative Evaluation of Voting and Meta-learning
on Partitioned Data. In Proceedings of the Twelfth International Conference on Machine Learning, pp. 90-98, Morgan Kaufmann.
Cost, S & S. Salzberg (1993). A Weighted Nearest Neighbor Algorithm for Learning with
Symbolic Features. Machine Learning, 10, pp. 57-78.
Fan, D.W., P.K. Chan, S.J. Stolfo (1996). A Comparative Evaluation of Combiner and
Stacked Generalization. In Proceedings of AAAI-96 workshop on Integrating Multiple
Learned Models, pp. 40-46.
Hansen, L.K. & P. Salamon (1990). Neural Network Ensembles. IEEE Transactions of
Pattern Analysis and Machine Intelligence, 12, pp. 993-1001.
287

fiTing & Witten

Ho, T.K., J.J. Hull & S.N. Srihari (1994). Decision Combination in Multiple Classifier
Systems. IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 16,
No. 1, pp. 66-75.
Jacobs, R.A. (1995). Methods of Combining Experts' Probability Assessments. Neural
Computation 7, pp. 867-888, MIT Press.
Jacobs, R.A., M.I. Jordan, S.J. Nowlan & G.E. Hinton (1991). Adaptive Mixtures of Local
Experts. Neural Computation 3, pp. 79-87.
Jacobs, R.A. & M.I. Jordan (1994). Hierachical Mixtures of Experts and the EM Algorithms. Neural Computation 6, pp. 181-214.
Kim, K. & E.B. Bartlett (1995). Error Estimation by Series Association for Neural Network
Systems. Neural Computation 7, pp. 799-808, MIT Press.
Kononenko, I. & M. Kovacic (1992). Learning as Optimization: Stochastic Generation
of Multiple Knowledge. In Proceedings of the Ninth International Conference on
Machine Learning, pp. 257-262, Morgan Kaufmann.
Krogh, A. & J. Vedelsby (1995). Neural Network Ensembles, Cross Validation, and Active
Learning. Advances in Neural Information Processing Systems 7, G. Tesauro, D.S.
Touretsky & T.K. Leen (Editors), pp. 231-238, MIT Press.
Kwok, S. & C. Carter (1990). Multiple Decision Trees. Uncertainty in Artificial Intelligence 4, R. Shachter, T. Levitt, L. Kanal and J. Lemmer (Editors), pp. 327-335,
North-Holland.
Lawson C.L. & R.J. Hanson (1995). Solving Least Squares Problems. SIAM Publications.
LeBlanc, M. & R. Tibshirani (1993). Combining Estimates in Regression and Classification. Technical Report 9318. Department of Statistics, University of Toronto.
Matan, O. (1996). On Voting Ensembles of Classifiers (extended abstract). In Proceedings
of AAAI-96 workshop on Integrating Multiple Learned Models, pp. 84-88.
McCullagh, P. & J.A. Nelder (1983). Generalized Linear Models. London: Chapman and
Hall.
Merz, C.J. (1995). Dynamic Learning Bias Selection. In Proceedings of the Fifth International Workshop on Artificial Intelligence and Statistics, Ft. Lauderdale, FL:
Unpublished, pp. 386-395.
Oliver, J.J. & D.J. Hand (1995). On Pruning and Averaging Decision Trees. In Proceedings
of the Twelfth International Conference on Machine Learning, pp. 430-437, Morgan
Kaufmann.
Perrone, M.P. & L.N. Cooper (1993). When Networks Disagree: Ensemble Methods for
Hybrid Neural Networks. Artificial Neural Networks for Speech and Vision, R.J.
Mammone (Editor). Chapman-Hall.
Quinlan, J.R. (1993). C4.5: Program for machine learning. Morgan Kaufmann.
288

fiIssues in Stacked Generalization

Schapire, R.E. (1990). The Strength of Weak Learnability. Machine Learning, 5, pp.
197-227, Kluwer Academic Publishers.
Schapire, R.E., Y. Freund, P. Bartlett, & W.S. Lee (1997). Boosting the margin: A new
explanation for the effectiveness of voting methods. In Proceedings of the Fourteenth
International Conference on Machine Learning, pages 322-330, Morgan Kaufmann.
Smyth, P. & D. Wolpert (1997). Stacked Density Estimation. Advances in Neural Information Processing Systems.
Ting, K.M. (1996). The Characterisation of Predictive Accuracy and Decision Combination. In Proceedings of the Thirteenth International Conference on Machine Learning,
pp. 498-506, Morgan Kaufmann.
Ting, K.M. & I.H. Witten (1997). Stacking Bagged and Dagged Models. In Proceedings of
the Fourteenth International Conference on Machine Learning, pp. 367-375, Morgan
Kaufmann.
Weiss S. M. & C. A. Kulikowski (1991). Computer Systems That Learns. Morgan Kaufmann.
Wolpert, D.H. (1992). Stacked Generalization. Neural Networks, Vol. 5, pp. 241-259,
Pergamon Press.
Zhang, X., J.P. Mesirov & D.L. Waltz (1992). Hybrid System for Protein Secondary
Structure Prediction. Journal of Molecular Biology, 225, pp. 1049-1063.

289

fi	
fffi 	


 ! #"$ % 	'&)( *,+'( ---.$/10 24315

A

64789 :;/1<-3!=>7
%&:@?<--

BDCFEHGJIKMLNKPORQTSVUHW4KXICZY\[HK]CFLNKMSV^_Ca`bBDC;OcQdGHegfih!GjK

kmlonqpsrutwvyx,z|{~}'r,pff

oTssooo

Ns,~PN]'Ms1sMd1a
 ffjq
s mmsqFff 1

y;m
# a#4, !  |Hjq@|,F |
 
 Taq;9d41a)q! ,q# ]aP dffJ!
a ]@ !u4   Tm9@T@141a;94 F 
a49~@1Tq M1 $
Nj 9]P 
F]
  $	d
 ff
 fi1 	 H
     !1"#$	
 " 9 %1]1& '
( 
)*q+,+-M	.0/132(45,6"7%819MF
*:
;$"+<;
=
("1>?
1=
&1	
(m,$&@=
	
(4
 A$
(&B/DCFEHGI6 JK", L
M$fi N
( AOPH4R$
 9CRSU
Q T 7V ==&" 1W]< /GAXYC6Z&K
 P& 
 
< [/DCFEHG6"\]K  ; R |
;
 ;< [/G^XYC_6B
(a
 $I1& fi `
 &M  >fi %Ga* qbC7 ( M
- .

 ;$ " Hc;
< [/G+XYC6/;d
 &  Gd$fi qff1] B  	 q
;&&@
(KKHP
 
 ;< [/ G+XYC6%J
Ge fOg6"o
\ 
 9$\ & :=j

 ;$ " ihjK4 
 

Q T\
kflox <;[/ G^XYC_6 S h%/[;< /G^XYC_6!6F FCRSU

 fi 
 ff;< [/GdmnG:opXYC6qff
|;$"i9<;[/G_opXrGdmsC6q
fib<]/G^XYC6"\9
	\

;$
 " uteH4|
 

& NI


$ 1

Q T7
kuvx <;[/GwmuG o XYC6 S t/[<;[/G o XrGwmfC_6"EK<;[/G+XYC_6!6xGymfCzS{
| ff" )$
 @ L]< $F
M&$
(j;$"J\qffM9	
jK
(Mh%/;}]6 S 1]~N}^
fitN/;}]E"$6 S
}''7@M
- .+N
( %4IM
 	
( &9
("K$ " 	 W
("K , 
 %t;
 `= Bfi$&1q"?
((\=^

 " ,B1  fif$fi &K*(
 "* (\c
 

fi 
 qh
 `= fffi & q"?
((79a
 $fi )
& 1 
("KN " \
4
 	=
 
 ff]< F H
 &"o R
 10
i1& $
( `nfi "&"'s" n  N1 q1 j
 1& Nff

 " , $ 1 @1T;$ " :A { H4
 ZJ>]< x
B1& $
( `_fi "&K$s" 

iO\$

 fi
'/[;< /G^XYC_6!6Fu'/[;
< /DC_6!6 S '/[;
< /GymfC6!6F CS{
Q T\
/1(6
d& :]< /DC_6F=
 f
(&1*?
 " |&=;
< [/DCXrOg6"7
- .JW& KF
(W
 "&H
( 1fin
N1& 	
 M$fi 	
(  11&  \L$
(& "	?
(&"i 
| ffMK&"&K" \J@
N
.?ff q"& u Nff$ u
 fiL\$H
 & W&  q"\  :B Aff$ 7o d
& .
 
!qc;[!) [K[Z[H:JD%r,K(qH@K([=FppYZY_;)KH(HH%[K[
[(KMD(? ;;DcH9KY:;D!J	p(`@Z%YA[p@HpJ`Y	!c:9HYcp
pHpYL[FD3K(BDZ[p3$$(;DDpxY(D[D=Hp)pK(H[=Y=[pH
[[K[p




%



F



 

( ---  %% !:		: M1	 m	!fi8,	 7!
%&% 

&1%o% 1 :

fi

o

- 1	N
A/132,6
(	
(fiff#""&1
(&"Hq&x1P1K
fi$
(&"fi^/[<%
"?
6
 
$&1$
(`$&!>7F8??
(&1q"?Hq"F
(&.$&1"1fi,I
B/132(>\c7>4>6">fi$fiL\
- .J=)
@
 & 	)
 F _ & &" 1$
 x
 '1&  qB0/13225,6"7
 &= $
(&"  Z$1& $

 &!* "(\  K &KA
 J\'
 fiiZ
  ff"A/1325,6%1fii B
(=
I$
(K
$ i
 fi ffT
& & $
( ":
($1& 
(4 )
 1N1& 	
(  
(s=$ 1& K
( `7
 K &HN
 f/132,6xfi F
(F
:$
("P &@$1& 	*fi :
 A
. A
 "	
 "  &@ JJfi$
 1(7
)IA
( f "&"$"  PM$
( &Ma
 1u 	a/p,H
 	
 F
 
 y.  $1& .
N 6


 BM
- 	.=1& K)$fi )
 fffiu ^~#  1M$fi N
( 	\ * qf$$fi &% "1& ff
(KK$ " M
 hj
 fi
t/p1 "1&  ,& $
 j1 BN
($fi ),NM
- .A
 H
fi 1 =A
($fi ) N
('$
( &"x1& 3*> _*(
(&K?
 "] L@
- .J
& K"6"7^8  ff#  1$fi A
( :
(1& N
(&"$
(
1
 $1 H)H
  : 11&   nBq
($	
 " \ 
K 1 " 
 x
(&" q"# &" =1& $
( `:$
(1 
fi M
- 	.1& HDw
 
fi ff&""#$	
 " 
"?N?
(&: n"$&" DwffMRK
( qnB 
u&K
(  %K
( \
 fi &1& :	
(& 1& * M
 fiL7
- .J
("H " @
(1& 9 HN qP1_$1& 	* d
 1& 	* &\ $9 $11& .
N =H  "] 
 )@
& K* q u #  1M$fi N
( 7
1
 
 $	d
  
 ff1 H
 N
(KK$ " :1& 
(&"fi$ ft
 fihff^N
($fi H1i1& 3* +@
- .J
& K7qA
 fi@&H
($fi /1322,6* 0
 w.
N  My
1

 o " ;
< p\%$fi ~# w
fi 
~#  1
fi A
( Js\ 
 9)
$
 ff)1  &"o T
 1
ff1& '
( +fi "&"'s" J7$ @
& 94  ;
< p\M
 M	
 
K
(
 ut/;}ZE"6 S  J/;}]E"$6_
 fijh%/;}c6 S 1_~j}Z78  ^N j
 ff= ufi$ 1& q"?
((\@
- .J

("K$ " )$,H $Mq!@&K
($fi F.
$ (7
T$&:
s&"
 $
* NA
($fi fi$ 1& q_
("K$ " 	7W$ B/13255>\@s8  " 0/p)
 & 	1(6!6
fi 
$
 ff_A
( ff
 n
("KN " M
(sMtI\Z'sJI$fi :N
( RM
 |ff&
("KN " N\ 	
(! 
d
 ! >K
 MF&K
($fi H.
 (7A)
 ff#$&"1 :J
 
 J$N;
< [/GAXYC)
6 K
( R
  * &!
*
(?M +1 H
 q&K
  Nr(E":p\'= _7x  MM@&H
($fi a.
N (\ M$fi A
( A9~#  1(\
  q & K
( 	
 $ffJfic7qd
1
   fiT
 
 : FGa
 fiG:oZ
(1& fffip  m\ q1& ff:

 " ,);$ " ig  ?  \' "&" "u 1& 	
("   	
(4 0
(&" q\H4 $
 

k+m x ;< [/GwuG_opXYC6 S /[]< /GAXYC6"EK]< `/G_opXYC6!6"7
Vw H B
("K$ " 	\ =* )
_1& Jff!  =K&" P
 ;]M
- H
. 1 3 $
 ;
< 
; "1 q"?
(A
:& $
( Afi "&"$" J7M%
 fiNF&K
($fi 9  ]s]
 \ j;
& .
N (\
1
& W@
 $ " +K
 "  ffWA/ * q+ LM
 qfi1&  B& >& 	H
 qP
 == " ,

 fi1 "&" "u 1& 	
(" N  	
(4 0
(&" q6"7 ?

6 	
(&" &B$1& 	* fii
1& K=K??
(M
& 1NW$ ;\L$$fi &)1  d
 
 9 "&  &
 4 q,$
(4 s/132(42,@

("K$ " 	7 u$
(1& "	?
(&~\ :
(KKHfi+q>\$= fg 7
T$&%*(
(&"?

 "
 M
- .J)1& K
	* _
(1 Iq^ "$fi & fiu  q 1&K
 K&1(7@o 
& .
N (\


K





K
&
A







/
3
1

2


,

9
6





fi


!
&

*


"

(

\


K





K
&
A




J


\






fi
Z










ff

"

^


/
3
1

2


,
5
9
6
(


"

K


a








B


t
= " >



W

 fii1 "&" "i 1& 	
(K A 	
(4 
(&" qW
 fihB " >M
 fii1 "&" "i$fi 1& 	
(K 7
8  9N , ff "&" "I " , j	
(4 N
(&"Hq\ ,;
(9 &  "&" " R17+B ?$$
(
/132,6@*  %
 $ff&%   "  ]
("KN " @
 fiA?
(?NP 
 ]NKN 1
(&K
 1


 B;< cd
 "1 q"?
(i
I1& '
( ufi "&K$s" J7
	$_H`!$DD J"!][p%[q9M	px(`pYNFNHF[I;D=sH[);YH	pH()HL[
DH(3pYK?$!JD3[H '[HxDK)YxcH]DqpKpW[!HDZ`(	pH,
3'[(K"['p![;`pYF[K
 NJ[;`pxY(Dp!HYY@![%Kp)D	,cppY[[pH +JD 	
[D9cDHW;!c9[(K
 ff fi  fiH ]c" >3;@[(" JKc[;`p9Dp!HFHK>
HpH)' 


fi

o$s$!P"$$#@$~%PF!&


o$('*)$

 $I#$&" 11&"* N ff1q"?
(1& $	M= bM
)
- .J&1K_x
(&"^/1322(4>6"7fWA$s"
\_H-@.J&1=Hff\F&4
(\@
(&K&1
(I1 ^fi$
"II&1&ff
fidq


 1	$ WMN
(ofi F1^#$Z 0
( $fi K
(q1 H

 uff
"&K
("*q"9&"
(B17
x
(&"_$1& 	*$fi _
u&K 1& :& ]]$I1& K\
("KN  
 JI&K
  H;
<  K
( $fi
 >E1%
 fi" 
("KN " M"?N?
(F
& 1 1    &!* "(\  K &HN
 J\x
 fin
  ff"(7A 
$
(& "	?
(&N\ 
("HH)
 
 WtzW " >M
 fi0 "&" "0 1& 	
(" A s/[>E1 ? 
 |
fi 
 _h
fi$1& 	
(K 7  	M
 * &#\ ffN
( :,$ff
(fi$fi " 
(x
("KN " 
 \]
(J
 R?1  xH
\
)
 ff=* &!
( 	
( 
Q T\
k,+Nx $&W
(].-0/@E21E435-{1
fi687>\$$&1_
(&1:"MC (:9 C ?;9 C  9 C<:K! 
MC  S{

 |

fi 	
(4 %X ;< [/DC < XYC  6Z=
~ /X\X ;
< [/DC  XYC ? 6]>
~ 1FX\'
fisX <;[/DC ? XYC ( ]6 ~53xX9")
67
| ff"$
)W
("KN" &")$_&K
<;N1N:fioq1_b >E1p7=)WH	

\
u$
(&1"	?
(&\$_fi$N
(O +d4<;cBfi$#~fiu	
$$ff=q#~1(7
)
 q
(KK$ " 1& 	
($"K
(&!?x
(&"qK"T
MW$ ,fiW1HNff7
/p)
 "KNfiK	"1 fin i;&&:ofi K
(F 	_76jd
  $11& .
  M_$
( &* 
;&
& *$fi q (7% B $	=)
 
 qM
- 	.W1& K)
(W u#  1:$fi A
( o\ * qf ;
 
("K a
 
B&K

  c;< $ f >E1p\$h%/;}]6 S 1~N}/p1 
 \> N$
(& "	?
(&	\hnP `= Bfi$ 1& q"?
(q
 fi
 $ff1	
(n$fi 1& 	
(" >6"\FI/;}]E"$6 S }+y$\x
 fit  ~#  1fi 1& q"?
($^
 fis "&" "
H
 1
& 	
(K R
 f/[>E1 ? 7xV M	
  ;&$&
("HH)
 )td% AK
 "* (\t/[>E!}c6 S t/;}]EK,6 S >\

 

fi 
 Mt/;}ZE1(6 S t/1E!}]6 S }Z7:)
 .
N 	No 
(" T
   a
 aff
(	
($ 
@
- .J:1& KMJ
 ;
(J
& 
(&"& 	M
 a
& 
 0%
(_1& * "f * fiL7 q& 	N
( M
 y q>$ " 

(F
 1uT
 a
& 1& I
 n
(1& $&"?
 1I "1& qff $q  ;
("K$ " T
 
 $fi M* ^
- 	.B1& K9 +#  1:1 " 	7@)
M
 1& Md
 &&)fi"	""   9"HM fs8  " (@,7
 
( #\ R.
N ff 	BF

 * qH
 1& (7: ff &" ;M1& `\ZM
- .?
(?a
 1u 3


 9tgff%q
 +
(" ,?
 "* $ " Js\ 
 9s\ 
 9t/;}ZE"t/p$2E A6!6 S t/ptN/;}]E"$6"2E A>6"7o @
& 
< #   $11& .
N (\ 1& _	
 fN
(K1 ,?
 "* R;$ " ftK
 "  ^q,7) =d
;
 
1&"*(

 " 
 B)
 _  1A 3= j
 
 d1& d
 $1& $
( `fi "&"$" 1  &"o 
1N;
< p7
V 
 ]c  )
D
 J& ?^B K
(\M
- 	.Z1& "c $	=m $
 ]t/;}]E"tN/p$2E A>6!6 S t/ptN/;}]E"$6"2E A>6
_
 & $1  "&" /;}ZE"$2E A>60K4_$
 H
\ &1  s "C ( \^C ? \+C  \
 fiRC < \ff;
 b
	* 
} S ;< [/DC < XYC  mC ? mC ( 6"\x S ;< [/DC  XYC ? mC ( 6"\@
 B
fi A S ]< /DC ? XYC ( 6"70 M$A1 R)K!
"&" q/;}ZE"$2
E A>6@%$fi q1 =  >E1  s\ qAM
 B ?fi$B,N " , 
 )td)
(" ,?
 "* (7)
 
 1qj)W4f1& 1  
 $N1 R)K! "&"$ $fi q1 A y >E1?

7 a% &"1 (\x BO
B~#  1(\$M
 _	
 offa$
* $fi q" `79Bq+ o11& .
$ _ 3=\';
 $fi  ffW  q&H
( 
	* 

("1 >?
 "* i +#  1M$fi N
( 7  & 	* &\ 9?
(H 
(" ,?
 "* i	
 i1& K9  J;
(?&1
M
- .J
 $1& 	u7
UK??
(&1& 	1 	] 1. ) AB' ;9& x/[
()
(1& 	
(fi 1&!* fi+,
(&KW/1322(4>6!6"7
VD MB' ;W1& ]$fi 
 ff9 * * : 3= R
 
 9tgB
("1 >?
 "* (\' 9$fi ) * *  3= 


 a
(" ,?
 "* (7uW
( J\ 
 ff$
(&"y
fi 1i $	 
 I_
(K1 ,?
 "*  &_
(& &"?
 1
"&" 	\$"
(J
 A	
(1  &_t7+<%s 1 	NF
 
 W$ )
(1 fi$
 
(KK$ " 
 

(&K
 1# 
 F
(1& &K?
 11 #"&"$ ]]ofi q1 (\
 fi: ] ffZ 	
(#& 
 #
("KN " 
C

fi

o

fi$ff ;
(9
(&K
1a7 < W)	T++8"i,\q&1	
(
(&"1)  !q,$
(4J
1& `7
 $N$1&1.
 1-M	.&	u\=KH>fi#$	
"\	
b
(10A1fi 1
)
3 
 9
 ff&; s 3d
 +1& K%  W 1&K
 K&1q@
 ff)  1^ &"1&  7  %1 	ff

(
 1& $
($ 0
 fi>
( K
 "* N1& $
( `b/132(,6"\ ff "$fi &K:
 $> ,$H&"
ff" jEDGFHJIKLMKNPORQTSVU4D2FWXYORNPOFWKZ [JI!L\F^]_K%]`ORZaORNPb\>d
 ! 
( 	=%u1:H
0Cw* q^GU@
 F 	
( 

(1& $
(^
(CWo* qjGMo\x$fi qff1fiCIXrd
G caCBo[XrG:o7fM
- fi$ " 
 ecz
(1& N* qi
 I
(1& 
?
(?H
 R
fi 1F&" ;@. 1q @Z/[
H
 a
 ff9&  6]T

 $ " I]< H4
 CXrf
G c{C o XrG o
j]< /DCIXrGI;
6 gd]< /DCBoXrGMo6=
 fin
 
(" ,?
 "*  $ " taK
 "1 > uq,7+/p)
 MM)
 $1& 	
 @
H
- $
( 1&9") /p $(\]132(,6"76  	M
 * &\ _;
< $fi ~# fii i^ o11& .
$ J1^@
- .J
1
& 	 	
 u:1fi 1N* 
I $11& .
 a1H=1& H=
(9M
 ;7
 1&  " a

\ + ff 0#$&"  "?H
 
sK??
(& &"1& & 
(+q ff1fiw  $1
;$
 " 
(N 
" 	7%'
(?N
( A/132>1(6%* q
 ffT
& .
N I/p i
N	
(1 _ * * A
As" 
 >$fi  Z!  :q
	*> &6@
 fi q" M
H
 
 )q $	=ff1 
 9 	
( @M
 "?N?
(M
& .
N ) 
:$!>!
  	
( 1&K
 K&17
 $W& 	N
( $fi M
)
& 9$
( &%@
 &"
  fi0
(@
  3=7@  Js. 91  "  & M9
IH
 1& 
fi K
( fifi$"	""  m$W$1& 	R uM
$
- .J)1& 7d
 B o11& .
$ d1M
- 	.M
 $1& 	z
* q s8  " >7_d
  	B u1  "  $	=T
 
 : MM
(1 
^ $11& .
N 1+ $(
1
& 	7x8  " h@= ?fioZB _1  @fiK	"" J\$
(1& "	?
(&"
 
("H " Z$ofi &cd
 ! 
- 	.)
M
 1& 	 N )$fiL7
i#kj,lnmBo

qp

m!r

s



lt

u8v
o

u
w

 ofi$&"K
fib&1$	Bw-@.Ju&1\9^
(K
(y"fi$&  !q'
(4J$&1`\
d! 0WK??
(&WfK&":-M.JM&1)/pMq
(K$
(*q1&a1+W$ ;:&16"\L$sW1
  ff
(fi$fi " 
(@
("H " \Ld
1
 ! nN
( : 	
(" J
& 1 .?
( n ofi K
(;7NB' ;\FM
- 	.\
 fi
 ! q,$
(4 f
(cN
( q&" "	
(]T#o " 
(m 
" 9  &)$1& `\
 fi uN
( T
K
 I/p1 	 u$""~# fiJ6 	
(f
 = &"& " fi I  "9  &9$1& 7
 R)$ffK
 "  F$
( &\  ! q'
(4 0/132(42>\L7xY5 @`x>56x
("HH9/1(#6 
 P=&K
  

Z;
< [M/ yzX y69
ffK1M) >E1p\]/6F;
< [/G+XYC_6 S 1M |
C { GN\L/[,,6 
 9 G
 fiG o 
(1& qfip  \
qA]
< `/GnffGMo[XYC_6 S ;< [/G+XYC_6f;< [/G_o[XYC_6%'/ ,	s\ B
("K , 
 W
 fi\>= A 
6"\Z
 fi/p4>
6 
 _M fiMB 
 o " t 
 _Mfi$ 1& q"?
((7i/  1& 	A
(&">d
 $
 J
& KMfi$] * q^= $s
("H " f/p4>6"\
(  W1& L)H
1
 1& B 	
 1fiLW$ L 
;
(
 =$fi )
 ffBA
( :
 i
("K$ " ^ N/p4>6"76
  3=  $?
( ^G o  MI,fG ( G ? \$d
 & G ( 
 fi
 4 q,$
(4 LM1& $1& , fi$B
(T
G ? 
(1& :fi;  \; M d
 
< [/Gym/G ( G ? 6XYC6 S tN/[]< /G ( G ? XrGwmfC_6"EK;
;
< /G^XYC_6!_6 }
/6
W" j
 F;
( 
 qgWff\; :?AH
 fi?
 1^ 
< [/Gwm0/G ( iG ? 6XYC6 S ;
;
< [/GwmuG ( XYC6Jj;
< [/GymG ? XYC_6
/[,6
~$L;:[p!pc[(KZFBDH[pDK)YxcK9DH[pDK)Y[=D`   c[HpqY(`F@`3Yp
p;)!J[("Z[x[HHH$JD,LY [JZ!JD3!cHYH]H[pKp3Y9JLY[M3]pH
H`;KY;!][Kx3xKp)xH@K3YM[:
 (3[%H9KY(D`D :H`@LKp)H[
pHY9LL[_3ZpK*  ;HK[FDH)3KpY>M _?xxK[p"!qp!;3]Y_=Y%H;Y;L[
[@"MKJ)p4 Yp)D	]K TGff2ff\?`D  xHp	D`4 	,% M`c3MZYqH`9[p
p4 Yp)D	[(HW ~3(K(=[	LK;)p4 Yp!J[9"YB[%Y [


fi

o$s$!P"$$#@$~%PF!&


o$('*)$


fi

t/[<;[/G ( G ? XrGwmfC6"EK<;/G^XYC_6!6
S t/[<;`/G ( XrGymfC_6Lj<;[/G ? XrGymfC6"EK<]`/GAXYC6!6
 &1	*&\J,^M,\M_
(1  
	* (~\ &: S 1EH,\

/p4>6

<;/GymG"XYC_6 S t/[<;/GymG!XrGwmfC6"EK<]`/GAXYC6!6_}
F "j1&/6"\Z/[,6"\Z/p4>6"\J
 fi/@6"\$M:$


/@6

t/[<;[/GwmG ( XrGym0C_6"EK<;[/G+XYC_6!6qjt/[<;/GymG ? XrGymfC6"EK<]`/G+XYC_6!6
/[5,6
S t/[;< `/GymuG ( XrGwmiC_6J<]/GymiG ? XrGwmiC_6"EK<;/G+XYC6!6_}

(,} S ;< [/GmG ( XrGbm^C_6"\ S <]/GbmAG ? XrGmAC6"\
fiA S <;[/G+XYC_6i/[5,6"\Mq
J;$"$
(m
 >
" 
t/;}]2E A>6ct/p'2E A>6 S tN/;}I'2E A>_6 }
/6
8 1 )$
 9; 
("K /[
(  4 $q$
(! i?N "u$fi ,6 
 )
 $ " 
(m >$
" 
fiP
 &@
(Z/;}]E"'2E A>6  |
;
/
]
}
"
E
'

E
2
A>
6
s >E1  }9u"

-{
1
7)



)

&
1



1
P







)1
& $	  	B
S 
	
("7&K
 $\ K
(> } S ff n/6"\$ d 3=)
 $
 
t/[>2E A>6Ljt/p$2E A6 S t/p'2E A>6"E
& zd!+M:

 1

t /[>E2A>6 S }
N
| .\J#.A+
fifBY(/;}c6 S t/;}ZE2A>6"7:8t\J,f
("KN"J\$fi$&1q"?
((\N&1 /6M

	*J


 o /;}c6 S ? /pt/;}'2E A>6Z~nt/;}Z2E A>\6 $6 S ? t/p'2E A>\6 ! }


*



*

)>d	Bd$
=o /;}c6)W
AK
\Lfi$qfi$q)x}Z7W8_K
:A
fi$qfi
BA9
\ 1& ^ H
  ;$"bK! $
_ o /;}c6 S c/A>6"7BK| ;
(
fft/[>E2A>6 S >\
 	H
 qK
(&!u	
(	?)1B
 
Y/;}]6 S t/;}]E2A6 S c/A>6[}}
W"j:
(KK$" 
)&=
(CFEHGN\M
	*<;[/G^XYC_6 S 1C{ G\;:d

<]/G^XYC6 S <;[/GwmuG+XYC_6 S tN/[]< `/G+XrG mfC6"EK;
< /G^XYC_6!6 S t/1EK<;/G^XYC_6!6_}
)>\MJ
*


t/1E2A6 S c /A>6 S

A}

V _?fi$a
=tN/;}]E2A>6 S }A7
| ff1(\P	M*&\9
?"sfi$qfiMb
&K?
()
  A
("H" 

 $
 " 
(P 
" y/F
6 $fi
 &
(B/;}]E"'2E A>.
6 I7 5   ;
( \x
(]
;A	
s?fi$
1
&  /[5,6FM
 
 ) )fiM
 &9
(x/;}]E"'2E A>6@K! 
 M1& F. WC\'G\G ( \
 fiiG ? \B +G ( 
 fi
G ? fi;  \$H4 $
 9} S ;< [/GwmG ( XrGwmfC_6"\ S ;
< /GymG ? XrG mfC6"\'
 
fi A S ;
< [/G+XYC_6"7
	'[(KY[c`pY33@H
 F; 9`![K$[J(pH("(4 ("pY)K'x;D'H[;YY!c[
c;Y
 F
T

fi

o

 @K

#
 
 @d

 "&" ;
 K
 ""o# 9xfi$"ff;\DGFWNPL\KOW!S2X_/p")@ZK
"
&K
(s"&K
("_?N1fit 
fis $"  &1I&  4$q$
(!J\u1
fi "    ff" b1& 
"?N?
(&Hfio#~fij |$.N"J76RWIIHq"fi
	
(&" &\LW$ 
(
 ^
("HH)
 
 W;< [/G+XYC_M
6 K
( a
 f
(Z*
(?B r(E"_p\Jd
 1& ff S ;
< [/ T XYC6

 fi S ;< [/DCXYC_6"7q/;   ! q'
(4 Ja

 &Kff?
 " J\ S 
 fi S 176ffd
 1& _
(1& JM
 )

1ff 1&K1
& M)
("KN " J7x)
 BM
 	
(N 1&"1& K
 " u;
 
 @M
& 	
(4 +(
} s >E1p$\ 1& T. 
CFEHG H4 
 ;< [/G^XYC_6 S }]7u)
 I "& i 1&"1& K
 " b
 
 
& 	
(! Ca
 fi}]\ 1& 
.
 "WGK! 
 B;< [/G^XYC_6 S }]7 9)
 ff9 	
(&Bd
 ! + 1&"$1& K
 " i= 1qofi fi+W$ ;7
& $,*> KKN )
 1N1& 3* J
 T* &! "&"      "&K
( fiL\L
( i 
|  d
fi 91 	 ?
"a$
 = B  	
$
 1&  M1  fi0
("KN " J7
 u
 ^	
(1 (~\  $&)B' # $&  4 q,$
(! 1 :R


 fi 1I! K 
 :F>
" /]6 $fi
1
& sI7W/ | &W$fi WM
- 	|
. T
& =
 
(  a;$ " 
( >
" L\ &B$fi j_
&")
 
 & &  q
 fi 4 fi1& 1 qK
 " J
H
 )M
- 	.1& K\]H4
(_,
 /13225,6M
 fiZ&K$
/13252,6"76  3; * &\' ;K&M
 s;1IW1F "K
(&! 1I$fi 7  & 	* &\ %% 	
(@
& $
 % 
O ~#  1(\ $1& W
(& T~#  1H
 K % "_
 9
(1&     "&K
( fiL\$
 fiA )@
 ffMW	
(1 


 
( w7BM
 F $
(> F Ms. 1  " L\ u 1&!*
 " j
(1 &"   >q 

()
 ;
(&=
(=
( 1 M& =
(1& :  & fiL7
ukj,lnm0t

  


m

m u9

r

p m

ff

!u8v
t



j,lnm

mr

)M
(#=1"i1&	*
Pmx;l$

tNpl~p


KYNPOffbTOW^.



JS`Z

*






O

SL4SOhKW!D`NPOFW5JSZ
* KWORNS"XYFH.KOW
KWXk"L4SIS_DNPORQTSZabkD 
N  KN

/G^XYC_6qb >E1FL:CRS{
Q T

_h  t

KWXW!D`NPOFW


 /;}]E"$6 S }^wUF5N  KN=OkNPLGOD`NPZab$ORWDLMS2KOW^ORW0S2KYD




KYLYHkS`WNKWX5O,OWWORNS`Zzb

KLPHkSWN
OW

KLPHkSWN*OW+ >E1 ?
KWXNPLODNPZzbORW

tOD2FYHVHhNKNPOQS  t/;}]EK,6 S t/[>E!}c6 S

WFWX%S2D`L4S_KORW.OWS2KYD 

I/[>E1 ?%8
  KWXfft/;}ZE1(6 S t/1E!}]6 S } 
DLMS2KOW^ORWS2KYD 

FSQTSL







 tO8OWWORNS`ZzbVXO ;SL4SWNPOK%]ZS



+

KWX



 h)/;}c6 S 1B~}UFN  KNhO;NPLODNPZzbX%S_DLMS2KOW^KYWXORW`WONSZab"XO SL4SWNPOK%]`ZS4[
XYO S`LMS`WNPOK%]ZSM[



FL4S_FYQSL


NAJ >E1J  >E1KYNPOffbTOW^U4[

N  SL4SVOWFFW!S\NFMFW!ShFWNFWDNPOFW





>ff,I<; * \>h\>I\
fiItU
(&19
	
(F
(x1"&1:
(99N
(fi$I
(
Jff$&9*
(&"?
"d-M.J=&1H\da$_
("KN"@^
(&1MM	
(&$
 1N
(fi$
 $*
(&"?
 "	7$ 
& .
$ (#\ & 
 $1& 1& 	H
 qJ
 _ " >&_&1	
(K
&a

 qW;<  * :
u& $
( fi "&K$s" /[
( n
(&K_
 fiW$ ff1& 3* R
 \
$o
fi )
& &M
("H " \$i	
 K
( q1+K
 "1 0
( 1 ff1& 1& 	 q"6"7:d
 B &!* a
 1
N
( a$: $11& .
N :1: "& 7
|

ff1@ 9@

`

fi

(


o$s$!P"$$#@$~%PF!&


o$('*)$

 $&1j)$&1	 >71j"&H"*(7 M
)
- "fi$&0
fioN
( O =1"
E}}}E  (? 7V 
("1>?
1:=	
(4  0O 
I;
 J/  6"\J
(	=7
/ 
/ 
/ 

<
6 S 
/  < 6
S @ff13 <
/ 
? 6 S 
5 6 S 5I13
<
/ 
/ 6 S I13
6 S 5
3
( 3
/ 
/ 
0 6 S ff13
( * 6 S ff13
3
( 3
/ 
/ 
3 6 S ff13
(( 6 S 13
/ 
6- S ff13 3 /  (? 6 S 1	413 ( 3
$&
0K$1NC qO\x;+fi$#~$"/DC_6 SY /  6"7)>\;+	
fi$#^
f&1'
(
fi"&K$s"uF&@fO  K
(>@&3/DC_6 S /DC\6 T/Og6"7
#o=ffi$q"	
(T1
\ .   $
 o/  ( * 6 S /[^~6: 13 ( 3 
fio/  (( 6 S /ff
6_
13 ( 3 \=d&1(+$fi ~# fi  3:7W
( J\B;
 . 1q
fi  o 1bK$1" O ofi ~#  
o;/DC_6
Q T \$ofi ~# 
S Y o/  6"7 WOo |
S   ( * E  (( E  (? 7 @CRS{
o/GwmfC\
6 T/DC_6 xOUo {wC
<; * /GAXYC6 
S  /GymiC_\6 T/DC_6 ff&!B1 (7


(

<; * 	
(&"ff*&!ff1@1MF&7LCSw
Q T \$qff,	
(!1:1M
BX <; * /G^XYC_6~I@&3/GAXYC6X S
X  o /GymiC6Z~>/GymfC_6XT/DC6q-07@V :!1h7ff1H

F&/G^XYC6q7j@&3/G:o[XYCBo6"\$qi<] * /GAXYC6q7<; * /G:o[XYCWo6"7

/[,6

8a$:&K
J@&=)#~1(\'
(]KNq"uKN
(
K
"1/[,6"7
 $.
( +!  yq;  "
(	* 0 ffA$
(1& "	?
(&"?N &1K
7_J| 
+
)
? & K
 @@
 J 	=    "  
( " 
F&	/  ( X   ( E  ? (6 S F&/  ( * X   ( * E  (( (6 S Y @
F&	/   ( E  ? ,X   ( E  ? E   (6 S F&	/  <,X   <E  5 (6 S @,11
F&	/   < E  5 ,X   < E  5 E  / (6 S F&	/   0 E  3 ,X   0 E  3 E  - (6 S 11 ,132
/[2,6
F&	/  <X   <E  5 E  / (6 S F&/   ( * E  (( ,X   ( * E  (( E  (? (6 S @,132
F&	/  ( X   ( E  ? E   (6 S F&/  0 X   0 E  3 (6 S Y ,11 }
9)
 	
(! 1! K 
 d.
( " _K
H
 a
( " T
 $fi ;
 :& ?
( :@&=u;
<  * 7
V  	 
 B;<  * H
 "!o# 
 $:1& 1& 	H
 q"
 )
 & 	 >71,
I1 q J	AN
(7
 9#$&"  	AN
q, $9 j
)
 1_ $	= 
 
 F;
<  * 	
 offF)1  &"o M
 1
:1& '
( H
 ;$
" J7B M1)
 ;
( ff/p1& 	* fi f 	AN
>7Y,@
6 
 W @;
<  * M
 1&  H
 &"o J
 1+
1& '
( 
;$
 " J#\ qy1& ffM
 fi $
* H1i|

 $ " taK
 "1  M 
 _
("1 >?
 "* (7^W
L\
(x
 3d
 ff ff 	AN
=>7,\ @;$ " fft{K
 "1  MqW	
 ff;K
( qR1M% ~#  1
fi 1& q"?
(=
 fi 1& 	
(" M j	
(! N
(&"$Hq\ @
( " F +/[2,6KN M1:$
(&K
 1
 
 =	

 $$ff=aK
( q 1:
("1 >?
 "* (\ 
 =\M
 :$fi H$ff= u q&K
(# 
* 
t/;}ZE"t/p'E2A>6!6 S t/pt/;}]E"$6"E2A>6_}
fi$fiL\&1J+
("1>?
"*j$ " ftzK
 "+q,\N*q;fi&1&1&1	Hq"

=tMfi$&1q"?
(&91
& 	
(" 7


fi

]p=

Nx?v
{

Jlml2


fi $


FLJSZ

KX%SPW!S2XK%]_FQTS


^tKYNPOffbTOW^k

N  SL4SVOffWFKGF`DOKYNPORQTSWDNPOFYW



81T&1qM&1:H4
H$"utI7@& [/ 2,6"\$M:ff)
	*F

t/ @,11E11 ,132,6
<  * /   < E  5 ,X   < E  5 E  / (6!6
S t/[;<  * /  < X   < E  5 (6"EK;
<
;



/
X
E
E
(

6
<
<
 5  /
S
 
S @,132
* 
S

3=)$


fi $


*

o

S

t/[Y@,EG@,11(6
t/[;<  * /  ( X   ( E  ? (6"EK<; * /   ( E  ? , X 
<  * /  ( X   ( E  ? E   (6 S Y,11}
;


(

E  ? E   ( 6!6

t/[Y@,E"t/@,11E11>132,6K6 S t/[Y@,EG@,132,6

t /ptN/[Y@,EG@,11(6"E11>132>6 S tN/[Y,11E11,132,6_}

)>\tgM&1_
("1>?
"*(\;MMfi$
*
F

t/[Y@,EG@,132,6 S t/[Y,11E11,132,6_}
$Fff&d
fiL\&1
/[2,6%
(
( J\M
 :1 J

t/[Y@,EG@,132,6
<  * /   ( * E  (( ,X  
S t/[<; * /  ( * X   ( * E  (( (6"EK;
<
;



/
X
E
E
(

~ \6 ,132>E
S
*  ( *   ( *  ((  (? 6 S /[:

d

( *

E

((

E

(?

(6!6


t/[Y,11E11,132,6
S t/[;<  * /  0 X   0 E  3 (6"EK<; * /   0 E  3 ,X   0 E  3 E  - (6!6
S ;<  * /  0 X   0 E  3 E  - (6 S Y,132}
3=)$
=te	
$ffB:
(K1 ,?
 "* (7J
 f$fi$&"K
fi $	z 	NA
+>7u1& ?
 11&_fi"	""b8s"b|;N&	
=  !q'
(4Jx& `\M
 K
N/;}ZE"$2E A6LV

 D2FWNPL\KYORW!S2XVNPLGOI!ZS0 1& ]. 1 "FC ( 9 C ? 9
C  9 C < =bC  S
Q T H4y$
 M} S ;
<  * /DC < XYC  6"\] S ;
<  * /DC  XYC ? 6"\
 
fi A S ;
<  * /DC ? XYC ( 6"7
H	
(! 11  
 My
 &" t 1u
(" ,?
 "*   "&K
( $b
fi "&" 	\F"  i   S
<; * /DC  XYC ( 6%
 fi  o S ;<  * /DC <,XYC ? 6"\,uq,\M
 
	* tN/;}]E"t/p'2E A>6!6 S t/;}]E  6 S ;
<  * /DC <,XYC ( 6

 fi0t/pt/;}ZE"6"2E A>6 S t/  o 2E A>6 S ;<  * /DC < EC ( 6"7BW4+K
T

 
 d$1 ax  "&H
( 
fi "&" q
fi q M  >E1?7
$
V K??
(&"$fi ~# /;}ZE"
6 1u

 DGFWNPLMKOW!S_X$IKOL0 d1&  . N "+C ( 9 C ? 9 C 
= C ? S Q T K4i
 ff} S ;<  * /DC  XYC ? 6:
 fis S ;
<  * /DC ? XYC ( 6"7V +K
i
 
 u/DC ( EC ? EC  6
D2FYLGL4SIFWX 1 ff
  "&H
( fin$
(&I/;}ZE"6"7+/ | ff1H
 F1& A
fffH
 1& 
 y$R"&" 
1
 "= &K1& " fi R
 1A
I  "&K
( $fii$
(&76 /DC ( EC ? EC  6F &K1& " fiM
 1 :  "&H
( fi
$
(&I/;}ZE"6B
 fit K
 "!o# :M,N\ q0M
 ffF
* Nt/;}]E"$6 S ;
<  * /DC  XYC ( 6"7 | ff1j
 :ff
/[Y @,GE @,11(6
 fi / @,11E11 ,132,6
(1&  1 "&K
( fib$
(&"\
(  $H"&" i/[Y @,GE @,11E11 ,132>6
)
 ffB  "&K
( fic7 9)
 
 ;
( 
 9M
 _M u 	AN
ff>7,7
 $J. B 	NN
 3=
)
 $
 B;<  * 	
 $ff=M1  &"o T
 1A
ff$1& $
( ` ;$ " L7


fi

o$s$!P"$$#@$~%PF!&


o$('*)$

{N
 x . FLVJS`Z * KT.X%SPW!S2XK%]2FQS  N  SL4S"Off.WF(FW!S`NFMFW!S"FWNFW!D`NPOFWu >E1
 >E1KNPORbTORWU4[ 
 1 M&1=;&BK4^
J;$"$7@&"Mff1)$
@'/[<; * /DC6!6BS Q CRS{
Q T 7o&
Jlml2 8
]'/[;<  * /DC_6!6 S >$\ qu d 3=d
 1& /1(;
6 
 )&=
(Z
G {wC\M
 
	*
'/[;<  * /G6!6 S '/[;<  * /G+XYC_6!6F+/[]<  * /DC_6!6 S '/[;
<  * /G+XYC_6!6Fi S  }
]p=

)>\3'/[<; * /G6!6 S '/[<; * /DC6!6&Z
(K1"G 'C7x89$fi$#~"J<; * 
(&K
1


 B;<  * /G6=S Q <; * /DC6FGB
ff1"&"=K$1C\$9"&K
(fi")_
("H" $
%

  1 $(7)
 >\/[<] * /DC_6!6WS Q @CzS{
Q T 7)	_3=)&1 /1(6;
=@CRS{
Q T \oq
'/[<; * /G^XYC_6!6 S '/[<; * /GwmfC_6!6\3'/[<; * /DC_6!6_}
/13,6
| 	{fi$#~$=t/;}ZE"6 S   ( /'/;}c6c'/p$6!6"7V B$	 
Ft fi$#fiN F%
	AK
"!#~FM

fiB
("1>?
"*(7%d%=c* 9
I "&K
(fi"1N	AN
>7,7
 ff1T
)tgK
"!o# )M,o\ ff" a
 \,^
( 
 a1&!*
 "u
(	*M&1	
1fi\
GymfCRS{
Q T \$;: 
S

t/[<; * /G o XrGymiC6"EK<; * /G^XYC_6!6
 ( /!/'/[<; * /G:o[XrGwmfC_6!6^'/[<; * /G+XYC_6!6
  ( /!/'/[;<  * /G o mGwmiC_6!6\3/[<] * /GwmfC_6!6!6n/'/[<; * /GymfC_6!6\3/[<] * /DC_6!6!6!6
 ( /'/[;<  * /G:omGymfC_6!\6 3/[]<  * /DC_6!6!6
 ( /'/[;<  * /G:omG^XYC_6!6!6
<  * /G o miGAXYC_6 }
;

S
S
S

S
)>\teH
"!#o=M,7
 1 F$
 =teB
(K1,?
"*(\mff1F$


t/pt/;}ZE"6"E2A6 S   ( /'/  ( /'/;}c6%+'/p$6!6!6+'/A6!6
S  ( /'/;}]6+'/p$6F+/A>6!6
S   ( /'/;}]6+'/ ( /'/p$6+'/A6!6!6!6
S t/;}]E"tN/p$E2A>6!6_}
):*IFofi "1& fi "&K
(fi " i1f 	NA
+>7,7^	=
<; * 	
$ff
1 &"oT1N
I$&1$
( ` ;$ " L8
7 
a"1],;
(  
 ;<  * u ff]1  &"o , 1B
9$1& $
( `J
 $ " J\ ;$ " h\(tI\
fi
g	
i:fi$~# fi $
 BK
 "1 u_1\q,\J
 fiq>\'1& K  "* \L
 fii
( Jff&B1& 1& 	H
 q"
K
1fi f)
 1& 	>717M)
 
(&" qT&:hy
 fia
 	
(!]
( ;
 &"i q 1^$1& 	* 


 B
 i
(1& &K?
 1:t . "7
Nx+V S`LMSS_%OffNKWfORWqWORNS`ZzbXYO S`LMS`WNPOK%]ZS  NPLODNPZzbX%S2D`L4S_KORWWD`NPOFWh 
 >E1VD  N  KNJS`Z * / G+XYC_6 S h)/\S`Z * /G+XYC_6!6;FLKZZS`N^CEHG{ O EORN  C S Q T 
ShD2KYW(NKTSMh%/;}]6
 WVK%D`N
S 1=~} 

 F?AH
 fi?
 1@1& 
 $1&!*
 "  
 ;
<  * / G+XYC_6 S 1Z~+]<  * /G^XYC_u6 &9CFEHf
G {
Jlml2 )
O
7 

]p=

 >E1_

{

`

fi
Nxff.

]p=
OWS2KYD 

{

KYLYHkS`WN

o

ffg' >E1 ?   >E1  ORW!D`L4S_KORW^
D  N  KN*O )CFEHGEHG_o{
O  Gm_G:o SUT  KWXCzS{
Q T  N  SW,JSZ * /G_GMopXYC6 S

/G o EC6!6  WVK%D`N  ShD2KYW(NKTSMI/;}ZE"6 S }ff 

S`LMSS2YONJKWOWWONSZabXO S`LMS`WNPOK^]ZSWDNPOFYW


I/\JS`Z * /G+XYC_6"EJSZ *

 99?AHfi?
1F&1 $Mfi$#~" x<; * 78
)
)>\>
($
&1	N
(xP1_$	 $
F
N
($&1&"?
19t .1"7)9I1A@&	*fi$fi
, y 	= j 	AN
>\9T
 4  "1q"?
({3= 
 &1
s;Mfio#~fiwt 

&1	
(K 7
Jlml2

Q T KWXIG ? miG ( S{
Q T  N  SW
Nx J MC ? mfC ( S{
U4K[BO JS`Z /G
*
 XrG ? mNG ( 6-JS`Z * /DC  XYC ? mAC ( 6JKYWX.JS`Z * /G ? XrG ( 6-JS`Z * /DC
G ? XrG ( 6 -JSZ * /DC  miC ? XYC ( 6 
U_]M[=O 8JSZ /G
*
 XrG ? m:G ( 6@JSZ * /DC  XYC ? mC ( 6  JSZ * /G ? XrG ( 6q-JSZ * /DC ? XYC (
  KWX"JSZ * /DC ? XYC ( 67   N  SWJSZ * /G  mG ? XrG ( 6@JSZ * /DC  mfC ? XYC
U4D4[=O 8JSZ /G
*
 XrG ? m:G ( 6 -JSZ * /DC  XYC ? mC ( 6  JSZ * /G ? XrG ( 6FJSZ * /DC ? XYC (
  KWX"JSZ * /DC ? XYC ( 6 7   N  SWJSZ * /G  mG ? XrG ( 6@JSZ * /DC  mfC ? XYC

]p=

{



?

6
(

6
(

XYC ( 6 
6
6

N  SWS`Z

*

/G  m

JSZ

*

/DC  YX C ? mC ( 67

JSZ

*

/DC  YX C ? mC ( 67

&"1 1&"* 
0<; * /G  XrG ? m G ( 6- <; * /DC  XYC ? mwC ( 6+
fid<; * /G ? XrG ( 6<  * D/ C ? XYC ( 6"\q &1a/[,6"\>P	BP
F@&	/G  XrG ? mG ( 6q-@&/DC  XYC ? mC ( 6
fiF&/G ? XrG ( 6;
@&/DC ? YX C ( 6"7;M
*M&F&/G  XrG ? m9G ( 6@@&	/DC  XYC ? mBC ( 6m&@&/G ? XrG ( 6@F&	/DC ? XYC ( 6"\q
MR$
* j&MF&	/G  mfG ? XrG ( 6W@&/DC  mC ? XYC ( 6@&qF&	/DC  XYC ? mC ( 6 S  &MF&/DC ? XYC ( 6 S >7
  3= 
   $&A<; * /G  mbG ? XrG ( 6u <; * /DC  mjC ? XYC ( 6+/'Ai/[,6ff
(
(J6R& 

<  * /G  muG ? XrG ( 6 S ;<  * /DC  miC ? XYC ( 6 S >7@   $&=	
(1 (~\ M	NA
$fi7
;
 >\M i& 	N
(  1 $fi 	
(M=  $n	
(1  $
 i@&	/G  XrG ? mG ( 6 S @&/DC  XYC ? m C ( 6^
fi
)
@&/G ? XrG ( 6 S @&/DC ? XYC ( 6"\@
 fi q ^@&/G  mnG ? XrG ( 6 S F&	/DC  msC ? XYC ( 6"70d
 Aofi K
(
 

 
("B
(& : )1j:
( qfi.J

7 
Jlml2

]p=

Nx 
=
{



 S2FLMS`H  UMEORN 

0t x >E1 ? 

SL4S,S2YONKWDNPOFW
L4SIS_D`N8NFJSZ

*

 >E1JKNPORbTORW^(KZZnN 

S,KGHJI!NPOFW,FM

[ 

a#~I
^$
(&"?
(u;$"0t o  >E1 ? d$1fffi$N
(
"1"FF
(x"&H
(fi
$
(&"	7zo&f
  "&H
( fiU$
(&\qM
 fi$#~tMoq no>$f)
{&1&1fi 1K
"1yM,7

I!LOFLGO\Bt:o=N

$ff^uM
 Bofi ~# fiLq A+ ""|
 $&1. "&"0/DC ( EC ? EC  6

fi{/G ( EHG ? EHG  J
6 
 Iff &"1& " fi 1j/;}]E"$6N/p;7 (7\} S ;
<  * /DC  XYC ? 6 S ;
<  * /G  XrG ? 6
fi
 S ;<  * /DC ? XYC ( 6 S ;<  * /G ? XrG ( 6!6@K! 
 =;
<  * /DC  XYC ( 6BS Q ;
<  * /G  XrG ( 6"7x %M
 1& F$M	
(1 (\
qIt o /;}ZE"6]M
 fi $ff%M
 $fi # fiL7  3;
 * &\ 	AN
W>7Y5MK
	>P 
 ,	
 offP
( qJ7
  i\$
 fiu "&" "+ 1& 	
(" 
(= 
 1& 	* &\ 	AN
>7Y5
("K&9M
 9tMoJ) 1& 	
(" j

(J
  F "
(&"Hq"M
 ff>7I ofi fiL\] ]1& I_
 "&K u/DC ( EC ? EC  6= &"1& K fi  1
/;}]E"$6FK4 
    ( * E  (( E  (? N{w
Q C ( o\ q+M
 _ff
* _t o /;}]E"$6 S }''7
 $u$fi N
( 
)
BtMo)I
#  1(7j  Ao u AK
 "*  K&1  f\F1 y$
  No
 "1 "j

  
 fi
()'
(&"+/p$E!}]6_K4 $
 +/;}ZE"6_I  f>
7 xs. 1qfit o 1
f AffsK
 "* 
;$
 " ^tMo ~o  Ao',N$fi ~#  t:o o;/p'E!}c6 S tMo/;}ZE"6 F/;}]E"$q6  f7tMo o'%M
 ofi ~# fi+	
1(\

(_	
  	
("nff* &"o# fiL\ q/;}]E"$6q
 fi/p'E!}c6q
(1& Nff  f#\ $H} &0ff:+1\x
 fi
Jlml2









	




ff

fi





 



fi

o$s$!P"$$#@$~%PF!&


o$('*)$

tMo;/;}]E1(6 S tMop/1E!}c6 S }Z7-%	
(&"tMo oFIAffsK
"*(7sI
(1&1	
(K7bo&IK1
/;}]E"$6"E	/;}$opE",o6 Ao\L}B-}$o\]
fi$-,o7:@ffb/;}]E"$6B
fi/;}$o;E",o6B
(& f\J;ff1a
	*
t o o /;}]E"$J
6 -Ut o o /;} o E" o 6"\cKfft o M&1	
(K78?N?
(&"\L@ffb/p$E!}]69
fib/p o E!} o 6=
(&1ff f\
M_ff)
	* _tMo op/;}]E"$6 S tMo/p'E!}c
6 -tMop/p,oE!}'o6 S tMo op/;}$oE",o6"7 
(\ %/;}ZE"6)
fin/p,oE!}'o6)
(&1
  f\]
+
 "&K
( 1&!)
(&"fin! K
 	* &
(x ""R 	H
 q"M 
 	=a
4
 $
 FM	
  
( q
i ,"&K ff/DC ( EC ? EC 69
 
 fis/G ( EHG ? EHG  6% &K1& " fi  1/;}]E"$69
 fis/p,oE!}'o6)
(1& K!


    ( * E  (( E  (? A
 $ff
uK$1M &IC ( &G ( 7A  	=
 
 tMo/;}ZE"6 S }'
 fi
t o /p o E!} o 6 S } o  o \1 A
(
( iM
 _ )$
 Bt o o = 1& 	
(" 7) "??
(&W
(&" q=4 	=)
 
 =t o o
9 "&K " 1& 	
(" A
(9 N
(d
 J "B
(&" q"=)
 ffB>7
 
 "&K
( 1&!%
(&Ki
fi 1ys. 1qfibtMo ,o 10
f NffsK
 "* (\ ~#  1nfi 1& q"?
((\F
 fib >
1& 	
(" )
 ;$ " :t $fi ~# 
fi _
( c >E1 ? \(d
 4 M "&" ": & 	
(" 
 N/[>E1 ? \
 fi:K
 "!~# 
t/;}ZE1(6 S t/1E!}]6 S }
 fi0tN/;}]EK,6 S t/[>E!}c6 S >7MV I1& > fi
(F
  	B7:V #$&" as. 1qfi
?
t o o 1 T
  $fi ~# $
fi &
($
(&")/;}ZE"
6  >E1 K!
 x
} g_1 a
  P$
(u )1& 1& fi
1&  & " 	7 }jd$\cM
 Rq$fi # ff1  
 _t/;}ZE"6 S tN/p$E!}]6"78  ItMo oM AffsK
 "* (\
A$
fi ~#  " 
(& N= tMo o;/;}ZE"
6 &I}e '7y-% 	
(&"jt A NffsK
 "* i
 fi ~#  1
fi 1& q"?
((7W ^1 
 WtRq 1& 	
(" \JH 1 F
 W>
} -y} o 
 fif
 -{ o 7W,W
(q 
	
(1 TctMo o\> %%?NH
 fi$?
 1@
 %t% 1& 	
(K  LffN
} g
 fiN}'o g,$o &%ffI}fN
 fi
} o   od
7 a&!=1 (\K 1 q
} gyu
 fii o g } o 7))
 q;
 
* 
 - $
} -y} o -y o 798  _tR
 1
& 	
(K d
   /;}ZE"6(
} g! \(; @
	* %t/;}]E"$q6 -t/;}'o;E"q6 -jtN/;}$o;E!}$o6 -t/p,o;E!}$o6 S t/;}'o;E"o6"7
K??
(&x
(&" q 3=u 
 xt{ "&" "ff 1& 	
(" M$ "u % "@
(&" q"x>7x $
(\
t  	
(&"+K
 "!o# )M,\"  ff/pA  "&K" J6@t o $fi \
 fi+q_$s"% 1 "&K
( "@
   
fi A
(  t:o8
$
7 
 $1& 	a>7
)
1 $	  	=T
 1& z 	AN
(9>7Y>\>74\>z7 @,\
 fii>7,7










,kj,lnm0t

  


m

m u9

r

p m

ffJ m v 

j"lm

N

mr

1&111fisnd
N	
(,DGFHJIKLMKNPORQTSDGFWXONPOFWKZI!LMF%]_K%]`ORZaONPb7d,	\]&K
&


("1 >?
 " 0
u1& 	
(P >&q=  	
(4 " fi " $
(P  "0G^XYCu\ $s":
  &"$fi &" 5
 c 
K! "	7qWMK
(;\]G^XYC G o XYC o T
 K
( q1+
 
(&*>?
 " y&:GAXYC cG o XYC o 
 fi
ff	/G_o[XYCB
o c G^XYC_6"7
 ffM 11&  1fin 0d
 $qiK4
 y&"$fi &K AM fi$fi0
+1& 	
([*(
(?$fi ]o " 
= & 	
(1 
(A1&  & " 7  K
	>
 
 
1& 	
([*(
(?$i
fi ;$ " 5 nK!  ",
 KL4S2S
EON 
c /G^XYC_
6 g/G o XYC o 6B G^XYC cG o XYC o 7^  qn K$fi &"

 ,F
& )
. N


 ;c{ FK
 "1 7@$ M
& &$&K  \ qH
 1 F1&  *
 )
(1& Td% $B$fi q$ff1 _-9-W1\
:-9-=,\ :-9:
- @,\$
 fi :-9-9,7
:-=-W1%!9K

 $
 cU=
I $	
()
& &"$fi &	












fi

l~x G+XYC|cyGMoXYCBo&WG:o[XYCBoc G^XYC7

:-=-9K
$
cU@"&K
""*(


G  YX C  \qiG ( XYC ( c G  XYC  7
:-=-:@B
R1!$	
(fi"i**  $ff"d &"fi$&)1(7)$M&1*(
qfi$#~
"_
(&H1fi $&1u/p1/p(\F132(,T
6 &:$fi K
(6"\" :-=-:@,\Z
(:H$1&!*\#$fi
*
(	"u+#~1Mfi$N
(M/'$J 
  11&  d& 6"7
fi

vmx G ( XYC

(

yG ? XYC
c

?


fifG ? XYC

?

c







fi

mx

fi

o

)$M1  G+XYC$
(=
I$K
(:$
(K=

&Kfi$&@1(fi$fiu, M7

F


(\ :-9-9"q"?
(K
	>)
cUB&1	
("\$




M1q1J	NA
ff>7Y5>7



x

fi

[/ 
,6NxG  XrG ? muG ( c{C  XYC ? miC ( 
fifG ? XrG ( cwC ? XYC ( qfG  muG ? XrG ( c{C  miC ? XYC ( 7
/pJ6xG  XrG ? muG ( c{C ? XYC ( 
fiiG ? XrG ( cwC  XYC ? mfC ( qfG  muG ? XrG ( c{C  miC ? XYC ( 7
/p6N G  XrG ? mG ( {C  XYC ? mfC ( \G ? XrG ( cUC ? XYC ( \J
fifG ? XrG ( T XrO\$q0G  mfG ? XrG (
C  mfC ? XYC ( 7
F$qu?
(?@$J3= &1	u
- 
(1&Z"\)&	d,6  cKNPORS
n

p n  tplp /p (\132(>\@


S`WN  SL4SVS_YONJFHkSKL4S2S`ORW^:W!D`NPOFWk   SL4SVS_YONKW!D`NPOFWt
FM;NPnFkQKLGOK%]`ZSJD





N 



#"%$$

!

"%$$



"%$$'&




N  KN

N/GymiG o XYC_6 S t/P/G o XrGwmfC6"E_/G+XYC_6!6  /
tN/;}]E"$6 S t/p'E!}c6 
tN/;}]E"$
6 OORW!D`L4S_KORW^ORW^}FYL9"70/ T XrOe6 

 
 



 

(
& 
) 

O |c

tN/;}]E"t/p'E2A>6!6 S 
t /pt/;}ZE"6"E2A>6 
tNP/ /OzXYC_6"E"$6 S  
tNP/ / T XYC_6"E"$6 S / T XYC_6 
KZF"KYNPOffS*"%$$,+ 

 $T^1&  *
 =?
1
)
 
& &)'&" 1 %
(1& _-%?
1I/1(6"\$d
 4 !1%M,\'
 fii-)?
1
p/ 4>6"\d!+K
M
)tg9
("1>?
"*(7%B%	AN
>7	B\s&1q@I
("1>?
"*Jo"
K
"1MR&B<] * 7FB)@33:\$= 	
M
=()&1	fio)$ff=>1Jfi
 &7
< 1& $fi  u \Z  $&"  
;
 14 
uK" IKKff1& 
(&"fi  I$fi A
( yJcM7I 

 o11& .
$ HP$1& * :1  " L\;
<  * /G^XYC_6B$fi ~# fin
( i
(C Sz
Q T 7N 
fi H
$
 ffN
("K$H 
 j5c1& ?
 " H
  "K
(&"j$fi # fi 
(@
  "AGAXYCK! 
 
CFEHG {dO 
 fibC Sg
Q T 7  I
("K T
 
 a1& ff:
 
( &K
 @K1"a
 O '/ 
 :\]

 )K$1"9 1 fi0$$fi &%~#  1M 1&"  " W
 fiu  	 qK
 " 6%
 fii
IK1 Io 
1
 1 fiu$ofi &~#  1W 1&"1  " 9
 fi ff% K
(  
 d	N  K4 
 cy%$fi ~# fi 
 fi " $
(  "9G^XYCK4 
 9

G  z
 fii|
C  Io7F8   Io$F  fi+o$fi &@ 1&"1  " 

 finofi 

 ff K
(  $H	 `1 \ o 	
 $$ff_ K
( bfip  _1 "7^ )O ~#  1(#\ q
a)
+

   "  Io'	
 u  ()1& 1 "&" " u% m1& q%1  T$	 `N1 BC *
K! 
 B
(  	H
 q"=  IoL K
( nC * 7@d
 91&  "&K " 9 	
(&" 1 "& j
 1j. 1q


 I '
(&K
 "* + fi " 
()& $
( bff 1qofi i
fi 1 q$&K
( u1& $
($ 7n )@&ff

1& '
( H
 ;$ " J\ qA F & K
( AN
( 1 q1 )1 N$
(1& 9F&	/G^XYC_6
 fiNF&	/GMo[XYCBou6 * q
3 Yp;)Z[("
  : r
 > )  fi   p@Z"FpH[p_[HpH)ZpF
DH([(BL[:!Y  L[pDq
.-

/

0/

/

fi/

2/

fi/

*/

!3

4

65

75 4

 


/

1/

fio$s$!P"$$#@$~%PF!&





o$('*)$

)Cz
fibCBo
(&1Ifi;M1"	7i &K*(
1IAo	
"J\x1322Y@@K1fi 
M_
)1P
& 1:  "&K
(  :-9-9W1 
 M
 =$fi ff@ fi "  H* q"=C 
 %
(&1)*
(q]1
 $1& ffCg)
 *(
( qT1 T   T cUCg
 fiC c T 6"7=8  F * qa>*(
( q)1 T  
T /;d

 $1& .
N u$_1& * W1  " 0 T  "1  `\ W 	
 
 $
 ) $11& .
N 
	
 uq1fi+= %! 
  (7)
 )%d
 
 )9ofi q  M1& c 	:7@F 3U 	 3D
 1
 >fi  M o11& .
$ :1 j
 9 BK
 "!o# B $()
H
 &" 
(Z1&  "&" " 7
fi

;l

tNpl~p


D 

+Nx  SL4SS_%OffN,KWFLMX%SLOW^5cKNPORbTORW8"%$$n

N  KYNFLSQTSLb;WDNPOFYWKL4S2S`ORWEON 

QKYLGOK%]ZSD 

c





"%$$



"%$$'&



KWX8"%$$,+

ftdF4kNPnF



N  SL4S,O.W!FKGF`DOKYNPORQTSJWDNPOFW

/GwmG:o6XYC6 S t/PN/G:oXrGymfC_6"E_N/GuXYC_6!6 

N  KN*

 NO 
 fi;<  * ^
(ff ^$1&1.
N+iA$&1*>"J7a#~(c

Jlml2
1 
^<; * 
(&N= cM7{)>\9GAXYC c G:o[XYCBo9<; * /G+XYC_6g <] * /GMoXYCBo6"7-%	
(&"
cK
"!#~ :-9-q1u
fi
:-9-9,7jWI%
(AHq"fiw	
(&"&\%"fO I#~1(\Jc*
(	"
K
 "!~#  :-=:
- @,7x 	NA
M>7Y5_4	=P
;cK
"!#~F$
(&1"B/[
,6
fii/p69 :-9-=,7 4	 

c

( _K
 "!~# F$
(1& =/pJ6  :-=-9,\M
 Bff$1& 	* )
 F L;
<  * /G  XrG ? mG ( 6g<; * /DC ? XYC ( 6x
fi
<  * /G ? XrG ( 
;
6 gg;<  * /DC  XYC ? mC ( 6"\ qn;
<  * /G  m0G ? XrG ( 
6 ge;
<  * /DC  mnC ? XYC ( 6"7Ad
 I1& ]

(?H
  ofi q"	
(o 1J
 P 	AN
q>7Y5>>;
 9K?
 .! 
  $)1&  P J@&/G ? XrG ( 6
 fi
@&/G  XrG ? mqG ( 6c 
 $1& `7Z 	
* )%$fi K
(9 1a%1& 	
(ofi &7x 	NA
=>7q4 	=u $
  $1& )
_
(K1
 ,?
 "* a;$ " NtK
 "1  _Ma
 &F;
<  * 7xBo 
 @)
(F1fiN R$=1& '%
(] ;
( 


 :;<  * K
 "!o# y
fi $ $>
( " 
 =/[2,6"7<%sa 
( " _ff1afi &M
 
 o " 

(1&  := cM7)
 ,\ .
( "R
 )H
H
 %1&  3=u 
  {@
 
 ;$ " I
(1&  := 
cM
\ qa& # B
("1 >?
 "* ;;$ " :tK
 "1  
 /GffmFG o XYC_6 S tP/ /G o XrGImC_6"_E N/G^XYC6!6"7
*

9

,

2

:



% ?fi$J91  " i+&"  ^" "4  3\M$1&1.
_	
u:H>fi#ofi+1

 IK
"!#~I$(H&"
()&11"&""J7  fi$#~O 
(fifiyuH& 	 q  * 7
 fio#~;f
fio$
:/  * 6 S o;/  * 6 S 13^ 5 +
(fifi"L\&fi$#~;i
fioo   \  / \

 fi  (? \ N
(@
 1Nofi 1& 	
(1 F&9;
  B,f13  5 \MMT  * 7)>\
 - \$
.-

 

5 ~j13^ 5 \
 /   6 S o/   6 S :
 13 < ~j31 
 /  / 6 S  o /  / 6 S 


5

\

~ 13^ 5 '\ 
fi
  /  - 6 S  o/  - 6 S 13 3 j
  / 

(?

6 S


o/

(?

6 S 1	413

( 3

~j13


5

7


(\'&fi$#~_Oo1   * E  ( * E  (( E  (? 7@)Mfi$#" <] *  1&K@E\o\'
fi
Oo1& 	N
( m K
H
 (7ZVy 1F&1fi$#~"\F$&1s$@&1*1")&1
"1
 q"?
($! 
  fiL7 $
(1& "	?
(&\ M
( " @ ^/[2,#6 3 fiff M
 %
(fi$fi  * 1F* &!1 7
 Io " ]c
('K", cO  K
(    * 7 | ff" )
  Io 1 fi+$$fi &x 1&"1  " 

 finofi 

 ff_ K
(   	 ` 7A)
 N?
(K )
("1 >?
 "*> `s # 	NA
u>7+	
 i$	
fi$	  "&K
 1fi^A fi "  
 ^1 "%  ffo7W%
 1 q (\M
 W )
 $11& .
 d1
 (
 $1& 	 * qd
 q+1&  "&K " H
 1 fi " 
(N  "
 $
 =K
 "1 |
 91&  "&K " J7
;/

;/

/

 C

fi

<#>=

o

ffPffff 

HffKAN
(&"IK
K@*
(&"_&1K":
$
( &

IP$I$1&.
NH]



- .J&	 
(&"
(nK
1fibfi$ff$fi#1fi$A
(7  &1	*&	\,*q
 @
 f#~1_fi$A
(\$$1&1.

fi$_fi"	""8s"IHT

 1& 9
("K$ " 
(& )1& >1& H
fi & "@ &"&  "7x I$
(& "	?
(&\ )?
(? H@1& 
$

 =t=
(K1 ,?
 "* $fi )
 ff) 	_7
 W 0$1&1.
Ni*q &i ff+
$1&1.
N|1bW$ ;|
& 	uo\ =
(KK$")fi$ ffB1	a"&jq|1
(&K
1J
dF;$"fe


(K1 ,?
 "* (\c
()
 $M?
(?=B7
 d9*
(&"?
"]]-M	.;&	K
1fi+,  H&KN
0/132,6"\  &!*>"(\  K&KA
J\
fi

  ff"N/1325,6"\L
 fiW ?$
(/132,6)
(]K	 1j_$1&.
N(7
 d?
(? 
H$"jt ff
(",?
"*( &1	 N&K&17
 H$
(:


(_&KI/p(\@132(>\x-@
(1&q"\J)&1	4>6)&_$fi"
(
 N$
(&K
 "* ff1& '
(  * *> +
 ;$ " fR
(W iW$ ;F

 1& 	7=)
 d
 o " 
1?
(? fi 1B
("
 ,?
 "* (\'
 fiA
(
( J\ $fi ;
 $ffF1 	 1 3e/[
( +
 o11& .
$ :$fi )

 ffB
($ 1j$
 1& 	u6"7
aB
 &"1 (]\ + 1&  " n " w3 ffd
 
 I IM
 fi K
(  1&13*&^-M	.H
&1	7x
(&"q
("K$"uW4NHN\J
(=fi$"&1&q
("K$" 9$
1s/p1
$ffff1I4>6"7BWB; R
* R&!* fiL\JB4 &K d
 $_$fi A
( ;
< # 1^:#~1(\L
(Wfiod

("K$ " i
 j+&K
   B;< 9
(@
 I >E1p7bV u	
 
(%
	> . 1qfi
ofi N
( i1n
 
~#  1Hy $fi fiL\$ $K
(Hy$fi A
( 
("K$  
 MM
  
	* N
  ~#  1I   " i
$fi  qofi qa
(&M  \Z
 
fi 
 MM
 I	
 K
(0
(sFs"  F
 @  y1K1 _
(qM
 
(F
 
&" 
( 
* q"W $fi N
( J7M/p)
 
  q1 s. 1qfi `>u
("H " i)
 ;
(&"i K
 fi$
(&"fiL
@
& .
N (\ 99N
($fi q,+8
	*(
( /13Y2 @4>6 +>1:
fi 1& q9 1s. 76 +K!u
  . 1q$fi fi
fi$A
( J\ 1 	1& 	
(1 
($ 1
(1 f
(KKHH
 ff;
< F*(
(&K $ &KN0`;
 qb/p 1& K
( 
;
(1
 q,fiJ6)
 fi1^/p & K
( "&Ks6"7% ZM
 
( A
("K$H:W4i/ &W1 H
   _ 6"\M
 _	
 q
&1 3* &AM
- .Jj
 & 	u7 | ff" (;\ 3;
 * &;
\ 
 R* =  IfiK
( 3=Ny

 ff"  B 


 K
( T
  +~#  1+A
 +&K
(fi$
 " 	7
 ff&9 "K +@
a
 1H&!* a
 9M
 :
(1& Jff9 11&  1fif !@M$fi N
( + + ?

" J7  

 &\T
 
 M
 B
(1& B 11& 1 1fiA NF

 $ff"  J L]< ~ 
 F
($ o &H
 1
(
fi A
( 7_)
$
 >N\ * qn =/DCFEHG6=
 fij/DC o EHG o 6=
(1& I$
(&"F
 FK1"F
 Ffi 1& q/p & $
(a
 * q
fi;  6)ofi N
( \ @;< [/G+XYC_69
 fi]< /G:o[XYCBo69
(1& ff1 ,m\ qfM
 _M
 y
fi .  TT
 1
fi qff1K
H
$
 _1& ?
 "* I "1& qff  `7= |W1 " \c
 
 
( RxW4A 	qH
 1& 
& 	
(1 $
((7N)
1
 
 :	\]M
 	
 
("HH
 J&_
(F(
 -/@2E 14E 3e-R1N
 =
fi 6V7e>#\ 1& I1 H
 
fi A
( 0O 
 fiK1"C ( \C ? \C  \]
 fisC < FO H4
 aff ?K y@W4 $fi7q 
$
Md;&&
("K 
 ;To " tI\I\
 fi+hb
(1& q
(1 ff$ &K
(& "%$fi N
( B'/ 
 )\


 :1\]M,\
 fiq fi a
& ffK
H
 ff4 $ HFt\ff\]
 fihy y* &"0$fi A
( 6"m\ q0M
 
0
	
 i
(
( i1&  	* &MM
- 	.)
 1& 	u7

	'JLHYLLHcYp9;p!B	 KDH;q ;HK[`)"pH,M_?


@?

 

fi

o$s$!P"$$#@$~%PF!&


o$('*)$

 $M$fi 	H
)

 u
* ^H

 ff" |x$ & K
( ` 
 B
($ B$ &KNN i
(cofi N
( 9 	
?$ff1H%fi"	""ff
F,
&1q@ff&1'
(&!+/13225,6"7,

,	F
(?H
 1 ].?"*  N~#  19ofi N
( 7 3 W;
 =K
_! $&"  (s\ * &!1& $	ff
K
(& = sK!n~#  1N1 ff1& $
($ " ] s. 1q" 
 10 ~#  1A1 "ff &KN 1fi d
 q
W)
 $_1& Kd
IM
 $fi ~# $fi0
 fii;
 q
	* fi? " A1& > "d
 1&  
I~#  11 7 
N
( 1 q1 9W? " N1& > "\J q1 	d
 
 M
 Mff=
("KN j
 
 TK
H
 
ff"  $
 & K
( u
( ) +
(L$fi A
( 7  & 	* &o\ $W	
 uA
( M
(&"Hq")
( 	
( 
1
 " > 
 d
 q; W "$fi &%K4A? " 1& > "1 \M
 B	
 ^
(%
	>%# fiNK1"=C ( \
C ? \C  \L
 fiC <  H
 KN q"f&"! /p$sW~#  1
6 s. 1q" y,$&K 
(x$fi N
( fK!


 =W4 fi$7
V  RM1 	NM I & 
(d
D
 H
 1 W1& 	
( 
(
(fifi " $
(
("KN " q1& 1& 
fi 1
 ff@

- .J:1& K\ _$fi :1& 1& J1 "$fi &N
 0$fi A
( :
  (7  1& 3* &\x _$fi 
ffI
( 	

 ff"  ) @
 j
(

 n~#  1sA
 &K
(fi'
 " \@ I
( u

 $ff" i
 $

 B
( 	=W1  F* q"d
 1q "$fi 1& fif  '
(&K
(M u  >fiL7
8 1 ff; A1& 	
(
(1& A 11& 1 1fis  N$
(1& "	?
(&:~#  1N$fi A
( J\
 fin;
 A$fi ff%
 
1
. 1qfi R&ff "$fi &ff
(M
 ff&ff K"Nofi N
( 7iV 
 I
("K$ " $fi f;
  q fi
1
 MM
- .J)
 $1& 	"
 ?i)
 : o11& .
$ :* q& : fiiM&"	$_* q1fii,+1& >&" 


 t=
("1 >?
 "* aN
(o K =/p&H
 ,& 
 M!Pj$9  "&K
( $fi "&"$ 6"7  3;
 * &	\ 
M:1& 	
(
(1& M 11&  1fii i
ff"  :$fi A
( Js\ _ ff"*(
 "  &=A
(, I& >& 	H
 q"@
  
q
* P
& Jt  *(
(?] 
 @ofi ffF
(&" =] $ff@1 : 	
(&7  1& 3* &\ F] 
(,& 1&  	
(&


 %
("KN F
 
 t%
("1 >?
 "* MKN ] 1_$1& 	* d$1& 	u7x$ M
& .
 (\M
- .J%1& 
N
( ))L*
(&" ;o " 
( >
" ) * * fftg
 fi+h%\
 
(  M1T
" /6


 I
( 	
(&"_ s8  " j,7fd
 1  ;$ " $
(P 
" I
(1&  	
("1 q 1$i
fi & 1& K
( 
K 	7  	M
 * &\
(; ^K
	z js8  " j,9\ ^1& )1& 	
(& >& 
 
 i
 $i
fi ,
& KYZRZ
K 	7@
("KN F
 
 %t 
(" ,?
 "* M$fi M
 ff%
($ 	
(P& 1ffKN )1
(&H
 1T
 ;
;$
 " 
( 
" % * * Nh fi &%
( K$ 7$&$&%
(KK$ " F
( 	
(@
&  "H
(&!7
 
(u (  K&fi 
    3= j fi$ " J\
| &u&" fi$A
 g &"*
 1 Nff$	
 " J
d! uK
	>)
 
 )"1 q"?
(i
(] =
(1& :fi$ "  \$KN 
GN\ T CWo G_o\$
 fin/DCEHGI6WS Q /DCBoEHG_o6"$\ $q;
< [/DCIXrG6BS Q ;
< [/DCWopXrG_o6"7
   T C

* qs M fi " bKA u\ $ff1 
  $1& ?fi$u\ 
& .
 (\x
0$ &K 1& '
( 
fi "&K$s" J\$
 |
fi ,B
(
( 1 	N=$fi$N1&  "&" "* (7
 ff&) ""$A 11&  " I F1& 1 	
(&K4 uM
a
 
 Z4 
(&H
( 1&" H
 $T;$ " M
 
 
K
 "1 bM
- 	.I
("H " 7B
  .
N ^* q $1& N $	=9\ $N?
("j
 )K4i$ " 
 ?fio;
 ;$ " ] $
 )
(& a$ff% H
 &"o 
 1I
 ^1& $
($  ;$ " L7x@   K&1T
 ) 
;
(
 B = ?fi$
  ;$ " @
 $
 B
(1& _ 1 H
 M1 q1 u" 1  1Nj

 ;$ " u H
 &"o a
 1A

1& '
( ^fi "&"$" J\
( $^ %@
 ff% 	
(@
& .
( " 3z" 1  fiA=ofi ~# fi0/ &
3 1
&  " H
 9?
("W1& 	
(u9 u&K
( " 6"7
8 d
s
 
 ^$fi ^
()
 AK
	1& 
(&"fi$  01M1& $
( ` ? | ff+ff!J7{B $

	
* |"&" w
fi 1s
(&"&  
 ^M
- 	.:!"#$	
 " bW1& '
( j $ff>1f
(N "1& 
(
3'[(K 3!pYpHM[=pHpY(D>K;DD3!>HK[!:!H;Y[p@p;p"Y
3pDxDJ=[J
3$[ppH 3!$;4
 G3Z(	Yx3%Y[(">"Yc3K(YHKY,$DY),K(c(K;p"Y	
[3p!:"ppD99!_9Wp;H3="Y[Dp(KpY%[B[[3pYKpH3Y_[D; ZY (;Y!39HffK(_
;4 G4 G34 G](!@p!Dp:3DYM;([%[;:K(M;"c:[("Zp"3!9(;`(Z
[Y	Y%HH]3DK]p!;HY9K(WDYDpY
C

BA

A

>A

A

D?

E?

GF

 

63

fi

o

1& * "s * fic\F
 fi +
("KN"ff$fi$&"N*
(&"?
"H9Hfi?
(&"#$	
"L\
 
 ffJ"&">|1K
_&$
($fin
($
fi$$fiL7N)&
(&1NN
yff&
M
""#$	
"d&="B1(7


IH  !Jp

 K
m 6

rem~



fi|1 
j
$NW$ ;\Wu1&+-@$1	N
J\% &"&!$(\  '
(J\ | &A&"fi$A
J\
M
*fi  K&KA
J\@&K  &!*"(\-@&K1o&  $\'0x
(&"	\$
fi M
 )&1&1
&+1=
 N q"  f'
(&	7fiy
(11 
,fi$	
nu	
(&"a&+" s
 1^ 
 fi
 qW$ , &W  "  sM$
(?A
( (M$
( &7W)
 B;&"
 ! q,$
(4 J:; &"|
)
(F?
(&" 	
(&K&" fi sFd
  ))
(
 ])!<  B?A
($fi q   	
(&"4 +M
- q1&7x<  @K & 
&K
 1;_
(Ks 3= fi fiL7x)
 M
 &"W)
(Z
(1 BK & 1fiM M'
(& ],T$ | 8F\$$fi &L&K
 "c  `
2 @3`>132u
 fii  `25D @(2>1\]
 
Y
fi :W&Bo &" RqN J@8 q"#$  1 	
(&"! /pW8-B6"\o$fi &
&K
 x2(45(`25"1`>7{ & ? 
(&!* &"" wd$
( &I
( 	
(&"I  :L\F`D  KNPOFWKZ
EFW`SL4SW!DGShFW;LNPO qD`OKZ  WNS`ZRZaO^SWDSUPJ 
[
IYI  T^T T^
7

ML

$



P Q )

8m~

Pu_

ho

 wJ
w#S

mrr



IR

ON

Q

uT

 	
(

(
&1	N
(]J@&1#	NN
)>7Y5=1Bfi$	
(BFF	
(1,
@&	/G  XrG ? m
G ( 6 S @&	/DC  XYC ? m)C ( 6L
fi:@&3/G ? XrG ( 6 S @&/DC ? XYC ( 6"\
fi$q@F&/G  mFG ? XrG ( 6 S F&	/DC  m%C ? XYC ( 6"7
< 1& F$1& , fi$ )= J@& `\ ff1B   x1 H
;
  q$&K
( ;
( "x
(]@&71
C xK
(R
fi 1MJNKYWXYKLMX cC 
qK M   ( E  ? E   \   < E  5 E  / \   0 E  3 E  - \ &
E
E 71& 	
(m ,& N)K
(fi 1ffVL4SZSQKYWN% m1& a. ")1 H
 W K
 fi'
(&"fifCd
 fi
  ( *  ((  (?
1 _
(&""&K
(&"GK4 $
  S F&	/G^XYC_6"7 | ff" 
 T* qi FCaS
Q T T
  K
 fi$
(&"fic\ qJ\
K
(> CWm
o 1AF$_ K
 fi'
(&"fiiK1dCgd
 4 
(
 1& 	
 1 qM
  \ qXD@&	/G^XYC_6~
@&/G+XYCWo6Xx }Y,7s/pd
 
 A1& 	
(1  
 AM
  "I
(1& ^" fis, 
( 1&KH4b
(
13 < \J13 3 \
 fif13 ( 3 76_)
 >s\ &)
 AK$1"9Gg
 fifC O\>;
 F
	* d$
 %F&	/G^XYC_6) 1 T1

I1&  *
 d,$&M/;d
 $1& +" 1 A 	
 I!=  7Y>6"7
-)
(Wy

 "&" /DCFEHGEHGo
6 qK1"H
 _O YFF`X M;
<  * /G_omG+XYC6 S ;
<  * /G_opXrGemjC_6q
<  * /G+XYC_6"7-) 	
(&" )ff/DC ( EC ? EC  6q
 fiy/G ( EHG ? EHG  6:
(1& ^ >fiLu\ q N 	AN|
;

 $fi7
 ffF ,fic\ qC 9   ( * E  (( E  (? W
 ,
fi /Gnm   ( * E  (( E  (? (6BS Q
| ff" d$
 F x/DCFEHGEHG_o6M
 o /Gjm
E E (6"\d
 ! uH
 	
 ] 
 =Gjm   ( * E  (( E  (? Mff1F K
(  a  ( * 
 fi
  ( *  ((  ((

\
$
s
)
$

ff

=


ff


J

$
\





fi


>


=
ff


9aJ   ( * \   (( \   ( * E  (? o
\ &   (( E  (? 7
 ((
 >\,; WN
	N
(@M
)
 
(KKHM$
 %
  	
( ;$)x/DC ( EC ? EC  u6 &B/G ( EHG ? EHG  6M
 ff >fiL7
 
 =	
(1 (\$?
(? 
 )F  3= Nff)$fiL
VU

WU

m G ? rX G ( 6 S  `/G  XrG ? mG ( 6 S <] * /DC  XYC ? mfC ( 6 S <; * D/ C  mfC ? XYC ( 6 S 
 <; * /G  
m C ( S C ? m0C ( 
fifG  mG ? miG ( S G ? mG (
 C  mfC ? f
 /DC ( 6 S /G ( 6%
fi/DC ( mfC ? 6 S /G ( miG ? 6
YX

[Z

|#$&"1B	
(1(\LM$
*I
(&1	
(fi01q
d$	AN
 $fi7W1fi	
(1(\J;j
	*
<  * /G  mG ? XrG ( 6 S ]<  * /G ? XrG ( 6"\x;<  * /DC  mC ? XYC ( 6 S ;
;
<  * /DC ? XYC ( 6"\x
fis<; * /G  XrG ? mG ( 6 S
<  * /DC  XYC ? mC ( 6 S 1\1 RM 	AN
@
;
 	
("u1 q 1 fiL7
(\' a&"fiu	
(1(\ff"


 I"  uF&/DC ? mbC  XYC ( 6 S F&	/G ? msG  XrG ( 6"\@M
 uff
(y$
* 
/DC ( msC ? mbC  6 S
 

fi

o$s$!P"$$#@$~%PF!&

o$('*)$


 /G ( m_G ? m_G  6"7  &1	*&	\FP	
(!R1_@
F
(o1
("%Pfi+&1$?
(fi
,o7@W
(J\$M	AN
?N fi?
1 	B7
 +1& 	* ff?
(?u\ &Wofi #~1q"	\L
(KKHJ
I/DC ( EC ? EC  6%Fffq,fi/[
0fi$q"	
(

(&" qM
 &",) F/G ( EHG ? EHG  6
 ff) ,fiL6"71&  q! 
(&K
( 1&"	
 " 0
(	* Fm"&"$ M
 
 

(1& jffq >fiL\L F 3=F
 
 /DC ( mC ? 6 S +13 ( 3  :
 5
fi /DC ( 6 S 132As13 ( 3  \T
 1& 
"
,EK>E135>E1^ A/p$fi  qfi$ J
 C ? m   ( * E  (( E  (? (6"\
 fiAff 	E qy(B+13 3 7F-% 	
(&"s\ 

&1 *
 T,& 1  1IF&/DC ? XYC ( 6@ ,132>7%8  M@&/G ? XrG ( 6 S @&	/DC ? XYC ( 6@+
("KN " J\
@&/G ? XrG ( 6Wff
(1 f   1 ,132>70)
 >\;
 ^
	*  
 ./G ( mG ? 6 S i13 q o 
 fi
/G
6( S 132%I13  Ho\T
 1&  ,  >E"4EK>E13 7 H
( \> P 	
(!
 1:1 @$
  ff,  &@J
 &)13>\
"  1& I
(1& R^1&  *
 J>&K)
 9&K ,1320/ &   ,EK>E135>E1^ (F
6 
 M
(1& ff 1 
1F&/G^XYC6B =
C {   ( E  ? E   E  < E  5 E  / 7I n
(fifi " L\]  S 13>\ $q KoE HoFe(^b13 3 \
d M  S >o\ q o E o  (13 < 7F<F^1 K
 fi$
(&"fii
(&K H
 "_A
 $?
 " L\>M
 
	* J
 
13 ( 3 / o ~j132 o 6Jy13 /132 %~ 36Jw/ o ~ o 36 S  }
 S >o\ qu =d
 	
(! 11 F
 =;
 _ff1@$
* 
/11(6
o ~j132 o S >\c132 ~
S 
 fi o ~ o S >\
d M  S 13>~\ q+M
 :ff)
	* 
132/ %~ "o6J '/ Ho~ 36 S I
 fi Ho~ Ko S >7
/16
 q
A	
(1 
 $
(>"	7B&" qK 1 a$
  S >7B)
 $quM
 ffT
*  Ko S Ho S >\
| 	g H
"  I  Ho=S Q >\ qy1&  /11(6=M
 H
	* j
  Kffo  Ko S ,132>\x
 fi :J
 	
(!
 11 R
 1& 
fi  ff . +1 " ( 
 fi ? K4 
 / ( 6 S "oJ
$
\ / ? 6 S Ho\B
 fi Ko  Ho S ,132>\B= 
 ,	\' a 3=a
 
 q@&/DC ? XYC ( 6 S @&/G ? XrG ( 6 S ,132>7  1& 	* &	\c;
 ffff
o E o -(N13 < 7Wd

	
* qG ( |
  $7 ; 3=] 
 
S   0 E  3 E  - W
 fi+G ? mG (  &   0 d&   3 E  - \,$fi  qfi$ F
@&/G  XrG ? mG ( 6Fff1%F  >E1 ,E1 7B8  :@&/DC  XYC ? mfC ( 6 S @&/G  XrG ? miG ( 6"\M
 _ff

	
* 
 @F&/DC  XYC ? mC ( q6   >E1 ,E1 798  WC ? mC (  K
( ;
 .
( "H
 )  ( * 
 fi  (( \ 
 	
(!J
 1W1 P$
 Z@&3/DC  XYC ? m=C ( 6L	
 $ff)1 ,7 F&	/DC  XYC ? m=C ( 6 S @&/G  XrG ? m)G ( 6 S >ff\ q
C  mC ? mIC ( S G  mffG ? mffG ( S{T \
 fiA;
 W]
	* W;
<  * /DC  mC ? XYC ( 6 S ;
<  * /G  mffG ? XrG ( 6 S >\
 +?
(?V
1
  	=	7 Fi ffH
& 
 fiL\ 9@&3/DC  XYC ? mC ( 6 S @&/G  XrG ? mG ( 6 S 1P\ q
C  m0C ? mfC ( S C ? mfC ( 
 fifG  muG ? mG ( S G ? miG ( \'
 |
fi M?
(? 
(
(  3=7
 _ff)$
* 
  S "o7 W?NH
 fi$?
 1
| 	 K 1  S 13>7%  S Ho~\ qu,/16"\M
 	=d
 
 J/DC ( 6 S /G ( 6%
 
fi /DC ( mfC ? 6 S /G ( mG ? 6"\'1 j:?
(? fi	7@)
 >\M
 :	
 
K$   S Q Ho7i8$  $
  S Q /[
 n$fi q"	
()
(&"Hq:M
 &">_  S Q ,6"7u)
 q 1& 
.
 "F H
 %}S Q 1BK!j
  S } Ho;7@8   Ho	~ Ko S >\, ; 3=] 
  S } "o7F8$" Ks" 
} o & =
 fi} o & q /16"\$M
 M 
 :/19~}]6 o >/19~}]6 o S ,132>\ 1& RT
 4 + ) 	B


  "o  Ho S ,132>7  1& 3* &\J; ff
(1 A d
 T & S S H
 &  S ,132>7) BT
 	
(! 1
 $K
4
 
  ffq & &135>7   S ,132>\ q0;
 Iffa
*  S o 
 fi S o 7
WFM
 F
* M qJs\ )KN ; 1ff1& 3* aW?
(?u7)
 >\>;
 q	
 u
("HH)
  S S >7F<%s
H
 	
 F
 $
 IC ( S   ( * E  (( E  (? \
 fi 
 C ( mnC ? 
  $&   ( *  &   (( E  (? 7A 
 	=d
 
 )$Ju "" " T
 &B@&/DC  XYC ? m0C ( 6%
(1& _>\Z1 (>\L (>\ &:17% =)
 	
(! 1N1 


 )@&/G  XrG ? mG ( 6x	
 $ff):1 (
 &= (>\d
  )W	
(1 %d
 $1& = )M
  &)
 &B1M
(1& a	
("
K
(
 q	
(& `\$
(B
(	* (7
 9  1
)
 :1&  _?
(? 
 |
fi #: 	AN
>
7 
U

\

O]

U

*\ ^]

GU

U

_

]

U


a

bU

c\

Y\

	U

Ga

6a

`_

Va

\

^]

^]

dUD]

_

I\

I\

Ue]

f\g]

ff\

]

7a

Ue]

I\

I\

Ue]

\g]

h\

]

6a

f\

ff\

8U

d]

]

\g]

h\ i]

%a

,]

j\

*l

\

9l

k]

>\

]

U

ml

\

ml

]

n\

^]

k]

U

U

oU

#a

]

p]

]

W\

%\

q]

k]

W\

j]

0]

r\

]

]

q]

@\g]

fi\ ]

G]

,\

s\

U

#U

\

t]

%\

,\ k]

U

]

\

U

W\ k]

U

\

\


\

 

]

]

]

fi

m w m
u

 o
m  

o


m

W$ ;\7/13255,6"7 S2D`NPL4SFW  WD`NPOFWKZ `KNPOFW:KWX  SOLnI%I!ZzOD2KYNPOFWH7$W	
(fi$	@&"\
|  P&K$7
W$ ;\J7\ M
(1& >\ 7L/132@6"7 W  S_KLMSF4  W`FLH.KNPOFWKWX  SOL  KLMKYDNSLO KNPOFYWH7
W	
($fi 	N:@1& K\ |  P&"'7
W ?$
(\  7B/132,6"7g KAN
(&! :
  &HN
"*&!b:&$
("0(7
:L\FDGS2S2XOW^FMN  S  FYLN 
FL2  FIFYW
WDGS`LGNKYORWNPb5OWBLGNPO qD`OKZ  WNSZZaO^SWDS
  >

$	
(
 	\ f| \L7Z x$1	47W1 f   78 
(4 1&\xM7]# *> \x@7 _
 
(;\x
 fis7] 	AH
 &\
fi$ 1&"\ WDGS`LGNKYORWNPbORW$;LNPO qDOKYZ  WNSZZzO%S`WDGS
$
( I1322 x(5>7 | 1& >  ?
 fiL\ | 

P&K$\c1322>7
-  	N
 J\x7)/132,6"7sa
@
  &!s 1 's1&o$fi &" K
 fi 7 EFYHINKYNPOFW!KZ  WNS`ZRZaOR
^SWDS\
/1(6"\ @( x>55>7
- 	.\  7x/132(45,6"7ffF1& $
( `\ 1& >$q\]
 fi1& 	
(1 $
(R.  K
 " Jk
M
7 ;HkSLODGKW ^FLWKZnFM
\  /1(6"\Z1 x$13>7
 bOD
M\7\ F&K
($fi (\  7/1322,6"7d
 A 	
(%*  9 fi "  
 fi "ff
($	
 "  1
 "K s
 i

fi *$fi q  &" 7  WNSLWKNPOFWKYZ FLWKZFMh8IYI!LMF`YOH.KNS:S_KTFWOW^\
/1(6"\c( x,45>7
$
(?A
( (\%7@-W7)/132>1(6"b
7 Jj
f& 	&"1& qK W
?
(""	
(
 ;$ " 
(@
 
" j& K7
FLWKZF4 
KN  SH.KNPOD2KZ bTD  FZF2b
\ %Z/6"\132 x$132>7
 (\$M7@7]/132(,6"7  S_FLOPSVFM :L\F^]_K%]`ORZaORNPb7%B	
(ofi 	M@& "\ |  P&"'7
&" fi'N
 J\ | 7\
 
( & J\7 ff7ff/132Y2 @6"7 @?
" e 	
(K&1d
{1&N
 >
(;7 
:L\FD  :ZS`QS`WN 
EFYWS`LMS`WDGSFW
WDSLNKOWNPb=OW;LGNPO qDOKZ  WNSZZzO%S`WDGS>U  
[\9L7
1 @`x$13(47
&" fi'N
 J\ | 7\  
( 4& J\@7 7)/13225,6"7n@?
" H
 	
(K&1
 fis$fi ;
ff1& 	
(1  70 
:L\FDGS2S2XOW^
KNPOFYWKZ EFYWS`LMS`WDGS$FYWLGNPO qD`OKZ  WNS`ZRZaO%SW!DGS>UP 
[\
 ORLNS2S`WN 

$L7L1(2` x$13(47
&" fi'N
 J\ | 7\  
( & J\J7 7/13226"7  >$fi  ^ x 0fis $
:! 1	N7'$
(1& =~ $>
fi'
 " 7 ;LNPO qD`OKZ  WNS`ZRZaO%SW!DGS\ ]/6"\c @` x>>135>7
 n
. N
 " &K
 ;
 &K
 &: fi'
 17ff # 	NH
 &	\L7c7\
 K &KA
 J\Z7@/132,6"7^T

 
(;\7 | 7P/ @fi$76"\ W!DGSLNKOWNPbOWV;LNPO D`OKZ  WNSZZzO%S`WDGS:\L7,11 x,7 | 1& >  ?
 fiL\
q1 1&"fi$
u7
 &H
H
 M
 &"j
 &% N$
(&" 
( 1&
 &!*> "(\ =7>7\  K &HN
 J\7\ 
  ff"(\'-W7Z7J/1325,6"7xD
$

 "* &KA
(K
 &W?
"1& 	
(1  7=  :L\F`DS2S2XORW   O N  KNPOFWKYZ EFYWS`LMS`WDGS
FYWLGNPO qD`OKZ  WNSZZzO%S`WDGSkUP 
[3\'$L7$,13
 x,1	47

	s $Y\ 97M7/132(,6"7D
V 1& %$fi B;  K
 R
fi ffN
.?ff\q"1& , ?7  * (\  77\ yZ&K$\
 7)P/ @fi	76"\  S  KYOHVH 8WNPL\FIb  FLH.KZzOH\%L7F1 @`x$113>7  R@1& "	\F-)
&"fi (\
 
("7
qv

xw
y

nz
|{

q}

~

$

i

z

L





2

#

(

z

$

(



L

(

7{

,

(



L

@L

#{

L

w

nz

Wz

$



'{

k

9P Q &

2z

N

L

:{

$

MP Q )

z

Q &



1{

6

|{

L

N

,$

P  )

I{

w

 

fi

o$s$!P"$$#@$~%PF!&


o$('*)$


	s$\97'M7c/13225,6"7 8LMF%]_K%]`ORZaONPb  S2FLb  S F2ODkFM !D`OPSWDS7@a$fiL
*
(?
(ff

"L $
	
 7rB1";7fi$J7
x
(&"\7<=7/1322(4>6"7  S WDGS`LGNKYORW>:S2KFYW!SL  EFHJIKWOFW7-)
&"fia*&"Kn@&"\
-9
$&"fi (\7 I7
 ! q,$
(4 J\  7/132(42,6"7  S  S_FLbVF4 8LMF%]_K^]OZzONPb7a*&""`jJ-)
(&?
qF&1"\<;&"7
 :
 "&K
 "?
 " s
 fin1& *"  ; a&KN
  fi " J\Z' fin
( K  L2D  SOW
d
ZaOD  YSONZS  L4S\ 132Y
 @,7
8
	*(
( (\7'7c/13Y2 @4>6"7  FWXYKNPOFW.FM NKNPONPOD7F o+Vy  s8 \ |  P&"'7
&"$\  7J/13252,6"
7 8KNPOFWKZ hSD`LOI!NPOFYW  hS_DOffOFYW  KW!X hSOYWH7u &"
N AF1& "\ | 
P&K$7

L

`

v

#

`

ff

P $



0L

*







c{



j

z

 

nz

fi	
fffi 	


	"!$#%'&#(((*)+#,-(."#(/

0*12345(67(/891
!4;:6((

<>=?=A@CB3D5E$FHG-=JILKMBNFPOQBRB$ILST=A@?UVW=ROXILEAI?Y[Z\=]FF^=J_`UbaW@
Sdc?B'=]D5B$_

efD5='gAB3D5h

ikjlnmpoNq5rs5t

uvxwyz{}|~+vn+'x+~ w++~ u

A$^* 7x
P-}Ax*x33*
lxrko3q5rst

vnwyz{-|~+vn++Rx+~ +w+'w+yz+ u

 Pn R-}'R>x *
n}nx *x$*A

'^
Hx"3MkPJ"WxxAkP*P-P}x}
 k}x}*J"C]}PMk-x;Ax+
}
;$x"x3-}Hx"3-55xx-P*
;$}x3A^n}P5-^"^'x}n-
;'A}-'-nP-?";$x3?$PJ"-J";-x
3*x33P3x?5JJ"3$x"3J*^x
3]-5n}x}5Ax--?x3R3
x$};3J$RJ-?}?]b3J-
k?}MA-J*J'x5?P}}TP-CkJ
"A53xRJCx'3;'J-'}P]}
}}-?RJx?x-}-}53
}}}x^Rx;'JxR-"P}P-P
^xx;3JRR +z+P } {*{ P-"?-JJ'-Q''
}Px}+^3xPn}

 	ff
'fi 


!"#$!&%('$)!&%+*&,-%.*&/*0'$1%23(45367*&2894)%:5#%+4;<=%23(4
%95%>@?#A94B5%+C#DE!0F23(2#<)2*&2*"!4/B7G2#$/<*"5H!I#J3(23KL5M,N!&94
53(7*&2O%QP3(R94S<3(2OPTCK943(2U536V/!W#;>TXY%%2#<!W*&*"DZ[P\3Y]^3(%6_3(23-943(2
53(/!I#;O(,-`a!I#)5<3!&;O%ffP\3ff2*&2*"!b3(c!I#)%dSegf:hi(jfk	l+m:no&m2po&qb*"!WrKsOf2jto^to&qusOqvlnw\qvfl
xvy XNZ{zg/*W#Z	|2}~GZ^|}-25N.3623(%!&/*&D73(2<rKV,c#+#{93#%(P\3RO;<*!W#<
%97;*&%T94	2<#]^#*&*&D7G53(/2#!WO!W*"DK,N!&94O:4!"O%T3b,Q!":4.%%95!&#%-
3(!W#;)94S53(P>NNfw\w\f<sSi(phLm9n<o"mpo&qff*&!Ira.pht2hfaqvw\quf<l x >;[>WZa4a!I3cR#!W#;23Z|}}
;M94=:423,ND17DE53(!I#;*&;!&=#%2#%{P36:4!W#5{%+#!"*S<#17/!&%
!W##%!&%2#D{!&%23(!&/>
 42#C536!I#;3(%:*"%aP/V36!"%536V/<23(% x >;>WZ*"!0FSH9#23Zg|2}}<b!&!&%N7/!&%
94	53(/23(%b7%O#!0F23(2#<5<3!&;O%	P\2#724/T!&-!0F2362#*&D>TQ423(3653(7*&2O%
,423(7<_5C94362536V/<23(%N523P\3#%!&237*&D),-*&*Z[75<_,#.536V/<23(%N53(*&DZ
#=/!&/23(%:>N4.a!I#3(2%#P\3c94!&%S!&%94S7<_553(/23(%cP2#%9<F23QP3694
*WrMPS;*0_36!"2#<9!"#MPS94!W3%23(4gZN753(a]P3(:4!I3C%936#;B3(##D#<93(*
O4#!&%9O%2>$?#L#<93a%2Zff5<_,#L53(/23(%K53(]OP3(:4!I3K;<*0_3(!&2#<9!&#L7K%9<F23
P3(!W#%9<.!&2#K3(##DL#<93(*\>=N4!&%O2#<9!&*&%.*&#;=53(P*&2#;94%P3O<#D=53(7*&2O%
 #((-(fi+fi4	5	4ff$-		^	*ff23		1
!fi

x!*Pv4

fi

 

wyz{

wyz{

x >;[>WZzgO*\>WZ	|2}}a>NN423(:P\3(ZgC5!&O944%OO!I#<K94P2%P3(%23(4)!&%94
!W#;3!&#MaP7G94L553(4%>5G!0]2*&*WDZc5G23!&#L7G(,2#943(253(/236% x >;>Z
-#36DN*\>WZg|2}}4##gZ|2}}<2#!W#;23Z|2}<}ff#a!I#CQ%!W#;Z|}}T#!W#Z
|2}}<~  *0P^Mg4%2Z|2}}<2g4%Z|2}<}7gZ|2}}a27%#c5<_,#<#S7_553(!W#!W5*&%
55G23(%N7GS53(O!&%!W#;)72%S7<DK4#;!W#;!W#<P\3!"#K24)<553(42<#)53(]-P3(
94{9423>E?\K!&%*&%L5<%%!W7*&O!0PDL2a*"2*&!3C53(/23(%,4!&4,3r=36!I#;L=#
53a!";%S%ff!W#:3(%95G%	P94N<9423	53!&;!W#!&2>	N4!&%2Z4V,-/23Z3(!W3(%-
*&TaP!W5*&2O2#<9!"#*:F3(	`O!0PDO94536V/<23(%2Z,c423(2%T3	553(4O%#-3(!I36
4#;%Pc94536V/<23(%7#*&DB4#;%OP94!W3O!W#52>  K2#L42#+2C5*"DL37!&93<3(D
%9a:_Pv_94:_3(N53(/23(%>
?#<P3!&#94c!&%,*&*0_%9!&P\3Q!W53(/!W#;)945G23P3#OPT5<_V,c#+53(/23(%c3(
*&2%OE7DB7G_5B536V/<23(%2>N4%K*"2C%3()L{94)!W#5P{5<_
,#L53(/23O#L2#L4*W5%943(2#M:4+53(aP*&2#;94L7<DM!ICO!W*&DL%*&/!I#;M%97;*&%2>
 3*&*&DZc9425*&D53(P`53(3(%+2<#1%!";#!]2<#*&D536]P3(:4536PS*&2#;:4
3(!&#{7:!W#>NN4`%PT*&2%Z4,/<23Z*&%K!W536%a!"!"#*36##D+!W#<
942*&2*I%>Q4!"%S2#%N94#{#7G#=%OPY7G_5);2#23+*&2C%,Q!":4
%!W#;K4#!&%cP3-4%!W#;K#*&D=(t2o&t2nlwff*&2% x !>>*&2a%N,4!&4{*&2{.3(!"#
Pg94N%2364O:F362#23NS536P!&%#<T%2#%!W7*&>-?#O94!&%-3(!&*&Z!I#C#<93%<9423
553(4%ff,4!&4K;<2#23N*&2C%-D#!"2a*"*&DK3(!W#;O94536P3# x c%93a4#OH!&ra*Z
|2}}<%:34#.zg/*W#Z|2}<}Z<,,N#<-25*&D)7_5)53(/23YP\3-;2#23!W#;
*&2%)!W#$L536253(%%!W#;A54a%>QP\23K94;2#23!"#1aPL5*P)o&t2sOsOnLm9nl[jqvjnw\t
3(*&/V<#N*&2C%3(c%*&P3(:4!"%c5*#)94QP3`*WO7GS3(:P)!&%;O2#<)7D
94%S7G_5K;2#23)P\3O*W%2>
Q4%#C!W#+%95GN94Q,#%!&23N!&%c5<_,#7G`_5K!I#<;3!&#)7<D.93#%(_
P\233(!W#;B!W#<P\3a!&#P365<_,#L53(/23==7_5L53(/23 x >;>WZY^4%2Z|}}>
3S<553(4!&%S{93#%6P23c5<_V,c#+;<2#23Lp<f2no	mo"n<pt'E,4!&4{%%2#!W*&*&DL3(253(:_
%2#<93#%(P\3C!&#KP#3(!&;!W#*b;*g*W%O!W#<.%:7;*&%('E.K7_5+536V/<23N#
;O2#<!&%S!W#5.7<D94%*W%%>+N4!&%S!W#<93(%;*0_36!"2#<M5G#2#!W#
7<_553(/23,4!&4=2<#2#7*&)!&`)%*&/)53(aPQ5367*&2O%O#%!&237*&DP%23>.Q,-_
/23Z[%!&%c94S2a%S,N!&94*&2%2Zg#)#7#93#%(P\23-P	%97;**W%%!&%#N%2#%!W7*&>
N4%2Z[,;<2#23O;!W#)%:7;**W%%!W#53(253(%%!W#;+54%`#{!I#<;3S#*"D)%O
PT94%S*W%%!W#<)94S!W#5%cPK7_5{53(/23>NN4!&%S#%%!&9a%4#!"%P\3
t2o&t9mw\qulS(to"t2nl[wp<f2no[m2o&np<tZ!\>>4#!&%-P\3	%*&!W#;.%-P%97;a**W%%-,4!&4
2#K23(2a%S94%23(4K:F3(-PYC7_5)53(/23ff!W#)3623-O]^#53(P6>
?#)3623NKO!W#O94!&%r<!W#=P	5<_,#7G`_5)!W#;3!&#,-`3(%:3(!&36%*&/%
M947G_5L%95G235<%!&!&#E2*&2*W%#E94{5<_,###!&#E9<7*"2<12a*"2*W%2>
N4%O2*&2*&!N3(/23(D+!W5G3(9<#%!W#:4D3(O947%!"%cP\3<#D+4!&;4<_5G23P3#K94:_
3(253(/23(%2>C3!W#%9#Z	:4.7_5=536V/<23(%. x  !&2#74`*\>WZ-|2}}<~#
<#*0P x <O2Z|}}ff94Q,236`O%N%9%%(P*b!I#3(2#<53(/!W#;K5!"!"#%25*&VD
%95G235%!"!"#B#3(23(=53<O*W!"#gZ36%95!&/*&D>KN4##!&#97*&22*&2*W%
x 3ff!&%36%93(!&!&#{O*g*&!WO!W#!&#c!&%*&%C94S7%!&%QP3ff/236D%9%%(P*b5<_,#K53(/23(%2Z
>;>Z xy <%23O.*\>WZ|}}O3 y XTNXffc x c%934<#Lzg/*W#Z|2}<}|2>E?#3
5!W#!&#{94#25%c!W#:3({P\3ff%95235%!&!&##{94##!&#{9<7*"2<)2*&2*W%2#
3:423T2a%!&*"D793#%(P\233()O9423Q7_5)#)5<_V,c#K2*&2*"!\>NQ2#Z944!&SP
94%(,-O2*&2*&!	%93(*&D)!&%	6%!0]>
92

fi

J    J++uM'++'

  +x+~+



'z+++;+{

Q4S3(!&*&S!&%N36;#!&%ffP\*&*&V,Q%2>  %:3(-,N!&94)73(!&:PT/23(/!&,EP%:5235G%!&!&##
 **&!I!I#a!&# x !&#<> y 3(/23Z,-!&%2%%-%:3(2#;94%T#C,2<r#%%%	P^94Q2*&2*"!
O
!W#O3(9!&*<#+!W#:3(C3N553(4P3NO7!W#!W#;)94O%93(2#;<94%NP7G94)2a*"2*&!\>S?#
!&#Kc,-3(%%ff:F%	P94N!W#<;3!"#SaP y X%:7;**W%%-!W#<S94Q%23(4%9-P
C%95235G%!&!&#<_7%53(/23>g3(94233(Z[,O%236!I7G(,-./3(!W#<%aPK3(*&/V#D<_7%
]*&23(!W#;P%97;a**W%%2>	!&#N2*&%	,N!&9494%TP7_5;2#23*&2C%2>  
!&%2%%c!W#+:!&*94S7!&*&!&D{P	94S53(*W%%!W#)3(23-.4*W5{23(2%S53(aP*&2#;94%
P\336:P!W#;+K;!&/2#{%aPT*I<%%`%,-*&*	%)3(3(23c94O%2<3(4%95O!W#=#553(53(!W
##23>S-%#):4!"%!&%2%%!&#gZb,!W#936%/23*	3(*&/V#D=O2a%93(%2>S?#!&#=Z
#K523(!WO2#<9*%9D#+,N!&94K944!&;4<_523P3#S:43(2R53(/23(%M#
.3(/<2*&%S94.5G2#<!W*TaP34#!&%2>  .4/O4<%2#=:4%%D%2O%!W#=3623
%94,:4S3#252#2%!&*&D7G.!W#<;3B!W#<+!&%!W#;=%D%2O%O#M!"%O/2#M7*&)
!W53(/#)94O523P\3C#SPT/<23(D5G,23P*536V/<23(%2>-	!W#*&*&DZg!I#!&#~K#)/236/!&,$P
3(*W553(a4%-P\3ff5<_,#<7_5K!W#;3!&#K#*I%:4S3(!&*&>

3g$.95.
Tfffi 	 Y=G 
 


 )nA=Jb

?#94CP<*"*&,N!W#;Z	,-!W#<93()(D5!&2*-3(253(%2#<9!&/%OPN5<_V,c#=#L7_52*&2*"!
#!&%2%%N94!W3	%:3(2#;94%-#.,-2r#%%%ff!W#9a!"*\>	QP\23	94a2Z,-N%9r4O947%!&%ffP3
O94*&;DK!W#)3623-O7!W#S:4%2*&2*&!>
v q 	ff
sfiHl?ljCjxsff;q+lHtjj>>"!#j j Hj
N4;2#23*5367*&2!I#]^3(%(_3(23-:43(253(/!W#;!&%%:4V,J94S!W##%!&%2#DaPYC%"$
P*W%%2>Y*W%!&%%TaP*&!&23a*"%>	%-*W3(2D!&%2%%Z943(253(/23(%T%9*&*&D)!&*"!&
!&9423Q5<_,#K3-7<_5K2a*"2*&!bP\3-5*&!&%94!W#;+:4!"%Q9%9r[>
ffD5!&2*&*"DZff7G_52*&2*W%#<9!W#%O%/23a*	!I#<P\23(2#3*&%`,c4!"42#B7G<55*"!&
)%P*W%%O94aS#%!":94K%23(4%:>)c2#23*&*&DZ	94!W#<P\23(2#+3*&%O2#=7G
!&/!&!I#<(,-)*Ia%%%2d&%('hnlqvflM!I#<P\23(2#3*&%5G23O!&94K;2#23a!&#=aPQ#,R*W%%
#m9f<lw\(nm2w\qvfl)!W#<P\23(2#`3*"%Q*"*I<%%N3-3(25*W942R7<D94236%2>	N4SO%-55*W3
7<_5K2a*"2*W%!&%N94(tfo&pw\quf<l2*&2*W% x 7!W#%#gZ|2}~<>N4236Z945#%!&#+3*"%
3(3(%*W!&#E#Pa3(!W#;>$N43(%*W!&#2*&2*W%+2<#172#E,N!&94L#93!&#
3*&%2Z>;>[94*&!&#PT9<*"<;!&%2>`?PN*&!&(D!"%!W#</*&/=!W#=)5367*&2 !&S!&%%2#%!W7*&)
25*&D94N%:5235G%!&!&#K2*&2*W% x -4!W3T<#!I#;<23Z|2}<}Z,4!&42#%N3(%<*I!"#
,N!&94O%:5!0]S3*&%T%9!&9<7*"QP\3T4#*&!W#;Oa!&#%2>TN4Q5#%!"#3*&%-P^94Q%95235G%!&!&#
2*&2*W%<3(.%:5235G%!&!&#gZ-*&!"(DL3(%*W!&#gZ-#Ma*"!&(DP3(!W#;>c;!W#gZa!"!"#*
#<93!"#3*"%O%94=%9<*"<;D+*&!&#gZ	%:7%95!&#gZb#2#%!W#;Z	#M3(,3(!&!W#;2#
725*&D>R?\)!&%)L7=2C54%!&$94CP\33K%9D1,-{25*&VDE94{/23(%!&#PO94
%95G235%!"!"#$2*&2*W%!W#9367<D-4!W3)#H#!W#;23 x |}}>H5!0]2*&*WDH94!&%
2#<9!&*&%94aTP3(!W#;!&%#*&D+55*&!&5%!"!"/<S*&!&23*&%2>
E7_59436253(/23	%9*&*&D.!W#<9!W#%T%*),++Pg%_2*&*&Ohfw\t2l[w\quno[3hn9qv2t
m2o&np<tP3(U,4!&4{!"%*"%`#=3(2O/%c#*I<%,-@C!WO>SN4!&%*W%!&%S5!W#<
94%#)/.BPNnmw\qunw\t9j)mo&npt>-!&/*W%%3(Zg#*"!WrK52#<!W**W%%2Z*&*&V,-
53(#,*I<%%/!WK9455*&!&2!&#PT%O!W#<P23(2#K3*&%2>N4O!I#<P\233(=#,*W%%
3(5-!W#0),+->	?#!&!W*&*&DZ),.132S#4),+516$T>	N4!W#23O!W#!&%!&O%*&!&#K3cnmw\qunw\quf<l
9

fi

 

wyz{

wyz{

 w\t(h!&%3(2*&!&7<D4236!"%!&2#%2>T94!&%N2#Zg423(!&%!&07@%%!W%O#93*#`7G23
8:9<; ?  ,N!&94M24=- ; ),+TZ-#L944- ; ),+$,N!&94M94)%:*&*&%.,-!&;4< 8:9 !&%%*&>
#+!W5G3(9<#53(5G23((D)P423(!&%!"%!&%94!W3?>nqv:lt:>N4236!"%!&!&%2*&*"P!W3N!0P!&%*&%
5<2#!Ia**W%%!W#+%:4)##23c:4#K*W%.362!W#%S5%%!&/O!W#<]^#!&*&D=*&#;>A@Q%9*&*&D
94P!W3#%%PT94`%4236!"%!&!W5*&!"%O94aN9453(/23-!&%5*&Zg!\>>g!&c2#{23(!&/O94
25(D*W%,c42#K79!W#!W#;.#K!W##%!&%2#N!W#5c% x 53(/!"):4#23(*&D!W#;.2*&2*W%c!"%
5*&2>
Q4a!I#C%9362#;94CP7<_52*&2*"!	#)53(/23(%ff!"%Q94!W3T%93(#;O3(##D)#<93(*\>
#94C#.4#Z	#<D+!W#<P\23(2#%O,4!&4M3(O:]^#!&*&DL##%%93(D!W#M+53(PZg>;>g!W#<P23_
2#%-!W#/<*"/!W#;O9*&;<!"%Z3(-!">T#O94Q9423T4<#Z#<93!"#O!W#<P23(2#3*&%-*&!Ira
%97%9C5!&#=/!&=943(25G!&!&#P5#%!&#!W#<P\23(2#%O!W#/<*"/!W#;94O%9O x 33(O!W#<_
%9<#!W*W%%>E7!&;!"%:/V#<9;<aP^7_52*&2*&!!&%	94!W3b*WrP;a*_3(!&2#9a!&#g>
ff2%23(9!W#)!W#<P\23(2#%S3(cP/3(K/23ff9423(%QS:4c]{%23(4K%93a;D.#{94
423(!&%!&,-!&;4<aP94c*I<%%N53(-P!&2Z!"cO!&;4-794c2%c94YP3/23(D*&#;O!WOc#*&D
*W%%c,4!&4{3(S#c53(-PT#D)53(PT3(2#O23>
y **&!WO!W#!&#!&%S(D5!&2*	5<_,#2*&2*I%,4!&4,%94*&*	!W#:3(O!W#94P\3
P94Sm:fl[lt:m2w\qvfl.w\no&t9n<pm9n<o"mpo&p< x -ABC-O x zgQ*\>WZ[|2}}>?#C3(23YS!W#<93(#-DBC-$,-
,N#<T%93(	,Q!":4947%!& x P3(/3(!W7*&2ff97*&2K2*&2*W% x >;>WZ	!&!W#;Zg|2}}<~P3T*W%%2>
97*&2EBJP3?$B!&%S:3(S,4<%`##<_36c#%S36S*W7*&=,Q!":4+*&!&23a*"%S<#+94QP*]*&*&%
94)#!&!&#gd?vP94{!ICO!W+%:%%3#%GF #IHIJJIJKH FL=P=#FP#B3()*W7*&
,N!&94C*&!"23*&%#M #IHIJIJJNH MLZ942#K:4*W%DOPM #QHJIJJKH MLR x w\no&t:np.mo&npt9Y!&%<#!W#%9<#PS*W%
!W#5$T>?#949<7*"2<2*&2*W%(,)!W#<P\23(2#)3*&%<3(%Z	#O*&D94+t'hnlGqvfl+<#=94
(t9j<pmw\quflK3*& x >;>WZ	!&!W#;Zb|2}}~>#+55*&!&2!&#{P	94S5#%!&#{3*&`O2<#%N%*&!W#;+
*W%OP3(S$1#Ba94!W#;)94*&!&23*&%OPK/3(!W#<SP-!&S+{pfnoT,4!&4!&%`*"!&23*
-94*&2P	PT#+fht2lK73#4 x O73#4K94-%#-#<9!W#K(,OC5*"22#9<3(D*&!&23*&%9>
b7*&2)3(!&#*"<%%O73#4)7DK#!P\D!I#;)%97;a*T,N!&94K94c5*&2O2#<NPT*"!&23*
U x 2#.7<D,V U b#O94-%9<O73#4gZ<#.55*&D!W#;O94-%97%!":!&#94N,4*&N:7*&2g>
##!&#{97*&2{2*&2*&!-,3rK#)##=97*&2g>97*&2!&%2*&*&m:fl[lt:m2w\t:j
3=m:fll[t9mw\quflMw\no"t:npK!0P24=!W##23#4F x ##<_*&2P#2S,c4!"4!"%O*W7G*",N!&94*"!&23*
MN4%O)*&2P#4FXW	O#;{!&%S!WO!W)%9%%3#%O94a!"%O*W7G*",N!&94=*"!&23*CMYW
5*&2O2#<936DZM(>bN4T!W#<P\23(2#3*&%T36Nw\n9w\Zt['Vw\tlqufl[Z2#)(t9j<pmw\qufl[>N4ff%9363*&-!"%
*&,ND%ff94N]^36%-!I#<P\23(2#%25P	S236!"/!&#g>T?N523O!&%cS:7*&25#%!&#K:4T2#C#*&D
755*&!&+O936!"/!W*g97*&2gZ!\>>#c#%!&%!W#;OP#*&D.##>  N94aT94c%936T3*&
2#73(%93(!&K%_2*&*&Lw\n9w-(t2o&t2nl[w-*I<%%,N!&942%!I#;)!W#C5*"2#%%2>O93(
3(*&/V<#DBP+*W%.!&%:]^#1%P\*&*&V,Q%2>?PC$!&%#M#%9!&%(]^<7*"{%SaP*W%%2Z	,-K2*&*
\ ; $+%93(-3(*&/V#<-!P	9423(c!&%N%9!"%6]^7*&%97%?$ Wfi] $+%:4K94a*$ W_^ OP\"R!&%N#%9!&%(]^<7*">
!W#94c%TP	#;!&/c*W%%-#<9!W#%NT*&2%-#c%9<3(T3(*&/V#<-*W%Z,-*&%O#%!"23
S36%93(!&K2*&2*W%N,4!&4C#*&D25*&D%#;!&/c*I<%%ffP3Y94N%:3(T5#%!&# x -DBC-a`Ibdc2>
N43(!&#E3*&!"%):4+%9%K!W#L94#</2#<!&#*N9<7*"2<12a*"2*W%2>XY2#%!"#1!&%)
O7!W#!&#PN5<#%!&#L#L3(!&#g>?\O!&%5G23P\3OL7D%*&!W#;B{%97;<*(TK!W#M94
97*&2EBSZg55*&D!I#;#)5#%!&#{%25+eT<Z^#!WO!W*"D=5G23P3O!W#;+.36!&#{%25
,N!&94=T)#M#.aP!&%#,N*&D=2362M%9%%36%2>  94aS!W#M94.362+aPQQ3#*I<%%!&
!&%%:<.!&2#cO25*&D)%93(N#)2#%!&#gZ[!\>>94S36!&#)!W#<P\23(2#O!"%##%%9<3(D x >;>Z
##!"Rz<#;25Zff|2}}>NN4%2Zg,-a%%9O94c,%O/236%!&#%aPf-ABg-3C-DBC-a`Ibdc
94-)#-25*&D+3(!&#)%25%N!W#)94O3(2PTN3#K*W%%2>
9Ih

fi

J    J++uM'++'

  +x+~+



'z+++;+{

-DBC-13-DBC-a`Ibdc-#<T42/<T%95G!]Q!I#<P\23(2#3*"%bP\3b4#*&!W#;`*&!&(D>?#%2Z,c42#
2*&!W#;=,N!&94*&!&(DZ	94.!&!"2a!&#=O%`7G.2#L7D94K3(ji!&/!&DZY%DCO93(DZ
93<#%!&!&/!&(DZ#%97%!&9!"#!"O%	P94-*&!"(D%DO7G*\>?#Z94N%-P^#O!"!&
P\3aPa*"!&(DK!"%-!W#)#O%2#%c5!W*\>T--!&N!&%-/23(D!0.2*&NO/*&5)94%ffP\3T%!I#;
7!&*&(_!W#a*"!&(D)!W#)9<7*"2<K2*&2*"!	:4-D!&*&#/!W#!W#;+3(%9*&%N!W#+53!&>
?P%97;*fiTc7% x P23	%N!W#<P23(2#%:42a.P*"<% x %97<_(:7*&2O,-N2*&*g94
79a!I#{%97%!&9!"#+Kfo&pw\qvflCP:T>
Q4#!&#Pc97*&223(!&/V!&#K#.%23(493(N!&%ff!IC53(:#d  N%:2DDBlk4B W !0P x #
#*&D!0PY97*&20BCW2<#7c23(!&/CP3(mB7<D55*&D!W#;%93(T3*&c!0PnB1!&%T:4936!"/!W*:7*&2gZ
3ff7D#C2#%!&#3(!&#K3*&S%97;*[!W#,BS>	N4c##!&#C97*&2C2*&2*W%N!&%N#
x 53(Pb#oi^2#2>	?#3623	%94,94#%9!"%6]^7!&*"!&(DKPc*I<%%*$TZ%23(493(Z;<!"/<2#
%-P\*&*&,N%2Z4%c.7GSO!W#+!W#p>nqvO,D x 24)#OP	9493(O`%7/!&%!&=P\23-
]^#!&O#<-PT!WO2N#<!&*	O*&%97*&223(%>TRt9n<m[qw\(t:t#r:]^#7<D+O2*&2*W%
#.%	Pg*I<%%?$!&%-;!&/2#7<Dc93(N,4<%3(	!&%T*W7G*"),Q!":4O94N936!"/!W*:7*&2g>	X	/23(D
!W##23#.!W#sr *I<7*&1,N!&9497*&2tBU4%`a%`!W!Ia.%:%%3(%O94)#%SP3( 94
!W*%aOPF #QHJIJJKH FLRZ,4236uFv!&%N*W7G*&=,N!&94wBv<#xBlkwBvZ|aylz*yl{b>
!W#S#ff#*&D94#O723ffP53(P7(%7N*&%O94!W3ff%!&c!I#2362%%-3(!W#;94536P
53(%%2Z-5*&!"!&)9<7*"2<L2#O23!&#15363(%K94C#%93K*&*9<7*"2<L!I#6r!I#
73(2:4<_\]^3(%	##23b3(#<3(2a%#7*&>	N2#Z!W5*&!&!&T2#O23!"#`5363(%	:455*&D
m:flt9mpw\qv2tod|fpljt:jSqvw\t2(nw\qv2tcjt:t(htlqvlct:n(mqSk	qvwYqCnm[}Vw\(nm}qul x~ 3PZ|}b3(-#3*&*&D
%>T?#:4!"%N55364O!&23!&/*&D*W36;23b]^#!&c!W#!"!Ia*53(%ffP^:4%2<3(493(#r36N5*&36
,N!&942594<_\]^3(%%23(4g>)]^#!&K%;O2#<S!&%#3a*"*&D=:]^#17<D=)%a_2*&*"$m:fsQh^o&t2w\tlt9
fpl[j x ,c4!"4)5<%%-%9393*^3(%93(!&!&#%-#C94:7*&2,4!&4)3(*&*&,-.!W#K94c233(2#<
%;2#2Z[%7*&,c#=O]=#93a*#O723Zg%_2*&*&1(tfp(m:t>c?\23!&/O252#!W#;
!&%.523P3O17D%93(!I#;,N!&94L7%!"+36%3(K/V*W5{ ; ?  #L!&23!&/*&DB!W#23(2a%!W#;{
#<!&*+536P-!&%P\#B,Q!":4!I#94O]^#!&C!I#!&!W*-%;O2#Pr :]^#L7D#.7G#L#{b>
 36O!W#2#O5*&%P3S5*&2#%%.7G#%3(K94j<t(h^wYqfpljZ-qvl>t2(t2l[m9t)fpl[jZ	#
k	t2q&qw\t9ji(jt(hgwYqfplj<>
Q4N2594)7#.*&!WO!&%N94!W*[2594aP!W##23#% x ##<_*"2VP#%:T!W#K97*&2
,423(:4233(2#<3(%36A{!&%N94S!W*25:4)523O!& x 94S36N#`4%-2594{>
?#53!&Zb9425947#M!&%S!".%9%%(P* x zgCS*\>WZT|2}<}c336!"%#gZT|2}<}~c7S!&
%9<F23(%P36$:4*W36;T!W#23(2%NP94ff%;O2#< x :]^#7DO36%3(C{g2<%7DO#!W#23(2%
Pn{b>	N4N!W#<P2362#S7#)*&*&V,Q%c*&/*7DO*&/*[5*&3a!&#OP94N%23(4O93( x >;[>WZ!&ra*Z
|2}<>?#)C53(!&%#K,N!&94K:42594+7G#Z94!W#<P\23(2#7#r%NO%9:4!W#23(2%
PT94O%2<3(4{%95a5G%%!W7*&Z	7!&!"%!W#<P23(!&3c)94O25947#=!W#=53!&>S?#3(23c
O7!W#94/#:;%cPT94O2594=#94O!W#<P\23(2#.7#Z94O,-!&;4_2594=7#
,N%	!W#:3()7<D y %23bT*\> x |2}<}>N4!&%N7#%23(!W7%cc*Ia%%TP5G%%!W7*&7G#%-94
3(%:3(!&N9497*&22594+<#)94S#O7G23NP	!W#<P2362#%*&*&,-+!W#<P\23%95G!0]`:7*&2g>
c*0_3(!&2#<9!&#caP-ABC-KZV%3(D5!&2*5<_,#2*&2*W%2Z!&%b;!&/2#O7D94ff###%%
#!&!&#g>-N4!&%-#!&!&#K2#:!&*"%Q94T/<23(D*&!&23*g!W#)97*&2K723(%N3(*W!&#K94%93(
*W%>SQ4`%P5%%!W7*"C%93(c*W%%2##3*&*&D7K3(%93(!&K!"K%:*&*%P
*W%%O,4!&4B36%9<.!&2#<!W#=3623{;3#<O5*&2#%% x >;>Z y <%23O*\>WZ-|2}}Z
>;>:4%	P#;!&/-*W%%-%*W3(2aD`O2#<!&#>TN4%2Z<#*&D`2369!W#O%2##<%-42/!W#;
##!&#S%93( x ;*Wff*W%O3(c2#O23>	C!W#)53(7*&2RPT53(P%-,N!&94w-DBC-

9I

fi

 

wyz{

wyz{

TD

CTD

TD

BU

CBU

BU

C

	!&;3(|dff-523!"#)7(,-2#)O5<_,#)#+C7_5)53(/23
!&%-94T!W#K;2#23*94D363a9423	*&#;>	?#CPZX-ABg-!&%NO#;94N,-2r%T2*&2*&!,42#C94
*&2#;94%NaP!&%!W#;.53(P\%3(c#%!&23(>-N423(:P\3(ZzN*\> x |2}}aT53(5%)2#%!&#%
P(-DBC-,4!&43(`7a%+#{#936*&*"!W#<;3!"#)PT94Km2pw-9po&t>cN4%O2#%!&#%2#
*&%+7G%2#%S3(%:3(!&*"2C)O4#!&%9O%2>P3(942353(7*"2 !&%94cP2#+36!I#;{94
%2364M9<7*"2<B,N!&9494)%9.3%97%9O%97;*&%23K3(252*"D>N423(<3(.%O
2#%!&#%cP:42*&2*I%O53(5G%)/236O%94)53(7*&2O%2>-XN>;>WZ7D)zg*\> x |2}}
K3(%93(!&{%97%95!"#+#25S#7<D)%934#+<#!&r* x |2}}24!W#;)4#!&%
4/S72#!W#936>
WR

rs5jjfisDfiljs?l	;l5rttjfi

ff3q

 q 5j

 3K553(4P!W#<;3a!W#;=5<_,#L#17G_5L53(/23(%.7<DM5G23!&#M!&%K4<3:_

23(!&17<D=hgt6h^(f2m:t:qvl#Eqvlh^pwSnpsOtlw\nw\qvfl>=Q2#:P\3(94gZff*&A$$7)94)!W#!&!W*N*W%
%O,4%!W##%!&%2#DL%94*"L7)%:4V,c#g>+?#94)53(253(%%!W#;B54%K94)7_5%9<_
5235%!&!&#E53(/23;2#23%.%`aP*W%%/$:J%94M940$ 1$*T>M#*&;%*&DZ-,-
93cP3(K23(9!W#=#O723P53(PN25%P-94 y X$53(/23K*W%%p$	%94
94$ 1$  >+N42#gZb94K!W#5%a$1aP:4.%95G235<%!&!&#L53(/23!&%;2#M7D5$  Z
#)94!W#5cP	94 y X153(/23ff,N!&94/$:ff>	QP23T:4N794{53(/23(%-2#)53(+`,-3rO!W#
53a*"*&*\>ff	!";3(|c!"%:5*ID%N94!&%r<!W#+P5G23!&#K94a!&%N%%2#!Ia*"*&D)7%)#)%2#<!W*
#22#!&#)aPY7G94+536V/<23(%2>TN4O553(a42#+7GS%2#{%C%95!0]O!W#%9#<!W!&#{P	94
;2#23a*523!"#)553(4)NXffN x 2#!I#;<23^4%2Z|2}}<>
!W#O94%95235G%!&!&#=536V/<23N,-3r<%N#{%23(4)%9a,4!&4{#<9!W#%%PT*W%%2Z
!&S!&%O/23(D2%D);<2#23.%SaP/*&!&B*W%%O!W#M+53(253(%%!W#;=54%>KU/<23(D+%!W5*&
O94S!&%b523P\3$]`#`7G23nz[P!&/!&#%25%	#SN;2#23	94T*W%-%%),. v
#5) + v aP!&/#5a%%!&/O*W%%2>SQ42#gZg,O%*&S*&*>nm2wvZ[!>>5%!&!&/#!&S*W%%2Z
P3() . v >H!W#=94!W#<P23(2#%{PS=%95G235<%!&!&#<_7%53(/23K3(+%#ZN!&)53(%
#*&DL*&;!&+#%2#%)aPC$T>L%C,)%:4*&*5*W!W#1!W#!&#L=!W#O3()9a!"*\Z-!&K!"%K#
%2#%!W7*&K=*&*;2#235<%!&!&/#!"%94O!W#5P	94S5<_V,c#+53(/23ZG!>>C%
$ : 1OI-d-!&%P H - ; ) . v R>+Q,-/23Z!&O!&%O,N!&%.+%*&#*&D=%O.#!&%O,N!&94M
P#!&#x*	Z!\>>$	*x13: x OI-d-!&%P H - ; )/. v RV>
ff2%##!&#:7*&2<_7%.536V/<23(%4/NQ%23(4%9T,4!&4O#<9!W#%T!&#%
x 9<7*"2<!W#%2MP*W%%2Z	!&O!"%K]^3(%`%!";4#7/!&%4,+93O/Va*"!&L*W%%
P3( %94=%23(4L%9a+,4!&4,N!&*"*S7G,*&*0_%9!&EP\3K=%:5235G%!&!&#<_7%H53(/23>$
9

fi

J    J++uM'++'

  +x+~+



'z+++;+{

#O94!W#3(23c)93c/V*&!&M*I<%%S!&%)25*&D*&2)O4#!&%9O%P y X
53(/23(%>Tc%%9O94O*&!&23**TO!&%C*W7*bPT94O3(#`aPYC*&%%9797*&2&B#>Nzg
M #QHJIJIJH ML7G94c*"!&23*&%94a3(%)!W#+36!&#K%25%ffP\3ff*"<%!W#;,B  #):436%!&
P*B#>-N42#gZ[94*W%wOPVT H VM #QHJIJJKH VMLR`C2D)723(!&/a%.#,J*"2C x %!W#`!&N!&%
*&;!&2*b#%2#PT9497*&2*I<%%!W#xB  >N4*&2C*&=7O93#%(P\233(+.
7<_5{53(/23>-c%S552a*"!W#;%:4!"%c!&2K%#%2Zg!&4%%S%/236`3(%:3(!&!&#%2dN4
*&2%%9*&*&D<3(Z>;>O!W#%9<#!W!"#%,4!&4{,236`53(/!&%*&D#K*&%S<9423
73#4%2Zg#%Q;2#23*a%94DK*&=7>NQ2#ZaP2#94DK2##7`%+!W#{!I#<P\23(2#%2Z
#O%95G!Ia*"*&D#b!W#O#<93!W#;N!W#<P\23(2#%T,c4!"4O3(ff/23(D!W53(9#<P\3b7_553(/23(%2>
!W#94%C*I<%%S3(O;2#23a3(!W#;)9453(aP3#{!W#=K39423#%D%2C!&O,D)94D
`#<362*&*"DC!I#<93(SO4;*0_3(!&2#<9!&#K#)42##-rc%aP:4/#<9;%
P	94%2364K%42OD5!&2*gP\3 y XN>
Q4S#25PT%:7;*b*W%%S523O!&%94O;2#23!"#)PT*W%%23(!&/=7D)!W#<P\23(2#%
!W#/<*&/!W#;)53(P;<*\d
iwof5jj

v tbqrX^qt[fi'tbq$rX^q5t [t 

|<>NzgC$L7%PT*W%%2Zg*&aB 7GC97*&2P\3$Y>QRpf2n<omo"n<pt,\  3(;3(!W#;wB
!"%Q94*W%u\x1OM #HIJJIJKH MLRZ,423(:4*"!&23*&%ZMv3(c94%97;<*&%NP:49<7*"2<wBS>
G>Nzg#R7O7#Z{ ; ?  7O3(%3(Z#w$B7OO%NaP*W%%2>
?vP-ABC-E!&%N%Z:4pf2n<om2o&np<tQtw   L  ,S>3>>PKZX{bZ#$YZ<!&%T:]^#)7DD   L  u1
OP\LdBH!"%O:7*&2{!I#94O!I#!&!W*	%;O2#<PT94O%23(4):3(P3$#5-DBC-R94c!"%
:]^#7<DeR#5{R"?$T>
?vPfi-DBC-a`Ibdc-!&%	!W#%Z94cpfnomo&nptQtw `I bdc L   !"%ff94-% `I bc L   1OP\d\ ;    L   Z
94%9365#%!&#P*B$!&%523P\3+,N!&94)#;!&/S*W%R>
 Q94-%97;a**W%%<3(N/Va*"!&{*I<%%2Z!\>>*&;!&2*g#%2#%NPb94!W#!&!W**W%
%2>ffN4cP<*"*&,N!W#;KC5*"!&*"*W%:3%c3N#!"#)P%:7;**W%%2>
! 5 v zg"$x1OXOfiR H OP #KHIJJIJKH L H fiR H OP* #KHIJJIJKH *j H RXR>bN42#gZOP #IHIJJIJNH LR
g
!&%T94Q%97;**W%a\  7*&#;<!I#;O:4N97*&2O79!W#,42#O2#!W#;O94-;*,N!&94
94*I<%4OP #HIJJIJKH L H fiR>-?vP-,-S25*&Dxl1H!W#<P\23(2#7# x l>c#=3(%36u41Z
942#&f  A1fff`Ibd c [  1OXOP #IHJIJJH LR H OP* #HIJIJJKH *jRXR>

 %97;*[*W%A\3(253(%2#<%N93#%(P\3C!&#P#C3(!&;!W#*g;**W% x ,4!&4C!&%N94
J
%9<3(O*I<%)P94)97*&2=B!W#<B#,U%97;<*&%.3(2*&!&$7DM94)!&#,4!&4*&1
94O97*&2EBS>N4O%pf `  [ !&%94O%cP*&*T5G%%!W7*&;a*93#%(P\3!"#%N!W#)%:7;*
*W%%ff,N!&94!W#GO!W#<P\23(2#%-!0P,-N#%!&23Nnovoqvlh^pwbm2o&np<tS7G;<**I<%%2Z94-%( `I `bc   
!&%:4%aPY*&*5G%%!W7*&O;*g93#%(P\3!"#%!W#<K%97;*g*W%%c,N!&94!W#5K!W#<P23(2#%!0PT,-
#*&D#%!&23wYqt.l[t<nw\qutm2o&np<tO7G;a**W%%2> y 3(a*&DZf `   +!&%94O*&%936
PN*&* x ;*WQ*W%%S,>3>2> x O]B#O723a{PQ2#%!&#=#=3(!&#%25%2Z `I `bdc  [  !"%
94*&%936SPT*&*#;!"/< x ;*W-*W%%,S>03>2>K2#%!"#+#3(!&#)%25%2>
?#K3(23-5*&`# y XL#%95235G%!&!&#53(/23Z,-;2#23a!W#)94S53(2536%%!I#;
54%,Q!":4)94!W#<P\23(2#`7G##+`]3(%3(Aw$|!":423N94%Cf `   .3T:4%
9I

fi

 

wyz{

wyz{

 `I ` db c  [  Z25G2#!W#;=#,49423a-DBC-3p-ABC-`IbcK!&%%>)?\O!&%#%2#%!W7*&+)%a$1
f `  [ +3p$m1<"`I `bdc  [  #=;2#94C!I#5OPN94K7_5=53(/237D94!&%%
x %c!&#.<>	N4%Z,-%;!W#]*&23YP#!&#wMP\3b%*&!W#;%ON%97;<**W%%2>
N4Q!"%Z$	13 x f `   "s" `   .3*$s1 x "`I `bdc  [  "sf`I `bdc  [  >
	!W#*&*&DZ	,-O,N#)5*W!W#L4,3S94'$53(253(%%!W#;=#B;O2#:!&#{PN94
!W#5NP9453(/23(%('E!&%T!W#+,-*&*0_%9!&KP3T/236O!W#;S94c!&%9/#:;%-P9453(/23(%2>
 %93(-,N!&94K:45<_,#)53(/23>*@Q%9*&*&D)94S*W%%C$:;2#23+7<D+%95235%!0_
!&#{53(/23-3(!"S;2#23a*72%`%:5!W*&!&=*W%%3(*&!WO!W#B7<D.%:7%95!&#3
3(,36!"!I#;[>T?\N!&%42#S!&`53(77*&S94-94DK2#KP\2#)7G`%KP\3-*&%!W#;K52#{73#4%
PN97*&22#O23L7DB5<_,#=536V/<23k	qvwYqfpwSqvlw\nlw\qvnw\qvl{wYqt)w\no&t:npo'V>?vP%94
Kr!W#=P-*&2)4!W#; x >;[>WZ?\,N#Zb|2}}<N!&%S5G%%!W7*&.,-O3(7*&O.*&%.73#4%
,N!&94!W#<93(!W#;#,%:7;*&%33(!W#;{94.5<%%!W7!&*"!&(D=94a94K3(2!W#!W#;+%97;<*&%
3(K%*&/7*&>B?vPc%97;*&%O,4!&4MP2#=23!I#M:7*&2=2#L7G.%<*"/<Z	94K*"2C%.36.
;O2#%QP3N3(##D#<93(*\> y 3(/23Z%!I#O94O%2<3(4K%42OOPTC%95235G%!&!&#
53(/23Q!0F236%P3( 94cP# y XE53(/23Q!"!&%+7O5M94c!&2#{;2#23O*W%%
,N!&94CP\,!W#<P\23(2#%c94N2#K*&%`73<#4K,4!&4)*&{#*&D+7S*&%7<D<#D!W#<P\23(2#%
,42#M%!W#;B#*&2%2>=Q42#B53(P*&2#;:4%<3(.3%!&2*&*&D36>B)!&#M{P3
O369!&*&+%23(!W5!&#{P	94S%P	*"2C%2>
Q4!W#5	PN%:5235G%!&!&#K53(/23!&%T;O2#`7<DS%97;**W%%T,4!&4`<3(-94N3(%9*&
PT:3#%(P\3a!&#aP#K3(!&;!W#*b;**I<%O!I#<%:7;*&%2>NQ2#Zg94S;<*0_3(!&2#<9!&#KP
%95235%!&!&#{53(/23	!&%N!W#23(2a%+!0P!&%%-%94K93<#%(P3O;**W%%Q!I#K!&%Q!I#<P\23(2#%2>
!W#S94 y X53(/23ff25*&VD%O!0F23(2#<N%2364K%42O!&N2#K/<23(D.!&r<*&D)#c23(9!W#
%25%Q94-94S%:5235G%!&!&#+536V/<23-2##36#%93N7G2%SaP!&%4236!"%!&`%23(4g>TN4
%2364CP\3NO53(P	2#)942#)7G`3(>
	w 
'  5g.g
'95  	=G " )^xE= 2   

fi 



?#M:4!"%C%!&#M,-)<O!W#)94)!W#;3!&#P%97;<*-*W%%!W#<=94K!W#5.%OP%9<_
5235%!&!&#53(/23>NQN]^3(%,-`a%%9OO94*&*b%97;*b*W%%;2#23,N!&94!W#K23(9!W#
#`7G23cP!W#<P\23(2#%`<3(.:4`!W#5%S#,-S;!&/%O`36%9*&%S3(;36!I#;+536P
*&2#;94L#M%2364M3(!&#g>QP2394Z,-K5*W!W#M94)#%%!&(DMPN%*&!W#;B#*&D=%O
%97;*g*I<%%<#+!W#:3((,O%*&!&#{O94%7a%)#K94943(!&!&%2%%!"#g>
v 	Nq5rjlp?la*fixs  3filxrsxs5lIqfisffqp0^q5t+t

 45G23!&#=94!I#<93(M!I#94.53(!W#;%!&#;<!"/<%`3(!&%)94%!&#P
N
,49423O{hgffN>)o"tl<wYq(t:jpm2w\qvfl1!&%.5G%%!W7*&Zff!>>	,494239423(+<3(.%:43(23%95235G%!&!&#
53(P\%`aP94)!W##%!"%2#DLPp$ ^   `    3a$ ^  `I `bc    94<#MP94)!W##%!&%2#DLP#$T>
x  94N,-O2%936S94*"2#;<94PK53(PfR7D)#<!W#;)94O#O723caPT!I#<P\23(2#%25%
,b!W#!">U!W#%O)!W#<P\23(2#%25%.36+#%%93(DP\3O2#O23!W#;M%97;a**W%%.,-
%94*&{93(DK]^#+N,c49423-94%!W#<P23(2#%2<#)7S%:2/<),42#)%!W#;.:4*I<%%2>
Q4!"%K%!&#L!&%+a!I#*&DP:43(!&2*c!W#236%.72<%!I#;2#23*7<_553(/23(%
1#K2#23=O!W#!W*O53(aP%2> y 3(/23ZN7_51536V/<23(%%:*&*"DH523P\3M*&
P##%%93(DL!W#<P\23(2#%2>1?!&%.O3()!W5G3(9<#O=#*&D+,4:4237_5L53(/23
9I

fi

J    J++uM'++'

  +x+~+



'z+++;+{

2#L7G2#:]P3(94+%)aP%97;a**W%%!W#L94KP\3Ph^(f2fN>Kt:n(mqMt:jpm2w\qvflZY!>>WZ
=3(!"#MP:4+#O723P!W#<P2362#%)94+53(/23O#%!W#L3623O{]^#53(P>?O!"%
53(!"2*W36*"D)!W#<23(%!I#;K!&2#<!0PD):4S2%%QP!W*536P	%2364)3(!"#g>
fi  n425b[vsn-DBC	!W3(%*&DZff,-.O!W#+:4)2%K,423(),-)25*&DB2*&2*W%w-ABC-KZ	!\>>	;2#23aG  `    >  
%%:OP3(:423c94#)*&!&(D!"%!W#</*&/=!W#:45367*&2)Z!\>>g%95G235<%!&!&#=33(%95G#%
 x 3(23(-3(%<*I!"#g>

sHl

v

X t w$ tn)t2w-fN>S<f<pl[j)m2o&np<t`lf<wNm9f<lw\nqvlqvlKtj2pno&quw|No&t2w";  $*Nnl[j)o"tw(5|t
n.l[nw\p(nolpst2  tw # nlj0tOsOqul[qusOnogo&t2lwYq.(tfo&pw\quf<l(t>pw\nw\qvflCh^(f2fN>:n>f?$
nlj$ ^   `    T(tht:m2w\qv2tod|  eqt2lTquwqfo&jIa #    
 <f +t:nmq |LwYqt2(tBqnMt2wOfN>llflGi<f<pl[jjBm2o&np<t,$  l[fwOm9f<lw\nqvlqvlMtj2pno&quw|
3;  $  P	pmq)wYqnw-lfKsOqul[qusOnoo&tlwYqKtf<o"pw\qvflt>pw\nw\qvflCh^(f2fN>?>f<?$  ^   `  [ [ qW
_qf<9w\twYqnl=nKsOqul[qusOnoo&tlwYq)(tfo&pw\qvfl{t>pw\nw\qvflKh^(ffN>*>f<"$  
 (ffN>[

|<>  94N#OP3(!&2!"#)%25%c3(S#+!W#{942%P;3(#)*W%% x 362*&*94
*I<%%<3(+%%PS*&!&23*&%9>$Q42#gZ-94+*W!W!&%.:3(!&/!W*c%!W#943(%:*"KP94)]^36%
3(%*W!&#%25KP	24)O!W#!IC*536Pb!"%#K*&2O2#<aP:  `  [  >
G>Nzge|<>$zg,$  7:]^#$7D=$  1OXOP x #  HIJJIJNH  x  QR H O_ x #  HIJIJJKH  x  jRXR>
zg4C127K94K3(23(!W#;=%MP\33(23(L3(%*W!&#g>N42#gZTO!W#!W*N3(%<*I!"#
3(:P:!&#O53(PgP3$  3(!W3(%"C)|c7!I#<3(DP3(!&2!&#%25% x 3(%9*&!W#;O!W#O94N*W%
O_ x # jRVc#36%*W!&#{%25%2>^3(9423O3(Z[!&2#{2%!&*&D7G.3(;#!"94c9423(
3(T!W#Df `   Iff#*&DS*W%%	,c4!"4O#<9!W#*&2%#-5%!"!"/<#S##;!&/T*&!&23a*>
N4%Z##NaP^94%c*W%%ff2#O*&2KSS3(:P9!"#53(PP\3$  ^   `  [  Q!W#*&%%ff94#
X0L|!W#<P2362#%2>

Q2#ZNM3(!&#P9453(PS*&2#;94!&%+*&2%)5%%!W7*"!W#94+;3(#12a%>$N4
x 423(!&%!"253(P%2<3(4{P)36%*W!&#<_7%L53(/23cD+#S53(]cP3( 94.536PT*&2#;:4
3(!&#C79a!I#>Y3YC5*"!&ff!"%N5G%%!W7*&94-*&*^*W%%aPO!W#!W*3(:P9!&#536P
P$4/-%9*&*&23	423(!&%!&c,!&;4<%	94<#S:4*W%%bP3(  `  [  #O,N!&*&*^42#7GN!&/V
7:P\3(:42)>T-#%!"23P\*&*",N!W#;K<5*&d
!g5
  v zg"C12N7G-94T3623(!W#;%P33623(`3(%*W!&#g>	zg:4T*W%ff%$.7G
;!&/2#7Dp$x1OXOP* H * Hj R H O H [R H OPR H OjfiR H O[  RoR>N4-423(!&%!&C7336%95#%bN:4TT?\	
423(!&%!&>ff^3(:423O3(ZP\394-]^3(%({)!&/V!"#O%25% x { ; ?  H {51}Z3(%*&/2#%TPg94-,-
O%S3(2#*"D=!"/=*W%%`3(53(:P\233(M7D57+>N42#gZP\*&*&V,Q!I#;{*W%%`<3(!&/V
7<D.9453(/23 x !W#K94!&%N3623d?OP* H * H_ R H OP H R H OP* H  HK R H OIR H OP HK R H O[fiR H O  R H O  R H c>
^369423O36Z!0P:4`%:7;*b*W%%P"f `  [ +3(O!W#%23(=724!W#M94O3(!&;!W#*	!"O%94
53(/23-,Q!"*&*b]^#94%9OO3(%*W!&#3(:P9!&#{53(PP\3$ ^   `  [  x E<#{94`536P
%2364K%#<7G2#:]cP36R5%%!W7*"53(P	*&2#;94+36!&#g>

92

fi

 

wyz{

wyz{

!W#94S7/c5*& x %95G!Ia*"*&D{944<%2#)423(!&%!&2Q!"%Q%O,4a#936!"/<Z!&N2#
7 K5MP\3SC#DM53(7*&2O%O94*I<%%P3(f `  [ ,N!&*&*N7+!"/>?#94!&%O2%
9423(Q!"%N*&%S#;3<#Q94	94536Pg%23(4O!&%-!W53(/.7G2%c94N%97;**W%%-2#
!W53(!&!&#*	3(##D>
-DBC-R!0F236%('A5<3(NP3( 94O*Wr)PffP3(!&2!&#<'$!W#*&D+!W#944#*&!W#;PTa*"!&(D
P3(94)%95G235%!"!"#L2*&2*W%2>1?#L94)2%.94a`*&!&(DL!"%C!I#</*&/!W#M94+53(7*&2)Z-
53(P	*"2#;<94+3(!"#)/2#CP\3-;36#)*W%%c!"%#N;3#<>

 sHl W  ft:nmqB(tfp(m9twl |wYqt2(t+q)ntwfN>(fplj=plqvwt_pn<w\quflGA$; 

$+kqt2(tKwYqt)sOqul[qusOnobpht2hfqvw\quflM(t>pw\n<w\quflh^(f2f>9C>fg$ ^   `  [  n(t)l[fw-jqf:w\t2wYqn<l
sOqul[qusOnoh^(f2fN>:*>f<?$ 
 (ffN>[ffzgaC12`7G94c3(23(!W#;.%KP\3ff%95G235%!"!"#g>N-#%!&23-94c%-P#!&ca!&#%
$1OoOP1R H OP  # x E1
  [ # x jRXR>  )%%:O.:44C12!&%%1%#M3(23(!W#;P\3
%95G235%!"!"#g>N42#gZO!W#!W*%95G235%!"!"#.3(:P9!"#`536P[P3$3(!W3(%T(,-c!I#<P\23(2#%2Z
%95235%!&!&#{%25!W#<G  # x p1
  [ # x T36%9*&!W#;.!W#K94!W#!&#x [ # x p13
  [ # x Z

`

#942##*&!&(D=3(%*W!&#{%25g>?#+:4`%af  [ +3(O!&9423##<_#!&S*W%%,c4%
3(:P9!&#C3(!W3(%cT*&2%N!I#<P\23(2#%N3	94#!&%*1OXO v x p1
  v x jR H O x *1 x jRd
5ymzamw| H Ety,$|R>!W#.94K3(:P:!&#P?$ ^ @*&%3(!I36%`)!W#<P\23(2#%
3(!&#P	94S53(P*&2#;:4)!&%!W5G%%!W7*&>

?#=%:3(D={3(!&#MPN94)423(!&%!&)%2364P3S+536PN2##<7G.;3#<B7G:_
2%K94.536Pc*"2#;<94BC2D=#O7)3(!W7*&ZT94K%97;*T*W%%D=7K!&;#3(L7<D=94
%95G235%!"!"#=53(/23Z3N94%97;a**W%%SC2DK!W53(.O4{!&!&#*T3(##D>
N4,-O*W23c5<!I#<%*&%)4*&+!W#{94S;36#+2%,N!&94c*&!&(D+,4236`N*&2%536P
*&2#;94{3(!&#)!&%c;3<#>
Q4%#5G!W#ff!&%#S3(2*5367*&2%!I#:'$%T3b5G23(!WO2#%%:4V,-'$%9*&*&D`%:7;*
*W%%ff,N!&*"*g7a!&/V#C,N!&*"*g7-!W#/<*&/!W#O94N%23(4`536%%	aP53(/23>bN4N3(!&%9r94
%97;**W%%<3(S!&;#36=2#=7G.O!W#!WO!&7<D%*&!W#;+%95G!Ia*"*&DM%94%97;a**W%%
,4!&4,N!&*&*g9rN536T!W#:4N%23(4O,N!&94KS4!&;4K53(7<7!"*&!&(DZ>;>*W%%,Q!":4.c%9C*&*^423(!&%!&
,-!&;4S36;3(!W#;K94423(!&%!&PN%95G235<%!&!&#B536V/<23>?#{3Q%*&!&#B536%%,-O#
#%S%94+P\2%3(!W#;.C945G23(!WO2#<9*	3(%9*&%2>NN4c]^36%<#)94!W3(5G!W#%94,
%`:43(!&2*	,-2r#%%%O7!I###!&#,N!&94=553(53(!W3(*&/V#D<_7%L%*"!"#
4#!&%,-S*"7%23(/S!W#53!"943(%:393(!W#;KPT94S%23(4)2%7D+%!I#;
%97;*g*I<%%a*"*&,N%53(P%Q7P\#KP%23>
fi n425b[vsn-DBC-a`Ibdc

#*&DZ,-NO!W#94N2a%,c423(,-N2C5*"D:42*&2*W%C-DBC-a`IbdcZ!\>>;2#23C `I `bdc  [  >
N42#gZff/2#P3;36#B*W%%#O#<9!W#!W#;=*&!&DM!&!&%.5<%%!W7*&+94OO!W#!W*53(P\%
2##c7S%:43(2#),42#25*&D!W#;K%97;**I<%%2>

sHl  eqt2(t=qntwOfN>+(fplj1mo&npt0$@kqt2(t=lfsOqul[qusOnoco&t2l<wYq1(tfo&pw\qvfl
(t>pw\n<w\quflCh^(ffN>*>f<?$ ^  `I `bc     qjqf:w\t2wYqnln.sOqvlqvs`n<o^o&tlwYq)(tfo&pw\qvfl{t>pw\nw\qvflCh^(f2fN>
>f"$ 

9I

fi

J    J++uM'++'

  +x+~+



'z+++;+{

 (ffN>[ff-#%!"23Q94cP\*&*&V,Q!I#;K%"$=Pb*I<%% x ;!W#K,-25*&DC12d
 OM H M ,IH M[RZ
OPM :PH *M , RZ
OP*M  H M  RZ


OPM H M ,IH *M[RZ
OPM :H *MRZ
O*M  H *MIRZ OPM H *M H *M , RZ 	
OPM # H M  H *M : RZ OP*M # H M  H *M : R 

XTa4)O!W#!W*	3(:P9!&#)536PbP\3ff94!&%%c3(!W3(%}3(%*W!&#)%25%2Z>;>Wd

$&1  

| H  fi OPM H M ,PH MjR
ff 
H  fi OPM  H M , H *M  R
ff 
H  fi OPM :H *MIR
ff
H  fi OPM :H *M , R
ff 
H  fi OP*MY H *MR
ff ~
H  fi OPM H *M H *M , R
ff 
H  fi OP*MY H MjR
ff 
H  fi OPM #H MY H *M : R
ff }
H  fi OP*M # H M  H *M : R
 ,SZ!&4*&%2d
ff

|2
ff ||
ff |2
ff |2
ff |
ff |2
ff |2~
ff |2
ff |2
ff

H U
H U 
H U 
H U
H U 
H U 
H U
H U 
H U 

T x| H
T x~ H
T x H
T x H
T x H
T x H
T x H
T x |
T x |2

 fi
| fi
| fi
||2 fi
| fi
| fi
} fi
H |2~< fi
H |2< fi

OM H M , R
OM  H *M  R
OM :H M , R
O*M  H MIR
O*M [R
OM : R
OM  H *M : R
O*M : R


OP*MY H M ,IH *
 MRZ OPM #QH *M :H *MRZ
OP*MY H *M H *
 M, R

 42#2#O23!W#;a*"*	53(P\%NP\3?$ ^  `I `bc     #O2#+3(<;#!&`:4N94OO!W#!IC*536P
*&2#;942##7G`3(>

?#E942%,4236=a*"!&(DE!&%+!W#/<*&/$!W#E3)53(P53(7*&2O%2Z,-79a!I#EM943(2
#*&;<%NO94O53(/!&%c#d
 `I ` bdc     
1 

OP*MY H M ,H M RZ
OP*M #IH *M :H *
 MIRZ


sHl   fTt:nm[q(tfp(m9t?4$|SwYqt2(tqNnt2wf>plqvwtj2pnw\qvfl$BkqttcwYqtcsOqul[qusOno
pht2hfquw\qvfl(t>pw\n<w\quflCh^(ffN>9*>f$ ^  `I `bc    n<tClfwY_qf<9w\twYqnl=sOqvlqvs`n<oh^(f2fN>:*>f?$ 

 (ffN>[ff?#{#*&;DKN4362U>>
 S2#{3(;#!&O94QP3C-DBC-a`IbdcS:4`3(%9*&%S<3(S%%2#!W*&*&D+:4`%:O`a%-P3C-DBC-.>N?#
;2#23a*T94)3(!&#PN94)423(!&%!&)%23(4P353(PN2##O7K;3<#L#B536P
*&2#;94%D#<`*&,ND%S7G3(>{?#M53!&Z	4,/<23Z,-*&L;!W#7%23(/:4S
3(%:393(!W#;OP94c%23(4O2%)7<D%97;a**I<%%NP\2#*&*&,N%N53(P%ff`7GNP\#CPa%23>
?#K94cP\*&*",N!W#;,-%!W5*&D+%%9O94-!W#<P\23(2#%,Q!":4K%97;*g*W%%3(S#<O!&
7<D1=%95G235<%!&!&#$53(/23Zff!\>>ff9494DE3()!W#</*&/E!W#1:453(PS%2364g>  ,N#<
2*N!W#LO3()9!&*N,N!&94M:4+53(7*&2aP!&2#!0P\D!W#;L%97;<*-*W%%K,4!&4M2#M*&2=
*W3(;3(!"#+aPT94O%23(4{:F3(#=4,,-O2#:.!&2#*&D%*&S%:4{%97;**W%%2>
N4!&%53(7*&24%7G)9r*&M,N!&94M423(!&%!&%%!W#)9423(C!"%6'A%O,-.4/O!W#'A#
9436!&2*;3##*&%.#.94)!&`,c49423-%97;**W%%3(S%:P*\>
W< 	+rt[	w+ljsA;qgu^q5t+t
X	/<2#=,42#M%!W#;=%9C*&*3(%3(%,=94C%%0  `  [  #= `I `bdc    2#=7GO)!&.*W36;>
N4%2Zff!"C!"%K#O%2#%!W7*&!W#<;3a+*&*-%97;*-*W%%CP3(f `  [ 3A"`I `bc    !W#=94

9

fi

 

wyz{

wyz{

%2364O%9NaP%95235%!&!&#<_7a%53(/23>?#;3!W#;O#<DO*I<%%%9*&*&D%N#
2#<9!&*P/37*&36233#;<2O2#ffP	94%23(4)72%94423(!&%!&;<%-*"<% !W#K94S4;
#`7G23NaP*W%%c,4!&4)2#)7GS23(!&/{P3(R#<D.%:7;**W%%2>?N!&%42#3(2a%#7*&
M/*&54#!"%)P\3]*&23(!W#;L%97;a**W%%):4<5523K2#9a!"*S*W3(;{;!W#!W#
:.!&2#DP3)%95G235<%!&!&#153(/23!0P94D=2#7+53(/2#g>+Q4S!&%2Zb,-<3(!W#23(%M!W#
]*&23(!W#;L(t2o&t2nlw-%97;<*	*W%%2>Oc%`a*I362D+%236!I7GL!W#=!&#=Z,-`;<2#23{t2wNfN>
pfnom2o&np<tcm:nljqvjnw\t#942#,-N%*&ff%O-%97;**W%%	P3(J94!&%T%2>	N4N4%2#
%97;*T*W%%36.M+94C%23(4=%9OPN94)7_5=536V/<23>)?#94P\*&*&,N!W#;Z
,-O,N!&*"*-c]^3(%c!W#:3(K%`236!"23(!WCP32%93(!W#;+:436*"/#D=PK*W%>N42#gZ,-
%94*&*	!W#<93(`(,-K4#!&%cP3N;2#23!W#;)%97;a**W%O2#!&%`#2*b,N!&94{94
%*&!&#{P36*"/#<%97;<**W%%>
fifi! <n#"%$pWW'&1bgn($p2

-,-!W#4323(!&%!&%	P%97;**W%%	2##:3(!W7-c%95G_5OP94-53(aP^%2364g>
	!W3(%*&DZ%!W#3(!W#;K.!&#>W|%97;**I<%%!W#<93(!&!&#*	3(##D
!&-!"%Q!IC53(:#-94aT%Pb94*W%%2#K7S536V/<2#!&2%!&*&DZ94ff!&%O3(c2%!&*&DK94#
94K3(!&;!W#*-;a* x %9>)?#3(23{%!WC94!&%2Z	!&O!"%#%%:3(D=C6;<.,4:423S:4D=2#
h^(fnod|)tCfo&2t:j),N!&94{944*W5PT*W%%PT94O!W#5S%2> y 2%936!I#;)%!I!"*W36!"(D=7(,-2#
{;*N#L<9423*I<%%.,Q!":4M94)4#!"%K/*&5E7DM2#!W#;23#Lg4% x |2}}Z
2#!W#;23Q*\> x |2}<}Z<3-^4% x |}}-D.7GS,-*&*_%:!"+P\3-:4!"%c%!Wa!&#g>
#*"DZN{%<*I!"#LP#,N*&DL!W#<93(1%97;*-*I<%=jqfpo&j=lfwno&k	nX|tlw\nqvo-n
fo&pw\qvfl=fN>Onl=f:q&qvlnogfnok	qvwYqqul>tk1w\t(h[`fN>OwYqtpht2hfaqvw\quf<li6nt9jh^(ft2:>N?vP:4!"%c,-23(
94c2%N:42#94Q!I#<;3!&#CP#,1%97;**W%%-,-*&)#53(O!&%O4O;!W#g>TQ3(!&23(!W
!W#3(23)%!WaO94!&%`3(d	!I36%*&DZ94C93#%(P\3C!&#)aP#3(!&;!W#*T;**W%.!W#<+
%97;*g*I<%S7DK# y XL53(/23ff%94*"+4/72#)5G23P\3O+7<D.%!W#;.<#D!W#<P\23(2#%2Z[!\>>
%94*"L7C!&)4!&;4g>)N42#gZ%*W!&#P)#,%97;*ff*W%.%9a*"*&D=%#2#<9!&*
K%*W!&#P#{36!";<!I#a*T;a*,N!&94!W#{P\,%25%O72%9453(77!&*&!&(D=!&%`3:4234!";494
O7_5K53(/23ff2##('E`!&%c423(!&%!&S%2<3(4<'E!&r*&D)3(#%:3-94!W#<P\23(2#%
#1!W#<P\23:4.36!";<!I#a*N;*\>L#*&DZ-!0P:423()!&%.{%97;*-*W%5\$#L%.P
949<7*"2<K*I<%%aP94:7*&2wB4/SO4!&;4+423(!&%!"O,-!&;4<N,S>3>2>94S4236!"%!&SP	94
%95G235%!"!"#<_7%+53(/23Z4!&;4;!W#OP:.!&2#D2#7G5.!0P9453(/23b2<#.53(/
\	>N4!&%S!&%O):4SP94a!I#<P\23(2#%#M)!W#<P23943(!&;!W#*ff;*	%!W#;\13(
!0.2*&cP3T:4S%95G235%!"!"#<_7%=53(/23>
fifi*)

 vg',`[vnMn-E[uL.&Mbgn/$#a2

&+&

? #3(23c);2#23K%P-!I#<23(%!W#;+%97;*	*W%%S!&!"%!W5369#<94c,C25*&VD
*W3(;c3(%3(P3b;<2#23!W#;S%:7;**W%%>	%ff,-4/N*W3(2D!&%2%%Z%:7;**W%%
94O3(;<2#23=,Q!":4B%9*&*N#O7G23PN!W#<P2362#%=#`53(O!&%O4;!W#M72%
K7_553(/23cD)2%!&*&D3(#%9394!I#<P\23(2#%#=K!W#<P23c:42)>N,-/23Z
!&S!&%`#<S5%%!I7*&K);2#23a*&*T%97;**W%%u" `   )3pf`I `bdc  [  P3K%9<.!&2#*"D*I<3(;
3(%3(A.a%%:7;*g*W%2#!&%72%S94!W3N4;#O723QO2#%-94-94%%TP
;2#23a!&#)#)!&!&#*%*&!&#{3(c4!&;4g>ffN2#Z,-O%N3(%93(!&N3(%*&/%-%
P	%97;a**W%2#!&%94aN!&%SKp:t2w-aP(  `  [  3" `I `bdc  [  Zfi%9<.!&2#*"D{*W3(; x %
!&#{>
_2

fi

J    J++uM'++'

  +x+~+



'z+++;+{

	!&;3(Od	?#<P\23(2#:_7%;2#23!&#KaPYO%aP%97;<**W%2#!&%
3]^3(%-/V36!I<#2Z[#qul[>t(t2lm:tinat:jO94Z%9<3(%N7DK;2#23a!W#;%97;a*^*W%%NP3(
  `   [  3 `I `bc    P\3Q39423g*W36;3(%3(f#S%5%,42#10 2 %:7;**W%T2#!&%
3(;2#23>SN4/V<#9a;SPT:4!"%S94!&%94c!&!&%S/23(D)2a%D+#2#7:K!"2#<*&D
!W5*&2O2#<>7*&2E3({2#O231,Q!":41]E%93;DP3O%*&!W#;L%97;a*"%KP\3
!W#<P2362#% x %9a*"*&D*&:P6_O%9a2594<_\]^3(%9c#{P\3N2a497*&2!&%c%97;a**W%C!"%%3(>
N4)!W#!"%:/V#<9;<.PN94!&%O94M!"%O94aSK+94C]B%:3;D=#M94*&!WO!&P
94=#`7G23KPS%97;*N*W%%2Zc,-+#*"DE7:!W#L%97;**W%%),4!&4$<3(+!W#<P\233(EP3(
;a**W%%7D)5#!W#;+53(!&2*W3Q%97;a*"%c,N!&94{*W3(;<`#`7G23NaP!W#<P\23(2#%S#+<9423
%97;*&%S,N!&94#*&DB)%:*&*#O723PN!W#<P23(2#%> x K*&%	!";3(.dOc/V*&%.<3(97*&2
!W#E{]^#!&%;O2#<P94+%23(4L93(xrKZff94+*&!W#%+3(253(%2#K94kJ3(*W!&#g>H36DLV/*&%
3(253(%2#2#O23:7*&2^Zg!\>>g:4!I3%97;a**W%%S<3(O%3(Z[,4!&/*&%S3(253(%2#<
97*&2),c4!"4+<3(S#N2#O23>ON4%Z94`94)!&%c%O,c4N#!I#<*&*&!&;2#O72%
#=!W#<P\3!"#L7C94.*&!&(DLP94)93#%(P\3!"#=P#M3(!&;!W#*N;<*-*W%)!W#B
%97;**W%O!&%%>N-23(9!W#93#%(P\3C!&#%36cP/36+;!W#%N<9423(%c#*&D)`94
#!W#<P3O+%:7;*%*"!"#)%93;D>
3c%#/V3(!W#<2Zb#=nj<n:h^w\qv2t+O:4Zg936!"%./23(OO94%O!&%9/V<#9a;%!W#94
P\*&*",N!W#;),ND^dff?#%2a+P5G23O!&!W#;+O36!I#<P\23(2#%,42#);2#23!W#;.%:7;*b*W%%c
#=#!W#<P3OM%97;*ff%*&!&#%93;DZ,-,N#<a*"*&,3(!W#<P\23(2#%.23(9!W#
qvlw\t2(tw\qvlhfquw\qvflGaP94S%23(4K93(ArHP\3N;!&/2#K%NP	*W%%g$T>
?#{9!&*\Z355364+!&%S%cP\*&*&,N%2dNQc]^3(%2Z[,-`;<2#23*&*b%97;*	*W%%a  `  4 3K 
30 `I `bc  4 3K  ,N!&94B36%3(x # ,4!&4L!&%)%9a*"*&23C5361M94K]^3(%K/V<3(!W#>$N42#gZN
]#`7G25
3 076 b OaP%97;<*g*W%%c!"%c4%2#K,4!&4+53(!"%S94S4!&;4%Q;!W#)Pb:.!&2#D
3(;<3(!W#;S9453(/!"%*&D.O2#<!&#)23(!&23(!W> y 3(N*&DZ,-N4%N%97;a**W%%-,4!&4
3(SC!Wa*^,>3>2>O%*"!"#KP#!&
# 8c>	#`5G%%!W7*&3(2*&!&2!&#{9
P 8!&%2d

8

8

x \g*1%:

#<;=

x \^?>@:n ; a x O7 x -`-d-!&%97*&2*W%S!W#&BaRV
x
x \ H -`ffd- ; $ H  -e1|RV
>':
:5; C OPTzBA

Q44!&;423O:4+#O723P!W#<P2362#% = x \gS,c4!"4L3(+#L!W#<P\23,\TZY944!&;423
x \g%94*&L7>KN2#ZC: # %94*&L7.5G%!&!&/>)!W#;(:nw)!&%O*&%+%2#%!I7*&>+?PN9423(
_

fi

 

wyz{

wyz{

	!&;36`dbc5!&/S;<2#23!&#KPTO%QP%:7;*g*W%2#!&%
 3(C97*&2*I<%%!W#BR,4!&4B4/K4!&;4M423(!&%!&),-!&;4<`3(;<3(!W#;:4423(!&%!"47P
94%95235G%!&!&#<_7%536V/<23-,-S2#<'$%N*W3(2D)!&%2%%'E;!W#O*&cP:K!"2#D>cN4
P#!&#TIDz AO2%93(%,c49423c*&!"23*&%P3(\L2#53(7<7*"D=7G`%*&/=,N!&94#!&S*W%%
P3($T>E?\)5%.M5!W3aP*W%%)B=3(2*#`7G23>EN4+*W3(;<23GTBz A x \ H -`94+*W36;23
94%!WO!&*W3(!&(D7G,-2#ff\#E94=#!&)*I<%5-.>  =!&*&!"L/V3(!W#<KPS94{P#!"#
T F	,c4!"4K!&%-:]^#+7DO2#!W#;23N#K^4% x |2}}agP\3ff5*&!&%94!W#;.:49a%9r>  c%
E  {  G
:
 :na@
 : : 1OO94S!W#23(2a%!W#;./;2#%%cP	9423(!&23(!W>
# @
 H%JCKMLONxm" `  4 3N 1
3 H%JCKMLON4mf`I `bdc  4 3N  7K94%PN4%2#=%97;<*T*W%%2>
 ,SZ*&I
N42#gZ,-N;2#23aN%97;**W%%N,N!&94CS3(%3(Z  7-25*&VDC94N*W%%ffP3(
 H J KMLONN%
%9<3(*W%%P394ff%97;a**W%T2#O23a!&#g>  T2*&*94T%P%97;**W%%	;2#23
,N!&94M94!&%.94s  `  Q Pj  RTS KOLMN > x #%!&23*&%=	!&;36d)N4)<L*&!W#+%94,N%O,4!&4
%97;**W%%-3(	;2#23aO,N!&94S3(%3(C # >	N42#%OTaP942<3(T%*& x 7*Wrc/*&%9
#.%.%	%9<3(!W#;S5!W#<%	P\394N;2#23!&#OP#,L%97;a**I<%%T,N!&94C3(%3(p>ON4
3(%3(#  %94*&);!W##-7NO4!";4!W#C3(23	S*&*",EcP%	2#O23!&#CP94N%:7;*
*W%%2>cN4O%cP%:7;*b*W%O2#!&%!&%c942#{;!&/2#+7<D4  `  4 3K  ^   `  Q P  R S KMLON x !P
,-25*&D-DBC-`c3`7<D5f`I `bdc  4 3N  ^ " `   P_  RTS KOLMN x !0P,-25*&D-ABg-a`Ibc>N4%Z%:7;*
*W%2#!&%3(c#C94#4#+*&*g%97;*[*W%%c23(!&/),N!&94KS2369!W#)#O7G23C #
P-!I#<P\23(2#%O%9494!&2#7.%%9O=94a94K53(aP*&2#;94!&%O3(>.#:4`<9423
4#Zg,-`4/%O%97;a**W%2#!&%,4!&43(23(!&/=,N!&94{.4!&;423#O7G23NP
!W#<P2362#%2ZNO%f # >t  >	N4%c%97;*g*I<%%53(!"%O4!&;4K;!W#CP:.!&2#D+72%
94D3(O23(!&/P3( %97;a**W%%%*&=,N!&94P#!&U
# 8>N4a!"%Zg94D36`236!"/<
P3( *W%%,4!&4L<3(.#%!&23(L=7K/23(DB36*"/#<OP3S{%95235%!&!&#<_7a%1943(2
53(/23>
[3	%*"!I#;K%97;*g*I<%%NP3(94%-P%:7;*g*W%2#!&%N,-c25*&VDCP#:_
!&#0',c4!"4!&%T!W#*&D7a%O#94ffP#!&V
# 8Y'A<#%*&T*W%%	,N!&9494N4!&;4%	,-!&;4<
3(;<3(!W#;G->(M!&%N:]^#=7D
 x \*1W8 x \^*(X x \ J

_Ih

fi

J    J++uM'++'

  +x+~+



'z+++;+{

X%!W5*&DB#%{,-!&;4B%9Pc94#O723P/3(!W7*&%!W#s\$#M(,{!WO%O94
#`7G23-PbP#!"#K3-53(!&2S%DO7<*"%Q!I#E\	>TQ2#Z!&Y;2#23a*ZC%97;*g*W%%c3(
53(:P\233(>TQ4!"%c!&%%2#%!W7*"7G2%S:4D.2#{%9*&*&D+7%*&/3(c2%!&*&D>

	]\ M  L[_^c$Q^fi *` 	T[5aOfi$fi 
[

fi 



?#94!&%S%!&#,OO!W#943(!&2*T#=53!"2a*%95G%#23#!W#;94O!W#;3!&#{P
%95G235%!"!"#<_;2#23*"2C%c!I#<:4S!W#5%NPCO*b*&!WO!W#!&#=53(/23>TN]^3(%2Z
,-53(%2#%O36%9*&%36;3(!W#;53(aP*"2#;<94S#%23(4S36!&#%2>b%	7:P\3(Z,-O2a%93(
9453(P*"2#;<94)7DO94#`7G23ffP!W#<P2362#%N!W#K!">  3(P%23(4!&%NO2%:3(7<D94#`7G23
P-!I#<P\23(2#%:4536V/<23`%`523P3!I#3(23cK]^#)53(P>.N42#gZ,-!W#936%O
O94%-P\3N36*"/#D<_7%{]*&23(!W#;.aP*&2a%2>
v lI#*fixs  	Nqrj


 4 2#.a!I#;K5%!&!&/#!&N*&2%?$:{PO7<_5C53(/23	94!&C!&2!&#$+P
5<_,#K53(/23ZO53(P	*"2#;<94)3(!&#!"%c5%%!I7*&!PT:4NP\*&*&V,Q!I#;K%!&9!"#K23(%>T?vP*B
!&%Tc97*&294T36253(%2#<%536P^<#GTjS!&%Tc*&!&23*,4!&44%TQ2594O%9C*&*"23b:4#0{CK|TP
S73#4C!W#wB1,N!&94C25944{,Q2#.369453(P*&2#;94C!09
P b*Tj!&%N#!0]^7*&S,N!&94K*"2C
M ; $ * >Q2#Z[,S<3(!W#236%+!W#94S%!&#P,c49423-,-2#K]^#{*&2%%:P*!W#
94%23(!W7L%2#%K!0P,-4%0$	*l1S: x OI-d-!&%P H - ; )/. v RV%`5365%=!W#
!&#>p@#<P\3(9#a*&DZ/2#{!0P*%*&%S*&*bPa%N!W#tOI-Ud-!&%`P H - ; ) . v R#5z
!&%<37!&933(DC*I<3(;9423(!&%#;3#94a,-2#C]^#%:P**&2O!W#94!&%N%2>TQ4!"%Q!"%
/2#93!0P:4`7<_5)536V/<23T2C5*"D%P!W34236!"%!&>

sHl v  fOt9n<mqez ; d c wYqt2(t)q`nm2o&np<tt2w$vSnl[j+nD>nquDqtp:qw\qvm07,vpm[qwYqn<w
lfhfquw\qv2t{pl[quwo&ts`sOn/>(fs),. v vtltn<w\t9j=|nM(tfo&pw\qvfl{h^(ft2Kw\n9w\qvlk	quwYqE$v`nl[j
t2sQh^o&fX|qvl/qtp:qWw\qvm#7/vY.m9nl{(t9jpm:t`wYqtch^(f2fN>So&tlwYq)fN>Snh^(ffN>*>f<"$vNk	quwYq,-DBC- -ABC-`IbcQ 
 (ffN>[bzgz7-N#93*#`7G23<#,C12N7GT94	3(23(!W#;%P\3g3(236S3(%*W!&#g>b3
*&!&23*M(ZMK2#<%T94c#O723YP^%DO7<*"%ff!W#,M(>$	v1OXOj x jR H O x  H  x  x R H OP* x jR H
OP* x  H  x QR H OP x :jRR>^zf7/v x OM #HIJJIJNH MLRV*%
1 e L # V
7 gv x M h  Z<,N!&94 M h  1M  Z!0P:M  !"%N5G%!&!&/Z#
f
hM
y
 1 b M  Z9423(,Q!"%> 3(/23Z
MK
H M#i  x F H FT!&%23
7 vg x M\
1 
 >ljz >MK H #M i3 x F H FT!&%O23)>
5

Q42#)!&4<*"%d-3N]53<O23pzZ7,v	!&%SP!W3c423(!&%!&> y 3(/23Z9423(O3(#*&D
y =
X 53(P\%	P^94Q!I##%!&%2#DP$	v[,4!&4C#<9!W#*&!"23*&%-,N!&94O5<_%DO7<*	>),. v #<9!W#%
#*&D=*&!&23*&%,Q!":4=5<_%DO7G*nZb94;4g>+Q2#Z	!&`!&%O!W5<%%!W7*&+94O)*&2{PC) . v !"%
55*&!&27*&>

g3(943(!&2*g5!W#<-P/!&,E,-4/;a!I#94#;!"/<3(%:*"ff94ff!I#C;2#23a*^%:P*
*&2%3(S#<N*&2O2#%P) . v >TQV,-/23Z2C5!I36!"2a*%:!"% x %S!&#+<N3(/2*g94aN!W#
94O%2%%%:P*	*&2%S<3(S;2#23=7D+C%95G235%!"!"#B53(/23>Q2#Z,-`%%9O
94K%:P*c*&2%)3()!W#$	*#142#:P\3(94!I#,4!&4L*&2a%('A7G!I#;15<3(PS
53(Pv'2#C*&2+K4!&;4+53(P	%23(4)3(!&#PT# y XL53(/23>
_I

fi

 

wyz{

wyz{

W lIafilxrs  	Nqrj


N4O:F%3(;3(!W#;)94S%9393(PT94%23(4)%95a`aP,-DBC- x -DBC-a`Ibdc2c53(/23-2%
7<D`:4%cP*&2%-3(N*&%*"D)3(*WK94Spw\quo&qvw|Nhgfo&t2s x >;>Z y !W#<#gZ[|2}}P3(94
3(2caP^5*I<#!&#<_7%K*&23#!W#; x XT-z	<#.23(5233*&23#!I#; x %*&% y 3r/!&4
H2Z[|2}}>Nff94-]^3(%ff%!&;4<2Z*"2CS%c*&+7c!W#2353()%T!W#<93(!W#;.#,E;%
!W#943(!&;!W#*%23(4K93(arR72%S%97<_!&# x 53(PPT*&2-2<#)7`36
#Q!I#<P\23(2#S7<D55*&D!W#;c*&2>TQ4!"%ff33(%:5#%-Sa23(5233b*&23#!W#;O3	Xffz
,423(c!W#<P2362#4!W#%N3(c;2#23a*"!&+#K!&%\#!&/*&D)%3(K%#,E5G2336%	3	#25
%23(!W5!&#% x >;>Z y !I#<#gZb|2}}<Z3(%:5!&/*&D>  O%94*"=#!"Z4,-/23Z[94Q94%SP
*&2%-%N#-#*&D!W#%23(N#,E;%N7a*"%#,l[f2jt!W#<O94c%23(4O93(>ffN4!&%O%
P3(R94Pa94aN94S%9393(PT9<7*"2<xB # ,4236`C*"2C!&%55*&!&=!0F236%cP3(R94
%9393(cP#!W#K:4235<3(%T*g97*&2/BN,c423(:4*&2O53(P!&I
% 5#j >TQ4!"%
4%#!W#oi^2#+#94K!I#<P\23(2#%.5G%%!W7*&+,Q!":4B # #=B x 94K;%O;<!W#;+P3( 94
#%AF # #F:4<3(O*I<7*&=,N!&945B # #xBZg3(%95!"/<*"DO7!&S4%S<#+:Fc#{94
/Va*IOO5*&2#%%7G#4$%%!&;#%N`:497*&2g>T-#%!&23(!W#;K94S7#%!W#<93(
!W#B!"#BZB # 2#=7G.2#O23=,N!&94M+3(%3(/Va*I),c4!"4!"%%9*&*&2394#3c*
{94`#L+2#O23wB2>?#M#*&;<D=C23(+5233*&23#!W#;=#M#%!&23(!W#;
94%)3(2<3r%Z,-)#,%9C3(!&)94)/V#<9;<%`#M!&%9/V<#9a;%OP%!W#;*&2%+qvl
m:fll[t9mw\qufl{k	quwYq)qvw\t2(nw\qv2tOjt:t(htlqvlh^(f2m:t9jp(t>
$O!W#3ff/V<#9a;-P!I#<93(!W#;*&2!"%-94c/V#<9;<aPYj<t9mt:nqulffhn<wYq.m9fawvZ!\>>
94%%NPT3(253(!W#;)94!W#<P23(2#%S#{P\3-!&%536P>TN4O(3ff/V#<9;<PY%!I#;
*&2%Q!"%c94Q94DCrSK(tw\9pm2w\p9qvlfN>SwYqtwYqtt9n<m[q.hn<m9thf:q\o&t>
#94-#c4#Z#N2#%9/ff945G%%!W7*&D4!";4O%23(4:F3(	#OP3	53(/!W#;S%:P*
*&2 x a%%9O!W#;+:4`*&2C)53(aP2#7C5#,N!&94!W#=94]^#!&%;O2#<PfrU7G
#%!&23(>T#:4:423T4#Z!&-!"%N5G%%!W7*&94-*&%K97*&2C2#K73(24.,N!&94!W#K
%9a*"*&23N36%3(c/V*W x :3(%3(3(!&k# >TN42#gZ94S3(3(23(!W#;O:F%%:*&*"D)*&*&,%
%*&/`53(7*"2%94a,-23(O53(/!"%*&D+NaPY3(2a4)7G2%O94%2364{53(36S;%Q*"<%
!W#:4 x %9*&*&DK5G#2#!Ia*"*&D-*W3(;23Y%;O2#<	P94c%23(4O936N:]^#7<D*W3(;<23T3(%3(>
?\-!&%-*&23Z4,-/23Z<94T:4!"%N/#<9;c#*&D.4*&%N!0P94c%;2#-P94c%23(4C93(c:]^#
7<DS94-*&,23	36%3(-/Va*Ic!&%T#	!W#23(2%CSO4O7D94N%NP94Q*"2C%2>	-#%!"236!I#;
3b%2<3(4O7G#%-,-2#%-94T#3C*&*"D3(%3(3(!"#%T2##T7GN;3#`,c42#
%!W#;)%95G235%!"!"#=;2#23*&2%c!W#=# y X536V/<23>  42#=%!W#;)94O!W#<P\23(2#.7#
M3(%3(=3(!"#1!&%);<3#<1!0P7<D1%!W#;L*&2%+M53(PS*&2#;94E3(!&#A2#17G
79a!I#>?#{94S2a%OPT94O2594#,-!";4_25:47G#=!W#{;2#23*	#c/2#.536P
*&2#;94{3(!&#)*&2%c3(%3(`36!&#g>
ff%!&%:45G%!&!&/+:F%P%!W#;=*&2C%2Z	%O#;!&/K:F%a*"%23>MN4%
%2 P3(#{!W#23(2%M3(##D>N4!W#{!&%9/#:;.3(;3(!W#;)94%OP*&2C%
!&%94)!W#23(2%+P:4+73#4!I#;L3.P94K%23(4M93(>L?!&%.5%%!W7*"94aMsOqo&t:njqvl
fo&pw\qvfl{PY%97;*D)77:!W#+94Q*&#N7P#7:P\3(,Q!":4!I#;!&/2#]^#!"
%;2#2>	XY/2#!P3(%3(3(!"#P36m{Ka{ W 6{K23(%	!&ff!"%-5%%!W7*"c94	%*W!&#%TP
%97;*&%:4T*&+#-7cP\#K,N!&94.36%3(a{ x ,Q!":4-*"2C%9ff2#K#,7QP\#),N!&94
3(%3(#{ W #C*"2C%2>	N4!&%-2#K3(3(23Y94N%2364O%:5!W#KS436*"DC#:3(*&*W7*&<##23>
-#%!"236!I#;94)!W#<P23(2#7#L!W#M%O.2a%%O97*&2M,4!&4M*&1#7G)2#O23
,N!&94K3(%36A{)2#K#,A7G2#O23a),N!&94C*"2C%2>T?-!"%N5G%%!W7*&S94a:4%cP*&2C%
_

fi

J    J++uM'++'

  +x+~+



'z+++;+{

%95<3(% =O3(K94#={6{ W !W#<P\23(2#%2>L?vP,-%):4)2594L7#L!&.!";4.7G)94O!W#L
97*&2%OS73#4%Q,4!&4{2#)7GS*&%{!I#O25:4);3(2a23ff94#4{,N!&94N*&2%c2#
#,7O*&%!W#O2594{%9a*"*&23c94<#K3N*bG{ W >NN42#+C*&cP%:523i^%!W#<P\23(2#%
2#=7G!W#:3()94.#,O!W#!W*-53(PN%;O2#<2>#*&;<%:F%9r5*W,c42#
%!W#;94c,-!&;4_2594)7# x %95G!W*&*"D*&%S,c42#)%!W#;`:4#<];3!&#KP947#
%N%23(!W7=7D y %23-c*\> x |2}}<>
c!&!&#*&*&DZjph^o&qum:nw\qvflfN>+t(sOt2l[wv+fN>wYqtt9n(m[qBhnm:tK2#23>%%9O!W#;L94
5#*"2C.536PT*&!&%,N!&94!W#94!W#!"!Ia*	%;O2#<aPrR.7O#%!&23(Zg:4`%P#
!W33(*&/V<#*&2C2#2%`K3(25G2+5*&3!"#)P536%NP	94S%23(4)%95,4!&4{%
#ff#:!W#S53(Pd	!I#S%9523i^%-%*W!&#CP%97;*!&%TP\#K(,N!& x /!I94c*"2C
#E7D15G23P3O!W#;B:4+!W#<P2362#%+#B53(/+:4)*"2CC943(%:*"!I#;L%:523i^%
!W#<P2362#%4/K=7523P\3OM(,N!&ZT>=Q4!"%K!&%9/#:;ZT4,-/23Z	2<#B%9a*"*&D17G
/23(7<D%!I#;K*&2a*P!&*W3(S24!W#; x zg*\>WZ|2}}>
ff%!&%N:4%:F%Z,c4!"4K2%O3(%9393(!W#;P94c%23(4C%95Z!&-!&%N/2#K5%%!I7*&
94Q94`%P	*"2C%Oqul[m2(t9natwYqtClpst2f>Sfo&pw\qvfl-P	23(9!W#%97;*&%c94N!&%%c!W#
94O,4*&O%236493(>N4!&%!&%S72%O94%OPT*&2C%2#)%:4,,-*&*0_r#,#=53#!I#;
4#!&%O*&!Wr36;*W3(!&(D+%!W#)#3(;*W36!"(D4r<%S3(.5G%%!W7*&K!I#9453(PNPK*&2C>
^369423O36Z-94=#,N*&D!W#<93($*&2%)2<%9453(7*"2 94K!W#12a4!W#<P2362#B
5<%%!W7*&D)*I<3(;S#`7G23-P*&2C%4%-7%K!W#)3623T`23O!W#S,4:423T!W#<P\23(2#%
3(S5G%%!W7*& x n:hhgo"qvm:nqvo&quw|Ow\twW>TQ4!"%c#%%!&9%#,#!]2a!&#+25%2>
?#L%9C!&#M3*"2CB4#!&%9 !&%.!W#;2#23*#<.7*&+M53({*&2%K94
*&2+.53(P	*"2#;<94+3(!"#+#{94%Q.3(%3(S3(!&#g>  /23(:4*"%%523(!&2#
%94,N%94!W#BC#D2%%36!&#%OPN94.53(PN*&2#;94M#=94)#36%3(K2#=7G
79a!I#>  42#C%9a*"*g#O7G23	P*&2%ff!&%%:<.!&2#ffP\3	S3(%3(3(!"#94#`7G23
P!W#<P23(2#%	,c4!"42#S7GT%95<3(`7<D%!I#;*&2C%2<#cO94-#O723P#,B%:523i^%
!W#<P2362#%7DK;#!&9%2>ffN4%Z4#!&%9%<3(#)!W#K3623TS%*&S(t2o&t2nl[w*&2C%
P3(OI-Ud-!"%Pa H - ; ) . v R`94a%94*"=7G`!W#%236!I#</$	*	>c?vP,-2#]^#=K39423
%9a*"**"2C%,4!&4+5G23O!&%3(%36`3(!&#{942#K!W#*WO%*&*2%%c,-2#K]^#
53(PO4CP%23ff94#K,-*&+7S5G%%!W7*&O,N!&94N%!W#;.*&2C% x %S!"#)>  <94
94c2%cP*W3(;3(!&#KaP:453(P*&2#;:4K,N!&94NO3(!&#KP94S3(%3(#
#3C*&*"D+5G23P\3O%N%!";#!]2<#*&D{,3(%94#K:4S2%aPYC%9*&*536P	*&2#;94{3(!&#{,N!&94
3(!"#)P	94S3(%3(S#>

< 	+rt[	=+rj


#*&;%cK94P36;!W#;.%!&#{,O#,,N#<!W#936%O`<7%93c53(!W#!I5*&%OP\3
]*&23(!W#;*&2a%7%K#C94!&%2%%!&#+3(;3(!W#;O94%9393(cP:4%2<3(4C%95>ffN42#gZ
,-2*,N!&94K#23(`4236!"%!&%55*&!&P\3ff%*&!W#;)*&2%2>
fi! <n#"%$pWW'&nmbjopoQ
l

 !W#)%95235%!&!&#L536V/<23(%25*&DB)!0F23(2#<`%23(4%42O.:4# y X536V/<23(%S#M%!W#
94D=4/O:F!&/.O4#!&%9O%P\34#*&!W#;*&!&(DZ,-2<#=%%994SCP\,%97;<*&%
,4!&4+3(S4<3()O%*&/ x :4S53(aPY#%%!":%O*W36;S3(%36,S>3>>;!&/2#5*&2#%%
7#S,Q!":4=# y X$53(/23c2<#=7K%*&/=,Q!":4*&2%2>)Q,/<23Zg,42#=%!W#;*&2%!W#
_I

fi

 

wyz{

wyz{

3(23*&%)%O)%97;*&%`aP#M5G2#M97*&2M94)3(2!W#!W#;M52#M%97;<*&%%94*&17G
2%DKO%*&/,>3>2><94c;!&/2#+7G#>Tc9423(,Q!"%Z,-c%!&*&*2##N%*&/94S53(7*&2R,Q!":4!I#{
%9a*"*&233(%3(>  O94,-%9*&*&D=2##594*&*T73#4%SPN)53(P2#7G
%943(2#j
 +7<D)%95235G%!&!&#<_;2#23M*"2C%2>S!W#3c*"2CK;2#23!"#536V/!&%S#
;3#:4%:P*[*"2C%T3(-;2#23 x %!"#O>W|2b%9*&*&D#*&Dc%9a*"*#O723bP
*&2%ff2#7G25*&D!W#K53(P6>bc*&*!W#.a*"*[,-79!W#O94q
 !I#<23(%!W#r; `53(P\% x !\>>:4%
,-S,N#<NO]^#QP\3N<#+55*&!&2!&#aPT*"2C%3(`536P\%N94a#<9!W#{#<D.%97;<*&%94
3(2a%D)%<*"/<:'A#{2#+42#O7O%*&/@
 #</2#!"#*&*"kD K,N!&94!W#C%9a*"*b3(%3(:'$#
#*&D.P,E43(%97;<*&%T94aT`%7c%*&/C,N!&94*&2C%2>	N42#gZ,-N2#O5-94T%!I#;
*&2%-*&2%N`3(%3(36!&#%2>-3	]*&234#!&%N%94*&+42#936D]^#)*&2C%
94NO!&;4<7S53(QP%:4)53(P\%2>
g3(94233(Z,-S%:4*&=%!W`4, C#D+#,H%95G23i^%S!W#<P\23(2#%`<3(S!W#<93(
7<D`c*&2>	N4-!W#<;3!"#SaP^#,1*&2%TO%	#	!W#23(2%N94N73#4!W#;`3TO4g>
c9423(,Q!"%Z94;!W#{PK5%%!W7*"K3(%3(3(!"#!&%S#;=7<D)94O*I<3(;O/2342 x %
!&#>>
Q4%=23(!&23(!W*"2a%+L:43(=!0F23(2#K]*&23P#!"#%:4)#2#<93#A23(9!W#
%95G%-P3(*&/V#D>NQ4N]*&23YP#!&#%3(Q,*&*0_%9!&P3ff*&*gP9453(/!"%*&D.!W#<93(
5*&2#%%7G#%2>ffSO94S/;2#%%NaP94c]*&23Q23(!&23(!WO,-S%2a4]*"23ffP#!"#
!W#3(23O4%{%O{*"2C% x %!"#1>  ):4!&.!&%+7G23C=%*&+{P\,
##%%9<3(D)*&2%N:4#K!"Q94%*&!&#{P	!IC53(:#-#%>
fi*)ts nIvCuj$g[[vn?vxwNj-L[vn
l

 4O]^36%c]*&23cP#!&#!&%S2a*"*&sC:
N
y  >ON4!&%P#!&#=!&%O39423c%!W5*&)#=!WO%`ac]^#!I#;
y 
*&2%ff94ff`#ff*"2a`4!&;4!W#23(2a%aP:473#4!W#;3>n *
5*&!&%94%-94!&%N7D
%!W#;.r#,N*&;79!W#)!W#K94c*&2;2#23!"# x 53(253(%%!W#;N54a%aP947_5
y 
53(/23>O?#9!&*\Zn *
%*&%P%,N!&94{94.4!&;4%/V*W.3(;3(!W#;;O2#<cP#!"#
y  >
8 *
iwof5jj

vQz q,-qn5 rj 8 :y  
3TS5G%!&!&/S#!&CM(Z;2#23!W#K9453(253(%%!W#;54%Z*&|{ x M\ff#T} x M\T7c94#O7G23(%
P	5<#%!&#+#)#93!&#K!W#<P2362#%2Z^36%95!&/*&DZg94a#M,N%Q!I#</*&/{!W#g>TN42#


8

:y  x M\n1%} x M\/{ x M\ J

 y  #<%:4)!I#<P\23(2#%)94a`2a4*"2C2#!&{,N%!W#/<*&/1!W#1<#13%<_
*
5#!W#;+!W#<P\23(2#%`#;!&/Zg#<93!I#;)!W#<P\23(2#%`5G%!&!&/>O?vPNCPaM	,N%aP2#!W#/<*"/<
!W#B<#5<#!I#;!I#<P\23(2#K*&!Ira+3(%*W!&#3c%95G235%!"!"#gZ	942#=M-3#<D%9723%SPN!&
3(#!0]^7*&S,N!&94 x %9723O%-P x a!W*WY*"!&23*&%P	!&%3	23(!&/{*I<%%2>TQ2#Z!0PM
!&%a+:4`!&!&2!"#)P	945<_,#)536V/<23-!&2#{75G94#M3Q23(9!W#
%2##<%aP!&2<#=/236DaP2#9ra536S!W#M2#%!&#M%25%2>!W#+94!&%O*&2%4!";4
!W#23(2%cP9473#4!W#;3N,-3aN94!&%N#;!&/>	QP3(%Z,-3(N!W#<23(%.!W#C94NP
94NO*&2C2#)7G`55*&!&=7DK94 y XL53(/23>	Q,/<23Z%!W#S*&2%cP%95235G%!&!&#
53(/23N<3(`%9a*"*&D!"`;<2#23*O<%aP942D+7%P3N*&%!W#;)233(!W#;)%97;*&%2>
8

_I

fi

J    J++uM'++'

  +x+~+



'z+++;+{

g(b) = f(h(b))
transitivity "="
g(b) = f(f(b))

f(f(b)) = f(h(b))

symmetry "="

congruence "="
f(f(b)) = g(b)

f(b) = h(b)

f(f(b)) = g(b)

h(b) = f(b)

axiom

symmetry "="
axiom
h(b) = f(b)

	!&;36dT!WO*Ia!W#;O%:5235G%!&!&#{%25K,N!&94 y X
3Q23(!&23(!&#!WO%!W#*&DaN*W!W#;+*&2C%:4<3(S55*&!&27*&.!W#{.#<D)2%%#
42#O!W#936.C#D)%*W!&#%PT%97;*&%94N+#c*&2.K3(:P9!&#{PT94!W#<_
5*W%%2>?##<93%N)5#!W#;+!W#<P2362#%`,-3S#<93!"#+!W#<P\23(2#%5%!"!"/<*"D>
?#Z y XM53(/23(%ff`#-4/N#<93!I#;!W#<P23(2#%>-N%T%:4V,c#7DzgN*\> x |2}}Z
%97%9C5!&#{2#53(*&D+7O%!WO*W=7<D=ppsQh^w\quf<l=m9f<lw\n<qul[wv>-N2#Z*W%%94c3(
7*&S#<93N#<D:423-*W%%c2#)%955G3(N%23(4)53#!W#;.4#!&%>
fi*~ vn?vxwNj-E[u
l

 4%#)]*&23P#!&#x * :3(!&%C%*&NP%N:43(S<7*"OC*"<%S%97;<*&%N94c3(
N
/23(D=436=+%*&/,N!&94MK##!&#<_9<7*"2<<_7%536V/<23>.?#=3623)%!IC94!&%2Zb,-
#%!&2394S23(!&/!&#=4!&%3(D+PCP2>  25*&D:4!"%c]*&23QP#!&##*"D{!0P*&!"(D{!"%
!W#/<*&/+!W#+C53(7*&2)>
!g5 bv zgtOP x  x E1 x QR#mO  x x1  x QRB7B!&O%2>RN42#gZ:4*W%
O x *1 x  x QR2<#+7O23(!&/=7<D)#S%:5235G%!&!&#%25g>NN,-/23Z!0Pf x (1 x  x ff!"%
O%97;<*gPT# y X153(PZ!&%53(P	!"%cO3(C5*"!&2 x %	!&;3(>

?#=;<2#23*\Z	!0P:4.%95G235<%!&!&#L%25=!&%.5G23P3OL`5<%!&!&#5L# n2#%O94
2594aP945<%!&!&# x 7G/x n1|2Zg:42#aSO%, n>EK!I#<P\23(2#%O3(#B!W#3(23
.536V/<94O3(%9*&NP	%94+O%:5235G%!&!&#{%25g>TQ4`53(PT#%%!&9%cO%2594)P
 n4 >>
Q4!"%<5*&)%94,N%9494%!WO*W!&#MPN94%:5!0])a!&#*T523!"#%`aPQ%9<_
5235%!&!&#{53(/23-#%%!&9%O4!&;4)25:4)%N,-*&*%-!W#<P23(2#O3(%36!I#{# y XL53(/23>
N4ff!&%2Z*&2a%236!"/<7<D#<D`%:5235G%!&!&#C%25%<3(7*&cS*&%Q%97;*&%-94	2<##
7C%*&/L7D# y X$53(/23c,N!&94!W#%9*&*-3(%3(%>.Q2#Z!0PN%94*&2%O3(.<55*"!&27*&
*W3(;S36%3(O3(!&#%5%%!I7*&D{23P3T25:4)3-!W#<P\23(2#O3(!&2#<7G#%2>-N4N;_
O2#<ffP#!&
# 8 *  25*&D%N94!&%N23(!&23(!&#g>Y;a!I#gZG94N]*&23P#!&#E : %*&%-P%-,N!&94
94S4!&;4%c/Va*I3(;3(!W#;94!&%	;O2#<-P#!&#g>
_2

fi 



wyz{

wyz{

WsQz q,-qn5 rj 8 :  
3NO5%!&!&/#!&aM;2#23)!W#)94O53(253(%%!W#;)54%Z*&q8 :  x M\7GS:]^#=7<D
iwof5jj









8

8


* x M\*1  




 >8
  xM#?
:
L 8
e
vf #

H M!&%#)!&
H M!&%N23(!&/7D+O%:5235G%!&!&#)%25),N!&94)5362O!&%%
M # #xM 
MH !&%N23(!&/7D+##<_%95235G%!&!&#{!W#<P2362#
!W#</*&/!W#;)94*&!&23a*"%aM #IHIJIJJKH ML x { ; ?   J


  x MY9?>J|
*

: x Mvv

$ oc s 
 "v N
w b2j-E[vn
fil 
l

9  !WO%%*&!W#;=*&2%O94a`3(K7*&.{%*&/K%OK43(
 394!W3(]*"23P#!&#= :

y
%97;*&%NP X%97;a*^*W%%%94K94Q94S3(%9*&!W#;K52#%97;*&%N2<#K2%!&*&D+7S%*&/>
9  #%!"236%:4N%%ffP%97;**W%%C  L  
Q2#Z:4	6;O2#ffP#!&]
# 8 :9  %7<D, :
L
3 `Ibd c   P\3	23(:!W#3(%36#{b>	3b2a4O%:7;**W%aTjZ!0P*&2CAMg,N!&97
4 8 :9   2 x M\?1
!"%%2Z94*&2,Mb,N!&9494S4!&;4%ff6;O2#q
 8 *9   2 x M\ff!&%c%*&#<!&*C!IC*#`7G23
P	*&2%N!&%c%*& x %S!&#>	N4!&%ff6;2#N!&%N5a%-P<*"*&,N%2>

sQz q,-qn5 rj 8 :9   2 
3)15<%!&!&/#!&M;2#23$!W#$94M53(253(%%!W#;$54%B#M%97;*S*W%=Tj1
OPM # HJIJJKH M  RZ*"q
 8 *9   2 x M\-7GS:]^#+!W#94P\*&*&V,Q!I#;)##23d
?vP#%97;a*2#O7G%*&/,N!&940M(Z!\>>C
 z H |ay6z*n
y A H  d  W
1 A/  x bnMv H M\Z:42_
# 8 *9   2 x M\*1$>
c9423(,Q!"%Z*&CTj51O  #IHIJJIJKH   Ru6Tj.7%-P*&!&23*&%<#  7GS%97%!":!&#%`:4 
!&%%N;2#23*,N!&94g
d  H |a'
y ,yff)d  x bj2<
 i  x M\> y 36V/<23Z#23*&*b%97%%QPfTj+#
%97%!":!&#%T,N!&9494!&%-53(5236DZ*&	94Q%:TQ<#`:4%:7%!&9!&#  7Gc!IOHPg94
P#!&/
#   2 Z[:]^#=7
D   2 x O  #HIJJIJKH   R 4H  *1
   &Z  )    > # Q42#gZg94`3(2C!W#!I#;
B
# e
3+ 
 
*&!&23*&%cP:Tj)3(aTjr 1O U #HIJJIJNH U  RZ1TQg"TQoff>Tzg
 +7S
OC
5*"!&(DP#!&#gZ!\>j> +C5%
*&!&23*&%S ff 2| fi #=4!&;4/Va*I%
P !I#!&2.94a94K3(%95!"/<*&!"23* x %97;<*W552<3(%
.7G%*&/V<7*">NQ42#gZ
iwof5jj



8

 9  2 x M\*1
*






x  x U 






  2G

 2

x  x [4 J

 8 *9   2 x M\3(2*&*&DB3%AMff,N!&94+4!&;4/*W.!0P<#D43(=%97;<*&%
 `2<#=3(;#!&K94
x ,S>03>2>bPnTjK2#.7G%*&/.,Q!":44M(> y 3(/23ZMg!&%N3K,N!&94KS4!&;4K/Va*I!0P:423(<3(N#*&D
P,H%97;a*"%c!W#)94O%97;<**W%,TQ94aN2##7O%*&/7D)*&2C%<#:455G23
S7G%<*"/7*&S39423b2a%!&*"D x ,S>3>2> >b?#C3T362*&!"2a!&#gkZ .#%!"236%%:7;*&%T`7Q%*&/V7*&
94T<3(T%9C*&*Z4/Nc39423i^	23H%93:3(Z##<DS/3(!W7*&%-!I#53(!&%#S,Q!":4O94
23 %!&>?#P936S,-S,N!&*&*bP3(9423N3(:]^#V
 8 *9   2 7D)5*&!&!"*"D#%!&23(!W#;+945*&2#%%
7#+,4!&4)!&%%)P\3ff94S5<_V,c#.53(P	%23(4g>
4D OqB4D5OxBqQt C4xOp5QxVrq O4QTO|45G1xVGxO B
dBGGQ5dD 

OODdOrQx|BBOCrdddZq4?BQt dd44 O

Q qrCxOQOQDB4QqGtC 

_I

fi




J    J++uM'++'

  +x+~+



'z+++;+{

TNfi$  g   
TC

a1

?#{3623-K#<#)523(!WO2#<9*	/*W!&#{P	3N!W#<;3a!&#)PT5<_,#7<_5
53(/23(%Z,-S5*&=(,-.3(2#,#53(/23(%2dff94 y X536V/<23L#94%95235G%!&!&#
53(/23O>  .4/.%94./<23(%!&#PE%S%23(!W717<D y %23c`*\> x |2}}>
S4%7G2#)25*&D{!I#/23(%!&#)G>>
v


lxrsj+rxql

'Ds^j^l,#xs!Clxjgfi;t

35G23(!WO2#<9*T2#</!I36#O2#<`2<#=7K%23(!W7E%P\*&*&,N%2dOXT4=53(/233#%O#!"%S,#
53(%%3K#79!W#%)94{!I#!&!W**W%%,$ a%.!W#52>  {25*&VD<AM3:423O:.!&2#
O9436;#!&O9453(253(%%!W#;>SXY%%2#<!W*&*"DZg:4`5<_,#+53(/23Q;2#23a%%:7;*
*W%%ff,N!&94#TPg94-(,Q/V3(!W#<%2>	?#S32#</!W3(#O2#	:4!"%ff%T#<3(!W3(N4#;%b!W#O94
5<_,#K53(/23ff72<#.7G5G23P3O),N!&94K7!&*"6_!I#%cP:4  zN_%D*&!W#5N*W#;;
P`[T>M!I#MJ25*&VD%,-DBC-a`Ibdc),-.5236!I2##*&DB,Q!":4M%97;*-*W%%
79a!I#C,N!&94#;!"/<N%936	*I<%%2>TN42#gZ<94%N%:7;**W%%-3(-]*&236Z93<#%(P233(
94-7_5S536V/<23ZV<#S!W#;3!W#c!&%b%23(4%:>N4N53(253(%%!W#;P:47<_
5S536V/<23!&%	523P\3O!W#`5<3*&*&*,N!&9494-53(253(%%!W#;SaP94ff5<_,#53(/23>N4N53(/23
!&/%	*W%%ff,N!&94O!&%T7%!&4236!"%!&#<!&*94-5<_V,c#`536V/<23g]^#!&%94%-!&%T53(253(%%!W#;>
N4%2Z[,O4!"/<`%D#43(#!&2!&#P:4536V/<23(%2>-QP23Q94Z,-S93a94O5%!"!"/<#!&%
P3(H94N%TP!&/-P%ffP<#O]*&23	%O-P%T%	%236!I7G>N!W#,-N2#25*&VD
9  :4;2#23)%:7;*
94;2#23)%97;*g*I<%%aPP\3ff94c]*&23-P#!&#4 *
*W%%2#{7%%a!"!"#*!W#5P[2b2O%N,-*&*a%NP\3-94%*&!&#P	*&2%cP\3
ff>		!W#*&*&DZ94S536V/<23(%53(+`:r<*&9453(7*&2U!W#)53*&*"*,N!&94K94!W3-%9<#3(
%!I#;<%2>ffD1%!W#;L94!&%K2#/!W3(#O2#<K,)2<#14!&/5G23!&#7DM4#;<!I#;L*&2C%
#%97;**W%%,N!&94#O#25!&%937!I#;{94O9423>?#+#93%2Zg7:4+#25%
%955G3(T2a4C9423ff72%3(%9*&%-7:!W#P3(H#53(253(%%!W#;O2#K7c25*&D.!W#C94
9423>
 T523(!WO2#<O!W#S:4	*"!&;4<	P53(7*&2O%	%2O!W#;NP3(A94T,-*&*0_r#,#O53(7*&2J*&!I733(D
    /g>W|>0>W| x *&!0Fca*>Z|2}}a*&!0FSJ9#23Zg|2}}<>?#C3(23YS79!W#S36*"!W7*&
*&*&!&#KPg9Z,-N25*&D.a*"*[!W#%-#<9!W#!W#C94    %	3Y%	%>ff2%
94%Q!W#%	/23	c,N!&3<#;-P^/236DS!0F23(2#-53(7*&2O%	,-%%9O-94b94!&%T!&%36*"!W7*&
%Q%2>
!W#O94O    #<9!W#%c.#<D+53(7*&2O%cK*"!&%#!&%2%%94O3#<!WO%aPT%!W#;*&
53(7*&2O%Z,-{,N!&*"*O53(%2#<<#1/236/!&, PS94=#O723KPS%<*"/<53(7*&2O%)!W#E94   
*&!W733(D>^3(:423O3(Z[,-S%:D+!W#,4!&4+!W#%S523!&#{!&%%95!W*&*&D=!W53(9#<S#
2*b,N!&94{94!W#P2a93(%3(%95#%!W7*"P3Q94!&%2>?#!&!&#{,%9D{943(%9*&%!W#{943(
a!I#%!W#=3(O9!&*	K;!&/.#{!W53(%%!&#{P\3N:4`2362%!W#=3#{!WO>ON4!&%#23#%
94K!W#%.T x 2;36D+9436DZ	zgc x zc_*&;273%9ZT#LNz x O7!W#3(D*"<;!&2>
N4S53(7*"2%!W#):4Sa!I#%c-T$#zgH#<9!W#K*&!"(D+%Q,*&*a%##<_Q3#)*W%%2>
Nz!&%Q3#<_*&!"(D)C!W#g>
?#O9!&*\Z:45323(%	Pg3b5G23(!WO2#<9*%D%23(dQ4N%97;a**I<%N2#!&%
,-23(;2#23=!W#M%94=),ND94cP\3/3(!W#<.|C,C25*&VD<B94)3(%3(G1 |),4!&4
523P3O7G%-!W#94c523(!WO2#<%2>TQ4%QP4!&;423-3(%36%T!&+#TD!&*&+723-3(%:*"%2>
D 0  2 1$G>3	/V<3(!W#N,-N25*&D4 # 1"1$}
 c*&!I!")94%aP%:7;*[*I<%%7<
_

fi

 

wyz{

wyz{

%.36%3(%2>c%%936*W%%CP3C#L5!&/3(:]^#2O2#<.,-)%*&%076 b 1%:7;*
*W%%2>HN4%=53<O23(%.a*"*&,-194{:.!&2#);<2#23!&#P`*&*%:7;*N*W%%),N!&94!W#
94{!I#!&!W*%;O2#<%KPS94{%23(4L936>@Q%9*&*&D,Q!":41:4!"%)O94$)O%.<=%:7;*
*W%%,-23(;2#23Z[!\>>g7c94O%9S#O723a%,42#25*&D!W#;+/3(!W#<`|<>-3Q94
%*&!&#KP%97;<**W%%N94-3(NO793#%9O!&C.N,-%K!W#<_252#2#<
53<O23(%2>H[3)-TZ-Nz	Zc#$zg,-%|=*W%%2>?#E949423K!W#%)!W#
53(*&!WO!W#3(D{5G23(!WO2#%94S%SPT*W%%4!&/{94`7G%3(%:*"%2>

9  >  T%*"
y  ZP * ZV#, *
Q47<_5*&2%b,-23(T%*&O/!Wc94	P#!&#%* :
,N!&9424KaP94cP#!&#%!WORPN|2*I<%%2>
Q4`%!W#;+P[1,N%!&2*&*&D4%2#=%%23(!W7G7<D y %23cSa*> x |2}}>
N4+[2b2O%:#3(B4236!"%!&.%%2#!W*&*&D=%*&%O*W%%OP-94%9C*&*"%S%!&>  23(!&!&2*&*&DZ
*W%%3(%*&{,N!&94+736294<_\]^3(%Q%23(4g>
W !gn+lnj5  tbqt


?#{94P\*&*&V,Q!I#;{,-S5<3(O94`3(%:*"%P3Q523a!&/53(/23N,Q!":4+:4`%!I#;<*"K53(/23(%2>
N4!&%S53(!&%#!"%O523P\3B3(;36!I#;{94O,4*&.    *&!W733(D>KQP23c942Zg,-#*&D
3#<!WO%c!I#P,J%*&+C!W#%P	    >
$ oc2fiv2M.&/-&+&ggsnWn/ MU
fifi 


b7*&|O53(%2#<%3(%9*&%cPT3Q5G23(!WO2#<%2>?%:4V,Q%94O#O7G23NPT%*&/43653(7*&2O%
!W#2369!W#K!W#%-P    >*&/)O2#%-94-S53(P*&+7QP\#.,Q!":4!I#)<%#%2>
 #%!&23K53(7*&2 .7G`43({!0P#!":423SS#3M3(O7*&S%*&/S!&c,N!&94!W#
|2%#%>TN497*&#*&D)53(%2#<%N94S36%9*&%NP%:4KC!W#%N,423(S43653(7*"2%!&%
#M,423(+O*&2%O#)43(15367*&2*&17)%<*"/<7<D<#D=aP:4)#%!&23(L/V<3(!W#%2>
 c94-9497*&2##<;<!"/<S4!I#<%N#K945G,23ffPb94%!W#;*&`53(/236%2>	N4!&%N!&%72%S!&
%#	;!&/Q94N5*&c#O723YP5367*&2O%-,4!&4O2<#7N%*&/.7<D`2a4%!W#;*&53(/23b!W#
94,4<*"!W#g>T!W#`<#D.##<_43(+53(7*&2O%c3(c!I#94S    94!&%#`7G23-!&%%9*&*&D
O4)4!&;42394#K94S#O723-Pb%*&/+43(+5367*&2O%2>  /23694*&%%2Z94:7*&!"%Q%9<.!&2#
P\3N#*&D!W#;+94O523P\3<#SPT35G23!&/O%D%2 %!W##*&D)9443(53(7*&2O%3(
!W#23(%!W#;CP3ff%:D!W#;K94`5G2#<!W*gP5G23!&#g>
*W#=|PT94O97*&!"%:5*ID%S94O#OPT94O!W#g>c-*W#%SK#=.53(%2#c94
#`7G23ffP%*&/.53(7*"2%aPY[2b2c#[ x #S  c-%:!&#<_<|2,42#C,3r_
!W#;`*&#>ff-*W#O%94,N%	:4#O723YP^%<*"/<.53(7*&2O%ffP-,42#O!&ff79!W#%T%:7;*
*W%%YP3(R{,4!&4<3(N;2#23a3(;3(!W#;/V3(!W#<T>	N4!&%T/3(!W#<5G23P3O%T723
94#K/3(!W#<| x %S*&%C94NP\*&*&,N!W#;.%97%!&#>T-<*IC#+!&%95*W2D%c94S#O7G23-P	%*&/
53(7*&2O%CPS$,c42#=!&7:!W#%7G_5=;<2#23M*&2%P3(2<>?#M94
2%,-S*&,D%N25*&D+/3(!W#<P3;2#23!W#;%:7;**W%% x 3(2*&*94aN94S%*"!"#
P*&2C%O252#%#94K,N2D=4,R%97;a*T*W%%.<3(.;<2#23>{-*W#L~{;!&/%O94
#`7G23ffP%*&/+5367*&2O%-P5G!&!&//23(%!&#CP[2b2#!W#K3(23ffO%94,
94b3523!"/<53(/23!&%	!I#K`4S3(5G,23P*94#N%!W5*&N5!&!&/N53*&*"*
53(/23>b	!W#*&*&DZg!W#)*W#{O,-2#C]^#+94S#O723QP%<*"/<53(7*&2O%cP	3-523!&/
%D%2)>
2

fi

J    J++uM'++'

  +x+~+

!W#
  
-
-T
N?
Nz
Xff
 
X 
zNz
zgc
 @ y
 zg
  

XT
  
k

[2b2 




~

|


|

|

|





|
|




~

|
|
a


||2
<

5!&/ &* 2




||

|


|

||
~

}

~
}
}
|
|




~

|


|

|
|2



'z+++;+{

5!&!&/ 5G23!&/



~

|
|
|
|
|2~
|
|2
<

|
|2
<
|
~
}
|
|


}
}


<}


|
|2
||

b7*&.|dN?#;3!&#P5<_,#<7_51<553(4%+7DE523!&/B53(/236%2dM%*&/
436+53(7*&2O%
Q4S3(%9*&%3(/2*:4`4!&;4+5G2#<!W*P	3c553(a4KC%!&;#!0]2#*"D{!W53(/#%!W#;*&
5 3(/23(%>.O!&%S#*&D=7*&K%*&/K>}r P-94.53(7*&2O%,4!&42#7%<*"/<B7D5<_
23!"#gZ	2#{#*&D%*&/.~>0r)>S-5!&!&#P53(/236%!&%S/<23(D+%9%%(P*-72%
P-94O/23(D+!0F23(2#<`7G242/!&3aP9453(/23(%>S-S/2#K5G!&!&/)53(/23N#%!&%!W#;+P
`<#BM2#{#*&D)%<*"/<G|>r RaP9453(7*"2%%<*"/7*&.7<D)5G23!&#g>cN2#Z
523a!&#!&%-3(2*&*&D!W5369#<T!W#3(23	!W#23(2%c94N%9%%3>  42#O!W#;3!W#;S%:7<_
;a**W%%N!W#<)2c!&%-%<*"/7!&*&!"(D+3aN!&%N!W#23(2%+7<D.G>r} )>b?#K94O%-2%%%:7;*
*W%%O9ra.53(!I#M:4%23(4M53(%%`#M2#M4*I5M3(362394K%23(4!W#M)P/3<7*"
##23>+N4)%.aP*&2C%O!I#2362%%+|
 %O523P\3<#7<D=>r >Q4.!W#23(2%.P
94%<*"/7!&*&!"(D=3P[=!&%3(2*&*&D)S233(!W#;)3(%36`3(!&#%>?#+*WO%*&*
2%%	,c423(Nc%97%9#<!W*%95_5C!&%T7:!W#`,--*&O]^#.536P,Q!":4N%:*&*&23T3(%3(>
N42#gZ94c*&2%<3(%+%ff5GZ!\>>94D)3(<7*"S*&%%97;<*&%-94T23NP\23
P\,$!W#<P23(2#%S<#),4% y X1536P	,-*&+3(!I36`#<DK!I#<P\23(2#%2>
 42#9r<!W#;M*&%23K*"r.:436%9*&%),-2<#36;#!&=94{P\*&*",N!W#;> 53(/23
,4!&41*W3(2D%94,N%=39423%9a!&%(Pa3(D=724/!&3!W#L{%95G!]C!W#M2#MP\2#B536]
P3( 9423(%2>-5G23!&#2#{2#9a!"*	:4<94234<3(=53(7*&2O%2#!&!&#*&*&DB7G`%*&/>
QV,-/23Z!P	S53(/23Y!"%N#ff%9!&97*&cP\3T23(9!W#C!W#C942#O523a!&#,Q!"*&*#3C*&*"DK#
3(%9*&O!W#L{%!&;#!0]2#O!W#23(2%)PN!"%.523P\3C#>ff2%.PN94CPO94.[$#
N%94,$/<23(D!0F23(2#N7G242/!&3ff!W#K94%T2a%%NT*&2%-#53(/23Y2#.7G!W53(/
!W#+O2369!W#)C!W#g>


fi

 

wyz{

wyz{

?S!&%S!W#<23(%!I#;K]^#S,4:42323(9a!I#4323(!&%!&%OPN53(7*&2O%O*&2=)4!";4
3O*&,@5G23P3#{P:4+523a!&/+%D%2>  +O!W#{,49423C94+4323(!&%!&%
9!W#M#<9!W#%Oa*"!&(k
D <#
 9{C!W#=#<9!W#%##<_Q3#M53(7*&2O% !I#oi^2#{94
523P3#>ff	!I36%2Z,-%94*&=#:4N94%4<323(!&%!"%Q#Q5*&*&D+23O!W#
94)523P\3C#.aP94K5G23!&/K%D%2)>{N423(+3(C;!W#%OP:.!&2#DP3O*&*-r!W#%P
53(7*&2)Zb3(;36*"%%P94O(D5OP*W%%2336!I#;{!W#9453(7*&2O%2>O-,-`2<#a*"2a%
7%236/%O2#2#!"%>
	!W3(%*&DZ,-c2#C7%23(/c94-94c523a!&#)553(a4O!&%N%:5!W*&*&D+,-*&*_%:!")P\3-53(7<_
*&2O%#<9!W#!W#;=*&!&D>=Q47G%.3(%9*&%36.7:!W#L!I#M:4.C!W#%TZff  Zb#
XTJ,4!&4+#9a!I#{#<D+53(7*&2O%,N!&94a*"!&(D>  42#<#*&D!W#;+53(P3#%c,-S2#]^#
(,-3(2a%#%	P\3b94!&%2>	?#O%94O!W#%c2Q!&%7*&N%:553(c72%N!&4%-`4
%936#;23Q!I#<P\23(2#%P3c4#*&!W#;+*&!&D94<#B[T>OS2<#+aP2#{23(!&//
 !0.2*& 
*&2%O,N!&94P\,!W#<P\23(2#%2Zff!\>>*&2a%`,c4%K23(!&/V!&#M,-*&L3(!I36+#<D!W#<P\23(2#%
7<D=T>c2#)%:553(OS72<%S!&c!"%7*&O.<r93#%6P3!&#%-P	94
53(P	;*:4S2##523P3U72%`aP!&%Q]{3(23(!W#;)%{P3-%95235%!&!&#g>
N4!&%c2#K!W#23(2%94ai!W7!"*&!&(D+P	94S53(P	%23(4)523P3O7<D[2b2>
#*"DZ,-T#%!&23	,49423Y94ffPa94aTc!W##<9!W#%TO%*"DON3#3	##<_Q3#
53(7*&2O%ff!W#oi^2#%N94N523P\3C#NPg94N523a!&#553(4g>b-#%!&23(!W#;O94N!W#%
,423(94523a!&#+55364K*&+%9%%6P*&*&D7G`55*&!&,2<#+#!&94-%9%%%
*&L7K79!W#P3N3# x >;[>WZNzO%,*&*-%`##<_Q3#!W#% x >;>ZXTN>b?#94
a!I#%b,423(N#43(O53(7*&2O%b*&7G-%*&/ x #!":423b%2#<!W*&*&D#3,Q!":4523a!&#
P\2#94)52362#9a;.aPQ##<_N3#=*W%%O!&%394234!&;4 x #94aS94%Ka!I#%O#
55G23O!W#94)97*&2>1Q4!W#L3(2a%#P\3O94!&%2Z-4,/<23Z<5523(%CB7{94O94{%!W#;*&
53(/23(%C%94,@,-2rM523P\3<#+!W#L94%+a!I#%>1 %:3(#;B3(*W!"#%94!W57G(,2#94
523P3#cP94N523a!&/536V/<23T#K94-PT,c49423-S53(7*&2!&%NN3#3ff##<_Q3#
*&#<3(2*&*&D+7P#{!W#)94523(!WO2#<%2>
fifi gn4"uO&xgoc,YL2[j-'-oNnY


@c5K#V,E,-#*&DK#%!&23(+:4S#O723P%*&/+5367*&2O%2>T?#+!&!&#gZ!&N!&%N!W#<23(%!I#;
)#*&DS,49423c:4`%OP	%97;a**W%%3-*&2%2#%95_594`53(PT%2<3(4!W#
;2#23a*ZY!>>a*"%+P\3O53(7*&2O%O94a`2<#B7G)%*&/L7D=%!I#;<*"+536V/<23(%2>43(3#!WO%3(
%95G!Ia*"*&D!IC53(:#O!0P943(253(/23(%O3()%L,N!&94!W#L!W#<23!"/<+53(/232#</!W3(#O2#%2>
 O3(%93(!&N3(%*&/%c94943(a!I#%-TZgNz	Z[#zgc#+36S;!W#;.#*&D
94S3#<!WO%c!W#+O369!&*\>
b7*&Q53(%2#<%94-3#!I%,42#9r*&!W#;43(S53(7*&2O%bP94T:43(	%!W#%2>  
O!&`*&*53(7*&2O%	:4*"#!&9423ff7-%*&/7<DSN%!W#;*&536V/<23,42#,-3r<!W#;a*"#Z#3
7<D`#<DSPg94-523!"#O/V36!I<#%>-*W#|-P^94-9<7*"Q!"%:5*ID%T94N#NP945367*&2)>
-*W#%c`<#+53(%2#<-94S3#<!WO%NP[2b2#= x #K  c-%9a!&#<_G|2
,42#O,-3r!W#;S*&#Z<*W#%TS#Kc943#<!WO%	P	2-,c42#O!&T79a!I#%ff%97;a**W%%
P3(M,4!&436S;2#23a=3(;3(!W#;K/V36!I<#%O|O#=Z^36%95!&/*&D>  94c94
3#<!WO%-!W#*I94c;2#23!&#K#%*"!"#)!WOcP%97;a**W%%2Z#K94c93#%:O!&%%!&#
L>B*W#L~!&%95*WD%:4+3#!I)P[E!0PS!"C79!W#%7_5M;2#23
*&2%CP3(2<>1?#942a%),-+*&,D%25*&D1/3(!W#<.{P\3O;2#23!W#;B%:7;*
*W%%2>cc*&%)94%O3#!I%!I#*WK94`536253(%%!W#;)P2O#9493#%:O!&%%!&##

Ih

fi

B OQ

J    J++uM'++'

  +x+~+

4+Q

4GGGGG

4  

4GGGGG

4  

4GGGG
4GGGGG

r

dDBDQD4Q

 O

'z+++;+{


OQtt

Q|rQOO

4



4  

4

 4


4  

 4

 4 

  

  

 4

 4

 

 4




 4



 




 



  




x 



 4

 


 4

 



  

 


  

 



x 


44

  

 4 

  

  



 

 

 

4GGGGG






4G G




4G GG




4GG 

 4

4GG G

  

QG rDBO4

GGG 








 


 

GGG G

 4

  

 

 

4 

  

 

GGG 4

4

4 

 

 

 

 

 

GGGGGG








 4


 4

GGGGG








44



44

GGG4G


 


 

 4

 4

 

GGGGG

  

 x 

 

 

44

  

 

 4




 4

GGGGG




 4

GGGGGG






  

  


  

GGGGG4

 4


  

 4


 4

 4

GG G




 

 




 

GGG G

  


  

  


  

  

GGQG

 4


 

 


 4

4 



GG GG






 4



 4

GGGGGG








  


  4

GGGGGG


 




 4

 4

 4

GGGGG4


  




  

  

  

GGGGGG








 4


 44

GGGGGG


   




  

   

  

GGGGGG


4 




  

 

  

GGG4


 




 4

 4

 4

GGGGG


 4




   

 4

   

GGGGG





  

4 4

  

4 4

 44



4 

GGGGG


4 




 4

GG4r 


  




44

  

44

GG4GG








44



44

GG4GG








  


  

GG4G4








4 


4 

GGGGG


  




4

  

4

GGGGG

  


 4

 4


  

 4

GGG 

  
   4


   

  

  

   

4   


  4

  
  4

  
  

b7*&`d	?#<;3!&#KP	5<_,#7G_5.<553(4%7<D.523!&/`536V/<23(%2d	3#<!WO%

I

fi

 

wyz{

wyz{

!W#;3!&#{PT:4`*&2C%2>S-<*IC#K;<!"/<%943#<!WOOPNC5!&!&//<23(%!&#{P
#M x !I#!WOP	943#<!WO%aPT*W#%S.<#>-	!W#*&*&DZ!W#{*W#C,2#
]^#)943#<!WOP3ff523!&/%D%2 x O!W#!WORP94S3#<!WO%-P<*IC#%O#+~>
N42#<93(
D Q+.2#%N94-94S5367*&2U*&=#N7%*&/{,N!&94!W#=|2<S%#%2>
!W#S*&*ga!I#%-#<9!W#Ca*"!&(DK9436%9*&%N3(723ff94<#943(%9*&%-/23Y94,c4*&
    >3Q523a!&/S53(/23ff2#K%*&/Sa*"**"!&%53(7*&2O%Z,42362%2!"%Q#*&D+7*&S
%*&/K>r Z#*&D>r >C5!&!&/)53(/23Q#%!&%!W#;P#1
2#=23(*&D%*&/~>r aP9453(7*&2O%>  #*"D94C%9%%`37`*&%):4.3#<!WO%
3(Q*"2<3(*&D.!W53(/C,42#.%!I#;K523a!&/536V/<23>N43#<!WO%N3(NaP2#23(2%)7D
%97%:#!Ia*bP3(% x !W#%95!&OP:4OPa94aS3##!W#;+94O(,-53(/236%!I#53*&*&*T#%:O%
(,N!&S%O4K9*  @$!I2>
 42#O%9D!W#;943#<!WO%N#.53(P\%	79!W#)7DK{,-N2#O7%23(/N94P*&*&,-_
!W#;>S?PT%95_5%OPL<3(3(2*&*&D+OK2336!I#;3(%36`3(!&#%Z!W#*WO%*&*
2%%N%97%9#<!W*[%95_5K!&%N7:!W#>TO!WO%6'1P\3b!W#%9#!W#C94Qz+!W#<',-
4/N94Q%!&9!&#C,423(#O3(%363(!&#K9<r%T5*W7-3(3(236!I#;O:F%-*&*",]^#_
!W#;536P\%QP%23>-?#):4!"%%!":!&#gZ[94S%95G_5%S3(*",S>-zgS%c9rS*"<%23c*&r)aN94
3#<!WO%P,42#%!W#;)%97;*b*W%%2>  42#{#%!&23(!W#;+:4`3(%9*&%aPT/V3(!W#<|Z
9436%9*&%T%94,L94aTS#!&/<#.#!W#<P3O.;<2#23!&#P%97;**W%%%:*&*"DC%-#
2#<9!&*`4O;a!I#g>ffZ#*&Dr P945367*&2O%N2#7G%*&/)%!W#;94!&%-/V36!I<#2
> T36!I<#NZ
4,-/23Z%94,N%-!&OO%9!"%6P3(D.7G242/!&3>TQ2#Zg#K!W#*&*&!&;2#<;2#23!&#KaPYO%:7;*
*W%O5*3(2*&*&D)%%:3(#;*&DK!I#oi^2#O94:K!"2#D>
	 =fix
'xfi 


? #<;3!&#P5<_,#O#.7G_5O53(/23(%T7<DS25*&D!W#;O523a!&#O!&%T/236D`53(!"%!I#;
!W#=:4]*&MPa=!&#g>)SK{23(9!W#%:3(2#;94%O#B,-2r#%%%P53(/23(%
P\*&*",N!W#;!0F23(2#<53a!";O%2Z4#!&%c94-936DOO7!W#S94%:3(2#;94%N7<D.523!&#
2#{*&*",#!W53(/2O2#<aPT94S!&/C%D%2)>3c553(4PTO7!W#!W#;)5<_,#
#=7<_553(/236%7<D53(%%!W#;{5<_,#);<2#23%97;**W%%S!W#=K7_5
53(/234!&/%S:4!"%`7!W#!"#B7<D+!W#<93(!I#;;*0_3(!&2#:!&#{!W#+{7_553(/23
94%O7!W#!I#;{%93(#;3(#<#D#936*O4#!&%9O%O#;*0_!W3(=%23(4g>SN4%
P7<_5;2#23K*&2%-!W#K5<_,#C53(/23	2##:3(!W7S%!&;#!0]2#<*&D36
53(P	*"2#;<94%%:4K94a53(P%-2#{7P#),Q!":4)%9a*"*&23c3(%36%2>
c*W)553(a4%ffP\3	%955G3(!W#;5<_,#.7<D.7G`_5O!W#<P23(2#O*&%!W#*&Da!I
c25*&D!W#;7G_5)23(2a*"2C%c!I#5<_V,c#+53(/23>!WO!&*W3.3cO94=7D
4<## x |2}}a<#^4% x |}}Z<|2}}}*&2%-3(N2362O!W#.53(2536%%!I#;54%#
94-!W#5T*W%%-3(N;2#7<DS94%-P3O*Ia%2>N4Na!I#!F23(2#QP^94%<553(4%
#3c553(a4{!&%94r!W#=aPT94%=*&2%>Q423(Zg94 y XE!W#<P23(2#KO4<#!"%:!"%
%{!I#3(23-;2#23*"2C%2>-N4!&%4a%N94`a/V#<9;:4-!I#%O2%%('E!W#K#:3%
3ff4#!&:'A53(P*&2#;:43ff3(%363(!"#%3(N;3#<>	N,-/23Z<94c*"2C
O4#!&%9O%T%7<DSg4% x |}}7gZ|}}Z<|2}}};2#23ff!&7
 2%kD *&2C%2>	N2#Z:4!I3
5<2#!Ia*,S>3>2>94%!&SPb94`3(%3(S3(!&#!&%*&!WO!&>
c:423S553(4%O936D+D#O!&2*&*&DB23(2a#!&O*&2%O3(!W#;=:4.53(P3#PN94
y XU53(/23 x c%934# !"r*\ZO|2}}G?,N#CZS|2}<}c%934#Ezg/*W#ZO|2}}>


fi

J    J++uM'++'

  +x+~+



'z+++;+{

QP23Q24{%9%%(P*	%*W!&#{PN%97;<*	*&2)!";4S7G`;<2#23=#=K94
!W#5*W%%2>=Q4+!WaP94!&%r!W#LP*&2C+;<2#23!&#M!&%O=53()*"2C%O94O3(
7*&K3(K94K%23(4=#O7D*&!WO!W#!W#;L3(252B%97<_!"#%2>#K23(!&!&!&%9
3(;<3(!W#;94!&%r<!W#+Pb*"2C;<2#23!&#K!&%N94Pa:4-!"c!&%#*&23Q,49423Q3-#%:P*
*&2%K2#7+;<2#23>EN423({!"%)#M;3#<K94*&2C%.2<#1753(36!I#;
9453(P3#,4!&42#{#:3(!W7))53(P6Zg!\>>g,c4!"42#7(
 936:_%j >^3(9423O3(Z
%*W3(2DO2#!"#Z94O;2#23a*"2C%S3(O%9*&*&D=#S%c;2#23*	%S5<%%!W7*&
!W#%9#<!W!&#%CO!W#;=P3(94)%*W!&#%P%97;a*"%K53(/!&%*"DL%*&/>1N4!&%2#L36
94S55*&!&27!&*&!&D{PTS*&2C*&94;4K:4
 ;2#23*&!&j )53(aP*&7GS3(:_%KP\3N3(:P!W#;
94{!I#5)*W%%2>N4%2ZN*&94;4L%O43653(7*&2O%)*"E#*&D17G%*&/1,N!&94%94
*&2K4#!&% x %`c%934<#+Rzg/*W#ZT|}}Zg#)%9<7*"O%9%%`4%S7G2#=3(253(
/23O{*I<3(;)%OP5367*&2O%2>LN4+!W#M!&%9/#<9;%aP*&*553(4%O,4!&4L#*&DL!W
N%:553(!I#;K5<_,#)536V/<23(%-3(!&;!W#P3(R94cPN94Q!I#%O!W#%2Z%95G!W*&*"D!0P
*&!"(D{!"%!W#</*&/Zg%95G235<%!&!&#<_7%B536V/<23(%N*&23(*&D95G23P3 y XE53(/23(%2>NN4%2Z[!W#
%94{!W#%c!"SC2D)7O3(S%2#%!I7*&./*&5{4#!&%!W#+3(23N.%955G3(c94`3(
5,-23P*7_5)53(/23-:4#K94,-2r23-5<_,#.536V/<23>
?#O3(23b!IC53(/7<_5C53(aP^%2364O7<D%!I#;5<_,#5G23P\3O!W#<P\23(2#%-94
P\*&*",N!W#;553(4%T4/c72#C25*&VD<>		!W3(%*&DZa;!W#O#536V/<23 x 94N7G`_553(/23
!&%%%!&%L7<D=*W%%23(!&/MP3(#942353(/23 x 94.5<_,#=53(/23>+N4)553(4
P3(U*&!0F x |}}-%%N*&2C%;<2#23+7<D;!&*&!W#23c!&#%D%2 x <#+#
%97;**W%%9N!W#3(23N.%955G3(3(%*W!&#<_7a%B53(/23(%>-S`.94*WrPT;a*3(!0_
2#<9!&# x %O%23(!W7J!I#E!&#>94!&%O:4*&#KD!&*&E#</!W#!W#;13(%9*&%K!W#
53!">ff#*&DZ94236S3(553(4%N<r7G_5.536V/<23(%NO3(c;*0_!W3(7D
P\3(!W#;.:42R,-3r#*&D),N!&94)%OS3(*&/V#<c*I<%%,c4!"43(7<D.5<_V,c#K2*0_
2*W!&#%2>ffN494%-%236!I7G7<D<#!"*W4#N*\> x |2}<~Z!&r* x |2}}aZ#)a%;,N
*\> x |2}}Y93#%6P3%NP*W%%!W#<.#:423-*W%S%N,4!&4!&%942#K/*W{!I#{
7<_5<##23>N4%95G!0])93#%(P\3C!&#+536V/!&%`KO7!W#!&#PN5<_,##
7<_5C53(%%!W#;.#)53#%-947G_5O/Va*Ia!&#K`36*"/#<*W%% x ,4!&4.7G23
C##!&#)K53(aP;a*I>N4%2Zg7</!&%*"D{947_5{53(aP%2364{7O%S3(
;a*	3(!&2#>)*&%{94)O94=%23(!W7E7D=zg/*W#M`a*> x |2}}<53(/!&%+36*"/#D
%!I#;P3C7_5M2*&2*W!&#%2>$-%1#M5<_V,c#L53(aP25%O943(*&/V#DLP
)*W%.!&%SD#O!&2*&*&DM23O!W#M3(!W#;:47G`_5+2a*"2*W!"#g>+?##<93%)3
O94)!W#)94%`553(4%Q94S7_5)53(/23-4%Q9r<*":4,4*&`53(P:%9r[>T3
553(4P\3%!I#;L5<_,#M;2#231%97;*N*W%%K!W#7_5L53(/23O%)#
53(/!")+36*"/#D=%!W#;aP7<_5!W#<P2362#7O%955G3(%94.7<_5!I#<P\23(2#
53(%%7<DO%!W5*&!0PD!W#;.94Q3(!&;!W#*;<*\>	N4%Z94536P*&2#;94KD`7G%:43(2#>b^369423_
O36Z53(%TP94N%23(4%95aNP947_553(/23Z,4!&4#<9!W#36*"/#<N*W%%N7
D+7O!0.2*&S.2#O23Z2#7G`:3/23(%+7<DC%!W#;*&!W#<P2362#,4!&453(/!&%*I<3(;
%2364)3(!"#%2>
9<   


##!"gZ`>ZV$z#;25GZXQ> x |2}}a>55*&D!W#;.zc_3(%*W!&#OSc*Ia%%TP##<_43#*"<;!&
53(;3<O%2>	Npouo&tw\qulfN>SwYqt     Z  x <Z|4a>
I

fi

 

wyz{

wyz{

c%934#gZ-O>WZTzg/*W#Z-> x |2}<}|2> y XTNXffcgdffN!&;4523P\3<#+9436253(/23(%
%!W#;O**&!WO!W#!&#g>?#pw\fsOnw\t:j-t9nfl[qul%ff9nX|Tqvlfl[fTfN>)f2fjX|cNo"t:jf2t>
~ *I<,-23-c22O!&  7*&!&%9423(%2>
c%934#gZO>WZzg/*W#Z> x |2}}>N4S%P	*"2C%N!W#):4`O**&!WO!W#!&#53(:_
3(
> fp:ln<ofN> pw\fsOnw\t:jt:nflqvl<Z 
	 x |2Z^|<|2^|[|>
c%934#gZO>WZJ!&r*\Z y > x |2}}>Q4!W#;S#C*"2C!&!W#;`!W#*[*"!WO!W#!"#943(2
53(/23(%2>	?#  (f2m:t9t:jqvlcfN>fiff.p%Ti o Z55g>aG>53(!W#;23Z[z  ?N~<>
-4!W3Z-z	>WZT #!W#;23ZN> x |}}>,c3(!&:_7%!"#*N9436253(/!W#;M,N!&94
%*&!&#+#{%!W5*&!0]2!&#g>fp:ln<ofN>  f:qvmSnl[jffTf<sNhgpw\nw\qvfl[Z x Z|G>
-#!&*W4#gZ	N>WZ y !&23Zg>WZa;!&/^Z`>WZb @Q*"*W<##gZ[> x |2}~<> y ;!&%%S#=9423c%93#;
,D%+!W5*&2O2#<*&;!&+53(<;3O%>.?#  (f2m:t9t:jqvlOfN>wYq/ff  ci  ffe
fi|sQhfqupsUfl  9qvlmqh^o&tfN
> nw\nn
t fi|w\t2sZ55g>|4^|2>
ff#!W#Z y > x |2}}~<>.#94)3(#%93!&#P536P\%S!W#!&%93(!W7L943(253(/!W#;dO
O!0]{*I<%:_!0F%!"#94>fp9l[nogfN>fi|sf<o"qvmfffffsQh^pw\n<w\qufl[Z  x Z<G>
ff#!W#Z y >WZUQ%!W#;Z > x |2}}<>N4*W%:_!0F%!&#LO:4*&;<D+P\3!"%93(!W7M:_
!&#g>  pl[jnsOt2l[w\n  l> f9sOnw\qvm:nt2Z  Z|2>
-#36DZg>XN>Z y 2?#<%94gZG>![>WZ y D23Z`>O> x |2}<}>bcXTgd!&%93(!W7=
3(2%#!W#;%D%2)>	?#  (f2m:t9t:jqvlcfN>pp  i 	#" Z55g>>
2#!W#;23Z$[> x |2}}> ~ #V,Q*";<:_7%+!&%:3(!W7)%23(4)%!W#;.-2<S,-3r>g?#  fm9t:t:jqul
fN>  ff[i 	 Z55g>G|4><c?v_  36%%2>
2#!W#;23Z%>WZA^4%2Z> x |}}>XT#4#!W#;O#</2#<!&#*%2364O%D%2O%	,N!&94O*&!0_;2#<
4#!&%2dT2%%9D>?#  (f2m:t9t:jqvlaf>  ffi 	#& Z55g>[|2}<>?XffXTXL-C523
!&(D>
2#!W#;23Z#>Z2Lg4%2Z y > x |2}}>a*3(!&2#<S!&#*<943(2H53(/!W#;>?#  fm9t:t:jqul
fN
> '  i 	 Z55g> [>53(!W#;23Zgz  ?-~G|>
2#!W#;23Z(>WZ^4%2Z y >WZVg4%2Z y > x |2}}<>Q!";4`5G23P\3#ffT  %D%2%7DO7!W#!I#;
%/23*g?-O94%2>T?#  (f2m:t9t:jqvlcfN>  )ff. fi* 	$+ Z55g>|^|2<>
	!&!W#;Z y > x |2}<}~>  qvwvi,N(jt  f:qvmSnl[j_pw\fsOnw\t:j=eqt:f(t2s  (f2qvl<>	53(!W#;23>
^4%2Zb> x |2}<}>5G23!&#PN5<_,#=#M7_5943(253(/236%`7<D%:7;*
*I<%S93#%(P\23>	?#  (f2m:t9t:jqvlNfN>q  ff	i 	#& Z55g>|2^|2~}>53(!W#;23Zgz  ?c|<~>
^4%2Zc> x |2}}7>-5*&!W#;E%993a!&#<_7%536V/<23(%+7DE4<#;!W#;5<%!&!&/2#;!"/<
!I#<P\3C!&#g>T?#  (f2m:t9t:jqvlafN>eji 	-& Z55g>|2|>53(!W#;23Zgz  Q|2}>
^4%2ZQ> x |}}2>Ec!I362O2#6_7%$523!&/943(253(/!I#;[> ?#  (f2m:t9t:jqvlafN>
%   i 	-& Z55g>|2}g|2>53(!W#;23Zgz  ?c|}G>
I

fi

J    J++uM'++'

  +x+~+



'z+++;+{

^4%2Z y > x |2}}<>	*"!W7*&+53(aPu_3(25*WD,N!&94M423(!&%!&%2>)?#  (f2m:t:t9jqvlaSfN>,%   
| ^|2>53(!W#;23Zgz  ?c|2<>
4

* 	$+ Z	55g>

^4%2Z y > x |}}>c*&/V#D<_7%H*&2L%*"!"#JP3)**"!WO!W#!"#%!W#;1*WD
97*&2K2#O23!&#g>-?#  (f2m:t9t:jqvlNfN>D%.ff.  i 	#& Z55g>^a~<>#4#  !&*&D#%2Z
zg>
^4%2Z y > x |2}}<7>gD%27%:32db!I!"*W36!"(D<_7%{*"2C;2#23!&#P\3	O*^*&!WO!W#_
!&#g>T?#  (f2m:t:t9jqvlaNfN>fiff.p%Ti  Z55g>>53(!W#;23Zgz  ?c||<>
^4%2Z y > x |2}}}<>)zg2{;2#23a!&#P\3O*ff*&!I!I#a!&#17<D=O7!W#!W#;=5<_,#M#
7_5K!W#<P2362#>?#  (fm9t:t9j<qulfN>  /ff.  i 	
	 > y 3(;# ~ <P##gZ.552<3>
c33(!&%#gZ#[> x |}}~>5!I!"!W#;53(P%2364!W#OO**&!WO!W#!&#g>?#  fm9t:t:jqul	fN>ff.#%ffi
# 0 Z55g>G|2<>53(!W#;23Z^z  ?|<|2>
c%;,NZff`>WZ-?#Z ~ >ZN49GZt`>WZN ~ %:4!IO3GZ y > x |2}<}>  #<_43#;!&%%K
!I#353K5<_,#!W#<P\23(2#)!W#=7G`_5=943(253(/!W#;>?#  (f2m:t:t9jqvla`fN>
ff.p%Ti  Z55g>|2~ ^|}>536!I#;<23Zz  ?|2}>
?\,N#Z ~ > x |2}<}>Kzg24!W#;{P3S  N  _7%M5<_,#943(253(/23>)?#
 (f2m:t9t:jqvlaf>fiff.#%ffi  GZ55g>|~^|2~>53(!W#;23Zgz  ?c|2}>
~ 3PZ`>XN> x |2}<>[2594<_\]^3(%-!&23a!&/:_252#!W#;d-#K5!W*!"%%!W7*"93(c%23(4g>.  Z
 + Z}|}>	X	*&%/!&23  7*&!&%9423(%Sc>dO> x  3694<_N<*"*W#>

zgZG`>WZ y 2D3Z ~ >WZ*&*&23Z> x |2}}a>-#<93(<*"*&)!W#<;3!"#Pb942N3*&S!W#`##:_
!&#K97*&22*&2*"!\>fp9l[nofN>ppw\fsOnw\t:jt:nflqvl<Z -0 Z}>
zgZffO>WZ	4##gZ[>WZT-D23(*\Zg>Z ff!W7*\Z  > x |2}}<>XTNcXTOdb 4!";4<_523P\3<#
943(2U536V/<23
> fp:lnofp
> pw\f<s`n<w\t9j-t9nfl[qulZ & x Z|2|2>
zg/*W#Zff> x |2}~<> y 4<#!"2a*N943(2`_53(/!W#;B7<DBO*-*"!WO!W#!"#g>1f<p:lno-fN>+wYqt
ffZ   x >
zg/*W#Z> x |2}<>.pw\fsOnw\t:j=eqt:f(t2s  (f2qvlNn  f9qvm:no[naq>  3(94<_Q*&*W#>
zg/*W#Z>WZ<Z<>WZ  !&*&%#gZ> x |2}}>TNN y cXQdTNN y J,N!&94CXY*&/V#Dg>
fp:lnofp> pw\f<s`n<w\t9j-t9nfl[qulZ  Z<G|>
y 3r/!&4gZg>WZ2Z  > x |2}}<>?#<P\3C!&#]*"23(!W#;d*&!&#{O4#!&%9O%N!W#)*&23#!I#;
%D%2O%2
> n<mqqvlt  t9n<9l[qulZ -" x <Zg||2^||>
y !W##gZg> x |2}}<>!2#<!&9!"/<36%9*&%T#23#!I#;94N!&*&!"(DOPg5*W#!"#<_7%*&23#!W#;>
9w\q 3mqun<o  lw\t2ovo&q"<t2l[m9tZ
  Z~<}|<>X	*&%/!&23!&2#  7*&!"%:423(%2>
y %23Z y >WZ?72#%2ZO>ZzZ`>WZ!W#7a4gZ$[>WZ[*&*&23Z>WZ4##gZ$[>WZ y D3Z ~ > x |2}}>
N4O**&!WO!W#!&#$53(/236%XffNXff#X_XTNcXTO>4fp:ln<ofN>pw\fsOnw\t9j
t:nf<lqvlZ # & x >
2

fi

 

wyz{

wyz{

c7!W#%#gZ%> x |2}~<>C4!W#36!"2#<K*&;!&S7%K#C9436%*W!&#K53(!W#!I5*&>5f<p:lnogfN>
wYqtqffZ  x |2>
4<##gZ> x |2}}>L*&9_=7<_553(253(%%3P\3O5<_,#943(2 53(/23(%2>
%D%2R7%93a2>	?#  (f2m:t9t:jqvlcfN>ff.#%ffi  Z[55g>>53(!W#;23Zgz  ?-|>
!&r*\Z y > x |2}<>R53(*&;)4#*&;D94362 53(/23d?5*&2O2#<9!&#=7<D=#{2#
53(*&;C5!"*&23>5fp:ln<ofN> pw\fsOnw\t:j6t:nf<lqvlZ$Z[<>
!&r*\Z y > x |2}}>l@c5%!&:_V,c#1O9V_!I#<235369!&#P:4O*N*&!WO!W#!&#E943(2_
53(/!W#;S53(3(QP3b!"#)#.7G!&#g> f<p:lno[fN>pw\fsOnw\t:jt:nflqvl<Z -0 Z
|2} G|2>
*&!0FZO> x |2}}<>E423(;2#%53a*"*&*g!&#C%D%2)>?#  (f2m:t9t:jqvl-fN> 
)fK}_qf:h7 0 >


ff * 	

*&!0FZ`>ZV9#23Z> x |2}<}>N4N    53(7*&2H*&!W733(Dgd	  3(*&2%-/g|>>W|<>%fp:lno
fNp
> pw\fsOnw\t9
j -t9nafl[qulZ  Z|2<G>
*&!0FZO>WZ9#23Z^> x |2}}<>N4O3(%9*&%cP	94S-cSXb_9|2OT  %D%2R5!&!&#g>
fp:lnofp> pw\f<s`n<w\t9
j -t9nfl[qulZ #& x Z|~>
*&!0FZO>WZ9#23Z>WZ 	2O2#!&%2Z> x |2}}a>N4N    53(7*&2*&!I733(D>g?#  fm9t:t:jqul
fN
> ff.#%ffi  Z[55g>~~>z  ?-|>
bO2Z> x |2}}<>	#*0P6>8fp:lnof> 
 pw\fsOnw\t:j-t9nfl[qulZ #& x Zg|2}}>
 !&2#74gZ->WZffZ	>ZTUcr[Zff`> x 2| }}~>5a%%U	*&23	236%!&#BG>>+?#  (f2m 
ff.p%Ti # 0 Z55g>|4| ^|>536!I#;<23Zz   ?||2>
 *0PZSO>WZ^4%2Z y > x |2}}>-523a!&/5<3*&*&*.C$943(2 53(/!W#;>?#
4#2r2#73(;23Z>Z *"*W#23ZcO> x XY%2>Za|Vl[nsOqum  f2n<j9qw\9q\pw\quf<lx>f  n(nouo&to
-hhgo"qvm:nw\quf<lZ55g>b|2
} ^|>27#23>

I

fiJournal of Artificial Intelligence Research 10 (1999) 353-373

Submitted 8/98; published 5/99

\Squeaky Wheel" Optimization
David E. Joslin

david joslin@i2.com

i2 Technologies
909 E. Las Colinas Blvd.
Irving, TX 75039

David P. Clements

Computational Intelligence Research Laboratory
1269 University of Oregon
Eugene, OR 97403-1269

clements@cirl.uoregon.edu

Abstract

We describe a general approach to optimization which we term \Squeaky Wheel" Optimization (SWO). In SWO, a greedy algorithm is used to construct a solution which is
then analyzed to find the trouble spots, i.e., those elements, that, if improved, are likely
to improve the objective function score. The results of the analysis are used to generate
new priorities that determine the order in which the greedy algorithm constructs the next
solution. This Construct/Analyze/Prioritize cycle continues until some limit is reached, or
an acceptable solution is found.
SWO can be viewed as operating on two search spaces: solutions and prioritizations.
Successive solutions are only indirectly related, via the re-prioritization that results from
analyzing the prior solution. Similarly, successive prioritizations are generated by constructing and analyzing solutions. This \coupled search" has some interesting properties,
which we discuss.
We report encouraging experimental results on two domains, scheduling problems that
arise in fiber-optic cable manufacturing, and graph coloring problems. The fact that these
domains are very different supports our claim that SWO is a general technique for optimization.

1. Overview
We describe a general approach to optimization which we term \Squeaky Wheel" Optimization (SWO) (Joslin & Clements, 1998). The core of SWO is a Construct/Analyze/Prioritize
cycle, illustrated in Figure 1. A solution is constructed by a greedy algorithm, making decisions in an order determined by priorities assigned to the elements of the problem. That
solution is then analyzed to find the elements of the problem that are \trouble makers." The
priorities of the trouble makers are then increased, causing the greedy constructor to deal
with them sooner on the next iteration. This cycle repeats until a termination condition
occurs.
On each iteration, the analyzer determines which elements of the problem are causing
the most trouble in the current solution, and the prioritizer ensures that the constructor
gives more attention to those elements on the next iteration. (\The squeaky wheel gets the
grease.") The construction, analysis and prioritization are all in terms of the elements that

c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiJoslin & Clements

Analyzer
Blame

Solution

Constructor

Priorities

Prioritizer

Figure 1: The Construct/Analyze/Prioritize cycle
define a problem domain. In a scheduling domain, for example, those elements might be
tasks. In graph coloring, those elements might be the nodes to be colored.
The three main components of SWO are:

Constructor. Given a sequence of problem elements, the constructor generates a solution

using a greedy algorithm, with no backtracking. The sequence determines the order
in which decisions are made, and can be thought of as a \strategy" or \recipe" for
constructing a new solution. (This \solution" may violate hard constraints.)

Analyzer. The analyzer assigns a numeric \blame" factor to the problem elements that

contribute to aws in the current solution. For example, if minimizing lateness in
a scheduling problem is one of the objectives, then blame would be assigned to late
tasks.
A key principle behind SWO is that solutions can reveal problem structure. By analyzing a solution, we can often identify elements of that solution that work well, and
elements that work poorly. A resource that is used at full capacity, for example, may
represent a bottleneck. This information about problem structure is local, in that it
may only apply to the part of the search space currently under examination, but may
be useful in determining where the search should go next.
Prioritizer. The prioritizer uses the blame factors assigned by the analyzer to modify
the previous sequence of problem elements. Elements that received blame are moved
toward the front of the sequence. The higher the blame, the further the element is
moved.
The priority sequence plays a key role in SWO. As a dicult problem element moves
forward in the sequence it is handled sooner by the constructor. It also tends to be handled
better, thus decreasing its blame factor. Dicult elements rise rapidly to a place in the
sequence where they are handled well. Once there, the blame assigned to them drops,
causing them to slowly sink in the sequence as other parts of the problem that are not
handled as well are given increased priority. Eventually, dicult elements sink back to the
point where they are no longer handled well, causing them to receive higher blame and to
move forward in the sequence again. Elements that are always easy to handle sink to the
end of the sequence and stay there.
354

fi\Squeaky Wheel" Optimization

Iteration: 1 Priorities: C,A,B
Late: A (20), B (30)

0

10

20

C

Iteration: 2 Priorities: B,A,C
Late: A (20), C (10)

0

10

A

20

B
Iteration: 3 Priorities: A,C,B
Late: B (30)

0

10

A

30

A

C

50

B

30

20

40

40

Task
A
B
C

Duration Deadline
10
10
20
20
40
20

50

C
30

40

50

B

Figure 2: Simple example
To illustrate the SWO cycle, consider a simplified scheduling example. Suppose we have
a single production line, and three tasks to schedule, A, B and C . Only one task can be
performed at a time. Execution starts at t = 0. The duration and deadline for each task
is shown in Figure 2. The objective is to minimize the number of late tasks. An optimal
solution will have one late task.
Suppose our initial priority sequence is hC; A; B i, and the constructor schedules tasks
in order, at the earliest possible time. The resulting schedule has two late tasks (B and
A). Suppose that our analyzer assigns one point of \blame" to each late task, for each
unit of time it is late. In this case, A, B , and C receive 20, 30 and 0 units of blame,
respectively. Figure 2 shows the prioritization, the schedule that the constructor builds
from that prioritization, and the late tasks with the blame assigned to each.
For the next cycle, the prioritizer must take the previous priority sequence, and the
blame assigned by the analyzer, and generate a new priority sequence. A simple prioritizer
might just sort the tasks by their numeric blame in descending order, resulting in the new
priority sequence hB; A; C i.
After the second cycle, tasks A and C are late, scoring 20 and 10 points of blame,
respectively. The new priority sequence is then hA; C; B i.
The third solution, constructed from this priority sequence, has only one late task, B ,
which receives 30 points of blame. At this point we have an optimal solution. If we continue
running SWO, however, as we might expect to do since we typically do not know when we
have reached optimality, SWO will attempt to fix what was wrong with the current solution.
Here, since task B was late, its priority would be increased, and the resulting solution would
fix that problem at the expense of others. (We would also enter a short cycle, alternating
between the last two schedules. We address this by introducing some randomization in the
prioritizer.)
Although this example is highly simplified, and there would clearly be better and more
sophisticated ways to implement each of the three modules, Figure 3 shows that the behavior
illustrated by the simple example is reected in a real domain. The figure shows the changing
position in the priority sequence of three tasks in the scheduling domain that is described
in detail in the following section. One task (\Job 24") starts out with a high priority, and
remains at a relatively high priority level. We can see that when the task is scheduled
effectively, and therefore receives little or no blame, its priority tends to drop, but it does
355

fiPriority

(high)

Joslin & Clements

(low)

Job 24
Job 26
Job 39
1

2

3

4

5

6

7

8

9 10 11 12 13 14 15 16 17 18 19 20
Iteration

Figure 3: Examples of priority changes over time
not have to drop very far before it ceases to be scheduled well, acquires a significant level
of blame, and moves quickly back to a higher priority.
The other two tasks shown in the figure behave quite differently. One task (\Job 39")
starts out with a relatively high priority, but this task is \easy" to schedule, with little
blame, even when it is scheduled late in the sequence. Over successive iterations, the
priority of such a task will tend to decrease steadily. The other task illustrated here (\Job
26") does just the opposite, starting at a low priority and moving fairly steadily toward a
high priority.
The following section discusses the characteristics of SWO that make it an effective technique for optimization. We then discuss implementations of SWO for scheduling and for
graph coloring problems. The final sections discuss related work, describe directions for
future research, and summarize our findings.

2. Key ideas

As the experimental results below show, SWO is a general approach to optimization. In this
section, we explore a few insights into what makes SWO effective.
It is useful to think of SWO as searching two coupled spaces, as illustrated in Figure 4.
One search space is the familiar solution space, and the other is priority space. Moves in
the solution space are made indirectly, via the re-prioritization that results from analyzing
the prior solution. Similarly, successive prioritizations are generated by constructing and
analyzing a solution, and then using the blame that results from that analysis to modify
the previous prioritization.
A point in the solution space represents a potential solution to the problem, and a
corresponding point in priority space, derived by analyzing the solution, is an attempt to
capture information about the structure of the search space in the vicinity of the solution.
As SWO constructs a new solution from scratch, the priorities can be thought of as providing
356

fi\Squeaky Wheel" Optimization

Construct

p
Analyze/
Prioritize

p

s

Construct

s
Priority space
Solution space

Figure 4: Coupled search spaces
information about pitfalls common to the current region of the solution space. If some elements of the solution have tended to be sources of diculty over some number of iterations,
increasing their priority makes it more likely that the constructor will handle those elements
in a good way.
One consequence of the coupled search spaces is that a small change in the sequence of
elements generated by the prioritizer may correspond to a large change in the corresponding
solution generated by the constructor, compared to the solution from the previous iteration. Moving an element forward in the sequence can significantly change its state in the
resulting solution. In addition, any elements that now occur after it in the sequence must
accommodate that element's state. For example, in the scheduling domain, moving a task
earlier in the priority sequence may allow it to be placed on a different manufacturing line,
thus possibly changing the mix of jobs that can run on that line, and on the line it was
scheduled on in the previous iteration. One small change can have consequences for any
element that follows it, with lower-priority tasks having to \fill in the gaps" that are left
after higher-priority tasks have been scheduled.
The result is a large move that is \coherent" in the sense that it is similar to what we
might expect from moving the higher priority task, then propagating the effects of that
change by moving lower priority tasks as needed. This single move may correspond to a
large number of moves for a search algorithm that only looks at local changes to the solution,
and it may thus be dicult for such an algorithm to find.
The fact that SWO makes large moves in both search spaces is one obvious difference
between SWO and traditional local search techniques, such as WSAT (Selman, Kautz, & Cohen,
1993). Another difference is that with SWO, moves are never selected based on their effect
on the objective function. Instead, unlike hillclimbing techniques, each move is made in
response to \trouble spots" found in the current solution. The resulting move may be
uphill, but the move is always motivated by those trouble spots.
357

fiJoslin & Clements

In priority space the only \local optima" are those in which all elements of a solution are
assigned equal blame. SWO tends to avoid getting trapped in local optima, because analysis
and prioritization will always (in practice) suggest changes in the sequence, thus changing
the solution generated on the next iteration. This does not guarantee that SWO will not
become trapped in a small cycle, however. In our implementations we have introduced
small amounts of randomness in the basic cycle. We also restart SWO periodically with a
new initial sequence.
Another aspect of local search is that typically each point in the solution space is associated with a single value, the objective function score for that solution. When we talk about
hillclimbing, we generally refer to the \terrain" described by this objective function score,
over the space of solutions. The process of analysis in SWO can be thought of as synthesizing
a more complex description of that terrain, by breaking a solution down into its component
elements and assigning a score to each. Prioritization then translates the analysis into a
\strategy" that the constructor can use to generate the next solution.
Assigning scores to the individual elements of a solution allows SWO to take advantage
of the fact that real problems often combine some elements that are dicult to get right,
plus others that are easy. In the scheduling problems presented below, some tasks can be
assigned to just a few production lines, while others allow for much more exibility. Some
have due dates close to their release time, while others have a lot of leeway. It is sometimes
possible to identify \dicult" elements of a problem with static analysis, but interactions
can be complex, and elements that are causing diculty in one part of the search space may
be no trouble at all in another. Rather than trying to identify elements that are globally
dicult by analyzing the entire problem, SWO analyzes individual solutions in order to find
elements that are locally dicult. Globally dicult elements tend to be identified over time,
as they are dicult across large parts of the search space.
By assigning blame and adjusting priorities based on identified problems in actual solutions, SWO avoids dependence on complex, domain dependent heuristics. It is our belief
that this independence is particularly important in complex domains where even the best
heuristics will miss some key interactions and therefore inhibit the search from exploring
good areas that the heuristic incorrectly labels as unpromising. SWO uses actual solutions
to discover which areas of the search space are promising and which are not.

3. SWO for scheduling
This section describes an application of SWO to a fiber-optic production line scheduling
problem, derived from data provided by Lucent Technologies. In this particular plant, a
cable may be assembled on any one of 13 parallel production lines. For each cable type,
only a subset of the production lines are compatible, and the time required to produce the
cable will depend on which of the compatible lines is selected. Each cable also has a setup
time, which depends on its own cable type and that of its predecessor. Setups between
certain pairs of cable types are infeasible. Task preemption is not allowed, i.e. once a cable
has started processing on a line, it finishes without interruption.
Each cable is assigned a release time and due date. Production cannot begin before the
release time. The objective function includes a penalty for missing due dates, and a penalty
for setup times.
358

fi\Squeaky Wheel" Optimization

3.1 Implementation

We describe the implementation in terms of the three main components of SWO:

Constructor. The constructor builds a schedule by adding tasks one at a time, in the

order they occur in the priority sequence. A task is added by selecting a line and a
position relative to the tasks already in that line. A task may be inserted between
any two tasks already in the line or at the beginning or end of that line's schedule.
Changes to the relative positions of the tasks already in the line are not considered.
Each task in the line is then assigned to its earliest possible start time, subject to the
ordering, i.e., a task starts at either its release time, or immediately after the previous
task on that line, whichever is greater.
For each of the possible insertion points in the schedule, relative to the tasks already in
each line, the constructor calculates the effect on the objective function, and the task
is placed at the best-scoring location. Ties are broken randomly. After all tasks have
been placed, the constructor applies SWO to the individual line schedules, attempting
to improve the score for each line by reordering the cables that were assigned to it.

Analyzer. To assign blame to each task in the current schedule, the analyzer first calculates

a lower bound on the minimum possible cost that each task could contribute to any
schedule. For example, if a task has a release time that is later than its due date,
then it will be late in every schedule, and the minimum possible cost already includes
that penalty. Minimum possible setup costs are also included. For a given schedule,
the blame assigned to each task is its \excess cost," the difference between its actual
cost and its minimum possible cost. Excess lateness costs are assigned to tasks that
are late, and excess setup costs are split between adjacent tasks.

Prioritizer. Once the blame has been assigned, the prioritizer modifies the previous sequence of tasks by moving tasks with non-zero blame factors forward in the sequence.
Tasks are moved forward a distance that increases with the magnitude of the blame.
To move from the back of the sequence to the front, a task must have a high blame
factor over several iterations. We call this a \sticky sort."

Our current implementation has considerable room for improvement. The analysis and
feedback currently being used are very simple, and the construction of schedules could take
various heuristics into account, such as preferring to place a task in a line that has more
\slack," all other things being equal.

3.2 Experimental results

We have six sets of test data, ranging in size from 40 to 297 tasks, all with 13 parallel
production lines. The largest problem was the largest that the manufacturer required in
practice. We compare the following solution methods:
SWO

Applies the SWO architecture to the problem, running for a fixed number of iterations
and returning the best schedule it finds.
359

fiJoslin & Clements

Data
Set
40
50
60
70
148
297

Best
Obj
1890
3101
2580
2713
8869
17503

SWO

Avg
Obj
1890
3156
2584
2727
8927
17696

Avg
Time
48
57
87
124
431
1300

TABU

Obj
1911
3292
2837
2878
10421
|

Time
425
732
1325
2046
17260
|

IP

Obj
1934
3221
2729
2897
|
|

Time
20
175
6144
4950
|
|

Table 1: Experimental results: scheduling
TABU

IP

Uses TABU search (Glover & Laguna, 1997), a local search algorithm in which moves
that increase cost are permitted to avoid getting trapped at local optima. To avoid
cycling, when an \uphill" move is made, it is not allowed to be immediately undone.

Applies an Integer Programming (IP) solver, using an encoding described in (?).

On the 297 task problem, SWO was far more effective than either TABU or IP. TABU,
for example, failed to find a feasible schedule after running for over 24 hours. On the
smallest problems, TABU and IP were able to find solutions, but SWO outperformed both by
a substantial margin.
Table 1 presents results on each problem for SWO, TABU and IP. For SWO, ten trials were
run and the results averaged. The TABU and IP implementations were deterministic, so
only the results of a single run are shown. The second column of the table shows the best
objective function value we have ever observed on each problem. The remaining columns
show the objective function value and running times for SWO, TABU and IP. All but the IP
experiments were run on a Sun Sparcstation 10 Model 50. The IP experiments were run on
an IBM RS6000 Model 590 (a faster machine).
The best values observed have been the result of combining SWO with IP, as reported
in (?). In that work, SWO generated solutions, running until it had produced a number of
\good" schedules. An IP solver was then invoked to re-combine elements of those solutions
into a better solution. Although the improvements achieved by the IP solver were relatively
small, on the order of 1.5%, it achieved this improvement quickly, and SWO was unable to
achieve the same degree of optimization even when given substantially more time. While
noting that the hybrid approach can be more effective than SWO alone, and much more
effective than IP alone, here we focus on the performance of the individual techniques.
We also note that our very first, fairly naive implementation of SWO for these scheduling
problems already outperformed both TABU and IP. Moreover, our improved implementation,
reported above, is still fairly simple, and is successful without relying on domain-dependent
heuristics. We take this as evidence that the effectiveness of our approach is not due
to cleverness in the construction, analysis and prioritization techniques, but due to the
effectiveness of the SWO cycle at identifying and responding to whatever elements of the
problem happen to be causing diculty in the local region of the search.
360

fi\Squeaky Wheel" Optimization

10

# of lines job in that position can run on

8
6
4
2
0

0

2

4

6

0

2

4

6

8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38
Position in priority sequence
Order based on # of lines job can run on

10
8
6
4
2
0

8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38
Position in priority sequence
Order after 14th iteration, producing a solution 0.05% over best known

Figure 5: Comparison of heuristic priorities and priorities derived by SWO
It is also instructive to compare the results of a good heuristic ordering, with the sequence derived by SWO. A good heuristic for this scheduling domain (and the one that is used
to initially populate the priority sequence) is to sort the tasks by the number of production
lines on which a task could be feasibly assigned in an empty schedule. A task that can be
scheduled on many lines is likely to be easier to schedule than one that is compatible with
only a small number of lines, and should therefore be expected to need a lower priority. The
top graph in Figure 5 shows the sequence of tasks, as determined by this heuristic. The
lower graph illustrates the changes in priority of these tasks, after SWO has run for fourteen
iterations (enough to improve the solution derived from the sequence to within 0.05 percent
of the best known solution).
As the figure illustrates, the heuristic is generally accurate, but SWO has had to move
some tasks that are compatible with most of the production lines to positions of relatively
high priority, reecting the fact that contrary to the heuristic, these tasks turned out to be
relatively dicult to schedule well. Other tasks that are compatible with only a few production lines are actually easy to schedule well, and have moved to relatively low priorities.

3.3 Restarts
The SWO solver used to produce the results reported in Table 1 restarted the priority
queue every n=2 iterations, where n is the number of jobs in the problem. The same noisy
heuristic that was used to initially populate the priority queue was also used to restart
it. This restart cutoff was picked in a rather ad hoc manner. A more careful analysis of
361

fiJoslin & Clements

Iterations
Feasible
< 18000
< 17700
per Success Mean Success Mean Success
Mean Sample
Restart
Rate Cost
Rate Cost
Rate
Cost
Size
10 0.8542
5.9 0.0504 195.3 0.0002 49994.5 10000
20 0.9722
6.0 0.2052 90.9 0.0006 33328.3
5000
30 0.9955
5.8 0.3812 67.5 0.0030 9895.5
3300
40 0.9996
5.8 0.5488 56.7 0.0060 6658.2
2500
50 0.9995
6.0 0.6330 57.0 0.0160 3112.7
2000
60 1.0000
5.7 0.7242 52.9 0.0188 3170.4
1650
70 1.0000
5.7 0.8079 50.2 0.0350 1973.5
1400
80 1.0000
6.2 0.8552 49.5 0.0296 2670.0
1250
90 1.0000
5.8 0.8827 48.9 0.0300 2965.3
1100
100 1.0000
5.9 0.8840 52.4 0.0400 2452.3
1000
200 1.0000
6.0 0.9680 53.0 0.0600 3204.3
500
300 1.0000
5.3 0.9967 50.1 0.0567 5090.8
300
400 1.0000
5.8 1.0000 52.9 0.0720 5320.2
250
500 1.0000
5.8 1.0000 52.8 0.1000 4692.6
200
600 1.0000
5.8 1.0000 57.2 0.0867 6590.8
150
700 1.0000
6.1 1.0000 42.4 0.1200 5472.4
100
800 1.0000
5.6 1.0000 53.0 0.1200 6210.3
100
900 1.0000
5.3 1.0000 45.8 0.1700 4691.6
100
1000 1.0000
6.0 1.0000 45.4 0.1800 4838.1
100

Table 2: Experimental results: restarts in the scheduling domain
different restart cutoff values might lead to producing better solutions faster, and to some
additional insight on the workings of SWO.
Restarts are often used in non-systematic search to avoid getting trapped in local optima
or in cycles. (See Parkes and Walser, 1996, for an empirical study of WSAT and further
references.) Restarts have also been used in systematic search to escape exponentially large
regions of the search space that do not contain a solution (Gomes, Selman, & Kautz, 1998).
Local optima pose little threat to SWO, since it is not directly driven by uphill/downhill
considerations. SWO, through its use of large coherent moves, also tends to escape unpromising parts of the search space quickly. However, SWO is open to getting trapped in a cycle,
and restarts are used as a means to escape them.
For these scheduling problems, SWO is unlikely to get into a tight cycle where priority
queues and solutions repeat exactly. This is due to the presence of random tie breaking in
several places, and to the presence of noise in the prioritizer. However, it is our belief that
SWO can get trapped in a cycle where similar priority queues and solutions repeat.
We ran a series of experiments with the 297 task problem to determine the impact of
various restart cutoffs. The results are summarized in Table 2. Restart cutoffs ranged from
after every 10 iterations to after every 1000 iterations. The success rate and mean cost are
shown for each value for each of three different solution qualities. The success rate indicates
the probability that a solution of at least the given quality was found in a given pass. The
mean cost is the average number of total iterations to get a solution of that quality.
For the feasible and 18000 solution thresholds, SWO reaches a 100 percent success rate
well before reaching the maximum restart cutoff of 1000 used in these experiments. In some
sense, it is easy for SWO to produce solutions that are at least of these qualities. The results
362

fi\Squeaky Wheel" Optimization

for these 2 thresholds indicate that when it is easy for SWO to solve the problem, any cutoff
greater than the average number of uninterrupted iterations it takes to produce a solution
can be used to solve the problem at minimum cost. For such \easy" problems, it appears
that too small a restart cutoff can hurt, but that too big a cutoff will not.
The numbers for the 17700 solution quality threshold, tell a different story. The success
rate is still climbing when the experiment ends, and the mean cost has actually risen above
its minimum. For this solution quality, the restart cutoff that minimizes mean cost falls
around the range of 70 to 100. Mean costs rise steeply for restart cutoffs below this range,
and slowly for cutoffs larger than that. This is an example of a hard problem for SWO, and it
shows that some care needs to be taken when choosing a restart strategy for such problems.
Additional research is needed to determine how to set the restart cutoff automatically for
arbitrary problems.
This data indicates that SWO does benefit from restarts, up to a point. With the 17700
threshold, for restart cutoffs up to 100, each increase in the cutoff in general led to a
superlinear increase in the success rate. (This is also another indicator that SWO is learning
from iteration to iteration.) Above 100 iterations per restart, the success rate initially
climbs sublinearly and then appears to level out. It is an open question what this tells us
about the search space.

4. SWO for graph coloring
We have also applied SWO to a very different domain, graph coloring. Here the objective
is to color the nodes of a graph such that no two adjoining nodes have the same color,
minimizing the number of colors.

4.1 Implementation

The priority sequence for graph coloring consists of an ordered list of nodes. The solver is
always trying to produce a coloring that uses colors from the target set, which has one less
color than was used to color the best solution so far. Again, we describe the implementation
in terms of the three main components of SWO:

Constructor. The constructor assigns colors to nodes in priority sequence order. If a

node's color in the previous solution is still available (i.e. no adjacent node is using
it yet), and is in the target set, then that color is assigned. If that fails, it tries to
assign a color in the current target set, picking the color that is least constraining on
adjacent uncolored nodes, i.e. the color that reduces the adjacent nodes' remaining
color choices the least. If none of the target colors are available, the constructor tries
to \grab" a color in the target set from its neighbors. A color can only be grabbed
if all neighbor nodes with that color have at least one other choice within the target
set. If multiple colors can be grabbed, then the least constraining one is picked. If no
color in the target set can be grabbed then a color outside the target set is assigned.
Nodes that are early in the priority sequence are more likely to have a wide range of
colors to pick from. Nodes that come later may grab colors from earlier nodes, but
only if the earlier nodes have other color options within the target set.
363

fiJoslin & Clements

SWO
IG
Dist. impasse
Par. impasse
TABU
Problem
colors
time colors
time colors
time colors
time colors
time
DSJC125.5
18.3
1.6 18.9
2.5 17.0
6.3 17.0 4043.6 20.0 153.3
DSJC250.5
31.9
8.3 32.8
6.9 28.0
268.5 29.2 4358.1 35.0 3442.2
DSJC500.5
56.3
40.9 58.6
18.2 49.0 8109.1 53.0 4783.9 65.0 3442.2
DSJC1000.5 101.5 208.6 104.2
67.6 89.0 41488.7 100.0 5333.8 117.0 3442.2
C2000.5
185.7 1046.2 190.0 272.4 165.0 14097.9
|
|
|
|
C4000.5
341.6 4950.8
346.9 1054.1
|
|
|
|
|
|
R125.1
5.0
0.2
5.0
2.0
5.0
0.2
5.0
64.6
5.0
0.4
R125.1c
46.0
5.1 46.0
1.1 46.0
0.2 46.0
85.0 46.0
0.9
R125.5
36.0
2.8 36.9
1.9 36.0
0.2 37.0
33.0 36.0
0.7
R250.1
8.0
0.5
8.0
7.0
8.0
0.2
8.0
22.0
8.0
0.2
R250.1c
64.0
30.6 64.0
4.6 64.0
0.5 64.0 278.2 65.0
46.4
R250.5
65.0
14.7 68.4
8.3 65.0
82.2 66.0
39.9 66.0
59.0
DSJR500.1
12.0
2.0 12.0
21.1 12.0
0.2 12.0
26.6 12.0
0.5
DSJR500.1c
85.2
96.9 85.0
14.6 85.0
59.1 85.2 5767.7 87.0 3442.2
DSJR500.5
124.1
68.7 129.6
26.1 123.0
175.3 128.0
90.5 126.0 395.1
R1000.1
20.0
8.0 20.6
87.2 20.0
8.2 20.0
49.9 20.0
1.7
R1000.1c
101.7 433.2 98.8
49.1 98.0
563.3 102.6 3940.0 105.0 3442.2
R1000.5
238.9
574.5 253.2 102.9 241.0
944.0 245.6 215.9 248.0 3442.2
at300 20 0
25.3
16.4 20.2
3.8 20.0
0.2 20.0 274.3 39.0 3442.2
at300 26 0
35.8
12.0 37.1
7.7 26.0
10.0 32.4 6637.1 41.0 3442.2
at300 28 0
35.7
11.9 37.0
9.6 31.0 1914.2 33.0 1913.5 41.0 3442.2
at1000 50 0 100.0 203.9 65.6 146.3 50.0
0.2 97.0 7792.7
|
|
at1000 60 0 100.7 198.0 102.5
87.3 60.0
0.2 97.8 6288.4
|
|
at1000 76 0 100.6 208.4 103.6
79.6 89.0 11034.0 99.0 6497.9
|
|
latin sqr 10
111.5 369.2 106.7
59.7 98.0 5098.0 109.2 6520.1 130.0 3442.2
le450 15a
15.0
5.5 17.9
17.0 15.0
0.2 15.0 162.6 16.0
17.8
le450 15b
15.0
6.1 17.9
16.2 15.0
0.2 15.0 178.4 15.0
28.4
le450 15c
21.1
8.0 25.6
14.5 15.0
57.2 16.6 2229.6 23.0 3442.2
le450 15d
21.2
7.8 25.8
13.5 15.0
36.3 16.8 2859.6 23.0 3442.2
mulsol.i.1
49.0
5.9 49.0
4.2 49.0
0.2 49.0
27.2 49.0
0.3
school1
14.0
8.4 14.0
10.5 14.0
0.2 14.0
46.3 29.0
90.7
school1 nsh
14.0
7.2 14.1
8.9 14.0
0.2 14.0
66.4 26.0
31.2

Table 3: Experimental results: graph coloring problems

Analyzer. Blame is assigned to each node whose assigned color is outside the target set,
with the amount of blame increasing for each additional color that must be added
to the target set. We ran experiments with several different variations of color-based
analysis. All of them performed reasonably.

Prioritizer. The prioritizer modifies the previous sequence of nodes by moving nodes with
blame forward in the sequence according to how much blame each received. This is
done the same way it is done for the scheduling problems. The initial sequence is a list
of nodes sorted in decreasing degree order, with some noise added to slightly shue
the sort.
364

fi\Squeaky Wheel" Optimization

4.2 Experimental results
We applied SWO to a standard set of graph coloring problems, including random graphs and
application graphs that model register allocation and class scheduling problems. These were
collected for the Second DIMACS Implementation Challenge (Johnson & Trick, 1996), which
includes results for several algorithms on these problems (Culberson & Luo, 1993; Glover,
Parker, & Ryan, 1993; Lewandowski & Condon, 1993; Morgenstern, 1993). Problems range
from 125 nodes with 209 edges to 4000 nodes with 4,000,268 edges.
Glover et al. (1993) is the only paper that is based on a general search technique, TABU
with branch and bound, rather than a graph coloring specific algorithm. This approach
had the worst reported average results in the group. Morgenstern (1993) used a distributed
IMPASSE algorithm and had the best overall colorings, but also required that the target
number of colors, as well as several other problem specific parameters be passed to the
solver. Lewandowski & Condon (1993) also found good solutions for this problem set.
Their approach used a hybrid of parallel IMPASSE and systematic search on a 32 processor
CM-5. Culberson & Luo (1993) used an Iterated Greedy (IG) algorithm that bears some
similarity to SWO. IG is the simplest algorithm in the group. Its solution quality falls between
the IMPASSE algorithms and TABU but solves the entire set in 1 to 2 percent of the time
taken by the other methods. Both IG and IMPASSE are discussed further under related
work.
Table 3 compares SWO with the results for IG (Culberson & Luo, 1993), distributed
IMPASSE (Morgenstern, 1993), parallel IMPASSE (Lewandowski & Condon, 1993), and TABU
(Glover et al., 1993). For each, one column shows the number of colors required for each
problem, and the run time (in CPU seconds). Bold face indicates that the number of colors
is within 0.5 of the best result in the table.
We used a Pentium Pro 333MHz workstation running Linux for the SWO graph coloring
experiments. The times shown for the other four algorithms are based on those reported in
(Johnson & Trick, 1996). The results for IG, IMPASSE and TABU are normalized to our times
using the DIMACS benchmarking program dfmax, provided for this purpose. Therefore,
timing comparisons are only approximate. Our machine ran the dfmax r500.5 benchmark
in 86.0 seconds; the times reported for the machines used on the other algorithms were
86.9 seconds for the TABU experiments, 192.6 seconds for IG, 189.3 seconds for IMPASSE,
and 2993.6 seconds for parallel IMPASSE. Because the dfmax benchmark runs on a single
processor, it is unsuitable for normalizing the times for parallel IMPASSE. We report their
unnormalized times.
A variety of termination conditions were used. SWO terminated after 1000 iterations.
IG terminated after 1000 iterations without improvement. Distributed IMPASSE used a
wide variety of different termination conditions to solve the different problems. The only
common element across problems was that distributed IMPASSE stopped when the target
number of colors, provided as an input parameter, was reached. The times reported for
parallel IMPASSE are the times it took to find the best solution that was found, not the time
it took the algorithm to terminate, which was always 3 hours. TABU ran until the algorithm
determined that it could make no further progress, or an hour had passed, whichever came
first.
365

fiJoslin & Clements

25
TABU

Avg. percent over best in group

20

15
Iterated Greedy

10
Squeaky Wheel

5

Par IMPASSE

Dist IMPASSE
0
0

10000

20000

30000
Time (CPU seconds)

40000

50000

60000

Figure 6: Experimental results: quality of solution vs. time
The TABU numbers are for a single run on each problem. The numbers for the other
algorithms are averages for 4 runs (parallel IMPASSE), 5 runs (distributed IMPASSE, parallel
IMPASSE) or 10 runs (SWO, IG, distributed IMPASSE) on each problem.
Figure 6 summarizes the performance of each technique on the set of 27 problems that
all of the algorithms solved. For each solver the graph indicates the average solution quality
and the average amount of time needed to solve the set. The ideal location on the graph
is the origin, producing high quality solutions in very little time. The points shown for the
other techniques are the points reported in each of the papers. The curve shown for SWO
shows how it performs when given varying amounts of time to solve the set. As the graph
shows, SWO clearly outperforms TABU, the only other general purpose technique, both in
terms of quality and speed. SWO also outperforms IG, a graph coloring specific algorithm,
both in terms of quality and speed. The IMPASSE solvers clearly produce the best solutions
in the group. However, IMPASSE is a domain specific method, and both solvers represent
much more programming effort. The SWO solver uses a general purpose search technique
and was implemented in less than a month by a single programmer.

4.3 Alternate configurations of SWO
We note that, as with the scheduling work, our first, naive implementation of SWO for graph
coloring produced respectable results. Even without color reuse, color grabbing, or the least
constraining heuristic (the first free color found was picked), SWO matched IG on 6 problems
and beat it on 10. However, on half of the remaining problems IG did better by 10 or more
colors.
To explore the sensitivity of SWO to such implementation details we tried the following
approaches in the constructor and prioritizer, and ran SWO using all combinations:
366

fi\Squeaky Wheel" Optimization

Construction: With or without color grabbing
Analysis: Either blame all nodes that receive a color outside the target set, or only the

first node (in the priority sequence) that causes a new color outside the target set to
be introduced. If color grabbing is used, the determination of blame is based on the
final color assigned to the node.

The difference in solution quality from the worst combination to the best combination
was less than 15 percent. Even when the alternative of using a standard sort instead of
the \sticky" sort (a fairly fundamental change) was added to the mix, the spread between
worst and best was still under 20 percent.

5. Related work

The importance of prioritization in greedy algorithms is not a new idea. The \First Fit"
algorithm for bin packing, for example, relies on placing items into bins in decreasing order
of size (Garey & Johnson, 1979). Another example is GRASP (Greedy Randomized Adaptive
Search Procedure) (Feo & Resende, 1995). GRASP differs from our approach in several ways.
First, the prioritization and construction aspects are more closely coupled in GRASP. After
each element is added to the solution being constructed, the remaining elements are reevaluated by some heuristic. Thus the order in which elements are added to the solution
may depend on previous decisions. Second, the order in which elements are selected in each
trial is determined only by the heuristic (and randomization), so the trials are independent.
There is no learning from iteration to iteration in GRASP.
Doubleback Optimization (DBO) (Crawford, 1996) was to some extent the inspiration for
both SWO and another similar algorithm, Abstract Local Search (ALS) (Crawford, Dalal, &
Walser, 1998). In designing SWO, we began by looking at DBO, because it had been extremely
successful in solving a standard type of scheduling problem. However, DBO is only useful
when the objective is to minimize makespan, and is also limited in the types of constraints
it can handle. Because of these limitations, we began thinking about the principles behind
DBO, looking for an effective generalization of that approach. DBO can, in fact, be viewed
as an instance of SWO. DBO begins by performing a \right shift" on a schedule, shifting all
tasks as far to the right as they can go, up to some boundary. In the resulting right-shifted
schedule, the left-most tasks are, to some extent, those tasks that are most critical. This
corresponds to analysis in SWO. Tasks are then removed from the right-shifted schedule,
taking left-most tasks first. This ordering corresponds to the prioritization in SWO. As each
task is removed, it is placed in a new schedule at the earliest possible start time, i.e., greedy
construction.
Like SWO, ALS was the result of an attempt to generalize DBO. ALS views priority space
(to use the terminology from SWO) as a space of \abstract schedules," and performs a local
search in that space. Unlike SWO, if a prioritization is modified, and the corresponding
move in solution space is downhill (away from optimal), then the modified prioritization
is discarded, and the old prioritization is restored. As is usual with local search, ALS also
sometimes makes random moves, in order to escape local minima.
ALS, and also List Scheduling (Pinson, Prins, & Rullier, 1994), are scheduling algorithms
that deal with domains that include precedence constraints on tasks. Both accommodate
367

fiJoslin & Clements

precedence constraints by constructing schedules left-to-right temporally. A task cannot
be placed in the schedule until all of its predecessors have been placed. In order for the
analysis, prioritization and construction to be appropriately coupled, it is not sucient to
simply increase the priority of a task that is late, because the constructor may not be able
to place that task until after a lot of other decisions have been made. Consequently, some
amount of blame must be propagated to the task's predecessors.
The commercial scheduler OPTIFLEX (Syswerda, 1994) uses a genetic algorithm approach
to modify a sequence of tasks, and a constraint-based schedule constructor that generates
schedules from those sequences. OPTIFLEX can also be viewed as an instance of SWO, with
a genetic algorithm replacing analysis. In effect, the \analysis" instead emerges from the
relative fitness of the members of the population.
Two graph coloring algorithms also bear some similarity to SWO. Impasse Class Coloration Neighborhood Search (IMPASSE) (Morgenstern, 1993; Lewandowski & Condon,
1993), like SWO, maintains a target set of colors and produces only feasible colorings. Given a
coloring, IMPASSE places any nodes that are colored outside of the target set into an impasse
set. On each iteration a node is selected from the impasse set, using a noisy degree-based
heuristic, and assigned a random color from the target set. Any neighbor nodes that are
now in conict are moved to the impasse set.
Iterated Greedy (IG) (Culberson & Luo, 1993), like SWO, uses a sequence of nodes to
create a new coloring on each iteration, and then uses that coloring to produce a new
sequence for the next iteration. The method used to generate each new sequence differs
from SWO. The key observation behind IG is that if all nodes with the same color in the
current solution are grouped together in the next sequence (i.e. adjacent to each other in
the sequence), then the next solution will be no worse than the current solution. IG achieves
improvement by manipulating the order in which the groups occur in the new sequence,
using several heuristics including random based on color, descending based on color, and
ascending based on the cardinality of each group. IG learns groupings of nodes as it runs,
but it does not learn about about the diculty of any nodes. A node's place in the sequence
indicates nothing about its expected or detected diculty.

6. Analysis and future work

This section summarizes several areas of future research suggested by the results reported
in the previous sections.

6.1 Scaling

While SWO uses fast, greedy algorithms for constructing solutions, and we have demonstrated
its effectiveness on problems of realistic size, the greatest threat to the scalability of SWO is
that it constructs a new solution from scratch on each iteration. A partial solution to this
problem is seen in the use of a \history" mechanism for the graph coloring problems. Using
the same color for a node as in the previous solution means that in many cases we do not
need to check any of the other possible colors. This significantly speeds up the construction.
A more fundamental solution to this problem would be to develop an incremental version
of SWO. The selective reuse of colors in the graph coloring solver is a small step in this
direction. This allows the constructor to avoid spending time evaluating other alternatives
368

fi\Squeaky Wheel" Optimization

when the previous choice still works. More generally, it may be possible to look at the
changes made to a prioritization, and modify the corresponding solution in a way that
generates the same solution that would be constructed from scratch based on the new
prioritization. It seems feasible that this could be done for some domains, at least for small
changes to the prioritization, because there may be large portions of a solution that are
unaffected.
A more interesting possibility is based on the view of SWO as performing local search
plus a certain kind of propagation. A small change in priorities may correspond to a large
change in the solution. For example, increasing the priority of one task in a scheduling
problem may change its position in the schedule, and, as a consequence, some lower priority
tasks may have to be shued around to accommodate that change. This is similar to what
we might expect from moving the higher priority task, then propagating the effects of that
change by moving lower priority tasks as well. This single move may correspond to a large
number of moves in a search algorithm that only looks at local changes to the schedule, and
may thus be dicult for such an algorithm to find.
Based on this view, we are investigating an algorithm we call \Priority-Limited Propagation" (PLP). With PLP, local changes are made to the solution, and then propagation is
allowed to occur, subject to the current prioritization. Propagation is only allowed to occur
in the direction of lower-priority elements. In effect, a small change is made, and then the
consequences of that change are allowed to \ripple" through the plan. Because propagation
can only occur in directions of decreasing priority, these ripples of propagation decrease in
magnitude until no more propagation is possible. A new prioritization is then generated by
analyzing the resulting solution. (It should be possible to do this analysis incrementally,
as well.) The resulting approach is not identical to SWO, but has many of its interesting
characteristics.

6.2 Coordination of modules
For SWO to be effective, it is obvious that analysis, prioritization and construction must all
work together to improve the quality of solutions. We have already discussed the complications that can arise when constraints are placed on the order in which the constructor
can make decisions, as is the case for List Scheduling and ALS, where construction is done
strictly left-to-right. Without more complex analysis, the search spaces can effectively become uncoupled, so that changes in priority don't cause the constructor to fix problems
discovered by analysis.
Another way the search can become uncoupled is related to the notion of \excess cost,"
discussed for the scheduling implementation. The calculation of excess cost in the analyzer
turned out to be a key idea for improving the performance of SWO. However, problems sometimes have tasks that must be handled badly in order to achieve a good overall solution. One
of the scheduling problems described previously has two such \sacrificial" tasks. Whenever
a good solution is found, the analyzer assigns high blame to these sacrificial tasks, and the
constructor handles them well on the next iteration. This means that the resulting solution
is of poor overall quality, and it is not until other aws cause other tasks to move ahead of
the sacrificial tasks in the priority sequence that SWO can again, briey, explore the space
369

fiJoslin & Clements

of good solutions. In such cases, to some extent the analysis is actually hurting the ability
of SWO to converge on good solutions.
Ideally, we would like to generalize the notion of excess cost to recognize sacrificial
tasks, and allow those tasks to be handled badly without receiving proportionate blame.
For problems in which a task must be sacrificed in all solutions, it may be possible to use
a learning mechanism to accomplish this.
However, the notion of a sacrificial task can be more subtle than this. Suppose for
example that we are scheduling the construction of two airplanes, P1 and P2, and that
each has a key task, T1 and T2, respectively, requiring all of some shared resource, R.
Because of the resource conict, we must either give R to T1 early in the schedule, starting
construction on plane P1 before P2, or we must give R to T2 early in the schedule, with
the opposite result. Whichever of the two tasks is started early will finish on time, but the
other will be late.
Suppose we construct a schedule in which T1 goes first, and T2 is late, thus receiving a
heavy blame factor. SWO increases the priority on T2, and as a consequence, T2 goes first
in the subsequent schedule. But then T1 is late, and on the next iteration it will again go
first. We could alternate in this manner forever, and the result would be that SWO would
fail to explore either option very effectively, because it would be jumping back and forth
between the option of building plane P1 first, and the option of building plane P2 first,
without remaining in one region of the search space long enough to refine a solution.
The diculty is that neither T1 nor T2 can be identified as a sacrificial task. Assuming
the two planes are not identical, we cannot simply argue from symmetry that we should
just pick one of the two tasks to be sacrificed. If, however, we could identify a sacrificial
task by the role it plays in a solution, we could achieve what we need. Here, the task to be
sacrificed must be the one that belongs to whichever plane is started later. If the analyzer
could reduce the blame assigned to that task in a schedule, whichever task it happens to
be, it would allow SWO to explore that region of the search much more effectively.
This problem of interchangeable roles would arise even more clearly with the introduction of conditional elements in a solution. Suppose, for example, we have a scheduling
problem in which the constructor may choose to include or not include task instances of
some type, adding however many instances are needed to satisfy a resource requirement.
If those tasks are all instances of the same task type, then they are interchangeable, and
penalizing one may simply cause a shuing of those instances that does not really address
the problem. Moreover, with conditional tasks, it is not clear how the analyzer should
assign blame when the set of task instances in the current schedule may be very different
from the set of task instances in successor schedules.
To address these concerns, the notion of prioritization could be generalized to apply to
additional aspects of a problem. In scheduling this might mean not just prioritizing tasks,
but also resources over various time intervals. We also propose that the these prioritizations
be limited to the \fixed" elements of a problem. In scheduling problems, for example, these
may be the non-conditional tasks, resources, etc. (In our example domains, all of the
elements are fixed in this sense, so this was not an issue.)
One intuition behind this proposal is that these are the elements that will tend to define
roles. In the earlier example with tasks T1 and T2, corresponding to the two planes being
built, the critical element is not either task per se, but actually resource R, early in the
370

fi\Squeaky Wheel" Optimization

schedule. If this phase of resource R receives a high priority, and the later phase of resource
R receives a lower priority, then whichever of the two tasks occurs later will be recognized
as less critical. While this does not exactly capture the notion of \role" that we would like,
it comes a lot closer than the current approach. In addition, assigning priorities to the fixed
elements of a problem has the advantage of being applicable to problems with conditional
tasks. Research is currently under way to explore this approach.

6.3

SWO

and local search

Although the ability to make large, coherent moves is a strength of the approach, it is also
a weakness. SWO is poor at making small \tuning" moves in the solution space, but the
coupled-search view of SWO suggests an obvious remedy. SWO could be combined with local
search in the solution space, to look for improvements in the vicinity of good solutions.
Similarly, making small changes to a prioritization would generally result in smaller moves
in the solution space than result from going through the full analysis and re-prioritization
cycle.
Yet another alternative is genetic algorithm techniques for \crossover" and other types
of mutation to a pool of nodes, as is done in OPTIFLEX. Many hybrid approaches are possible, and we believe that the coupled-search view of SWO helps to identify some interesting
strategies for combining moves of various sizes and kinds, in both search spaces, adapting
dynamically to relative solution qualities.

7. Conclusions
Our experience has been that it is fairly straightforward to implement SWO in a new domain,
because there are usually fairly obvious ways to construct greedy solutions, and to analyze
a solution to assign \blame" to some of the elements. Naive implementations of SWO tend
to perform reasonably well.
We have found the view of SWO as performing a \coupled search" over two different
search spaces to be very informative. It has been helpful to characterize the kinds of moves
that SWO makes in each of the search spaces, and the effect this has on avoiding local optima,
etc. We hope that by continuing to gain a deeper understanding of what makes SWO work
we will be able to say more about the effective design of SWO algorithms.
As the number of directions for future research suggests, we have only begun to scratch
the surface of \Squeaky Wheel" Optimization.

Acknowledgments
The authors wish to thank Robert Stubbs of Lucent Technologies for providing the data
used for the scheduling experiments. The authors also wish to thank George L. Nemhauser,
Markus E. Puttlitz and Martin W. P. Savelsbergh with whom we collaborated on using SWO
in a hybrid AI/OR approach. Many useful discussions came out of that collaboration, and
without them we would not have had access to the Lucent problems. Markus also wrote
the framework for the scheduling experiments and the TABU and IP implementations.
371

fiJoslin & Clements

The authors also thank the members of CIRL, and James Crawford at i2 Technologies,
for their helpful comments and suggestions. We would like to thank Andrew Parkes in
particular for suggestions and insights in the graph coloring domain.
This effort was sponsored by the Air Force Oce of Scientific Research, Air Force Materiel Command, USAF, under grant number F49620-96-1-0335; by the Defense Advanced
Research Projects Agency (DARPA) and Rome Laboratory, Air Force Materiel Command,
USAF, under agreements F30602-95-1-0023 and F30602-97-1-0294; and by the National
Science Foundation under grant number CDA-9625755.
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon. The views and conclusions
contained herein are those of the authors and should not be interpreted as necessarily representing the ocial policies or endorsements, either expressed or implied, of the Defense
Advanced Research Projects Agency, Rome Laboratory, the Air Force Oce of Scientific
Research, the National Science Foundation, or the U.S. Government.
Most of the work reported in this paper was done while both authors were at CIRL.

References

Crawford, J., Dalal, M., & Walser, J. (1998). Abstract local search. In Proceedings of the
AIPS-98 Workshop on Planning as Combinatorial Search. In conjunction with the
Fourth International Conference on Artificial Intelligence Planning Systems (AIPS98).
Crawford, J. M. (1996). An approach to resource constrained project scheduling. In Proceedings of the 1996 Artificial Intelligence and Manufacturing Research Planning Workshop, pp. 35{39.
Culberson, J. C., & Luo, F. (1993). Exploring the k{colorable landscape with iterated
greedy. In (Johnson & Trick, 1996), pp. 245{284.
Feo, T. A., & Resende, M. G. (1995). Greedy randomized adaptive search procedures.
Journal of Global Optimization, 6, 109{133.
Garey, M. R., & Johnson, D. S. (1979). Computers and Intractability: A Guide to the
Theory of NP-Completeness. W. H. Freeman.
Glover, F., & Laguna, M. (1997). Tabu Search. Kluwer.
Glover, F., Parker, M., & Ryan, J. (1993). Coloring by tabu branch and bound. In (Johnson
& Trick, 1996), pp. 285{307.
Gomes, C., Selman, B., & Kautz, H. (1998). Boosting combinatorial search through randomization. In Proceedings of AAAI-98, pp. 431{437.
Johnson, D. S., & Trick, M. A. (Eds.). (1996). Cliques, Coloring, and Satisfiability: Second
DIMACS Implementation Challenge, 1996, Vol. 26 of DIMACS Series in Discrete
Mathematics and Theoretical Computer Science. American Mathematical Society.
372

fi\Squeaky Wheel" Optimization

Joslin, D., & Clements, D. (1998). \Squeaky wheel" optimization. In Proceedings of AAAI98, pp. 340{346.
Lewandowski, G., & Condon, A. (1993). Experiments with parallel graph coloring heuristics
and applications of graph coloring. In (Johnson & Trick, 1996), pp. 309{334.
Morgenstern, C. (1993). Distributed coloration neighborhood search. In (Johnson & Trick,
1996), pp. 335{357.
Parkes, A., & Walser, J. (1996). Tuning local search for satisfiability testing. In Proceedings
of AAAI-96, pp. 356{362.
Pinson, E., Prins, C., & Rullier, F. (1994). Using tabu search for solving the resourceconstrained project scheduling problem. In EURO-WG PMS 4 (EURO Working
Group on Project Management and Scheduling), pp. 102{106 Louvain, Belgium.
Selman, B., Kautz, H. A., & Cohen, B. (1993). Local search strategies for satisfiability
testing. In (Johnson & Trick, 1996), pp. 521{531.
Syswerda, G. P. (1994). Generation of schedules using a genetic procedure.. U.S. Patent
number 5,319,781.

373

fiJournal of Artificial Intelligence Research 10 (1999) 243-270

Submitted 10/98; published 5/99

Learning to Order Things
William W. Cohen
Robert E. Schapire
Yoram Singer

AT&T Labs, Shannon Laboratory, 180 Park Avenue
Florham Park, NJ 07932, USA

wcohen@research.att.com
schapire@research.att.com
singer@research.att.com

Abstract

There are many applications in which it is desirable to order rather than classify instances. Here we consider the problem of learning how to order instances given feedback
in the form of preference judgments, i.e., statements to the effect that one instance should
be ranked ahead of another. We outline a two-stage approach in which one first learns by
conventional means a binary preference function indicating whether it is advisable to rank
one instance before another. Here we consider an on-line algorithm for learning preference
functions that is based on Freund and Schapire's \Hedge" algorithm. In the second stage,
new instances are ordered so as to maximize agreement with the learned preference function. We show that the problem of finding the ordering that agrees best with a learned
preference function is NP-complete. Nevertheless, we describe simple greedy algorithms
that are guaranteed to find a good approximation. Finally, we show how metasearch can
be formulated as an ordering problem, and present experimental results on learning a combination of \search experts," each of which is a domain-specific query expansion strategy
for a web search engine.
1. Introduction

Work in inductive learning has mostly concentrated on learning to classify. However, there
are many applications in which it is desirable to order rather than classify instances. An
example might be a personalized email filter that prioritizes unread mail. Here we will
consider the problem of learning how to construct such orderings given feedback in the
form of preference judgments, i.e., statements that one instance should be ranked ahead of
another.
Such orderings could be constructed based on a learned probabilistic classifier or regression model and in fact often are. For instance, it is common practice in information retrieval
to rank documents according to their probability of relevance to a query, as estimated by a
learned classifier for the concept \relevant document." An advantage of learning orderings
directly is that preference judgments can be much easier to obtain than the labels required
for classification learning.
For instance, in the email application mentioned above, one approach might be to rank
messages according to their estimated probability of membership in the class of \urgent"
messages, or by some numerical estimate of urgency obtained by regression. Suppose,
however, that a user is presented with an ordered list of email messages, and elects to read
the third message first. Given this election, it is not necessarily the case that message three
is urgent, nor is there sucient information to estimate any numerical urgency measures.

c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiCohen, Schapire, & Singer
However, it seems quite reasonable to infer that message three should have been ranked
ahead of the others. Thus, in this setting, obtaining preference information may be easier
and more natural than obtaining the labels needed for a classification or regression approach.
Another application domain that requires ordering instances is collaborative filtering; see,
for instance, the papers contained in Resnick and Varian (1997). In a typical collaborative
filtering task, a user seeks recommendations, say, on movies that she is likely to enjoy. Such
recommendations are usually expressed as ordered lists of recommended movies, produced
by combining movie ratings supplied by other users. Notice that each user's movie ratings
can be viewed as a set of preference judgements. In fact, interpreting ratings as preferences
is advantageous in several ways: for instance, it is not necessary to assume that a rating of
\7" means the same thing to every user.
In the remainder of this paper, we will investigate the following two-stage approach to
learning how to order. In stage one, we learn a preference function, a two-argument function
PREF(u; v) which returns a numerical measure of how certain it is that u should be ranked
before v. In stage two, we use the learned preference function to order a set of new instances
X ; to accomplish this, we evaluate the learned function PREF(u; v) on all pairs of instances
u; v 2 X , and choose an ordering of X that agrees, as much as possible, with these pairwise
preference judgments.
For stage one, we describe a specific algorithm for learning a preference function from a
set of \ranking-experts". The algorithm is an on-line weight allocation algorithm, much like
the weighted majority algorithm (Littlestone & Warmuth, 1994) and Winnow (Littlestone,
1988), and, more directly, Freund and Schapire's (1997) \Hedge" algorithm. For stage two,
we show that finding a total order that agrees best with such a preference function is NPcomplete. Nevertheless, we show that there are ecient greedy algorithms that always find
a good approximation to the best ordering.
We then present some experimental results in which these algorithm are used to combine
the results of several \search experts," each of which is a domain-specific query expansion
strategy for a web search engine. Since our work touches several different fields we defer
the discussion of related work to Sec. 6.
2. Preliminaries

Let X be a set of instances. For simplicity, in this paper, we always assume that X is
finite. A preference function PREF is a binary function PREF : X  X ! [0; 1]. A value of
PREF(u; v) which is close to 1 (respectively 0) is interpreted as a strong recommendation
that u should be ranked above (respectively, below) v. A value close to 1=2 is interpreted
as an abstention from making a recommendation. As noted earlier, the hypothesis of our
learning system will be a preference function, and new instances will be ranked so as to
agree as much as possible with the preferences predicted by this hypothesis.
In standard classification learning, a hypothesis is constructed by combining primitive
features. Similarly, in this paper, a preference function will be a combination of primitive
preference functions. In particular, we will typically assume the availability of a set of N
primitive preference functions R1 ; : : : ; RN . These can then be combined in the usual ways,
for instance with a boolean or linear combination of their values. We will be especially
interested in the latter combination method.
244

fiLearning to Order Things
1/4

a

a

c

c

3/4

a

1/8

c

1

b

d

b

f(a)=1 f(b)=2
f(c)=0 f(d)=

d

g(a)=0 g(b)=2
g(c)=1 g(d)=2

b

7/8 1/8
1

7/8

d

1/4f() + 3/4g()

Figure 1: Left and middle: Two ordering functions and their graph representation. Right:
The graph representation of the preference function created by a weighted ( 41 and
3 ) combination of the two functions. Edges with weight of 1 or 0 are omitted.
4
2
It is convenient to assume that the Ri 's are well-formed in certain ways. To this end, we
introduce a special kind of preference function called a rank ordering which is defined by
an ordering function. Let S be a totally ordered set. We assume without loss of generality
that S  R . An ordering function into S is any function f : X ! S , where we interpret an
inequality f (u) > f (v) to mean that u is ranked above v by f . It is sometimes convenient
to allow an ordering function to \abstain" and not give a preference for a pair u, v. We
therefore allow S to include a special symbol ? not in R , and we interpret f (u) = ? to
mean that u is \unranked." We define the symbol ? to be incomparable to all the elements
in S (that is, ? 6< s and s 6< ? for all s 2 S ).
An ordering function f induces the preference function Rf , defined as

8
>
<1
Rf (u; v) = 0
>
: 12

if f (u) > f (v)
if f (u) < f (v)
otherwise.

We call Rf a rank ordering for X into S . If Rf (u; v) = 1, then we say that u is preferred
to v, or u is ranked higher than v. Note that Rf (u; v) = 12 if either u or v (or both) is
unranked.
We will sometimes describe and manipulate preference functions as directed weighted
graphs. The nodes of a graph correspond to the instances in X . Each pair (u; v) is connected by a directed edge with weight PREF(u; v). Since an ordering function f induces
a preference function Rf , we can also describe ordering functions as graphs. In Fig. 1 we
give an example of two ordering functions and their corresponding graphs. For brevity, we
do not draw edges (u; v) such that PREF(u; v) = 12 or PREF(u; v) = 0.
To give a concrete example of rank orderings, imagine learning to order documents
based on the words that they contain. To model this, let X be the set of all documents in
a repository, and for N words w1 ; : : : ; wN , let fi(u) be the number of occurrences of word
wi in document u. Then Rf will prefer u to v whenever wi occurs more often in u than v.
As a second example, consider a metasearch application in which the goal is to combine the
i

245

fiCohen, Schapire, & Singer
rankings of several web search engines on some fixed query. For N search engines e1 ; : : : ; eN ,
one might define fi so that Rf prefers web page u to web page v whenever u is ranked
ahead of v in the list Li produced by the corresponding search engine. To do this, one could
let fi (u) = k for the web page u appearing in the k-th position in the list Li , and let
fi (u) = M (where M > jLi j) for any web page u not appearing in Li .
Feedback from the user will be represented in a similar but more general way. We will
assume that feedback is a set element pairs (u; v), each representing an assertion of the form
\u should be preferred to v." This definition of feedback is less restricted than ordering
functions. In particular, we will not assume that the feedback is consistent|cycles, such as
a > b > a, will be allowed.
i

3. Learning a Combination of Ordering Functions

In this section, we consider the problem of learning a good linear combination of a set of
ordering functions. Specifically, we assume access to a set of ranking experts, each of which
generates an ordering function when provided with a set of instances. For instance, in a
metasearch problem, each ranking expert might be a function that submits the user's query
to a different search engine; the domain of instances might be the set of all web pages
returned by any of the ranking experts; and the ordering function associated with each
ranking expert might be represented as in the example above (i.e., letting fi (u) = k for
the k-the web page u returned by i-th search engine, and letting fi (u) = M for any web
page u not retrieved by the i-th search engine). The user's feedback will be a set of pairwise
preferences between web pages. This feedback may be obtained directly, for example, by
asking the user to explicitly rank the URL's returned by the search engine; or the feedback
may be obtained indirectly, for example, by measuring the time spent viewing each of the
returned pages.
We note that for the metasearch problem, an approach that works directly with the
numerical scores associated with the different search engines might not be feasible; these
numerical scores might not be comparable across different search engines, or might not
be provided by all search engines. Another problem is that most web pages will not be
indexed by all search engines. This can be easily modeled in our setting: rather than
letting fi (u) = M for a web page u that is not ranked by search engine i, one could let
fi (u) = ?. This corresponds to the assumption that the search engine's preference for u
relative to ranked web pages is unknown.
We now describe a weight allocation algorithm that
functions Ri to
P usesw Rthe(u;preference
learn a preference function of the form PREF(u; v) = N
v
).
We
adopt
the on-line
i=1 i i
learning framework first studied by Littlestone (1988) in which the weight wi assigned to
each ranking expert i is updated incrementally.
Formally, learning is assumed to take place in a sequence of rounds. On each round t, we
assume the learning algorithm is provided with a set X t of instances to be ranked, for which
each ranking expert i 2 f1; : : : ; N g provides an ordering function fit . (In metasearch, for
instance, fit is the ordering function associated with the list Lti of web pages returned by the
i-th ranking expert for the t-th query, and X t is the set of all web pages that appear in any
of the lists Lt1 ; : : : ; LtN .) Each ordering function fit induces a preference function Rf , which
we denote for brevity by Rit . The learner may compute Rit (u; v) for any and all preference
t
i

246

fiLearning to Order Things
functions Rit and pairs u; v 2 X t before producing a combined preference function PREFt ,
which is then used to produce an ordering ^t of X t . (Methods for producing an ordering
from a preference function will be discussed below.)
After producing the ordering ^t , the learner receives feedback from the environment.
We assume that the feedback is an arbitrary set of assertions of the form \u should be
preferred to v." That is, the feedback on the t-th round is a set F t of pairs (u; v).
The algorithm we propose for this problem is based on the \weighted majority algorithm" of Littlestone and Warmuth (1994) and, more directly, on Freund and Schapire's
(1997) \Hedge" algorithm. We define the loss of a preference function R with respect to
the user's feedback F as
Loss(R; F ) =

P

2

(u;v) F (1

jF j

R(u; v))

1 X
jF j (u;v)2F R(u; v) :

=1

(1)

This loss has a natural probabilistic interpretation. If R is viewed as a randomized prediction
algorithm that predicts that u will precede v with probability R(u; v), then Loss(R; F ) is the
probability of R disagreeing with the feedback on a pair (u; v) chosen uniformly at random
from F .
It is worth noting that the assumption on the form of the feedback can be further relaxed
by allowing the user to indicate the degree to which she prefers u over v. In this case, the
loss should be normalized by the weighted sum of feedback pairs. Since this generalization
is rather straightforward, we assume for brevity that the feedback is an unweighted set of
assertions over element pairs.
We now can use the Hedge algorithm almost verbatim, as shown in Figure 2. The
algorithm maintains a positive weight vector whose value at time t is denoted by wt =
t ). If there is no prior knowledge about the ranking experts, we set all initial
(w1t ; : : : ; wN
weights to be equal so that wi1 = 1=N .
On each round t, the weight vector wt is used to combine the preference
functions of the
P
N
t
different experts to obtain the preference function PREF (u; v) = i=1 wit Rit (u; v). This
preference function is next converted into an ordering ^t on the current set of elements
X t . For the purposes of this section, the method of producing an ordering is immaterial; in
particular, any of the methods described in Sec. 4 could be used here. Based on this ordering,
the user provides feedback F t , and the loss for each preference function Loss(Rit ; F t ) is
evaluated as in Eq. (1). Finally, the weight vector wt is updated using the multiplicative
rule
wt  fi Loss(R ;F )
wit+1 = i
Zt
where fi 2 [0; 1] is a parameter, and Zt is a normalization constant, chosen so that the
weights sum to one after the update. Thus, in each round, the weights of the ranking
experts are adjusted so that experts producing preference functions with relatively large
agreement with the feedback are increased.
We now give the theoretical rationale behind this algorithm. Freund and Schapire (1997)
prove general results about Hedge which can be applied directly to this loss function. Their
results imply almost immediately a bound on the cumulative loss of the preference function
PREFt in terms of the loss of the best ranking expert, specifically:
t
i

247

t

fiCohen, Schapire, & Singer
Allocate Weights for Ranking Experts
P
Parameters: fi 2 [0; 1], initial weight vector w1 2 [0; 1]N with Ni=1 wi1 = 1
N ranking experts, number of rounds T
Do for t = 1; 2; : : : ; T

1. Receive a set of elements X t and ordering functions f1t ; : : : ; fNt . Let Rit denote the
preference function induced by fit .
2. Compute a total order ^t which approximates
PREFt (u; v) =

N
X
i=1

wit Rit (u; v)

(Sec. 4 describes several ways of approximating a preference function with a total
order.)
3. Order X t using ^t .
4. Receive feedback F t from the user.
5. Evaluate losses Loss(Rit ; F t ) as defined in Eq. (1).
6. Set the new weight vector
wit+1 =

wit  fi Loss(R ;F
Zt
t
i

t

where Zt is a normalization constant, chosen so that

)

PN

t+1
i=1 wi

= 1.

Figure 2: The on-line weight allocation algorithm.

Theorem 1 For the algorithm of Fig. 2,
T
X
t=1

Loss(PREFt ; F t )  afi min

where afi = ln(1=fi )=(1

P
Note that

i

fi ) and cfi = 1=(1

T
X
t=1

Loss(Rit ; F t ) + cfi ln N

fi ).

t t
t Loss(PREF ; F )
and t Loss(Rit ; F t )

is the cumulative loss of the combined preference funcP
tions
is the cumulative loss of the ith ranking expert. Thus,
Theorem 1 states that the cumulative loss of the combined preference functions will not be
much worse than that of the best ranking expert.
Proof: We have that
1 X X t t
w R (u; v)
Loss(PREFt ; F t ) = 1
F t (u;v)2F i i i
PREFt ,

=

0
X t@
wi 1
i

1

t

1 X
Rt (u; v)A
F t (u;v)2F i
t

248

fiLearning to Order Things

X

=

i

wit Loss(Rit (u; v); F t ):

Therefore, by Freund and Schapire's (1997) Theorem 2,
T
X
t=1

Loss(PREFt ; F t ) =



T X
X
t=1 i

afi min

2

i

wit Loss(Rit (u; v); F t )
T
X
t=1

Loss(Rit ; F t ) + cfi ln N:

Of course, we are not interested in the loss of PREFt (since it is not an ordering), but
rather in the performance of the actual ordering ^t computed by the learning algorithm.
Fortunately, the losses of these can be related using a kind of triangle inequality. Let
DISAGREE(; PREF) =

X

u;v:(u)>(v)

(1

PREF(u; v)) :

(2)

Theorem 2 For any PREF, F and total order defined by an ordering function ,
Loss(R ; F ) 

DISAGREE(; PREF)
+ Loss(PREF; F ):
jF j

(3)

For x; y 2 [0; 1], let us define d(x; y) = x(1 y) + y(1 x). We now show
that d satisfies the triangle inequality. Let x, y and z be in [0; 1], and let X , Y and Z be
independent Bernoulli (f0; 1g-valued) random variables with probability of outcome 1 equal
to x, y and z , respectively. Then

Proof:

d(x; z ) = Pr[X 6= Z ]
= Pr[(X 6= Y ^ Y = Z ) _ (X = Y
 Pr[X 6= Y _ Y 6= Z ]
 Pr[X 6= Y ] + Pr[Y 6= Z ]
= d(x; y) + d(y; z ):

^ Y 6= Z )]

For [0; 1]-valued functions f; g defined on X  X , we next define
D(f; g) =

X
d(f (u; v); g(u; v)):
u;v:u=
6v

Clearly, D also satisfies the triangle inequality.
Let F be the characteristic function of F so that F : X  X ! f0; 1g and F (u; v) = 1
if and only if (u; v) 2 F . Then from the definition of Loss and DISAGREE, we have

jF j Loss(R ; F )

2

= D ( R ;  F )
 D(R; PREF) + D(PREF; F )
= DISAGREE(; PREF) + jF j Loss(PREF; F ):

Notice that the learning algorithm Hedge minimizes the second term on the right hand
side of Eq. (3). Below, we consider the problem of finding an ordering  which minimizes
the first term, namely, DISAGREE.
249

fiCohen, Schapire, & Singer
4. Ordering Instances with a Preference Function

4.1 Measuring the Quality of an Ordering
We now consider the complexity of finding a total order that agrees best with a learned
preference function. To analyze this, we must first quantify the notion of agreement between
a preference function PREF and an ordering. One natural notion is the following: Let X
be a set, PREF be a preference function, and let  be a total ordering of X , expressed again
as an ordering function (i.e., (u) > (v) if and only if u is above v in the order). For
the analysis of this section, it is convenient to use the measure AGREE(; PREF), which is
defined to be the sum of PREF(u; v) over all pairs u; v such that u is ranked above v by :
AGREE(; PREF) =

X

u;v:(u)>(v)

PREF(u; v):

(4)

Clearly, AGREE is a linear transformation of the measure DISAGREE introduced in Eq. (2),
and hence maximizing AGREE is equivalent to minimizing DISAGREE. This definition is
also closely related to similarity metrics used in decision theory and information processing (Kemeny & Snell, 1962; Fishburn, 1970; Roberts, 1979; French, 1989; Yao, 1995) (see
the discussion in Sec. 6).

4.2 Finding an Optimal Ordering is Hard
Ideally one would like to find a  that maximizes AGREE(; PREF). The general optimization problem is of little interest in our setting, since there are many constraints on the
preference function that are imposed by the learning algorithm. Using the learning algorithm of Sec. 3, for instance, PREF will always be a linear combination of simpler functions.
However, the theorem below shows that this optimization problem is NP-complete even if
PREF is restricted to be a linear combination of well-behaved preference functions. In particular, the problem is NP-complete even if all the primitive preference functions used in
the linear combination are rank orderings which map into a set S with only three elements,
one of which may or may not be ?. (Clearly, if S consists of more than three elements then
the problem is still hard.)

Theorem 3 The following decision problem is NP-complete for any set S with jS j  3:
Input: A rational number ; a set X ; a collection of N ordering functions fi : X ! S ;
and a preference function PREF defined as
PREF(u; v) =

N
X
i=1

wi Rf (u; v)

(5)

i

P

where w = (w1 ; : : : ; wN ) is a rational weight vector in [0; 1]N with N
i=1 wi = 1.
Question: Does there exist a total order  such that AGREE(; PREF)  ?

Proof: The problem is clearly in NP since a nondeterministic algorithm can guess a total

order and check the weighted number of agreements in polynomial time.
To prove that the problem is NP-hard we reduce from CYCLIC-ORDERING (Galil &
Megido, 1977; Gary & Johnson, 1979), defined as follows: \Given a set A and a collection
250

fiLearning to Order Things
C of ordered triples (a; b; c) of distinct elements from A, is there a one-to-one function
f : A ! f1; 2; : : : ; jAjg such that for each (a; b; c) 2 C we have either f (a) > f (b) > f (c) or
f (b) > f (c) > f (a) or f (c) > f (a) > f (b)?"
Without loss of generality, S is either f0; 1; ?g or f0; 1; 2g. We first show that the
problem of finding an optimal total order is hard when S = f0; 1; ?g. Given an instance of
CYCLIC-ORDERING, we let X = A. For each triplet t = (a; b; c) we will introduce three
ordering functions ft;1 , ft;2 , and ft;3 , and define them so that ft;1 (a) > ft;1 (b), ft;2 (b) >
ft;2 (c), and ft;3 (c) > ft;3 (a). To do this, we let ft;1 (a) = ft;2 (b) = ft;3 (c) = 1, ft;1 (b) =
ft;2 (c) = ft;3 (a) = 0, and ft;i () = ? in all other cases. We let the weight vector be uniform,
so that wt;i = 3j1C j . Let
=

P

5 jAj(jAj 1)=2
+
3
2

3

:

Define Rt (u; v) = 3i=1 wt;i Rf (u; v), which is the contribution of these three functions
to PREF(u; v). Notice that for any triplet t = (a; b; c) 2 C , Rt (a; b) = 3j2C j whereas
Rt (b; a) = 3j1C j , and similarly for b; c and c; a. In addition, for any pair u; v 2 A such that
at least one of them does not appear in t, we get that Rt (u; v) = 2j1C j . Since a total order
 can satisfy at most two of the three conditions (a) > (b), (b) > (c), and (c) > (a),
the largest possible weighted number of agreements associated with this triple is exactly
=jC j.
If the number of weighted agreements is at least , it must be exactly , by the argument
above; and if there are exactly  weighted agreements, then the total order must satisfy
exactly 2 out of the possible 3 relations for each three elements that form a triplet from
C . Thus, the constructed rank ordering instance will be positive if and only if the original
CYCLIC-ORDERING instance is positive.
The case for S = f0; 1; 2g uses a similar construction; however, for each triplet t =
(a; b; c), we define six ordering functions, ft;j 1 , ft;j 2 , and ft;j 3 , where j 2 f0; 1g. The basic
0 and f 1 , that agree on the single
idea here is to replace each ft;i with two functions, ft;i
t;i
ordering constraint associated with ft;i , but disagree on all other orderings. For instance,
we will define these functions so that ft;j 1 (a) > ft;j 1 (b) for j = 0 and j = 1, but for all other
pairs u; v, ft;11 (u) > ft;11 (v) iff ft;01 (v) > ft;01 (u). Averaging the two orderings ft;01 and ft;11
will thus yield the same preference expressed by the original function ft;1 (i.e., a preference
for a > b only).
In more detail, we let ft;j 1 (a) = ft;j 2 (b) = ft;j 3 (c) = 2 j , ft;j 1 (b) = ft;j 2 (c) = ft;j 3 (a) = 1 j ,
j
and ft;i
() = 2j in all other cases. We again let the weight vector be uniform, so that
P
j
wt;i = 6j1C j . Similar to the first case, we define Rt (u; v) = i;j wt;i Rf (u; v). It can be
verified that Rt is identical to the Rt constructed in the first case. Therefore, by the same
argument, the constructed rank ordering instance will be positive if and only if the original
CYCLIC-ORDERING instance is positive. 2
Although this problem is hard when jS j  3, the next theorem shows that it becomes
tractable for linear combinations of rank orderings into a set S of size two. Of course, when
jS j = 2, the rank orderings are really only binary classifiers. The fact that this special
case is tractable underscores the fact that manipulating orderings (even relatively simple
t;i

j
t;i

251

fiCohen, Schapire, & Singer
ones) can be computationally more dicult than performing the corresponding operations
on binary classifiers.

Theorem 4 The following optimization problem is solvable in linear time:
Input: A set X ; a set S with jS j = 2; a collection of N ordering functions fi : X ! S ;
and a preference function PREF defined by Eq. (5).
Output: A total order defined by an ordering function  which maximizes
AGREE(; PREF).
Assume
P without loss of generality that the two-element set S is f0; 1g, and
define (u) = i wi fi(u). We now show that any total order1 consistent with  maximizes
AGREE(; PREF). Fix a pair u; v 2 X and let

Proof:

qb1 b2 =

X

i

s.t.

fi (u)=b1 ;fi (v)=b2

wi :

We can now rewrite  and PREF as
(u) = q10 + q11
(v) = q01 + q11

PREF(u; v) = q10 + 21 q11 + 21 q00
PREF(v; u) = q01 + 12 q11 + 12 q00 :

Note that both (u) (v) and PREF(u; v) PREF(v; u) are equal to q10 q01 . Hence, if
(u) > (v) then PREF(u; v) > PREF(v; u). Therefore, for each pair u; v 2 X , the order
defined by  agrees on all pairs with the pairwise preference defined by PREF. In other
words, we have shown that
AGREE(; PREF) =

X
maxfPREF(u; v); PREF(v; u)g
fu;vg

(6)

where the sum is over all unordered pairs. Clearly, the right hand side of Eq. (6) maximizes
the right hand side of Eq. (4) since at most one of (u; v) or (v; u) can be included in the
latter sum. 2

4.3 Finding an Approximately Optimal Ordering
Theorem 3 implies that we are unlikely to find an ecient algorithm that finds the optimal
total order for a weighted combination of rank orderings. Fortunately, there do exist ecient algorithms for finding an approximately optimal total order. In fact, finding a good
total order is closely related to the problem of finding the minimum feedback arc set, for
which there exist good approximation algorithms; see, for instance, (Shmoys, 1997) and
the references therein. However, the algorithms that achieve the good approximation results for the minimum feedback arc set problem are based on (or further approximate) a
linear-programming relaxation (Seymour, 1995; Even, Naor, Rao, & Schieber, 1996; Berger
& Shor, 1997; Even, Naor, Schieber, & Sudan, 1998) which is rather complex to implement
and quite slow in practice.
1. Notice that in case of a tie, so that (u) = (v ) for distinct u; v ,  defines only a partial order. The
theorem holds for any total order which is consistent with this partial order, i.e., for any  so that
(u) > (v ) )  (u) >  (v ).
0

0

0

252

fiLearning to Order Things

Algorithm Greedy-Order
Inputs: an instance set X ; a preference function PREF
Output: an approximately optimal ordering function ^
let V = X
P
P PREF(u; v)
for each v 2 V do (v) = u2V PREF(v; u)
u2V
while V is non-empty do
let t = arg maxu2V (u)
let ^(t) = jV j
V = V ftg
for each v 2 V do (v) = (v) + PREF(t; v)

endwhile

PREF(v; t)

Figure 3: The greedy ordering algorithm.
We describe instead a simple greedy algorithm which is very simple to implement. Figure 3 summarizes the greedy algorithm. As we will shortly demonstrate, this algorithm
produces a good approximation to the best total order.
The algorithm is easiest to describe by thinking of PREF as a directed weighted graph,
where initially, the set of vertices V is equal to the set of instances X , and each edge u ! v
has weight PREF(u; v). We assign to each vertex v 2 V a potential value (v), which is the
weighted sum of the outgoing edges minus the weighted sum of the ingoing edges. That is,
 (v ) =

X
X
PREF(v; u)
PREF(u; v) :
u2V
u2V

The greedy algorithm then picks some node t that has maximum potential2 , and assigns it
a rank by setting ^(t) = jV j, effectively ordering it ahead of all the remaining nodes. This
node, together with all incident edges, is then deleted from the graph, and the potential
values  of the remaining vertices are updated appropriately. This process is repeated
until the graph is empty. Notice that nodes removed in subsequent iterations will have
progressively smaller and smaller ranks.
As an example, consider the preference function defined by the leftmost graph of Fig. 4.
(This graph is identical to the weighted combination of the two ordering functions from
Fig. 1.) The initial potentials the algorithm assigns are: (b) = 2, (d) = 3=2, (c) = 5=4,
and (a) = 9=4. Hence, b has maximal potential. It is given a rank of 4, and then node b
and all incident edges are removed from the graph.
The result is the middle graph of Fig. 4. After deleting b, the potentials of the remaining
nodes are updated: (d) = 3=2, (c) = 1=4, and (a) = 5=4. Thus, d will be assigned
rank jV j = 3 and removed from the graph, resulting in the rightmost graph of Fig. 4.
After updating potentials again, (c) = 1=2 and (a) = 1=2. Now c will be assigned
rank jV j = 2 and removed, resulting in a graph containing the single node a, which will
2. Ties can be broken arbitrarily in case of two or more nodes with the same potential.

253

fiCohen, Schapire, & Singer
1/4

1/4
3/4

a

1/8

1

b

3/4

a

c

1/4

1/8

7/8 1/8
1

7/8

a

c

3/4

c

7/8 1/8
7/8

d

d

Figure 4: Behavior of the greedy ordering algorithm. The leftmost graph is the original
input. From this graph, node b will be assigned maximal rank and deleted,
leading to the middle graph; from this graph, node d will deleted, leading to the
rightmost graph. In the rightmost graph, node c will be ranked ahead of node a,
leading the total ordering b > d > c > a.
finally be assigned the rank jV j = 1. The ordering produced by the greedy algorithm is
thus b > d > c > a.
The next theorem shows that this greedy algorithm comes within a factor of two of
optimal.

Theorem 5 Let OPT(PREF) be the weighted agreement achieved by an optimal total order
for the preference function PREF, and let APPROX(PREF) be the weighted agreement
achieved by the greedy algorithm. Then
1
APPROX(PREF)  OPT(PREF) :
2

Proof:

Consider the edges that are incident on the node vj which is selected on the
j -th repetition of the while loop of Figure 3. The ordering produced by the algorithm will
agree with all of the outgoing edges of vj and disagree with all of the ingoing edges. Let
aj be the sum of the weights of the outgoing edges of vj , and dj be the sum of the weights
P
of the ingoing edges. Clearly APPROX(PREF)  jjV=1j aj . However, at every repetition,
the total weight of
Pall incoming edges must equal the total weight of all outgoing edges.
This means that v2V (v) = 0, and hence for the node v? that has maximal potential,
(v? )  0. Thus on every repetition j , it must be that aj  dj , so we have that
OPT(PREF)



jV j
X
j =1

(aj + dj )



jV j
X

(aj + aj )

j =1

 2  APPROX(PREF):

The first inequality holds because OPT(PREF) can at best include every edge in the graph,
and since every edge is removed exactly once, each edge must contribute to some aj or some
dj . 2
254

fiLearning to Order Things
1

2
1
k+2
2
k

k+3
k+1
k+1

k+2

2k+3
k

2k+3

Figure 5: An example of a graph (left) for which the node-based greedy algorithm achieves
an approximation factor of 21 by constructing the partial order on the right.

In passing, we note that there are other natural greedy algorithms that do not achieve
good approximations. Consider, for example, an algorithm that starts from a graph consisting of all the nodes but with no edges, and iteratively adds the highest weighted edge in
the graph, while avoiding cycles. It can be shown that this algorithm can produce a very
poor partial order, given an adversarially chosen graph; there are cases where the optimal
total order achieves a multiplicative factor of O(jV j) more weighted agreements than this
\edge-based" greedy algorithm.

4.4 Improvements to the Greedy Algorithm
The approximation factor of two given in Theorem 5 is tight. That is, there exist problems
for which the greedy algorithm approximation is worse than the optimal solution by a
factor arbitrarily close to two. Consider the graph shown on the left-hand side of Fig. 5. An
optimal total order ranks the instances according to their position in the figure, left to right,
breaking ties randomly, and achieves OPT(PREF) = 2k +2 weighted agreements. However,
the greedy algorithm picks the node labeled k + 1 first and orders all the remaining nodes
randomly, achieving as few as APPROX(PREF) = k + 2 agreements. For large k, the ratio
APPROX(PREF)=OPT(PREF) approaches 12 .
For graph of Figure 5, there is another simple algorithm which produces an optimal
ordering: since the graph is already a partial order, picking any total order consistent with
this partial order gives an optimal result. To cope with problems such as the one of Figure 5,
we devised an improvement to the greedy algorithm which combines a greedy method with
topological sorting. The aim of the improvement is to find better approximations for graphs
which are composed of many strongly connected components.
As before, the modified algorithm is easiest to describe by thinking of PREF as a
weighted directed graph. Recall that for each pair of nodes u and v, there exist two edges:
one from u to v with weight PREF(u; v) and one from v to u with weight PREF(v; u). In
the modified greedy algorithm we will pre-process the graph. For each pair of nodes, we
255

fiCohen, Schapire, & Singer
Algorithm SCC-Greedy-Order
Inputs: an instance set X ; a preference function PREF
Output: an approximately optimal ordering function ^
Define PREF0 (u; v) = maxfPREF(u; v) PREF(v; u); 0g :
Find strongly connected components U1 ; : : : ; Uk of the graph G = (V; E ) where
V = X and E = f(u; v) j PREF0 (u; v) > 0g :

Order the strongly connected components in any way consistent with the partial order
<scc :

U <scc U 0 iff 9u 2 U; u0 2 U 0 : (u; u0 ) 2 E

Use algorithm Greedy-Order or full enumeration to order the instances within each component Ui according to PREF0 .

Figure 6: The improved greedy ordering algorithm.
remove the edge with the smaller weight and set the weight of the other edge to be

j PREF(v; u)

PREF(u; v) j :

For the special case where PREF(v; u) = PREF(u; v) = 12 , we remove both edges. In the
reduced graph, there is at most one directed edge between each pair of nodes. Note that
the greedy algorithm would behave identically on the transformed graph since it is based
on the weighted differences between the incoming and outgoing edges.
We next find the strongly connected components3 of the reduced graph, ignoring (for
now) the weights. One can now split the edges of the reduced graph into two classes: intercomponent edges connect nodes u and v, where u and v are in different strongly connected
components; and intra-component edges connect nodes u and v from the same strongly
connected component. It is straightforward to verify that any optimal order agrees with all
the inter-component edges. Put another way, if there is an edge from node u to node v of
two different connected components in the reduced graph, then (u) > (v) for any optimal
total order .
The first step of the improved algorithm is thus to totally order the strongly connected
components in some way consistent with the partial order defined by the inter-component
edges. More precisely, we pick a total ordering for the components consistent with the
partial order <scc , defined as follows: for components U and U 0 , U <scc U 0 iff there is an
edge from some node u 2 U to some node u0 2 U 0 in the reduced graph.
We next order the nodes within each strongly connected component, thus providing a
total order of all nodes. Here the greedy algorithm can be used. As an alternative, in
cases where a component contains only a few elements (say at most five), one can find the
optimal order between the elements of the component by a brute-force approach, i.e., by
full enumeration of all permutations.
3. Two nodes u and v are in the same strongly connected component iff there are directed paths from u to
v and from v to u.

256

fiLearning to Order Things
0.4

b

a

0.2

a

b

a

0.6

0.2

b

0.45

0.5
0.95

0.9

0.45

0.55
0.05
0.5

0.55
0.65

c

d
0.35

0.9

0.1

)

0.1

0.3

c

d

0.2
b

c

0.3

d

0.9

)

0.1

c

0.1

0.3

d

a

0.1

Figure 7: An illustration of the approximation algorithm for finding a total order from
a weighted combination of ordering functions. The original graph (top left) is
reduced by removing at least one edge for each edge-pair (u; v) and (v; u) (middle).
The strongly connected components are then found (right). Finally, an ordering
is found within each strongly connected component which yield the order b > c >
d > a (bottom).
The improved algorithm is summarized in Figure 6 and illustrated in Figure 7. There
are four elements in Figure 7 which constitute two strongly connected components in the
reduced graph (fbg and fa; c; dg). Therefore, b is assigned the top rank and ranked above
a, c and d. If the brute-force algorithm were used to order the components, then we would
check all 3! permutations between a, c and d and output the total order b > c > d > a,
which is the optimal order in this toy example.
In the worst case, the reduced graph contains only a single strongly connected component. In this case, the improved algorithm generates the same ordering as the greedy
algorithm. However, in the experiments on metasearch problems described in Sec. 5, many
of the strongly connected components are small; the average size of a strongly connected
component is less than five. In cases such as these, the improved algorithm will often
improve on the simple greedy algorithm.

4.5 Experiments with the Ordering Algorithms
Ideally, each algorithm would be evaluated by determining how closely it approximates the
optimal ordering on large, realistic problems. Unfortunately, finding the optimal ordering
for large graphs is impractical. We thus performed two sets of experiments with the ordering
algorithms described above. In the first set of experiments, we evaluated the algorithms on
small graphs|specifically, graphs for which the optimal ordering could be feasibly found
with brute-force enumeration. In these experiments, we measure the \goodness" of the
resulting orderings relative to the optimal ordering. In the second set of experiments, we
evaluated the algorithms on large graphs for which the optimal orderings are unknown. In
these experiments, we compute a \goodness" measure which depends on the total weight
of all edges, rather than the optimal ordering.
257

fiCohen, Schapire, & Singer
In addition to the simple greedy algorithm and its improvement, we also considered the
following simple randomized algorithm: pick a permutation at random, and then output
the better of that permutation and its reverse. It can be easily shown that this algorithm
achieves the same approximation bound on expected performance as the greedy algorithm.
(Briey, one of the two permutations must agree with at least half of the weighted edges
in the graph.) The random algorithm can be improved by repeating the process, i.e.,
examining many random permutations and their reverses, and choosing the permutation
that achieves the largest number of weighted agreements.
In a first set of experiments, we compared the performance of the greedy approximation
algorithm, the improved algorithm which first finds strongly connected components, and the
randomized algorithm on graphs of nine or fewer elements. For each number of elements, we
generated 10;000 random graphs by choosing PREF(u; v) uniformly at random, and setting
PREF(v; u) to 1 PREF(u; v). For the randomized algorithm, we evaluated 10n random
permutations (and their reverses) where n is the number of instances (nodes). To have
a fair comparison between the different algorithms on the smaller graphs, we always used
the greedy algorithm (rather than a brute-force algorithm) to order the elements of each
strongly connected component of a graph.
To evaluate the algorithms, we examined the reduced graph and calculated the average
ratio of the weights of the edges chosen by the approximation algorithm to the weights of
the edges that were chosen by the optimal order. More precisely, let  be the optimal order
and ^ be an order chosen by an approximation algorithm. Then for each random graph, we
calculated
X
maxfPREF(u; v) PREF(v; u); 0g
u; v : ^(u) > ^(v)
X
:
maxfPREF(u; v) PREF(v; u); 0g
u; v : (u) > (v)
If this measure is 0.9, for instance, then the total weight of the edges in the total order
picked by the approximation algorithm is 90% of the corresponding figure for the optimal
algorithm.
We averaged the above ratios over all random graphs of the same size. The results
are shown on the left hand side of Figure 8. On the right hand side of the figure, we
show the average running time for each of the algorithms as a function of the number of
elements. When the number of ranked elements is more than five, the greedy algorithms
outperform the randomized algorithm, while their running time is much smaller. Thus, if
a full enumeration had been used to find the optimal order of small strongly connected
components, the approximation would have been consistently better than the randomized
algorithm.
We note that the greedy algorithm also generally performs better on average than
the lower bound given in Theorem 5. In fact, combining the greedy algorithm with prepartitioning of the graph into strongly connected components often yields the optimal order.
In the second set of experiments, we measured performance and running time for larger
random graphs. Since for large graphs we cannot find the optimal solution by brute-force
enumeration, we use as a \goodness" measure the ratio of the weights of the edges that were
left in the reduced graph after applying an approximation algorithm to the total weight of
258

fiLearning to Order Things

0.08
1

Greedy
SCC + Greedy
Randomized

Greedy
SCC + Greedy
Randomized

0.07

0.06

Running time (seconds)

Fraction of optimal solution

0.98

0.96

0.94

0.92

0.05

0.04

0.03

0.02
0.9
0.01

0.88

3

4

5

6

7

8

0

9

3

4

5

Number of elements

6

7

8

9

Number of elements

Figure 8: Comparison of goodness (left) and the running time (right) of the approximations
achieved by the greedy algorithms and the randomized algorithm as a function of
the number of ranked elements for random preference functions with 3 through 9
elements.

0.45

Greedy
SCC + Greedy
Randomized

0.95

0.9

0.35

Running time (seconds)

Fraction of total weight

Greedy
SCC + Greedy
Randomized

0.4

0.85

0.8

0.75

0.7

0.3

0.25

0.2

0.15

0.1
0.65
0.05
0.6
0
5

10

15

20

25

30

5

Number of elements

10

15

20

25

30

Number of elements

Figure 9: Comparison of goodness (left) and the running time (right) of the approximations
achieved by the greedy algorithms and the randomized algorithm as a function of
the number of ranked elements for random preference functions with 3 through 30
elements. Note that the graphs for Greedy and SCC+Greedy coincide for most
of the points.

259

fiCohen, Schapire, & Singer
edges in the graph. That is, for each random graph we calculated

X

maxfPREF(u; v)

u; v : ^(u) > ^(v)
X
maxfPREF(u; v)
u; v

PREF(v; u); 0g

PREF(v; u); 0g

:

We ran the three algorithms with the same parameters as above (i.e., 10;000 random
graphs). The results are given in Figure 9. The advantage of the greedy algorithms over
the randomized algorithm is even more apparent on these larger problems. Note also that
for large graphs the performance of the two greedy algorithms is indistinguishable. This is
mainly due to the fact that large random graphs are strongly connected with high probability.
To summarize the experiments, when there are six or more elements the greedy algorithm
clearly outperforms the randomized algorithm even if many randomly chosen permutations
are examined. Furthermore, the improved algorithm which first finds the strongly connected
components outperforms the randomized algorithm for all graph sizes. In practice the
improved greedy algorithm achieves very good approximations|within about 5 percent of
optimal, for the cases in which optimal graphs can be feasibly found.
5. Experimental Results for Metasearch

So far, we have described a method for learning a preference function, and a means of
converting a preference function into an ordering of new instances. We will now present
some experimental results in learning to order. In particular, we will describe results on
learning to combine the orderings of several web \search experts" using the algorithm of
Figure 2 to learn a preference function, and the simple greedy algorithm to order instances
using the learned preference function. The goals of these experiments are to illustrate the
type of problems that can be solved with our method; to empirically evaluate the learning
method; to evaluate the ordering algorithm on large, non-random graphs, such as might arise
in a realistic application; and to confirm the theoretical results of the preceding sections.
We thus restrict ourselves to comparing the learned orderings to individual search experts,
as is suggested by Theorem 1, rather than attempt to compare this application of learningto-order with previous experimental techniques for metasearch, e.g., (Lochbaum & Streeter,
1989; Kantor, 1994; Boyan, Freitag, & Joachims, 1994; Bartell, Cottrell, & Belew, 1994).
We note that this metasearch problem exhibits several properties that suggest a general
approach such as ours. For instance, approaches that learn to combine similarity scores
are not applicable, since the similarity scores of web search engines are often unavailable.
In the experiments presented here, the learning algorithm was provided with ordered lists
for each search engine without any associated scores. To further demonstrate the merits of
our approach, we also describe experiments with partial feedback|that is, with preference
judgments that are less informative than the relevance judgments more typically used in
improving search engines.
260

fiLearning to Order Things

ML Search Experts
NAME
\NAME"
title:\NAME"
NAME +LASTNAME title:\home page"
NAME +LASTNAME title:homepage
NAME +LASTNAME machine learning
NAME +LASTNAME \machine learning"
NAME +LASTNAME case based reasoning
NAME +LASTNAME \case based reasoning"
NAME +LASTNAME PLACE
NAME +LASTNAME \PLACE"
NAME +LASTNAME url:index.html
NAME +LASTNAME url:home.html
NAME +LASTNAME url:~*LASTNAME*
NAME +LASTNAME url:~LASTNAME
NAME +LASTNAME url:LASTNAME

UNIV Search Experts
NAME
\NAME"
\NAME" PLACE
title:NAME
title:\NAME"
title:\NAME" PLACE
NAME title:\home page"
NAME title:\homepage"
NAME welcome
NAME url:index.html
NAME url:home.html
\NAME" title:\home page"
\NAME" title:\homepage"
\NAME" welcome
\NAME" url:index.html
\NAME" url:home.html
\NAME" PLACE title:\home page"
\NAME" PLACE title:\homepage"
\NAME" PLACE welcome
\NAME" PLACE url:index.html
\NAME" PLACE url:home.html

Table 1: Search (and ranking) experts used in the metasearch experiments. In the associated queries, NAME is replaced with the person's (or university's) full name,
LASTNAME with the person's last name, and PLACE is replaced with the person's aliation (or university's location). Sequences of words enclosed in quotes
must appear as a phrase, and terms prefixed by title: and url: must appear
in that part of the web page. Words prefixed by a \+" must appear in the web
page; other words may or may not appear.

5.1 Test Problems and Encoding
We chose to simulate the problem of learning a domain-specific search engine|i.e., an engine
that searches for pages of a particular, narrow type. Ahoy! (Shakes, Langheinrich, & Etzioni,
1997) is one instance of such a domain-specific search engine. As test cases, we picked two
problems: retrieving the home pages of machine learning researchers (ML), and retrieving
the home pages of universities (UNIV). To obtain sample queries, we obtained a listing of
machine learning researchers, identified by name and aliated institution, together with
their home pages,4 and a similar list for universities, identified by name and (sometimes)
geographical location.5 Each entry on a list was viewed as a query, with the associated
URL the sole relevant web page.
4. From http://www.aic.nrl.navy.mil/aha/research/machine-learning.html, a list maintained by David
Aha.
5. From Yahoo!

261

fiCohen, Schapire, & Singer
We then constructed a series of special-purpose \search experts" for each domain. These
were implemented as query expansion methods which converted a name/aliation pair (or
a name/location pair) to a likely-seeming Altavista query. For example, one expert for the
UNIV domain searched for the university name appearing as a phrase, together with the
phrase \home page" in the title; another expert for the ML domain searched for all the
words in the person's name plus the words \machine" and \learning," and further enforces
a strict requirement that the person's last name appear. Overall, we defined 16 search
experts for the ML domain and 22 for the UNIV domain; these are summarized in Table 1.
Each search expert returned the top 30 ranked web pages. In the ML domain, there were
210 searches for which at least one search expert returned the named home page; for the
UNIV domain, there were 290 such searches. The task of the learning system is to find an
appropriate way of combining the output of these search experts.
To give a more precise description of the search experts, for each query t, we first
constructed the set X t consisting of all web pages returned by all of the expanded queries
defined by the search experts. Next, each search expert i was represented as a preference
function Rit . We chose these preference functions to be rank orderings defined with respect
to an ordering function fit in the natural way: we assigned a rank of fit = 30 to the first
listed page, fit = 29 to the second-listed page, and so on, finally assigning a rank of fit = 0
to every page not retrieved in the top 30 by the expanded query associated with expert i.
To encode feedback, we considered two schemes. In the first, we simulated complete
relevance feedback|that is, for each query, we constructed feedback in which the sole
relevant page was preferred to all other pages. In the second, we simulated the sort of
feedback that could be collected from \click data"|i.e., from observing a user's interactions
with a metasearch system. For each query, after presenting a ranked list of pages, we noted
the rank of the one relevant web page. We then constructed a feedback ranking in which the
relevant page is preferred to all preceding pages. This would correspond to observing which
link the user actually followed, and making the assumption that this link was preferred to
previous links.
It should be emphasized that both of these forms of feedback are simulated, and contain
less noise than would be expected from real user data. In reality some fraction of the
relevance feedback would be missing or erroneous, and some fraction of click data would
not satisfy the assumption stated above.

5.2 Evaluation and Results
To evaluate the expected performance of a fully-trained system on novel queries in this
domain, we employed leave-one-out testing. For each query t, we trained the learning system
on all the other queries, and then recorded the rank of the learned system on query t. For
complete relevance feedback, this rank is invariant of the ordering of the training examples,
but for the \click data" feedback, it is not; the feedback collected at each stage depends on
the behavior of the partially learned system, which in turn depends on the previous training
examples. Thus for click data training, we trained on 100 randomly chosen permutations
of the training data and recorded the median rank for t.
262

fiLearning to Order Things
5.2.1 Performance Relative to Individual Experts

The theoretical results provide a guarantee of performance relative to the performance of
the best individual search (ranking) expert. It is therefore natural to consider comparing
the performance of the learned system to the best of the individual experts. However, for
each search expert, only the top 30 ranked web pages for a query are known; if the single
relevant page for a query is not among these top 30, then it is impossible to compute any
natural measures of performance for this query. This complicates any comparison of the
learned system to the individual search experts.
However, in spite of the incomplete information about the performance of the search
experts, it is usually possible to tell if the learned system ranks a web page higher than a
particular expert.6 Motivated by this, we performed a sign test: we compared the rank of
the learning systems to the rank given by each search expert, checking to see whether this
rank was lower, and discarding queries for which this comparison was impossible. We then
used a normal approximation to the binomial distribution to test the following two null
hypotheses (where the probability is taken over the distribution from which the queries are
drawn):

H1. With probability at least 0.5, the search expert performs better than the learning
system (i.e., gives a lower rank to the relevant page than the learning system does.)
H2. With probability at least 0.5, the search expert performs no worse than the learning
system (i.e., gives an equal or lower rank to the relevant page.)
In training, we explored learning rates in the range [0:001; 0:999]. For complete feedback
in the ML domain, hypothesis H1 can be rejected with high confidence (p > 0:999) for every
search expert and every learning rate 0:01  fi  0:99. The same holds in the UNIV domain
for all learning rates 0:02  fi  0:99. The results for click data training are nearly as strong,
except that 2 of the 22 search experts in the UNIV domain show a greater sensitivity to
the learning rate: for these engines, H1 can only be rejected with high confidence for
0:3  fi  0:6. To summarize, with high confidence, in both domains, the learned ranking
system is no worse than any individual search expert for moderate values of fi .
Hypothesis H2 is more stringent since it can be rejected only if we are sure that the
learned system is strictly better than the expert. With complete feedback in the ML domain
and 0:3  fi  0:8, hypothesis H2 can be rejected with confidence p > 0:999 for 14 of the 16
search experts. For the remaining two experts the learned system does perform better more
often, but the difference is not significant. In the UNIV domain, the results are similar. For
0:2  fi  0:99, hypothesis H2 can be rejected with confidence p > 0:999 for 21 of the 22
search experts, and the learned engine tends to perform better than the single remaining
expert.
Again, the results for click data training are only slightly weaker. In the ML domain,
hypothesis H2 can be rejected for all but three experts for all but the most extreme learning
rates; in the UNIV domain, hypothesis H2 can be rejected for all but two experts for 0:4 
fi  0:6. For the remaining experts and learning rates the differences are not statistically
6. The only time this cannot be determined is when neither the learned system nor the expert ranks the
relevant web pages in the top 30, a case of little practical interest.

263

fiCohen, Schapire, & Singer
significant; however, it is not always the case that the learned engine tends to perform
better.
To summarize the experiments, for moderate values of fi the learned system is, with
high confidence, strictly better than most of the search experts in both domains, and never
significantly worse than any expert. When trained with full relevance judgments, the learned
system performs better on average than any individual expert.
5.2.2 Other Performance Measures

We measured the number of queries for which the correct web page was in the top k ranked
pages, for various values of k. These results are shown in Figure 10. Here the lines show the
performance of the learned systems (with fi = 0:5, a generally favorable learning rate) and
the points correspond to the individual experts. In most cases, the learned system closely
tracks the performance of the best expert at every value of k. This is especially interesting
since no single expert is best at all values of k.
The final graph in this figure investigates the sensitivity of this measure to the learning
rate fi . As a representative illustration, we varied fi in the ML domain and plotted the
top-k performance of the system learned from complete feedback for three values of k. Note
that performance is roughly comparable over a wide range of values for fi .
Another plausible measure of performance is the average rank of the (single) relevant
web page. We computed an approximation to average rank by artificially assigning a rank
of 31 to every page that was either unranked, or ranked above rank 30. (The latter case is
to be fair to the learned system, which is the only one for which a rank greater than 30 is
possible.) A summary of these results for fi = 0:5 is given in Table 2, together with some
additional data on top-k performance. In the table, we give the top-k performance for three
values of k, and average rank for several ranking systems: the two learned systems; the naive
query, i.e., the person or university's name; and the single search expert that performed
best with respect to each performance measure. Note that not all of these experts are
distinct since several experts scored the best on more than one measure.
The table illustrates the robustness of the learned systems, which are nearly always
competitive with the best expert for every performance measure listed. The only exception
to this is that the system trained on click data trails the best expert in top-k performance for
small values of k. It is also worth noting that in both domains, the naive query (simply the
person or university's name) is not very effective: even with the weaker click data feedback,
the learned system achieves a 36% decrease in average rank over the naive query in the ML
domain, and a 46% decrease in the UNIV domain.
To summarize the experiments, on these domains the learned system not only performs
much better than naive search strategies, but also consistently performs at least as well as,
and perhaps slightly better than, any single domain-specific search expert. This observation
holds regardless of the performance metric considered; for nearly every metric we computed,
the learned system always equals, and usually exceeds, the performance of the search expert
that is best for that metric. Finally, the performance of the learned system is almost as
good with the weaker \click data" training as with complete relevance feedback.
264

fiLearning to Order Things
ML: queries answered in top k
250

Learned System - Full feedback
Learned System - Click data
Individual Rankers

# queries in top k

200
150
100
50
0
0

5

10

15

20

25

30

35

k
UNIV: queries answered in top k
Learned System - Full feedback
Learned System - Click data
Individual Rankers

# queries in top k

300
250
200
150
100
50
0
0

5

10

15

20

25

30

35

k

0.85
0.80

k=8

% Relevant

0.75
0.70
0.65

k=4

0.60
0.55
0.50

k=1

0.45
0.40
0

0.2

0.4
0.6
Learning Rate

0.8

1

Figure 10: Top and middle: Performance of the learned system versus individual experts
for two different domains. Bottom: the percentage of time the relevant web page
was in the top-k list for k = 1,4, and 8.
265

fiCohen, Schapire, & Singer

Learned (Full Feed.)
Learned (Click Data)
Naive
Best (Top 1)
Best (Top 10)
Best (Top 30)
Best (Avg Rank)

Top 1
114
93
89
119

114
97
114

ML Domain
Top 10 Top 30

Avg Rank

185

198

4.9

185

198

4.9

165
170
182
181
182

176
184
190
194
190

7.7
6.7
5.3
5.6
5.3

Top 1
111
87
79
112

111
111
111

University Domain
Top 10 Top 30 Avg Rank
225
253
7.8
229

157
221
223
223
223

259

191
247
249
249
249

7.8

14.4
8.2
8.0
8.0
8.0

Table 2: Comparison of learned systems and individual search queries.

6. Related Work

Problems that involve ordering and ranking have been investigated in various fields such as
decision theory, the social sciences, information retrieval and mathematical economics (Black,
1958; Kemeny & Snell, 1962; Cooper, 1968; Fishburn, 1970; Roberts, 1979; Salton & McGill,
1983; French, 1989; Yao, 1995). Among the wealth of literature on the subject, the closest to
ours appears to be the work of Kemeny and Snell (1962) which was extended by Yao (1995)
and used by Balabanovc and Shoham (1997) in their FAB collaborative filtering system.
These works use a similar notion of ordering functions and feedback; however, they assume
that both the ordering functions and the feedback are complete and transitive. Hence, it
is not possible to leave elements unranked, or to have inconsistent feedback which violates
the transitivity requirements. It is therefore dicult to combine and fuse inconsistent and
incomplete orderings in the Kemeny and Snell model.
There are also several related intractability results. Most of them are concerned with the
diculty in reaching consensus in voting systems based on preference ordering. Specifically,
Bartholdi, Tovey and Trick (1989) study the problem of finding a winner in an election
when the preferences of all voters are irreexive, antisymmetric, transitive, and complete.
Thus, their setting is more restrictive than ours. They study two similar schemes to decide
on a winner of an election. The first was invented by Dodgson (1876) (better known by
his pen name, Lewis Carroll) and the second is due to Kemeny (1959). For both models,
they show that the problem of finding a winner in an election is NP-hard. Among these
two models, the one suggested by Kemeny is the closest to ours. However, as mentioned
above, this model is more restrictive as it does not allow voters to abstain (preferences are
required to be complete) or to be inconsistent (all preferences are transitive).
As illustrated by the experiments, the problem of learning to rank is closely related to
the problem of combining the results of different search engines. Many methods for this
have been proposed by the information retrieval community, and many of these are adaptive, using relevance judgments to make an appropriate choice of parameters. However,
generally, rankings are combined by combining the scores that were used to rank documents (Lochbaum & Streeter, 1989; Kantor, 1994). It is also frequently assumed that other
properties of the objects (documents) to be ranked are available, such as word frequencies.
In contrast, in our experiments, instances are atomic entities with no associated properties
except for their position in various rank-orderings. Similarly, we make minimal assump266

fiLearning to Order Things
tions about the rank-orderings|in particular, we do not assume scores are available. Our
methods are thus applicable to a broader class of ranking problems.
General optimization methods have also been adopted to adjust parameters of an IR
system so as to improve agreement with a set of user-given preference judgments. For instance, Boyan, Freitag, and Joachims (1994) use simulated annealing to improve agreement
with \click data," and Bartell, Cottrell and Belew (1994) use conjugate gradient descent
to choose parameters for a linear combination of scoring functions, each associated with
a different search expert. Typically, such approaches offer few guarantees of eciency,
optimality, or generalization performance.
Another related task is collection fusion. Here, several searches are executed on disjoint
subsets of a large collection, and the results are combined. Several approaches to this problem that do not rely on combining ranking scores have been described (Towell, Voorhees,
Gupta, & Johnson-Laird, 1995; Voorhees, Gupta, & Johnson-Laird, 1994). However, although the problem is superficially similar to the one presented here, the assumption that
the different search engines index disjoint sets of documents actually makes the problem
quite different. In particular, since it is impossible for two engines to give different relative
orderings to the same pair of documents, combining the rankings can be done relatively
easily.
Etzioni et al. (1996) formally considered another aspect of metasearch|the task of
optimally combining information sources with associated costs and time delays. Our formal
results are disjoint from theirs, as they assume that every query has a single recognizable
correct answer, rendering ordering issues unimportant.
There are many other applications in machine learning, reinforcement learning, neural
networks, and collaborative filtering that employ ranking and preferences, e.g., (Utgoff &
Saxena, 1987; Utgoff & Clouse, 1991; Caruana, Baluja, & Mitchell, 1996; Resnick & Varian,
1997), While our work is not directly relevant, it might be possible to use the framework
suggested in this paper in similar settings. This is one of our future research goals.
Finally, we would like to note that the framework and algorithms presented in this paper
can be extended in several ways. Our current research focuses on ecient batch algorithms
for combining preference functions, and on using restricted ranking experts for which the
problem of finding an optimal total ordering can be solved in polyomial time (Freund, Iyer,
Schapire, & Singer, 1998).
7. Conclusions

In many applications, it is desirable to order rather than classify instances. We investigated
a two-stage approach to learning to order in which one first learns a preference function by
conventional means, and then orders a new set of instances by finding the total ordering
that best approximates the preference function. The preference function that is learned is
a binary function PREF(u; v), which returns a measure of confidence reecting how likely
it is that u is preferred to v. This is learned from a set of \experts" which suggest specific
orderings, and from user feedback in the form of assertions of the form \u should be preferred
to v".
We have presented two sets of results on this problem. First, we presented an online
learning algorithm for learning a weighted combination of ranking experts which is based
267

fiCohen, Schapire, & Singer
on an adaptation of Freund and Schapire's Hedge algorithm. Second, we explored the
complexity of the problem of finding a total ordering that agrees best with a preference
function. We showed that this problem is NP-complete even in a highly restrictive case,
namely, preference predicates that are linear combinations of a certain class of well-behaved
\experts" called rank orderings. However, we also showed that for any preference predicate,
there is a greedy algorithm that always obtains a total ordering that is within a factor of
two of optimal. We also presented an algorithm that first divides the set of instances into
strongly connected components and then uses the greedy algorithm (or full enumeration,
for small components) to find an approximately good order within large strongly connected
components. We found that this approximation algorithm works very well in practice and
often finds the best order.
We also presented experimental results in which these algorithms were used to combine
the results of a number of \search experts," each of which corresponds to a domain-specific
strategy for searching the web. We showed that in two domains, the learned system closely
tracks and often exceeds the performance of the best of these search experts. These results
hold for either traditional relevance feedback models of learning, or from weaker feedback
in the form of simulated \click data." The performance of the learned systems also clearly
exceeds the performance of more naive approaches to searching.
Acknowledgments

We would like to thank Noga Alon, Edith Cohen, Dana Ron, and Rick Vohra for numerous
helpful discussions. An extended abstract of this paper appeared in Advances in Neural
Information Processing Systems 10, MIT Press, 1998.
References

Balabanovc, M., & Shoham, Y. (1997). FAB: Content-based, collaborative recommendation. Communications of the ACM, 40 (3), 66{72.
Bartell, B., Cottrell, G., & Belew, R. (1994). Automatic combination of multiple ranked
retrieval systems. In Seventeenth Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval.
Bartholdi, J., Tovey, C., & Trick, M. (1989). Voting schemes for which it can be dicult
to tell who won the elections. Social Choice and Welfare, 6, 157{165.
Berger, B., & Shor, P. (1997). Tight bounds for the acyclic subgraph problem. Journal of
Algorithms, 25, 1{18.
Black, D. (1958). Theory of Committees and Elections. Cambridge University Press.
Boyan, J., Freitag, D., & Joachims, T. (1994). A machine learning architecture for optimizing web search engines. Tech. rep. WS-96-05, American Association of Artificial
Intelligence.
268

fiLearning to Order Things
Caruana, R., Baluja, S., & Mitchell, T. (1996). Using the future to `Sort Out' the present:
Rankprop and multitask learning for medical risk evaluation. In Advances in Neural
Information Processing Systems (NIPS) 8.
Cooper, W. (1968). Expected search length: A single measure of retrieval effectiveness
based on the weak ordering action of retrieval systems. American Documentation, 19,
30{41.
Dodgson, C. (1876). A method for taking votes on more than two issues. Clarendon Press,
Oxford. Reprinted with discussion in (Black, 1958).
Etzioni, O., Hanks, S., Jiang, T., Karp, R. M., Madani, O., & Waarts, O. (1996). Ecient
information gathering on the internet. In Proceedings of the 37th Annual Symposium on Foundations of Computer Science (FOCS-96) Burlington, Vermont. IEEE
Computer Society Press.
Even, G., Naor, J., Rao, S., & Schieber, B. (1996). Divide-and-conquer approximation algorithms via spreading metrics. In 36th Annual Symposium on Foundations of Computer
Science (FOCS-96), pp. 62{71 Burlington, Vermont. IEEE Computer Society Press.
Even, G., Naor, J., Schieber, B., & Sudan, M. (1998). Approximating minimum feedback
sets and multicuts in directed graphs. Algorithmica, 20 (2), 151{174.
Fishburn, F. (1970). Utility Theory for Decision Making. Wiley, New York.
French, S. (1989). Decision Theory: An Introduction to the Mathematics of Rationality.
Ellis Horwood Series in Mathematics and Its Applications.
Freund, Y., Iyer, R., Schapire, R., & Singer, Y. (1998). An ecient boosting algorithm for
combining preferences. In Machine Learning: Proceedings of the Fifteenth International Conference.
Freund, Y., & Schapire, R. (1997). A decision-theoretic generalization of on-line learning
and an application to boosting. Journal of Computer and System Sciences, 55 (1),
119{139.
Galil, Z., & Megido, N. (1977). Cyclic ordering is NP-complete. Theoretical Computer
Science, 5, 179{182.
Gary, M., & Johnson, D. (1979). Computers and Intractability: A Guide to the Theory of
NP-completeness. W. H. Freeman and Company, New York.
Kantor, P. (1994). Decision level data fusion for routing of documents in the TREC3
context: a best case analysis of worst case results. In Proceedings of the third text
retrieval conference (TREC-3).
Kemeny, J. (1959). Mathematics without numbers. Daedalus, 88, 571{591.
Kemeny, J., & Snell, J. (1962). Mathematical Models in the Social Sciences. Blaisdell, New
York.
269

fiCohen, Schapire, & Singer
Littlestone, N. (1988). Learning quickly when irrelevant attributes abound: A new linearthreshold algorithm. Machine Learning, 2 (4).
Littlestone, N., & Warmuth, M. (1994). The weighted majority algorithm. Information and
Computation, 108 (2), 212{261.
Lochbaum, K., & Streeter, L. (1989). Comparing and combining the effectiveness of latent semantic indexing and the ordinary vector space model for information retrieval.
Information processing and management, 25 (6), 665{676.
Resnick, P., & Varian, H. (1997). Introduction to special section on Recommender Systems.
Communication of the ACM, 40 (3).
Roberts, F. (1979). Measurement theory with applications to decision making, utility, and
social sciences. Addison Wesley, Reading, MA.
Salton, G., & McGill, M. (1983). Introduction to Modern Information Retrieval. McGrawHill.
Seymour, P. (1995). Packing directed circuits fractionally. Combinatorica, 15, 281{288.
Shakes, J., Langheinrich, M., & Etzioni, O. (1997). Dynamic reference sifting: a case study
in the homepage domain. In Proceedings of WWW6.
Shmoys, D. (1997). Cut problems and their application to divide-and-conquer. In
Hochbaum, D. (Ed.), Approximation algorithms for NP-Hard Problems. PWS Publishing Company, New York.
Towell, G., Voorhees, E., Gupta, N., & Johnson-Laird, B. (1995). Learning collection fusion
strategies for information retrieval. In Machine Learning: Proceedings of the Twelfth
International Conference Lake Taho, California. Morgan Kaufmann.
Utgoff, P., & Clouse, J. (1991). Two kinds of training information for evaluation function
learning. In Proceedings of the Ninth National Conference on Artificial Intelligence
(AAAI-91), pp. 596{600 Cambridge, MA. AAAI Press/MIT PRess.
Utgoff, P., & Saxena, S. (1987). Learning a preference predicate. In Proceedings of the
Fourth International Workshop on Machine Learning, pp. 115{121 San Francisco,
CA. Morgan Kaufmann.
Voorhees, E., Gupta, N., & Johnson-Laird, B. (1994). The collection fusion problem. In Sev-

enteenth Annual International ACM SIGIR Conference on Research and Development
in Information Retrieval.

Yao, Y. (1995). Measuring retrieval effectiveness based on user preference of documents.
Journal of the American Society for Information Science, 46 (2), 133{145.

270

fiJournal of Artificial Intelligence Research 10 (1999) 87-115

Submitted 9/98; published 2/99

Ecient Implementation of the Plan Graph in STAN
Derek Long
Maria Fox

d.p.long@dur.ac.uk
maria.fox@dur.ac.uk

Department of Computer Science
University of Durham, UK

Abstract

Stan is a Graphplan-based planner, so-called because it uses a variety of STate ANalysis techniques to enhance its performance. Stan competed in the AIPS-98 planning
competition where it compared well with the other competitors in terms of speed, finding
solutions fastest to many of the problems posed. Although the domain analysis techniques
Stan exploits are an important factor in its overall performance, we believe that the speed
at which Stan solved the competition problems is largely due to the implementation of
its plan graph. The implementation is based on two insights: that many of the graph
construction operations can be implemented as bit-level logical operations on bit vectors,
and that the graph should not be explicitly constructed beyond the fix point. This paper
describes the implementation of Stan's plan graph and provides experimental results which
demonstrate the circumstances under which advantages can be obtained from using this
implementation.

1. Introduction
Stan is a domain-independent planner for STRIPS domains, based on the graph construc-

tion and search method of Graphplan (Blum & Furst, 1997). Its name is derived from the
fact that it performs a number of preprocessing analyses, or STate ANalyses, on the domain
before planning, using the Type Inference Module Tim described by Fox and Long (1998).
Stan competed in the AIPS-98 planning competition and achieved an excellent overall
performance in both rounds. The results of the competition, which can be found at the
URL given in Appendix A, show that Stan was able to solve some problems notably
quickly and that it could find optimal parallel solutions to some problems which could not
be solved optimally by any other planner in the competition, for example in the Gripper
domain. The problems posed in the competition did not give Stan much opportunity to
exploit its domain analysis techniques, so this performance is due mainly to the underlying
implementation of the plan graph that Stan constructs and searches. A more detailed
discussion of the competition, from the competitors' point of view, is in preparation.
The design of Stan's plan graph is based on two insights. First, we observe that action
pre- and post-conditions can be represented using bit vectors. Checking for mutual exclusion
between pairs of actions which directly interact can be implemented using logical operations
on these bit vectors. Mutual exclusion (mutex relations) between facts can be implemented
in a similar way. In order to best exploit the bit vector representation of information
we construct a two-layer graph called a spike which avoids unnecessary copying of data
and allows layer-dependent information about a node to be clearly separated from layerindependent information about that node. The spike allows us to record mutex relations
c 1999 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiLong & Fox

using bit vectors, making mutex testing for indirect interaction much more ecient (we
distinguish between direct and indirect interaction in Section 2.1). Second, we observe that
there is no advantage in explicit construction of the graph beyond the stage at which the
fix point is reached. Our plan graph maintains a wave front which keeps track of all of the
goal sets remaining to be considered during search. Since no new facts, actions or mutex
relations are added beyond the fix point these goal sets can be considered without explicit
copying of the fact and action layers. The wave front mechanism allows Stan to solve very
large problem instances using a fraction of the time and space consumed by Graphplan and
Ipp (Koehler, Nebel, & Dimopoulos, 1997). For example, using a heuristic discussed in
Section 5.1, Stan can solve the 10-disc Towers of Hanoi problem (a 1023 step plan) in less
than 9 minutes.
In this paper we describe the spike and wave front mechanisms and provide experimental
results indicating the performance advantages obtained.

2. The Spike Graph Structure
Graphplan (Blum & Furst, 1997) uses constraint satisfaction techniques to search a layered graph which represents a compressed reachability analysis of a domain. The layers
correspond to snapshots of possible states at instants on a time line from the initial to the
goal state. Each layer in the graph comprises a set of facts that represents the union of
states reachable from the preceding layer. This compression guarantees that the plan graph
can be constructed in time polynomial in the number of action instances in the domain.
The expansion of the graph, from which solutions can be extracted, is partially encoded in
binary mutex relations computed during the construction of each layer. STAN implements
an ecient representation of the graph in which a wave front, discussed in Section 4, further
supports its compression. In Graphplan-style planners the search for a plan, from layer k,
involves the selection and exploration of a collection of action choices to see whether a plan
can be constructed, using those actions at the kth time step. If no plan is found the planner
backtracks over the action choices. Two important landmarks arise during the construction
of the plan graph. The first is the point at which the graph opens in the sense that the
problem becomes, in principle, solvable. This is the layer at which all of the top level goals
first become pairwise non-mutex and is referred to here as the opening layer. The second
is the fix point, referred to as level off by Blum and Furst (1997), the layer after which no
further changes can be made to either the action, fact or mutex information recorded in the
graph at each layer.
In the original implementation of Graphplan the graph was implemented as an alternating sequence of layers of fact nodes and action nodes, with arcs connecting actions to
their preconditions in the previous layer and their postconditions in the subsequent layer.
The layers were constructed explicitly involving the repeated copying of large portions of
the graph at each stage in maintaining the graph structure. This copying was due to two
features of the graph. First, since actions with satisfied preconditions in one layer continue
to have satisfied preconditions in all subsequent layers, actions that have once been added
to a layer will appear in every successive action layer with the same name and the same
pre- and post-conditions. Second, since facts that have once been achieved by the effects
of an action will always be achieved by that action, they will continue to appear in every
88

fiEfficient Implementation of the Plan Graph in STAN

successive fact layer after the layer in which they first appeared. Although the layers can
get deeper at every successive stage they each duplicate information present in the previous
layer, so there is only a small amount of new information added at every stage. The proportion of new material, relative to copied material, decreases progressively as the graph
develops.
In the original Graphplan, mutex relations were checked for by maintaining lists of facts,
corresponding to the pre- and post-conditions of actions, and checking for membership of
facts within these lists. Because of the need to copy information at each new layer, the preand post-conditions of actions were duplicated even though this information did not vary
from layer to layer (it can be determined once and for all at the point of instantiation of
the schema). It is possible to identify layer-independent information, with each node in the
graph, which can be stored just once using a different representation of the graph structure.
The spike representation reimplements the graph as a single fact array, called the fact
spike, and a single action array, called the action spike, each divided into ranks corresponding
to the layers in the original Graphplan graph structure. The observations leading to this
compressed implementation of the plan graph were made independently by Smith and Weld
(1998). In Stan, a fact rank is a consecutive sequence of fact headers storing the layerindependent information associated with their associated facts in the corresponding fact
layer. Similarly, an action rank is a consecutive sequence of action headers storing layerindependent information about their associated actions in the corresponding action layer.
Each header is a tuple containing, amongst other things, the name of the fact or action it
is associated with and a structure which stores the layer-dependent information relevant to
that fact or action. In the case of fact headers this structure is called a fact level package
and in the case of action headers it is an action level package. Figure 1 shows how a simple
graph structure can be viewed as a spike.
In the spike the positions of all fact and action headers are fixed and can be referred to
by indexing into the appropriate array. At any point, the sizes of the arrays are referred
to using the constant MaxSize, a large number setting an upper bound on the size of the
spike. All of the vectors allocated are also initialised to this size, although they are used
in word-sized increments. This saves the effort of re-allocating and copying vectors as the
spike increases in size towards MaxSize. We now define the data types so far introduced.

Definition 1 A spike vector is a bit vector of size MaxSize.
Definition 2 A fact header is a tuple of six components: a name which is the predicate

and arguments that comprise the fact itself; an index, i, giving the position of the fact in
the fact array; a bit mask which is a spike vector in which the ith bit is set and all other bits
are unset; a reference identifying its achieving no-op; a spike vector consumers with bits set
for all the actions which use this fact as a precondition and a fact level package storing the
layer-dependent information about that fact.

Definition 3 An action header is a tuple of eight components: the name of the action;

an index, i, giving the position of the action in the action array; a bit mask which is a
spike vector in which the ith bit is set and all other bits are unset; a ag indicating whether
the action is a no-op; three spike vectors, called precs, adds and dels and an action level
package storing the layer-dependent information about that action. Each bit in precs, adds
89

fiLong & Fox

Fact Layer 0

P

Action Layer 1

Noop

P

Noop

Q

Q
R

Fact Layer 1

Noop
op1
op2

P
Noop
Q
Noop

S

Noop

U

Fact Layer 2

Noop

R

T

Action Layer 2

R
S

Noop
T
Noop
U

op1
op2
op3

V
W

Fact Spike
and Fact Level Packages

rank 0

rank 1

Action Spike
and Action Level Packages

P

Noop
P

Q

Noop
Q

R

Noop
R

S

op1

T

op2

U

Noop
S

V

Noop
T

W

Noop
U

rank 2

rank 1

rank 2

op3

Figure 1: Representation of a plan graph as a spike. In the fact spike, ranks 0, 1 and 2
correspond to fact layers 0, 1 and 2 respectively. In the action spike, ranks 1 and
2 correspond to action layers 1 and 2 respectively.

90

fiEfficient Implementation of the Plan Graph in STAN

and dels corresponds to an index into the fact array and is set in precs if the fact at that
index is a precondition (and unset otherwise), in adds if the fact at that index is an add list
element (and unset otherwise) and in dels if the fact at that index is a delete list element
of the action (and unset otherwise).

Definition 4 A fact mutex vector (FMV) for a fact, f , is a spike vector in which the bits
correspond to the indices into the fact array and a bit is set if the corresponding fact is
mutex with f .
Definition 5 An action mutex vector (AMV) for an action, a, is a spike vector in which

the bits correspond to the indices into the action array and a bit is set if the corresponding
action is mutex with a.

Definition 6 A fact level package for a fact, f , is an array of pairs, one for each rank in

the spike, each containing a fact mutex vector for f and a vector of achievers, called the
achievement vector (AV), in the previous action rank.

Definition 7 An action level package for an action, a, is an array of triples, one for each
rank in the spike, each containing an action mutex vector for a and a list of actions mutex
with a (MAs).
Using these definitions we can now provide a detailed description of the spike construction process.

2.1 The Spike Construction Process

We will make use of these header access functions in the following discussion:
mvec : fact ! fact mutex vector
precs of : action ! precs
adds of : action ! adds
dels of : action ! dels
The spike construction process takes place within a loop which stops when all goals are
pairwise achievable, and thereafter alternates with search until the fix point is reached and
the wave front mechanism takes over. The use of the wave front is discussed in Section 4.
The key component of the process is the rank construction algorithm which builds a fact
rank and an action rank by extending the previous fact and action ranks in the spike. The
action rank is started by adding no-ops for each of the fact headers in the previous fact
rank. As soon as these are added, the fact headers can be updated to refer, by index into
the action rank, to their achieving no-ops. This information allows Stan to give preference,
when searching, to plans that use the no-op to achieve a goal rather than some other
achiever. In Graphplan this preference was ensured by keeping all of the no-ops at the top
of the graph layers and considering the achievers in order during search.
All possible action instances are then considered. All applicable action instances are
enacted and then removed so that they will never be reconsidered for enactment. We then
identify mutex relations between the actions in the new action rank, and between facts in
the new fact rank.
91

fiLong & Fox

As in Graphplan, an action instance is applicable in a rank if all of its preconditions are
present and non-mutex in the previous rank. The way in which preconditions are tested for
mutual exclusion in Stan is based on our bit vector representation of fact mutex relations.
We take the logical or of all of the fact mutex vectors of the preconditions, and logically
and the result with the precondition vector of the action. If the result is non-zero then
there are mutex preconditions and the action is not applicable. This test corresponds to
checking whether the action being considered is mutex with itself - a condition we define as
being self-mutex.

Definition 8 An action a, with preconditions a 1::a , is self-mutex if:
(mvec(a 1) _ mvec(a 2) _ ::: _ mvec(a )) ^ precs of (a)
p

p

pn

p

pn

is non-zero.

An applicable action is enacted by adding an action header to the new rank and setting
its name to the name of the action and its bit mask to record its position in the spike.
In Figures 2 and 3 no-ops are given the names of the facts they achieve and are identified
as no-ops by the ag components of their headers. We allocate space for the action level
package and create and set its pres, adds and dels vectors. We then add any new facts on
the add list of the action to the corresponding new fact rank. The addition of new facts
requires new fact headers to be initialised.
We then identify mutex actions and mutex facts in the new ranks. Mutex actions
are identified in two phases. Actions which were non-mutex in the previous rank remain
non-mutex and are not considered at this stage. First, existing action mutex relations are
checked to see whether they hold in the new rank. Second, new action mutex relations
must be deduced from the addition of new actions in the construction of this rank. We first
consider the existing action mutex relations.
Two actions are mutex, as in Graphplan, if they have conicting add and delete lists,
conicting precondition and delete lists or mutex preconditions. In the first two cases
the actions are directly, or permanently, mutex and never need to be re-tested although
their mutex relationship must be recorded at each rank. In the third case the actions are
indirectly, or temporarily, mutex and must be retried at subsequent ranks. We keep track of
which actions to retry in order to avoid unnecessary retesting. We confirm that two actions,
a and b, which were temporarily mutex in the previous rank are still temporarily mutex
using the following logical operations on the fact mutex vectors for the action preconditions.
We first logically or together the mutex vectors for a's preconditions then and the result
with the precondition vector for b. If the result is non-zero then a and b are mutex. This
procedure, which is expressed concisely in Definition 9, is identical to that for checking
whether an action is self-mutex except that, in this case, the result of oring the fact mutex
vectors of the preconditions of one action is anded with the precondition vector of the other
action. Since mutex relations are symmetric it is irrelevant which action plays which role
in the test.

Definition 9 Two actions a (with n preconditions a 1::a ) and b are temporarily mutex

if

p

pn

(mvec(a 1) _ mvec(a 2) _ ::: _ mvec(a )) ^ precs of (b)
p

p

pn

92

fiEfficient Implementation of the Plan Graph in STAN

is non-zero.

We now consider what new mutex relations can be inferred from the introduction of
the new actions. It is necessary to check all new actions against all actions in the spike.
This check is done in only one direction - low-indexed actions against high-indexed actions
- so that the test is done only once for each pair. We check for both permanent and
temporary mutex relations. The permanent mutex test is done first, because if two actions
are permanently mutex it is of no interest to find that they are also temporarily mutex.
Definition 10 provides the logical operation used to confirm that two actions are permanently
mutex. Temporary mutex relations are checked for using the logical operation defined in
Definition 9.
Definition 10 Two actions a and b are permanently mutex if the result of
((precs of (a) _ adds of (a)) ^ dels of (b))_
((precs of (b) _ adds of (b)) ^ dels of (a))
is non-zero.

We add these mutex relations by setting the appropriate bits in the mutex vectors of
each of the new actions. This is done by oring the mutex vector of the first action with the
bit mask of the second action, and vice versa. A list of mutex actions is also maintained for
use during search of the spike.
A refinement of the action mutex checking done by Stan is the use of a record of actions
whose preconditions have lost mutex relations since the last layer of the graph. This record
enables Stan to avoid retesting temporary mutex relations between actions when the mutex
relations between their preconditions cannot have changed. We use a bit vector called
changedActs to record this information. Each fact which loses mutex relations between
layers adds its consumers to changedActs. The impact of this refinement on eciency is
discussed in Section 3.
This concludes the construction of the new action rank. The new fact rank has already
been partially constructed by the addition to the spike of fact headers for any add list
elements, of the new actions, that were not already present. Now it is necessary to determine
mutex relations between all pairs of facts in the spike. To do this we must first complete
the achievement vectors for all of the fact headers in the new rank. Any non-mutex pairs
remain non-mutex, as with actions, so effort is focussed on deciding whether previously
mutex facts are still mutex following the addition of the new actions, and whether new
facts induce new mutex relations. Two facts are mutex if the only way of achieving both
of them involves the use of mutex actions. We therefore consider every new fact with every
other fact, in only one direction. The pair f , g is mutex in the new rank if every possible
achiever of f is mutex with every possible achiever for g . The test for this exclusion is done
using g 's achievement vector and the result of logically anding the action mutex vectors for
all possible achievers of f . the following definition gives the details:

Definition 11 Two facts, f and g, are mutex if:
vec ^ all mutex = vec
g

f

93

g

fiLong & Fox

where vec is g 's achievement vector and all mutex is the consequence of anding all of the
action mutex vectors of all of f 's possible achievers.
f

g

It does not matter in which order f and g are treated. The computation of the above
condition corresponds to testing the truth of

8a  8b  (achiever(a; f ) ^ achiever(b; g) ! mutex(a; b))
Since mutex relations are symmetric and the quantifiers can be freely reordered the expression equally corresponds to
vec ^ all mutex = vec
If f and g are found to be mutex then we set the fact mutex vector of f by oring it
with g 's bit mask and the fact mutex vector of g is set conversely. This concludes the rank
construction process and one iteration of the spike construction process.
f

g

2.2 Subset Memoization in Stan

f

Most of the search machinery used in Stan is essentially identical to that of Graphplan.
That is, a goal set is considered by identifying appropriate achieving actions in the previous
layer and propagating their preconditions back through the graph. The use of the spike
and bit vector representations does not impact on the search algorithm. We experimented
with using bit vector representations of bad goal sets in the memoization process, in order
to exploit logical bit operations to test for subset relations between sets of goals, but this
proved too expensive and we now rely upon a trie data structure. This benefits marginally
from the spike because goal sets do not need to be sorted for subset testing. The order
in which the goals are generated in the spike can be taken as the canonical ordering since
goal sets are formed by a simple sweep through the spike at each successive layer. Stan
implements an improvement on the goal set memoization of Graphplan. In the original
Graphplan, when a goal set could not be achieved at a particular layer the entire set was
memoized as a bad set for that layer. In Stan version 2, only the subset of goals that
have been satisfied at the point of failure, within a layer, are actually memoized. More goal
sets are likely to contain the smaller memoized subset than would be likely to contain the
complete original failing goal set. This therefore allows us to prune search branches earlier.
This method is a weak version of Kambhampati's (1998, 1999) EBL (Explanation-Based
Learning) modifications. EBL allows the identification of the subset of a goal set that is
really responsible for its failure to yield a plan. Memoization of smaller sets increases the
eciency of the planner by reducing the overhead necessary in identifying failing goal sets.
DDB (Dependency-Directed Backtracking) improves the search performance by ensuring
that backtracking returns to the point at which the last choice responsible for failure was
made. These modifications result in smaller sets being memoized and a more ecient search
behaviour which, in combination with the trie, ensure that a higher proportion of failing
search paths are terminated early.
We have experimented with an implementation of the full EBL/DDB modifications
proposed by Kambhampati, but there is an interaction between the EBL/DDB machinery
and the wave front of Stan which we are currently attempting to resolve. Our experiments
so far indicate that both the wave front and EBL/DDB have significant beneficial impact
94

fiEfficient Implementation of the Plan Graph in STAN

on search, but not consistently across the same problems. We believe that we can enhance
the advantages of the wave front by full integration with EBL/DDB, but this remains to
be demonstrated.

2.3 A Worked Example

We now demonstrate the spike construction process in action on a simple blocks world example in which there are two blocks and two table positions. In the initial state, both blocks
are on the table, one in each of the two positions. Consequently there are no clear table
positions. The initial spike consists of a fact rank containing fact headers for the four facts
that describe the initial state. There is a single operator schema, puton(Block; To; From),
as follows:

puton(X,Y,Z)

Pre:
on(X,Z), clear(X), clear(Y)
Add:
on(X,Y), clear(Z)
Del:
on(X,Z), clear(Y)
The action rank is initially empty. On the first iteration of the loop the first action rank
is constructed by creating no-ops for every fact in the zeroth fact rank. Two further actions
are applicable and are enacted, and the facts on their addlists are used to create a new fact
rank. This results in the partially developed spike shown in Figure 2.
It can be observed from Figure 2 that, following enactment, the fact headers associated
with the newly added facts are incomplete, and although the new fact level and action level
packages have been allocated they do not yet contain any values. The new fact headers are
missing references to the no-ops that will be used to achieve them in the next action rank.
The new fact level packages are blank because their corresponding fact headers will have
no level information for rank 0.
After identification of mutex actions and mutex facts, the picture is as shown in Figure 3.
In the action level packages, the lists of mutex actions are given as lists of indices for the
sake of clarity. In fact they are lists of pointers to actions, in order to avoid the indirection
involved in the use of indices. None of the action pairs are temporarily mutex at rank 1
because all of the fact mutex vectors from rank 0 are zero-valued.

3. Empirical Results

In this section we present results demonstrating the eciency of the spike and vector representation of the plan graph used by Stan. We consider graph construction only in this
section { the eciency of search in Stan will be demonstrated in Section 4. We show the
eciency of graph construction in Stan by showing relative performance figures for Stan
and the competition version of Ipp in several of the competition domains and two further
standard bench mark domains. These are the Graphplan version of the Travelling Salesman
domain (Blum & Furst, 1997), which uses a complete graph and is referred to here as the
Complete-Graph Travelling Salesman domain, and the Ferry domain available in the PDDL
release.
We compare Stan with Ipp because, to the best of our knowledge, Ipp is the only
other fast Graphplan-based planner currently publicly available. We use the competition
95

fiLong & Fox

Fact Spike
name: on(a,t1)
index: 0
msk 10000000
noop: 0

Action Spike

(rank 0)
FMV: 0...0
AV:

name: on(b,t2)
index: 1
msk 01000000
noop: 1

name: clear(b)
index: 3
msk 00010000
noop: 3
name: on(a,b)
index: 4
msk 00001000
noop:

0...0

0...0

FMV: 0...0
AV:

name: clear(a)
index: 2
msk: 00100000
noop?: True
precs: 00100000
adds: 00100000
dels: 00000000

0...0

FMV: 0...0
AV:

Action Level Packages
(rank 1 - as yet
uninstantiated)

name: on(b,t2)
index: 1
msk: 01000000
noop?: True
precs: 01000000
adds: 01000000
dels: 00000000

FMV: 0...0
AV:

name: clear(a)
index: 2
msk 00100000
noop: 2

name: on(a,t1)
index: 0
msk: 10000000
noop?: True
precs: 10000000
adds: 10000000
dels: 00000000

Fact Level Packages

0...0

name: clear(b)
index: 3
msk: 00010000
noop?: True
precs: 00010000
adds: 00010000
dels: 00000000

name: clear(t1)
index: 5
msk 00000100
noop:

name: puton(a,b,t1)
index: 4

name: clear(t2)
index: 6
msk 00000010
noop:

msk: 00001000
noop?: False
precs: 10110000
adds: 11000000
dels: 10010000

name: on(b,a)
index: 7
msk 00000001
noop:

name: puton(b,a,t2)
index: 5
msk: 00000100
noop?: False
precs: 01110000
adds: 00000011
dels: 01100000

Figure 2: The spike after enactment of the rank 1 actions.

96

fiEfficient Implementation of the Plan Graph in STAN

Action Spike

Fact Spike

name: on(a,t1)
index: 0
msk 10000000
noop: 0
name: on(b,t2)
index: 1
msk 01000000
noop: 1
name: clear(a)
index: 2
msk 00100000
noop: 2
name: clear(b)
index: 3
msk 00010000
noop: 3
name: on(a,b)
index: 4
msk 00001000
noop:

name: on(a,t1)

Fact Level Packages
(ranks 0 and 1)

FMV: 0..0

00001000

AV: 0..0

10000000

index: 0
msk: 10000000
noop?: True
precs: 10000000
adds: 10000000
dels: 00000000

AMV: 00001000
MAs: 4

name: on(b,t2)
FMV: 0..0

00000100

AV: 0..0

01000000

FMV: 0..0

00000011

AV: 0..0

00100000

FMV: 0..0

00001000

AV: 0..0

00010000

index: 1
msk: 01000000
noop?: True
precs: 01000000
adds: 01000000
dels: 00000000

AMV: 00000100
MAs: 5

name: clear(a)
index: 2
msk: 00100000
noop?: True
precs: 00100000
adds: 00100000
dels: 00000000

AMV: 00000100
MAs: 5

name: clear(b)
index: 3
msk: 00010000
noop?: True
precs: 00010000
adds: 00010000
dels: 00000000

10000011

name: clear(t1)
index: 5
msk 00000100
noop:

00001000

name: clear(t2)
index: 6
msk 00000010
noop:

00001000

AMV: 00001000
MAs: 4

name: puton(a,b,t1)
index: 4

01000011

msk: 00001000
noop?: False
precs: 10110000
adds: 11000000
dels: 10010000

00100100
00000100

name: on(b,a)
index: 7
msk 00000001
noop:

Action Level Packages
(rank 1)

name: puton(b,a,t2)
index: 5
msk: 00000100
noop?: False
precs: 01110000
adds: 00000011
dels: 01100000

00101100
00000100

AMV: 10010100
MAs: 0,3,5

AMV: 01101000
MAs: 1,2,4

Figure 3: The spike at the end of the rank 1 construction phase.

97

fiLong & Fox

100000

33 3
3

10000

3
3

1000

100
100
IPP

3

1000

10000

STAN

100000

Figure 4: Graph construction in the logistics domain: Stan shows a constant factor improvement over the performance of Ipp.
1000

100

3

IPP
10

3

3

3
3

33
3
3

10

3

100
STAN

Figure 5: Graph construction in the Gripper domain.
98

1000

fiEfficient Implementation of the Plan Graph in STAN

version of Ipp because this is the most up to date version available from the Freiburg
webpage at the time of writing. In order to focus on the graph construction phase, and
eliminate the search phase from both planners, we have constructed versions of Stan and
Ipp which terminate once the graph has opened. We have removed from Stan all of the
unnecessary pre-processing, domain analysis and additional features that contribute to later
search eciency. However, since Ipp is designed to build one more layer before opening
than is strictly necessary, to include a dummy goal corresponding to the achievement of the
conjunction of the top level goal set, we make Stan build one extra layer too so that the
two systems are comparable. We have removed all of the meta-strategy control from Ipp,
forcing Ipp directly into its graph construction. It is possible that a more streamlined graph
constructor could be built from Ipp by elimination of further processing, but we observed,
during experimentation with Ipp, that pre-processing accounts for insignificant proportions
of the timings reported below. We are therefore confident that any further streamlining
would have minimal effects on our results. In order to compare Stan and Ipp accurately it
was necessary to modify the timing mechanisms to ensure that precisely the same elements
are timed. A Unix/Linux diff file is available at the Stan website, and in Online Appendix
1, for anyone interested in reconstructing the Ipp graph construction system we have used.
The domains and problems used, and our graph construction version of Stan, can also be
found at these locations.
All experiments reported in this paper were carried out on a P300 Linux PC, with
128Mb of RAM and 128Mb swap space. All of the timings in the data sets reported are in
milliseconds.
All the graphs are log-log scaled. This was necessary to combat the long scales caused by
very large timings associated with a few instances in each domain. The graphs show Ipp's
construction performance compared with Stan's construction performance measured on the
same problems in each of six domains. The straight line shows where equal performance
would be. Points above the line indicate superior performance by Stan and points below
the line indicate superior performance by Ipp. In all of the first five data sets, Stan clearly
out-performs Ipp. In the last data set (Figure 9), Ipp convincingly out-performs Stan and
we now consider a more detailed analysis of the characteristics of the domains and instances
which explain these data sets.
The first four data sets reveal a very similar performance. The points are broadly parallel to the equal performance line, indicating that Stan performs at a constant multiple
of the performance of Ipp. Despite the trend that these data sets reveal, occasional data
points deviate significantly from this behaviour. This reects the fact that different structures of particular problems exercise different components of the graph construction system.
Components include instantiation of operators, application of individual operator instances
and the corresponding extension of fact layers and checking and re-checking mutex relations
between facts and between actions. We observed that in some problem instances, 50 per
cent or more of the construction time was spent in action mutex checking, whilst in others
instantiation dominated. The density of permanent mutex relations between actions, and
the degree of persistence of temporary mutex relations between actions, are both very significant in determining eciency of performance. For example in problem 8 in the Mystery
domain, where 21 layers are constructed before the graph opens, only 9 per cent of the
action pairs were discarded as permanently mutex and, of the temporary mutex pairs, the
99

fiLong & Fox

100000

3
3

10000

3 3
3

1000
IPP

3

3

100
10

3

10

100

1000
STAN

10000

100000

Figure 6: Graph construction in the Mystery domain. Stan's performance in this domain
is consistently better than that of Ipp, but shows more marked variation revealing
that the benefits of the spike are problem-dependent.
100000

3

10000

3

3

3

33

3

IPP
1000
1000

10000
STAN

Figure 7: Graph construction in the Mprime domain.
100

100000

fiEfficient Implementation of the Plan Graph in STAN

1000

100

33
3
3
33
3

3
3
3

10
IPP
1

1

10

STAN

100

1000

Figure 8: Graph construction in the Ferry domain. Stan shows polynomially better graph
construction performance than Ipp.
average number of re-tests across the entire graph construction was over 7. The use of
the changedActs mechanism described in Section 2.1, to avoid retesting actions when their
precondition mutex relations had not changed from the previous layer, gave us a 50 per
cent improvement in performance and accounts for a more than 40 second advantage over
Ipp in the construction phase of this problem.
In other problems a much higher percentage of action pairs are permanently mutex,
allowing early elimination of many action pairs from further retesting. Where mutex relations are not highly persistent a similar elimination rate is possible. This allows much
faster construction for Stan. Ipp does not benefit in the same way, because it does not
distinguish between temporary and permanent mutex and does not try to identify which
pairs of actions should be retested.
In the Ferry domain, Figure 8, 7 layers are constructed to open the graph regardless
of instance size. Analysis reveals that approximately 25 per cent of action pairs are permanently mutex and the average persistence of temporary mutex relations is slightly more
than 2 layers. Since Ipp does not intelligently eliminate actions from retesting, the implication of this is that Ipp unnecessarily re-checks mutex relations for a polynomially increasing
number of pairs of actions. This explains the polynomial advantage obtained by Stan in
this domain.
The last data set shows a rather different pattern of performance from that of the
others. The Complete-Graph Travelling Salesman domain used to produce the data set for
Figure 9 is a simplified version, in which the graph is fully connected, of the well known
101

fiLong & Fox

1000

100

3

IPP
10

10

3

3

100
STAN

3

3

3

1000

Figure 9: Graph construction in the Complete-Graph Travelling Salesman domain. Stan
displays a polynomially deteriorating graph construction performance. This is
further discussed in the text.

NP-hard TSP. It is, in principle, eciently solvable. In Figure 9 Ipp's performance appears
to be polynomially better than that of Stan. Analysis of the graph structure built for
different instances reveals that, on all instance sizes, the graph opens at layer 3. In these
graphs an interesting pattern can be observed in the mutex relations between actions: the
vast majority of action pairs are mutex after their first application at layer 2 (because the
salesman can only ever be in one place). These mutex relations are considered, by both
Stan and Ipp, to be temporary although they in fact persist. The consequence is that both
Stan and Ipp retest all pairs at the next layer. Stan obtains no advantage from the use of
changedActs or the distinction between temporary and permanent mutex relations in this
domain. The number of mutex pairs to be checked increases quadratically with increase
in instance size, which is in line with Stan's performance. Ipp clearly pays much less for
this retesting, despite the fact that it does the same amount of work. This fact, together
with profiling of both systems, leads us to believe that the disadvantage suffered by Stan is
due to the overhead in supporting object member applications in its C++ implementation.
It is worth pointing out that in the Complete-Graph Travelling Salesman domain, as well
as in Gripper and Ferry, the construction time for both planners is under 1 second for all
instances tested so the discrepancies in performance in these three domains are insignificant
compared with the discrepancies measured in seconds (for large instances) in the other
domains.
102

fiEfficient Implementation of the Plan Graph in STAN

Fix Point

G1

Buffer

G

G2
G3
G4

G1

G5

G2

Figure 10: The wave front in Stan.

4. The Wave Front
When a layer is reached in which all of the top level goals are pairwise non-mutex Graphplanbased planners begin searching for a plan. If no plan can be found, new layers are constructed alternately with search until the fix point of the graph is reached. In Graphplan
and Ipp the graph continues to be explicitly constructed beyond the fix point, even though
the layers which can be built beyond this point are sterile (contain no new facts, actions or
mutex relations). Their construction is necessary to allow the conditions for achievement of
goal sets to be established, between the fix point and the current layer. However, this constitutes significant computational effort in copying existing structures and in unnecessary
searching of these duplicate structures. Instead of building these sterile layers explicitly,
Stan maintains a single layer, called the buffer, beyond the fix point together with a queue
of goal sets remaining to be considered. Each time a goal set is removed from this queue,
to be considered in the buffer, those goal sets it generates in the fix point layer, which have
103

fiLong & Fox

not been previously marked as unsolvable, are added to the queue. The goal sets in this
queue are considered in order, always for achievement in the buffer layer. Thus, rather
than constructing a new layer each time the top level goal set proves unsolvable, and then
reconsidering all of the same achievers in the new layer, the goal sets in the queue are simply
considered in the buffer layer. We call this mechanism a wave front because it pushes goal
sets forward from the fix point layer into the buffer, and then recedes to consider another
goal set from the fix point layer. The goal sets generated at the fix point, which join the
queue for propagation, are referred to as candidate goal sets. The wave front is depicted in
Figure 10. The underlying implementation of the plan graph remains based on the spike,
but the figure depicts the graph in the traditional way for simplicity.
In the picture, G represents the top level goal set and when it is used to initiate a plan
search from the buffer layer it generates the sequence of goal sets G1, G2 and G3 at the
fix point layer. Assuming that these all fail, the first set in this queue, G1, is propagated
forward to the buffer leading to the generation of goal sets G4 and G5 in the fix point layer.
These are added to the end of the queue and G2 will be the next goal set selected from the
queue to propagate forward.
In order to demonstrate that the wave front machinery maintains an appropriate behaviour there are three questions to be considered.
1. Is every goal set that would have been considered in the buffer layer, had the graph
been constructed explicitly, still considered using the wave front? This question concerns completeness of the search process.
2. Does every plan generated to achieve a goal set that is considered in the buffer layer
correspond to a plan that would have been generated had the graph been explicitly
constructed? This question concerns soundness.
3. The final question concerns whether the termination properties of Graphplan are
maintained.

Definition 12 A k-level goal tree for goal set G at layer n in a plan graph, GT , is a
general tree of depth k in which the nodes are goal sets and the parent-child relationship is
defined as follows. If the goal set x is in the tree at level i then the goal set y is a child of
x if y is a minimal goal set containing no mutex goal pairs such that achievement of y at
layer n , i , 1 in the plan graph enables the achievement of x at layer n , i in that graph.
We take the root to be at level 0 of the tree and the leaves to be at level k , 1.
k;G;n

Lemma 1 If n , k  FP then GT
point layer in the plan graph.

k;G;n

= GT

+1 ,

k;G;n

where FP is the number of the fix

Proof By definition of the fix point, all layers in a plan graph beyond the fix point contain

an exact replica of the information contained at the fix point layer. Since, by definition
of the goal tree, the parent-child relationship depends exclusively upon the relationship
between two consective layers in the plan graph, and layers cannot change after the fix
point, it follows that if x is the parent of y at some layer beyond the fix point then the
parent-child relationship between x and y must hold at any pair of consecutive layers beyond
the fix point. Further, no new parent-child relationships can arise beyond the fix point. The
104

fiEfficient Implementation of the Plan Graph in STAN

restriction that n , k  FP ensures that all layers in both goal trees lie in the region beyond
the fix point.

2
The completeness of Stan follows from the completeness of Graphplan provided that
all of the goal sets that would appear in the layer after the fix point in the explicit graph
arise as candidates to be considered in the buffer layer using the wave front. We now prove
that this condition is satisfied by first proving that the leaves of goal trees generated at
successive layers of a plan graph are all used to generate candidates in Stan. Since the goal
sets considered by Graphplan are always subsets of the leaves of goal trees it will be shown
that the completeness of Stan follows.

Theorem 1 Given a goal set, G, and a plan graph of n layers, containing no plan for G
of length n , 1, with fix point at layer FP (n > FP ), all of the leaves of GT ,
are
n

generated as candidates by Stan.

F P;G;n

Proof The proof is by induction on n, with base case n = FP + 1. In the base case the

result follows trivially because the only leaf in GT1
+1 is the top level goal set G and
this is generated as the initial candidate by Stan.
Suppose n > FP + 1. The inductive hypothesis states that all of the leaves of the tree
GT ,1,
,1 are generated as candidates by Stan. Since the plan graph constructed by
Stan is identical to that of Graphplan up to layer FP + 1, and all candidates are used to
initiate search from layer FP + 1, the leaves of GT ,
,1 will also be generated as goal
sets in layer FP by Stan. These goal sets are then used by Stan to construct candidates.
Stan will not generate multiple copies of candidates, but each new goal set will generate a
new candidate.
By Lemma 1, GT ,
= GT ,
are gener,1 , so that the leaves of GT ,
ated as candidates by Stan.
;G;F P

n

F P;G;n

n

n

F P;G;n

n

F P;G;n

F P;G;n

n

F P;G;n

2
The definition of goal trees captures precisely the relationship between goal sets and
the search paths considered by Graphplan. However, because Graphplan memoizes failed
goal sets it can prune parts of a goal tree as it regresses through the explicit plan graph
during search. Whenever a goal set contains a memoized goal set search terminates along
this branch and none of its children will be generated. It can now be seen that Graphplan
will generate at layer FP + 1 a subset of the leaves of GT ,
, when searching from
layer n with goal set G, whereas Theorem 1 demonstrates that Stan will construct all of
these leaves as candidates.
This argument might suggest that Stan engages in unnecessary search by generating
candidates that Graphplan can prune, using memos, in layers that are not constructed
explicitly by Stan. In fact, Stan generates no more candidates than Graphplan generates
goal sets at layer FP +1. Indeed, Stan achieves a dramatic reduction in search by exploiting
the correspondence between the goal trees generated at layers n and n , 1, demonstrated by
Lemma 1. Because of this correspondence there is no need to construct the layers between
FP + 1 and n explicitly, and undertake all of the concommitant search from those layers.
n

105

F P;G;n

fiLong & Fox

Layer 0

FP

FP+1

n-1

n

G1

L1
L2

G2

G

G3

Ln

L1

G1

L2

G2

G

G3

Ln

Figure 11: The sliding window of layers between FP + 1 and n.
Graphplan rebuilds the sliding window, shown in Figure 11, of layers between FP and n , 1
as layers FP + 1 through to n. Stan simply promotes the leaves of the tree, generated at
layer FP in GT ,
,1 , into layer FP + 1.
It is straightforward to show that the wave front maintains soundness. The search that
Graphplan performs generates a goal tree of goal sets, as defined in Definition 12. In the
example in Figure 10, the tree is rooted at G, with G1, G2 and G3 its children and G4 and
G5 the children of G1. It can be seen from the picture that the tree structure generated
by Graphplan, in which each successive layer would be embedded in a separate layer of the
explicitly constructed graph, appears in a spiral of related goal sets between the fix point
and buffer layers. All of the candidate goal sets lie in this same search tree and therefore no
additional goal sets are generated. Graphplan constructs the final plan by reading off the
sequence of action choices at each layer in the final graph. In Stan, the plan is obtained
by reading off the initial fragment of the plan in the same way, from the layers preceding
the fix point. The rest of the plan is extracted from the spiral. This extraction process
yields the same path of action choices from the top level goal set to the candidate goal set
as would be recorded explicitly in the Graphplan plan graph.
The only question remaining to be considered is whether the wave front has the same
termination properties as Graphplan. It can be seen that it does since, if no new unsolvable
goal sets are generated at the fix point, the queue will become empty and the planner
terminates. This corresponds exactly to the termination conditions of Graphplan.
A subtlety concerns the interaction between the wave front and the subset memoization
discussed in Section 2.2. In principle, subset memoization could cause the loss of all three of
the desired properties of the graph. The way that Stan generates candidate goal sets is by
n

F P;G;n

106

fiEfficient Implementation of the Plan Graph in STAN

simultaneously generating a candidate set whenever a goal set is memoized at the fix point.
If the candidate set and the memoized set are one and the same, then the memoization of
a subset of a goal set will lead to the propagation of only a subset of the actual candidate
goals into the buffer and soundness might be undermined. If we use subset memoization at
the wave front then the question arises whether sets that contain a memoized subset should
be propagated forward as candidates. If they are not, then completeness is potentially
lost, since there might be action sequences that could have been constructed following
propagation that will not now be found. If they are, then termination is potentially lost,
since the set that led to the construction of the memoized subset might itself be generated
as a candidate. This could happen, for example in Figure 10, if G1 is unsolvable at the fix
point but is generated again by consideration of a later candidate at the buffer.
To avoid these problems we have restored full subset memoization at the wave front.
An alternative solution, which we are currently exploring, is to separate the subsets of
goals memoized from the identification of the candidate sets. Both solutions avoid the loss
of soundness because candidates are constructed from entire goal sets rather than from
subsets. In the first solution, termination is preserved because memoizing full goal sets
ensures that repeated candidates can be correctly identified as they recur. In the second
solution, we would separately memoize candidates as they were generated to avoid repeated
generation, thereby maintaining termination. In both cases, completeness is preserved by
propagating goal-sets forward as new candidates provided only that they do not contain
previously encountered candidates as subsets. If a potential candidate is a superset of an
entire memoized candidate then it is correct not to propagate that potential candidate into
the buffer because if the memoized candidate cannot be solved at the buffer then no superset
of it can be solved there either.

5. Experimental Results
The results presented here use Stan version 2 (available at our website). We have performed
experiments comparing Stan with and without the wavefront in order to demonstrate the
advantages obtained by the use of the wave front. We have performed further experiments
to compare Stan with the competition version of Ipp. There are some minor discrepancies
in the timing mechanisms of these two systems. Stan measures elapsed time for the entire
execution, whereas Ipp measures user+system time for graph construction and search but
not for parsing of the problem domain and instance. On a single user machine as used for
these experiments the discrepancy is negligible.
The problem domains used in this section have been selected to emphasise the benefits
offered by the wave front. The important characteristic is that there should be an early
fix point relative to the length of plan as instances grow. In the comparisons with Ipp the
wave front accounts for the trends in performance, although Stan employs a range of other
mechanisms which give it some minor advantages. Amongst these is the Tim machinery,
which we have not decoupled as the problem domains used are the standard typed ones
so that no significant advantage is obtained from inferring type structures automatically.
Only the resource invariants inferred by Tim are exploited by Stan version 2, and we
have indicated where this gives us an advantage over Ipp. Our ablation data sets confirm
107

fiLong & Fox

100000

3

10000

3
3

1000
IPP

3

100
10

10

3

100

STAN

1000

10000

Figure 12: Stan compared with Ipp: solving Towers of Hanoi problems of 3-7 discs.
that the wave front is the most significant component in the performance of Stan in these
experiments.
Stan is capable of eciently solving larger Towers of Hanoi instances than are presented
in the graph in Figure 12, which accounts for the additional point in Figure 13. Stan with
the wave front found the 511-step plan for the 9-disc problem in less than 7 minutes using
about 15Mb of memory. During the experiments reported here, Ipp was terminated after
15 minutes having reached layer 179 out of 255 layers in the 8-disc problem. We observe
that on a machine with 1Gb of RAM, Ipp has solved this problem in 8 minutes.
The results for the Gripper domain demonstrate only a small advantage for Stan. The
reason is because the search space grows exponentially in the size of the graph in the Gripper
domain, so that the cost of searching dominates everything else. Although the search spaces
for Towers of Hanoi instances also grow exponentially, they grow as 2 whereas Gripper
instances grow as x (where x is the number of discs or balls respectively). Although the
wave front helps under these conditions, the size of the search space dwarfs the benefits it
offers. The Ferry domain is a less rapidly growing version of the gripper domain since only
one vehicle can be carried on each journey, reducing the number of choices at each layer.
The difference in benefits obtained in the Towers of Hanoi domain relative to the Gripper
and Ferry domains can be explained by consideration of the table in Figure 16. The benefits
of the wave front are proportional to the number of layers which exist implicitly between
the buffer and the layer from which the plan is ultimately found. In the Towers of Hanoi
the number of implicit layers is exponential in the number of discs whereas the number of
layers between the initial layer and the buffer is linear in the number of discs. Therefore
the benefits offered by the use of the wave front are magnified exponentially as the problem
x

x

108

fiEfficient Implementation of the Plan Graph in STAN

1e+06

3

100000

3
3

10000

3

1000
100

3

10
STAN no wf 10

3
100

1000
STAN wf

10000

100000

Figure 13: Stan with and without the wave front: solving Towers of Hanoi problems of 3-8
discs.
1e+06

3

100000

3

10000
1000

3

IPP 100
10

3
10

100

1000

STAN

10000

100000

1e+06

Figure 14: Stan compared with Ipp: solving Gripper problems of 4-10 balls.
109

fiLong & Fox

1e+06

3

100000

3

10000
1000
100
10
STAN no wf 10

3
3
100

1000
10000
STAN wf

100000

1e+06

Figure 15: Stan with and without the wave front: solving Gripper problems of 4-10 balls.
Domain
Towers of Hanoi
Gripper
Ferry
Complete-Graph TSP

Parameter n Plan Length Buffer
no. discs
2 ,1
n+3
no. balls
2n , 1
5
no. vehicles
4n , 1
7
no. cities
n
4
n

Figure 16: Relative values of plan length and number of layers to buffer for four domains.
instance grows. On the other hand, in both Gripper and Ferry there is only a linear growth
in the difference between plan length and fix point layer, so benefits are magnified only
linearly. This analysis can be confirmed by observation of Figures 12, 14 and 17.
The benefit of the wave front is measured not only in terms of the cost of construction
that is avoided by not explicitly building the layers beyond the buffer, but also in terms
of the search that is avoided in those layers. Crudely, the benefits can be measured as
the number of layers not constructed multiplied by the search effort avoided at each of
those layers. Thus, the number of layers not constructed magnifies the benefits obtained
by not searching amongst them. This is a simplification, since the search effort avoided at
successive layers increases as they get further away from the fix point, but it gives a guide
to the kind of benefits that can be expected from the wave front.
Stan obtains significant advantages over Ipp in the Complete-Graph Travelling Salesman domain, as Figure 19 demonstrates. Some of these advantages are obtained by ex110

fiEfficient Implementation of the Plan Graph in STAN

1e+06

3

100000

3

10000

3

1000

3
3

IPP 100
10

3
10

100

1000
STAN

10000

100000

Figure 17: Stan compared with Ipp: solving Ferry problems of 2-12 cars.
1e+06

3

100000

3

10000

3

1000

3

100
10
STAN no wf 10

3

3
100

1000
STAN with wf

10000

100000

Figure 18: Stan with and without the wave front: solving Ferry problems of 2-12 cars.
111

fiLong & Fox

1e+10

3

1e+09

3

1e+08

3

1e+07

3

1e+06

3

100000
IPP

10000

3

1000
100
100

1000
STAN

10000

Figure 19: Stan compared with Ipp: solving Complete-Graph Travelling Salesman problems of 10-20 cities.
ploiting the resource analysis techniques of Tim (Fox & Long, 1998), whilst a significant
proportion of the advantage is obtained from the use of the wave front, as Figure 20 shows.
Resource analysis allows a lower bound to be determined on the number of layers that must
be built in a plan graph before it is worth searching for a plan. In the Complete-Graph
Travelling Salesman domain this is very powerful, as the calculated bound is n, the number
of cities in the instance, which is precisely the correct plan length. In this domain, if no
search is done until n layers are constructed, no search needs to be done at all since it
doesn't matter in what order the cities are visited. This would allow the problem to be
solved in polynomial time (of course, this only makes sense because the Complete-Graph
TSP used here is simpler than the NP-hard TSP). However, when the wave front is used,
the buffer is at layer 4 and the only way of finding the plan is to generate all of the candidate
goal sets at layer 4, of which there are an exponential number. The use of the wave front
in this domain therefore forces Stan to take exponential time in the size of the instances.
Despite this the wave front offers great advantages. The benefits increase exponentially as
instance sizes grow although the magnification of these benefits at each layer is only linear,
see Figure 16, although the benefits are offset by the exponential growth in the number of
candidates. It must be observed that in Figure 19, the figures are extrapolated for Ipp for
instances in which n is greater than 14. The extrapolation was based on Ipp's performance
on instance sizes between 2 and 14, which demonstrates a clear exponential growth.
It appears that we could allow the resource analysis to over-ride the wave front when a
domain is encountered in which it can be guaranteed that explicit construction of the graph
112

fiEfficient Implementation of the Plan Graph in STAN

10000

3
3
3
3

1000

3
3
100
STAN no wf 100

1000
STAN with wf

10000

Figure 20: Stan with and without the wave front: solving Complete-Graph TSP problems.
will be more ecient. In practice the Complete-Graph Travelling Salesman domain seems
exceptional, since search is eliminated if the graph is constructed to layer n, and if this were
not the case the explicit construction and subsequent search would be more costly than the
use of the wave front.

5.1 The Wave Front Heuristic
The queue of candidate goal sets considered in the buffer can be implemented as an unordered structure in which goal sets are selected for consideration according to more sophisticated criteria than the order in which they were stored. In principle, this could save
much searching effort since it could avoid costly consideration of goal sets which turn out to
be unsolvable before meeting a solvable goal set. We have experimented with a number of
goal set selection heuristics which favour goal sets for which the search progresses deepest
into the graph structure. These sets are considered to be closer to being solvable than sets
which fail in a layer very close to the buffer. Candidates are evaluated by considering the
length of the plan fragment associated with the candidate and the extent to which the failed
search penetrated into the graph when initiated from the fix point layer when the candidate
was first generated. The search penetration should be maximized while the plan fragment
length should be minimized. Considering the goal sets in some order other than that in
which they are generated does not affect any of the formal properties of the planner other
than the optimality of the plans generated. Non-optimal plans can be favoured because
113

fiLong & Fox

1e+06

3

100000

3

10000

3
Stanh

1000
100
100

3 33

3
1000

10000

Stan

100000

1e+06

Figure 21: Towers of Hanoi with (Stanh) and without the heuristic: 3-9 discs.
the balance between fragment length and penetration can cause candidates with shorter
fragments to be overlooked.
Using the heuristic Stan is able to solve Towers of Hanoi problems very eciently, as
Figure 21 shows. As previously, the graph is log-log scaled. The line indicates at least a
polynomial improvement in the size of instances. The heuristic was originally developed by
consideration of blocks world problems, in which it also performs well. However, it does not
provide a reliable advantage so it is not used in Stan version 2. It was used on all problems
in the competition but often represented a heavy overhead for Stan. We are continuing to
experiment with alternative domain-independent evaluation criteria.

6. Conclusion
This paper presents two improvements on the representation of the plan graph exploited by
Graphplan-based planners. These are: the representation of the graph as a single pair of
layers, called a spike, built around bit vectors and logical operations, and the use of a wave
front which avoids the explicit construction of the graph beyond the fix point. We describe
a highly ecient procedure for checking mutex relations between actions and explain what
characteristics of problems allow its full exploitation. The spike and the wave front have
both been implemented in Stan, a Graphplan based planner version 11 of which competed
successfully in the AIPS-98 planning competition. We have presented empirical evidence
to support both improvements. The first set of data demonstrates the increase in graph
1. Version 1 contained implementations of both the spike and the wave front. Version 2 enhances both
of these mechanisms with improved implementation and the addition of the changedActs mechanism
discussion in Section 2.1.

114

fiEfficient Implementation of the Plan Graph in STAN

construction eciency obtained by the use of the spike. The second set of data shows the
advantages obtained during the search of the plan graph by using the wave front.
Stan also employs the state invariant inference machinery of Tim (Fox & Long, 1998),
but in version 2 the integration of the invariants into the graph construction process is
still only partial. We observe that the mutex relations generated in the Complete-Graph
TSP, in particular, are almost entirely domain invariants of the kind inferred by Tim.
Integration of these inferred invariants into the graph would allow these mutex relations
to be identified immediately as permanent and eliminate them from retesting, dramatically
enhancing Stan's graph construction performance in this domain. A similar advantage
would be obtained across other domains since many of the mutex relations inferred during
graph construction correspond to invariants of the various forms inferred eciently by Tim
during a preprocessing stage.

Appendix A. Website Addresses

Online Appendix 1 contains a complete collection of the domains and problems used in this
paper, executables (Linux and Sparc-Solaris binaries) for Stan and the reduced version of
Stan for graph construction, and a diff file showing how the graph constructing version of
IPP was generated.
The results of the AIPS-98 planning competition can be found at:
http://ftp.cs.yale.edu/pub/mcdermott/aipscomp-results.html.
The Stan website can be found at:
http://www.dur.ac.uk/dcs0www/research/stanstuff/planpage.html.

References

Blum, A., & Furst, M. (1997). Fast Planning through Planning Graph Analysis. Artificial
Intelligence, 90, 281{300.
Fox, M., & Long, D. (1998). The Automatic Inference of State Invariants in TIM. JAIR,
9, 317{371.
Kambhampati, S. (1998). EBL and DDB for Graphplan. Tech. rep. ASU CSE TR 98-008,
Arizona State University.
Kambhampati, S. (1999). On the Relations Between Intelligent Backtracking and Explanation Based Learning in Planning and CSP. Artificial Intelligence, 105 (1-2).
Koehler, J., Nebel, B., & Dimopoulos, Y. (1997). Extending Planning Graphs to an ADL
Subset. In Proceedings of 4th European Conference on Planning.
Smith, D., & Weld, D. (1998). Incremental Graphplan. Tech. rep. TR 98-09-06, University
of Washington.

115

fi