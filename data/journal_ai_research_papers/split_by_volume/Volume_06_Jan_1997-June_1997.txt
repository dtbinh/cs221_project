Journal of Artificial Intelligence Research 6 (1997) 147-176

Submitted 6/96; published 5/97

Query DAGs: A Practical Paradigm for Implementing
Belief-Network Inference
Adnan Darwiche

darwiche@aub.edu.lb

Department of Mathematics
American University of Beirut
PO Box 11 - 236, Beirut, Lebanon

Gregory Provan

provan@risc.rockwell.com

Rockwell Science Center
1049 Camino Dos Rios
Thousand Oaks, CA 91360

Abstract

We describe a new paradigm for implementing inference in belief networks, which consists of two steps: (1) compiling a belief network into an arithmetic expression called a
Query DAG (Q-DAG); and (2) answering queries using a simple evaluation algorithm.
Each node of a Q-DAG represents a numeric operation, a number, or a symbol for evidence. Each leaf node of a Q-DAG represents the answer to a network query, that is,
the probability of some event of interest. It appears that Q-DAGs can be generated using any of the standard algorithms for exact inference in belief networks | we show how
they can be generated using clustering and conditioning algorithms. The time and space
complexity of a Q-DAG generation algorithm is no worse than the time complexity of the
inference algorithm on which it is based. The complexity of a Q-DAG evaluation algorithm
is linear in the size of the Q-DAG, and such inference amounts to a standard evaluation of
the arithmetic expression it represents. The intended value of Q-DAGs is in reducing the
software and hardware resources required to utilize belief networks in on-line, real-world
applications. The proposed framework also facilitates the development of on-line inference
on different software and hardware platforms due to the simplicity of the Q-DAG evaluation
algorithm. Interestingly enough, Q-DAGs were found to serve other purposes: simple techniques for reducing Q-DAGs tend to subsume relatively complex optimization techniques
for belief-network inference, such as network-pruning and computation-caching.

1. Introduction
Consider designing a car to have a self-diagnostic system that can alert the driver to a range
of problems. Figure 1 shows a simplistic belief network that could provide a ranked set
of diagnoses for car troubleshooting, given input from sensors hooked up to the battery,
alternator, fuel-tank and oil-system.
The standard approach to building such a diagnostic system is to put this belief network,
along with inference code, onto the car's computer; see Figure 2. We have encountered a
number of diculties when using this approach to embody belief network technology in industrial applications. First, we were asked to provide the technology on multiple platforms.
For some applications, the technology had to be implemented in ADA to pass certain certification procedures. In others, it had to be implemented on domain-specific hardware that
only supports very primitive programming languages. Second, memory was limited to keep

c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiDarwiche & Provan

fuel sensor
fuel
battery

oil-pressure
battery sensor

fault

oil-pressure
sensor
alternator
alternator
sensor

Figure 1: A simple belief network for car diagnosis.
the cost of a unit below a certain threshold to maintain product profitability. The dilemma
was the following: belief network algorithms are not trivial to implement, especially when optimization is crucial, and porting these algorithms to multiple platforms and languages would
have been prohibitively expensive, time-consuming and demanding of qualified manpower.
To overcome these diculties, we have devised a very exible approach for implementing
belief network systems, which is based on the following observation. Almost all the work
performed by standard algorithms for belief networks is independent of the specific evidence
gathered about variables. For example, if we run an algorithm with the battery-sensor set
to low and then run it later with the variable set to dead, we find almost no algorithmic
difference between the two runs. That is, the algorithm will not branch differently on any
of the key decisions it makes, and the only difference between the two runs is the specific
arguments to the invoked numeric operations. Therefore, one can apply a standard inference
algorithm on a network with evidence being a parameter instead of being a specific value. The
result returned by the algorithm will then be an arithmetic expression with some parameters
that depend on specific evidence. This parameterized expression is what we call a Query
DAG, an example of which is shown in Figure 4.1
The approach we are proposing consists of two steps. First, given a belief network, a set
of variables about which evidence may be collected (evidence variables), and a set of variables for which we need to compute probability distributions (query variables), a Q-DAG
is compiled off-line, as shown in Figure 3. The compilation is typically done on a sophisticated software/hardware platform, using a traditional belief network inference algorithm in
conjunction with the Q-DAG compilation method. This part of the process is far and away
the most costly computationally. Second, an on-line system composed from the generated
Q-DAG and an evaluator specific to the given platform is used to evaluate the Q-DAG. Given
evidence, the parameterized arithmetic expression is evaluated in a straightforward manner
using simple arithmetic operations rather than complicated belief network inference. The
1. The sharing of subexpressions is what makes this a Directed Acyclic Graph instead of a tree.

148

fiA Practical Paradigm for Implementing Belief-Network Inference

Traditional Approach

Compiled Approach

Fault
Variables
Causal
Network

O
N
L
I
N
E

Sensor
Values

Causal Network
Inference
Software

Sensor
Variables

Q-DAG
Compiler

Query
DAG

Q-DAG
Evaluator

O
F
F
L
I
N
E

0
N
L
I
N
E

Fault
Probabilities

Figure 2: This figure compares the traditional approach to exact belief-network inference
(shown on the left) with our new compiled approach (shown on the right) in the
context of diagnostic reasoning. In the traditional approach, the belief network
and sensor values are used on-line to compute the probability distributions over
fault variables; in the compiled approach, the belief network, fault variables and
sensor variables are compiled off-line to produce a Q-DAG, which is then evaluated
on-line using sensor values to compute the required distributions.
computational work needed to perform this on-line evaluation is so straightforward that it
lends itself to easy implementations on different software and hardware platforms.
This approach shares some commonality with other methods that symbolically manipulate probability expressions, like SPI (Li & D'Ambrosio, 1994; Shachter, D'Ambrosio, &
del Favero, 1990); it differs from SPI on the objective of such manipulations and, hence,
on the results obtained. SPI explicates the notion of an arithmetic expression to state that
belief-network inference can be viewed as an expression-factoring operation. This allows
results from optimization theory to be utilized in belief-network inference. On the other
hand, we define an arithmetic expression to explicate and formalize the boundaries between
on-line and off-line inference, with the goal of identifying the minimal piece of software that
is required on-line. Our results are therefore oriented towards this purpose and they include:
(a) a formal definition of a Q-DAG and its evaluator; (b) a method for generating Q-DAGs
using standard inference algorithms | an algorithm need not subscribe to the inference-as149

fiDarwiche & Provan

Query Variables

Evidence Variables

Causal Network

Q-DAG Compiler
Off-line

On-line
Query DAG

Evidence

Q-DAG Evaluator

Figure 3: The proposed framework for implementing belief-network inference.

(a)

(b)

Pr(A=ON) = .3

Pr(B=OFF, c)

Pr(B=ON, c)

A

+

+

.56

.075

+

Pr(B=ON|a)

.14

.225

B

C

a

*

*

*

*

a

*

Pr(C=ON|a)

ON

.25

ON

.9

OFF

.8

OFF

.5

.9

*
.1

(C,ON)

+
*

*
.5

(C,OFF)

Figure 4: A belief network (a); and its corresponding Query-DAG (b). Here, C is an evidence
variable, and we are interested in the probability of variable B .
factoring view to be used for Q-DAG generation; and (c) computational guarantees on the
size of Q-DAGs in terms of the computational guarantees of the inference algorithm used
to generate them. Although the SPI framework is positioned to formulate related results, it
has not been pursued in this direction.
It is important to stress the following properties of the proposed approach. First, declaring an evidence variable in the compilation process does not mean that evidence must be
collected about that variable on-line|this is important because some evidence values, e.g.,
from sensors, may be lost in practice|it only means that evidence may be collected. Therefore, one can declare all variables to be evidence if one wishes. Second, a variable can be
declared to be both evidence and query. This allows one to perform value-of-information
150

fiA Practical Paradigm for Implementing Belief-Network Inference

computations to decide whether it is worth collecting evidence about a specific variable.
Third, the space complexity of a Q-DAG in terms of the number of evidence variables is no
worse than the time complexity of its underlying inference algorithm; therefore, this is not
a simple enumerate-all-possible-cases approach. Finally, the time and space complexity for
generating a Q-DAG is no worse than the time complexity of the standard belief-network
algorithm used in its generation. Therefore, if a network can be solved using a standard
inference algorithm, and if the time complexity of this algorithm is no worse than its space
complexity,2 then we can construct a Q-DAG for that network.
The following section explains the concept of a Q-DAG with a concrete example and
provides formal definitions. Section 3 is dedicated to the generation of Q-DAGs and their
computational complexity, showing that any standard belief-network inference algorithm
can be used to compile a Q-DAG as long as it meets some general conditions. Section 4
discusses the reduction of a Q-DAG after it has been generated, showing that such reduction
subsumes key optimizations that are typically implemented in belief network algorithms.
Section 5 contains a detailed example on the application of this framework to diagnostic
reasoning. Finally, Section 6 closes with some concluding remarks.

2. Query DAGs

This section starts our treatment of Q-DAGs with a concrete example. We will consider a
particular belief network, define a set of queries of interest, and then show a Q-DAG that
can be used to answer such queries. We will not discuss how the Q-DAG is generated; only
how it can be used. This will allow a concrete introduction to Q-DAGs and will help us
ground some of the formal definitions to follow.
The belief network we will consider is the one in Figure 4(a). The class of queries we
are interested in is Pr (B j C ), that is, the probability that variable B takes some value
given some known (or unknown) value of C . Figure 4(b) depicts a Q-DAG for answering
such queries, which is essentially a parameterized arithmetic expression where the values of
parameters depend on the evidence obtained. This Q-DAG will actually answer queries of
the form Pr (B; C ), but we can use normalization to compute Pr (B j C ).
First, a number of observations about the Q-DAG in Figure 4(b):
 The Q-DAG has two leaf nodes labeled Pr (B=ON ; c) and Pr (B=OFF ; c). These are
called query nodes because their values represent answers to the queries Pr (B=ON ; c)
and Pr (B=OFF ; c).
 The Q-DAG has two root nodes labeled (C; ON ) and (C; OFF ). These are called
Evidence Specific Nodes (ESNs) since their values depend on the evidence collected
about variable C on-line.
According to the semantics of Q-DAGs, the value of node (V; v ) is 1 if variable V is
observed to be v or is unknown, and 0 otherwise. Once the values of ESNs are determined,
we evaluate the remaining nodes of a Q-DAG using numeric multiplication and addition.
The numbers that get assigned to query nodes as a result of this evaluation are the answers
to queries represented by these nodes.
2. Algorithms based on join trees have this property.

151

fiDarwiche & Provan

.2725

.2875

.0925

Pr(B=OFF, c)

Pr(B=ON, c)

Pr(B=OFF, c)

.3475

Pr(B=ON, c)

+

+
.28

.2025

.07

*

*

*

*

.9

.0075

.28

*

*

.5

.1

+

+

.5

+

.9

0

.5

0

0

.1

*

*

*

*

*

*

(C,ON)

.5

.9

.1

0
(C,OFF)

0

(b)

.14

.225

+

.1

*

*

.56

.075

.07

.0225

.9

1

(a)

.14

.225

.56

.075

+

+

.0675

(C,ON)

0

.5

*

*
.5
1
(C,OFF)

Figure 5: Evaluating the Q-DAG in Figure 4 with respect to two pieces of evidence: (a)
C=ON and (b) C=OFF .
For example, suppose that the evidence we have is C = ON . Then ESN (C; ON ) is
evaluated to 1 and ESN (C; OFF ) is evaluated to 0. The Q-DAG in Figure 4(b) is then
evaluated as given in Figure 5(a), thus leading to
Pr (B=ON ; C=ON ) = :3475;

and

Pr (B=OFF ; C=ON ) = :2725;
from which we conclude that Pr (C = ON ) = :62. We can then compute the conditional
probabilities Pr (B=ON j C=ON ) and Pr (B=OFF j C=ON ) using:
Pr (B=ON j C=ON ) = Pr (B=ON ; C=ON )=Pr (C=ON );
Pr (B=OFF j C=ON ) = Pr (B=OFF ; C=ON )=Pr (C=ON ):
If the evidence we have is C=OFF , however, then (C; ON ) evaluates to 0 and (C; OFF )
evaluates to 1. The Q-DAG in Figure 4(b) will then be evaluated as given in Figure 5(b),
thus leading to
Pr (B=ON ; C=OFF ) = :2875;
and
Pr (B=OFF ; C=OFF ) = :0925:
We will use the following notation for denoting variables and their values. Variables
are denoted using uppercase letters, such as A; B; C , and variable values are denoted by
lowercase letters, such as a; b; c. Sets of variables are denoted by boldface uppercase letters,
such as A; B; C, and their instantiations are denoted by boldface lowercase letters, such as
a; b; c. We use E to denote the set of variables about which we have evidence. Therefore,
152

fiA Practical Paradigm for Implementing Belief-Network Inference

we use e to denote an instantiation of these variables that represents evidence. Finally, the
family of a variable is the set containing the variable and its parents in a directed acyclic
graph.
Following is the formal definition of a Q-DAG.

Definition 1 A Q-DAG is a tuple (V ; ; I ; D; Z ) where
1. V is a distinguished set of symbols (called evidence variables)
2.  is a symbol (called unknown value)
3. I maps each variable in V into a set of symbols (called variable values) different from
.
4. D is a directed acyclic graph where
- each non-root node is labeled with either + or 
- each root node is labeled with either
- a number in [0; 1] or
- a pair (V; v ) where V is an evidence variable and v is a value

5. Z is a distinguished set of nodes in D (called query nodes)

Evidence variables V correspond to network variables about which we expect to collect
evidence on-line. For example, in Figure 5, C is the evidence variable. Each one of these
variables has a set of possible values that are captured by the function I . For example, in
Figure 5, the evidence variable C has values ON and OFF . The special value  is used
when the value of a variable is not known. For example, we may have a sensor variable with
values \low," \medium," and \high," but then lose the sensor value during on-line reasoning.
In this case, we set the sensor value to .3 Query nodes are those representing answers to
user queries. For example, in Figure 5, B is the query variable, and leads to query nodes
Pr(B=ON ; c) and Pr(B=OFF ; c).
An important notion is that of evidence:

Definition 2 For a given Q-DAG (V ; ; I ; D; Z ), evidence is defined as a function E that
maps each variable V in V into the set of values I (V ) [ fg.
When a variable V is mapped into v 2 I (V ), then evidence tells us that V is instantiated to
value v . When V is mapped into , then evidence does not tell us anything about the value
of V .
We can now state formally how to evaluate a Q-DAG given some evidence. But first we
need some more notation:
1. Numeric-Node: n(p) denotes a node labeled with a number p 2 [0; 1];
2. ESN: n(V; v ) denotes a node labeled with (V; v );
3. This is also useful in cases where a variable will be measured only if its value of information justifies
that.

153

fiDarwiche & Provan

3. Operation-Node: n1 
 : : : 
 ni denotes a node labeled with  and having parents
n1 ; : : :; ni ;
4. Operation-Node: n1  : : :  ni denotes a node labeled with + and having parents
n1 ; : : :; ni .
The following definition tells us how to evaluate a Q-DAG by evaluating each of its nodes.
It is a recursive definition according to which the value assigned to a node is a function of
the values assigned to its parents. The first two cases are boundary conditions, assigning
values to root nodes. The last two cases are the recursive ones.
Definition 3 For a Q-DAG (V ; ; I ; D; Z ) and evidence E , the node evaluator is defined as
a function ME that maps each node in D into a number [0; 1] such that:
1. ME [n(p)] = p
(The value of a node labeled with a number is the number itself.)
(
E (V ) = v or E (V ) = ;
2. ME [n(V; v )] = 10;; ifotherwise
(The value of an evidence-specific node depends on the available evidence: it is 1 if v
is consistent with the evidence and 0 otherwise.)
3. ME [n1 
 : : : 
 ni ] = ME (n1)  : : :  ME (ni )
(The value of a node labeled with  is the product of the values of its parent nodes.)
4. ME [n1  : : :  ni ] = ME (n1) + : : : + ME (ni )
(The value of a node labeled with + is the sum of the values of its parent nodes.)
One is typically not interested in the values of all nodes in a Q-DAG since most of these
nodes represent intermediate results that are of no interest to the user. It is the query nodes
of a Q-DAG that represent answers to user queries and it is the values of these nodes that one
seeks when constructing a Q-DAG. The values of these queries are captured by the notion
of a Q-DAG output.
Definition 4 The node evaluator ME is extended to Q-DAGs as follows:
ME ((V ; ; I ; D; Z )) = f(n; ME (n)) j n 2 Zg:
The set ME ((V ; ; I ; D; Z )) is called the Q-DAG output.
This output is what one seeks from a Q-DAG. Each element in this output represents a
probabilistic query and its answer.
Let us consider a few evaluations of the Q-DAG shown in Figure 4, which are shown in
Figure 5. Given evidence E (C )= ON , and assuming that Qnode(B = ON ) and Qnode(B =
OFF ) stand for the Q-DAG nodes labeled Pr (B=ON ; c) and Pr (B=OFF ; c), respectively,
we have
ME [n(C; ON )] = 1;
ME [n(C; OFF )] = 0;
ME [Qnode(B=ON )] = :075  (:9  1 + :1  0) + :56  (1  :5 + :5  0) = :3475;
ME [Qnode(B=OFF )] = (:9  1 + :1  0)  :225 + (1  :5 + :5  0)  :14 = :2725;
154

fiA Practical Paradigm for Implementing Belief-Network Inference

meaning that Pr (B=ON ; C=ON ) = :3475 and Pr (B=OFF ; C=ON ) = :2725. If instead the
evidence were E (C )=OFF , a set of analogous computations can be done.
It is also possible that evidence tells us nothing about the value of variable C , that is,
E (C ) = . In this case, we would have

ME [n(C; ON )] = 1;
ME [n(C; OFF )] = 1;
ME [Qnode(B=ON )] = :075  (:9  1 + :1  1) + :56  (1  :5 + :5  1) = :635;
ME [Qnode(B=OFF )] = (:9  1 + :1  1)  :225 + (1  :5 + :5  1)  :14 = :365;
meaning that Pr (B=ON ) = :635 and Pr (B=OFF ) = :365.

2.1 Implementing a Q-DAG Evaluator

A Q-DAG evaluator can be implemented using an event-driven, forward propagation scheme.
Whenever the value of a Q-DAG node changes, one updates the value of its children, and so
on, until no possible update of values is possible. Another way to implement an evaluator
is using a backward propagation scheme where one starts from a query node and updates
its value by updating the values of its parent nodes. The specifics of the application will
typically determine which method (or combination) will be more appropriate.
It is important that we stress the level of refinement enjoyed by the Q-DAG propagation scheme and the implications of this on the eciency of query updates. Propagation in
Q-DAGs is done at the arithmetic-operation level, which is contrasted with propagation at
the message-operation level (used by many standard algorithms). Such propagation schemes
are typically optimized by keeping validity ags of messages so that only invalid messages
are recomputed when new evidence arrives. This will clearly avoid some unnecessary computations but can never avoid all unnecessary computations because a message is typically
too coarse for this purpose. For example, if only one entry in a message is invalid, the
whole message is considered invalid. Recomputing such a message will lead to many unnecessary computations. This problem will be avoided in Q-DAG propagation since validity
ags are attributed to arithmetic operations, which are the building blocks of message operations. Therefore, only the necessary arithmetic operations will be recomputed in a Q-DAG
propagation scheme, leading to a more detailed level of optimization.
We also stress that the process of evaluating and updating a Q-DAG is done outside of
probability theory and belief network inference. This makes the development of ecient online inference software accessible to a larger group of people who may lack strong backgrounds
in these areas.4

2.2 The Availability of Evidence

The construction of a Q-DAG requires the identification of query and evidence variables. This
may give an incorrect impression that we must know up front which variables are observed
and which are not. This could be problematic in (1) applications where one may lose a sensor
reading, thus changing the status of a variable from being observed to being unobserved;
4. In fact, it appears that a background in compiler theory may be more relevant to generating an ecient
evaluator than a background in belief network theory.

155

fiDarwiche & Provan

A

.3

.3

Pr(B=true|a)
.1
.8

true
false

Pr(B=true,b)

+

*

Pr(a)

a

B

Pr(A=true,b)

a
true

Pr(B=false,b)

+

Pr(A=false,b)

+

+

*

.1

*

.9

(B,true)

(B,false)

.8

*

.7

.2

Figure 6: A belief network and its corresponding Q-DAG in which variable B is declared to
be both query and evidence.
and (2) applications where some variable may be expensive to observe, leading to an on-line
decision on whether to observe it or not (using some value-of-information computation).
Both of these situations can be dealt with in a Q-DAG framework. First, as we mentioned
earlier, Q-DAGs allow us to handle missing evidence through the use of the  notation which
denotes an unknown value of a variable. Therefore, Q-DAGs can handle missing sensor
readings. Second, a variable can be declared to be both query and evidence. This means
that we can incorporate evidence about this variable when it is available, and also compute
the probability distribution of the variable in case evidence is not available. Figure 6 depicts a
Q-DAG in which variable A is declared to be a query variable, while variable B is declared to
be both an evidence and a query variable (both variables have true and false as their values).
In this case, we have two ESNs for variable B and also two query nodes (see Figure 6). This
Q-DAG can be used in two ways:
1. To compute the probability distributions of variables A and B when no evidence is
available about B . Under this situation, the values of n(B; true ) and n(B; false ) are
set to 1, and we have
Pr (A = true ) = :3  :1 + :3  :9 = :3
Pr (A = false ) = :8  :7 + :7  :2 = :7
Pr (B = true ) = :3  :1 + :8  :7 = :59
156

fiA Practical Paradigm for Implementing Belief-Network Inference

Pr (B = false ) = :3  :9 + :7  :2 = :41

2. To compute the probability of variable A when evidence is available about B . For
example, suppose that we observe B to be false . The value of n(B; true ) will then be
set to 0 and the value of n(B; false ) will be set to 1, and we have
Pr (A = true ; B = false ) = :3  :9 = :27
Pr (A = false ; B = false ) = :7  :2 = :14

The ability to declare a variable as both an evidence and a query variable seems to be
essential in applications where (1) a decision may need to be made on whether to collect
evidence about some variable B ; and (2) making the decision requires knowing the probability
distribution of variable B . For example, suppose that we are using the following formula
(Pearl, 1988, Page 313) to compute the utility of observing variable B :
X
Utility Of Observing (B ) = Pr(B = bje) U (B = b);
b

where U (B = b) is the utility for the decision maker of finding that variable B has value b.
Suppose that U (B = true ) = $2:5 and U (B = false ) = ,$3. We can use the Q-DAG to
compute the probability distribution of B and use it to evaluate Utility Of Observing (B ):
Utility Of Observing (B ) = ($2:5  :59) + (,$3  :41) = $0:24;

which leads us to observe variable B . Observing B , we find that its value is false . We can
then accommodate this evidence into the Q-DAG and continue with our analysis.

3. Generating Query DAGs

This section shows how Q-DAGs can be generated using traditional algorithms for exact
belief-network inference. In particular, we will show how Q-DAGs can be generated using the
clustering (join tree, Jensen, LS) algorithm (Jensen, Lauritzen, & Olesen, 1990; Shachter,
Andersen, & Szolovits, 1994; Shenoy & Shafer, 1986), the polytree algorithm, and cutset
conditioning (Pearl, 1988; Peot & Shachter, 1991). We will also outline properties that must
be satisfied by other belief network algorithms in order to adapt them for generating Q-DAGs
as we propose.

3.1 The Clustering Algorithm

We provide a sketch of the clustering algorithm in this section. Readers interested in more
details are referred to (Shachter et al., 1994; Jensen et al., 1990; Shenoy & Shafer, 1986).
According to the clustering method, we start by:
1. constructing a join tree of the given belief network;5
5. A join tree is a tree of clusters that satisfies the following property: the intersection of any two clusters
belongs to all clusters on the path connecting them.

157

fiDarwiche & Provan

2. assigning the matrix of each variable in the belief network to some cluster that contains
the variable's family.
The join tree is a secondary structure on which the inference algorithm operates. We need
the following notation to state this algorithm:
- S1; : : :; Sn are the clusters, where each cluster corresponds to a set of variables in the
original belief network.
- 	i is the potential function over cluster Si , which is a mapping from instantiations of
variables in Si into real numbers.
- Pi is the posterior probability distribution over cluster Si , which is a mapping from
instantiations of variables in Si into real numbers.
- Mij is the message sent from cluster Si to cluster Sj , which is a mapping from instantiations of variables in Si \ Sj into real numbers.
- e is the given evidence, that is, an instantiation of evidence variables E.
We also assume the standard multiplication and marginalization operations on potentials.
Our goal now is to compute the potential Pr (X; e) which maps each instantiation x of
variable X in the belief network into the probability Pr (x; e). Given this notation, we can
state the algorithm as follows:
 Potential functions are initialized using
Y
	i = Pr X X ;
X

where

{ X is a variable whose matrix is assigned to cluster Si;
{ Pr X is the matrix for variable X : a mapping from instantiations of the family of
X into conditional probabilities; and
{ X is the likelihood vector for variable X : X (x) is 1 if x is consistent with given

evidence e and 0 otherwise.
 Posterior distributions are computed using

Pi = 	i

Y
k

Mki ;

where Sk are the clusters adjacent to cluster Si .
 Messages are computed using
X Y
Mij =
	i Mki ;
Si nSj

k6=j

where Sk are the clusters adjacent to cluster Si .
158

fiA Practical Paradigm for Implementing Belief-Network Inference

 The potential Pr (X; e) is computed using
Pr (X; e) =

X
Si nfX g

Pi ;

where Si is a cluster to which X belongs.
These equations are used as follows. To compute the probability of a variable, we must
compute the posterior distribution of a cluster containing the variable. To compute the
posterior distribution of a cluster, we collect messages from neighboring clusters. A message
from cluster Si to Sj is computed by collecting messages from all clusters adjacent to Si
except for Sj .
This statement of the join tree algorithm is appropriate for situations where the evidence
is not changing frequently since it involves computing initial potentials each time the evidence
changes. This is not necessary in general and one can provide more optimized versions of the
algorithm. This issue, however, is irrelevant in the context of generating Q-DAGs because
updating probabilities in face of evidence changes will take place at the Q-DAG level, which
includes its own optimization technique that we discuss later.

3.2 Generating Q-DAGs

To generate Q-DAGs using the clustering method, we have to go through two steps. First,
we have to modify the initialization of potential functions so that the join tree is quantified
using Q-DAG nodes instead of numeric probabilities. Second, we have to replace numeric
addition and multiplication in the algorithm by analogous functions that operate on Q-DAG
nodes. In particular:
1. Numeric multiplication  is replaced by an operation 
 that takes Q-DAG nodes
n1; : : :; ni as arguments, constructs and returns a new node n with label  and parents
n1; : : :; ni .
2. Numeric addition + is replaced by an operation  that takes Q-DAG nodes n1 ; : : :; ni
as arguments, constructs and returns a new node n with label + and parents n1 ; : : :; ni.
Therefore, instead of numeric operations, we have Q-DAG-node constructors. And instead
of returning a number as a computation result, we now return a Q-DAG node.
Before we state the Q-DAG clustering algorithm, realize that we now do not have evidence
e, but instead we have a set of evidence variables E for which we will collect evidence.
Therefore, the Q-DAG algorithm will not compute an answer to a query Pr (x; e), but instead
will compute a Q-DAG node that evaluates to Pr (x; e) under the instantiation e of variables
E.
In the following equations, potentials are mappings from variable instantiations to QDAG nodes (instead of numbers). For example, the matrix for variable X will map each
instantiation of X 's family into a Q-DAG node n(p) instead of mapping it into the number
p. The Q-DAG operations 
 and  are extended to operate on these new potentials in the
same way that  and + are extended in the clustering algorithm.
The new set of equations is:
159

fiDarwiche & Provan

 Potential functions are initialized using
O
O
	i = n(Pr X ) 
 n(E );
X

E

where

{ X is a variable whose matrix is assigned to cluster Si;
{ n(Pr X ) is the Q-DAG matrix for X : a mapping from instantiations of X 's family

into Q-DAG nodes representing conditional probabilities;
{ E is an evidence variable whose matrix is assigned to cluster Si; and
{ n(E ) is the Q-DAG likelihood vector of variable E : n(E )(e) = n(E; e), which
means that node n(E )(e) evaluates to 1 if e is consistent with given evidence
and 0 otherwise.
 Posterior distributions are computed using
O
Pi = 	i Mki ;
k

where Sk are the clusters adjacent to cluster Si .
 Messages are computed using
M O
Mij =
	i Mki ;
Si nSj

k6=j

where Sk are the clusters adjacent to cluster Si .
 The Q-DAG nodes for answering queries of the form Pr (x; e) are computed using
M
Qnode(X ) =
Pi ;
Si nfX g

where Si is a cluster to which X belongs.
Here Qnode(X ) is a potential that maps each instantiation x of variable X into the Q-DAG
node Qnode(X )(x) which evaluates to Pr (x; e) for any given instantiation e of variables E.
Hence, the only modifications we made to the clustering algorithm are (a) changing
the initialization of potential functions and (b) replacing multiplication and addition with
Q-DAG constructors of multiplication and addition nodes.

3.3 An Example

We now show how the proposed Q-DAG algorithm can be used to generate a Q-DAG for
the belief network in Figure 4(a).
We have only one evidence variable in this example, C . And we are interested in generating a Q-DAG for answering queries about variable B , that is, queries of the form Pr (b; e).
Figure 7(a) shows the join tree for the belief network in Figure 4(a), where the tables contain
the potential functions needed for the probabilistic clustering algorithm. Figure 7(b) shows
160

fiA Practical Paradigm for Implementing Belief-Network Inference

S1

AC
A
ON
OFF

C=ON
.9
.5

2

(a)

AB

A
C=OFF
.1

S1

S2

AC
A

1

.5
A
ON
OFF

B=ON
.25 * .3
.8 * .7

B=OFF
.75 * .3
.2 * .7

AB

A
C=OFF

C=ON

ON

n(.9)

n(C,ON)

n(.1)

n(C,OFF)

OFF

n(.5)

n(C,ON)

n(.5)

n(C,OFF)

A
2

(b)

B=ON

S2

1

B=OFF

ON

n(.075)

n(.225)

OFF

n(.56)

n(.14)

Figure 7: A join tree quantified with numbers (a), and with Q-DAG nodes (b).
the join tree again, but the tables contain the potential functions needed by the Q-DAG
clustering algorithm. Note that the tables are filled with Q-DAGs instead of numbers.
We now apply the Q-DAG algorithm. To compute the Q-DAG nodes that will evaluate
to Pr (b; e), we must compute the posterior distribution P2 over cluster S2 since this is a
cluster to which variable B belongs. We can then sum the distribution over variable A to
obtain what we want. To compute the distribution P2 we must first compute the message
M12 from cluster S1 to cluster S2 .
The message M12 is computed by summing
M the potential function 	1 of cluster S1 over
all possible values of variable C , i.e., M12 = 	1 ; which leads to:
C

M12 (A=ON ) = [n(:9) 
 n(C; ON )]  [n(:1) 
 n(C; OFF )];
M12(A=OFF ) = [n(:5) 
 n(C; ON )]  [n(:5) 
 n(C; OFF )]:
The posterior distribution over cluster S2 , P2 , is computed using P2 = 	2 
 M12 ; which

leads to

P2 (A=ON ; B=ON ) = n(:075) 
 [[n(:9) 
 n(C; ON )]  [n(:1) 
 n(C; OFF )]]
P2(A=ON ; B=OFF ) = n(:225) 
 [[n(:9) 
 n(C; ON )]  [n(:1) 
 n(C; OFF )]]
P2(A=OFF ; B=ON ) = n(:56) 
 [[n(:5) 
 n(C; ON )]  [n(:5) 
 n(C; OFF )]]
P2(A=OFF ; B=OFF ) = n(:14) 
 [[n(:5) 
 n(C; ON )]  [n(:5) 
 n(C; OFF )]]:
The Q-DAG node Qnode(b) for answering queries M
of the form Pr (b; e) is computed by
summing the posterior P2 over variable A, Qnode =
P2 ; leading to
S nfB g
Qnode(B=ON ) = [n(:075) 
 [[n(:9) 
 n(C; ON )]  [n(:1) 
 n(C; OFF )]]] 
[n(:56) 
 [[n(:5) 
 n(C; ON )]  [n(:5) 
 n(C; OFF )]]]
Qnode(B=OFF ) = [n(:225) 
 [[n(:9) 
 n(C; ON )]  [n(:1) 
 n(C; OFF )]]] 
[n(:14) 
 [[n(:5) 
 n(C; ON )]  [n(:5) 
 n(C; OFF )]]];
2

161

fiDarwiche & Provan

which is the Q-DAG depicted in Figure 4(b). Therefore, the result of applying the algorithm
is two Q-DAG nodes, one will evaluate to Pr (B = ON ; e) and the other will evaluate to
Pr (B=OFF ; e) under any instantiation e of evidence variables E.

3.4 Computational Complexity of Q-DAG Generation

The computational complexity of the algorithm for generating Q-DAGs is determined by
the computational complexity of the clustering algorithm. In particular, the proposed algorithm applies a -operation precisely when the clustering algorithm applies an additionoperation. Similarly, it applies a 
-operation precisely when the clustering algorithm applies
a multiplication-operation. Therefore, if we assume that  and 
 take constant time, then
both algorithms have the same time complexity.
Each application of  or 
 ends up adding a new node to the Q-DAG. And this is the
only way a new node can be added to the Q-DAG. Moreover, the number of parents of each
added node is equal to the number of arguments that the corresponding arithmetic operation
is invoked on in the clustering algorithm. Therefore, the space complexity of a Q-DAG is
the same as the time complexity of the clustering algorithm.
In particular, this means that the space complexity of Q-DAGs in terms of the number
of evidence variables is the same as the time complexity of the clustering algorithm in those
terms. Moreover, each evidence variable E will add only m evidence-specific nodes to the
Q-DAG, where m is the number of values that variable E can take. This is important to
stress because without this complexity guarantee it may be hard to distinguish between the
proposed approach and a brute-force approach that builds a big table containing all possible
instantiations of evidence variables together with their corresponding distributions of query
variables.

3.5 Other Generation Algorithms

The polytree algorithm is a special case of the clustering algorithm as shown in (Shachter
et al., 1994). Therefore, the polytree algorithm can also be modified as suggested above
to compute Q-DAGs. This also means that cutset conditioning can be easily modified to
compute Q-DAGs: for each instantiation c of the cutset C, we compute a Q-DAG node for
Pr (x; c; e) using the polytree algorithm and then take the -sum of the resulting nodes.
Most algorithms for exact inference in belief networks can be adapted to generate QDAGs. In general, an algorithm must satisfy a key condition to be adaptable for computing
Q-DAGs as we suggested above. The condition is that the behavior of the algorithm should
never depend on the specific evidence obtained, but should only depend on the variables
about which evidence is collected. That is, whether variable E is instantiated to value v1
or value v2 should not affect the complexity of the algorithm. Only whether variable E is
instantiated or not should matter.
Most belief networks algorithms that we are aware of satisfy this property. The reason
for this seems to be the notion of probabilistic independence on which these algorithms
are based. Specifically, what is read from the topology of a belief network is a relation
I (X; Z; Y), stating that variables X and Y are independent given variables Z. That is,
Pr (x; y j z) = Pr (x j z)Pr (y j z)
162

fiA Practical Paradigm for Implementing Belief-Network Inference

for all instantiations x; y; z of these variables. It is possible, however, for this not to hold
for all instantiations of z but only for specific ones. Most standard algorithms we are aware
of do not take advantage of this instantiation{specific notion of independence.6 Therefore,
they cannot attach any computational significance to the specific value to which a variable
is instantiated. This property of existing algorithms is what makes them easily adaptable to
the generation of Q-DAGs.

3.6 Soundness of the Q-DAG Clustering Algorithm

The soundness of the proposed algorithm is stated below. The proof is given in Appendix A.

Theorem 1 Suppose that Qnode(X ) is a Q-DAG potential generated by the Q-DAG clustering algorithm for query variable X and evidence variables E. Let e0 be an instantiation
of some variables in E, and let Q-DAG evidence E be defined as follows:
(
if evidence e0 sets variable E to value e;
E (E ) = e;; otherwise.
then

ME (Qnode(X )(x)) = Pr (x; e0):

That is, the theorem guarantees that the Q-DAG nodes generated by the algorithm will
always evaluate to their corresponding probabilities under any partial or full instantiation
of evidence variables.

4. Reducing Query DAGs

This section is focused on reducing Q-DAGs after they have been generated. The main
motivation behind this reduction is twofold: faster evaluation of Q-DAGs and less space to
store them. Interestingly enough, we have observed that a few, simple reduction techniques
tend in certain cases to subsume optimization techniques that have been inuential in practical implementations of belief-network inference. Therefore, reducing Q-DAGs can be very
important practically.
This section is structured as follows. First, we start by discussing four simple reduction
operations in the form of rewrite rules. We then show examples in which these reductions subsume two key optimization techniques known as network-pruning and computation-caching.

4.1 Reductions

The goal of Q-DAG reduction is to reduce the size of a Q-DAG while maintaining the
arithmetic expression it represents. In describing the equivalence of arithmetic expressions,
we define the notion of Q-DAG equivalence:
Definition 5 Two Q-DAGs are equivalent iff they have the same set of evidence-specific
nodes and they have the same output for all possible Q-DAG evidence.
6. Some algorithms for two{level binary networks (BN20 networks), and some versions of the SPI algorithm
do take advantage of these independences.

163

fiDarwiche & Provan

Q

I

.

.

.
p

.

q
Q2

Q

p

.

+

Q1

*
Q1

Q3

*
Q2 Q 1

*

.

q

+

Q2

Q3

b) numeric
reduction

c) associative
merging

Q1

Q1
Q2

(a) Identity
elimination

Q3

Q3

d) commutative
merging

Figure 8: The four main methods for Q-DAG reduction.
Figure 8 shows four basic reduction operations that we have experimented with:
1. Identity elimination: eliminates a numeric node if it is an identity element of its child
operation node.
2. Numeric reduction: replaces an operation node with a numeric node if all its parents
are numeric nodes.
3. Associative merging: eliminates an operation node using operation associativity.
4. Commutative merging: eliminates an operation node using operation commutativity.
These rules can be applied successively and in different order until no more applications are
possible.
We have proven that these operations are sound in (Darwiche & Provan, 1995). Based
on an analysis of network structure and preliminary empirical results, we have observed
that many factors govern the effectives of these operations. The degree to which reduction
operations, numeric reduction in particular, can reduce the size of the Q-DAG depends on
the topology of the given belief network and the set of evidence and query variables. For
example, if all root nodes are evidence variables of the belief network, and if all leaf nodes
are query variables, then numeric reduction will lead to little Q-DAG reduction.
We now focus on numeric reduction, showing how it sometimes subsumes two optimization techniques that have been inuential in belief network algorithms. For both optimizations, we show examples where an unoptimized algorithm that employs numeric reduction
yields the same Q-DAG as an optimized algorithm. The major implication is that optimizations can be done uniformly at the Q-DAG level, freeing the underlying belief network
algorithms from such implementational complications.
The following examples assume that we are applying the polytree algorithm to singlyconnected networks.
164

fiA Practical Paradigm for Implementing Belief-Network Inference

A

a

P(a)

ON

.6

A
a

B

.9
.5

.6

a

B
ON
OFF

.8
.3

P(B=ON|a)
.9
.5

ON
OFF

P(C=ON|b)

b

(a)

P(a)

P(B=ON|a)

ON
OFF

C

a
ON

(b)

Figure 9: A simple belief network before pruning (a) and after pruning (b). The light-shaded
node, A, is a query node, and the dark-shaded node, B , is an evidence node.

P(A=ON,B=b)

P(A=ON,B=b)

*

*

+

(B,ON)

+

.8

.2

.1

+

(B,OFF)

.3

.6

*

*

*

*
.9

+

.6

.9

(B,ON)

(B,OFF)

.1

.7

(a) Original Q-DAG

(b) Reduced Q-DAG

Figure 10: A Q-DAG (a) and its reduction (b).

4.2 Network Pruning
Pruning is the process of deleting irrelevant parts of a belief network before invoking inference. Consider the network in Figure 9(a) for an example, where B is an evidence variable
and A is a query variable. One can prune node C from the network, leading to the network
in Figure 9(b). Any query of the form Pr (a j b) has the same value with respect to either
network. It should be clear that working with the smaller network is preferred. In general,
pruning can lead to dramatic savings since it can reduce a multiply-connected network to a
singly-connected one.
165

fiDarwiche & Provan

If we generate a Q-DAG for the network in Figure 9(a) using the polytree algorithm, we
obtain the one in Figure 10(a). This Q-DAG corresponds to the following expression,
X
X
Pr (A=ON ; e) = Pr (A=ON ) B (b)Pr (b j A=ON ) Pr (c j b):
c

b

If we generate a Q-DAG for the network in Figure 9(b), however, we obtain the one in
Figure 10(b) which corresponds to the following expression,
X
Pr (A=ON ; e) = Pr (A=ON ) B (b)Pr (b j A=ON ):
b

As expected, this Q-DAG is smaller than the Q-DAG in Figure 10(a), and contains a subset
of the nodes in Figure 10(a).
The key observation, however, is that the optimized Q-DAG in Figure 10(b) can be
obtained from the unoptimized one in Figure 10(a) using Q-DAG reduction. In particular,
the nodes enclosed in dotted lines can be collapsed using numeric reduction into a single
node with value 1. Identity elimination can then remove the resulting node, leading to the
optimized Q-DAG in Figure 10(b).
The more general observation, however, is that prunable nodes contribute identity elements when computing answers to queries. These contributions appear as Q-DAG nodes
that evaluate to identity elements under all instantiations of evidence. Such nodes can be
easily detected and collapsed into these identity elements using numeric reduction. Identity
elimination can then remove them from the Q-DAG, leading to the same effect as network
pruning.7 Whether Q-DAG reduction can replace all possible pruning operations is an open
question that is outside the scope of this paper.

4.3 Computation Caching

Caching computations is another inuential technique for optimizing inference in belief networks. To consider an example, suppose that we are applying the polytree algorithm to
compute Pr (c; b) in the network of Figure 11. Given evidence, say B =ON , the algorithm
will compute Pr (c; B = ON ) by passing the messages shown in Figure 12. If the evidence
changes to B=OFF , however, an algorithm employing caching will not recompute the message B (a) (which represents the causal support from A to B (Pearl, 1988)) since the value of
this message does not depend on the evidence on B .8 This kind of optimization is typically
7. Note, however, that Q-DAG reduction will not reduce the computational complexity of generating a QDAG, although network pruning may. For example, a multiply{connected network may become singlyconnected after pruning, thereby, reducing the complexity of generating a Q-DAG. But using Q-DAG
reduction, we still have to generate a Q-DAG by working with a multiply-connected network.
8. This can be seen by considering the following expression, which is evaluated incrementally by the polytree
algorithm through its message passes:
Pr (c; e) =

X
b

Pr (c j b) B (b)

|

X
a

Pr (b j a) Pr (a) :

{z

C (b)

| {z }
B a
}
( )

It is clear that the subexpression corresponding to the message B (a) from A to B is independent of the
evidence on B .

166

fiA Practical Paradigm for Implementing Belief-Network Inference

A
B
C

a

Pr(a)

ON

.6

a

Pr(B=ON|a)
.9
.5

ON
OFF

Pr(C=ON|b)

b

.8
.3

ON
OFF

Figure 11: A simple belief network for demonstrating the relationship between Q-DAG reduction and computation caching. The light-shaded node, C , is a query node,
and the dark-shaded node, B , is an evidence node.

A

 (a)
B
B

 (b)
C
C

Figure 12: Message passing when C is queried and B is observed.
implemented by caching the values of messages and by keeping track of which messages are
affected by what evidence.
Now, consider the Q-DAG corresponding to this problem which is shown in Figure 13(a).
The nodes enclosed in dotted lines correspond to the message from A to B .9 These nodes do
not have evidence-specific nodes in their ancestor set and, therefore, can never change values
due to evidence changes. In fact, numeric reduction will replace each one of these nodes and
its ancestors with a single node as shown in Figure 13(b).
In general, if numeric reduction is applied to a Q-DAG, one is guaranteed the following:
(a) if a Q-DAG node represents a message that does not depend on evidence, that node will
not be re-evaluated given evidence changes; and (b) numeric reduction will guarantee this
P Pr (b a)Pr (a).
9. More precisely, they correspond to the expression
a

167

j

fiDarwiche & Provan

P(C=ON,B=b)

P(C=ON,B=b)

+

+

*

.8

*
+

*

*

(B,ON)

*

.3

*

.74
+

(B,OFF)

*

(B,OFF)

(B,ON)

.3

*

.8

.26

*

*

*

*

cached value
.9

.6

.5

.4
.1

.6 .5

.4

(a) Original Q-DAG

(b) Reduced Q-DAG

Figure 13: A Q-DAG (a) and its reduction (b).
under any Q-DAG evaluation method since it will replace the node and its ancestor set with
a single root node.10

4.4 Optimization in Belief-Network Inference

Network pruning and computation caching have proven to be very inuential in practical
implementations of belief-network inference. In fact, our own experience has shown that
these optimizations typically make the difference between a usable and a non-usable beliefnetwork system.
One problem with these optimizations, however, is their algorithm-specific implementations although they are based on general principles (e.g., taking advantage of network
topology). Another problem is that they can make elegant algorithms complicated and hard
to understand. Moreover, these optimizations are often hard to define succinctly, and hence
are not well documented within the community.
In contrast, belief{network inference can be optimized by generating Q-DAGs using unoptimized inference algorithms, and then optimizing the generated Q-DAG through reduction techniques. We have shown some examples of this earlier with respect to pruning and
caching optimizations. However, whether this alternate approach to optimization is always
feasible is yet to be known. A positive answer will clearly provide an algorithm{independent
10. Note that Q-DAGs lead to a very refined caching mechanism if the Q-DAG evaluator (1) caches the value
of each Q-DAG node and (2) updates these cached values only when there is need to (that is, when the
value of a parent node changes). Such a refined mechanism allows caching the values of messages that
depend on evidence as well.

168

fiA Practical Paradigm for Implementing Belief-Network Inference

fuel sensor
fuel
battery

oil-pressure
battery sensor

fault

oil-pressure
sensor
alternator
alternator
sensor

Figure 14: A simple belief network for car diagnosis.
approach to optimizing belief{network inference, which is practically important for at least
two reasons. First, Q-DAG reduction techniques seem to be much simpler to understand
and implement since they deal with graphically represented arithmetic expressions, without
having to invoke probability or belief network theory. Second, reduction operations are applicable to Q-DAGs generated by any belief{network algorithm. Therefore, an optimization
approach based on Q-DAG reduction would be more systematic and accessible to a bigger
class of developers.

5. A Diagnosis Example
This section contains a comprehensive example illustrating the application of the Q-DAG
framework to diagnostic reasoning.
Consider the car troubleshooting example depicted in Figure 14. For this simple case
we want to determine the probability distribution for the fault node, given evidence on four
sensors: the battery-, alternator-, fuel- and oil-sensors. Each sensor provides information
about its corresponding system. The fault node defines five possible faults: normal, cloggedfuel-injector, dead-battery, short-circuit, and broken-fuel-pump.
If we denote the fault variable by F , and sensor variables by E, then we want to build
a system that can compute the probability Pr (f; e); for each fault f and any evidence e.
These probabilities represent an unnormalized probability distribution over the fault variable
given sensor readings. In a Q-DAG framework, realizing this diagnostic system involves three
steps: Q-DAG generation, reduction, and evaluation. The first two steps are accomplished
off-line, while the final step is performed on-line. We now discuss each one of the steps in
more detail.

5.1 Q-DAG Generation
The first step is to generate the Q-DAG. This is accomplished by applying the Q-DAG
clustering algorithm with the fault as a query variable and the sensors as evidence vari169

fiDarwiche & Provan

P(F=normal,e)

P(F=normal)
.90

P(F=pump)
.05

fuel
(normal)

P(F=pump,e)

fuel
subtree

(pump)

battery
(normal)

battery
(pump)

alternator
(normal)

oil
alternator
(pump)

(normal)

oil
(pump)

structure-sharing

Figure 15: A partial Q-DAG for the car example, displaying two of the five query nodes,
broken fuel pump and normal. The shaded regions are portions of the Q-DAG
that are shared by multiple query nodes; the values of these nodes are relevant
to the value of more than one query node.
ables. The resulting Q-DAG has five query nodes, Qnode(F = normal ; e), Qnode(F =
clogged fuel injector ; e), Qnode(F = dead battery ; e), Qnode(F = short circuit ; e), and
Qnode(F = broken fuel pump; e). Each node evaluates to the probability of the corresponding fault under any instantiation of evidence. The probabilities constitute a differential
diagnosis that tells us which fault is most probable given certain sensor values.
Figure 15 shows a stylized description of the Q-DAG restricted to two of the five query
nodes, corresponding to Pr (F = broken fuel pump ; e) and Pr (F = normal ; e). The Q-DAG
structure is symmetric for each fault value and sensor.
Given that the Q-DAG is symmetric for these possible faults, for clarity of exposition
we look at just the subset needed to evaluate node Pr (F = broken fuel pump ; e). Figure 16
shows a stylized version of the Q-DAG produced for this node. Following are some observations about this Q-DAG. First, there is an evidence-specific node for every instantiation
of sensor variables, corresponding to all forms of sensor measurements possible. Second, all
other roots of the Q-DAG are probabilities. Third, one of the five parents of the query node
Pr(F = broken fuel pump ; e) is for the prior on F = broken fuel pump , and the other four
are for the contributions of the four sensors. For example, Figure 16 highlights (in dots) that
part of the Q-DAG for computing the contribution of the battery sensor.

5.2 Q-DAG Reduction

After generating a Q-DAG, one proceeds by reducing it using graph rewrite rules. Figure 16
shows an example of such reduction with a Q-DAG that is restricted to one query node
for simplicity. To give an idea of the kind of reduction that has been applied, consider the
partial Q-DAG enclosed by dots in this figure. Figure 17 compares this reduced Q-DAG with
the unreduced one from which it was generated. Given our goal of generating Q-DAGs that
(a) can be evaluated as eciently as possible and (b) require minimal space to store, it is
170

fiA Practical Paradigm for Implementing Belief-Network Inference

KEY
F-S fuel-sensor
B-S battery-sensor
A-S alternator-sensor
O-S oil-sensor

P(F=pump,e)

*

+

P(F=pump)
.05

+

*

*

*

*

full)

+

*

*

*

*

.36 ESN(B-S, .64 ESN(A-S, .45 ESN(A-S, .55 ESN(O-S, .27 ESN(O-S,

.4 ESN(F-S, .6 ESN(B-S,

ESN(F-S,
empty)

+

dead)

charged)

not-OK)

OK)

low)

.73

normal)

Figure 16: A partial Q-DAG for the car example.
+
*

*

(a) Reduced Q-DAG
ESN(B-S,

.36 ESN(B-S, .64

dead)

charged)

+

(b) Original Q-DAG

+

+

*
ESN(B-S,

ESN(B-S,

*

charged)

dead)

P(B-S=charged| P(B=charged|
F=pump,B=charged) F=pump)
.8

*

*

.6

ESN(B-S,

*

charged)

P(B-S=dead|
P(B-S=charged|
P(B=charged|
F=pump,B=dead)
F=pump,B=charged) F=pump)
.2

.6

.4

*
*
P(B=dead|
F=pump)
.4

ESN(B-S,
dead)
P(B-S=dead|
F=pump,B=dead)
.6

*
P(B=dead|
F=pump)
.4

Figure 17: Reduced and unreduced Q-DAGs for the car diagnosis example.
important to see, even in a simple example, how Q-DAG reduction can make a big difference
in their size.
171

fiDarwiche & Provan

5.3 Q-DAG Evaluation

Now that we have a reduced Q-DAG, we can use it to compute answers to diagnostic queries.
This section presents examples of this evaluation with respect to the generated Q-DAG.
Suppose that we obtain the readings dead, normal, ok and full for the battery, oil,
alternator and fuel sensors, respectively. And let us compute the probability distribution
over the fault variable. This obtained evidence is formalized as follows:
- E (battery sensor ) = dead ,
- E (oil sensor ) = normal ,
- E (alternator sensor ) = ok ,
- E (fuel sensor ) = full .
Evidence-specific nodes can now be evaluated according to Definition 3. For example, we
have
ME [n(battery sensor ; charged)] = 0;
and
ME [n(battery sensor ; dead )] = 1:
The evaluation of evidence-specific nodes is shown pictorially in Figure 18(a). Definition 3
can then be used to evaluate the remaining nodes: once the values of a node's parents
are known, the value of that node can be determined. Figure 18(b) depicts the results of
evaluating other nodes. The result of interest here is the probability 0.00434 assigned to the
query node Pr (fault = broken fuel pump ; e).
Suppose now that evidence has changed so that the value of fuel sensor is empty instead
of full. To update the probability assigned to node Pr (fault = broken fuel pump ; e), a brute
force method will re-evaluate the whole Q-DAG. However, if a forward propagation scheme
is used to implement the node evaluator, then only four nodes need to be re-evaluated in
Figure 18(b) (those enclosed in circles) instead of thirteen (the total number of nodes). We
stress this point because this refined updating scheme, which is easy to implement in this
framework, is much harder to achieve when one attempts to embed it in standard beliefnetwork algorithms based on message passing.

6. Concluding Remarks

We have introduced a new paradigm for implementing belief-network inference that is oriented towards real-world, on-line applications. The proposed framework utilizes knowledge
of query and evidence variables in an application to compile a belief network into an arithmetic expression called a Query DAG (Q-DAG). Each node of a Q-DAG represents a numeric
operation, a number, or a symbol that depends on available evidence. Each leaf node of a
Q-DAG represents the answer to a network query, that is, the probability of some event of
interest. Inference on Q-DAGs is linear in their size and amounts to a standard evaluation
of the arithmetic expressions they represent.
A most important point to stress about the work reported here is that it is not proposing
a new algorithm for belief-network inference. What we are proposing is a paradigm for
172

fiA Practical Paradigm for Implementing Belief-Network Inference

Pr(F=pump,e)
(a) Evaluating ESNs

*

+

.05
Pr(F=pump)

+

*
0

*
1

.4

ESN(F-S,
empty)

+

*

*

1

.6

*

.36 0

ESN(B-S,
dead)

ESN(F-S,
full)

+

.64

ESN(B-S,
charged)

0

*

*

.45 1

ESN(A-S,
not-OK)

.55

ESN(A-S,
OK)

*
.27

0

ESN(O-S,
low)

1

ESN(O-S,
normal)

.73

ESN values

.0043362

Pr(F=pump,e)
(b) Propagating probabilities

*

0 *
0
ESN(F-S,
empty)

+ .36

+ .6

.05
Pr(F=pump)

* .36

.6 *
.4

1
ESN(F-S,
full)

.6

1
ESN(B-S,
dead)

+ .55

0*

.36 0
ESN(B-S,
charged)

*0
.64

0
ESN(A-S,
not-OK)

+ .73

.55*
.45 1
ESN(A-S,
OK)

* 0
.55

0

ESN(O-S,
low)

.73 *

.27

1

ESN(O-S,
normal)

.73

ESN values

Figure 18: Evaluating the Q-DAG for the car diagnosis example given evidence for sensors.
The bar in (a) indicates the instantiation of the ESNs. The shaded numbers in
(b) indicate probability values that are computed by the node evaluator. The
circled operations on the left-hand-side of (b) are the only ones that need to be
updated if evidence for the fuel-system sensor is altered, as denoted by the circled
ESNs.

173

fiDarwiche & Provan

implementing belief-network inference that is orthogonal to standard inference algorithms
and is engineered to meet the demands of real-world, on-line applications. This class of
applications is typically demanding for the following reasons:
1. It typically requires very short response time, i.e., milliseconds.
2. It requires software to be written in specialized languages, such as ADA, C++, and
assembly before it can pass certification procedures.
3. It imposes severe restrictions on the available software and hardware resources in order
to keep the cost of a \unit" (such as an electromechanical device) as low as possible.
To address these real-world constraints, we are proposing that one compile a belief network
into a Q-DAG as shown in Figure 3 on and use a Q-DAG evaluator for on-line reasoning. This
brings down the required memory to that needed for storing a Q-DAG and its evaluator. It
also brings down the required software to that needed for implementing a Q-DAG evaluator,
which is very simple as we have seen earlier.
Our proposed approach still requires a belief-network algorithm to generate a Q-DAG,
but it makes the eciency of such an algorithm less of a critical factor.11 For example,
we show that some standard optimizations in belief-network inference, such as pruning and
caching, become less critical in a Q-DAG framework since these optimizations tend to be
subsumed by simple Q-DAG reduction techniques, such as numeric reduction.
The work reported in this paper can be extended in at least two ways. First, further QDAG reduction techniques could be explored, some oriented towards reducing the evaluation
time of Q-DAGs, others towards minimizing the memory needed to store them. Second, we
have shown that some optimization techniques that dramatically improve belief-network
algorithms may become irrelevant to the size of Q-DAGs if Q-DAG reduction is employed.
Further investigation is needed to prove formal results and guarantees on the effectiveness
of Q-DAG reduction.
We close this section by noting that the framework we proposed is also applicable to
order-of-magnitude (OMP) belief networks, where multiplication and addition get replaced
by addition and minimization, respectively (Goldszmidt, 1992; Darwiche & Goldszmidt,
1994). The OMP Q-DAG evaluator, however, is much more ecient than its probabilistic
counterpart since one may evaluate a minimization node without having to evaluate all its
parents in many cases. This can make considerable difference in the performance of a Q-DAG
evaluator.

Acknowledgements
Most of the work in this paper was carried out while the first author was at Rockwell Science
Center. Special thanks to Jack Breese, Bruce D'Ambrosio and to the anonymous reviewers
for their useful comments on earlier drafts of this paper.
11. We have shown how clustering and conditioning algorithms can be used for Q-DAG generation, but other
algorithms such as SPI (Li & D'Ambrosio, 1994; Shachter et al., 1990) can be used as well.

174

fiA Practical Paradigm for Implementing Belief-Network Inference

Appendix A. Proof of Theorem 1

Without loss of generality, we assume in this proof that all variables are declared as evidence
variables. To prove this soundness theorem, all we need to show is that each Q-DAG potential will evaluate to its corresponding probabilistic potential under all possible evidence.
Formally, for any cluster S and variables X , the matrices of which are assigned to S , we
need to show that
O
Y
ME ( n(Pr X ) 
 n(X )) = Pr X X
(1)
X

X

for a given evidence E . Once we establish this, we are guaranteed that Qnode(X )(x) will
evaluate to the probability Pr (x; e) because the application of 
 and  in the Q-DAG algorithm is isomorphic to the application of  and + in the probabilistic algorithm, respectively.
To prove Equation 1, we will extend the Q-DAG node evaluator ME to mappings in the
standard way. That is, if f is a mapping from instantiations to Q-DAG nodes, then ME (f )
is defined as follows:
ME (f )(x) =def ME (f (x)):
That is, we simply apply the Q-DAG node evaluator to the range of mapping f .
Note that ME (f 
 g ) will then be equal to ME (f )ME (g ). Therefore,
O
ME ( n(Pr X ) 
 n(X ))
XY
=
ME (n(Pr X ))ME (n(X ))
X
Y
=
Pr X ME (n(X )) by definition of n(Pr X ):
X

Note also that by definition of n(X ), we have that n(X )(x) equals n(X; x). Therefore,
ME (n(X ))(x) = ME (n(X )(x))
= M
( E (n(X; x))
1; if E (X ) = x or E (X ) = 
=
0; otherwise
= X (x):
Therefore,
O
Y
ME ( n(Pr X ) 
 n(X )) = Pr X X :
X

X

References

Darwiche, A., & Goldszmidt, M. (1994). On the relation between kappa calculus and probabilistic reasoning. In Proceedings of the Tenth Conference on Uncertainty in Artificial
Intelligence (UAI), pp. 145{153.
Darwiche, A., & Provan, G. (1995). Query DAGs: A practical paradigm for implementing
on-line causal-network inference. Tech. rep. 95-86, Rockwell Science Center, Thousand
Oaks, CA.
175

fiDarwiche & Provan

Goldszmidt, M. (1992). Qualitative probabilities: A normative framework for commonsense
reasoning. Tech. rep. R-190, University of California at Los Angeles, Ph.D. thesis.
Jensen, F. V., Lauritzen, S., & Olesen, K. (1990). Bayesian updating in recursive graphical
models by local computation. Computational Statistics Quarterly, 4, 269{282.
Li, Z., & D'Ambrosio, B. (1994). Ecient Inference in Bayes Networks as a Combinatorial
Optimization Problem. International Journal of Approximate Reasoning, 11, 55{81.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Peot, M. A., & Shachter, R. D. (1991). Fusion and propagation with multiple observations
in belief networks. Artificial Intelligence, 48 (3), 299{318.
Shachter, R., Andersen, S., & Szolovits, P. (1994). Global Conditioning for Probabilistic
Inference in Belief Networks. In Proc. Tenth Conference on Uncertainty in AI, pp.
514{522 Seattle WA.
Shachter, R., D'Ambrosio, B., & del Favero, B. (1990). Symbolic Probabilistic Inference in
Belief Networks. In Proc. Conf. on Uncertainty in AI, pp. 126{131.
Shenoy, P. P., & Shafer, G. (1986). Propagating belief functions with local computations.
IEEE Expert, 1 (3), 43{52.

176

fiJournal of Artificial Intelligence Research 6 (1997) 211-221

Submitted 12/96; published 6/97

Research Note

A Complete Classification of Tractability in RCC-5

Peter Jonsson
Thomas Drakengren

Department of Computer and Information Science, Linkoping University
S-581 83 Linkoping, Sweden

petej@ida.liu.se
thodr@ida.liu.se

Abstract

We investigate the computational properties of the spatial algebra RCC-5 which is a restricted
version of the RCC framework for spatial reasoning. The satisfiability problem for RCC-5 is known
to be NP-complete but not much is known about its approximately four billion subclasses. We
provide a complete classification of satisfiability for all these subclasses into polynomial and NPcomplete respectively. In the process, we identify all maximal tractable subalgebras which are four
in total.

1. Introduction

Qualitative spatial reasoning has received a constantly increasing amount of interest in the literature.
The main reason for this is, probably, that spatial reasoning has proved to be applicable to realworld problems in, for example, geographical database systems (Egenhofer, 1991; Grigni, Papadias,
& Papadimitriou, 1995) and molecular biology (Cui, 1994). In both these applications, the size of
the problem instances can be huge, so the complexity of problems and algorithms is a highly relevant
area to study. However, questions of computational complexity have not received so much attention
in the literature; two notable exceptions are the results reported by Nebel (1995) and Renz and
Nebel (1997). In this article we take a small step towards a better understanding of complexity
issues in qualitative spatial reasoning.
A well-known framework for qualitative spatial reasoning is the so-called RCC approach (Randell
& Cohn, 1989; Randell, Cui, & Cohn, 1992). This approach is based on modelling qualitative spatial
relations between regions using first-order logic. Of special interest, from a complexity-theoretic
standpoint, are the two subclasses RCC-5 and RCC-8. It is well-known that both RCC-5 and
RCC-8 have quite weak expressive power. Although they can be used to describe spatial situations,
they are very general and should perhaps better be described as topological algebras. However, we
will denote these algebras as spatial algebras in order to avoid terminological confusion; the term
topological algebra has a well-established but completely different meaning in mathematics (Mallios,
1986).
Bennett (1994) has shown the suciency of using propositional logics for reasoning about RCC5 and RCC-8. Hence, the reasoning becomes more ecient when compared to reasoning in a full
first-order logic. Bennett's approach uses classical propositional logic for RCC-5 and intuitionistic
propositional logic for RCC-8. Unfortunately, these logics are known to be computationally hard.
The satisfiability problem for classical propositional logic and intuitionistic propositional logic is NPcomplete (Cook, 1971) and Pspace-complete (Statman, 1979) respectively. However, the complexity
of the underlying logic does not carry over in both cases; Renz and Nebel (1997) have shown that
the satisfiability problem for both RCC-5 and RCC-8 is NP-complete. The full proofs can be found
in (Renz, 1996).
These findings motivate the search for tractable subclasses of RCC-5 and RCC-8. Nebel (1995)
showed that reasoning with the basic relations in RCC-8 is a polynomial-time problem. Renz and
Nebel (1997) improved this result substantially by showing the following results:

c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiJonsson & Drakengren

 There exists a large, maximal subclass of RCC-8, denoted Hb8, which contains all basic relations
and is polynomial. Hb8 contains 148 elements out of 256 (58%).
 There exists a large, maximal subclass of RCC-5, denoted Hb5, which contains all basic relations
and is polynomial. Hb5 contains 28 elements out of 32 (87%). Furthermore, this is the unique,
maximal subclass of RCC-5 containing all basic relations.

We will concentrate on RCC-5 in this article. The main result is a complete classification of all
subclasses of RCC-5 with respect to tractability. The classification makes it possible to determine
whether a given subclass is tractable or not by a simple test that can be carried out by hand or
automatically. We have thus gained a clear picture of the tractability borderline in RCC-5. As is
more or less necessary when showing results of this kind, the main proof relies on a case analysis
performed by a computer. The number of cases considered was roughly 4  104 . The analysis cannot,
of course, be reproduced in a research paper or be verified manually. Hence, we include a description
of the programs used. The programs are also available as an on-line appendix to this article.
The structure of the article is as follows: Section 2 defines RCC-5 and some auxiliary concepts.
Section 3 contains the tractability proofs for three subclasses of RCC-5. In Section 4 we show that
these subclasses together with Hb5 are the only maximal tractable subclasses of RCC-5. The article
concludes with a brief discussion of the results.

2. The RCC-5 Algebra

We follow Bennett (1994) in our definition of RCC-5. RCC-5 is based on the notions of regions and
binary relations on them. A region p is a variable interpreted over the non-empty subsets of some
fixed set. It should be noted that we do not require the sets to be open sets in some topological
space. This is no limitation since it is impossible to distinguish interior points from boundary points
in RCC-5. Thus we can take any set X and use the discrete topology T = hX ; 2X i, where every
subset of X is an open set in T .
We assume that we have a fixed universe of variable names for regions. Then, an R-interpretation
is a function that maps region variables to the non-empty subsets of some set.
Given two interpreted regions, their relation can be described by exactly one of the elements of
the set B of five basic RCC-5 relations. The definition of these relations can be found in Table 1.
Figure 1 shows 2-dimensional examples of the relations in RCC-5. A formula of the form XBY where
X and Y are regions and B 2 B, is said to be satisfied by an R-interpretation iff the interpretation
of the regions satisfies the relations specified in Table 1.
To express indefinite information, unions of the basic relations are used, written as sets of basic
relations, leading to 25 binary RCC-5 relations. Naturally, a set of basic relations is to be interpreted
as a disjunction of the basic relations. The set of all RCC-5 relations 2B is denoted by R5. Relations
of special interest are the null relation ? (also denoted by ?) and the universal relation B (also
denoted >).
A formula of the form X fB1 ; : : :; B gY is called an RCC-5 formula. Such a formula is satisfied
by an R-interpretation = iff XB Y is satisfied by = for some i, 1  i  n. A finite set  of RCC-5
formulae is said to be R-satisfiable iff there exists an R-interpretation = that satisfies every formula
of . Such a satisfying R-interpretation is called an R-model of . Given an R-interpretation =
and a variable v, we write =(v) to denote the value of v under the interpretation =.
The reasoning problem we will study is the following:
n

i

: A finite set  of RCC-5 formulae.
: Does there exist an R-model of ?

Instance
Question

212

fiA Complete Classification of Tractability in RCC-5

X fDRgY
X fPOgY
X fPPgY
X fPPIgY
X fEQgY

iff X \ Y = ?
iff 9a; b; c : a 2 X; a 62 Y; b 2 X; b 2 Y; c 62 X; c 2 Y
iff X  Y
iff X  Y
iff X = Y
Table 1: The five basic relations of RCC-5.

X

X

Y

Y

(X; Y )

DR

(X; Y )

PO

X Y

PP

(X; Y )

Y X

PPI

(X; Y )

X Y
(X; Y )

EQ

Figure 1: Pictorial example of the relations in RCC-5.
We denote this problem by RSAT. In the following, we often consider restricted versions of RSAT
where the relations used in formulae in  are only from a subset S of R5. In this case we say that 
is a set of formulae over S and we use a parameter in the problem description to denote the subclass
under consideration, e.g., RSAT(S ). Note that an RSAT problem instance can be represented by a
labelled directed graph, where the nodes are region variables and the arcs are labelled by relations
between variables. Given an instance  of RSAT, we say that such a graph is a graph representation
of .
We continue by defining an algebra over the RCC-5 relations.

Definition 2.1 Let B = fDR; PO; PP; PPI; EQg. The RCC-5 algebra consists of the set R5 = 2B
and the operations unary converse (denoted by ), binary intersection (denoted by \) and binary
composition (denoted by ). They are defined as follows:
8X; Y :
XR Y iff Y RX
8X; Y : X (R \ S )Y iff XRY ^ XSY
8X; Y : X (R  S )Y iff 9Z : (XRZ ^ ZSY )
If S is a subset of R5 , S is said to be a subalgebra of RCC-5
S iff S is closed under converse, intersection
and composition. It can easily be verified that R  S = fB  B 0 jB 2 R; B 0 2 S g, i.e., composition
^

^

is the union of the component-wise composition of basic relations.
Next, we introduce a closure operation. The closure operation transforms a given subclass of
R5 to one that is polynomially equivalent to the original subclass with respect to satisfiability. The
operation is similar to the closure operation for RCC-5 introduced by Renz (1996) but it does not
pose the same restrictions on the given subclass. (Renz's operation requires fEQg to be a member
of the subclass to be closed.)

Definition 2.2 Let S  R5. Then we denote by S the closure of S , defined as the least subalgebra
containing S closed under converse, intersection and composition.
Observe that a subset S of R5 is a subalgebra iff S = S .

The next lemma is given without proof. A proof of the analogous result for Allen's algebra can
be found in Nebel and Burckert (1995).
213

fiJonsson & Drakengren

Lemma 2.3 Let S  R5. Then RSAT(S ) can be polynomially transformed to RSAT(S ) and vice
versa.

Corollary 2.4 Let S  R5. RSAT(S ) is polynomial iff RSAT(S ) is polynomial. RSAT(S ) is
NP-complete iff RSAT(S ) is NP-complete.

3. Tractable Subclasses of RCC-5

We begin this section by defining four tractable subalgebras of RCC-5, which can be found in Table 2.
Later on, we show that these algebras are the only maximal tractable subalgebras of RCC-5. The
28
tractability of the first algebra, R28
5 , has been established by Renz and Nebel (1997). The name R5
reects the fact that the algebra contains 28 elements.

Theorem 3.1 RSAT(R28
5 ) is polynomial.
The tractability of our second algebra, R20
5 , can be settled quite easily. The algorithm can be found
in Figure 2.
20
Lemma 3.2 Let  be an instance of RSAT(R20
5 ). The algorithm A accepts on input  iff  has

an R-model.

Proof: if: We show the contrapositive, i.e., if A20 rejects then  has no R-model. Clearly, the
satisfiability of  is preserved under the transformations made in lines 7-10. Note that if XRX 2 
then EQ 2 R if  is satisfiable. Thus  is not satisfiable if the algorithm rejects in line 5. Similarly,
 is not satisfiable if the algorithm rejects in line 6.

only-if: Consider the set  after the completion of line 11. We denote this set by 0 . Obviously, 0

is satisfiable if the initial  was satisfiable. Also observe that line 7 ensures that 0 does not relate
any variables with EQ. Furthermore, line 8 guarantees that there is at most one relation that relates
two variables.
Now, we construct an R-model M for 0 as follows: Let V be the set of variables in 0 . Let
M assign non-empty sets that are pairwise disjoint to the members of V . Let U = S 2 M (X ).
Introduce a set of values U 0 = fff j X; Y 2 V g satisfying the following:
X

V

X;Y

1. ff = ff iff X = Z and Y = W ; and
2. for arbitrary X; Y 2 V , ff 62 U .
X;Y

Z;W

X;Y

For each relation of the type X fPOgY or X fPO; EQgY , extend the sets M (X ) and M (Y ) with the
element ff .
Clearly, two sets X; Y are disjoint (and are thus related by DR) under M unless X fPOgY or
X fPO; EQgY is in . But in these cases, X and Y must not be disjoint. In fact, by introducing
ff , we have forced X fPOgY to hold under M which satisfies formulae of the type X fPOgY as well
as formulae of the type X fPO; EQgY . Hence, M is an R-model of 0 which implies the R-satisfiability
of .
2
X;Y

X;Y

Theorem 3.3 RSAT(R20
5 ) is polynomial.
Proof: Algorithm A20 correctly solves the RSAT(R20
5 ) problem by the previous lemma. Further-

more, the number of iterations is bounded from above by the number of variables and the number
of formulae in the given instance and the tests can easily be performed in polynomial time.
2
Next we show the tractability of RSAT(R17
5 ).
214

fiA Complete Classification of Tractability in RCC-5

20 R17 R14
R28
5 R5
5
5
?
  

fDRg
 
fPOg
 
fDR; POg
 
fPPg


fDR; PPg
 
fPO; PPg

fDR; PO; PPg
 
fPPIg


fDR; PPIg
 
fPO; PPIg

fDR; PO; PPIg
 
fPP; PPIg

fDR; PP; PPIg


fPO; PP; PPIg


fDR; PO; PP; PPIg  

fEQg
  

fDR; EQg
  
fPO; EQg
  
fDR; PO; EQg
  
fPP; EQg



fDR; PP; EQg
  
fPO; PP; EQg


fDR; PO; PP; EQg   
fPPI; EQg



fDR; PPI; EQg
  
fPO; PPI; EQg


fDR; PO; PPI; EQg   
fPP; PPI; EQg


fDR; PP; PPI; EQg
 

fPO; PP; PPI; EQg 


>
  

Table 2: The maximal tractable subalgebras of RCC-5.

Theorem 3.4 RSAT(R17
5 ) is polynomial.
Proof: Consider the algorithm A17 in Figure 2. If there exist X; Y such that X ?Y 2  then 

is not satisfiable. Otherwise, we can let all variables have the same value. Since EQ is a member of
every relation that occurs in , this interpretation is an R-model of .
2

We continue by proving that RSAT(R14
5 ) is a tractable problem. Let
9
R5 = ffPP; EQgg [ fR [ fPP; PPIg j R 2 R5g:
9
Using a machine-assisted proof, it can be shown that R14
5 = R5 so it is sucient to prove the
9
tractability of RSAT(R5) by Corollary 2.4. The program that we used for showing this is available
as an on-line appendix to this article.
From now on, let  be an arbitrary instance of RSAT(R95) and G = hV; E i be its graph representation. The following proofs are similar in spirit to some of the proofs appearing in Drakengren and
215

fiJonsson & Drakengren

1
2
3
4
5
6
7
8
9
10
11
12

algorithm A20
Input: An instance  of RSAT(R20
5 ).
repeat
0 
if 9X; R : XRX 2  and EQ 62 R then reject
if 9X; Y : X ?Y 2  then reject
if 9X; Y : X =6 Y and X fEQgY 2  then substitute Y for X in 
if 9X; Y; R; S : XRY 2  and XSY 2  then
 ( , fXRY; XSY g) [ fX (R \ S )Y g
if 9X; R : XRX 2  and EQ 2 R then   , fXRX g
until  = 0
accept

1
2
3
4

algorithm A17
Input: An instance  of RSAT(R17
5 ).
if 9X; Y such that X ?Y 2  then reject
else accept

1
2
3
4
5
6
7

algorithm A9
Input: An instance  of RSAT(R95) with graph representation G.
Let G0 be the graph obtained from G by removing arcs which are not labelled fPP; EQg.
Find all strongly connected components C in G0
for every arc e in G whose relation does not contain EQ do
if e connects two nodes in some C then reject
accept
17
9
Figure 2: Algorithms for RSAT(R20
5 ), RSAT(R5 ) and RSAT(R5).

Jonsson (1996). The algorithm itself is reminiscent of an algorithm by van Beek (1992) for deciding
satisfiability in the point algebra.
Definition 3.5 A RCC-5 relation R is said to be an acyclic relation iff any cycle in any G with R
on every arc is never satisfiable.
The relation PP is an example of an acyclic relation while fPP; EQg is not acyclic. We continue by
showing a few properties of acyclic relations.
Proposition 3.6 Let R be an acyclic relation. Then every relation R0  R is acyclic.
Proof: Since taking subsets of R constrains satisfiability further, the result follows.
2
Proposition 3.7 Let R be an acyclic relation, and choose A such that A  fR0 j R0  Rg. Then,
any cycle in G where every arc is labelled by some relation in A is unsatisfiable.
Proof: Same argument as in the previous proposition.
2
The following definition is needed in the following proofs.
Definition 3.8 Let I be an instance of the R-satisfiability problem, M a model for I , and r 2 R5
a relation between two region variables X and Y in I . Then r is said to be satisfied as r0 in M for
any relation r0  r, such that Xr0 Y is satisfied in M .
216

fiA Complete Classification of Tractability in RCC-5

The definition may seem a bit cumbersome but the essence should be clear. As an example, let X
and Y be region variables related by X fPO; PPgY , and M a model where X is interpreted as f1; 2g
and Y as f1; 2; 3g. Then in M , fPO; PPg is satisfied as fPPg, but also as fPO; PPg.
Lemma 3.9 Let R be an acyclic relation, and A; A0 sets such that A  fR0 j R0  Rg and A0 
fa [ fEQg j a 2 Ag. Then, every cycle C labelled by relations in A [ A0 is satisfiable iff it contains
only relations from A0 . Furthermore, all relations in the cycle have to be satisfied as EQ.
Proof: only-if: Suppose that a cycle C is satisfiable and that it contains some relation from
A. Apply induction on the number n of arcs in the cycle. For n = 1, we get a contradiction by
Proposition 3.7. So, suppose for the induction that C contains n + 1 arcs. Let M be an R-model
for the relations in C . It cannot be the case that every relation in C is satisfied in M as some
relation in A, by Proposition 3.7. Thus, some relation R0 in C has to be satisfied as EQ. But then
we can collapse the two variables connected by R0 to one variable, and we have a cycle with n nodes
containing a relation from A. This contradicts the induction hypothesis.
if: Suppose that a cycle C contains only relations in A0 . Then C can be satisfied by choosing EQ on
every arc. Notice that the only-if part implies that C must be satisfied by choosing EQ on every arc.

2

Hence, the variables are forced to be equal.

After having studied acyclic relations, we will now turn our attention to DAG-satisfying relations.
The formal definition is as follows.
Definition 3.10 A basic relation B is said to be DAG-satisfying iff any DAG (directed acyclic
graph) labelled only by relations containing B is satisfiable, i.e., if the corresponding RSAT problem
has a model.
A typical example of a DAG-satisfying relation is EQ. Given a DAG labelled only by relations containing EQ, we can always satisfy these relations by assigning some non-empty set S to all variables.
We can now show that PP is a DAG-satisfying relation.
Definition 3.11 Let G be an arbitrary DAG. A node v in G is said to be a terminal node iff there
are no arcs which start in v.
Lemma 3.12 The basic relation PP is DAG-satisfying.
Proof: Let G be a DAG labelled only by relations containing PP. We show that G is satisfied
by some R-model M . Induction on n which is the number of nodes in G. The case when n = 1 is
trivial. Suppose that G has n +1 nodes and remove a terminal node g. By induction, the remaining
graph G0 = hV 0 ; E 0i is satisfiable by a model M 0.SWe shall now construct a model M of G, which
agrees with M 0 on every variable in G0. Let S = fM 0(v) j v 2 V 0 g and let ff be an element not in
S . Let M (g) = S [ fffg. Obviously, M is a model of G.
2
We now state a simple result from Drakengren and Jonsson (1996).
Lemma 3.13 Let G be irreexive1 and have an acyclic subgraph D. Then those arcs of G which
are not in D can be reoriented so that the resulting graph is acyclic.
By specializing this result, we get the next lemma.
Lemma 3.14 Let G be irreexive with an acyclic subgraph D and let the arcs of D be labelled by
relations containing PP, and the arcs not in D being labelled by relations containing PP and PPI.
Then G is R-satisfiable.
1. A graph is irreexive iff it has no arcs from a node v to the node v.

217

fiJonsson & Drakengren

Proof: Reorient the arcs of G such that the resulting graph is acyclic. This is always possible by
the previous lemma. Furthermore, whenever an arc is reoriented, also invert the relation on that
arc, so that G0 is satisfiable iff G is. By this construction, only arcs containing both PP and PPI
have been reoriented, so every arc in the DAG G0 contains PP and, thus, since PP is DAG-satisfying
by Lemma 3.12, G0 is satisfiable. Consequently, G is also satisfiable.
2
Lemma 3.15 Algorithm A9 correctly solves RSAT(R95).
Proof: Assume that the algorithm finds a strongly connected component of G0 (which then contains
only the relation fPP; EQg), containing two nodes that in G are connected by an arc e that is labelled
by a relation R0 which does not contain EQ. Then there exists a cycle C in which the relation of
every arc contains EQ, such that e connects two nodes in that C but e is not part of that cycle. By
Lemma 3.9, C can be satisfied only by choosing the relation EQ on every arc in C , and since R0 does

not admit EQ, C is unsatisfiable.
Otherwise, every such strongly connected component can be collapsed to a single node, removing
all arcs which start and end in the collapsed node. This transformation retains satisfiability using the
same argument as above. After collapsing, the subgraph obtained by considering only arcs labelled
fPP; EQg will be acyclic. Since the remaining arcs are labelled by relations containing both PP and
PPI, the graph is R-satisfiable by Lemma 3.14. (Note that the graph will be irreexive since every
node is contained in some strongly connected component.)
2
Lemma 3.16 Given a graph G = hV; Ei, algorithm A9 runs in O(jV j + jEj) time.
Proof: Strongly connected components can be found in O(jV j + jEj) time (Baase, 1988) and the
remaining test can also be made in O(jV j + jE j) time.
2
Theorem 3.17 RSAT(R14
5 ) can be solved in polynomial time.
14
9
Proof: RSAT(R95) is polynomial by the previous two lemmata. Since R14
5 = R5, RSAT(R5 ) can
be solved in polynomial time by Corollary 2.4.
2

4. Classification of RCC-5

Before we can give the classification of RCC-5 we need two NP-completeness results.
Theorem 4.1 RSAT(S ) is NP-complete if
1. (Renz & Nebel, 1997) C1 = ffPOg; fPP; PPIgg  S , or
2. C2 = ffDR; POg; fPP; PPIgg  S .
Proof: The proof for C2 is by polynomial-time reduction from RSAT(C1). Let  be an arbitrary
instance of RSAT(C1). Construct the following set:
0 = fX fPP; PPIgY j X fPP; PPIgY 2 g [ fX fDR; POgY j X fPOgY 2 g:
Clearly, 0 can be obtained from  in polynomial time and 0 is an instance of RSAT(C2). We show
that  is satisfiable iff 0 is satisfiable.
only-if: Assume that there exists an R-model I of . It is not hard to see that I is also an R-model

of I 0 since if X fPOgY under I then X fDR; POgY under I . Thus 0 is R-satisfiable if  is R-satisfiable.

if: Assume the existence of an R-model I 0 that assigns subsets of some set U to the region variables

of 0 . Let ff be an element such that ff 62 U . We construct a new interpretation I as follows:
I (x) = I 0 (x) [ fffg for every variable x in 0 . It can easily be seen that the following holds for I :
218

fiA Complete Classification of Tractability in RCC-5

1.
2.
3.
4.

If xfDRgy under I 0 then xfPOgy under I .
If xfPOgy under I 0 then xfPOgy under I .
If xfPPgy under I 0 then xfPPgy under I .
If xfPPIgy under I 0 then xfPPIgy under I .

It is easy to see that if xfPP; PPIgy under I 0 then xfPP; PPIgy under I . Similarly, if xfDR; POgy under
I 0 then xfPOgy under I . It follows that I is a model of  so  is R-satisfiable if 0 is R-satisfiable.
2
The main theorem can now be stated and proved.

Theorem 4.2 For S  R5, RSAT(S ) is polynomial iff S is a subset of some member of R =
20 17 14
fR28
5 ; R5 ; R5 ; R5 g, and NP-complete otherwise.
Proof: if: For each R 2 R , RSAT(R) is polynomial as was shown in the previous section.
only-if: Choose S  R5 such that S is not a subset of any algebra in R . For each subalgebra
R 2 R , choose a relation x such that x 2 S and x 62 R. This can always be done since S 6 R. Let
X be the set of these relations and note that X is not a subset of any algebra in R . The set R
contains four algebras so by the construction of X , jX j  4. Observe that RSAT(S ) is NP-complete
if RSAT(X ) is NP-complete.
To show that RSAT(S ) has to be NP-complete, a machine-assisted case analysis of the following
P

P

P

P

P

P

form was performed:


4 
X
32
1. Generate all subsets of R5 of size  4. There are
i = 41449 such subsets.
=0
i

2. Let T be such a set. Test: T is a subset of some subalgebra in R or C  T for some
i 2 f1; 2g.
P

The test succeeds for all T . Hence, RSAT(S ) is NP-complete by Corollary 2.4.

i

2

The program used for showing the previous theorem appears in the on-line appendix of this article.

5. Discussion

The main problem of reporting tractability results for restricted classes of problems is the diculty
of isolating interesting and relevant subclasses. The systematic approach of building complete classifications is a way of partially overcoming this problem. If the problem class under consideration
is regarded relevant, then its tractable subclasses should be regarded relevant if the computational
problem is of interest. This is especially true in spatial reasoning where the size of the problem instances can be extremely large; one good example is spatial reasoning in connection with the Human
Genome project (Cui, 1994).
Another advantage with complete classifications is that they are more satisfactory from a scientific
point of view; to gain a clear picture of the borderline between tractability and intractability has
an intrinsic scientific value. A common critique is that complete classifications tend to generate
certain classes which are totally useless. For instance, the subalgebra R17
5 is certainly of no use.
It must be made clear that such critique is unjustified since the researcher who makes a complete
classification does not deliberately invent useless classes. Instead, if useless classes appear in a
complete classification, they are unavoidable parts of the classification.
219

fiJonsson & Drakengren

The work reported in this article can be extended in many different ways. One obvious extension
is to study other computational problems than the RSAT problem. Renz (1996) has studied two
problems, RMIN and RENT, on certain subclasses of RCC-5 and RCC-8. The RMIN problem is to
decide if a set of spatial formulae  is minimal, i.e., whether all basic relations in every formula of
 can be satisfied or not. The RENT problem is to decide whether a formula XRY is entailed by a
set of spatial formulae. Grigni et al. (1995) study a stronger form of satisfiability which they refer
to as realizability: A finite set  of RCC-5 formulae is said to be realizable iff there exist regions
on the plane bounded by Jordan curves which satisfy the relations in . Grigni et al. (1995) have
shown that the realizability problem is much harder than the satisfiability problem. For instance,
deciding realizability of formulae constructed from the two relations DR and PO is NP-complete while
the satisfiability problem is polynomial. Certainly, further studies of the realizability problem would
be worthwhile.
Another obvious research direction is to completely classify other spatial algebras, such as RCC8. RCC-8 contains 2256  1077 relations so the question whether this is feasible or not remains to
be answered.

6. Conclusions

We have studied computational properties of RCC-5. All of the 232 possible subclasses are classified with respect to whether their corresponding satisfiability problem is tractable or not. The
classification reveals that there are four maximal tractable subclasses of the algebra.

References

Baase, S. (1988). Computer Algorithms: Introduction and Analysis (2nd edition). Addison Wesley,
Reading, MA.
Bennett, B. (1994). Spatial reasoning with propositional logics. In Doyle, J., Sandewall, E., &
Torasso, P. (Eds.), Proceedings of the 4th International Conference on Principles on Knowledge
Representation and Reasoning (KR-94), pp. 165{176 Bonn, Germany. Morgan Kaufmann.
Cook, S. A. (1971). The complexity of theorem-proving procedures. In Proceedings of the 3rd ACM
Symposium on Theory of Computing, pp. 151{158.
Cui, Z. (1994). Using interval logic for order assembly. In Proceedings of the Second International
Conference on Intelligent Systems for Molecular Biology, pp. 103{111. AAAI Press.
Drakengren, T., & Jonsson, P. (1996). Maximal tractable subclasses of Allen's interval algebra: Preliminary report. In Proceedings of the 13th (US) National Conference on Artificial Intelligence
(AAAI-96), pp. 389{394 Portland, OR, USA. American Association for Artificial Intelligence.
Egenhofer, M. J. (1991). Reasoning about binary topological relations. In Gunther, O., & Schek,
H. J. (Eds.), Advances in Spatial Databases, pp. 143{160. Springer-Verlag.
Grigni, M., Papadias, D., & Papadimitriou, C. (1995). Topological inference. In Mellish, C. (Ed.),
Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI-95),
pp. 901{906 Montreal, PQ, Canada. Morgan Kaufmann.
Mallios, A. (1986). Topological Algebras. Selected Topics. North-Holland, Amsterdam.
Nebel, B. (1995). Computational properties of qualitative spatial reasoning: First results. In
Wachsmuth, I., Rollinger, C.-R., & Brauer, W. (Eds.), KI-95: Advances in Artificial Intelligence, pp. 233{244 Bielefeld, Germany. Springer-Verlag.
220

fiA Complete Classification of Tractability in RCC-5

Nebel, B., & Burckert, H.-J. (1995). Reasoning about temporal relations: A maximal tractable
subclass of Allen's interval algebra. Journal of the ACM, 42 (1), 43{66.
Randell, D. A., & Cohn, A. G. (1989). Modelling topological and metrical properties of physical
processes. In Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings of the 1st
International Conference on Principles on Knowledge Representation and Reasoning (KR-89),
pp. 55{66 Toronto, ON, Canada. Morgan Kaufmann.
Randell, D. A., Cui, Z., & Cohn, A. G. (1992). A spatial logic based on regions and connection. In
Swartout, B., & Nebel, B. (Eds.), Proceedings of the 3rd International Conference on Principles
on Knowledge Representation and Reasoning (KR-92), pp. 165{176 Cambridge, MA, USA.
Morgan Kaufmann.
Renz, J. (1996). Qualitatives raumliches Schlieen: Berechnungseigenschaften und eziente Algorithmen. Master thesis report, Fakultat fur Informatik, Universitat Ulm. Available from
http://www.informatik.uni-freiburg.de/sppraum.
Renz, J., & Nebel, B. (1997). On the complexity of qualitative spatial reasoning: A maximal
tractable fragment of the region connected calculus. In Proceedings of the 15th International
Joint Conference on Artificial Intelligence (IJCAI-97) Nagoya, Japan. Morgan Kaufmann. To
appear.
Statman, R. (1979). Intuitionistic logic is polynomial-space complete. Theoretical Computer Science,
9 (1), 67{72.
van Beek, P. (1992). Reasoning about qualitative temporal information. Artificial Intelligence, 58,
297{326.

221

fiJournal of Artificial Intelligence Research 6 (1997) 1-34

Submitted 5/96; published 1/97

Improved Heterogeneous Distance Functions
D. Randall Wilson
Tony R. Martinez
Computer Science Department
Brigham Young University
Provo, UT 84602, USA

RANDY @AXON.CS.BYU.EDU
MARTINEZ @CS.BYU.EDU

Abstract
Instance-based learning techniques typically handle continuous and linear input values well,
but often do not handle nominal input attributes appropriately. The Value Difference Metric
(VDM) was designed to find reasonable distance values between nominal attribute values, but it
largely ignores continuous attributes, requiring discretization to map continuous values into
nominal values. This paper proposes three new heterogeneous distance functions, called the
Heterogeneous Value Difference Metric (HVDM), the Interpolated Value Difference Metric
(IVDM), and the Windowed Value Difference Metric (WVDM). These new distance functions
are designed to handle applications with nominal attributes, continuous attributes, or both. In
experiments on 48 applications the new distance metrics achieve higher classification accuracy
on average than three previous distance functions on those datasets that have both nominal and
continuous attributes.

1. Introduction
Instance-Based Learning (IBL) (Aha, Kibler & Albert, 1991; Aha, 1992; Wilson & Martinez,
1993; Wettschereck, Aha & Mohri, 1995; Domingos, 1995) is a paradigm of learning in which
algorithms typically store some or all of the n available training examples (instances) from a
training set, T, during learning. Each instance has an input vector x, and an output class c.
During generalization, these systems use a distance function to determine how close a new
input vector y is to each stored instance, and use the nearest instance or instances to predict the
output class of y (i.e., to classify y). Some instance-based learning algorithms are referred to as
nearest neighbor techniques (Cover & Hart, 1967; Hart, 1968; Dasarathy, 1991), and memorybased reasoning methods (Stanfill & Waltz, 1986; Cost & Salzberg, 1993; Rachlin et al., 1994)
overlap significantly with the instance-based paradigm as well. Such algorithms have had much
success on a wide variety of applications (real-world classification tasks).
Many neural network models also make use of distance functions, including radial basis
function networks (Broomhead & Lowe, 1988; Renals & Rohwer, 1989; Wasserman, 1993),
counterpropagation networks (Hecht-Nielsen, 1987), ART (Carpenter & Grossberg, 1987), selforganizing maps (Kohonen, 1990) and competitive learning (Rumelhart & McClelland, 1986).
Distance functions are also used in many fields besides machine learning and neural networks,
including statistics (Atkeson, Moore & Schaal, 1996), pattern recognition (Diday, 1974;
Michalski, Stepp & Diday, 1981), and cognitive psychology (Tversky, 1977; Nosofsky, 1986).
 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiWILSON & MARTINEZ

There are many distance functions that have been proposed to decide which instance is
closest to a given input vector (Michalski, Stepp & Diday, 1981; Diday, 1974). Many of these
metrics work well for numerical attributes but do not appropriately handle nominal (i.e.,
discrete, and perhaps unordered) attributes.
The Value Difference Metric (VDM) (Stanfill & Waltz, 1986) was introduced to define an
appropriate distance function for nominal (also called symbolic) attributes. The Modified Value
Difference Metric (MVDM) uses a different weighting scheme than VDM and is used in the
PEBLS system (Cost & Salzberg, 1993; Rachlin et al., 1994). These distance metrics work well
in many nominal domains, but they do not handle continuous attributes directly. Instead, they
rely upon discretization (Lebowitz, 1985; Schlimmer, 1987), which can degrade generalization
accuracy (Ventura & Martinez, 1995).
Many real-world applications have both nominal and linear attributes, including, for
example, over half of the datasets in the UCI Machine Learning Database Repository (Merz &
Murphy, 1996). This paper introduces three new distance functions that are more appropriate
than previous functions for applications with both nominal and continuous attributes. These
new distance functions can be incorporated into many of the above learning systems and areas
of study, and can be augmented with weighting schemes (Wettschereck, Aha & Mohri, 1995;
Atkeson, Moore & Schaal, 1996) and other enhancements that each system provides.
The choice of distance function influences the bias of a learning algorithm. A bias is a rule
or method that causes an algorithm to choose one generalized output over another (Mitchell,
1980). A learning algorithm must have a bias in order to generalize, and it has been shown that
no learning algorithm can generalize more accurately than any other when summed over all
possible problems (Schaffer, 1994) (unless information about the problem other than the
training data is available). It follows then that no distance function can be strictly better than
any other in terms of generalization ability, when considering all possible problems with equal
probability.
However, when there is a higher probability of one class of problems occurring than another,
some learning algorithms can generalize more accurately than others (Wolpert, 1993). This is
not because they are better when summed over all problems, but because the problems on which
they perform well are more likely to occur. In this sense, one algorithm or distance function can
be an improvement over another in that it has a higher probability of good generalization than
another, because it is better matched to the kinds of problems that will likely occur.
Many learning algorithms use a bias of simplicity (Mitchell, 1980; Wolpert, 1993) to
generalize, and this bias is appropriatemeaning that it leads to good generalization
accuracyfor a wide variety of real-world applications, though the meaning of simplicity varies
depending upon the representational language of each learning algorithm. Other biases, such as
decisions made on the basis of additional domain knowledge for a particular problem (Mitchell,
1980), can also improve generalization.
In this light, the distance functions presented in this paper are more appropriate than those
used for comparison in that they on average yield improved generalization accuracy on a
collection of 48 applications. The results are theoretically limited to this set of datasets, but the
hope is that these datasets are representative of other problems that will be of interest (and occur
frequently) in the real world, and that the distance functions presented here will be useful in
such cases, especially those involving both continuous and nominal input attributes.
Section 2 provides background information on distance functions used previously. Section 3
2

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

introduces a distance function that combines Euclidean distance and VDM to handle both
continuous and nominal attributes. Sections 4 and 5 present two extensions of the Value
Difference Metric which allow for direct use of continuous attributes. Section 4 introduces the
Interpolated Value Difference Metric (IVDM), which uses interpolation of probabilities to avoid
problems related to discretization. Section 5 presents the Windowed Value Difference Metric
(WVDM), which uses a more detailed probability density function for a similar interpolation
process.
Section 6 presents empirical results comparing three commonly-used distance functions with
the three new functions presented in this paper. The results are obtained from using each of the
distance functions in an instance-based learning system on 48 datasets. The results indicate that
the new heterogeneous distance functions are more appropriate than previously used functions
on datasets with both nominal and linear attributes, in that they achieve higher average
generalization accuracy on these datasets. Section 7 discusses related work, and Section 8
provides conclusions and future research directions.

2. Previous Distance Functions
As mentioned in the introduction, there are many learning systems that depend upon a good
distance function to be successful. A variety of distance functions are available for such uses,
including the Minkowsky (Batchelor, 1978), Mahalanobis (Nadler & Smith, 1993), Camberra,
Chebychev, Quadratic, Correlation, and Chi-square distance metrics (Michalski, Stepp &
Diday, 1981; Diday, 1974); the Context-Similarity measure (Biberman, 1994); the Contrast
Model (Tversky, 1977); hyperrectangle distance functions (Salzberg, 1991; Domingos, 1995)
and others. Several of these functions are defined in Figure 1.
Although there have been many distance functions proposed, by far the most commonly
used is the Euclidean Distance function, which is defined as:
m

E(x, y) =

 (xa  ya )2

(1)

a=1

where x and y are two input vectors (one typically being from a stored instance, and the other an
input vector to be classified) and m is the number of input variables (attributes) in the
application. The square root is often not computed in practice, because the closest instance(s)
will still be the closest, regardless of whether the square root is taken.
An alternative function, the city-block or Manhattan distance function, requires less
computation and is defined as:
M(x, y) =

m

 xa  ya

(2)

a=1

The Euclidean and Manhattan distance functions are equivalent to the Minkowskian rdistance function (Batchelor, 1978) with r = 2 and 1, respectively.

3

fiWILSON & MARTINEZ

Minkowsky:

Euclidean:

m
r
D(x, y) =   xi  yi 
 i=1

Camberra:

1

r

Manhattan / city-block:

m

2
 ( xi  yi )

D(x, y) =

i=1

m x y
i
D(x, y) =  i
x
+
y
i
i=1 i

Chebychev:

m

D(x, y) =  xi  yi
i=1

m

D(x, y) = max xi  yi
i=1

m m

D(x, y) = (x  y)T Q(x  y) =    (xi  yi )q ji  (x j  y j )
Quadratic:

Q is a problem-specific positive
j=1 i=1
definite m  m weight matrix
V is the covariance matrix of A 1..Am,
Mahalanobis:
and Aj is the vector of values for
D(x, y) = [det V]1/ m (x  y)T V 1 (x  y)
attribute j occuring in the training set
instances 1..n.
m
Correlation:
 (xi  xi )(yi  yi )
xi = yi and is the average value for
i=1
D(x, y) =
attribute
i occuring in the training set.
m
m
2
2
 (xi  xi )  (yi  yi )
i=1

i=1

y 
1  xi
Chi-square: D(x, y) = 
 i 

sumi  sizex size y 
i=1
m

Kendalls Rank Correlation:
sign(x)=-1, 0 or 1 if x < 0,
x = 0, or x > 0, respectively.

D(x, y) = 1 

2

sumi is the sum of all values for attribute
i occuring in the training set, and sizex is
the sum of all values in the vector x.

m i1
2

 sign(xi  x j )sign(yi  y j )
n(n  1) i=1 j=1

Figure 1. Equations of selected distance functions.
(x and y are vectors of m attribute values).
2.1. Normalization
One weakness of the basic Euclidean distance function is that if one of the input attributes has a
relatively large range, then it can overpower the other attributes. For example, if an application
has just two attributes, A and B, and A can have values from 1 to 1000, and B has values only
from 1 to 10, then Bs influence on the distance function will usually be overpowered by As
influence. Therefore, distances are often normalized by dividing the distance for each attribute
by the range (i.e., maximum-minimum) of that attribute, so that the distance for each attribute is
in the approximate range 0..1. In order to avoid outliers, it is also common to divide by the
standard deviation instead of range, or to trim the range by removing the highest and lowest
few percent (e.g., 5%) of the data from consideration in defining the range. It is also possible to
map any value outside this range to the minimum or maximum value to avoid normalized
values outside the range 0..1. Domain knowledge can often be used to decide which method is
most appropriate.
Related to the idea of normalization is that of using attribute weights and other weighting
4

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

schemes. Many learning systems that use distance functions incorporate various weighting
schemes into their distance calculations (Wettschereck, Aha & Mohri, 1995; Atkeson, Moore &
Schaal, 1996). The improvements presented in this paper are independent of such schemes, and
most of the various weighting schemes (as well as other enhancements such as instance pruning
techniques) can be used in conjunction with the new distance functions presented here.
2.2. Attribute Types
None of the distance functions shown in Figure 1, including Euclidean distance, appropriately
handle non-continuous input attributes.
An attribute can be linear or nominal, and a linear attribute can be continuous or discrete. A
continuous (or continuously-valued) attribute uses real values, such as the mass of a planet or
the velocity of an object. A linear discrete (or integer) attribute can have only a discrete set of
linear values, such as number of children.
It can be argued that any value stored in a computer is discrete at some level. The reason
continuous attributes are treated differently is that they can have so many different values that
each value may appear only rarely (perhaps only once in a particular application). This causes
problems for algorithms such as VDM (described in Section 2.4) that depend on testing two
values for equality, because two continuous values will rarely be equal, though they may be
quite close to each other.
A nominal (or symbolic) attribute is a discrete attribute whose values are not necessarily in
any linear order. For example, a variable representing color might have values such as red,
green, blue, brown, black and white, which could be represented by the integers 1 through 6,
respectively. Using a linear distance measurement such as (1) or (2) on such values makes little
sense in this case.
2.3. Heterogeneous Euclidean-Overlap Metric (HEOM)
One way to handle applications with both continuous and nominal attributes is to use a
heterogeneous distance function that uses different attribute distance functions on different
kinds of attributes. One approach that has been used is to use the overlap metric for nominal
attributes and normalized Euclidean distance for linear attributes.
For the purposes of comparison during testing, we define a heterogeneous distance function
that is similar to that used by IB1, IB2 and IB3 (Aha, Kibler & Albert, 1991; Aha, 1992) as well
as that used by Giraud-Carrier & Martinez (1995). This function defines the distance between
two values x and y of a given attribute a as:
if x or y is unknown, else
 1,

da (x, y) = overlap(x, y), if a is nominal, else
 rn_ diff (x, y)
a


(3)

Unknown attribute values are handled by returning an attribute distance of 1 (i.e., a maximal
distance) if either of the attribute values is unknown. The function overlap and the rangenormalized difference rn_diff are defined as:
0, if x = y
overlap(x, y) = 
1, otherwise

5

(4)

fiWILSON & MARTINEZ

rn_ diff a (x, y) =

| x  y|
rangea

(5)

The value rangea is used to normalize the attributes, and is defined as:
rangea= maxa- mina

(6)

where max a and mina are the maximum and minimum values, respectively, observed in the
training set for attribute a. This means that it is possible for a new input vector to have a value
outside this range and produce a difference value greater than one. However, such cases are
rare, and when they do occur, a large difference may be acceptable anyway. The normalization
serves to scale the attribute down to the point where differences are almost always less than one.
The above definition for da returns a value which is (typically) in the range 0..1, whether the
attribute is nominal or linear. The overall distance between two (possibly heterogeneous) input
vectors x and y is given by the Heterogeneous Euclidean-Overlap Metric function HEOM(x,y):
m

 da (xa , ya )2

HEOM(x, y) =

(7)

a=1

This distance function removes the effects of the arbitrary ordering of nominal values, but its
overly simplistic approach to handling nominal attributes fails to make use of additional
information provided by nominal attribute values that can aid in generalization.
2.4. Value Difference Metric (VDM)
The Value Difference Metric (VDM) was introduced by Stanfill and Waltz (1986) to provide an
appropriate distance function for nominal attributes. A simplified version of the VDM (without
the weighting schemes) defines the distance between two values x and y of an attribute a as:
C Na,x,c

Na,y,c
vdma (x, y) = 

N
Na,y
a,x
c=1

q

C

=  Pa,x,c  Pa,y,c

q

(8)

c=1

where
 Na,x is the number of instances in the training set T that have value x for attribute a;
 Na,x,c is the number of instances in T that have value x for attribute a and output class c;
 C is the number of output classes in the problem domain;
 q is a constant, usually 1 or 2; and
 P a,x,c is the conditional probability that the output class is c given that attribute a has the
value x, i.e., P(c | xa). As can be seen from (8), Pa,x,c is defined as:
Pa,x,c =

Na,x,c
Na,x

(9)

where Na,x is the sum of Na,x,c over all classes, i.e.,
C

Na,x =  Na,x,c
c=1

6

(10)

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

and the sum of Pa,x,c over all C classes is 1 for a fixed value of a and x.
Using the distance measure vdma(x,y), two values are considered to be closer if they have
more similar classifications (i.e., more similar correlations with the output classes), regardless
of what order the values may be given in. In fact, linear discrete attributes can have their values
remapped randomly without changing the resultant distance measurements.
For example, if an attribute color has three values red, green and blue, and the application is
to identify whether or not an object is an apple, red and green would be considered closer than
red and blue because the former two both have similar correlations with the output class apple.
The original VDM algorithm (Stanfill & Waltz, 1986) makes use of feature weights that are
not included in the above equations, and some variants of VDM (Cost & Salzberg, 1993;
Rachlin et al., 1994; Domingos, 1995) have used alternate weighting schemes. As discussed
earlier, the new distance functions presented in this paper are independent of such schemes and
can in most cases make use of similar enhancements.
One problem with the formulas presented above is that they do not define what should be
done when a value appears in a new input vector that never appeared in the training set. If
attribute a never has value x in any instance in the training set, then Na,x,c for all c will be 0, and
N a,x (which is the sum of Na,x,c over all classes) will also be 0. In such cases P a,x,c = 0/0,
which is undefined. For nominal attributes, there is no way to know what the probability should
be for such a value, since there is no inherent ordering to the values. In this paper we assign
P a,x,c the default value of 0 in such cases (though it is also possible to let Pa,x,c = 1/C, where C
is the number of output classes, since the sum of Pa,x,c for c = 1..C is always 1.0).
If this distance function is used directly on continuous attributes, the values can all
potentially be unique, in which case Na,x is 1 for every value x, and Na,x,c is 1 for one value of c
and 0 for all others for a given value x. In addition, new vectors are likely to have unique
values, resulting in the division by zero problem above. Even if the value of 0 is substituted for
0/0, the resulting distance measurement is nearly useless.
Even if all values are not unique, there are often enough different values for a continuous
attribute that the statistical sample is unreliably small for each value, and the distance measure
is still untrustworthy. Because of these problems, it is inappropriate to use the VDM directly on
continuous attributes.
2.5. Discretization
One approach to the problem of using VDM on continuous attributes is discretization
(Lebowitz, 1985; Schlimmer, 1987; Ventura, 1995). Some models that have used the VDM or
variants of it (Cost & Salzberg, 1993; Rachlin et al., 1994; Mohri & Tanaka, 1994) have
discretized continuous attributes into a somewhat arbitrary number of discrete ranges, and then
treated these values as nominal (discrete unordered) values. This method has the advantage of
generating a large enough statistical sample for each nominal value that the P values have some
significance. However, discretization can lose much of the important information available in
the continuous values. For example, two values in the same discretized range are considered
equal even if they are on opposite ends of the range. Such effects can reduce generalization
accuracy (Ventura & Martinez, 1995).
In this paper we propose three new alternatives, which are presented in the following three
sections. Section 3 presents a heterogeneous distance function that uses Euclidean distance for
linear attributes and VDM for nominal attributes. This method requires careful attention to the
7

fiWILSON & MARTINEZ

problem of normalization so that neither nominal nor linear attributes are regularly given too
much weight.
In Sections 4 and 5 we present two distance functions, the Interpolated Value Difference
Metric (IVDM) and the Windowed Value Difference Metric (WVDM), which use discretization
to collect statistics and determine values of Pa,x,c for continuous values occurring in the training
set instances, but then retain the continuous values for later use. During generalization, the
value of Pa,y,c for a continuous value y is interpolated between two other values of P, namely,
P a,x1,c and Pa,x2,c, where x 1  y  x2. IVDM and WVDM are essentially different techniques
for doing a nonparametric probability density estimation (Tapia & Thompson, 1978) to
determine the values of P for each class. A generic version of the VDM algorithm, called the
discretized value difference metric (DVDM) is used for comparisons with the two new
algorithms.

3. Heterogeneous Value Difference Metric (HVDM)
As discussed in the previous section, the Euclidean distance function is inappropriate for
nominal attributes, and VDM is inappropriate for continuous attributes, so neither is sufficient
on its own for use on a heterogeneous application, i.e., one with both nominal and continuous
attributes.
In this section, we define a heterogeneous distance function HVDM that returns the distance
between two input vectors x and y. It is defined as follows:
HVDM(x, y) =

m

 da2 (xa , ya )

(11)

a=1

where m is the number of attributes. The function da(x,y) returns a distance between the two
values x and y for attribute a and is defined as:
if x or y is unknown; otherwise...
1,

da (x, y) = normalized_ vdma (x, y), if a is nominal
 normalized_ diff (x, y), if a is linear
a


(12)

The function da(x,y) uses one of two functions (defined below in Section 3.1), depending on
whether the attribute is nominal or linear. Note that in practice the square root in (11) is not
typically performed because the distance is always positive, and the nearest neighbor(s) will still
be nearest whether or not the distance is squared. However, there are some models (e.g.,
distance-weighted k-nearest neighbor, Dudani, 1976) that require the square root to be
evaluated.
Many applications contain unknown input values which must be handled appropriately in a
practical system (Quinlan, 1989). The function da(x,y) therefore returns a distance of 1 if either
x or y is unknown, as is done by Aha, Kibler & Albert (1991) and Giraud-Carrier & Martinez
(1995). Other more complicated methods have been tried (Wilson & Martinez, 1993), but with
little effect on accuracy.
The function HVDM is similar to the function HOEM given in Section 2.3, except that it
8

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

uses VDM instead of an overlap metric for nominal values and it also normalizes differently. It
is also similar to the distance function used by RISE 2.0 (Domingos, 1995), but has some
important differences noted below in Section 3.2.
Section 3.1 presents three alternatives for normalizing the nominal and linear attributes.
Section 3.2 presents experimental results which show that one of these schemes provides better
normalization than the other two on a set of several datasets. Section 3.3 gives empirical results
comparing HVDM to two commonly-used distance functions.
3.1. Normalization
As discussed in Section 2.1, distances are often normalized by dividing the distance for each
variable by the range of that attribute, so that the distance for each input variable is in the range
0..1. This is the policy used by HEOM in Section 2.3. However, dividing by the range allows
outliers (extreme values) to have a profound effect on the contribution of an attribute. For
example, if a variable has values which are in the range 0..10 in almost every case but with one
exceptional (and possibly erroneous) value of 50, then dividing by the range would almost
always result in a value less than 0.2. A more robust alternative in the presence of outliers is to
divide the values by the standard deviation to reduce the effect of extreme values on the typical
cases.
For the new heterogeneous distance metric HVDM, the situation is more complicated
because the nominal and numeric distance values come from different types of measurements:
numeric distances are computed from the difference between two linear values, normalized by
standard deviation, while nominal attributes are computed from a sum of C differences of
probability values (where C is the number of output classes). It is therefore necessary to find a
way to scale these two different kinds of measurements into approximately the same range to
give each variable a similar influence on the overall distance measurement.
Since 95% of the values in a normal distribution fall within two standard deviations of the
mean, the difference between numeric values is divided by 4 standard deviations to scale each
value into a range that is usually of width 1. The function normalized_diff is therefore defined
as shown below in Equation 13:
normalized_ diff a (x, y) =

xy
4 a

(13)

where a is the standard deviation of the numeric values of attribute a.
Three alternatives for the function normalized_vdm were considered for use in the
heterogeneous distance function. These are labeled N1, N2 and N3, and the definitions of each
are given below:
N1: normalized_ vdm1a (x, y) =

C N
a,x,c



c=1

N2: normalized_ vdm2 a (x, y) =

C N
a,x,c



c=1

9

Na,x

Na,x



Na,y,c



Na,y,c

(14)

Na,y

Na,y

2

(15)

fiWILSON & MARTINEZ

C N
a,x,c

N3: normalized_ vdm3a (x, y) = C * 

c=1

Na,x



Na,y,c

2

(16)

Na,y

The function N1 is Equation (8) with q=1. This is similar to the formula used in PEBLS
(Rachlin et al., 1994) and RISE (Domingos, 1995) for nominal attributes.
N2 uses q=2, thus squaring the individual differences. This is analogous to using Euclidean
distance instead of Manhattan distance. Though slightly more expensive computationally, this
formula was hypothesized to be more robust than N1 because it favors having all of the class
correlations fairly similar rather than having some very close and some very different. N1
would not be able to distinguish between these two. In practice the square root is not taken,
because the individual attribute distances are themselves squared by the HVDM function.
N3 is the function used in Heterogeneous Radial Basis Function Networks (Wilson &
Martinez, 1996), where HVDM was first introduced.
3.2. Normalization Experiments
In order to determine whether each normalization scheme N1, N2 and N3 gave unfair weight to
either nominal or linear attributes, experiments were run on 15 databases from the machine
learning database repository at the University of California, Irvine (Merz & Murphy, 1996). All
of the datasets for this experiment have at least some nominal and some linear attributes, and
thus require a heterogeneous distance function.
In each experiment, five-fold cross validation was used. For each of the five trials, the
distance between each instance in the test set and each instance in the training set was
computed. When computing the distance for each attribute, the normalized_diff function was
used for linear attributes, and the normalized_vdm function N1, N2, or N3 was used (in each of
the three respective experiments) for nominal attributes.
The average distance (i.e., sum of all distances divided by number of comparisons) was
computed for each attribute. The average of all the linear attributes for each database was
computed and these averages are listed under the heading avgLin in Table 1.

Database
Anneal
Australian
Bridges
Crx
Echocardiogram
Flag
Heart
Heart.Cleveland
Heart.Hungarian
Heart.Long-Beach-VA
Heart.More
Heart.Swiss
Hepatitis
Horse-Colic
Soybean-Large
Average

avgLin
0.427
0.215
0.328
0.141
0.113
0.188
0.268
0.271
0.382
0.507
0.360
0.263
0.271
0.444
0.309
0.299

N1
avgNom
0.849
0.266
0.579
0.268
0.487
0.372
0.323
0.345
0.417
0.386
0.440
0.390
0.205
0.407
0.601
0.422

N2
avgNom
0.841
0.188
0.324
0.193
0.344
0.195
0.228
0.195
0.347
0.324
0.340
0.329
0.158
0.386
0.301
0.313

N3
avgNom
0.859
0.266
0.808
0.268
0.487
0.552
0.323
0.434
0.557
0.417
0.503
0.421
0.205
0.407
0.872
0.492

#Nom.
29
8
7
9
2
18
6
6
6
6
6
6
13
16
29
11

#Lin.
9
6
4
6
7
10
7
7
7
7
7
7
6
7
6
7

Table 1. Average attribute distance for linear and nominal attributes.
10

#C
6
2
7
2
2
8
2
5
5
5
5
5
2
2
19
5

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

Average distance

Average distance

Average distance

The averages of all the nominal attributes for each of the three normalization schemes are
listed under the headings avgNom in Table 1 as well. The average distance for linear
variables is exactly the same regardless of whether N1, N2 or N3 is used, so this average is
given only once. Table 1 also lists the number of nominal (#Nom.) and number of linear
(#Lin.) attributes in each database, along with the number of output classes (#C).
As can be seen from the overall averages in the first four columns of the last row of
Table 1, N2 is closer than N1 or N3. However, it is important to understand the reasons behind
this difference in order to know if the normalization scheme N2 will be more robust in general.
Figures 2-4 graphically display the averages shown in Table 1 under the headings N1, N2
and N3, respectively, ordered from left to right by the number of output classes. We
hypothesized that as the number of output classes grows, the normalization would get worse for
N3 if it was indeed not appropriate to add the scaling factor C to the sum. The length of each
line indicates how much difference there is between
the average distance for nominal attributes and
Nominal
1
linear attributes. An ideal normalization scheme
Linear
would have a difference of zero, and longer lines
.8
indicate worse normalization.
.6
As the number of output classes grows, the
.4
difference for N3 between the linear distances and
.2
the nominal distances grows wider in most cases.
N2, on the other hand, seems to remain quite close
0
2 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avg
independent of the number of output classes.
Number of output classes
Interestingly, N1 does almost as poorly as N3, even
Figure 2. Average distances for N1.
though it does not use the scaling factor C.
Apparently the squaring factor provides for a more
Nominal
1
well-rounded distance metric on nominal attributes
Linear
similar to that provided by using Euclidean distance
.8
instead of Manhattan distance on linear attributes.
.6
The underlying hypothesis behind performing
.4
normalization is that proper normalization will
.2
typically improve generalization accuracy. A
nearest neighbor classifier (with k =1) was
0
2 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avg
implemented using HVDM as the distance metric.
Number of output classes
The system was tested on the heterogeneous
Figure 3. Average distances for N2.
datasets appearing in Table 1 using the three
different normalization schemes discussed above,
1
Nominal
using ten-fold cross-validation (Schaffer, 1993), and
Linear
the results are summarized in Table 2. All the
.8
normalization schemes used the same training sets
.6
and test sets for each trial. Bold entries indicate
.4
which scheme had the highest accuracy. An
.2
asterisk indicates that the difference was greater that
1% over the next highest scheme.
0
2 2 2 2 2 2 5 5 5 5 5 6 7 8 19 Avg
As can be seen from the table, the normalization
Number of output classes
scheme N2 had the highest accuracy, and N1 was
Figure 4. Average distances for N3.
11

fiWILSON & MARTINEZ

substantially lower than the other two. N2
Database
N1
N2
N3
and N3 each had the highest accuracy for
Anneal
93.98
94.61 94.99
8 domains. More significantly, N2 was
Australian
71.30
81.45 81.59
Bridges
43.36
59.64 59.55
over 1% higher 5 times compared to N1
Crx
70.29
80.87 81.01
being over 1% higher on just one dataset.
Echocardiogram
70.36
94.82 94.82
N3 was higher than the other two on just
Flag
28.95
55.82* 51.50
Heart.Cleveland
73.88
76.56* 71.61
one dataset, and had a lower average
Heart.Hungarian
70.75
76.85* 75.82
accuracy than N2.
Heart.Long-Beach-Va
65.50
65.50 70.00*
These results support the hypothesis
Heart.More
60.03
72.09 72.48
Heart
88.46
89.49 89.49
that the normalization scheme N2
Heart.Swiss
74.81
78.52* 75.19
achieves higher generalization accuracy
Hepatitis
73.50
76.67 77.33
than N1 or N3 (on these datasets) due to
Horse-Colic
64.75* 60.53 60.53
Soybean-Large
41.45
90.88* 87.89
its more robust normalization though
Average
66.09
76.95 76.25
accuracy for N3 is almost as good as N2.
Note that proper normalization will not
Table 2. Generalization accuracy
using N1, N2 and N3.
always necessarily improve generalization
accuracy. If one attribute is more
important than the others in classification, then giving it a higher weight may improve
classification. Therefore, if a more important attribute is given a higher weight accidentally by
poor normalization, it may actually improve generalization accuracy. However, this is a
random improvement that is not typically the case. Proper normalization should improve
generalization in more cases than not when used in typical applications.
As a consequence of the above results, N2 is used as the normalization scheme for HVDM,
and the function normalized_vdm is defined as in (15).
3.3. Empirical Results of HVDM vs. Euclidean and HOEM
A nearest neighbor classifier (with k=1) using the three distance functions listed in Table 3 was
tested on 48 datasets from the UCI machine learning database repository. Of these 48 datasets,
the results obtained on the 35 datasets that have at least some nominal attributes are shown in
Table 3.
The results are approximately equivalent on datasets with only linear attributes, so the results
on the remaining datasets are not shown here, but can be found in Section 6. 10-fold crossvalidation was again used, and all three distance metrics used the same training sets and test sets
for each trial.
The results of these experiments are shown in Table 3. The first column lists the name of the
database (.test means the database was originally meant to be used as a test set, but was
instead used in its entirety as a separate database). The second column shows the results
obtained when using the Euclidean distance function normalized by standard deviation on all
attributes, including nominal attributes. The next column shows the generalization accuracy
obtained by using the HOEM metric, which uses range-normalized Euclidean distance for linear
attributes and the overlap metric for nominal attributes. The final column shows the accuracy
obtained by using the HVDM distance function which uses the standard-deviation-normalized
Euclidean distance (i.e., normalized_diff as defined in Equation 13) on linear attributes and the
normalized_vdm function N2 on nominal attributes.
The highest accuracy obtained for each database is shown in bold. Entries in the Euclid. and
12

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

HOEM columns that are significantly
higher than HVDM (at a 90% or higher
confidence level, using a two-tailed
paired t test) are marked with an
asterisk (*).
Entries that are
significantly lower than HVDM are
marked with a less-than sign (<).
As can be seen from Table 3, the
HVDM distance functions overall
average accuracy was higher than that
of the other two metrics by over 3%.
HVDM achieved as high or higher
generalization accuracy than the other
two distance functions in 21 of the 35
datasets. The Euclidean distance
function was highest in 18 datasets,
and HOEM was highest in only 12
datasets.
HVDM was significantly higher
than the Euclidean distance function on
10 datasets, and significantly lower on
only 3. Similarly, HVDM was higher
than HOEM on 6 datasets, and
significantly lower on only 4.
These results support the hypothesis
that HVDM handles nominal attributes
more appropriately than Euclidean
distance or the heterogeneous
Euclidean-overlap metric, and thus
tends to achieve higher generalization
accuracy on typical applications.

Database
Euclid.
Anneal
94.99
Audiology
60.50 <
Audiology.Test
41.67 <
Australian
80.58
Bridges
58.64
Crx
78.99
Echocardiogram
94.82
Flag
48.95 <
Heart.Cleveland
73.94
Heart.Hungarian
73.45 <
Heart.Long-Beach-Va 71.50
Heart.More
72.09
Heart.Swiss
93.53 *
Hepatitis
77.50
Horse-Colic
65.77
House-Votes-84
93.12 <
Image.Segmentation
92.86
Led+17
42.90 <
Led-Creator
57.20 *
Monks-1.Test
77.08
Monks-2.Test
59.04 <
Monks-3.Test
87.26 <
Mushroom
100.00
Promoters
73.73 <
Soybean-Large
87.26 <
Soybean-Small
100.00
Thyroid.Allbp
94.89
Thyroid.Allhyper
97.00
Thyroid.Allhypo
90.39
Thyroid.Allrep
96.14
Thyroid.Dis
98.21
Thyroid.Hypothyroid 93.42
Thyroid.Sick-Euthyroid 68.23
Thyroid.Sick
86.93 *
Zoo
97.78
Average:
79.44

HOEM
94.61
72.00 <
75.00
81.16
53.73
81.01
94.82
48.84
74.96
74.47
71.00 *
71.90
91.86
77.50
60.82
93.12 <
93.57
42.90 <
57.20 *
69.43
54.65 <
78.49 <
100.00
82.09 <
89.20
100.00
94.89
97.00
90.39 *
96.14
98.21
93.42
68.23
86.89 *
94.44
80.11

HVDM
94.61
77.50
78.33
81.45
59.64
80.87
94.82
55.82
76.56
76.85
65.50
72.09
89.49
76.67
60.53
95.17
92.86
60.70
56.40
68.09
97.50
100.00
100.00
92.36
90.88
100.00
95.00
96.86
90.29
96.11
98.21
93.36
68.23
86.61
98.89
83.38

Table 3. Generalization accuracy of the
Euclidean, HOEM, and HVDM distance functions.

4. Interpolated Value Difference Metric (IVDM)
In this section and Section 5 we introduce distance functions that allow VDM to be applied
directly to continuous attributes. This alleviates the need for normalization between attributes.
It also in some cases provides a better measure of distance for continuous attributes than linear
distance.
For example, consider an application with an input attribute height and an output class that
indicates whether a person is a good candidate to be a fighter pilot in a particular airplane.
Those individuals with heights significantly below or above the preferred height might both be
considered poor candidates, and thus it could be beneficial to consider their heights as more
similar to each other than to those of the preferred height, even though they are farther apart in a
linear sense.

13

fiWILSON & MARTINEZ

On the other hand, linear attributes for which linearly distant values tend to indicate different
classifications should also be handled appropriately. The Interpolated Value Difference Metric
(IVDM) handles both of these situations, and handles heterogeneous applications robustly.
A generic version of the VDM distance function, called the discretized value difference
metric (DVDM) will be used for comparisons with extensions of VDM presented in this paper.
4.1. IVDM Learning Algorithm
The original value difference metric (VDM) uses statistics derived from the training set
instances to determine a probability Pa,x,c that the output class is c given the input value x for
attribute a.
When using IVDM, continuous values are discretized into s equal-width intervals (though
the continuous values are also retained for later use), where s is an integer supplied by the user.
Unfortunately, there is currently little guidance on what value of s to use. A value that is too
large will reduce the statistical strength of the values of P, while a value too small will not allow
for discrimination among classes. For the purposes of this paper, we use a heuristic to
determine s automatically: let s be 5 or C, whichever is greatest, where C is the number of
output classes in the problem domain. Current research is examining more sophisticated
techniques for determining good values of s, such as cross-validation, or other statistical
methods (e.g., Tapia & Thompson, 1978, p. 67). (Early experimental results indicate that the
value of s may not be critical as long as s  C and s  n, where n is the number of instances in
the training set.)
The width wa of a discretized interval for attribute a is given by:
wa =

maxa  mina
s

(17)

where max a and mina are the maximum and minimum value, respectively, occurring in the
training set for attribute a.
As an example, consider the Iris database from the UCI machine learning databases. The
Iris database has four continuous input attributes, the first of which is sepal length. Let T be a
training set consisting of 90% of the 150 available training instances, and S be a test set
consisting of the remaining 10%.
In one such division of the training set, the values in T for the sepal length attribute ranged
from 4.3 to 7.9. There are only three output classes in this database, so we let s=5, resulting in a
width of |7.9 - 4.3| / 5 = 0.72. Note that since the discretization is part of the learning process, it
would be unfair to use any instances in the test set to help determine how to discretize the
values. The discretized value v of a continuous value x for attribute a is an integer from 1 to s,
and is given by:
 x, if a is discrete, else

v = discretizea (x) =  s, if x = max a , else
 (x  min ) / w + 1
a
a


(18)

After deciding upon s and finding w a, the discretized values of continuous attributes can be
14

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

used just like discrete values of nominal attributes in finding Pa,x,c. Figure 5 lists pseudo-code
for how this is done.
LearnP(training set T)
For each attribute a
For each instance i in T
Let x be the input value for attribute a of instance i.
v = discretizea(x) [which is just x if a is discrete]
Let c be the output class of instance i.
Increment Na,v,c by 1.
Increment Na,v by 1.
For each discrete value v (of attribute a)
For each class c
If Na,v=0
Then Pa,v,c=0
Else Pa,v,c = Na,v,c / Na,v
Return 3-D array Pa,v,c.

Figure 5. Pseudo code for finding Pa,x,c.

Probability

For the first attribute of the Iris database, the values of Pa,x,c are displayed in Figure 6. For
each of the five discretized ranges of x, the probability for each of the three corresponding
output classes are shown as the bar heights. Note that the heights of the three bars sum to 1.0
for each discretized range. The bold integers indicate the discretized value of each range. For
example, a sepal length greater than or equal to 5.74 but less than 6.46 would have a discretized
value of 3.
1.0

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

.867

Output Class:
1. Iris
Setosa

.609
.485
.455

.100
.033
4.3

1

5.02

.474 .500

3. Iris
Viginica

.061 .026

2

2. Iris
Versicolor

.391

0.0

3

5.74

6.46

4

Sepal Length (in cm)

0.0 0.0
7.18 5

7.9

Bold =
discretized
range number.

Figure 6. Pa,x,c for a=1, x=1..5, c=1..3, on the first attribute of the Iris database.
4.2. IVDM and DVDM Generalization
Thus far the DVDM and IVDM algorithms learn identically. However, at this point the DVDM
algorithm need not retain the original continuous values because it will use only the discretized
values during generalization. On the other hand, the IVDM will use the continuous values.
During generalization, an algorithm such as a nearest neighbor classifier can use the distance
function DVDM, which is defined as follows:
DVDM(x, y) =

m

 vdma (discretizea (xa ), discretizea (ya ))

a=1

15

2

(19)

fiWILSON & MARTINEZ

where discretizea is as defined in Equation (18) and vdma is defined as in Equation (8), with
q=2. We repeat it here for convenience:
vdma (x, y) =

C

 Pa,x,c  Pa,y,c

2

(20)

c=1

Unknown input values (Quinlan, 1989) are treated as simply another discrete value, as was done
in (Domingos, 1995).

A:
B:

1
5.0
5.7

y:

5.1

Input Attributes
2
3
3.6
1.4
2.8
4.5
3.8

1.9

4
0.2
1.3

->
->

Output Class
1 (Iris Setosa)
2 (Iris Versicolor)

0.4

Table 4. Example from the Iris database.
As an example, consider two training instances A and B as shown in Table 4, and a new
input vector y to be classified. For attribute a=1, the discretized values for A, B, and y are 1, 2,
and 2, respectively. Using values from Figure 6, the distance for attribute 1 between y and A is:
|.867-.485|2 + |.1-.455|2 + |.033-.061|2 = .273

Probability of Class 2

while the distance between y and B is 0, since they have the same discretized value.
Note that y and B have values on different ends of range 2, and are not actually nearly as
close as y and A are. In spite of this fact, the discretized distance function says that y and B are
equal because they happen to fall into the same discretized range.
IVDM uses interpolation to alleviate such problems. IVDM assumes that the Pa,x,c values
hold true only at the midpoint of each range, and interpolates between midpoints to find P for
other attribute values.
Figure 7 shows the P values for the second output class (Iris Versicolor) as a function of the
first attribute value (sepal length). The dashed line indicates what P value is used by DVDM,
and the solid line shows what IVDM uses.
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Center
points
DVDM
IVDM

4

4.3

1

5.02 2

5.74 3 6.46 4
7.18 5
Sepal Length (in cm)

7.9

Bold =
discretized
range number.

Figure 7. P1,x,2 values from the DVDM and IVDM for attribute 1, class 2 of the Iris database.
16

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

The distance function for the Interpolated Value Difference Metric is defined as:
IVDM(x, y) =

m

 ivdma (xa , ya )2

(21)

a=1

where ivdma is defined as:
if a is discrete
 vdma (x, y),
C
2
ivdma (x, y) = 
p (x)  pa,c (y) , otherwise
  a,c
c=1

(22)

The formula for determining the interpolated probability value pa,c(x) of a continuous value x
for attribute a and class c is:


x  mida,u
pa,c (x) = Pa,u,c + 
 * (Pa,u+1,c  Pa,u,c )
 mida,u+1  mida,u 

(23)

In this equation, mida,u and mida,u+1 are midpoints of two consecutive discretized ranges such
that mida,u  x < mida,u+1. Pa,u,c is the probability value of the discretized range u, which is
taken to be the probability value of the midpoint of range u (and similarly for Pa,u+1,c). The
value of u is found by first setting u = discretizea(x), and then subtracting 1 from u if x < mida,u.
The value of mida,u can then be found as follows:
mida,u = mina + widtha * (u+.5)

(24)

Probability of Class

Figure 8 shows the values of pa,c(x) for attribute a=1 of the Iris database for all three output
classes (i.e. c=1, 2, and 3). Since there are no data points outside the range mina..maxa, the
probability value Pa,u,c is taken to be 0 when u < 1 or u > s, which can be seen visually by the
diagonal lines sloping toward zero on the outer edges of the graph. Note that the sum of the
probabilities for the three output classes sum to 1.0 at every point from the midpoint of range 1
through the midpoint of range 5.
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Output Class:
1. Iris Setosa
2. Iris Versicolor
3. Iris Viginica

4

4.3

1

5.02 2

5.74 3 6.46 4
7.18 5
Sepal Length (in cm)

7.9

Bold =
discretized
range number.

Figure 8. Interpolated probability values for attribute 1 of the Iris database.
17

fiWILSON & MARTINEZ

A
B

value
5.0
5.7

p1,1 (v)
.687
.281

p1,2 (v)
.268
.463

p1,3 (v)
.046
.256

y

5.1

.634

.317

.050

ivdm1(v,y)
.005
.188

vdm1(v,y)
.273
0

Table 5. Example of ivdm vs. vdm.
Using IVDM on the example instances in Table 4, the values for the first attribute are not
discretized as they are with DVDM, but are used to find interpolated probability values. In that
example, y has a value of 5.1, so p1,c(x) interpolates between midpoints 1 and 2, returning the
values shown in Table 5 for each of the three classes. Instance A has a value of 5.0, which also
falls between midpoints 1 and 2, but instance B has a value of 5.7, which falls between
midpoints 2 and 3.
As can be seen from Table 5, IVDM (using the single-attribute distance function ivdm)
returns a distance which indicates that y is closer to A than B (for the first attribute), which is
certainly the case here. DVDM (using the
discretized vdm), on the other hand, returns
Database
DVDM
IVDM
Annealing
94.99
96.11 *
a distance which indicates that the value of
Australian
83.04 *
80.58
y is equal to that of B, and quite far from A,
Bridges
56.73
60.55
illustrating the problems involved with
Credit Screening
80.14
80.14
Echocardiogram
100.00
100.00
using discretization.
Flag
58.76
57.66
The IVDM and DVDM algorithms were
Glass
56.06
70.54 *
implemented and tested on 48 datasets
Heart Disease
80.37
81.85
Heart (Cleveland)
79.86
78.90
from the UCI machine learning databases.
Heart
(Hungarian)
81.30
80.98
The results for the 34 datasets that contain
Heart (Long-Beach-Va) 71.00
66.00
at least some continuous attributes are
Heart (More)
72.29
73.33
shown in Table 6. (Since IVDM and
Heart (Swiss)
88.59
87.88
Hepatitis
80.58
82.58
DVDM are equivalent on domains with
Horse-Colic
76.75
76.78
only discrete attributes, the results on the
Image Segmentation
92.38
92.86
remaining datasets are deferred to Section
Ionosphere
92.60
91.17
Iris
92.00
94.67
6.) 10-fold cross-validation was again
Liver Disorders
55.04
58.23
used, and the average accuracy for each
Pima Indians Diabetes
71.89
69.28
database over all 10 trials is shown in
Satellite Image
87.06
89.79 *
Shuttle
96.17
99.77 *
Table 6. Bold values indicate which value
Sonar
78.45
84.17
was highest for each dataset. Asterisks (*)
Thyroid (Allbp)
94.86
95.32
indicates that the difference is statistically
Thyroid (Allhyper)
96.93
97.86 *
Thyroid (Allhypo)
89.36
96.07 *
significant at a 90% confidence level or
Thyroid (Allrep)
96.86
98.43 *
higher, using a two-tailed paired t-test.
Thyroid (Dis)
98.29
98.04
On this set of datasets, IVDM had a
Thyroid (Hypothyroid)
93.01
98.07 *
higher average generalization accuracy
Thyroid (Sick)
88.24
95.07 *
Thyroid (Sick-Euthyroid) 88.82
96.86 *
overall than the discretized algorithm.
Vehicle
63.72
69.27 *
IVDM obtained higher generalization
Vowel
91.47
97.53 *
accuracy than DVDM in 23 out of 34
Wine
94.38
97.78 *
Average:
83.08
85.22
cases, 13 of which were significant at the
90% level or above. DVDM had a higher
Table 6. Generalization for DVDM vs. IVDM.
18

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

accuracy in 9 cases, but only one of those had a difference that was statistically significant.
These results indicate that the interpolated distance function is typically more appropriate
than the discretized value difference metric for applications with one or more continuous
attributes. Section 6 contains further comparisons of IVDM with other distance functions.

5. Windowed Value Difference Metric (WVDM)
The IVDM algorithm can be thought of as sampling the value of Pa,u,c at the midpoint mida,u of
each discretized range u. P is sampled by first finding the instances that have a value for
attribute a in the range mida,u  w a / 2. Na,u is incremented once for each such instance, and
N a,u,c is also incremented for each instance whose output class is c, after which
P a,u,c = Na,u,c / Na,u is computed. IVDM then interpolates between these sampled points to
provide a continuous but rough approximation to the function pa,c(x). It is possible to sample P
at more points and thus provide a closer approximation to the function pa,c(x), which may in
turn provide for more accurate distance measurements between values.
Figure 9 shows pseudo-code for the Windowed Value Difference Metric (WVDM). The
WVDM samples the value of P a,x,c at each value x occurring in the training set for each
Define:
instance[a][1..n] as the list of all n instances in T sorted in ascending order by attribute a.
instance[a][i].val[a] as the value of attribute a for instance[a][i].
x
as the center value of the current window, i.e., x=instance[a][i].val[a].
p[a][i][c]
as the probability Pa,x,c that the output class is c given the input value x for
attribute a. Note that i is an index, the not value itself.
N[c]
as the number Na,x,c of instances in the current window with output class c.
N
as the total number Na,x of instances in the current window.
instance[a][in] as the first instance in the window.
instance[a][out] as the first instance outside the window. (i.e., the window contains
instances instance[a][in..out-1]).
w[a]
as the window width for attribute a.
LearnWVDM(training set T)
For each continuous attribute a
Sort instance[a][1..n] in ascending order by attribute a, using a quicksort.
Initialize N and N[c] to 0, and in and out to 1 (i.e., start with an empty window).
For each i=1..n
Let x=instance[a][i].val[a].
// Expand window to include all instances in range
While (out < n) and (instance[a][out].val[a] < (x + w[a]/2))
Increment N[c], where c=the class of instance[a][out].
Increment N.
Increment out.
// Shrink window to exclude instances no longer in range
While (in < out) and (instance[a][in].val[a] < (x - w[a]/2))
Decrement N[c], where c=the class of instance[a][in].
Decrement N.
Increment in.
// Compute the probability value for each class from the current window
for each class c=1..C
p[a][i][c] = N[c] / N. (i.e., Pa,x,c = Na,x,c / Na,x).
Return the 3-D array p[a][i][c].

Figure 9. Pseudo code for the WVDM learning algorithm.
19

fiWILSON & MARTINEZ

attribute a, instead of only at the midpoints of each range. In fact, the discretized ranges are not
even used by WVDM on continuous attributes, except to determine an appropriate window
width, wa, which is the same as the range width used in DVDM and IVDM. The pseudo-code
for the learning algorithm used to determine Pa,x,c for each attribute value x is given in Figure 9.
For each value x occurring in the training set for attribute a, P is sampled by finding the
instances that have a value for attribute a in the range x  w a / 2, and then computing Na,x,
Na,x,c, and Pa,x,c = Na,x,c / Na,x as before. Thus, instead of having a fixed number s of sampling
points, a window of instances, centered on each training instance, is used for determining the
probability at a given point. This technique is similar in concept to shifted histogram estimators
(Rosenblatt, 1956) and to Parzen window techniques (Parzen, 1962).
For each attribute the values are sorted (using an O(nlogn) sorting algorithm) so as to allow a
sliding window to be used and thus collect the needed statistics in O(n) time for each attribute.
The sorted order is retained for each attribute so that a binary search can be performed in O(log
n) time during generalization.
Values occurring between the sampled points are interpolated just as in IVDM, except that
there are now many more points available, so a new value will be interpolated between two
closer, more precise values than with IVDM.
WVDM_Find_P(attribute a,continuous value x)
// Find Pa,x,c for c=1..C, given a value x for attribute a.
Find i such that instance[a][i].val[a]  x  instance[a][i+1].val[a] (binary search).
x1 = instance[a][i].val[a]
(unless i<1, in which case x1=min[a] - (w[a] / 2))
x2 = instance[a][i+1].val[a] (unless i>n, in which case x2=max[a] + (w[a] / 2))
For each class c=1..C
p1=p[a][i][c]
(unless i<1, in which case p1=0)
p2=p[a][i+1][c] (unless i>n, in which case p2=0)
Pa,x,c = p1 + ((x-x1)/(x2-x1)) * (p2 - p1)
Return array Pa,x,1..C.

Figure 10. Pseudo-code for the WVDM probability interpolation (see Figure 9 for definitions).
The pseudo-code for the interpolation algorithm is given in Figure 10. This algorithm takes
a value x for attribute a and returns a vector of C probability values Pa,x,c for c=1..C. It first
does a binary search to find the two consecutive instances in the sorted list of instances for
attribute a that surround x. The probability for each class is then interpolated between that
stored for each of these two surrounding instances. (The exceptions noted in parenthesis handle
outlying values by interpolating towards 0 as is done in IVDM.)
Once the probability values for each of an input vectors attribute values are computed, they
can be used in the vdm function just as the discrete probability values are.
The WVDM distance function is defined as:
WVDM(x, y) =

m

 wvdma (xa , ya )2

(25)

a=1

and wvdma is defined as:
if a is discrete
vdma (x, y),
 C
2
wvdma (x, y) = 
P
 Pa,y,c , otherwise
  a,x,c
 c=1

20

(26)

fiProbability of Class

IMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Output Class:
1. Iris Setosa
2. Iris Versicolor
3. Iris Viginica

4

5

6

7

8

Sepal Length (in cm)

Figure 11. Example of the WVDM probability landscape.
where Pa,x,c is the interpolated probability value for the continuous value x as computed in
Figure 10. Note that we are typically finding the distance between a new input vector and an
instance in the training set. Since the
instances in the training set were used to
Database
DVDM WVDM
define the probability at each of their attribute
Annealing
94.99
95.87
Australian
83.04
82.46
values, the binary search and interpolation is
Bridges
56.73
56.64
unnecessary for training instances because
Credit Screening
80.14
81.45
they can immediately recall their stored
Echocardiogram
100.00
98.57
probability values, unless pruning techniques
Flag
58.76
58.74
Glass
56.06
71.49 *
have been used.
Heart Disease
80.37
82.96
One drawback to this approach is the
Heart (Cleveland)
79.86
80.23
increased storage needed to retain C
Heart (Hungarian)
81.30
79.26
Heart (Long-Beach-Va) 71.00
68.00
probability values for each attribute value in
Heart (More)
72.29
73.33
the training set. Execution time is not
Heart (Swiss)
88.59
88.72
significantly increased over IVDM or
Hepatitis
80.58
79.88
Horse-Colic
76.75
74.77
DVDM. (See Section 6.2 for a discussion on
Image
Segmentation
92.38
93.33
efficiency considerations).
Ionosphere
92.60
91.44
Figure 11 shows the probability values for
Iris
92.00
96.00
Liver Disorders
55.04
57.09
each of the three classes for the first attribute
Pima Indians Diabetes
71.89
70.32
of the Iris database again, this time using the
Satellite Image
87.06
89.33 *
windowed sampling technique. Comparing
Shuttle
96.17
99.61 *
Figure 11 with Figure 8 reveals that on this
Sonar
78.45
84.19
Thyroid (Allbp)
94.86
95.29
attribute IVDM provides approximately the
Thyroid (Allhyper)
96.93
97.50
same overall shape, but misses much of the
Thyroid (Allhypo)
89.36
90.18
detail. For example, the peak occurring for
Thyroid (Allrep)
96.86
97.07
Thyroid (Dis)
98.29
98.00
output class 2 at approximately sepal
Thyroid (Hypothyroid)
93.01
96.96 *
length=5.75. In Figure 8 there is a flat line
Thyroid (Sick)
88.24
97.11 *
which misses this peak entirely, due mostly to
Thyroid (Sick-Euthyroid) 88.82
94.40 *
Vehicle
63.72
65.37 *
the somewhat arbitrary position of the
Vowel
91.47
96.21 *
midpoints at which the probability values are
Wine
94.38
97.22 *
sampled.
Average:
83.08
84.68
Table 7 summarizes the results of testing
Table 7. Generalization of WVDM vs. DVDM.
21

fiWILSON & MARTINEZ

the WVDM algorithm on the same datasets as DVDM and IVDM. A bold entry again indicates
the highest of the two accuracy measurements, and an asterisk (*) indicates a difference that is
statistically significant at the 90% confidence level, using a two-tailed paired t-test.
On this set of databases, WVDM was an average of 1.6% more accurate than DVDM
overall. WVDM had a higher average accuracy than DVDM on 23 out of the 34 databases, and
was significantly higher on 9, while DVDM was only higher on 11 databases, and none of those
differences were statistically significant.
Section 6 provides further comparisons of WVDM with other distance functions, including
IVDM.

6. Empirical Comparisons and Analysis of Distance Functions
This section compares the distance functions discussed in this paper. A nearest neighbor
classifier was implemented using each of six different distance functions: Euclidean
(normalized by standard deviation) and HOEM as discussed in Section 2; HVDM as discussed
in Section 3; DVDM and IVDM as discussed in Section 4; and WVDM as discussed in Section
5. Figure 12 summarizes the definition of each distance function.
All functions use the same
overall distance function:

D(x, y) =

m

 da (xa , ya )2

a=1

Distance
Function
Euclidean

Definition of da(xa,ya) for each attribute type:
Linear
Continuous
Discrete Nominal
xa  ya
xa  ya
a
a

HOEM

xa  ya
rangea

0 if xa = ya
1 if xa  ya

HVDM

xa  ya
4 a

vdma (xa , ya )

DVDM

vdma(disca(xa),disca(ya))

vdma (xa , ya )

IVDM

ivdma(xa,ya)
Interpolate probabilities
from range midpoints.

vdma (xa , ya )

WVDM

wvdma(xa,ya)
Interpolate probabilities
from adjacent values.

vdma (xa , ya )

where rangea = maxa  mina , and vdma (x, y) =

C

 Pa,x,c  Pa,y,c

2

c=1

Figure 12. Summary of distance function definitions.
Each distance function was tested on 48 datasets from the UCI machine learning databases,
22

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

again using 10-fold cross-validation. The average accuracy over all 10 trials is reported for
each test in Table 8. The highest accuracy achieved for each dataset is shown in bold. The
names of the three new distance functions presented in this paper (HVDM, IVDM and WVDM)
are also shown in bold to identify them.
Table 8 also lists the number of instances in each database (#Inst.), and the number of
continuous (Con), integer (Int, i.e., linear discrete), and nominal (Nom) input attributes.
D i s t
Database
Euclid HOEM
Annealing
94.99
94.61
Audiology
60.50
72.00
Audiology (test)
41.67
75.00
Australian
80.58
81.16
Breast Cancer
94.99
95.28
Bridges
58.64
53.73
Credit Screening
78.99
81.01
Echocardiogram
94.82
94.82
Flag
48.95
48.84
Glass
72.36
70.52
Heart Disease
72.22
75.56
Heart (Cleveland)
73.94
74.96
Heart (Hungarian)
73.45
74.47
Heart (Long-Beach-Va)
71.50
71.00
Heart (More)
72.09
71.90
Heart (Swiss)
93.53
91.86
Hepatitis
77.50
77.50
Horse-Colic
65.77
60.82
House-Votes-84
93.12
93.12
Image Segmentation
92.86
93.57
Ionosphere
86.32
86.33
Iris
94.67
95.33
LED+17 noise
42.90
42.90
LED
57.20
57.20
Liver Disorders
62.92
63.47
Monks-1
77.08
69.43
Monks-2
59.04
54.65
Monks-3
87.26
78.49
Mushroom
100.00 100.00
Pima Indians Diabetes
71.09
70.31
Promoters
73.73
82.09
Satellite Image
90.21
90.24
Shuttle
99.78
99.78
Sonar
87.02
86.60
Soybean (Large)
87.26
89.20
Soybean (Small)
100.00 100.00
Thyroid (Allbp)
94.89
94.89
Thyroid (Allhyper)
97.00
97.00
Thyroid (Allhypo)
90.39
90.39
Thyroid (Allrep)
96.14
96.14
Thyroid (Dis)
98.21
98.21
Thyroid (Hypothyroid)
93.42
93.42
Thyroid (Sick-Euthyroid) 68.23
68.23
Thyroid (Sick)
86.93
86.89
Vehicle
70.93
70.22
Vowel
99.24
98.86
Wine
95.46
95.46
Zoo
97.78
94.44
Average:
80.78
81.29

a n c e
HVDM
94.61
77.50
78.33
81.45
94.99
59.64
80.87
94.82
55.82
72.36
78.52
76.56
76.85
65.50
72.09
89.49
76.67
60.53
95.17
92.86
86.32
94.67
60.70
56.40
62.92
68.09
97.50
100.00
100.00
71.09
92.36
90.21
99.78
87.02
90.88
100.00
95.00
96.86
90.29
96.11
98.21
93.36
68.23
86.61
70.93
99.24
95.46
98.89
83.79

F u n
DVDM
94.99
77.50
78.33
83.04
95.57
56.73
80.14
100.00
58.76
56.06
80.37
79.86
81.30
71.00
72.29
88.59
80.58
76.75
95.17
92.38
92.60
92.00
60.70
56.40
55.04
68.09
97.50
100.00
100.00
71.89
92.36
87.06
96.17
78.45
92.18
100.00
94.86
96.93
89.36
96.86
98.29
93.01
88.24
88.82
63.72
91.47
94.38
98.89
84.06

c t i o n
# of inputs
IVDM WVDM #Inst. Con Int Nom
96.11
95.87
798
6 3
29
77.50
77.50
200
0 0
69
78.33
78.33
26
0 0
69
80.58
82.46
690
6 0
8
95.57
95.57
699
0 9
0
60.55
56.64
108
1 3
7
80.14
81.45
690
6 0
9
100.00
98.57
132
7 0
2
57.66
58.74
194
3 7
18
70.54
71.49
214
9 0
0
81.85
82.96
270
5 2
6
78.90
80.23
303
5 2
6
80.98
79.26
294
5 2
6
66.00
68.00
200
5 2
6
73.33
73.33 1541
5 2
6
87.88
88.72
123
5 2
6
82.58
79.88
155
6 0
13
76.78
74.77
301
7 0
16
95.17
95.17
435
0 0
16
92.86
93.33
420 18 0
1
91.17
91.44
351 34 0
0
94.67
96.00
150
4 0
0
60.70
60.70 10000
0 0
24
56.40
56.40 1000
0 0
7
58.23
57.09
345
6 0
0
68.09
68.09
432
0 0
6
97.50
97.50
432
0 0
6
100.00 100.00
432
0 0
6
100.00 100.00 8124
0 1
21
69.28
70.32
768
8 0
0
92.36
92.36
106
0 0
57
89.79
89.33 4435 36 0
0
99.77
99.61 9253
9 0
0
84.17
84.19
208 60 0
0
92.18
92.18
307
0 6
29
100.00 100.00
47
0 6
29
95.32
95.29 2800
6 0
22
97.86
97.50 2800
6 0
22
96.07
90.18 2800
6 0
22
98.43
97.07 2800
6 0
22
98.04
98.00 2800
6 0
22
98.07
96.96 3163
7 0
18
95.07
94.40 3163
7 0
18
96.86
97.11 2800
6 0
22
69.27
65.37
846 18 0
0
97.53
96.21
528 10 0
0
97.78
97.22
178 13 0
0
98.89
98.89
90
0 0
16
85.56
85.24

Table 8. Summary of Generalization Accuracy

23

fiWILSON & MARTINEZ

On this set of 48 datasets, the three new distance functions (HVDM, IVDM and WVDM) did
substantially better than Euclidean distance or HOEM. IVDM had the highest average accuracy
(85.56%) and was almost 5% higher on average than Euclidean distance (80.78%), indicating
that it is a more robust distance function on these datasets, especially those with nominal
attributes. WVDM was only slightly lower than IVDM with 85.24% accuracy. Somewhat
surprisingly, DVDM was slightly higher than HVDM on these datasets, even though it uses
discretization instead of a linear distance on continuous attributes. All four of the VDM-based
distance functions outperformed Euclidean distance and HOEM.
Out of the 48 datasets, Euclidean distance had the highest accuracy 11 times; HOEM was
highest 7 times; HVDM, 14; DVDM, 19; IVDM, 25 and WVDM, 18.
For datasets with no continuous attributes, all four of the VDM-based distance functions
(HVDM, DVDM, IVDM and WVDM) are equivalent. On such datasets, the VDM-based
distance functions achieve an average accuracy of 86.6% compared to 78.8% for HOEM and
76.6% for Euclidean, indicating a substantial superiority on such problems.
For datasets with no nominal attributes, Euclidean and HVDM are equivalent, and all the
distance functions perform about the same on average except for DVDM, which averages about
4% less than the others, indicating the detrimental effects of discretization. Euclidean and
HOEM have similar definitions for applications without any nominal attributes, except that
Euclidean is normalized by standard deviation while HOEM is normalized by the range of each
attribute. It is interesting that the average accuracy over these datasets is slightly higher for
Euclidean than HOEM, indicating that the standard deviation may provide better normalization
on these datasets. However, the difference is small (less than 1%), and these datasets do not
contain many outliers, so the difference is probably negligible in this case.
One disadvantage with scaling attributes by the standard deviation is that attributes which
almost always have the same value (e.g., a boolean attribute that is almost always 0) will be
given a large weightnot due to scale, but because of the relative frequencies of the attribute
values. A related problem can occur in HVDM. If there is a very skewed class distribution
(i.e., there are many more instances of some classes than others), then the P values will be quite
small for some classes and quite large for others, and in either case the difference |Pa,x,c - Pa,y,c|
will be correspondingly small, and thus nominal attributes will get very little weight when
compared to linear attributes. This phenomenon was noted by Ting (1994, 1996), where he
recognized such problems on the hypothyroid dataset. Future research will address these
normalization problems and look for automated solutions. Fortunately, DVDM, IVDM and
WVDM do not suffer from either problem, because all attributes are scaled by the same amount
in such cases, which may in part account for their success over HVDM in the above
experiments.
For datasets with both nominal and continuous attributes, HVDM is slightly higher than
Euclidean distance on these datasets, which is in turn slightly higher than HOEM, indicating
that the overlap metric may not be much of an improvement on heterogeneous databases.
DVDM, IVDM and WVDM are all higher than Euclidean distance on such datasets, with
IVDM again in the lead.
6.1. Effects of Sparse Data
Distance functions that use VDM require some statistics to determine distance. We therefore
hypothesized that generalization accuracy might be lower for VDM-based distance functions
24

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

than for Euclidean distance or HOEM when there was very little data available, and that VDMbased functions would increase in accuracy more slowly than the others as more instances were
made available, until a sufficient number of instances allowed a reasonable sample size to
determine good probability values.

85.00

%Average Generalization Accuracy

80.00

75.00

Euclidean
70.00
HOEM
HVDM

65.00

DVDM
IVDM

60.00

WVDM
55.00
0

20

40
60
%Instances Used

80

100

Figure 13. Average accuracy as the amount of data increases.
To test this hypothesis, the experiments used to obtain the results shown in Table 8 were
repeated using only part of the available training data. Figure 13 shows how the generalization
accuracy on the test set improves as the percentage of available training instances used for
learning and generalization is increased from 1% to 100%. The generalization accuracy values
shown are the averages over all 48 of the datasets in Table 8.
Surprisingly, the VDM-based distance functions increased in accuracy as fast or faster than
Euclidean and HOEM even when there was very little data available. It may be that when there
is very little data available, the random positioning of the sample data in the input space has a
greater detrimental affect on accuracy than does the error in statistical sampling for VDM-based
functions.
It is interesting to note from Figure 13 that the six distance functions seem to pair up into
three distinct pairs. The interpolated VDM-based distance functions (IVDM and WVDM)
maintain the highest accuracy, the other two VDM-based functions are next, and the functions
based only on linear and overlap distance remain lowest from very early in the graph.
25

fiWILSON & MARTINEZ

6.2. Efficiency Considerations
This section considers the storage requirements, learning speed, and generalization speed of
each of the algorithms presented in this paper.
6.2.1. STORAGE
All of the above distance functions must store the entire training set, requiring O(nm) storage,
where n is the number of instances in the training set and m is the number of input attributes in
the application, unless some instance pruning technique is used. For the Euclidean and HOEM
functions, this is all that is necessary, but even this amount of storage can be restrictive as n
grows large.
For HVDM, DVDM, and IVDM, the probabilities Pa,x,c for all m attributes (only discrete
attributes for HVDM) must be stored, requiring O(mvC) storage, where v is the average number
of attribute values for the discrete (or discretized) attributes and C is the number of output
classes in the application. It is possible to instead store an array Da,x,y = vdma(x,y) for HVDM
and DVDM, but the storage would be O(mv2), which is only a savings when C < v.
For WVDM, C probability values must be stored for each continuous attribute value,
resulting in O(nmC) storage which is typically much larger than O(mvC) because n is usually
much larger than v (and cannot be less). It is also necessary to store a list of (pointers to)
instances for each attribute, requiring an additional O(mn) storage. Thus the total storage for
WVDM is O((C+2)nm) = O(Cnm).
Distance Function
Euclidean
HOEM
HVDM
DVDM
IVDM
WVDM

Storage
O(mn)
O(mn)
O(mn+mvC)
O(mn+mvC)
O(mn+mvC)
O(Cmn)

Learning Time
O(mn)
O(mn)
O(mn+mvC)
O(mn+mvC)
O(mn+mvC)
O(mnlogn+mvC)

Generalization Time
O(mn)
O(mn)
O(mnC) or O(mn)
O(mnC) or O(mn)
O(mnC) or O(mn)
O(mnC)

Table 9. Summary of efficiency for six distance metrics.
Table 9 summarizes the storage requirements of each system. WVDM is the only one of
these distance functions that requires significantly more storage than the others. For most
applications, n is the critical factor, and all of these distance functions could be used in
conjunction with instance pruning techniques to reduce storage requirements. See Section 7 for
a list of several techniques to reduce the number of instances retained in the training set for
subsequent generalization.
6.2.2. L EARNING SPEED
It takes nm time to read in a training set. It takes an additional 2nm time to find the standard
deviation of the attributes for Euclidean distance, or just nm time to find the ranges for HOEM.
Computing VDM statistics for HVDM, DVDM and IVDM takes mn+mvC time, which is
approximately O(mn). Computing WVDM statistics takes mnlogn+mnC time, which is
approximately O(mnlogn).
In general, the learning time is quite acceptable for all of these distance functions.
26

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

6.2.3. GENERALIZATION SPEED
Assuming that each distance function must compare a new input vector to all training instances,
Euclidean and HOEM take O(mn) time. HVDM, IVDM and DVDM take O(mnC) (unless
Da,x,y has been stored instead of Pa,x,c for HVDM, in which case the search is done in O(mn)
time). WVDM takes O(logn+mnC) = O(mnC) time.
Though m and C are typically fairly small, the generalization process can require a
significant amount of time and/or computational resources as n grows large. Techniques such
as k-d trees (Deng & Moore, 1995; Wess, Althoff & Derwand, 1993; Sproull, 1991) and
projection (Papadimitriou & Bentley, 1980) can reduce the time required to locate nearest
neighbors from the training set, though such algorithms may require modification to handle both
continuous and nominal attributes. Pruning techniques used to reduce storage (as in Section
6.2.1) will also reduce the number of instances that must be searched for generalization.

7. Related Work
Distance functions are used in a variety of fields, including instance-based learning, neural
networks, statistics, pattern recognition, and cognitive psychology (see Section 1 for
references). Section 2 lists several commonly-used distance functions involving numeric
attributes.
Normalization is often desirable when using a linear distance function such as Euclidean
distance so that some attributes do not arbitrarily get more weight than others. Dividing by the
range or standard deviation to normalize numerical attributes is common practice. Turney
(1993; Turney & Halasz, 1993) investigated contextual normalization, in which the standard
deviation and mean used for normalization of continuous attributes depend on the context in
which the input vector was obtained. In this paper we do not attempt to use contextual
normalization, but instead use simpler methods of normalizing continuous attributes, and then
focus on how to normalize appropriately between continuous and nominal attributes.
The Value Distance Metric (VDM) was introduced by Stanfill & Waltz (1986). It uses
attribute weights not used by the functions presented in this paper. The Modified Value
Difference Metric (MVDM) (Cost & Salzberg, 1993; Rachlin et al., 1994) does not use attribute
weights but instead uses instance weights. It is assumed that these systems use discretization
(Lebowitz, 1985; Schlimmer, 1987) to handle continuous attributes.
Ventura (1995; Ventura & Martinez, 1995) explored a variety of discretization methods for
use in systems that can use only discrete input attributes. He found that using discretization to
preprocess data often degraded accuracy, and recommended that machine learning algorithms
be designed to handle continuous attributes directly.
Ting (1994, 1996) used several different discretization techniques in conjunction with
MVDM and IB1 (Aha, Kibler & Albert, 1991). His results showed improved generalization
accuracy when using discretization. Discretization allowed his algorithm to use MVDM on all
attributes instead of using a linear distance on continuous attributes, and thus avoided some of
the normalization problems discussed above in Sections 3.1 and 3.2. In this paper, similar
results can be seen in the slightly higher results of DVDM (which also discretizes continuous
attributes and then uses VDM) when compared to HVDM (which uses linear distance on
continuous attributes). In this paper, DVDM uses equal-width intervals for discretization, while
27

fiWILSON & MARTINEZ

Tings algorithms make use of more advanced discretization techniques.
Domingos (1995) uses a heterogeneous distance function similar to HVDM in his RISE
system, a hybrid rule and instance-based learning system. However, RISE uses a normalization
scheme similar to N1 in Sections 3.1 and 3.2, and does not square individual attribute
distances.
Mohri & Tanaka (1994) use a statistical technique called Quantification Method II (QM2) to
derive attribute weights, and present distance functions that can handle both nominal and
continuous attributes. They transform nominal attributes with m values into m boolean
attributes, only one of which is on at a time, so that weights for each attribute can actually
correspond to individual attribute values in the original data.
Turney (1994) addresses cross-validation error and voting (i.e. using values of k > 1) in
instance-based learning systems, and explores issues related to selecting the parameter k (i.e.,
number of neighbors used to decide on classification). In this paper we use k = 1 in order to
focus attention on the distance functions themselves, but accuracy would be improved on some
applications by using k > 1.
IVDM and WVDM use nonparametric density estimation techniques (Tapia & Thompson,
1978) in determining values of P for use in computing distances. Parzen windows (Parzen,
1962) and shifting histograms (Rosenblatt, 1956) are similar in concept to these techniques,
especially to WVDM. These techniques often use gaussian kernels or other more advanced
techniques instead of a fixed-sized sliding window. We have experimented with gaussianweighted kernels as well but results were slightly worse than either WVDM or IVDM, perhaps
because of increased overfitting.
This paper applies each distance function to the problem of classification, in which an input
vector is mapped into a discrete output class. These distance functions could also be used in
systems that perform regression (Atkeson, Moore & Schaal, 1996; Atkeson, 1989; Cleveland &
Loader, 1994), in which the output is a real value, often interpolated from nearby points, as in
kernel regression (Deng & Moore, 1995).
As mentioned in Section 6.2 and elsewhere, pruning techniques can be used to reduce the
storage requirements of instance-based systems and improve classification speed. Several
techniques have been introduced, including IB3 (Aha, Kibler & Albert, 1991; Aha, 1992), the
condensed nearest neighbor rule (Hart, 1968), the reduced nearest neighbor rule (Gates, 1972),
the selective nearest neighbor rule (Rittler et al., 1975), typical instance based learning
algorithm (Zhang, 1992), prototype methods (Chang, 1974), hyperrectangle techniques
(Salzberg, 1991; Wettschereck & Dietterich, 1995), rule-based techniques (Domingos, 1995),
random mutation hill climbing (Skalak, 1994; Cameron-Jones, 1995) and others (Kibler & Aha,
1987; Tomek, 1976; Wilson, 1972).

8. Conclusions & Future Research Areas
There are many learning systems that depend on a reliable distance function to achieve accurate
generalization. The Euclidean distance function and many other distance functions are
inappropriate for nominal attributes, and the HOEM function throws away information and does
not achieve much better accuracy than the Euclidean function itself.
The Value Difference Metric (VDM) was designed to provide an appropriate measure of

28

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

distance between two nominal attribute values. However, current systems that use the VDM
often discretize continuous data into discrete ranges, which causes a loss of information and
often a corresponding loss in generalization accuracy.
This paper introduced three new distance functions. The Heterogeneous Value Difference
Function (HVDM) uses Euclidean distance on linear attributes and VDM on nominal attributes,
and uses appropriate normalization. The Interpolated Value Difference Metric (IVDM) and
Windowed Value Difference Metric (WVDM) handle continuous attributes within the same
paradigm as VDM. Both IVDM and WVDM provide classification accuracy which is higher on
average than the discretized version of the algorithm (DVDM) on the datasets with continuous
attributes that we examined, and they are both equivalent to DVDM on applications without any
continuous attributes.
In our experiments on 48 datasets, IVDM and WVDM achieved higher average accuracy
than HVDM, and also did better than DVDM, HOEM and Euclidean distance. IVDM was
slightly more accurate than WVDM and requires less time and storage, and thus would seem to
be the most desirable distance function on heterogeneous applications similar to those used in
this paper. Properly normalized Euclidean distance achieves comparable generalization
accuracy when there are no nominal attributes, so in such situations it is still an appropriate
distance function.
The learning system used to obtain generalization accuracy results in this paper was a nearest
neighbor classifier, but the HVDM, IVDM and WVDM distance functions can be used with a knearest neighbor classifier with k > 1 or incorporated into a wide variety of other systems to
allow them to handle continuous values including instance-based learning algorithms (such as
PEBLS), radial basis function networks, and other distance-based neural networks. These new
distance metrics can also be used in such areas as statistics, cognitive psychology, pattern
recognition and other areas where the distance between heterogeneous input vectors is of
interest. These distance functions can also be used in conjunction with weighting schemes and
other improvements that each system provides.
The new distance functions presented here show improved average generalization on the 48
datasets used in experimentation. It is hoped that these datasets are representative of the kinds
of applications that we face in the real world, and that these new distance functions will
continue to provide improved generalization accuracy in such cases.
Future research will look at determining under what conditions each distance function is
appropriate for a particular application. We will also look closely at the problem at selecting
the window width, and will look at the possibility of smoothing WVDMs probability landscape
to avoid overfitting. The new distance functions will also be used in conjunction with a variety
of weighting schemes to provide more robust generalization in the presence of noise and
irrelevant attributes, as well as increase generalization accuracy on a wide variety of
applications.

References
Aha, David W., (1992). Tolerating noisy, irrelevant and novel attributes in instance-based
learning algorithms. International Journal of Man-Machine Studies, Vol. 36, pp. 267-287.
Aha, David W., Dennis Kibler, and Marc K. Albert, (1991). Instance-Based Learning
Algorithms. Machine Learning, Vol. 6, pp. 37-66.
29

fiWILSON & MARTINEZ

Atkeson, Chris, (1989). Using local models to control movement. In D. S. Touretzky (Ed.),
Advances in Neural Information Processing Systems 2. San Mateo, CA: Morgan Kaufmann.
Atkeson, Chris, Andrew Moore, and Stefan Schaal, (1996). Locally weighted learning. To
appear in Artificial Intelligence Review.
Batchelor, Bruce G., (1978). Pattern Recognition: Ideas in Practice. New York: Plenum Press,
pp. 71-72.
Biberman, Yoram, (1994). A Context Similarity Measure. In Proceedings of the European
Conference on Machine Learning (ECML-94). Catalina, Italy: Springer Verlag, pp. 49-63.
Broomhead, D. S., and D. Lowe (1988). Multi-variable functional interpolation and adaptive
networks. Complex Systems, Vol. 2, pp. 321-355.
Cameron-Jones, R. M., (1995). Instance Selection by Encoding Length Heuristic with Random
Mutation Hill Climbing. In Proceedings of the Eighth Australian Joint Conference on
Artificial Intelligence, pp. 99-106.
Carpenter, Gail A., and Stephen Grossberg, (1987). A Massively Parallel Architecture for a
Self-Organizing Neural Pattern Recognition Machine. Computer Vision, Graphics, and
Image Processing, Vol. 37, pp. 54-115.
Chang, Chin-Liang, (1974). Finding Prototypes for Nearest Neighbor Classifiers. IEEE
Transactions on Computers, Vol. 23, No. 11, pp. 1179-1184.
Cleveland, W. S., and C. Loader, (1994). Computational Methods for Local Regression.
Technical Report 11, Murray Hill, NJ: AT&T Bell Laboratories, Statistics Department.
Cost, Scott, and Steven Salzberg, (1993). A Weighted Nearest Neighbor Algorithm for
Learning with Symbolic Features. Machine Learning, Vol. 10, pp. 57-78.
Cover, T. M., and P. E. Hart, (1967). Nearest Neighbor Pattern Classification. Institute of
Electrical and Electronics Engineers Transactions on Information Theory, Vol. 13, No. 1,
pp. 21-27.
Dasarathy, Belur V., (1991). Nearest Neighbor (NN) Norms: NN Pattern Classification
Techniques. Los Alamitos, CA: IEEE Computer Society Press.
Deng, Kan, and Andrew W. Moore, (1995). Multiresolution Instance-Based Learning. To
appear in The Proceedings of the International Joint Conference on Artificial Intelligence
(IJCAI95).
Diday, Edwin, (1974). Recent Progress in Distance and Similarity Measures in Pattern
Recognition. Second International Joint Conference on Pattern Recognition, pp. 534-539.
Domingos, Pedro, (1995). Rule Induction and Instance-Based Learning: A Unified Approach.
to appear in The 1995 International Joint Conference on Artificial Intelligence (IJCAI-95).
Dudani, Sahibsingh A., (1976). The Distance-Weighted k-Nearest-Neighbor Rule. IEEE
Transactions on Systems, Man and Cybernetics, Vol. 6, No. 4, April 1976, pp. 325-327.
30

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

Gates, G. W., (1972). The Reduced Nearest Neighbor Rule. IEEE Transactions on Information
Theory, Vol. IT-18, No. 3, pp. 431-433.
Giraud-Carrier, Christophe, and Tony Martinez, (1995). An Efficient Metric for Heterogeneous
Inductive Learning Applications in the Attribute-Value Language. Intelligent Systems, pp.
341-350.
Hart, P. E., (1968). The Condensed Nearest Neighbor Rule. Institute of Electrical and
Electronics Engineers Transactions on Information Theory, Vol. 14, pp. 515-516.
Hecht-Nielsen, R., (1987). Counterpropagation Networks. Applied Optics, Vol. 26, No. 23, pp.
4979-4984.
Kibler, D., and David W. Aha, (1987). Learning representative exemplars of concepts: An
initial case study. Proceedings of the Fourth International Workshop on Machine
Learning. Irvine, CA: Morgan Kaufmann, pp. 24-30.
Kohonen, Teuvo, (1990). The Self-Organizing Map. In Proceedings of the IEEE, Vol. 78, No.
9, pp. 1464-1480.
Lebowitz, Michael, (1985). Categorizing Numeric Information for Generalization. Cognitive
Science, Vol. 9, pp. 285-308.
Merz, C. J., and P. M. Murphy, (1996). UCI Repository of Machine Learning Databases.
Irvine, CA: University of California Irvine, Department of Information and Computer
Science. Internet: http://www.ics.uci.edu/~mlearn/MLRepository.html.
Michalski, Ryszard S., Robert E. Stepp, and Edwin Diday, (1981). A Recent Advance in Data
Analysis: Clustering Objects into Classes Characterized by Conjunctive Concepts.
Progress in Pattern Recognition, Vol. 1, Laveen N. Kanal and Azriel Rosenfeld (Eds.).
New York: North-Holland, pp. 33-56.
Mitchell, Tom M., (1980). The Need for Biases in Learning Generalizations. in J. W. Shavlik
& T. G. Dietterich (Eds.), Readings in Machine Learning. San Mateo, CA: Morgan
Kaufmann, 1990, pp. 184-191.
Mohri, Takao, and Hidehiko Tanaka, (1994). An Optimal Weighting Criterion of Case
Indexing for both Numeric and Symbolic Attributes. In D. W. Aha (Ed.), Case-Based
Reasoning: Papers from the 1994 Workshop, Technical Report WS-94-01. Menlo Park,
CA: AIII Press, pp. 123-127.
Nadler, Morton, and Eric P. Smith, (1993). Pattern Recognition Engineering. New York:
Wiley, pp. 293-294.
Nosofsky, Robert M., (1986). Attention, Similarity, and the Identification-Categorization
Relationship. Journal of Experimental Psychology: General, Vol. 115, No. 1, pp. 39-57.
Papadimitriou, Christos H., and Jon Louis Bentley, (1980). A Worst-Case Analysis of Nearest
Neighbor Searching by Projection. Lecture Notes in Computer Science, Vol. 85,
Automata Languages and Programming, pp. 470-482.
31

fiWILSON & MARTINEZ

Parzen, Emanuel, (1962). On estimation of a probability density function and mode. Annals of
Mathematical Statistics. Vol. 33, pp. 1065-1076.
Quinlan, J. R., (1989). Unknown Attribute Values in Induction. In Proceedings of the 6th
International Workshop on Machine Learning. San Mateo, CA: Morgan Kaufmann, pp.
164-168.
Rachlin, John, Simon Kasif, Steven Salzberg, David W. Aha, (1994). Towards a Better
Understanding of Memory-Based and Bayesian Classifiers. In Proceedings of the
Eleventh International Machine Learning Conference. New Brunswick, NJ: Morgan
Kaufmann, pp. 242-250.
Renals, Steve, and Richard Rohwer, (1989). Phoneme Classification Experiments Using Radial
Basis Functions. In Proceedings of the IEEE International Joint Conference on Neural
Networks (IJCNN89), Vol. 1, pp. 461-467.
Rittler, G. L., H. B. Woodruff, S. R. Lowry, and T. L. Isenhour, (1975). An Algorithm for a
Selective Nearest Neighbor Decision Rule. IEEE Transactions on Information Theory,
Vol. 21, No. 6, pp. 665-669.
Rosenblatt, Murray, (1956). Remarks on Some Nonparametric Estimates of a Density Function.
Annals of Mathematical Statistics. Vol. 27, pp. 832-835.
Rumelhart, D. E., and J. L. McClelland, (1986). Parallel Distributed Processing, MIT Press,
Ch. 8, pp. 318-362.
Salzberg, Steven, (1991). A Nearest Hyperrectangle Learning Method. Machine Learning,
Vol. 6, pp. 277-309.
Schaffer, Cullen, (1993). Selecting a Classification Method by Cross-Validation. Machine
Learning, Vol. 13, No. 1.
Schaffer, Cullen, (1994). A Conservation Law for Generalization Performance. In Proceedings
of the Eleventh International Conference on Machine Learning (ML94), Morgan
Kaufmann, 1994.
Schlimmer, Jeffrey C., (1987). Learning and Representation Change. In Proceedings of the
Sixth National Conference on Artificial Intelligence (AAAI87), Vol. 2, pp. 511-535.
Skalak, D. B., (1994). Prototype and Feature Selection by Sampling and Random Mutation Hill
Climbing Algorithsm. In Proceedings of the Eleventh International Conference on
Machine Learning (ML94). Morgan Kaufman, pp. 293-301.
Sproull, Robert F., (1991). Refinements to Nearest-Neighbor Searching in k-Dimensional
Trees. Algorithmica, Vol. 6, pp. 579-589.
Stanfill, C., and D. Waltz, (1986). Toward memory-based reasoning. Communications of the
ACM, Vol. 29, December 1986, pp. 1213-1228.

32

fiIMPROVED HETEROGENEOUS DISTANCE FUNCTIONS

Tapia, Richard A., and James R. Thompson, (1978). Nonparametric Probability Density
Estimation. Baltimore, MD: The Johns Hopkins University Press.
Ting, Kai Ming, (1994). Discretization of Continuous-Valued Attributes and Instance-Based
Learning. Technical Report No. 491, Basser Department of Computer Science, University
of Sydney, Australia.
Ting, Kai Ming, (1996). Discretisation in Lazy Learning. To appear in the special issue on
Lazy Learning in Artificial Intelligence Review.
Tomek, Ivan, (1976). An Experiment with the Edited Nearest-Neighbor Rule. IEEE
Transactions on Systems, Man, and Cybernetics, Vol. 6, No. 6, June 1976, pp. 448-452.
Turney, Peter, (1994). Theoretical Analyses of Cross-Validation Error and Voting in InstanceBased Learning. Journal of Experimental and Theoretical Artificial Intelligence (JETAI),
pp. 331-360.
Turney, Peter, (1993). Exploiting context when learning to classify. In Proceedings of the
European Conference on Machine Learning. Vienna, Austria: Springer-Verlag, pp. 402407.
Turney, Peter, and Michael Halasz, (1993). Contextual Normalization Applied to Aircraft Gas
Turbine Engine Diagnosis. Journal of Applied Intelligence, Vol. 3, pp. 109-129.
Tversky, Amos, (1977). Features of Similarity. Psychological Review, Vol. 84, No. 4, pp. 327352.
Ventura, Dan, (1995). On Discretization as a Preprocessing Step for Supervised Learning
Models, Masters Thesis, Department of Computer Science, Brigham Young University.
Ventura, Dan, and Tony R. Martinez (1995). An Empirical Comparison of Discretization
Methods. In Proceedings of the Tenth International Symposium on Computer and
Information Sciences, pp. 443-450.
Wasserman, Philip D., (1993). Advanced Methods in Neural Computing. New York, NY: Van
Nostrand Reinhold, pp. 147-176.
Wess, Stefan, Klaus-Dieter Althoff and Guido Derwand, (1994). Using k-d Trees to Improve
the Retrieval Step in Case-Based Reasoning. Stefan Wess, Klaus-Dieter Althoff, & M. M.
Richter (Eds.), Topics in Case-Based Reasoning. Berlin: Springer-Verlag, pp. 167-181.
Wettschereck, Dietrich, and Thomas G. Dietterich, (1995). An Experimental Comparison of
Nearest-Neighbor and Nearest-Hyperrectangle Algorithms. Machine Learning, Vol. 19,
No. 1, pp. 5-28.
Wettschereck, Dietrich, David W. Aha, and Takao Mohri, (1995). A Review and Comparative
Evaluation of Feature Weighting Methods for Lazy Learning Algorithms. Technical
Report AIC-95-012. Washington, D.C.: Naval Research Laboratory, Navy Center for
Applied Research in Artificial Intelligence.

33

fiWILSON & MARTINEZ

Wilson, D. Randall, and Tony R. Martinez, (1993). The Potential of Prototype Styles of
Generalization. In Proceedings of the Sixth Australian Joint Conference on Artifical
Intelligence (AI93), pp. 356-361.
Wilson, D. Randall, and Tony R. Martinez, (1996). Heterogeneous Radial Basis Functions. In
Proceedings of the International Conference on Neural Networks (ICNN96), Vol. 2, pp.
1263-1267.
Wilson, Dennis L., (1972). Asymptotic Properties of Nearest Neighbor Rules Using Edited
Data. IEEE Transactions on Systems, Man, and Cybernetics, Vol. 2, No. 3, pp. 408-421.
Wolpert, David H., (1993). On Overfitting Avoidance as Bias. Technical Report SFI TR 9203-5001. Santa Fe, NM: The Santa Fe Institute.
Zhang, Jianping, (1992). Selecting Typical Instances in Instance-Based Learning. Proceedings
of the Ninth International Conference on Machine Learning.

34

fiJournal of Artificial Intelligence Research 6 (1997) 87-110

Submitted 7/96; published 3/97

A Uniform Framework for Concept Definitions in
Description Logics
Giuseppe De Giacomo

degiacomo@dis.uniroma1.it

Universita di Roma \La Sapienza"
Via Salaria 113, 00198 Roma, Italy

Maurizio Lenzerini

lenzerini@dis.uniroma1.it

Universita di Roma \La Sapienza"
Via Salaria 113, 00198 Roma, Italy

Abstract

Most modern formalisms used in Databases and Artificial Intelligence for describing an
application domain are based on the notions of class (or concept) and relationship among
classes. One interesting feature of such formalisms is the possibility of defining a class,
i.e., providing a set of properties that precisely characterize the instances of the class.
Many recent articles point out that there are several ways of assigning a meaning to a
class definition containing some sort of recursion. In this paper, we argue that, instead of
choosing a single style of semantics, we achieve better results by adopting a formalism that
allows for different semantics to coexist. We demonstrate the feasibility of our argument, by
presenting a knowledge representation formalism, the description logic ALCQ, with the
above characteristics. In addition to the constructs for conjunction, disjunction, negation,
quantifiers, and qualified number restrictions, ALCQ includes special fixpoint constructs
to express (suitably interpreted) recursive definitions. These constructs enable the usual
frame-based descriptions to be combined with definitions of recursive data structures such
as directed acyclic graphs, lists, streams, etc. We establish several properties of ALCQ,
including the decidability and the computational complexity of reasoning, by formulating
a correspondence with a particular modal logic of programs called the modal mu-calculus.

1. Introduction
Most modern formalisms used in Databases and Artificial Intelligence for representing an
application domain are based on the notions of class (or concept) and relationship among
classes. For example, the object-oriented and semantics data models developed in Databases
describe data in terms of classes (sometimes called entity types) and incorporate several
features for establishing various forms of relationships between classes. On the other hand,
the notion of class (often called concept or frame) and that of link among classes are provided
in all structured formalisms for Knowledge Representation (frame-based languages, semantic
networks, description logics, etc.). Finally, this notion is also present in several type systems
of programming languages, specially those based on the object-oriented paradigm.
There are basically two ways of using and describing classes (concepts). In the first one,
which we can call the prescriptive approach, the description formalism allows for expressing
a number of properties of a class, thus prescribing constraints that the instances of the class
must satisfy. In the second one, which we can call the definitional approach, the formalism
allows for providing the definition of a class, i.e., a set of properties that precisely characterc 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiDe Giacomo & Lenzerini

ize the instances of the class. While the prescriptive approach is quite well understood and
established, the definitional approach is still the subject of an interesting debate, regarding
both its nature and its semantic foundation. In particular, it is well known that there are
various ways to assign a meaning to a class definition when it contains some sort of recursion
(Baader, 1990, 1991; Nebel, 1991; Beneventano & Bergamaschi, 1992; Beeri, 1990).
In this paper, we are concerned with the semantic problems related to the definitional
approach, arguing that, instead of choosing a single style of semantics for the knowledge
representation formalism, we achieve better results by allowing different semantics to coexist.
We discuss this issue in the context of Description Logics1 , which are logics originally
developed in Knowledge Representation to provide a formal reconstruction of frame-based
languages. Description logics describe the domain of interest in terms of concepts, which
represent classes of individuals, and roles, which are binary relations used to specify properties or attributes of individuals as well as links with other individuals (Nebel, 1990). Starting
from atomic concepts, denoted simply by a name, more complex concepts are built by using a suitable set of constructs. For example, the expression parent u male u 8child:male
denotes the concept of father (male parent) whose children are all male. The symbol u
denotes the construct for concept conjunction, while 8 denotes universal role quantification.
Typically, concepts are structured into hierarchies determined by the properties associated
with them. The hierarchical structure is defined in such a way that more specific concepts
inherit the properties of the more general ones.
We introduce a description logic, called ALCQ, which extends the well-known description logic ALC (Schmidt-Schau & Smolka, 1991) by including the so called qualified
number restrictions, which are a very general form of cardinality constraints on roles, and
special fixpoint constructs, which enable us to capture the various semantics for recursive
definitions within a single formalism. Notably, the availability of these constructs makes
it possible to combine the usual frame-based descriptions with definitions of recursive data
structures such as directed acyclic graphs, lists, streams, etc.
We establish several properties of ALCQ, including the decidability and the computational complexity of reasoning, by formulating a correspondence with a particular modal
logic of programs called the modal mu-calculus.
Recent articles, (e.g., Bergamaschi & Sartori, 1992; Borgida, 1992), advocate the use
of description logics as a unifying framework for several types of database and knowledge
representation formalisms. Indeed, it is possible to show that, depending on both the constructs and the semantics used, one can capture several database models and programming
language type systems by using description logics. Therefore, the study presented in this paper is not merely confined to description logics, but is also applicable to other representation
formalisms.
The paper is organized as follows. In Section 2, we present the basic notions regarding
both description logics and fixpoints. In Section 3, we motivate our approach through
a detailed discussion about the different semantics of concept definitions that have been
considered in the literature, and we argue for a formalism in which the various semantics
coexist. In Section 4, we present one such formalism, namely the logic ALCQ, and we
1. Also called Concept Languages or Terminological Languages.

88

fiConcept Definitions in Description Logics

discuss several of its properties. In Section 5 we study reasoning techniques for ALCQ
and expose the correspondence with modal mu-calculus. Finally, in Section 6, we draw the
conclusions and discuss some open problems.

2. Preliminaries
In this section, we briey present the basic notions regarding both description logics, and
fixpoints. The interested reader is referred to (Nebel, 1990) and (de Bakker, 1980) for a
more complete introduction to the subjects.

2.1 Description Logics

Description logics allow one to represent a domain of interest in terms of concepts and
roles. Concepts model classes of individuals, while roles model relationships between classes.
Starting with atomic concepts (denoted by A) and atomic roles (denoted by R), which are
concepts and roles described simply by a name, complex concepts and roles can be built by
means of suitable constructs.
In this section, we concentrate on the description logic ALCQ, obtained from the wellknown description logic ALC (Schmidt-Schau & Smolka, 1991) by including qualified number restrictions. These are cardinality constraints on the role fillers of a very general form,
where role fillers to which a constraint applies are selected by means of a generic concept
expression, the qualifier.
ALCQ concepts (denoted by C or D, possibly with a subscript) are composed inductively
according to the following abstract syntax (n denotes a natural number):

C ::= A j > j ? j :C j C1 u C2 j C1 t C2 j 9R:C j 8R:C j ( n R:C ) j ( n R:C ):
These constructs are not all independent. The following equalities hold: > = A t :A,

? = :>, 8R:C = :9R::C , and ( n R:C ) = :( n + 1 R:C ).

From a semantic point of view, concepts are interpreted as subsets of an abstract domain,
while roles are interpreted as binary relations over such a domain. More precisely, an
interpretation I = (I ; I ) consists of a domain of interpretation I , and an interpretation
function I mapping every atomic concept A to a subset of I and every atomic role R to
a subset of I  I .
The interpretation function I is extended to complex concepts of ALCQ (note that in
ALCQ roles are always atomic) as follows:

>I
?I
(:C )I
(C1 u C2 )I
(C1 t C2 )I
(9R:C )I
(8R:C )I
( n R:C )I
( n R:C )I

=
=
=
=
=
=
=
=
=

I

;

I , C I

C1I \ C2I
C1I [ C2I
fs 2 I j 9s0: (s; s0 ) 2 RI and s0 2 C I g
fs 2 I j 8s0: (s; s0 ) 2 RI implies s0 2 C I g
fs 2 I j #fs0 j (s; s0) 2 RI and s0 2 C I g  ng
fs 2 I j #fs0 j (s; s0) 2 RI and s0 2 C I g  ng
89

fiDe Giacomo & Lenzerini

where #S denotes the cardinality of the set S .
A concept C is satisfiable iff there exists an interpretation I such that C I 6= ;, otherwise
C is unsatisfiable. A concept C1 is subsumed by a concept C2, written as C1 v C1, iff for
every interpretation I , C1I  C2I .
Our knowledge expressed in terms of concepts and roles is assembled into a special
knowledge base, traditionally called TBox, which consists of a finite (possibly empty) set
of assertions. In order to be as general as possible, we assume that every assertion has the
form of an inclusion assertion (or simply inclusion):

C1 v C2

without any restriction on the form of the concepts C1 and C2 . A pair of inclusions of the
form fC1 v C2 ; C2 v C1 g is often written as C1  C2 and is called equivalence assertion.
An interpretation I satisfies an inclusion C1 v C2 iff C1I  C2I . An interpretation I is
a model of a TBox K iff I satisfies all inclusions in K.
Let K be a TBox. We say that a concept C is satisfiable in K, iff there exists a model
I of K such that C I 6= ;, unsatisfiable otherwise. We say that a concept C1 is subsumed by
a concept C2 in K, written K j= C1 v C2 , iff for every model I of K, C1I  C2I .

2.2 Fixpoints

We briey recall few notions on fixpoints. Consider the equation:
X = f (X )
where f is an operator from 2S to 2S (2S denotes the set of all subsets of a set S ). Every
solution E of this equation is called a fixpoint of the operator f (while every set E such that
f (E )  E is called pre-fixpoint, and every set E such that E  f (E ) is called post-fixpoint).
In general, an equation as the one above may have either no solution, a finite number of
solutions, or an infinite number of them. Among the various solutions, the smallest and the
greatest solutions (with respect to set-inclusion) have a prominent position, if they exist. A
fundamental result due to Tarski (Tarski, 1955) guarantees the existence and the uniqueness
of both such solutions in case f is monotonic wrt set-inclusion (), where f is monotonic
wrt  whenever E1  E2 implies f (E1 )  f (E2 ).
Theorem 1 (Tarski) Let S be a set, and f an operator from 2S to 2S that is monotonic
wrt . Then:
 There exists a unique least fixpoint of f , which is given by TfE  S j f (E )  Eg.
 There exists a unique greatest fixpoint of f , which is given by SfE  S j E  f (E )g.

3. Concept Definitions as Equations

We now analyze the notion of concept definition in detail. Let us ignore for the moment
knowledge bases as they have been introduced in the previous section, and let us consider a
different kind of assertion: the definition statement. Let the form of a definition statement
(or simply definition) be:
A =def C
90

fiConcept Definitions in Description Logics

where A is an atomic concept which cannot appear in the left-hand side of other definition
statements, and C is a concept expression in ALCQ. In principle, A =def C is intended to
provide an exact account for the concept to A in terms of C , i.e., to define A as the set of
the individuals satisfying C .
In specifying the semantics of definitions, we need to distinguish between two different
types of atomic concepts, namely, primitive concepts and defined concepts. Given a set of
definition statements, the primitive concepts are the atomic concepts that do not appear in
the left-hand side of any definition statement, whereas the defined concepts are those that
appear in the left-hand side of a definition statement.
Given an interpretation I = (I ; I ), the interpretation function I directly assigns
a subset of I to primitive concepts, but not to defined concepts. The meaning of a
defined concept A is assigned through its definition statement A =def C , extending the
interpretation function so as the following requirement is satisfied:
AI = C I :
(1)
Consider, for example, the definition statement:
parent =def 9child:>:
Note that the defined concept parent does not appear in the body of its definition statement.
By (1), the definition statement provides the definition for the concept parent, in the
following sense: in any interpretation I = (I ; I ), parentI denotes a single subset of I ,
exactly the one denoted by (9child:>)I , i.e., fs j 9t:(s; t) 2 childI g. In general, if a concept
A is defined in terms of primitive and already defined concepts, then for every interpretation
I there exists a unique way to extend the interpretation function to defined concepts, and
hence there is no doubt that the definition statement provides a definition of A.
Now, consider the following definition statement:
A =def 9child:A:
Given an interpretation I = (I ; I ), by (1) the statement is interpreted as the equation:
AI = fs 2 I j 9t:(s; t) 2 childI and t 2 AI g:
However such equation does not specify univocally how to extend the interpretation function
I to the defined concept A, since ; satisfies the equation as well as any set of individuals
where each member has an infinite chain of descendants that are also members.
In general, we call recursive definition statements2 (or simply recursive definitions),
definition statements of the form:
A =def F (A)
where F (A) stands for a concept that has A as a subconcept3 . According to (1), the recursive
definition A =def F (A) is interpreted simply as a sort of equation specifying that, given an
2. Terminological cycles in (Baader, 1990, 1991; Nebel, 1991). In the present discussion, for sake of simplicity, we do not consider mutual recursive definitions, as A =def F (B ), B =def F (A). We shall come
back to this point later on.
3. A subconcept of a concept C is any substring of C (including C itself) that is a concept, according to
the syntax rules.
0

91

fiDe Giacomo & Lenzerini

interpretation I , the subset of I that can be tied to the defined concept A must satisfy
the equation AI = F (A)I , i.e., must be one of its solutions. Observe that, in general, either
none, one, or several subsets of I may exist which are solutions of the above equation.
Another convenient way to consider a definition statement is to associate to it, for every
interpretation I , an operator from subsets of I to subsets of I instead of an equation, so
that the fixpoints of the operator correspond to the solutions of the equation. For example,
to the definition A =def 9child:A we associate the operator:

S:fs 2 I j 9t:(s; t) 2 childI and t 2 S g
for any interpretation I . In general as either none, one or multiple solutions exist for the
equation associated with a recursive definition, we have that either none, one or multiple
fixpoints exist for the corresponding operator.
In this situation the word \definition" itself seems misleading: the body of the definition
does not give a complete account of the defined concept. An additional criterion is needed
for selecting solutions of the associated equation, or equivalently, fixpoints of the associated
operator. In other words in addition to (1), a criterion is needed to extend univocally the
interpretations I to the defined concepts. This observation has led to various semantics,
each of which interprets recursive definitions differently, by choosing, a priori and once and
for all, which solutions, or equivalently which fixpoints, are to be assigned to the defining
concept of a recursive definition4.

3.1 Different Semantics for Recursive Definitions

In the literature on description logics, three semantics for recursive definitions have been
proposed (see Nebel, 1991):

 Descriptive Semantics
 Least Fixpoint Semantics
 Greatest Fixpoint Semantics
and which of these semantics is the \right" one is a long standing matter of debate. Below
we describe how each of the three semantics interprets recursive definitions, and present
some examples showing that the choice of the semantics depends in fact upon the concept
to be defined. But first, it should be stressed that only the descriptive semantics is able to
assign meaning to general inclusion assertions C1 v C2 introduced in the previous section.
According to the Descriptive Semantics, a recursive definition A =def F (A) is a constraint stating that, for any I , AI has to be a solution of the equation AI = F (A)I . Under
the descriptive semantics, A =def 9child:A simply states that the individuals in the class
A have a child in the class A, and the individuals that have a child in the class A are
themselves in the class A, where A is no better specified. In general the descriptive semantics is not appropriate to properly define recursive concepts, in the sense that, given an
4. We remark that a non-recursive definition is interpreted by the various semantics in the same way, since,
for every I , the equation associated to it has a single solution.

92

fiConcept Definitions in Description Logics

interpretation I , it is unable to assign a unique subset of I to the defined concept of the
recursive definition.
In fact under descriptive semantics definition statements are indistinguishable from the
equivalence assertions introduced in the previous section. In other words, the meaning
assigned to A =def F (A) is the same as that assigned to the equivalence assertion A  F (A).
Although such equivalence assertions can be used to specify if-and-only-if constraints, they
do not provide proper definitions when recursion is involved. For example, we can express
the fact that humans are mammals having parents that are humans, and on the converse,
that mammals having parents that are humans are humans themselves, in terms of the
equivalence assertion:

human  mammal u 9parent:> u 8parent:human:
Similarly we may require horses to satisfy an analogous property:

horse  mammal u 9parent:> u 8parent:horse:
However the two equivalence assertions above do not define human and horse as shown,

e.g., by the fact that (correctly) they do not imply that all humans are horses and vice-versa
(in contrast to what happen when a fixpoint semantics is used, see below).
The Least Fixpoint Semantics interprets a recursive definition statement A =def F (A)
by assigning to A the smallest possible extension in each interpretation I , among those that
satisfy AI =def F (A)I { i.e., the least fixpoint of the corresponding operator. In fact it is
always assumed that the operator associated with the definition statement is monotonic,
so that Theorem 1 applies and a least fixpoint exists and is unique, i.e., the corresponding
equation has a unique smallest solution. Hence under the least fixpoint semantics the
recursive definition statement A =def F (A) defines the concept A. It is easy to verify that
in the example A =def 9child:A, the least fixpoint semantics leads us to identify A with ?.
Indeed the empty set is a solution of the equation associated with the statement, and it is
obviously the smallest solution. Similarly if we interpret the definition statement:
human =def mammal u 9parent:> u 8parent:human
with the least fixpoint semantics, we have that humanI = ; for any interpretation I .
Observe that if, as above, we adopt a similar definition for horse, we get again horseI = ;,
so we can trivially infer that horse  human.
The least fixpoint semantics is particularly suitable for providing inductive definitions
of concepts. For example, consider the class of a list (LIST) defined as follows:
 An EMPTY-LIST is a LIST.
 A NODE that has exactly one successor that is a LIST is a LIST.
 Nothing else is a LIST.
The first two conditions can be captured by the following recursive definition statement5 :
list =def emptylist t (node u ( 1 succ:>) u 9succ:list)
5. Additionally we specify that the two concepts emptylist and node are disjoint.

93

fiDe Giacomo & Lenzerini

where ( 1 succ:>) forces succ to be a function. To enforce the third condition we must
assign the smallest possible extension to list. Thus, the class of LISTs can be naturally
defined by means of the above definition statement, interpreted according to the least
fixpoint semantics.
The Greatest Fixpoint Semantics interprets a recursive definition statement A =def F (A)
by assigning to A the largest possible extension in each interpretation I , among those that
satisfy AI =def F (A)I { i.e., the greatest fixpoint of the corresponding operator. Again, it
is assumed that such operator is monotonic in order to guaranty the existence an the unicity
of the greatest fixpoint (Theorem 1). As for the least fixpoint semantics, under the greatest
fixpoint semantics a recursive definition statement A =def F (A) defines the concept A. For
example, considering again the definition statement A =def 9child:A, the greatest fixpoint
semantics leads us to interpret A as the class of all the individuals having a child that in
turn is a member of A.
While the least fixpoint semantics naturally captures classes defined by induction, the
greatest fixpoint semantics naturally captures classes of individuals whose structure is nonwell-founded or co-inductive. An example is the class of STREAMs, modeling the wellknown linear data structure having a NODE as first element, and such that the rest of the
structure is a STREAM itself. Note that streams are similar to lists except that while lists
can be considered as finite sequences of nodes, streams are infinite sequences of nodes. Such
a class can be captured by the following recursive definition statement:

stream =def node u ( 1 succ:>) u 9succ:stream
with the proviso that the greatest possible extension is assigned to stream.
Finally, consider under the greatest fixpoint semantics the recursive definition statements:
human =def mammal u 9parent:> u 8parent:human
horse =def mammal u 9parent:> u 8parent:horse:
Although they do not assign the empty extension to both human and horse as the least
fixpoint semantics does, we do have again the rather counter intuitive consequence that
human  horse, since humanI = horseI for any interpretation I . In general under both
types of fixpoint semantics the particular name used to denote a defined concept does not
have any impact on the interpretation of it, since the meaning of the defined concept is
completely specified by its definition statement.

3.2 Least and Greatest Fixpoints as Concept Constructs

The above considerations show that arguing about which is the \right" semantics for recursive definitions is not really an issue. Each of them captures an essential use of recursive
equations: the descriptive semantics is appropriate to specify constraints on concepts and
is the only one that extends to the general inclusion assertions introduced in Section 2; the
least fixpoint semantics is appropriate to define a structure inductively; the greatest fixpoint
semantics is the appropriate to define non-well-founded structures. Generally, we may need
the three of them in the same knowledge base, in order to model the various properties of
the different concepts.
94

fiConcept Definitions in Description Logics

Our proposal in this paper is exactly in the direction of reconciling the various semantics
in the same knowledge base. This is pursued by means of a logic that incorporates two
constructs, X:F (X ) and X:F (X ) (the symbols X; Y; : : : stand for concept variables),
denoting, respectively, the least fixpoint and the greatest fixpoint of the operator associated
with the definition X =def F (X ), that is, for every I , the smallest solution and the greatest
solution of the equation X I = F (X )I .
In our approach, definition statements will never appear in a TBox. Instead, a knowledge
base will be simply a set of inclusion assertions (interpreted according to the descriptive semantics) that can involve fixpoint constructs. For example, in order to specify the properties
of the concepts of list, stream, human and horse we can use the following assertions6 :
list
 X:emptylist t (node u ( 1 succ:>) u 9succ:X )
stream  X:node u ( 1 succ:>) u 9succ:X

human  mammal u 9parent:> u 8parent:human
horse  mammal u 9parent:> u 8parent:horse:

Note that, if we then add to the above knowledge base the equivalence assertion:

mgm  X : mammal u 9parent:> u 8parent:X
defining the concept mgm (mammal generated by mammal), then it correctly turns out
that both human and horse are subsumed by mgm.

The availability of least and greatest fixpoint constructs, by allowing different semantics
to be used in the same TBox, makes it possible to model not only abstract classes, but also
inductively and co-inductively defined data structures, such as lists and streams. This is
particularly important if our objective is to integrate class-based representation formalisms
and programming systems (declarative or procedural), in order to make these formalisms
more useful in practice. Furthermore, we have the possibility of nesting fixpoints, thus
going beyond the simple equational format by which we motivated their introduction. As
an example, consider the following one:
Among the inhabitants of the planet \Plonk", a disease called \foo" is quite
common. Such a disease manifests itself in two forms: a \visible" one and a
\latent" one, and it has a rather intricate hereditary pattern. Individuals that
have the visible form transmit the visible form to at least one (say the first) direct
descendant (obviously, if there is any direct descendant), these ill descendants
in turn do the same, and so on, until someone transmits the latent form of the
disease. More precisely, along any chain of descendants, the visible form of the
disease sooner or later is interrupted, because either an individual has no direct
descendant or an individual transmits to some descendant the latent form. All
direct descendants (if any) of an individual that has the latent form inherit the
visible form. The pattern goes on like this, generation after generation, forever.
The hereditary pattern (foo hp) of the above disease can be defined as follows:
foo hp  X:Y:((visible u (9child:Y t 8child:?))t
(latent u 8child:(visible u X )))
6. We also include the assertion emptylist v :node, specifying that the concepts emptylist and node are
disjoint.

95

fiDe Giacomo & Lenzerini

where visible and latent denote the visible and the latent form respectively of the disease,
and are assumed to be disjoint (latent v :visible).

4. The Description Logic ALCQ
We provide a formal account of the meaning of the fixpoint constructs by introducing a
description logic, called ALCQ, which is obtained by adding these constructs to ALCQ.
We make use of the notions of scope, bound and free occurrences of variables, closed
formulae, etc. The definitions of these notions are the same as the analogues in first-order
logic, treating  and  as quantifiers. In addition, we use the symbol  as an abstraction
for either  or  .
The primitive symbols in ALCQ are atomic concepts, (concept) variables (denoted by
X; Y; : : :), and atomic roles which are the only roles admitted in the logic.
Concepts in ALCQ are formed inductively according to the following abstract syntax:

C ::= A j > j ? j :C j C1 u C2 j C1 t C2 j 9R:C j 8R:C j ( n R:C ) j ( n R:C ) j
X:C j X:C j X
where A denotes an atomic concept, R an atomic role, n a natural number, and X a variable,
and with the restriction that only a variable X occurring positively in C can be bounded by
a fixpoint  in X:C . We say that a variable X occurs positively in a concept C , if every
free occurrence of X is in the scope of an even number of negations, considering concepts
C 0 in ( n R:C 0 ) in the scope of one negation.
The two fixpoint constructs are mutually definable: X:C = :X::C [X=:X ] (where
C [X=:X ] is the concept obtained substituting all free occurrences of X by the concept
:X ).
As before, an interpretation I = (I ; I ) consists of a domain of interpretation I , and
a interpretation function I , which maps every atomic concept to a subset of I , and every
atomic role to a subset of I  I . But the presence of free variables does not allow us to
extend the interpretation function I directly to every concept of the logic. For this reason
we introduce valuations. A valuation  on an interpretation I is a mapping from variables
to subsets of I .
Given a valuation , we denote by [X=E ] the valuation identical to  except for
[X=E ](X ) = E . In other words, for every variable Y :

(

X
[X=E ](Y ) = E(Y ) ifif YY =
6= X
Let I be an interpretation and  a valuation on I . We assign meaning to concepts of
the logic by associating to I and  an extension function I , mapping concepts to subsets
of I , as follows:
96

fiConcept Definitions in Description Logics

XI
AI

>I
?I
(:C )I
(C1 u C2 )I
(C1 t C2 )I
(9R:C )I
(8R:C )I
( n R:C )I
( n R:C )I

(X:C )I
(X:C )I

=
=
=
=
=
=
=
=
=
=
=
=
=

(X )  I
AI  I
I

;

I , CI
(C1 )I \ (C2 )I
(C1 )I [ (C2 )I
fs 2 I j 9s0: (s; s0 ) 2 RI and s0 2 CI g
fs 2 I j 8s0: (s; s0 ) 2 RI implies s0 2 CI g
fs 2 I j #fs0 j (s; s0) 2 RI and s0 2 CI g  ng
fs 2 I j #fs0 j (s; s0) 2 RI and s0 2 CI g  ng
T
 I j CI[X=E ]  E g
SfE
fE  I j E  CI[X=E ] g

In the last two cases CI[X=E ] is interpreted as an operator from subsets E of I to subsets
of I . By the syntactic restriction enforced on variables, such an operator is guaranteed
to be monotonic wrt . Notice that free variables appearing in a concept are interpreted
similarly to atomic concepts.
A concept C is satisfiable, if there exists an interpretation I and a valuation  on I
such that CI 6= ;, otherwise C is unsatisfiable. A concept C1 is subsumed by a concept C2 ,
written as C1 v C2 , if for every interpretation I and every valuation  on I , (C1 )I  (C2 )I .
A ALCQ TBox is a finite (possibly empty) set of inclusion assertions C1 v C2 where
C1 and C2 are closed concepts of ALCQ. As before, we use equivalence assertions of the
form C1  C2 as an abbreviation for fC1 v C2 ; C2 v C1 g.
An interpretation I satisfies an inclusion assertion C1 v C2 , if (C1 )I  (C2 )I , where 
is any valuation on I (being C1 and C2 closed, and hence independent from valuations).
I is a model of a TBox K, if I satisfies all inclusion assertions in K. We say that a TBox
K is satisfiable, if it has a model. Observe that inclusion assertions in K are interpreted
according to the descriptive semantics.
We say that a TBox K logically implies an inclusion assertion C1 v C2 , written K j=
C1 v C2, if for every model I of K and every valuation  on I , (C1 )I  (C2 )I .

4.1 Properties of the Fixpoint Constructs

In the following, we use the notation C (X ) to indicate that the variable X occurs free in
the concept C (other variables could occur free in C as well), and the notation C (D), where
D is a concept, as a shorthand for C (X )[X=D] (i.e., the concept obtained substituting all
free occurrences of X in C (X ) by the concept D).
Let us comment briey on some simple properties of the logic. First, the concept
X:C (X ) is equivalent to the concept Y:C (Y ), as long as Y is free for X in C (X ). Second,
the extension function I assign to a closed concept a value which is independent of the actual
valuation . Hence X:C , where X does not occur in C , is equivalent to C . Third, since
X:C (X ) is a fixpoint we have that C (X:C (X )) is equivalent to X:C (X ). Furthermore,
we have that the concept X:C (X ) is always subsumed by the concept X:C (X ).
97

fiDe Giacomo & Lenzerini

The next property is more substantial. Consider the class of a single source finite
directed acyclic graphs (DAGs) defined inductively as follows7:
 The EMPTY-DAG is a DAG (base step).

 A NODE that has connections and all connections are DAGs, is a DAG (inductive
step).

 Nothing else is a DAG.
Consider now a ALCQ TBox K containing the two equivalence assertions:
dag of student  X : emptydag t (student u 9arc:> u 8arc:X )
dag of person  X : emptydag t (person u 9arc:> u 8arc:X )

which define the concepts dag of student and dag of person as the classes of DAGs whose
nodes are students and persons respectively. Assuming that students are persons, we want
to be able to infer that DAGs of students are DAGs of persons as well. That is, we want:

K j= student v person implies K j= dag of student v dag of person:
It turns out that for ALCQ such a property holds. To prove this, we introduce the

following two theorems.

Theorem 2 Let K be a ALCQ TBox, and C and D two ALCQ concepts in which a
variable X occurs free positively. Then:
K j= C v D implies K j= X:C v X:D:
Proof We proceed by contradiction8 . Assume that CI  DI holds for all models I of K
and all valuations  on I . And suppose that there exists a model I of K and a valuation 
on I such that (X:C )I 6 (X:D)I .

First we prove the result for  = . Let s be an individual in (X:C )I but not in
(X:D)I . Now, we have:

s 2 (X:C )I iff 8E  I : (CI[X=E ]  E implies s 2 E )

(2)

s 62 (X:D)I iff 9E 0  I : (DI[X=E ]  E 0 and s 62 E 0 ):

(3)

0

For the set E 0 in (3), the following expression holds:

CI[X=E ]  DI[X=E ]  E 0
0

0

7. We assume that a leaf of a DAG is a NODE with all arcs leading to a special DAG called EMPTY-DAG.
As an alternative, one can assume that a leaf of a DAG is a NODE having no connection at all. In the
latter case, the definition of dag would simplify to dag =def node u 8arc:dag (in which the general form
of inductive definitions { i.e., base case and inductive case { is less apparent).
8. For uniformity, we do not distinguish if X occurs free or not. Obviously if X does not occur free, the
result is trivial.

98

fiConcept Definitions in Description Logics

hence by (2) we have s 2 E 0 and by (3) we have s 62 E 0 , which is impossible.
The proof for  =  is similar. Let s be an individual in (X:C )I but not in (X:D)I .
Now, we have:

s 2 (X:C )I iff 9E 00  I : (E 00  CI[X=E ] and s 2 E 00)

(4)

s 62 (X:D)I iff 8E  I : (E  DI[X=E ] implies s 62 E ):

(5)

00

For the set E 00 in (4), the following expression holds:

E 00  CI[X=E ]  DI[X=E
00

00

]

hence by (4) we have s 2 E 00 and by (5) we have s 62 E 00 , which is impossible. 2
Above we have defined what it means for a variable X to occur positively in a concept C .
Similarly we say that a variable X occurs negatively in a concept C , if every free occurrence
of X is in the scope of an odd number of negations, considering concepts C 0 in ( n R:C 0 )
in the scope of one negation.

Theorem 3 Let K be a ALCQ TBox, and D(X ) a ALCQ concept with the variable X
as a free variable. Then, for any ALCQ concepts C1 and C2 :
K j= C1 v C2 implies

(

K j= D(C1) v D(C2) if X occurs positively in D(X )
K j= D(C2) v D(C1) if X occurs negatively in D(X )

Proof We prove the result by induction on the formation of D(X ).

Base case. If D(X ) = X , the result holds trivially.
Inductive cases. If D(X ) has the form :D0 (X ) j ( n R:C 0 ) , then X occurs positively
(negatively) in D0 (X ) and negatively (positively) in D(X ). By induction hypothesis K j=
D0 (Ci ) v D0(Cj ) (where i; j 2 f1; 2g and i 6= j ) and hence by the semantics of the constructs
K j= D(Cj ) v D(Ci).
If D(X ) has the form D10 (X ) u D20 (X ) j D10 (X ) t D20 (X ) j 8R:D0(X ) j ( n R:D0 (X )),
then X occurs positively (negatively) both in D0 (X ) and in D(X ). By induction hypothesis
K j= D0(Ci) v D0(Cj ) and hence by the semantics of the constructs K j= D(Ci) v D(Cj ).
It remains to prove the result for D(X ) = Y:D0 (X ) (Y 6= X ). In this case, by the
syntactic restriction enforced, Y occurs positively in D0 (X ) and hence by Theorem 2 we have
K j= D0(Ci) v D0(Cj ) implies K j= Y:D0(Ci ) v Y:D0 (Cj ), thus by induction hypothesis
we are done. 2
Going back to our example, we can, in fact, infer that DAGs of students are also DAGs of
persons. Indeed, by applying Theorem 3 and then Theorem 2, we have that K j= student v
person implies K j= X:emptydag t (studentu9arc:>u8arc:X ) v X:emptydag t (person u
9arc:> u 8arc:X ).
99

fiDe Giacomo & Lenzerini

4.2 Internalizing Assertions

We now show that logical implication in ALCQ TBoxes (thus also satisfiability of ALCQ
TBoxes) is reducible to unsatisfiability of a single ALCQ concept. To prove this result, we
introduce the notions of generated sub-interpretation and sub-valuation9.
Let I = (I ; I ) be an interpretation,
 a valuation on I , and s 2 I an individual.
s Is
s
I
We define the interpretation I = ( ;  ), and the valuation s on I s, as follows:
 I s = fs0 2 I j (s; s0) 2 (R1I [ : : : [ RmI )g.
 For each atomic role Ri, we have RiI s = RiI \ (I s  I s ).
 For each atomic concept A, we have AI s = AI \ I s .
 For each variable X , we have s(X ) = (X ) \ I s .
We call I s the sub-interpretation of I generated by s, and s the sub-valuation of  generated
by s.
For generated sub-interpretations and sub-valuations we can state the following lemma.

Lemma 4 Let C be a ALCQ concept. Then for any interpretation I , any valuation  on
I , and any individual s 2 I , we have:
8t 2 I s : t 2 CI iff t 2 CIss :
Proof Without loss of generality, we consider concepts formed according to the following
simplified abstract syntax: C ::= A j ? j :C j C1 u C2 j 9R:C j ( n R:C ) j X:C j X:

We prove the result by induction on the number of nested fixpoint constructs. Base
case. If in C there are no fixpoint constructs, the thesis can be proven by induction on the
formation of C .
Inductive case. We assume that the thesis holds for concepts C with k nested fixpoint
constructs, and we prove it for concepts X:C with k + 1. We recall that, by the TarskiKnaster Theorem on fixpoints (Tarski, 1955), t 2 (X:C )I iff there exists an ordinal ff such
that t 2 (ff X:C )I , where (ff X:C )I is defined by transfinite induction as:
 (0 X:C )I = ;

 (ff+1 X:C )I = CI[X=(ff X:C ) ]
 ( X:C )I = Sff< (ffX:C )I , if  is a limit ordinal.
I

Hence we proceed by transfinite induction on ordinals ff.
Base case of the transfinite induction. 0 X:C is defined as ?, thus trivially we have
t 2 (0 X:C )I iff t 2 (0 X:C )Iss .
Successor case of the transfinite induction. We want to show that t 2 (ff+1 X:C )I iff t 2
(ff+1 X:C )Iss , which reduces to:

t 2 CI[X=(ff X:C ) ] iff t 2 CIss[X=(ff X:C )ss ]:
I

I

9. Together these notions play the same role as that of generated sub-model in modal logics.

100

(6)

fiConcept Definitions in Description Logics

To prove this, we start by showing that:

t 2 CIss[X=(ff X:C )ss ] iff t 2 C(Is[X=(ff X:C ) ])s :
I

I

(7)

Notice that the two valuations above may differ only on the value of X . If it holds that:

t 2 XIss[X=(ff X:C )ss ] iff t 2 X(Is[X=(ff X:C ) ])s ;
I

I

(8)

then by straightforward induction on the formation of C we have that (7) holds as well.
Let us prove (8). We can write it as:

t 2 s[X=(ff X:C )Iss ](X ) iff t 2 ([X=(ff X:C )I ])s (X );
and since t 2 I s , this reduces to

t 2 (ff X:C )Iss iff t 2 (ff X:C )I :
which holds by transfinite inductive hypothesis.
Now, since C contains k fixpoint constructs, by inductive hypothesis on k, we have:

t 2 CI[X=(ff X:C ) ] iff t 2 C(Is[X=(ff X:C ) ])s :
I

I

Hence, considering (6) and (7), it follows that indeed t 2 (ff+1 X:C )I iff t 2 (ff+1 X:C )Iss .
Limit case of the transfinite induction. Let  be a limit ordinal, then t 2 ( X:C )I iff
there exists an ordinal ff <  such that t 2 (ff X:C )I . By transfinite induction hypothesis,
it holds that: t 2 (ff X:C )I iff t 2 (ff X:C )Iss , and thus:

t 2 ( X:C )I iff t 2 ( X:C )Iss :
This completes the transfinite induction. So for all ordinals ff it holds that:

t 2 (ff X:C )I iff t 2 (ff X:C )Iss :
The induction on the nesting of fixpoint constructs is completed as well, hence we have
proven the lemma. 2
Now we are ready to state the result mentioned above.

Theorem 5 Let K = fC1 v D1 ; : : : ; Cq v Dq g be a ALCQ TBox, and C and D two
ALCQ concepts. Then K j= C v D if and only if the ALCQ concept:
X:(8R1 :X u : : : u 8Rm :X u CK) u C u :D
(9)
is unsatisfiable, where R1 ; : : : ; Rm are all the atomic roles appearing in K, and CK = (:C1 t
D1 ) u : : : u (:Cq t Dq ).
101

fiDe Giacomo & Lenzerini

Proof If part. By contradiction. Assume that (9) is not satisfiable, and suppose that
K 6j= C v D, i.e., there exists an interpretation I , and a valuation  on I , such that I
is a model of K and CI 6 DI . It follows that, there exists an individual s 2 I such
that s 2 CI and s 2 (:D)I . On the other hand, the fact that I is a model of K implies
that (CK )I = I , and thus that (X:(8R1 :X u : : : u 8Rm :X u CK ))I = I . So we have
s 2 (X:(8R1 :X u : : : u 8Rm:X u CK ) u C u :D)I , i.e., (9) is satisfiable, contradicting the

hypotheses.
Only If part. Again we proceed by contradiction. Assume K j= C v D. And suppose
that (9) is satisfiable, i.e., there exists an interpretation I , a valuation  on I , and an
individual s 2 I , such that s 2 (X:(8R1 :X u : : : u 8Rm :X u CK ) u C u :D)I .
Now consider the sub-interpretation I s = (I s ; Iss ) and the sub-valuation s on I s
generated by s. On the one hand, we clearly have that (CK )Iss = I s , hence I s is a model
of K. On the other hand by Lemma 4 s 2 (X:(8R1 :X u : : : u8Rm :X u CK ) u C u:D)Iss , so it
follows that I s and s do not satisfy the subsumption C v D, contradicting the hypotheses.

2

This result states that satisfiability of ALCQ concepts and logical implication in
ALCQ TBoxes (and thus of satisfiability of ALCQ TBoxes) are not distinct reasoning
tasks. Hence in the following we will limit our attention to concept satisfiability without
loss of generality.

5. Reasoning with Fixpoints

In this section we concentrate on developing reasoning methods to check for satisfiability
concepts involving fixpoints. In particular, we exhibit a correspondence between ALCQ
and a well-known logic of programs, called modal mu-calculus (Kozen, 1983; Kozen &
Parikh, 1983; Streett & Emerson, 1984, 1989), that has been recently investigated for
expressing temporal properties of reactive and parallel processes (Stirling, 1992; Larsen,
1990; Cleaveland, 1990; Winsket, 1989; Dam, 1992).
To get a better insight on the correspondence between the two logics, we first study
the sublanguage ALC obtained from ALCQ leaving out qualified number restrictions10 .
Then, we study the full logic ALCQ.

5.1 Reasoning in ALC

Let us introduce modal mu-calculus formally. Formulae ; 	; : : : of modal mu-calculus
are formed inductively from atomic formulae A; : : : and variables X; : : : according to the
following abstract syntax:
; 	 ::= A j > j ? j : j  ^ 	 j  _ 	 j hai j [a] j X: j X: j X
where a is the generic element of a set of labels L, and every bounded occurrence of every
variable X must be in the scope of an even number of negation signs.
10. Observe that, in Theorem 5 qualified number restrictions play no role. Hence exactly the same reduction
from logical implication to unsatisfiability holds for ALC as well. This allows us to restrict our attention
to satisfiability only.

102

fiConcept Definitions in Description Logics

The semantics of modal mu-calculus is based on the notions of (Kripke) structure and
valuation. A Kripke structure M is a triple (S ; fRi j i 2 Lg; V ), where S is a set of states,
each Ri is a binary relation on S , and V is a mapping from atomic formulae to subsets of
S . A valuation  on M is a mapping from variables to subsets of S . To a Kripke structure
M and a valuation  on M, it is associated an extension function M
 defined inductively
as follows:
XM
= (X )  S
AM
= V (A)  S

M
>
= S
?M
= ;

(:)M
= S , M


M
M
( ^ 	)M
 =  \ 	
M
M
( _ 	) =  [ 	M

(hai)M
= fs 2 S j 9s0 : (s; s0 ) 2 Ra and s0 2 M

 g
0 : (s; s0 ) 2 Ra implies s0 2 M g
([a])M
=
f
s
2
S
j
8
s


T
M
(X:)M
 = SfE  S j [X=E ]  E g
(X:)M
= fE  S j E  M

[X=E ] g
A formula  is satisfiable if there exists a Kripke structure M and a valuation  on M such
that M
 6= ;.
The following theorem is the basis for the correspondence between ALC and the modal
mu-calculus.

Theorem 6 There exists a one-to-one linear-time function q mapping concepts of ALC
to formulae of modal mu-calculus such that: for any ALC concept C , C is satisfiable if
and only if q(C ) is satisfiable.

Proof We can define q in the following way: q(A) = A (atomic concepts are mapped
to atomic formulae), q(X ) = X , q(>) = >, q(?) = ?, q(:C ) = :q(C ), q(9R:C ) =
hRiq(C ) (atomic roles are mapped to labels), q(8R:C ) = [R]q(C ), q(X:C ) = X:q(C ),
and q(X:C ) = X:q(C ).
An interpretation I = (I ; I ) is equivalent to a Kripke structure M = (S ; fRi j i 2
Lg; V ) such that: S = I ; L is equal to the set of names of the atomic roles interpreted
in I ; RR = RI for each atomic role R; and V (A) = AI for each atomic concept A. In
addition, a valuation  on I is equivalent to a valuation 0 on M. Now both the extension
function associated with I and  and the extension function associated with M and 0
map, respectively, any concept C and the corresponding formula q(C ) to the same subset
of I = S . Hence the thesis follows. 2
It follows that we may transfer both decidability and complexity results for the modal
mu-calculus (Kozen & Parikh, 1983; Emerson & Jutla, 1988; Safra, 1988) to ALC . Thus,
we can immediately state what is the complexity of reasoning with ALC concepts and
ALC TBoxes.

Theorem 7 Satisfiability of ALC concepts, satisfiability of ALC TBoxes, and logical
implication in ALC TBoxes are EXPTIME-complete problems.
103

fiDe Giacomo & Lenzerini

Proof The satisfiability problem for modal mu-calculus is EXPTIME-complete (Emerson
& Jutla, 1988), hence by Theorem 6 and by Theorem 5 the thesis follows. 2

5.2 Reasoning in ALCQ
Next we exhibit a mapping from ALCQ concepts to formulae of variant of modal mucalculus, called deterministic modal mu-calculus, which has the same syntax as the modal
mu-calculus, but is interpreted over deterministic Kripke structures, that is Kripke structures M = (S ; fRi j i 2 Lg; V ) in which the relations Ri are partial functions (Streett &
Emerson, 1984).
Let us ignore for a moment the qualified number restriction constructs. Formulae of
ALCQ without qualified number restrictions are, in fact, formulae of the modal mucalculus, as shown in the previous section. By using a well-known technique developed
for propositional dynamic logic (Parikh, 1981), (nondeterministic) modal mu-calculus formulae can be reduced to deterministic modal mu-calculus formulae (Streett & Emerson,
1984), as shown below.
We use the following notations for usual operations on binary relations:  for chaining,
 for reexive transitive closure, + for transitive closure, and , for converse. We also use
the following abbreviations:
[R ]
[R+ ]

for
for
hR i for
hR+i for

X:( ^ [R]X )
[R][R ]
X:( _ hRiX )
hRihR i:

The reduction is as follows: in a formula , we recursively replace each subformulae of
the form [R] by [R][(Rnew ) ] and each subformulae of the form hRi by hRih(Rnew ) i,
where Rnew is a new symbol and both R and Rnew in the resulting formula are interpreted
as partial functions. Let us call the resulting formula 0 , we have that  is satisfiable if and
only if 0 is satisfiable.
We briey sketch the reasoning behind the proof of this statement. The if direction
is easy: it suces to observe that if M D = (S D ; fRDi j i 2 LD g; V D ) is a model of 0 ,
then can transform it into a model M = (S ; fRi j i 2 Lg; V ) of  by defining S = S D ,
L = LD , new, RR = RDR  (RDnew ) , and V = V D . The only if direction is as follows. We
recall that both nondeterministic and deterministic modal mu-calculus have the tree model
property (Streett & Emerson, 1989, 1984): if a formula has a model it has a tree model,
i.e., a model having the form of a tree11 . So without loss of generality we can restrict our
attention to tree models only. Now there is a one-to-one transformation from tree models
M T = (S T ; fRTi j i 2 LT g; V T ) of  to (tree) models M B = (S B ; fRBi j i 2 LB g; V B ) of
0 . Indeed, we put S B = S T , V B = V T , LB = LT , and given a state x 2 S T having as
11. Given a model of  we get a tree model simply by \unfolding" the original one.

104

fiConcept Definitions in Description Logics

RTR -successors z1; : : : ; zl ,12 we put (x; z1 ) 2 RBR , and (zi ; zi+1 ) 2 RBRnew , for i = 1; : : : ; l , 1.
In this way we have (x; zi ) 2 RTR if and only if (x; zi ) 2 RBR  (RBRnew ) .13

We remark that M T is required to be a tree because once we get M B we need to recover
the \original" RTR -predecessor x of a state zi , namely we need (RBR  (RBRnew ) ), to be
a partial function, otherwise, given a state zi , we would not know which of the various
(RBR  (RBRnew ) ), -successors is its original RTR -predecessor x, and therefore we would not
be able to reconstruct M T from M B .
By interpreting R and Rnew as partial functions, it easy to express qualified number
 )-successors of a state. For example:
restrictions as constraints on the chain of (R  Rnew
( 3 R:) can be expressed by
[R][(Rnew ) ](: _ [(Rnew )+ ](: _ [(Rnew )+ ](: _ [(Rnew )+ ]:)))
and can be read as \everywhere along the chain R  (Rnew ) there are at most three states
where  holds", which corresponds exactly to the intended meaning. Similarly ( 3 R:)
can be expressed by

hRih(Rnew ) i( ^ h(Rnew )+i( ^ h(Rnew )+ i))
and can be read as \somewhere along the chain R  (Rnew ) there are at least three states
where  holds", which again corresponds exactly to the intended meaning.
The above discussion allows us to state the following result.

Theorem 8 There exists a polynomial function t mapping concepts of ALCQ to formulae
of deterministic modal mu-calculus such that: for any ALCQ concept C , C is satisfiable

if and only if u(C ) is satisfiable.

Proof The function t is defined inductively as follows:
u(A)
u(X )
u(C1 u C1 )
u(C1 t C2 )
u(:C )
u(X:C )
u(X:C )
u(9R:C )
u(8R:C )

A
X
u(C1 ) ^ u(C2 )
u(C1 ) _ u(C2 )
:u(C )
X:u(C )
X:u(C )
hRih(Rnew )iu(C )
[R][(Rnew ) ]u(C )
where Rnew is a new role. Finally, ( n R:C ) and ( n R:C ) are mapped to the following
=
=
=
=
=
=
=
=
=

formulae:

12. We implicitly assume that M T is a finite branching tree model. This can be done without loss of
generality since modal mu-calculus has the finite model property, and hence unfolding a finite model we
get a finite branching tree model. Note however that it would suce to assume M T to be a countable
branching tree model.
13. Note that this construction is similar to the one often used in programming to reduce n-ary trees to
binary trees by coding children of a node as the combination of one child and its siblings.

105

fiDe Giacomo & Lenzerini

u(( n R:C )) =[R][(Rnew ) ](:u(C ) _ [(Rnew )+](:u(C )_
[(Rnew )+ ](: : : (:u(C ) _ [(Rnew )+ ]:u(C )) : : :)))
where the number of nested formulae of the form :u(C ) _ [(Rnew )+ ] is n, and

u(( n R:C )) =hRih(Rnew ) i(u(C ) ^ h(Rnew )+i(u(C )^
h(Rnew )+i(: : : (u(C ) ^ h(Rnew )+iu(C )) : : :)))
where the number of nested formulae of the form u(C ) ^ h(Rnew )+ i is n , 1.
u(C ) is clearly polynomial in the size of C (under the usual assumption that numbers in
C coded in unary). Moreover, following the technique in (Parikh, 1981; Streett & Emerson,
1984) that as been exposed above, it is easy to verify, by induction on the formation of the
concept C , that the mapping t preserves satisfiability. 2
It follows that we may transfer both decidability and complexity results for the deterministic modal mu-calculus (Streett & Emerson, 1984; Emerson & Jutla, 1988; Safra,
1988) to ALCQ. Thus, we can immediately state what is the complexity of reasoning with
ALCQ concepts and ALCQ TBoxes.

Theorem 9 Satisfiability of ALCQ concepts, satisfiability of ALCQ TBoxes, and logical
implication in ALCQ TBoxes are EXPTIME-complete problems.
Proof Satisfiability in deterministic modal mu-calculus is an EXPTIME-complete problem

(Streett & Emerson, 1984; Emerson & Jutla, 1988; Safra, 1988). Hence by Theorem 8 and
Theorem 5 the thesis follows. 2

6. Discussion and Conclusion

The work presented in this paper stems out from (De Giacomo, 1993), where the basic ideas
of introducing explicit fixpoint was first presented, and (De Giacomo & Lenzerini, 1994b),
where such idea was further elaborated and ALCQ was first introduced.
One of the main contributions of this work has been to devise a tight correspondence
between description logics with fixpoints and modal mu-calculus. In this respect we remark
that, while ALC corresponds directly to modal mu-calculus, the full ALCQ corresponds
to a variant of modal mu-calculus whose decidability and complexity had not been studied.
More precisely, a notion essentially equivalent to that of qualified number restrictions has
independently emerged in modal logics, namely that of graded modalities (Van der Hoek
& de Rijke, 1995; Van der Hoek, 1992; Fattorosi-Barnaba & De Caro, 1985; Fine, 1972).
However the combination of fixpoints and graded modalities had not been investigated
before in the setting of modal logics. Given the tight correspondence between ALC and
modal mu-calculus, ALCQ can be considered as modal mu-calculus augmented with graded
modalities. Hence the results in this paper apply to such a logic as well.
The research reported in this paper bears several similarities with the one on the correspondence between description logics and propositional dynamic logics (Baader, 1991;
106

fiConcept Definitions in Description Logics

Schild, 1991; De Giacomo & Lenzerini, 1994a, 1995; De Giacomo, 1995). In fact what characterize description logics based on propositional dynamic logics are the role constructs for
chaining, choice, test, and above all reexive transitive closure of roles, which is a limited
form of fixpoint. Such role constructs can be easily expressed by using the explicit fixpoints
introduced here. It suce to resort to the following equivalences:
9R1  R2 :C = 9R1:9R2:C
9R1 t R2:C = 9R1:C t 9R2:C
9R:C = X:(C t 9R:X )
9id(D):C = C u D:
Note that 8R :C = X:(C u 8R:X ). In (Calvanese, De Giacomo, & Lenzerini, 1995)
a further implicit form of fixpoint has been advocated, the so called well-founded role
construct wf (R). By explicit fixpoints, wf (R) is expressed simply as X:(8R:X ).
Our proposal of allowing for fixpoint constructs explicitly in the formalism is shared
by the study independently carried out by Schild in (Schild, 1994)14 . The main goal of
that work is to study both the expressive power and the computational complexity of
subsumption and satisfiability for TBoxes expressed in ALC (no fixpoint constructs), that
allow for mutually recursive definitions. To this end, a description logic is defined that
corresponds to a variant of the modal mu-calculus in which mutual fixpoints are allowed
but some restrictions on nested fixpoints are enforced (Vardi & Wolper, 1984). It is well
known that mutual fixpoints can be re-expressed by means of nested ones (see, for example,
Park, 1976; de Bakker, 1980). As a consequence of this observation it follows that the logic
introduced in this paper, is more expressive than the one analyzed in (Schild, 1994) since,
on the one hand, it allows nesting of fixpoints without any restriction, on the other hand
it makes it possible to state sophisticated forms of cardinality constraints on role fillers by
means of qualified number restrictions.
The present work can be extended along several directions. We conclude by outlining
two of them.
We already noticed that fixpoint constructs allow for representing not only abstract
classes, but also several data structures extensively used in software development. We
believe that this characteristic is an important step towards a satisfactory integration of
description logics with both traditional and declarative programming systems. Indeed the
description logic proposed in this paper provides powerful mechanisms for data structure
modeling. In particular, the properties stated in Section 4.1 can be the base to formulate a
notion of parametric concept15 . For instance, the expression (named dag of [Z ])
X : emptydag t (Z u 9arc:> u 8arc:X )
where Z is a formal parameter, denotes the class of DAGs whose nodes are left unspecified.
This class can be used in several ways in the TBox. For example, it can be instantiated
by binding the formal parameter to actual parameters, thus getting, say, dag of [student],
dag of [person], etc., which are concepts inheriting the properties of dag of [Z ].
14. In (Schild, 1994) number restrictions are not considered.
15. Note that parametric concepts can be introduced also in simpler logics which do not include fixpoint
constructs.

107

fiDe Giacomo & Lenzerini

Although ALCQ is a powerful logic, it lacks the construct for inverse roles which is
needed for example to correctly capture the notions of (finite) TREE, BINARY-TREE, etc.
Indeed, to define the concept of TREE (an EMPTY-TREE is a TREE; a NODE that has
at most one parent, some children, and all children are TREEs, is a TREE; nothing else is a
TREE) we can write tree  X : empty tree t (node u ( 1 child, :>) u9child:>u8child:X
where child, denotes the inverse of child. Notice that the introduction of inverse roles
does not pose any diculty from the semantical point of view; however, its impact on
the reasoning method needs to be investigated. More generally, a wide variety of concept
constructs can be studied in conjunction with fixpoints. The research on description logics
related to propositional dynamic logics in (De Giacomo & Lenzerini, 1994a, 1995; Calvanese
et al., 1995; De Giacomo, 1995) may give us hints on how to proceed along this direction.

References

Baader, F. (1990). Terminological cycles in KL-ONE-based knowledge representation languages. In Proc. of the 8th Nat. Conf. on Artificial Intelligence (AAAI-90), pp.
621{626 Boston, Ma.
Baader, F. (1991). Augmenting concept languages by transitive closure of roles: An alternative to terminological cycles. In Proc. of the 12th Int. Joint Conf. on Artificial
Intelligence (IJCAI-91) Sydney, Australia.
Beeri, C. (1990). A formal approach to object-oriented databases. Data and Knowledge
Engineering, 5, 353{382.
Beneventano, D., & Bergamaschi, S. (1992). Subsumption for complex object data models.
In Proc. of the 4th Int. Conf. on Database Theory (ICDT-92), No. 646 in Lecture
Notes in Computer Science, pp. 357{375. Springer-Verlag.
Bergamaschi, S., & Sartori, C. (1992). On taxonomic reasoning in conceptual design. ACM
Transaction on Database Systems, 17 (3), 385{422.
Borgida, A. (1992). From type systems to knowledge representation: Natural semantics
specifications for description logics. Journal of Intelligent and Cooperative Information
Systems, 1 (1), 93{126.
Calvanese, D., De Giacomo, G., & Lenzerini, M. (1995). Structured objects: modeling and
reasoning. In Proc. of the 4th Int. Conf. on Deductive and Object-Oriented Databases
(DOOD-95), Lecture Notes in Computer Science. Springer-Verlag.
Cleaveland, R. (1990). Tableaux-based model checking in the propositional mu-calculus.
Acta Informatica, 27, 725{747.
Dam, M. (1992). CTL* and ECTL* as fragments of the modal mu-calculus. In Proceeding of
the Col. on Trees and Algebra in Programming, No. 581 in Lecture Notes in Computer
Science, pp. 145{164. Springer-Verlag.
de Bakker, J. (1980). Mathematical Theory of Program Correctness. Prentice-Hall.
108

fiConcept Definitions in Description Logics

De Giacomo, G. (1993). Reconciling different semantics for concept definition (extended
abstract). In Proc. of the 1st COMPULOG Net Meeting on Knowledge Representation
and Reasoning Systems (CNKRR-93).
De Giacomo, G. (1995). Decidability of Class-Based Knowledge Representation Formalisms.
Ph.D. thesis, Dipartimento di Informatica e Sistemistica, Universita di Roma \La
Sapienza".
De Giacomo, G., & Lenzerini, M. (1994a). Boosting the correspondence between description
logics and propositional dynamic logics. In Proc. of the 12th Nat. Conf. on Artificial
Intelligence (AAAI-94), pp. 205{212. AAAI-Press/the MIT-Press.
De Giacomo, G., & Lenzerini, M. (1994b). Concept language with number restrictions and
fixpoints, and its relationship with mu-calculus. In Proc. of the 11th Eur. Conf. on
Artificial Intelligence (ECAI-94), pp. 411{415. John Wiley and Sons.
De Giacomo, G., & Lenzerini, M. (1995). What's in an aggregate: foundation for description
logics with tuples and set. In Proc. of the 14th Int. Conf. on Artificial Intelligence
(IJCAI-95).
Emerson, E. A., & Jutla, C. S. (1988). The complexity of tree automata and logics of
programs. In Proc. of the 20th An. Symp. on the Foundations of Computer Science
(FOCS-88), pp. 328{337.
Fattorosi-Barnaba, M., & De Caro, F. (1985). Graded modalities I. Studia Logica, 44,
197{221.
Fine, K. (1972). In so many possible worlds. Notre Dame Journal of Formal Logic, 13 (4),
516{520.
Kozen, D. (1983). Results on the propositional mu-calculus. Theoretical Computer Science,
27, 333{355.
Kozen, D., & Parikh, R. (1983). A decision procedure for the propositional mu-calculus. In
Proc. of the 2nd Work. on Logic of Programs, No. 164 in Lecture Notes in Computer
Science, pp. 313{325. Springer-Verlag.
Larsen, K. J. (1990). Proof systems for satisfiability in Hennessy-Milner logic with recursion.
Theoretical Computer Science, 72, 265{288.
Nebel, B. (1990). Reasoning and Revision in Hybrid Representation Systems. No. 422 in
Lecture Notes in Artificial Intelligence. Springer-Verlag.
Nebel, B. (1991). Terminological cycles: Semantics and computational properties. In Sowa,
J. F. (Ed.), Principles of Semantic Networks, pp. 331{361. Morgan Kaufmann, Los
Altos.
Parikh, R. (1981). Propositional dynamic logic of programs: A survey. In Proc. of the
1st Work. on Logic of Programs, No. 125 in Lecture Notes in Computer Science, pp.
102{144. Springer-Verlag.
109

fiDe Giacomo & Lenzerini

Park, D. (1976). Finiteness is mu-ineffable. Theoretical Computer Science, 3, 173{181.
Safra, S. (1988). On the complexity of !-automata. In Proc. of the 20th An. Symp. on the
Foundations of Computer Science (FOCS-88), pp. 319{327.
Schild, K. (1991). A correspondence theory for terminological logics: Preliminary report. In
Proc. of the 12th Int. Joint Conf. on Artificial Intelligence (IJCAI-91), pp. 466{471
Sydney, Australia.
Schild, K. (1994). Terminological cycles and the propositional -calculus. In Doyle, J.,
Sandewall, E., & Torasso, P. (Eds.), Proc. of the 4th Int. Conf. on the Principles
of Knowledge Representation and Reasoning (KR-94), pp. 509{520 Bonn. Morgan
Kaufmann, Los Altos.
Schmidt-Schau, M., & Smolka, G. (1991). Attributive concept descriptions with complements. Artificial Intelligence, 48 (1), 1{26.
Stirling, C. (1992). Modal and temporal logic. In Abramsky, S., Gabbay, D. M., & Maibaum,
T. S. E. (Eds.), Handbook of Logic in Computer Science, pp. 477{563. Clarendon Press,
Oxford.
Streett, R. S., & Emerson, E. A. (1984). The propositional mu-calculus is elementary. In
Proc. of the 6th Int. Col. on Automata, Languages and Programming, No. 172 in
Lecture Notes in Computer Science, pp. 465{472. Springer-Verlag.
Streett, R. S., & Emerson, E. A. (1989). An automata theoretic decision procedure for the
propositional mu-calculus. Information and Control, 81, 249{264.
Tarski, A. (1955). A lattice-theoretical fixpoint theorem and its applications. Pacific Journal
of Mathematics, 5, 285{309.
Van der Hoek, W. (1992). On the semantics of graded modalities. Journal of Applied
Non-Classical Logics, 2 (1), 81{123.
Van der Hoek, W., & de Rijke, M. (1995). Counting objects. Journal of Logic and Computation, 5 (3), 325{345.
Vardi, M. Y., & Wolper, P. (1984). Automata theoretic techniques for modal logics of
programs. In Proc. of the 16th An. Symp. on the Foundations of Computer Science
(FOCS-84), pp. 446{456.
Winsket, G. (1989). A note on model checking the modal  -calculus. In Proc. of the 11th
Int. Col. on Automata, Languages and Programming, No. 372 in Lecture Notes in
Computer Science, pp. 761{772. Springer-Verlag.

110

fiJournal of Artificial Intelligence Research 6 (1997) 177-209

Submitted 10/96; published 5/97

Connectionist Theory Refinement:
Genetically Searching the Space of Network Topologies
David W. Opitz

opitz@cs.umt.edu

Jude W. Shavlik

shavlik@cs.wisc.edu

Department of Computer Science
University of Montana
Missoula, MT 59812 USA

Computer Sciences Department
University of Wisconsin
1210 W. Dayton St.
Madison, WI 53706 USA

Abstract

An algorithm that learns from a set of examples should ideally be able to exploit the
available resources of (a) abundant computing power and (b) domain-specific knowledge to
improve its ability to generalize. Connectionist theory-refinement systems, which use background knowledge to select a neural network's topology and initial weights, have proven to
be effective at exploiting domain-specific knowledge; however, most do not exploit available computing power. This weakness occurs because they lack the ability to refine the
topology of the neural networks they produce, thereby limiting generalization, especially
when given impoverished domain theories. We present the Regent algorithm which uses
(a) domain-specific knowledge to help create an initial population of knowledge-based neural networks and (b) genetic operators of crossover and mutation (specifically designed for
knowledge-based networks) to continually search for better network topologies. Experiments on three real-world domains indicate that our new algorithm is able to significantly
increase generalization compared to a standard connectionist theory-refinement system, as
well as our previous algorithm for growing knowledge-based networks.

1. Introduction
Many scientific and industrial problems can be better understood by learning from samples
of the task. For this reason, the machine learning and statistics communities devote considerable research effort to inductive-learning algorithms. Often, however, these learning
algorithms fail to capitalize on a number of potentially available resources, such as domainspecific knowledge or computing power, that can improve their ability to generalize. Using
domain-specific knowledge is desirable because inductive learners that start with an approximately correct theory can achieve improved \generalization" (accuracy on examples not
seen during training) with significantly fewer training examples (Ginsberg, 1990; Ourston
& Mooney, 1994; Pazzani & Kibler, 1992; Towell & Shavlik, 1994). Making effective use of
available computing power is desirable because, for many applications, it is more important
to obtain concepts that generalize well than it is to induce concepts quickly. In this article, we present an algorithm, called Regent (REfining, with Genetic Evolution, Network
Topologies), that utilizes available computer time to extensively search for a neural-network

c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiOpitz & Shavlik

topology that best explains the training data while minimizing changes to a domain-specific
theory.
Inductive learning systems that utilize a set of approximately correct, domain-specific
inference rules (called a domain theory) which describe what is currently known about
the domain, are called theory-refinement systems. Making use of this knowledge has been
shown to be important since these rules may contain insight not easily obtainable from
the current set of training examples (Ourston & Mooney, 1994; Pazzani & Kibler, 1992;
Towell & Shavlik, 1994). For most domains, an expert who created the theory is willing
to wait for weeks, or even months, if a learning system can produce an improved theory.
Thus, given the rapid growth in computing power, we believe it is important for learning
techniques to be able to trade off the expense of large numbers of computing cycles for gains
in predictive accuracy. Analogous to anytime planning techniques (Dean & Boddy, 1988),
we believe machine learning researchers should create better anytime learning algorithms.
Such learning algorithms should produce a good concept quickly, then continue to search
concept space, reporting the new \best" concept whenever one is found.
We concentrate on connectionist theory-refinement systems, since they have been shown
to frequently generalize better than many other inductive-learning and theory-refinement
systems (Fu, 1989; Lacher, Hruska, & Kuncicky, 1992; Towell, 1991). Kbann (Towell &
Shavlik, 1994) is an example of such a connectionist system; it translates the provided
domain theory into a neural network, thereby determining the network's topology, and
then refines the reformulated rules using backpropagation (Rumelhart, Hinton, & Williams,
1986). However, Kbann, and other connectionist theory-refinement systems that do not
alter their network topologies, suffer when given impoverished domain theories { ones that
are missing rules needed to adequately learn the true concept (Opitz & Shavlik, 1995;
Towell & Shavlik, 1994). TopGen (Opitz & Shavlik, 1995) is an improvement over these
systems; it heuristically searches through the space of possible network topologies by adding
hidden nodes to the neural representation of the domain theory. TopGen showed statistically
significant improvements over Kbann in several real-world domains (Opitz & Shavlik, 1995);
however, in this paper we empirically show that TopGen nevertheless suffers because it only
considers simple expansions of the Kbann network.
To address this limitation, we broaden the types of topologies that TopGen considers
by using genetic algorithms (GAs). We choose GAs for two reasons. First, GAs have
been shown to be effective optimization techniques because of their ecient use of global
information (Goldberg, 1989; Holland, 1975; Mitchell, 1996). Second, GAs have an inherent
quality which makes them suitable for anytime learning. In \off-line" application mode
(DeJong, 1975), GAs simulate many alternatives and output the best alternative seen so
far.
Our new algorithm, Regent, proceeds by first trying to generate, from the domain
theory, a diversified initial population. It then produces new candidate networks via the
genetic operators of crossover and mutation, after which these networks are trained using
backpropagation. Regent's crossover operator tries to maintain the rule structure of the
network, while its mutation operator adds nodes to a network by using the TopGen algorithm. Hence, our genetic operators are specialized for connectionist theory refinement.
Experiments reported herein show that Regent is better able to search for network topologies than TopGen.
178

fiConnectionist Theory Refinement

The rest of the paper is organized as follows. In the next section, we briey argue for
the importance of effectively exploiting data, theory, and available computer time in the
learning process. We then review the Kbann and TopGen algorithms. We present the
details of our Regent algorithm in Section 4. This is followed by empirical results from
three Human Genome Project domains. In Section 6, we discuss these results, as well as
future work. We then review related work before concluding.

2. Using Data, Prior Knowledge, and Available CPU Cycles
A system that learns from a set of labeled examples is called an inductive learner (alternately, a supervised, empirical, or similarity-based learner). The output for each example
is provided by a teacher, and the set of labeled examples given to a learner is called the
training set. The task of inductive learning is to generate from the training set a concept
description that correctly predicts the output of all future examples, not just those from
the training set. Many inductive-learning algorithms have been previously studied (e.g.,
Michalski, 1983; Quinlan, 1986; Rumelhart et al., 1986). These algorithms differ both
in their concept-representation language, and in their method (or bias) for constructing a
concept within this language. These differences are important since they determine which
concepts a classifier will induce.
An alternative to the inductive learning paradigm is to build a concept description not
from a set of examples, but by querying experts in the field and directly assembling a set of
rules that describe the concept (i.e., build an expert system; Waterman, 1986). A problem
with building expert systems is that the theories derived from interviewing the experts tend
to be only approximately correct. Thus, while the expert-provided domain theory is usually
a good first approximation of the concept to be learned, inaccuracies are frequently exposed
during empirical testing.
Theory-refinement systems (Ginsberg, 1990; Ourston & Mooney, 1994; Pazzani & Kibler,
1992; Towell & Shavlik, 1994) are systems that revise a theory on the basis of a collection of
examples. These systems try to improve the theory by making minimal repairs to the theory
to make it consistent with the training data. Changes to the initial domain theory should
be kept to a minimum because the theory presumably contains useful information, even if
it is not completely correct. These hybrid learning systems are designed to learn from both
theory and data, and empirical tests have shown them to achieve high generalization with
significantly fewer examples than purely inductive-learning techniques (Ourston & Mooney,
1994; Pazzani & Kibler, 1992; Towell & Shavlik, 1994). Thus, an ideal inductive-learning
system should be able to incorporate any background knowledge that is available in the
form of a domain theory to improve its ability to generalize.
As indicated earlier, available computer time is also an important resource since (a) computing power is rapidly increasing, and (b) for most problems an expert is willing to wait a
lengthy period for an improved concept. For these reasons, one should develop \anytime"
learning algorithms that can continually improve the quality of their answer over time. Dean
and Boddy (1988) defined the criteria for an anytime algorithm to be: (a) the algorithm can
be suspended and then resumed with minimal overhead, (b) the algorithm can be stopped
at any time and return an answer, and (c) the algorithm must return answers that improve
179

fiOpitz & Shavlik

x
x

x

x

Output

x x

x

x

x

Input

Figure 1: This is a classical regression example where a smooth function (the solid curve)
that does not fit all of the noisy data points (the x's) is probably a better predictor
than a high-degree polynomial (the dashed curve).

over time. While these criteria were created for planning and scheduling algorithms, they
can apply to inductive learning algorithms as well.1
Most standard inductive learners, such as backpropagation (Rumelhart et al., 1986) and
ID3 (Quinlan, 1986), are unable to continually improve their answers (at least until they
receive additional training examples). In fact, if run too long, these algorithms tend to
\overfit" the training set (Holder, 1991). Overfitting occurs when the learning algorithm
produces a concept that captures too much information about the training examples, and
not enough about the general characteristics of the domain as a whole. While these concepts
do a great job of classifying the training instances, they do a poor job of generalizing to
new examples { our ultimate measure of success. To help illustrate this point, consider
the typical regression case shown in Figure 1. Here, fitting noisy data with a high-degree
polynomial is likely to lead to poor generalization.
The general framework we use for encouraging our algorithm to improve its answer
over time is quite simple. We spend our computer time considering many different possible
concept descriptions, scoring each possibility, and always keeping the description that scores
the best. Our framework is anytime with respect to the scoring function. The scoring
function is only an approximate measure of generalization and is obviously still prone to the
problems of overfitting; thus there is no guarantee that generalization will monotonically
decrease over time. Nevertheless, assuming an accurate scoring function, then as long as we
are considering a wide range of good possibilities, the quality of our best concept is likely
to improve for a longer period of time.
1. Our use of the term anytime learning differs from that of Grefenstette and Ramsey (1992); they use it
to mean continuous learning in a changing environment.

180

fiConnectionist Theory Refinement

3. Review of KBANN and TopGen
The goal of this research is to exploit both prior knowledge and available computing cycles
to search for the neural network that is most likely to generalize the best. We proceed
by choosing, as an initial guess, the network defined by the Kbann algorithm. We then
continually refine this topology to find the best network for our concept. Before presenting
our new algorithm (Regent), we give an overview of the Kbann algorithm as well as our
initial approach of refining a Kbann-created network's topology (TopGen).

3.1 The KBANN Algorithm
Kbann (Towell & Shavlik, 1994) works by translating a domain theory consisting of a set of

propositional rules directly into a neural network (see Figure 2). Figure 2a shows a Prologlike rule set that defines membership in category a. Figure 2b represents the hierarchical
structure of these rules, with solid lines representing necessary dependencies and dotted lines
representing prohibitory dependencies. Figure 2c represents the network Kbann creates
from this translation. It sets the biases so that nodes representing disjuncts have an output
near 1 only when at least one of their high-weighted antecedents is satisfied, while nodes
representing conjuncts must have all of their high-weighted antecedents satisfied (i.e., near
1 for positive links and near 0 for negative links). Otherwise activations are near 0. Kbann
creates nodes b1 and b2 in Figure 2c to handle the two rules disjunctively defining b. The
thin lines in Figure 2c represent low-weighted links that Kbann adds to allow these rules
to add new antecedents during backpropagation training. Following network initialization,
Kbann uses the available training instances to refine the network links. Refer to Towell
(1991) or Towell and Shavlik (1994) for more details.
Kbann has been successfully applied to several real-world problems, such as the control
of a chemical plant (Scott, Shavlik, & Ray, 1992), protein folding (Maclin & Shavlik, 1993),
a

a : b, not c.
b : d, f, g.

b

a

b1

b : d, not f, i.
c : h, j, k.
d
(a)

b

c

e f g h i j k
(b)

d e

b2

f

g h i
(c)

c

j k

Figure 2: KBANN's translation of a knowledge base into a neural network. Panel (a) shows
a sample propositional rule set in Prolog (Clocksin & Mellish, 1987) notation,
panel (b) illustrates this rule set's corresponding and/or dependency tree, and
panel (c) shows the resulting network created by Kbann's translation.
181

fiOpitz & Shavlik

finding genes in a sequence of DNA (Opitz & Shavlik, 1995; Towell & Shavlik, 1994), and
ECG patient monitoring (Watrous, Towell, & Glassman, 1993). In each case, Kbann was
shown to produce improvements in generalization over standard neural networks for small
numbers of training examples. In fact, Towell (1991) favorably compared Kbann with
a wide variety of algorithms, including purely symbolic theory-refinement systems, on a
version of the promoter and splice-junction tasks that we include as testbeds in Section 5.
While training the Kbann-created network alters the antecedents of existing rules, it
does not have the capability of inducing new rules because it does not add any additional
hidden nodes during training. For instance, Kbann is unable to add a third rule for
inferring b in Figure 2's example. To help illustrate this point, consider the following
example. Assume that Figure 2's target concept consists of Figure 2a's domain theory plus
the rule:
b :- not d, e, g.
Although we trained the Kbann network shown in Figure 2c with all possible examples of
this target concept, it was unable to completely learn the conditions under which a is true.
The topology of the Kbann network must be modified in order to learn this new rule.
Studies show (Opitz & Shavlik, 1995; Towell, 1991) that while Kbann is effective at
removing extraneous rules and antecedents in an expert-provided domain theory, its generalization ability suffers when given \impoverished" domain theories { theories that are
missing rules or antecedents needed to adequately learn the true concept. An ideal connectionist theory-refinement algorithm, therefore, should be able to dynamically expand the
topology of its network during training.

3.2 The TopGen Algorithm

TopGen (Opitz & Shavlik, 1995) addresses Kbann's limitation by heuristically searching
through the space of possible expansions to a knowledge-based neural network { a network
whose topology is determined by the direct mapping of the dependencies of a domain theory
(e.g., a Kbann network). TopGen proceeds by first training the Kbann network, then
placing it on a search queue. In each cycle, TopGen takes the best network from the search
queue, estimates where errors occur in the network, adds new nodes in response to these
estimates, trains these new networks, then places them back on the queue. TopGen judges
where errors occur in a network by using training examples to increment two counters for
each node, one for false negatives and one for false positives.
Figure 3 illustrates the possible ways TopGen can add nodes to one of its networks. In a
symbolic rule base that uses negation-by-failure, one can decrease false negatives by either
dropping antecedents from existing rules or adding new rules to the rule base. Kbann
is effective at removing antecedents from existing rules, but is unable to add new rules;
therefore, TopGen adds nodes, intended for decreasing false negatives, in a fashion that is
analogous to adding a new rule to the rule base. If the existing node is an or node, TopGen
adds a new node as its child (see Figure 3a), and fully connects this new node to the input
nodes. When the existing node is an and node, TopGen creates a new or node that is
the parent of the original and node and another new node that TopGen fully connects to
the inputs (see Figure 3c); TopGen moves the outgoing links of the original node (A in
Figure 3c) to become the outgoing links of the new or node.
182

fiConnectionist Theory Refinement

Existing Node

Decrease False Negatives

Decrease False Positives
...

...

...

New
Node

A

A

New
Node

A
B

B

C

OR Node

C

New
Node

B

C

(a)

(b)
...

A

C

AND Node

A

New
Node

A
B

...

New
Node

...

B
B

C

C

(c)

New
Node

(d)

Figure 3: Possible ways to add new nodes to a knowledge-based neural network (arcs indicate AND nodes). To decrease false negatives, we wish to broaden the applicability of the node. Conversely, to decrease false positives, we wish to further
constrain the node.
In a symbolic rule base, one can decrease false positives by either adding antecedents
to existing rules or removing rules from the rule base. Kbann can effectively remove
rules, but it is less effective at adding antecedents to rules and is unable to invent (i.e.,
constructively induce; Michalski, 1983) new terms as antecedents. Thus TopGen adds new
nodes, intended to decrease false positives, in a fashion that is analogous to adding new
constructively induced antecedents to the network. Figures 3b and 3d illustrates how this is
done (analogous to Figures 3a and 3c explained above). Refer to Opitz and Shavlik (1993;
1995) for more details.
TopGen showed statistically significant improvements over Kbann in several real-world
domains, and comparative experiments with a simpler approach to adding nodes verified
that new nodes must be added in an intelligent manner (Opitz & Shavlik, 1995). In this
article, however, we increase the number of networks TopGen considers during its search
and show that the increase in generalization is primarily limited to the first few networks
considered. Therefore, TopGen is not so much an \anytime" algorithm, but rather is a first
step towards one. This is mostly due to the fact that TopGen only considers larger networks that contain the original Kbann network as subgraphs; however, as one increases the
number of networks considered, one should also increase the variety of networks considered
183

fiOpitz & Shavlik

during the search. Broadening the range of networks considered during the search through
topology space is the major focus of this paper.

4. The REGENT Algorithm

Our new algorithm, Regent, tries to broaden the types of networks that TopGen considers
with the use of GAs. We view Regent as having two phases: (a) genetically searching
through topology space, and (b) training each network using backpropagation's gradient
descent method. Regent uses the domain theory to aid in both phases. It uses the theory
to help guide its search through topology space and to give a good starting point in weight
space.
Table 1 summarizes the Regent algorithm. Regent first sets aside a validation set
(from part of the training instances) for use in scoring the different networks. It then perturbs the Kbann-produced network to create an initial set of candidate networks. Next,
Regent trains these networks using backpropagation and places them into the population. In each cycle, Regent creates new networks by crossing over and mutating networks
from the current population that are randomly picked proportional to their fitness (i.e.,
validation-set correctness). It then trains these new networks and places them into the
population. As it searches, Regent keeps the network that has the lowest validation-set
error as the best concept seen so far, breaking ties by choosing the smaller network in an
application of Occam's Razor. A parallel version of Regent trains many candidate networks at the same time using the Condor system (Litzkow, Livny, & Mutka, 1988), which
runs jobs on idle workstations.
A diverse initial population will broaden the types of networks Regent considers during
its search; however, since the domain theory may provide useful information that may not be
present in the training set, it is still desirable to use this theory when generating the initial
population. Regent creates diversity around the domain theory by randomly perturbing
the Kbann network at various nodes. Regent perturbs a node by either deleting it, or by
adding new nodes to it in a manner analogous to one of TopGen's four methods for adding

GOAL: Search for the best network topology describing the domain theory and data.

1. Set aside a validation set from the training instances.
2. Perturb the Kbann-produced network in multiple ways to create initial networks, then train
these networks using backpropagation and place them into the population.
3. Loop forever:
(a) Create new networks using the crossover and mutation operators.
(b) Train these networks with backpropagation, score with the validation set, and place into
the population.
(c) If a new network is the network with the lowest validation-set error seen so far (breaking
ties by preferring the smallest network), report it as the current best concept.

Table 1: The REGENT algorithm.
184

fiConnectionist Theory Refinement

Crossover Two Networks:

GOAL: Crossover two networks to generate two new network topologies.
1. Divide each network's hidden nodes into sets A and B using DivideNodes.

2. Set A forms one network, while set B forms another. Each new network is created as follows:
(a) A network inherits weight w from its parent if nodes i and j either are also inherited
or are input or output nodes.
(b) Link unconnected nodes between levels with near-zero weights.
(c) Adjust node biases to keep original and or or function of each node (see text for explanation).
ji

DivideNodes:
GOAL:

Divide the hidden nodes into sets A and B, while probabilistically maintaining each
network's rule structure.
While some hidden node is not assigned to set A or B:
(i) Collect those unassigned hidden nodes whose output is linked only to either previouslyassigned nodes or output nodes.
(ii) If set A or set B is empty:
For each node collected in part (i), randomly assign it to set A or set B.

Else

Probabilistically add the nodes collected in part (i) to set A or set B. Equation 1
shows the probability of being assigned to set A. The probability of being assigned
to set B is one minus this value.

Table 2: REGENT's method for crossing over networks.
nodes. (Should there happen to be multiple theories about a domain, all of them can be
used to seed the population.)

4.1 REGENT's Crossover Operator

Regent crosses over two networks by first dividing the nodes in each parent network into

two sets, A and B, then combining the nodes in each set to form two new networks (i.e., the
nodes in the two A sets form one network, while the nodes in the two B sets form another).
Table 2 summarizes Regent's method for crossover and Figure 4 illustrates it with an
example. Regent divides nodes, one level2 at a time, starting at the level nearest the
output nodes. When considering a level, if either set A or set B is empty, it cycles through
each node in that level and randomly assigns it to either set. If neither set is empty, nodes
are probabilistically placed into a set. The following equation calculates the probability of
2. Although one can define level several different ways, we define a node's level as the longest path from it
to an output node.

185

fiOpitz & Shavlik

Original
Networks
Crossed
Over

Output

Output

Input

Input

Output

Output

Input

Input

Resulting
Networks
Figure 4: REGENT's method for crossing over two networks. The hidden nodes in each
original network are divided into the sets A and B; the nodes in the two A sets
form one new network, while the nodes in the two B sets form another. Grey lines
represent low-weighted links that are added to fully connect neighboring levels.
a given node being assigned to set A:

Pj2A jwjij
Prob(node i 2 setA) = P jw j + P jw j ;
j 2A ji
j 2B ji

(1)

where j 2 A means node j is a member of set A and wji is the weight value from node i
to node j . The probability of belonging to set B is one minus this probability. With these
probabilities, Regent tends to assign to the same set those nodes that are heavily linked
together. This helps to minimize the destruction of the rule structure of the crossed-over
networks, since nodes belonging to the same syntactic rule are connected by heavily linked
weights. Thus, Regent's crossover operator produces new networks by crossing-over rules,
rather than simply crossing-over nodes.
Regent must next decide how to connect the nodes of the newly created networks.
First, a new network inherits all weight values from its parents on links that (a) connect
two nodes that are both inherited by the new network, (b) connect an inherited hidden
node and an input or output node, or (c) directly connect an input node to an output node.
It then adds randomly set, low-weighted links between unconnected nodes on consecutive
levels.
Finally, it adjusts the bias of all and or or nodes to help maintain their original function.
For instance, if Regent removes a positively weighted incoming link for an and node,
it decrements the node's bias by subtracting the product of the link's magnitude and the
186

fiConnectionist Theory Refinement

average activation (over the set of training examples) entering that link. We do this because
the bias for an and node needs to be slightly less than the sum of the positive weights on
the incoming links (see Towell and Shavlik, 1994 for more details). Regent increments the
bias for an or node by an analogous amount when it removes negatively weighted incoming
links (since the bias for an or node should be slightly greater than the sum of the negative
weights on the incoming links so that the node is inactive only when all incoming negatively
weighted linked nodes are active and all positively weighted linked nodes are inactive).

4.2 REGENT's Mutation Operator

Regent mutates networks by applying a variant of TopGen. Regent uses TopGen's
method for incrementing the false-negatives and false-positives counters for each node. Regent then adds nodes, based on the values of these counters, the same way TopGen does.

Since neural learning is effective at removing unwanted antecedents and rules from KNNs
(see Section 3.1), Regent only considers adding nodes, and not deleting them, during mutation. Thus, this mutation operator adds diversity to a population, while still maintaining
a directed, heuristic-search technique for choosing where to add nodes; this directedness is
necessary because we currently are unable to evaluate more than a few thousand possible
networks per day.

4.3 Additional Details
Regent adds newly trained networks to the population only if their validation-set correctness is better than or equal to an existing member of the population. When Regent

replaces a member, it replaces the member having the lowest correctness (ties are broken
by choosing the oldest member). Other techniques (Goldberg, 1989), such as replacing the
member nearest the new candidate network, can promote diverse populations; however, we
do not want to promote diversity at the expense of decreased generalization. As a future
research topic, we plan to investigate incorporating diversity-promoting techniques once we
are able to consider tens of thousands of networks.
Regent can be considered a Lamarckian3 , genetic-hillclimbing algorithm (Ackley, 1987),
since it performs local optimizations on individuals, then passes the successful optimizations
on to offspring. The ability of individuals to learn can smooth the fitness landscape and
facilitate subsequent learning. Thus, Lamarckian learning can lead to a large increase in
learning speed and solution quality (Ackley & Littman, 1994; Farmer & Belin, 1992).

5. Experimental Results
In this section, we test Regent on three real-world Human Genome Project problems
that aid in locating genes in DNA sequences (recognizing promoters, splice-junctions, and
ribosome-binding sites). In these domains, the input is a short segment of DNA nucleotides
(about 100 elements long) and the task is learn to predict if this DNA subsequence contains a
biologically important site. Each domain is also accompanied by a domain theory generated
by a DNA expert (M. Noordewier).
3. Lamarckian evolution is a theory based on the inheritance of characteristics acquired during a lifetime.

187

fiOpitz & Shavlik

The promoter domain contains 234 positive examples, 702 negative examples, and 31
rules. The splice-junction domain contains 1,200 examples distributed equally among three
classes, and 23 rules. Finally, the ribosome binding sites (RBS) domain, contains 366
positive examples, 1,098 negative examples, and 17 rules. (Note that the promoter data set
and domain theory is a later version of the one that appears in Towell, 1994.) These domains
are available at the University of Wisconsin Machine Learning (UW-ML) site via the World
Wide Web (ftp://ftp.cs.wisc.edu/machine-learning/shavlik-group/datasets/) or
anonymous ftp (ftp.cs.wisc.edu, then machine-learning/shavlik-group/datasets).
We first directly compare Regent with TopGen and Kbann. We then perform a
lesion study4 on Regent. In particular, we investigate the value of adding randomly
created networks to Regent's initial population and examine the utility of Regent's
genetic operators.

5.1 Experimental Methodology

All results in this article are from ten-fold cross validation runs. For each ten-fold cross
validation the data set is first partitioned into ten equal-sized sets, then each set is in turn
used as the test set while the classifier trains on the other nine sets. In each fold, Regent is
run with a population size of 20. Each network is trained using backpropagation. Parameter
settings for the neural networks include a learning rate of 0.10, a momentum term of 0.9,
and the number of training epochs of 20; the first two are standard settings and while 20
epochs may be fewer than typically found in the neural network literature, we set it at 20
to help avoid overfitting. We set aside a validation set consisting of 10% of the training
examples for Regent to use as its scoring function.

5.2 Generalization Ability of REGENT

This section's experiments compare the test-set accuracy (i.e., generalization) of Regent
with TopGen's. Figure 5 shows the test-set error of Kbann, TopGen, and Regent as they
search through the space of network topologies. The horizontal line in each graph results
from the Kbann algorithm. We drew a horizontal line for the sake of visual comparison;
recall that Kbann only considers a single network. The first point of each graph, after
one network is considered, is nearly the same for all three algorithms, since they all start
with the Kbann network; however, TopGen and Regent differ slightly from Kbann since
they must set aside part of the training set to score their candidate networks. Notice that
TopGen stops improving after considering 10 to 30 networks and that the generalization
ability of Regent is better than TopGen's after this point. The reason for the occasional
upward movements in Figure 5 is due to the fact that a validation set (or any scoring
function) is an inexact estimate of the true generalization error (as are the results of the
ten-fold cross validation).
Figure 6 presents the test-set error of TopGen and Regent after they each consider
500 candidate topologies. The standard neural network results are from a fully connected,
single-layer, feed-forward neural network; for each fold, we trained 20 networks containing
up to 100 hidden nodes and used a validation set to choose the best network. Our results
4. A lesion study is one where components of an algorithm are individually disabled to ascertain their
contribution to the full algorithm's performance (Kibler & Langley, 1988).

188

fiConnectionist Theory Refinement

10 %

8%
Ribosome Binding Sites

6%
KBANN
TopGen

4%

REGENT

TestSet Error

2%

6%

4%

Splice Junctions

2%

6%

4%
Promoters
2%

0

100

200

300

400

Networks Considered
Figure 5: Error rates on the three Human Genome problems.

189

500

fiOpitz & Shavlik

show Kbann generalizes much better than the best of these standard networks, thus further
confirming Kbann's effectiveness in generating good network topologies. While TopGen is
able to improve on the Kbann network, Regent is able to significantly decrease the error
rate over both Kbann and TopGen. (For benchmark purposes, Regent has an error rate
of 3.9% from a ten-fold cross validation on the full Splice Junction dataset of 3190 examples
commonly used by machine learning researchers.)
Table 3 contains the number of hidden nodes in the final networks produced by Kbann,
TopGen, and Regent. The results demonstrate that Regent produces networks that are
larger than both Kbann's and TopGen's networks (even though TopGen only adds nodes
during its search). While Regent's networks are larger, it does not necessarily mean that
they are more \complex." We inspected sample networks and found that there are large
portions of the network that are either not used (e.g., their weights are insignificantly small)
or are functional duplications of other groups of hidden nodes.
One could prune weights and nodes during Regent's search; however, such pruning can
prematurely reduce the variety of structures available for recombination during crossover
(Koza, 1992). Real-life organisms, for instance, have superuous DNA that are believed
to enhance the rate of evolution (Watson, Hopkins, Roberts, Argetsinger-Steitz, & Weiner,
1987). However, while pruning network size during genetic search may be unwise, one
could prune Regent's final network using, say, Hassibi and Stork's (1992) Optimal Brain
Surgeon algorithm. This post-pruning process may increase the future classification speed
of the network, as well as increase its comprehensibility and possibly its accuracy.

5.3 Lesion Study of REGENT
In this section, we describe a lesion study we performed on Regent. Since a single run
of Regent takes about four CPU days to consider 500 networks, a single ten-fold cross
10.70
10 %

9.40

9.15

TestSet Error

8.23
8%

7.83
6.62

6%

5.25 4.92

Key

6.26

Standard NN

5.25

4.08

4.17

KBANN
TopGen

4%

REGENT
2%

RBS

Splice Junctions

Promoters

Figure 6: Test-set error rates after TopGen and REGENT each consider 500 networks. Pairwise, one-tailed t-tests indicate that Regent differs from Standard NN, Kbann,
and TopGen at the 95% confidence level on all three problems.
190

fiConnectionist Theory Refinement

Domain
Kbann TopGen
Regent
RBS
18
42.1 (9.3) 70.1 (25.1)
Splice Junction
21
28.4 (4.1) 32.4 (12.2)
Promoters
31
40.2 (3.3) 74.9 (38.9)
Table 3: Number of hidden nodes in the networks produced by KBANN, TopGen, and
REGENT. The columns show the mean number of hidden nodes found within
these networks. Standard deviations are contained within parentheses; we do not
report standard deviations for Kbann since it uses only one network.

validation takes (a minimum of) 40 CPU days. Therefore, given the inherent similarity
of investigating various aspects of Regent over multiple datasets, it is not feasible to
run all experiments in this section until a 95% confidence level is reached in all cases
(assuming that such a level actually exists). Nonetheless, these results convey important
information about various components of Regent, and, as shown in the previous section,
the complete Regent algorithm does generate statistically significant improvements over
existing algorithms.
5.3.1 Including Non-KNNs in REGENT's Population

The correct theory may be quite different from the initial domain theory. Thus, in this
section we investigate whether one should include, in the initial population of networks,
a variety of networks not obtained directly from the domain theory. Currently, Regent
creates its initial population by always perturbing the Kbann network. To include networks
that are not obtained from the domain theory, we first randomly pick the number of hidden
nodes to include in a network, then randomly create all of the hidden nodes in this network.
We do this by adding new nodes to a randomly selected output or hidden node using one
of TopGen's four methods for adding new nodes (refer to Figure 3). Adding nodes in this
manner creates random networks whose node structure is analogous to dependencies found
in symbolic rule bases, thus creating networks suitable for Regent's crossover and mutation
operators.
Table 4 shows the test-set error of Regent with various percentages of knowledge-based
neural networks (KNNs) present in the initial population. The first row contains the results
of initializing Regent with a purely random initial population (i.e., the population contains
no KNNs). The second row lists the results when Regent creates half its population with
the domain theory, and the other half randomly. Finally, the last row contains the results
of seeding the entire population with the domain theory.
These results suggest that including, in the initial population, networks that were not
created from the domain theory increases Regent's test-set error on all three domains.
This occurs because the randomly generated networks are not as correct as the KNNs, and
191

fiOpitz & Shavlik

0% KNN
50% KNN
100% KNN

RBS
9.7%
8.6%
8.2%

Splice Junction
6.3%
4.3%
4.1%

Promoters
5.1%
4.6%
4.2%

Table 4: Test-set error after considering 500 networks. Each row gives the pergentage of
KNNs present in the initial population. Pairwise, one-tailed t-tests indicate that
initializing Regent with 100% KNNs differs from 0% KNNs at the 95% confidence
level on all three domains; however, the difference between the runs of 50% and
100% KNNs is not significant at this level.

thus offspring of the original KNN quickly replace the random networks. Hence, diversity in the population suffers compared to methods that start with a whole population of
KNNs. Assuming the domain theory is not \malicious," it is therefore better to seed the
entire population from the Kbann network. Should the domain theory indeed be malicious
and contain information that promotes spurious correlations in the data, it would then be
reasonable to randomly create the \whole" population. Running Regent both with and
without the domain theory allows one to investigate the utility of that theory.
These results are also interesting from a GA point of view. Forrest and Mitchell (1993)
showed that GAs perform poorly on complex problems where the basic building blocks either
(a) are non-trivial to find or (b) get split during crossover. Seeding the initial population
with a domain theory (as Regent does) can help define the basic building blocks for these
problems.
5.3.2 Value of REGENT's Mutation

Typically with GAs, mutation is a secondary operation that is only sparingly used (Goldberg, 1989); however, Regent's mutation is a directed approach that heuristically adds
nodes to KNNs in a provenly effective manner (i.e., it uses TopGen). It is therefore reasonable to hypothesize that one should apply the mutation operator more frequently than
traditionally done in GAs. The results in this section test this hypothesis.
Figure 7 presents the test-set error of Regent with varying percentages of mutation
(versus crossover) when creating new networks in step 3a of Table 1. Each graph plots four
curves: (a) 0% mutation (i.e., Regent only uses crossover), (b) 10% mutation, (c) 50%
mutation, and (d) 100% mutation. Performing no mutations tests the value of solely using
crossover, while 100% mutation tests the ecacy of the mutation operator by itself. Note
that 100% mutation is just TopGen with a different search strategy; instead of keeping
an OPEN list for heuristic search, a population of KNNs are generated and members of
the population are improved proportional to their fitness. The other two curves (10% and
50% mutation) test the synergy between the two operators. Performing 10% mutation is
192

fiConnectionist Theory Refinement

10 %

8%

Ribosome Binding Sites
6%
0% Mutation
10% Mutation

4%

50% Mutation
100% Mutation

TestSet Error

2%

6%

4%

Splice Junctions
2%

6%

4%

Promoters
2%

0

100

200

300

400

500

Networks Considered
Figure 7: Error rates of REGENT with different fractions of mutation versus crossover
after considering 500 networks. Arguably due to the inherent similarity of the
algorithms, and the limited number of runs due to their computational complexity,
the results are not significant at the 95% confidence level.

193

fiOpitz & Shavlik

closer to the traditional GA viewpoint that mutation is a secondary operation, while 50%
mutation means that both operations are equally valuable. (Previous experiments in this
section used 50% mutation and 50% crossover.)
While the differences are not all statistically significant, the results nevertheless suggest
that a synergy exists between the two operations. Except for the middle portion of the
promoter domain, the results show that, qualitatively, using both operations at the same
time is better than using either operation alone. In fact, equally mixing the mutation and
crossover operator is better than the other three curves on all three domains once Regent
has considered 500 networks. This result is particularly pronounced on the splice-junction
domain.
5.3.3 Value of REGENT's Crossover
Regent tries to cross over the rules in the networks, rather than just blindly crossing over

nodes. It does this by probabilistically dividing the nodes in the network into two sets
where nodes belonging to the same rule tend to belong to the same set. In this section,
we test the ecacy of Regent's crossover by comparing it to a variant of itself where it
randomly assigns nodes to two sets (rather than using DivideNodes in Table 2).
Table 5 contains the results of this test after 250 networks were considered. In the
first row, Regent-random-crossover, Regent randomly breaks its hidden nodes into
two sets, while in the second row, Regent assigns nodes to two sets according to Table
2. In both cases, Regent creates half its networks with its mutation operator, and the
other half with crossover operator. Although the differences are not statistically significant,
the results suggest that keeping the rule structure of the networks intact during crossover
is important; otherwise, the basic building blocks of the networks (i.e., the rules) get split
during crossover, and studies have shown the importance of keeping intact the basic building
blocks during crossover (Forrest & Mitchell, 1993; Goldberg, 1989).

Regent-random-crossover
Regent

Promoters Splice Junction RBS
4.6%
4.7%
9.1%
4.4%
4.1%
8.8%

Table 5: Test-set error of two runs of REGENT: (a) randomly crossing over \nodes" in
the networks, and (b) one with crossing over \rules" in the network (defined by
Equation 1). Both runs considered 250 networks and used half crossover, half
mutation. The results are not significant at the 95% confidence level; there is only
a slight difference between the learning algorithms and the long run-times limited
runs to a ten-fold cross validation.

6. Discussion and Future Work

Towell (1991) showed Kbann generalized better than many other machine learning algorithms on the promoter and splice-junction domains (the RBS dataset did not exist then).
194

fiConnectionist Theory Refinement

Despite this success, Regent is able to effectively use available computer cycles to significantly improve generalization over both Kbann and our previous improvement to Kbann,
the TopGen algorithm. Regent reduces Kbann's test-set error by 12% for the RBS domain, 22% for the splice-junction domain, and 33% for the promoter domain; it reduces
TopGen's test-set error by 10% for the RBS domain, 17% for the splice-junction domain, and
21% for the promoter domain. Also, Regent's ability to use available computing time is
further aided by being inherently parallel, since we can train many networks simultaneously.
Further results show that Regent's two genetic operators complement each other. The
crossover operator considers a large variety of network topologies by probabilistically combining rules contained within two \successful" KNNs. Mutation, on the other hand, makes
smaller, directed improvements to members of the population, while at the same time adding
diversity to the population by adding new rules to the population. Equal use of both operators, therefore, allows a wide variety of topologies to be considered as well as allowing
incremental improvements to members of the population.
Since Regent searches through many candidate networks, it is important for it to be
able to recognize the networks that are likely to generalize the best. With this in mind, our
first planned extension of Regent is to develop and test different network-evaluation functions. We currently use a validation set; however, validation sets have several drawbacks.
First, keeping aside a validation set decreases the number of training instances available
for each network. Second, the performance of a validation set can be a noisy approximator
of the true error (MacKay, 1992; Weigend, Huberman, & Rumelhart, 1990). Finally, as
we increase the number of networks searched, Regent may start selecting networks that
overfit the validation set. In fact, this explains the occasional upward trend in test-set error,
from both TopGen and Regent, in Figure 5.
To avoid the problem of overfitting the data, a common regression trick is to have a cost
function that includes a \smoothness" term along with the error term. The best function,
then, will be the smoothest function that also fits the data well. For neural networks, one
can add to the estimated error a smoothness component that is a measure of the complexity
of the network. The complexity of the network cannot simply be estimated by counting
the number of possible parameters, since there tends to be significant duplication in the
function of each weight in a network, especially early in the training process (Weigend,
1993). Two techniques that try to take into account the effective size of the network are
Generalized Prediction Error (Moody, 1991) and Bayesian methods (MacKay, 1992).
Quinlan and Cameron-Jones (1995) propose adding an additional term to the accuracy
and smoothness term that takes into account length of time spent searching. They coin the
term \oversearching" to describe the phenomenon where more extensive searching causes
lower predictive accuracy. Their claim is that oversearching is orthogonal to overfitting, and
thus these complexity-based methods alone cannot prevent oversearching. As we increase
the number of networks we consider during a search, we too may start oversearching, and
thus plan to investigate adding an oversearching penalty term as well.
As indicated earlier, Regent is Lamarckian in that it passes local optimizations of individuals (i.e., the trained weights of a network) to offspring. A viable alternative, called the
Baldwin effect (Ackley & Littman, 1992; Baldwin, 1896; Belew & Mitchell, 1996; Hinton &
Nowlan, 1987), is to have local search still change the fitness of an individual (backpropagation learning in this case), but then not pass these changes on to the offspring (this form of
195

fiOpitz & Shavlik

evolution is Darwinian in nature). Even though what is learned is not explicitly coded into
the genetic material, individuals who are best able to learn will have the most offspring;
thus learning still impacts evolution. In fact this form of evolution can sometimes outperform forms of Lamarckian evolution that employ the same local search strategy (Whitley,
Gordon, & Mathias, 1994). Future work is to investigate the utility of the Baldwin effect
on Regent. In this case we would not cross over the trained networks, but instead cross
over the initial weight settings before backpropagation learning took place.
Finally, often times there are multiple, even conicting, theories about a domain. Future work, then, is to investigate ways of using all of these domain theories to seed the
initial population. Although the results in Section 5.3.1 show that including randomly generated networks degrades generalization performance, seeding the population with multiple
approximately correct theories should not degrade generalization, assuming the networks
will have about the same initial correctness. Thus Regent should be able to naturally
combine good parts of multiple theories. Also, for a given domain theory, there are many
different but equivalent ways to represent that theory using a set of propositional rules.
Each representation leads to a different network topology, and even though each network
starts with the same theory, some topologies may be more conducive to neural refinement.

7. Related Work

Regent mainly differs from previous work in that it is an\anytime" theory-refinement sys-

tem that continually searches, in a non-hillclimbing manner, for improvements to the domain
theory. In summary, our work is unique in that it provides a connectionist approach that
attempts to effectively utilize available background knowledge and available computer cycles
to generate the best concept possible. We have broken the rest of this section into four parts:
(a) connectionist theory-refinement algorithms, (b) purely symbolic theory-refinement algorithms, (c) algorithms that find an appropriate domain-specific neural-network topology,
and (d) optimization algorithms wrapped around induction algorithms.

7.1 Connectionist Theory-Refinement Techniques

We begin our discussion with connectionist theory-refinement systems. These systems have
been developed to refine many types of rule bases. For instance, a number of systems
have been proposed for revising certainty-factor rule bases (Fu, 1989; Lacher et al., 1992;
Mahoney & Mooney, 1993), finite-state automata (Maclin & Shavlik, 1993; Omlin & Giles,
1992), push-down automata (Das, Giles, & Sun, 1992), fuzzy-logic rules (Berenji, 1991;
Masuoka, Watanabe, Kawamura, Owada, & Asakawa, 1990), and mathematical equations
(Roscheisen, Hofmann, & Tresp, 1991; Scott et al., 1992). Most of these systems work like
Kbann by first translating the domain knowledge into a neural network, then modifying
the weights of this resulting network. Few attempts (which we describe next) have been
made to dynamically adjust the resulting network's topology during training (as Regent
does).
Like both TopGen and Regent, Fletcher and Obradovic (1993) present an approach
that adds nodes to a Kbann network. Their system constructs a single layer of nodes, fully
connected between the input and output nodes, \off to the side" of the Kbann network.
They generate new hidden nodes using a variant of Baum and Lang's (1991) constructive
196

fiConnectionist Theory Refinement

algorithm. Baum and Lang's algorithm first divides the feature space with hyperplanes.
They find each hyperplane by randomly selecting two points from different classes, then
localizing a suitable split between these points. Baum and Lang repeat this process until
they generate a fixed number of hyperplanes. Fletcher and Obradovic then map each of
Baum and Lang's hyperplanes into one new hidden node, thus defining the weights between
the input layer and that hidden node. Fletcher and Obradovic's algorithm does not change
the weights of the Kbann portion of the network, so modifications to the initial rule base
are solely left to the constructed hidden nodes. Thus, their system does not take advantage
of Kbann's strength of removing unwanted antecedents and rules from the original rule
base. In fact, TopGen compared favorably to a similar technique that also added nodes off
to the side of Kbann (Opitz & Shavlik, 1993) and Regent outperformed TopGen in this
article's experiments.
Rapture (Mahoney & Mooney, 1994) is designed for domain theories containing probabilistic rules. Like most connectionist theory-refinement systems, Rapture first translates
the domain theory into a neural network, then refines the weights of the network with a
modified backpropagation algorithm. Like Regent, Rapture is then able to dynamically
refine the topology of its network. It does this by using the Upstart algorithm (Frean,
1990) to add new nodes to the network. Aside from being designed for probabilistic rules,
Rapture differs from Regent in that it adds nodes with the intention of completely
learning the training set, not generalizing well. Thus, while Rapture hillclimbs until the
training set is learned, Regent continually searches topology space looking for a network
that minimizes the scoring function's error. Also, Rapture initially only creates links that
are specified in the domain theory, and only explicitly adds links through ID3's (Quinlan,
1986) information-gain metric. Regent, on the other hand, fully connect consecutive layers
in their networks, allowing each rule the possibility of adding antecedents during training.
The Daid algorithm (Towell & Shavlik, 1992) is an extension to Kbann that uses the
domain theory to help train the Kbann network. Since Kbann is more effective at dropping antecedents than adding them, Daid tries to find potentially useful inputs features
not mentioned in the domain theory. It does this by backing-up errors to the lowest level of
the domain theory, then computing correlations with the features. Daid then increases the
weight of the links from the potentially useful input features based on these correlations.
Daid mainly differs from Regent in that it does not refine the topology of the Kbann network. Thus, while Daid addresses Kbann's limitation of not effectively adding antecedents,
it is still unable to introduce new rules or constructively induce new antecedents. Daid will
therefore suffer with impoverished domain theories. Also notice that since Daid is an improvement for training KNNs, Regent can use Daid to train each network it considers
during its search (however, we have not done so).
Opitz and Shavlik (1996) used a variant of Regent as their learning algorithm when
generating a neural network \ensemble." A neural-network ensemble is a very successful
technique where the outputs of a set of separately trained neural networks are combined
to form one unified prediction (Drucker, Cortes, Jackel, LeCun, & Vapnik, 1994; Hansen
& Salamon, 1990; Perrone, 1993). Since Regent considers many networks, it can select a
subset of the final population of networks as an ensemble at minimal extra cost. Previous
work, though, has shown that an ideal ensemble is one where the networks are both accurate
and make their errors on different parts of the input space (Hansen & Salamon, 1990;
197

fiOpitz & Shavlik

Krogh & Vedelsby, 1995). As a result, Opitz and Shavlik (1996) changed the scoring
function of Regent so that a \fit" network was now one that was both accurate and
disagreed with the other members of the population as much as possible. In addition,
their algorithm (Addemup) actively tries to generate good candidates by emphasizing the
current population's erroneous examples during backpropagation training. As a result of
these alterations, Addemup is able to create enough diversity among the population of
networks to be able to effectively exploit the knowledge of the domain theory. Opitz and
Shavlik (1996) show that Addemup is able to generate a significantly better ensemble
using the domain theory than either running Addemup without the benefit of the theory
or simply combining Regent's final population of networks. Actively searching for a highly
diverse population, however, does not aid in searching for the single best network. In fact,
the single best network produced by Addemup is significantly worse than Regent's single
best network on all three domains.

7.2 Purely Symbolic Theory-Refinement Techniques
Additional work related to Regent includes purely symbolic theory-refinement systems
that modify the domain theory directly in its initial form. Systems such as Focl (Pazzani
& Kibler, 1992) and Forte (Richards & Mooney, 1995) are first-order, theory-refinement
systems that revise predicate-logic theories. One drawback to these systems is that they
currently do not generalize as well as connectionist approaches on many real-world problems,
such as the DNA promoter task (Cohen, 1992).
There have been several genetic-based, first-order logic, multimodal concept learners
(Greene & Smith, 1993; Janikow, 1993). Giordana and Saitta (1993) showed how to integrate one of these system, Regal (Giordana, Saitta, & Zini, 1994; Neri & Saitta, 1996),
with the deductive engine of ML-SMART (Bergadano, Giordana, & Ponsero, 1989) to help
refine an incomplete or inconsistent domain theory. This version works by first using an automated theorem prover to recognize unresolved literals in a proof, then uses the GA-based
Regal to induce corrections to these literals. Regent, on the other hand, use genetic
algorithms (along with neural learning) to refine the whole domain theory at the same time.
Dogma (Hekanaho, 1996) is a recently proposed GA-based learner that can use background knowledge to learn the same description language as Regal. Current restrictions,
however, force the representation language of the domain theory to be propositional rules.
Dogma converts a \at" set of background rules (i.e., it does not handle intermediate
conclusions) into individual bitstrings that are used as building blocks for a higher-level
concept. Dogma does not focus on theory refinement, rather it builds a completely new
theory using substructures from the background knowledge. They term their approach as
being more theory-suggested than theory-guided (Hekanaho, 1996).
Several systems, including ours, have been proposed for refining propositional rule bases.
Early such approaches could only handle improvements to overly specific theories (Danyluk,
1989) or specializations to overly general theories (Flann & Dietterich, 1989). Later systems
such as Rtls (Ginsberg, 1990), Either (Ourston & Mooney, 1994), Ptr (Koppel, Feldman,
& Segre, 1994), and Tgci (Donoho & Rendell, 1995) were later able to handle both types
of refinements. We discuss the Either system as a representative of these propositional
systems.
198

fiConnectionist Theory Refinement

Either has four theory-revision operators: (a) removing antecedents from a rule, (b)
adding antecedents to a rule, (c) removing rules from the rule base, and (d) inventing new
rules. Either uses these operators to make revisions to the domain theory that correctly
classify some of the previously misclassified training examples without undefining any of
the correctly classified examples. Either uses inductive learning algorithms to invent new
rules; it currently uses ID3 (Quinlan, 1986) as its induction component.
Even though Regent's mutation operator add nodes in a manner analogous to how
a symbolic system adds antecedents and rules, its underlying learning algorithm is \connectionist." Towell (1991) showed that Kbann outperformed Either on the promoter
task, and Regent outperformed Kbann in this article. Kbann's power on this domain
is largely attributed to its ability to make \fine-grain" refinements to the domain theory
(Towell, 1991). Because of Either's diculty on this domain, Baffes and Mooney (1993)
presented an extension to it called Neither-MofN that is able to learn M -of-N rules {
rules that are true if M of the N antecedents are true. This improvement generated a
concept that more closely matches Kbann's generalization performance.
While we want to minimize changes to a theory, we do not want to do it at the expense of accuracy; however, Donoho and Rendell (1995) demonstrate that most existing
theory-refinement systems, such as Either, suffer in that they are only able to make small,
local changes to the domain theory. Thus, when an accurate theory is significantly far in
structure from the initial theory, these systems are forced to either become trapped in a
local maximum similar to the initial theory, or are forced to drop entire rules and replace
them with new rules that are inductively created purely from scratch. Regent does not
suffer from this in that it translates the theory into the less restricting representation of
neural networks (Donoho & Rendell, 1995). Also, Regent is able to further reconfigure
the structure of the domain with genetic algorithms.
Many authors have reported results using varying subsets of the splice junction domain
(e.g., Donoho and Rendell 1995; Mahoney 1996; Neri and Saitta 1996, and Towell and Shavlik 1994). While these authors used different training set sizes, it is nevertheless worthwhile
to qualitatively discuss some of their conclusions here. Towell and Shavlik (1994) compared
Kbann with numerous machine learning algorithms where each learning algorithm was
given a training set of 1000 examples; Kbann's generalization ability compared favorably
with these algorithms on the splice domain and Regent, in turn, compared favorably with
Kbann in this article. Donoho and Rendell (1995) showed their purely symbolic approach
converged to the performance of Kbann at around 200 examples. Mahoney (1996) showed,
using training set sizes of up to 400 examples, that his Rapture algorithm generalized
better than Kbann on this domain; his results look similar to those of Regent. Finally,
Neri and Saitta (1996) showed that the generalization ability of the GA-based Regal compares favorably to other purely symbolic, non-GA based techniques; while they used slightly
different training set sizes than we did in this article, Regent compares well to the results
reported in their paper.

7.3 Finding Appropriate Network Topologies
Our third area of related work covers techniques that attempt to find a good domaindependent topology by dynamically refining their network's topology during training. Many
199

fiOpitz & Shavlik

studies have shown that the generalization ability of a neural network depends on the topology of the network (Baum & Haussler, 1989; Tishby, Levin, & Solla, 1989). When trying
to find an appropriate topology, one approach is to construct or modify a topology in an
incremental fashion. Network-shrinking algorithms start with too many parameters, then
remove nodes and weights during training (Hassibi & Stork, 1992; Le Cun, Denker, &
Solla, 1989; Mozer & Smolensky, 1989). Network-growing algorithms, on the other hand,
start with too few parameters, then add more nodes and weights during training (Blanziere
& Katenkamp, 1996; Fahlman & Lebiere, 1989; Frean, 1990). The most obvious difference between Regent and these algorithms is that Regent uses domain knowledge and
symbolic rule-refinement techniques to help determine the network's topology. Also, these
other algorithms restructure their network based solely on training-set error, while Regent
minimized validation-set error.
Instead of incrementally finding an appropriate topology, one can mount a \richer"
search than hillclimbing through the space of topologies. One common approach is to
combine genetic algorithms and neural networks (as Regent does). Genetic algorithms
have been applied to neural networks in two different ways: (a) to optimize the connection
weights in a fixed topology, and (b) to optimize the topology of the network. Techniques
that solely use genetic algorithms to optimize weights (Montana & Davis, 1989; Whitley
& Hanson, 1989) have performed competitively with gradient-based training algorithms;
however, one problem with genetic algorithms is their ineciency in fine-tuned local search,
thus the scalability of these methods are in question (Yao, 1993). Kitano (1990b) presents
a method that combines genetic algorithms with backpropagation. He does this by using
the genetic algorithm to determine the starting weights for a network, which are then
refined by backpropagation. Regent differs from Kitano's method in that we use a domain
theory to help determine each network's starting weights and genetically search, instead,
for appropriate network topologies.
Most methods that use genetic algorithms to optimize a network topology are similar
to Regent in that they also use backpropagation to train each network's weights. Of
these methods, many directly encode each link in the network (Miller, Todd, & Hegde,
1989; Oliker, Furst, & Maimon, 1992; Schiffmann, Joost, & Werner, 1992). These methods
are relatively straightforward to implement, and are good at fine tuning small networks
(Miller et al., 1989); however, they do not scale well since they require very large matrices
to represent all the links in large networks (Yao, 1993). Other techniques (Dodd, 1990;
Harp, Samad, & Guha, 1989; Kitano, 1990a) only encode the most important features of
the network, such as the number of hidden layers, the number of hidden nodes at each
layer, etc. These indirect encoding schemes can evolve different sets of parameters along
with the network's topology and have been shown to have good scalability (Yao, 1993).
Some techniques (Koza & Rice, 1991; Oliker et al., 1992) evolve both the architecture and
connection weights at the same time; however, the combination of the two levels of evolution
greatly increases the search space.
Regent mainly differs from genetic-algorithm-based training methods in that it is designed for knowledge-based neural networks. Thus Regent uses domain-specific knowledge
and symbolic rule-refinement techniques to aid in determining the network's topology and
initial weight setting. Regent also differs in that it does not explicitly encode its networks;
rather, in the spirit of Lamarkian evolution, it passes trained network weights to the off200

fiConnectionist Theory Refinement

spring. A final difference is that most of these other algorithms restructure their network
based solely on training-set error, while Regent minimizes validation-set error.

7.4 Wrapping Optimization Around Learning

We end our related work discussion with a brief overview of methods that combine global and
local optimization strategies. Local search algorithms iteratively improve their estimate of
the minimum by searching in only a local neighborhood of the current solution; local minima
are not guaranteed to be global minima. (Many inductive learning methods are often
equated with local optimization techniques; Rumelhart et al., 1986.) Global optimization
methods (such as GAs), on the other hand, perform a more sophisticated search across
multiple local minima and are good at finding regions of the search space where nearoptimal solutions can be found; however, they are usually not as good at refining a solution
(once it is close to a near-optimal solution) as local optimization strategies (Hart, 1994).
Recent research has shown that it is desirable to emply both a global and local search
strategy (Hart, 1994).
Hybrid GAs (such as Regent) combine local search with a more traditional GA. While
we focus on hybrid-GA algorithms in this section, this two-tiered search strategy has been
employed by other researchers as well (Kohavi & John, 1997; Provost & Buchanan, 1995;
Schaffer, 1993). GAs have been combined with many local search methods (Bala, Huang,
Vafaie, DeJong, & Wechsler, 1995; Belew, 1990; Hinton & Nowlan, 1987; Turney, 1995).
Neural networks are the most common choice for the local search strategy of hybrid GA
systems and we discussed GA/neural-network hybrids in the Section 7.3. There are two
common forms of hybrid GAs: Lamarckian-based evolution and Darwinian-based evolution (the Baldwin effect). Lamarckian evolution encodes its local improvements directly
into its genetic material, while Darwinian evolution leaves the genetic material unchanged
after learning. As discussed in Section 6, most authors use Lamarckian local search techniques and many have shown numerous cases where Lamarckian evolution outperforms
non-Lamarckian local search (Belew, McInerney, & Schraudolph, 1992; Hart, 1994; Judson,
Colvin, Meza, Huffa, & Gutierrez, 1992).

8. Conclusion

An ideal inductive-learning algorithm should be able to exploit the available resources of
extensive computing power and domain-specific knowledge to improve its ability to generalize. Kbann (Towell & Shavlik, 1994) has been shown to be effective at translating
a domain theory into a neural network; however, Kbann suffers in that it does not alter
its topology. TopGen (Opitz & Shavlik, 1995) improved the Kbann algorithm by using
available computer power to search for effective places to add nodes to the Kbann network;
however, we show empirically that TopGen suffers from restricting its search to expansions
of the Kbann network, and is unable to improve its performance after searching beyond
a few topologies. Therefore TopGen is unable to exploit all available computing power to
increase the correctness of an induced concept.
We present a new algorithm, Regent, that uses a specialized genetic algorithm to
broaden the types of topologies considered during TopGen's search. Experiments indicate
that Regent is able to significantly increase generalization over TopGen; hence, our new
201

fiOpitz & Shavlik

algorithm is successful in overcoming TopGen's limitation of only searching a small portion
of the space of possible network topologies. In doing so, Regent is able to generate a
good solution quickly, by using Kbann, then is able to continually improve this solution as
it searches concept space. Therefore, Regent takes a step toward a true anytime theory
refinement system that is able to make effective use of problem-specific knowledge and
available computing cycles.

Acknowledgements
This work was supported by Oce of Naval Research grant N00014-93-1-0998 and National
Science Foundation grant IRI 95-02990. Thanks to Richard Maclin, Richard Sutton, and
three anonymous reviewers for their helpful comments. This is an extended version of a
paper published in Machine Learning: Proceedings of the Eleventh International Conference,
pp. 208-216, New Brunswick, NJ, Morgan Kaufmann. David Opitz completed a portion of
this work while a graduate student at the University of Wisconsin and a professor at the
University of Minnesota, Duluth.

References
Ackley, D. (1987). A Connectionist Machine for Genetic Hillclimbing. Kluwer, Norwell,
MA.
Ackley, D., & Littman, M. (1992). Interactions between learning and evolution. In Langton,
C., Taylor, C., Farmer, C., & Rasmussen, S. (Eds.), Artificial Life II, pp. 487{509,
Redwood City, CA. Addison-Wesley.
Ackley, D., & Littman, M. (1994). A case for Lamarckian evolution. In Langton, C. (Ed.),
Artificial Life III, pp. 3{10, Redwood City, CA. Addison-Wesley.
Baffes, P., & Mooney, R. (1993). Symbolic revision of theories with M-of-N rules. In
Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence,
pp. 1135{1140, Chambery, France. Morgan Kaufmann.
Bala, J., Huang, J., Vafaie, H., DeJong, K., & Wechsler, H. (1995). Hybrid learning using
genetic algorithms and decision trees for pattern classification. In Proceedings of
the Fourteenth International Joint Conference on Artificial Intelligence, pp. 719{724,
Montreal, Canada. Morgan Kaufmann.
Baldwin, J. (1896). Physical and social heredity. American Naturalist, 30, 441{451.
Baum, E., & Haussler, D. (1989). What size net gives valid generalization? Neural Computation, 1, 151{160.
Baum, E., & Lang, K. (1991). Constructing hidden units using examples and queries. In
Lippmann, R., Moody, J., & Touretzky, D. (Eds.), Advances in Neural Information
Processing Systems, Vol. 3, pp. 904{910, San Mateo, CA. Morgan Kaufmann.
202

fiConnectionist Theory Refinement

Belew, R. (1990). Evolution, learning and culture: Computational metaphors for adaptive
search. Complex Systems, 4, 11{49.
Belew, R., McInerney, J., & Schraudolph, N. (1992). Evolving networks: Using the genetic
algorithm with connectionist learning. In Langton, C., Taylor, C., Farmer, C., &
Rasmussen, S. (Eds.), Artificial Life II, pp. 511{547, Redwood City, CA. AddisonWesley.
Belew, R., & Mitchell, M. (1996). Adaptive Individuals in Evolving Populations: Models
and Algorithms. Addison-Wesley, Massachusetts.
Berenji, H. (1991). Refinement of approximate reasoning-based controllers by reinforcement
learning. In Proceedings of the Eighth International Machine Learning Workshop, pp.
475{479, Evanston, IL. Morgan Kaufmann.
Bergadano, F., Giordana, A., & Ponsero, S. (1989). Deduction in top-down inductive
learning. In Proceedings of the Sixth International Workshop on Machine Learning,
pp. 23{25, Ithaca, NY. Morgan Kaufmann.
Blanziere, E., & Katenkamp, P. (1996). Learning radial basis function networks on-line.
In Proceedings of the Thirteenth International Conference on Machine Learning, pp.
37{45, Bari, Italy. Morgan Kaufmann.
Clocksin, W., & Mellish, C. (1987). Programming in Prolog. Springer-Verlag, New York.
Cohen, W. (1992). Compiling prior knowledge into an explicit bias. In Proceedings of
the Ninth International Conference on Machine Learning, pp. 102{110, Aberdeen,
Scotland. Morgan Kaufmann.
Danyluk, A. (1989). Finding new rules for incomplete theories: Explicit biases for induction
with contextual information. In Proceedings of the Sixth International Workshop on
Machine Learning, pp. 34{36, Ithaca, NY. Morgan Kaufmann.
Das, A., Giles, C., & Sun, G. (1992). Using prior knowledge in an NNPDA to learn
context-free languages. In Hanson, S., Cowan, J., & Giles, C. (Eds.), Advances in
Neural Information Processing Systems, Vol. 5, pp. 65{72, San Mateo, CA. Morgan
Kaufmann.
Dean, T., & Boddy, M. (1988). An analysis of time-dependent planning. In Proceedings of
the Seventh National Conference on Artificial Intelligence, pp. 49{54, St. Paul, MN.
Morgan Kaufmann.
DeJong, K. (1975). An Analysis of the Behavior of a class of Genetic Adaptive Systems.
Ph.D. thesis, University of Michigan, Ann Arbor, MI.
Dodd, N. (1990). Optimization of network structure using genetic techniques. In Proceedings
of the IEEE International Joint Conference on Neural Networks, Vol. III, pp. 965{970,
Paris. IEEE Press.
203

fiOpitz & Shavlik

Donoho, S., & Rendell, L. (1995). Rerepresenting and restructuring domain theories: A
constructive induction approach. Journal of Artificial Intelligence Research, 2, 411{
446.
Drucker, H., Cortes, C., Jackel, L., LeCun, Y., & Vapnik, V. (1994). Boosting and other
machine learning algorithms. In Proceedings of the Eleventh International Conference
on Machine Learning, pp. 53{61, New Brunswick, NJ. Morgan Kaufmann.
Fahlman, S., & Lebiere, C. (1989). The cascade-correlation learning architecture. In Touretzky, D. (Ed.), Advances in Neural Information Processing Systems, Vol. 2, pp. 524{
532, San Mateo, CA. Morgan Kaufmann.
Farmer, J., & Belin, A. (1992). Artificial life: The coming evolution. In Langton, C., Taylor,
C., Farmer, J. D., & Rasmussen, S. (Eds.), Artificial Life II, pp. 815{840, Redwood
City, CA. Addison-Wesley.
Flann, N., & Dietterich, T. (1989). A study of explanation-based methods for inductive
learning. Machine Learning, 4, 187{226.
Fletcher, J., & Obradovic, Z. (1993). Combining prior symbolic knowledge and constructive
neural network learning. Connection Science, 5, 365{375.
Forrest, S., & Mitchell, M. (1993). What makes a problem hard for a genetic algorithm?
Some anomalous results and their explanation. Machine Learning, 13, 285{319.
Frean, M. (1990). The upstart algorithm: A method for constructing and training feedforward neural networks. Neural Computation, 2, 198{209.
Fu, L. (1989). Integration of neural heuristics into knowledge-based inference. Connection
Science, 1, 325{340.
Ginsberg, A. (1990). Theory reduction, theory revision, and retranslation. In Proceedings of
the Eighth National Conference on Artificial Intelligence, pp. 777{782, Boston, MA.
AAAI/MIT Press.
Giordana, A., & Saitta, L. (1993). REGAL: An integrated system for relations using genetic
algorithms. In Proceedings of the Second International Workshop on Multistrategy
Learning, pp. 234{249, Harpers Ferry, WV.
Giordana, A., Saitta, L., & Zini, F. (1994). Learning disjunctive concepts by means of genetic algorithms. In Proceedings of the Eleventh International Conference on Machine
Learning, pp. 96{104, New Brunswick, NJ. Morgan Kaufmann.
Goldberg, D. (1989). Genetic Algorithms in Search, Optimization, and Machine Learning.
Addison-Wesley, Reading, MA.
Greene, D., & Smith, S. (1993). Competition-based induction of decision models from
examples. Machine Learning, 13, 229{258.
204

fiConnectionist Theory Refinement

Grefenstette, J., & Ramsey, C. (1992). An approach to anytime learning. In Proceedings
of the Ninth International Conference on Machine Learning, pp. 189{195, Aberdeen,
Scotland. Morgan Kaufmann.
Hansen, L., & Salamon, P. (1990). Neural network ensembles. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 12, 993{1001.
Harp, S., Samad, T., & Guha, A. (1989). Designing application-specific neural networks
using the genetic algorithm. In Touretzky, D. (Ed.), Advances in Neural Information
Processing Systems, Vol. 2, pp. 447{454, San Mateo, CA. Morgan Kaufmann.
Hart, W. (1994). Adaptive Global Optimization with Local Search. Ph.D. thesis, University
of California, San Diego.
Hassibi, B., & Stork, D. (1992). Second order derivatives for network pruning: Optimal brain
surgeon. In Hanson, S., Cowan, J., & Giles, C. (Eds.), Advances in Neural Information
Processing Systems, Vol. 5, pp. 164{171, San Mateo, CA. Morgan Kaufmann.
Hekanaho, J. (1996). Background knowledge in GA-based concept learning. In Proceedings
of the Thirteenth International Conference on Machine Learning, pp. 234{242, Bari,
Italy. Morgan Kaufmann.
Hinton, G., & Nowlan, S. (1987). How learning can guide evolution. Complex Systems, 1,
495{502.
Holder, L. (1991). Maintaining the Utility of Learned Knowledge Using Model-Based Control. Ph.D. thesis, Computer Science Department, University of Illinois at UrbanaChampaign.
Holland, J. (1975). Adaptation in Natural and Artificial Systems. University of Michigan
Press, Ann Arbor, MI.
Janikow, C. (1993). A knowledge intensive GA for supervised learning. Machine Learning,
13, 198{228.
Judson, R., Colvin, M., Meza, J., Huffa, A., & Gutierrez, D. (1992). Do intelligent configuration search techniques outperform random search for large molecules? International
Journal of Quantum Chemistry, 277{290.
Kibler, D., & Langley, P. (1988). Machine learning as an experimental science. In Proceedings of the Third European Working Session on Learning, pp. 1{12, Edinburgh,
UK.
Kitano, H. (1990a). Designing neural networks using genetic algorithms with graph generation system. Complex Systems, 4, 461{476.
Kitano, H. (1990b). Empirical studies on the speed of convergence of neural network training using genetic algorithms. In Proceedings of the Eighth National Conference on
Artificial Intelligence, pp. 789{795, Boston, MA. AAAI/MIT Press.
205

fiOpitz & Shavlik

Kohavi, R., & John, G. (1997). Wrappers for feature subset selection. Artificial Intelligence.
Koppel, M., Feldman, R., & Segre, A. (1994). Bias-driven revision of logical domain theories.
Journal of Artificial Intelligence Research, 1, 159{208.
Koza, J. (1992). Genetic Programming. MIT Press, Cambridge, MA.
Koza, J., & Rice, J. (1991). Genetic generation of both the weights and architectures for
a neural network. In International Joint Conference on Neural Networks, Vol. 2, pp.
397{404, Seattle, WA. IEEE Press.
Krogh, A., & Vedelsby, J. (1995). Neural network ensembles, cross validation, and active
learning. In Tesauro, G., Touretzky, D., & Leen, T. (Eds.), Advances in Neural
Information Processing Systems, Vol. 7, pp. 231{238, Cambridge, MA. MIT Press.
Lacher, R., Hruska, S., & Kuncicky, D. (1992). Back-propagation learning in expert networks. IEEE Transactions on Neural Networks, 3, 62{72.
Le Cun, Y., Denker, J., & Solla, S. (1989). Optimal brain damage. In Touretzky, D. (Ed.),
Advances in Neural Information Processing Systems, Vol. 2, pp. 598{605, San Mateo,
CA. Morgan Kaufmann.
Litzkow, M., Livny, M., & Mutka, M. (1988). Condor | a hunter of idle workstations. In
Proceedings of the Eighth International Conference on Distributed Computing Systems,
pp. 104{111, San Jose, CA. Computer Society Press.
MacKay, D. (1992). A practical Bayesian framework for backpropagation networks. Neural
Computation, 4, 448{472.
Maclin, R., & Shavlik, J. (1993). Using knowledge-based neural networks to improve algorithms: Refining the Chou-Fasman algorithm for protein folding. Machine Learning,
11, 195{215.
Mahoney, J. (1996). Combining Symbolic and Connectionist Learning Methods to Refine
Certainty-Factor Rule-Bases. Ph.D. thesis, University of Texas, Austin, TX.
Mahoney, J., & Mooney, R. (1993). Combining connectionist and symbolic learning to refine
certainty-factor rule-bases. Connection Science, 5, 339{364.
Mahoney, J., & Mooney, R. (1994). Comparing methods for refining certainty-factor rulebases. In Proceedings of the Eleventh International Conference on Machine Learning,
pp. 173{180, New Brunswick, NJ. Morgan Kaufmann.
Masuoka, R., Watanabe, N., Kawamura, A., Owada, Y., & Asakawa, K. (1990). Neurofuzzy
system | fuzzy inference using a structured neural network. In Proceedings of the
International Conference on Fuzzy Logic & Neural Networks, pp. 173{177, Iizuka,
Japan.
Michalski, R. (1983). A theory and methodology of inductive learning. Artificial Intelligence,
20, 111{161.
206

fiConnectionist Theory Refinement

Miller, G., Todd, P., & Hegde, S. (1989). Designing neural networks using genetic algorithms. In Proceedings of the Third International Conference on Genetic Algorithms,
pp. 379{384, Arlington, VA. Morgan Kaufmann.
Mitchell, M. (1996). An Introduction to Genetic Algorithms. MIT Press, Cambridge, MA.
Mitchell, T. (1982). Generalization as search. Artificial Intelligence, 18, 203{226.
Montana, D., & Davis, L. (1989). Training feedforward networks using genetic algorithms. In
Proceedings of the Eleventh International Joint Conference on Artificial Intelligence,
pp. 762{767, Detroit, MI. Morgan Kaufmann.
Moody, J. (1991). The effective number of parameters: An analysis of generalization and
regularization in nonlinear learning systems. In Moody, J., Hanson, S., & Lippmann,
R. (Eds.), Advances in Neural Information Processing Systems, Vol. 4, pp. 847{854,
San Mateo, CA. Morgan Kaufmann.
Mozer, M. C., & Smolensky, P. (1989). Using relevance to reduce network size automatically.
Connection Science, 1, 3{16.
Neri, F., & Saitta, L. (1996). Exploring the power of genetic search in learning symbolic
classifiers. In IEEE Transactions on Pattern Analisys and Machine Intelligence.
Oliker, S., Furst, M., & Maimon, O. (1992). A distributed genetic algorithm for neural
network design and training. Complex Systems, 6, 459{477.
Omlin, C., & Giles, C. (1992). Training second-order recurrent neural networks using hints.
In Proceedings of the Ninth International Conference on Machine Learning, pp. 361{
366, Aberdeen, Scotland. Morgan Kaufmann.
Opitz, D., & Shavlik, J. (1993). Heuristically expanding knowledge-based neural networks.
In Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence, pp. 1360{1365, Chambery, France. Morgan Kaufmann.
Opitz, D., & Shavlik, J. (1995). Dynamically adding symbolically meaningful nodes to
knowledge-based neural networks. Knowledge-Based Systems, 8, 301{311.
Opitz, D., & Shavlik, J. (1996). Actively searching for an effective neural-network ensemble.
Connection Science, 8, 337{353.
Ourston, D., & Mooney, R. (1994). Theory refinement combining analytical and empirical
methods. Artificial Intelligence, 66, 273{309.
Pazzani, M., & Kibler, D. (1992). The utility of knowledge in inductive learning. Machine
Learning, 9, 57{94.
Perrone, M. (1993). Improving Regression Estimation: Averaging Methods for Variance
Reduction with Extension to General Convex Measure Optimization. Ph.D. thesis,
Brown University, Providence, RI.
207

fiOpitz & Shavlik

Provost, F., & Buchanan, B. (1995). Inductive policy: The pragmatics of bias selection.
Machine Learning, 20, 35{61.
Quinlan, J. (1986). Induction of decision trees. Machine Learning, 1, 81{106.
Quinlan, J., & Cameron-Jones, R. (1995). Lookahead and pathology in decision tree induction. In Proceedings of the Fourteenth International Joint Conference on Artificial
Intelligence, pp. 1019{1024, Montreal, Canada. Morgan Kaufmann.
Richards, B., & Mooney, R. (1995). Automated refinement of first-order Horn-clause domain
theories. Machine Learning, 19, 95{131.
Roscheisen, M., Hofmann, R., & Tresp, V. (1991). Neural control for rolling mills: Incorporating domain theories to overcome data deficiency. In Moody, J., Hanson, S., &
Lippmann, R. (Eds.), Advances in Neural Information Processing Systems, Vol. 4, pp.
659{666, San Mateo, CA. Morgan Kaufmann.
Rumelhart, D., Hinton, G., & Williams, R. (1986). Learning internal representations by
error propagation. In Rumelhart, D., & McClelland, J. (Eds.), Parallel Distributed
Processing: Explorations in the microstructure of cognition. Volume 1: Foundations,
pp. 318{363. MIT Press, Cambridge, MA.
Schaffer, C. (1993). Selecting a classification method by cross-validation. Machine Learning,
13, 135{143.
Schiffmann, W., Joost, M., & Werner, R. (1992). Synthesis and performance analysis of
multilayer neural network architectures. Tech. rep. 16, University of Koblenz, Institute
for Physics.
Scott, G., Shavlik, J., & Ray, W. (1992). Refining PID controllers using neural networks.
Neural Computation, 5, 746{757.
Tishby, N., Levin, E., & Solla, S. (1989). Consistent inference on probabilities in layered
networks, predictions and generalization. In International Joint Conference on Neural
Networks, pp. 403{410, Washington, D.C. IEEE Press.
Towell, G. (1991). Symbolic Knowledge and Neural Networks: Insertion, Refinement, and
Extraction. Ph.D. thesis, Computer Sciences Department, University of Wisconsin,
Madison, WI.
Towell, G., & Shavlik, J. (1992). Using symbolic learning to improve knowledge-based neural
networks. In Proceedings of the Tenth National Conference on Artificial Intelligence,
pp. 177{182, San Jose, CA. AAAI/MIT Press.
Towell, G., & Shavlik, J. (1994). Knowledge-based artificial neural networks. Artificial
Intelligence, 70, 119{165.
Turney, P. (1995). Cost-sensitive classification: Empirical evaluation of a hybrid genetic
decision tree induction algorithm. Journal of Artificial Intelligence Research, 2, 369{
409.
208

fiConnectionist Theory Refinement

Waterman, D. (1986). A Guide to Expert Systems. Addison Wesley, Reading, MA.
Watrous, R., Towell, G., & Glassman, M. (1993). Synthesize, optimize, analyze, repeat
(SOAR): Application of neural network tools to ECG patient monitoring. In Proceedings of the Symposium on Nonlinear Theory and its Applications, pp. 565{570,
Honolulu, Hawaii.
Watson, J. D., Hopkins, N. H., Roberts, J. W., Argetsinger-Steitz, J., & Weiner, A. M.
(1987). Molecular Biology of the Gene (Fourth edition). Benjamin/Cummings, Menlo
Park, CA.
Weigend, A. (1993). On overfitting and the effective number of hidden units. In Proceedings of the 1993 Connectionist Models Summer School, pp. 335{342, Boulder, CO.
Lawrence Erlbaum Associates.
Weigend, A., Huberman, B., & Rumelhart, D. (1990). Predicting the future: A connectionist
approach. International Journal of Neural Systems, I, 193{209.
Whitley, D., Gordon, S., & Mathias, K. (1994). Lamarckian evolution, the Baldwin effect
and function optimization. In Davidor, Y., Schwefel, H., & Manner, R. (Eds.), Parallel
Problem Solving from Nature - PPSN III, pp. 6{15. Springer-Verlag.
Whitley, D., & Hanson, T. (1989). Optimizing neural networks using faster, more accurate genetic search. In Proceedings of the Third International Conference on Genetic
Algorithms, pp. 391{396, Arlington, VA. Morgan Kaufmann.
Yao, X. (1993). Evolutionary artificial neural networks. International Journal of Neural
Systems, 4, 203{221.

209

fiJournal of Artificial Intelligence Research 6 (1997) 223-262

Submitted 2/97; published 6/97

Flaw Selection Strategies For Partial-Order Planning

Martha E. Pollack

Department of Computer Science and Intelligent Systems Program,
University of Pittsburgh, Pittsburgh, PA 15260 USA

David Joslin

Computational Intelligence Research Laboratory,
University of Oregon, Eugene, OR 97403 USA

pollack@cs.pitt.edu
joslin@cirl.uoregon.edu

Massimo Paolucci

Intelligent Systems Program,
University of Pittsburgh, Pittsburgh, PA 15260 USA

paolucci@pitt.edu

Abstract

Several recent studies have compared the relative eciency of alternative aw selection
strategies for partial-order causal link (POCL) planning. We review this literature, and
present new experimental results that generalize the earlier work and explain some of the
discrepancies in it. In particular, we describe the Least-Cost Flaw Repair (LCFR) strategy
developed and analyzed by Joslin and Pollack (1994), and compare it with other strategies,
including Gerevini and Schubert's (1996) ZLIFO strategy. LCFR and ZLIFO make very
different, and apparently conicting claims about the most effective way to reduce searchspace size in POCL planning. We resolve this conict, arguing that much of the benefit that
Gerevini and Schubert ascribe to the LIFO component of their ZLIFO strategy is better
attributed to other causes. We show that for many problems, a strategy that combines
least-cost aw selection with the delay of separable threats will be effective in reducing
search-space size, and will do so without excessive computational overhead. Although such
a strategy thus provides a good default, we also show that certain domain characteristics
may reduce its effectiveness.

1. Introduction
Much of the current research in plan generation centers on partial-order causal link (POCL)
algorithms, which descend from McAllester and Rosenblitt's (1991) SNLP algorithm. POCL
planning involves searching through a space of partial plans, where the successors of a node
representing partial plan P are refinements of P . As with any search problem, POCL
planning requires effective search control strategies.
In POCL planning, search control has two components. The first, node selection, involves choosing which partial plan to refine next. Once a partial plan has been selected for
refinement, the planner must then perform aw selection, which involves choosing either a
threat to resolve or an open condition to establish.
Over the past few years, several studies have compared the relative eciency of alternative aw selection strategies for POCL planning and their extensions (Peot & Smith, 1993;
Joslin & Pollack, 1994; Srinivasan & Howe, 1995; Gerevini & Schubert, 1996; Williamson &
Hanks, 1996). These studies have been motivated at least in part by a tension between the
attractive formal properties of the POCL algorithms, and the limitations in putting them

c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiPollack, Joslin, & Paolucci
to practical use that result from their relatively poor performance. To date, the POCL
algorithms cannot match the eciency of the so-called industrial-strength planners such as
SIPE (Wilkins, 1988; Wilkins & Desimone, 1994) and O-Plan (Currie & Tate, 1991; Tate,
Drabble, & Dalton, 1994). Flaw selection strategy has been shown to have a significant
effect on the eciency of POCL planning algorithms, and thus researchers have viewed
the design of improved aw selection strategies as one means of making POCL planning
algorithms more practical.
In this paper, we review the literature on aw selection strategies, and present new
experimental results that generalize the earlier work and explain some of the discrepancies
in it. In particular, we describe the Least-Cost Flaw Repair (LCFR) strategy developed
and analyzed by Joslin and Pollack (1994), and compare it with other strategies, including
Gerevini and Schubert's ZLIFO strategy (1996). LCFR and ZLIFO make very different,
and apparently conicting claims about the most effective way to reduce search-space size
in POCL planning. We resolve this conict, arguing that much of the benefit that Gerevini
and Schubert ascribe to the LIFO component of their ZLIFO strategy is better attributed
to other causes. We show that for many problems, a strategy that combines least-cost aw
selection with the delay of separable threats will be effective in reducing search-space size,
and will do so without excessive computational overhead. Although such a strategy thus
provides a good default, we also show that certain domain characteristics may reduce its
effectiveness.

2. Background
2.1 Node and Flaw Selection

Although the main ideas of POCL planning have been in the literature for more than
two decades, serious efforts at comparing alternative plan generation algorithms have been
relatively recent. What made these comparisons possible was the development of a set
of clear algorithms with provable formal properties, notably TWEAK (Chapman, 1987),
and SNLP (McAllester & Rosenblitt, 1991). These algorithms were not intended to add
functionality to known planning methods, but rather to capture the essential elements of
these known methods in a readily analyzable fashion.
In analyzing POCL algorithms, researchers have found it useful to decouple the search
control strategy from the underlying plan refinement process. Figure 1 is a generic POCL
algorithm, in which we highlight the two search decisions.1 Following convention, we use
CHOOSE to indicate that node selection is a backtracking point, and SELECT to indicate
that aw selection is not. A given node may not lead to a solution, and so it may be necessary
to backtrack and consider alternative nodes. On the other hand, if a node does lead to a
solution, that solution will be found regardless of the order in which its aws are selected.
See Weld's (1994) tutorial paper for more discussion of this difference.
The generic algorithm sketched in the figure must be supplemented with search strategies
that implement the CHOOSE and SELECT operators. Most POCL algorithms perform
node selection using a best-first ranking that computes some function of the number of
1. Various versions of this well-known algorithm have appeared in the literature (Weld, 1994; Russell &
Norvig, 1995; Kambhampati, Knoblock, & Yang, 1995). The version we give corresponds most directly
to that given by Williamson and Hanks (1996).

224

fiFlaw Selection Strategies

POCL (init,goal)

dummy-plan make-skeletal-plan(init,goal).
nodes f dummy-plan g.
While nodes is not empty do:

CHOOSE (and remove) a partial plan P from nodes. (Node Selection)
If P has no aws
then return P
else do:

SELECT a aw from P. (Flaw Selection)

Add all refinements of P to nodes.
Return failure (because nodes has become empty without a aw-free plan being found.)
Figure 1: The Basic POCL Planning Algorithm
steps (denoted S ), open conditions (OC ), and unsafe conditions (UC , i.e., threats) in the
partial plan. Gerevini and Schubert (1996) have argued that, in general, only steps and
open conditions should be included in the ranking function, and we adopt that strategy in
our experiments, except where otherwise indicated.
Having chosen a node, a POCL planning algorithm must then select a aw|open condition or threat|within that node to repair. Open conditions are repaired by establishment,
which consists either in adding a new step that has a unifying condition as an effect (along
with a causal link from that new step to the condition), or else in simply adding a new
causal link from an existing step with a unifying effect. We use the term repair cost to
denote the number of possible ways to repair a aw.
For an open condition o, the repair cost R(o) is I + S + N , where

I = the number of conditions in the initial state that unify with o given the
current binding constraints,
S = the number of conditions in the effects of existing plan steps that unify
with o given the current binding constraints, counting only existing plan
steps that are not constrained to occur after the step associated with o, and
N = the number of conditions in the effects of operators in the library that
unify with o given the current binding constraints.
Note that over time, the repair cost for an open condition that is not resolved may either
increase, as new steps that might achieve the condition are added to the plan, or decrease,
as steps already in the plan are constrained by temporal ordering or variable binding so
that they can no longer achieve the condition.
In considering the cost of threat repair, it is useful to distinguish between nonseparable
and separable threats. Nonseparable threats consist of a step S1 with effect E , and a
causal link  S2; F; S3 , where E and F are complementary literals that necessarily unify:
either they are complementary ground literals (E  :F ), or else they are complementary
literals where each of E 's variables is identical with, or forced by a binding constraint to be
225

fiPollack, Joslin, & Paolucci
equivalent to the variable in the same position in F (e.g., E = p(x; y ) and F = :p(x; z ),
where there is currently a binding constraint that y = z ).2
Nonseparable threats can be repaired in at most two ways: by promoting S1, requiring
it to occur after S3 , or by demoting it, requiring it to occur before S2 . Of course, already
existing temporal ordering constraints may block one or both or these repair options, which
is why there are at most two possible repairs.3 Over time, the repair cost for an unresolved
nonseparable threat can only decrease.
A separable threat consists of a step S1 with an effect E , and a causal link  S2 ; F; S3 ,
where E and F are complementary literals that can be unified, but where such a unification
is not forced (e.g., where E = p(x) and F = p(y ) and there does not exist a binding
constraint x = y ). In such circumstances, the threat may disappear if a subsequent variable
binding blocks the unification. (A nonseparable threat may also disappear if a subsequent
ordering constraint has the effect of imposing promotion or demotion.) The repair cost
for a separable threat may be higher than that for an nonseparable threat: not only can
promotion and demotion be used, but so can separation, which involves forcing a variable
binding that blocks the unification. Separation can introduce one repair for each unbound
variable in the threat. For example, if the effect P (x; y; z ) threatens  S2 ; :P (t; u; v ); S3 ,
there are three possible repairs: x 6= t, y 6= u, and z 6= v . As with nonseparable threats, the
repair cost for a separable threat that remains unresolved can only decrease over time.

2.2 Notation

The aw selection strategies that have been discussed in the literature typically have been
given idiosyncratic names (e.g., DUnf, LCFR, ZLIFO). It is useful, in comparing them,
to have a precise unifying notation. We therefore specify a aw strategy as a sequence of
preferences. A strategy begins by attempting to find a aw that satisfies its first preference;
if it is unable to do so, it then looks for a aw that satisfies the second preference; and
so on. To ensure that a POCL algorithm using the strategy is complete, the sequence of
preferences must be exhaustive: every aw must satisfy some preference. If a aw satisfies
more than one preference in a strategy, we assume that the first match is what counts.
In principle, a preference could identify any feature of a aw. In practice, however, aw
selection strategies have only made use of a small number of features: the type of a aw
(open condition, nonseparable threat, or separable threat), the number of ways it can be
repaired, and the time at which it was introduced into the plan. Often, more than one aw
will have a given feature, in which case a tie-breaking strategy may be specified for choosing
among the relevant aws.
We therefore describe a preference using the following notation

faw typesgrepair cost rangetie-breaking strategy
2. An alternative approach also treats cases in which E  F as threats; this is required to make the planner
systematic, i.e., guaranteed never to generate the same node more than once (McAllester & Rosenblitt,
1991).
3. Conditional planners make use of an additional method of threat resolution|confrontation|but we
ignore that within this paper (Peot & Smith, 1992; Etzioni, Hanks, Weld, Draper, Lesh, & Williamson,
1992). Joslin (1996) provides a detailed account of generalizing the treatment of aws to other types of
planning decisions.

226

fiFlaw Selection Strategies
which indicates a preference for any aw f of the specified type or types, provided that the
repair cost for f falls within the range of values specified. (If there are no restrictions on
repair cost, we omit the repair cost range.) If more than one aw meets these criteria, then
the tie-breaking strategy is applied to select among them.
We abbreviate aw type as \o" (for open condition), \n" (for nonseparable threat), and
\s" (for separable threat). We also use abbreviations for common tie-breaking strategies,
e.g., \LC" (least (repair) cost), \LIFO" and \R" (Random). In the case of LC, if a choice
must be made between aws that have the same repair cost, LIFO selection is used.
Thus, for example
fng0-1R
specifies a preference for nonseparable threats with a repair cost of zero or one; if more than
one aw meets these conditions, a random selection will be made among them. We use the
term forced to describe aws with repair cost of one or less.
An example of a complete aw selection strategy is then:
fng0-1R / fogLIFO / fn,sgR
This strategy would begin by looking for a forced nonseparable threat; if more than one aw
meets this criterion, the strategy would select randomly among them. If there are no forced
nonseparable threats, it would then look for an open condition, with any repair cost, using a
LIFO scheme to select among them. Finally, if there are neither forced nonseparable threats
nor open conditions, it would randomly select either an unforced nonseparable threat or a
separable threat.
While we have distinguished between aw type and maximum repair cost, on the one
hand, and tie-breaking strategy, on the other, it is easy to describe strategies that use
something other than aw type as the main criterion for selection. For example, a pure
LIFO selection strategy would be encoded as follows. (Henceforth, we give the name of a
strategy in boldface preceding the specification.)
LIFO fo,n,sgLIFO

3. Flaw Selection Strategies

We begin by reviewing the aw selection strategies that have been proposed and studied in
the literature to date.

3.1 Threat Preference and Delay

The original SNLP algorithm (McAllester & Rosenblitt, 1991) adopted a aw selection
strategy in which threats are resolved before open conditions, and early versions of the
widely used UCPOP planning system (Penberthy & Weld, 1992) did the same.4 SNLP
does not specify a principle for selecting among multiple threats or multiple opens; UCPOP
used LIFO for this purpose. Employing the notation above, we can describe the basic
UCPOP strategy as:
4. In the current version of UCPOP (v.4), the aw selection strategy that is run by default is the DSep
strategy, discussed just below. For historical reasons, we maintain the name DSep for that strategy, and
use UCPOP for the older default strategy.

227

fiPollack, Joslin, & Paolucci

UCPOP fn,sgLIFO / fogLIFO
The first study of alternative aw selection strategies was done by Peot and Smith (1993),
who relaxed the requirement that threats always be resolved before open conditions, and
examined several strategies for delaying the resolution of some threats. They analyzed five
different strategies for delaying the repair of threats; of these, two are provably superior:
DSep and DUnf.
DSep (Delay Separable Threats) was motivated by the observation that sometimes separable threats can simply disappear in the planning process as blocking variable bindings
are introduced. As we pointed out earlier, nonseparable threats may also \disappear",
but typically this is less frequent. Moreover, if the resolution of all threats|separable and
nonseparable|were delayed, then nonseparable threats would only disappear early as a side
effect of step reuse, making their disappearance even less frequent.
The DSep strategy therefore defers the repair of all separable threats until the very end of
the planning process. However, like UCPOP, it continues to give preference to nonseparable
threats:
DSep fngLIFO / fogLIFO / fsgLIFO
Actually, Peot and Smith do not specify a tie-breaking strategy for choosing among multiple
threats; we have here indicated this as LIFO. They explored three different tie-breaking
strategies for selecting open conditions (FIFO, LIFO, and least-cost); here we list LIFO,
but one can also specify the alternatives:
DSep-LC fngLIFO / fogLC / fsgLIFO
DSep-FIFO fngLIFO / fogFIFO / fsgLIFO
Peot and Smith prove that the search space generated by a POCL planner using DSep will
never be larger than the search space generated using the UCPOP strategy. This result
holds when the tie-breaking strategy for open conditions is LIFO or FIFO, but not LC, a
point we will return to later in the paper.
Peot and Smith's second successful strategy is DUnf (Delay Unforced Threats). It makes
use of the notion of forced aws. As we stated earlier, a aw is forced if there is at most
one possible way to repair it. The DUnf strategy delays the repair of all unforced threats:
DUnf fn,sg0LIFO / fn,sg1LIFO / fogLIFO / fn,sg2-1LIFO
We can define DUnf-LC and DUnf-FIFO in a manner analogous to that used for DSep-LC
and DSep-FIFO:
DUnf-LC fn,sg0LIFO / fn,sg1LIFO / fogLC / fn,sg2-1LIFO
DUnf-FIFO fn,sg0LIFO / fn,sg1LIFO / fogFIFO / fn,sg2-1LIFO
Peot and Smith proved that the DUnf strategy would never generate a larger search
space than either of the remaining two strategies that they examined. They also proved
that that DSep and DUnf are incomparable: there exist planning problems for which DSep
generates a smaller search space than DUnf, and other problems for which the reverse is
true.
228

fiFlaw Selection Strategies
Peot and Smith support their theoretical results on DSep and DUnf with experiments
showing that, at least for the domains they examined, these strategies can result in significant decrease in search-space size. The decrease in search is correlated with the diculty of
the problem, and consequently, as the problems get more dicult, these strategies reduce
search time as well as space. That is, on large enough problems, they \pay for" their own
overhead.
In follow-on work, Peot and Smith (1994) describe a strategy called DMin, which generates smaller search spaces than both DSep and DUnf. DMin combines a process of pruning
dead-end nodes with the process of aw selection. It gives preference to forced threats. If
there are no forced threats, it checks to see whether all the remaining nonseparable threats
could be repaired simultaneously. If so, it leaves them as threats, and selects an open condition to repair; if there are no open conditions, then presumably it selects a remaining
unforced threat to repair. On the other hand, if it is impossible to repair all the unforced,
nonseparable threats, then the node is a dead end, and can be pruned from the search
space. Note that some dead-end nodes can be recognized immediately, even without doing
the complete consistency checking of DMin. This is because an unrepairable aw cannot
subsequently become repairable, hence, any node containing a aw with repair cost of zero
is a dead end. Consequently, all aw selection strategies should give highest priority to such
aws (Joslin & Pollack, 1996; Joslin, 1996).

3.2 Least-Cost Flaw Repair

Peot and Smith's work provided the foundation for our subsequent exploration of the leastcost aw repair (LCFR) strategy (Joslin & Pollack, 1994). We hypothesized that the power
of the DUnf strategy might come not from its relative ordering of threats and open conditions, but instead from the fact that DUnf has the effect of imposing a partial preference
for least-cost aw selection. DUnf will always prefer a forced threat, which, by definition
has a repair cost of at most one; thus, in cases in which there is a forced threat, DUnf will
make a low-cost selection. What about cases in which there are no forced threats? Then
DUnf will have to select among open conditions, assuming there are any. If our hypothesis is correct, a version of DUnf that makes this selection using a least-cost strategy (i.e.,
DUnf-LC) ought to perform better than a version that uses one of the other strategies (i.e.,
bare DUnf or DUnf-FIFO). In fact, if it is the selection of low-cost repairs that is causing
the search-space reduction, then the idea of treating threat resolution differently from open
condition establishment ought to be abandoned. Instead, a strategy that always selects
the aw with minimal repair cost, regardless of whether it is a threat or an open condition,
ought to show the best performance. This is the Least-Cost Flaw Repair (LCFR) strategy:5

LCFR fo,n,sgLC
There are strong similarities between LCFR and certain heuristics that have been proposed and studied in the literature on constraint satisfaction problems (CSPs). This is
perhaps not surprising, given that aw selection in POCL planning corresponds in some
5. The LCFR strategy is similar to the branch-1/branch-n search heuristics included in the O-Plan system
(Currie & Tate, 1991). The contribution of our original work on this topic was to isolate this strategy
and examine it in detail.

229

fiPollack, Joslin, & Paolucci
fairly strong ways to variable selection in constraint programming. Flaws in a POCL planner represent decisions that are yet to be made, and that must be made before the plan
will be complete; unbound variables play a similar role in constraint satisfaction problems
(CSPs).6 Although there exist a number of heuristics for selecting a variable to branch on
in solving a CSP (Kumar, 1992), one well-known heuristic that is often quite effective is the
fail first principle, which picks the variable that is the \most constrained" when selecting
a variable to branch on. A simple and common implementation of the fail first principle
selects the variable with the smallest domain (Tsang, 1993).
The intuition behind the fail first principle is that one should prune dead-end regions
of the search as early as possible. The unbound variables that are most tightly constrained
are likely to be points at which the current partial solution is most \brittle" in some sense,
and by branching on those variables we hope to find a contradiction (if one exists) quickly.
Similarly, LCFR can be thought of as selecting the \most constrained" aws, resulting in
better pruning.
A similar heuristic has also been adopted in recent work on controlling search in hierarchical task network (HTN) planning, in the Dynamic Variable Commitment Strategy (DVCS). DVCS, like LCFR, is based on a minimal-branching heuristic. Experimental
analyses demonstrate that DVCS generally produces a well-focused search (Tsuneto, Erol,
Hendler, & Nau, 1996).
Our own initial experimental results, presented in Joslin and Pollack (1994), similarly
supported the hypothesis that a uniform least-cost aw repair strategy could be highly
effective in reducing the size of the search space in POCL planning. In those experiments,
we compared LCFR against four other strategies: UCPOP, DUnf, and DUnf-LC, as defined
above, and a new strategy, UCPOP-LC which we previously called LCOS (Joslin & Pollack,
1994):
UCPOP-LC fn,sgLIFO / fogLC
We included UCPOP-LC to help verify that search-space reduction results from a preference
for aws with minimal repair costs. If this is true, then UCPOP-LC ought to generate a
smaller search space then DUnf, even though it does not delay any threats. Our results were
as expected. UCPOP and DUnf, which do not do least-cost selection of open conditions,
generated the largest search spaces; UCPOP-LC generated significantly smaller spaces; and
DUnf-LC and LCFR generated the smallest spaces.
At the same time, we observed that LCFR incurred an unwieldy overhead, often taking
longer to solve a problem than UCPOP, despite the fact that it was searching far fewer
nodes. In part this was due a particularly inecient implementation of LCFR that we were
using, but in part it resulted from the fact that computing repair costs is bound to take more
time than simply popping a stack (as in a LIFO strategy), or finding a aw of a particular
type (as in a strategy that prefers threats). We therefore explored approximation strategies,
which reduce the overhead of aw selection by accepting some inaccuracy in the repair cost
calculation. For example, we developed the \Quick LCFR" (or QLCFR) strategy, which
calculates the repair cost of any aw only once, when that aw is first encountered. In
any successor node in which the aw remains unresolved, QLCFR assumes that its repair
6. When planning problems are cast as CSPs in the planner Descartes (Joslin & Pollack, 1996; Joslin,
1996), this correspondence is even more direct.

230

fiFlaw Selection Strategies
cost has not changed. Our experiments with QLCFR showed it to be a promising means
of making a least-cost approach suciently fast to pay for its own overhead. Additional
approximation strategies were studied by Srinivasan and Howe (1995), who experimented
with three variations of LCFR, along with a fourth, novel strategy that moves some of the
control burden to the user.

3.3 Threat Delays Revisited

Recently, Gerevini and Schubert (1996) have revived the idea that a aw selection strategy
should treat open conditions and threats differently, and have suggested that LIFO should
be used as the tie-breaking strategy for deciding among open conditions. They combine
these ideas in their ZLIFO strategy:
ZLIFO fngLIFO / fog0LIFO / fog1New / fog2-1LIFO / fsgLIFO
The ZLIFO strategy gives highest priority to nonseparable threats, and then to forced open
conditions. If there are neither nonseparable threats nor forced open conditions, ZLIFO
will select an open condition using LIFO. It defers all separable threats to the end of the
planning process. The name ZLIFO is intended to summarize the overall strategy. The \Z"
stands for \zero-commitment", indicating that preference is given to forced open conditions:
in repairing these, the planner is not making any commitment beyond what must be made
if the node is ultimately to be refined into a complete plan. The \LIFO" indicates the
strategy used for selecting among unforced open conditions.
For open conditions with a repair cost of exactly one, the ZLIFO strategy uses a tiebreaking strategy here called \New". It prefers the repair of an open condition that can only
be established by introducing a new action over the repair of an open condition that can only
be established by using an element of the start state. Gerevini and Schubert state that this
preference \gave improvements in the context of Russell's tire changing domain . . .without
significant deterioration of performance in other domains" (1996, p. 104). However the
difference was apparently not dramatic, and Gerevini believes this to be an implementation
detail, though is open to the possibility that further study might show this preference to be
significant (Gerevini, 1997).
Gerevini and Schubert make three primary claims about ZLIFO:
1. A POCL planner using ZLIFO will tend to generate a smaller search space than one
using a pure LIFO strategy.
2. The reduction in search space using ZLIFO, relative to LIFO, is correlated with the
complexity of the planning problem (where complexity is measured by the number of
nodes generated by the pure LIFO strategy).
3. ZLIFO performs comparably with LCFR on relatively easy problems, and generates
a smaller search space on harder problems.
The first two claims are consistent with what we found in the earlier LCFR studies.
While a LIFO strategy pays no attention to repair costs, ZLIFO does, at least indirectly,
both in its initial preference for nonseparable threats, which have a repair cost of no more
than two, and in its secondary preference for forced opens.
231

fiPollack, Joslin, & Paolucci
The third claim is harder to square with our earlier LCFR study, in which the LIFObased strategies, such as UCPOP and DUnf, generated much larger search spaces than the
least-cost based strategies. What explains ZLIFO's performance? Gerevini and Schubert
answer this question as follows:
Based on experience with search processes in AI in general, [a LIFO] strategy
has much to recommend it, as a simple default. In the first place, its overhead
cost is low compared to strategies that use heuristic evaluation or lookahead to
prioritize goals. As well, it will tend to maintain focus on the achievement of a
particular higher level goal by regression . . .rather than attempting to achieve
multiple goals in a breadth-first fashion. [p. 103]
Their point about overhead is an important one. ZLIFO is a relatively inexpensive control
strategy, and a competing strategy that does a better job of pruning the search space may
end up paying excessive overhead. But it is the second point that addresses the question
we are asking here, namely, how ZLIFO could produce smaller search spaces. Gerevini and
Schubert go on to say that:
[m]aintaining focus on a single goal should be advantageous at least when
some of the goals to be achieved are independent. For instance, suppose that two
goals G1 and G2 can both be achieved in various ways, but choosing a particular
method of achieving G1 does not rule out any of the methods of achieving G2.
Then if we maintain focus on G1 until it is solved, before attempting G2, the
total cost of solving both goals will just be the sum of the costs of solving
them independently. But if we switch back and forth, and solutions of both
goals involve searches that encounter many dead ends, the combined cost can
be much larger. This is because we will tend to search any unsolvable subtree
of the G1 search tree repeatedly, in combination with various alternatives in the
G2 search tree . . .. [p. 103]
This is certainly a plausible explanation. A key remaining question, of course, is the extent to which this explanation carries over to the many planning problems that involve
interacting goals.

4. Experimental Comparison of Flaw Selection Strategies

As discussed in the previous section, several different proposals have been made in the
literature about how best to reduce the size of the search space during POCL planning.
These include:
 giving preference to threats over open conditions;
 giving preference only to certain kinds of threats (either separable or forced threats),
and delaying other threats until after all open conditions have been resolved;
 giving preference to aws that have minimal repair cost;
 giving preference to the most recently introduced aws.
232

fiFlaw Selection Strategies
Moreover, different strategies have combined these preference schemes in different ways,
and apparently conicting claims have been made about the effects of these preferences on
search-space size.
To resolve these conicts, we performed experimental comparisons of POCL planners
using a variety of aw selection strategies. We gave particular attention to the comparison
of LCFR and ZLIFO, because of the their apparently conicting claims. LCFR generates
its search space treating all aws uniformly, using a least-cost approach to choose among
them. ZLIFO distinguishes between aw types (non-separable threats, open conditions, and
separable threats), and uses a modified LIFO approach to select among the aws in each
class. The original LCFR studies would have led us to predict that ZLIFO would generate
larger search spaces than did LCFR, but Gerevini and Schubert found just the opposite to
be true. We aimed, then, to explain this discrepancy.
Our principal focus was on search-space size, for two reasons. First, the puzzle raised
by LCFR and ZLIFO is one of space, not time. As we mentioned earlier, it is easy to see
why ZLIFO would be faster than LCFR, even on a per node basis. A least-cost strategy
must compute repair costs, while ZLIFO need only pop a stack containing the right type
of aws. The puzzle for us was not why ZLIFO was faster, but why it generated smaller
search spaces. Second, we believe that understanding the effect of search control strategies
on search-space size can lead to development of approximation techniques that produce
speed-up as well; the QLCFR strategy (Joslin & Pollack, 1994) and Srinivasan and Howe's
strategies (1995) are examples of this.
However, a secondary goal was to analyze the time requirements of the strategies we
compared, and we therefore collected timing data for all our experiments. As we discuss in
Section 4.6, the strategy that tends to generate the smallest search space achieves enough
of a reduction to pay for its own overhead, by and large.

4.1 Experimental Design

To conduct our comparison, we implemented a set of aw selection strategies in UCPOP
v.4.7 Table 1 lists the strategies that we implemented. Except for LCFR-DSep and DUnfGen, which are discussed later, all the implemented strategies were described in Section
3.
We tested all the strategies on three problem sets, also used in our earlier work (Joslin
& Pollack, 1994) and in Gerevini and Schubert's (1996):
1. The Basic Problems, 33 problems taken from the test suite distributed with the
UCPOP system. These include problems from a variety of domains, including the
7. Note that the experiments in both our earlier LCFR paper (Joslin & Pollack, 1994) and Gerevini and
Schubert's (1996) ZLIFO paper were run using an earlier version (v.2) of UCPOP. As a result, the
number of nodes produced in our experiments sometimes differs from what is reported in these other
two papers. This appears to be largely due to the fact that UCPOP v.4 puts the elements of a new set
of open conditions onto the aw list in the reverse order of the way in which UCPOP v.2 does (Gerevini,
1997). As discussed below in Sections 4.3{4.5, we studied the inuence of this ordering change by also
collecting data using a modified version of UCPOP v.4 in which we reversed the order of conditions
entered in the open list. While the resulting numbers are similar to those previously published, they
are not identical, leading us to conclude that there are additional subtle differences between v.2 and
v.4. However, because all the experiments on which we report here were run using the same version of
UCPOP, we believe this to be a fair comparison of the strategies.

233

fiPollack, Joslin, & Paolucci
UCPOP
UCPOP-LC
DSep
DSep-LC
DUnf
DUnf-LC
DUnf-Gen
LCFR
LCFR-DSep
ZLIFO

fn,sgLIFO / fogLIFO
fn,sgLIFO / fogLC
fngLIFO / fogLIFO / fsgLIFO
fngLIFO / fogLC / fsgLIFO
fn,sg0LIFO / fn,sg1LIFO / fogLIFO / fn,sg2-1LIFO
fn,sg0LIFO / fn,sg1LIFO / fogLC / fn,sg2-1LIFO
fn,s,og0LIFO / fn,s,og1LIFO / fn,s,og2-1LIFO
fo,n,sgLC
fn,ogLC / fsgLC
fngLIFO / fog0LIFO / fog1New / fog2-1LIFO / fsgLIFO
Table 1: Implemented Flaw Selection Strategies

blocks world, the Monkeys and Bananas problem, Pednault's (1988) briefcase-andoce problem, Russell's (1992) tire changing world, etc.
2. The Trains Problems, three problems taken from the TRAINS transportation domain
(Allen, Schubert, & et al., 1995).
3. The Tileworld Problems, seven problems taken from the Tileworld domain (Pollack &
Ringuette, 1990).
We ran each strategy on each problem twice. The first time, we imposed a node limit,
of 10,000 nodes for the basic problems, and of 100,000 nodes for the Trains and Tileworld
problems. The second time, we imposed a time limit, of 100 seconds for the basic problems,
and of 1000 seconds for the Trains and Tileworld problems.
Gerevini and Schubert experimented with several different node selection strategies for
the Trains and Tileworld domains, so to facilitate comparison we also used the same node
selection strategies as they did. For the basic problems, we used S + OC .
In reporting our results, we make use not only of raw counts of nodes generated and
computation time in seconds taken, but we also compute a measure of how badly a strategy
performed on a given problem or set of problems. We call this measure %-overrun, and
compute it as follows. Let m be the minimum node count on a given problem for any of
the strategies we tested, and let c be the node count for a particular strategy S . Then
%-overrun(S ) = [(c , m)=m]  100
Thus, for example, if the best strategy on a given problem generated 100 nodes, then a
strategy that generated 200 nodes would have a 100 %-overrun on that problem. The
strategy that does best on a given problem will have a %-overrun of 0 on that problem. In
Section 4.6, we make use of similarly computed %-overruns for computation time.
If a strategy hit the node limit, we set c to the relevant node limit (10,000 or 100,000)
to compute its node-count %-overrun.8 Similarly, if a strategy hit the time limit, we used
the relevant time limit (100 or 1000) to compute the computation-time %-overrun.
8. Because of the way in which UCPOP completes its basic iteration, it sometimes will go somewhat beyond
the specified node limit before terminating the run. In such cases, we used the node limit value, rather
than the actual number of nodes generated, in our computation of %-overrun.

234

fiFlaw Selection Strategies
Online Appendix A provides the raw data|node counts and computation-time taken|
for all the experiments we conducted; it also includes computed %-overruns.
In conducting experiments such as these, one has to set either a node- or time limit
cutoff for each strategy/problem pair. However, there is always a danger that these cutoffs
unfairly bias the data, if the limits are set in such a way that certain strategies that fail
would instead have succeeded were the limits increased slightly. We have carefully analyzed
our data to help eliminate the possibility of such a bias; details are given in Appendix A.

4.2 The Value of Least-Cost Selection

Having described our overall experimental design, we now turn to the analysis of the results. To begin, we sought to re-establish the claims we originally made in our earlier
work. Specifically, we wanted first to reconfirm, using a larger data set, that least-cost
aw selection is an effective technique for reducing the size of the search space generated
by a POCL planner. We therefore ran an experiment in which we compared the the node
counts for the five strategies we had earlier studied|LCFR, DUnf, DUnf-LC, UCPOP, and
UCPOP-LC|plus one new one, DUnf-Gen, explained below.
The results of this experiment are shown in Figures 2 and 3. The former is a log-log
scatter plot, showing the performance of each of the six strategies on the 33 problems in the
basic set. The problems were sorted by the minimal number of nodes generated on them
by any of the six strategies. Thus, the left-hand side of the graph includes the problems
that at least one of the six strategies found to be relatively easy, while the right-hand side
has the problems that were hard for all six strategies. We omitted problems that none
of the six strategies were able to solve. The actual number of nodes generated by each
strategy is plotted on the Y-axis, against the minimal number of nodes for that problem,
on the X-axis. LCFR's performance is highlighted with a line connecting its data points.
This graph shows that, in general, LCFR generates small search spaces on this problem set,
relative to the other strategies in this class. There were only six problems for which LCFR
was not within 10% of the minimum. Three of these are in the Get-Paid/Uget-Paid class
of problems|including two of the \hardest" problems (UGet-Paid3 and UGet-Paid4). We
discuss this class of problems more in Section 4.5.
An alternative view of the data is given in Figure 3, which shows the aggregate performance of the six strategies, i.e., the average of their node-count %-overrun on the basic
problems. As can be seen, LCFR has the smallest average %-overrun.
Figures 4 and 5 present similar views of the data for the Tileworld domain, while Figure
6 gives the data for the Trains problems. On the Trains domain, these six strategies were
only able to solve the easiest problem (Trains1), so we simply show the actual node counts
in Figure 6. We have omitted two data points, because they were so extreme that their
inclusion on the graph made it impossible to see the differences among the other strategies:
LCFR and DUnf-Gen with S + OC + UC node selection took 28,218, and 35,483 nodes,
respectively, to solve the problem.
For the Tileworld and Trains problems, we observed the same sorts of interactions between node and aw selection strategies as were seen by Gerevini and Schubert. Specifically,
LCFR performs relatively poorly with S + OC on the Tileworld problems, and it performs
very poorly with S + OC + UC on the Trains problems. However, when paired with the
235

fiPollack, Joslin, & Paolucci
10000

Nodes Generated (Log)

1000
UCPOP
DUnf
UCPOP-LC
DUnf-LC
DUnf-Gen
LCFR
100

10
10

100

1000

10000

Minimum Number of Nodes Generated (Log)

Figure 2: Basic Problems: Node Counts for Strategies without Forced-Flaw Delay
other node-selection strategies, LCFR produces the smallest search spaces of any strategies
in this class.
In sum, LCFR does tend to produce smaller search spaces than the other strategies in
this class. But a question remains. LCFR uses a least-cost strategy, and a side effect of
this is that it will prefer forced aws, since forced aws are low-cost aws. It is therefore
conceivable that LCFR's performance is mostly or even fully due to its preference for forced
aws, and not (or not greatly) inuenced by its use of a least-cost strategy for unforced
aws. This same hypothesis could explain why DUnf-LC consistently outperforms DUnf,
and why UCPOP-LC consistently outperforms UCPOP.
It was to address this issue that we included DUnf-Gen in our experiment. DUnf-Gen is
a simple strategy that prefers forced aws of any kind, and otherwise uses a LIFO regime.
We would expect DUnf-Gen and LCFR to perform similarly, since they frequently make
the same decision. Specifically, they will both select the same aw in any node in which
there is a forced aw; they will differ when there are only unforced aws, with DUnf-Gen
selecting a most recently introduced aw and LCFR selecting a least-cost aw.
In practice, DUnf-Gen's performance closely mimicked that of LCFR's. On the basic
problem set it did only marginally worse than LCFR. In fact, it does marginally better
when we reverse the order in which the planner adds the preconditions of each new step
to the open list (see Section 4.4). LCFR does somewhat better than DUnf-Gen on both
the Trains and Tileworld problems, and this is true regardless of the order in which the
preconditions were added to the open list, but the extent to which it does better varies.
Thus, the data is inconclusive about the value of using a least-cost strategy for unforced
aws. LCFR clearly benefits from selecting forced aws early (as a side effect of preferring
236

fiFlaw Selection Strategies
3500

3000

Node-Count %-Overrun

2500

2000

1500

1000

500

0
LCFR

DUnf-Gen

UCPOP-LC

UCPOP

DUnf-LC

DUnf

Figure 3: Basic Problems: Aggregate Performance for Strategies without Forced-Flaw Delay
100000

10000

Nodes Generated (Log)

UCPOP S+OC
UCPOP-LC S+OC
DUnf S+OC
DUnf-LC S+OC
DUnf-Gen S+OC

1000

DUnf-Gen S+OC+UC
DUnf-Gen S+OC+.1UC+F
LCFR S+OC
LCFR S+OC+UC
LCFR S+OC+.1UC+F
100

10
10

100

1000

Minimum Number of Nodes Generated (Log)

Figure 4: Tileworld Problems: Node Counts for Strategies without Forced-Flaw Delay
237

fiPollack, Joslin, & Paolucci

35000

30000

25000

20000

15000

10000

5000

UCPOP
S+OC

UCPOP-LC
S+OC

DUnf
S+OC

DUnf-LC
S+OC

LCFR
S+OC

DUnf-Gen
S+OC

DUnf-Gen
S+OC+.1UC+F

DUnf-Gen
S+OC+UC

LCFR
S+OC+.1UC+F

LCFR
S+OC+UC

0

Figure 5: Tileworld Problems: Aggregate Performance for Strategies without Forced-Flaw
Delay
800

700

Nodes Generated

600

500

400

300

200

100

UCPOP
S+OC

DUnf
S+OC

DUnf-Gen
S+OC+.1UC+F

DUnf-Gen
S+OC

UCPOP-LC
S+OC

DUnf-LC
S+OC

LCFR
S+OC

LCFR
S+OC+.1UC+F

0

Figure 6: Trains 1: Node Counts for Strategies without Forced-Flaw Delay
238

fiFlaw Selection Strategies
least-cost aws), but it may not matter whether it continues to use a least-cost strategy for
the unforced aws. If indeed it is generally sucient to use a least-cost strategy only for
forced aws, then ZLIFO's performance is somewhat less puzzling, since ZLIFO also prefers
forced aws. However the puzzle is not completely resolved. After all, DUnf-Gen, like
ZLIFO, prefers forced aws and and then makes LIFO-based decisions about unforced aws,
and while its performance is not clearly inferior to LCFR's, neither is it clearly superior.
Even if the use of LIFO for unforced aws does not obviously increase the search-space,
neither does it appear to decrease it.

4.3 Comparing LCFR and ZLIFO

We next turn to a direct comparison of LCFR and ZLIFO. Gerevini and Schubert compared
these strategies on only a few problems. To get a more complete picture of the performance
of both LCFR and ZLIFO, we ran them both on all the problems from our three problem
sets.
The data for the basic problem set is shown in Figure 7. We have sorted the problems
by the difference between the node counts produced by LCFR and ZLIFO. Thus, problems
near the left-hand side of the graph are those for which LCFR generated a smaller search
space, while problems near the right-hand side are the ones on which ZLIFO had a space
advantage. We omit problems which neither strategy could solve.
As can be seen, on some problems (notably R-Test2, Move-Boxes, and Monkey-Test2),
LCFR generates a much smaller search space than ZLIFO, while on other problems (notably
Get-Paid4, Hanoi, Uget-Paid4, and Uget-Paid3), ZLIFO generates a much smaller search
space. These are problems on which LCFR also did worse than the strategies mentioned
above in Section 4.2.
As we noted earlier, one of the major changes between UCPOP v.2 and v.4 is that
v.4 puts the elements of a new set of open conditions onto the aw list in the reverse
order from that of v.2. This ordering may make a difference, particularly for LIFO-based
strategies. Indeed, other researchers have suggested that one reason a LIFO-based strategy
may perform well is because it can exploit the decisions made by the system designers in
writing the domain operators, since it is in some sense natural to list the most constraining
preconditions of an operator first (Williamson & Hanks, 1996). We therefore also collected
data for a modified version of UCPOP, in which the preconditions for each step are entered
onto the open condition in the reverse of the order in which they would normally be entered.
We discuss the results of this modification in more detail in the next two sections, but for
now, we simply present the node counts for LCFR and ZLIFO with the reversed precondition
insertion, in Figure 8. As can be seen, there are a few problems on which reversing the
precondition ordering has a significant effect (notably FIXB and MonkeyTest2), but by and
large LCFR and ZLIFO showed the same relative performance.
For the problems in the basic set, it is dicult to discern an obvious pattern of performance. In contrast to what Gerevini and Schubert suggest, there does not seem to be a clear
correlation between the diculty of the problem, measured in terms of nodes generated,
and the relative performance of LCFR and ZLIFO. (In fact, it is a little dicult to determine which strategy's node-count should serve as the measure of diculty.) On the other
hand, it is true that in the aggregate, ZLIFO generates smaller search spaces than LCFR
239

fiR-TEST2

240

UGET-PAID3

UGET-PAID4

MONKEY-TEST2

HANOI

GET-PAID4

GET-PAID3

GET-PAID2

UGET-PAID2

UGET-PAID

ROAD-TEST

FIX5

FIX4

GET-PAID

FIXA

R-TEST1

FIX2

TEST-FERRY

MONKEY-TEST1

FIX1

SUSS-ANOM

TWO-INV3

FIX3

RAT-INSULIN

PRODIGY-SUSS

TWO-INV4

FIXB

MOVE-BOXES

Nodes Generated (Log)

R-TEST2

UGET-PAID3

UGET-PAID4

HANOI

GET-PAID4

GET-PAID3

TEST-FERRY

GET-PAID2

UGET-PAID2

HO-DEMO

TOW-INV3

UGET-PAID

TOW-INV4

ROAD-TEST

FIX5

FIX4

GET-PAID

R-TEST1

SUSS-ANOM

FIX2

FIX1

FIX3

MONKEY-TEST1

PRODIGY-SUSS

RAT-INSULIN

FIXA

MONKEY-TEST2

MOVE-BOXES

Nodes Generated (Log)

Pollack, Joslin, & Paolucci

10000

1000

100
LCFR -Default

ZLIFO -Default

10

1

Figure 7: Basic Problems: Node Counts for LCFR and ZLIFO

10000

1000

100
ZLIFO-Reversed

LCFR-Reversed

10

1

Figure 8: Basic Problems: Node Counts for LCFR and ZLIFO with Reversed Precondition
Insertion

fiFlaw Selection Strategies
on the basic problems. With the default precondition ordering, ZLIFO obtains an average
%-overrun of 212.62, while LCFR obtains 647.57. With reverse ordering, ZLIFO's average
%-overrun is 244.24, while LCFR's is 914.87. The fact that LCFR's relative performance is
worse when the preconditions are entered in the reverse direction results primarily from its
failure on MonkeyTest2 in the reverse direction.
The Trains data is scant. Neither LCFR nor ZLIFO can solve the hardest problem,
Trains3, regardless of whether the preconditions are entered in the default or the reverse
order. (In fact, none of the strategies we studied were able to solve Trains3.) But, at least
when the preconditions are entered in the default order, ZLIFO can solve Trains2, and
LCFR cannot. With reverse precondition insertion, neither strategy can solve Trains2. The
data are shown in Figure 9. Note that LCFR's performance is essentially the same for both
node-selection strategies shown.
Finally, the Tileworld data, for the default order of precondition insertion, is shown in
Figure 10. Here is the only place in which LCFR clearly generates smaller search spaces
than ZLIFO. We have not also plotted the data for reverse precondition insertion, because
most of the strategies are not affected by this change. There is however, one very notable
exception: with reversed insertion, ZLIFO (with S + OC + :1UC + F ) does much better|
indeed, it does as well as LCFR. We return to the inuence of precondition ordering on the
Tileworld problems in Section 4.5.
For now, however, it is enough to observe that our experiments show that ZLIFO does
tend to generate smaller search spaces than LCFR. It does so on the basic problem set,
regardless of the order of precondition insertion, it does so on Trains for one ordering (and
does no worse than LCFR on the other ordering), and it does as well as LCFR for the
Tileworld problems when the preconditions are inserted in the reverse order. The only
exception is the Tileworld problem set when the preconditions are inserted in default order:
there LCFR does better.

4.4 The Value of Separable-Threat Delay

Our first two analyses were essentially aimed at replicating earlier results from the literature,
namely the LCFR results and the ZLIFO results. We next address the question of how to
square these results with one another.
Recall that LCFR and ZLIFO differ in two key respects. First, LCFR treats all aws
uniformly, while ZLIFO distinguishes among aw types, giving highest preference to nonseparable threats, medium preference to open conditions, and lowest preference to separable
threats. Second, while LCFR uniformly makes least-cost selections, ZLIFO uses a LIFO
strategy secondary to its aw-type preferences (but after giving preference to forced open
conditions). The comparisons made in Section 4.2 suggest that the use of a LIFO strategy
for unforced aws should at best make little difference in search-space size, and may possibly lead to to the generation of larger search spaces. On the other hand, the first difference
presents an obvious place to look for a relative advantage for ZLIFO. After all, what ZLIFO
is doing is delaying separable threats, and Peot and Smith demonstrated the effectiveness
of that approach in their DSep strategy.
Peot and Smith's proof that DSep will never generate a larger search space than UCPOP
does not transfer to LCFR. There are planning problems for which LCFR will generate a
241

fiPollack, Joslin, & Paolucci

100000

Nodes Generated (Log)

10000

1000
ZLIFO S+OC
ZLIFO S+OC+.1UC+F
LCFR S+OC
LCFR S+OC+.1UC+F
100

10

1
TRAINS1 (Default)

TRAINS1 (Reverse)

TRAINS2 (Default)

Figure 9: Trains Problems: Node Counts for LCFR and ZLIFO
100000

Nodes Generated (Log)

10000

ZLIFO S+OC

1000

ZLIFO S+OC+.1UC+F
LCFR S+OC
LCFR S+OC+UC
LCFR S+OC+.1UC+F
100

10

1
TW-EZ

TW-1

TW-2

TW-3

TW-4

TW-5

TW-6

Figure 10: Tileworld Problems: Node Counts for LCFR and ZLIFO
242

fiFlaw Selection Strategies
smaller search space than DSep. Their proof relies on the fact that, in DSep, open conditions
will be selected in the same order, regardless of when threats are selected. But the selection
of a threat in LCFR can inuence the repair cost of an open condition (e.g., by promoting
an action so that it is no longer available as a potential establisher for some condition), and
this in turn can affect the order in which the remaining open conditions are selected.
Nonetheless, despite the fact that one can't guarantee that delaying separable threats
will lead to a reduction in search-space size, the motivation behind DSep is still appealing:
separable threats may often simply disappear during subsequent planning, which will naturally lead to a reduction in search-space size. For this reason, we implemented a slightly
modified version of LCFR, which we called LCFR-DSep, in which separable threats are
delayed. Note that it is relatively easy to do this in the UCPOP system, which provides
a switch, the dsep switch, which when turned on will automatically delay the repair of all
separable threats. As defined earlier in Table 1, the definition of LCFR-DSep is:
LCFR-DSep fn,ogLC / fsgLC
Our hypothesis was that if ZLIFO's reduction in search-space size were largely due to its
incorporating a DSep approach, then LCFR-DSep ought to be \the best of both worlds",
combining the advantages of LCFR's least-cost approach with the advantages of a DSep
approach.
On the basic problems, LCFR-DSep proved to have the smallest average node-count %overrun of on the basic problems of all of the strategies tested. Moreover, this was true even
when we reversed the order in which the preconditions of an operator were added to the open
list. Figure 11 gives the average node-count %-overruns for both the unmodified UCPOP v.4
(labeled \default") and the modified version in which we reversed the precondition ordering
(labeled \reverse"). Reversing the ordering does not effect the conclusion that LCFR-DSep
generates the smallest search spaces for these problems; in fact, in general it had very little
affect on the relative performance of the strategies at all. The only notable exception, which
we mentioned earlier, is that the relative performance of LCFR and DUnf-Gen ips.
For more detailed comparison, we plot node counts on the basic problems for LCFR,
ZLIFO, and the Separable-Threat Delay strategies in Figure 12. For ease of comparison, we
again show the data sorted by the difference between LCFR and ZLIFO's node counts. The
problems near the left-hand side of the graph are, again, those for which LCFR generated
a smaller search space than ZLIFO; the problems near the right are those for which it
generated a larger search space. As can be seen, LCFR-DSep nearly always does as well
as, or better than LCFR. It does much better than ZLIFO on the problems that LCFR is
good at. And it also does much better than LCFR on the problems that ZLIFO is good at.
However, ZLIFO still outperforms LCFR-DSep on this latter class of problems.
Another view of the data is given in Figure 13, the log-log scatter plot for the basic
problems, for all the strategies we studied. This time we have highlighted LCFR-DSep's
performance. Although there are some problems for which it does not produce a minimal
search space, its performance on the individual problems is actually quite good, consistent
with its good aggregate performance.
At least for the basic problems, augmenting the simple LCFR strategy with a delay of
separable threats reduces the search space as expected. This in turn suggests that when
LCFR generates a larger search space than ZLIFO, that is due in large part to the fact that
243

fiPollack, Joslin, & Paolucci

4000

3500

Node-Count %-Overrun

3000

2500

Default

2000

Reverse

1500

1000

500

0
LCFRDSep

DSepLc

ZLIFO

DSep

LCFR

DUnfGen

UC
POP-LC

UCPOP

DUnfLC

DUnf

Figure 11: Basic Problems: Aggregate Performance for all Strategies

10000

Nodes Generated (Log)

1000

ZLIFO
100

LCFR
LCFR-DSep

10

UGET-PAID3

HANOI

UGET-PAID4

GET-PAID4

GET-PAID3

GET-PAID2

TEST-FERRY

HO-DEMO

UGET-PAID2

TOW-INV3

TOW-INV4

UGET-PAID

ROAD-TEST

FIX4

PRODIGY-P22

R-TEST1

FIX5

GET-PAID

FIX2

SUSS-ANOM

FIX1

FIX3

PRODIGY-SUSS

MONKEY-TEST1

FIXA

RAT-INSULIN

MOVE-BOXES

MONKEY-TEST2

R-TEST2

1

Figure 12: Basic Problems: Node Counts for LCFR, ZLIFO, and DSep Strategies
244

fiFlaw Selection Strategies
10000

1000
Nodes Generated (Log)

UCPOP
DSep
DUnf
UCPOP-LC
DUnf-LC
ZLIFO
DUnf-Gen
LCFR
DSep-Lc

100

LCFR-DSep

10
10

100

1000

10000

Minimum Number of Nodes Generated (Log)

Figure 13: Basic Problems: Node Counts for all Strategies
it does not delay separable threats. ZLIFO's primary advantage relative to LCFR seems
not to be its use of a LIFO strategy for unforced threats, but rather its separable-threat
delay component. Combining separable-threat delay with a least-cost approach yields a
strategy that tends to generate smaller search spaces than either strategy by itself for the
basic problem set. However, analysis of the Trains and Tileworld problem sets reveals the
situation to be a little more complicated than the comparison of the basic problems would
suggest, as we discuss in the next section.

4.5 The Need for Domain Information

The Tileworld and Trains domains problems challenge overly simple conclusions we might
draw from the basic problem sets. We consider each set of problems in turn.
4.5.1 The Tileworld Problems

The Tileworld domain involves a grid with tiles and holes, and the goal is to fill each hole
with a tile. This goal can be achieved with a fill operator, which has two preconditions:
the agent must be at the hole, and it must be holding a tile. In our encoding, an agent can
hold up to four tiles at a time. The go operator is used to achieve the (sub)goal of being
at a hole, while the pickup operator is used to achieve the (sub)goal of holding a tile. In
the normal way, go has a precondition of being at some location, namely whatever location
the agent will move from. Pickup has a precondition of being at the location of some tile.
The problems in the Tileworld problem set differ from one another in the number of holes
that the agent must fill: each problem adds another hole.
245

fiPollack, Joslin, & Paolucci
100000

LCFR S+OC+UC
10000

LCFR S+OC+.1UC+F
DUnf-Gen S+OC+UC

Nodes Generated (Log)

DUnf-Gen S+OC+.1UC+F
DUnf-Gen S+OC
LCFR S+OC
LCFR-DSep S+OC+UC
ZLIFO S+OC+.1UC+F

1000

ZLIFO S+OC
LCFR-DSep S+OC+.1UC+F
DSep-LC S+OC
LCFR-DSep S+OC
DUnf S+OC
DSep S+OC
100

UCPOP-LC S+OC
DUnf-LC S+OC
UCPOP S+OC

10
10

100

1000

Minimum Number of Nodes Generated (Log)

Figure 14: Tileworld Problems: Node Counts for All Strategies
Figures 14 gives the log-log plot for the various strategies on the Tileworld problems,
when the preconditions were entered in the default order. Note that LCFR (S + OC + UC )
is the strategy highlighted. Three other strategies were almost indistinguishable from LCFR
(S + OC + UC ), namely, LCFR (S + OC + :1UC + F ), DUnf-Gen (S + OC + UC ) and
DUnf-Gen(S + OC + :1UC + F ). All the other strategies performed worse. This can more
easily be seen in Figure 15, which gives the aggregate performance for the leading strategies:
those that were able to solve all seven Tileworld problems. In fact, these leading strategies
were able to solve the seven Tileworld problems without generating more than 1800 nodes
for any problem. In contrast, the remaining strategies failed on at least one, and up to four,
of the seven problems, given the limit of 100,000 nodes generated.
What was originally surprising to us is that on the Tileworld problems, delaying separable threats actually seems to hurt performance. The strategies that did best were those like
LCFR and DUnf-Gen that do not delay separable threats. LCFR-DSep, ZLIFO, DSep-LC,
and DSep all generated larger search spaces, in contrast to what we would have predicted
given the experiments on the basic problem set.
To understand this result, we looked in detail at the planning trace for these problems.
What that revealed is that for the Tileworld domain, the early resolution of separable threats
has an important advantage: it imposes what turns out to be the correct temporal ordering
between the steps of going to up a tile (to pick it up), and carrying it to a hole. Virtually
all the strategies create subplans like the one shown in Figure 16. The goals involve filling
holes, so the planners insert steps to go to and pick up a tile, and to go to the hole. At this
point, there are two separable threats: (1) the effect of going to the hole, :at(X ), threatens
the link between going to the tile and picking it up (at(Z )), and (2) the effect of going to
246

fiFlaw Selection Strategies
100

90

80

Node-Count %-Overrun

70

60

50

40

30

20

10

0
LCFR
S+OC+UC

LCFR
S+OC+.1UC+F

DUnf-Gen
S+OC+UC

DUnf-Gen
S+OC+.1UC+F

DUnf-Gen
S+OC

Figure 15: Tileworld Problems: Aggregate Performance for Leading Strategies

at(X)

GO(X,Y)

at(Y)
loc(H,Y)
holding(T)

~at(W)
at(W)

GO(W,Z)

at(Z)
tile(T)
loc(T,Z)

~at(X)

FILL(H)

filled(H)

PICKUP(T)

Figure 16: Typical Partial Plan for the Tileworld Domain
the tile, :at(W ), threatens the link between going to the hole and filling it (at(Y )). Both
threats are separable, because X and W will be unbound; the planner does not yet know
where it will be traveling from. But there is only one valid temporal ordering that will
resolve these threats: going to the tile must precede picking up the tile, which in turn must
precede going to the hole. Once this temporal ordering is determined, further planning goes
smoothly.
In contrast, if this ordering decision is not made, the planner can often \get lost",
attempting to find plans in which it goes from some location to the hole and then from the
hole to the tile. There are many ways to attempt this, because there are many different
247

fiPollack, Joslin, & Paolucci
100000

LCFR-DSep S+OC+.1UC+F
10000

ZLIFO S+OC+.1UC+F
LCFR S+OC+UC

Nodes Generated (Log)

LCFR S+OC+.1UC+F
DUnf-Gen S+OC+.1UC+F
LCFR-DSep S+OC+UC
DUnf-Gen S+OC
DUnf-Gen S+OC+UC

1000

DUnf-LC S+OC
LCFR-DSep S+OC
DSep-LC S+OC
LCFR S+OC
ZLIFO S+OC
UCPOP-LC S+OC
100

DUnf S+OC
DSep S+OC
UCPOP S+OC

10
10

100

1000

Minimum Number of Nodes Generated (Log)

Figure 17: Tileworld Problems: Node Counts with Reversed Precondition Insertion
tiles to select, and many different locations to move among. The planner may try many
of these alternatives before determining that there is a fundamental inconsistency in these
plans, and that they are destined to fail. The larger the number of holes to be filled, the
worse the situation becomes.
Sometimes the planner may make the right decision about temporal ordering even if it
has deferred separable threats. When faced with the partial plan in Figure 16, if the planner
does not select a threat, it will select from among several open conditions. It can attempt
to establish the precondition of going to the hole (at(X )) by reusing the effect of going to
the tile (at(Z )), or it can do the reverse, and attempt to establish the precondition of going
to the tile (at(W )) by reusing the effect of going to the hole (at(X )). Of course, the first
solution is the right one, and includes the critical temporal ordering constraint, while the
second will eventually fail.
The order in which the open conditions are selected will determine which of these two
choices the planner makes. When preconditions are entered in the default order, planners
that delay separable threats end up making the latter, problematic choice. In contrast,
when the preconditions are entered in the reverse order, the planners make what turns
out to be the correct choice. Thus, for the experiments in which we reversed precondition
insertion, we see a different pattern of performance, as shown in Figures 17{18.9
When the preconditions are entered in the reverse order, a larger number of strategies
perform well, solving all the problems. In particular, with S + OC + :1UC + F node9. To preserve readability, in Figure 18, we have used \(1)" to denote S + OC , \(2)" for S + OC + U C ,
and \(3)" for S + OC + U C + :1F .

248

fi249
UCPOP (1)

DUnf (1)

DSep (1)

UCPOP-LC (1)

LCFR (1)

ZLIFO (1)

DSep-LC (1)

LCFR-DSep (1)

DUnf-LC(1)

DUnf-Gen (2)

DUnf-Gen (1)

LCFR-DSep (2)

DUnf-Gen (3)

LCFR (3)

LCFR (2)

ZLIFO (3)

LCFR-DSep (3)

Node-Count %-Overrun

Flaw Selection Strategies

50000

45000

40000

35000

30000

25000

20000

15000

10000

5000

0

Figure 18: Tileworld Problems: Aggregate Performance for all Strategies with Reversed
Precondition Insertion

fiPollack, Joslin, & Paolucci
25000

20000

15000
TRAINS1
TRAINS2
10000

5000

DSep-LC
S+OC

LCFR-DSep
S+OC

LCFR-DSep
S+OC+.1UC+F

ZLIFO
S+OC+.1UC+F

DUnf
S+OC

LCFR-DSep
S+OC+UC

ZLIFO
S+OC

DSep
S+OC

0

Figure 19: Trains Problems: Node Counts
selection, the performance of LCFR, DUnf-Gen, ZLIFO, and LCFR-DSep is virtually indistinguishable. It is important to note that the leading strategies that do not delay separable
threats|LCFR and DUnf-Gen|are not affected much by the reversal of precondition insertion for the Tileworld problems; in fact, LCFR's performance is identical in both cases.
In contrast, the strategies that use separable-threat delay|LCFR-DSep, ZLIFO, and DSepLC|all perform much better when we reverse precondition insertion. This is explained by
our analysis above.
In sum, what is most important for the Tileworld domain is for the planner to recognize,
as early as possible, that there are certain required temporal orderings between some of the
steps in any successful plan. Every successful plan will involve going to a tile before going
to a hole, although there is exibility in the order in which multiple holes are visited, and
in the interleaving of picking up tiles and dropping them in holes. For the strategies we
studied, there were two different methods that led to this temporal constraint being added
to the plan. It was added when the planner selected a separable threat to resolve, and it
was added when it selected one particular precondition to resolve before another.
4.5.2 The Trains and Get-Paid Problems

The Trains domain present a somewhat different variation on our original conclusions. The
Trains domain involves a set of locations and objects, and the goal is to transport various
objects from specific starting locations to specified destinations. Gerevini and Schubert
studied three Trains problems. All of our strategies failed to successfully complete the
hardest of these (Trains3) within either the 100,000 node or the 1000 second limit. Moreover,
many of them also failed on the second hardest (Trains2). Caution must therefore be taken
in interpreting the results, as there are a limited number of data points.
250

fiFlaw Selection Strategies
Figure 19 gives the node counts for the Trains domain, with preconditions inserted in the
default order. We only show the strategies that were able to solve both Trains1 and Trains2.
These results are closer to what we would have predicted from the basic problem set than
were the results with the Tileworld. In particular, LCFR-DSep does very well, generating
much smaller search spaces than LCFR. However, it does slightly worse than ZLIFO.
Recall that we saw the same pattern of performance on a subset of the basic problems,
specifically on the Get-Paid/Uget-Paid problems. There, LCFR-DSep again improved on
LCFR, but did not generate as small search spaces as ZLIFO. It turns out that there are
similar factors inuencing both sets of problems, and it is instructive to consider in some
detail the planning done by ZLIFO and LCFR-DSep for the Get-Paid/Uget-Paid problems
to understand what is occurring.
Like the Trains domain problems, the Get-Paid/Uget-Paid problems involve moving
particular objects to specified locations. In the Get-Paid/Uget-Paid domain there are three
objects: a paycheck, a dictionary, and a briefcase. As generally formulated, in the initial
state all three are at home, and the paycheck is in the briefcase. The goal is to deposit
the paycheck at the bank, bring the dictionary to work, and have the briefcase at home.
Both the dictionary and the paycheck can be moved only in the briefcase. For a human,
the solution to this problem is obvious. The dictionary must be put into the briefcase, and
it must then be carried to work, where the dictionary is taken out. The briefcase must then
be carried home. In addition, a stop must be made at the bank, either on the way to work
or on the way home, at which point the paycheck must be taken out of the briefcase and
deposited.
ZLIFO and LCFR-DSep take different paths in solving this problem. ZLIFO begins by
forming plans to get the paycheck to the bank and the dictionary to work. These goals
are selected first because they are forced: there is only one way to get the paycheck to the
bank (carry it there), and similarly only one way to get the dictionary to the oce (carry
it there). In contrast, there are two possible ways to get the briefcase home: either by
leaving it there (i.e., reusing the initial state) or by carrying it there from somewhere else
(i.e., adding a new step). The LIFO mechanism then proceeds to complete the plans for
achieving the goals of getting the paycheck to the bank and the dictionary to work, before
beginning to work on the remaining goal, of getting the briefcase home. At this point, that
goal is easy to solve. All that is needed is to plan a route home from wherever the briefcase
is at the end of these two errands.
LCFR-DSep, like ZLIFO, begins by selecting the forced goals of getting the dictionary
to the oce and getting the paycheck to the bank. However, instead of next completing
the plans for these goals, LCFR-DSep continues to greedily select least-cost aws, and thus
begins to work on achieving the goal of getting the briefcase home. Unfortunately, at this
point it is not clear where the briefcase needs to be moved home from, and hence LCFRDSep begins to engage in a lengthy process of \guessing" where the briefcase will be at the
end of the other tasks, before it has planned for those tasks.10
10. The diculty that LCFR-DSep encounters by greedily picking low-cost aws might be reduced by doing
a lookahead of several planning steps, to determine a more accurate repair cost. This is the approach
taken in the branch-n mechanism in O-Plan (Currie & Tate, 1991). Significant overhead can be involved
in such a strategy, however.

251

fiPollack, Joslin, & Paolucci
The key decision for the Get-Paid/Uget-Paid domain|and, as it turns out, for the Trains
domain|is related to, but subtly different from the key decision in the Tileworld domain.
For Get-Paid/Uget-Paid and Trains, the key insight for the planner is again that there is
an important temporal ordering between goals. The goal of getting the briefcase home is
going to have to be achieved after the goal of taking the dictionary to work. However,
recognition of this constraint is not affected by separable-threat delay, as it was for the
Tileworld. Instead, what happens in these domains is that a higher-cost aw interacts with
a lower-cost one, causing the latter to become fully constrained.
It is tempting to think that here finally is a case in which a LIFO-based strategy is
advantageous. After all, for this example, by completely determining what you will do to
achieve one goal, you make it much easier to know how to solve the another goal. But the use
of ZLIFO (or an alternative LIFO-based strategy) does not guarantee that the interactions
between high- and lower-cost aws will be exploited. In particular if the interactions are
among two or more unforced aws, then the order of the goals in the agenda can lead ZLIFO
to make an inecient choice. Thus, when we modified the problem so that the briefcase was
at work in the initial state, ZLIFO and LCFR-DSep both solved the problem very quickly
(178 nodes for ZLIFO and 157 for LCFR-DSep). Note that this modification removes the
problematic interaction between a low-cost and a high-cost aw.
Finally, note that the effectiveness of the LIFO strategies is again heavily dependent
on the the order in which preconditions are entered onto the open list. Figure 20 gives
the node counts for the Trains domain with reverse precondition insertion. We once again
plot only the strategies that can solve both Trains 1 and Trains2. In this case, there are
only two such strategies: LCFR-DSep and DSep-LC. The strategies that rely on LIFO for
open-condition selection, ZLIFO, DSep, DUnf-Gen, and UCPOP, all do significantly worse
than they did when the preconditions were in the correct order. To the extent that LIFO
helps in such domains, it appears to be because of its ability to exploit the decisions made
by the system designers in writing the domain operators, as suggested by Williamson and
Hanks (1996).

4.6 Computation Time
We have now covered the key questions we set out to address: what are the relative effects
of alternative search-control strategies on search-space size, and, in particular, how can
we reconcile the apparently conicting approaches of LCFR and ZLIFO? We concluded
that LCFR-DSep combines the main advantages for reducing search-space size of these two
strategies, namely LCFR's use of a least-cost selection mechanism, at least for forced aws,
with ZLIFO's use of separable-threat delay. A final question concerns the price one has to
pay to use LCFR-DSep|or for that matter, any of the alternative strategies. To achieve a
reduction in search-space size, is it necessary to spend vastly more time in processing? Or
do these strategies pay for themselves?
To answer these questions, we collected timing data on all our experiments. Figures 21
and 22 gives this data for the basic problems, for both the experiments run with the node
limit and those run with the time limit. (As detailed in Appendix A, the results for the
experiments with the node limit and the time limit were very similar.) Because we saw
little inuence of precondition ordering on the basic problems, we analyze only the data for
252

fiFlaw Selection Strategies
30000

25000

20000

TRAINS1

15000

TRAINS2

10000

5000

0
LCFR-DSep
S+OC+UC

LCFR-DSep
S+OC+.1UC+F

LCFR-DSep
S+OC

DSep-LC
S+OC

Figure 20: Trains Problems: Node Counts with Reversed Precondition Insertion
350

300

Computation-Time %-Overrun

250

200
Time Limit
Node Limit
150

100

50

0
DSep-Lc

ZLIFO

LCFR-DSep

DSep

Figure 21: Basic Problems: Aggregate Computation Time Performance for Leading Strategies
the default precondition ordering. We show one graph with all the strategies, and another
that includes only the \leading strategies", to make it possible to see the distinctions among
them.
253

fiPollack, Joslin, & Paolucci
30000

Computation-Time %-Overrun

25000

20000

Time Limit

15000

Node Limit

10000

5000

0
DSepLc

ZLIFO

LCFRDSep

DSep

UCPOP

UC
POP-LC

DUnfGen

LCFR

DUnfLC

DUnf

Figure 22: Basic Problems: Aggregate Computation Time Performance
The timing data show that LCFR-DSep does, by and large, pay for its own overhead
on the basic problems by generating smaller search spaces (and therefore having to process
fewer nodes). When run with a time limit, LCFR-DSep's time performance is almost
identical with ZLIFO's, despite the fact that repair cost computations are more expensive
than the stack-popping of a LIFO strategy. When run with a node limit, LCFR-DSep does
show worse time performance than ZLIFO in aggregate, but still performs markedly better
than most of the other strategies. The change in relative performance results from the cases
in which both strategies fail at the node limit: LCFR-DSep takes longer to generate 10,000
nodes.
Another interesting observation is that DSep-LC has the best time performance of all
on the basic problem set. This should perhaps not be a surprise, because DSep-LC closely
approximates LCFR-DSep. It differs primarily in its preference for nonseparable threats,
which in any case will tend to have low repair costs. Whenever a node includes a nonseparable threat, DSep-LC can quickly select that threat, without having to compute repair
costs. This speed advantage outweighs the cost of processing the extra nodes it sometimes
generates.
Figures 23{26 provide the timing data for the Trains and Tileworld domains.11 Here
there are no real surprises. The computation times taken parallel quite closely the size
of the search spaces generated. The strategies that generate the smallest search spaces
are also the fastest. With the Trains problems, we again see the DSep-LC can serve as
11. We have omitted the strategies that did very poorly, performing worse both on the node- and time-limit
experiments than did any of the strategies graphed. Note that we ran the reverse-order experiments only
with a node limit.

254

fiFlaw Selection Strategies
7000

6000

Computation-Time %-Overrun

5000

4000
Default-Node Limit
Default-Time Limit
3000

2000

1000

0
LCFR
(2)

DUnfGen
(2)

LCFR
(3)

DUnfGen
(3)

DUnfGen
(1)

ZLIFO
(1)

LCFR
(1)

ZLIFO
(3)

LCFRDSep
(2)

LCFRDSep
(3)

DSep
(1)

Figure 23: Tileworld Problems: Aggregate Computation Time Performance for Leading
Strategies
a good approximation technique for LCFR-DSep. Although it generates more nodes than
LCFR-DSep, it is somewhat faster.12

5. Conclusion
In this paper, we have synthesized much of the previous work on aw selection for partialorder causal link planning, showing how earlier studies relate to one another, and have
developed a concise notation for describing alternative aw selection strategies.
We also presented the results of a series of experiments aimed at clarifying the effects
of alternative search-control preferences on search-space size. In particular, we aimed at
explaining the comparative performance of the LCFR and ZLIFO strategies. We showed
that neither of these aw selection strategies consistently generates smaller search spaces,
but that by combining LCFR's least-cost approach with the delay of separable threats
that is included in the ZLIFO strategy, we obtain a strategy|LCFR-DSep|whose space
performance was nearly always as good as the better of LCFR or ZLIFO on a given problem.
We therefore concluded that much of ZLIFO's advantage relative to LCFR is due to its delay
of separable threats rather than to its use of a LIFO strategy. Although we were unable
to resolve the question of whether least-cost selection is required for unforced, as well as
forced aws, we found no evidence that a LIFO strategy for unforced aws was better. On
the other hand, separable-threat delay is clearly advantageous. An open question is exactly
why it is so advantageous. We have conducted preliminary experiments that suggest that
12. In interpreting the Trains timing data, it is important to note that some of the strategies shown|notably
UCPOP, UCPOP-LC, and Dunf, failed to solve Trains2 within either the node or the time limit.

255

fiPollack, Joslin, & Paolucci
900

800

Computation-Time %-Overrun

700

600

500

400

300

200

100

S+OC+UC
DUnf-Gen

S+OC
DUnf-Gen

S+OC
LCFR-DSep

S+OC
DUnf-LC

S+OC
DSep-LC

S+OC+.1UC+F
DUnf-Gen

S+OC+.1UC+F
LCFR

S+OC+UC
LCFR

S+OC+.1UC+F
LCFR-DSep

S+OC+.1UC+F
ZLIFO

S+OC+UC
LCFR-DSep

0

Figure 24: Tileworld Problems: Aggregate Computation Time Performance for Leading
Strategies with Reversed Precondition Insertion
2500

Computation-Time %-Overrun

2000

1500
Default - Node Limit
Default-Time Limit
1000

500

S+OC
UCPOP

S+OC
LCFR-DSep

S+OC+UC
LCFR-DSep

S+OC+.1UC+F
LCFR-DSep

S+OC
DSep-LC

S+OC+.1UC+F
ZLIFO

S+OC
ZLIFO

S+OC
DUnf

S+OC
DSep

0

Figure 25: Trains Problems: Aggregate Computation Time Performance for Leading Strategies
256

fiFlaw Selection Strategies

2000
1800

Computation-Time %-Overrun

1600
1400
1200
1000
800
600
400
200

S+OC
DSep

S+OC+.1UC+F
ZLIFO

S+OC
ZLIFO

S+OC+UC
LCFR-DSep

S+OC+.1UC+F
LCFR

S+OC
DUnf-LC

S+OC
LCFR

S+OC
UCPOP-LC

S+OC
LCFR-DSep

S+OC+.1UC+F
LCFR-DSep

S+OC
DSep-LC

0

Figure 26: Trains Problems: Aggregate Computation Time Performance for Leading Strategies with Reversed Precondition Insertion

257

fiPollack, Joslin, & Paolucci
much of the search-space reduction that results from delaying separable threats can also be
achieved by making separation systematic, something that UCPOP v.4 does not do.
We also considered the question of computation time, and showed that often LCFR-DSep
only requires computation time comparable to that of ZLIFO. LCFR-DSep can therefore be
seen as paying for its own computational overhead by its search-space reduction. Moreover,
Peot and Smith's DSep-LC provides a good approximation of LCFR-DSep: although it
produces somewhat larger search spaces, it does so more quickly.
These conclusions, however, are tempered by the fact that for certain clusters of problems, our combined strategy, LCFR-DSep, does not generate minimal search spaces. As
we saw, for the Tileworld problems, what is most important is to recognize the need for
a particular temporal ordering among plan steps, and this recognition can be obtained by
resolving separable threats early. For the Trains and Get-Paid/Uget-Paid domains, what
matters most is recognizing that a particular effect can in fact only be achieved in one
way, and this is only recognized when a particular aw is selected|a aw which happens
generally not to be the least cost aw available. The lesson to be learned from these sets of
problems is that although we now understand the reasons that LCFR and ZLIFO perform
the way they do, and how to combine the best features of both to create good default strategies for POCL planning, it is clear that domain-dependent characteristics such as those we
identified in the Trains and Tileworld domains must still be taken into account in settling
on a aw selection strategy for any domain.

Acknowledgments
Martha Pollack's work on this project has been supported by the Air Force Oce of Scientific
Research (F49620-96-1-0403) and an NSF Young Investigator's Award (IRI-9258392). David
Joslin has been supported by Rome Labs (RL)ARPA (F30602-95-1-0023) and an NSF CISE
Postdoctoral Research award (CDA-9625755). Massimo Paolucci has been supported by the
Oce of Naval Research, Cognitive and Neural Sciences Division (N00014-91-J-1694).
We are very grateful to Alfonso Gerevini for providing us with the code he used in his
earlier study, and allowing us to use it in our experiments. We would also like to thank
Arthur Nunes and Yazmine DeLeon, who assisted us in carrying out experiments done in
the preliminary stages of this work. Finally, we thank Alfonso Gerevini, Len Schubert,
Michael Wellman, and the anonymous reviewers for their helpful comments on this work.

Appendix A: Ruling Out Ceiling Effects
For the data collected using a node limit, we examined all the problems in which at least
one of the strategies hit the node limit. Table 27 gives the second worst node count for
all such problems. It shows that, for all the basic problems in which at least one strategy
failed, and at least one other succeeded, the second-worst strategy generally created fewer
than 7000 nodes.
Similarly, for the Trains and Tileworld problems, in all such cases except TW3, the
second-worst strategy took fewer than 50,000 nodes (and in TW3 it took 89,790). Recall
that the node limit for the basic problems was 10,000 nodes, while for the Trains and
Tileworld problems it was 100,000 nodes. It is thus clear that the strategies that hit the
258

fiFlaw Selection Strategies
PROBLEM
HANOI
R-TEST2
MONKEY-TEST2
MONKEY-TEST3
GET-PAID2
GET-PAID3
GET-PAID4
FIXIT
HO-DEMO
FIXB
UGET-PAID2
UGET-PAID3
UGET-PAID4
PRODIGY-P22
MOVE-BOXES
MOVE-BOXES-1

Default

Reverse
2919
7567
3744
10000
129
6431
1625
10000

TRAINS2
TRAINS3
TW-2
TW-3
TW-4
TW-5
TW-6

10000
175
4725
2894
8265
4402
10000

2952
5227
5200
10000
129
6431
1625
10000
10000
3184
175
4725
2894
9264
2687
10000

22351
100000

29585
100000

89790
3844
49024
1722

11620
401
1266
20345
3040

Figure 27: Second-Worst Node Counts on Problems with Failing Strategies
node limit are doing substantially worse than the strategies that succeed. Even if they were
to succeed by increasing the node limit slightly, their comparative performance would still
be poor.
Thus, by using the node limits we imposed, we are not making any strategies look worse
than they actually are. On the other hand, in computing %-overrun, we may be making
some strategies look better than they actually are, because we use a value of 10,000 (or
100,000) nodes generated when a strategy hits the limit, and the actual number of nodes it
might take, if run to completion, could be significantly higher. This is why, in our analyses,
we considered both the absolute performance of strategies on individual problems, and their
aggregate performance, as measured by average %-overrun.
We also compared the experiments that were run with a time limit and those that were
run with a node limit. For the basic problem set, the time limit of 100 seconds was high
enough that, in most cases, strategies could compute significantly more nodes than they
259

fiPollack, Joslin, & Paolucci
could with the node cutoff. Nonetheless, the results were almost identical. In nearly all
cases, if a strategy failed with the node cutoff, it also failed with the time limit cutoff. There
were only four exceptions to this:
1. Hanoi: With the 10,000 nodes limit, DSep fails, while with the 100 second time limit,
it succeeds, taking 46,946 nodes.
2. Uget-Paid3: With the 10,000 node limit, UCPOP-LC fails, while with the 100 second
time limit, it succeeds, taking 37,951 nodes.
3. Uget-Paid4: With the 10,000 node limit, UCPOP-LC fails, while with 100 second
time limit, it succeeds, taking 23,885 nodes.
4. Fixit: With the 10,000 nodes limit, DSep-LC, UCPOP-LC, and ZLIFO fail, while
with the 100 second time limit, they succeed in 12,732, 13,510, and 20,301 nodes
respectively. All the other strategies fail to solve this problem under either limit.
There was a similarly strong correspondence between the results we obtained on the
Trains and Tileworld problems using a node limit and a time limit. In a few cases, a
strategy that was able to succeed within the 100,000 node limit was not able to succeed
within the 1,000 second time limit. The nature of these problems is that the computation
time per node can be very great. Specifically,
1. On TW3, DUnf succeeded in 56,296 nodes when run with a node limit, but failed
with the 1,000 second time limit.
2. On TW4, LCFR-DSep (with an S+OC node-selection strategy) succeeded in 69,843
nodes, but failed on the time limit.
3. On TW5, LCFR-DSep (with an S+OC+UC node-selection strategy) succeeded in
49,024, but failed on the limit.
4. On TW6, LCFR (with an S+OC node-selection strategy) succeeded in 4,506 nodes,
but failed with the time limit.
In only one case did a strategy fail under the node limit but succeed within the time limit:
1. On TW3, DSep (with an S+OC node-selection strategy) failed with a 100,000 node
limit, but succeeded with 134,951 nodes using a 100 second time limit. Note that
this is significantly worse than the second worst strategy, which solved this problem
generating 89,790 nodes.
Given this close correspondence between the experiments with node and time limits, we
collected only node-limit data for the experiments in which we reversed the precondition
insertion.

260

fiFlaw Selection Strategies

References

Allen, J. F., Schubert, L. K., Ferguson, G. M., Heeman, P. A., Hwant, C. H., Kato, T., Light,
M., Margin, N. G., Miller, B. W., Poesio, M., & Traum, B. R. (1995). The TRAINS
project: A case study in building a conversational planning agent. Experimental and
Theoretical Artificial Intelligence, 7, 7{48.
Chapman, D. (1987). Planning for conjunctive goals. Artificial Intelligence, 32 (3), 333{378.
Currie, K., & Tate, A. (1991). O-plan: The open planning architecture. Artificial Intelligence, 52, 49{86.
Etzioni, O., Hanks, S., Weld, D., Draper, D., Lesh, N., & Williamson, M. (1992). An
approach to planning with incomplete information. In Proceedings of the Third International Conference on Principles of Knowledge Representation and Reasoning, pp.
115{125.
Gerevini, A. (1997). Personal communication.
Gerevini, A., & Schubert, L. (1996). Accelerating partial-order planners: Some techniques
for effective search control and pruning. Journal of Artificial Intelligence Research, 5,
95{137.
Joslin, D. (1996). Passive and Active Decision Postponement in Plan Generation. Ph.D.
thesis, Intelligent Systems Program, University of Pittsburgh.
Joslin, D., & Pollack, M. E. (1994). Least-cost aw repair: A plan refinement strategy for
partial-order planning. In Proceedings of the Twelfth National Conference on Artificial
Intelligence (AAAI), pp. 1004{1009 Seattle, WA.
Joslin, D., & Pollack, M. E. (1996). Is \early commitment" in plan generation ever a good
idea?. In Proceedings of the Thirteenth National Conference on Artificial Intelligence
(AAAI), pp. 1188{1193 Portland, OR.
Kambhampati, S., Knoblock, C. A., & Yang, Q. (1995). Planning as refinement search: A
unified framework for evaluating design tradeoffs in partial-order planning. Artificial
Intelligence, 76 (1-2), 167{238.
Kumar, V. (1992). Algorithms for constraint-satisfaction problems: A survey. AI Magazine,
13 (1), 32{44.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. In Proceedings of
the Ninth National Conference on Artificial Intelligence, pp. 634{639 Anaheim, CA.
Pednault, E. P. D. (1988). Synthesizing plans that contain actions with context-dependent
effects. Computational Intelligence, 4 (4), 356{372.
Penberthy, J. S., & Weld, D. (1992). UCPOP: A sound, complete, partial order planner for
ADL. In Proceedings of the Third International Conference on Knowledge Representation and Reasoning, pp. 103{114 Cambridge, MA.
261

fiPollack, Joslin, & Paolucci
Peot, M., & Smith, D. E. (1992). Conditional nonlinear planning. In Proceedings of the First
International Conference on AI Planning Systems (AIPS-92), pp. 189{197 College
Park, MD.
Peot, M., & Smith, D. E. (1993). Threat-removal strategies for partial-order planning. In
Proceedings of the Eleventh National Conference on Artificial Intelligence, pp. 492{499
Washington, D.C.
Pollack, M. E., & Ringuette, M. (1990). Introducing the Tileworld: Experimentally evaluating agent architectures. In Proceedings of the Eighth National Conference on Artificial
Intelligence, pp. 183{189 Boston, MA.
Russell, S., & Norvig, P. (1995). Artificial Intelligence: A Modern Approach. Prentice Hall,
Englewood Cliffs, NJ.
Russell, S. J. (1992). Ecient memory-bounded search algorithms. In Proceedings of the
Tenth European Conference on Artificial Intelligence, pp. 1{5.
Smith, D. E., & Peot, M. A. (1994). A note on the DMIN strategy. Unpublished manuscript.
Srinivasan, R., & Howe, A. E. (1995). Comparison of methods for improving search eciency
in a partial-order planner. In Proceedings of the 14th International Joint Conference
on Artificial Intelligence, pp. 1620{1626.
Tate, A., Drabble, B., & Dalton, J. (1994). Reasoning with constraints within O-plan2.
Tech. rep. ARPA-RL/O-Plan2/TP/6 V. 1, AIAI, Edinburgh.
Tsang, E. (1993). Foundations of Constraint Satisfaction. Academic Press.
Tsuneto, R., Erol, K., Hendler, J., & Nau, D. (1996). Commitment strategies in hierarchical task network planning. In Proceedings of the Thirteenth National Conference on
Artificial Intelligence (AAAI), pp. 526{542 Portland, OR.
Weld, D. S. (1994). An introduction to least commitment planning. AI Magazine, 15 (4),
27{61.
Wilkins, D. E. (1988). Practical Planning: Extending the Classical AI Paradigm. Morgan
Kaufmann, San Mateo, CA.
Wilkins, D. E., & Desimone, R. V. (1994). Applying an AI planner to military operations
planning. In Fox, M., & Zweben, M. (Eds.), Intelligent Scheduling, pp. 685{708.
Morgan Kaufmann Publishers, San Mateo, CA.
Williamson, M., & Hanks, S. (1996). Flaw selection strategies for value-directed planning. In
Proceedings of the Third International Conference on Artificial Intelligence Planning
Systems, pp. 237{244.

262

fiJournal of Artificial Intelligence Research 6 (1997) 111{145

Submitted 8/96; published 4/97

Lifeworld Analysis
Philip Agre

pagre@ucsd.edu

Ian Horswill

ian@ils.nwu.edu

Department of Communication 0503
University of California, San Diego
La Jolla, CA 92093, USA
Northwestern University Computer Science Department
1890 Maple Avenue
Evanston, IL 60201, USA

Abstract

We argue that the analysis of agent/environment interactions should be extended to
include the conventions and invariants maintained by agents throughout their activity. We
refer to this thicker notion of environment as a lifeworld and present a partial set of formal
tools for describing structures of lifeworlds and the ways in which they computationally
simplify activity. As one specific example, we apply the tools to the analysis of the Toast
system and show how versions of the system with very different control structures in fact
implement a common control structure together with different conventions for encoding
task state in the positions or states of objects in the environment.

1. Introduction
Biologists have long sought concepts to describe the ways in which organisms are adapted to
their environments. Social scientists have likewise sought concepts to describe the ways in
which people become acculturated participants in the social worlds around them. Yet it has
been dicult to approach these phenomena with the methods of computational modeling.
We can see at least two reasons for this diculty. The first is that the tradition of modeling
in artificial intelligence developed around a concern with cognition, that is, mental processes
understood to intervene between stimuli and responses in human beings. Although minority
traditions such as ecological psychology reacted against this approach to studying human
life, they have not been able to translate their concepts into computational mechanisms that
match the expressive power of symbolic programming. The second reason is more subtle:
if one conceives both organisms and their environments as spatially extended mechanisms
that can be explained according to the same principles then the boundary between them
(the surface of the body) is not particularly different from, or more interesting than, the
rest of the total organism-environment system. The challenge for computational modeling,
then, is to conceptualize agents' adaptations to their environments in ways that neither
treat agents as isolated black boxes or dissolve them into one big machine.
For these purposes, we find it useful to distinguish between two aspects of an agent's
involvement in its familiar environment: its embodiment and its embedding. \Embodiment"
pertains to an agent's life as a body: the finiteness of its resources, its limited perspective
on the world, the indexicality of its perceptions, its physical locality, its motility, and so
on. \Embedding" pertains to the agent's structural relationship to its world: its habitual
c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiAgre & Horswill
paths, its customary practices and how they fit in with the shapes and workings of things,
its connections to other agents, its position in a set of roles or a hierarchy, and so forth.
The concept of embedding, then, extends from more concrete kinds of locatedness in the
world (places, things, actions) to more abstract kinds of location (within social systems,
ecosystems, cultures, and so on). Embodiment and embedding are obviously interrelated,
and they each have powerful consequences both for agents' direct dealings with other agents
and for their solitary activities in the physical world. Our principal focus in this article is on
embedding, and particularly on the ways in which agents maintain relationships to objects
that are functionally significant for their tasks.
In this paper we develop some thoughts about embodiment and embedding as follows:

 Section 2 reviews the concept of the environment as it developed with the early work
of Newell and Simon.

 Section 3 introduces our own adaptation of the traditional idea, which we call life








worlds, and we sketch what is involved in lifeworld analysis.
Section 4 introduces informally the concept of factorization of lifeworlds; this refers
roughly to the structures of the lifeworld that permit agents' decisions to be made
independently of one another.
Section 5 defines the basics of our formal theory of lifeworld analysis, namely the
concepts of environments, actions, policies, factorization, and the reduction of one
environment to another. The purpose of this formalism is to characterize the kinds of
interactions that can arise between agents and their familiar lifeworlds.
Section 6 briey introduces the computer program we wrote to illustrate some of the
phenomena of lifeworlds.
Section 7 then applies our formalism to modeling the world in which our program
operates; it proceeds by modeling successively more complicated versions of this world.
Section 8 explains how our program keeps track of the objects in the world that
figure in its activities, and discusses the issues that arise when trying to model this
keeping-track in formal terms.
Section 9 sums up our formal work by explaining the precise relationship between the
program and the formal model of its world.
Section 10 then expands our theory of lifeworlds more informally by introducing the
concept of cognitive autopoiesis, which is the collection of means by which agents manipulate their surroundings to provide the conditions of their own cognitive processes;
we provide a taxonomy of these phenomena.
Section 11 concludes by suggesting some directions for future work.

2. The Concept of the Environment

Intuitively, the notion of \the environment" in AI and robotics refers to the relatively enduring and stable set of circumstances that surround some given individual. My environment is
probably not the same as yours, though they may be similar. On the other hand, although
my environment starts where I leave off (at my skin, perhaps), it has no clear ending-point.
Nor is it necessarily defined in terms of metric space; if physically distant circumstances
have consequences for my life (via the telephone, say) then they are properly regarded as
112

fiLifeworld Analysis
part of my environment as well. The environment is where agents live, and it determines the
effects of their actions. The environment is thus a matter of importance in computational
modeling; only if we know what an agent's environment is like can we determine if a given
pattern of behavior is adaptive. In particular we need a positive theory of the environment,
that is, some kind of principled characterization of those structures or dynamics or other
attributes of the environment in virtue of which adaptive behavior is adaptive.
Herbert Simon discussed the issue in his pre-AI work. His book Administrative Behavior (1947), for example, presents the inuential theory that later became known as limited
rationality. In contrast to the assumption of rational choice in classical economics, Simon
describes a range of cognitive limitations that make fully rational decision-making in organizations impracticable. Yet organizations thrive anyway, he argues, because they provide
each individual with a structured environment that ensures that their decisions are good
enough. The division of labor, for example, compensates for the individual's limited ability
to master a range of tasks. Structured ows of information, likewise, compensate for the
individual's limited ability to seek this information out and judge its relevance. Hierarchy
compensates for the individual's limited capacity to choose goals. And fixed procedures
compensate for individuals' limited capacity to construct procedures for themselves.
In comparison to Simon's early theory in Administrative Behavior, AI has downplayed
the distinction between agent and environment. In Newell and Simon's early work on
problem solving (1963), the environment is reduced to the discrete series of choices that it
presents in the course of solving a given problem. The phrase \task environment" came to
refer to the formal structure of the search space of choices and outcomes. This is clearly a
good way of modeling tasks such as logical theorem-proving and chess, in which the objects
being manipulated are purely formal. For tasks that involve activities in the physical world,
however, the picture is more complex. In such cases, the problem solving model analyzes the
world in a distinctive way. Their theory does not treat the world and the agent as separate
constructs. Instead, the world shows up, so to speak, phenomenologically: in terms of the
differences that make a difference for this agent, given its particular representations, actions,
and goals. Agents with different perceptual capabilities and action repertoires, for example,
will inhabit different task environments, even though their physical surroundings and goals
might be identical.
Newell and Simon's theory of the task environment, then, tends to blur the difference
between agent and environment. As a framework for analysis, we find the phenomenological
approach valuable, and we wish to adapt it to our own purposes. Unfortunately, Newell and
Simon carry this blurring into their theory of cognitive architecture. They are often unclear
whether problem solving is an activity that takes place wholly within the mind, or whether
it unfolds through the agent's potentially complicated interactions with the physical world.
This distinction does not arise in cases such as theorem-proving and chess, or in any other
domain whose workings are easily simulated through mental reasoning. But it is crucial
in any domain whose actions have uncertain outcomes. Even though we wish to retain
Newell and Simon's phenomenological approach to task analysis, therefore, we do not wish
to presuppose that our agents reason by conducting searches in problem spaces. Instead,
we wish to develop an analytical framework that can guide the design of a wide range of
agent architectures. In particular, we want an analytical framework that will help us design
the simplest possible architecture for any given task.
113

fiAgre & Horswill

3. Lifeworlds
We will use the term lifeworld to mean an environment described in terms of the customary
ways of structuring the activities that take place within it | the conventional uses of
tools and materials, the \loop invariants" that are maintained within it by conventional
activities, and so on. The term originally comes from phenomenological sociology (Schutz
& Luckmann, 1973), where it refers to the familiar world of everyday life, and specifically
to that world as described in the terms that make a difference for a given way of life. Cats
and people, for example, can be understood as inhabiting the same physical environment
but different lifeworlds. Kitchen cupboards, window sills, and the spaces underneath chairs
have different significances for cats and people, as do balls of yarn, upholstery, television
sets, and other cats. Similarly, a kitchen affords a different kind of lifeworld to a chef
than to a mechanic, though clearly these two lifeworlds may overlap in some ways as well.
A lifeworld, then, is not just a physical environment, but the patterned ways in which a
physical environment is functionally meaningful within some activity.
This idea is similar to Gibson's theory of perception (1986), but the two theories also
differ in important ways. Whereas Gibson believes that the perception of worldly affordances
is direct, we believe that the perceptual process can be explained in causal terms. Also,
whereas Gibson treated the categories of perception as essentially biological and innate, we
regard them as cultural and emergent.
In analyzing a lifeworld, one attempts to draw out the individual structures within it
that facilitate its customary activities. For example, lifeworlds typically contain artifacts
such as tools that have been specifically evolved to support those activities. These tools
are also arranged in the world in ways that simplify life and reduce the cognitive burden
on individuals: cups are typically found in cupboards, food in refrigerators and grocery
stores. No one needs to remember where butter is found in a specific grocery store because
butter in all grocery stores is found in a well-defined dairy section, usually along a wall,
which can be recognized from a distance; once the dairy section is in view, the butter will
be visible in a definite area. Artifacts are also designed to make their functional properties
perceptually obvious. Handles are perceptibly suited for picking up, knobs are perceptibly
suited for turning, forks are perceptibly suited for impaling things, and so on (Brady,
Agre, Braunegg, & Connell, 1984; Winston, Binford, Katz, & Lowry, 1983). Contrarily,
it can generally be assumed that artifacts that provide no readily perceptible grounds for
drawing functional distinctions are in fact interchangeable. Usually, when some functionally
significant property of an object is not obvious, the lifeworld provides some alternate way
of marking it. If you see a record player in my house, for example, then you will assume
that it is mine unless you have some specific reason not to. These aspects of lifeworlds
tend to make it easy to perform particular kinds of activities within them without having
to remember too many facts or reinvent the screwdriver from first principles.
Lifeworlds contain networks of interacting conventions and practices that simplify specific aspects of specific activities. The practices relieve agents of the burden of solving certain
problems on the spot and diffuse their solutions throughout the activity of the agent or of
many agents. For example, a hospital might try to get along without maintaining sterile
conditions. People always have germs, so technically they are always infected. The problem
is making sure that those infections never get out of control. The most direct solution would
114

fiLifeworld Analysis
be constantly to monitor patients, assess their degree of infection and treat them when it
becomes severe. Since this is undesirable for any number of reasons, a hospital instead tries
to prevent infections in patients by maintaining sterile conditions. They might do this, for
example, by looking for contaminated objects and surfaces and disinfecting them. Unfortunately, sterility is not a visible surface characteristic. Instead, hospitals solve the problem
by structuring space and activity. Different locations are kept more or less sterile depending
on their conventional uses: operating rooms are more sterile than hallway oors. Objects
that can generate germs (people) are washed, masked, and gloved. Critical instruments
that come in contact with them are specially sterilized after use. Tongue depressors are
assumed to be dirty when they are in the trash can (or biohazard bag) and clean when
they are wrapped in paper. All objects and surfaces are periodically disinfected regardless
of their level of contamination. These practices are maintained regardless of the immediate
need for them. If a hospital were (for some reason) to temporarily find itself without any
patients, its workers would not stop washing their hands or disinfecting the bathrooms.

4. Factorization of Lifeworlds

Simon, in Sciences of the Artificial (1970), argued that complex systems had to be \nearly
decomposable." His model for this was the rooms in a building, whose walls tend to minimize
the effects that activity in one room has upon activity in another. Sussman (1975), in
his analysis of block-stacking tasks, classified several types of \subgoal interactions" that
result from attempts to break tasks down into subtasks; one hopes that these tasks will be
decomposable, but bugs arise when they are not decomposable enough. One assumes that a
task is decomposable unless one has reason to believe otherwise. Sussman's research, and the
rich tradition of planning research that it helped inaugurate, concerned the dicult problem
of constructing plans in the presence of subgoal interactions. Our goal, complementary to
theirs, is to analyze the many ways in which tasks really are decomposable, and to derive the
broadest range of conditions under which moment-to-moment activity can proceed without
extensive analysis of potential interactions.
A non-pathological lifeworld will be structured in ways that limit or prevent interactions
among subtasks. Some of these structures might be taxonomized as follows:

 Activity partition. Most lifeworlds separate activities under discrete headings: sewing

is a distinct activity from bathing, gathering food is a separate activity from giving
birth, and so on. These distinctions provide the basis for reckoning \different activities" for the purposes of most of the rest of the partitions. The boundaries among
the various activities are often marked through some type of ritual.

 Spatial partition. Different things are often done in different places. Tasks may be

confined to the places where their associated tools or materials are stored, or where
suitable conditions or lighting or safety obtain. These places may even be close together, as when different recipes are prepared in different sections of countertop space
or different kinds of food are kept in different parts of one's plate, with boundary
regions perhaps employed to assemble forkfuls of neighboring foods. In general, activities are arranged in space, and decisions made in one place tend to have minimal
interaction with decisions made in other places. Of course spatial distance brings no
115

fiAgre & Horswill
absolute guarantees about functional independence (using up all the resources at one
location will prevent them from being carted to another location for another use later
on), so these are just general tendencies.

 Material partition. Different activities often involve different materials, so that decisions that affect the materials in one activity do not interact with decisions that affect
the materials of the other activity.

 Temporal partition. Different activities often take place at different times, thus lim-

iting the channels through which they might constrain one another. These times
might be standardized points during the cycle of the day or week, or their ordering
might be constrained by some kind of precondition that the first activity produces
and successive ones depend upon.

 Role partition. Simon pointed out that division of labor eases cognitive burdens. It
does this in part by supplying individuals with separate spheres in which to conduct
their respective activities.

 Background maintenance. Many activities have background conditions that are main-

tained without reference to specific goals. For example, one maintains stocks of supplies in the pantry, puts things back where they belong, and so forth. Hammond,
Converse, and Grass (1995) call some of these \stabilization." (See Section 5.) What
these practices stabilize are the relationships between an agent and the materials used
in its customary activities. They tend to ensure, for example, that one will encounter
one's hammer or the currently opened box of corn akes in definite sorts of recurring
situations. They thus reduce the complexity of life, and the variety of different hassles
that arise, by encouraging the rise of routine patterns and cycles of activity rather
than a constant stream of unique puzzles.

 Attributes of tools. Numerous properties of tools limit the interactions among separate

decisions. Virtually all tools are resettable, meaning that regardless of what one has
been doing with them, they can be restored to some normal state within which their
full range of functionalities is accessible. (This of course assumes that one has only
been using the tools in the customary ways and has not been breaking them.) Thus
the properties of the tool do not place any ordering constraints on the activities that
use it. Likewise, most tools are not committed to tasks over long periods. Once you
have turned a screw with a screwdriver, for example, the screwdriver does not stay
\stuck" to that screw for any long period. Thus it is not necessary to schedule the
use of a screwdriver unless several people wish to use it at once. Exceptions to this
general rule include bowls (whose ingredients must often sit waiting for future actions
or conditions, and which cannot contain anything else in the meantime), stove burners
(which sometimes must remain committed to heating particular dishes until they have
reached certain states and not before), and clamps (which must remain fastened until
the glue has dried or the sawing operations have been completed).

 Supplies of tools. These latter tools raise the spectre of generalized scheduling problems and the potential for deadlock among multiple activities, and such problems do
116

fiLifeworld Analysis
in fact sometimes arise when cooking for more people than the number to which a
given kitchen is adapted. Most of the time, though, one solves such problems not
through scheduling but simply through having enough of the tools that must remain
committed to particular purposes over a period of time. Lansky and Fogelsong (1987)
modeled the effects on search spaces of limited interactions between different cooks
using overlapping sets of tools.

 Warning signs. When things go wrong, unpleasant subgoal interactions can ensue.

To avoid such diculties, an individual, community, or species keeps track of warning
signs and cultivates the capacity to notice them; these warning signs include supplies
running low and funny smells. This is often done on a primitive associative level, as
when rats stay away from smells that were associated with stuff that made them sick
or people develop phobias about things that were present when they suffered traumas.
Communities often arrange for certain warning signs to become obtrusive, as when
kettles whistle or natural gas is mixed with another gas that has a distinctive smell.

 Simple impossibility. Sometimes things are just impossible, and obviously so, so that
it is not necessary to invest great effort in deciding not to do them.

 Monotonicity. Many actions or changes of state are irreversible. Irreversible changes
cause decisions to interact when certain things must be done before the change takes
place. But it also provides a structure for the decision process: the lifeworld needs to
make it evident what must be done before a given irreversible change occurs.

 Flow paths. Often a lifeworld will be arranged so that particular materials (parts on an

assembly line, paperwork in an organization, food on its way from refrigerator to stove
to table) follow definite paths. These paths then provide a great deal of structure for
decision-making. By inspecting various points along a path, for example, one can see
what needs to be done next. Or by determining where an object is, one can determine
what must be done to it and where it must be taken afterward. Some of these paths
are consciously mapped out and others are emergent properties of a set of customs.

 Cycles. Likewise, many lifeworlds involve stable cycles of activities, perhaps with

some of the cycles nested inside of others. The resulting rhythms are often expressed
in recurring combinations of materials, decisions, spatial arrangements, warning signs,
and so on.

 Externalized state. To computer people, \state" (used as a mass noun) means dis-

cernible differences in things that can be modified voluntarily, and that can be interpreted as functionally significant in some way. Early AI did not treat internal state
(memory) and external state (functionally significant mutable states of the world) as
importantly different, and it is often analytically convenient to treat them in a uniform
fashion. It is often advantageous to record state in the world, whether in the relative
locations of things and the persistent states (in the count noun sense) that they are
left in (Beach, 1988). For example, one need not remember whether the eggs have
been broken if that fact is readily perceptible, if one's attention will be drawn to it on
a suitable occasion, and if one understands its significance for the task. Likewise, one
117

fiAgre & Horswill
can save a great deal of memory by retrieving all of the ingredients for an evening's
recipes from the cupboards and placing them in a customary place on the shelf.
Lifeworlds, then, have a great deal of structure that permits decisions to be made independently of one another. The point is not that real lifeworlds permit anyone to live in a
100% \reactive" mode, without performing any significant computation, or even that this
would be desirable. The point, rather, is that the nontrivial cognition that people do perform takes place against a very considerable background of familiar and generally reliable
dynamic structure.
The factorability of lifeworlds helps particularly in understanding the activities of an
agent with a body. A great deal of focusing is inherent in embodiment. If you can only look
in one place at a time, or handle only one tool at a time, your activities will necessarily
be serial. Your attention will have a certain degree of hysteresis: having gotten to work
on one countertop or using one particular tool, for example, the most natural step is to
carry on with that same task. It is crucial, therefore, that different tasks be relatively
separate in their consequences, that the lifeworld provide clues when a change of task is
necessary, and that other functionally significant conditions can generally be detected using
general-purpose forms of vigilance such as occasionally looking around. Of course, certain
kinds of activities are more complex than this, and they require special-purpose strategies
that go beyond simple heuristic policies such as \find something that needs doing and do
it." The point is that these more complex activities with many interacting components are
rare, that they are generally conducted in specially designed or adapted lifeworlds, and that
most lifeworlds are structured to minimize the diculty of tasks rather than to increase it.
These various phenomena together formed the motivation for the concept of indexicalfunctional or deictic representation (Agre & Chapman, 1987; Agre, 1997). Embodied agents
are focused on one activity and one set of objects at a time; many of these objects are specifically adapted for that activity; their relevant states are generally readily perceptible; objects
which are not perceptibly different are generally interchangeable; and stabilization practices
help ensure that these objects are encountered in standardized ways. It thus makes sense,
for most purposes, to represent objects in generic ways through one's relationships to them.
The ashlight I keep in the car is the-ashlight-I-keep-in-the-car and not FLASHLIGHT-13.
I maintain a stable relationship to this ashlight by keeping it in a standard place, putting
it back there when I am done with it, using it only for its intended purposes, keeping its
batteries fresh, and so on. Its presence in the environment ensures that I have ready access
to light when my car breaks down at night, and therefore that I need not separately plan
for that contingency each time I drive. The conventional structures of my own activity
maintain the ashlight's presence as a \loop invariant." Both the presence of the ashlight
and the activities that ensure it are structures of my lifeworld.

5. Environments, Policies, and Reducibility

In this section, we will introduce our formalism. The purpose of the formalism is not directly
to specify the workings of the agent's cognitive machinery. Instead, its purpose is to construct \principled characterizations of interactions between agents and their environments
to guide explanation and design" (Agre, 1995). The formalism, in other words, describes
an agent's embodied activities in a particular environment. Having characterized the dy118

fiLifeworld Analysis
namics of those activities, it becomes possible to design suitable machinery. As a matter
of principle, we want to design the simplest possible machinery that is consistent with a
given pattern of interaction (Horswill, 1995). We therefore make no a priori commitments
about machinery. We do not favor any particular architecture until a particular activity has
been analyzed. Nor do we make any a priori commitments about matters such as analog
versus digital, \planning" versus \reaction," and so on. Our experience has been that real
lifeworlds and real activities incorporate a great deal of useful dynamic structure, and that
any effort we invest in studying that structure will be repaid in parsimonious theories about
machinery. But we intend our methods to be equally useful for investigating all types of
activity and designing all types of machinery that might be able to participate in them.
The concept of a lifeworld will not appear as a specific mathematical entity in our
formalism. The intuition, however, is this: while there is an objective material environment,
the agent does not directly deal with all of this environment's complexity. Instead it deals
with a functional environment that is projected from the material environment. That
projection is possible because of various conventions and invariants that are stably present
in the environment or actively maintained by the agent. The lifeworld should be understood
as this functional world together with the projection and the conventions that create it.
This section summarizes the formal model of environmental specialization given by Horswill
(1995); for proofs of the theorems, see the original paper. Subsequent sections will apply
and extend the model.
We will model environments as state machines and the behavior of agents as policies
mapping states to actions.
 An environment E is a pair (S; A) where S is its state-space and A its set of possible
actions.
 An action a: S ! S is a mapping from states to states.
 A policy p: S ! A is a mapping from states to actions to be taken. In this paper, the
states will only include facts about the physical environment, but it is a straightforward matter to include an agent's internal states as well (Horswill, 1995).
The combination of a policy with an environment creates a dynamic system: the environment's state is mapped by the policy to an action that maps the environment to a new state
and the whole process is repeated.
 A discrete control problem (DCP) is a pair (E; G) of an environment E and a goal G,
which is some subset of E 's state space.
 A policy solves the problem if the dynamic system it generates with the environment
eventually reaches a goal state.
 It solves the problem and halts if it remains within G once entering it.
For example, consider a robot moving along a corridor with n equally spaced oces
labeled 1, 2, 3, and so on. We can formalize this as the environment Zn = (f0; 1; :::; n ,
1g; fincn ; dec; ig), where i is the identity function, and where incn and dec map an integer
i to i + 1 and i , 1, respectively, with the proviso that dec(0) = 0 and incn(n , 1) = n , 1
119

fiAgre & Horswill

(dec,i)
(i,inc)

dec

dec

inc5
3

dec

inc5

4

(i,dec)

inc5
2

(1,1)
(i,inc)

1

(dec,i)

(i,dec)

inc5

inc5
0

(i,inc)

(0,1)

dec

(inc,i)
(i,inc)

(inc,i)

(0,0) (dec,i) (1,0)

dec

(dec,i)
(i,dec)

(inc,i)

(inc,i)
(i,dec)

Figure 1: The environment Z5 (left) and and the serial product of Z2 with itself, expressed
as graphs. Function products have been written as pairs, i.e. inci is written as
(inc; i). Identity actions (i and ii) have been left undrawn to reduce clutter.
(see Figure 1). Note that the effect of performing the identity action is to stay in the same
state.
We emphasize that a policy is a model of an agent's behavior, not of the causal/computational processes by which that behavior is exhibited. It specifies what an agent does in each
state, not how it does it. It is thus a theoretical construct, not a data structure or algorithm
in the agent's head. We will examine the implementation issues that surround policies in
section 8.

5.1 Product Environments

The majority of the formal sections of this paper will explore the phenomenon of factoring.
In particular, we will explore how policies for factorable environments can be composed
from policies for the factors. In state-machine models of environments, factorization is
the factorization of the state-space; the environment's state-space is a Cartesian product
of other state-spaces. The environment, as a whole, is \factorable" into its component
sub-environments. For example, the position of the king on a chess board has row and
column components. It can be thought of as the \product" of those components, each if
which is isomorphic to Z8 (since there are eight rows and eight columns). If we consider
an environment in which a car drives through an 88 grid of city blocks, we see that it too
is a kind of product of Z8 with itself. Both environments have 88 grids as state spaces,
but the car environment only allows one component to change at a time, whereas the king
environment allows both to change.
We must therefore distinguish different kinds of factorization. We will call the chessboard
case the parallel product of Z8 with itself, while the car case is its serial product. We will
focus on another kind of factorization later. Let the Cartesian product of two functions f
and g be fg: (a; b) 7! (f (a); g(b)), and let i be the identity function. For two environments
E1 = (S1; A1 ) and E2 = (S2 ; A2 ), we will define the parallel product to be

E1 k E2 = (S1S2; fa1a2 : a1 2 A1; a2 2 A2 g)
120

fiLifeworld Analysis
and the serial product to be
E1 *
) E2 = (S1S2; fa1i : a1 2 A1 g [ fia2 : a2 2 A2 g)
The products of DCPs are defined in the obvious way:
(E1 ; G1 ) k (E2 ; G2 ) = (E1 k E2 ; G1G2)
(E1 ; G1 ) *
) (E2 ; G2) = (E1 *
) E2 ; G1G2)
The state diagram for Z2 *
) Z2 is shown in Figure 1.
We will say that an environment or DCP is parallel (or serial) separable if it is isomorphic
to a product of environments or DCPs.
5.1.1 Solvability of Separable DCPs

The important property of separable DCPs is that their solutions can be constructed from
solutions to their components:
Lemma 1 Let p1 be a policy which solves D1 and halts from all states in some set of initial
states I1 , and let p2 be a policy which solves D2 and halts from all states in I2 . Then the
policy
p(x; y) = p1(x)p2(y)
solves D1 k D2 and halts from all states in I1I2 . (Note that here we are using the convention
of treating p, a function over pairs, as a function over two scalars.)
Lemma 2 Let p1 be a policy which solves D1 from all states in some set of initial states
I1, and let p2 be a policy which solves D2 from all states in I2 . Then any policy for which
p(x; y) = p1 (x)i or ip2(y)
and
y 2 G2; x 62 G1 ) p(x; y) = p1(x)i
x 2 G1; y 62 G2 ) p(x; y) = ip2(y)
will solve D1 *
) D2 and halt from all states in I1I2.
Note that the parallel and serial cases are different. One would expect the parallel case
to be easier to solve because the policy can perform actions on both state components
simultaneously. In fact it is more dicult because one is required to perform actions on both
simultaneously and this leaves the agent no way of preserving one solved subproblem while
solving another. Consider a \ip-op" environment F = (f0; 1g; fflipg) where flip(x) =
1 , x. F has the property that every state is accessible from every other state. F *
)F
also has this property. F k F , however, does not. F k F has only one action, which ips
both state components at once. Thus only two states are accessible from any given state
in F k F : the state itself and its ip. As with the king, the problem is fixed if we add the
identity action to F . Then it is possible to leave one component of the product intact, while
changing the other. The identity action, while sucient, is not necessary. A weaker, but
still unnecessary, condition is that F have some action that always maps goal states to goal
states.
121

fiAgre & Horswill

s'



s = (s' )

a'
a' (s' )
unreduced environment

a


a(s) = (a' (s' ))
reduced environment

Figure 2: A simple reduction from an environment E 0 to E . Here s and s0 are corresponding
states from the reduced and unreduced environments respectively and a and a0
are corresponding actions. A projection  is a simple reduction if it \commutes"
with actions, so that (a0 (s0 )) = a((s0 )), or alternatively,   a0 = a  . Thus
regardless of whether we take the projection before or after the action, we will
achieve the same result.

5.2 Reduction

Another important kind of structure is when one environment can be considered an abstraction of another (Newell, Shaw, & Simon, 1960; Sacerdoti, 1974; Knoblock, 1989). The
abstract environment retains the fundamental structure of the concrete environment but
removes unimportant distinctions among states. An abstract state corresponds to a set
of concrete states and abstract actions correspond to complicated sequences of concrete
actions.
We will say that a projection  from an environment E 0 to another environment E is a
mapping from the state space of E 0 to that of E . We will say that  is a simple reduction
of E 0 to E if for every action a of E , there is a corresponding action a0 of E 0 such that for
any state s0
(a0 (s0)) = a((s0 ))
or equivalently, that
  a0 = a  
where  is the function composition operator. We will say that a0 is a -implementation of
a and we will use A to denote the function mapping E -actions to their implementations
in E 0 .
It is possible to define a much more powerful notion of reduction in which implementations are allowed to be arbitrary policies. It requires a fair amount of additional machinery,
however, including the addition of state to the agent. Since simple reduction will suce for
our purposes, we will simply assert the following lemma, which is a direct consequence of
the more general reduction lemma (Horswill, 1995):
Lemma 3 Let  be a simple reduction from E 0 to some environment E and let (E 0 ; G0) be
a DCP. If a policy p solves (E; (G0 )), then
p = A  p  
122

fiLifeworld Analysis
solves (E 0 ; G0 ).

5.3 Related Work

Most formal models of environments use state-space descriptions of the environment, usually finite-state machines. Rosenschein and Kaelbling used finite state machines to represent
both agent and environment (1987, 1989, 1986). Their formalization allowed specialized
mechanisms to be directly synthesized from descriptions of desired behavior and a formalization of the behavior of the environment. The formalization was powerful enough to form
the basis of a programming language used to program a real robot. Later, Rosenschein developed a method for synthesizing automata whose internal states had provable correlations
to the state of the environment given a set of temporal logic assertions about the dynamics
of the environment. Donald and Jennings (1992) use a geometric, but similar, approach
for constructing virtual sensors. Lyons and Arbib (1989) model both organisms and robots
using process algebras, and Beer (1995) employs the formalisms of dynamic systems theory.
Wilson (1991) has specifically proposed the classification of simulated environments
based on the types of mechanisms which can operate successfully within them. Wilson
also used a finite state formalization of the environment. He divided environments into
three classes based on properties such as determinacy. Todd and Wilson (1993) and Todd
et al. (1994) taxonomized grid worlds in terms of the behaviors that were successful in
them. Littman (1993) used FSM models to classify environments for reinforcement learning
algorithms. Littman parameterized the complexity of RL agents in terms of the amount
of local storage they use and how far into the future the RL algorithm looks. He then
empirically classified environments by the the minimal parameters that still allowed an
optimal control policy to be learned.
There is also an extensive literature on discrete-event dynamic systems (Kosecka, 1992),
which also model the environment as a finite state machine, but which assume that transition
information (rather than state information) is visible to the agents.
An alternative to the state-machine formalism can be found in the work of Dixon (1991).
Dixon derives his semantics from first order logic, in which the world comes individuated into
objects and relations, rather than on the state-space methods used here. Dixon's \open"
approach also avoids the need to define the environment as a single mathematical structure.
Like this work, Dixon's work attempts to formally model the assumptions a system makes
about its environment. Dixon's interest, however, is on what an individual program means
rather than on comparing competing programs.

6. Toast

Toast (Agre & Horswill, 1992) is a program that simulates a short-order cook in a reasonably detailed simulation of a kitchen (see Figure 3). In Toast, the world consists of a

set of objects such as ovens, pans, cutting boards, globs of pancake batter, individual eggs,
and customers of the restaurant. Each object has a type (e.g., EGG) and all objects of a
given type have a common set of possible states and a common set of possible operations
that can be performed on them. An action involves a set of objects of given types. The
action can require that the objects be in specified states and it may change the states of
those objects, but no others. For example, the MIX operation would involve objects of type
123

fiAgre & Horswill
Time
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
30
31
36
46
56
57
58
59
60
69
79
89
90
91
92
93
94
95
96
97
98
99
100
101
102

Event
(BREAK-EGG EGG-11 BOWL-4) [Making omelette]
(ADD-EGG EGG-10 OMELETTE-BATTER-0)
(ADD-EGG EGG-9 OMELETTE-BATTER-0)
(BEAT OMELETTE-BATTER-0 WHISK)
(MOVE PAN-4 BURNER-4)
(MOVE BUTTER-PAT-15 PAN-4)
(MELT BURNER-4 PAN-4 BUTTER-PAT-15)
(MOVE SLICE-23 TOASTER) [Waiting for butter so making toast]
(START TOASTER SLICE-23)
(MOVE KNIFE-4 PLATE-1) [Waiting for toast so setting table]
*** Done with goal (KNIFE CLEAN PLATE-1) ***
(MOVE PLATE-1 KITCHEN-TABLE)
(MOVE FORK-4 PLATE-1)
*** Done with goal (FORK CLEAN PLATE-1) ***
(MOVE SPOON-4 PLATE-1)
Toaster pops!
(MOVE BUTTER-PAT-14 KNIFE-3) [Back to toast]
(BUTTER SLICE-23 KNIFE-3 BUTTER-PAT-14)
(POUR-OMELETTE-BATTER OMELETTE-BATTER-0 ...) [Butter melted so back to omelette]
(MOVE SLICE-23 PLATE-1) [Setting table]
*** Done with goal (SLICE BUTTERED PLATE-1) ***
*** Done with goal (SPOON CLEAN PLATE-1) ***
(POUR-FLOUR FLOUR BOWL-3) [Making pancake]
(ADD-SUGAR SUGAR PANCAKE-BATTER-0)
(ADD-BAKING-POWDER BAKING-POWDER PANCAKE-BATTER-0)
(FOLD OMELETTE-0 SPATULA-2) [Tending omelette]
(ADD-MILK MILK-DISPENSER PANCAKE-BATTER-0) [Back to pancakes]
(ADD-EGG EGG-8 PANCAKE-BATTER-0)
(MIX PANCAKE-BATTER-0 SPOON-3)
(MOVE PAN-3 BURNER-3)
(FLIP OMELETTE-0 SPATULA-2) [Tending omelette]
(MOVE BUTTER-PAT-13 PAN-3) [Pancake]
(MELT BURNER-3 PAN-3 BUTTER-PAT-13)
(MOVE OMELETTE-0 PLATE-1) [Finishing omelette]
*** Done with goal (OMELETTE COOKED PLATE-1) ***
(SPOON-BATTER PANCAKE-BATTER-0 PAN-3 BUTTER-PAT-13) [Pancake]
(FLIP PANCAKE-0 SPATULA-2)
(MOVE PANCAKE-0 PLATE-3)
*** Done with goal (PANCAKE COOKED PLATE-3) ***
(MOVE PLATE-3 KITCHEN-TABLE)
(MOVE PAN-2 BURNER-2) [Pancake 2]
(MOVE BUTTER-PAT-12 PAN-2)
(MELT BURNER-2 PAN-2 BUTTER-PAT-12)
(SPOON-BATTER PANCAKE-BATTER-0 PAN-2 BUTTER-PAT-12)
(FLIP PANCAKE-1 SPATULA-2)
(MOVE PANCAKE-1 PLATE-2)
*** Done with goal (PANCAKE COOKED PLATE-2) ***
(MOVE PLATE-2 KITCHEN-TABLE)
(CLEAN PAN-2) [Cleanup]
(CLEAN PAN-3)
(CLEAN SPOON-3)
(CLEAN SPATULA-2)
(CLEAN BOWL-3)
(CLEAN KNIFE-3)
(CLEAN PAN-4)
(CLEAN WHISK)
(CLEAN BOWL-4)
(TURN-OFF BURNER-2)
(TURN-OFF BURNER-3)
(TURN-OFF BURNER-4)

Figure 3: Sample run of the breakfast program. The agent was given the goals of making
an omelette, two pancakes, a slice of toast, and setting the table, then cleaning
up. Our comments appear in square brackets.
MIXING-BOWL, BATTER,

and SPOON. It would require that the spoon be in the CLEAN state
and its effects would be to put the batter in the MIXED state and the spoon in the DIRTY
state. Objects can perform actions, so the Toast agent, the oven, and the customers are
each modeled as objects that perform the actions of cooking, transferring heat, and making
orders, respectively.
Toast divides most of the objects in its world into two important classes (see Figure
4). Informally, tools are objects that (1) are not end products of cooking and (2) are easily
124

fiLifeworld Analysis
Material. Eggs. Fresh ! broken ! beaten ! cooked.
Material. Butter pat. Fresh ! melted.
Material. Milk supply. Non-empty ! empty.
Material. Pancake batter. Has-our ! has-sugar ! has-dry ! has-milk ! has-all ! mixed.
Material. Pancake. Cooking ! cooked-1-side ! ipped ! cooked ! burnt.
Material. Bread slice. Fresh ! toasted ! buttered.
Tools. Forks, spoons, knives, spatulas, whisks. Clean ! dirty, dirty ! clean.
Containers. Bowls, plates, pans, stove burners, countertop, toaster, bread bag.
Active objects. Agent, stove burners, toaster.

Figure 4: Some object types in the current system.
reset to their initial states. For example, knives and spoons are used and dirtied in the
process of cooking, but they are not end products of cooking and they are easily reset to
their clean state by washing. Materials are objects that are end products of cooking but
have state graphs that form linear chains. In other words, for any state of the material,
there is exactly one other state that it can be brought to and there is exactly one action that
can bring it there. For example, an egg being scrambled always goes through the series of
states UNBROKEN, BROKEN, BEATEN, COOKED. In the UNBROKEN state, the only action available
on an egg is BREAK, after which the only action available will be BEAT.
Toast is given a stock of each type of object. As it runs, the customers give it goals
(orders) to prepare specific dishes. The goal specifies a type of material (e.g., \EGG"). It
is satisfied by putting some object of that type into its finished state. Which egg object is
cooked does not matter. Toast manages a dynamic set of these goals and opportunistically
overlaps their preparation as processes finish and scarce resources, such as stove burners,
become free. Toast uses a surprisingly simple algorithm:
On each clock cycle of the simulator:
Choose a material already being cooked
Look up the action needed to advance it to the next state
If the action requires additional tools,
then choose objects of the proper types
If those objects are in their reset states
then perform the action
else choose one of the unreset tool objects
look up and perform its reset action

This algorithm is intentionally sketchy because we have implemented many versions of
it which we find intuitively similar, but which have very different control structures and
require very different correctness proofs. The task of the next section will be to draw out
their similarities and produce a coherent theory of them.
The Toast algorithm has two interesting features:

 Most of the algorithm proceeds by table-lookup.
 The algorithm is stateless: no internal plans or models are stored in the agent; all
information used to choose actions is stored in the world.
125

fiAgre & Horswill
Table lookup implies that the algorithm is fast and simple. Statelessness makes the algorithm simple as well, and relatively robust in the face of unexpected perturbations.

7. Modeling the Toast World

Why does Toast work? More specifically, what properties of its environment does it rely
upon to work? In general, our strategy is to identify a series of structures in the environment
that permit Toast's tasks to be factored, and then to define a series of reductions that
permit more complex versions of Toast's problem to be defined in terms of simpler ones.
We do not claim any vast generality for the Toast architecture; we simply observe that the
environmental regularities that Toast relies upon are common to many other environments,
and we suggest that our method in arguing for Toast's architecture seems likely to extend
to other types of structure in the environment. Although different versions of Toast rely
on different structures, we will show below that all the versions rely on:
1. The factorability of the environment into individual objects. Factoring allows us
to construct solutions to problems from solutions to subproblems for the individual
factors.
2. The special properties of the tool and material object classes.
3. The maintenance of invariants in the agent's own activity that introduce new structure
into the environment.
The formalization of the properties of tools and materials is simple. The precise formalization of factorability into objects, however, is surprisingly dicult because the environment is not directly factorable using the methods we have developed so far. We will solve
the problem by defining a new factoring technique called uniform reduction, in which the
environment is viewed as a collection of overlapping instances of schematic environments,
each containing the minimal set of objects necessary to perform the task. The agent solves
the task by choosing one of these instances and reducing the goal in the true environment
to the solution of that schematic instance. To do this, the agent must keep track of which
instance it is operating on as it goes along. This could be accomplished with internal memory, of course, but then the agent would need more and more memory as it performs more
and more tasks concurrently. We will show that by structuring its activity, the agent can
make this information manifest in the environment, thus \storing" the information in the
world.

7.1 Single-Material Worlds

We will start by defining the schematic environment for Toast. The environment has
exactly one material to be cooked and one of each tool needed to cook it. To simplify
further, we will start by ignoring even the tools. Then we will
1. Solve the no-tools case.
2. Reduce the self-resetting tools case to the no-tools case.
3. Reduce the general case to the self-resetting tools case.
126

fiLifeworld Analysis
7.1.1 Single-Material Worlds with No Tools

Since materials have linear chains as their state spaces, action in them is restricted, to say
the least. In the case of an egg, we might have the chain:
fresh break
! broken beat
! beaten heat
! cooked heat
! burnt
(We will assume that the identity, or \nop," action is always available in every state. This
is not a trivial assumption.) In any given state, only one non-trivial action can be executed,
so action selection for an agent is trivial. When solving a DCP involving a single-material
world one of the following must always hold:
 The current state is a goal state, so we need only execute the identity action.
 The current state is a pregoal state: some goal state is later in the chain than the
current state, so we can reach it by executing the unique action that brings us to the
next state in the chain.
 The current state is a postgoal state: all goal states are earlier in the chain, so the
problem is unsolvable.
All that really matters in single-material worlds, therefore, is how many states there are
and in which direction the goal lies relative to the current state. In a sense, there is only
really one single-material world, or rather one class of them, namely the chains Cn of given
length:
Cn = (f1; :::; ng; fincn ; ig)
(Note this is just the same as the environment Zn , but without the actions that move
backward along the chain.)
Proposition 1 All single-material worlds of n states are reducible to Cn
Proof: Let E = (S; A) be the single-material environment. Define : S ! f1; :::; ng by
letting (s) be s's position in E 's state chain, i.e. the first state maps to 1, the second to
2, etc. Let action(s) denote the unique action that can be performed in state s. Then
pincn (s) = (action(s))(s)
is a -implementation of incn and so E is reduced. 2
Just as there is only one real class of single-material worlds, there is only one real class
of policies for single-material DCPs:
(
s2G
pCn ;G(s) = i;inc ; ifotherwise
n
which clearly solves the DCP (Cn ; G) for any n and valid G.
Corollary 1 If a goal G is solvable in a single-material environment E with no tools, then
it is solved by the policy
(
s2G
pE;G(s) = i;(action(s))(s); ifotherwise
127

fiAgre & Horswill
7.1.2 Single-Material Worlds with Single-State Tools

Now suppose the world contains a material and a set of tools, but those tools always clean
or otherwise reset themselves after use. Self-resetting tools have only one state, and so they
are a trivial kind of environment. We define the \singleton" environment as the environment
with exactly one state:
S = (freadyg; fig)
All single-state environments are isomorphic to S , so we model an environment consisting
of a material M = (S; A) and a self-resetting tool as M k S . Its state space is simply
S  freadyg and its actions are just the set

fa0 : (sM ; ready) 7! (a(sM ); ready)ja 2 Ag
Each such action performs some action from M on the M -component of the product's state
and leaves the S component unchanged. By induction, we have that:

Proposition 2 Any environment M is isomorphic to M kS n .
And so single-state-tool worlds are trivially reducible to tool-free worlds.
7.1.3 Single-Material Worlds with General Tools

The general tool environment is identical to the single-state tool environment, except that
actions can change the states of tools in addition to the states of materials. We can solve the
general tool case using a solution to the single-state tool case by resetting tools whenever
they are dirtied.
The proof is simple, but requires that we formalize the notion of being a tool. Let E be
an environment with a state space of the form S1  S2  :::  Sn. Let a be an action of E
and Si be a component of its state space. We will say

 a is independent of Si if a never changes Si and it has the same result regardless of
the value of Si .

 a is focused on a component Si if it is independent of all other components.
 Si is a tool if it has some privileged value readyi 2 Si such that:
{ From any state (s1; :::; si ; :::; sn ) of E , we can reach the state (s1; :::; readyi ; :::; sn )

using only actions focused on Si .
{ For any action a, a is either independent of the Si, focused on Si, or else only
defined on states whose Si component is readyi .

Now we can prove the general tool case is reducible to the single-state tool case:

Lemma 4 Any environment with tool components can be reduced to one in which the tools
have been replaced by singletons. Specifically, let D = ((S; A); G) be a DCP and let readyT 2
T , and A0 = fa0 : (s; readyT ) 7! (a(s); t)ja 2 A; s 2 S; and t 2 T g. Then D0 = ((S  T; A0 [
At ); G  freadyT g) is reducible to D when T is a tool in D0.
128

fiLifeworld Analysis
Proof: Let pD be a solution (policy) for D. By the definition of a tool, there must be a
policy pT that will bring D0 from any state (s; t) to (s; readyt ) without changing the S
component. Let  be the projection from D0 to D given by

(

t = readyT
(s; t) = s;?; ifotherwise
For each a 2 A, we define the -implementation of a, pa by
( 0
t = readyT
pa (s; t) = ap ; ; ifotherwise
T
and so D0 is reducible to D. The general case of multiple tools follows from induction. 2

7.2 Multiple-Material Worlds with Single-Material Goals

To reprise: we want to factor the environment into its individual objects and then describe
Toast as a composite of techniques for operating on the individual factors. We cannot
properly define environments as Cartesian products of individual objects defined in isolation
because we have no way of expressing actions involving multiple objects. We can, however,
define a set of objects in the context of a minimal, schematic environment containing one
copy of each object. Having done so, we now want to recapture the notion of an environment
being some kind of product of objects of different types. We will do this by showing that an
environment with two eggs can be thought of as two overlapping copies of an environment
with one egg; the copies differ only in the choice of the egg.
We will treat environments as having state spaces formed as products of the state spaces
of their objects. A state of the environment is a tuple of the states of its objects. A binding
of the schematic environment to the real environment is a particular kind of projection from
the complex environment to the schematic, one which is also a reduction. If all reasonable
projections are valid bindings, then we will say the environment is uniformly reducible to
the schematic environment.
7.2.1 Bindings and Uniform Reducibility
Let E 0 and E be environments with state spaces built as Cartesian products of a family of

disjoint sets fSi g. The Si might represent the state spaces of object types like egg and fork.
E 0 and E would then each have state spaces make of up some number of copies of egg and
fork.
We will say that a projection  from E 0 to E is simple if every component of its result
is a component of its argument. That is

(s1; s2 ; s3; :::; sn ) = (si1 ; si2 ; :::; sim )
for some i1 ; :::; im in [1; n]. Thus  takes a E 0 -state, s0 , probably throws away some of its
components, and possibly rearranges the rest to form a new tuple. For example,  might

single out a particular egg's state and/or a particular fork's state and throw the other state
components away. When a projection is simple, we can define a kind of inverse for it,
129

fiAgre & Horswill

schematic world

multiple-object world

the-egg

egg0

the-fork

egg1

the-spatula

egg2

the-pan

egg3
egg4
fork0
fork1
fork2
spatula0
spatula1
pan0
pan1

Figure 5: A binding (solid vectors) and an alternate binding (dashed).
which we will call its back-projection. We will define the back-projection, , (s; s0 ), of  to
be the function whose result is s0 with those components that  keeps replaced by their
corresponding components from s. For example, if  is defined by
(s01 ; s02; s03 ) = (s03 ; s02)
then its back-projection would be given by:
, ((sa; sb ); (s01 ; s02; s03 )) = (s01; sb ; sa)
We will say that a simple projection is a binding of E to E 0 if it is also a simple reduction
of E 0 to E (see Figure 5).
Lemma 5 Let  be a binding of E to E 0 . Then A is given by
A (a) = a ; where a (s0) = ,(a((s0 )); s0 )
That is, the implementation of an E -action is simply 's back-projection composed with that
action and .
The proof follows from the definitions of simple projection and back-projection. We will
say that E 0 is uniformly reducible to E if every simple projection from E 0 to E is a binding.
7.2.2 Existential Goals
Toast is given the goal of putting some instance of a given material in its finished state.

We will call this an existential goal because it is satisfied by exactly those environment
states in which there exists an object of a specified type in a specified state. Let (E; G) be
a DCP and let E 0 be uniformly reducible to E . We define the existential goal 9E;E G of G
in E 0 to be the set of states in E 0 that project under some binding to a goal state in (E; G):
[
,1(G)
9E;E G =
0

0

 a binding of E to E

130

0

fiLifeworld Analysis
where ,1 (G) = fs0 : (s0 ) 2 Gg is the set of states that map to goal states under . Given
a solution to a schematic goal in a schematic environment, we can easily construct any
number of solutions to the existential goal:

Lemma 6 If policy p is a solution for the problem (E; G) from initial states I , and  is a
binding from E 0 to E , then
p = A  p  
is a solution for (E 0 ; 9E;E G) from initial states ,1 (I ), where A is the function mapping
actions in E to their corresponding actions under  in E 0 .
0

The Toast algorithm implements a policy which is a composition of a schematic solution
and a binding that maps it onto the real world. Consider the problem of cooking an egg.
The schematic solution might be:

break the-egg into the-pan
beat the-egg in the-pan using the-whisk
heat the-egg in the-pan
here the boldface verbs break, beat, and heat name actions. The italicized expressions the-

egg and the-pan name the objects (state components) that they affect in the simplified world.
The binding then determines objects in the real world to which those state components
correspond. Given a binding, the main control structure need only remember the sequence
break, beat, heat. Each of these may have preconditions on the states of the tools (i.e. the
whisk needs to be clean), but they can be handled by reduction given policies for resetting
the tools.
7.2.3 Binding Maps

Given the basic policy for cooking a single egg with a single pan and whisk, we can construct
a policy to achieve the goal by composing the basic policy with a binding. This policy will
solve the goal from any state in which the bound material is in a non-postgoal state. For a
policy to solve the goal from any solvable state, it must be able to change bindings at run
time. We will call a function from states to bindings a binding map.
One simple policy for choosing bindings is to impose some a priori ordering on the
objects and always use the first acceptable object in the ordering. The ordering might be
random, or it might correspond to order imposed by a visual search mechanism. From a
formal standpoint, the ordering does not matter, so we can, without loss of generality, use
the left-to-right order of state components in the environment's state tuple. Let M0 be
some binding map that always chooses the leftmost pregoal material and uses some fixed
mapping for the tools (we do not care what). This mapping allows us to construct a true
solution, and one that requires no internal state in the agent:

Proposition 3 The policy
pM0 (s) = (AM0(s)  p  (M0 (s)))(s)
is a solution from any state for which M0 is defined.
131

fiAgre & Horswill
Proof: By assumption, M0 is defined in the initial state. The environment must then map
to a solvable state under M0 in the initial state. Since p is, by assumption, a solution for
the problem in E , pM0 must solve the problem in E 0 unless M0 changes value before the
pM0 can solve the problem. Suppose it does. Then the environment must go from a state
s00, in which some state component of E 0 is the leftmost pregoal material, to a state s01, in
which some other component is the leftmost pregoal material. This can only happen if (a)
the leftmost pregoal material in s00 is changed to be in a goal state in s01 or (b) some other
component that was not pregoal in s00 becomes pregoal in s00 . Case (b) is impossible and
case (a) implies that s01 is itself a goal state. Thus pM0 must be a solution. 2

7.3 Multiple Goals: Metabolism

Thus far, we have not considered what happens once a policy achieves its goal. Since agents
rarely set out to achieve a goal and die, we now want to consider how to account for extended
activity involving many goals.
One important class of extended activities is when an agent transforms a whole class of
identical objects. We will call this metabolizing the class. Metabolism can be useful or it
can make extra work: cooking 100 eggs is useful, at least if you are feeding a lot of people;
dirtying 100 forks, however, probably means you have to wash them all.
Whether a policy metabolizes an object class depends in large part on the binding map
it uses. The policy pM0 metabolizes its materials because the material being worked on
ceases to be the leftmost pregoal material as soon as it arrives in a goal state. When this
happens, M0 changes bindings and the agent starts to work on a different object. Policy p
never actually sees a material in a goal state. Of course, the property of being \leftmost"
is an artifact of our formalism. What matters to the property of metabolism is simply
that the binding map implement some ordering on the instances of the material and always
choose the minimum under that ordering of the objects that are in pre-goal states. Such
an ordering might be implemented by the agent visually scanning its work surface for an
uncooked egg, but always scanning left-to-right and top-to-bottom. We will return to these
issues in section 8.
Other binding maps lead to other kinds of behavior, some of which are pathological. If
the binding map always chooses the same binding, then metabolism ceases. If the binding
map always chooses uncooked eggs but doesn't impose any ordering on them, it might start
cooking an infinite number of eggs without ever actually finishing any one of them.
Metabolism is also an issue for tool use. To metabolize its materials, pM0 must repeatedly
reset its tools. An alternate policy is to metabolize the tools too. Let us define M1 to be
the binding map that uses not only the leftmost pregoal material but also the leftmost reset
tools. Then clearly,
pM1 (s) = (AM1(s)  p  (M1 (s)))(s)
is a solution from any state for which M1 is defined. This policy treats tools as disposable.
So long as there is an infinite supply of fresh tools, p will see a succession of states in which
tools are in their reset states. It will never need to execute a resetting action and so the
environment is effectively a single-state-tool environment. Thus the reduction of section
7.1.3 is unnecessary.
132

fiLifeworld Analysis

7.4 Multiple Goals: Interleaved Execution

Metabolism involves performing the same transformation uniformly to instances of the
same type of object: cooking all the eggs, or cleaning/dirtying all the forks. Often times,
however, an agent will work toward different kinds of goals at once. This can often be
done by interleaving the actions from solutions to the individual goals. We will say that
an interleaving I is a function that returns one or the other of its first two arguments,
depending on a third state argument:

I (s; p1 ; p2 ) 2 fp1 ; p2g; for all s
When the last two arguments of I are policies, the result is itself a policy, so we will define
the notation:
Ip1;p2 (s) = (I (s; p1 ; p2 ))(s)
If we wanted to simultaneously make toast and cook an egg, then a good interleaving of
a toast-making policy and an egg-cooking policy would be one that chose the egg-making
policy whenever the egg had finished its current cooking step (and so was ready to be
ipped or removed from the pan) and chose the toast-making policy when the egg was busy
cooking. A bad interleaving would be one that always chose the toast-making policy.
An interleaving I is fair for p1 and p2 if starting from any state, Ip1 ;p2 will after some
finite number of steps have executed both p1 and p2 at least once. Finally, we will say
that two bindings are independent if they map disjoint sets of components to their images.
Binding independence is a special case of subgoal independence: two policies can't possibly
interfere if they alter distinct state components. Fairness and binding independence are
sucient conditions for an interleaving to solve a conjunctive goal:

Lemma 7 Let p1 = A1  p01  1 and p2 = A2  p02  2 be policies that solve the goals G1

and G2, respectively, and halt. If 1 and 2 are independent and I is a fair interleaving for
p1 and p2 then Ip1;p2 solves G1 \ G2 and halts.
Proof: Since I is a fair interleaving, each of the two policies will be executed in finite time,
regardless of starting state. By induction, for any n, there is a number of steps after which
I is guaranteed to have executed at least n steps of each policy.
The policy p1 is the composition of a policy p01 for a state space S1 with a binding. If
p1 solves G1 and halts, then it must do so by having p01 solve (G1 ) and halt in some finite
number of steps n. During execution, the environment goes through a series of states

s0; s1; :::; sn
which project under 1 to a series of states

s00; s01; :::; s0n
we claim that any execution of the interleaving Ip1 ;p2 must bring the environment through
a sequence of states that project under 1 to
(s00 )+ ; (s01 )+ ; :::; (s0n )+ ; :::
133

fiAgre & Horswill
that is, a string of states in which s00 appears at least once, then s01 , appears at least once,
and so on. The only state transitions that appear are from some s0i to itself or to s0i+1 .
Suppose it were otherwise. Then there must be a point at which this series is broken:
(s00 )+ ; (s01 )+ ; :::; (s0i )+ ; s
where s is neither s0i nor s0i+1 . We have two cases. Case 1: p1 executed the transition.
Then we have that p01 (s0i ) = s 6= s0i+1 , a contradiction. Case 2: p2 executed the transition.
Then p2 has changed one of the state components mapped by 1 and so 2 and 1 are not
independent, a contradiction. Thus the interleaving solves G1 . By the same reasoning, it
must halt in G1 , since p1 halts in G1 . Also by the same reasoning, it must solve G2 and
halt, and hence, must solve the intersection and halt. 2
A useful corollary to this is that when the same policy is applied under two independent
bindings, the bindings can be safely interleaved, that is, interleaving commutes with binding:

Corollary 2 If p1 = A1  p  1 and p2 = A2  p  2 be policies that solve the goals G1 and
G2, respectively, and halt, and I is a fair interleaving for p1 and p2, then AI1;2  p  I1;2
solves G1 \ G2 and halts.

8. Implementing Policies and Bindings

We have modeled Toast's behavior as a composition of various bindings and interleavings
with a basic policy for a schematic environment. In the case of Toast, the basic policy
is simple enough to be implemented by table-lookup. The hard part is implementing the
bindings and interleavings given realistic limitations on short-term memory and perceptual
bandwidth.
One approach would be to assume a relatively complete representation of the world.
Each egg would be represented by a logical constant and its state would be represented
by a set of propositions involving that constant. A binding would be implemented as a
frame structure or a set of variables that point at the logical constants. The problem is
that this approach presupposes the underlying perceptual and motor systems maintain a
correspondence between logical constants and eggs in the world. When one of the eggs
changes, the visual system has to know to be looking at it and to update the assertions
about the egg in the model.
This is not an assumption to be taken lightly. The capacity of the human perceptual
system to keep track of objects in the world is extremely limited. Ballard et al. (1995)found
that their experimental subjects adopt strategies that minimized the amount of world state
they needed to track internally, preferring to rescan the environment when information is
needed rather than memorize it in advance. The environment could even be modified during
saccadic eye movements without the subjects noticing.
An alternative is to treat the limitations of the body, its locality in space, and its limited
attentional and motor resources as a resource for implementing bindings directly. A person
can visually focus on one object, stand in one place, and grasp at most a few objects at
any one time. The orientation of the body's parts relative to the environment can be used
to encode the selection of objects being operated on at the moment. In other words, it can
134

fiLifeworld Analysis
implement a binding. Actions of the body, gaze shifts, and movements to new places can
be used to shift that binding.
Another alternative is to use the states and relationships of objects in the world to keep
track of bindings. An egg is being cooked if it is in the frying pan. A fork is available for
use if it is in the drawer, but not if it is in the sink waiting to be washed.
In this section, we will model the use of the body and conventions to implement bindings and interleavings. To simplify the presentation and to be concrete, we will focus on
materials, particularly eggs.

8.1 Binding, Deixis, and Gaze

To a first approximation, people can only visually recognize objects at which they are
directly looking. People achieve the illusion of direct access to arbitrary objects by rapidly
changing their gaze direction. Thus in addition to the normal state of the environment,
our lived world contains an additional state component, our gaze direction. Since we can
normally change our gaze direction without changing the world, and vice versa, our lived
world E 0 can be separated into a parallel product of the objective environment and our gaze
direction:
E0 = E k D
Our access to this world is through our gaze, which allows us to focus in on one particular
object at a time. Our gaze implements a binding, or more precisely, a binding map, since it
depends on the direction of gaze. If we model gaze direction as a number indicating which
object is presently foveated, we have that:
gaze(s1 ; s2; :::; sn ; d) = sd
A person could implement a single-object binding just by fixating the object they wish to
bind. First they would set the D component to some egg, and then use D as their binding.
Since D is really a binding map, however, rather than a true binding, the agent must
pervasively structure its activity so as to ensure that its gaze need never be redirected.

8.2 Binding and Convention

In general, agents must maintain bindings through some sort of convention, whether it is the
structuring of their internal memory, as in the case of a problem solver, or the structuring
of their activity. In the case of gaze above, the agent maintains the binding through a
convention about the spatial relation between its eye and the object it is binding. All
versions of Toast to date have maintained bindings using conventions about (simulated)
spatial arrangement or the states of objects.
One reason Toast cannot rely solely on gaze binding is that the technique breaks down
when binding multiple objects. The agent must continually move its gaze among the objects
of interest and so some additional convention must be introduced to ensure that when its
gaze leaves the egg and later returns, it always returns to the same egg. (This assumes, of
course, that Toast must return to the same egg. In some tasks it may suce for Toast
to return to some functionally equivalent egg. If it is preparing three fried eggs and its
attention is distracted while preparing to break the second one, it is alright if its attention
returns to the third egg, so long as it gets back to the second egg eventually.)
135

fiAgre & Horswill
State conventions

The original version of Toast used the convention eggs were bound to a cooking task
iff they were not in their starting (unbroken) state. Eggs were therefore bound using the
binding map

Toast (s) = the state of the unique egg in s that is in an unbroken state
which the agent can implement by first visually searching for an unbroken egg, and then
using gaze . By corollary 2, the interleaving of the cooking of multiple eggs can be accomplished by interleaving the bindings of the eggs. For example, we might assume that the
visual system searched non-deterministically or in a round-robin fashion for eggs. Any fair
interleaving will suce.
Spatial conventions

Later on in our development of Toast, we found it useful to adopt the convention that
eggs were bound to a cooking task iff they were located in a designated workspace. Cooking
eggs are on the counter or in the frying pan, while idle eggs are in the refrigerator. This
convention lets the agent use space as an external memory for binding information. To bind
the egg, the agent faces the workspace and performs visual search for an egg. Any egg it
finds will be an egg being cooked, since idle eggs will be out of view.
This still leaves open the issue of fairness. An extreme but elegant solution to the fairness
problem is to use multiple workspaces and employ the convention that each workspace
defines a unique binding. To cook two eggs, the agent just works on cooking whatever egg
is in front of it, but it spins in place so that it alternates between workspaces.
Formally, the environment then consists of two copies of the workspace and the objects
therein plus an extra state component that determines which workspace the agent faces.
The agent's perceptual system implements a binding map in which one or the other of
the two workspaces is bound depending on the agent's orientation. Given a policy for
cooking one egg in one workspace, we can construct a policy for cooking two eggs in two by
interleaving the policy with a \ipping" operation that switches the workspaces:

Proposition 4 Let E = (S; A) be an environment, p be a policy that solves some goal G

in E and halts, and let D be an environment with two states, 0 and 1, and two actions, i
(the identity) and flip which moves the environment into the opposite state from its present
state. Consider the product environment:

E0 = E *
)E *
)D
and the binding map from E 0 to E :

MD (s0 ; s1; d) = sd
Any fair interleaving of the policies:

pMD = AMD  p  MD
136

fiLifeworld Analysis

the real world
idealization

functionally equivalent objects
least reset
binding map

binding maps
and interleavings

general tools
resetting policies

self-cleaning tools
isomorphism

single object
isomorphism

canonical chain

Figure 6: Various alternative reductions used in Toast.
and

pflip(s0; s1 ; d) = i  flip

is a solution to the problem (E 0 ; (G  G  f0; 1g)).
Proof: Consider the bindings 0 : (s0 ; s1 ; d) ! s0 and 1 : (s0 ; s1 ; d) ! s1 , and let p0 =
A0  p  0 and p1 = A1  p  1. Since the binding map MD alternates between the
bindings 0 and 1 , any fair interleaving of pMD with pflip is equivalent to some interleaving
of p0 , p1 and pflip . We would like to show that this interleaving is also fair, that is, that
each of p0 and p1 will get run in finite time. We can see this from the fact that with
each execution of pflip switches MD from one binding to another. An objection is that this
leaves open the possibility that that pflip will always get run twice in a row, thus returning
the environment to its original state and so preventing MD from switching bindings. This
cannot occur, however, since it would introduce a loop, causing the interleaving to run pflip
forever, never running pMD , and so violating the assumption of fairness of the interleaving
of pMD and pflip. Thus the interleaving of p0 , p1 and pflip must be fair. Now note that
p0 solves the goal G  S  f0; 1g and halts, p1 solves the goal S  G  f0; 1g and halts,
and pflip solves the goal G  G f0; 1g and halts. Thus by lemma 7, the interleaving solves
the intersection of these goals, which is G  G  f0; 1g. 2
137

fiAgre & Horswill

9. Reductions and the Structure of Toast
We have shown how the cooking problem can be solved by a series of reductions and
conventions. Binding allows the reduction of the problem to a schematic world in which
action is greatly restricted and so action selection is greatly simplified. This world can be
further reduced, given algorithms for resetting tools, to a world in which tools are always
reset. This world, in turn, is equivalent to a world in which there is only one object, the
material being cooked, and only one action can be taken at any given time. Such actions
can be found by table lookup.
Multiple materials can be cooked by interleaving the execution of processes for cooking
the individual materials. Interleaving the processes is equivalent, however, to interleaving
the bindings, so the schematic-world algorithm need not even be aware that it is pursuing
multiple goals. If tool bindings are continuously changed as tools are dirtied then tools are
effectively disposable, tools effectively have only a single state, and the separate reduction
from general tools to single-state tools is unnecessary. Material bindings can be maintained
by any number of conventions involving the states and/or positions of objects.
In short, we can describe a Toast algorithm as a path through a network of possible
simplifications of the problem (see Figure 6) in which every path from the actual world
to the idealized single-object world defines a possible (and correct) version of the Toast
algorithm.

10. Cognitive Autopoiesis
In formalizing our ideas about binding and gaze, we have been moving toward a theory of
intentionality that depends on the agent's embedding in its world, rather than solely upon
its internal models of that world. An agent can keep track of particular objects in terms
of their functional significance { the roles that they play in the ongoing activity. And it
can keep track of the tools and materials associated with different tasks by keeping them
in different locations, for example different regions of a countertop. So far, however, our
ideas on the subject have been limited to very simple cases, for example an agent switching
its visual focus back and forth between two objects. To model the more complex patterns
that are found in everyday life, we need a much better theory of the world in which we
are embedded. This theory is partially a matter of biology and physics, of course, but it
is also a matter of cultural practices for organizing activities in space. In this section, we
would like to sketch a more general theory of these matters using the concept of \cognitive
autopoiesis."
For Maturana and Varela (1988), autopoiesis refers to the processes by which organisms
act on their environments in order to provide the conditions for their own continued functioning. Cognitive autopoiesis refers to the active means by which agents structure their
environments in order to provide the conditions for the own cognitive activities. These
include most basically the means by which agents provide for the factorability of environments: engaging in customary activities, using the customary tools and materials for them,
partitioning the activities in the customary ways, and so on. But it also includes a range
of more subtle phenomena. Kirsh (1995), for example, has drawn the useful distinction
between actions that aim at achieving functional goals (beating eggs, sweeping oors) and
138

fiLifeworld Analysis
actions that aim at facilitating cognition (setting out the right number of eggs at the beginning, opening the curtains so that dust will be more visible). Actions can, of course,
serve both purposes, for example when one chooses to boil water in a kettle rather than a
saucepan: each strategy achieves the result, but the latter will also provide a sign that it
is possible to take the next action, for example preparing tea. Stabilization actions (Hammond et al., 1995) also provide the cognitive conditions for other actions. One might, for
example, develop the habit of leaving items by the door the moment one realizes that they
need to be taken in to work.
These phenomena help in understanding what is inadequate about the concept of \the
environment." If one conceptualizes \the environment" as a monolithic whole, perhaps the
way it looks when viewed from an airplane, or else the way it looks when understood through
the peephole of a momentary vector of sense-perceptions, it begins to seem arbitrary, chaotic,
or hostile. In a certain sense it seems static, as if it has an anatomy but no physiology.
But in fact the phenomena of cognitive autopoiesis reveal that the lifeworld has a great
deal of living structure, and that this structure is actively maintained by agents while also
providing crucial preconditions for their own cognition. Indeed it is hard to draw a clear line
around an agent's cognition; if we trace the sequence of causal events that led a given agent
to pour a pitcher of milk on a particular moment, this sequence will lead back and forth
between the agent and its customary surroundings. It is almost as if these surroundings
were an extension of one's mind.
Cognitive autopoiesis is a complex and multifaceted phenomenon and no single theory
will suce to explain it. One useful way to think about cognitive autopoiesis is spatially,
in terms of a series of buffer zones between the embodied agent and the putative dangers
and complexities of \the environment." For people whose lives are similar to our own, these
buffer zones can be conveniently sorted under six headings:

 The body itself: its posture, its markings, things that might be attached to it or hung

from it, prostheses, artificial markings, the things one is holding in one's hands, and
so on. All of these things can serve as forms of memory, for example as a way to
remember what activity one was in the middle of before some momentary distraction.
The body's motility also makes possible a wide range of voluntary reconfigurations
of one's physical relationship to things, for example to get a better view or better
leverage.

 Clothing, including pockets, purses, money belts, hats, and so on. Everyone carries
around various objects in ways that draw on customary practices and artifacts (cash
in wallets, keys in pockets, watch on wrist, etc) while configuring these things in an
evolving personal way (keys in left pocket and money in right, tissues in the hip pocket
of one's coat, spare change in the outer ap of the backpack, and so on).

 Temporary workspaces that one occupies to perform a particular activity over a bound-

ed period. In repairing a bicycle, for example, one might spread tools and bicycle
parts about on the oor in patterns that have a cognitive significance in relationship
to one's own body and cognitive and other states (Chapman & Agre, 1986). One is
not claiming this space as a permanent colony (it might be located on a patio in a
139

fiAgre & Horswill
public park, for example), but one does lay claim to the space long enough to perform
a customarily bounded task.

 One's own private spaces: home, desk, oce, car, trunks of stuff kept in someone else's

attic, and so forth. These spaces serve numerous functions, of course, but among these
are the cognitive functions of providing stable locations over long periods of time for
tools and materials, storage places for stuff that needs to be kept in adequate supply,
practices for regulating other people's access to the stuff, and so on. These stable
conditions are actively maintained and provide the background for a wide variety of
more transient activities.

 Spaces that are shared with other people within stable, time-extended relationships.
These spaces include living rooms, kitchens, shared oce spaces, and so forth. The
line between the private and shared spaces clearly depends on the particular culture
and set of relationships, and the distinction might not be clear. The point is that
the cognitive functions of the spaces are maintained through shared practices such as
letting someone know when you borrow their stuff.

 Public spaces and the whole range of customary artifacts and practices that regu-

late activities in them. Public spaces offer fewer guarantees than private and shared
spaces, but they do include a wide variety of supports to cognition, including signs
and architectural conventions. It is also possible to use one's body and clothing to
carry artifacts that provide cognitive support for dealing with public spaces.

These buffer zones do not always offer perfect protection from harm or complete support
for the pursuit of goals. Shared and public spaces can be sites of conict, for example,
and these conicts can include involuntary disruption or destruction of one's body and the
other buffer zones that are customarily under one's own private control. A serious theory
of activity must include an account of these phenomena as well, which are usually just as
orderly in their own way as anything else.
In any event, the nested buffer zones of ordinary life participate in a large metabolism
that continually interweaves cognitive and functional purposes. Among these purposes is
learning. Just as the adaptation of body parts and tools to customary activities helps channel action in customary directions, so does the existing background of objects, spaces, and
practices help channel the actions of children and other newcomers in customary directions
on a larger scale. Caretakers regularly construct customized types of buffer zones around
the young, for example, so that it is dicult or impossible for them to get into anything
that could cause harm. The lifeworld of a child, for example, differs from that of an adult
who can reach up to the cookie jar and into the locked cupboard where the roach spray is
kept. A growing literature has investigated the processes of cognitive apprenticeship (Rogoff, 1990), situated learning (Lave & Wenger, 1991), distributed cognition (Hutchins, 1995;
Salomon, 1993), and shared construction of activities (Grin & Cole, 1989) that go on in
these systematically restrictive and supportive lifeworlds.
140

fiLifeworld Analysis

11. Conclusion

In this paper we have explored some of the ways in which the structure of the lifeworld
supports agents' cognition, and we have suggested how this analysis might be expanded to
cover a wider range of phenomena. Much work obviously remains to be done. Perhaps the
most significant part of this work concerns a fundamental assumption of lifeworld analysis:
that people use objects in customary ways. This is a plausible enough first approximation,
but it is not always true. Faced with a diculty that goes beyond the capacities of the
usual practices and the artifacts that are readily available, people frequently improvise.
The handle of a spoon might be used to pry open a lid, a pen might be used to fish acorns
out of an exhaust duct, a book might be used to provide backing for a sheet of paper one is
writing on, or a protruding section of a car's bumper might be bent straight by deliberately
driving the car into a concrete wall. In these cases the underlying physical affordances of
an object \show through" beyond their ready-to-hand appropriation in routine patterns
of interaction. These underlying affordances can also show through in situations of breakdown, for example when a tool breaks or proves inadequate to a job. In such cases, people
confer improvised meanings upon artifacts. Such phenomena are particularly important
in conversation, in which each utterance is interpreted in the context created by previous
utterances, while simultaneously helping to create the context for interpretation of successive utterances as well (Edwards & Mercer, 1987; Atkinson & Heritage, 1984). The point
is not that the lifeworld does not exist, but rather that it is something actively created as
well as something adapted to through socialization. One challenge for future research is to
learn how computational methods might help in modeling such phenomena|and how such
phenomena might help us to rethink basic ideas about computation.

Acknowledgements

We appreciate the detailed comments of the referees. This work was funded in part by
the National Science Foundation under grant number IRI{9625041. The Institute for the
Learning Sciences was established in 1989 with the support of Anderson Consulting, part
of the Arthur Anderson Worldwide Organization.

Glossary of Terms

Binding. A simple projection (mapping between state-space components of two environ-

ments) that acts as a reduction from one environment to another (see section 7.2.1).
Binding map. A mapping from environment states to bindings (see section 7.2.3).
Cartesian product. For sets: A  B is the set of all pairs (a; b) for a 2 A, b 2 B .
For environments: an environment is the Cartesian product of two other environments iff
its state space is the Cartesian product of their state spaces. Since the set of actions is
left open in this definition, there are many possible ways of forming products, e.g. serial
product, parallel product, uniform extension, etc.(see section 5.1).
Discrete control problem (DCP). An environment and a set of goal states within it
(see section 5).
Environment. A state machine, i.e. , a set of possible states and a set of possible actions
mapping states to states. The sets of states and actions need not be finite (see section 5).
141

fiAgre & Horswill

Focus. An action is focused on a state component if it only alters that component (see

section 7.1.3).
Material. An object (environment) whose state space is a chain (see section 7.1).
Policy. A mapping from states to actions; the formalization of an agent's control structure
(see section 5).
Projection. A mapping from the state space of one environment to the state space of
another (see section 5.2).
Simple projection. A mapping between state spaces that maps state space components
of one environment to state space components of another (see section 5.2).
State component. (For environments whose state spaces are Cartesian products) An
element of an environment's state-tuple (see section 5.1).
Solution. A policy solves a DCP from an initial state if, when run from that state, it
eventually reaches a goal state (see section 5).
Tool. (Roughly) A state component that can be brought to ready state without altering
any other state components (see section 7.1.3).
Uniform reducibility. (Roughly) E 0 is uniformly reducible to E if it consists of multiple
copies of E 's objects (see section 7.2.1).

Glossary of Notation

. Function composition operator: f  g(x) = f (g(x)).

. A projection (p. 122).
,1. The inverse of , i.e. the set of states that map to a given state under  (p. 131).
,. (For a simple projection : S 0 ! S ). A generalized inverse. Since  only maps certain
components of S 0 to S , , (s; s0 ) is s0 with those components replaced by their corresponding
components in s (p. 130).
A . For a simple reduction  from an environment E 0 to E , the function mapping an action
a from E to the action that implements it in E 0 (p. 122).
Cn. The chain-environment of n states (p. 127).
E . An environment.
9E;E G. G a goal of E and E 0 uniformly reducible to E . The existential goal of G in E 0 :
the set of all E 0 -states that map to a goal state under some binding (p. 130).
E1 *
) E2. The serial product. The Cartesian product of E1 and E2 in which actions from
0

the two environments must be taken separately (p. 120).
E1 k E2 . The parallel product. The Cartesian product of E1 and E2 in which actions from
the two environments must be taken simultaneously (p. 120).
LE;E . (E 0 an environment uniformly reducible to E ) The leftmost-ready binding map from
E 0 to E (p. 131).
p. A policy.
pE;G. The standard policy for single-material environment E and goal G (p. 127).
S . The singleton environment (the environment with exactly one state). Used to represent
a self-resetting tool (p. 128).
0

142

fiLifeworld Analysis

References

Agre, P., & Horswill, I. (1992). Cultural support for improvisation. In Tenth National Conference on Artificial Intelligence Cambridge, MA. American Association for Artificial
Intelligence, MIT Press.
Agre, P. E. (1995). Computational research on interaction and agency. Artificial Intelligence,
72 (1{2), 1{52.
Agre, P. E. (1997). Computation and Human Experience. Cambridge University Press,
Cambridge, UK.
Agre, P. E., & Chapman, D. (1987). Pengi: An implementation of a theory of activity. In
Proceedings of the Sixth National Conference on Artificial Intelligence, pp. 268{272.
Atkinson, J. M., & Heritage, J. (1984). Structures of Social Action. Cambridge University
Press, Cambridge, UK.
Ballard, D. H., Hayhoe, M. M., Pook, P. K., & Rao, R. P. N. (1995). Deictic codes for
the embodiment of cognition. Technical report 95.1, University of Rochester National
Resource Laboratory for the study of Brain and Behavior, Rochester, NY. Revised
July 1996.
Beach, K. D. (1988). The role of external mnemonic symbols in acquiring an occupation. In
Gruneberg, M. M., Morris, P. E., & Sykes, R. N. (Eds.), Practical Aspects of Memory:
Current Research and Issues, volume 1: Memory in Everyday Life. Wiley, Chichester,
UK.
Beer, R. D. (1995). A dynamical systems perspective on agent-environment interaction.
Artificial Intelligence, 72 (1{2), 173{215.
Brady, J. M., Agre, P. E., Braunegg, D. J., & Connell, J. H. (1984). The mechanic's mate.
In Proceedings of the 1984 European Conference on Artificial Intelligence Pisa, Italy.
Chapman, D., & Agre, P. E. (1986). Abstract reasoning as emergent from concrete activity.
In Georgeff, M. P., & Lansky, A. L. (Eds.), Reasoning about Actions and Plans, Proceedings of the 1986 Workshop, Timberline, Oregon. Morgan-Kaufmann Publishers,
Los Altos, CA.
Dixon, M. (1991). Embedded computation and the semantics of programs. TR SSL-91-1,
Xerox Palo Alto Research Center, Palo Alto, CA.
Donald, B. R., & Jennings, J. (1992). Constructive recognizability for task-directed robot
programming. Robotics and Autonomous Systems, 9, 41{74.
Edwards, D., & Mercer, N. (1987). Common Knowledge: The Development of Understanding in the Classroom. Methuen, London.
Gibson, J. J. (1986). The Ecological Approach to Visual Perception. Erlbaum, Hilldale, NJ.
Originally published in 1979.
143

fiAgre & Horswill
Grin, D. N. P., & Cole, M. (1989). The Construction Zone: Working for Cognitive Change
in School. Cambridge University Press, Cambridge.
Hammond, K. J., Converse, T. M., & Grass, J. W. (1995). The stabilization of environments.
Artificial Intelligence, 72 (1{2), 305{327.
Horswill, I. (1995). Analysis of adaptation and environment. Artificial Intelligence, 73 (1{2),
1{30.
Hutchins, E. (1995). Cognition in the Wild. MIT Press, Cambridge, MA.
Kirsh, D. (1995). The intelligent use of space. Artificial Intelligence, 72 (1{2), 31{68.
Knoblock, C. A. (1989). A theory of abstraction for hierarchical planning. In Benjamin,
D. P. (Ed.), Change of Representation and Inductive Bias. Kluwer, Boston.
Kosecka, J. (1992). Control of discrete event systems. GRASP LAB report 313, University
of Pennsylvania Computer and Information Science Department, Philadelphia, PA.
Lansky, A. L., & Fogelsong, D. S. (1987). Localized representations and planning methods
for parallel domains. In Proceedings of the Sixth National Conference on Artificial
Intelligence, pp. 240{245 Menlo Park, CA. AAAI Press.
Lave, J., & Wenger, E. (1991). Situated Learning: Legitimate Peripheral Participation.
Cambridge University Press, Cambridge, UK.
Littman, M. L. (1993). An optimization-based categorization of reinforcement learning
environments. In Meyer, & Wilson (Meyer & Wilson, 1993), pp. 262{270.
Lyons, D. M., & Arbib, M. A. (1989). A formal model of computation for sensory-based
robotics. IEEE Transactions on Robotics and Automation, 5 (3), 280{293.
Maturana, H. R., & Varela, F. J. (1988). The Tree of Knowledge: The Biological Roots of
Human Understanding. Shambhala, Boston.
Meyer, J.-A., & Wilson, S. W. (Eds.). (1993). From Animals to Animats: The Second
International Conference on Simulation of Adaptive Behavior. MIT Press, Cambridge,
MA.
Newell, A., Shaw, J. C., & Simon, H. A. (1960). Report on a general problem-solving
program. In Proceedings of the International Conference on Information Processing,
pp. 256{264 Paris.
Newell, A., & Simon, H. A. (1963). GPS: A program that simulates human thought. In
Feigenbaum, E. A., & Feldman, J. (Eds.), Computers and Thought, pp. 279{296.
McGraw-Hill.
Rogoff, B. (1990). Apprenticeship in Thinking: Cognitive Development in Social Context.
Oxford University Press, New York.
144

fiLifeworld Analysis
Rosenschein, S. J. (1987). Formal theories of knowledge in AI and robotics. report CSLI87-84, Center for the Study of Language and Information, Stanford, CA.
Rosenschein, S. J. (1989). Synthesizing information-tracking automata from environment
descriptions. In Brachman, R. J., Levesque, H. J., & Reiter, R. (Eds.), Proceedings
of the First International Conference on Principles of Knowledge Representation and
Reasoning, pp. 386{393.
Rosenschein, S. J., & Kaelbling, L. P. (1986). The synthesis of machines with provable
epistemic properties. In Halpern, J. (Ed.), Proc. Conf. on Theoretical Aspects of
Reasoning about Knowledge, pp. 83{98. Morgan Kaufmann.
Sacerdoti, E. D. (1974). Planning in a hierarchy of abstraction spaces. Artificial Intelligence,
5 (2).
Salomon, G. (Ed.). (1993). Distributed Cognitions: Psychological and Educational Considerations. Cambridge University Press.
Schutz, A., & Luckmann, T. (1973). The Structures of the Life-World. Northwestern
University Press, Evanston, IL.
Simon, H. A. (1947). Administrative Behavior: A Study of Decision-Making Processes in
Administrative Organization. Macmillan, New York.
Simon, H. A. (1970). The Sciences of the Artificial. MIT Press, Cambridge, MA.
Sussman, G. J. (1975). A Computer Model of Skill Acquisition. Elsevier, New York.
Todd, P. M., Wilson, S. W., Somayaji, A. B., & Yanco, H. A. (1994). The blind breeding
the blind: Adaptive behavior without looking. In Cliff, D., Husbands, P., Meyer,
J.-A., & Wilson, S. W. (Eds.), From Animals to Animats: The Third International
Conference on Simulation of Adaptive Behavior, pp. 228{237. MIT Press.
Todd, P. M., & Wilson, S. W. (1993). Environment structure and adaptive behavior from
the ground up. In Meyer, & Wilson (Meyer & Wilson, 1993), pp. 11{20.
Wilson, S. W. (1991). The animat path to AI. In Meyer, J.-A., & Wilson, S. W. (Eds.), From
Animals to Animats: Proceedings of the First International Conference on Simulation
of Adaptive Behavior, pp. 15{21. MIT Press, Cambridge, MA.
Winston, P. H., Binford, T. O., Katz, B., & Lowry, M. (1983). Learning physical descriptions
from functional definitions, examples, and precedents. In Proceedings of the National
Conference on Artificial Intelligence, pp. 433{439 Austin, TX.

145

fiJournal of Artificial Intelligence Research 6 (1997) 35-85

Submitted 7/96; published 1/97

SCREEN: Learning a Flat Syntactic and Semantic Spoken
Language Analysis Using Artificial Neural Networks
Stefan Wermter
Volker Weber

wermter@informatik.uni-hamburg.de
weber@informatik.uni-hamburg.de

Department of Computer Science
University of Hamburg
22527 Hamburg, Germany

Abstract
Previous approaches of analyzing spontaneously spoken language often have been based
on encoding syntactic and semantic knowledge manually and symbolically. While there
has been some progress using statistical or connectionist language models, many current
spoken-language systems still use a relatively brittle, hand-coded symbolic grammar or
symbolic semantic component.
In contrast, we describe a so-called screening approach for learning robust processing
of spontaneously spoken language. A screening approach is a at analysis which uses shallow sequences of category representations for analyzing an utterance at various syntactic,
semantic and dialog levels. Rather than using a deeply structured symbolic analysis, we
use a at connectionist analysis. This screening approach aims at supporting speech and
language processing by using (1) data-driven learning and (2) robustness of connectionist
networks. In order to test this approach, we have developed the screen system which is
based on this new robust, learned and at analysis.
In this paper, we focus on a detailed description of screen's architecture, the at
syntactic and semantic analysis, the interaction with a speech recognizer, and a detailed
evaluation analysis of the robustness under the inuence of noisy or incomplete input.
The main result of this paper is that at representations allow more robust processing of
spontaneous spoken language than deeply structured representations. In particular, we
show how the fault-tolerance and learning capability of connectionist networks can support
a at analysis for providing more robust spoken-language processing within an overall
hybrid symbolic/connectionist framework.

1. Introduction
Recently the fields of speech processing as well as language processing have both seen
efforts to examine the possibility of integrating speech and language processing (von Hahn
& Pyka, 1992; Jurafsky et al., 1994b; Waibel et al., 1992; Ward, 1994; Menzel, 1994; Geutner
et al., 1996; Wermter et al., 1996). While new and large speech and language corpora are
being developed rapidly, new techniques have to be examined which particularly support
properties of both speech and language processing. Although there have been quite a few
approaches to spoken-language analysis (Mellish, 1989; Young et al., 1989; Hauenstein &
Weber, 1994; Ward, 1994), they have not emphasized learning a syntactic and semantic
analysis of spoken language using a hybrid connectionist1 architecture which is the topic
c 1997 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiWermter & Weber

of this paper and our goal in screen2 . However, learning is important for the reduction
of knowledge acquisition, for automatic system adaptation, and for increasing the system
portability for new domains. Different from most previous approaches, in this paper we
demonstrate that hybrid connectionist learning techniques can be used for providing a
robust at analysis of faulty spoken language.
Processing spoken language is very different from processing written language, and successful techniques for text processing may not be useful for spoken-language processing.
Processing spoken language is less constrained, contains more errors and less strict regularities than written language. Errors occur on all levels of spoken-language processing.
For instance, acoustic errors, repetitions, false starts and repairs are prominent in spontaneously spoken language. Furthermore, incorrectly analyzed words, unforeseen grammatical and semantic constructions occur very often in spoken language. In order to deal with
these important problems for \real-world" language analysis, robust processing is necessary.
Therefore we cannot expect that existing techniques like context-free tree representations
which have been proven to work for written language can simply be transferred to spoken
language.
For instance, consider that a speech recognizer has produced the correct German sentence hypothesis \Ich meine naturlich Marz" (English translation: \I mean of course
March"). Standard techniques from text processing - like chart parsers and context-free
grammars - may be able to produce deeply structured tree representations for many correct
sentences as shown in Figure 1.
sentence
verb phrase

noun group

pronoun

verb group

verb

noun group

adverb

ich (I) meine (mean) natrlich (of_course)

noun

Mrz (March)

Figure 1: Tree representation for a correctly recognized sentence
However, currently speech recognizers are still far from perfect and produce many word
errors so that it is not possible to rely on a perfect sentence hypothesis. Therefore, incorrect
1. Sometimes connectionist networks are also called artificial neural networks. From now on we will use
only the term \connectionist networks", and the term \hybrid connectionist architecture" to refer to
an architecture which emphasizes the use of connectionist networks but does not rule out the use of
symbolic representations on higher levels where they might be needed.
2. Symbolic Connectionist Robust EnterprisE for Natural language

36

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

variations like \Ich meine ich Marz" (\I mean I March"), \Ich hatte ich Marz" (\I had I
March") and \Ich Ich meine Marz" (\I I mean March") have to be analyzed. However,
in context-free grammars a single syntactic or semantic category error may prevent that a
complete tree can be built, and standard top-down chart parsers may fail completely. However, suboptimal sentence hypotheses have to be analyzed since sometimes such sentence
hypotheses are the best possible output produced by a speech recognizer. Furthermore,
a lot of the content can be extracted even from partially incorrect sentence hypotheses.
For instance, from \I had I March" it is plausible that an agent \I" said something about
the time \March". Therefore, a robust analysis should be able to analyze such sentence
hypotheses and ideally should not break for any input.

1.1 Screening Approach: Flat Representations Support Robustness
For such examples of incorrect variations of sentence hypotheses, an in-depth structured
syntactic and semantic representation is not advantageous since more arbitrary word order and spontaneous errors make it often impossible to determine a desired deep highly
structured representation. Furthermore, a deep highly structured representation may have
many more restrictions than appropriate for spontaneously spoken language. However, and
maybe even more important, for certain tasks it is not necessary to perform an in-depth
analysis. While, for instance, inferences about story understanding require an in-depth
understanding (Dyer, 1983), tasks like information extraction from spoken language do not
need much of an in-depth analysis. For instance, if the output of our parser were to be used
for translating a speech recognizer sentence hypothesis \Eh ich meine eh ich Marz" (\Eh I
mean eh I March"), it may be sucient to extract that an agent (\I") uttered (\mean") a
time (\March"). In contrast to a deeply structured representation, our screening approach
aims at reaching a at but robust representation of spoken language. A screening approach
is a shallow at analysis based on category sequences (called at representations) at various
syntactic and semantic levels.
A at representation structures an utterance U with words w1 to wn according to the
syntactic and semantic properties of the words in their contexts, e.g., according to a sequence
of basic or abstract syntactic categories. For instance, the phrase \a meeting in London"
can be described as a at representation \determiner noun preposition noun" at a basic
syntactic level and as a at representation \noun-group noun-group prepositional-group
prepositional-group" at an abstract syntactic level. Similar at representations can be used
for semantic categories, dialog act categories, etc.
Kase
(Rubbish)
noun
no
noun group
negation

ich
(I)
pronoun
animate
noun group
agent

meine
(mean)
verb
utter
verb group
action

naturlich
(of course)
adverb
nil
special group
miscellaneous

Marz
(March)
noun
time
noun group
at time

Figure 2: Utterance with its at representation
37

fiWermter & Weber

Figure 2 gives an example for a at representation for a correct sentence hypothesis
\Kase ich meine naturlich Marz" (\Rubbish I mean of course March"). The first line shows
the sentence, the second its literal translation. The third line describes the basic syntactic
category of each word, the fourth line shows the basic semantic category. The last two lines
illustrate the syntactic and semantic categories at the phrase level.
Kase
(Rubbish)
noun
no
noun group
negation

ich
(I)
pronoun
animate
noun group
agent

hatte
(had)
verb
have
verb group
action

ich
(I)
pronoun
animate
noun group
agent

Marz
(March)
noun
time
noun group
at time

Figure 3: Utterance with its at representation
Figure 3 gives an example for a at representation for the incorrect sentence hypothesis
\Kase ich hatte ich Marz" (\Rubbish I had I March"). A parser for spoken language
should be able to process such sentence hypotheses as far as possible, and we use at
representations to support the necessary robustness. In our example, the analysis should
at least provide that an animate agent and noun group (\I") made some statement about a
specific time and noun group (\March"). Flat representations have the potential to support
robustness better since they have only a minimal sequential structure, and even if an error
occurs the whole representation can still be built. In contrast, in standard tree-structured
representations many more decisions have to be made to construct a deeply structured
representation, and therefore there are more possibilities to make incorrect decisions, in
particular with noisy spontaneously spoken language. So we chose at representations
rather than highly structured representations because of the desired robustness against
mistakes in speech/language systems.

1.2 Flat Representations Learned in a Hybrid Connectionist Framework

Robust spoken-language analysis using at representations could be pursued in different
approaches. Therefore we want to motivate why we use a hybrid connectionist approach,
which uses connectionist networks as far as possible but does not rule out the use of symbolic
knowledge. So why do we use connectionist networks?
Most important, due to their distributed fault tolerance, connectionist networks support
robustness (Rumelhart et al., 1986; Sun, 1994) but connectionist networks also have a number of other properties which are relevant for our spoken-language analysis. For instance,
connectionist networks are well known for their learning and generalization capabilities.
Learning capabilities allow to induce regularities directly from examples. If the training
examples are representative for the task, the noisy robust processing should be supported
by inductive connectionist learning.
Furthermore, a hybrid connectionist architecture has the property that different knowledge sources can take advantage of the learning and generalization capabilities of connectionist networks. On the other hand, other knowledge - task or control knowledge - for
38

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

which rules are known can be represented directly in symbolic representations. Since humans apparently do symbolic inferencing based on real neural networks, abstract models
as symbolic representations and connectionist networks have the additional potential to
shed some light on human language processing capabilities. In this respect, our approach
also differs from other candidates for robust processing, like statistical taggers or statistical
n-grams. These statistical techniques can be used for robust analysis (Charniak, 1993) but
statistical techniques like n-grams do not relate to the human cognitive language capabilities while simple recurrent connectionist networks have more relationships to the human
cognitive language capabilities (Elman, 1990).
screen is a new hybrid connectionist system developed for the examination of at
syntactic and semantic analysis of spoken language. In earlier work we have explored a
at scanning understanding for written texts (Wermter, 1995; Wermter & Lochel, 1994;
Wermter & Peters, 1994). Based on this experience we started a completely new project
screen to explore a learned fault-tolerant at analysis for spontaneously spoken-language
processing. After preliminary successful case studies with transcripts we have developed the
screen system for using knowledge generated from a speech recognizer. In previous work,
we gave a brief summary of screen with a specific focus on segmentation parsing and dialog
act processing (Wermter & Weber, 1996a). In this paper, we focus on a detailed description
of screen's architecture, the at syntactic and semantic analysis, the interaction with a
speech recognizer, and a detailed evaluation analysis of the robustness under the inuence
of noisy or incomplete input.

1.3 Organization and Claim of the Paper
The paper is structured as follows. In Section 2 we provide a more detailed description of
examples of noise in spoken language. Noise can be introduced by the human speaker but
also by the speech recognizer. Noise in spoken-language analysis motivates the at representations whose categories are described in Section 3. All basic and abstract categories at
the syntactic and semantic level are explained in this section. In Section 4 we motivate and
explain the design of the screen architecture. After a brief functional overview, we show
the overall architecture and explain details of individual modules up to the connectionist
network level. In order to demonstrate the behavior of this at analysis of spoken language
we provide various detailed examples in Section 5. Using several representative sentences
we walk the reader through a detailed step-by-step analysis. After the behavior of the system has been explained, we provide the overall analysis of the screen system in Section 6.
We evaluate the system's individual networks, compare the performance of simple recurrent networks with statistical n-gram techniques, and show that simple recurrent networks
performed better than 1-5 grams for syntactic and semantic prediction. Furthermore we
provide an overall system evaluation, examine the overall performance under the inuence
of additional noise, and supply results from a transfer to a different second domain. Finally
we compare our approach to other approaches and conclude that at representations based
on connectionist networks provide a robust learned spoken-language analysis.
We want to point out that this paper does not make an argument against deeply structured symbolic representations for language processing in general. Usually, if a deeply
structured representation can be built, of course due to the additional knowledge it con39

fiWermter & Weber

tains, its potential for more powerful relationships and interpretations will be greater than
that of a at representation. For instance, in-depth analysis is required for tasks like making
detailed planning inferences while reading text stories. However, our screening approach is
motivated based on noisy spoken-language analysis. For noisy spoken-language analysis,
at representations support robustness, and connectionist networks are effective for providing such robustness due to their learned fault-tolerance. This is a main contribution
of our paper, and we demonstrate this by building and evaluating a computational hybrid
connectionist architecture screen based on at, robust, and learned processing.

2. Processing Spoken Language

Our goal is to learn to process spontaneously spoken language at a syntactic and semantic
level in a fault-tolerant manner. In this section we will give motivating examples of spoken
language.

2.1 \Noise" in Spoken Language

Our domain in this paper is the arrangement of meetings between business partners, and
we currently use 184 spoken dialog turns with 314 utterances from this domain. One
turn consists of one or more subsequent utterances of the same speaker. For these 314
utterances, thousands of utterance hypotheses can be generated and have to be processed
based on the underlying speech recognizer. German utterance examples from this domain
are shown below together with their literal English translation. It is important to note that
the English translations are word-for-word translations.
1. Kase ich meine naturlich Marz
(Rubbish I mean of course March)
2. Der vierzehnte ist ein Mittwoch richtig
(The fourteenth is a Wednesday right)
3. A hm am sechsten April bin ich leider auer Hause
(Eh on sixth April am I unfortunately out of home)
4. Also ich dachte noch in der nachsten Woche auf jeden Fall noch im April
(So I thought still in the next week in any case still in April)
5. Gut prima vielen Dank dann ist das ja kein Problem
(Good great many thanks then is this yeah no problem)
6. Oh das ist schlecht da habe ich um vierzehn Uhr dreiig einen Termin beim Zahnarzt
(Oh that is bad there have I at fourteen o'clock thirty a date at dentist)
7. Ja genau allerdings habe ich da von neun bis vier Uhr schon einen Arzttermin
(Yes exactly however have I there from nine to four o'clock already a doctorappointment)
As we can see, spoken language contains many performance phenomena, among them
exclamations (\rubbish", see Example 1), interjections (\eh", \so", \oh", see Examples 3,
40

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

4 and 6), new starts (\there have I ...", see Example 6). Furthermore, the syntactic and
semantic constraints in spoken language are less strict than in written text. For instance, the
word order in spontaneously spoken language is often very different from written language.
Therefore, spoken language is \noisier" than written language even for these transcribed
sentences, and well-known parsing strategies from text processing - which can rely more on
wellformedness criteria - are not directly applicable for analyzing spoken language.

2.2 \Noise" from a Speech Recognizer

If we want to analyze spoken language in a computational model, there is not only the
\noise" introduced by humans while speaking but also the \noise" introduced by the limitations of speech recognizers. Typical speech recognizers produce many separated word
hypotheses with different plausibilities over time based on a given speech signal. Such word
hypotheses can be connected to a word hypothesis sequence and have to be evaluated for
providing a basis for further analysis. Typically, a word hypothesis consists of four parts: 1)
#PAUSE#
0.00-[0.01-0.33]

hm (eh)

ich (I)

0.02-[0.11-0.33]

5.36e-02

0.12-[0.33-0.33]

wie (how)
2.92e-03

htte (had)
1.06-[1.21-1.21]

0.13-[0.33-0.33]

am (on)
2.78e-03

April (April)
3.66e-04

0.81-[1.05-1.22]

ich (I)
1.22-[1.37-1.37]

1.12-[1.22-1.22]

ich (I)

leider (unfortunately)
3.33e-04

0.34-[0.43-0.43]

6.84e-03

sechsten (sixth)

6.53e-05

0.44-[0.80-0.80]

3.54e-03

1.13-[1.22-1.22]

bin (am)
1.53e-03

1.23-[1.30-1.37]

1.38-[1.59-1.59]

3.01e-01

5.07e-08

wenn (if)
3.35e-04

ich (I)
1.18e-02

1.31-[1.38-1.38]

1.81e-02

leider (unfortunately)
1.39-[1.59-1.59]

6.37e-04

auer (out of)
1.60-[1.90-1.90]

Hause (home)

6.74e-05

1.91-[2.37-3.38]

7.18e-01

2.38-[3.38-3.38]

#PAUSE#
3.39-[3.39-3.39]

1.88e-07

#not recognized#
2.74e-07

Figure 4: Simple word graph for a spoken utterance: \ahm am sechsten April bin ich
leider auer Hause" (\eh on sixth April am I unfortunately out of home").
Each node represents a word hypothesis; each arrow represents its possible
subsequent word hypotheses. Each word hypothesis is shown with its word
string, start time, end time interval and acoustic plausibility.
41

fiWermter & Weber

the start time in seconds, 2) the end time in seconds, 3) the word string of the hypothesis,
and 4) a plausibility of the hypothesis based on the confidence of the speech recognizer. Below we show a simple word graph3 . In practice, word graphs for spontaneous speech can be
much longer leading to comprehensive word hypothesis sequences. However, for illustrating
the properties of the speech input we focus on this relatively short and simple word graph
(Figure 4).
These word hypotheses can overlap in time and constitute a directed graph called word
graph. Each node in this word graph represents one word hypothesis. Two hypotheses in
this graph of generated word hypotheses can be connected if the end time of the first word
hypothesis is directly before the start time of the second word hypothesis. For instance, the
word hypothesis for \am" (\on") ending at 0.43 and the hypothesis \sechsten" (\sixth")
starting at 0.44 can be connected to a word hypothesis sequence.
hm
(eh)
hm
(eh)
0sec

ich
(I)

am
(on)

sechsten
(sixth)

April
(April)

bin
(am)

leider
(unfort.)

auer
(out of)

Hause
(home)

am
(on)

sechsten
(sixth)

April
(April)

wenn ich ich leider
(if) (I) (I) (unfort.)

auer
(out of)

Hause
(home)

1sec

ich
(I)

3sec

Figure 5: Two examples for word hypothesis sequences in a word graph
Our example word graph is very simple. However, as shown in Figure 5, a possible
word hypothesis sequence is not only the desired \A hm am sechsten April bin ich leider
auer Hause" (\Eh on sixth April am I unfortunately out of home"), but also the sequence
\A hm ich am sechsten April wenn ich ich leider auer Hause" (\Eh I on sixth April if I
I unfortunately out of home"). Consequently, we have to deal with incorrectly recognized
words in an extraordinary order. Therefore syntactic and semantic analysis has to be very
fault-tolerant in order to process such noisy word hypothesis sequences.

3. Flat Category Representation: An Intermediate Connecting
Representation
In this section we will describe our at category representations. First, we will show the
categories for the syntactic analysis before we will depict the categories for the semantic
analysis.
3. The speech input in the form of test word graphs was taken from the so-called Blaubeuren Meeting
Corpus. The particular word graphs we used here were provided by project partners for general test
purposes in the Verbmobil project. They were particularly generated for testing parsing strategies.
Therefore the speech recognizer was fine-tuned to produce relatively small word graphs with a relatively
high word accuracy of 93%. The vocabulary size for the HMM recognizer is 628. The average number
of hypotheses per word was 6.3 over 10 dialogs.

42

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

3.1 Categories for Flat Syntactic Analysis

Flat syntactic analysis is the assignment of syntactic categories to a sequence of words, e.g.,
the word hypothesis sequence generated by a speech recognizer. Flat representations up to
the phrase group level support local structural decisions. Local structural decisions deal
with the problem of which phrase group (abstract syntactic category) a word belongs to.
In this case the local, directly preceding words and their phrase group can inuence the
current decision. For instance, a determiner \the" could be part of a prepositional group
\in the mine" or part of a starting noun group \the old mine". That is, local structural
decisions depending on local context will be made based on a at analysis.
For at syntactic analysis we have developed a level of basic syntactic categories and
abstract syntactic categories. These syntactic categories may vary depending on the language, and the degree of detail of the intended structural representation. However, the
general approach is rather independent of the specifically used categories. In fact, we have
used the same syntactic categories for two different domains: railway counter interactions
and business meeting arrangements. The basic syntactic categories we used were noun,
verb, preposition, pronoun, numeral, past participle, pause, adjective, adverb, conjunction,
determiner, interjection and other. They are shown with their abbreviations in Table 1.
Category
noun (N)
verb (V)
preposition (R)
pronoun (U)
numeral (M)
participle (P)
pause (/)

Examples
date, April
meet, choose
at, in
I, you
fourteenth
taken
pause

Category
adjective (J)
adverb (A)
conjunction (C)
determiner (D)
interjection (I)
other (O)

Examples
late
often
and, but
the, a
eh, oh
particles

Table 1: Basic syntactic categories
The abstract syntactic categories we used are verb group, noun group, adverbial group,
prepositional group, conjunction group, modus group, special group and interjection group.
These abstract syntactic categories are shown in Table 2.
Category
verb group (VG)
noun group (NG)
adverbial group (AG)
prepositional group (PG)
conjunction group (CG)
modus group (MG)
special group (SG)
interjection group (IG)

Examples
mean, would propose
a date, the next possible slot
later, as early as possible
in the dining hall
and, either ... or
interrogatives, confirmations: when, how long, yes
additives like politeness: please, then
interjections, pauses: eh, oh

Table 2: Abstract syntactic categories
43

fiWermter & Weber

The categories should express main syntactic properties of the phrases. Most of our
basic and abstract syntactic categories are widely used in different parsers. However, the
approach of at representations does not crucially rely on this specific set of basic and
abstract syntactic categories. Our goal is to train, learn and generalize a at syntactic
analysis based on abstract syntactic categories and basic syntactic categories. Local syntactic decisions should be made as far as possible. Local syntactic ambiguities up to the
phrase group level (abstract syntactic categories) can be dealt with but more global ambiguities like prepositional phrase attachment will not be dealt with since they will need
additional knowledge, e.g., from a semantics module. While complete syntax trees have
a certain preference (which might turn out to be wrong based on semantic knowledge), a
at syntactic representation goes as far as possible using only local syntactic knowledge for
disambiguation.

3.2 Categories for Flat Semantic Analysis

Since semantic analysis is domain-dependent, the semantic categories can differ for different
domains. We have worked particularly on two domains: railway counter interactions (called:
Regensburg train corpus) and business meeting arrangements (called: Blaubeuren meeting
corpus). There was about 3/4 overlap between the semantic categories of the train corpus
Category
select (SEL)
suggest (SUG)
meet (MEET)
utter (UTTER)
is (IS)
have (HAVE)
move (MOVE)
aux (AUX)
question (QUEST)
physical (PHYS)
animate (ANIM)
abstract (ABS)
here (HERE)
source (SRC)
destination (DEST)
location (LOC)
time (TIME)
negative evaluation (NO)
positive evaluation (YES)
nil (NIL)

Examples
select, choose
propose, suggest
meet, join
say, think
is, was
had, have
come, go
would, could
question words: where, when
physical objects: building, oce
animate objects: I, you
abstract objects: date
time or location state words, prepositions: at, in
time or location source words, prepositions: from
time or location destination words, prepositions: to
Hamburg, Pittsburgh
tomorrow, at 3 o' clock, April
no, bad
yes, good
words \without" specific semantics, e.g., determiner: a

Table 3: Basic semantic categories
and the meeting corpus (Wermter & Weber, 1996b). Differences occurred mainly for verbs,
e.g., NEED-events are very frequent in the railway counter interactions while SUGGESTevents are frequent in the business meeting interactions. The semantic categories of the
44

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

Category
action (ACT)
aux-action (AUX)
agent (AGENT)
object (OBJ)
recipient (RECIP)
instrument (INSTR)
manner (MANNER)
time-at (TM-AT)
time-from (TM-FRM)
time-to (TM-TO)
loc-at (LC-AT)
loc-from (LC-FRM)
loc-to (LC-TO)
confirmation (CONF)
negation (NEG)
question (QUEST)
misc (MISC)

Examples
action for full verb events: meet, select
auxiliary action for auxiliary events: would like
agent of an action: I
object of an action: a date
recipient of an action: to me
instrument for an action: using an elevator
how to achieve an action: without changing rooms
at what time: in the morning
start time: after 6am
end time: before 8pm
at which location: in Frankfurt, in New York
start location: from Boston, from Dortmund
end location: to Hamburg
confirmation phrase: ok great, yes wonderful
negation phrase: no stop, not
question phrases: at what time
miscellaneous words, e.g., for politeness: please, eh

Table 4: Abstract semantic categories
railway counter interactions were described in previous work (Weber & Wermter, 1995).
Here we will primarily focus on the semantic categories of the meeting corpus. The basic
semantic categories for a word are shown in Table 3. At a higher level of abstraction, each
word can belong to an abstract semantic category. The possible abstract semantic categories
are shown in Table 4. In summary, these categories provide a basis for a at analysis. Each
word is represented syntactically and semantically in its context by four categories at two
basic and two abstract levels.

4. The Architecture of the SCREEN System

In this section we want to describe the constraints and principles which are important for our
system design. As we outlined and motivated in the introduction, the screening approach
is a at, robust, learned analysis of spoken language based on category sequences (called
at representations) at various syntactic and semantic levels. In order to test this screening
approach, we designed and implemented the hybrid connectionist screen system which
processes spontaneously spoken language by using learned connectionist at representations.
Here we summarize our main requirements in order to motivate the specific system design
which will be explained in the subsequent subsections.

4.1 General Motivation for the Architecture

We consider learning to be extremely important for spoken-language analysis for several
reasons. Learning reduces knowledge acquisition and increases portability, particularly
in spoken-language analysis, where the underlying rules and regularities are dicult to
formulate and often not reliable. Furthermore, in some cases, inductive learning may detect
45

fiWermter & Weber

unknown implicit regularities. We want to use connectionist learning in simple recurrent
networks rather than other forms of learning (e.g., decision trees) primarily because of the
inherent fault-tolerance of connectionist networks, but also because knowledge about the
sequence of words and categories can be learned in simple recurrent networks.
Fault-tolerance for often occurring language errors should be reected in the system
design. We do this for the commonly occurring errors (interjections, pauses, word repairs,
phrase repairs). However, fault-tolerance cannot go so far as to try to model each class of
occurring errors. The number of potentially occurring errors and unpredictable constructions is far too large. In screen, we want to incorporate explicit fault-tolerance by using
specific modules for correction as well as implicit fault-tolerance by using connectionist network techniques which are inherently fault-tolerant due to their support of similarity-based
processing. In fact, even if a word is completely unknown, recurrent networks can use an
empty input and may even assign the correct category if there is sucient previous context.
Flat representations, as motivated in Sections 1 and 3, may support a robust spokenlanguage analysis. However, at connectionist representations do not provide the full recursive power of arbitrary syntactic or semantic symbolic knowledge structures. In contrast
to context-free parsers, at representations provide a better basis for robust processing
and automatic knowledge acquisition by inductive learning. However, it can also be argued that the use of potentially unrestricted recursion of well-known context-free grammar
parsers provides a computational model with more recursive power than humans have in
order to understand language. In order to better support robustness, we want to use at
representations for spontaneous language analysis.
Incremental processing of speech, syntax, semantics and dialog processing in parallel
allows us to start the language analysis in parallel before the speech recognizer has finished
its analysis. This incremental processing has the advantage of providing analysis results
at a very early stage. For example, syntactic and semantic processing occur in parallel
only slightly behind speech processing. When analyzing spoken language based on speech
recognizer output, we want to consider many competing paths of word hypothesis sequences
in parallel.
With respect to hybrid representations, we examine a hybrid connectionist architecture
using connectionist networks where they are useful but we also want to use symbolic processing wherever necessary. Symbolic processing can be very useful for the complex control
in a large system. On the other hand for learning robust analysis, we use feedforward and
simple recurrent networks in many modules and try to use rather homogeneous, supervised
networks.

4.2 An Overview of the Architecture

screen has a parallel integrated hybrid architecture (Wermter, 1994) which has various

main properties:

1. Outside of a module, there is no difference in communication between a symbolic and
a connectionist module. While previous hybrid architectures emphasized different
symbolic and connectionist representations, the different representations in screen
benefit from a common module interface. Outside of a connectionist or symbolic
46

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

module all communication is identically realized by symbolic lists which contain values
of connectionist units.
2. While previous hybrid symbolic and connectionist architectures are usually within
either a symbolic or a connectionist module (Hendler, 1989; Faisal & Kwasny, 1990;
Medsker, 1994), in screen a global state is described as a collection of individual
symbolic and connectionist modules. Processing can be parallel as long as one module
does not need input from a second module.
3. The communication among the symbolic and connectionist modules is organized via
messages. While other hybrid architectures have often used either only activation
values or only symbolic structures, we used messages consisting of lists of symbols
with associated activation or plausibility values to provide a communication medium
which supports both connectionist processing as well as symbolic processing.
We will now give an overview of the various parts in screen (see Figure 6). The
important output consists of at syntactic and semantic category representations based
on the input of incrementally recognized parallel word hypotheses. A speech recognizer
generates many incorrect word hypotheses over time, and even correctly recognized speech
can contain many errors introduced by humans. A at representation is used since it is
more fault-tolerant and robust than, for instance, a context-free tree representation since a
tree representation requires many more decisions than a at representation.
Each module in the system, for instance the disambiguation of abstract syntactic categories, contains a connectionist network or a symbolic program. The integration of symbolic
and connectionist representations occurs as an encapsulation of symbolic and connectionist
processes at the module level. Connectionist networks are embedded in symbolic modules
which can communicate with each other via messages.
However, what are the essential parts needed for our purposes of learning spokenlanguage analysis and why? Starting from the output of individual word hypotheses of
a speech recognizer, we first need a component which receives an incremental stream of
individual parallel word hypotheses and produces an incremental stream of word hypothesis sequences (see Figure 6). We call this part the speech sequence construction part. It is
needed for transforming parallel overlapping individual word hypotheses to word hypothesis sequences. These word hypothesis sequences have a different quality and the goal is
to find and work with the best word hypothesis sequences. Therefore we need a speech
evaluation part which can combine speech-related plausibilities with syntactic and semantic
plausibilities in order to restrict the attention to the best found word hypothesis sequences.
Furthermore, we need a part which analyzes the best found word hypothesis sequences
according to their at syntactic and semantic representation. The category part receives
a stream of current word hypothesis sequences. Two such word hypothesis sequences are
shown in Figure 6. This part provides the interpretation of a word hypothesis sequence
with its basic syntactic categories, abstract syntactic categories, basic semantic categories,
and abstract semantic categories. That is, each word hypothesis sequence is assigned four
graded preferences for four word categories.
Human speech analyzed by a speech recognizer may contain many errors. So the question
arises to what extent we want to consider these errors. An analysis of several hundred
47

fiWermter & Weber

two word hypotheses sequences:
1.

output to further analysis
2.

Kse

ich

meine

natrlich

(rubbish)

(I)

(mean)

(of course) (March)

N

NG

U

NG

NO

NEG

ANIM

AGENT UTTER ACT

V

VG

A

SG

N

NG

NILL

MISC

TIME

TMAT

Kse

ich

htte

ich

(rubbish)

(I)

(had)

(I)

N

NG

U

NG

NO

NEG

ANIM

AGENT HAVE

V

Mrz

Mrz
(March)

VG

U

ACT

ANIM [AGENT] TIME

[NG]

N

NG
TMAT

....
syntactic/semantic hypotheses

case frame part

dialog part
learned
flat
syntactic and
semantic
analysis

correction part
speech evaluation part

category part
constructed word hypotheses sequences:
Kse ich meine natrlich Mrz
1. Rubbish I mean of course March

speech sequence construction part

Kse ich htte ich Mrz
I had I March

2. Rubbish

....

word hypotheses
word hypotheses generated by speech recognizer:
0.00
0.11
0.45
0.45
0.57
0.57
0.58
0.76
0.95
1.12
1.13
0.76
1.15
1.35
3.00

input from speech recognizer
current word hypothesis

0.10
0.44
0.56
0.57
0.75
0.75
0.94
1.14
1.11
2.99
1.34
1.11
2.99
2.99
3.00

#PAUSE#
Kse
ich
ich
meine
meine
htte
etliche
ich
Mrz
da
natrlich
Mrz
aus
#PAUSE#

Figure 6: Overview of screen
48

(rubbish)
(I)
(I)
(mean)
(mean)
(had)
(several)
(I)
(March)
(there)
(of course)
(March)
(out)

7.022857e02
2.269389e06
3.697864e03
2.017291e03
1.245984e05
1.016475e04
2.831144e08
3.045548e08
1.749518e04
9.596145e16
1.257770e04
1.017243e07
4.249394e15
2.624843e12
7.497616e01

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

transcripts and speech recognizer outputs revealed that there are some errors which occur
often and regularly. These are interjections, pauses, word repairs, and phrase repairs.
Therefore we designed a correction part which receives hypotheses about words and deals
with most frequently occurring errors in spoken language explicitly.
These parts outlined so far build the center of the integration of speech-related and
language-related knowledge in a at fault-tolerant learning architecture, and therefore we
will focus on these parts in this paper. However, if we want to process complete dialog turns
which can contain several individual utterances we need to know where a certain utterance
starts and which constituents belong to this utterance. This task is performed by a case
frame part which fills a frame incrementally and segments a speaker's turn into utterances.
The long-term perspective of screen is to provide an analysis for tasks such as spoken
utterance translation or information extraction. Besides the syntactic and semantic analysis
of an utterance, the intended dialog acts convey important additional knowledge. Therefore,
a dialog part is needed for assigning dialog acts to utterances, for instance if an utterance is
a request or suggestion. In fact, we have already fully implemented the case frame part and
the dialog part for all our utterances. However, we will not describe the details of these two
parts in this paper since they have been described elsewhere (Wermter & Lochel, 1996).
Learning in screen is based on concepts of supervised learning as for instance in feedforward networks (Rumelhart et al., 1986), simple recurrent networks (Elman, 1990) and
more general recurrent plausibility networks (Wermter, 1995). In general, recurrent plausibility networks allow an arbitrary number of context and hidden layers for considering long
distance dependencies. However, for the many network modules in screen we attempted
to keep the individual networks simple and homogeneous. Therefore, in our first version
described here we used only variations of feedforward networks (Rumelhart et al., 1986)
and simple recurrent networks (Elman, 1990). Due to their greater potential for sequential
context representations, recurrent plausibility networks might provide improvements and
optimizations of simple recurrent networks. However, for now we are primarily interested
in an overall real-world hybrid connectionist architecture screen rather than the optimization of single networks. In the following description we will give detailed examples of the
individual networks.

4.3 A More Detailed View

After we motivated the various parts in screen, we will now give a more detailed description
of the architecture of screen with respect to the modules for at syntactic and semantic
analysis of word hypothesis sequences. Therefore, we will focus on the speech related parts,
the categorization part and correction part. Figure 7 shows a more detailed overview of these
parts. The basic data ow is shown with arrows. Many modules generate hypotheses which
are used in subsequent modules at a higher level. These hypotheses are illustrated with
rising arrows. In some modules, the output contains local predictive hypotheses (sometimes
called local top-down hypotheses) which are used again in modules at a lower level. These
hypotheses are illustrated with falling arrows. Local predictive hypotheses are used in the
correction part to eliminate4 repaired utterance parts and in the speech evaluation part
to eliminate syntactically or semantically implausible word hypothesis sequences. In some
4. This means that repaired utterance parts are actually only marked as deleted.

49

fiWermter & Weber

SEGMENT-PARSER

DIA-ACT

frame

slots
dialog act
type
verb-form

...

case frame part 1

2

8

reject
utter
meinen
(mean)

4

3

dialog part
PHRASE-ERROR

2

2

3

3

BAS-SYN-EQ

BAS-SEM-EQ

2

2

2*13

2*20

correction part

LEX-START-EQ

LEX-WORD-EQ

8

5

WORD-ERROR

Is there a
pause, interjection,
hesitation, unresolved
phonetic material?

INTERJECTION

1

...

PAUSE-ERROR

PAUSE

Dialog Lexicon

2

ABS-SYN-EQ
2

2

2*8

2*17

3

4

SEM-SPEECH-ERROR

2

PHRASE-START?

3

BAS-SYN-PRE

5
4

separates
SYN-SPEECH-ERROR

ABS-SEM-EQ

5

ABS-SYN-CAT

ABS-SEM-CAT

2

8

17

13

13

20

BAS-SEM-PRE

13

20

13

20

BAS-SYN-DIS

2

2

BAS-SEM-DIS

13

20

13

20

3

3
verb, pronoun
UTTER, NIL

speech evaluation part

Syntactic Lexicon
Semantic Lexicon

category part

1
CON-SEQU-HYPS
Kse ich meine

(rubbish I mean)
constructed word hypotheses sequences:
Kse ich
Kse ich meine

(rubbish I)
(rubbish I mean)

speech sequence construction part

Figure 7: More detailed overview of screen. The abbreviations and functionality of
the modules are described in the text.
50

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

cases where arrows would have been too complex we have used numbers to illustrate the
data ow between individual modules.
4.3.1 Speech sequence construction part

The speech sequence construction part receives a stream of parallel word hypotheses and
generates a stream of word hypothesis sequences within the module con-sequ-hyps at the
bottom of Figure 7. Based on the current word hypotheses many word hypothesis sequences
may be possible. In some cases we can reduce the number of current word hypotheses, e.g.,
if we know that time has passed so far that a specific word hypothesis sequence cannot
be extended anymore at the time of the current word hypothesis. In this case we can
eliminate this sequence since only word hypothesis sequences which could reach the end of
the sentence are candidates for a successful speech interpretation.
Furthermore, we can use the speech plausibility values of the individual word hypothesis
to determine the speech plausibility of a word hypothesis sequence. By using only some
of the best word hypothesis sequences we can reduce the large space of possible sequences.
The generated stream of word hypothesis sequences is similar to a set of partial N-best
representations which are generated and pruned incrementally during speech analysis rather
than at the end of the speech analysis process.
4.3.2 Speech evaluation part

The speech evaluation part computes plausibilities based on syntactic and semantic knowledge in order to evaluate word hypothesis sequences. This part contains the modules for
the detection of speech-related errors. Currently, the performance of speech recognizers
for spontaneously spoken speaker-independent speech is in general still far from perfect.
Typically, many word hypotheses are generated for a certain signal5 . Therefore, many hypothesized words produced by a speech recognizer are incorrect and the speech confidence
value for a word hypothesis alone does not provide enough evidence for finding the desired
string for a signal. Therefore the goal of the speech evaluation part is to provide a preference
for filtering out unlikely word hypothesis sequences. syn-speech-error and sem-speecherror are two modules which decide if the current word hypothesis is a syntactically
(semantically) plausible extension of the current word hypothesis sequence. The syntactic
(semantic) plausibility is based on a basic syntactic (semantic) category disambiguation and
prediction.
In summary, each word hypothesis sequence has an acoustic confidence based on the
speech recognizer, a syntactic confidence based on syn-speech-error, and a semantic
confidence based on sem-speech-error. These three values are integrated and weighted
equally6 to determine the best word hypothesis sequences. That way, these two modules can
5. The HMM-speech recognizer used for generating word hypotheses in our domain has a word accuracy
of about 93% for the best match between the word graph and the desired transcript utterance. This
recognizer was particularly optimized for this task and domain in order to be able to examine the
robustness at the language level. An unoptimized version for this task and domain currently has 72%
word accuracy.
6. This integration of speech, syntax, and semantics confidence values provided better results than just
using one or two of these three knowledge sources.

51

fiWermter & Weber

act as an evaluator for the speech recognizer as well as a filter for the language processing
part.
In statistical models for speech recognition, bigram or trigram models are used as language models for filtering out the best possible hypotheses. We used simple recurrent
networks since these networks performed slightly better than a bigram and a trigram model
which had been implemented for comparison (Sauerland, 1996). Later in Section 6.1 we
will also show a detailed comparison of simple recurrent networks and n-gram models (for n
= 1,...,5). The reason for this better performance is the internal representation of a simple
recurrent network which does not restrict the covered context to a fixed number of two or
three words but has the potential to learn the required context that is needed.
output-layer
13 units
N

J

V

A

R

C

U

D

M

I

P

O

/

14*13 connections

context-layer

hidden-layer
14*14
conn.

input-layer

2*14 units

14 copy

13*14 connections

13 units
N

J

V

A

R

C

U

D

M

I

P

O

/

disambiguated representation of "ich" ("I") from BAS-SYN-DIS

Figure 8: Network architecture for the syntactic prediction in the speech evaluation part
(bas-syn-pre). The abbreviations are explained in Table 1.
The knowledge for the syntactic and semantic plausibility is provided by the prediction
networks (bas-syn-pre and bas-sem-pre) of the speech evaluation part and the disambiguation networks (bas-syn-dis and bas-sem-dis) of the categorization part. As an example, we show the network for bas-syn-pre in Figure 8. The previous basic syntactic
category of the currently considered word hypothesis sequence is input to the network. In
our example \ich" (\I") from the word hypothesis sequence \Kase ich meine" (\Rubbish I
mean") is found to be a pronoun (U). Therefore, the syntactic category representation for
\ich" (\I") contains a \1" for the pronoun (U) category. All other categories receive a \0".
The input to this network consists of 13 units for our 13 categories. The output of
the network has the same size. Each unit of the vector represents a plausibility for the
predicted basic syntax category of the last word in the current word hypothesis sequence.
The plausibility of the unit representing the desired basic syntactic category (found by
bas-syn-dis) is taken as syntactic plausibility for the currently considered word hypothesis
sequence by syn-speech-error. In this example \meine" (\mean") is found to be a verb
52

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

(V). Therefore the plausibility for a verb (V) will be taken as syntax plausibility (selection
marked by a box in the output-layer of bas-syn-pre in Figure 8).
In summary, the syntactic (semantic) plausibility of a word hypothesis sequence is evaluated by the degree of agreement between the disambiguated syntactic (semantic) category
of the current word and the predicted syntactic (semantic) category of the previous word.
Since decisions about the current state of a whole sequence have to be made, the preceding
context is represented by copying the hidden layer for the current word to the context layer
for the next word based on an SRN network structure (Elman, 1990). All connections in
the network are n:m connections except for the connections between the hidden layer and
the context layer which are simply used to copy and store the internal preceding state in
the context layer for later processing when the next word comes in. In general, the speech
evaluation part provides a ranking of the current word hypothesis sequences by the equally
weighted combination of acoustic, syntactic, and semantic plausibility.
4.3.3 Category part

The module bas-syn-dis performs a basic syntactic disambiguation (see Figure 9). Input to
this module is a sequence of potentially ambiguous syntactic word representations, one for
each word of an utterance at a time. Then this module disambiguates the syntactic category
representation according to the syntactic possibilities and the previous context. The output
is a preference for a disambiguated syntactic category. This syntactic disambiguation task is
learned in a simple recurrent network. Input and output of the network are the ambiguous
and disambiguated syntactic category representations. In Figure 9 we show an example
input representation for \meine" (\mean", \my") which can be a verb and a pronoun.
However, in the sequence \Ich meine" (\I mean"), \meine" can only be a verb and therefore
the network receives the disambiguated verb category representation alone.
The module bas-sem-dis is similar to the module bas-syn-dis but instead of receiving
a potentially ambiguous syntactic category input and producing a disambiguated syntactic
category output, the module bas-sem-dis receives a semantic category representation from
the lexicon and provides a disambiguated semantic category representation output. This
semantic disambiguation is learned in a simple recurrent network which provides the mapping from the ambiguous semantic word representation to the disambiguated semantic word
representation. Both modules bas-syn-dis and bas-sem-dis provide this disambiguation
so that subsequent tasks like the association of abstract categories and the test of category
equality for word error detection is possible.
The module abs-syn-cat supplies the mapping from disambiguated basic syntactic
category representations to the abstract syntactic category representations (see Figure 10).
This module provides the abstract syntactic categorization and it is realized with a simple
recurrent network. This module is important for providing a at abstract interpretation
of an utterance and for preparing input for the detection of phrase errors. Figure 10 shows
that the disambiguated basic syntactic representation of \meine" (\mean") as a verb - and
a very small preference for a pronoun - is mapped to the verb group category at the higher
abstract syntactic category representation. Based on the number of our basic and abstract
syntactic categories there are 13 input units for the basic syntactic categories and 8 output
units for the abstract syntactic categories.
53

fiWermter & Weber

output-layer
13 units
N

J

V

A

R

C

U

D

M

I

P

O

/

14*13 connections

hidden-layer

context-layer
14*14
conn.

input-layer

2*14 units

14 copy

13*14 connections

13 units
N

J

V

A

R

C

U

D

M

P

O

/

ambiguous representation
of "meine" (verb/pronoun)

syntactic lexicon
meine

Kse
(rubbish)

I

verb
pronoun

ich meine
(I) (mean)

current word hypotheses sequence

Figure 9: Network architecture for the basic syntactic disambiguation (bas-syn-dis).
The abbreviations are explained in Table 1.
The module abs-sem-cat is a parallel module to abs-syn-cat but uses basic semantic
category representations as input and abstract semantic category representations as output.
Similar to the previous modules, we also used a simple recurrent network to learn this
mapping and to represent the sequential context. The input to the network is the basic
semantic category representation for the word, and the output is an abstract category
preference.
These described four networks provide the basis for the fault-tolerant at analysis and
the detection of errors. Furthermore, there is the module phrase-start for distinguishing
abstract categories. The task of this module is to indicate the boundaries of subsequent
abstract categories with a delimiter. We use these boundaries to determine the abstract
syntactic and abstract semantic category of a phrase7 . Earlier experiments had provided
support to take the abstract syntactic category of the first word in a phrase as the final
abstract syntactic category of a phrase, since phrase starts (e.g., prepositions) are good
7. In Figure 7 we show the inuence of the phrase start delimiter on the abstract syntactic and semantic
categorization with dotted lines.

54

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

output-layer
8 units
NG

VG

PG

CG

AG MG

SG

IG

14*13 connections

hidden-layer

context-layer
14*14
conn.

input-layer

13*14 connections

2*14 units

14 copy

13 units
N
J
V
A
R
C
U
D
disambiguated representation of "meine" (mean)

M

I

P

O

/

Figure 10: Network architecture for the abstract syntactic categorization (abs-syn-cat).
The abbreviations are explained in Table 2.
indicators for abstract syntactic categories (Wermter & Lochel, 1994). On the other hand,
earlier experiments supported to take the abstract semantic category of the last word of a
phrase as the final abstract semantic category of a phrase, since phrase ends (e.g., nouns)
are good indicators for abstract semantic categories (Wermter & Peters, 1994). Furthermore, the phrase start gives us an opportunity to distinguish two equal subsequent abstract
categories of two phrases. For instance, if we have a phrase like \in Hamburg on Monday"
we have to know where the border exists between the first and the second prepositional
phrase.
4.3.4 Correction part

The correction part contains modules for detecting pauses, interjections, as well as repetitions and repairs of words and phrases (see Figure 7). The modules for detecting pause
errors are pause-error, pause and interjection. The modules pause and interjection receive the currently processed word and detect the potential occurrence of a pause
and interjection, respectively. The output of these modules is input for the module pauseerror. As soon as a pause or interjection has been detected, the word is marked as deleted
and therefore virtually eliminated from the input stream8. An elimination of interjections
and pauses is desired - for instance in a speech translation task - in order to provide an inter8. Pauses and interjections can sometimes provide clues for repairs (Nakatani & Hirschberg, 1993) although
currently we do not use these clues for repair detection. Compared to the lexical, syntactic, and semantic
equality of constituents, interjections and pauses provide relatively weak indicators for repairs since they
also occur relatively often at other places in a sentence. However, since we just mark interjections and
pauses as deleted we could make use of this knowledge in the future if necessary.

55

fiWermter & Weber

pretation with as few errors as possible. Since these three modules are basically occurrence
tests they have been realized with symbolic representations.
The second main cluster of modules in the correction part are the modules which are
responsible for the detection of word-related errors. Then, word repairs as in \Am sechsten
April bin ich ich" (\on sixth April am I I") or \Wir haben ein Termin Treffen" (\We have
a date meeting") can be dealt with. There are certain preferences for finding repetitions
and repairs at the word level. Among these preferences there is the lexical equality of two
subsequent words (symbolic module lex-word-eq), the equality of two basic syntactic
category representations (connectionist module bas-syn-eq), and the equality of the basic
semantic categories of two words (connectionist module bas-sem-eq). As an example for
the three modules, we show the test for syntactic equality (BAS-SYN-EQ) in Figure 11.
output-layer
2 units
equal not equal
5*2 connections

hidden-layer
5 units
input-layer

(2*13)*5 connections

N J V A R C U D M I P O /

N J V A R C U D M I P O /

2*13
units

disambiguated representation of second "ich" (I)

disambiguated repr. of first "ich" (I)

output-layer
2 units
equal not equal
5*2 connections

hidden-layer
5 units
input-layer

(2*13)*5 connections

N J V A R C U D M I P O /
disambiguated repr. of "Termin" (date)

N J V A R C U D M I P O /

2*13
units

disambiguated representation of "Treffen" (meeting)

Figure 11: Network architecture for the equality of basic syntactic category representation (bas-syn-eq). The abbreviations are explained in Table 1.
56

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

Two output units for plausible/implausible outcome have been used here since the network with two output units gave consistently better results compared with a network with
only one output unit (with 1 for plausible and 0 for implausible). The reason why the network with two output units performed better is the separation of the weights for plausible
and implausible in the hidden-output layer. In order to receive a single value, the two output values are integrated according to the formula: unit1  (1:0 , unit2 ). Then, the output
of all three equality modules is a value between 0 and 1 where 1 represents equality and 0
represents inequality. Although a single such preference may not be sucient, the common
inuence provides a reasonable basis for detecting word repairs and word repetitions in the
module word-error. Then, word repairs and repetitions are eliminated from the original
utterance. Since the modules for word-related errors are based on two representations of two
subsequent input words and since context can only play a minor role, we use feedforward
networks for these modules. On the other hand, the simple test on lexical equality of the
two words in lex-word-eq is represented more effectively using symbolic representation.
The third main cluster in the correction part consists of modules for the detection
and correction of phrase errors. An example for a phrase error is: \Wir brauchen
den fruheren Termin den spateren Termin" (\We need the earlier date the later date").
There are preferences for phrase errors if the lexical start of two subsequent phrases is
equal, if the abstract syntactic categories are equal and if the abstract semantic categories
are equal. For these three preferences we have the modules lex-start-eq, abs-syn-eq
and abs-sem-eq. All these modules receive two input representations of two corresponding
words from two phrases, lex-start-eq receives two lexical words, abs-syn-eq two abstract
syntactic category representations, and abs-sem-eq two abstract semantic category representations. The output of these three modules is a value toward 1 for equality and toward
0 otherwise. These values are input to the module phrase-error which finally decides
whether a phrase is replaced by another phrase. As the lexical equality of two words is a
discrete test, we have implemented lex-start-eq symbolically, while the other preferences
for a phrase error have been implemented as feedforward networks.

5. Detailed Analysis with Examples

In this section we will have a detailed look at processing the output from a speech recognizer
and producing a at syntactic and semantic interpretation of concurrent word hypothesis
sequences (also called sentence hypothesis here).

5.1 The Overall Environment

The overall processing is incremental from left to right, and any time multiple sentence
hypotheses are processed in parallel. Figure 12 shows a snapshot of screen after 0.95s of
the utterance. At this time the snapshot shows the first three sentence hypotheses as the
German words together with their (literal) English translations (\Rubbish I mean", \Rubbish I", \Rubbish I had"). The screen environment allows the user to view and inspect
the incremental generation of word hypothesis sequences (partial sentence hypotheses) and
their most preferred syntactic and semantic categories at the basic and abstract level. Each
sentence hypothesis is illustrated horizontally. At a certain time many sentence hypotheses
can be active in parallel. They are ranked according to the descending plausibility of the
57

fiWermter & Weber

SCREEN - Symbolic Connectionist Robust EnterprisE for Natural language
Quit

on line

Stop

Go

single step

1

3 Sentencehypotheses. Time: 0.95s (System)/0.95s (Display)

N

NO

NG

SUG

NEG CONF

Kse (rubbish)

N

NO

0

NG

SUG

NEG CONF

Kse (rubbish)

N

NO

NG

SUG

NEG CONF

Kse (rubbish)

U

NG

SUG

ANIM AGENT CONF

ich (I)

V

NIL

SUG

UTTER NIL

CONF

meine (mean)

U

NIL

SUG

ANIM

NIL

CONF

NG

SUG

ich (I)

U

ANIM AGENT CONF

ich (I)

V

NIL

SUG

HAVE

NIL

CONF

htte (had)

0

0.0000 0.0000 0.9799 0.0000 0.0038 0.0004 0.1653 0.0048 0.0001 0.0003 0.0001 0.0017 0.0001
N
J
V
A
R
C
U
D
M
I
P
O
/

Figure 12: First snapshot for sentence \Kase ich meine naturlich Marz (\Rubbish I mean
of course March"). The abbreviations are explained in Table 1 to 4. Below,
the second pop-up window illustrates the full preferences of the word \meine"
(\mean") for its basic syntactic categories.
sentence hypotheses. So in the snapshot in Figure 12 there are currently three sentence
hypotheses and the preferred current sentence hypothesis consists of \Rubbish I mean".
All these sentence hypotheses are syntactically and semantically plausible starts. The
underlying variations are introduced by the speech recognizer which produced different word
hypotheses for slightly overlapping signal parts of the sentence. Besides the speech plausibility, syntax and also semantics can help with choosing better sentence hypotheses. Currently
we combine the speech recognition plausibility, the syntactic plausibility, and the semantic
plausibility to compute the plausibility of the sentence hypotheses as a multiplication of the
respective normalized plausibility values between 0 and 1. Since the speech recognizer does
not contain syntactic and semantic knowledge, a sequence hypothesis rated plausible based
on speech knowledge alone may neglect the potential of syntactic and semantic regularity.
58

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

By using corresponding syntactic and semantic plausibility values for a sentence hypothesis
we can integrate acoustic, syntactic, and semantic knowledge.
Each word hypothesis is shown with the preferred basic syntactic hypothesis (upper left
square of a word hypothesis), the preferred abstract syntactic hypothesis (upper middle
square), the preferred basic semantic hypothesis (lower left square), the preferred abstract
semantic hypothesis (lower middle square), the preferred dialog act (upper right square)9,
and the integrated acoustic, syntactic and semantic confidence of the partial sentence hypothesis up to that point (lower right square). The size of the square illustrates the strength
of the hypothesis, and a full black square means that a preferred hypothesis is close to one.
For instance, in the word hypothesis for \ich" (\I") in the first sentence hypothesis we have
the hypothesis of a pronoun (U) as the basic syntactic category, a noun group (NG) as the
abstract syntactic category, an animate object (ANIM) as the basic semantic category, an
AGENT as the abstract semantic category, and suggestion (SUG) as dialog act. Furthermore, the length of a vertical bar between word hypotheses indicate the plausibility for a
new phrase start.
As another example, we can see the representation of our example word \meine" (could
be the verb \mean" or the pronoun \my" in German) which we have used throughout the
network descriptions (see Figure 9). The network had a correct preference for \meine"
being a verb (V). Figure 12 shows this preference as well as a zoomed illustration of all
other less favored preferences in a second pop-up window below. As we can see, the ambiguous other pronoun preference U received the second strongest activation while all other
preferences are close to 0. These shown activation preferences are the output values of the
corresponding network for basic syntactic categorization. So any shown activation value in
our snapshots shows only the most preferred hypothesis while all other hypotheses can be
shown on request10.
Within the display we can scroll up and down the descending and ascending sentence
hypotheses. Furthermore we can scroll left and right for analyzing specific longer word
hypothesis sequences. There is also a step mode which allows the screen system to wait
for an interactive mouse click to process the next incoming word hypothesis for a very
detailed analysis. This step mode can be adapted for a different number of steps (word
hypotheses) and it can be switched off completely if one decides to analyze the sentence
hypotheses later or at the end of all word hypotheses. Only the preferred of all possible
syntactic and semantic hypotheses are shown. Therefore many different hypotheses appear
to have the same size. However, by clicking on one of the squares the other less confident
hypotheses can be displayed as well.
9. The dialog acts we use are: accept (ACC), query (QUERY), reject (REJ), request-suggest (RE-S),
request-state (RE-S), state (STATE), suggest (SUG), and miscellaneous (MISC). Since this paper focuses
on the syntactic and semantic aspects of screen we do not further elaborate on the implemented dialog
part here. Further details on dialog act processing have been described previously (Wermter & Lochel,
1996).
10. In the snapshots in Figure 12 the abstract syntactic and semantic categories have not yet been computed
and therefore are represented as NIL. In the next processing step this computation will be performed
which can be seen in next Figure 13.

59

fiWermter & Weber

5.2 Analyzing the Final Snapshot in Short Sentence Hypotheses

In Figure 13 we illustrate the final state after 3.01s of the utterance. Eight possible sentence hypotheses remained out of which we see the first four in Figure 13. Starting with the
fourth sentence hypothesis \Kase ich hatte ich Marz" (\Rubbish I had I march") we can
see that this lower rated sentence hypothesis is not the desired sentence. The lower ranked
hypotheses are good examples that current state-of-the-art speech recognizers alone will not
be able to produce reliable sentence hypotheses, since the problem of analyzing spontaneous
speaker-independent speech is very complex. Therefore the syntactic and semantic components for spontaneous language have to take into account that there will be highly irregular
sequences as shown below. However, it is interesting to observe that the underlying connectionist networks always produce a preference for the syntactic and semantic interpretation
at the abstract and basic level. In fact, although the lower ranked sentence hypotheses
do not constitute the desired sentence all assigned syntactic and semantic categories are
correct for the individual word hypotheses. Of course there may be cases that a network
also could make a wrong decision for uncertain word hypotheses. However the syntactic
and semantic processing will never break for any possible sentence hypothesis, and is in this
respect different from more well-known methods like symbolic context-free chart parsers.
If we look at the top-ranked sentence hypothesis \Kase ich meine naturlich Marz" (\Rubbish I mean of course March") this is also the desired sentence. It is the most plausible
SCREEN - Symbolic Connectionist Robust EnterprisE for Natural language
Quit

Go

on line

Stop

single step

1

8 Sentencehypotheses. Time: 3.01s (System)/3.01s (Display)

N

NG DSUG

NO

NEG CONF

KSE

0

NG DSUG

ANIM AGENT CONF

ICH

N

NG DSUG

NO

NEG CONF

KSE

U

NG DSUG

NG DSUG

ANIM AGENT CONF

NO

NEG CONF

KSE

U

NG DSUG

NG DSUG

ANIM AGENT CONF

NO

NEG CONF

U

UTTER ACT

CONF

V

VG DSUG

UTTER ACT

V

HAVE

NG DSUG

V

HAVE

HTTE

A

SG DSUG

NILL

MISC CONF

NATRLICH

CONF

A

SG DSUG

NILL

MISC CONF

NATRLICH

VG DSUG

ACT

CONF

HTTE

ANIM AGENT CONF

ICH

VG DSUG

MEINE

ICH

N

V

MEINE

ICH

N

KSE

U

U

NG DSUG

ANIM AGENT CONF

ICH

VG DSUG

ACT

CONF

U

N

NG DSUG

TIME TMAT CONF

MRZ

N

NG DSUG

TIME TMAT CONF

MRZ

N

NG DSUG

TIME TMAT CONF

MRZ

NG DSUG

ANIM AGENT CONF

ICH

N

NG DSUG

TIME TMAT CONF

MRZ
0

Figure 13: Final snapshot for sentence \Kase ich meine naturlich Marz (\Rubbish I mean
of course March").
60

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

sentence based on speech and language plausibility. Furthermore, we can see that the assigned categories are correct: The German word \Kase" (\Rubbish") is found to be a noun
as part of a noun group which expresses a negation. \Ich" (\I") starts a new phrase, that is
a pronoun as a noun group which represents an animate being and an agent. The following
German word \meine" is particularly interesting since it can be used as a verb in the sense
of \mean" but also as a pronoun in the sense of \my". Therefore, the connectionist network
for the basic syntactic classification has to disambiguate these two possibilities based on
the preceding context. The network has learned to take into consideration the preceding
context and is able to choose the correct basic syntactic category verb (V) rather than
pronoun (U) for the word \meine" (\mean"). At this time a new phrase start has been
found as well. The following word \naturlich" (\of course") has the highest preference for
an adverb and a special group. Finally, the word \Marz" (\March") is assigned the highest
plausibility for a noun and noun group as well as a time at which something happens.

5.3 Phrase Starts and Phrase Groups in Longer Sentence Hypotheses

Now we will focus on a detailed analysis of a second example: \A hm ja genau allerdings
habe ich da von neun bis vier Uhr schon einen Arzttermin". The literally translated
SCREEN - Symbolic Connectionist Robust EnterprisE for Natural language
Quit

Go

on line

Stop

single step

1

10 Sentencehypotheses. Time: 2.18s (System)/2.18s (Display)

A

YES

MG DACC

CONF CONF

JA

YES

MG DACC

CONF CONF

JA

DREJ

CONF CONF

J

YES

YES

MG DACC

CONF CONF

JA

A

NILL

MG

DREJ

CONF CONF

YES

MG DACC

CONF CONF

A

NILL

NO

SG

DREJ

NEG CONF

A

NO

SG

DREJ

NEG CONF

ALLERDINGS

MG DMISC

MISC CONF

DENNOCH

A

A

ALLERDINGS

GENAU

A

JA

YES

MG

GENAU

A

0

J

MG DMISC

MISC CONF

DENNOCH

A

NO

SG DMISC

NEG CONF

ALLERDINGS

A

NO

SG DMISC

NEG CONF

ALLERDINGS

V

VG

DREJ

HAVE

ACT

CONF

HABE

VG

DREJ

HAVE

ACT

CONF

HABE

U

NILL

ACT

CONF

HAVE

NG

DREJ

MISC CONF

ACT

CONF

ANIM AGENT CONF

U

NILL

ES

DREJ

MISC CONF

NILL

SG

DREJ

MISC CONF

NILL

SG DMISC

MISC CONF

DA

MISC CONF

DREJ

HERE TMAT CONF

R

PG

DREJ

HERE TMAT CONF

R

HERE

NIL DMISC

NIL

CONF

VON

A

NILL

DA

PG

VON

A

NG DMISC

R

VON

A

NG DMISC

ICH

HABE

NILL

SG

DA

U

VG DMISC

A

DA

ES

HABE

V

DREJ

ANIM AGENT CONF

VG DMISC

HAVE

NG

ICH

V

V

U

SG DMISC

MISC CONF

R

HERE

NIL DACC

NIL

CONF

VON

0

Figure 14: First part of the snapshot for sentence \A hm ja genau allerdings habe ich
da von neun bis vier Uhr schon einen Arzttermin" (literal translation: \Yes
exactly however have I there from nine to four o'clock already a doctorappointment"; improved translation: \Eh yes exactly however then I have
a doctor appointment from nine to four o'clock").
61

fiWermter & Weber

SCREEN - Symbolic Connectionist Robust EnterprisE for Natural language
Quit

on line

Stop

Go

single step

1

10 Sentencehypotheses. Time: 4.45s (System)/4.45s (Display)

M

PG

MISC

TIME TMAT CONF

neun (nine)

M

PG

MISC

neun (nine)

M

PG

MISC

TIME TMAT CONF

PG

MISC CONF

R

NIL

R

NIL

ACC

R

NIL

bis (to)

M

PG

MISC

TIME TMAT CONF

vier (four)

PG

MISC

MISC CONF

M

PG

PG

MISC

MISC

TIME TMAT CONF

MISC CONF

M

PG

MISC

MISC

TIME TMAT CONF

MISC CONF

M

PG

MISC

TIME TMAT CONF

N

PG

MISC

TIME TMAT CONF

N

PG

MISC

TIME TMAT CONF

Uhr (oclock)

MISC

TIME TMAT CONF

zehn (ten)

PG

Uhr (oclock)

zehn (ten)

PG

N

Uhr (oclock)

vier (four)

bis (to)

TIME TMAT CONF

neun (nine)

MISC

bis (to)

neun (nine)

M

NIL

PG

bis (to)

TIME TMAT CONF

0

R

N

PG

ACC

TIME TMAT CONF

Uhr (oclock)

A

NIL

SG

MISC

MISC CONF

schon (already)

A

NIL

SG

MISC

MISC CONF

schon (already)

A

NIL

SG

MISC

MISC CONF

schon (already)

A

NIL

SG

ACC

MISC CONF

schon (already)

D

NIL

NG

RES

MISC CONF

einen (a)

D

NIL

NG

RES

MISC CONF

NIL

NG

RES

MISC CONF

NIL

NG

ABS

OBJ

CONF

N

NG

RES

ABS

OBJ

CONF

N

NG

RES

ABS

OBJ

CONF

Arzttermin(doc.app

RES

MISC CONF

einen (a)

RES

Arzttermin(doc.app

einen (a)

D

NG

Arzttermin(doc.app

einen (a)

D

N

N

NG

RES

ABS

OBJ

CONF

Arzttermin(doc.app

7

Figure 15: Second part of the snapshot for sentence \A hm ja genau allerdings habe ich
da von neun bis vier Uhr schon einen Arzttermin" (\Yes exactly however have
I there from nine to four o'clock already a doctor-appointment").
sentence to be analyzed is: \Eh yes exactly however have I there from nine to four o'clock
already a doctor-appointment". A better but non-literal translation would be: \Eh yes
exactly however then I have a doctor appointment from nine to four o'clock". During
the analysis of the first few sentence hypotheses, the interjection \ahm" (\eh") is detected
by the corresponding module in the correction part and is eliminated from the respective
sentence hypotheses.
In Figure 14 and Figure 15 we show the best found four sentence hypotheses. The
categories of these sentence hypotheses look similar but we have to keep these separate
hypotheses since they differ in their time stamps and their speech confidence values.
In these two snapshots of this longer example we can also illustrate the inuence of
the phrase starts. The sequences \von neun" (\from nine") and \bis vier Uhr" (\to four
o'clock") constitute two phrase groups which are clearly separated by the black bar before
the prepositions \von" (\from") and \bis" (\to"). All the other words \neun" (\nine"),
\vier" (\four"), and \Uhr" (\o'clock") do not start another phrase group. Since the underlying connectionist network for learning the phrase boundaries is a simple recurrent network
this example demonstrates that this network has learned the preceding context. Without
having learned that there had been a preposition \von" (\from") or \bis" (\to") a noun
62

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

like \Uhr" (\o'clock") does not have to be within a prepositional phrase group but could
also be part of a noun phrase in another context like \vier Uhr pat gut" (\four o'clock fits
well").

5.4 Dealing with Noise as Repairs
Finally we will focus on the example for the simple word graph shown in the beginning of
this paper on page 41: \A hm am sechsten April bin ich leider auer Hause". The literal
translation is \Eh on 6th April am I unfortunately out of home". Using this sentence we
will give an example for an interjection and a simple word repair. Dealing with hesitations
and repairs is a large area in spontaneous language processing and is not the main topic of
this paper (a more detailed discussion on repairs in screen can be found in previous work,
Weber & Wermter, 1996). Nevertheless, for the sake of illustration and completeness we
show the ability of screen to deal with interjections and word repairs. The first snapshot
in Figure 16 shows the start of our example sentence after 1.39s. The leading interjection
\eh" has been eliminated already.
Furthermore, we can see that the second word hypothesis sequence shows two subsequent
word hypotheses for \ich" (\I"). This is possible since there were two word hypotheses
SCREEN - Symbolic Connectionist Robust EnterprisE for Natural language
Quit

Go

on line

Stop

single step

1

18 Sentencehypotheses. Time: 1.39s (System)/1.39s (Display)

R

PG

SUG

HERE TMAT CONF

am (on)

R

PG

SUG

am (on)

R

PG

SUG

HERE TMAT CONF

TIME TMAT CONF

M

PG

SUG

TIME TMAT CONF

M

PG

SUG

TIME TMAT CONF

sechsten (6th)

PG

SUG

HERE TMAT CONF

am (on)

SUG

sechsten (6th)

am (on)

R

PG

sechsten (6th)

HERE TMAT CONF

0

M

M

PG

SUG

TIME TMAT CONF

sechsten (6th)

N

PG

SUG

TIME TMAT CONF

April (April)

N

PG

SUG

TIME TMAT CONF

PG

SUG

TIME TMAT CONF

PG

IS

ACT

CONF

V

VG

SUG

HAVE

ACT

CONF

U

PG

SUG

U

NG

STATE

ANIM AGENT CONF

ich (I)

U

NIL

STATE

ANIM

NIL

CONF

U

NIL

STATE

ANIM

NIL

CONF

ich (I)

U

NIL

SUG

ANIM

NIL

CONF

U

NIL

SUG

ANIM

NIL

CONF

NG

STATE

ich (I)

SUG

ANIM RECIP CONF

ich (I)

TIME TMAT CONF

April (April)

STATE

htte (had)

April (April)

N

VG

bin (am)

April (April)

N

V

ich (I)

V

VG

STATE

IS

ACT

CONF

bin (am)

U

ANIM AGENT CONF

ich (I)

ich (I)

0

Figure 16: First snapshot for sentence \A hm am sechsten April bin ich leider auer
Hause" (\Eh on 6th April am I unfortunately out of home").
63

fiWermter & Weber

generated by the speech recognizer which could be connected. In this case there were the
four word hypotheses shown below:
start time
1.22s
1.23s
1.23s
1.31s

end time
1.37s
1.30s
1.37s
1.38s

word hypothesis
ich (I)
ich (I)
ich (I)
ich (I)

speech plausibility
1.527688e-03
1.178415e-02
2.463924e-03
1.813340e-02

Just using this speech knowledge from the word hypotheses, it is possible to connect
the second hypothesis which runs from 1.23s to 1.30s with the fourth hypothesis which runs
from 1.31s to 1.38s. This is an example of noise generated by the speech recognizer, since
the desired sentence contains only one word \ich" (\I") but the sentence hypothesis at this
point contains two. This repetition can be treated and eliminated in the same way as actual
word repairs in language. While the reasons for the occurrence of such repairs are different
the effect of a repeated word is the same. Therefore, in this case the repeated \ich" (\I")
is eliminated from the sentence sequence. In Figure 17 we show the final snapshot of the
sentence. We can see that no word repairs occur in the top-ranked sentence hypothesis
which is also the desired sentence.
SCREEN - Symbolic Connectionist Robust EnterprisE for Natural language
Quit

on line

Stop

Go

single step

1

10 Sentencehypotheses. Time: 3.40s (System)/3.40s (Display)

M

PG

SUG

TIME TMAT CONF

sechsten (6th)

M

PG

SUG

TIME TMAT CONF

0

sechsten (6th)

M

PG

SUG

TIME TMAT CONF

sechsten (6th)

M

PG

SUG

TIME TMAT CONF

sechsten (6th)

N

PG

SUG

TIME TMAT CONF

April (April)

N

PG

SUG

TIME TMAT CONF

PG

SUG

TIME TMAT CONF

PG

IS

ACT

CONF

U

PG

SUG

U

NG

STATE

ANIM AGENT CONF

ich (I)

SUG

ANIM RECIP CONF

U

V

VG

STATE

NG

SUG

ANIM RECIP CONF

IS

ACT

CONF

VG

STATE

NG

STATE

ANIM AGENT CONF

IS

ACT

CONF

U

NO

SG

REJ

NEG CONF

A

NO

SG

REJ

NEG CONF

leider (unfort.)

ich (I)

V

bin (am)

U

A

leider (unfort.)

ich (I)

bin (am)

TIME TMAT CONF

April (April)

STATE

ich (I)

April (April)

N

VG

bin (am)

April (April)

N

V

A

NO

SG

REJ

NEG CONF

leider (unfort.)

NG

STATE

ANIM AGENT CONF

ich (I)

A

NO

SG

REJ

NEG CONF

leider (unfort.)

R

PG

REJ

HERE LCAT CONF

auer (out of)

R

PG

REJ

HERE LCAT CONF

auer (out of)

R

PG

REJ

HERE LCAT CONF

auer (out of)

R

PG

REJ

HERE LCAT CONF

auer (out of)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

N

PG

REJ

PHYS LCAT CONF

Hause (home)

1

Figure 17: Final snapshot for sentence \A hm am sechsten April bin ich leider auer
Hause" (\Eh on 6th April am I unfortunately out of home").
64

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

In general, for language repairs, screen can deal with the elimination of interjections
and pauses, the repair of word repetitions, word corrections (where the words may be
different, but their categories are the same) as well as simple forms of phrase repairs (where
a phrase is repeated or replaced by another phrase).

6. Design Analysis of SCREEN
In this section we will describe our design choices in screen. In particular we focus on the
issues why we use connectionist networks, why we reach high accuracy with little training,
and how screen can be compared to other systems and other design principles.

6.1 Why Did We Use Connectionist Networks in SCREEN?
In the past, n-gram based techniques have been used successfully for tasks like syntactic
category prediction or part of speech tagging. Therefore, it is possible to ask why we developed simple recurrent networks in screen. In this subsection we will provide a detailed
comparison of simple recurrent networks and n-gram techniques for the prediction of basic
syntactic categories. We chose this task for a detailed comparison since it is currently the
most dicult task for a simple recurrent network in screen. So purposefully we did not
choose a subtask for which a simple recurrent network had a very high accuracy, but the
prediction task since it is more dicult to predict a category compared to disambiguating among categories, for instance. So we chose the dicult prediction with a relatively
low network performance in order to be (extremely) fair for the comparison with n-gram
techniques.
We are primarily interested in the generalization behavior for new unknown input.
Therefore Figure 18 shows the accuracy of the syntactic prediction for the unknown test
set. After each word several different syntactic categories can follow and some syntactic
categories are excluded. For instance, after a determiner \the" an adjective or a noun can
follow: \the short ...", \the appointment", but after a determiner \the" a preposition is
implausible to occur and should most probably be excluded. Therefore it is important to
know how many categories can be ruled out and Figure 18 shows the relationship between
the prediction accuracy and the number of excluded categories for n-grams and our simple
recurrent network (as described in Figure 8).
As we can expect, for both techniques, n-grams and recurrent networks, the prediction
accuracy is higher if only a few categories have to be excluded and the performance is lower
if many categories have to be excluded. However, more interestingly, we can see that simple
recurrent networks performed better than 1-grams, 2-grams, 3-grams, 4-grams and 5-grams.
Furthermore, it is interesting to note that higher n-grams do not necessarily lead to better
performance. For instance, the 4-grams and 5-grams perform worse than 2-grams since they
would probably need much larger training sets.
We did the same comparison of n-grams (1-5) and simple recurrent networks also for
semantic prediction and received the same result that simple recurrent networks performed
better than n-grams. The performance of the best n-gram was often only slightly worse
than the performance of the simple recurrent network, which indicates that n-grams are a
reasonably useful technique. However, in all comparisons simple recurrent networks per65

fiWermter & Weber

Testset
100

correct prediction in %

80

60

40

SRN
1gram
2gram
3gram
4gram
5gram

20

0
0

2

4

6

8

10

12

number of excluded categories

Figure 18: Comparison between simple recurrent network and n-grams
formed at least slightly better than the best n-grams. Therefore, we used simple recurrent
networks as our primary technique for connectionist sequence learning in screen.
How can we explain this result? N-grams like 2-grams still perform reasonably well
for our task and simple recurrent networks are closest to their performance. However,
simple recurrent networks perform slightly better since they do not contain a fixed and
limited context. In many sequences, the simple recurrent network may primarily use the
directly preceding word representation to make a prediction. However, in some exceptions
more context is required and the recurrent network has a memory of the internal reduced
representation of the preceding context. Therefore, it has the potential to be more exible
with respect to the context size.
N-grams may not perform optimally but they are extremely fast. So the question arises
how much time is necessary to compute a new category using new input and the current
context for the network. In general our networks differ slightly in size but typically they
contain several hundred weights. For a typical representative simple recurrent network with
13 input units, 14 hidden units, 8 output units, and 14 context units, and about 500 weights
it takes 10,4 s on a Sparc Ultra to compute a new category within the whole forward sweep.
66

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

Since the techniques for smoothed n-grams basically rely on an ecient table-look-up
of precomputed values, of course typical n-gram techniques are still faster. However, due to
their fixed-size context they may not perform as well as simple recurrent networks. Furthermore, computing the next possible categories in 10,4s is fast enough for our current version
of screen. For the sake of an explanation one could argue that screen contains about 10
networks modules and a typical utterance contains 10 words, so a single utterance hypothesis could be performed in 10,2 s. However, different from text tagging, we do not have single
sentences but we process word graphs. Depending on the specific utterance, about 105 word
hypothesis sequences could be generated and have to be processed. Furthermore there is
some book-keeping required for keeping the best word hypotheses, for loading the appropriate networks with the appropriate word hypotheses, etc. The potentially large number of
word hypotheses, the additional book-keeping performance, and the number of individual
modules for syntax, semantics and dialog processing explain why the total analysis time of
the whole unoptimized screen system is in the order of seconds although a single recurrent
network performs in the order of 10,4 s.

6.2 Improvement in the Hypothesis Space
In this subsection we will analyze to what extent the syntactic and semantic prediction
knowledge can be used to improve the best found sentence hypotheses. We illustrate the
pruning performance in the hypothesis space by integrating acoustic, syntactic, and semantic knowledge. While the speech recognizer alone provides only acoustic confidence
values, screen adds syntactic and semantic knowledge. All these knowledge sources are
weighted equally in order to compute a single plausibility value for the current word hypothesis sequence. This plausibility value is used in the speech construction part to prune
the hypothesis space and to select the currently best word hypothesis sequences. Several
word hypothesis sequences are processed incremental and in parallel. At a given time the
11
n best incremental word hypothesis sequences are kept .
The syntactic and semantic plausibility values are based on the basic syntactic and semantic prediction (bas-syn-pre and bas-sem-pre) of the next possible categories for a
word and the selection of a preference by the determined basic syntactic respectively semantic category (bas-syn-dis and bas-sem-dis)12 . The performance of the disambiguation
modules is 86%-89% for the test set. For the prediction modules the performance is 72%
and 81% for the semantic and syntactic test set, respectively if we want to exclude at least
8 of the 12 possible categories. This performance allows us the computation of a syntactic
and semantic plausibility in syn-speech-error and sem-speech-error. Based on the
combined acoustic, syntactic, and semantic knowledge, first tests on the 184 turns show
that the accuracy of the constructed sentence hypotheses of screen could be increased
by about 30% using acoustic and syntactic plausibilities and by about 50% using acoustic,
syntactic, and semantic plausibilities (Wermter & Weber, 1996a).
11. In our experiments low values (n = 10) provided the best overall performance.
12. This was explained in more detail in Section 4.3.2

67

fiWermter & Weber

6.3 SCREEN's Network Performance and Why the Networks Yield High
Accuracy with Little Training

For evaluating the performance of screen's categorization part on the meeting corpus we
first show the percentages of correctly classified words for the most important networks for
categorization: bas-syn-dis, bas-sem-dis, abs-syn-cat, abs-sem-cat, phrase-start.
There were 184 turns in this corpus with 314 utterances and 2355 words. 1/3 of the 2355
words and 184 turns was used for training, 2/3 for testing. Usually more data is used for
training than testing. In preliminary earlier experiments we had used 2/3 for training and
1/3 for testing. However, the performance on the unknown test set was similar for the 1/3
training set and 2/3 test set. Therefore, we used more testing than training data since we
were more interested in the generalization performance for unknown instances in the test
set compared to the training performance for known instances.
At first sight, it might seem relatively little data for training. While statistical techniques
and information retrieval techniques often work on large texts and individual lexical word
items, we need much less material to get a reasonable performance since we work on the
syntactic and semantic representations rather than the words. We would like to stress that
we use the syntactic and semantic category representations of 2355 words for training and
testing rather than the lexical words themselves. Therefore, the category representation
requires much less training data than a lexical word representation would have required. As
a side effect, also training time was reduced for the 1/3 training set, while keeping the same
performance on the 2/3 test set. That is, for training we used category representations from
64 dialog turns, for testing generalization the category representations from the remaining
120 dialog turns.
Table 5 shows the test results for individual networks on the unknown test set. These
networks were trained for 3000 epochs with a learning rate of 0.001 and 14 hidden units.
This configuration had provided the best performance for most of the network architectures.
In general we tested network architectures from 7 to 28 hidden units, learning parameters
from 0.1 to 0.0001. As learning rule we used the generalized delta rule (Rumelhart et al.,
1986). An assigned output category representation for a word was counted as correct if the
category with the maximum activation was the desired category.
Module

Accuracy on test set
bas-syn-dis
89%
bas-sem-dis
86%
abs-syn-cat
84%
abs-sem-cat
83%
phrase-start
90%
word-error
94%
phrase-error
98%

Table 5: Performance of the individual networks on the test set of the meeting corpus
The performance for the basic syntactic disambiguation was 89% on the unknown test
set. Current syntactic (text-)taggers can reach up to about 95% accuracy on texts. However,
68

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

there is a big difference between text and speech parsing due to the spontaneous noise
in spoken language. The interjections, pauses, repetitions, repairs, new starts and more
\ungrammatical" syntactic varieties in our spoken-language domain are reasons why the
typical accuracy of other syntactic text taggers has not been reached.
On the other hand we see 86% accuracy for the basic semantic disambiguation which
is relatively high for semantics. So there is some evidence that the noisy \ungrammatical"
variety of spoken language hurts syntax but less semantics. Due to the domain dependence
of semantic classifications it is more dicult to compare and explain semantic performance.
However, in a different study within the domain of railway interactions we could reach a
similar performance (for details see Section 6.6). In all our experiments syntactic results
were better than the semantic results, indicating that the syntactic classification was easier
to learn and generalize. Furthermore, our syntactic results were close to 90% for noisy
spoken language which we consider to be very good in comparison to 95% for more regular
text language.
The performance for the abstract categories is somewhat lower than for the basic categories since the evaluation at each word introduces some unavoidable errors. For instance,
after \in" the network cannot yet know if a time or location will follow, but has to make
an early decision already. In general, the networks perform relatively well on this dicult
real-world corpus, given that we did not eliminate any sentence for any reason and took all
the spontaneous sentences as they had been spoken.
Furthermore, we use transcripts of spontaneous language for training in the domain
of meeting arrangements. Most utterances are questions and answers about dates and
locations. This restricts the potential syntactic and semantic constructions, and we certainly
benefit from the restricted domain. Furthermore, while some mappings are ambiguous for
learning (e.g., a noun can be part of a noun group or a prepositional group) other mappings
are relatively unambiguous (e.g., a verb is part of a verb group). We would not expect
the same performance on mixed arbitrary domains like the random spoken sentences about
various topics from passers-by in the city. However, the performance in somewhat more
restricted domains can be learned in a promising manner (for a transfer to a different
domain see Section 6.6). So there is some evidence that simple recurrent networks can
provide good performance using small training data from a restricted domain.

6.4 SCREEN's Overall Output Performance
While we just described the individual network performance, we will now focus on the
performance of the running system. The performance in the running screen system has to
be different from the performance of the individual networks for a number of reasons. First,
the individual networks are trained separately in order to support a modular architecture.
In the running screen system, however, connectionist networks receive their input from
other underlying networks. Therefore, the actual input to a connectionist network in the
running screen system may also differ from the original training and test sets. Second, the
spoken sentences may contain errors like interjections or word repairs. These have to be part
of the individual network training, but the running screen system is able to detect and
correct certain interjections, word corrections and phrase corrections. Therefore, system
and network performance differ at such disuencies. Third, if we want to evaluate the
69

fiWermter & Weber

performance of abstract semantic categorization and abstract syntactic categorization we
are particularly interested in certain sentence parts. For abstract syntactic categorization,
e.g., the detection of a prepositional phrase, we have to consider that the beginning of a
phrase with its significant function word, e.g., preposition, should be the most important
location for syntactic categorization. In contrast, for abstract semantic categorization, the
content word at the end of a phrase group, directly before the next phrase start, is most
important.
Correct at syntactic output representation 74%
Correct at semantic output representation 72%

Table 6: Overall syntactic and semantic accuracy of the running screen system on the
unknown test set of the meeting corpus
As we should expect based on the explanation in the previous paragraph, the overall accuracy of the output of the complete running system should be lower than the performance
of the individual modules. In fact, this is true and Table 6 shows the overall syntactic and
semantic phrase accuracy of the running screen system. 74% of all assigned syntactic
phrase representations of the unknown test set are correct and 72% of all assigned semantic
phrase representations. The slight performance drop can be partially explained by the more
uncertain input from other underlying networks which themselves are inuenced by other
networks. On the other hand, in some cases the various decisions by different modules (e.g.
the three modules for lexical, syntactic and semantic category equality of two words) can
be combined in order to clean up some errors (e.g. a wrong decision by one single module).
In general, given that the 120 dialog turns of the test set were completely unrestricted, unknown real-world and spontaneous language turns, we believe that the overall performance
is quite promising.

6.5 SCREEN's Overall Performance for an Incomplete Lexicon

One important property of screen is its robustness. Therefore, it is an interesting question
how screen would behave if it could only receive incomplete input from its lexicon. Such
situations are realistic since speakers could use new words which a speech recognizer has
not seen before. Furthermore, we can test the robustness of our techniques. While standard
context-free parsers usually cannot provide an analysis if words are missing from the lexicon,
screen would not break on missing input representations, although of course we have to
expect that the overall classification performance must drop if less reliable input is provided.
In order to test such a situation under the controlled inuence of removing items from
the lexicon, we first tested a scenario where we randomly eliminated 5% of the syntactic and
semantic lexicon representations. If a word was unknown, screen used a single syntactic
and single semantic average default vector instead. This average default vector contained
the normalized frequency of each syntactic respectively semantic category across the lexicon.
Even without 5% of all lexicon entries all utterances could still be analyzed. So screen
does not break for missing word representations but attempts to provide an analysis as good
70

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

Correct at syntactic output representation 72%
Correct at semantic output representation 67%

Table 7: Overall syntactic and semantic accuracy of the running screen system for the
meeting corpus on the unknown test set after 5% of all lexicon entries were eliminated
as possible. As expected, Table 7 shows a performance drop for the overall syntactic and
semantic accuracy. However, compared to the 74% and 72% performance for the complete
lexicon (see Table 6) we still find that 72% of the syntactic output representations and 67%
of the semantic output representations are correct after eliminating 5% of all lexicon entries.
Correct at syntactic output representation 70%
Correct at semantic output representation 67%

Table 8: Overall syntactic and semantic accuracy of the running screen system for the
meeting corpus on the unknown test set after 10% of all lexicon entries were
eliminated
In another experiment we eliminated 10% of all syntactic and semantic lexicon entries.
In this case, the syntactic accuracy was still 70% and the semantic accuracy was 67%.
Eliminating 10% of the lexicon led to a syntactic accuracy reduction of only 4% (74%
versus 70%) and a semantic accuracy reduction of 5% (72% versus 67%). In general we
see that in all our experiments the percentage of accuracy reduction was much less than
the percentage of eliminated lexicon entries demonstrating screen's robustness for working
with an incomplete lexicon.

6.6 Comparison with the Results in a New Different Domain

In order to compare the performance of our techniques, we will also show results from
experiments with a different spoken Regensburg Train Corpus. Our intention cannot be to
describe the experiments in this domain at the same level of detail as we have done for our
Blaubeuren Meeting Corpus in this paper. However, we will provide a summary in order
to provide a point of reference and comparison for our experiments on the meeting corpus.
This comparison serves as another additional possibility to judge our results for the meeting
corpus.
As a different domain we chose 176 dialog turns at a railway counter. People ask
questions and receive answers about train connections. A typical utterance is: \Yes I need
eh a a sleeping car PAUSE from PAUSE Regensburg to Hamburg". We used exactly the
same screen communication architecture to process spoken utterances from this domain:
the same architecture was used, 1/3 of the dialog turns was used for training, 2/3 for
71

fiWermter & Weber

testing on unseen unknown utterances. For syntactic processing, we even used exactly the
same network structure, since we did not expect much syntactic differences between the
two domains. Only for semantic processing we retrained the semantic networks. Different
categories had to be used for semantic classification, in particular for actions. While actions
about meetings (e.g., visit, meet) were predominant in the meeting corpus, actions about
selecting connections (e.g., choose, select) were important in the train corpus (Wermter &
Weber, 1996b). Just to give the reader an impression of the portability of screen, we
would estimate that 90% of the original human effort (system architecture, networks) could
be used in this new domain. Most of the remaining 10% were needed for the necessary new
semantic tagging and training in the new domain.
Module

Accuracy on test set
bas-syn-dis
93%
bas-sem-dis
84%
abs-syn-cat
85%
abs-sem-cat
77%
phrase-start
89%
word-error
94%
phrase-error
98%

Table 9: Performance of the individual networks on the test set in the train corpus
Table 9 shows the performance on the test set in the train corpus. If we compare our
results in the meeting corpus (Table 5) with these results in the train corpus we see in
particular that the abstract syntactic processing is almost the same in the meeting corpus
(84% in Table 5 compared to 85% in Table 9) but the abstract semantic processing is better
in the meeting corpus (83% in Table 5 compared to 77% in Table 9). Other modules dealing
with explicit robustness for repairs (phrase start, word repair errors, phrase repair errors)
show almost the same performance (90% vs 89%, 94% vs 94%, 98% vs 98%).
Correct at syntactic output representation 76%
Correct at semantic output representation 64%

Table 10: Overall syntactic and semantic accuracy of the running screen system on the
unknown test set of a different train corpus
As a comparison we summarize here the overall performance for this different train
domain. Table 10 shows that screen has about the same syntactic performance in the two
domains (compare with Table 6). So in this different domain we can essentially confirm our
previous results for syntactic processing performance (74% vs. 76%). However, semantic
processing appears to be harder in the train domain since the performance of 64% is lower
than the 72% in the meeting domain. However, semantic processing, semantic tagging or
semantic classification is often found to be much harder than syntactic processing in general,
72

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

so that the difference is still within the range of usual performance differences in syntax and
semantics. Since semantic categories like agents, locations, and time expressions are about
the same in these two domains the more dicult action categorization is mainly responsible
for this difference in semantic performance between the two domains.
In general the transfer from one domain to another only requires a limited amount of
hand-modeling. Of course, syntactic and semantic categories have to be specified for the
lexicon and the transcripts. These syntactically or semantically tagged transcript sentences
are the direct basis for generating the training sets for the networks. Generating these
trainings sets is the main manual effort while transferring the system to a new domain.
After the generation of the training sets has been performed the training of the networks
can proceed automatically. The training of a typical single recurrent network takes in the
order of a few hours. So much less manual work is required than for transferring a standard
symbolic parser to a new domain and generating a new syntactic and semantic grammar.

6.7 An Illustrative Comparison Argument Based on a Symbolic Parser
We have made the point that screen's learned at representations are more robust than
hand-coded deeply structured representations. Here we would like to elaborate this point
with a compelling illustrative argument. Consider different variations of sentence hypotheses
from a speech recognizer in Figure 19: 1. A correct sentence hypothesis: \Am sechsten
April bin ich auer Hause" (\On 6th April am I out of home") and 2. A partially incorrect
1.Input: AM SECHSTEN APRIL BIN ICH AUER HAUSE
(ON 6th APRIL AM I OUT OF HOME)
1.Output:
S
PP

,!
VP

NP

NP

NG

NG

R

PP

V

NP

ADJG
N

U

ADJ
am(on)

sechsten(6th)April(April)

R

NG
N

bin(am)

2.Input: AM SECHSTEN APRIL ICH ICH AUER HAUS
(ON 6th APRIL I I OUT OF HOME)
2.Output:NIL (NO ANALYSIS POSSIBLE)

ich(I)

auer(out_of) Hause(home)

,!

Figure 19: Two sentence hypotheses from a speech recognizer. The first hypothesis can
be analyzed, the second partially incorrect hypothesis cannot be analyzed
anymore by the symbolic parser.
73

fiWermter & Weber

sentence hypothesis: \Am sechsten April ich ich auer Hause" (\On 6th April I I out of
home"). Focusing on the syntactic analysis, we used an existing chart parser and an existing
grammar which had been used extensively for other real-world parsing up to the sentence
level (Wermter, 1995). The only necessary significant adaptation was the addition of a rule
N G ! U for pronouns, which had not been part of the original grammar. This rule states
that a pronoun U (e.g., \I") can be a noun group (NG).
If we run the first sentence hypothesis through the symbolic context-free parser we receive the desired syntactic analysis shown in Figure 19, but if we run the second slightly
incorrect sentence hypothesis through the parser we do not receive any analysis (The syntactic category abbreviations in Figure 19 are used in the same manner as throughout the
paper (see Table 1-4); furthermore and as usual, \S" stands for sentence, \ADJG" for adjective group, \NP" for complex nominal phrase, \VP" for verb phrase. The literal English
translations are shown in brackets).
The reason why the second sentence hypothesis could not be parsed by the context-free
chart parser was that the speech recognizer generated incorrect output. There is no verb
in the second sentence hypothesis and there is an additional pronoun \I". Such mistakes
occur rather frequently based on the imperfectness of current speech recognition technology.
Of course one could argue that the grammar should be relaxed and made more exible to
deal with such mistakes. However, the more rules for fault detection are integrated into
the grammar or the parser the more complicated the grammar or the parser. Even more
important, it is impossible to predict all possible mistakes and integrate them into a symbolic
context-free grammar. Finally, relaxing the grammar for dealing with mistakes by using
explicit specific rules also might lead to other additional mistakes because the grammar now
has to be extremely underspecified.
As we have shown, for instance in Figure 17, screen does not have problems dealing with
such speech recognizer variations and mistakes. The main difference between a standard
context-free symbolic chart parser analysis and screen's analysis is that screen has learned
to provide a at analysis under noisy conditions but the context-free parser has been handcoded to provide a more structural analysis. It should be emphasized here that we do
not make an argument against structural representations per se and in general. The more
structure that can be provided the better, particularly for tasks which require structured
world knowledge. However, if robustness is a major concern, as it is for lower syntactic and
semantic spoken-language analysis, a learned at analysis provides more robustness.

6.8 Comparisons with Related Hybrid Systems
Recently, connectionist networks have received a lot of attention as computational learning
mechanisms for written language processing (Reilly & Sharkey, 1992; Miikkulainen, 1993;
Feldman, 1993; Barnden & Holyoak, 1994; Wermter, 1995). In this paper however, we have
focused on the examination of hybrid connectionist techniques for spoken language processing. In most previous approaches to speech/language processing processing was often
sequential. That is, one module like the speech recognizer or the syntactic analyzer completed its work before the next module like a semantic analyzer started to work. In contrast,
screen works incrementally which allows the system (1) to have modules running in par74

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

allel, (2) to integrate knowledge sources very early, and (3) to compute the analysis more
similar to humans since humans start to process sentences before they may be completed.
We will now compare our approach to related work and systems. A head-to-head comparison with a different system is dicult based on different computer environments and
whether systems can be accessed and adapted easily for the same input. Furthermore,
different systems are typically used for different purposes with different language corpora,
grammars, rules, etc. However, we have made an extensive effort for a fair conceptual
comparison.
parsec (Jain, 1991) is a hybrid connectionist system which is embedded in a larger
speech translation effort janus (Waibel et al., 1992). The input for parsec is sentences,
the output is case role representations. The system consists of several connectionist modules
with associated symbolic transformation rules for providing transformations suggested by
the connectionist networks. While it is parsec's philosophy to use connectionist networks
for triggering symbolic transformations, screen uses connectionist networks for the transformations themselves. It is screen's philosophy to use connectionist networks wherever
possible and symbolic rules only where they are necessary.
We found symbolic processing particularly useful for simple known tests (like lexical
equality) or for complex control tasks of the whole system (when does a module communicate to which other module). Much of the actual transformational work can be done
by trained connectionist networks. This is in contrast to the design philosophy in parsec
where connectionist modules provide control knowledge which transformation should be
performed. Then the selected transformation is actually performed by a symbolic procedure. So screen uses connectionist modules for transformations and a symbolic control,
while parsec uses connectionist modules for control and symbolic procedures for the transformations.
Different from screen, parsec receives sentence hypotheses either as sentence transcripts or as N-best hypotheses from the janus system. Our approach receives incremental
word hypotheses which are used in the speech construction part to build sentence hypotheses. This part is also used to prune the hypothesis space and to determine the best sentence
hypotheses. So during the at analysis in screen the semantic and syntactic plausibilities
of a partial sentence hypothesis can still inuence which partial sentence hypotheses are
processed.
For parsec and for screen a modular architecture was tested which has the advantage
that each connectionist module has to learn a relatively easy subtask. In contrast to the
development of parsec it is our experience that modularity requires less training time.
Furthermore, some modules in screen are able to work independently from each other
and in parallel. In addition to syntactic and semantic knowledge, parsec can make use of
prosodic knowledge while screen currently does not use prosodic hints. On the other hand,
screen also contains modules for learning dialog act assignment while such modules are
currently not part of parsec. Learning dialog act processing is important for determining
the intended meaning of an utterance (Wermter & Lochel, 1996).
Recent further extensions based on parsec provide more structure and use annotated
linguistic features (Bu et al., 1994). The authors state that they \implemented (based
on parsec) a connectionist system" which should approximate a shift reduce parser. This
connectionist shift-reduce parser substantially differs from the original parsec architecture.
75

fiWermter & Weber

We will refer to it as the \parsec extension". This parsec extension labels a complete
sentence with its first level categories. These first level categories are input again to the
same network in order to provide second level categories for the complete sentence and so
on, until at the highest level the sentence symbol can be added.
Using this recursion step the parsec extension can provide deeper and more structural
interpretations than screen currently does. However, this recursion step and the construction of the structure also have their price. First, labels like NP for a noun phrase have to be
defined as lexical items in the lexicon. Second, and more important, the complete utterance
is labeled with the n-th level categories before processing with the n+1-th level categories
starts. Therefore several parses (e.g., 7 for the utterance \his big brother loved himself")
through the utterance are necessary. This means that this recent parsec extension is more
powerful than screen and the original parsec system by Jain with respect to the opportunity to provide deeper and more structural interpretations. However, at the same time this
parsec extension looses the possibility to process utterances in an incremental manner.
However, incrementality is a very important property in spoken-language processing and
in screen. Besides the fact that humans process language in an incremental left-to-right
manner, this also allows screen to prune the search space of incoming word hypotheses
very early.
Comparing parsec and screen, parsec aims more at supporting symbolic rules by using symbolic transformations (triggered by connectionist networks) and by integrating linguistic features. Currently, the linguistic features in the recent parsec extension (Bu et al.,
1994) provide more structural and morphological knowledge than screen does. Therefore,
currently it appears to be easier to integrate the parsec extension into larger systems of
high level linguistic processing. In fact, parsec has been used in the context of the janus
framework. On the other hand, screen aims more at robust and incremental processing
by using a word hypothesis space, specific repair modules, and more at representations.
In particular, screen emphasizes more the robustness of spoken-language processing, since
it contains explicit repair mechanisms and implicit robustness. Explicit robustness covers
often occurring errors (interjections, pauses, word and phrase repairs) in explicit modules,
while other less predictable types of errors are only supported by the implicit similaritybased robustness from the connectionist networks themselves. In general, the representations generated by the extension of parsec provide better support for deeper structures
than screen, but screen provides better support for incremental robust processing. In a
more recent extension based on parsec called feaspar, the overall parsing performance was
a syntactic and semantic feature accuracy of 33.8%. Although additional improvements can
be shown using subsequent search techniques on the parsing results, we did not consider
such subsequent search techniques for better parses since they would violate incremental
processing (Bu, 1996). Without using subsequent search techniques screen reaches an
overall semantic and syntactic accuracy between 72% and 74% as shown in Table 6. However
it should be pointed out, that screen and feaspar use different input sentences, features
and architectures.
Besides parsec also the berp and trains systems focus on hybrid spoken-language processing. berp (Berkeley Restaurant Project) is a current project which employs multiple
different representations for speech/language analysis (Wooters, 1993; Jurafsky et al., 1994,
1994b). The task of berp is to act as a knowledge consultant for giving advice about choos76

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

ing restaurants. There are different components in berp: The feature extractor receives
digitized acoustic data and extracts features. These features are used in the connectionist phonetic probability estimation. The output of this connectionist feedforward network
is used in a Viterbi decoder which uses a multiple pronunciation lexicon and different language models (e.g. bigram, hand-coded grammar rules). The output of the decoder are word
strings which are transformed into database queries by a stochastic chart parser. Finally, a
dialog manager controls the dialog with the user and can ask questions.
berp and screen have in common the ability to deal with errors from humans and from
the speech recognizer as well as a relatively at analysis. However, for reaching this robustness in berp a probabilistic chart parser is used to compute all possible fragments at first.
Then, an additional fragment combination algorithm is used for combining these fragments
so that they cover the greatest number of input words. Different from this sequential process
of first computing all fragments of an utterance and then combining the fragments, screen
uses incremental processing and desirably provides the best possible interpretation. In this
sense screen's language analysis is weaker but more general. screen's analysis will never
break and produce the best possible interpretation for all noisy utterances. This strategy
may be particularly useful for incremental translation. On the other hand, berp's language
analysis is stronger but more restricted. berp's analysis may stop at the fragment level if
there are contradictory fragments. This strategy may be particularly useful for question
answering where additional world knowledge is necessary and available.
trains is a related spoken-language project for building a planning assistant who can
reason about time, actions, and events (Allen, 1995; Allen et al., 1995). Because of this
goal of building a general framework for natural language processing and planning for
train scheduling, trains needs a lot of commonsense knowledge. In the scenario, a person
interacts with the system in order to find solutions for train scheduling in a cooperative
manner. The person is assumed to know more about the goals of the scheduling while
the system is supposed to have the details of the domain. The utterance of a person is
parsed by a syntactic and semantic parser. Further linguistic reasoning is completed by
modules for scoping and reference resolution. After the linguistic reasoning, conversation
acts are determined by a system dialog manager and responses are generated based on a
template-driven natural language generator. Performance phenomena in spoken language
like repairs and false starts can currently be dealt with already (Heeman & Allen, 1994b,
1994a). Compared to screen, the trains project focuses more on processing spoken
language at an in-depth planning level. While screen uses primarily a at connectionist
language analysis, trains uses a chart parser with a generalized phrase structure grammar.

7. Discussion
First we will focus on what has been learned for processing spoken-language processing.
When we started the screen project, it was not predetermined whether a deep analysis
or a at screening analysis would be particularly appropriate for robust analysis of spoken
sentences. A deep analysis with highly structured representations is less appropriate since
the unpredictable faulty variations in spoken language limit the usefulness of deep structured knowledge representations much more than it is the case for written language. Deep
interpretations and very structured representations - as for instance possible with HPSG
77

fiWermter & Weber

grammars for text processing - make a great deal of assumptions and predictions which do
not hold for faulty spoken language. Furthermore, we have learned that for generating a
semantic and syntactic representation we do not even need to use a deep interpretation for
certain tasks. For instance, for translating between two languages it is not necessary to
disambiguate all prepositional phrase attachment ambiguities since during the process of
translation these disambiguations may get ambiguous again in the target language.
However, we use some structure at the level of words and phrases for syntax and semantics respectively. We learned that a single at semantics level rather than the four at
syntax and semantics levels is not sucient since syntax is necessary for detecting phrase
boundaries. One could argue that one syntactic abstract phrase representation and one
abstract semantic phrase representation may be enough. However, we found that the basic
syntactic and semantic representations at the word level make the task easier for the subsequent abstract analysis at the phrase level. Furthermore, the basic syntactic and semantic
representations are necessary for other tasks as well, for instance for the judgment of the
plausibility of a sequence of syntactic and semantic categories. This plausibility is used as
a filter for finding good word hypothesis sequences. Therefore, we argue that for processing
faulty spoken language - for a task like sentence translation or question answering - we
need much less structured representations as are typically used in well-known parsers but
we need more structured representations than those of a single-level tagger.
In some of our previous work we had made early experiences with related connectionist
networks for analyzing text phrases. Moving from analyzing text phrases to analyzing unrestricted spoken utterances, there are tremendous differences in the two tasks. We found that
the phrase-oriented at analysis used in scan (Wermter, 1995) is advantageous in principle
for spoken-language analysis and the phrase-oriented analysis is common to learning text
and speech processing. However, we learned that spoken-language analysis needs a much
more sophisticated architecture. In particular, since spoken language contains many unpredictable errors and variations, fault tolerance and robustness are much more important.
Connectionist networks have an inherent implicit robustness based on their similarity-based
processing in gradual numerical representations. In addition, we found that for some classes
of relatively often occurring mistakes, there should be some explicit robustness provided by
machinery for interjections, word and phrase repairs. Furthermore, the architecture has
to consider the processing of a potentially large number of competing word hypothesis
sequences rather than a single sentence or phrase for text processing.
Now, we will focus on what has been learned about connectionist and hybrid architectures. In the beginning we did not predetermine whether connectionist methods would
be particularly useful for control or for individual modules or for both. However, during the development of the screen system it became clear that for the general task of
spoken language understanding, individual subtasks like syntactic analysis had to be very
fault-tolerant because of the \noise" in spoken language, due both to humans and to speechrecognizers as well. Especially unforeseeable variations often occur in spontaneously spoken
language and cannot be predefined well in advance as symbolic rules in a general manner.
This fault-tolerance at the task level could be supported particularly well by the inherent
fault-tolerance of connectionist networks for individual tasks and the support of inductive
learning algorithms. So we learned that for a at robust understanding of spoken-language
connectionist networks are particularly effective within individual subtasks.
78

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

There has been quite a lot of work on control in connectionist networks. However,
in many cases these approaches have concentrated on control in single networks. Only
recently there has been more work on control in modular architectures (Sumida, 1991;
Jacobs et al., 1991b; Jain, 1991; Jordan & Jacobs, 1992; Miikkulainen, 1996). For instance,
in the approach by Jacobs and Jordan (Jacobs et al., 1991b; Jordan & Jacobs, 1992), task
knowledge and control knowledge are learned both. Task knowledge is learned in individual
task networks, and higher control networks are responsible for learning when a single task
network is responsible for producing the output. Originally it was an open question whether
a connectionist control would be possible for processing spoken language. While automatic
modular task decomposition (Jacobs et al., 1991a) can be done for simple forms of function
approximation, more complex problems like understanding spoken language in real-world
environments still need designer-based modular task decomposition for the necessary tasks.
We learned that connectionist control in an architecture with a lot of modules and
subtasks currently seems to be beyond the capabilities of current connectionist networks.
It has been shown that connectionist control is possible for a limited number of connectionist modules (Miikkulainen, 1996; Jain, 1991). For instance Miikkulainen shows that
a connectionist segmenter and a connectionist stack can control a parser to analyze embedded clauses. However, the communication paths still have to be very restricted within
these three modules. Especially for a real-world system for spoken-language understanding from speech, over syntax, semantics to dialog processing for translation it is extremely
dicult to learn to coordinate the different activities, especially for a large parallel stream
of word hypothesis sequences. We believe that it may be possible in the future, however
currently connectionist control in screen is restricted to the detection of certain hesitations
phenomena like corrections.
Considering at screening analysis of spoken language and hybrid connectionist techniques together, we have developed and followed a general guideline (or design philosophy )
of using as little knowledge as necessary while getting as far as possible using connectionist
networks wherever possible and symbolic representations where necessary. This guideline
led us to (1) a at but robust representation of spoken-language analysis and to (2) the
use of hybrid connectionist techniques which support the task by the choice of the possibly
most appropriate knowledge structure. Many hybrid systems contain just a small portion
of connectionist representations in addition to many other modules, e.g. berp (Wooters,
1993; Jurafsky et al., 1994, 1994b), janus (Waibel et al., 1992), trains (Allen, 1995; Allen
et al., 1995). In contrast, most of the important subtasks in screen are performed directly
by many connectionist networks.
Furthermore, we have learned that at syntactic and semantic representations could give
surprisingly good training and test results when trained and tested with a medium corpus
of about 2300 words in the 184 dialog turns. These good results are mostly due to the
learned internal weight representation and the local context which adds sequentiality to the
category assignments. Without the internal weight representation of the preceding context
the syntactic and semantic categorization does not perform equally well, so the choice of
recurrent networks is crucial for many sequential category assignments. Therefore these
networks and techniques hold potential especially for such medium-size domains where a
restricted amount of training material is available. While statistical techniques are often
79

fiWermter & Weber

used for very large data sets, but do not work well for medium data sets, the connectionist
techniques we used work well for medium-size domains.
The used techniques can be ported to different domains and be used for different purposes. Even if different sets of categories would have to be used the learning networks are
able to extract these syntactic regularities automatically. Besides the domain of arranging
business meetings we have also ported screen to the domain of interactions at a railway
counter with comparable syntactic and semantic results. These two domains differed primarily in their semantic categories, while the syntactic categories (and networks) of screen
could be used directly.
screen has the potential for scaling up. In fact, based on the imperfect output of a
speech recognizer, several thousand sentence hypotheses have already been processed. If
new words are to be processed, their syntactic and semantic basic categories are simply
entered into the lexicon. The structure of individual networks does not change, new units
do not have to be added and therefore the networks do not have to be retrained.
The amount of hand-coding is restricted primarily to the symbolic control of the module
interaction and to the labeling of the training material for the individual networks. When
we changed the domain to railway counter interactions, we could use the identical control,
as well as the syntactic networks. Only the semantic networks had to be retrained due to
the different domain.
So far we have focused on supervised learning in simple recurrent networks and feedforward networks. Supervised learning still requires a training set and some manual labeling
work still has to be done. Although especially for medium size corpora labeling examples
is easier than for instance designing complete rule bases it would be nice to automate the
knowledge acquisition even further. Currently we plan to build a more sophisticated lexicon component which will provide support for automatic lexicon design (Riloff, 1993) and
dynamic lexicon entry determination using local context (Miikkulainen, 1993).
Furthermore, screen could be expanded at the speech construction and evaluation
part. The syntactic and semantic hypotheses could be used for more interaction with the
speech recognizer. Currently syntactic and semantic hypotheses from the speech evaluation
part are used to exclude unlikely word hypothesis sequences from the language modules.
However, these hypotheses by the connectionist networks for syntax and semantics - in
particular the modules of basic syntactic and semantic category prediction - could also
be used directly into the process of recognition in the future in order to provide more
syntactic and semantic feedback to the speech recognizer at an early stage. Besides syntax
and semantics, cue phrases, stress and intonation could provide additional knowledge for
speech/language processing (Hirschberg, 1993; Gupta & Touretzky, 1994). These issues will
be additional major efforts for the future.

8. Conclusions
We have described the underlying principles, the implemented architecture, and the evaluation of a new screening approach for learning the analysis of spoken language. This work
makes a number of original contributions to the fields of artificial intelligence and advances
the state of the art in several perspectives: From the perspective of symbolic and connectionist design we argue for a hybrid solution, where connectionist networks are used
80

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

wherever they are useful but symbolic processing is used for control and higher level analysis. Furthermore, we have shown that recurrent networks provided better syntactic and
semantic prediction results than 1-5 grams. From the perspective of connectionist networks
alone, we have demonstrated that connectionist networks can in fact be used in real-world
spoken-language analysis. From the perspective of natural language processing we argue
that hybrid system design is advantageous for integrating speech and language since lower
speech-related processing is supported by fault-tolerant learning in connectionist networks
and higher processing and control is supported by symbolic knowledge structures. In general, these properties support parallel rather than sequential, learned rather than coded,
fault-tolerant rather than strict processing of spoken language.
The main result of this paper is that learned at representations support robust processing of spoken language better than in-depth structured representations and that connectionist networks provide a fault-tolerance to reach this robustness. Due to the noise in
spontaneous language (interjections, pauses, repairs, repetitions, false starts, ungrammaticalities, and also additional false word hypotheses by a speech recognizer) complex structured possibly recursive representations often cannot be computed using standard symbolic
representations like context-free parsers. On the other hand, there are tasks like information
extraction from of spoken language which may not need an in-depth structured representation. We believe our hybrid connectionist techniques have considerable potential for such
tasks, for instance for information extraction in restricted but noisy spoken-language domains. While an in-depth understanding like inferencing for story interpretation needs
complex structured representations, a shallow understanding for instance for information
extraction in noisy speech language environments will benefit from at, robust and learned
representations.

Acknowledgements
This research was funded by the German Federal Ministry for Research and Technology
(BMBF) under Grant #01IV101A0 and by the German Research Association (DFG) under
Grant DFG Ha 1026/6-3, and Grant DFG We 1468/4-1. We would like to thank S. Haack,
M. Lochel, M. Meurer, U. Sauerland, and M. Schrattenholzer for their work on screen; as
well as David Bean, Alexandra Klein, Steven Minton, Johanna Moore, Ellen Riloff and five
anonymous referees for comments on earlier versions of this paper.

References
Allen, J. F. (1995). The TRAINS-95 parsing system: A user's manual. Tech. rep. TRAINS
TN 95-1, University of Rochester, Computer Science Department.
Allen, J. F., Schubert, L. K., Ferguson, G., Heeman, P., Hwang, C. H., Kato, T., Light,
M., Martin, N. G., Miller, B. W., Poesio, M., & Traum, D. R. (1995). The TRAINS
project: A case study in building a conversational planning agent. Journal of Experimental and Theoretical AI, 7, 7{48.
81

fiWermter & Weber

Barnden, J. A., & Holyoak, K. J. (Eds.). (1994). Advances in Connectionist and Neural
Computation Theory, Vol. 3., Ablex Publishing Corporation.
Bu, F. D. (1996). FeasPar - A Feature Structure Parser Learning to Parse Spontaneous
Speech. Ph.D. thesis, University of Karlsruhe, Karlsruhe, FRG.
Bu, F. D., Polzin, T. S., & Waibel, A. (1994). Learning complex output representations
in connectionist parsing of spoken language. In Proceedings of the International Conference on Acoustics, Speech and Signal Processing, Vol. 1, pp. 365{368, Adelaide,
Australia.
Charniak, E. (1993). Statistical Language Learning. MIT Press, Cambridge, MA.
Dyer, M. G. (1983). In-Depth Understanding: A Computer Model of Integrated Processing
for Narrative Comprehension. MIT Press, Cambridge, MA.
Elman, J. L. (1990). Finding structure in time. Cognitive Science, 14 (2), 179{211.
Faisal, K. A., & Kwasny, S. C. (1990). Design of a hybrid deterministic parser. In Proceedings of the 13 th International Conference on Computational Linguistics, pp. 11{16,
Helsinki, Finnland.
Feldman, J. A. (1993). Structured connectionist models and language learning. Artificial
Intelligence Review, 7 (5), 301{312.
Geutner, P., Suhm, B., Bu, F.-D., Kemp, T., Mayfield, L., McNair, A. E., Rogina, I.,
Schultz, T., Sloboda, T., Ward, W., Woszczyna, M., & Waibel, A. (1996). Integrating
different learning approaches into a multilingual spoken language translation system.
In Wermter, S., Riloff, E., & Scheler, G. (Eds.), Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing, pp. 117{131, Springer,
Heidelberg.
Gupta, P., & Touretzky, D. S. (1994). Connectionist models and linguistic theory: Investigations of stress systems in language. Cognitive Science, 18 (1), 1{50.
Hauenstein, A., & Weber, H. H. (1994). An investigation of tightly coupled time synchronous
speech language interfaces using a unification grammar. In Proceedings of the 12th
National Conference on Artificial Intelligence Workshop on the Integration of Natural
Language and Speech Processing, pp. 42{49, Seattle, Washington.
Heeman, P. A., & Allen, J. (1994a). Detecting and correcting speech repairs. In Proceedings
of the 32nd Annual Meeting of the Association for Computational Linguistics, pp. 295{
302, Las Cruces, NM.
Heeman, P. A., & Allen, J. (1994b). Tagging speech repairs. In Proceedings of the Human
Language Technology Workshop, pp. 187{192, Plainsboro, NJ.
Hendler, J. A. (1989). Marker-passing over microfeatures: Towards a hybrid symbolic/connectionist model. Cognitive Science, 13 (1), 79{106.
82

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

Hirschberg, J. (1993). Pitch accent in context: Predicting intonational prominence from
text. Artificial Intelligence, 63, 305{340.
Jacobs, R. A., Jordan, M. I., & Barto, A. G. (1991a). Task decomposition through competition in a modular connectionist architecture: The what and where vision tasks.
Cognitive Science, 15, 219{250.
Jacobs, R. A., Jordan, M. I., Nowlan, S. J., & Hinton, G. E. (1991b). Adaptive mixtures
of local experts. Neural Computation, 3 (1), 79{87.
Jain, A. N. (1991). Parsing complex sentences with structured connectionist networks.
Neural Computation, 3 (1), 110{120.
Jordan, M. I., & Jacobs, R. A. (1992). Hierarchies of adaptive experts. In Moody, J. E.,
Hanson, S. J., & Lippmann, R. R. (Eds.), Advances in Neural Information Processing
Systems 4, pp. 985{992, Morgan Kaufmann, San Mateo, CA.
Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., Fosler, E., & Morgan,
N. (1994a). The Berkeley Restaurant Project. In Proceedings of the International
Conference on Speech and Language Processing. pp. 2139-2142, Yokohama, Japan.
Jurafsky, D., Wooters, C., Tajchman, G., Segal, J., Stolcke, A., & Morgan, N. (1994b). Integrating experimental models of syntax, phonology, and accent/dialect in a speech recognizer. An investigation of tightly coupled time synchronous speech. In Proceedings
of the 12th National Conference on Artificial Intelligence Workshop on the Integration
of Natural Language and Speech Processing, pp. 107{115, Seattle, Washington.
Medsker, L. R. (1994). Hybrid Neural Network and Expert Systems. Kluwer Academic
Publishers, Boston.
Mellish, C. S. (1989). Some chart-based techniques for parsing ill-formed input. In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics, pp.
102{109, Vancouver, Canada.
Menzel, W. (1994). Parsing of spoken language under time constraints. In Cohn, A. G.
(Ed.), Proceedings of the 11th European Conference on Artificial Intelligence, pp. 561{
564, Amsterdam.
Miikkulainen, R. (1993). Subsymbolic Natural Language Processing. An integrated model of
scripts, lexicon and memory. MIT Press, Cambridge, MA.
Miikkulainen, R. (1996). Subsymbolic case-role analysis of sentences with embedded clauses.
Cognitive Science, 20, 47{73.
Nakatani, C., & Hirschberg, J. (1993). A speech-first model for repair detection and correction. In Proceedings of the 31st Annual Meeting of the Association for Computational
Linguistics, pp. 46{53 Columbus, Ohio.
Reilly, R. G., & Sharkey, N. E. (Eds.). (1992). Connectionist Approaches to Natural Language Processing. Lawrence Erlbaum Associates, Hillsdale, NJ.
83

fiWermter & Weber

Riloff, E. (1993). Automatically constructing a dictionary for information extraction tasks.
In Proceedings of the 11th National Conference on Artificial Intelligence, pp. 811{816,
Washington, DC.
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning internal representations by error propagation. In Rumelhart, D. E., McClelland, J. L., & The PDP
research group (Eds.), Parallel Distributed Processing, Vol. 1., pp. 318{362. MIT Press,
Cambridge, MA.
Sauerland, U. (1996). Konzeption und Implementierung einer Speech/Language
Schnittstelle. Master's thesis, University of Hamburg, Computer Science Department,
Hamburg, FRG.
Sumida, R. A. (1991). Dynamic inferencing in parallel distributed semantic networks. In
Proceedings of the 13th Annual Meeting of the Cognitive Science Society, pp. 913{917,
Boston, Chicago.
Sun, R. (1994). Integrating Rules and Connectionism for Robust Common Sense Reasoning.
Wiley and Sons, New York.
von Hahn, W., & Pyka, C. (1992). System architectures for speech understanding and
language processing. In Heyer, G., & Haugeneder, H. (Eds.), Applied Linguistics.
Wiesbaden.
Waibel, A., Jain, A. N., McNair, A., Tebelskis, J., Osterholtz, L., Saito, H., Schmidbauer,
O., Sloboda, T., & Woszczyna, M. (1992). JANUS: Speech-to-speech translation using
connectionist and non-connectionist techniques. In Moody, J. E., Hanson, S. J., &
Lippmann, R. R. (Eds.), Advances in Neural Information Processing Systems 4, pp.
183{190, Morgan Kaufmann, San Mateo, CA.
Ward, N. (1994). An approach to tightly-coupled syntactic/semantic processing for speech
understanding. In Proceedings of the 12th National Conference on Artificial Intelligence Workshop on the Integration of Natural Language and Speech Processing, pp.
50{57, Seattle, Washington.
Weber, V., & Wermter, S. (1995). Towards learning semantics of spontaneous dialog utterances in a hybrid framework. In Hallam, J. (Ed.), Hybrid Problems, Hybrid Solutions
| Proceedings of the 10th Biennial Conference on AI and Cognitive Science, pp.
229{238, Sheeld, UK.
Weber, V., & Wermter, S. (1996). Artificial neural networks for repairing language. In
Proceedings of the 8th International Conference on Neural Networks and their Applications, pp. 117{123, Marseille, FRA.
Wermter, S., & Weber, V. (1996a). Interactive spoken-language processing in a hybrid
connectionist system. IEEE Computer { Theme Issue on Interactive Natural Language
Processing, July, 65{74.
84

fiSCREEN: Flat Syntactic and Semantic Spoken Language Analysis

Wermter, S. (1994). Hybride symbolische und subsymbolische Verarbeitung am Beispiel
der Sprachverarbeitung. In Duwe, I., Kurfe, F., Paa, G., & Vogel, S. (Eds.),
Herbstschule Konnektionismus und Neuronale Netze. Gesellschaft fur Mathematik und
Datenverarbeitung (GMD), Sankt Augustin, FRG.
Wermter, S. (1995). Hybrid Connectionist Natural Language Processing. Chapman and
Hall, Thompson International, London, UK.
Wermter, S., & Lochel, M. (1994). Connectionist learning of at syntactic analysis for
speech/language systems. In Marinaro, M., & Morasso, P. G. (Eds.), Proceedings
of the International Conference on Artificial Neural Networks, Vol. 2, pp. 941{944,
Sorrento, Italy.
Wermter, S., & Lochel, M. (1996). Learning dialog act processing. In Proceedings of
the 16th International Conference on Computational Linguistics, pp. 740{745, Kopenhagen, Denmark.
Wermter, S., & Peters, U. (1994). Learning incremental case assignment based on modular
connectionist knowledge sources. In Werbos, P., Szu, H., & Widrow, B. (Eds.), Proceedings of the World Congress on Neural Networks, Vol. 4, pp. 538{543, San Diego,
CA.
Wermter, S., Riloff, E., & Scheler, G. (Eds.). (1996). Connectionist, Statistical and Symbolic
Approaches to Learning for Natural Language Processing. Springer, Berlin.
Wermter, S., & Weber, V. (1996b). Artificial neural networks for automatic knowledge acquisition in multiple real{world language domains. In Proceedings of the 8th International Conference on Neural Networks and their Applications, pp. 289{296, Marseille,
FRA.
Wooters, C. C. (1993). Lexical modeling in a speaker independent speech understanding
system. Tech. rep. TR-93-068, International Computer Science Institute, Berkeley.
Young, S. R., Hauptmann, A. G., Ward, W. H., Smith, E., & Werner, P. (1989). High
level knowledge sources in usable speech recognition systems. Communications of the
ACM, 32, 183{194.

85

fi