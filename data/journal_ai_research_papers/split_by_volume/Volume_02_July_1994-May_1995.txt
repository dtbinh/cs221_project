
	ff
fi 
			 ! #"$ % 
'&)(+*, --.0/2113541361

789:;  <=,,5>
-
1?A@9	%&<B.0>
-.

CEDGFHJILKMFNPORQTSUOVHJDGF0DWQX+HJY[Z\QO^]TX_Y;OV`bacOVDdX
e HJfhgiOVj0NVXlknmnHJYoQpF0OVH

e jqSrgiKMD

sitou'vuwowyx{z}|~u

dpV2+=ff

$5)J8dipA$+)0
R
 0B 


)_#8A0
6ni$56

)p
Aff 588A658
B6n0685V5i586
000[
 5 
AB66 05688$Ai6J$5PP5Vy66558+A#5
 5
A##5ffA6
#6A+580)0o58 6!W5B 5
A688 
V55B5ABA5_ 5
A6G6 !5p5+65d5A!o;65
i80 550665c 856558_Ad
0
 5
A60 
 5
A6
_c6505
AG6558)50o6255856
VAp6 5
A6B88c56AJi5M5A==5i5d5
ff 50PAo56+8AA
A5882RcP6 R
A
056V 6)550BA#5
A6A88;
oJAJ5!0c656ff0i6A'[8rA
5 580P;
oRo86UA$A505 580A8A+
8!i !0V
0 5!A !o5J05 580oB685[5506858 6!ff
 6A!o5U5Pff56=
A56A;6i6ffA Pi!A6
6!5nJ 6$2;
8)566856A566868U06
y ff8 P05	
 ff
fi8



_


"!$#&%(')+*",.-/012,43506%7,.'0489%(*:!',;!=<>"1,?;-=%('@)=!-=A*B!=<C-/">"%ED	06%-=A%('F>G,.AA(%7)=,.'04,=H;IJ3506%7,.'0489%(*
K-/">"%06LA(-/A78M%(N!=">"-='O>P<Q!=P",.*G,.-/01R,6*C%('O>G,6",.*G>G,.S+%('504!'*G>G-=%'F>T*"-/>"%(*G<U-=04>"%7!'V"!=W	A7,.;*YXZN[.\*]^
-=A(*G!_06-=AA7,.Sa`b/cdfeUgGh/iQc	e5cNj6eUklb/gmndfHop'q!=SR,6r>G!s-=01K%7,6#=,t>"1%(*r-=%r^Y#/-/%7!LK*r-/"!-=01R,.*u1-n#=,
WN,6,.'_>G%(,.S^P*L01v-=*;D	A(>G,6%('R)9>G,.01K'%(w&LR,.*xXU;-=%'A78y-/0u-='SsK-/>"1s04!'K*"%(*G>G,.'06%(,.*]rXUzx!'F>"-='-/%{^
|.}~$R

zx-=0OP!=">"1^

|.}~=~O

zx!1R,.'KSR,6*G!'^

WK-=0O>G-=0;"!ff04,.*"*XUY-/-=A%(0";IA(A(%7!=>6^ |.}=/ffff

|.}==&N

,.*"*%U,6
 ",=^

|.}=} ]!=%(!n#=,.,.'O>"*>G!V>"1R,

,.01F>G,6,.-/A^ |.}==&	

%('K*GWN,6")R^ |.}=}=& J"!**G,6.^

|.}=}= ]HT>"1R,6T!="V04!'04,6'R,.S+>"1,01-/-=04>G,6%(.-/>"%7!'r!=<06A(-=**G,.*T!=<N!A78ff'R!;%(-=AK"!=WKA(,.;*6^FW	-=*G,.S
!'x>"1R,*%76,!=<J>"1,.%7YSR!?-=%('*MX 
XUR",.LKSR,6.^
`6Red.j6eX 

,.01F>G,6n^

|.}=}= ]Y!=Y!'>"1R,*G>GL04>"LR,!=<J>"1R,04!'*G>G-=%'F>'R,6>P!="

|.}~/ ]^A7,.-=SK%('R)r>G!>"1R,?",.*G,.'O>"-/>"%7!'@!=<CSR,.04!N!*"%(>"%7!'@,6>"1R!ffS*B*"LK01t-=*>"1R,x`6`.7j6
,.01O>G,6.^

|.}=}/ ];!=?>"1R,teUg"jj9`.&d4ej4gfiQcOX 

,.01O>G,6,.-/A{^

|.}==} ],6>"1!&S*.Hs!=",

",.04,.'O>-/!-=01@04!'*"%*G>"*!=<>"-/ff%('R)%'F>G!r-=0604!L'O>d6j6;h/cKeUi{`:"!=N,6">"%(,.*Y!=<P>"1R,;04!'*">G-=%('O>"*;XU-=*
!=N!*G,.S2>G!d4eUg`neU&gGh/!=VebRb/Eb=i{`h/"!=N,6">"%(,.*B!=<C>"1R,+'R,6>P!="]:>G!@-=01%7,6#=,+-/0504!'K*"%(*G>G,.'048
,43506%7,.'O>"A78+<!=*GN,.06%ED0:06A(-=*"*G,.*Y!=<J04!'*G>G-=%'F>"*XJ-='Y,.'O>G,.'R"8ff0"^


,6#ff%(A(A7,=^	,.')R^

zx-=*"%'%{^ |.}== ]^R!=P>G!01-/-=04>G,6%(6,*G!;,Y>G-=04>"-/W	A7,Y06A(-=**G,.*l!=<"!=WKA7,.?*X#-='
,6,6+




,.01F>G,6.^

|.}=}RK

%7"!LK*"%(*6^ |.}=}=&N

!&!=N,6.^ 

!1R,.'^=,.-.#=!'K*6^



|.}=}=&

,6,6	^

zx!1R

|.}=}=& #/-='

|.}=} ]Hl@,",.*G,.'O>>"1,.*G,

",.*"LKA7>"*T<L">"1R,6%('+>"1%*CK-/N,6.H
 !;,Y<",.w&LR,.'F>"A(8,.'04!L'O>G,6",.Sr04!'*G>G-=%'F>"*T-/",Pffc	`neUiUb=c	h/O04!'K*G>G-=%('O>"*6^ff<Q!=T%('*">"-='04,%'?N,6R
>"%(SR,*G8&'O>"1R,.*"%*X{-='**G,.'^,6
 )=!L^Y!LR)L%(,6.^%(A(-/",.r^





-=*G>G!R^

|.}=}/ ]!=%('

 , --.o %%	!<6
<TB0
Pp
!fi:y
l9!	%&%		&0%W%0 <$



!'*G>G-=%'F>!=)%(0

fi$7

J===;;(J=?.OG.R"ff"M6l={7	.==lx=OM4GG=(OK=G.?G&"G.;J=(=/=.
GYK4"7=	4GG=(O"6R(6(RBQO@UP=(R.=ffn	@Uu=6.	(G=ff
J=R6N=R..===FKnN@R"6.;=R.KGa=(RR.==

(KN6.	PG"RuK4"7=4GG=(O"ff
.(/"7YR6uff".G.O/fi	/""(=
U4"7UR="(4RG/""=M= ffY4GG=F"ff
CG6MG.4"7K&(M=& 
x="".6(".7=PG"R2R"N6""7.!=._G@R.

&%'$%()ff	ff*/,+@u="/K72R-

Oy@Rff

7ff6=C4"GG.4=#"$

K/6PKR6;G4K7"76(M7ff6=4"GG.4/G

=OG6.;R+.R(GG.4r=G(R"(M=

;/=.R.

.=76;G0/	1
2/K"63P+'/=4G6546x

"R	G6=JR6/(/K7.6	6=(7.879:%ff=KxR.=G.<;>=	P.uR?K/7RR6)P="
(@K!==C4(GG.O6RR.r=FV4"("G.F(KG"=F"/"7V=A;

6=rN((R./7.&G.KR.+G;MG/

(R"(&"?&(.rRG"=O"(/"7r=6Y(B;<C9D"FEGH5MIKJ-J(K(LN"G."G.YGG(=(6=

"N6""(.C="Gff6(/G.8(M;
+@R.

=r:K4"7=4GG=(F"f

(FG&K4u2ff

6RffvQ=+G!ff(Rt=O_U4"7=._&_R.4N"(7

(OG+)P"RN=K7.;ff
@/KG6/	(?+4"(GG.O:(G"=O"(/"7=RO=:G66=K".4
.ffG.(RK(:K/""(=G"=O"(/"7+G5"(R"7tU(uMK="&G="O"6?=R6f

V;=QPV67t67./7@G</24"GG.FM(""=F"(/"(=5"&=G66#B
O

".;=.FNR.F"=F(B(""546=

O

RP6RffRP3.G.FSR6"P(R66Q="P=(="P567.O

"(K4:R:"&=G6(T="?=("!46=

T

R=R6r=9N.4MU(_GVN(F5Rr(5/6YK(7=u"V=R>P="s.=((RW7

4GG=(F"RB('0G."BG;;9N.6Q/	fi"N6""7..(:6RfftR=7xXK(7.YBR.,EH$H
R4GG=(O"N""."JR!=.ZK"N6"r=[K"N6""7.	Rl=(G\BR.;K7Z%ffDZl=R.
RR

O

K(]KN6B(:="=K!46.t=B(7?ff
BG.4"(2^/KGB(OG"&K4.R;K=(MR/	7"(:=

R="/"7K6/(RtN6\B('_Y((JNVG.y(tV(7?(RR>+@+R.yR/	RVK4"7=
4GG=(F"=;"6"`ff&7K#=M=K;7"J.(/"7#Y7M(#	6n

O

R(=G	/"J=NR

G.4"7U.G.F"R="(Y=G&6/G.>Y7U4"7K=4"G=(O"6	(/"M;=((Vx(
=XR6==a+@R.9(FG&K4\K!==:4(GG.4u=K=cb?d1e(fgenY=7==7

=(7?(R5G

=K7ff=CRC(/GG6J(MG.4"72h&F6="@".G.O"(R(MG.4"7jiR:6"7."&NK7.:GBBN6
&K(J4"GG.4=#+@L/=(76"NG;6R&;K=G.;?RG"N6""7.=G5&(.
4NG.5=K4"7=	4GG=(O"7;=@7Rl=("7=RRK4"7=4"G=(O"

k`lmnpoXq)rtsur)vwxnyr)oXz
{|g}`~S$?	~uxKuff$E7'*;N6<$%6y38ff*5<>'Y:`F7


Yff9


?[ffffff-SIffffff-SN>%F%ffffj%]dpD2E&%'B`F7MEpffS3-y'tffffff<$%

e

ffffff?9[ffffff9:X^$%RF\%ff@\%LdE7(EgH5(%J

&%ff]9FR"F%%'GH5MEHN%Bff7ZE7'KEyffH!fi:tRF%'5-M9F^H!E7Kg%(RpD2Efi$%
'EHH!jf	J
%0FU%ff2U%,&%(79EX%?  ffffff-yffffff-xffaff70FU%ffE_<%($D"	HKff*?E




'&%7EXxa:t9MNH-g^E7'KEyffH!%L@BE	fi`$%6y)pJ
$%Y&]%ff]F7H!E&%6E%%ffffKE)2#^F6&%(79EX%3`&7RFR7H!EMX$%
&Y%'X%ffff#]FZ#E7()%'KEj"	79N-SX6%G"Nff (*gZF["FE$7'%a9Dj&NEH$H*2D"FEpKffH!
EHN%J

-?

fi[XXU@XX'5FyXy0X8`N	y&5	&XZg:

,'X2c<'6Sff5!fi&R&(9X19'X]ffjff59j!fipB&ff:&:ff
NN2&fiff'Y9x!!UffN9gR&ZX!aNNZpN99yff^N&ff


 
 !&
	RffN9g&RpX995gBN8pX599N^XXNR$p!-B&jfiffF	!

X1#ffN9g5&U&M55pNfiB&8xffff5UxM&	& 2&cN'$(  <9'Xg



	Z'(	K&\GZ\G 'fi!#"L'$%$'&A(p)$*<'+
,$.-/fi0+1X320465c'78$fi(9(Q?8y:%F7(G_yB&)W,fi
!
. K3fi$'
; =j
< (?
> y(@ A
A B( ]
 F 7( @	9- 7j
 ,6
 $ffC D2
 9<%Q 0E!
9

gyG

F . K3G0#$B6Gjy^GH"L(6-0+81	%2I$J<fi&#'Bj)KG,82-.LMff	B@
; M
< G, 8-2 
:
N g $V(OL Mff 	\
$ 4Pp Q 	p.3
0 XaG8g0GOc
5  '7SRT<&
F Y
y3I
 fiUM
 , 6VDW@
> g'$fi)K2
 ), -2 YX &N$L
$ (
 :VCDg ( \Gjy^GM)
 ffVZ<F [-0+8	1 %2@
F 
A ,Y2=ffY03B\]^2RG_4`1BF''a<` a(YbVC3G2yc/$7@`Q@d$0`yKZ7
A
,
 4 O0`yKcffVI$#0#?0`yff_F':8$e2?	0#$gUp.p8F7Hf(
Mfi
C '\),2^B!g&-=jCfiBjFXDBZRt\BW -$'%$:(MBj(:	
f (e<%fi
 F\
C Bj
 'F X3@
g

 'W  <G



NNX5

F g

ihjFxp96FX35X5ANRX@pX995g

ff63NN\a&:xR

&R9ffL`&]X\X!5

lk,mino7prqts8uvo3w=oVqxsIuxvxyinzew={oVqts8uvn{{xq(zivoVqts8u=|}rzJmin}EmUqxsI~



F g



_r8c4B lk8D]R`eWQ$[;Y<ZRV;WI$_>y(]RD>(WQ~
" (3$[1& (p ,$H<
* 'ygpG)$[-0+81	%2I$'5c'78~
_MIc k8L
_Ur88)c k8xL 9	3fi$E;#$GrXB$X F,~
 t8()B[8c k8xL :L$J.$E$'" %~
N g $$X FX'~
trI'=B lk8L Mff 	$:
&!:X\N 25N


kI r8c4QQ8MIc % 8M8^BQ)r8U^B % r8c4BQ4r8'= 
 )r8U^BQ4UU8^B % )r8)cQtrI'=B ~
&ff2&ZpN99ya9x!!0ffNya&ff!!a&ZN
 5&a5,6ffffX'
9UF5!ff&ZN
 g9!6&ff5!Rx!p&9&`&^5&N fi9x c&2X 5&ffS&
N
 Nff!N 9W5&^N y9'!ff#NcNZ
 ff5[5&N 6&^N y9'!ff
 5
Nff65&ZfiF
ff X5ff!LpN99yfft[ffU&fi& Xff!BN<&\X 5&@N5pN995g
55NxY5N)N
 ZgZ&Yff5!YXN [&]N y9'!'5!9Z2&YN 5N3p^&Yp&
XNNN^&R&
 Xff!S&\N g9!p8&R&ffBXN

F g

F g

&R9ffL`&]X6pN995gL5




 r8c4BQ8M8^B lkURV K3fi$b"B(WQ$_RV K3fi$b-/fi0+1X32%WI$#R`;Y<D$^"L'$WI$R`;Y<fi$b&A(pWQ$
RV;Y<D$*<'y$pGWI$.RV;Y<D$^-0+8	1 %23WQ$RD
> y'$%$^-/fi0+X1 32%WQ~
; <fi$bL Mff 	WI$RV
; =<D$^:
N g $WI$
Er8c4BQ4r8'= lkUR` K3D$^xL : WI$_R`Y
RD>y(3$cX&N$WI~
&]X\ff59<5!pX

QI

fiI4d
4U)B8^B
)


8c

 r  =
 
8^7
 3: c
%3 ^
)r8U^B

%QIfiDfii:=:fi
Q=%%QKfi
3`%Kfi=:Kfi

8  V   %3 

8M8^B
  7
8M%M
  c33MdM
 =T:`
  M7K




rI`(B


[d,:
iJ)MM%^e%()OJ)%bMM)fiZ%U'i
 8:I^BQ)r8)cU`#3c%^tMQY	ff
fi
,IO8=
,!"I
	 #$&%')(
 *I +,-Q	 . /
 fiD0 fi8 /1B2 354
 )r8)cQt8()B[8c lU`x67D^t:ffQY#	8"Q_5!.	9Q31B2,^:D;54
 )r8)cQ  r  =BSlUVtM7fibx&5QY#=<"/>c?I5,=<"/>c?I
 31B2 ,231BU^7?54
@T:):6b

,Pfi)MM3bBAtDCJFE%bAHGbJILKYUMINPO0Q6KRNTUW
S VYX7Z 3G[G#Ud%H\E3Gb,]:
:,:`:G3G=Gd5CJx  KRN ^] K`_ ] Na  KRNYb#:,3G[Gdcb Ud3fi3fi>e>d3V0
 a
f ).):d   b 1/1,
 bJ:?G^MMH:,Ud3 :UgAt?Gd,/,eMH:,:?G^:d)`CJY:
:)h
 E83 G^,$
 ikj U ] jHb.  b 11,
  l
 O`Y:,U4%: X B
 E83 G^,m
 iK U ] K`:)ffiUMM%b=n
 Q K j
b
) o Gdb:
 O	iKqpeikj XlU  K ja\rsGbM Z :,m
 E83 G^,m
 ikj U ] j
bZ%,)t:# :,(dt
 O	iKqpei)N XlU  KuNfb
)H Gd]d`
 ikjYAt::,U4%: iK'c:,Gfi)MM3bs
 Q K j/)c
 iN`#:,GfiUMM%b=:
 Q N ja
v M:)Uc :!
 A(M"
 w Z Ux
 vj]:)%M:Y:, MYi:,z
 yU%MY
 {|E%b AHGbL
 w Z
C}a ? a & a6 %,/ ~BH
 Gbb,Pb :,ZfiM ~B& a f ,],Vo GdG%,Y
 C_[ G[GAtz
 Il?pIp&&&5pI&pI"Ha
rsGbM Z :,Y3,#`#Jt
 C[ G[G6Ath
 "30+)ffk7	)"3"	)ff3ffffk	,""3Ha
 [ E
 v   I  p&&&pI 4  %! AUM z
 w Z :, ::do 
 M 3
 E83b AHGdP
 ILK
B
 vH
G
 E83 Gb)
 i K  ] K bZ3 G[Gd   1B VV > S )a HV73 V0 

q v  aB)3  b)M:=:b:d
  
O	i  p&&&?peiKqp&&&pei)N/p&&&?pei X b fi):bMM=idx) H
 GdHdx& E: fi):M%b= b)& G^),
bB
 vH'bE%:bq 
yU
 =c7 
3 G[Gd Z6 pDzF[? a & aQ KRN U|VtZ O	i K pei N XU  KRN a, ^)M:)fi Z ,d:, 	 s>K	 D 
fi/
/ ,
2 s
fii#3c% 31, / :
fiU:bMM= Z C): 2 s>K0 7DJD^;  )  +3c% #$&%')(H
 *IJ:
 D? &a8
t
A


:




:


3

a
r
b
b

/

:

,



:



`



:


,



(
y
,



9



f

?

fi



)

:

b

M

M



=

f

b

)

M

:



=

:

b



:

d







:
wPar
31B3
 )^7 ?
& 
> V0 

M/ Gb):d Mz
 w bi:=U 2 s>K0 7D'D^3[tM DxMte &? a
)?

fiLHH|HH7[,H)Hc`o![!H-"


=
[

oe0
:e0
)?
ffD  e2
"77










  

tm7

)=e?2
H 6
  ) +

o ))H= 

`/!Yk-z,-	2
fiffe
off
fi3


	!#"$%&(')"*,+-!.!%/*0+13254768	9:;"*
<>=H?@BAo=$
!n(CoD"Eff&GF?HGI$J0K/L/MI$NDOJ?MDIQPRK/S@NDL#IK#P3T	`/!e}Uoee
7V;Lz!W["efiff?C
ff
fi@73
7RX?Y[Z6-23e\AHff&fi
!e[DAFL3^]$_`<aC!
Mff&(z3D$CbC!&3cb
oe
fi
Z-3Eff^Coff&7ed?
!oe&fcg
!ffe^cg23hC!)J-C!GA L>He
:
iCoVD6&0_
2546j	;!#"$k9ml L#nDo-IpK/qrMsnDNDSRL/N7t-OeoPUuBvWNDI$w5uVxyEqzo\w7oI*MKfo{uVv}| uVx~L F-MDSiNO;Oj7vUL#I	vfy
K#Go-S@o5L9PNKM:PKEMDI*o{xsL#IjxP?HfiJ-K#NKET/vxX{ v xogK#QoIpw7o-I$MKfoWxm v xT/vfXMDS
x` v xT/7vXfL F3K#7L;PEn:NDOHoWoL;PRK#P?y,MK#Go-S?q8L;P-o0
 J^MIQPRK/S@NDL#IK v xgL;PB	fi
fiffe[
o8L puBv|u[x5MDS[uVx|uzv@h?IK#GorF-MDO#OMDq8L#IyqzoEq8L#O#O,J^NDO#OQuzv
K#Gol3[/
NDI*wUuBx5K#Goe3-WM@F3K#GozFRHI*JK/LMDI$NDOjJ^MDIQPK/SNL;IKju v |u[x
!eCH{A!=$
oee[
Y+5ff&
A!Aofiff aHee
C!iff
fi@3
W-t(C!\-ffz
C!

!Co
AsVY,C!-\rCoW2fi
ffe
ojff
fi@39
7-Y
~C!tC!&3Co
fiA~B:YC!JC!&?T#C!

!
s	fi
fiffe[
off
fi@73
7RX?_gm-x9Ee3As\Z62fi
ffe
oe"e3ff
e3
fiPMDo32
fiffe
o
ff
fi@73
7TV
 X?Y 
fiAPK/S?LJK/O3FRHGI$JK/LMDI$NDOeeMDIfiOff
e3
fi3fiff^C~ff
@3
&UV
T  `X?_

9g4&#%Q!4".:

bC!5=A Eff
fi@73
7eDe@	ffe
oeZ-Y
!>C!\JBW3e
zZGffee3h
ceAHfiffffWHfieDe
seJ_g
cs@efiAo[>Co3Z6&
ff&eA/fiE ff^CH-3Co9T/&23

fie
fiffzCo-&e
ff
3Co"9
7eGAofiffe[
}CH,D6&X?_ hCo-cE&^zesAofiffYJ-e9J
A!eff&ecYjC!ieJhekoeAse3\-fi-_l5-3&YL
 Zeff-g=ze3C!?tff&
fiffc6
C!-cez3
!&7J-C!GAfi-Y
AY3fiff^CY,C!-csA!
!>eD]3B9
7cff-ff/fi
3Co@ff&=$ff&ee[l
C!>oZBWZ>e3AYfi
!eDZ$ecE_u0_-_VP-oNDI$K/L/J-P	C!>ff
fi@39
7-_LhCoVA!=$ff&[
fiffc"
03&?ffJWZc\)[/fiUT	
AY3>J@srCo5Yff
7?Xlefie-_shC!-ccQCoeZH(JWff-[el
ff
fi@73
7s(CHff^CHeff&[He&e-_shC!meefi(	 
7gD5ff-[?:
aC!

!gCo
fiAY	C!goee
oc33eCfi3@ff&=$ff&9ec|AHDfiAazff-[eY(ff
@3
-Y
J3eYff&
hCo
c3
o&337eCfi-Yo
A 
5C!}Co&Co
fiAYQC!)ff?Coff&d?
!ff-[^
3ffeDZ$ioeZ[-_(
Co}ffe
n
C!$@lzCoHD&YHt:,eQfi)CoD-Y
fi
fi["C!&e:9>@eDAYCo3
!-D3]G:e>Z
oc_
:

fi(!*e

 fi{^@E-^E79fiEQ@^fifi>(fi?sD@WVQi--W//->BfiG
h
@@^97[@fi@E@-$}fi^^Q-QfiWgD^3fi@@$@-^Q-
 QVfi  ,rfi@h@{WGfie#)(zU@U9Wfi!(eg-efiWa^fi#
 
#*^fi#\	D;-^fi#\@@^-khQ-fifi9W\Wff
Ge(B#
fi  !BiQ-^-@fi@ fi  GV#hQ@3*-e$fi@@^-
 (BGUQ-D^Rffi@fie^fi59fi7@7@Q^^a-8?
}fi,(z i>QEs^efi >e>fifi^DQ-!
 Wfifi-E5WGQ	(e
--^fi" ez*-9 #Defi-^fiQ>@3Qh-@@@^8@Efi^h$ &%
' G$/ (D$
 *)D/, + ' G$0/ (D* W (D.
 (/ (D/Bfi@@?71
 0Q8DQ@r@@^
^@ee{@fiW@  Qzfi  fi 2 } fi/ 34D;- fi / Wfi5#* fi / {G
@^??z(z ^fie-}D^Rffi^@@fi fi  GV#hQ@3@@^-fi(^9[G
^@@h(eiQ>#^W-(fie-5
hfi@fi-Ufi)Q@g@^fifi9Q)(fi9^9Q7;fi@@^97U#)(^@W
e G-jfi@@\}G-e}@gD^7@-W@@fifi^*3eGQeD
^eV@@eEW3-h	fie-
 D76z--p)fi0(3fiD3Dfi@fi~fifier@@fiseVQG
@^hD 89(:; (D=
 <D? >5 @
 DA6B--fiCB}^@-i:EQ0 fiDEeQ@@^EDDie9EQ~@Q
, DGFHfffi@fi5fififiV
 fi@fi5I
 

@ ^->JfiDfi@@^Efi7$KV--L:?NMPO$O:9
@@^-4Q*#zWez:D?e4RTSVU9R4W7--:fihYXNSrfifi@UQ-
MGVi
 ,:fi>Z
 X W 	QsQ-ff 
G9@E^efi5	-e\
 [^]`_ / a*-^
 bcQ3 b:};?
fi^eQ-3$fifiE@Q,{Q#^fiD{Q\Qeff 
G3seGQ9jW
/We fi  *, deFfG@@?g
 QWW@Q!(fiDQ--^{fi@@?7W-@
fiQ-[-^UQDefii^@@^eQ)Qfi[9i
 hkjfWe-@

 mrfi@z)eGQQe?efi @{@e!
 n`opfir(e\;k
 q./?/ (D$G
\l efi9(
@^3#(fi?Q#ZfiD^fi@@?7fiDEQ3^WErMPO$O:fi@@^97?s0?
tvuxw y3z*{|y~}y3v3&rz5~;{VY4{9559V ?VLu
u=z5}x5}}y9/y?9vz5/y.*;{}|;z*x5vz5{`3/|iiz53?ffVz/3vZ;z5}?L;=Y/}/z5{V/9{*}}
;}z*{1{Vv}|;z5/}v$VJ;/{V{}z5}/3{VJ5v;/z5/y3i}x3/?z&$1N${z5}z5v$/{9$3/y3v}1{i5V$z,
z5}1/y}/;i4}/y{Vvi5V$z,Z;=Y.ir"9$u
$u. z5?Z{v3}|z5Y 4z*}./?{VvffVizYi$!$5z/}`}3;/}1;/{Vv}V{3/z5ffz*~^$3/?z*39
/y/V$z5}/};z5i5z5{z|$V/z5;/y4$vZz53}u
 u.g3z5;{}|z5   z5}Jr"/z*yz5vV53i    z5}J}3;/9z/yVJ;i}Jv;*3}z5
  ivL53}1  PP{vff/}VffV5J  -  z/yV4y}4?4iv}}3;/}z5  4z5}
}3/9rvL5};==u
u.`yL$/yV/i;/J}y3?ey9e/yz5}N/V}35z5}N/r3z5?3V,/};!y}T{}|;z*/}
y9ff;/z,kT;N5}};/;Yi}r"/z*yJ";?,?r{v3}|z5Nz5}Yk"/z5vyz;*z/}3z*;r3/?V{V/z5v}
;/4r"/z*y3z/y34rz5}Y}/5t?VN-t? t9{v3}z*}/V9$/yV~zYz*}*;*~{v3}z*}/V9u
$u.;/y3=}/;ffx$}z5i5z5{z,`xz*533/}3z5?Nz5i3*z5{9?/z5v;ff{}|z5/}Lyz5{y;$VffP;
5/z/yz5}3/}/9$T;|;*55v;/z/y5}i}/$z*~z5~yz5};V9u
$

fiJ==T==";P=Pe=x.P".=i

7=9ff^-N`^Y?^9;?x?r"?
 "x ff^x99;
 P?
 "r;1"?1"?x^9
?



?



P

9

	





`

ff






1
fi
x














	



ff







r

ff

^

=

9

9

;



"



?





?









?





/





^

P




fi
!

"
$#&%"(')fi`* ?,+ff^-
/.10

 "P??5
 4ff
 +r-9!`i9;ff?=
 076k "ffZ?xJff^x99;
 "?""	
 98):<;ff=;>@?-
2  39ff 
rff^x99

 2  4A#B	CCD$'4*
 "
 FEH
 Gr9  4IJ>@?LKM#B	CCD$'?Zff?x / 		(@4ff^x99;
 "?O N,0QP
??xR
 Sfi
 xxff ^xNff^x99
 "PU
 TWVYXZT\[]"~	
 ?xxff??O "^ _/ ^P
 fix`
 !"ff
#9a
 k/ .  ff^x99
 "PM
 bdcfe"gh"I
 i\^;a
 D$')fi==xM
 j Vk[ ?-
 "=i?ff
 + ff^ 
/ .l#,
 
 ?x^m
 ^
j<[VZ	 gx`, ')0 2 ;R
 
 
<"m
   ?\ff^x 99x/ "7n +T 4+k^9ff^x99;
 "?? "
xxff ^x-	
 ff?9^o
 ,=xff ^xff^x99;
 "?p
 #,9;xq ,; 9^r
 ,x=ff ^xNff^x99;
 "
"9 ^o
 ,x=ff ^xN^) ')0a
 2 
 4s5??x"M
  R  K!
 ?I
 # "=ff?x??-^
?,
 + ff^!
 
/ .ff^=99;
 "?) ')0Yixxxff "^xxff^x99
 "P?	
 fiPxx^ ^4J*
  3ff 
Zff^=99;
 "?
 fi;5
 "P9ff?=
"t
 9
 0
  ff^-t
 " -?v
 "  ;?PC"r
 ?^9??x? ??x- ?xw
 >@?(?4
 !?
u xK9ff^R
ff^x99
 "P?!
 J?-xn +T 4K`^R
  9t
 $^
A"?H
 #ffKyx-K^fizt/ ^^P
 fiJ!"ff"{ fiY;ff
 + ff^ 
/ .|0,00)')fi
R
 ^x ! *  h"?R
 "N9
 0 u W
 RL}`?xff
 fiR
 Sfi$"^xN  "R
 ^
 fip
 "9?9 "m
 U"  ;ff
 
 fi
"?=!?-?;x?`
 +T  ?9F
 "e?*
 "    "? R  v+rC^x^ ~=@H
 ?ff^=99;
 "?
?h
 xxff "^x{ 0
 #~ff
 
"fi	CC$')fiaI
  ?ff
 +k ?x
 "   ? ff^x 99P
 |	fi!
 
    ; 
"^=    
ff^x 99P7
 x9? " ^`/ .9*
 	
 99^"x ^]
 fi,4
 
 ^<
 nx9? "9	
 ]
) "=
 fi
??K/ .<9? 79	
 xffK
 h,=xff ^xi *
  39ff 
ff^x99;
 "?
 ?^ 
 #!
 R'x9? "9	
 

O "=9?R
 "^<
 n"x??P "9	
 
) "=
 0 G?=?!
 i?H
 
O ".h
 "?xa
 ff.	
 Sfi?x
?x4 
 *?ff^xO "99\
 x9? " ^T^ " / .9R
 x	
 9~9^"x ^
 0~ff?x"^ fi  ?
ff^x 99x/ "~ff??O .~H
 +T@
 4ff^= "99x/ fi(=$O=@;R~)~n/;|@fiS"~?<
  
 
 fi1
+Tff +  ?  ^99?xff +h0

1^J,(*a|,,*|ffH*I(,"ff"dRJ
 `1h"Sxxff"^x{fi,"?Yff^x99"P;  `QR^
"^x	9"P9kn+T~;=9?0YWZff^?"x?
#R;ff9	';r?  ?9"m?hxxff^x1ff^=99;"?fi*+k?! F"5*?ff9	A,?^TV9
TWhL}ATWVXTW-
fi *tZ
 ff^?" xJ?~	m h#{K(ffK^
fi xRR" ?ff9	')fi!,^,x=ff^x=ff^=99;"?0
 9F_c#()WUIT
' ?R" W
 ;  x
fi R1hc#(v)W-'W ?* ?ff9	
 ?xR ;  0
 ax
 $" R,x??	fimT
+ 	 9-?"9^h   ?O
 x ^x?x!/~/);$>@;
 
2 ,?F

?9/.#(
 O" =",')x
fi R
 ?q=	=Y
 HR ?ff9	t ;  1
 ;ffRx
 w=q8T V (;>@(qO	nOxq>)*
A-\J,(1^r"*v-< //nTW~o>w
#()W"'F (<q$~/(~a(;vWw>F<>(_#(TVqT7[/ffqTY[@	qT7[{!qTW'F~):R/(">$YTV\XT\[O/ff
TY[  XTY[n  ffqTY[  XTW|a@ $K
 //nTA~> ?t=q8H>offnIx$B>)#()W!' >@;R=(<H@nOo~H>!/~/);$>@;
8B=@T@K
 fim+J9ff.xq=	=~	N]R;ff9	t;  0  5"Tq 9R^xi?xZB=	=$S"i
2 / .9x ^S
?r95+kR"; ff^?"xr-"m^"U
;9/.|0

> ??]=B8F>@(qO	nOrx$B>*v#()W!'9 >@;R@//nt=B8
 -\J,(1 ~:R/~	S=B8Z~F
A
_~r>I!/~//;$>;*18)q=@>@;l?H/;*=B8MoKM~aO>@?(?O-R"-Q (<qH$=ff~r;=O~
>q=	=~	Y~):R(">JHoKW~aO>@?(?^
  R" x (m/p$=ff/~F;=5$~/>Hq=	=~	JH
~):RA(<>5   " LK
	v{nO	J$ Q 


 B&Y	FkS ff
fi,&)@
 &1m&R1R!"
 &#m7&|$R"%R&
')(+*

fi,-/.102

314!56567893):;7=<

S!T 8UP4 T

UV7=<

314!56567893):;7=<

3ONP4!89Q!5O:;7=<

S!T 89UP4 T

UV7<

3ONP4!89Q!5O:;7=<

3):RQ/:;7=<

UP4):XW17<

Y

3):RQ/:;7=<

>?A@CBEDGFIHffJKFL&M

UP4/:W17<

>/H?A@CBEDGFIH+M

Z"[]\^I_R`bacEd=^OeO\f_&g!h6ijgfkOlm_&nVnfopR`qornfsPtuwv
xEyzG{$|~}/zVz|~}/~yfV$z|})9yff~|z|})m=$xyfx6|}
nf_
314!56567893):;7=<

S!T 8UP4 T

UV7=<

zVz|})~xyfzG{P|})ff~yfV$z|})VPExyfxO|~}/P9yfffff|Ez|~}

g!_R`enfoRijnhg!oR[e6`f
xEyzG{$|~}/zVz|~}/PExyfx6|~}/~yfVffz|})9yfff~|1Ez|~}

3ONP4!89Q!5O:;7=<

[]phO_R`O=`+ljee6^Io[o[;pkOnfonh6g!oR[]e6`fc
Y

3):RQ/:;7=<

iOgfpkIngfk6`+ponf_

[]koRiO[]pnf_&lI`q_&[]kO\p&^O&i#oRiOg!o

BE

=$xyfx6|}
BE

=$

xEyx6|} 

UP4):XW17<

xEyzG{$|~}/=$xEyx6|})~EyVffz|~}/9yf$~|z|})zVz|~}
[]pkInforAnh6g!oR[e6]`fcO[or[]pkInforh6_R`O=`+ljeV
Z"[]\^I_R`IcAnh6g!oR[e6]`gfkOlkInkmAnh6g!oR[e`nf_&lI`q_&[;kI\pnfsPtuwv

Z[\^I_R`a[]]]^6po_&g!o`+poRiO`kOnfoR[nkOpKnfsPlO[_&`+o`+lp&^IeO\f_&g!h6igfkOlnfs$_Rnnfop`qoiI`q_R`fIgXO=_Rnnfo
p`qog!hOh6;[`+lonjn^I_`Igfh6`tEuwv=nfoR[;`oRi6g!ooRiO`g!_[]pnkO]lO[_R`+o`+ls_Rn
9yf$~|z|} OgfkOlkInfors_Rn
gfkOl

9yff~|1Ez|}


9yff~|1Ez|}

9yff~|1Ez|}


on

~yfVffz|}

~EyVffz|~}

oRiIn^I\iK`bi6g+f`benfoRi

on

~yVffz|~}

~yVffz|~} $iO[]p[]pnk6snf_oRiI`pRg!f`AnfspR[]h6][]q[owc

oRiO[]p[;kIsXnf_g!oR[nkj[];1kOnfoe1`^6p`qs^6~[]kjoRiI`sn]n[]kI\I
[oRig_Rnnfop`qo1K`gfpRpn=q[]g!o`&!=f!~ghO_&nfh1`q_&omoRiOg!oqgfke`f`q_&[6`+legfk
nf_&lI`q_[]kI\nfsc
mV"X/;!qV
1 
~ 


B





#

B+B!qqq+B

;b!X]Rnh6g!oR[e6`A 

!


O

B9BE 

knfoRiI`q_EKnf_lOpqoRiO`r6_&pRo)g!_[]g!e6`+p[;koRiO[]pnf_&lI`q_&[]kO\g!_R`oRiInpR`iO[;&ie`+nkO\onK`oRiI`+kpRg+
oRiOg!ooRiO[;pnf_&lO`q_&[]kI\[]pRPReAmOgfkOljgfknfoRiI`q_r!g!_&[]g!e6]`
[]kjoRiI`bnf_&lI`q_&[]kO\m B9

[;pnf_&lI`q_R`+lje`qsnf_R`

B p&^O&imoRi6g!o

B

B
B

iOgfpg!or`+gfpRoEnkO`gfk6`+ponf_

B9

p`q`Z[\^I_R`V

	ff
fi
fi


!"[fnfonkOpR[]po`+k6lI`qh`+kOl6pnkoRiI`gfpRp&[\k=

Z[_&ponfs9gf]imlO[]lE`bqgf]ff[]oE !f&!OX1q

$# &%k`qf`q_R

`+kVonf_&lI`q_&[;kI\ 

po`qh

nfsEoRiI`gfpRp&[\kO`+kVoqffoEnm`+`+`+kVoRpiOgf`one`lO[]poR[;kI\^O[]pRiO`+l~c

6_&pRoRfoRiI`p`qoEnfs~oRiI`sXnf_&`q_&[]kOpoRgfkVoR[]g!o`+l)g!_[]g!e6`+poRiI`I!6GfRq+;gfkOlp`+nkOl6oRiI`

'!(*)!+-,.+-/10324/658749.:+624;=<>74+19@?03/A0B74CD<=9@?FE	+-EG74;=?<H5I03?:J0K:F03A70B74+1LK;M<=9K?E	+1EG74;H?F<H5ONQP;=<CR74;H2ffSUTV;W0324/QXZYW[K'@']\>(
^F_R^

fi`badcefgheij@akj3fVlminmoqpFertsuviwnmfxakewixyz&g.{Z`|j

}x~]V|F3Q~W~Ik}vWB}ZBkW~bI}v~DR}]$}v3kx~R|Q|]$}vBkBW~}v]|vB~RB>~Rh~R~}
~3k}vWB}ZBkW~W~R}vBx~}x~]VF3Q~W~k}vWB}ZBkW~x~3Bx~W~W~RBb
]$}vWW@k}mDv&BBkRk8B$Q~W&k!whBx~]$}BkWW~}v]t@x~BVDBx3}$}QR.8vk]$}vWW3k}Z
k|Bv8Rkk~Bx~IwF$Bv~W~RR
	F*xw
vx3Bx~R}BvkW~]BQ$}.h~kk.k}ZWBVvv]~Bx~x~]*}vQBQ$}wQ]$}v3kWW~}v]k}BW~RR
]$}vBWW~}v]~Rh~R~}F@kQ~RwBx~}twQBxW~RM}vt*}vkQQJ]$}BkWW~}v]
Bx~OR
 Z w	 h>WW.Kv]  m3  O8  *  t  |Z]$wBQQ~
 vGw  =.v-  K  @$VK&].  *  Z|KdFGZHBb-F
 R4GZ=BZh  twGBb  
x$xD]$~}ZB3W~3$Bvk.x~]*}vQBQ$}
 x~O~]xkWW~}]~O]$}vWW@k}mD~Rh~R~}qbb}vMkJ}xD]$vkW3w.Bx~B~kBk$}-
&~v}vQ~R33	
 J  I}v  DB~}xb}x~]~BB3Q*~R3~}mRH}vR  IOvB~8h@3JV$G	R  JQBQBW~k>
}BvRW~b~BBk&kkW~Bx~QGmHBZ48Bx~B~kBQ$}v8WBx~Fkv~Z.8Bx~
v$k}=
vkhx~]w}vQBk$}&!&~JW~R~}|QVR~R@BQ$}WW3$}x]$}BkWW~}v]q  }v]$}v3k=
W~}RQ~@@
  ]$}BkWW~}v]*QMkvx~hWBx~|B~B*~}ZFkv~hk}wvWMv!~8BxvB
}tm
]$}BkWW~}v]*}Z]$}vBWW~}mk}vBB}mBkBk$}|HWq&~~]VW~}vx~W
BQ33kQ~xx~R3~|m
}x!}xBvB]$}v3kWW~}v]~vQQ~}ZffW]$}vBWW~}v]$h~.R}v~vv]~hBvB
]$}BkWW~}v]R}~B~R3QWW~}k}W~R3&8|]$BQwkkQ>w
 bx3v@K  w ROx|>WW.V M  KGwhHW|mw&MW|m
  3|$W3JVG4]  

 ~QB~xt3ktBvIW$~]$}vWW@k}mBIRkk~Bx~wFJ~&wBBkRvkBDW*wh~
}xx~]w}x~Bv~

 Z w
	   fi ff w   R4|h |
 $.Off *bff|h h
OwQ=ff   w ff R 4|  q
 ff  w  t
   |Z=@JVG4]  
=}Bx~RDb3Rv$Q~}}mvB~R8BvW~Rff *}v]BQ$}v]$}WW3k}Z8   |W]$&k}x
$x B$
 ff bI
 ff }| 
 ffkQff kh}v$}vQUQh}Z]$}vBkWW~}Z
k}vBB}mBkBk$} G  B    }v }ZBx~RF@kQ~t  k} ff&8Bv~RB~~]xkWBQ~W$}x~
kx~IZOk}Bv3BvGZHBFFR}~D~]W~}x~W]$}BkWW~}Z.k}vWB}ZBkBQ$}UGZHBB
|>WMW.$$"
 !JGv}v]BQ$}M]$}vWW3k}ZBRh~&RkhhBx~K$ #$}vq.Bx~t4% #  hBx~
Q.|  |m

&(')'

fi*+-,/.10

6:

28:

5:
287
67 57
97

243
53



63

H1M_`Xp1AM
a/

8


8





;=<?>A@CBEDF@HGEI
JHKMLONMPRQ)S)TCSUfi>@CBADF@HGIPRVC@HGXWY@HZ
JHKMP$VX[]\_^`PRVHNaPbQ-STCcS)deVfP$VgThL_d(Tji/ThKMLOkNal)PbmnVfiSU8opBfG-qrTFKalT
P$Vsut B DFt Gjv qwsux B DFt Gjv ldayzs{x B Dh| Gjv l}R}pKalAQ-Ll~VFMNMNS)mFTPRd
 Z s
mFLVfNLjcTFPRQ)L_}R`t Z qet Z l)dayx Zjv
 dOThKMLS)TFKMLjm8Kal)dayqAPbT8P$VpdMLjPThKML_m/NalTFKc_S)daVFPRVfTFLjd(TjqEVfPRdac_L
sux G Dhx Zjv Kel)VdaSVFMNMNS)mFTpPbd  B qEdMS-m8l)mhcwc_S)daVFPRVfTFLjd(TjqEVfPRdac_L
xGKal-VHdMSVfaNMNeS-mfTPRd  B 

4


;=<?>A@CBEDF@HGEI
JHKMLONMPRQ)S)Tc_ldeyPRyalETFLS)U>A@HBDF@fiGIOP$VC@HGWY@HZ 
JHKMP$VH[]\j^P$VdaSTNaPbQ-STc_S)daVFPRVfTFLjd(TjiHs
tMBEDnxG v Kal)VdMSVFMN
NS)mFTPbd  Z 


fiM`XMpAMe4E

 )rp1pEpX4EA8aEe]AM

8{(_jufE8E H4E
eHfiu-{8w {rE 4E{j`_ ~En {j` r8r_r]M%E1
(jj1A8raA{e   EEE   Er  
 p1"AM_ezX     {aurneAue 
4           	 ff 

~8{(Mn  
fi      EEE  
fi  
nu"]EErr_r1p_/M  
~rEfi 81OMj1M
O4E{`1
_1M eO_Ej H1M p )="p1AMpe4Ezp
M81AMa4
 1zAM
 / 1M   A  E`A1Mp
 AMp_e
4M_~pr_E r4E1Efip1 
 A811M"!#$
! r/--&
% E] {u(]'  E
A1M4 AM_eE4_r_AEjE) wp pr4EpAMe*&% p
p_/Mfi~E~AM1MOr
+
 A/11M!#-, 
. AMp11M0/E_p1{O_ 
1fi     CEF2EE{
81AM
a*3
. AMp11M54p6!71A_rAM_eCMEfiMMpEC8nrE9
j ff
;: =<  pz p1O_e>   
?A@B

fiCEDGFHI0JKHLMDMNIPOQLRQSUTAHVWXLYRQIDHYLZ[6J\]CffM
^+_]`acbedbgfYaihjkmlffngoqp*rts6uwv*xUy{z}|g~{zffK1	Ns*p*srNqPs n*p
sAnr6prY6qQpner#****E"sqrYsp*PrY1 n rYsqNqr sqnerYg+ff]6n 0gp
*qeqngr]+gQpNpNqrYng nqrsp	*s ngKp
Q K;~=#ff	ff	    sqrY;K	KneffYngoAff 
 sqr"oAsqnsQp(~n	gpsq #p*ff;sYngoAG
# K;~=5ff;ff	sqrK;(6  z
 sqr"oAsqnsQp(~n	gpsq #p*ff;sEAqrwpYneoqG
  #K
] 
 rY"oAsnsQp(ne	gPpsq]pff;s7neoqG
gPp*rne	NsqgpN+s;*gPpuwvxwEsqrY;ynKYngoAffqrnpr 
616]PU*P*E**gQP*
P;uwv*x*#&&Nqg(*c5	w55pp(*
6ffYngoAqrnep*r*A#pwNQ0+Pff*N
7N*--*(U7*77]K1NYK
0nggpp1KsYngoA&*p
^+_]`acbedbgfYaihj lffngoqp*r suwvxyz |g~	N	sp*K "|g~	NsqrUNqPs n*p
sAnr6prYqQpngr]ffq***ffsrY	sNqr sqnerYp* Epff*sqyne]
Nw ffN*n ine	sneoqE*p*ffy 
h j	bfd	;faff
b
d1_#adfigf
_
*uwv*xUy7Y]* UqE66
 *{N+c 
y P	K6ffQ	 0**6w**+
NK Uw*gw**6 N;YYngoANrnep*r
*A#puwv*x
^+_]`acbedbgfYaihj  y  z|g~      n;sqep"gPpYQ*gPpuwv*xy z
|g~	;n 
y  y  -    q" !$ #   %
 #c  i
 ]EsqrY   6 q" !$ &    %
 & +q(
 ' U
 1EsrY
Q 
# y  neffYneoqffNqrnprgsqrY
y  nA* )gPp*p 1p(r,p +n.
y -YngoANqrnprUg#s5
y fi .
y -/ y sqr
] 
y  zi
 y -
0K*eNQ E;w*w5QE*
y wuvxyQK]P
g(6PE	q*] *
1K3
_ 242 5h7j 698 pyz |g~	NpUsuwv*x  8p* &Uuwvxwy  z |g~      fi
 y
sqrYy  z|g~      :
 y p;YngoA	NqrneprY      sp*;s"YngoA7*p z

 ;=< ? >A @ C B  wfi
y G7z
 DFE  E srY+sqrqPs npsAnr6prYffQp*ngr]  8 p*ffgPp	uvxH
 I    G z  /
 K    G z  J
 I   Nngg+ G z  J
 I   zL# G zM#   N# 
|g~ G z  J
 q" !+srY(.
 Gz   I   z L &OG  P
z &   	
 & -    4
 q" !     '=G  0.
 G :
y G
 4
 Q Pp*r(5N  H
neEneoqKqrnprE      gPppsq6p	*pgsrYsqrgQn7*sq6pNqPs npsAnr6p*r
qQpngr]qsqrY *pNNqrP y  y   H
y GR y 
SUTLV

fiWYXLZO[]\

^H_U`a`b$cedgfihj$kmlnk,oqprsl,outlnvHwyxk{zx]|}p}ln~Cpuk$xkmlmflflnk:qfqp}lmfN=$
p}j,f:uj$x]fC}ff


?

L

ukk,oqprl,outlp}jt}s 
l,outl.  e
    
7 } 3 





4   

7 }   



P   

 l,oqfj,fp}j,f

 w  

4   ?   

L
xvHw

qp}jt} gul,oqfj,f.fCqxkml,k



xkzx]|}p}l{~Cpuk,xkmlmfll,oufj,f	fCxkml,k








 
xvHwfiflnxe L
k,u~o


7   
 ?     ?C p}j 7     

 w 
  Ofx]l,oqfj

7 ?  

t}

t}uN





t}kv

 p}j


xvt}ugvHp}jt}e nfffl

xkl,oqf:zx|}p}lp}

J

7 }   

U(qp}jHt}

7    ? 



l,oufzx]|}p}l.rYoupkmfl,tj,}flxk.



 l,oqfj,fp}j,f

 


 w  

 ~Cp 

tj,f{~Cpukmf3qfl,]y



x

k,u~o4l,outl

 lHxkl,oqf{k,t 

ztl,x]]f 



fx






xk

zx]|}p}lp}/

 mv

fl(ukqpLrPk,oqpLrl,outlv





O

 ]"

(
w 

qj,l,oqfj 



w












O *

e ]"



O *

9 ]"



 
.






w






t}u

k,u~o	l,outl(



t}y







w 

k,u~ogl,outl

w

t}u



  }urYoux~o	x 


w

  

dgfqfu~Cfj,p 

 

t}u



 


C 
 

U

  


 

w 

 ~Cpukmf3qfAl,}.
w 







  


w




  

kmp

 w 

qp	rfnout|}f







  

U

 w 


  

t}u

  Lfffl
 w 

w arJfl,oqfj,fp}j,fout|}f

 w 

 

 
R


w   w 

zx]fk

 
.

t}ufi

UqrJfout|}f



vHw.xkzx]|}p}l(~Cpuk,xkmlmfl






 
.


L

zx|}p}lp}

v

w  Ji~Cpukmlmju~Cl,x]pp}

  

t}



Lkmp



vHw

 k,pn


p}j,f}urJfout|}f

kmpqk,xu~Cf



 



.





?





  


 w  


 

   YpLr




oqf=w 
  

  


U 



l,outlRv

w

 


vHwt}uNv

{



vHwt}ivHw

C  

vj,p 

U 

   

t}u



dgf~t}yqprzuj,fkmfll,oqfHzuj$p}zOfj$l,x]fkJrft}qpuu~Cffixl,oqf.=fxuuxup}l,ouxkk,f~Cl,x]pa
^H_U`3_L%ffmu:,}.Ov


v
	fffi$}q*Cff}Cfi/
U$ ! ":C#AC $&%

ff}C	fffiff}C
^H_U`a`b$c('qzzOpk,f{l,outlv
 xk

l,outlJv

*

(

  
qp}l



t}t}u

. ,53

tUx 


tUqx 





xkHqp}luux3qf 

l,o3ukl,oqfj,f:fCqxkml,kv
- ,

zx]|}p}l~Cpk,xkmlmflqt}u:v

t}rYoux~o	~CpAlmj$t}x~Cl,kl,oqfzuj,f|x]pukt}k,k, 



xkzOfjoutzkJl,oqf

^H_U`3_L%
6fi.0/1=v7}v

pk,lYx 


)


+*

  

 ,

vflukux{l,ouf.0/1:v

  oxk.0/1Nxk(zx]|}p}l~Cpuk,xkmlmflRt}uyv

oqfHk,f~Cpu	zuj,p}z=fj,lnp}v




v




 

 fff 
v



vk,u~o
)

 

+*243
v

    
t

zul,x]pa

xk


z=p}j,l,t}l 

,{+893ff:}];<fi4{<=ff}2H>=:?R@9<A


7q>%
^H_U`a`b$cflukffqfup}lmfB

B

 v

 flukqpLrk,oqpr

p}v
JI  

I

rYoux~o
 

 v


t}uCB

l,outl5B

xk	qp}lfitkmpql,x]p

  


G


 v

 v 




p}v

xk{tkmpql,x]p4p}(v

k,qzzOp}j$l(p}jHtlH]ft}kml.pqf{~Cpuk,lmj$t}xl 
l,oqfj,fp}j,fJout|}f

JI   IL 

N
, u]

p}j

l,oqfx]jj,fkmz=f~Cl,x]|}fk,fl,kffp}ukmpql,x]pukED|x]puk$]}FB

B

JI } L
I 




 

 v  

k,qzuz=pkmfl,oqfj,fRfCqxkml,kHG 

YoqfLK  *

t}k{vxk

Kuik"l
,   
 i




G

3




P:QR



 ]"



tUqx 



 

k,u~$ol,outl

t}l,outl
JI   3 



JI


JI  



  

I

 

ft}ukl,otl

4
, ]

p}j

I

,

 

JI  

   

I

JI } 3 

xkffqp}ltYkmpql,x]p.p}qv{}l,outlxkMB

ON

 v 


kmpql,x]p
YpLr

 

out}k{qp



4
,    dgf


B

 v  

fiST@UVWYX4VZ[\T][^W`_&Za&b;c:VdeEf"Za&WT]VZghX5i$SH[

j kl"mFnpo`lmFnpq+r"s=qq+r"kt+kuk>v`wyx#q+xzs{"l"w]|<{k}~YMsfiyk;q+rk:fi^=y>>z:<+zmfi
ux+{^rq+r"s=q5 0 u  wyx5s:v`wysfisfil"(  w]xHwfimfiq>mlx+w]x#q#kl$qmfit+kmFfiktq+r"w]x}0~rsfix5q+rk
x+sfiukzx#kq4mfix#m]{"q+wml"xsfix4u`q+rk"t+mfi]kwqH>mukx4t^mH{q$kfikl(q+r"m{rw]qw]x4w]l$q#kt+kx#q+w]lq#m
o`lmFnq+r"s=qzx+{"\rs}0~k>v`w]x+q+xw]qx#kkxt+ksfix+ml"s=k2q#mnw]x+rq#m(mfi"q+sfiwylwq5q+rs=qw]xq+rk2{t+0mx#k
mfiEq+rklk>v`qx#k>q+wmlMnr"w]\r"t+mfi0mx#kx5sfilsfi]fimfit^wq+r"sfi\r"wk`w]lsw]fimfiq>ml"x+w]x+q#kl&qH]q#kt^w]l
]OF<:O(=
Ewt^x#qslmfiq+s=q+wmlMq+rk2x#kqmfiEq+rk{l">q+wml"sfiM>mlx#q#t^sfiw]l$q+xH24\rmx#klq#m0kq+rkwfimfiq+xmfi
ksfi^rwyxsfi]]k2s?=fi\==Jfi>\$sfil2"klmfiq#kuEq#kt-q+rk4]q#kt^w]l=Lufiq+rk
wfimfiqx#kqj k2nw]yx+{"0mx#kCwylq+rk2>m{t^x#kmfiq+r"w]xx#k>q+wmlq+r"s=q0mfiq+rq+rksfix+x^wl"ukl$qmfit^"kt^w]l
sfil"2ps=t+ko`lmFnlnkCk>v<ysfiw]lrmFnLq+rks=t+kmfi"q+sfiw]l"kw]ls="0kl""w!vC<
 r"ksfifimfit^w]q+r"w]x>mu0mx#kmfix+kfikt^sfi4"t+m`>k"{t+kx  r"kwtC"w!0kt+kl$qCkfik]xt+k"t^kx#kl&qq+rk
q+rt+kk4x#q#kxmymFn4kq#mzk>lkwfimfiq>mlx+w]x#q#kl">fij k4"t+kx#kl$qq+rkx+k"t^m<>k"{"t+kxMw]lsfilsfix+>kl"w]l
nHs
 Ys=ofikCq+r"kC>ml"x#q#t^sfiwyl&q+x\Csfil04C45>mus=q+w]kfi
<4Hmu{q#ksuwfimfiq5424mfitsfi]05wyl(
 ^rwkfikCw]fimfiq>ml"x+w]x#q#kl>mfitq+rk2}0~
 t^m<>k"{"t+k<"&F&`#5$# : s=ofikxz>ml"x#q#t\sfiw]l&q+x5Husfil"\H>mus=q+w]kfi5wq

t+kumfikxCt+m^q+rmx#kq+{"kxznr"wy^rml"mfiqCr"sfiks>mumlx+{"0mfit+qw]lEmfitq+rkx#kqn4m
>ml"x#q#t\sfiw]l&q+xElk>kx+x^s=t+fiwq>t+ks=q#kxq+rk>ml"x+q#t^sfiw]l$q0^z0kqn4kklq+r"k:s=t\w]s=kxHHusfil"  
=Ffififi	ff
fiff:ff
&! "
#fiF$
 
%'&  &  (*) + fi

&-,/.!'&021
#3&  &  (5
4 )  6&  &  (5
4 )  fi7&8"%98fi	::;&  &  <#:=) +
!"0>#=

!"0
t^m<>k"{"t+@
k ?
 A`&z4`#5  s=ofikxsfi]>ml"x#q#t\sfiw]l&q+x\>ml$q+sfiw]l"w]lHsfil"(x+{"\rq+r"s=q5 CB DFE
H>mus=q+wk5nw]q+r4C 4$x+{">kx^x+wfiksfi]yx-q#mq+rkx^{"t+m{q+wylkH<:`$`#H&#   
q#ktwq+x5>mu{q+s=q+w]ml"HC5w]xHq+r"kt+kmfit^kCsuwfimfiq5mfiE!DFE
=FfifiGfifiHIffI!
&! "
#fiF$
 
JK-(<LMNPO:RQSfiTQKUVW(5XYfi;fiffff
!fiZ:['	\K
!"0
 rk}0~w]x5wfimfiq>mlx+w]x#q#kl$qw!;sfil&(=s=t^w]s=kzHCmfiE7

7wyxHq+rkq+s=t+fikqmfisuwfimfiq5mfi-DFE>

]!^`_`aWbdce8fgdeihkjlceffmjonqprtsuwvKectvSxyy0cwzShKjle*{P|n}cwz~Zr+|8mg!gdechkgwr+|priR8m0uwe	mcn`bcxzkvSgprSw[
  r+|
uwepwSw\
   |8^
8

fi

	!%!!0i	!0JM!!	!0
ff!
0!$3	;
\  !;ffV0%!!	Zi0	ffff!J	!	= 
M	  ff  8
!0>
!0
Cq`!'`
Kffoff0wff	ffk0`0Pw'2iw'ZC`ffii'VH'0
0Vw'2iq-iw+5dtY[ikC5Mi;		k

	ff
fifififi
)*$+
*

  "!$#&%
* -,

CFq<i8i+q'i*	<qV+V
 q 00C0
0+i 0i -	q>+VP88+++%+VPq+8++	q+ i'0
0i0 PV;+P V `P+	0
P`0@@+VPq+8+ +	Y 8+		q @P0WV +VPR0+t +V+0iW0
+ViP++8Z-q 00ti0 P P
 	q ZP8ff++<`P 0 +V
+qC0ffJ+VPq+8++	 PV5
@P0
V  `V8P 	+VC` 00+
0
0+P+8i+8 q
It q 00t0
i'0C	<qV+P
P+P8 `80 
V0+Vt+ 0@0 + 2  @ V8V05+V	V+t0R+P\P+M0
+V	<qP++	
0+VPM PP+
Ki
+P +P
q 00 0
i0+
Vq	+
H5VJ	V0iq 00*0
5'i
	q ZP8ff+ [+Vi+
 V+
+P+P
T0
\+<V0
2	<q+ 
* o
0
P0 +MP +PPP+8++
W+	
\0
@+	
P
<R	+  0+q  V P+	5PM PP+
\	P5< P q8[	P0Z+
+
\+%*i
M
PZ8V0* `V8P<` 00+
[0
tq-000+q+Vi+i0+	<qP8-+VCq 00t	P+8Zi	V+ 0\

'

( )
)*
. "/0213 (4 536

2* 7* 8%
)9
)
(:
;*  <	ff
fifi=8
>
 ?fi@ABfiC EDGFIHJ%='
8 Gfi@ABfiC
 KJC!$#
L
M 3A
fifi
=:
%
N
O L & 8P: ?: *
RQffSJ
TH2
)* 	ff
fiUfi=8%WV XD L
Xfi @  fiC
 AJC!$# L
QffSR
TH2%ZY
[fi@ fiC
 \JC!$# XQ]SJ
TH2%_^ )9
8
L 8+Ei$
kj e ljP@<\mon e @ &% &%[
kj e ljPCkqmo
-` =abcD
]deC *fd @ C
EfiChg
p nUeC
r
kjP@8ljPCksmt
p n @ CT%[QffSR
TH2
)*Z
kj e ljUCu vneC r
kj3@3ljPCu wn @ CT%[x
L 8
L s* -,
)* =	
fifi=
* h,
dR)yzP:
{ |}b~HJ
{ |MbD
THbD%fY QffSR
TH2*
>
 fi@ fiC
DFHJ%x

rR&$%

 0++qPP0O w 0tq+	P+8qi8=: P 	P Vi)*OV":)*V0 L 	V-+PMR&$
@
+Vq0
 0 	P8Zi	+P+  8*2P* +	tV* -`, V)*t:]o% )o% &% ;+M0+i&t ;q0 0i023
* 0
0++	P<8Z 0V
* iV+Z\N 	V+o
 +V": V"
: +V;P	0+V`0 0(
  !6`> V8P+V
,`i)* P+ L 8%
 
$ I 	V  !>";E
d +PC+8+	$
:  Pw*+Ps`, iV 000+P P+V +P)0 808P-V` 0<q8% 
,q+-+8i0F+VP+0`P+ L 8 02* -` R	 +Vq* +V88++ +V000w+Pv
 +M0@i
it0Iq0
 0@i02P* P* 8Qq 02*X2g 	<q+ L  0V* iVP%
~2\3K2<P
Qq22"UzX GEMPzU
G\qUKs K$]P
G\qUKs K]\2\
 [2g 	<`+ L  0P* iV<&+
Ez3K2"Uz3GEMPzPKK$]2zP K]\2\
d  0V
* iF0wP&0 q0 0	P+8P8<: [Pi)* 	<qP3E
GEMUKzPffE\
<	A
G\qUK3$ff2$ 02*3E
2<P3GEMUKz%
"(

fif33<G2 3 X=P

Z-&zG)G&
G		zP<zz3	(()=K~(3G~?)PMG~"
G	?"zz"	A<G(83\3-(=	<hK  z  z    
k} 	<fz3 	")Gc z	3z
	


	 z&Xz	 l"3z)"fiff  A)38	(
3(	() <z		h)"8(z	G	(	






& 
k		"z$		((J  ~  z	3 38
	($  	3zz$(<	3)	   3	(3
 K
hz	z(	?)A=(z3=	zh)(	 ]





!#"%$'&)()+*-,-.0/1,2!3#+3#.4"2!/156&782:96;"2!/1"<,-=.#>;"@?A+*-,-.

BDCEAE!F:GHBI8F:J
K!LNM
O
w
PQRP

G UVC T U'FWJ
ST H
PQ8LNXY[Z
F X]\#^ _`MRZ
Jba]c X_`M8Z

B!dVCGHeEAI8F:J
xybz{z|1}x~`|1#}'y#|1

PQ c XYfL

UWghCJ T

Jba]c _`X

x{'yb}Wbz{~u|1
x]~sb~u|1'y#~u|1

BI4eI8F:J
K c Q[_iM
Sj4Xkbj4X
l c MRZ]_`X]\4mj4X
G L
n'oqpj#Qsr
t c k4Q[_uk

UVCIsv6F:J
T
g
B

;#"W&,2!34.4b-+2'.-2!/1,2!3b+34.4"2!/15fi-b?A>A3,-=.#>!"+2!.#8-A




fi0D

DA!:H8:
!N


R

 V  'W
 H
8N[
 ]# `R
b] `8

!VHA8:
b{1`1#'#1

  f

Wh 

b] `

{'bWb{u1
]sbu1'#u1

48:
  [i
4b4
  R]`]44
 
'q#s
  4[u

Vs6:




;#W0s46;;%W7qVu67@!

 6;##!

%!{;#-8#;4 1

 A ;## -V6;:%W7qVu67 ! V<f;b]
	#s-
fiff'A : ')NV'uA7 ; V : W7NV!b ;W;-
 W!+ -W#!+;)-Aff'A :%W7qVu67 ! V :!"0!]#1#%$
4#;&1!#4b-+'('
' :!H;%W7qV*)+
 A ;## -V6;:%W7qV ;7) ;qV]
,
 #R-"-Wff  6 :%W7qV ;7) ;qV : W7NV 0!] ;W ;-
 W!+ -W #!+;+
 A ;## -V6;!WN :%W7qVf;#/.10 ]
2
 #s-
3Wff  64 ;WNV' ;%W7N !WN%0!5b ;W ;-6]!-;-fi-$
#A+;'
 -A2Wff  64 !WNV' ;%W7qV :!-": 0!]7 :!968 H#;:1!44b-+'
' :!V'7!WNV;)+
<>=5?A@BCEDFHG6DEI*JBJKF4LMI;NPORQMST@VUFWXGYDI;J4BZJ1F4LI*NPO
[A
 #1W\ +!#] b-+ #!)"^$
-!$_A #`1!#+44%%-);-;K1##a 4 \-4 [!#P##
4  sA1#!-cbed1f>;
 -! #!g6 ]-\ -g1!#+44% - #h`'1H+ (8A]4b;{ + #!8#K1#
#!/6
 ]-\ -71!#844%+ j-i ; s-
 -:A #k1!#+44%P -A +4K1#kl  0++
!##4 &! #P ## -A  #;:s-04]:\ +; f!1#A->bedK!f nAm -4   #!KH+
o -4 #!1 #+1pA -\ -q1!b+44% +VA#K14>- ;n1!+ 08# 4(1A b+;-!@ 0#

r f!+s(6 #21A#+44%PMAm ;-+4 0#utjvwaxay4z{v{|P}~jMA #`1A#+44%PH+ <#;bR-#! #P 44
!###+#!b!]A m 
uA ]-\ -[1!b+44% -!m -#A #1!#+44% -! !+#K1#!-
A#Y1!#+#4%P+ 08+-#W!V##!A -\ -;1!#844% +0b44b146-\ b#%-A!+#K1#!-
A#1A#+44%fi-++


fipu"
7gn
Ej5
!




j  ;  M
5!K
 "a 

" 15
;j5

j
4%^%najaK%

  K{ Mj  
" 

4
M
4%
"Z
%aj%

5
 ;Z
K
 

   ""]

K aZ  
qa/1V1Vj:^M!;_q6M!q>"KHP;a(]1
5
]
11 ga    a  	p
  ff[KH%fi    a5]E
!#"%$'&)(+*-,/.01!2&32.4&# 5762,'89$/:;: fi
$'.?>KH fi D BCfiJ $/83 fiIL *M,/N#"%$'&OQP2:R3S

 a] UTe1aK  

).=<

e 
 V]aH]a a 

$/.?>
6,/89$/:): fiA@%BCfiAD ;.E<GFIH fiI@%BCfiI'J

a 
K E

 V  

  

 
WX!Y>/)8C3M*&OZ,/.?$/:?"%$'&)(G*M,'.0-;1&3.4& 5[6,/8Y$/:): 
fi  ) .\<]$/.^>_62,'8`$/:): fiA@%BCfiD ).\<
h
F
H
/
$
?
.
K
>
H
/
$
C
8
3
, N#"%$'&OQP2:R3S
fiI@%BCfiI'J
fiADiBCfiAjJ
fiIj
 L *-/

 bacBCdfe7g


 H
 a 
kRlPP  
K  kK2P 1K X  j
maKanR]
1ofiAp  Y  a]q#57R
amM]aKPr l  "  ]KV <tsvu n[aa1MPaPEPV ' PaKawfieP  5cPa
E
a]
  ]"TP  a  a  aH1aK>  a  aK   ]a  K>xfiAp  Y  a]q,TR
 [g
ayl  "  ]I
  KKyfiZaV  /a  
a]VK
' ] lPK7ZP    ay
P
1"0 n6   P>aY]1" :  ' ] lPKG
 ffn  n  nTa`
  lPP    `
 [  
P1
fi2{  \fiA@{z#|}fij- nf~HPa1
 pP"1
 ^v;I"?),&*-,/.01!2&32.4&A 5X6,/8`$/:;: fiA ;.<tsGu$/.?>b62,/8$/:;: fi D ;.<1V*2(&)($'&

dxe7g FH fi@pz'BCfiI'J $/.?>_H fiDBCfiIJ $/83 fijL *-,/N#"%$'&OQP2:R31F4"?8i,'pZ>j3>
&)($'& fiAp
@ zr|}fiIw S

 Ya4 0c  `
  /a  P ' fi%  a  aaK  /1Kp  a1I/)c4

  ]K1]a  a  f  a  
K  X7Zg    +lPP  aK  /Zg-n  2UTe1aK  
e1 1KG  a  RlPP  aaK  ]K  ]  "  4E  "( a/  lPK  PK   2  ]P&R
    a  
  ]1aKn  7
T qqqVYM!;1  a  K>  #a
  # q  n;VM!q16`9K>h[1a    a  aK  X9K,a24lP
2a    a1    a  Ka4 lPPa1r eaa ]    a1^  M5/a    
P     Y]1{a1`]aP4- nVp  lP1Ka(2   Y]/K6P]]    U Te1aK  
e1 1K
  lPP  a5K    a  a]     a  a5K  'n&]a  	aKaKa:{  lPP
 a5K     ]a  a]     a  a5K     U TE1
Ka ]) a    5&P  
P   [K
 a  Kaa  Mb fin
{p

fio{^

^/4V%h!%

;




   
/ h
!qZ
 - ;
M- !

Vq

V/h4!%
  O

/ 

M- 

C!%
  Z
CMC
  ;--CC
 )
  CZ

/Mp{2j12/jj2

{)?%




pMMp2
-)M2/2

R0'/f/=24RCCoVb'q
 

 i

Pivot consistency

 

 

Directional path consistency

 
 

 

0i
%

V
V



0

0


0#y%2RVb4''f2VMRCCV2Y'42V'%?/92V!CCV2900	ff
fio
 ^ ff 0'4C02VCC-'Rj! 4_2/C "w4''
   0
2VRCC42#
 
fi%$  $ &
 $'(*),+-  %0,
 0'CC  0'0_/ .%CM0A0 4R`2M/C
1
 VM2V'^4/=24RCCV2

243 2

fi57698:;#<:=>?6!>;@	=A	BDCE:FHGJI=KA	;L6!:K=LMNO<PQ5>

R SUWV%X/YZUW[\0V/]LS0^`_aSbT\0Y*cV&dfeYgdf[KS0hgYg^fX/YZibSb^V iX/_a^jkgiHeYgdf[Kkl^jmX/YZibSb^V iX/_aYgdonS!dV X/^S0YZikg\
T
[kl^jHX/YZibS!b^V iX/_gpKkgbTcfS!\\KiLY4crqffV%bjLY4cfits
utv!wyx{z}|~J	
 d YX/V ndVal	S!b"X/YZUW[KL^V nV/]kgX/^\!_YZiX/VmeYgdWV kgX?jhEkld?S!klq\0VamS!iS!^^jV iX&kg\!\!b
kl^UWYZb^OW^SUWV b,[dYX/V nLdV4LZK*KQYZiX/VeYgd%V kgXjYge7^jVWeYgdUWV&dhEkldSklq\0V b??s
 XjS0V&hS!iL&X/YZUW[Kkl^S0qS!\!S!^_qffV&^cV&V ia^cYOX/YZib^dkgS!iQ^bTff*{kgin1}{X/YgddV b[ffYZinb7^YWkgX?jS0V&hS!iL
[kl^j1X/YZibS!b^V iX/_eYgddV \!kl^S!YZia}&c%sd s^&shlkldS!klq\!Vf	sRTjS!bYg[ffV&dkl^S!YZi1iLV&V nbTQ*SigV iV&dkg\s
 L^1bS!iX/V#^jLVDX/YZib^dkgSi	^Hff*?S!beiX/^S0YZikg\pf^jS!bX/YZUW[\0V/]LS0^_S!baiLY*cQ*?sRTjLV#Y*hgV&d?kg\!\
X/YZUW[\!V/]S0^`_YgeJ^jLV,}\0^V&dS!iLWS!b^jV&dV&eYgdV
  "*        
&}
S!ib^V kgnYge'    eYgd[kl^jaX/YZibS!b^V iX/_OYgdTnS!dV X/^S0YZikg\K[kl^jaX/YZibS!b^V iX/_  S!b7^jLViQUqffV&d
YgeJhEkld?S!klq\0V b&pLS!b^jLV%bS!&V%Yge^jVnLYZUkgS!ibkgin1"S!b^jLV%bS!&V%Yge^jV%dYYg^TbV&^??s
'	

fJt,E4gffZ}Zg`'Z

RTjLVS!i	^d?S!ibS!XXjkldkgX/^V&dS!b^SXYgekm\0YX&kg\X/YZibS!b^V iX/_S!b^YHV ibLdV^jkl^km[kld^S!kg\Sib^kgiQ^S!kl^S0YZi
X&kgiq}VV/]^V inV nH^YakOiLV&chEkldSklq\0VgsV%db^T[dV bV iQ^f^jV[dYg[ffV&d^S!V bYgeJ[S0hgYg^oX/YZibS!b^V iX/_gp}S!i
[kld^SX&\!kld^jLVX/YZinS0^S!YZibinLV&dcfjSXjOk{X/YZibS!b^V i	^7[kld^S!kg\KS!ib^kgiQ^S!kl^S0YZiUk _WqffVTV/]^V inLV n^Y
kabYZ\!L^S!YZitsfVW^jLV i#V/][\!kgS!ijLY*c^Y1X/YZUW[^V^jVnkl^kdV S0dV nmq_H^jLV{K\0^V&dSiLkg\0gYgd?S0^jU1p
kgina}ikg\!\0_[dV bV iQ^TkUWV&^jLYn1eYgdfbYZ\0hS!iL"eiX/^S0YZikg\ff b&s
v%Ez~Q44Q
V[dYX/V&V n1S!i^cYb^klgV b&db^&p^jLVkgnnS0^S!YZiOYgekWiLV&chEkldSklq\0Vf^YW^jV,X&ddV iQ^Sib^kgiQ^S!kl^S0YZitp
^jLV i1^jV%V/]^V ibS0YZi1edYZU^jLVdYQYg^fbV&^T^YOkbYZ\L^S0YZits
 	fiff& t
  // g !#"%$ t	
%Ez~4?v&J m  ff&

 )
'& (
 *}, +.-/0  1 "234Z6587"{39L0O:;/3 < $ =t >?,9m39@g BA C
 t 	 3 9  ff& tIH J  W:	'&Q&K ff&4	 24,K3/ g4LF"G$  5

3

/
g


E
F

G
"
$
D
%EztN
z MO*P V&^b{bjLY4c^jkl^"kgi	_X/YZib^dkgS!iQ^{S!iX&\!nLV nS!i $ aS!b{bkl^S!b KV nts P V&^Q< $ tbX?j
^jkl^RA #SbOk[KS0hgYg^Yge $ =t/pTkginTSQS!^bhlkg\!LVmS!iUff&=t&sWVYZibV Q LV iQ^\0_gp^jLV&dVHV/]Sb^b
S,.
 Xl Y	SQ?s P V&^TbTnLV iLYg^VZff&S  ,[,[,[ SL,[,[,[ S=t Sg?s
ls  Qi _OX/YZib^dkgSi	^bkl^S!b KV nOq_ff&t7kgincfjS!X?jnYQV biLYg^X/YZi	^kgS!iaS!b7^jLV&dV&eYgdVYgqQhS0YZb\!_
kg\bYObkl^S!bV naqQ_2ff&Qs
\G
s ]Ygdkg\!K
\ ^)_ b&s^&s}0Q<W"s(]JS0db^&p'  < $ t/\0V&^CS  qffVS0^bhEkg\!VS!i`ff&t&sbaV X/YZintp

 A WS!b,k[S0hgYg^,Yge $ = t&s%}0kgin#A OkldVWX/YZibV LV i	^\!_H*X/YZUW[kl^S!q\0Vgs,V
^jbTjk hgV S   SQZc
 <K0ZbYLpK}0{S!bbkl^S!b V n1q2
_ ff&Zs
d

hgV&d_X/YZib^dkgS!iQ^TS!iX&\!nV nS!i
$

S!bbkl^S!b V naq_ff&QsfefV iX/VZff&S!bkWX/YZibS!b^V iQ^TS!ib^kgiQ^S!kl^S0YZisEg

h#i=j'kmlnopnqrnKrstq/uvoFw6uvx/y{z=u}|oFs~nuvlx/r/rnqIsFlx uno~x/s~IlxC/xs~nuvlxr/F=fuvKnuv'E6FfirxzIx/lnKEF=#
 uvx/sFo|n'/x/snulxrsFlxn |truvx,nr|oxln'x/oFs~oF r|uv}zu}|oFsno#zpnq/o|uvyq,nNrF%qo~|or/xs~nuvlxr/sFlx/n |trux,n
uvB3=|l4o~|}=Bz=u}|oFs~no#zu}mu}nl|uvyuxuvE4o~l|o%u}nEntr|yo~nuvxnqouvx/ntrx,nurnuvlx*l|tzo~|uvxy,rxz oFsFlxzx/lx
x/s~nuvlxrsFlx/n |truvx,nrF4oms~|o#rnoFz,Gnqofi|l,s~oF  uvx/yj


fiG

QI?=?6#6?8,4686#,4mZ),?@pZ#??%,6
C@N/@

,E3ZG

(F=4{6,3Z'Lb#4G4 ,/4?,N

#3L?3@4C'3/4CtNIKW3`?t'Z34N;W#)
;3c3(3E4bB;t,'2*;F;,C
 /N 	64 ff
b

;fi*?,6#
8N#4#6;G

4,fi4c6446c4,E4CN44  ? 
4,N6##,

!##,3;

8?#4;4 

$&%('*),+ 	-/.1032146579895:<;;>=Kfi?@032A4CB

 ;)Nfi

K'44p;N##6  4
,

##";

#

<DFE

GF)#6; 3 ,46H  c6RN  ;46Z;?##6f?4;B4 I 4?B?@6
?fip?fi6

mN44m;?##6mZ}6},m4

 ;)Nfip4;?)64,%4?CN44

#,  p*,4`4Z;fiJ;?4#,*?,I#";b#*G"Nfi6

 NZ#

'Nb

G?;4KLN4M#4M@fQI,4,,34Z6?N%),;?E?4
,4fQZ
#??{?G),  6;)
;#6#;GN?4#6  4?34G644fi6

 pZN6#6

)8;fiONP24?Z66E4fi;)';;{ON4fi4


AQ6?6`SR ;)N;`44#,

I N44),4??N#2,UT


4?4

 ;)Nfi

4;?)64,

 ?N?4#,4;;6V
;6T4W'??6b(#;6*4ZC4NTG,64
#;";??6#6;)
;6%6N?6#;C?@
,K4
?6#6,KX4,Z(?6f
4

Y


 T

 ;)N;4 2 '?N

Z 4?)6,4#4";,

 4;?)64,6  [Z4)4Z,4  ,Z?
6??6]\I84?^\Z`_@

a 4G43bcedgf]hji #2;N#
?Z4;N)64,

 {@4G#,G 



 N6N?kN

\Z  4N

dgfhji 34lT 

4?

 ?
6?NkNW\I`_  m@  34ZG"%N?4 dgfhCi 

on6prqtsuwvAx<y{z6sX|!sv}x1~ 

 N44f,4?N?#G#,f[T Wn6z6s|<svAxzrqt|![svAxAFzrqt|![svAxezwqt[vF]
z6svAx<[zrqt|![svAxfi{prqp1vAx<~
   ;)'fi84;?)64,BcZ;#C



prqsPuvAxKy[z6sX|!svAxKy{zrqt|![svAx<y[zwqt[{v&z6svAx<y	fi[eprqp1vAxt
AQ6?6

'

 44G;?##6]	#,

a 4G43bcd#i&
6K=#{ #,@` 



 {N44;?##6?fi6
AQ6?6J

;)N#6#6;I@

GF?#4;4 

a 4G43bcdgfK6 , f

8@?
,4;?##4G???6*




 ,8	4Z;?#6N#4;?4 on6prqsPuvAxKy{z6s|<svAx1~ 
nfi3(=GP3;3/3(I,N4@~
X@

fififiwfifitKfiKJfi

A66<"
33

6	K	fi]<

}
jKOt66(

^O"6<6K"]^"(""6

666]
 e""6A  e6fi
  g(		

fffi
  O	[	
fffi

 
  &
 K
    
 [ !" "fffi
 
 #^$"ff<!K 
%'&  ()!"fffi
  *+-,$.fi"/X0%1&  ( !" "fffi
 4  4 76 498;:< 6>=    t
 ]32(O"fiO    ![   5
"""  /][366O"fi@?AB^W  
 "U66fiO <
 

  666O   

l!el^DCr  UUE!6F2!"6^6fi6"  HG{JI5Kw6(
  KS<6([UO"firfifi
  

QPtKoHGe!"

C

HG<LC

6O{O"6E!6Ol{  

I6  
MW<    tNK99O"6E<<

"P

9"fi}    ]9e"6eL  QR

OKw 

K  

O"666({  r6	fiLOI    !69[O"TS

KU6<"fie

  LL  !6"6"6e  UK  "6fi



 (]]O"fi6OI6VKe9Ke

 `b[	 c[
 d OP

 fi[U 
e"fhgji'fftkmltQ
onOplt3gd
XW$Y9Z[FW3[]\ '^_ Aa
o ne` " ql6rfftsmltQ
UondPfid 	333gdon  "
ffNplt3gfft"Pdg on
<"3Uonff!d fi33"33m
g

z9{|}}}|	z [9O"fi<fiK("F  r!w
{|}}}3|

=Oy
=
y~
x=3
CrO6  RIw C9Ot6C"L""  ` J !
=
k{
 r
C K
C ,U   Ofi6KU"
2fi
^  

 =7
|	z 
O"6!
E <>Ofi6E!2 z
6     z
Iw6I{dIj"6
f
=    =  
O"6(KfiK("C
6(66Jw I[  / "6" ""C6fi6w 
)
=
=
I
2 [
I w
K Ifi
 K(6<"6 F!
2 "fiIfi9Ot6>^  
"6"
I   O"6!
E <LOt"6e"6fi(U
K I    O"6<
6K"66   eO A  ""fi ` 

XW$YY9t"u 1
v xw

f1dxh'
 P!6

<CO"fiK

<69e  JO"6KLWV]OK

66" 



6O  e
MW6OW@	fi6U""6?AB6  fi9]9""  ]

s	<!fi6OJ6K

!O"fi6OI1fiH2eO"6(6OI&

O"6K/r3KlO"  
6OeNKwP

]fi 

fi 

O"66O

fK 


K     Kw

fi6O"6

  fiH2O"TS

O"66O  fi9">  

I  2

fiH2O"6<L@v1IFKw6fi"69  fiH2{O"fi6OU62t
fi6O"6-?ABK  F
I Ifi(6lO"66"firfi6K   

9O!fi

LO"6<l(6<"J

""F

K  ^ 6<6O"9""   ! fi "   "fi9ITK  ( 
O  O"fiOPA"Ht
2 fi6O"6?AB6-CrLK9"K  ]  l 
3$

fiV3aH

>d	H>m-j	de"Qm	HL	mm
	d"] >d	H>9-	me	d9m	9H
m9m
jjk9		mf"d9>	m)	L		m-mm	9Hs)>HQjDs	dT
mmmdjdd"	
 m		d"s"5xQjmX9	m	mks	dTdkeH	m	9QkVm]mXf	d

>m]	DmJm9
	H>mej;		d
ds93]Vm>dj9mH>
		mQm	QVQ>km	TH>mO	ddVH	Jm			HVxa		e

>m]	s"	msj	mQx	d;
>m]De	d;d	a>"	D>Hm		m
>mHm9)	m)
 x	>s9	9HQ	Q5  H"-m	mjJ"	xm	9HjDjm	

m	T
		d>x"k
>9
"dLV9x
Te	mk99	H>'	mkQ	dFkm	)d	
mmb		)ma;>	msd		H>;md"	mU>dNk	d
d	f	mVs	dTN)	mV	d
>e@	m"]OFd3V;";	dXm"F
	m>d
N	Fm)		QH1	d
>	Fm	H>;@	dXm"F
	V x"	V9Hked
k	dj	dXm99Hk
>m	9
m	ds	T
>m	m
Nm"a"	He

>d"	am"HUm>9m	;mT9	>sXm	HQ mf9"	-hammdD
Q99	Fa
>Q-
F>d	'Lf	dV	Q)m	9HLmmdj>
 Qmm
	H	ds)		>mLm	9	-'m]d	k">>]s	3-m
>sD
>m]	QNmm9
NF;	dX"dQ9	F
"	ddaHf	mVVdkU9	9H
O9m"mX	md
>m	"	O		a9m	m]d	mT	>s
>m]	VQ
m9m
d>dx	X"HVm]JQ	>NH;J
T9H>"H>x	d
;"
 m9dQmJ"m"
]Hd	e-m	HQOmFdQ	F		VL	U'	ex1
m	HQOed>]HNdFde"VdJ"mHTd9H
>m	9
N		m	"j	d

>	9Hf	dx"Xm"	m 9
1
>mmd	Tdj
>m	mVQ	x5
>m"	QxV"	d
	]"Q	Tm-	9">)s	mmX9
Tmmm	9@F9	md"m"
]H	H>Q
m			1m99	F
"	d>1Lk	@9
>9"	]'k	d-	@
>9"	

 
	fffi'		ff
	
"!$#&%('*),+-.0/1.324'ff56'879/;:<2=5>2=)-)@?''8.BACD.E
)h

Od
TsHm 	mQ9UQd	mH	dm]	H>k	d
>s9m		H>
m		Od"mx	d		mXm	dO>d  H>m	X D >]

GF

GH

IKJffLNMOPRQffPTSUJffVWJ3XNYffZ\[^]0_3`ffOa3_\`;b8]0QMdceJ3XNYfff*g
h >s9djilkmonpoqororor\qsnt>
u 	m5	d	>d>Q
>md
;
>s>d	Yfffr
v h >s9d"9wYffZk =xqzyZ ]LVd	"	
|{UV} jx 	d"mm
	H>V
		>d>H
>9d

>s>d(n~o} Lm	d"
d	D"">{O
} {$
 Vm
>9H1N"X
T	;">s	
;n } Us	
N>n  
IKJffLNMOPRQffPTSUJffVWJ3XPsc_
J*O]0a\_"J3XNYffZ\[QffV`6Psc_]0JJffP
_PJ3XNYfffg
F h >s9d	dZkmG{sRoqorororGqT{Tfi\u @	d>m"
)YffZ 
F
 )h d>	e"	>d"
{TUX >kZ "
Nnff 9Vm]Va	m"O
H VVdX E m	T
	N	9ON)s	FOOYFf 
F
\0

fi8888zD8D38Bd~*D1*18

1



d

d

d

d



G
ffjG\T3T3
  G0
  G0
ffjG0T3T\

1


1




8



1RGTo,R1TT1~1GTGff~GDR








  GzGT  



d1R1To8j
8R1^RG8~GN
8
~NRT~G

1

1





1





  


$



&

~








(

)%

d1 To8
~  ~~&R
9To
-

.-

/ 01

!



% ff

'



+*

 \ U   U
\U K\ \
U Uz zU 

  	 







1

d
0D\fi 
U    
\ U 
   
 D  0 R  
 d 0





 


,

 

" #



 


ff fi

!

fi24357698

:<;>=@?ACBCD9EFHGJIDKAC?ALNMO"PRQTS"OSPVUWIC?G)XYX9Z\[]+^R_`^R]bac]edgff)PhOSPYi
?I?lGJIC?"G)mnBC=`G)XKXKZBoNEp;c=@?AqBCDKEF`ALsrtIACBu`DKA'UvGwICE>E)B4AC?Bxi.G)FtyHD9z{ACE@utDKA|B k

j4k

?"rtIAqB|A k
~

?B=`AA k


U.

v

E oB k

E oB k

GJBB k

?lAq?B4UeoN?"mnEwt=@Bq?yHDKAGICEcE)B4Aq?BL

GJBG)FffZ
)?ICBq?n	DKAGy@?ACmn?F`ytG)FffBzRICEeG)F	?X9?w?FffBE)zU




FtD9BCD9EFuT

DYA'B k

?+ACG)w?AqBqICEF`X9ZHmnEF`F@?mnBq?ymnEEF@?F>BG)AhhZHy@?nr`

?FHGwy@?Amn?F`y`G)F>B4z}IEB k

E.?XK??FffB+DKFU?X9EF@A"BqE.B k
y`?F@E)Bq?|tB k
B k

?BN?bG)?ICBq?n	E)z


ohEwEACACDKtDKXKD9BCDK?AL
j

 :F
?X9??F>BE)zUW?X9EF@ABqEB k



DYA|Aq?Bl]b^}_t^}]baT]"i

?")IGJ

qDYF

DKA'?X9?w?FffB

?AqBqIEF@X9ZmnEFtF@?mnBq?ymnEwEF`?FffBo

k	 cE@u7DKAF@E)BGAqE=@Imn?E)zB k
A=`m k



B k

 

?ACG)?ACBqICEF@X9ZmnEF`F@?mnBq?ymnEEF@?F>BG)A
k

DKm k

DKA|)IGJ

k

GJB'%{DKA'Gby@?ACmn?F`ytG)FffB'zRICEgg

I?`IC?Aq?F>B4qDKFHU.:mmnE)Iy`DKF`BqEwB k

mnEF>BCG)DKF`AN%u>G)F`yb%D9BCAIC?y`=tmnBCD9EFDKF
mnEF`AC?;>=@?F>BCX9Z)uB k

?B'|?B k


?B+=`A


?"y@?nrF`D9BCD9EFE)zsB k

?IC??nTDKACBCAGpACE=@Imn?

?)?IBq?nE)z

?lIC?yt=`mn?y)IGJ

oN?lm k


EAq?BqE

u@cF@E oDKF@B k
k

GJB4

DYAGy@?Amn?F`y`G)F>BzRICEvq%uG)F>Z.?X9??F>BE)zthDKAGy@?Amn?F`y`G)F>BzRICEWG)F>Z.?X9??F>BE)zgu
G)FtyB k

?IC?zRE)IC?lzRICE|gNsDKA4mnEF`AC?;>=@?F>BCX9ZGwy@?ACmn?Fty`G)FffBz}ICEG)F?X9??F>B4E)zU.

UeDYA4GICEcE)B4Aq?B
~

?F@EoA k



EoB k

GJBUDKA|]b^R_`^}]baT]%^RSKu>B k

?Bh=`Ay@?F`E)Bq?" U:ACAC=t?|B k


?B k

?lAq?B4E)zB k

?+TBqICEF@X9ZhEF`F@?mnBq?y
'EEF@?FffBCA4B k

X9?B'RUK?B k
AqE=@Imn?A

j4k

?Aq?BhE)zB k

?DKINIC?yt=`mnBCD9EF`AhDKF

?B{=`AVy@?F`E)Bq?h"p`B k

E)zB k

?IC?y`=tmn?yp)IGJ
k

u>B k

k

EAq?ACD9?DKAJc

GJBmnEF>BCG)DKFHG)XKXB k

 hZpy@?nr7F`DKBCD9EFwE)zU
uTB k

?IC??n@DKAqBCA4GJBX9?G)AqB|EF@?"ACE=@Imn?q"DKF

 RUpY>J7x'hEF`Aq?;c=@?F>BCX9Z)u@B k


?IC?y@Ec?AF`E)B?nTDYAqBG)FffZIE>E)BAC?BE)zACwG)XKX9?IAD9? xL

?IC??nTDKACBCAGICEcE)BNAC?BUpTo

o



DKm k
k

?B'wRUpK


?"?X9??F>BCA|E)zsU

?I?y`=`mn?y)IGJ

y@Ec?A4F@E)B|?X9EF`BqEwRU

G)A

 ADKF`mn?

zRICEG)F?XK??FffBE)zsRUpYhBqEwq  

?IC?l?n@DKAqBCAF@EtGJB k

?ACBqICEF@X9ZmnEF`F@?mnBq?y+mnEEF@?F>BIC?y`=`mn?ylBqE  s@ICEB k
?IC??n@DKAqBCA'F@E+tGJB k

 utG)F`y

k7k

z}IEG)F?X9?w?FffBhE)zU


?y@?nrF`D9BCD9EF

BqEbG)F?X9??F>B'E)zw`x

hEF`AC?;>=@?F>BCX9Z)u@UDYA|F@E)BGICEcE)B4Aq?B
UeDYA|B k


=tA4G]b^}_t^}]baT]ICEcE)B4Aq?B

fJ]7KSC^RPBDKAB k

mnEEF@?F>BCAu@B k



?4ACG)?G)AB k

?4mnEtXK?nTD9BZI?;>=`DKIC?ybz}E)INmnEt=@BCDKF`B k

GJB4DKA4p{ j

GJICG)Fu

J xu7D9zlDKAhB k

?4AqBqICEF@XKZ+mnEF`F`?mnBq?y

?Fc=`"?I'E)z?y@)?A|G)F`yB k

?F>=t"?I

E)zs)?ICBCDKmn?A

Up 7{` RRw{c


Y+VR
74 {.Y`t{\sV@ R7t7
?F@EoWy@?ACmnIDK?
~

E)Iy@?IxDKF@@

?rtIxAqB`IC?AC?FffBB k
~

G)FG)X9)E)IxD9B k

EovBqEm k
k

B k

E>EAC?
B k

?
tD9)E)BmG)F`y`DKy`GJBq?AG)F`yBqEmnEt=`Bq?	G)FUwmnEtGJBCDKtX9?

?mnEF`y`DKBCD9EF`AB k

GJBpmnEwt=@Bq?AE)B k

?tD9)E)BNmG)Fty`DKy`GJBq?AN=`ACBACGJBCDKAqzRZ

G)F`yG)FUpmnEtGJBCD9tXK?E)Iy@?IDKF`@

tD9)E)B4mnEFtACDKAqBq?F`mnZDKwtXKD9?ANBohEmnEF`ytD9BCD9EF`A'EFB k

 :F>Zp'"DKF
DYA|B k



U+=`AqB'?B k

oh?B k

?Fp`IC?Aq?F>B

?Hy@?nr7F`D9BCDKEFE)z

?ltD9)E)BCAL

?BCGJIC)?B4E)zVEF`?G)FtyEFtX9ZwEF@?tD9)E)Bu@G)F`yF`EJGJIDKGJtXK?E)z{U

?BCGJIC)?BE)zsGb7D9)E)B



4%z

@E)I?G)m k





j4k

|4DKF

h+DKA|GtDK)E)Bu`B k





U
u)oN?
k



?F

G)?|BqElm k

DKA'?z}E)I?'+DKFB k



?n@DKAqBCAutADKF`mn?|y@Ec?A4F@E)B?XKEF@BqEwUx
ohE=`XKy?DKF,mnEF>BqIG)y`DKmnBCDKEF,oD9B k



EcEAq?|GGJIxDKGJtX9?N
.E)I?E)?Iu

mnEF`y`D9BCDKEF

	ff






DKF

?E)Ixy@?IDKF@@



AqEB k



GJBs



|"R

F`?mn?ACACGJIDKXKZ

+=`AqBF`E)BmnEFffBCG)DYF.G)F>ZmDKIm=`D9BuTo
k

DYm k

:o'GZBqE`IC?)?F>BwmD9Im=`DKBCADKA+BqEwGJI\?)?ICZ

fifi!"#%$'&()*)*+,-./fi
021435146872149;:=<=>?<=@31	AB<	C(9D72EF02143514687G<HC*1ffIJ:=<=>?<=@)351K<	LMENC*OH7QP*1!R(C(LS<=>T	149DENC*140ffAUIUP(?6PV?0W7QP*1
7Q<=>QO	1ff7E	XY<ZX[RC(687Q?5ENC(<	3)68ENC(0272><	?C/7IUP*EN021\E	>?5ON?CW?0<	35>Q14<	9*]SLS<=>T	149_^a`BP(?0bX[RC(687Q?5ENC(<	3)68ENC(0272><	?C/7
?07QP*14CG?C(6ff3R9*149-?C/72EdcZedA<	C(9G?57Q07Q<=>QO	1ff7f[7QP*1gC*1ffI;:"<=>?<=@351ihb?07QP*14CGLS<=>QT	149_^a`BP(1\021ff7cZejI1
E	@(7Q<	?Ck7QP(?0lI<4]k?m0U7QP*1d021ff7nE	Xa7QP*1po?5:	E	7n6ff<	C(9(?m9(<=72140lR02149K@q]%7QP*1po?5:	E	7n68ENC(0Q?m027214C(68]K<	35O	E	>?57QP(L
fr0214687Q?5ENCSsq^tsNh^a`UP(?0'021ff7u?C(9(R68140v<\o<=>Q7Q?m<	3/E	>9*1ff>wBxyENCdz{f[I1ENC(3]P(<4:	172E|<	99Z7QP(172><	C(0Q?57Q?5:?57}]
68ENC(0272><	?C7Q0~h^-CE	>9*1ff>|72E0Q<=7Q?02X[]7QP*1-68ENC(9(?7Q?5ENC(0nE	X\18)C(?57Q?5ENCsq^tsqA'7QP*1W<	0Q0Q?5ONC(LS14C7gE	>9(1ff>?C*O
68ENC(0214qR*14C/7Q35]P(<	072EW@1|<-3?C*14<=>187214C(0Q?5ENCKE	Xv7QP(1|o<=>Q7Q?<	3E	>9*1ff>|wBxo>Q18(149G@/]GK^l687QR<	335]	A
68ENLMoR(7Q?C*OMwBxF?0aC(E	7aC*1468140Q0Q<=>Q]ucZe?m0u0QRW6ff?514C/7u72E68ENLMo)R*721B7QP*1U3m?C*14<=>u187214C(0Q?5ENC_^u`BP(1ff>Q1B<=>Q1
C*ES68ENC(9?57Q?5ENC(0ENC7QP*1g:=<=>?<=@)35140E	Xvk*7QP*1<	35O	E	>?57QP(L6ff<	C7QPqR(0@1|9*1468ENLMoEN02149%?mC72Ed7IEW0Q721ffo0ff
 ^-2ff[/%
 R(LZ@1ff>BX>ENL  72ES !7QP*1g:"<=>?<=@35140E	X'J<	C9%LS<=>QT7QP*14L
 ^-2ff[/%z
 1ffo14<=7
 P*EqEN021g<MC*1ffIR(C(LS<=>T	149G:"<=>?m<=@351\Z?Cz!J0ff^7ff^a7QP(1ff>Q1n18?0Q7Q0<MLS<=>QT	149d0ff^7ff^

 R(LZ@1ff>B<	C(9%LS<=>TW
 C/7Q?3<	33:=<=>?<=@3140<=>Q1LS<=>QT	149
 ?5ONR*>1 4 o(>Q140214C/7Q0<	CW<	3O	E	>?57QP(L68ENLMoR*7Q?mC*O@E	7QPW7QP*1\0Q1ff7E	XYo?5:	E	76ff<	C9(?9(<=72140cZe<	C(9<	C
S68ENLSo<=7Q?5@351l<	0Q0Q?5ONC(LS14C7aE	>9*1ff>?C*O*^uY1ff7bR(0a>1ffo14<=77QP(<=7<	C/]S3?C(14<=>a18q7214C0Q?5ENC-?m0Q0QR*149MX[>QENLcZe
?0<	CKS68ENLMo<=7Q?@351gE	>9*1ff>?C*O*^
 `UP*1|021ff7(N/(W68ENC7Q<	?C07QP*1|:=<=>?<=@31407QP(<=7UP(<:	1<	35>Q14<	9*]@1ff14C72>Q14<=72149
 `UP*1%021ff7M*//*//)/!68ENC7Q<	?C0M7QP*1KC*187M:=<=>?<=@35140p7QP(<=7W6ff<	CF@1%6P*EN0214CA7QP(<=7W?0d7QP*1
RC(LS<=>QT	149WENC*140IUP(?6P-<=>Q1\7QP*1\7Q<=>QO	1ff7E	X<pX[RC(687Q?5ENC(<	3)68ENC(0272><	?C/7bIlP*EN021\E	>?5ON?CW?0L-<=>QT	149
 `UP*1021ff7Q0-	)	(iB[Ny68ENC7Q<	?C7QP(1E	>?5ON?C(0pE	XUXrR(C(687Q?ENC(<	368ENC0272><	?C/7Q0dIUP*EN021G7Q<=>QO	1ff7Q0W<=>Q1
9(140Q68>?5@149<=@E:	1Wf[*/qqi/h
 %>Q1ffo>Q140214C/7Q07QP*1CqR(LZ@1ff>E	X7QP*16ffR(>Q>Q14C/7:"<=>?m<=@351g?CG7QP*1<	00Q?5ONC(LM14C/7E	>9*1ff>?C*O
 =~24r8ff
D 1ff7UcZed
 	)=rrr=N<lX[R(C687Q?5ENC(<	3N68ENC(0Q72><	?C/7v?0Y<	9(9(14972E\cZeV14<	6Pp7Q?LM1<lC*1ffI:"<=>?<=@351
n?0a6P*EN0214C_'I1U7QP*1ff>Q1ffX[E	>Q1UC(1ff149S72Eo>QE:	1l7QP(<=7<	C/]d:"<=>?m<=@351E	XzW?0b02143146872149Q/N4r
ENC681	AN<	C(9|7QP(<=7C*ENC*1b?m0Y021435146872149ZX[>QENLk^`BP(1a:"<=>?<=@35140v<=>Q102143146872149X[>QENL*/qqi/A
IlP(?6PGENC35]68ENC/7Q<	?C(0lR(C(LS<=>T	149G:"<=>?m<=@35140ff(0Q?mC(681|C*ESLS<=>QT	149K:"<=>?<=@351gLS<]@1|R(CLS<=>QT	149
@)<	6QTA'<	C91ff:	1ff>Q]y0Q1435146872149y:=<=>?<=@)351S?0L-<=>QT	149_A1ff:	1ff>Q]:=<=>?<=@351S6ff<	C@1-021435146872149H<=7dLMEN027
ENC681	^
Y1ff7UR(0C*EiIo(>QEi:	1|7QP(<=71ff:	1ff>Q]G:=<=>?<=@351\E	Xz!J?0|4r(=[-fr<=7B3514<	0Q7ENC(681ih021435146872149b<=7
<	C/]7Q?LM1	A*/q//i/?0\7QP*1S021ff7gE	X<	3m3u9(?5>Q14687g9*140Q6814C9(<	C7Q0nE	X7QP*1SLS<=>T	149!:"<=>?m<=@35140
7QP<=7d9(EC*E	7p@1435ENC*Ok72Ek<=7p14<	6PDENR*721ff>M35E/E	oHE	Xl0Q721ffo  Aa<!C*1ffI:=<=>?<=@351?0p18q72><	6872149
X[>QENL*//*//)/<	C(9GLS<=>T	149_*X>ENL7QP(1\9*18C(?57Q?5ENC-E	XYKA*<	33:=<=>?<=@3140bE	XzkIU?33
7QP(1ff>Q1ffXE	>1|@1g>Q14<	6P*149k<	C(9%?C021ff>Q72149?CG*/q//i/(^
==

fiUi5
(/
5Q	54=QN(
* (

 	
fifffii 
 j/
 ki
 
(')*+

fi!N)=#"$$%&

, . -0/ 13254687 -09:d<;>=

? (/ (N*AB @ = C
D EE	GFIHJ'qq((i =
*&FIHLKNMPOfiFIHQ
C ((RMTS
('
) UF H ? T
'()
Ofi*VW
CU')
  j/XF HZY F\[]>^N
I^ F_[ CW'qq(N(
OfifiF [ 
U
 	
fffi/
 
 
OfifiFIHa
N! 	#"dc%
=   
= ?   

, . -0/Le 13254687 -09:d<;>fhgi=kjmlN(Q.9 4n

= 
': 4

=F`[ab @
=

C

Q5N<;_o8p

o8p 
? (/ (N*AB @ f C
D EE	GFrq its	 *T)u
  CT)wvW*	
fiffCE/iE/
*&Frq&KNMxOfiFrqy
C (N(RMTS
('
) UFrq ? T
&(')
Ofi*VW
CU')
D EE	 GFrj
z ts = *){(*
u jT
  )|vx	! )=i}"~C%
OfiFIz Y Frqy
 o8p
  j/XFq Y F_&_^$
r^ F_
 Cyq
' q((UC
OfifiF_G
CU*
 	
fiffCEfi iE/
 
OfifiFrqy
&N! 	(i#"%
=   
= ?   
9- fi1 l 6 / 4

Q=Q5N%<;S-ffB<;|/)		 n 	 ((=.-4}o8p		= n  6 /=Q 7 -g<9-09:



`<fi 7fiXn N(2.9 4En Q5N<;d-y.-ffQ !	)	(i}"c(% P"9 7 - FIH %(-09Q.-
!N)=#"c(%  6Q6 -(m=.-4  ;[.-09 F H (	 7 -0-4V 4687 -09-(SN(  //-4J;[<9-- 4 C
6 9<- F [< ,  EF [ - n -4QQ9   4687 -09-;.-09 FrH 

(mB	QQ:N 6 -4<9-09:J= n  6 /=Q 7 -
 = 9 7 -49-| 7 q 4 Q  *N.-|Q<-4;d9Q
 -E92
 ( 9- n  n N( - 4 -4 n -|<; n N(5Q5Ned 7 <- 



6

=

K 2.-0/ S   -g	-09 n N(Q5N

fiEEIEECETE_Er

 ((
`
I<..0<Q<a..<fi(.0*TEJI|Q<ifi00><
 <<]  LEQ<a<0.(QQa<{0(LE..0fi
(E..<Q<Ex.#Ex<.ifiQ.X}<0<#a(aC P
0  <
Q
#0fi







	ff
 fir
.&QT

rr.0}  }E<  (


r

 "!$#%"&(')%"*+%",.-

  CBI(aE.0EDC0GF|<.<H JI (LK
0  <rI  <fi<<<(Mfia(E0fi0I0  <rI  (Qa<
<<(0N/<.<POEr<0<R
 Q_<0<T
 S(EM
  <(VU(3}
<{JQ<r_E0>#>.ar<`E<W E{<.8X
 Z
 Y[:=2[\]>@< .
_^.G03257Y`baMc[d?A  V2e6?:)7
/#.<103254)6798;:=<?>@6)8=7A.<

%[gL%[h%"b%"f

I0<<5Bw9ij_kmlNn]o "pCrqaTs

 pCrq N
nut.n]o "
 vC[Q_0

Iu0w <MB9i.i_xXOyK$(..r<8yK$(..r(<bz{n  |} o . ~E$ t re}  [.|
 ji9 ikC

I<O89i.Ck}Q\<<<QQF|<(<O5.  }EFwwOBr(..<LK
 .C
  nLo [q o } [q8  n  tnLo JJ t?o  t[o9t rq o ;
 DC8(
 Fw<.<3 <z ?

 q$m
 q 
 > x5
 ..X.j
BIfi<0 I
zn

 B5bBI(v.OXS<<(E0MQ>M9i.i_x?Br<.05.<E}(E..<0

 |}0 o ;~$  t e} .;_xMj9X.C

vCQ|39i.i.(


 }3 t qaL{~ z
n 

 (<_<iE ^.<Q(..<<RBZDbQX(WC(Q< V/
~] <wE<_
 x_fi<. ifi?
 B<N
 0 3 <"<<

 <	BI(..<Q3fi>I<9^aFwbK
<$Br.0Zv5(a((zn  |}0 o ;~$  t e} "">u(jXCfi

v5.0bE9i.ik?U3E<aDCa

v5.0ew9i.i<((kC0<.Q(<E<(..r<z{n

 |}0 o e
 ~E$0d t re}  )>;j9kj

<..0  <(..<  <(<K
 ~E$0d t re}  ?9r_X.fi
Q0z{n  |	}0 o ;

v5.0?=Q| 5
 S>9i..(0$I<K

v5.05eQ> ;
 Sw9i..i(|00E..0

 e}
t r

 )>u(=..X..fi

0<bK$I.(5N8N

<.L<(E<</

 <{BI(E..<Z#0N<fi0Zz{n  |	}0 o ;
 ~E$0d@

<ZO89i.i<(/.0<W(E..<#G<]<b^.LK
 n 
 }3   t q] {N
  JL ZE. .fi. .fi


fi;W

H9"9Z"{=L9	XbH[9HW9	[]].Nb[H93HW[{Emb[u3[VLb?
X L.?..X..X

 eZ y9H]r
 
{3
	3efiff W 		.  	(L9.L[rH9.H[]H$H933 W9[r.Cr[]]3.M
3H .rHW [3.	W9({r 	u;"@   reyr  ..Xb9X
."H]9= Wfi  .?! W#
" [W9	{W
$ 	 39P % {W# N.]]HJ{L9.ff'&("*)fi+-,/.
, HH ]]99HW$
 5[H[V]bH[9H	 .[1m
{
0 
2 be. LCrE r43   L T..


"]5HMM 5L9..T{X[.GN.HX]3.3X[ be.=]J{r u["r 
  . X

X

5W3[HJ L9.. ".]C"3
		W	r[]]3.MCHH.rHW= {r 9.N"@   reyr76  
M
 9e9b
)"39H T{) W 9
8 ]5.3=;(L9$N."[[].b:. 3	HW[R<;.=;b?>
@ 3 rr @  r;yy BA C D E F X
 .HF
G .HH?V
, H
5 ZL9.. N[H]]9"r1I" JG .3X
*Zff 	 H[ {r u "r   reyr
K L=.e.9X
$9#
ff W!L
 9[3]?!
) N{L9..M, 3$.[N H+	"H]]9[rff PXO 3W]9=ff{y 9
er   e K C
 D
. F. .X
$9+ff W
 $.H [u  L9..Q
ff [[[[
 W9MRW	   r"H]]9[r.S  @ 3 " 9u?>
@ [9b]DT .uryUZ 33  [u[;[?Vb 9F. b)X[.%W$ X	 b	X	 Y 9 W	 5H
$H.[u[V
Z  L9\M ]
" ^	G .Hb
Z 	[]]3. HP.( [[[.9H
T	 [3.;3HW9.[[	 HW[
]G"rHH"HXr93H 9y @  reyyy A L=.e9
X

$.3T[, W  [].m_, W`Q(
$ .[[75a .[9?){L9.
 P9P	 3Hb.O G"H..3. P
"H.].X5
% []H.[r HX]]9c
. .BLd 9re% .39]9 [H..3.GfG WHgZG WH Hb[
 UJT L9y3X> @  E]ihjhT @<k jlm  [)?9E_ F
b ?($ ."rB.O 9;N.".[b
L
(3H]9 ML9..'
 M"3
W	 ..3H[D .)H r"]]3.M)HHR .rHW [H.	 9P5.;= b ;
er   e[
m uD. .F. .X
)n]d .?+
ff L9  {[H<%C"o 3HCH933.[p	  9  3" 
W	 ..3H[ @ ]{ be..
.;
= b    C  e9b 
O. 	;q (L9.
 /
8 $HE$ [
	 C.[${9r5He	 W P
	 	[]].(
" ^	G .HX9*L 
T L3X>   L{{{4lem  [?<
M 9 
X )b.r ].;N
	 @ .3"b
J
O.1	eH W  {93M]9s
ff L9.EM $N[]]3.M:Z) H93j.O 3H[  W	 ."
		 	[HH]9[r.]L 
T L3X>   L*tj*lm  "	[?  3.M.
J
$(.u
 9M]9HbH;F WM{PbO 	W	 .E
& WFv)) 9{ % eL9.
 w+
, .93J3x% r"H]]9[r
W	 ..WH[
." WHZ]59
	 W9HW[ {r ue"@   reyr[y A C
 Xw. bX
b 
z{z

fiJournal of Artificial Intelligence Research 2 (1995) 541-573

Submitted 9/94; published 5/95

Pac-learning Recursive Logic Programs:
Negative Results
William W. Cohen

AT&T Bell Laboratories
600 Mountain Avenue, Murray Hill, NJ 07974 USA

wcohen@research.att.com

Abstract

In a companion paper it was shown that the class of constant-depth determinate k-ary
recursive clauses is eciently learnable. In this paper we present negative results showing
that any natural generalization of this class is hard to learn in Valiant's model of paclearnability. In particular, we show that the following program classes are cryptographically
hard to learn: programs with an unbounded number of constant-depth linear recursive
clauses; programs with one constant-depth determinate clause containing an unbounded
number of recursive calls; and programs with one linear recursive clause of constant locality.
These results immediately imply the non-learnability of any more general class of programs.
We also show that learning a constant-depth determinate program with either two linear
recursive clauses or one linear recursive clause and one non-recursive clause is as hard as
learning boolean DNF. Together with positive results from the companion paper, these
negative results establish a boundary of ecient learnability for recursive function-free
clauses.

1. Introduction
Inductive logic programming (ILP) (Muggleton, 1992; Muggleton & De Raedt, 1994) is
an active area of machine learning research in which the hypotheses of a learning system
are expressed in a logic programming language. While many different learning problems
have been considered in ILP, including some of great practical interest (Muggleton, King,
& Sternberg, 1992; King, Muggleton, Lewis, & Sternberg, 1992; Zelle & Mooney, 1994;
Cohen, 1994b), a class of problems that is frequently considered is to reconstruct simple
list-processing or arithmetic functions from examples. A prototypical problem of this sort
might be learning to append two lists. Often, this sort of task is attempted using only
randomly-selected positive and negative examples of the target concept.
Based on its similarity to the problems studied in the field of automatic programming
from examples (Summers, 1977; Biermann, 1978), we will (informally) call this class of
learning tasks automatic logic programming problems. While a number of experimental
systems have been built (Quinlan & Cameron-Jones, 1993; Aha, Lapointe, Ling, & Matwin,
1994), the experimental success in automatic logic programming systems has been limited.
One common property of automatic logic programming problems is the presence of recursion . The goal of this paper is to explore by analytic methods the computational limitations
on learning recursive programs in Valiant's model of pac-learnability (1984). (In brief, this
model requires that an accurate approximation of the target concept be found in polynomial time using a polynomial-sized set of labeled examples, which are chosen stochastically.)
While it will surprise nobody that such limitations exist, it is far from obvious from previous
c 1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiCohen

research where these limits lie: there are few provably fast methods for learning recursive
logic programs, and even fewer meaningful negative results.
The starting point for this investigation is a series of positive learnability results appearing in a companion paper (Cohen, 1995). These results show that a single constant-depth
determinate clause with a constant number of \closed" recursive calls is pac-learnable. They
also show that a two-clause constant-depth determinate program consisting of one nonrecursive clause and one recursive clause of the type described above is pac-learnable, if some
additional \hints" about the target concept are provided.
In this paper, we analyze a number of generalizations of these learnable languages. We
show that that relaxing any of the restrictions leads to dicult learning problems: in particular, learning problems that are either as hard as learning DNF (an open problem in
computational learning theory), or as hard as cracking certain presumably secure cryptographic schemes. The main contribution of this paper, therefore, is a delineation of the
boundaries of learnability for recursive logic programs.
The paper is organized as follows. In Section 2 we define the classes of logic programs and
the learnability models that are used in this paper. In Section 3 we present cryptographic
hardness results for two classes of constant-depth determinate recursive programs: programs
with n linear recursive clauses, and programs with one n-ary recursive clause. We also
analyze the learnability of clauses of constant locality, another class of clauses that is paclearnable in the nonrecursive case, and show that even a single linearly recursive local
clause is cryptographically hard to learn. We then turn, in Section 4, to the analysis of
even more restricted classes of recursive programs. We show that two different classes of
constant-depth determinate programs are prediction-equivalent to boolean DNF: the class
of programs containing a single linear recursive clause and a single nonrecursive clause, and
the class of programs containing two linearly recursive clauses. Finally, we summarize the
results of this paper and its companion, discuss related work, and conclude.
Although this paper can be read independently of its companion paper we suggest that
readers planning to read both papers begin with the companion paper (Cohen, 1995).

2. Background

For completeness, we will now present the technical background needed to state our results;
however, aside from Sections 2.2 and 2.3, which introduce polynomial predictability and
prediction-preserving reducibilities, respectively, this background closely follows that presented in the companion paper (Cohen, 1995). Readers are encouraged to skip this section
if they are already familiar with the material.

2.1 Logic Programs

We will assume that the reader has some familiarity in logic programming (such as can
be obtained by reading one of the standard texts (Lloyd, 1987).) Our treatment of logic
programs differs only in that we will usually consider the body of a clause to be an ordered
set of literals. We will also consider only logic programs without function symbols|i.e.,
programs written in Datalog.
The semantics of a Datalog program P will be defined relative to to a database , DB ,
which is a set of ground atomic facts. (When convenient, we will also think of DB as a
542

fiPac-Learning Recursive Logic Programs: Negative Results

conjunction of ground unit clauses). In particular, we will interpret P and DB as a subset
of the set of all extended instances . An extended instance is a pair (f; D) in which the
instance fact f is a ground fact, and the description D is a set of ground unit clauses. An
extended instance (f; D) is covered by (P; DB ) iff
DB ^ D ^ P ` f
If extended instances are allowed, then function-free programs can encode many computations that are usually represented with function symbols. For example, a function-free
program that tests to see if a list is the append of two other lists can be written as follows:

Program P :

append(Xs,Ys,Ys)
null(Xs).
append(Xs,Ys,Zs)
components(Xs,X,Xs1) ^
components(Zs,X,Zs1) ^
append(Xs1,Ys,Zs1).

Database DB :

null(nil).
Here the predicate components(A,B,C) means that A is a list with head B and tail C; thus
an extended instance equivalent to append([1,2],[3],[1,2,3]) would have the instance fact
f = append (list12 ; list3 ; list123 ) and a description containing these atoms:
components(list12,1,list2), components(list2,2,nil),
components(list123,1,list23), components(list23,2,list3),
components(list3,3,nil)
The use of extended instances and function-free programs is closely related to \attening"
(Rouveirol, 1994; De Raedt & Dzeroski, 1994); some experimental learning systems also
impose a similar restriction (Quinlan, 1990; Pazzani & Kibler, 1992). Another motivation
for using extended instances is technical. Under the (sometimes quite severe) syntactic
restrictions considered in this paper, there are often only a polynomial number of possible
ground facts|i.e., the Herbrand base is polynomial. Hence if programs were interpreted
in the usual model-theoretic way it would be possible to learn a program equivalent to any
given target by simply memorizing the appropriate subset of the Herbrand base. However,
if programs are interpreted as sets of extended instances, such trivial learning algorithms
become impossible; even for extremely restricted program classes there are still an exponential number of extended instances of size n. Further discussion can be found in the
companion paper (Cohen, 1995).
Below we will define some of the terminology for logic programs that will be used in this
paper.
2.1.1 Input/Output Variables

If A B1 ^ : : : ^ Br is an (ordered) definite clause, then the input variables of the literal Bi
are those variables which also appear in the clause A B1 ^ : : : ^ Bi,1 ; all other variables
appearing in Bi are called output variables .
543

fiCohen

2.1.2 Types of Recursion

A literal in the body of a clause is a recursive literal if it has the same predicate symbol
and arity as the head of the clause. If every clause in a program has at most one recursive
literal, the program is linear recursive . If every clause in a program has at most k recursive
literals, the program is k-ary recursive . If every recursive literal in a program contains no
output variables, the program is closed recursive.
2.1.3 Depth

The depth of a variable appearing in a (ordered) clause A B1 ^ : : : ^ Br is defined as follows.
Variables appearing in the head of a clause have depth zero. Otherwise, let Bi be the first
literal containing the variable V , and let d be the maximal depth of the input variables of
Bi ; then the depth of V is d +1. The depth of a clause is the maximal depth of any variable
in the clause.
2.1.4 Determinacy

The literal Bi in the clause A B1 ^ : : : ^ Br is determinate iff for every possible substitution
 that unifies A with some fact e such that
DB ` B1  ^ : : : ^ Bi,1 

there is at most one maximal substitution  so that DB ` Bi . A clause is determinate
if all of its literals are determinate. Informally, determinate clauses are those that can be
evaluated without backtracking by a Prolog interpreter.
The term ij -determinate (Muggleton & Feng, 1992) is sometimes used for programs that
are depth i, determinate, and contain literals of arity j or less. A number of experimental systems exploit restrictions associated with limited depth and determinacy (Muggleton
& Feng, 1992; Quinlan, 1991; Lavrac & Dzeroski, 1992; Cohen, 1993c). The learnability of constant-depth determinate clauses has also received some formal study (Dzeroski,
Muggleton, & Russell, 1992; Cohen, 1993a).
2.1.5 Mode Constraints and Declarations

Mode declarations are commonly used in analyzing Prolog code or describing Prolog code;
for instance, the mode declaration \components (+; ,; ,)" indicates that the predicate components can be used when its first argument is an input and its second and third arguments
are outputs. Formally, we define the mode of a literal L appearing in a clause C to be a
string s such that the initial character of s is the predicate symbol of L, and for j > 1
the j -th character of s is a \+" if the (j , 1)-th argument of L is an input variable and a
\," if the (j , 1)-th argument of L is an output variable. (This definition assumes that all
arguments to the head of a clause are inputs; this is justified since we are considering only
how clauses behave in classifying extended instances, which are ground.) A mode constraint
is a set of mode strings R = fs1 ; : : :; sk g, and a clause C is said to satisfy a mode constraint
R for p if for every literal L in the body of C , the mode of L is in R.
We define a declaration to be a tuple (p; a0; R) where p is a predicate symbol, a0 is an
integer, and R is a mode constraint. We will say that a clause C satisfies a declaration if
544

fiPac-Learning Recursive Logic Programs: Negative Results

the head of C has arity a0 and predicate symbol p, and if for every literal L in the body of
C the mode of L appears in R.
2.1.6 Determinate Modes

In a typical setting, that facts in the database DB and extended instances are not arbitrary:
instead, they are representative of some \real" predicate, which may obey certain restrictions. Let us assume that all database and extended-instance facts will be drawn from some
(possibly infinite) set F . Informally, a mode is determinate if the input positions of the
facts in F functionally determine the output positions. Formally, if f = p(t1 ; : : :; tk ) is a
fact with predicate symbol p and pff is a mode, then define inputs (f; pff) to be hti1 ; : : :; ti i,
where i1 , : : : , ik are the indices of ff containing a \+", and define outputs (f; pff) to be
htj1 ; : : :; tj i, where j1, : : : , jl are the indices of ff containing a \,". We define a mode
string pff for a predicate p to be determinate for F iff
k

l

fhinputs (f; pff); outputs (f; pff)i : f 2 Fg
is a function. Any clause that satisfies a declaration Dec 2 DetDEC must be determinate.
The set of all declarations containing only modes determinate for F will be denoted
DetDEC F . Since in this paper the set F will be assumed to be fixed, we will generally omit
the subscript.
2.1.7 Bounds on Predicate Arity

We will use the notation a-DB for the set of all databases that contain only facts of arity
a or less, and a-DEC for the set of all declarations (p; a0; R) such that every string s 2 R is
of length a + 1 or less.
2.1.8 Size Measures

The learning models presented in the following section will require the learner to use resources polynomial in the size of its inputs. Assuming that all predicates are arity a or
less for some constant a allows very simple size measures to be used. In this paper, we will
measure the size of a database DB by its cardinality; the size of an extended instance (f; D)
by the cardinality of D; the size of a declaration (p; a0; R) by the cardinality of R; and the
size of a clause A B1 ^ : : : ^ Br by the number of literals in its body.

2.2 A Model of Learnability
2.2.1 Preliminaries

Let X be a set. We will call X the domain , and call the elements of X instances . Define a
concept C over X to be a representation of some subset of X , and define a language Lang
to be a set of concepts. In this paper, we will be rather casual about the distinction between
a concept and the set it represents; when there is a risk of confusion we will refer to the
set represented by a concept C as the extension of C . Two sets C1 and C2 with the same
extension are said to be equivalent . Define an example of C to be a pair (e; b) where b = 1 if
e 2 C and b = 0 otherwise. If D is a probability distribution function, a sample of C from
545

fiCohen

X drawn according to D is a pair of multisets S + ; S , drawn from the domain X according
to D, S + containing only positive examples of C , and S , containing only negative ones.
Associated with X and Lang are two size complexity measures , for which we will use
the following notation:

 The size complexity of a concept C 2 Lang is written j C j .
 The size complexity of an instance e 2 X is written j ej .
 If S is a set, Sn stands for the set of all elements of S of size complexity no greater
than n. For instance, Xn = fe 2 X : j ej  ng and Langn = fC 2 Lang : j C j  ng.
We will assume that all size measures are polynomially related to the number of bits needed
to represent C or e; this holds, for example, for the size measures for logic programs and
databases defined above.
2.2.2 Polynomial Predictability

We now define polynomial predictability as follows. A language Lang is polynomially
predictable iff there is an algorithm PacPredict and a polynomial function m( 1 ; 1 ; ne ; nt)
so that for every nt > 0, every ne > 0, every C 2 Langn , every  : 0 <  < 1, every
 : 0 <  < 1, and every probability distribution function D, PacPredict has the following
behavior:
t

1. given a sample S + ; S , of C from Xn drawn according to D and containing at least
m( 1 ; 1 ; ne ; nt) examples, PacPredict outputs a hypothesis H such that
e

Prob(D(H , C ) + D(C , H ) > ) < 
where the probability is taken over the possible samples S + and S , and (if PacPredict
is a randomized algorithm) over any coin ips made by PacPredict;
2. PacPredict runs in time polynomial in 1 , 1 , ne , nt , and the number of examples;
and
3. The hypothesis H can be evaluated in polynomial time.
The algorithm PacPredict is called a prediction algorithm for Lang, and the function m( 1 ; 1 ; ne ; nt ) is called the sample complexity of PacPredict. We will sometimes
abbreviate \polynomial predictability" as \predictability".
The first condition in the definition merely states that the error rate of the hypothesis
must (usually) be low, as measured against the probability distribution D from which the
training examples were drawn. The second condition, together with the stipulation that the
sample size is polynomial, ensures that the total running time of the learner is polynomial.
The final condition simply requires that the hypothesis be usable in the very weak sense
that it can be used to make predictions in polynomial time. Notice that this is a worst case
learning model, as the definition allows an adversarial choice of all the inputs of the learner.
546

fiPac-Learning Recursive Logic Programs: Negative Results

2.2.3 Relation to Other Models

The model of polynomial predictability has been well-studied (Pitt & Warmuth, 1990), and
is a weaker version of Valiant's (1984) criterion of pac-learnability . A language Lang is
pac-learnable iff there is an algorithm PacLearn so that
1. PacLearn satisfies all the requirements in the definition of polynomial predictability,
and
2. on inputs S + and S , , PacLearn always outputs a hypothesis H 2 Lang.
Thus if a language is pac-learnable it is predictable.
In the companion paper (Cohen, 1995), our positive results are all expressed in the model
of identifiability from equivalence queries, which is strictly stronger than pac-learnability;
that is, anything that is learnable from equivalence queries is also necessarily pac-learnable.1
Since this paper contains only negative results, we will use the the relatively weak model
of predictability. Negative results in this model immediately translate to negative results
in the stronger models; if a language is not predictable, it cannot be pac-learnable, nor
identifiable from equivalence queries.
2.2.4 Background Knowledge in Learning

In a typical ILP system, the setting is slightly different, as the user usually provides clues
about the target concept in addition to the examples, in the form of a database DB of
\background knowledge" and a set of declarations. To account for these additional inputs it
is necessary to extend the framework described above to a setting where the learner accepts
inputs other than training examples. Following the formalization used in the companion
paper (Cohen, 1995), we will adopt the notion of a \language family".
If Lang is a set of clauses, DB is a database and Dec is a declaration, we will define
Lang[DB ; Dec] to be the set of all pairs (C; DB ) such that C 2 Lang and C satisfies Dec .
Semantically, such a pair will denote the set of all extended instances (f; D) covered by
(C; DB ). Next, if DB is a set of databases and DEC is a set of declarations, then define
Lang[DB ; DEC ] = fLang[DB ; Dec ] : DB

2 DB and Dec 2 DECg

This set of languages is called a language family .
We will now extend the definition of predictability queries to language families as follows.
A language family Lang[DB; DEC ] is polynomially predictable iff every language in the set
is predictable. A language family Lang[DB; DEC ] is polynomially predictable iff there is
a single algorithm Identify(DB ; Dec ) that predicts every Lang[DB ; Dec] in the family
given DB and Dec .
The usual model of polynomial predictability is worst-case over all choices of the target
concept and the distribution of examples. The notion of polynomial predictability of a
language family extends this model in the natural way; the extended model is also worstcase over all possible choices for database DB 2 DB and Dec 2 DEC . This worst-case
1. An equivalence query is a question of the form \is H equivalent to the target concept?" which is answered
with either \yes" or a counterexample. Identification by equivalence queries essentially means that the
target concept can be exactly identified in polynomial time using a polynomial of such queries.

547

fiCohen

model may seem unintuitive, since one typically assumes that the database DB is provided
by a helpful user, rather than an adversary. However, the worst-case model is reasonable
because learning is allowed to take time polynomial in the size of smallest target concept
in the set Lang[DB ; Dec ]; this means that if the database given by the user is such that
the target concept cannot be encoded succinctly (or at all) learning is allowed to take more
time.
Notice that for a language family Lang[DB ; Dec] to be polynomially predictable, every
language in the family must be polynomially predictable. Thus to show that a family is not
polynomially predictable it is sucient to construct one language in the family for which
learning is hard. The proofs of this paper will all have this form.

2.3 Prediction-Preserving Reducibilities

The principle technical tool used in our negative results in the notion of prediction-preserving
reducibility , as introduced by Pitt and Warmuth (1990). Prediction-preserving reducibilities
are a method of showing that one language is no harder to predict than another. Formally,
let Lang1 be a language over domain X1 and Lang2 be a language over domain X2.
We say that predicting Lang1 reduces to predicting Lang2, denoted Lang1  Lang2 , if
there is a function fi : X1 ! X2 , henceforth called the instance mapping , and a function
fc : Lang1 ! Lang2 , henceforth called the concept mapping , so that the following all hold:
1. x 2 C if and only if fi (x) 2 fc (C ) | i.e., concept membership is preserved by the
mappings;
2. the size complexity of fc (C ) is polynomial in the size complexity of C |i.e., the size
of concept representations is preserved within a polynomial factor;
3. fi (x) can be computed in polynomial time.
Note that fc need not be computable; also, since fi can be computed in polynomial time,
fi(x) must also preserve size within a polynomial factor.
Intuitively, fc (C1) returns a concept C2 2 Lang2 that will \emulate" C1|i.e., make
the same decisions about concept membership|on examples that have been \preprocessed"
with the function fi . If predicting Lang1 reduces to predicting Lang2 and a learning
algorithm for Lang2 exists, then one possible scheme for learning concepts from Lang1
would be the following. First, convert any examples of the unknown concept C1 from
the domain X1 to examples over the domain X2 using the instance mapping fi . If the
conditions of the definition hold, then since C1 is consistent with the original examples,
the concept fc (C1) will be consistent with their image under fi ; thus running the learning
algorithm for Lang2 should produce some hypothesis H that is a good approximation of
fc (C1). Of course, it may not be possible to map H back into the original language Lang1,
as computing fc ,1 may be dicult or impossible. However, H can still be used to predict
membership in C1: given an example x from the original domain X1, one can simply predict
x 2 C1 to be true whenever fi (x) 2 H .
Pitt and Warmuth (1988) give a more rigorous argument that this approach leads to a
prediction algorithm for Lang1 , leading to the following theorem.
548

fiPac-Learning Recursive Logic Programs: Negative Results

Theorem 1 (Pitt and Warmuth) Assume Lang1  Lang2. Then if Lang1 is not polynomially predictable, Lang2 is not polynomially predictable.

3. Cryptographic Limitations on Learning Recursive Programs

Theorem 1 allows one to transfer hardness results from one language to another. This is
useful because for a number of languages, it is known that prediction is as hard as breaking
cryptographic schemes that are widely assumed to be secure. For example, it is known
that predicting the class of languages accepted by deterministic finite state automata is
\cryptographically hard", as is the class of languages accepted by log-space bounded Turing
machines.
In this section we will make use of Theorem 1 and previous cryptographic hardness
results to show that certain restricted classes of recursive logic programs are hard to learn.

3.1 Programs With n Linear Recursive Clauses

In a companion paper (Cohen, 1995) we showed that a single linear closed recursive clause
was identifiable from equivalence queries. In this section we will show that a program with
a polynomial number of such clauses is not identifiable from equivalence queries, nor even
polynomially predictable.
Specifically, let us extend our notion of a \family of languages" slightly, and let
DLog[n; s] represent the language of log-space bounded deterministic Turing machines with
up to s states accepting inputs of size n or less, with the usual semantics and complexity
measure.2 Also let d-DepthLinRecProg denote the family of logic programs containing
only depth-d linear closed recursive clauses, but containing any number of such clauses. We
have the following result:
Theorem 2 For every n and s, there exists a database DB n;s 2 1-DB and declaration
Dec n;s 2 1-DetDEC of sizes polynomial in n and s such that
DLog[n; s]  1-DepthLinRecProg[DB n;s ; Dec n;s ]
Hence for d  1 and a  1, d-DepthLinRecProg[DB; a-DetDEC ] is not uniformly polynomially predictable under cryptographic assumptions.3
Proof: Recall that a log-space bounded Turing machine (TM) has an input tape of length
n, a work tape of length log2 n which initially contains all zeros, and a finite state control
with state set Q. To simplify the proof, we assume without loss of generality that the tape
and input alphabets are binary, that there is a single accepting state qf 2 Q, and that the
machine will always erase its work tape and position the work tape head at the far left after
it decides to accept its input.
At each time step, the machine will read the tape squares under its input tape head and
work tape head, and based on these values and its current state q , it will
2. I.e., a machine represents the set of all inputs that it accepts, and its complexity is the number of states.
3. Specifically, this language is not uniformly polynomially predictable unless all of the following cryptographic problems can be solved in polynomial time: solving the quadratic residue problem, inverting the
RSA encryption function, and factoring Blum integers. This result holds because all of these cryptographic problems can be reduced to learning DLOG Turing machines (Kearns & Valiant, 1989).

549

fiCohen






write either a 1 or a 0 on the work tape,
shift the input tape head left or right,
shift the work tape head left or right, and
transition to a new internal state q 0
A deterministic machine can thus be specified by a transition function

 : f0; 1g  f0; 1g  Q ,! f0; 1g  fL; Rg  fL; Rg  Q
Let us define the internal configuration of a TM to consist of the string of symbols
written on the worktape, the position of the tape heads, and the internal state q of the
machine: thus a configuration is an element of the set
CON  f0; 1glog2 n  f1; : : :; log2 ng  f1; : : :; ng  Q

A simplified specification for the machine is the transition function

0 : f0; 1g  CON ! CON
where the component f0; 1g represents the contents of the input tape at the square below
the input tape head.
Notice that for a machine whose worktape size is bounded by log n, the cardinality of
CON is only p = jQjn2 log2 n, a polynomial in n and s = jQj. We will use this fact in our
constructions.
The background database DB n;s is as follows. First, for i = 0; : : :; p, an atom of the
form coni(ci ) is present. Each constant ci will represent a different internal configuration of
the Turing machine. We will also arbitrarily select c1 to represent the (unique) accepting
configuration, and add to DB n;s the atom accepting(c1). Thus
DB n;s  fcon i (ci)gpi=1 [ faccepting (c1)g

Next, we define the instance mapping. An instance in the Turing machine's domain is
a binary string X = b1 : : :bn ; this is mapped by fi to the extended instance (f; D) where

f  accepting (c0 )
D  ftruei gb 2X :b =1 [ ffalsei gb 2X :b =0
i

i

i

i

The description atoms have the effect of defining the predicate truei to be true iff the i-th
bit of X is a \1", and the defining the predicate falsei to be true iff the i-th bit of X is
\0". The constant c0 will represent the start configuration of the Turing machine, and the
predicate accepting(C) will be defined so that it is true iff the Turing machine accepts input
X starting from state C.
We will let Dec n;s = (accepting ; 1; R) where R contains the modes coni (+) and coni (,),
for i = 1; : : :; p; and truej and falsej for j = 1; : : :; n.
Finally, for the concept mapping fc , let us assume some arbitrary one-to-one mapping
 between the internal configurations of a Turing machine M and the predicate names
550

fiPac-Learning Recursive Logic Programs: Negative Results

con0,: : : ,conp,1 such that the start configuration (0log2 n ; 1; q0) maps to con0 and the accepting configuration (0log2 n ; 1; qf ) maps to con1. We will construct the program fc (M )
as follows. For each transition  0(1; c) ! c0 in  0, where c and c0 are in CON , construct a
clause of the form

accepting(C)

conj (C) ^ truei ^ conj 0 (C1) ^ accepting(C1).

where i is the position of the input tape head which is encoded in c, con j =  (c), and
con j 0 =  (c0). For each transition  0(0; c) ! (c0) in  0 construct an analogous clause, in
which truei is replaced with falsei.
Now, we claim that for this program P , the machine M will accept when started in
configuration ci iff
DB n;s ^ D ^ P ` accepting (ci )
and hence that this construction preserves concept membership. This is perhaps easiest to see by considering the action of a top-down theorem prover when given the goal
accepting (C ): the sequence of subgoals accepting (ci ), accepting (ci +1 ), : : : generated by the
theorem-prover precisely parallel the sequence of configurations ci , : : : entered by the Turing
machine.
It is easily verified that the size of this program is polynomial in n and s, and that the
clauses are linear recursive, determinate, and of depth one, completing the proof.
There are number of ways in which this result can be strengthened. Precisely the
same construction used above can be used to reduce the class of nondeterministic log-space
bounded Turing machines to the constant-depth determinate linear recursive programs.
Further, a slight modification to the construction can be used to reduce the class of log-space
bounded alternating Turing machines (Chandra, Kozen, & Stockmeyer, 1981) to constantdepth determinate 2-ary recursive programs. The modification is to emulate configurations
corresponding to universal states of the Turing machine with clauses of the form
accepting(C)
conj (C) ^ truei ^
conj 10 (C1) ^ accepting(C1) ^
conj 20 (C2) ^ accepting(C2).
where conj1 0 and conj2 0 are the two successors to the universal configuration conj . This is
a very strong result, since log-space bounded alternating Turing machines are known to be
able to perform every polynomial-time computation.

3.2 Programs With One n-ary Recursive Clause

We will now consider learning a single recursive clause with arbitrary closed recursion.
Again, the key result of this section is an observation about expressive power: there is
a background database that allows every log-space deterministic Turing machine M to
be emulated by a single recursive constant-depth determinate clause. This leads to the
following negative predictability result.
551

fiCohen

Theorem 3 For every n and s, there exists a database DB n;s 2 3-DB and declaration
Dec n;s 2 3-DetDEC of sizes polynomial in n and s such that
DLog[n; s]  3-DepthRec[DB n;s ; Dec n;s ]
Hence for d  3 and a  3, d-DepthRec[DB n ; a-DetDEC ] is not uniformly polynomially
predictable under cryptographic assumptions.

Proof: Consider a DLOG machine M . As in the proof of Theorem 2, we assume without
loss of generality that the tape alphabet is f0; 1g, that there is a unique starting configura-

tion c0, and that there is a unique accepting configuration c1. We will also assume without
loss of generality that there is a unique \failing" configuration cf ail; and that there is exactly
one transition of the form
 0(b; cj) ! c0j
for every combination of i 2 f1; : : :; ng, b 2 f0; 1g, and cj 2 CON , fc1; cf ailg. Thus on
input X = x1 : : :xn the machine M starts with CONFIG=c0 , then executes transitions
until it reaches CONFIG=c1 or CONFIG=cf ail, at which point X is accepted or rejected
(respectively). We will use p for the number of configurations. (Recall that p is polynomial
in n and s.)
To emulate M , we will convert an example X = b1 : : :bn into the extended instance
fi(X ) = (f; D) where

f  accepting (c0 )
D  fbit i (bi)gni=1
Thus the predicate bit i (X ) binds X to the i-th bit of the TM's input tape. We also will
define the following predicates in the background database DB n;s .

 For every possible b 2 f0; 1g and j : 1  j  p(n), the predicate statusb;j (B,C,Y) will
be defined so that given bindings for variables B and C , statusb;j (B,C,Y) will fail if
C = cf ail; otherwise it will succeed, binding Y to active if B = b and C = cj and
binding Y to inactive otherwise.
 For j : 1  j  p(n), the predicate nextj (Y,C) will succeed iff Y can be bound to
either active or inactive. If Y = , then C will be bound to cj ; otherwise, C will be
bound to the accepting configuration c1.
 The database also contains the fact accepting (c1 ).
It is easy to show that the size of this database is polynomial in n and s.
The declaration Dec n;s is defined to be (accepting ; 1; R) where R includes the modes
status bj (+; +; ,), next j (+; ,), and bit i (,) for b 2 f0; 1g, j = 1; : : :; p, and i = 1; : : :; n.
Now, consider the transition rule  0(b; cj ) ! c0j , and the corresponding conjunction
TRANSibj  biti (Bibj ) ^ statusb;j (C,Bibj ,Yibj ) ^ nextj 0 (Yibj ,C1ibj ) ^ accepting(C1ibj )
552

fiPac-Learning Recursive Logic Programs: Negative Results

Given DB n;s and D, and assuming that C is bound to some configuration c, this conjunction
will fail if c = cf ail. It will succeed if xi 6= b or c 6= cj ; in this case Yibj will be bound to
inactive, C1ibj will be bound to c1, and the recursive call succeeds because accepting(c1) is in
DB n;s . Finally, if xi = b and c = cj , TRANSibj will succeed only if the atom accepting(cj 0 )
is provable; in this case, Yibj will be bound to active and C1ibj will be bound to cj 0 .
From this it is clear that the clause fc (M ) below
^
accepting(C)
TRANSibj
i

2f1;:::;ng; b2f0;1g
j 2f1;:::;pg

will correctly emulate the machine M on examples that have been preprocessed with the
function fi described above. Hence this construction preserves concept membership. It is
also easily verified that the size of this program is polynomial in n and s, and that the
clause is determinate and of depth three.

3.3 One k-Local Linear Closed Recursive Clause

So far we have considered only one class of extensions to the positive result given in the
companion paper (Cohen, 1995)|namely, relaxing the restrictions imposed on the recursive
structure of the target program. Another reasonable question to ask is if linear closed
recursive programs can be learned without the restriction of constant-depth determinacy.
In earlier papers (Cohen, 1993a, 1994a, 1993b) we have studied the conditions under
which the constant-depth determinacy restriction can be relaxed while still allowing learnability for nonrecursive clauses. It turns out that most generalizations of constant-depth
determinate clauses are not predictable, even without recursion. However, the language of
nonrecursive clauses of constant locality is a pac-learnable generalization of constant-depth
determinate clauses. Below, we will define this language, summarize the relevant previous
results, and then address the question of the learnability of recursive local clauses.
Define a variable V appearing in a clause C to be free if it appears in the body of C but
not the head of C . Let V1 and V2 be two free variables appearing in a clause. V1 touches V2
if they appear in the same literal, and V1 inuences V2 if it either touches V2, or if it touches
some variable V3 that inuences V2. The locale of a free variable V is the set of literals that
either contain V , or that contain some free variable inuenced by V . Informally, variable
V1 inuences variable V2 if the choice of a binding for V1 can affect the possible choices of
bindings for V2.
The locality of a clause is the size of its largest locale. Let k-LocalNonRec denote the
language of nonrecursive clauses with locality k or less. (That is, k-LocalNonRec is the
set of logic programs containing a single nonrecursive k-local clause.) The following facts
are known (Cohen, 1993b):
 For fixed k and a, the language family k-LocalNonRec[a-DB; a-DEC] is uniformly
pac-learnable.
 For every constant d, every constant a, every database DB 2 a-DB, every declaration
Dec 2 a-DetDEC , and every clause C 2 d-DepthNonRec[DB ; Dec ], there is an
553

fiCohen

equivalent clause C 0 in k-LocalNonRec[DB ; Dec] of size bounded by kj C j , where k
is a function only of a and d (and hence is a constant if d and a are also constants.)
Hence
k-LocalNonRec[DB; a-DEC]
is a pac-learnable generalization of

d-DepthNonRec[DB; a-DetDEC ]
It is thus plausible to ask if recursive programs of k-local clauses are pac-learnable. Some
facts about the learnability of k-local programs follow immediately from previous results.
For example, an immediate consequence of the construction of Theorem 2 is that programs
with a polynomial number of linear recursive k-local clauses are not predictable for k  2.
Similarly, Theorem 3 shows that a single recursive k-local clause is not predictable for k  4.
It is still reasonable to ask, however, if the positive result for bounded-depth determinate
recursive clauses (Cohen, 1995) can be extended to k-ary closed recursive k-local clauses.
Unfortunately, we have the following negative result, which shows that even linear closed
recursive clauses are not learnable.

Theorem 4 Let Dfa[s] denote the language of deterministic finite automata with s states,

and let k-LocalLinRec be the set of linear closed recursive k-local clauses. For any constant s there exists a database DB s 2 3-DB and a declaration Dec s 2 3-DEC , both of size
polynomial in s, such that
Dfa[s]  3-LocalLinRec[DB s ; Dec s ]

Hence for k  3 and a  3, k-LocalLinRec[a-DB ; Dec] is not uniformly polynomially
predictable under cryptographic assumptions.

Proof: Following Hopcroft and Ullman (1979) we will represent a DFA M over the alphabet

 as a tuple (q0; Q; F;  ) where q0 is the initial state, Q is the set of states, F is the set of
accepting states, and  : Q   ! Q is the transition function (which we will sometimes
think of as a subset of Q    Q). To prove the theorem, we need to construct a database
DB s of size polynomial in s such that every s-state DFA can be emulated by a linear
recursive k-local clause over DB s .
Rather than directly emulating M , it will be convenient to emulate instead a modification of M . Let M^ be a DFA with state set Q^  Q [ fq(,1); qe ; qf g, where q(,1) , qe and qf
are new states not found in Q. The initial state of M^ is q(,1) . The only final state of M^ is
qf . The transition function of M^ is
[
^   [ f(q(,1); a; q0); (qe; c; qf )g [
f(qi; b; qe)g
2

qi F

where a, b, and c are new letters not in . Note that M^ is now a DFA over the alphabet
 [ fa; b; cg, and, as described, need not be a complete DFA over this alphabet. (That
is, there may be pairs (qi ; a) such that ^(qi ; a) is undefined.) However, M^ can be easily
554

fiPac-Learning Recursive Logic Programs: Negative Results

M

1


q


0

?

0 

M^

1



q



- ?

1

0

1

1







q 
q
q
q
q
  

,1

0

?

a

-

0 

M0




-

0

?

1

b,c,0,1








1







b

-

a,b,c
1

-

c

e


q

?

r

a,b,c

-

f

a,b,c,0,1
a,b,c,0,1


6

a,b,
0,1







q
q
q
q
q









,1

a



0 

?

-



0
0

-

?

1





,
,

,
, b -



e

c

-

f

Figure 1: How a DFA is modified before emulation with a local clause

555

fiCohen

made complete by introducing an additional rejecting state qr , and making every undefined
transition lead to qr . More precisely, let  0 be defined as
0  ^ [ f(qi; x; qr) j qi 2 Q^ ^ x 2  [ fa; b; cg ^ (6 9qj : (qi ; x; qj ) 2 ^)g
Thus M 0 = (q(,1); Q^ [fqr g; fqf g;  0) is a \completed" version of M^ , with Q0 = Q^ [fqr g. We
will use M 0 in the construction below; we will also let Q0 = Q^ [ fqr g and 0 =  [ fa; b; cg.
Examples of M , M^ and M 0 are shown in Figure 1. Notice that aside from the arcs into
and out of the rejecting state qr , the state diagram of M 0 is nearly identical to that of M .
The differences are that in M 0 there is a new initial state q(,1) with a single outgoing arc
labeled a to the old initial state q0 ; also every final state of M has in M 0 an outgoing arc
labeled b to a new state qe , which in turn has a single outgoing arc labeled c to the final
state qf . It is easy to show that

x 2 L(M ) iff axbc 2 L(M 0)
Now, given a set of states Q0 we define a database DB that contains the following
predicates:
 arcq ;;q (S,X,T) is true for any S 2 Q0, any T 2 Q0, and any X 2 0, unless S = qi,
X = , and T 6= qj .
 state(S) is true for any S 2 Q0.
 accept(c,nil,qe,qf ) is true.
As motivation for the arc predicates, observe that in emulating M 0 it is clearly useful to be
able to represent the transition function  0. The usefulness of the arc predicates is that any
transition function  0 can be represented using a conjunction of arc literals. In particular,
the conjunction
^
arc q ;;q (S; X; T )
i

j

i

(q ;;q )20
i

j

j

succeeds when  0 (S; X ) = T , and fails otherwise.
Let us now define the instance mapping fi as fi (x) = (f; D) where

f = accept (a; xbc; q(,1); q0)
and D is a set of facts that defines the components relation on the list that corresponds to
the string xbc. In other words, if x = 1 : : :n , then D is the set of facts
components(1 : : :n bc; 1; 2 : : :n bc)
components(2 : : :n bc; 2; 3 : : :n bc)
..
.
components(c,c,nil)
The declaration Dec n will be Dec n = (accept ; 4; R) where R contains the modes
components (+; ,; ,), state (,), and arc q ;;q (+; +; +) for qi , qj in Q0 , and  2 0 .
Finally, define the concept mapping fc (M ) for a machine M to be the clause
i

j

556

fiPac-Learning Recursive Logic Programs: Negative Results

accept(X,Ys,S,T)
V
(q ;;q )20 arcq ;;q (S,X,T)
^ components(Ys,X1,Ys1) ^ state(U) ^ accept(X1,Ys1,T,U).
where  0 is the transition function for the corresponding machine M 0 defined above. It is
easy to show this construction is polynomial.
In the clause X is a letter in 0, Ys is a list of such letters, and S and T are both states
in Q0 . The intent of the construction is that the predicate accept will succeed exactly when
(a) the string XYs is accepted by M 0 when M 0 is started in state S , and (b) the first action
taken by M 0 on the string XYs is to go from state S to state T .
Since all of the initial transitions in M 0 are from q(,1) to q0 on input a, then if the
predicate accept has the claimed behavior, clearly the proposed mapping satisfies the requirements of Theorem 1. To complete the proof, therefore, we must now verify that the
predicate accept succeeds iff XYs is accepted by M 0 in state S with an initial transition to
T.
From the definition of DFAs the string XYs is accepted by M 0 in state S with an initial
transition to T iff one of the following two conditions holds.
 0(S; X ) = T , Ys is the empty string and T is a final state of M 0, or;
 0(S; X ) = T , Ys is a nonempty string (and hence has some head X 1 and some tail
Ys1) and Ys1 is accepted by M 0 in state T , with any initial transition.
The base fact accept(c,nil,qe,qf ) succeeds precisely when the first case holds, since in
M 0 this transition is the only one to a final state. In the second case, the conjunction of the
arc conditions in the fc (M ) clause succeeds exactly when  (S; X ) = T (as noted above).
Further the second conjunction in the clause can be succeeds when Ys is a nonempty string
with head X 1 and tail Ys1 and X1Ys1 is accepted by M 0 in state T with initial transition
to any state U , which corresponds exactly to the second case above.
Thus concept membership is preserved by the mapping. This completes the proof.
i

j

i

j

4. DNF-Hardness Results for Recursive Programs

To summarize previous results for determinate clauses, it was shown that while a single
k-ary closed recursive depth-d clause is pac-learnable (Cohen, 1995), a set of n linear closed
recursive depth-d clauses is not; further, even a single n-ary closed recursive depth-d clauses
is not pac-learnable. There is still a large gap between the positive and negative results,
however: in particular, the learnability of recursive programs containing a constant number
of k-ary recursive clauses has not yet been established.
In this section we will investigate the learnability of these classes of programs. We will
show that programs with either two linear closed recursive clauses or one linear closed recursive clause and one base case are as hard to learn as boolean functions in disjunctive
normal form (DNF). The pac-learnability of DNF is a long-standing open problem in computational learning theory; the import of these results, therefore, is that establishing the
learnability of these classes will require some substantial advance in computational learning
theory.
557

fiCohen

4.1 A Linear Recursive Clause Plus a Base Clause

Previous work has established that two-clause constant-depth determinate programs consisting of one linear recursive clause and one nonrecursive clause can be identified, given
two types of oracles: the standard equivalence-query oracle, and a \basecase oracle' (Cohen,
1995). (The basecase oracle determines if an example is covered by the nonrecursive clause
alone.) In this section we will show that in the absence of the basecase oracle, the learning
problem is as hard as learning boolean DNF.
In the discussion below, Dnf[n; r] denotes the language of r-term boolean functions in
disjunctive normal form over n variables.

Theorem 5 Let d-Depth-2-Clause be the set of 2-clause programs consisting of one

clause in d-DepthLinRec and one clause in d-DepthNonRec. Then for any n and
any r there exists a database DB n;r 2 2-DB and a declaration Dec n;r 2 2-DEC , both of sizes
polynomial in n and r, such that
Dnf[n; r]  1-Depth-2-Clause[DB n;r ; Dec n;r ]

Hence for a  2 and d  1 the language family d-Depth-2-Clause[DB; a-DetDEC ] is
uniformly polynomially predictable only if DNF is polynomially predictable.

Proof: We will produce a DB n;r 2 DB and Dec n;r 2 2-DetDEC such that predicting
DNF can be reduced to predicting 1-Depth-2-Clause[DB n;r ; Dec n;r ]. The construction
makes use of a trick first used in Theorem 3 of (Cohen, 1993a), in which a DNF formula is
emulated by a conjunction containing a single variable Y which is existentially quantified
over a restricted range.
We begin with the instance mapping fi . An assignment  = b1 : : :bn will be converted
to the extended instance (f; D) where
f  p(1)
D  fbit i (bi)gni=1
Next, we define the database DB n;r to contain the binary predicates true1 , false1, : : : , truer ,
falser which behave as follows:

 truei(X,Y) succeeds if X = 1, or if Y 2 f1; : : :; rg , fig.
 falsei(X,Y) succeeds if X = 0, or if Y 2 f1; : : :; rg , fig.
Further, DB n;r contains facts that define the predicate succ(Y,Z) to be true whenever
Z = Y + 1, and both Y and Z are numbers between 1 and r. Clearly the size of DB n;r is
polynomial in r.
Let Dec n;r = (p; 1; R) where R contains the modes bit i (,), for i = 1; : : :; n; true j (+; +)
and false j (+; +), for j = 1; : : :; r, and succ (+; ,).
Now let  be an r-term DNF formula  = _ri=1 ^sj =1 lij over the variables v1 ; : : :; vn.
We may assume without loss of generality that  contains exactly r terms, since any DNF
formula with fewer than r terms can be padded to exactly r terms by adding terms of the
i

558

fiPac-Learning Recursive Logic Programs: Negative Results

Background database:

for i = 1; : : :; r
truei (b; y ) for all b; y : b = 1 or y 2 f1; : : :; rg but y 6= i
falsei (b; y ) for all b; y : b = 0 or y 2 f1; : : :; rg but y 6= i
succ(y,z)
if z = y + 1 and y 2 f1; : : :; rg and z 2 f1; : : :; rg

DNF formula: (v1 ^ v3 ^ v4) _ (v2 ^ v3) _ (v1 ^ v4)
Equivalent program:
p(Y) succ(Y,Z)^p(Z).
p(Y) bit1 (X1 ) ^ bit2 (X2 ) ^ bit3 (X3 ) ^ bit4 (X4 ) ^
true1 (X1,Y) ^ false1 (X3 ,Y) ^ true1(X4 ,Y) ^
false2 (X2,Y) ^ false2 (X3,Y)^
true3 (X1,Y) ^ false3 (X4 ,Y).
Instance mapping: fi(1011) = (p(1); fbit1(1); bit 2(0); bit3(1); bit4(1)g)
Figure 2: Reducing DNF to a recursive program
form v1 v1. We now define the concept mapping fc () to be the program CR; CB where CR
is the linear recursive depth 1 determinate clause

p(Y ) succ(Y; Z ) ^ p(Z )
and CB is the nonrecursive depth 1 determinate clause
s
n
^
^r ^
p(Y )
bit k (Xk ) ^
Bij
i

i=1 j =1

k =1

where Bij is defined as follows:

Bij 

(

truei (Xk ,Y) if lij = vk
falsei (Xk ,Y) if lij = vk

An example of the construction is shown in Figure 2; we suggest that the reader refer
to this figure at this point. The basic idea behind the construction is that first, the clause
CB will succeed only if the variable Y is bound to i and the i-th term of  succeeds (the
definitions of truei and falsei are designed to ensure that this property holds); second, the
recursive clause CR is constructed so that the program fc () succeeds iff CB succeeds with
Y bound to one of the values 1; : : :; n.
We will now argue more rigorously for the correctness of the construction. Clearly, fi ( )
and fc () are of the same size as  and  respectively. Since DB n;r is also of polynomial
size, this reduction is polynomial.
Figure 3 shows the possible proofs that can be constructed with the program fc ();
notice that the program fc () succeeds exactly when the clause CB succeeds for some value
559

fiCohen

p(1)

 A@
A@
AA @
@
B(1)





succ(1,2) p(2)


 @
A


A@


AA @
@
B(2)

succ(2,3) p(3)


 A
@


A@


AA @
@
B(3)
:::

p(n-1)

B (i)  V bit (X ) ^ V V B
i

i

ij


 A
@


A@


AA @
B(n-1)
@

succ(n-1,n) p(n)
B(n)

Figure 3: Space of proofs possible with the program fc ()
Vs l must be true; in
of Y between
1
and
r
.
Now,
if

is
true
then
some
term
T
i =
j =1 ij
V
V
s0
s
this case j =1 Bij succeeds with Y bound to the value i and j =1 Bi0 j for every i0 6= i also
succeeds with Y bound to i. On the other hand, if  is false for an assignment, then each Ti
fails, and hence for every possible binding of Y generated by repeated use of the recursive
clause CR the base clause CB will also fail. Thus concept membership is preserved by the
mapping.
This concludes the proof.
i

i

i

4.2 Two Linear Recursive Clauses

Recall again that a single linear closed recursive clause is identifiable from equivalence
queries (Cohen, 1995). A construction similar to that used in Theorem 5 can be used to
show that this result cannot be extended to programs with two linear recursive clauses.
Theorem 6 Let d-Depth-2-Clause0 be the set of 2-clause programs consisting of two
clauses in d-DepthLinRec. (Thus we assume that the base case of the recursion is given
as background knowledge.) Then for any constants n and r there exists a database DB n;r 2
2-DB and a declaration Dec n;r 2 2-DEC , both of sizes polynomial in n, such that
Dnf[n; r]  1-Depth-2-Clause0[DB n;r ; Dec n;r ]
Hence for any constants a  2 and d  1 the language family
d-Depth-2-Clause0 [DB; a-DetDEC ]
560

fiPac-Learning Recursive Logic Programs: Negative Results

is uniformly polynomially predictable only if DNF is polynomially predictable.

Proof: As before, the proof makes use of a prediction-preserving reducibility from DNF to

d-Depth-2-Clause0[DB ; Dec ] for a specific DB and Dec . Let us assume that  is a DNF
with r terms, and further assume that r = 2k . (Again, this assumption is made without
loss of generality, since the number of terms in  can be increased by padding with vacuous
terms.) Now consider a complete binary tree of depth k + 1. The k-th level of this tree has
exactly r nodes; let us label these nodes 1, : : : , r, and give the other nodes arbitrary labels.

Now construct a database DB n;r as in Theorem 5, except for the following changes:
 The predicates truei (b,y) and falsei(b,y) also succeed when y is the label of a node at
some level below k.
 Rather than the predicate succ, the database contains two predicates leftson and
rightson that encode the relationship between nodes in the binary tree.
 The database includes the facts p(!1), : : : , p(!2r), where !1, : : : , !2r are the leaves
of the binary tree. These will be used as the base cases of the recursive program that
is to be learned.
Let  be the label of the root of the binary tree. We define the instance mapping to be

fi (b1 : : :b1)  (p(); fbit1 (b1); : : :; bit n (bn )g)
Note that except for the use of  rather than 1, this is identical to the instance mapping
used in Theorem 5. Also let Dec n;r = (p; 1; R) where R contains the modes bit i (,), for i =
1; : : :; n; true j (+; +) and false j (+; +), for j = 1; : : :; r; leftson (+; ,); and rightson (+; ,).
The concept mapping fc () is the pair of clauses R1; R2, where R1 is the clause
s
n
^
^r ^
p(Y )
bit k (Xk ) ^
Bij ^ leftson(Y; Z ) ^ p(Z )
i

k =1

and R2 is the clause

p(Y )

n
^
k =1

bit k (Xk ) ^

i=1 j =1

s
^r ^
i

i=1 j =1

Bij ^ rightson (Y; Z ) ^ p(Z )

Note that both of these clause are linear recursive, determinate, and have depth 1. Also,
the construction is clearly polynomial. It remains to show that membership is preserved.
Figure 4 shows the space of proofs that can
V be constructed
V V with the program fc (); as
in Figure 3, B (i) abbreviates the conjunction bit i (Xi) ^ Bij . Notice that the program
will succeed only if the recursive calls manage to finally recurse to one of the base cases
p(!1), : : : , p(!2r ), which correspond to the leaves of the binary tree. Both clauses will both
succeed on the the first k , 1 levels of the tree. However, to reach the base cases of the
recursion at the leaves of the tree, the recursion must pass through the k-th level of the tree;
that is, one of the clauses above must succeed on some node y of the binary tree, where
y is on the k-th level of the tree, and hence the label of y is a number between 1 and r.
The program thus succeeds on fi ( ) precisely when there is some number y between 1 and
561

fiCohen

p()

"
, b
@b
"

H

"H
,
@bb
"
" ,
@ b
" ,
@ bb
"
"
b
,
@
"
b
"
,
@
b
"
b
,
@
B() p(L)
B()
p(R)
 Z
 Z
`
` \
Z
X \\
Z

X
\
 
Z

Z
 
\ Z
 
\ Z
 
 
\ Z
\
\ Z


E
X
X
X
EX


E


E


E

:::

:::

:::

B
 B
 B




B
B

:::

:::

B(1) p(LL: : : L) B(1) p(LL: : : R)

p(!1 )

:::



J
 J

J


J

J

B
 B
 B

B

B

B(n) p(RR: : : LR) B(n) p(RR: : : R)

p(!2 )

p(!2 ,1 )
r

p(!2 )
r

Figure 4: Proofs possible with the program fc ()

r such that the conjunction B(i) succeeds, which (by the argument given in Theorem 5)
can happen if and only if  is satisfied by the assignment  . Thus, the mappings preserve

concept membership. This completes the proof.

Notice that the programs fc () used in this proof all have the property that the depth
of every proof is logarithmic in the size of the instances. This means that the hardness
result holds even if one additionally restricts the class of programs to have a logarithmic
depth bound.

4.3 Upper Bounds on the Diculty of Learning

The previous sections showed that several highly restricted classes of recursive programs
are at least as hard to predict as DNF. In this section we will show that these restricted
classes are also no harder to predict than DNF.
We will wish to restrict the depth of a proof constructed by a target program. Thus, let
h(n) be any function; we will use Langh(n) for the set of programs in the class Lang such
that all proofs of an extended instance (f; D) have depth bounded by h(j Dj ).
562

fiPac-Learning Recursive Logic Programs: Negative Results

Theorem 7 Let Dnf[n; ] be the language of DNF boolean functions (with any number

of terms), and recall that d-Depth-2-Clause is the language of 2-clause programs consisting of one clause in d-DepthLinRec and one clause in d-DepthNonRec, and that
d-Depth-2-Clause0 is the language of 2-clause programs consisting of two clauses in
d-DepthLinRec.
For all constants d and a, and all databases DB 2 DB and declarations Dec 2 a-DetDEC ,
there is a polynomial function poly (n) such that

 d-Depth-2-Clause[DB ; Dec]  Dnf[poly (j DB j ); ]
 d-Depth-2-Clause0h(n) [DB ; Dec]  Dnf[poly (j DB j ); ] if h(n) is bounded by c log n
for some constant c.
Hence if either of these language families is uniformly polynomially predictable, then Dnf[n; ]
is polynomially predictable.

Proof: The proof relies on several facts established in the companion paper (Cohen, 1995).
 For every declaration Dec, there is a clause BOTTOM d(Dec) such that every nonrecursive depth-d determinate clause C is equivalent to some subclause of BOTTOM d .
Further, the size of BOTTOM  d is polynomial in Dec . This means that the language of subclauses of BOTTOM  is a normal form for nonrecursive constant-depth
determinate clauses.

 Every linear closed recursive clause CR that is constant-depth determinate is equivalent to some subclause of BOTTOM  plus a recursive literal Lr ; further, there are
only a polynomial number of possible recursive literals Lr .
 For any constants a, a0, and d, any database DB 2 a-DB, any declaration Dec =
(p; a0; R), any database DB 2 a-DB , and any program P in d-Depth-2-Clause[DB ; Dec ],
the depth of a terminating proof constructing using P is no more than hmax, where
hmax is a polynomial in the size of DB and Dec .
 At can be assumed without loss of generality that the database DB and all decsriptions
D contain an equality predicate , where an equality predicate is simply a predicate
equal(X,Y) which is true exactly when X = Y .
The idea of the proof is to contruct a prediction-preserving reduction between the two
classes of recursive programs listed above to and DNF. We will begin with two lemmas.

Lemma 8 Let Dec 2 a-DetDEC , and let C be a nonrecursive depth-d determinate clause

consistent with Dec. Let SubclauseC denote the language of subclauses of C , and let
Monomial[u] denote the language of monomials over u variables. Then there is a polynomial poly 1 so that for any database DB 2 DB,
SubclauseC [DB ; Dec]  Monomial[poly 1(j DB j )]

563

fiCohen

Proof of lemma: Follows immediately from the construction used in Theorem 1 of

Dzeroski, Muggleton, and Russell (Dzeroski et al., 1992). (The basic idea of the construction is to introduce a propositional variable representing the \success" of each connected
chain of literals in C . Any subclause of C can then be represented as a conjunction of these
propositions.)
This lemma can be extended as follows.

Lemma 9 Let Dec 2 a-DetDEC , and let S = fC1; : : :; Crg be a set of r nonrecursive depth-

d determinate clauses consistent with Dec, each of length n or less. Let SubclauseS denote
the set of all programs of the form P = (D1; : : :; Ds) such that each Di is a subclause of
some Cj 2 S .
Then there is a polynomial poly 2 so that for any database DB 2 DB,
SubclauseS [DB ; Dec]  Dnf[poly 2 (j DB j ; r); ]

Proof of lemma: By Lemma 8, for each Ci 2 S , there is a set of variables Vi of size
polynomial in j DB j such
every clause in SubclauseC can be emulated by a monomial
Sr that
over
V
V
.
Clearly,
jV j is polynomial in n and r, and every clause in
i . Let V =
i
i=1
S
i

i

SubclauseC can be also emulated by a monomial over V . Further, every disjunction

of r such clauses can be represented by a disjunction of such monomials.
Since the Ci 's all satisfy a single declaration Dec = (p; a; R), they have heads with the
same principle function and arity; further, we may assume (without loss of generality, since
an equality predicate is assumed) that the variables appearing in the heads of these clauses
are all distinct. Since the Ci's are also nonrecursive, every program
P 2 SubclauseS can
S
be represented as a disjunction D1 _ : : : _ Dr where for all i, Di 2 ( i SubclauseC ). Hence
every P 2 SubclauseS can be represented by an r-term DNF over the set of variables V .
i

i

Let us now introduce some additional notation. If C and D are clauses, then we will use
C u D to denote the result of resolving C and D together, and C i to denote the result of
resolving C with itself i times. Note that C u D is unique if C is linear recursive and C and
D have the same predicate in their heads (since there will be only one pair of complementary
literals.)
Now, consider some target program

P = (CR; CB ) 2 d-Depth-2-Clause[DB ; Dec]
where CR is the recursive clause and CB is the base. The proof of any extended instance
(f; D) must use clause CR repeatedly h times and then use clause CB to resolve away
the final subgoal. Hence the nonrecursive clause CRh u CB could also be used to cover the
instance (f; D).
Since the depth of any proof for this class of programs is bounded by a number hmax
that is polynomial in j DB j and ne , the nonrecursive program

P 0 = fCRh u CB : 0  h  hmax g
564

fiPac-Learning Recursive Logic Programs: Negative Results

is equivalent to P on extended instances of size ne or less.
Finally, recall that we can assume that CB is a subclause of BOTTOM d ; also, there
is a polynomial-sized set LR = Lr1 ; : : :; Lr of closed recursive literals such that for some
Lr 2 LR , the clause CR is a subclause of BOTTOM d [ Lr . This means that if we let S
be the polynomial-sized set
S1 = f(BOTTOM d [ Lr )h u BOTTOM d j 0  h  hmax and Lr 2 LR g
then P 0 2 SubclauseS1 . Thus by Lemma 9, d-Depth-2-Clause  Dnf. This concludes
the proof of the first statement in the the theorem.
To show that
d-Depth-2-Clause0h(n) [DB ; Dec]  Dnf[poly (j DB j ; ]
a similar argument applies. Let us again introduce some notation, and define
MESHh;n (CR1 ; CR2 ) as the set of all clauses of the form
p

i

i

i

i

CR 1 u CR 2 u : : : u CR 0
where for all j , CR = CR1 or CR = CR2 , and h0  h(n). Notice that for functions
h(n)  c log n the number of such clauses is polynomial in n.
Now let p be the predicate appearing in the heads of CR1 and CR2 , and let C^ (respectively
^ ) be a a version of C (DB ) in which every instance of the predicate p has been replaced
DB
with a new predicate p^. If P is a recursive program P = fCR1 ; CR2 g in d-Depth-2-Clause0
^ ,
over the database DB , then P ^ DB is equivalent4 to the nonrecursive program P 0 ^ DB
i;

ij

where

i;

i;h

ij

P 0 = fC^ j C 2 MESHh;n (CR1 ; CR2 )g
e

Now recall that there are a polynomial number of recursive literals Lr , and hence a
polynomial number of pairs of recursive literals Lr ; Lr . This means that the set of clauses
[
S2 =
fC^ j C 2 MESHh;n (BOTTOM d [ Lr ; BOTTOM d [ Lr )g
i

i

(L

ri

e

2 

;Lrj ) LR LR

j

i

j

is also polynomial-sized; furthermore, for any program P in the language d-Depth-2-Clause,
P 0 2 SubclauseS2 . The second part of the theorem now follows by application of Lemma 9.
An immediate corollary of this result is that Theorems 6 and 5 can be strengthened as
follows.
Corollary 10 For all constants d  1 and a  2, the language family
d-Depth-2-Clause[DB; a-DetDEC ]
is uniformly polynomially predictable if and only if DNF is polynomially predictable.
For all constants d  1 and a  2, the language family
d-Depth-2-Clause0 [DB; a-DetDEC ]
is uniformly polynomially predictable if and only if DNF is polynomially predictable.
4. On extended instances of size n or less.
e

565

fiCohen

Thus in an important sense these learning problems are equivalent to learning boolean
DNF. This does not resolve the questions of the learnability of these languages, but does
show that their learnability is a dicult formal problem: the predictability of boolean DNF
is a long-standing open problem in computational learning theory.

5. Related Work
The work described in this paper differs from previous formal work on learning logic programs in simultaneously allowing background knowledge, function-free programs, and recursion. We have also focused exclusively on computational limitations on ecient learnability
that are associated with recursion, as we have considered only languages known to be paclearnable in the nonrecursive case. Since the results of this paper are all negative, we have
concentrated on the model of polynomial predictability; negative results in this model immediately imply a negative result in the stronger model of pac-learnability, and also imply
negative results for all strictly more expressive languages.
Among the most closely related prior results are the negative results we have previously
obtained for certain classes of nonrecursive function-free logic programs (Cohen, 1993b).
These results are similar in character to the results described here, but apply to nonrecursive
languages. Similar cryptographic results have been obtained by Frazier and Page (1993) for
certain classes of programs (both recursive and nonrecursive) that contain function symbols
but disallow background knowledge.
Some prior negative results have also been obtained on the learnability of other firstorder languages using the proof technique of consistency hardness (Pitt & Valiant, 1988).
Haussler (1989) showed that the language of \existential conjunction concepts" is not paclearnable by showing that it can be hard to find a concept in the language consistent with a
given set of examples. Similar results have also been obtained for two restricted languages
of Horn clauses (Kietz, 1993); a simple description logic (Cohen & Hirsh, 1994); and for the
language of sorted first-order terms (Page & Frisch, 1992). All of these results, however, are
specific to the model pac-learnability, and none can be easily extended to the polynomial
predictability model considered here. The results also do not extend to languages more
expressive than these specific constrained languages. Finally, none of these languages allow
recursion.
To our knowledge, there are no other negative learnability results for first-order languages. A discussion of prior positive learnability results for first-order languages can be
found in the companion paper (Cohen, 1995).

6. Summary
This paper and its companion (Cohen, 1995) have considered a large number of different
subsets of Datalog. Our aim has been to be not comprehensive, but systematic: in particular, we wished to find precisely where the boundaries of learnability lie as various syntactic
restrictions are imposed and relaxed. Since it is all too easy for a reader to \miss the forest
for the trees", we will now briey summarize the results contained in this paper, together
with the positive results of the companion paper (Cohen, 1995).
566

fiPac-Learning Recursive Logic Programs: Negative Results

Local
Clauses

Constant-Depth Determinate
Clauses

nCR,

nCR,

nCR jCB,

nCR ; CB,

k  nCR,

n  nCR,

kCR,

kCR+

kCRjCB+

kCR; CBDNF

k  k0CRDNF

n  kCR,

1CR,

1CR+

1CRjCB+

1CR; CB=DNF

2  1CR=DNF

n  1CR,

Table 1: A summary of the learnability results
Throughout these papers, we have assumed that a polynomial amount of background
knowledge exists; that the programs being learned contain no function symbols; and that
literals in the body of a clause have small arity. We have also assumed that recursion is
closed , meaning that no output variables appear in a recursive clause; however, we believe
that this restriction can be relaxed without fundamentally changing the results of the paper.
In the companion paper (Cohen, 1995) we showed that a single nonrecursive constantdepth determinate clause was learnable in the strong model of identification from equivalence
queries . In this learning model, one is given access to an oracle for counterexamples|that
is, an oracle that will find, in unit time, an example on which the current hypothesis is
incorrect|and must reconstruct the target program exactly from a polynomial number of
these counterexamples. This result implies that a single nonrecursive constant-depth determinate clause is pac-learnable (as the counterexample oracle can be emulated by drawing
random examples in the pac setting). The result is not novel (Dzeroski et al., 1992); however
the proof given is independent, and is also of independent interest. Notably, it is somewhat
more rigorous than earlier proofs, and also proves the result directly, rather than via reduction to a propositional learning problem. The proof also introduces a simple version of the
forced simulation technique, variants of which are used in all of the positive results.
We then showed that the learning algorithm for nonrecursive clauses can be extended
to the case of a single linear recursive constant-depth determinate clause, leading to the
result that this restricted class of recursive programs is also identifiable from equivalence
queries. With a bit more effort, this algorithm can be further extended to learn a single
k-ary recursive constant-depth determinate clause.
We also considered extended the learning algorithm to learn recursive programs consisting of more than one constant-depth determinate clauses. The most interesting extension
was to simultaneously learn a recursive clause CR and a base clause CB , using equivalence
queries and also a \basecase oracle" that indicates which counterexamples should be covered
by the base clause CB . In this model, it is possible to simultaneously learn a recursive clause
and a nonrecursive base case in all of the situations for which a recursive clause is learned
567

fiCohen

Language Family
d-DepthNonRec[a-DB; a-DetDEC]
d-DepthLinRec[a-DB; a-DetDEC]
d-Depth-k-Rec[a-DB; a-DetDEC]
d-Depth-2-Clause[a-DB; a-DetDEC]
kd-MaxRecLang[a-DB; a-DetDEC ]
d-Depth-2-Clause[a-DB; a-DetDEC]
d-Depth-2-Clause [a-DB; a-DetDEC ]
d-DepthLinRecProg[a-DB; a-DetDEC ]
d-DepthRec[a-DB; a-DetDEC ]
k-LocalLinRec[a-DB; a-DEC ]
0

B
1
0
0
1
1
1
0
0
0
0

R
0
1
1
1
1
1
2

L/R Oracles
, EQ
1
EQ
k
EQ
1
EQ,BASE
k
EQ,BASE
1
EQ
1
EQ
n 1
EQ
1 n
EQ
1 1
EQ

Notation Learnable
CB
yes
1CR
yes
kCR
yes
1CRjCB yes
kCRjCB
yes
1CR; CB =DNF
2  1CR =DNF
n  1CR no
nCR
no
1CR
no

Table 2: Summary by language of the learnability results. Column B indicates the number
of base (nonrecursive) clauses allowed in a program; column R indicates the number of recursive clauses; L/R indicates the number of recursive literals allowed in
a single recursive clause; EQ indicates an oracle for equivalence queries and BASE
indicates a basecase oracle. For all languages except k-LocalLinRec, all clauses
must be determinate and of depth d.
alone; for instance, one can learn a k-ary recursive clause to together with its nonrecursive
base case. This was our strongest positive result.
These results are summarized in Tables 1 and 2. In Table 1, a program with one rary recursive clause is denoted rCR, a program with one r-ary recursive clause and one
nonrecursive basecase is denoted rCR; CB , or rCRjCB if there is a \basecase" oracle, and
a program with s different r-ary recursive clauses is denoted s  rCR . The boxed results
are associated with one or more theorems from this paper, or its companion paper, and
the unmarked results are corollaries of other results. A \+" after a program class indicates
that it is identifiable from equivalence queries; thus the positive results described above are
summarized by the four \+" entries in the lower left-hand corner of the section of the table
concerned with constant-depth determinate clauses.
Table 2 presents the same information in a slightly different format, and also relates the
notation of Table 1 to the terminology used elsewhere in the paper.
This paper has considered the learnability of the various natural generalizations of the
languages shown to be learnable in the companion paper. Consider for the moment single
clauses. The companion paper showed that for any fixed k a single k-ary recursive constantdepth determinate clause is learnable. Here we showed that all of these restrictions are
necessary. In particular, a program of n constant-depth linear recursive clauses is not
polynomially predictable; hence the restriction to a single clause is necessary. Also, a single
clause with n recursive calls is hard to learn; hence the restriction to k-ary recursion is
necessary. We also showed that the restriction to constant-depth determinate clauses is
necessary, by considering the learnability of constant locality clauses . Constant locality
clauses are the only known generalization of constant-depth determinate clauses that are
pac-learnable in the nonrecursive case. However, we showed that if recursion is allowed,
568

fiPac-Learning Recursive Logic Programs: Negative Results

then this language is not learnable: even a single linear recursive clause is not polynomially
predictable.
Again, these results are summarized in Table 1; a \," after a program class means that
it is not polynomially predictable, under cryptographic assumptions, and hence neither
pac-learnable nor identifiable from equivalence queries.
The negative results based on cryptographic hardness give an upper bound on the expressiveness of learnable recursive languages, but still leave open the learnability of programs
with a constant number of k-ary recursive clauses in the absence of a basecase oracle. In
the final section of this paper, we showed that the following problems are, in the model of
polynomial predictability, equivalent to predicting boolean DNF:
 predicting two-clause constant-depth determinate recursive programs containing one
linear recursive clause and one base case;
 predicting two-clause recursive constant-depth determinate programs containing two
linear recursive clauses, even if the base case is known.
We note that these program classes are the very nearly the simplest classes of multi-clause
recursive programs that one can imagine, and that the pac-learnability of DNF is a longstanding open problem in computational learning theory. These results suggest, therefore,
that pac-learning multi-clause recursive logic programs is dicult; at the very least, they
show that finding a provably correct pac-learning algorithm will require substantial advances
in computational learning theory. In Table 1, a \= Dnf" (respectively  Dnf) means that
the corresponding language is prediction-equivalent to DNF (respectively at least as hard
as DNF).
To further summarize Table 1: with any sort of recursion, only programs containing
constant-depth determinate clauses are learnable. The only constant-depth determinate
recursive programs that are learnable are those that contain a single k-ary recursive clause
(in the standard equivalence query model) or a single k-ary recursive clause plus a base
case (if a \basecase oracle" is allowed). All other classes recursive programs are either
cryptographically hard, or as hard as boolean DNF.

7. Conclusions

Inductive logic programming is an active area of research, and one broad class of learning
problems considered in this area is the class of \automatic logic programming" problems.
Prototypical examples of this genre of problems are learning to append two lists, or to
multiply two numbers. Most target concepts in automatic logic programming are recursive
programs, and often, the training data for the learning system are simply examples of the
target concept, together with suitable background knowledge.
The topic of this paper is the pac-learnability of recursive logic programs from random
examples and background knowledge; specifically, we wished to establish the computational
limitations inherit in performing this task. We began with some positive results established
in a companion paper. These results show that one constant-depth determinate closed k-ary
recursive clause is pac-learnable, and that further, a program consisting of one such recursive
clause and one constant-depth determinate nonrecursive clause is also pac-learnable given
an additional \basecase oracle".
569

fiCohen

In this paper we showed that these positive results are not likely to be improved. In
particular, we showed that either eliminating the basecase oracle or learning two recursive clauses simultaneously is prediction-equivalent to learning DNF, even in the case of
linear recursion. We also showed that the following problems are as hard as breaking (presumably) secure cryptographic codes: pac-learning n linear recursive determinate clauses,
pac-learning one n-ary recursive determinate clause, or pac-learning one linear recursive
k-local clause.
These results contribute to machine learning in several ways. From the point of view
of computational learning theory, several results are technically interesting. One is the
prediction-equivalence of several classes of restricted logic programs and boolean DNF; this
result, together with others like it (Cohen, 1993b), reinforces the importance of the learnability problem for DNF. This paper also gives a dramatic example of how adding recursion
can have widely differing effects on learnability: while constant-depth determinate clauses
remain pac-learnable when linear recursion is added, constant-locality clauses become cryptographically hard.
Our negative results show that systems which apparently learn a larger class of recursive
programs must be taking advantage either of some special properties of the target concepts
they learn, or of the distribution of examples that they are provided with. We believe that
the most likely opportunity for obtaining further positive formal results in this area is to
identify and analyze these special properties. For example, in many examples in which
FOIL has learned recursive logic programs, it has made use of \complete example sets"|
datasets containing all examples of or below a certain size, rather than sets of randomly
selected examples (Quinlan & Cameron-Jones, 1993). It is possible that complete datasets
allow a more expressive class of programs to be learned than random datasets; in fact, some
progress has been recently made toward formalizing this conjecture (De Raedt & Dzeroski,
1994).
Finally, and most importantly, this paper has established the boundaries of learnability
for determinate recursive programs in the pac-learnability model. In many plausible automatic programming contexts it would be highly desirable to have a system that offered some
formal guarantees of correctness. The results of this paper provide upper bounds on what
one can hope to achieve with an ecient, formally justified system that learns recursive
programs from random examples alone.

Acknowledgements
The author wishes to thank three anonymous JAIR reviewers for a number of useful suggestions on the presentation and technical content.

References
Aha, D., Lapointe, S., Ling, C. X., & Matwin, S. (1994). Inverting implication with small
training sets. In Machine Learning: ECML-94 Catania, Italy. Springer-Verlag. Lecture
Notes in Computer Science # 784.
570

fiPac-Learning Recursive Logic Programs: Negative Results

Biermann, A. (1978). The inference of regular lisp programs from examples. IEEE Transactions on Systems, Man and Cybernetics, 8 (8).
Chandra, A. K., Kozen, D. C., & Stockmeyer, L. J. (1981). Alternation. Journal of the
ACM, 28, 114{113.
Cohen, W. W. (1993a). Cryptographic limitations on learning one-clause logic programs. In
Proceedings of the Tenth National Conference on Artificial Intelligence Washington,
D.C.
Cohen, W. W. (1993b). Pac-learning non-recursive Prolog clauses. To appear in Artificial
Intelligence.
Cohen, W. W. (1993c). Rapid prototyping of ILP systems using explicit bias. In Proceedings
of the 1993 IJCAI Workshop on Inductive Logic Programming Chambery, France.
Cohen, W. W. (1994a). Pac-learning nondeterminate clauses. In Proceedings of the Eleventh
National Conference on Artificial Intelligence Seattle, WA.
Cohen, W. W. (1994b). Recovering software specifications with inductive logic programming. In Proceedings of the Eleventh National Conference on Artificial Intelligence
Seattle, WA.
Cohen, W. W. (1995). Pac-learning recursive logic programs: ecient algorithms. Journal
of AI Research, 2, 501{539.
Cohen, W. W., & Hirsh, H. (1994). The learnability of description logics with equality
constraints. Machine Learning, 17 (2/3).
De Raedt, L., & Dzeroski, S. (1994). First-order jk-clausal theories are PAC-learnable.
In Wrobel, S. (Ed.), Proceedings of the Fourth International Workshop on Inductive
Logic Programming Bad Honnef/Bonn, Germany.
Dzeroski, S., Muggleton, S., & Russell, S. (1992). Pac-learnability of determinate logic
programs. In Proceedings of the 1992 Workshop on Computational Learning Theory
Pittsburgh, Pennsylvania.
Frazier, M., & Page, C. D. (1993). Learnability of recursive, non-determinate theories: Some
basic results and techniques. In Proceedings of the Third International Workshop on
Inductive Logic Programming Bled, Slovenia.
Haussler, D. (1989). Learning conjunctive concepts in structural domains. Machine Learning, 4 (1).
Hopcroft, J. E., & Ullman, J. D. (1979). Introduction to Automata Theory, Languages, and
Computation. Addison-Wesley.
Kearns, M., & Valiant, L. (1989). Cryptographic limitations on learning Boolean formulae
and finite automata. In 21th Annual Symposium on the Theory of Computing. ACM
Press.
571

fiCohen

Kietz, J.-U. (1993). Some computational lower bounds for the computational complexity
of inductive logic programming. In Proceedings of the 1993 European Conference on
Machine Learning Vienna, Austria.
King, R. D., Muggleton, S., Lewis, R. A., & Sternberg, M. J. E. (1992). Drug design by
machine learning: the use of inductive logic programming to model the structureactivity relationships of trimethoprim analogues binding to dihydrofolate reductase.
Proceedings of the National Academy of Science, 89.
Lavrac, N., & Dzeroski, S. (1992). Background knowledge and declarative bias in inductive
concept learning. In Jantke, K. P. (Ed.), Analogical and Inductive Inference: International Workshop AII'92. Springer Verlag, Daghstuhl Castle, Germany. Lectures in
Artificial Intelligence Series #642.
Lloyd, J. W. (1987). Foundations of Logic Programming: Second Edition. Springer-Verlag.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory and methods.
Journal of Logic Programming, 19/20 (7), 629{679.
Muggleton, S., & Feng, C. (1992). Ecient induction of logic programs. In Inductive Logic
Programming. Academic Press.
Muggleton, S., King, R. D., & Sternberg, M. J. E. (1992). Protein secondary structure
prediction using logic-based machine learning. Protein Engineering, 5 (7), 647{657.
Muggleton, S. H. (Ed.). (1992). Inductive Logic Programming. Academic Press.
Page, C. D., & Frisch, A. M. (1992). Generalization and learnability: A study of constrained
atoms. In Inductive Logic Programming. Academic Press.
Pazzani, M., & Kibler, D. (1992). The utility of knowledge in inductive learning. Machine
Learning, 9 (1).
Pitt, L., & Warmuth, M. K. (1988). Reductions among prediction problems: On the difficulty of predicting automata. In Proceedings of the 3rd Annual IEEE Conference
on Structure in Complexity Theory Washington, D.C. Computer Society Press of the
IEEE.
Pitt, L., & Valiant, L. (1988). Computational limitations on learning from examples. Journal
of the ACM, 35 (4), 965{984.
Pitt, L., & Warmuth, M. (1990). Prediction-preserving reducibility. Journal of Computer
and System Sciences, 41, 430{467.
Quinlan, J. R., & Cameron-Jones, R. M. (1993). FOIL: A midterm report. In Brazdil, P. B.
(Ed.), Machine Learning: ECML-93 Vienna, Austria. Springer-Verlag. Lecture notes
in Computer Science # 667.
Quinlan, J. R. (1990). Learning logical definitions from relations. Machine Learning, 5 (3).
572

fiPac-Learning Recursive Logic Programs: Negative Results

Quinlan, J. R. (1991). Determinate literals in inductive logic programming. In Proceedings
of the Eighth International Workshop on Machine Learning Ithaca, New York. Morgan
Kaufmann.
Rouveirol, C. (1994). Flattening and saturation: two representation changes for generalization. Machine Learning, 14 (2).
Summers, P. D. (1977). A methodology for LISP program construction from examples.
Journal of the Association for Computing Machinery, 24 (1), 161{175.
Valiant, L. G. (1984). A theory of the learnable. Communications of the ACM, 27 (11).
Zelle, J. M., & Mooney, R. J. (1994). Inducing deterministic Prolog parsers from treebanks:
a machine learning approach. In Proceedings of the Twelfth National Conference on
Artificial Intelligence Seattle, Washington. MIT Press.

573

fiJournal of Artificial Intelligence Research 2 (1994) 131-158

Submitted 4/94; published 12/94

Wrap-Up: a Trainable Discourse
Module for Information Extraction
Stephen Soderland

Wendy Lehnert
Department of Computer Science, University of Massachusetts
Amherst, MA 01003-4610

soderlan@cs.umass.edu
lehnert@cs.umass.edu

Abstract

The vast amounts of on-line text now available have led to renewed interest in information
extraction (IE) systems that analyze unrestricted text, producing a structured representation of selected information from the text. This paper presents a novel approach that
uses machine learning to acquire knowledge for some of the higher level IE processing.
Wrap-Up is a trainable IE discourse component that makes intersentential inferences and
identifies logical relations among information extracted from the text. Previous corpusbased approaches were limited to lower level processing such as part-of-speech tagging,
lexical disambiguation, and dictionary construction. Wrap-Up is fully trainable, and not
only automatically decides what classifiers are needed, but even derives the feature set for
each classifier automatically. Performance equals that of a partially trainable discourse
module requiring manual customization for each domain.

1. Introduction

An information extraction (IE) system analyzes unrestricted, real world text such as newswire
stories. In contrast to information retrieval systems which return a pointer to the entire
document, an IE system returns a structured representation of just the information from
within the text that is relevant to a user's needs, ignoring irrelevant information.
The first stage of an IE system, sentence analysis, identifies references to relevant objects
and typically creates a case frame to represent each object. The second stage, discourse
analysis, merges together multiple references to the same object, identifies logical relationships between objects, and infers information not explicitly identified by sentence analysis.
The IE system operates in terms of domain specifications that predefine what types of information and relationships are considered relevant to the application. Considerable domain
knowledge is used by an IE system: about domain objects, relationships between objects,
and how texts typically describe these objects and relationships.
Much of the domain knowledge can be automatically acquired by corpus-based techniques. Previous work has centered on knowledge acquisition for some of the lower level
processing such as part-of-speech tagging and lexical disambiguation. N-gram statistics have
been highly successful in part-of-speech tagging (Church, 1988; DeRose, 1988). Weischedel
(1993) has used corpus-based probabilities both for part-of-speech tagging and to guide
parsing. Collocation data has been used for lexical disambiguation by Hindle (1989), Brent
(1993), and others. Examples from a training corpus have driven both part-of-speech and
semantic tagging (Cardie, 1993) and dictionary construction (Riloff, 1993).

c 1994 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiSoderland and Lehnert

This paper describes Wrap-Up (Soderland & Lehnert, 1994), the first system to automatically acquire domain knowledge for the higher level processing associated with discourse
analysis. Wrap-Up uses supervised learning to induce a set of classifiers from a training corpus of representative texts, where each text is accompanied by hand-coded target output.
We implemented Wrap-Up with the ID3 decision tree algorithm (Quinlan, 1986), although
other machine learning algorithms could have been selected.
Wrap-Up is a fully trainable system and is unique in that it not only decides what
classifiers are needed for the domain, but automatically derives the feature set for each
classifier. The user supplies a definition of the objects and relationships of interest to the
domain and a training corpus with hand-coded target output. Wrap-Up does the rest with
no further hand coding needed to tailor the system to a new domain.
Section 2 discusses the IE task in more detail, introduces the microelectronics domain,
and gives an overview of the CIRCUS sentence analyzer. Section 3 describes Wrap-Up,
giving details of how ID3 trees are constructed for each discourse decision, how features
are automatically derived for each tree, and requirements for applying Wrap-Up to a new
domain. Section 4 shows the performance of Wrap-Up in two domains and compares its
performance to that of a partially trainable discourse component. In Section 5 we draw
some conclusions about the contribution of this research. A detailed example from the
microelectronics domain is given in an appendix.

2. The Information Extraction Task

This section gives an overview of information extraction and illustrates IE processing with
a sample text fragment from the microelectronics domain. We then discuss the need for
trainable IE components to acquire knowledge for a new domain.

2.1 An Overview of IE

An information extraction system operates at two levels. First, sentence analysis identifies
information that is relevant to the IE application. Then discourse analysis, which we will
focus on in this paper, takes the output from sentence analysis and assembles it into a
coherent representation of the entire text. All of this is done according to predefined guidelines that specify what objects from the text are relevant and what relationships between
objects are to be reported.
Sentence analysis can be further broken down into several stages, each applying different
types of domain knowledge. The lowest level is preprocessing, which segments the text into
words and sentences. Each word is assigned a part-of-speech tag and possibly a semantic
tag in preparation for further processing. Different IE systems will do varying amounts of
syntactic parsing at this point. Most research sites that participated in the ARPA-sponsored
Message Understanding Conferences (MUC-3, 1991; MUC-4, 1992; MUC-5, 1993) found
that robust, shallow analysis and pattern matching performed better than more elaborate,
but brittle, parsing techniques.
The CIRCUS sentence analyzer (Lehnert, 1990; Lehnert et al., 1992) does shallow syntactic analysis to identify simple syntactic constituents, and to distinguish active and passive
voice verbs. This shallow syntactic analysis is sucient for the extraction task, which uses
132

fiWrap-Up: a Trainable Discourse Module

local linguistic patterns to instantiate case frames, called concept nodes (CN's) used by
CIRCUS.
Each CN definition has a trigger word and a syntactic pattern relative to that word.
Whenever the trigger word occurs in the text, CIRCUS looks in one of the syntactic buffers
for appropriate information to extract. Some CN definitions will extract information from
the subject or from the direct object, first testing for active or passive voice. Other CN
definitions look for a prepositional phrase with a particular preposition. Examples of CN
extraction patterns from a particular domain are shown in Section 2.3.
Discourse analysis starts with the output from the sentence analyzer, in this case a set
of concept nodes representing locally extracted information. Other work on discourse has
often involved tracking shifts in topic and in the speaker/writer's goals (Grosz & Sidner,
1986; Liddy et al., 1993) or in resolving anaphoric references (Hobbs, 1978). Discourse
processing in an IE system may concern itself with some of these issues, but only as a
means to its main objective of transforming bits and pieces of extracted information into a
coherent representation.
One of the first tasks of discourse analysis is to merge together multiple references to
the same object. In a domain where company names are important, this will involve recognizing the equivalence of a full company name (\International Business Machines, Inc.")
with shortened forms of that name (\IBM") and generic references (\the company", \the
U.S. computer maker"). Some manually engineered rules seem unavoidable for coreference
merging. Another example is merging a domain object with a less specific reference to that
object. In the microelectronics domain a reference to \DRAM" chips may be merged with
a reference to \memory" or an \I-line" process merged with \lithography."
Much of the work of discourse analysis is to identify logical relationships between extracted objects, represented as pointers between objects in the output. Discourse analysis
must also be able to infer missing objects that are not explicitly stated in the text and in
some cases split an object into multiple copies or discard an object that was erroneously
extracted.
The current implementation of Wrap-Up begins discourse processing after coreference
merging has been done by a separate module. This is primarily because manual engineering
seems unavoidable in coreference. Work is underway to extend Wrap-Up to include all of IE
discourse processing by incorporating a limited amount of domain-specific code to handle
such things as company name aliases and generic references to domain objects.
Wrap-Up divides its processing into six stages, which will be described more fully in
Section 3. They are:
1. Filtering out spuriously extracted information
2. Merging objects with their attributes
3. Linking logically related objects
4. Deciding when to split objects into multiple copies
5. Inferring missing objects
6. Adding default slot values
At this point an example from a specific domain might help. The following sections introduce the microelectronics domain, then illustrate sentence analysis and discourse analysis
with a short example from this domain.
133

fiSoderland and Lehnert

2.2 The Microelectronics Domain

The microelectronics domain was one of the two domains targetted by the Fifth Message
Understanding Conference (MUC-5, 1993). According to the domain and task guidelines
developed for the MUC-5 microelectronics corpus, the information to be extracted are microchip fabrication processes along with the companies, equipment, and devices associated
with these processes. There are seven types of domain objects to be identified: entities (i.e.
companies), equipment, devices, and four chip fabrication processes (layering, lithography,
etching, and packaging).
Identifying relationships between objects is of equal importance in this domain to identifying the objects themselves. A company must be identified as playing at least one of four
possible roles with respect to the microchip fabrication process: developer, manufacturer,
distributor, or purchaser/user. Microchip fabrication processes are reported only if they are
associated with a specific company in at least one of these roles. Each equipment object
must be linked to a process which uses that equipment, and each device object linked to
a process which fabricates that device. Equipment objects may point to a company as
manufacturer and to other equipment as modules.
The following sample from the MUC-5 microelectronics domain has two companies in the
first sentence, which are associated with two lithography processes from the second sentence.
GCA and Sematech are developers of both the UV and I-line lithography processes, with
GCA playing the additional role of manufacturer. Each lithography process is linked to the
stepper equipment mentioned in sentence one.
GCA unveiled its new XLS stepper, which was developed with
assistance from Sematech. The system will be available in
deep-ultraviolet and I-line configurations.

Figure 1 shows the five domain objects extracted by sentence analysis and the final
representation of the text after discourse analysis has identified relationships between objects. Some of these relationships are directly indicated by pointers between objects. The
roles that companies play with respect to a microchip fabrication process are indicated by
creating a \microelectronics-capability" object with pointers to both the process and the
companies.

2.3 Extraction Patterns

How does sentence analysis identify GCA and Sematech as company names, and extract the
other domain objects such as stepper equipment, UV lithography and I-line lithography?
The CN dictionary for this domain includes an extraction pattern \X unveiled" to identify
company names. The subject of the active verb \unveiled" in this domain is nearly always
a company developing or distributing a new device or process. However, this pattern will
occasionally pick up a company that fails the domain's reportability criteria. A company
that unveils a new type of chip should be discarded if the text does not specify the fabrication
process.
Extracting the company name \Sematech" is more dicult since the pattern \assistance
from X" is not a reliable predictor of relevant company names. There is always a trade-off
between accuracy and complete coverage in deciding what extraction patterns are reliable
134

fiWrap-Up: a Trainable Discourse Module

A. Five concept nodes extracted by sentence analysis.
Entity
Type: company
Name: GCA

Equipment
Type: stepper
Name: XLS

Lithography
Type: UV

Lithography
Type: I-line

Entity
Type: company
Name: Sematech

B. Final representation of the text after discourse analysis.
Template
Contents:
ME-Capability
Manufacturer:
Developer:
Process:

ME-Capability
Manufacturer:
Developer:
Process:

Entity
Type: company
Name: GCA

Entity
Type: company
Name: Sematech
Lithography
Type: UV
Equipment:

Lithography
Type: I-line
Equipment:

Equipment
Type: stepper
Name: XLS
Manufacturer:
Status: in-development

Figure 1: Output of (A) sentence analysis and (B) discourse analysis
enough to include in the CN dictionary. Including less reliable patterns increases coverage
but does so at the expense of spurious extraction. The more specific pattern \developed
with assistance from X" is reliable, but was missed by the dictionary construction tool
(Riloff, 1993).
For many of the domain objects, such as equipment, devices, and microchip fabrication
processes, the set of possible objects is predefined and a list of keywords that refer to these
objects can be created. The extraction pattern \unveiled X" looks in the direct object
of the active verb \unveiled", instantiating an equipment object if a keyword indicating
an equipment type is found. In this example an equipment object with type \stepper" is
created with the equipment name \XLS". The same stepper equipment is also extracted by
135

fiSoderland and Lehnert

the pattern \X was developed", which looks for equipment in the subject of the passive verb
\developed". This equipment object is extracted a third time by the keyword \stepper"
itself, which is sucient to instantiate a stepper equipment object whether or not it occurs
in a reliable extraction pattern.
The keyword \deep-ultraviolet" and the extraction pattern \available in X" are used to
extract a lithography object with type \UV" from the second sentence. Another lithography
object of type \I-line" is similarly extracted. Case frames are created for each of the objects
identified by sentence analysis. This set of objects becomes input for the next stage of
processing, discourse analysis.

2.4 Discourse Processing

In the full text from which this fragment comes, there are likely to be other references to
\GCA" or to \GCA Corp." One of the first jobs of discourse analysis is to merge these
multiple references. It is a much harder task to merge pronominal references and generic
references such as \the company" with the appropriate company name. This is all part of
the coreference problem that is handled by processes separate from Wrap-Up.
The main job of discourse analysis is to determine the relationships between the objects
passed to it by sentence analysis. Considerable domain knowledge is needed to make these
discourse-level decisions. Some of this knowledge concerns writing style, and specific phrases
writers typically use to imply relationships between referents in a given domain. Is the
phrase \<company> unveiled <equipment>" sucient evidence to infer that the company
is the developer of a microelectronics process? The word \unveiled" alone is not enough,
since a company that unveiled a new DRAM chip may not be the developer of any new
process. It may simply be using someone else's microelectronics process to produce its chip.
Such inferences, particularly those about what role a company plays in a process, are often
so subtle that two human analysts may disagree on the output for a given text. A human
performance study for this task found that experienced analysts agreed with each other on
only 80% on their text interpretations in this domain (Will, 1993).
World knowledge is also needed about the relationships possible between domain objects. A lithography process may be linked to stepper equipment, but steppers are never
used in layering, etching, or packaging processes. There are delicate dependencies about
what types of process are likely to fabricate what types of devices. Knowledge about the
kinds of relationships typically reported in this domain can also help guide discourse processing. Stories about lithography, for example, often give the developer, manufacturer,
or distributor of the process, but these roles are hardly ever mentioned for packaging processes. Companies associated with packaging tend to be limited to the purchaser/user of
the packaging technology.
A wide range of domain knowledge is needed for discourse processing, some of it related
to world knowledge, some to writing style. The next section discusses the need for trainable components at all levels of IE processing, including discourse analysis. Wrap-Up uses
machine learning techniques to avoid months of manual knowledge engineering otherwise
required to develop a specific IE application.

136

fiWrap-Up: a Trainable Discourse Module

2.5 The Need for Trainable IE Components

The highest performance at the ARPA-sponsored Fifth Message Understanding Conference
(MUC-5, 1993) was achieved at the cost of nearly two years of intense programming effort,
adding domain-specific heuristics and domain-specific linguistic patterns one by one, followed by various forms of system tuning to maximize performance. For many real world
applications, two years of development time by a team of half a dozen programmers would
be prohibitively expensive. To make matters worse, the knowledge used in one domain
cannot be readily transferred to other IE applications.
Researchers at the University of Massachusetts have worked to facilitate IE system development through the use of corpus-driven knowledge acquisition techniques (Lehnert et
al., 1993). In 1991 a purely hand-crafted UMass system had the highest performance of
any site in the MUC-3 evaluation. The following year UMass ran both a hand-crafted system and an alternate system that replaced a key component with output from AutoSlog, a
trainable dictionary construction tool (Riloff, 1993). The AutoSlog variant exhibited performance levels comparable to a dictionary based on 1500 hours of manual coding. Encouraged
by the success of this one trainable component, an architecture for corpus-driven system
development was proposed which uses machine learning techniques to address a number
of natural language processing problems (Lehnert et al., 1993). In the MUC-5 evaluation,
output from the CIRCUS sentence analyzer was sent to TTG (Trainable Template Generator), a discourse component developed by Hughes Research Laboratories (Dolan, et al.,
1991; Lehnert et al., 1993). TTG used machine learning techniques to acquire much of the
needed domain knowledge, but still required hand-coded heuristics to turn this acquired
knowledge into a fully functioning discourse analyzer.
The remainder of this paper will focus on Wrap-Up, a new IE discourse module now
under development which explores the possibility of fully automated knowledge acquisition
for discourse analysis. As detailed in the following sections, Wrap-Up builds ID3 decision
trees to guide discourse processing and requires no hand-coded customization for a new
domain once a training corpus has been provided. Wrap-Up automatically decides what
ID3 trees are needed for the domain and derives the feature set for each tree from the output
of the sentence analyzer.

3. Wrap-Up, a Trainable IE Component

This section describes the Wrap-Up algorithm, how decision trees are used for discourse
analysis, and how the trees and tree features are automatically generated. We conclude
with a discussion of the requirements of Wrap-Up and our experience porting to a new
domain.

3.1 Overview

Wrap-Up is a domain-independent framework for IE discourse processing which is instantiated with automatically acquired knowledge for each new IE application. During its training
phase, Wrap-Up builds ID3 decision trees based on a representative set of training texts,
paired against hand-coded output keys. These ID3 trees guide Wrap-Up's processing during
run time.
137

fiSoderland and Lehnert

At run time Wrap-Up receives as input all objects extracted from the text during sentence analysis. Each of these objects is represented as a case frame along with a list of
references in the text, the location of each reference, and the linguistic patterns used to
extract it. Multiple references to the same object throughout the text are merged together
before passing it on to Wrap-Up. Wrap-Up transforms this set of objects by discarding
spurious objects, merging objects that add further attributes to an object, adding pointers
between objects, and inferring the presence of any missing objects or slot values.
Wrap-Up has six stages of processing, each with its own set of decision trees designed
to transform objects as they are passed from one stage to the next.
Stages in the Wrap-up Algorithm:
1. Slot Filtering
Each object slot has its own decision tree that judges whether the slot contains reliable
information. Discard the slot value from an object if a tree returns \negative".
2. Slot Merging
Create an instance for each pair of objects of the same type. Merge the two objects
if a decision tree for that object type returns \positive". This stage can merge an
object with separately extracted attributes for that object.
3. Link Creation
Consider all possible pairs of objects that might possibly be linked. Add a pointer
between objects if a Link Creation decision tree returns \positive".
4. Object Splitting
Suppose object A is linked to both object B and to object C. If an Object Splitting
decision tree returns \positive", split A into two copies with one pointing to B and
the other to C.
5. Inferring Missing Objects
When an object has no other object pointing to it, an instance is created for a decision
tree which returns the most likely parent object. Create such a parent and link it to
the \orphan" object unless the tree returns \none". Then use decision trees from the
Link Creation and Object Splitting stages to tie the new parent in with other objects.
6. Inferring Missing Slot Values
When an object slot with a closed class of possible values is empty, create an instance
for a decision tree which returns a context-sensitive default value for that slot, possibly
\none".

3.2 Decision Trees for Discourse Analysis

A key to making machine learning work for a complex task such as discourse processing
is to break the problem into a number of small decisions and build a separate classifier
138

fiWrap-Up: a Trainable Discourse Module

for each. Each of the six stages of Wrap-Up described in Section 3.1 has its own set of
ID3 trees, with the exact number of trees depending on the domain specifications. The
Slot Filtering stage has a separate tree for each slot of each object in the domain; the Slot
Merging stage has a separate tree for each object type; the Link Creation stage has a tree
for each pointer defined in the output structure; and so forth for the other stages. The
MUC-5 microelectronics domain (as explained in Section 2.2) required 91 decision trees: 20
for the Slot Filtering stage, 7 for Slot Merging, 31 for Link Creation, 13 for Object Splitting,
7 for Inferring Missing Objects , and 13 for Inferring Missing Slot Values.
An example from the Link Creation stage is the tree that determines pointers from
lithography objects to equipment objects. Every pair of lithography and equipment objects
found in a text is encoded as an instance and sent to the Lithography-Equipment-Link tree.
If the classifier returns \positive", Wrap-Up adds a pointer between these two objects in
the output to indicate that the equipment was used for that lithography process.
The ID3 decision tree algorithm (Quinlan, 1986) was used in these experiments, although
any machine learning classifier could be plugged into the Wrap-Up architecture. A vector
space approach might seem appropriate, but its performance would depend on the weights
assigned to each feature (Salton et al., 1975). It is hard to see a principled way to assign
weights to the heterogeneous features used in Wrap-Up's classifiers (see Section 3.3), since
some features encode attributes of the domain objects and others encode linguistic context
or relative position in the text.
Let's look again at the example from Section 2.2 with the \XLS stepper" and see how
Wrap-Up makes the discourse decision of whether to add a pointer from UV lithography to this equipment object. Wrap-Up encodes this as an instance for the LithographyEquipment-Link decision tree with features representing attributes of both the lithography
and equipment objects, their extraction patterns, and relative position in the text.
During Wrap-Up's training phase, an instance is encoded for every pair of lithography
and equipment objects in a training text. Training instances must be classified as positive or
negative, so Wrap-Up consults the hand-coded target output provided with the training text
and classifies the instance as positive if a pointer is found between matching lithography and
equipment objects. The creation of training instances will be discussed more fully in Section
3.4. ID3 tabulates how often each feature value is associated with a positive or negative
training instance and encapsulates these statistics at each node of the tree it builds.
Figure 2 shows a portion of a Lithography-Equipment-Link tree, showing the path used
to classify the instance for UV lithography and XLS stepper as positive. The parenthetical
numbers for each tree node show the number of positive and negative training instances represented by that node. The a priori probability of a pointer from lithography to equipment
in the training corpus was 34%, with 282 positive and 539 negative training instances.
ID3 uses an information gain metric to select the most effective feature to partition
the training instances (p.89-90, Quinlan, 1986), in this case choosing equipment type as
the test at the root of this tree. This feature alone is sucient to classify instances with
equipment type such as modular equipment, radiation source, or etching system, which have
only negative instances. Apparently these types of equipment are never used by lithography
processes (a useful bit of domain knowledge).
The branch for equipment type \stepper" leads to a node in the tree representing 202
positive and 174 negative training instances, raising the probability of a link to 54%. ID3
139

fiSoderland and Lehnert

(282 pos, 539 neg)

Equipment-type
modularequipment

...
radiationsource

(0 pos, 11 neg)

etchingsystem

...

Stepper

lithographysystem

(0 pos, 125 neg)

(0 pos, 15 neg)

(80 pos, 141 neg)

(202 pos, 174 neg)

Lithography-type
...
G-line

...

E-beam

I-line

optical

UV
(15 pos, 27 neg)

(6 pos, 25 neg)
(2 pos, 31 neg)

(87 pos, 20 neg)

(27 pos, 14 neg)

Distance
-2

...

...

0

-1
(0 pos, 1 neg)

(18 pos, 12 neg)

(4 pos, 0 neg)

Figure 2: A decision tree for pointers from lithography to equipment objects.
recursively selects a feature to partition each partition, in this case selecting lithography
type. The branch for UV lithography leads to a partition with 27 positive and 14 negative
instances, in contrast to E-beam and optical lithography which have nearly all negative
instances. The next test is distance, with a value of -1 in this case since the equipment
reference is one sentence earlier than lithography. This branch leads to a leaf node with
4 positive and no negative instances, so the tree returns a classification of positive and
Wrap-Up adds a pointer from UV lithography to the stepper.
This example shows how a decision tree can acquire useful domain knowledge: that
lithography is never linked to equipment such as etching systems, and that steppers are
often used for UV lithography but hardly ever for E-beam or optical lithography. Knowledge
of this sort could be manually engineered rather than acquired from machine learning, but
the hundreds of rules needed might take weeks or months of effort to create and test.
Consider another fragment of text and the tree in Figure 3 that decides whether to add
a pointer from the PLCC packaging process to the ROM chip device.
: : :a

new line of 256 Kbit and 1 Mbit ROM chips.
available in PLCC and priced at : : :

They are

The instance which is to be classified by a Packaging-Device-Link tree includes features for
packaging type, device type, distance between the two referents, and the extraction patterns
used by sentence analysis.
140

fiWrap-Up: a Trainable Discourse Module

(325 pos, 750 neg)

Distance

(0 pos, 12 neg)

...

...

-50

-20

(7 pos, 40 neg)

50

0

-1
(60 pos, 70 neg)

(130 pos, 93 neg)

(0 pos, 12 neg)

Device-type
...
EPROM
(6 pos, 2 neg)

memory

(0 pos, 11 neg)

...
DRAM

ROM
(13 pos, 2 neg)

none

(1 pos, 4 neg)

(0 pos, 19 neg)

pp-available-1
true

false

(13 pos, 0 neg)

(0 pos, 2 neg)

Figure 3: A tree for pointers from packaging to device objects.
ID3 selects \distance" as the root of the tree, a feature that counts the distance in sentences between the packaging and device references in the text. When the closest references
were 20 or more sentences apart, hardly any of the training instances were positive. The
distance is -1 in the example text, with ROM device mentioned one sentence earlier than
the PLCC packaging process. As Figure 3 shows, the branch for distance of -1 is followed
by a test for device type. The branch for device type ROM leads to a partition with only
15 instances, 13 positive and 2 negative. Those with PLCC packaging found in the pattern
\available in X" (encoded as pp-available-1) were positive instances.
These two trees illustrate how different trees learn different types of knowledge. The
most significant features in determining whether an equipment object is linked to a lithography process are real world constraints on what type of equipment can be used in lithography.
This is reected in the tree in Figure 2 by choosing equipment type as the root node followed by lithography type. There is no such overriding constraint on what type of device
can be linked to a packaging technique. Here linguistic clues play a more prominent role,
such as the relative position of references in the text and particular extraction patterns.
The following section discusses how these linguistic-based features are encoded.

3.3 Generating Features for ID3 Trees

Let's look in more detail at how Wrap-Up encodes ID3 instances, using information available
from sentence analysis to automatically derive the features used for each tree. Each ID3
tree handles a discourse decision about a domain object or the relationship between a pair
of objects, with different stages of Wrap-Up involving different sorts of decisions.
141

fiSoderland and Lehnert

The information to be encoded about an object comes from concept nodes extracted
during sentence analysis. Concept nodes have a case frame with slots for extracted information, and also have the location and extraction patterns of each reference in the text.
Consider again the example from Section 2.2.
GCA unveiled its new XLS stepper, which was developed with
assistance from Sematech. The system will be available in
deep-ultraviolet and I-line configurations.

Sentence analysis extracts five objects from this text: the company GCA, the equipment XLS stepper, the company Sematech, UV lithography, and I-line lithography. One of
several discourse decisions to be made is whether the UV lithography uses the XLS stepper
mentioned in the previous sentence. Figure 4 shows the two objects that form the basis of
an instance for the Lithography-Equipment-Link tree.
Equipment
Type: stepper
Name: XLS

Lithography
Type: UV
Extraction Patterns:
pp-available-in
keyword-deep-ultraviolet

Extraction Patterns:
obj-active-unveiled
subj-passive-developed
keyword-stepper

Figure 4: Two objects extracted from the sample text
Each object includes the location of each reference and the patterns used to extract
them. An extraction pattern is a combination of a syntactic pattern and a specific lexical
item or \trigger word" (as explained in Section 2.1). The pattern pp-available-in means that
a reference to UV lithography was found in a prepositional phrase following the triggers
\available" and \in".
Figure 5 shows the instance for UV lithography and XLS stepper. It encodes the attributes and extraction patterns of each object and their relative position in the text. WrapUp encodes each case frame slot of each object using the actual slot value for closed classes
such as lithography type. Open class slots such as equipment names are encoded with the
value \t" to indicate that a name was present, rather than the actual name. Using the
exact name would result in an enormous branching factor for this feature and might overly
inuence the ID3 classification if a low frequency name happened to occur only in positive
or only in negative instances.
Extraction patterns are encoded as binary features that include the trigger word and
syntactic pattern in the feature name. Patterns with two trigger words such as \pp-availablein" are split into two features, \pp-available" and \pp-in". For instances that encode a pair
of objects these features will be encoded as \pp-available-1" and \pp-in-1" if they refer to
the first object. The count of how many such extraction patterns were used is also encoded
142

fiWrap-Up: a Trainable Discourse Module

(lithography-type . UV)
(extraction-count-1 . 3)
(pp-available-1 . t)
(pp-in-1 . t)
(keyword-deep-ultraviolet-1 . t)

(equipment-type . stepper)
(equipment-name . t)
(extraction-count-2 . 3)
(obj-unveiled-2 . t)
(subj-passive-developed-2 . t)
(keyword-stepper-2 . t)

(common-triggers . 0)
(common-phrases . 0)
(distance . -1)

Figure 5: An instance for the Lithography-Equipment-Link tree.
for each object. The feature \extraction-count" was motivated by the Slot Filtering stage
since objects extracted several times are more likely to be valid than those extracted only
once or twice from the text.
Another type of feature, encoded for instances involving pairs of objects, is the relative
position of references to the two objects, which may be significant in determining if two
objects are related. One feature easily computed is the distance in sentences between
references. In this case the feature \distance" has a value of -1, since XLS stepper is found
one sentence earlier than the UV lithography process. Another feature that might indicate
a strong relationship between objects is the count of how many common phrases contain
references to both objects. Other features list \common triggers", words included in the
extraction patterns for both objects. An example of this would be the word \using" if the
text had the phrase \the XLS stepper using UV technology".
It is important to realize what is not included in this instance. A human making this
discourse decision might reason as follows. The sentence with UV lithography indicates
that it is associated with \the system", which refers back to \its new XLS stepper" in the
previous sentence. Part of this reasoning involves domain independent use of a definite
article, and part requires domain knowledge that \system" can be a nonspecific reference
to an equipment object. The current version of Wrap-Up does not look beyond information
passed to it by sentence analysis and misses the reference to \the system" entirely.
Using specific linguistic patterns resulted in extremely large, sparse feature sets for most
trees. The Lithography-Equipment-Link tree had 1045 features, all but 11 of them encoding
extraction patterns. Since a typical instance participates in at most a dozen extraction
patterns, a serious time and space bottle neck would occur if the hundreds of linguistic
patterns that are not present were explicitly listed for each instance. We implemented a
sparse vector version of ID3 that was able to eciently handle large feature spaces by only
tabulating the small number of true-valued features for each instance.
As links are added during discourse processing, objects may become complex, including
many pointers to other objects. By the time Wrap-Up considers links between companies
and microelectronics processes, a lithography object may have a pointer to an equipment
object or to a device object, and the equipment object may in turn have pointers to other
objects. Wrap-Up allows objects to inherit the linguistic context and position in the text
of objects to which they point. When object A has a pointer to object B, the location and
143

fiSoderland and Lehnert

extraction patterns of references to B are treated as if they references to A. This version
of inheritance is helpful, but a little too strong, ignoring the distinction between direct
references and inherited references.
We have looked at the encoding of instances for isolated discourse decisions in this
section. The entire discourse system is a complex series of decisions, each affecting the
environment used for further processing. The training phase must reect this changing
environment at run time as well as provide classifications for each training instance based
on the target output. These issues are discussed in the next section.

3.4 Creating the Training Instances

ID3 is a supervised learning algorithm that requires a set of training instances, each labeled
with the correct classification for that instance. To create these instances Wrap-Up begins
its tree building phase by passing the training texts to the sentence analyzer, which creates
a set of objects representing the extracted information. Multiple references to the same
object are then merged to form the initial input to Wrap-Up's first stage. Wrap-Up encodes
instances and builds trees for this stage, then repeats the process using trees from stage one
to build trees for stage two, and so forth until trees have been built for all six stages.
As it encodes instances, Wrap-Up repeatedly consults the target output to assign a
classification for each training instance. When building trees for the Slot Filtering stage
an instance is classified positive if the extracted information matches a slot in the target
output. Consider the example of a reference to an \Ultratech stepper" in a microelectronics
text. Sentence analysis creates an equipment object with two slots filled, equipment type
stepper and equipment name \Ultratech". This stage of Wrap-Up has a separate ID3 tree
to judge the validity of each slot, equipment type and equipment name.
Suppose that the target output has an equipment object with type \stepper" but that
\Ultratech" is actually the manufacturer's name and not the equipment model name. The
equipment type instance will be classified positive and the equipment name instance classified negative since no equipment object in the target output has the name Ultratech.
Does this instance include features that capture why a human analyst would not consider
\Ultratech" to be the equipment name? The human is probably using world knowledge
to recognize Ultratech as a familiar company name and recognize other names such as
\Precision 5000" as familiar equipment names. Knowledge such as lists of known company
names and known equipment names is not presently included in Wrap-Up, although this
could be derived easily from the training corpus.
To create training instances for the second stage of Wrap-Up, the entire training corpus
is processed again, this time discarding some slot values as spurious according to the Slot
Filtering trees before creating instances for Slot Merging trees. An instance is created for
each pair of objects of the same type. If both objects can be mapped to the same object in
the target output, the instance is classified as positive. For example, an instance would be
created for a pair of device objects, one with device type RAM and the other with size 256
KBits. It is a positive instance if the output has a single device object with type RAM and
size 256 KBits.
By the time instances are created for later stages of Wrap-Up, errors will have crept in
from previous stages. Errors in filtering, merging, and linking will have resulted in some
144

fiWrap-Up: a Trainable Discourse Module

objects retained that no longer match anything in the target output and some objects that
only partially match the target output. Since some degree of error is unavoidable, it is
best to let the training instances reect the state of processing that will occur later when
Wrap-Up is used to process new texts. If the training is too perfectly filtered, merged, and
linked, it will not be representative of the underlying probabilities during run time use of
Wrap-Up.
In later stages of Wrap-Up objects may become complex and only partially match anything in the target output. To aid in matching complex objects, one slot for each object
type is identified in the output structure definition as the key slot. An object is considered
to match an object in the output if the key slots match. Thus an object with a missing
equipment name or spurious equipment name will still match if equipment type, the key
slot, matches. If object A has a pointer to an object B, the object matching A in the output
must also have a pointer to an object matching B.
Such recursive matching becomes important during the Link Creation stage. Among the
last links considered in microelectronics are the roles a company plays towards a process. A
company may be the developer of an x-ray lithography process that uses the ABC stepper,
but not developer of the x-ray lithography process linked to a different equipment object.
Wrap-Up needs to be sensitive to such distinctions in classifying training instances for trees
in the Link Creation and Object Splitting stages.
Instances in the Inferring Missing Objects stage and the Inferring Missing Slot Values
stage have classifications that go beyond a simple positive or negative. An instance for the
Inferring Missing Objects stage is created whenever an object is found during training that
has no higher object pointing to it. If a matching object indeed exists in the target output,
Wrap-Up classifies the instance with the type of the object that points to it in the output.
For example a training text may have a reference to \stepper" equipment, but have no
mention of any process that uses the stepper. The target output will have a lithography
object of type \unknown" that points to the stepper equipment. This is a legitimate inference to make, since steppers are a type of lithography equipment. The instance for the
orphaned stepper equipment object will be classified as \lithography-unknown-equipment".
This classification gives Wrap-Up enough information during run time to create the appropriate object.
An instance for Inferring Missing Slot Values is created whenever a slot is missing from
an object which has a closed class of possible values, such as the \status" slot for equipment
objects, that has the value of \in-use" or \in-development". When a matching object is
found in the target output, the actual slot value is used as the classification. If the slot is
empty or no such object exists in the output, the instance is classified as negative. As in
the Inferring Missing Objects stage, negative is the most likely classification for many trees.
Next we consider the effects of tree pruning and confidence thresholds that can make
the ID3 more cautious or more aggressive in its classifications.

3.5 Confidence Thresholds and Tree Pruning

With any machine learning technique there is a tendency toward \overfitting", making
generalizations based on accidental properties of the training data. In ID3 this is more
likely to happen near the leaf nodes of the decision tree, where the partition size may
145

fiSoderland and Lehnert

grow too small for ID3 to select features with much predictive power. A feature chosen
to discriminate among half a dozen training instances is likely to be particular to those
instances and not useful in classifying new instances.
The implementation of ID3 used by Wrap-Up deals with this problem by setting a pruning level and a confidence threshold for each tree empirically. A new instance is classified by
traversing the decision tree from the root node until a node is reached where the partition
size is below the pruning level. The classification halts at that node and a classification of
positive is returned if the proportion of positive instances is greater than or equal to the
confidence threshold.
A high confidence threshold will make an ID3 tree cautious in its classifications, while
a low confidence threshold will allow more positive classifications. The effect of changing
the confidence threshold is more pronounced as the pruning level increases. With a large
enough pruning level, nearly all branches will terminate in internal nodes with confidence
somewhere between 0.0 and 1.0. A low confidence threshold will classify most of these
instances as positive, while a high confidence threshold will classify them as negative.
Wrap-Up automatically sets a pruning level and confidence threshold for each tree using
tenfold cross-validation. The training instances are divided into ten sets and each set is
tested on a tree built from the remaining nine tenths of the training. This is done at
various settings to find settings that optimize performance.
The metrics used in this domain are \recall" and \precision", rather than accuracy.
Recall is the percentage of positive instances that are correctly classified, while precision is
the percentage of positive classifications that are correct. A metric which combines recall
and precision is the f-measure, defined by the formula f = (fi 2 + 1)P R=(fi 2P + R) where fi
can be set to 1 to favor balanced recall and precision. Increasing or decreasing fi for selected
trees can fine-tune Wrap-Up, causing it to select pruning and confidence thresholds that
favor recall or favor precision.
We have seen how Wrap-Up automatically derives the classifiers needed and the feature
set for each classifier, and how it tunes the classifiers for recall/precision balance. Now
we will look at the requirements for using Wrap-Up, with special attention to the issue of
manual labor during system development.

3.6 Requirements of Wrap-Up

Wrap-Up is a domain-independent architecture that can be applied to any domain with
a well defined output structure, where domain objects are represented as case frames and
relationships between objects are represented as pointers between objects. It is appropriate
for any information extraction task in which it is important to identify logical relationships
between extracted information. The user must supply Wrap-Up with an output definition
listing the domain objects to be extracted. Each output object has one or more slots, each of
which may contain either extracted information or pointers to other objects in the output.
One slot for each object is labeled as the key slot, used during training to match extracted
objects with objects in the target output.
If the domain and application are already well defined, a user should be able to create
such an output definition in less than an hour. For a new application, whose information needs are not established, there is likely to be a certain amount of trial and error in
146

fiWrap-Up: a Trainable Discourse Module

developing the desired representation. This need for a well defined domain is not unique
to discourse processing or to trainable components such as Wrap-Up. All IE systems require clearly defined specifications of what types of objects are to be extracted and what
relationships are to be reported.
The more time consuming requirement of Wrap-Up is associated with the acquisition of
training texts and most importantly, hand-coded target output. While hand-coded targets
represent a labor-intensive investment on the part of domain experts, no knowledge of
natural language processing or of machine learning technologies is needed to generate these
answer keys, so any domain expert can produce answer keys for use by Wrap-Up. A
thousand microelectronics texts were used to provide training for Wrap-Up. The actual
number of training instances from these training texts varied considerably for each decision
tree. Trees that handled the more common domain objects had ample training instances
from only two hundred training texts, while those that dealt with the less frequent objects
or relationships were undertrained from a thousand texts.
It is easier to generate a few hundred answer keys than it is to write down explicit and
comprehensive domain guidelines. Moreover, domain knowledge implicitly present in a set
of answer keys may go beyond the conventional knowledge of a domain expert when there
are reliable patterns of information that transcend a logical domain model. Once available,
this corpus of training texts can be used repeatedly for knowledge acquisition at all levels
of processing.
The architecture of Wrap-Up does not depend on a particular sentence analyzer or a
particular information extraction task. It can be used with any sentence analyzer that uses
keywords and local linguistic patterns for extraction. The output representation produced
by Wrap-Up could either be used directly to generate database entries in a MUC-like task
or could serve as an internal representation to support other information extraction tasks.

3.7 The Joint Ventures Domain

After Wrap-Up had been implemented and tested in the microelectronics domain, we tried
it on another domain, the MUC-5 joint ventures domain. The information to be extracted
in this domain are companies involved in joint business ventures, their products or services,
ownership, capitalization, revenue, corporate ocers, and facilities. Relationships between
companies must be sorted out to identify partners, child companies, and subsidiaries. The
output structure is more complex than that of microelectronics, with back-pointers, cycles
in the output structure, redundant information, and longer chains of linked objects.
Figure 6 shows a text from the joint ventures domain and a diagram of the target output.
With all the pointers and back-pointers, the output for even a moderately complicated text
becomes dicult to understand at a glance. This text describes a joint venture between a
Japanese company, Rinnai Corp., and an unnamed Indonesian company to build a factory
in Jakarta. A tie-up is identified with Rinnai and the Indonesian company as partners
and a third company, the joint venture itself, as a child company. The output includes an
\entity-relationship" object which duplicates much of the information in the tie-up object.
A corporate ocer, the amount of capital, ownership percentages, the product \portable
cookers", and a facility are also reported in the output.
147

fiSoderland and Lehnert

RINNAI CORP., JAPAN'S LEADING GAS APPLIANCE MANUFACTURER, WILL SET UP
A JOINT VENTURE IN INDONESIA IN AUGUST TO PRODUCE PORTABLE COOKERS FOR
LOCAL USERS, PRESIDENT SUSUMU NAITO SAID MONDAY.
THE NEW FIRM WILL BE CAPITALIZED AT ONE MILLION DOLLARS, OF WHICH
RINNAI IS SCHEDULED TO PUT UP 50 PCT AND A LOCAL DEALER 50 PCT, HE SAID.
IT WILL MANUFACTURE 3,000 TO 4,000 UNITS A MONTH INITIALLY AT A PLANT
IN A 26,000-SQUARE-METER SITE IN JAKARTA, NAITO SAID, ADDING RINNAI AIMS
TO START FULL-SCALE PRODUCTION NEXT SPRING.
THE NAGOYA-BASED COMPANY HAS NOW SEVEN OVERSEAS PRODUCTION UNITS.

Template
Doc-Nr: 1485
Content:

Tie-Up
Status: existing
Entity:
Joint-venture:
Ownership:
Activity:

Activity
Site: (
Industry:

Entity
Type: company
Location: Indonesia
Relationship:
Facility:

Entity
Type: company
Name: Rinnai Corp
Aliases: "Rinnai"
Location: Nagoya, Japan
Relationship:
Person:

Entity
Type: company
Nationality: Indonesia
Relationship:

Facility
Type: factory
Location: Jakarta,
Indonesia

Person
Name: Susumu Naito
Position: pres
Entity:

Relationship
Entity-1:
Entity-2:
Relation: child
Status: future

)

Industry
Type: Production
Product:
"portable
cookers"

Ownership
Capital: 1000000 $
Ownership-Percent: (
Owned:

50) (

50)

Figure 6: A sample text and target output from the joint ventures domain.

148

fiWrap-Up: a Trainable Discourse Module

Some special handling was required for the joint ventures domain since the output
structure defined for the MUC-5 evaluation included some slots such as activity site and
ownership percent whose values had a mixture of extracted information and pointers. These
slot values have their own internal structure and can be thought of as pseudoobjects, an
activity site object with pointers to a facility object and a company, and an ownership
percent object with a pointer to a company and another slot giving a numeric value. These
pseudoobjects were reformulated as standard objects conforming to the requirements of
Wrap-Up, the activity site slot pointing to an activity site object and so forth. These were
then transformed back into the complex slot fills when printing the final representation of
the output.
The output specifications for joint ventures were less well-behaved in other ways, with
graph cycles, back pointers, and redundant objects whose content must agree with information elsewhere in the output. Modifications to Wrap-Up were needed to relax some implicit
requirements for the domain structure, allowing graph cycles and giving special handling
to any pointer slot which the user has labeled in the output definition as a back pointer.
Joint ventures also has some implicit constraints on relationships between objects. A
company can play only a single role in a tie-up or a joint venture relationship: it cannot be
both a joint venture child and also a parent or partner company. Wrap-Up had diculty
learning this constraint and performed better when certain pointer slots were labeled with
a \single-role" constraint in the output definition.
This strategy of letting the user indicate constraints by annotating slots in the output
definition was implemented in an ad hoc fashion. A more general approach would allow the
user to declare several types of constraint on the output. A pointer slot may be required
or optional, may have at most one pointer or allow several. Some slots of an object may be
mutually exclusive, an entry in one prohibiting an entry in another slot. There may be a
required agreement between the value of a slot in one object and a slot in another object. A
fully domain-independent discourse tool needs a mechanism to implement such generalized
constraints.

4. System Performance

As a point of comparison for the performance of Wrap-Up, the UMass/Hughes system was
run with the TTG discourse module, which had been used in the ocial MUC-5 evaluation. Overall system performance with Wrap-Up was compared to performance with TTG,
holding the rest of the system constant.
Wrap-Up takes the idea of TTG and extends it into a fully trainable system. TTG
used decision trees to acquire domain knowledge, but often relied on hand-coded heuristics
to apply that acquired knowledge, in particular the decisions about splitting or merging
objects, which Wrap-Up handles during its Object Splitting stage; inferring missing objects,
which Wrap-Up does in its Inferring Missing Objects stage; and adding context sensitive
default slot values, which Wrap-Up does in its Inferring Missing Slot Values stage.
Several iterations of hand tuning were required to adjust thresholds for the decision trees
produced by TTG, whereas Wrap-Up found thresholds and pruning levels to optimize recall
and precision for each tree automatically. After a day of CPU time devoted to decision tree
training, Wrap-Up produced a working system and no further programming was needed.
149

fiSoderland and Lehnert

The comparison with TTG was made for both the microelectronics domain and the
joint ventures domain. The metrics used here are recall and precision. Recall is the percentage of possible information that was reported. Correctly identifying two out of five
possible company names gives recall of 40. Precision is the percent correct of the reported
information. If four companies are reported, but only two of them correct, precision is 50.
Recall and precision are combined into a single metric by the f-measure, defined as f =
(fi 2 + 1)P R=(fi 2P + R), with fi is set to 1 for balanced recall and precision.

4.1 The Microelectronics Domain

Wrap-Up's scores on the ocial MUC-5 microelectronics test sets were generally a little
higher than to those of TTG, both in overall recall and precision.
Wrap-Up
Rec. Prec. F

TTG
Rec. Prec.

Part 1
Part 2

32.3 44.4 37.4
36.3 38.6 37.4

27.1 39.5 32.1
32.7 37.0 34.7

Part 3

34.6 37.7 36.1

34.7 40.5 37.5

Avg.

34.4 40.2 36.8

31.5 39.0 34.8

F

Figure 7: Performance on MUC-5 microelectronics test sets
To put these scores in perspective, the highest scoring systems in the MUC-5 evaluation
had f-measures in the high 40's. This was a dicult task both for sentence analysis and
discourse analysis.
Another way to assess Wrap-Up is to measure its performance against the baseline
provided by output from sentence analysis. Lack of coverage by the sentence analyzer
places a ceiling on performance at the discourse level. In test set part 1 there were 208
company names to be extracted. The CIRCUS analyzer extracted a total of 404 company
names, with only 131 correct and 2 partially correct, giving a baseline of 63% recall and 33%
precision for that slot. Wrap-Up's Entity-Name-Filter tree managed to discard a little over
half of the spurious company names, keeping 77% of the good companies. This resulted in
49% recall and 44% precision for this slot, raising the f-measure by 5 points, but doing so
at the expense of recall.
Limited recall for extracted objects is compounded when it comes to links between
objects. If half the possible companies and a third of the microelectronics processes are
missing, discourse processing has no chance at a large proportion of the possible links
between companies and processes.
Although precision is often increased at the expense of recall, Wrap-Up also has mechanisms to increase recall slightly. When the Inferring Missing Objects stage infers a missing
process from an equipment object or the Object Splitting stage splits a process that points
to multiple equipment, Wrap-Up can sometimes gain recall above that produced by the
sentence analyzer.

150

fiWrap-Up: a Trainable Discourse Module

4.2 The Joint Ventures Domain

In the joint ventures domain Wrap-Up's scores on the MUC-5 test sets were a little lower
than the ocial UMass/Hughes scores. Wrap-Up tended to have lower recall but slightly
higher precision.
Wrap-Up
Rec. Prec. F

TTG
Rec. Prec.

Part 1
Part 2

23.5 52.9 32.5
22.7 53.6 31.9

26.0 53.9 35.1
26.0 52.1 34.7

Part 3

23.3 51.4 32.1

27.7 49.7 35.6

Avg.

23.2 52.7 32.2

26.5 52.0 35.1

F

Figure 8: Performance on MUC-5 joint ventures test sets
The performance of Wrap-Up and TTG is roughly comparable for each of the two
domains. Both systems tend to favor the domain in which they were first developed, WrapUp developed in microelectronics then ported to joint ventures, while the opposite was true
for TTG. A certain amount of bias has probably crept into design decisions that were meant
to be domain independent in each system. The higher scores of TTG for joint ventures are
partly due to hand-coded heuristics that altered output from TTG before printing the final
output, something that was not done for TTG in microelectronics or for Wrap-Up in either
domain.
The most noticeable difference between Wrap-Up and TTG output in the joint ventures
domain was in the filtering of spuriously extracted company names. Discourse processing
started with 38% recall and 32% precision from sentence analysis for company names. Both
systems included a filtering stage that attempted to raise precision by discarding spurious
companies, but did so at the expense of discarding some valid companies as well. Each
system used threshold settings to control how cautiously or aggressively this discarding is
done (as in the example from Section 3.5). TTG's were set by hand and Wrap-Up's were
selected automatically by cross-validation on the training set. TTG did only mild filtering
on this slot, resulting in a gain of 2 precision points but a drop of 6 recall points. Wrap-Up
chose aggressive settings and gained 13 precision points but lost 17 points in recall for this
slot.
As a result, Wrap-Up ended up with only two thirds as many correct companies as
TTG. This in turn meant two thirds as many pointers to companies in tie-ups and entity
relationships. For other objects Wrap-Up scored higher recall than TTG, getting more than
three times the total recall for activity, industry, and facility objects.

5. Conclusions

With the recent accessibility of large on-line text databases and news services, the need for
information extraction systems is growing. Such systems go beyond information retrieval
and create a structured summary of selected information contained within relevant documents. This gives the user the ability to skim vast amounts of text, pulling out information
151

fiSoderland and Lehnert

on a particular topic. IE systems are knowledge-based, however, and must be individually
tailored to the information needs of each application.
Some research laboratories have focused on sophisticated user interfaces to ease the
burden of knowledge acquisition. GE's NLToolset is an example of this approach (Jacobs et
al., 1993), while BBN typifies systems that combine user input with corpus-based statistics
(Ayuso et al., 1993). The University of Massachusetts has been moving in the direction
of machine learning to create a fully trainable IE system. The ultimate goal is a turnkey
system that can be tailored to new information needs by users who have no special linguistic
or technical expertise.
Wrap-Up embodies this goal. The user defines an information need and output structure,
and provides a training corpus of representative texts with hand-coded target output for
each text. Wrap-Up takes it from there and instantiates a fully functional IE discourse
system for the new domain with no further customization needed by the user. Wrap-Up
is the first fully trainable system to handle discourse processing, and it does so with no
degradation in performance. It automatically decides what classifiers are needed based on
the domain output structure and derives the feature set for each classifier from sentence
analyzer output.
The most intriguing aspect of Wrap-Up is the automatic generation of features. How
effective was this, and what did the trees actually learn? The greatest leverage seems to
come from features that encode attributes of domain objects. The trees in microelectronics
often based their classification on probabilities conditioned on the device type, equipment
type, or process type. The example tree in Section 3.2 first tested the equipment type and
lithography type in determining whether a piece of equipment was used for a lithography
process. This type of real world domain knowledge was the most important thing that
Wrap-Up learned about microelectronics.
Useful knowledge was also provided by features that encoded the relative position of
references in the text. Distance, measured in number of sentences apart, played a prominent
role in many classifications, with other trees relying on more fine-grained features such as
the number of times both references were in the same noun phrase or had overlapping
linguistic context.
An enhancement to Wrap-Up's feature generation would be to increase its expressiveness
about relative position. In addition to direct references to object A and object B, Wrap-Up
could look for indirect references to A (pronominal or anaphoric) found near references to
B and vice versa. The instance shown in Section 3.3 is an example where features for such
indirect relationships might be useful.
Wrap-Up currently encodes an instance for each pair of objects that might be related,
but is incapable of expressing the rule \attach object B to the most recent object of type A."
It is blind to the existence of other objects that are alternate candidates to the relationship
being considered. Features could be encoded to reect whether object A is the most recently
mentioned object of its type.
The features that were least successful and most tantalizing were those that encoded the
local linguistic context, the extraction patterns. These included an exact lexical item and
were nearly all of such low frequency that they added noise more often than aiding useful
discriminations. Tree pruning was only a partial solution, and an experiment in combining
semantically similar terms only caused a sharp drop in classification accuracy.
152

fiWrap-Up: a Trainable Discourse Module

Low frequency terms are a built-in problem for any system that processes unrestricted
text. Dunning (93) estimated that 20-30% of typical English news wire reports are composed
of words of frequency less than one in 50,000 words. Yet the discourse decisions made
by a human reader often seem to hinge on the use of one of these infrequent terms. It
is a challenging open question to find methods to utilize local linguistic context without
drowning in the noise produced by low frequency terms.
Finding a mechanism for choosing appropriate features is more critical than which machine learning algorithm is applied. ID3 was chosen as easy to implement, although other
approaches such as vector spaces are worth trying. It is not obvious, however, how to craft
a weighting scheme that gives greatest weight to the most useful features in the vector
space and nearly zero to those not useful in making the desired discrimination. Cost and
Salzberg (1993) describe a weighting scheme for the nearest neighbor algorithm that looks
promising for lexically-based features. Another candidate for an effective classifier is a back
propagation network, which might naturally converge on weights that give most inuence
to the most useful features.
We hope that Wrap-Up will inspire the machine learning community to consider analysis
of unrestricted text as a fruitful application for ML research, while challenging the natural
language processing community to consider ML techniques for complex processing tasks.
In a broader context, Wrap-Up provides a paradigm for user customizable system design,
where no technological background on the part of the user is assumed. A fully functional
system can be brought up in a new domain without the need for months of development
time, signifying substantial progress toward fully scalable and portable natural language
processing systems.

Appendix A: Walk-through of a Sample Text

To see the Wrap-Up algorithm in action, consider the sample text in Figure 9. The
desired output has the company, Mitsubishi Electronics America, Inc., linked as purchaser/user to two packaging processes, TSOP and SOJ packaging. Each of these processes
point to the device, 1 Mbit DRAM. The packaging material, plastic, should be attached
to TSOP but not SOJ. All other details from the text are considered extraneous to the
domain.
After sentence analysis, followed by the step that merges multiple references, there are
eight objects passed as input to Wrap-Up. Sentence analysis did fairly well in identifying
the relevant information, only missing \1 M" as a reference to 1 MBits. Three of the
eight objects are spurious and should be discarded during Wrap-Up's Slot Filtering stage.
According to domain guidelines, the name \Mitsubishi Electronics America, Inc." should
be reported, not \The Semiconductor Division ...". The packaging material EPOXY and
the device MEMORY should also be discarded.
The Slot Filtering stage creates an instance for each slot of each object. The EntityName-Filter tree classifies \Mitsubishi Electronics America, Inc." as a positive instance,
but \The Semiconductor Division ..." as negative and it is discarded. The most reliable
discriminator of valid company names is \extraction-count", which was selected as root
feature of this tree. Training instances participating in several extraction patterns were
twice as likely to be valid as those extracted only once or twice. This held true in this text.
153

fiSoderland and Lehnert

The Semiconductor Division of Mitsubishi Electonics America, Inc. now offers
1M CMOS DRAMs in Thin Small-Outline Packaging (TSOP*), providing the
highest memory density available in the industry. Developed by Mitsubishi,
the TSOP also lets designers increase system memory density with standard and
reverse or "mirror image," pin-outs. Mitsubishi's 1M DRAM TSOP provides
the density of chip-on-board but with much higher reliability because the
plastic epoxy-resin package allows each device to be 100% burned-in and fully
tested. *Previously referred to as VSOP (very small-outline package) or USOP
(ultra small-outline package). The 1M DRAM TSOP has a height of 1.2 mm, a
plane measurement of 16.0 mm x 6.0 mm, and a lead pitch of 0.5 mm, making
it nearly three times thinner and four times smaller in volume than the 1M
DRAM SOJ package. The SOJ has a height of 3.45 mm, a plane dimension of
17.15 mm x 8.45 mm, and a lead pitch of 1.27 mm. Additionally, the TSOP
weighs only 0.22 grams, in contrast with the 0.75 gram weight of the SOJ.
Full text available on PTS New Product Announcements.

Figure 9: A microelectronics text

Entity
Type: company
Name:Mitsubishi Electronics
America, Inc.

Entity
Type: company
Name: The Semiconductor Division of
Mitsubishi Electronics America, Inc.

Device
Type: DRAM

Packaging
Type: TSOP

Device
Type: MEMORY

Packaging
Material: EPOXY

Packaging
Material: PLASTIC

Packaging
Type: SOJ

Figure 10: Input to Wrap-Up from the sample text

154

fiWrap-Up: a Trainable Discourse Module

\Mitsubishi Electronics America, Inc." had extraction count of 5, while the spurious name
was extracted from only 2 patterns.
As the Slot Filtering stage continues, the packaging material EPOXY is classified negative by the Packaging-Material-Filter tree, whose root test is packaging type. It turns out
that EPOXY was usually extracted erroneously in the training corpus. This contrasts with
the material PLASTIC which was usually reliable and is classified positive. Both TSOP and
SOJ packaging types are classified positive by the Packaging-Type-Filter tree. Instances for
these types were usually positive in the training set, particularly when extracted multiple
times from the text. The Device-Type-Filter tree, with root feature device type, finds that
DRAM is a reliable device type but that MEMORY was usually spurious in the training
corpus. It should usually be merged with a more specific device type.
The Slot Merging stage of Wrap-Up then considers each pair of remaining objects of
the same type. There are three packaging objects, one with type TSOP, one with material
PLASTIC, and one with type SOJ. The Packaging-Slotmerge tree easily rejects the TSOPSOJ instance, since packaging objects never had multiple types in training. After testing
that the second object has no packaging type, the feature \distance" is tested. This led to a
positive classification for TSOP-PLASTIC, which are from the same sentence, and negative
for SOJ-PLASTIC, with nearest references two sentences apart. At this point four objects
remain:
Entity
Type: company
Name:Mitsubishi Electronics
America, Inc.

Packaging
Type: TSOP
Material: PLASTIC

Device
Type: DRAM

Packaging
Type: SOJ

The Link Creation stage considers each pair of objects that could be linked according
to the output structure. The first links considered are pointers from packaging to device
objects. Separate instances for the Packaging-Device-Link tree are created for the possible
TSOP-DRAM link and for the possible SOJ-DRAM link. Although only 25% of the training
instances were positive, the tree found that 78% were positive with packaging type TSOP
and \distance" of 0 sentences, and 77% were positive with packaging type SOJ and device
type DRAM. After testing a few more features, the tree found each of these instances
positive and pointers were added in the output. Notice how this tree interleaves knowledge
about types of packaging and types of devices with knowledge about relative position of
references in the text.
The next Link Creation decision concern the roles Mitsubishi plays towards each of the
packaging processes. The output structure has a \microelectronics-capability" object with
one slot pointing to a lithography, layering, etching, or packaging process, and four other
slots (labeled developer, manufacturer, distributor, and purchaser/user) pointing to companies. Wrap-Up accordingly encodes four instances for Mitsubishi and TSOP packaging,
one for each possible role. The same is done for Mitsubishi and SOJ packaging.
Instances for Mitsubishi in the roles of developer, manufacturer, and distributor were all
classified as negative. Training instances for these trees had almost no positive instances.
155

fiSoderland and Lehnert

Template
Doc-Nr: 2523814
Contents:
ME-Capability
Purchaser/User:
Developer:
Process:

ME-Capability
Purchaser/User:
Process:

Packaging
Type: TSOP
Material: plastic
Device:

Packaging
Type: SOJ
Device:

Entity
Type: company
Name: Mitsubishi
Electronics
America, Inc.

Device
Type: DRAM

Figure 11: Final output after links have been added
It seems that stories about packaging processes in this corpus are almost exclusively about
companies purchasing or using someone else's packaging technology.
There are seldom explicit linguistic clues about the relationship of a company to a process
in this corpus, so the Packaging-User-Link tree tests first for the relative distance between
references. Only 20% of training instances were positive, but when distance was 0 it jumped
to 43% positive. Mitsubishi is in the same sentence with TSOP and the Mitsubishi-SOJ
instance also has distance of 0 by inheritance. Even though the nearest reference to SOJ is
two sentences after Mitsubishi, SOJ is linked to DRAM which occurs in the same sentence
as Mitsubishi. Both instances are classified positive after further testing for packaging type
and other features.
The last discourse decision in the Link Creation stage is to add pointers to each microelectronics capability from a \template object", created as a dummy root object in this
domain's output. The Object Splitting stage finally gets to make a decision, albeit a vacuous
one, and decides to let the template object point to multiple objects in its \content" slot.
There were no \orphan" objects or missing slot values for the last two stages of Wrap-Up
to consider. The final output for this text is shown in Figure 11.

Acknowledgements
This research was supported by NSF Grant no. EEC-9209623, State/Industry/University
Cooperative Research on Intelligent Information Retrieval.

156

fiWrap-Up: a Trainable Discourse Module

References

Ayuso, D., Boisen, S., Fox, H., Gish, H., Ingria, R., & Weischedel, R. (1992). BBN: Description of the PLUM System as Used for MUC-4. In Proceedings of the Fourth Message
Understanding Conference, 169-176. Morgan Kaufmann Publishers.
Brent, M. (1993). Robust Acquisition of Subcategorization Frames. In Proceeding of the
Association for Computational Linguistics.
Cardie, C. (1993). A Case-Based Approach to Knowledge Acquisition for Domain-Specific
Sentence Analysis. In Proceedings of the Eleventh National Conference on Artificial
Intelligence, 798-803.
Church, K. (1988). A stochastic parts program and noun phrase parser for unrestricted text.
In Proceedings of the Second Conference on Applied Natural Language Processing of
the ACL, 136-143.
Cost, S., & Salzberg, S. (1993). A Weighted Nearest Neighbor Algorithm for Learning with
Symbolic Features. Machine Learning, 10(1), 57-78.
DeRose, S. (1988). Grammatical Category Disambiguation by Statistical Optimization.
Computational Linguistics, 14(1), 31-39.
Dolan, C. P., Goldman, S. R., Cuda, T. V., & Nakamura, A. M. (1991). Hughes Trainable
Text Skimmer: Description of the TTS System as used for MUC-3. In Proceedings of
the Third Message Understanding Conference, 155-162. Morgan Kaufmann Publishers.
Dunning, T. (1993). Accurate Methods for the Statistics of Surprise and Coincidence. Computational Linguistics, 19(1), 61-74.
Grosz, B., & Sidner C. (1986). Attention, intention and the structure of discourse. Computational Linguistics, 12(3), 175-204.
Hindle, D. (1989). Acquiring Disambiguation Rules from Text. In Proceeding of the Association for Computational Linguistics, 118-125.
Hobbs, J. (1978). Resolving Pronoun References. Lingua, 44(4), 311-338.
Jacobs, P., Krupka, G., Rau, L., Mauldin, M., Mitamura, T., Kitani, T., Sider, I., &
Childs, L. (1993). GE-CMU: Description of the SHOGUN System used for MUC5. In Proceedings of the Fifth Message Understanding Conference, 109-120. Morgan
Kaufmann Publishers.
Lehnert, W. (1990). Symbolic/Subsymbolic Sentence Analysis: Exploiting the Best of Two
Worlds. Advances in Connectionist and Neural Computation Theory. vol. 1.. Norwood,
NJ: Ablex Publishing, 151-158.
Lehnert, W., Cardie, C., Fisher, D., McCarthy, J., Riloff, E., & Soderland, S. (1992).
University of Massachusetts: Description of the CIRCUS System as Used for MUC-4.
In Proceedings of the Fourth Message Understanding Conference, 282-288. Morgan
Kaufmann Publishers.
157

fiSoderland and Lehnert

Lehnert, W., McCarthy, J., Soderland, S., Riloff, E., Cardie, C., Peterson, J., Feng, F.,
Dolan, C., & Goldman, S. (1993). UMass/Hughes: Description of the CIRCUS System
as Used for MUC-5. In Proceedings of the Fifth Message Understanding Conference,
257-259. Morgan Kaufmann Publishers.
Liddy, L., McVearry, K., Paik, W., Yu, E., & McKenna, M. (1993). Development, Implementation, and Testing of a Discourse Model for Newspaper Texts. In Proceedings of
the Human Language Technology Workshop, 159-164. Morgan Kaufmann Publishers.
MUC-3. (1991). Proceedings of the Third Message Understanding Conference. Morgan Kaufmann Publishers.
MUC-4. (1992). Proceedings of the Fourth Message Understanding Conference. Morgan
Kaufmann Publishers.
MUC-5. (1993). Proceedings of the Fifth Message Understanding Conference. Morgan Kaufmann Publishers.
Quinlan, J.R. (1986). Induction of Decision Trees. Machine Learning, 1, 81-106.
Riloff, E. (1993). Automatically Constructing a Dictionary for Information Extraction
Tasks. In Proceedings of the Eleventh National Conference on Artificial Intelligence,
811-816.
Salton, G., Wong, A., & Yang, C.S. (1975). A vector space model for automatic indexing.
Correspondences of the ACM, 18(11), 613-620.
Soderland, S., & Lehnert, W. (1994). Corpus-Driven Knowledge Acquisition for Discourse
Analysis. In Proceedings of the Twelfth National Conference on Artificial Intelligence,
827-832.
Weischedel, R., Meteer, M., Schwartz, R., Ramshaw, L., & Palmucci, J. (1993). Coping
with Ambiguity and Unknown Words Through Probabilistic Models. Computational
Linguistics, 19(2), 359-382.
Will, C. (1993). Comparing human and machine performance for natural language information extraction: Results for English microelectronics from the MUC-5 evaluation.
In Proceedings of the Fifth Message Understanding Conference, 53-67. Morgan Kaufmann Publishers.

158

fiJournal of Artificial Intelligence Research 2 (1995) 361{367

Submitted 8/94; published 3/95

Research Note

On the Informativeness of the DNA
Promoter Sequences Domain Theory

Julio Ortega
Computer Science Dept., Vanderbilt University
P.O. Box 1679, Station B
Nashville, TN 37235 USA

julio@vuse.vanderbilt.edu

Abstract
The DNA promoter sequences domain theory and database have become popular for
testing systems that integrate empirical and analytical learning. This note reports a simple
change and reinterpretation of the domain theory in terms of M-of-N concepts, involving no
learning, that results in an accuracy of 93.4% on the 106 items of the database. Moreover,
an exhaustive search of the space of M-of-N domain theory interpretations indicates that
the expected accuracy of a randomly chosen interpretation is 76.5%, and that a maximum
accuracy of 97.2% is achieved in 12 cases. This demonstrates the informativeness of the
domain theory, without the complications of understanding the interactions between various
learning algorithms and the theory. In addition, our results help characterize the diculty
of learning using the DNA promoters theory.

1. Introduction
The DNA promoter sequences domain theory and database, contributed by M. Noordewier
and J. Shavlik to the UCI repository (Murphy & Aha, 1992), have become popular for
testing systems that integrate empirical and analytical learning (Hirsh & Japkowicz, 1994;
Koppel, Feldman, & Segre, 1994b; Mahoney & Mooney, 1994, 1993; Norton, 1994; Opitz &
Shavlik, 1994; Ortega, 1994; Ourston, 1991; Towell, Shavlik, & Noordewier, 1990; Shavlik,
Towell, & Noordewier, 1992). The original domain theory, as usually interpreted, is overly
specific in that it classifies all of the promoter sequences in the database as negative instances. Since the database consists of 53 positive instances and 53 negative instances, the
accuracy over this database is 50%. The learning systems cited above take advantage of
the initial domain theory in order to achieve higher accuracy rates, especially with fewer
training examples, than the rates achieved by purely inductive methods such as C4.5 and
backpropagation. Thus, the informativeness of this theory is acknowledged, despite its 50%
accuracy rate using a naive interpretation. However, the extent to which the theory is
informative is not easily ascertained; this is implicit in the interactions between each of the
learning algorithms and the theory. This note reports a simple change and reinterpretation
of the domain theory in terms of M-of-N concepts, which involve no learning, that results
in an accuracy of 93.4% on the 106 data items. Moreover, an exhaustive search of the space
of M-of-N interpretations reveals some that achieve 97.2% accuracy.

c 1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiOrtega

promoter

contact

conformation

minus_35

p-37=c
p-36=t
p-35=t
p-34=g
p-33=a
p-32=c

p-36=t
p-35=t
p-34=g
p-32=c
p-31=a

p-36=t
p-35=t
p-34=g
p-33=a
p-32=c
p-31=a

minus_10

p-36=t
p-35=t
p-34=g
p-33=a
p-32=c

p-14=t
p-13=a
p-12=t
p-11=a
p-10=a
p-9=t

p-13=t
p-12=a
p-10=a
p-8=t

p-13=t
p-12=a
p-11=t
p-10=a
p-9=a
p-8=t

p-12=t
p-11=a

p-7=t

p-47=c
p-46=a
p-45=a
p-43=t
p-42=t
p-40=a
p-39=c
p-22=g
p-18=t
p-16=c
p-8=g
p-7=c
p-6=g
p-5=c
p-4=c
p-2=c
p-1=c

p-45=a
p-44=a
p-41=a

p-49=a
p-44=t
0-27=t
p-22=a
p-18=t
p-16=t
p-15=g
p-1=a

p-45=a
p-41=a
p-28=t
p-27=t
p-23=t
p-21=a
p-20=a
p-17=t
p-15=t
p-4=a

Figure 1: DNA Promoters Theory

2. The DNA Promoter Sequences Database and Domain Theory
The sources of the UCI promoter sequences database and domain theory are described
by Towell (1990). The rules of the theory were derived from the biological research of
O'Neill (1989). The negative examples are contiguous strings from a long DNA sequence
believed not to contain promoters. The positive examples of promoters were taken from
the compilation of Hawley and McClure (1983). This database has been recently augmented (Harley & Reynolds, 1987; Lisser & Margalit, 1993) and new theories of promoter
action are still appearing (Lisser & Margalit, 1993). Nevertheless, the UCI promoter sequences database of examples and domain theory has remained a prominent testbed for
evaluating machine learning methods.
The DNA promoters domain theory obtained from the UCI repository is shown in
Figure 1 as an AND-OR tree. Each box at a leaf of the tree in Figure 1 is usually interpreted
as a conjunction of conditions. Each condition in a box requires that a particular nucleotide
appear at a particular position in the sequence. According to this theory, a DNA sequence
can be classified as a promoter if two regions of the DNA sequence can be identified. The
first region is called a contact, and the second a conformation. For a conformation region to
be identified, any one of the four specific nucleotide sequences shown at the right-hand side
of Figure 1 need to be present. For a contact region to be identified, both a minus 10 and
a minus 35 region also need to be identified. Again, for a minus 10 or a minus 35 region to
362

fiOn the Informativeness of the DNA Promoter Sequences Domain Theory

be identified, one of their respective four specific nucleotide sequences need to be present.
If a sequence is not classified as a promoter by the domain theory, then that sequence is
classified as negative (i.e., not a promoter).
As noted earlier, the promoters domain theory is coupled with a database of 106 items
in the UCI repository: 53 examples of promoters and 53 non-examples. When interpreting
each leaf of the domain theory as a logical conjunction, the theory classifies all of the data
items as negative. Thus, it is clearly too restrictive: No sequence in the database satisfies
all the conditions specified in the theory. Two pieces of domain knowledge suggest ways
to loosen the conditions of the domain theory. First, the conformation condition has very
weak biological support. This was implied by the initial KBANN experiments (Shavlik
et al., 1992), where none of the learned rules referenced the conformation conditions. In
addition, the EITHER system (Ourston, 1991) eliminated rules involving conformation
altogether from the domain theory. Eliminating conformation was also supported by a
domain expert (Ourston, 1991). The second piece of domain knowledge is that the concepts
in this domain tend to take the form of M-of-N concepts. Some of the final rules extracted
in the KBANN approach take this form. This was also made clear in the NEITHER-MofN
system (Baffes & Mooney, 1993), which added a mechanism to handle M-of-N concepts to
the original learning mechanism of the EITHER/NEITHER system.

3.

M-of-N

Interpretations of the DNA Promoters Theory

We can modify the original DNA domain theory as follows, and allow more sequences to be
positively classified as promoters: a) eliminate the conformation condition altogether from
the theory, and b) reinterpret the conjunctions of conditions in the leaves of Figure 1 as
M-of-N concepts. As usually interpreted, each of the leaves of Figure 1 is equivalent to a
concept of the form (N-of-N c1c2:::cN ). For example, the conjunction (p-37=c ^ p-36=t ^
p-35=t ^ p-34=g ^ p-33=a ^ p-32=c) of the leftmost leaf is logically equivalent to (6-of-6
p-37=c p-36=t p-35=t p-34=g p-33=a p-32=c).
Progressively less restrictive theories can be created by lowering the number of conditions
that need to be satisfied in each leaf of the theory. Thus, a new theory can be constructed
where each of the N-of-N concepts is substituted by (N { 1)-of-N, (N { 2)-of-N, etc. The
variable N (i.e., the number of conditions at a leaf) is decremented by a constant value i to
obtain the value M for each of the M-of-N concepts at the leaves of the theory. Figure 2
shows the accuracy of the theories constructed in this manner over all of the examples in the
database. As the number of conditions that have to be met for each of the M-of-N concepts is
lowered, the number of false negatives decreases, and the number of false positive increases.
The total number of misclassifications (false negatives plus false positives) is minimized
when each leaf is interpreted as a (N { 2)-of-N concept, resulting in an accuracy of 93.4%.
Even better accuracies can be obtained if we remove the constant decrement restriction.
That is, we allow greater exibility in choosing different values of M for each of the leaves
corresponding to the minus 35 and minus 10 regions in Figure 1. By an exhaustive search
through all of the 388800 possible combinations of M values we found twelve theories that
correctly classify 103 of the 106 examples in the database (i.e., the accuracy of these theories
is 97.2%), and 5148 theories of accuracy equal or better than 93.4%. Figure 3 shows the
probabilities of obtaining theories of different accuracies when the value of M for each of
363

fiOrtega

Correct
False
False
Percent
M-of-N criteria
Predictions Positives Negatives Accuracy
N-of-N (original theory)
53
0
53
50.00%
N-of-N w/ conformation rule removed
57
0
49
53.77%
(N { 1)-of-N
78
0
28
73.58%
(N { 2)-of-N
99
1
6
93.40%
(N { 3)-of-N
90
16
0
84.91%
(N { 4)-of-N
62
44
0
58.49%
Figure 2: Accuracy of DNA promoters theory under different M-of-N interpretations
0.06
P[accuracy]
0.05

Probability

0.04

0.03

0.02

0.01

0
0

0.2

0.4

0.6

0.8

1

Accuracy

Figure 3: Probability distribution of DNA-theory-interpretation accuracies
the contact leaves of Figure 1 is chosen at random (but under the restriction that M  N,
where N is the total number of conditions at a particular leaf). The probabilities in Figure 3
were computed by counting the total number of combinations of M values that produced
theories of specific accuracies. The mean accuracy of a randomly chosen theory is 76.5%,
with a standard deviation of 9.3%.
These results show that when leaves are interpreted as appropriate M-of-N concepts,
the existing DNA domain theory possesses a large amount of predictive information, a fact
that has also been pointed out by Koppel et al. (1994a). It is much better than the null
power suggested by its initial 50% accuracy, which would be equivalent to random guessing
with no theory at all. At the least, the theory allows us to make a single random guess of
an M-of-N interpretation with an expected accuracy of 76.5%. As shown in Figure 2 a few
random guesses allow us to do much better than that.
364

fiOn the Informativeness of the DNA Promoter Sequences Domain Theory

4. Learning with the DNA Promoters Theory

The accuracies of various systems that integrate analytical and empirical learning are around
93% (Baffes & Mooney, 1993). These results are typically means computed over multiple
trials with 80-85 training examples and 21-26 tests examples. Our reported accuracies of
93.4% and 97.2% are not based on such splits of training and test data. Instead, they
represent the maximum accuracies (relative to the database of 106 examples) that could be
obtained by learning algorithms with certain representational biases. For example, 93.4%
is the maximum accuracy that may be achieved by a learning system that identifies (N
{ i)-of-N concepts at the leaves, where i is constant across leaves. This approach can be
converted into a learning task where the learner identifies the optimal value of i given a set
of training examples, and evaluates the resultant classifier using a test set. The results of
this algorithm, averaged over 100 trials, produce mean accuracies of 88.7% with 10 training
examples, and 92.5% with 85 training examples (on a test set of 21 examples). These results
are similar to the best of the algorithms reported by Baffes and Mooney (1993).
Koppel et al. (1994a) also show that there is considerable information in a \reinterpreted" promoters domain theory. In their DOP (Degree of Provedness) classification
methodology, the logical operations of a propositional domain theory (AND, OR, or NOT)
are replaced by arithmetic equivalents that contain a degree of uncertainty. Rather than
directly returning a truth value indicating whether an example is positive, the system first
calculates the DOP numerical score for that example. If the DOP score value is greater
than a pre-specified threshold value, then the example is considered \suciently" proved
and thus classified as a positive example by the theory. Otherwise, the example is classified
as negative. Koppel et al. determine the threshold value with two pieces of knowledge: a)
the distribution of the DOP score over all examples, and b) the proportion (n%) of positive
examples in the database. The DOP values for all examples are sorted, so that the threshold
value can be set to the value that separates the n% of the examples with highest DOP values
from the rest. An important assumption is that the domain theory be of a certain proofadditive nature, so that DOP values will be higher for positive examples than for negative
examples. The DOP classification methodology achieves a high accuracy (92.5%) when applied to the DNA promoter sequences domain theory. As with our approach, this accuracy
is not based on a split of the available data into training and test sets, and represents an
upper bound on the accuracy that could be obtained if their method was converted into a
learning algorithm. The DOP classification methodology could be converted into a learning
algorithm by estimating the distribution of DOP values over a set of training examples.

5. Concluding Remarks

This note does not detail a new learning algorithm. Rather, it demonstrates that a suitable
learning model in the promoters domain is finding the correct number, M, for each of the
M-of-N concepts at the leaves of the original domain theory. 1 Assessing the diculty of
learning using the available theory is usually complicated by the need to understand the
learning algorithms that exploit the theory. The theory-accuracy distribution of Figure 3
1. Some algorithms may introduce some structural modification to the theory (i.e., add/delete clauses and
conditions). However, the increase in accuracy due to these structural modifications is negligible in the
case of the promoters domain, as illustrated by the high accuracies that can be obtained without them.

365

fiOrtega

helps characterize learning complexity in this domain (under the M-of-N model) and provides a dimension along which to evaluate the performance of learning algorithms that use
the DNA promoter's theory as their testbed.

Acknowledgements
This research was supported by a grant from NASA Ames Research Center (NAG 2-834) to
Doug Fisher. I am grateful for the suggestions of Doug Fisher, Stefanos Manganaris, Doug
Talbert, Jing Lin, as well as comments and pointers from Larry Hunter and anonymous
JAIR referees.

References

Baffes, P. T., & Mooney, R. J. (1993). Symbolic revision of theories with M-of-N rules. In
Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence
Chambery, France.
Harley, C. B., & Reynolds, R. P. (1987). Analysis of e. coli promoter sequences. Nucleic
Acids Research, 15 (5), 2343{2361.
Hawley, D. K., & McClure, W. R. (1983). Compilation and analysis of escherichia coli
promoter DNA sequences. Nucleic Acids Research, 11 (8), 2237{2255.
Hirsh, H., & Japkowicz, N. (1994). Boostraping training-data representations for inductive
learning: A case study in molecular biology. In Proceedings of the Twelfth National
Conference on Artificial Intelligence, pp. 639{644 Seattle, WA.
Koppel, M., Segre, A. M., & Feldman, R. (1994a). Getting the most from awed theories.
In Proceedings of the Eleventh International Conference on Machine Learning, pp.
139{147 New Brunswick, NJ.
Koppel, M., Feldman, R., & Segre, A. M. (1994b). Bias-driven revision of logical domain
theories. Journal of Artificial Intelligence Research, 1, 159{208.
Lisser, S., & Margalit, H. (1993). Compilation of e. coli mRNA promoter sequences. Nucleic
Acids Research, 21 (7), 1507{1516.
Mahoney, J. J., & Mooney, R. J. (1993). Combining connectionist and symbolic learning
to refine certainty-factor rule-bases. Connection Science, 5 (3{4), 339{364.
Mahoney, M. J., & Mooney, R. J. (1994). Comparing methods for refining certainty-factor
rule-bases. In Proceedings of the Eleventh International Conference on Machine Learning, pp. 173{180 New Brunswick, NJ.
Murphy, P. M., & Aha, D. W. (1992). UCI Repository of Machine Learning Databases.
Department of Information and Computer Science, University of California at Irvine,
Irvine, CA.
366

fiOn the Informativeness of the DNA Promoter Sequences Domain Theory

Norton, S. W. (1994). Learning to recognize promoter sequences in e. coli by modeling
uncertainty in the training data. In Proceedings of the Twelfth National Conference
on Artificial Intelligence, pp. 657{663 Seattle, WA.
O'Neill, M. C. (1989). Escherichia coli promoters I: Consensus as it relates to spacing class,
specificity, repeat structure, and three dimensional organization. Journal of Biological
Chemistry, 264, 5522{5530.
O'Neill, M. C., & Chiafari, F. (1989). Escherichia coli promoters II: A spacing-class dependent promoter search protocol. Journal of Biological Chemistry, 264, 5531{5534.
Opitz, D. W., & Shavlik, J. W. (1994). Using genetic search to refine knowledge-based
neural networks. In Proceedings of the Eleventh International Conference on Machine
Learning, pp. 208{216 New Brunswick, NJ.
Ortega, J. (1994). Making the most of what you've got: using models and data to improve learning rate and prediction accuracy. Tech. rep. TR-94-01, Computer Science
Dept., Vanderbilt University. Abstract appears in Proceedings of the Twelfth National
Conference on Artificial Intelligence, p. 1483, Seattle, WA.
Ourston, D. (1991). Using Explanation-Based and Empirical Methods in Theory Revision.
Ph.D. thesis, University of Texas, Austin, TX.
Shavlik, J. W., Towell, G., & Noordewier, M. O. (1992). Using neural networks to refine
existing biological knowledge. International Journal of Human Genome Research, 1,
81{107.
Towell, G. G. (1990). Symbolic Knowledge and Neural Networks: Insertion, Refinement,
and Extraction. Ph.D. thesis, University of Wisconsin, Madison, WI.
Towell, G. G., Shavlik, J. W., & Noordewier, M. O. (1990). Refinement of approximate
domain theories by knowledge-based neural networks. In Proceedings of the Eighth
National Conference on Artificial Intelligence, pp. 861{866 Boston, MA.

367

fiJournal of Artificial Intelligence Research 2 (1995) 475-500

Submitted 10/94; published 5/95

Adaptive Load Balancing: A Study in Multi-Agent
Learning
Andrea Schaerf

aschaerf@dis.uniroma1.it

Dipartimento di Informatica e Sistemistica
Universita di Roma \La Sapienza", Via Salaria 113, I-00198 Roma, Italy

Yoav Shoham

Robotics Laboratory, Computer Science Department
Stanford University, Stanford, CA 94305, USA

Moshe Tennenholtz

Faculty of Industrial Engineering and Management
Technion, Haifa 32000, Israel

shoham@flamingo.stanford.edu
moshet@ie.technion.ac.il

Abstract
We study the process of multi-agent reinforcement learning in the context of load balancing in a distributed system, without use of either central coordination or explicit communication. We first define a precise framework in which to study adaptive load balancing,
important features of which are its stochastic nature and the purely local information
available to individual agents. Given this framework, we show illuminating results on the
interplay between basic adaptive behavior parameters and their effect on system eciency.
We then investigate the properties of adaptive load balancing in heterogeneous populations,
and address the issue of exploration vs. exploitation in that context. Finally, we show that
naive use of communication may not improve, and might even harm system eciency.

1. Introduction
This article investigates multi-agent reinforcement learning in the context of a concrete
problem of undisputed importance { load balancing. Real life provides us with many examples of emergent, uncoordinated load balancing: trac on alternative highways tends to
even out over time; members of the computer science department tend to use the most powerful of the networked workstations, but eventually find the lower load on other machines
more inviting; and so on. We would like to understand the dynamics of such emergent
load-balancing systems and apply the lesson to the design of multi-agent systems.
We define a formal yet concrete framework in which to study the issues, called a multiagent multi-resource stochastic system, which involves a set of agents, a set of resources,
probabilistically changing resource capacities, probabilistic assignment of new jobs to agents,
and probabilistic job sizes. An agent must select a resource for each new job, and the
eciency with which the resource handles the job depends on the capacity of the resource
over the lifetime of the job as well as the number of other jobs handled by the resource over
that period of time. Our performance measure for the system aims at globally optimizing
the resource usage in the system while ensuring fairness (that is, a system shouldn't be made
ecient at the expense of any particular agent), two common criteria for load balancing.
c 1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiSchaerf, Shoham, & Tennenholtz

How should an agent choose an appropriate resource in order to optimize these measures?
Here we make an important assumption, in the spirit of reinforcement learning (Sutton,
1992): The information available to the agent is only its prior experience. In particular,
the agent does not necessarily know the past, present, or future capacities of the resources,1
and is unaware of past, current, or future jobs submitted by the various agents, not even
the relevant probability distributions. The goal of each agent is thus to adapt its resourceselection behavior to the behavior of the other agents as well as to the changing capacities
of the resources and to the changing load, without explicitly knowing what they are.
We are interested in several basic questions:

 What are good resource-selection rules?
 How does the fact that different agents may use different resource-selection rules affect
the system behavior?

 Can communication among agents improve the system eciency?
In the following sections we show illuminating answers to these questions. The contribution of this paper is therefore twofold. We apply multi-agent reinforcement learning to the
domain of adaptive load balancing and we use this basic domain in order to demonstrate
basic phenomena in multi-agent reinforcement learning.
The structure of this paper is as follows. In Section 2 we discuss our general setting.
The objective of this section is to motivate our study and point to its impact. The formal
framework is defined and discussed in Section 3. Section 4 completes the discussion of this
framework by introducing the resource selection rule and its parameters, which function as
the \control knobs" of the adaptive process. In Section 5 we present experimental results
on adaptive behavior within our framework and show how various parameters affect the
eciency of adaptive behavior. The case of heterogeneous populations is investigated in
Section 6, and the case of communicating populations is discussed in Section 7. In Section 8
we discuss the impact of our results. In Section 9 we put our work in the perspective of
related work. Finally, in Section 10 we conclude with a brief summary.

2. The General Setting

This paper applies reinforcement learning to the domain of adaptive load balancing. However, before presenting the model we use and our detailed study, we need to clarify several
points about our general setting. In particular, we need to explain the interpretation of
reinforcement learning and the interpretation of load balancing we adopt.
Much work has been devoted in the recent years to distributed and adaptive load balancing. One can find related work in the field of distributed computer systems (e.g., Pulidas,
Towsley, & Stankovic, 1988; Mirchandaney & Stankovic, 1986; Billard & Pasquale, 1993;
Glockner & Pasquale, 1993; Mirchandaney, Towsley, & Stankovic, 1989; Zhou, 1988; Eager,
Lazowska, & Zahorjan, 1986), in organization theory and management science (e.g., Malone,
1. In many applications the capacities of the resources are known, at least to some extent. This point will
be discussed later. Basically, in this paper we wish to investigate how far one can go using only purely
local feedback and without the use of any global information (Kaelbling, 1993; Sutton, 1992).

476

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

1987), and in distributed AI (e.g., Bond & Gasser, 1988). Although some motivations of
the above-mentioned lines of research are similar, the settings discussed have some essential
differences.
Work on distributed computer systems adopts the view of a set of computers each of
which controls certain resources, has an autonomous decision-making capability, and jobs
arrive to it in a dynamic fashion. The decision-making agents of the different computers
(also called nodes) try to share the system load and coordinate their activities by means of
communication. The actual action to be performed, based on the information received from
other computers, may be controlled in various ways. One of the ways adopted to control
the related decisions is through learning automata (Narendra & Thathachar, 1989).
In the above-mentioned work each agent is associated with a set of resources, where both
the agent and the related resources are associated with a node in the distributed system.
Much work in management science and in distributed AI adopts a somewhat complementary
view. In difference to classical work in distributed operating systems, an agent is not
associated with a set of resources that it controls. The agents are autonomous entities which
negotiate among themselves (Zlotkin & Rosenschein, 1993; Kraus & Wilkenfeld, 1991) on
the use of shared resources. Alternatively, the agents (called managers in this case) may
negotiate the task to be executed with the processors which may execute it (Malone, 1987).
The model we adopt has the avor of models used in distributed AI and organization
theory. We assume a strict separation between agents and resources. Jobs arrive to agents
who make decisions about where to execute them. The resources are passive (i.e., do not
make decisions). A typical example of such a setting in a computerized framework is a set
of PCs, each of which is controlled by a different user and submits jobs to be executed on
one of several workstations. The workstations are assumed to be independent of each other
and shared among all the users. The above example is a real-life situation which motivated
our study and the terminology we adopt is taken from such a framework. However, there
are other real-life situations related to our model in areas different from classical distributed
computer systems.
A canonical problem related to our model is the following one (Arthur, 1994): An agent,
embedded in a multi-agent system, has to select among a set of bars (or a set of restaurants).
Each agent makes an autonomous decision but the performance of the bar (and therefore of
the agents that use it) is a function of its capacity and of the number of agents that use it.
The decision of going to a bar is a stochastic process but the decision of which bar to use is
an autonomous decision of the respective agent. A similar situation arises when a product
manager decides which processor to use in order to perform a particular task. The model we
present in Section 3 is a general model where such situations can be investigated. In these
situations a job arrives to an agent (rather than to a node consisting of particular resources)
who decides upon the resource (e.g., restaurant) where his job should be executed; there is
a-priori no association between agents and resources.
We now discuss the way the agents behave in such a framework. The common theme
among the above-mentioned lines of research is that load-balancing is achieved by means
of communication among active agents or active resources (through the related decisionmaking agents). In our study we adopt a complementary view. We consider agents who
act in a purely local fashion, based on purely local information as described in the recent
reinforcement learning literature. As we mentioned, learning automata were used in the
477

fiSchaerf, Shoham, & Tennenholtz

field of distributed computer systems in order to perform adaptive load balancing. Nevertheless, the related learning procedures rely heavily on communication among agents (or
among decision-making agents of autonomous computers). Our work applies recent work
on reinforcement learning in AI where the information the agent gets is purely local. Hence,
an agent will know how ecient the service in a restaurant has been only by choosing it as a
place to eat. We don't assume that agents may be informed by other agents about the load
in other restaurants or that the restaurants will announce their current load. This makes
our work strictly different from other work applying reinforcement learning to adaptive load
balancing.
The above features make our model and study both basic and general. Moreover, the
above discussion raises the question of whether reinforcement learning (based on purely
local information and feedback) can guarantee useful load balancing. The combination of
the model we use and our perspective on reinforcement learning makes our contribution
novel. Nevertheless, as we mentioned above (and as we discuss in Section 9) the model we
use is not original to us and captures many known problems and situations in distributed
load balancing. We apply reinforcement learning, as discussed in the recent AI literature,
to that model and investigate the properties of the related process.

3. The Multi-Agent Multi-Resource Stochastic System

In this section we define the concrete framework in which we study dynamic load balancing.
The model we present captures adaptive load balancing in the general setting mentioned
in Section 2. We restrict the discussion to discrete, synchronous systems (and thus the
definition below will refer to N , the natural numbers); similar definitions are possible in
the continuous case. We concentrate on the case where a job can be executed using any of
the resources. Although somewhat restricting, this is a common practice in much work in
distributed systems (Mirchandaney & Stankovic, 1986).

Definition 3.1 A multi-agent multi-resource stochastic system is a 6-tuple hA; R; P ; D; C;
SRi, where A = fa1; : : :; aN g is a set of agents, R = fr1; : : :; rM g is a set of resources,
P : A  N ! [0; 1] is a job submission function, D : A  N ! < is a probabilistic job size
function, C : RN ! < is a probabilistic capacity function, and SR is a resource-selection
rule.

The intuitive interpretation of the system is as follows. Each of the resources has a
certain capacity, which is a real number; this capacity changes over time, as determined by
the function C . At each time point each agent is either idle or engaged. If it is idle, it may
submit a new job with probability given by P . Each job has a certain size which is also
a real number. The size of any submitted job is determined by the function D. (We will
use the unit token where referring to job sizes and resource capacities, but we do not mean
that tokens come only in integer quantities.) For each new job the agent selects one of the
resources. This choice is made according to the rule SR; since there is much to say about
this rule, we discuss it separately in the next section.
In our model, any job may run on any resource. Furthermore, there is no limit on the
number of jobs served simultaneously by a given resource (and thus no queuing occurs).
However, the quality of the service provided by a resource at a given time deteriorates with
478

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

the number of agents using it at that time. Specifically, at every time point the resource
distributes its current capacity (i.e., its tokens) equally among the jobs being served by it.
The size of each job is reduced by this amount and, if it drops to (or below) zero, the job is
completed, the agent is notified of this, and becomes idle again. Thus, the execution time
of a job j depends on its size, on the capacity over time of the resource processing it, and
on the number of other agents using that resource during the execution of j .
Our measure of the system's performance will be twofold: We aim to minimize timeper-token, averaged over all jobs, as well as to minimize the standard deviation of this
random variable. Minimizing both quantities will ensure overall system eciency as well as
fairness. The question is which selection rules yield ecient behavior; so we turn next to
the definition of these rules.

4. Adaptive Resource-Selection Rules
The rule by which agents select a resource for a new job, the selection rule (SR), is the
heart of our adaptive scheme and the topic of this section. Throughout this section and
the following one we make an assumption of homogeneity. Namely, we assume that all
the agents use the same SR. Notice that although the system is homogeneous, each agent
will act based only on its local information. In Sections 6 and 7 we relax the homogeneity
assumption and discuss heterogeneous and communicating populations.
As we have already emphasized, among all possible adaptive SRs we are interested in
purely local SRs, ones that have access only to the experience of the particular agent. In our
setting this experience consists of results of previous job submissions; for each job submitted
by the agent and already completed, the agent knows the name r of the resource used, the
point in time, tstart , the job started, the point in time, tstop , the job was finished, and the
job size S . Therefore, the input to the SR is, in principle, a list of elements in the form
(r; tstart; tstop ; S ). Notice that this type of input captures the general type of systems we
are interested in. Basically, we wish to assume as little as possible about the information
available to an agent in order to capture real loosely-coupled systems where more global
information is unavailable.
Whenever agent i selects a resource for its job execution, i may get its feedback after
non-negligible time, where this feedback may depend on decisions made by other agents
before and after agent i's decision. This forces the agent to rely on a non-trivial portion of
its history and makes the problem much harder.
There are uncountably many possible adaptive SRs and our aim is not to gain exhaustive understanding of them. Rather, we have experimented with a family of intuitive and
relatively simple SRs and have compared them with some non-adaptive ones. The motivation for choosing our particular family of SRs is partially due to observations made by
cognitive psychologists on how people tend to behave in multi-agent stochastic and recurrent situations. In principle, our set of SRs captures the two most robust aspects of these
observations: \The law of effect" (Thronkide, 1898) and the \Power law of practice" (Blackburn, 1936). In our family of rules, called 
, which partially resembles the learning rules
discussed in the learning automata literature (Narendra & Thathachar, 1989), and partially resembles the interval estimation algorithm (Kaelbling, 1993), agents do not maintain
complete history of their experience. Instead, each agent, A, condenses this history into
479

fiSchaerf, Shoham, & Tennenholtz

a vector, called the eciency estimator, and denoted by eeA . The length of this vector is
the number of resources, and the i'th entry in the vector represents the agent's evaluation
of the current eciency of resource i (specifically, eeA (R) is a positive real number). This
vector can be seen as the state of a learning automaton. In addition to eeA , agent A keeps
a vector jdA, which stores the number of completed jobs which were submitted by agent A
to each of the resources, since the beginning of time. Thus, within 
, we need only specify
two elements:
1. How agent A updates eeA when a job is completed
2. How agent A selects a resource for a new job, given eeA and jdA
Loosely speaking, eeA will be maintained as a weighted sum of the new feedback and the
previous value of eeA , and the resource selected will most probably be the one with highest
eeA entry except that with low probability some other resource will be chosen. These two
steps are explained more precisely in the following two subsections.

4.1 Updating the Eciency Estimator
We take the function updating eeA to be

eeA (R) := WT + (1 , W )eeA (R)
where T represents the time-per-token of the newly completed job and is computed from
the feedback (R; tstart; tstop; S ) in the following way:2

T = (tstop , tstart)=S
We take W to be a real value in the interval [0; 1], whose actual value depends on jdA(R).
This means that we take a weighted average between the new feedback value and the old
value of the eciency estimator, where W determines the weights given to these pieces of
information. The value of W is obtained from the following function:

W = w + (1 , w)=jdA(R)
In the above formula w is a real-valued constant. The term (1 , w)=jdA(R) is a correcting
factor, which has a major effect only when jdA (R) is low; when jdA (R) increases, reaching
a value of several hundreds, this term becomes negligible with respect to w.

4.2 Selecting the Resource

The second ingredient of adaptive SRs in 
 is a function pdA selecting the resource for a
new job based on eeA and jdA . This function is probabilistic. We first define the following
function
(
if jdA(R) > 0
A (R),n
0
pdA(R) := ee
,
n
E [ee ]
if jd (R) = 0
A

A

2. Using parallel processing terminology, T can be viewed as a stretch factor, which quantifies the stretching
of a program's processing time due to multiprogramming (Ferrari, Serazzi, & Zeigner, 1983).

480

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

where n is a positive real-valued parameter and E [eeA] represents the average of the values
of eeA (R) over all resources satisfying jdA (R) > 0. To turn this into a probability function,
we define the pdA as the normalized version of pd0A :

pdA(R) := pd0A(R)=
where  = Rpd0A (R) is a normalization factor.3
The function pdA clearly biases the selection towards resources that have performed
well in the past. The strength of the bias depends on n; the larger the value of n, the
stronger the bias. In extreme cases, where the value of n is very high (e.g.,  20), the agent
will always choose the resource with the best record. This strategy of \always choosing
the best", although perhaps intuitively appealing, is in general not a good one; it does not
allow the agent to exploit improvements in the capacity or load on other resources. We
discuss this SR in the following subsection, and expand on the issue of exploration versus
exploitation in Sections 6 and 7.
To summarize, we have defined a general setting in which to investigate emergent load
balancing. In particular, we have defined a family of adaptive resource-selection rules,
parameterized by a pair (w; n). These parameters serve as knobs with which we tune the
system so as to optimize its performance. In the next section we turn to experimental
results obtained with this system.

4.3 The Best Choice SR (BCSR)

The Best Choice SR (BCSR) is a learning rule that assumes a high value of n, i.e, which
always chooses the best resource in a given point. We will assume w is fixed to a given
value while discussing BCSR. In our previous work (Shoham & Tennenholtz, 1992, 1994),
we showed that learning rules that strongly resemble BCSR are useful for several natural
multi-agent learning settings. This suggests that we need to carefully study it in the case
of adaptive load balancing. As we will demonstrate, BCSR is not always useful in the load
balancing setting.
The difference between BCSR and a learning rule where the value of n is low, is that
in the latter case the agent gives relatively high probability for the selection of a resource
that didn't give the best results in the past. In that case the agent might be able to notice
that the behavior of one of the resources has been improved due to changes in the system.
Note that the exploration of \non-best" resources is crucial when the dynamics of the
system includes changes in the capacities of the resources. In such cases, the agent could not
take advantage of possible increases in the capacity of resources if it uses the BCSR. One
might wonder, however, whether in cases where the main dynamic changes of the system
stem from load changes, relying on BCSR is sucient. If the latter is true, we will be
able to ignore the parameter n and to concentrate only on the BCSR, in systems where
the capacity of resources is fixed. In order to clarify this point, we consider the following
example.
3. If for all R we have jdA (R) = 0, (i.e., if the agent is going to submit its very first job), then we assume
the agent chooses a resource randomly (with a uniform probability distribution).

481

fiSchaerf, Shoham, & Tennenholtz

Suppose there are only two resources, R1 and R2 , whose respective (fixed) capacities,
cR1 and cR2 , satisfy the equality cR1 = 2cR2 . Assume now that the load of the system varies

between a certain low value and a certain high one.
If the system's load is low and the agents adopt BCSR, then the system will evolve in
a way where almost all of the agents would be preferring R1 to R2. This is due to the
fact that, in the case of low load, there are only few overlaps of jobs, hence R1 is much
more ecient. On the other hand, when the system's load is high, R1 could be very busy
and some of the agents would then prefer R2, since the performance obtained using the
less crowded resource R2 could be better than the one obtained using the overly crowded
resource R1. In the extreme case of a very high load, we expect the agents to use R2 one
third of the time.
Assume now that the load of the system starts from a low level, then increases to a
high value, and then decreases to reach its original value. When the load increases, the
agents, that were mostly using R1, will start observing that R1's performance is becoming
worse and, therefore, following the BCSR they will start using R2 too. Now, when the load
decreases, the agents which were using R2 will observe an improvement in the performance
of R2, but the value they have stored for R1 (i.e., eeA (1)), will still reect the previous
situation. Hence, the agents will keep on using R2, ignoring the possibility of obtaining
much better results if they moved back to R1. In this situation, the randomized selection
makes the agents able to use R1 (with a certain probability) and therefore some of them
may discover that the performance of R1 is better than that of R2 and switch back to R1.
This will improve the system's eciency in a significant manner.
The above example shows that the BCSR is, in the general case, not a good choice.
This is in general true when the value of n is too high.
In the above discussion we have assumed that the changes in the load are unforeseen. If
we are able to predict the changes in the load, the agents can simply use the BCSR while
the load is fixed and then use a low value of n during the changes. In our case, instead,
without even realizing that the system has changed in some way, the agents would need to
(and, as we will see, would be able to) adapt to dynamic changes as well as to each other.

5. Experimental Results
In this section we compare SRs in 
 to each another, as well as to some non-adaptive,
benchmark selection rules.
The non-adaptive SRs we consider in this paper are those in which the agents partition
themselves according to the capacities and the load of the system in a fixed predetermined
manner and each agent uses always the same resource. Later in the paper, a SR of this
kind is identified by a configuration vector, which specifies, for each resource, how many
agents use it. When we test our adaptive SRs, we compare the performance against the nonadaptive SRs that perform best on the particular problem. This creates a highly competitive
set of benchmarks for our adaptive SRs.
In addition, we compare our adaptive SRs to the load-querying SR which is defined as
follows: Each agent, when it has a new job, asks all the resources how busy they are and
always chooses the less crowded one.
482

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

5.1 An Experimental Setting
We now introduce a particular experimental setting, in which many of the results described
below were obtained. We present it in order to be concrete about the experiments; however,
the qualitative results of our experiments were observed in a variety of other experimental
settings.
One motivation of our particular setting stems from the PCs and workstations problem
mentioned in Section 2. For example, part of our study is related to a set of computers
located at a single site. These computers have relatively high load with some peak hours
during the day and a low load at night (i.e., the chances a user of a PC submits a job
is higher during the day time of the week days than at night and on weekend). Another
part of our study is related to a set of computers split all around the world, where the
load has quite random structure (i.e., due to difference in time zones, users may use PCs in
unpredictable hours).
Another motivation of our particular setting stems from the restaurant problem mentioned in Section 2 (for discussion on the related \bar problem" see Arthur, 1994). For
example, we can consider a set of snack bars located at an industrial park. These snack
bars have relatively high loads with some peak hours during the day and low load at night
(i.e., the chances an employee will choose to go to a snack-bar is higher during the day
because there are more employees present during the day). Conversely, we can assume a
set of bars near an airport where the load has quite random structure (i.e., the airport
employees may like to use these snack-bars in quite unpredicted hours).
Although these are particular real-situations, we would like to emphasize the general
motivation of our study and the fact that the related phenomena have been observed in
various different settings.
We take N , the number of agents, to be 100, and M , the number of resources, to be
5. In the first set of experiments we take the capacities of the resources to be fixed. In
particular, we take them to be c1 = 40; c2 = 20; c3 = 20; c4 = 10; c5 = 10. We assume
that all agents have the same probability of submitting a new job. We also assume that all
agents have the same distribution over the size of jobs they submit; specifically, we assume
it to be a uniform distribution over the integers in the range [50,150].
For ease of exposition, we will assume that each point in time corresponds to a second,
and we consequently count the time in minutes, hours, days, and weeks. The hour is our
main point of reference; we assume, for simplicity, that the changes in the system (i.e., load
change and capacity change) happen only at the beginning of a new hour. The probability
of submitting a job at each second, which corresponds to the load of the system, can vary
over time; this is the crucial factor to which the agents must adapt. Note that agents can
submit jobs at any second, but the probability of such submission may change. In particular
we concentrate on three different values of this quantity, called Llo ; Lhi and Lpeak , and we
assume that the system load switches between those values. The actual values of Llo ; Lhi and
Lpeak in the following quantitative results are 0:1%, 0:3% and 1%, which roughly correspond
to each agent submitting 3.6, 10.8, and 36 jobs per hour (per agent) respectively.
483

fiSchaerf, Shoham, & Tennenholtz

load

configuration
time-per-token
Llo
f100; 0; 0; 0; 0g
38.935
Lhi
f66; 16; 16; 1; 1g
60.768
Lpeak f40; 20; 20; 10; 10g
196.908
Figure 1: Best non-adaptive SRs for fixed load
In the following, when measuring success, we will refer only to the average time-pertoken.4 However, the adaptive SRs that give the best average time-per-token were also
found to be fair.

5.2 Fixed Load

We start with the case in which the load is fixed. This case is not the most interesting for
adaptive behavior; however, a satisfactory SR should show reasonably ecient behavior in
that basic case, in order to be useful when the system stabilizes.
We start by showing the behavior of non-adaptive benchmark SRs in the case of fixed
load.5 Figure 1 shows those that give the best results, for each of the three loads.
As we can see, there is a big difference between the three loads mentioned above. When
the load is particularly high, the agents should scatter around all the resources at a rate
proportional to their capacities; when the load is low they should all use the best resource.
Given the above, it is easy to see that an adaptive SR can be effective only if it enables
moving quickly from one configuration to the other.
In a static setting such as this, we can expect the best non-adaptive SRs to perform better than adaptive ones, since the information gained by the exploration of the adaptive SRs
can be built-in in the non-adaptive ones. The experimental results confirm this intuition,
as shown in Figure 2 for Lhi . The figure shows the performance obtained by the population
when the value of n varies between 2 to 10 and for three values of w: 0.1, 0.3, and 0.5.
Note that for the values of (n; w) that are good choices in the dynamic cases (see later in
the paper, values in the intervals [3; 5] and [0:1; 0:5], respectively), the deterioration in the
performance of the adaptive SRs with respect to the non-adaptive ones is small. This is an
encouraging result, since adaptive SRs are meant to be particularly suitable for dynamic
systems. In the following subsections we see that indeed they are.

5.3 Changing Load

We now begin to explore more dynamic settings. Here we consider the case in which the
load on the system (that is, the probability of agents submitting a job at any time) changes
over time. In this paper we present two dynamic settings: One in which the load changes
according to a fixed pattern with only a few random perturbations and another in which the
load varies in some random fashion. Specifically, in the first case we fix the load to be Lhi
4. In the data shown later we refer, for convenience, to the time for 1000 tokens.
5. The non-adaptive SRs are human-designed SRs that are used as benchmarks; they assume knowledge of
the load and capacity, which is not available for the adaptive SRs we design.

484

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

A
v
e
r
a
g
e
T
i
m
e
p
e
r
T
o
k
e
n

6
67





 Weight: w = 0.5
Weight: w = 0.3
 Weight: w = 0.1

66





65
64





63
62
61
2



 

 


 


















3
4 5
6 7
8
9 10
Exponent of the Randomization Function: n

-

Figure 2: Performance of the adaptive Selection Rules for fixed load
for ten consecutive hours, for five days a week, with two randomly chosen hours in which
it is Lpeak , and to be Llo for the rest of the week. In the second case, we fix the number
of hours in a week for each load as in the first case, and we distribute them completely
randomly in a week.
The results obtained for the two cases are similar. Figure 3 shows the results obtained
by the adaptive SRs in the case of random load. The best non-adaptive deterministic
SR gives the time-per-token value of 69:201 obtained with the configuration (partition of
agents) f52; 22; 22; 2; 2g; the adaptive SRs are superior. The load-querying SR instead gets
the time-per-token value of 48:116, which is obviously better, but is not so far from the
performances of the adaptive SRs.
We also observe the following phenomenon: Given a fixed n (resp. a fixed w) the average
time-per-token is non-monotonic in w (resp. in n). This phenomenon is strongly related to
the issue of exploration versus exploitation mentioned before and to phenomena observed
in the study of Q-learning (Watkins, 1989).
We also notice how the two parameters n and w interplay. In fact, for each value of
w the minimum of the time per token value is obtained with a different value of n. More
precisely, the higher w is the lower n must be in order to obtain the best results. This means
that, in order to obtain high performance, highly exploratory activity (low n) should be
matched with giving greater weight to the more recent experience (high w). This \parameter
485

fiSchaerf, Shoham, & Tennenholtz

A
v
e
r
a
g
e
T
i
m
e
p
e
r
T
o
k
e
n

6
71
70
69


 Weight: w = 0.5




Weight: w = 0.3
 Weight: w = 0.1













68



 

    






67
66
65
2













3
4 5
6 7
8
9 10
Exponent of the Randomization Function: n

-

Figure 3: Performance of the adaptive Selection Rules for random load
matching" can be intuitively explained in the following qualitative way: The exploration
activity pays because it allows the agent to detect changes in the system. However, it is
more effective if, when a change is detected, it can significantly affect the eciency estimator
(i.e., if w is high). Otherwise, the cost of the exploration activity is greater than its gain.

5.4 Changing Capacities
We now consider the case in which the capacity of the resources can vary over time. In
particular, we will demonstrate our results in the case of the previously mentioned setting.
We will assume the capacities rotate randomly among the resources and, in five consecutive
days, each resource gets the capacity of 40 for one day, 20 for 2 days, and 10 for the other
2 days.6 The load also varies randomly.
The results of this experiment are shown in Figure 4. The best non-adaptive SR
in this case gives the time-per-token value of 118:561 obtained with the configuration
f20; 20; 20; 20; 20g.7 The adaptive SRs give much better results, which are only slightly
6. Usually the capacities will change in a less dramatic fashion. We use the above-mentioned setting in
order to demonstrate the applicability of our approach under severe conditions.
7. The load-querying SR gives the same results as in the case of fixed capacities, because such SR is
obviously not inuenced by the change.

486

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

A
v
e
r
a
g
e
T
i
m
e
p
e
r
T
o
k
e
n

6




92.5




90





87.5



82.5

    




80




85

77.5



2








 Weight: w = 0.5

Weight: w = 0.3
 Weight: w = 0.1




-

3
4
5
6 7 8
9 10
Exponent of the Randomization Function: n

Figure 4: Performance of the adaptive Selection Rules for changing capacities
worse than in the case of fixed capacities. The phenomena we mentioned before are visible
in this case too. See for example how a weight of 0:1 mismatches with the low values of n.

6. Heterogeneous Populations
Throughout the previous section we have assumed that all the agents use the same SR, i.e.
Homogeneity Assumption. Such assumption models the situation in which there is a sort
of centralized off-line controller which, in the beginning, tells the agents how to behave and
then leaves the agents to make their own decisions.
The situation described above is very different from having an on-line centralized controller which makes every decision. However, we would like now to move even further from
that and investigate the situation in which each agent is able to make its own decision about
which strategy to use and, maybe, adjust it over time.
As a step toward the study of systems of this kind, we drop the Homogeneity Assumption
and consider the situation in which part of the population uses one SR and the other part
uses a second one.
In the first set of experiments, we consider the setting discussed in Subsection 5.1 and
we confront one with the other, two populations (called 1 and 2) of the same size (50 agents
each). Each population uses a different SR in 
. The SR of population i (for i = 1; 2) will
487

fiSchaerf, Shoham, & Tennenholtz



A
v
e
r
a
g
e
T
i
m
e
p
e
r
T
o
k
e
n

6



67
66



65























63
61





 


  

64
62


 : T1
 : T2



2 3
4 5
6 7
8
9 10
Exponent of the Randomization Function (n2 )

-

Figure 5: Performance of 2 populations of 50 agents with n1 = 4 and w1 = w2 = 0:3
be determined by the pair of parameters (wi; ni ). The measure of success of population i
will be defined as the average time-per-token of its members, and will be denoted by Ti .
Figure 5 shows the result obtained for w1 = w2 = 0:3, and n1 = 4, and for different
values of n2 , in the case of randomly varying load.
Our results expose the following phenomenon: The two populations obtain different
outcomes from the ones they obtain in the homogeneous case. More specifically, for 4 
n2  6 , the results obtained by the agents which use n2 are generally better than the results
obtained by the ones which use n1 , despite the fact that an homogeneous population which
uses n1 gets better results than an homogeneous population which uses n2 .
The phenomenon described above has the following intuitive explanation. For n2 in
the above-mentioned range, the population which uses n2 is less \exploring" (i.e., more
\exploiting") than the other one, and when it is left on its own it might not be able to
adapt to the changes in a satisfactory manner. However, when it is joined with the other
population, it gets the advantages of the experimental activity of agents in that population,
without paying for it. In fact, the more exploring agents, in trying to unload the most
crowded resources, make a service to the other agents as well.
It is worth observing in Figure 5 that when n2 is low (e.g., n2  3) the agents that use
n2 take the role of explorers and lose a lot, while the agents that use n1 gain from that
situation. Conversely, for high values of n2 (e.g., n2  7) the performances of the exploiters,
488

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

A
v
e
r
a
g
e
T
i
m
e
p
e
r
T
o
k
e
n



6
67
66



65


 : T1
 : T2

 





 


64
63
62










61
2
















3
4 5
6 7
8
9 10
Exponent of the Randomization Function: n2

-

Figure 6: Performance of 2 populations of 90/10 agents with n1 = 4 and w1 = w2 = 0:3
which use n2 , deteriorate. This means that if the exploiters are too static, then they hinder
each other, and the explorers can take advantage of it.
For a better understanding of the phenomena involved, we have experimented with an
asymmetric population, composed of one large group and one small one, instead of two
groups of similar size. Figure 6 shows the results obtained using a setting similar to the
one above, but where population 1 is composed of 90 members while population 2 consists
of only 10 members. In this case, for every value of n2  4, the exploiters do better than
the explorers. The experiments also show that in this case, the higher n2 is the better T2
is, i.e. the more the exploiters exploit, the more they gain.
The above results suggest that a single agent gets the best results for itself by being noncooperative and always adopting the resource with the best performance (i.e., use BCSR),
given that the rest of the agents use an adaptive (i.e., cooperative) SR. However, if all of
the agents are non-cooperative then all of them will lose.8 In conclusion, the selfish interest
of an agent does not match with the interest of the population. This is contrary to results
obtained in other basic contexts of multi-agent learning (Shoham & Tennenholtz, 1992).
What we have shown is how, for a fixed value of w, coexisting populations adopting
different values of n interact. Similar results are obtained when we fix the value of n and
8. This is in fact an illuminating instance of the well-known prisoners dilemma (Axelrod, 1984).

489

fiSchaerf, Shoham, & Tennenholtz

A
v
e
r
a
g
e
T
i
m
e
p
e
r
T
o
k
e
n

6
67




 : T1
 : T2

66
65
64




















63

























62
61

-

0.01 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
Weight of the estimator parameter (w2)

1

Figure 7: Performance of 2 populations of 50 agents with n1 = n2 = 4 and w1 = 0:3
use two different values for w. In such cases, the agents adopting the lower value of w are
in general the winners, as shown in Figure 7 for n1 = n2 = 4 and w1 = 0:3. When w is very
low then the corresponding agents get poor results and they are no longer the winners, as
in the case of very high n in Figure 5.
Another interesting phenomenon is obtained when confronting adaptive agents with
load-querying agents. Load-querying agents are agents who are able to consult the resources
about where they should submit their jobs. A load-querying agent will submit its job to the
most unloaded resource at the given point. When confronting load-querying agents with
adaptive ones, the results obtained by the adaptive agents are obviously worse than the
results obtained by the load-querying ones, but are better than the results obtained by a
complete population of adaptive agents. This means that load-querying agents do not play
the role of \parasites", as the above-mentioned \exploiters"; the load-querying agents help
in maintaining the load balancing among the resources, and therefore help the rest of the
agents. Another result we obtain is that agents who adopt deterministic SRs may behave
as parasites and worsen the performance of adaptive agents.
These assertions are supported by the experiments described in Figure 8, where a population of 90 agents, each of which uses an adaptive SR with parameters (n; w), is faced with
a minority of 10 agents which use different SRs, as stated above. In particular, in the four
cases we consider, the minority behaves in the following ways: (i) they choose the resource
490

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

90 agents
10 agents
T1
(.3,4)
(.3,20)
65.161
(.3,4)
(.1,4)
64.630
(.3,4) Load-querying 62.320
(.3,4)
Using Res. 0 65.499

T2

59.713
63.818
47.236
55.818

Figure 8: Performance of 2 populations of 90/10 agents with various SRs
which gave best results, (ii) they are very conservative in updating the history, (iii) they
are load-querying agents, (iiii) they all use deterministically the resource with capacity 40
(in our basic experimental setting).

7. Communication among Agents
Up to this point, we have assumed that there is no direct communication among the agents.
The motivation for this was that we considered situations in which there were absolutely
no transmission channels and protocols. This assumption is in agreement with the idea of
multi-agent reinforcement learning. In systems where massive communication is feasible
we are not so much concerned with multiple agent adaptation, and the problem reduces to
supplying satisfactory communication mechanisms. Multi-agent reinforcement learning is
most interesting where real life forces agents to act without a-priori arranged communication channels and we must rely on action-feedback mechanisms. However, it is of interest to
understand the effects of communication on the system eciency (as in Shoham & Tennenholtz, 1992; Tan, 1993), where the agents are augmented with some sort of communication
capabilities. Our study of this extension led to some illuminating results, which we will now
present.
We assume that each agent can communicate only with some of the other agents, which
we call its neighbors. We therefore consider a relation neighbor-of and assume it is reexive, symmetric and transitive. As a consequence, the relation neighbor-of partitions the
population into equivalence classes, that we call neighborhoods.
The form of communication we consider is based on the idea that the eciency estimators of agents within a neighborhood will be shared among them when a decision is made
(i.e., when an agent chooses a resource). The reader should notice that this is a naive
form of communication and that more sophisticated types of communication are possible.
However, the above form of communication is most natural when we concentrate on agents
that update their behavior based only on past information. In particular, this type of
communication is similar to the ones used in the above-mentioned work on incorporating
communication into the framework of multi-agent reinforcement learning.
We suppose that different SRs may be used by different agents in the same population,
but we impose the condition that within a single neighborhood, the same SR is used by all
its members.
We also assume that each agent keeps its own history and updates it by itself in the
usual way. The choice, instead, is based not only on the agent eciency estimator, but on
491

fiSchaerf, Shoham, & Tennenholtz

A
v
e
r
a
g
e
T
i
m
e
p
e
r
T
o
k
e
n

6
71
70














68





67



66

 

65
2














69









  






 : 5 CNs of 20 agents
: 20 CNs of 5 agents
 : 50 CNs of 2 agents

3
4 5
6 7
8
9 10
Exponent of the Randomization Function: n

-

Figure 9: Performance of the adaptive Selection Rules for random load profile for communicating agents
the average of the eciency estimators of the agents in the corresponding neighborhood.
Such average is called the neighborhood eciency estimator. The neighborhood eciency
estimator has no physical storage: Its value is recalculated each time a member needs it.
In order to compare the behavior of communicating agents and non-communicating ones,
we assume that in a single population there might be, aside from the neighborhoods defined
above, also some neighborhoods that do not allow the sharing of eciency estimators among
its members. The members of these neighborhoods behave as described in the previous
sections, i.e., each agent relies only on its own history. The only thing that is common
among the members of such a neighborhood is that all its members use the same SR.
We call communicating neighborhood (CN), a neighborhood in which the eciency estimators are shared when a decision is taken and non-communicating neighborhood (NCN),
a neighborhood in which this is not done.
The first set of experiments we ran, regards a population composed of only CNs, all
of the same size. In particular, we considered CNs of various sizes, starting from 50 CNs
of size 2, going to 5 CNs of size 20. The load profile exploited is the random load change
defined in Subsection 5.3, the value of w is taken to be 0:3, and n is taken to have various
values. The results obtained are shown in Figure 9.
492

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

The results show that such communicating populations do not get good results. The
reason for this is that members of a CN tend to be very conservative, in the sense that they
mostly use the best resource. In fact, since they rely on an average of several agents, the
picture they have of the system tends to be much more static. In particular, the bigger is
the CN the more conservative its members tend to be. For example, consider the values of
(n; w) that give the best results for non-communicating agents, those values give quite bad
performance for CNs since they turn to be too conservative.
Using more adaptive values of (n; w), the behavior of a communicating population improves and reaches a performance that is just slightly worse than the performance of a
non-communicating population. Tuning the parameters using a finer grain, it is possible to
obtain a performance that is equal to the one obtained by a non-communicating population.
However, it seems clear that no obvious gain is achieved from this form of communication
capability. The intuitive explanation is that there are two opposite effects caused by the
communication. On the one hand, the agents get a fairer picture of the system which prevents them from using bad resources and therefore getting bad performance. On the other
hand, since all of the agents in a CN have a \better" picture of the system, they all tend
to use the best resources and thus they all compete for them. In fact, the agents behave
selfishly and their selfish interest may not agree with the interest of the population as a
whole.
The interesting message that we get is that the fact that some agents may have a
\distorted" picture of the system (which is typical for non-communicating populations),
turns out to be an advantage for the population as a whole.
Sharing the data among agents leads to poorer performances also because in this case
the agents have common views of loads and target jobs toward the same (lightly loaded)
resources, which quickly become overloaded. In order to profitably use the shared data,
we should allow for some form of reasoning about the fact that the data is shared. This
problem however is out of the scope of this paper (see e.g., Lesser, 1991).
In order to understand the behavior of the system when CNs and NCNs face each other,
we consider an NCN of 80 agents together with a set of CNs of equal size, for different values
of that size. The results of the corresponding experiments are shown in Figure 10. The
members of the CNs, being more inclined to use the best resources, behave as parasites in
the sense explained in Section 6. They exploit the adaptiveness of the rest of the population
to obtain good performance from the best resources. For this reason they get better results
than the rest of the population, as shown by the experimental results.
It it interesting to observe that when the NCN uses a very conservative selection rule,
the CNs obtain even better results. The intuitive explanation for this behavior is that
although all groups, i.e., both the communicating ones and the one with high value of n,
tend to be conservative, the communicating ones \win" because they are conservative in a
more \clever" way, that is making use of a better picture of the situation.
The conclusion we draw in this section is that the proposed form of communication
between agents may not provide useful means to improve the performance of a population
in our setting. However, we do not claim that communication between agents is completely
useless. Nevertheless, we have observed that it does not provide a straightforward significant
improvement. Our results support the claim that the sole past history of an agent is a
493

fiSchaerf, Shoham, & Tennenholtz

80 agents
(.3,4) 1 NCN
(.3,4) 1 NCN
(.3,4) 1 NCN
(.3,4) 1 NCN
(.3,10) 1 NCN
(.3,10) 1 NCN
(.3,10) 1 NCN
(.3,10) 1 NCN

20 agents
(.3,4) 1 CN
(.3,4) 2 CNs
(.3,4) 5 CNs
(.3,4) 10 CNs
(.3,4) 1 CN
(.3,4) 2 CNs
(.3,4) 5 CNs
(.3,4) 10 CNs

T1

65.287
65.069
65.091
64.895
68.419
68.319
68.529
68.351

T2

63.054
63.307
62.809
63.840
60.018
59.512
60.674
61.711

Figure 10: Performance of CNs and NCNs together
reasonable information on which to base its decision, assuming we do not consider available
any kind of real-time information (e.g., current load of the resources).

8. Discussion
The previous sections were devoted to a report on our experimental study. We now synthesize our observations in view of our motivation, as discussed in Sections 1 and 2.
As we mentioned, our model is a general model where active autonomous agents have
to select among several resources in a dynamic fashion and based on local information.
The fact that the agents use only local information makes the possibility of ecient loadbalancing questionable. However, we showed that adaptive load balancing based on purely
local feedback is a feasible task. Hence, our results are complementary to the ones obtained
in the distributed computer systems literature. As Mirchandaney and Stankovic (1986) put
it: \: : : what is significant about our work is that we have illustrated that is possible to design
a learning controller that is able to dynamically acquire relevant job scheduling information
by a process of trial and error, and use that information to provide good performance."
The study presented in our paper supplies a complementary contribution where we are able
to show that useful adaptive load balancing can be obtained using purely local information
and in the framework of a general organizational-theoretic model.
In our study we identified various parameters of the adaptive process and investigated
how they affect the eciency of adaptive load balancing. This part of our study supplies
useful guidelines for a systems designer who may force all the agents to work based on a
common selection rule. Our observations, although somewhat related to previous observations made in other contexts and models (Huberman & Hogg, 1988), enable to demonstrate
aspects of purely local adaptive behavior in a non-trivial model.
Our results about the disagreement between selfish interest of agents and the common
interest of the population is in sharp contrast to previous work on multi-agent learning
(Shoham & Tennenholtz, 1992, 1994) and to the dynamic programming perspective of
earlier work on distributed systems (Bertsekas & Tsitsiklis, 1989). Moreover, we explore
how the interaction between different agent types affects the system's eciency as well as
494

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

the individual agent's eciency. The related results can be also interpreted as guidelines
for a designer who may have only partial control of a system.
The synthesis of the above observations teaches us about adaptive load balancing when
one adopts a reinforcement learning perspective where the agents rely only on their local
information and activity. An additional step we performed attempts to bridge some of the
gap between our local view and previous work on adaptive load balancing by communicating
agents, whose decisions may be controlled by learning automata or by other means. We
therefore rule out the possibility of communication about the current status of resources
and of joint decision-making, but enable a limited sharing of previous history. We show
that such limited communication may not help, and even deteriorate system eciency. This
leaves us with a major gap between previous work where communication among agents is the
basic tool for adaptive load balancing and our work. Much is left to be done in attempting
to bridge this gap. We see this as a major challenge for further research.

9. Related Work
In Section 2 we mentioned some related work in the field of distributed computer systems
(Mirchandaney & Stankovic, 1986; Billard & Pasquale, 1993; Glockner & Pasquale, 1993;
Mirchandaney et al., 1989; Zhou, 1988; Eager et al., 1986). A typical example of such work
is the paper by Mirchandaney and Stankovic (1986). In this work learning automata are
used in order to decide on the action to be taken. However, the suggested algorithms heavily
rely on communication and information sharing among agents. This is in sharp contrast
to our work. In addition, there are differences between the type of model we use and the
model presented in the above-mentioned work and in other work on distributed computer
systems.
Applications of learning algorithms to load balancing problems are given by Mehra
(1992), Mehra and Wah (1993). However, in that work as well, the agents (sites, in the
authors' terminology) have the ability to communicate and to exchange workload values,
even though such values are subject to uncertainty due to delays. In addition, differently
from our work, the learning activity is done off-line. In particular, in the learning phase the
whole system is dedicated to the acquisition of workload indices. Such load indices are then
used in the running phase as threshold values for job migration between different sites.
In spite of the differences, there are some similarities between our work and the abovementioned work. One important similarity is the use of learning procedures. This is in
difference from the more classical work on parallel and distributed computation (Bertsekas
& Tsitsiklis, 1989) which applies numerical and iterative methods to the solution of problems
in network ow and parallel computing. Other similarities are related to our study of the
division of the society into groups. This somewhat resembles work on group formation
(Billard & Pasquale, 1993) in distributed computer systems. The information sharing we
allow in Section 7 is similar to the limited communication discussed by Tan (1993). In
the classification of load-balancing problems given by Ferrari (1985), our work falls into
the category of load-independent and non-preemptive pure load-balancing. The problems we
investigate can be also seen as sender-initiated problems, although in our case the sender
is the agent and not the (overloaded) resource.
495

fiSchaerf, Shoham, & Tennenholtz

One may wonder how our work differs from other work on adaptive load balancing
in Operations Research (OR) (e.g., queuing theory Bonomi, Doshi, Kaufmann, Lee, &
Kumar, 1990). Indeed, there are some commonalities. In both OR and our work, individual
decisions are made locally, based on information obtained dynamically during runtime. And
in both cases the systems constructed are suciently complex that the most interesting
results tend to be obtained experimentally. However, a careful look at the relevant OR
literature reveals an essential difference between the perspective of OR on the topic and our
reinforcement-learning perspective: OR permits free communication within the system, and
thus there is no significant element of uncertainty in that framework. In particular, the issue
of exploration versus exploitation, which lies at the heart of our approach, is completely
absent from work in OR.
Some work on adaptive load balancing and related topics has been carried out also by
the Artificial Intelligence community (see e.g., Kosoresow, 1993; Gmytrasiewicz, Durfee, &
Wehe, 1991; Wellman, 1993). This work too, however, tends to be based on some form of
communication among the agents, whereas in our case the load balancing is obtained purely
from a learning activity.
This article is related to our previous work on co-learning (Shoham & Tennenholtz,
1992, 1994). The framework of co-learning is a framework for multi-agent learning, which
differs from other frameworks discussed in multi-agent reinforcement learning (Narendra &
Thathachar, 1989; Tan, 1993; Yanco & Stein, 1993; Sen, Sekaran, & Hale, 1994) due to
the fact that it considers the case of stochastic interactions among subsets of the agents,
where there is purely local feedback revealed to the agents based on these interactions. The
framework of co-learning is similar in some respects to a number of dynamic frameworks in
economics (Kandori, Mailath, & Rob, 1991), physics (Kinderman & Snell, 1980), computational ecologies (Huberman & Hogg, 1988), and biology (Altenberg & Feldman, 1987). Our
study of adaptive load balancing can be treated as a study in co-learning.
Relevant to our work is also the literature in the field of Learning Automata (see Narendra & Thathachar, 1989). In fact, an agent in our setting can be seen as a learning automaton. Therefore, one may hope that theoretical results on interconnected automata and
N-player games (see e.g., El-Fattah, 1980; Abdel-Fattah, 1983; Narendra & Wheeler Jr.,
1983; Wheeler Jr. & Narendra, 1985) could be imported in our framework. Unfortunately,
due to the stochastic nature of job submissions (i.e., agent interactions) and the real-valued
(instead of binary) feedback, our problem does not fit completely in to the theoretical
framework of learning automata. Hence, results concerning optimality, convergence or expediency of learning rules such as Linear Reward-Penalty or Linear Reward-Inaction, can
not be easily adapted into our setting. The fact that we use a stochastic model for the
interaction among agents, makes our work closely related to the above-mentioned work on
co-learning. Nevertheless, our work is largely inuenced by learning automata theory and
our resource-selection rules closely resemble reinforcement schemes for learning automata.
Last but not least, our work is related to work applying organization theory and management techniques to the field of Distributed AI (Fox, 1981; Malone, 1987; Durfee, Lesser,
& Corkill, 1987). Our model is closely related to models of decision-making in management
and organization theory (e.g., Malone, 1987) and applies a reinforcement learning perspective to that context. This makes our work related to psychological models of decision-making
(Arthur, 1994).
496

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

10. Summary

This work applies the idea of multi-agent reinforcement learning to the problem of load
balancing in a loosely-coupled multi-agent system, in which agents need to adapt to one another as well as to a changing environment. We have demonstrated that adaptive behavior
is useful for ecient load balancing in this context and identified a pair of parameters that
affect that eciency in a non-trivial fashion. Each parameter, holding the other parameter
to be fixed, gives rise to a certain tradeoff, and the two parameters interplay in a non-trivial
and illuminating way. We have also exposed illuminating results regarding heterogeneous
populations, such as how a group of parasitic less adaptive agents can gain from the exibility of other agents. In addition, we showed that naive use of communication may not
improve, and might even deteriorate, the system eciency.

Acknowledgments

We thank the anonymous reviewers and Steve Minton, whose stimulating comments helped
us in improving on an earlier version of this paper.

References

Abdel-Fattah, Y. M. (1983). Stochastic automata modeling of certain problems of collective
behavior. IEEE Transactions on Systems, Man, and Cybernetics, 13 (3), 236{241.
Altenberg, L., & Feldman, M. W. (1987). Selection, generalized transmission, and the
evolution of modifier genes. I. The reduction principle. Genetics, 117, 559{572.
Arthur, W. (1994). Inductive reasoning, bounded rationality and the bar problem. Tech. rep.
94-03-014 (working paper), Santa Fe Institute. Appeared also in American Economic
Review 84.
Axelrod, R. (1984). The Evolution of Cooperation. New York: Basic Books.
Bertsekas, D., & Tsitsiklis, J. (1989). Parallel and Distributed Computation: Numerical
Methods. Prentice Hall.
Billard, E., & Pasquale, J. (1993). Effects of delayed communication in dynamic group
formation. IEEE Transactions on Systems, Man, and Cybernetics, 23 (5), 1265{1275.
Blackburn, J. M. (1936). Acquisition to skill: An analysis of learning curves. IHRB Report
No. 73.
Bond, A. H., & Gasser, L. (1988). Readings in Distributed Artificial Intelligence. Ablex
Publishing Corporation.
Bonomi, F., Doshi, B., Kaufmann, J., Lee, T., & Kumar, A. (1990). A case study of
adaptive load balancing algorithm. Queuing Systems, 7, 23{49.
Durfee, E. H., Lesser, V. R., & Corkill, D. D. (1987). Coherent cooperation among communicating problem solvers. IEEE Transactions on Computers, 36, 1275{1291.
497

fiSchaerf, Shoham, & Tennenholtz

Eager, D., Lazowska, E., & Zahorjan, J. (1986). Adaptive load sharing in homogeneous
distributed systems. IEEE Transactions on Software Engineering, 12 (5), 662{675.
El-Fattah, Y. M. (1980). Stochastic automata modeling of certain problems of collective
behavior. IEEE Transactions on Systems, Man, and Cybernetics, 10 (6), 304{314.
Ferrari, D. (1985). A study of load indices for load balancing schemes. Tech. rep. Ucb/CSD
86/262, Computer Science Division (EECS), Univ. of California, Berkeley.
Ferrari, D., Serazzi, G., & Zeigner, A. (1983). Measurement and Tuning of Computer
Systems. Prentice Hall.
Fox, M. S. (1981). An organizational view of distributed systems. IEEE Transactions on
Systems, Man, and Cybernetics, 11, 70{80.
Glockner, A., & Pasquale, J. (1993). Coadaptive behavior in a simple distributed job
scheduling system. IEEE Transactions on Systems, Man, and Cybernetics, 23 (3),
902{907.
Gmytrasiewicz, P., Durfee, E., & Wehe, D. (1991). The utility of communication in coordinating intelligent agents. In Proc. of the 9th Nat. Conf. on Artificial Intelligence
(AAAI-91), pp. 166{172.
Huberman, B. A., & Hogg, T. (1988). The behavior of computational ecologies. In Huberman, B. A. (Ed.), The Ecology of Computation. Elsevier Science.
Kaelbling, L. (1993). Learning in Embedded Systems. MIT Press.
Kandori, M., Mailath, G., & Rob, R. (1991). Learning, mutation and long equilibria in
games. Mimeo. University of Pennsylvania.
Kinderman, R., & Snell, S. L. (1980). Markov Random Fields and their Applications.
American Mathematical Society.
Kosoresow, A. P. (1993). A fast first-cut protocol for agent coordination. In Proc. of the
11th Nat. Conf. on Artificial Intelligence (AAAI-93), pp. 237{242.
Kraus, S., & Wilkenfeld, J. (1991). The function of time in cooperative negotiations. In
Proc. of the 9th Nat. Conf. on Artificial Intelligence (AAAI-91), pp. 179{184.
Lesser, V. R. (1991). A retrospective view of FA/C distributed problem solving. IEEE
Transactions on Systems, Man, and Cybernetics, 21 (6), 1347{1362.
Malone, T. W. (1987). Modeling coordination in organizations and markets. Management
Science, 33 (10), 1317{1332.
Mehra, P. (1992). Automated Learning of Load-Balancing Strategies For A Distributed
Computer System. Ph.D. thesis, Department of Electrical and Computer Engineering,
University of Illinois at Urbana-Champaign.
498

fiAdaptive Load Balancing: A Study in Multi-Agent Learning

Mehra, P., & Wah, B. W. (1993). Population-based learning of load balancing policies for a
distributed computer system. In Proceedings of Computing in Aerospace 9 Conference,
AIAA, pp. 1120{1130.
Mirchandaney, R., & Stankovic, J. (1986). Using stochastic learning automata for job
scheduling in distributed processing systems. Journal of Parallel and Distributed
Computing, 3, 527{552.
Mirchandaney, R., Towsley, D., & Stankovic, J. (1989). Analysis of the effects of delays on
load sharing. IEEE Transactions on Computers, 38 (11), 1513{1525.
Narendra, K., & Thathachar, M. A. L. (1989). Learning Automata: An Introduction.
Prentice Hall.
Narendra, K., & Wheeler Jr., R. M. (1983). An N-player sequential stochastic game with
identical payoffs. IEEE Transactions on Systems, Man, and Cybernetics, 13 (6), 1154{
1158.
Pulidas, S., Towsley, D., & Stankovic, J. (1988). Imbedding gradient estimators in load balancing algorithms. In Proceedings of the 8th International Conference on Distributed
Computer Systems, IEEE, pp. 482{489.
Sen, S., Sekaran, M., & Hale, J. (1994). Learning to coordinate without sharing information.
In Proc. of the 12th Nat. Conf. on Artificial Intelligence (AAAI-94).
Shoham, Y., & Tennenholtz, M. (1992). Emergent conventions in multi-agent systems: initial experimental results and observations. In Proc. of the 3rd Int. Conf. on Principles
of Knowledge Representation and Reasoning (KR-92), pp. 225{231.
Shoham, Y., & Tennenholtz, M. (1994). Co-learning and the evolution of social activity.
Tech. rep. STAN-CS-TR-94-1511, Dept. of Computer Science, Stanford University.
Sutton, R. (1992). Special issue on reinforcement learning. Machine Learning, 8 (3{4).
Tan, M. (1993). Multi-agent reinforcement learning: Independent vs. cooperative agents.
In Proceedings of the 10th International Conference on Machine Learning.
Thronkide, E. L. (1898). Animal intelligence: An experimental study of the associative
processes in animals. Psychological Monographs, 2.
Watkins, C. (1989). Learning With Delayed Rewards. Ph.D. thesis, Cambridge University.
Wellman, M. P. (1993). A market-oriented programming environment and its application to
distributed multicommodity ow problems. Journal of Artificial Intelligence Research,
1, 1{23.
Wheeler Jr., R. M., & Narendra, K. (1985). Learning models for decentralized decision
making. Automatica, 21 (4), 479{484.
499

fiSchaerf, Shoham, & Tennenholtz

Yanco, H., & Stein, L. (1993). An adaptive communication protocol for cooperating mobile robots. In From Animals to Animats: Proceedings of the Second International
Conference on the Simulation of Adaptive Behavior, pp. 478{485.
Zhou, S. (1988). A trace-driven simulation study of dynamic load balancing. IEEE Transactions on Software Engineering, 14 (9), 1327{1341.
Zlotkin, G., & Rosenschein, J. S. (1993). A domain theory for task oriented negotiation. In
Proc. of the 13th Int. Joint Conf. on Artificial Intelligence (IJCAI-93), pp. 416{422.

500

fi	
	fffi	
	

	!"!#%$'&)(*+*-,+.0/-(*21-/+34

A

BDCFEHGJILKNMPOQKSRUTWVXTYKSRUTYK[Z\A^]+_[CJ`9IZ9aUE

kmlnPomnqpsrmtQuwv

56789":;3-<2*+=>?7
#	@:;(+<*-,

b	CJ`dce]2GfKgAdRUGYVhZiGWZ9I2CjK

xzyz{z|~}[z} y}6x){z{9 

rmtinYk;nz

Fi[z} y}6xz){z{9 

0F+F9@+z22FF)26)
0)++FUhL)L!
z-

m
;P	Fm!0"@N!	P)00P+!@LN0	PJ0N+0		
 w		[@+!F;[	0@LF"	!+P!0X	))X@

J@	+f+@+U@0JPP+F9N0@)S	NP+P6P+F	@@"	
)	@	P+F@!@J@P%@Pz2	F+!	zPh!@@6N@)P	F@Y
!F	@0+	@	h	@@0FN!@+!@	
 0f@	!JP!-	U+)F@L!X	%P@!0-
 6+@	J)0N!!@W![ W@	WPF	+'"@F@J@h)
! P+F6	+@@-wh)YN0!	Y!F)N@!!NWN!
)X%!N!@@PW	!N!-@@)@	@X	@@d+
0S	!!FF[!P6F+	+@@[L	)!UN++![0+P6!
@6@;	!@@;PJ!@+w"!	!0  ;	@@0U i	F06@+6@9+@0@L!Pi!
	0@S	@!;P++@P@-!U!+@!	UN!;@@!+N!2+!@+
@;;F![;@0	;!-P0@N!-!NN@!;i@0%
ih ;@ 

 	ff
fi	ff		
fi		
fi fi!""#$&%'ff(ff)
*+,+#"#
fi+$ff
-	+.
-/0%'1ff2

.34$65879
-.$:ff"#ff
fi
-
fi$;	$<=<=ff	/>+?#@().;ffA>CBD	+E;-$ff+%
F	fffi/>F+?+fi	
-%'<D	,	ff-/G2H+fi
fi	C%'/>"#5<I$"#4:"#/G		.
fi3
"#/Gfffi#@ff
fiJ+	/GD#K=	+EL=+K$!ff
fi	M%'/ON.K	!
fi"P
fifffi$Q$Rff
-$
fi/G;#@		ff
S	
fi
=	T&
-U+%*=		fffi/V5FI(!/>KP=+KM+,+-	
fiK"+Wff
SXfiY3
C=ff
	ff-/
DL+-
fi	ZZ!/>3XfiW	fffi/V[?=G+%J	+	
fi	Z\	P
fi>fi	
fi]\=	\"#	ffG.B45
^Hffff
fi
->P#XKF=_/?+DW	E`	Pfffi/G2Hfi
-	a 
fi+
-SF"PfiD#-G$/,fffiM+?&
fi
fi:
=	#%'b=	Pb/>3>)Yff++D#+MG&
fi	W""#$$c>!+fiM	Ed	Pfffi/>5
7e;#@e+/Wfffi:"2'$fff		.;Dff
'"3XfiG""#/WffX
=f=	#
-.Ba
fif=	b	=!$[
gih?jMkJh?ljmbnfo [9p
fiq?T%1
fiff
-
38"#
fi
fic+fff3:	P
fiM%'/r=	sX
fi	.+P
W&
fi/,
X'+;ff+fftu	C=+=cE;B$W
-V"P
fi."#	/>#+"#$P=+$/,fffibP=	b
fi			.65v;=	
P
fi+3*	=J/?$?3,
-Dfi+/GJ	!Nw"P
3K/G(
xNw"+
fi?+%K=	bx
fi	.+Wff+*:ff%'
#@+/Gff-:++/,
fi	J"#.+ff.+,/>+B
fi	b=	FX
-	.+bff*yz9
fiff
fi
'3eJD3w"#
fi!
fi
/?+."P=>=	s
fi			T)$"P
XNw"+
-5
gin  nf{Jk;nbkCl3|a} [(~	
X%'f=	JP
fi$Aff+?t 55X:eDV	
-	+A/G+
fi	>6:
ff>"P=+	+
fi	?f.ff#:ff;D?/G	%
fi	,S+
'+fffiMff
fi
fi	DFt	ff
X*=	bP$fffi
fi	,ff
"P=ff
fi$F=	s
fi			ff3 5
 (*+*-,wfizfi@@!"	2	:!	:<W+<mff8
F

2_07
)#Hfiz

#"0!" 6:+

fi

yz{z|~}a

	

gjM}VjMh>nfoFl3QnCkJl3|G} [ffpM	.3X
fiU;=	c	E;fiY"#P$+$,ff>+,P<
-<<M	E0"

fi>P=	X
-	.+?H	+
ff$a
fiF
;ff"P
fifffiG
X*ffF%/ff+;"#	PD-,
fi?=	MX
fi	.#5
v=ff
C+W%	"#$WL=	\	+	.+!
fi]	("#$PC
fiL=		.3"#D#@	,+%JZ"2'!$
ff+	ff
-	q	/V=	+E;$:4	,	+	.
fiZ3fi
fi=	/"#ff?#%ffF%J.&%/>+&
fiS
+?ffVff		+
fi	f	/>;;E;#X5
 
 O

l	ozrzl	


t

ZPB?
fiq"!2'$ff+	ff
fi	?=M=ff
!
"SXX>)"#ff"#$A
fi\+!
"#ff+T	ffX
"+
-Vff2
/>3
-:T+=?Pff$0]%'("#?0	P$D#+
fi.+=	fP=+3fi!
fi=	/,
"?
'	$5v;=	
$$."=f	ff$P$;	ff-/>QX
fiBME=+F%'$+	$F+%8sX
-	.+,ff+f/?+BMD	a
fi
"#$F%'_!		2
$R	D!
fiS3:$=	+E%$+P	$4+%=	QX
fi	.Tff'+Y"+,	$!1#*$"#
fi<	+	.+!
fiJ#++
fi$6:
+fW*5
 	E;Bbff#fiMff/>3
fi	2-
-D)ffD<Sfi
- =	/%9ff+Y	+	.+
-*:$+s
4P=	#%
"#/Gfffi/WD.w[Q
fiM	+
'ff$T?"#/G/GVff+!%P/E;
fi=fEc=ff
"=\	,"+Z+3fiffUYV"#/G
=	\S+!
fi?	$!D.
fi0"=	/W$f+0	+	.+!
fi`!.+
fi$:WE;#Xs?#@(fffi
fi0=	
+#"#=	Cff
S1	#N.M%<=	Y"!2'$\+		D"=Gff+	ff
-	5bI$"#
-bG+	5z

"#MP=	a9*	\ M+/G/W4:13ff+	XKLb+/,	=+/G+
<-$:<$ff_	/?
&
fi	?	c%./GE;B4:(ZI$"#!
fiqe5XJ"P=+."#!
fiU$;	$"P
!#fif=	J)ff
3	#N.M+%<ff'+
	+	.
fi?.ff+f	.
fi*5
v;=ff
'+)b	$ff.M+Z3fi!
fi=	/V:wuHP=	V(!/>+
fi"sff+q	+	.(K%Tff	+	2
.+
-P=+C
G	4:;"#/Gff-:_u	/>
"+5LI	ff	$G/W$+,=+W=	f			Gff'+

M+#+DP$\V+!
&%'V=	,DS :*"#/GfffiP	$b/G$b=+bP=	Gff+		CE;
XX_3-E6(cN
+fi	!
fiZffZ
X%	?#@ff
.WHff+.fi$s+%=	?X
fi	#+Vff'+	PS
ff$D=	>P
fi6.:K+
	/>+!
"P
fiHW/G$+F=+P=	3-
fiP=	/#@	fffi$;P=	J"#b+%8	+	.+
-F		2'$ff		+fffi
'
fiV=	$:
fi;E;
XX*	b"#&
'ffT+V	+	#+
fi?/GPT=f"#+.5
I	/>
"P
fi&\
,=	
"PB
fi$,	)\.+ff:_]%'GE;qP$579
fi.$:Q=	
	+	F#+$
-C"#+%4
fi"#/GfffiMff+5 (G "P=W
fi"#/GfffiPff+>"G#@(W
fiDPJ+
#@()	ff
3;D	/,C+%T"#/Gfffi!
fiK	/>
"P
fi&V$Rff
fi$s=+JP=	>	+	.
fiZ3fi
fi=	/
	"#&
ff;E;b
fi"#/Gfffiff'+F=+=+cf	b"#/Gfffi
-*:E=	P$;"#/Gfffi	$P
$Rff
fi$M=+b\ff
SQ"#/Wfffi
fi\)"# 
ff$45fI$"#4:*ff+]	+	.+!
fiVP$Rff
fiP$
G"#/,ff
fi+!
fi?+%1#"#
fi	,	
fi;ff'+	ff
fi	>ff$"P
 
fic "P=	+
"#J+?#ff
fi	G+%ff+V6:
ff
fi
fi	?+%KS+
'+fffi$;E;
-=ff
fif=	,"#
fiVP"=	/>#.:4;E;#X8/>+B
fi	G	Eff$"P
&
fi65MI(P/G2
+
"P
- ,$Rff
fi$;P=+TGff$"P
 
fi*:ff"#JP."#$4:ff	MJ"#&
ff$+D3
fi*5
 	;%'.+/GE;PB,%ff+	ff
fi	WDV		.+
fi+?
F!$f E;,	/,
'$;=3
-	YP>ff>E
fi=
=	b+	b%QP$?ff+c+?=	+E=	f+b/>+ff
-	ff+$4[
X
fi	#+Jff'+G;";
FP$G<C"#/GfffiPT+?"#&
PDKff,%_+-
fi	bP=	T	
-
	fffi/V5fv;=ff
sff+"#ff.3
-M=	!J+.ff
fi	ffb=+,+fi$VP=	>	
-b	fffi/
3-	fE;
fi=L	
fi!
fi3_"#!.3
fiff.b+]ffff3"#Z
-ff%P/>+
fiqP=+J$"#.ZEc=DZP=	
PYZ#ff
fi	DC+	$+,=	P5  	fffi
fi	ZV"fq	E	ff-/N#b
fiff+-$
3
-	=	AX
fi	.Lff+/?+."P=u=	
fiff
fi!
3T+D3b"#
fi
fiG+%JP=	"#	PD
	fffi/V:4?	("#$PM=+M	(ff"#$C>"#&
ffM		M
fi"#/GfffiPYff'+*5bv;=	G	+	.+!
fi
		"#$/G	.F?"#/GfffibP=ff
Fff+*5

g

.W$#;'b6PGG+bSP'-!zY#'$'G.H!?SP'-!z, #$''H!3f.-X6*3f!
'6'_P$6-.+	''$*#*.3''H'*X#44'PH.K'3<#!fi
3$

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

v =		+	.+
-G		"#$;"#&
!.K+%KY!.+	+.W;+%1ff+	2'P#N	/GD;).+.;HP=	D
g ;
=+_	f;+?"#.S
fiD#K,=	Mff+4KfffiF=	J+ff
xX
fiH,,P."#<P=	b#N	/Gff.
/>ffbE=	=	MX
fi	.Gff+fEF!
fi+
fi3xW	.+$45
 J
fiEdP=	Y	.3Kff+	ff
fi	f	fffi/T?$+."P=\=		=q?
fi$"#$.	=V+%;+
S

ff+65v;=	f#+	=*yzCff,	$ff.,=	fffffXff+u\
fi#b-$$$JP	$ff,Nff
=	$ff+5
pT	#+
fi?ff+	ff
-	!.+.C+,=	?DY%T=	f.	=i+]$+#"=	$C%'G	(ff\&ff+4b=+
+!
&N$M=	GD3 5W^HJ	.+$M=	?.	=qffZ""#$&
-#fi\#Nff
fi	 "##3
fiff
fi		;=	Gff'+*5
v;=	P
fi+3	=%+>	+	.+
-	2'$sff+		$:G=	=	K=+4:P	<>+ff
fiP.+
		ff,
fiZ=	,#+	=*:1+=	?	+	b)+
fiJ!$+."P=ff
fi	?%P/P=+b+
-D$5,^&b/,b>fffiG
$+."P=Vff+EVP=	b.+	=AX
fiBb,	.
fibff		T		TSG/,)Y+ff-b>$+#"="BffE+.
=		=>=	b.+	=?DGP."#
-	Y"#P.3
fiff.:	(ff"P
-	G/Gb+P."#<ff'+5  	T"#/Gff-
+u!(P/>+
"?	+	#+
fiuSfi
X=	/
W+fffiVP$+."P=LL		fff
-u=	.+	=LE;
-=		
"#&
ff!
fi	>+ff>		ffb/GPb=+f"#5
ZF=3K
fi/Wfffi/Gff$b	K3fi
X=	/ $ 
fiW</G/WJ)
,,Tc^HE;B	.+&
fi9+b$!$

fib!.3<	fffi/ff/>3
-5  @	
-/GD#3_
fi$b"#/G+G	J3fi!
fi=	/rVV&
-/,
X+
#*$:;	xK0 b+/,	=+/G
Tfi3:b$ff#5  	G$!fffi.,=	+EZ	/?+
"G!$ff	
%P/ff+fs%T"#.3
-&
-/GfffiJ+?ff+	fffi/"P$65
 	E;PBGV+]/>+B$F=	s%Xfi$E
fi	Y"#ff
-		
fi[
 	
 K3fi
X=	/"+		$9=	F$"#<%(=	Fff+	2H		.+
fiT		"#$9E;
fi=ff
-J+b#@(P/G#fi
 
fi/Gfffi%'.+/GE;PBw5  *"P=b
fi
*+/GfffiK;%'/>S3fi	&
:$b	+
ff$*F%'.+/GE;PB
E
fi=VEc=ff
"=>+3fi+PG=	Jff/?3
fi	2-
fiff)ffD,3fi!
fi=	/>;x
fiB,=	?	XK!(P/
b+/,	=+/G+
Kcfi$:K3ff.:)+ff+3-DU,ff/>3
fi	2Hff)ff	b	$ff.+!
fi
f	+	.+!
fif.+P+
fi$5
g

g TM=	c%#+/GE;B,s
fiD$
fiD M*9	(yzF#+&%'/>+!
3w+		D"=?Jff'+	+	2
#+
fi*:++G!=	SEL=	+E0*9	(yzQ3
fi<!.+
fi$1"#ff,M	ff$GPJ+qK!$+."P=	2H"#DP+
=		!

"65
g Y+3-DU,=	C.ff+]E;qff'+V	#+
fi\+V	+	.+
-*:w"P=+."#
fiU#
fi	W=	
 
fi/,
XH
-HG$Rff
fi$?ff?=	Jfff
fi+3*	
-	b,	(ff"#,$ff	*5
g YPM\/Gff
fi!
"3K#@()
fi/Gff.M+\ff/G#+C%?&
fi/Gff-a"P'c+%<	fffi/?
f!(P/>+
"s#+!
fi=ff
fi\) E;"#/G		.+
-V
-/GG+\=	> 
fi/,
X
X f)E_=	

-				fffi/r+?=	MX
fi	#+Gfff=	Y		.+
fi>3fi
fi=	/
fi;E;
fiP=*5
v =	,+)b		"#$	Jc%'+Xfi+ET6[;E_CN.!T
fiE	
fiME;PB?
fi\ff+	ff
fi	fffq	+	!
fi	
;
3
-
fi	G	
fic+fi	
-5<c#@(ME;b
fiE=	sfi$2H"#/G/,
fi/WD;	.
fiMff+	ff
fi	
3fi!
fi=	/ZEc=ff
"=]+
b!$4:*
-iff+
-	qA
fiDP(ff"P
-	V/>+ff\+%T+<yzC	+."#	P$5
I$"#
fi?,=	f#@(ff'3
fiF=	bff.3
XQ+%1			.+
fi>3fi
fi=	/V59^H\I$"#
-CE;M	+TP=+
+\
!	4:"#/Gff-J+f	/>
"+5
I+
fi"#f=	V!$L%	+	.
fiff)W]=	VRSX
fiZ+%TP=	fff+L!
fi$%/P=	
X
fi	.+P:
-"Vs%;G)%/	.
fiMff+	ff
fi	W=+V+P/G	G	+	M+?
fi+		2
	
+sX
fi	.>ff'+*	
-ZI$"#
fiqWE_,+3fiffUJP=ff
P.ff++\3!>
"#M/Wb
fiff$!
fi	

fiDP."#
fi<)E_\=	,3fi
X=	/>Q%		.+
fi+Aff+AN
fi	5v=	f
fiI$"#
fiJE;
w6$bD'F$$P#	ff
fiffff	#<X#)X#'-.M.JP-$FX'K'.3'<$K#Xff
3

fi

yz{z|~}a

	

=	+EO=	SE .+&%'/?+
fi+31ff'+		.M"=\MT+/W/G4yzs.$ff<*9		/"+V)G++2
fiffU$G 
fi	J	Q%#+/GE;B45KI$"#
-s.K	</Gff
fi!
"3w
-$5  %F
fiE;
fi	b#'+$
E;B?I$"#
-(.:)I$"#
fi\,
"#!$<		P$<+?)D$;R	$
fiQ%'F%	P	TP$$+."P=*5
 "#<@w%$
! 

i& 

(';)#*"

,+

 

.-

v;=	M
ff$C+%ff+	ff
fi	,ff>	+	.
fiG=<)f
fi?=	cX
fi#+	;%';/>+ffG$.:	+a
fi>/?+D

X*ffF%P/>5^Hf=ff
'_!$"#
fifE;M
-E=ff
FE;BG	!
fi /:ff
fi	,,/G
fi++b+?		;
fiff
#$"#
-J	M"#	ffE;BGV<5
v=	b&
"c
ff$a=ff
fiff+	ff
-	GDf	+	#+
fiHM&
fi/,
X'$;E;BW
fiV"!2'$fff'+	ff
fi	:
.&%/>+
XSff+	ff
fi	:;ff+	ff
fi	CD?+fi	
-Gff3)4
FY!+fiTs	E	ff-/fff.+
!
fi
-	,%P//G/GW	ff-/==f)Z+fi$?	P
fi&fi:	=	] (_	+	
-	G=	
+f!+fi	
fi>,=	C	E	ff-/V5
v=	V**	Z	/ T+/W/G4:$ ffM
,Z"2'$Lff		G=+G+-$C	fffi/>Y
fi
=	Vff/>S
fi%YIU$"P=DE+u"#ffB
fi	5`=	L
fiuD3\		ff"#q\
!=LE;
fi=]+
'"#ff+
	)
fi$:ff9*	bN.F
fi$Q1
 024365	7598:036;;+ffY	Pfffi/>Q_"#
 /	
'"#.K=</,
fi=D<+!
;%'/=	
	ED3 :+]$C=+,+3fi	&
s=
 <ff;>36<5	;?>;C%//G/GZq"
	+f+fi	!
fi]H#x
fi	
ff+4.5Kv;=	b#X
fi	Mff+W
F=	?/>+ff
fi	ff$Gff>%
 @BAC5 DE5	2GFbSfi
-=	/=+;
-$<PY+!
&%'
+ff	ErD3'G+LP3
fiG	fffi/>,=>
L	+!
?
fiL=	#X
-	q"#+!
fi5^H?=	
#@($"#	P$=	bff'+*:	+W
X%K#@($"#	
-f$fffi#K
-?%3
xfi	b1
 <ff;H8:05	<_Sfi
-=	/+SfiDU$=	M%S
Xfi	
+W$F=	TP$fffi;+%*=++3-(&
'C
fi/G	+P=	
fiff#@W%F=ff
;+-	
fi>!J=+Q
fi;E;
XX	
C
fi$W
fiV&
fi
fi+FE=	b
-_E
XX4%S
X1+D3
fi*5
9*	Z	ff$!$G\E;
fff#+	?+%	Pfffi/>s
fi/G).D,Z"2'$Lff	ff
fi	[?=	+E
+ff
"P
fi+PV	ff-/>:=	+ErL!
fiq]+-	
fi%/ =	]"X
fi	.:;=	+Eu	+	>
/G	
X%f++f+-	
fi*:f=	+EG!J#@	$"#	
fiA%3
xfi	b,
-/G	+J	$R	ffTP
fiSS5
 	J+u	/r	
fi/>
XfiV	ffP$$M=	,	+	.+!
fiV	Pfffi/V:4+
fiI$"#
fi],E;Y!Y	
%#+/GE;BGPa3fiffUJ*9	(yz/G(
xNw"+
fiV!.+
fi$
fiV!/GJff.3
x 5
v;=	c
 I JLKwc(!/  fiP/>+*:ff$(w"#ff%'ff.*P=	<	ff-/d+%K	+	
fi<ff+	ff
-	:zc		
3,	ff$!$<P=	T	fffi/+.
% <MG2ONP365	@B;T	+	#+
fi,Cff+W%S
Xfi	5Q
 I JLKwC+		D"P=	$Kff'+
	+	.
fiZE
fi=\"#/,ff
fi+!
fi\+%T."#
"3_"#ff+]&
fi
fiZ/?+."P=ff
fi	5f0=	LVff'+
%S
Xfi	c
ff$"#P$?
fiF
"P'&
XN$f;#
fi	W#
fi=	TC%H3
Xx
fi	,	$"#
fi
-*:	C%S
XX
fi	,	."#/G:	
"%9
x!
fi	Jff3:+;JPG	<%.ff$5^H	
fi	JP=	T)$"#.F+%K
 I JLKwM=<ff$3*E;
fi=

fi"#/Gff-J+W
fi"#P$"#;BD	+E;fi$ff:DP=	b	./VyzF/>3
fi?3
-!.+,
fiff+fi$Fff'"P
fi	
,%H3
X-$>ff'+qPVE;
fiP=V	C=+/,
-=DM"=ff
-J=	,+/GC		ff5b
 I JQKw,$M>!/>+ff
"
	 E;PBG,	$ffT+!."#
-"P'$;%8"#
fi<P=+T"P=ff
fiM=	J+/Wb		D!GHE3fiB
X	
+fff
fi
fi	>+Pb=?
-.+"#$;%8#+.+
Xf"#
-:%_#@+/Gff-+.5
v;=	S
 RTK(
 Uw) Kw,	/PI+
fi/G/G6:*$(1
'V
 36<ff02OWXDA<@B0365XA240Y8(YZ02424;><.5F0=ff
Xfib=	J
xP2
"#GE;Z?.+&%'/?+
X31ff'+		J+Z?"2'!$\ff+		b=M	bZ	$"P
'#fi
ff#N	$4:8?/?+
xP"#>"#"#s=	SEP=	YE;? ff$s+%_ff'+		.Mb=	?.+!
fi	G
fiD
%Fff+f	+	.
fi*5Q_$ff2'!$>	/?K;=ff
Qff+?
'b!
fiS34+%1C_!+fi	
fi,%P/
MX
fi	#+:+		[
 R*TQ(
 Uw) KwT"#/Yff
-	$</>SXff+W%#+/Gff.9%'<
X*ffH=	)#%ffxfiC
fiffffff
$"##+%<P=	Y"#	ff	fffi/V[
5 RTK(
 Uw) Kw,
X*.%/9*	,
fiVE;,=	ME$	[N#T%Q3x :
R*TQ(
 Uw6 K4GffD$c	M%'/=
 02\365X7>5]80365XA23fi	&
;\=	Cff+*:)
fi	?G
'ffD
x%?	ff-
#J)#%?X
fi	.\
fi+3 5\^&$
fiG""#	#JP=	?%"#,=J=	fP
fi$ff+]E;
XX;
/w$E;$4:*+\"#	ff.M
fi#S
fib=		
!
"M?+."P=V
-$5J9*		:4\=	G=	M=+4:	/G$
3$

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

=+C=	?
fi$X
fi	.VffE;
xX<f\"PfiDG		=ZN,=	G	E	ff-/ !V=+sX
fi2
fi,C	q		.+
fiVE;
Xx<G	$"#$P+5I$"#4:/,"=Z%_=	1
 RTQ
 U46 KwWE;BA
Jff$\
ff#fiff
fi	>Gc+%13
-#+.Q%'TR+ff
XN$f+?/GP
"MS
+fffi$65
v=	G/>3
fi
ff$f)=ff
fi]=	>0	/!+.+$
fib%'/P=	>=	P>	/>s/GD!
fi	$
+)S[G=+,=	?		"#$,+%Mff+^
 0C08360365XA2
,A%3
-fiZ&
fi/Gff->#@	&
fi\=	f	P("#$C+%
ff+%
 F;2\;<ff0365	A25  ;C"#$R	"#TE;T"+?	/GM=+KP=	T3fi
fi=	/=K	.+$8X
fi	.
ff+ t`+f=	,"#P	J+%K=	D!Jff+ tL
P=	J+/G,;=	,	+	.+!
fiV3fi
fi=	/+A=	
ff+V!"#	$
fi;	.$5F^HVP=	Y+Z
fiEJ:eff+f	.
fi?
8 MG$"P
'38"C+%Kff+
	+	#+
fiH	M
-fE=ff
"P=f=	M
;	W
fi$f"#	Pb,.@	fffi+
-.5
v;E;Gff
-$"#$+%KE;Bfff#fi)$\+=	,+/GC
fi/GJM+Lff	T 
fi/,
X	/G	
-[F=	
	XKu	/  b+/,	=+/G
cfi$:3ffT+]P=	V
 _STQ`8) ac bu	/ e dK#fiD!:<$	:
$+e.5
v;=	b/?3
fif
X*"#J) E;V]+\	xK?
;=	b	ff-
fi	Wff+	ff
fi	>Sfi
-=	/V[1
$GZ"#.3
-D2')D
X	\$"P=	ff
R	V&
fi/,
X'+J]<=	/>+*yzW.$fff
 b(gfQ
 ha/G(
xN$]D
~\"  X-$+V
 iDffffX
fiM.$	+.:E=	$M	xKV$c,S+!
+ff_
% jTQjkIS) jZ v+:4$(.:ff
=ff
fi.+#"=ff
"Sff'+		$5;I$"#
-VG"#/G$;=	$bE;,ff+		._
fiV/GJff#3
X 5
v;=	l
 _STL`K6 ac bq	/3!Y#+B$;,$+."P=	2'
fiff$?+		D"=?,ff+	ff
fi	)51^&T
X*.Q%'/
+ 
fiL=	VP+fiV]"Vff'$	C
fiLP=	V	ff-/G2H+fi
fi	Z	P("#$65  X
-	.+]ff+0 "+J
-u
.+ %P/>+
X3f"2'$ff2'ff+	ff
fi	%'.+/GE;BL$>+fi	
-LLZ	
-G	ff-/
3fi	\E;
-=Z	/W/>+\+%bE=+C	E	fffi/?b
-YE;ff'Z)Vq!ff
fi.+fffif+-	
fi\%'$:Q		,
fi
"#ff.3
fiWX
-X
fiff%/>+
X0+	V=	m
 8(<PA>7;nWWGP=+f	.+P$uP=	+fi	!
fi*p
5 oM
fiS
fi3
+3fi:fP=	b=	;=+4:P$;	.D
'31ff$"#
fi	
-F+%1=	!
 C;75cW5XA2OWK=+;$fffiP$W
fi
=	Y!+fi	
fi*5;^H\+
'"#ff+$
: dK#-DyzM	/r$"#.	c/GPb
fiff%'/>
XV+M$"=\"=	
"#J)+
fiff
=+ffff$J<[YX
M+%;%H3
Xfi$\3fiP+
fi$:)%b#@e+/Wfffi5fv;=	G#
fi,#*$"#
fi	$PM+%=	
E_?+		D"P=	$b/>MP>=ff
fi	YV=	,#@	DbP>E=ff
'"=+fff'+	ff
fi	Vff$"P
&
-b	D$
G=	bff'+;=	/>!#fi$#<"+b	ff.PD	V+A#@(ff-+
fi$a
fiV&
fi/a
X+;ff+	ff
-	Gff
	ff$5
^&>	/G/>:+E;"#&
ff<	KE_Bb>fPbT"#/Wfffi/Gff.+CT/WDK#@ff

fi	bE;PBM
fi
.+ %P/>+
X3	;"2'$Wff+	ff
-	5Kv;=	;+PK=<"#"#D#+$W>ff#fiff
fi	J=		
'2

"3xfif#*$"#
fiC	fffi/fi.%b+
"#ff'+ff/>3
fi5a_2'!$ff2'ff+	ff
fi	f$!$+."P=q=
3,#@	fffi$?P=	b	fffi/%8=	+E,P
fib"$F%'/P=	bff+?X
fi	#+tL
fi>
"#ff_P=	
	fffi/+%*=	+E0b
fiff#@?=	/#$"#!
fi#fi5+<:ff?=	T=	;=+4:
<,ff/>S
fi	2-
fiffffff
3fi!
fi=	/V:	+fffD$c	T	ff$;=	bP
fi+3*;
fiff#@ff
fi	G	fffi/>F
fiVDfffVE35
v;=	,/>3
-V	$"#
fi$;+%_P=ff
E;PBV+G#+_P>#@	fffi,=	s
ff$?=+Mff+Z		.+
fi+A
T
%3
-fi/,
-	4	$ff.+
-3D+JSfi
X=	/a
"*++
D4+%	=	K&
'"	fffi/%(ffb	.+
-*:
 ffKG	+
ffM	#X
fi/,
-+G
ff"#JP=+;=ff
;
fiE+%ff+V	+	#+
fiW
F/Gff
fi!
"3XfiW
fffi:
+Lff qffT\	+
ff?V=	f"#/G/,	ff
fiZ+
fi/Gfffi/WD.
fiZ%ci3-
fiP=	/=+CE;
XX3Xfi+E
#$"#!
fiM	fffi/!+fi.FWJ	ff
xfi;$ff=ff
F
ff$e5
ZC	SE)+
fi\=	Gff#fi	/GDM+%<	M%'.+/WE_B>E
fi=qfff$P"#
fi	
fiV+%<=	,	ff-
fi	
%./GE;B,%';		#fif	#+
fiMff+	ff
-	5
r;%s "

" )#*"
 

!+

 

.-Lt

uv"^wLxVy{z


+|-

i u.}

I+
fi"#>P=	03fi
fi=	/r
C+]#@( 
fiZ+%T+!
3fi2'+.ff$:"##3
fiff2'D!
fi	:)fi$Y"#/W2
/ 
fi/Gffb	.
fi,ff+	ff
-	q3fi
X=	/V:4E;G)+
fiZff\	$ff
fi	VP=	G	.+!
fiZ3fi
fi=	/
,

fi.#X%5,+E;$:4E;GffVV 
fi	f=	G	#+
fi+\+%_P=	>+u	/V:*
fiZ=	,		"#$
fiDP2
3$

fi

yz{z|~}a

	

ff"#?/>+ffV+%=	>	.f"#P	$J+q%	"#
-b	$ff$f
-/Gfffi/Gffb=	,%'ffX_	+	#+
fi
3fi
fi=	/V5  	b$+/WDc
c	
fi#%-t`,#E=	? ~\"  Xfi$PTp
 i;DffffX
fi3:1$	(
 ~_
#4:4$+D(1%';/GPJff.3
X 5
 

rzlr

k~lklk	nzv

 07>365XA2a
GP"=	/>
"M	$!D.
fi?+%<+f#+T3+3
X+ff-T,=	Cff+		$5  \"#
fi
 =
"#&
'.b%c2\0@B;D:KV!Y%8(<P;7A24C5	365	A2WD:+0CCY5W3':KC;>YZ;>36;Y5W3.:K+]V!Y%5X2\C5	2GF
7A2W36<ff05X2\3	WD5v=	fN.C%'	>+P
 ;8(<P;nWW5	A2WJP=+G"+`"#ff.3
-
 ?>0<5	0YZ;nWD5]ZV!VR	$!
fi
/>+PB(cW
ffD!
X%f++
fffi$
: ?%'c
fi.+"#
5 ~Q
fi
fi	V"#.3
-D.c+J!$VPG
fi
'"+,=+
?+!
"#ff+MS+!
+fffiG"+		b)>)	\V?
"#ff"#!.+ffbbV/WY=	bS+!
+fffi5
cM
+V"#
fiV"#P$
fi	GGG&
-/Gfffibfffi	"B	E;'B
 :>#+$[
4 6 k
 :
G ( nO  nOG (G
6 G 
  O
G ( nOG (
 GO
 
G ( nOG (
 OO  
    G  n pGnG ( nG (  (
 ^GG(  GG(G

 W36;H8w5^H#+D!
+
X	b+Y"#!
fib
-Dfi$
 C
fi.+"#F+%Y"#
-b
9
-$
fiDPMffYK
.+K+
fi
fi	,	ff
R	J+/W$;G=	b++
fffi$F
fif=	J"#
fi*:	+ ff<&
-ff
fi	,=	JVa	ff
R	

fiff#@]
fiP=	fff+*:<Zff+L"+u"#ff.3
-Z/G?=+]	?
fi!.+"#?+%T=	V/G"#
fi*5 
A
P=	#%Y+A
fi."#J+%_+\"#
fi?
fi$
fiff>Wff+VE
fi=qf
fiff#@V=T	ff
R	#fi

ffff
XN$F
fi35
% 7A2W36<ff05X2\3	WD:3E=ff
"P=G#
fi=	<"#!.3
fi,=	;#ff<+%4 E;b8
fi
 ff+>3'"#D.S
fiKJK
=	;ff+,<"#!.3
fiC=	;ff
fi
fi	D%wS
+fffi$9
-YP=	!5  ,#ff
fi	J"#P.3
fiff*.+B$=	
%
/ \S:+E=	{
 44+%
 __P:D+s
fi
'"+$9=+K=	,E;
-=b
fiff#!
@ 4/,K	""#	
#%';=	,E;
-=b
fiff#
@ 45  ff
-
fi	J"##3
fiff*
9+%4=	F%P/  (  $ w; 
  (  $ .:+Ec=	
 ( 
'T?++
+ff-Y+	)$+
fi	W
fiZ/GGPV
-V=	,ff+Z+m
  $ 
c#
fi=	JWS+
'+fffiJJ"#.+ff
+	$
fi	,
fifP=	bff+*5 /
ZZ3'i		.+0"#.S
fiD?E;
fiP=$"##u%YE=ffL
fifEWff"#$
fi0=	\ff*5
v;=	#%'fff+*yz,"#P.3
fiff.M
'J"#SXfiZ\,+%T3
fi#J%T=	W%P
/ [+v
: GE=	V
 Y
,
#
fi=	Tf.ff
fi	W;ff
fi
fi	>"#!.3
fiff$:	+
 s

 <P;0WA2G	+.,P"#	, ff#N	$)#fi+Eb.5
v;=	CN3_"#/G	ffJ%?ff+
bf!b+%"+P3fY5X2OW :$"P=Z+%;=	C%/     :*Ec=	
4<+J+J!:4+ 
+f#@		$&
-*5_v=	bX
fi	B?$"##	=	M%H"#P=+	C		D!J+%
49
 
fif=	bff+?
'<PG/>+BP	:	E=	S
;,	$"#
-
fi?+%S5K^%Q,ff'+V"#ff.3
fi;sX
fi	B
      
-_/,M3G"#ff.3
fi?=	C.ff
fi	%  ^  5

ff+V"#&
'.F+%<G+%<6:(W+%<"##3
fiff.:DVGc+%*X
fi	B	5
 Lc*
: ;
:   (  bS
5 0
'JV!J+%;#@(	$P&
fiCff$"#
fiff
fi	
 8Y0242\5X2Fl8<ffAYZ;>@
J?P
fifffiV
=	V	fffi/Vyzs
fiff
fi!
3T"#
fi
-
:  
GZW+%#@		$ 
fi?ff$"#
fiff
fi	=	V	fffi/Vyz,D3 :
+    
'b=	fJ%c3+3
X+ff-a"#
fi5?Zf!	/GG=+l
   (  
C3S3
X'+fffi,VP=	
3fi!
fi=	/ ,+fi3*S+
'+fffi5


49$6S>fi|$S&TPP-#$'-3-#!'F.H!3*$$;.3''H'ffe,4
!*';'3ffV
    4
 3.HP-#b$'cM'$K''*P'$KSP+

3

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

c#@	E;J#@	fffi+
fi?.+	+#?	$ff.+
-3*
"PB>+"#ffTWff+	ff
fi	W	fffi/P>
ff+fff?	ff
X
fi	>aff+f=+"#ff.3
-
5J?E;
fiP=>+/W5	245	365X0Y:
fiff#@	:ff=3
fi	J	,	$"#
-
fiF	ff#ficX
!$:+		E;
fiP=>+
	WX
"# 

fi	,+%K=	b	fffi/VyzF
-ff
fi
3*"#
fi
-
 :
e5J?E;
fiP=>+/WFA0Y:+
-ff#@u:ffE;
fiP=G	$"#
fi!
fi;"#&
!
fi	J%P=	Tff3w#@		$&
-
<:			c/G		+fff#fiMx
.:
qe5;=	J&
fi	+-T#ff
fi	>"#!.3
fiff{
4

^?:

)5;	GS+!
+fffi2'ff
fi
-	a"#.3
-D.6:
e5;	,X
fi	B	5
 fffV/,b"#D#3
fiqfi$TP=	JE;PT+=	,#ff
fi	:4+fE;G"3X=	,ff+
E;
fiP=ffffiG=ff
'"#P	b=	!24MY	Y8Y025
vE_c
fiff$!
fi		)
fi$%wMff+G+Q
fi.K+
% A8:;28<ff;7A2\C5	365XA2OW_+s
fi.K+L
% 3	G<ff;03	N
;2\;C%Y5X2OW5Kv;=	b%'/GF
=	Yc+%8#@		$ 
fi;=T+	$;
fiqDf*yz;	P$"#
fi
fif		
=3b	>"+S9!		cE;
fi=ff
fi?=	bff*	=	M+PF
F=	J+%K#@	ffX
"P
fi"+SP#+
fi=ff
fi
=+b/,
-=DMWDffXx
XN$D=	Jc
-qP=	Yff'+*5Y7e/>SXfiV+\)"#
fi
-f
fi]Gff*:
	.+P$^
   OS:4
bf!
 b
fi\=	Wff+\=+b=M	P$"#
fi
fi
 W:1+A%'bE=ff
"P=\=	,
'M	
X
fi	BW
fif=	bfff+%8P=	M%P/\  %'T+ff!m45
 X
fi	B?+%<=	M%'/\  T
'3	G<ff;036;24;C;;
fi\"b=	Pb
	=	bm4Q
fif=	Jff'+
"P=V=+
5;P=	Yff'+*yzc.ff
fi	V"#.3
-D.cE;ff3Xfi+E4;f)G.ffP$qS%l4;+\#%'%+:

	5{\=JAD!."#
fi
-LH#
fiP=	Y	 = Yff#fi+M=+C=	>ff'+*yzb++
fffi2'ff
fi
fi	\"#	2
!.3
fiff.QE_fff3Xfi+EG	ff
X%'>E
fi=G5
 ff+\E;
fi=	V)\	$"#
fi
-b+	V=	P$+	$AX
fi	B	c
M"3Xfi$\WAYMG365	A2ZPf=	
	"P
+P$Gff	ff
fi	G	ff-/V5
79
fiSXfi]E_A
fiff	ff"#V=	
 <ff;0WA2]	+.]"#P	:			$"#$P+L%'?	.+!
fifff+	ff
-	
		J$!D
'3<%'J	+	#+
fi*5  Pq!
fi/G>fP*:*x
fi	B\Y"#!.3
fiffM
b	ff$\fff+]+
	"P
+P$1
 <ff;0WA2b$"##	
fi.		PD5  $!>"#&
'.+%4 E;M+.6[<+KbD/,)+$"#.
-	
E=ff>=	b"#P.3
fiff;E_	ff$H#
fi=	;L
 UkU( n b	:)Dn bDL
 \IS-+1:	T	
 TkbD\
 b.:+f(8#
-=	
X
fi	B4:	*:	;=	P$+F
fif=	bff+?
'ffD
x%
fi	,=	b+;+%=	bff+f)#
fi	G3
-$45;I$"#
fiV
 q	5

"#!$;$F
fif/GPJff.3
X 5
$4#_K+#QS3w#$'-'6-.F'SP*)'$#T'3'!P'S  >Kzff4+*.c'L9z'(9X'!z-
'$$''$K4e
 $' *$'# kA
 X'.]+&$F''$L*
 3f>*
 wff$'($4$|S6-.P$#$'c'#
 9z'' 3 4.'6z'Q'  & +43 'HP'b'_3'$'<'''P-&-#w[ KP<3SP_+--D 4
 X#1

6'$'-.







3
	



fi

fiff 
k 



n

{



rmt9ti!t

n

fi


 l

yz{z|~}a

	



v;=	,	.
fibff	ff
fi	Sfi
-=	/
c$A\=	b
ff$?%_.+!
	WE;
fi==	,DffXff+Z+
""#$ 
fi#fi
 <P;2\5X2FM
fiMD\"=	ffD&
-	,
 /w3EH)Z"#
fi
fiVb=	P$+	$AX
fi	B)q	
fi	
	EdP:ffX
fi	B	:	"#.3
-D.FaN	@>
fi35<v;=	J3fi
fi=	//,
-+$;#
fiP=	_Ec=	qG"#/Wfffi
ff+s
)%'	W ""#$w9E=	G3XDP&
fifffiF#N	/GffK	
fi=$K,#@(=$W'%H3
Xfi	+#5
F&
ff<Mff	ff
fi	b	fffi/E;
fi=C
fiff
-
3("#
fi
fi
 >k(  ,D3
   59ZTP	/G
=		=		<P=	+;=K=	!<+%1"#
-K3S3
X'+fffi;JP=	ff+		$
:   (  :+
'N	@	$45KZ
	+Eff#N	JJP	2-fi#4%'	"#
fi*
:         (
  w:E=ff
"P=G
fiff
-
3X
XU$F=	b$+."P=f+f"3XF
%'	"#
fif=%'/?<P=	J#N	/Gff		"#$5



 tkl	  t { rmt  ntmn:rzl	omnfi !k( #" G %$ [<8+?LD05	YZM<ff;
&\[<P"#;=	JffffX*ff+?%'/'>k(  +( 
nPlk0t*)   k :G  (
&



)  n k GW!$+."P=	$K=		=>P=	"#T+%+
Sff+Q%_,+fi	!
fiGff*:D
fi	
=	q!$+."P=L=	
fiU]
-DP3Xfi:K$"=L
-/GV"=	ffD&
-	\ff+uu"3Xx
fi	+)  n    *:KE=ff
"P=
"=	ffD$c+?3
fi#G&
fi	fi[
 /w3E0
-f=+ff*5


 tkl	  t h n-,Wt~n  ntl o w/. & G  O  $ [<>QD05	YMG<ff;
0::(  2143
&    /5
 4.   nomn:6
  
0 ::(  ,
';/G	l  nt=	nlkt,D05	YMG<ff;
 7?
^
1 #fi$"#Tf#fi/Gff;%P/80(  
oM#fi9?
 %'/80 :(  
  W
 
Gfi	
fil  ntnPlk0t:
nzvn>	fSX*#fi/Gff.;+%#)     O   (
 M;0:




q






 

i;#Nff
-	aCff"# 
.Q+%1E;J+#[1#-$"#
fi	G{
 /w3E
fi?=	Tff'+V+>?	$"#
fi
-
JP=	$+	$x
fi	B#:*=	Z	.+
fi	\3X<)D&
fiff->"#$"#!
fiM=	B/w3EJ5>v=	#-$"#
fi\+%
E=ff
"P
= /w3EZ"#P$"#Y	$]	Y)f$"#&
'ff$4:<		,=	?/>+		a
fiEc=ff
"=
fiC
,"#P$"#$
/,
fi=ff;=3b,:)E=ff
"P=?
;E=fff3X*DP&
fifffiJ"#P$"#
fi;+PJ	ff$f,=	,$+."P=?%'ff
fi$5



 tkl	  t h n-,Wt~n { rmt< $ [<)
!_%8ff
0 7 1AI#fi$"#Tl/w3E%'/8
nPlk0t:
=   >0 @L?  0 " (



<P$"#
fi	Gl/w3Ed+/G	D.F,$!+fi
fi	G+V)V"#
fi
-f$!+fi
fi	G,=	$+3[


q



 tkl	  tBA  nl
CrD(E0 "  $ [<)
!+%1ff
  a
0 
+f)V	$"#
fi
fiXl  nt
nPlk0t*) G    GF     0 " (
nzvn1nl 0t*) G     -
H     0 "  
3
I

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

 G)"#
fi
fi?"+Gb		)$W#
fi=	FDG"P=	DD 
fi	Y+W#@D
!
fi	J?=+<.Q=	
	)D&
fi!
fi?ff	
-	>,	EdPf=+Tffff$[



 tkl	  t h nv  omn | . ntK:J L  "  $ [<)
!+%Kff+
  C$"P=V L  "#	PD-G
fi(X 
  L 8"VC.ff$?)#% L S:	+ L K		G"#
-
fif	ff
X%'
fi	,E;
fi=
J l  nt
"J L  " 
  n:l L G4G  L  "
  C$"P=V"#
fi%W
fi  (  E=	DJ	X
"#ff.3
-_W"#
fi
fi>	ff
X%'
fi	GE;
fiP= J 
 LM :-N T[  G L      " (


"
" L  "  N
  n:l L G4G LM
J
nl 0tV=	sX
;+%ff+"#+xfi$"#$f+;x
fi	$qG+Ve5


q







v=	G%'	"#
fi   L   Z.+B$J+"#
fiZffi
fi			.:/>B$J\"#ff\+%T=	Gff'+*:

fi#+D!
+$;=	,"#
fi?
-DfGP*:w+\		
fiPG=	,ff+E;
fi=f=	C$RD
-$f#ff
fi	f+
ff
fi
fi	>"#.3
-D.65*^HM	P;P=f=	b	E;fif	ff$V!q+?P=	b	E;fif"#ff
fi$fff'+*5



 tkl	  t n 'kmln .  "  $ [;PI*:'+4
L M [d,	EfE
fi=f"#
fif+f+?
-ff#@V	ff
R	bPO
) [d,	E$f+%K=	M%'/'P LUkU( nb	 LM
Q
\
 N [Y"#D?+%#
 	 L M R N
 	?$"=+%Lwyz%      n:  RN :ff$"P=V#+$WE;
fi=()
 	?=	J#ff
fi	D L 4  LGM + LM  L OfiN :e=f#+$?E;
-=;)
nPlk0tZ LM :%XN 


q







c+E L GOa		_C"+34X
-	BY)E_?E;J#@ff

fi	,Q
fiGP=	Tff L  + L  :(Sfi	
E;
fi=fP=	b$Rff
-$f#ff
fi	>+?ff
-
fi	"#.3
-D.658c
'"#b=+=	Pb/,
fi=ffC/GbP=+
	GE3VAX
fi	B\=	GE;Vs$"+!>=	PG/,
fi=ffb?/GPG=+Z	GD!."#
fi
-\+% L 
=+;"+>	ff
x%,E;
fiP=G=	cX
fi	B,	)D&
fi
- 5ffv;=ff
K.+!
fi,
8
ffff
"34J=	cE3G jIa		
J
"+39X
fi	B	<#@"#	M=+;=	Y"#.3
-D.F+J+		.+$?E;
-=
 <P;0WA2GP"#	5



q










 tkl	  t k* .<. l@ L  " J " L  "  $ [K)
c+%8ff'+
  C$"=V!+%Kff
fi
fi	Df"+&
-	 L KG! J  
fN 2>
1 G"#D?+%#
^7?
1 C	EX
-	B L :S L 
) 7?
^
1 C	Ed$TP DnbDL\IS-+ Q
 	%>UGN
 	?=	J#ff
fi	G"##3
fiff L   L  R N :	#+$WE;
fi=()
 	%>UG'N :ff.+$?E;
fi=V)
  n:lW N
nPlk0tV=	,+%1ff'+"#+X-$"#$f+TPV

3
X



fi

yz{z|~}a

L :L

	

i$"3X	=+<M=	$1bcX
fi	B   K
KT!%44=+<"+G"#&
'fffib;#ff$,E;
_+
aq""#&
!D!fiVPb#
fi=	S *rb?)D."#
-
fi]'
 5 5J#
fiP=	J		

L

L

RY

ff#fi$ ,.5ZbbP=	b	.+
-V%4>  @Z40Gff	b=ff
'<P=	$+$5Kv;=	b=	PbD 
fifffi
E3(M$+->fP=	$+tu	/G
fi*:*ff/G
fi*:1+]+.
fifftL
fiff+-SG	
-	q.ff
fi	
+?ff
fi
-	"#!.3
fiff.QG=	bff*[






q









 
$
q

$ 

 tkl	  t h nv  omn k nrzl@ L :S L [Z L  "  $ [<)
;+%Kff+
) 71?C	EdP$TP	TkbD\b L :S L \Z L  Q
^
  L <"+V)J"#&
!D!fiG.ffP$f#%' L 9l  nt
fN 2>
1 W"#D?+%#
 	?=	Y"#.3
-D L . L R N :	#+$WE;
fi=()
  n:lW N
  L <"+q"#&
fffi,)J.ffP$V3%' L Jl  nt
 N 2>
1 W"#D?+%#
	

?

=	Y"#.3
-D L  L KPOG-N :	.+$GE
fi=()

  n:lWGN
  C$"=V!+%Kff
fi
fi	D?=+;	D. L yzF#*$"#.F%'/ 	ff
X%
fi	,E;
fiP= J
fN 2>
1 G"#D?+%#
	

f

"#.S
fiD# L   L  + L   L  U N :ffP=V.+$GE
fi=()

	

%

>

UG'N :ff.+$?E;
fi=V)

  n:lW N




nPlk0tq3X*	EOff+"#Xfi$"#$f+FX
-	$	:		:+\6>++

cM=+FX
fi	G> b
',ff
fi		-b$"+CP=V"#(ff$&
-+
fi+?	"#(ff$&
-+
fiV"#	2
.S
fiD#,/,>)Z	ff$45 , 7e>#@+/Gff-:=	\+ E;
xPD?/,
fiff
fi/?3.W+%Jff
fi
-	
"##3
fiff.F=+;/,,	ff$fPG	$"#  &   ]|#]| .   %'/G!  P=+ff#fi$   

^kffW
[ 3 `
 _/_   5D:4+a
 3 `__  !:> b
 _c_^*2 5D5Jw
fi	V$a
M3W
fiff$
-	Gt =	G"#P.3
fiff.
L


<

+




L


b

+



J



	

ff

$



fi


f



.

ffP>	PJ(!/>+
'"P
fiH5
L L
L L
 

C

 



r

n l	nv-6k  ti;tmnzv	ved
{  . 

A  .

-d 

nPlnt~nzv	v 9k 9vln





rzl	6l

~\"  X-$+ViDffffX
fiM.$	+1	PSb=	b	)
fi$+%8P=ff
;3fi!
fi=	/V[
5MI	ff	$[0%'Z+ff0
fi			\	ff-/ E
fi=0
fiff
-
3Y"#
-
fif	:DS):d"#!
fi
    :
X
%  O       g     " 4Z""#$P&%ffxfiuP	>]ff'+i
 hG:c=	0#@($"#	2

-	J=	JPK
-;
 hO
fif+ff>&
fiP+
fi+>
&%'
-	O
 JE;
xX3-E3			ff"#YJ!.+c
fi?E=ff
"Pj
= 

'<P	5
	5MF/Gfffi	$P[< O       k  YE
XX4NVG!+fi	
fi>ff?
X%1	C#@D
!.5

l O 

q	5MI	/?+
"P
fi&w[

k

     

ff-+K/Gb=f"#5

 ,E;
XX4	T"#&
'ff_P=	J+/GMff+H+!
3w"#/G2

 /Gfffi	$+C(!/>+
'"P
fi"+C;#@	ff3
fi	$s%'	=	Db
fiE;
fi	9        (
  
<
$."=ff
-	>G
fi$"#P$f.	=f+%8
34ff+5;v;=	b#+	=V=c,	ff
R	Jff$:ff=	CDffX*ff*:

m/n31'Xff#o\F'DE4X#PJ!''SP-#<3$'&
3
p

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

+]\"3X_P:
 )  n    q	#+$,	(ffyz,"P=ff
Xff]ff"=	ffD&
-	q/w3E Z	#+
fi	

fi.C""#$.WH=	?+
S<ff+C$fffi!
fi	?%P/ "#&
ff
-	q3X;DP&
fifffiGE3	b+%N	@ff
fi	A
fi.5
79
fi	P?K+
 qqff
XX-.+P$<=	+E0#N	/GffMff"#$Y%D
-_		ffJE
fi=W
fi."P=ff
Xff*5
v=	T"#/GfffiP	$$fffiF/G$+K&
-/GfffiJP=+KG+-	
fiCff+>+	)$+.FKMfi$S%w		ff;
fi
=ff
.+	=*:	+A=+ { rmt  nt~nrzl	omnfiE;
XX*ff3X-G
'&
fi;Wfi$3%K	(ffM
x%8	$"#$P+5
I	/?+
"P
fi&M
fi/GffX
-$=+K=ff
K
-$"#$,#+	=C

fiC%H"#<!
 36<ff;;$:K79
-	b	$!.5Kv;=	
.	=f=F=ff
;	G)$"+JP=	J"=ff
X'fff+%8,
34ff+f		ffJ+J3x9Sfi+!
N	@	$
%'J%
 /w3r
E qetu$"P=i"P=ff
X=CV
X*ffJ*:9.ff
fi	):4Jff
fi
-	q"#P.3
fiff	ff$\fN	@
q5  >&
-"#J	$R	D;#N	/Gff.;ff-a	?/GT"#.3
-D.6:$"P=>% 5X3	W<"P=ff
Xff?
-	=	
fi
=ff
b"#/W/,
fi/GffMf=	+s
E qL=	ff,N	@	$45Gv;=	#%'>Dff+\\=	C%PD!
fibE;
XX<
X*
%P/?=	cff+ff=	s%PD!
fiF
fif=	JE3,
fiN	@(${
 WA@B;/w3EJ:)+f=	JP+/Gbff+fE
XX
	T+	)$+Mf=	M%'ff
fi;/GbP=+f"#5

ut8vXv	!t/xw;0WA2OWl 



n   
h :

h

e,

n Wtmn



ntlnv



tiv

 E;;/Gff
fi	$,+)+:+=	;$a	.b"#P	F
			$"#$+Pb
fi>cff+		F=+%'/?
 
fffi?#N	/Gffb#+
fi65_jkI:e%c#@e+/Wfffi:wffff$c	,=	/V5c+E;$:ff=	f	+
ff
=	,&
c%'bP."#
fi	?Jff$"P
'&
fiME=ff
'"=
M?	$"#$+P"#/G	ffb+%;ff+Z	+	.
fi
?
"#$i
fiuP=	V	#@	$"#!
fi*5 ~F#%V#@	ff3
fiff
-	=	."#
fi]		"#$:=	+E;$:FE;
	/G/>
fiUf=	
 <ff;0WA2Z	.!"#	$a=+?$"#.=	SEr+LE=ffuff+uEa#N	$45 

X*ff_P$VP"#	M
$?%';$"P=f+%8P=	J=	bff$;%8#N	/WD$[
IPd	
fi
-*50=	]	EP
 4C
f	ff$0PuLff+ '%	"#!
fi^
   L   4.:c=	
++
fffi2'ff
fi
fi	V"#!.3
fiff.	"P
+$E;
fiP=V
-.T"#
fiZ"P=	/>f+G3'V	ff$4:1Sfi	
E
fi=? E;,.ff!
fi	G"#.S
fiD#<!	
fi	G=_P=	b	EPf(""#	.c3%P=	M
fiff
fi!
3!
V)#%,=	Jff3Q!*5bv;=	,$M""#/W+D
fi	?=	$G"#P.3
fiff.M+YSX8%<=	
%''
/ PQ
 UkU b	V
 \ Q 5
g

;+3*x
fi	B	
fi
fi*5;0=	\,X
-	B>+%<P=	b%'/4>  OT
c	ff$G=	,ff+\%	"#
-
   ^  
'J3!	ff$4:K3-	>E
fi=\S+!
+fffi2'ff
fi
-	
L G4).:wZ.ff
-	V"#.S
fiDl
"#.3
-D.9	
-	J=+KP=	T#fi$"#$aD#"#
fi
fiY*
% 4*"#SXfiJ!.=		PD 
fi2
!
fi?$Rff
-$?D?=	,#fi$"#$?	$"#
fi
fif
% +5<v;=	$J"#!.3
fiff.FE;
Xx)J+		.$
g

E
fi=f,$V"#	Pb+%8P=	M%P/yPDbffL4IS-+      Q 5

v =	P$+J$!+fi	
fi*5f0=	iAX
fi	B4  OY
'b=	$	$Zff\ 4:K=	WX
fi	BZ"+]
g ;
$!+fi$'%'	"#
fiT)      eH  MD	
fi	\	f+%T=	PV.s+%"#!.3
fiff.[G
#ff
fi	\+%b=	?%/ 4L^4:;+u#ff
fi	\+%b=	f%'/ ^4:;,S+
'+fffi2'ff
fi
fi	
"#!.3
fiff.	!
fi	,=+<P=	T=	P$+ff
fi	CD#"#
fi
fiG+.
% 4ffD$F	"#SXfib%H3 
X%
=	cX
fi	B4yzF	)D&
fi!
fi1
 W58v=	$J"##3
fiff.KE;
xXw)J+		.+P$GE;
-=C$f"#	P
+%=	b%''
/ P	
 TkbD\
 b L >:
S L \Z L  Q 5
v;=ff
M"#/Gff-$M	b
fiE+%;	.+
-GHP#N	/GD6ff+	ff
fi	:*!fE_,	+E	\fP=	
#@( 
fi;=_P	V=ff
'<ff'+		;
fiff>+V	+	
fib3fi
fi=	/V5

z;!!+ 


(''@ 

v;=	J+bE;,/>+
X*"#$;)E_	.+!
fib+f	+	
-bff+	ff
fi	)[
3
{

fi

yz{z|~}a

	

Null Plan

Retraction

Fitted
Library Plan

Extension
Working Plan?

79
fi	,[<8+?#N	/Gff?."#!
fif$+#"=?
fi

.

rmtZ"#5

Plan Extension

79
fi	P	[M>#N	/WDPff"#$Cff+?.+$U(T(gjVE;
-=W;+%8	E
+V	
fi!
fi3*fT"#.3
-D$5

ff+:ff$"P=fE;
fi=

5;^Hu	+	!
fifff+	ff
-	Z=	?
W=Y5)<ff0<E<ff;36<5X;>?0Y	=!?
fiLE=ff
"P=L=	fff+]x
fi	.+

$+."P=	$?%'TWff+f="Pfiff#fi?/>+."P=	$;=	s
fi			
-ff
fi
31+AD39%P/>	=	sX
fi	.
ff+?
F=	
 0C2|MW36;CsG/>+#"=f=	J"#	PDc	fffi/V5
e5  	
 +	!
fiJff'+	ff
fi	f
fibE;
-=V=ff
'M
fi$qq3 P$V
3Kff+*:*q"Z2
."#ff'+	ff
fi	f"#.S
fiD#T	ff$E=	\=	,ffVEc
fi+
-3fi>	.+$44	#+
fi
ff+	ff
fi	,
fiE
fi=f,ff+fE;
-=f	>"#P.3
fiff.;+f"+fff-	A	E	$5
&^ >=	;E_.	:)=f	#+
fiM+>	+	
fiMff+	ff
-	Y+b$+#"=ff
fi	C%'_,fi	
fiWff+

fi?PG+%;+
S<ff+:9(	C	.+!
fi,ff+	ff
fi	V!.+.bb=	fH	ff
R	+TPDb%_=	Gff'+
?E=	$,		
fiGff'+	ff
fi	V)+
fiGY/W+Pff
fi.+PVff"#W
fi]=	?HDP&
fifffiZ+,
+fi	!
fi*:ffDP&
fifffi>=	bff$:ffff&
fifffif+/WM
fiDP
fi;		ff+.5
79
fi	Yb=	+ET=+	+	.
fif.+P.<+M+?
fiff
fiF	(ff:)+fG+-	
fi?/,
fi=ff+	$
.#-SEM\
fiW
fi0=	\\W
fiL
X*ff!		Z3fi=	$5  f]$fffi?=	Z	+	.
fi
3fi
fi=	//,Cf+fffi?V/G+.	=	?WD
 <ff;>@A?5	2GF?"#.S
fiD#c%/=	?ff+
E;#X1;/G+Wff+E,=	bPbDm
 0CC5X2FJ"#P.3
fiff.5
79
fi	$bf+
 q=	+E=	GE3V=ff
M/WS/GDM
'b""#/GffX
'=	$4[bff+ <P;2\;@B;2\34
s=	
Hfffi)K#+
fif)%'/G$ADf,	.
fibff		$5<^&.+B$,+!
3*ff+f=	b=	
-U
+ff"#$c
-bE;
fi==+Mff+*yzB
 7nG5XYC<ff;>2:4fb+%<ff+c
'ffD
'"38P>=	C
fi			Cff+#@e"#	
%=3
fi	,	b/W{
 /w3E3
-$45
8+!
 <ff;36<ff07>365XA2M.B$*cff+JJ=	F=	
fiU,+J"P=	ffD$T"+P3X
fi	B4:38!1+%"#P.3
fiff.

 <ff;@BA?>;$5v;=Gff+]
Wff"#$LL=	=	
fiULE;
fi=L=	+ffV&E=ff
"P=]
,/>+PB$]%'
	
fi
-3<#"#
fi4#:13fi	fE;
fi=ZP=	>ff*yzJ&
-ffX
fi	DaH	$ff
fi	\3Xf
 0Y36;><2\0365X?>;,E$	M+%
3$

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

Plan Retraction

79
fi	Pq	[ML."#!
fi]ff"#$?+ K9.+$]ff+E;
fi=u+	=	VK9ff+0+u!.3
&
fiffX
-	Yff'+;.+$
 U(T(gj15

2-N	@ff
fi	?=	/w3EE=	ffbN	@VE;P."#$W%'/ =	Jff4.5_v=	Y&
fiffx
fi	D+Pb=	V.$?%'
	
fi!
fi3*#N	/Gff$5
^&LI$"#
fi?E;>=	+E=+b=ff
'J&
fi/WfffiG"=	/W#t`+	/Gff
fi	\?	.+
-,ff+		$yzs2
N	/Gffq+ff
xX
fiLE;
fi=0=	Z+ff
xX
fiLL#"#V"##3
fiff.&tL
?ff"P
fifff]
fi/Wfffi/Gfffff+
	+	#+
fi*59^H?=	FE_.	:E;	PS=+K=	b	+	!
fi;ff+		;E;
Xxw
XXfffi,	(ff"#MSSX

+-	
fiM	ff	$##:ff
fib"+fN>fi	
fif	W/>+cE=	b
-V=	Cff+q!"#J=	sX
fi	.
ff+Lff'"#$C
fiC
fiff
fi!
3XXL "#/Gfffi	$.:<+
fiG!
XXTffD$!*yG#@	fffif+$a+%T=	fffL
$ff		+fffi 	/?+
"P
fi&#5

t  
k 
n

n

wr

.

l	omn

{



rmt9ti!t

n

fi


 l

<

v;=	b	+	.
fiG3fi
fi=	/)%'/>;J!.+	+.,	P$ff=	2-N.$."=*:/>3
fiff.3
-ff
fi	b=	b$+."P=
%PD!
fi8<bF+%w3
-.$"P=G+%wP=	;%/ }h>:K*(L%'/ }h?:UT(gj*C5^HG#
fiP=	_"}h0
'
?H)D&
fiff-,
fi"#/Gff-+<ff+f+
 K*G
 UT gjf
fi
"$F=	JE3G,/>+ff
-	ff+M=	Jff'+f
	.+PT=	bff'+*yzF	#
fi=ff#F
fi?=	J$+."P=V"#[ UT(gjf/G$+	.+W
 hGy_!""#$.D
%	P=	#Nff
fi	C
fiM 	
fi	G	EdP_c
 ~$T"#!.3
fiff.##@e"#fi>Q
fif	.+
fiTff	ff
fi	
K*,/G$+F	.+P
 hGyz;""#$P.FffG."#
fi	J	T+%=	TP#N	/GD#</?ffTEc=	f=	Tff'+
EF
fi+
-3XfiG"#P"#$45







q

 tkl	  t { rmt n ir . l	omnfi !k( #" G #" (!^   $ [<8+?LD05	YZM<ff;
(!^% O 71<ff;36<5X;>?;MJff'+f%'9k>  +*  %'/ (g^:  
 G      O  2
1 0C2| MW3k(!^%  >,/>+#"=+> >(  +G  #@e"#!fi
& \?  O 7,
1   :  G  g^> O  
 36A<P;& @?  O W
fig^   G

nPlk0t*& \?  O 

l%b

xJb'effLI%#BUKKwbaMj4b*LjkUOb

I3Lj

TQ	kRK

 	< 
";ff+	2'P
fi+3w3fi
fi=	/ 
<Rff
fiM&
fi/Gfffi[9E;T"+GP=	ff+,x
fi	.+:+/?+."P=ff
fi	M%/>

fi,=	FX
fi	.Tff'+*yzDSDE;
fi=,=	F
fi			KD3 54Z;P
fiF=	FX
fi	.+Pbff+E;
fiP=J=	;$$
D	/,)T+%K/>+#"=	$:ff=		$+B?
fi$;fff"#	D!
fi	G=	bff	/,M+%8/?+."P=	$;E;f=	b
-			

fiff
fi
'3e"#
fi
fiF+,=	
fiff
fi
Se"#
-
fiQ+%w=	M
fi$Cff5KvF
fi$
-G=	ff	/,;+%w/?+."P=	$
%P=fD31+W
fiff
-
3*#@		$&
fi+M	B\+ff
fiP.+&
Xfi5
3

fi

yz{z|~}a

	

v=ff
b		"#$,#fi$"##JV 
fi	+fi,x
fi	.+ff+*:		C
fi.c
fiff
-
3_+DS_"#
fi
fib	$	
/>+#"=?=	M
fi			;
-ff
fi
3*+?DSw#@		$&
fi;#@e"#fi5Kv;=	!0C2|MW36@B;2\34		"#$		;D3F
=	sX
fi	.+PGff+=++	$
fi=	M
fi			MD3*		b+C	T3fiP$ffG
-f=	Jff*:+Vff#-$
DSc%P/=	,X
-	.+ff+\=+,ffV	J+	)$+b
-Z=	,
fi			CD3<#@		$ 
fi*5>v=	,X
fi	.
ff+*y4
fiff
-
3("#
fi
fi9+"=	$,&
fi/,
X'$!fiTPT/>."=C=	K
-			K	fffi/ff$"#
fi	!
fi*51v=	
"+S1X
-	B(M+G3$4[M,X
-	Bf
fi=	CX
fi	.+Pfff+V%<=	C%P/ 4   OE=	P1
 \<=M)
ff#fi$A$"#/W$b+V)Z"#
fi
fif+%<=	b%'/   Se
X%[b=cZff#fi$4:)=	sX
fi	B?
fi.!#X%
"+Z)>P/G+$45>cE"#
fi
fiC+>SV	ff$%',+D\	ED3K%'/>65>v;=ff
s	E
ff+A
c+.+ff$?GW#N	/Gffb+%<=	,Dffx8fff%'TP=	a"#	PDM	fffi/:4		T	ffX
-B
=	FX
fi	.bff+C
fi
	1	$"#$P+
Xfi,"#/GfffiP5<IsI$"#
fiGc%'1/Wff.3
X'*W=	;
fi+3
+f3/GffT3-
fi=	/>65
v;=	=	Y	+	.+
->	=b
_
fiff
fi
$4:ffE=ff
"P=V/G	
XN$c=	JP
fi$?fff>	P(ff"#,
+fi	!
fiVff'+%bP=	G	E	fffi/5Yv;=ff
'b+fi	
-
M$fP=	Jx
fi	.+ W36A<P0>F;b	
fi	:
E=ff
"P=qff$"P
ff$MEc=	=	f=	+EdP>PJ=	Cff+f%'!J
-V	$R	Dbff	ff
fi	>ff
'(ff$65
v;=	VR	$
fi]+O
% G;3	;<CZf\	E;-i		$!+fi	
fi"PB
fiDPV=	fff]X
fi	.+PV
'
+
fi/G).+ffM	:1&
-"#G=3
fi	?/GPYff'+c
fiZ=	,ffVx
fi	.+/>+B$c=	,x
fi	.+ff2'!
+3
		"#$C.+BWfi	35  L=	?=	,=+4:<P
fi	/>+ffqff'+s
fiP=	GX
-	.+
fi"#$$C=	
"="#$=_	bE;
XX*,G"PfiD!b/>+."P=fGG	$R	ff
fi			c	fffi/V5
^ff$3Xfib=	;ffJx
fi	.+J!=	ff,"#&
!1+%wMP#+
fi#fi!/>3X+%<R3X
-.+&
fi#fib
X*ff.
+fi	!
fiF"#/G/WfffiG	""#	
fi	ffJ	Pfffi/>:ff		TW"=+#"#
fiU$
X>%8RSX
fi.+!
fi+#fiG
X*2
DM+?+%<"#/G/Gff->	""#	
fi	?"+fC=+.?G"#/Gbff5;+Z/>+B$<	?"#DP
fi		
fi>W=	
R	$!
fi?+%1E=!=	ff?+	$+
fi>P=	TffGX
-	.+:ff+?	;/Gff
fi
'"3wE;Ba
fiVI$"#!
fifY2
	/G$;b	P$ff/,
fi	$?ff'+,X
fi	#+,E=ff
"P=,
Q	+	/Gff$Gff	
-	YP=	T#@	
-/GD#3w!
35
IGe dK#-D:4$ff%+?
xXfi	/,
fi
fi	b
-D$!
fiD+!
>+%K=	$M
'	$5

tfiff R
k 

n

n

ir

.

lrzl	



t

o w/.

v;=	
     :GL%'	"#
fi
f&
-/,
X+?]
fi#?	.+
-Z"#	DP+(
 )  n k GG
#@e"#	
fi>P=	M+;"M?ff+f#fi$"#$W%';#N	/GffF
Q%	P=	#N	$45K^&f=	J"M+%
	+	.
fi*:*?+P
3Kff+Z/a
fi=ffbG/>B$A%b#N	/GffYJ3fi
fi+#fif%'!
 <ff;36<ff07>365XA2:
+\=	?3fi!
fi=	/r/Y!bBP."PBV+%;E=ff
"P=*5>v;=ffb=	a%D
-)$"#/G$CVC+%_3
-.M+%
=	C%P/ hGK
: \E=	P
 h
MW+
S1ff+\++
 W
T?ff/,+<ff	
fi	f
 C5X<ff;7365	A2:)#
fi=	
UT(gjVf
 K958v=	B
 UT(gjq"T/W$+;#N	b=	Mff+?%'	=	3:
->E=ff
'"=f"b=	9
 )     O 
%	"#
-f
M"3X-$4:	#@e"#fif=	,+/G,;
-V	.
fi*5  
fiP$"#
fi+
% K9P$fffi.F
-q?"3XK
)  G   O :E=ff
"P=?
ff#N	$#fi+EJ5






q








 9tkl	  t n ir . lrzl	  t o */. !>k(   O  $ [<8+fLD05	YMG<ff;
0:(  213Gk(   O :OK*4b:kW>k(   O *:U(T(gj*95
 4.   no~n6
  
0 :(  ,
/G	l  nt=nl 0t!D05	YMG<ff;
}w
 : 2>
1 !#fi$"#T+f#fi/WD;%'/80:  
oM#fiB4
 : %/0   
  G
 
'G+-	
fil  nt	nlkt+
  ,
  UT(gjl  nt
  b$"P=Vff(  		$?ff()     O   4 N 
3$

fi yz){	{z{z0{ 
 	




 

t 

nzvn

h

/

nPlr4l	!t

h

 !

mez)zx	0	yz{



zy	yz"z{

 	m : UT(gj*0P;0:(  

K9Ul



nt

	fSX*#fi/Gff.;+%#)    )   (   (
 M;0::(  

-,

n %tmn



ntl	v

^H!$+%	
-	q+	$"#!
fi	V"+3FX
fi	B	:*P."#
-\/G+$b"P=	+
"#$b/?ffGE=	]=	
X
fi	#+ZffuEC
fi
fi3Xfi	.+$45`+?R)     O u#fi$"##G/w3E
fiL=	\"#	ff
ff+?+G		QJ=	%D
-<3Xw
X*ffKE$	+%4N	@ff
fi	J=	 /w$EC:e)    G)  n k :C.+B$
?	
fib#N	/GffY"P=	+
"#:*!$M=	>!("P
$$ZP"#	,V"#/Wfffi#fi/G+,=+
#N	/Gff$:+\		Mf=	C%'ff
fib3XK+%<=	>3-+
XCE$	c=+M=	G#N	/Gffb/,
fi=D
=3b/>ff5
: K*
 ;E
fi=Z
 b79
fi	P q
XXfi!.+$:4P."#
fiqPff"#$bVR		?DPV+%=	,%'/ }hGQ
.+PD.?
% h?yz,3f.$ K*b3fi	fE
fi=J+
% hGyzC&
fiffX
-	D:*$"=].+$
 U(T(gj15 
	$"P
Mff#Nff
fi
fiW+%;&
fiffX
-	D;
'K=	T!<+%4#N	/Gff.FW
 hGyzKDF=+<+P	[
 5cWA@BA<)84G5	7
36AWh>5QZJff#N	b
!/G	=ff
'/F%'+Xfi+E[

e,
 t#6OLAl8(YZ02W}h ( 024Ch $ 0<ff;c
/G	=ff
"|MW3v5X2m70W;
- (36;ff84W0F<P;;@
g 3	;<ff;!5cWS0    @B0885X2FD<ffA@ W36;H84WS5X2Vh ( 024Ch $ WM7V3	G037A<<ff;W|8:A2\C5X2F
W36;ff8\W0?;l5XC;>24365	70Y240@B;WRe360;3	G;7A<<ff;nWe8A24C;>247;f36A,;{ ( Z $ Z
k!36A
 ( ZE $ Z

!29@
> 5	2W{0F<ff;;@
    (h $
g \  W(h ( 5 b{
> <ffC;><5	2GFW0>F<ff;;[
 i (h $
g \*^W(h ( 5 {
 5	24C5	2GF,7A2W36<P05X2\3	W0F<ff;;[
 (h ( 5 
 b_ G9 4h $k  ;<ff;_  [5W0?0<5	0Y;B5X2W36;H8 AffDh (
g _  )
024CU_   5cW3	G;,7A<<ff;W|8:A2\C5	2GF!?>0<5X0Y;5	2W36;H8{AffDh $ 024C
 5WS0%7A2W360243
 5W;LDA<Mb
 _  9)
 02\CG>b
 _ )

g Y5c;kL
 b_ _  $Th $!  ;<ff;T_  024Ca_    0<P;
g _  _   +:h ( 5 
?>0<5X0Y;W5X2W36;H84W  024C AHDh ( <ff;nWe8;7>365X?>;Y E  024CU_ :}_ G
  0<P;l3	G;B7A<<ff;N
W|8:A24C5	2GF,?0<5X0:Y;WS5	2W36;ff84Wf{02\Cf AffDh $ <ff;W|8:;7365	?;>YZE
 5W;LDA<Mb
 _  _  
 $02\C?`
 _ 4[G
 $ 
g Y5c;kL

n Wtil	

v;=ff
'Jff#Nff
fi
-\
fi/Gffx
fi$M=+C E;?
!/G	=ff
'"Jff'+b=3GP=	/GG)i"#
-
fiC+
=	$+P	$fx
fi	B(McE;#X 5TcC=+ME_Wff+c/>3f=$Y"#P$
-	VM+A
ffD!
"3
.ff
-	D<+
 24A3	)
'/GP	=ff
"+:+=	+E_$:D&
-"#=	G"+f
X*KG	MK/GPT"+3)X
fi	B	5
3$

fi

yz{z|~}a

	

v=	JR	$!
fiV	+Ed
$;;PGE=ff
"P=qff$"P
 
fi"+C.$AE=	V/WS
fi	,	ffE.W
fi
=	G"#,+%<
3ff+5Jv=	a 
fi/Gfffi$b+E;c
c=+9)  G  )    Gf/,T)G+fffi
C#X
fi/,
fiT+ff>ff$"P
&
->P=+"#ffW=$/>ffMDO)  n    5i;#N	/GffTff$"P
&
-
/>ffbffV
 )  n    "+fP$fffi;
fifP=	M%+xfi+E;
fi	J#-/GD#;#
fi	f	ff$??,ff+*[
g] &
fi	+fi,"+3X
fi	B4:	fffibV.ff!
fi	"#.3
-Dff-ff
fi
-	"#!.3
fiff.F
-$
N	@q+V)Z"#
fi
fi*5<^&qP=ff
",3X1P=	a"#.3
-D.FE;
xX1,.$?E;
fiP=f=	J$
PD bffL 4I+fi
 \   Q 5
	ELff-Y\"+P3;X
fi	B4:
fiP$]N	@i+L)u"#
fi
fi*5\^HuP=ff
,"? E;
.ff
fi	G"#!.3
fiff.;+G+%Kff
fi
fi	f"#P.3
fiff.;	"P
+P$GE;
-=f=	Y!fE;
XX*)
.+$aE;
fi=?=	b$!:
 PL
 UkU b	
  Q :+?+f.ff!
fi	G"#.S
fiD;+f,$"#f;+%
ff
-
fi	>"#P.3
fiff.KE
XX*,	ff$V3-	,E;
fi=f=	b	EX
fi	B4:+)+5

g]

 #ff
fi	Y"#.3
-D
fi!$WMN	@bP=	$+<#
-=	<ffG	/W
fi,;ff/G
-*51v;=ff
'
g G
"#.3
-DbE;
xX<?.+$VE
fi=iP	TkbD\b L >:
S L \Z L  Q E=	4
b=	?=	$ff
fi	
!*5
 C+%T++
+ff-2'ff
fi
fi	q"#.3
-D.Mff-bE;f.ff
fi	\"##3
fiff.c
fiP$ZAN	@
P=	$+<ffG+.
fi*5Kv;=	$b"#P.3
fiff.E;
XxwM.+$,E;
fiP=*P	:TbD\b L %:
S L \Z L  Q 5

g

 
fi	+fiJ"3xPO)    )   k G>=	ff?=	#%'bP."#	J!"=#N	/Gffff$"P
 
fi*:
E=ff
"P=V+/G	ff.F,/G+
fi	,=	J!("P
$f;+%K.ff
fi	ff:ffff
fi
fi	>"#!.3
fiff.:ff:)+
X
fi	B	;%'/ =	Jff*5Tc
"#C=+T?ff$"P
&
fiq"#P$	M"PfiD!#fif>?M+%K
ffff
"3
 <ff;0WA2
"#P	$F
fi\,ff+*:!G."#
fi	G>ff$"P
'&
fi?%'/aff+f$3xfi/G	ff.;,/G+
fi	>G!
+%<"#.S
fiD#KE;
fiP=?
ffD!
"3*.+D6:(Sfi	,E;
fi=fP=	#
fi	"P
+$Wx
fi	B(;+5
v;=	b	J#@"#	
fiG=ff
c"#$)ff"#C
;=	s%"#=+P=	Jff$"P
&
fi>	G
Gff'+]H$
 PL
 UU b	:
 k
 Q ;
'S
 0YuL0E>W/>ffaM+M+%_>ff$"P
'&
fi\f	\,x
fi	BZHP$
PD bffL \ISfi
 
k Q .:ff,=	$ME_,ff$"P
&
fi<=	ff'G)b."#P$G;b3
-_FE;#X 59ZTE
XXwP$+
=	JE;GM+.+PJff$"P
&
fi6:			T	3-
X=	/E;
Xx1	C=+T?A
;/G+$W%'/r
ff+VcDVF
fi.Q"+3*x
fi	B,
;P."#$45
 fi=		=f=	G"=	+
'"#J+%_Gff$"P
'&
fi>P."#;
'/>ffJ	ffP/,
fiff
!
"3Xfi:(
fiT"+		M
/>ffV+Pff
fi.+!
-:8 
fi"#f=	fff+		G"#ff']	,=$f	.+$=	Vff$"P
 
fiC
fiL+ff.ff$5
7	?#@+/Gfffi:;E=		ff
X
fi	]ff+B
 h>:;=	ff+		?/,
fi=ffG=3\"#$+$0X
-	^
B 4  Oq+
+
fiDP(ff"#$\?M+%<.ff
-	>Mff
fi
fi	f"#P.3
fiff.
 ?	$"#M=ff
X
fi	B?%'/r#
-	
=	$+P	$]DL+	=	>!^
 45iv=	V#"#
fi]3fi!
fi=	//,WV+fffifPqP."#,#
fi=	
ff$"P
&
fi ff#fiC=	bx
fi	B>T=	,"##3
fiff.#.:ff		M=	$JE;>ff$"P
 
fiM+b	bff/G/G
'"+5;^'%
 
;ff#fi$4%: L)$"#/G$;=	P$+	$?+D3
fi*:		;
X% 
'_ff#-$4:ff=	*
 O$"#/W$	H /	5
v9Z	$"#f+DS
fiCfi$3
-	Z=	Vff'+uE;
-=`	)ff /	fP:FX
fi	B	:F"#.3
-D.6:KE;
3Xfi+E0=	J3fi
fi=	/W."#;ff-f=	DJff$"P
 
fi;=T+!
 ;n8:AW;C5F^Hff%'/>3xfi:	Gff$"P
&
fi

F#@()D$W
X%*	GP=	"#.3
-D.9
->=	bff'+ff)f?=	b"#P		ff$?,=	Tff'+>ff
=+ff$"P
&
fi*5<v;=	M%'/>31ff#Nff
fi!
fif+%K#@()D$W
c.+$W
-f/>F+[
% <ff;0WA2OW8E
fi=ff
fiVCff+*:
&
fi"#YE;J	$V+)+Yff$"P
 
fiM	V"#!.3
fiff.;P>Gff'+V=T+C.+$AE;
fi=?
'ffD
'"3
$65


3

fi yz){	{z{z0{ 
 	

-,
e 

n %til	

 

mez)zx	0	yz{

#6p<ff;0WA2( 5cW#@()D$5X2 8Y02Vh5 D
5cWSAffDS3	G;vDA<@P 	:TbD\b4   Q DA<WA@B;BYZ5	2l4 




zy	yz"z{

t

PDbffL\ISfi=

5cWSAffDS3	G;vDA<@

Q

   







DA<{WA@B;BY5X2O      02\C

|0Th7A243605	2W24A%<ff;0WA2mAffDS3	;DA<@8P	:Tb1D\b      Q  02\C
H 
 ;5	3	G;<,4{8:0<365	7598:036;nW5	2024A3	G;><Y5X2O4   c  A<,4!CA;nWY	V088;0<%5	2
024E{8(<PA36;7>36;C%3	G<ff;03.AffDB3	G;vDA<@P 	:TbD4b %*  Z4 Q  
 

PLUkU( nb	 M
Q

5cWSAffDS3	G;vDA<@

Rh

024C

7A2\3605	2W24A%YZ5	2!AffDS3	;DA<@p

M   

v =	GN.!a]=ff
fi.]"$,+W%H3
fifiZP.3
fi=ff%'+E+4[G"#.S
fiD#b=+,$!+fif=	$+

"+V3-E3	K)J#"#$4:	+fGPV"+ffffiG)J/WS$,
X%
fi;	,fi	;+
"P
-+$
-V+D
"+S*X
fi	B	5
v=	$"#f"Jff$$_!/GM#@(ff+
fi*:=	+E_$5Kv;=	MN.	4"J3	<P=+_sX
fi	B
"+		Fbff#fi$C%'/Mff+>fi	,=	M+T"#!.3
fiff.9
fiW=	ff+W	$"#
fi	M
-K%'/
,=	$tu=	E
M=	J"##3
fiff.<	ff$A,$+-TP=	b=	$+;E;ff?)$"#/GJ	)ff /	5
v;=	T$"#>	4"M+.	F+D3
-K=	;%'+Xfi+E;
X	J)$"P
3*"[K		ffTP=+
 hd"#D.S
fifffi
E_cX
fi	B	
: 4  _+,
 <  ff5K7		=	P/G:		)D;=+
 \ff$,M=	$+Kl
 <  ff:+		<
	
fiKff$"P
&
-J$!+fi$C=+=	$$5  	/a
fi=ff1)_P/G	$Cb/G+F=	FX
fi	BB4>  O_+
3fi	bE
fi=,
fiKP=	T
 4:D&
fi"#
 44E_ff,	b-	<T+ffY		PDc
fiGP=	ff+*5L~F	_ff+
-	
fE;ffAfi$3G	)ff /	J!"#	C
fi=	,ff+*:*/G#fiVP=	a"#.3
-D.c=+bE;G	ff$
,$+-=	b=	P$+
 %  GZn4J5  	Tff#Nff
-
fiW%_#@	ff$?+.D$QN.!_P=+Y!
E;
XX<)>P/G+$E=		C
fiJ"#$$sq!>?		)DW
fiZ=	Wff+*yzC"+3_P"#	f
 55
E=		Q
fi.9!X
fi	Bb
'K/G+$)#:+		<=+<ff
fi	JJE
XX		Kfi$3	)ff /	;"#P.3
fiff.

fif=	bff*5
c+E`P=	T#ff;
fi?E=ff
"P=Vff$"P
&
fi;"+f)JP."#$?"+fJ!.+$?&
fi/Gff-w[K,ff$"P
&
fiV"+
bP."#$?ff-,
X%*
fi#_	"P
+$W$?
F#@()D$45  )
fi	?=ff
F#ff
fi	,/G$+;P=+;=	
ff+\E;
Xx<	Y"#ff.3
-q	)ff /	,"##3
fiff.:)X
fi	B	:4J!$Rff
-S3fifffiE;Y/a
fi=ffJ3
=+."#
fi	ff-b#@()D$,ff$"P
&
fiK"#$)	P=	_P.F.ff
fiCE=ff
"P=ac	.
fi
ff+		S
 @B5FG3vG0?;B@B0C;M=	DJff$"P
'&
fi;
fi+
fiSXX5
<.3
-ff
fi	b."#
fiGPJ	""#	;
fi?=ff
K.ff;/,
fi=ff_/,)T+-YP$
"#!
fi:,E;
/>+B;E;
-/GP.+ffK++
fi65179
fi.!$:$	=+KP=	.ffK+%4."#
fiC

 2\A3	"#.S
fi	$
J)b=	M.M+%1P=	T#ff_!$GE=	fP=	X
-	.+,ff+?E<"#P$+$atfffi,=	M.M+%
A24;c+%1=	,ff$"P
&
fi	2'.ff
fi	ff<P=+
 7AMYCJ=3M\$?P>"#$+bP=	MX
fi	.+Wff+*5FI$"#4:
E_?
fi$"#b=	GP$ffJ\I$"#!
fiLD:9E=ff
"P=\#@(ffS
fib=	+E9*	f3
fi,.+
X$:4"#	ff$
+Z=		
!
":	"#ff&
ff$Pf=	$b$P
"#
fi<fff"#
fi	G;/?"#G).+.5
c#@(CE_W	$ffJ=	O
 )  G G )  n  f%'	"#
fi*5fc
"#,=	+E=	?ff#Nff
fi
fi/,
fi.
=++%K
-.;	.
fiJ"#	ff
 )     O *[K=	s+P"P=	ffD$Ml
 /w3E+A	MCX
'
=+K
-"Pfiff$3X4DP&
fifffiE3	K+%*N	@ff
fi	C
fi$:=	c%P/G_"P=	Dff$;+>#@	ff$fff$"P
&
fi*:4<ff;@BA?>;W
=	J"##3
fiff.F=+;
fi
fi3XfiCN	@	$?
fi3:(fR		$T3xP=	J3fi
fiME$	F+%N	@D
fi	a
fi$5

3
	

fi


q




	

 tkl	  t h nPlr4l h ne,Wtmn  ntl@ $ [<)
c+% 8+*:oc
fi$"#!
fik
)\[d#fi$"#M+f#@()D$A$
  =	Pb
F	G#@	D!$f$!Xl  nt=nPlk0tT3e5D5
7)
0 : N [)  -  L G     ) " 
  n:l} N Z K9:
  C$"P=fff+(NN 	P	$fffj=  G >0 O\L?  0 " NS 
   NN 
F	;
/G	=ff
"cO
 l  nt  nl NN Z UT(gj 




yz{z|~}a



nl 0tq3xff'+*:
fi$"#!
fif3
fi#_"#Xfi$"#$W
fi?x
fi	$;>+fe5

v =	fE3ZPqP/G+>P=	V"#	PP("P
'+$E;
fi=u+]#@	D$$uff	WL=	

D)>%P=	>$*5Vv;=	W%'	"#
fia)  e  L     	s=	!/w3E!("P
$\E;
fiP=Z=	

fi			b$qME_#xQc=	,ff+\		ff"#$\ffV/WS
fi	?=	G+			!
+J"#!.3
fiff.:eX
fi	B	:
+Z!5f
"#G=J=	>"#	ffX
fi	V)E_X
fi	B\+]ff$"P
 
fiM
'b/>ffW=	[JEc=	
=	sFX
fi	BfP>GA
ff#fi$A=	Y!f
cff#fi$fPD5;7	=ff
;P$E_Jff?	=3C
=+fiGP=	>"G%P/G+
fi	VA$q%P=	,%
/ PL
 UkU( n b	VI Q [,fZ)$"#/G$C#@	D$
fffiGEc=	Vbx
fi	B,
;ff#fi$4:e		_P=ff
Q%	"#
-f/G+$Q=	JW
fi/G/G$
'+#fi5FIGC$?+%
=	M%'
/ PQ
 UkU b	VI Q E;
XX*	T	$+#@	ff$?
fiVaff+*5



q










 
$
q

 tkl	  t h n   o~nkmlklkn) "  $ [;793EJ:D8+4
  W
) 
;+%K=	M%'/P	TkbD\b%4  \Z L  Q l  nt
0 [%4  \Z L 

 N [Y"#D?+%#
oM#fic%'/8*
N 3X1"##3
fiff.K.$?E;
fiP=;)
nPlk0tZ7)
0 :% N 
nzvn  G
) 
F+%K=	M%'/P DbffL4IS-+ 4  O Q l  nt
0 [: L 

1N [Y"#D?+%#
oM#fil4>  c%/8GN
oM#fic%'/8 N 3X1"##3
fiff.K.$?E;
fiP=;)
  
N "#D.S
fiF	,X
fi	B?+%K=	M%/ L >: LM %'T+fff LM +A#@(	$P&
fiVl  nt
ff#fi L 9%/8GN4
N 3fi	,E;
-=V3X1"#P.3
fiff.K#+$?E;
-=:P LUkUb	 L  Q
nPlk0tZ7)
0 :%XN 

v =ff
'T"#"P-ff$b=	>ff$P"#
fi	
fiV+%;=	>+u3-
X=	/V4E;,	#@	b#@e+/a
fi	,=	G3fi!
fi=	/Vyz
;
%/>3	
-$:ff	+
fi	C=+Q
fiK
F	A +ff,ff+W
fi<P	;"#
fiP	$<C+fi	
-GC=	

fi			ff	ff
fi	G	ff-/f.:	"#/GfffiPJ'
x%1=	s
{
 024Eb+-	
fi?,=	M
fi			ff'+	ff
fi	G	fffi/V:
+uE
XX<ff3X-fN
fi3:*D.fi$M+%=	aX
fi	.+PVff+
fiJ"=	ffD$sV	+	6.:1	/?+
"
H=	J		.+
fi>E;
xX*	T"#&
'ffT,+!
3*ff+f/GTP=+f"#+.5

V

9k}^'

w    
" 

+ "z"



"    
 

<

"\}e!	



v*,	+c%'/>34	)
fi$;%1=	J+Z3fi
fi=	/E;T)+
fifff>"=."#
-U#
fi	Gbx
X%P$G#&
fi
+%YP=	q	.+
fiq3fi
fi=	/ ff#fi)$0D0~\"  X-$f+ i;D!DffX
-$yzA.$e+Y3fi
fi=	/
3
I

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

H=	$S%,"3Xfi$\ jkI	M
fiZP/>M+%TV$."==		==	!"#G+%+!
3Kff+5?Z?=	
"#&
'ff>P."#
fiu,E;#X 5v;=ff
'>
P"#&
fiL!$?/>+ff+%JP=	q"#"#	.fL/?,%'/
I$"#
fiV
 qGff$"#
fiff
-	Gff+?ff+	ff
fi	G	Pfffi/>5
F&
ff,q
-$"#$].	=s
fiL79
fi	\?E=	fV		fff	$!D.,ff+L+]+L+."
	$!D.?]ff+	2'P#N	/GD?).+35ZZ"+0ff#N	Z=	Z"=ff
xffu%YZ		ff]Hff+4R
 hG:
		$"#?,	ff/a
fiff

'"T"P=	+
"#:K%'+X-SEM[

-,
 t#6OG;b"=ff
X'ffAffDS08(YZ02;h0<ff;B;0736YE!3	;W;@
eW Dh5cWS7A@[8(YZ;>36;B3	G;2m5	3LG0WS2\A17nG5	YZC<P;>2 
O 3	G;<L 5W;lW;>Y;7>3LA24;BAffDhT WSA8:;>2m7A2\C5	365XA2OWA<S3	G<ff;036;2\;C%Y5X2OW 
W D3	G;%7A5X7;!5cW3	G;%A8;27A2\C5	365XA2      3	;2hT WB7G5	YC<ff;20<ff;%0Y	Y8Y02OW3	G03
702,;[7A2W36<M736;ClE0CC5	2GF0lYZ5	2 >     02!A<ffC;><5	2GF{     024Cl0@B5X2\5X@B0Y
?0<5X0:Y;5	24C5	2GF7A2W36<P05X2\3  
 G;<ff;%4S5cW1;>5X3	G;><102;5cW365X2FW36;ff8A<%0m24;
 YE
7><ff;036;C%W36;ff8 3	03[7027A2W5W36;2\36YE%H;%A<ffC;><P;Cl8<5XA<!36A  024CV3	03f0CCWBWA@;
8(<PA8:AW5X365	A2i  
 G;><ff;Sil
 b 
 3	;<L 5W;  5 D3	;7nGA5	7;m5cW3	;V3	G<ff;03  {4>  O  4  3	;23	;2\AC;G0WV3	G;

n %til	

7nG5	YZC<P;>2VA3605	24;CE

e0
H 
| 72

0CC5	2GF%3	G;BA<ffC;<5	2GF%4L^\
0CC5	2GF%3	G;BA<ffC;<5	2GF%f4
0CC5	2GF%3	G;!A<ffC;><5	2GFWf    02\C!    5X2m0CC5X365	A2m36A0@B5X2\5X@B0Y(?>0<5cN
0:Y;,5	24C5	2GF%7A2W36<ff05X2\3
3	G03\DA<ff7;nWS0Y	YDA<@lW 5	24 WS0CCV024C%C;Y;36;
Y5cW3 i CA;nW2 3vMG2\5 DE L5	3	

w
e

c
O T 
 
8(<PA?5	C;C%3	G;nW;B0<ff;B7A2W5W36;2\3#L
 5X3	3	G;!7A2W36<ff05	243	W7M<<ff;2\36YE5	2Vh 

~ "  Xfi$b+mi;D!DffX
-J#$	+"P3
-/=	PY	P!
fi$M+%_P=ff
M	$ff.+!
fiqqSfi2
\

-=	/V[
g

I	ff	$[<sfi$3%	(ffJ"#P$	;YC+P
34ff+*:	+ff>"#/Gfffi!
fi?+%1E=ff
"P=?E;
XX)
fi
%H"#+!
&%'G=	M
fi			MD35
g

F/Gfffi	$P
[ 02\E>ff'+L=+>!+fi$,P=	fff+	ff
fi	Z	Pfffi/ 
a$3X
fiU$
-u=	f#+	=
 Yqfi$3%b	(ff5uv=	#%V+ffiP.+%?$+."P=ff
fi	\=	f.	=L=+,
C.+ff$

P>"#&
ffMf		ff,ff3Xfi?E;
Xx*NV?+fi	!
fif?=	Jff'+	ff
fi	G	fffi/
x%<	
#@ff
#5
g

I	/?+
"P
fi&w[cE_V
'
fi"#M	(ff$
fiZ=	,#+	=Z	$!Db		2-
'/GP	=ff
"Cff+:+
%'	=	P/G:=	T.+	=G	#+$WD>Cff	ff
fi	J	fffi/
<C5Kv;=	P#%PC$+."P=
%_=	Gff'+Z.	=Z=+,ffD$s	J)$+YA	(ffWE;
XX<	,"#&
ff,f+P
3<ffq
DG%1
fi#;#N	/Gff.;/Gb=+f"#5
3
X

fi





k

yz{z|~}a

	

 9tQ'tmnvv

v;=	,	ff	$c	)?%M+Z%'+X-$ET;
fi$"#!fiG%'/rjkIyT	ff	$:4&
fi"#Y!	ff	$

	Ta	P ?+%K=	J3fi
fi=	/Vyz;$."=V!.+:D		M"#/G/Gff.;ff->fP=	b+	C+%1-$3%
		ff$; "#/Wfffiff#.5KI+
-"#\ff#N	$Fff+K+G!+fi	
fi9
fiG=	TP+/G;E$,<jkI:ff+
ff,
;	45

 fi ffA   .

nlntmnvv

</Wfffi	$:ff$"SX :	"#&
!.;+%KE_,"P3
fi/?[
5;=+bZfi	
fiVP=	Gff+	ff
fi	f	Pfffi/
'M$3X
fiU$b?fi$S%_		ff>+%=	W.+	=*:
+
e5;=+;=	J$+#"=V3-
fiP=	/E
XXwDSXfi?
 
fi;Wfi$3%1		ffb
fifP=	b.+	=*5
v=	N.!_"#
fi!
fiG"#b+DS
fi>ffff$<	_ff?>=	ME3J=	M.+	=W
F$+."P=	$4:ff=	2
%'c
fiF
KP	b+%1+Z$"M
fiF
F	M+%8jkI5<v;=	b$"#f"#
fi
fiW
8fi$;"Pfi$+$:ff=	+E;$[
 jIY/?+B$<!	
-_"#+.Q=	Tff
fiP.+	=WD>!.+
-	J+<=	Mff_,#@(
fi	,=	T.+	=

ff+EffE.A
fif	/>+!
"s%!=ff
fi*:*Ec=	$J`..M+Y+Z+Pff
fi.+PV
fiDM
-Z=	G#+	=
+?.3#$Q
fi;
fif)=V
fi$"#!
fi5
 h  	2
 	PD+%M+%"#/Gff-	$G+/W	D#bZff/G!.+
-	V=+C%'G+ffZ+
'3_ff
$ff
fi	]=	V)+
fi	ff
fi	]
fiDW%'>+4tuP=	"Z'x
fi	.+]ff+4G		ffX
-$Lffu=	
fi+3
/G$"P=+ff
/,tuP=	>3fi
X=	/E
XXKDP3XfifP."#J"#P.3
fiff.%/=	Wff+\	D!
XK
fiM
 
fi.
=	MD_		ffCHDffxff'+4.:Dfff+
fi	Y!aSb
-/GffX
fi$F=+Q
fi;E;
XX
&
-_3X1		P$F+%*=	bff
	(ff,;E;#X 5~M%'/>3xfiG.+$4:eE_b=3[
kR

n  n 
 5X3	0Y5)<ff0<E!8(YZ02ThL 5	YXY70MW;V;>?;><E,8:0<365	0Y
 6* 70YXYv36AV  G  iL
xe;>?;><E!2\AC;B5	2V3	G;8Y02F<ff084C;24;CEWhT W8Y0242\5X2F{8<ffAYZ;>@136A;B?5cW5	36;C 

8Y02

Zc,
fiff"#
fi+P	/GffKJ	+c=ff
KP=	/V:ff=	+E;
fi	b=+F=	b		.+	=WD$
+ }h  
"#/Wfffi#fiG#@	fffiP$4:(?=+;=	b3fi!
fi=	/E
XX%'+X-SE0,+=?	f,=	bffMHffffX
ff+4<#@	fffi!
fi	,f		.+	=?
-f=	J		"#$5
Zf)+
fiDuff/G.+!
fi	
fiff%/>3X-Z=+?ID  yG/GP=	(+% <ff;245	2GFf+
Sff'+
 	
fi	?"#.S
fiD#_;	ff$f,P."#
fi	e1
';$Rff
-S3fiffW=	b.+	=V!$+."P=V	ff.B
DL jI5LP i$"3X=+G+.+P$Jff]/>+ff
fi	ff
fi	q$+."P=Z%'ff
fi,E=	ff>ff
-$Y
}h>\
: UT(gjO+m
 hG(
: K94
 J:"#P$
fi	>P$$"#
-#fi?>	
fi	?+Vff#fi!
fi	>"#P.3
fiff.
%P
/ h>5

ASr   6 k G; ;2\36<5	;W F;>24;<ff036;C E W 8<ffA7;WW5X2F02;>2436<E AHD3	G;DA<@
}h  UT gj* 7A<<P;nWe8A24C;n07>36YE36A3	G;VjkIF<ff084 AffD!80<365X0Yv8(YZ02W<ffA>A36;C 03Wh 
0WWM@B5X2F3	G;BW0@B;17nGA5	7;,5WB@0C;!0W!36A(G03 7A2\C5	365XA2BeA8;2A<S3	G<ff;0336A<P;nWAYZ?>;
03;07%W360F; 

^&Tff"#$;Pa!=	SE =+;=	b	Eff
fi$F	#+$?ff
fif$)b>fDPG+%K=	
%/ }h?\
: UT(gj*"#P$VP>=	G/GJ+P
31ff'+P=+"#/G	
h>yzM"P=ff
XffA
fi\=	
.+	=?Kff#N	$f++M K[
 qqff.5v;=	E;c=	+#Kb=	Mff#Nff
fi
fi*<
[ hd"#/Gfffi: h
#N	$fff"P=	ffD&
fi	>f\"#
fi
fi>?+
 %
: h#N	$ADf"=	ffD&
-	>,=	$_PG$+-5
^H,=	;";=+l
 hu
'1"#/Wfffik: h`=*	J"P=ff
Xff*:++sX
fiBE;
<?/a
fi+$9	.+!
fi	
	G	Edff
-$5
3
p

fi yz){	{z{z0{ 
 	

K)

mez)zx	0	yz{



zy	yz"z{



 P=	E;
;+V"3X'  n  O 
 :Ec=ff
"=G"P=	Dff$KT"#
fi
fiCM$+fi_+C	.$	E
UT(gj>ff
fi$:+	%'K$"P=Gff&
fifffic$+fi	!
fi*5*c=	P#%P=+< UT(gj?DPJ	.$
A2\YZEUT(gf
j ff
fi$6
->P=	_E;#	<P#N	/GDcE;
XX4fffiG	#+M/GM#N	/Gff.;


fi$"#P$?+=?
fif=	C.+	=?-$	;G""#$ 
fi#fi?/GJ"#.3
-	$?ff+5
^&,=	$"#G"!Y>"#
-
fis
K"=	ff*e)  n   O 	#+$	E^UT(gj>ff
fi$
%'SX8#@ff
!
fi	VM)D&
fiff-f	
fiMf=	,)"#
fi
-q+q%b3X<"#
-P=+J	=	
)q"#
fi!
fi*yzF	)D&
fi!
fi*5Kv;=ff
;"#P$	c#@"#fiGP>",P q(Q+5
^&G=	;'<"Mb=	$<"#
fi
fi>MX
fi	B,+Gs=	$+ff
-	Y44
'<"P=	D*e)  n    
		s=	G.ff!
fi	Db+c
 ~$bff
fi
fi	q"#.3
-D.c=+C	ffb=	G=	P$+$:*#@"#fi\c
fi"
H	<+)S5
M3
fi	b
XN$W=+_q	.+$Q=	
-/G/G$
+PT"=ff
xffG+%Kb+!
3ff+W
fi>C/>		
$Rff
-S3fifffu jkI:J+%'	=	/W\=3
fi	L	$0=+?
-fD#?=	$"P=ff
Xff0 =	
%PD!
fiGE;
fiP^
= UT(gj0.+D,WE;#XJ !Z=	#
fi>"P=ff
XffPuE;
XxcSZ)q#@	ff$).:;P=	f%'+Xfi+E;
X	
fi/G/>s%'+Xfi+ETF
fi$"#-G%'/rKS
fi/+:	=	J"#/Gfffi	$+%Q jkI:fJP$
"#!
fi?
=	J$+#"=V3-
fiP=	/	$A#fi+EJ[
o n  r  6  D ;>?;<0CCWm36A3	G;BD<ffA24365	;<3	G;;2\36<E}h  UT(gj3	G;>25	3RL5XY	Y

<h|5	247YMC5	2GFh

;?>;2436M0Y	YE!;8YA<ff;!0Y	Y8:0<365	0Y8(YZ02WS7A243605	24;C%5X2m3	G;SF<ff084V<ffAA36;C%03
5X3	W;Y D

k 

 	G/,b)G	$"P
!a	bE=M
fib/G$+M]##@(fffi$f?+
'31ff+*:9b$Rff
fiS3-D-
\.
&
-.C=	Y"#P$
fi	G.	=V		ff5 O  O f"#D#3
fiC-DA
fifE=ff
"P=f
-T#fi$"#.c+
DPb%'/=	%D
-;'
 55bff+V
 ~b
fi$"#
fiYS
fi.:"P=	$"B	
-%<"#/Gfffi	$H/a
fi+
X	

X%w	#:S+s=	E
<P#N	$=	<ff*5<IW.#@	fffi
-	D;c"#&
'ff
fi	Dcff+C/G$+K#-$"#
fi	
=	ff*yzDP,G=	T!$+."P=,%PD!
fi$5*4/G/?GT"#3XfiC#X
fi$>J$."=	2H"#DP+e!.+
=+Q
K.+ff$GDSXfiJPY"#&
'ff_Gff,?=	%'ff
fi351v;=ff
F"#$!	F,
$+."P=>P.+bP=+<E;
xX(DSXfiJ
&
-K,	(ffc
fiGb.+	=G+
-,		=?
fi/G#tL
fi,P=	
E;.	:ff	b=E;
XX*	)\+?
fiffNff
fiJ/G	ff_%8
-/G
-VG		.	=VE;
fiP=		;#@(fffi
fi	
=	,+$M+%=	W.+	=*5f jIyzM
-.+
-2Hffff
fi	\$+."P=P.+=bP=ff
M	)
ffD$M+<y<	P$ff=	2-N.M$+."P=*5
v;=	K<"%'1"#/Wfffi	$)%'+X-SEM
fi$"#!fi%'/4/W/>b<+MP=	K%H"#4=+k  G  

fiff
fi
'3XXG		.;)
= }h\
: K*
 m
 h \
: UT gj*f=	M%PD!
fi$[
o
n

r ff6Vk;SWMO)F<P084<ffA>A36;C03KhL5XY	Y;vDMYXYE!;n8YA<ff;C 
 a

+EE;b"+q!.+M=	M
fiff"#
-V"#
fi
fiVCfi/W/>	[
o n  r  6  Df0{80<365X0Y8Y02Oh 5cWkDMGY	YES;n8YA<ff;C  024C9h 5cWf3	G; 8:0<365X0Y8(YZ02!F;2\;<ff036;C

*

h  3	G;>2=3	G;,WMeF<ff084
<h;
 
v;=	s%"#c=+9hb
'T"# 
ff$\W$fffiM+%<GP."#
-?%P/8h/G$+c=+P=	Jff
}h>:\K*EW"#&
ff$4:F$ff-
fi	
fiuZ"3xPT)    )   ( \%'/ E=ff
"P=xhV
 E
	.+$LJP=	f+ffG	(ff(hK
N 
fiLP=	V"3X+)    )   k :)5v9!=	SE =+Rh yz
0W!0V<ff;WMGY3AffD |24A2\C;36;><@B5	245cW365	70YXYE 1<ff;36<ff07365	2GF0V7A5X7; D<ffA@
<PA>A36;C103
L5	YXY;vDMY	YZE,;8(YZA<P;C%0W L;Y	Y

		.+	=?
'F%ffxfi>#@	fffiP$?E_b	$AG=	+E=+
5}h




;
&
fi$4:

	5;=	J!		.+	=f)+
fi	ff
fi	f+}h
Q%'ffXfi?#@(ff-$4:

h 

q	5;=SX*+%

yz"P=ff
XffA3	G;<;=(h+M%'ffXfiW#@(fffi$45
3
{

fi

yz{z|~}a

	

v;=	MN.!;
;P	b$"+
 )    )   k :,	#+$;=	bffm
 }hD(
: K*4
 b:	Ec=ff
"=f/W$+
=+9hYE;
xX1ff3X->)Y
&
-$45Tv;=	G$"#q"#
fi
fiA
;=	C
fiff"#!
fiV=ffff=	$ 
5bv;=	
=ff
fi#"#
fi
-+/G	ff.?uff/G.+!
fi	L=+\.G=	"P=ff
XffP		$0ff`
 )  G  c
)   k :f"#SXfif	$!D9 h  yzT"P=ff
XffPTff#N	$Z+:4+ ff;=+M=	$G"=ff
xff
E;
XxP=	/>#fi$M%'ffXfi?#@(fffi$45
v=	bN.c
;$&
Xfi?
XN$4}
[ )  G G )  n ( G
fi/W/G$
+#->"3X
 =GG  %0 O@? =	
/w3E
fiq"P=	Dff$0."#3:bE=ff
"P=
'f#@"#fiP=	Z%'	"#
fi"3X-$ffb
 )     O 0ff2
ff$A=	m
 /w3E
-=	\N.!Vff"#5 ^HO=	E_.	:M=	Z	E	(ff$	.$%'(
 hD









k






O


)  G) n :V+PJ#@"#fi=	DC=+bE;ffAG	#+$D
 )
 
*:	E=ff
"P=\D
KS
fi/J+W
 hyz"P=ff
Xff*5
 h
fi.!#X%_+C		b
 %M=	G"P=D
xff\#
fi	?%'ffXfif#@	fffiP$4:*3X1=	G"P=ff
Xff\#@"#	M%
=	b%'ff
fi;E;
-=
 UT(gj\.+:	+A=	#%'bff/G/>bE;
XX*)b%'ffXfi?#@(fffi$4#
5 h
-.#X%*
'
%ffxfi>#@	fffiP$?Df	/W	
fi*:ffE=ff
"P=V"#"Pfiff$c=	b	ff+%K+%<4/G/>!
 qe5
79
fiSXfi\E;>	$Zff/G#+?=	V"3Xm
   :  w h.'bff3X-Z."#.C\=	
.+	=*yfff$5r79
fi.+%>3X :M=	\N#q"3xY
   G  	.+P$V+ff0+%G=	%'/
}h (
: K94
 b:1+		"#$&
fi	\+\DPV+%;=	C%/ }h (
: K94
 	.+P$b+\DPV+%;=	,%'/
}h ( (
: K94
 J:ffE=	
 h ( 	$!D.=	b."#
fi?+%<G&
fi	+-"#!.3
fiffF%P
/ h5
v;=	<"SX[
   :  w h.'P=	#%K	.+P$wc$R	"#F+%	D!
fi$4+%DP=	K%'
/ }h ( (
: K*4
 b:
}h $ 4
: K9
 b
: k
#[
: h M : K*4
 b:<Ec=	j
 
'JP=	fD	/,W+%sff$"P
'&
fi 3 
fia
 h 5^HuP=ff
,$R	"#
h ( hT+a
 h M =,	"#P.3
fiff.5Z7e	=	/G:<4/G/?Z\#X'Ja=+,=	V		#+	=
ff$V
 h ( 
'c%ffX-f#@(fffi$V+\4/W/>
 qGP#XcM=+M=	,$M+%<=	R
 h<		.+	=b
%ffxfi>#@	fffiP$f;E;#X 5
v;=	N31R	$!
fi,
QE=	=	}
 h M :	bff'+GE;
fiP=G	G"#.S
fiD#:3
K	$"#$P+
X-YP=	TffffXwff'+
 ff#N	$f+)SJ)sff+GE
fi=b<P=	
fiff
-
3w+YN31<G=	M&
fi	+fiM"#.S
fiDK2
ff
fi	M
fiff
-
3D)#%FN3H.5Z;Bff	SE]=+<"SX9
 )  G G )  n  ME;
XX	ff3XfiJff#-
3X8"3X
fi	B	+\3X1.ff
fi	Dc=+cE_PY	ff$\c=	JP$fffiM+%<	$"#!
fi	>W=	$+$5MI	2
ff /	_!; !K=K=$	YP("P
'+$sX
fi	B)8+a.ff
fi	ffFH=+KE;T	ff$GE;
-=		
V"#P$
fi	f=	$+,"#
fi
-4_/a
fi=ffJ+	$+s
fiT
 h:*=	+E;$:*++
 )  G G )  n  
E;ffW	;N?=	/V<
5 h M :e=	*:ffE_ff>"#D.S
fi>	,/GTP."#
-G	
-:ff		;E_ffG	
C=	bDffXff+*5
Z\"+LN	@u=ff
',$&
X-		=*:;#
fi=	?DL$Rff
fi
-	Z=	fx
fi	.+ff2'!
fiS3/>"=ff
fi	PL
		fffiZffbE;
fiP=		Y	)ff /	G!,+"#.3
-D.6:4,D
fiP
fi	q#@	ffX
"P
fi,"=	$"PB

fi+
 )  G  )    f=+M/G+$b	)ff /	Cb+\"#P.3
fiff.cE=	Z=	G+PY	
/Gb	!
fiFGP."#$5
v;=	?%'/GW/,
fi=ffG	G)qff$&
-.+fffi[=	fx
fi	.+ff+u/a
fi=ffa"#D.S
fiu,P=+>ff*y

fiff
fi
SXXa	$+Pa!M=	bD3:		;_"#/WM
fi>=ffwff-$$
fi	C=	/
fi?=	bff+?/G$+
=	Tff'+		<	$W	<P2-
fiDP(ff"#M=	/ 
fiDPJ=	ff'+*5Kv;=	'+K	!
fi,
8
fi	#@	&
fi:(

"#SXfi,
fi/Wfffi/Gff$W
fif	T"#	ff5;IWI$"#
fiV	5 qb%';%'	=	M
"#&
-f+%1=ff
'F
	5
 h M 
P=	JffffX8ff'+*:P=	a"#/Gfffi	$c	ff+%K
Nff
=	$4[cE_G=	+E;$fP=+
 	/,
fi	?=+
"3XX
fi	
  O G O 4 h;%ffX-V#@	fffi$
fi.M+EZ		.	=*:1+%'	=	P/G,	.$J?+P=
,=	T.+	=*yzQDT&=	TffffX4ff+4K	
fi	,=SXw		ff$F#fi+E0=	M+=f+M
 
fi$a
fi>P=	
	("#$P5



#'<3'H'&#$'$K3<+1P'-3 |7!K'''3 '3'
nS

fi yz){	{z{z0{ 
 	




/


k vln

mez)zx	0	yz{



zy	yz"z{

E



rzl	6l

I 	/>+!
"P
fi:9X
fiBf"#/GfffiP	$:
,\E;2'+PY"P3
-/V5Zv;=	?N.a
s%P/>3 [,=YP=	fff+
.	=G
FC#tL
fi?=	;E;.	:=+F=	T)+X
"#W+%*	.+
-	as	(ffy;+ff.KffG/>B
fi	,
	ffP/,
fiff
!
"F		KN	@	$>"P=	+
"#;+%1b"#
fi!
fifHGKP=	$+*bP$+fi:=	G	#+
fi	
=	\		ffyzV"P=ff
Xff0ff`+	ff-
fi	L3Xbff&
fifffi\E3(W]$+-\=+f"#
fi
fi`/W$+?=+
+fffE_?

fi"#cff+V		ff$M	$!DM		2-
/G	=ff
"sff+5v=	a!$"#V"PS
fi/
';=+M=	
#+,%'$+#"=ff
fi	W=	b.+	=f	T
&
fi#_Cfff	(ffC/Gb=f"#5
v=	N.K"P3
fi/+	ffX
-$ff !1c=	%/>3(ff#Nff
-
fib+%	=	Fff+b.	=*:Sc=	_	/?+
"P
fi&
+%< jkI>ff"#$c,	+b=	J	/>
"P
fi,+%<+<5
v9?
X%'f=	G$"#\"P3
-/E;,	$fffiVP=	+EO=+c%+ffV
3ff+*
 h?:wLE;
XX
	.+Pb=+;ff+,"#5FZJff/G.+PT=ff
'F
fifE;Y.[

 Tt<6W

n
r
<ffA>7;nWW52GF,02;>2436<E!AffD3	;DA<@
F;>24;<ff036;C%0F05	2

o



h

h 


L5XY	Y24;?>;<70MW;9h36AH;

UT gj*

h

v;=ff
';
c	C$"+!G	.+!
fi	V G: UT(gj*
 "+!$ ?yzT"P=ff
XffPV?,	.$E;
fi=
UT(gjZ#+D:*+\f*5  q!""#$&
fi,		ffG=+b.M	.+P$VE
XXK=$a!
"#->/G

"##3
fiff.F;/GMX
-	B(;P=+(hG:+?=	P#%PbE;
XX*	)b
!/G	=ff
'"+5

 6x<ffA>7;nWW5X2F 02^;2\36<EAHDV3	G;BDA<@ h  K*4L5	YXY[2\;?>;<70MW;Oh 36A H;
F;>24;<ff036;C%0F05	2 
Q("#$P&
fi	}?
h :(K*4"$OhGyG+PDOh  Z\	#+$LE
fi=u+K*.+xhGy
&
fiffX
-	DJ)	.$,E;
fiP=>BUT gj>.51cP=+#
h 
'24A3		.+$?+D3
-aK=ff
K)+
fiff$5
cb%'	=	;#@	&
fiW+%1Y 
fiffX
fi	C+%K
h "+?FM
/G	=ff
"FRG
h :ff&
fi"#M=	GE;
Xx
X*
 +9fi$6,=	_!#fi$"#
fiC+%M+-	
fibM=	"#
fi!
fiJP$+fi$sE;Rh
 +s
fi.*"P=ff
XffP*5
)
fiBE
:	,&
fiffX
-	J+%Kh
 "+G_)TP#N	$GCc
/W	=ff
";PG
h :D 
fi"#
-<E;
Xxw
X*K%'/
h <-$
fif=	J"#.3
-D;=+.+$}h  %P/
fi.;&
-ffX
fi	D5
o

n



r

v;=	P#%P>sfi	\Jff+
C	J#@	ffX
"P
fi!fi\DP$Z=	G%'ff
fiCE;
fi== UT(gj
+ K*f.+D6:ff
fiME;
XXK	bG"# 
ff$/GC=+\"#5  "#3xfi>P=	JNP$AX
fi	.+P>ff*:
h :
Q
fiff
fi
S-Jff$W>P=	R		TE
fi=G)
= UT(gjV+
 K*,.+D:ffYq/?$G"# 
ff<=ff
'
+
'38ff'+\/G,=+\"#:+A
M=	#%',	J!
"#-V(!/>+
'"+5  PV=	b
3
ff+*:)=	+E_$:ff
c	.+P$Vff	
fi	f+
fi#+
Xf+%<=	sfifff
fi
  O : O :	Ec=ff
"=	.+P$
$"P=`%b
fi.,ffGff-L"#:#
fiP=	V
 K*L
 UT(gj15I=	\+.	=	2H$+."P=`3-
fi=	/ 
'
	/>+!
"#@"#	c%;=	s%"#_P=+;
fi;/,
fi=D"#&
'ff;
fi.F
-ff
fi
34ff+fE;
"#5

;h

!1"4" 
 

"m@  X["

"z|"#i +

  \(''@ 

0=ff
XfiJP=	G	fffiBV%_	M$$+."P=\=M]ff$\P>=	G		.+
fiV	=,+%;=	,ff+	ff
fi	
	("#$P:4
fiM
'c
fi/Gff&
fifffi,V"#&
ffb=ff
M	=>"#/Gff-#fif
-V
'++!
fi+*5J^&Z=ff
b$"#!
fi\E;
"#&
ff?=	f#@	$"#$	#Nf%s		.+
fiiaE_#xG/GV		fiA
fiff."#
-SaE;
	+	.+!
fi>+?P
fi+3 5K79
fi.;E;b"#/G+bP=	J"#/Gfffi#@ff
fiG+%1ff'+V	+	.
fi+>E
fi=?=+;+%
ff+V	.+
fi?%/"#.+#"=*)=ff
;#+
fi,	+
ff$TV$
-/>+b+%K=	+E"P-Db=	sX
fi	.+P>ff
/Y!K/>+."P=,=	T"#	ff_ 
fi+
-b
fiW.ff%'<	+	.
fi,b);%K=+W	.+
-*51c#@(
E_W	X
fi	W=	SEffJ+?$
fiZP
fi$%'/ +<yzX
fi	.5V79
fi3xfiVE;>ff$"#!
fi
/GM
fiff$!
fi	C
fiff."#
-SF) E;=	b		"#$$c+%1!
fiS3K+f	+	.
fi*5
nG

fi





k



 Q 

tmnrir

yz{z|~}a

	

. @l 

 X *ff+		.F=+;!b+?"$Q%"#T=	M%'		+/Gff.3*	fffi/+%8ff/a
fiff
fi	,E=ff
"P=>ff'+
+W.ff		JPJ!
fi:
 55X:E=ff
"P=>ff'+;"+fJ"P=	$+fffi>	+	$?C=	J"#	ff;	fffi/V5^&
=ff
C$"#
fiZE;>	$!D,q 
fi/Gfffi>3fi	&
M+%=	f"#
fi
-b	ff,E=ff
"P=L	+	.+!
fi+Z+%T+
#@ff

fi	G"!M
FX
fiB#fiGG)b/Gb#@	$
-
fi;P=+f	.+!
fibff+	ff
-	5
v=	J&
'"b
'ff$,
c=+b+b+ffV		ff:*	+	.+!
fif=M#@"#fifP=	Y+/WY	
fiM	2
+
-bff+	ff
fi	):	fffic=	,	P	ff
fi>PG."#TG	P
fiTff$"P
 
fi*5v;=ffP=	Y$+#"=\"#
	.+"P=ff
fi	,%H"#<
';	b$F%M	+	.+!
fi?=+?%';	.+
-bff+	ff
fi	)5
I		)Db=_P=	b	.+
-T	#+"=ff
-	,%"#K
'
 bfJE;PB
fi	Cff+f+%9fi	*
= #@ff
.

%'G=	f	Er	fffi/5L^H=ff
G"!:;=	V"#DG%	.
fi]
U
  5ucSEr		D!V=+W=	
X
fi	.D2'P
fi+3/G(ffff-qP	?Zffu=+f"+\#@(Pff$uPiE;B
fi	Zff+E;
fi`
= 
	+	.
fi=ff
'J"#P$	a	=fffi\=	f	
fi
fiZ+
% 	ECJP=	>ff'"#/Gff
+% M$ 
fi+			!
+,5?v;=DC	+	.
fi
cX
-B#fiVPf,%HbP=+Z	.
fi,ff+	ff
-	
E=		
7 `
 

M i 

v;=ff
'K
-	$R3x
fi,

&N$?E=		





G  ( 

]fi

 ?
fi"#$$:;=	AfiD+!
fi=	/ 
fi"#P$$W+E.	,X
fi/,
fi,+%J	5
 GP=	V	.+"P=ff
fi	%"#(
v =ff_!/>3X	."=ff
fi	s%"#.Q#@e"#F=	M$+$!K	?W=	  M #+
fi5k~F	&
fi"#M	.
fi
;
ff+	ff
fi	Z3-/GDG3fiE3	b=,\	."=ff
fi	%H"#,+%b+Cfi$!qZ+L 
fi"#G- = q S	:E;
"#"Pfiff,=+b	+	#+
fi?
';X
-B#fi?	#%#+fffi,E=		b=	C
-S3K/G	fffffiJP	b>"
=+P$Rff
fiP$T+c/GDT
 ;/?+Df/W(
XNw"
fi;c	.+!
fibff+	ff
-	GE;ff?$Rff
fi5 
"#++
fi>$!
fi/>+f	$.C=+,=ff
,"#P$	GZAN$x
fi	.+ff+
fiLE=ff
"P=u+
/GDcG
 +%8P=	Y"#
-+s
fi+			
+5F0=ff
XfiCE_,"PBD	+E;fi$ffb=+=ff
'T+Sfi( 
F/Y!
;.+BJ-DD!#fi:$E;F#X
fi<
-1	+
ff$#%'ffD
-Dff
-
fi4YP=	"2HRSX
fiTP$Rff
fiP$JPT/>B
	+	.
fi?E;=ffE=ff
XX5

 fiff kR

nnPlnozr

. 

rvn

 	;/G(ff#*+%*P
fiSS+?	+	.
fi+,
Q$W>P=		/,
!T=<=	b+qSfi
-=	/O
fi.#x%
	.+P$
fi.9x
fi	.+Cff+5K8+K	.+$,ffG+q	/>+!
"3XXJ=3M$CE;
-=G=	/3X
=	Gffff"
fi$c
fiff	ff"#$f
-qP=	J		"#$M+%<	ff
X'
fi	>P=	Yff'+*:)
 55M3XK+%K
fi.M"+3X
fi	B	
+f"#P.3
fiff.5
~D+%*Mff+*yz9	)D&
fi
-1;S+
'+ff
XX
fiU$C)#%P_P=	ff+C
KP$M
-G=	FX
fi	.tuE;
ff>P=	JS
+ff
Xx
fiU$+
X?
fi\G	Pfffi/G2H)$"P
XNw"C/>+		$:)		M=	J	#31
'	J%8E=T+P.;+%
bff>CS+!
+ff
XX
-U">)T
fiE;$><b	Pfffi/%1#@(ff'++
fi	2'$,	.SX
fiU$+
-S*:ff+C


"#$?ffGM$	+2_#XX
1+?~\"3_+P=D?.$ff1+?ff>b+/,	=+/G
+?M$	+M.$	+.5
)
fi	#+b!
fiS3
1cE;2Hb		"#$[+
-YM+%	
fiff
fi
'3(+sD3("#
fi
fi6:$=	3-2

fi=	/N.
ffD!
XN$;=	C/GD;	/a
&
fi	CX
fi	#+Gff*:	=	qffff$/GJ=3X-SE0/G	
XNw"+!
fi
G/>+BT=	Cff+*yzQ
fiff
-
3*+fff31"#
fi
fi</?+."P=f=	M
fi			.5
nS

fi yz){	{z{z0{ 
 	

@

//

mez)zx	0	yz{



zy	yz"z{

e

`8)	K 04be ffLI

v;=	AN.G	=!q%=	
-S3T	P("#$W$W#
fi=	>`+	ffX
'"+
fi	2H!		ffX
fi$]/G=		L>
ff/>S
fi	2-
fiffffff<3fi
fi=	/&
-/,
X+9=	F	;$bffYb+/,	=+/W+
(+C-;.$(
G#fi$"#"+
'	+bff+65879
-.<P=	M
fi			DS<+PT/>."=	$fD3
fiF=	b$"P=Gx
fi	.+Wff+*yz
DS:*+\P=	GX
-+Vff'+ME;
fi==	G$$bff	/Y)J+%/>."=	$C+,
'ffD
xN$45>v;=ff
C"+
$ff-M
fi\/>+ffq"+
	$:*&
fi"#?.3Kff+b"Z/>+."P=*:*+\f&
fi	fi,ff+Z"+\/>+."P=
fi
\ff	/,?+%s
xPDGE3	5Lv*"P=	ffDq/G	Z=	fP/>3
fiff
fi	]3fi
fi+$C=	q3-
fi=	/
#@+/,
fi	$C=	?/>+."P=Z) E;L=	W
fiff
fi!
3_"#
fi!
fi5^HG"#/G		P$b%'C$"=uSfi+!
G=	
ff	/Y),+%T)i"#
-
fiC"#$+$Dff"P
fi	=	WX
fi	.+PVff+*yb
-ff
fi
3_"#
fi
fisE;
fi=
=	A
fi			G
-ff
fi
3T"#
fi!
fi5v;=ff
',
Y
fiDPff$uPZ/G$	PV=	\+/G	ff>%ff	ff
fi	E;PB
	$"#$+PL\G=	A
fi			,
fiff
fi!
3E;].+P>=	V.+Pf#@()$"#$D]=	?X
fi	#+Zff*5
^H>"#	D.a=	fD	/,)>+%b)`"#
fi!
fis%G$"P=L	
fiL+"=	ffD$,P=	fff+LE;
fiP=L=	
/,
fiff
fi/,	/V:ff	$B
fi	W
fi$;+ff
fiP.+
XX5

//

b(b*6j(Rb19Z4b1eKUuI3Lj

T3
fi	,/>+."P=	$fCX
-	.+Gff'+*:ffN
-	J
-,=	J	E

	fffi/
'&
fi/Gff-[

5;^&.+ff
=	cX
fi	.Gff+?E;
fiP=>=	MS
+fffiMff
fi
fi	ff<	P(ff"#$ADGP=	b/>+."P=+5
	5[iff"#b=	sX
fi	.+PGff+*yzFff31"#
fi
fi;E;
fi=?=	b	EOD31"#
-
fi5
q	5MF$+,G	E)Z"#
fi
fif%'T$"=\DS1	)D&
fi
-f=+b+	$.c
fi\=	J	ED3

!			;
-f=	MX
fi	.Gff+*y;D3135

5[iff"#M=	;X
fi	#+,ff+*yz9
-ff
fi
3w"#
fi
fiQE;
fi=,=	M	E0	fffi/yz9
fiff
fi
'3w"#
fi
-5
	57e;$"P=q"+S*X
fi	B?=+,"#	/G$W,	)D&
fi
-G%'/ =	b+W
fiff
-
31"#
fi!
fi:
X%
P=+b	)D&
fi
-\
C+ffb%'/P=	G	E
fiff
fi
S_"#
fi
fi:*=	Lff#fiW=	Gx
fi	BZ+
	fG"#$!
fi	W	E\"#
fi
-*5
	57e<$"=V"+P34X
fi	BG=b.		ff"#$GC	D&
-
fiW%<=	b+'Gff3"#
-
fi:
X%=+
	PD 
fi
fiW
;+ff;%'/P=	b	ED3':ff=	Vff#fiC=	MX
fi	B45






A


9nt~n  iv,;ll	!t

tQvn:ozrzl	omno9v

v;=	G3fi
fi=	/+Yffff$M	?		ff
fi	f+%_	)ff/	C[c=	JffqP		$\"+Z"#ff.3
fi
M=T#@ff
$]#	(ff"#$f"3KX
fi	B	%b	PD 
fi
fi
fi\=	CX
fi	#+fff+*yff3Q!
=+G+f	G+G%T=	V	E D365c"#V=	AN$]ff+u"u"#D#3
fiX
fi	B	:_!:;+
"##3
fiff.;E=ff
"P=Z+? +	D!fiQ
fi#fi++ffT?=	G"#	ffb	ff-/V5  %"#	.:4	ff
XK=	
	+	.
fiG3fi
fi=	/"#SXfiJP	
fiQ
9
fi/G)D&
fiff-JP#XE=	=	F=	$T.+%*=	;x
fi	.+
ff+JE
XX("#P3XfiM	C	1PT)<#%'ff 5^'%4/G+$bff	
fi	M=	FN
-			"#$:+=	;	+	.+!
fi
3fi!
fi=	//a
fi=ff
'"#+=+F
fic	$	,2'	.+b=	JP+/GJP"#	$5
v;=	JR	$
fiV=	#%'J
$;GE=	P=	T=	sN
fi	?3fi!
fi=	/ !=	ffVff#-Y3x8"P=
X
fi	B	:$)ff
3xM/G+
fi	;/>+ff!1J"#P.3
fiff.9 "#!S+!
fi<#+).:=	ff
fi
fi$3;=	/
fiW=	Tff'+,=	ff
fi	JP=+<=	,E;
xXff3XfiC	+;#%'ff8M	F+		D"P=4 _
 	"Y$&
XfiJ"#!"#K"$9
fi,E=ff
"P=J#
-=	<.M%'/>9E;#X+C=	;=	%'/>
fffi5
nS

fi

yz{z|~}a

	

	$?++b+,
-DP$
fi	s
fiDP."#
fiY)E_?=	M	;P.+,+W		+	2
.+!
fiYSfi
- =	/5k  :  y4."#
fi,3fi!
fi=	/
P=	<
-D#;+%w#@	&
fi*:+E=ff
"P=Y/W$+
=+
fi\"+fffi0P."#Zff$"P
&
fiVP=+f
fi\/,
-=D=3i"#3Xfi0/>ffiff	
-	`#@	&
-*5
  :  iE
XXff
fi&fi]	>	.+\	)ff /	?ff`*:uLX
fi	#+]ff+
"#ff.3
fiff
-	J	ff /	FX
fi	B	K;F"#ffW	<=3)f		ff"#$f
fi$"#fi,ff,=		+	$5
^'%<
:  O : O a/a
fi=ff_	_)J+fffiMJP."#3X4=	bff+	ff
-	aff$"P
'&
fiQ
fi?=	cX
fi	.+PYff'+*:
+
'M=	#%'G	J"#/Gfffi5AI+
fi"#,
fiJ"		JP."#J3X<	P
fiMff+	ff
fi	\ff$"P
&
fi6:4
fi
"+		F."#<3X=	ME$C"PBYPb=	ffffXwff*:D+,P=	#%/>3C%S
Xb#@	fffiP=	D!
fi
ff+f"#5
 i;$"3X4%'/ I$"#
fif	5zC=+F=	M."#!
fi>3-
fiP=	/	$ff$a
fiI$"#
fi?C

fffi,"#/GfffiFE=	G$Y
fiY"#+	"#
fiYE
fi=Gb"#++
fiKN
-	P.+:+83-+
-#X
DC/G	
X%
fi	M=	
 )  G G )  n  b"#(ffc
fiKff#fi$K	)ff /	<!&t`=	1P=+
=	M
fiff
fi!
31+?DS9!;=+MffG	;		ff"#a,"+P3*X
fi	BtL%'/+ff>ff?
fi	P5

 O
 

k

   +i}e!  

+

(''@ 

~D?	
-?E;BL"2'$0ff+	ff
-	L=f"#"#ff.+$N
fi	LD	
fiff#@D
-	
"P=	/G$C%'J=	fff'+Zx
fi	.+:E;
-=Z=	?
ff$=Y
fi	q]
fi
fi	\+			
'+>"!$
E;ff/,
fiff
fi/,
-UG=	f	$%'G	+	.+!
fi*5Z"L		=	#fi$CfP=	%./GE;B\
+3fiffUJP=	Y	+	#+
fiV"#/G	ffM+%<=	b	/>5v=	YP3
fiTP.++
-$F
fi"Pfiff$A
fi=	
9*		/ M+/G/G4:K$ ff#:ff%T#@+/Gfffi:*!$"P
X%'V#+&%'/>+&
fi;=+b"+\>ff$"#/G2
D!$W
fiDPY$R	"#$%8+
 <ff;2\;_m
 <P;>36<ff073)	
fi/,
-
fi$5  	T+3-(&
'K	+$F#%'ff4
fi>E;

X*ff_E3	[
5;^&!=	SEM,=	+E9*	(y,
fiff#@ff
fi	L+LP3
fif.+P+
X$G"#ff\#@(ff-+
fi$
fi=	q
%'.+/WE_B,D?	+
'
fi	G=		
!
"M$+."P=	2H"#ff+4
fiff%'/>
fi*5
	5;^&>ff/G!.+$a=	SE+<yG&
fi/Gff-V"#	Pq"+L)q!$L3fiffUV/GPV"#/Gfffi#@
	+	.+
-qP.++
-$:*+\fffi!
fi/>+#-V"#ff\)>$q"#/W+G3fiP+
fi,=	
fi$
%1ff+fS
fi$5
 ?.+ME;
fiP=f$"#
fi	/G/>
fiU#
fi	f9*	(yJff$&
fi*5>v;=	
fiLI$"#
-]D5z?E;>"#&
'ff
Z

fi.;P3
fiTP.++
X$!$R	ff
3xfi:	ff$"#/Gff&
fi	G=	/ 
fiffG+]..5I$"#
fi\D5 q,	+$
=+J9*		yzbb+%<P3
fi.c
c
-"#/Gfffi:*ZI$"#!
fi]D5V
P"#$ME3(cf"#	ff>9*	(y
=		
!
"F
fiVFyzQ%./GE;B45<I$"#!
fi\D5z,
P"#$c=	SE0	M+3fi	&
;"#ff?)J#@	ff$
=	P.+&%'/>H
-3wff'+		."P=q[
 R*TQ(
 Uw) Kw,I+
-/G/G:4$ff.5





{

rmt

rir

.

lrzl



t!ti9*	

9*	V$,?N2H.+W	("#$Pb%'Y	+	
fi	\+Z#@ff

fi	ff+ZPq"P=ff
fiG	Eff35f9*	
N..B$CX
-	.+Gff'+*:ffN.F
-,=	J	EO	ff-/V:	+V&
-/Yff'+$Q
fi.;#@	$"#	
fi*:	&
fi	GP=	
	E
-ff
fi
3_"#
fi
fiC+D36V
5 i;	=ff-$B
fi	):89*		yzs%H3
Xfi	$C"#$!q\
ff+fE;
fiP=V+Ffi$;	
 /w$Et`,=	$+P	$WX
fi	B?;	$"#
fi
-*5
9*	T	#@	<!$9%PE.,+C"BffE+.,"P=3
fiff
fi	MJ+3-DU;=	;%H3
X-	:S
'"#+
fi	M=ff
fi	D
X
fiBCE=+TPqPT"+!$VP=	b%H3
Xfi	:4+AE=+MD3=	D,ME;Y!
'"P
fi	5Tv=	
$fffi9
*M"+3		E;Bb"#$)
fi	MM=	_"+P3Dx
fi	B("#P"#$bffJ+W
fiJP=	_	P("#$
n

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

+%ffJ	.
fi*5 W+>P=	#%<)%/>9=	FN. E;T!.+$4%w*9	(yzK	+	.+
-b		"#$

fif=	b	P("#$c+%Kff+f	#+
fi*5
9*	P=	Y!$=	"+3D#@	ff+
fiC!#fi$"#1	_%w&
X@	J	$!$C
+	D!$:S"SXfi$
v  FFID"=	Bw:)$ff#5  v  Z3b"#ff.3
fiKb!K+%wS
fi8!.+
fi$&tuff+C.+ %P/>+
fi+
=+M/,
fi=D#x
fi/,
fi+Pb=	C%3
xfi	#t`+A$"=3
fib#+?=M+qP("P
'+$fP$TP"P=	$"B

fi.,+	ffx
"+ff
XX
-H59*		yz,v  I+V
fi
ff$
fifffNV"P$6[G%H3
X-	$Jff	Z&
fff#*$"#.:
ff$&
fiP$G#*$"#.:	&
'ff%'$+	$6:Dff$&
fiP$,%'$+	$6:(>P>+#+/G.651v;=	Jn b1DT"#
fi?	2
$ff.+!
fiJ!$,D,+qffff$K	<

fi	ff
=J)E_W	$"#%$+P	$K+C=	K	D&
-
fi
+ffD$M	M3Xfi+E+#+/G
-U$f:4?fffif=	sN.E;>"PP$%Qv  FTJ#-S+ff
?	T+3-(&
'5;^HZ+ffV":)=	$C E;>"P'$M+b=	,/Gff;
fi/G).D$:)&
fi"#JP=	V""#	ff
%/GC=+f=3x%<+%8P=	Yv  F5v;=	Y
'
fi"#
-fE;q?&
ffC#$"#M+V?ff$&
fi$A#*$"#

;.S
fi=ff% E+#4[1&
ffb#*$"#.c+M.;D!."#
fi
-F=+ff*yT!		Mbx
fi	Bw:ffE=ff
xfi
ff$&
fi$A#*$"#.TffW=$Y,		)DC
fif=	Cff+*5M+	.SXfi:ff=	Y!T+%<+			
+bP3
fi.

X*ff<
-f=	JE;G"$5
 %P1"=	ffD&
-	Tv  :+*9	;
fi.+ff
 $=	_P("P
'+$c3
fiK.+
X$4&
fi	c=	_ff.S
X
+%1=	J"#	PD;ffff
fi	,.B45K7	;$"P=fDP&
fifffiM3
fi9*	G	;,P$;GM
X%1=	M3
-<
'
+	ffX
"fffi:	&
fi	?=	,$ff-+%<=ff
c$cG
-.+ff
3b=	C3
fi357	M#@e/Gfffi:)=	J$!%'
+q."#M3
-T"#$!
fi	fP,
fi!
fiV%_\.Ec=ff
fibBffff
fi=ff.fP<=+	/>+*:$(<E;ff
ff/,
-	bE=ff
"P=V"#ff'f$P;=	Jff$&
fiP$f	)D&
fi!
fi*5
79
fiSXfi:$9*	$+%	=		
!
"Kff-$4.	Bb=	<++
fiw
fi.+ff
$P3
fi.:+"P=	DD!$
=	M$$:	+?+	ffX
-$K
-$5  "#b=	Tff'+G
'K.&%/G$4:+
-K
;&
fi/,ff$,"#b+D3
-*Dff$"#
-
+%<,	E0%H3
Xfi	b..F=	Y"#	"PfiJ+	EC5

 fi ff
{

lrmtQv

rmt

  

rzl	


t

!ti9*	

I ?+%1*9	(yzFff?3
fi;.+P+
fi$KffJ	_+	fffi,C	_nbeD2-x
fiBT"#!
fi,	$	2
.+
-*5K7	#@+/Gff-:	=	b3
-=+T3 #;=	Jff	.+!
fif+%<+V"#
-?
F
fi	ffX
"+fffiJ 
fi"#
3X< b'D3"#
fi+G!	/G$f?	""#	b
fi#+D#+	&fi5Mv;=	JP$b+%<=ff
M$"#
-qff$"#!
fi$
=	b#fiSD;3
-.+?$ff"#$c=	/P>+Z	
-/,
fi
fi$5
7 	*S
fi.*	M	EL9P=	/w$E;$Mff*51^&J$"P=J"F=	<ff'+M%S
Xfi	<"#P$	
g e
PaYX
fi	B%   F=	$+P	$fff+	=	Tm\ 5
5%
ek@Xt  	LV	ErL3%P1\T=YE
XX_P/G+G=	V&
ff2'#*$"#,	)D&
fi!
fi
Y* #%'JP=	J"#	/,
fi	?*:(#:ff
'<#@	$"#	$45

	5}} @kefi#t  	O]	E0=V"=+	$f+0	ff$&
fi$0P.3
fi,
-D]	ZP=+
/>."=	$F=	CD35

% ek!  k e#t

	

q	5




'"+5

  

 	fC	E!>P=+ff#fi$;+?	$"#$yzK	ff$ 
fi$f"P=+."#!
2

w6.;;Pff
fi 9fi3'KP6PSP-#$<P'<;#'<ff$''-#;'SP *3H)z*-$<'3KP''1P$3.
ff 3' 'M;H#!M'$&Vb#$!
 *P''HX6QP-#$
 *'JP$??'$C''<#$bPS!-
 4b # 
-$<#b'$;XP'$'K
 
fiJ'SP<+'HJ'
 "!#";6P$6$3%
 $Jc!P$-.C'$'P$<'+KPJP

fi 4$3.P-#$<P'K'H.#cM$#
 &'!("Q$#!3<3b'$'SP1#$KPS!-c$ '-fi#+
$#_6'#
n\	

fi

yz{z|~}a

	

v;=	$G=	P>S
fi.J,
ffff
"3K%'/ +<yzs.!$"#
fi:8 
fi"#nbeD?ffD$C	,
2

fi	ff
!=) E;Le $"#C%'$+	$G]=	,D)$,+%b	ff&
fi
fi5]I+
fi"#VP=	f3
fi
.+P,
;P=	J+/Gs
fif=	JP=	J"$:(
fi;
;	"P-$+TP=+=	J
!
fi"#
fiV*9	Y/>B$
E;f	$"#.+W%'$+	$	+
ff$c+DW#%ff<"#ff+*Bff	+E;fi$ffc
fif=	$,"$5
 "P=b+%=	$F3
fi#*"#$!	9=	Q
fiff	ff"#
fib+%a.E=ff
fiKBffff
fi=ff$5z  ""#/Gffx
=	2

fi	,=	$b3
-.	/>
"3fi,$Rff
fi$;P."#
-	YP=	b=	$+	$Wx
fi	BG=	V	
-	>
	Ex
fi	B\	(ff"#$]ffZ	E !LH.=	J=i&
-/GfffiZ	
fi	=	>	EP4.5Vv;=ff
+q"+f&
fi/,ff=	$M=	c.+&%'/?+
fi+KE
fi=>s."#P2'#N	!$R	"#:Sfi=		=
	
fi
fi3_P."#
fiZ/,
fi=ffJ)f	$ff$L\#X
-/,
fi+fff$"P
&
-C=+Gffff$LL=	

fi+
fiSw=	$	$WX
fi	B45
5%)+*--, '.0/@21'ctoc
fi
'ffJG?
fiff,E;a
'
fi"#=+;P=	"=ff
fib=	
ff$ 
fi$?$ff-.;+%1P=	J
-+
fi3H5
^&+/,
fi	fi:)
fiM
'b"Pfi$+b=+C=	>PqPV?ffX
fi$:D:*/,J)G		ff"P
fi	VE;
"3X
fi	B	:*&
fi"#,
-
b""#/GffX
!=ff
fi	>E;?		D!$5Gv;=ffb+u"+Z#*$"#b=ff
MP3
fi
ffJP."#
-	b=	=	$	$CX
fi	BWHE=ff
"P=>+	P/>+
'"3fib/G+$K/GS
+fffi;ff
fi
-	
,.ff
-	Y"#P.3
fiff.#:	
fi	,b	E



2

:ff+GP=	>	
fi	Gb	EX
fi	B%



2

 

5

g vE_,#+&%'/>+&
fi<Pff"#J+f#@ff

-	a!?
fif=	Cff+*5
	5}} @fi3*e .54761,7/@!18K
Htu^&f=ff
F"M=	;%H3
Xfi	F
FMX
-	B1  KE=ff
'"=,
'K=	$	$
ff`	=	q!
   E=	D!ZD!."#
fi
-
 Y* 
?	?
fiD+fi$
fi+	P=	fX
fi	B45
v=	f3
fi,
',Zff'"#m
 4bE;
fiP=u+	=	G*{
:  92 =+?ffD$*y G=3+
 Y*W
)D."#
fi
fi*5
	5}} @fi3*e .54:*@fi
;.0/<, , =.tv;=ff
'%H3
Xfi	Q
b%9E=ff
"P=J#
fi=	K=K+,,	$"#	2

-
fi1
 O<E=	D!T	$"#
fi
fia
;		P$Gff>C=	$	$,x
fi	Bw5Kv;=	M3
-
fi	
P.+&%'/>H
-Gff"#${
 FE;
fi=VC	Ef=ffff$;	c=$
 C	$"#
fi2
!
fi*5

v=	$,.+&%'/?+
X;=3,=	,$!bff
S1%'M	+

-	LE
fi=q!$+."P=	2H"#DP+
=		!

"65~F=u%Y=	$\S
fi.?/>+Bq]ff"#/GD\<P;>36<ff073a%+xfi+E<$Lff <ff;24;
Pq?x
fi	B\
fiZP=	>/,
'	fi>%c\"+P3_	E;B4V
5 i;$"3x :=	SE;3:*=+,+0fffi\/>+B$
"P=+	$?P=	%'
fi	$Z+%,=	\	E_Bw[]+fffiLP."#.?ff$"P
&
-?=+?=3\	
=	ff$"P
'&
fiMff(
fi	f\=	/V5J7eM#@e+/Wfffi:w"#&
ffb=	C%'+Xfi+E;
X	G#.
fi
%P=	(
 } @fi3*e .54#6>,7/@!18K
,#@e+/Wfffi+5]I		fff=+C=	V"#	ff,ff+L"#D#3
fi
E;>	
-
fi3Kff$"P
&
fi6[=	Gff$"P
&
-V?$.ffX
=\f"+3X
fi	m
B 4>  +?VHP=ff
;
'E=
"$?=	c
fi"Pfi&
fif+.
% 4,+
fifE
fi=48f3G,ff$"P
&
fi>,	$"#=ff
QX
-	B,%P/
+	=	;=	$+ff
-	a!m
  M 5I+
fi"#b=	M+P"=	+
'"#Jff	cf=	bW#@D
!"#b+%
=	cX
fi	B4:ff=	bff$"P
&
fi?G	
 4,=	Tff'+_!		%{
 4   +?Y"+		;)b."#P$
	ff
X*=	Jff$"P
 
fifG	P$"#F
fi=VP."#$45
 /Yff'+
fi+M+%(P=	#} @fi3*e .54#6>,7/@!8K
19} @fi3*e .54@*\fi
;.0/<, , ;..+ %P/>+
X)E;ff
$!fffi*
-
 >;+f#"#*).+
fi4%'+Xfi3E;$MDR
 ><P#N	$:+E=	
 a
*P=	_ff	/,+%
ff)ffDbff$"P
&
fiF
fif=	,"+3*	E;B451^&V=	J"#	PDM+Z
-/Gfffi/Gff.+
-S*:ff=	P
n\I

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{


F	J%H"P
Xx
fiJ%'F=ff
FD)b+%1/>"#PY.+P$:		c=	$J9*	J#+&%'/>+!
fi+_!	$
=	J	
xX
fi>%_
-	G=	G$R	"#Y%_ff$"P
&
fiMP."#$
fiVP=	Y"#	.!Y%<	
fi	+
fi	
b=	c%
-	:D+W=	?ff3
fi	b=	$bff$"P
&
fiKE;
fiP=>b		"#$;&
fi/a
X+Yff!
fiS+!
fi3
+3fif_+P	#X:$
 q	
 dK#fiD>;+	#X :4$ qeG
 dK#-D:4$ff.5
 	J3
-"P=+	$=	Jff*yzFS+
'+fffi2'ff
fi
fi	?"#.S
fiD#5
g

ff5}} @fi3, t  	Er	$"#W
G	!
fi	$Z#X
fi/a
fi+f	ffE+DP$]%'$+	$,Ec=ff
Xfi
/>3
fiff.3
Xff
fi	Gff$&
fiP$f"=+#"#
!
"5
v =ff
93
fi<"+,)$,J"#$"#KMD	/,F+%?%3
xfi	$[4=	P$+	$sX
fi	B	:3
fi"# 
2
;
D"#!.3
fiff.:	+A=	M
fi+ff
xX
fi,>		)b+f\"#
fi
-Vff	JG		P$+fi++fffi
=	$+..5G+`"#ff\#*$"#J=	W3
fibff\."#!
fi	f=	>ff$"P
 
fiZ=J	ff$ZP=	>"#	2
.3
-D.FH/WDKx
fiB#fi,=	J	
-
fiG%8,"+34X
fi	B)8?#Nff
fi	G,&
fi/,
X'+_ff$"P
 
fi?=+
)	Va	E	$"#$5
g v=	\.+&%'/?+&
fi,/G	
X%'u=	\ff*yz?/G).3J"##3
fiff.:;#ff
fi	]#@D
!
fi	
!5
	5}} @fi3*e @.k>4-@Xt`v=ff
M3
fiM"#$)	cG	/W
fif+A$Rff
-$;	?2
P."#
fi*5
	5}} @fi3*e @.k>4:Ae1#t`v;=ff
P3
fiK"#$)	KPff/G
fi,+,3P$Rff
fiP$	
P."#
-*5

	5%!B/@@xt`v;=	G#ffb
fiZEc=ff
"= E;VPJ+WV)>	
b.$45fv;=ff
C"+Z
""#/GffX
!=	$]DLP."#
fi	=	qff$"P
 
fiuP=+>	ff$=	V!
fi+
fi3#ff
fi	L+

-	YP=	b	D 
fib.ff!
fi	5
v =ff
'Y3fi	&
b%s9*	Z3
	s
fiL	,	ff.!.+
fi	Z%T.+ %P/>+
X3;ff+		.Y
fiE;
;
E$	579
fi.Q
fi_"P
XN$K9*		yzF.
fi*:	+

-	YJ 
fi/Gfffi#@	ff+
fiG%w
-.KS
fi_P.+2
+
fi$C+Z=	+E;
fi	E=+J.b%_.&%/>+
-Sc
-Y"+"+		Y""#/WffX
=*5I$"#
fi
3(Q=	b	ffE_B,%'K
fi"##+
fi	G9*		yz;.+P+
fi$
-D,+<yz;		.+
fi3-
X=	/ 
fi
=	M%'/+%K"#DP+*+x
"P
fi$MI$"#!
fi\D5e.5






n  
kR 

 .

nPlnt~nzv	v





9*	

 	\$fffi?+%Y+3-DU#
fi	L9*		yzGP3
fif.+P+
fi$C
fi0+<yza%'.+/GE;B
?ff/W.
fi
=+,*9	(yzs+
'"#ff+JC+%3
fi.
M
-"#/Gfffi#tuP=+M
:=	?+>/G>"#/,ff
fi+!
fi
+%<x
fi	.+fff'+b+
fi			C	fffi/?c%ME=ff
"P=9*	fE;
Xx8)G	+fffiGP>	#+>fff
-.+fffi
$R	"#J+%K3
fi#5F<&
ff3:ff%_#@+/Gff-:	=	J"+S8"#P	J=	+E?
fiV79
fi	T)5
 	/G\=f.ff
fi	u"#.3
-D.W$P
"#?=	Zff+P?L=	\N	PyzWfi#%'2'2'
-=D
.ff
-	4
fi\P=	JE;.	b		)DGP=+b=	Gff-q"#&
'ffMX
fi	$+
-U$+
XV%P=ff
Mff+Z..
E;
fi
= ffCP=	V
 4=	
   +?J*5<v;=	b++ETKff	P"+P3X
-	B(:		;fffi,E_Mx
fi	B(Q=3
+)#fi$fE
fi=f=	C	ff&
fi
fif	(ff"#$HP=	J=	#+s
fi#fi++ff.5cI+
fi"#!
 4;ff#fi$%
 D


+
  $Rff
-$Q
fi$:
fiK
'_"P-$+_P=+{
 41P=	$+ ffC+ E  5;I+
fi"#B
 F?G"#	/W$
 YD,:eG
= D
YDd+P#%'ffw#*$"#.<,=	=	P$+</,K/>."=W	+%19*		yz<ff$&
-$,#*$"#_v  F5^HW%"#$:
79
fi	G
,"P&
'"G#@+/Gfffi?+%=	H
 Ae >I/@3*@
;./<, , ;.Zv  OE=ff
"P=]=CfffiZE;VS
fi
n\X

fiyz{z|~}a



P

S

Sa

	

Goal

b
S

P

St

u

79
fi	M[<9*	,3
-."+		N	@Aff$&
-$ff2'#*$"#Tff?%3
xfi	$FE;
fi=?=ff
c"+38!"#	5
#++
fi$6
[ >
ek@1+U
 } @fi3*e .54@*\fi
;.0/<, , ;.D5F^H?+
"#ff'+$:9*	b
8%ff
	ffW%/
fi	
=	R} @3*e7.54761, /@!18K
bS
fi 
fi"#J=	,=	P$+TP$fffi.%P/?ff$&
fiP$V#*$"#C'%' ? ;	b
&
ffb#*$"#$5Kv;=ff
';/G$+F=+9*	GE;
xXw	M"#&
ffPff"P
fi	%4E;
fi=V,Pf=+ffD$!*y
ff#fiJ
 D,:1Z=		==+b/>3V)>P=	Gfffi\E3VV"P=ff
fiGAE_B
-	fff+*5>v9V?=+
=ff
.+&%'/?+
XW
"++ff-J+%K$fffi!
fi	C
fiq,E;PB
fi	,ff*:		C=+;=	Y"P=	+
"#C+
% F?G
		)JP=	GD3</?$\=3,
fi"#P$"#$5G^&=	JE;.	6:)
fiJ/>3?D 
fifffiGfPff"#
F?GE
fi=V+	P=	T=+ffD$c	M$Rff
fiR
 YD,:)E=ff
"P=fE_ff?/>+BbP=	b%H3
Xfi	JW&
ff2'#*$"#
%H3
Xfi	c
fiP$?+%<Gff$&
fi$ff2'#*$"#;%H3
X-	:	+?E;ff?+fffiB
 4y;ff"#/WD$5
0=+b+,=	C
fi/Gffx
"+
fi;+%_P=ff
M$fffig _Q+ff-V*9	(yzc
-"#/Gfffi	$Pc
M+%_/a
fi	
"#$R	"#:<$!$"P
3xfi&
fi"#fP=+J	 $"#3yzbff3_EC	(ff"#V=		
'
"3xfiZff$R
J%_
-ff#@D
fi	\+.+&%'/?$!
fiZ.+
X$M.+=	C=+%/>3X-V
xNw+fffiG3fi
fi=	/V5
 V3fi	&
QX
fiBc=ff
F
F		P=	#fi$F
fi!"#
fiT&
fi"#M
fi;/>B$F	$"P
bE=_P.ff+1;9*	(y
3fi
fi=	/d/?+B$5^H<"G;
-"#
-<J;
B GEM
"#ff83-
fiP=	/
	!	4:+
fi"#/G2
fffi:)		/?+
"+:fE=+bff++D#+$F
fi#@(	P$&
fiC+E;M#@()$"#$%'/?+"#
+ff3
fi	$CDG"#
XNw"P
fi	J/G;%'/>3		)5Z#x
fi=<+>3fi
fi=	/Vyz%'/>3	P	2

fi$F	+
ffb	b+%K,D	/,)+%KE3	F,	ff..+A=	J3fi
X=	/VyzQ=3
fi$:ff		TffG	
"#
-	M=	Jfffi!
fi/>+M.+	+#?D?E=ff
"P=V+qSfi
X=	/yzK+3fi	Y!=	ff?c ff$45
Z	#@(?	]=	Vff
"f+%J=	+ErZ\=	\9*	S
fi>#++
fi$aE;
fi=ff
fi=	q
%#+/GE;BGPYff
ffb=	Y	+	.+
-Sfi
X=	/5

 u t9*	XlrmtQv    

rzl	



tivrv>



n\ 
 vl	60v

 =	=ff
fi=	$afi# :;9*	+u#+f
-LL
X*DWE3	5u9*	#+.CE;
fiP=u
 G
"#/GfffiPfff+uP=+,%H3
XCP+
&%'Z=	D3T+$W.+&%'/?+
XCZ	#+V	E
"#/GfffiPff+*5<9*	,ff/,
fi.Q	J	!
fiG+%1C+!
3ff+f+,	,#@	ffX
"P
fiF	
fiG+%*."#
fi	
L"#/G/,
-/Gff$5<ff.?=ff
?E
fi=uP=			D"P=0.+B0ff`+<:ME=ff
'"="+0#"#D
	
fiKff'+	ff
fi	Yff$"P
'&
fi*:ff$ff-
fi	M
fi>G
fi"#/Gfffi#fiG)$"P
XN$Wff+*5Kv;=ff:ffJff+E`
E;
fi=]$+."P=	2H"#ff+<=		
'
"b"#P$
fi	V\9*	(yb.&%/>+
X6:4E_W	$]V"=S
fi
P=	Y+<ycfi("S_#N	@ ~$P."#,ff$"P
&
fisV#*$"#,]H	/G?%'/	+P$f+%=	Gff'+
"#b?+	=	$5
v;=	,&
fi/Gff-$E3>+%<
fi
-	>+]=ff
M"++ff
XX
- a
P>#%'/,ff J<yzc	2-fi#8"#DP+
fiD,%P/s	$ff=	2-N.!<#@	fffi.+!
fi,+%*=	b"#+%*ff&&
fi	J,R		MF	
fi
- JR		+
>?ff	=	2-N.Mc
fi.+!
2Hffff
fi	fff	=	2-N.b$+#"=H&
fi	fG."B).5F^HZ"P=q?"=	/W
)  n    >E;ff?	Wfi	R		,3X1P=	J	EOff+;P		$fffj
 =G G %0 O\? 
fi$

fiTE;ff'q"P=	ffD,=	.$!.f""#$bff+]H&
fi	f/WY=		!

"s.+	B
fi	?
fiff%'/>
fi+4
#@(fffiC
fi$:)fi$3
fi	>P=	aSfi+P$\=	?."PB?%M+M#@(ff-.+
-f
X%<"Bff."PB
fi	>	PS$
	$"#$+9
5 )   G G)  n k :?E;fffff?X
-BE;
bE
fi=f=	,#"#$f		ffyzM&
fiffX
-	D5v;=ff

n\p

fi yz){	{z{z0{ 
 	

mez)zx	0	yz{



zy	yz"z{

/G	
XNw"+
-G,+<yzF	2--#"#ff	fiD>#X
-/,
fi+$P=	T	$W%'b+-3wff'+	2'S3-+
fi
=		
!
"+:ff&
fi	,
-$?=	M%'+X-SE
fi	b%'	=	ffB	F%=		
!
"T"#DP+*BD	+E;fi$ff[

5;`=	=	O)    G)  n k :f		"#$ff	W
b
fiZfffZf#"#$:4=		
!
"C
fiff%'2
/>+
fiG
F		=DcG$Gff$"P
ffJEc=ff
"=Vff$"P
'&
fifW."#35

e5  '% <)  G  )    :M	.+P$9
fi.	ELff+9
-K$=		
!
"J"P=	DD!_Ec=	=	
Y"#ff
fiff	M."#!
fi	G"#.S
fiD#9%/P=	b+ff__Ec=	=	;,#N	J,"=ff
X'f ,
X%

fi"=	ffD$;P=	M+3:DEc=ff
"=V 
fiffX
fi	,GP#N	+.5

})

qe5

 n    Jx
fiBE;
!$;=		
'
"
fiff%'/>+!
GGff/,
-	TE=ff
'"=?V"#
fi
fiW
=	$+	$Wx
fi	B!=	ff?,	ff$!$WN.$5

)5  %'<)  n    T	#+$
fi.""#$ff+
fi$9=		!

"9b#fi$"#E=ff
"P=Y&
-ffX
fi	
Pa"#D
-D	b#Nff
-	5
<&
ffJP=	f.
fiZ%T=ff
,ff	=	2-N.!GS+!
+ffJ+%<:K+
fi=	W
fiff
fi!
3<NP$Zff'+
.+$]=^K9i+ UT gj85 i;fffiq+	ffX
fi$:;&
fi"#=ff
G"P=	+
"#fP$Rff
fiP$Gff$"P

fi	]E;
."#
fi0+#@( 
fi*5ZZ"#ff'u"#	ffL*9	(yz?P3
fif.+P+
fi$,ffu/>B
fi	ifffiZ
#@e/,
fi	?=	"#	PDCff+*yz,"+P3P"#	:?=+,"#	P>\"=	ffDf+L+			!
+
v  :+0"=	ffDZ]S
fi!.+5  fff$"#
-$
fi0=	\	
fif!$"#
fi:;$"=P3
fi
.L"+0\"#(ff$ >]/?"#Z).+>+%JP#N	$V+."##,t =	$Z"#ff'L
E
fiPL
fiffL]+fiSXXu""#$&
fiff-q/W/Gu+P$+ .P$+\ff`!	$R	ffVPfffi$5 
>
-
@1P3
fi</a
fi=ff_#@	+?,C E;2H!!$R	"#[KP."#FX
fi	B4:P#N	MX
fi	B4.5 i;fffib,E;ff
"=	ffDZP."#G=	AN$ff+*:;=	^
 i;fffiLfE;ff"=	ffDf=		ff-$/GAX
fi	B]Z
."#$4:=	
 i;fffibbE;ff'G"=	ffDM=	T"P=ff
XW"#$)
fi	,,	
fi	JP=	P>$"P
xN$?D
=	
 >
-
@43
fi$5  K=ff
)+
fiff$:+=	;/>"#Pb.E_ffC=$_)"#/Gfffi#fib#@	$"#	$45
I+
fi"#M=ff
Q	E"#DP+wP"#	M$Ffffi,=	b.+	+#G+Vff'+>/W(
XNw"
fiG.+P.
+ffffi>P	cE=	V=	,M+%8Z"#
fi
-+A=	$+	$X
fi	B	+bffffX :)	ff	$

?/>3
-D.S
fi	$45I+
-/,
X+!fi:Wfi	ufff	=	2-N.A
fi.+!
fi2Hffff
-	u$+."P=0
?$4:M=ff
'
+		D"=Z	P$$,+<yY"#/Gfffi	$65\I(!/>+
'"P
fif
C
fi++P$VffZ=	??+%
fiP.+
X2
ffff
fi	0$+."P=*:;=	+E;$:+=	A
?+	=	?	fffi/ E;
fiP=`	/>
"P
fi&	fff=ff
'
+		D"=f;E;#X [9/,fffi
fifffiM3
-.;"+		;	$"#$+!
Xfi?b!%P/G$W
fif$R	"#5;v;=	M
	fffi/P/?K%'/=	M%H"#;=+3x9*	,3
fi.Q
fiff+-#N	$?/GDF
fiff+fi."#.
%+xfi+E<$WDGP#N	$L
5 KK$:ff=	MfffiGff'+F		$?ff>,"3X4R
 )  n    aT#+$
 UT(gj
+?=ff=	f"+		c=$J,.+ %P/>+&
fiW
fiff+fi
fi	JP."#
-	ffX
fi$?GP=	/HE;
fiP=		

fi+
X	G	/>+!
"P
fiH).5v;=	Y	$+PG,.3*)D&
fiff-J+fi	
-F,=ff
;	fffi/V[
g oM#3>/G	
-	Y+ff>P3
fi.F=+MffG	F
fiff+fiM#"#
fi*:ff"P=V}} @3*e7@.
4
@++
 } @3*e7@.
4:A@1 fi:1	ff
X+	=	bP3
fiJP=+!
 CA;nWb."#b=J)i	2
ffX
-$45
g %'/3xP."#
-Q
fiff
fi
S-:#%'C
fi	G+ff>#@	&
fiV	+	.+!
fi57M
g ^&	C=	%K*+ UT gjq#+D+\3xfi+EP=V#@	&
fi\+."#
fiV+b+fff	(ff5
0=ff
Xfi;=ff
'<+		ff"=G"#
XNw"#$<!(P/>+
"P
- :+P=	=	c
=<=	TffS+ff.+$%9!$+."P=
"#ffs
fiP$"#$D0*9	S2Hfi\.+ %P/>+
XE;
XXb+1?=	
fi"#$$ &
fiU\+%YP=	
+.SX$."=V!"#5K^H\+ff"!:	=	J+		ff"=V!
XX4+.+ff$"#/Gfffi	$65
499SPz;*ff'';&-<P4'_'3<+3H-.b'&$$$'bO!(	
N

n\{

fi

 

jQP

 l 

lntQ9!t

yz{z|~}a

	

fi

nrmtmr v	v

v;=ff
b!$"#
fiZ"+\fffi\B."P=\=	G)D&
fiff
xX
fi
X$%M
-D.+
fi	W=	,
ff$M%_.&%/>+&
fiS
ff+		#
fiffM=	T+A%./GE;B45*7			c$$+."P=,E;
XX	
-/Gfffi/GffK=	$F
ff$F+,$!KJ
E=	=	bP=	VE;BVMP=	Y	P
fib$"#
fi\	$!.5  
fi/Gfffi/Gff.+!
fifE;ff\3!3xfi+E
+ff
fi,
fi$QS3fi
fi	M=	#
fiF	
XX
fib+%*
X*ffK3
fiK=		
'
"5Z!$"#;=+
} @3*e7.54761, /@!8K
<+
 } @fi3*e .54@*\fi
;.0/<, 1, ;.bE;ffs	+
ff;=	c$+$!1ff
'	+"#:		KE;
E;
XxP$;=ff
;)#X
fi#%5
^&<E;ffW3b)
fiff$!
fi	b,ff	ffX
"+c	_+Sfi( 
+%19*	b%'<P=	<.&%/>+&
fiS
ff+		#5KZb)#X
fib=ff
'<E;ff'G)Y,.S
fi=ff%E_+#,#@(#"P
M
fif/>D>"$5<7e;#@e+/Wfffi:
=	WN.G]=+!
 RTK(
 Uw) KwI+
-/G/G:;$ffT#+B$CE=	Lff		+
fi	ffZ
s\	ff
X]
"+SP"#	;X
-B=			ff
X	5I+
fi"#
 RTQ
 U46 Kws'X
-BT9*	D$;b
'"=>!<+%1P3
fi
=		
!
"=+K/>."=s%fffiY"+SeP"#	$:E;!$"#F=+K=	,"+GMff$"#/Gff$C
fiff
+*2-X
-B	
fi/a
fi
fi$K<E;b9*		yz5  	J
X"#fffiC
fiGP=ff
;+3fi	&
E;ff?"#"#
 RTK(
 Uw) Kwy
/G	=&
'Z"#!
fi;E;
-=V/GP
"b#*$"#.65JI+
-"#a<yzM b'DC	$!D.
fi\ffD$M	b3X-SE
"#
fi
-3<#*$"#.,&	J=	ff>"#/G		P$ZffZ+
fi=	/W
"s%	"#!
fi#b?N.J!E;ff'\?
	Z92HfiW."#!
fiVPV=	
 K4*G
 TQZ ffP=DZ#4:;$ff;S
 Rff
 jT  ff=ffZ
Z#4:ff$ q(ff+		.6510=ff
X-
 Kw9G
 TKM=+fi$K"#
fi!
fi3#*$"#.+b	ff
fi.3RD
xNw"+
fi*:

fiJffff$b	C/>+."P
= R*TQ(
 Uw6 K4,
fi#@(	$P&
fi	$6T
5 Rff
 jTF:*=	+E;$:9=+fi$s/G
"C#*$"#.C+
"#ff
fiff	"P=+	5
U;WV

9

}^'<@@z +





Zb=A E;,DS
fiV"#ff"#
fi	?/Gff
fi
"S9!
fi$[
5;PT/>B;/G;	$"P
!_P=	+	+C#@	ffK+%)$ff	>P=+<"#ffCc$3X
fiU$CffJ&
-	
x
fi	.+ff2'#N;ff+	ff
-	:	+
	5;P"#/G+V0	exK0 b+/,	=+/W+
T-$:T3ff.:E=ff
'"=L		.!	$>&
-/,
X+

'ff$;E;
fiP=ff
fiW
X*D;ff	ff
fi	,%'.+/GE;B45
v;=	cE_B,f	XQ"PfiD!#fi,+.3X-#	<+E*[=	MBC
ff$
fi>)=>"$Q
K=<J	2
+ 
fiTff	ff
fi	G3fi!
fi=	/"fJ!$?>	+	FX
-	.+Gff'+:ff	+
'ff$?=+M.+K=	bff		
BM/GC$"#.A+%8P=	J$!F%'
-."P=	+
"#$:\ ffF=	Jff		"+."#T;E;#X8
/>+BW#N	/GffY"P=	+
"#$5I+
fi"#f	xKi0=+WG+%TVn beD2-x
fiB,	$ff.+!
fi*:
E;E;T+fffi;CffX
";=	#@	
fi/WD.Q	ff.+B>ffGb+/,	=+/G+
wG-T#$ff
+f"#/Gb	$!fffi.;E;
-=>P=	#
fi. * 5
X





{  ZY

n



vlrzln



ntl

7 
fi.,/GW"Bff	4[,=	V	xKL#@()
fi/Gff.sfE_f	.3"P'$C+%fffi	"Bff2H."B
fi	
9
	fffi/?:K+/G$\[O L +][O L_^ 5][
,+
fiff?H.+	
fi	f%'/ qL$ffff$ 
fi+
-	qP=	
D	/,M+%1ff-("PB(_
fiD+fi$a
fif=+c	fffi/V5
v;=	sN.b"P:e5F
5 ` L :ff
fiff+-$+A
fiff
fi
S9"#ffN	.+
-?
fiVEc=ff
"=\3X1P=	Jfffi	"B	M+J
=	>#+fffi>+]"Pfi$+35qv;=	?DS<
fiZP=	a
 [O L_^ 	ff-/>M
,3'V	ff
X]V#"B+%=	#
fi=ffb
 [*:
		Y3XK=	Gff-("PB(b,	J"Pfi$+b=	,.+fffiC
fiff
fi!
3XX?
fiZP=	$,	fffi/> t`/GGff-("PB(b"

w6_-#WKX#1F' 3'-#b	'$K6 '$1+X4b'$K	4<''';
-c

k	$

fi yz){	{z{z0{ 
 	

A

B

C

mez)zx	0	yz{

A
B
C

J

K



I
L

3BS

zy	yz"z{

I
K
J
L
LL

LL
5BS1

79
fi	J	[Kv;E;1~Qfi	"PB(E;!x?KPfffi/>
W\\+%<$"P=Z=	35Jv;=	C
fiff
fi
'3Q!.+s%d LZ^ :	%'b#@+/Gfffi:)
-ff
fi
3xf		#Mfffi("PBT?
L%Tfffi	"
B w5  =	J
 [ LZ^ 	fffi/?J=3fE;VG=	f3
-.C+%Tfffi	"B	G#"B$\
fiff
-
3X-:
=		=V=	,+C	G
fiff
-
31."B	;+%K=	CT/WJff-("PB(6579
fi	JG!=	SEM;
fiff
-
31+N3
.$4%'E_M#fi$"#$C	ff-/>K"#/Gfffi;$"P
xNw"+
fi9%'=	L
  LZ^ 	fffi/>K"+C;%'	
#Ec=	, M+	B(cZ#4:4$		b+/,	=+/G+!
9-$:*$ff.5
v=	\	exKu#@	!
fi/Gff.C
fiff+fi+$]"#/G+!
fi	Z=	fff		$yzC%'/?+"#Vu	fffi/
E=	=	fff+LEC	.$%P/ "#.."=LE
fi=
fi.C%'/?+"#VE=	LP=	q+-	
fi]Z
/>SXfi	fffi/Ec$\MWX
fi	.>ff'+*5%e L,gf  L +H` LB d LZ^ +PJE;G#@e/Gfffi
#@	
fi/WD.6587e;#@e/Gfffi;
: ` LB d LZ^ 
fiD+fi$K"#/W+
fi	,=	M
fi/GM$Rff
fi$WJ	#+b
ff+W%!+fi
fi	J=	
 d LZ^ %'/"#.+#"=?E;
fi=W=	b
fi/GM$Rff
fi$a%!+fi
fi	J=	h
 d L_^ 	ff-/
.+P
fi	,E;
fi=fGfi	
fiW%'i
 ` L 5

cGP=+J=	$!>#@	
-/GD#b
-DfiG=	f	+	#+
fi\		"#$,fffituP=	>	fffi/+%b2
fi$"#
fi	G+\+			!
+cX
fi	.Gff+fEF	M"#&
ff$45

/% J		4D+j\bDb*	TLj
j

I$LjRQKkRK

Z!
fi$,M
fi/a
fi.+c	XK*yzF	P$D#+
fiC	+K"Pfiff#fiGff&
fifffi[)=G	P$D#+2

fi)=3KE;;	$
"+$6: F &b+
 =G) F w:#+bE;<	!
fi/,
fi
-8"#
fig: k F =ec F &c F =e
+V
 k:c F =- F &GG5 (4
	xKY!$K=ff
fi#+."P=ff
"3D	P$D#+
fi*:6
fi"Pfi
-	T		2'	!
fi/,
fi
-_"#!
fi4#@		$&
-	J"#	2
#" 	.cX
fiBf.ffmw:eN.b	#+G?ff+V"Pfi$+{w:4P=	q	.+G?ff+\f"Pfi$+{4:
=	]#@($"#	fP=	VH	!
fi/,
fi
-S+9kc F =- F &c F =-q"#
-*5zFyzC	$ff.+
-"#&
'.
fffib+%wff$P"#
fi	
fi)%1=	FE_c	
fi/,
fi!
fiK"#
fi651v;=	"PfiD!$1+3-	
fi,+f=ff
fi#+."P=ff
"3
ff/>3
-	2H$"P
XNw"cBff	SEfi$ffc
K=	M	
-G+%1$+#"=	2H"#ff	
fiff%/>+
-*[1+	ffx
"+
fi	2H		ffX
fi$
%	"#!
fiM=+JffP/,
fi	,E=ff
"P=\	(ffa
fi\=	G.	=q%<+
S8ffMV"#&
ffb	#@	$:4E=
"#
fi<P,
fiff	ff"#:ff
fifE=+;#ff$:	=	+E	$"#
-
fi;+bPG,"=ff
-$4:	+V,*5
l\*$K3.!M'$.'c$''' MKP<$+;+-oH*$6ff.6+13S3Z9n9'<;-#$*HPF$
3f P[
 4&z8P;.P-#$'6;z:.M$#'$,.6?+m1nasHFq$M$,HP<$ S#$'
G'3bP +-;'3' ''W
 KP<3SP_+-
 oo*3 #*-# 	 &(
 wc.F''?'$ '#
.3_'3' 'HP-#p
 !-": '$''H-.?'b3&$3<'.H!1$#> ##_). $	#$M'SP;$| S$
 am1nGP$#'$]
 f3 M$#M$'#$MX.c$#!V ##;1'B
 4
qr1stuv m1wYPM'$JP$'$JP<#$J6
$#'S#HP' b'+96X.'P-#'_'3<-.b3b$'# L3| S-#$
k	

fi

/%
j

yx

yz{z|~}a

	

TQj4b:TQI>)j*TQa;b*XTQj

v;=	C
M	fD
fiM"#$!ff"#?E;]	exK*yzs=ff
fi.+."P=ff
"3Kff+\	P$D#+
fi\+
+<y"#ff+4BD	+E;fi$ff:,=	JR	$
fi?
-/G/G$
+P#fi>+ff;,E=+T"#DP+4
fiff%/>+
X
E;Y=	ff	+
ffs
fiVP		ff
fi	>P=	Y#@	!
fi/Gff.5Tu"+V#@	fffi+
fibff/>S
fi	2HffffffJ"#ff+

fiff%'/>
fi+G
-f=	Jff'"#$[
5;>ff$"P
ffC=	SE G/>+#"=fe $"#._
fiV=	WH+
fi41x
fi	.+?ff+VD3
fi;=	C	$"#.F
fi=	

fi				ff-/VyzQ
fiff
fi
'31+?D34%'/>6:
e5;Gff$"P
ffJE=ff
'"=f+P
3*ff+fPa"#&
ff	#@	$:+
qe5;Gff$"P
ffJE=ff
'"=f+P+%1=	C+
'31'
-"#/Gfffi+Fff+f,E;BGf	#@($5

v =	bN.cff
fi$"#J+%<ff/>S
fi	2HffffffJ"#ff+4
fiff%'/>
fiW
fiff+fi$F=	+EO,N=	sX
fi	.

ff+?,=	b	E0	ff-/V: (+( E=ff
"P=G
-Dfi$<"P=	ffD&
fi	G"##+D#
fi?=	M
fi			;	ff-/Y!		2

-	;%'"#.D.Q
fi?=	MX
fi	#+,ff+*5ZJff	$GP=	J+/GM+x
"#>;
fb+/,	=+/W+

+Vcfi$[;"P=	DD!J=	J	!
fi	
-f=+/?3@D
-/,
fiU$;=	bff	/,M+%K
fi			D3*%'/>=+
"#3xfi>+	)$+
-f=	J#+&%'/G$aX
fi	.Gff+*:)+?
fifP=	Y"b%Q,!
fiJ"=	ffDC=	J	!
fi2
	
fiG=+F/>3@ff
fi/,
fiU$F=	MD	/,)_%*
fiff
fi
'3w"#
fi
-
fi?=	c
fi			;	fffi/=_+	)$+F
fi
=	b.&%/G$WX
fi	#+Gff*5
v;=	,	fffi/
'=N
fi	fP=	Y	
fi/>3/>+	ff
fi	V"+\)aRff
fiC#@()&
fi[c
X%<P=	J
-			
	fffi//WD
-
 ]	 $"##T+=	CX
fi	.+Pf	fffi//Gff
fi
 	$"#.:)N
-	f=	G$!
/>+	ff
fi	M/>3M
fiff+fiK#@e+/a
fiff
fi	b3X{z





<|

)D&
-ff
XX
fi
X$5v;=	_3fi	&
)
fi? M+	B	1Z#'4:D$ff

 /GP.+$;P=	Y)ff
31"#D!T+%</?+	ff
fi	?&
fi	G=	,#@+/GfffiC+%<+fi
fi	G=	 f  L 	ff-/
ff
&
fi	>!""#$&
fi#-G;X
-	.+Gff'+5<v;=	,"#/Gfffi#@ff
fiG+%<"#/G		!
fi	G=	b	!
fi/>3*/>+	ff
-	
+ETs#@()	D!
3Xfi\E;
-=Z=	f&
fiU?+%T=	WX
fi	#+\ff+]VP=	>)+
fiffYEc=	!+fi
fi	V=	 f  L
	fffi/&
fi	ZV!+fi	
fiZV#@"#-qP=	/GG	ff-/ JAX
fi	.VffZ
C"#3xfiV/G
#@()&
fiC=+&
fi	>?/>3xfiFX
fi	.+P>ffZHfP=		=f
-$Rff
fi$;	f	+	.
fiV+M3XH.5
ZG	PG=+b=ff
'c
J&
-/,
X+Mf=	
 MG365	Y5X36E 8<ffAY;@	ff$$\ffZ~A
fiDP
fiZ=	>"#D#@	b+%
 ~;0~f
-D*:K$ff#5,^H	!$R	ff,#@()
fi/Gff.bE;,$]?=		
!
"+:1ff/?3
fi	2Hffffff$:
X
fi	$+P2'
fi/GM/>+	ff
fi	?3fi!
fi=	/V:	ff$"#
fi)$?
fi\ M+	B	OZ#4:9$ff#5
 "#ff+;+x
"#%,=	f$"#]ff$"P
&
-P$Rff
fiP$J=ff
X%'
fi	A%P/	$ff=	2-N.G$+#"=]
f)$2-N.GP.+5v;=	G-	JG
"#!$J	Y#+	B
-	f%'	"#
fi
fiff.S
X 5Vv9Z"#	2
+<ff$"P
&
-M+%_P=	G=ff
fi.,&E=+ /w$EO
-qP=	>"#	ffbff+\V	ffP$M	#@(6E_,	ff
X-J
$+."P=	2H"#ff+=		!

"F=<$ff
SXfiM
fi/Gff-/GDP$Gb)+X
"#,+%<#	ff
XG#"B	9%'/P=	P2
/r	*5z0ZG"PBD	+E;-$ffJ=T=	G	
-
fi+%_ff/>3
-q)$"P
XNw",=		
!
"M"#/GffX
"$P=	
"#/G+
'?E;V+<yzF!%P/>+"#J+?=_%<	XK*:			cE_b+	b=+;=ff
;	
fi!
fi

,P%3
-.,$"?	exK\$=		
!
"M
fiff%'/?+
fi?
-.#X%5^&	xK*yzM",=	Yff/>3
fi\2
"P
XNw"Bff	+E;fi$ffcDBJ=	c%/+%1C<+%*.BD2'P$ff"#
fi>P"=	/>.,F=+ff
+B,d~\" oM/W$:
$+	4.+P=	K=+G.	B
fi	M%'	"#
fi:+		<)=>	/?=		
!
""#ff(Bff	+E;fi$ff5	2
%P	+#fi:e
fic
M	$+-?
fi/Gff&
fifffiCV!$P=	a"#$)ff"#GE;Z=	,E;,%'/>c+%
ff/>3
fifBff	+E;fi$ff:e		T	#x
fi/,
fi+P>#@	
-/GD#:ff%'#@+/Gfffis
fi\P ~;+PTZ#'4:*$+4.:
=	+Ed=T.BD2'P$ff"#
fiV"P=	/>+#>"+\	+
ffJff'+		!$ff	Z=
QT&
-ff
XNw"+ff
;=+;	#3
fi	$?ffFyz;.+	B
fi	,%'	"#
fi5

#.KP<3SP;SP-QP$T9$6;!!z'F'$S}.~~5u;$'#WF4&zff3*W,'$cz'H'3'.*P$,
6'$''MS
 fi6HSP Wo\+H'.D  	>	 &G
 fi6H+ +	 1N. &3B
 9 '3D >N# 4X#wff $P;#
k	$

fi yz){	{z{z0{ 
 	

KPfffi/
q~cI 
qc
~ I 
Gc
~ I 
Gc
~ I 
c
~ I 
Gc
~ I 
Gc
~ I 
c
~ I 
c
~ I 
c
~ I 
Gc
~ I 
c
~ I 
c
~ I 
q~cI 
c
~ I 
>c
~ I 

G~cI
 ~cI

 ~cI

 ~cI

 ~cI
 ~I

 ~cI

 ~cI

 ~cI

 ~cI

~I
~I
~I
$
 ~I
$
 ~I
$ ~cI

mez)zx	0	yz{

KP("+5K!
fi/GCH/>$"3

	xK
5
	5 
)5 
5 q
e5z
q	5
e5z
5
5z
5x
$e5z
	5
	5 q
$	5 
$e5z
 	5x
qe5z
$	5x
+)5z
5 
	5
	5
 e5
G
 q	5 

qe5 
5
 qqe5z
D5x
)5 
	5
 qe5X

	5



zy	yz"z{

I)$ff	\w"#5
+
	xK

 
 
G

D
 
%
 

 
q
q+%
 

 
D@ 

 
S
 
ff
 
	@ 
%
 
ffe 
 q

 

e@ 
+%
 

ffe 
e@ 
+%
 

 

 
3
 

 
q
ffe 
(e 

 

v+fffi,[;</G+.+!
fi)%/>+"#:1+\	xK
X

fiffA   .


r4rzl	omnV	nzvil	v

v=	,N.C=	f"#+fi	/Gs+%Tv1+ff-V>=	+E=	SE+<yzs%'/?+"#"#/G+$sZ	xK*yz

fi\++fi	Pb/>5 (+$ Z,"+	
fif$ff.M+D3
-_ 
fi	>P=ff
F
fiff%'/>
fi?>ff.3E+ff>	ff
"#"Pfi&
-<+)	K=	M#+!
fi+_/W
fi.+%*=	c E;b+		D"=	$[=	c E;M	#+/>E;E!
fi

fiu
X*ffC+	+$:K	Lu
xPD,/>"P=ff
fi	$:;+]	#
fiP=	GEC	
fi/,
-U$]\	(ff"#
=	J)$MD 
fifffib.3E0%'/?+"#Jff	/,.5 (/ c	=	#fi$P;E;J	bP=+=	,++fi	Pb
fi/G
D	/,).TJ"#/G+#+fffi[<]ff$AGE;BW%;q!/>3Xfi;	fffi/>:4	xKV)M
+_	Pfffi/>:ff		M=	J	+.WffG	T	$;=+#
-=		.+/
;"Pfi$+-	)
fi35
b+/,	=+/W+
8+\cfiJ!$b	xK*yzM!%P/>+"#JP#+
fibG
-.+E=3
fic
fi
	.+!
fi	,ff+Q%P/"#.+."P=*5<v;=ff
'<ff	/,$:)"3Xfi$W=	B
 W0?5	2GFWL8:;><P7;2\360F;3:
;ff#N	$f,
J
 3; :4E=	W
 C
'=	,
-/GJ$Rff
fi$Af+fi,?	fffi/:5)5 ^  L_^ :e%P/P"#.+."P=q+m
 C
'

=	b
fi/W$Rff
fi$?G+-=+/GT	Pfffi/&
fi	G,/>3xfiFX
fi	.+PYff'+*:ff55	M%%
 ` L 5
v;=	M%'	=V+N	%P=V"#+fi	/G;%Qv+fffiGb"#/GJ+L+	XKf=ff
;/W
"+5
v;=	?R	$!
fi]=	#%'>+!
$JbE=D	exK*yzC$ff	D	/,#Y>"#&
'fffiq!
/,"=C+P
fi,/>+ff
-ff;=+>Fyz:++!
"#ff+Xba+	ff-/>:+GP=		=>+!+fi	
%'/?+"#G
'b	G&
fiff
XNw"+fffiV)$5\v;=	f+E;J=JPqffVE
fi=]=	>	/>6y*#
fi
%'/?+"#f
fiLff'+	ff
fi	%/ P"#.+."P=*5  ?79
fi	VZff/W.$:c	exK*yzW%'/?+"#
ff.ff$c/,"=%Hc=+q<yzcV	#+
fib#B	5ZC=3J	?#@(ff'++
fi?%C	XQy
=3
fi$:			c
fi.#$"#M=	Y3
fi	D2')."#ff.+bff	/,c
T"P-$+$[K=	$!Jff	/Y).b+b=ff
-=
$"+!V	xK*yzC%'/>"#>	.+
-G.!B(bff#ff$C/Y"P=Z/G>Rff
"Bfi\=+Lffff$
)*D+ -X#'3 F$FS'9X.Z!-G3SP*KP<$+;+-o9$6D.66 -. 	 &
4[
 9ff3 Wo9'$;;.3)>l3B91PGffPzX+[o_>;11>_>33L:&&1h>h&
3O:3>:>F@Q&1>'O3



fiO;;ff

1800000
1600000
1400000

CPU Msec

1200000
1000000
800000

SPA
PRIAR

600000
400000
200000
0
4

6

8

10

12

Problem size

9;h;O;3F3&T"F1BQ;>3i<&;<9;

9>FFi1Fi13;{"F3hWW;F9<BO1B"39F3<Bi;SQ;QFp;;
9;FL-;19;39WJB<(=TQ;%F9pBJ<""-o;
Q;%F;<;b+B5<T;;&;>3;;ZQB1>">;=L;FO+;
39Wp9OTO<&h3<hF9<>;F";JSF3hF3J1Wa";3990F39;
<a3F3;3h1B9h3F<;F;F9F1h;1F09WW3;39;S<9

	ff
fi	


;



F;;<9

+3{3O

3F1T1F;<>SiH9;"9T3;3G

<B9;S%;J;1%<B"FL&



SF3%>"%5W1;5%;h _19;O"

WB3F9<>;

1>1SF3S";;39;p;

;h;F<9;W;>9WF<B3

 "!#!$&%'
(


;O3{p5&{ip3><B3Tp3T3&O1B9F3<9S+O9;>bF

F;<W

)

399;J FG1WFS;3;3-F3&JF1WJFhO;W9SBp;=L

'

;QF>3{3%Oi;%FT119W;<9TW53;><9S;QF%;\TQ1F><;O&
J<B"

*

FH3;3J3B1B3F3<9F3O



,+

W;;<95;W F1W+O

213)4

;<9

;SFhF3O9;>GF9;;;h;<9J

.-/

]F

0

i"FG;W39Wp <9H3S;

{;<Bh;;{F;{W<9F";LF;O<TFh;;<9J

)5
7

<S91hJF3B1<&39<9FW;S

H9S<B"W;<9'399;1F35

26

<SOF ;3W<9>TG;h1F
;G31F3OG<WF31F;

F3&JF1h;G3O3TS%p;<9

1WF><T+\F39;TW"F

9

T;p1B3%009;L1F9;F

8 :9 <;>= ? A@CB
  3

 

I

D

;1 >1

FE HG HG
J 7J
L

O330 3

&{1FO& &3h&O&:>& :3



FJ ffE

K

ff31':>SO&3>&3&:>p{ff&0&3:&


0 &h1h&:( ' %@i 33

fiMONQPR S TVU XW
 

4

&Y M [Z P]\ SY^ R`_[P\Ca

&;F ;F



;





dc

bSF3hF1T5

<B3W;3995;39;J;33<9>

;;B<SW;19S9F"TB;"39{"-99;
Fpp;F

M W	Y bYS P

;

+

Q9;;

OSF19

"F39;hTFH1W

_(<9>><BF;;<;'1B;O1;F395>O%1F<F1pQ

<&%FT9W<9h;<9

<T9<%<&9OSFOF>139;h9h

p;<9

O<BJF9;WS9;"9i<;SF+FS&;;9FOWF">13i;1;5OS%<&
9;1J<BHO<BJFJ3<9><BF3p9H399;SB"O9;;;h;<9

5G1F39;J;

<;b+>%3&JO9T;p3{S<B"F
=;;O

bFW;1&1F1<>\OJ;G%;"9T;<9

9h5;W<&JB
{9;F9

gc

;<9

*
e5

;%9;>

9SB"{F&{";F>{9

*ih

<<9

;0QL9



139

|{~}

S;FWF

F3&1<Bp9>SFGh;G;>39T<B";;T

<FF<Z9hF"Bh+W>1ZS;F

F;;;

 >

*ih

SFb<G53;;SO];FL



9; >5FJ;i;5

f6
jXj /

<pLF S+3{9;>"T<&

kglnmo&prq&s	out`vxwy	z
4

b/

Q<B+]F;F

&339h<TF;

h;

j	j /


QF9L

 i9<3

;B<J9;>

<BFJF

]F&3aFS;T"WW F&59

;3<>39O;WT09 F1WF3OH;W3Oa";;5;QB;W;F<9;

0
* j	j b/



<B;<9;G093;%\F3h1F3>9<&F<339;W;< ;TSBQ

: g
|  *


 c

LOW;FJ5

j	X/



Z



H %93OF

O53<<9



F;T-

* j		/


; 1%;;FLF3QS0B<

>5S<>><B<B;;

*

;FL-<BH;5>"39ZF<F%;W39;TOFhJ<9;<B;G"W



1W<&hF-O;%{;% 535+ffB;"39F

:/



1B3F3<9FF3O



;<;O<Bp>; 1&1=<9 \;9L1F93;1F939Fh;F<



<5

O1ff _5

V6


50 

><F139S1B Q&;%<BWF;351h<>><Bff<1F539

|

F>F1;09;O9Fi <

>"9Z&F99;iB;"399;

<>3

<BO;3<>39TOG-<B;5>"391FB39;SF9;OF3;&1<
1F319<>

h

* j	j
5

;FL-W%1<Bp<B";<9;FSB;9bF1;OT"9LF><Lh09F"
;b093;

&T09

}

S;FWF

F

QF9



FW;9<BTB;F3p91W<9;

	j/

;%

;0W3;F<;Q3<

>O%B9

FL;&>WOS1>

%F<9<9JW;ff3FBS<B"FSFW<13F<9O9<9];G139;5>"39

26

<139+9<B%F"F

hBQ;9"h;W1=1h1B3F3<9F3O<B;F3

"F

;i1W<;O;F3

n * }

O;OOhW;";>39B3&F3p<B;<;hFT9<hFT1F1;SO9pFF9;
5;S3>"9_B;<99;



x

;;>3F 139

%O%B1F3

j	j /

iWFZ;





9<>"F9<19;J9Q9J%%-h;;>3G;3S939S9F1T"F3;J F&5

;3<>3a"FG;;Q;3<i9S<91;FO139Fi139F9JWF>1;<

&

{LO<9h<9L1FB<h

}

(35pF93>9 Q{O1FB<

9L9<39;hF<9;;3>F&J39F"WFhF1;<9W<L19;;3O
F;];9S930

j	j / 

139



 1

;<9

* j	j /

JB3B1F

195



 	g * c
ff

j		/ C |   *

Q9T

 0B3b<139FQhWF<B3

ff0

OF

 %

{

19<3

{"F;1

<W%<B3WWpB1;F<<;39;

399;F=9F9F;W9"<9;J;< ;
 

Q
 &O9;9;J;S9S&39TW3BhF

fiO;;ff

9;139LO;3O&3;F%F1W<19p9;p9W;O<19;5<;;
9BO+5<9hF%;a1<&JFb;<S;i3G

* j	j / c

n}

W%3&F3<B;<9;hOZ&L1="W<9O5

WWF



 F

* j		/

Q9T"



u

1

BT;<iF39F%<BG;p<B;;-Q<T9W;<1B9F1W<9F OF1

*

1H%;33;3Tp;>"T<BF9;HG;1p39"F];";>39

7bfff

;

<

;S<B

u/

&O11;3B

;;;SW<1LF113T;&1HFQ9

O<B3F1 >Z;3W3;3JO9G;p3FQ%<ff"F
3;T3;3

<5p;hJW;WSB31W5ToB<3F<BpF9;9;

;<G{9F19J;<3<9\;;<9
;<

p;h'9;h9WW



;<&&&39W<&;139 ;W;

H

L11;3GFJ%1O;

&<B";;

*V


 Q

{4

"B< L19<

F3W<B";<9;W&>{a9SB%T-ff<1<9;T;3<>9GF99;
;>9%<B";<9;h9;%;3F1h"ffF1W<99<BT3 ;
%F%F"3B+9<&T99OFB%11<;O



4

W59;9\13]Fh;5BQ9

 <B

jXj /

1BZZ



&

&+<B";;{33ff3;

;<B9;;J3;3

OT3%F

W<3LOh;;39O<B";<9;F;955BFLQ&T<&>WO"

HFWFHF9<W3&F3

c

<B;;>J;F<>31FH;

;<9

<T09F hh9<9W<h3;3

;<9

39>GO;JB919GF;;99H

;

F19HF3&1<B


> 

{;FFL+{Fh

 139

<J9;'<FF<<T&39

9393;TOF;;B33B1<3>

4

&gl.xwp[rwA
JFT;5;a"

393;GL\;;<

*

3&F3<&;<9;GF3;

B<pFO;;";>39T;F<B;<9;W<&3<

/

9;>"S<BF B9Tp;;1O

;;;B19p>139;"BS<B;<;<&9FOFJ;9;p;
9><QWTi;9;><BG31G3i;;<
O;S93;



3;3TB9'
F\;

Bi9W<9F"FJF%<&1h&T;F3{;F<;Z1W<9;ZF

'&3WTi9"i;WB39F139GF3O

<T;'<FF<<

(

<T9;9F<+F<;9393;T

c

;<&39\"<J9;'<FF<<G1<5;O9<

<B9p&h3F<9;;S;<9



F9;;FJ1F3>9<>

"%FFZ

hTF9SBW"1F119<

"3&F3<B;<9;J9H;WF>1hFBF9<19;

3>L&%<&F9

;h1;F3W513<91%31<B3;H3;3J3B1B3F3<9F3O]1W;;>"39F

0

 L <9W"FS;%1;5h%<BTQ;>p<BWb<;O9;;;;<9G<FW&3
1WFp;L3;3G(+3BTF1OhF"F;9SB"L;FL;3G-F3&T"F1

BF1;>"9;FZ;;OS;

Fh;S3<>h3;<B

FS9<;O9<9H;W1<1;h

;9W<FJ<B"%;<9JL%<BG;JO1F<F1Z

ffO.7b:%X!$&"% %&Q$&u%bb"!
4


g}

%3;<Bp1WW<L;39 FhS;9<B3F_ff;L9393;G-ffBT5;F3

i9;

;F39_91<9;LFp3;3TB9'h<<;;13iT"{S939;o<Z
;

<<;SF3F1W;3;F3%;139Jb"

&>{Bp<B;<9;HSF3S<93T19H+W3;

i

;<9T S;B<10>%"
9i"F



3

9

093;FZhO;S09;p
9>S<9'H3S9<39;

95339;S<TWip;<9J"3F<9

;F<;h1W<9;hFo3;3TB9'"H;19;;1";



3 a9<%S;<B 139<B;;





fiMONQPR S TVU XW
 

}



"4

;





p<B;<9;J99;T<;O<%<B

oFB9i"F;



M W	Y bYS P

;

u	ff	&


QO<;;F9%<J;19GFO

0

BO FW9F15

4

&Y M [Z P]\ SY^ R`_[P\Ca

&;F ;F



:

WF%T<% 1399J>%1<;T<T



oFZB_;L3<3B; F1LF3O;Q;FLSF;{"SB1WO; W;J5F9;B
%99;



4

H;B<p9F9<%9<%F"hT9h 139

d

W3;OF

;-

>"FBT3G>"9%1WS;b15i{"9F1<9b093;;;;h;F<>3>"F9;
%FpF>";T3>]3F1W;1F9F<T;19FFb;F<13>FH;

;



 139
=T0



;F3]0B3G1S

 a1<W9F



=

 139F3&T"F1

1V (

];;F"FZ9B59F99F15hTJ3;JF

W<&;';;>"39G39;
3Bp939;

B<9"39HiG<91<9W;F3GFhB

O<&\;&W1FW<9F3;3T"3B3HB;1&

<5;

1;9FObQ9%F>"5pFhT3W

1

OL;1;9ShF3&<BF

0
|:b%):%[

G3T3B'S95FW5G3;

 <9W<BT9393;G;;OL;i"WO39W9L;B<LWFF9<LhF1;

(

0

;iOW>BJ5

 c

;339FF%3;i5;{B&;;h>

Q9;;T;T<W;<{B%<J9;'<FF<<Q9<BT39;%;;>"39

n0

093;;OhF;h339F9J1<9;

}

Q

15<5JB

F93W";b3">;'159<3'1

F&o;;3B33&J]<B<];;139

:

9

WH0B339

<T9

 (

*

;LF&ZF>"FBT30F05<B;<9;h3;3T

S9W<95;b";;5

  :  *

>F&T"'Fff<&;;>
;%9<<&S+O<B9FJ<

 ff ff

 (

 (

91&%T1FB<



*

; F&5S19J;3<>3

&<iWL1;;9B;F"

  *i

;9;>139H

  :  /

 ff ff >


V &
E
V &



;JW1<B5;QB3;



hJJFS<9h;>h;

r

X;> J
fJ


  Q3ZO5313>

ffE

L

*

;F9;B

'1



b/

319; BOJ9<39;

9\<&SFFBp9>S<+F;F1

|  *i

'{<BJFp3FB0995339;SS1;F;
&1FW<03W<9;Q9L

{O4

5+<

093;

j	j /

1&Z

O;S<B";<9;T13JB95311BJF{<9

4

%;

4

;i;;<9J9\;G;;5<;

<

9WFO

%FOTOS5;J<BS39;FJ%F"&O;hF

%WpF%FO<BJ&O;h<BG;";
>;;iSFJB

;-%>F&

'hO<BH&3T+S9<

<;9;S;i<&;&30Z;1%F;i<&;

;;>3S;1F;OFO1Z1<Z
<_3&F3<B;;>


j		/

)

1W;;>3F+;1F

39;GGFB;WJ35+T"Q"F9;Bh

4

=B;19S9F" ;F

<19F;WF<S;bQ<B

J39F0F91%;B<S;S3



n	/

13

jX	/

<F<95

*

 >+h;SB";FSF3H<

/

+Hb5<;B1399 >

J;<3&FG<9;WF<

ffE



0O09<11>&3&&11&&0 &&311&O&3&

FE

- O3& 331L>3>OO>h& 3O3

[G

  11%3>3% &&3@ &0@3ffO&& >33'&@+&0F&33: Z1
&'&33





fiO;;ff

F>W

*4

<B1F9;&<Z&y3<<FSB

j	j /


j	j 	

9T



{4

Q9

1BZ

 1

 	zgAw]vpoutAouous	


O<&3>S%9W;p<WB1FFO9W<bO

( 

h





19<3F

%


c

"b;F"WF3

x
d

<B3

>"F9;




3B"39;WF;;h;;<F9;G9W;3;3G

hB

F&TOF";SB

S9

x

9O>O%;5

95 QB1

;33FSW;\;

n

Op&;F<S9F<

i j X 
j

 j

'   0;+F

;35139

(
H

';<F<S><B

|

a1p

;

g

0



>"F

;]3WSO;T1;<Z9<&;

H5G;1FHOG;SW<3B

i"39FZ59F1=;F;39

' 5;5<



<ffW <B3

%;;F

;a";5<WF

<BF+G3;F3><3B09





><>

O3>

i 	j
Xi 	j 
Qj j
,
'

><>

;;



<B

 ;

"' WF

i;

iG1+>9

moVo&yXo&Aou
h
c
}
{
	c *  / * j	j / 		
bQ
.	u&
	 &

uAc
c
 * j		/ c
<Afi	u
>ff

uf [ 	j 
gc A{4  * jXj / 


Hff
 
	 f&ff>
	f  * b/  
c {4 & * j	j :/
 fi
	g[	fiffH		
  !"$#&%'#)('+*,+-!.+/#&0212
fi	 	fiX 		"c
* j	 / n

0
*
 x
	  / fif	
3fi 5 4A
>, fuff&	ff
fi	u	6	 
&87fXfu
>	:9fi	&;+<
fi >=
g
?=


	 * j	X/ 

@
Hfff
 
>X" fuff
FX& A	 * / [ 	

 { 
 * j	 / Bf&fffi	ff
>fiXffCfi fff
 
>	D &ff
FX c

4
.
&
&,c

b * j	 / bc
	 nfiffX
>b
Efi dF
 fuff&	ff
fi	&X"fi	 uVdfiXH G	V&ff
> 	u.fi
>I G A

h A
( { 4 A * j	j ]/ (
g fi
 	gb	fi ff X 	AAfi	 	"fi	fi 	J	
h * j	Xj/ nbK <)LQbf.	&u
> MCN"
+ Og
	&u
>	eb B 6+ P)fi	QGSR&bQ ; <c
}

h * j	j / Q
}
$Hff
 
	 fuff
FX& >TU
  b
Q95= QF9<;
5

HF

Q9T h
O

 S

; >



b

1BZ

S



5 

O S

1BZ S

{+;1;



 1



<; S

>

&

_

&9;BO

QFF" FWF





 >

WF< O9;F



19<



1&Z

i"WWFZ



<B

i"WWFZ



S



5

;B;

S

  3F1;T;<9;i";;5F9

JFW<9<B;<;F

 > 


FW>;; 


&<





B;<9;QB1 ;F19O5&

;<B<9;



0F39;HF<9<9 9F1

" >L35'<1WF5939JBS<BF">9;F

H W S

9

F  55;

Z 1

Z %<>93S




390"39F{"F99;<9g3"9;GF<;O9<W <B39

BFB3 h

%

<BJ;

 > 5 ff;

0&<9hBSL

F<&ff

 <

3&%1<W<B;<9;+



F;T" S

 >

> h;;39h<B;<9;F

<9F





S

 >

%

W<9+F1O;;SW<B9F1F3

'

>

0

h





 0  ;



 1

;<B9<9;JFF93;W<BFQFQ0


V





fiMONQPR S TVU XW
 



}

;FF

&Y M [Z P]\ SY^ R`_[P\Ca

&;F ;F

  {O

BZ  %

;

}

9W<>39;FJ;<9G"

&{4
A

;ZF

h

W5Q



 & * j	j /
 



M W	Y bYS P

;

;



WX6X
Y
&ZT

|c

 >;3T3&<BG;;1

)j 	j

<B;<;FG;<B0F



;;h59F1SF



 F;J;;3F;F15W1;F

<i><91;

* jXj /

:

1BZ SZF

3&F3



 >

&T0B;F;39J&

[=Q<9193HQ4]3<9;"F"

' "'F

;9;39;+

* /

* j	j / (
\=
b
# fifVX
>bxfi3
^]DW3<^_
A
X  	
h
* j	j / c
{ }
`Hff
 
	fuff
FX UU j [ 	
h
* j	j / c
h *  / ufi2	
 }
	&af&	gAfi	K +	"fi	fi 	JK	FX&&
b Gff+ P
b Xj c<cc<
 {

c
g * jXj /

n
d HQ e9fi	&;fifi	f
 f&ufi	Xff
>g Xfi	 nfffi	&u
>
hA:	
>
hX&fi	&fffi	
h
	j 
 c
 { 
 * j	j b/
g ifi
 	_[fi ffH	 	
fi	 	fiX 		
b Xj
* j		/ i

 fi2 	/fi ffH	 	AAfi	K +	"fi	fi 	JK	
b 	j

& &{4 & * j	j / g
 j9fi	^;b
>k ffHfi	ff
Efi dg
 8?5$4	& G
PQfib
> P fi	: dH
FXg fi"P~ G
fX:
>u


b * jX	/

*
"fi PffXff
>fi	u	 fuff
FX& T /  

*
{ 4  * j	j / uc
/ Q 7fiV	
bdEfi g ?85)" _"_lA,b G
Pfi
 Pfi	f
 4fi	u		ff
fi	dEfi 5ff"fi P)	ff

	&u
>	 MmRxFf
>	 	:ifi		uk L Gbfi	&


{~4  * j	j / W=H  (  :c
cHW c  fi2 	nAXi:fu 	QAfi	 	fi	C
&
n3fi aod&"fi Of	:i &ff	ff
fi	#	&,f
 <
 pb !q#&%'r#(>'*s + -!.q+ #&0"1

fi	u
>
 c
 b [{
	 * j	j /
 efi2	
X[fi ff X 	AAfi	 	fi	C 	J	 j [ j	j
 * jX / tduGbu" P)
>5 6+ P)fi	QGMnvRfi	QG)3fi + P)
&	
)	uF 7fXfu
>d
Afi PQ:ffV

X&fi 
u=
& &{c
& * j	X/ g:
 Q hg	]w h xQfiX2Q hg	&z
 y &	Vff	u	
> 
 * j		/ Hc
H fi2 	X \ ffH	 	
fi	 	fiX 		 &j bj	j
S;FWF"3F



 >

o;G;393]"b3T3&9'Z

QF<>31F9;\;>< 

F3O\<;F;F1F\1S9W<p9\FB9&<S<B;<;F

'

<;  ff =

S;FWF"3+F

QF9F=



 >

00B;3aF1;hF3J;JL<BW;<

ff39aFJF3

<<9F;



 >



iB9;p<93'B

0   ;

9G3&FJ<B;<9;F



iWFZ

; ff 5

;



;WWFZ





 >W">H



Z >

>

;F9W<>%59F1J

B;<9;+

'

:

;

ffF 5

H %3 S

<BJ

53<<9 S



; ;3TB;<9;"{<&;<9;F



@<;F  ;

95F



1 %F<39>"39<9>1F1<9;p;O;393ff1;<BF"39;&F9<9;F



@<;F"  =

% S

1BZ S



 1

';;0"39S<9H%3;3T"3Bh31

'



<F<9 %



><<5;919;<BFF"1<>9S139F_O9S151'<+F<5 1>


5+<;;+F
F >

1BZ S;F

 >; ; 0;



 

;

;;5JF>0ff<B;<;

;19S9F



<; Z<

5+<;
L

1BZ S



 >



3;FZ1W<9F3&><h<&;;h&

'

; ffF 00B<9hBSL

 

S S





W



 5O;"&W00=3>+BLF3B09&><<&;<9;F '
;+  5

5F";ff h

B

<

 >


{S;3&<

5F";ff 

F1&3 h

9WWF h





Q<9193





>



;G%<;;9;<BFhF9<;>39F

@<; "

;



{

'

L39F";G

fiO;;ff

:c * j	X/ 
@
H 7fi
	 U[|f&	D]fiX
>uHAfi	K+	Afi	|F		
		Xj
* j	j / 
 { 
gc

  t} Hc
c 0
:=
6X
&~7fXfu
> :
 j[ [
" * jXj / k7f	&
	,GHu	fif	
	ffi	u
>
xQ&	 fi+P:fi	
  2
u
d =
c
|=  j b
[ * j	j /
:c
 fi
 	g[	fi ffH	 	Afi	 	fi	fi F		 	j 
* j	j / :

 Cfi2 	[fi ff X 	AAfi	 	"fi	fi 	J	
j[
} <{
H * j	j /

  j 


 S



>

;139;; 1h;3O;



Z;



0=

195F 

{+;1;





 <B99;>;F

195F





195F 



<9

;F



ff

F





;T9;

Q<9>93 0&<9O;<B0_F

O3

;

 S

% %  F

" >91<9<9O3>%<9;F F9B5<BiF;<9y39;Q<B3;<
5;+  ;

&J5



iF09J9;



19

'

4

909F

 

;B {";9



 1

%99





 > '<>139;&FS9<<39

'

<;F

&3;

S

F>">;<B

=%<9>93Z



 >

F

9<;;1<&1B

SB9'<&F3o39bF

% "; F5%"



+

F>{;9F9

<

F3B0F3WT1

W;;h59F1

F<<9

fiJournal of Artificial Intelligence Research 2 (1994) 227-262

Submitted 10/94; published 12/94

Total-Order and Partial-Order Planning:
A Comparative Analysis
Steven Minton
John Bresina
Mark Drummond

Recom Technologies
NASA Ames Research Center, Mail Stop: 269-2
Moffett Field, CA 94035 USA

minton@ptolemy.arc.nasa.gov
bresina@ptolemy.arc.nasa.gov
med@ptolemy.arc.nasa.gov

Abstract

For many years, the intuitions underlying partial-order planning were largely taken for
granted. Only in the past few years has there been renewed interest in the fundamental
principles underlying this paradigm. In this paper, we present a rigorous comparative
analysis of partial-order and total-order planning by focusing on two specific planners that
can be directly compared. We show that there are some subtle assumptions that underly
the wide-spread intuitions regarding the supposed eciency of partial-order planning. For
instance, the superiority of partial-order planning can depend critically upon the search
strategy and the structure of the search space. Understanding the underlying assumptions
is crucial for constructing ecient planners.

1. Introduction

For many years, the superiority of partial-order planners over total-order planners has been
tacitly assumed by the planning community. Originally, partial-order planning was introduced by Sacerdoti (1975) as a way to improve planning eciency by avoiding \premature
commitments to a particular order for achieving subgoals". The utility of partial-order
planning was demonstrated anecdotally by showing how such a planner could eciently
solve blocksworld examples, such as the well-known \Sussman anomaly".
Since partial-order planning intuitively seems like a good idea, little attention has been
devoted to analyzing its utility, at least until recently (Minton, Bresina, & Drummond,
1991a; Barrett & Weld, 1994; Kambhampati, 1994c). However, if one looks closely at
the issues involved, a number of questions arise. For example, do the advantages of partialorder planning hold regardless of the search strategy used? Do the advantages hold when the
planning language is so expressive that reasoning about partially ordered plans is intractable
(e.g., if the language allows conditional effects)?
Our work (Minton et al., 1991a, 1992) has shown that the situation is much more interesting than might be expected. We have found that there are some \unstated assumptions"
underlying the supposed eciency of partial-order planning. For instance, the superiority of
partial-order planning can depend critically upon the search strategy and search heuristics
employed.
This paper summarizes our observations regarding partial-order and total-order planning. We begin by considering a simple total-order planner and a closely related partialorder planner and establishing a mapping between their search spaces. We then examine
c 1994 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiMinton, Bresina, & Drummond

the relative sizes of their search spaces, demonstrating that the partial-order planner has
a fundamental advantage because the size of its search space is always less than or equal
to that of the total-order planner. However, this advantage does not necessarily translate
into an eciency gain; this depends on the type of search strategy used. For example, we
describe a domain where our partial order planner is more ecient than our total order
planner when depth-first search is used, but the eciency gain is lost when an iterative
sampling strategy is used.
We also show that partial-order planners can have a second, independent advantage
when certain types of operator ordering heuristics are employed. This \heuristic advantage"
underlies Sacerdoti's anecdotal examples explaining why least-commitment works. However,
in our blocksworld experiments, this second advantage is relatively unimportant compared
to the advantage derived from the reduction in search space size.
Finally, we look at how our results extend to partial-order planners in general. We
describe how the advantages of partial-order planning can be preserved even if highly expressive languages are used. We also show that the advantages do not necessarily hold for
all partial-order planners, but depend critically on the construction of the planning space.

2. Background
Planning can be characterized as search through a space of possible plans. A total-order
planner searches through a space of totally ordered plans; a partial-order planner is defined
analogously. We use these terms, rather than the terms \linear" and \nonlinear", because
the latter are overloaded. For example, some authors have used the term \nonlinear"
when focusing on the issue of goal ordering. That is, some \linear" planners, when solving a
conjunctive goal, require that all subgoals of one conjunct be achieved before subgoals of the
others; hence, planners that can arbitrarily interleave subgoals are often called \nonlinear".
This version of the linear/nonlinear distinction is different than the partial-order/totalorder distinction investigated here. The former distinction impacts planner completeness,
whereas the total-order/partial-order distinction is orthogonal to this issue (Drummond &
Currie, 1989; Minton et al., 1991a).
The total-order/partial-order distinction should also be kept separate from the distinction between \world-based planners" and \plan-based planners". The distinction is one
of modeling: in a world-based planner, each search state corresponds to a state of the
world and in a plan-based planner, each search state corresponds to a plan. While totalorder planners are commonly associated with world-based planners, such as Strips, several
well-known total-order planners have been plan-based, such as Waldinger's regression planner (Waldinger, 1975), Interplan (Tate, 1974) and Warplan (Warren, 1974). Similarly,
partial-order planners are commonly plan-based, but it is possible to have a world-based
partial-order planner (Godefroid & Kabanza, 1991). In this paper, we focus solely on the
total-order/partial-order distinction in order to avoid complicating the analysis.
We claim that the only significant difference between partial-order and total-order planners is planning eciency. It might be argued that partial-order planning is preferable
because a partially ordered plan can be more exibly executed. However, execution exibility can also be achieved with a total-order planner and a post-processing step that removes
unnecessary orderings from the totally ordered solution plan to yield a partial order (Back228

fiTotal-Order and Partial-Order Planning

strom, 1993; Veloso, Perez, & Carbonell, 1990; Regnier & Fade, 1991). The polynomial
time complexity of this post-processing is negligible compared to the search time for plan
generation.1 Hence, we believe that execution exibility is, at best, a weak justification for
the supposed superiority of partial-order planning.
In the following sections, we analyze the relative eciency of partial-order and totalorder planning by considering a total-order planner and a partial-order planner that can
be directly compared. Elucidating the key differences between these planning algorithms
reveals some important principles that are of general relevance.

3. Terminology

A plan consists of an ordered set of steps, where each step is a unique operator instance.
Plans can be totally ordered, in which case every step is ordered with respect to every other
step, or partially ordered, in which case steps can be unordered with respect to each other.
We assume that a library of operators is available, where each operator has preconditions,
deleted conditions, and added conditions. All of these conditions must be nonnegated propositions, and we adopt the common convention that each deleted condition is a precondition.
Later in this paper we show how our results can be extended to more expressive languages,
but this simple language is sucient to establish the essence of our argument.
A linearization of a partially ordered plan is a total order over the plan's steps that is
consistent with the existing partial order. In a totally ordered plan, a precondition of a plan
step is true if it is added by an earlier step and not deleted by an intervening step. In a
partially ordered plan, a step's precondition is possibly true if there exists a linearization in
which it is true, and a step's precondition is necessarily true if it is true in all linearizations.
A step's precondition is necessarily false if it is not possibly true.
A state consists of a set of propositions. A planning problem is defined by an initial
state and a set of goals, where each goal is a proposition. For convenience, we represent a
problem as a two-step initial plan, where the propositions that are true in the initial state
are added by the first step, and the goal propositions are the preconditions of the final
step. The planning process starts with this initial plan and searches through a space of
possible plans. A successful search terminates with a solution plan, i.e., a plan in which all
steps' preconditions are necessarily true. The search space can be characterized as a tree,
where each node corresponds to a plan and each arc corresponds to a plan transformation.
Each transformation incrementally extends (i.e., refines) a plan by adding additional steps
or orderings. Thus, each leaf in the search tree corresponds either to a solution plan or
a dead-end, and each intermediate node corresponds to an unfinished plan which can be
further extended.

1. Backstrom (1993) formalizes the problem of removing unnecessary orderings in order to produce a \leastconstrained" plan. He shows that the problem is polynomial if one defines a least-constrained plan as a
plan in which no orderings can be removed without impacting the correctness of the plan. Backstrom
also shows that the problem of finding a plan with the fewest orderings over a given operator set is a
much harder problem; it is NP-hard.

229

fiMinton, Bresina, & Drummond

TO(P; G)
1. Termination check: If G is empty, report success and return solution plan P.
2. Goal selection: Let c = select-goal(G), and let Oneed be the plan step for which c is a precondition.
3. Operator selection: Let Oadd be an operator in the library that adds c. If there is no such Oadd , then
terminate and report failure. Choice point: all such operators must be considered for completeness.
4. Ordering selection: Let Odel be the last deleter of c. Insert Oadd somewhere between Odel and
Oneed , call the resulting plan P . Choice point: all such positions must be considered for completeness.
5. Goal updating: Let G be the set of preconditions in P that are not true.
6. Recursive invocation: TO(P ; G ).
0

0

0

0

0

Figure 1: The to planning algorithm
Plan P
O

S

del

A

B

Oneed

F

+ O

add

S

O

del

Oadd

S

Oneed F

B

A

O

del

A

Oadd

B

S

O

del

Oneed F

A

B

Oadd

Oneed F

Figure 2: How to extends a plan: Adding Oadd to plan P generates three alternatives.

4. A Tale of Two Planners
In this section we define two simple planning algorithms. The first algorithm, shown
in Figure 1, is to, a total-order planner motivated by Waldinger's regression planner
(Waldinger, 1975), Interplan (Tate, 1974), and Warplan (Waldinger, 1975). Our purpose
here is to characterize the search space of the to planning algorithm, and the pseudo-code
in Figure 1 accomplishes this by defining a nondeterministic procedure that enumerates
possible plans. (If the plans are enumerated by a breadth-first search, then the algorithms
presented in this section are provably complete, as shown in Appendix A.)
230

fiTotal-Order and Partial-Order Planning

to accepts an unfinished plan, P , and a goal set, G, containing preconditions which are

currently not true. If the algorithm terminates successfully then it returns a totally ordered
solution plan. Note that there are two choice points in this procedure: operator selection
and ordering selection. The procedure does not need to consider alternative goal choices.
For our purposes, the function select-goal can be any deterministic function that selects
a member of G.
As used in Step 4, the last deleter of a precondition c for a step Oneed is defined as
follows. Step Odel is the last deleter of c if Odel deletes c, Odel is before Oneed , and there is
no other deleter of c between Odel and Oneed . In the case that no step before Oneed deletes c,
the first step is considered to be the last deleter.
Figure 2 illustrates to's plan extension process. This example assumes that steps A
and B do not add or delete c. There are three possible insertion points for Oadd in plan P ,
each yielding an alternative extension.
The second planner is ua, a partial-order planner, shown in Figure 3. ua is similar to
to in that it uses the same procedures for goal selection and operator selection; however,
the procedure for ordering selection is different. Step 4 of ua inserts orderings, but only
\interacting" steps are ordered. Specifically, we say that two steps interact if they are
unordered with respect to each other and either:
 one step has a precondition that is added or deleted by the other step, or
 one step adds a condition that is deleted by the other step.
The only significant difference between ua and to lies in Step 4: to orders the new step
with respect to all others, whereas ua adds orderings only to eliminate interactions. It is
in this sense that ua is less committed than to.
Figure 4 illustrates ua's plan extension process. As in Figure 2, we assume that steps
A and B do not add or delete c; however, step A and Oadd interact with respect to some
other condition. This interaction yields two alternative plan extensions: one in which Oadd
is ordered before A and one in which Oadd is ordered after A.
Since ua orders all steps which interact, the plans that are generated have a special
property: each precondition in a plan is either necessarily true or necessarily false. We
call such plans unambiguous. This property yields a tight correspondence between the two
planners' search spaces. Suppose ua is given the unambiguous plan U and to is given
the plan T , where T is a linearization of U . Let us consider the relationship between
the way that ua extends U and to extends T . Note that the two planners will have the
same set of goals since, by definition, each goal in U is a precondition that is necessarily
false, and a precondition is necessarily false if and only if it is false in every linearization.
Since the two plans have the same set of goals and since both planners use the same goal
selection method, both algorithms pick the same goal; therefore, Oneed is the same for both.
Similarly, both algorithms consider the same library operators to achieve this goal. Since T
is a linearization of U , and Oneed is the same in both plans, both algorithms find the same
last deleter as well.2 When to adds a step to a plan, it orders the new step with respect to
2. There is a unique last deleter in U . This follows from our requirement that for any operator in our
language, the deleted conditions must be a subset of the preconditions. If two unordered steps delete
the same condition, then that condition must also be a precondition of both operators. Hence, the two
steps interact and will be ordered by ua.

231

fiMinton, Bresina, & Drummond

UA(P; G)
1. Termination check: If G is empty, report success and return solution plan P.
2. Goal selection: Let c = select-goal(G), and let Oneed be the plan step for which c is a precondition.
3. Operator selection: Let Oadd be an operator in the library that adds c. If there is no such Oadd , then
terminate and report failure. Choice point: all such operators must be considered for completeness.
4. Ordering selection: Let Odel be the last deleter of c. Order Oadd after Odel and before Oneed.
Repeat until there are no interactions:
 Select a step Oint that interacts with Oadd .
 Order Oint either before or after Oadd .
Choice point: both orderings must be considered for completeness.
Let P be the resulting plan.
5. Goal updating: Let G be the set of preconditions in P that are necessarily false.
6. Recursive invocation: UA(P ; G ).
0

0

0

0

0

Figure 3: The ua planning algorithm

Plan P
A
S

O

O

F

need

del

B
+ O

add

S

O

O add

A

add

O

O del

need

S

F

A
O

O del

need

F

B

B

Figure 4: How ua extends a plan: Adding Oadd to plan P generates two alternatives. The
example assumes that Oadd interacts with step A.

232

fiTotal-Order and Partial-Order Planning

all existing steps. When ua adds a step to a plan, it orders the new step only with respect
to interacting steps. ua considers all possible combinations of orderings which eliminate
interactions; hence, for any plan produced by to, ua produces a corresponding plan that
is less-ordered or equivalent.
The following sections exploit this tight correspondence between the search spaces of
ua and to. In the next section we analyze the relative sizes of the two planners' search
spaces, and later we compare the number of plans actually generated under different search
strategies.

5. Search Space Comparison

The search space for both to and ua can be characterized as a tree of plans. The root
node in the tree corresponds to the top-level invocation of the algorithm, and the remaining
nodes each correspond to a recursive invocation of the algorithm. Note that in generating
a plan, the algorithms make both operator and ordering choices, and each different set of
choices corresponds to a single branch in the search tree.
We denote the search tree for to by treeTO and, similarly, the search tree for ua by
treeUA . The number of plans in a search tree is equal to the number of times the planning
procedure (ua or to) would be invoked in an exhaustive exploration of the search space.
Note that every plan in treeUA and treeTO is unique, since each step in a plan is given
a unique label. Thus, although two plans in the same tree might both be instances of a
particular operator sequence, such as O1  O2  O3, the plans are distinct because their
steps have different labels. (We have defined our plans this way to make our proofs more
concise.)
We can show that for any given problem, treeTO is at least as large as treeUA , that is,
the number of plans in treeTO is greater than or equal to the number of plans in treeUA .
This is done by proving the existence of a function L which maps plans in treeUA into sets
of plans in treeTO that satisfies the following two conditions.
1. Totality Property: For every plan U in treeUA , there exists a non-empty set
fT1; : : :; Tmg of plans in treeTO such that L(U ) = fT1; : : :; Tmg.
2. Disjointness Property: L maps distinct plans in treeUA to disjoint sets of plans in
treeTO ; that is, if U1; U2 2 treeUA and U1 6= U2, then L(U1) \ L(U2) = fg.
Let us examine why the existence of an L with these two properties is sucient to prove
that the size of ua's search tree is no greater than that of to. Figure 5 provides a guide for
the following discussion. Intuitively, we can use L to count plans in the two search trees.
For each plan counted in treeUA , we use L to count a non-empty set of plans in treeTO .
The totality property means that every time we count
P a plan in treeUA , we count at least
one plan in treeTO ; this implies that j treeUA j  U 2treeUA j L(U ) j. Of course, we must
further show that each plan counted in treeTOPis counted only once; this is guaranteed by
the disjointness property, which implies that U 2treeUA j L(U ) j  j treeTO j. Thus, the
conjunction of the two properties implies that j treeUA j  j treeTO j.
We can define a function L that has these two properties as follows. Let U be a plan
in treeUA , let T be a plan in treeTO , and let parent be a function from a plan to its parent
233

fiMinton, Bresina, & Drummond

ua search tree

h

L

h

?
,@
,
	
@
@
R
@

h

to search tree

L

h

h

L

- f
- f

L

- f
g

H
HH



j
H

h

hg

,@
, @
	
R

h

hg

- f

A


ff


h

A
AA
U

hg

Figure 5: How L maps from treeUA to treeTO
plan in the tree. Then T 2 L(U ) if and only if (i) T is a linearization of U and (ii) either
U and T are both root nodes of their respective search trees or parent(T ) 2 L(parent(U )).
Intuitively, L maps a plan U in treeUA to all linearizations which share common derivation
ancestry.3 This is illustrated in Figure 5, where for each plan in treeUA a dashed line is
drawn to the corresponding set of plans in treeTO .
We can show that L satisfies the totality and disjointness properties by induction on the
depth of the search trees. Detailed proofs are in the appendix. To prove the first property,
we show that for every plan contained in treeUA , all linearizations of that plan are contained
in treeTO . To prove the second property, we note that any two plans at different depths in
treeUA have disjoint sets of linearizations, and then show by induction that any two plans
at the same depth in treeUA also have this property.
How much smaller is treeUA than treeTO ? The mapping described above provides an
answer. For each plan U in treeUA there are j L(U ) j distinct plans in to, where j L(U ) j is
the number of linearizations of U . The exact number depends on how unordered U is. A
totally unordered plan has a factorial number of linearizations and a totally ordered plan
has only a single linearization. Thus, the only time that the size of treeUA equals the size of
treeTO is when every plan in treeUA is totally ordered; otherwise, treeUA is strictly smaller
than treeTO and possibly exponentially smaller.

6. Time Cost Per Plan
While the size of ua's search tree is possibly exponentially smaller than that of to, it does
not follow that ua is necessarily more ecient. Eciency is determined by two factors: the
3. The reader may question why L maps U to all its linearizations in treeTO that share common derivation ancestry, as opposed to simply mapping U to all its linearizations in treeTO . The reason is that
our planners are not systematic, in the sense that they may generate two or more plans with the same
operator sequence. We can distinguish such plans by their derivational history. For example, suppose
two instantiations of the same operator sequence O1  O2  O3 exist within a treeTO but they correspond to different plans in treeUA . L relies on their different derivations to determine the appropriate
correspondence.

234

fiTotal-Order and Partial-Order Planning

Step Executions Per Plan TO Cost UA Cost
1
1
O(1)
O(1)
2
1
O(1)
O(1)
3
<1
O(1)
O(1)
4
1
O(1)
O(e)
5
1
O(n)
O(e)
Table 1: Cost per plan comparisons
time cost per plan in the search tree (discussed in this section) and the size of the subtree
explored during the search process (discussed in the next section).
In this section we show that while ua can indeed take more time per plan, the extra
time is relatively small and grows only polynomially with the number of steps in the plan,4
which we denote by n. In comparing the relative eciency of ua and to, we first consider
the number of times that each algorithm step is executed per plan in the search tree and
we then consider the time complexity of each step.
As noted in the preceding sections, each node in the search tree corresponds to a plan,
and each invocation of the planning procedure for both ua and to corresponds to an attempt
to extend that plan. Thus, for both ua and to, it is clear that the termination check and
goal selection (Steps 1 and 2) are each executed once per plan. Analyzing the number of
times that the remaining steps are executed might seem more complicated, since each of
these steps is executed many times at an internal node and not at all at a leaf. However,
the analysis is actually quite simple since we can amortize the number of executions of each
step over the number of plans produced. Notice that Step 6 is executed once for each plan
that is generated (i.e., once for each node other than the root node). This gives us a bound
on the number of times that Steps 3, 4, and 5 are executed.5 More specifically, for both
algorithms, Step 3 is executed fewer times than Step 6, and Steps 4 and 5 are executed
exactly the same number of times that Step 6 is executed, that is, once for each plan that
is generated. Consequently, for both algorithms, no step is executed more than once per
plan, as summarized in Table 1. In other words, the number of times each step is executed
during the planning process is bounded by the size of the search tree.
In examining the costs for each step, we first note that for both algorithms, Step 1,
the termination check, can be accomplished in O(1) time. Step 2, goal selection, can also
be accomplished in O(1) time; for example, assuming the goals are stored in a list, the
select-goal function can simply return the first member of the list. Each execution of
Step 3, operator selection, also only requires O(1) time; if we assume the operators are
indexed by their effects, all that is required is to \pop" the list of relevant operators on each
execution.
4. We assume that the size of the operators (the number of preconditions and effects) is bounded by a
constant for a given domain.
5. Since Steps 3 and 4 are nondeterministic, we need to be clear about our terminology. We say that Step
3 is executed once each time a different operator is chosen, and Step 4 is executed once for each different
combination of orderings that is selected.

235

fiMinton, Bresina, & Drummond

Steps 4 and 5 are less expensive for to than for ua. Step 4 of to is accomplished
by inserting the new operator, Oadd , somewhere between Odel and Oneed . If the possible
insertion points are considered starting at Oneed and working towards Odel , then each execution of Step 4 can be accomplished in constant time, since each insertion constitutes one
execution of the step. In contrast, Step 4 in ua involves carrying out interaction detection
and elimination in order to produce a new plan P 0 . This step can be accomplished in O(e)
time, where e is the number of edges in the graph required to represent the partially ordered
plan. (In the worst case, there may be O(n2 ) edges in the plan, and in the best case, O(n)
edges.) The following is the description of ua's ordering step, from Figure 3, with some
additional implementation details:
4. Ordering selection: Order add after del and before need . Label all steps preceding add and
O

O

O

O

all steps following Oadd . Let stepsint be the unlabeled steps that interact with Oadd . Let Odel be the
last deleter of c. Repeat until stepsint is empty:



Let Oint = Pop(stepsint )
if Oint is still unlabeled then either:
{ order Oint before Oadd , and label Oint and the unlabeled steps before Oint ; or
{ order Oint after Oadd , and label Oint and the unlabeled steps after Oint .
Choice point: both orderings must be considered for completeness.

Let P be the resulting plan.
0

The ordering process begins with a preprocessing stage. First, all steps preceding or following Oadd are labeled as such. The labeling process is implemented by a depth-first traversal
of the plan graph, starting with Oadd as the root, which first follows the edges in one direction and then follows edges in the other direction. This requires at most O(e) time. After
the labeling process is complete, only steps that are unordered with respect to Oadd are
unlabeled, and thus the interacting steps (which must be unordered with respect to Oadd)
are identifiable in O(n) time. The last deleter is identifiable in O(e) time.
After the preprocessing stage, the procedure orders each interacting step with respect to
Oadd, updating the labels after each iteration. Since each edge in the graph need be traversed
no more than once, the entire ordering process takes at most O(e) time (as described in
Minton et al., 1991b). To see this, note that the process of labeling the steps before (or
after) Oint can stop as soon as a labeled step is encountered.
Having shown that Step 4 of to has O(1) complexity and Step 4 of ua has O(e) complexity, we now consider Step 5 of both algorithms, updating the goal set. to accomplishes this
by iterating through the steps in the plan, from the head to the tail, which requires O(n)
time. ua accomplishes this in a similar manner, but it requires O(e) time to traverse the
graph. (Alternatively, ua can use the same procedure as to, provided an O(e) topological
sort is first done to linearize the plan.)
To summarize our complexity analysis, the use of a partial order means that ua incurs
greater cost for operator ordering (Step 4) and for updating the goal set (Step 5). Overall,
ua requires O(e) time per plan, while to only requires O(n) time per plan. Since a totally
ordered plan requires a representation of size O(n), and a partially ordered graph requires
a representation of size O(e), designing procedures with lower costs would be possible only
if the entire plan graph did not need to be examined in the worst case.
236

fiTotal-Order and Partial-Order Planning

7. The Role of Search Strategies

The previous sections have compared to and ua in terms of relative search space size
and relative time cost per node. The extra processing time required by ua for each node
would appear to be justified since its search space may contain exponentially fewer nodes.
However, to complete our analysis, we must consider the number of nodes actually visited
by each algorithm under a given search strategy.
For breadth-first search, the analysis is straightforward. After completing the search to
a particular depth, both planners will have explored their entire trees up to that depth.6
Both ua and to find a solution at the same depth due to the correspondence between their
search trees. Thus, the degree to which ua will outperform to, under breadth-first, depends
solely on the \expansion factor" under L, i.e., on the number of linearizations of ua's plans.
We can formalize this analysis as follows. For a node U in treeUA , we denote the number
of steps in the plan at U by nu , and the number of edges in U by eu . Then for each node U
that ua generates, ua incurs time cost O(eu ); whereas, to incurs time cost O(nu )  j L(U ) j,
where j L(U ) j is the number of linearizations of the plan at node U . Therefore, the ratio
of the total time costs of to and ua is as follows, where bf (treeUA ) denotes the subtree
considered by ua under breadth-first search.
P
cost(tobf ) = u2bfP(treeUA ) O(nu )  j L(U ) j
cost(uabf )
u2bf (treeUA ) O(eu )

The analysis of breadth-first search is so simple because this search strategy preserves
the correspondence between the two planners' search spaces. In breadth-first search, the two
planners are synchronized after exhaustively exploring each level, so that to has explored
(exactly) the linearizations of the plans explored by ua. For any other search strategy which
similarly preserves the correspondence, such as iterative deepening, a similar analysis can
be carried out.
The cost comparison is not so clear-cut for depth-first search, since the correspondence is
not guaranteed to be preserved. It is easy to see that, under depth-first search, to does not
necessarily explore all linearizations of the plans explored by ua. This is not simply because
the planners nondeterministically choose which child to expand. There is a deeper reason:
the correspondence L does not preserve the subtree structure of the search space. For a plan
U in treeUA , the corresponding linearizations in L(U ) may be spread throughout treeTO .
Therefore, it is unlikely that corresponding plans will be considered in the same order by
depth-first search. Nevertheless, even though the two planners are not synchronized, we
might expect that, on average, ua will explore fewer nodes because the size of treeUA is less
than or equal to the size of treeTO .
Empirically, we have observed that ua does tend to outperform to under depth-first
search, as illustrated by the experimental results in Figure 6. The first graph compares
the mean number of nodes explored by ua and to on 44 randomly generated blocksworld
problems; the second graph compares the mean planning time for ua and to on the same
problems and demonstrates that the extra time cost per node for ua is relatively insignificant. The problems are partitioned into 4 sets of 11 problems each, according to minimal
6. For perspicuity, we ignore the fact that the number of nodes explored by the two planners on the last
level may differ if the planners stop when they reach the first solution.

237

fiMinton, Bresina, & Drummond

10000

7500

Time to Solution

Nodes Explored

50

TO
5000

UA
2500

40
TO
30
UA
20

10

0

0
3

4

5

6

3

Depth of Problem

4

5

6

Depth of Problem

Figure 6: ua and to Performance Comparison under Depth-First Search
solution \length" (i.e., the number of steps in the plan). For each problem, both planners
were given a depth-limit equal to the length of the shortest solution.7 Since the planners
make nondeterministic choices, 25 trials were conducted for each problem. The source code
and data required to reproduce these experiments can be found in Online Appendix 1.
As we pointed out, one plausible explanation for the observed dominance of ua is that
to's search tree is at least as large as ua's search tree. In fact, in the above experiments
we often observed that to's search tree was typically much larger. However, the full story
is more interesting. Search tree size alone is not sucient to explain ua's dominance; in
particular, the density and distribution of solutions play an important role.
The solution density of a search tree is the proportion of nodes that are solutions.8 If the
solution density for to's search tree is greater than that for ua's search tree, then to might
outperform ua under depth-first search even though to's search tree is actually larger. For
example, it might be the case that all ua solution plans are completely unordered and that
the plans at the remaining leaves of treeUA { the failed plans { are totally ordered. In this
case, each ua solution plan corresponds to an exponential number of to solution plans, and
each ua failed plan corresponds to a single to failed plan. The converse is also possible:
the solution density of ua's search tree might be greater than that of to's search tree, thus
favoring ua over to under depth-first search. For example, there might be a single totally
ordered solution plan in ua's search tree and a large number of highly unordered failed
7. Since the depth-limit is equal to the length of the shortest solution, an iterative deepening (Korf, 1985)
approach would yield similar results. Additionally, we note that increasing the depth-limit past the
depth of the shortest solution does not significantly change the outcome of these experiments.
8. This definition of solution density is ill-defined for infinite trees, but we assume that a depth-bound is
always provided, so only a finite subtree is explicitly enumerated.

238

fiTotal-Order and Partial-Order Planning

UA Search Tree

*

*

TO Search Tree

*

*

*

*

* = Solution plan

Figure 7: Uniform solution distribution, with solution density 0.25
plans. Since each of these failed ua plans would correspond to a large number of to failed
plans, the solution density for to would be considerably lower.
For our blocksworld problems, we found that the solution densities of the two planners'
trees does not differ greatly, at least not in such a way that would explain our performance
results. We saw no tendency for treeUA to have a higher solution density than treeTO . For
example, for the 11 problems with solutions at depth six, the average solution density9 for
to exceeded that of ua on 7 out of the 12 problems. This is not particularly surprising
since we see no a priori reason to suppose that the solution densities of the two planners
should differ greatly.
Since solution density is insucient to explain ua's dominance on our blocksworld experiments when using depth-first search, we need to look elsewhere for an explanation.
We hypothesize that the distribution of solutions provides an explanation. We note that
if the solution plans are distributed perfectly uniformly (i.e., at even intervals) among the
leaves of the search tree, and if the solution densities are similar, then both planners can
be expected to search a similar number of leaves, as illustrated by the schematic search
tree in Figure 7. Consequently, we can explain the observed dominance of ua over to by
hypothesizing that solutions are not uniformly distributed; that is, solutions tend to cluster.
To see this, suppose that treeUA is smaller than treeTO but the two trees have the same
solution density. If the solutions are clustered, as in Figure 8, then depth-first search can be
expected to produce solutions more quickly for treeUA than for treeTO .10 The hypothesis
9. In our experiments, a nondeterministic goal selection procedure was used with our planners, which meant
that the solution density could vary from run to run. We compared the average solution density over 25
trials for each problem to obtain our results.
10. Even if the solutions are distributed randomly amongst the leaves of the trees with uniform probability
(as opposed to being distributed \perfectly uniformly"), there will be some clusters of nodes. Therefore,
to will have a small disadvantage. To see this, let us suppose that each leaf of both treeUA and treeTO
is a solution with equal probability p. That is, if treeUA has NUA leaves, of which kUA are solutions,

239

fiMinton, Bresina, & Drummond

UA Search Tree

*

TO Search Tree

*

*

**

*

* = Solution plan

Figure 8: Non-uniform solution distribution, with solution density 0.25
that solutions tend to be clustered seems reasonable since it is easy to construct problems
where a \wrong decision" near the top of the search tree can lead to an entire subtree that
is devoid of solutions.
One way to test our hypothesis is to compare ua and to using a randomized search
strategy, a type of Monte Carlo algorithm, that we refer to as \iterative sampling" (cf.
Minton et al., 1992; Langley, 1992; Chen, 1989; Crawford & Baker, 1994). The iterative
sampling strategy explores randomly chosen paths in the search tree until a solution is
found. A path is selected by traversing the tree from the root to a leaf, choosing randomly
at each branch point. If the leaf is a solution then search terminates; if not, the search
process returns to the root and selects another path. The same path may be examined
more than once since no memory is maintained between iterations.
In contrast to depth-first search, iterative sampling is relatively insensitive to the distribution of solutions. Therefore, the advantage of ua over to should disappear if our hypothesis is correct. In our experiments, we did find that when ua and to both use iterative
sampling, they expand approximately the same number of nodes on our set of blocksworld
problems.11 (For both planners, performance with iterative sampling was worse than with
depth-first search.) The fact that there is no difference between ua and to under iterative
sampling, but that there is a difference under depth-first search, suggests that solutions are
and treeTO has NTO leaves, of which kTO are solutions, then p = kUA =NUA = kTO =NTO . In general,
if k out of N nodes are solutions, the expected number of nodes that must be tested to find a solution
is :5N=k when k = 1 and approaches N=k as k (and N ) approaches 1. (This is simply the expected
number of samples for a binomial distribution.) Therefore, since kTO  kUA , the expected number of
leaves explored by to is greater than or equal to the expected number of leaves explored by ua, by at
most a factor of 2.
11. The iterative sampling strategy was depth-limited in exactly the same way that our depth-first strategy
was. We note, however, that the performance of iterative sampling is relatively insensitive to the actual
depth-limit used.

240

fiTotal-Order and Partial-Order Planning

indeed non-uniformly distributed. Furthermore, this result shows that ua is not necessarily
superior to to; the search strategy that is employed makes a dramatic difference.
Although our blocksworld domain may be atypical, we conjecture that our results are
of general relevance. Specifically, for distribution-sensitive search strategies like depth-first
search, one can expect that ua will tend to outperform to. For distribution-insensitive
strategies, such as iterative sampling, non-uniform distributions will have no effect. We note
that while iterative sampling is a rather simplistic strategy, there are more sophisticated
search strategies, such as iterative broadening (Ginsberg & Harvey, 1992), that are also
relatively distribution insensitive. We further explore such strategies in Section 8.2.

8. The Role of Heuristics

In the preceding sections, we have shown that a partial-order planner can be more ecient
simply because its search tree is smaller. With some search strategies, such as breadthfirst search, this size differential obviously translates into an eciency gain. With other
strategies, such as depth-first search, the size differential translates into an eciency gain,
provided we make additional assumptions about the solution density and distribution.
However, it is often claimed that partial-order planners are more ecient due to their
ability to make more informed ordering decisions, a rather different argument. For instance,
Sacerdoti (1975) argues that this is the reason that noah performs well on problems such
as the blocksworld's \Sussman anomaly". By delaying the decision of whether to stack A
on B before or after stacking B on C, noah can eventually detect that a conict will occur
if it stacks A on B first, and a critic called \resolve-conflicts" can then order the steps
intelligently.
In this section, we show that this argument can be formally described in terms of our
two planners. We demonstrate that ua does in fact have a potential advantage over to
in that it can exploit certain types of heuristics more readily than to. This advantage is
independent of the fact that ua has a smaller search space. Whether or not this advantage
is significant in practice is another question, of course. We also describe some experiments
where we evaluate the effect of a commonly-used heuristic on our blocksworld problems.

8.1 Making More Informed Decisions

First, let us identify how it is that ua can make better use of certain heuristics than to.
In the ua planning algorithm, step 4 arbitrarily orders interacting plan steps. Similarly,
Step 4 of to arbitrarily chooses an insertion point for the new step. It is easy to see,
however, that some orderings should be tried before others in a heuristic search. This is
illustrated by Figure 9, which compares ua and to on a particular problem. The key in
the figure describes the relevant conditions of the library operators, where preconditions are
indicated to the left of an operator and added conditions are indicated to the right (there
are no deletes in this example). For brevity, the initial step and final step of the plans
are not shown. Consider the plan in treeUA with unordered steps O1 and O2 . When ua
introduces O3 to achieve precondition p of O1 , Step 4 of ua will order O3 with respect to
O2, since these steps interact. However, it makes more sense to order O2 before O3, since O2
achieves precondition q of O3. This illustrates a simple planning heuristic that we refer to
as the min-goals heuristic: \prefer the orderings that yield the fewest false preconditions".
241

fiMinton, Bresina, & Drummond

UA

TO

O1

O1

O1
O1

O2

O1

O2

O2
O1
O2

O3

O1

O1

O2

q O3

p

O3

O3

O2

O3

O1

O3

O2

O1

O2

KEY
p

O1

r

O2 q

Figure 9: Comparison of ua and to on an example.
This heuristic is not guaranteed to produce the optimal search or the optimal plan, but it
is commonly used. It is the basis of the \resolve conicts" critic that Sacerdoti employed
in his blocksworld examples.
Notice, however, that to cannot exploit this heuristic as effectively as ua because it
prematurely orders O1 with respect to O2 . Due to this inability to postpone an ordering
decision, to must choose arbitrarily between the plans O1  O2 and O2  O1, before the
impact of this decision can be evaluated.
In the general case, suppose h is a heuristic that can be applied to both partially ordered
plans and totally ordered plans. Furthermore, assume h is a \useful" heuristic; i.e., if h
rates one plan more highly than another, a planner that explores the more highly rated
plan first will perform better on average. Then, ua will have a potential advantage over to
provided that h satisfies the following property: for any ua plan U and corresponding to
plan T , h(U )  h(T ); that is, a partially ordered plan must be rated at least as high as any
of its linearizations. (Note that for unambiguous plans, the min-goals heuristic satisfies this
property since it gives identical ratings to a partially ordered plan and its linearizations.)
ua has an advantage over to because if ua is expanding plan U and to is expanding a
corresponding plan T , then h will rate some child of U at least as high as the most highly
rated child of T . This is true since every child of T is a linearization of some child of U ,
and therefore no child of T can be rated higher than a child of U . Furthermore, there may
be a child of U such that none of its linearizations is a child of T , and therefore this child of
U can be rated higher than every child of T . Since we assumed that h is a useful heuristic,
this means that ua is likely to make a better choice than to.
242

fiTotal-Order and Partial-Order Planning

5000
TO
UA
TO-MG
UA-MG

Nodes Explored

4000

TO without MinGoals
UA without MinGoals
TO with MinGoals
UA with MinGoals

TO

3000
UA
2000
TO-MG
1000
UA-MG
0
3

4

5

6

Depth of Problem

Figure 10: Depth first search with and without min-goals

8.2 Illustrative Experimental Results
The previous section showed that ua has a potential advantage over to because it can better
exploit certain ordering heuristics. We now examine the practical effects of incorporating
one such heuristic into ua and to.
First, we note that ordering heuristics only make sense for some search strategies. In
particular, for breadth-first search, heuristics do not improve the eciency of the search in a
meaningful way (except possibly at the last level). Indeed, we need not consider any search
strategy in which to and ua are \synchronized", as defined earlier, since ordering heuristics
do not significantly affect the relative performance of ua and to under such strategies. Thus,
we begin by considering a standard search strategy that is not synchronized: depth-first
search.
We use the min-goals heuristic as the basis for our experimental investigation, since it is
commonly employed, but presumably we could choose any heuristic that meets the criterion
set forth in the previous section. Figure 10 shows the impact of min-goals on the behavior
of ua and to under depth-first search. Although the heuristic biases the order in which the
two planners' search spaces are explored (cf. Rosenbloom, Lee, & Unruh, 1993), it appears
that its effect is largely independent of the partial-order/total-order distinction, since both
planners are improved by a similar percentage. For example, under depth-first search on
the problems with solutions at depth six, ua improved 88% and to improved 87%. Thus,
there is no obvious evidence for any extra advantage for ua, as one might have expected
from our analysis in the previous section. On the other hand, this does not contradict our
theory, it simply means that the potential heuristic advantage was not significant enough
to show up. In other domains, the advantage might manifest itself more significantly. After
all, it is certainly possible to design problems in which the advantage is significant, as
243

fiMinton, Bresina, & Drummond

Nodes Explored

100
TO-IB
UA-IB
TO-IS
UA-IS

75

TO Iterative Broadening
UA Iterative Broadening
TO Iterative Sampling
UA Iterative Sampling

TO-IB

UA-IB
50

TO-IS

25

UA-IS

3

4

5

6

Depth of Problem

Figure 11: Iterative sampling & iterative broadening, both with min-goals
our example in Figure 9 illustrates. Our results simply illustrate that in our blocksworld
domain, making intelligent ordering decisions produces a negligible advantage for ua, in
contrast to the significant effect due to search space compression (discussed previously).12
While the min-goals heuristic did not seem to help ua more than to, the results are
nevertheless interesting, since the heuristic had a very significant effect on the performance
of both planners, so much so that to with min-goals outperforms ua without min-goals.
While the effectiveness of min-goals is domain dependent, we find it interesting that in these
experiments, the use of min-goals makes more difference than the use of partial orders. After
all, the blocksworld originally helped motivate the development of partial-order planning
and most subsequent planning systems have employed partial orders. While not deeply
surprising, this result does help reinforce what we already know: more attention should be
paid to specific planning heuristics such as min-goals.
In our analysis of search space compression in Section 7, we described a \distribution
insensitive" search strategy called iterative sampling and showed that under iterative sampling ua and to perform similarly, although their performance is worse than it is under
depth-first search. If we combine min-goals with iterative sampling, we find that this produces a much more powerful strategy, but one in which to and ua still perform about
equally. For simplicity, our implementation of iterative sampling uses min-goals as a pruning heuristic; at each choice point, it explores only those plan extensions with the fewest
goals. This strategy is powerful, although incomplete.13 Because of this incompleteness, we
note there was one problem we removed from our sample set because iterative sampling with
12. In Section 9.2, we discuss planners that are \less-committed" than ua. For such planners, the advantage
due to heuristics might be more pronounced since they \delay" their decisions even longer than ua.
13. Instead of exploring only those plan extensions with the fewest goals at each choice point, an alternative
strategy is to assign each extension a probability that is inversely correlated with the number of goals,

244

fiTotal-Order and Partial-Order Planning

min-goals would never terminate on this problem. With this caveat in mind, we turn to the
results in Figure 11, which when compared against Figure 10, show that the performance
of both ua and to with iterative sampling was, in general, significantly better than their
performance under depth-first search. (Note that the graphs in Figures 10 and 11 have very
different scales.) Our results clearly illustrate the utility of the planning bias introduced by
min-goals in our blocksworld domain, since on 43 of our 44 problems, a solution exists in
the very small subspace preferred by min-goals.
These experiments do not show any advantage for ua as compared with to under the
heuristic, which is consistent with our conclusions above. However, this could equally well
be because min-goals was so powerful, leading to solutions so quickly, that smaller inuences
were obscured.
The dramatic success of combining min-goals with iterative sampling led us to consider
another search strategy, iterative broadening, which combines the best aspects of depthfirst search and iterative sampling. This more sophisticated search strategy initially behaves
like iterative sampling, but evolves into depth-first search as the breadth-cutoff increases
(Langley, 1992). Assuming that the solution is within the specified depth bound, iterative
broadening is complete. In its early stages iterative broadening is distribution-insensitive;
in its later stages it behaves like depth-first search and, thus, becomes increasingly sensitive
to solution distribution. As one would expect from our iterative sampling experiments, with
iterative broadening, solutions were found very early on, as shown in Figure 11. Thus, it is
not surprising that ua and to performed similarly under iterative broadening.
We should point out that the results presented in this subsection are only illustrative,
since they deal with only a single domain and with a single heuristic. Nevertheless, our
experiments do illustrate how the various properties we have identified in this paper can
interact.

9. Extending our Results
Having established our basic results concerning the eciency of ua and to under various
circumstances, we now consider how these results extend to other types of planners.

9.1 More Expressive Languages
In the preceding sections, we showed that the primary advantage that ua has over to is that
ua's search tree may be exponentially smaller than to's search tree, and we also showed
that ua only pays a small (polynomial) extra cost per node for this advantage. Thus far we
have assumed a very restricted planning language in which the operators are propositional;
however, most practical problems demand operators with variables, conditional effects, or
conditional preconditions. With a more expressive planning language, will the time cost
per node be significantly greater for ua than for to? One might think so, since the work
required to identify interacting steps can increase with the expressiveness of the operator
language used (Dean & Boddy, 1988; Hertzberg & Horz, 1989). If the cost of detecting step
and pick accordingly. Given a depth bound, this strategy has the advantage of being asymptotically
complete. We used the simpler strategy here for pedagogical reasons.

245

fiMinton, Bresina, & Drummond

interaction is high enough, the savings that ua enjoys due to its reduced search space will
be outweighed by the additional expense incurred at each node.
Consider the case for simple breadth-first search. Earlier we showed that the ratio of
the total time costs of to and ua is as follows, where the subtree considered by ua under
breadth-first search is denoted by bf (treeUA ), the number of steps in plan a U is denoted
by nu , and the number of edges in U is denoted by eu :

P

cost(TObf ) = U 2bfP(treeUA ) O(nu )  j L(U ) j
cost(UAbf )
U 2bf (treeUA ) O(eu )
This cost comparison is specific to the simple propositional operator language used so
far, but the basic idea is more general. ua will generally outperform to whenever its cost
per node is less than the product of the cost per node for to and the number of to nodes
that correspond under L. Thus, ua could incur an exponential cost per node and still
outperform to in some cases. This can happen, for example, if the exponential number of
linearizations of a ua partial order is greater than the exponential cost per node for ua. In
general, however, we would like to avoid the case where ua pays an exponential cost per
node and, instead, consider an approach that can guarantee that the cost per node for ua
remains polynomial (as long as the cost per node for to also remains polynomial).
The cost per node for ua is dominated by the cost of updating the goal set (Step 5) and
the cost of selecting the orderings (Step 4). Updating the goal set remains polynomial as
long as a plan is unambiguous. Since each precondition in an unambiguous plan is either
necessarily true or necessarily false, we can determine the truth value of a given precondition
by examining its truth value in an arbitrary linearization of the plan. Thus, we can simply
linearize the plan and then use the same procedure to uses for calculating the goal set.
As a result, it is only the cost of maintaining the unambiguous property (i.e., Step 4) that
is impacted by more expressive languages. One approach for eciently maintaining this
property relies on a \conservative" ordering strategy in which operators are ordered if they
even possibly interact.
As an illustration of this approach, consider a simple propositional language with conditional effects, such as \if p and q, then add r". Hence, an operator can add (or delete)
propositions depending on the state in which it is applied. We refer to conditions such as
\p" in our example as dependency conditions. (Note that, like preconditions, dependency
conditions are simple propositions.) Chapman (1987) showed that with this type of language it is NP-hard to decide whether a precondition is true in a partially ordered plan.
However, as we pointed out above, for the special case of unambiguous plans, this decision
can be accomplished in polynomial time.
Formally, the language is specified as follows. An operator O, as before, has a list of preconditions, pre(O), a list of (unconditional) adds, adds(O), a list of (unconditional) deletes,
dels(O). In addition, it has a list of conditional adds, cadds(O), and a list of conditional
deletes, cdels(O); both containing pairs hDe ; ei, where De is a conjunctive set of dependency conditions and e is the conditional effect (either an added or a deleted condition).
Analogous with the constraint that every delete must be a precondition, every conditional
delete must be a member of its dependency conditions; that is, for every hDe ; ei 2 cdels(O),
e 2 De.
246

fiTotal-Order and Partial-Order Planning

Figure 12 shows a version of the ua algorithm, called ua-c, which is appropriate for this
language. The primary difference between the ua and ua-c algorithms is that in both Steps
3 and 4b an operator may be specialized with respect to a set of dependency conditions.
The function specialize(O, D ) accepts a plan step, O, and a set of dependency conditions,
D; it returns a new step O0 that is just like O, but with certain conditional effects made
unconditional. The effects that are selected for this transformation are exactly those whose
dependency conditions are a subset of D. Thus, the act of specializing a plan step is the
act of committing to expanding its causal role in a plan.14 Once a step is specialized, ua-c
has made a commitment to use it for a given set of effects. Of course, a step can be further
specialized in a later search node, but specializations are never retracted.
More precisely, the definition of O0 = specialize(O; D), where O is a step, D is a conjunctive set of dependency conditions in O, and n is the set difference operator, is as follows.







pre(O0) = pre(O) [ D.
adds(O0) = adds(O) [ fe j hDe; ei 2 cadds(O) ^ De  Dg.
dels(O0) = dels(O) [ fe j hDe ; ei 2 cdels(O) ^ De  Dg.
cadds(O0) = fhDe ; ei j hDe ; ei 2 cadds(O) ^ De 6 D ^ De = De nDg.
cdels(O0) = fhDe ; ei j hDe ; ei 2 cdels(O) ^ De 6 D ^ De = De nDg.
0

0

0

0

The definition of step interaction is generalized for ua-c as follows. We say that two
steps in a plan interact if they are unordered with respect to each other and the following
disjunction holds:
 one step has a precondition or dependency condition that is added or deleted by the
other step, or
 one step adds a condition that is deleted by the other step.
The difference between this definition of step interaction and the one given earlier is indicated by an italic font. This modified definition allows us to detect interacting operators
with a simple inexpensive test, as did our original definition. For example, two steps that
are unordered interact if one step conditionally adds r and the other has precondition r.
Note that the first step need not actually add r in the plan, so ordering the two operators
might be unnecessary. In general, our definition of interaction is a sucient criterion for
guaranteeing that the resulting plans are unambiguous, but it is not a necessary criterion.
Figure 13 shows a schematic example illustrating how ua-c extends a plan. The preconditions of each operator are shown on the left of each operator, and the unconditional
adds on the right. (We only show the preconditions and effects necessary to illustrate the
specialization process; no deletes are used in the example.) Conditional adds are shown
14. For simplicity, the modifications used to create ua-c are not very sophisticated. As a result, ua-c's space
may be larger than it needs to be in some circumstances, since it aggressively commits to specializations.
A more sophisticated set of modifications is possible; however, the subtlies involved in eciently planning
with dependency conditions (Pednault, 1988; Collins & Pryor, 1992; Penberthy & Weld, 1992) are largely
irrelevant to our discussion.

247

fiMinton, Bresina, & Drummond

UA-C(P; G)
1 Termination check: If G is empty, report success and return solution plan P.
2 Goal selection: Let c = select-goal(G), and let Oneed be the plan step for which c is a precondition.
3 Operator selection: Let Oadd be an operator schema in the library that possibly adds c; that is,
either c 2 adds(O), or there exists an hDc ; ci 2 cadds(O). In the former case, insert step Oadd and in
the latter case, insert step specialize(Oadd ; Dc). If there is no such Oadd , then terminate and report
failure. Choice point: all ways in which c can be added must be considered for completeness.
4a Ordering selection: Let Odel be the (unconditional) last deleter of c. Order Oadd after Odel and
before Oneed .
Repeat until there are no interactions:
 Select a step Oint that interacts with Oadd .
 Order Oint either before or after Oadd .
Choice point: both orderings must be considered for completeness.
Let P be the resulting plan.
4b Operator role selection: While there exists a step Ocadd with unmarked conditional add hDc ; ci
and a step Ouse with precondition c, such that Ouse is after Ocadd and there is no (unconditional)
deleter of c in between Ouse and Ocadd .
 Either mark hDc; ci, or replace Ocadd with specialize(Ocadd ; Dc ).
Choice point: Both options must be considered for completeness.
5 Goal updating: Let G be the set of preconditions in P that are necessarily false.
6 Recursive invocation: UA-C(P ; G ).
0

0

0

0

0

Figure 12: The ua-C planning algorithm
underneath each operator. For instance, the first operator in the plan at the top of the
page has precondition p. This operator adds q and conditionally adds u if t is true. The
figure illustrates two of the plans produced as a result of adding a new conditional operator
to the plan. In one plan, the conditional effects [u ! s] and [t ! u] are selected in the
specialization process, and in the other plan they are not.
The new step, Step 4b, requires only polynomial time per plan generated, and the time
cost of the other steps are the same as for ua. Hence, as with our original ua algorithm,
the cost per node for the ua-c algorithm is polynomial.
to can also handle this language given the corresponding modifications (changing Step
3 and adding Step 4b), and the time cost per plan also remains polynomial.15 Moreover,
the same relationship holds between the two planners' search spaces { treeUA is never larger
than treeTO and can be exponentially smaller. This example illustrates that the theoretical
advantages that ua has over to can be preserved for a more expressive language. As we
pointed out, our definition of interaction is a sucient criterion for guaranteeing that the
resulting plans are unambiguous, but it is not a necessary criterion. Nevertheless, this
conservative approach allows interactions to be detected via a simple inexpensive syntactic
test. Essentially, we have kept the cost per node for ua-c low by restricting the search space
it considers, as shown in Figure 14. ua-c only considers unambiguous plans that can be
generated via its \conservative" ordering strategy. ua-c is still a partial-order planner, and
15. In fact, Step 4b be implemented so that the time cost is O(e), using the graph traversal techniques
described in Section 6. As a result the ua-c implementation and the corresponding to-c implementation
have the same time cost per node for this new language as they did for the original language, O(e) and
O (n), respectively.

248

fiTotal-Order and Partial-Order Planning

q
r O
s
p

q

O
[t

u]

O
O

Add Operator:
[u

O
p
[t

[u

q

O

r
s]

r
s]

q
r O
s

u
p

u]

t

O

q

O

r
s

q
r O
s

Ou
O

Figure 13: An example illustrating the ua-c algorithm
it is complete, but it does not consider all partially ordered plans or even all unambiguous
partially ordered plans.
The same \trick" can be used for other languages as well, provided that we can devise
a simple test to detect interacting operators. For example, in previous work (Minton et al.,
1991b) we showed how this can be done for a language where operators can have variables in
their preconditions and effects. In the general case, for a given ua plan and a corresponding
to plan, Steps 1,2, and 3 of the ua algorithm cost the same as the corresponding steps of
the to algorithm. As long as the plans considered by ua are unambiguous, Step 5 of the
ua algorithm can be accomplished with an arbitrary linearization of the plan, in which case
it costs at most O(e) more than Step 5 of the to algorithm. Thus, the only possibility for
additional cost is in Step 4. In general, if we can devise a \local" criterion for interaction
such that the resulting plan is guaranteed to be unambiguous, then the ordering selection
step can be accomplished in polynomial time. By \local", we mean a criterion that only
considers operator pairs to determine interactions; i.e., it must not examine the rest of the
plan.
Although the theoretical advantages that ua has over to can be preserved for more
expressive languages, there is a cost. The unambiguous plans that are considered may have
more orderings than necessary, and the addition of unnecessary orderings can increase the
size of ua's search tree. The magnitude of this increase depends on the specific language,
domain, and problem being considered. Nevertheless, we can guarantee that ua's search
tree is never larger than to's.
The general lesson here is that the cost of plan extension is not solely dependent on
the expressiveness of the operator language, it also depends on the nature of the plans that
249

fiMinton, Bresina, & Drummond

partially ordered plans
unambiguous
partially ordered plans
unambiguous partially
ordered plans produced by
conservative ordering strategy
totally ordered
plans

Figure 14: Hierarchy of Plan Spaces
the planner considers. So, although the extension of partially ordered plans is NP-hard for
languages with conditional effects, if the space of plans is restricted (e.g., only unambiguous
plans are considered) then this worst-case situation is avoided.

9.2 Less Committed Planners

We have shown that ua, a partial-order planner, can have certain computational advantages
over a total-order planner, to, since its ability to delay commitments allows for a more
compact search space and potentially more intelligent ordering choices. However, there
are many planners that are even less committed than ua. In fact, there is a continuum
of commitment strategies that we might consider, as illustrated in Figure 15. Total-order
planning lies at one end of the spectrum. At the other extreme is the strategy of maintaining
a totally unordered set of steps during search until there exists a linearization of the steps
that is a solution plan.
Compared to many well-known planners, ua is conservative since it requires each plan
to be unambiguous. This is not required by noah (Sacerdoti, 1977), NonLin (Tate, 1977),
Totally
Ordered
TO

Completely
Unordered
UA

Figure 15: A continuum of commitment strategies
250

fiTotal-Order and Partial-Order Planning

MT(P; G)
1. Termination check: If G is empty, report success and stop.
2. Goal selection: Let c = select-goal(G), and let Oneed be the plan step for which c is a precondition.
3. Operator selection: Let Oadd be either a plan step possibly before Oneed that adds c or an operator
in the library that adds c. If there is no such Oadd , then terminate and report failure.
Choice point: all such operators must be considered for completeness.
4. Ordering selection: Order Oadd before Oneed. Repeat until there are no steps possibly between
Oadd and Oneed which delete c:
Let Odel be such a step; choose one of the following ways to make c true for Oneed
 Order Odel after Oneed .
 Choose a step Oknight (possibly Oadd ) that adds c that is possibly between Odel and Oneed;
order it after Odel and before Oneed .
Choice point: both alternatives must be considered for completeness.
Let P be the resulting plan.
5. Goal updating: Let G be the set of preconditions in P that are not necessarily true.
6. Recursive invocation: MT(P ; G ).
0

0

0

0

0

Figure 16: A Propositional Planner based on the Modal Truth Criterion
nor Tweak (Chapman, 1987), for example. How do these less-committed planners compare
to ua and to? One might expect a less-committed planner to have the same advantages
over ua that ua has over to. However, this is not necessarily true. As an example, in
this section we introduce a Tweak-like planner, called mt, and show that its search space
is larger than even to's in some circumstances.16
Figure 16 presents the mt procedure. mt is a propositional planner based on Chapman's
Modal Truth Criterion (Chapman, 1987), the formal statement that characterizes Tweak's
search space. It is straightforward to see that mt is less committed than ua. The algorithms
are quite similar; however, in Step 4, whereas ua orders all interacting steps, mt does not.
Since mt does not immediately order all interacting operators, it may have to add additional
orderings between previously introduced operators later in the planning process to produce
correct plans.
The proof that ua's search tree is no larger than to's search tree rested on the two
properties of L elaborated in Section 5. By investigating the relationship between mt and
to, we found that the second property, the disjointness property, does not hold for mt,
and its failure illustrates how mt can explore more plans than to (and, consequently, than
ua) on certain problems. The disjointness property guarantees that ua does not generate
\overlapping" plans. The example in Figure 17 shows that mt fails to satisfy this property
because it can generate plans that share common linearizations, leading to considerable
redundancy in the search tree. The figure shows three steps, O1, O2, and O3 , where each Oi
has precondition pi and added conditions gi, p1, p2, and p3 . The final step has preconditions
g1, g2, and g3, but the initial and final steps are not shown in the figure. At the top of the
figure, in the plan constructed by mt, goals g1 , g2, and g3 have been achieved, but p1 , p2,
and p3 remain to be achieved. Subsequently, in solving precondition p1, mt generates plans
which share the linearization O3  O2  O1 (among others). In comparison, both to and
16. We use Tweak for this comparison because, like ua and to, it is a formal construct rather than a realistic
planner, and therefore more easily analyzed.

251

fiMinton, Bresina, & Drummond

O1
O2
O3

O1

O2

O2

O3

O3

O2

O1

O3

O1

O3

O2

O1

KEY
p O1
1

g1
p
1
p2
p3

p2 O
2

g2
p
1
p2
p3

p3 O3

g3
p
1
p2
p3

Figure 17: \Overlapping" plans.
ua only generate the plan O3  O2  O1 once. In fact, it is simple to show that, under
breadth-first search, mt explores many more plans than to on this example (and also more
than ua, by transitivity) due to the redundancy in its search space.
This result may seem counterintuitive. However, note that the search space size for a
partial-order planner is potentially much greater than that of a total-order planner since
there are many more partial orders over a set of steps than there are total orders. (Thus,
when designing a partial-order planner, one may preclude overlapping linearizations in order
to avoid redundancy, as discussed by McAllester & Rosenblitt, 1991 and Kambhampati,
1994c.)
Of course, one can also construct examples where mt does have a smaller search space
than both ua and to. Our example simply illustrates that although one planner may be
less committed than another, its search space is not necessarily smaller. The commitment
strategy used by a planner is simply one factor that inuences overall performance. In
particular, the effect of redundancy in a partial-order planner can overwhelm other considerations. In comparing two planners, one must carefully consider the mapping between
their search spaces before concluding that \less committed ) smaller search space".

10. Related Work
For many years, the intuitions underlying partial-order planning were largely taken for
granted. Only in the past few years has there been renewed interest in the fundamental
principles underlying these issues.
252

fiTotal-Order and Partial-Order Planning

Barrett et al. (1991) and Barrett and Weld (1994) describe an interesting and novel
analysis of partial-order planning that complements our own work. They compare a partialorder planner with two total-order planners derived from it, one that searches in the space
of plans, and the other that searches in the space of world states. Their study focuses
on how the goal structure of the problem affects the eciency of partial-order planning.
Specifically, they examine how partial-order and total-order planning compare for problems
with independent, serializable, and non-serializable goals, when using a resource-bounded
depth-first search. They refine Korf's work on serializable goals (Korf, 1987), introducing a
distinction between trivially serializable subgoals, where the subgoals can be solved in any
order without violating a previously solved subgoal, and laboriously serializable subgoals,
where the subgoals are serializable, but at least 1=n of the orderings can cause a previously
solved subgoal to be violated. Their study describes conditions under which a partial-order
planner may have an advantage. For instance, they show that in a domain where the goals
are trivially serializable for their partial-order planner and laboriously serializable for their
total-order planners, their partial-order planner performs significantly better.
Our study provides an interesting contrast to Barret and Weld's work, since we investigate the relative eciencies of partial-order and total-order planning algorithms independent
of any particular domain structure. Instead, we focus on the underlying properties of the
search space and how the search strategy affects the eciency of our planners. Nevertheless,
we believe there are interesting relationships between the forms of serializability that they
investigate, and the ideas of solution density and clustering that we have discussed here.
To illustrate this, consider an artificial domain that Barret and Weld refer to as D1S 1,
where, in each problem, the goals are a subset of fG1; G2; : : :G15g, the initial conditions
are fI1; I2; : : :I15g, and each operator Oi2f1;2;:::;15g has precondition Ii , adds Gi , and deletes
Ii,1. It follows that if a solution in D1S 1 contains operators Oi and Oj where i < j , then Oi
must precede Oj . In this domain, the goals are trivially serializable for their partial-order
planner and laboriously serializable for their total-order planners; thus, the partial-order
planner performs best. But note also that in this artificial domain, there is exactly one
solution per problem and it is totally ordered. Therefore, it is immediately clear that, if
we give ua and to problems from this domain, then ua's search tree will generally be
much smaller than to's search tree. Since there is only single solution for both planners,
the solution density for ua will clearly be greater than that for to. Thus, the properties
we discussed in this paper should provide a basis for analyzing how differences in subgoal
serializibility manifest their effect on the search. This subject, however, is not as simple as
it might seem and deserves further study.
In other related work, Kambhampati has written several papers (Kambhampati, 1994a,
1994b, 1994c) that analyze the design space of partial-order planners, including the ua
planner presented here. Kambhampati compares ua, Tweak, snlp (McAllester & Rosenblitt, 1991), ucpop (Penberthy & Weld, 1992), and several other planners along a variety of
dimensions. He presents a generalized schema for partial order planning algorithms (Kambhampati, 1994c) and shows that the commitment strategy used in ua can be viewed as a
way to increase the tractability of the plan extension (or refinement) process. Kambhampati
also carries out an empirical comparison of the various planning algorithms on a particular problem (Kambhampati, 1994a), showing how the differences in commitment strategies
affects the eciency of the planning process. He distinguishes two separate components
253

fiMinton, Bresina, & Drummond

of the branching factor, bt and be , the former resulting from the commitment strategy for
operator ordering (or in his terms, the \tractability refinements") and the latter resulting
from the choice of operator (\establishment refinements"). Kambhampati's experiments
demonstrate that while \eager" commitment strategies tend to increase bt, sometimes they
also decrease be , because the number of possible establishers is reduced when plans are more
ordered. This is, of course, closely related to the issues investigated in this paper.
In addition, Kambhampati and Chen (1993) have compared the relative utility of reusing
partially ordered and totally ordered plans in \learning planners". They showed that the
reuse of partially ordered plans, rather than totally ordered plans, result in \storage compaction" because they can represent a large number of different orderings. Moreover, partialorder planners have an advantage because they can exploit such plans more effectively than
total-order planners. In many respects, these advantages are fundamentally similar to the
advantages that ua derives from its potentially smaller search space.

11. Conclusions
By focusing our analysis on a single issue, namely, operator ordering commitment, we have
been able to carry out a rigorous comparative analysis of two planners. We have shown
that the search space of a partial-order planner, ua, is never larger than the search space of
a total-order planner, to. Indeed for certain problems, ua's search space is exponentially
smaller than to's. Since ua pays only a small polynomial time increment per node over
to, it is generally more ecient.
We then showed that ua's search space advantage may not necessarily translate into
an eciency gain, depending in subtle ways on the search strategy and heuristics that are
employed by the planner. For example, our experiments suggest that distribution-sensitive
search strategies, such as depth-first search, can benefit more from partial orders than can
search strategies that are distribution-insensitive.
We also examined a variety of extensions to our planners, in order to demonstrate
the generality of these results. We argued that the potential benefits of partial-order
planning may be retained even with highly expressive planning languages. However, we
showed that partial-order planners do not necessarily have smaller search spaces, since
some \less-committed" strategies may create redundancies in the search space. In particular, we demonstrated that a Tweak-like planner, mt, can have a larger search space than
our total-order planner on some problems.
How general are these results? Although our analysis has considered only two specific
planners, we have examined some important tradeoffs that are of general relevance. The
analysis clearly illustrates how the planning language, the search strategy, and the heuristics
that are used can affect the relative advantages of the two planning styles.
The results in this paper should be considered as an investigation of the possible benefits
of partial-order planning. ua and to have been constructed in order for us to analyze the
total-order/partial-order distinction in isolation. In reality, the comparative behavior of two
planners is rarely as clear (as witnessed by our discussion of mt). While the general points
we make are applicable to other planners, if we chose two arbitrary planners, we would not
expect one planner to so clearly dominate the other.
254

fiTotal-Order and Partial-Order Planning

Our observations regarding the interplay between plan representation and search strategy raise new concerns for comparative analyses of planners. Historically, it has been
assumed that representing plans as partial orders is categorically \better" than representing plans as total orders. The results presented in this paper begin to tell a more accurate
story, one that is both more interesting and more complex than we initially expected.

Appendix A. Proofs
A.1 Definitions

This section defines the terminology and notation used in our proofs. The notion of plan
equivalence is introduced here because each plan step is, by definition, a uniquely labeled
operator instance, as noted in Section 3 and Section 5. Thus, no two plans have the same
set of steps. Although this formalism simplifies our analysis, it requires us to define plan
equivalence explicitly.

 A plan is a pair h; i, where  is a set of steps, and  is the \before" relation on ,
i.e.,  is a strict partial order on . Notationally, O1  O2 if and only if (O1; O2) 2.
 For a given problem, we define the search tree treeTO as the complete tree of plans
that is generated by the to algorithm on that problem. treeUA is the corresponding








search tree generated by ua on the same problem.
Two plans, P1 = h1; 1 i and P2 = h2 ; 2i are said to be equivalent, denoted
P1 ' P2, if there exists a bijective function f from 1 to 2 such that:
{ for all O 2 1, O and f (O) are instances of the same operator, and
{ for all O0; O00 2 1, O0  O00 if and only if f (O0)  f (O00).
A plan P2 is a 1-step to-extension (or 1-step ua-extension) of a plan P1 if P2 is
equivalent to some plan produced from P1 in one invocation of to (or ua).
A plan P is a to-extension (or ua-extension) if either:
{ P is the initial plan, or
{ P is a 1-step to-extension (or 1-step ua-extension) of a to-extension (or uaextension).
It immediately follows from this definition that if P is a member of treeTO (or treeUA ),
then P is a to-extension (or ua-extension). In addition, if P is a to-extension (or
ua-extension), then some plan that is equivalent to P is a member of treeTO (or
treeUA ).
P1 is a linearization of P2 = h; 2i if there exists a strict total order 1 such that
2  1 and P1 ' h; 1i.
Given a search tree, let parent be a function from a plan to its parent plan in the tree.
Note that P1 is the parent of P2 , denoted P1 = parent(P2 ), only if P2 is a 1-step
extension of P1 .
255

fiMinton, Bresina, & Drummond

 Given U 2 treeUA and T 2 treeTO , T 2 L(U ) if and only if plan T is a linearization
of plan U and either both U and T are root nodes of their respective search trees, or
parent(T ) 2 L(parent(U )).
 The length of the plan is the number of steps in the plan excluding the first and last
steps. Thus, the initial plan has length 0. A plan P with n steps has length n , 2.
 P1 is a subplan of P2 = h2; 2i if P1 ' h1; 1i, where
{ 1  2 and
{ 1 is 2 restricted to 1, i.e., 1 = 2 \ 1 1.
 P1 is a strict subplan of P2, if P1 is a subplan of P2 and the length of P1 is less than
the length of P2.
 A solution plan P is a compact solution if no strict subplan of P is a solution.

A.2 Extension Lemmas
TO-Extension Lemma: Consider totally ordered plans T0 = h0; 0i and T1 = h1; 1i,
such that 1 = 0 [ fOadd g and 0  1 . Let G be the set of false preconditions in T0.

Then T1 is a 1-step to-extension of T0 if:
 c = select-goal(G), where c is the precondition of some step Oneed in T0, and
 Oadd adds c, and
 (Oadd; Oneed) 21, and
 (Odel; Oadd) 21, where Odel is the last deleter of c in T1.

Proof Sketch: This lemma follows from the definition of to. Given plan T0, with false
precondition c, once to selects c as the goal, to will consider all operators that achieve c,
and for each operator to considers all positions before c and after the last deleter of c.
UA-Extension Lemma: Consider a plan U0 = h0; 0i produced by ua and plan
U1 = h1; 1i, such that 1 = 0 [ fOaddg and 0  1. Let G be the set of false
preconditions of the steps in U0 . Then U1 is a 1-step ua-extension of U0 if:
 c = select-goal(G), where c is the precondition of some step Oneed in U0, and
 Oadd adds c, and
 1 is a minimal set of consistent orderings such that
{ 0  1, and
{ (Oadd; Oneed) 21, and
{ (Odel; Oadd) 21, where Odel is the last deleter of c in U1, and
{ no step in U1 interacts with Oadd
256

fiTotal-Order and Partial-Order Planning

Proof Sketch: This lemma follows from the definition of ua. Given plan U0, with false

precondition c, ua considers all operators that achieve c, and for each such operator ua then
inserts it in the plan such that it is before c and after the last deleter. ua then considers
all consistent combinations of orderings between the new operator and the operators with
which it interacts. No other orderings are added to the plan.

A.3 Proof of Search Space Correspondence L
Mapping Lemma: Let U0 = h0; u0i be an unambiguous plan and let U1 = h1; u1i
be a 1-step ua-extension of U0. If T1 = h1; t1i is a linearization of U1 , then there exists

a plan T0 such that T0 is a linearization of U0 and T1 is a 1-step to-extension of T0 .
Proof: Since U1 is a 1-step ua-extension of U0, there is a step Oadd such that 1 = 0 [
fOaddg. Let T0 be the subplan produced by removing Oadd from T1; that is, T0 = h0; t0i,
where t0 = t1 \ 0 0 . Since u0 = u1 \ 0 0  t1 \ 0 0 = t0 , it follows that T0
is a linearization of U0.
Using the TO-Extension lemma, we can show that T1 is a 1-step to-extension of T0.
First, T0 is a linearization of U0 , so the two plans have the same set of goals. Therefore, if
ua selects some goal c in expanding U0 , to selects c in extending T0. Second, it must be
the case that Oadd adds c since Oadd is the step ua inserted into U0 to make c true. Third,
Oadd is before Oneed in T1, since Oadd is before Oneed in U1 (by definition of ua) and since
T1 is a linearization of U1. Fourth, Oadd is after the last deleter of c, Odel, in T1, since Oadd
is after Odel in U1 (by definition of ua) and since T1 is a linearization of U1. Therefore, the
conditions of the TO-Extension lemma hold and, thus, T1 is a 1-step to-extension of T0.
Q.E.D.

Totality Property For every plan U in treeUA , there exists a non-empty set fT1; : : :; Tmg
of plans in treeTO such that L(U ) = fT1; : : :; Tmg.
Proof: It suces to show that if plan U1 is a ua-extension and plan T1 is a linearization

of U1 , then T1 is a to-extension. The proof is by induction on plan length.
Base case: The statement trivially holds for plans of length 0.
Induction step: Under the hypothesis that the statement holds for plans of length n, we
now prove that the statement holds for plans of length n + 1. Suppose that U1 is a uaextension of length n + 1 and T1 is a linearization of U1 . Let U0 be a plan such that U1 is a
1-step ua-extension of U0 . By the Mapping lemma, there exists a plan T0 such that T0 is a
linearization of U0 and T1 is a 1-step to-extension of T0. By the induction hypothesis, T0
is a to-extension. Therefore, by definition, T1 is also a to-extension. Q.E.D.

Disjointness Property: L maps distinct plans in treeUA to disjoint sets of plans in treeTO ;
that is, if U1 ; U2 2 treeUA and U1 =
6 U2, then L(U1) \ L(U2) = fg.
Proof: By the definition of L, if T1; T2 2 L(U ), then T1 and T2 are at the same tree depth
d in treeTO ; furthermore, U is also at depth d in treeUA . Hence, it suces to prove that if
plans U1 and U2 are at depth d in treeUA and U1 6= U2 , then L(U1 ) \ L(U2 ) = fg.

Base case: The statement vacuously holds for depth 0.
Induction step: Under the hypothesis that the statement holds for plans at depth n, we
prove, by contradiction, that the statement holds for plans at depth n + 1. Suppose that
257

fiMinton, Bresina, & Drummond

there exist two distinct plans, U1 = h1; 1 i and U2 = h2 ; 2i, at depth n + 1 in
treeUA such that T 2 L(U1) \L(U2). Then (by definition of L), parent(T ) 2 L(parent(U1))
and parent(T ) 2 L(parent(U2 )). Since parent(U1 ) 6= parent(U2 ) contradicts the induction
hypothesis, suppose that U1 and U2 have the same parent U0 . Then, by the definition
of ua either (i) 1 6= 2 or (ii) 1 = 2 and 1 6=2 . In the first case, since the two
plans do not contain the same set of plan steps, they have disjoint linearizations and,
hence, L(U1 ) \ L(U2 ) = fg, which contradicts the supposition. In the second case,
1 = 2; hence, both plans resulted from adding plan step Oadd to the parent plan. Since
16=2, there exists a plan step Oint that interacts with Oadd such that in one plan Oint
is ordered before Oadd and in the other plan Oadd is ordered before Oint . Thus, in either
case, the linearizations of the two plans are disjoint and, hence, L(U1 ) \ L(U2 ) = fg,
which contradicts the supposition. Therefore, the statement holds for plans at depth n + 1.
Q.E.D.

A.4 Completeness Proof for TO

We now prove that to is complete under a breadth first search control strategy. To do so, it
suces to prove that if there exists a solution to a problem, then there exists a to-extension
that is a compact solution. Before doing so, we prove the following lemma.

Subplan Lemma: Let totally ordered plan T0 be a strict subplan of a compact solution Ts.

Then there exists a plan T1 such that T1 is a subplan of Ts and T1 is a 1-step to-extension
of T0.
Proof: Since T0 is a strict subplan of Ts and Ts is a compact solution, the set of false
preconditions in T0, G, must not be empty. Let c = select-goal(G), let Oneed be the
step in T0 with precondition c, and let Oadd be the step in Ts that achieves c. Consider the
totally ordered plan T1 = h0 [ fOadd g; 1i, where 1  s . Clearly, T1 is a subplan of
Ts. Furthermore, by the TO-Extension Lemma, T1 is a 1-step extension of T0 by to. To
see this, note that Oadd is ordered before Oneed in T1 since it is ordered before Oneed in Ts .
Similarly, Oadd is ordered after the last deleter of c in T0 since any deleter of c in T0 is a
deleter of c in Ts , and Oadd is ordered after the deleters of c in Ts . Thus, the conditions of
the TO-Extension Lemma hold. Q.E.D.
TO

Completeness Theorem: If plan Ts is a totally ordered compact solution, then Ts

is a to-extension.
Proof: Let n be the length of Ts. We show that for all k  n, there exists a subplan of Ts
with length k that is a to-extension. This is sucient to prove our result since any subplan
of exactly length n is equivalent to Ts . The proof is by induction on k.
Base case: If k = 0 the statement holds since the initial plan, which has length 0, is a
subplan of any solution plan.
Induction step: We assume that the statement holds for k and show that if k < n the
statement holds for k + 1. By the induction hypothesis, there exists a plan T0 of length k
that is a strict subplan of Ts . By the Subplan Lemma, there exists a plan T1 that is both a
subplan of Ts and a 1-step to-extension of T0. Thus, there exists a subplan of Ts of length
k + 1. Q.E.D.
258

fiTotal-Order and Partial-Order Planning

A.5 Completeness Proof for UA

We now prove that ua is complete under a breadth-first search strategy. The result follows
from the search space correspondence defined by L and the fact that to is complete. In
particular, we show below that for any to-extension T , there exists a ua-extension U such
that T is a linearization of U . Since ua produces only unambiguous plans, it must be the
case that if T is a solution, U is also a solution. From this, it follows immediately that ua
is complete.

Inverse Mapping Lemma: Let T0 = h0; t0i be a totally ordered plan. Let T1 =
h1; t1i be a 1-step to-extension of T0. Let U0 = h0; u0i be a plan produced by ua such
that T0 is a linearization of U0 . Then there exists a plan U1 such that T1 is a linearization
of U1 and U1 is a 1-step ua-extension of U0 .
Proof: By the definition of to, 1 = 0 [ fOaddg, where Oadd added some c that is a
false precondition of some plan step Oneed in U0 . Consider U1 = h1 ; u1 i, where u1 is a
minimal subset of t1 such that:
 u0  u1, and
 (Oadd; Oneed) 2u1, and
 (Odel; Oadd) 2u1 , where Odel is the last deleter of c in U1, and
 no step in U1 interacts with Oadd
Since u1  t1 , T1 is a linearization of U1. In addition, U1 is an extension of U0 since
it meets the three conditions of the UA-Extension Lemma, as follows. First, since c must
have been the goal selected by to in extending T0, c must likewise be selected by ua in
extending U0 . Second, Oadd adds c since Oadd achieves c in T0. Finally, by construction,
u1 satisfies the third condition of the UA-Extension Lemma. Q.E.D.
UA Completeness Theorem: Let Ts be a totally ordered compact solution. Then there

exists a ua-extension Us such that Ts is a linearization of Us .
Proof: Since to is complete, it suces to show that if T1 is a to-extension, then there
exists a ua-extension U1 such that T1 is a linearization of U1 . The proof is by induction on
plan length.
Base case: The statement trivially holds for plans of length 0.
Induction step: Under the hypothesis that the statement holds for plans of length n, we
now prove that the statement holds for plans of length n + 1. Assume T1 is a to-extension
of length n + 1, and let T0 be a plan such that T1 is a 1-step to-extension of T0. By
the induction hypothesis, there exists a ua-extension U0 of length n such that T0 is a
linearization of U0. By the Inverse Mapping Lemma, there exists a plan U1 that is both a
linearization of T1 and a 1-step ua-extension of U0 . Since U1 is a 1-step ua-extension of
U0, it has length n + 1. Q.E.D.

259

fiMinton, Bresina, & Drummond

Acknowledgements
Most of the work present in this paper was originally described in two conference papers
(Minton et al., 1991a, 1992). We thank Andy Philips for his many contributions to this
project. He wrote the code for the planners and helped conduct the experiments. We also
thank the three anonymous reviewers for their excellent comments.

References

Backstrom, C. (1993). Finding least constrained plans and optimal parallel executions
is harder than we thought. In Proceedings of the Second European Workshop on
Planning.
Barrett, A., Soderland, S., & Weld, D. (1991). The effect of step-order representations on
planning. Tech. rep. 91-05-06, Univ. of Washington, Computer Science Dept.
Barrett, A., & Weld, D. (1994). Partial-order planning: Evaluating possible eciency gains.
Artificial Intelligence, 67 (1), 71{112.
Chapman, D. (1987). Planning for conjunctive goals. Artificial Intelligence, 32, 333{377.
Chen, P. (1989). Heuristic Sampling on Backtrack Trees. Ph.D. thesis, Dept. of Computer
Science, Stanford Univ., Stanford, CA.
Collins, G., & Pryor, L. (1992). Achieving the functionality of filter conditions in a partial
order planner. In Proceedings of the Tenth National Conference on Artificial Intelligence.
Crawford, J., & Baker, A. (1994). Experimental results on the application of satisfiability
algorithms to scheduling problems. In Proceedings of the Twelfth National Conference
on Artificial Intelligence.
Dean, T., & Boddy, M. (1988). Reasoning about partially ordered events. Artificial Intelligence, 36, 375{399.
Drummond, M., & Currie, K. (1989). Goal-ordering in partially ordered plans. In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence.
Ginsberg, M., & Harvey, W. (1992). Iterative broadening. Artificial Intelligence, 55, 367{
383.
Godefroid, P., & Kabanza, F. (1991). An ecient reactive planner for synthesizing reactive
plans. In Proceedings of the Ninth National Conference on Artificial Intelligence.
Hertzberg, J., & Horz, A. (1989). Towards a theory of conict detection and resolution
in nonlinear plans. In Proceedings of the Eleventh International Joint Conference on
Artificial Intelligence.
Kambhampati, S. (1994a). Design tradeoffs in partial order (plan space) planning. In
Proceedings of the Second International Conference on AI Planning Systems.
260

fiTotal-Order and Partial-Order Planning

Kambhampati, S. (1994b). Multi contributor causal structures for planning: A formalization
and evaluation. Artificial Intelligence, 69, 235{278.
Kambhampati, S. (1994c). Refinement search as a unifying framework for analyzing plan
space planners. In Proceedings of the Fourth International Conference on Principles
of Knowledge Representation and Reasoning.
Kambhampati, S., & Chen, J. (1993). Relative utility of EBG-based plan reuse in partial ordering vs. total ordering planning. In Proceedings of the Eleventh National Conference
on Artificial Intelligence.
Korf, R. (1985). Depth-first iterative deepening: An optimal admissible tree search. Artificial Intelligence, 27, 97{109.
Korf, R. (1987). Planning as search: A quantitative approach. Artificial Intelligence, 33,
65{88.
Langley, P. (1992). Systematic and nonsystematic search strategies. In Proceedings of the
First International Conference on AI Planning Systems.
McAllester, D., & Rosenblitt, D. (1991). Systematic nonlinear planning. In Proceedings of
the Ninth National Conference on Artificial Intelligence.
Minton, S., Bresina, J., & Drummond, M. (1991a). Commitment strategies in planning: A
comparative analysis. In Proceedings of the Twelfth International Joint Conference
on Artificial Intelligence.
Minton, S., Bresina, J., Drummond, M., & Philips, A. (1991b). An analysis of commitment
strategies in planning: The details. Tech. rep. 91-08, NASA Ames, AI Research
Branch.
Minton, S., Drummond, M., Bresina, J., & Philips, A. (1992). Total order vs. partial order
planning: Factors inuencing performance. In Proceedings of the Third International
Conference on Principles of Knowledge Representation and Reasoning.
Pednault, E. (1988). Synthesizing plans that contain actions with context-dependent effects.
Computational Intelligence, 4, 356{372.
Penberthy, J., & Weld, D. (1992). UCPOP: A sound, complete, partial-order planner for
adl. In Proceedings of the Third International Conference on Principles of Knowledge
Representation and Reasoning.
Regnier, P., & Fade, B. (1991). Complete determination of parallel actions and temporal
optimization in linear plans of action. In Hertzberg, J. (Ed.), European Workshop
on Planning, Vol. 522 of Lecture Notes in Artificial Intelligence, pp. 100{111 Sankt
Augustin, Germany. Springer.
Rosenbloom, P., Lee, S., & Unruh, A. (1993). Bias in planning and explanation-based learning. In Minton, S. (Ed.), Machine Learning Methods for Planning. Morgan Kaufmann
Publishers.
261

fiMinton, Bresina, & Drummond

Sacerdoti, E. (1975). The nonlinear nature of plans. In Proceedings of the Fourth International Joint Conference on Artificial Intelligence.
Sacerdoti, E. (1977). A Structure for Plans and Behavior. American Elsivier, New York.
Tate, A. (1974). Interplan: A plan generation system which can deal with interactions
between goals. Tech. rep. Memo MIP-R-109, Univ. of Edinburgh, Machine Intelligence
Research Unit.
Tate, A. (1977). Generating project networks. In Proceedings of the Fifth International
Joint Conference on Artificial Intelligence.
Veloso, M., Perez, M., & Carbonell, J. (1990). Nonlinear planning with parallel resource
allocation. In Proceedings of the Workshop on Innovative Approaches to Planning,
Scheduling and Control.
Waldinger, R. (1975). Achieving several goals simultaneously. In Machine Intelligence 8.
Ellis Harwood, Ltd.
Warren, D. (1974). Warplan: A system for generating plans. Tech. rep. Memo 76, Computational Logic Dept., School of AI, Univ. of Edinburgh.

262

fiJournal of Artificial Intelligence Research 2 (1995) 411-446

Submitted 11/94; published 4/95

Rerepresenting and Restructuring Domain Theories:
A Constructive Induction Approach
Steven K. Donoho
Larry A. Rendell

Department of Computer Science, Univeristy of Illinois
405 N. Mathews Ave., Urbana, IL 61801 USA

donoho@cs.uiuc.edu
rendell@cs.uiuc.edu

Abstract

Theory revision integrates inductive learning and background knowledge by combining
training examples with a coarse domain theory to produce a more accurate theory. There
are two challenges that theory revision and other theory-guided systems face. First, a
representation language appropriate for the initial theory may be inappropriate for an
improved theory. While the original representation may concisely express the initial theory,
a more accurate theory forced to use that same representation may be bulky, cumbersome,
and dicult to reach. Second, a theory structure suitable for a coarse domain theory may
be insucient for a fine-tuned theory. Systems that produce only small, local changes to
a theory have limited value for accomplishing complex structural alterations that may be
required.
Consequently, advanced theory-guided learning systems require exible representation
and exible structure. An analysis of various theory revision systems and theory-guided
learning systems reveals specific strengths and weaknesses in terms of these two desired
properties. Designed to capture the underlying qualities of each system, a new system uses
theory-guided constructive induction. Experiments in three domains show improvement
over previous theory-guided systems. This leads to a study of the behavior, limitations,
and potential of theory-guided constructive induction.

1. Introduction
Inductive learners normally use training examples, but they can also use background knowledge. Effectively integrating this knowledge into induction has been a widely studied research problem. Most work to date has been in the area of theory revision in which the
knowledge given is a coarse, perhaps incomplete or incorrect, theory of the problem domain,
and training examples are used to shape this initial theory into a refined, more accurate
theory (Ourston & Mooney, 1990; Thompson, Langley, & Iba, 1991; Cohen, 1992; Pazzani
& Kibler, 1992; Baffes & Mooney, 1993; Mooney, 1993). We develop a more exible and
more robust approach to the problem of learning from both data and theory knowledge by
addressing the two following desirable qualities:

 Flexible Representation. A theory-guided system should utilize the knowledge contained in the initial domain theory without having to adhere closely to the initial
theory's representation language.

 Flexible Structure. A theory-guided system should not be unnecessarily restricted by
the structure of the initial domain theory.

c 1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiDonoho & Rendell

Before giving more precise definitions of our terms, we motivate our work intuitively.

1.1 Intuitive Motivation
The first desirable quality, exibility of representation, arises because the theory representation most appropriate for describing the coarse, initial domain theory may be inadequate
for the final, revised theory. While the initial domain theory may be compact and concise in
one representation, an accurate theory may be quite bulky and cumbersome in that representation. Furthermore, the representation that is best for expressing the initial theory may
not be the best for carrying out refinements. A helpful refinement step may be clumsy to
make in the initial representation yet be carried out quite simply in another representation.
As a simple example, a coarse domain theory may be expressed as the logical conjunction
of N conditions that should be met. The most accurate theory, though, is one in which any M
of these N conditions holds. Expressing this more accurate theory in the DNF representation
used to describe the initial theory would be cumbersome and unwieldy (Murphy & Pazzani,
1991). Furthermore, arriving at the final theory using the refinement operators most suitable
for DNF (drop-condition, add-condition, modify-condition) would be a cumbersome task.
But when an M-of-N representation is adopted, the refinement simply involves empirically
finding the appropriate M, and the final theory can be expressed concisely (Baffes & Mooney,
1993).
Similarly, the second desirable quality, exibility of structure, arises because the theory
structure that was suitable for a coarse domain theory may be insucient for a fine-tuned
theory. In order to achieve the desired accuracy, a restructuring of the initial theory may be
necessary. Many theory revision systems act by making a series of local changes, but this
can lead to behavior at two extremes. The first extreme is to rigidly retain the backbone
structure of the initial domain theory, only allowing small, local changes. Figure 1 illustrates
this situation. Minor revisions have been made { conditions have been added, dropped,
and modified { but the refined theory is trapped by the backbone structure of the initial
theory. When only local changes are needed, these techniques have proven useful (Ourston
& Mooney, 1990), but often more is required. When more is required, these systems often
move to the other extreme; they drop entire rules and groups of rules and then build entire
new rules and groups of rules from scratch to replace them. Thus they restructure, but
they forfeit valuable knowledge in the process. An ideal theory revision system would glean
knowledge from theory substructures that cannot be fixed with small, local changes and
use this in a restructured theory.
As an intuitive illustration, consider a piece of software that \almost works." Sometimes
it can be made useful through only a few local operations: fixing a couple of bugs, adding
a needed subroutine, and so on. In other cases, though, a piece of software that \almost
works" is in fact far from full working order. It may need to be redesigned and restructured.
A mistake at one extreme is to try to fix a program like this by making a series of patches in
the original code. A mistake at the other extreme is to discard the original program without
learning anything from it and start from scratch. The best approach would be to examine
the original program to see what can be learned from its design and to use this knowledge
in the redesign. Likewise, attempting to improve a coarse domain theory through a series
of local changes may yield little improvement because the theory is trapped by its initial
412

fiRerepresenting and Restructuring Domain Theories

Initial Theory

a

b

c

j

d e

h i

Refined Theory

n

k l m

s

a

b

c

o p q r

j

w e

f g

i

n

k l

u

o

p

v

r

t f g

Figure 1: Typical theory revision allows only limited structural exibility. Although conditions have been added, dropped, and modified, the revised theory is much
constrained by the structure of the initial theory.
structure. This does not render the original domain theory useless; careful analysis of the
initial domain theory can give valuable guidance for the design of the best final theory.
This is illustrated in Figure 2 where many substructures have been taken from the initial
theory and adapted for use in the refined theory. Information from the initial theory has
been used, but the structure of the revised theory is not restricted by the structure of the
initial theory.
Initial Theory

a

b

c

n

j

d e

h i

Refined Theory

k l m

k

o p q r

l

f

d

g

m

e

h

i

s

o

p

u

v

f g q r

f g

Figure 2: More exible structural modification. The revised theory has taken many substructures from the initial theory and adapted and recombined them for its use,
but the structure of the revised theory is not restricted by the structure of the
initial theory.

413

fiDonoho & Rendell

1.2 Terminology

In this paper, all training data consist of examples which are classified vectors of feature/value pairs. We assume that an initial theory is a set of conditions combined using the
operators AND, OR, and NOT and indicating one or more classes. While it is unreasonable
to believe that all theories will always be of this form, it covers much existing theory revision
research.
Our work is intended as an informal exploration of exible representation and exible
structure. Flexible representation means allowing the theory to be revised using a representation language other than that of the initial theory. An example of exible representation
is the introduction of a new operator for combining features | an operator not used in
the initial theory. In Section 1.1 the example was given of introducing the M-of-N operator
to represent a theory originally expressed in DNF. Flexible structure means not limiting
revision of the theory to a series of small, incremental modifications. An example of this
is breaking the theory down into its components and using them as building blocks in the
construction of a new theory.
Constructive induction is a process whereby the training examples are redescribed using
a new set of features. These new features are combinations of the original features. Bias
or knowledge may be used in the construction of the new features. A subtle point is that
when we speak of exible representation, we are referring only to the representation of the
domain theory, not the training data. Although the phrase \change of representation" is
often applied to constructive induction, this refers to a change of the data. In our paper,
the term exible representation is reserved for a change of theory representation. Thus
a system can be performing constructive induction (changing the feature language of the
data) without exhibiting exible representation (changing the representation of the theory).

1.3 Overview

Theory revision and constructive induction embody complementary aspects of the machine
learning research community's ultimate goals. Theory revision uses data to improve a
theory; constructive induction can use a theory to improve data to facilitate learning. In
this paper we present a theory-guided constructive induction approach which addresses the
two desirable qualities discussed in Section 1.1. The initial theory is analyzed, and new
features are constructed based on the components of the theory. The constructed features
need not be expressed in the same representational language as the initial theory and can
be refined to better match the training examples. Finally, a standard inductive learning
algorithm, C4.5 (Quinlan, 1993), is applied to the redescribed examples.
We begin by analyzing how landmark theory revision and learning systems have exhibited exibility in handling a domain theory and what part this has played in their performance. From this analysis, we extract guidelines for system design and apply them to the
design of our own limited system. In an effort to integrate learning from theory and data,
we borrow heavily from the theory revision, multistrategy learning, and constructive induction communities, but our guidelines for system design fall closest to classical constructive
induction methods. The central focus of this paper is not the presentation of \another new
system" but rather a study of exible representation and structure, their manifestation in
previous work, and their guidance for future design.
414

fiRerepresenting and Restructuring Domain Theories

Section 2 gives the context of our work by analyzing previous research and its inuence on our work. Section 3 explores the Promoter Recognition domain and demonstrates
how related theory revision systems behave in this domain. In Section 4, guidelines for
theory-guided constructive induction are presented. These guidelines are a synthesis of the
positive aspects of related research, and they address the two desirable qualities, exibility
of representation and exibility of structure. Section 4 also presents a specific theory-guided
constructive induction algorithm which is an instantiation of the guidelines set forth earlier
in that section. Results of experiments in three domains are given in Section 5 followed
by a discussion of the strengths of theory-guided constructive induction in Section 6. Section 7 presents an experimental analysis of the limits of applicability of our simple algorithm
followed by a discussion of limitations and future directions of our work in Section 8.

2. Context and Related Work

Although our work bears some resemblance in form and objective to many papers in constructive induction (Michalski, 1983; Fu & Buchanan, 1985; Utgoff, 1986; Schlimmer, 1987;
Drastal & Raatz, 1989; Matheus & Rendell, 1989; Pagallo & Haussler, 1990; Ragavan &
Rendell, 1993; Hirsh & Noordewier, 1994), theory revision (Ourston & Mooney, 1990; Feldman, Serge, & Koppel, 1991; Thompson et al., 1991; Cohen, 1992; Pazzani & Kibler, 1992;
Baffes & Mooney, 1993), and multistrategy approaches (Flann & Dietterich, 1989; Towell,
Shavlik, & Noordeweir, 1990; Dzerisko & Lavrac, 1991; Bloedorn, Michalski, & Wnek, 1993;
Clark & Matwin, 1993; Towell & Shavlik, 1994), we focus only upon a handful of these systems, those that have significant, underlying similarities to our work. In this section we
analyze Miro, Either, Focl, LabyrinthK , Kbann, Neither-MofN, and Grendel to
discuss their related underlying contributions in relationship to our perspective.

2.1

Miro

(Drastal & Raatz, 1989) is a seminal work in knowledge-guided constructive induction. It takes knowledge about how low-level features interact and uses this knowledge to
construct high-level features for its training examples. A standard learning algorithm is
then run on these examples described using the new features. The domain theory is used
to shift the bias of the induction problem (Utgoff, 1986). Empirical results showed that
describing the examples in these high-level, abstract terms improved learning accuracy.
The Miro approach provides a means of utilizing knowledge in a domain theory without
being restricted by the structure of that theory. Substructures of the domain theory can
be used to construct high-level features that a standard induction algorithm will arrange
into a concept. Some constructed features will be used as they are, others will be ignored,
others will be combined with low-level features, and still others may be used differently in
multiple contexts. The end result is that knowledge from the domain theory is utilized,
but the structure of the final theory is not restricted by the structure of the initial theory.
Miro provides exible structure.
Another benefit is that Miro-like techniques can be applied even when only a partial
domain theory exists, i.e., a domain theory that only specifies high-level features but does
not link them together or a domain theory that specifies some high-level features but not
others. One of Miro's shortcomings is that it provided no means of making minor changes
Miro

415

fiDonoho & Rendell

in the domain theory but rather constructed the features exactly as the domain theory
specified. Also the representation of Miro's constructed features was primitive | either
an example met the conditions of a high-level feature or did not. An example of Miro's
behavior is given in Section 3.2.

2.2

,

, and LabyrinthK

Either Focl

The

Either

(Ourston & Mooney, 1990), LabyrinthK (Thompson et al., 1991), and
Focl (Pazzani & Kibler, 1992) systems represent a broad spectrum of theory revision
work. They make steps toward effective integration of background knowledge and inductive
learning. Although these systems have many superficial differences with regard to supervised/unsupervised learning, concept description language, etc., they share the underlying
principle of incrementally revising an initial domain theory through a series of local changes.
We will discuss Either as a representative of this class of systems. Either's theory
revision operators include: removing unwanted conditions from a rule, adding needed conditions to a rule, removing rules, and adding totally new rules. Either first classifies its
training examples according to the current theory. If any are misclassified, it seeks to repair
the theory by applying a theory revision operator that will result in the correct classification
of some previously misclassified examples without losing any of the correct examples. Thus
a series of local changes are made that allow for an improvement of accuracy on the training
set without losing any of the examples previously classified correctly.
Either-type methods provide simple yet powerful tools for repairing many important
and common faults in domain theories, but they fail to meet the qualities of exible representation and exible structure. Because the theory revision operators make small, local
modifications in the existing domain theory, the final theory is constrained to be similar in
structure to the initial theory. When an accurate theory is significantly different in structure from the initial theory, these systems are forced to one of the two extremes discussed
in Section 1. The first extreme is to become trapped at a local maximum similar to the
initial theory unable to reach the global maximum because only local changes can be made.
The other extreme is to drop entire rules and groups of rules and replace them with new
rules built from scratch thus forfeiting the knowledge contained in the domain theory.
Also, Either carries out all theory revision steps in the representation of the initial
theory. Consequently, the representation of the final theory is the same as that of the initial
theory. Another representation may be more appropriate for the revised theory than the
one in which the initial theory comes, but facilities are not provided to accommodate this.
An advanced theory revision system would combine the locally acting strengths of Eithertype systems with exibility of structure and exibility of representation. An example of
Either's behavior is given in Section 3.3.

2.3

Kbann

and Neither-MofN

The Kbann system (Towell et al., 1990; Towell & Shavlik, 1994) makes unique contributions to theory revision work. Kbann takes an initial domain theory described symbolically
in logic and creates a neural network whose structure and initial weights encode this theory.
Backpropagation (Rumelhart, Hinton, & McClelland, 1986) is then applied as a refinement tool for fine-tuning the network weights. Kbann has been empirically shown to give
416

fiRerepresenting and Restructuring Domain Theories

significant improvement over many theory revision systems for the widely-used Promoter
Recognition domain. Although our work is different in implementation from Kbann, our
abstract ideologies are similar.
One of Kbann's important contributions is that it takes a domain theory in one representation (propositional logic) and translates it into a less restricting representation (neural
network). While logic is an appropriate representation for the initial domain theory for the
promoter problem, the neural network representation is more convenient both for refining
this theory and for expressing the best revised theory. This change of representation is
Kbann's real source of power. Much attention has been given to the fact that Kbann combines symbolic knowledge with a subsymbolic learner, but this combination can be viewed
more generally as a means of implementing the important change of representation. It may
be the change of representation that gives Kbann its power, not necessarily its specific
symbolic/subsymbolic implementation. Thus the Kbann system embodies the higher-level
principle of allowing refinement to occur in an appropriate representation.
If an alternative representation is Kbann's source of power, the question must be raised
as to whether the actual Kbann implementation is always the best means of achieving this
goal. The neural network representation may be more expressive than is required. Accordingly, backpropagation often has more refinement power than is needed. Thus Kbann may
carry excess baggage in translating into the neural net representation, performing expensive
backpropagation, and extracting symbolic rules from the refined network. Although the full
extent of Kbann's power may be needed for some problems, many important problems may
be solvable by applying Kbann's principles at the symbolic level using less expensive tools.
Neither-MofN (Baffes & Mooney, 1993), a descendant of Either, is a second example
of a system that allows a theory to be revised in a representation other than that of the
initial theory. The domain theory input into Neither-MofN is expressed in propositional
logic as an AND/OR tree. Neither-MofN interprets the theory less rigidly | an AND
rule is true any time any M of its N conditions are true. Initially M is set equal to N (all
conditions must be true for the rule to be true), and one theory refinement operator is to
lower M for a particular rule. The end result is that examples that are a close enough
partial match to the initial theory are accepted. Neither-MofN, since it is built upon
the Either framework, also includes Either-like theory revision operators: add-condition,
drop-condition, etc.
Thus Neither-MofN allows revision to take place in a representation appropriate
for revision and appropriate for concisely expressing the best refined theory. NeitherMofN has achieved results comparable to Kbann on the Promoter Recognition domain,
which suggests that it is the change of representation which these two systems share that
give them their power rather than any particular implementation. Neither-MofN also
demonstrates that a small amount of representational exibility is sometimes enough. The
M-of-N representation it employs is not as big a change from the original representation
as the neural net representation which Kbann employs yet it achieves similar results and
arrives at them much more quickly than Kbann (Baffes & Mooney, 1993).
A shortcoming of Neither-MofN is that since it acts by making local changes in an
initial theory, it can still become trapped by the structure of the initial theory. An advanced
theory revision system would incorporate Neither-MofN's and Kbann's exibility of
417

fiDonoho & Rendell

representation and allow knowledge-guided theory restructuring. Examples of
and Neither-MofN's behavior are given in Sections 3.4 and 3.5.

2.4

's

Kbann

Grendel

Cohen (1992) analyzes a class of theory revision systems and draws some insightful conclusions. One is that \generality [in theory interpretation] comes at the expense of power."
He draws this principle from the fact that a system such as Either or Focl treats every
domain theory the same and therefore must treat every domain theory in the most general way. He argues that rather than just applying the most general refinement strategy
to every problem, a small set of refinement strategies should be available that are narrow
enough to gain leverage yet not so narrow that they only apply to a single problem. Cohen
presents Grendel, a toolbox of translators each of which transforms a domain theory into
an explicit bias. Each translator interprets the domain theory in a different way, and the
most appropriate interpretation is applied to a given problem.
We apply Cohen's principle to the representation of domain theories. If all domain
theories are translated into the same representation, then the most general, adaptable representation has to be used in order to accommodate the most general case. This comes
at the expense of higher computational costs and possibly lower accuracy due to overfit
stemming from unbridled adaptability. The neural net representation into which Kbann
translates domain theories allows 1) a measure of partial match to the domain theory 2) different parts of the domain theory to be weighted differently 3) conditions to be added to
and dropped from the domain theory. All these options of adaptability are probably not
necessary for most problems and may even be detrimental. These options in Kbann also
require the computationally expensive backpropagation method.
The representation used in Neither-MofN is not as adaptable as Kbann's | it does
not allow individual parts of the domain theory to be weighted differently. NeitherMofN runs more quickly than Kbann on small problems and probably matches or even
surpasses Kbann's accuracy for many domains | domains for which fine-grained weighting
is unfruitful or even detrimental. A toolbox of theory rerepresentation translators analogous
to Grendel would allow a domain theory to be translated into a representation having the
most appropriate forms of adaptability.

2.5 Outlook and Summary

In summary, we briey reexamine exible representation and exible structure, the two
desirable qualities set forth in Section 1. We consider how the various systems exemplify
some subset of these desirable qualities.
 Kbann and Neither-MofN both interpreted a theory more exibly than its original
representation allowed and revised the theory in this more adaptable representation.
A final, refined theory often has many exceptions to the rule; it may tolerate partial
matches and missing pieces of evidence; it may weight some evidence more heavily
than other evidence. Kbann's and Neither-MofN's new representation may not
be the most concise, appropriate representation for the initial theory, but the new
representation allows concise expression of an otherwise cumbersome final theory.
These are cases of the principle of exible representation.
418

fiRerepresenting and Restructuring Domain Theories

 Standard induction programs have been quite successful at building concise theories
with high predictive accuracy when the target concept can be concisely expressed using
the original set of features. When it can't, constructive induction is a means of creating
new features such that the target concept can be concisely expressed. Miro uses
constructive induction to take advantage of the strengths of both a domain theory and
standard induction. Knowledge from the theory guides the construction of appropriate
new features, and standard induction structures these into a concise description of
the concept. Thus Miro-like construction coupled with standard induction provides
a ready and powerful means of exibly restructuring the knowledge contained in an
initial domain theory. This is a case of the principle of exible structure.

In the following section we introduce the DNA Promoter Recognition domain in order
to illustrate tangibly how some of the systems discussed above integrate knowledge and
induction.

3. Demonstrations of Related Work
This section introduces the Promoter Recognition domain (Harley, Reynolds, & Noordewier,
1990) and briey illustrates how a Miro-like system, Either, Kbann, and NeitherMofN behave in this domain. We implemented a Miro-like system for the promoter domain; versions of Either and Neither-MofN were available from Ray Mooney's group;
Kbann's behavior is described by analyzing (Towell & Shavlik, 1994). We chose the promoter domain because it is a non-trivial, real-world problem which a number of theory
revision researchers have used to test their work (Ourston & Mooney, 1990; Thompson
et al., 1991; Wogulis, 1991; Cohen, 1992; Pazzani & Kibler, 1992; Baffes & Mooney, 1993;
Towell & Shavlik, 1994). The promoter domain is one of three domains in which we evaluate
our work, theory-guided constructive induction, in Section 5.

3.1 The Promoter Recognition Domain

A promoter sequence is a region of DNA that marks the beginning of a gene. Each example in the promoter recognition domain is a region of DNA classified either as a promoter
or a non-promoter. As illustrated in Figure 3, examples consist of 57 features representing a sequence of 57 DNA nucleotides. Each feature can take on the values A,G,C, or T
representing adenine, guanine, cytosine, and thymine at the corresponding DNA position.
The features are labeled according to their position from p-50 to p+7 (there is no zero
position). The notation \p-N " denotes the nucleotide that is N positions upstream from
the beginning of the gene. The goal is to predict whether a sequence is a promoter from its
nucleotides. A total of 106 examples are available: 53 promoters and 53 non-promoters.
The promoter recognition problem comes with the initial domain theory shown in Figure 4 (quoted almost verbatim from Towell and Shavlik's entry in the UCI Machine Learning
Repository). The theory states that promoter sequences must have two regions that make
contact with a protein and must also have an acceptable conformation pattern. There are
four possibilities for the contact region at minus 35 (35 nucleotides upstream from the beginning of the gene). A match of any of these four possibilities will satisfy the minus 35
contact condition, thus they are joined by disjunction. Similarly, there are four possibilities
419

fiDonoho & Rendell

DNA Sequence

p-50

p+7

C G A C T T
Figure 3: An instance in the promoter domain consists of a sequence of 57 nucleotides
labeled from p-50 to p+7. Each nucleotide can take on the values A,G,C, or T
representing adenine, guanine, cytosine, and thymine.
for the contact region at minus 10 and four acceptable conformation patterns. Figure 5
gives a more pictorial presentation of portions of the theory. Of the 106 examples in the
dataset, none matched the domain theory exactly, yielding an accuracy of 50%.

3.2

Miro

in the Promoter Domain

A Miro-like system in the promoter domain would use the rules in Figure 4 to construct new high-level features for each DNA segment. Figure 6 shows an example of this. A
DNA segment is shown from position p-38 through position p-30. The minus 35 rules from
the theory are also shown, and four new features (feat minus35 A through feat minus35 D)
have been constructed for that DNA segment, one for each minus 35 rule. The new features feat minus35 A and feat minus35 D both have the value 1 because the DNA fragment
matches the first and fourth minus 35 rules. Likewise, feat minus35 B and feat minus35 C
both have the value 0 because the DNA fragment does not match the second and third
rules. Furthermore, since the four minus 35 rules are joined by disjunction, a new feature,
feat minus35 all, is created for the group that would have the value 1 because at least one
of the minus 35 rules matches.
New features would similarly be created for the minus 10 rules and the conformation
rules, and a standard induction algorithm could then be applied. We implemented a Mirolike system; Figure 7 gives an example theory created by it. (Drastal's original Miro used
the candidate elimination algorithm (Mitchell, 1977) as its underlying induction algorithm.
We used C4.5 (Quinlan, 1993).) As opposed to theory revision systems that incrementally
modify the domain theory, Miro has broken the theory down into its components and has
fashioned these components into a new theory using a standard induction program. Thus
Miro has exhibited the exible structure principle for this domain { it was not restricted
in any way by the structure of the initial theory. Rather, Miro exploited the strengths of
standard induction to concisely characterize the training examples using the new features.
420

fiRerepresenting and Restructuring Domain Theories

Promoters have a region where a protein (RNA polymerase) must make contact and
the helical DNA sequence must have a valid conformation so that the two pieces
of the contact region spatially align. Prolog notation is used.
promoter :- contact, conformation.
There are two regions "upstream" from the beginning of the gene at which the
RNA polymerase makes contact.
contact

:- minus_35, minus_10.

The following rules describe the compositions of possible contact regions.
minus_35
minus_35
minus_35
minus_35

:- p-37=c, p-36=t, p-35=t, p-34=g, p-33=a, p-32=c.
:p-36=t, p-35=t, p-34=g,
p-32=c, p-31=a.
:p-36=t, p-35=t, p-34=g, p-33=a, p-32=c, p-31=a.
:p-36=t, p-35=t, p-34=g, p-33=a, p-32=c.

minus_10
minus_10
minus_10
minus_10

:- p-14=t, p-13=a, p-12=t, p-11=a, p-10=a, p-9=t.
:p-13=t, p-12=a,
p-10=a,
p-8=t.
:p-13=t, p-12=a, p-11=t, p-10=a, p-9=a, p-8=t.
:p-12=t, p-11=a,
p-7=t.

The following rules describe sequences that produce acceptable conformations.
conformation :- p-47=c,
p-18=t,
p-1=c.
conformation :- p-45=a,
conformation :- p-49=a,
conformation :- p-45=a,
p-15=t,

p-46=a, p-45=a, p-43=t, p-42=t, p-40=a, p-39=c, p-22=g,
p-16=c, p-8=g, p-7=c, p-6=g, p-5=c, p-4=c, p-2=c,
p-44=a, p-41=a.
p-44=t, p-27=t, p-22=a, p-18=t, p-16=t, p-15=g, p-1=a.
p-41=a, p-28=t, p-27=t, p-23=t, p-21=a, p-20=a, p-17=t,
p-4=t.

Figure 4: The initial domain theory for recognizing promoters (from Towell and Shavlik).
A weakness Miro displays in this example is that it allows no exibility of representation
of the theory. The representation of the features constructed by Miro is basically the same
all-or-none representation of the initial theory; either a DNA segment matched a rule, or it
did not.

3.3

Either

in the Promoter Domain

An Either-like system refines the initial promoter theory by dropping and adding
conditions and rules. We simulated Either by turning off the M-of-N option in Neither
and ran it in the promoter domain. Figure 8 shows the refined theory produced using a
randomly selected training set of size 80. Because the initial promoter domain theory does
not lend itself to revision through small, local changes, Either has only limited success.
421

fiDonoho & Rendell

DNA Sequence

p-50

p+7

Contact at minus_35

Contact at minus_10

-37 -36 -35 -34 -33 -32 -31

C T

T G A C

*

-14 -13 -12 -11 -10 -9

-8 -7

T A A T

* *

T

A

OR

OR

* T T G * C A

*

T A

OR

T *

OR

* T T G A C A

*

T A

OR

* T T G A C

* A *
T A A

T *

OR

*

*

*

T A *

*

* T

Figure 5: The contact portion of the theory. There are four possibilities for both the
minus 35 and minus 10 portions of the theory. A \*" matches any nucleotide.
The conformation portion of the theory is too spread out to display pictorially.
In this run, the program exhibited the second behavioral extreme discussed in Section 1;
it entirely removed groups of rules and then tried to build new rules to replace what was
lost. The minus 10 and conformation rules have essentially been removed, and new rules
have been added to the minus 35 group. These new minus 35 rules contain the condition
p-12=t previously found in the minus 10 group and the condition p-44=a previously found
in the conformation group.
Either's behavior in this example is a direct result of its lack of exibility of representation and exibility of structure. It is dicult to transform the minus 10 and conformation
rules into something useful in their initial representation using Either's locally-acting operators. Either handles this by dropping these sets of rules, losing their knowledge, and
attempting to rediscover the lost knowledge empirically. The end result of this loss of
knowledge is lower than optimal accuracy shown later in Section 5.

3.4

Kbann

in the Promoter Domain

Figure 9, modeled after a figure by Towell and Shavlik (1994), shows the setup of a Kbann
network for the promoter theory. Each slot along the bottom represents one nucleotide
in the DNA sequence. Each node at the first level up from the bottom embodies a single
domain rule, and higher levels encode groups of rules with the final concept at the top. The
links shown in the figure are the ones that are initially high-weighted. The net is next filled
out to be fully connected with low-weight links. Backpropagation is then applied to refine
the network's weights.
422

fiRerepresenting and Restructuring Domain Theories

A DNA segment fragment:
:::

p-38=g, p-37=c, p-36=t, p-35=t, p-34=g, p-33=a, p-32=c, p-31=t, p-30=t

:::

The minus 35 group of rules and corresponding constructed features:
minus 35 :- p-37=c, p-36=t, p-35=t, p-34=g, p-33=a, p-32=c.
minus 35 :p-36=t, p-35=t, p-34=g,
p-32=c, p-31=a.
minus 35 :p-36=t, p-35=t, p-34=g, p-33=a, p-32=c, p-31=a.
minus 35 :p-36=t, p-35=t, p-34=g, p-33=a, p-32=c.

feat minus35 A = 1
feat minus35 B = 0
feat minus35 C = 0
feat minus35 D = 1

feat minus35 all = (feat minus35 A _ feat minus35 B _ feat minus35 C _ feat minus35 D) = 1

Figure 6: An example of feature construction in a Miro-like system. The constructed
features for the first and fourth rules in the minus 35 group are true (value = 1)
because the DNA segment matches these rules. The constructed feature for the
entire group, feat minus35 all, is true because the four minus 35 rules are joined
by disjunction.
feat_minus10_all
0

1
promoter

feat_conf_B
0

1

feat_minus35_D
0
non-promoter

promoter
1

promoter

Figure 7: An example theory created by a Miro-like system. A DNA segment is recognized
as a promoter if it matches any of the minus 10 rules, the second conformation
rule, or the fourth minus 35 rule.
The neural net representation is more appropriate for this domain than the propositional
logic representation of the initial theory. It allows for a measurement of partial match by
weighting the links in such a way that a subset of a rule's conditions are enough to surpass a
node's threshold. It also allows for variable weightings of different parts of the theory; therefore, more predictive nucleotides can be weighted more heavily, and only slightly predictive
nucleotides can be weighted less heavily. Kbann has only limited exibility of structure.
Because the refined network is the result of a series of incremental modifications in the
initial network, a fundamental restructuring of the theory it embodies is unlikely. Kbann
423

fiDonoho & Rendell

promoter :- contact, conformation.
contact

:- minus_35, minus_10.

minus_35
minus_35
minus_35
minus_35
minus_35
minus_35

::::::-

p-35=t,
p-36=t,
p-36=t,
p-34=g,
p-34=g,
p-35=t,

p-34=g.
p-33=a, p-32=c.
p-32=c, p-50=c.
p-12=t.
p-44=a.
p-47=g.

minus_10 :- true.
conformation :- true.

Figure 8: A revised theory produce by Either.
promoter

contact

conformation
minus_35

p-50

minus_10

DNA Sequence

p+7

Figure 9: The setup of a Kbann network for the promoter theory.
is limited to finding the best network with the same fundamental structure imposed on it
by the initial theory.
One of Kbann's advantages is that it uses a standard learning algorithm as its foundation. Backpropagation has been widely used and consequently improved by previous
researchers. Theory refinement tools that are built from the ground up or use a standard
tool only tangentially suffer from having to invent their own methods of handling standard
problems such as overfit, noisy data, etc. A wealth of neural net experience and resources
is available to the Kbann user; as neural net technology advances, Kbann technology will
passively advance with it.
424

fiRerepresenting and Restructuring Domain Theories

3.5

Neither-MofN

in the Promoter Domain

refines the initial promoter theory not only by dropping and adding conditions and rules but also by allowing conjunctive rules to be true if only a subset of their
conditions are true. We ran Neither-MofN with a randomly selected training set of size
80, and Figure 10 shows a refined promoter theory produced. The theory expressed here
with 9 M-of-N rules would require 30 rules using propositional logic, the initial theory's
representation. More importantly, it is unclear how any system using the initial representation would reach the 30-rule theory from the initial theory. Thus the M-of-N representation
adopted not only allows for the concise expression of the final theory but also facilitates the
refinement process.
Neither-MofN

promoter :- 2 of ( contact, conformation ).
contact

:- 2 of ( minus_35, minus_10 ).

minus_35 :- 2 of ( p-36=t, p-35=t, p-34=g,
p-32=c, p-31=a ).
minus_35 :- 5 of ( p-36=t, p-35=t, p-34=g, p-33=a, p-32=c
).
minus_10
minus_10
minus_10
minus_10

::::-

2
2
6
2

of
of
of
of

(
(
p-13=t,
( p-14=t, p-13=a,
(
p-13=t,

p-12=t, p-11=a,
p-12=a,
p-10=a,
p-12=t, p-11=a, p-10=a, p-9=t
p-12=a,
p-10=a,

p-7=t
p-8=t

).
).
).
p-34=g ).

conformation :- true.

Figure 10: A revised theory produced by Neither-MofN.
Neither-MofN displays exibility of representation by allowing an M-of-N interpretation of the original propositional logic, but it does not allow for as fine-grained refinement
as Kbann. Both allow for a measure of partial match, but Kbann could weight more
predictive features more heavily. For example, in the minus 35 rules, perhaps p-36=t is
more predictive of a DNA segment being a promoter than p-34=g and therefore should be
weighted more heavily. Neither-MofN simply counts the number of true conditions in a
rule; therefore, every condition is weighted equally. Kbann's fine-grained weighting may be
needed in some domains and not in others. It may actually be detrimental in some domains.
An advanced theory revision system should offer a range of representations.
Like Kbann, Neither-MofN has only limited exibility of structure. The refined
theory is reached through a series of small, incremental modifications in the initial theory
precluding a fundamental restructuring. Neither-MofN is therefore limited to finding the
best theory with the same fundamental structure as the initial theory.

4. Theory-Guided Constructive Induction

In the first half of this section we present guidelines for theory-guided constructive induction
that summarize the work discussed in Sections 2 and 3. The remainder of the section
425

fiDonoho & Rendell

presents an algorithm that instantiates these guidelines. We evaluate the algorithm in
Section 5.

4.1 Guidelines

The following guidelines are a synthesis of the strengths of the previously discussed related
work.
 As in Miro, new features should be constructed using components of the domain
theory. These new features are combinations of existing features, and a final theory is
created by applying a standard induction algorithm to the training examples described
using the new features. This allows knowledge to be gleaned from the initial theory
without forcing the final theory to conform to the initial theory's backbone structure.
It takes full advantage of the domain theory by building high-level features from the
original low-level features. It also takes advantage of a strength of standard induction
| building concise theories having high predictive accuracy when the target concept
can be concisely expressed using the given features.
 As in Either, the constructed features should be modifiable by various operators
that act locally, such as adding or dropping conjuncts from a constructed feature.
 As in Kbann and Neither-MofN, the representation of the constructed features
need not be the exact representation in which the initial theory is given. For example,
the initial theory may be given as a set of rules written in propositional logic. A
new feature can be constructed for each rule, but it need not be a boolean feature
telling whether all the conditions are met; for example it may be a count of how
many conditions of that rule are met. This allows the final theory to be formed and
expressed in a representation that is more suitable than the representation of the
initial theory.
 Like Grendel, a complete system should offer a library of interpreters allowing the
domain theory to be translated into a range of representations with differing adaptability. One interpreter might emulate Miro strictly translating a domain theory
into boolean constructed features. Another interpreter might construct features that
count the number of satisfied conditions of the corresponding component of the domain theory thus providing a measure of partial match. Still another interpreter
might construct features that are weighted sums of the satisfied conditions. The
weights could be refined empirically by examining a set of training examples. Thus
the most appropriate amount of expressive power can be applied to a given problem
without incurring unnecessary expense.

4.2 A Specific Interpreter

This section describes an algorithm which is a limited instantiation of the guidelines just
described. The algorithm is intended as a demonstration of the distillation and synthesis
of the principles embodied in previous landmark systems. It contains a main module,
Tgci described in Figure 12, and a specific interpreter, Tgci1 described in Figure 11.
The main module Tgci redescribes the training and testing examples by calling Tgci1
426

fiRerepresenting and Restructuring Domain Theories

and then applies C4.5 to the redescribed examples (just as Miro applied the candidate
elimination algorithm to examples after redescribing them). Tgci1 can be viewed as a
single interpreter from a potential Grendel-like toolbox. It takes as input a single example
and a domain theory expressed as an AND/OR tree such as the one shown in Figure 13.
It returns a new vector of features for that example that measure the partial match of the
example to the theory. Thus it creates new features from components of the domain theory
as in Miro, but because it measures partial match, it allows exibility in representing
the information contained in the initial theory as in Kbann and Neither-MofN. One
aspect of the guidelines in 4.1 that does not appear in this algorithm is Either's locally
acting operators such as adding and dropping conditions from a portion of the theory.
The following two paragraphs explain in more detail the workings of Tgci1 and Tgci
respectively.
Given: An example E and a domain theory with root node R. The domain
theory is an AND/OR/NOT tree in which the leaves are conditions which can
be tested to be true or false.
Return: A pair P = (F; F ) where F is the top feature measuring the partial
match of E to the whole domain theory, and F is a vector of new features measuring the partial match of E to various parts and subparts of the domain theory.

1. If R is a directly testable condition, return P=(1,<>) if R is true for E
and P=(-1,<>) if R is false for E .
2. n = the number of children of R
3. For each child Rj of R, call Tgci1(Rj ,E ) and store the respective results
in Pj = (Fj ; Fj ).
4. If the major operator of R is OR, Fnew = MAX (Fj ).
Return P = (Fnew ; concatenate(<Fnew >; F1; F2; :::; Fn)).
P
5. If the major operator of R is AND, Fnew = ( nj=1 Fj )=n.
Return P = (Fnew ; concatenate(<Fnew >; F1; F2; :::; Fn)).
6. If the major operator of R is NOT, Fnew = ,1  F1 .
Return P = (Fnew ; F1).
Figure 11: The Tgci1 algorithm
The Tgci1 algorithm, given in Figure 11, is recursive. Its inputs are an example E and
a domain theory with root node R. It ultimately returns a redescription of E in the form
of a vector of new features F . It also returns a value F called the top feature which is used
in intermediate calculations described below. The base case occurs if the domain theory is
a single leaf node (i.e., R is a simple condition). In this case (Line 1), Tgci1 returns the
top feature 1 if the condition is true and -1 if the condition is false. No new features are
returned in the base case because they would simply duplicate the existing features. If the
427

fiDonoho & Rendell

domain theory is not a single leaf node, Tgci1 recursively calls itself on each of R's children
(Line 3). When a child of R, Rj , is processed, it returns a vector of new features Fj (which
measures the partial match of the example to the j th child of R and its various subparts).
It also returns the top feature Fj which is included in Fj but is marked as special because it
measures the partial match of the example to the whole of the j th child of R. If there are n
children, the result of Line 3 is n vectors of new features, F1 to Fn , and n top features, F1
to Fn . If the operator at node R is OR (Line 4), then Fnew , the new feature created for that
node, is the maximum of Fj . Thus Fnew measures how closely the best of R's children come
to having its conditions met by the example. The vector of new features returned in this
case is a concatenation of Fnew and all the new features from R's children. If the operator
at node R is AND (Line 5), then Fnew is the average of Fj . Thus Fnew measures how closely
all of R's children as a group come to having their conditions met by the example. The
vector of new features returned in this case is again a concatenation of Fnew and all the new
features from R's children. If the operator at node R is NOT (Line 6), R should only have
one child, and Fnew is F1 negated. Thus Fnew measures the extent to which the conditions
of R's child are not met by the example.
Given: A set of training examples Etrain , a set of testing examples Etest , and a
domain theory with root node R.
Return: Learned concept and accuracy on testing examples.
1. For each example Ei 2 Etrain , call Tgci1(R,Ei) which returns Pi =
(Fi ; Fi). Etrain,new = fFig.
2. For each example Ei 2 Etest, call Tgci1(R,Ei). which returns Pi =
(Fi ; Fi). Etest,new = fFi g.
3. Call C4.5 with training examples Etrain,new and testing examples
Etest,new . Return decision tree and accuracy on Etest,new .
Figure 12: The Tgci algorithm
If Tgci1 is called twice with two different examples but with the same domain theory,
the two vectors of new features will be the same size. Furthermore, corresponding features
measure the match of corresponding parts of the domain theory. The Tgci main module
in Figure 12 takes advantage of this by creating redescribed example sets from the input
example sets. Line 1 redescribes each example in the training set producing a new training
set. Line 2 does the same for the testing set. Line 3 runs the standard induction program
C4.5 on these redescribed example sets. The returned decision tree can be easily interpreted
by examining which new features were used and what part of the domain theory they
correspond to.

4.3

Tgci1

Examples

As an example of how the Tgci1 interpreter works, consider the toy theory shown in
Figure 13. Tgci1 redescribes the input example by constructing a new feature for each node
428

fiRerepresenting and Restructuring Domain Theories

in the input theory. Consider the situation where the input example matches conditions A,
B, and D but not C and E. When Tgci1 evaluates the children of Node 6, it gets the values
F1 = 1, F2 = 1, F3 = ,1, F4 = 1, and F5 = ,1. Since the operator at Node 6 is AND, Fnew
is the average of the values received from the children, 0.20 ((1 + 1 + (,1) + 1 + (,1))=5 =
0:20). Likewise, if condition G matchs but not F and H, Fnew for Node 5 will have the value
0.33 (,1  ((1 + (,1) + (,1))=3)) because two of three matching conditions at Node 7 give
the value ,0:33, and this is negated by the NOT at Node 5. Since Node 2 is a disjunction,
its new feature measures the best partial match of its two children and has the value 0.33
(MAX(0.20,0.33)), and so on.
1
3

NOT
2
4
5

NOT
6

A B C D E

7

F G H

8

I J K

9

L M N O

Figure 13: An example theory in the form of an AND/OR tree that might be used by the
interpreter to generate constructed features.
Figure 14 shows how Tgci1 redescribes a particular DNA segment using the minus 35
rules of the promoter theory. A partial DNA segment is shown along with the four minus 35
rules and the new feature constructed for each rule (We have given the new features names
here to simplify our illustration). For the first rule, four of the six nucleotides match; therefore, for that DNA segment feat minus35 A has the value 0.33 ((1+1+1+1+(,1)+(,1))=6).
For the second rule, four of the five nucleotides match; therefore, feat minus35 B has
the value 0.60. Because these and the other two minus 35 rules are joined by disjunction in the original domain theory, feat minus35 all, the new feature constructed for this
group, takes the maximum value of its four children; therefore, feat minus35 all has the
value 0.60 because feat minus35 B has the value 0.60, the highest in the group. Intuitively, feat minus35 all represents the best partial match of this grouping | the extent
to which the disjunction is partially satisfied. The results of running Tgci1 on each DNA
sequence is a set of redescribed training examples. Each redescribed example has a value for
feat minus35 A through feat minus35 D, feat minus35 all, and all other nodes in the promoter domain theory. The training set is essentially redescribed using a new feature vector
derived from information contained in the domain theory. In this form, any off-the-shelf
induction program can be applied to the new example set.
Anomalous situations can be created in which Tgci1 gives a \good score" to a seemingly
bad example and a bad score to a good example. Situations can also be created where
logically equivalent theories give different scores for a single example. These occur because
429

fiDonoho & Rendell

A DNA segment fragment:
:::

p-38=g, p-37=c, p-36=t, p-35=t, p-34=g, p-33=c, p-32=a, p-31=a, p-30=t

:::

The minus 35 group of rules and corresponding constructed features:
minus 35 :- p-37=c, p-36=t, p-35=t, p-34=g, p-33=a, p-32=c.
minus 35 :p-36=t, p-35=t, p-34=g,
p-32=c, p-31=a.
minus 35 :p-36=t, p-35=t, p-34=g, p-33=a, p-32=c, p-31=a.
minus 35 :p-36=t, p-35=t, p-34=g, p-33=a, p-32=c.

feat minus35 A = 0.33
feat minus35 B = 0.60
feat minus35 C = 0.33
feat minus35 D = 0.20

feat minus35 all = max(feat minus35 A, feat minus35 B, feat minus35 C, feat minus35 D) = 0.60

Figure 14: An example of how Tgci1 generates constructed features from a portion of the
promoter domain theory and a DNA segment. Four of the conditions in the first
minus 35 rule match the DNA segment; therefore, the constructed feature for
that rule has the value 0.33 ((1 + 1 + 1 + 1 + (,1) + (,1))=6). Feat minus35 all,
the new feature for the entire minus 35 group takes the maximum value of its
children thus embodying the best partial match of the group.
is biased to favor situations where more matched conditions of an AND is desirable,
but more matched conditions of an OR is not necessarily better. Eliminating these anomalies
would remove this bias.
Tgci1

5. Experiments and Analysis
This section presents the results of applying theory-guided constructive induction to three
domains: the promoter domain (Harley et al., 1990), the primate splice-junction domain (Noordewier, Shavlik, & Towell, 1992), and the gene identification domain (Craven & Shavlik,
1995). In each case the Tgci1 interpreter was applied to the domain's theory and examples
in order to redescribe the examples using new features. Then C4.5 (Quinlan, 1993) was
applied to the redescribed examples.

5.1 The Promoter Domain
Figure 15 shows a learning curve for theory-guided constructive induction in the promoter
domain accompanied by curves for Either, LabyrinthK , Kbann, and Neither-MofN.
Following the methodology described by Towell and Shavlik [1994], the set of 106 examples
was randomly divided into a training set of size 80 and a testing set of size 26. A learning
curve was created by training on subsets of the training set of size 8, 16, 24, : : : 72, 80,
using the 26 examples for testing. The curves for Either, LabyrinthK , and Kbann were
taken from Ourston and Mooney (1990), Thompson, Langley, and Iba (1991), and Towell
430

fiRerepresenting and Restructuring Domain Theories

and Shavlik (1994) respectively and were obtained by a similar methodology1 . The curve
forTgci is the average of 50 independent random data partitions and is given along with 95%
confidence ranges. The Neither-MofN program was obtained from Ray Mooney's group
and was used in generating the Neither-MofN curve using the same 50 data partitions
as were used for Tgci2.
42.5
40

EITHER
Labyrinth-k
NEITHER-MofN
KBANN
TGCI
95% confidence of NEITHER-MofN
95% confidence of TGCI

37.5
35
32.5
30
27.5
% Error

25
22.5
20
17.5
15
12.5
10
7.5
5
2.5
0
0

5

10 15 20 25 30 35 40 45 50 55 60 65 70 75 80
Size of Training Sample

Figure 15: Learning curves for theory-guided constructive induction and other systems in
the promoter domain.
Tgci showed improvement over Either and LabyrinthK for all portions of the curve
and also performed better than Kbann and Neither-MofN for all except the smallest training sets. Confidence intervals were not available for Either, LabyrinthK , and

1.

used a testing set of size 25 and did not use the conformation portion of the domain theory. The
testing set in LabyrinthK always consisted of 13 promoters and 13 non-promoters.
2. Baffes and Mooney (1993) report a slightly better learning curve for Neither-MofN than we obtained,
but after communication with Paul Baffes, we think the difference is caused by the random selection of
data partitions.
Either

431

fiDonoho & Rendell

Kbann, but in a pairwise comparison with Neither-MofN, the improvement of Tgci was
significant at the 0.0005 level of confidence for training sets of size 48 and larger.

Structure of Initial Promoter Theory

100% of
first
conf.
rule

100% of
first
minus_35
rule

100% of
second
minus_35
rule

100% of
third
minus_35
rule

100% of
fourth
minus_35
rule

100% of
first
minus_10
rule

100% of
second
minus_10
rule

100% of
third
minus_10
rule

100% of
second
conf.
rule

100% of
third
conf.
rule

100% of
fourth
conf.
rule

100% of
fourth
minus_10
rule

Structure of Revised Promoter Theory

>20% of
second
minus_35
rule

>33% of
first
minus_10
rule

>33% of
second
minus_10
rule

>33% of
third
minus_10
rule

>33% of
fourth
minus_10
rule

Figure 16: The revised theory produced by theory-guided constructive induction has borrowed substructures from the initial theory, but as a whole has not been restricted by its structure.
Figure 16 compares the initial promoter theory with a theory created by Tgci. Reasons
for Tgci's improvement can be inferred from this figure. Tgci has extracted the components of the original theory that are most helpful and restructured them into a more
concise theory. Neither Kbann nor Neither-MofN facilitates this radical extraction and
restructuring. As seen in the leaf nodes, the new theory also measures the partial match
of an example to components of the original theory. This aspect is similar in Kbann and
Neither-MofN.
Part of Tgci's improvement over Kbann and Neither-MofN may be due to a knowledge/bias conict in the latter two systems, a situation where revision biases conict with
knowledge in such a way as to undo some of the knowledge's benefits. This can occur
whenever detailed knowledge is opened up to revision using a set of examples. The revision
is not guided only by the examples but rather by the examples as interpreted by a set
432

fiRerepresenting and Restructuring Domain Theories

of algorithmic biases. Biases that are useful in the absence of knowledge may undo good
knowledge when improperly applied. Yet these biases developed and perfected for pure induction are often unquestioningly applied to the revision of theories. The biases governing
the dropping of conditions in Neither-MofN and reweighting conditions in Kbann may
be neutralizing the promoter theory's potential. We speculate this because we conducted
some experiments that allowed bias-guided dropping and adding of conditions within Tgci.
We found that these techniques actually reduced accuracy in this domain.
45
42.5
40
37.5
c4.5
backpropagation
KBANN
TGCI
95% confidence of TGCI
domain theory

35
32.5
% Error

30
27.5
25
22.5
20
17.5
15
12.5
10
7.5
0

20

40

60

80

100

120

140

160

180

200

Size of Training Sample

Figure 17: Learning curves for Tgci and other systems in the primate splice-junction domain.

5.2 The Primate Splice-junction Domain

The primate splice-junction domain (Noordewier et al., 1992) involves analyzing a DNA
sequence and identifying boundaries between introns and exons. Exons are the parts of a
DNA sequence kept after splicing; introns are spliced out. The task then involves placing a
433

fiDonoho & Rendell

given boundary into one of three classes: an intron/exon boundary, an exon/intron boundary, or neither. An imperfect domain theory is available which has a 39.0% error rate on
the entire set of available examples.
Figure 17 shows learning curves for C4.5, backpropagation, Kbann, and Tgci in the
primate splice-junction domain. The results for Kbann and backpropagation were taken
from Towell and Shavlik (1994). The curves for plain C4.5 and the Tgci algorithm were
created by training on sets of size 10,20,30,...90,100,120,...200 and testing on a set of size
800. The curves for C4.5 and Tgci are the average of 40 independent data partitions.
No comparison was made with Neither-MofN because the implementation we obtained
could handle only two-class concepts. For training sets larger than 200, Kbann, Tgci, and
backpropagation all performed similarly.
The accuracy of Tgci appears slightly worse than that of Kbann but perhaps not significantly. Kbann's advantage over Tgci is its ability to assign fine-grained weightings
to individual parts of a domain theory. Tgci's advantage over Kbann is its ability to
more easily restructure the information contained in a domain theory. We speculate that
Kbann's capability to assign fine-grained weights outweighted its somewhat rigid structuring of this domain theory. Theory-guided constructive induction has an advantage of
speed over Kbann because C4.5, its underlying learner, runs much more quickly than
backpropagation, Kbann's underlying learning algorithm.

5.3 The Gene Identification Domain
The gene identification domain (Craven & Shavlik, 1995) involves classifying a given DNA
segment as a coding sequence (one that codes a protein) or a non-coding sequence. No
domain theory was available in the gene identification domain; therefore, we created an
artificial domain theory using the information that organisms may favor certain nucleotide
triplets over others in gene coding. The domain theory embodies the knowledge that a DNA
segment is likely to be a gene coding segment if its triplets are coding-favoring triplets or if
its triplets are not noncoding-favoring triplets. The decision of which triplets were codingfavoring, which were noncoding-favoring, and which favored neither, was made empirically
by analyzing the makeup of 2500 coding and 2500 noncoding sequences. The specific artificial domain theory used is described in Online Appendix 1.
Figure 18 shows learning curves for C4.5 and Tgci in the gene identification domain.
The original domain theory yields 31.5% error. The curves were created by training on
example sets of size 50,200,400,...2000 and testing on a separate example set of size 1000.
The curves are the average of 40 independent data partitions.
Only a partial curve is given for Neither-MofN because it became prohibitively slow
for larger training sets. In the promoter domain where training sets were smaller than 100,
Tgci and Neither-MofN ran at comparable speeds (approximately 10 seconds on a Sun4
workstation). In this domain Tgci ran in approximately 2 minutes for larger training sets.
Neither-MofN took 21 times as long as Tgci on training sets of size 400, 69 times as
long for size 800, and 144 times as long for size 1200. Consequently, Neither-MofN's
curve only extends to 1200 and only represents five randomly selected data partitions. For
these reasons, a solid comparison of Neither-MofN and Tgci cannot be made from these
curves, but it appears that Tgci's accuracy is slightly better. We speculate that Neither434

fiRerepresenting and Restructuring Domain Theories

45
42.5
40

TGCI
95% confidence of TGCI
C4.5
NEITHER-MofN
domain theory

37.5

% Error

35
32.5
30
27.5
25
22.5
20
0

200

400

600

800

1000 1200 1400 1600 1800 2000

Number training examples

Figure 18: Learning curves for Tgci and other systems in the gene identification domain.
's slightly lower accuracy is partially due to the fact that it revises the theory to
correctly classify all the training examples. The result is a theory which likely overfits the
training examples. Tgci does not need to explicitly avoid overfit because this is handled
by its underlying learner.
MofN

5.4 Summary of Experiments
Our goal in this paper has not been to present a new technique but rather to understand
the behavior of landmark systems, distill their strengths, and synthesize them into a simple
system, Tgci. The evaluation of this algorithm shows that its accuracy roughly matches or
exceeds that of its predecessors. In the promoter domain, Tgci showed sizable improvement
over many published results. In the splice-junction domain, Tgci narrowly falls short of
Kbann's accuracy. In the gene identification domain, Tgci outperforms Neither-MofN.
In all these domains Tgci greatly improves on the original theory alone and C4.5 alone.
435

fiDonoho & Rendell

is faster than its closest competitors. Tgci runs as much as 100 times faster than
on large datasets. A strict quantitative comparison of the speeds of Tgci
and Kbann was not made because 1) backpropagation is known to be much slower than
decision trees (Mooney, Shavlik, Towell, & Gove, 1989), 2) Kbann uses multiple hidden
layers which makes its training time even longer (Towell & Shavlik, 1994), and 3) Towell
and Shavlik (1994) point out that each run of Kbann must be made multiple times with
different initial random weights, whereas a single run of Tgci is sucient.
Overall, our experiments support two claims of this paper: First, the accuracy of Tgci
substantiates our delineation of system strengths in terms of exible theory representation
and exible theory structure, since this characterization is the basis for this algorithm's
design. Second, Tgci's combination of speed and accuracy suggest that unnecessary computational complexity can be avoided in synthesizing the strengths of landmark systems.
In the following section we take a closer look at the strengths of theory-guided constructive
induction.
Tgci

Neither-MofN

6. Discussion of Strengths
Below a number of strengths of theory-guided constructive induction are discussed within
the context of the Tgci algorithm used in our experiments.

6.1 Flexible Representation

As discussed in Section 1, for many domains the representation most appropriate for an
initial theory may not be most appropriate for a refined theory. Because theory-guided constructive induction allows the translation of the initial theory into a different representation,
it can accommodate such domains. In the experiments in this paper a representation was
needed which allowed for a measurement of partial match to the domain theory. Tgci1
accomplished this by simply counting the matching features and propagating this information up the theory appropriately. Either and LabyrinthK do not easily afford this
measure of partial match and therefore are more appropriate for problems in which the best
representation of the final theory is the same as that of the initial theory. Kbann allows
a finer-grained measurement of partial match than both Neither-MofN and our work,
but a price is paid in computational complexity. The theory-guided constructive induction framework allows for a variety of potential tools with varying degrees of granularity of
partial match, although just one tool is used in our experiments.

6.2 Flexible Structure

As discussed in Section 2.5, a strength of existing induction programs is fashioning a concise
and highly predictive description of a concept when the target concept can be concisely
described with the given features. Consequently, the value of a domain theory lies not in its
overall structure. If the feature language is sucient, any induction program can build a
good overall theory structure. Instead, the value of a domain theory lies in the information
it contains about how to redescribe examples using high-level features. These high-level
features facilitate a concise description of the target concept. Systems such as Either and
Neither-MofN that reach a final theory through a series of modifications in the initial
436

fiRerepresenting and Restructuring Domain Theories

theory hope to gain something by keeping the theory's overall structure intact. If the initial
theory is suciently close to an accurate theory, this method works, but often clinging to
the structure hinders full exploitation of the domain theory. Theory-guided constructive
induction provides a means of fully exploiting both the information in the domain theory and
the strengths of existing induction programs. Figure 16 in Section 5.1 gives a comparison of
the structure of the initial promoter theory to the structure of a revised theory produced by
theory-guided constructive induction. Substructures have been borrowed, but the revised
theory as a whole has been restructured.

6.3 Use of Standard Induction as an Underlying Learner

Because theory-guided constructive induction uses a standard induction program as its
underlying learner, it does not need to reinvent solutions to overfit avoidance, multi-class
concepts, noisy data, etc. Overfit avoidance has been widely studied for standard induction,
and many standard techniques exist. Any system which modifies a theory to accommodate
a set of training examples must also address the issue of overfit to the training examples. In
many theory revision systems existing overfit avoidance techniques cannot be easily adapted,
and the problem must be addressed from scratch. Theory-guided constructive induction can
take advantage of the full range of previous work in overfit avoidance for standard induction.
When multiple theory parts are available for multi-class concepts, the interpreter is
run on the multiple theory parts, and the resulting new feature sets are combined. The
primate splice-junction domain presented in Section 5.2 has three classes: intron/exon
boundaries, exon/intron boundaries, and neither. Theories are given for both intron/exon
and exon/intron. Both theories are used to create new features, and then all new features
are concatenated together for learning. Interpreters such as Tgci1 also trivially handle
negation in a domain theory.

6.4 Use of Theory Fragments

Theory-guided constructive induction is not limited to using full domain theories. If only
part of a theory is available, this can be used. To demonstrate this, three experiments
were run in which only fragments of the promoter domain theory were used. In the first
experiment, only the four minus 35 rules were used. Five features were constructed | one
feature for each rule and then an additional feature for the group. Similar experiments were
run for the minus 10 group and the conformation group.
Figure 19 gives learning curves for these three experiments along with curves for the entire theory and for no theory (C4.5 using the original features). Although the conformation
portion of the theory gives no significant improvement over C4.5, both the minus 35 and
minus 10 portions of the theory give significant improvements in performance. Thus even
partial theories and theory fragments can be used by theory-guided constructive induction
to yield sizable performance improvements.
The use of theory fragments should be explored as a means of evaluating the contribution
of different parts of a theory. In Figure 19, the conformation portion of the theory is shown
to yield no improvement. This could signal a knowledge engineer that the knowledge that
should be conveyed through that portion of the theory is not useful to the learner in its
present form.
437

fiDonoho & Rendell

45
C4.5
conformation portion of theory
minus_10 portion of theory
minus_35 portion of theory
whole theory

42.5
40
37.5
35
32.5
30

% Error

27.5
25
22.5
20
17.5
15
12.5
10
7.5
5
2.5
0
0

5

10 15 20 25 30 35 40 45 50 55 60 65 70 75 80
Size of Training Sample

Figure 19: Learning curves for theory-guided constructive induction with only fragments of
the promoter domain theory. The minus 35 portion of the theory, the minus 10
portion of the theory, and the conformation portion of the theory were used
separately in feature construction. Curves are also given for the full theory and
for C4.5 alone for comparison.

6.5 Use of Multiple Theories

Theory-guided constructive induction can use multiple competing and even incompatible
domain theories. If multiple theories exist, theory-guided constructive induction provides
a natural means of integrating them in such a way as to extract the best from all theories.
Tgci1 would be called for each input theory producing new features. Next, all the new
features are simply pooled together and the induction program selects from among them
in fashioning the final theory. This is seen on a very small scale in the promoter domain.
438

fiRerepresenting and Restructuring Domain Theories

% Error

In Figure 4 some minus 35 rules subsume other minus 35 rules. According to the entry in
the UCI Database, this is because \the biological evidence is inconclusive with respect to
the correct specificity." This is handled by simply using all four possibilities, and selection
of the most useful knowledge is left to the induction program.
Tgci could also be used to evaluate the contributions of competing theories just as it was
used to evaluate theory fragments above. A knowledge engineer could use this evaluation
to guide his own revision and synthesis of competing theories.
25
22.5
20
17.5
15
12.5
10
7.5
5
2.5
0

TGCI using C4.5
TGCI using LFC
95% confidence of LFC

5

10 15 20 25 30 35 40 45 50 55 60 65 70 75 80
Size of Training Sample

Figure 20: Theory-guided constructive induction with Lfc and C4.5 as the underlying
learning system. Theory-guided constructive induction can use any inductive
learner as its underlying learning component. Therefore, more sophisticated
underlying induction programs can further improve accuracy.

6.6 Easy Adoption of New Techniques

Since theory-guided constructive induction can use any standard induction method as its
underlying learner, as improvements are made in standard induction, theory-guided constructive induction passively improves. To demonstrate this, tests were also run with Lfc
(Ragavan & Rendell, 1993) as the underlying induction program. Lfc is a decision tree
learner that performs example-based constructive induction by looking ahead at combinations of features. Characteristically, Lfc improves accuracy for a moderate number of
examples. Figure 20 shows the resulting learning curve along with the C4.5 Tgci curve.
Both curves are the average of 50 separate runs with the same data partitions used for each
program. In a pairwise comparison the improvement of Lfc over C4.5 was significant at the
0.025 level of confidence for training sets of size 72 and 80. More sophisticated underlying
induction programs can further improve accuracy.
439

fiDonoho & Rendell

7. Testing the Limits of Tgci
The purpose of this section is to explore the performance of theory-guided constructive
induction on theory revision problems ranging from easy to dicult. In easy problems
the underlying concept embodied in the training and testing examples matches the domain
theory fairly closely; therefore, the examples themselves match the domain theory fairly
closely. In dicult problems the underlying concept embodied in the examples does not
match the domain theory very well so the examples do not either. Although many other
factors determine the diculty of an individual problem, this aspect is an important component and worth exploring. Our experiment in this section is intended to relate ranges of
diculty to the amount of improvement produced by Tgci.
Since a number of factors affect problem diculty we chose that the theory revision
problems for the experiment should all be variations of a single problem. By doing this we
are able to hold all other factors constant and vary the closeness of match to the domain
theory. Because we wanted to avoid totally artificial domains, we chose to start with the
promoter domain and create \new" domains by perverting the example set.
These \new" domains were created by perverting the examples in the original promoter
problem to either more closely match the promoter domain theory or less closely match the
promoter domain theory. Only the positive examples were altered. For example, one domain
was created with 30% fewer matches to the domain theory than the original promoter
domain as follows: Each feature value in a given example was examined to see if it matched
part of the theory. If so, with a 30% probability, it was randomly reassigned a new value
from the set of possible values for that feature. The end result is a set of examples with 30%
fewer matches to the domain theory than the original example set3. For our experiment
new domains such as this were created with 10%, 30%, 60%, and 90% fewer matches.
For some features, multiple values may match the theory because different disjuncts
of the theory specify different values for a single feature. For example, referring back to
Figure 4, feature p-12 matches two of the minus 10 rules if it has the value a and another
two rules if it has the value t. So a single feature might accidentally match one part of a
theory when in fact the example as a whole more closely matches another part of the theory.
For cases such as these, true matches were separated from accidental matches by examining
which part of the theory most clearly matched the example as a whole and expecting a
match from that part of the theory.
New domains that more closely matched the theory were created in a similar manner. For
example, a domain was created with 30% fewer mismatches to the domain theory than the
original promoter domain as follows: Each feature value in a given example was examined
to see if it matched its corresponding part of the theory. If not, with a 30% probability,
it was reassigned a value that matched the theory. The end result is a set of examples in
which 30% of the mismatches with the domain theory are eliminated. For our experiment
new domains such as this were created with 30%, 60%, and 90% fewer mismatches.
Ten different example sets were created for each level of closeness to the domain theory:
10%, 30%, 60%, 90% fewer matches, and 30%, 60%, 90% fewer mismatches. In total, forty
example sets were created which matched the original theory less closely than the original
3. More precisely, there would be slightly more matches than 30% fewer matches because some features
would be randomly reassigned back to their original matching value.

440

fiRerepresenting and Restructuring Domain Theories

55
50
45
40

% Error

35

C4.5
TGCI

30
25
20
15
10
5
0
-100

-80

-60

-40

-20

0

20

40

60

80

100

Closeness to theory

Figure 21: Seven altered promoter domains were created, three that more closely matched
the theory than the original domains and four that less closely matched. A
100 on the x-axis indicates a domain in which the positive examples match the
domain theory 100%. A negative 100 indicates a domain in which any match
of the positive examples to the domain theory is purely chance. The accuracy
of C4.5 and Tgci are plotted for different levels of proximity to the domain
theory.

example set, and thirty example sets were created which matched the original theory more
closely than the original example set. Each of these example sets was tested using a leaveone-out methodology using C4.5 and the Tgci algorithm. The results are summarized in
Figure 21. The x-axis is a measure of theory proximity { closeness of an example set to the
domain theory. \0" on the x-axis indicates no change in the original promoter examples.
\100" on the x-axis means that each positive example exactly matches the domain theory.
\-100" on the x-axis means that any match of a feature value of a positive example to the
441

fiDonoho & Rendell

domain theory is totally by chance4 . Each datapoint in Figure 21 is the result of averaging
the accuracies of the ten example sets for each level of theory proximity (except for the
point at zero which is the accuracy of the exact original promoter examples).
One notable portion of Figure 21 is the section between 0 and 60 on the x-axis. Domains
in this region have a greater than trivial level of mismatch with the domain theory but not
more than moderate mismatch. This is the region of Tgci's best performance. On these
domains, Tgci achieves high accuracy while a standard learner, C4.5, using the original
feature set gives mediocre performance. A second region to examine is between -60 and 0
on the x-axis where the level of mismatch ranges from moderate to extreme. In this region
Tgci's performance falls off but its improvement over the original feature set remains high
as shown in Figure 22 which plots the improvement of Tgci over C4.5. The final two
regions to notice are greater than 60 and less than -60 on the x-axis. As the level of
mismatch between theory and examples becomes trivially small (x-axis greater than 60),
C4.5 is able to pick out the theory's patterns leading to high accuracy that approaches that
of Tgci's. As the level of mismatch becomes extreme (x-axis less than -60) the theory gives
little help in problem-solving resulting in similarly poor accuracy for both methods. In
summary, as shown in Figure 22 for variants of the promoter problem there is a wide range
of theory proximity (centered around the real promoter problem) for which theory-guided
constructive induction yields sizable improvement over standard learners.
20
17.5

error difference

% Error

15
12.5
10
7.5
5
2.5
0
-100

-80

-60

-40

-20

0

20

40

60

80

100

Closeness to theory

Figure 22: The difference in error between C4.5 and Tgci for different levels of proximity
of the example set to the domain theory.

4. The scale 0 to -100 on the left half of the graph may not be directly comparable with the scale 0 to 100
on the right half of the graph since there were not a equal number of matches and mismatches in the
original examples.

442

fiRerepresenting and Restructuring Domain Theories

8. Conclusion
Our goal in this paper has not been just to present another new system, but rather to
study the two qualities exible representation and exible structure. These capabilities are
intended as a frame of reference for analyzing theory-guided systems. These two principles
provide guidelines for purposeful design. Once we had distilled the essence of systems
such as Miro, Kbann, and Neither-MofN, theory-guided constructive induction was
a natural synthesis of their strengths. Our experiments have demonstrated that even a
simple application of the two principles can effectively integrate theory knowledge with
training examples. Yet there is much room for improvement; the two principles could be
quantified and made more precise, and the implementations that proceed from them should
be explored and refined.
Quantifying representational exibility is one step. Section 4 gave three degrees of
exibility: one measured the exact match to a theory, one counted the number of matching
conditions, and one allowed for a weighted sum of the matching conditions. The amount of
exibility should be quantified, and finer-grained degrees of exibility should be explored.
The accuracy in assorted domains should be evaluated as a function of representational
exibility.
Finer-grained structural exibility would be advantageous. We have presented systems
that make small, incremental modifications in a theory as lacking structural exibility. Yet
theory-guided constructive induction falls at the other extreme, perhaps allowing excessive
structural exibility. Fortunately, existing induction tools are capable of fashioning simple
yet highly predictive theory structures when the problem features are suitably high-level.
Nevertheless, approaches should be explored that take advantage of the structure of the
initial theory without being unduly restricted by it.
The strength discussed in Section 6.5 should be given further attention. Although the
promoter domain gives a very small example of synthesizing competing theories, this should
be explored in a domain in which entire competing, inconsistent theories are available such as
synthesizing the knowledge given by multiple experts. The point was made in Section 6.4
that Tgci can use theory fragments to evaluate the contribution of different parts of a
theory. This should also be explored further.
In an exploration of bias in standard induction, Utgoff (1986) refers to biases as ranging
from weak to strong and from incorrect to correct. A strong bias restricts the concepts that
can be represented more than a weak bias thus providing more guidance in learning. But as
a bias becomes stronger, it may also become incorrect by ruling out useful concept descriptions. A similar situation arises in theory revision | a theory representation language that
is inappropriately rigid may impose a strong, incorrect bias on revision. A language that
allows adaptability along too many dimensions may provide too weak a bias. A Grendellike toolbox would allow a theory to be translated into a range of representations with
varying dimensions of adaptability. Utgoff advocates starting with a strong, possibly incorrect bias and shifting to an appropriately weak and correct bias. Similarly, a theory could
be translated into successively more adaptable representations until an appropriate bias is
found. We have implemented only a single tool; many open problems remain along this line
of research.
443

fiDonoho & Rendell

The converse relationship of theory revision and constructive induction warrants further
examination | theory revision uses data to improve a theory; constructive induction can
use theory to improve data to facilitate learning. Since the long-term goal of machine
learning is to use data, inference, and theory to improve any and all of them, we believe
that a consideration of these related methods can be beneficial, particularly because each
research area has some strengths that the other lacks.
An analysis of landmark theory revision and theory-guided learning systems has led
to the two principles exible representation and exible structure. Because theory-guided
constructive induction was based upon these high-level principles, it is simple yet achieves
good accuracy. These principles provide guidelines for future work, yet as discussed above,
the principles themselves are imprecise and call for further exploration.

Acknowledgements
We would like to thank Geoff Towell, Kevin Thompson, Ray Mooney, and Jeff Mahoney for
their assistance in getting the datapoints for Kbann, LabyrinthK , and Either. We would
also like to thank Paul Baffes for making the Neither program available and for advice on
setting the program's parameters. We thank the anonymous reviewers for their constructive
criticism of an earlier draft of this paper. We gratefully acknowledge the support of this
work by a DoD Graduate Fellowship and NSF grant IRI-92-04473.

References
Baffes, P., & Mooney, R. (1993). Symbolic revision of theories with M-of-N rules. In
Proceedings of the 1993 IJCAI.
Bloedorn, E., Michalski, R., & Wnek, J. (1993). Multistrategy constructive induction:
AQ17-MCI. In Proceeding of the second international workshop on multistrategy learning.
Clark, P., & Matwin, S. (1993). Using qualitative models to guide inductive learning. In
Proceedings of the 1993 International Conference on Machine Learning.
Cohen, W. (1992). Compiling prior knowledge into an explicit bias. In Proceedings of the
1992 International Conference on Machine Learning.
Craven, M. W., & Shavlik, J. W. (1995). Investigating the value of a good input representation. Computational Learning Theory and Natural Learning Systems, 3. Forthcoming.
Drastal, G., & Raatz, S. (1989). Empirical results on learning in an abstraction space. In
Proceedings of the 1989 IJCAI.
Dzerisko, S., & Lavrac, N. (1991). Learning relations from noisy examples: An empirical
comparison of LINUS and FOIL. In Proceedings of the 1991 International Conference
on Machine Learning.
444

fiRerepresenting and Restructuring Domain Theories

Feldman, R., Serge, A., & Koppel, M. (1991). Incremental refinement of approximate
domain theories. In Proceedings of the 1991 International Conference on Machine
Learning.
Flann, N., & Dietterich, T. (1989). A study of explanation-based methods for inductive
learning. Machine Learning, 4, 187{226.
Fu, L. M., & Buchanan, B. G. (1985). Learning intermediate concepts in constructing a
hierarchical knowledge base. In Proceedings of the 1985 IJCAI.
Harley, C., Reynolds, R., & Noordewier, M. (1990). Creators of original promoter dataset.
Hirsh, H., & Noordewier, M. (1994). Using background knowledge to improve inductive
learning of DNA sequences. In Tenth IEEE Conference on AI for Applications San
Antonio, TX.
Matheus, C. J., & Rendell, L. A. (1989). Constructive induction on decision trees. In
Proceedings of the 1989 IJCAI.
Michalski, R. S. (1983). A theory and methodology of inductive learning. Artificial Intelligence, 20 (2), 111{161.
Mitchell, T. (1977). Version spaces: A candidate elimination approach to rule learning. In
Proceedings of the 1977 IJCAI.
Mooney, R. J. (1993). Induction over the unexplained: Using overly-general domain theories
to aid concept learning. Machine Learning, 10 (1), 79{110.
Mooney, R. J., Shavlik, J. W., Towell, G. G., & Gove, A. (1989). An experimental comparison of symbolic and connectionist learning algorithms. In Proceedings of the 1989
IJCAI.
Murphy, P., & Pazzani, M. (1991). ID2-of-3: Constructive induction of M-of-N concepts for
discriminators in decision trees. In Proceedings of the 1991 International Conference
on Machine Learning.
Noordewier, M., Shavlik, J., & Towell, G. (1992). Donors of original primate splice-junction
dataset.
Ourston, D., & Mooney, R. (1990). Changing the rules: A comprehensive approach to theory
refinement. In Proceedings of the 1990 National Conference on Artificial Intelligence.
Pagallo, G., & Haussler, D. (1990). Boolean feature discovery in empirical learning. Machine
Learning, 5 (1), 71{99.
Pazzani, M., & Kibler, D. (1992). The utility of knowledge in inductive learning. Machine
Learning, 9 (1), 57{94.
Quinlan, J. R. (1993). C4.5: Programs for Machine Learning. San Mateo, CA: Morgan
Kaufmann.
445

fiDonoho & Rendell

Ragavan, H., & Rendell, L. (1993). Lookahead feature construction for learning hard concepts. In Proceedings of the 1993 International Conference on Machine Learning.
Rumelhart, D. E., Hinton, G. E., & McClelland, J. L. (1986). A general framework for
parallel distributed processing. In Rumelhart, D. E., & McClelland, J. L. (Eds.),
Parallel Distributed Processing: Explorations in the Microarchitecture of Cognition,
Volume I. Cambridge, MA: MIT Press.
Schlimmer, J. C. (1987). Learning and representation change. In Kaufmann, M. (Ed.),
Proceedings of the 1987 National Conference on Artificial Intelligence.
Thompson, K., Langley, P., & Iba, W. (1991). Using background knowledge in concept
formation. In Proceedings of the 1991 International Conference on Machine Learning.
Towell, G., & Shavlik, J. (1994). Knowledge-based artificial neural networks. Artificial
Intelligence, 70, 119{165.
Towell, G., Shavlik, J., & Noordeweir, M. (1990). Refinement of approximately correct
domain theories by knowledge-based neural networks. In Proceedings of the 1990
National Conference on Artificial Intelligence.
Utgoff, P. E. (1986). Shift of bias for inductive concept learning. In Michalski, Carbonell,
& Mitchell (Eds.), Machine Learning, Vol. 2, chap. 5, pp. 107{148. San Mateo, CA:
Morgan Kaufmann.
Wogulis, J. (1991). Revising relational domain theories. In Proceedings of the 1991 International Conference on Machine Learning.

446

fiJournal of Artificial Intelligence Research 2 (1994) 1-32

Submitted 4/94; published 8/94

A System for Induction of Oblique Decision Trees
Sreerama K. Murthy
Simon Kasif
Steven Salzberg

Department of Computer Science
Johns Hopkins University, Baltimore, MD 21218 USA

murthy@cs.jhu.edu
kasif@cs.jhu.edu
salzberg@cs.jhu.edu

Abstract

This article describes a new system for induction of oblique decision trees. This system,
OC1, combines deterministic hill-climbing with two forms of randomization to find a good
oblique split (in the form of a hyperplane) at each node of a decision tree. Oblique decision
tree methods are tuned especially for domains in which the attributes are numeric, although
they can be adapted to symbolic or mixed symbolic/numeric attributes. We present extensive empirical studies, using both real and artificial data, that analyze OC1's ability to
construct oblique trees that are smaller and more accurate than their axis-parallel counterparts. We also examine the benefits of randomization for the construction of oblique
decision trees.

1. Introduction
Current data collection technology provides a unique challenge and opportunity for automated machine learning techniques. The advent of major scientific projects such as the
Human Genome Project, the Hubble Space Telescope, and the human brain mapping initiative are generating enormous amounts of data on a daily basis. These streams of data
require automated methods to analyze, filter, and classify them before presenting them in
digested form to a domain scientist. Decision trees are a particularly useful tool in this context because they perform classification by a sequence of simple, easy-to-understand tests
whose semantics is intuitively clear to domain experts. Decision trees have been used for
classification and other tasks since the 1960s (Moret, 1982; Safavin & Landgrebe, 1991). In
the 1980's, Breiman et al.'s book on classification and regression trees (CART) and Quinlan's work on ID3 (Quinlan, 1983, 1986) provided the foundations for what has become a
large body of research on one of the central techniques of experimental machine learning.
Many variants of decision tree (DT) algorithms have been introduced in the last decade.
Much of this work has concentrated on decision trees in which each node checks the value
of a single attribute (Breiman, Friedman, Olshen, & Stone, 1984; Quinlan, 1986, 1993a).
Quinlan initially proposed decision trees for classification in domains with symbolic-valued
attributes (1986), and later extended them to numeric domains (1987). When the attributes
are numeric, the tests have the form xi > k, where xi is one of the attributes of an example
and k is a constant. This class of decision trees may be called axis-parallel, because the tests
at each node are equivalent to axis-parallel hyperplanes in the attribute space. An example
of such a decision tree is given in Figure 1, which shows both a tree and the partitioning it
creates in a 2-D attribute space.

c 1994 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiFigure 1: The left side of the figure shows a simple axis-parallel tree that uses two attributes.
The right side shows the partitioning that this tree creates in the attribute space.
Researchers have also studied decision trees in which the test at a node uses boolean
combinations of attributes (Pagallo, 1990; Pagallo & Haussler, 1990; Sahami, 1993) and
linear combinations of attributes (see Section 2). Different methods for measuring the
goodness of decision tree nodes, as well as techniques for pruning a tree to reduce overfitting
and increase accuracy have also been explored, and will be discussed in later sections.
In this paper, we examine decision trees that test a linear combination of the attributes
at each internal node. More precisely, let an example take the form X = x1 ; x2; : : :; xd; Cj
where Cj is a class label and the xi 's are real-valued attributes.1 The test at each node will
then have the form:
d
X
ai xi + ad+1 > 0
(1)
i=1

where a1 ; : : :; ad+1 are real-valued coecients. Because these tests are equivalent to hyperplanes at an oblique orientation to the axes, we call this class of decision trees oblique
decision trees. (Trees of this form have also been called \multivariate" (Brodley & Utgoff,
1994). We prefer the term \oblique" because \multivariate" includes non-linear combinations of the variables, i.e., curved surfaces. Our trees contain only linear tests.) It is clear
that these are simply a more general form of axis-parallel trees, since by setting ai = 0
for all coecients but one, the test in Eq. 1 becomes the familiar univariate test. Note
that oblique decision trees produce polygonal (polyhedral) partitionings of the attribute
space, while axis-parallel trees produce partitionings in the form of hyper-rectangles that
are parallel to the feature axes.
It should be intuitively clear that when the underlying concept is defined by a polygonal space partitioning, it is preferable to use oblique decision trees for classification. For
example, there exist many domains in which one or two oblique hyperplanes will be the
best model to use for classification. In such domains, axis-parallel methods will have to ap1. The constraint that x1 ; : : : ; xd are real-valued does not necessarily restrict oblique decision trees to
numeric domains. Several researchers have studied the problem of converting symbolic (unordered)
domains to numeric (ordered) domains and vice versa; e.g., (Breiman et al., 1984; Hampson & Volper,
1986; Utgoff & Brodley, 1990; Van de Merckt, 1992, 1993). To keep the discussion simple, however, we
will assume that all attributes have numeric values.

2

fiFigure 2: The left side shows a simple 2-D domain in which two oblique hyperplanes define
the classes. The right side shows an approximation of the sort that an axis-parallel
decision tree would have to create to model this domain.
proximate the correct model with a staircase-like structure, while an oblique tree-building
method could capture it with a tree that was both smaller and more accurate.2 Figure 2
gives an illustration.
Breiman et al. first suggested a method for inducing oblique decision trees in 1984. However, there has been very little further research on such trees until relatively recently (Utgoff
& Brodley, 1990; Heath, Kasif, & Salzberg, 1993b; Murthy, Kasif, Salzberg, & Beigel, 1993;
Brodley & Utgoff, 1994). A comparison of existing approaches is given in more detail in
Section 2. The purpose of this study is to review the strengths and weaknesses of existing
methods, to design a system that combines some of the strengths and overcomes the weaknesses, and to evaluate that system empirically and analytically. The main contributions
and conclusions of our study are as follows:

 We have developed a new, randomized algorithm for inducing oblique decision trees

from examples. This algorithm extends the original 1984 work of Breiman et al.
Randomization helps significantly in learning many concepts.

 Our algorithm is fully implemented as an oblique decision tree induction system and
is available over the Internet. The code can be retrieved from Online Appendix 1 of
this paper (or by anonymous ftp from ftp://ftp.cs.jhu.edu/pub/oc1/oc1.tar.Z).

 The randomized hill-climbing algorithm used in OC1 is more ecient than other

existing randomized oblique decision tree methods (described below). In fact, the
current implementation of OC1 guarantees a worst-case running time that is only
O(log n) times greater than the worst-case time for inducing axis-parallel trees (i.e.,
O(dn2 log n) vs. O(dn2)).

 The ability to generate oblique trees often produces very small trees compared to
axis-parallel methods. When the underlying problem requires an oblique split, oblique

2. Note that though a given oblique tree may have fewer leaf nodes than an axis-parallel tree|which is what
we mean by \smaller"|the oblique tree may in some cases be larger in terms of information content,
because of the increased complexity of the tests at each node.

3

fiMurthy, Kasif & Salzberg

trees are also more accurate than axis-parallel trees. Allowing a tree-building system
to use both oblique and axis-parallel splits broadens the range of domains for which
the system should be useful.
The remaining sections of the paper follow this outline: the remainder of this section
briey outlines the general paradigm of decision tree induction, and discusses the complexity issues involved in inducing oblique decision trees. Section 2 briey reviews some
existing techniques for oblique DT induction, outlines some limitations of each approach,
and introduces the OC1 system. Section 3 describes the OC1 system in detail. Section 4
describes experiments that (1) compare the performance of OC1 to that of several other
axis-parallel and oblique decision tree induction methods on a range of real-world datasets
and (2) demonstrate empirically that OC1 significantly benefits from its randomization
methods. In Section 5, we conclude with some discussion of open problems and directions
for further research.

1.1 Top-Down Induction of Decision Trees

Algorithms for inducing decision trees follow an approach described by Quinlan as top-down
induction of decision trees (1986). This can also be called a greedy divide-and-conquer
method. The basic outline is as follows:
1. Begin with a set of examples called the training set, T . If all examples in T belong
to one class, then halt.
2. Consider all tests that divide T into two or more subsets. Score each test according
to how well it splits up the examples.
3. Choose (\greedily") the test that scores the highest.
4. Divide the examples into subsets and run this procedure recursively on each subset.
Quinlan's original model only considered attributes with symbolic values; in that model,
a test at a node splits an attribute into all of its values. Thus a test on an attribute
with three values will have at most three child nodes, one corresponding to each value.
The algorithm considers all possible tests and chooses the one that optimizes a pre-defined
goodness measure. (One could also split symbolic values into two or more subsets of values,
which gives many more choices for how to split the examples.) As we explain next, oblique
decision tree methods cannot consider all tests due to complexity considerations.

1.2 Complexity of Induction of Oblique Decision Trees

One reason for the relatively few papers on the problem of inducing oblique decision trees is
the increased computational complexity of the problem when compared to the axis-parallel
case. There are two important issues that must be addressed. In the context of top-down
decision tree algorithms, we must address the complexity of finding optimal separating
hyperplanes (decision surfaces) for a given node of a decision tree. An optimal hyperplane
will minimize the impurity measure used; e.g., impurity might be measured by the total
number of examples mis-classified. The second issue is the lower bound on the complexity
of finding optimal (e.g., smallest size) trees.
4

fiFigure 3: For n points in d dimensions
(n  d), there are n  d distinct axis-parallel splits,
, 
while there are 2d  nd distinct d-dimensional oblique splits. This shows all distinct
oblique and axis-parallel splits for two specific points in 2-D.
Let us first consider the issue of the complexity of selecting an optimal oblique hyperplane for a single node of a tree. In a domain with
n training instances, each described using
, 
d real-valued attributes, there are at most 2d  nd distinct d-dimensional oblique splits; i.e.,
hyperplanes3 that divide the training instances uniquely into two nonoverlapping subsets.
This upper bound derives from the observation that every subset of size d from the n points
can define a d-dimensional hyperplane, and each such hyperplane can be rotated slightly
in 2d directions to divide the set of d points in all possible ways. Figure 3 illustrates these
upper limits for two points in two dimensions. For axis-parallel splits, there are only n  d
distinct possibilities, and axis-parallel methods such as C4.5 (Quinlan, 1993a) and CART
(Breiman et al., 1984) can exhaustively search for the best split at each node. The problem
of searching for the best oblique split is therefore much more dicult than that of searching
for the best axis-parallel split. In fact, the problem is NP-hard.
More precisely, Heath (1992) proved that the following problem is NP-hard: given a
set of labelled examples, find the hyperplane that minimizes the number of misclassified
examples both above and below the hyperplane. This result implies that any method
for finding the optimal oblique split is likely to have exponential cost
(assuming P 6= NP ).
, 
Intuitively, the problem is that it is impractical to enumerate all 2d  nd distinct hyperplanes
and choose the best, as is done in axis-parallel decision trees. However, any non-exhaustive
deterministic algorithm for searching through all these hyperplanes is prone to getting stuck
in local minima.
3. Throughout the paper, we use the terms \split" and \hyperplane" interchangeably to refer to the test
at a node of a decision tree. The first usage is standard (Moret, 1982), and refers to the fact that the
test splits the data into two partitions. The second usage refers to the geometric form of the test.

5

fiMurthy, Kasif & Salzberg

On the other hand, it is possible to define impurity measures for which the problem
of finding optimal hyperplanes can be solved in polynomial time. For example, if one
minimizes the sum of distances of mis-classified examples, then the optimal solution can
be found using linear programming methods (if distance is measured along one dimension
only). However, classifiers are usually judged by how many points they classify correctly,
regardless of how close to the decision boundary a point may lie. Thus most of the standard
measures for computing impurity base their calculation on the discrete number of examples
of each category on either side of the hyperplane. Section 3.3 discusses several commonly
used impurity measures.
Now let us address the second issue, that of the complexity of building a small tree.
It is easy to show that the problem of inducing the smallest axis-parallel decision tree is
NP-hard. This observation follows directly from the work of Hyafil and Rivest (1976). Note
that one can generate the smallest axis-parallel tree that is consistent with the training
set in polynomial time if the number of attributes is a constant. This can be done by
using dynamic programming or branch and bound techniques (see Moret (1982) for several
pointers). But when the tree uses oblique splits, it is not clear, even for a fixed number
of attributes, how to generate an optimal (e.g., smallest) decision tree in polynomial time.
This suggests that the complexity of constructing good oblique trees is greater than that
for axis-parallel trees.
It is also easy to see that the problem of constructing an optimal (e.g., smallest) oblique
decision tree is NP-hard. This conclusion follows from the work of Blum and Rivest (1988).
Their result implies that in d dimensions (i.e., with d attributes) the problem of producing
a 3-node oblique decision tree that is consistent with the training set is NP-complete. More
specifically, they show that the following decision problem is NP-complete: given a training
set T with n examples and d Boolean attributes, does there exist a 3-node neural network
consistent with T ? From this it is easy to show that the following question is NP-complete:
given a training set T , does there exist a 3-leaf-node oblique decision tree consistent with
T?
As a result of these complexity considerations, we took the pragmatic approach of trying
to generate small trees, but not looking for the smallest tree. The greedy approach used by
OC1 and virtually all other decision tree algorithms implicitly tries to generate small trees.
In addition, it is easy to construct example problems for which the optimal split at a node
will not lead to the best tree; thus our philosophy as embodied in OC1 is to find locally
good splits, but not to spend excessive computational effort on improving the quality of
these splits.

2. Previous Work on Oblique Decision Tree Induction
Before describing the OC1 algorithm, we will briey discuss some existing oblique DT
induction methods, including CART with linear combinations, Linear Machine Decision
Trees, and Simulated Annealing of Decision Trees. There are also methods that induce
tree-like classifiers with linear discriminants at each node, most notably methods using
linear programming (Mangasarian, Setiono, & Wolberg, 1990; Bennett & Mangasarian,
1992, 1994a, 1994b). Though these methods can find the optimal linear discriminants for
specific goodness measures, the size of the linear program grows very fast with the number
6

fiInduction of Oblique Decision Trees

To induce a split at node T of the decision tree:
Normalize values for all d attributes.
L=0
While (TRUE)
L = L+1

Let the current split sL be v  c, where v = Pdi=1 ai xi.
For i = 1; : : :; d
For  = -0.25,0,0.25
Search for the  that maximizes the goodness of the split v , (ai + )  c.
Let  , be the settings that result in highest goodness in these 3 searches.
ai = ai ,   , c = c ,     .
Perturb c to maximize the goodness of sL , keeping a1 ; : : :; ad constant.
If jgoodness(sL) - goodness(sL,1)j   exit while loop.
Eliminate irrelevant attributes in fa1; : : :; ad g using backward elimination.
Convert sL to a split on the un-normalized attributes.
Return the better of sL and the best axis-parallel split as the split for T .
Figure 4: The procedure used by CART with linear combinations (CART-LC) at each node
of a decision tree.
of instances and the number of attributes. There is also some less closely related work on
algorithms to train artificial neural networks to build decision tree-like classifiers (Brent,
1991; Cios & Liu, 1992; Herman & Yeung, 1992).
The first oblique decision tree algorithm to be proposed was CART with linear combinations (Breiman et al., 1984, chapter 5). This algorithm, referred to henceforth as CART-LC,
is an important basis for OC1. Figure 4 summarizes (using Breiman et al.'s notation) what
the CART-LC algorithm does at each node in the decision tree. The core idea of the CARTLC algorithm is how it finds the value of  that maximizes the goodness of a split. This
idea is also used in OC1, and is explained in detail in Section 3.1.
After describing CART-LC, Breiman et al. point out that there is still much room for
further development of the algorithm. OC1 represents an extension of CART-LC that
includes some significant additions. It addresses the following limitations of CART-LC:

 CART-LC is fully deterministic. There is no built-in mechanism for escaping local

minima, although such minima may be very common for some domains. Figure 5
shows a simple example for which CART-LC gets stuck.

 CART-LC produces only a single tree for a given data set.
 CART-LC sometimes makes adjustments that increase the impurity of a split. This
feature was probably included to allow it to escape some local minima.

 There is no upper bound on the time spent at any node in the decision tree. It halts
when no perturbation changes the impurity more than , but because impurity may
increase and decrease, the algorithm can spend arbitrarily long time at a node.
7

fiMurthy, Kasif & Salzberg

1

OC1

2

1

Initial Loc.

1

2

CART-LC

1

2

2

Figure 5: The deterministic perturbation algorithm of CART-LC fails to find the correct
split for this data, even when it starts from the location of the best axis-parallel
split. OC1 finds the correct split using one random jump.
Another oblique decision tree algorithm, one that uses a very different approach from
CART-LC, is the Linear Machine Decision Trees (LMDT) system (Utgoff & Brodley, 1991;
Brodley & Utgoff, 1992), which is a successor to the Perceptron Tree method (Utgoff, 1989;
Utgoff & Brodley, 1990). Each internal node in an LMDT tree is a Linear Machine (Nilsson,
1990). The training algorithm presents examples repeatedly at each node until the linear
machine converges. Because convergence cannot be guaranteed, LMDT uses heuristics to
determine when the node has stabilized. To make the training stable even when the set of
training instances is not linearly separable, a \thermal training" method (Frean, 1990) is
used, similar to simulated annealing.
A third system that creates oblique trees is Simulated Annealing of Decision Trees
(SADT) (Heath et al., 1993b) which, like OC1, uses randomization. SADT uses simulated
annealing (Kirkpatrick, Gelatt, & Vecci, 1983) to find good values for the coecients of
the hyperplane at each node of a tree. SADT first places a hyperplane in a canonical
location, and then iteratively perturbs all the coecients by small random amounts. Initially, when the temperature parameter is high, SADT accepts almost any perturbation of
the hyperplane, regardless of how it changes the goodness score. However, as the system
\cools down," only changes that improve the goodness of the split are likely to be accepted.
Though SADT's use of randomization allows it to effectively avoid some local minima, it
compromises on eciency. It runs much slower than either CART-LC, LMDT or OC1,
sometimes considering tens of thousands of hyperplanes at a single node before it finishes
annealing.
Our experiments in Section 4.3 include some results showing how all of these methods
perform on three artificial domains.
We next describe a way to combine some of the strengths of the methods just mentioned,
while avoiding some of the problems. Our algorithm, OC1, uses deterministic hill climbing
most of the time, ensuring computational eciency. In addition, it uses two kinds of
randomization to avoid local minima. By limiting the number of random choices, the
algorithm is guaranteed to spend only polynomial time at each node in the tree. In addition,
randomization itself has produced several benefits: for example, it means that the algorithm
8

fiInduction of Oblique Decision Trees

To find a split of a set of examples T :
Find the best axis-parallel split of T . Let I be the impurity of this split.
Repeat R times:
Choose a random hyperplane H .
(For the first iteration, initialize H to be the best axis-parallel split.)
Step 1: Until the impurity measure does not improve, do:
Perturb each of the coecients of H in sequence.
Step 2: Repeat at most J times:
Choose a random direction and attempt to perturb H in that direction.
If this reduces the impurity of H , go to Step 1.
Let I1 = the impurity of H . If I1 < I , then set I = I1 .
Output the split corresponding to I .
Figure 6: Overview of the OC1 algorithm for a single node of a decision tree.
can produce many different trees for the same data set. This offers the possibility of a new
family of classifiers: k-decision-tree algorithms, in which an example is classified by the
majority vote of k trees. Heath et al. (1993a) have shown that k-decision tree methods
(which they call k-DT) will consistently outperform single tree methods if classification
accuracy is the main criterion. Finally, our experiments indicate that OC1 eciently finds
small, accurate decision trees for many different types of classification problems.

3. Oblique Classifier 1 (OC1)

In this section we discuss details of the oblique decision tree induction system OC1. As
part of this description, we include:
 the method for finding coecients of a hyperplane at each tree node,
 methods for computing the impurity or goodness of a hyperplane,
 a tree pruning strategy, and
 methods for coping with missing and irrelevant attributes.
Section 3.1 focuses on the most complicated of these algorithmic details; i.e. the question of
how to find a hyperplane that splits a given set of instances into two reasonably \pure" nonoverlapping subsets. This randomized perturbation algorithm is the main novel contribution
of OC1. Figure 6 summarizes the basic OC1 algorithm, used at each node of a decision
tree. This figure will be explained further in the following sections.

3.1 Perturbation algorithm

OC1 imposes no restrictions on the orientation of the hyperplanes. However, in order to be
at least as powerful as standard DT methods, it first finds the best axis-parallel (univariate)
split at a node before looking for an oblique split. OC1 uses an oblique split only when it
improves over the best axis-parallel split.4
4. As pointed out in (Breiman et al., 1984, Chapter 5), it does not make sense to use an oblique split when
the number of examples at a node n is less than or almost equal to the number of features d, because the

9

fiMurthy, Kasif & Salzberg

The search strategy for the space of possible hyperplanes is defined by the procedure
that perturbs the current hyperplane H to a new location. Because there are an exponential
number of distinct ways to partition the examples with a hyperplane, any procedure that
simply enumerates all of them will be unreasonably costly. The two main alternatives
considered in the past have been simulated annealing, used in the SADT system (Heath
et al., 1993b), and deterministic heuristic search, as in CART-LC (Breiman et al., 1984).
OC1 combines these two ideas, using heuristic search until it finds a local minimum, and
then using a non-deterministic search step to get out of the local minimum. (The nondeterministic step in OC1 is not simulated annealing, however.)
We will start by explaining how we perturb a hyperplane to split the training set T at
a node of the decision tree. Let n be the number of examples in T , d be the number of
attributes (or dimensions) for each example, and k be the number of categories. Then we
can write Tj = (xj 1 ; xj 2; : : :; xjd; Cj ) for the j th example from the training set T , where xji is
the value of attribute i and Cj is the category label. As defined P
in Eq. 1, the equation of the
current hyperplane H at a node of the decision tree is written as di=1
(a x )+ad+1 = 0. If we
Pd i i
substitute a point (an example) Tj into the equation for H , we get i=1 (aixji )+ ad+1 = Vj ,
where the sign of Vj tells us whether the point Tj is above or below the hyperplane H ;
i.e., if Vj > 0, then Tj is above H . If H splits the training set T perfectly, then all points
belonging to the same category will have the same sign for Vj . i.e., sign(Vi) = sign(Vj ) iff
category(Ti) = category(Tj ).
OC1 adjusts the coecients of H individually, finding a locally optimal value for one
coecient at a time. This key idea was introduced by Breiman et al. It works as follows.
Treat the coecient am as a variable, and treat all other coecients as constants. Then
Vj can be viewed as a function of am . In particular, the condition that Tj is above H is
equivalent to
Vj > 0
= Uj
am > am xxjm , Vj def
jm

(2)

assuming that xjm > 0, which we ensure by normalization. Using this definition of Uj , the
point Tj is above H if am > Uj , and below otherwise. By plugging all the points from T
into this equation, we will obtain n constraints on the value of am .
The problem then is to find a value for am that satisfies as many of these constraints
as possible. (If all the constraints are satisfied, then we have a perfect split.) This problem
is easy to solve optimally: simply sort all the values Uj , and consider setting am to the
midpoint between each pair of different values. This is illustrated in Figure 7. In the figure,
the categories are indicated by font size; the larger Ui 's belong to one category, and the
smaller to another. For each distinct placement of the coecient am , OC1 computes the
impurity of the resulting split; e.g., for the location between U6 and U7 illustrated here, two
examples on the left and one example on the right would be misclassified (see Section 3.3.1
for different ways of computing impurity). As the figure illustrates, the problem is simply
to find the best one-dimensional split of the U s, which requires considering just n , 1 values
for am . The value a0m obtained by solving this one-dimensional problem is then considered
data underfits the concept. By default, OC1 uses only axis-parallel splits at tree nodes at which n < 2d.
The user can vary this threshold.

10

fiFigure 7: Finding the optimal value for a single coecient am . Large U's correspond to
examples in one category and small u's to another.

Perturb(H,m)
For j = 1; : : :; n
Compute Uj (Eq. 2)
Sort U1; : : :; Un in non-decreasing order.
a0m = best univariate split of the sorted Uj s.
H1 = result of substituting a0m for am in H .
If (impurity(H1 ) < impurity(H))
f am = a0m ; Pmove = Pstag g
Else if (impurity(H) = impurity(H1 ))
f am = a0m with probability Pmove
Pmove = Pmove , 0:1  Pstag g
Figure 8: Perturbation algorithm for a single coecient am .

as a replacement for am . Let H1 be the hyperplane obtained by \perturbing" am to a0m . If
H has better (lower) impurity than H1, then H1 is discarded. If H1 has lower impurity, H1
becomes the new location of the hyperplane. If H and H1 have identical impurities, then
H1 replaces H with probability Pstag .5 Figure 8 contains pseudocode for our perturbation
procedure.
Now that we have a method for locally improving a coecient of a hyperplane, we need
to decide which of the d + 1 coecients to pick for perturbation. We experimented with
three different methods for choosing which coecient to adjust, namely, sequential, best
first and random.
Seq: Repeat until none of the coecient values is modified in the For loop:
For i = 1 to d, Perturb(H; i)
Best: Repeat until coecient m remains unmodified:
m = coecient which when perturbed, results in the
maximum improvement of the impurity measure.
Perturb(H; m)
R-50: Repeat a fixed number of times (50 in our experiments):
m = random integer between 1 and d + 1
Perturb(H; m)
5. The parameter Pstag , denoting \stagnation probability", is the probability that a hyperplane is perturbed
to a location that does not change the impurity measure. To prevent the impurity from remaining
stagnant for a long time, Pstag decreases by a constant amount each time OC1 makes a \stagnant"
perturbation; thus only a constant number of such perturbations will occur at each node. This constant
can be set by the user. Pstag is reset to 1 every time the global impurity measure is improved.

11

fiMurthy, Kasif & Salzberg

Our previous experiments (Murthy et al., 1993) indicated that the order of perturbation
of the coecients does not affect the classification accuracy as much as other parameters,
especially the randomization parameters (see below). Since none of these orders was uniformly better than any other, we used sequential (Seq) perturbation for all the experiments
reported in Section 4.

3.2 Randomization

The perturbation algorithm halts when the split reaches a local minimum of the impurity
measure. For OC1's search space, a local minimum occurs when no perturbation of any
single coecient of the current hyperplane will decrease the impurity measure. (Of course,
a local minimum may also be a global minimum.) We have implemented two ways of
attempting to escape local minima: perturbing the hyperplane with a random vector, and
re-starting the perturbation algorithm with a different random initial hyperplane.
The technique of perturbing the hyperplane with a random vector works as follows.
When the system reaches a local minimum, it chooses a random vector to add to the
coecients of the current hyperplane. It then computes the optimal amount by which the
hyperplane should beP perturbed along this random direction. To be more precise, when
a hyperplane H = di=1 ai xi + ad+1 cannot be improved by deterministic perturbation,
OC1 repeats the following loop J times (where J is a user-specified parameter, set to 5 by
default).

 Choose a random vector R = (r1; r2; : : :; rd+1).
 Let ff be the amount
by which we want to perturb H in the direction R. In other
Pd
words, let H1 = i=1 (ai + ffri )xi + (ad+1 + ffrd+1 ).
 Find the optimal value for ff.
 If the hyperplane H1 thus obtained decreases the overall impurity, replace H with H1,
exit this loop and begin the deterministic perturbation algorithm for the individual
coecients.

Note that we can treat ff as the only variable in the equation for H1 . Therefore each of the
n examples in T , if plugged into the equation for H1, imposes a constraint on the value of
ff. OC1 therefore can use its coecient perturbation method (see Section 3.1) to compute
the best value of ff. If J random jumps fail to improve the impurity, OC1 halts and uses
H as the split for the current tree node.
An intuitive way of understanding this random jump is to look atPthe dual space in which
the algorithm is actually searching. Note that the equation H = di=1 ai xi + ad+1 defines
a space in which the axes are the coecients ai rather than the attributes xi . Every point
in this space defines a distinct hyperplane in the original formulation. The deterministic
algorithm used in OC1 picks a hyperplane and then adjusts coecients one at a time. Thus
in the dual space, OC1 chooses a point and perturbs it by moving it parallel to the axes.
The random vector R represents a random direction in this space. By finding the best value
for ff, OC1 finds the best distance to adjust the hyperplane in the direction of R.
12

fiInduction of Oblique Decision Trees

Note that this additional perturbation in a random direction does not significantly increase the time complexity of the algorithm (see Appendix A). We found in our experiments
that even a single random jump, when used at a local minimum, proves to be very helpful.
Classification accuracy improved for every one of our data sets when such perturbations
were made. See Section 4.3 for some examples.
The second technique for avoiding local minima is a variation on the idea of performing
multiple local searches. The technique of multiple local searches is a natural extension
to local search, and has been widely mentioned in the optimization literature (see Roth
(1970) for an early example). Because most of the steps of our perturbation algorithm
are deterministic, the initial hyperplane largely determines which local minimum will be
encountered first. Perturbing a single initial hyperplane is thus unlikely to lead to the best
split of a given data set. In cases where the random perturbation method fails to escape
from local minima, it may be helpful to simply start afresh with a new initial hyperplane.
We use the word restart to denote one run of the perturbation algorithms, at one node of
the decision tree, using one random initial hyperplane.6 That is, a restart cycles through
and perturbs the coecients one at a time and then tries to perturb the hyperplane in a
random direction when the algorithm reaches a local minimum. If this last perturbation
reduces the impurity, the algorithm goes back to perturbing the coecients one at a time.
The restart ends when neither the deterministic local search nor the random jump can find
a better split. One of the optional parameters to OC1 specifies how many restarts to use.
If more than one restart is used, then the best hyperplane found thus far is always saved.
In all our experiments, the classification accuracies increased with more than one restart.
Accuracy tended to increase up to a point and then level off (after about 20{50 restarts,
depending on the domain). Overall, the use of multiple initial hyperplanes substantially
improved the quality of the decision trees found (see Section 4.3 for some examples).
By carefully combining hill-climbing and randomization, OC1 ensures a worst case time
of O(dn2 log n) for inducing a decision tree. See Appendix A for a derivation of this upper
bound.

Best Axis-Parallel Split. It is clear that axis-parallel splits are more suitable for some

data distributions than oblique splits. To take into account such distributions, OC1 computes the best axis-parallel split and an oblique split at each node, and then picks the better
of the two.7 Calculating the best axis-parallel split takes an additional O(dn log n) time,
and so does not increase the asymptotic time complexity of OC1. As a simple variant of
the OC1 system, the user can opt to \switch off" the oblique perturbations, thus building
an axis-parallel tree on the training data. Section 4.2 empirically demonstrates that this
axis-parallel variant of OC1 compares favorably with existing axis-parallel algorithms.
6. The first run through the algorithm at each node always begins at the location of the best axis-parallel
hyperplane; all subsequent restarts begin at random locations.
7. Sometimes a simple axis-parallel split is preferable to an oblique split, even if the oblique split has slightly
lower impurity. The user can specify such a bias as an input parameter to OC1.

13

fiMurthy, Kasif & Salzberg

3.3 Other Details
3.3.1 Impurity Measures

OC1 attempts to divide the d-dimensional attribute space into homogeneous regions; i.e.,
regions that contain examples from just one category. The goal of adding new nodes to
a tree is to split up the sample space so as to minimize the \impurity" of the training
set. Some algorithms measure \goodness" instead of impurity, the difference being that
goodness values should be maximized while impurity should be minimized. Many different
measures of impurity have been studied (Breiman et al., 1984; Quinlan, 1986; Mingers,
1989b; Buntine & Niblett, 1992; Fayyad & Irani, 1992; Heath et al., 1993b).
The OC1 system is designed to work with a large class of impurity measures. Stated
simply, if the impurity measure uses only the counts of examples belonging to every category
on both sides of a split, then OC1 can use it. (See Murthy and Salzberg (1994) for ways of
mapping other kinds of impurity measures to this class of impurity measures.) The user can
plug in any impurity measure that fits this description. The OC1 implementation includes
six impurity measures, namely:
1.
2.
3.
4.
5.
6.

Information Gain
The Gini Index
The Twoing Rule
Max Minority
Sum Minority
Sum of Variances

Though all six of the measures have been defined elsewhere in the literature, in some
cases we have made slight modifications that are defined precisely in Appendix B. Our
experiments indicated that, on average, Information Gain, Gini Index and the Twoing Rule
perform better than the other three measures for both axis-parallel and oblique trees. The
Twoing Rule is the current default impurity measure for OC1, and it was used in all of
the experiments reported in Section 4. There are, however, artificial data sets for which
Sum Minority and/or Max Minority perform much better than the rest of the measures.
For instance, Sum Minority easily induces the exact tree for the POL data set described in
Section 4.3.1, while all other methods have diculty finding the best tree.

Twoing Rule. The Twoing Rule was first proposed by Breiman et al. (1984). The value

to be computed is defined as:

k
X

TwoingValue = (jTLj=n)  (jTRj=n)  (

i=1

jLi=jTLj , Ri=jTRjj)2

where jTLj (jTRj) is the number of examples on the left (right) of a split at node T , n is
the number of examples at node T , and Li (Ri ) is the number of examples in category i on
the left (right) of the split. The TwoingValue is actually a goodness measure rather than
an impurity measure. Therefore OC1 attempts to minimize the reciprocal of this value.
The remaining five impurity measures implemented in OC1 are defined in Appendix B.
14

fiInduction of Oblique Decision Trees

3.3.2 Pruning

Virtually all decision tree induction systems prune the trees they create in order to avoid
overfitting the data. Many studies have found that judicious pruning results in both smaller
and more accurate classifiers, for decision trees as well as other types of machine learning
systems (Quinlan, 1987; Niblett, 1986; Cestnik, Kononenko, & Bratko, 1987; Kodratoff
& Manago, 1987; Cohen, 1993; Hassibi & Stork, 1993; Wolpert, 1992; Schaffer, 1993).
For the OC1 system we implemented an existing pruning method, but note that any tree
pruning method will work fine within OC1. Based on the experimental evaluations of
Mingers (1989a) and other work cited above, we chose Breiman et al.'s Cost Complexity
(CC) pruning (1984) as the default pruning method for OC1. This method, which is also
called Error Complexity or Weakest Link pruning, requires a separate pruning set. The
pruning set can be a randomly chosen subset of the training set, or it can be approximated
using cross validation. OC1 randomly chooses 10% (the default value) of the training data
to use for pruning. In the experiments reported below, we only used this default value.
Briey, the idea behind CC pruning is to create a set of trees of decreasing size from the
original, complete tree. All these trees are used to classify the pruning set, and accuracy is
estimated from that. CC pruning then chooses the smallest tree whose accuracy is within k
standard errors squared of the best accuracy obtained. When the 0-SE rule (k = 0) is used,
the tree with highest accuracy on the pruning set is selected. When k > 0, smaller tree size
is preferred over higher accuracy. For details of Cost Complexity pruning, see Breiman et
al. (1984) or Mingers (1989a).
3.3.3 Irrelevant attributes

Irrelevant attributes pose a significant problem for most machine learning methods (Breiman
et al., 1984; Aha, 1990; Almuallin & Dietterich, 1991; Kira & Rendell, 1992; Salzberg, 1992;
Cardie, 1993; Schlimmer, 1993; Langley & Sage, 1993; Brodley & Utgoff, 1994). Decision
tree algorithms, even axis-parallel ones, can be confused by too many irrelevant attributes.
Because oblique decision trees learn the coecients of each attribute at a DT node, one
might hope that the values chosen for each coecient would reect the relative importance
of the corresponding attributes. Clearly, though, the process of searching for good coecient
values will be much more ecient when there are fewer attributes; the search space is much
smaller. For this reason, oblique DT induction methods can benefit substantially by using a
feature selection method (an algorithm that selects a subset of the original attribute set) in
conjunction with the coecient learning algorithm (Breiman et al., 1984; Brodley & Utgoff,
1994).
Currently, OC1 does not have a built-in mechanism to select relevant attributes. However, it is easy to include any of several standard methods (e.g., stepwise forward selection
or stepwise backward selection) or even an ad hoc method to select features before running
the tree-building process. For example, in separate experiments on data from the Hubble
Space Telescope (Salzberg, Chandar, Ford, Murthy, & White, 1994), we used feature selection methods as a preprocessing step to OC1, and reduced the number of attributes from 20
to 2. The resulting decision trees were both simpler and more accurate. Work is currently
underway to incorporate an ecient feature selection technique into the OC1 system.
15

fiMurthy, Kasif & Salzberg

Regarding missing values, if an example is missing a value for any attribute, OC1 uses
the mean value for that attribute. One can of course use other techniques for handling
missing values, but those were not considered in this study.

4. Experiments

In this section, we present two sets of experiments to support the following two claims.
1. OC1 compares favorably over a variety of real-world domains with several existing
axis-parallel and oblique decision tree induction methods.
2. Randomization, both in the form of multiple local searches and random jumps, improves the quality of decision trees produced by OC1.
The experimental method used for all the experiments is described in Section 4.1. Sections 4.2 and 4.3 describe experiments corresponding to the above two claims. Each experimental section begins with a description of the data sets, and then presents the experimental
results and discussion.

4.1 Experimental Method

We used five-fold cross validation (CV) in all our experiments to estimate classification
accuracy. A k-fold CV experiment consists of the following steps.
1. Randomly divide the data into k equal-sized disjoint partitions.
2. For each partition, build a decision tree using all data outside the partition, and test
the tree on the data in the partition.
3. Sum the number of correct classifications of the k trees and divide by the total number
of instances to compute the classification accuracy. Report this accuracy and the
average size of the k trees.
Each entry in Tables 1 and 2 is a result of ten 5-fold CV experiments; i.e., the result of tests
that used 50 decision trees. Each of the ten 5-fold cross validations used a different random
partitioning of the data. Each entry in the tables reports the mean and standard deviation
of the classification accuracy, followed by the mean and standard deviation of the decision
tree size (measured as the number of leaf nodes). Good results should have high values for
accuracy, low values for tree size, and small standard deviations.
In addition to OC1, we also included in the experiments an axis-parallel version of OC1,
which only considers axis-parallel hyperplanes. We call this version, described in Section 3.2,
OC1-AP. In all our experiments, both OC1 and OC1-AP used the Twoing Rule (Section
3.3.1) to measure impurity. Other parameters to OC1 took their default values unless stated
otherwise. (Defaults include the following: number of restarts at each node: 20. Number
of random jumps attempted at each local minimum: 5. Order of coecient perturbation:
Sequential. Pruning method: Cost Complexity with the 0-SE rule, using 10% of the training
set exclusively for pruning.)
In our comparison, we used the oblique version of the CART algorithm, CART-LC.
We implemented our own version of CART-LC, following the description in Breiman et
al. (1984, Chapter 5); however, there may be differences between our version and other
16

fiInduction of Oblique Decision Trees

versions of this system (note that CART-LC is not freely available). Our implementation
of CART-LC measured impurity with the Twoing Rule and used 0-SE Cost Complexity
pruning with a separate test set, just as OC1 does. We did not include any feature selection
methods in CART-LC or in OC1, and we did not implement normalization. Because the
CART coecient perturbation algorithm may alternate indefinitely between two locations
of a hyperplane (see Section 2), we imposed an arbitrary limit of 100 such perturbations
before forcing the perturbation algorithm to halt.
We also included axis-parallel CART and C4.5 in our comparisons. We used the implementations of these algorithms from the IND 2.1 package (Buntine, 1992). The default
cart0 and c4.5 \styles" defined in the package were used, without altering any parameter
settings. The cart0 style uses the Twoing Rule and 0-SE cost complexity pruning with
10-fold cross validation. The pruning method, impurity measure and other defaults of the
c4.5 style are the same as those described in Quinlan (1993a).

4.2 OC1 vs. Other Decision Tree Induction Methods

Table 1 compares the performance of OC1 to three well-known decision tree induction
methods plus OC1-AP on six different real-world data sets. In the next section we will
consider artificial data, for which the concept definition can be precisely characterized.
4.2.1 Description of Data Sets

Star/Galaxy Discrimination. Two of our data sets came from a large set of astronom-

ical images collected by Odewahn et al. (Odewahn, Stockwell, Pennington, Humphreys, &
Zumach, 1992). In their study, they used these images to train artificial neural networks
running the perceptron and back propagation algorithms. The goal was to classify each example as either \star" or \galaxy." Each image is characterized by 14 real-valued attributes,
where the attributes were measurements defined by astronomers as likely to be relevant for
this task. The objects in the image were divided by Odewahn et al. into \bright" and \dim"
data sets based on the image intensity values, where the dim images are inherently more
dicult to classify. (Note that the \bright" objects are only bright in relation to others
in this data set. In actuality they are extremely faint, visible only to the most powerful
telescopes.) The bright set contains 2462 objects and the dim set contains 4192 objects.
In addition to the results reported in Table 1, the following results have appeared on
the Star/Galaxy data. Odewahn et al. (1992) reported accuracy of 99.8% accuracy on the
bright objects, and 92.0% on the dim ones, although it should be noted that this study
used a single training and test set partition. Heath (1992) reported 99.0% accuracy on the
bright objects using SADT, with an average tree size of 7.03 leaves. This study also used
a single training and test set. Salzberg (1992) reported accuracies of 98.8% on the bright
objects, and 95.1% on the dim objects, using 1-Nearest Neighbor (1-NN) coupled with a
feature selection method that reduces the number of features.
Breast Cancer Diagnosis. Mangasarian and Bennett have compiled data on the problem of diagnosing breast cancer to test several new classification methods (Mangasarian
et al., 1990; Bennett & Mangasarian, 1992, 1994a). This data represents a set of patients
with breast cancer, where each patient was characterized by nine numeric attributes plus
the diagnosis of the tumor as benign or malignant. The data set currently has 683 entries
17

fiMurthy, Kasif & Salzberg

Bright S/G
98.90.2
4.31.0
CART-LC
98.80.2
3.91.3
OC1-AP
98.10.2
6.92.4
CART-AP
98.50.5
13.95.7
C4.5
98.50.5
14.32.2
Algorithm
OC1

Dim S/G
95.00.3
13.08.7
92.80.5
24.28.7
94.00.2
29.38.8
94.20.7
30.410
93.30.8
77.97.4

Cancer
96.20.3
2.80.9
95.30.6
3.50.9
94.50.5
6.41.7
95.01.6
11.57.2
95.32.0
9.82.2

Iris
94.73.1
3.10.2
93.52.9
3.20.3
92.72.4
3.20.3
93.83.7
4.31.6
95.13.2
4.60.8

Housing
82.40.8
6.93.2
81.41.2
5.83.2
81.81.0
8.64.5
82.13.5
15.110
83.23.1
28.23.3

Diabetes
74.41.0
5.43.8
73.71.2
8.05.2
73.81.0
11.47.5
73.93.4
11.59.1
71.43.3
56.37.9

Table 1: Comparison of OC1 and other decision tree induction methods on six different
data sets. The first line for each method gives accuracies, and the second line gives
average tree sizes. The highest accuracy for each domain appears in boldface.
and is available from the UC Irvine machine learning repository (Murphy & Aha, 1994).
Heath et al. (1993b) reported 94.9% accuracy on a subset of this data set (it then had
only 470 instances), with an average decision tree size of 4.6 nodes, using SADT. Salzberg
(1991) reported 96.0% accuracy using 1-NN on the same (smaller) data set. Herman and
Yeung (1992) reported 99.0% accuracy using piece-wise linear classification, again using a
somewhat smaller data set.

Classifying Irises. This is Fisher's famous iris data, which has been extensively studied

in the statistics and machine learning literature. The data consists of 150 examples, where
each example is described by four numeric attributes. There are 50 examples of each of
three different types of iris ower. Weiss and Kapouleas (1989) obtained accuracies of 96.7%
and 96.0% on this data with back propagation and 1-NN, respectively.

Housing Costs in Boston. This data set, also available as a part of the UCI ML repos-

itory, describes housing values in the suburbs of Boston as a function of 12 continuous
attributes and 1 binary attribute (Harrison & Rubinfeld, 1978). The category variable (median value of owner-occupied homes) is actually continuous, but we discretized it so that
category = 1 if value < $21000, and 2 otherwise. For other uses of this data, see (Belsley,
1980; Quinlan, 1993b).

Diabetes diagnosis. This data catalogs the presence or absence of diabetes among Pima

Indian females, 21 years or older, as a function of eight numeric-valued attributes. The
original source of the data is the National Institute of Diabetes and Digestive and Kidney
Diseases, and it is now available in the UCI repository. Smith et al. (1988) reported 76%
accuracy on this data using their ADAP learning algorithm, using a different experimental
method from that used here.
18

fiInduction of Oblique Decision Trees

4.2.2 Discussion

The table shows that, for the six data sets considered here, OC1 consistently finds better
trees than the original oblique CART method. Its accuracy was greater in all six domains,
although the difference was significant (more than 2 standard deviations) only for the dim
star/galaxy problem. The average tree sizes were roughly equal for five of the six domains,
and for the dim stars and galaxies, OC1 found considerably smaller trees. These differences
will be analyzed and quantified further by using artificial data, in the following section.
Out of the five decision tree induction methods, OC1 has the highest accuracy on four
of the six domains: bright stars, dim stars, cancer diagnosis, and diabetes diagnosis. On the
remaining two domains, OC1 has the second highest accuracy in each case. Not surprisingly,
the oblique methods (OC1 and CART-LC) generally find much smaller trees than the axisparallel methods. This difference can be quite striking for some domains|note, for example,
that OC1 produced a tree with just 13 nodes on average for the dim star/galaxy problem,
while C4.5 produced a tree with 78 nodes, 6 times larger. Of course, in domains for which
an axis-parallel tree is the appropriate representation, axis-parallel methods should compare
well with oblique methods in terms of tree size. In fact, for the Iris data, all the methods
found similar-sized trees.

4.3 Randomization Helps OC1

In our second set of experiments, we examine more closely the effect of introducing randomized steps into the algorithm for finding oblique splits. Our experiments demonstrate that
OC1's ability to produce an accurate tree from a set of training data is clearly enhanced
by the two kinds of randomization it uses. More precisely, we use three artificial data sets
(for which the underlying concept is known to the experimenters) to show that OC1's performance improves substantially when the deterministic hill climbing is augmented in any
of three ways:

 with multiple restarts from random initial locations,
 with perturbations in random directions at local minima, or
 with both of the above randomization steps.
In order to find clear differences between algorithms, one needs to know that the concept
underlying the data is indeed dicult to learn. For simple concepts (say, two linearly
separable classes in 2-D), many different learning algorithms will produce very accurate
classifiers, and therefore the advantages of randomization may not be detectable. It is
known that many of the commonly-used data sets from the UCI repository are easy to
learn with very simple representations (Holte, 1993); therefore those data sets may not be
ideal for our purposes. Thus we created a number of artificial data sets that present different
problems for learning, and for which we know the \correct" concept definition. This allows
us to quantify more precisely how the parameters of our algorithm affect its performance.
A second purpose of this experiment is to compare OC1's search strategy with that
of two existing oblique decision tree induction systems { LMDT (Brodley & Utgoff, 1992)
and SADT (Heath et al., 1993b). We show that the quality of trees induced by OC1 is as
good as, if not better than, that of the trees induced by these existing systems on three
19

fiMurthy, Kasif & Salzberg

artificial domains. We also show that OC1 achieves a good balance between amount of
effort expended in search and the quality of the tree induced.
Both LMDT and SADT used information gain for this experiment. However, we did
not change OC1's default measure (the Twoing Rule) because we observed, in experiments
not reported here, that OC1 with information gain does not produce significantly different
results. The maximum number of successive, unproductive perturbations allowed at any
node was set at 10000 for SADT. For all other parameters, we used default settings provided
with the systems.
4.3.1 Description of Artificial Data

LS10 The LS10 data set has 2000 instances divided into two categories. Each instance is

described by ten attributes x1 ,: : : ,x10, whose values are uniformly distributed in the range
[0,1]. The data is linearly separable with a 10-D hyperplane (thus the name LS10) defined
by the equation x1 + x2 + x3 + x4 + x5 < x6 + x7 + x8 + x9 + x10. The instances were all
generated randomly and labelled according to which side of this hyperplane they fell on.
Because oblique DT induction methods intuitively should prefer a linear separator if one
exists, it is interesting to compare the various search techniques on this data set where we
know a separator exists. The task is relatively simple for lower dimensions, so we chose
10-dimensional data to make it more dicult.

POL This data set is shown in Figure 9. It has 2000 instances in two dimensions, again

divided into two categories. The underlying concept is a set of four parallel oblique lines
(thus the name POL), dividing the instances into five homogeneous regions. This concept is
more dicult to learn than a single linear separator, but the minimal-size tree is still quite
small.

RCB RCB stands for \rotated checker board"; this data set has been the subject of

other experiments on hard classification problems for decision trees (Murthy & Salzberg,
1994). The data set, shown in Figure 9, has 2000 instances in 2-D, each belonging to one of
eight categories. This concept is dicult to learn for any axis-parallel method, for obvious
reasons. It is also quite dicult for oblique methods, for several reasons. The biggest
problem is that the \correct" root node, as shown in the figure, does not separate out any
class by itself. Some impurity measures (such as Sum Minority) will fail miserably on this
problem, although others (e.g., the Twoing Rule) work much better. Another problem is
that a deterministic coecient perturbation algorithm can get stuck in local minima in
many places on this data set.
Table 2 summarizes the results of this experiment in three smaller tables, one for each
data set. In each smaller table, we compare four variants of OC1 with LMDT and SADT.
The different results for OC1 were obtained by varying both the number of restarts and the
number of random jumps. When random jumps were used, up to twenty random jumps
were tried at each local minimum. As soon as one was found that improved the impurity
of the current hyperplane, the algorithm moved the hyperplane and started running the
deterministic perturbation procedure again. If none of the 20 random jumps improved the
impurity, the search halted and further restarts (if any) were tried. The same training and
test partitions were used for all methods for each cross-validation run (recall that the results
20

fiInduction of Oblique Decision Trees

lr1

ot

rr1

-1

l-1

1

r-1

rl-

1
rr-

r-1

t-1
oo
R

3
4
4
4
77
4
33
333
33
4
33
33
7
3 4 4
4 44 44 4
1 33
3
3 3 3
4 4 7
4 44
3
4
4
44
33 3 3
3 33
4
4
7
4
33 3 3
4 44
111 1 3 33 3
7 7 77 7
4
3
3 3 3 33 3 3
4
1
4 4 444
1
44
7
4 4
3
3
4
4 4
3 333 3
4 44444
44 4 4 44
47
1 1
777
3
33 3 4 4
3
4
7
4 4
444 4
7
4444 4
3
7
334 4 4
44
44
33
1
77 77 777
3
4 4
34 44
1 1
7 777 7
44
113
4 7 777 7
4
7
7
4
1
1
4
1
4 4 44 4 4 44 4 4
1
3
7
1
7
1 111
4
4
1
7
7 7 7 777 7
44
4 4 4447
44 4 4
4
77
7
111 1 1 1 4 4 44 4 4
7 7 77 7
44 4
1
4
1 1
4 44 4
7
444
7 7
44 4 4
1 111 1
4
1
4
1
7 77
11
1 1
44 4
4
4
1
7
7
7
7 77
1 1 11 14
1 1 111
4 4 44 477 7
7
4 44
7
1
77
4 4
77 7 7 7 7 7
11
4
8
4
11
7
1 1 1
4
8
2
77 77
7
4 4 7
1
2 4 44 4
7
11 1
7
8
7 77
7
1
1
1
2
1
2
7
7
8
11
11
22 2444 4 4
7 777 77 7 77 7 7 77 7 7 8
4
1 2 22 2 2
7
1
88 8
ll-2
2
7
77 7
4
1 1 22
8
7 7
22 2 22 44 4 4 77
7
7 77888 8
11
1
22 22
8
888
2 22 22
5
7
1
8
22 222
1
2 2
88
7 77 7
2
2
2
11 2 2
8
22
2
5
7777
8
8
222 22 2
8
222
2 2
2
77 8 8 8
2
2
55
77 8
2 2 22 2
22
8 88 8 8 8
5
55
8
2 22 2
2
2 2
8 88
7 8
2 222
8
5 5 77
888 8
2 2
8
2
5
5
5
5
2
2
8
2
55 55
8
88 8
22 222 2
7
2 22
8
2
25
8 88 8
5
2
22
88
55
5
8 8 8 8 8 88
5 5
2 22 2 22 22 2 22 22
8
8 88 8
5
5
2 2
55
22
8 8 88 8
5
2 22 2 5 5 5
8
2 2
5 56
8
8 8
5
5
8
2
2
55
5
5 5 55 5 6 6
8 88 8888
22
5
2
8
5
5
8 88
6 66 8 8
2 2 2 2 2 2 2 2 5 5 55 5 5
6
8
6
8
8
2 2 2 2
8
55
8
5
6
8
8 8
5
6
55
2 2222 2 5
5
5
5
5
5
6
6
6
5 5 5
5 55
6
55 5 5
222 22 2 22
8 8
6
5
55 5 5
6
6
6
66
8
5
55
8
22
6 66 6
8 8
5 5 5
2 22
55
6
6
6 6
2 2
2
5 55 5 5 5
5
6 66 8 8
6
2
5
66 6
5
6 66
55 5
5
5 6
5
55 5
6 6 66
55
5
22 2
55 5
5 5
66 6 6
6
55
6666
8
5 5
6
5
6
6
6
66
55
6 6 66
55
55
8 8
6 66 6
5 5555
6 66 6
5
6
66
2
5 5555
5
66
6
5
5
8
66 6 6
5 5 5 55 555 5
6 66
55 5
6 68
5
6 6
6
6 6

Ro

-1
rrr

2
2
1
2
11
1
22
222
11
2
22
22
1
2 2 2
1 11 11 1
1 11
2
2 2 2
1 1 1
2 22
2
2
1
11
22 2 2
2 22
2
2
1
2
22 2 2
2 22
111 1 1 11 2
1 1 11 1
1
2
1 2 2 22 2 2
1
1
2 2 222
1
22
1
1 1
2
2
2
2 2
2 222 2
2 22222
22 2 2 11
11
1 1
111
2
22 2 2 2
1
2
1
2 1
222 2
1
2222 2
1
1
222 2 2
22
22
22
1
11 11 111
1
2 2
22 22
1 1
1 111 1
22
111
2 2 222 1
2
1
2
2
1
1
2
1
2 2 22 2 2 22 2 2
1
1
1
1
1
1 111
2
2
1
2
2 1 1 111 1
22
2 2 2222
22 2 2
1
22
2
111 1 1 1 1 1 11 2 2
1 1 11 1
22 2
1
2
1 1
2 22 2
2
222
1 1
22 2 2
1 111 1
2
1
2
1
2 22
11
1 1
22 2
2
1
1
2
1
2
2 22
1 1 11 11
1 1 111
2 2 22 222 2
2
2 22
2
1
22
2 2
22 2 2 2 2 2
11
1
2
2
11
2
1 1 1
2
2
1
22 22
2
2 2 2
1
1 1 11 1
2
21 1
2
2
2 22
2
1
1
1
1
2
1
2
2
2
11
111
11 1111 1 1
2 222 22 2 22 2 2 22 2 2 2
1
11 1
2
1
22 2
1 1
1
2
22 2
1
2 1 11
2
2 2
11 1 11 11 1 1 12
2
2 22222 2
22
2
11 11
2
222
1 11 11
1
2
2
2
22 111
2
1 1
22
2 22 2
1
1
1
22 2 2
2
11
1
1
2222
2
2
111 11 1
2
111
2 2
2
22 2 2 2
2
1
11
22 2
2 2 22 2
11
2 22 2 2 2
1
11
2
1 11 1
2
1 1
2 22
2 2
2 222
2
1 1 11
222 2
2 2
2
1
1
1
1
1
1
1
2
1
11 11
2
22 2
22 222 2
1
2 22
2
1
11
2 22 2
1
2
22
22
11
1
1 2 2 2 2 22
1 1
2 22 2 22 22 2 22 21
2
2 22 2
1
1
2 2
11
22
2 2 22 2
1
2 22 2 1 1 1
2
2 2
1 11
2
2 2
1
1
1
2
2
22
1
1 1 11 1 1 1
1 22 2222
22
2
2
2
1
2
2 22
1 11 1 1
1 2 2 2 2 2 2 2 2 2 22 1 1
1
2
1
1
1
1 1 2 2
2
11
2
1
1
1
2 2
1
1
11
2 2222 2 2
1
1
1
1
2
1
1
1
2 2 2
1 11
1
22 2 2
111 11 1 22
2 2
1
1
22 2 2
1
1
1
11
1
1
22
2
11
1 11 1
1 2
2 2 2
1
1 11
11
1
1
1 1
1 1
1
2 22 2 2 2
2
1 11 1 2
1
1
2
11 1
2
1 11
11 1
2
1 1
2
22 2
1 1 11
22
1
11 1
22 2
1 2
11 1 1
1
22
1111
1
2 2
2
2
1
1
2
11
11
1 1 11
11
22
1 1
1 11 1
1 1111
1 11 1
2
1
11
1
2 2222
1
22
1
1
2
1
22 1 1
1 1 1 11 111 2
1 11
11 1
1 11
1
2 2
1
1 1

Figure 9: The POL and RCB data sets
Linearly Separable 10-D (LS10) data
R:J Accuracy
Size
Hyperplanes
0:0 89.81.2 67.05.8
2756
0:20 91.51.5 55.27.0
3824
20:0 95.00.6 25.62.4
24913
20:20 97.20.7 13.93.2
30366
LMDT 99.70.2 2.20.5
9089
SADT 95.21.8 15.55.7
349067
Parallel Oblique Lines (POL) data
R:J Accuracy
Size
Hyperplanes
0:0 98.30.3 21.61.9
164
0:20 99.30.2 9.01.0
360
20:0 99.10.2 14.21.1
3230
20:20 99.60.1 5.50.3
4852
LMDT 89.610.2 41.919.2
1732
SADT 99.30.4 8.42.1
85594
Rotated Checker Board (RCB) data
R:J Accuracy
Size
Hyperplanes
0:0 98.40.2 35.51.4
573
0:20 99.30.3 19.70.8
1778
20:0 99.60.2 12.01.4
6436
20:20 99.80.1 8.70.4
11634
LMDT 95.72.3 70.19.6
2451
SADT 97.91.1 32.54.9
359112
Table 2: The effect of randomization in OC1. The first column, labelled R:J, shows the
number of restarts (R) followed by the maximum number of random jumps (J)
attempted by OC1 at each local minimum. Results with LMDT and SADT are
included for comparison after the four variants of OC1. Size is average tree size
measured by the number of leaf nodes. The third column shows the average
number of hyperplanes each algorithm considered while building one tree.
21

fiMurthy, Kasif & Salzberg

are an average of ten 5-fold CVs). The trees were not pruned for any of the algorithms,
because the data were noise-free and furthermore the emphasis was on search.
Table 2 also includes the number of hyperplanes considered by each algorithm while
building a complete tree. Note that for OC1 and SADT, the number of hyperplanes considered is generally much larger than the number of perturbations actually made, because
both these algorithms compare newly generated hyperplanes to existing hyperplanes before
adjusting an existing one. Nevertheless, this number is a good estimate of much effort
each algorithm expends, because every new hyperplane must be evaluated according to the
impurity measure. For LMDT, the number of hyperplanes considered is identical to the
actual number of perturbations.
4.3.2 Discussion

The OC1 results here are quite clear. The first line of each table, labelled 0:0, gives the
accuracies and tree sizes when no randomization is used | this variant is very similar
to the CART-LC algorithm. As we increase the use of randomization, accuracy increases
while tree size decreases, which is exactly the result we had hoped for when we decided to
introduce randomization into the method.
Looking more closely at the tables, we can ask about the effect of random jumps alone.
This is illustrated in the second line (0:20) of each table, which attempted up to 20 random
jumps at each local minimum and no restarts. Accuracy increased by 1-2% on each domain,
and tree size decreased dramatically, roughly by a factor of two, in the POL and RCB
domains. Note that because there is no noise in these domains, very high accuracies should
be expected. Thus increases of more than a few percent in accuracy are not possible.
Looking at the third line of each sub-table in Table 2, we see the effect of multiple restarts
on OC1. With 20 restarts but no random jumps to escape local minima, the improvement
is even more noticeable for the LS10 data than when random jumps alone were used. For
this data set, accuracy jumped significantly, from 89.8 to 95.0%, while tree size dropped
from 67 to 26 nodes. For the POL and RCB data, the improvements were comparable to
those obtained with random jumps. For the RCB data, tree size dropped by a factor of 3
(from 36 leaf nodes to 12 leaf nodes) while accuracy increased from 98.4 to 99.6%.
The fourth line of each table shows the effect of both the randomized steps. Among the
OC1 entries, this line has both the highest accuracies and the smallest trees for all three
data sets, so it is clear that randomization is a big win for these kinds of problems. In
addition, note that the smallest tree for the RCB data should have eight leaf nodes, and
OC1's average trees, without pruning, had just 8.7 leaf nodes. It is clear that for this data
set, which we thought was the most dicult one, OC1 came very close to finding the optimal
tree on nearly every run. (Recall that numbers in the table are the average of 10 5-fold
CV experiments; i.e., an average of 50 decision trees.) The LS10 data show how dicult it
can be to find a very simple concept in higher dimensions|the optimal tree there is just a
single hyperplane (two nodes), but OC1 was unable to find it with the current parameter
settings.8 The POL data required a minimum of 5 leaf nodes, and OC1 found this minimalsize tree most of the time, as can be seen from the table. Although not shown in the Table,
8. In a separate experiment, we found that OC1 consistently finds the linear separator for the LS10 data
when 10 restarts and 200 random jumps are used.

22

fiInduction of Oblique Decision Trees

OC1 using Sum Minority performed better for the POL data than the Twoing Rule or any
other impurity measure; i.e., it found the correct tree using less time.
The results of LMDT and SADT on this data lead to some interesting insights. Not
surprisingly, LMDT does very well on the linearly separable (LS10) data, and does not
require an inordinate amount of search. Clearly, if the data is linearly separable, one should
use a method such as LMDT or linear programming. OC1 and SADT have diculty finding
the linear separator, although in our experiments OC1 did eventually find it, given sucient
time.
On the other hand, for both of the non-linearly separable data sets, LMDT produces
much larger trees that are significantly less accurate than those produced by OC1 and
SADT. Even the deterministic variant of OC1 (using zero restarts and zero random jumps)
outperforms LMDT on these problems, with much less search.
Although SADT sometimes produces very accurate trees, its main weakness was the
enormous amount of search time it required, roughly 10-20 times greater than OC1 even
using the 20:20 setting. One explanation of OC1's advantage is its use of directed search, as
opposed to the strictly random search used by simulated annealing. Overall, Table 2 shows
that OC1's use of randomization was quite effective for the non-linearly separable data.
It is natural to ask why randomization helps OC1 in the task of inducing decision trees.
Researchers in combinatorial optimization have observed that randomized search usually
succeeds when the search space holds an abundance of good solutions (Gupta, Smolka,
& Bhaskar, 1994). Furthermore, randomization can improve upon deterministic search
when many of the local maxima in a search space lead to poor solutions. In OC1's search
space, a local maximum is a hyperplane that cannot be improved by the deterministic
search procedure, and a \solution" is a complete decision tree. If a significant fraction
of local maxima lead to bad trees, then algorithms that stop at the first local maximum
they encounter will perform poorly. Because randomization allows OC1 to consider many
different local maxima, if a modest percentage of these maxima lead to good trees, then it
has a good chance of finding one of those trees. Our experiments with OC1 thus far indicate
that the space of oblique hyperplanes usually contains numerous local maxima, and that a
substantial percentage of these locally good hyperplanes lead to good decision trees.

5. Conclusions and Future Work
This paper has described OC1, a new system for constructing oblique decision trees. We
have shown experimentally that OC1 can produce good classifiers for a range of real-world
and artificial domains. We have also shown how the use of randomization improves upon
the original algorithm proposed by Breiman et al. (1984), without significantly increasing
the computational cost of the algorithm.
The use of randomization might also be beneficial for axis-parallel tree methods. Note
that although they do find the optimal test (with respect to an impurity measure) for each
node of a tree, the complete tree may not be optimal: as is well known, the problem of
finding the smallest tree is NP-Complete (Hyafil & Rivest, 1976). Thus even axis-parallel
decision tree methods do not produce \ideal" decision trees. Quinlan has suggested that his
windowing algorithm might be used as a way of introducing randomization into C4.5, even
though the algorithm was designed for another purpose (Quinlan, 1993a). (The windowing
23

fiMurthy, Kasif & Salzberg

algorithm selects a random subset of the training data and builds a tree using that.) We
believe that randomization is a powerful tool in the context of decision trees, and our
experiments are just one example of how it might be exploited. We are in the process of
conducting further experiments to quantify more accurately the effects of different forms of
randomization.
It should be clear that the ability to produce oblique splits at a node broadens the capabilities of decision tree algorithms, especially as regards domains with numeric attributes.
Of course, axis-parallel splits are simpler, in the sense that the description of the split only
uses one attribute at each node. OC1 uses oblique splits only when their impurity is less
than the impurity of the best axis-parallel split; however, one could easily penalize the
additional complexity of an oblique split further. This remains an open area for further
research. A more general point is that if the domain is best captured by a tree that uses
oblique hyperplanes, it is desirable to have a system that can generate that tree. We have
shown that for some problems, including those used in our experiments, OC1 builds small
decision trees that capture the domain well.

Appendix A. Complexity Analysis of OC1

In the following, we show that OC1 runs eciently even in the worst case. For a data
set with n examples (points) and d attributes per example, OC1 uses at most O(dn2 log n)
time. We assume n > d for our analysis.
For the analysis here, we assume the coecients of a hyperplane are adjusted in sequential order (the Seq method described in the paper). The number of restarts at a node will
be r, and the number of random jumps tried will be j . Both r and j are constants, fixed in
advance of running the algorithm.
Initializing the hyperplane to a random position takes just O(d) time. We need to
consider first the maximum amount of work OC1 can do before it finds a new location for
the hyperplane. Then we need to consider how many times it can move the hyperplane.
1. Attempting to perturb the first coecient (a1 ) takes O(dn + n log n) time. Computing
Ui 's for all the points (equation 2) requires O(dn) time, and sorting the Ui 's takes
O(n log n). This gives us O(dn + n log n) work.
2. If perturbing a1 does not improve things, we try to perturb a2 . Computing all the new
Ui 's will take just O(n) time because only one term is different for each Ui . Re-sorting
will take O(n log n), so this step takes O(n) + O(n log n) = O(n log n) time.
3. Likewise a3; : : :; ad will each take O(n log n) additional time, assuming we still have not
found a better hyperplane after checking each coecient. Thus the total time to cycle
through and attempt to perturb all these additional coecients is (d , 1)  O(n log n) =
O(dn log n).
4. Summing up, the time to cycle through all coecients is O(dn log n)+O(dn+n log n) =
O(dn log n).
5. If none of the coecients improved the split, then we attempt to make up to j random
jumps. Since j is a constant, we will just consider j = 1 for our analysis. This step
24

fiInduction of Oblique Decision Trees

involves choosing a random vector and running the perturbation algorithm to solve
for ff, as explained in Section 3.2. As before, we need to compute a set of Ui 's and sort
them, which takes O(dn + n log n) time. Because this amount of time is dominated by
the time to adjust all the coecients, the total time so far is still O(dn log n). This is
the most time OC1 can spend at a node before either halting or finding an improved
hyperplane.
6. Assuming OC1 is using the Sum Minority or Max Minority error measure, it can only
reduce the impurity of the hyperplane n times. This is clear because each improvement
means one more example will be correctly classified by the new hyperplane. Thus the
total amount of work at a node is limited to n  O(dn log n) = O(dn2 log n). (This
analysis extends, with at most linear cost factors, to Information Gain, Gini Index and
Twoing Rule when there are two categories. It will not apply to a measure that, for
example, uses the distances of mis-classified objects to the hyperplane.) In practice,
we have found that the number of improvements per node is much smaller than n.
Assuming that OC1 only adjusts a hyperplane when it improves the impurity measure,
it will do O(dn2 log n) work in the worst case.
However, OC1 allows a certain number of adjustments to the hyperplane that do not
improve the impurity, although it will never accept a change that worsens the impurity.
The number allowed is determined by a constant known as \stagnant-perturbations". Let
this value be s. This works as follows.
Each time OC1 finds a new hyperplane that improves on the old one, it resets a counter
to zero. It will move the new hyperplane to a different location that has equal impurity at
most s times. After each of these moves it repeats the perturbation algorithm. Whenever
impurity is reduced, it re-starts the counter and again allows s moves to equally good
locations. Thus it is clear that this feature just increases the worst-case complexity of OC1
by a constant factor, s.
Finally, note that the overall cost of OC1 is also O(dn2 log n), i.e., this is an upper
bound on the total running time of OC1 independent of the size of the tree it ends up
creating. (This upper bound applies to Sum Minority and Max Minority; an open question
is whether a similar upper bound can be proven for Information Gain or the Gini Index.)
Thus the worst-case asymptotic complexity of our system is comparable to that of systems
that construct axis-parallel decision trees, which have O(dn2 ) worst-case complexity. To
sketch the intuition that leads to this bound, let G be the total impurity summed over all
leaves in a partially constructed tree (i.e., the sum of currently misclassified points in the
tree). Now observe that each time we run the perturbation algorithm on any node in the
tree, we either halt or improve G by at least one unit. The worst-case analysis for one node
is realized when the perturbation algorithm is run once for every one of the n examples,
but when this happens, there would no longer be any mis-classified examples and the tree
would be complete.

Appendix B. Definitions of impurity measures available in OC1

In addition to the Twoing Rule defined in the text, OC1 contains built-in definitions of five
additional impurity measures, defined as follows. In each of the following definitions, the
25

fiMurthy, Kasif & Salzberg

set of examples T at the node about to be split contains n (> 0) instances that belong to
one of k categories. (Initially this set is the entire training set.) A hyperplane H divides T
into two non-overlapping subsets TL and TR (i.e., left and right). Lj and Rj are the number
of instances of category j in TL and TR respectively. All the impurity measures initially
check to see if TL and TR are homogeneous (i.e., all examples belong to the same category),
and if so return minimum (zero) impurity.

Information Gain. This measure of information gained from a particular split was pop-

ularized in the context of decision trees by Quinlan (1986). Quinlan's definition makes
information gain a goodness measure; i.e., something to maximize. Because OC1 attempts
to minimize whatever impurity measure it uses, we use the reciprocal of the standard value
of information gain in the OC1 implementation.

Gini Index. The Gini Criterion (or Index) was proposed for decision trees by Breiman et
al. (1984). The Gini Index as originally defined measures the probability of misclassification
of a set of instances, rather than the impurity of a split. We implement the following
variation:
GiniL = 1:0 ,
GiniR = 1:0 ,

k
X
i=1
k
X
i=1

(Li =jTLj)2
(Ri=jTRj)2

Impurity = (jTLj  GiniL + jTRj  GiniR)=n
where GiniL is the Gini Index on the \left" side of the hyperplane and GiniR is that on the
right.

Max Minority. The measures Max Minority, Sum Minority and Sum Of Variances were

defined in the context of decision trees by Heath, Kasif, and Salzberg (1993b).9 Max
Minority has the theoretical advantage that a tree built minimizing this measure will have
depth at most log n. Our experiments indicated that this is not a great advantage in
practice: seldom do other impurity measures produce trees substantially deeper than those
produced with Max Minority. The definition is:
MinorityL =
MinorityR =

k
X
i=1;i6=max Li
k
X
i=1;i6=max Ri

Li
Ri

Max Minority = max(MinorityL; MinorityR)
9. Sum Of Variances was called Sum of Impurities by Heath et al.

26

fiInduction of Oblique Decision Trees

Sum Minority. This measure is very similar to Max Minority. If MinorityL and MinorityR are defined as for the Max Minority measure, then Sum Minority is just the sum of
these two values. This measure is the simplest way of quantifying impurity, as it simply
counts the number of misclassified instances.
Though Sum Minority performs well on some domains, it has some obvious aws. As
one example, consider a domain in which n = 100; d = 1, and k = 2 (i.e., 100 examples, 1
numeric attribute, 2 classes). Suppose that when the examples are sorted according to the
single attribute, the first 50 instances belong to category 1, followed by 24 instances of category 2, followed by 26 instances of category 1. Then all possible splits for this distribution
have a sum minority of 24. Therefore it is impossible when using Sum Minority to distinguish which split is preferable, although splitting at the alternations between categories is
clearly better.
Sum Of Variances. The definition of this measure is:
jX
TL j
jX
TL j
VarianceL = (Cat(TLi ) , Cat(TLj )=jTLj)2
VarianceR =

i=1

j =1

jX
TRj

jX
TRj

i=1

(Cat(TRi ) ,

j =1

Cat(TRj )=jTRj)2

Sum of Variances = VarianceL + VarianceR
where Cat(Ti) is the category of instance Ti . As this measure is computed using the actual
class labels, it is easy to see that the impurity computed varies depending on how numbers
are assigned to the classes. For instance, if T1 consists of 10 points of category 1 and 3
points of category 2, and if T2 consists of 10 points of category 1 and 3 points of category
5, then the Sum Of Variances values are different for T1 and T2. To avoid this problem,
OC1 uniformly reassigns category numbers according to the frequency of occurrence of each
category at a node before computing the Sum Of Variances.

Acknowledgements
The authors thank Richard Beigel of Yale University for suggesting the idea of jumping in a
random direction. Thanks to Wray Buntine of Nasa Ames Research Center for providing the
IND 2.1 package, to Carla Brodley for providing the LMDT code, and to David Heath for
providing the SADT code and for assisting us in using it. Thanks also to three anonymous
reviewers for many helpful suggestions. This material is based upon work supported by the
National Science foundation under Grant Nos. IRI-9116843, IRI-9223591, and IRI-9220960.

References
Aha, D. (1990). A Study of Instance-Based Algorithms for Supervised Learning: Mathematical, empirical and psychological evaluations. Ph.D. thesis, Department of Information
and Computer Science, University of California, Irvine.
27

fiMurthy, Kasif & Salzberg

Almuallin, H., & Dietterich, T. (1991). Learning with many irrelevant features. In Proceedings of the Ninth National Conference on Artificial Intelligence, pp. 547{552. San
Jose, CA.
Belsley, D. (1980). Regression Diagnostics: Identifying Inuential Data and Sources of
Collinearity. Wiley & Sons, New York.
Bennett, K., & Mangasarian, O. (1992). Robust linear programming discrimination of two
linearly inseparable sets. Optimization Methods and Software, 1, 23{34.
Bennett, K., & Mangasarian, O. (1994a). Multicategory discrimination via linear programming. Optimization Methods and Software, 3, 29{39.
Bennett, K., & Mangasarian, O. (1994b). Serial and parallel multicategory discrimination.
SIAM Journal on Optimization, 4 (4).
Blum, A., & Rivest, R. (1988). Training a 3-node neural network is NP-complete. In Proceedings of the 1988 Workshop on Computational Learning Theory, pp. 9{18. Boston,
MA. Morgan Kaufmann.
Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification and Regression
Trees. Wadsworth International Group.
Brent, R. P. (1991). Fast training algorithms for multilayer neural nets. IEEE Transactions
on Neural Networks, 2 (3), 346{354.
Brodley, C. E., & Utgoff, P. E. (1992). Multivariate versus univariate decision trees. Tech.
rep. COINS CR 92-8, Dept. of Computer Science, University of Massachusetts at
Amherst.
Brodley, C. E., & Utgoff, P. E. (1994). Multivariate decision trees. Machine Learning, to
appear.
Buntine, W. (1992). Tree classification software. Technology 2002: The Third National
Technology Transfer Conference and Exposition.
Buntine, W., & Niblett, T. (1992). A further comparison of splitting rules for decision-tree
induction. Machine Learning, 8, 75{85.
Cardie, C. (1993). Using decision trees to improve case-based learning. In Proceedings of
the Tenth International Conference on Machine Learning, pp. 25{32. University of
Massachusetts, Amherst.
Cestnik, G., Kononenko, I., & Bratko, I. (1987). Assistant 86: A knowledge acquisition
tool for sophisticated users. In Bratko, I., & Lavrac, N. (Eds.), Progress in Machine
Learning. Sigma Press.
Cios, K. J., & Liu, N. (1992). A machine learning method for generation of a neural network
architecture: A continuous ID3 algorithm. IEEE Transactions on Neural Networks,
3 (2), 280{291.
28

fiInduction of Oblique Decision Trees

Cohen, W. (1993). Ecient pruning methods for separate-and-conquer rule learning systems. In Proceedings of the 13th International Joint Conference on Artificial Intelligence, pp. 988{994. Morgan Kaufmann.
Fayyad, U. M., & Irani, K. B. (1992). The attribute specification problem in decision tree
generation. In Proceedings of the Tenth National Conference on Artificial Intelligence,
pp. 104{110. San Jose CA. AAAI Press.
Frean, M. (1990). Small Nets and Short Paths: Optimising neural computation. Ph.D.
thesis, Centre for Cognitive Science, University of Edinburgh.
Gupta, R., Smolka, S., & Bhaskar, S. (1994). On randomization in sequential and distributed
algorithms. ACM Computing Surveys, 26 (1), 7{86.
Hampson, S., & Volper, D. (1986). Linear function neurons: Structure and training. Biological Cybernetics, 53, 203{217.
Harrison, D., & Rubinfeld, D. (1978). Hedonic prices and the demand for clean air. Journal
of Environmental Economics and Management, 5, 81{102.
Hassibi, B., & Stork, D. (1993). Second order derivatives for network pruning: optimal
brain surgeon. In Advances in Neural Information Processing Systems 5, pp. 164{171.
Morgan Kaufmann, San Mateo, CA.
Heath, D. (1992). A Geometric Framework for Machine Learning. Ph.D. thesis, Johns
Hopkins University, Baltimore, Maryland.
Heath, D., Kasif, S., & Salzberg, S. (1993a). k-DT: A multi-tree learning method. In
Proceedings of the Second International Workshop on Multistrategy Learning, pp. 138{
149. Harpers Ferry, WV. George Mason University.
Heath, D., Kasif, S., & Salzberg, S. (1993b). Learning oblique decision trees. In Proceedings
of the 13th International Joint Conference on Artificial Intelligence, pp. 1002{1007.
Chambery, France. Morgan Kaufmann.
Herman, G. T., & Yeung, K. D. (1992). On piecewise-linear classification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 14 (7), 782{786.
Holte, R. (1993). Very simple classification rules perform well on most commonly used
datasets. Machine Learning, 11 (1), 63{90.
Hyafil, L., & Rivest, R. L. (1976). Constructing optimal binary decision trees is NPcomplete. Information Processing Letters, 5 (1), 15{17.
Kira, K., & Rendell, L. (1992). A practical approach to feature selection. In Proceedings
of the Ninth International Conference on Machine Learning, pp. 249{256. Aberdeen,
Scotland. Morgan Kaufmann.
Kirkpatrick, S., Gelatt, C., & Vecci, M. (1983). Optimization by simulated annealing.
Science, 220 (4598), 671{680.
29

fiMurthy, Kasif & Salzberg

Kodratoff, Y., & Manago, M. (1987). Generalization and noise. International Journal of
Man-Machine Studies, 27, 181{204.
Langley, P., & Sage, S. (1993). Scaling to domains with many irrelevant features. Learning
Systems Department, Siemens Corporate Research, Princeton, NJ.
Mangasarian, O., Setiono, R., & Wolberg, W. (1990). Pattern recognition via linear programming: Theory and application to medical diagnosis. In SIAM Workshop on
Optimization.
Mingers, J. (1989a). An empirical comparison of pruning methods for decision tree induction. Machine Learning, 4 (2), 227{243.
Mingers, J. (1989b). An empirical comparison of selection measures for decision tree induction. Machine Learning, 3, 319{342.
Moret, B. M. (1982). Decision trees and diagrams. Computing Surveys, 14 (4), 593{623.
Murphy, P., & Aha, D. (1994). UCI repository of machine learning databases { a machinereadable data repository. Maintained at the Department of Information and Computer
Science, University of California, Irvine. Anonymous FTP from ics.uci.edu in the
directory pub/machine-learning-databases.
Murthy, S. K., Kasif, S., Salzberg, S., & Beigel, R. (1993). OC1: Randomized induction of
oblique decision trees. In Proceedings of the Eleventh National Conference on Artificial
Intelligence, pp. 322{327. Washington, D.C. MIT Press.
Murthy, S. K., & Salzberg, S. (1994). Using structure to improve decision trees. Tech. rep.
JHU-94/12, Department of Computer Science, Johns Hopkins University.
Niblett, T. (1986). Constructing decision trees in noisy domains. In Bratko, I., & Lavrac,
N. (Eds.), Progress in Machine Learning. Sigma Press, England.
Nilsson, N. (1990). Learning Machines. Morgan Kaufmann, San Mateo, CA.
Odewahn, S., Stockwell, E., Pennington, R., Humphreys, R., & Zumach, W. (1992). Automated star-galaxy descrimination with neural networks. Astronomical Journal,
103 (1), 318{331.
Pagallo, G. (1990). Adaptive Decision Tree Algorithms for Learning From Examples. Ph.D.
thesis, University of California at Santa Cruz.
Pagallo, G., & Haussler, D. (1990). Boolean feature discovery in empirical learning. Machine
Learning, 5 (1), 71{99.
Quinlan, J. R. (1983). Learning ecient classification procedures and their application to
chess end games. In Michalski, R., Carbonell, J., & Mitchell, T. (Eds.), Machine
Learning: An Artificial Intelligence Approach. Morgan Kaufmann, San Mateo, CA.
Quinlan, J. R. (1986). Induction of decision trees. Machine Learning, 1, 81{106.
30

fiInduction of Oblique Decision Trees

Quinlan, J. R. (1987). Simplifying decision trees. International Journal of Man-Machine
Studies, 27, 221{234.
Quinlan, J. R. (1993a). C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, San Mateo, CA.
Quinlan, J. R. (1993b). Combining instance-based and model-based learning. In Proceedings
of the Tenth International Conference on Machine Learning, pp. 236{243 University
of Massachusetts, Amherst. Morgan Kaufmann.
Roth, R. H. (1970). An approach to solving linear discrete optimization problems. Journal
of the ACM, 17 (2), 303{313.
Safavin, S. R., & Landgrebe, D. (1991). A survey of decision tree classifier methodology.
IEEE Transactions on Systems, Man and Cybernetics, 21 (3), 660{674.
Sahami, M. (1993). Learning non-linearly separable boolean functions with linear threshold unit trees and madaline-style networks. In Proceedings of the Eleventh National
Conference on Artificial Intelligence, pp. 335{341. AAAI Press.
Salzberg, S. (1991). A nearest hyperrectangle learning method. Machine Learning, 6,
251{276.
Salzberg, S. (1992). Combining learning and search to create good classifiers. Tech. rep.
JHU-92/12, Johns Hopkins University, Baltimore MD.
Salzberg, S., Chandar, R., Ford, H., Murthy, S. K., & White, R. (1994). Decision trees for
automated identification of cosmic rays in Hubble Space Telescope images. Publications of the Astronomical Society of the Pacific, to appear.
Schaffer, C. (1993). Overfitting avoidance as bias. Machine Learning, 10, 153{178.
Schlimmer, J. (1993). Eciently inducing determinations: A complete and systematic
search algorithm that uses optimal pruning. In Proceedings of the Tenth International
Conference on Machine Learning, pp. 284{290. Morgan Kaufmann.
Smith, J., Everhart, J., Dickson, W., Knowler, W., & Johannes, R. (1988). Using the
ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings
of the Symposium on Computer Applications and Medical Care, pp. 261{265. IEEE
Computer Society Press.
Utgoff, P. E. (1989). Perceptron trees: A case study in hybrid concept representations.
Connection Science, 1 (4), 377{391.
Utgoff, P. E., & Brodley, C. E. (1990). An incremental method for finding multivariate
splits for decision trees. In Proceedings of the Seventh International Conference on
Machine Learning, pp. 58{65. Los Altos, CA. Morgan Kaufmann.
Utgoff, P. E., & Brodley, C. E. (1991). Linear machine decision trees. Tech. rep. 10,
University of Massachusetts at Amherst.
31

fiMurthy, Kasif & Salzberg

Van de Merckt, T. (1992). NFDT: A system that learns exible concepts based on decision
trees for numerical attributes. In Proceedings of the Ninth International Workshop on
Machine Learning, pp. 322{331.
Van de Merckt, T. (1993). Decision trees in numerical attribute spaces. In Proceedings of
the 13th International Joint Conference on Artificial Intelligence, pp. 1016{1021.
Weiss, S., & Kapouleas, I. (1989). An empirical comparison of pattern recognition, neural
nets, and machine learning classification methods. In Proceedings of the 11th International Joint Conference of Artificial Intelligence, pp. 781{787. Detroit, MI. Morgan
Kaufmann.
Wolpert, D. (1992). On overfitting avoidance as bias. Tech. rep. SFI TR 92-03-5001, The
Santa Fe Institute, Santa Fe, New Mexico.

32

fiJournal of Artificial Intelligence Research 2 (1995) 501-539

Submitted 9/94; published 5/95

Pac-Learning Recursive Logic Programs:
Ecient Algorithms
William W. Cohen

AT&T Bell Laboratories
600 Mountain Avenue, Murray Hill, NJ 07974 USA

wcohen@research.att.com

Abstract

We present algorithms that learn certain classes of function-free recursive logic programs in polynomial time from equivalence queries. In particular, we show that a single
k-ary recursive constant-depth determinate clause is learnable. Two-clause programs consisting of one learnable recursive clause and one constant-depth determinate non-recursive
clause are also learnable, if an additional \basecase" oracle is assumed. These results immediately imply the pac-learnability of these classes. Although these classes of learnable
recursive programs are very constrained, it is shown in a companion paper that they are
maximally general, in that generalizing either class in any natural way leads to a computationally dicult learning problem. Thus, taken together with its companion paper, this
paper establishes a boundary of ecient learnability for recursive logic programs.

1. Introduction
One active area of research in machine learning is learning concepts expressed in firstorder logic. Since most researchers have used some variant of Prolog to represent learned
concepts, this subarea is sometimes called inductive logic programming (ILP) (Muggleton,
1992; Muggleton & De Raedt, 1994).
Within ILP, researchers have considered two broad classes of learning problems. The
first class of problems, which we will call here logic based relational learning problems,
are first-order variants of the sorts of classification problems typically considered within
AI machine learning community: prototypical examples include Muggleton et al.'s (1992)
formulation of ff-helix prediction, King et al.'s (1992) formulation of predicting drug activity, and Zelle and Mooney's (1994) use of ILP techniques to learn control heuristics for
deterministic parsers. Logic-based relational learning often involves noisy examples that reect a relatively complex underlying relationship; it is a natural extension of propositional
machine learning, and has already enjoyed a number of experimental successes.
In the second class of problems studied by ILP researchers, the target concept is a Prolog
program that implements some common list-processing or arithmetic function; prototypical
problems from this class might be learning to append two lists, or to multiply two numbers.
These learning problems are similar in character to those studied in the area of automatic
programming from examples (Summers, 1977; Biermann, 1978), and hence might be appropriately called automatic logic programming problems. Automatic logic programming
problems are characterized by noise-free training data and recursive target concepts. Thus a
problem that is central to the enterprise of automatic logic programming|but not, perhaps,
logic-based relational learning|is the problem of learning recursive logic programs.
c 1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiCohen

The goal of this paper is to formally analyze the learnability of recursive logic programs
in Valiant's (1984) model of pac-learnability, thus hopefully shedding some light on the
task of automatic logic programming. To summarize our results, we will show that some
simple recursive programs are pac-learnable from examples alone, or from examples plus a
small number of additional \hints". The largest learnable class we identify in a standard
learning model is the class of one-clause constant-depth determinate programs with at most
a constant number of \closed" recursive literals. The largest learnable class we identify
that requires extra \hints" is the class of constant-depth determinate programs consisting
of a single nonrecursive base clause and a single recursive clause from the class described
above. All of our results are proved in the model of identification from equivalence queries
(Angluin, 1988, 1989), which is somewhat stronger than pac-learnability. Identification from
equivalence queries requires that the target concept be exactly identified, in polynomial
time, and using only a polynomial number of equivalence queries . An equivalence query
asks if a hypothesis program H is equivalent to the target program C ; the answer to a
query is either \yes" or an adversarily chosen example on which H and C differ. This
model of learnability is arguably more appropriate for automatic logic programming tasks
than the weaker model of pac-learnability, as it is unclear how often an approximately
correct recursive program will be useful.
Interestingly, the learning algorithms analyzed are different from most existing ILP
learning methods; they all employ an unusual method of generalizing examples called forced
simulation . Forced simulation is a simple and analytically tractable alternative to other
methods for generalizing recursive programs against examples, such as n-th root finding
(Muggleton, 1994), sub-unification (Aha, Lapointe, Ling, & Matwin, 1994) and recursive
anti-unification (Idestam-Almquist, 1993), but it has been only rarely used in experimental
ILP systems (Ling, 1991).
The paper is organized as follows. After presenting some preliminary definitions, we
begin by presenting (primarily for pedagogical reasons) a procedure for identifying from
equivalence queries a single non-recursive constant-depth determinate clause. Then, in
Section 4, we extend this learning algorithm, and the corresponding proof of correctness,
to a simple class of recursive clauses: the class of \closed" linear recursive constant-depth
determinate clauses. In Section 5, we relax some assumptions made to make the analysis
easier, and present several extensions to this algorithm: we extend the algorithm from linear
recursion to k-ary recursion, and also show how a k-ary recursive clause and a non-recursive
clause can be learned simultaneously given an additional \basecase" oracle. We then discuss
related work and conclude.
Although the learnable class of programs is large enough to include some well-known
automatic logic programming benchmarks, it is extremely restricted. In a companion paper
(Cohen, 1995), we provide a number of negative results, showing that relaxing any of these
restrictions leads to dicult learning problems: in particular, learning problems that are
either as hard as learning DNF (an open problem in computational learning theory), or as
hard as cracking certain presumably secure cryptographic schemes. Thus, taken together
with the results of the companion paper, our results delineate a boundary of learnability
for recursive logic programs.
Although the two papers are independent, we suggest that readers wishing to read both
this paper and the companion paper read this paper first.
502

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

2. Background

In this section we will present the technical background necessary to state our results. We
will assume, however, that the reader is familiar with the basic elements of logic programming; readers without this background are referred to one of the standard texts, for example
(Lloyd, 1987).

2.1 Logic Programs

Our treatment of logic programs is standard, except that we will usually consider the body
of a clause to be an ordered set of literals.
For most of this paper, we will consider logic programs without function symbols|
i.e., programs written in Datalog.1 The purpose of such a logic program is to answer
certain questions relative to a database , DB , which is a set of ground atomic facts. (When
convenient, we will also think of DB as a conjunction of ground unit clauses.) The simplest
use of a Datalog program is to check the status of a simple instance . A simple instance
(for a program P and a database DB ) is a fact f . The pair (P; DB ) is said to cover f iff
DB ^ P ` f . The set of simple instances covered by (P; DB ) is precisely the minimal model
of the logic program P ^ DB .
In this paper, we will primarily consider extended instances which consist of two parts:
an instance fact f , which is simply a ground fact, and a description D, which is a finite set
of ground unit clauses. An extended instance e = (f; D) is covered by (P; DB ) iff
DB ^ D ^ P ` f

If extended instances are allowed, then function-free programs are expressive enough to
encode surprisingly interesting programs. In particular, many programs that are usually
written with function symbols can be re-written as function-free programs, as the example
below illustrates.

Example. Consider the usual program for appending two lists.
append([],Ys,Ys).
append([XjXs1],Ys,[XjZs1])

append(Xs1,Ys,Zs1).

One could use this program to classify atomic facts containing function symbols
such as append([1,2],[3],[1,2,3]). This program can be rewritten as a Datalog
program that classifies extended instances as follows:

Program P :

append(Xs,Ys,Ys)
null(Xs).
append(Xs,Ys,Zs)
components(Xs,X,Xs1) ^
components(Zs,X,Zs1) ^
1. This assumption is made primarily for convenience. In Section 5.2 we describe how this assumption can
be relaxed.

503

fiCohen

append(Xs1,Ys,Zs1).

Database DB :
null(nil).

The predicate components(A,B,C) means that A is a list with head B and tail
C; thus an extended instance equivalent to append([1,2],[3],[1,2,3]) would be

Instance fact f :

append(list12,list3,list123).

Description D:

components(list12,1,list2).
components(list2,2,nil).
components(list123,1,list23).
components(list23,2,list3).
components(list3,3,nil).
We note that using extended instances as examples is closely related to using ground
clauses entailed by the target clause as examples: specifically, the instance e = (f; D) is
covered by P; DB iff P ^ DB ` (f D). As the example above shows, there is also a close
relationship between extended instances and literals with function symbols that have been
removed by \attening" (Rouveirol, 1994; De Raedt & Dzeroski, 1994). We have elected
to use Datalog programs and the model of extended instances in this paper for several
reasons. Datalog is relatively easy to analyze. There is a close connection between Datalog
and the restrictions imposed by certain practical learning systems, such FOIL (Quinlan,
1990; Quinlan & Cameron-Jones, 1993), FOCL (Pazzani & Kibler, 1992), and GOLEM
(Muggleton & Feng, 1992).
Finally, using extended instances addresses the following technical problem. The learning problems considered in this paper involve restricted classes of logic programs. Often, the
restrictions imply that the number of simple instances is polynomial; we note that with only
a polynomial-size domain, questions about pac-learnability are usually trivial. Requiring
learning algorithms to work over the domain of extended instances precludes trivial learning
techniques, however, as the number of extended instances of size n is exponential in n even
for highly restricted programs.

2.2 Restrictions on Logic Programs

In this paper, we will consider the learnability of various restricted classes of logic programs. Below we will define some of these restrictions; however, we will first introduce
some terminology.
If A B1 ^ : : : ^ Br is an (ordered) definite clause, then the input variables of the literal
Bi are those variables appearing in Bi which also appear in the clause A B1 ^ : : : ^ Bi,1 ;
all other variables appearing in Bi are called output variables . Also, if A B1 ^ : : : ^ Br is a
definite clause, then Bi is said to be a recursive literal if it has the same predicate symbol
and arity as A, the head of the clause.
504

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

2.2.1 Types of Recursion

The first set of restrictions concern the type of recursion that is allowed in a program.
If every clause in a program has at most one recursive literal, then the program is linear
recursive . If every clause in a program has at most k recursive literals, then the program is
k-ary recursive . Finally, if every recursive literal in a program contains no output variables,
then we will say that the program is closed recursive.
2.2.2 Determinacy and Depth

The second set of restrictions are variants of restrictions originally introduced by Muggleton
and Feng (1992). If A B1 ^ : : : ^ Br is an (ordered) definite clause, the literal Bi is
determinate iff for every possible substitution  that unifies A with some fact e such that
DB ` B1  ^ : : : ^ Bi,1 

there is at most one maximal substitution  so that DB ` Bi . A clause is determinate
if all of its literals are determinate. Informally, determinate clauses are those that can be
evaluated without backtracking by a Prolog interpreter.
We also define the depth of a variable appearing in a clause A B1 ^ : : : ^ Br as follows.
Variables appearing in the head of a clause have depth zero. Otherwise, let Bi be the first
literal containing the variable V , and let d be the maximal depth of the input variables of
Bi ; then the depth of V is d +1. The depth of a clause is the maximal depth of any variable
in the clause.
Muggleton and Feng define a logic program to be ij -determinate if it is is determinate,
of constant depth i, and contains literals of arity j or less. In this paper we use the phrase
\constant-depth determinate" instead to denote this class of programs. Below are some
examples of constant-depth determinate programs, taken from Dzeroski, Muggleton and
Russell (1992).

Example. Assuming successor is functional, the following program is determinate. The maximum depth of a variable is one, for the variable C in the second
clause, and hence the program is of depth one.
less than(A,B)
less than(A,B)

successor(A,B).
successor(A,C) ^ less than(C,B).
!
A
The following program, which computes C , is determinate and of depth
two.
choose(A,B,C)
zero(B) ^
one(C).
choose(A,B,C)
decrement(B,D) ^
decrement(A,E) ^
505

fiCohen

multiply(B,C,G) ^
divide(G,A,F) ^
choose(E,D,F).
The program GOLEM (Muggleton & Feng, 1992) learns constant-depth determinate
programs, and related restrictions have been adopted by several other practical learning
systems (Quinlan, 1991; Lavrac & Dzeroski, 1992; Cohen, 1993c). The learnability of
constant-depth determinate clauses has also received some formal study, which we will
review in Section 6.
2.2.3 Mode Constraints and Declarations

We define the mode of a literal L appearing in a clause C to be a string s such that the initial
character of s is the predicate symbol of L, and for j > 1 the j -th character of s is a \+" if
the (j , 1)-th argument of L is an input variable and a \," if the (j , 1)-th argument of L
is an output variable. (This definition coincides with the usual definition of Prolog modes
only when all arguments to the head of a clause are inputs. This simplification is justified,
however, as we are considering only how clauses behave in classifying extended instances,
which are ground.) A mode constraint is simply a set of mode strings R = fs1 ; : : :; sk g, and
a clause C is said to satisfy a mode constraint R for p if for every literal L in the body of
C , the mode of L is in R.

Example. In the following append program, every literal has been annotated
with its mode.

append(Xs,Ys,Ys)
null(Xs).
append(Xs,Ys,Zs)
components(Xs,X,Xs1) ^
components(Zs,X,Zs1) ^
append(Xs1,Ys,Zs1).

% mode: null+
% mode: components + ,,
% mode: components + +,
% mode: append + ++

The clauses of this program satisfy the following mode constraint:
f components + ,,; components + +,; components + ,+;
components , ++; components + ++; null +
append + +,;
append + ,+;
append , ++;
append + ++
g
Mode constraints are commonly used in analyzing Prolog code; for instance, they are
used in many Prolog compilers. We will sometimes use an alternative syntax for mode
constraints that parallels the syntax used in most Prolog systems: for instance, we may
write the mode constraint \components + ,," as \components (+; ,; ,)".
We define a declaration to be a tuple (p; a0; R) where p is a predicate symbol, a0 is an
integer, and R is a mode constraint. We will say that a clause C satisfies a declaration if
the head of C has arity a0 and predicate symbol p, and if for every literal L in the body of
C the mode of L appears in R.
506

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

2.3 A Model of Learnability

In this section, we will present our model of learnability. We will first review the necessary
definitions for a standard learning model, the model of learning from equivalence queries
(Angluin, 1988, 1989), and discuss its relationship to other learning models. We will then
introduce an extension to this model which is necessary for analyzing ILP problems.
2.3.1 Identification From Equivalence Queries

Let X be a set. We will call X the domain , and call the elements of X instances . Define a
concept C over X to be a representation of some subset of X , and define a language Lang
to be a set of concepts. In this paper, we will be rather casual about the distinction between
a concept and the set it represents; when there is a risk of confusion we will refer to the set
represented by a concept C as the extension of C . Two concepts C1 and C2 with the same
extension are said to be (semantically) equivalent .
Associated with X and Lang are two size complexity measures , for which we will use
the following notation:

 The size complexity of a concept C 2 Lang is written j C j .
 The size complexity of an instance e 2 X is written j ej .
 If S is a set, Sn stands for the set of all elements of S of size complexity no greater
than n. For instance, Xn = fe 2 X : j ej  ng and Langn = fC 2 Lang : j C j  ng.
We will assume that all size measures are polynomially related to the number of bits needed
to represent C or e.
The first learning model that we consider is the model of identification with equivalence
queries . The goal of the learner is to identify some unknown target concept C 2 Lang|
that is, to construct some hypothesis H 2 Lang such that H  C . Information about the
target concept is gathered only through equivalence queries . The input to an equivalence
query for C is some hypothesis H 2 Lang. If H  C , then the response to the query is
\yes". Otherwise, the response to the query is an arbitrarily chosen counterexample |an
instance e that is in the symmetric difference of C and H .
A deterministic algorithm Identify identifies Lang from equivalence queries iff for
every C 2 Lang, whenever Identify is run (with an oracle answering equivalence queries
for C ) it eventually halts and outputs some H 2 Lang such that H  C . Identify
polynomially identifies Lang from equivalence queries iff there is a polynomial poly (nt; ne )
such that at any point in the execution of Identify the total running time is bounded by
poly (nt ; ne ), where nt = j C j and ne is the size of the largest counterexample seen so far, or
0 if no equivalence queries have been made.
2.3.2 Relation to Pac-Learnability

The model of identification from equivalence queries has been well-studied (Angluin, 1988,
1989). It is known that if a language is learnable in this model, then it is also learnable
in Valiant's (1984) model of pac-learnability. (The basic idea behind this result is that
an equivalence query for the hypothesis H can be emulated by drawing a set of random
507

fiCohen

examples of a certain size. If any of them is a counterexample to H , then one returns
the found counterexample as the answer to the equivalence query. If no counterexamples
are found, one can assume with high confidence that H is approximately equivalent to the
target concept.) Thus identification from equivalence queries is a strictly stronger model
than pac-learnability.
Most existing positive results on the pac-learnability of logic programs rely on showing
that every concept in the target language can be emulated by a boolean concept from
some pac-learnable class (Dzeroski et al., 1992; Cohen, 1994). While such results can be
illuminating, they are also disappointing, since one of the motivations for considering firstorder representations in the first place is that they allow one to express concepts that cannot
be easily expressed in boolean logic. One advantage of studying the exact identification
model and considering recursive programs is that it essentially precludes use of this sort of
proof technique: while many recursive programs can be approximated by boolean functions
over a fixed set of attributes, few can be be exactly emulated by boolean functions.
2.3.3 Background Knowledge in Learning

The framework described above is standard, and is one possible formalization of the usual
situation in inductive concept learning, in which a user provides a set of examples (in
this case counterexamples to queries) and the learning system attempts to find a useful
hypothesis. However, in a typical ILP system, the setting is slightly different, as usually
the user provides clues about the target concept in addition to the examples. In most ILP
systems the user provides a database DB of \background knowledge" in addition to a set
of examples; in this paper, we will assume that the user also provides a declaration. To
account for these additional inputs it is necessary to extend the framework described above
to a setting where the learner accepts inputs other than training examples.
To formalize this, we introduce the following notion of a \language family". If Lang is
a set of clauses, DB is a database and Dec is a declaration, we will define Lang[DB ; Dec]
to be the set of all pairs (C; DB ) such that C 2 Lang and C satisfies Dec . Semantically,
such a pair will denote the set of all extended instances (f; D) covered by (C; DB ). Next,
if DB is a set of databases and DEC is a set of declarations, then define
Lang[DB ; DEC ] = fLang[DB ; Dec ] : DB

2 DB and Dec 2 DECg

This set of languages is called a language family .
We will now extend the definition of identification from equivalence queries to language families as follows. A language family Lang[DB; DEC ] is identifiable from equivalence
queries iff every language in the set is identifiable from equivalence queries. A language
family Lang[DB; DEC ] is uniformly identifiable from equivalence queries iff there is a single
algorithm Identify (DB ; Dec) that identifies any language Lang[DB ; Dec ] in the family
given DB and Dec .
Uniform polynomial identifiability of a language family is defined analogously:
Lang[DB; DEC ] is uniformly polynomially identifiable from equivalence queries iff there is a
polynomial time algorithm Identify (DB ; Dec ) that identifies any language Lang[DB ; Dec]
in the family given DB and Dec . Note that Identify must run in time polynomial in the
size of the inputs Dec and DB as well as the target concept.
508

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

2.3.4 Restricted Types of Background Knowledge

We will now describe a number of restricted classes of databases and declarations.
One restriction which we will make throughout this paper is to assume that all of the
predicates of interest are of bounded arity. We will use the notation a-DB for the set of all
databases that contain only facts of arity a or less, and the notation a-DEC for the set of
all declarations (p; a0; R) such that every string s 2 R is of length a + 1 or less.
For technical reasons, it will often be convenient to assume that a database contains an
equality predicate |that is, a predicate symbol equal such that equal (ti ; ti) 2 DB for every
constant ti appearing in DB , and equal (ti ; tj ) 62 DB for any ti 6= tj . Similarly, we will
often wish to assume that a declaration allows literals of the form equal(X,Y), where X
and Y are input variables. If DB (respectively DEC ) is any set of databases (declarations)
we will use DB = (DEC = ) to denote the corresponding set, with the additional restriction
that the database (declaration) must contain an equality predicate (respectively the mode
equal (+; +)).
It will sometimes also be convenient to assume that a declaration (p; a0; R) allows only
a single valid mode for each predicate: i.e., that for each predicate q there is in R only
a single mode constraint of the form qff. Such a declaration will be called a unique-mode
declaration. If DEC is any set of declarations we will use DEC 1 to denote the corresponding
set of declarations with the additional restriction that the declaration is unique-mode.
Finally, we note that in a typical setting, the facts that appear in a database DB and
descriptions D of extended instances are not arbitrary: instead, they are representative of
some \real" predicate (e.g., the relationship of a list to its components in the example above).
One way of formalizing this is assume that all facts will be drawn from some restricted set F ;
using this assumption one can define the notion of a determinate mode . If f = p(t1 ; : : :; tk )
is a fact with predicate symbol p and pff is a mode, then define inputs (f; pff) to be the
tuple hti1 ; : : :; tik i, where i1, : : : , ik are the indices of ff containing a \+". Also define
outputs (f; pff) to be the tuple htj1 ; : : :; tjl i, where j1 , : : : , jl are the indices of ff containing
a \,". A mode string pff for a predicate p is determinate for F iff the relation

fhinputs (f; pff); outputs (f; pff)i : f 2 Fg
is a function. Informally, a mode is determinate if the input positions of the facts in F
functionally determine the output positions.
The set of all declarations containing only modes determinate for F will be denoted
DetDEC F . However, in this paper, the set F will be assumed to be fixed, and thus we will
generally omit the subscript.
A program consistent with a determinate declaration Dec 2 DetDEC must be determinate, as defined above; in other words, consistency with a determinate declaration is a
sucient condition for semantic determinacy. It is also a condition that can be verified with
a simple syntactic test.
2.3.5 Size Measures for Logic Programs

Assuming that all predicates are arity a or less for some constant a also allows very simple
size measures to be used. In this paper, we will measure the size of a database DB by its
cardinality; the size of an extended instance (f; D) by the cardinality of D; the size of a
509

fiCohen

declaration (p; a0; R) by the cardinality of R; and the size of a clause A B1 ^ : : : ^ Br by
the number of literals in its body.

3. Learning a Nonrecursive Clause

The learning algorithms presented in this paper all use a generalization technique which
we call forced simulation. By way of an introduction to this technique, we will consider a
learning algorithm for non-recursive constant-depth clauses. While this result is presented
primarily for pedagogical reasons, it may be of interest on its own: it is independent of
previous proofs of the pac-learnability of this class (Dzeroski et al., 1992), and it is also
somewhat more rigorous than previous proofs.
Although the details and analysis of the algorithm for non-recursive clauses are somewhat involved, the basic idea behind the algorithm is quite simple. First, a highlyspecific \bottom clause" is constructed, using two operations that we call DEEPEN and
CONSTRAIN . Second, this bottom clause is generalized by deleting literals so that it covers the positive examples: the algorithm for generalizing a clause to cover an example is
(roughly) to simulate the clause on the example, and delete any literals that would cause
the clause to fail. In the remainder of this section we will describe and analyze this learning
algorithm in detail.

3.1 Constructing a \Bottom Clause"

Let Dec = (p; a0; R) be a declaration and let A B1 ^ : : : ^ Br be a definite clause. We
define
^
DEEPEN Dec (A B1 ^ : : : ^ Br )  A B1 ^ : : : ^ Br ^ (
Li )
Li 2LD

where LD is a maximal set of literals Li that satisfy the following conditions:
 the clause A B1 ^ : : : ^ Br ^ Li satisfies the mode constraints given in R;
 if Li 2 LD has the same mode and predicate symbol as some other Lj 2 LD , then the
input variables of Li are different from the input variables of Lj ;
 every Li has at least one output variable, and the output variables of Li are all
different from each other, and are also difference from the output variables of any
other Lj 2 LD .
As an extension of this notation, we define DEEPEN iDec (C ) to be the result of applying
the function DEEPEN Dec repeatedly i times to C , i.e.,
(
if i = 0
i
DEEPEN Dec (C )  C
i,
1
DEEPEN Dec (DEEPEN Dec (C )) otherwise
We define the function CONSTRAIN Dec as
^
CONSTRAIN Dec (A B1 ^ : : : ^ Br )  A B1 ^ : : : ^ Br ^ (
Li )
Li 2LC

where LC is the set of all literals Li such that A B1 ^ : : : ^ Br ^ Li satisfies the mode
constraints given in R, and Li contains no output variables.
510

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

Example. Let D0 be the declaration (p; 2; R) where R contains the mode
constraints mother (+; ,), father (+; ,), male (+), female (+), and equal (+; +).

Then

DEEPEN D0(p(X,Y) ) 
p(X,Y) mother(X,XM)^father(X,XF)^ mother(Y,YM)^father(Y,YF)
DEEPEN 2D0(p(X,Y) )  DEEPEN D0 (DEEPEN D0 (p(X,Y) )) 
p(X,Y)
mother(X,XM)^father(X,XF)^ mother(Y,YM)^father(Y,YF)^
mother(XM,XMM)^father(XM,XMF)^ mother(XF,XFM)^father(XF,XFF)^
mother(YM,YMM)^father(YM,YMF)^ mother(YF,YFM)^father(YF,YFF)
CONSTRAIN D0(DEEPEN D0(p(X,Y) )) 
p(X,Y)
mother(X,XM)^father(X,XF)^ mother(Y,YM)^father(Y,YF)^
male(X)^female(X)^male(Y)^female(Y)^
male(XM)^female(XM)^male(XF)^female(XF)^
male(YM)^female(YM)^male(YF)^female(YF)^
equal(X,X)^equal(X,XM)^equal(X,XF)^
equal(X,Y)^equal(X,YM)^equal(X,YF)^
equal(XM,X)^equal(XM,XM)^equal(XM,XF)^
equal(XM,Y)^equal(XM,YM)^equal(XM,YF)^
equal(XF,X)^equal(XF,XM)^equal(XF,XF)^
equal(XF,Y)^equal(XF,YM)^equal(XF,YF)^
equal(Y,X)^equal(Y,XM)^equal(Y,XF)^
equal(Y,Y)^equal(Y,YM)^equal(Y,YF)^
equal(YM,X)^equal(YM,XM)^equal(YM,XF)^
equal(YM,Y)^equal(YM,YM)^equal(YM,YF)^
equal(YF,X)^equal(YF,XM)^equal(YF,XF)^
equal(YF,Y)^equal(YF,YM)^equal(YF,YF)

Let us say that clause C1 is a subclause of clause C2 if the heads of C1 and C2 are
identical, if every literal in the body of C1 also appears in C2 , and if the literals in the
body of C1 appear in the same order as they do in C2. The functions DEEPEN and
CONSTRAIN allow one to easily describe a clause with an interesting property.
Theorem 1 Let Dec = (p; a0; R) be a declaration in a-DetDEC =, let X1; : : :; Xa be distinct
variables, and define the clause BOTTOM d as follows:
BOTTOM d (Dec )  CONSTRAIN Dec (DEEPEN dDec (p(X1; : : :; Xa ) ))
For any constants d and a, the following are true:
 the size of BOTTOM d(Dec) is polynomial in j Decj ;
 every depth-d clause that satisfies Dec (and hence, is determinate) is (semantically)
equivalent to some subclause of BOTTOM d (Dec ).
0

0

511

fiCohen

begin algorithm Force1NR (d ; Dec; DB ):

% below BOTTOM d is the most specific possible clause
let H BOTTOM d(Dec)

repeat

Ans answer to the query \Is H correct?"
if Ans =\yes" then return H
elseif Ans is a negative example then
return \no consistent hypothesis"
elseif Ans is a positive example e+ then
% generalize H minimally to cover e+
let (f; D) be the components of the extended instance e+
H ForceSimNR (H ; f ; Dec; (DB [ D ))
if H = FAILURE then
return \no consistent hypothesis"

end

endif
endif
endrepeat

Figure 1: A learning algorithm for nonrecursive depth-d determinate clauses

Proof: See Appendix A. A related result also appears in Muggleton and Feng (1992).
Example. Below C1 and D1 are equivalent, as are C2 and D2. Notice that D1
and D2 are subclauses of BOTTOM 1 (D0).

C1 : p(A,B) mother(A,C)^father(A,D)^ mother(B,C)^father(B,D)^male(A)
D1 : p(X,Y) mother(X,XM)^father(X,XF)^ mother(Y,YM)^father(Y,YF)^
male(X)^equal(XM,YM)^equal(XF,YF)
C2 : p(A,B) father(A,B)^female(A)
D2 : p(X,Y) father(X,XF)^female(X)^equal(XF,Y)
For C1 and D1, p(X,Y) is true when X is Y 's brother. For C2 and D2, p(X,Y)
is true when X is Y 's daughter, and Y is X 's father.

3.2 The Learning Algorithm

Theorem 1 suggests that it may be possible to learn non-recursive constant-depth determinate clauses by searching the space of subclauses of BOTTOM d in some ecient
manner. Figures 1 and 2 present an algorithm called Force1 NR that does this when Dec is
a unique-mode declaration.
Figure 1 presents the top-level learning algorithm, Force1 NR . Force1 NR takes as
input a database DB and a declaration Dec , and begins by hypothesizing the clause
BOTTOM d (Dec ). After each positive counterexample e+ , the current hypothesis is generalized as little as possible in order to cover e+ . This strategy means that the hypothesis is
512

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

begin subroutine ForceSimNR(H ; f ; Dec; DB ):

% \forcibly simulate" H on fact f
if f 2 DB then return H
elseif the head of H and f cannot be unified then
return FAILURE

else

let H 0 H
let  be the mgu of f and the head of H 0
for each literal L in the body of H 0 do
if there is a substitution 0 such that L0 2 DB then
   0, where  0 is the most general such substitution
else
delete L from the body of H 0 , together with
all literals L0 supported (directly or indirectly) by L

end

endif
endfor
return H 0
endif

Figure 2: Forced simulation for nonrecursive depth-d determinate clauses
always the least general hypothesis that covers the positive examples; hence, if a negative
counterexample e, is ever seen, the algorithm will abort with a message that no consistent
hypothesis exists.
To minimally generalize a hypothesis H , the function ForceSimNR is used. This subroutine is shown in Figure 2. In the figure, the following terminology is used. If some
output variable of L is an input variable of L0 , then we say that L directly supports L0. We
will say that L supports L0 iff L directly supports L0, or if L directly supports some literal
L00 that supports L0. (Thus \supports" is the transitive closure of \directly supports".)
ForceSim NR deletes from H the minimal number of literals necessary to let H cover e+ . To
do this, ForceSim NR simulates the action of a Prolog interpreter in evaluating H , except
that whenever a literal L in the body of H would fail, that literal is deleted, along with all
literals L0 supported by L.
The idea of learning by repeated generalization is an old one; in particular, previous
methods exist for learning a definite clause by generalizing a highly-specific one. For example, CLINT (De Raedt & Bruynooghe, 1992) generalizes a \starting clause" guided
by queries made to the user; PROGOL (Srinivasan, Muggleton, King, & Sternberg, 1994)
guides a top-down generalization process with a known bottom clause; and Rouveirol (1994)
describes a method for generalizing bottom clauses created by saturation. The Force1 NR algorithm is thus of interest not for its novelty, but because it is provably correct and ecient,
as noted in the theorem below.
513

fiCohen

In particular, let d-DepthNonRec be the language of nonrecursive clauses of depth
d or less (and hence i-DepthNonRec[DB; j -DetDEC ] is the language of nonrecursive ij determinate clauses). We have the following result:

Theorem 2 For any constants a and d, the language family
d-DepthNonRec[DB= ; a-DetDEC =1]
is uniformly identifiable from equivalence queries.

Proof: We will show that Force1 NR uniformly identifies this language family with a polyno-

mial number of queries. We begin with the following important lemma, which characterizes
the behavior of ForceSimNR .

Lemma 3 Let Dec declaration in DetDEC =1 , let DB be a database, let f be a fact, and let

H be a determinate nonrecursive clause that satisfies Dec. Then one of following conditions

must hold:
 ForceSimNR(H ; f ; Dec; DB ) returns FAILURE, and no subclause H 0 of H satisfies
both Dec and the constraint H 0 ^ DB ` f ; or,
 ForceSimNR(H ; f ; Dec; DB ) returns a clause H 0, and H 0 is the unique syntactically
largest subclause of H that satisfies both Dec and the constraint H 0 ^ DB ` f .

Proof of lemma: To avoid repetition, we will refer to the syntactically maximal subclauses
H 0 of H that satisfy both Dec and the constraint H 0 ^ DB ` f as \admissible subclauses"

in the proof below.
Clearly the lemma is true if H or FAILURE is returned by ForceSim NR . In the remaining
cases the for loop of the algorithm is executed, and we must establish these two claims
(under the assumptions that A and f unify, and that f 62 DB ):
Claim 1. If L is retained, then every admissible subclause contains L.
Claim 2. If L is deleted, then no admissible subclause contains L.
First, however, observe that deleting a literal L may cause the mode of some other
literals to violate the mode declarations of Dec . It is easy to see that if L is deleted from
a clause C , then the mode of all literals L0 directly supported by L will change. Thus if C
satisfies a unique-mode declaration prior to the deletion of L, then after the deletion of L
all literals L0 that are directly supported by L will have invalid modes.
Now, to see that Claim 1 is true, suppose instead that it is false. Then there must
be some maximal subclause C 0 of H that satisfies Dec , covers the fact f , and does not
contain L. By the argument above, if C 0 does not contain L but satisfied Dec , then C 0
contains no literals L0 from H that are supported by L. Hence the output variables of L
are disjoint from the variables appearing in C 0. This means that if L were to be added to
C 0 the resulting clause would still satisfy Dec and cover f , which leads to a contradiction
since C 0 was assumed to be maximal.
To verify Claim 2, let us introduce the following terminology. If C = (A B1 ^ : : : ^ Br )
is a clause and DB is a database, we will say that the substitution  is a (DB ; f )-witness
514

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

for C iff  is associated with a proof that C ^ DB ` f (or more precisely, iff A = f and
8i : 1  i  r; Bi 2 DB .) We claim that the following condition is an invariant of the for
loop of the ForceSim NR algorithm.
Invariant 1. Let C be any admissible subclause that contains all the literals in H 0 preceding L (i.e., that contains all those literals of H that were retained on previous
iterations of the algorithm). Then every (DB ; f )-witness for C is a superset of  .
This can be easily established by induction on the number of iterations of the for loop. The
condition is true when the loop is first entered, since  is initially the most general unifier
of A and f . The condition remains true after an iteration in which L is deleted, since 
is unchanged. Finally, the condition remains true after an iteration in which L is retained:
because  0 is maximally general, it may only assign values to the output variables of L, and
by determinacy only one assignment to the output variables of L can make L true. Hence
every (DB ; f )-witness for C must contain the bindings in  .
Next, with an inductive argument and Claim 1 one can show that every admissible
subclause C must contain all the literals that have been retained in previous iterations of
the loop, leading to the following strengthening of Invariant 1:
Invariant 10. Let C be any admissible subclause. Then every (DB ; f )-witness for C is a
superset of  .
Now, notice that only two types of literals are deleted: (a) literals L such that no superset
of  can make L true, and (b) literals L0 that are supported by a literal L of the preceding
type. In case (a), clearly L cannot be part of any admissible subclause, since no superset
of  makes L succeed, and only such supersets can be witnesses of admissible clauses. In
case (b), again L0 cannot be part of any admissible subclause, since its declaration is invalid
unless L is present in the clause, and by the argument above L cannot be in the clause.
This concludes the proof of the lemma.
To prove the theorem, we must now establish the following properties of the identification
algorithm.
Correctness. By Theorem 1, if the target program is in d-DepthNonRec[DB ; Dec],
then there is some clause CT that is equivalent to the target, and is a subclause of
BOTTOM d (Dec ). H is initially BOTTOM  d and hence a superclause of CT . Now consider
invoking ForceSim NR on any positive counterexample e+ . By Lemma 3, if this invocation
is successful, H will be replaced by H 0, the longest subclause of H that covers e+ . Since
CT is a subclause of H that covers e+ , this means that H 0 will again be a superclause of
CT . Inductively, then, the hypothesis is always a superclause of the target.
Further, since the counterexample e+ is always an instance that is not covered by the
current hypothesis H , every time the hypothesis is updated, the new hypothesis is a proper
subclause of the old. This means that Force1 NR will eventually identify the target clause.
Eciency. The number of queries made is polynomial in j Decj and j DB j , since H is
initially of size polynomial in j Dec j , and is reduced in size each time a counterexample is
provided. To see that each counterexample is processed in time polynomial in nr , ne , and
nt, notice that since the length of H is polynomial, the number of repetitions of the for
loop of ForceSim NR is also polynomial; further, since the arity of literals L is bounded by
515

fiCohen

a, only anb + ane constants exist in DB [ D, and hence there are at most (anb + ane )a
substitutions  0 to check inside the for loop, which is again polynomial. Thus each execution

of ForceSim NR requires only polynomial time.
This concludes the proof.

4. Learning a Linear Closed Recursive Clause

Recall that if a clause has only one recursive literal, then the clause is linear recursive ,
and that if no recursive literal contains output variables, then the clause is closed linear
recursive. In this section, we will describe how the Force1 algorithm can be extended to
learn a single linear closed recursive clause.2 Before presenting the extension, however, we
would first like to discuss a reasonable-sounding approach that, on closer examination, turns
out to be incorrect.

4.1 A Remark on Recursive Clauses

One plausible first step toward extending Force1 to recursive clauses is to allow recursive
literals in hypotheses, and treat them the same way as other literals|that is, to include
recursive literals in the initial clause BOTTOM d , and delete these literals gradually as
positives examples are received. A problem with this approach is that there is no simple
way to check if a recursive literal in a clause succeeds or fails on a particular example. This
makes it impossible to simply run ForceSimNR on clauses containing recursive literals.
A straightforward (apparent) solution to this problem is to assume that an oracle exists
which can be queried as to the success or failure of any recursive literal. For closed recursive
clauses, it is sucient to assume that there is an oracle MEMBERCt (DB ; f ) that answers
the question
Does DB ^ P ` f ?
where Ct is the unknown target concept, f is a ground fact, and DB is a database. Given
such an oracle, one can determine if a closed recursive literal Lr should be retained by
checking if MEMBERCT (DB ; Lr  ) is true. Such an oracle is very close to the notion of a
membership query as used in computational learning theory.
This is a natural extension of the Force1NR learning algorithm to recursive clauses|in
fact an algorithm based on similar ideas has been been previously conjectured to pac-learn
closed recursive constant-depth determinate clauses (Dzeroski et al., 1992). Unfortunately,
this algorithm can fail to return a clause that is consistent with a positive counterexample.
To illustrate this, consider the following example.

Example. Consider using the extension of Force1NR described above to learn
following target program:
append(Xs,Ys,Zs)
2. The reader may object that useful recursive programs always have at least two clauses|a recursive
clause and a nonrecursive base case. In posing the problem of learning a single recursive clause, we are
thus assuming the non-recursive \base case" of the target program is provided as background knowledge,
either in the background database DB , or in the description atoms D of extended instances.

516

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

components(Xs,X,Xs1),
components(Zs,Z,Zs1),
X1=Z1,
append(Xs1,Ys,Zs1).
This program is determinate, has depth 1, and satisfies the following set of
declarations:
components(+,,,,).
null(+).
equal(+,+).
odd(+).
append(+,+,+).
We will assume also a database DB that defines the predicate null to be true
for empty lists, and odd to be true for the constants 1 and 3.
To see how the forced simulation can fail, consider the following positive instance
e = (f; D):

f = append (l12 ; l3 ; l123 )
D = f cons(l123,1,l23), cons(l23,2,l3), cons(l3,3,nil),
cons(l12,1,l2), cons(l2,2,nil),
append(nil,l3,l3) g

This is simply a \attened" form of append([1,2],[3],[1,2,3]), together with the
appropriate base case append([],[3],[3]). Now consider beginning with the clause
BOTTOM 1 and generalizing it using ForceSimNR to cover this positive instance.
This process is illustrated in Figure 3. The clause on the left in the figure is
BOTTOM d (Dec ); the clause on the right is the output of forcibly simulating
this clause on f with ForceSimNR . (For clarity we've assumed that only the
single correct recursive call remains after forced simulation.)
The resulting clause is incorrect, in that it does not cover the given example e.
This can be easily seen by stepping through the actions of a Prolog interpreter
with the generalized clause of Figure 3. The nonrecursive literals will all succeed, leading to the subgoal append(l2,l3,l23) (or in the usual Prolog notation,
append([2],[3],[2,3])). This subgoal will fail at the literal odd(X1), because X1
is bound to 2 for this subgoal, and the fact odd(2) is not true in DB [ D.
This example illustrates a pitfall in the policy of treating recursive and non-recursive
literals in a uniform manner (For more discussion, see also (Bergadano & Gunetti, 1993; De
Raedt, Lavrac, & Dzeroski, 1993).) Unlike nonrecursive literals, the truth of the fact Lr 
(corresponding to the recursive literal Lr ) does not imply that a clause containing Lr will
succeed; it may be that while the first subgoal Lr  succeeds, deeper subgoals fail.
517

fiCohen

BOTTOM 1 (Dec ):
ForceSimNR (BOTTOM 1(Dec); f; Dec; DB [ D) :
append(Xs,Ys,Zs)
append(Xs,Ys,Zs)
components(Xs,X1,Xs1)^
components(Xs,X1,Xs1)^
components(Ys,Y1,Ys1)^
components(Ys,Y1,Ys1)^
components(Zs,Z1,Zs1)^
components(Zs,Z1,Zs1)^
null(Xs)^
null(Ys1)^
null(Ys)^
equal(X1,Z1)^
..
odd(X1)^
.
odd(Y1)^
null(Ys1)^
odd(Z1)^
null(Zs1),
append(Xs1,Ys,Zs1).
equal(Xs,Xs)^
..
.
equal(X1,Z1)^
..
.
equal(Zs1,Zs1)^
odd(Xs)^
..
.
odd(X1)^
odd(Y1)^
odd(Z1)^
..
.
odd(Zs1)^
append(Xs,Xs,Xs)^
..
.
append(Zs1,Zs1,Zs1).

Figure 3: A recursive clause before and after generalization with ForceSimNR

4.2 Forced Simulation for Recursive Clauses
A solution to this problem is to replace the calls to the membership oracle in the algorithm
sketched above with a call to a routine that forcibly simulates the actions of a top-down
theorem-prover on a recursive clause. In particular, the following algorithm is suggested.
First, build a nonrecursive \bottom clause", as was done in ForceSimNR . Second, find some
recursive literal Lr such that appending Lr to the bottom clause yields a recursive clause
that can be generalized to cover the positive examples.
As in the nonrecursive case, a clause is generalized by deleting literals, using a straightforward generalization of the procedure for forced simulation of nonrecursive clauses. During
forced simulation, any failing nonrecursive subgoals are simply deleted; however, when a
recursive literal Lr is encountered, one forcibly simulates the hypothesis clause recursively
518

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

begin subroutine ForceSim (H ; f ; Dec; DB ; h ):

% \forcibly simulate" recursive clause H on f
% 1. check for infinite loops
if h < 0 then return FAILURE
% 2. check to see if f is already covered
elseif f 2 DB then return H
% 3. check to see if f cannot be covered
elseif the head of H and f cannot be unified then
return FAILURE

else

let Lr be the recursive literal of H
let H 0 H , fLrg

% 4. delete failing non-recursive literals as in ForceSimNR
let A be the head of H 0
let  be the mgu of A and e
for each literal L in the body of H 0 do
if there is a substitution 0 such that L0 2 DB
then    0, where 0 is the most general such substitution

else

delete L from the body of H 0 , together with
all literals L0 supported (directly or indirectly) by L

endif
endfor

% 5. generalize H 0 on the recursive subgoal Lr 
if Lr  is ground then return ForceSim(H 0 [ fLr g; Lr; Dec; DB ; h , 1)
else return FAILURE

end

endif
endif

Figure 4: Forced simulation for linear closed recursive clauses

519

fiCohen

on the corresponding recursive subgoal. An implementation of forced simulation for linear
closed recursive clauses is shown in Figure 4.
The extended algorithm is similar to ForceSimNR , but differs in that when the recursive
literal Lr is reached in the simulation of H , the corresponding subgoal Lr  is created, and
the hypothesized clause is recursively forcibly simulated on this subgoal. This ensures that
the generalized clause will also succeed on the subgoal. For reasons that will become clear
shortly, we would like this algorithm to terminate, even if the original clause H enters an
infinite loop when used in a top-down interpreter. In order to ensure termination, an extra
argument h is passed to ForceSim . The argument h represents a depth bound for the forced
simulation.
To summarize, the basic idea behind the algorithm of Figure 4 is to simulate the hypothesized clause H on f , and generalize H by deleting literals whenever H would fail on
f or on any subgoal of f .

Example.

Consider using ForceSim to forcibly simulate the following recursive clause
BOTTOM 1(Dec ) [ Lr
append(Xs,Ys,Zs)
components(Xs,X1,Xs1)^components(Ys,Y1,Ys1)^components(Zs,Z1,Zs1)^
null(Xs)^: : : ^null(Zs1)^
odd(Xs)^: : : ^odd(Zs1)^
equal(Xs,Xs)^: : : ^equal(Zs1,Zs1)^
append(Xs1,Ys,Zs1)
Here the recursive literal Lr is append(Xs1,Ys,Zs1). We will also assume that f
is taken from the extended query e = (f; D), which is again the attened version
of the instance append([1,2],[3],[1,2,3]) used in the previous example; that Dec
is the set of declarations of in the previous example; and that the database DB
is D [ null (nul ).
After executing steps 1-4 of ForceSim, a number of failing literals are deleted,
leading to the substitution3  of fXs = [1; 2], Ys = [3], Zs = [1; 2; 3], X1 = 1,
Xs1 = [2], Y1 = 3, Ys1 = [], Z1 = 1, Zs1 = [2; 3]g and the following reduced
clause:
append(Xs,Ys,Zs)
components(Xs,X1,Xs1)^components(Ys,Y1,Ys1)^components(Zs,Z1,Zs1)^
null(Ys1)^odd(X1)^odd(Y1)^odd(Z1)^equal(X1,Z1)^
append(Xs1,Ys,Zs1)
Hence the recursive subgoal is

Lr  = append (Xs1 ; Ys ; Zs1 ) = append ([2]; [3]; [2; 3])
3. Note that for readability, we are using the term notation rather than the attened notation of Xs = l12,
Ys = l3, etc.

520

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

Recursively applying ForceSim to this goal produces the substitution fXs = [2],
Ys = [3], Zs = [2; 3], X1 = 2, Xs1 = [], Y1 = 3, Ys1 = [], Z1 = 2, Zs1 = [3]g
and also results in deleting the additional literals odd(X1) and odd(Z1). The
next recursive subgoal is Lr  = append ([]; [3]; [3]); since this clause is included
in the database DB , ForceSim will terminate. The final clause returned by
ForceSim in this case is the following:
append(Xs,Ys,Zs)
components(Xs,X1,Xs1)^components(Ys,Y1,Ys1)^components(Zs,Z1,Zs1)^
null(Ys1)^odd(Y1)^equal(X1,Z1)^
append(Xs1,Ys,Zs1)
Notice that this clause does cover e.
As in Section 3 we begin our analysis by showing the correctness of the forced simulation
algorithm|i.e., by showing that forced simulation does indeed produce a unique maximally
specific generalization of the input clause that covers the example.
This proof of correctness uses induction on the depth of a proof. Let us introduce again
some additional notation, and write P ^ DB `h f if the Prolog program (P; DB ) can be
used to prove the fact f in a proof of depth h or less. (The notion of depth of a proof is the
usual one; we will define looking up f in the database DB to be a proof of depth zero.) We
have the following result concerning the ForceSim algorithm.

Theorem 4 Let Dec be a declaration in DetDEC =1, let DB be a database, let f be a fact,

and let H be a determinate closed linear recursive clause that satisfies Dec. Then one of
the following conditions must hold:

 ForceSim(H; f; Dec; DB ; h) returns FAILURE, and no recursive subclause H 0 of H
satisfies both Dec and the constraint H 0 ^ DB `h f ; or,
 ForceSim(H; f; Dec; DB ; h) returns a clause H 0, and H 0 is the unique syntactically
largest recursive subclause of H that satisfies both Dec and the constraint H 0^DB `h f .

Proof: Again to avoid repetition, we will refer to syntactically maximal recursive (nonrecursive) subclauses H 0 of H that satisfy both Dec and the constraint H 0 ^ DB `h f as

\admissible recursive (nonrecursive) subclauses" respectively.
The proof largely parallels the proof of Lemma 3|in particular, similar arguments
show that the clause returned by ForceSim satisfies the conditions of the theorem whenever
FAILURE is returned and whenever H is returned. Note that the correctness of ForceSim
when H is returned establishes the base case of the theorem for h = 0.
For the case of depth h > 0, let us assume the theorem holds for depth h , 1 and
proceed using mathematical induction. The arguments of Lemma 3 show that the following
condition is true after the for loop terminates.

Invariant 10. H 0 is the unique maximal nonrecursive admissible subclause of H , and every
(DB ; f )-witness for H 0 is a superset of  .
521

fiCohen

begin algorithm Force1 (d ; Dec; DB ):

% below BOTTOM d is the most specific possible clause
let Lr1 ; : : :; Lrp be all possible closed recursive literals for BOTTOM d(Dec)
choose an unmarked recursive literal Lri
let H BOTTOM d(Dec) [ fLri g

repeat

answer to the query \Is H correct?"

Ans

if Ans =\yes" then return H
elseif Ans is a negative example e, then
H

FAILURE

elseif Ans is a positive example e+ then

% generalize H minimally to cover e+
let (f; D) be the components of e+
H ForceSim (H ; f ; Dec; (DB [ D ); (a j Dj + a j DBj )a )
where a0 is the arity of the clause head as given in Dec
0

endif
if H = FAILURE then
if all recursive literals are marked then
return \no consistent hypothesis"
else

mark Lri
choose an unmarked recursive literal Lrj
let H BOTTOM d(Dec) [ fLrj g

end

endif
endif
endrepeat

Figure 5: A learning algorithm for nonrecursive depth-d determinate clauses
Now, let us assume that there is some admissible recursive subclause H . Clearly H  must
contain the recursive literal Lr of H , since Lr is the only recursive literal of H . Further,
the nonrecursive clause H^ = H  , fLr g must certainly satisfy Dec and also H^ ^ DB ` f ,
so it must (by the maximality of H 0) be a subclause of H 0. Hence H  must be a subclause
of H 0 [ fLr g. Finally, if Lr  is ground (i.e., if Lr is closed in the clause H 0 [ Lr ) then by
Invariant 10, the clause H  must also satisfy H  ^ DB ` Lr  by a proof of depth h , 1.
(This is simply equivalent to saying that the recursive subgoal of Lr  generated in the proof
must succeed.)
By the inductive hypothesis, then, the recursive call must return the unique maximal
admissible recursive subclause of H 0 [ Lr , which by the argument above must also be the
unique maximal admissible recursive subclause of H .
Thus by induction the theorem holds.
522

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

4.3 A Learning Algorithm for Linear Recursive Clauses

Given this method for generalizing recursive clauses, one can construct a learning algorithm for recursive clauses as follows. First, guess a recursive literal Lr , and make
H = BOTTOM d [ Lr the initial hypothesis of the learner. Then, ask a series of equivalence
queries. After a positive counterexample e+ , use forced simulation to minimally generalize
H to cover e+ . After a negative example, choose another recursive literal L0r , and reset the
hypothesis to H = BOTTOM d [ L0r .
Figure 5 presents an algorithm that operates along these lines. Let d-DepthLinRec
denote the language of linear closed recursive clauses of depth d or less. We have the
following result:
Theorem 5 For any constants a and d, the language family
d-DepthLinRec[DB=; a-DetDEC =1]
is uniformly identifiable from equivalence queries.
Proof: We will show that Force1 uniformly identifies this language family with a polynomial number of queries.
Correctness and query eciency. There are at most aj Dj + aj DBj constants in
any set DB [ D, at most (aj Dj + aj DB j )a a0 -tuples of such constants, and hence at most
(aj Dj + aj DB j )a distinct recursive subgoals Lr  that might be produced in proving that a
linear recursive clause C covers an extended instance (f; D). Thus every terminating proof
of a fact f using a linear recursive clause C must be of depth (aj Dj + aj DB j )a or less; i.e.,
for h = (aj Dj + aj DB j )a ,
C ^ DB ^ D `h f iff C ^ DB ^ D ` f
Thus Theorem 4 can be strengthened: for the value of h used in Force1, the subroutine
ForceSim returns the syntactically largest subclause of H that covers the example (f; D)
whenever any such a subclause exists, and returns FAILURE otherwise.
We now argue the correctness of the algorithm as follows. Assume that the hypothesized recursive literal is \correct"|i.e., that the target clause CT is some subclause of
BOTTOM d [ Lr . In this case it is easy to see that Force1 will identify CT , using an argument that parallels the one made for Force1 NR . Again by analogy to Force1 NR , it is easy to
see that only a polynomial number of equivalence queries will be made involving the correct
recursive literal.
Next assume that Lr is not the correct recursive literal. Then CT need not be a subclause
of BOTTOM d [ Lr , and the response to an equivalence query may be either a positive or
negative counterexample. If a positive counterexample e+ is received and ForceSim is
called, then the result may be FAILURE, or it may be a proper subclause of H that covers
e+ . Thus the result of choosing an incorrect Lr will be a (possibly empty) sequence of
positive counterexamples followed by either a negative counterexample or FAILURE. Since
all equivalence queries involving the correct recursive literal will be answered by either
a positive counterexample or \yes"4, then if a negative counterexample or FAILURE is
obtained, it must be that Lr is incorrect.
0

0

0

0

4. Recall that an answer of \yes" to an equivalence query means the hypothesis is correct.

523

fiCohen

The number of variables in BOTTOM d can be bounded by aj BOTTOM d (Dec )j , and
as each closed recursive literal is completely defined by an a0-tuple of variables, the number
of possible closed recursive literals Lr can be bounded by

p = (aj BOTTOM d (Dec )j )a

0

Since j BOTTOM d (Dec )j is polynomial in j Dec j , p is also polynomial in j Dec j . This means
that only a polynomial number of incorrect Lr 's need to be discarded. Further since each
successive hypothesis using a single incorrect Lr is a proper subclause of the previous hypothesis, only a polynomial number of equivalence queries are needed to discard an incorrect
Lr . Thus only a polynomial number of equivalence queries can be made involving incorrect
recursive literals.
Thus Force1 needs only a polynomial number of queries to identify Ct.
Eciency. ForceSim runs in time polynomial in its arguments H , f , Dec, DB [ D
and h. When ForceSim is called from Force1, h is always polynomial in ne and j DB j , and
H is always no larger than j BOTTOM d(Dec)j + 1, which in turn is polynomial in the size
of Dec . Hence every invocation of ForceSim requires time polynomial in ne , Dec , and DB ,
and hence Force1 processes each query in polynomial time.
This completes the proof.
This result is somewhat surprising, as it shows that recursive clauses can be learned
even given an adversarial choice of training examples. In contrast, most implemented ILP
systems require well-choosen examples to learn recursive clauses.
This formal result can also be strengthened in a number of technical ways. One of
the more interesting strengthenings is to consider a variant of Force1 that maintains a
fixed set of positive and negative examples, and constructs the set of all least general
clauses that are consistent with these examples: this could be done by taking each of the
clauses BOTTOM d [ Lr1 , : : : , BOTTOM d [ Lrp , forcibly simulating them on each of the
positive examples in turn, and then discarding those clauses that cover one of more negative
examples. This set of clauses could then be used to tractably encode the version space of
all consistent programs, using the [S; N ] representation for version spaces (Hirsh, 1992).

5. Extending the Learning Algorithm

We will now consider a number of ways in which the result of Theorem 5 can be extended.

5.1 The Equality-Predicate and Unique-Mode Assumptions
Theorem 5 shows that the language family

d-DepthLinRec[DB=; a-DetDEC =1]
is identifiable from equivalence queries. It is natural to ask if this result can be extended
by dropping the assumptions that an equality predicate is present and that the declaration
contains a unique legal mode for each predicate: that is, if the result can be extended to
the language family
d-DepthLinRec[DB; a-DetDEC ]
524

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

This extension is in fact straightforward. Given a database DB and a declaration Dec =
(p; a0; R) that do not satisfy the equality-predicate and unique-mode assumptions, one can
modify them as follows.
1. For every constant c appearing in DB , add the fact equal (c ; c ) to DB .
2. For every predicate q that has k valid modes qs1 , : : : , qsk in R:
(a) remove the mode declarations for q , and replace them with k mode strings for
the k new predicates qs1 , : : : , qsk , letting qsi si be the unique legal mode for the
predicate qsi ;
(b) remove every fact q (t1 ; : : :; ta) of the predicate q from DB , and replace it with
the k facts qs1 (t1 ; : : :; ta ), : : : , qsk (t1 ; : : :; ta).
Note that if the arity of predicates is bounded by a constant a, then the number of modes
k for any predicate q is bounded by the constant 2a , and hence these transformations can
be performed in polynomial time, and with only a polynomial increase in the size of Dec
and DB .
Clearly any target clause Ct 2 d-DepthLinRec[DB ; Dec ] is equivalent to some clause
Ct0 2 d-DepthLinRec[DB 0; Dec0], where DB 0 and Dec 0 are the modified versions of DB
and Dec constructed above. Using Force1 it is possible to identify Ct0 . (In learning Ct0, one
must also perform steps 1 and 2b above on the description part D of every counterexample
(f; D).) Finally, one can convert Ct0 to an equivalent clause in d-DepthLinRec[DB ; Dec]
by repeatedly resolving against the clause equal(X,X) , and also replacing every predicate
symbol qsi with q .
This leads to the following strengthening of Theorem 5:

Proposition 6 For any constants a and d, the language family
d-DepthLinRec[DB; a-DetDEC ]
is uniformly identifiable from equivalence queries.

5.2 The Datalog Assumption

So far we have assumed that the target program contains no function symbols, and that the
background knowledge provided by the user is a database of ground facts. While convenient
for formal analysis, these assumptions can be relaxed.
Examination of the learning algorithm shows that the database DB is used in only two
ways.

 In forcibly simulating a hypothesis on an extended instance (f; D), it is necessary to
find a substitution  0 that makes a literal L true in the database DB [ D. While this
can be done algorithmically if DB and D are sets of ground facts, it is also plausible
to assume that the user has provided an oracle that answers in polynomial time any
mode-correct query L to the database DB . Specifically, the answer of the oracle will
be either
525

fiCohen

{ the (unique) most-general substitution 0 such that DB ^ D ` L0 and L0 is
ground; or
{ \no" if no such 0 exists.

Such an oracle would presumably take the form of an ecient theorem-prover for DB .

 When calling ForceSim, the top-level learning algorithm uses DB and D to determine

a depth bound on the length of a proof made using the hypothesis program. Again,
it is reasonable to assume that the user can provide this information directly, in the
form of an oracle. Specifically, this oracle would provide for any fact f a polynomial
upper bound on the depth of the proof for f in the target program.

Finally we note that if ecient (but non-ground) background knowledge is allowed, then
function symbols always can be removed via attening (Rouveirol, 1994). This transformation also preserves determinacy, although it may increase depth|in general, the depth of
a attened clause depends also on term depth in the original clause. Thus, the assumption
that the target program is in Datalog can be replaced by assumptions that the term depth
is bounded by a constant, and that two oracles are available: an oracle that answers queries
to the background knowledge, and a depth-bound oracle. Both types of oracles have been
frequently assumed in the literature (Shapiro, 1982; Page & Frisch, 1992; Dzeroski et al.,
1992).

5.3 Learning k-ary Recursive Clauses

It is also natural to ask if Theorem 5 can be extended to clauses that are not linear recursive.
One interesting case is the case of closed k-ary recursive clauses for constant k. It is
straightforward to extend Force1 to guess a tuple of k recursive literals Lr1 , : : : , Lrk , and
then to extend ForceSim to recursively generalize the hypothesis clause on each of the facts
Lr1  , : : : , Lrk  . The arguments of Theorems 4 and 5 can be modified to show that this
extension will identify the target clause after a polynomial number of equivalence queries.
Unfortunately, however, it is no longer the case that ForceSim runs in polynomial time.
This is easily seen if one considers a tree of all the recursive calls made by ForceSim; in
general, this tree will have branching factor k and polynomial depth, and hence exponential
size. This result is unsurprising, as the implementation of ForceSim described forcibly
simulates a depth-bounded top-down interpreter, and a k-ary recursive program can take
exponential time to interpret with such an interpreter.
There are at least two possible solutions to this problem. One possible solution is to
retain the simple top-down forced simulation procedure, and require the user to provide
a depth bound tighter than (aj Dj + aj DB j )a , the maximal possible depth of a tree. For
example, in learning a 2-ary recursive sort such as quicksort, the user might specify a logarithmic depth bound, thus guaranteeing that ForceSim is polynomial-time. This requires
additional input from the user, but would be easy to implement. It also has the advantage
(not shared by the approach described below) that the hypothesized program can be executed using a simple depth-bounded Prolog interpreter, and will always have shallow proof
trees. This seems to be a plausible bias to impose when learning k-ary recursive Prolog
programs, as many of these tend to have shallow proof trees.
0

526

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

A second solution to the possible high cost of forced simulation for k-ary recursive
programs is to forcibly simulate a \smarter" type of interpreter|one which can execute
k-ary recursive program in polynomial time.5 One sound and complete theorem-prover for
closed k-ary recursive programs can be implemented as follows.
Construct a top-down proof tree in the usual fashion, i.e., using a depth-first left-to-right
strategy, but maintain a list of the ancestors of the current subgoal, and also a list VISITED
that records, for each previously visited node in the tree, the subgoal associated with that
node. Now, suppose that in the course of constructing the proof tree one generates a subgoal
f that is on the VISITED list. Since the traversal of the tree is depth-first left-to-right, the
node associated with f is either an ancestor of the current node, or is a descendant of some
left sibling of an ancestor of the current node. In the former case, the proof tree contains
a loop, and cannot produce a successful proof; in this case the theorem-prover should exit
with failure. In the latter case, a proof must already exist for f 0 , and hence nodes below the
current node in the tree need not be visited; instead the theorem prover can simply assume
that f is true.
This top-down interpreter can be easily extended into a forced simulation procedure:
one simply traverses the tree in the same order, generalizing the current hypothesis H as
needed to justify each inference step in the tree. The only additional point to note is that
if one is performing forced simulation and revisits a previously proved subgoal f at a node
n, the current clause H need not be further generalized in order to prove f , and hence it is
again permissible to simply skip the portion of the tree below n. We thus have the following
result.

Theorem 7 Let d-Depth-k-Rec be the set of k-ary closed recursive clauses of depth d.
For any constants a, d, and k the language family
d-Depth-k-Rec[DB; a-DetDEC]
is uniformly identifiable from equivalence queries.

Proof: Omitted, but following the informal argument made above.
Note that we give this result without the restrictions that the database contains an
equality relation and that the declaration is unique-mode, since the tricks used to relax
these restrictions in Proposition 6 are still applicable.

5.4 Learning Recursive and Base Cases Simultaneously

So far, we have analyzed the problem of learning single clauses: first a single nonrecursive
clause, and then a single recursive clause. However, every useful recursive program contains
at least two clauses: a recursive clause, and a nonrecursive base case. It is natural to ask
if it is possible to learn a complete recursive program by simultaneously learning both a
recursive clause, and its associated nonrecursive base case.
In general, this is not possible, as is demonstrated elsewhere (Cohen, 1995). However,
there are several cases in which the positive result can be extended to two-clause programs.
5. Note that it is plausible to believe that such a theorem-prover exists, as there are only a polynomial
number of possible theorem-proving goals|namely, the (aj Dj + aj DB j )a possible recursive subgoals.
0

527

fiCohen

begin algorithm Force2 (d ; Dec; DB ):
let Lr1 ; : : :; Lrp be all possible recursive literals for BOTTOM d(Dec)
choose an unmarked recursive literal Lri
let HR BOTTOM d(Dec) [ fLri g
let HB BOTTOM d(Dec)
let P = (HR; Hb)

repeat

Ans answer to query \Is HR ; HB correct?"
if Ans =\yes" then return HR ; HB
elseif Ans is a negative example e, then
P FAILURE
elseif Ans is a positive example e+ then
let (f; D) be the components of e+
P ForceSim2 (HR; HB ; f ; Dec; (DB [ D ); (a j Dj + a j DBj )a )
0

endif
if P = FAILURE then
if all recursive literals Lrj are marked then
return \no consistent hypothesis"
else

mark Lri
choose an unmarked recursive literal Lrj
let HR BOTTOM d(Dec) [ fLrj g
let HB BOTTOM d (Dec)
let P = (HR ; HB )

end

endif
endif
endrepeat

Figure 6: A learning algorithm for two-clause recursive programs

528

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

begin subroutine ForceSim2 (HR; HB ; f ; Dec; DB ; h ):

% \forcibly simulate" program HR ; HB on f
if h < 1 then return FAILURE
% check to see if f should be covered by HB
elseif BASECASE (f ) then
return current Hr and generalized HB
return (HR; ForceSimNR(HB ; f ; Dec; DB ))
elseif the head of HR and f cannot be unified then
return FAILURE

else

let Lr be the recursive literal of HR
let H 0 H , fLrg
let A be the head of H 0
let  be the mgu of A and e
for each literal L in the body of H 0 do
if there is a substitution 0 such that L0 2 DB
then    0, where 0 is the most general such substitution
else
delete L from the body of H 0 , together with
all literals L0 supported (directly or indirectly) by L

endif
endfor

% generalize H 0; HB on the recursive subgoal Lr 
if Lr  is ground then
% continue the simulation of the program
return ForceSim2(H 0 [ fLr g; HB; Lr; Dec; DB ; h , 1)
else return FAILURE

end

endif
endif

Figure 7: Forced simulation for two-clause recursive programs

529

fiCohen

In this section, we will first discuss learning a recursive clause and base clause simultaneously, assuming that any determinate base clause is possible, but also assuming that an
additional \hint" is available, in the form of a special \basecase" oracle. We will then
discuss various alternative types of \hints".
Let P be a target program with base clause CB and recursive clause CR. A basecase
oracle for P takes as input an extended instance (f; D) and returns \yes" if CB ^ DB ^ D ` f ,
and \no" otherwise. In other words, the oracle determines if f is covered by the nonrecursive
base clause alone. As an example, for the append program, the basecase oracle should return
\yes" for an instance append(Xs,Ys,Zs) when Xs is the empty list, and \no" otherwise.
Given the existence of a basecase oracle, the learning algorithm can be extended as
follows. As before, all possible recursive literals Lri of the clause BOTTOM d are generated;
however, in this case, the learner will test two clause hypotheses that are initially of the
form (BOTTOM d [ Lri ; BOTTOM d ). To forcibly simulate such a hypothesis on a fact f ,
the following procedure is used. After checking the usual termination conditions, the forced
simulator checks to see if BASECASE(f) is true. If so, it calls ForceSimNR (with appropriate
arguments) to generalize the current hypothesis for the base case. If BASECASE(f) is
false, then the recursive clause Hr is forcibly simulated on f , a subgoal Lr  is generated
as in before, and the generalized program is recursively forcibly simulated on the subgoal.
Figures 6 and 7 present a learning algorithm Force2 for two clause programs consisting of
one linear recursive clause CR and one nonrecursive clause CB , under the assumption that
both equivalence and basecase oracles are available.
It is straightforward to extend the arguments of Theorem 5 to this case, leading to the
following result.

Theorem 8 Let d-Depth-2-Clause be the set of 2-clause programs consisting of one

clause in d-DepthLinRec and one clause in d-DepthNonRec. For any constants a
and d the language family

d-Depth-2-Clause[DB; a-DetDEC ]
is uniformly identifiable from equivalence and basecase queries.

Proof: Omitted.
A companion paper (Cohen, 1995) shows that something like the basecase oracle is
necessary: in particular, without any \hints" about the base clause, learning a two-clause
linear recursive program is as hard as learning boolean DNF. However, there are several
situations in which the basecase oracle can be dispensed with.
Case 1. The basecase oracle can be replaced by a polynomial-sized set of possible base
clauses. The learning algorithm in this case is to enumerate pairs of base clauses CBi
and \starting clauses" BOTTOM  [ Lrj , generalize the starting clause with forced
simulation, and mark a pair as incorrect if overgeneralization is detected.
Case 2. The basecase oracle can be replaced by a fixed rule that determines when the base
clause is applicable. For example, consider the rule that says that the base clause is
applicable to any atom p(X1; : : :; Xa) such that no Xi is a non-null list. Adopting
530

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

such a rule leads immediately to a learning procedure that pac-learns exactly those
two-clause linear recursive programs for which the rule is correct.
Case 3. The basecase oracle can be also be replaced by a polynomial-sized set of rules for
determining when a base clause is applicable. The learning algorithm in this case is
pick a unmarked decision rule and run Force2 using that rule as a basecase oracle. If
Force2 returns \no consistent hypothesis" then the decision rule is marked incorrect,
and a new one is choosen. This algorithm will learn those two-clause linear recursive
programs for which any of the given decision rules is correct.
Even though the general problem of determining a basecase decision rule for an arbitrary
Datalog program may be dicult, it may be that a small number of decision procedures
apply to a large number of common Prolog programs. For example, the recursion for most
list-manipulation programs halts when some argument is reduced to a null list or to a
singleton list. Thus Case 3 above seems likely to cover a large fraction of the automatic
logic programming programs of practical interest.
We also note that heuristics have been proposed for finding such basecase decision rules
automatically using typing restrictions (Stahl, Tausend, & Wirth, 1993).

5.5 Combining the Results

Finally, we note that all of the extensions described above are compatible. This means
that if we let kd-MaxRecLang be the language of two-clause programs consisting of one
clause CR that is k-ary closed recursive and depth-d determinate, and one clause CB that
is nonrecursive and depth-d determinate, then the following holds.

Proposition 9 For any constants a, k and d the language family
kd-MaxRecLang[DB; a-DetDEC ]
is uniformly identifiable from equivalence and basecase queries.
5.5.1 Further Extensions
The notation kd-MaxRecLang may seem at this point to be unjustified; although it is the

most expressive language of recursive clauses that we have proven to be learnable, there are
numerous extensions that may be eciently learnable. For example, one might generalize
the language to allow an arbitrary number of recursive clauses, or to include clauses that are
not determinate. These generalizations might very well be pac-learnable|given the results
that we have presented so far.
However, a companion paper (Cohen, 1995) presents a series of negative results showing
that most natural generalizations of kd-MaxRecLang are not eciently learnable, and
further that kd-MaxRecLang itself is not eciently learnable without the basecase oracle. Specifically, the companion paper shows that eliminating the basecase oracle leads
to a problem that is as hard as learning boolean DNF, an open problem in computational
learning theory. Similarly, learning two linear recursive clauses simultaneously is as hard
as learning DNF, even if the base case is known. Finally, the following learning problems
are all as hard as breaking certain (presumably) secure cryptographic codes: learning n
531

fiCohen

linear recursive determinate clauses, learning one n-ary recursive determinate clause, or
learning one linear recursive \k-local" clause. All of these negative results hold not only
for the model of identification from equivalence queries, but also for the weaker models of
pac-learnability and pac-predictability.

6. Related Work
In discussing related work we will concentrate on previous formal analyses that employ a
learning model similar to that considered here: namely, models that (a) require all computation be polynomial in natural parameters of the problem, and (b) assume either a neutral
source or adversarial source of examples, such as equivalence queries or stochastically presented examples. We note, however, that much previous formal work exists that relies on
different assumptions. For instance, there has been much work in which member or subset
queries are allowed (Shapiro, 1982; De Raedt & Bruynooghe, 1992), or where examples are
choosen in some non-random manner that is helpful to the learner (Ling, 1992; De Raedt
& Dzeroski, 1994). There has also been some work in which the eciency requirements
imposed by the pac-learnability model are relaxed (Nienhuys-Cheng & Polman, 1994). If
the requirement of eciency is relaxed far enough, very general positive results can be obtained using very simple learning algorithms. For example, in model of learnability in the
limit (Gold, 1967), any language that is both recursively enumerable and decidable (which
includes all of Datalog) can be learned by a simple enumeration procedure; in the model
of U-learnability (Muggleton & Page, 1994) any language that is polynomially enumerable
and polynomially decidable can be learned by enumeration.
The most similar previous work is that of Frazier and Page (1993a, 1993b). They analyze
the learnability from equivalence queries of recursive programs with function symbols but
without background knowledge. The positive results they provide are for program classes
that satisfy the following property: given a set of positive examples S + that requires all
clauses in the target program to prove the instances in S + , only a polynomial number of
recursive clauses are possible; further the base clause must have a certain highly constrained
form. Thus the concept class is \almost" bounded in size by a polynomial. The learning
algorithm for such a program class is to interleave a series of equivalence queries that
test every possible target program. In contrast, our positive results are for exponentially
large classes of recursive clauses. Frazier and Page also present a series of negative results
suggesting that the learnable languages that they analyzed are dicult to generalize without
sacrificing ecient learnability.
Previous results also exist on the pac-learnability of nonrecursive constant-depth determinate programs, and on the pac-learnability of recursive constant-depth determinate
programs in a model that also allows membership and subset queries (Dzeroski et al.,
1992).
The basis for the intelligent search used in our learning algorithms is the technique
of forced simulation . This method finds the least implicant of a clause C that covers
an extended instance e. Although when we developed this method we believed it to be
original, subsequently we discovered that this was not the case|an identical technique had
been previously proposed by Ling (1991). Since an extended instance e can be converted
(via saturation) to a ground Horn clause, there is also a close connection between forced
532

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

simulation and recent work on \inverting implication" and \recursive anti-unification"; for
instance, Muggleton (1994) describes a nondeterministic procedure for finding all clauses
that imply a clause C , and Idestam-Almquist (1993) describes a means of constraining such
an implicant-generating procedure to produce the least common implicant of two clauses.
However, while both of these techniques have obvious applications in learning, both are
extremely expensive in the worst case.
The CRUSTACEAN system (Aha et al., 1994) uses inverting implication in constrained
settings to learn certain restricted classes of recursive programs. The class of programs
eciently learned by this system is not formally well-understood, but it appears to be
similar to the classes analyzed by Frazier and Page. Experimental results show that these
systems perform well on inferring recursive programs that use function symbols in certain
restricted ways. This system cannot, however, make use of background knowledge.
Finally, we wish to direct the reader to several pieces of our own research that are relevant. As noted above, a companion paper exists which presents negative learnability results
for several natural generalizations of the language kd-MaxRecLang (Cohen, 1995). Another related paper investigates the learnability of non-recursive Prolog programs (Cohen,
1993b); this paper also contains a number of negative results which strongly motivate the
restriction of constant-depth determinacy. A final prior paper which may be of interest
presents some experimental results with a Prolog implementation of a variant of the Force2
algorithm (Cohen, 1993a). This paper shows that forced simulation can be the basis of a
learning program that outperforms state-of-the art heuristic methods such as FOIL (Quinlan, 1990; Quinlan & Cameron-Jones, 1993) in learning from randomly chosen examples.

7. Conclusions
Just as it is often desirable to have guarantees of correctness for a program, in many
plausible contexts it would be highly desirable to have an automatic programming system
offer some formal guarantees of correctness. The topic of this paper is the learnability of
recursive logic programs using formally well-justified algorithms. More specifically, we have
been concerned with the development of algorithms that are provably sound and ecient in
learning recursive logic programs from equivalence queries. We showed that one constantdepth determinate closed k-ary recursive clause is identifiable from equivalent queries; this
implies immediately that this language is also learnable in Valiant's (1984) model of paclearnability. We also showed that a program consisting of one such recursive clause and
one constant-depth determinate nonrecursive clause is identifiable from equivalence queries
given an additional \basecase oracle", which determines if a positive example is covered by
the non-recursive base clause of the target program alone.
In obtaining these results, we have introduced several new formal techniques for analyzing the learnability of recursive programs. We have also shown the soundness and
eciency of several instances of generalization by forced simulation . This method may have
applications in practical learning systems. The Force2 algorithm compares quite well experimentally with modern ILP systems on learning problems from the restricted class that
it can identify (Cohen, 1993a); thus sound learning methods like Force2 might be useful as
a filter before a more general ILP system like FOIL (Quinlan, 1990; Quinlan & CameronJones, 1993). Alternatively, forced simulation could be used in heuristic programs. For
533

fiCohen

example, although forced simulation for programs with many recursive clauses is nondeterministic and hence potentially inecient, one could introduce heuristics that would make
the forced simulation ecient, at the cost of completeness.
A companion paper (Cohen, 1995) shows that the positive results of this paper are not
likely to be improved: either eliminating the basecase oracle for the language above or
learning two recursive clauses simultaneously is as hard as learning DNF, and learning n
linear recursive determinate clauses, one n-ary recursive determinate clause, or one linear
recursive \k-local" clause is as hard as breaking certain cryptographic codes. With the positive results of this paper, these negative results establish the boundaries of learnability for
recursive programs function-free in the pac-learnability model. These results thus not only
give a prescription for building a formally justified system for learning recursive programs;
taken together, they also provide upper bounds on what one can hope to achieve with an
ecient, formally justified system that learns recursive programs from random examples
alone.

Appendix A. Additional Proofs

Theorem 1 states: Let Dec = (p; a0; R) be a declaration in 2 a-DetDEC = , let nr = j Rj , let
X1; : : :; Xa be distinct variables, and define the clause BOTTOM d as follows:
0

BOTTOM d (Dec )  CONSTRAIN Dec (DEEPEN dDec (p(X1; : : :; Xa ) ))
0

For any constants d and a, the following are true:

 the size of BOTTOM d(Dec) is polynomial in nr ;
 every depth-d clause that satisfies Dec is equivalent to some subclause of
BOTTOM d (Dec ).

Proof: Let us first establish the polynomial bound on the size of BOTTOM d. Let C be a
clause of size n. As the number of variables in C is bounded by an, the size of the set LD

is bounded by

Thus for any clause C
By a similar argument

nr 
|{z}

(|an{z)a,1}

(# modes) (# tuples of input variables)

j DEEPEN Dec (C )j  n + (an)a,1nr

(1)

j CONSTRAIN Dec (C )j  n + (an)anr

(2)

Since both of the functions DEEPEN Dec and CONSTRAIN Dec give outputs that are polynomially larger in size than their inputs, if follows that composing these functions a constant
number of times, as was done in computing BOTTOM d for constant d, will also produce
only a polynomial increase in the size.
Next, we wish to show that every depth-d determinate clause C that satisfies Dec is
equivalent to some subclause of BOTTOM d . Let C be some depth-d determinate clause,
534

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

and without loss of generality let us assume that no pair of literals Li and Lj in the body
of C have the same mode, predicate symbol, and sequence of input variables.6
Given C , let us now define the substitution C as follows:
1. Initially set
C fX1 = X1; : : :; Xa = Xa g
where X1; : : :; Xa are the arguments to the head of BOTTOM d and X1 ; : : :; Xa are
the arguments to the head of C .
Notice that because the variables in the head of BOTTOM d are distinct, this mapping
is well-defined.
2. Next, examine each of the literals in the body of C in left-to-right order. For each
literal L, let variables T1; : : :Tk be its input variables. For each literal L in the
body BOTTOM d with the same mode and predicate symbol whose input variables
T1; : : :; Tk are such that 8i : 1  i  r; TjC = Tj , modify C as follows:
0

0

0

0

C [ fU1 = U1 ; : : :; Ul = Ul g
where U1 ; : : :; Ul are the output variables of L and U1; : : :; Ul are the output variables
of L .
Notice that because we assume that C contains only one literal L with a given predC

icate symbol and sequence of input variables, and because the output variables of
literals L in BOTTOM d are distinct, this mapping is again well-defined. It is also
easy to verify (by induction on the length of C ) that in executing this procedure some
variable in BOTTOM d is always mapped to each input variable Ti , and that at least
one L meeting the requirements above exists. Thus the mapping C is onto the
variables appearing in C .7
Let A be the head of BOTTOM d , and consider the clause C 0 which is defined as follows:
 The head of C 0 is A.
 The body of C 0 contains all literals L from the body of BOTTOM d such that either
{ LC is in the body of C
{ L is the literal equal (Xi; Xj) and XiC = XjC .
We claim that C 0 is a subclause of BOTTOM d that is equivalent to C . Certainly C 0
is a subclause of BOTTOM d . One way to see that it is equivalent to C is to consider
the clause C^ and the substitution ^C which are generated as follows. Initially, let C^ = C 0
and let ^C = C . Then, for every literal L = equal (Xi; Xj) in the body of C^ , delete L
^ ij and replace ^C with (^C )ij , where ij is the
from C^ , and finally replace C^ with C
substitution fXi = Xij ; Xj = Xij g and Xij is some new variable not previously appearing
6. This assumption can be made without loss of generality since for a determinate clause C , the output
variables of Li and Lj will necessarily be bound to the same values, and hence Li or Lj could be unified
together and one of them deleted without changing the semantics of C .
7. Recall that a function f : X Y is onto its range Y if 8y 2 Y 9x 2 X : f (x) = y.

535

fiCohen

in C^ . (Note: by (^C )ij we refer to the substitution formed by replacing every occurrence
of Xi or Xj appearing in ^C with Xij .) C^ is semantically equivalent to C 0 because the
operation described above is equivalent to simply resolving each possible L in the body of
C 0 against the clause \equal(X,X) ".
The following are now straightforward to verify:
 ^C is a one-to-one mapping.
To see that this is true, notice that for every pair of assignments Xi = Y and Xj =
Y in C there must be a literal equal (Xi; Xj) in C 0. Hence following the process
described above the assignments Xi = Y and Xj = Y in ^C would eventually be
replaced with Xij = Y and Xij = Y .

 ^C is onto the variables in C .
Notice that C was onto the variables in C , and for every assignment Xi = Y in C
there is some assignment in ^C with a right-hand side of Y (and this assignment is
either of the form Xi = Y or Xij = Y ). Thus ^C is also onto the variables in C .
 A literal L^ is in the body of C^ iff L^^C is in the body of C .
This follows from the definition of C 0 and from the fact that for every literal L from
C 0 that is not of the form equal (Xi; Xj) there is a corresponding literal in C^ .
Thus C^ is an alphabetic variant of C , and hence is equivalent to C . Since C^ is also equivalent
to C 0, it must be that C 0 is equivalent to C , which proves our claim.

Acknowledgements
The author wishes to thank three anonymous JAIR reviewers for a number of useful suggestions on the presentation and technical content.

References
Aha, D., Lapointe, S., Ling, C. X., & Matwin, S. (1994). Inverting implication with small
training sets. In Machine Learning: ECML-94 Catania, Italy. Springer-Verlag. Lecture
Notes in Computer Science # 784.
Angluin, D. (1988). Queries and concept learning. Machine Learning, 2 (4).
Angluin, D. (1989). Equivalence queries and approximate fingerprints. In Proceedings of
the 1989 Workshop on Computational Learning Theory Santa Cruz, California.
Bergadano, F., & Gunetti, D. (1993). An interactive system to learn functional logic programs. In Proceedings of the 13th International Joint Conference on Artificial Intelligence Chambery, France.
536

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

Biermann, A. (1978). The inference of regular lisp programs from examples. IEEE Transactions on Systems, Man and Cybernetics, 8 (8).
Cohen, W. W. (1993a). A pac-learning algorithm for a restricted class of recursive logic
programs. In Proceedings of the Tenth National Conference on Artificial Intelligence
Washington, D.C.
Cohen, W. W. (1993b). Pac-learning non-recursive Prolog clauses. To appear in Artificial
Intelligence.
Cohen, W. W. (1993c). Rapid prototyping of ILP systems using explicit bias. In Proceedings
of the 1993 IJCAI Workshop on Inductive Logic Programming Chambery, France.
Cohen, W. W. (1994). Pac-learning nondeterminate clauses. In Proceedings of the Eleventh
National Conference on Artificial Intelligence Seattle, WA.
Cohen, W. W. (1995). Pac-learning recursive logic programs: negative results. Journal of
AI Research, 2, 541{573.
De Raedt, L., & Bruynooghe, M. (1992). Interactive concept-learning and constructive
induction by analogy. Machine Learning, 8 (2).
De Raedt, L., & Dzeroski, S. (1994). First-order jk-clausal theories are PAC-learnable.
In Wrobel, S. (Ed.), Proceedings of the Fourth International Workshop on Inductive
Logic Programming Bad Honnef/Bonn, Germany.
De Raedt, L., Lavrac, N., & Dzeroski, S. (1993). Multiple predicate learning. In Proceedings
of the Third International Workshop on Inductive Logic Programming Bled, Slovenia.
Dzeroski, S., Muggleton, S., & Russell, S. (1992). Pac-learnability of determinate logic
programs. In Proceedings of the 1992 Workshop on Computational Learning Theory
Pittsburgh, Pennsylvania.
Frazier, M., & Page, C. D. (1993a). Learnability in inductive logic programming: Some
basic results and techniques. In Proceedings of the Tenth National Conference on
Artificial Intelligence Washington, D.C.
Frazier, M., & Page, C. D. (1993b). Learnability of recursive, non-determinate theories:
Some basic results and techniques. In Proceedings of the Third International Workshop
on Inductive Logic Programming Bled, Slovenia.
Gold, M. (1967). Language identification in the limit. Information and Control, 10.
Hirsh, H. (1992). Polynomial-time learning with version spaces. In Proceedings of the Tenth
National Conference on Artificial Intelligence San Jose, California. MIT Press.
Idestam-Almquist, P. (1993). Generalization under implication by recursive anti-unification.
In Proceedings of the Ninth International Conference on Machine Learning Amherst,
Massachusetts. Morgan Kaufmann.
537

fiCohen

King, R. D., Muggleton, S., Lewis, R. A., & Sternberg, M. J. E. (1992). Drug design by
machine learning: the use of inductive logic programming to model the structureactivity relationships of trimethoprim analogues binding to dihydrofolate reductase.
Proceedings of the National Academy of Science, 89.
Lavrac, N., & Dzeroski, S. (1992). Background knowledge and declarative bias in inductive
concept learning. In Jantke, K. P. (Ed.), Analogical and Inductive Inference: International Workshop AII'92. Springer Verlag, Daghstuhl Castle, Germany. Lectures in
Artificial Intelligence Series #642.
Ling, C. (1991). Inventing necessary theoretical terms in scientific discovery and inductive
logic programming. Tech. rep. 301, University of Western Ontario.
Ling, C. (1992). Logic program synthesis from good examples. In Inductive Logic Programming. Academic Press.
Lloyd, J. W. (1987). Foundations of Logic Programming: Second Edition. Springer-Verlag.
Muggleton, S. (1994). Inverting implication. To appear in Artificial Intelligence.
Muggleton, S., & De Raedt, L. (1994). Inductive logic programming: Theory and methods.
Journal of Logic Programming, 19/20 (7), 629{679.
Muggleton, S., & Feng, C. (1992). Ecient induction of logic programs. In Inductive Logic
Programming. Academic Press.
Muggleton, S., King, R. D., & Sternberg, M. J. E. (1992). Protein secondary structure
prediction using logic-based machine learning. Protein Engineering, 5 (7), 647{657.
Muggleton, S., & Page, C. D. (1994). A learnability model for universal representations.
In Wrobel, S. (Ed.), Proceedings of the Fourth International Workshop on Inductive
Logic Programming Bad Honnef/Bonn, Germany.
Muggleton, S. H. (Ed.). (1992). Inductive Logic Programming. Academic Press.
Nienhuys-Cheng, S., & Polman, M. (1994). Sample pac-learnability in model inference.
In Machine Learning: ECML-94 Catania, Italy. Springer-Verlag. Lecture notes in
Computer Science # 784.
Page, C. D., & Frisch, A. M. (1992). Generalization and learnability: A study of constrained
atoms. In Inductive Logic Programming. Academic Press.
Pazzani, M., & Kibler, D. (1992). The utility of knowledge in inductive learning. Machine
Learning, 9 (1).
Quinlan, J. R., & Cameron-Jones, R. M. (1993). FOIL: A midterm report. In Brazdil, P. B.
(Ed.), Machine Learning: ECML-93 Vienna, Austria. Springer-Verlag. Lecture notes
in Computer Science # 667.
Quinlan, J. R. (1990). Learning logical definitions from relations. Machine Learning, 5 (3).
538

fiPac-Learning Recursive Logic Programs: Efficient Algorithms

Quinlan, J. R. (1991). Determinate literals in inductive logic programming. In Proceedings
of the Eighth International Workshop on Machine Learning Ithaca, New York. Morgan
Kaufmann.
Rouveirol, C. (1994). Flattening and saturation: two representation changes for generalization. Machine Learning, 14 (2).
Shapiro, E. (1982). Algorithmic Program Debugging. MIT Press.
Srinivasan, A., Muggleton, S. H., King, R. D., & Sternberg, M. J. E. (1994). Mutagenesis:
ILP experiments in a non-determinate biological domain. In Wrobel, S. (Ed.), Proceedings of the Fourth International Workshop on Inductive Logic Programming Bad
Honnef/Bonn, Germany.
Stahl, I., Tausend, B., & Wirth, R. (1993). Two methods for improving inductive logic
programming. In Proceedings of the 1993 European Conference on Machine Learning
Vienna, Austria.
Summers, P. D. (1977). A methodology for LISP program construction from examples.
Journal of the Association for Computing Machinery, 24 (1), 161{175.
Valiant, L. G. (1984). A theory of the learnable. Communications of the ACM, 27 (11).
Zelle, J. M., & Mooney, R. J. (1994). Inducing deterministic Prolog parsers from treebanks:
a machine learning approach. In Proceedings of the Twelfth National Conference on
Artificial Intelligence Seattle, Washington. MIT Press.

539

fiJournal of Artificial Intelligence Research 2 (1995) 575-609

Submitted 12/94; published 5/95

Provably Bounded-Optimal Agents
Stuart J. Russell

Computer Science Division, University of California
Berkeley, CA 94720, USA

Devika Subramanian

Computer Science Department, Cornell University
Ithaca, NY 14853, USA

russell@cs.berkeley.edu
devika@cs.cornell.edu

Abstract

Since its inception, artificial intelligence has relied upon a theoretical foundation centred around perfect rationality as the desired property of intelligent systems. We argue,
as others have done, that this foundation is inadequate because it imposes fundamentally
unsatisfiable requirements. As a result, there has arisen a wide gap between theory and
practice in AI, hindering progress in the field. We propose instead a property called bounded
optimality. Roughly speaking, an agent is bounded-optimal if its program is a solution to
the constrained optimization problem presented by its architecture and the task environment. We show how to construct agents with this property for a simple class of machine
architectures in a broad class of real-time environments. We illustrate these results using
a simple model of an automated mail sorting facility. We also define a weaker property,
asymptotic bounded optimality (ABO), that generalizes the notion of optimality in classical
complexity theory. We then construct universal ABO programs, i.e., programs that are
ABO no matter what real-time constraints are applied. Universal ABO programs can be
used as building blocks for more complex systems. We conclude with a discussion of the
prospects for bounded optimality as a theoretical basis for AI, and relate it to similar trends
in philosophy, economics, and game theory.

1. Introduction

Since before the beginning of artificial intelligence, philosophers, control theorists and
economists have looked for a satisfactory definition of rational behaviour. This is needed to
underpin theories of ethics, inductive learning, reasoning, optimal control, decision-making,
and economic modelling. Doyle (1983) has proposed that AI itself be defined as the computational study of rational behaviour|effectively equating rational behaviour with intelligence. The role of such definitions in AI is to ensure that theory and practice are correctly
aligned. If we define some property P , then we hope to be able to design a system that
provably possesses property P . Theory meets practice when our systems exhibit P in reality. Furthermore, that they exhibit P in reality should be something that we actually care
about. In a sense, the choice of what P to study determines the nature of the field.
There are a number of possible choices for P :
 Perfect rationality: the classical notion of rationality in economics and philosophy.
A perfectly rational agent acts at every instant in such a way as to maximize its
expected utility, given the information it has acquired from the environment. Since
action selection requires computation, and computation takes time, perfectly rational
agents do not exist for non-trivial environments.
c 1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiRussell & Subramanian

 Calculative rationality: the notion of rationality studied in AI. A calculatively rational

agent eventually returns what would have been the rational choice at the beginning of
its deliberation. There exist systems such as inuence diagram evaluators that exhibit
this property for a decision-theoretic definition of rational choice, and systems such
as nonlinear planners that exhibit it for a logical definition of rational choice. This
is assumed to be an interesting property for a system to exhibit since it constitutes
an \in-principle" capacity to do the right thing. Calculative rationality is of limited
value in practice, because the actual behaviour exhibited by such systems is absurdly
far from being rational; for example, a calculatively rational chess program will choose
the right move, but may take 1050 times too long to do so. As a result, AI systembuilders often ignore theoretical developments, being forced to rely on trial-and-error
engineering to achieve their goals. Even in simple domains such as chess, there is little
theory for designing and analysing high-performance programs.
 Metalevel rationality: a natural response to the problems of calculative rationality.
A metalevel rational system optimizes over the object-level computations to be performed in the service of selecting actions. In other words, for each decision it finds
the optimal combination of computation-sequence-plus-action, under the constraint
that the action must be selected by the computation. Full metalevel rationality is
seldom useful because the metalevel computations themselves take time, and the metalevel decision problem is often more dicult than the object-level problem. Simple
approximations to metalevel rationality have proved useful in practice|for example, metalevel policies that limit lookahead in chess programs|but these engineering
expedients merely serve to illustrate the lack of a theoretical basis for agent design.
 Bounded optimality: a bounded optimal agent behaves as well as possible given its
computational resources. Bounded optimality specifies optimal programs rather than
optimal actions or optimal computation sequences. Only by the former approach
can we avoid placing constraints on intelligent agents that cannot be met by any
program. Actions and computations are, after all, generated by programs, and it is
over programs that designers have control.
We make three claims:
1. A system that exhibits bounded optimality is desirable in reality.
2. It is possible to construct provably bounded optimal programs.
3. Artificial intelligence can be usefully characterized as the study of bounded optimality,
particularly in the context of complex task environments and reasonably powerful
computing devices.
The first claim is unlikely to be controversial. This paper supports the second claim in
detail. The third claim may, or may not, stand the test of time.
We begin in section 2 with a necessarily brief discussion of the relationship between
bounded optimality and earlier notions of rationality. We note in particular that some important distinctions can be missed without precise definitions of terms. Thus in section 3 we
provide formal definitions of agents, their programs, their behaviour and their rationality.
576

fiProvably bounded-optimal agents

Together with formal descriptions of task environments, these elements allow us to prove
that a given agent exhibits bounded optimality. Section 4 examines a class of agent architectures for which the problem of generating bounded optimal configurations is eciently
soluble. The solution involves a class of interesting and practically relevant optimization
problems that do not appear to have been addressed in the scheduling literature. We illustrate the results by showing how the throughput of an automated mail-sorting facility
might be improved. Section 5 initiates a discussion of how bounded optimal configurations
might be learned from experience in an environment. In section 6, we define a weaker property, asymptotic bounded optimality (ABO), that may be more robust and tractable than
the strict version of bounded optimality. In particular, we can construct universal ABO
programs. A program is universally ABO if it is ABO regardless of the specific form of
time dependence of the utility function.1 Universal ABO programs can therefore be used as
building blocks for more complex systems. We conclude with an assessment of the prospects
for further development of this approach to artificial intelligence.

2. Historical Perspective
The classical idea of perfect rationality, which developed from Aristotle's theories of ethics,
work by Arnauld and others on choice under uncertainty, and Mill's utilitarianism, was put
on a formal footing in decision theory by Ramsey (1931) and vonNeumann and Morgernstern
(1947). It stipulates that a rational agent always act so as to maximize its expected utility.
The expectation is taken according to the agent's own beliefs; thus, perfect rationality does
not require omniscience.
In artificial intelligence, the logical definition of rationality, known in philosophy as the
\practical syllogism", was put forward by McCarthy (1958), and reiterated strongly by
Newell (1981). Under this definition, an agent should take any action that it believes is
guaranteed to achieve any of its goals. If AI can be said to have had a theoretical foundation, then this definition of rationality has provided it. McCarthy believed, probably
correctly, that in the early stages of the field it was important to concentrate on \epistemological adequacy" before \heuristic adequacy" | that is, capability in principle rather than
in practice. The methodology that has resulted involves designing programs that exhibit
calculative rationality, and then using various speedup techniques and approximations in
the hope of getting as close as possible to perfect rationality. Our belief, albeit unproven, is
that the simple agent designs that fulfill the specification of calculative rationality may not
provide good starting points from which to approach bounded optimality. Moreover, a theoretical foundation based on calculative rationality cannot provide the necessary guidance
in the search.
It is not clear that AI would have embarked on the quest for calculative rationality had it
not been operating in the halcyon days before formal intractability results were discovered.
One response to the spectre of complexity has been to rule it out of bounds. Levesque and
Brachman (1987) suggest limiting the complexity of the environment so that calculative and
perfect rationality coincide. Doyle and Patil (1991) argue strongly against this position.
1. This usage of the term \universal" derives from its use in the scheduling of randomized algorithms by
Luby, Sinclair and Zuckerman (1993).

577

fiRussell & Subramanian

Economists have used perfect rationality as an abstract model of economic entities, for
the purposes of economic forecasting and designing market mechanisms. This makes it
possible to prove theorems about the properties of markets in equilibrium. Unfortunately,
as Simon (1982) pointed out, real economic entities have limited time and limited powers
of deliberation. He proposed the study of bounded rationality, investigating \: : : the shape
of a system in which effectiveness in computation is one of the most important weapons
of survival." Simon's work focussed mainly on satisficing designs, which deliberate until
reaching some solution satisfying a preset \aspiration level." The results have descriptive value for modelling various actual entities and policies, but no general prescriptive
framework for bounded rationality was developed. Although it proved possible to calculate
optimal aspiration levels for certain problems, no structural variation was allowed in the
agent design.
In the theory of games, bounds on the complexity of players have become a topic of
intense interest. For example, it is a troubling fact that defection is the only equilibrium
strategy for unbounded agents playing a fixed number of rounds of the Prisoners' Dilemma
game. Neyman's theorem (Neyman, 1985), recently proved by Papadimitriou and Yannakakis (1994), shows that an essentially cooperative equilibrium exists if each agent is a
finite automaton with a number of states that is less than exponential in the number of
rounds. This is essentially a bounded optimality result, where the bound is on space rather
than on speed of computation. This type of result is made possible by a shift from the
problem of selecting actions to the problem of selecting programs.
I. J. Good (1971) distinguished between perfect or \type I" rationality, and metalevel
or \type II" rationality. He defines this as \the maximization of expected utility taking into
account deliberation costs." Simon (1976) also says: \The global optimization problem is
to find the least-cost or best-return decision, net of computational costs." Although type II
rationality seems to be a step in the right direction, it is not entirely clear whether it can be
made precise in a way that respects the desirable intuition that computation is important.
We will try one interpretation, although there may be others.2 The key issue is the space
over which the \maximization" or \optimization" occurs. Both Good and Simon seem to
be referring to the space of possible deliberations associated with a particular decision.
Conceptually, there is an \object-level machine" that executes a sequence of computations
under the control of a \meta-level machine." The outcome of the sequence is the selection of
an external action. An agent exhibits type II rationality if at the end of its deliberation and
subsequent action, its utility is maximized compared to all possible deliberate/act pairs in
which it could have engaged. For example, Good discusses one possible application of type
II rationality in chess programs. In this case, the object-level steps are node expansions in
the game tree, followed by backing up of leaf node evaluations to show the best move. For
simplicity we will assume a per-move time limit. Then a type II rational agent will execute
whichever sequence of node expansions chooses the best move, of all those that finish before
2. For example, it is conceivable that Good and Simon really intended to refer to finding an agent design
that minimizes deliberation costs in general. All their discussions, however, seem to be couched in terms
of finding the right deliberation for each decision. Thus, type II or metalevel rationality coincides with
bounded optimality if the bounded optimal agent is being designed for a single decision in a single
situation.

578

fiProvably bounded-optimal agents

the time limit.3 Unfortunately, the computations required in the \metalevel machine" to
select the object-level deliberation may be extremely expensive. Good actually proposes a
fairly simple (and nearly practical) metalevel decision procedure for chess, but it is far from
optimal. It is hard to see how a type II rational agent could justify executing a suboptimal
object-level computation sequence if we limit the scope of the optimization problem to a
single decision. The diculty can only be resolved by thinking about the design of the
agent program, which generates an unbounded set of possible deliberations in response to
an unbounded set of circumstances that may arise during the life of the agent.
Philosophy has also seen a gradual evolution in the definition of rationality. There has
been a shift from consideration of act utilitarianism | the rationality of individual acts | to
rule utilitarianism, or the rationality of general policies for acting. This shift has been caused
by diculties with individual versus societal rationality, rather than any consideration of
the diculty of computing rational acts. Some consideration has been given more recently
to the tractability of general moral policies, with a view to making them understandable
and usable by persons of average intelligence (Brandt, 1953). Cherniak (1986) has suggested
a definition of \minimal rationality", specifying lower bounds on the reasoning powers of
any rational agent, instead of upper bounds. A philosophical proposal generally consistent
with the notion of bounded optimality can be found in Dennett's \Moral First Aid Manual"
(1986). Dennett explicitly discusses the idea of reaching equilibrium within the space of
decision procedures. He uses as an example the PhD admissions procedure of a philosophy
department. He concludes, as do we, that the best procedure may be neither elegant nor
illuminating. The existence of such a procedure, and the process of reaching it, are the
main points of interest.
Many researchers in AI, some of whose work is discussed below, have worked on the
problem of designing agents with limited computational resources. The 1989 AAAI Symposium on AI and Limited Rationality (Fehling & Russell, 1989) contains an interesting
variety of work on the topic. Much of this work is concerned with metalevel rationality.
Metareasoning | reasoning about reasoning | is an important technique in this area,
since it enables an agent to control its deliberations according to their costs and benefits.
Combined with the idea of anytime (Dean & Boddy, 1988) or exible algorithms (Horvitz,
1987), that return better results as time goes by, a simple form of metareasoning allows
an agent to behave well in a real-time environment. A simple example is provided by
iterative-deepening algorithms used in game-playing. Breese and Fehling (1990) apply similar ideas to controlling multiple decision procedures. Russell and Wefald (1989) give a
general method for precompiling certain aspects of metareasoning so that a system can eciently estimate the effects of individual computations on its intentions, giving fine-grained
control of reasoning. These techniques can all be seen as approximating metalevel rationality; they provide useful insights into the general problem of control of reasoning, but there
is no reason to suppose that the approximations used are optimal in any sense.
The intuitive notion of bounded optimality seems to have become current in the AI
community in the mid-1980's. Horvitz (1987) uses the term bounded optimality to refer
to \the optimization of computational utility given a set of assumptions about expected
3. One would imagine that in most cases the move selected will be the same move selected by a Type
I agent, but this is in a sense \accidental" because further deliberation might cause the program to
abandon it.

579

fiRussell & Subramanian

problems and constraints in reasoning resources." Russell and Wefald (1991) say that an
agent exhibits bounded optimality for a given task environment \if its program is a solution
to the constrained optimization problem presented by its architecture." Recent work by
Etzioni (1989) and Russell and Zilberstein (1991) can be seen as optimizing over a welldefined set of agent designs, thereby making the notion of bounded optimality more precise.
In the next section, we build a suitable set of general definitions from the ground up, so
that we can begin to demonstrate examples of provably bounded optimal agents.

3. Agents, Architectures and Programs
Intuitively, an agent is just a physical entity that we wish to view in terms of its perceptions
and actions. What counts in the first instance is what it does, not necessarily what it thinks,
or even whether it thinks at all. This initial refusal to consider further constraints on the
internal workings of the agent (such as that it should reason logically, for example) helps in
three ways: first, it allows us to view such \cognitive faculties" as planning and reasoning
as occurring in the service of finding the right thing to do; second, it makes room for those
among us (Agre & Chapman, 1987; Brooks, 1986) who take the position that systems can
do the right thing without such cognitive faculties; third, it allows more freedom to consider
various specifications, boundaries and interconnections of subsystems.
We begin by defining agents and environments in terms of the actions and percepts
that they exchange, and the sequence of states they go through. The agent is described
by an agent function from percept sequences to actions. This treatment is fairly standard
(see, e.g., Genesereth & Nilsson, 1987). We then go \inside" the agent to look at the agent
program that generates its actions, and define the \implementation" relationship between
a program and the corresponding agent function. We consider performance measures on
agents, and the problem of designing agents to optimize the performance measure.

3.1 Specifying agents and environments

An agent can be described abstractly as a mapping (the agent function) from percept
sequences to actions. Let O be the set of percepts that the agent can receive at any instant,
and A be the set of possible actions the agent can carry out in the external world. Since
we are interested in the behaviour of the agent over time, we introduce a set of time points
or instants, T. The set T is totally ordered by the < relation with a unique least element.
Without loss of generality, we let T be the set of non-negative integers.
The percept history of an agent is a sequence of percepts indexed by time. We define
the set of percept histories to be OT = fOT : T ! Og. The prefix of a history OT 2 OT
till time t is denoted Ot and is the projection of OT on [0::t]. We can define the set of
percept history prefixes as Ot = fOt j t 2 T; OT 2 OTg. Similarly, we define the set of
action histories AT = fAT : T ! Ag. The set of action history prefixes is At, defined as
the set of projections At of histories AT 2 AT .

Definition 1 Agent function: a mapping
f : Ot ! A
580

fiProvably bounded-optimal agents

where

AT(t) = f (Ot)
Note that the agent function is an entirely abstract entity, unlike the agent program that
implements it. Note also that the \output" of the agent function for a given percept sequence
may be a null action, for example if the agent is still thinking about what to do. The agent
function specifies what the agent does at each time step. This is crucial to the distinction
between perfect rationality and calculative rationality.
Agents live in environments. The states of an environment E are drawn from a set X.
The set of possible state trajectories is defined as XT = fX T : T ! Xg. The agent does not
necessarily have full access to the current state X T(t), but the percept received by the agent
does depend on the current state through the perceptual filtering function fp. The effects
of the agent's actions are represented by the environment's transition function fe, which
specifies the next state given the current state and the agent's action. An environment is
therefore defined as follows:

Definition 2 Environment E : a set of states X with a distinguished initial state X0, a
transition function fe and a perceptual filter function fp such that

X T (0) = X0
X T(t + 1) = fe(AT (t); X T(t))
OT(t) = fp(X T(t))
The state history X T is thus determined by the environment and the agent function. We
use the notation effects(f; E ) to denote the state history generated by an agent function
f operating in an environment E . We will also use the notation [E; At ] to denote the
state history generated by applying the action sequence At starting in the initial state of
environment E .
Notice that the environment is discrete and deterministic in this formulation. We can
extend the definitions to cover non-deterministic and continuous environments, but at the
cost of additional complexity in the exposition. None of our results depend in a significant
way on discreteness or determinism.

3.2 Specifying agent implementations

We will consider a physical agent as consisting of an architecture and a program. The
architecture is responsible for interfacing between the program and the environment, and
for running the program itself. With each architecture M , we associate a finite programming
language LM , which is just the set of all programs runnable by the architecture. An agent
program is a program l 2 LM that takes a percept as input and has an internal state drawn
from a set I with initial state i0. (The initial internal state depends on the program l,
but we will usually suppress this argument.) The set of possible internal state histories is
IT = fI T : T ! Ig. The prefix of an internal state history I T 2 IT till time t is denoted I t
and is the projection of I T on [0::t].
581

fiRussell & Subramanian

Definition 3 An architecture M is a fixed interpreter for an agent program that runs the

program for a single time step, updating its internal state and generating an action:
M : LM  I  O ! I  A
where
hI T(t + 1); AT(t)i = M (l; I T(t); OT(t))
Thus, the architecture generates a stream of actions according to the dictates of the program.
Because of the physical properties of the architecture, running the program for a single
time step results in the execution of only a finite number of instructions. The program may
often fail to reach a \decision" in that time step, and as a result the action produced by the
architecture may be null (or the same as the previous action, depending on the program
design).

3.3 Relating agent specifications and implementations

We can now relate agent programs to the corresponding agent functions. We will say that an
agent program l running on a machine M implements the agent function Agent(l; M ). The
agent function is constructed in the following definition by specifying the action sequences
produced by l running on M for all possible percept sequences. Note the importance of the
\Markovian" construction using the internal state of the agent to ensure that actions can
only be based on the past, not the future.

Definition 4 A program l running on M implements the agent function f = Agent(l; M ),
defined as follows. For any environment E = (X; fe; fp), f (Ot) = AT (t) where
hI T(t + 1); AT(t)i = M (l; I T(t); OT(t))
OT (t)
X T(t + 1)
X T(0)
I T(0)

=
=
=
=

fp(X T(t))
fe(AT(t); X T(t))
X0
i0

Although every program l induces a corresponding agent function Agent(l; M ), the
action that follows a given percept is not necessarily the agent's \response" to that percept;
because of the delay incurred by deliberation, it may only reect percepts occurring much
earlier in the sequence. Furthermore, it is not possible to map every agent function to an
implementation l 2 LM . We can define a subset of the set of agent functions f that are
implementable on a given architecture M and language LM :
Feasible(M ) = ff j 9l 2 LM ; f = Agent(l; M )g
Feasibility is related to, but clearly distinct from, the notion of computability. Computability refers to the existence of a program that eventually returns the output specified by
a function, whereas feasibility refers to the production of the output at the appropriate
point in time. The set of feasible agent functions is therefore much smaller than the set of
computable agent functions.
582

fiProvably bounded-optimal agents

3.4 Performance measures for agents

To evaluate an agent's performance in the world, we define a real-valued utility function U
on state histories:
U : XT ! <
The utility function should be seen as external to the agent and its environment. It defines
the problem to be solved by the designer of the agent. Some agent designs may incorporate
an explicit representation of the utility function, but this is by no means required. We will
use the term task environment to denote the combination of an environment and a utility
function.
Recall that the agent's actions drive the environment E through a particular sequence
of states in accordance with the function effects(f; E ). We can define the value of an agent
function f in the environment E as the utility of the state history it generates:
V (f; E ) = U (effects(f; E ))
If the designer has a set E of environments with a probability distribution p over them,
instead of a single environment E , then the value of the agent in E is defined as the
expected value over the elements of E. By a slight abuse of notation,

V (f; E) =

X

E2E

p(E )V (f; E )

We can assign a value V (l; M; E ) to a program l executed by the architecture M in the
environment E simply by looking at the effect of the agent function implemented by the
program:
V (l; M; E ) = V (Agent(l; M ); E ) = U (effects(Agent(l; M ); E ))
As above, we can extend this to a set of possible environments as follows:

V (l; M; E) =

X

E2E

p(E )V (l; M; E )

3.5 Perfect rationality and bounded optimality

As discussed in Section 2, a perfectly rational agent selects the action that maximizes its
expected utility, given the percepts so far. In our framework, this amounts to an agent
function that maximizes V (f; E) over all possible agent functions.
Definition 5 A perfectly rational agent for a set E of environments has an agent function
fopt such that
fopt = argmaxf (V (f; E))
This definition is a persuasive specification of an optimal agent function for a given
set of environments, and underlies several recent projects in intelligent agent design (Dean
& Wellman,1991; Doyle, 1988; Hansson & Mayer, 1989). A direct implementation of this
specification, which ignores the delay incurred by deliberation, does not yield a reasonable
583

fiRussell & Subramanian

solution to our problem { the calculation of expected utilities takes time for any real agent.
In terms of our simple formal description of agents introduced above, it is easy to see where
the diculty has arisen. In designing the agent program, logicists and decision theorists
have concentrated on specifying an optimal agent function fopt in order to guarantee the
selection of the best action history. The function fopt is independent of the architecture M .
Unfortunately, no real program in LM implements this function in a non-trivial environment,
because optimal actions cannot usually be computed before the next percept arrives. That
is, quite frequently, fopt 62 Feasible(M ).
Suppose the environment consists of games of chess under tournament rules against some
population of human grandmasters, and suppose M is some standard personal computer.
Then fopt describes an agent that always plays in such a way as to maximize its total
expected points against the opposition, where the maximization is over the moves it makes.
We claim that no possible program can play this way. It is quite possible, using depth-first
alpha-beta search to termination, to execute the program that chooses (say) the optimal
minimax move in each situation, but the agent function induced by this program is not the
same as fopt. In particular, it ignores such percepts as the dropping of its ag indicating a
loss on time.
The trouble with the perfect rationality definition arose because of unconstrained optimization over the space of f 's in the determination of fopt , without regard to feasibility.
(Similarly, metalevel rationality assumes unconstrained optimization over the space of deliberations.) To escape this quandary, we propose a machine-dependent standard of rationality, in which we maximize V over the implementable set of agent functions Feasible(M ).
That is, we impose optimality constraints on programs rather than on agent functions or
deliberations.

Definition 6 A bounded-optimal agent with architecture M for a set E of environments
has an agent program lopt such that
lopt = argmaxl2LM V (l; M; E)

We can see immediately that this specification avoids the most obvious problems with
Type I and Type II rationality. Consider our chess example, and
suppose the computer has
26
2
a total program memory of 8 megabytes. Then there are 2 possible programs that can
be represented in the machine, of which a much smaller number play legal chess. Under
tournament conditions, one or more of these programs will have the best expected performance. Each is a suitable candidate for lopt. Thus bounded optimality is, by definition, a
feasible specification; moreover, a program that achieves it is highly desirable. We are not
yet ready to announce the identity of lopt for chess on an eight-megabyte PC, so we will
begin with a more restricted problem.

4. Provably Bounded-Optimal Agents

In order to construct a provably bounded optimal agent, we must carry out the following
steps:
 Specify the properties of the environment in which actions will be taken, and the
utility function on the behaviours.
584

fiProvably bounded-optimal agents

 Specify a class of machines on which programs are to be run.
 Propose a construction method.
 Prove that the construction method succeeds in building bounded optimal agents.
The methodology is similar to the formal analysis used in the field of optimal control, which
studies the design of controllers (agents) for plants (environments). In optimal control
theory, a controller is viewed as an essentially instantaneous implementation of an optimal
agent function. In contrast, we focus on the computation time required by the agent, and
the relation between computation time and the dynamics of the environment.

4.1 Episodic, real-time task environments

In this section, we will consider a restricted class of task environments which we call episodic
environments. In an episodic task environment, the state history generated by the actions of
the agent can be considered as divided into a series of episodes, each of which is terminated
by an action. Let A?  A be a distinguished set of actions that terminate an episode.
The utility of the complete history is given by the sum of the utilities of each episode,
which is determined in turn by the state sequence. After each A 2 A?, the environment
\resets" to a state chosen at random from a stationary probability distribution Pinit . In
order to include the effects of the choice of A in the utility of the episode, we notionally
divide the environment state into a \configuration" part and a \value" part, such that
the configuration part determines the state transitions while the value part determines the
utility of a state sequence. Actions in A? reset the configuration part, while their \value"
is recorded in the value part. These restrictions mean that each episode can be treated as
a separate decision problem, and translate into the following property: if agent program l1
has higher expected utility on individual episodes than agent l2, it will have higher expected
utility in the corresponding episodic task environment.
A real-time task environment is one in which the utility of an action depends on the
time at which it is executed. Usually, this dependence will be suciently strong to make
calculative rationality an unacceptably bad approximation to perfect rationality.
An automated mail sorter4 provides an illustrative example of an episodic task environment (see Figure 1). Such a machine scans handwritten or printed addresses (zipcodes) on
mail pieces and dispatches them to appropriate bins. Each episode starts with the arrival of
a new mail piece and terminates with the execution of the physical action recommended by
the sorter: routing of the piece to a specific bin. The \configuration part" of the environment corresponds to the letter feeder side, which provides a new, randomly selected letter
after the previous letter is sorted. The \value part" of the state corresponds to the state of
the receiving bins, which determines the utility of the process. The aim is to maximize the
accuracy of sorting while minimizing the reject percentage and avoiding jams. A jam occurs
if the current piece is not routed to the appropriate bin, or rejected, before the arrival of
the next piece.
We now provide formal definitions for three varieties of real-time task environments:
fixed deadlines, fixed time cost and stochastic deadlines.
4. See (Sackinger et al. 1992; Boser et al. 1992) for details of an actual system. The application was
suggested to us by Bernhard Boser after an early presentation of our work at the 1992 NEC Symposium.

585

fiRussell & Subramanian

camera
sacks of mail

zipcode
buckets

reject

Figure 1: An automated mail-sorting facility provides a simple example of an episodic,
real-time task environment.
4.1.1 Fixed deadlines

The simplest and most commonly studied kind of real-time task environment contains a
deadline at a known time. In most work on real-time systems, such deadlines are described
informally and systems are built to meet the deadline. Here, we need a formal specification
in order to connect the description of the deadline to the properties of agents running in
deadline task environments. One might think that deadlines are part of the environment
description, but in fact they are mainly realized as constraints on the utility function. One
can see this by considering the opposite of a deadline | the \starter's pistol." The two
are distinguished by differing constraints on the utilities of acting before or after a specific
time.
Definition 7 Fixed deadline: The task environment hE; U i has a fixed deadline at time td
if the following conditions hold.
 Taking an action in A? at any time before the deadline results in the same utility:

U ([E; At1]) = U ([E; A(2td ,1)  AT1 (t)])
where \" denotes sequence concatenation, t  td , AT1 (t) 2 A? , and A(1t,1) and A(2td ,1)
contain no action in A?.
 Actions taken after td have no effect on utility:

U ([E; At1])  U ([E; At2]) if U ([E; At1d ])  U ([E; At2d ]) and t  td
4.1.2 Fixed time cost

Task environments with approximately fixed time cost are also very common. Examples
include consultations with lawyers, keeping a taxi waiting, or dithering over where to invest
one's money. We can define a task environment with fixed time cost c by comparing the
utilities of actions taken at different times.
586

fiProvably bounded-optimal agents

Definition 8 Fixed time cost:
The task environment hE; U i has a fixed time cost if, for
t
t
any action history prefixes A11 and A22 satisfying
(1) AT1 (t1) 2 A? and AT2 (t2) = AT1 (t1)
(2) A(1t1 ,1) and A(2t2 ,1) contain no action in A?
the utilities differ by the difference in time cost:
U ([E; At22 ]) = U ([E; At11 ]) , c(t2 , t1)

Strictly speaking, there are no task environments with fixed time cost. Utility values have a
finite range, so one cannot continue incurring time costs indefinitely. For reasonably short
times and reasonably small costs, a linear utility penalty is a useful approximation.
4.1.3 Stochastic deadlines

While fixed-deadline and fixed-cost task environments occur frequently in the design of
real-time systems, uncertainty about the time-dependence of the utility function is more
common. It also turns out to be more interesting, as we see below.
A stochastic deadline is represented by uncertainty concerning the time of occurrence of
a fixed deadline. In other words, the agent has a probability distributionPpd for the deadline
time td . We assume that the deadline must come eventually, so that t2T pd (t) = 1. We
also define the cumulative deadline distribution Pd .
If the deadline does not occur at a known time, then we need to distinguish between
two cases:
 The agent receives a percept, called a herald (Dean & Boddy, 1988), which announces
an impending deadline. We model this using a distinguished percept Od :

OT(td ) = Od
If the agent responds immediately, then it \meets the deadline."
 No such percept is available, in which case the agent is walking blindfolded towards
the utility cliff. By deliberating further, the agent risks missing the deadline but may
improve its decision quality. An example familiar to most readers is that of deciding
whether to publish a paper in its current form, or to embellish it further and risk
being \scooped." We do not treat this case in the current paper.
Formally, the stochastic deadline case is similar to the fixed deadline case, except that td is
drawn from the distribution pd . The utility of executing an action history prefix At in E is
the expectation of the utilities of that state history prefix over the possible deadline times.
Definition 9 Stochastic deadline: A task environment class hE; U i of fixed-deadline task
environments has a stochastic deadline distributed according to pd if, for any action history
prefix At ,
X
U ([E; At ]) = pd (t0)U ([Et ; At ])
t 2T

0

0

where hEt ; U i is a task environment in hE; U i with a fixed deadline at t0.
0

587

fiRussell & Subramanian

The mail sorter example is well described by a stochastic deadline. The time between
the arrival of mail pieces at the image processing station is distributed according to a density
function pd , which will usually be Poisson.

4.2 Agent programs and agent architecture

We consider simple agent programs for episodic task environments, constructed from elements of a set R = fr1 ; : : : ; rn g of decision procedures or rules. Each decision procedure
recommends (but does not execute) an action Ai 2 A?, and an agent program is a fixed
sequence of decision procedures. For our purposes, a decision procedure is a black box with
two parameters:

 a run time ti  0, which is an integer that represents the time taken by the procedure
to compute an action.

 a quality qi  0, which is a real number. This gives the expected reward resulting
from executing its action Ai at the start of an episode:

qi = U ([E; Ai])

(1)

Let MJ denote an agent architecture that executes decision procedures in the language J .
Let tM denote the maximum runtime of the decision procedures that can be accommodated
in M . For example, if the runtime of a feedforward neural network is proportional to its
size, then tM will be the runtime of the largest neural network that fits in M .
The architecture M executes an agent program s = s1 : : : sm by running each decision
procedure in turn, providing the same input to each as obtained from the initial percept.
When a deadline arrives (at a fixed time td , or heralded by the percept Od ), or when
the entire sequence has been completed, the agent selects the action recommended by the
highest-quality procedure it has executed:

M (s; I T(td); OT(td)) = hi0; action(I T(td ))i
M (s; I T(ts); OT(ts)) = hi0; action(I T(ts))i where ts = Psi2s ti
M (s; I T(t); Od) = hi0; action(I T(t))i

(2)

where M updates the agent's internal state history I T(t) such that action(I T(t)) is the
action recommended by a completed decision procedure with the highest quality. When
this action is executed, the internal state of the agent is re-initialized to i0 . This agent
design works in all three of the task environment categories described above.
Next we derive the value V (s; M; E ) of an agent program s in environment E running
on M for the three real-time regimes and show how to construct bounded optimal agents
for these task environments.

4.3 Bounded optimality with fixed deadlines

From Equation 2, we know that the agent picks the action in A? recommended by the
decision procedure r with the highest quality that is executed before the deadline td arrives.
588

fiProvably bounded-optimal agents

P

Let s1 : : : sj be the longest prefix of the program s such that ji=1 ti  td . From Definition 7
and Equation 1, it follows that
V (s; M; E ) = Qj
(3)
where Qi = maxfq1; : : : ; qi g. Given this expression for the value of the agent program, we
can easily show the following:
Theorem 1 Let r = arg maxri 2 R;titd qi . The singleton sequence r is a bounded optimal
program for M in an episodic task environment with a known deadline td.
That is, the best program is the single decision procedure of maximum quality whose runtime
is less than the deadline.

4.4 Bounded optimality with fixed time cost

From Equation 2, we know that the agent picks the action in A? recommended by the best
decision procedure in the sequence, since M runs the entire sequence s = s1 : : : sm when
there is no deadline. From Definition 8 and Equation 1, we have

V (s; M; E ) = Qm , c

m
X
i=1

ti

(4)

Given this expression for the value of the agent program, we can easily show the following:
Theorem 2 Let r = arg maxri 2 R qi , cti . The singleton sequence r is a bounded optimal
program for M in an episodic task environment with a fixed time cost c.
That is, the optimal program is the single decision procedure whose quality, net of time
cost, is highest.

4.5 Bounded optimality with stochastic deadlines

With a stochastic deadline distributed according to pd, the value of an agent program
: : sm is an expectation. From Definition 9, we can calculate this as
P ps (t=)V s(s;1 :M;
Et), where hEt; U i is a task environment with a fixed deadline at t. Aft2T d
ter substituting for V (s; M; Et) from Equation 3, this expression simplifies to a summation,
over the procedures in the sequence, of the probability of interruption after the ith procedure
in the sequence multiplied by the quality of the best completed decision procedure:
m
X
Pi
V (s)  V (s; M; E) = [Pd(Pij+1
(5)
=1 tj ) , Pd ( j =1 tj )]Qi
i=1
Rt
where Pd (t) = ,1
pd(t0)dt0 and Pd (t) = 1 for t  Pmi=1 ti.
A simple example serves to illustrate the value function. Consider R = fr1 ; r2 ; r3g. The
rule r1 has a quality of 0.2 and needs 2 seconds to run: we will represent this by r1 = (0:2; 2).
The other rules are r2 = (0:5; 5); r3 = (0:7; 7). The deadline distribution function pd is a
uniform distribution over 0 to 10 seconds. The value of the sequence r1 r2r3 is
V (r1 r2r3 ) = [:7 , :2]:2 + [1 , :7]:5 + [1 , 1]:7 = :25
A geometric intuition is given by the notion of a performance profile, as shown in Figure 2.

589

fiRussell & Subramanian

q

0.7
0.5
0.2

p(t)
t

2

5

7

Figure 2: Performance profile for r1r2 r3, with pd superimposed.

Definition 10 Performance profile: For a sequence s, the performance profile Qs (t) gives
the quality of the action returned if the agent is interrupted at t:

Qs(t) = maxfqi :

i
X

j =1

tj  tg

For a uniform deadline density function, the value of a sequence is proportional to the
area under the performance profile up to the last possible interrupt time. Note that the
height of the profile during the interval of length ti while rule i is running is the quality of
the best of the previous rules.
From Definition 10, we have the following obvious property:
Lemma 1 The performance profile of any sequence is monotonically nondecreasing.
It is also the case that a sequence with higher quality decisions at all times is a better
sequence:
Lemma 2 If 8t Qs1 (t)  Qs2 (t), then V (s1)  V (s2 ).
In this case we say that Qs1 dominates Qs2 .
We can use the idea of performance profiles to establish some useful properties of optimal
sequences.
Lemma 3 There exists an optimal sequence that is sorted in increasing order of q's.

P

Without Lemma 3, there are ni=1 i! possible sequences to consider. The ordering constraint eliminates all but 2n sequences. It also means that in proofs of properties of sequences, we now need consider only ordered sequences. In addition, we can replace Qi in
Equation 5 by qi .
The following lemma establishes that a sequence can always be improved by the addition
of a better rule at the end:
Lemma 4 For every sequence s = s1 : : : sm sorted in increasing order of quality, and single
step z with qz  qsm , V (sz )  V (s).
590

fiProvably bounded-optimal agents

Corollary 1 There exists an optimal sequence ending with the highest-quality rule in R.
The following lemma reects the obvious intuition that if one can get a better result in
less time, there's no point spending more time to get a worse result:
Lemma 5 There exists an optimal sequence whose rules are in nondecreasing order of ti .
We now apply these preparatory results to derive algorithms that construct bounded
optimal programs for various deadline distributions.
4.5.1 General distributions

For a general deadline distribution, the dynamic programming method can be used to obtain
an optimal sequence of decision rules in pseudo-polynomial time. We construct an optimal
sequence by using the definition of V (s; M; E ) in Equation 5. Optimal sequences generated
by the methods are ordered by qi, in accordance with Lemma 3.
We construct the table S (i; t), where each entry in the table is the highest value of
any sequence that ends with rule ri at time t. We assume the rule indices are arranged
in
P
increasing order of quality, and t ranges from the start time 0 to the end time L = ri 2R ti .
The update rule is:

S (i; t) = maxk2[0:::i,1][S (k; t , ti ) + (qi , qk )[1 , Pd (t)]]
with boundary condition
S (i; 0) = 0 for each rule i and S (0; t) = 0 for each time t
From Corollary 1, we can read off the best sequence from the highest value in row n of the
matrix S .
Theorem 3 The DP algorithm computes an optimal sequence in time O(n2L) where n is
the number of decision procedures in R.

The dependence on L in the time complexity of the DP algorithm means that the algorithm is not polynomial in the input size. Using standard rounding and scaling methods,
however, a fully polynomial approximation scheme can be constructed. Although we do not
have a hardness proof for the problem, John Binder (1994) has shown that if the deadline
distribution is used as a constant-time oracle for finding values of P (t), any algorithm will
require an exponential number of calls to the oracle in the worst case.
4.5.2 Long uniform distributions

If the deadline is uniformly distributed over a time interval greater than the sum of the
running times of the rules, we will call the distribution a long uniform distribution. Consider
the rule sequence s = s1 : : : sm drawn from the rule set R. With a long uniform distribution,
the probability that the deadline arrives during rule si of the sequence s is independent of
the time at which si starts. This permits a simpler form of Equation 5:

V (s; M; E) = Pmi=1,1 Pd (ti+1)qi + qm (1 , Pmi=1 Pd (ti))
591

(6)

fiRussell & Subramanian

To derive an optimal sequence under a long uniform distribution, we obtain a recursive
specification of the value of a sequence as with a 2 R and s = s1 : : : sm being some sequence
in R.

V (as; M; E) = V (s; M; E) + qaPd (t1) , qmPd (ta)

(7)

This allows us to define a dynamic programming scheme for calculating an optimal sequence
using a state function S (i; j ) denoting the highest value of a rule sequence that starts with
rule i and ends in rule j . From Lemma 3 and Equation 7, the update rule is:

S (i; j ) = maxi<kj [S (k; j ) + Pd (tk )qi , Pd (ti)qj ]

(8)

with boundary condition

S (i; i) = (1 , Pd (ti))qi

(9)

From Corollary 1, we know that an optimal sequence for the long uniform distribution ends
in rn , the rule with the highest quality in R. Thus, we only need to examine S (i; n); 1 
i  n. Each entry requires O(n) computation, and there are n entries to compute. Thus,
the optimal sequence for the long uniform case can be calculated in O(n2 ).

Theorem 4 An optimal sequence of decision procedures for a long uniform deadline distribution can be determined in O(n2) time where n is the number of decision procedures in
R.
4.5.3 Short uniform distributions

P

When ni=1 Pd (ti) > 1, for a uniform deadline distribution Pd, we call it short. This means
that some sequences are longer than the last possible deadline time, and therefore some rules
in those sequences have no possibility of executing before the deadline. For such sequences,
we cannot use Equation 7 to calculate V (s). However, any such sequence can be truncated
by removing all rules that would complete execution after the last possible deadline. The
value of the sequence is unaffected by truncation, and for truncated sequences the use of
Equation 7 is justified. Furthermore, there is an optimal sequence that is a truncated
sequence.
Since the update rule 8 correctly computes S (i; j ) for truncated sequences, we can use
it with short uniform distributions provided we add a check to ensure that the sequences
considered are truncated. Unlike the long uniform case, however, the identity of the last rule
in an optimal sequence is unknown, so we need to compute all n2 entries in the S (i; j ) table.
Each entry computation takes O(n) time, thus the time to compute an optimal sequence is
O(n3).

Theorem 5 An optimal sequence of decision procedures for a short uniform deadline distribution can be determined in O(n3) time where n is the number of decision procedures in
R.
592

fiProvably bounded-optimal agents

4.5.4 Exponential distributions

For an exponential distribution, Pd(t) = 1,e,fit . Exponential distributions allow an optimal
sequence to be computed in polynomial time. Let pi stand for the probability that rule i
is interrupted, assuming it starts at 0. Then pi = Pd(ti ) = 1 , e,fiti : For the exponential
distribution, V (s; M; E) simplifies out as:

V (s; M; E) =

i
i
h
ij =1(1 , pj ) pi+1qi + mj=1(1 , pj ) qm

mX
,1 h
i=1

This yields a simple recursive specification of the value V (as; M; E) of a sequence that
begins with the rule a:

V (as; M; E) = (1 , pa )p1qa + (1 , pa)V (s; M; E)
We will use the state function S (i; j ) which represents the highest value of any rule sequence
starting with i and ending in j .

S (i; j ) = maxi<kj [(1 , pi )pk qi + (1 , pi)S (k; j )]
with boundary condition S (i; i) = qi(1 , pi). For any given j , S (i; j ) can be calculated in
O(n2). From Corollary 1, we know that there is an optimal sequence whose last element is
the highest-valued rule in R.

Theorem 6 An optimal sequence of decision procedures for an exponentially distributed
stochastic deadline can be determined in O(n2) time where n is the number of decision
procedures in R.

The proof is similar to the long uniform distribution case.

4.6 Simulation results for a mail-sorter

The preceding results provide a set of algorithms for optimizing the construction of an agent
program for a variety of general task environment classes. In this section, we illustrate these
results and the possible gains that can be realized in a specific task environment, namely,
a simulated mail-sorter.
First, let us be more precise about the utility function U on episodes. There are four
possible outcomes; the utility of outcome i is ui.
1. The zipcode is successfully read and the letter is sent to the correct bin for delivery.
2. The zipcode is misread and the letter goes to the wrong bin.
3. The letter is sent to the reject bin.
4. The next letter arrives before the recognizer has finished, and there is a jam. Since
letter arrival is heralded, jams cannot occur with the machine architecture given in
Equation 2.
593

fiRussell & Subramanian

1

1
mu=9

0.8

0.8

0.6

0.6
P(t)

Accuracy

lambda=0.9

0.4

0.4

0.2

0.2

0

0
0

2

4
6
Computation Time (sec)

8

10

0

2

4
6
Time (sec)

8

10

Figure 3: (a) Accuracy profile (1 , e,x ), for  = 0:9. (b) Poisson arrival distribution, for
mean  = 9 sec
Without loss of generality, we set u1 = 1:0 and u2 = 0:0. If the probability of a rule
recommending a correct destination bin is pi, then qi = piu1 + (1 , pi)u2 = pi . We assume
that u2  u3, hence there is a threshold probability below which the letter should be sent
to the reject bin instead. We will therefore include in the rule set R a rule rreject that
has zero runtime and recommends rejection. The sequence construction algorithm will then
automatically exclude rules with quality lower than qreject = u3. The overall utility for an
episode is chosen to be a linear combination of the quality of sorting (qi ), the probability of
rejection or the rejection rate (given by P (t1), where t1 is the runtime of the first non-reject
rule executed), and the speed of sorting (measured by the arrival time mean).
The agent program in (Boser et al. 1992) uses a single neural network on a chip.
We show that under a variety of conditions an optimized sequence of networks can do
significantly better than any single network in terms of throughput or accuracy. We examine
the following experimental conditions:
 We assume that a network that executes in time t has a recognition accuracy p that
depends on t. We consider p = 1,e,t . The particular choice of  is irrelevant because
the scale chosen for t is arbitrary. We choose  = 0:9, for convenience (Figure 3(a)).
We include rreject with qreject = u3 and treject = 0.
 We consider arrival time distributions that are Poisson with varying means. Figure 3(b) shows three example distributions, for means 1, 5, and 9 seconds.
 We create optimized sequences from sets of 40 networks with execution times taken
at equal intervals from t = 1 to 40.
 We compare
(a) BO sequence: a bounded optimal sequence;
(b) Best singleton: the best single rule;
(c) 50% rule: the rule whose execution time is the mean of the distribution (i.e., it
will complete in 50% of cases);
594

fiProvably bounded-optimal agents

1
BO Sequence
Best Singleton
50% Rule
90% Rule

Average utility per second

0.8

0.6

0.4

0.2

0
5

10

15

20
25
Mean arrival time

30

35

40

Figure 4: Graph showing the achievable utility per second as a function of the average time
per letter, for the four program types.  = 0:9.
(d) 90% rule: the rule whose execution time guarantees that it will complete in 90%
of cases.
In the last three cases, we add rreject as an initial step; the BO sequence will include
it automatically.
 We measure the utility per second as a function of the mean arrival rate (Figure 4).
This shows that there is an optimal setting of the sorting machinery at 6 letters per
minute (inter-arrival time = 10 seconds) for the bounded optimal program, given that
we have fixed  at 0.9.
 Finally, we investigate the effect of the variance of the arrival time on the relative
performance of the four program types. For this purpose, we use a uniform distribution
centered around 20 seconds but with different widths to vary the variance without
affecting the mean (Figure 5).
We notice several interesting things about these results:
 The policy of choosing a rule with a 90% probability of completion performs poorly
for rapid arrival rates (  3), but catches up with the performance of the best single
rule for slower arrival rates ( > 4). This is an artifact of the exponential accuracy
profile for any  > 0:5, where the difference in quality of the rules with run times
greater than 6 seconds is quite small.
 The policy of choosing a rule with a 50% probability of completion fares as well as
the best single rule for very high arrival rates (  2), but rapidly diverges from it
thereafter, performing far worse for arrival time means greater than 5 seconds.
595

fiRussell & Subramanian

1
BO Sequence
Best Singleton
50% Rule
90% Rule

Average utility per second

0.8

0.6

0.4

0.2

0
0

20

40

60
80
Variance in arrival time

100

120

Figure 5: Graphs showing the utility gain per second as a function of the arrival time
variance, for the four program types for the uniform distribution with a mean of
20 seconds.

 Both the best sequence and the best single rule give their best overall performance
at an arrival rate of around 6 letters per minute. The performance advantage of the
optimal sequence over the best single rule is about 7% at this arrival rate. It should
be noted that this is a significant performance advantage that is obtainable with no
extra computational resources. For slower arrival rates (  7), the difference between
the performance of the best rule and the best sequence arises from the decreased
rejection rate of the best sequence. With the exponential accuracy profile (  0:5)
the advantage of running a rule with a shorter completion time ahead of a longer rule
is the ability to reduce the probability of rejecting a letter. For high arrival rates
(inter-arrival times of 1 to 4 seconds), it is useful to have a few short rules instead of
a longer single rule.

 Figure 5 shows that the best sequence performs better than the best single rule as the

variance of the arrival time increases.5 The performance of the optimal sequence also
appears to be largely unaffected by variance. This is exactly the behaviour we expect
to observe | the ability to run a sequence of rules instead of committing to a single
one gives it robustness in the face of increasing variance. Since realistic environments
can involve unexpected demands of many kinds, the possession of a variety of default
behaviours of graded sophistication would seem to be an optimal design choice for a
bounded agent.

5. The performance of the 50% rule is at because the uniform distributions used in this experiment have
fixed mean and are symmetric, so that the 50% rule is always the rule that runs for 20 seconds. The
90% rule changes with the variance, and the curve exhibits some discretization effects. These could be
eliminated using a finer-grained set of rules.

596

fiProvably bounded-optimal agents

5. Learning Approximately Bounded-Optimal Programs

The above derivations assume that a suitable rule set R is available ab initio, with correct
qualities qi and runtimes ti , and that the deadline distribution is known. In this section, we
study ways in which some of this information can be learned, and the implications of this
for the bounded optimality of the resulting system. We will concentrate on learning rules
and their qualities, leaving runtimes and deadline distributions for future work.
The basic idea is that the learning algorithms will converge, over time, to a set of
optimal components | the most accurate rules and the most accurate quality estimates for
them. As this happens, the value of the agent constructed from the rules, using the quality
estimates, converges to the value of lopt. Thus there are two sources of suboptimality in the
learned agent:
 The rules in R may not be the best possible rules | they may recommend actions
that are of lower utility than those that would be recommended by some other rules.
 There may be errors in estimating the expected utility of the rule. This can cause the
algorithms given above to construct suboptimal sequences, even if the best rules are
available.
Our notional method for constructing bounded optimal agents (1) learns sets of individual decision procedures from episodic interactions, and (2) arranges them in a sequence
using one of the algorithms described earlier so that the performance of an agent using
the sequence is at least as good as that of any other such agent. We assume a parameterized learning algorithm LJ ;k that will be used to learn one rule for each possible runtime
k 2 f1; : : : ; tM g. Since there is never a need to include two rules with the same runtime
in the R, this obviates the need to consider the entire rule language J in the optimization
process.
Our setting places somewhat unusual requirements on the learning algorithm. Like
most learning algorithms, LJ ;k works by observing a collection T of training episodes in E,
including the utility obtained for each episode. We do not, however, make any assumptions
about the form of the correct decision rule. Instead, we make assumptions about the
hypotheses, namely that they come from some finite language Jk , the set of programs
in J of complexity at most k. This setting has been called the agnostic learning setting by
Kearns, Schapire and Sellie (1992), because no assumptions are made about the environment
at all. It has been shown (Theorems 4 and 5 in Kearns, Schapire and Sellie, 1992) that, for
some languages J , the error in the learned approximation can be bounded to within  of
the best rule in Jk that fits the examples, with probability 1 , . The sample size needed
to guarantee these bounds is polynomial in the complexity parameter k, as well as 1 and 1 .
In addition to constructing the decision procedures, LJ ;k outputs estimates of their
quality qi . Standard Chernoff-Hoeffding bounds can be used to limit the error in the quality
estimate to be within q with probability 1 , q . The sample size for the estimation of quality
is also polynomial in 1q and 1q .
Thus the error in each agnostically learned rule is bounded to within  of the best rule
in its complexity class with probability 1 , . The error in the quality estimation of these
rules is bounded by q with probability 1 , q . From these bounds, we can calculate a bound
on the utility deficit in the agent program that we construct, in comparison to lopt :
597

fiRussell & Subramanian

Theorem 7 Assume an architecture MJ that executes sequences of decision procedures in
an agnostically learnable language J whose runtimes range over [1::tM ]. For real time task

environments with fixed time cost, fixed deadline, and stochastic deadline, we can construct
a program l such that
V (lopt ; M; E) , V (l; M; E)   + 2q
with probability greater than 1 , m( + q ), where m is the number of decision procedures in
lopt .

Proof: We prove this theorem for the stochastic deadline regime, where the bounded

optimal program is a sequence of decision procedures. The proofs for the fixed cost and
fixed deadline regimes, where the bounded optimal program is a singleton, follow as a
special case. Let the best decision procedures for E be the set R = fr1 ; : : : ; rn g, and
let lopt = s1  : : : sm  be an optimal sequence constructed from R. Let R = fr1 ; : : : rng be
the set of decision procedures returned by the learning algorithm. With probability greater
than 1 , m, qi , qi   for all i, where qi refers to the true quality of ri . The error in the
estimated quality q^i of decision procedure ri is also bounded: with probability greater than
1 , mq , jq^i , qi j  q for all i.
Let s = s1 : : : sm be those rules in R that come from the same runtime classes as the
rules s1  : : : sm  in R . Then, by Equation 5, we have
V (lopt ; M; E) , V (s; M; E)  
because the error in V is a weighted average of the errors in the individual qi . Similarly, we
have
jV^ (s; M; E) , V (s; M; E)j  q
Now suppose that the sequence construction algorithm applied to R produces a sequence
l = s1 : : : sl . By definition, this sequence appears to be optimal according to the estimated
value function V^ . Hence
V^ (l; M; E)  V^ (s; M; E)
As before, we can bound the error on the estimated value:
jV^ (l; M; E) , V (l; M; E)j  q
Combining the above inequalities, we have
V (lopt ; M; E) , V (l; M; E)   + 2q
0

0

2

Although the theorem has practical applications, it is mainly intended as an illustration
of how a learning procedure can converge on a bounded optimal configuration. With some
additional work, more general error bounds can be derived for the case in which the rule
execution times ti and the real-time utility variation (time cost, fixed deadline, or deadline
distribution) are all estimated from the training episodes. We can also obtain error bounds
for the case in which the rule language J is divided up into a smaller number of coarser
runtime classes, rather than the potentially huge number that we currently use.
598

fiProvably bounded-optimal agents

6. Asymptotic Bounded Optimality

The strict notion of bounded optimality may be a useful philosophical landmark from which
to explore artificial intelligence, but it may be too strong to allow many interesting, general
results to be obtained. The same observation can be made in ordinary complexity theory:
although absolute eciency is the aim, asymptotic eciency is the game. That a sorting
algorithm is O(n log n) rather than O(n2) is considered significant, but replacing a \multiply
by 2" by a \shift-left 1 bit" is not considered a real advance. The slack allowed by the
definitions of complexity classes is essential in building on earlier results, in obtaining robust
results that are not restricted to specific implementations, and in analysing the complexity of
algorithms that use other algorithms as subroutines. In this section, we begin by reviewing
classical complexity. We then propose definitions of asymptotic bounded optimality that
have some of the same advantages, and show that classical optimality is a special case of
asymptotic bounded optimality. Lastly, we report on some preliminary investigations into
the use of asymptotic bounded optimality as a theoretical tool in constructing universal
real-time systems.

6.1 Classical complexity

A problem, in the classical sense, is defined by a pair of predicates  and such that output
z is a solution for input x if and only if (x) and (x; z ) hold. A problem instance is an
input satisfying , and an algorithm for the problem class always terminates with an output
z satisfying (x; z ) given an input x satisfying (x). Asymptotic complexity describes the
growth rate of the worst-case runtime of an algorithm as a function of the input size. We
can define this formally as follows. Let Ta (x) be the runtime of algorithm a on input x,
and let Ta (n) be the maximum runtime of a on any input of size n. Then algorithm a has
complexity O(f (n)) if
9k; n0 8n n > n0 ) Ta (n)  kf (n)
Intuitively, a classically optimal algorithm is one that has the lowest possible complexity.
For the purposes of constructing an asymptotic notion of bounded optimality, it will be
useful to have a definition of classical optimality that does not mention the complexity
directly. This can be done as follows:
Definition 11 Classically optimal algorithm: An algorithm a is classically optimal if and
only if
9k; n0 8a0; n n > n0 ) Ta (n)  kTa (n)
To relate classical complexity to our framework, we will need to define the special case of task
environments in which traditional programs are appropriate. In such task environments,
an input is provided to the program as the initial percept, and the utility function on
environment histories obeys the following constraint:
Definition 12 Classical task environment: hEP ; U i is a classical task environment for
problem P if
(
l outputs a correct solution for P
V (l; M; EP ) = u0 (T (l; M; EP )) ifotherwise
0

599

fiRussell & Subramanian

where T (l; M; EP ) is the running time for l in EP on M , M is a universal Turing machine,
and u is some positive decreasing function.
The notion of a problem class in classical complexity theory thus corresponds to a class of
classical task environments of unbounded complexity. For example, the Traveling Salesperson Problem contains instances with arbitrarily large numbers of cities.

6.2 Varieties of asymptotic bounded optimality

The first thing we will need is a complexity measure on environments. Let n(E ) be a suitable
measure of the complexity of an environment. We will assume the existence of environment
classes that are of unbounded complexity. Then, by analogy with the definition of classical
optimality, we can define a worst-case notion of asymptotic bounded optimality (ABO).
Letting V (l; M; n; E) be the minimum value of V (l; M; E ) for all E in E of complexity n,
we have
Definition 13 Worst-case asymptotic bounded optimality: an agent program l is timewise
(or spacewise) worst-case asymptotically bounded optimal in E on M iff
9k; n0 8l0; n n > n0 ) V (l; kM; n; E)  V (l0; M; n; E)
where kM denotes a version of the machine M speeded up by a factor k (or with k times
more memory).
In English, this means that the program is basically along the right lines if it just needs a
faster (larger) machine to have worst-case behaviour as good as that of any other program
in all environments.
If a probability distribution is associated with the environment class E, then we can use
the expected value V (l; M; E) to define an average-case notion of ABO:
Definition 14 Average-case asymptotic bounded optimality: an agent program l is timewise
(or spacewise) average-case asymptotically bounded optimal in E on M iff
9k 8l0 V (l; kM; E)  V (l0 ; M; E)
For both the worst-case and average-case definitions of ABO, we would be happy with a
program that was ABO for a nontrivial environment on a nontrivial architecture M , unless
k were enormous.6 In the rest of the paper, we will use the worst-case definition of ABO.
Almost identical results can be obtained using the average-case definition.
The first observation that can be made about ABO programs is that classically optimal
programs are a special case of ABO programs:7
6. The classical definitions allow for optimality up to a constant factor k in the runtime of the algorithms.
One might wonder why we chose to use the constant factor to expand the machine capabilities, rather
than to increase the time available to the program. In the context of ordinary complexity theory, the
two alternatives are exactly equivalent, but in the context of general time-dependent utilities, only the
former is appropriate. It would not be possible to simply \let l run k times longer," because the programs
we wish to consider control their own execution time, trading it off against solution quality. One could
imagine slowing down the entire environment by a factor of k, but this is merely a less realistic version
of what we propose.
7. This connection was suggested by Bart Selman.

600

fiProvably bounded-optimal agents

Theorem 8 A program is classically optimal for a given problem P if and only if it is
timewise worst-case ABO for the corresponding classical task environment class hEP ; U i.
This observation follows directly from Definitions 11, 12, and 13.
In summary, the notion of ABO will provide the same degree of theoretical robustness
and machine-independence for the study of bounded systems as asymptotic complexity does
for classical programs. Having set up a basic framework, we can now begin to exercise the
definitions.

6.3 Universal asymptotic bounded optimality

Asymptotic bounded optimality is defined with respect to a specific value function V . In
constructing real-time systems, we would prefer a certain degree of independence from the
temporal variation in the value function. We can achieve this by defining a family V of value
functions, differing only in their temporal variation. By this we mean that the value function
preserves the preference ordering of external actions over time, with all value functions in
the family having the same preference ordering.8
For example, in the fixed-cost regime we can vary the time cost c to generate a family of
value functions; in the stochastic deadline case, we can vary the deadline distribution Pd to
generate another family. Also, since each of the three regimes uses the same quality measure
for actions, then the union of the three corresponding families is also a family. What we will
show is that a single program, which we call a universal program, can be asymptotically
bounded-optimal regardless of which value function is chosen within any particular family.
Definition 15 Universal asymptotic bounded optimality (UABO): An agent program l is
UABO in environment class E on M for the family of value functions V iff l is ABO in E
on M for every Vi 2 V .
A UABO program must compete with the ABO programs for every individual value function
in the family. A UABO program is therefore a universal real-time solution for a given task.
Do UABO programs exist? If so, how can we construct them?
It turns out that we can use the scheduling construction from (Russell & Zilberstein,
1991) to design UABO programs. This construction was designed to reduce task environments with unknown interrupt times to the case of known deadlines, and the same insight
applies here. The construction requires the architecture M to provide program concatenation (e.g., the LISP prog construct), a conditional-return construct, and the null program
. The universal program lU has the form of a concatenation of individual programs of
increasing runtime, with an appropriate termination test after each. It can be written as
lU = [l0  l1    lj   ]
where each lj consists of a program and a termination test. The program part in lj is any
program in LM that is ABO in E for a value function Vj that corresponds to a fixed deadline
at td = 2j , where  is a time increment smaller than the execution time of any non-null
program in LM .
8. The value function must therefore be separable (Russell & Wefald, 1989), since this preservation of rank
order allows a separate time cost to be defined. See chapter 9 of (Keeney & Raiffa, 1976) for a thorough
discussion of time-dependent utility.

601

fiRussell & Subramanian

q

l U on 4M

0.7

l opt on M

0.5
0.2

p(t)
t

0

10

Figure 6: Performance profiles for lU running on 4M , and for lopt running on M
Before proceeding to a statement that lU is indeed UABO, let us look at an example.
Consider the simple, sequential machine architecture described earlier. Suppose we can
select rules from a three-rule set with r1 = (0:2; 2), r2 = (0:5; 5) and r3 = (0:7; 7). Since
the shortest runtime of these rules is 2 seconds, we let  = 1. Then we look at the optimal
programs l0 ; l1; l2; l3 ; : : : for the fixed-deadline task environments with td = 1; 2; 4; 8; : : :.
These are:

l0 = ; l1 = r1; l2 = r1; l3 = r3 ; : : :
Hence the sequence of programs in lU is [; r1; r1 ; r3; : : :].
Now consider a task environment class with a value function Vi that specifies a stochastic
deadline uniformly distributed over the range [0: : : 10]. For this class, lopt = r1 r2 is a
bounded optimal sequence.9 It turns out that lU has higher utility than lopt provided it is
run on a machine that is four times faster. We can see this by plotting the two performance
profiles: QU for lU on 4M and Qopt for lopt on M . QU dominates Qopt, as shown in Figure 6.
To establish that the lU construction yields UABO programs in general, we need to
define a notion of worst-case performance profile. Let Q (t; l; M; n; E) be the minimum
value obtained by interrupting l at t, over all E in E of complexity n. We know that each
lj in lU satisfies the following:

8l0; n n > nj ) Vj(lj ; kj M; n; E)  Vj(l0 ; M; n; E)
for constants kj , nj . The aim is to prove that

8Vi 2 V 9k; n0 8l0; n n > n0 ) Vi(lU ; kM; n; E)  Vi(l0; M; n; E)
Given the definition of worst-case performance profile, it is fairly easy to show the following
lemma (the proof is essentially identical to the proof of Theorem 1 in Russell and Zilberstein,
1991):
9. Notice that, in our simple model, the output quality of a rule depends only on its execution time and
not on the input complexity. This also means that worst-case and average-case behaviour are the same.

602

fiProvably bounded-optimal agents

1
BO Sequence
ABO sequence

Average utility per second

0.8

0.6

0.4

0.2

0
5

10

15

20
25
Mean arrival time

30

35

40

i , as a function of mean
Figure 7: Throughput and accuracy improvement of lU over lopt
arrival time,  = 0.2, Poisson arrivals.

Lemma 6 If lU is a universal program in E for V , and li is ABO on M in E for Vi 2 V ,
then Q(t; lU ; kM; n; E) dominates Q(t; li ; M; n; E) for k  4 maxj kj , n > maxj nj .
This lemma establishes that, for a small constant penalty, we can ignore the specific realtime nature of the task environment in constructing bounded optimal programs. However,
we still need to deal with the issue of termination. It is not possible in general for lU
to terminate at an appropriate time without access to information concerning the timedependence of the utility function. For example, in a fixed-time-cost task environment, the
appropriate termination time depends on the value of the time cost c.
For the general case with deterministic time-dependence, we can help out lU by supplying, for each Vi , an \aspiration level" Qi (ti; li ; M; n; E), where ti is the time at which
li acts. lU terminates when it has completed an lj such that qj  Qi (ti ; li; M; n; E). By
construction, this will happen no later than ti because of Lemma 6.

Theorem 9 In task environments with deterministic time-dependence, an lU with a suitable
aspiration level is UABO in E on M .
With deadline heralds, the termination test is somewhat simpler and does not require any
additional input to lU .
Theorem 10 In a task environment with stochastic deadlines, lU is UABO in E on M if
it terminates when the herald arrives.
Returning to the mail-sorting example, it is fairly easy to see that lU (which consists of
a sequence of networks, like the optimal programs for the stochastic deadline case) will be
ABO in the fixed-deadline regime. It is not so obvious that it is also ABO in any particular
603

fiRussell & Subramanian

stochastic deadline case | recall that both regimes can be considered as a single family.
We have programmed a constructor function for universal programs, and applied it to the
mail-sorter environment class. Varying the letter arrival distribution gives us different value
functions Vi 2 V . Figure 7 shows that lU (on 4M ) has higher throughput and accuracy
i across the entire range of arrival distributions.
than lopt
Given the existence of UABO programs, it is possible to consider the behaviour of compositions thereof. The simplest form of composition is functional composition, in which
the output of one program is used as input by another. More complex, nested compositional structures can be entertained, including loops and conditionals (Zilberstein, 1993).
The main issue in constructing UABO compositions is how to allocate time among the
components. Provided that we can solve the time allocation problem when we know the
total runtime allowed, we can use the same construction technique as used above to generate composite UABO programs, where optimality is among all possible compositions of
the components. Zilberstein and Russell (1993), show that the allocation problem can be
solved in linear time in the size of the composite system, provided the composition is a tree
of bounded degree.

7. Conclusions And Further Work
We examined three possible formal bases for artificial intelligence, and concluded that
bounded optimality provides the most appropriate goal in constructing intelligent systems.
We also noted that similar notions have arisen in philosophy and game theory for more or
less the same reason: the mismatch between classically optimal actions and what we have
called feasible behaviours|those that can be generated by an agent program running on a
computing device of finite speed and size.
We showed that with careful specification of the task environment and the computing
device one can design provably bounded-optimal agents. We exhibited only very simple
agents, and it is likely that bounded optimality in the strict sense is a dicult goal to
achieve when a larger space of agent programs is considered. More relaxed notions such
as asymptotic bounded optimality (ABO) may provide more theoretically robust tools for
further progress. In particular, ABO promises to yield useful results on composite agent
designs, allowing us to separate the problem of designing complex ABO agents into a discrete
structural problem and a continuous temporal optimization problem that is tractable in
many cases. Hence, we have reason to be optimistic that artificial intelligence can be
usefully characterized as the study of bounded optimality. We may speculate that provided
the computing device is neither too small (so that small changes in speed or size cause
significant changes in the optimal program design) nor too powerful (so that classically
optimal decisions can be computed feasibly), ABO designs should be stable over reasonably
wide variations in machine speed and size and in environmental complexity. The details of
the optimal designs may be rather arcane, and learning processes will play a large part in
their discovery; we expect that the focus of this type of research will be more on questions
of convergence to optimality for various structural classes than on the end result itself.
Perhaps the most important implication, beyond the conceptual foundations of the field
itself, is that research on bounded optimality applies, by design, to the practice of artificial
intelligence in a way that idealized, infinite-resource models may not. We have given, by
604

fiProvably bounded-optimal agents

way of illustrating this definition, a bounded optimal agent: the design of a simple system
consisting of sequences of decision procedures that is provably better than any other program
in its class. A theorem that exhibits a bounded optimal design translates, by definition,
into an agent whose actual behaviour is desirable.
There appear to be plenty of worthwhile directions in which to continue the exploration
of bounded optimality. From a foundational point of view, one of the most interesting
questions is how the concept applies to agents that can incorporate a learning component.
(Note that in section 5, the learning algorithm was external to the agent.) In such a
case, there will not necessarily be a largely stable bounded optimal configuration if the
agent program is not large enough; instead, the agent will have to adapt to a shorter-term
horizon and rewrite itself as it becomes obsolete.
With results on the preservation of ABO under composition, we can start to examine
much more interesting architectures than the simple production system studied above. For
example, we can look at optimal search algorithms, where the algorithm is constrained to
apply a metalevel decision procedure at each step to decide which node to expand, if any
(Russell & Wefald, 1989). We can also extend the work on asymptotic bounded optimality
to provide a utility-based analogue to \big-O" notation for describing the performance of
agent designs, including those that are suboptimal.
In the context of computational learning theory, it is obvious that the stationarity
requirement on the environment, which is necessary to satisfy the preconditions of PAC
results, is too restrictive. The fact that the agent learns may have some effect on the
distribution of future episodes, and little is known about learning in such cases (Aldous &
Vazirani, 1990). We could also relax the deterministic and episodic requirement to allow
non-immediate rewards, thereby making connections to current research on reinforcement
learning.
The computation scheduling problem we examined is interesting in itself, and does not
appear to have been studied in the operations research or combinatorial optimization literature. Scheduling algorithms usually deal with physical rather than computational tasks,
hence the objective function usually involves summation of outputs rather than picking the
best. We would like to resolve the formal question of its tractability in the general case, and
also to look at cases in which the solution qualities of individual processes are interdependent
(such as when one can use the results of another). Practical extensions include computation
scheduling for parallel machines or multiple agents, and scheduling combinations of computational and physical (e.g., job-shop and ow-shop) processes, where objective functions are
a combination of summation and maximization. The latter extension broadens the scope
of applications considerably. An industrial process, such as designing and manufacturing a
car, consists of both computational steps (design, logistics, factory scheduling, inspection
etc.) and physical processes (stamping, assembling, painting etc.). One can easily imagine
many other applications in real-time financial, industrial, and military contexts.
It may turn out that bounded optimality is found wanting as a theoretical framework. If
this is the case, we hope that it is refuted in an interesting way, so that a better framework
can be created in the process.
605

fiRussell & Subramanian

Appendix: Additional Proofs
This appendix contains formal proofs for three subsidiary lemmata in the main body of the
paper.

Lemma 3 There exists an optimal sequence that is sorted in increasing order of q's.
Proof: Suppose this is not the case, and s is an optimal sequence. Then there must be

two adjacent rules i, i + 1 where qi > qi+1 (see Figure 8). Removal of rule i + 1 yields a
sequence s0 such that Qs (t)  Qs (t), from Lemma 1 and the fact that ti+2  ti+1 + ti+2 . By
Lemma 2, s0 must also be optimal. We can repeat this removal process until s0 is ordered
by qi , proving the theorem by reductio ad absurdum.2
0

Lemma 4 For every sequence s = s1 : : : sm sorted in increasing order of quality, and single
step z with qz  qsm , V (sz )  V (s).
Proof: We calculate V (sz ) , V (s) using Equation 5 and show that it is non-negative:
V (sz ) , V (s) = qz [1 , Pd ((Pmj=1 tj ) + tz )] , qm[1 , Pd ((Pmj=1 tj ) + tz )]
P
= (qz , qm )[1 , Pd (( mj=1 tj ) + tz )]

which is non-negative since qz  qm .2
q

t i+2

qi+2
qi
qi-1
qi+1

t

ti

t i+1

Figure 8: Proof for ordering by qi; lower dotted line indicates original profile; upper dotted
line indicates profile after removal of rule i + 1.

Lemma 5 There exists an optimal sequence whose rules are in nondecreasing order of ti .
Proof: Suppose this is not the case, and s is an optimal sequence. Then there must be
two adjacent rules i, i + 1 where qi  qi+1 and ti > ti+1 (see Figure 9). Removal of rule i
yields a sequence s0 such that Qs (t)  Qs (t), from Lemma 1. By Lemma 2, s0 must also be
0

optimal. We can repeat this removal process until s0 is ordered by ti, proving the theorem
by reductio ad absurdum.2
606

fiProvably bounded-optimal agents

q

qi+1
qi

t i+1

qi-1

t

t i+1

ti

Figure 9: Proof for ordering by ti ; dotted line indicates profile after removal of rule i.

Acknowledgements

We would like to acknowledge stimulating discussions with Michael Fehling, Michael Genesereth, Russ Greiner, Eric Horvitz, Henry Kautz, Daphne Koller, and Bart Selman on the
subject of bounded optimality; with Dorit Hochbaum, Nimrod Megiddo, and Kevin Glazebrook on the subject of dynamic programming for scheduling problems; and with Nick
Littlestone and Michael Kearns on the subject of agnostic learning. We would also like to
thank the reviewers for their many constructive suggestions. Many of the early ideas on
which this work is based arose in discussions with the late Eric Wefald. Thanks also to
Ron Parr for his work on the uniform-distribution case, Rhonda Righter for extending the
results to the exponential distribution, and Patrick Zieske for help in implementing the dynamic programming algorithm. The first author was supported by NSF grants IRI-8903146,
IRI-9211512 and IRI-9058427, by a visiting fellowship from the SERC while on sabbatical
in the UK, and by the NEC Research Institute. The second author was supported by NSF
grant IRI-8902721.

References

Agre, P., & Chapman, D. (1987). Pengi: An implementation of a theory of activity. In
Proc. 6th National Conference on Artificial Intelligence, Seattle, WA. Morghan Kaufmann.
Aldous, D., & Vazirani, U. (1990). A markovian extension of valiant's learning model. In
Proc. 31st Annual Symposium on Foundations of Computer Science, St. Louis, MO.
IEEE Comput. Soc. Press.
Binder, J. (1994). On the complexity of deliberation scheduling with stochastic deadlines..
Boser, B. E., Sackinger, E., Bromley, J., & LeCun, Y. (1992). Hardware requirements for
neural network pattern classifiers | a case study and implementation. IEEE Micro,
12, 32{40.
Brandt, R. (1953). In search of a credible form of rule utilitarianism. In Nakhnikian, G., &
Castaneda, H. (Eds.), Morality and the Language of Conduct.
607

fiRussell & Subramanian

Breese, J. S., & Fehling, M. R. (1990). Control of problem-solving: Principles and architecture. In Shachter, R. D., Levitt, T., Kanal, L., & Lemmer, J. (Eds.), Uncertainty in
Artificial Intelligence 4. North Holland: Amsterdam.
Brooks, R. A. (1986). A robust, layered control system for a mobile robot. IEEE Journal
of Robotics and Automation, 2, 14{23.
Cherniak, C. (1986). Minimal rationality. MIT Press: Cambridge.
Dean, T., & Boddy, M. (1988). An analysis of time-dependent planning. In Proc. of AAAI88, pp. 49{54.
Dean, T. L., & Wellman, M. P. (1991). Planning and control. Morgan Kaufmann: San
Mateo, CA.
Dennett, D. (1986). The moral first aid manual. Tanner lectures on human values, University
of Michigan.
Doyle, J. (1983). What is rational psychology? toward a modern mental philosophy. AI
Magazine, 4, 50{53.
Doyle, J. (1988). Artificial intelligence and rational self-government. Tech. rep.. Technical
report CMU-CS-88-124.
Doyle, J., & Patil, R. (1991). Two theses of knowledge representation: language restrictions, taxonomic classification, and the utility of representation services. Artificial
intelligence, 48, 261{297.
Etzioni, O. (1989). Tractable decision-analytic control. In Proc. of 1st International Conference on Knowledge Representation and Reasoning, pp. 114{125.
Fehling, M., & Russell, S. J. (1989). Proceedings of the AAAI Spring Symposium on Limited
Rationality. AAAI.
Genesereth, M. R., & Nilsson, N. J. (1987). Logical Foundations of Artificial Intelligence.
Morgan Kaufmann: Mateo, CA.
Good, I. J. (1971). Twenty-seven principles of rationality. In In Godambe, V. P., & Sprott,
D. A. (Eds.), Foundations of Statistical Inference, pp. 108{141. Holt, Rinehart, Winston.: Toronto.
Hansson, O., & Mayer, A. (1989). Heuristic search as evidential reasoning. In Proceedings
of the Fifth Workshop on Uncertainty in Artificial Intelligence, Windsor, Ontario.
Horvitz, E. J. (1988). Reasoning about beliefs and actions under computational resource
constraints. In Levitt, T., Lemmer, J., & Kanal, L. (Eds.), Uncertainty in Artificial
Intelligence 3. North Holland: Amsterdam.
Kearns, M., Schapire, R., & Sellie, L. (1992). Toward ecient agnostic learning. In Proc. 5th
Ann. Workshop on Computational Learning Theory, Pittsburgh, PA. Morgan Kaufmann.
608

fiProvably bounded-optimal agents

Keeney, R., & Raiffa, H. (1976). Decisions with multiple objectives: Preferences and value
tradeoffs. Wiley: New York.
Levesque, H., & Brachman, R. (1987). Expressiveness and tractability in knowledge representation and reasoning. Computational Intelligence, 3, 78{93.
Luby, M., Sinclair, A., & Zuckerman, D. (1993). Optimal speedup of las vegas algorithms.
Information Processing Letters, 47, 173{80.
McCarthy, J. (1958). Programs with common sense. In Proceedings of the Symposium on
the Mechanization of Thought Processes, Teddington, England: HMSO.
Newell, A. (1981). The knowledge level. AI Magazine, 2, 1{20.
Neyman, A. (1985). Bounded complexity justifies cooperation in the finitely repeated prisoners' dilemma. Economics Letters, 19, 227{229.
Papadimitriou, C., & Yannakakis, M. (1994). On complexity as bounded rationality. In
Proc. ACM Symposium on the Theory of Computation.
Ramsey, F. P. (1931). Truth and probability. In Braithwaite, R. (Ed.), The foundations of
mathematics and other logical essays. Harcourt Brace Jovanovich: New York.
Russell, S. J., & Wefald, E. H. (1989a). On optimal game tree search using rational metareasoning. In Proc. IJCAI-89.
Russell, S. J., & Wefald, E. H. (1989b). Principles of metareasoning. In Proc. KR-89.
Russell, S. J., & Wefald, E. H. (1991). Do the right thing: Studies in limited rationality.
MIT Press: Cambridge, MA.
Russell, S. J., & Zilberstein, S. (1991). Composing real-time systems. In Proc. IJCAI-91,
Sydney.
Sackinger, E., Boser, B. E., Bromley, J., & LeCun, Y. (1992). Application of the anna
neural network chip to high-speed character recognition. IEEE Transactions on Neural
Networks, 3, 498{505.
Simon, H. A. (1976). On how to decide what to do. In Models of bounded rationality,
Volume 2.
Simon, H. A. (1982). Models of bounded rationality, Volume 2. MIT Press: Cambridge.
von Neumann, J., & Morgenstern, O. (1947). Theory of games and economic behavior.
Princeton University Press: Princeton.
Zilberstein, S. (1993). Operational Rationality Through Compilation of Anytime Algorithms.
Ph.D. thesis, Computer Science Division, University of California, Berkeley.
Zilberstein, S., & Russell, S. (1993). Optimal composition of real-time systems. Submitted
to Artificial Intelligence.
609

fiJournal of Artificial Intelligence Research 2 (1995) 287-318

Submitted 9/94; published 1/95

Truncating Temporal Differences:
On the Ecient Implementation of TD()
for Reinforcement Learning
Pawe Cichosz

Institute of Electronics Fundamentals, Warsaw University of Technology
Nowowiejska 15/19, 00-665 Warsaw, Poland

cichosz@ipe.pw.edu.pl

Abstract

Temporal difference (TD) methods constitute a class of methods for learning predictions
in multi-step prediction problems, parameterized by a recency factor . Currently the most
important application of these methods is to temporal credit assignment in reinforcement
learning. Well known reinforcement learning algorithms, such as AHC or Q-learning, may
be viewed as instances of TD learning. This paper examines the issues of the ecient
and general implementation of TD() for arbitrary , for use with reinforcement learning
algorithms optimizing the discounted sum of rewards. The traditional approach, based on
eligibility traces , is argued to suffer from both ineciency and lack of generality. The TTD
(Truncated Temporal Differences ) procedure is proposed as an alternative, that indeed
only approximates TD(), but requires very little computation per action and can be used
with arbitrary function representation methods. The idea from which it is derived is fairly
simple and not new, but probably unexplored so far. Encouraging experimental results are
presented, suggesting that using  > 0 with the TTD procedure allows one to obtain a
significant learning speedup at essentially the same cost as usual TD(0) learning.

1. Introduction
Reinforcement learning (RL, e.g., Sutton, 1984; Watkins, 1989; Barto, 1992; Sutton, Barto,
& Williams, 1991; Lin, 1992, 1993; Cichosz, 1994) is a machine learning paradigm that relies
on evaluative training information. At each step of discrete time a learning agent observes
the current state of its environment and executes an action . Then it receives a reinforcement value, also called a payoff or a reward (punishment), and a state transition takes
place. Reinforcement values provide a relative measure of the quality of actions executed
by the agent. Both state transitions and rewards may be stochastic, and the agent does not
know either transition probabilities or expected reinforcement values for any state-action
combinations. The objective of learning is to identify a decision policy (i.e., a state-action
mapping) that maximizes the reinforcement values received by the agent in the long term .
A commonly assumed formal model of a reinforcement learning task is a Markovian decision
problem (MDP, e.g., Ross, 1983). The Markov property means that state transitions and
reinforcement values always depend solely on the current state and the current action: there
is no dependence on previous states, actions, or rewards, i.e., the state information supplied
to the agent is sucient for making optimal decisions.
All the information the agent has about the external world and its task is contained
in a series of environment states and reinforcement values. It is never told what actions
to execute in particular states, or what actions (if any) would be better than those which
c 1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiCichosz

it actually performs. It must learn an optimal policy by observing the consequences of its
actions. The abstract formulation and generality of the reinforcement learning paradigm
make it widely applicable, especially in such domains as game-playing (Tesauro, 1992),
automatic control (Sutton et al., 1991), and robotics (Lin, 1993). To formulate a particular
task as a reinforcement learning task, one just has to design appropriate state and action
representation, and a reinforcement mechanism specifying the goal of the task. The main
limitation of RL applications is that it is by nature a trial-and-error learning method, and
it is hardly applicable in domains where making errors costs much.
A commonly studied performance measure to be maximized by an RL agent is the
expected total discounted sum of reinforcement:

E

"1
X

t=0

 trt

#

;

(1)

where rt denotes the reinforcement value received at step t, and 0    1 is a discount
factor , which adjusts the relative significance of long-term rewards versus short-term ones.
To maximize the sum for any positive  , the agent must take into account the delayed
consequences of its actions: reinforcement values may be received several steps after the
actions that contributed to them were performed. This is referred to as learning with delayed
reinforcement (Sutton, 1984; Watkins, 1989). Other reinforcement learning performance
measures have also been considered (Heger, 1994; Schwartz, 1993; Singh, 1994), but in this
work we limit ourselves exclusively to the performance measure specified by Equation 1.
The key problem that must be solved in order to learn an optimal policy under the
conditions of delayed reinforcement is known as the temporal credit assignment problem
(Sutton, 1984). It is the problem of assigning credit or blame for the overall outcomes
of a learning system (i.e., long-term reinforcement values) to each of its individual actions,
possibly taken several steps before the outcomes could be observed. Discussing reinforcement
learning algorithms, we will concentrate on temporal credit assignment and ignore the issues
of structural credit assignment (Sutton, 1984), the other aspect of credit assignment in RL
systems.

1.1 Temporal Difference Methods

The temporal credit assignment problem in reinforcement learning is typically solved using
algorithms based on the methods of temporal differences (TD). They have been introduced
by Sutton (1988) as a class of methods for learning predictions in multi-step prediction
problems. In such problems prediction correctness is not revealed at once, but after more
than one step since the prediction was made, though some partial information relevant to
its correctness is revealed at each step. This information is available and observed as the
current state of a prediction problem, and the corresponding prediction is computed as a
value of a function of states.
Consider a multi-step prediction problem where at each step it is necessary to learn a
prediction of some final outcome. It could be for example predicting the outcome of a game
of chess in subsequent board situations, predicting the weather on Sunday on each day of
the week, or forecasting some economic indicators. The traditional approach to learning
such predictions would be to wait until the outcome occurs, keeping track of all predictions
288

fiTruncating Temporal Differences

computed at intermediate steps, and then, for each of them, to use the difference between
the actual outcome and the predicted value as the training error. It is supervised learning,
where directed training information is obtained by comparing the outcome with predictions
produced at each step. Each of the predictions is modified so as to make it closer to the
outcome.
Temporal difference learning makes it unnecessary to always wait for the outcome. At
each step the difference between two successive predictions is used as the training error.
Each prediction is modified so as to make it closer to the next one. In fact, TD is a class
of methods referred to as TD(), where 0    1 is called a recency factor . Using  > 0
allows one to incorporate prediction differences from more time steps, to hopefully speed
up learning.
Temporal credit assignment in reinforcement learning may be viewed as a prediction
problem. The outcome to predict in each state is simply the total discounted reinforcement
that will be received starting from that state and following the current policy. Such predictions can be used for modifying the policy so as to optimize the performance measure given
by Equation 1. Example reinforcement learning algorithms that implement this idea, called
TD-based algorithms , will be presented in Section 2.2.

1.2 Paper Overview

Much of the research concerning TD-based reinforcement learning algorithms has concentrated on the simplest TD(0) case. However, experimental results obtained with TD( > 0)
indicate that it often allows one to obtain a significant learning speedup (Sutton, 1988;
Lin, 1993; Tesauro, 1992). It has been also suggested (e.g., Peng & Williams, 1994) that
TD( > 0) should perform better in non-Markovian environments than TD(0) (i.e., it should
be less sensitive to the potential violations of the Markov property). It is thus important
to develop ecient and general implementation techniques that would allow TD-based RL
algorithms to use arbitrary . This has been the motivation of this work.
The remainder of this paper is organized as follows. In Section 2 a formal definition of
TD methods is presented and their application to reinforcement learning is discussed. Three
example RL algorithms are briey described: AHC (Sutton, 1984), Q-learning (Watkins,
1989; Watkins & Dayan, 1992), and advantage updating (Baird, 1993). Section 3 presents
the traditional approach to TD() implementation, based on so called eligibility traces,
which is criticized for ineciency and lack of generality. In Section 4 the analysis of the
effects of the TD algorithm leads to the formulation of the TTD (Truncated Temporal
Differences ) procedure. The two remaining sections are devoted to experimental results
and concluding discussion.

2. Definition of TD()

When Sutton (1988) introduced TD methods, he assumed they would use parameter estimation techniques for prediction representation. According to his original formulation,
states of a prediction problem are represented by vectors of real-valued features, and corresponding predictions are computed by the use of a set of modifiable parameters (weights).
Under such representation learning consists in adjusting the weights appropriately on the
basis of observed state sequences and outcomes. Below we present an alternative formula289

fiCichosz

tion, adopted from Dayan (1992), that simplifies the analysis of the effects of the TD()
algorithm. In this formulation states may be elements of an arbitrary finite state space, and
predictions are values of some function of states. Transforming Sutton's original definition
of TD() to this alternative form is straightforward.
When discussing either the generic or RL-oriented form of TD methods, we consequently ignore the issues of function representation. It is only assumed that TD predictions or functions maintained by reinforcement learning algorithms are represented by a
method that allows adjusting function values using some error values, controlled by a learning rate parameter. Whenever we write that the value of an n-argument function ' for
arguments p0; p1; : : :; pn,1 should be updated using an error value of , we mean that
'(p0; p1; : : :; pn,1) should be moved towards '(p0; p1; : : :; pn,1) + , to a degree controlled
by some learning rate factor  . The general form of this abstract update operation is written
as
update ('; p0 ; p1; : : :; pn,1; ):
(2)
Under this convention, a learning algorithm is defined by the rule it uses for computing
error values.

2.1 Basic Formulation

Let x0; x1; : : :; xm,1 be a sequence of m states of a multi-step prediction problem. Each
state xt can be observed at time step t, and at step m, after passing the whole sequence, a
real-valued outcome z can be observed. The learning system is required to produce a corresponding sequence of predictions P (x0 ); P (x1); : : :; P (xm,1 ), each of which is an estimate
of z .
Following Dayan (1992), let us define for each state x:
(

x (t) =

1 if xt = x
0 otherwise:

Then the TD() prediction error for each state x determined at step t is given by:

x(t) = (P (xt+1) , P (xt ))

t
X
t,k 

k=0

x (k);

(3)

where 0    1 and P (xm ) = z by definition, and the total prediction error for state x
determined after the whole observed sequence accordingly is:

x =

mX
,1
t=0

x(t) =

mX
,1 (
t=0

(P (xt+1 ) , P (xt

t
X
)) t,k 
k=0

)

x (k )

:

(4)

Thus, learning at each step is driven by the difference between two temporally successive
predictions. When  > 0, the prediction difference at time t affects not only P (xt ), but also
predictions from previous time steps, to an exponentially decaying degree.1
1. Alternatively, learning the prediction at step t relies not only on the prediction difference from that
step, but also on future prediction differences. This equivalent formulation will play a significant role in
Section 4.

290

fiTruncating Temporal Differences

There are two possibilities of using such defined errors for learning. The first is to compute total errors x for all states x, by accumulating the x (t) errors computed at each time
step t, and to use them after passing the whole state sequence to update predictions P (x).
It corresponds to batch learning mode. The second possibility, called incremental or on-line
learning, often more attractive in practice, is to update predictions at each step t using
current error values x (t). It is then necessary to modify appropriately Equation 3, so as
to take into account that predictions are changed at each step:

x (t) = (Pt(xt+1 ) , Pt (xt ))

t
X
t,k 

k=0

x (k);

(5)

where Pt (x) designates the prediction for state x available at step t.
Sutton (1988) proved the convergence of batch TD(0) for a linear representation, with
states represented as linearly independent vectors, under the assumption that state sequences are generated by an absorbing Markov process .2 Dayan (1992) extended his proof
to arbitrary .3

2.2 TD() for Reinforcement Learning

So far, this paper has presented TD as a general class of prediction methods for multi-step
prediction problems. The most important application of these methods, however, is to reinforcement learning. As a matter of fact, TD methods were formulated by Sutton (1988) as
a generalization of techniques he had previously used only in the context of temporal credit
assignment in reinforcement learning (Sutton, 1984).
As already stated above, the most straightforward way to formulate temporal credit
assignment as a prediction problem is to predict at each time step t the discounted sum of
future reinforcement
1
X
zt =  k rt+k ;
k=0

called the TD return for time t. The corresponding prediction is designated by U (xt ) and
called the predicted utility of state xt . TD returns obviously depend on the policy being
followed; we therefore assume that U values represent predicted state utilities with respect
to the current policy. For perfectly accurate predictions we would have:
U (xt) = zt = rt + zt+1 = rt + U (xt+1):
Thus, for inaccurate predictions, the mismatch or TD error is rt + U (xt+1) , U (xt). The
resulting RL-oriented TD() equations take form:

x(t) = (rt + Ut(xt+1 ) , Ut (xt))

t
X

()t,k x (k)

(6)

k=0
2. An absorbing Markov process is defined by a set of terminal states XT , a set of non-terminal states XN ,
and the set of transition probabilities Pxy for all x 2 XN and y 2 XN [ XT . The absorbing property
means that any cycles among non-terminal states cannot last indefinitely long, i.e., for any starting
non-terminal state a terminal state will eventually be reached (all sequences eventually terminate).
3. Recently stronger theoretical results were proved by Dayan and Sejnowski (1994) and Jaakkola, Jordan,
and Singh (1993).

291

fiCichosz

and

x =

1
X
t=0

x (t) =

1
X
t=0

(

(rt + Ut(xt+1) , Ut (xt ))

t
X
k=0

)

()t,kx (k) :

(7)

Note the following additional differences between these equations and Equations 3 and 4:

 time step subscripts are used with U values to emphasize on-line learning mode,
 the discount applied in the sum in Equation 6 includes  as well as  for reasons that
may be unclear now, but will be made clear in Section 4.1,

 the summation in Equation 7 extends to infinity, because the predicted final outcome
is not, in general, available after any finite number of steps.

TD-based reinforcement learning algorithms may be viewed as more or less direct implementations of the general rule described by Equation 6. To see this, we will consider
three algorithms: well known AHC (Sutton, 1984) and Q-learning (Watkins, 1989; Watkins
& Dayan, 1992), and a recent development of Baird (1993) called advantage updating . All
the algorithms rely on learning certain real-valued functions defined over the state or state
and action space of a task. The  superscript used with any of the described functions
designates its optimal values (i.e., corresponding to an optimal policy). Simplified versions
of the algorithms, corresponding to TD(0), will be presented and related to Equation 6.
The presentation below is limited solely to function update rules | for a more elaborated
description of the algorithms the reader should consult the original publications of their
developers or, for AHC and Q-learning, Lin (1993) or Cichosz (1994). They are all closely
related to dynamic programming methods (Barto, Sutton, & Watkins, 1990; Watkins, 1989;
Baird, 1993), but these relations, though theoretically and practically important and fruitful, are not essential for the subject of this paper and will not be discussed.
2.2.1 The AHC Algorithm

The variation of the AHC algorithm described here is adopted from Sutton (1990). Two
functions are maintained: an evaluation function V and a policy function f . The evaluation
function evaluates each environment state and is essentially the same as what was called
above the U function, i.e., V (x) is intended to be an estimate of the discounted sum of
future reinforcement values received starting from state x and following the current policy.
The policy function assigns to each state-action pair (x; a) a real number representing
the relative merit of performing action a in state x, called the action merit . The actual
policy is determined from action merits using some, usually stochastic, action selection
mechanism, e.g., according to a Boltzmann distribution (as described in Section 5). The
optimal evaluation of state x, V  (x), is the expected total discounted reinforcement that
will be received starting from state x and following an optimal policy.
Both the functions are updated at each step t, after executing action at in state xt,
according to the following rules:

updateff(V; xt ; rt + Vt(xt+1 ) , Vt(xt));
updatefi (f; xt; at; rt + Vt(xt+1) , Vt (xt)).
292

fiTruncating Temporal Differences

The update rule for the V -function directly corresponds to Equation 6 for  = 0. The update
rule for the policy function increases or decreases the action merit of an action depending
on whether its long-term consequences appear to be better or worse than expected. We
present this, a simplified form of AHC corresponding to TD(0), because this paper proposes
an alternative way of using TD( > 0) to that implemented by the original AHC algorithm
presented by Sutton (1984).
2.2.2 The Q-Learning Algorithm

Q-learning learns a single function of states and actions, called a Q-function . To each
state-action pair (x; a) it assigns a Q-value or action utility Q(x; a), which is an estimate of
the discounted sum of future reinforcement values received starting from state x by executing
action a and then following a greedy policy with respect to the current Q-function (i.e.,
performing in each state actions with maximum Q-values). The current policy is implicitly
defined by Q-values. When the optimal Q-function is learned, then a greedy policy with
respect to action utilities is an optimal policy.
The update rule for the Q-function is:
updateff(Q; xt; at; rt +  maxa Qt (xt+1; a) , Qt (xt; at)).
To show its correspondence to the TD(0) version of Equation 6, we simply assume that
predicted state utilities are represented by Q-values so that Qt (xt; at) corresponds to Ut (xt)
and maxa Qt (xt+1 ; a) corresponds to Ut (xt+1).
2.2.3 The Advantage Updating Algorithm

In advantage updating two functions are maintained: an evaluation function V and an
advantage function A. The evaluation function has essentially the same interpretation as its
counterpart in AHC, though it is learned in a different way. The advantage function assigns
to each state-action pair (x; a) a real number A(x; a) representing the degree to which the
expected discounted sum of future reinforcement is increased by performing action a in
state x, relative to the action currently considered best in that state. The optimal action
advantages are negative for all suboptimal actions and equal 0 for optimal actions, and can
be related to the optimal Q-values by:
A (x; a) = Q(x; a) , max
Q(x; a0):
a
0

Similarly as action utilities, action advantages implicitly define a policy.
The evaluation and advantage functions are updated at step t by applying the following
rules:
updateff(A; xt; at; maxa At(xt; a) , At(xt; at) + rt + Vt(xt+1) , Vt (xt));
updatefi (V; xt; ff1 [maxa At+1 (xt) , maxa At(xt )]).
The update rule for the advantage function is somewhat more complex that the AHC or
Q-learning rules, but it still contains a term that directly corresponds to the TD(0) form of
Equation 6, by replacing V with U .
Actually, what has been presented above is a simplified version of advantage updating.
The original algorithm differs in two details:
293

fiCichosz

 the time step duration t is explicitly included in the update rules, while in this
presentation we assumed t = 1,
 besides learning updates , described above, so called normalizing updates are performed.

3. Eligibility Traces

It is obvious that the direct implementation of the computation described by Equation 6 is
not too tempting. It requires maintaining x (t) values for each state
x and past time step t.
P
Note, however, that one only needs to maintain the whole sums tk=0 ()t,kx (k) for all x
and only one (current) t, which is much easier due to a simple trick. Substituting

ex (t) =

t
X

()t,k x (k);

k=0

we can define the following recursive update rule:

ex(0) =
ex(t) =

(
(

1 if x0 = x
0 otherwise;
ex(t , 1) + 1 if xt = x
ex(t , 1)
otherwise:

(8)

The quantities ex (t) defined this way are called activity or eligibility traces (Barto,
Sutton, & Anderson, 1983; Sutton, 1984; Watkins, 1989). Whenever a state is visited, its
activity becomes high and then gradually decays until it is visited again. The update to
the predicted utility of each state x resulting from visiting state xt at time t may be then
written as
x (t) = (rt + Ut(xt+1) , Ut (xt ))ex(t);
(9)
which is a direct transformation of Equation 6.
This technique (with minor differences) was already used in the early works of Barto
et al. (1983) and Sutton (1984), before the actual formulation of TD(). It is especially
suitable for use with parameter estimation function representation methods, such as connectionist networks. Instead of having one ex value for each state x one then has one ei
value for each weight wi . That is how eligibility traces were actually used by Barto et al.
(1983) and Sutton (1984), inspired by an earlier work of Klopf (1982). Note that in the case
of the AHC algorithm, different  values may be used for maintaining traces used by the
evaluation and policy functions.
Unfortunately, the technique of eligibility traces is not general enough to be easy to implement with an arbitrary function representation method. It is not clear, for example, how
it could be used with such an important class of function approximators as memory-based
(or instance-based) function approximators (Moore & Atkeson, 1992). Applied with a pure
tabular representation, it has significant drawbacks. First, it requires additional memory locations, one per state. Second, and even more painful, is that it requires modifying both U (x)
and ex for all x at each time step. This operation dominates the computational complexity
294

fiTruncating Temporal Differences

of TD-based reinforcement learning algorithms, and makes using TD( > 0) much more expensive than TD(0). The eligibility traces implementation of TD() is thus, for large state
spaces, absolutely impractical on serial computers, unless an appropriate function approximator is used that allows updating function values and eligibility traces for many states
concurrently (such as a multi-layer perceptron). But even when such an approximator is
used, there are still significant computational (both memory and time) additional costs of
using TD() for  > 0 versus TD(0). Another drawback of this approach will be revealed
in Section 4.1.

4. Truncating Temporal Differences

This section departs from an alternative formulation of TD() for reinforcement learning.
Then we follow with relating the TD() training errors used in this alternative formulation
to TD() returns. Finally, we propose approximating TD() returns with truncated TD()
returns, and we show how they can be computed and used for on-line reinforcement learning.

4.1 TD Errors and TD Returns

Let us take a closer look at Equation 7. Consider the effects of experiencing a sequence of
states x0 ; x1; : : :; xk ; : : : and corresponding reinforcement values r0; r1; : : :; rk ; : : :. For the
sake of simplicity, assume for a while that all states in the sequence are different (though it
is of course impossible for finite state spaces). Applying Equation 7 to state xt under this
assumption we have:

xt = rt +h Ut(xt+1) , Ut(xt ) +
i
 rt+1 + Ut+1(xt+2) , Ut+1(xt+1) +
h
i
()2 rt+2 + Ut+2(xt+3 ) , Ut+2 (xt+2) + : : :
1
X

=

k=0

h

i

()k rt+k + Ut+k (xt+k+1 ) , Ut+k (xt+k ) :

If a state occurs several times in the sequence, each visit to that state yields a similar update.
This simple observation opens a way to an alternative (though equivalent) formulation of
TD(), offering novel implementation possibilities.
Let
0t = rt + Ut(xt+1 ) , Ut(xt)
(10)
be the TD (0) error at time step t. We define the TD () error at time t using TD(0) errors
as follows:

t =

1
X

h

i

()k rt+k + Ut+k (xt+k+1 ) , Ut+k (xt+k ) =

k=0

1
X

()k 0t+k :

k=0

(11)

Now, we can express the overall TD() error for state x, x , in terms of t errors:

x =

1
X
t=0

tx (t):

295

(12)

fiCichosz

In fact, from Equation 7 we have:

x =

1
X
t=0

0t

t
X

k=0

()t,k x (k) =

1 X
t
X

()t,k0t x (k):

(13)

t=0 k=0

Swapping the order of the two summations we get:

x =

1 X
1
X

k=0 t=k

()t,k0t x (k):

Finally, by exchanging k and t with each other, we receive:

x =

1X
1
X
t=0 k=t

()k,t0k x (t) =

1 X
1
X

t=0 k=0

()k 0t+k x (t) =

(14)
1
X
t=0

t x(t):

(15)

Note the following important difference between x (t) (Equation 6) and t : the former
is computed at each time step t for all x and the latter is computed at each step t only
for xt. Accordingly, at step t the error value x (t) is used for adjusting U (x) for all x
and t is only used for adjusting U (xt). This is crucial for the learning procedure proposed
in Section 4.2. While applying such defined t errors on-line makes changes to predicted
state utilities at individual steps clearly different than those described by Equation 6, the
overall effects of experiencing the whole state sequence (i.e., the sums of all individual error
values for each state) are equivalent, as shown above.
Having expressed TD() in terms of t errors, we can gain more insight into its operation and the role of . Some definitions will be helpful. Recall that the TD return for time t
is defined as
1
X
zt =  k rt+k :
k=0

The m-step truncated TD return (Watkins, 1989; Barto et al., 1990) is received by taking
into account only the first m terms of the above sum, i.e.,
mX
,1
[
m
]
zt =  k rt+k :
k=0
m
Note, however, that the rejected terms  rt+m +  m+1rt+m+1 + : : : can be approximated by
 mUt+m,1 (xt+m ). The corrected m-step truncated TD return (Watkins, 1989; Barto et al.,

1990) is thus:

zt(m) =

mX
,1
k=0

 k rt+k +  mUt+m,1 (xt+m ):

Equation 11 may be rewritten in the following form:

t

=
=

1
X

h

i

()k rt+k +  (1 , )Ut+k (xt+k+1 ) + Ut+k (xt+k+1 ) , Ut+k (xt+k )

k=0
1
X

h

i

()k rt+k +  (1 , )Ut+k (xt+k+1 ) , Ut (xt) +

k=0
1
X

h

i

()k Ut+k,1 (xt+k ) , Ut+k (xt+k ) :

k=1

296

(16)

fiTruncating Temporal Differences

Note that for  = 1 it yields:

1t =

1
X
 kr

k=0

t+k , Ut (xt) +

= zt , Ut (xt

1 h
X
k U

k=1

t+k,1 (xt+k ) , Ut+k (xt+k )

1 h
X
) + k U
k=1

i

i

t+k,1 (xt+k ) , Ut+k (xt+k )

:

If we relax for a moment our assumption about on-line learning mode and leave out time
subscripts from U values, the last term disappears and we simply have:

1t = zt , U (xt ):
Similarly for general , if we define the TD () return (Watkins, 1989) for time t as a
weighted average of corrected truncated TD returns:
1
1
h
i
X
X
(
k
+1)

k
zt = (1 , )  zt = ()k rt+k +  (1 , )Ut+k (xt+k+1 )
k=0
k=0

(17)

and again omit time subscripts, we will receive:

t = zt , U (xt):

(18)

The last equation brings more light on the exact nature of the computation performed
by TD(). The error at time step t is the difference between the TD() return for that step
and the predicted utility of the current state, that is, learning with that error value will
bring the predicted utility closer to the return. For  = 1 the quantity zt is the usual TD
return for time t, i.e., the discounted sum of all future reinforcement values.4 For  < 1 the
term rt+k is replaced by rt+k +  (1 , )Ut+k (xt+k+1 ), that is, the actual immediate reward
is augmented with the predicted future reward.
The definition of the TD() return (Equation 17) may be written recursively as

zt = rt +  (zt+1 + (1 , )Ut(xt+1 )):

(19)

This probably best explains the role of  in TD() learning. It determines how the return
used for improving predictions is obtained. When  = 1, it is exactly the actual observed
return, the discounted sum of all rewards. For  = 0 it is the 1-step corrected truncated
return, i.e., the sum of the immediate reward and the discounted predicted utility of the
successor state. Using 0 <  < 1 allows to smoothly interpolate between these two extremes,
relying partially on actual returns and partially on predictions.
Equation 18 holds true only for batch learning mode, but in fact TD methods have been
originally formulated for batch learning. The incremental version, more practically useful,
4. This observation corresponds to the equivalence of \generic" TD() for  = 1 to supervised learning
shown by Sutton (1988). To receive such a result it was necessary to discount prediction differences with
 instead of  alone in Equation 6, though Sutton presenting the RL-oriented form of TD did not make
this modification.

297

fiCichosz

introduces an additional term. Let Dt designate that term. By comparing Equations 16
and 17 we get:

Dt = t , (zt , Ut(xt)) =

1
X

k=1

h

i

()k Ut+k,1 (xt+k ) , Ut+k (xt+k ) :

(20)

The magnitude of this discrepancy term, and consequently its inuence on the learning
process, obviously depends on the learning rate value. To examine it further, suppose a
learning rate  is used when learning U on the basis of t errors. Let the corresponding
learning rule be:
Ut+1(xt) := Ut(xt) + t:
Then we have
Ut+1 (xt ) , Ut(xt) = (zt , Ut (xt )) + Dt
=  (z  , Ut (xt )) + 



1
X

h

()k Ut+k,1 (xt+k ) , Ut+k (xt+k )

k=1
1
X
(z  , Ut (xt )) ,  2 ()kt+k,1;
k=1

i

(21)

with equality if and only if xt+k = xt+k,1 for all k. A similar result may be obtained for the
eligibility traces implementation, with learning driven by x (t) errors defined by Equation 9.
We would then have:

Ut+1 (xt) , Ut(xt) = (z , Ut(xt )) ,  2

1
X

k=1

()k0t+k,1 ext+k (t + k , 1):

(22)

This effect may be considered another drawback of the eligibility traces implementation of
TD(), apart from its ineciency and lack of generality. Though for small learning rates
the effect of Dt is negligible, it may be still harmful in some cases, especially for large 
and .5

4.2 The TTD Procedure

We have shown that TD errors t or zt , Ut (xt ) can be used almost equivalently for TD()
learning, yielding the same overall results as the eligibility traces implementation, which has,
however, important drawbacks in practice. Nevertheless, it is impossible to use either TD()
errors t or TD() returns zt for on-line learning, since they are not available. At step t
the knowledge of both rt+k and xt+k is required for all k = 1; 2; : : :, and there is no way to
implement this in practice. Recall, however, the definition of the truncated TD return. Why
not define the truncated TD() error and the truncated TD() return? The appropriate
definitions are:
mX
,1
;m
=
()k0t+k
(23)
t
k=0
5. Sutton (1984) presented the technique of eligibility traces as an implementation of the recency and
frequency heuristics . In this context, the phenomenon examined above may be considered a harmful
effect of the frequency heuristic. Sutton discussed an example finite-state task where this heuristic might
be misleading (Sutton, 1984, page 171).

298

fiTruncating Temporal Differences

and

zt;m =
=

mX
,2

h

i

h

i

h

i

()k rt+k +  (1 , )Ut+k (xt+k+1 ) + ()m,1 rt+m,1 + Ut+m,1 (xt+m )

k=0
mX
,1

()k rt+k +  (1 , )Ut+k (xt+k+1 ) + ()mUt+m,1 (xt+m ):

(24)

k=0
We call ;m
t the m-step truncated TD() error, or simply the TTD (; m) error at time
step t, and zt;m the m-step truncated TD() return, or the TTD (; m) return for time t.
Note that zt;m defined by Equation 24 is corrected , i.e., it is not obtained by simply truncating Equation 17. The correction term ()mUt+m,1 (xt+m ) results in multiplying the
last prediction Ut+m,1 (xt+m ) by  alone instead of  (1 , ), which is virtually equivalent
to using  = 0 for that step. It is done in order to include in zt;m all the available infor-

mation about the expected returns for further time steps (t + m; t + m + 1; : : :) contained
in Ut+m,1 (xt+m ). Without this correction for large  this information would be almost
completely lost.
So defined, m-step truncated TD() errors or returns, can be used for on-line learning
by keeping track of the last m visited states, and updating at each step the predicted
utility of the least recent state of those m states. This idea leads to what we call the TTD
Procedure (Truncated Temporal Differences ), which can be a good approximation of TD()
for suciently large m. The procedure is parameterized by  and m values. An m-element
experience buffer is maintained, containing records hxt,k ; at,k ; rt,k ; Ut,k (xt,k+1 )i for all
k = 0; 1; : : :; m , 1, where t is the current time step. At each step t by writing x[k] , a[k] ,
r[k], and u[k] we refer to the corresponding elements of the buffer, storing xt,k , at,k , rt,k ,
and Ut,k (xt,k+1 ).6 References to U are not subscripted with time steps, since all of them
concern the values available at the current time step | in a practical implementation this
directly corresponds to restoring a function value from some function approximator or a
look-up table. Under this notational convention, the operation of the TTD(; m) procedure
is presented in Figure 1. It uses TTD(; m) returns for learning. An alternative version, using
TTD(; m) errors instead (based on Equation 11), is also possible and straightforward to
formulate, but there is no reason to use a \weaker" version (subject to the harmful effects
described by Equations 20 and 21) when a \stronger" one is available at the same cost.
At the beginning of learning, before the first m steps are made, no learning can take
place. During these initial steps the operation of the TTD procedure reduces to updating
appropriately the contents of the experience buffer. This obvious technical detail was left
out in Figure 1 for the sake of simplicity.
The TTD(; m) return value z is computed in step 5 by the repeated application of
Equation 19. The computational cost of such propagating the return in time is acceptable
in practice for reasonable values of m. For some function representation methods, such
as neural networks, the overall time complexity is dominated by the costs of retrieving a
function value and learning performed in steps 4 and 6, and the cost of computing z is
negligible. One advantage of such implementation is that it allows to use adaptive  values:
in step 5 one can use k depending on whether a[k,1] was or was not a non-policy action, or
6. This naturally means that the buffer's indices are shifted appropriately on each time tick.

299

fiCichosz

At each time step t:
1. observe current state xt ; x[0] := xt ;
2. select an action at for state xt ; a[0] := at ;
3. perform action at ; observe new state xt+1 and immediate reinforcement rt;
4. r[0] := rt; u[0] := U (xt+1 );
5. for k = 0; 1; : : :; m , 1 do
if k = 0 then z := r[k] + u[k]
else z := r[k] +  (z + (1 , )u[k]);
6. update (U; x[m,1] ; a[m,1]; z , U (x[m,1]));
7. shift the indices of the experience buffer.
Figure 1: The TTD(; m) procedure.
\how much" non-policy it was. This refinement to the TD() algorithm was suggested by
Watkins (1989) or recently Sutton and Singh (1994). Later we will see how the TTD return
computation can be performed in a fully incremental way, using constant time at each step
for arbitrary m.
Note that the function update carried out in step 6 at time t applies to the state and
action from time t , m + 1, i.e., m , 1 time steps earlier. This delay between an experience
event and learning might be found a potential weakness of the presented approach, especially
for large m. Note, however, that as a baseline in computing the error value the current utility
U (x[m,1] ) = Ut(xt,m+1) is used. This is an important point, because it guarantees that
learning will have the desired effect of moving the utility (whatever value it currently has)
towards the corresponding TTD return. If the error used in step 6 were z , Ut,m (xt,m+1 )
instead of z , Ut (xt,m+1 ), then applying it to learning at time t would be problematic.
Anyway, it seems that m should not be too large.
The TTD procedure is not an exact implementation of TD methods for two reasons.
First, it only approximates TD() returns with TTD(; m) returns. Second, it introduces
the aforementioned delay between experience and learning. I believe, however, that it is
possible to give strict conditions under which the convergence properties of TD() hold
true for the TTD implementation.
4.2.1 Choice of m

The reasonable choice of m obviously depends on . For  = 0 the best possible is m = 1
and for  = 1 and  = 1 no finite value of m is large enough to accurately approximate
TD(). Fortunately, this does not seem to be very painful. It is rather unlikely that in any
application one wanted to use the combination of  = 1 and  = 1, the more so as existing
300

fiTruncating Temporal Differences

previous empirical results with TD() indicate that  = 1 is usually not the optimal value
to use, and it is at best comparable with other, smaller values (Sutton, 1984; Tesauro, 1992;
Lin, 1993). Similar conclusions follow from the discussion of the choice of  presented by
Watkins (1989) or Lin (1993). For  < 1 or  < 1 we would probably like to have such a
value of m that the discount ()m is a small number. One possible definition of `small'
here could be, e.g., `much less than '. This is obviously a completely informal criterion.
Table 1 illustrates the practical effects of this heuristic. On the other hand, for too large m,
the delay between experience and learning introduced by the TTD procedure might become
significant and cause some problems. Some of the experiments described in Section 5 have
been designed in order to test different values of m for fixed 0 <  < 1.


0:99 0:975 0:95 0:9 0:8 0:6
minfm j ()m < 101 g 231 92
46 23 12 6
Table 1: Choosing m: an illustration.
4.2.2 Reset Operation

Until now, we have assumed that the learning process, once started, continues infinitely
long. This is not true for episodic tasks (Sutton, 1984) and for many real-world tasks,
where learning must usually stop some time. This imposes the necessity of designing a
special mechanism for the TTD procedure, that will be called the reset operation . The reset
operation would be invoked after the end of each episode in episodic tasks, or after the
overall end of learning.
There is not very much to be done. The only problem that must be dealt with is that the
experience buffer contains the record of the last m steps for which learning has not taken
place yet, and there will be no further steps that would make learning for these remaining
steps possible. The implementation of the reset operation that we find the most natural
and coherent with the TTD procedure is then to simulate m additional fictious steps, so
that learning takes place for all the real steps left in the buffer, and their TTD returns
remain unaffected by the simulated fictious steps. The corresponding algorithm, presented
in Figure 2, is formulated as a replacement of the original algorithm from Figure 1 for the
final time step. At the final step, when there is no successor state, the fictious successor
state utility is assumed to be 0. This corresponds to assigning 0 to u[0] . The actual reset
operation is performed in step 5.
4.2.3 Incremental TTD

As stated above, the cost of iteratively computing the TTD(; m) return is relatively small
for reasonable m, and with some function representation methods, for which restoring and
updating function values is computationally expensive, may be really negligible. We also
argued that reasonable values of m should not be too large. On the other hand, such iterative
return computation is easy to understand and reects well the idea of TTD. That is why
301

fiCichosz

At the final time step t:
1. observe current state xt ; x[0] := xt ;
2. select an action at for state xt ; a[0] := at ;
3. perform action at ; observe immediate reinforcement rt ;
4. r[0] := rt; u[0] := 0;
5. for k0 = 0; 1; : : :; m , 1 do
(a) for k = k0; k0 + 1; : : :; m , 1 do
if k = k0 then z := r[k] + u[k]
else z := r[k] +  (z + (1 , )u[k]);
(b) update (U; x[m,1] ; a[m,1]; z , U (x[m,1]));
(c) shift the indices of the experience buffer.
Figure 2: The reset operation for the TTD(; m) procedure.
we presented the TTD procedure in that form. It is possible, however, to compute the
TTD(; m) return in a fully incremental manner, using constant time for arbitrary m.
To see this, note that the definition of the TTD(; m) return (Equation 24) may be
rewritten in the following form:

zt;m =
=

mX
,1

()krt+k +

mX
,2

()k (1 , )Ut+k (xt+k+1 ) + ()m,1Ut+m,1 (xt+m )

k=0
k=0
;m
;m
St + Tt + Wt;m;

where

St;m =
Tt;m =
Wt;m

mX
,1
k=0
mX
,2
k=0

()krt+k ;
()k (1 , )Ut+k (xt+k+1 );

= ()m,1Ut+m,1(xt+m ):

Wt;m can be directly computed in constant time for any m. It is not dicult to convince

oneself that:

1 ;m
m
St;m
+1 =  St , rt + () rt+m ;
1 hT ;m ,  (1 , )U (x ) + (1 , )W ;mi :
Tt;m
=
t t+1
t
+1
 t
h

i

302

(25)
(26)

fiTruncating Temporal Differences

The above two equations define the algorithm for computing incrementally St;m and Tt;m,
and consequently computing zt;m in constant time for arbitrary m, with a very small computational expense. This algorithm is strictly mathematically equivalent to the algorithm
presented in Figure 1.7 Modifying appropriately the TTD procedure is straightforward and
will not be discussed. A drawback of this modification is that it probably does not allow
the learner to use different (adaptive)  values at each step, i.e., it may not be possible to
combine it with the refinements suggested by Watkins (1989) or Sutton and Singh (1994).
Despite this, such implementation might be beneficial if one wanted to use really large m.
4.2.4 TTD-Based Implementations of RL Algorithms

To implement particular TD-based reinforcement learning algorithms on the basis of the
TTD procedure, one just has to substitute appropriate function values for U , and define
the updating operation of step 6 in Figure 1 and step 5b in Figure 2. Specifically, for the
three algorithms outlined in Section 2.2 one should:

 for AHC:
1. replace U (xt+1) with V (xt+1 ) in step 4 (Figure 1);
2. implement step 6 (Figure 1) and step 5b (Figure 2) as:
v := V (x[m,1] );
updateff(V; x[m,1] ; z , v );
updatefi (f; x[m,1] ; a[m,1]; z , v );

 for Q-learning:
1. replace U (xt+1) with maxa Q(xt+1; a) in step 4 (Figure 1);
2. implement step 6 (Figure 1) and step 5b (Figure 2) as:
updateff(Q; x[m,1] ; a[m,1]; z , Q(x[m,1] ; a[m,1]));

 for advantage updating:
1. replace U (xt+1) with V (xt+1 ) in step 4 (Figure 1);

2. implement step 6 (Figure 1) and step 5b (Figure 2) as:
Amax := maxa A(x[m,1] ; a);
updateff(A; x[m,1]; a[m,1]; Amax , A(x[m,1] ; at) + z , V (x[m,1]));
updatefi (V; x[m,1]; ff1 [maxa A(x[m,1]) , Amax]).

4.3 Related Work

The simple idea of truncating temporal differences that is implemented by the TTD procedure is not new. It was probably first suggested by Watkins (1989). This paper owes much
to his work. But, to the best of my knowledge, this idea has never been explicitly and
7. But it is not necessarily numerically equivalent, which may sometimes cause problems in practical
implementations.

303

fiCichosz

exactly specified, implemented, and tested. In this sense the TTD procedure is an original
development.
Lin (1993) used a very similar implementation of TD(), but only for what he called
experience replay , and not for actual on-line reinforcement learning. In his approach a sequence of past experiences is replayed occasionally, and during replay for each experience
the TD() return (truncated to the length of the replayed sequence) is computed by applying Equation 19, and a corresponding function update is performed. Such a learning
method is by some means more computationally expensive than the TTD procedure (especially implemented in a fully incremental manner, as suggested above), since it requires
updating predictions sequentially for all replayed experiences, besides \regular" TD(0) updates performed at each step (while TTD always requires only one update per time step),
and it does not allow the learner to take full advantage of TD( > 0), which is applied only
occasionally.
Peng and Williams (1994) presented an alternative way of combining Q-learning and
TD(), different than discussed in Section 2.2. Their motivation was to better estimate TD
returns by the use of TD errors. Toward that end, they used the standard Q-learning error

rt +  max
a Qt (xt+1 ; a) , Qt (xt; at )
for one-step updates and a modified error

rt +  max
a Qt (xt+1 ; a) , max
a Qt (xt ; a);
propagated using eligibility traces, thereafter. The TTD procedure achieves a similar objective in a more straightforward way, by the use of truncated TD() returns.
Other related work is that of Pendrith (1994). He applied the idea of eligibility traces in
a non-standard way to estimate TD returns. His approach is more computationally ecient
that the classical eligibility traces technique (it requires one prediction update per time
step) and is free of the potentially harmful effect described by Equation 22. The method
seems to be roughly equivalent to the TTD procedure with  = 1 and large m, though it is
probably much more implementationally complex.

5. Demonstrations

The demonstrations presented in this section use the AHC variant of the TTD procedure.
The reason is that the AHC algorithm is the simplest of the three described algorithms and
its update rule for the evaluation function most directly corresponds to TD(). Future work
will investigate the TTD procedure for the two other algorithms.
A tabular representation of the evaluation and policy functions is used. The abstract
function update operation described by Equation 2 is implemented in a standard way as

'(p0; p1; : : :; pn,1 ) := '(p0; p1; : : :; pn,1 ) + :

(27)

Actions to execute at each step are selected using a simple stochastic selection mechanism based on a Boltzmann distribution. According to this mechanism, action a is selected
304

fiTruncating Temporal Differences

in state x with probability

Prob(x; a) = Pexp(f (x; a )=T ) ;
a exp(f (x; a)=T )

(28)

where the temperature T > 0 adjusts the amount of randomness.

5.1 The Car Parking Problem

This section presents experimental results for a learning control problem with a relatively
large state space and hard temporal credit assignment. We call this problem the car parking
problem, though it does not attempt to simulate any real-world problem at all. Using words
such as `car', `garage', or `parking' is just a convention that simplifies problem description
and the interpretation of results. The primary purpose of the experiments is neither just
to solve the problem nor to provide evidence of the usefulness of the tested algorithm
for any particular practical problem. We use this example problem in order to illustrate
the performance of the AHC algorithm implemented within the TTD framework and to
empirically evaluate the effects of different values of the TTD parameters  and m.
The car parking problem is illustrated in Figure 3. A car, represented as a rectangle,
is initially located somewhere inside a bounded area, called the driving area. A garage is
a rectangular area of a size somewhat larger than the car. All important dimensions and
distances are shown in the figure. The agent | the driver of the car | is required to park
it in the garage, so that the car is entirely inside. The task is episodic, though it is neither
a time-until-success nor time-until-failure task (in Sutton's (1984) terminology), but rather
a combination of both. Each episode finishes either when the car enters the garage or when
it hits a wall (of the garage or of the driving area). After an episode the car is reset to its
initial position.
5.1.1 State Representation

The state representation consists of three variables: the rectangular coordinates of the center
of the car, x and y , and the angle  between the car's axis and the x axis of the coordinate
system. The orientation of the system is shown in the figure. The initial location and
orientation of the car is fixed and described by x = 6:15 m, y = 10:47 m, and  = 3:7 rad.
It was chosen so as to make the task neither too easy nor too dicult.
5.1.2 Action Representation

The admissible actions are `drive straight on', `turn left', and `turn right'. The action of
driving straight on has the effect of moving the car forward along its axis, i.e., without
changing . The actions of turning left and right are equivalent to moving along an arc with
a fixed radius. The distance of each move is determined by a constant car velocity v and
simulation time step  . Exact motion equations and other details are given in Appendix A.
5.1.3 Reinforcement Mechanism

The design of the reinforcement function is fairly straightforward. The agent receives a
reinforcement value of 1 (a reward) whenever it successfully parks the car in the garage,
305

fiCichosz

y0

x

xG

x1

0

x0

yG

l

w

y1

0

1

2

3

m

y

Figure 3: The car parking problem. The scale of all dimensions is preserved: w = 2 m,
l = 4 m, x0 = ,1:5 m, xG = 1:5 m, x1 = 8:5 m, y0 = ,3 m, yG = 3 m, y1 = 13 m.
and a reinforcement value of ,1 (a punishment) whenever it hits a wall. At all other time
steps the reinforcement is 0. That is, non-zero reinforcements are received only at the last
step of each episode. This involves a relatively hard temporal credit assignment problem,
providing a good experimental framework for testing the eciency of the TTD procedure.
The problem is hard not only because of reinforcement delay, but also because punishments
are much more frequent than rewards: it is much easier to hit a wall than to park the car
correctly.
With such a reinforcement mechanism as presented above, an optimal policy for any
0 <  < 1 is a policy that allows to park the car in the garage in the smallest possible
number of steps.
306

fiTruncating Temporal Differences

5.1.4 Function Representation

The car parking problem has a continuous state space. It is artificially discretized | divided
into a finite number of disjoint regions by quantizing the three state variables, and then a
function value for each region is stored in a look-up table. The quantization thresholds are:

 for x: ,0:5, 0:0, 0:5, 1:0, 2:0, 3:0, 4:0, 6:0 m,
 for y: 0:5, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 8:0, 10:0 m,
21
29 3 31
 for : 19
20  ,  , 20  , : : :, 20  , 2  , 20  rad.
This yields 9  10  14 = 1260 regions. Of course many of them will never be visited. The

threshold values were chosen so as to make the resulting discrete state space of a moderate
size. The quantization is dense near the garage, and becomes more sparse as the distance
from the garage increases.
5.1.5 Experimental Design and Results

Our experiments with applying the TTD procedure to the car parking problem are divided
into two studies, testing the effects of the two TTD parameters  and m. The parameter
settings for all experiments are presented in Table 2. The symbols ff and fi are used to
designate the learning rates for the evaluation and policy functions, respectively. The initial
values of the functions were all set to 0, since we assumed that no knowledge is available
about expected reinforcement levels.
Study TTD Parameters
Number 
m
0
0:3
0:5
1
0:7
25
0:8
0:9
1
5
10
2
0:9
15
20

Learning Rates

ff
0:7
0:5
0:5
0:5
0:5
0:25
0:25
0:25
0:25
0:25
0:25

fi

0:7
0:5
0:5
0:5
0:5
0:25
0:25
0:25
0:25
0:25
0:25

Table 2: Parameter settings for the experiments with the car parking problem.
As stated above, the experiments were designed to test the effects of the two TTD
parameters. The other parameters were assigned values according to following principles:

 the discount factor  was fixed and equal 0:95 in all experiments,
307

fiCichosz

 the temperature value was also fixed and set to 0:02, which seemed to be equally good

for all experiments,
 the learning rates ff and fi were roughly optimized in each experiment.8
Each experiment continued for 250 episodes, the number selected so as to allow all or
almost all runs of all experiments to converge. The results presented for all experiments
are averaged over 25 individual runs, each differing only in the initial seed of the random
number generator. This number was chosen as a reasonable compromise between the reliability of results and computational costs. The results are presented as plots of the average
reinforcement value per time step for the previous 5 consecutive episodes versus the episode
number.
Study 1: Effects of . The objective of this study was to examine the effects of various
 values on learning speed and quality, with m set to 25. The value m = 25 was found to be
large enough for all the tested  values (perhaps except  = 1).9 Smaller m values might be
used for small  (in particular, m = 1 for  = 0), but it was kept constant for consistency.
Reinf/Step
0.04
0.02
0
-0.02
-0.04
-0.06
-0.08
0
50

 = 0:0
 = 0:3
 = 0:5
 = 0:7
100 150
Episode

200

Reinf/Step
0.04
0.02
0
-0.02
-0.04
-0.06
-0.08
250
0
50

 = 0:7
 = 0:8
 = 0:9
 = 1:0
100 150
Episode

200

250

Figure 4: The car parking problem, learning curves for study 1.
The learning curves for this study are presented in Figure 4. The observations can be
briey summarized as follows:
  = 0 gives the worst performance of all (not all of 25 runs managed to converge
within 250 episodes),
 increasing  improves learning speed,
  values above or equal 0:7 are all similarly effective, greatly outperforming  = 0 and
clearly better than  = 0:5,
8. The optimization procedure in most cases was as follows: some rather large value was tested in a few
runs; if it did not give any effects of overtraining and premature convergence, it was accepted; otherwise
a (usually twice) smaller value was tried, etc.
9. Note that for  = 0:9, m = 25, and  = 0:95 we have ()m  0:02  0:855 = .

308

fiTruncating Temporal Differences

 using large  caused the necessity of reducing the learning rates (cf. Table 2) to ensure

convergence.
The main result is that using large  with the TTD procedure (including 1) always
significantly improved performance. It is not quite consistent with the empirical results of
Sutton (1988), who found the performance of TD() the best for intermediate , and the
worst for  = 1. Lin (1993), who used  > 0 for his experience replay experiments, reported
 close to 1 as the most successful, similarly as this work. He speculated that the difference
between his results and Sutton's might have been caused by switching occasionally (for
non-policy actions) to  = 0 in his studies.10 Our results, obtained for  held fixed all the
time11 , suggest that this is not a good explanation. It seems more likely that the optimal 
value simply strongly depends on the particular problem. Another point is that neither our
TTD(1; 25) nor Lin's implementation is exactly equivalent to TD(1).
Study 2: Effects of m. This study was designed to investigate the effects of using several
different m values for a fixed and relatively large  value. The best (approximately)  from
study 1 was used, that is 0:9. The smallest tested m value is 5, which we find to be rather
a small value.12
Reinf/Step
0.04
0.02
0
-0.02
-0.04
-0.06
-0.08
0
50

m= 5
m = 10
m = 15
m = 20
m = 25
100 150
Episode

200

250

Figure 5: The car parking problem, learning curves for study 2.
The learning curves for this study are presented in Figure 5. The results for m = 25
were taken from study 1 for comparison. The observations can be summarized as follows:
 m = 5 is the worst and m = 25 is the best,
 the differences between intermediate m values do not seem to be very statistically
significant,
10. As a matter of fact, non-policy actions were not replayed at all in Lin's experience replay experiments.
11. Except for using  = 0 for the most recent time step covered by the TTD return, as it follows from its
definition (Equation 24).
12. For  = 0:95,  = 0:9, and m = 5 we have ()m  0:457, which is by all means comparable with
 = 0:855.

309

fiCichosz

 even the smallest m = 5 gives the performance level much better than that obtained in
study 1 for small , i.e., even relatively small m values allow us to have the advantages
of large , though larger m values are generally better than small ones,
The last observation is probably the most important. It is also very optimistic. It suggests
that, at least in some problems, the TTD procedure with  > 0 allows to obtain a significant
learning speed improvement over traditional TD(0)-based algorithms with practically no
additional costs, because for small m both space and time complexity induced by TTD is
always negligible.

5.2 The Cart-Pole Balancing Problem
The experiments of this section have one basic purpose: to verify the effectiveness of the
TTD procedure by applying its AHC implementation to a realistic and complex problem,
with a long reinforcement delay, for which there exist many previous results for comparison.
The cart-pole balancing problem, a classical benchmark of control specialists, is just such
a problem. In particular, we would like to see whether it is possible to obtain performance
(learning speed and the quality of the final policy) not worse than that reported by Barto
et al. (1983) and Sutton (1984) using the eligibility traces implementation.
Figure 6 shows the cart-pole system. The cart is allowed to move along a one-dimensional
bounded track. The pole can move only in the vertical plane of the cart and the track. The
controller applies either a left or right force of fixed magnitude to the cart at each time
step. The task is episodic: each episode finishes when a failure occurs, i.e., the pole falls or
the cart hits an edge of the track. The objective is to delay the failure as long as possible.
The problem was realistically simulated by numerically solving a system of differential
equations, describing the cart-pole system. These equations and other simulation details
are given in Appendix B. All parameters of the simulated cart-pole system are exactly the
same as used by Barto et al. (1983).
5.2.1 State Representation

The state of the cart-pole system is described by four state variables:

 x | the position of the cart on the track,
 x_ | the velocity of the cart,
  | the angle of the pole with the vertical,
 _ | the angular velocity of the pole.
5.2.2 Action Representation

At each step the agent controlling the cart-pole system chooses one of the two possible
actions of applying a left or right force to the cart. The force magnitude is fixed and
equal 10 N.
310

fiTruncating Temporal Differences



2l

F

x
d

Figure 6: The cart-pole system. F is the force applied to the cart's center, l is a half of the
pole length, and d is a half of the length of the track.
5.2.3 Reinforcement Mechanism

The agent receives non-zero reinforcement values (namely ,1) only at the end of each
episode, i.e., after a failure. A failure occurs whenever jj > 0:21 rad (the pole begins to
fall) or jxj > 2:4 m (the cart hits an edge of the track). Even at the beginning of learning,
with a very poor policy, an episode may continue for hundreds of time steps, and there may
be many steps between a bad action and the resulting failure. This makes the temporal
credit assignment problem in the cart-pole task extremely hard.
5.2.4 Function Representation

As in the case of the car parking problem, we deal with the continuous state space of the
cart-pole system by dividing it into disjoint regions, called boxes after Mitchie and Chambers
(1968). The quantization thresholds are the same as used by Barto et al. (1983), i.e.:

 for x: ,0:8, 0:8 m,
 for x_ : ,0:5, 0:5 m/s,
 for : ,0:105, ,0:0175, 0, 0:0175, 0:105 rad,
 for _: ,0:8727, 0:8727 rad/s,
which yields 3  3  6  3 = 162 boxes. For each box there is a memory location, storing a
function value for that box.
311

fiCichosz

5.2.5 Experimental Design and Results

Computational expense prevented such extensive experimental studies as for the car parking
problem. Only one experiment was carried out, intended to be a replication of the experiment presented by Barto et al. (1983). The values of the TTD parameters that seemed the
best from the previous experiments were used, that is  = 0:9 and m = 25. The discount
factor  was set to 0:95. The learning rates for the evaluation and policy functions were
roughly optimized by a small number of preliminary runs and equal ff = 0:1 and fi = 0:05,
respectively. The temperature of the Boltzmann distribution action selection mechanism
was set to 0:0001, so as to give nearly-deterministic action selection. The initial values of
the evaluation and policy functions were set to 0. We did not attempt to strictly replicate
the same learning parameter values as in the work of Barto et al. (1983), since they used not
only a different TD() implementation13 , but also a different policy representation (based
on the fact that there are only two actions, while our representation is general), action
selection mechanism (for the same reasons), and function learning rule.
The experiment consisted of 10 runs, differing only in the initial seed of the random
number generator, and the presented results are averaged over those 10 runs. Each run continued for 100 episodes. Some of individual runs were terminated after 500; 000 time steps,
before completing 100 episodes. To produce reliable averages for all 100 episodes, fictious
remaining episodes were added to such runs, with the duration assigned according to the
following principle, used in the experiments of Barto et al. (1983). If the duration of the
last, interrupted episode was less than the duration of the immediately preceding (complete) episode, the fictious episodes were assigned the duration of that preceding episode.
Otherwise, the fictious episodes were assigned the duration of the last (incomplete) episode.
This prevented any short interrupted episodes from producing unreliably low averages. The
results are presented in Figure 7 as plots of the average duration (the number of time steps)
of the previous 5 consecutive episodes versus the episode number, in linear and logarithmic
scale.
We can observe that TTD-based AHC achieved a similar (slightly better, to be exact)
performance level, both as to learning speed and the quality of the final policy (i.e., the
balancing periods), to that reported by Barto et al. (1983). The final balancing periods lasted
above 130; 000 steps, on the average. It was obtained without using 162 additional memory
locations for storing eligibility traces, and without the expensive computation necessary to
update all of them at each time step, as well as all evaluation and policy function values.

5.3 Computational Savings

The experiments presented above illustrate the computational savings possible with the
TTD procedure over conventional eligibility traces. A direct implementation of eligibility
traces requires computation proportional to the number of states, i.e., to 1260 in the car
parking task and to 162 in the cart-pole task | potentially many more in larger tasks.
Even the straightforward iterative version of TTD may be then beneficial, as it requires
computation proportional to m, which may be reasonably assumed to be many times less
13. It was the eligibility traces implementation, but eligibility traces were updated by applying a somewhat
different update rule than specified by Equation 8. In particular, they were discounted with  alone
instead of . Moreover, two different  values were used for the evaluation and policy functions.

312

fiTruncating Temporal Differences

Episode Duration
140000
120000
100000
80000
60000
40000
20000
0
0
20

(a)

40 60
Episode

80

Episode Duration
100000
10000
1000
100
10
1
100
0
20

(b)

40 60
Episode

80

100

Figure 7: The cart-pole balancing problem, learning curve in (a) linear and (b) logarithmic
scale.
than the size of the state space. Of course, the incremental version of TTD, which requires
always very small computation independent of m, is much more ecient.
In many practical implementations, to improve eciency, eligibility traces and predictions are updated only for relatively few recently visited states. Traces are maintained only
for the n most recently visited states, and the eligibility traces of all other states are assumed
to be 0.14 But even for this \ecient" version of eligibility traces, the savings offered by
TTD are considerable. For a good approximation to infinite traces in such tasks as considered here, n should be at least as large as m. For conventional eligibility traces, there will be
always a concern for keeping n low, by reducing  , , or the accuracy of the approximation.
The same problem occurs for iterative TTD,15 but for incremental TTD, on the other hand,
none of these are at issue. The same small computation is needed independent of m.

6. Conclusion
We have informally derived the TTD procedure from the analysis of the updates introduced
by TD methods to the predicted utilities of states, and shown that they can be approximated by the use of truncated TD() returns. Truncating temporal differences allows easy
and ecient implementation. It is possible to compute TTD returns incrementally in constant time, irrespective of the value of m (the truncation period), so that the computational
expense of using TD-based reinforcement learning algorithms with  > 0 is negligible (cf.
Equations 25 and 26). It cannot be achieved with the eligibility traces implementation.
The latter, even for such function representation methods to which it is particularly well
14. This modification cannot be applied when a parameter estimation function representation technique is
used (e.g., a multi-layer perceptron), where traces are maintained for weights rather than for states.
15. The relative computational expense of iterative TTD and the \ecient" version of eligibility traces
depends on the cost of the function update operation, which is always performed only for one state by
the former, and for n states by the latter.

313

fiCichosz

suited (e.g., neural networks), is always associated with significant memory and time costs.
The TTD procedure is probably the most computationally ecient (although approximate)
on-line implementation of TD(). It is also general, equally good for any function representation method that might be used.
An important question concerning the TTD procedure is whether its computational
eciency is not obtained at the cost of reduced learning eciency. Having low computational costs per control action may not be attractive if the number of actions necessary to
converge becomes large. As for now, no theoretically grounded answer to this important
question has been provided, though it is not unlikely that such an answer will eventually
be found. Nevertheless, some informal consideration may suggest that the TTD-based implementation of TD methods not only does not have to perform worse than the classical
eligibility traces implementation, but it can even have some advantages. As it follows from
Equations 20, 21, and 22, using TD(0) errors for on-line TD() learning, as in the eligibility
traces implementation, introduces an additional discrepancy term, whose inuence on the
learning process is proportional to the square of the learning rate. That term, though often
negligible, may be still harmful in certain cases, especially in tasks where the agent is likely
to stay in the same states for long periods. The TTD procedure, based on truncated TD()
returns, is free of this drawback.
Another argument supporting the TTD procedure is associated with using large  values,
in particular 1. For an exact TD() implementation, such as that provided by eligibility
traces, it means that learning relies solely on actually observed outcomes, without any regard
to currently available predictions. It may be beneficial at the early stages of learning, when
predictions are almost completely inaccurate, but in general it is rather risky | actual
outcomes may be noisy and therefore sometimes misleading. The TTD procedure never
relies on them entirely, even for  = 1, since it uses m-step TTD returns for some finite m,
corrected by always using  = 0 for discounting the predicted utility of the most recent step
covered by the return (cf. Equation 17). This deviation of the TTD procedure from TD()
may turn out to be advantageous.
The TTD procedure using TTD returns for learning is only suitable for the implementation of TD methods applied to reinforcement learning. This is because in RL a part of the
predicted outcome is available at each step, as the current reinforcement value. However,
it is straightforward to formulate another version of the TTD procedure, using truncated
TD() errors instead of truncated TD() returns, that would cover the whole scope of
applications of generic TD methods.
The experimental results obtained for the TTD procedure seem very promising. The results presented in Section 5.1 show that using large  with the TTD procedure can give a significant performance improvement over simple TD(0) learning, even for relatively small m.
While it does not say anything about the relative performance of TTD and the eligibility
traces implementation of TD(), it at least suggests that the TTD procedure can be useful.
The best results have been obtained for the largest  values, including 1. This observation,
contradicting to the results reported by Sutton (1988), may be a positive consequence of
the TTD procedure's deviation from TD() discussed above.
The experiments with the cart-pole balancing problem supplied empirical evidence that
for a learning control problem with a very long reinforcement delay the TTD procedure can
equal or outperform the eligibility traces implementation of TD(), even for a value of m
314

fiTruncating Temporal Differences

many times less than the average duration of an episode. This performance level is obtained
with the TTD procedure at a much lower computational (both memory and time) expense.
To summarize, our informal consideration and empirical results suggest that the TTD
procedure may have the following advantages:

 the possibility of the implementation of reinforcement learning algorithms that may
be viewed as instantiations of TD(), using  > 0 for faster learning,
 computational eciency: low memory requirements (for reasonable m) and little computation per time step,

 generality, compatibility with various function representation methods,
 good approximation of TD() for  < 1 (or for  = 1 and  < 1),
 good practical performance, even for relatively small m.
There seems to be one important drawback: lack of theoretical analysis and a convergence proof. We do not know either what parameter values assure convergence or what
values make it impossible. In particular, no estimate is available of the potential harmful
effects of using too large m. Both the advantages and drawbacks cause that the TTD procedure is an interesting and promising subject for further work. This work should concentrate,
on one hand, on examining the theoretical properties of this technique, and, on the other
hand, on empirical studies investigating the performance of various TD-based reinforcement
learning algorithms implemented within the TTD framework on a variety of problems, in
particular in stochastic domains.

Appendix A. Car Parking Problem Details

The motion of the car in the experiments of Section 5.1 is simulated by applying at each
time step the following equations:
1. if r 6= 0 then
(a) (t +  ) = (t) +  vr ;
(b) x(t +  ) = x(t) , r sin (t) + r sin (t +  );
(c) y (t +  ) = y (t) + r cos (t) , r sin (t +  );
2. if r = 0 then
(a) (t +  ) = (t);
(b) x(t +  ) = x(t) + v cos (t);
(c) y (t +  ) = y (t) + v sin (t);
where r is the turn radius, v is the car's velocity, and  is the simulation time step. In the
experiments r = ,5 m was used for the `turn left' action, r = 5 m for `turn right', and r = 0
for `drive straight on'. The velocity was constant and set to 1 m/s, and the simulation time
315

fiCichosz

step  = 0:5 s was used. With these parameter settings, the shortest possible path from the
car's initial location (x = 6:15 m, y = 10:47 m,  = 3:7 rad) to the garage requires 21 steps.
At each step, after determining the current x, y , and  values, the coordinates of the
car's corners are computed. Then the test for intersection of each side of the car with the
lines delimiting the driving area and the garage is performed to determine whether a failure
occurred. If the result is negative, the test is performed for each corner of the car whether
it is inside the garage, to determine if a success occurred.

Appendix B. Cart-Pole Balancing Problem Details

The dynamics of the cart-pole system are described by the following equations of motion:
h
i
F (t) + mpl _2(t) sin (t) ,  cos (t) , c sgn x_ (t)
x(t) =
mc + mp


where

2
(t)+c sgn x_ (t)
g sin (t) + cos (t) ,F (t),mp l_ (mt)sin
c +mp
h
(t) =
2 (t) i
l 43 , mmp cos
c +mp



, mp_p(lt)

= 9:8 m/s2 | acceleration due to gravity,
= 1:0 kg | mass of the cart,
= 0:1 kg | mass of the pole,
= 0:5 m
| half of the pole length,
= 0:0005 | friction coecient of the cart on the track,
= 0:000002 | friction coecient of the pole on the cart,
= 10:0 N | force applied to the center of the cart at time t.
The equations were simulated using Euler's method with simulation time step  = 0:02 s.

g
mc
mp
l
c
p
F (t)

Acknowledgements
I wish to thank the anonymous reviewers of this paper for many insightful comments. I was
unable to follow all their suggestions, but they contributed much to improving the paper's
clarity. Thanks also to Rich Sutton, whose assistance during the preparation of the final
version of this paper was invaluable.
This research was partially supported by the Polish Committee for Scientific Research
under Grant 8 S503 019 05.

References

Baird, III, L. C. (1993). Advantage updating. Tech. rep. WL-TR-93-1146, Wright Laboratory, Wright-Patterson Air Force Base.
Barto, A. G. (1992). Reinforcement learning and adaptive critic methods. In White, D. A.,
& Sofge, D. A. (Eds.), Handbook of Intelligent Control, pp. 469{491. Van Nostrand
Reinhold, New York.
316

fiTruncating Temporal Differences

Barto, A. G., Sutton, R. S., & Anderson, C. (1983). Neuronlike adaptive elements that can
solve dicult learning control problems. IEEE Transactions on Systems, Man, and
Cybernetics, 13, 835{846.
Barto, A. G., Sutton, R. S., & Watkins, C. J. C. H. (1990). Learning and sequential
decision making. In Gabriel, M., & Moore, J. (Eds.), Learning and Computational
Neuroscience. The MIT Press.
Cichosz, P. (1994). Reinforcement learning algorithms based on the methods of temporal
differences. Master's thesis, Institute of Computer Science, Warsaw University of
Technology.
Dayan, P. (1992). The convergence of TD() for general . Machine Learning, 8, 341{362.
Dayan, P., & Sejnowski, T. (1994). TD() converges with probability 1. Machine Learning,
14, 295{301.
Heger, M. (1994). Consideration of risk in reinforcement learning. In Proceedings of the
Eleventh International Conference on Machine Learning (ML-94). Morgan Kaufmann.
Jaakkola, T., Jordan, M. I., & Singh, S. P. (1993). On the convergence of stochastic iterative
dynamic programming algorithms. Tech. rep. 9307, MIT Computational Cognitive
Science. Submitted to Neural Computation .
Klopf, A. H. (1982). The Hedonistic Neuron: A Theory of Memory, Learning, and Intelligence. Washington D.C.: Hempisphere.
Lin, L.-J. (1992). Self-improving, reactive agents based on reinforcement learning, planning
and teaching. Machine Learning, 8, 293{321.
Lin, L.-J. (1993). Reinforcement Learning for Robots Using Neural Networks. Ph.D. thesis,
School of Computer Science, Carnegie-Mellon University.
Mitchie, D., & Chambers, R. A. (1968). BOXES: An experiment in adaptive control.
Machine Intelligence, 2, 137{152.
Moore, A. W., & Atkeson, C. G. (1992). An investigation of memory-based function approximators for learning control. Tech. rep., MIT Artificial Intelligence Laboratory.
Pendrith, M. (1994). On reinforcement learning of control actions in noisy and
non-markovian domains. Tech. rep. UNSW-CSE-TR-9410, School of Computer Science and Engineering, The University of New South Wales, Australia.
Peng, J., & Williams, R. J. (1994). Incremental multi-step Q-learning. In Proceedings of the
Eleventh International Conference on Machine Learning (ML-94). Morgan Kaufmann.
Ross, S. (1983). Introduction to Stochastic Dynamic Programming. Academic Press, New
York.
317

fiCichosz

Schwartz, A. (1993). A reinforcement learning method for maximizing undiscounted rewards. In Proceedings of the Tenth International Conference on Machine Learning
(ML-93). Morgan Kaufmann.
Singh, S. P. (1994). Reinforcement learning algorithms for average-payoff markovian decision
processes. In Proceedings of the Twelfth National Conference on Artificial Intelligence
(AAAI-94).
Sutton, R. S. (1984). Temporal Credit Assignment in Reinforcement Learning. Ph.D. thesis,
Department of Computer and Information Science, University of Massachusetts.
Sutton, R. S. (1988). Learning to predict by the methods of temporal differences. Machine
Learning, 3, 9{44.
Sutton, R. S. (1990). Integrated architectures for learning, planning, and reacting based
on approximating dynamic programming. In Proceedings of the Seventh International
Conference on Machine Learning (ML-90). Morgan Kaufmann.
Sutton, R. S., Barto, A. G., & Williams, R. J. (1991). Reinforcement learning is direct
adaptive optimal control. In Proceedings of the American Control Conference, pp.
2143{2146. Boston, MA.
Sutton, R. S., & Singh, S. P. (1994). On step-size and bias in temporal-difference learning.
In Proceedings of the Eighth Yale Workshop on Adaptive and Learning Systems, pp.
91{96. Center for Systems Science, Yale University.
Tesauro, G. (1992). Practical issues in temporal difference learning. Machine Learning, 8,
257{277.
Watkins, C. J. C. H. (1989). Learning from Delayed Rewards. Ph.D. thesis, King's College,
Cambridge.
Watkins, C. J. C. H., & Dayan, P. (1992). Technical note: Q-learning. Machine Learning,
8, 279{292.

318

fiJournal of Artificial Intelligence Research 2 (1994) 89-110

Submitted 3/94; published 8/94

Pattern Matching and Discourse Processing in Information
Extraction from Japanese Text
Tsuyoshi Kitani

tkitani@cs.cmu.edu

Yoshio Eriguchi
Masami Hara

eriguchi@rd.nttdata.jp
masami@rd.nttdata.jp

Center for Machine Translation
Carnegie Mellon University
Pittsburgh, PA 15213 USA
Development Headquarters
NTT Data Communications Systems Corp.
66-2 Horikawa-cho, Saiwai-ku, Kawasaki-shi, Kanagawa 210 JAPAN

Abstract
Information extraction is the task of automatically picking up information of interest
from an unconstrained text. Information of interest is usually extracted in two steps.
First, sentence level processing locates relevant pieces of information scattered throughout
the text; second, discourse processing merges coreferential information to generate the
output. In the first step, pieces of information are locally identified without recognizing
any relationships among them. A key word search or simple pattern search can achieve this
purpose. The second step requires deeper knowledge in order to understand relationships
among separately identified pieces of information. Previous information extraction systems
focused on the first step, partly because they were not required to link up each piece
of information with other pieces. To link the extracted pieces of information and map
them onto a structured output format, complex discourse processing is essential. This
paper reports on a Japanese information extraction system that merges information using
a pattern matcher and discourse processor. Evaluation results show a high level of system
performance which approaches human performance.

1. Introduction
In recent information extraction systems, most individual pieces of information to be extracted directly from a text are usually identified by key word search or simple pattern
search in the preprocessing stage (Lehnert et al., 1993; Weischedel et al., 1993; Cowie et al.,
1993; Jacobs et al., 1993). Among the systems presented at the Fifth Message Understanding Conference (muc-5), however, the main architectures ranged from pattern matching to
full or fragment parsing (Onyshkevych, 1993). Full or fragment parsing systems, in which
several knowledge sources such as syntax, semantics, and domain knowledge are combined
at run-time, are generally so complicated that changing a part of the system tends to affect
the other components. In past information extraction research, this interference has slowed
development (Jacobs, 1993; Hobbs et al., 1992). A pattern matcher, which identifies only
patterns of interest, is more appropriate for information extraction from texts in narrow
domains, since this task does not require full understanding of the text.

c 1994 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiKitani, Eriguchi, & Hara

textract, the information extraction system described here, uses a pattern matcher
similar to sri's fastus pattern matcher (Hobbs et al., 1992). The matcher is implemented
as a finite-state automaton. Unlike other pattern matchers, textract's matcher deals
with word matching problems caused by the word segmentation ambiguities often found in
Japanese compound words.
The goal of the pattern matcher is to identify the concepts represented by words and
phrases in the text. The pattern matcher first performs a simple key-word-based concept
search, locating individual words associated with concepts. The second step is a template
pattern search which locates phrasal patterns involving critical pieces of information identified by the preprocessor. The template pattern search identifies relationships between
matched objects in the defined pattern as well as recognizing the concept behind the relationship. One typical concept is the relationship of \economic activity" which companies
can participate in with each other.
It is usually dicult to determine the relationships among pieces of information which
have been identified in separate sentences. These relationships are often stated implicitly,
and even if the text explicitly mentions them the descriptions are often located far enough
apart to make detection dicult. Although the importance of discourse processing for information extraction has been emphasized in the Message Understanding Conferences (Lehnert
& Sundheim, 1991; Hirschman, 1992), no system presented has satisfactorily addressed the
issue.
The discourse processor in textract is able to correlate individual pieces of information
throughout the text. textract merges concepts which the pattern matcher has identified
separately (and usually in different sentences) when the concepts involve the same companies. textract can unify multiple references to the same company even when the company
name is missing, abbreviated, or pronominalized. Furthermore, the processor segments the
discourse to isolate portions of text relevant to a particular conceptual relationship. The
discourse segmentation lessens the chance of merging unrelated information (Kitani, 1994).
This paper analyzes some evaluation results for textract's discourse module and describes the tipster/muc-5 evaluation results in order to assess overall system performance.

2. tipster information extraction task
The goal of the tipster project sponsored by arpa is to capture information of interest
from English and Japanese newspaper articles about corporate joint ventures and microelectronics. A system must fill a generic template with information extracted from the text
by a fully automated process. The template is composed of several objects, each containing several slots. Slots may contain pointers to related objects (Tipster, 1992). Extracted
information is to be stored in an object-oriented database.
In the joint ventures domain, the task is to extract information concerning joint venture
relationships which organizations form and dissolve. The template structure represents
these relationships with tie-up-relationship objects, which contain pointers to organization
entity objects representing the organizations involved. Entity objects contain pointers to
other objects such as person and facility objects, as shown in Figure 1.
In the microelectronics domain, extraction focuses on layering, lithography, etching, and
packaging processes in semiconductor manufacturing for microchip fabrication. The entities
90

fiPattern Matching and Discourse Processing

TEMPLATE
doc. no.
doc. date
doc. source
content (*)

ENTITY
name
aliases
location
nationality
type
entity rel. (+)
person(*)
facility (*)

TIE-UP-REL.
tie-up status
entity (+)
created
entity (*)
activity (*)

ACTIVITY
industry (*)

ENTITY-REL.
entity1 (+)
entity2 (*)
rel. of ent2
to ent1
PERSON
name
persons entity
position
FACILITY
name
location
type
INDUSTRY
industry type
product /
service

denotes instantiations of multiple objects
(*) points to zero or more objects, (+) points to one or more objects

Figure 1: Object-oriented template structure of the joint ventures domain
extracted include manufacturer, distributor, and user, in addition to detailed manufacturing
information such as materials used and microchip specifications such as wafer size and device
speed. The microelectronics template structure is similar to that of the joint ventures but
has fewer objects and slots.
Both of these extraction tasks must identify not only individual entities but also certain
relationships among them. Often, however, a particular piece of extracted information
describes only part of a relationship. This partial information must be merged with other
pieces of information referring to the same entities. For merging to produce correct results,
therefore, correct identification of entity references is crucial.

3. Problem definition
This section first describes word matching problems caused by the word segmentation ambiguities. Diculties of reference resolution of company names are then explained. Issues
of discourse segmentation and concept merging are also discussed using an example text.

3.1 Word segmentation
Japanese word segmentation in the preprocessor gives rise to a subsequent under-matching
problem. When a key word in the text is not found in the word segmentor's lexicon, the
segmentor tends to divide it into separate words. With our current lexicon, for example, the
91

fiKitani, Eriguchi, & Hara

compound noun \ F " (teikei-kaisyo), consisting of two words, \  " (teikei: joint
venture) and \ F " (kaisyo: dissolve), is segmented into the two individual nouns. Thus a
key word search for \ F " (teikei-kaisyo) does not succeed in the segmented sentence.
On the other hand, the pattern matching process allows, by default, partial matching
between a key word and a word in the text. \  " (teikei) and \ [Z " (gyoum-teikei),
both meaning \a joint venture", can both be matched against the single key word \  "
(teikei). This exibility creates an over-matching problem. For example, the key word
\ JS " (silicon) matches \ f) JS" (nisanka-silicon: silicon dioxide), although
they are different materials to be reported in the microelectronics domain. These segmentation diculties for compound nouns also cause major problems in word-based Japanese
information retrieval systems (Fujii & Croft, 1993).

3.2 Company name references

In the corporate joint ventures domain, output templates mostly describe relationships
among companies (as described in Section 2). Information of interest is therefore found in
sentences which mention companies or their activities. It is essential for the extractor to
identify topic companies|the main concern of the sentences they appear in|in order to
correlate other information identified in the sentence. There are three problems which make
it dicult to identify topic companies.
1. Missing subject
Topic companies are usually the subject of a sentence. Japanese sentences frequently
omit subjects, however|even in formal newspaper articles. The veniex system which
nec presented at muc-5 can identify the company implied by a missing subject if
there is an explicit reference to it in the immediately preceding sentence (Doi et al.,
1993; Muraki et al., 1993). It is not clear whether veniex can resolve the missing
reference when the explicit reference appears in a sentence further separated from the
subjectless sentence.
2. Company name abbreviations
As is also seen in English, company names are often abbreviated in a Japanese text after their first appearance. A variety of ways to abbreviate company names in Japanese
is given in (Karasawa, 1993). The following examples show some typical abbreviations
of Japanese company names:
(a) a partial word
\ AK' 9S$" ! \ 9S$ "
(Mercedes-Benz)
(Benz)
(b) an English abbreviation
\ o%*NTT+ " ! \ NTT "
(Nippon Telegraph and Telephone)
(c) the first Katakana character + \  "
\ AJffS7L " ! \  "
(American Express Corp.)
92

fiPattern Matching and Discourse Processing
(d) the first character of each primitive segment
\o %   " ! \ o "1
(Japan Airlines)
(e) some randomly selected characters
\o % " ! \ o "
(Shin-nihon Steel)
Locating company name abbreviations is dicult, since many are not identified as
companies by either a morphological analyzer or the name recognizer in the preprocessor. Another problem is that the variety of ways of abbreviating names makes it
dicult to unify multiple references to one company.
Almost all muc-5 systems include a string matching mechanism to identify company name abbreviations. These abbreviations are specified in an aliases slot in the
company entity object. To the authors' knowledge, none of the systems other than
textract can detect company name abbreviations of type (d) or (e) above without
using a pre-defined abbreviation table.
3. Company name pronouns
Company name pronouns are often used in formal texts. Frequently used expressions
include \ ! " (ryosya: both companies), \ $ " (dosya: the company), and \ r
 " (jisya: the company itself). As shown in the following examples, resolving the
references is particularly important for full understanding of a text. Direct English
translation follows the Japanese sentences.
(a) \ X/Y( $ .WR r 6IS)'K "

*Y+

*X+

\X Corp. has tied up with Y Corp. and sells products of the company by its own
brand name."
(Y Corp.) (X Corp.)
(b) \ X/.'/ $ .p/NJ "

*X+

\X Corp. is the biggest company in this field. The president of the company is
Mr. Suzuki."
(X Corp.)
Reference resolution for \ $ " (dosya: the company) is implemented in veniex (Doi
et al., 1993). veniex resolves the pronominal reference in the same way as it identifies
missing company references. The crl/brandeis diderot system presented at muc5 simply chooses the nearest company name as the referent of \dosya". This algorithm
was later improved by Wakao using corpus-based heuristic knowledge (Wakao, 1994).
These systems do not handle pronominalized company names other than \dosya".
The three problems described in this section often cause individual information to be
correlated with the wrong company or tie-up-relationship object. To avoid this error, the
topic companies must be tracked from the context, since they can be used to determine
which company objects an information fragment should be assigned to. Abbreviated and
pronominalized company names must be unified as references to the same company.
1. \ o% " (nihon: Japan) and \  " (koukuu: airlines) are the primitive segments in this example.
93

fiKitani, Eriguchi, & Hara

3.3 Discourse segmentation and concept merging

In the joint ventures domain, a tie-up-relationship object contains pointers to other objects
such as economic activities (as shown in Figure 1). When a company is involved in multiple tie-ups, merging information into a tie-up relationship according to topic companies
sometimes yields incorrect results. Consider the following example:
"X Corp. has tied up with Y Corp. X will start selling products
in Japan next month. Last year X started a similar joint venture
with Z Inc."

Obviously, the sale in the second sentence is related to the tie-up relationship of X and
Y. However, since the topic company, which is the subject of a sentence, is X in all three
sentences, the sale could also be related to the X and Z tie-up relationship. This incorrect
merging can be avoided by separating the text into two blocks: the first two sentences
describe the X and Y tie-up, and the last sentence describes the X and Z tie-up. Thus,
discourse segmentation is necessary to identify portions of text containing related pieces
of information. The crl/brandeis diderot system segments the joint ventures text into
two types of text structures (Cowie et al., 1993). It is not known how well their discourse
segmentation performed, however.
Once the text is segmented, concepts or identified pieces of information can be merged
within the same discourse segment. For example, the expected income from a joint venture
is often stated in a sentence which does not explicitly mention the participating companies;
they appear in the previous sentence. In this case, the joint venture concept identifying the
companies and the income concept identifying the expected income must be merged so that
the latter will be linked to the correct entity objects.
4. The solution

This section describes details of textract's pattern matcher and discourse processor as
well as the system architecture.

4.1

textract architecture
textract is an information extraction system developed for the tipster Japanese do-

mains of corporate joint ventures and microelectronics (Jacobs, 1993; Jacobs et al., 1993).
As shown in Figure 2, the textract joint ventures system comprises four major components: preprocessor, pattern matcher, discourse processor, and template generator. Because
of its shorter development time, the textract microelectronics system has a simpler configuration than the joint ventures system. It does not include the template pattern search
in the pattern matcher, or the discourse segmentation and concept merging in the discourse
processor, as also shown in Figure 2.
In the preprocessor, a Japanese segmentor called majesty segments Japanese text into
primitive words tagged with their parts of speech (Kitani, 1991). Next, the name recognizer
identifies proper names and monetary, numeric, and temporal expressions. majesty tags
proper names which appear in its lexicon; the name recognizer identifies additional proper
names by locating name designators such as \  " (sya, corresponding to \Inc." or \Corp.")
94

fiPattern Matching and Discourse Processing

Pattern matcher
Preprocessor

concept
search

template
pattern
search

- concept
- concept
identification
identification
- information
merging within
a sentence

- morphological
analysis
- name
recognition

Discourse processor
company
discourse
concept
name
segmentamerging
unification
tion
- company
name
reference
resolution

- information
- text
segmentation merging
within a text

joint ventures
system only

Template
generator
- output
generation

Figure 2: textract system architecture
for company names. The recognizer extends the name string forward and backward from
the designator until it meets search stop conditions (Kitani & Mitamura, 1993). The name
segments are grouped into units which are meaningful to the pattern matching process
(Kitani & Mitamura, 1994). Most strings to be extracted directly from the text are identified
by majesty and the name recognizer.
Details of the pattern matcher and discourse processor are given in the following sections. The template generator assembles the extracted information and creates the output
described in Section 2.

4.2 Pattern matcher

The following subsections describe the concept search and the template pattern search in
the pattern matcher which identify concepts in the sentence. Whereas the former simply
searches for key words, the latter searches for phrasal patterns within a sentence. The
template pattern search also identifies relationships between matched objects in the defined
pattern. In the course of textract development, key words and template patterns were
obtained manually by a system developer using a kwic (Key Word In Context) tool and
referring to a word frequency list obtained from the corpus.
4.2.1 Concept search

Key words representing the same concept are grouped into a list and used to recognize the
concept in a sentence. The list is written in a simple format: (concept-name word1 word2
...). For example, key words for recognizing a dissolved joint venture concept can be written
in the following way:
95

fiKitani, Eriguchi, & Hara
(DISSOLVED

F  Fn)

or
(DISSOLVED dissolve terminate cancel).

The concept search module recognizes a concept when it locates one of the associated
words in a sentence. This simple procedure sometimes yields incorrect concepts. For example, the concept \dissolved" is erroneously identified from an expression such as \cancel a
hotel reservation". Key-word-based concept search is most successful when processing text
in a narrow domain in which words are used with restricted meanings.
The under-matching problem occurs when a compound noun in the key word list of a
concept fails to match the text because the instance of the compound in the text has been
segmented into separate primitive words. To avoid the problem, adjacent nouns in the text
are automatically concatenated during the concept search process, generating compound
nouns at run-time. The over-matching problem, on the other hand, arises when a key word
successfully matches part of a compound noun which as a whole is not associated with
the concept. Over-matching can be prevented by anchoring the beginning and/or end of a
key word pattern to word boundaries (with the symbol \>" at the beginning and \<" at
the end). For example, \> JS <" (silicon) must be matched against a single complete
word in the text. Since this problem is rare, its solution is not automatic: system developers
attach anchors to key words which are likely to over-match.
4.2.2 Template pattern search
textract's pattern matcher is implemented as a finite-state recognizer. This choice of

implementation is based on the assumption that a finite-state grammar can eciently handle
many of the inputs that a context-free grammar covers (Pereira, 1990). The pattern matcher
is similar to the pattern recognizer used in the muc-4 fastus system developed at sri
(Hobbs et al., 1992).
Patterns for the textract template pattern matcher are defined with rules similar
to regular expressions. Each pattern definition specifies the concept associated with the
pattern. (For the joint ventures domain, textract uses eighteen concepts.)
In the matcher, state transitions are driven by segmented words or grouped units from
the preprocessor. The matcher identifies all possible patterns of interest in the text that
match defined patterns, recognizing the concepts associated with the patterns. For some
inputs, the matcher must skip words that are not explicitly defined in the pattern.
Figure 3 shows definitions of equivalent Japanese and English patterns for recognizing
the concept *joint-venture*. This English pattern is used to capture expressions such
as \XYZ Corp. created a joint venture with PQR Inc." The notation \@string" represents
a variable matching an arbitrary string. Variables whose names begin with \@cname"
are called company-name variables and are used where a company name is expected to
appear. In the definitions shown, a string matched by \@cname partner subj" is likely
to contain at least one company name referring to a joint venture partner and functioning
as the subject in a sentence.
The pattern \ /#fi:strict:P" matches the grammatical particles \ / " (wa ) and \ fi "
(ga ), which serve as subject case markers. The symbol \strict" specifies a full string match
(the default in case of template pattern search), whereas \loose" allows a partial string
96

fiPattern Matching and Discourse Processing
(a)

(JointVenture1 6
@CNAME_PARTNER_SUBJ
/#fi:strict:P
@CNAME_PARTNER_WITH
(:strict:P
@SKIP
:loose:VN)

(b)

(JointVenture1 3
@CNAME_PARTNER_SUBJ
create::V
a joint venture::NP
with::P
@CNAME_PARTNER_WITH)

Figure 3: A matching pattern for (a) Japanese and (b) English

match. Partial string matching is useful for matching a defined pattern to compound words.
The verbal nominal pattern \ : loose:VN" matches compound words such as \ [ "
(kigyo-teikei: a corporate joint venture) as well as \  " (teikei: a joint venture).
The first field in a pattern is the pattern name, which refers to the concept associated
with the pattern. The second field is a number indexing a field in the pattern. This field's
contents are used to decide quickly whether or not to search within a given string. The
matcher only applies the entire pattern to a string when the string contains the text in
the indexed field. For eciency, therefore, this field should contain the least frequent word
in the entire pattern (in this case, \  " (teikei) for Japanese and \a joint venture" for
English).
The order of noun phrases is relatively unconstrained in a Japanese sentence. Case
markers, usually attached to the ends of noun phrases, provide a strong clue for identifying
the case role of each phrase (subject, object, etc.). Thus pattern matching driven mainly
by case markers recognizes the case roles well without parsing the sentence.
Approximately 150 patterns are used to extract various concepts in the Japanese joint
ventures domain. Several patterns usually match a single sentence. Moreover, since patterns
are often defined with case markers such as \ / " (wa), \ fi " (ga), and \ ( " (to), a single
pattern can match a sentence in more than one way when several of the same case markers
appear in the sentence. The template generator accepts only the best matched pattern,
which is chosen by applying the following three heuristic rules in the order shown:
1. select patterns that include the largest number of matched company-name variables
containing at least one company name;
2. select patterns that consume the fewest input segments (the shortest string match);
and
3. select patterns that include the largest number of variables and defined words.
These heuristic rules were obtained from an examination of matched patterns reported
by the system. To obtain more reliable heuristics, a large-scale statistical evaluation must
be performed. Heuristics for a similar problem of pattern selection in English are discussed
in (Rau & Jacobs, 1991). Their system chooses the pattern which consumes the most input
segments (the longest string match), as opposed to textract's choice of the shortest string
match in its second heuristic rule.2
2. In Rau and Jacobs' system, the third heuristic rule seems to be applied before the second rule. In this
case, there should be little difference in performance between the heuristic rules of the two systems.
97

fiKitani, Eriguchi, & Hara
Another important feature of the pattern matcher is that rules can be grouped according
to their concept. The rule name \JointVenture1" in Figure 3, for example, represents
the concept *joint-venture*. Using this grouping, the best matched pattern can be
selected from matched patterns of a particular concept group instead of from all the matched
patterns. This feature enables the discourse and template generation processes to narrow
their search for the best information to fill a particular slot.
4.3 Discourse processor

The following subsections describe the algorithm of company name reference resolution
throughout the discourse. Discourse segmentation and concept merging processes are also
discussed.
4.3.1 Identifying topic companies

Since no syntactic analysis is performed in textract, topic companies are simply identified wherever a subject case marker such as \ fi " (ga), \ / " (wa), or \ B " (mo) follows
company names. If no topic companies are found in a sentence, the previous sentence's
topic companies are inherited (even if the current sentence contains a non-company subject). This is based on the supposition that a sentence which introduces new companies
usually mentions them explicitly in its subject.
4.3.2 Abbreviation detection and unification

Company name abbreviations have the following observed characteristics:


majesty tags most abbreviations as \unknown", \company", \person", or \place";



a company name precedes its abbreviations;
an abbreviation is composed of two or more characters from the company name, in
their original order;





the characters need not be consecutive within the company name; and
English word abbreviations must be identical with an English word appearing in the
company name.

Thus the following are regarded as abbreviations: \unknown", \company", \person",
and \place" segments composed of two or more characters which also appear in company
names previously identified in the text. When comparing possible abbreviations against
known company names, the length of the longest common subsequence or LCS (Wagner &
Fischer, 1974) is computed to determine the maximum number of characters appearing in
the same order in both strings.3
To unify multiple references to the same company, a unique number is assigned to
the source and abbreviated companies. Repeated company names which contain strings
appearing earlier in the text are treated as abbreviations (and thus given unique numbers)
3. For example, the LCS of \abacbba" and \bcda" is \bca".
98

fiPattern Matching and Discourse Processing
1. Step 1: Initialization to assign each entity in C a unique number.
for i in C do (1  i  cmax)
C [i; \id"] i
done
2. Step 2: Search abbreviations and give unique numbers
for i in C do (1  i  cmax)
if C [i; \id"] 6= i then
# already recognized as an abbreviation
continue i loop
LENSRC length of C [i; \string"]
for j in C do (i + 1  j  cmax)
if C [j; \id"] 6= j then
# already recognized as an abbreviation
continue j loop
LEN length of C [j; \string"]
LCS length of the LCS of C [i; \string"] and C [j; \string"]
if LCS  2 then do
if C [i; \eg"] = \YES" and LENSRC = LCS = LEN then
C[j; \id"] C [i; \id"] # an English word abbreviation
else if C [i; \eg"] = \NO" and LCS = LEN then
# an abbreviation
C[j; \id"] C [i; \id"]
done
done
done
Figure 4: Algorithm to unify multiple references to the same company
by the algorithm described in Figure 4. In the pseudocode shown, all identified company
names are stored in an associative array named C . \Unknown", \company", \person", and
\place" segments are also stored in the array as possible abbreviations. Company names are
sorted in ascending order of their starting position in the text and numbered from 1 to cmax
(Step 1). A company name string which is indexed i can be addressed by C [i; \string"]. A
ag C [i; \eg"] records whether the company name is an English word abbreviation or not.
Step 2 compares each company name in the array C with all names higher in the array
(and thus later in the text). When the LCS of a pair of earlier and later company names
is equal to the length of the later company name, the later company name is recognized as
an abbreviation of the earlier company name. Then, the \id" of the later company name is
replaced with that of the earlier company name. The LCS must be two or more characters,
and if the abbreviation is an English word, the LCS must be equal to the length of the
earlier company name.
At the end of execution, a number is given in C [i; \id"]. If C [i; \id"] was changed during
execution, C [i; \string"] was recognized as a company name abbreviation.
99

fiKitani, Eriguchi, & Hara
4.3.3 Anaphora resolution of company name pronouns

The approach for reference resolution described in this section is based on heuristics obtained
by corpus analysis rather than linguistic theories. Three company name pronouns are the
target of reference resolution: \ ! " (ryosya), \ $ " (dosya), and \ r " (jisya), meaning
\both companies", \the company", and \the company itself". They are three of the most
frequent company name pronouns appearing in our corpus provided by arpa for the tipster
information extraction project. \Ryosya", \dosya", and \jisya" appeared 456, 277, and 129
times, respectively, in 1100 newspaper articles containing an average of 481 characters per
article.
The following heuristics, derived from analysis of pronoun reference in the corpus, were
used for reference resolution:






\ryosya" almost always referred to the \current" tie-up company, with one exception
in a hundred occurrences;
about ninety percent of \dosya" occurrences referred to the topic company when there
was only one possible referent in the same sentence, but:
when more than two companies, including the topic company, preceded \dosya" in
the same sentence, about seventy-five percent of the pronoun occurrences referred to
the nearest company, not necessarily the topic company; and
about eighty percent of \jisya" occurrences referred to the topic company.

Two additional heuristic rules were discovered but not implemented in textract:
 about four percent of \jisya" occurrences referred to more than one company; and
 about eight percent of \jisya" occurrences referred to entities which are general expressions about a company such as \ fi " (kaisya: a company).
As a result of the discourse processing described above, every company name, including
abbreviations and pronominal references, is given a unique number.
4.3.4 Discourse segmentation and concept merging
In the 150 articles of the tipster/muc-5 joint ventures test set, multiple tie-up relationships

appeared in thirty-one articles which included ninety individual tie-up relationships. The
two typical discourse models representing the discourse structures of tie-up relationships
are shown in Figure 5.




Type-I: tie-ups are described sequentially
Descriptions of tie-ups appear sequentially in this model. One tie-up is not mentioned
again after a new tie-up has been described.
Type-II: a main tie-up reappears after other tie-ups are mentioned
A major difference from the Type-I model is that a description of a main tie-up
reappears in the text after other tie-up relationships have been introduced. Non-main
tie-ups are usually mentioned briey.
100

fiPattern Matching and Discourse Processing

tie-up-1

tie-up-1

tie-up-2

tie-up-2
.
.non-main tie-ups
.

tie-up-3
.
.
.

tie-up-n

tie-up-n

tie-up-1

Type-I

Type-II

Figure 5: Discourse structure of tie-up relationships
Eleven Type-I structures and thirteen Type-II structures appeared in the thirty-one articles. Seven of the articles contained complicated discourse structures regarding the tie-up
relationships.
The two types of text structure described above are similar to the ones implemented in
the crl/brandeis diderot joint ventures system. The difference is only in the Type-II
structure: diderot processes all tie-up relationships which reappear in the text, not just
the reappearing main tie-up focused on by textract.
textract's discourse processor divides the text when a different tie-up relationship is
identified by the template pattern search. A different tie-up relationship is recognized when
the numbers assigned to the joint venture companies are not identical to those appearing in
the previous tie-up relationships. diderot segments the discourse if any other related pieces
of information such as date and entity location are different between the tie-up relationships.
Such strict merging is preferable when the pieces of information in comparison are correctly
identified. The merging conditions of discourse segments should be chosen according to the
accuracy of identification of the information to be compared.
After the discourse is segmented, identified concepts and extracted words and phrases
are merged. Figure 6 shows the merging process for the following text passage which actually
appeared in the tipster/muc-5 test set (a direct English translation follows):
\ /8o;.DAffAK..o%U'.$

RKRS .fi'KH+*K56'+/!
fiZ&fiRfiK(B4 "

\On the eighth (of this month), Tanabe Pharmaceuticals made a joint
venture contract with a German pharmaceutical maker, Merck and Co.
Inc., to develop and sell its new medicine in Japan. They also agreed that
both companies would invest equally to establish a joint venture company
in five or six years when they start selling new medicine."
101

fiKitani, Eriguchi, & Hara

First sentence:
"On the eighth (of this month),
Tanabe Pharmaceuticals made
a joint venture contract with a
German pharmaceutical maker,
Merck and Co. Inc., to develop
and sell its new medicine in
Japan."

Second sentence:
"They also agreed that both
companies would invest equally
to establish a joint venture
company in five or six years when
they start selling new medicine."

"Tanabe Pharmaceuticals"
Template
pattern
search

*ESTABLISH*
"a joint venture
"both
company"
companies"

*ECONOMICACTIVITY*
"Merck and Co. Inc."

"Tanabe Pharmaceuticals"
Discourse
processor

"both
companies"

*ECONOMICACTIVITY*

*ESTABLISH*

"a joint venture
company"

"Merck and Co. Inc."

Figure 6: Example of concept merging
The two company names in the first sentence, \  " (tanabe seiyaku: Tanabe
Pharmaceuticals) and \ AK " (ei meruku sya: Merck and Co. Inc.), are identified
by either majesty or the name recognizer during preprocessing. Next, the template pattern
search locates in the first sentence the \economic activity" pattern shown in Figure 7 (a).
The *economic-activity* concept relating the two companies has now been recognized.
The template pattern search also recognizes the *establish* concept in the second sentence
by the template pattern shown in Figure 7 (b).
After sentence-level processing, discourse processing recognizes that \ ! " (ryosya:
both companies) in the second sentence refers to Tanabe Pharmaceuticals and Merck in
the first sentence because they are the current tie-up companies. Since the second sentence
does not introduce a new tie-up relationship, both sentences are in the same discourse
segment. Concepts separately identified in the two sentences can now be merged because
the subjects of the two sentences are the same. The *establish* concept is therefore joined
to the *economic-activity* concept.
(a)

(EconomicActivityE 6
@CNAME_PARTNER_SUBJ
:strict:P
@CNAME_PARTNER_SUBJ
:strict:P
@SKIP
:loose:VN)

(b)

(Establish3 6
@CNAME_PARTNER_SUBJ
:strict:P
@CNAME_CREATED_OBJ
:strict:P
@SKIP
:loose:VN)

/#fi
R
fi

/#fi
.
$

Figure 7: Economic activity pattern (a) and establish pattern (b)
102

fiPattern Matching and Discourse Processing

5. Performance evaluation
This section shows some evaluation results for textract's discourse module. muc-5 evaluation metrics and overall textract performance are also discussed.

5.1 Unique identification of company name abbreviations
A hundred joint ventures newspaper articles used for the tipster 18-month evaluation
were chosen as a blind test set for this evaluation. The evaluation measures were recall,
the percentage of correct answers extracted compared to possible answers, and precision,
the percentage of correct answers extracted compared to actual answers. majesty and
the name recognizer identified company names in the evaluation set with recall of seventyfive percent and precision of ninety-five percent when partial matches between expected
and recognized strings were allowed, and with recall of sixty-nine percent and precision of
eighty-seven percent in an exact matching condition.
Company names that appeared in a form different from their first appearance in an
article were considered to be company name abbreviations. Among 318 abbreviations, the
recall and precision of abbreviation detection were sixty-seven and eighty-nine percent, respectively. Most importantly, detected abbreviations were unified correctly with the source
companies as long as the source companies were identified correctly by majesty and the
name recognizer.
The evaluation results clearly show that company name abbreviations were accurately
detected and unified with the source companies as long as company names were correctly
identified by the preceding processes. It is possible, however, that the simple string matching
algorithm currently used could erroneously unify similar company names, which are often
seen among family companies.

5.2 Anaphora resolution of company name pronouns
The accuracy of reference resolution for \ryosya", \dosya", and \jisya" is shown in Table
1. The numbers in parentheses were obtained by restricting attention to pronouns which
referred to companies identified correctly by the preceding processes. Since companies
referred to by \ryosya" (both companies) were usually \current" tie-up companies in the
joint ventures domain, reference resolution accuracy depended on the accuracy with which
tie-up relationships were identified.
company name pronouns

number of
references
\ ! " (ryosya: both companies) 101 (93)
\ $ " (dosya: the company)
100 (90)
\ r " (jisya: the company itself) 60 (53)

resolution
accuracy
64% (70%)
78% (87%)
78% (89%)

Table 1: Accuracy of reference resolutions
103

fiKitani, Eriguchi, & Hara
A major cause of incorrect references of \dosya" was the failure to locate topic companies. The simple mechanism of searching for topic companies using case markers did not
work well. A typical problem can be seen in the following example: \ '/X " (A
joint venture partner is X Corp.). Here X Corp is a topic company, but the subject \ X "
(X Corp.) is not followed by a subject case marker. Other errors can be attributed to the
fact that \dosya" did not always refer to a topic company as discussed in the heuristic rules
of \dosya" reference resolution.
Regarding \jisya" resolutions, five instances which should have referred to multiple
companies were bound to a single company. Since multiple companies are usually listed
using conjunctions such as \ ( " (to: and) and \ " (comma), they can be identified easily
if a simple phrase analysis is performed.
It became clear from this evaluation that resolving \dosya" references to a non-topic
company required intensive text understanding. Forty-seven percent of the occurrences of
\dosya" and \jisya" were bound to topic companies inherited from a previous sentence. This
result strongly supported the importance of keeping track of topic companies throughout
the discourse.

5.3 Discourse segmentation
Thirty-one of the 150 tipster/muc-5 evaluation test articles included ninety multiple tieup relationships. textract's discourse processor segmented the thirty-one articles into
seventy-one individual tie-up relationship blocks. Only thirty-eight of the blocks were correctly segmented. Main tie-up relationships which reappeared in Type-II discourse structures were not detected well, which caused the structures to be incorrectly recognized as
Type-I. This error was caused by the fact that the joint venture relationships were usually mentioned implicitly when they reappeared in the text. For example, a noun phrase,
\ ./ " (the joint venture this time), which was not detected by the template patterns used, brought the focus back to the main tie-up. As a result, textract identified eight
percent fewer tie-up relationships than the possible number expected in the tipster/muc-5
evaluation. This merging error must have affected system performance since the information in the reappearing main tie-up segment would not have been correctly linked to the
earlier main tie-up segment.
This preliminary study suggested that recognizing segmentation points in the text should
be regarded as crucial for performance. The template pattern matching alone was not good
enough to recognize the segmentation points. The discourse processor simply segmented
the text when it found a new tie-up relationship. The discourse models, currently unused at
run-time in textract, could be used to help infer the discourse structure when the system
is not sure whether to merge or separate discourse segments. Reference resolution of definite
and indefinite noun phrases must also be solved for accurate discourse segmentation in future
research.
The accuracy of discourse segmentation might be improved by checking the difference or
identity of date and entity location, as well as entity name, when deciding whether or not to
merge a tie-up relationship. textract did not take date and location objects into account
in making segmentation decisions, because textract's identification of these objects was
not considered reliable enough. For example, the date object was identified with recall of
104

fiPattern Matching and Discourse Processing
only twenty-seven percent and precision of fifty-nine percent. On the other hand, entities
were identified with over eighty percent accuracy in both recall and precision. To avoid
incorrect discourse segmentation, therefore, textract's merging conditions included only
entity names as reliable information.

5.4 Overall textract performance

250 newspaper articles, 150 about Japanese corporate joint ventures and 100 about Japanese
microelectronics, were provided by arpa for use in the tipster/muc-5 system evaluation.
Six joint ventures systems and five microelectronics systems, including textract developed at cmu as an optional system of ge-cmu shogun, were presented in the Japanese
system evaluation at muc-5. A scoring program automatically compared the system output
with answer templates created by human analysts. When a human decision was necessary,
analysts instructed the scoring program whether the two strings in comparison were completely matched, partially matched, or unmatched. Finally, the scoring program calculated
an overall score combined from all the newspaper article scores. Although various evaluation metrics were measured in the evaluation (Chinchor & Sundheim, 1993), only the
following error-based and recall-precision-based metrics are discussed in this paper. The
basic scoring categories used are: correct (COR), partially correct (PAR), incorrect (INC),
missing (MIS), and spurious (SPU), counted as the number of pieces of information in the
system output compared to the possible information.
(1) Error-based metrics
 Error per response fill (ERR):
wrong = INC + P AR=2 + MIS + SPU
total COR + PAR + INC + MIS + SP U


Undergeneration (UND):

MIS
MIS =
possible COR + PAR + INC + MIS


Overgeneration (OVG):

SPU =
SPU
actual COR + P AR + INC + SP U


Substitution (SUB):

INC + P AR=2
COR + P AR + INC

105

fiKitani, Eriguchi, & Hara

domain
ERR UND OVG SUB REC PRE P&R
textract (JJV)
50
32
23
12
60
68 63.8
System A (JJV)
54
36
27
12
57
64 60.1
System B (JJV)
63
51
23
12
42
67 52.1
textract (JME) 59
43
28
12
51
63 56.4
System A (JME)
58
30
38
14
60
53 56.3
System B (JME)
65
54
24
12
40
66 50.4
Table 2: Scores of textract and two other top-ranking ocial systems in tipster/muc-5
(2) Recall-precision-based metrics


Recall (REC):



Precision (PRE):



P&R F-measure (P&R):

COR + PAR=2
possible
COR + PAR=2
actual

2  REC  P RE
REC + PRE
The error per response fill (ERR) was the ocial measure of muc-5 system performance.
Secondary evaluation metrics were undergeneration (UND), overgeneration (OVG), and
substitution (SUB). The recall, precision, and F-measure metrics were used as unocial
metrics for muc-5.
Table 2 shows scores of textract and two other top-ranking ocial systems taken
from the tipster/muc-5 system evaluation results.4 textract processed only Japanese
domains of corporate joint ventures (JJV) and microelectronics (JME), whereas the two
other systems processed both English and Japanese text. textract performed as well as
the top-ranking systems in the two Japanese domains.
The human performance of four well-trained analysts was reported to be about eighty
percent in both recall and precision in the English microelectronics domain (Will, 1993).
This is about thirty percent better than the best tipster/muc-5 systems' performance
in P&R F-measure in the same language domain. In the Japanese joint ventures domain,
textract scored recall of seventy-five percent and precision of eighty-one percent with
a core template comprising only essential objects. This result suggests that the current
technology could be used to support human extraction work if the task is well-constrained.
4. The textract scores submitted to muc-5 were unocial. It was scored ocially after the conference.
Table 2 shows textract's ocial scores.
106

fiPattern Matching and Discourse Processing
Running on a SUN SPARCstation IPX, textract processed a joint ventures article in
about sixty seconds and a microelectronics article in about twenty-four seconds on average.
The human analysts took about fifteen minutes to complete an English microelectronics
template and about sixty minutes for a Japanese joint ventures template (Will, 1993).
Thus a human-machine integrated system would be the best solution for fast, high quality,
information extraction.
Some tipster/muc-5 systems processed both Japanese and English domains. These
systems generally performed better in the Japanese domains than in the corresponding English domains. One likely reason is that the structure of Japanese articles is fairly standard,
particularly in the Japanese joint ventures domain, and can be readily analyzed into the
two discourse structure types described in this paper. Another possible reason is a characteristic of writing style: expressions which need to be identified tend to appear in the first
few sentences in a form suitable for pattern matching.
The textract Japanese microelectronics system copied the preprocessor, the concept
search of the pattern matcher, and the company name unification of the discourse processor
used in the textract Japanese joint ventures system. The microelectronics system was
developed in only three weeks by one person who replaced joint ventures concepts and key
words with representative microelectronics concepts and key words. The lower performance
of the textract microelectronics system compared to the joint ventures system is largely
due to the short development time. It is also probably due to the less homogeneous discourse
structure and writing style of the microelectronics articles.
6. Conclusions and future research

This paper has described the importance of discourse processing in three aspects of information extraction: identifying key information throughout the text, i.e. topic companies and
company name references in the tipster/muc-5 domains; segmenting the text to select relevant portions of interest; and merging concepts identified by the sentence level processing.
The basic performance of the system depends on the preprocessor, however, since many
pieces of identified information are put directly into slots or are otherwise used to fill slots
during later processing. textract's pattern matcher solves the matching problem caused
by the segmentation ambiguities often found in Japanese compound words. The pattern
matching system based on a finite-state automaton is simple and runs fast. These factors
are essential for rapid system development and performance improvement.
To improve system performance with the pattern matching architecture, an increase
in the number of patterns is unavoidable. Since matching a large number of patterns is
a lengthy process, an ecient pattern matcher is required to shorten the running time.
Tomita's new generalized LR parser, known to be one of the fastest parsers for practical
purposes, skips unnecessary words during parsing (Bates & Lavie, 1991). The parser is
under evaluation to investigate if it is appropriate for information extraction from Japanese
text (Eriguchi & Kitani, 1993). Pattern matching alone, however, will not be able to improve
the system performance to human levels in a complicated information extraction task such
as tipster/muc-5, even if the task is well-defined and suitable for pattern matching. More
efforts should be made in discourse processing such as discourse segmentation and reference
resolution for definite and indefinite noun phrases.
107

fiKitani, Eriguchi, & Hara
The research discussed in this paper is based on an application-oriented, domain-specific,
and language-specific approach relying on patterns and heuristic rules collected from a
particular corpus. It is obvious that the patterns and heuristic rules described in this paper
do not cover a wide range of applications, domains, or languages. The empirical approach
described here is worth investigating even for an entirely new task, however, since it can
achieve a high level of system performance in a relatively short development time. While
linguistic theory-based systems tend to become complex and dicult to maintain, especially
if they incorporate full text parsing, the simplicity of an empirically-based, pattern-oriented
system such as textract keeps the development time short and the evaluation cycle quick.
Corpus analysis is a key element in this corpus-based paradigm. It is estimated that
corpus analysis took about half of the development time for textract. Statistically-based
corpus analysis tools are necessary to obtain better performance in a shorter development
time. Such tools could help developers not only extract important patterns and heuristic
rules from the corpus, but also monitor the system performance during the evaluationimprovement cycle.

Acknowledgements

The authors wish to express their appreciation to Jaime Carbonell, who provided the opportunity to pursue this research at the Center for Machine Translation, Carnegie Mellon
University. Thanks are also due to Teruko Mitamura and Michael Mauldin for their many
helpful suggestions.
References

Bates, J., & Lavie, A. (1991). Recognizing Substrings of LR(k) Languages in Linear Time.
Tech. rep. CMU-CS-91-188, Carnegie Mellon University, School of Computer Science.
Chinchor, N., & Sundheim, B. (1993). MUC-5 Evaluation Metrics. In Proceedings of the
Fifth Message Understanding Conference (MUC-5), pp. 69{78.
Cowie, J., Guthrie, L., et al. (1993). CRL/BRANDEIS: Description of the Diderot System
as Used for MUC-5. In Proceedings of the Fifth Message Understanding Conference
(MUC-5), pp. 161{179.
Doi, S., Ando, S., & Muraki, K. (1993). Context Analysis in Information Extraction System
Based on Keywords and Text Structure. In Proceedings of the Forty-seventh Annual
Conference of IPSJ (in Japanese).
Eriguchi, Y., & Kitani, T. (1993). A Preliminary Study of Using Tomita's Generalized LR
Parser for Information Extraction. Unpublished paper, Center for Machine Translation, Carnegie Mellon University.
Fujii, H., & Croft, B. (1993). A Comparison of Indexing Techniques for Japanese Text Retrieval. In Proceedings of the Sixteenth Annual International ACM SIGIR Conference
on Research and Development in Information Retrieval, pp. 237{246.
Hirschman, L. (1992). An Adjunct Test for Discourse Processing in MUC-4. In Proceedings
of the Fourth Message Understanding Conference (MUC-4), pp. 67{77.
108

fiPattern Matching and Discourse Processing
Hobbs, J., Appelt, D., et al. (1992). FASTUS: A System for Extracting Information from
Natural-Language Text. Tech. rep. 519, SRI International.
Jacobs, P. (1993). TIPSTER/SHOGUN 18-Month Progress Report. In Notebook of TIPSTER 18-Month Meeting.
Jacobs, P., Krupka, G., et al. (1993). GE-CMU: Description of the Shogun System Used
for MUC-5. In Proceedings of the Fifth Message Understanding Conference (MUC-5),
pp. 109{120.
Karasawa, I. (1993). Detection of Company Name Abbreviations in Japanese Texts. Unpublished paper, Center for Machine Translation, Carnegie Mellon University.
Kitani, T. (1991). An OCR Post-processing Method for Handwritten Japanese Documents.
In Proceedings of Natural Language Processing Pacific Rim Symposium, pp. 38{45.
Kitani, T. (1994). Merging Information by Discourse Processing for Information Extraction.
In Proceedings of the Tenth IEEE Conference on Artificial Intelligence for Applications, pp. 412{418.
Kitani, T., & Mitamura, T. (1993). A Japanese Preprocessor for Syntactic and Semantic
Parsing. In Proceedings of the Ninth IEEE Conference on Artificial Intelligence for
Applications, pp. 86{92.
Kitani, T., & Mitamura, T. (1994). An Accurate Morphological Analysis and Proper Name
Identification for Japanese Text Processing. Journal of Information Processing Society
of Japan, 35 (3), 404{413.
Lehnert, W., McCarthy, J., et al. (1993). UMASS/HUGHES: Description of the CIRCUS
System Used for MUC-5. In Proceedings of the Fifth Message Understanding Conference (MUC-5), pp. 277{291.
Lehnert, W., & Sundheim, B. (1991). A Performance Evaluation of Text-Analysis Technologies. AI Magazine, Fall, 81{94.
Muraki, K., Doi, S., & Ando, S. (1993). NEC: Description of the VENIEX System as Used
for MUC-5. In Proceedings of the Fifth Message Understanding Conference (MUC-5),
pp. 147{159.
Onyshkevych, B. (1993). Technology Perspective. In Notebook of the Fifth Message Understanding Conference (MUC-5).
Pereira, F. (1990). Finite-State Approximations of Grammars. In Proceedings of DARPA
Speech and Natural Language Workshop, pp. 20{25.
Rau, L., & Jacobs, P. (1991). Creating Segmented Databases from Free Text for Text
Retrieval. In Proceedings of Fourteenth Annual International ACM/SIGIR Conference
on Research and Development in Information Retrieval, pp. 337{346.
Tipster (1992). Joint Venture Template Fill Rules. In Plenary Session Notebook of the
TIPSTER 12-Month Meeting.
109

fiKitani, Eriguchi, & Hara
Wagner, R., & Fischer, M. (1974). The String-to-String Correction Problem. Journal of
ACM, 21 (1), 168{173.
Wakao, T. (1994). Reference Resolution Using Semantic Patterns in Japanese Newspaper
Articles. In Proceedings of COLING 94, pp. 1133{1137.
Weischedel, R., Ayuso, D., et al. (1993). BBN: Description of the PLUM System as Used
for MUC-5. In Proceedings of the Fifth Message Understanding Conference (MUC-5),
pp. 93{107.
Will, C. (1993). Comparing Human and Machine Performance for Natural Language Information Extraction: Results for English Microelectronics from the MUC-5 Evaluation.
In Proceedings of the Fifth Message Understanding Conference (MUC-5), pp. 53{67.

110

fiJournal of Artificial Intelligence Research 2 (1995) 369-409

Submitted 10/94; published 3/95

Cost-Sensitive Classification: Empirical Evaluation
of a Hybrid Genetic Decision Tree Induction Algorithm
Peter D. Turney
Knowledge Systems Laboratory, Institute for Information Technology
National Research Council Canada, Ottawa, Ontario, Canada, K1A 0R6.

TURNEY@AI.IIT.NRC.CA

Abstract
This paper introduces ICET, a new algorithm for cost-sensitive classification. ICET
uses a genetic algorithm to evolve a population of biases for a decision tree induction algorithm. The fitness function of the genetic algorithm is the average cost of classification
when using the decision tree, including both the costs of tests (features, measurements) and
the costs of classification errors. ICET is compared here with three other algorithms for
cost-sensitive classification  EG2, CS-ID3, and IDX  and also with C4.5, which classifies without regard to cost. The five algorithms are evaluated empirically on five realworld medical datasets. Three sets of experiments are performed. The first set examines the
baseline performance of the five algorithms on the five datasets and establishes that ICET
performs significantly better than its competitors. The second set tests the robustness of
ICET under a variety of conditions and shows that ICET maintains its advantage. The third
set looks at ICETs search in bias space and discovers a way to improve the search.

1. Introduction
The prototypical example of the problem of cost-sensitive classification is medical diagnosis, where a doctor would like to balance the costs of various possible medical tests with the
expected benefits of the tests for the patient. There are several aspects to this problem: When
does the benefit of a test, in terms of more accurate diagnosis, justify the cost of the test?
When is it time to stop testing and make a commitment to a particular diagnosis? How much
time should be spent pondering these issues? Does an extensive examination of the various
possible sequences of tests yield a significant improvement over a simpler, heuristic choice
of tests? These are some of the questions investigated here.
The words cost, expense, and benefit are used in this paper in the broadest sense,
to include factors such as quality of life, in addition to economic or monetary cost. Cost is
domain-specific and is quantified in arbitrary units. It is assumed here that the costs of tests
are measured in the same units as the benefits of correct classification. Benefit is treated as
negative cost.
This paper introduces a new algorithm for cost-sensitive classification, called ICET
(Inexpensive Classification with Expensive Tests  pronounced iced tea). ICET uses a
genetic algorithm (Grefenstette, 1986) to evolve a population of biases for a decision tree
induction algorithm (a modified version of C4.5, Quinlan, 1992). The fitness function of the
genetic algorithm is the average cost of classification when using the decision tree, including
both the costs of tests (features, measurements) and the costs of classification errors. ICET
has the following features: (1) It is sensitive to test costs. (2) It is sensitive to classification
error costs. (3) It combines a greedy search heuristic with a genetic search algorithm. (4) It
can handle conditional costs, where the cost of one test is conditional on whether a second

 1995 National Research Council Canada. All rights reserved. Published by permission.

fiT URNEY

test has been selected yet. (5) It distinguishes tests with immediate results from tests with
delayed results.
The problem of cost-sensitive classification arises frequently. It is a problem in medical
diagnosis (Nez, 1988, 1991), robotics (Tan & Schlimmer, 1989, 1990; Tan, 1993), industrial production processes (Verdenius, 1991), communication network troubleshooting
(Lirov & Yue, 1991), machinery diagnosis (where the main cost is skilled labor), automated
testing of electronic equipment (where the main cost is time), and many other areas.
There are several machine learning algorithms that consider the costs of tests, such as
EG2 (Nez, 1988, 1991), CS-ID3 (Tan & Schlimmer, 1989, 1990; Tan, 1993), and IDX
(Norton, 1989). There are also several algorithms that consider the costs of classification
errors (Breiman et al., 1984; Friedman & Stuetzle, 1981; Hermans et al., 1974; Gordon &
Perlis, 1989; Pazzani et al., 1994; Provost, 1994; Provost & Buchanan, in press; Knoll et al.,
1994). However, there is very little work that considers both costs together.
There are good reasons for considering both the costs of tests and the costs of classification errors. An agent cannot rationally determine whether a test should be performed without
knowing the costs of correct and incorrect classification. An agent must balance the cost of
each test with the contribution of the test to accurate classification. The agent must also consider when further testing is not economically justified. It often happens that the benefits of
further testing are not worth the costs of the tests. This means that a cost must be assigned to
both the tests and the classification errors.
Another limitation of many existing cost-sensitive classification algorithms (EG2, CSID3) is that they use greedy heuristics, which select at each step whatever test contributes
most to accuracy and least to cost. A more sophisticated approach would evaluate the interactions among tests in a sequence of tests. A test that appears useful considered in isolation,
using a greedy heuristic, may not appear as useful when considered in combination with
other tests. Past work has demonstrated that more sophisticated algorithms can have superior
performance (Tcheng et al., 1989; Ragavan & Rendell, 1993; Norton, 1989; Schaffer, 1993;
Rymon, 1993; Seshu, 1989; Provost, 1994; Provost & Buchanan, in press).
Section 2 discusses why a decision tree is the natural form of knowledge representation
for classification with expensive tests and how we measure the average cost of classification
of a decision tree. Section 3 introduces the five algorithms that we examine here, C4.5
(Quinlan, 1992), EG2 (Nez, 1991), CS-ID3 (Tan & Schlimmer, 1989, 1990; Tan, 1993),
IDX (Norton, 1989), and ICET. The five algorithms are evaluated empirically on five realworld medical datasets. The datasets are discussed in detail in Appendix A. Section 4 presents three sets of experiments. The first set (Section 4.1) of experiments examines the baseline performance of the five algorithms on the five datasets and establishes that ICET
performs significantly better than its competitors for the given datasets. The second set (Section 4.2) tests the robustness of ICET under a variety of conditions and shows that ICET
maintains its advantage. The third set (Section 4.3) looks at ICETs search in bias space and
discovers a way to improve the search. We then discuss related work and future work in Section 5. We end with a summary of what we have learned with this research and a statement of
the general motivation for this type of research.

2. Cost-Sensitive Classification
This section first explains why a decision tree is the natural form of knowledge representation for classification with expensive tests. It then discusses how we measure the average
cost of classification of a decision tree. Our method for measuring average cost handles
370

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

aspects of the problem that are typically ignored. The method can be applied to any standard
classification decision tree, regardless of how the tree is generated. We end with a discussion
of the relation between cost and accuracy.
2.1

Decision Trees and Cost-Sensitive Classification

The decision trees used in decision theory (Pearl, 1988) are somewhat different from the
classification decision trees that are typically used in machine learning (Quinlan, 1992).
When we refer to decision trees in this paper, we mean the standard classification decision
trees of machine learning. The claims we make here about classification decision trees also
apply to decision theoretical decision trees, with some modification. A full discussion of
decision theoretical decision trees is outside of the scope of this paper.
The decision to do a test must be based on both the cost of tests and the cost of classification errors. If a test costs $10 and the maximum penalty for a classification error is $5, then
there is clearly no point in doing the test. On the other hand, if the penalty for a classification
error is $10,000, the test may be quite worthwhile, even if its information content is relatively low. Past work with algorithms that are sensitive to test costs (Nez, 1988, 1991;
Tan, 1993; Norton, 1989) has overlooked the importance of also considering the cost of classification errors.
When tests are inexpensive, relative to the cost of classification errors, it may be rational
to do all tests (i.e., measure all features; determine the values of all attributes) that seem possibly relevant. In this kind of situation, it is convenient to separate the selection of tests from
the process of making a classification. First we can decide on the set of tests that are relevant, then we can focus on the problem of learning to classify a case, using the results of
these tests. This is a common approach to classification in the machine learning literature.
Often a paper focuses on the problem of learning to classify a case, without any mention of
the decisions involved in selecting the set of relevant tests.1
When tests are expensive, relative to the cost of classification errors, it may be suboptimal to separate the selection of tests from the process of making a classification. We may be
able to achieve much lower costs by interleaving the two. First we choose a test, then we
examine the test result. The result of the test gives us information, which we can use to influence our choice for the next test. At some point, we decide that the cost of further tests is not
justified, so we stop testing and make a classification.
When the selection of tests is interleaved with classification in this way, a decision tree is
the natural form of representation. The root of the decision tree represents the first test that
we choose. The next level of the decision tree represents the next test that we choose. The
decision tree explicitly shows how the outcome of the first test determines the choice of the
second test. A leaf represents the point at which we decide to stop testing and make a classification.
Decision theory can be used to define what constitutes an optimal decision tree, given (1)
the costs of the tests, (2) the costs of classification errors, (3) the conditional probabilities of
test results, given sequences of prior test results, and (4) the conditional probabilities of
classes, given sequences of test results. However, searching for an optimal tree is infeasible
(Pearl, 1988). ICET was designed to find a good (but not necessarily optimal) tree, where
good is defined as better than the competition (i.e., IDX, CS-ID3, and EG2).
1. Not all papers are like this. Decision tree induction algorithms such as C4.5 (Quinlan, 1992) automatically
select relevant tests. Aha and Bankert (1994), among others, have used sequential test selection procedures in
conjunction with a supervised learning algorithm.

371

fiT URNEY

2.2

Calculating the Average Cost of Classification

In this section, we describe how we calculate the average cost of classification for a decision
tree, given a set of testing data. The method described here is applied uniformly to the decision trees generated by the five algorithms examined here (EG2, CS-ID3, IDX, C4.5, and
ICET). The method assumes only a standard classification decision tree (such as generated
by C4.5); it makes no assumptions about how the tree is generated. The purpose of the
method is to give a plausible estimate of the average cost that can be expected in a real-world
application of the decision tree.
We assume that the dataset has been split into a training set and a testing set. The
expected cost of classification is estimated by the average cost of classification for the testing set. The average cost of classification is calculated by dividing the total cost for the
whole testing set by the number of cases in the testing set. The total cost includes both the
costs of tests and the costs of classification errors. In the simplest case, we assume that we
can specify test costs simply by listing each test, paired with its corresponding cost. More
complex cases will be considered later in this section. We assume that we can specify the
costs of classification errors using a classification cost matrix.
Suppose there are c distinct classes. A classification cost matrix is a c  c matrix, where
the element C i, j is the cost of guessing that a case belongs in class i, when it actually
belongs in class j. We do not need to assume any constraints on this matrix, except that costs
are finite, real values. We allow negative costs, which can be interpreted as benefits. However, in the experiments reported here, we have restricted our attention to classification cost
matrices in which the diagonal elements are zero (we assume that correct classification has
no cost) and the off-diagonal elements are positive numbers. 2
To calculate the cost of a particular case, we follow its path down the decision tree. We
add up the cost of each test that is chosen (i.e., each test that occurs in the path from the root
to the leaf). If the same test appears twice, we only charge for the first occurrence of the test.
For example, one node in a path may say patient age is less than 10 years and another node
may say patient age is more than 5 years, but we only charge once for the cost of determining the patients age. The leaf of the tree specifies the trees guess for the class of the case.
Given the actual class of the case, we use the cost matrix to determine the cost of the trees
guess. This cost is added to the costs of the tests, to determine the total cost of classification
for the case.
This is the core of our method for calculating the average cost of classification of a decision tree. There are two additional elements to the method, for handling conditional test
costs and delayed test results.
We allow the cost of a test to be conditional on the choice of prior tests. Specifically, we
consider the case where a group of tests shares a common cost. For example, a set of blood
tests shares the common cost of collecting blood from the patient. This common cost is
charged only once, when the decision is made to do the first blood test. There is no charge
for collecting blood for the second blood test, since we may use the blood that was collected
for the first blood test. Thus the cost of a test in this group is conditional on whether another
member of the group has already been chosen.
Common costs appear frequently in testing. For example, in diagnosis of an aircraft
engine, a group of tests may share the common cost of removing the engine from the plane
2. This restriction seems reasonable as a starting point for exploring cost-sensitive classification. In future work,
we will investigate the effects of weakening the restriction.

372

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

and installing it in a test cell. In semiconductor manufacturing, a group of tests may share the
common cost of reserving a region on the silicon wafer for a special test structure. In image
recognition, a group of image processing algorithms may share a common preprocessing
algorithm. These examples show that a realistic assessment of the cost of using a decision
tree will frequently need to make allowances for conditional test costs.
It often happens that the result of a test is not available immediately. For example, a
medical doctor typically sends a blood test to a laboratory and gets the result the next day.
We allow a test to be labelled either immediate or delayed. If a test is delayed, we cannot
use its outcome to influence the choice of the next test. For example, if blood tests are
delayed, then we cannot allow the outcome of one blood test to play a role in the decision to
do a second blood test. We must make a commitment to doing (or not doing) the second
blood test before we know the results of the first blood test.
Delayed tests are relatively common. For example, many medical tests must be shipped
to a laboratory for analysis. In gas turbine engine diagnosis, the main fuel control is frequently shipped to a specialized company for diagnosis or repair. In any classification problem that requires multiple experts, one of the experts might not be immediately available.
We handle immediate tests in a decision tree as described above. We handle delayed tests
as follows. We follow the path of a case from the root of the decision tree to the appropriate
leaf. If we encounter a node, anywhere along this path, that is a delayed test, we are then
committed to performing all of the tests in the subtree that is rooted at this node. Since we
cannot make the decision to do tests below this node conditional on the outcome of the test at
this node, we must pledge to pay for all the tests that we might possibly need to perform,
from this point onwards in the decision tree.
Our method for handling delayed tests may seem a bit puzzling at first. The difficulty is
that a decision tree combines a method for selecting tests with a method for classifying
cases. When tests are delayed, we are forced to proceed in two phases. In the first phase, we
select tests. In the second phase, we collect test results and classify the case. For example, a
doctor collects blood from a patient and sends the blood to a laboratory. The doctor must tell
the laboratory what tests are to be done on the blood. The next day, the doctor gets the results
of the tests from the laboratory and then decides on the diagnosis of the patient. A decision
tree does not naturally handle a situation like this, where the selection of tests is isolated
from the classification of cases. In our method, in the first phase, the doctor uses the decision
tree to select the tests. As long as the tests are immediate, there is no problem. As soon as the
first delayed test is encountered, the doctor must select all the tests that might possibly be
needed in the second phase.3 That is, the doctor must select all the tests in the subtree rooted
at the first delayed test. In the second phase, when the test results arrive the next day, the
doctor will have all the information required to go from the root of the tree to a leaf, to make
a classification. The doctor must pay for all of the tests in the subtree, even though only the
tests along one branch of the subtree will actually be used. The doctor does not know in
advance which branch will actually be used, at the time when it is necessary to order the
blood tests. The laboratory that does the blood tests will naturally want the doctor to pay for
all the tests that were ordered, even if they are not all used in making the diagnosis.
In general, it makes sense to do all of the desired immediate tests before we do any of the
desired delayed tests, since the outcome of an immediate test can be used to influence the
decision to do a delayed test, but not vice versa. For example, a medical doctor will question
3. This is a simplification of the situation in the real world. A more realistic treatment of delayed tests is one of
the areas for future work (Section 5.2).

373

fiT URNEY

a patient (questions are immediate tests) before deciding what blood tests to order (blood
tests are delayed tests).4
When all of the tests are delayed (as they are in the BUPA data in Appendix A.1), we
must decide in advance (before we see any test results) what tests are to be performed. For a
given decision tree, the total cost of tests will be the same for all cases. In situations of this
type, the problem of minimizing cost simplifies to the problem of choosing the best subset of
the set of available tests (Aha and Bankert, 1994). The sequential order of the tests is no
longer important for reducing cost.
Let us consider a simple example to illustrate the method. Table 1 shows the test costs
for four tests. Two of the tests are immediate and two are delayed. The two delayed tests
share a common cost of $2.00. There are two classes, 0 and 1. Table 2 shows the classification cost matrix. Figure 1 shows a decision tree. Table 3 traces the path through the tree for a
particular case and shows how the cost is calculated. The first step is to do the test at the root
of the tree (test alpha). In the second step, we encounter a delayed test (delta), so we must
calculate the cost of the entire subtree rooted at this node. Note that epsilon only costs $8.00,
since we have already selected delta, and delta and epsilon have a common cost. In the third
step, we do test epsilon, but we do not need to pay, since we already paid in the second step.
In the fourth step, we guess the class of the case. Unfortunately, we guess incorrectly, so we
pay a penalty of $50.00.
Table 1: Test costs for a simple example.
Test

Group

Cost

Delayed

1

alpha

$5.00

no

2

beta

$10.00

no

3

delta

A

$7.00 if first test in group A,
$5.00 otherwise

yes

4

epsilon

A

$10.00 if first test in group A,
$8.00 otherwise

yes

Table 2: Classification costs for a simple example.
Actual Class

Guess Class

Cost

0

0

$0.00

0

1

$50.00

1

0

$50.00

1

1

$0.00

4. In the real world, there are many factors that can influence the sequence of tests, such as the length of the delay
and the probability that the delayed test will be needed. When we ignore these many factors and pay attention
only to the simplified model presented here, it makes sense to do all of the desired immediate tests before we
do any of the desired delayed tests. We do not know to what extent this actually occurs in the real world. One
complication is that medical doctors in most industrialized countries are not directly affected by the cost of the
tests they select. In fact, fear of law suits gives them incentive to order unnecessary tests.

374

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

alpha < 3
T

F

beta > 6
T

delta = 2
F

0

T

F

1
beta < 5
T

epsilon < 4
F

1

T

0

0

F

1

Figure 1: Decision tree for a simple example.

Table 3: Calculating the cost for a particular case.
Step

Action

Result

Cost

1

do alpha

alpha = 6

$5.00

2

do delta

delta = 3

$7.00 + $10.00 + $8.00 = $25.00

3

do epsilon

epsilon = 2

already paid, in step #2

4

guess class = 0

actual class = 1

$50.00

total cost

$80.00

In summary, this section presents a method for estimating the average cost of using a
given decision tree. The decision tree can be any standard classification decision tree; no
special assumptions are made about the tree; it does not matter how the tree was generated.
The method requires (1) a decision tree (Figure 1), (2) information on the calculation of test
costs (Table 1), (3) a classification cost matrix (Table 2), and (4) a set of testing data (Table
3). The method is (i) sensitive to the cost of tests, (ii) sensitive to the cost of classification
errors, (iii) capable of handling conditional test costs, and (iv) capable of handling delayed
tests. In the experiments reported in Section 4, this method is applied uniformly to all five
algorithms.
2.3

Cost and Accuracy

Our method for calculating cost does not explicitly deal with accuracy; however, we can
handle accuracy as a special case. If the test cost is set to $0.00 for all tests and the classification cost matrix is set to a positive constant value k when the guess class i does not equal
the actual class j, but it is set to $0.00 when i equals j, then the average total cost of using the
decision tree is pk , where p  [0,1] is the frequency of errors on the testing dataset and
375

fiT URNEY

100 ( 1  p ) is the percentage accuracy on the testing dataset. Thus there is a linear relationship between average total cost and percentage accuracy, in this situation.
More generally, let C be a classification cost matrix that has cost x on the diagonal,
C i, i = x , and cost y off the diagonal, ( i  j )  ( C i, j = y ) , where x is less than y, x < y . We
will call this type of classification cost matrix a simple classification cost matrix. A cost
matrix that is not simple will be called a complex classification cost matrix.5 When we have
a simple cost matrix and test costs are zero (equivalently, test costs are ignored), minimizing
cost is exactly equivalent to maximizing accuracy.
It follows from this that an algorithm that is sensitive to misclassification error costs but
ignores test costs (Breiman et al., 1984; Friedman & Stuetzle, 1981; Hermans et al., 1974;
Gordon & Perlis, 1989; Pazzani et al., 1994; Provost, 1994; Provost & Buchanan, in press;
Knoll et al., 1994) will only be interesting when we have a complex cost matrix. If we have
a simple cost matrix, an algorithm such as CART (Breiman et al., 1984) that is sensitive to
misclassification error cost has no advantage over an algorithm such as C4.5 (Quinlan, 1992)
that maximizes accuracy (assuming other differences between these two algorithms are negligible). Most of the experiments in this paper use a simple cost matrix (the only exception is
Section 4.2.3). Therefore we focus on comparison of ICET with algorithms that are sensitive
to test cost (IDX, CS-ID3, and EG2). In future work, we will examine complex cost matrices
and compare ICET with algorithms that are sensitive to misclassification error cost.
It is difficult to find information on the costs of misclassification errors in medical practice, but it seems likely that a complex cost matrix is more appropriate than a simple cost
matrix for most medical applications. This paper focuses on simple cost matrices because, as
a research strategy, it seems wise to start with the simple cases before we attempt the complex cases.
Provost (Provost, 1994; Provost & Buchanan, in press) combines accuracy and classification error cost using the following formula:
score = A  accuracy  B  cost

(1)

In this formula, A and B are arbitrary weights that the user can set for a particular application. Both accuracy and cost, as defined by Provost (Provost, 1994; Provost & Buchanan, in press), can be represented using classification cost matrices. We can represent
accuracy using any simple cost matrix. In interesting applications, cost will be represented by a complex cost matrix. Thus score is a weighted sum of two classification cost
matrices, which means that score is itself a classification cost matrix. This shows that
equation (1) can be handled as a special case of the method presented here. There is no loss
of information in this translation of Provosts formula into a cost matrix. This does not mean
that all criteria can be represented as costs. An example of a criterion that cannot be represented as a cost is stability (Turney, in press).

3. Algorithms
This section discusses the algorithms used in this paper: C4.5 (Quinlan, 1992), EG2 (Nez,
1991), CS-ID3 (Tan & Schlimmer, 1989, 1990; Tan, 1993), IDX (Norton, 1989), and ICET.

5. We will occasionally say simple cost matrix or complex cost matrix. This should not cause confusion,
since test costs are not represented with a matrix.

376

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

3.1

C4.5

C4.5 (Quinlan, 1992) builds a decision tree using the standard TDIDT (top-down induction
of decision trees) approach, recursively partitioning the data into smaller subsets, based on
the value of an attribute. At each step in the construction of the decision tree, C4.5 selects
the attribute that maximizes the information gain ratio. The induced decision tree is pruned
using pessimistic error estimation (Quinlan, 1992). There are several parameters that can be
adjusted to alter the behavior of C4.5. In our experiments with C4.5, we used the default settings for all parameters. We used the C4.5 source code that is distributed with (Quinlan,
1992).
3.2

EG2

EG2 (Nez, 1991) is a TDIDT algorithm that uses the Information Cost Function (ICF)
(Nez, 1991) for selection of attributes. ICF selects attributes based on both their information gain and their cost. We implemented EG2 by modifying the C4.5 source code so that
ICF was used instead of information gain ratio.
ICF for the i-th attribute, ICF i , is defined as follows:6
I i

2 1
ICF i = ------------------------
( Ci + 1)

where 0    1

(2)

In this equation, I i is the information gain associated with the i-th attribute at a given stage
in the construction of the decision tree and C i is the cost of measuring the i-th attribute. C4.5
selects the attribute that maximizes the information gain ratio, which is a function of the
information gain I i . We modified C4.5 so that it selects the attribute that maximizes ICF i .
The parameter  adjusts the strength of the bias towards lower cost attributes. When
 = 0 , cost is ignored and selection by ICF i is equivalent to selection by I i . When
 = 1 , ICF i is strongly biased by cost. Ideally,  would be selected in a way that is sensitive to classification error cost (this is done in ICET  see Section 3.5). Nez (1991) does
not suggest a principled way of setting  . In our experiments with EG2,  was set to 1. In
other words, we used the following selection measure:
I i

2 1
----------------Ci + 1

(3)

In addition to its sensitivity to the cost of tests, EG2 generalizes attributes by using an ISA
tree (a generalization hierarchy). We did not implement this aspect of EG2, since it was not
relevant for the experiments reported here.
3.3

CS-ID3

CS-ID3 (Tan & Schlimmer, 1989, 1990; Tan, 1993) is a TDIDT algorithm that selects the
attribute that maximizes the following heuristic function:
2

( I i )
--------------Ci

(4)

6. This is the inverse of ICF, as defined by Nez (1991). Nez minimizes his criterion. To facilitate comparison
with the other algorithms, we use equation (2). This criterion is intended to be maximized.

377

fiT URNEY

We implemented CS-ID3 by modifying C4.5 so that it selects the attribute that maximizes
(4).
CS-ID3 uses a lazy evaluation strategy. It only constructs the part of the decision tree
that classifies the current case. We did not implement this aspect of CS-ID3, since it was not
relevant for the experiments reported here.
3.4

IDX

IDX (Norton, 1989) is a TDIDT algorithm that selects the attribute that maximizes the following heuristic function:
I i
------Ci

(5)

We implemented IDX by modifying C4.5 so that it selects the attribute that maximizes (5).
C4.5 uses a greedy search strategy that chooses at each step the attribute with the highest
information gain ratio. IDX uses a lookahead strategy that looks n tests ahead, where n is a
parameter that may be set by the user. We did not implement this aspect of IDX. The lookahead strategy would perhaps make IDX more competitive with ICET, but it would also complicate comparison of the heuristic function (5) with the heuristics (3) and (4) used by EG2
and CS-ID3.
3.5

ICET

ICET is a hybrid of a genetic algorithm and a decision tree induction algorithm. The genetic
algorithm evolves a population of biases for the decision tree induction algorithm. The
genetic algorithm we use is GENESIS (Grefenstette, 1986).7 The decision tree induction
algorithm is C4.5 (Quinlan, 1992), modified to use ICF. That is, the decision tree induction
algorithm is EG2, implemented as described in Section 3.2.
ICET uses a two-tiered search strategy. On the bottom tier, EG2 performs a greedy
search through the space of decision trees, using the standard TDIDT strategy. On the top
tier, GENESIS performs a genetic search through a space of biases. The biases are used to
modify the behavior of EG2. In other words, GENESIS controls EG2s preference for one
type of decision tree over another.
ICET does not use EG2 the way it was designed to be used. The n costs, C i , used in
EG2s attribute selection function, are treated by ICET as bias parameters, not as costs. That
is, ICET manipulates the bias of EG2 by adjusting the parameters, C i . In ICET, the values of
the bias parameters, C i , have no direct connection to the actual costs of the tests.
Genetic algorithms are inspired by biological evolution. The individuals that are evolved
by GENESIS are strings of bits. GENESIS begins with a population of randomly generated
individuals (bit strings) and then it measures the fitness of each individual. In ICET, an
individual (a bit string) represents a bias for EG2. An individual is evaluated by running EG2
on the data, using the bias of the given individual. The fitness of the individual is the average cost of classification of the decision tree that is generated by EG2. In the next generation, the population is replaced with new individuals. The new individuals are generated
from the previous generation, using mutation and crossover (sex). The fittest individuals in
the first generation have the most offspring in the second generation. After a fixed number of
7. We used GENESIS Version 5.0, which is available at URL ftp://ftp.aic.nrl.navy.mil/pub/galist/src/ga/genesis.tar.Z or ftp://alife.santafe.edu/pub/USER-AREA/EC/GA/src/gensis-5.0.tar.gz.

378

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

generations, ICET halts and its output is the decision tree determined by the fittest individual. Figure 2 gives a sketch of the ICET algorithm.

GENESIS
fittest

genetic algorithm

decision tree
population of
biases
EG2

data

fitness

decision tree

classifier

function
EG2
decision tree

classifier
EG2

decision tree

classifier

Figure 2: A sketch of the ICET algorithm.
GENESIS has several parameters that can be used to alter its performance. The parameters we used are listed in Table 4. These are essentially the default parameter settings
(Grefenstette, 1986). We used a population size of 50 individuals and 1,000 trials, which
results in 20 generations. An individual in the population consists of a string of n + 2 numbers, where n is the number of attributes (tests) in the given dataset. The n + 2 numbers are
represented in binary format, using a Gray code.8 This binary string is used as a bias for
EG2. The first n numbers in the string are treated as if they were the n costs, C i , used in ICF
(equation (2)). The first n numbers range from 1 to 10,000 and are coded with 12 binary digits each. The last two numbers in the string are used to set  and CF. The parameter  is
used in ICF. The parameter CF is used in C4.5 to control the level of pruning of the decision
tree. The last two numbers are coded with 8 binary digits each.  ranges from 0 (cost is
ignored) to 1 (maximum sensitivity to cost) and CF ranges from 1 (high pruning) to 100 (low
pruning). Thus an individual is a string of 12n + 16 bits.
Each trial of an individual consists of running EG2 (implemented as a modification to
C4.5) on a given training dataset, using the numbers specified in the binary string to set C i
( i = 1, , n ),  , and CF. The training dataset is randomly split into two equal-sized subsets
(  1 for odd-sized training sets), a sub-training set and a sub-testing set. A different random
split is used for each trial, so the outcome of a trial is stochastic. We cannot assume that
identical individuals yield identical outcomes, so every individual must be evaluated. This
means that there will be duplicate individuals in the population, with slightly different fitness
scores. The measure of fitness of an individual is the average cost of classification on the
sub-testing set, using the decision tree that was generated on the sub-training set. The aver8. A Gray code is a binary code that is designed to avoid Hamming cliffs. In the standard binary code, 7 is represented as 0111 and 8 is represented as 1000. These numbers are adjacent, yet the Hamming distance from
0111 to 1000 is large. In a Gray code, adjacent numbers are represented with binary codes that have small
Hamming distances. This tends to improve the performance of a genetic algorithm (Grefenstette, 1986).

379

fiT URNEY

Table 4: Parameter settings for GENESIS.
Parameter

Setting

Experiments

1

Total Trials

1000

Population Size

50

Structure Length

12n + 16

Crossover Rate

0.6

Mutation Rate

0.001

Generation Gap

1.0

Scaling Window

5

Report Interval

100

Structures Saved

1

Max Gens w/o Eval

2

Dump Interval

0

Dumps Saved

0

Options

acefgl

Random Seed

123456789

Rank Min

0.75

age cost is measured as described in Section 2.2. After 1,000 trials, the most fit (lowest cost)
individual is then used as a bias for EG2 with the whole training set as input. The resulting
decision tree is the output of ICET for the given training dataset.9
The n costs (bias parameters), C i , used in ICF, are not directly related to the true costs of
the attributes. The 50 individuals in the first generation are generated randomly, so the initial
values of C i have no relation to the true costs. After 20 generations, the values of C i may
have some relation to the true costs, but it will not be a simple relationship. These values of
C i are more appropriately thought of as biases than costs. Thus GENESIS is searching
through a bias space for biases for C4.5 that result in decision trees with low average cost.
The biases C i range from 1 to 10,000. When a bias C i is greater than 9,000, the i-th
attribute is ignored. That is, the i-th attribute is not available for C4.5 to include in the decision tree, even if it might maximize ICF i . This threshold of 9,000 was arbitrarily chosen.
There was no attempt to optimize this value by experimentation.
We chose to use EG2 in ICET, rather than IDX or CS-ID3, because EG2 has the parameter  , which gives GENESIS greater control over the bias of EG2. ICF i is partly based on
the data (via the information gain, I i ) and it is partly based on the bias (via the pseudo9. The 50/50 partition of sub-training and sub-testing sets could mean that ICET may not work well on small
datasets. The smallest dataset of the five we examine here is the Hepatitis dataset, which has 155 cases. The
training sets had 103 cases and the testing sets had 52 cases. The sub-training and sub-testing sets had 51 or 52
cases. We can see from Figure 3 that ICET performed slightly better than the other algorithms on this dataset
(the difference is not significant).

380

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

cost, C i ). The exact mix of data and bias can be controlled by varying  . Otherwise, there
is no reason to prefer EG2 to IDX or CS-ID3, which could easily be used instead of EG2.
The treatment of delayed tests and conditional test costs is not hard-wired into EG2. It
is built into the fitness function used by GENESIS, the average cost of classification (measured as described in Section 2). This makes it relatively simple to extend ICET to handle
other pragmatic constraints on the decision trees.
In effect, GENESIS lies to EG2 about the costs of the tests. How can lies improve the
performance of EG2? EG2 is a hill-climbing algorithm that can get trapped at a local optimum. It is a greedy algorithm that looks only one test ahead as it builds a decision tree.
Because it looks only one step ahead, EG2 suffers from the horizon effect. This term is taken
from the literature on chess playing programs. Suppose that a chess playing program has a
fixed three-move lookahead depth and it finds that it will loose its queen in three moves, if it
follows a certain branch of the game tree. There may be an alternate branch where the program first sacrifices a pawn and then loses its queen in four moves. Because the loss of the
queen is over its three-move horizon, the program may foolishly decide to sacrifice its pawn.
One move later, it is again faced with the loss of its queen. Analogously, EG2 may try to
avoid a certain expensive test by selecting a less expensive test. One test later, it is again
faced with the more expensive test. After it has exhausted all the cheaper tests, it may be
forced to do the expensive test, in spite of its efforts to avoid the test. GENESIS can prevent
this short-sighted behavior by telling lies to EG2. GENESIS can exaggerate the cost of the
cheap tests or it can understate the cost of the expensive test. Based on past trials, GENESIS
can find the lies that yield the best performance from EG2.
In ICET, learning (local search in EG2) and evolution (in GENESIS) interact. A common
form of hybrid genetic algorithm uses local search to improve the individuals in a population
(Schaffer et al., 1992). The improvements are then coded into the strings that represent the
individuals. This is a form of Lamarckian evolution. In ICET, the improvements due to EG2
are not coded into the strings. However, the improvements can accelerate evolution by altering the fitness landscape. This phenomenon (and other phenomena that result from this form
of hybrid) is known as the Baldwin effect (Baldwin, 1896; Morgan, 1896; Waddington, 1942;
Maynard Smith, 1987; Hinton & Nowlan, 1987; Ackley & Littman, 1991; Whitley & Gruau,
1993; Whitley et al., 1994; Anderson, in press). The Baldwin effect may explain much of the
success of ICET.

4. Experiments
This section describes experiments that were performed on five datasets, taken from the Irvine collection (Murphy & Aha, 1994). The five datasets are described in detail in
Appendix A. All five datasets involve medical problems. The test costs are based on information from the Ontario Ministry of Health (1992). The main purpose of the experiments is
to gain insight into the behavior of ICET. The other cost-sensitive algorithms, EG2, CS-ID3,
and IDX, are included mainly as benchmarks for evaluating ICET. C4.5 is also included as a
benchmark, to illustrate the behavior of an algorithm that makes no use of cost information.
The main conclusion of these experiments is that ICET performs significantly better than its
competitors, under a wide range of conditions. With access to the Irvine collection and the
information in Appendix A, it should be possible for other researchers to duplicate the
results reported here.
Medical datasets frequently have missing values.10 We conjecture that many missing values in medical datasets are missing because the doctor involved in generating the dataset
381

fiT URNEY

decided that a particular test was not economically justified for a particular patient. Thus
there may be information content in the fact that a certain value is missing. There may be
many reasons for missing values other than the cost of the tests. For example, perhaps the
doctor forgot to order the test or perhaps the patient failed to show up for the test. However,
it seems likely that there is often information content in the fact that a value is missing. For
our experiments, this information content should be hidden from the learning algorithms,
since using it (at least in the testing sets) would be a form of cheating. Two of the five
datasets we selected had some missing data. To avoid accusations of cheating, we decided to
preprocess the datasets so that the data presented to the algorithms had no missing values.
This preprocessing is described in Appendices A.2 and A.3.
Note that ICET is capable of handling missing values without preprocessing  it inherits this ability from its C4.5 component. We preprocessed the data only to avoid accusations
of cheating, not because ICET requires preprocessed data.
For the experiments, each dataset was randomly split into 10 pairs of training and testing
sets. Each training set consisted of two thirds of the dataset and each testing set consisted of
the remaining one third. The same 10 pairs were used in all experiments, in order to facilitate
comparison of results across experiments.
There are three groups of experiments. The first group of experiments examines the baseline performance of the algorithms. The second group considers how robust ICET is under a
variety of conditions. The final group looks at how ICET searches bias space.
4.1

Baseline Performance

This section examines the baseline performance of the algorithms. In Section 4.1.1, we look
at the average cost of classification of the five algorithms on the five datasets. Averaged
across the five datasets, ICET has the lowest average cost. In Section 4.1.2, we study test
expenditures and error rates as functions of the penalty for misclassification errors. Of the
five algorithms studied here, only ICET adjusts its test expenditures and error rates as functions of the penalty for misclassification errors. The other four algorithms ignore the penalty
for misclassification errors. ICET behaves as one would expect, increasing test expenditures
and decreasing error rates as the penalty for misclassification errors rises. In Section 4.1.3,
we examine the execution time of the algorithms. ICET requires 23 minutes on average on a
single-processor Sparc 10. Since ICET is inherently parallel, there is significant room for
speed increase on a parallel machine.
4.1.1

AVERAGE COST OF CLASSIFICATION

The experiment presented here establishes the baseline performance of the five algorithms.
The hypothesis was that ICET will, on average, perform better than the other four algorithms. The classification cost matrix was set to a positive constant value k when the guess
class i does not equal the actual class j, but it was set to $0.00 when i equals j. We experimented with seven settings for k, $10, $50, $100, $500, $1000, $5000, and $10000.
Initially, we used the average cost of classification as the performance measure, but we
found that there are three problems with using the average cost of classification to compare
the five algorithms. First, the differences in costs among the algorithms become relatively

10. A survey of 54 datasets from the Irvine collection (URL ftp://ftp.ics.uci.edu/pub/machine-learning-databases/
SUMMARY-TABLE) indicates that 85% of the medical datasets (17 out of 20) have missing values, while only
24% (8 out of 34) of the non-medical datasets have missing values.

382

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

small as the penalty for classification errors increases. This makes it difficult to see which
algorithm is best. Second, it is difficult to combine the results for the five datasets in a fair
manner.11 It is not fair to average the five datasets together, since their test costs have different scales (see Appendix A). The test costs in the Heart Disease dataset, for example, are
substantially larger than the test costs in the other four datasets. Third, it is difficult to combine average costs for different values of k in a fair manner, since more weight will be given
to the situations where k is large than to the situations where it is small.
To address these concerns, we decided to normalize the average cost of classification. We
normalized the average cost by dividing it by the standard cost. Let f i  [0,1] be the frequency of class i in the given dataset. That is, f i is the fraction of the cases in the dataset that
belong in class i. We calculate f i using the entire dataset, not just the training set. Let C i, j be
the cost of guessing that a case belongs in class i, when it actually belongs in class j. Let T
be the total cost of doing all of the possible tests. The standard cost is defined as follows:
T + min (1  f i)  max C i, j

(6)

i, j

i

We can decompose formula (6) into three components:
T

(7)

min (1  f i)

(8)

max C i, j

(9)

i

i, j

We may think of (7) as an upper bound on test expenditures, (8) as an upper bound on error
rate, and (9) as an upper bound on the penalty for errors. The standard cost is always less
than the maximum possible cost, which is given by the following formula:
T + max C i, j
i, j

(10)

The point is that (8) is not really an upper bound on error rate, since it is possible to be
wrong with every guess. However, our experiments suggest that the standard cost is better
for normalization, since it is a more realistic (tighter) upper bound on the average cost. In
our experiments, the average cost never went above the standard cost, although it occasionally came very close.
Figure 3 shows the result of using formula (6) to normalize the average cost of classification. In the plots, the x axis is the value of k and the y axis is the average cost of classification
as a percentage of the standard cost of classification. We see that, on average (the sixth plot
in Figure 3), ICET has the lowest classification cost. The one dataset where ICET does not
perform particularly well is the Heart Disease dataset (we discuss this later, in Sections 4.3.2
and 4.3.3).
To come up with a single number that characterizes the performance of each algorithm,
we averaged the numbers in the sixth plot in Figure 3.12 We calculated 95% confidence
regions for the averages, using the standard deviations across the 10 random splits of the
11. We want to combine the results in order to summarize the performance of the algorithms on the five datasets.
This is analogous to comparing students by calculating the GPA (Grade Point Average), where students are to
courses as algorithms are to datasets.
12. Like the GPA, all datasets (courses) have the same weight. However, unlike the GPA, all algorithms (students) are applied to the same datasets (have taken the same courses). Thus our approach is perhaps more fair
to the algorithms than GPA is to students.

383

fiT URNEY

BUPA Liver Disease

Heart Disease
100
Average % Standard Cost

Average % Standard Cost

100
80
60
40
20
0
10

80
60
40
20
0

100

1000

10000

10

Cost of Misclassification Error

Hepatitis Prognosis

Pima Indians Diabetes
Average % Standard Cost

Average % Standard Cost

60
40
20
0

80
60
40
20
0

100

1000

10000

10

Cost of Misclassification Error

100

1000

10000

Cost of Misclassification Error

Thyroid Disease

Average of Five Datasets
100
Average % Standard Cost

100
Average % Standard Cost

10000

100

80

80
60
40
20
0
10

1000

Cost of Misclassification Error

100

10

100

80
60
40
20
0

100

1000

10000

10

Cost of Misclassification Error

100

1000

10000

Cost of Misclassification Error

ICET:
EG2:
CS-ID3:
IDX:
C4.5:

Figure 3: Average cost of classification as a percentage of the standard cost of
classification for the baseline experiment.
datasets. The result is shown in Table 5.
Table 5 shows the averages for the first three misclassification error costs alone ($10,
$50, and $100), in addition to showing the averages for all seven misclassification error costs
($10 to $10000). We have two averages (the two columns in Table 5), based on two groups of
data, to address the following argument: As the penalty for misclassification errors increases,
the cost of the tests becomes relatively insignificant. With very high misclassification error
cost, the test cost is effectively zero, so the task becomes simply to maximize accuracy. As
384

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

Table 5: Average percentage of standard cost for the baseline experiment.
Algorithm

Average Classification Cost as Percentage of Standard
 95% Confidence
Misclassification Error Costs
from 10.00 to 10,000.00

Misclassification Error Costs
from 10.00 to 100.00

ICET

49  7

29  7

EG2

58  5

43  3

CS-ID3

61  6

49  4

IDX

58  5

43  3

C4.5

77  5

82  4

we see in Figure 3, the gap between C4.5 (which maximizes accuracy) and the other algorithms becomes smaller as the cost of misclassification error increases. Therefore the benefit
of sensitivity to test cost decreases as the cost of misclassification error increases. It could be
argued that one would only bother with an algorithm that is sensitive to test cost when tests
are relatively expensive, compared to the cost of misclassification errors. Thus the most realistic measure of performance is to examine the average cost of classification when the cost of
tests is the same order of magnitude as the cost of misclassification errors ($10 to $100).
This is why Table 5 shows both averages.
Our conclusion, based on Table 5, is that ICET performs significantly better than the
other four algorithms when the cost of tests is the same order of magnitude as the cost of
misclassification errors ($10, $50, and $100). When the cost of misclassification errors dominates the test costs, ICET still performs better than the competition, but the difference is less
significant. The other three cost-sensitive algorithms (EG2, CS-ID3, and IDX) perform significantly better than C4.5 (which ignores cost). The performance of EG2 and IDX is indistinguishable, but CS-ID3 appears to be consistently more costly than EG2 and IDX.
4.1.2

TEST EXPENDITURES AND ERROR RATES AS FUNCTIONS OF THE PENALTY FOR ERRORS

We argued in Section 2 that expenditures on tests should be conditional on the penalty for
misclassification errors. Therefore ICET is designed to be sensitive to both the cost of tests
and the cost of classification errors. This leads us to the hypothesis that ICET tends to spend
more on tests as the penalty for misclassification errors increases. We also expect that the
error rate of ICET should decrease as test expenditures increase. These two hypotheses are
confirmed in Figure 4. In the plots, the x axis is the value of k and the y axis is (1) the average expenditure on tests, expressed as a percentage of the maximum possible expenditure on
tests, T , and (2) the average percent error rate. On average (the sixth plot in Figure 4), test
expenditures rise and error rate falls as the penalty for classification errors increases. There
are some minor deviations from this trend, since ICET can only guess at the value of a test
(in terms of reduced error rate), based on what it sees in the training dataset. The testing
dataset may not always support that guess. Note that plots for the other four algorithms, corresponding to the plots for ICET in Figure 4, would be straight horizontal lines, since all four
algorithms ignore the cost of misclassification error. They generate the same decision trees
for every possible misclassification error cost.

385

fiT URNEY

80

60

60
40
40
20

20
0

0
1000

10000

30
40
20
20

10

Average % Maximum Test Expenditures

30
20
20
10
0

Average % Error Rate

Average % Maximum Test Expenditures

40

0
1000

10000

80

60

40
40
20
20

0
10

0
100

1000

10000

Cost of Misclassification Error

Average of Five Datasets

80

Average % Maximum Test Expenditures

Thyroid Disease
10
8

60

6
40
4
20

2

0

Average % Error Rate

Average % Maximum Test Expenditures

10000

60

Cost of Misclassification Error

0
100

1000

Pima Indians Diabetes
40

10

0
100

Cost of Misclassification Error

Hepatitis Prognosis
50

100

10

0

Cost of Misclassification Error

10

40

60

Average % Error Rate

100

50

1000

10000

Cost of Misclassification Error

80

50
40

60

30
40
20
20

10

0
10

Average % Error Rate

10

80

Average % Error Rate

Average % Maximum Test Expenditures

Heart Disease
80

Average % Error Rate

Average % Maximum Test Expenditures

BUPA Liver Disease
100

0
100

1000

10000

Cost of Misclassification Error

% Test Expenditures:
% Error Rate:

Figure 4: Average test expenditures and average error rate
as a function of misclassification error cost.
4.1.3

EXECUTION TIME

In essence, ICET works by invoking C4.5 1000 times (Section 3.5). Fortunately, Quinlans
(1992) implementation of C4.5 is quite fast. Table 6 shows the run-times for the algorithms,
using a single-processor Sun Sparc 10. One full experiment takes about one week (roughly
23 minutes for an average run, multiplied by 5 datasets, multiplied by 10 random splits, multiplied by 7 misclassification error costs equals about one week). Since genetic algorithms
can easily be executed in parallel, there is substantial room for speed increase with a parallel
machine. Each generation consists of 50 individuals, which could be evaluated in parallel,
reducing the average run-time to about half a minute.
4.2

Robustness of ICET

This group of experiments considers how robust ICET is under a variety of conditions. Each
section considers a different variation on the operating environment of ICET. The ICET
386

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

Table 6: Elapsed run-time for the five algorithms.
Algorithm

Average Elapsed Run-Time for Each Dataset  Minutes:Seconds
BUPA

Heart

Hepatitis

Pima

Thyroid

Average

ICET

15:43

13:14

10:29

28:19

45:25

22:38

EG2

0:1

0:1

0:1

0:3

0:3

0:2

CS-ID3

0:1

0:1

0:1

0:3

0:3

0:2

IDX

0:1

0:1

0:1

0:3

0:3

0:2

C4.5

0:2

0:1

0:1

0:4

0:3

0:2

algorithm itself is not modified. In Section 4.2.1, we alter the environment by labelling all
tests as immediate. In Section 4.2.2, we do not recognize shared costs, so there is no discount
for a group of tests with a common cost. In Section 4.2.3, we experiment with complex classification cost matrices, where different types of errors have different costs. In Section 4.2.4,
we examine what happens when ICET is trained with a certain penalty for misclassification
errors, then tested with a different penalty. In all four experiments, we find that ICET continues to perform well.
4.2.1

ALL TESTS IMMEDIATE

A critic might object that the previous experiments do not show that ICET is superior to the
other algorithms due to its sensitivity to both test costs and classification error costs. Perhaps
ICET is superior simply because it can handle delayed tests, while the other algorithms treat
all tests as immediate.13 That is, the method of estimating the average classification cost
(Section 2.2) is biased in favor of ICET (since ICET uses the method in its fitness function)
and against the other algorithms. In this experiment, we labelled all tests as immediate. Otherwise, nothing changed from the baseline experiments. Table 7 summarizes the results of
the experiment. ICET still performs well, although its advantage over the other algorithms
has decreased slightly. Sensitivity to delayed tests is part of the explanation of ICETs performance, but it is not the whole story.
4.2.2

NO GROUP DISCOUNTS

Another hypothesis is that ICET is superior simply because it can handle groups of tests that
share a common cost. In this experiment, we eliminated group discounts for tests that share a
common cost. That is, test costs were not conditional on prior tests. Otherwise, nothing
changed from the baseline experiments. Table 8 summarizes the results of the experiment.
ICET maintains its advantage over the other algorithms.
4.2.3

COMPLEX CLASSIFICATION COST MATRICES

So far, we have only used simple classification cost matrices, where the penalty for a classification error is the same for all types of error. This assumption is not inherent in ICET. Each
13. While the other algorithms cannot currently handle delayed tests, it should be possible to alter them in some
way, so that they can handle delayed tests. This comment also extends to groups of tests that share a common
cost. ICET might be viewed as an alteration of EG2 that enables EG2 to handle delayed tests and common
costs.

387

fiT URNEY

Table 7: Average percentage of standard cost for the no-delay experiment.
Algorithm

Average Classification Cost as Percentage of Standard
 95% Confidence
Misclassification Error Costs
from 10.00 to 10,000.00

Misclassification Error Costs
from 10.00 to 100.00

ICET

47  6

28  4

EG2

54  4

36  2

CS-ID3

54  5

39  3

IDX

54  4

36  2

C4.5

64  6

59  4

Table 8: Average percentage of standard cost for the no-discount experiment.
Algorithm

Average Classification Cost as Percentage of Standard
 95% Confidence
Misclassification Error Costs
from 10.00 to 10,000.00

Misclassification Error Costs
from 10.00 to 100.00

ICET

46  6

25  5

EG2

56  5

42  3

CS-ID3

59  5

48  4

IDX

56  5

42  3

C4.5

75  5

80  4

element in the classification cost matrix can have a different value. In this experiment, we
explore ICETs behavior when the classification cost matrix is complex.
We use the term positive error to refer to a false positive diagnosis, which occurs when
a patient is diagnosed as being sick, but the patient is actually healthy. Conversely, the term
negative error refers to a false negative diagnosis, which occurs when a patient is diagnosed as being healthy, but is actually sick. The term positive error cost is the cost that is
assigned to positive errors, while negative error cost is the cost that is assigned to negative
errors. See Appendix A for examples. We were interested in ICETs behavior as the ratio of
negative to positive error cost was varied. Table 9 shows the ratios that we examined.
Figure 5 shows the performance of the five algorithms at each ratio.
Our hypothesis was that the difference in performance between ICET and the other algorithms would increase as we move away from the middles of the plots, where the ratio is 1.0,
since the other algorithms have no mechanism to deal with complex classification cost; they
were designed under the implicit assumption of simple classification cost matrices. In fact,
Figure 5 shows that the difference tends to decrease as we move away from the middles.
This is most pronounced on the right-hand sides of the plots. When the ratio is 8.0 (the
extreme right-hand sides of the plots), there is no advantage to using ICET. When the ratio is
0.125 (the extreme left-hand sides of the plots), there is still some advantage to using ICET.
388

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

BUPA Liver Disease

Heart Disease
100
Average % Standard Cost

Average % Standard Cost

100
80
60
40
20
0
0.1

80
60
40
20
0

1.0

10.0

0.1

Ratio of Negative to Positive Error Cost

Hepatitis Prognosis
Average % Standard Cost

Average % Standard Cost

100

80
60
40
20
0

80
60
40
20
0

1.0

10.0

0.1

Ratio of Negative to Positive Error Cost

Thyroid Disease

10.0

Average of Five Datasets
100
Average % Standard Cost

Average % Standard Cost

1.0
Ratio of Negative to Positive Error Cost

100
80
60
40
20
0
0.1

10.0

Pima Indians Diabetes

100

0.1

1.0
Ratio of Negative to Positive Error Cost

80
60
40
20
0

1.0

10.0

0.1

Ratio of Negative to Positive Error Cost

1.0

10.0

Ratio of Negative to Positive Error Cost

ICET:
EG2:
CS-ID3:
IDX:
C4.5:

Figure 5: Average cost of classification as a percentage of the standard cost of
classification, with complex classification cost matrices.
The interpretation of these plots is complicated by the fact that the gap between the algorithms tends to decrease as the penalty for classification errors increases (as we can see in
Figure 3  in retrospect, we should have held the sum of the negative error cost and the positive error cost at a constant value, as we varied their ratio). However, there is clearly an
asymmetry in the plots, which we expected to be symmetrical about a vertical line centered
on 1.0 on the x axis. The plots are close to symmetrical for the other algorithms, but they are
asymmetrical for ICET. This is also apparent in Table 10, which focuses on a comparison of
the performance of ICET and EG2, averaged across all five datasets (see the sixth plot in
Figure 5). This suggests that it is more difficult to reduce negative errors (on the right-hand
sides of the plots, negative errors have more weight) than it is to reduce positive errors (on
389

fiT URNEY

Table 9: Actual error costs for each ratio of negative to positive error cost.
Ratio of Negative to
Positive Error Cost

Negative
Error Cost

Positive
Error Cost

0.125

50

400

0.25

50

200

0.5

50

100

1.0

50

50

2.0

100

50

4.0

200

50

8.0

400

50

Table 10: Comparison of ICET and EG2
with various ratios of negative to positive error cost.

Algorithm

Average Classification Cost as Percentage of Standard
 95% Confidence, as the Ratio of
Negative to Positive Error Cost is Varied
0.125

0.25

0.5

1.0

2.0

4.0

8.0

ICET

25  10

25  8

29  6

29  4

34  6

39  6

39  6

EG2

39  5

40  4

41  4

44  3

42  3

41  4

40  5

ICET/EG2 (as %)

64

63

71

66

81

95

98

the left-hand sides, positive errors have more weight). That is, it is easier to avoid false positive diagnoses (a patient is diagnosed as being sick, but the patient is actually healthy) than
it is to avoid false negative diagnoses (a patient is diagnosed as being healthy, but is actually
sick). This is unfortunate, since false negative diagnoses usually carry a heavier penalty, in
real-life. Preliminary investigation suggests that false negative diagnoses are harder to avoid
because the sick class is usually less frequent than the healthy class, which makes the
sick class harder to learn.
4.2.4

POORLY ESTIMATED CLASSIFICATION COST

We believe that it is an advantage of ICET that it is sensitive to both test costs and classification error costs. However, it might be argued that it is difficult to calculate the cost of classification errors in many real-world applications. Thus it is possible that an algorithm that
ignores the cost of classification errors (e.g., EG2, CS-ID3, IDX) may be more robust and
useful than an algorithm that is sensitive to classification errors (e.g., ICET). To address this
possibility, we examine what happens when ICET is trained with a certain penalty for classification errors, then tested with a different penalty.
Our hypothesis was that ICET would be robust to reasonable differences between the
penalty during training and the penalty during testing. Table 11 shows what happens when
ICET is trained with a penalty of $100 for classification errors, then tested with penalties of
390

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

Table 11: Performance when training set classification error cost is $100.

Algorithm

Average Classification Cost as Percentage of
Standard  95% Confidence, for Testing Set
Classification Error Cost of:
$50

$100

$500

ICET

33  10

41  10

62  9

EG2

44  3

49  4

63  6

CS-ID3

49  5

54  6

65  7

IDX

43  3

49  4

63  6

C4.5

82  5

82  5

78  7

$50, $100, and $500. We see that ICET has the best performance of the five algorithms,
although its edge is quite slight in the case where the penalty is $500 during testing.
We also examined what happens (1) when ICET is trained with a penalty of $500 and
tested with penalties of $100, $500, and $1,000 and (2) when ICET is trained with a penalty
of $1,000 and tested with penalties of $500, $1,000, and $5,000. The results show essentially
the same pattern as in Table 11: ICET is relatively robust to differences between the training
and testing penalties, at least when the penalties have the same order of magnitude. This suggests that ICET is applicable even in those situations where the reliability of the estimate of
the cost of classification errors is dubious.
When the penalty for errors on the testing set is $100, ICET works best when the penalty
for errors on the training set is also $100. When the penalty for errors on the testing set is
$500, ICET works best when the penalty for errors on the training set is also $500. When the
penalty for errors on the testing set is $1,000, ICET works best when the penalty for errors
on the training set is $500. This suggests that there might be an advantage in some situations
to underestimating the penalty for errors during training. In other, words ICET may have a
tendency to overestimate the benefits of tests (this is likely due to overfitting the training
data).
4.3

Searching Bias Space

The final group of experiments analyzes ICETs method for searching in bias space. Section
4.3.1 studies the roles of the mutation and crossover operators. It appears that crossover is
mildly beneficial, compared to pure mutation. Section 4.3.2 considers what happens when
ICET is constrained to search in a binary bias space, instead of a real bias space. This constraint actually improves the performance of ICET. We hypothesized that the improvement
was due to a hidden advantage of searching in binary bias space: When searching in binary
bias space, ICET has direct access to the true costs of the tests. However, this advantage can
be available when searching in real bias space, if the initial population of biases is seeded
with the true costs of the tests. Section 4.3.3 shows that this seeding improves the performance of ICET.
4.3.1

CROSSOVER VERSUS MUTATION

Past work has shown that a genetic algorithm with crossover performs better than a genetic
algorithm with mutation alone (Grefenstette et al., 1990; Wilson, 1987). This section
391

fiT URNEY

attempts to test the hypothesis that crossover improves the performance of ICET. To test this
hypothesis, it is not sufficient to merely set the crossover rate to zero. Since crossover has a
randomizing effect, similar to mutation, we must also increase the mutation rate, to compensate for the loss of crossover (Wilson, 1987; Spears, 1992).
It is very difficult to analytically calculate the increase in mutation rate that is required to
compensate for the loss of crossover (Spears, 1992). Therefore we experimentally tested
three different mutation settings.14 The results are summarized in Table 12. When the crossover rate was set to zero, the best mutation rate was 0.10. For misclassification error costs
from $10 to $10,000, the performance of ICET without crossover was not as good as the performance of ICET with crossover, but the difference is not statistically significant. However,
this comparison is not entirely fair to crossover, since we made no attempt to optimize the
crossover rate (we simply used the default value). The results suggest that crossover is
mildly beneficial, but do not prove that pure mutation is inferior.
Table 12: Average percentage of standard cost for mutation experiment.
Average Classification Cost as Percentage of
Standard  95% Confidence

ICET
Crossover
Rate

Mutation
Rate

Misclassification
Error Costs
from 10.00 to 10,000.00

Misclassification
Error Costs
from 10.00 to 100.00

0.6

0.001

49  7

29  7

0.0

0.05

51  8

32  9

0.0

0.10

50  8

29  8

0.0

0.15

51  8

30  9

4.3.2

SEARCH IN BINARY SPACE

ICET searches for biases in a space of n + 2 real numbers. Inspired by Aha and Bankert
(1994), we decided to see what would happen when ICET was restricted to a space of n
binary numbers and 2 real numbers. We modified ICET so that EG2 was given the true cost
of each test, instead of a pseudo-cost or bias. For conditional test costs, we used the nodiscount cost (see Section 4.2.2). The n binary digits were used to exclude or include a test.
EG2 was not allowed to use excluded tests in the decision trees that it generated.
To be more precise, let B 1, , B n be n binary numbers and let C 1, , C n be n real numbers. For this experiment, we set C i to the true cost of the i-th test. In this experiment, GENESIS does not change C i . That is, C i is constant for a given test in a given dataset. Instead,
GENESIS manipulates the value of B i for each i. The binary number B i is used to determine
whether EG2 is allowed to use a test in its decision tree. If B i = 0 , then EG2 is not allowed
to use the i-th test (the i-th attribute). Otherwise, if B i = 1 , EG2 is allowed to use the i-th
test. EG2 uses the ICF equation as usual, with the true costs C i . Thus this modified version
of ICET is searching through a binary bias space instead of a real bias space.
Our hypothesis was that ICET would perform better when searching in real bias space
14. Each of these three experiments took one week on a Sparc 10, which is why we only tried three settings for
the mutation rate.

392

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

than when searching in binary bias space. Table 13 shows that this hypothesis was not confirmed. It appears to be better to search in binary bias space, rather than real bias space.
However, the differences are not statistically significant.
Table 13: Average percentage of standard cost for the binary search experiment.
Algorithm

Average Classification Cost as Percentage of
Standard  95% Confidence
Misclassification
Error Costs
from 10.00 to 10,000.00

Misclassification
Error Costs
from 10.00 to 100.00

ICET  Binary Space

48  6

26  5

ICET  Real Space

49  7

29  7

EG2

58  5

43  3

CS-ID3

61  6

49  4

IDX

58  5

43  3

C4.5

77  5

82  4

When we searched in binary space, we set C i to the true cost of the i-th test. GENESIS
manipulated B i instead of C i . When we searched in real space, GENESIS set C i to whatever
value it found useful in its attempt to optimize fitness. We hypothesized that this gives an
advantage to binary space search over real space search. Binary space search has direct
access to the true costs of the tests, but real space search only learns about the true costs of
the tests indirectly, by the feedback it gets from the fitness function.
When we examined the experiment in detail, we found that ICET did well on the Heart
Disease dataset when it was searching in binary bias space, although it did poorly when it
was searching in real bias space (see Section 4.1.1). We hypothesized that ICET, when
searching in real space, suffered most from the lack of direct access to the true costs when it
was applied to the Heart Disease dataset. These hypotheses were tested by the next experiment.
4.3.3

SEEDED POPULATION

In this experiment, we returned to searching in real bias space, but we seeded the initial population of biases with the true test costs. This gave ICET direct access to the true test costs.
For conditional test costs, we used the no-discount cost (see Section 4.2.2). In the baseline
experiment (Section 4.1), the initial population consists of 50 randomly generated strings,
representing n + 2 real numbers. In this experiment, the initial population consists of 49 randomly generated strings and one manually generated string. In the manually generated
string, the first n numbers are the true test costs. The last two numbers were set to 1.0 (for
 ) and 25 (for CF). This string is exactly the bias of EG2, as implemented here (Section
3.2).
Our hypotheses were (1) that ICET would perform better (on average) when the initial
population is seeded than when it is purely random, (2) that ICET would perform better (on
average) searching in real space with a seeded population than when searching in binary
space,15 and (3) that ICET would perform better on the Heart Disease dataset when the ini393

fiT URNEY

tial population is seeded than when it is purely random. Table 14 appears to support the first
two hypotheses. Figure 6 appears to support the third hypothesis. However, the results are
not statistically significant.16
Table 14: Average percentage of standard cost for the seeded population
experiment.
Algorithm

Average Classification Cost as Percentage of
Standard  95% Confidence
Misclassification
Error Costs
from 10.00 to 10,000.00

Misclassification
Error Costs
from 10.00 to 100.00

ICET  Seeded
Search in Real Space

46  6

25  5

ICET  Unseeded
Search in Real Space

49  7

29  7

ICET  Unseeded
Search in Binary Space

48  6

26  5

EG2

58  5

43  3

CS-ID3

61  6

49  4

IDX

58  5

43  3

C4.5

77  5

82  4

This experiment raises some interesting questions: Should seeding the population be
built into the ICET algorithm? Should we seed the whole population with the true costs, perturbed by some random noise? Perhaps this is the right approach, but we prefer to modify
ICF i (equation (2)), the device by which GENESIS controls the decision tree induction. We
could alter this equation so that it contains both the true costs and some bias parameters.17
This seems to make more sense than our current approach, which deprives EG2 of direct
access to the true costs. We discuss some other ideas for modifying the equation in
Section 5.2.
Incidentally, this experiment lets us answer the following question: Does the genetic
search in bias space do anything useful? If we start with the true costs of the tests and reasonable values for the parameters  and CF, how much improvement do we get from the
genetic search? In this experiment, we seeded the population with an individual that represents exactly the bias of EG2 (the first n numbers are the true test costs and the last two numbers are 1.0 for  and 25 for CF). Therefore we can determine the value of genetic search by
comparing EG2 with ICET. ICET starts with the bias of EG2 (as a seed in the first genera15. Note that it does not make sense to seed the binary space search, since it already has direct access to the true
costs.
16. We would need to go from the current 10 trials (10 random splits of the data) to about 40 trials to make the
results significant. The experiments reported here took a total of 63 days of continuous computation on a Sun
Sparc 10, so 40 trials would require about six more months.
17. This idea was suggested in conversation by K. De Jong.

394

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

Heart Disease
100

80

80

Average % Standard Cost

Average % Standard Cost

BUPA Liver Disease
100

60

40

20
0
10

60

40

20
0

100

1000

10000

10

Cost of Misclassification Error

80

80

60

40

20
0

40

20
0

100

1000

10000

10

100

1000

10000

Cost of Misclassification Error

Thyroid Disease

Average of Five Datasets

100

100

80

80

Average % Standard Cost

Average % Standard Cost

10000

60

Cost of Misclassification Error

60

40

20
0
10

1000

Pima Indians Diabetes
100
Average % Standard Cost

Average % Standard Cost

Hepatitis Prognosis
100

10

100

Cost of Misclassification Error

60

40

20
0

100

1000

10000

10

Cost of Misclassification Error

100

1000

10000

Cost of Misclassification Error

ICET:
EG2:
CS-ID3:
IDX:
C4.5:

Figure 6: Average cost of classification as a percentage of the standard cost of
classification for the seeded population experiment.
tion) and attempts to improve the bias. The score of EG2 in Table 14 shows the value of the
bias built into EG2. The score of ICET in Table 14 shows how genetic search in bias space
can improve the built-in bias of EG2. When the cost of misclassification errors has the same
order of magnitude as the test costs ($10 to $100), EG2 averages 43% of the standard cost,
while ICET averages 25% of the standard cost. When the cost of misclassification errors
ranges from $10 to $10,000, EG2 averages 58% of the standard cost, while ICET averages
46% of the standard cost. Both of these differences are significant with more than 95% confidence. This makes it clear that genetic search is adding value.
395

fiT URNEY

5. Discussion
This section compares ICET to related work and outlines some possibilities for future work.
5.1

Related Work

There are several other algorithms that are sensitive to test costs (Nez, 1988, 1991; Tan &
Schlimmer, 1989, 1990; Tan, 1993; Norton, 1989). As we have discussed, the main limitation of these algorithms is that they do not consider the cost of classification errors. We cannot rationally determine whether a test should be performed until we know both the cost of
the test and the cost of classification errors.
There are also several algorithms that are sensitive to classification error costs (Breiman
et al., 1984; Friedman & Stuetzle, 1981; Hermans et al., 1974; Gordon & Perlis, 1989; Pazzani et al., 1994; Provost, 1994; Provost & Buchanan, in press; Knoll et al., 1994). None of
these algorithms consider the cost of tests. Therefore they all focus on complex classification
cost matrices, since, when tests have no cost and the classification error matrix is simple, the
problem reduces to maximizing accuracy.
The FIS system (Pipitone et al., 1991) attempts to find a decision tree that minimizes the
average total cost of the tests required to achieve a certain level of accuracy. This approach
could be implemented in ICET by altering the fitness function. The main distinction between
FIS (Pipitone et al., 1991) and ICET is that FIS does not learn from data. The information
gain of a test is estimated using a qualitative causal model, instead of training cases. Qualitative causal models are elicited from domain experts, using a special knowledge acquisition
tool. When training data are available, ICET can be used to avoid the need for knowledge
acquisition. Otherwise, ICET is not applicable and the FIS approach is suitable.
Another feature of ICET is that it does not perform purely greedy search. Several other
authors have proposed non-greedy classification algorithms (Tcheng et al., 1989; Ragavan &
Rendell, 1993; Norton, 1989; Schaffer, 1993; Rymon, 1993; Seshu, 1989). In general, these
results show that there can be an advantage to more sophisticated search procedures. ICET is
different from these algorithms in that it uses a genetic algorithm and it is applied to minimizing both test costs and classification error costs.
ICET uses a two-tiered search strategy. At the bottom tier, EG2 performs a greedy search
through the space of classifiers. On the second tier, GENESIS performs a non-greedy search
through a space of biases. The idea of a two-tiered search strategy (where the first tier is
search in classifier space and the second tier is search in bias space) also appears in (Provost,
1994; Provost & Buchanan, in press; Aha & Bankert, 1994; Schaffer, 1993). Our work goes
beyond Aha and Bankert (1994) by considering search in a real bias space, rather than search
in a binary space. Our work fits in the general framework of Provost and Buchanan (in
press), but differs in many details. For example, their method of calculating cost is a special
case of ours (Section 2.3).
Other researchers have applied genetic algorithms to classification problems. For example, Frey and Slate (1991) applied a genetic algorithm (in particular, a learning classifier system (LCS)) to letter recognition. However, Fogarty (1992) obtained higher accuracy using a
simple nearest neighbor algorithm. More recent applications of genetic algorithms to classification have been more successful (De Jong et al., 1993). However, the work described here
is the first application of genetic algorithms to the problem of cost-sensitive classification.
We mentioned in Section 2.1 that decision theory may be used to define the optimal solution to the problem of cost-sensitive classification. However, searching for the optimal solution is computationally infeasible (Pearl, 1988). We attempted to take a decision theoretic
396

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

approach to this problem by implementing the AO* algorithm (Pearl, 1984) and designing a
heuristic evaluation function to speed up the AO* search (Lirov & Yue, 1991). We were
unable to make this approach execute fast enough to be practical.
We also attempted to apply genetic programming (Koza, 1993) to the problem of costsensitive classification. Again, we were unable to make this approach execute fast enough to
be practical, although it was faster than the AO* approach.
The cost-sensitive classification problem, as we have treated it here, is essentially a
problem in reinforcement learning (Sutton, 1992; Karakoulas, in preparation). The average
cost of classification, measured as described in Section 2.2, is a reward/punishment signal
that could be optimized using reinforcement learning techniques. This is something that
might be explored as an alternative approach.
5.2

Future Work

This paper discusses two types of costs, the cost of tests and the cost of misclassification
errors. These two costs have been treated together in decision theory, but ICET is the first
machine learning system that handles both costs together. The experiments in this paper have
compared ICET to other machine learning systems that can handle test costs (Nez, 1988,
1991; Tan & Schlimmer, 1989, 1990; Tan, 1993; Norton, 1989), but we have not compared
ICET to other machine learning systems that can handle classification error costs (Breiman
et al., 1984; Friedman & Stuetzle, 1981; Hermans et al., 1974; Gordon & Perlis, 1989; Pazzani et al., 1994; Provost, 1994; Provost & Buchanan, in press; Knoll et al., 1994). In future
work, we plan to address this omission. A proper treatment of this issue would make this
paper too long.
The absence of comparison with machine learning systems that can handle classification
error costs has no impact on most of the experiments reported here. The experiments in this
paper focussed on simple classification cost matrices (except for Section 4.2.3). When the
classification cost matrix is simple and the cost of tests is ignored, minimizing cost is exactly
equivalent to maximizing accuracy (see Section 2.3). Therefore, C4.5 (which is designed to
maximize accuracy) is a suitable surrogate for any of the systems that can handle classification error costs.
We also did not experiment with setting the test costs to zero. However, the behavior of
ICET when the penalty for misclassification errors is very high (the extreme right-hand sides
of the plots in Figure 3) is necessarily the same as its behavior when the cost of tests is very
low, since ICET is sensitive to the relative differences between test costs and error costs, not
the absolute costs. Therefore (given the behavior we can observe in the extreme right-hand
sides of the plots in Figure 3) we can expect that the performance of ICET will tend to converge with the performance of the other algorithms as the cost of tests approaches zero.
One natural addition to ICET would be the ability to output an I dont know class. This
is easily handled by the GENESIS component, by extending the classification cost matrix so
that a cost is assigned to classifying a case as unknown. We need to also make a small
modification to the EG2 component, so that it can generate decision trees with leaves
labelled unknown. One way to do this would be to introduce a parameter that defines a
confidence threshold. Whenever the confidence in a certain leaf drops below the confidence
threshold, that leaf would be labelled unknown. This confidence parameter would be made
accessible to the GENESIS component, so that it could be tuned to minimize average classification cost.
The mechanism in ICET for handling conditional test costs has some limitations. As it is
397

fiT URNEY

currently implemented, it does not handle the cost of attributes that are calculated from other
attributes. For example, in the Thyroid dataset (Appendix A.5), the FTI test is calculated
based on the results of the TT4 and T4U tests. If the FTI test is selected, we must pay for the
TT4 and T4U tests. If the TT4 and T4U tests have already been selected, the FTI test is free
(since the calculation is trivial). The ability to deal with calculated test results could be
added to ICET with relatively little effort.
ICET, as currently implemented, only handles two classes of test results: tests with
immediate results and tests with delayed results. Clearly there can be a continuous range
of delays, from seconds to years. We have chosen to treat delays as distinct from test costs,
but it could be argued that a delay is simply another type of test cost. For example, we could
say that a group of blood tests shares the common cost of a one-day wait for results. The cost
of one of the blood tests is conditional on whether we are prepared to commit ourselves to
doing one or more of the other tests in the group, before we see the results of the first test.
One difficultly with this approach to handling delays is the problem of assigning a cost to the
delay. How much does it cost to bring a patient in for two blood samples, instead of one? Do
we include the disruption to the patients life in our estimate of the cost? To avoid these
questions, we have not treated delays as another type of test cost, but our approach does not
readily handle a continuous range of delays.
The cost of a test can be a function of several things: (1) It can be a function of the prior
tests that have been selected. (2) It can be a function of the actual class of the case. (3) It can
be a function of other aspects of the case, where information about these other aspects may
be available through other tests. (4) It can be a function of the test result. This list seems
comprehensive, but there may be some possibilities we have overlooked. Let us consider
each of these four possibilities.
First, the cost of a test can be a function of the prior tests that have been selected. ICET
handles a special case of this, where a group of tests shares a common cost. As it is currently
implemented, ICET does not handle the general case. However, we could easily add this
capability to ICET by modifying the fitness function.
Second, the cost of a test can be a function of the actual class of the case. For example, a
test for heart disease might involve heavy exercise (Appendix A.2). If the patient actually
has heart disease, the exercise might trigger a heart attack. This risk should be included in
the cost of this particular test. Thus the cost of this test should vary, depending on whether
the patient actually has heart disease. We have not implemented this, although it could easily
be added to ICET by modifying the fitness function.
Third, the cost of a test can be a function of the results of other tests. For example, drawing blood from a newborn is more costly than drawing blood from an adult. To assign a cost
to a blood test, we need to know the age of the patient. The age of the patient can be represented as the result of another test  the patient-age test. This is slightly more complex
than the preceding cases, because we must now insure that the blood test is always accompanied with the patient-age test. We have not implemented this, although it could be added to
ICET.
Fourth, the cost of a test can be a function of the test result. For example, injecting a
radio-opaque die for an X-ray might cause an allergic reaction in the patient. This risk should
be added to the cost of the test. This makes the cost of the test a function of one of the possible outcomes of the test. In a situation like this, it may be wise to precede the injection of the
die with a screening test for allergies. This could be as simple as asking a question to the
patient. This question may have no relevance at all for determining the correct diagnosis of
398

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

the patient, but it may serve to reduce the average cost of classification. This case is similar
to the third case, above. Again, we have not implemented this, although it could be added to
ICET.
Attribute selection in EG2, CS-ID3, and IDX shares a common form. We may view
n
attribute selection as a function from  to { 1, , n } , which takes as input n information
gain values I 1, , I n (one for each attribute) and generates as output the index of one of
the attributes. We may view C 1, , C n and  as parameters in the attribute selection function. These parameters may be used to control the bias of the attribute selection procedure. In
this view, ICET uses GENESIS to tune the parameters of EG2s attribute selection function.
In the future, we would like to investigate more general attribute selection functions. For
n
example, we might use a neural network to implement a function from  to { 1, , n } .
GENESIS would then be used to tune the weights in the neural network.18 The attribute
selection function might also benefit from the addition of an input that specifies the depth of
the decision tree at the current node, where the information gain values are measured. This
would enable the bias for a test to vary, depending on how many tests have already been
selected.
Another area for future work is to explore the parameter settings that control GENESIS
(Table 4). There are many parameters that could be adjusted in GENESIS. We think it is significant that ICET works well with the default parameter settings in GENESIS, since it
shows that ICET is robust with respect to the parameters. However, it might be possible to
substantially improve the performance of ICET by tuning some of these parameters. A recent
trend in genetic algorithm research is to let the genetic algorithm adjust some of its own
parameters, such as mutation rate and crossover rate (Whitley et al., 1993). Another possibility is to stop breeding when the fitness levels stop improving, instead of stopping after a
fixed number of generations. Provost and Buchanan (in press) use a goodness measure as a
stopping condition for the bias space search.

6. Conclusions
The central problem investigated here is the problem of minimizing the cost of classification
when the tests are expensive. We argued that this requires assigning a cost to classification
errors. We also argued that a decision tree is the natural form of knowledge representation
for this type of problem. We then presented a general method for calculating the average cost
of classification for a decision tree, given a decision tree, information on the calculation of
test costs, a classification cost matrix, and a set of testing data. This method is applicable to
standard classification decision trees, without regard to how the decision tree is generated.
The method is sensitive to test costs, sensitive to classification error costs, capable of handling conditional test costs, and capable of handling delayed tests.
We introduced ICET, a hybrid genetic decision tree induction algorithm. ICET uses a
genetic algorithm to evolve a population of biases for a decision tree induction algorithm.
Each individual in the population represents one set of biases. The fitness of an individual is
determined by using it to generate a decision tree with a training dataset, then calculating the
average cost of classification for the decision tree with a testing dataset.
We analyzed the behavior of ICET in a series of experiments, using five real-world medical datasets. Three groups of experiments were performed. The first group looked at the
baseline performance of the five algorithms on the five datasets. ICET was found to have sig18. This idea was suggested in conversation by M. Brooks.

399

fiT URNEY

nificantly lower costs than the other algorithms. Although it executes more slowly, an average time of 23 minutes (for a typical dataset) is acceptable for many applications, and there
is the possibility of much greater speed on a parallel machine. The second group of experiments studied the robustness of ICET under a variety of modifications to its input. The
results show that ICET is robust. The third group of experiments examined ICETs search in
bias space. We discovered that the search could be improved by seeding the initial population of biases.
In general, our research is concerned with pragmatic constraints on classification problems (Provost & Buchanan, in press). We believe that many real-world classification problems involve more than merely maximizing accuracy (Turney, in press). The results
presented here indicate that, in certain applications, a decision tree that merely maximizes
accuracy (e.g., trees generated by C4.5) may be far from the performance that is possible
with an algorithm that considers such realistic constraints as test costs, classification error
costs, conditional test costs, and delayed test results. These are just a few of the pragmatic
constraints that are faced in real-world classification problems.

Appendix A. Five Medical Datasets
This appendix presents the test costs for five medical datasets, taken from the Irvine collection (Murphy & Aha, 1994). The costs are based on information from the Ontario Ministry of
Health (1992). Although none of the medical data were gathered in Ontario, it is reasonable
to assume that other areas have similar relative test costs. For our purposes, the relative costs
are important, not the absolute costs.
A.1

BUPA Liver Disorders

The BUPA Liver Disorders dataset was created by BUPA Medical Research Ltd. and it was
donated to the Irvine collection by Richard Forsyth.19 Table 15 shows the test costs for the
BUPA Liver Disorders dataset. The tests in group A are blood tests that are thought to be
sensitive to liver disorders that might arise from excessive alcohol consumption. These tests
share the common cost of $2.10 for collecting blood. The target concept was defined using
the sixth column: Class 0 was defined as drinks < 3 and class 1 was defined as drinks 
3. Table 16 shows the general form of the classification cost matrix that was used in the
experiments in Section 4. For most of the experiments, the classification error cost equals the
positive error cost equals the negative error cost. The exception is in Section 4.2.3, for the
experiments with complex classification cost matrices. The terms positive error cost and
negative error cost are explained in Section 4.2.3. There are 345 cases in this dataset, with
no missing values. Column seven was originally used to split the data into training and testing sets. We did not use this column, since we required ten different random splits of the
data. In our ten random splits, the ten training sets all had 230 cases and the ten testing sets
all had 115 cases.
A.2

Heart Disease

The Heart Disease dataset was donated to the Irvine collection by David Aha.20 The princi19. The BUPA Liver Disorders dataset has the URL ftp://ftp.ics.uci.edu/pub/machine-learning-databases/liverdisorders/bupa.data.
20. The Heart Disease dataset has the URL ftp://ftp.ics.uci.edu/pub/machine-learning-databases/heart-disease/
cleve.mod.

400

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

Table 15: Test costs for the BUPA Liver Disorders dataset.
Test

Description

Group

Cost

Delayed

1

mcv

mean corpuscular volume

A

$7.27 if first test in group A,
$5.17 otherwise

yes

2

alkphos

alkaline phosphotase

A

$7.27 if first test in group A,
$5.17 otherwise

yes

3

sgpt

alamine aminotransferase

A

$7.27 if first test in group A,
$5.17 otherwise

yes

4

sgot

aspartate aminotransferase

A

$7.27 if first test in group A,
$5.17 otherwise

yes

5

gammagt

gamma-glutamyl transpeptidase

A

$9.86 if first test in group A,
$7.76 otherwise

yes

6

drinks

number of half-pint equivalents of
alcoholic beverages drunk per day

diagnostic class: drinks < 3
or drinks  3

-

7

selector

field used to split data into two sets

not used

-

Table 16: Classification costs for the BUPA Liver Disorders dataset.
Actual Class

Guess Class

Cost

0 (drinks < 3)

0 (drinks < 3)

$0.00

0 (drinks < 3)

1 (drinks  3)

Positive Error Cost

1 (drinks  3)

0 (drinks < 3)

Negative Error Cost

1 (drinks  3)

1 (drinks  3)

$0.00

pal medical investigator was Robert Detrano, of the Cleveland Clinic Foundation. Table 17
shows the test costs for the Heart Disease dataset. A nominal cost of $1.00 was assigned to
the first four tests. The tests in group A are blood tests that are thought to be relevant for
heart disease. These tests share the common cost of $2.10 for collecting blood. The tests in
groups B and C involve measurements of the heart during exercise. A nominal cost of $1.00
was assigned for tests after the first test in each of these groups. The class variable has the
values buff (healthy) and sick. There was a fifteenth column, which specified the class
variable as H (healthy), S1, S2, S3, or S4 (four different types of sick), but we
deleted this column. Table 18 shows the classification cost matrix. There are 303 cases in
this dataset. We deleted all cases for which there were missing values. This reduced the
dataset to 296 cases. In our ten random splits, the training sets had 197 cases and the testing
sets had 99 cases.
A.3

Hepatitis Prognosis

The Hepatitis Prognosis dataset was donated by Gail Gong.21 Table 19 shows the test costs
for the Hepatitis dataset. Unlike the other four datasets, this dataset deals with prognosis, not
21. The Hepatitis Prognosis dataset has the URL ftp://ftp.ics.uci.edu/pub/machine-learning-databases/hepatitis/
hepatitis.data.

401

fiT URNEY

Table 17: Test costs for the Heart Disease dataset.
Test

Description

1

age

2

Group

Cost

Delayed

age in years

$1.00

no

sex

patients gender

$1.00

no

3

cp

chest pain type

$1.00

no

4

trestbps

resting blood pressure

$1.00

no

5

chol

serum cholesterol

A

$7.27 if first test in group A,
$5.17 otherwise

yes

6

fbs

fasting blood sugar

A

$5.20 if first test in group A,
$3.10 otherwise

yes

7

restecg

resting electrocardiograph

$15.50

yes

8

thalach

maximum heart rate
achieved

B

$102.90 if first test in group B,
$1.00 otherwise

yes

9

exang

exercise induced angina

C

$87.30 if first test in group C,
$1.00 otherwise

yes

10

oldpeak

ST depression induced by
exercise relative to rest

C

$87.30 if first test in group C,
$1.00 otherwise

yes

11

slope

slope of peak exercise ST
segment

C

$87.30 if first test in group C,
$1.00 otherwise

yes

12

ca

number of major vessels
coloured by fluoroscopy

$100.90

yes

13

thal

3 = normal; 6 = fixed defect;
7 = reversible defect

$102.90 if first test in group B,
$1.00 otherwise

yes

14

num

diagnosis of heart disease

diagnostic class

-

B

Table 18: Classification costs for the Heart Disease dataset.
Actual Class

Guess Class

Cost

buff

buff

$0.00

buff

sick

Positive Error Cost

sick

buff

Negative Error Cost

sick

sick

$0.00

diagnosis. With prognosis, the diagnosis is known, and the problem is to determine the likely
outcome of the disease. The tests that were assigned a nominal cost of $1.00 either involve
asking a question to the patient or performing a basic physical examination on the patient.
The tests in group A share the cost of $2.10 for collecting blood. Note that, although performing a histological examination of the liver costs $81.64, asking the patient whether a
histology was performed only costs $1.00. Thus the prognosis can exploit the information
conveyed by a decision (to perform a histological examination) that was made during the
diagnosis. The class variable has the values 1 (die) and 2 (live). Table 20 shows the classification costs. The dataset contains 155 cases, with many missing values. In our ten random
402

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

Table 19: Test costs for the Hepatitis Prognosis dataset.
Test

Description

1

class

2

Group

Cost

Delayed

prognosis of hepatitis

prognostic class: live or die

-

age

age in years

$1.00

no

3

sex

gender

$1.00

no

4

steroid

patient on steroids

$1.00

no

5

antiviral

patient on antiviral

$1.00

no

6

fatigue

patient reports fatigue

$1.00

no

7

malaise

patient reports malaise

$1.00

no

8

anorexia

patient anorexic

$1.00

no

9

liver big

liver big on physical exam

$1.00

no

10

liver firm

liver firm on physical exam

$1.00

no

11

spleen palpable

spleen palpable on physical

$1.00

no

12

spiders

spider veins visible

$1.00

no

13

ascites

ascites visible

$1.00

no

14

varices

varices visible

$1.00

no

15

bilirubin

bilirubin  blood test

A

$7.27 if first test in group A,
$5.17 otherwise

yes

16

alk phosphate

alkaline phosphotase

A

$7.27 if first test in group A,
$5.17 otherwise

yes

17

sgot

aspartate aminotransferase

A

$7.27 if first test in group A,
$5.17 otherwise

yes

18

albumin

albumin  blood test

A

$7.27 if first test in group A,
$5.17 otherwise

yes

19

protime

protime  blood test

A

$8.30 if first test in group A,
$6.20 otherwise

yes

20

histology

was histology performed?

$1.00

no

Table 20: Classification costs for the Hepatitis Prognosis dataset.
Actual Class

Guess Class

Cost

1 (die)

1 (die)

$0.00

1 (die)

2 (live)

Negative Error Cost

2 (live)

1 (die)

Positive Error Cost

2 (live)

2 (live)

$0.00

splits, the training sets had 103 cases and the testing sets had 52 cases. We filled in the missing values, using a simple single nearest neighbor algorithm (Aha et al., 1991). The missing
values were filled in using the whole dataset, before the dataset was split into training and
testing sets. For the nearest neighbor algorithm, the data were normalized so that the mini403

fiT URNEY

mum value of a feature was 0 and the maximum value was 1. The distance measure used was
the sum of the absolute values of the differences. The difference between two values was
defined to be 1 if one or both of the two values was missing.
A.4

Pima Indians Diabetes

The Pima Indians Diabetes dataset was donated by Vincent Sigillito. 22 The data were collected by the National Institute of Diabetes and Digestive and Kidney Diseases. Table 21
shows the test costs for the Pima Indians Diabetes dataset. The tests in group A share the
cost of $2.10 for collecting blood. The remaining tests were assigned a nominal cost of
$1.00. All of the patients were females at least 21 years old of Pima Indian heritage. The
class variable has the values 0 (healthy) and 1 (diabetes). Table 22 shows classification costs.
The dataset includes 768 cases, with no missing values. In our ten random splits, the training
sets had 512 cases and the testing sets had 256 cases.
Table 21: Test costs for the Pima Indians Diabetes dataset.
Test

Description

Group

Cost

Delayed

1

times pregnant

number of times pregnant

$1.00

no

2

glucose tol

glucose tolerance test

$17.61 if first test in group A,
$15.51 otherwise

yes

3

diastolic bp

diastolic blood pressure

$1.00

no

4

triceps

triceps skin fold thickness

$1.00

no

5

insulin

serum insulin test

$22.78 if first test in group A,
$20.68 otherwise

yes

6

mass index

body mass index

$1.00

no

7

pedigree

diabetes pedigree function

$1.00

no

8

age

age in years

$1.00

no

9

class

diagnostic class

diagnostic class

-

A

A

Table 22: Classification costs for the Pima Indians Diabetes dataset.

A.5

Actual Class

Guess Class

Cost

0 (healthy)

0 (healthy)

$0.00

0 (healthy)

1 (diabetes)

Positive Error Cost

1 (diabetes)

0 (healthy)

Negative Error Cost

1 (diabetes)

1 (diabetes)

$0.00

Thyroid Disease

The Thyroid Disease dataset was created by the Garavan Institute, Sydney, Australia. The
file was donated by Randolf Werner, obtained from Daimler-Benz. Daimler-Benz obtained
22. The Pima Indians Diabetes dataset has the URL ftp://ftp.ics.uci.edu/pub/machine-learning-databases/pimaindians-diabetes/pima-indians-diabetes.data.

404

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

the data from J.R. Quinlan.23 Table 23 shows the test costs for the Thyroid Disease dataset.
A nominal cost of $1.00 was assigned to the first 16 tests. The tests in group A share the cost
of $2.10 for collecting blood. The FTI test involves a calculation based on the results of the
TT4 and T4U tests. This complicates the calculation of the costs of these three tests, so we
chose not to use the FTI test in our experiments. The class variable has the values 1
(hypothyroid), 2 (hyperthyroid), and 3 (normal). Table 24 shows the classification costs.
There are 3772 cases in this dataset, with no missing values. In our ten random splits, the
training sets had 2515 cases and the testing sets had 1257 cases.
Table 23: Test costs for the Thyroid Disease dataset.
Test

Description

1

age

2

Group

Cost

Delayed

age in years

$1.00

no

sex

gender

$1.00

no

3

on thyroxine

patient on thyroxine

$1.00

no

4

query thyroxine

maybe on thyroxine

$1.00

no

5

on antithyroid

on antithyroid medication

$1.00

no

6

sick

patient reports malaise

$1.00

no

7

pregnant

patient pregnant

$1.00

no

8

thyroid surgery

history of thyroid surgery

$1.00

no

9

I131 treatment

patient on I131 treatment

$1.00

no

10

query hypothyroid

maybe hypothyroid

$1.00

no

11

query hyperthyroid

maybe hyperthyroid

$1.00

no

12

lithium

patient on lithium

$1.00

no

13

goitre

patient has goitre

$1.00

no

14

tumour

patient has tumour

$1.00

no

15

hypopituitary

patient hypopituitary

$1.00

no

16

psych

psychological symptoms

$1.00

no

17

TSH

TSH value, if measured

A

$22.78 if first test in group A, yes
$20.68 otherwise

18

T3

T3 value, if measured

A

$11.41 if first test in group A, yes
$9.31 otherwise

19

TT4

TT4 value, if measured

A

$14.51 if first test in group A, yes
$12.41 otherwise

20

T4U

T4U value, if measured

A

$11.41 if first test in group A, yes
$9.31 otherwise

21

FTI

FTI  calculated from
TT4 and T4U

not used

-

22

class

diagnostic class

diagnostic class

-

23. The Thyroid Disease dataset has the URL ftp://ftp.ics.uci.edu/pub/machine-learning-databases/thyroid-disease/ann-train.data.

405

fiT URNEY

Table 24: Classification costs for the Thyroid Disease dataset.
Actual Class

Guess Class

Cost

1 (hypothyroid)

1 (hypothyroid)

$0.00

1 (hypothyroid)

2 (hyperthyroid)

Minimum(Negative Error Cost, Positive Error Cost)

1 (hypothyroid)

3 (normal)

Negative Error Cost

2 (hyperthyroid)

1 (hypothyroid)

Minimum(Negative Error Cost, Positive Error Cost)

2 (hyperthyroid)

2 (hyperthyroid)

$0.00

2 (hyperthyroid)

3 (normal)

Negative Error Cost

3 (normal)

1 (hypothyroid)

Positive Error Cost

3 (normal)

2 (hyperthyroid)

Positive Error Cost

3 (normal)

3 (normal)

$0.00

Acknowledgments
Thanks to Dr. Louise Linney for her help with interpretation of the Ontario Ministry of
Healths Schedule of Benefits. Thanks to Martin Brooks, Grigoris Karakoulas, Cullen Schaffer, Diana Gordon, Tim Niblett, Steven Minton, and three anonymous referees of JAIR for
their very helpful comments on earlier versions of this paper. This work was presented in
informal talks at the University of Ottawa and the Naval Research Laboratory. Thanks to
both audiences for their feedback.

References
Ackley, D., & Littman, M. (1991). Interactions between learning and evolution. In Proceedings of the Second Conference on Artificial Life, C. Langton, C. Taylor, D. Farmer, and S.
Rasmussen, editors. California: Addison-Wesley.
Aha, D.W., Kibler, D., & Albert, M.K. (1991). Instance-based learning algorithms, Machine
Learning, 6, 37-66.
Aha, D.W., & Bankert, R.L. (1994). Feature selection for case-based classification of cloud
types: An empirical comparison. Case-Based Reasoning: Papers from the 1994 Workshop, edited by D.W. Aha, Technical Report WS-94-07, pp. 106-112. Menlo Park, CA:
AAAI Press.
Anderson, R.W. (in press). Learning and evolution: A quantitative genetics approach. Journal of Theoretical Biology.
Baldwin, J.M. (1896). A new factor in evolution. American Naturalist, 30, 441-451.
Breiman, L., Friedman, J., Olshen, R., & Stone, C. (1984). Classification and regression
trees. California: Wadsworth.
De Jong, K.A., Spears, W.M., & Gordon, D.F. (1993). Using genetic algorithms for concept
learning. Machine Learning, 13, 161-188.

406

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

Fogarty, T.C. (1992). Technical note: First nearest neighbor classification on Frey and Slates
letter recognition problem. Machine Learning, 9, 387-388.
Frey, P.W., & Slate, D.J., (1991). Letter recognition using Holland-style adaptive classifiers.
Machine Learning, 6, 161-182.
Friedman, J.H., & Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistics Association, 76, 817-823.
Gordon, D.F., & Perlis, D. (1989). Explicitly biased generalization. Computational Intelligence, 5, 67-81.
Grefenstette, J.J. (1986). Optimization of control parameters for genetic algorithms. IEEE
Transactions on Systems, Man, and Cybernetics, 16, 122-128.
Grefenstette, J.J., Ramsey, C.L., & Schultz, A.C. (1990). Learning sequential decision rules
using simulation models and competition. Machine Learning, 5, 355-381.
Hermans, J., Habbema, J.D.F., & Van der Burght, A.T. (1974). Cases of doubt in allocation
problems, k populations. Bulletin of the International Statistics Institute, 45, 523-529.
Hinton, G.E., & Nowlan, S.J. (1987). How learning can guide evolution. Complex Systems,
1, 495-502.
Karakoulas, G. (in preparation). A Q-learning approach to cost-effective classification. Technical Report, Knowledge Systems Laboratory, National Research Council Canada. Also
submitted to the Twelfth International Conference on Machine Learning, ML-95.
Knoll, U., Nakhaeizadeh, G., & Tausend, B. (1994). Cost-sensitive pruning of decision trees.
Proceedings of the Eight European Conference on Machine Learning, ECML-94, pp.
383-386. Berlin, Germany: Springer-Verlag.
Koza, J.R. (1992). Genetic Programming: On the programming of computers by means of
natural selection. Cambridge, MA: MIT Press.
Lirov, Y., & Yue, O.-C. (1991). Automated network troubleshooting knowledge acquisition.
Journal of Applied Intelligence, 1, 121-132.
Maynard Smith, J. (1987). When learning guides evolution. Nature, 329, 761-762.
Morgan, C.L. (1896). On modification and variation. Science, 4, 733-740.
Murphy, P.M., & Aha, D.W. (1994). UCI Repository of Machine Learning Databases. University of California at Irvine, Department of Information and Computer Science.
Norton, S.W. (1989). Generating better decision trees. Proceedings of the Eleventh International Joint Conference on Artificial Intelligence, IJCAI-89, pp. 800-805. Detroit, Michigan.
Nez, M. (1988). Economic induction: A case study. Proceedings of the Third European
Working Session on Learning, EWSL-88, pp. 139-145. California: Morgan Kaufmann.

407

fiT URNEY

Nez, M. (1991). The use of background knowledge in decision tree induction. Machine
Learning, 6, 231-250.
Ontario Ministry of Health (1992). Schedule of benefits: Physician services under the health
insurance act, October 1, 1992. Ontario: Ministry of Health.
Pazzani, M., Merz, C., Murphy, P., Ali, K., Hume, T., & Brunk, C. (1994). Reducing misclassification costs: Knowledge-intensive approaches to learning from noisy data. Proceedings of the Eleventh International Conference on Machine Learning, ML-94, pp. 217225. New Brunswick, New Jersey.
Pearl, J. (1984). Heuristics: Intelligent search strategies for computer problem solving. Massachusetts: Addison-Wesley.
Pearl, J. (1988). Probabilistic reasoning in intelligent systems: Networks of plausible inference. California: Morgan Kaufmann.
Pipitone, F., De Jong, K.A., & Spears, W.M. (1991). An artificial intelligence approach to
analog systems diagnosis. In Testing and Diagnosis of Analog Circuits and Systems,
Ruey-wen Liu, editor. New York: Van Nostrand-Reinhold.
Provost, F.J. (1994). Goal-directed inductive learning: Trading off accuracy for reduced error
cost. AAAI Spring Symposium on Goal-Driven Learning.
Provost, F.J., & Buchanan, B.G. (in press). Inductive policy: The pragmatics of bias selection. Machine Learning.
Quinlan, J.R. (1992). C4.5: Programs for machine learning. California: Morgan Kaufmann.
Ragavan, H., & Rendell, L. (1993). Lookahead feature construction for learning hard concepts. Proceedings of the Tenth International Conference on Machine Learning, ML-93,
pp. 252-259. California: Morgan Kaufmann.
Rymon, R. (1993). An SE-tree based characterization of the induction problem. Proceedings
of the Tenth International Conference on Machine Learning, ML-93, pp. 268-275. California: Morgan Kaufmann.
Schaffer, C. (1993). Selecting a classification method by cross-validation. Machine Learning, 13, 135-143.
Schaffer, J.D., Whitley, D., & Eshelman, L.J. (1992). Combinations of genetic algorithms
and neural networks: A survey of the state of the art. In Combinations of Genetic Algorithms and Neural Networks, D. Whitley and J.D. Schaffer, editors. California: IEEE
Computer Society Press.
Seshu, R. (1989). Solving the parity problem. Proceedings of the Fourth European Working
Session on Learning, EWSL-89, pp. 263-271. California: Morgan Kaufmann.
Spears, W.M. (1992). Crossover or mutation? Foundations of Genetic Algorithms 2, FOGA92, edited by D. Whitley. California: Morgan Kaufmann.

408

fiC OST -S ENSITIVE C LASSIFICATION : E MPIRICAL E VALUATION

Sutton, R.S. (1992). Introduction: The challenge of reinforcement learning. Machine Learning, 8, 225-227.
Tan, M., & Schlimmer, J. (1989). Cost-sensitive concept learning of sensor use in approach
and recognition. Proceedings of the Sixth International Workshop on Machine Learning,
ML-89, pp. 392-395. Ithaca, New York.
Tan, M., & Schlimmer, J. (1990). CSL: A cost-sensitive learning system for sensing and
grasping objects. IEEE International Conference on Robotics and Automation. Cincinnati, Ohio.
Tan, M. (1993). Cost-sensitive learning of classification knowledge and its applications in
robotics. Machine Learning, 13, 7-33.
Tcheng, D., Lambert, B., Lu, S., Rendell, L. (1989). Building robust learning systems by
combining induction and optimization. Proceedings of the Eleventh International Joint
Conference on Artificial Intelligence, IJCAI-89, pp. 806-812. Detroit, Michigan.
Turney, P.D. (in press). Technical note: Bias and the quantification of stability. Machine
Learning.
Verdenius, F. (1991). A method for inductive cost optimization. Proceedings of the Fifth
European Working Session on Learning, EWSL-91, pp. 179-191. New York: SpringerVerlag.
Waddington, C.H. (1942). Canalization of development and the inheritance of acquired characters. Nature, 150, 563-565.
Whitley, D., Dominic, S., Das, R., & Anderson, C.W. (1993). Genetic reinforcement learning
for neurocontrol problems. Machine Learning, 13, 259-284.
Whitley, D., & Gruau, F. (1993). Adding learning to the cellular development of neural networks: Evolution and the Baldwin effect. Evolutionary Computation, 1, 213-233.
Whitley, D., Gordon, S., & Mathias, K. (1994). Lamarckian evolution, the Baldwin effect
and function optimization. Parallel Problem Solving from Nature  PPSN III. Y. Davidor, H.P. Schwefel, and R. Manner, editors, pp. 6-15. Berlin: Springer-Verlag.
Wilson, S.W. (1987). Classifier systems and the animat problem. Machine Learning, 2, 199228.

409

fiJournal of Artificial Intelligence Research 2 (1995) 263{286

Submitted 8/94; published 1/95

Solving Multiclass Learning Problems via
Error-Correcting Output Codes
Thomas G. Dietterich

tgd@cs.orst.edu

Department of Computer Science, 303 Dearborn Hall
Oregon State University
Corvallis, OR 97331 USA

Ghulum Bakiri

eb004@isa.cc.uob.bh

Department of Computer Science
University of Bahrain
Isa Town, Bahrain

Abstract

Multiclass learning problems involve finding a definition for an unknown function (x)
whose range is a discrete set containing
2 values (i.e., \classes"). The definition is
acquired by studying collections of training examples of the form hx (x )i. Existing approaches to multiclass learning problems include direct application of multiclass algorithms
such as the decision-tree algorithms C4.5 and CART, application of binary concept learning
algorithms to learn individual binary functions for each of the classes, and application
of binary concept learning algorithms with distributed output representations. This paper
compares these three approaches to a new technique in which error-correcting codes are
employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide
range of multiclass learning tasks. We also demonstrate that this approach is robust with
respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as
decision-tree pruning. Finally, we show that|like the other methods|the error-correcting
code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for
improving the performance of inductive learning programs on multiclass problems.
f

k >

k

i; f

i

k

1. Introduction

The task of learning from examples is to find an approximate definition for an unknown
function f (x) given training examples of the form hx ; f (x )i. For cases in which f takes
only the values f0; 1g|binary functions|there are many algorithms available. For example,
the decision-tree methods, such as C4.5 (Quinlan, 1993) and CART (Breiman, Friedman,
Olshen, & Stone, 1984) can construct trees whose leaves are labeled with binary values.
Most artificial neural network algorithms, such as the perceptron algorithm (Rosenblatt,
1958) and the error backpropagation (BP) algorithm (Rumelhart, Hinton, & Williams,
1986), are best suited to learning binary functions. Theoretical studies of learning have
focused almost entirely on learning binary functions (Valiant, 1984; Natarajan, 1991).
In many real-world learning tasks, however, the unknown function f often takes values
from a discrete set of \classes": fc1; : : : ; c g. For example, in medical diagnosis, the function
might map a description of a patient to one of k possible diseases. In digit recognition (e.g.,
i

i

k

c 1995 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

fiDietterich & Bakiri
LeCun, Boser, Denker, Henderson, Howard, Hubbard, & Jackel, 1989), the function maps
each hand-printed digit to one of k = 10 classes. Phoneme recognition systems (e.g., Waibel,
Hanazawa, Hinton, Shikano, & Lang, 1989) typically classify a speech segment into one of
50 to 60 phonemes.
Decision-tree algorithms can be easily generalized to handle these \multiclass" learning
tasks. Each leaf of the decision tree can be labeled with one of the k classes, and internal
nodes can be selected to discriminate among these classes. We will call this the direct
multiclass approach.
Connectionist algorithms are more dicult to apply to multiclass problems. The standard approach is to learn k individual binary functions f1 ; : : : ; f , one for each class. To
assign a new case, x, to one of these classes, each of the f is evaluated on x, and x is
assigned the class j of the function f that returns the highest activation (Nilsson, 1965).
We will call this the one-per-class approach, since one binary function is learned for each
class.
An alternative approach explored by some researchers is to employ a distributed output
code. This approach was pioneered by Sejnowski and Rosenberg (1987) in their widelyknown NETtalk system. Each class is assigned a unique binary string of length n; we will
refer to these strings as \codewords." Then n binary functions are learned, one for each bit
position in these binary strings. During training for an example from class i, the desired
outputs of these n binary functions are specified by the codeword for class i. With artificial
neural networks, these n functions can be implemented by the n output units of a single
network.
New values of x are classified by evaluating each of the n binary functions to generate an
n-bit string s. This string is then compared to each of the k codewords, and x is assigned to
the class whose codeword is closest, according to some distance measure, to the generated
string s.
As an example, consider Table 1, which shows a six-bit distributed code for a ten-class
digit-recognition problem. Notice that each row is distinct, so that each class has a unique
codeword. As in most applications of distributed output codes, the bit positions (columns)
have been chosen to be meaningful. Table 2 gives the meanings for the six columns. During
learning, one binary function will be learned for each column. Notice that each column is
also distinct and that each binary function to be learned is a disjunction of the original
classes. For example, f (x) = 1 if f (x) is 1, 4, or 5.
To classify a new hand-printed digit, x, the six functions f ; f ; f ; f ; f ; and f
are evaluated to obtain a six-bit string, such as 110001. Then the distance of this string
to each of the ten codewords is computed. The nearest codeword, according to Hamming
distance (which counts the number of bits that differ), is 110000, which corresponds to class
4. Hence, this predicts that f (x) = 4.
This process of mapping the output string to the nearest codeword is identical to the decoding step for error-correcting codes (Bose & Ray-Chaudhuri, 1960; Hocquenghem, 1959).
This suggests that there might be some advantage to employing error-correcting codes as
a distributed representation. Indeed, the idea of employing error-correcting, distributed
representations can be traced to early research in machine learning (Duda, Machanik, &
Singleton, 1963).
k

i

j

vl

vl

264

hl

dl

cc

ol

or

fiError-Correcting Output Codes

Table 1: A distributed code for the digit recognition task.
Class
0
1
2
3
4
5
6
7
8
9

vl
0
1
0
0
1
1
0
0
0
0

Code Word
hl dl cc ol
0 0 1 0
0 0 0 0
1 1 0 1
0 0 0 1
1 0 0 0
1 0 0 1
0 1 1 0
0 1 0 0
0 0 1 0
0 1 1 0

or
0
0
0
0
0
0
1
0
0
0

Table 2: Meanings of the six columns for the code in Table 1.
Column position Abbreviation
Meaning
1
vl
contains vertical line
2
hl
contains horizontal line
3
dl
contains diagonal line
4
cc
contains closed curve
5
ol
contains curve open to left
6
or
contains curve open to right
Table 3: A 15-bit error-correcting output code for a ten-class problem.
Class
0
1
2
3
4
5
6
7
8
9

f0

1
0
1
0
1
0
1
0
1
0

f1

1
0
0
0
1
1
0
0
1
1

f2

0
1
0
1
1
0
1
0
0
1

f3

0
1
1
1
0
0
1
1
1
1

f4

0
1
0
0
1
1
1
1
0
0

f5

0
1
0
1
0
1
0
1
1
0

f6

1
0
0
1
1
0
0
1
1
0

Code Word
f7

0
1
1
1
1
1
0
0
0
0

265

f8

1
0
1
0
0
1
0
1
0
1

f9

0
1
1
0
0
1
1
0
1
0

f10

0
1
1
0
1
0
0
1
0
1

f11

1
0
0
0
0
0
1
1
0
0

f12

1
0
1
1
0
0
0
0
0
0

f13

0
1
0
0
0
0
0
0
1
1

f14

1
0
1
1
1
1
1
1
1
1

fiDietterich & Bakiri
Table 3 shows a 15-bit error-correcting code for the digit-recognition task. Each class is
represented by a code word drawn from an error-correcting code. As with the distributed
encoding of Table 1, a separate boolean function is learned for each bit position of the errorcorrecting code. To classify a new example x, each of the learned functions f0 (x); : : :; f14(x)
is evaluated to produce a 15-bit string. This is then mapped to the nearest of the ten
codewords. This code can correct up to three errors out of the 15 bits.
This error-correcting code approach suggests that we view machine learning as a kind
of communications problem in which the identity of the correct output class for a new
example is being \transmitted" over a channel. The channel consists of the input features,
the training examples, and the learning algorithm. Because of errors introduced by the
finite training sample, poor choice of input features, and aws in the learning process,
the class information is corrupted. By encoding the class in an error-correcting code and
\transmitting" each bit separately (i.e., via a separate run of the learning algorithm), the
system may be able to recover from the errors.
This perspective further suggests that the one-per-class and \meaningful" distributed
output approaches will be inferior, because their output representations do not constitute
robust error-correcting codes. A measure of the quality of an error-correcting code is the
minimum Hamming distance between any pair of code words. If the minimum Hamming
distance is d, then the code can correct at least b ,2 1 c single bit errors. This is because each
single bit error moves us one unit away from the true codeword (in Hamming distance). If
we make only b ,2 1 c errors, the nearest codeword will still be the correct codeword. (The
code of Table 3 has minimum Hamming distance seven and hence it can correct errors in
any three bit positions.) The Hamming distance between any two codewords in the oneper-class code is two, so the one-per-class encoding of the k output classes cannot correct
any errors.
The minimum Hamming distance between pairs of codewords in a \meaningful" distributed representation tends to be very low. For example, in Table 1, the Hamming
distance between the codewords for classes 4 and 5 is only one. In these kinds of codes, new
columns are often introduced to discriminate between only two classes. Those two classes
will therefore differ only in one bit position, so the Hamming distance between their output
representations will be one. This is also true of the distributed representation developed by
Sejnowski and Rosenberg (1987) in the NETtalk task.
In this paper, we compare the performance of the error-correcting code approach to
the three existing approaches: the direct multiclass method (using decision trees), the
one-per-class method, and (in the NETtalk task only) the meaningful distributed output
representation approach. We show that error-correcting codes produce uniformly better
generalization performance across a variety of multiclass domains for both the C4.5 decisiontree learning algorithm and the backpropagation neural network learning algorithm. We
then report a series of experiments designed to assess the robustness of the error-correcting
code approach to various changes in the learning task: length of the code, size of the training
set, assignment of codewords to classes, and decision-tree pruning. Finally, we show that
the error-correcting code approach can produce reliable class probability estimates.
The paper concludes with a discussion of the open questions raised by these results.
Chief among these questions is the issue of why the errors being made in the different bit
positions of the output are somewhat independent of one another. Without this independ

d

266

fiError-Correcting Output Codes
Table 4: Data sets employed in the study.
Name
glass
vowel
POS
soybean
audiologyS
ISOLET
letter
NETtalk

Number of Number of
Number of
Number of
Features
Classes
Training Examples Test Examples
9
6
214
10-fold xval
10
11
528
462
30
12
3,060
10-fold xval
35
19
307
376
69
24
200
26
617
26
6,238
1,559
16
26
16,000
4,000
203
54 phonemes
1000 words =
1000 words =
6 stresses
7,229 letters
7,242 letters

dence, the error-correcting output code method would fail. We address this question|for
the case of decision-tree algorithms|in a companion paper (Kong & Dietterich, 1995).

2. Methods
This section describes the data sets and learning algorithms employed in this study. It
also discusses the issues involved in the design of error-correcting codes and describes four
algorithms for code design. The section concludes with a brief description of the methods
applied to make classification decisions and evaluate performance on independent test sets.

2.1 Data Sets
Table 4 summarizes the data sets employed in the study. The glass, vowel, soybean, audiologyS, ISOLET, letter, and NETtalk data sets are available from the Irvine Repository of
machine learning databases (Murphy & Aha, 1994).1 The POS (part of speech) data set
was provided by C. Cardie (personal communication); an earlier version of the data set was
described by Cardie (1993). We did not use the entire NETtalk data set, which consists of
a dictionary of 20,003 words and their pronunciations. Instead, to make the experiments
feasible, we chose a training set of 1000 words and a disjoint test set of 1000 words at
random from the NETtalk dictionary. In this paper, we focus on the percentage of letters
pronounced correctly (rather than whole words). To pronounce a letter, both the phoneme
and stress of the letter must be determined. Although there are 54  6 syntactically possible
combinations of phonemes and stresses, only 140 of these appear in the training and test
sets we selected.
1. The repository refers to the soybean data set as \soybean-large", the \audiologyS" data set as \audiology.standardized", and the \letter" data set as \letter-recognition".

267

fiDietterich & Bakiri

2.2 Learning Algorithms

We employed two general classes of learning methods: algorithms for learning decision trees
and algorithms for learning feed-forward networks of sigmoidal units (artificial neural networks). For decision trees, we performed all of our experiments using C4.5, Release 1, which
is an older (but substantially identical) version of the program described in Quinlan (1993).
We have made several changes to C4.5 to support distributed output representations, but
these have not affected the tree-growing part of the algorithm. For pruning, the confidence
factor was set to 0.25. C4.5 contains a facility for creating \soft thresholds" for continuous
features. We found experimentally that this improved the quality of the class probability
estimates produced by the algorithm in the \glass", \vowel", and \ISOLET" domains, so
the results reported for those domains were computed using soft thresholds.
For neural networks, we employed two implementations. In most domains, we used the
extremely fast backpropagation implementation provided by the CNAPS neurocomputer
(Adaptive Solutions, 1992). This performs simple gradient descent with a fixed learning
rate. The gradient is updated after presenting each training example; no momentum term
was employed. A potential limitation of the CNAPS is that inputs are only represented
to eight bits of accuracy, and weights are only represented to 16 bits of accuracy. Weight
update arithmetic does not round, but instead performs jamming (i.e., forcing the lowest
order bit to 1 when low order bits are lost due to shifting or multiplication). On the
speech recognition, letter recognition, and vowel data sets, we employed the opt system
distributed by Oregon Graduate Institute (Barnard & Cole, 1989). This implements the
conjugate gradient algorithm and updates the gradient after each complete pass through
the training examples (known as per-epoch updating). No learning rate is required for this
approach.
Both the CNAPS and opt attempt to minimize the squared error between the computed
and desired outputs of the network. Many researchers have employed other error measures,
particularly cross-entropy (Hinton, 1989) and classification figure-of-merit (CFM, Hampshire II & Waibel, 1990). Many researchers also advocate using a softmax normalizing layer
at the outputs of the network (Bridle, 1990). While each of these configurations has good
theoretical support, Richard and Lippmann (1991) report that squared error works just as
well as these other measures in producing accurate posterior probability estimates. Furthermore, cross-entropy and CFM tend to overfit more easily than squared error (Lippmann,
personal communication; Weigend, 1993). We chose to minimize squared error because this
is what the CNAPS and opt systems implement.
With either neural network algorithm, several parameters must be chosen by the user.
For the CNAPS, we must select the learning rate, the initial random seed, the number
of hidden units, and the stopping criteria. We selected these to optimize performance
on a validation set, following the methodology of Lang, Hinton, and Waibel (1990). The
training set is subdivided into a subtraining set and a validation set. While training on the
subtraining set, we observed generalization performance on the validation set to determine
the optimal settings of learning rate and network size and the best point at which to
stop training. The training set mean squared error at that stopping point is computed,
and training is then performed on the entire training set using the chosen parameters and
stopping at the indicated mean squared error. Finally, we measure network performance
on the test set.
268

fiError-Correcting Output Codes
For most of the data sets, this procedure worked very well. However, for the letter
recognition data set, it was clearly choosing poor stopping points for the full training set.
To overcome this problem, we employed a slightly different procedure to determine the
stopping epoch. We trained on a series of progressively larger training sets (all of which
were subsets of the final training set). Using a validation set, we determined the best
stopping epoch on each of these training sets. We then extrapolated from these training
sets to predict the best stopping epoch on the full training set.
For the \glass" and \POS" data sets, we employed ten-fold cross-validation to assess
generalization performance. We chose training parameters based on only one \fold" of the
ten-fold cross-validation. This creates some test set contamination, since examples in the
validation set data of one fold are in the test set data of other folds. However, we found
that there was little or no overfitting, so the validation set had little effect on the choice of
parameters or stopping points.
The other data sets all come with designated test sets, which we employed to measure
generalization performance.

2.3 Error-Correcting Code Design

We define an error-correcting code to be a matrix of binary values such as the matrix shown
in Table 3. The length of a code is the number of columns in the code. The number of
rows in the code is equal to the number of classes in the multiclass learning problem. A
\codeword" is a row in the code.
A good error-correcting output code for a k-class problem should satisfy two properties:
 Row separation. Each codeword should be well-separated in Hamming distance
from each of the other codewords.
 Column separation. Each bit-position function f should be uncorrelated with the
functions to be learned for the other bit positions f ; j 6= i: This can be achieved by
insisting that the Hamming distance between column i and each of the other columns
be large and that the Hamming distance between column i and the complement of
each of the other columns also be large.
i

j

The power of a code to correct errors is directly related to the row separation, as
discussed above. The purpose of the column separation condition is less obvious. If two
columns i and j are similar or identical, then when a deterministic learning algorithm
such as C4.5 is applied to learn f and f , it will make similar (correlated) mistakes. Errorcorrecting codes only succeed if the errors made in the individual bit positions are relatively
uncorrelated, so that the number of simultaneous errors in many bit positions is small. If
there are many simultaneous errors, the error-correcting code will not be able to correct
them (Peterson & Weldon, 1972).
The errors in columns i and j will also be highly correlated if the bits in those columns
are complementary. This is because algorithms such as C4.5 and backpropagation treat
a class and its complement symmetrically. C4.5 will construct identical decision trees if
the 0-class and 1-class are interchanged. The maximum Hamming distance between two
columns is attained when the columns are complements. Hence, the column separation
condition attempts to ensure that columns are neither identical nor complementary.
i

j

269

fiDietterich & Bakiri

Table 5: All possible columns for a three-class problem. Note that the last four columns
are complements of the first four and that the first column does not discriminate
among any of the classes.
Class
c0
c1
c2

f0

0
0
0

f1

0
0
1

f2

0
1
0

Code Word
f3

f4

0
1
1

1
0
0

f5

1
0
1

f6

1
1
0

f7

1
1
1

Unless the number of classes is at least five, it is dicult to satisfy both of these properties. For example, when the number of classes is three, there are only 23 = 8 possible
columns (see Table 5). Of these, half are complements of the other half. So this leaves us
with only four possible columns. One of these will be either all zeroes or all ones, which
will make it useless for discriminating among the rows. The result is that we are left with
only three possible columns, which is exactly what the one-per-class encoding provides.
In general, if there are k classes, there will be at most 2 ,1 , 1 usable columns after
removing complements and the all-zeros or all-ones column. For four classes, we get a
seven-column code with minimum inter-row Hamming distance 4. For five classes, we get
a 15-column code, and so on.
We have employed four methods for constructing good error-correcting output codes
in this paper: (a) an exhaustive technique, (b) a method that selects columns from an
exhaustive code, (c) a method based on a randomized hill-climbing algorithm, and (d) BCH
codes. The choice of which method to use is based on the number of classes, k. Finding a
single method suitable for all values of k is an open research problem. We describe each of
our four methods in turn.
k

2.3.1 Exhaustive Codes

When 3  k  7, we construct a code of length 2 ,1 , 1 as follows. Row 1 is all ones. Row 2
consists of 2 ,2 zeroes followed by 2 ,2 , 1 ones. Row 3 consists of 2 ,3 zeroes, followed by
2 ,3 ones, followed by 2 ,3 zeroes, followed by 2 ,3 , 1 ones. In row i, there are alternating
runs of 2 , zeroes and ones. Table 6 shows the exhaustive code for a five-class problem.
This code has inter-row Hamming distance 8; no columns are identical or complementary.
k

k

k

k

k

k

k

k

i

2.3.2 Column Selection from Exhaustive Codes

When 8  k  11, we construct an exhaustive code and then select a good subset of
its columns. We formulate this as a propositional satisfiability problem and apply the
GSAT algorithm (Selman, Levesque, & Mitchell, 1992) to attempt a solution. A solution
is required to include exactly L columns (the desired length of the code) while ensuring
that the Hamming distance between every two columns is between d and L , d, for some
chosen value of d. Each column is represented by a boolean variable. A pairwise mutual
270

fiError-Correcting Output Codes

Row

1
1
0
0
0
0

1
2
3
4
5

2
1
0
0
0
1

Table 6: Exhaustive code for k=5.
Column
3 4 5 6 7 8 9 10 11 12
1 1 1 1 1 1 1 1 1 1
0 0 0 0 0 0 1 1 1 1
0 0 1 1 1 1 0 0 0 0
1 1 0 0 1 1 0 0 1 1
0 1 0 1 0 1 0 1 0 1

13
1
1
1
0
0

14
1
1
1
0
1

1

0

1

0

1

0

0

1

15
1
1
1
1
0

Figure 1: Hill-climbing algorithm for improving row and column separation. The two closest
rows and columns are indicated by lines. Where these lines intersect, the bits in
the code words are changed to improve separations as shown on the right.
exclusion constraint is placed between any two columns that violate the column separation
condition. To support these constraints, we extended GSAT to support mutual exclusion
and \m-of-n" constraints eciently.
2.3.3 Randomized Hill Climbing

For k > 11, we employed a random search algorithm that begins by drawing k random
strings of the desired length L. Any pair of such random strings will be separated by a
Hamming distance that is binomially distributed with mean L=2. Hence, such randomly
generated codes are generally quite good on average. To improve them, the algorithm
repeatedly finds the pair of rows closest together in Hamming distance and the pair of
columns that have the \most extreme" Hamming distance (i.e., either too close or too
far apart). The algorithm then computes the four codeword bits where these rows and
columns intersect and changes them to improve the row and column separations as shown
in Figure 1. When this hill climbing procedure reaches a local maximum, the algorithm
randomly chooses pairs of rows and columns and tries to improve their separations. This
combined hill-climbing/random-choice procedure is able to improve the minimum Hamming
distance separation quite substantially.
271

fiDietterich & Bakiri
2.3.4 BCH Codes

For k > 11 we also applied the BCH algorithm to design codes (Bose & Ray-Chaudhuri,
1960; Hocquenghem, 1959). The BCH algorithm employs algebraic methods from Galois
field theory to design nearly optimal error-correcting codes. However, there are three practical drawbacks to using this algorithm. First, published tables of the primitive polynomials
required by this algorithm only produce codes up to length 64, since this is the largest word
size employed in computer memories. Second, the codes do not always exhibit good column
separations. Third, the number of rows in these codes is always a power of two. If the number of classes k in our learning problem is not a power of two, we must shorten the code by
deleting rows (and possible columns) while maintaining good row and column separations.
We have experimented with various heuristic greedy algorithms for code shortening. For
most of the codes used in the NETtalk, ISOLET, and Letter Recognition domains, we have
used a combination of simple greedy algorithms and manual intervention to design good
shortened BCH codes.
In each of the data sets that we studied, we designed a series of error-correcting codes
of increasing lengths. We executed each learning algorithm for each of these codes. We
stopped lengthening the codes when performance appeared to be leveling off.

2.4 Making Classification Decisions
Each approach to solving multiclass problems|direct multiclass, one-per-class, and errorcorrecting output coding|assumes a method for classifying new examples. For the C4.5
direct multiclass approach, the C4.5 system computes a class probability estimate for each
new example. This estimates the probability that that example belongs to each of the
k classes. C4.5 then chooses the class having the highest probability as the class of the
example.
For the one-per-class approach, each decision tree or neural network output unit can
be viewed as computing the probability that the new example belongs to its corresponding
class. The class whose decision tree or output unit gives the highest probability estimate
is chosen as the predicted class. Ties are broken arbitrarily in favor of the class that comes
first in the class ordering.
For the error-correcting output code approach, each decision tree or neural network
output unit can be viewed as computing the probability that its corresponding bit in the
codeword is one. Call these probability values B = hb1; b2; : : : ; b i, where n is the length of
the codewords in the error-correcting code. To classify a new example, we compute the L1
distance between this probability vector B and each of the codewords W (i = 1 : : :k) in
the error correcting code. The L1 distance between B and W is defined as
n

i

L1 (B; Wi)

=

Xj

i

L

j

=0

bj

, W j:
i;j

The class whose codeword has the smallest L1 distance to B is assigned as the class of the
new example. Ties are broken arbitrarily in favor of the class that comes first in the class
ordering.
272

fiPerformance relative to Multiclass

So
yb
ea
n
A
ud
io
lo
gy
IS
O
LE
T
Le
tte
r
N
ET
ta
lk

PO

S

el
ow
V

G

la

ss

Error-Correcting Output Codes

*

10

*

*
*

*

*

0

C4.5 Multiclass
*
*

-10

*

-20
-30

*

C4.5 one-per-class

C4.5 ECOC

Figure 2: Performance (in percentage points) of the one-per-class and ECOC methods relative to the direct multiclass method using C4.5. Asterisk indicates difference is
significant at the 0.05 level or better.

3. Results
We now present the results of our experiments. We begin with the results for decision trees.
Then, we consider neural networks. Finally, we report the results of a series of experiments
to assess the robustness of the error-correcting output code method.

3.1 Decision Trees
Figure 2 shows the performance of C4.5 in all eight domains. The horizontal line corresponds
to the performance of the standard multiclass decision-tree algorithm. The light bar shows
the performance of the one-per-class approach, and the dark bar shows the performance of
the ECOC approach with the longest error-correcting code tested. Performance is displayed
as the number of percentage points by which each pair of algorithms differ. An asterisk
indicates that the difference is statistically significant at the p < 0:05 level according to the
test for the difference of two proportions (using the normal approximation to the binomial
distribution, see Snedecor & Cochran, 1989, p. 124).
From this figure, we can see that the one-per-class method performs significantly worse
than the multiclass method in four of the eight domains and that its behavior is statistically
indistinguishable in the remaining four domains. Much more encouraging is the observation
that the error-correcting output code approach is significantly superior to the multiclass
approach in six of the eight domains and indistinguishable in the remaining two.
273

fiDietterich & Bakiri
In the NETtalk domain, we can also consider the performance of the meaningful distributed representation developed by Sejnowski and Rosenberg. This representation gave
66.7% correct classification as compared with 68.6% for the one-per-class configuration,
70.0% for the direct-multiclass configuration, and 74.3% for the ECOC configuration. The
differences in each of these figures are statistically significant at the 0.05 level or better
except that the one-per-class and direct-multiclass configurations are not statistically distinguishable.

3.2 Backpropagation

Figure 3 shows the results for backpropagation in five of the most challenging domains.
The horizontal line corresponds to the performance of the one-per-class encoding for this
method. The bars show the number of percentage points by which the error-correcting
output coding representation outperforms the one-per-class representation. In four of the
five domains, the ECOC encoding is superior; the differences are statistically significant in
the Vowel, NETtalk, and ISOLET domains.2
In the letter recognition domain, we encountered great diculty in successfully training
networks using the CNAPS machine, particularly for the ECOC configuration. Experiments
showed that the problem arose from the fact that the CNAPS implementation of backpropagation employs a fixed learning rate. We therefore switched to the much slower opt
program, which chooses the learning rate adaptively via conjugate-gradient line searches.
This behaved better for both the one-per-class and ECOC configurations.
We also had some diculty training ISOLET in the ECOC configuration on large networks (182 units), even with the opt program. Some sets of initial random weights led to
local minima and poor performance on the validation set.
In the NETtalk task, we can again compare the performance of the Sejnowski-Rosenberg
distributed encoding to the one-per-class and ECOC encodings. The distributed encoding
yielded a performance of 71.5% correct, compared to 72.9% for the one-per-class encoding,
and 74.9% for the ECOC encoding. The difference between the distributed encoding and the
one-per-class encoding is not statistically significant. From these results and the previous
results for C4.5, we can conclude that the distributed encoding has no advantages over the
one-per-class and ECOC encoding in this domain.

3.3 Robustness

These results show that the ECOC approach performs as well as, and often better than,
the alternative approaches. However, there are several important questions that must be
answered before we can recommend the ECOC approach without reservation:

 Do the results hold for small samples? We have found that decision trees learned using

error-correcting codes are much larger than those learned using the one-per-class or
multiclass approaches. This suggests that with small sample sizes, the ECOC method
may not perform as well, since complex trees usually require more data to be learned
reliably. On the other hand, the experiments described above covered a wide range of

2. The difference for ISOLET is only detectable using a test for paired differences of proportions. See
Snedecor & Cochran (1989, p. 122.).

274

fiPerformance relative to one-per-class

10

lk
ET
ta
N

te
Le
t

IS
O

r

LE
T

el
ow
V

G

la

ss

Error-Correcting Output Codes

*

5
*
*

0

Backprop one-per-class

Backprop ECOC

Figure 3: Performance of the ECOC method relative to the one-per-class using backpropagation. Asterisk indicates difference is significant at the 0.05 level or better.
training set sizes, which suggests that the results may not depend on having a large
training set.

 Do the results depend on the particular assignment of codewords to classes? The

codewords were assigned to the classes arbitrarily in the experiments reported above,
which suggests that the particular assignment may not be important. However, some
assignments might still be much better than others.

 Do the results depend on whether pruning techniques are applied to the decision-

tree algorithms? Pruning methods have been shown to improve the performance of
multiclass C4.5 in many domains.

 Can the ECOC approach provide class probability estimates? Both C4.5 and back-

propagation can be configured to provide estimates of the probability that a test
example belongs to each of the k possible classes. Can the ECOC approach do this
as well?

3.3.1 Small sample performance

As we have noted, we became concerned about the small sample performance of the ECOC
method when we noticed that the ECOC method always requires much larger decision trees
than the OPC method. Table 7 compares the sizes of the decision trees learned by C4.5
under the multiclass, one-per-class, and ECOC configurations for the letter recognition task
and the NETtalk task. For the OPC and ECOC configurations, the tables show the average
number of leaves in the trees learned for each bit position of the output representation. For
275

fiDietterich & Bakiri

Table 7: Size of decision trees learned by C4.5 for the letter recognition task and the
NETtalk task.
Letter Recognition Leaves per bit Total leaves
Multiclass
2353
One-per-class
242
6292
207-bit ECOC
1606
332383
NETtalk
Multiclass
One-per-Class
159-bit ECOC

Leaves per bit
phoneme stress
61
901

600
911

Total leaves
phoneme stress
1425 1567
3320 3602
114469 29140

letter recognition, the trees learned for a 207-bit ECOC are more than six times larger
than those learned for the one-per-class representation. For the phoneme classification part
of NETtalk, the ECOC trees are 14 times larger than the OPC trees. Another way to
compare the sizes of the trees is to consider the total number of leaves in the trees. The
tables clearly show that the multiclass approach requires much less memory (many fewer
total leaves) than either the OPC or the ECOC approaches.
With backpropagation, it is more dicult to determine the amount of \network resources" that are consumed in training the network. One approach is to compare the
number of hidden units that give the best generalization performance. In the ISOLET task,
for example, the one-per-class encoding attains peak validation set performance with a 78hidden-unit network, whereas the 30-bit error-correcting encoding attained peak validation
set performance with a 156-hidden-unit network. In the letter recognition task, peak performance for the one-per-class encoding was obtained with a network of 120-hidden units
compared to 200 hidden units for a 62-bit error-correcting output code.
From the decision tree and neural network sizes, we can see that, in general, the errorcorrecting output representation requires more complex hypotheses than the one-per-class
representation. From learning theory and statistics, we known that complex hypotheses
typically require more training data than simple ones. On this basis, one might expect that
the performance of the ECOC method would be very poor with small training sets. To test
this prediction, we measured performance as a function of training set size in two of the
larger domains: NETtalk and letter recognition.
Figure 4 presents learning curves for C4.5 on the NETtalk and letter recognition tasks,
which show accuracy for a series of progressively larger training sets. From the figure it is
clear that the 61-bit error-correcting code consistently outperforms the other two configurations by a nearly constant margin. Figure 5 shows corresponding results for backpropagation on the NETtalk and letter recognition tasks. On the NETtalk task, the results are
the same: sample size has no apparent inuence on the benefits of error-correcting output coding. However, for the letter-recognition task, there appears to be an interaction.
276

fiError-Correcting Output Codes

NETtalk

Letter Recognition

75

100
C4 61-bit ECOC

Percent Correct

70

C4 Multiclass
C4 One-per-class

90
C4 Multiclass

65

80

60

70

55

60

50

50

45

40

40

30

35
100

C4 62-bit ECOC

C4 One-per-class

20
100

1000

1000

Training Set Size

10000
Training Set Size

Figure 4: Accuracy of C4.5 in the multiclass, one-per-class, and error-correcting output
coding configurations for increasing training set sizes in the NETtalk and letter
recognition tasks. Note that the horizontal axis is plotted on a logarithmic scale.
NETtalk

Letter Recognition
100

75
90
70

CNAPS 61-bit ECOC

Percent Correct

80
65

opt OPC
opt 62-bit ECOC

70

CNAPS One-per-class

60

60

55

50

50

45
100

1000
Training Set Size (words)

40
100

1000
Training Set Size

10000

Figure 5: Accuracy of backpropagation in the one-per-class and error-correcting output
coding configurations for increasing training set sizes on the NETtalk and letter
recognition tasks.
Error-correcting output coding works best for small training sets, where there is a statistically significant benefit. With the largest training set|16,000 examples|the one-per-class
method very slightly outperforms the ECOC method.
From these experiments, we conclude that error-correcting output coding works very
well with small samples, despite the increased size of the decision trees and the increased
complexity of training neural networks. Indeed, with backpropagation on the letter recognition task, error-correcting output coding worked better for small samples than it did for
277

fiDietterich & Bakiri

Table 8: Five random assignments of codewords to classes for the NETtalk task. Each
column shows the percentage of letters correctly classified by C4.5 decision trees.
Multiclass One-per-class
70.0
68.6

61-Bit Error-Correcting Code Replications
a
b
c
d
e
73.8 73.6 73.5 73.8
73.3

large ones. This effect suggests that ECOC works by reducing the variance of the learning
algorithm. For small samples, the variance is higher, so ECOC can provide more benefit.
3.3.2 Assignment of Codewords to Classes

In all of the results reported thus far, the codewords in the error-correcting code have been
arbitrarily assigned to the classes of the learning task. We conducted a series of experiments
in the NETtalk domain with C4.5 to determine whether randomly reassigning the codewords
to the classes had any effect on the success of ECOC. Table 8 shows the results of five
random assignments of codewords to classes. There is no statistically significant variation
in the performance of the different random assignments. This is consistent with similar
experiments reported in Bakiri (1991).
3.3.3 Effect of Tree Pruning

Pruning of decision trees is an important technique for preventing overfitting. However, the
merit of pruning varies from one domain to another. Figure 6 shows the change in performance due to pruning in each of the eight domains and for each of the three configurations
studied in this paper: multiclass, one-per-class, and error-correcting output coding.
From the figure, we see that in most cases pruning makes no statistically significant
difference in performance (aside from the POS task, where it decreases the performance of
all three configurations). Aside from POS, only one of the statistically significant changes
involves the ECOC configuration, while two affect the one-per-class configuration, and one
affects the multiclass configuration. These data suggest that pruning only occasionally has
a major effect on any of these configurations. There is no evidence to suggest that pruning
affects one configuration more than another.
3.3.4 Class Probability Estimates

In many applications, it is important to have a classifier that cannot only classify new cases
well but also estimate the probability that a new case belongs to each of the k classes.
For example, in medical diagnosis, a simple classifier might classify a patient as \healthy"
because, given the input features, that is the most likely class. However, if there is a
non-zero probability that the patient has a life-threatening disease, the right choice for the
physician may still be to prescribe a therapy for that disease.
A more mundane example involves automated reading of handwritten postal codes on
envelopes. If the classifier is very confident of its classification (i.e., because the estimated
278

fiPerformance relative to no pruning

lk
ET
N

Le

tte

r

ta

T
LE

lo
gy

IS
O

ud

io

an
A

be
So
y

PO

S

el
ow
V

G

la

ss

Error-Correcting Output Codes

10
*

*
*

5

0
-2

No Pruning
**

*
*

C4.5 Multiclass

C4.5 one-per-class

C4.5 ECOC

Figure 6: Change in percentage points of the performance of C4.5 with and without pruning
in three configurations. Horizontal line indicates performance with no pruning.
Asterisk indicates that the difference is significant at the 0.05 level or better.

279

fiDietterich & Bakiri
probabilities are very strong), then it can proceed to route the envelope. However, if it
is uncertain, then the envelope should be \rejected", and sent to a human being who can
attempt to read the postal code and process the envelope (Wilkinson, Geist, Janet, et al.,
1992).
One way to assess the quality of the class probability estimates of a classifier is to
compute a \rejection curve". When the learning algorithm classifies a new case, we require
it to also output a \confidence" level. Then we plot a curve showing the percentage of
correctly classified test cases whose confidence level exceeds a given value. A rejection curve
that increases smoothly demonstrates that the confidence level produced by the algorithm
can be transformed into an accurate probability measure.
For one-per-class neural networks, many researchers have found that the difference in
activity between the class with the highest activity and the class with the second-highest
activity is a good measure of confidence (e.g., LeCun et al., 1989). If this difference is large,
then the chosen class is clearly much better than the others. If the difference is small, then
the chosen class is nearly tied with another class. This same measure can be applied to the
class probability estimates produced by C4.5.
An analogous measure of confidence for error-correcting output codes can be computed
from the L1 distance between the vector B of output probabilities for each bit and the
codewords of each of the classes. Specifically, we employ the difference between the L1
distance to the second-nearest codeword and the L1 distance to the nearest codeword as
our confidence measure. If this difference is large, an algorithm can be quite confident of
its classification decision. If the difference is small, the algorithm is not confident.
Figure 7 compares the rejection curves for various configurations of C4.5 and backpropagation on the NETtalk task. These curves are constructed by first running all of the test
examples through the learned decision trees and computing the predicted class of each example and the confidence value for that prediction. To generate each point along the curve,
a value is chosen for a parameter , which defines the minimum required confidence. The
classified test examples are then processed to determine the percentage of test examples
whose confidence level is less than  (these are \rejected") and the percentage of the remaining examples that are correctly classified. The value of  is progressively incremented
(starting at 0) until all test examples are rejected.
The lower left portion of the curve shows the performance of the algorithm when  is
small, so only the least confident cases are rejected. The upper right portion of the curve
shows the performance when  is large, so only the most confident cases are classified.
Good class probability estimates produce a curve that rises smoothly and monotonically.
A at or decreasing region in a rejection curve reveals cases where the confidence estimate
of the learning algorithm is unrelated or inversely related to the actual performance of the
algorithm.
The rejection curves often terminate prior to rejecting 100% of the examples. This occurs
when the final increment in  causes all examples to be rejected. This gives some idea of the
number of examples for which the algorithm was highly confident of its classifications. If
the curve terminates early, this shows that there were very few examples that the algorithm
could confidently classify.
In Figure 7, we see that|with the exception of the Multiclass configuration|the rejection curves for all of the various configurations of C4.5 increase fairly smoothly, so all of
280

fiError-Correcting Output Codes
C4.5

Backpropagation

100

100
61-bit ECOC

61-bit ECOC

159-bit ECOC

95

95
OPC

OPC

159-bit ECOC

Percent Correct

90
90

Multiclass

Distributed

Distributed

85
85
80
80
75
75

70

65

70
0

10

20

30

40
50
60
Percent Rejected

70

80

90

100

0

10

20

30

40
50
60
Percent Rejected

70

80

Figure 7: Rejection curves for various configurations of C4.5 and backpropagation on the
NETtalk task. The \Distributed" curve plots the behavior of the SejnowskiRosenberg distributed representation.
them are producing acceptable confidence estimates. The two error-correcting configurations have smooth curves that remain above all of the other configurations. This shows that
the performance advantage of error-correcting output coding is maintained at all confidence
levels|ECOC improves classification decisions on all examples, not just the borderline ones.
Similar behavior is seen in the rejection curves for backpropagation. Again all configurations of backpropagation give fairly smooth rejection curves. However, note that the
159-bit code actually decreases at high rejection rates. By contrast, the 61-bit code gives a
monotonic curve that eventually reaches 100%. We have seen this behavior in several of the
cases we have studied: extremely long error-correcting codes are usually the best method
at low rejection rates, but at high rejection rates, codes of \intermediate" length (typically
60-80 bits) behave better. We have no explanation for this behavior.
Figure 8 compares the rejection curves for various configurations of C4.5 and backpropagation on the ISOLET task. Here we see that the ECOC approach is markedly superior
to either the one-per-class or multiclass approaches. This figure illustrates another phenomenon we have frequently observed: the curve for multiclass C4.5 becomes quite at and
terminates very early, and the one-per-class curve eventually surpasses it. This suggests that
there may be opportunities to improve the class probability estimates produced by C4.5
on multiclass trees. (Note that we employed \softened thresholds" in these experiments.)
In the backpropagation rejection curves, the ECOC approach consistently outperforms the
one-per-class approach until both are very close to 100% correct. Note that both configurations of backpropagation can confidently classify more than 50% of the test examples with
100% accuracy.
From these graphs, it is clear that the error-correcting approach (with codes of intermediate length) can provide confidence estimates that are at least as good as those provided
by the standard approaches to multiclass problems.
281

90

100

fiDietterich & Bakiri
C4.5

Backpropagation

100

101
107-bit ECOC

98
45-bit ECOC

100

96

30-bit ECOC

Multiclass
Percent Correct

94

99

92
90

98

One Per Class

88
97

86
84

96

One Per Class
82
80

95
0

10

20

30

40
50
60
Percent Rejected

70

80

90

100

0

5

10

15

20
25
Percent Rejected

30

35

Figure 8: Rejection curves for various configurations of C4.5 and backpropagation on the
ISOLET task.

4. Conclusions

In this paper, we experimentally compared four approaches to multiclass learning problems:
multiclass decision trees, the one-per-class (OPC) approach, the meaningful distributed
output approach, and the error-correcting output coding (ECOC) approach. The results
clearly show that the ECOC approach is superior to the other three approaches. The
improvements provided by the ECOC approach can be quite substantial: improvements on
the order of ten percentage points were observed in several domains. Statistically significant
improvements were observed in six of eight domains with decision trees and three of five
domains with backpropagation.
The improvements were also robust:
 ECOC improves both decision trees and neural networks;
 ECOC provides improvements even with very small sample sizes; and
 The improvements do not depend on the particular assignment of codewords to classes.
The error-correcting approach can also provide estimates of the confidence of classification decisions that are at least as accurate as those provided by existing methods.
There are some additional costs to employing error-correcting output codes. Decision
trees learned using ECOC are generally much larger and more complex than trees constructed using the one-per-class or multiclass approaches. Neural networks learned using
ECOC often require more hidden units and longer and more careful training to obtain
the improved performance (see Section 3.2). These factors may argue against using errorcorrecting output coding in some domains. For example, in domains where it is important
for humans to understand and interpret the induced decision trees, ECOC methods are not
appropriate, because they produce such complex trees. In domains where training must
be rapid and completely autonomous, ECOC methods with backpropagation cannot be
recommended, because of the potential for encountering diculties during training.
282

40

45

fiError-Correcting Output Codes
Finally, we found that error-correcting codes of intermediate length tend to give better
confidence estimates than very long error-correcting codes, even though the very long codes
give the best generalization performance.
There are many open problems that require further research. First and foremost, it is
important to obtain a deeper understanding of why the ECOC method works. If we assume
that each of the learned hypotheses makes classification errors independently, then coding
theory provides the explanation: individual errors can be corrected because the codewords
are \far apart" in the output space. However, because each of the hypotheses is learned
using the same algorithm on the same training data, we would expect that the errors made
by individual hypotheses would be highly correlated, and such errors cannot be corrected by
an error-correcting code. So the key open problem is to understand why the classification
errors at different bit positions are fairly independent. How does the error-correcting output
code result in this independence?
A closely related open problem concerns the relationship between the ECOC approach
and various \ensemble", \committee", and \boosting" methods (Perrone & Cooper, 1993;
Schapire, 1990; Freund, 1992). These methods construct multiple hypotheses which then
\vote" to determine the classification of an example. An error-correcting code can also
be viewed as a very compact form of voting in which a certain number of incorrect votes
can be corrected. An interesting difference between standard ensemble methods and the
ECOC approach is that in the ensemble methods, each hypothesis is attempting to predict
the same function, whereas in the ECOC approach, each hypothesis predicts a different
function. This may reduce the correlations between the hypotheses and make them more
effective \voters." Much more work is needed to explore this relationship.
Another open question concerns the relationship between the ECOC approach and the
exible discriminant analysis technique of Hastie, Tibshirani, and Buja (In Press). Their
method first employs the one-per-class approach (e.g., with neural networks) and then
applies a kind of discriminant analysis to the outputs. This discriminant analysis maps the
outputs into a k , 1 dimensional space such that each class has a defined \center point". New
cases are classified by mapping them into this space and then finding the nearest \center
point" and its class. These center points are similar to our codewords but in a continuous
space of dimension k , 1. It may be that the ECOC method is a kind of randomized,
higher-dimensional variant of this approach.
Finally, the ECOC approach shows promise of scaling neural networks to very large
classification problems (with hundreds or thousands of classes) much better than the oneper-class method. This is because a good error-correcting code can have a length n that is
much less than the total number of classes, whereas the one-per-class approach requires that
there be one output unit for each class. Networks with thousands of output units would
be expensive and dicult to train. Future studies should test the scaling ability of these
different approaches to such large classification tasks.

Acknowledgements
The authors thank the anonymous reviewers for their valuable suggestions which improved
the presentation of the paper. The authors also thank Prasad Tadepalli for proof-reading the
283

fiDietterich & Bakiri
final manuscript. The authors gratefully acknowledge the support of the National Science
Foundation under grants numbered IRI-8667316, CDA-9216172, and IRI-9204129. Bakiri
also thanks Bahrain University for its support of his doctoral research.

References

Adaptive Solutions (1992). CNAPS back-propagation guide. Tech. rep. 801-20030-04, Adaptive Solutions, Inc., Beaverton, OR.
Bakiri, G. (1991). Converting English text to speech: A machine learning approach. Tech.
rep. 91-30-2, Department of Computer Science, Oregon State University, Corvallis,
OR.
Barnard, E., & Cole, R. A. (1989). A neural-net training program based on conjugategradient optimization. Tech. rep. CSE 89-014, Oregon Graduate Institute, Beaverton,
OR.
Bose, R. C., & Ray-Chaudhuri, D. K. (1960). On a class of error-correcting binary group
codes. Information and Control, 3, 68{79.
Breiman, L., Friedman, J. H., Olshen, R. A., & Stone, C. J. (1984). Classification and
Regression Trees. Wadsworth International Group.
Bridle, J. S. (1990). Training stochastic model recognition algorithms as networks can
lead to maximum mutual information estimation of parameters. In Touretzky, D. S.
(Ed.), Neural Information Processing Systems, Vol. 2, pp. 211{217 San Francisco, CA.
Morgan Kaufmann.
Cardie, C. (1993). Using decision trees to improve case-based learning. In Proceedings of
the Tenth International Conference on Machine Learning, pp. 17{24 San Francisco,
CA. Morgan Kaufmann.
Duda, R. O., Machanik, J. W., & Singleton, R. C. (1963). Function modeling experiments.
Tech. rep. 3605, Stanford Research Institute.
Freund, Y. (1992). An improved boosting algorithm and its implications on learning complexity. In Proc. 5th Annu. Workshop on Comput. Learning Theory, pp. 391{398.
ACM Press, New York, NY.
Hampshire II, J. B., & Waibel, A. H. (1990). A novel objective function for improved
phoneme recognition using time-delay neural networks. IEEE Transactions on Neural
Networks, 1 (2), 216{228.
Hastie, T., Tibshirani, R., & Buja, A. (In Press). Flexible discriminant analysis by optimal
scoring. Journal of the American Statistical Association.
Hinton, G. (1989). Connectionist learning procedures. Artificial Intelligence, 40, 185{234.
Hocquenghem, A. (1959). Codes corecteurs d'erreurs. Chiffres, 2, 147{156.
284

fiError-Correcting Output Codes
Kong, E. B., & Dietterich, T. G. (1995). Why error-correcting output coding works with
decision trees. Tech. rep., Department of Computer Science, Oregon State University,
Corvallis, OR.
Lang, K. J., Hinton, G. E., & Waibel, A. (1990). A time-delay neural network architecture
for isolated word recognition. Neural Networks, 3 (1), 23{43.
LeCun, Y., Boser, B., Denker, J. S., Henderson, B., Howard, R. E., Hubbard, W., & Jackel,
L. D. (1989). Backpropagation applied to handwritten zip code recognition. Neural
Computation, 1 (4), 541{551.
Murphy, P., & Aha, D. (1994). UCI repository of machine learning databases [machinereadable data repository]. Tech. rep., University of California, Irvine.
Natarajan, B. K. (1991). Machine Learning: A Theoretical Approach. Morgan Kaufmann,
San Mateo, CA.
Nilsson, N. J. (1965). Learning Machines. McGraw-Hill, New York.
Perrone, M. P., & Cooper, L. N. (1993). When networks disagree: Ensemble methods for
hybrid neural networks. In Mammone, R. J. (Ed.), Neural networks for speech and
image processing. Chapman and Hall.
Peterson, W. W., & Weldon, Jr., E. J. (1972). Error-Correcting Codes. MIT Press, Cambridge, MA.
Quinlan, J. R. (1993). C4.5: Programs for Empirical Learning. Morgan Kaufmann, San
Francisco, CA.
Richard, M. D., & Lippmann, R. P. (1991). Neural network classifiers estimate bayesian a
posteriori probabilities. Neural Computation, 3 (4), 461{483.
Rosenblatt, F. (1958). The perceptron: a probabilistic model for information storage and
organization in the brain. Psychological Review, 65 (6), 386{408.
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning internal representations by error propagation. In Parallel Distributed Processing { Explorations in the
Microstructure of Cognition, chap. 8, pp. 318{362. MIT Press.
Schapire, R. E. (1990). The strength of weak learnability. Machine Learning, 5 (2), 197{227.
Sejnowski, T. J., & Rosenberg, C. R. (1987). Parallel networks that learn to pronounce
english text. Journal of Complex Systems, 1 (1), 145{168.
Selman, B., Levesque, H., & Mitchell, D. (1992). A new method for solving hard satisfiability
problems. In Proceedings of AAAI-92, pp. 440{446. AAAI/MIT Press.
Snedecor, G. W., & Cochran, W. G. (1989). Statistical Methods. Iowa State University
Press, Ames, IA. Eighth Edition.
Valiant, L. G. (1984). A theory of the learnable. Commun. ACM, 27 (11), 1134{1142.
285

fiDietterich & Bakiri
Waibel, A., Hanazawa, T., Hinton, G., Shikano, K., & Lang, K. (1989). Phoneme recognition using time-delay networks. IEEE Transactions on Acoustics, Speech, and Signal
Processing, 37 (3), 328{339.
Weigend, A. (1993). Measuring the effective number of dimensions during backpropagation
training. In Proceedings of the 1993 Connectionist Models Summer School, pp. 335{
342. Morgan Kaufmann, San Francisco, CA.
Wilkinson, R. A., Geist, J., Janet, S., et al. (1992). The first census optical character recognition systems conference. Tech. rep. NISTIR 4912, National Institute of Standards
and Technology.

286

fi	
	fffi	
	

	!"$#%$&('*),+--.0/!+++21+3'-

435678:9;<-.=>5
#&	8?-0;-.

@BADCFE0GHAIAIJALKNMPOIJE0QSRTQUGWVXAIJALK

Y?Z:[]\_^a`UY_bac2deb
w:xy{z}|e~t}z~yH3o~
 323F,<<~
 3|	03yW"	3

f3gahjiag_kmlafon paqarsn gtlun s,v

Z^{^"?^?Z_`,

("f3pa_kWs,_n a}l!paas%:n gtlun s,v

!|e~a?o}o}}	y3o~
 o%x
  0	je	2e

e_!
7!!uoo!:*%3:e7	u_,7X0$U7$	3j__		3
ej!e$	UI3joe3j?7eU}3}oe77	},o7m	o
$m$2	<2u		7ooeL$U($}7%ee
}a,$:_,U7am$j$0oU,3!$o0I}	3}0
$0$	}WeX*:3	t<			$37,"e%	7$W,$
o$7}oo$2	<2e
:}7e7"!7ooem$$0a}$}oe_}
u	$t$	%$00<	}}$"}:3$0U	aW(<Loe	$,L0
uo 7{! 
aa"!""a0,	ff
Ifi,!}fia3 !"a$#%&
'a(a)*#+$,*-7

!.!0/ff
21}a,	fi#3*a

"!4fi,

$5%
I	

a6ff7,"98ff,:#!,;$#50/%<7,2U1a "!0>=5, ?(+/"+/0@!4AB!o5ff7W
a<aa"%,$#oUa$1!aC28ff,:#!,;a
DoIa!}fi! a3WoE,	<F=5,G-7a

#&C% fi; a  e$a3 fiHfi,$#a$#ff2Iff0"$aaa"%,$#}
I!Jfi3!#&CK,
 M"
 
/ N

 fi9% 6 "B0O+
 a
 P ,CQ $#R
# a5CX+7,$#!SETUV%WX!Y[Z \
L a
7,$#3,.o*WX^]_a`7bffX!cAWX^Y>%3ff,$#AffBfi+/MA#/R#&0I,T UffB ",fi,7
IfffiaM#&
%d R
 B e
 5 ff, L a
 fJ
# &O+
 "
  fi,!	
 <
 	R}
 
 !Bgah	!a3ff&fi;B!+\

A, a	a
 ah"ff7, 2 A"
 35
1 $
 3 a!7, G0 fi% 7 JX
 753 	+,Gm
T fi/ff, $I

 &Q 
5
1 (3 6!0
/ Wff

 9iBW+jfiUff]_abff`}
 !+ 
H fi, $#!J 7+
/ L5 o
 "ff7, A5J
1 A}
 3a
  
# fia
 
a$H
 7 MB! O"ffBa
 	, Zk% "#
/ l
 +
 7
 "}34fi	"
 +!0/ff, Oa
 fi/% 3$I

 fi
fi,]am fiBl% 9a
 n% !0O"+!0/%,  a
  "B e fi/ff, $

 &,	]
o e
 *!PZp!
 
!o
 ;C!,fi 
D7,  Ra
 ""
 +!0/ff, @a
 &/%, $I

 fi,GZDq 
# &C!%E#
/ 
 O
 $"
 <+(
 J@a
 
75J
 	+,U
r ffBfi, $#no
 ! sBa
 	753 	E%  
 "4% !	*I
 !+
 	3+,
ZRq 3
# &0%+{
 M a0ff{
 affI
 a 	Bo
 7,tfffi, +/fi,ffu"
De
 
 a
 +
 2!3 Ia
a"!4fi,"+!0/%0Oafi/ff,$
&BaI!}	afffiMva!Im%7,""!
Ufi%w,
 xZy l
 !+ 	F,{
z 3C
/ ?
 +
/ '6 I+
/ 3]"}34fi]B e2"
 +!0/%, J6a
 
fi/ff, $

 &"a
 fi 0 6 
v a! mff7, "!,
 a"Z| 	0 
# &0IN<"
De
 77O"Aa
 
+
 !JZ}+o
 aaffOffBfi, +
/ E< 
# fi0I,s
~ ?N

 fiffff
 "4% !mo
 &/%, $I

 fiA7(
 "}g<fi,
"+!0/%, 0M + o
 "l ' ,AI3
De
 "
 Ra
 +
 	!Pa
 Ifi'ff7, !",
 a3Z R0 9
# &0
 +--3.:fiafi"$##$	8:	8EU3O_ff6O5
#&	#I	fi

o%&##>8


fiff$$*$$xO%$$ff$!$!

 $
 +$M+fiff%$+&><6""fiff$"D5">ff fi$M%&0$fff%fi+CJfi<3
$P+fiff%$+&"!+!0ffff+ff5%$R6
 +ff+B$<B++%+PM$O+%7Mfi;BMR^&$fiffE$$+&%ff$+fi[;[$ff@%fi+ff
6R27ff	+7!3!&B4fi<Hff|D%fi+ff9< fffi0Iff$$!&(B! M!J$ffM$MJ!ff
!fi.7*!J(B$+2&7tff7fftRB![M5ff+'&'Ds<%$3t$+ff2!A$
+fiffff$	+&R!+!0ffRff+ff5%$'  Bl75J2 fiRff!7+fit%++fi	%$
75J6B! 7fi5m%B$MMff<%*g0O5%+D $+$P+fiffff$	+& ^+!0ff ff+ff%<$
"A4ff$%7ffG7$$!&!P$+B&7Pff7ffl!^'!ffl+ff++%+57P
5+GI	fiO+ff7ff%+0 0hffBfi+ff5dff&0IfffiP>$M$>$Peff^!57E5ff
!!^ff+ff5%$R$Pfi<<$275JMfiBfi($+$+6B$P+&%ff$+fi6^+!0ff ff+ff%<$
M  ffOff+%5%$(BM60$+fi5ff ff7ffRMBPff+O!ffBAP$fi70@75Jff@[!0ff!$fi
$M$fi+fiD7%$+!MJdff<%!E% $+6B$M  ff$A6"+ff7ff
4ff+$+5CK%}D0M^+7>ff|7ff	6ff7ff!G!Jfi!6B$ &$A^+O!&g<fi"!+!0%<%5
$+fiff%$+&E>I:ffF!ff7E$Ofi$fiff![t!ff%P$O+fiff%$+&F5fi 0ff%$
ff7ff!9!PD0RffwRI0<$BA{fiJm$D7!&B4fi<R!+!0%ff5PJm$+fi%<Bff$+fi
ff+ff%<$'*DMfi$fiffffD0l+ff+fi!0'+$ff$ffJ!ff$B$2!+!0ffffRP$
+fiffff$	+&"DB$&fi7M$A$fi+fiDff7ff!ff$D7!+B+ fi"$$>+
D% ff!^fiG&aMff!a&ff
Qfi;E!^+6%!7Q$"+ff3sG$fi$R fiMfi$!$fiAff!+&B57$Aff
$>7ff0>&+a>AJO!!%$2;gKffBfffi>I:ff ffBfi+ffDB$ff&0+&J5%P
 fiBD^&4fiP!+!0%<%O$ +fi%<Bff$+fiE$6ff!C!ff$5ff%mB$%$(B!OPff+	fi;J
6B74Iffffff$3$hP77ff*fi!$PA!ff4">5	+m%D$+(s;J$fi<$2fiBfi<$
+!(!% Iwff7fflA(%!$Aff$$5<%!0sff7^5mM!fiR.Bfi;!^+
I	!7fifi %;7$fffi72!+7++$+D07&^+$7+fi5<%&!A^+7m++	$+
D0*ff$$5<%!0s++%ff7+4ff<%! $AMB;%4s$fi$2 fi<Jfi$2!ff7
ffB$7f%$$57ff!C++%ff7O!H+$7+fi57ffR7&^+GIff7ff2P6%! +ff+50
$+!4ff!PBDff$P!%43+ff"I'ff7ffxA$$Pff$">5+ff2!*B7fi5l$
!+7!7ffARffBe
@RO'2C4%e$D%
 ff
 !g;fi+R$$xNJfiR fi!0ff2ff<ff$n!fiff}$2!7D!fi;

5%+x>ffw%+0(fiffDC<  %!4fi+nw5$RI+*7h+ $+$+lDfi
ff!7+BC7ff!RB!n+J^*Dfffi%w!7+fi27ff}P7ff!R5Jff+tfit$*fihBff2D0
B!$ffR$7ff!+C<%!+.NffM!fiffB$DfihBffMD0*!2fi2ff!7+ff	 $+$+A$
!7+fi[fi&$3$7$E[fi<%(%M!3 $+$+G$O!<+fi!ff[fiffAff+	!+5B$ff
ff7	ff$"ff!7+BC7ff!dDfffifffi$6fi$ffED0A$+35ff"Dff7fffi fiBDR3R$
ffRA$+ff!7+7ff!+
%7RffR$7P$+ff!7+7ff!+N$ffi$ffD0$+RBHB$fi&7
27$!7%$+fiMff7ff@J!.2ffM$+3M	7P!&B4fi<	
 g$<9!P$A!<+fiPAfffi
7fi+%$$$P$3Nff"!$B(Js$ffB!0
 g$B2"$ff"&$ *$7ff7I  J$50ff$
5"$Dff7ffw5ff+*fi$Dfi$ffPRfi+^+!'ff*$DffB!0@
 7$l$A!7+fi
$6fi$ffE$+$EMfi+ff7M"fiR!Ee5% $ !<+fi>ff fidfi70@ff!7+BCfiP75
M9ff&0!75BP>I:ffff
 $&$4+0D75Jfi<P75J
 fi5$"fih%m+%!7+ff B$ !7+fimffB

	ff
fi "!$#$#&%'()**()'(	'+fi,-.0/!21'31141567!2()8941*!2:fi0;<(6#$#2(.!2,=
1'>7!2(	@?A6/"!$#$#B%C!2/,7!$DE/+.!2fiF4(	7!G#H!2fi,I'3#ff41567!2()J17!2K>	
LL)M

fiNOQPSRTHOHOHUVOffWYXZHU<R[8\ff[@TH]HOHUVOffW

^ff_a`cbedf`<b d`<g h@iejbffkmlchjanbJoj@p	d	qCjrff_@sHdCd6tHhujvp	dsffj,le`cbwsHnxzy`5{$h@{<idtHhj@p	dsffjElffhbA|v`<n_@bHg hbedCrffhtffj,|v`c_vn}
kesHn`<bH~:dtHhh	Hhp	sHd`<_@b_oIdtHhJ^el9jb{+hbffp	h@i.hJ~@hdj bffjd6sHn)j,lIq`<dsffjd`<_@bYtHhnh &lVjabHbe`cbH~:te`Gl<h
 hjn6be`cbH~z`9qbHhp	hq6qjnx@{
 sHnqhp	_@bffkh	jgz^elch`Vqd	j@hbon6_@gjQd6n)jbffq^_@nd)jd`c_vbke_@g-jE`cb{  hdy*)z}rffhj
kv`<nhp	dhkQ~@n	j^HtiCtHhnh:d6tHh-|@hn6d`9p	hq kehbH_@dhzl<_Bpjd`c_vbffqJ`<bjtH_eqd`l<hhbe|@`<n_@bHgzhbAd{utHh:hke~@hq
kehbH_@dh:qj,ohn_@sHdhqmon_@g_vbHhlc_Hpjd`<_@bd6_jbH_@d6tHhniCdtffjdjnhd)j@hbQd_8rffh:_@bHhj,xQy5d_vuj,x
n_@sHd6hqIjnh0kehqp	n`<rffhk8j@qIjm^ffj,`<n_ao"_vbHhuj,xJn_@sHdhq	}	{  bHhj,xn_@sHdhq&`<b:dte`9qC^ffjnd`Vp	sel9jn0ke_@g-j,`<b
_Hpp	sHnj@qj nhqselcd0_oCdtHhqdnsffp	dsHnh_ao&dtHhJhbA|v`<n_@bHg hbedjbffk:_oCdtHhJ|@hte`9p6lchsffqhk8rex-d6tHhj~@hbed{
 bffp	hnd)j,`<bed>xQ`<bdte`9qzdn)jbffq^_@nd)jad`<_@bke_@g-j,`<bjn`9qhqon_@gdtHhojvp	d-dtffjad dtHhnh`Vq`<bffp	_@g ^el<hdh
`<beo_vng-jd`<_@bjarff_@sHd0dtHhhbffke^ff_a`cbed_oIq_@g hn6_@sHdhq*_@n`c~a`cbffjad`<bH~ on_@gq_@gzh^ffjnd`9p	sel9jnlc_Hpjd`<_@bffq
y`5{$h@{<idtHh g-ja^Y`9q^ffjnd`VjElGl<xsHbHebH_b.}){z5bq_@g h pj@qhqmdte`9qm`cbffp	_vg ^el<hdh `<beo_@ng-jad`<_@bp	_@bffp	hnbffq
_@bel<xjqg-jElGlCbesHgrhn_aoClc_Hpjd`<_@bffqjabffk:n_@sHd6hqtHhn6h+dtHhbesHgrhn_aoI^ff_Aqq>`crel<h hbffke^_`<bAd	q0_oj
n_@sHd6h*`9qIj,l9q_qg-j,ll5{20b-j~@hbedIg _|v`<bH~j,l<_@bH~JdtHhqhn_vsHdhqCebH_qfdtHh0^ff_Aqq>`crel<hj,l<dhnbffjd`c|vhqCo_@n
dtHh+qd6nsffp	dsHnh0_oSdtHhhbe|v`cn6_@bHg hbedjbffkpjb`9kehbAd`ox:dtHh0l<_Bpjad`<_@bffq`<djnn`c|vhqjad{C*tHh_@rHwhp	d`<|@h
_oCdtHh+j~@hbed*`9q*d_znhj@p6tj~`<|@hb:d)jn6~@hdlc_Hpjd`<_@bYqd)jn6d`<bH~on6_@gj~`<|@hb:`<be`<d`9j,lfl<_Bpjd`c_vb{
utHhjarff_|@hh	jag ^el<hq+jnhd)ja@hb8on_vgnhjElc7l`ohq`<dsffjd`<_@bffq{*tHhxjnhdxe^e`VpjElq`<dsffjd`<_@bffq0_o
rff_vsHbffkehksHbffp	hnd)j,`<bed>x@{u`cg`Gl9jn0q`<dsffjd`<_@bffq_Hpp	sHntHhbHh|@hn*h0tffj,|@hd_J_@^ffhn	jdhjg-j@p6te`<bHhdtffjd
*_@nHq*`<bQ_@bHh_ouqh|@hn)j,lI_@^Hd`c_vbffq{5bgjbAx8_od6tH_Aqh pj@qhqidtHh ^_Aqq`<rel<h-_vrffqhn|Ejad`<_@bffq+pjbYrh
qd)jadhk.iCjbffkYdtHh:qhd_o^ff_Aq6q`<relch:hbe|v`cn6_@bHg hbedrhtffj,|@`<_@n)qzpjbrffhl`9qdhk.dtHh:j@p	dsffj,l*rffhtffj,|v`c_vni
tH_*h|@hnig-j,x0rffhsHbHAbH_bj^Hn`<_@n`5{fll<sHg`<bffjd`<bH~+n6hqsel<d)qn6h~Ajn)kv`<bH~0dtHhqhIh	ffjg ^el<hqfjnh`cgz^elG`<hk
rex-_@sHn0qdsffkex@{Ih|@hndtHh	l<hqqiff*h0ffn)qdtffj|vhd_keh	ffbHh+_@sHnrffjvq`9p0on)jg h*_@n.{
v<VC

0b@,ff7ff,9@ff
y> 6-		).8}+p	_@bffq`9qd)q_omjYqhd_o
A,),AY@-zijqhd:_aoB	Y@,9@-ijb7ff79@@:	jbffk@@e@
@H79@meff,9v-.	:d6tffjdkehdhng`<bHhquo_@n*hj@p6tqd)jadh++8jbffk:j@p	d`c_vb-
dtHhbHh	Hdqd)jdh,ff"Yy>e)}){
 @
j qhk_@b-d6tHh+jrff_|@h+keh	ffbe`<d`<_@bY*hpjabkeh	ffbHh+tffjdj &l9jbHbe`<bH~-te`l<h  hjnbe`<bH~-qxBqd6hg`9q{
_@d`9p	hd6tffjdI*hj@qq_Hp6`9jdh0dtHh*`<beo_vng-j,ldhng	rffhtffj,|v`<_@n)J*`<dtdtHhd6hng	d6n)jbffq`<d`<_@bzosHbffp	d`c_vbffHi
tHhnhd6tHhj@p	dsffjEl"rhtffj,|@`<_@n`9qdtHh+jvp	dsffj,ldn)jbffq>`cd`c_vb:osHbffp	d`<_@b{
v<V7

*@ff9efe9Y	@)9e,yf}p	_vbffq`9qd)q_ojbj~vhbAd
hbe|@`<n_@bHgzhbAd:qxHqdhg
y )		.Y})i*jbffkjqhd _oH)@79v:A7@H
 0,<<<	ei&jElGlqtffjan`<bH~d6tHh qjag h-qhd_o_@rffqhn6|Ejrel<hqd)jadhq+ziStHhnh-d6tHh j@p	d6sffj,ldn	jbffq`<d`<_@b
osHbffp	d`<_@b:`9q_@bHh_oCdtHhqh^ff_eqq`<rel<hd6n)jbffq`<d`<_@bosHbffp	d`<_@bffq{
_@d`9p	hdtffjd0*hsffqhkYdtHhdhngA,),Az@n)jdtHhnd6tffjb wsffqd+qd)jadhq{0bY_@rffqhn|jrel<h
q d)jadh_oujbQj~@hbed0`VqmtffjddtHh j~vhbAd^hn)p	h	`<|@hqjd+j:~`<|@hb^ff_`<bed y5h@{$~{<i`<d)q^HtexBq>`VpjElClc_Hpjd`<_@b.}
n)jd6tHhndtffjb0`<d)qfp	_@g ^el<hdh*qd)jdhC_aoBebH_*l<hke~@h@{  hj@q6qsHg hCdtffjdfjbj~vhbAdpjbj,l<uj,xHqkv`9qd`<bH~@se`9qt
rffhd*hhbkv` hnhbAd_@rffqhn|jrel<hqd)jadhq{C*tHh+p	_@g ^el<hdh+qd)jdh0_oCAbH_*l<hke~@h+pjb:rh+keh	ffbHhk8rffj@qhk
_@bdtHhte`9qd_@n6x_oj@p	d`<_@bffq jbffkQ_vrffqhn|Ejarelchqd)jdhqJ_od6tHhj~@hbed{*te`9q te`9qd6_@nxY`9q jb_vn)kehnhk
qh vsHhbffp	h-_aou_vrffqhn|Ejarelch:qd)jadhq0dtHh-j~vhbAd|v`9q`<dhkjabffkj@p	d`<_@bffq`cdJ^ffhno_@ngzhk.
{ H_vnh	jgz^elch@i`o
jbj~vhbAd^ffhno_@ng hk:jabj@p	d`<_@bdtffjadIl<hk on_vg jab-_@rffqhn|Ejrel<hqd)jd	
h d_ jb:_@rffqhn|Ejrel<hqd)jdh

fiff

!#"$&%&'$$)(*+'-,.'$/0,1%2'-43*56-7859!+':";<'-="6>0";)?38?@A"B.'-59C.'-D@Eff	830"B?.'->AF

:"B?G"B33$'->6"B.'-59H%&#3*6"BIJ"B(*598)8#!+(*@?K56LM8>?A"'-N?5EO'-+-5EPQ"B?.'-!+'->EM%<fi'$-G8G8!R(*?56L
3*59.'-(fi'$$':.':SLT5E?<6"B>AU>A	?5EV'-V(*598,8@,	(7	"+!#"$

WW9X

>598A"6ff

fiY[Z

jk*l
t6}

m*noHpJqrm[o





Crnt1o{u{rs4n

t=t6}{vs={n

u0wqTro{drNvsJn

m^sBvnEtm*nonm*t6

t#{n

w}
t6}

t6}

6|Hu*xOt6}

4Ku*yr~drltB}

sKt6u1t6}

r46rm[o{r	s}

r#n{

o{rt6r6JvTn



u[{qon

rron

u[t	Eu[n{xsr4u[



rNvt9squ

r




rwmzu*~[rRCuo{rEq

srd

6rd{v6r	t6}

Usru*xym*

rEvn<lU[[

u*Gs

6t6}

r	odvs6Es6svu[n

us;rns66}

rEvn

rGEu[C1u[n
r[l<



t	u[n{q|

Crntr}m8~dvu[9sSvtwEudnsvo{r9sSvs

m8qstEm*t6r=vs=n

6rsrn{t9m*t;vTudnsl)mdst6}

vsVx

no

CrntO}{vsS

m*1rn{t9m8qm*no1s;u[1rRrE
u*m*{qr	t6u1o{rEn

6u[{qrvsVx

6t6}

u[t=n

r	u[n

rErs6sBm*vq|6r

r4t6}

n

rn

}

u*qt6[lOd

*9

t6rnsvu[nsSu*xvtOvqq)r#odvsBEs6sroJvTn[rEtvu[n

rUm[sv

6u[{qrvnVqm*n

rRodvs6EsBsrovn1t6}

N#}{vqTr=&rm*6n{vn

rxu*qqu*vn

n{vn

#}{vqr&rm*6n{vn

s|

rm*[rn{t#Nl[vsUms;

t9m0vTn

r46r

xBu[

E[l

no{rUm*n|Nu{s6sv{qr4t69mznsvtvu[nNx

=ru*xMm[Etvu[nsSt6}m*tymz6r#rE

6rs;rnt9mztvu[nHu*xOt6}

s6m*tvsxAm[Et6ud6|{qm*n

vst6}

r4Vqm*n

n{vn

rE

t6ro=vnmEu[

N#}{vqTr1&rmz6n{vn

r6rExu[6rm{qmznvn#}{v6}t6}

Crnt=r}m8~dvu[lvnu[Eo{r4t6u[m*9m*n{t6rr=t6}

st6rlK#}

srtGuzxt6}

}m[stBu4noHmJ

r6r

BuErs6sfil&t6u



r=st9m*tBrsyC



s|

s@vTtBm*tvu[nsU#}

6u[rUEu[={vTnmztvu[nHu*xVqTrmz6n{vn

u1qu[n

m*noHm[Etvn

	

1

u[=vm8qq|

st6r9

rm*[rn{t1qrm*6nsrn

rHm[B}{vTr~dr1rntu*x#t6}

r6rvt9sU[um8qVvsUn

rm*drnt

nEt;vTudnNvTnOM{qmzn

9sr#uzx)vt+vs+u*q|{n

u[

[}m*u[

tHt6}

r

rm*drnt s	[um0q#udtvEr

r9m8qAlOm{qm*nJvTd}t=rN~[r6|Eu[C{qTrE<Gnbm*[rn{t4=v[}{t1m*6v~[r[lvnt6}



ro&lvxRr

rUus6s@vT{qrr}m8~[vu[Es

nEtvu[nxBu[vTtEs#}{vst6ud6|uzxSstEm*t6rsUvn^=ym*noHmdEtvu[ns	vTn1RtBum*n

stEm*6tvn
r#n{



srEtvu[n1m*novTn{~[rst;vT{m*t6ro

vT~drnmJ[um8q<<lmQd.Qd[	&:d1vsUm1{qm*n^t6}mzt#[m*9mznt6rrswt6}m*tUt6}

vqqM6rm[B}m=st9m*tBr#vnN

t6}m*t8l&vnb[rn

n{vn



*v~[rn1m*n{|4us6sv{qrGr}m8~[vu[Ou*x

u*qo&l<m*nos@vTJv:qm*6rs{qt9sUm*n^r=u[

&rt@BVrmbVqm*n

vsm8qqTro^.{vxMt6}
no{rovTnHtB}

BrsrntBro

rsUodvs6Es6srovnKvsBE6rt6r

r	m*[rn{tytBum[B}{vr~[rUvt9s+[um8q&u[n{q|1vnmUx9m[Et;vTudnAr[ld{1MuzxMt6}



Gm*novs==6}Cu[6r

}m*lR[d{Gm*novTnu[6vTnU	t6}m*t	vnEu[Bu[9mzt6rs

rnt4srEt;vTudns	*v=vqm*o{rEn{vtvu[ns}

m[Etvu[nvn^19

vt9sKqrm*6n{vn

r6rUvtUn

r

m*nou[sr6~{

6rswvt6}^u[t6}

OUm8qr6nusrsld*

ru[BrtvU1uo{rEqs@usrs#rn

)[=xu[Gm*n^m*[rn{t+vsUmx



rEvn<l[[

t6u[Nm*t9m*.qv[rs;t66Et6

@C6EE929lm*noH^G*8E[+[8[dxu[#tB}

rn{~[v6u[n

Et6u[l*K}{v:qr

st6rNs	@Um8qrBnusrsfilMd*Um8qr6n<l

rHm*[rn{t-sUqu

	@#m*Nm[o{[ru[n

r4m*BrGn

Ndy<<)U

ud

ro^{|m[Etvn

{q:vBvtq|[

tBu[m*t9m@us;rns66}

t6ros|

6u[{qrvsSt6uKno1mGsBm*tvsxAm[Et6u[6|	{qm*nCt6}m*tRm[B}{vr~[rsOmU[um8q

rrn{~[v6u[n

vns

rGo{u

r

Et6u[8-s4m[Et;vTudns	*v~[rnt6}

1r=t6}mzt4m*nm*[rn{tm[EtEs	m[sKvxyvtvsmCn{vt6rAst9m*tBr1m[B}{vn

m8qGst9m*t6r@usrnsB6}

v~[rnHtB}{vsw1uo{rEqAl

}

6rsrn{t6rorE

=ru*x<usBsv{qTru[sr6~*m*tvu[ns+m*no1us6sv{qr	rn{~[v6u[n

nEr6t9m0vTn{t|tBuEu[n{t66u*qt6}

t6}



{q:vBvtq|[	}{vs#zvT~drsGsBvnEt4m*nosrEx{qM6r

w}

rxAm[Et9swvtUqTrmz6n

udt	r=6r

rsvt6mzt6rom*

ro{u

m*tvu[nsfil4m*no
1rn{tKAn^t6}

r=m*[rn{t-s#o{rBvsvu[nsUvqqOr4mdsroHu[nvt9s#}{vstBu[6|Nu*xRu[sr6~*m*tvu[nsUm*noHm[Etvu[nsK#}{vB}

~drntC[|stBrs=@



rqTu

rrn~dv6u[n

r=m*[rn{tm8|16rm[B}m1st9mzt6r	#}

Crntl&mdsrou[nt6}

Eu[1{qrEbt6}m*nvt9s=u[srB~0m*{qrst9mzt6r[}
rE



6r[

srsu*xRvtro{u[n<t4m[s6s
t6}m*t+t6}

t6rsyvTn^t6}

rNrE<rEt9sUu*x#t6}

st6uHt6}

novnt6}

n{vt6r[#}

r1m[Et6m0qM6u[

r#us6sv{qrGudsr6~0mztvu[nsOu*x&t6}

l[[{m*noH{n

t9m8vn

6rsrn{t9m*tvu[n}m[s=m8q6rm[o{|

nEtvu[nbEu[66rs;u[no

rsr1Eu[1{qrEstEm*t6rsKn

r

rEvn<l[d{2mzno	vn=u[6	u[n=6rmdsu[n{vn

r#u[s;r6~0m*{qr	st9m*tBrsOm*6rt6}

r=rn{~[v6u[n

u*t6}m*tt6}

^t6}{vsmdEtvu[n<l

9

u*qro{[rvTnodvs;t6v

w}

rsxu*qqu*vn

r^t69m*ns;u[6tEm*tvu[no{u[m8vnrEm*1{qrmz6r^t6}



[d{Vq:vt6rEm*t6

rnHyr4mzns6m8|1t6}m*t

rm*[rn{t4vqqG{n

rstEm*t6r=vt=6rm[B}

t6u[Nm*t9mU@wusrns6B}

u*x	t6}{vs=t6u[{vm*nbrxu[
m*rEq{qvn

u[t1*w}

u[t#*ltB}

rHu[sr6~*m*{qrst9m*t6rNjk*}{vs=rnm*{qrsCst6u^u[

nEtvu[nEu[66rsu[no

tUt6}

g6hi

1rn{t#r}m~dvu[vsKn

r	m*tvrn{tOnudt6}HrEmz1{qrs#t6}

Eu[1{qrExm[EtEs	m*u[

ef

^t6u^vnbt6}

u0wqTro{dr1@Um8qr6n^usrsl<8[*

m[Et6m0q)vn*

c[_

6rs;rnt9mztvu[nuzxKmz[rntEs}{vs=t|{rNu*x#6r

rudsr6~0mz{qTrbst9mzt6rs=vnt6}

m	m*6r#o{u[m0vTn<ldt6}

_

Crnt=r}m8~dvu[vsn

rEvn<-sRs@vTtBm*t6ro=m*

rmdEt6m8qytB9m*nsvtvu[n^x

vn

`baRcd_

u[t	v1{qvro|tB}

9m0qy6r

r=m[Et6m8qMtB9m*nsvtvu[nx

t69mz

rNrn{~[v6u[n

_

r	rn~dv6u[n

udt4r}m8~[rHm[Eu[EodvTn

rrnCsrovTnNusrns6B}
m*u[

Z^Z

sKt6u1jkwv:xymznoNu[n{q|1vxOt6}

rHm*[rn{tE[99=tB}m*t4t6}

rn{~[v6u[n

\*]

r

Eud

dr4m[6}{vr~*m*{qr[KrnEr[l<t6}

9sr1u*x

r1m*drnt

}mdsrsOs6m*tvsxAm[Et6ud6|1{qm*nm*nHr

fi
fiffffffffffff

!#"%$'&($)+*#,-*.)/$01"2,3"456	7	$'$8&fi9$'7	$:$*019;$)/<#$:"2,*,	,=401"2*>6	$)&("6	9?*A@*B"74>CD*E5;4#F,=$'7	!G*EF/H%$,=6I*>6	$
*>5)*>5.*06="45.6	48F$@$'7JCK471LM$):"5.6	9*E6N,=6I*E6	$OQP(9/"2,R"2,N*8<$'5$'7*BHS7	$'@7	$,=$'5/6I*>6="454>C045)#"6="45*BH
@/H2*>5,'OTU5+$VW01"$'5X6:@/H2*>5&("YHYHD619$'7	$CK4#7	$M047	7	$,=@Z45)[6	4\*\)/$01"2,3"45]6	71$'$^4ECD@Z4>H_X54#L:"2*BH-)/$'@6	9SO
` 46="20$a94>&($'!$'7a/6	9*>6fi619$b,3"c'$b4>Cd*>5.$VW01"$'5/6-@/H2*>5Le*B_W,=6J"fHYHFZ$b$g@45$'5/6="2*BHhO
iQjMkmlenSoqpdrtsusv3nSwduyxUz{sErR|Q}
~ :
5 6	9$R@7	$'!#"%4#,Q,=$06="45:&($N)/$5$)M*F*,3"20tCK7*>LM$'&(47	U4>C{H2*>55/"5<8&fi9/"YH%$fiy$*E7	5/"5<aX*>5)8&fi9*E6*
,	*>6J",C*06147	_@/H2*>5ACK47d*E5*E<$'5X6Q",O ~ 5M6	9/"2,d,J$06="45e*>5)8"5M619$(CK4EHfH4>&("5<b4#5$,Q&($(&N4#/H)^Hf"$U6	4
045,3"2)/$'7U6	9$04LM@/H$gX"6=_.4>CS5)#"5<.,=019\*b@/H2*>547fi0	9$01#"%5<A6	9*>6fi*:<>"!$'5.@/H2*>5"2,fi,	*E6="2,3C*#06	47	_O
~ 547)/$'7fi6	4.)#",10,	,U6	9$"2,	,J$^4ECN04LM@/H$gX"6=_\&($5$'$)6	4.)#"2,	0,	,U47ULM$*,=71$,fi4>Cd04LM@/H$g/"6_a
*>5)6	9$:6=_X@Z$b4>C(7	$'@7	$,=$'5/6I*>6J"%4#5,fi4>CNH2*>55/"5<\&fi9/"YH$W$*>7	5/"5<\,=_,=6	$'Le,&($^&(4/H2)HY"$M6	4AH4X4
*>6O



S8\AB'Z'
$&("YHYHd)#",J6="5</"2,=9F$'6=&($'$'5\6	97	$'$F*#,3"20b{H2*>55/"5<.&fi9/"YH$^$*>7	5/"5<\,=_,=6	$'L7	$'@7	$,=$'5/6I*>6J"%4#5,'
 OU ZBdA{B'SS( 46	9.6	9$U5/L^FZ$'7fi4>C*E<$'5X6B,R4F,=$'7	!>*>F/H$b,=6I*>6	$,"hO$Oae
*>5):6	9$fi5/L:F$'7(4>CS@4/,	,3"F/H$6	7I*>5,3"6="45CK506="45,RLe*B_8F$U$g@Z45$'5X6J"*GH%U"56	9$-,3"c'$U4>CS6	9$
*06	*BHS7	$'@7	$,J$'5X6I*E6="45SO
 OUe 	'MB'Z'SS P(9$(5/L:F$'7Q4>C*><#$'5X6,y4F,=$'7	!>*>F/H$-,=6I*E6	$,yL:"<9/6
F$M$g@45$'5/6="2*BH("5?619$e,3"c'$e4ECD619$e,=_,=6	$'L7	$'@7	$,J$'5X6I*E6="45Sa{F6b6	9$M5/L:F$'7:4>C(@4X,	,"%F/H$
6	7I*>5,3"6="45AC506="45,R"2,fi*>6(LM4X,J6d@4EH%_/54L:"2*BH"%56	9*>6(,3"c'$ONP(9/"2,R"2,(*8LM4X,=6fi*>@@Z$*BHY"5<e6=_/@$
4>C7	$'@7	$,J$'5X6I*E6="45.C47fi,=_,=6	$'Le,(&D"%619.F45)/$)50$'7	6I*G"%5/6=_\=-*BH@Z$'7	5;d*>7I)#"ha  IO
P(9$.6	7I*>L*>h0'*>7	$e,J_,=61$'LLA$'5X6="45$)"5$06="45  "2,M*>5]$g*>LM@/H$\4EC*,=_,J6	$'L&("6	9*
*,"%LA4)/$'7I*E6	$\7	$'@71$,=$'5X6*>6="45SO ~ 5q,=0	9*?,J_,=61$'L&($.,=*BHYH_9*B!$;*,=$'6M4>C^*E6	4L:"20
4F,=$'7	!>*>6="45,h$O<OaX&9$'6	9$'7(6	9$F/H4X4).@7	$,1,=7	$U"2,(9/"<9.47RH4>&IOQP(9$5/L^FZ$'7fi4>C*E6	4L:"20
4F,=$'7	!>*>6="45,t"2,RHY"%5$*E7("5.6	9$-@714F/H$'L\,R"5@6aF6(6	9$U5/L^FZ$'7fi4>C@Z4X,	,3"F/H$b4#F,=$'7	!G*E6="45,
"hO$OaB4F,=$'7	!>*>F/H$D,J6I*>6	$,y&9/"019M*>7	$Q6	@/H$,{4>C*E6	4L:"20Q4#F,=$'7	!G*E6="45,Z",$g@45$'5/6="2*BHhOdP(9$tHf"2,=6
4>CS@4X,	,"%F/H$U"5>=7="$,(6	9*>6Q6	9$U@*>6="$'5/6dL:"<9/6d9*B!$D",R,=*GHfH_@4>H_/54L:"2*BHy"5e619$-@7	4#F/H%$'L,
"%5@6BOMfi$'50$a&N$:<$'6b*.#*,3"LM4)/$'7I*>61$M7	$'@7	$,=$'5/6I*>6J"%4#5;4ECD*.{H2*>55/"5<&fi9/"YH%$.y$*>715/"%5<
,=_,J6	$'L\O
 O 
 '.A{B'SSfi 4619M6	9$fi5/L:F$'7(4>C*><$'5/6,{4F,J$'7	!G*>F/H$b,=6*>6	$,Q*>5)A6	9$
5XL:F$'74>C@4/,	,3"F/H$b6	7I*E5,3"6="45CK506J"%4#5,R"2,(@4>H_/54L:"2*BHS"56	9$-71$'@7	$,=$'5/6I*>6="45\,3"c'$OdPD9/",
6_/@$84>Cd7	$'@7	$,J$'5X6I*E6="45",H$,	,U<#$'5$'7I*BHd6	9*>5*e#*,3"LM4)/$'7I*>61$^71$'@7	$,=$'5/6I*>6="45SayF6U"6",
,=6="YHYH$g@7	$,	,3"!$*>5)M04LA@/H%$'61$H%_5456	7J"%!#"2*BH*#,Q&($fi&("YHYHH2*>6	$'7()#"2,	0,	,'O(P(9$fi6	7*>5,=@4#7	6I*>6="45
)/4Le*B"5$g*>LM@/H$4>Cb6	9$\@71$'!"4,,=$06="45",LA4)/$'7I*E6	$H_]7	$'@7	$,=$'5/6	$)]F/_]*+<7*>@9HY"%#$
,=6	7	06	71$aS"50'*,J$,b&9$'7	$e619$'7	$\*>7	$e*E6^LA4X,=6b@Z4>H_X54#L:"2*BHYH%_Le*>5/_+*BH6	$'7	5*>6="!$,C47:6	9$
*06	*BH,J6	7	06	7	$84>Cd6	9*>6U<7I*E@9+h$O<ZOa/"5+*M@*>716="20/H*E7b*>@@/HY"0'*E6="45SaS6	9$'71$*E7	$^*045,=6I*E5X6
5XL:F$'74>C@Z4X,	,3"F/"YHY"6="$,6	4e*^H%4#<X*>7="6	9L:"205XL:F$'74>C7146	$,IO
b:y(bB:='G='fJ-	B\>	'BIRfJ-y3h	BG1N	1:Y I>1'dfJ1
='G='fJBd	=GJB='h1b= 
I

fi>]d#	

3.		%/'	ff
1fiffZ'(=		'/'>	=	h	 !#"$%&')(*/'>	
=	,+	
'^-.//'0>1e	1 ='X>)1h	 #"2$&%')(*/'0>			 ='/0>!3#4+56
5
798:>fi;,fifi<8>= >	fi;?!=1@"

A#BDCFEHGI JDKMLHN#OQP2R4SGS J)NUTVGWXLGSYfiZN4[JYI
\ )]'^M7_8Efi%;`fifi<8a=y E	fi;b=	@cQ1'	@>			'de^f%>)e8gf>	;& 
	 >h(f':/' "
i "j TS [eGKffSGklWY4mn  f-o&%;'	'p	fi8:>H
q{	ff;'/U2->:'
r%f	:2f%s0>)e8<8)
>04c>,d A0ffot'/:e8!3A%"
hQ798:>fi;,fifi<8=y >1fi%;M=	(1>
re8<89%/.	fi:f>1;%%c]#';1%ufi8vff

		 ='/;:	gfi8:>@E]'!w
*&%;A	>(	fi:hfi8<% xfi8:>d:>:'
r%f#Hhf%s0ff(
)e8<8),X10%f0ffufi8d*r"%")cZ	'	y%fb' / a
qU		 J'X0E),:Ut'/:e82
	]'<zVf>)/f (0ffo# (t{'/:e8)Mff+0"

| "	}~h! J*T4YQh[ GK6SGklWYVm	 >:'
r%f#fi8:>,
*fi1ff;'/%J	fi	1 ='X>)
*r"%")c{ff8)X%82%	:	1 ='X>)@6
d	&ufi8%x+0cVEaf1 f-o%;,fi'	'sfi8E
>:'
r%f-f>@uZ>f>1 d%fi?f-'/8),@{ff8)X%8)M%"
 =1{	>U
8w8/	fi:pfE	;%d yffyu:U	:e8V>8'	-l-f cfffifi:f1
>dX	8<8<);'// ');'"%")c:d>4+;%;# =0h%Mfi8:>x
q#!ff8)]%;,y%ufi8@"h(
;%; =1 `fi8E`A		 J'X	 E]'<z 4"]
gs
w8:A	,]'<zVf>!3#f -c(	'
	bt%fh
re<8)	HU1	1 4cV>	>/ 3;#'ee	-.;''0E	>:fi8:>#"gDfi
	:e8l>A'	hf :8fi:fe8l683!3#,
*/ ');,%ufi8"  / ');';ff)]'@
 f-<zVfy&ufi8%/c#>/e=:'t''fs.!;%; =;,fi8:>#"H(yfi8E.J%fi8:
u\1	 ='/	 >]'!wz ?f-'/8)%"*
b	/fi8E^:A,>:'
r%f-%cd	?f-'X
]'<zVf>)/f -h8)f>	 	
re<8)	 >dfi
*	y/ ');' c{fid ,f1Jb
;''0>	hU^fi8:>#c#'0fff"2(fi:2ff%f1y%lE9z0=2%/(tfi8<f-M	  #8<	'0>-	%c
u	>Jye8_6'	ff
Mf n E		fi>@	e 	Mf n E		fiF	e c i &% +2fi'	X%
	
K'1	 ?&U	,:!%2%;06@"(fi:fffi%f	/:/' +1>#>J /ad>
0%f:fe8'>)cgf1%M1a# dM'X!3# 	M	]&)%,= f)#"  s	
/'0e<8 @/J	0>),6
	Ep:/ d>s
*		'g&:f3#.fE,u
*%?%M@fi= 
S''ff8%c i %&  ffS''ff8%c i %6 +0"
fi'f%cfi@=	dd1>
e8<84X-^1fif>	;%-%c]ff>)%hfi8:>f>uZ	 sa>dff#(D8<
/ ');f cp{		 `ufibMf%1')' ]?f-'/]'<zVf>)-f fi	%cfifi:f1
%
*fi8<83	 fi80M>:'
r%f#fi8:>#"
 "	} T  JTVYM[eGKffSGk9WYVm >:'
r%f#yfi8Ed
qR	ff;'/%hHff8)/%y:e8S		 J'(
0>)#c1>h:fi#fi8).?f-'X!83/]'<zVffufi8%c4uf>,u%f8w8)@f%s	 M83;&	(
y:fe8<83{+%/ff8)/%y:e8Q)M%"
A#B)AEHGI JDK@sYIffR#W)S I
+yh%fi8:x8w)oA?f-8:%-'<
qM798:>fi;@fifi<8=y E	fi;a=	u%= /	yffuff]f>1;% "
(X
qff8<8)ffh;.	 fi80	>	y')fi8f#ff8<8:> 	ff
Q	 fi80	ff] dufi@/= >M''ff8H
>1'f#X	tS''ff8M/J c i %% @fi= v''ff8%c i %i% S''ff8%c
i %i +p>	g-ff
9:h%y	1 d
%	ufi,ff
Q	fi:6' "
 0

fi`l M) /%

&	)%&0e fi0ff)%yffV	9:fffi)yfi<)g4 ff-fi3!-@e&)>	ff:'r%
%dfi:ff,:h{h2*ff04hhH%fi)ve)	h{*ff0x%,<ph>%fi
%fi)?-)figfi:ffh3Hff2:ff- dfi6@ed&:er
h*ghfiM%H :y%0!3& -@?-)fi>fi:ff2&3@-ff:'r%%Mfi:ff)
 %3*sfi06:	h{*ff04hh>3Hff2:ff xfi6ad s&
:er
U3&),ffd?-)ff:'r%&yfi6,)  &')*fiff9:fffi)dfi<)>4 ff-fi3,
23-%fi)%	-')fi3-0ff'))%sq!3&@*r%%fi:fffi)h),%fi))fiq%-ff
)%42:	2*ff04r@-fi	%%3%%/%':fi	fi6ff263fi%y:ep')%
 bffff%M !fi3,ff)%b!%0e !:)%@&,6,h<wyb6fi3`%e))

%-fiVhffQ&%-ff	&)a@-ff:'r%%,fi:ff#U)y?-)H%	)?-) 
h<<_{dr%,ff#D<)ff0%06fi363&.6fi)0ffd !06)%hff_6fi3,fiw)4 ff-fi3
b'^%&))%#hh@ff%y%{@ff_6fi3`fi<)Q4 fffi)3  &')*fiff
 !06)%hh<<_{%D<)y0%fffi)%2Q3/ff&3-@%0e9%':   )%
&	)%  %')*fi0ffd fi0ff!3&Qff5/9:fffi)Qfi<)@4 fffi)Q@U:H
%fi)6#&)@ff,?-)ff!%-%fi:ff/ff#Dw)H0%06fi3ff
	)%Hfi0ff fi0ff)%sffl9:fffi)fiw)4 6fi)!-@ff:&fi3
ff#&)@ff,)	?-)	%gff-fi3-0ff-ff:'r%%sfi6@0&0fffi)r)ff#Dw)H%
%D<3ff-
 aw< 6,fiffM fi0ff!3&d0e@ fi)0xff&3  &')*fiff

 !06)%9h<<g')fi)s&<Vff)%sff fi)p-ff0&)fi0ff fi0ff!3&
Q	h%fi:sw)%ff1ff^fi&fi3ff29:fffi)fi<)>4 6fi)%s),fiff
 !06)%fi:h%*-)%:er
%':fiffa6%	,fi 	%	e%>&fi)H3fi*%dff)%@&a-fi%)%s{
e%)%e{%)#-e,d%y6a&>{')fi),e&)%ffhy&)%fi yd	fi:ff#
) %sff#)y  ffl%)%% & fi -:')%,-%22%)%#&)fi:&%ff:h
*)%#%%fi)ff#	%-fffi)06%%e:yff#	%hfi:%->6l9rd	6fi)
fi)% H)3fifi)%#&&9	0206%p	%)%&:)%fi:de%)%
	 *%e%)% g fi2fi:ff,%h&<#fiffd*%h%	fi%)%s{e% 
%%&3d 	 ffsq&%	)	e% &%0&)- 	 
%-ff &)-fi-),h%-%	yff0ffsh),)0fi:ff,fi:h: fi:e<3/
&<#{h@!  yff,fi -:')%@-%hd2fi:ffxeffyff&:e
fi)ff*d),536-ffpfi:ff#6eyff&)fi0%06fi3		0%sfflfi%:')d%p%!w*&3
Hfi:ff#fi%d)fi0ff-g- ff)%2hfi:hff:h&dh5&':fi?-)fi6
 %V_6fi3dfi<)4 fffi)d%,)@sfi06:g&fi)),%*)&

	
pfiff'

2d,g'p

rfi: )%`hff ffff)%dfi0ffdr !#  %3*sfi06ffg- ff)%Qff
9:fffi)`fi<)@4 fffi)b/2%yd:yMff:'r%&Mfi6r #2ff`?-)
ff!%-%@fi:ff4	*%>6bff%fi #-y:y@ff!%-%@fi:ff1r !#lffQ,-3fiff:'r%&



fi !"$#%'&$(
	) *,+-. /'0$+1/32+-54$687'6)796:;6-</96=?>@-5)$A1*@B	-ACD>,+E*F:;)$+2G6H+-$=I2+-54$6J29062'K!6=D>L-I)$A1*@B	-ACD>,+E*M/;>LCN6O
P :RQR68CN6-</S>@A!-6=H/'0	>,:T>,:U+V-A-W/97;>LX>,+E*MYZ+!2G/36X!6-5Y[A7RCNA=	67+/96J:;B\:S/'6C]:OM^68)7'AX68/90687'6:;_	*L/
YA78CNA=	67+/'6N:;B:;/'6C]:`Ha+-$=/'06-b:S0AcQdQe0<Bf>@/g>,:J+))	*h>,2+4	*L65Y[A!78/'06D7;>,2'067D2GA-</96Gi\/8AYkj_$+!:l>LW
CNA=	67+/'6J:SB\:;/96C]:O
m 068)7'A<A1YnAYFA_7kA1opWq*h>L-6J/97+2G/+4	>h*h>L/;B]7'6:S_	*@/QR>h*h*rYA*h*LAQsY[79ACt/'06YA*h*LAcQu>@-v?*L6CNC]+:`O
wFxzy{y}|~rzpEr'D5LqGhVJ!<qE,	]N!\ qID!;DR!$$q<
 <qh8a!z,	VE  qqghJ'`<E,9NfiLhF;q,	$qfin!$88<E`
<`V5< q<;N`cqJ5,!ghI$D`<,Eq<gbq}q	RV  <E;
q<Nh	`zqS  '!<zIVUG
JE$GR YF/'06+1v6-</R)$67;YA7'C]:e+E*LA-v]+-	B])$+1/'0AY  CNA7968/'0$+-  +2G/;>LA-$:RQu>@/90A_/k*L6+79-	>@-v
+-	B</90	>@-v5>fiO6OH\+c*@A!-v  +2G/;>LA-$:T/'068+v6-	/k=	A<6:T-A/Rv6/k+-	BN-6Q>L-	Y[A79C]+/;>LA-I+4$A!_/k/'068+2G/'_$+E*
4$60$+EX!>LA7.H/'06->@/8CD_$:;/X!>:>@/D+5)$+7'/;>,2G_	*,+7VA4$:;67'X+4	*L6]:;/+/96J/;QR>,2G6HQR>L/'0A_/8v6/9/;>L-v+-<B-6Q
>L-	Y[A!7'C]+/;>LA-+14$A_/k/906J+2G/'_$+E*a4$60$+EX!>LA7H+-$=5/'067'6GYA7'68QR682+-}:;07S>@-K  4	BI=	7'A))	>L-v+!2G/;>LA-$:
Qk0	>,290}/9A<AKI)	*,+2G6?4$6/;QR66-}/906:;6JX!>,:l>L/:O8^6N2+-)$67;YA7'C/90	>:)79A\2G6:':e_-	/;>h* /'067'6DQR>h*h* 4$6D-A
:;6j!_6-$2G6JAY  +2G/;>LA-$:T>L-Qk0	>,2'0-AD*L6+7'-	>L-vIA\22G_7G:O
m 06*@6+17'-	>L-v]AYF/'06J+v!6-</T>,:RCNA-A!/'A-	>,2FQk06-6X67e>L/R*L6+7'-6=:;ACN6/'0	>L-v]+14$A_/k/90686-<X!>LW
7'A-C?6-</84z60$+X!>LA7HzY_/'_7'6V>L-	Y[A!7'C]+/;>LA-{2+-5_$:;/8C5+K6J/90	>:gK<-AQR*L6=	v6DCNA!7'6N2GA-$2G7'6/'6OD>L-$2G6
/'06V-<_CD4$67AYF)$A<:9:l>L4	*@6D4z60$+X!>LA7:u>,:  H$QR68v6/k/90$+/U+?K<-AQR*L6=	v6g>@-$2G796+:;62+1-A22G_7+/eCNA<:;/
 /S>@C?6:O
 ACD4	>@-	>L-v5/'06J+4zAcX!68A4$:;67'X+/;>LA-$:T*L6+=:e/'AN/'06J=	6:>@796=I7'6:;_	*L/O
wFxzy{y}|~rqk a89LqGfhkDE;3hz$q<  <qhaG$q<
  qq?\1[`h]'`<E,9Gu!$  	;Iq<5!<`q,ShE<q5a<
q<EVLq5;;;`E$qI;kl,fT\h$Dq,55$8Z	Iq< EG ,	Dq<F
8qEGN!9D!G,G5<RqqD\h$!qaq]f$V
JE$G}m 062GA-$29>,:;67'6)7'6:;6-	/+/;>LA-   AY  2GA-$:l>,:;/G:DAY+/G+4	*L6H Qk067966+2906-</97'BAY8/'06
/+4	*L6J2GA797'6:;)$A!-$=:R/'AN+D=!>:S/;>L-$2G/UA4$:S67'Xc+4	*L6V0	>:S/'A7'BNA1Y+-?>L-</967+2G/;>LA-IAYM/'06J+v6-	/RdQR>L/'0I/'06
6-	X>L7'A-C?6-</Hz+-$=2GA-	/+E>L-$:k+1-+2G/;>LA-I/'AN4z6J/+1K6-]4	BIYA7k/'0$+/k:;)z629>h2Nl)$+7'/;>,+E*.3:'2G6-$+17;>LA$O
m 06-	_C4z67IAY=!>,:;/;>L-$2G/I6-	/'7;>L6:?>L-/906/+4	*L6{   .N2+-4z6*h>LCD>L/'6=/'A>L-$29*L_$=	6bA!-	*@B/'06
)	*,+_$:l>L4	*L6N=!>:S/;>L-$2G/k0	>,:;/'A7;>L6:Z>ZO6OLH	/'06U0	>,:;/9A7;>L6:RQk0	>,2902+-]4z68v6-67+/96=z.rYA7R/'068:;B:;/'6C  +-$=
/'068)	*,+-  O m 068-	_C4z67kAY :;_$290=!>:S/;>L-$2G/U0	>,:;/'A!7;>L6:T>,:k4zA_-$=	6=I4	B  fi/'068-	_CD4$67kAYM)$A<:':>@4	*L6
4$60$+EX!>LA7:eAYr/'06V6-<X!>L7'A-CN6-	/. /;>LCN6:  l/'06J=!>hop6796-</U:S/+v6:T>L-+N:;)$629>h2g>L-</967+2G/;>LA-.O
 -]A!7=	67 /'AVX67;>hYB/90$+/3+g)	*+1-   Qk0	>,2'05>,:T7'6)7'6:;6-	/'6=>L-]/'0$+1/ C]+--67>,:3:9+/;>,:lYfi+2G/'A7'BH!A-6
-66=:e/'ADvADAcX!67u+c**M)$A<:':>@4	*L6D4$60$+EX!>LA7:k+-$=?YA7k6+!2'0IA-68A1Yr/'06C29062'K5/'0$+/   *L6+=:e/'AD]:
vA<+c*ZO
P :k+-5>LCNC?6=!>+1/'62GA79A*h*+17'B]QR68A4/G+E>L-/'06YA*h*LAcQu>@-vz
D x	Ex$y~rLe  ,zq<{,Efh$DE;Rh$z,	  <qhaG$q<
L8;k;q$D;E<hc
 A-$:l>,=	67]+-+v!6-</DQk0AQu>:S06:D/'A7'6+2900	>,:]=	6:;/S>@-$+1/;>LA->L-/'06I0A<:S/;>h*@66-<X!>L7'A-CN6-	/NAY
62G/;>LA-sO  -)7;>L-$29>L)	*L6HU/9067'6ICD>Lv0	/4z66Gi)$A-6-	/;>,+E*h*LB<WC5+-<B0	>,:;/'A7;>L6:DA1YA4$:S67'Xc+/S>@A!-$:D/'06


fik{r$8L$$
 	I]E$G	'te''GL'`8I';	L'E\5'$15@5,f'G!$l,		L
$1@	D,EhL]	 'L	'I$9}9';,'		,aff
R	,e,N<;Gfi[	
k'J	lLa;Rhh$	@V'N'9;<e;!;'I;1@S@!LD'G,;LGL}G!$9S
kE
 39;!;'SL;L!U';, fiG'!'$9	 fiG uh z I9@	;L}	9G'a$
$9$ $R $' $EL' 
R 9 	L  $EL<1;LNLI8<S;h@	L'?< 3eN<S@!
 zc!eG'$EhL;Lf'	, kE
e;,GD'$ !N5# "$fi $g& %	L'5';, fiG'9# [N	'N;;'5 'k RL(
 %$!lfi 
N	';;'5N'	,) !N] ,I!I$; [	fi8lL$G @'$I;+ *]@!<, z} -$!<;,E
Ls'G'$E8' ';	S@!lfi ./
 'e 3! 90 9 $'S@5 EL1
 <2
 !N]3
 "$fi $
$'<EL1
 	G$l,	;L 9L<, 	,$`5
 4N?<; !G;,E6 7 $<;` 3	{?L<;
cL;, 	]'S';,G;LNU1''	;LI'D 9L<8 	,$lL$G	 	,8 Rhhn! $D 	LJ'
 -G'] -$!<;,EhL{]	!G;L$L{']GSN U,
 	,a) 9kL{'$ff !pN], "z; :		
,#  %!$lfi N	98' ';	;L$` R8= <
>	?A@BDC@FEHGJIGLKNM OQP=RS(T)U=VTWOfiXY[Z\R=]T^R`_baTScSFOQSed#fhgeOQaRijRT]kScOlSd`WnmW^R=Y&oApbSF\OlSdqTS(RsrtX
u OQR=Sc^LWT^OvWlwT u ^Z]km8xAayTS0OvWffZz XaOlScRff^]T u ^T{aR}|

u	M9;	LF,
 %!	L'U'S~ ZG9'lL$G6 %!$lfiN	'k;;'5F'k;,'5G<9-\h4F-
	L;?U9	L'G''R;$9!F'k! !,'G$';#	qT'	 $D	,RGhL8 9<
$=p1
 $''9! %!$lfi N	'US\;9]L
RVL$9@$	J8zL<!D,Ea<	$TpS
;GA k	,'{G'' z$'1} -$!<;,ER<	zJ$<'	L5$;';L$M$99;'
<c@$SUVh,;U J$<9lfi 	@D	L'!N<8 $$E!L8 fi'J ' ;,'J;$;!  aG'kN9 
	,;,I9 
 I ,;I J<!L'N	, $$E!@! 
 8` 3N	;L1
 $ '8 %$!lfi 
N	';;']5G'' $$'G 	L - ;;']` k''	[ zI ff$	'lfi 	L
 R;,
	'G;fi 	L'N	L'!N<g,8 9L	;L<? 	Lq 
RS]G$;;L'9]5;,'{$ zEfi 
L) ZL{ U;;'] ~'Uc z'
  !fi $=$) kD';	LD; J [!J -$ 	LF'$V'
'1] fi';\S't!9G$';?LI'8 'L$e;G;L# $ 	hLUR5 -z'k;;''$
	!SR' -\kG;L5'& $ $ [9N $!;N!]'	,;'9N r $S'cS@!$ 	N'8	G'

R
 9 	L kGDL u@9' 	,5 $5';L!,Efij J!8';	LJS} d9$J
G$9,;k9 ';	;LD 8 	, e	9D,M 9L	;L!;  	LU	< -<,;L e D 9L<
'S~ ZG9'# 	1} -	,; 
R9 [9$'D a'e  S@5'N ' ;,'ff 	, jqhLV
R'' k	hL
J#L8}DAs

fi?'	, ;G;L`3k;{'$MLM,FMhfiGLN'$1F''T, cEL;L'd'JG!NRRL'
I'S~ZG9'	,3J	N	'#M,	L+k	h@,!9	@;;'alL$Gff;$;	9,!L
k'5;$'	1-	SV,]8L$1,'5'I';	L`[D',$!l,#NR
 G;L5
 :1
 lLDh,I';	L5,N'	!Lb I9@	'S~ ZG9'
 	,$
 
R	, uh8L 	L
lLDh,8';	L '!;J   I9@	J'S~ ZG9'# 	1$e@
 %!$lfi N	' n1	@, e	L
!9	@I;;']`\1$#
 R'J -'$	# ? 3! \R!,'G$'S5L' [1L RLI;G;La

u	f';	L9'#
 RL'' ';	L5 c@ L'+ '!L$;G;L G` 	@9'
9,'l S@!} M,	L, k	hL !'	LI!9G$';fL  G;L+ 


>	?A@BDC@FEDIKM OQP=RS,TqY	Z=\R=]T^R_aTSFScOlSd	fhgeOlaRiRT]SFOQSed&WmWn^RYffoh\R u Ol\OlSdfhgeR^QgeR=]^QgeR]R
ROfiW^QWTST]n{Ol^]T]mZ]&Rr u OlRSF^	WnT^OvWQwnT u ^Z]m8xDaTS&wnZ]ff^QgeR	T=dR=SF^OfiWffTS)8_XgeT]\xA]~Z{aR=Y|
=k

fi+tFF

ffAF fie57[lt8,}lfi==fififi=tF5Flfi27lF=
  =fifiv  +FFhficfie	l6`b+`khlfit fiA=fit
 F7tF7, elk#lsl
  fi  [Ffiff,lk#
~eq=fifififfF8l F= 

 	F	l Dyfi	 7[llfi
 ff8LFkA
lfifi=ff7F6=7lfi+ 8	 vk,lqlj)k7[
ql8
 ff8LF,fi
 	 8=Ffi+l ff  7fiffl
lF8 	
  l
F}=
  fi
  =fififi    A 	,Fe~fi
FFfik	8,efiq7
 !  " $# fififi % " $# &  " # =vfifi&  " # ')( 7 7+
 *,1cefific
Ffi -&			fifilk&l.
   	qFe~fi,fiF6/
  v0
 21  13& 4  =fifiv& 46576	98;
e}Dl	=7,[k/
     A 	
 9
 l;
 :<>=?@BADCFEHG%<JIh (fiF
 kL K=67M
 	=fik	F7 K(N
 
(  l7,l )FF=kL -	
O e,k7.
 P~R
 QTSUH3=vfifi& ,V=fiF	= .
  kL K=[W
 13ffF 
fi`eLcF==Lkfiff7X
 PY" $# F& 7Z
 2k[ K=j7fi 21 F&efi
87ffFFfi.
 PY" # A	=fifikl/
     A ( 98;e\ -&	fiO8FFfi
Z
  kL K=fiF 21  137k
 P~c	=fifikl/
 P]AL 	 ( JL Kfiq7fiF
4  =fifiv& 465Lfi=		k/
 B-&	
Obeq7lF _ ^ fi,=7 7fi ( fflfi=fi=`fi _ ^ -LF l F=


 4  =fifiv& 465 ( t7lF+fi3}lfi=,Fa
 `(lfi
_ ^ b77l7+	fiF
~e)fiklfi= -&	cbsF}k	l
   ^ LFd
  L K=8,fi;
 4He
 l7fflL77l7=ff7[~ehFL~F 2 ( 3L-F7lfiL fFefi
FF=&kfi)

  ( Fh
 98 Llff7fi}fi
f " #g
 ( f " $# -k=fifi+k&l.
e`L -&ickL Kfi,fiW
 4 e k
    ^ AFff8FfifiqcF=fikcfi=
qk/
   ^ A% 	
j3}ttFjJ vl D elkL7ll`    	LA
kZl 3fififi ,VnmM 2 B 3L Ffffifflfi=8  fififi  Fl F= 

 	FjF7F
`v
 oFp,n
 bfi l fi+N
 Qq>r 7jF	 kL K= 	fi 21  13[cF)
	}}` k ( Qs-&	jAfiW
 ,tcuAFe8kL K=8fiW
 46eFFff=cF8#
=7lfi, k 	lfi=F F=fi _ ^ 	Fbl=Fn
 oFp`fi=F=
ekfi=LffF}Jefi cF=fi	
 	hFFA8v~s78v9
 oF
 qb vkL[fi
kwv F vD F= 

 	 kwv l FF=,kfi	x
 Fkn
 ,+Fy
 o ( cFfik
Fhvj=7[F=h -!zN l7	[FjFfi 21  13	 k v l F=Jl
lcff	7vF _ ^ F7qFbq~eFbvD F= _ ^ elk6fi
 k v 8;fi	J8}lfi=8L f l,l,F7# ( ,t9u{- q>r 7j
fi8FFfi/
 f " $# n
 f " # 	

|~}~wTT~R!9V
	fiFff=F8fie7F=F fie=fie=3#kh7K, hlfiyfi
A=7{
 	L5q[ ~ =8j`JlF= fi,7fiF=fiFbvFb76e
=ffB j=	fie&FF 	l8l.fiF7kLfiq0ylF	b
qt=	,ql1(F~v,+F7lvqFfifi0v (  	  	fiFFfi

&

fin!!!wc/!]aw!!!w

7&[w]])!w]w&fiLw)7!_h!;7%_7!a7!h_wL!xL]7wL
 67]6]
s)  _>waa6>/7&LwDs%;\!w]fi]H7_]!!7w]7s6\7
7B6]!W76L_!7!%NwL  ]F]7!h7&Lw  7&[]696_]wd]]!
!9B
;7%w6+can!7L%]!B]!  [76L7!_  76&\!7!7
L6&n%!7!7!7/
6x/6!7h7!/7wLL6&fi%!+%.7%!7
9B7%B7!.L6H7w7L!+[wh
>J  76n7!.L6L6nB]!
g7!7_wL.L7!w67!!R.677[gfi!%7!/]677]!a7wD%

6
>].7hw6nx7!./[6]]L6fi!7ws7[D![[H!
 _LT7!LwL_w]w/L77!&B>]L]wLT!w&[
7Rn
!7
\7%!/!Y>!g]H_&&L6>>]W76]&!Lc]W7!g7w6U\&L
7!
JhnL

 !]w7HL%!LY>]!/7&L6>J]!6hw/L7\6>]+wD6_RTW
>>6w!/7!
!7w6h\&L
_
Lwg]6]HL_/7!.LY>]!.7&L6>>]D[7!._[7  76]9
\h~RRWa.{RHL
h%Z]\F fi\BwcZ>{wYHaHYJ&wYH	
\
fffi
!"#
wLZ9s/L%$'&!()&>*\\	%gh/L,+-$./&>0\1$-2hLYwY\YB{	3 4\%\
657s/LXB8(19$8ffBw%&_	H:(1$;<~L;YwY\~B8(B=9$>ffNBw2&_	H(B=$:?57[wW
@$'&_F/-\1$*A	B680\1$C"#!DFEGHEIJKHEI_wL.677]!X_W&L75Lg
wwB%]?M5CgwLwa]CN569 7!/!&L7.[whwwB]4
O=O>PQ"#	).N &

R n_wLF]9!7w6SFL!6]!n6>]?T L76]!s79%7!nL]wBR7&LwDs%!ws%
9B9_wL!7!/wwB%%U\ H_!N7w _&Lw]]h\!w]R
Ly_!/H%]7!6
 !fi6w6]]LHB[wL.7[%77  [9
>>79B]9%F]9_!nw &[
7R
V 7W  _JJ]
U%7!c7wL_!U[H66h!h]6]B>] 6!L 7!a66]LWL
!!
!76%  L_wL.
>>Xwd7H[&%]7Lfi7!66]L%   !+L%H
!L
6!Lfi"XF
!n7s!  ]wF
>>  7!72Sy[!6!/x6J]%T L76]!/]7!
_w6
\&L
7Rng6&[77    w%]\6L7L
7w6YSFL!6]!n6>]TR[76]!s7
/SyL!6]!n6>TRL76]!s_ ]Wn67c7!H!{/LT]HxG   L]H!0
Lwh7!6!N{nL]6&]I   L]6!BP_  6  !Hs]7!.]/L_!.7wB
7  7sH&[]T
!L6]!LF7!/6w6s%w
n]7!/wD<SyL!6]!n6>]ZTRL_6!
\&L
7R
[ 6\77!wL_\TR9]w_^h6H!!Ld\.!6&L_9!7w67SFL!6]!Wx6J]
TRL_6!!79xLZ%Z%hZa6]!)] ]`]w
7!  7  7] !&B]!)H
TRh*]w_^/Law/7H! Hw6]!a+_]6  LwT!xH  &s  !  6!

6!~]Hs/!&B>]Hg77]!!nL7_H]g7.a+_]6  Lw!]w.  L!!n
>>!
wL6]7a!_  !6B>9L6W]wX7!9%!&Ln  Lh//
Hs%!
w\76Ln\  ];7!]LX_L77  Lw9BsJ>nw  H7]6]>fi
97s7
!&s%7ca+_]H  Lw6]W9[9!7!  s%wLw%!N_!]LX_!7L7
6_]c77
 77!w[7]8TR9b]w66n![ \n!7w6CSyL!6]!n6>TR[76]!s79

!
 76L!Lw76R]h
\7!_w6/\&LgZ%7nF]>L~7
]&  76L!].7!w&[
7R
c 6]6]!9_!.LwL/
/!D
d R 6Bw \!fe =(Bg!B6._h9ff*$
D%\N\Bw
>w{6H>i wYH4	
\
ffUj)kZ{YH
c/lm0BBwn\o1A0B/$M+>c_U$qp2hD>Yw./0B\'&>.r
sts

fiuv-w.x-vIv-y-z7{P|:y-y-|y-}8~-;8

X 1X_!o;8>86		>G
M-;-	_'	;!99_-U-;	8_Wo,:8	;-!Z-	:92-	;2;-	P=n;\;8.*-%.:	'
_;-29-9;	C-!9.8-8)_9_X)\@@;q-P;8;-	;%	'X;8	-	.;
9_8
MY);	;!q9_-I!;-;.M;-*)_9_.	)	9=4;8.*.	'**_)*-U>*@=.
_;-2'
8*;-_)_9=
9.;-2:;-	.:	'!2	8-o-)-*2)@_<!.;)_-*;/	
-.7;U-%	9\_)o6..	),;9_!n;U)	:2_n'
-2)@_M!;)_-W8-,;-8	8
_
.,;-<	)_;-b	'!>.8C.>-2;-<:'
=2.8b_)_9=
P9.;!.:;-	2.	)	
 : X_!oXX18 H*'@/o!:!>P@8>=)*'=@4X:>=)*	!	/!=%*-)
8`U
4!        M2-	i)=,%9	.'

'	@	//8	!
8'!=,M9	
 i-=,;-4=>=/1)	//<9%!:!>=\<9	,.
8
=9>Z
8	)!1
.>./	@2:!/1-	' <

   =%.=>=/1!>!198*!>P;'
=8.8 *    M    M    M F=M
@'/9-	1/=4	'>!/18.2)	;	;*_-!!;68M.P9.!	  U.	  4.)8	8
_
  .89._'9_7%;-C.	)b)!'    ,;-6--Z:89	;)I9.!U%;-
.	).8;-<-	':_;-	)%>	8
_          ,Q      .      



m.	)Z8:4_.2'.8*)=.7=G)!=_;;	6;8.*;/	*:)7G;8.
.	)	89	;..)_Z9;!	ff
 
-Z) fi8)_9_8M.Pb)	;U.8
 :8_/-)	.U;	-;!q	'9_8
.;9;:'9/;2.M	-	
@ !.9_8n.;-_P) fi8)_9_8n/-;	8)!=.-)_-U2)@_%!.)-
9-9;	
 7-:_9_X\;9-;8.4!L.	)Z	.79;<_->._'-:*=
@7.'
_)_9=
X89	;..)_?9.;!	.8W
Z8
-.X8._)-*=
@_'*'o#_\*_'\8M;	 :)!
;*;)_	
 2		;-_!;	-!6.	)!*-
 '-.28.\;-<8,_)_9=
9.;M.X;-%:;-	
.	)M=	8I28.<;-b <:'
P.;-;-	U	'M=	
 Y.;4_'	;!9;! _L;.9=;:;
*'@/o!:!>@ P ;_-<8
 
 :X_!oXX 
  _	 **)_9_.	)%o-)-6)_*!.;)_-C9-9;	C-6*)@/_9!
8:
=248
_.9	\.)o8	--<9	\:!:;6.	)!,	!  )	-;<;-<9	.)=.82.:	'
;`*)_9_.	))=.=M:/_1:!/@X/! .:	',.8*/\!;8);_)_U'#"..:	'
;:;-	;=M)=.b
 $%!_9);8.P)_	!&
 "W9.;9_-M/; '48';)_M_)_9=
9.;	':_!;
.-%)=./_6;-<;;!9>8:_-'
 $%!)(
n8*_)_9=
9.;2.;-%:;-	2.	)!'.8b;	':_!;
.2;-*_)_9=
28	8
:_*.2;-	)_;-b	'!MQ+ *m!1!>:/_1:!/IZ)@/_9!
8n@o4
;.qo;6*)_9_.	)<)o 8.?:8=9M.P)=.8i2)=;L;Z)!=_G;	!M.P8)-*=

)	-;X


-Z.>:U) fi8)q:L	.-;-;!_')q:_;8.9_8.P=.-)_-C)_!.)-_I*)_9_
. 	)Z):
_8	G<;9-b/U8.)_6;8Z-	; ;96/!4;8U8
;C.b_7;-
-'9q_I	)_;-b	'.,!9_.--/
-	m9.;b._-G10.32L\.87-	!;G!;7-
)!99_8.q:8U)5
 4
 26 2		;-_!;	,;-		.G-48C9-;.8-*;-b 4_)_9=
_	.q:
.,!C;-	M.86.8:-%!6;-	7 2)!99_8.q:Xff
 Q8-Z.8)	%.;	-;)*_
;8.2	q=\;)	:oqUU9;	;/)=.68.9-:)o><)W:X)
=	:)_9=
#-	.9_88.8
	)_;-b	'<>	8!:_	
 
)=M9;	/)oC=i;-Z;9=:;;6*)_9_.	)<)=.I4_)8 6/!
9=U;82.		)\.,-Z.:	'2!7 9X!2;-U>	8
_M.,;-U9-9;	 .8;-U!9)_
:7;=<?>	@6ACBEDGFH>	DGDIBEJKMLK	A3@GNHDG>COEPGDRQ7JSOEAUTJ@RLSKWVXFJK	DGPYLKWP?KW>	Z\[%NH@?JST=L]^NHKWPGDH;
_^`	`

fiacbedRf	ghbhbhijb#kml3nhif	oqp#o8ghrhbhijb#k
s%tus8vSwhxWy{z}|8xW~vW	sxWxW~vW6vx	z8vs$HxWxcvSw#z%v\Mz%ycSxW~#z}yHsshWhy~vSwhxcvSy^z}h'z%YWz%ySx
x#z%!xz%~#~q'z%~!'s8vwhxWyc~#z%vShy^zHvxW'W
 x'~hs%whsvSw#z}v$s8hys%6I)~hxvSy^z8v^z}!)vH5yx	H!vMWz}~5xxvSxW~#!x	evsvwhx'!vHYz%|8xW~!v
Wz8Hx$zffffxY  x3ff))#x$vSwhxUtGs%)s~h|vHffs$xWz8W
e6I#cI	7	!%WH	87G)Gj		#&{)8#I?I)$68#IW	WG	\?7H
8W		$!%8#)8878' 8.+	I	$W8GjW87G8^e)Gj		U=)8mW8WI	7!
IC$	8$CjI\I	I	HCjI!W8m+	I	#W8GjW8	G^)Gj		#=)8I8c8
 7#	8I8)%#8I8u8W8  		 {'Ih8)86G%
$7u# ~vSw!ffWz8HxUx	z8Swz%|8xW~!v\!~hs%vSwhxU|8sz7us%t6vSwhxsvSwhxWycz%|8xW~!v	z%~#whxW~#xUvffffx	z}ycvSw#z%v
vc|8w!vcx	z%y~s8~!t+z8vcz%#shvcvSwhx3#s!S!x$~!vHz7\Hv^z%vx	{z}~##xWw#z7s8y^W
 8xW~vSw#z%vvwhxWySxs8~!zms%~hsz7~!h#xWys}tsS!xq~!vHz7$Hv^z}vSx	z%~#exW~!8ySs~h
xW~!vc#xWw#z7s8y^W#z}~#|%8xW~vSwhx3s%~hsz7s8h~#s~vSwhx$!xWhvSwqs%tRvSwhx!z%~#WhvSwhxWyxz%ySxUs8~!
#s}!~hs8z7)m'z%~!x	8hxW~#x	Xs%ts8#HxWyS%z%vHs8~#Yx	z8ws%tXw!jwms%t#s%!~hs8z7?xW~h|vSwu{s}tx	z8w
z%|8xW~!vUvSw#z%v3z%ySx$s}t~!vSxWySx	v$zff~5uxW'zE!^UcxW~#x8uffxWz}~xW~#sh!x8u~m#s}!~hs8z7{#z8x8
z!x	js~v^z%!xtsycx	z8wz}|8xW~vXxW~vs~!~h|qs8~!vSwhx	HxHx	hxW~#x	W6z%~#mwhx	Suh~m#s}!~hs8z7
vHx8hXwhxWvSwhxWycv!xWvxWyS~hx	zSz%vHtYz8vSs8y!vYz}|8xW~vU!z%~6
e6.cI	737}j		H8GU!)GH	87#{)8#IX?)ff68#IffW7G7.=?7H
8W	87#%\}^W  )\878?	H\mj?8)%#8I8I  883IU8	G!8hHH=HC7#G8GI8
WWH%\I	HW%WI$7%Wj	87H8G'!)GH	87#ffff##I?IM8#IW	WG	RUY?7H
	!%WH	87GHGW	GIm87GHHuC7#G8GI8jqHI!^)8I#87WG	$II
!#I	!c8	WW8c8W'78	I6WCMI!8I	H3CjIc8G77#3GI	G8$!Gj78	hu
I   $88#) $I	HCjI38Y+	I	W8GjW8	G^!)GH	87#=)8mqc
$7u#ff  ff)#xffh!vffz8utGs%)s%Wffwhxffs8#HxWyS%z%!xHv^z}vSx	us%t=z%|xW~v~   ff))##xffvSwhxcWz%yvSx	z%~
hySsh!#vs}tRvSwhx$s#HxWySz}!xHv^z%vx	\s}t&z%|xW~v~  ffvSwqvSwhx$HxWvcs%t\Hv^z}vSx	W
C!	HH^%W	7%7 S^%W7	%    %    'ffwhxM~!vHz7Hvz%vSxs%tz}|8xW~v$~   ff))c#xv^z}8xW~vSs
#xvwhx'#z7ys8~#Hv~h|s%tffv3~!vHz7v^z%vSx~  z%~# WH7  z}~#mv^|8sz\v^z%xW~vSsxvSwhx
HxWvs}tHvz%vSx	~cw!	
w     zs#s8~hxW~!v	1ffwhxxW~!8ySs8~hxW~v~   ff))xzWz%yvSx	z%~
hySsh!#vs}tvSwhx3xWw#z78s8y^ff
~ 
 ffvSwqvffsHxWv^ fi3z%~#
 fi%hcwhxWySx fi  w#z8  HvH~#v3xxWxW~vW
     S      
   %    cw!Swqwhx$#Hvffxx	hvx
 |8xW~!vcff))w#z78x$zjvH~h|8!Hwhx	mz8vHs8~6#Wz7)x	 %W		%!
~ v~!vHz7v^z%vSx8.ffwhxHvz%vSxvSy^z}~#vHs8~ th~#vHs8~1ff))$#xmz8M~  ffhhvcwhxW~/#xWyts8y'
%W	7!   %   v^
 ~hxW s#s8~hxW~!v  ~vSwhxWz%ySvx	z%~5hys!#vHz%~#s~!vW3ff))Sw#z}~h|8x 
vSwhx$w#z%~h|8xff)?#x$vs %W		%!   )t{z%~#s8~!)t\vSwhx3hySs x	vs~s%tvwhxU~!vHz7\xWw#z78s8ycs
~ fi  j
 S     z%ySxUvSwhx3#s!x|8sz7&tGs8y{z%|xW~vc~  vSwhxW~vSwhx
    ~z8hvHs8~6#z8Shxvw#z%v    


vSy^z}~#vHs8~tGh~#vHs8~~ ff)){Sw#z%~h|x3vSwhx$~hxWs8s8~hxW~vUs%tvSwhx$s#HxWySz}!xHv^z%vx3vS!s     )t
z%~#s8~!)tRvwhx~hxW.s8s8~hxW~!v{s}tRvSwhxUxW~ySs8~hxW~!vj{~v^z%vS"x     hz%~#zHv^z%vxSz%vHtG~h|   
w#z8ffxWxW~ySx	zSwhx	u
whx\z%#s%8xvSyz%~#tGs8yS'z%vs~UtySs  vSs   z%8x	uvSwhx?!xW~!vHvH$s%t#z%~$z%|8xW~!v	E|8s!z7zcs8#s8~hxW~!v
s%t6vSwhxff~!vHz7)h~h~hs%c~#xWw#z78s8y7\cs%ffxW8xWy	8z}|8xW~v\?z%~#~hss8vSwhxWyffz%|8xW~!vff)6s8#xWyS8xffv^&|8sz7
z7tGvSxWyv^$ ##y^Hvcz8vHs8~6?v\x	z8HvSsHxWxcvSw#z}v\vSwhx3z%#s%8xXvSy^z%~#tGs8ySz%vHs8~8xWxW#vSwhxHhHvSxW8#z
sh!xWy^z%vSx8z%~#vw#z%vvSwhxWySxxHv^zz%vHtYz8vSs8ySm!vHYz%|8xW~!v!jz}~e~  )t$z%~#s8~!)t3vSwhxWySx
x!jv^#Swz!z%~ ~   hcwhxWySxU~   x	z8wz%|8xW~!v{w#zffs8~!s8~hx$sS!x$|sz7Y
%&'

fi()+*-,+).)+/+0	132 /+/+2/+465+7986:

;=<>!?@BA@CA+DFE9G+HI-?J<LK HNMBHO>P>QIR"S"HTDHOEU
V!WYXZ\[X6]_^a`cbYdfegihjklnmol-pOgCqsr!tujvwl xyjr!ozcxyg{qwl| jkJx~}zclk6kJgk|~gzcjNajl vkJgk|TpOpxyjr k6uq
gik|Flk.jygjk6xr!ozcxyg{qwl| jkJx3pOlxyg{pOlxytv\zclk.gCptsqwzcgkJj!xyvwl xylzj-
 G+HI-?J<-KH+<<-RsG+<-SR=E9G6I-E$MI-A+A@CA+DQSG@cMCHHI-9A@CA+D!@R"<-aiMc@CA+HTE9IEI?MBHN@CA>!MCEs@CI-DHOAE
O IRsHR"Rs6GIRE9G+H< A+HRHR9s@C?6HI-?6<-KH=@BK HOAQE9G+HRE996E9+9H<-E9G+HTI-?6<-KHMCHO>n>QIR@CE"@R=HIRs
E9<+<LK HR@C>!@cMI-9HRsMCERy<< E9G+HO<AE9H+ERaSG+HO9H3E9G+HOH@RI"6<MBA+<>!@IMcMC!?6<+A6H+A6HO9EI@CAEw
I-?J<+EIT>!MCEs@CI-DHOAERRsEHO>+<=HI->PMBH@~SHNS"<M!Mc@CHTE9<6A6IT>!MCEs@CI-DHOAE"M{IASG+HO9H
IRGI@cMC+9HR=<-IDHOAERa>!@CDGE3<+O+@BAPE9G6I-EOIRsHE9G+H=I-MCEsIDHOAE~>!@CDGE3A+<E3I 9G@CHOKH"@CERD<IM
?++ES"HN9H@C9HE9G6I-E"E9G+HT<EG+HOIDHOAE"S"@cMcM3RsEs@cMcM?6HI-?MCHE9<nI9G@CHOKHN@CERD<IMyE9G+HOAS"HOI-ARsG+<-S
E9G6I-E"E9G@R+9<?MCHO>@{R<-aiMc@CA+HE9I EI-?MCH+6R@CA+DFE9G+HI-?6<-KHTEH9G+A@ +HRO
n.6JJa 
 IsMCQS"<9@BAE9G+HI-9HI<-MI-A+A@CA+DQSIR"HOK< E9HFE9<nK-I-s@C<6ROIRHR"<-MI-A+A@CA+DS"@CE9G<>PMBHOEH
C@ A< 9>QI-Es@C<AFwRHOHMcMCHOAa+HOA6 MCHO+  IE9H++< >QI-AT6I-6HOR<A!E9G6I-E~E9<@~TR~9HRsHI-G
@CAE9G@RTI-9HIF+<D9HR9RH@CAK-I-s@C<6RT @C9HEs@C<A6R$RHOKHOIM~@CA6HO6HOA6HOAES"<R<?6RsHO9K H.E9G6I-ENE9G+H
IR9R+>n+Es@C<AE9G6I-EI!MI-A+A+HONG6IR< >nMCHOE9HT@CAy<9>QI-E@B< AF@{R+A+9HIMc@RsEs@<">QIAR@CE96I-Es@C<A6R+E9G+H
Rs+?+I-HInE9G6IEE9HI-ER"EG6I-EIRsJHE<-3MI-A+A@CA+DF@R6R6IMcMB9HyHO99HFE9<QI R"MI-A+A@CA+D@CA+A6HO9EI@CA
E9HO9@BE<s@CHRO
 I>nMCHR<9HRHI-G@CA	E9G@RnRs+?+I9HI@BA6MC6H.S"<9< A6HO9A@CA+DA+<-S"MCHDHIA6	IEs@C<A
w<<9H~+aNIMC6HOAaJS"<9<A<A6 @CEs@C<A6ILMI-A69HIE@BK HnMI-A6R!wNHIAHMcMC>QI-Aa
-IA6S"<<A@BAE9HOsMCHIK @BA+D.MI-A+A@CA+DI-A6HH+E@B< A	N>?+<RsyA+D HORs<AE9HOHM=
 G+HT9HI Es@CKHI-++9<I 9GF@R"+9< 6<RsHIR"I!E9<<-MY@CAE9G+H<AE99<M\<-9<?J<ER=<6HOI-Es@CA+D!@CA+A6HO9EI@CA
HOAK@C9<A+>PHOAERI-A6@BAE9G+HffHR@CDA<-9HIMCiMc@cH< AE9<-MI-G@CE9HE9+9HRFEG6I-EnS"<M?6HI-?MCHE9<
9HIE@CAIFR9I-Es@RIE9<Q>QIA+A+HOYD-@CKHOA.+A++9H @E9H.HOKHOAERw=9<<+ROa   G+H@BAE9HOsMCHIK @BA+D
<-3MI-A+A@CA+DI-A6HH+E@B< A>QIRs<>nHOE@B>PHR?JHQIn6RHMIMCE9HOA6I-Es@CKH!E9<<A6 @CEs@C<A6IMMI-A+A@CA+D6
<LS"HOKHO@CA>QI-AF9HIMc@RsEs@n<>QIL@BA6RE9G+HO9HN@RTI!A+HOHE9<F<A6R@HOI!SG+<-MCH<MI-DHT6<Es@C<A<-
I!MI-A?JH<HH@{ @CA+D<AIAIEs@C<Aa  G@R=@R"EG+HOIRsHN@CAE9G+HTEI-A6RsJ<9EI-E@B< A<>FI@CAI-A6FE9G+H
E9I+>QI-OI-9H!<>QI@CA.S"H @R96R9RHYHOK HO9E9G+HMCHR9ROSH!RsHOH!E9G+HT@CAE9HOsMCHIK@CA+D<-3HH+E@B< AS"@CE9G
~MI-A+A@CA+DSG@cMCHHI-9A@CA+DI+9<>!@R@CA+D @BHEs@C<A<=y+E9+9H9HRsHI-Ga
 HRsHI-G@CAE9G+H @BHEs@C<A<-<A6 @CEs@C<A6ILMMI-A6RPHIMRS@BEG	M{IA6RT@CA	SG@GEG+HQ<+E<>nH
<-"E9G+HQI-DHOAERNIEs@C<A.>QI.IaHETE9G+H!A+HE!IEs@C<AEIHOA?.E9G+HnI-DHOAE  G+HO<9HOEs@OIM"S< 9<A
E9G@R@R9Rs+H!@RN>QIL@BAMCHOK<EHE<IR6HERN<-"9HIRs< A@BA+DI?6<+ENA+<-S"MCHDHFI-A6.IEs@C<A_w<<9H
 +NIMC6HO9Aa! +T<9DHOA6RsEHO9AaT IA6E<E9G+HMC<D-@OIMTy<9>!MI-Es@C<A<-<A6 @CEs@C<A6IM
MI-A6R  <RsHOA6R9G+H@CAaT-	JH@c\.>nHG6I-A@Rs>QR!E9<<A6RsE996EF<A6 @CEs@C<A6IMMI-A6R@CASG@G
<?6RsHOKLI-?MCHFHOKHOAERTI-A6.E9HRsERTI-9HnH+Mc@{@CEsMC	HMI-9HI-9HQ @R96R9RHIRNS"HMcMHMcMB>FI-Aa"
 G+HRsHNIR~S"HMM\I R~E9G+H">n<9HMIR9R@OIMYS"<9T<AQ< A6 @BE@B< A6IM\MI-A6RI-9HOAa+LLI-A6S"<9E9G6I-E
y<-McMB<-S"HIA6H+E9HOA6H@BE@CAK-I-s@C<6RN @BHEs@C<A6Rw~HO<E>!@CE9Ga~+  E9@C<A@aI-A++RO+HM{Y
NI-JHOYHRsGa@cMMc@I->QR<AaYYG6IKH"A+<E<A6HOAEI-E9H<AnD HOA+HOIM6<>n++EI-E@B< A6IM\IRsJHER
<-$$MI-A+A@CA+DQSG@cMCHHI-9A@CA+D6+S"<Q<HRA+<E<A6HOAEI-E9HN<ARsJH@\>nHG6I-A@Rs>QR=y<"E9G+H
<A6RsE96Es@C<AF<-<A6 @CEs@C<A6IMMI-A6RO  IE9G+HO @CE< A6HOAE9I-E9HR< AQDHOA+HOIM<>P++EI-Es@C<A6IMaIRsJHER
<-< A6 @BE@B< A6IMMI-A+A@CA+D6<>nH9HHOAEnS"<9G6I RnIMRs<?JHOHOA<A6HO9A+HS@BEG<>n++EI-Es@C<A6IM
IRsJHER"<-<A6 @CEs@C<A6IMMI-A6RO?++E<A6HOAE9I-E9HF< ARsHOK HOIMaA6I-E9+ILM++A@BA+DP9MCHRE9G6IEOIAQ?JH
6RsH@BAE9G+H<A6RsE96Es@C<A<$<A6 @CEs@C<A6IMMI-A6RTHOA+HRsHO9HOEGf<+9?6I-G6RsGaa 
O

fi+++{6.T+C++{6

	
fiff
ff
ff!#"%$&$(')*+',-ff'.ff0/$%'12*'$%
3ff+#'/546#.ff'$%'17+#
'89$%':;ff'<
ff7#'/5589$=>46#?ff@'<+##'ff6Aff'B:;4	AC4D+E<F#$ff<>G$9ff/+$%'1HI	/ffB#'J$%7$%

K#L#$?LM$%ff7+#
>,N$J$%'17+#
'89$%'JOK1P*L#$Q46
A<MR3SUTJ$?ff0
$>8Gff#'#V'$%
'$<W46#
/$%'$%
3ffXN893ff)*+'ffNffM$35,9YZAff''#'/[4	#$]\;$ff
'#'/:(ff0'<^AffK,_`YaAff''#'/b4c!#$
\;$ff
'*'/@Lff$<F'$%7$%
ffd893ff)*+'ffa%ff$%/+
#$	ff'<@
$%
$$%'1ff#'51M$%S
e '$%
g//+$$<(ff0
1ffh,i
jEff0''*'/h#'='$%
3ff#'9$%'7+*
'89$%'3%:4	1)$DffA%ffLA
f
ff
+$<fik#$6ff6$ff$<fi<+AK#'=
$$%'1)*:Aj
$,_$%

$<f	ff;'#7$%
ffEff0'ZOl1$%
3m:nopqRS
er'#7$%
3ffDAff'QAh'$s*'Q4	At$G
$ff#'J,f$Gff/$%'($%7$%
C1P*L#$5$%7$%'=,	$
$%'7#
'8s$%'1&Efi)$u$<Q$vA##S	
fi
$#3fA0Eff0$9/$%'$%
3ffXDEff+$f,	)$%8Gc#'J4	A
$ff/+$%'1HI9ff#'9%ff0']L$>$u$<w$v!A##[#'bff0't$xy#$%'1@8Gff''$%
:z#'w
3<$%
9C$%'ffL#$
ff+8GffA67$%
)!u{%ff0#'BS-|
$%
89
$:1$%8G}ff6<('},~ffM*'=$ff0L7$fiEff+$z8Gff(LM$
#'1
3ff3ffL#$h$%7$%'@,-$(ff/$%'	ff	+89#$%$fi#',_
8Gff)*+'5'5$fi$%'7#
'8s$%'1fL$%ff7+*+
S
	$%
(89$%4	ff0fi
$Aff$<>46
FA('$%
'$<46#JAff''#'/>
$f4	$%
$9$9/$%+/
3ff
A6''X4c'>OPYgffff<+#8=#
#>-ff''ffffA%:jnopo>%<$%
89+	fiff7+A%:;nopR3Sd|
6$vff8s*$:
'$f8Gff9L$f#'$%
$$<=#'5u'<+#'/Gffh
+$	#$ff<+#'/=,_
8U'$fi#G=ff'$%
646#+2ff+%$6
ff'Gff0

Aff$c8GffBSd2Ez46
h8Gff(LM$	7#$%46$<@ffgff(M$Affd%ff$6,B$	/$%'$%
ff,i
ff89$%46
fi,
YZAff''#'/=4	#$\$ff
'#'/SZTJ
h'9$	<$K#/'s,{PE%ffX{ff
g+
#$%'1$%
zOL$#3%:+ff'ff'<+#$%
3R
ffgff%$%gff'=L$;#'='$6,{$%7$%
3ffX11K#L*$f
#$%'3ff#'Zff'<&Z#B#'9ffc
$<$%$%
8=#'$<

#$%'3ff#'>Offff
3ffff'B:MnopRg8GffGffXE)9L$h7#$%46$<ffcff9$Aff-%ff$fi0,a
2,i
3ff089$%46
;S
	
z46
fA6'$%
'$<=46#s$	B#'$ff'<'*'$f
3ff+3ffL*=,BYZAff''#'/=4	*$fi\;$ff
'
#'/SU6A5
$Aff$s#5t46
]'$%
'$<[46#W$>
3ff3ff0L!#],9<+$%
$%'15$@,=Eff0'
'#'/Og
:;ff0B:UlL
3ff08Gff'Aff'B:Znooz+Eff0'<$%
:gnooR3S-6Ac4D+
98Gff#'#.+'$%'1
ff$<
'w'*'$C
3ff3ff0L!#t,NffJK#'/#$%ff/+$%'15Aff''#'/]42*b89#$%$#',_
8Gff)*+'BS	
@4D+

'$%'
3ff$='t/$%'$%
3ffXc+893ff#'ffXffM$3=,Aff''#'/t46##'89#$%$5#',_
8Gff0#'B:
'KA<$%
3@ffA>8=##ff/$%'GK#ff#'m:Dff'<t<+A$9LMt'#'$.ff0'<QB!#'$
3ff3ff0L!#S
 $%ff6fffB!#'$5<$K#/'?ff'<
ff3ffL#P:Zff#/J'PE<$%
$<?ff'Jff
3ff#7$h#'QOP>
Dff
1ff$%:gnooR3:MfffLM$%$%'ff#89fi'$%/#$$<#'Q$=
$$%'1h$ff
3&OL($%$FOP1$fi
j$%''$%'#":dnooMlff8j$%''$%'#":dnooRRS
 $$ff
3?+'J#',_$%
$%'$5,	u'#$%ff8Gff3ffO  #7$@l1ff#
$:	no+pq1:-nopoRff89$=ff'
ff /$%'6ff6
#$zh#',i$%
f$fi

$fi,aff'5ff+8Gff'BSZ6$(ff/$%'zA6/#7$%'ff&*8*$<.ff+%$

Q$.ff08Gff'B:Dff0'<tA@$v$$<wQ/1ff#'w$%'/w#',i
8Gff#'w<$<$C$.8s*$%$


$@,$ff8Gff0'BSJz?'
3ff):j*'w$@,_
3ff89$%46
J<+A)$<Q#']A=ff0$%
:z$
ff/$%'fi'$%$<fi+'*>/1ffX*'#',_
8Gff)*+'Jfff46A<>$#>#'?
$ff+#'/5$9/0*7+$%'J/1ffS(2$%
$,i+
$:
#'54	ff}E2
LffL#Gffh891)-'ff
ff%ff)$:$fiff8@ff'=A},ff#
#y8s!A%ff$<;:g#$ff
'*'/
#3=89#$%$

$=A9+893ff#'ffX!#>#',_$ffK#L#$S?c4D$%7+$%
:ZL$#'/J'#>#'$%
$$<C#'tff
M$!u{/ff:g'$58GffQL$ffL#$.+L3ff#']$5'$$ff
C#',i
8Gff#'B:6ff'<t%$%$<*'wff
/1ffX~S>K']ff<<+##'B:z4D+
>'+893ff#'ffXD#$ff
'*'/Qff89$hff0N$G/#7$%']ff08Gff'E
,_!#t''$$<;:Z$%'ffL#$5
$ff*'/Jff'J3ff$N0,2$yff8Gff+'ff0'<>$*8*'ff0#'/?$s'$%$<
,-ff7A<+#'/3ff$D,i
+8r4	A>$%
3ff$	ff
$h'	
$ffffL#$S2Efff)89#'5
ff0	$
ff+8Gff'sA6,_#''$$<@8Gff97$%
@46$dL$&,~ffA$&#'8Gff'9
$ffX*,_$ff0!A%ff)*+'%S
2$Dff0
g,{+
g4D+
(4	AG<+A$z8=##ff/$%'gAff'ZAg
$Eff0$<=fA$a#'G<+A
#L$<
effiOPz'<fiff$%
:jnoppR6ff'<G$N89#$v#P,-8=##ff/$%'fiEff0''*'/COPj$%''$%'#"G
1$%:fnop+oR3z4D$F#'17$)#/1ff$$893ff0#'ff<+xy#]ff0Gff
A$@<$C'$%
3ff#'P
'$%
'#'/@$Nff+#7##$c,}ff0'ff<<+##'ff-ff/$%'%OPR3S
3

fi>t-+

fi2~f	E0%%3#f=%;;h9a6(%1fAf+%%1f_
 AKA%	%%1#f#Q5##N01c6P2dKfiA=APE%XccA%Gg+%1s%G
9PcG@UJD3929%%3	#Q%6%%?A#JQ
02%Q=%%[+A#]%+#sD+tPf]J#GBfi3JKb+##B
j%%#?[19)XC#[_+1#_%%A9A59.+96
+AsJ5sAKA%=1	66#>%%3)*+@Pj%%#J%f
6%>V9E%X	1	6P2*+G%%1#.%0.M955+K#_9%
%)%130#B.c6%%Z51#_%%)Es%)%130#hD5KA%t0y+%
#J+%%1&i+APE%XDA#>9A%g95h~fi%.s-E##
@1K#*%#h%3hJGB3h#h#%]+B%%=%1+#9%
%+#3%%-G%%D+%%3;~+36	@%#s%1z6N3KfiN_I
30	d5%cE@Az+%%30%1-+A)s*5fZ*%3=
+3M6!	fiM9%)%1A##Q*C(%%1#J>6	9#h#9E##
hh	%B+#gh%#%gc%691g+ADP*!Az9
X2*+fi%%3#@#}E2(K#50G961%#BB+3g	+Afi
#5%%3=%	j*%d306y0%16=#69A6+%1Aj*5fi1=%6
#36)%X#930%
g@GBzzXKB-
)igA#)%%c@fi%h%Aa%)*m
 j**fiA>#
=9AU_	fi%%3#50aA%2;#)A#9Ah	ic%%
%#5A%=6#3;;#N)AJ#J> y#%1h90E)ifiN+% {%#J-A
6_6)*@%+A=A%
K ?E%=6y+%19QA#J#t%#t%#dc%Gy+%1h
#JA-#_G)*+?Q9%+*9%NM%#J50f*hAh#330*@
At5_DA#?%%+%J_fi9%3s%%3#_ #j%%3##
	AJ9=%fi6%#yf>K##GM%+#3cAfiM#1+=A-#J@
%)%130#GK#%3-c6%%+-K###36]}#gAz1P*##59%3
+K#_9%3h%%3#	%fifi=%fd)%X#930z=#1c(+%
A_3+(AK_=
 s	
 3h+%#z9%#9Mg	%B#K#s9
3+3#6+A>%93#h%

 A=2!66+KA%(P*_s%309)%Gfy#%1fiA%;cE>Afis91
c
K#0#B6#3D*s*@	aE0*@	#ff
;#sAD+-5*%zA#
6#s*%f*_@#B
 fizfB#fi330*fi@#fi#3#-	6%%0#
9%39%@%;A#.2*?9#%=#_G0#>A(+#9#+AEcA&G%=
303>fc{0iM
 6#GBg
 3+	#(#%)fiD()XWaE0*
	#
 
;0#=A	}_3;gf%%3#6f3#5N+9#%(AK {%#aaE0*
	#
 
#N%@B)=9%%3X%%1#9g=9#{%%#%
+##Bfi6?+A%K#50ZA#[	#
 
#(V5aA#bc!#

;*s#=##%+G#%
2=i9%6ZA#J	#
 
;#A=5%%3X-_39%6	%@A#>#
%3X*t%#Q%?M+#;t6s*#tfAhi9%6;gJ5A
M1K##N0@%1#-#3%*=	



fi!"###$%'&)(+*#$,-/.'-0"#1##$%'&
2 30457698:<;>=7?@;>AB;'5DC0E
)
FHGJILKNMPO%QROS,T0G	UVKWUVX'Y[Z#T]\+Y^ZFHGO_Qa`@Y[Z'QRUVX#bVGcG	Y[Z#K0ZPdfeWK0M'gbhGci0S,GcIjGcbgc`9klKNbUVX#GS,b+X#GO,mPknMPOLoK0e	p
e	GcZPUgcq
r);#sV;'tN;'573#;>E
u X#K'` u q>vwq,`@xKNmyobVK[knU`az#qavwq,`y{}|~OOeY[Z@`!z#qP#q@f0HN'	+>0c%ff70yPn
+00_Pffcq u Q#QNS_gKNZ#pnFHGgO,Gcd]M#POS_gXPS,Z#7K0e	m'Y[ZPd0q
u OO,GcZ@`az#q,`PxGcZ'QNO,Gcb`az#q,`#{!Y[UhG0` u q'7Q#gcqq#N0PqDL00f^_RL0>'f0qa/K0bVfY^Z+Y[MPkneY[Z#Z
M#POS_gX#Gcbgcq
u e#bhKfgpn<Z#NGcbgK0Z@`#z#q,`#{0UVGcGO<`a'q>00PqaZfUhGcbO,GYiNS,Z#O_Y[Z#ZPS,Z#'`'#GoM#US,K0Z)Y[Z'Q/K0ZPS,UVKNbS,Z#'q
<Z)LN_P[+V0^`fm#m@q>009q
K0Z'Qa` u q!xJq,`!{YNgVgGcb`q00q/L00f[_+,cnlfn+n L_N>n0'q u PO,G
M#POS_gXPS,Z#)7K0bVm>K0bY[US,K0Z@q
bVKPK0Tg`0+q u qP0NPq u jKN#M'gUL@Yd0GcbhGQ	K0ZfUhbVK[Oa0dgUhGceklK0b7Y+/K0PSO,G+jK0'KNUqaV70P'0
+Lfh0ncff0>fn0w0n0>`@0`@c^0#q
d0O_Y[Z'QPGcb`+qjN0Pq7K0eWmPOGPS,UdjGgMPO,UgklK0bR0GcbS_YO\GoKNe	m'KfghY[PSOS,UdaqZBLN_P[
+h[0`Pm#m@qa[0'^'q
\GY[Z@`[+qcq,`{FHGOO,eY[Z@`0qc!q^0#^q[L0>'f0'J70>nNq[/K0bVfY^Z+Y[MPkneY[Z#ZwM#POS_gX#Gcbgcq
bhK[O<`fwq,`PY[M@`P\wq,`0{0M##bY[X#eY[ZPS_Y[Z@`Nvq90NPq>ZUhX#G+7K0e	mPO,GPS,UdwK[k!\K0eYS,Z#pn<Z'QPGcm'GcZ'QPGcZPU
O_Y[Z#ZPS,Z#'q<ZHj0f[+V[N`fm#m@qa0#00#q
UhSKNZPS`ffq%`yxY[Z#T#gc`@'q%`#FHGO_Qa`@\wq,`'\bY^m'Gcb`a\wq,`'aGgX@`@ffq,`>{FSOOS%Y^egK0Z@`@qD00q u Z u m#p
m#bVKfY0ohXffUVK+O_Y[Z#ZPS,Z#JIjS,UVXffZ'oK0e	mPO,GcUVGZPklK0bheY[US,K0Z@qP<Zj0_P[7f0	0cc>
0/L_>yc++ff'0j0JLycc>n0n_N0>	j[c0>_P0`Pm#m@q@0y0#q
GcZ#GgGcbVGcUVX@`@q,`'{K0M#bh'Y[TfX'gX@`aqa+q@00PqS,e	G	fYiNSZ#LSm'gknK0b+bVKNPOGce0K[O,iNSZ#/IjS,UVX
<Z'oK0e	mPO,GcUVGJ<ZPknK0bVeY^US,K0Z@q<ZL0f^VV[0q
xYO,m'GcbVZ@`ffz9q,`L{KPgGgc`wq0[9qZ#KI~OGQPNGY[Z'QoK0e	e	KNZTPZ#K[IjO,GQP0G)S,ZYQNS_gUVbS,#M#UVGQ
GcZfiNS,bVK0Z#e	GcZPUq7DGoVX@q9bVGcm@q'zW0f#N`fjq
xYO,m'GcbVZ@`'z9qfwq>0NPqajGY0gK0ZPS,Z#Y^'K0M#UjTPZ#KI~OGQPNG0 u ZK[i0GcbViNS,GcIffq@Z@P0n_0f
L[N'f+ffh0P7ff>0jN~L0f^fff0000cc'`0m#m@qDy[fq
xYO,m'GcbVZ@`z#q'wq,`a{v7Y[bQNS<`@q'wq@0#[q/KQPGO7ohX#GoVTNS,Z#igcqaUhX#GcK0bVGcem#bVK[i0S,Z#'aY	eY[ZPSklGgUhK'q
<Z)L'yc+ff'0j0La'n0n00>	j^0>_Pfj0f[+fJy0'
'n>0n_N'070'`[m#m@qa000['q
)oLY[bVUhXfd0`z#q,`!{xYd0Ggc`qN0PqR0K0e	GXPSO,KfgK0m#XPS_ocYObhK0PO,GcegknbVK0eUVX#G0UY[Z'QPm>K[S,ZfUwK[k
u bVUSyohS_YO<ZPUVGOOS,0GcZ'oG0q]0f'J'n_0'`0#`#P00N#q


fi0#[#)##N#0	

fiff "!$#&%(')+*,.-0/1&243507698(!;::%<:=?>@A'CB@DA=&DFEC:ffGG!$%:FB7H%<IKJ"LGMON PRQ
S NUTV.W0XYMOZVUV[N]\Z$X S Z^^&

_&`>a7bcd-0/1&2e50C>@!&'f:%:=F!4g&Aihj:lkm8<=&n!;:Fo"ffGf%:7"BdffD7Yp7K/1/&.q>@rjrs:t
:!4f%:!$8s

_=:'H:7uv-G/12w5G7hj:lkm8<=&i6KffG:&%f%:'yxz@o"ffGf%:'@!4:?6{8|!4:')7rs:fi}@Lf~ S Z0ZGNUX\4C~f
MUZ4MU?W0XYMOZLGXTMONU~XT&V~NUXM,~XZLfZ$X S Z"~X?J"L0MON P S N|T&V.W0XMOZ$V|V]N]\Z$X S Z4pp72+w+2w3Y

_'f'YB7:::D;8<
7-G/11/45GCbpY0!4f%:_%:EC:ffGG!$%:Bdf%&IFEc'%<:=F!
_A8f%t
*K:f%I
_G8fir:RAff'fG%:7KoKG8|!4:7KR-*')]50KJ"LGMON P S NUTVKW0XYMOZVUV]N[\&ZX S ZTXY
~,`MOZLF{N(NU~X*{8|'f#&%qff%<:ffG

_'f'jCBd:::D48
j-G/115G@7tsuY%:>@!'f:%:=xzC:tsuY%:*{ff%:ffGI.r:
}yLf~ S Z0ZGNUX\;m~HMUZ4MU?WGXMOZLGXT&MON|~XYTVY+~&N|XYMC~X)Z$LfZX S Zi~&XJaL0MON P S N|TVYW0XYMOZVUV]N[\&ZX S Z
j!40!40!;H!;:7h;-0/12+50oj:"oC8=H%<D%|ffojpp!&ffD"@DRocA!4f%|ffKj'%=:";x6K!40'dCf%:G'
rs:}yLf~ S ZGZ0NUX\;~fCMUZ"^MUWR.4C7~&X7~XT&MON|~Xy~f~,`MOZL@ S NUZX S Z)pp7/$
/3
6K!4p!&%%H%<&A7bjl!4::!4l!;%|'
-G/1215GqD&'f6K!4D'{%D&A!i
fi!4p7r:J"MO~TMOT4
T&X\T\&Z?TX}yLf~0\&LfTNUX\"4MUW0XYMOZLGXTMONU~XYTVj~VUV[~$N|}yLf~ S Z0ZGNUX\;{pp7@/e$
e
6{7
.o7q%D7{{-0/11&50b&:&%<H%<&:!$8m,:8]%:!46{8|!4::%:=r:}yLf~ S ZGZ0&N|X\4i~fMUZ
$MvW0XMOZ$L0XYTMONU~XTV{~&XZLfZX S Z"~X?JaWc}@V]TXXYN|X\`$MOZ$pp77/2&1$`/1w
>C!4!=6{:D!4F Y-0/12&1507B@Db&:48`4x,%|'ffGi*v#:cqI'f'K}@L~ S ZGZGN|X\4
~fiMUZWR@-0/450Y2/G+12
>R%#'f$`>".uKYqffD!4p%7>".*C.-0/$12w50R,%<#&0'%fIts@!'frs:xO:ffG4xd%<:%ojA!;0!Kr:
}yLf~ S Z0ZGNUX\;y~f"MUZi^4MUWR`4,d~X7~XTMONU~Xc~f~,`MOZL, S NUZX S Z$4pp7Ywl2$+2w
>R%#'f$i>"CuKCqffD!4p%>"c*,j-0/121+50 rs:xO:ffG4xnd%:%ojA!40!Ej'%:=,%:=
qA:ffG'rs:}yLf~ S ZGZ0NUX\;~ffiMUZ^4MUJK`4,a~X7ZG~LG~H~,`MONUX\,pp7
3//G3e
>@'H:'ffDG%:7dq.-G/125G7!$8B@D&f%'C4xKhj:lkm8<=&"%:?ocr@!4:?>@gYf%|ff'@"ZCZXYZLQ
TMON|~&XR~,`MONUX\&7d-5043l+w
>@'H:'ffDG%:7qCCh"!;G8<g8]%:=uKC6{j-0/$1250B@D'fI:D'%|'?4x&%<=;%<G!$8!&ffD%:'_k@%D
p4#l!4g8@p%|'f%|ff@p&pf%'rs:}yLf~ S ZGZ0NUX\;~fCMUZ~XZLfZ$X S Zy~&X7Z0~LfZ$MON S TV4J"+Z S MU
~f"yZGT4~XNUX\T~&MRiX~&yV]ZG\Z$pp72$+1&2
>@'H:'ffDG%:7,qK-0/$12/4506{8|!4:qI:D'%|'o8<&=4%|ff!$8c6{0'fpffGH%<#&?rs:}yLf~ S ZGZ0NUX\;~f?MUZMU
W0XMOZ$L0XYTMON|~&XTVY~N|XYMC~&XZLfZX S Z"~X?J"LGMON P S NUTVYW0XYMOZVUV[N]\Z$X S Z
qffDpp0')+
&-0/12+w50EC:%#G'!$8698|!4:'{xOK>@!ffGf%#">@gY0'd%:E,:p&%|ffG0!4g8"*K:#%&::G'
rs:fi}yLf~ S ZGZ0&N|X\4c~f~fcJjJcJaWQHpp77/e&1$`/e;3
0

fiC(fi"_(
4_d4.G4G{+|$9dO	fff
`|$fij+f	U[
  7d  @
 f l
 
4_0+0!"f#%$&G4Kd77.!')(C**+s   
(,
  jG{04- O .#0/, 1 .) 2
d4K{G4G4365879;:<6=?>	:)@BA):DCE:F<G=IH=I9;J<KH<GLM>N:OHCEJP<G9;<RQS9T<VU%W-Xff=I9YIZ	Q:<6=\[B]FCE=I:F^_C
$K7   T a
 `G4b
 sG fH<c  de04Gs
d4K(`_Rf.{0Pf0_CK(0;f_<?fhgvf)2_i#Gs_skj	AdJY
7.:O:.LP9T<-QClJ)m4=;n-:poo=;n0q.<6=I:AO<GH=I9;J<6HX6riJ9;<G=s?J<DmE:FAd:F<G7O:!J<0Z!AO=I9 t	79;HX6q.<G=I:FXTXff9ffQ:<67.:$
`c7  vu  70$-wyx0zj04fb(&G#&<H<&$N${|4G"4G#b$&0;p	s{jNA)J7O:.:OL9;<RQC|J)m
=;nR:_[BW-^}^~:FA,s?J<DmE:FA):<G7O:!J<0Zq|H<6L,[v9T^~W-XffH=I9TJP<%Jem!:DnRHF9TJAc?3	L9;<BW-AIQn
`G]47${Y0+0JA.^~W-XffH=I9TJP<%JempGA)HL:OJ)"C!9;<0jNXffH<6<G9;<RQ<6L:A0<G7O:AO=IH9;<G=I]4${47
.G# 7

.

fi	
	fffi	
	

	!"$#%$&('*)+,,-/.1002433

@BADCFEHGJI

K

GDL*M/EHNOADCFEQP

_a`cbedgfihkjmlonqper

56789:;-/<=,->?7
#&	:*3/<,-

ASRHTIVUWI

XYC[Z;L;GD\^]

sutwv!xqyqz{tqy!|y}qtq~!;"qy~e~qvq

iSi/4^=^wo=w	=wH4
*w4e	
f;nrwh9ab"*rql

q}q	y1tqez{}q	i}quyD~qvq

*	oFk/4=DD4{io
 4/=9"o
b"eranrwl

q}q1qqyqz[~q|	ytquy	yyu

4  wk4{"1=J^ /
	6="4!

ioe!
	91	{o^  	$	^!o6(oH$	$  ou%  $"*  o6(
 $     1  	 =4q	4D/9J=%/ %	  	   {o"!$	
$	*	
o;	oF  "*	koo[o *[*	$^o	6  o$D

 1 	1  	  	$*	  	$i*	$	e!o6i66	9^oo
fffi 
 oe	$ [  o	  	  $$*%  o{q6 [91  e   1
$	${!= $[!{$	   o  	 k$*%  o	 
 	$99oo  i$
$	*91(o  	 o 
6 1
  	 
6  o$	9o
1	     ok	 o
*  oo $	 [o$  o	 === 9  o   
 	$9o	6${	$i	
 
	ko99o9$    =%	$q  o
  
 4DD =%1{ 	  o	
$  	  $$9okq  ;$ ;;D	u  e   ;o{  
   
o	$   	q	   99%o	o$	 ! ;#
 " 	u$6^${6 i$ ;	$
$[$	oo$(     %$ o  	$	 oD6$  	a$
		   1  	6[$
  $		  & $ o$	1	J*	$1;$		6;1D	1o%$  o  	

 '
$  H$i$  	kHDo 		   	 ( $^	$o	1i 		6
1) '    	$	e^$    o* De+
 '
D  {$ 

,-/.0

1&243i!51

0

6879;:=<?>A@B&C9/CD@9AE&F7B@GIH;@BJEK:)LI:)E#@MON;PQ<REJST:)7MU@&<V9AWX7B#MYCE)<V79%C[Z;7\IE&C]H;CB#E^<?_\A`CB8:^\IZIa=@b_Edce:)\;_JS
C :!<R9AE#@B#9;Ce`fMU@b><?_J<V9I@gh7MU@]WiC_E:cj:^\;_#SOC:kCd``lH;C[E)<V@9jE:4P]<VE#SmSI@H;CE)<VE)<:]@GISA<VZA<VE&a^C[\I9;><?_@bnoc;_C9
Z;@9;CE#\IBCd``RL/@GIHIB#@b:#:)@b>p<V9YC%:^EC9;>ICB>Tq;B:)E#r*7B>A@Bs`R7D<_cjPtSA<u`V@7E#SI@B:+cj:)\;_JSYC:kvwAxy7WH;CE)<V@9AE:
E#S;CE@GISA<RZA<VEta^C\I9;><_@mS;Cdz@%SI@H;CE^<RE^<?:JnIcCB#@:)EC[E)<:)E)<_Cd`g/h\IHIH;7A:)@E#SI@CD@9AEPQC[9jE:QE#7Y\;:^@E#SA<:
<V9AWX7B#MYCE)<V79{EJ7|MYC}@O>A@b_J<:	<V79;:gy~I7BU@GoCMUHA`R@c]C|>A7I_E#7BMp<RDSjE/9I@@b>{EJ7>A@b_J<>A@PSI@E#SI@BmE#7
C>AM/<V9A<:)E#@BC[9jE)<VZA<V7E)<_:mE#7C|H;CBJE)<_\A`?C[BYH;CE^<R@9AEO&B)<_g7{CHIHA`VL:)EC9;>ICB>{E#7A7`:7[W>A@b_J<:	<V79
E#SI@7BJLOF=:)@@F=\;_@/Ce<uKCIcbANW*7BC9m<V9AE#B#7I>A\;_E)<V79NcAE#SI@%CD@9AE]M/\;:)EC:J:	<VD9OHIB#7Z;CZA<`<VE)<V@b:c
7B)#()TJb**cE#7/zCB)<V7\;:]@z@9AE:g4~I7B]@G;CMHA`V@cIE#SI@>A7_EJ7BMYCdL/9I@@b>OE#7C:J:	<VD9CU>A@DB#@@
7W]Z;@`<V@WE#7C[9@z@9jE%:)\;_JSC:k+&B)<_/S;C:SI@H;CE)<VE)<:#nIg/@P]7\A`>E#SI@B#@W*7B#@`<V}@YEJ@b_#SI9A<\I@b:W*7B
_7MHI\IE^<R9ID/>A@DB#@@b:s7WZ;@`<V@W<V9YCHIB)<V9;_J<VHA`V@b>mMYC9I9I@Bbc\;:	<V9ID%Cd``lE#SI@>ICECCE&S;C9;>gs	9E#SA<:sH;CH;@B
P]@<V9jz@b:^E)<VDjCE#@E#SI@HIBJ7H;@B#E^<R@b:t7W&79I@H;CB#E^<?_\A`CBtW*7B#MYCd`<:)MWX7BQ>A7[<R9IDmE#SA<:g
QSI@%M@E#SI7I>mP]@T_79;:=<?>A@Bdc;PSA<_JSP@%_Ce`u`&E#SI@U^[l/	8/bAbcS;C:]7B^<RD[<R9;:EJS;CED7
Z;C_J}EJ74@B#9I7\A`u`<TC9;>{CHA`C_@|FdvwANgE/<:/@b:J:)@9jE^<?Ce`u`VLyC9CHIHA`<_CE)<V79y7W(PS;C[ES;C:/Z@@9


+,,6-fiuqfi"$##I	:	:468eff8i817
#&	#	fi

%&##*:

fiAI&]IbIsQobd

dVbO#Il+l) (#=AIbdIs]I;	tAbAV#%)#eRj)*#
 II;A)%]%#VA##b)JbUR##AVIY/A#&;V#*#/A/VAIeQRbA
;)yI;)*A(b#	VAVI^YA)/#AJb;VT*#/AJ|;)
OIJ;AR))J)VII)V{%)8IU8=dV;#]bA #;#JR
)IIj)]*sIe{J;K]#]#b)AVI%;I V;RA;dX

8u&UARJ
Ab#)VI)V8A#R;VA;d/;d%bJ8#I/I##)Vb&VA##b)b I#mdRU])
 =;)/OIA&VA##I#[)Vse%I ;) *AI; o% ;AV(I?[
;Q;	)&[l#I]I;#/I#bJb )  
j*A *;m  l#I]AV;#
I#b# #d *  ;s;#IY;)A 8XAJIO])|AbJ)V;bA#{)I;)#I
V;V?A;e?J) ;b4bJO#II;#IJb?[#bIAJ)]K;dV 4VO#I #b * 
#)V];AJ#I
R;VA;dm 4* VI)VI#;[AuV))#)VII)V
#IY^j#	VAVO])IJIp[j%[|IdVA#[;VRyV{ j
;V)VAVIm#/IdV;A)#)V()J)VII)Vl[;#III)VI#II#;AuV)
RI#m#AI )#)VII)Vm]I/;A *)I#II;^b#I/I)V;JRAVO
V; fJ;Y#OJIjj^pU;#^?AI)V%)#)VII)Ve(#I)])I (d&#I/])I
#/[#Yb;dRVV 	?b)#)/#;#IAJT[;VV V{ ?
#II#bJ)V#I*)VO[!])IJ)	*VIO #;d)O#^?=XO]
QIp[II#jJ)m%Ab#)Vb{IARbII%]#;dV|AIe JII#bJ)OAYdV
	 
jIA*#JI;#VO#A]tdV)VOI; 	YA)b+IIbAV]#b);AV%#
;V#;  J# I |#t#j; ;#)A)VUVj#Jb)#bpROJI()AI#^?Q;;dV]
#A X)V A#;sA](]IA#;V!J%;#I)AI#^?QedVI#A X)V

#( #
o ;AV)IIj)%]Q[jJ#b)ImAYeR8Ij)AVeK;)VA;
JI% =I;^R&#I*R]VIUXI]X#/A?


 
   "!
.(
1( 32



,+



 "- *
/

0

4

65

;: =<
C

9

 ?>
fi<


	
 fiff

 
$#&%
'! )(*



+

 "- *

87

9

@ BA




"
87
DFEHG )IG&JK"!Al[X	G#]L>eus;)Vj]]V#OI;)V)IAVARM#I;@A
DON ^ P e	G 
Q'"j! *IG 
NRS 'T L+> II#j VY[#VUT Wy
V ;;^RAs#;[KI AVARB#I
?;dI;^R^?X@I
< ]I A?eROJA? *#Yeu) ;p#I(Jb)](Jb0> [II#j VYJR
T WVU
@ JIJ;Y> ; )V1T WVU@ V  b^RA
DOQ;Q '! )(* oIG 8Q;Q R S Z U
[ L> IIJA VY#VO[WV [K;)VA;dAVI/bA@ 
D3"A! l[XX8( X]\^#&% *u4( *8>8&_ )t#AII AVAR&# I;A@ 
` 8 ;a ^ P eX8( X< #;?+4j##)V;A#];;V##I)#Ab>)&_ )
;]I;[)V)I
@   II;A)/#ITAmdV;=c: 
 8]I]%AJY;	A%dK])It]V#
AYeRFj
d 	^%e );JJ;#I%)tKV;V?A;eX%#[)	XVI0 ) P (m)I;)t!JIj)
#^?=XVI^"j
! *AII#A Rm#VfT V #IV;VA;dJ)	*VI^"A! l*Yd)#[)	X
 )  II#j VY[#V[WV ]#IV;VA;d*TJ)	*|'! )(* ;JI%VA##I#)V

b]8
( X &V;VA;d#)	*RI."A! l*;1#&% XB9 ?&^#dVA)*#t#()I#;bd
I
 ;b#b] ^ P eX8( X8IIQRII#A Rm#V0T WV &#Ib)/)##;#IJb#bI
J#I4*)VUf)J#;#I#bVAJ0
 ) P 4( *II]A#bs#; )VgIT 
 V;h
T W
V ;#I];^RA#;s AVAVfi# I;;d4I;)V)&;.&_ )4I ARAVi^ [I;?
%A#;V!KI'
T #;&_ ^?Q;&I;^R^?])m$) ;))6l AVktj #]#;[bdVY#A o UAR
#I/VA*#Y[)V#;l&
_ ^?p%OJA?b#^j)dV|#Jb#b|tV#JRAb|
A UA?#I
#U;^]O?IT;dU#ImVAXJY)Vm#&% *;X8
( Xn9 {d);)I#;
o8p

fiqrstHuZvxwyuz{tH|arst=}~rvvBszuZ"
0W8X80"?6;l;OC'8$M
P"UW8lXgn48
"38X
1W88"h;l"b'8MP"&^"$"P
WM
P"?8fZgBW."
g"ngC?aU	6k	8$XWa8"	.
WP	80X"
Cg8M

"3"WH"P
,;^;W88W8WX=."W;18"084.n8W8n
.X
"aWf;0	X
"W	W"."a	8	;a8UX"
W;8l8?X	;8.88l;ab6
 8M".;	.;yW4ZW;1"WP	.48=c"	8
.X""6;"
P8					;~W;^~"W0	
"
,h?		8~IB"&fiB"6;$
WW;8;;8$
fiaC	X.;W;	;	W;
&	WW8P8W?8W88"
a1C81lWW8l.	8C~lW88"6c
 f"	8=,
	1	c)h4fcOW8
?;mI8X)?hX
 ;8fi&a"6c8k"
./^""8fi~	""
WP	a8,8
~"X"W;f8/PW"?"I;~W/W8

,W4IWWc)k	W;
c8a"FP880X.X	W;yIaWW  1X	W;
."l	k8W
8;C"h	""~8;1;yZW;0""4W;1886c
W1~"Wf8l8	;k4kW1~	/$  W8];XW"8~W
C	81	;MI	6;~a
"WP	"XfiWCWXM;
C	X8"
"W	8anW84P833I8W48;"Z?	XO/;xyP
"=Z.;"	;y"C8;.,;y0	W;	;"C
Wk	/	
"W;y""fi
Wl"3		8
C84"X8~	^	;~	
"  	~		;~f88WcX..6".1XW8
lC""C1	W
4W6;	;.""	;;"88^U"W;B;y1WUk	P
W8P.W8
;6;P"CyUP.W,;=f	"?P	;	W."."	4	
W6;	h;80~,I";fikW;8	ga"fi&;fig  ""HW
X8X&08"WXWfWXOXh
"	"fia
  "k88&0"466l
""acX;Wa	

MM6&k;~"C;	;X"W66cc	"";fi$W"W

8n^.;
W8?1^".W88"k;aaXUW;W";c
"W";;W8B;	;,1C"W"Cfi
/	f"W;y"8
4h"  ;8fia"6c8h&"$
B/W8
		;1"fiC"M"8kc1Xh
	XP
W8C8	C88b
"			8;WX~"
	;$$;X"8&W8
6&^h	"="i;UB8M"];	&CW;"XUX8h	W."
;~X""W84W;~WC8	W	Cccfi"W66;	;M;~88
IBCM;W	"CW"c
W
k;k6HXh	;MC.;WC"W&l	
I	X1WX;~88C6;.;	;"W66;IW
hW;W;WX"W;  "88
6	.n,8WbcXyW;^"=8"0	W."."y
"W
8B8y
;0aXUW4nCWFk"XccWc,lX"	/H"W;.;"XWcX
"	6;,.W
I,	c^CWF.WXWc;="^8	"
]~X	;	;C"W6;	
W
h18"1.icc
/yW."81/W8~.Xy	PW8	181";W11
	
			86k	P
W8bcWP"	;fia;W?"	W;
a"CXh"?8?;BZ
"$
k4	C"&?"8h?	h"X8	;1XUXU8	?80?W";Wla
	;^"""lC?"	C	W;a;W";a	";1"?	W	;
	;X"W66cc8"4"X8UhXlIcM$8'H6hC".8HIW8
"fmF8$"W


fiC	
fiffb
fi

 "!$#"%&'#)(*!+,&-/.0%1324.5.6 #7789:	!+883!$;#)(=<?> %A@BC%A79D>E!F2G!+#"!H&-I#7(
Q[Z\^]&_5`
%&79587fiJ2G> %&#)/!+9.5@&BG!LKNM&OPfiPfiP+OEKQRNSTU> %&V>E!W2C 	#7(YX
#)(%&#a> %&b@	-cJ7.bfid-^7.
#7(fi!+587fiJ2G> %&#)V!+9.e@&BG! :f%&.bEB49:f#7(d-^7.5BG%!g&-h#7(d-^7.iKYMg
j k PPfiP k KYQ j :flm( 75fi%>)(nKYo j 2C!
E24#7( UK o JUpNK o RSI> %&=<24 lq#)(Ur&l	B4fisI@%!+I%!L8BG%>)24st>E!$#7"%24#"!LV#)(I878J7#+24
&-u.0%24bEB4 .b 3#E!!7%&#+2G!F-^924sIfi%>)(b%&#7.,RNvJNE1%&.b8B4:#)(h>E!+#)"%243#UwxKNMxyWzf{ |}KN~xyWz{wEd&X
!7%9!#7(%&##)(m8787#+240&-#7(U.0%24t!7%A#+2G!F-c9J24se!+J.bU%&#7J.#7(%&#a>EJ3#"%2!	K~m%!L%[>E&+>E#
2G!L#Wl2C>EI#)(U87J87#$2Jt!7%A#+2G!F-c9J24sb%&#7.V!#7(%&#	>E3#E%24V@#7(=K M %&0K ~ %!a>EJ&W>E#"!xR	m24< =%
.bEB&-Ie:l	/> %&0EI#7(U #77J8395&-#7(2G!L.bEB%J!#7(Y 3#)789eA-#)(U<fi>E#)h #$2s
#7(b8)8)#+24!I&-m#7(0J2 7 #e%A#7.V! R5STV!+(&l#7(%A#fi:%![sJ7&lU!	BG%&)s:#7( 7V%&)e.0%&39
.b)*.bEBG!=l	24#7((24s(q #7789'#7(%&l	24#7(B4&l	 V #7789R	( 7E-^7:g.b?EBG!l	24#7((2sJ(
 #7789b.524%&#7RSY!+Y#7(2G!U ]& " u\7Z\^]&[  f]&_  u]A #75!+(&lD#7(%A#a	 s7 Y&-@EB24E24*sA2<J I%> >EEJ2s5#75#7(IE%&.b^l	+BG!.b #7(H2C!g>)B!+EB49V7EBG%&#)fi0#75#7(/%J!7!F24s.b #
&-N8)8)#+24!	#7b%&#7J.V!L#7(%&#	(%!	.V%1324.5. #7789V%&.bJs%BB%!7!F24s.b #"!m>EJ!F2G!+#7 #ml	24#7(
#7([>E!$#7"%24#"!L24.b8!+fi=@9*IbR
(e>E>E #7"%&#$2J*8( .b J;)EBC%A#+24sV #77890#7V#)(["%&J.b^l	+BG!	.b #7(02G!Yl	EBB4
rlgyW%93fi!x:mfiX:h{"RT'8(9?!W2C> !x:	#7(El	+BG!7%A7V#)(=83!7!W2@B4>EsE%&#+24!5&%!+9!+#7 .#+9382G> %BB49D>E!F2G!+#+24sA-U.V%&98%&7#$2C>)B4fi!5Je.H&B4fi>EBfi!x:h%&#)(V.5#7%BB49E1>)B4!F24<
878 7#+24fi!Hy5%&#7.V!{U> %&@:-cIE1%&.b8B4:aJ%&#7.!$#"%&#7fi! R=	(0>E77fi!+8J24s #7789
.bfi%!$7m2G!m%A#h#)(U(fi%&)#hA-!+#"%&#$2C!$#+2G> %B.bfi>7(%A2C> !g%&0#7( 7.b9%&.52G> ! Ra	( )[%&7I!+@#+B4I@#
24.b8J7#"%&#J2 7 >Efi!@ #+l	  eJN<J24 lm8&24#h%&d#7(%A#N&-#)(h8(9!F2G>)2C!$#"! R	(	.V%245LB2fi!24
>7(A2C>Eg&-BG%&s%&sRS	lm%&#N#)UE187fi!7!!+.bL24#7EBB24s #h%As 3#!r&l	B4fis:&lm(2G>)(52G!lm(39
l	a#"%Ar"!$#7^" B4s&2G>	%!Ja!+#"%&7#$2sg8&24#fiR	(	.b3!+#!+8fi>)2u>mJ2 7 >EU>EJ>E 7!>E!+#"%A3#
!+9.5@&BG! RYSd fi*#)(fi!+5@fi> %&!+5#7(d.b3!+#g243#) 7fi!+#+24s*Jfi!+#+24!g-^m!I%&+2G!+dlm( l	[(%<
!+.Her&l	B4fisV%&@#+%&Tl	2G!+(#)*%!7!F24s s7 fi!&-m@EB24E-U#7*!+#E%&#7 .b #"!I>E>E 724s&%
8%&7#$2C>EBG%&g24J24<2G%BWRI	(d8%&"%BB4EB28(9?!W2C> !gl	BG*%)fi!7!m8)8 7#$2fi!YA-%b!W2sAB58%&)#+2G>)B:
lm(2G>)(=2G!msJ  "%BB49*>E!F2G 7fi,#75@dlhEBBNJ#"!F2G[#7([!)>E8d&-!$#"%&#+2G!+#+2G> %B.bfi>)(%&2G> ! R
 #7( glhJ7r=#7(%&#mE1%&.524fi!g#7(b>Efi>E#+24@ #+l	  *E%&.l	+BG!Y%&= #77J8390-^7.
	8A2#	&-N<J24 l	>E.b8#+24s= s7 fi!L&-N@EB2E--^-c).eBG%!24*%I8%A7#+2G>EBG%&	B4s&2G>)'2G!m#)(%&#a&%&+2G!%& >E<!+r&%5y"fiJ{"R	( 957fi!+#7+2G>E##7(gr3&l	B4fism@%J!+m#7[>E!W2C!$#a&-%[>E&+>E#+24b&>E!+#)"%243#E!f#7(%&#Ly^24[#"%A#+24f{(%<#7(-c).w yWz{)| ayWzf{"wEdDU%AV|4|}yWz{)|C| [?:lm( 7
%&d=%&7aJ%&3#$2 )-c7 -cJ7.5BC%J!243<AB<J24sI%&79I87fiJ2G> %&#)fi!B49:&l	24#7(dU>E!+#E%&3#!+93.5@&BG! R
g#	B4952G!	.b3!+#L&-N#7(YE187fi!7!F24<I8l	 L&-"!+#)^" LB4s&2G>Y#h%<&%2BC%A@B24=#7(E24U%&8873%J>7(:
@#	#7(U!+#E%&#+2G!+#+2G> %B2-^7.0%&#+240#7(%&#a> %&0@YE1?8)fi!7!+fi2C!	J24#7mB24.524#7fifRmvE1%A.b8B4:24#2G!L#
8!7!F24@B4*#7,.V%&r0s  "%Bm%!7!+ )#+24!5%&@#b!+#E%&#+2G!+#+2G> %BL2 8  >ERD%&+2G!d%& >E&<!+r%
!+(&lD#)(%&#a#7(I s7 Y&-@EB24E-h> %&0@I>E.b8#7fi0!W2s5.V%1324.5. 3#7)839d-^a#)(E2LBG%&s%AsR
 (%!+#)+2my"fiJ{m(%![%BC!$;!+(&lm!$>7('%=7fi!$B#:NA-fi%A+B49;fiJ24<%B4 #V!7>E8R*L#fi:%!Yl	b(%<
%B47fi%9'!+ssJfi!+#7fif:l	V@EB24 <#7(%A#I24#52G!2.H87#E%&3#5#7,B4r%&#b%-%Ae$2C>)( dBG%&s%&sRm
BG%&s%&sJn%BB4&lU!=%&)@2#)"%&79"!$#7^" =%!7!+ )#+24! :	-^BBeL3&B4fi%&B4s&2G>&:I%&7@24#7E%&79'8AB9.52G%B
>E.5@24%&#+24!d&-U!+#"%A#+2G!+#+2G> %BhE187fi!7!W2J! :%&.H7#7(fi!+=%&7V%BBL-cfi%A#77fi!I#)(%&#e%&)V%>E#7%BB49
!+E-^BN#7br&l	B4fis ^7 87fi!$ 3#"%A#+24=8"%>E#+24#+24 E! Rhv7#7( 7.H7:#7(I"%&J.b^l	+BG!	.b #7(
.V%&rJfi!m8 +-cfi>E#[!$ !+d2T#7(2G!Y+2G>7(!+ #7#$2sR[	(5s3%B&-h#7(2G!Y8%&8 Y2G!Y#7tJ2G!7>E&< Ilg( #7( I#7(
>Efi>E#+24#7.V%124.e. 3#7)839%BG!+(&BG! RS*!+(&l#7(%&#H.V%12.5. #7789>E#+243fi!
#7@*l	2GEB49'!+E-^B:U>E&< +24s.V%A3987@B4 .V!H#7(%&#b%&70-%&bJ#"!F2G*#7(*!)>E8,&-ey+%&+2G!b
 >E&<?!$r%:  (%!+#)+2:fi?{"R
fi

fiau'uYVCa?&

m')=7 b&f4b77b7&5	* &5VA=7GbEfiE+4cJb5 3$)
G&&JaJU74	m437fiHfi&+4 fi7 7I&7g74 VN	m7757[EJ4+4=JV
fiJI+Y7&L4)fig^&)V7fiJG &)fi 	/$+fiEm)&aV345 37)3H
*)&4bm&"$3  Y47G[ $bJ4+4h0+&7&I7 70&7b++4 +4fi57A[&+G+
43J&4407I47 "E+4= +h  +"&$C$+G f^70&+4*&t"+7^E J&+u &+4
 
^ Eh7&5&4b7"&eEJ37$$J&m7Gd& [4fid4&4+4e$b5454"&+4d&
V45b^ 3)7Vb )? 
 m7fi+	&7GL& LGL73A  fi0^&&UxNFV)UEm+fiE+4	UJG7E7	cJ7V
^"&b 	7
 fi7+ +G4	7&b&
 		 7 ff
 
fifi
 U4 7
 
fifi"
 T*JC)E7b);+3E
&,+ V&+G 	&h+E&+G++G J7+ 7+4xG7+fi&4J4
  &70&7E4VfiJG f&,E
7bE&b^	+GYb )?^7V4bF
 fiE+4
 0	b+"A757bFG5)fi+4"I7A/EfiE
V45i 7707VE&b^	+G &
 fiE+4
 V	5JC)E7Y&7H+[7fi$e)fi+4"
g! fiE+4eEH"&+47Efi7fi g"
 fiE+4
 #b	d7 77,7b7C)+5&a&7= E+
^&)V7fiJG &)fi &07Ifi+$J=&N&	GE=&G &457U$)445&NV345
 77bG $
 [E)4d
 fiE+4&
 %	47;+Jb/JG7E)F4

')(+*ff,.-/0213-547698;:<,56=13>?130;4@:A13,7B
57G+fiE$J&hL&4a)^7VE$Jb&G&&m&7aE&b^	+Gb 7f
 		 )	 U4@
 
fifiD5"
 IVA7 +GGCA7E4VE& 0^7C

EGF=HJILKGMNPO@QGRTSGO5R7M
*&)07 7fi$7fiT4,^7Va4&G mG&J&=7&0&U57E?)fi75J7+E&+G++G 
4cJ7V&+4q&"$7^" H4c)V&+4JT;) 7EcJ7E$"&+G++G YG&&JU;VL
mG)'Gb&&+G&b&/,G&J&*fiF4fi3	 7WX
YfifiZ"b7=) V4 b&I7
& fiJ \
 [//)m"$7^" L? ACA73EWC$+4b&u)fiJC A7/AVE$"&a+35&G 
&H4 
 ]eb+ g&&&+G&4fi _ ^
m5+"&$C$+G aG&AV&H 3"d+"&A","+)^" I4ACH	47tcJ7 &U+E&+G++G 
J&3$  bc)eG
 `ff	ab"707 7d
 cec `fga@hcPc i0GVk
 j.lm!j5mAlonqp=mArtsvuwj.lsvx!xXp=mArfb	U
43) 77 7fi0IE&+45 a +h  y
 [Ay
 
&7&L7 7fi+ "7m77+4H&NV4
E4 b "[7A+GFcJ4z
 `ff	ab"{
 bE744& &&747"&);+ I&m&&+G&4fiT7V+7E$
&4)*^75G"
 `I   gcJ=E&H+
 cec}|2~p=7	aT7hcec ifi7E+4fixI^=T?fi
 fY7
77+4,&hVE4 b "Y7&Y&7e)G7 &;
 f
 cPcq|2~p=.ga7hcPc fi7E$fi f^Ufi
af)e))+4&hV4E4 b "Im+b7G,G9
 a&
 cecq|2~p=5	aT7Xcec iA  fi)E+4fid7
77+4=A4"g&JV4*E4 b "g7&m&7Y4*)[7G,7EG&+4_
ThG+[4&'77+45E7fi7F4&7LcJ7
 o`fga@hcga@o i &mG)5hm )
 !mArGDp}nqp=mArG<
j.lm!j5mAlonqp=mArsvuwj.lsvx!xXp=mAr7x )*&=E?)fi7F4=GL47 fi,7b 7I7I))+4=&aV4
E4 b "	7&+GF^4{
 `Tc7J &bJI73+YE4 b 3Eh)&+GF^4
 a44&5"&+4ue 
G5G+;EWC )fi7===7J7$JE7fi7F4&T7V$ [&m77+4TE?7fi)F4C
)43+fi /J4+4&=54+4G &+4

! .AX@q_v_q!@)w==2=w)WYv	T!Gg!v3g_ffeYgq_X=vA_gq_Y	2=Yg=2hwA2Agff_f=g=
.Y=gv_=gg
Gv=q_gq_9=Aw!_Y=g==!!=q_!Y=	=q_!{=!v_q_==g@_==g=)w.Xwq_g2_9=Y2=Y=	q_Yg
_yeY_=< =w ho@gXggTg{=_v=g==g3q_!{_3_wg5Gwe=	{Y=YX3wq_!Lw{Y=X
=2=gY3__=g=g


fiZ57255Y
 5e+.wXAZf<bvwv.!7vgvv5fgZZXYzA.y.DD	vZ.vYZw5.g9A

!7hL	
fiff	 +!+.Aw5.<gey!55e.5v9D.wy5Zeh5ZvA.
5X!hPv <g.ZW!!!+.Dgg.ffvAy.e.A555hPD ;.Zv9+hXAv+vZfg.w

  tA.AhvZX$e"
 !A5.<!. #<5v.Ageg% $&(' )Z;g!Av+vZ;A5.DX$y
 )Z5*
  +<
.gDe2; e+Zg;!vXYe e{5vf<2g5+ Aw9A),
 A% +7- @Ab5DX& /.e2< PL.ff& +
 evw5vfw50
 #A e5+Z1
 evX 2e  Az.D 3	 4  A 2.AgevZXffe5
 !A5.<!
. #5v.AhhP 7655w5v+AwZPevw5vXAgeW e+ ey	A & +5vZe& +!)w.A25
Z57v)D !A5.<!.Agev!@{ ege eD9 8:# ;/Zb5 < )= e{.g+vwZ& +ffev.> 
 DGFff e.vT HZ!
? ff5v!=ff.g5A55<yZ!ge. e	vZ.v @e@- A:B Cff- 2evE
A.W!+.Aw5.<geW!5we..e& +y=e.gwWA/ I A.K
 Jff;5ffAA e 8.Zw3A{2 e A
!55!g< #M
 LNA.P
 OQNXZ=
 RQI  SfiHTSfiUWVVVX =R@Y3D55Ye Aw= W Z<. [$+\
 =R]Y3A55YZWA= e

 e
.A" Z. [$Z= ^65!D+ e2 vA!5w9w5 g!Av+vZ_
 <  A7 !A5.<!".AgevZX
. #5v.AhhP` $9Z+5 .!A =- a\bvA= 0&d
 ce"g g fbfi hji  9a g fb c=k Lml\& V&(5eZZegey.vZe.
59gvWAhPvA$D55Ye Awf Z<. e	W\.Awz!+.AhPhzg5 y7eZv5vW.	& +
g  gW 2- evXD.!+3!v!5Z={+g5wv+vvYwA+ ed
 #AAgAge.;A."g
n o5A555hPDz v!A.!z2 2<v+=5
 #Age. Ze!WAeZ}< Ageh5p
  +A
 2eAf9<vvZg5.!h5!5q
 A55Ye D= e& Z<. % $!55!g< # prJ={ yg."
 v cs7j g fb` ht   g f@ c=k Lmw"YL.A+7 cs7j g fbX hjt % u g fb cXk A.
cs7j g fb` ht q% u g fb cXk Lml\
 vD55Ye Aw= & $ Y+.9<vvZ
cs7j g fb` ht 
  g f@ c=k AA55Ye D= ezZ555ff5geWA*
eyw vh x59!. 5A!A)g5.w!ge5}<W
 L5Z .!A 7FA #vDe;$e+.<XAZ
y.g+<vvZg5.!h5!ff=9<bvwv{A55Ye D+!+.Agg<.ff5 w5+w- evXA.!ff=
59<vvZf+<g5v+vZXAwm
 )Z5Ay+7959D+ 
 +A< #9{!5!< #Z= 8.ZegeA25
 A& +.- +<0
 y7zQ
? 9vAy5Ao
 y z P,
 G5v
 zw59gvA!<.gXAZg{7- e
{5|}~n<n~	& 59gv\A 	v=1 e^
 egffgv.A
 759gvA .!DX =- a.% ==}- a P\5
	 !!Ye.5XAh<. )Z57vXv
3@y!!Ye. .!5A}-a	v=0 D5}<
 h<h \h<h  A. c Mh c }<={ 
 "Sfi1Py z A.
 8.Zegv\A #DgA e

 .A.
	Y P\` Zgy5.Zv5<egeA.W{ ege vAh<n 
59gv\A)={ eP
 y z w5
 <gfgvw.A
	 !!Ye. =-1	3boDfi1& A25}w
 ] gl-SVVV%S`	AXZ5v1
  fL5<vAh{. e
 +A.
 gl-SVVV%S`	 Dv 
 I"9A;Ageg

3@y!!Ye. .!DX=-aPboDfi1& Af5W=
 LN0-A.
 OQN0-5v^
 D.
 -A
5.<gey!55e.ffA.5
 R2ff{.A5! 5{.vY.A.
	Y P\` Zgy5.Zv!- !g5.!ge.5 +ZAge.A._
 8.Xg% Y=<XZvW
 Z.AZg2 8GvAgen 
 y z  2eAf5{.g{AZ.eg5v! .Age&+yv @5555v! .Age&+
 {.A"
57gey!55	<.
ZP{Z= 8.Zege  2eAf{AZeXD5gge&+AmZ<.Ah8.v!D.5<.h<!55e.^r
.gv` # e	vZ.v@<ZXw59g5.!ge5"
 f 5.<gey!55e.Ze.5\5"
 #DgA e
fWe5!5wen
 B.Zv@@9vA
 #<ev
 hh2<h<h k <{5vtgZ.A7 Z.Dg2 8GvAh<n 


fi7&&T&&&&d&&7&G(&&4T-

0&-G&P`^ =:&d%&
5-9M-`&\<-pEd:2
:=<-\
9"-%&
 =: <<:
-`1%fi< 	%W-fi>5&5g5	-%&%M%:-1-:
&% 5
-%d&&%9<
d-`=
:-[:1-:=:<<:W&%%<=&&%%g:51<9`%&%\`&d-&&% 5-%
=&&=<11->%1
-`:-W[%`<9"%d/K%"&``=T<[W*` P
%
d7`-<fi-:=1@=%"%d2<
% [":g&PP	2%->fip=	-
 	%     
  
@ % <<=<^1  -T2x%&&,-x1-:-%<% <   -(%%&

 	x=&fi9&"&%&
< *`% [Q[W%:&fi2<^*2&fi
 ff9&- %&"-<&\-  ("9%&0[%=:`]<^-
% [*`&\& 2%&"&=&E=<n
&%&^ _= <-W& < %%&%&o=:<<:0&%%<=4&%`]<: &
&% < %:-
  &&: =:& =:<<:0&%: 2<oW&o`&%-%
&%]<&p9fi%P%&5[- <1<
  `:-\ [%-g
  /-:K-&&
< K9
%: &fi:&-fi :2[1:fi-%&1%:-&&%9<d% :<% [
&%  
]2<-fi=
]<
 < -[<&q=:<<:W&%:- 2<<<%&d- [\<%%&
&<-<&
  <:%n"
 !#$# &% T1-^=2<1<:-%5=:<<:7&%%<K=4&`%]<:"<%%&
 <<&Kfi-`
91:` '
  )
 + -,./+  0
 ( 1--&&%[-<*
 ( ++ \
 :>1&0=`:2K	%1
 &<9fi&%: 2<<5 [\-&&% %-%"=
 <%=<
<%%&^fi-:&fi<9%`&%fi-<-\=:<<:[dP<& 2
 ++ 4 3  
 5
 +678     <
 	fi=,%&0=  <%:-,	%1 [W:`q9
  :



;










=

<


%\%`&-9
 (
(
  ?,%5%:-1^ &
%<-`0:`W:-1:-&:1< :% QP<&0
( >
=:][`9m:=2@ =:&>W* =  <%&% fi&\%:- <\%&= %
^: `& `-
q&&%9`o- -<Kfi]< -\% [:-:
 A@%-B
 m<%n
 C
D-2<E
 !#$#$F % <`&=9%=&-p[-&:-1%:m:"&&%9<d-`\ :2H
 GW 	%`&:-%=<
,%&"	-2<-<&d=:-
 <
&-m&` ,:,&% <dI
 GW 2+ ff1%&1"	W`%&\ :2<g27
1 <<  :
 ++  %`<-d2J
 &< fi/^ P&
&fi<   < p`0 [P2
++  [W&&`:
KMLONQPSRUT8VWQXYWEZ[<fid=:g `&\ff9&-< K:[]_^  `a7cbd e % cf7gihdjO e % k  &% 
 [^`&5%:-`&9&1^-9:
l <&& <:`d<9 &%:%o-1:& <:

  27< %%&%"=:<<:7&`:`<:mW-:-1-:1 << <^&&\&fiK%&
,
ff &
 * 0:']_^   +ca7cb& e % ,\fgmh&j[U e % + k
  9n +cf7gihdjO e % + k&:, `K[ < 
%.+oa7pbqe % ,2f7gihdjO e % + kM   
]_^ mr :7%&/%:-/`&W9&17-sl:<&1:& <: [d2@
-::M<91%&] :9%g <<
:`fi-  %  	%5-<%:-1%&59&1:p-fil:&:& <:
d>%2Yj 	\Y9
t ,/h&u.%v WqwU4
x gmh&[j sXy z@ (["
  `*=:][% /<%']_^  %:-/24& <:"l:
@ &%-[ "%&Q%fi 9&1:(-&:& <:x(d %|{ % [>[(&(=:][% *`}]_

^ 
/
~ <-<-%&

&%&=%/ 1 << <<&
&=% %/-d-&&` <d-%=&&=<" 9Q&/&%%W%&,<9`: 
<9`%&%fi--x`&`0 [

  =:-
 <d p:%fi%"-P&: ]<fi- <p %fi=<:%&
5-91:
*
`&91	&&%9<d-`:2<d-:p%&W&%&=%/ 1 << <<&	&W%"=2<1<:-%\=:<<:
&%%<:W=4=J
   M( `"
-1%:-
 [/<% <d
W%-<fi:=  - ( 
"%&1<&
 +678    % [ [%&"%-
"%<&1%:-_
 + -,./+ [<% <  ++  - ( 8+ "
	W^`&\%&:-:>%&\=&&%%gq`:-W% <fi, 0 << <&K&,H
 + -,./+  
 ( ++ \
 [5%4%:-
 + [,.s+  [p<% <   @&   8+  % - ( ++  Ep^%-:-Q%&
 n%:=\gK%&"< %%&%fi<:W-K:0g 9
Q-:\-7% [,&% <^>\-&&%%m=:<<:7&%:%:m,-&&%<:"-:
<:%5:\& 5%& &\=&&%%]<:Q<K%&[-&:-
 	 =&= "&- :


fifi7&s"B$$OU$

A\m+$5A`q`.m&q`_A/im_A}$&+`1/A|mA-&Si}&+*cH[}B$&
+$[A.+&|+>A[$d`dq+$/'/M`B/$$/+q>Am$/i$$Im}+$
+B$q5fi`A+ Q|+ :
  EB\fim&I  A&`$2A|q+$m_`5`d|
Am8 + A/m.8AiqI QqHfi`A+ Q`+   BB\id9$AH&$
mfiA5AI  BJ$*I | Q|
JA/'AA$2B`*m*dH/`Hm
fi7m$`$5&oq&+\A&`
Bfi}BI|m$BBs`A/m/B+}&+q
+B+dA7&/
.$&+`A}A/i"BoOs+&&m`"Bfi/$&_
A_.i$fiAB+&A`AA`mq+$}m"5$A
&o+Oq5A/mBB`m\/iA}$/+q+$/"A$/Aq+$/B&.H&+q+&`mq+$[m/'$``A|$
mEA$/$`/Im"&m+*qs
-m+$Hq`.m&q`fi.Am$/m$HEd\Am25A|i/mq+$\A$$AH&$
+[E
AI$AH&$U+\Im$/i$ESfidq`.m&q`U
}$Afi'&Aq+/QBBBm$/i$J
8
Aq`&q+}A
m$/mfimq+s`AO/  |A/m"/qAAB/qH|m`"A/m}mA&'mA
/qfi`$}/iq+$/$q+$7A+$/`[$A'Aq+$BA\&/&+q+$m_E8
&`d8`A5A&/&+q+$m
m+$`'+I/&+q+$[+d/`fiA/i


_/ 

m/+/qA\mBBm/
A



_+mJq`BmUA$/Aq+$'7A+$/BA9+/+/&;mA&+AmA}A&;s`|IOq/q
|mq+$/O&H/`|


&5$fim$/+q+$/"A$s$Aq+$\AA+$/


}$q}}A/i; 
`_A`

/$92qsBmo+[iiqm&+|Q$_ 

|`Q+&A`AA`

B9mqm&+9`"fi/\A}&+&A`AA`IAmA&+.mA_/+ $q+$Bm/

AEfi/MA&U"&$$$BB`m}AHH&+q+&+;"Afi$/+q+$/`$U&Aq+/'m/m$$"$A
Aq+$Q`$`A5$AH&H2
`m\/H$AqmA'B+A9$AH&HI2  
io+m`


`$`A'A$/Aq+$'$AH&}}  ms+2A| sBA`&$\&*9[mO  


`$`AA$/Aq+$$AH&B;  +>A| sHA`&$&2$m /
 _[mO z\ m[} 


//$Q$/+q+$/"A$s$Aq+$\AA /m_o+H+/m2&';&+q+&+$

 &HAm/mq+$+I/9A`H/  +dS
E[d/`z$HA'A`.+/&`HmA'/ms`
B
B_A`dm\E$B}q&m/m$i  EB&B`H/+2$mBA_$&+` `/$&A`A*+
U/m}&+c&/`m/q9fi`\BH&+q+&+2A}+m//$/$q+$/
A_Am+`|m/MmA
&o+Om/\.mAq5;&+q+&+[$Bm$qmA$
q`.m&q`E  B$&+A_qA+$d$i|Qi/HB+HmBAA/iUq+s`AOQ$  
[Hm+$.`.m&q`IA2E+[A`A'fim 	ff
 Q$I/&+AH/| fi$|&`_}&`
 $m&2/iA|
&;s`
 Q+`
 )$/q9mEB$q_B+A&$.+
 dA dHB&/`Q+
 HOBH/$
$_B$q5$B$\/dA &+&A`A`|mq+$\m"A_q&;sm
+
 m$`BA_&$.
 d$q &
 `
 =_&`$A
 !"H
MmQ$/&`}q$}HB$q$
 #
  9m$`IA}&$.+

 %  d$  d$}H+/m
& ( '*)+% $fiiqm&+M$
 '2sm/2q}_Am+`|m/9$A$ . , E[H+H&m`$/+A+$
A9$A5A$/Aq+$'7A+$*9_A&;s`"
 /p
 0214365 785	9 m/HA9$A5$AH&>
 =;_AA}m+

:<;

?A@

fiBCEDEFHGJILKGEMENOFHP>CEDEFQRCESETUIVEIXWYDEZEM[GJ\]
^`_bacedfhgjikfhlaYam"njopq`pst8r uvYwxm8gja!myEacEfzl|{2}~kgfhgYmy[a|cEfz8fk8_baj_bms}df`lmsi8{bfaf{bgja}kE}dgjm^`f
ms_baa|cEfcEfdfsvik}daj_2l~8{2}dhA}ffdj_2}8{bfhg}d|f"_b(a|fdiEdfafh~kg_bEqkacEf"a|m{bfd}klf}dj_2}8{bfhg>
}df_b(afd|iEdfafh"~kg_E"a|cEfam{bfd}ffklfhg!tha|cEfiEdfh_2l}afhg}ffklmskgja}(ag!}df_8afdiEd|fafh"~kg_bEo
acEfm8m{bfh}lmsEEfhla_fhg}k-a|cEf>kdgjamsd8fds~k}ff(aj_kfdg6}df8fkEfh-_bacEfgja}kE}ffdy}gjc8_bms!
}k$^6cEf$_b(afd|iEdfaj_bExiEdmikmsda_mf[iEd|fhgg_bmskgYacEfd|fh}O{(~Efdg}E_a_m!~8{baj_bi8{_2l}aj_bms!
}kL}dfe_bsf$acEf_bdga}kE}dfh}8_bEkv6a>dfR}O_bkg6am_b(a|fdiEdfa>iEdmsikmdaj_bmsxa|fdRgv`fhl}A{	{
ack}a`^`f>f{	_b_bk}a|flmsk_baj_bmsk}O{YiEdmsikmdaj_bms-afdRg8~8{a_i8{b_bERms~EaO[gma|ck}a^`f>Effham8fh}O{
ms8{b^`_bac~Eklmk_a_mk}O{iEd|msikmsd|aj_bmsa|fdRgvy_UgacEfRiEd|msikmsd|aj_bmsf[iEd|fhgg_bmsLb b 	|  
nymsd`>jhh8su8acEf
 ff22  8  Y    n8hpOhh|pux  njopq     8hpOhh|p     hpstr uz  "  

  

 8c ~kg_y$  YacEfRiEd|msikmsd|aj_bmsfEiEdfhgg_mLb b     8fEmsa|fhga|cEfyd}slaj_bmsmyacEf  
 a~Ei8{bfhg_b  ack}ffag}aj_2gy"vJmsdfk}i8{bfs  b4sJn  p|kub O 4  [	<  _2ga|cEf`yd}slaj_bmsmy8msR}O_b
f{bff8agack}a}d|flc8_{28df$myqnkuv
 g_bEms~Ed"fkfhE_bE$my_b(amx`^`fEm^ck}OsfgjfR}8aj_2lg6ymd`vJmsd"`^`f
g}O$ack}anopq`p8rt u  _Lnjopq`pst8r u  v-ae_2ggmsfaj_bfhg~kgjfy~8{`_bms~Ed"y~Ea~Edf-dfhgj~8{bageam
_bklmsdimsd}af6ik}daj_2l~8{2}d}O{b~EfhgYymsdacEfa|m{bfd}klfhg_b(a|macEfymsd~8{2}>  v  c(~kg{bfa  tEr EdfiEdfhgjf8a
acEfeymsd~8{2}ack}ffadfhg~8{ag6ydm  _yzfh}sl|c$A}dj_2}8{bf_2g>dfi8{2}slfh$^`_bac_bag>A}A{~Ef-}sllmsd_bEam
!rt Eack}ffa_2gtv
 8i8_2l}O{{^`f}d|f_b8afdfhgjafh_bl|{bm(gjfhgjf(a|fklfhgEack}a_2g8ymsd~8{2}sg`^_a|cEmyd|ff"A}dj_2}8{bfhgv
ack}a"l}sgjfs_ba>_2g"Emsa>ck}damxgjcEm^ack}a>acEfA}O{b~k}a_mi8{2}hEg"Emd|m{bfsv  c8~kg_y_2g"l|{bm(gjfh
^`f^d_a|fRnjoptEr u  d}ffacEfda|ck}nopq`pst8r u  v_bk}O{{bs_y"}ffk}dfl|{bm(gjfhymsd~8{2}sg
^`f"^dj_baf"  _	ynjoptEr u  "_bi8{_bfhgnoptJr u  v
H4-8HO8[YU(
 gY^zf`fEi8{2}O_bEfh_bacEf_b8admE8~klaj_bms!8^zf`_bsfgjf-}(a_UlgYa|m8fsdffhgYmykf{_bfy(lmskg_28fdj_bE}O{{
^`msdj{2Egmffy g_ f  amekffh~k}O{{b{_ sf{bsklmsk_baj_bms8_bEms"8}kacEfRl|cEfhl s_bEacEfiEdmk}8_{	_baj
m
y 	msfd`acEf"d|fhgj~8{baj_bEiEdmsk}8_{_baj_2gjadj_bE~Eaj_bms!va|cEf"iEdfs_bms~kg>gjfhlaj_bms!J^zf"8fkEfh^6ck}a`_ba
fh}kg ymdz}gf(afklf>xa|mkf" g}a_Ugkfhe_bx}>^zmdj{2my!g_ f  ~kg_E}am{bfd}klf>sfhlamsde!rt fi
v ff_bsf

 nuamf"acEf"(~Efdmy^`msdj{2Eg_b  g~klcack}ffanjoptkr uz v
ff
}
k



!
t
r
(

`
^

f
8


f
k

E


f






<








_bklf^zf}ffdf"a} _bE}O{{^`msd{UEgamkfefhs~k}A{	{b{	_ sf{bsacEf8fsdffemy f{_fy_b
 	ff_f"X^`_bac
dfhgjifhlaa|
m   }krt _2g
<   n 	"!x"u
 d   n 	""u



<  n"u

y#   n"u %$ Eac8_2g8fsd|ffmykf{_bfy_2g6Emsa`^zf{{b8fkEfhv
 cEfl}dfy~8{dfh}s8fd>R}Ock}OsfEmaj_2lfh}imsaf8aj_2}O{iEdms8{bf ^`_bac$ac8_2g"8fk8_baj_bms!v  adj_2laj{b
gjifh} s_bEk^`fgjcEms~8{2^6dj_ba&
f   n 'ud}acEfda|ck}
   kg_bklfacEfgjfa6my ^`msd{UEg~Ek8fdlmskg_U8fd|
}aj_bmsl|{bfh}dj{bx8fikfkEg6ms-acEf"smEl}E~8{2}dsv (6fklfsEacEf"8~Ekfd`my^`msd{UEgz_
   }O{2gjm8fikfkEg







ms-acEf>sm[l}ffE~8{U}ffdsv c8~kg8kmsa|c< n 	u}k)< n 	*!"eu8fikfkmRacEf"l|cEm_2lf

+-,/.1032546257892;:50=<#4>09?@257A4B2509CD4EF8GAH4:6I  <68JLKM4fiNDE5EF892OND03GM8PCQ@ND2;ND:R?03E257-ND:SE5498:50=G257M82TU4V8PCWCD09TU4 XNDE5EF892OND03GM8PC
GZYA<;KM4E5:[NDG]\AE503\0=E52OND03G&4_^A\AE54:5:OND03GA:`NDG]aUbU,
ced

fif6gihkjlnmRo#pqArslsgt@m`uwvfihxqAqylsg

z{&|>}~xzs99/3s`9kkZ/Z/kZ/3ZZ/33zs=L5{|6|VR9Z9Z93zs/P=k
  R#yF 5Z L
  R=}
/9/#{5zs]y1{5zs9ks#zsZ6ziZk|V@*F W5



6



]


 kL9AkA[{59zsBkL{5zzM>&/&9*kZs9Z*z{6/33{  
>/kZ/Z/kZkz{



zsVz3&z{
szZk9siB9zsA
9zs6Z>yF}@AsU=}
 kkZysB#)ez39Z)zs
 3/s3s}6V#ezw9/9A/
9/
 Zy}  k/Z6##zsks9z3sz s939yD55   Z ] 9z
/ M    ]     6] =}Bzs39/*9zs3kZz{&#z3)zsZ%
 /%

/zs =kA}5{9) A  /A9Asy69Z%#SzkeM%zskk/ 

9zyk96A/ysi /3]6 9Ak##zsknVAkMyZk69z&9A9zye6As/M
s#3/s36A/ys}
 k]k3/kzs@[zSZZA>zs&PkZeAU&&*A)zV3kA}]zs/PZ9sA/zs
9/)R    6] &*zs)y6AS3Fk3/AU}F%/3kA#)y/9ZsP/{5zs
3Z9=M%yA*z{@ 6R    6] *z#3Fk3/A%{5zsk=9}%F%zs=kZ*9z
kAy&#9%9k*9zkZz{#3Fk3/AkAZ]#k3/ ] 9z/ -M-Os=/3Z5ZU {
{5zsM&kZk*y%
 /k)Zk9s>    9] }>zsz9Z
9keZZZe9/Mx3zs/ P9Z/3LkA9/`9 ] R9_k;/k96kzsy/`z{9k9=
9s*_Zs}~xzs]3/ksR ] =9/39Z93/s3kzsM3ZZk=9*zs
ZsZk9/y3zs/_9ZkA}~xzs69]Zy/kZVz{19&//ZA#&s]9/6y1kz#Aks&/A
9ZsZk9/y3zs/_9ZkA}_=s3P3sB#3/A3ZsZk9/y&3zs/_9Z/3%9z/z/=kZ
9zA99/3zs/_9Z/3s}kzzs3/A3ez#Aks/s)9zks3nzs/zs9
kzsM_ZsR3/3Z6Znzs/&As/ZeA})~xzs&9zk/_/A#99k
ekPz@Ryznze9_k9z//{5zs9Mfi3zs/zs/Z/ZsZk9/yV3zs/ P9Z/3s}~zs
/=/3sfi*/zk9_k9zz9/){5zz#3zs/zs/9k)Zk)9zs/=e9Z
9/ ] #ZsZk9/y)3zs/_9ZkA  k ] kzkA#zs#/]ezs5/9AZ9AZk//
A/y/Z#ZZ9Z9`/  U ] 3zs/ P9Ze`{5zs  kzsy_Z#6Zy/9zyk*9
3zs/zs/>9&Zk3Ak3/s3V3z/zs/-}]/3#3zs/3Zk9=9&zs/9*s/sA
9kB//Zy9k6AkV3zsZ=#zk6ZsA#z{`eZ9AA}
 sZ{ ] ZsZe/y3zs/_9ZkA@yzs]3kA}~xzs]3/ks[Lyn
9]Zs>9/   6] Rze99A#/Z#ZZ))3
/*
 *3`{ zs#zs  s#sZ3`9ss}`_
9k>Zssx{ zs>e*/9P3k@ x9]sB9zV##
zV3kA
} BzM#ZsZys]ZZ>s;{
9> )
 s9zV#M1zkUx9k6Zs/&;/_/3L9]ze9zs/]nzsVsz9z}
&ysz/9)zskZ6k)3zs/_kZ)9 O3  / y k=Z69/)9y}6~zs
kPZ
 
	fiff ]k/ z
{ Sik
{ S6&s9A9A;zM#Z6nzs/z
{ S}   OA z{
AZ/3]B9>]z{
9>k/Zn9/;Z
 k{     k{    
]
 
]

 #k{13k=`{5zs#eAZ/3>/zs/kA{59zsn3z&kZsZ{@966kzeA;zsy}   
3  Bk3/A/yzszs/_s6Z9&P
 kZzs9A#6AsB/Z>/zs/*z
{ S}R {@  ] 






kzkA3ey9Z ]
k{ ]
P ]
}/3s;{ zsk @ ;9 
AZ/3    6] >y fiyL/zs/kA { 9z /zs)//3z& ;9*/ k{
y6yiU3kA}  e/-A#SkzBzs@/ysR9z6#zs9Vnzs1R9zskZz{izs3k9Z/3;{5zs@/9P3k
MMABz{&@ }R&ZzAZeB9]//y[{ zs z{
zs>k3/kPz@}

!#"%$!'&)(#*,+

{

    k{     6] /
 
]
M   

-.

    %     6] 
M   
 
]

fi/103234)57698:53;3<=4)>?03234A@B03C3D%61E36GF23H3;I57JLK
MONPRQTSVUWYXZP\[L]O^[L_RS\S`aO[=bdc!PeQ3Sf]gPeQ3SihjlknmojVjpZqBrejsutvjvq\txwzy{kntY|Ljfwz}~c,_oWPePRSf]z_lyu}~c7W%X
^SVO]3S^T[XPRQ3SVNN]bWWP=,NPRQ3Sf_RWYXZS\_lyu}~^NSX]3NPSVUW%XoP
 S\ebNXZSPRQWYXXZSVPoWN]gWPeQg[vSf9_eSfB[L_R3XN]Na3_^SVO]W#PZW#N]!W#_XZP?]3NPRSPRQO[LP=c3SfSf]aOXlW]3
PRQWYX^SVO]W#PZW#N]!c1PeQ3Sf_RSB[L_RSB[L]f[XZSXQ3Sf_RSPRQ3S^Sf_RSfSNLMOSVbW#SV\^NSX]3NPSVUWYXZPNLSfSf_c
[XXoNSNLNa3_bY[LPRSf_SVUO[Lb#SXXZQ3NL\cW#]:B[L]
XlWPeaO[LPZW#N]OXPRQ3S]3N]3SVUWYXZPRSf]OVSTNL[z^Sf_RSfSNL
MOSVbW#SVif[L]MSga3]O^Sf_VXZPRNNI^fiW#]PRaW#PZW#SVb#GvvN_W]OXoP[L]OVScXZSfSzUO[Lb#STOA[L]O^fiPRQ3SzXZa3MOXZS`a3Sf]P
^WYXRVaOXRXW#N],V  STVNabY^,c[=b#PRSf_R]O[LPZW# SVb#c?QO[=STP[LSf]fiPRQ3Sz^Sf_RSfSTNL\MSVbW#SVB PeNMSgPeQ3SW#]PRSf_RL[=b
^SVO]3S^MbW#A   bW#W]f   _  lyu}~[L]O^bW#A   bW#XZa3    _  lyu}~c33_RNLWY^S^
S[eQBNnPRQ3SfSVUWYXZP1QWYXNabY^QO[=S?MOSfSf][OSf_oSVPZb#_RS[XZN]O[LMb#SRQ3NLWYVSNXZPNLPRQ3S_eSXZab#PX
SXZP[LPeSNab%^ANzPRQ3_RNa3Q:W#PRQSf_ezbW#PRPZb#SgeQO[L]3SWSQO[^P[LSf]:PRQWYX^SVO]W#PZW#N]!a3_
^SVO]W#PZW#N]zXW#bWOSX?PRQ3S\SVU3ONXlWPoWN]gXbW#QPZb#
W#]O[=bb#c3S?_RSfB[L_RPRQO[LPW#PB[=BXZSfSfa3]3_RS[XZN]O[LMb#SPRNP[LSbWWPVXWS?]3NLPeQ3S\^NB[=W#]
XW#fS\N_QO[=S\[MONa3]O^N]PRQ3S\^NB[=W#]gXW#fSbS[n_Zb#c3W1S]3NL[L]O^  c3PRQ3Sf]W#PXZSfSfBXN_RS
_RS[XoN]O[LMb#SPRNaOXoS_   _[LPeQ3Sf_PRQO[n]_[X!Na3_^Sf_eSfSNn)MOSVbW#SVRd]O^SfS^,c3[XXZQ3NL]W#]BZ[fRQaOX
SfP[b%c=L3c,[L]TNL PRQ3SW#ON_RP[L]P3_RNSf_RPZW#SXPRQO[LPQ3Nnb%^vN_\PRQ3S^Sf_RSfSNLMOSVbW#SV^SVO]3S^
M_Q3NLbY^vN__  cN_[bbeQ3NLWYVSXNL[L]O^  Q3SVN]3]3SVPZW#N]fiPRNB[UW#a3Sf]PR_RN
PRQO[LPSB[LSW#]PeQW%X?O[nOSf_\Q3Nnb%^3XN]b#z[LPPRQ3SbWWP=cM3a3PMOSf[LaOXoSl[XNa3_\3_eNNLdX?XZQ3NLPRQ3S
VN]Sf_RSf]OVSWYX_V[LWY^,cPRQ3S^Sf_RSfSNL,MOSVbW#SV_VZyu}~\WYXPZWYf[=bb#B[Sf_RNN3^[L33_RN=UW[LPZW#N]
PRNB_   ly}~\cSfSf]N_N3^Sf_[LPeSVbbY[L_eS\[L]O^N3^Sf_[LPRSVb#XZB[=bb  
z7O,7vd3)GO!
!vLO=!L%!fif:g3vzO=)
Q3SW%^S[NLB[=UW#W#VW]3jw)xmRpVO:QO[Xb%[=S^fi[L]:W#N_RP[n]P_eNLb#SW#]B[n]OSVbY^3XfcW#]Oeb#aO^W#]3
PRQ3SXZPRaO^TNL13_eNMO[LMWbW%XoPZWYNI^SVbYXN_W#]Sf_e_ZW#]3^Sf_RSfSX?NLMSVbWSVl[=]3SXcQO[n]3]3N
]
 S[=Sf_c=Ld]PRQ3SBXW#b#SXZPXZSfPRPZW#]3OcSf[L]TW#SfSf]Pe_RN[X\[_RS[b vL[=b#a3S^a3]OVPoWN]zN]
O]W#PRS3_RNMO[LMWbW#PZBXZO[VSXfv WYX1[?O]W#PRS?XZSfP1[L]O^ WYX1[?3_eNMO[LMWbWPZS[XZa3_RSN
] cLPRQ3SSf]PR_RN







%
W
?
X

^
V
S
O

3
]

S

^
R
P

N
O
M
S
fi

ff
















#
b
]









d




S

P
n
[


S



#
b
]










	
]3S?XZP[L]O^3[L_V^[n3bWYf[LPoWN]BNL,Sf]Pe_RNWYXPRQ3SNLbb#NLW#]3Oa33NXZSS]3NL:PRQ3SXZO[VS cM3a3P
QO[=S\N]bO[L_RPZWY[=bW]vN_R[LPZW#N]z[LMONa3P cSVUI3_RSXeXZS^W]PRQ3SvN_RNnVN]OXZPR_[W]PXf?3N_SVU7[LbSc
SW#QPQO[SB[VN]OXoPR_[=W#]PXZaOeQ
[X  =   !L "$ #3fi
 %bPeQ3Na3Q:PRQ3Sf_RSB[=gMSB[L]
S[Xoa3_RS&X PRQO[LP[L_RSzVN]OXlW%XoPRSf]PW#PRQQO[LPST]3NL\cPRQ3SOmVtx(w 'ftu)sjTpZ*
q )&+$,-t )./) jw)xmRpVO
XZa3SXZPXPRQO[nPBS[^N3PPRQO[L0
P 21QWYRQQO[XPRQ3Sb%[n_RSXZPSf]Pe_RN
[LN]3
[bbPRQ3STVN]OXWYXZPRSf]P
ONXRXW#MWbW#PZW#SXf4
 3?XW#]3zPRQ3S[n33_RN3_ZWY[LPRS^SVO]W#PZW#N]OXfcW#PBf[L]:MSXZQ3NL]:PRQO[LPPRQ3Sf_eSWYX[gXoSf]OXZSW#]
QWYeQzPRQWYX  1 W#]OVN_eON_[nPRSX?PRQ3
S 5eb#S[XZ7P 6[^3^WPoWN]O[=bW#]N_eB[LPZW#N]ARQO[L]3]3N8
]  S[=Sf_cLV
3N_1SVUO[Lb#ScWSQO[=S?]3NVN]OXZPR_[=W#]PXN
] cPRQ3Sffi
]  1 Wbb!MOSPRQ3SS[XZa3_RS?PRQO[LP[XRXW#]OXS`aO[=b
3_RNMO[nMWbW#PZzPRN[=bb1SVb#SfSf]PXNL9 & :Na3Qb#zXZOS[nW#]3O;c  1 [XRXlW]OX?3_RNMO[LMWbW#PZW#SX[X?S`aO[=bbA[X
ONXRXW#Mb#SnWSf]PRQ3S\VN]OXoPR_[=W#]PXf
!-<>==!@?d,z2A%CBf:L!DBf=OOEB
F W#S?B[=UW#a3Sf]PR_RNcPeQ3S_[n]O^N& vN_ZbY^3XSfPRQ3NI^WYX[=bYXZN\aOXZS^PeN\^SfPRSf_RW#]3S\^Sf_RSfSXNL!MSG
bW#SVW S#c3_eNMO[LMWbWPoWSX _eSVb%[nPZW#SPRN[]3NLb#S^SMO[XoSD %XWY^S_eN9PeQW%XcLWYXPRQ3Sf_RS[L]VN]3]3SVPoWN]
MOSfPZSfSf]PRQ3SPZNW%^S[IX H!VNa3_XZScLPRQ3Sf_eS1WYXPRQ3S_[nPRQ3Sf_Pe_ZW#WY[=b3NMOXZSf_RL[LPZW#N]PRQO[LP_[L]O^N&
 vN_ZbY^3X
VN]OXWY^Sf_X[a3]WvN_R3_RNMO[LMWbW#PZB^WYXZPR_oWM3a3PoWN]TdNLSf_PRQ3SXZSfPNL,N_ZbY^3X1XR[nPZWYXW#]3}~Vc[L]O^W#PW%X

JLK

fiMONQPSRUTWVXZYU[E\]T]NU^DV;_a`9P[E[bT]N
cZdIefeghSiUj$cOifikmlCn$kkmlUdOoUiSpfqj]rmsutvpxwykmryp{zUoUkyp{j]ifij$|]dGr}n$iS~&wydGk}lCn]wkmlUdOlSp{]lUdEwykCj/wwp{zSeddGiSkmrmjv/~]oUk
p{ikmlSpxwwydEIkyp{j]icZdwlUjLcn$iUj]kmlUdGrbdGi/kprdIe~tvpfDdGrmdGi/k&n$iCtsoCl tSdGdGWdGrE}Ij]iUiUdEIkpjvizCdGkycZdGdGi
r7n$iCtSjvs&gcZj]ryextUwZn$iCt&klUdUryp{iCp{Se{dj$q;snbSpsoUsdGiSkmrmj]S~]ZlSpxwIjviUiUdEIkyp{j]ilUj$extUwCm$b]I&-/v
}0-IE}-S&b($Of7b]$G-S]Z}SGG(S(7CmI$7]$7CG$(-EZikmlSpxw
Gn]wydcZdGniIj]iCwptSdGrUrmj]zCn$zSpfefp{k~tvpxwykmryp{zUoUkyp{j]iCw(n$iCtp{iCn$rmkypxIoSexn$rZkmlUdsnL/p{soUs&gdGiSkmrmj]S~&tvpwg
kmryp{zUoUkyp{j]iDj$|]dGrkmlUd&wydGkjq9n$kmjvswGOkj]swn$rmdj$q9IjvoUr7wyd&|]dGr~tvpfDdGrmdGi/kqrj]sWj/wmwp{zSe{dficjvryextUwG
qj]rp{iCwyk7n$iCId]kmlUdGrmd*n$rmdj]iSe{~CiSp{kmdIe{~sn$iS~j$qklUdGsp{iCtSdGCdGiCtSdGiSkj$qkmlUd*tSj]snbp{i4wp{Gd7
 oUrkmlUdGrms&j]rd]$kmlUdOsnbSp{soUs&gdGi/krmj]S~tvpxwykmryp{zUoUkyp{j]iCw9cdOIj]iCwptSdGrZcZpfefe(ky~SSpxGnbefe~0iUj]k}zWdOoUiSpfqj]rs
 dG|]dGrmkmlUdIe{dEwmwGsnbSp{soUsdGiSkmrmjv/~p{ikmlSpxwiUdGcuwyCn]IdGn$ikmdIefeOoCw&nfie{j]kfin$zCj]oUkkmlUdtSdG]rmdGdEwj$q
zCdIefp{dIqtSdICiUdEt*zS~rIn$iCtSj]scZj]ryextUwGi*Cn$rmkypxIoSexn$rEkmlSpxwIj]iUiUdEIkyp{j]icZpfefe9nLee{j$coCwkmjfioCwyd&snL/p{g
soUsdGiSkmrmjv/~n]wn0kmjSj$e;qj]rIj]s&UoUkpiUtSdGvrmdGdEwj$qzWdIefpdIqmdzCdIefp{dG|]dklCn$kklUdrmdEwykrypxIkyp{j]ikmj
oUiCn$rm~UrdEtvpGnkmdEwpxwOiUdEIdEwmwn$rm~fiqj]rOkmlUdIj]iUiUdEIkyp{j]i*cZdn$rmdn$zCjvoUkkmj0sn$h]d]
iCtSdGdEt;n]we{j]iUn]w
kmlUdh/iUj$cZe{dEtS]dzCn]wydsn$hvdEwoCwydj$qnzSp{iCn$rm~&UrdEtvpGnkmdwy~SszWj$ej]r}oUiCn$r~qoUiCIkpjviwy~SszCj$e7ScZd
wyoCwyWdEIkklCn$kZkmlUdGrmdpxwOiUj0oCwydIqoSeIj]iUiUdEIkyp{j]izWdGkycdGdGiklUdkcZj&n$UUrmjSn]mlUdEwn$kOnbefewydGd]dEIkyp{j]i*
qj]rwyj]s0dtvpxwmIoCwmwpjviD
 dGkzCdkmlUdwoUzSeniU]oCn$]dj$q}cOlUdGrmdjviSe~oUiCn$rm~UrmdEtvpxGn$kmdw~/szCjew0n$iCtIj]iCwyk7ni/k
wy~SszCj$exwZn$UCdEnr}p{ifiqj]rmsoSexn]wGvp{iCnrmkypxIoSexn$rEUcZdn]wmwyoUs&dkmlCn$kZdE]oCnLep{ky~&zWdGkcZdGdGikmdGrsw}tSjSdEwiUj]k
jUGIoUrp{i&qj]rmsoSexn]wp{i ZyZdEGnbefe(kmlCnk;pifi  ]cZdnLee{j$cdEvoCnbefpky~&zWdGkycdGdGi0kmdGrmswG$zUoUkZtvpxwmnbefe{jLc
dEvoCnbefpky~zCdGkycZdGdGiUrmj]Wj]rmkyp{j]idIQUrdEwmwp{j]iCwGf  dGk}zCd*kmlUd*Ij]rmrmdEwCj]iCtvp{iUwyoUzSexn$iU]oCn]dj$q
  ZikmlSpxwwyoUzCwydEIkyp{j]iDcZdwylUj$ckmlCn$kOklUddIUUrmdEwmwp{|]dCj$cZdGrj$q}n0h/iUj$cZe{dEtS]dzCn]wyd&p{i*kmlUd
exn$iU]oCn$vd9fipxw;]oSp{kmdefp{sp{kmdEt}iqn]IkbLwyoCl&nGn$idEwmwdGi/kypxnbefe{~j]iSe{~Sexn]IdOIj]iCwykr7nbp{i/kIwDj]ikmlUd
Urmj]Wj]rmkyp{j]iCwj$qkmlUdn$kj]swGqCcZdZkmlUdGikmlSp{iUhj$qCkmlUdEwdn]w;Ij]iCwykmrInbp{i/k7wj]ikmlUdIUrmj]zCn$zSpfefp{kyp{dEwj$qCkmlUd
n$kmjvswmUvkmlUdGicZdlCnE|vdkmlUdp{iU]rmdEtvp{dGi/kIwiUdEIdEwmwmn$rm~fikmj&n$USe{~snbSp{soUsudGi/krmj]S~]i]dEIkyp{j]i*U
cZdOwylUj$ckmlCn$k;kmlUdGrmdpxw}nwykmrj]iUIjviUiUdEIkyp{j]i&zCdGkycZdGdGi&kmlUdZsnL/p{soUs&gdGiSkmrmj]S~tvpxwykmrpzUoUkpjvi&qj]oUiCt
kmlSpxwc9nb~niCtfikmlUdtSdG]rmdGdj$qzWdIefpdIqZ]dGiUdGr7n$kdEtfiz/~fir7n$iCtSj]s0gcjvryextUwZs&dGkmlUjUt
jwydGdficOlCn$kIj]iCwkmr7nbp{iSk7wnfiqj]rmsoSexnSexn]IdEwj]iklUd&Urmj]zCn$zSpfefp{kyp{dEwj$qn$kmjvswGWp{kpxwoCwdIqoSeOkmj
Ij]iS|]dGrmkOklUdqj]rsoSexnkjn0IdGrmk7nbp{iGniUj]iSpxGnbeqj]rmswOnCrIwykwykmdGkjtSj$p{iUklSpwUcZdqj]rsnbefp{Gd
kmlUdtSdICiSp{kyp{j]ij$qn$kmjvs>$p{|]dGifip{iklUdOp{iSkmrmjUtSoCIkyp{j]iD  dGk4L $EEbm ]Ij]iCwpwkjqkmlUdoUiCn$rm~
UrmdEtvpxGn$kmdwy~SszWj$exwZp{ikmlUd|]jUGn$zUoSexn$rm~
fivD{EDD i v$y$LpxwIj]i$yoUiCIkyp{j]ijq}kmlUdqj]rsb ; bE   27WcOlUdGrmd
dEn]l   pxwdIp{kmlUdGr  jvr   $p{iCIdkmlUd|Ln$rypxn$zSe{d& pxwZp{rmrmdIe{dG|$n$i/kkj&j]oUrIj]iCIdGrmiCwGWcZdky~/SpxGnbefe{~
wyoUUUrmdEwwZp{kn$iCttSdEwmIryp{zCdn$inkmj]sun]wOnIj]i$yoUiCIkyp{j]i*j$qkmlUdqjvrmsu   EE    
 j]kmdklCn$k&kmlUdGrmdn$rd  9
   n$kj]swj$|]dGr&@n$iCt kmlCn$kfikmlU dG~n$rmdsoUkmoCnbefe{~dICeoCwp|vdn$iCt
dIUlCn$oCwykyp{|]d]ZlUrmjvoU]lUj]oUkkmlSpxwCn$CdGrEcZdoCwyd
	@kmjtSdGiUj]kmd
 n$iCtfiff EbEbm ffkmjtSdGiUj]kmdkmlUd
n$kmjvswjL|vdGrfiSefpxwykmdEtfip{i*wyj]s&dUUdEtj]rItSdGrE
8 ( ZlUdGrmdnrm
d 	 
 n$kmjvswZj$|]dGrOa $ b  G !ff  4  " $ ff#   $ $
ff%&
   " $' ff  (
   ) $
9lUd v$ CmIQ-$ 7+
 *,*-ff  . *,* / EbEm *,*-ff. *,* /cZpfefeSexnb~ nwp{]iSpf(Gn$i/krmj$e{dp{i
j]oUr&kdEmlUiSpxGnbetSdG|]dIe{j]Us0dGi/kE
kfikmoUrmiCw0j]oUk&klCn$k  pxwn*rIn$kmlUdGr&cZdEn$hexn$iU]oCn$]0d *nqj]rmsoSexn
2
 1*}tSjSdEwZefp{kmkye{ds&j]rmdklCn$iIj]iCwkmr7nbp{iklUdUrmj]Wj]rmkyp{j]ijqkmlUdn$kmj]sfiwG
i*j]klUdGrOcZj]r7tUwGSqj]r
354'687:9;7=<?>@9;A#B;CD>EB<?>EFHGJI@KLINMO99;7=P;MRQSB;PUTE>EFVD77XWOB;7YFOZ57YZ8B;I[B;CO7:T\>@P;7]^CO7Y9;7B;C57?_`a<!7YFHBbSINFOPU7YcHMd>\Q-bSBG.e VOM5B
B;CO7U7XWOB;9f>[TYIN<!gRQS7XWHbSBhGINVOP;TYMO9;7YP<?>EFHGJIEKB;CO7U7YP;P;7YFHBbi>\QbSZO7E>EPY4
jOj

fiklmnLoqpsrtouv5nLwJlmnyxzl{|}p~pmuoqD
D Y'@y[HDfi''DfiO0 ,ddH E
 },a }@aE
0 ,fiE00EY,0fiNEOEX,0'
DEEOY'N0',Y,0'd#E00EY,0'D#DE0zRz[0EzN0 NtY .0N\}z0@ H@fi,
^ @0'0@Y,0':dHUE ,OH'.YE;0N H!'D\iLHY,0 OYEOE0'EY,0'H D'N0',Y,0'5
E00EY,0'   O:00NEO@X,0#D!H5UfX!  O0N0H ,H'N0 D[H0HOD dO 
HD)D;EH)8NEOEYOD0EY'H@,'NY,)EJ; d[H?"EhD'D0Jh?'\O
 ,0H$D )@J'.Y#Y@H)ED.D ,,zzd,
H EE0 
h?@'\  [ h0@zD
NEOEX,YfiD')EH h0N5"@0'0@Y,0$EH@z[ $DE0
hE0'EY,0$@HEzH:fh#5hY'YN; 
EzD0DDY,0'
EHX, LHDY,0'EE'D8i#N,t',0ON\t')a)N0
 ,
EOYJYEH''
EO @?E'D[(?E.D'=0@O E
Y'O@h5NDLDN0@.(? h@z[[D
 OENY,0
!,O},[ fi0;D
;8;HNDdR!&h!'D, 0
h5"D0HU@HEz:DE0@,-=\,  
?HEhDDED0H0'EDE0}EHE}DN;hD?H0HEaN N@,H
D[E
' 0
h5UUh'=\0
!,O}U
 =@,YO#YH EH'N(  hJ,NDD';.0HDN,})h='N\D
N0DY'NY,0'H?HEO0@$N0DY'N?h0DUEJ;DD[,'
yf+ff:?tXiR=N?fX:
Uf! f,R=EN0?HEJD'fDEDE0
h[@HEz[D'
  h?X,Y,00
  #=YU0  J[Y=!Y0DE[E0
t[Y 5#Y0DE[D')Y8N0'Y. D
 @EHE0@00}='N?HD0N.d'0EE 5D'
 O 5;0	 ff
 
 fi8N0DY'N.H0HD

,8N0 .5,$0Ea[Y 5?D'fi JE=. 0E8@'D#@OYh0Y8N'\'DEX, ,$
, ,z5
N0'XhY@H'N)EO0 ,EHH.R
 5   
  DH#HDN)  h8 hD0H!;J.i hy.DD';N0DHD. "!DE$#
  
DDH %! &R\8D( '#.5hD['E5. )* \ &0 %,+hDHaDN
 .
 -   %[.D O8Da  hD0HL
HD.
 0
 )
/- haNDL';.05HDN.
 
[JE D"DE h[EHEH$'DU5@H0EHz)@ }:'DHO'HD';0',)E'H'
8EHzEz@'D#@,H0EfiDUE;0E
 h 
/- hJ=  hH5,$N'0H Yh5U,fiE,H0EfiD1-
0'@
 ,D?\HHz:,HEH ?,)E@H8 N'O EHEzDDEzH
H0EH3
 25 4hz0HH.57 6ODY,0D
 8Uh5,9
 4; : 7 < =J5,'H@><@?A?0 NXO:,EE:h
0HH.di7 6OD\D'?[N,;D?
EOY ,U? h@E5^E'D"J'.\E;0. H^E
 }[,E0 ,8'DE
EOhHDEOhJO0 ,ddH 
E)0
[,Efi0 ,a HE;0z'D Y'HOYY,'
 B[00 ,aYOD0,'
E h}'OH'Y;0#'D Y'O;0E
 hY'@0  C -  'Y ;0E
 h0[.d,'0#dYhD ,
D)0EHJE'DafiHDfi'
D0O 0.Xh 
EEN0
DE'D Y'HO8[ hhJ' EX, ,'OHD'\
,EH.5!Y ;0E
 h)HDfi.5,$D08aD'0
 D)E0HEHOF
 E?E D!'\OJEED} OD'
NEH':,[E
E0'EY,0)Y.DEHH.R"X)'DEYhN hDO?YD#:E'U;0?D.-   EHEh?D
O D5,HH
 -
G ? h@$'0OYEO0'D Y'H.0[OYEO E0'EY,0'H
0YhN0D[H0HOE'D8Y'@t$@OY ,  O08}y'Nz[z5,D
H0H X,D,) ,'DE


EOhHDE,EhD0'D00 0N'D ,0?E E
 }J
 ID  KYM LND8@,ODY,HOOY@O
'D\iLHY,0t'OHD'\O
 K=P LND?.5,D'0
0EtD'Q
 D 'Yfi
'Y
EHzdt@  E
RTS

fiUCVXWZY\[^]1_a`\b@cA[AV\dM]fehgWib@bj[AV

kNlmAn^opm*qsr^mAtNuwvAxy{z|t~};ok$}7tNurZ}7zy*Nn\No@}ly*tNo@kPo@yAluJy\}t}mzyjZon\tNuwm*qsz\o@kt~}7z\No@yj;7
ZmZo@k1yA\o\n\No@kNk}7AoCn^m*oj	auZ}ksku\mTffkMtNuy{t	tNu\ooly{zproaz\m

ly*z\mzZ}lyT\qmA

;}7Aoau\omANo\5qmAa~}lu\oy{z\Axy*Ao@kauZ}k1}kNkx\off}kmAz\offm*qMtNu\off

Ctu\omANovxZ}to

yj}7zNo@yAkmAzk1CuZpaoCNo@ktN~}lt

tNu\o>tNm yFx\zy*y{z\Axy*Aoff}7ztuZ}kny*n^o@aNAoo.Ao@lt~}7mAzOqmAaqx\NtNu\o}kNlxkNk}mzM;
 }7AozOy*zZ.qmAxZy"}7zOly*z\mAzZ}lyjfqmANaoly{z}7ppo@}y*tNo7Zo~}7AoFqNm}7t@\}7zy k~ZzZtyAlt~}l


y*z\z\ojypk~otCm{qlmAzktNyj}7zZtkmAztNu\on^m|kNk}7rZ7on\NmAn^mANt~}7mAzkam{qy*tmA

k

M7@MM7Mff otF>r^o>}7zOly{z\mAzZ}lyj	qmAN01wolmzk~tNNxltyqmAxZyp,N>1}7zOtu\offy{z\
Axy*osm*qNo@yjlmZk~o@Fo\ka}oA@m*AoftNu\oaAm\ly*r\xZy*Np*\@A$AaAyAkPqm*;7m*k*Cu\oNoa*@@jNN^
y*NoffqNo@k~u*y*~}y*rZ7o@kF}k~t~}7zltqmAtNu\o>tNm*7oy*zloFTy*}y{rZo@kff$@
o>onZyloo@yAlumXllx\Nozlom*q1tNu\offqmANxZypj1rZ\1\
o0NonZyAloo@yAlum\llx\NNozlom*qp|ff  rZH 
 |  ~1r| 	

y*zNonZyAloo@yAlum\llx\NNozlom*q

i

o>onZyloo@yAlumXllx\Nozlom*q7  7 Fr|  


mAt~}loCtNuy*tafN>F	uyAktamfft~|n^o@k1m*qMTy{~}y*rZ7o@k1tNu\oCz\oTy*}y{rZo@k  tNuy*t1aofxkt1}7z|tNmXZxlo@
y*z.tNu\o>tNm*7oy{zlo>Ty*~}y*rZ7o@ka$zmAZoatNmo;}7}7zy*tNoFtNu\oZon^ozZozlomAz

tu\oCy*tNto@Zoffm*qtNoz

lmAzk}ZofftNu\offqmANxZypfN>p\
 fqmAk~mpotm*7oy*zloo@ltNmApM
 


M7@MMM

Ao@ltNmk}7z


}7Aozy.qmANxZy.m*Ao>tNu\oTy*}y{rZo@k*j@@NF7otA~ MMr^optNu\opk~ot>m*q



  i 
{kNy*t}kq}7z\pimAN yT7A}q>  @j@~  H



 5\@

tNu\ozQ|j@j@NAsA~ Mi}H  
M7@MM7f

ZCu\oo}kffyTyTxy{t~}7mAzOk~xlutuy*tCp   

au\oA5\Q	ff
.fi>
M
 MZoz\mAto@  ;>i}kZoz\o@tm

  
r^optNu\o

l7m|k~x\NoFm*qaA fN>\
 
qF>}kFz\mAt>}7zHly*z\mAzZ}lyjaqmANao
No@k~n^o@lt~}7Ao7ACu\oNo

>
 

Zoz\of>y{z  ;>ffstNm0ro

}katu\o>qmANxZyF}7zOly*z\mAzZ}lyjfqmANo@vxZ}7Tyj7ozZt>tNm>mr\tyj}7z\o@0r|tNu\o

n\Nm\lo@Zx\Noy{n\no@y*~}7z\.}7ztNu\o>n\NmZm*q1m*qsau\omANo

i \

!#"%$'&)(JP+* ot!,ro-	*.-0/$|\a}7tNutu\oy*tNmA

>
au\oly*z\mzZ}lyT	qmANxZy

>
 

7 8-  #9

k1o\no@ltNo@ >
 

kmAZoNo@yAk}z21fy*pnZ7oi43\65mAzk}Zo

;:-  <9=- / >: @? 

o@vxZ}7Tyj7ozZt>tNm>}kBA

 |!C*<9
H

f>
 >y*z  >
 

lmAzk~tyj}7zk1r^mAtNuw7

 |ff!D*#9

^7

C 7 >y*zO

k~oo>tNuy{t7ff~7 }oA7Zj1}k>y{n\n\Nmj|}7
   ;> KJ j@j@N D s

 7 FE

FGH

D  (}( oA7A C

y*z D 	tNm>r^o\fwoffyjk~m

y*to^sy*tCpmZk~t>IT\1au\oNoqmANoA
D

A8G

IT  IT\ C

 Dff

L>

MON;P#QRTSUBU0VXWSTVYVXWQ[Z\4].^_`baYcedfS8gXQVihkjml npoRqc.rsgt4gXVXg!cTdfSuUBU0v8wVXxyU4QgYVXWzSeV{Se|XQVXWsQ!UBt4}~t4VcedfS8gXQxsQrsRQ8cTd
v8wVXxyU4Qgpt4rh@N
ON;0c.VXQ6VXWzSeV)WsQ|XQ6%QiST|XQ6.t4Q%t4r[)'Seg0S~d+c.|X}ixOUS~t4rF<xsrsQ|0VXWQ6VX|STrgUSTVt4c.r@sQzrQFQuSe|UBt4Q|%Q)scVXWOt4g
VXWs|Xc.xs.Wsc.xsV6VXWQ6yzSeyzQ|)%t4VXWsc.xsVpd+xs|XVXWQq|pRqc.}Y}YQqrVN

z

fii<<8i)

#+<p;ss#<%#2;%#
+T	T2Y	2

#Y	TeT;e.[T+<sse;ff#e~

T8Xff	.+	=fT[+Tb+T	Y)+


{#+s##Xp8

+	2[Y	u

KYF.;qi=



e

>BOqe +B8qff+ sTz+ F%ff+ 
TT[+s86T[T;	Tu ;e8 TTeTs=	


	

e

	TeTs

Y+T

fiff 
	



.;T






 

T;Fq





@TT;T[s.T	6



{=.{

%ssseT;ffTTYTT	F#
 Te;6	6T;



T;@T@TT	{6 %T;

<ssTe;F





O% {6

)Y{T	6TF[TYTT	

	T		ue	~+;T	~#zY	i

'	.%TTe=	T@Y	8sF+ff

{+	

TT8T;e
Te	T;

fi  ff !
 	#"$	%

	#f'&	s(*),+,-Y;	  s
+s[seuz+T.	T[YT
.   
;/; ;s!	Y+eTsY+2TF0.+@21XeT	;+q.~4367
5 8:9<;>=


5
7
L
?	=A@CB 
 EDGF IH:JK
8 @ =  9<; 	ee@;=[Y	u= qNM PO
;eT; q,Q   
   +RDGF IH:JK L 57 8  =  9<; 
9<; ; ;TT;FqFA@>%X	
TTGD2F SHTJUK 7L 5 8NV X
 W =  9<; 
{.	ffu2D2F SH:JK L 57 8   =  9<; i!s.sTTu+E
M T+sTF 
>Y
.		ffY
 eF+++s86(Z[O
zY		 6TT@T[ .8	TeTsY+TE
]\
zY[s+eFT.+@_
^ +T	..T.+;q TTe	b;.+	#
Y

+		T= TT[+ff

.+	Ts.+.



` #X;badc ff  ffffSe KS	KSf ffg[h  	 %Ubi j Olkmj O " 
Jfi	 F nKS	 	oHpqK%	r ff  ,Hs
Ufto",H
gh  	oK'u wvj Oxkxj y K hz c 	 c "$	{ g U <
   {6 gtDGF IH:JK L 57 8  =  <
  {
9 ; }|~ "U
J 
9 ; 
	c ff 
L4
L4
[5  D2F  SH:JK L 57 8  =  9<;   i wOv<O 
I5  
 i O
Z u O
T
Y

i.	ffu	+!b +~XT	eF+

	T.+@++	T=Y		TeTs

T;YT+s8uFTe	
Y+T

T

T;

e s

.

s +@;	

uTT	beT

0.
Y!sT +=T.	;.Tff+	=		
]

 ,( ( @	.e;  ++s	Tez
@X  Y+++.

2
TFz  s


XT	 +



'pXz;q

%'

GA V W; 9<;

;




TTT	T









;

 V


P



 

*(2

C 

	.	. @TT8;+{eFT=T.	eTs;;
;6e;e++	

   ;uTffTs

 	 hzff[;	

  


 

	ff.	;	



 Y

 

 (Wi

?	AOY;T++	T2{@+ L
? 	~

. +	e	.@+p
? +	T'F
( 

;+>
  Z[
O wO2 Z[O 
8


E  q    T[8 eq T	.+	
s
Te=TA
 .+.TX  Y
 ;.	~T=@ ;eY	 
 L  L>

    L  ?p+	T-uz8YTt^; +ff+	@;s+	8iTYX;.+	X	YT	z+s8


[ 
O
! s	TFT@	T	u8.	;.Tffu T;fifi
  s[s



Y{[.	Tes;	;+2T



fi6zz*,,zd*0,

#worlds4

||P(x)|| x



0

0.25

0.5

0.75

1

X,zn,ww,fi]P',S,$NzG2

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

X,zt],S[w,fizzSz,GSz,fio,6,wzUS}
 SU*#wREz,,w0z*#NzPbz*,z,ww:Nzpzz*z

Rw,d>6,#S[Gnz,,w0<Uzz0RNnI2
fi zt
 ,<0oS 
wzw#Nzwzn%,>zzSq$,w0S!tSU*#wR ',>    
 
	  ff 	
   ff 	
  

6**>2 
 z'S,RSz<$SzS[0 S,#tww*4%$ z'#<4,#N
 	  
:zp>zz0RUw,2E0,,$]60,  2,<Sod*wwR>6$z>Nz<z 
!S2n
 z,ztzS$Td:



fi"!"#%$
&(')$"*"+,#%-"!"#/.0"1"23&4"&657!"8"*9$
:<;

=?>A@CB<DEF>HGJIKffL">M>ON9PQGSR">CRTKFU3BVWX>CP>CRWX>CR@O>YGSR[Z\K]U_^>AEKL">`>CRXKffaffGSPXbScdKffL">MRTD"^MeQ>CafG<IghGSa]ViW"E
BSEffEFG9@UiB<Kff>AWjghU_KffLkPQG<U_RTKOElG<ImLXU_nSLo>CRXKffaffGSPXb)E]gB<^PpBVqVGSKffL">CalgGra]ViW"E0BSEsZtnSaffG<guEvViB<affnS>SwyxzLXU3E
@OGSR@O>CRXKffaB<KFU{GrR|P"L">CR"GS^s>CR"GSR}c~gh>OVV{XR"G<gR/U_R)KffL">s>OV3W/GJImE]KB<KFU3EFK]Ui@CB,VP"LXb9EU3@CEc7IGraff^0EKffL">leBSEUiE
IGSaGSD"al^0B,U_Roaff>AE]DXV_KsU{RoKffLXUiElE]>A@OK]U_GSR}wKYBSEffE]>CaffKOEKffLBJKMU_KUiElPGXEffEU_eXV_>KffG|@OGS^sP"D"Kff>WX>CnSa>C>AEG<I
e>OVU_>OIBS@C@OGSaWrU_R"nMKffG`aOB<RWXGS^ghGSaFV3W"EgLXUV_>U{nrR"GSa]U_R"nB,VV%e"D"KKL"GTE]>ghGSa]ViW"EgL"GTE]>>CRTKaffGSPXbfUiE?R">AB<a
^0B,NXU_^MD"^wxhL">fR">ON"KuKL">CGSaff>C^>AEffE]>CRXK]UiB,VV_bYIGSaff^0B,VU_C>AEKffLXUiEhP"L">CR"GS^>CR"GSR}w
MdX%,}X}<fSOOkCC%S~d  T?CSqJ~i"if"},`Xh9Jidu~
<ffOSCC%ffOi/" fu <d,h Y<O"C)CAO<d<iQi"Mj}T0C<0ri
M? <d< VU_^Y [ VU{^oE]D"PFVU{^jU_RXI T<
<CqJ        fM
<C<       f`

>aff>C^0BJafffKffLB<K}KLXU3EUiE~rDXU_Kff>BuWrU@ODXV_KKL">CGSaff>C^w>hLBAr>WrUiEff@ODEffE]>AWgLTb`>C^^0B"w_SV_>CKE
DEV_GTGrHB<K ArA] f gL"GXE]>>CRXKffaffGSPXbfUiE  R">ABJa  ^0B,NXU_^HD"^w=?D"K~KffL">hKffL">CGSaff>C^6K>OVqViEDE7KffGV_GTGS
B<KKL">f^0B,NXU{^MD"^>CRXKffaffGrPTblPG<U_RXKEG<I    ff c"gLXUi@L[g>`WX>OR">AWDEU_R"nYB  E]GIB<aD"R"^GSK]U_BJKff>AW 
E]bXRTKOBS@OK]Ui@fP"affG"@O>AWXD"aff>MB<P"PXVU{>AWKffG f whKuE]>C>C^0Eaff>ABSEFGSRB<eXV_>`KffGs>ON9PQ>A@OKfKffLB<K 9 f E]L"GSDXViWKff>OVV
DE C<AS9 B<eGSD"K^G"WX>OViEG<I f wm=?D"K^0B<rU_R"nYKffLXUiEf@OGSR"R">A@OK]U_GSRP"aff>A@UiE]>Sc}BJRWYU_R[PB<affKFU3@ODXViB<a
E]L"G<ghU_R"n[L"G<gKffL">l^0B,NXU_^HD"^s>CRTKffaGSPTb[PQG<U_RTKEG<I 9 ff a>OV3BJKff>0KG^G"WX>OViE`GJI f ghU_KffL/R">AB<aff
^0B,NXU_^MD"^>CRTKffaGSPTbScQUiEWrUqY@ODXV{K,wG<gh>CS>CaAcQgh>WX>OI>CaHBVqVWX>CKOB,UV3EvG<IKL">HP"aGTG<IhG<IKLB<Kua>AE]DXV_K`KffG
KffL">`B<P"PQ>CRWrUNw
R[nS>CR">CaB,Vc}xhL">CGSa>C^"w_AM^lBAbEF>C>C^KffG0eQ>G<I~VU_^MU_Kff>AWDE]>OIDXV_R">AEffEuXR"G<ghU_R"nYKffLB<Kgh>`GSRXV_b
LB,S>[KffG/V_GTGrpB<KYghGSa]ViW"ElR">AB<aKffL">[^0B,NXU_^HD"^s>CRTKffaGSPTbPG<U_RXKWXGX>AEYR"GSKEFD"eE]KB<RXK]UiB,VV_bpa>AWXD@O>
KffL">MRXD"^HeQ>Ca`G<IhghGSa]ViW"Egh>HR">C>AWKffGY@OGSREUiWX>CaAw  RWX>C>AWdcKffL">gL"G<V_>PQG<U_RTKG<IKffL">0@OGrR@O>CRTKffaOB<K]U_GSR
P"L">CR"GS^>CR"GrRUiEKffLB<KfB,V_^GTE]KB,VVghGSa]ViW"ELB,S>fLXU_nSL[>CRTKffaGSPTbSw  >CS>CaffKffL">OV_>AEffEc}BSEhKffL">aff>AE]KG<IKffLXUiE
PB<PQ>CamE]L"G<guEcTKLXU3Ezaff>AE]DXV_Km@CBJRYe>HrDXU_Kff>`DEF>OIDXVgL">CR@OGS^MeXU_R">AWYghU_KffLKffL">IG<VV{G<ghU_R"nlK]gGMaff>AEFDXV{KOECw
xhL">?aE]K~GJI%KffL">AE]>EffB,b"E}KLB<K7UIB,VVKffL">ghGSaFV3W"E7R">ABJa~KffL">h^0B,NXU{^MD"^>CRXKffaffGrPTbfPQG<U_RTKELB,S>Bf@O>CaffKB,U_R
P"affGSPQ>CaffK]bSc"KffL">CRYgh>`E]L"GSDXViWLBAr>`WX>CnSaff>C>`GJIe>OVU_>OI`fKffLB<KhKffLXUiEP"affGSP>CaKbsUiEhKffaffD">Sw
qV U_^ ~ a f
   9 fH~ zVqU_f^  
f

 dAdi3,pS}<uri
OkCCdSd  T~CSqJ~i"iuO"}A~fTh"<%~
<ffOSCC7C%ffOQH   f  q,7)   f<9C,~J%<9M  <%,      
<<O<TS?TrqJ~<`l<CqM O"CYTS     0s}T
 a         f`~ 

 d73
	 GSafKL">TR"G<ghV_>AWXnS>leBSE]> " U_fi
R ff7NB<^PXV_>Y"w_"cQU_KvU3E>ABSEFbKGE]>C>0KLB<KfKffL">
^0B,NXU_^MD"^>CRTKaffGSPXbPG<U_RXKhUiE     w 	 UqNE]GS^s>mB<aeXU{KaB<aff
b   
w ~V_>AB<a]V_bScQKffL">Caff>UiEE]GS^>GSPQ>CR






E]>CK  B<affGSD"RWKffLXUiEPG<U_RXKHE]D@L[KffLB<KfKffL">BSEffEF>CaffK]U_GSR   _     _ Y  
C 
  L"G<ViW"EIGSa

 
>CS>CaffblghGSa]ViWsU_R  whxhL">Caff>OIGSaff>ScXgh>`@CB<R@OGSR@V_DWX>MKffLB<K
 Sa    3   _ H  
C
   O9 ~ 
 !  

" Ehgh>`E]L"G<goU_R  =hBS@C@LTDEh>CKfB,Vw_c}$ #%#'&  crIGSaff^MDXViBSE  gzU{KLWX>CnSaff>C>G<I~e>OVU_>OIv@CB<RY>AEffE]>CRXK]UiB,VV_b
e>sKffaff>AB<Kff>AW)(]DE]KVU_S>0GrKffL">CafTR"G<ghV_>AWXnS>U{R f wMxhLB<KUiECcKffL">0WX>CnSa>C>AEG<IeQ>OVqU_>OIfaff>OViB<K]U_S>KG f
B<RW f  ghUVqVhe>MUiWX>CRXK]Ui@CB,V  >CS>CRUqI f BJRW f  B<aff>MR"GSKV_GSnJU3@CBVqV_b>ArDXU_B,V_>CRXK  +
w *GSaff>
IGSaff^0B,VV_bd

,.-

fi/!0214357698;:<=%5%0>?6@BAC1D<<$5%0
EGFIH4JLK$HNMPO?QSR4TVUXWY;Z%[\[^]4_N`ba\cdZ$egfih;jklk'mnporqds9t'vw u Wxyz{bnp|}j~'L
ei\ei`_eifii4%
 dq\'G~'N!q\'G2~+!
ei  s9t v u W!yz{n9| e w  s9t v u W!yz{xln
  w
!
!
 K$JIJNUD%t[%+4eia\c^a\a``\h;;at^a\7aZ'cc]at^t^lPWY;Z%[\[]_N`Ga\cZ$egfih jk%k'mDnp]a\t^a%fYZl`[
t^%NZ4e`c[bt^aZ%`%4i`]'`c^]NZch4S%t!Z'Z'N? 
s9t  uv W!yz{pn9|s9t v u W!yxlns9t v u Wx2yz{pnst v u W!yxlnst v u W^xyz{Gn
YZ%``_+ci%?h s9t'v u Wx2yz{dnGc^a\N`
c^j!]a\acZ'%aXec`\h`fic^]aNt`cc^a\t^c^a\N`
c^
s9t'v u W!yz{fidxlnfC!c^]a%c^]a\t;]NZ'NIhs9t'v u W^xyz{Gn9]NZ%`eiGicf9Ya[\Z'_N`apst'v u W!y)x%nr`
Nl_N4aIhN;ap[%N[ei_N4aGc^]NZ'c!c]ap`a[%Nt24_N[cZ.er`+c^a\N`c^+fV;]at^a`_4ecS'ee'`f
 `9;a`]NZ$ee`a\a;ic^]aa2c;`a[ci%?h4c^]a[%G4iNZ'ci%
'9V%t'eerZt^+fij\mpZ'N);]a\%t^a\fij
`l_4ic^ap7'a\t_4egf
9
?9'g9lNN
IG!SgD
 e c]%_%]pc]aV[%N[a\ctZ'ci%b]a\%+a\%r`ica\t^a`ciNh$ic`?Z4e[\Z'cldcZ%[c^_NZ$eeip[%+_c
4a\%t^a\a`'V7aeia;Z$%c!NaG%4ll_N`\f 'iN[ad;ab'c^]NZcZ$ei+`cZ$ee;%te`;eeV]NZla]4l]
a\4c^t^%4%hNZ
lta[cZ'4e[\Z'ci%'C]a\%t^a\}fijG44a`!%c`_N`cZ'crZ.eeit^a4_N[apc^]ab_G7a\t'
;%te` ;a+G_N`c[%N`4a\tf+9a\c$hZ%` ;a+`]'ic^]4`p`a[cl?hc]a[lN[a\c^tZ'ci%c^]a\lt^a\[\Z'
S%t^c^]apNZ%`r` CZ)tZ%[c[\Z$e9c^a[]4rl_aGS%t[%+_ci4a\%t^a\a` VNaeia!i
Z'[\Zl`a`\f a
Na\%a[ci%mNfrjt^a`a\4cic^]ai4c^_4ici%N`_N4a\telic^]4` c^a[]4%_a%fg%a[ci%mNf
;aG_4e%c^]a`api4c^_4ici%N`bt^a`a\4cit^a`_4ec` S%tpZ
t^a`c^tr[ca[eZ%`^` '%td_4eZ%`  c]`a
l_a\tia`
!]4[^]Z't^a%_NZcNa\t St^a\aS%t^G_4eZ%`+'%a\tZ_NZ't^eZ'%_NZ'laCc]Z`i'eia[%N`cZc
`4GN'egf+ `4ca+'!c^]4`t^a`c^t[ci%?hZ'4';c^]aG`^`_a`GZ'tr`Xic^]a)%a\a\tZ$e[\Z%`a[\Z'7a
`a\a\]a\t^a%
f %t^a\'%a\t$hNZ%`;;ad`].%a[ci%mNfhc^]4` t^a`ct[c^a`_4eZ'l_NZ'%a` t[]a\%_%]
c^+Z$eei'_N`;c^Ga\GNaXc;baee S4.t^%7`ici%NZ$e9Z't^Z%[]a`c^]NZ'c;Z'la_N`a'Z.iG_
a\4c^t^%4 
` 	7fi ff^~ ff   
 
W  e`^`%?h!jk l4nCZNc^]a
Z$4G_
 Sa\4c^t^la2c^a\N`l
  e`^`% 

'
 g`a\
Z'cr[\`)W  a ?a\!
t
saZ'te h;jklk%4n4_a
c^"
 'e` #\r4c$$
h %t^t`\hsaZ'te!Wjklk%4nW`a\a
Z$e`
W  'e` #\G4c%
h %tt`\&h saZ'tegh9jk%k%2n^nf gfi%a[clmNfmNh7;a+[%N`4a\tp!]a\c]a\tc^]aGt^a`_4eic` S%t
c^]abt^a`c^t[c^aeZ'%_NZ'%a+[\Z'NaGac^a\N4aIf!aG`]'c^]NZ'c c^]a\[\Z'?h7_c`a\%a\tZ$e9l( '[_4ecGZ'N
`_ceiar``_a`Zt`a%f
QSR EFLH"*NH,+IH2K.-0/2143K.-53\Hfi*06
 ec]%_%]c^]atZN4%S;%te`+a\c^])`!4aNa4[%_4ci+;%te`\h;a[\Z'`%)a\ci+a`NN
+%talit^a[cG!Z$2`c^[\Z$e[_4eZ'c^a
c^]a4a\lt^a\a`';Naeiaicb%iae`\f
gfiWYZl[\[^]4_N`a\cpZ$egfihjk%k'mDn;a
t^a`a\4cZ+4_GNa\t'V`_N[]ca[^]4l_a`\hI+`c 'V!]4[]Z'4ei%4ei
i%a\t^`7a[rZ.e[\Z%`a`\f!a
'?c^]a`)4ea`cCZN++4`cic^_4ici%a `c^]a!S'eei';idla\t`i%+'?!]NZc9]4ei`%]a\t`;]NZ$%a!ca\t^+a
     q    7   9W 8;a[^]a\4NZ%[]?h!jk'm4k4nf%_N`ac^]NZ'cpZ$ee!;a+'Z'N%_c+Z'Nlil4_NZ$;

e :dr`
`%)apZ%`^`a\t^cl=
 < 9W :$?n >i%c^]a\t;;%t`hNz{]NZ%`;c^]a S%t^@
 < 9W :$n7z

{ AShZ'N
c^]ap[%N`cZ'
c :44a`
%cZNaZ't iz{ A f  e``_7`abc^]NZ'cz{+h7c^%%a\c^]a\t;ic^]ZGNZt^c[_4eZ'tc^'eia\tZ'N[a  hi+4eia`
c^]NZ'
c B\9W Cny < 9W CIn BDG`i`%+ai4c^a\t^'Z$
e EGF H%Igf;cp`a\a\`t^aZ%`lNZ'4eiadcZ't%_apc^]NZJ
c :r``]%_4e
NaGc^taZ'c^aZl`L
Z Kc44[\Z$Ne M+aeia\+a\4cd`^Zc`liO
 < 9W CInhDNa[\Z'_N`aG4Z%``_+ci%z{ [%4cZ$iN` 
)

PRQ

fiS$T5U5V&WYX[Z\W5]5^.V&_`T5U5Vba=T5c5deX$f5XhgiU5j5]kWYlm

nofiprqtsu=vwnqoLxy5ztz{Rxwno5zOqw|5{4s~}2nNx{|5{4s{prqts{}2{unz|fiw
|5q0{wqOy0x{w|5{xw?vwnNxwne4x
tns{Rw
vo0qo0~y0fi{
w|0vw2s
 99.4

$LG% 2|finNxnNxno0fi{4{ROw|5{`4vx{5vxw~|5{pqq}no5zw|5{4qts{4u
x|5q}x4
 5

N
7fi&.0%fi 9 v4~|y0x{4wve&. .
~
.&R!~4
Jfi$4h.7
7=,47?r&?&
R?  

  %   ? `  ?

L$%


s 

 kNb
    `  
 &?04&

9R
 
JG% 

t9!.G
4.N4!N 

|finexs{RxyfiwRYnoLqufino0vwnqo}2nw|w|5{!s~{Rxyfiw?xqpw|5{5s{4tnqty0x
x{Rwnqo,5sqnNfi{Rxy0x}2nw|"v
{4s0q}2{4spyfiwqq2qy5z|fix,{Rvno5z0,}2{
5sq,qx{
wqy0x{
w|5{`prq(q}2no5zOxws?vw~{4z&2|5{
0vtxnN
qo0{4ofiws?vwnqtoL5|5{4o5qu{4o5qox~vR5x`w|0vwuqxw
}2qse5xvs~{{4sLxnunNvsnov{4sw?v.no\x{4o0x{O
x
x|5q}ono$qsq(Nvs~=54,}{`4vo=y0x{w|finNxwq
0o0xqu{`vxx{4swnqto0x$w~|0vw$vs{v.uqxw2{4sw?v.nofik
wsy5{  n{eR}2nw|fi{4zs~{4{qp00{n{p  {4{4on(p7w|5{4vs{$o5qwqznN4v.nufin{Rfi




|5{4qs{4uh5R

w|5{4ow{NxOy0xw|0vw=}2{L4vows{Rvww|5{Rx{"o5{4}vx~x{4swnqo0xOvxnpw|5{4vs{nopvw=fio5q}o}2nw|
{4sw?vnofiwi|5{4ow|5{Rx{o5{4}vxx{4swnqto0xxw?vw{xwvwnNxwnN4v.fio5q}2{Rfiz{R5tw|5{44vovxwno0s{Rvx{
qy5sqt50qsw~y5ofinwn{Rxwq=v5fitns{Rwnofipr{4s~{4o0{2|5{;prq(q}2no5z{Yvufi{;n(y0xw~s?vw{Rxw|finNx2nNfi{Rv5

 
	eififf%

qo0xnNfi{4svO{4sLxnufi{Ofio5q}2{Rfiz{=0vtx{=q{4s!v

q54v5yfiNvs

qofiw?v.nofino5z"w|5{

xno5z{y5o0vs5s{RtnN4vw{


2|5{4s{!vs{w}2qvwqux
w|finNx 


e 


  ?
  ?


vo0q{4s=fi}2nw|





  nex`~{Rvs

zn{4o

# 

7

 %$




&$  $'

hvo0  "! $2|5{!xqy5wnqox0v{
qp


$


xwsv.nz|wprqs~}vs?qu5y5wvwnqo!x|5q}x7w~|0vwRprqs 
*
0qnofiw 1     
 )   3 24   



 )



(

   

,+ 4w~|finex|0vxvy5ofin.-ty5{2u=v/finuy5u0{4ows~q


 

5 q}!0qo0x9nefi{4s
w~|5{-ty5{4s 9.  65qsv(798

Y{4w;:  7  ,{w~|5{
pqsuyfiNv     ? \  )



<

4






7


)
=
)
7

2

fi
|
N
n
=
x

x

v

w
N
n

x
0

R
{

x
~
w
5
|

{



q
0
o
t

nwnqoqp$qsq(Nvs~540xqLnwprq(q}xw|0vw
 
 

  :  7 9
$  ?> xno5z |5{4qs{4u5eR5fi}2{fio5q} w|0vw2pqsnuA@  4nu nofip  nuxy5B
s 
nu  @ s 
C

CD

 

nu  @ s   
C

9.4

$

9.(


CD

:  7 

 y5w2o5q}}2{
4vo=y0x{!tns~{Rw2nofipr{4s{4o0{  5qw{`w|0vw|5{4s{5qy5s!fio5q}2{Rfiz{Rv0qy5w  nNx2vy5qty0x4
n{% ?549. 5  

{qo0~y0fi{w|0vwRtnpw|5{4s{
nNxvonunw!vwv(,w|5{4oo5{R{Rx~xvsn
  
s 

F q0fipqsv.G7 8


9.4


:  7 L

 )



  
4

7 4


 )

   )E7 


s  

 

9.

$





 )

  H4

7 4


 )

   )I7 

F no0{
w|finNxinNxwsy5{2pqs2v.J74fiw|5{qtofi0qxx9nfi{
v.y5{pqss    9.(

 nNx  K)  }|finN~|nNxw|5{


 n{e      Jt w|5{u=v/finuy5uL0 {4ofiwsqt0qnofiwR5qw{w|0vwnwnNx
v.NxqO~{Rvs
}|0vw


 5
|0v5,{4o0xvx   w{4o05xw~q  $s    .

 nNx


vy5{qp $

MON

fiPQSRUT?VXWZY[?\^]OVOQ?_W
`bacRd\^\/VOQ

ecfUg.hBijlknmLoUpqi<rUismLtvulhxwzy{knw&i^hlw&f?im|k/gqu}hxwzisolh~tn?tOu?iolthzhgUpqihxwzyknwzisOtOyHtvmLo??wxgqu?rUisvyzisi^h
tnlXipgqizBgqy{hxw
wzf?im|k/jUgqm?misuwzy&tOo9oXtngquwhtnlw&f?icholkOiS
 399 kny&i<tOmLo??w&i^rkvhHkc?ulwgtvu
  99 kOhzhx?mgu?wzf?ip3gmgwijghxwh  g3<u?tvw^~wzf?i
tnL  ;ef?isuw&f?i^hxiLknyzi}lhxi^rwzttOmLo??w&i|Zy 
p3gqmhx?oknulrp3gqmIgquU9tnKKyz  9; kny&i;tOmLo??wzi^rAgulhwzi^kOr  Bgqulk/p3pqO~i;tOmLo??wzi9w&f?i9p3gqm}gqwtn
wzfUgho?yztOlknUg3p3gqwkvhL  OtUi^hwztLsisyztX
uUtOyzwz?ulknw&ipOnw&fUg.hZhwzy{knwzisv9flkOhHk9hisyxgqtOlh
oltOw&isuwxgk/p?o?yztOUpqismKi<&pqi^knyxpqLsknu?u?tOwtvmLo??wzi
Zy   x 9; hxisolkny{knw&iptOyi^kvzfLtJw&f?igquUluUgqwzipq|mknu}wztpisyknulivi^wztOy{h  knulrwzf?isuLw{knviwzf?i
p3gqm}gqw;kOh  vti^hwzt|?im}gqOfw f?tOoXi;wzt|tvmLo??wzi;w&fUg.h o?y&tOlknUg3p3gwxkOhknuijSoUp3g&gqw9?ulwxgqtOutn
  ~knulrwzf?isutOmLo??wzi}wzf?ip3gmgw/?tvygqulhxw{kuliO?gqu
jlknmLoUpqi}l,LKy      99 kOhtO?ulrwzt
li?, ^ Zknulrhtgqwg.hi^kOhw&thxisiflknwflkno?olisulh}kOh ^
dA?w}wzf?isyzig.hu?tyzi^kOhtOuwzt
lip3gqisOiLw&flknwKy    99 ghsXgquvisu?isy{k/p%kui^kOhg3pqzflky{kOwzisyxgq^knUpqi?ulwxgqtOutn;  gwgh u?tOw^
wzf?isuEtvmLo??wxgqu?wzf?i}p3gqm}gqw|kOh  OtUi^h9w&tsknuXiArvg3AUpqwLtvy gmolthzhgUpqiOiLtOUprp3gqOiwzt
lulrkk^}wzt}k/OtngrLw&fUg.hcijSoUp3g&gqwp3gqm}gqwxgqu?|o?y&tSi^hzhk/pqwztOOiswzf?isy/Hwwz?yzulhtO?wwzflknwwzfUghghZgqulrUisi^r
oltUhzhgqUpqigquhxtOmLi&gqy{?m|hxwknuli^hsef?im|kguyzi^OUgqyzismisuwKg.hKwzflknwZwzf?im|k/jUgm}?mLisuUwzyztvooltngquUw{h
tn  399 tOuvisyzOiw&twzf?im|kjgqm}?mLisuUwzyztOoU;oXtngquw{h
t   399   dtOyB?wz?y&i<y&iisyzisuliOnu?tvwxgi
9 
wzflknw   39 gh;w&f?iA&pqthx?y&i|tnwzf?ihxtnpq?wxgqtOuIhxolkOitnwzf?i|tvulhxwzy{k/gquUw{h9tv?w{k/gqu?i^ryztOm
yzisoUpkO&gqu?k/p3pZtSs?yzy&isuli^h tn<kulrk/p3pZtSs?yzy&isuli^h tn9  umknuhxl&fskOhi^hs
isknutOmo??wziKy   9; rvgqyzi^wxpqgquw&isyzm|htnw&f?imk/jgqm}?mLisuUwzyztOoUoltguUw{htn   9 
gqwzf?tO?ww{knvgu?pgqm}gqw{h9kwckpp%
 h wzf?i}tnp3pqtngqu?ijlknmLoUpqi|hf?t s
h ~wzfUghwUoli}tntOuUwxgquUUgwxrUtUi^h9u?tOw9f?tnprgquOisu?isy{k/p%wzf?i
m|k/jUgqm}?mLisuw&yztOoU|oXtngquw{hctn<  39  rUtLu?tOwu?i^i^hzhzknyxg3pqtvuOisy&Oiw&tLwzf?thxi9t<   39  
~
.
q~9tvulhgrUisywzf?i;Uu?tnpqi^rUOi9lkOhxi
9


.  q    ?,

q  q  ? ~

q  . |
  ?

%wgh9i^kOhxwzthxisiLw&flknw}   39 ghxlhxw}  ??{? z ;ef?iLoXtngquw  ?l?,  gh;rvghzkppqtni^rUwzf?i
   
hxi^tOulrtOunx?ulw^tn;
tOulhgrUisy  39 tOy
  U

  
wzf?isu  9 gqulrUisi^rIrUtUi^h
u?tOwtvuw{kguoltngquUw{hf?isyzi9  ghu?i^kny ?lUwzf?im|k/jUgm}?mLisuUwzyztvooltngquUwtGwzfUgh hxolkOig.hi^kOhg3pq
hxisisuw&tli?,   tnisOisy^Xg3    Lwzf?isuwzf?isy&iLg3p3pcXiLoltguUw{hgu  39 f?isyziL  g.h
knyztv?ulrE?lBtOygqulhxw{kuliOZwzf?thxif?isyzi?}     ?}   ngquliwzf?i^hxioltguUw{hflk/Oi
kfUgqOf?isy}isuwzy&tOowzflknuwzf?i|oXtngquwh9gquIwzf?ivg.&gquUgqwxItn?,?
wzf?itOyzmLisyg3pp9rUtOm}gqulknwziOefUlhs
wzf?ihxisw;tm|k/jUgqm?misuwzy&tOooXtngquw{htn9  399 rUtUi^hu?tOwtvuOisy&Oi|w&tkhgu?piip3pq%rUilu?i^r
 ecfUg.h u?tvultOuvisyzOisuli
hxisw^flknwcgw9tOuUOisyzOi^hwzt  g<kuUwzfUgqu?  rUisolisulr?h9tvuf?tn  vti^hwzt ?
flkOhtvulhxi^O?isuli^htOyrUisvyzisi^htGXipgqiz%wghu?tOwflkny{rwzt|hf?tZy      99 skuli;igqwzf?isy
?,c   tOy?  /SrUisoXisulrvgqu?tOu|w&f?i9o?yzi^&ghxi9yzipknwxgqtOulhxfUgqoliswxisisu     n?knulr  O
%wtnp3pqtnh
wzflknwKy     99 rUtUi^hu?tOwijUghxw^
  9  tOyZtn
 ih&k^wzflknwk9rUisOy&isitn~lip3gqiKKy   99 g.hKu?tOwzUs
g3Jw&f?ilisflk/vgtvytnZy 

 rUisolisulr?htOu	 Oti^hwzt ?
 
u
p3gqmIgquUHZy   x  knulrpgqmhx?oKy    z kOh  vti^hwzt }

tOwzf?isy tOyxpr?hs~u?tOu?y&tO?lhxwzu?i^hzh rUi^hzyxgqXi^hhgw&lknwxgqtOulh f?isuZy  x 9; rUti^h u?tvwijUghxw9li^sknlhi
tnhxisulhgqwxgqvgwxwzt}wzf?i9ijlkOw&f?tngi;tHwztnpqisy{knuli^h Zi;hxflk/p3pGhisiku?m}Xisytn
tOwzf?isyijlknmLoUpqi^htn
u?tOu?yztv?lhxwzu?i^hzhgqup.kwzisyhi^wxgqtOulhs
wZm}gqOfUw<hxisismbwzflknwZwzf?iu?tvwxgqtOuLtnyztO?lhwzu?i^hzhBghknuLknyzwxg3%kOwtn~tO?y<ko?o?yztkO&fu|olkny&wxgUp.ky^
gqwGhisism|hw&trUisoXisulr;tvu;wzf?iK kOw
wzflknwBtO?ypknu?vlknOiflkvhwzf?iijSo?y&i^hzhgqOioltnisywzt9hzk/w&flknwwzf?iwt
wztnpqisy{kuli^h
yziso?yzi^hxisuUwGk9rvffg 
isyzisuUwGrUisvyzisitnkno?o?yzt/jUgmknwxgqtOuOhgqmLoUpq}9lhgu?;rvffg 
isyzisuUwhx?lhzyxgqo?w{h
fi

fi

"!#$%&')(*+,-	.

/1032546870:9:;=<?>1@A3ACBED	FHGJI=A	KL7NMO<PD	<#D	GGQ1RJDTS1@U>1RVQ1A8GQWA6XA8<Y>Z;[<\HD	GGQWRBJ;=F#D	>1A
<RT>cF#D	dTA5>1@A6XA

A]_^EDIff;[>X`H>W@ED	>baJRJA6

a_;&6Z>X;=<ESC>X;=RT<E68ef5A3D	QWAbghRT^<EaU>1RV\TA8>i>W@A3D	<E6Xf5A8Qbjkmln;=<H>1@A:ACBED	FHGJI=AoD	gER	4TATeJ6p;=<ESCA

>1@A8<q=qrs/utvKLq=q w:
x0
9yjkzyQ1AD{I|I=`"f5RT^JI}a"gEAP>1@A?<A8\YD	>X;=RT<"R	~q&qrs/utvKLq=q w032?jkzE7APf5RT^JI}aDQ1\T^A
>1@ED	>

>1@AD	<E6Xf5A8Qjkmls;}6

a_;ffA8Q1A8<Y>

;=<E6X>CD	<ESCA6

<RT>oDT6:QWADT6XRT<ED	gJI=ADT65;=>oF;=\T@J>oD	>:EQC6X>6ZA8A8Fy7oT^GGhRY6XAHRT<AsR	~>1@As>uf5R

R	~bjkzU;=<>1@AGQ1A84T;=RT^E6

ACBED	FHGJI=A@EDTagEA8A8<"6pIff;[\_@Y>XI=`a_;ffA8Q1A8<Y>h~RTQnACBD	FUGJI[ATe

6X^GGhRY6XA?fbAU@EDTa^E6ZAajklTTUQLD	>1@A8Qs>1@ED	<jkzP;=<>W@AEQL6X>sR	~:>1@A8Fy7PMp<>1@J;}6S8DT6XATe*>1@A#6XASCR_<Ea
SCRT<	X^<ESC>*;}6iA616XA8<J>X;}DIffI=`H4{D_SC^RT^E68eTD	<EaHS8D<ghAc;[\_<RTQ1Aav75@A5F#D{BY;=F^FHA8<J>1Q1RTGJ`VGhR	;=<Y>*;=<P{
 ffo



;}6*<R	fjkmlTTeD	<Easf5A;=<EaJA8AaHaJA8QZ;[4_A3D3aJA8\_Q1A8A5R	~ghACI|;=AC~R	~jkmlTTb;[<?rs/uKL7@Y^E68eTDQ1gJ;=>1QLD	QX;ffI=`6ZF#DIffI
SW@ED	<\TA6>1R:>1@Ac<Y^FgEA8QC6v;=<>1@AR_QX;=\	;=<EDI,dJ<R	f5I=AaJ\TAgED_6XAbS8D	<S8D	^E6XAcI}D	Q1\TASW@ED	<\TA6;=<RT^QaJA8\_Q1A8A6
R	~ghACIff;[AC~175^>5>1@A6ZA3<J^FgEA8QL6:DQ1AD{I[FURY6X>bD{I[f:D`6i>1@AoQ1A6Z^JI[>5R	~iD	GGQ1RBY;=F#D>1A:RTgE6XA8QW4{D	>X;=RT<E6>1@J;}6
;}6cQ1ACEASC>1Aa?gJ`HRT^Q:aJASW;}6p;=RT<P>1R^E6XAoD	GGQ1RBY;=F#D>1A3A]_^EDIff;=>X`HQLD	>1@A8Q5>1@ED<#A]_^EDIff;=>u`Uf:@A8<PQ1AC~A8Q1QX;=<\
>1RH>W@A8Fy7iMO>

aJRYA65<R_>36XA8A8FQ1ADT6XRT<EDgJI[Ao>WRHgEDT6XAVDTSC>Z;[R_<E65RT<DaJA8\TQWA8AVR	~igEACIff;=AC~b>1@ED>3S8D	<ySW@ED	<\TA

6XRaJQLDT6X>X;}S8DIffI=`;[<>W@AH~ODTSCAHR	~o6XF#DIffISW@ED	<\TA6;=<>1@AHFUADT6X^Q1A8FHA8<J>R	~3aD	>LD7:RT>WAH>1@ED	>e;ff~3f5A
dJ<R{f>1@ED	>s>1@A#>Xf5R?;=<E6X>LD	<ESCA6R	~3jkzaJRhe;=<"~ODTSC>e*aJA8<RT>1A?ACBDTSC>ZI[`">1@A#6WD	FHA?<Y^FgEA8Qef5APS8D	<
Q1A8GQ1A6ZA8<Y>5>1@J;}6cgY`U^E6p;=<\H>1@A361DFHADGGQ1RBY;=F#D	>WA:A]T^ED{I|;=>X`PSCRT<<ASC>X;=4TA

;=<PgERT>W@a_;}6X^<ESC>L687iMp<P>1@J;}6

S8DT6XATe,;[>;&6nADT6X`?>1R#6ZA8Ao>1@ED	>:f5AoaJR#\TA8>5>1@AD	<E6Xf5A8Q:jkml7


SWI=RY6XA

I=RJRTd#D	>c>1@A

ACBD	FUGJI[AV6Z@R{f

6i>1@ED	>c>1@A

<RT<Q1RTg^E6X>W<A6165D	QX;}6XA6cgEAS8D	^E6ZAoR	~>1@A3<A8\JD	>1Aa

GQ1RTGhRTQ1>X;=RT<"ACBGQ1A616p;=RT<q=qrs/utKLq=q w":
x0
9jkzE7?MO<EaJA8Aaveif5A#S8D	<6X@R	f>W@ED	>o;ff~3f5A#6X>CD	Q1>of5;=>1@D
;=<S8D	<RT<J;}S8DIi~RTQ1F>1@ED	>VaJRJA6

<RT>VSCRT<J>LD;=<<A8\YD	>WAayGQWRTGERTQW>X;=RT<ACB,GQ1A6W6p;=RT<E6o>1@A8<eh;=<D?GQWASW;&6ZA

6XA8<E6XATe5>W@Ay6XA8>HR	~oF#DBJ;=F^FUA8<Y>1QWRTGY`"GER;[<J>L6UR	~V
F#DBJ;=F^FHA8<Y>WQ1RTGJ`PGER	;=<J>L6

o

R	~:

  ffo

 7




[o3

<D	Q1\_^FHA8<Y>

<ASCA616WD	QX;ffI=`SCRT<Y4_A8Q1\TA6>1R>1@Ay6XA8>HR	~

S8D	<gEAF#DTaJA>1@ED	>nfbAH6X@R_^JI&aACIff;=F;=<ED	>1A

<A8\YD	>WAaGQWRTGERTQW>X;=RT<ACBGQ1A616p;=RT<E6~Q1R_F>1@AI}D	<\T^ED\TADI=>1RT\_A8>1@A8Q7)Mp>P;}6PRT<A>1@J;=<\>1RDQ1\T^A
>1@ED	>

6XRTFHA8>X;=FHA6nf5Ao@ED4TAV6X>LD	>Z;&6Z>X;}S8DI4{D{I[^A6

f:D	<J>o>1RyF#DdTAsI[R_\	;}S8DI3DT616XA8Q1>Z;[R_<E6
>1R>1@J;=<dR	~3S8DT6ZA6

fn@RY6XAVDTS8SC^QLD_SC`PfbAVDQ1AV^<E6X^QWAD	ghRT^>eE6XRU>1@ED	>:f5A

I=A6166X>1QX;=<\TA8<J>V>W@ED	<ACBEDTSC>V<J^FHA8QX;}S8DI5A]T^EDIff;=>X`T7PMO>;}6V@EDQLaJA8Q

;=<f:@J;}S1@>W@AHRTGGERJ6p;=>1A?;}6V>WQ1^ATeiD	<EaD{I|I5f5A#dJ<R	f);}6s>1@ED	>6ZRTFHAP6X>LD	>X;}6X>Z;&S;&6

 <RT>?A84TA8<D	GGQ1RBJ;=F#D	>1ACI=`A]_^EDIo>1R6ZRTFHAy4	DI=^AT7nR{f5A84TA8Qef5AaJR<R_>#ACIff;=F;=<ED	>1A<A8\JD	>1Aa
GQ1RTGhRTQ1>X;=RT<ACB,GQWA616p;=RT<E6~Q1R_F>1@API}D	<\_^ED	\TATe:6p;=<ESCAf5;=>1@RT^>?>1@A8FfbAPf5RT^JI}a<RT>#ghAD	gJI=A>1R
GQ1R	4TAHD	<D	<EDI=RT\_^A>WRy5@A8RTQ1A8Fl77/u5@A8`D	QX;}6XAf:@A8<f5A>1Q1`>1RUD	>1>1A8<<A6X>1AaGQ1RTGER_Q1>X;=RT<
ACBGQ1A616p;=RT<E68eh~RTQ

ACBDFHGJI=AT7ffKPMO<E6X>1AD_aveEf5AV@ED4TA;}aJA8<Y>X;ffEAa"DHf5AD	d_A8Q3SCRT<Ea_;=>X;=RT<>1@ED>5;}6o6X^JSW;=A8<Y>

>1RoGQ1A84_A8<Y>cGQ1RTgJI=A8F#656X^ESW@#DT6i>W@ED	>6XA8A8<U;[<P*BED	FHGJI=A:zh7ml7cCT,	CH6p;=FHGJI=`H>1A6X>L6N>1@ED	>
<A8\YD	>Z;[R_<E6:D	Q1Ao<RT>;[<J>1A8QLD_SC>X;=<\#f5;=>1@P>W@AoF#DBJ;[F^FHA8<J>1Q1R_GY`PSCRTFHG^>LD>X;=RT<?;=<D@ED	QWF~^JI*fD`T7
A8>*i/ oj   KvgEAn>1@A5Q1A6X^JI=>R	~vQ1A8GJI}DTSW;=<\VADTSW@#6X>WQX;}SC>*;[<A]_^EDIff;=>X`;=<#*/ oj   K

?_b=&ffE5

f5;=>1@;=>L6of5AD	dTA8<Aa4TA8QL6p;=RT<7PRTQ1A~RTQ1F?DIffI[`Te*f5AHQ1A8GJI}DTSCA?ADTSW@6X^gJ~RTQ1F^JI}DR	~b>1@AU~RTQ1Fj
f5;=>1@ojevD	<EaAD_S1@6X^gJ~RTQ1F^JI}DHR~b>1@As~RTQ1FjHf;[>W@oj7/u5AS8D{I|I>W@ED	>3>W@A6XAHD	Q1A>1@A
RT<JI=`SCRT<E6X>1QCD;=<Y>L6nGERJ616p;=gJI=AH;=<*/ o j   KLe6p;=<ESCA#DIffI>1R	I=A8QLD<ESCAH4{D	QZ;&DgJI[A683D	Q1AHDT6W6p;=\T<Aaj7ffK


 
v

ffo



gEA

vT  


/ o j   K  eJf:@A8Q1AsfbAo^E6ZA

;}6yL88v_}H	C{;ff~V>1@Ay6XA8>L6?

 

ffo

>1R#aJA8<R_>1Ao>1@ASWI=RY6Z^Q1AoR	~i7*AV6WD`?>1@ED	>




D	<Ea



A8>

o

ffo3

@ED4TA?>1@A61D	FHA?F#DBJ;=F^FUA8<Y>1QWRTGY`

o

~Q1RTFBDFHGJI=AVzE7ml7b5@AVSCR_<E6X>1QLD;=<J>

GER;[<J>L687

nv*&*

RT<E6p;}aJA8QoD	\YD;=<y>W@AodY<R	f5I=AaJ\TAsgEDT6XA

~RTQ1F^JI}DH*/ oj   K*;}6o/XD~>WA8Q6u;[FUGJI|;ffS8D	>Z;[R_<vKL

/Onjkl:Hv

MO>C6

 f5AD	dTA8<Aa4_A8QL6p;=RT<?;}63

/O





jkzKvP/O

jkz3?

jkzKLk

/ o j   KL

jkl:H



jkzKvP/O





jkz3?



jkzKL

fi  
	fiff 

:,Jh

TT





T

!"$#%&')(*+*-,/.10/24357698/.:0;2<35>=@?A#@)BCEF&D G!HJILK 2NM$OP.:0'Q-.1R)SUTWV R X
. 0ZY 3576[\)-$]C_^ F D G`HJIJK 2aC F D G`HJIbK@c M$Od35>=@Qe357fSg[h?ji!(@eU*\*gk,+l@meJ@'%mn$`op)-)(*
q'rq]#q\st)(h*-,mllu,(h*vwB*-Jx(,&y!nz$|{@mg HJI }(,m*-g)(*g'`!~l@,hd!*!%$m?
 *-Jt,`,(z-#!*Jg,)B-)(h*g'
l@,h*g%$*d/g#e*,\zm#@v(h*-)J*@**-|q&rhq]#q\s
)(*--,mllu,(h*e,C  D G!HJIK e,m(%m)-z$J*-,]*-,hgJ,C F D G`HJIbK ?
|'1
:p
hveh\bhm HJI )ew:  mE    1|`
hb)g\  ]h]
)1-e@  :g C FD G`HJIKE 1]mhbm]g CE^ FD G`HJIKh] )bJmm 3 1]mve  )1t
ej$Etm`)-:e  ete/  P hw-ve  )1t+ej$]\mw:/    wv/\  ]h]
)1-e@J  1_g C  D G`HJIKE     +]gJj9\  ]g)1@]  :   
aZ:]::1
1@

 ]
 (,g,W,*-,Ue,mq\l#*-ZOd HJI S,m|Ue)*v'(/-g*-ge*-n$-b,_@eg*-st,mvn)}t,m-s
q]#m|(@n/x(,nzm\{@m HJI ?ZA]q\,hg*|d!z$(:)(h*gg*-ge*g,m(J*-@*J*j"$#)-
g,m#n/{u\"$#@(*g`@)-s)UOt@vg*st,mvn))Sk)(h*-)(@e],%m)b*-]%m,){#-+ c M&'[hu*-h#@wB*bJ
"$#)-\{@,m#*J(z(@n$%$n#@&B1?  b*-_m-e*-)-g*ge*g%mmB*k#eE*-,Jerl-
q(+'s`tUerq\l)?~,m-),%m)'Bu!*|zm(`:)(*g)|*@(*-](z$#@zme,m(@dn)n
{}(@nZ)(@e,%gxUOemmSe?
Ayb,`,(zne@(*g,m(/el@bne@(*|$-,p(h*-)g*?
Z$kpp&  t,m-q]#E )e)):  mu    1m *1
"m#@(*g`@)-st-)k(@nJl-,mlu,m-*g,m(s
t-)\t,m-q]#Z(*-(zm#@z$EEO-M&
0Q'555Qvm[mS9Odg,+*@*B(l@-*ge#B
*]@m9(,e,m(@g*v(h*
gq]{@,eSk(@nU@m,$(!Z,m(-)J%g{\p?
 |-'\*-@*EOg'S   b:`wwvb) HJI  X
EOd1S
g)(h*&Ul-,$l@,h*g,m(@&B
 HJI b,*|t,m-qbOd'S1 HJIJ B1})-|bOdSb-g)(*g'`!/l-,$l@,h*g,m(@&(@n HJIJ n,
(,m*q\)(h*!,$(?
A#@)Bg#@g*]mb(A),m-)q=@?mBkZg#ll@,h*-@*JOg'Syg#qqg)]'`k*-@*JJx(,({u,m#*
?EP(+*Je*g,m(pB@bt,e#@},m(/e,mq\l#*g(zZ*-n)zm)|,{@e`e  OdEOd'S) HJI St,m9t,m-q]#
EOd'SUq\l"$#)-Z,$ HJI ?
 ,m*-~*-@*(g)(h*&l-,mlu,h*g,m(@'bt,m-q]#OdS|Z"$#!%')(h*~*-,n$g#(@e*g,m(,
*-,$q)?,mer@q\lmBu,&%$)k*J%m,){#-/M0QeRw[hB*-bt,m-q]#\
0'Od1S18
R'Od1Sy"m#%&&!)(*
*-,J 0 Og1S8 R Od1S'8k
 Od1S
OP)-E*-*-,mqZp-,mvn)n$1
( 
r@q\l6? Se?,$(9-g)(*g'`
l-,mlu,h*g,m(@'u,$-q]#Bh*exm
 \OPS
{@b*-|O#("$#S_g)*_,*-,mqg#@Z*-@*bE"m#%&&!)(*
*-	
, 
fiff
 &Og1Sv?
 T~
 *-,
pk}%m)J*-#l .+
V Wm9l-,m{@{`*gm-d!z$(q\)(h*E*-,|*L*,mq)B)(er*-)(@n .U
Zl-,m{@{`*g $-zm(q\)(*J,m('`-g)(*g'`!l-,ml@,*g,m(@'_t,m-q]#mb#@(z/*-bn)(*g`:)*g,m(
,_(U-g)(*g'`+l-,$l@,h*g,m(@&p,$-q]#j*-+\g)*,*,mq X
Z$kpp p
  )*J{@(+-g)(*g'`/l-,ml@,*g,m(@'
,mq#?  jne@(\j#(@e*!,$( "! $# X
V &%(' )$E,, X

 ! $# O .p S2 *
fi. 5


+ff,-

./

fi021fi3fi465+798:5fi;fi<=46>?1fi3fi4A@	1fiBfiC72Dfi7FEG3fiHfi;I5+JK
LfiMONQPSR-RTPUWVTXZY=[\[^]`_fiN-Ma_bMWR$XVTXMaUbY=[bcdMaN-efW[ZYaRQgihkjmlYUbno?hkjml6pPqnWPsrbUfiPtVvufiPhw_bYN-VXYx[ylzcdffiUb{sVTXMaU}|Q~ + 
&(  VvMbPa
| ~ OW hk l
| ~ +  hT lQ |"~ whT  l

MaV-PV-ubYVV-uWXZRcyffiUb{sVX^MOU}XZRqffiUbnWPsrbUfiPSnpqufiPU|"~ WwhT l2fi
 RV-ufiPQcdM[\[MxpX^UfiNvPSRTfW[V2RTufiMptRXcg`XZRQYtR$Xe_W[PtOffiPN-]?cdMaNihwMcfiV-ufiPicyMON-eo?hk=ltlV-ufiPU
Y=[\[qV-ubYVe	YV-V-PNsRX^U:{sMae_fiffiVX^UfiAQN-hkgql?XZR|Q~ + dhT lqcdMaNV-ffi_W[PSR`  Mcqe	Y=WXeffiePUWV-N-MO_]a
uWfbRzXU:Y}RTPUbRTPapPYN-PMaUW[]fbR$XUfi  V-MnWPV-PN-eX^UfiPV-ufiP	R_bYa{sPMaPNpquWXZ{vupPe	Y=WXeXP
PUWV-N-Ma_W]aqtY=OXUfinWPsrbUfiPSnV-uWXZRRT_bYa{sPapP{YUcyMfi{sfbRMaUoYUbngAXUnWPV-PN-eXUWXUfi}V-ufiPnWPON-PPMc
bPs[\XPsc-
zW6=bG`b=aI gihk=lt } Z 6 \I, 	` aZ    s  zd  OZ  	
 	SqT      6-s	fi  6  :qI \? 6 |"~ dhS  l , 	a 
  },
[\Xe  [\XeRffi_T[\Xe:XUWcS x
[\X^e  "N   hkgihk=l,?l  XUWc |"~ fi WdhS  lsRTffi_ |Q~ + dhS  l 
q   
S fi
 I
ufiP2cdM[\[MpXUfi?XRiYUXeePSnOXZYV-PqfiffiVGXe_MaN-VYUVQ{sMaN-M[\[ZYN-]Mc6VvuWXRGVvufiPMaN-PeGwV2YOR-RTPN-VRV-ubYV=X\c
V-ufiPtR_bYa{sP    \?bubYaRiYffiUWXZOffiPe	Y=WX^effiedPUWV-N-MO_]_bMXUWVSWV-ufiPUXVR"xY=[ffiPffiUWXZOffiPs[^]}nWPV-PN-eX^UfiPSR
V-ufiP_fiN-MObYWX\[XVT]"N   hkgihk=l,tl
 z SbG
	zb=aI, gihk=l?   zI 
   aZ   ss  6d  a    
   I   Z   z-sbI  6  qfi \t z Q| ~ WdhS  l2 2W
QN   hTgihk=l,?l2| ~ fi W hS  l 
ff PYN-P?XUVvPN-PSRTV-PSn`XU"N  hkgihk=l,lfipquWXZ{vuePSYUbRV-ubYVpPYN-P?XUVvPN-PSRTV-PSnX^UV-ufiP?[\XeXVtMc
QN   hTgihk=l,ltYaR   W fiaffi_fi_bMRTP XZRPSRvRTPUVXYx[[]_MR$XVTXaPaufiPUW]VvufiPN-PSRTfW[VR?McV-ufiP
_fiN-POXMafbRqRTPS{sVTXMaUYUbnV-ufiP{sMaUWVTXUfWXVT]Mc | ~ fi  OXViXRPUfiMaffiauV-M[^MWM }nOXN-PS{sVT[]YVVvufiPte	YxXeffie
PUWV-N-Ma_W]_bMX^UWVRMc    \?w MaN-PcyMaNve	Y=[\[]afi]}{sMaeWXUWXUfiufiPMON-P
e b pXV-uQNvMa_bMRkX^VX^MO
U b fi
pP{YURTufiMp
zW6=b fi?b=aI gihT=l  Z 6\Iq 	   W$IO?  \t W `W  fi
     6-sI  6      s,6  aZ?I    2z | ~ W h=  l 2
QN-hTgihk=l,?l2| ~ fi W hS  l 
ff PtPs[XPaPV-ubYViV-uWXZRV-ufiPMaN-Pe pX\[\[V-ffiN-UMaffiVV-M{sMaPNqY [^MOVMc {YaRTPSRiV-ubYViMI{{sffiNX^U}_fiNsYa{sVTXZ{sPa
 RQMaffiNiPs+Ye`_W[^PSRiYUbn`V-ufiPtnOXZR-{sfbR-R$XMaU`XU	VvufiPqUfiPsIVRTPS{sVTXMaU}RTufiMpapPMcdV-PU	nWMaPVR$Xe_W[PaffiPNX^PSR
YUb
n UfiMp[PSnWaPbYaRTPSRV-ubYVYN-PPSR-RTPUWVTXZY=[\[]_bMWR$XVTXaPa
 2MaUb{sPN-UWXUfi}V-ufiPYaR-RTffie_fiVX^MOUMcYffiUWXZaffiP
e	Y=WXeffiedPUVvN-Ma_W]}_bMXUWVSzUfiMaV-PV-ubYV?V-ufiPPUV-NvMa_]cdffiUb{sVTXMaUXZR{sMaUWaPs YUbnRTMV-uWXZRYaR-Rffie_fiVTXMaU
XZRYffiV-Mae	YVTXZ{Y=[\[^]R-YVTXZR$rbPSnX\c    ^tQXZRY sb RT_bYa{sPa
 PS{Y=[\[qV-ubYVYRT_bYa{sP  XZR{sMaUWaPsX\c
cdMaN Yx[[ s    YUbnY=[\![  fi "wWXV?XZRY=[ZRTM}V-ufiP{YaRTPV-ubY#
V "
 $ %h "'&(QlT    ufiPRT_bYa{sP

 \?GXRRffiN-Ps[] {sMOUaPs}X\cXV?XZRnWPsrbUfiPSnfbR$XUfiY{sMa*U )TffiUb{sVTXMaUMcQ[\XUfiPSYN{sMOUbRTV-NY=XUWVR+
 ffuWX\[PXV
XZRq{v[PSYNT[]}_bMWR-R$XW[PV-M{sN-PSYVv+
P UfiMp[PSnWaPbYaRPSRpqufiPN-P   \?zubYaRefW[VTX_W[^Pe	Y=WXeffie`dPUV-NvMa_]
,-,

fi.0/21436578:96;-<5/6=>7@?BA1C;-;5/

DFEHGJI4KMLONPEQ@R%SCTHUVD4WXRYZFL[GXI6\^]_GLa`bZ6IFc%KbGXEIFL%d%Y
e:ROR%S2DR-c%KfKhgFT*KLbZFcigkj
I6E*e:WXR-]4\R0lFT_LbR-LT*QbGLbR:QMT*QiR%WJmnGXI
D6QMTc%KoGcpTqWrT*D6D4WsGcpTHKbGXEIFLpt:u@RpQhgFT*DFL@Khg6R:UVE
LoKQhR-LbKhQbGc%KbGXvR0TLiLbZ6UVD6KbGXEIVUwT]4R:l
mKhg4GLKhg6RpEQiRpUxGL!Khg6R
LbRpRpUkGXI6\*WXmwGXI6I6E6c%Z6EZFLyQhR-z_Z4GJQiRpUVRpI
KyKhgFT*K0{!| }
~N df6t:g4GLyTLhLbZ6UD6KbGXEIwGL0El4v_GJE_ZFL[WXmI6R-c%R-LhLhT*Qhm
PEQKhg6R:Khg6RpEQhRpUBKhEyg6E*W]
eGJKig6EZ6KGXK-Y_Khg6ROPZ6IFc%KbGXEIw{ | 6 }4~ GLfL[GXUVD4WXmVI6E_Kf]4R%FI6R-]tf0I4PEQhKiZ6IFT*KhR%WXmY
e:RfLbg6E*eGXIwR-c%KbGXEIFt0KhgFT*K>Kig4GLQhR-z_Z4GXQhRpUVRpI4K>GLpYGXI+PTc%K-Y*T0LbRpv_RpQhRfEI6RGXIDFT*QhKbGc%Z4WT*Q-YGXK@D6QhRpvRpI4KML
Khg6R0Kig6RpEQhRpUPQhEUlR%GXI6\T*D6D4WsGXR-]wKhE+UVE
LbKOR%SCTHUVD4WXR-L]4RpQoGJv_R-]kPQhEU]4R%PT*Z4WXK:QhR-TLbEI4GXI6\FY_ZFL[GXI6\kEZ6Q
LbKMTHKbGLbKbGcpTW>GXI4KhRpQhD6QhRpKMTHKbGXEIE*Pf]4R%PT*Z4WXKML#N:Tcpchg4ZFLRpK'TWtXY-*CdMt
 RciWJE4LbRKhg4GL0LoZ6lFLbR-c%KbGXEIe:GXKhgT*IR%SFT*UVD4WXREHPKhg6R+Kig6RpEQhRpUGXIT_c%KbGXEI>t
>@@6# RpK+Khg6R+WT*I6\ZFTH\R^c%EIFLGLoK+E*Pf_#o2aa2*4rH%p06pf%T*IF]Khg6R
c%EIFLbK%T*I
Kf%4t:g6RpQhRT*QiR0R%GX\g
KyT*KhEULGXIKhg4GLWT*I6\_ZFT*\Rt  RyZFLbR>  >  >  KhE^]4RpI6E_KhR+Khg6R+T*KhEU
y  Nd y  Nd- y  Nd%Y-e0g6RpQiR y  GL!R%GJKig6RpQfN]4RpI6EKbGXI6\k+b6aaa*drE_Q N]4RpI6EKbGXI6\k+b2_aaadMY
   GLEQ NPEQ+6*
*MVT*IF]2H
*%6YQhR-LbDFR-c%KoGJv_R%WJmdMY>T*IF]    GL+EQ NPE_Q+06pOM
T*IF]02f%>Y6QhR-LbDR-c%KbGXvR%WXmFd%t
 EIFL[G]4RpQ0Khg6Rj
I6E*e:WXR-]4\R+lFTLoRV+#X

 n
 Nh#o2aaaqNbd@6*4r*M_Ndhd
 +b6aaa*NdM6*4r*%Nd %  6
X06pf%6NdX    6
6*
*M_Nhf%*dM
 Pe:R'E_QM]4RpQ:Khg6R#THKhEUL:TLO0yp'Y y  Y   2 Y     Y2 p Y  
   Y   r Y     Y4Khg6RpI
GXK:GL0I6E_K0gFT*QM]wKhEwLbg6E*eKigFT*K'@Nh+p*dGLp
 
F 
N
N
N
N
N


 
  
 
 
  

d

d
: r   d
  r   d
:
      d






NC q diN !
   O
     F *d
NC   diN           d
NC q d
NC
  q d
6

















 EkFIF]Khg6RLoDFTc%R	
fi ff + X  eRLGJUD4WJmLoRpK      6t:g6RpIGJKGLyz_Z4GJKiR^LbKhQ%TGX\g
KoPEQieTHQM]kKhE

FIF]Kig6R+UTS4GJUkZ6URpI4KhQhE_D
mwDFE*GXI4K0GXIKhg4GL0LbDFTc%RY6eg4Gcig>YKMT*j_GJI6\   Y_GLp




N[  i  i  h*qi-iq*h hfi df
 
  M6%6



 

     
6Nb  d CN  d 6Nb  d CN  d 
yL[GXI6\( Y6e:RcpT*Ic%EUVD6Z6KiR+vqT*QbGXEZFLyTLbm4UVD6KhE_KbGcyD6QhElFT*l4GsWsGXKbGXR-LyvRpQhmwR-TL[GsWXmtCEQ0R%SFT*UVD4WXRY
u!QNh#o2aaaqNif%*dp+#pd

{| X!#"%$&"'$)( + * !-,.fi/-$10a ~N d
 O  
 O  O    *
3 25 4  325 4
66
3 25 4  3 25 4   6a3  25487  63 25487





TLkR%S6DFR-c%KiR-]t *GXUkGsWT*QbWXmYye:RcpT*ILbg6E*eKhgFT*KVu!QNh06pOMNhOM*d++pX_d 6T*IF] KhgFT*K
uQ  Ni6pOH%Nhf%*d#o2aaaqNif%*dp+ p d: 66t:9EKhRKhgFT*KyKhg6R+FQMLoK'Kbe:EVT*IFLbe:RpQMLyTWLbE

;<

fi=	>@?@AB5CEDFB@G@HIAJ>@?@ALKM>@N@OPC	Q@CSRT?@U@GVB5WfiX
Y[Zfi\)\&Zfi]^Y`_3Zbadc3e@fMgbh1_3ficjh1klY[f_3fkmifon@_ph1kmiqh1nl\&fsrutve@fZ_qfadwmx1y{z|}]:elh~i3eFem{n@nmfkmjc3Zf{n@nl\h~ifil\1f
h1kc3elh~ibpfxFtve@foc3elh1_g{kmp]vf_#e@Z8]cqemfico:V	Ffikmgp@[~fi_3fofh1k@c3_qffic3fgL
h1kmglfnmfkmglfklcx:c:h~pnfiqhP8\ipfZfiYaZ_3ffk@f_8\h1kmglfnmfkmglfkmifn@e@fk@Zafk@Zkc3emfic:fin@nl\)h1f
c3Z_fikmglZa]vZ_p\~g@mpffruviiqemvfcI\-x1|}yfiwm|@tve@fZb_3fa@x'Vzx
1j}mT~IT}P1mPm
-kocqelhPvpfic#h&Zbko]fiZkmh~glf_:cp]vZ8{_ph~fikc	Z{Y#l3`[m3@fi[[fi}){`fiT	cqe@f:Y[Zfi\)\1Z8]h&k@
gbh~3im3h1Zkope@Zfi]|fiZc3eifikfh)\1fifin@c3@_3fgjlZ@_TY[_fiaf]Zb_3xTtve@fvfamfg@gbh1k@]f:gbh~3im3
mpfvh1anl\1fb@f_ph1fvc3e@_qZ@e@Z@c|lI\)\1Z8]h&k@mvcqZfin@nfI\c3Zc3e@f_3fpl\1cZfiYc3e@fn@_qfh1Zm:#ficph1Zkx
 h)\~3pZkryblzMiZkmh~glf_3fgc3e@fLn@_3Zl\1faZfiY]:emficiZbl\Pgmfsh1klY`f_q_3fgE{mZ@cc3e@fn@_qZmfi
lh)\)h&cpFZfiYif_3c8h&kFn@_qZnmZuh&c#h&Zbkmfih1fkpZafoiZkmpcq_Ih1kcxF@Z_fmfianl\1f|v]vfMah1elclk@Zfi]c3emfic
 _r1v13mz@)ofikmgLc3emfic  _r3I~)fiz@@|fikmgfh1klc3f_3fpcqfgsh&k  _r1v1~3)fizx
 Z@bel\&#nmffibh1k@m|  h)\PqpZk#@fpciZan@@cph1k@Lc3elh~liZkmh~glf_ph1k@I\)\n@_3Zbmfilh)\h1cpgbh~pcq_ph1
@@cph1ZkmiZkmh~pcqfkcj]vh1c3ec3e@fMiZbkmpc3_Ih1klc|fikmgsc3e@fkiZban@@cph1k@c3e@f_fik@fZ{Y88\&@fjfih1fkLc3Z
 _r1v13)fiz:c3e@fpfMgbh~pcq_ph1@@cph1ZkmxM5Z_3aM8\\1|Tp@n@nmZ#fZ @_\~fik@mfibfiZbkmh~pcZ{Y
n@_ph1ah1cph1fon@_3ZbnmZh1cph1Zk|mfiI3@xZkmh~glf_c3e@f#fcZfiY cq_3@c3eqh1k@afklcjc3e@fpf
n@_3ZnZh1cph1Zkmxf{h&bfpfaM{kcph~ic3Zn@_3Zmfilh)\)h~pcph~ipc{c3fafklcvZfif_:c3elh~\~fik@mfifh1kcqf_3aMvZfiY
n@_3Zbmfilh)\h1cpgbh~pc3_ph1@@cph1ZkZfif_:cqe@fpfc^rupffrum{fih1k|m8\&nf_3k|ffih~g@glZm|TyblzTY`Z_glf
cIh)\~zxfih&kmiffbi3ec3_3@c3e3h1k@afklcglfc3f_qah1k@fvc3e@fc3_3@c3efiI\1@fZfiYff_3n@_qZnmZuh&c#h&ZbkmI\
Y[Z_3al\~j|@]vfifikglfc3f_qah1k@fc3e@fn@_3Zbmfilh)\h1cpZ{Y ff_qpmiqeY[Z_3al\~ 
 _r[	z

Tr[:z

 	ff


\1ffi_p\1|T]vfifikglfc3f_3ah1k@f]:e@fc3e@f_on@_qZmfilh)\)h&cpgbh~pc3_ph1@@cph1ZkL3fic#hPfimfopfc ZfiYn@_qZmfi
lh)\)hP#cph~iiZkmpc3_Ih1kcxtve@fpcfikmg@{_gk@Zcph1ZkZfiY n@_qZmfilh)\)hP#cph~in@_3ZnZh1cph1ZkmI\Th1klY`f_3fkmif]Zbl\Pg3I
c3emfic E   _r[z	
    5hY  _ @r[	zhP]vh1c3elh1koc3e@f_fik@f  ffmY[Z_vff_3gbhP#c3_ph1@@cph1Zkoc3emfic
3fic#hP fimfvc3e@fiZbkmpc3_Ih1klc h1
k x
f fimklh1cph1Zk|5c3e@fiZkmpcq_Ih1kcTc3emficZk@f:ifikMglf_#h&bf
 klY[Z_3c3@kmficqf\&|b]:elh)\1fc3elh~ hPf_3kmfic3@_I\5gl
Y[_3Zah1cfi_qfcpnlh~iI\)\1blh&cqf]vffi}x	5Z_:c3emficv_3fbpZk|  h)\PqpZkp@f#c3fgopc3_3fk@bc3e@fklh1k@Mc3elh~k@Z
cph1ZkZ{Yh1klY[f_3fkmifl{n@nl\&bh1k@c3e@f:n@_#h&kmiqh1nl\1fZ{YaMIlh1a@afklc3_3Zbn  _{c3e@f_c3emfikMiZbkmh~glf_ph1k@MI\)\
gbh~pc3_ph1@@cph1ZkmL3ficph~Y[h1k@
 |@]vfiZkmh~glf_Zkl\1oc3e@fgbh~pcq_ph1@@cph1Zk}ruzv c3emficembfc3e@f_qffic3fpc
fklc3_3ZnlfiaZk@oc3e@ZlpfM3fic#hPuY`bh1k@cqe@fMiZkmpc3_Ih1kcxM]vfk@Zfi]pe@Zfi]|Zk@fh&anl\h~ific#h&ZbkFZfiY:Z@_
_3fpl\1ch~Tc3em{cc3e@f	_{kmglZa[]vZ_p\~g@Tafc3e@Z@gjn@_3Zfih~glfn@_ph1kmiqh1nl\1fgaZcph1fificph1ZkjY`Zb_c3elh~h1klc3_3Z@glmi
cph1ZkZfiY	aM8h1a@afklc3_3Zbnoc3Zn@_3Zm{lh\)h~pcph~in@_3ZnZh1cph1ZkmI\_3fpZbklh&k@xkY icI|mc3e@fiZk@k@fic#h&Zbk
mfcp]vffkn@_3Zmfilh)\)h~pcph~in@_3ZnmZlh1cph1ZkmI\m_3f#Zklh1k@fikmgj_fikmglZaS]vZ_p\~g@pe@Zbl\Pgjk@Zfi]FmfY-Ih1_p\1iq\&f{_ 
 "fiII3$ "x
! tve@fn@_ph1ah1cph1fn@_3ZnZh1cph1ZkmmII3-@iZ_3_3f#nmZkmgc3Zc3e@f@kmfi_3n@_3fgbh~ific3f#
! Fn@_3ZnmZlh1cph1ZkmI\lY`Z_qal\~oZfif_m  I3  iZb_3_3fpnZkmg@T@klh~@f\1c3Zfikjf3pfklcph~I\)\1n@_3ZnZ
h1cph1ZkmI\}Y`Zb_3al\P&
 % 
  Y`Zfi\)\1Zfi]  ]vf_qfnl\PbiffiqeZVii@_3_qfkmifZfiYc3e@fn@_3ZnZh1cph1ZkmI\plamZfi\
 ' ]h&cq
(
e ")'3r * zx
c Z{Y n@_3Zbmfilh)\h~pc#hPisiZkmpc3_8h&klciZb_3_3fpnZkmg@cqZlk@Z8]\&fglbfmp,
f +. -/012
! tve@fpf
iZkmpcfiklc3Y[_3ff:lk@Zfi]v\1fglfmpfiZklcIh1klh1k@MZkl\1n@_qZnmZ_qcph1ZkofVn@_qf3h1Zkmx	te@fiZ_3_3fpnZk@
glfkmifh~bY[Zfi\)\1Zfi] 
354

fi687:9(;=<?>A@1B=C5DE<E7=F >HGJIK9ffC5CL<E7

MONQP=RSETUVT(WXWZY\[^]_:P=R]5``aWZSEbcSVd#Ye=]dfSgRhjiARlk/mn&UoP=P]5UVR\WZb=pqWZbsrOWt`R]lP(XtUEu]5vwTx[yYe=]
P=RSEPSgRY\WZSEbq]_:P=R]5``aWZSEb{zZz |}k~)n$zZz xVWZhWXtUVR\XZ[EUuSEbvgWZY\WZSEbULX1P=RSETUVT(WXWZY\[]_=P=R]5``WSgb
iARk/mKz mHtnHWt`R]lP(XtUEu]5vT([|}k~n$z | }x k\~)n(
MUEueuSEhPUoR\Wt`\SEbuSEb=b=]5uYWg]cWt`R]lP(XtUEu]5vTx[1)d/SER`SEh]8xUVbv]5UEuecKWYe
k1e=]PUoRY\Wtu(XtUVRue=SoWu]5`d/SER8Ye=]UoP=P=RSL_xWZhUVY]]5gULXWY\[quSEb=b=]5uY\WZE]5`v(Sb=SEY.hUVYY]lR
WbYe(Wt`8uSEb(Y]_=Y5n
1e=]SEYe=]lR]XZ]lh]lb(Y$`#YeUVYulUVbUVP=P?]5UVR#WZbUP=RSEP?SERY\WZSEbd/SERh(XtUk`\ueUE`#R$UVY\WZSEbUXb(=h
T]lR$`UVbvUoR\WZYe=h]lY\WtulULXuSEb=b=]5uY\WZE]5`nR]lhUWb=bueUVb=pg]5v)=SER]_UVhP(XZ]EYe=]qd/SERh(XtU
iARkZ1zZt?n8{ff1SE(XtvuSERR]5`\PSgbvYSYe=]P=RSEPSERY\WZSEbd/SERh(XtU=k\~)n$z1t)k\~)n$
=x


1e=]lR]Wt`AU8SEb=]l/YSE/SEb=]8uSERR]5`PSEbv(]lbu]8T?]lY\]l]lbYR=YeUE``aWZpEb=h]lb(Y$`AUVbvUVYSEh`l)Ye=]YR=Ye
 
UE``aWZpEb=h]lb(YA^uSERR]5`\P?SEbv=`YSYe=]UVYSEh{ )

5L     8e=]lR]   Wt` Wd 8kt:nA:
SEYe=]lR1Wt`\]E^)]lY V 55  T?]Ye=]YR=YeUE``aWZpEb=h]lb(Y$`uSERR]5`\PSEbvgWZb=pyYSqYe=]

UVbvs 
UVYSEh`1


  L5  


ffR]5`\P]5uYWg]X[E

1e=]lR]Wt`USEb=]l/YSE/Sgb=]uSgRR]5`\P?SEbv(]lbu]T]lY\1]l]lbP=RSETUoT(WXWZY\[vgWt`\YR\WZT==Y\WZSEb`SVE]lRYe=]`\]lY



SVdAYR=YeUE``aWZpEb=h]lb(Y$`.UobvPSoWb(Y$`KWZb
ffSER8]5UEueP?SVWZbxY&q
  
(XZ]lY   v(]lb=SEY]Ye=]


uSERR]5`\P?SEbvgWZb=pP=RSETUVT(WXWY\[vgWt`\YRWT==YWSgbSVE]lR
ff8e=]lR]   k/ \n


qVy/x)&

XZ]5UVR\XZ[E( z cm,WK



k| } n$1e=]lR]d/SER]E(d/SER8ULXX  ff]eULE]

 /l 
k\ nAiARE  k/mn$
Ke=]dfSoXXZSV1WZb=pqR]5`\(XZYv(]lhSEb`\YR$UVY]5`#Ye=]Y\WZpEexYuSEb=b=]5uY\WZSEbyT]lY\1]l]lbP=RSETUVT(WXW`Y\WtuP=RSEPS(`aWZ
Y\WZSEbULXHR]5UE`\SEb(WZb=p`Wb=phUL_(WZh=hQ]lbxYRSEP([UVbvRUVbv(SEhQ1SER\Xtv=`l
 (L/gJ


5rc$LfO^$	lo
)ff

fiffxo

iARk/mKz m  nc

   (lqffs?:xx/fco
l$=/{!^fi"#L

lE
ffff'&&r(*)V+,oE(mm  , .iAR.-lk/m  n0/c,Affx$

iARk/mKz mn

iAR1k|}k2Lnz |}  k2Ln 43


QV

$%

 5
r /nH{iAR.-lk/mKz m  n

Ke=]lSER]lh6?8796Wt`UVby]5UE`\[uSgRSVXXtUVR[SVd.1e=]lSgR]lh:687;7E Sque=]5u<YeUVYYe=]P=R]5uSEbvgWZY\WZSEb`
SVdYe=]XtUVYY]lRYe=]lSER]lh
UoP=P(X[E1b=SgY]YeUVYYe=]quSEb`\YR$UWb(Y$`&WZbcrQUVR]XWZb=]5UVR58Uobvc`\SqYe=]q`\PUEu]
= >  3    0
r ?eUE`U=b(Wtg=]hUL_xWZh=h/]lb(YRSEP([P?SVWZbxY@  BAb d UEuYL?WY#Wt`&]5UE`\[YS`\e=SVOYeUVY# C  W`

Ye=]qk=b(Wtg=]VnhUL_(WZh=h/]lbxYRSEP([P=RSETUVT(WXWZY\[vgWt`\YRWT==YWSgbcSVE]lR
`UVY\Wt`ad/[EWZb=pYe=]uSEb`YR$ULWZb(Y$`
rDAbUEv=vgWZY\WZSEb 8T?]5ulUV`\]qYe=]lR]qUVR]b=Syb=]lpxUVY]5vyP=RSEPSgRY\WZSEbc]_=P=R]5``WSgb`WbrYe=]d/SERh(XtU

3


E

c| }  k2Ln 43



 0
r ?Wt`8u]lRYULWZb(X[]5``\]lb(Y\WtULXXZ[PSx`aWZY\WZE]E

Sx`YUVP=P(XWtulUVY\WZSEb`SVd#P=RSETUVT(WXWt`\Y\WtuP=RSEPS(`aWZY\WZSEbULX.R]5Ug`\SEb(WZb=puSEb`aWtv(]lR`aWZhP(XZ]uSEb`YR$ULWZb(Y$`

SVd8Ye=]dfSgRh`\]5v

WZbYe=]Ye=]lSgR]lhAUVbvy`\S`\ue^UVP=P(XWulUoY\WZSEb`ulUVbyT]EWZ]l1]5v^UE`&E]lR[`\P]5uWtULX

ulUE`\]5`SVd#Ye=]RUVbv(SEh/1SER$v=`UVP=P=RSxUgue FAbydUEuY5HYe(Wt`Ye=]lSER]lh
1e=]uSgb=b=]5uY\WZSEbT?]lY\]l]lbyuSE=bxYWb=pHG1SER\Xtv=`JIUVbv

Wt`]5``]lbxY\WtULXXZ[^Ug]lR[SVXtv,SEb=]E
WZb^U`\PUEu]v(]%Kb=]5v

Ye=]]lb(YRSEP([qhUL_(Wh=h

UE`UuSEbL=buYWSgbSVdXWZb=]5UVRuSEb`\YR$ULWZbxY`W`&E]lR[q1]XXM<(b=SV8b NAaYeUE`#T?]l]lb]_=Y]lb`aWZE]XZ[`YvgWZ]5v

WZbYe=]*K]XvSodYe=]lRhS=v([xbUVhWul``\Y$UVRY\WZb=p1WZYeYe=]B7POVYeu]lb(Y=R[SgRJ<SVd

R

E

U_:1]XXUVbv4QWZT=T`l

]5u]lb(Y\XZ[E=Ye(Wt`AY\[(P]8SodR]5UE`\SEb(WZb=peUg`AT]l]lbUVP=P(XWZ]5vYSP=RSET(XZ]lh`WZbUVbNSAuSEb(Y]_=YATx[iAUVRW`UVbv

TPU

fiVXWZYZ[]\^`_H\ZaZb[]cdWZYZ[fegWZhZi?^XjZ^lkmYZnZa'\op

qsr9t	u%vw'xfiy{z}|~P;.zt	;	z;xJm|~P;.5Zrd5v;JyBvsz
xXzt	Nqsr9t	u%vwZxy{z
x	zJ
u%
z8Jr%8r9
w{ztsrPu9z	xrdJZr9Nz
xvJrPz89rSZrtZrPu%rPxJx8Bvz;v;Z8tZ(zdMv;Jz'tZv.8v;tNvX9zZZJvz8v;t	Z
z8JZv;Z.4JZr(ZJrPu
xrBr9z
xvJZr%8zZZJvz.uJ.r95MJv;v;Z%x9
v4JZrB	rPxfi(v5v;ZytZv58rP;r;Nvxv0JZrB5v;JyFv;tZJv;	z
x
uZJv;vx88v;t	zXJrPz.xv;tZ
8tZ"zt	zXMv;JgzsZJrPxr9tzfiv.t	xv5JZrNr9tJJv;	0v.
ZxSu%v;tZtZrPu%fiv.t|M8t	zJ
u%
zPmJZvxrBv
|szfi?xqsr9t	u%v{wZxyzZ5~P;;Zm;	z.xJ5~P;;'J0	zw;r8B8JrPfJZr9gxfir%w.rPxJvu%v;tZt	u%8v;t	xv8tZ
rPz(u%v;t	xfiJz8tx9Z(}v;JrB;r9tZr9zs
ztZ.	z;rN8w;rPx	x(z;rPz(rPzXvz;Z.88v;t	z0r%ZZJrPxJxw.r
	v5r9P4Zv.(r%	zN8r;
xB;8JrJrPz;xfiv;t	z8rNJvFztJZr4z8Jvr%ZZJrPxJxJ	zZv;	r9JfirPx
zJrF|zZZvP8gzJr%8xz
x
u9z88t	r9	r9t	r9tPDZv;Br%	zN8r;55rgzP5
xJvz;xxr9JBJ	z
5
J|Nzt		Pffd|NzJrt	r9r9t	r9tZJv;	r98rPxDxJz;8tZ`85ffJ	|	
d|98 D
85ffJ	|8 8	
*|? s8rPz8;	xfi	uJu%v;t	xfiJz8tx5zJrdtZv;8tZrPz0*r9w;r9JJZr%8rPxJx$v.ZS5Zr9
v;Jr9	8~;~u%vw;r9x5x	u"u9z;xfirPxzt	B	uJ4}v;Jr;
 w;r9xv.tvXZJv.	z
xfi?uZJv;	vx88v;t	zsJrPz;xv;t8tZ	z;xdz
xvN	r9r9t	xrPFJv}ZJvw;
r(Zv;	z
?xfi
uNxr9gzt
u9xv;dr%z8JrPz.xv;t8tZ|mrPz~P;.X*r9Jrz{?xfiv		Zr(u%v;tZtZrPu%8v;tJvNzt	v;
5v;
Zx*
xv58tJr9JrPxPtf	zJfi?u%
z8Mv8v{dx*Jv.:Xv;Jv
zJ	?~PN	zJZrBJrPu%r9t(5v;Jy4v
 v?Zxfi9B
PFv;J
x9zt	mrPz5|~P;.0u9ztF	rBr9B	rPZrPF8tJZrBzt	v;NM5v;
ZxzNr95v;Jy
tFJZrJrPx*v?x*xZ	xrPu%8v;t5rr%'
z8tJZr%8zZZJvz;uzt	4JZrr9B	rPZ.8tZ	
v;t	x
r9Xz*
ztZ;	z;ru%v;t	x?xfi8tZ(vZJv;	vx88v;t	zZMv;JB
z;xvw;r9mJZr5ZJv;vx88v;t	zw{zfi?zrPx
	PPZ mzt	r%z8rPxv5JZrBMv;J:|JrPz;$NxzJrN?u9z{8BxJZr9Jrg
zt	NzJr*ZJv;	vx88v;t	z	Mv;JB
z;x9  .
xJ8ZZ8v;t4
xxJz
Nv(%9;ffff
%gzr%z5J8rl:
(m|NB~B9tz.Z.fiv.tJvr%z8J8rPx95JZrMzNr95v;Jyfz
xv	r9B8xNZr	xr4v
gzr9
z8N
u9z8v;t8t"z}J8r;z;x8tB  .
xJfiZZfiv.t"?xdxJz
JvgxJzfi?xx	u"zJ8r
Sm|NN~.  JNPM$ P%  J
 
 Mff"ffff% Zff
 H|X

 	*
xzu%v8rPu%8v;fi
t ffP
 gv
ZJv;	z8".
xJfiZZfiv.t	xdv{w.r9
 Z	z%zNr9Jr989rP9  X
 	ffP    xz
x 	rPxzNxr9
  v
J8rPxv.(r9w;r9J9m  fixJz
x 	rPxr9w;r9Jr%z8BJ8
r  ! zt	fxJzfi?"x 	rPx(r9w.r9JtZv;tZr%z
J8#
r $   xr9%
 vr%z8J8rPx(fiMr9tz{
x v;dr9w;r9JX
 	 	zfixJz
x 	rP&
x "
8 (')   |NB`~;
 xNxZvt8t |  r%tZr9mrPz~P.;XfiMr9tz{8Nr9t	vxJxfirPxJxrPxNztZB	r9NvJrPz.xv;t	z8r
ZJv;r9J8rPx*
u9z8z;xJxvZu
zJrP4r%z8dJrPz;xv.ttZ8t	u	.8tZzBZr%r9Jr9t	u%rv.Nv;Jrxr9
u*]u58tMv;Jgz8v;tsv5r9w;r9PJZr9rzJrSzdtZr9XvrPx8z8rdZJv;	r98rPxX	zm80vrPxmtZv;X	zw;r;
 Nv;tZv;JZr9dJ8tZx98JJr%8r9w{zttMv;Jz8v;t4
xdtZv;*8;tZv;JrP|J;r9rN"| +5z;u9u	xdr9z8s~;ZsMv;
zt4r%ZJr9t	x8w;rB.?xu%	xJx8v;tvsJ
x
xJxZr;
v(v.Zz8tz.Z.fiv.t	zrPx8z8rZJv;r9J8rPx9	xfir9gzt
u9xs
xr%ZJr9t	rP}8t|  v
Zx9?5r95z8
P~ ;.Szt zZ
u9zfiv.tvSZrgZ8t	u88rvdgzBZ:r9tJJv;;t	xJrPz;vSu%v;t	x
r98tZHz
	vxJx88r 
	Bx9z;x4z	vw;r;d5ru%v.t	x
r9"v.tDJZrfX
	-,Z/. 0 132  xfi	uJJ	zPv.4rPz;uJ9

/. 0 1 	z;x*JZrBgz8Zr9tJJv;zNv;tZ4.
xJ8ZZ8v;t	xJ	zSfixJz
xM"zXJZrJ8rPx*8t "|J;r9r
|  v
Zx9B
r9Sz8~P.;Mv;5ZJrPu
xrBr	tfiv.t	xzt	NrPuJZt
u9zXr9z
x9*v;JrdJ	z'xt	u%rJZr
u%v;t	xz8t%x	xrPJvr 	tZr5/
 . 0 1 zJr5z8tZrPzP.JZr9Jr
xt	r9rP}zZt
.ZrSx	u(	vtsv	gz{8BZ
r9tJJv;;  J8r"  
xgz5
t 476X  
 % 99
 8
  :;Z; 8v%
  8 (')  . 0 1 |NB4 ~;
5ZrtZv;8v;t4vX9
 <sM
z	x88rgu%v;t	xrP.Zr9t	u%r
xzt	z89rP48tr9z8tf|  v
Zx9?dr9Sz8~P;;%
Zr9Jr8d
xxZvtJv}tZZr9fiBzXJZr(t
u%rNZv;	r9JfirPxv0Mr9tz8Nr9tN|x	uz;x*JZrBZJr%r9r9t	u%r
Mv;Nv;JrNxrPu* ]uB8tMv;Jgzfiv.t8rx	u9u%rPxx8.tZv;8tZ48JJr%8r9wzt8tv;gz8v;t#
 <;	z8
8N	v.Jzt8;Zz8;v;8JZgxzJrdZJvw;
rPv.0u%v;NZZfitZBJZrd=
 < M
z	x88ru%v;t	xrP.Zr9t	u%rPx5vzxr9
vsJ8rPx58tu%r9Jz8tu9z;xrPx$
>?

fi@BADCFEGIHKJMLNOPGPAQ/HSRTUCVNNWGPA

XBYZ%[]\W^_[`Y[#a(b;cFdZePfFghZibjkYFldmj3n;\cpoqb#Yqjkbrsdetjvuexwydiuq\d%dub#\ffZe\znu9e{)|}el~rjk;[_rFd
b;d3\WlKzPFn;\c9oIb#b;[`oqbrrFbr7_c

ePYZ){(Zm\[b;wezZ#_c\$jvdZm\W_PuFdk{(ePZwB\Zmr[\ccb;Z

b#j_[#fFlg

dZm\cqjl~\db3\#rFb{\YFldBZYFlb3`e{Kdub){(ePZ[_cFde\qZmjkda(ePZrFb;ZrFb{\YFld)ZYFlb
%B;U;|"m ;M|"%P
\Pj_c$ePYZb\Zkl*_b;ZdZ\cqjl~\dk_ePc$e{KM_*l~jjkePc/j\ffZie\Pniu/ePdb%diuq\dMdub){ezZ[`YFl\zjMduq\dB\Zk_~jkb%YcqrFb;Z
duF_~j%diZm\cqjl~\dk_ePc\Wl*l
Yqjkb#dubji\[#b\ffZie^F_[\db`bzYq\Wl*_d"g

nePccbndv_zbh

 #MubZb\PjkePc7_~jduq\d

dubh\ffZie\Pniue{|}el~rjk;[_rFdb;d\WlBzPFYqjvbj`dub$j\[#bh{(ePZ#\Wl*lrFb{\YFldZYFlbj;

bhn;\c

j_[`_*l~\ZklgdZm\cqjl~\dib\s|cePcarFb{\YFld;ZiYFlb]$e{Mdub`{(ePZ[_cdie=\]qZjkda(ePZmrFb;Z3nezcqjkdZm\W_cFd
Yqj_c]YcF_zb;Zmj\WlzYq\cFdk_*n;\dk_ePc/
 



;(/

&| 

|"K 

|"

cqrFb;ZduF_~jMdiZm\cqjl~\dk_ePc/Vwb3n;\c$fZePb%dub){(el*lewM_c]dub;ePZb;[7


`FWq-(V]/W7]hq;(
P/~$]q;*PP;;;hi;
;/v3P(;mm;*%m





 cfq\Zdk_~nYFl~\ZduF_~j`dub;ezZb;[

%9h
*Fm;*`mq;mD%kB 

ZF 

|     |  /
 
P

;



_[fFl_bj]duq\d\xllBdubhnez[#fYdm\dk_ePcq\xlUdibnucF_~zYbj\cqrZibjkYFldmj

rFbjnZk_oIbr$_c|})el~rjk;[`_~rFdb;d)\Wl/PzF
n;\ZZg]ePb;ZBde#diuF_j)jkfIbni_\xl
[#b;duer

 d\xljve

jkuewjduq\d/Zm\cqrFeP[#a(wMePZkl~r)fZez_rFbjS\MfZk_cqni_fFlbr

n;\Pjvb3e{Kdub%Zm\cqrFez[#a(wMePZkl~rj

 Yqjkdk_*n;\dv_ezc3{(ePZ/diub
\ffZe\Pniu

|})el~rjk;[`_~rFd%b;d3\WlSPPFfZbjkb;cFd`|ePcb3wuF_niu9_~j%zYF_dibrz_b;Zib;cd{ZieP[diub
_c

 Yqjkdk_*n;\dv_ezc=_zb;c

|})el~rjk;[`_~rFd)b;d\WlPPD_dmjvbl{Wm

*	ff
fiDfi
 cPbndk_ePcq]wMb#ZbjvdZk_~ndbr\ddb;cFdk_ePc9de=j"_[fFlb$zYb;Zk_bj;9XBYZ`[\W_cZbjkYFldKMub;ePZb;[qPz
cb;brFbr$ezdub;ZB\PjjkY[#fdv_ezcqjB\PjwMbllKbjijkb;cdv_\xlfqej"_dv_z_dkgPdub%b^F_jvdb;cqnb3e{K\3YcF_~zYb3[\x^_[`Y[#a
b;cFdZePfFgfIe_cd
!

 x\cqr&dub
ZibPYF_Zb;[#b;cFdKduq\d"$# %&(| ('!/
!

boqbl*_b;PbBduq\d/duF_~j/diub;ePZb;[fi_j

_cjkfF_db`e{K_dmjl*_[`_dm\dk_ePcqj\zjrFb;[#ezcqjkdZm\dibr$oFghdub#rz_~jnYqjj_ePcs_c)Pbndk_ePc*q+V

Yqjkb{(YFl

b;Pb;Zdiublbjij;

duF_~jZbjkYFld3\Wl*lexw)jBYqjde#dm\Pb3\PrFx\cdm\Pb%e{
ePcFlgh\#jk[]\Wl*l{(Zm\P[b;cdBe{ePYZ)Zk_~niu$l~\cPYq\zbP-,\c
wMbqcqr=\][ePZb3zb;cb;Zm\WlKdub;ePZb;[/.0B{(db;Z3\Wl*l/diuboq\zj_~nnezcqnb;cdZ\dk_ePc9ZbjkYFld`|"Mub;ezZb;[1++D
uel~rj)wM_du9bjjkb;cFdk_~\Wl*lg9ceZbjvdZk_~ndk_ePcqj;

 c9duF_~j%jkbndk_ePc9wMbjkuew



b^db;cqrUub;ePZb;[2qP]j_PcF_*n;\cFdklgP*3BewMb;Pb;Z

duq\dM_d)_~j_cqrFb;br9fqejij_oFlb]de

dub;Zb$\Zb$jkb;Zk_ePYqj&l*_[_d\dk_ePcqj#\cqrjkYodklb;dk_bj;

b)_*l*lYqjkdZm\dibdiubjkb%fZePoFlb;[jog][#b\cqjUe{b^q\[#fFlbj;I\cqr$dub;chjvdm\db3\c$b^db;cqrFbr
XBYZ#\didb;[#fd3dies\zrrFZbjjdubjkb]fZePoFlb;[j]|kjke7{\Z`\Pj&_~j`fqejij_oFlb&lb\zrj`de
fFl*_~n;\dbrsqcq\Wl
ZbjkYFld
dub$dub;ezZb;[

ZbjkYFld

\$Zm\dub;Z#neP[#a

 c9{\PnddiubfZiePoFlb;[j%wMbrz_~jnYqjij\Zb#\PjM_cFdb;Zbjkdv_c9\cqr7_[#fIePZdm\cFd%\Pj

wMbh\PndiYq\Wl*lg_zbP$dub;gublf

b;cFdZePfFgP`XM{UnezYZmjkbPb;Pb;Zg

YqjYcqrFb;Zmjkdm\cqr[#ePZib$e{

_~jjkYb`wMbrz_~jnYqjij)_c

de7[\W^F_[`Y[b;cFdZePfFgj)[\W_c

diub]l_[`_dmj]e{

[\x^_[`Y[

duF_~j%jkYoqjkbndv_ezc9_~j%Zbl~\dk_Pblg9[`_cePZ3neP[fq\Zbr

|k\ffq\Zb;cFd;ZibjkdZk_~ndk_ePc/KwuF_niunePcqnb;Zcqj`dubYqjkbe{cePca(Ycq\Zg

fZbrz_~n;\dbj54ePZ)dubZb\PrFb;Z%wBue_~jlbjij%nePcqnb;Zcbr

\oIePYd)dub`ePdub;ZVlbjjkb;ZI_~jjkYbj)wMb`Zb;[\Z

duq\d_d_jfqeFjj_oFlbdiejvP_f=rz_Zbndvlg7de6Pbndk_ePc7V
pb3qZjkdnePcqj"_rFb;Z`dubZbjkdZk_~ndk_ePcqj&wMbfFl~\PnbrpePc

diub/8:9K\cqr

jvuexwydiubrz_;tnYFldk_bj`duq\d

\Zk_~jkbU_{Swb)rFZePf#dub;[7pbjkdm\ZidKwM_dudiubBZbjkdZv_ndv_ezcde3\j_clb%[\W^F_[Y[a(b;cdZiePfgfqe_cFd$0%j

<=

fi>@?BABCEDGFIHJDBKBLMCEN-?BABCOP?BQBRSF@TBFVUABWBKDGXY

Z\[B]_^a`cbd^a]ebfZ\gahZjik`lb6Z\[B]e`lg\]emonqpr[B]e`lg\]emtsGukvswyxj[B`z_x|{lZ\[B]}]ebZ\g\`c~f`yhMkm`fxjZ]el]eg\zr`lgjixbB]hg
mPhMikmBmu(BZrikZ:`f]xbB`lZr`k`zZ\[dhZ_hZ\[B]5mPhfikmBm]ebZ\g\`l~P~`ikbfZax_hg]5xjBg\g\`lBbd]f
xikmihg@bBmd]egx`Ezr`lgSBx|up[fdxe{MikbZ[B]}~Bg\]xj]ebd^a]}`Em`lg](Z[dhb`lbB]rmPhMimBm]ebZ\g\`c~f~d`ikbZ{
zr]hl^a]6Z\[B]6~Bg\`lk]em`rdbdcikbBZ[B]Pg\]ahZic]ikm~`lg\Zhbd^a]l{`lgz(]aikl[ZjikbBd{$`_]hl^[mPhfikmBm
]ebZ\g\`l~P~`ikbfZMu@:x}Z[B]-`k`zrikbB/]aGhm~k]:idxZ\ghZ\]x|{dZ\[ixzr]aic[fZjikbBix}`Z\]ebxj]ebdxqiZic]Z`Z\[B]
Z\`k]eghbd^a]:hMkB]xeurB`lgrZ\[ixg\]hlx`lb{bB`lbBBbilB]]ebZ\g\`l~mPhMikmPh`Z\]ebk]hl6Z`bB`cbBg\`lBdxjZ\bB]xxeu

Sf

 B~B~d`fxj]JraM{hbd/^a`lbdxi]eg-Z\[B]5bB`zrk]l]:dhlxj]

:

nenqffwa5}Bsw/nenjwa}rBlwa

:x\xjBm]:zr]:z}hbZ(Z`P^a`lm~BBZ\]5gnqnqMw :

ln

hbd

   :_

 

`lZ\]:Z\[dhZ-




Bs 

_

iSx

`lgr

:

B}  f

Bs`lgr

:

Bcf

ix
ln





 w@

wubZ\[ix_^ehcxj]l{}B
  :_

   :_

 

 w@

V


_

[dhcxrZjz(`mPhMikmBm]ebfZ\g`l~f6~d`ibZx

`z^a`lbdxi]eg}Z\[B]:mPhfikmBm]ebZ\g\`l~P~`ikbfZaxr`@





nqBsBaBlwyhbdnqBfBsw\u
 :-

  u$ZrixrbB`cZ}[dhgZ\`Pxj[B`z


`cg
 

Z\[dhZi({dZ\[B]ebZ\[ix:xj~dhl^a][dhlx:hBbiScB]mPhfikmBm]ebZ\g\`l~~`ikbfZ{njBs-JMB-*Mwu
bZ\[ix^ehlxj]l{@g   

nqnqMw :

w5Bs  u*}bZ\[B]6`lZ\[B]eg[dhbd{i_ /

  {Z\[B]ebZ[B]BbilB]

mPhMikmBm]ebfZg\`l~~d`ikbZr`yZ\[ix}xj~dhc^a]}ix-nqG$  Gsr/  w{ib/z[iS^[^ehcxj]g   
  {rZ\[B]ebJZ[B]xj~dhl^a]}B
  :_

B  u5 

xjmm]eZ\g/z(]`lBZhMikbZ\[dhZ:$g   

nqnqMwe :

 `d{h~B~Bg\`l~BgjihZ]a^\[B``fxikbBh6xj]cB]ebd^a]

wrIBBu

]aikZ\[B]eg:BsB{BBG{f`cgGfu$pr[dx}$gnqnjMw :

wr`f]xrbB`cZ}]afixjZMu

ZiSxbB`lZciSxqBbd^aZjik`lbdxBe6Z\[dhZ^ehdxj]/Z\[B]/~Bg`lk]em[B]eg\]
::

nenqffw 



Bsw	nenjw 


w@

  {@zr]^ehbmPhl]/Z[B]hlxjm~BZ\`lZji^6hMkB]`Z\[ixgahl^aZjik`lb
B

`:Z\`k]eghbd^a]l]^aZ\`lgax^a`lbl]eg\ikbB*Z\`

BhZhdhlxj]

nqnqMw :

[dhcxZjzr`mPhMimBm]ebZ\g\`c~f~d`ikbZxe{}hbd)f

h/BbicB]/mPhMikmBm]ebfZ\g`l~f~`ikbfZ`



   :_





izr]/^a`lbdxi]egikbdxjZ]hlZ\[B]

Bw{Z\[B]ebZ\[B]eg\]:ixbB`ci^akZjlu:pr[B]eg\]

nqBBaBBw 

iSx

hbdZ\[B]Phlxjm~BZ\`cZji^~Bg\`cdhiikZj

$ganjnqMw :- w$BB{Bhlxrzr]:zr`l/z}hbZu

bikl[Z_`@Z[iSx]adhm~k]6nqhbd/m6hbfxqimihg:`cbB]x}zr]^ehb^a`lbdxjZg\d^aZew{Bzr]^a`lbfZibB]Z\`PhlxxjBm]
Z\[dhZ-Z\[B]eg\]ix:h6xikbBk]mPhMikmBm]ebfZ\g`l~f/~`ikbfZMu:xzr]hg\lB]]hgjik]eg{zr]5]aB~d]^aZ:Z[iSx-Z`P]
Z\g\B]-ikbZq~i^ehMy~Bghc^aZji^ehMh~B~i^ehZjik`lbdxe{x`Z[B]5g\]xjZgji^aZjik`lb`f]xbB`lZ_x]e]eml]eg\/xj]egjik`ldxeu

  

]bB`ztZ\Bg\b`lBghZZ\]ebfZi`cb*Z\`Z[B]Pg\]cikg\]em]ebZZ\[dhZ

nM wtGuP:xzr][dhMl]PhMkg\]hl

`ldxj]egl]{$Z\[ixxj]e]em6x5Z`]hb`lfcik`ldxg\]xjZ\giS^aZi`cbJZ\`mPhl]l{$^a`lbdxi]egjikbBZ\[dhZZ\[B]Bbd^aZi`cb

  	ff
  

fi

nM wriSx-bB`cZ5]adbB]`lZ\[B]eg\ziSx]lu

}`zr]el]eg{Z\[ix:ci^akZjixhl^aZ\dhMkh6mPhbi]xjZhZjik`lb`(h

md^\[J]e]e~d]eg~Bg\`c]emu:x:Z\[B]``zrikbB]adhm~k]x[B`z-xe{$hbf*h~B~Bg`fhl^[*Z\[dhZqdxjZdxj]xZ\[B]
mPhMikmBm]ebfZg\`l~P~`ikbfZ}`(

ff 

S

d

   ::

   

zribB]^a]xx\hgjik/hMiikbxj`cm]5^ehlxj]xrz[B]eg\]

nM w$Bu

`lbdxi]eg}Z\[B]fbB`zrk]l]:dhcxj]

 
  !"  #
$ %& 'ff#( *),+ .-"
/0213546387:9;46<>=6?#9@=%AB=ABC!9EDBC6F:G#FHC6CABIDB3:=6FKJLFHMC6=646N.JL=O3QPR9@7KG'DB3LCOF;S27!NDB=ABG'DB3:7:9EP'AB7!N.75T(3LM'=646FUG'VG#F;ABM'=6CWI'VXN.CABMY
Z NR9;[.4\9;=ABJKJ8FUM.C6=64\9EABM'=6CO4\9;=6?.3L4,=6?R9;M]['ABCB^QNM.JL=ABFHM_0
:

nek (

nqffwS 

_

w

/n

Bnqwe (

`*a

nqw 

_

w

(

n

@a

Bwa

fib:cdefffhgOiKjffk.l*f*cffm,gonqprdsk.kf*c
t*uffvffv2wxLy]zKy:z:{#|}5}@w~Uw_vffuff}@y]OH@!ff*,!U.ff'#,*,!U.ff@UWy~'{#|y.{*xQ~Uw*|2~;u2y
6@w*Kffy'w_@y'h]}@2{#}X}@(xXy'*@y'yw#O2yUyU(x]ffh{*x:zKy$zw_uyUvhy.~U}.>w#zKy'*y'.ffzKy~'{|ff|ffw*}
@y.{*~;}@(x]~Uw*|2~;u2xQw*|u2xQ|ffKffy'w*@y'2*]w*]{#|}@|ff*y}.sw*]~Uw*|2xQ(y'}@ffy{Ruff
y'|}@@w*vvhw#|}w#!# ]> Kffy~Uww*H_|2{#};y.x*#K~Uw*@@y.xLvhw*|2_|ff};w!#K{#|2*
~Uw*@;y.xLv2w*|2_|ff]}@w$O!,K#*{#;y!2w_}@ffo:y'|2~Uy*O h('QH#6s Off*xLw:};2{#}rffy'w*@y'2*
wy.x:|ffw*}:{#vffv*
 uff}.h{*x:zKyx@{Rh}@ffy$vff@w*y'(x:w_@y]6uff|2ff{#y'|}H{\:Kffy|6w*@{#}Lw*|zKy]|ffy'y.\}@2{}:}@ffy
vff@w*vhw*@}Lw*|&w,2*|ffvhy'|ff*u|2xK(xK'y';wffO(x:xQv&|ffw*}Kvff@y.xLy'|}5{WzKyX|ffw#z(xK}@ffy]{Ruff
y'|}@@w*vv2w|} y&~'{#|w*ff}U{|}@ffyx;{#yxLv2{*~Uy  ]> 8{#|2}@u2x$}@ffyx@{#y{Ruff
y'|}@@w*vvhw#|}];w*_u};y_,y'@y'|}|ffwRzry._y2{*xLy.xQ|v2{#@}E~Uu({#:~Uw*|2xQ(y' ]] z:(~;
xQv{*x;xLy'@}Hx}@2{#}'ff#(%8H   O#W*%!HffHK(x$|ffy'z|ffw#zKy.*y2{*xLy
}@yU(x]u2x|ffw*}@|ff&z:2{#}UxLwy'_y'{#hw*uff}]}@ffy$6H{*~U}Lw*|w#O2*|ffv2y'|ff*u|2x'o{#|2|\{*~U}}X(xXy.{*xE}@w
xLffw#z}@2{#}]O  @!ff*,!U.ff' ]  :ffBff  uff}>w#~Uw_uffHxLy$}:(xv2wx@xQy}@w&_(xL}L|ff*u(xL}@(x
~'{*xLy@w_}@ffyvff@y'_w*u2x$w*|ffy]Lu2xL}ww*_|ff{}& \}]6w#w#z>x]}@2{}]|ffw@y.xLu}$|}@ffy&xLvL}w#
Kffy'w*;y'2*$\z~;Lu2xL}:u2xEy.xK}@ffy]R{Ruffyw#]ff ~'{|&2y~Uw_vff@y'ffy'|2xQ*y*
rffy]yUs{#vyxEffwRzXxK}@2{#}K}@ffy]vffwxLw*vff&2y'|2Kffy'w*;y'2*X~'{#|ff|ffw*}:hy]yU};y'|2y.&*y'@
\{#.,{#}W{\%},(x%|ffy'*}H{y}@2{#}o}@ffy'@y!zr2hyvff;w*y'x,zffy'| 2 Os  uff},}o(x%|2{#}@uffH{ff}@w
{*xL$z:ffy'}@ffy'5}@ffy'@yK(x!{$_y';y'|}K{#vffvff@w{*~;{}@w**y'};ffy'O|z:(~;}@(x@y.xL}@L(~U}Lw*|~'{#|2yX@yU({ffy.
K2{#}(x'_x}vhwx@xQy]}@w~Uw*|2xL}@@u2~U}K{]}@y.~;ff|(*uffy6w*~Uw*vffuff}L|ffy'_@y'y.x5w#hyUyUO|}@ffwxLy>~'{_xLy.x
z:ffy'@y   xzKyy'|}Ew_|ffy.&|t*y.~U}Lw*|h*ffzKy*}>ffw*vhy}@ww&};xX~Uw*vffuff}E|ff
O   L: ] ]{*x]{6uff|2~U}Lw*|w#  {#|2}@ffy'|}H{#_|ff}@ffy}{_x  *wy.x]};wff\|*y'|ffy'U{\O}@(x
xLy'y'x*y'@2{#H  uff}.O|}@y'@y.xL}E|ff*}@ffy~Uw*vffuff}U{#}Lw*|2{:}@y.~;ff|(*uffyw#;>w#(ffxL'(}y'}{\
.*_>wy.x$u2xLy}@(x$}Lvhyw#:v2{#U{#y'}@L(~{|2{xQ(x'5y'w*|2xL}@U{#}L|ff}@2{#}};|ffx_}$|ffw*}hy
xLw2{_6w*:R{Lw*u2x:;y.xL}@L(~U}@y.~'{*xLy.x'KX|ffw*}@ffy'>xEw*uffH~Uyw!ffw*v2yx}@w;y'y'2y'X}@2{#}:{Ruff
y'|}@@w*v&(x'%6w*]u2x',y'@yUw*|ffy}@ww#O6w*~Uw*vffuff}E|ffH{|2w*6zKw*L(ffx]y'*@y'y.xw#:2yUyUEKffy'@y
{hyw*}@ffy':{#vffvff;w{*~;ffy.x!};2{#}Kv2{*x@xKy'|}@@w_vy'|}L@yU*5\|v2{@}L(~Uu({#.2xLw_y>wW}@ffy]}@ffy'w*;y'x
zKy]#*yX|  {*~'~;u2xKy'}:{\%.*#ffO~'{#|&2yxLy'y'|{*xKw#|ff}@(x'ff}@ffy.xLy]};ffy'w*@y'x5zKw}@y'|&{#vffv
y'*y'|!   s
X|ffw*}@ffy'K{*x@xLuffvff}Lw*|{*y:}@ff@w_uff*ffw*uff}:t*y.~U}Ew_|2 X(x5}@2{#}!};ffy:|ffw#zKy.*yX2{*xLyX2{*x5{xLvhy'
~;({26w*@#|2{#yU X * ]: *zffy'@y xy.x@xLy'|}L({vff@w*vhwxQ}Lw*|2{,{#|2 ]] wy.xO|ffw_}~Uw*|}H{|
{#|wff~'~Uuff@@y'|2~Uy.xw# #Kffyw_@y*y'|ffy'H{!}@ffy'w_@y'zKyxE}H{#}@y$({#}@y']@yU({ffy.x]};x$xLw*y'z2{#}.{*x
6w#w#z>x
q|ffw#zKy.*y2{*xEy ] x]x;{(};why  O6 @  .! 'ff U
}2{*x$}@ffy6w*@  ]] oz:ffy';y ~Uw*|}H{|2x$|ffyU}@ffy'_u2{#|}L 2y'Hx$|ffw*vff@w*v2w_@}Lw*|2x'O{#|2 ]>
~Uw*|}H{|2xK|ffw*|ffy$w#O}@ffy~Uw*|2xL}H{|}:xL2w#(xX{#vffv2y.{#E|ff|w*5| ]
\}KxLffw*u(2y]~;y.{!}@2{#}%{$*uffy';5 x5xQvyXw_ ] 8{*xO{*x@xEuffy.$|vff;y'*w*u2xKxLuff2xLy.~U}Ew_|H
}@ffy'|}@ffyxLy'v2{#H{}L~Uw*|2_}Lw*|(x:x@{#}L(x 2y.
]xO};ffyKww#zK|ffyUs{vyxLffw#z>x#,zyXw|ffw*}K{*x@xLuffyXxLy'v2{#H{#}L*ffzKy>~'{#|y.{*x8;uff||}@w
|ffw*|ff@w_ffu2xL}:2y'2{_w*.
w_|2xQ(y'O}@ffyO6w#wRzr|ff]|ffw#zKy.*yK2{*xLy ] w#*y',}@ffyK*wff~'{#ffu({#@ 

 $8H $  ff  $ @  $8H ]  s  $ @U










! #"%$'&($)


	fiff
4

5

+*,& -."

0/

132

-&

76

8

:9

;

.6

KJ

<>=?A@CBD	EFGIH

:N

UT

5N



AV

:N

UT

N

MLONIPQSR



WYX[Z]\U^(_(`+\Ua0bdc+eUfSg^ihQjS`_lkk`h-_lgnmoeUcpc^q_lf-r+eUg0b'eUr_;\Uch>cj-sg;^cte:uvrm^xw-fhlyA\U^;z{0^|'_(c^eUc^;}-j-eU~Q_#\U^;f-rxrhIhQfS^xh(uvrmYeUc
uhQ`qX



fi[S[5%'

od8;-v'0'GI((#v08l(fi-(MSQI;vd0'
  o0dv#Q!'
Gd!]'
UQ7dQ]G(KS;,(5SGK-l(dGE]'S8id(fiv0Q'oo
'(0dv#(-!llE
SK-G((dGvGo;IEfi
0%]08(v5(,(#-v0
'(,0d';v0Q5;S'vS(,fi+v00
fiGd!S0(EG-fi(-,']070(
Iv'-7K,I-(,vG(.G(ddldEfi(0fi3(l''((-0'v0-oIIdG
0v08x0;So!M'I-d-IlG
d
(-d;didv.G-!(8]-vSdd!'
x   

  


;Sod



o

 Q7

 Q
'x0dvG-;fi5

Soox   

8;Gl-G;#5S7;3(v'




dl'7(E-vAIGGv05(vx   
d(-4   

(:A( 




:;A# 

S0o

;Sooox   



(d(-iv'vAG7
7







o





E-:tl 




ff


fi



'((d
(5fi-;>'(



  GI-55
G

 Q7
U



x   

pQ;o;];

,+





 

/



:tQ 

'IGdvd;
o

;0';;;-SGd(5;d

)

U
'v,(fi-(


-

v   

. 


 ox   

-

 o

 (id(;(I7K0G#Q0QxII'l(-0((.dIl;5

.



 (-o

   


 oG-]-vfi!O

,

o(S(fiG-
;77K'vl

  nx;3(v'



-lol

   

  oo



.

l:t# 


3:tQ 


5ld(-iv'vA

d,IGv-(7K;v-vSddK'

 ;lv'x(
 ooxfi(dv;


d(

0

0fi

;-5;->'x(dvfi(;d80((fivId-#Y

2143657198;:=<4>?365@<
4C
D
E
-H I
KJLJM

0d0#fi0((#Q';;;-SGGfi(5';dK(

vinS;ov0dG(('d-Q.SnSQp('i



   o'iU

-(ldvG'

id('7'(8-vG'7'>(v'ox   

(d

  t0ooIdI-(0d(d]G8I-d(-

U
7



(fid8I>G(-v3(

fi-;lv'Ifi'd

UAnppd;ol;-lv'(iGfiI5SG

 Q




it>(;-G;S78(d].;dvSn

(


dvG-(

:;AQ 



d0#fiv I(#(;0(

I'7O
0v'Go77v;(Q'l(fi70G;-

!"$#&%'
*
,+

d(fi;(d;I'S





i;SQG-(

d;(Gl;(;0;dIKGdIG(-v3(5S7'

G

Sx(
;Sooidi(dv;

'l(-#fi(!(;l;0;dvd(5fi-(d!.

dl

S oo



S ooQix';dvG5'ld;'(0

l;d-v0'('-Qv0d0(d00dGd-('(
'(G0d0;d5'G'GU'fidGdid0G;'S7n

;0fivEfi+;v0AI

UG(d'v,dU

	

fi   

GId-I(o0%]0(!'S'xU

 !

  (ofi(;K8lK7


 dId-l;G-l;]-vfid>-(  




;StlS





  t0oodI-(0d(dAGI-


0G#Q0Qo.v0K(K-IEdG30((.d3v0fiv.;(-GI(3(
dQO(v'x   

   oo>

 (-(,5SGK-G((fiv'G8'

xiKdG

GQS';vl

 BA

G7K(

;

'IGdIvd##dG

d




v'Giv d

Kv(ll'xIId(
S#-5'G;-xIIvfiG vldG((v'xI0dv.G-S7vv(G

(

('-Qv0xdoldvdl;d50((fi

v;vSl;G

I;

Ifi#(;.(v'id(dv#((I(

GF

KKdG'(d(v'(K('-Q'v0>fi-;;fiGCvS7OI3(!G-v-v

dllG;08d!(-0'v0

0((.dv,(

(G>lG#fidoGd '7-

'IGdvd;dinI>vl.GK(dl5S7 -

GS7,I((d]d(;d,0((.dv

Sv-l

GQ(
'd',S(-(v';d;-
'#->d

OC

%0vidlo(;'x(;0#fi8d

LN

(G!n' v0-(

BC

*

v0;(dQG-ofi-;-v-fi-El;lv'Ifi'dK(fi

-'('(G(Q'(!';;!'v!fivS7S(dfi!#;7 x-3((#(;0(
(
(Kv'(
'dvd



A-



AQ.xid;K(

SC

'IGdvd;

Qo>OI-d-Svd>('7'I!0G5;'-Adv; v-Ql!-'

-'v;oldG-5-



iQ'l-I

vQ#(dQG-fi-;-

.!nd0]ddGS(5S7''(G(Q(

BPRQ
!"$#7T=',U WV YX 9Z
 Y]

9C

fi-;(v'o'(-,'dod(K(d;fiv'Gv-vSfifi

dvG-0';dv'(GS(-(v;d5;-5;-IdG,dv

OIQ o'v
0dv.G-oo
#-(v'I

   o

 AM

_K`

\[



   o

YX

^Z

[o;AQ]o

 A





*

:tQ 



'v

d;' OvK(-(0d(lGd

fiacb&d=egf@hffi0jgkKlLfLbgmhnpoqdrkKk9fLb
s2t9u=vGs(wgsBxzy|{~}^L=6vG{=}cvG{L}^vO -gK	60y|Ly|Kgff-cE,9vW^GyKt6.G!rcgy|^yKtL
ff4B.cEffv,tM4}wt9SG)LR2.y|y}^gyWt	}}y|0tL4}K=L.y|^LyE}t6}c}^gyEtL.}s2t6.L.vG}.B6ffsBg=y4
60EEt6Lwg{ tL4}wt9SG!^t6}.vzD~W*-4R0gy|yvWtL4}wtGL{=GDtOvG{g6Gy0L.tL.g^vt6}yK
0vG}-g96t6}Wc=v^\~,*.vt9.yLq=vy4urt	sB=Gyvy4t6}yK}ut6sB=Gy(G6~@yK|t	w.y(vG}
vSSw}t6}yKWt6{gL}^gy|,|tL.yWvG{D=v^)L  E,|t6{g{gL},.w=4yE}2=y|}y|sv{gy(=y|Ly|yK0	@y4vGy4
 {}gy|tL.y6}^gy)~{g60GyK=LytLyE6}gys2t9u=vs(wgsBxzy|{=}M~6vG{=})-g96EvMw=v}^y
s(vGyKtLMvG{g!t	Lwg}W}gy({t6}wgy*6R{gyKt6=0L.g|W)y*sw}t9L6v}=vE.L}c	|Mv4L{=}.vG{~w=vG}.&
cgy|{{Mv{g\}^gyD=y|Ly|yD	@y4vGy4B6tzLs(w=t}t6}(vG{=L6GLyK.}xzM=y|2Mwt6{~}vy|4|Y0gy
{gL}.vGL{O6.}t	=vSvG}.2=y4{gyKOy4G6vffvG{=}y|{=yK}=yKt90vG}O}=vRg^L=Gy|sDR=y4{gyWvG}KL0y04.}
{gy|yK}^gyW?6SG60vG{g2{gM}.vGL{D6fftOG9M|||4;7$z6
OMGK$R 49L7$z6.6BEOvBt4L{6-wg{4}vM{6zLs(w=tL|?L(yKtL^
t6}Ms06Ly|2=vG}v{^Gw=yK*y4utL4}.GL{gy(60~,qK-qt6{ff~,q6-crLW) )((@}gyB49
L7$z6	|K?Lz4Wffz$E 6.vG}}y|{B. 9v}t	}v |yc=yK4.vGg}.vGL{c=v(vG{^Gw=yK0ff~W -
vSR  Bt6{~, -.vSR \g
qgyg^L=Gy|s2E}t	},0y(ct6{~}W}Dt9L6vg|4wgEcgy|{)}gy|y*vtOsOt9u~vGs(wgsBxzy|{=}L=D@6vG{~} 
0vG})v |y2=yK4vg}vM{Kg c.w^}t6}v{tB{gy4vGL= L^g~g6( sB~.}W6R}gy(0L.gEt	}.v?MvG{g
EYt6yctL.g^vt6}yK*0vG}(L}gy|R-v |yW=yK4.vGg}.vGL{| {~}^w=v}vMy4Lr}gy0gL=Gy|s 0vG}(}=vv}^t6}ff}gy
4=LMvG{t6}yK60 t9GL{gy06vGLy0w s(vGyKtLMvG{gEvG{=?Ms2t6}.vGL{Ot6Lwg}}gyc{t	}wgyR	70L.g{gyKt6E Lt6{
.t6Mwg}=y|L^y|yKc6R@y4Svy4 )y	vMyt.w=^vGy|{~}4M{Mv}vM{)c=v)|t6{y(w.yK}t9L	v}=v
gL=Gy|s vG{D}gy4L{=}y4ug}c6ffLwgc}gy|My|s2|ff0=vW4L{MvG}.vGL{vy yK4}vMyt6{Ow.yKs2tL^=vG{gy|zvG{
t6}v4w=t69}gyt6=vSSvG}.D}({.	wg}vM{tL4yK40}t6}0vW{gy|yK=yK}Ow.y}gy*s2t9u=vGswgsxzy|{~}^L~
t6gg=tLOvG{t6{~|tL.yL
OMGK$  y|}  yts2t9u=vGs(wgsBxzy|{~}^L=)6vG{=}(6E   E, yt9}t6} v| |
0vG}^yK.yK4}W}E t6{ ffvSB v{gL},4L{=}t9vG{gyKOvG{    E D Kg z)yt92}^t6}EE6
) 6E|z  	q qvSzL0y|Ly|Bs2tu~vGs(wgsBxzy|{=}L=(6vG{=}B2   EWytKMy,}t	}9r R 
t6{O}t	}BB vc^t9?yEqv}^DyK.@yK4},}^2E t6{ 
qgyE{gy4u&}c^yK.w=G}cv}gyELy|OgLy|^}-O6R.}t6=vSSvG}.}t6}00yE{gy|yK
= 9 $= EE/6) D 6(|z  	 ($~Dff   . Eff~
wgE}^gy|Ly|s20vSSRw.y(}gyBtL.wgsBg}vM{!}^t6},}^gy|y(y4u~v.}ELsBy .w^}t6}Kr?Mt9S.w=zx
7^vGy|{~}.s2t9S E t6{! t6^y.}t	=y?M, 0)y*{gL}yE}t6}W}=vW=~yK{gL}vs=}t6L},  v
{gyK4yKt	.vS}gyv |y=yK^4.vGg}.vGL{)tL.g^vt6}yKO0vG}}gyEs2t9u=vGswgsxzy|{~}^L~O	v{=}|-R6RR E,z
!$  L{v=y|}^gy={g60GyK=LyBtLy2Ev{ut6sB=GyB rL7t	{D^yK|t9S}t6}O 
-g96vc}gy*s2t9u=vGswgsxzy|{~}^L~O	v{=}W6   E  zc0gy( v |y=yK4vg}vM{Kg vff~W  -
~W,9-60y|Ly|}^gycs2t9u=vGswgsxzy|{~}^L~*6vG{=}R6  Er?L vtL4}wt9SG K9K K
.B}^t6}0}gyt6gg^Lg.vt6}y qzL,.w^Dt O vE~WW9- D~WW|-














	

ff


fi











 













! #"



%$ 

&

 







'













(*)+,".-0/

#1

32

54













6

7

,

89#:<;=?>A@CBD=E	E5F*>AGffHAIJ;>@CBLKC;,@CMN=?@OLKCGffPQE5;RTS,GVUW@CMX5S#SCGffKC@>Y=?HLHZG[@#=?K\X5SC;,X5HT@CML;,>GffHQ@C;6]L@^GVU=_R`=]QX5RaBLRabc;HQ@CKCG[OQFTODG?X5HQ@
m 9#r%GffKC;sOLKC;>JX5SC;JE5F[tuUG[K,SCBQv`>JX5;HQ@\E5F%SCR`=E	Em =VHZwx=aR`=Y]QX5RBLRabc;HQ@CKCGffOQF%ODGVX5HQ@pm G?Uzd0D
GVU!d0D
ef gihkj_l UG[K`np
m o
q
ef gihkj_l
n
y
0
h
}
j

|

~

t { ;>G[HIJ;A>@CBZKC;@CMD=V@s^K  ef g lCW yL
m  hkj 0{ ML;KC; 
X5S=?H<GffON;HSC;@k@CMD=V@s>GffHQ@6=X5HZS<y m PLBZ@
{ X5@CM

HLG`Gff@CML;KsR`=Y]QX5RBLRabc;HQ@CKCGffOQF%ODGVX5HQ@aGVU!d ef gihkj_l 9U#@CMQX5S0X5S_X5HLwL;;w@CML;a>Y=?SC;fftW@CML;H%@CML;aR`=V>JMQX5HL;KCFGVU#SC@6=?PQX	E	X5@\F
@CMN=?@

{ ;=?KC;=?PNGffBL@s@CGX5HQ@CKCGQwLBL>;TX5SsBZHLHZ;A>;SCS6=?KCF[tS\X5HZ>A;X5@kMZGVE5wZSsX5H=YE	E!>V=?SC;Ss@CMN=?@
MN=ff;PD;;HpBZHN=?PQE5;T@CGTOLKCGVff;@CMX5S9

Q

{

;HZ;;AwX5@9skG {

;ff;AKt {

;

fi!z}Z!0zD

%TT<DYNV<?LVcffW#*WLD#DW<D#&WLffYu#&ff%CW`upff
VLWffu&QuVQL`^ffffV6u[Qp?[D?%Vc`VLYZ#T%QLWuuYu#Z
ffW#ffQLTLQZsV#D*WLffW#5TffVL?LDLVYQcZ?W#AYu#ZkCWVcaA,
Wuc\#ffWD?WQD#ffTY?Zc}ffW#JcQCWVcW#J}WVV#D
WffW#ffDD#WC#DVVLucQDVLQ_QLcVQ<ffW#ffQ%?#DDVWpTc*cV
WYDDW#Q#V<ff#WDffD!LCW[i!\CD#Q

Qp^<W<QTD0NDcDLD#ffW#ffDffQ0

uLk\,`



DWQ



D#cp


	

fiff

(ff )$* ! !!" % +,ff )- !!!.# %
0/21

WTQWQVVLucQDV

ffzWffYWD

 
3



[p,ZCWQQQff5,\ D


 !! !"#$&%'

W#D#LffWD#ffWD0CWVcW`#?V#D

<DDY



W

D#3 u`QWQV







ffW[Z#

TW`ffWD#ffL

c`ffW#AYVQZ

W3Q?xLVffYYu#A3ffVQ#?`VDDkDVW_V%ffW?ffaD!LVYQcZVW#J
W#ZCWVcW0V%?`WVTWQQffZ!QV#0%_V`QWY`D

VWQ

W[QYVffWDA#ffff*ffWQVL?ffWVQffW3Q?

fi3


Zffz?#JW#ff#D#YuW

54

sLDWk

ffW[ZLD#*?cc

CWVc

64

#?V#


64 87 94
:;=<->,?&@"A 


B4

	

WY#V*CWVc

ZQ

WVV#YLDVVQZucVff#VJW}JffzffQ%TV?D6ff[^TDV%VQVL?L



QDuQLVffW

	
IHKJLEGM

DC

DWQWaLVff?pu

FEG

Wxffu#VV#ffW,*QffW#JcQ

N

VL^Lff%V

H

uQVT^ff#VQx

EGOM

%06#VcffcDLVc*LD#T?#D
ffW3Q?xLVffYYu

Q SR T UR

V

AD#



D  D

 /



Q?QaVW#Q?L!Vpffu#[D[_&

DVCWV

k*?c%Q#DffDTV

V&ffu[NVL?cffVYffW#ffDffa.




P



VVVQ`#V[

V#DWDW#DVVLucQDVL

VPQUR WT XR

 uLW?<VffW#[D^Dcff[TV}



WDu



Wi   DQ

 W#ZD#?#QVQV

Z9Q SR #T UR

VffW#ffDffDV W#N<V}LW?uVQQ[D#V}!



  D

\[ /

L

NY

`cV}D

`cVffW#Jc[D

WDWWC#DVVLucQDVL3A#?#%QVQ?L<?WC#DV



VW^QVLWVQ%?#D u#ZAD?
ffWQVLVffW

	

D#&

,TsQYu&ffW#Y[D

`c?ffW#Jc[xV&ffuDA#ff[3D

V#QVQVLDDVu

ffuDA#ff[D

upYQpDffu#[D[`T

DWQ<YQDkffW#ffDffsQD#%LffW^L

`c?ffW#Jc[Dp?ffWDA#ffffD

VY

`QVc*V



WffWQVLVffW#NuQpDQ3AYQpDDDcDLQ

6

3 !^p%QsD!ffW3Q?

* uDZQVVuc\#ffW

Q`ffW#Y[D[TD#3 ?Q<NcDLT

	

`CVQNDYLD#ffu#[D[DV

u#D#QVpD#?W#W?W\ ?QW,c WDZQVuuY

#ffWD!ffW3Q?pLVffW#aDWQs
LVffW#DWQ

W3pDVV[V

L?ffW#<D?<V



ffu#[D[ff[T%TuWLVL,,V#D?#DVD#?

^] _
gf

ffVQ#VWWD

F`ba ced

u`Vc`?#W^T<ZcffVQ#

CCWpDVW

QDVW

VVQWD&ffu#[D[Q

h`ia ; d

D#ff#

, upLVffW





6VWffWTDV<?VLDLWVD?%#uWc#Z W#Q#Q#QLsV#D`VVu#D

6j /

V#DffW#[D

kfmln
6fml9

VDcJ#L*DVW

6j /

V%Vu#D?#D

%D#

VDcJ#L

jPo

V#D`ffW#ffD

Ofmlqp

pVcJ#L

OjPo

%D#V<?W#DV#

A#*V<V#ff`D

f=lqp

p?DcJ#L

N

r 	


sfmln )j / =Js! !!tJf=lqu )j.v
5j / ! !!2#j.v
w"xzy{| }2~#| W0qq).|  }2fi0b-~#qW0z0p 2}".q6~.Sq 6q=~.2P-20WyO-~#b.=P0t0|}0 )= =  p " b.
-~#q^W "#"| ^W ""000|}2~|W0qq2|P2y
uLk\

 uDZQ?

WffuQVLVffW

T







TVuDDcDL`#D?#DV

%CCWuc#ffffW#ffDff





<D#CW^D

fi6XtUb=UUme 
 Bfifi=^tU


b q  b  Uq$
n
  "-6  * tPP   t  B   " U -  -"=- B
 =5P    Ui    P   h U "  " t  6  " t   .-^      
  UqU -      -   tfi    6    5U #-     ' " t   q    t       " 
    fiU5qP ." t  U "t   t        -   fi  Uh  "5"       U  (.O"-  8 9&
 #b     -"   =       .O"-  6 9&   "   U     t5 "           
 "             Ps         U          t ^   =&tN   F  N     t   
"-        q D   	      U  ff
 
  fi    #=^    U .     -      
  t  -      "      " =  t  -     .^    O  D&      .  "    5"-
      ff!^          t  (.  " #"8 "  5   " &   8 DS     " 
 &')( +*, 8"    t5 "  m "         - 
.  "= - *     &      U^ % $  & "     ff
  P5=    .   8-" P     "   t    ) U.  " . -  t b"   5U   
  fi   / =
"    q   tP     " 5.  "     5U   "    -      t-     .  "       *       
     " .  "   -   U " -  & -            1 0 -#   " PBt  t      .  "
   "  "    5 .  6 .         -   0  .56 U
- =       ="-  "    5  t        U "  "   "   5P " 2 - "     
" ^.  "   - tU  UN  5t&  t             "   U .    -  1 0 t         4325 
  6   N + 6   P  .-  #-.  b" 5      U  D         P    "5"     mt
   =    P "#    "U    *   "          -" =    UqP ".         
     U   " =            .- b       b.-b"     "       ""   6     6       
 P      -"    5U #-      " t  . -9 n    "   t&h + 6   P  N  5U   U " 
  -   =   t6-,. ' + 6   P  .  "            PB  ^  U ) U    fiUkP "" 
  U "  "t   t       87    49;:U

<>=@?ACBD?EGFHJILKMON2PRQ TS P *U>LV*WJYX[ZT*@\ff PRQ  ^]`_>a S P * Pcbb	P  Q d*eJ!fg b  Q ih P
jR@, P \Rk P Sl* b	P i8X Z ,.meon	mp bqb	P fL*)*rS	 P ,. Q ms Pcb f P n QQ Bt NuPDQ[v S PwQ m PwbPDQ xYn bQ * QJb
*fef P *UJgk`J
 yYJ ]{z b  Q mr* Q  a n Q *i b C P x Q m P nU b	Q * QJb i v}| *UC\p PRQ#~/  S P
Q m P >g+*px e>8   a t8 bb r PQ mr* QQ m P  P`P	  b	QJb * b  P \ Pcb nc!f Q o 3 5 b gncm Q mr* QJ 
*eJ p    *C\   * PbQ *S	 P  3 5  *UC\ Q mr* QQ m Pb fg*en P[e  O m* b *wo	 P ff*  J>r '
P  Q )ffLi Q   tW2m P 
fi   3 5 _ \     e  
 r  
 )

  fi   ^b
 L      e  

  Q m P \ P C>JC* Q  b fg b  Q ih P t
7  O "   W3 5 O_  -       t  fit    ff3 5 O_       & -S.         q 
  "O. 6 6 9&   " P
 
fi   3 5 _     "        ='  N   .   &   " 
-="O. 6 O 9&    "   5U   "          "    ^  U       U "   
6U " D -  -6"    -   .-"  q fit  ~/  U     .  "             P  
   mtO    -S.  q = -            =    "       "^ t n t 6 . U5U
    - r%dc P C* Pcb    "  .  - P     t   " Bt  # t    t            U
    P   

R

fi[LLCLLDCOLLYLL[LLLg
T+1ff)iO)L	el	RO)	L)Rx	Y1e+C		L	D+1Rx1e8/L	e)	1ee1xx++
erLff	le#)Rx)xix1ecL	)i#LffeLRx1eYl[xeff2)LRx	Y%1rx	LRW)qeff
L)	rDD1)LeLepDeL		81>)>pwlRU	/e1x1e1e+C	x1We)
e	L	ul)LeLR#)Dex)R@8O1RDeO1e	L)e1	L	)L	xl
x	Ue1x1eOix	/eLxeLlLffrVC	UrO)Rx)DeYe})
D+11LYe1LlYL)Ri	lR1lL>#ii)xL}i)LqLLR)LLgRx1e2
 ff2[[#@#e L U
Le oexiLff	lLgY R.eff1	)x	d)Ld+LiLe @D1	R@oe
	e	xilL	iLeR #`)Le)L	U@LeLL+i	x1epYr1>L	))effi#+1>1)R
)>L) rL1ReeR	 )i)Rx)R)x	xiD T+1ffLeDe )L	)	)
)iO 2R 	R@u1OOL	e	8l1RU)L>e1LYU/x)8W)L	e)	{ei  @
exR)L))#1i	
	)D11LeL>)LlR)LiLRRxR`1p)iU		p>e	L	D+	R1e+
i	x1ewLY 1`ilR@e>>Rw1l4L	qx1xL)Ri	)effx	>L
D1eL)>)LLex1e[)ew/ULY	L	oe)lL	e)	  eRx1e L > `)L
L).L	e)	 L e i)l>1ReWR.1ff%r)11>)	/wULRx)Rx+	
 L)e)x1eL	DeL oL)L)Ri	)Rc .e	pei	x1LY)l	#e4>We)
1rlw	 )LwL)e1	Yx		 d)>iL1e L)`iLeUee.)eYU)ffxo/%
	x)L	ff)1ff1R)x1Lx1el[xLffYUx1		e	lr)1L).>1e[% LffeL
eYW	W	r#1 }ffL  [Lei	OiLeUe1)Y1L11lffL)Ri	)

8eL	)i#iLe1l1V1)L L	))1 
Li1Lff+
)L	)pRe>o)e 8l  s)iOiLee2)L	)ffl>1lsY4Lle	)R})
YDff%))LOe#Dixq%eLffeY1	ff	R eff1eL)L)x	)x1e lLLg e
L1er%e `)>LL)R)11w18)L>iLeUedeR) >	@18	))8)L
eYw1	ff	e	e1L>)lLL)	)x1R#)L	Ylxioeeei>L	RwlqL1)1
Y)	 LL))L	lffe)e1 	p%L) x	V1 o e11WrxD+eL
/x l	x18elR1	 R)pLLlxiR 2	)	r	#x o	Lle	)Rc	
1ffrx#eLcrD+2)LOLgRU) 	 2	)	 LLxqlx1x1eYUeYD1w1	ff	r.1)ff}l
Lq%	ff c)eY Y R+1)x1px	xe >i>e	)s)8x	L)LeiwL) )
	eDeR@/LffYx11L>ffL.rw+ixx1LlLLq%	U[	W	r1)`x1e
L)e%	)x1R	@	)11d.L	)e
L 1x>L1LqffeL)	rl)eO>)LL)R	C1eL	 x1xL)Ri	)R
ixLL))RT^)RWd) O)e	D1 e  T)i%	4DepxLT)
YD1>L{	r)lerp	pYwd)rUoeeffLLL	)	R+11 	)	exR	%+
)L> e1eRe1wL)wL)Ri	)R	  O)e	 C e xLl)L	)	%
e	L	D[effLLUx1eD.)R)LiLff)eWLL)ff	e)	RO[%V1q>De>Le oL)
L)Ri	)r>U1)LffLL)	 21LY	e)	R#+1.l	ei1e1
LRliL1effi)ReL)e	`1)LeLxUxixxi	D[e)x	)p)LiLeUee2 1
effLiLoeY1)R LULeeRWOx oe	1eU ee#1`iLe
1)LeLwRD+xT1) e1^	L) ox x+	YLRxL% e 		+q)L	liYeff
e	L	V1	RWe	1eWYD1qL 	rl)eeD.V+@lL	[g)l	ff1qlRx)xi)R}1YL+i	x1e
eV+.x1R)/WeffLLD)
  






	fiff





















 

!





"

#

%$

&

'




)(

+*,.-0/213

4

8-

#

913 ,

fi:

+;

7=

<

-

<

+:

?

;



2=

#=>



@;

B;

5*,6-0/71





7

A=



7



2

C7D

FEGEG H I

 7D

JEGEG ?

#

KML



7

#

N.:

8

OFP

fiQ%RHS?T#UVWYX#ZF[GUGR#\0V^]`_aSbZFZJUGR

cd&egf0h)i?jkfilJmf0h
nYo?prqYs3tsu'v%o3tGqYo3txw&y.zY{,|gt}6{Gvfiy2o#v7~3q6yAq'nYo#u43vq6y)pqay7{uFq6yAt?prq6ot{G##uFy6p{G93u'y6zYu'u'9|gtJ#
p|~#|!u'y2v7{Gs?t3w&y2o#uvAt3w?{x|zY{Gv6rw#qYts#s#v7{tG2o&{Gv
tqpG?pM't?y4vAtG|u'?y{{G~#vYrt#G~3tGuG
{G#utv4v6pr2o#u'v+y7o3ty2o3ty{x3qprw?u'v7uFw>tvpq4t3w>u'3{Hqt>AFxG?{Gv,Go3tGq6y7v6p)AFGGHA%nYo#u
q6uF{G3wprqYy7{gq6~#xGuFq6y%y7o3tyaq~37otv2uFq6~?y%prq~#?pGu>y7{{G#yAtp&{Gv%y2o#u4~?^t#G~3tGuG
nao#utGy+y7o3ty+zuo3tJGut9{G##uFy6p{G3u'y6zYu'u'|gtJ?p|@~#|u'y2v7{Gs?t3w>vAt3w?{x|8z{xv6rw#qpq
qpG?pM't?yF
b{Gv%{G#u,y7o?p#3bpy+tJ{z
q%~3qy7{~#ypp'ugtJy7o#uy2{{rqy7o3ty%o3tJGu+u'u'w?u'Gu{Gs3uFw>{Gv
{G|s#~#yp#|gtp|~#|u'y7v2{Gsu2pu'?y66q6u'u2
{rw?|gt0YFx?Gt3wy7o#u~#v7y7o#u'vv2uu'v7u'3uFq
y7o#u'v7upA?t3w,|gtJy7o?~3quFtxwy7{+u2pu'?ytJG{Gvpy2o#|gq{xv{G|s#~#y6p#@w?u'Gv7u'uFq^{M3upu0{Gvttv7Gu
2rtGq7qY{#{zYuFw?Gu+3txq6uFq'tGw#wxpy6p{G03|&tJp|~#|u'y2v7{Gs?prqY#{z%9y2{@o3tJGu4|gt?gty2y7vAtGy6pGu
s#v7{Gsu'v7y6puFq&.xtF?#uFq'%J??A%~#vv7uFq6~?yq6o#{z
q,y7o#uFq6u&s#v7{Gsu'v7y6puFqtv7u9q6o3tv2uFwy2o#ugvAt3w?{G|
zY{Gv6rw#qts#s#v2{tG2opy2o#uw?{G|gtJpz%o#u'v7u>y7o#uFq6u9y6zY{ts#s#v2{tG2o#uFqtGv7u'uG3w?u'uFw%tGqq6o#{z%p
.YtG'2o~3qu'y@tJ)FGbAy7o#uvAt3w?{G|zY{Gv6rw#q+ts#s#v7{?tG7oo3tGq+|gt>{%y7o#uFq6us#v7{xs3u'v7y6puFq{Gv+y7o#u
~?Y#{G#~#3tv73^rt#G~3tGuG
%y7o#u
{xy7o#u'vo3t3w#t+?~#|3u'vfi{s#v2{Gs3u'v7ypuFq){0|gtp|~#|u'?y7v7{Gs?Gq~37ogtxq^pyAqfiw?u'su'3w?u'3u
{Gy7o#ug2o#{pru{)rt#G~3tGu&t3w>pyAqp3t?ppy6y7{9o3t3wxug't~3q2tJfiv7uFtGq6{x?p#ts#s#v7{Gs#vpty7uG0o3tJGu
3u'u'Iq6u'Gu'v7uv6py6pr2p'uFw`.^uFtv6JGG#,
{w#q'|prw?yu'ytJFGx?A%{xyq6~#v7s#v6prqp#G,y7o#uFq6u
v6py6pr2prq6|gqts#s?y7{vAt3w?{G|zY{Gv6rw#q,tGq+zYu9!wxpq2~3q7qp{G{y7o#uFq6u9v6py6pr2prq6|gq')t3wzo#u'y7o#u'v
y7o#u'&v7uFtJq6o#{x~?w3u,Gpu'zYuFwtGqq6o#{Gv7yA{x|p#qY{y7o#u+vAt3w?{x|zY{Gv6rw#qY|u'y7o#{#w?prq3u'G{G3wy7o#u
q7{Gsu{fiy7o?prqs3ts3u'vFy7o#u,py7u'v2uFq6y7uFwv7uFtxw?u'vq6o#{G~?rw{G3q6~?y.YtG'7o?~3q4u'y+tJfiFx3GuFy6p{GG
{Gv
t,|{Gv7u+y2o#{Gv7{G~#Gowxprq7~3q2qp{G{y7o#uFq6uprq7q6~#uFq4t3w9tGw#wxpy6p{G3tJv7uu'v7u'3uFq'
u93upu'Guy7o3ty{G~#v{G3qu'v7typ{x3qv7u'?tvAwxp#y7o#u&p|pyAq{y2o#u{G##uFy6p{Gu'y6zu'u'y7o#u
vAt3w?{x|zY{Gv6rw#q,|u'y7o#{#wt3w|&tJp|~#|u'y2v7{Gs?tv7utq{q.px?pM'tyFnYo#ux~#uFq6y6p{G{%o#{z
zYprw?u|gtJ?p|~#|8u'?y7v7{Gs?ts#s?puFqpq+x~?py7u,p|s3{Gv2yAt?yFtJ?p|~#|u'y2v7{Gs?9o3tGq43u'u'?tJp?p#
s#v7{G|Bp#u'3u&tGq
t&|uFt3q%{w?uFtJp#>zYpy7o~#3u'v7yAtJp?y63{xy7o>p4t3w9{Gy7o#u'vtv7uFtGq'4%{zYu'Gu'vF
y7o#uwxp9~?ypuFq{~3qp#y7o#u|u'y2o#{Hw{G3u>zu9|{xuy7{#{x#~#3tv7s#v7uFwxpr'ty7uFq9qu'u'|#{Gy&y7{
o3tJGu3u'u'~?ts#s#v2uF2pty7uFw&v7u'y2v7{q6suFyF0y7o?prqpq#{Gy+y7o3ty+o3tvAwy7{9u#s?rtJp0^ptJ|{?q6ytJ
ts#s?pr'ty6p{G3qYzo#u'v7u+|gtJ?p|@~#|`u'y2v7{Gs?o3tGqu'u'9~3q6uFw>.t3wBz%o#u'v7u4pyAqYts#s?pr'ty6p{G't&3u+uFq6y
}6~3q6y6p3uFwpy7u'v2|gq%{fiy7o#uvAt3w?{G|zY{Gv6rw#q|u'y7o#{#wy7o#u,#{zYuFw?Gu3tGquprq4w?uFq7v6p3uFwpy7u'v7|gq
{~#3tv7&s#v7uFwxpr'ty7uFq{GvFbuFG~?ptu'?y6G~#3tv7&~#3y6p{G3qzYpy7ot,3?py7uvAt#xuAfi#{xvu3t|s?uGbp
s#o?Hqpr'qts#s?pr'ty6p{G3qzYugtv7u,p?y7u'v7uFqy7uFwpq6~32os#v7uFwxpr'ty2uFq@txq+G~3t?y7~#|q6yAty7u&.qu'u.4u'??pGo


4u'??pxo0FxG?7A5p|ptv6G
%ts#s?pr'ty6p{G3q+t3w&u#s3u'v2y
q6#q6y7u'|gqYy6?s?pr'tJ>~3q6u+{G?9~#3tv7

s#v7uFwxpr'ty7uFqq~37otGq0q6?|s#y7{G|&q0t3wwxprq6uFtxq6uFq)7fio#u'uFq6u'|&t0JGG?Auq6~3q6suFyy2o3ty0y7o?prqpq^#{xyt
tG'2prw?u'?yF#t3wy2o3tyw?u'u's&s#v7{G?u'|gq)zYptv6prq6up&|{Gv2u%Gu'#u'vAtJ0'tGq6uFq')nYo?prqfis{q6uFq)t@2o3tJu'#Gu+y7{
s#v7{Gs{G#u'?yAq){0|gtJ?p|~#|`u'y7v2{Gsqp3uG#u'xu'p{G#u+tG'u's#yAq)y7o#u|gtJ?p|~#|u'?y7v7{xss#vp32ps?uG
y7o#uYwxpq2~3q7qp{Gt3{Gufiq~#GGuFq6yAqy7o3typy^|gtJqp|s?,3up3ts#s?pr't?uptYrtv2Gufi2rtGq7q{p?y7u'v7uFq6yp#
u3t|s?uFq'

fi% hfi5m



dGffl7f0  i?mf0hd

?MJ30fiAH&fi+G&H&A3	GJff
fi7
'?'7@
37A?4A#
'A#%9
$ rM3	AGJ'


&'





A!"A#'?rG'

fi()#*#+,.-0/1,#2#3+4)#*#+65ff)#7#89-:#-<;=*#>#2?,.@BA

CEDFGF!HIJLKNMPO#QBRSO#QTRVUWQXKYZK[UP\^]K_^`ffUWabBc!Med	QaWf<gihkjmlnUWQobBcpKqrs\^]TbT_tK"csUud	QaWfors_vbw\tck["bxc#Qcs\v["b_
d	QaWfkyLJKpz!aMPUoaWK"c!bBfK

]TbBaP\vbB{s_^KM|\}dNc#K[KMWM~bBaW`uMPQUWO!bBUib_}_]TbxaP\vbB{s_^KMir!MPKL\^cSgbBaWKk\vMPU\tc![U

 \yKy^c#QoURuQEqr!bBcsUP\}z!K"aM"\^c![~_tr!\^c#p#aWQQaWUP\^QcpK?#a~KMWMe\^Qc!M"sK"]K"au{s\^c!pUWO#KMWbBfiK]BbBaP\vbB{s_^KEMP`sfi
{!Qx_y
JLK

c#K?UpUWabBc!MdQa~fg%\tcsUWQ1bBcKqrs\^]Tb_^K"csUoXdQaWfors_9bgVhjmnu
 uRO#K"aWKb%bBUod	QaWfors_vb

\vMpQc#KkRO#K"aWKc#Qqr!bBcsUP\}z!K"aM

 \tc![~_^r!\^c#V#aWQQaWUP\^QcVqr!bBcsUP\}z!K"aMiO!b]K

R\tU~Os\tcUWO#K\^akMW[Q!Kb

[Qc!MPUbBcUmQa]BbBaP\vbB{s_^KQUWO#K"amUWO!bBciU~O#K]BbBaP\vbB{s_^K  MUWO#Kqr!bxcUP\}z!K"am\^UMPK_}d{s\tc!#My



QUWKUWO!bxU\^c

UWOs\vM

UWabxc!MedQaWfffbBUP\^QcpRuKEsQic#QUa~Kqrs\^aWKXUWO!bBUgo{!Ko[~_^QMPKGym_vMPQ!.Q{!MPK"aW]KU~O!bBUubBUWc#KM~Mm\^fis_}\tKMwUWO!bBU
UWO#K"aWKEbxaWKc#Qic#KMPUWK%qr!bxcUP\}z!K"aMy}
JLKsKz!c#KoUWO#KEU~abBc!Med	QaWfffbxUP\^Qc

{`p\^c!sr![UP\^QcLQckUWO#KoMPUWaWr![U~r#aWKEQBdg#yuO#K"aWKbxaWKEUWO#a~K"KEKbMP`

MPUWK"!M
6 dgE\vMbBc

r#c!qr!bBcU\z!Kd	QaWfors_vbM"sUWO#K"c%gXg#y



 gBigBXgB 


W gB^X

ffgB 

 gsy

__UWO!bBUaWK"fffb\^c!M\9MU~Qff[Qc!Me\vsK"aEqr!bBcU\z!Kd	QaWfors_vbMuQBdUWO#KwdQa~fgB	^ gT	^ !QaogB gTv? y  U


UWr#aWc!MmQr#UuUWO!bxUUWO#KEMWbxfiKUWabxc!MedQaWfffbBUP\^QcRQaW?M\^ckb_}_UWO#aWK"K["bMPKM"y=JK\}_}_^r!MPUWabxUWKUWO#KUWabBc!Med	QaW
fffbBU\tQci{`X_^QsQ\^c#ibBUmUWO#K["bMPKRO#K"aWKg\9MmQBdZUWO#KdQa~f^ g  ^ ym`oUWO#Ku\^c!sr![UP\^]KOs`QUWO#KMe\vM"sRuK

["bBcffbMWMPr#fiKUWO!bBUg  \vMbBUy#QamUWO#K#r#aWQMPKMmQBdZUWOs\vMm#aWQsQBdRuKsKz!c#KNbpWx	ud	QaWfors_vbUWQX{!KbBc
bBUWQfo\v[d	QaWfors_vb

 \yKy9!Qc#KoQBdU~O#KEd	QaWf

 \yKy^Qc#KuQBdGUWO#KmdQa~fyGK"U
bBcs`ff]BbBaP\vbB{s_^KX\^c
 yGK"U


_^KbBaP_^`





nBW Z{!Kb_}_!{!bMe\v[MPr#{sd	QaWfors_vbM=QBd!g  UWO!bBUsQc#QUfiK"csUP\^Qc

{Kbo]BbBaP\vbB{s_^KoQa[Qc!MUbBcsUMP`sf{QB_c#QU\tc
 UWO!bBUu\vMfiK"cU\tQc#Kp\^cg  y

fr!MUQ?["[r#a\^cMPQfKE{!bMe\v[oMPr#{sd	QaWfors_vbpQBdgBvGMWb`

\^U\vMKbMP`kU~QMPK"KoUWO!bxU 
 

 ~b#aWQQaWUP\^Qc%d	QaWfors_vb#QaNbpqr!bBcU\z!Kd	QaWfors_vb

nBW Gy

["bBc#c#QUfiK"csUP\^QcbBcs`

nB~ Gic#QUfK"cUP\^QcbBcs`

 

 cQUWO#K"aRuQa#M"c#QUQcs_^`sQ

Z	ym`kU~O#K\^c!sr![UP\^]KpO`s!QU~O#KMe\vM"

]TbBaP\vbB{s_^Ko\^c
 bBc!MPQ!{s`[Qc!MUWaWr![UP\^QcZ\^U\vM\^c

UWO#K"`bT_9MQ[QcsUb\^cbT__Q#["[r#aWaWK"c![KMQBdUWO#KpQUWO#K"ao]BbBaP\vbB{s_^KMffbxc![Qc!MUbBcsUM"y

]TbxaP\vbB{s_^Ko\^c0
 G{#r#U


QUP\v[K

UWO!bBUoUWOs\vM

bBaWr#fiK"cUdb\}_vMw\dUWO#Ki_vbBc#r!bBKff[QcsUb\^c!MXbBc`Os\^O#bBa\tUP`#a~K\9["bxUWKM"=\^c![~_^r!\^c#Kqr!b_}\^U`y%#Qa
UWO#K"cg 

fo\^OsU\^c![~_^r!sKkMPr#{sdQaWfors_9bMQBduUWO#Kod	QaWf

Qr#UM\9sK

 nm

Ru\^UWO

QBRE_tK"U
 

 

  W QaE

 ZROs\9[~O1["bBcfo\}]TbBa\9bx{s_tKM

U~O#QMPK\^c
 y}
n W Z{!Kb_}_#UWO#KE"bBUWQfpMWuQB]K"aZ
RO#K"aWK 


\9MK\^UWO#K"a


Qa

 


y



n W   yuO!bBU\9MBRK[Qc!M\9sK"abT__sd	QaWfors_vbM

QBR[Qc!Me\vsK"aUWO#Ko\vMr#c![U\tQcZ

 

 l

 
n



^ g  ^  



uOs\vM\vMMPr#a~K_t`Kqrs\^]Tb_^K"csUU~Q^ g  ^  G{!K["bBr!MPKpMPQfiKi
for!MPU{!KUWaWr#KyEQBRK"]K"a#\}duRKibM~MPr#fiK


\vMU~aWr#KZRuKi["bBcMe\^fis_}\}d`9 g  ^ {`aWK"s_vb[~\^c#bT__uUWO#Ko
MPr#{sd	QaWfors_vbM{`



?mQaZ"""b["[Qa\tc#XUWQE
y P QU~KU~O!bBUUWOs\vM=\vMub_}_^QTRuKoQcs_t`o{K["bBr!MPKUWO#K
sQEc#QUfiK"csUP\^Qc


 ^ g  ^ [Qc!Me\vsK"abx{s_t`y
bBcs`]TbBa\9bx{s_tK\^c6G
 yuO#KuaWKMPrs_^U=\vM=UWO!bBU=RuK["bBciMe\^fis_}\d	`oKb[~O|\vMPr#c![U  


n P   xUWO#K"aWKR\_}_{KEc#Q [Qc!MPUbBcsUM


c

d

b

[

U
#

!
{

K
"
[
x
b
!
r
P
M
o
K
B
Q

d

Q
#
r

a
#

W
a
"
K

]
^
\

Q
!
r

M

Q
!
{
P
M
"
K
W
a
B
]
B
b
P
U
^
\

Q

c
x
b
!
{

Q
#
r
U


UWO!bBUEbp!bxaWUP\v[rs_vbBa

Qai]BbBaP\vbB{s_^KMQr#UMe\vsKV

_^KdUpRu\^UWOs\^cUWO#K

#a~Q!Qa~UP\^Qcqr!bBcsUP\}z!K"ayuOs\vMp[Qfis_^K"UWKMUWOs\vMiMPUWK"1QBd

UWO#Kw\tc!sr![U\tQcZyEB\^c![KiU~O#KEQUWO#K"aqr!bBcU\z!K"aM["bBc%{!KoUWaWKbxUWK
aWKMPrs_^Uy



Me\^fo\}_vbBaP_^`ZUWOs\vM#aWQB]KMUWO#KbBU~c#KMWM

fi?s#u##Z=.

e#BVW^ u
 W
#
	 Bff#
	 BfiB
 x!Wxi WB#!#"%$&('()
'!P*,+.-%/012B"43G"5*768+.-:0;
9 ! 	#% <=?>@^"pW8*=#^# ACBD^(E	#
Wx
 B
 
^ i@F
$   
^ #GH"JI&"LKM
> "B5#
' W&
' W
^&'B
P^* 6 Nm@Z	#O	QPSRTPVUXWY=Z	#"W[P
 \P U B
B
 ~Z!
' @Js
B #&5u
 @
> "MB
 :#
  =^ 
^ ]L#
' W&
' W
^ =
" eV&  ^=P U SJ'JB2#
' W( @
B
 Z#
  =t _t :#
' W&
' W
^ ` Z#
	 "WX#
	 '#
B#
' W( Z
 @
a " ~!
 I@b"S
c WdP p	B
 
^  p^  B
 W A
 Z B# =t _t Z#
' W&!
' W
^ eB#5^ 
J'JB&^ (E4BfP U ^gXZP U%hji #
	 "AP ePk^
 P #
B
	 [ 5NlPmRTP U W Y N[@#
 W=B
XJB W#
 &"o
n dB
 %#
	 "Wk	 WW'& X#
	 d &'x
 
P 
BT`VPVU hpi bFqD`VPRrPUsWtYFu#PVUev i b"D$@J5XB
 
JB&
^ uB
 ~'N= w%
 #ECB
 W A &'x
 
P TB,B
 
kx(#
' W ^ %@
 #
	 [ zyF`VPSRTP U WY
b{uP U v i "
|#
	  #k?
x  W'4
 WW"
^ W#]s
 #
	 B
 5#
  =^ 
^ e#
' W&
' W
^ 2^ 1W"o@}x
 W&5
' W&
#
' W
^ tV
" ffx
 CBT
	ff#
' ~&!
' ~
^ fi~J~ * U ~N~ u
^ #
	  5N* U NA
 s@^  B
 1 &5t x
 
^ @

2`YbF	 Z#
' ~ =Nx
 W e+jB
 8Y:+.!
 "m|	C.
^ #
	 e	 55*@Ug
  <=J>]^ "sW=
#
  
^ 



O ` 0 `Ytb:u, %uw
`YJObb
^ Z#
	 "~  &	T Y B
 TB
 W& ]
> "x
 Q hz Y  YJZ&"

|S#
	  P 5=#
  kB
 ~e#X?B kxJJ
> B
 p
 #
	 dP B_N
 WW x
 S=N 
^  >@B
 
@^  e&S
 kt (E
^s
 !
' "s
 "s ^{P 



~N~ * U ~J~ hff
~J~ Y `b~J~ 


 Y 0
9
n 5!

' "_ 	
 W'& "  &	##
' W=!
' W_t kx(#
' W t {"d(#
 W#
	 "iW&^gB
 B W"P U ^ 
 1kx(#
B
' W ^ 17
 #
	 	 PRrP U W Y SXX!
 f##
' ~ i7
1
	 kx(#
' W ^ ^SB
 TP SXX
 
' ^ 
J
!
> &"
c k#

x  #
^ ue5P Z'(#
 eX'(#
 W!
 P 	) s
 "S	 5&%^ #
	 
JE&s
	 Z	 #"M
n e!
  W"
^ W2i
* W
'(
	X#
 #ECB
 
^ !^ sx
 (L=gVB
 F&{
' CJ^ &^C 	x
 JB5B
 W&5%
( 5N=LB
 X
 kxP W"s

	5&SB
 W#ECx
 W g":
c k?
x  
^ #W	B
 Z^  e*eMB
  s
^  &p
	 kxCP W"s
L
(	 52 :	
> 
#
	  zCZ*@U#
^ Z#
	 "~*@Ue<=B
 _s!
 ") W"2	 5o
 Z		w"
^ 
 # P B
 sZx
  JB
#
	 5>]x
 
@^ !"d
 " &^!* U dm
 7t  x
 , &5^ B
 
^ @m2`
gbS	 e#
' W =B
 W 2+4"e[EC^ {^
#
	  5* U 
  <&J>@^ "XW=
#
  
^ @:B
 W=u@
 #
	 e	  [{@LJ `b^P CO* U N
 <=?>@^ "XW  {@LJ C[`gb"O
n oW'& CZ* U k
B 	N
 kx(#
' W t {"d!^ X?B&
^ ud5P es
  
S^ 	
 &
 @
 #
	  p2`u
b eyL2`b%	 }+f"Z|	NO
  &
BgS
n x
 w@EC]t %W'& 
	55o
* @
 #
	 [ 2`

b eyL2`b%Cp
B #
	 d=
#
  
^   {@LJ `b"
|#
	 :!
' "^ 
JBWZP ~'[N=
 ~ 
> "W{*%^ ~}=
#
  
J
> u#]& #"L|	N
  P "s
XJBd#
 
^ (EC
	^ (EC}t sWfB
 #S #"
c Wo	B
 5^  ffus
  ^ XS^ 	f	 5&
 @u
 #
	 5	 yL2`bO^ 
#
	 e#
' W>=^ &[P W'{#
^ uds
 i#O	 
> Ws
  
 S^ 	f @#
  ku
 @
 #
	 [ zyLY`bk"
|#
	 e!
 :P W'8
 ~#
	  %
a 	B
 u5s
 ff#[	
>  Y `bx
  k^ #
	 "5yFC[ Y `
b e  `b:	 
 &Z#h
P
  &S @
#
  
 7MP =id=#
  
" 
 uds
 #
^ udJ'JB W]
> 	x
 =#
  "

f:Z:Mf5&Fg_!4F@V{QF
FAw#!{Cte {@FkCg @8@  @:lkZ7@%&@7&

kCg @d
4  (4C={7ep+,-%/0 7  +T52Z \:@X@ 5 
  `edb5h
 i 
Ct
   

   

 R1:@X@ d 
 
``Db ]!`Dbb 
  `e2b:Rg`
4b`Db
+   B
B=t(Ee
	k	xM`Qb h   ^#u5PZ'xW
^
^

	#es&^@i(EX	#eBW&F==^(EiWX	#Z'#W&'W
^M^8  ^B	#"	#sCPeB=JE()
i"sS	u	#dPxM^k	#[Nx
 (E&@
E d
(H   ~i#
	 d P ~^ kFJ'CP CB8e":!^X?B&^

	fiffffkm|	#PdX




fi!#"$%&fi'(*)+,-./1023%4!576

8:9;8:<>=?@;ABC?EDGF1HI8:<J=LKM@;<N(@;<JOMPQA<R7STPUS8VCKXW:R7=8N:YZK\[=?8:S8IR7ST8]R7<JP+<@C<^_A<R7SPQUST8VCK.W:R`=8NaKM<
=?8G9;@W:R7bAJOXR7SPc8GHdANL=eWT?@f@fNg8
RIVJ8:<@;=hR7=gKi@C<[_@;S=?8:HQj
k AUUZ@fNL8m$
l npoqmr7stfittsTmuGvhY2R7<VwOi8:=dxzy{n|m!y}x~[_@;S
zn;stfittLsh*j?8+<JAHdb8:S@7[eUR7S=LKM^
=LKM@;<N@`[=?8GVJ@;H+RfiKM<KM<f=T@+R7=@;HN2KXNd


8R;WT?QNLAW?UR`S=LKM=LKM@;<QW@;HIUJOM8:=8OMPVJ8:=8:SHdKM<8Na=?8
  7
VJ8:<@;=hR`=LKM@;<[_@;Se=?8A<R7SPUS8VCKXW:R7=8N:jaE8GHdANL=GRfiOXNL@+NLUZ8WTK[_PQ=T?8]VJ8:<@;=hR`=LKM@;<Ne@`[=?8dW@;<NL=hR`<f=
NLPJHdb@7OXN:j?8:S8GR7S8(R7=HI@fNL=x* ceRfiP4N2@`[WT?@J@fNKM<B
=?8Ng8;je<=?8e@C=?8:S?R7<VYCc8ef<@7c=?8:S8

KXNR7=2OM8R;NL=@;<8HI@VJ8Oo*s;Z
l v@7[2DGFNLAWT?d=?R7=2ovnm
l Y;NL@G=T?8:S8=?8:S8eR7=Oi8RCNL=@;<8eW?@`K.W8;j2<
[qR;W=Y;=T?8:S8KXNR7=OM8R;NL=@C<8ec@;SLOXVIQ

NLAWT?=?R7=o_s;Z
l v nDGF[@CS8R;W?@7[=?8I


    
ceRfiP4N@7[UR7S=LKM=LKM@;<JKM<B=?8G8OM8:HI8:<J=hNa@7[=?8]VJ@;HRfiKM<EoR7<V8RCW?>NLAW?c@;SLOXV  KXNK.Ng@;HI@;SU?JKXW=@
vhjeKM<RfiO\OiPc8GH]ANg=WT?@f@JNL8G=?8]VJ8:<@C=hR7=LKM@;<@7[=?8
<@C<^_A<R7SPUS8VCKXW:R7=8Njee@7c8:9;8:SYZmE
l VJ@J8N
<@;=
W@;<Ng=ShRfiKM<>=?JKXN
WT?@7KXW8+R7<VYbfP>R;NNLAHIU=gKi@C<Y<8KM=?8:SIVJ@f8NDGFIjd?8:S8[_@;S8d=?8I<JAHdb8:SG@7[
rr
NLAWT?WT?@7KXW8NKXNeNg@;HI8([_A<W=LKM@;<oxvca?JK.WT?KXNKM<VJ8:U8:<VJ8:<J=
@7[m2
l j
E8
W@C<WTOiAVJ8d=?R`=
x

 mZ
l _oDGFv
xdrfistfittsx
uaI7:\7

 


oLxEv

x

  

oxvx

xdrsfitttTshxue

t

q=aS8:H+RfiKM<Na=@d8NL=LKMH+R7=8


x

x
n

xdrsfittfitshxue

xdrfixdfittfitqxu]

t

k =LKMSLO\Ki<BZN{R`UUS@fifKMH+R7=gKi@C<[@;Sa=?8([}RCW=@;SLKXRfiOXN:Yca?JK.WT?NTRPN=?R`=

@I@;b=hRfiKM<@;ASaS8NLAJOM=YZc8(ANL8

EJn

7
7J
ohoh7>vTvht

q=[@7O\OM@7c{N=?R`=e8fKXNL=GW@;<NL=R7<f=Nas]NgAW?=?R7=
IG7J

E


e`J


[_@;S{RfiO\OEj(NKM<B+=?8Ng8
b@CA<VN:YR;Nc8O\OR;N=?8([}RCW=e=?R7={x y



u


x

u

x

Q
 


u
yXr  

x*

u
x y  
yXr 

xdrfixdfitttx
ud


(x
u


x*Yfc8GB;8:=fi
x


 


u
yXr  

t
u
x y 
yXr Q

 @cY4W@C<NKXVJ8:S{=?884UST8NNKM@;<W@CHIHI@;<=@IbZ@;=?b@CA<VN:
x
 





u
yXr  

n

u
Xy r x y 


n

n
n
X_(_hLM{_7(.TL







u

x 
u
Xy r x y 
x



x y
yXra z
u

 T
 .}M
yXr
  +




;` T  X n e   t


!"

	ff
fi
# L_%$2_&fiT_eMq')(L:T+*!,.-0/1324 56 ,fiL_2_T{T_7fi_8,__9(%:7<; 5 
=?>

fi@BADCFEGIHJLKMON?G?APQHSRUTVC	MOM!G?A

WYXZ?[\0]!^3_`\<ab]c\
d egYhi
f
j g
  e<h%vg D dfe8gh
sutwvyx.z%{c|9}~c  b
sOt<
i kl9nLoBprq
jBk g kml9nLoBprq
q
n
 aF^am^B\aXFXO^3<XOm<XOF\!
WX._X0D\  ]c_F\\<Z<Zc?XLaX9Z<X93OmZYFZ\aF^uQ^3\^bX0FB\<Z`ab]!?X]_]!3\<X9_b]c\^3?X
<X9<XOX9_\)]\^3Z?_yZc\<aXZc3\^3Z?_b]0X     Z  ]c0.\<aF^X9_bf  Xab]!?X\<aXZc3Z  ^_
q
FX0b_F^3\^3Z?_Q
 Q3OQyfX9\    %O eh+

q
^3^3\Zc6\<aXOXb]?0XO9wZ?n <]!?
     f 
q


n

e8   
h 

 .fX9\      [IX.\<aX
q

gO3D+gg 
n

 
      O  ^3   
n  
q
n
nB
VaXZc3Z  ^3_\aX9Z?<X9XO\0]c[F^aXO]\^a\0Z__XO0\^3Z?_`[IX9\  9X X9_     ]c_bm      
q
q
 F+!brb
0 {|  }r}fg

 ~ f
  z% c      Q      
q
q
n
< {|  }r})09  }0  }} f  z% c       f      
q
q
  e8 h ZZ? X 

!fb0.]c<\ e ] h ^^3..XO^]c\X           \<aX9_ 
ba
q
\<ab]c\ e8   h      \^.] Z\^3..XO^n ]c\<X<Z? \<aX`FX0b_F^3\^3Z?_b \<ab]c\  e8 h b\.n <]\^
e< F  h Z  e8 h% +{?}  e<   h   VaX^_b3b^3Z?_    Q      _Z  Zc3Z  9
q
q
_X`^3<XO0\^Z_Zcb]c<\ e [ h Zc3Z  ^3. XO^]\<X03<Zn  b]<\ e ] h  LXO9]!\<ab]\     
q
     ]c_b \<ab]c\%\aXIZc^3_\) ^3_m      ]<XL^3^3\)LZc6]X ?X9_b0XZcQIZc^3_\) ^3_`   n    c^3_b0X
q 
q
q
    ^3ZXOfF^3\ Z 3Z  L\ab]c\     6      
n
q
q
q
	Z?L\<aXZ?IZ^3\<X^3_b3b^3Z?_Qf\<aX?X9_X9)]!6\)]c\<X9? Zc \aX<ZZ6^ \<Z.aZ  \<aXZcZ  ^3_ 



 





ff

   



	



e ^ h    ^.  ^3X9_\3]!\<aX9_Z?]!        \<aX9<X ^ Z?.XX ?X9_b0XmZcbZc^3_F\)
q
 
 
!O!
+{?}  e<   h  ba`\<ab]\OFZ?]! g yg \aX0ZFZ?
  n   n
n
n
 
 
^_b]\<XOLZc  
] <X]!Q^3_F\<X9?X9BF3\^3F3XOZcB g ]c_b ^
c
n
n  
nB
e ^^ h ^    +{}  e   h  ]c_b]!%^3\)0ZFZ?)^3_b]c\XO]c<X^3_F\<X9?X9F3\^3F3XOZc  g f\<aX9_  
     
q
n
LaF^XO]3` 0XO \<Z<Zc?X\<ab]c\          
q
WX[bX9c^3_  ^\a \<aX<ZFZcZc e ^^ h   aF^a ^ \<)]^a\Z?  ]c0f
?bZFX\<aXIZc^3_\
 e




g
gO!O< k gh ^^3_ +{} e  h  YWYX`0Z_b\<<b0\]  Z 
 
ba
\<ab]c\  e8h   ]? Zc3Z  9.LaX.FX9_Z?\)]\^3Z?_YZcB]c\<Z?
^ \<aX.X9\ZX03X9.X9_F\)   OOn !  
 ]c_b`Z Z?_Q  \B<X9]^_b \<ZaZFZX
\<aXFX9_Z?\)]c\^3Z?_mZ ]c\Z?
^ \<aXX9\ 
 !O!<
\<aX`FX9_Z?\0]c\^3Z?_b Zc\<aX0Z?_b\)]c_F\) e ^3_b0X\<aXFX9_Z?\0]c\^3Z?_Zc\<aXm<XO^9]c\<XO Zc]c^3\ <XO]c\<X9
\<ab]c_ ^ ^3<<X03X9c]c_\ h .W ^3\<aZ?\ ZF<ZcL?X9_X9)]!^3\  X9]c_ ]?<.X  ^ ^3_9]c_Z_F^9]%Z?<`
e _Z?\O  X`0Z_b^FX9   h LaFb9  ^]^ 8_b0\^3Z?_ Zc 0Z_ 8_b0\^3Z?_buB<]!
 c^3_b0X
  f{?}  e< F  h    Xb\ab]!?X   f{?}  e   h  ZZ? X fmWYXbX
\<ZFX0b_Xm\<aX
e !h ZZ?.X]c\<Z?
<Z?IX9<\^3XOZc\<aX0Z_b\)]c_F\)9  
0Z?_F\)]!^3_b
<b\aX9_  X] ?X
<]\^

fi

 



! " 

!

ff

$#  # 
 !

! 4 

%# 
(&

,+







!



 
#
*)

#

.4


31
!
	3 1
8&:9 <;
@A

#

'&
#
*) 

65
=&29

0/213 1 4
73 1
?> ;



fiB	CEDEFHGJILK,GEMENOFHPQCEDEFSR7CETEUVI	WEIYXZDE[EM\GJ] ^
_:`acbedgfhcfij fklffmonQhpqffrsf<rsdtqvuJaxwEkyr{ze|}6ijt~8~<%ivj7dgq EqffiEhqE`Eaz|}dtqfffjOrsq~QqEd
j fdgcrdgq EqfhqfrdgqffrqEfiEhdtq~<fj?qf6 kfiEhq2hc7j thc~j frV~z.m_2`z.dt6~dthj lffrsfj?m
j fdg2rsfiJ`0Ea$fe~<iEdtffqEd lh6%shj 2fij fQSgJ  ~%j f<r~ph~2|}kEj q~<d~j frV~ph~e8a*bdtfh
fij fQrsq,fiffr~dtq~<ffrdgqrsf8r~rsdgfj qfff6fij?f8h~<fj f%h:rf%i  rsq0t$Z8E $ kj fiEh
fij q~<frsq,fiEh7%sd~<Eh~<jthe  {8  dgfiEh2r~<htkZfiEhd rsqfffcdgffVqEdtf6qEhh~~%j <r{sm~j?f<r~z.m
Z8ff  a
 hqEd 4dtq~rffh8dtqgrsf<rsdtqr  a*2iffr~r~Q~<EE<r~rsqE smgr{ffsfQfdcEd th  fiEhE%dd zrqfftd sth~
fh%iEqffrtEh~zdtjghlEjOrQthdthf%mta*eEZ<dtl2dtfflyh%hVj?f<rsthsm7hjt~m6r{z	t$Z8E $ 2hh
j qdtyhq~hfa6qffz.dt%fEqj fhsmtkyrsfQr~QqEdtfaeqfiEhcdtfiEhQij qkyrsf82dtfflhijOthh~~hqf<rjO{sm{rgh
j qdthq~<hfr{z	hcdtffhffjthcfiEh6dEEhqh~Qd zrsq8$  lffm8a2$fQfEq~dtEfQfij fk
zdtedtEeEE%d~<h~:iEhhtkf%iffrV~:hffjthhqfffer~d~~rlffshta
 hfZ*%8E  lhf%iEho~j hojt~8$E  hhEf7f%ij f7hghm0EqEqEhj fh  dtq <Eqf7d z
fiEhz.dg$c  `.  r~6%hffVjghSlm,  `.  abdtf<rhfij?f6fiffr~r~ch~~<hqfff<rjO{smvfiEhdtEd~rf%h
fj?q~z.dg7j f<rsdtqcfd8f%iEhedtqEhe~<heiEhqffhpqffrsqEch~~<hqfff<rjOd~rsf<rsgrsfmrqnQhpqffrsf<rsdtqaa 8 rsqjO{mtk
shfc	   {8  lh Htx  8$ $ af8fEq~QdtEfQfij fOkEzdt8jO{~<ff%rshqfm~<jO{6  kZ   {8 *
   {8  a2iffr~8h~<ffsfkeiffrihj lyh:jt~  h7jQaxEk:r{2lh7~<fj fhj qEd thj fhOa  dt
qEd 42h8~<h8fiEhQsh7jfddtqfff<rsqEhfiEh6E%dd zZd zf%iEh87jOrsqh~fffOa
dtq~rffh6~<dthS
 ,   {8  a8$f6~<ffh~Qfd~iEdfij fQzdt8jO{LfiEhhchr~<f~6~<%i
fij fz.dgjO{"6 ktf%iEhhhffr~<f~2j8yd rsqfQy t<xZZ8E $ ~<%ifij?fjO{fiEh8ddtgrqj?fh~
d z  j hrsqfhgh*ffsf<rsffsh~d z =j qc~<%if%ij f: c  ff0ffa*  dtZfiEhqchej qcfj?th~<jO{h
j q~<7jO{sheffx~Zfd%hj fhj~<htEhqh  dtqgh rsqE6fdc a 8 hqhtk\hfe0Ea*m  h7jcQaxEk
2hj qpqc~<dthe  Htx  8$ $ ~ifij fe   ff0gEaZ	m6ffhpqffrsf<rsdtqkffhth%mdtq <Eqf
rsqo  %8E  r~d zf%iEhQz.dt%(  Z8 * Ek  Z8  0EkEg    `  Z8  kEdteg6    `  8  kJeiEhh
Or~8jyd~rsf<rsthyd smqEdtrVjactqEdthz.dtQfiEhcdthqf8fiEhdtq~fjOrsqfff~Qd z	fiEhczdt'O8 e Ek
j qdtq~rVffhfiEh8h7jOrsqffrsqEdtq~<fjrqfff~fij f  ~j frV~ph~a*2iEh~<h6dtq~<f%jOrsqf~jrqfftd sth6~f<rf
rsqEhtjrsf<rsh~kZj qf%iEh8zEqf<rsdtq~rsqtd?ghj?q   j?hdtqfff<rsqffEdt~ae2iff~kEfiEh%h6hffrV~f~~dth
O~<ifij f2zdtj  zdteeiffr%i    y0OkEfiEh~<hcdtq~<fjrqfff~Qj h6jO~<d~j frV~phlffm  a
bd,dtq~rffh	jQdtq <Eqf*d z\f%iEh	zdt  Z 	 fij fr~*~j?f<r~phlmc  a rsqh  r~Zd~rsf<rsthtkgfiffr~
ij Eyhq~rzej qdgqffmr{z2fiEh8zd {sd:rqEdgqgrfrdgqoiEd?VE~z.dtQhthmdffdtgrsqj f%h  `	fij?fjtfjO{sm
j Eyhj ~Qrsqv  k2hijOthc `  Eacqj f<rffj kr{z,  j q  ijghf%iEh~%j h7dffdtgrsqj fh~2rsfi
jEhEkfiEhqvOsZ Q Jac$f8zd {sd ~8fij?fQz.dt6jS  kr{z    ZYOj?q  j q  ijOthcfiEh
~j h6ddtgrqj?fh~22rsfijOsEhJkEfiEhq  jO~<d~%j f<r~ph~eZ*%8E  a
 hoqEd dtq~ff  fij?f~j f<r~ph~fiEhhgffrshhqfff~a  hflhSfiEhrsqffhLd zfij f
dtydtqEhqfff	d zZ  2rsfifiEhj th~f*jOsEhta  heffhpqEhy0lffmdtq~rffh<rsqEhjgicd zyrf~	dtydtqEhqfff~
 ` kgz.dg68,20S

 `  
    j q ` 0
 `    ` 
 `  } `  } }    

$fQr~hjt~<mfdthrzmf%ij ff%iEhdgdtqEhqfff~d ze ~<E'fdta 2fiEhdtydtqEhqf~rqS  kdgfiEh
fij qfiEh8 fikj hQrsqhjg~<hlmj fd~<f6?va22iEhcdtdgqEhqfQ ` r~ffhhjg~<hlmj fd~<f
Sa  hQ2r{{~<iEd 0f%ij fe  ijt~fiEhQ<rstif2Edghf<rsh~zdtejO{0  kiEhh   r~2~<%ifij f
 4rq$E` t E   tSa62iEhz$jtf8fij f84J` tj?j qfffhh~Qfij f8  rV~rsq zdt
jO{0a2iEhQzjgfefij fet"t 6gj j qfffhh~fij fQ  r~e:rf%iffrqgd z	  kj?qiEhqh
2rsfiffrsq,d zeZ a rqhg  YOkrsf8zd {sd ~Qfij f7     ZYa rsqh  r~6dtq~<f%fh






fi

 ff

	
















fi!#"%$&'(()*,+.-/0&&(

13254768(9:9<;76(=<1?>A@1B49DC36FE:9HG5=<2I2(J<KMLON76P139CQ6(CST!
R UV,W
J39oMXLAJ39Kqprs2(N7KMLA1?LA2(N
{ 1vN2 W

JB9uED6LAN7CQ132}|J32F8(9D~q9uE:EH6pc V,W

4LANI1B9K96PJ?>zLO9uJ V

134LCJ39oMXLAJ39C1322F>C

|J39C?9uN1t6F1wLO2MNLAN
L x

9=<2MN7=B>OX7K951B476F1QT!
R Y[Z]\_^(`?acbedgf3hiQa j
R ff
k lmknV

f L ltV 6FN7KH49uN7=<9v1349S9uNI1wLOJB91349u2(J39uE

LA1%LCK9<7N76F>A9LAN1B49>6PN(X76F(92 x
x 2(J3EQX>6D

R  
R l
f Lmp9(p VFf Tg

I

6MCX7C?9KLAN1349H|J322 x# X7Cw1PLO8M9uN*pC
W

6(C

Cup
9
W

x J32(E6>A(9uJt6L=QM9u2(E:9u13J3@(p9v76MC?9Q2(XJK9<7NLA1?LA2(N7C2(N1349

f s2=34N76P V r2C?139 V]

67JtC?13ff2(J<K9uJ

4L=B4

V N2 Wyx 2F>z>A2 W

2F@ V((l pqC?X7C?9u1#2 x  LC#C36LK132!9uuQ ` <3Fff

J396>Am=B>A2IC?9K79<>KCup/476F1sLC V LCC?9uEQLAm6>A(9uJt6L=L x

\  ` t ^F}

uQ:

#!HA,

v
R Fl

f C?9u9

x J39u9S86FJ?L6F>A9CS6FJ39

1349uJB9LC

f?7?t
lW
!F?t
W 42IC?9v2MN>O@}N2(N


3
>A2(FL=u6>gC?@EQ72F>C%6FJ39G V7MVvV,Vq
6FN7K5 V C?X7=B4H13476F1    fmT  B3T
l Lz
fnT  33T
lZ Sp



x XN7=<1wLO2MNF V(W 49uJB9
  6FN7K
   V LCCB6LK:132!9Cw9uEQLAm6>A(9uJt6L=L x LA1tC#MJt6F|4
R l
f Tq

42IC?9

6PN7K

LCQC?9uELOm6>OM9uJt6L=Fp/49DED6LON1322F>

9:X7C?9LCv1B49
W

x 2P>>A2 W

LAN#tF

f s2=34N76PD9u16>p V*(V |*p7F l3l 

\ M ^ u:I(sHuuQ? ` F<3FffQs 5 

 ^F    ^ <uuQ? ` F<3Fff<   ^F

 a G uk







 _

R
T
Z

<I(

f G l



:* 
T R

I3:uu

 _



fn3lZ

 ^ 

 ``%Zf G uk 


XJ7JtC?1SX7C?9D2 x

1349}rXJ38(9(9<>O9=<1wLO2MN~q9uE:ED6LCLAN1349

x 2F>z>O2 W

LAN VW

4L=34C36@C1B476F1 V LAN6

=<9uJ31t6LONQC?9uN7C?9 V C?9uELOm6>OM9uJt6L=

x XN7=<1?LA2(N7C,79u4768(9<NL=<9<>O@N96FJ>zLOELO1<Cup%49s1@|79s2 x |49uN2(E:9uN2MN

9

L
?
C
}
4
3
1
5
2

6
M
8
F
2

L

K

L

C
z
L
z
>
A
>
7
X
?
C
3
1
t
J
P
6
3
1

9
K}I@  CnLAN
W
W
W 4L=B45LC=<2(N1?LANX2(X7C6P1G V X1476(C/LAN7NLA139<>A@EH6FNI@

>A2=u6>gED6;LAED6:6FN7KEQLANLOEH6:N96FJGp

H% \ ( ^ }I( a G uk    5 ^F    ^ tuuQ ` F<3Ffft   ^P
<I( fmT*l
G  T	
G q  f G l 
G!* 
Iw5 ^ :ff
 
GtuIM
utff `fi   w<F<   
IS  fftF `*a G  
 k 
vq<
  (X||!2IC?9 V @ W 6@Q2 x =<2(NI1BJt6(KML=<1?LA2(N V 13476F1CB6F1?LCn79Cs13494I@|72(1B49C?9Cs2 x 1349|JB2(|72ICLO1wLO2MN
X11349uJB9LC/N2

 C?X7=B413476P1
 LCLON7=<JB96(CnLANHLAN51349LANI139uJB86> a G  
 k pg9vK9<7N96S|72FLAN1 T LAN a G k
132!9B  L x*x 2(JC?2ME:9 T U Za G 3T*lqW 94768(9 fmT U l
 fmT*l p,~q9u1]!91349C?9u12 x 6>z>_134976(KQ|!2FLANI1<Cup
FLAN7=<9:
 LCC?9uELOm6>OM9uJt6L=QC?2SLC V CnLAN7=<9 T U Z Lz
vq,_


FLAN7=<9 V



s9=u6FX7C?9S2 x



a G uk

1B49=<2(N1?LANIXLA1?@52 x

@6(C3CwXE:|1?LA2(N
2F8(9uJ1349QJt6FN(9

V







fmT*l

fmT U l3l3lt

V }LCN2(1LAN7=<J396(CLON}LAN6FN@5LAN139uJ38F6>

6FJ3LA13J<6FJ?Lz>A@=B>A2IC?9Q1325GD6PN7KCw2G

1349K9<7NLA1?LA2(N2 x

T U Tl



@6(C3CwXE:|1?LA2(N

C?9uEQLAm6>A(9uJ<6L==<XJB8(9

5f 

T U fBf G






9:=u6FN7N7K76(K

kmV!W

|72FLAN1tC

Sps@51349HrXJ38(9(9<>O9=<1wLO2MN~q9uE:ED6 V 1349uJ39LC65=<2(N1?LANX2(X7C
Z


C?X7=341B476F1:



V 1349vJ<6FN(92 x

ffZ 

V!f G  Fk ]vp%FLAN7=<9QG





V LA1

f G l

V Lmp9(p V 
x 2F>z>A2 W



G6FN7K


 



9=u6>z> V 1349J39C?X>A1
W

Zf G uk p

G 1349uJ39 x 2(J39

 fl  GpFLAN7=<9!}LCS65=<2(N1?LANIX2(X7C x XN7=<1wLO2MN V
a G $F
 k pr2MN7CnLK9uJv1349QEQLANLAEQXE|72PLON1LAN1B49vLAN139uJ38F6>

|J32F8(9~q9uE:ED6Hpcp

x 2(JD6>>

a G  Fk!x 2MJC?2(E:9

f<Fl

%}2(J39|JB9=BLCw9<>O@ V >A9u1 T 79Q1349LAN7EQXE2 x 1349Cw9u1 T U
 fmT*l ("qp%FLAN7=<9"  G W 92M1t6LAN13476P1 T) G:6PN7K51349uJ39 x 2(J39 T}Z
E:96FN7C13476F11349uJ39LC6:|!2FLANI1 T U Tx 2(J W 4L=34* fmT U l+
 fmT*l<VW
"56FN7K T p



fm3lDZ

:Za G k p#@
 GQ6FN7K5C?2 V
LA16(=B4LA9u8(9Cv6HEH6;ILAEQXE#"
 G

f<a G kffltV LC
C1B476F1

6(=B4LA9u8(9Kqp

9v=u6FN5N2 W

aG 

$

49uJ39Q134LCED6;LAEQXE
W

Za G  Fk

&


Sp%4X7C VT

fnT U l

'"  7 =B>A96FJw>O@

LC



LC76(KqpsX113476F1

4L=34=<2(N13Jt6MKML=<1<C1349Q=342PL=<9Q2 x

9N9u9KHLC6(C

x 2F>z>A2 W

Cup

,-/.021436587:9<;=1?>@+ACBD>CEF.GH,JILKLMON<GP>QRACBSTQDB>@LAC1 BR7VU?AWQRACXSZYR>CET[LACU=\>JST9VSZ]^STBSTQD_`Aa?1P>$U:ETAU:bc>d:eP>$1:B6SZaPAC\6YF]F\RACAW]F7O\RXe:Ef>
ST1gBR;=AWEf>$1=[LeP>$[OA7$]h\RA>JEh9<ET7LQRAC_4aPA<ET_=QC.Dij7$k8AClLAC\CGP>Qm7OU`QRAn\RlLAC_4ST1365D7:9;=1?>@4ACBj>JEF.TG^,JILKOMLN<G?Q6ST1=9CABR;`AVBR;=AC7O\Rbo7]
\RA>CE9<ET7OQRAC_4aPA<ET_`Q>_`XSTBRQWA<EZSTXST1P>$B6ST7O17$]d:eP>$1:B6SZaPAC\RQ36p>\RQR@LSFG^,IOq/,JN<G?BR;=AB2kD7_=A<aP1/STB6ST7O1`Qr>$\RAVAnd:e/STlO>JETAn1:BC.
s:t

V

fiuvwx8y{z}|~y`x84vwxvzzWwhy{?

Vff684?H6DLO(//8RO!H6D Vj g4D + gg
`DLVF=?CF  W  g *    g <  ? )  :LC*$F<    <2^:	g
 
~:?  ^2:`g  =^  `F:   g!   <2^:=26CL   g
  C  O?LF  :
   ?nLJ  '$?!2    26CLO&F g
 	 $F=?CFC^L=&  C  ?
  TW     R<  W    D  H T       RRW $C!   +`  j  $OH2LC    ?    FO?CF
CPfg   $:L^2CO+  !
   H T     R +^2$ff:C  O?=R  J:  H T       R
   F 24  +F*FOg$  C g* 4  ff`  `?g 2g:C?HRLR    H        R 
:42o   D  H T        C*?
     
      <2^:$  C  ?   C  FL*F  H T      ?C  ?O?$=	R  
  T       R< 

	 ff
  fi  fi       fi    fi 
   H W     R 2+C  ?L?=&R    H T       
VF=?CF 	 2C:`H  L`2  (HC  C    :)?  FLF 	   ?  FOC(J`
  F:OL  =L  Lff   FL 	 2g   ^=C  C:    !#"%$'&($   +:*) 2g!^  :  
  F:OL  P= F	  O :?*C 
  =+ ? -, LF:OJOH    $:     $F^?4^2
C:    FOoH4?H:L^2?C    ^4+  C/. OJ     :o2 {  ^  $:42   F
   fi 01 fi    F 	 2 4    LF=LC    :!  :2Vg  ^CF  VC:`H  O`2cLJ  
3   fi4 '5  ! "%$'&($  C$? 3 ^ V   fi 01 fi     3 76   	    6  8 fi94 
 FL 3 oC: `H   O`2  F2+C: `H   L`2o=  FO ^ OF?= :   :! 4<;
:424  !>=   C$? 3 2 C$C2LCFffL$=H<F?!
 F*=H  WL:. OC()  ^ OF?$= ? :
3
!  P  fi = 1   C!?  = +  fi  fi  LA+
@      <2^:!  C$O`FLo W     R
?  !&  CB  0    ED B   0  O =C  COP^O?`c?J8. =   ?)$: `
F     J  ?
 =`FCF= (    CF^^Fn    ^  2`2(gB FB   :$ L^2CO  !
G(  C$?    +`  J*?F     G    P  ?C27. =o=C  CO`F^O 
@o    ($   ^CF^FC   3  $:L^JO  FH=   8 fi =  C^$:^CF}$  C  =
C$ $?g 3  =       fi   fi   O :

        fiIG OH FL 3  =   fi  fi    	 ?
(
        F     W?  K J  H T       Rm +  $F^ $      !C  F?g
 V^2m



F  < F r W   C  ? D H T      j    CL`FOV  =?CF?
         R
:?    +    c?*
     B   0  L  B   0    {  B  0    ED B   0  L *B  0   ED B   0  O
+:B  2  <FC    F^  2` H L 3  =    	  *^M   ?   H TW   ^  R 
  C$O`FL  r   $NB   0  gO ?PB   0     ?2^:J:PF       R F        RO
?!:L  +?C27. =  !  : FL  Q    G H 2Ln  !Fff        ?L-H O  
F  F=!  CL`FO  +&  CB  0   ED B   0   ?`2  ?J8. =    PR F` 
  <2^:!  CO`F^  4  SB  0    ED B   0  Lr   =  F?
   C$O`Fc W      R
2AB  0  AT  D  B   0  OU FL*  C27. =g^2 :  CO`F^  *^M   ?AB    AT  D  B     O
     =:`rgr   ? =)? 3 2 L$=H<F? ? :  fi =  F. OC>)  ^ OF?$= 
   ?$C2L^   D   ED V ^E. ^FC    :?  ^2:`W    B           $?   $F^
B     T  D  B        D B     L W :L  CL`FO  $^oC  ?$`2  $?C27. =  *  r ^
  $F^=   ^ +? +  H T  g    $^:C  F? *  $OH2LC  ~?   P F?
g=J^ 

 ?/.`F=H^ff !  ?     :YX  4 X 

Z\[^]`_Aa2bcEd9egfh9ai2cEdkjl/mn9cEeaobcEp q-cEd9adkmerfd>mn9asfdkt-dkfmavuEa8bmcEiVx w mnzy{mKy{bm|zy}j<jlAy\qqza\y{ifd*~E ?gxEw  ]
9

fi(?'2v?9?s%9
*` rr -Fg2EI^^UE/  g/kg-2?HgI?z9/{Ug*?-g
2g-\Ekko^g\E`g(? >V -U9: /{*-`UE^k9vI-g`gU*kQ-
g`*:ff-/Q-vU>PE?K}zo1-z
(>  22 >   >2 %>  1 o-ok-k-         #  >A>* 
 

 E H

  ff-?! 9" ff- #$ F%
 ff #P 	 &ffv'
 
  	  fi ffz k   ff  k


(ffk k) *-+ , k *./0{$ 1ff $ 2) 34059 6 8796ff86: A;
 05) (ff` ffz  <ff= -
<7  > #??
 ff8( ff7@ 2 > ?A-  V  10{: E! 2BC/  ff05$ D - } 0E7  > #? 6ff8*ff  #%
 k #?
-F<ffH
 GJILK 
MN 	 &6&k)   O 2D-+
 * ) I#" PQ 	 Q
 A  )- 	 2  87v D,5R 6k 05
-
 NOSUTVNXW  TYN   06Zff  @   ) 340{$ kO }! 2> ff  DG   ff  [  2H -)  \ ^
 ]  >V 7*  
 P
 ff* k)   ) 2Eff8( : *NOS'ff- #  	    /< ffv$ 1ff  > -) A\ '
 ]   >/ 7v$ \ 
\`
_ a
ff-
 #Dk)   ) 2Eff8:! 1ff N W 
 d  Qf- 05-* ff05& 0{$ : 1#B+Dk)   ) 2
b    ff    ff  Bc05`7> #)  } ff05   >Ve
? 05$ U
 (ffg9" ^
 ff fi ffhR*?i
 [jffz U
   ffk05l:!   	 EN S `f- 05- ff05-#))9
 *
 0{ #)mff-) 2  -) fi7v$ `k)   O 2nN  9 -ff  -ffz#     B7U`: ffh[ENOSYToNp
?2Z  ki
 qBr]*  >> (? >V D  Es   B @   ff-) 2tGnBe kO   O 2
- ff-) 2 C -O  
 d  * ff8#   N)Sr
]   >/
b    ff    	  B$ NW 	    u[jffz 1'
 >)   [8ff  NOS6 N   @   5Rvff-!   N)S,wmN  x   ff- #
$yD 	 uff-) 2FC -O % " +?2fiu05O $ z2D-c kO   O 2? 05$ e B  <5R I(:  u{"|U}
 06Zff8/s   ff(\ 7v$ <\ d y  ~ T{)B~7 ff1[k  \ u  N W ?10ff-`:  <  kZ
 7fi0ff-e B 	 2
05`7> #)   -ff }fi
 ff$   {>o 1059\6 ff  2Bff\? <6ff8 \ d y  v TU{1 $ 91\  ?2EA 105 #
 ff  -e   ka

 Bh  :+ ff/ 1 k 05` -) I2\   ]*  >>  0,ffs (> \   y  
.H
 ff  > 0E> ff  B@   G > ff  <k  
7ffh[F \  d y  ) TU{)B` 6ff8*  \   |`NW?B?  8[  ff  
	 
~05 $ "A  )- B)7>`: &k D
 ff$FF05 0{ #),ff8%@   ff= GnB

 

 (
+
 o-Q- A  >1+   o-k-    \   >A+  z G  x8  G {z   =  z  G  xj  G \z  
  6<  ff- #B
 

o-k    \   >A
 o-k      d    >1

O 8+ 
? C$
 6
 /   ]   >/e   P
_ *   G s   G   
 
  GwUF    G   G z 

  Es  <6/  ffk05$E-2X#)EH- > 7H06tff  <I7>#)* ff8v
 GwUF     G z   G   s   G z       GwUF * $ 5   G6    G 



 G z 

f-
 05  Gw9F  8  G    G  < ffC -$ 2 *> ff2m
 GnB#  ff05$ 

 k #? E}Eff Gi  87V:> ff  
  9}!#s-!87V
1

fi+pv`hpnfi+%Xv8

'+*C+sa-kcEeQ=C)j~
uhp11e-$em5()*O<Y(@k>qc8(sj*8u1e%6*OHhe81,O,
5*8p**+  <
 z8,Oq,*
    <
 
	fiffe)8< D8,>v( ssq
5k>?s8
 5 j 1s85
   cO
 ( ssq-5k> ,8t:Xp'8
 !j('81,O,
5<8>+" "  <
 ?>#
 cs$
 ,<"8h>,) p5CjX8p>mfi
 	
uh&5% ')(+*,-/.0123415!68759;:=<>3?@(A7:B(C59EDF3G=GBH/IKJ$:=L&3!:K:=L&3!:M:=L/JN<OJP(AGPGB5IMJGBJRQ@H/JN9&7J
5!6:O5!SCJN<>3!9&7JUTJR7:=5<>GV; W DYX[Z]\^_/^R`4`N`aDb:=L&3!:M759;TJN<=cJRGd:=5 / De3!9&?V6f5@<gJR3@7=LhXi3jIk3l*
(CIfiH/IMm
JN9;:=<=5n;1on&5p(q9;:Ur W 5pu
6  "N s <GBH&7OL:OL&3!:d6f5<M34S+SXoDr W (AGM3!:#SCJR3Gt:kM3423R1u6f<O5I8.hv!(C9&7J
:=L/JGBn&37Jowfixy(AGU75IMn&37:4D2zJ{7N3!9|3G=GBH/IKJ$2z(C:=L/5H/:USC5
GOGM5!68c@JN9/JN<>34S+(C:}1~:=L&3!:U:=L;(AGPGBJRQ@H/JN9&7J
759;TJN<=cJRG:=5oGB5IMJUn&5p(q9;:Mr .zJR7N34S+S:=L&3p:gb <fiF(AGfi3P&9;(C:=J$75@Ig;(C9&3!:t(q5@9|H&G(C9/cN3!9&?/3!9&?
5<;85!6g759&Gt:=<>34(C9;:>GND2L/JN<=J$JNTJN<O1GBH&7OL759&GB:=<>3l(q9;:K(GU5p68:=L/Jj6f5<OI4Ab  $Z/D4  {/D
@  |NN  b  >D&5@<@b  ~NR  b  >D&GBH&7OL:=L&3!:  (AG#3fin5
G(C:B(CTJMn5!SC1
9/5@Ifi(A34S.8v!(C9&7JM:OL/J85!TJN<>34S+S
9;H/IgJN<5!6e759&GB:=<34(C9
:>GY(AG&9;(q:OJ82zJ87N3!9$3G=GtH/IMJD/3!c
34(C9P2z(C:=L/5H/:Sq5;G=G5p6cJN9/JN<>34S+(C:B1D&:OL&3!:34S+S:=L/J
 Wfi GGO3!:B(AG61Pn/<=JR7O(AGBJSC1{:OL/JGO3!IMJg75@9&GB:=<>34(C9;:>GN.zoJM7OSA34(CIy:=L&3!:F:=L/Jfi75<=<=JRGBn59&?@(C9/c$759!BH/9&7:>G(C9
r/
b < ! 3!<=J8G=3p:B(AG&JR?U
1Ur .e'5<3g75@9!}H/9&7:5p6:=L/J6f5<OI  b  Z|fi9/5:=JF:=L&3!:RDp(+6Y  Br W Z
65<34S+S/XoD!:=L/JN98:=L;(AG34SAGB5FL/5!SA?/G3!:E:OL/JS+(CIfi(C:RD
GB5F:=L&3!:bBr Z/.)759!BH/9&7:5!6:OL/Je65<=I  b  e
:=<>3p9&GSA3!:=JRG(q9;:=5$    K(C9o   < 4 GBH&7OLo759!BH/9&7:>G#3!<=Jfi:=<B(CT@(A34S+Sq1oG=3p:B(AG&JR?j
13!9
1Pn5!(C9
:
(C9w x .P63759!BH/9&7:fi5!6:=L/JK6f5<OI@  MN4  F(AGfiG=3!:B(AG&JR?V6f5@<g34S+Sr W 3!9&?  W Db:=L/JN93!:
:=L/JKS+(qI(q:fi2zJUL&3RT@Jk@}r gD2L;(7OL(Gdn/<=JR7O(AGBJSC1h:=L/JP75<=<=JRGBn59&?@(C9/co759!}H/9&7:d(C9   < 4 >.
')(C9&34S+SC1D65<3U759!}H/9&7:F5!6e:=L/J6f5@<=I@b  ~    b  >D;(+6Br W    W   Br W 6f5@<34S+SXoD:=L/JN9o3!:
:=L/JKS+(qI(q:fi2zJUL&3RT@Jk@}r g/DE2L;(7OL3!c
3l(q9V(Gd:=L/JP75<=<OJRGBn&59&?@(C9/co759!BH/9&7:d(q9   < 4 .k:
65!S+Sq5!2G:=L&3!:Fr (G(CZ
9   ! <#.
01o3G=GtH/IMn/:B(C59EDe34S+Szn&5!(C9;:>Gfir W 3!<=Jk3p:#SCJR3GB:Mfi342341u6f<=5@I d.$JN9&7JDer 7N3p9/9/5:fi&JK(q9
9 d.
6F2JKSCJN:fio<=JNn/<=JRGBJN9;:fi:=L/JUJN9
:=<O5n
15!6F:=L/Jkn5!(C9
:G#(C
9 dDeG(C9&7m
J (G:=L/JGtJN:85!63lSSIk3l*
(CIfiH/IMm
JN9;:=<=5n;1Mn&5p(q9;:>G(CZ
9     <#D;(C:z6f5pSSC5!2Gz:OL&3!:Br e.zeL/5;5
GBJ#;$3!9&?U/GBH&7OL$:OL&3!:oBr 
;-y.v!(C9&7Jo:=L/JJN9
:O<=5n;1h6fH/9&7:B(C59~(AGP759;:B(C9
H/5@H&GND2zJ
9/5!2:=L&3!:K6f5@<GBH;P7O(qJN9;:BSC1
SA3!<=cJXoDBr; W   .v!(C9&7J~r/
 W (Gj3Ik3l*
(CIfiH/IMmJN9;:=<=5n;1n5!(C9
:j5!fi
6  "  s <D(C:P65!S+SC5!2G
:=L&3!::=L/JfiJN9
:=<O5n
1P37OL;(CJNTJR?u(q9:=L;(AG#GBn&3@7J#65<GtH;7O(CJN9
:BSC1uS3p<=cJ8X(AG#3!:IK5
GB:;E.oJfi?;JN<B(CTJM3
759;:=<>3?@(A7:B(C59fi;1gGBL/5!2z(C9/c#:=L&3p:E65<GBH;7O(CJN9
:tSq1dSA3!<=c@JXoD4:=L/JN<=J(AGeGt5IMJen5!(C9
:b(C9P
  b <   W 
2z(C:=LJN9;:=<=5n;1$3!:SqJR3@GB:#.8zL/JM3!<OcH/IMJN9;:(AG#3G6f5pSSC5!2GN.dJN:P  JGt5IMJ8n5!(C9
:(C9 d.fiv!(C9&7Jh 
(AG#3fiIk34*;(CIfiH/IMmJN9
:O<=5n;1Pn&5!(C9;:5!*
6  l <D:=L/JN<=Jfi3!<=J8n5!(C9
:Gz(C9hp
  b < ! 3!<=;(C:=<>3p<B(+Sq1$7OSC5
GtJ

:=5~  .U9hn&3!<=:B(A7H;SA3!<RDb:=L/JN<=JK(AG8GB5@IMJMn&5p(q9;:Mr z p
 k b6 < R2L/5
GBJKJN9
:=<O5n
1j(AG83p:#SCJR3GB:d.
#Gfi2zJ$9/5!2GBL/5!28D:OL;(GKn&5p(q9;:K(GU34SAGB5(C9p
 k b6 <   e65<k3lSS#GBH;7O(CJN9
:tSq1|GBIk34S+SP  .~Fc
34(C9ED
759&G(A?;JN<M34S+S:OL/Jk759!BH/9&7:>GF(C9b < ! G=3!:t(G}&JR?
1hr   3!9&?:=L/Jk75@<=<=JRGBn59&?@(C9/cV75@9!}H/9&7:>G(C9
b <   >.e59!BH/9&7:>G5!6e:=L/Jd6f5@<=I    ZU3!9&?$  b  (C9b < ! e<OJNIk34(C9H/9&7=L&3!9/c@JR?
(C9b <   >.|e5@9!}H/9&7:>GK5!6#:=L/JP65<=Ib  $    b  #(C9b <   g3!<=J7JN<=:>34(C9;SC1G=3!:t(G}&JR?
;1or  DG(C9&7JU:=L/Jk75<=<OJRGBn&59&?@(C9/co759!BH/9&7:#(C9b < ! >D9&3!IKJSq1hb  8/D(AG8GO3!:B(AG&JR?
1r  D
GB5j:=L&3!:M@}r  go    Br  fi<OJR7N34S+S:OL&3!:g  (AGfi3$n5
G(C:B(CTJUn&5!SC1;9/5Ifi(A34S>.h')(q9&3lSSC1Dz759&G(A?;JN<M3
759!BH/9&7:z(C9$b <   5!6E:=L/JF65<=I@b  e    b  .L/J875<=<=JRGBn59&?@(C9/ck759!BH/9&7:z(C9$b < ! 
(AGfib  g.$vH/n/n5
GBJ$@Br  8Z/.v!(C9&7JP:=L/JMT!34SCH/JP5!6  (G&5H/9&?;JR?h5!TJN<d:=L/Jk75IKn&37:
GBn&37J#w x D@(q:65!S+SC5l2FG:=L&3!:Y6f5@<3lSSEGBH;7O(CJN9;:BSC1GBIU34S+S   D     Br  ;.zL;H&GND/@}r  e     }r  65<
34S+SGBH;7O(CJN9;:BSC1$GBIk34S+S  lD/3G<=JRQ@H;(q<OJR?.e:e65!S+SC5!2Gz:=L&3!:r   (G(q9
  b <   6f5@<34S+SGBH;P7O(qJN9;:BSC1
GBIk3lSS#  3!9&?D(C9{n&3p<=:B(A7H;SA3!<RD(q9h
   < ; W 65<34S+SeGBH;7O(CJN9;:BSC1PSA3!<=cJdXo.0H/:#}r  ~D
2L/JN<=JR3@GF2JMGBL/5!2zJR?j:=L&3!:F:=L/JfiIk34*;(CIgH/IyJN9;:=<=5@n
137=L;(CJNTJR?{(q9  "  s <#)(Gd3!:FIM5
GB:#    .
R

fi;/z/R/EbR4

z;A$@
=@ABC|/=!RMO&!k@/$=B/M/tq@4AB#BO&!P=/o&OC&C!fi=/
/=
CBCj/RR==!B+C$/p/
fi;4&bCE-&4	ff
fifiFN!"$#&%E')* ( +-,.fi/.012344'5367fi $8
fi91:;<1	4=<fifi;>	01=?k/fi01fi50A@CFBD E "HG0IKJML N;O2<P ( 
QSRT9'CPV
( U 861:;.0K
+CXW UZY +Ct/\[B+CC;<]^ :;_`
+q W\d  a BD eeff
f3"H
 Uhg C; J L lm NnO <P ( 
 [B/ J L lom N;O <P ( 
qpsr
aCbc
<Bi jk
Bi jFk
t 4 vuw Nx Uzy
!x AOCR!tq

( |~  x 
 Fz/8!4C/gpe=/8/=@&=tq@$//=R=C
W p&UCN {}


ffe
ff  |
{  | J L N;O 	{( 
r
v
N

v
N

o j`\
o j`\

ff He
ff 

 J L NnO 	{( 
HQR =/NZ
PO/O!M8ORB;CPzM&OC&;M=&!F=/fil4C/Mps e
f He
   !
x <@&4= JML lm NnO2e{( 
 
!8bCNKp&F&PC;
J L lom N;O <P ( 
 !&B/
J L lm NnO <P ( 
 =Rt&RBCCC;/U	
Bi jk
Bi jFk
B/M/tq@E J L lm N;O ffP ( 
 Fz+;&/Rf@4+ PZ
T

!

q

&



K

=

/

M;N/fiC&!=AF/ R  J L lm N;O 
( U 8
M;BC;/&/&BC{!R=PUff
Cfi/4N;==;U&!C;Rez;&N&C& J L lm NnO <P ( 
 U E [ G 
4+k`
Cfi/4N;==;k!C
N/=/#!4C/gp J L lom N;O 	{( 
 f@ {(  OC
t<fi=MBM PK
( U 8 ;z++C=/N
&qh=/M! E   [v G #N=Oq;BM=uq44$@=fi/=ROABCe=/;
BU!
Z QR !&;&/
 E  G O4&d=/Ff@=fi;
 	
f He
   U E 9[. K  Gr

! C& QR CKUOCR!U=&!fi=/N=uUBK$BnOCN
tq|Bk4+@&NtNp=/& 8 B&O
=&!=;A/=@&=tq@P/=ROCjz+;&/R!&UzC=;C=/RB/&/F!4+zBA/CM
z;&N?
}e=!+A!=& d c BD   E  Gef3"
 | FC$z/N=N/ff/&zd'/>4C$O&!+qKW
&!
+C W d  a BD 	eff
f3"H
 | +C W d  a BD eeff
f"A  E  G2
r
abc
aCbc
/8/!zkNp&BK=/@C=RdC;N=N&kOR=/;5@/P/B+C/RhR!B+CNRKokp=fiC
ON=RB=RVC
=/#/=&;+CBP! eff
 @/N=#=/#;CKC;fOk!BCPz#&48/  qj=/H
/!zCRn!&B
A Heff
 p&/N=fizfi&R@t>!BABBAN9 e
f He
   gz/Rtp=fi/=ROABCo=/k&@CBC&
/&;NF;A=z/N=N#!/;+qR)o8&OC&;fi=&!
C W d  a BD 	eff
f3"
 U E F4[   Gr
abc
!C&fi=;Az/!A/zl7 Q-R q/RR==pB+qPO/gNB#O&!

+C W7d  a BD eeff
f3"
 U E [  G [
aCbc
zO<;C=R
fi;4&-2v R@Ceff
7fi!fiFNNC"9#C1:;F,@  B E "G:;sdn0vfi2N
4=<fifi;>	01=?fifi01P ( 67"fi.01fi2'53Ffi21fi5_60IJ L NnO ffP ( 
Q-RF61:;0
d  c 	eff
f3"H
 |
<

J L lm NnO < P ( 
r

fioAffH9Fo

ffvCKv'4vK  v'4Zn59ffn42;?;n;<$'
 v;Kvn55K	5	z	K2'  
  fiff 7v;	' ff < v
!9ffn42nvnH75s v'<<	!"Z#;	%& $ ff' '<5	()
*)Xn;	9	4,+-/.01)K'v#2nKv&/'	!	3X; "A	9456 $ 7	!99`;4
n%vn! 
  H )!587v)n9+& $ ff C:;n5#< 	4X=7n=%>?-@. ff%A v
BDC EFHG&J$ I -/.0!2!!vKBDC LNM EF754;	n'vO& $ ffQP /'\4n	'4+-/.
	vvHR $ S)nT+!U& $ ;B C L0M EF GVRW
$ I S)nT>T*B C LNM EF G	&0$ I ffUX Yv	55 n5&&
'	 /$459ffn42;?;T 
   2'945	3XnZ)		!,6 $ ff[P n	!
v-N) P '\ ff] 2 'v#2nv2'	!	3XnZ)	9	!^6 $ 22'_`ba
c 	N;dZAnef g
` hi M 
g  GZjkGVl Inm  I o)n9>KpB C LNM EF G&N$ I ff^ vn5&54	5	Z
'	H2'q
g
` hi M 
g  GZjkGVl Inm  I ffqA vn5)r/'H	!s>:-.Nn)2!v

  h 
 An M 
g  GVjkGVl Inm  Iut  N M 
g  GVjkGVl Im  Ivt B C LNM EF G	&J$ Ixw

  h   ghi

  h   ghi
P nvN7,n(yvn	'WWM i GVjkGVl Inm{zQ|oI1t B C LNM EF G&N$ I ff

W8=Y9((HZ%(2=rZ%_n(7GH m 1 I^t 
}U~  2 1
 H 
V



 =^QJ2=#(H9rxfi(NH[ `  Q	rU=(2
7GH m   I a  2
d
  0
r(4S  =(4xnK1u *7=GH1 I -9.v
7 i Gfi(2GZl Inm   GVl I      I;t

7=  GH m   (I w

ffv8v<Z)H2'5'jkGZ Ivt (2GZ I 28GV I1t (  GV I <	;45)v;	'v4 ff
P <;q  7v'	      5)Z2' M'	v	'Kv'	'K2'5'
'KCn5Z   ff  <	HV	K$'v	ff;K'	5)  t
8GVl I2      	5	4vT2' ff      <)4'	v	'K'v	`nkCn5
b7v}<''v	   /G;
$ I% 	G;$ I ff@ zKv288GVl I  <
	'TK;< K7nv'vffn457vCn5Zv	'!2' q -[. ffq U7v  ^7
'vrn	  	!u    Gv   s I 	)K  'S'vffn
2'C ff
k  H 5Un(yvY7 'evVq<9'vffnCn59G	'5v	<  I
<v'''2nvv'7Hn5'Cff;42n:?;	;	O& $ ffs v ` t 

7vp5	"7' '<Zv2  O& $ ff;X 5C#<Cvv	ffn7s  G  . $  I
'K?;CuU<5	() 4<C')n	1 ffuP /' ` n5'
9ffn42;	)7	'V	5  $v	ffnu ff u^)9#< ff) FH2!
vUB C   F G	&N$ IUt  ` GH  I ff?A vO)4v	'X	4}v ` G  I -@.N;)X9K	4;-
vn	'Tv	 P ' ff)ff;X C9ffvU'<	n	5	1?;	)Z ff
<	!\vp!v7vZ),;vG $ . $  I 2;G $ . $  I 5)v)5)9	v	'
	'T'	v)2'   -9. ff <#<'  n(yvn	'v Nff 2 Nff )	Cv	v9
ZNv<H')n(  GVl I 2o q  C'	)v*B C    F G;$ I -[. ff )
v	'4'	Tv:B C   F G&J$ I -.K2Z	& $ 5!9ffn42nOvn`  '8)(! ff
P nv<;	5	;v;	)VKH2K	JN7 P '@ ff) 

M i GVjkGVl Im 8Gl IN      I;t
')<'n ff



B C LNM EF Gfi ` Iut

MZ  G m   I

fiNJvqNNW;0	

U	2;HNW# 	ff
fififf
 fi"!# $% &'fi( )
*fi,+&ff-=ff+.fi0/ff 
fi21345
6 
&7n8:9;
 6 + 6 ff-!%&ff<"!=5?>A@CBD *fiFEHGJILK(<Mff-!
finffN<NfiOx%
 6 9P Q
RTSffUWVYXZ\[ 8]?^ X_\[ 8]:`ba
cihkjmln
^
^
cdegf
^
^
o 	p(%qOrst%u%v?wYrx3ys'r2z
y S%}8~(~JY rxMs ~0}8~(~	  } xwy S

c
%
{
|
j
cide
 
s ~ r }S~Y r  sy7 S yr%
s' } s
f
- e {?
RTSU  [-XZ\[ 8] X_T[ 8]:`t%u v ]
j

 ~ rs%:wYrx3ys'r

RS[ B2>]

 r S r  r }8~( s   r }8~. y  r } xs' } syx3r  wYr . wYrffx3rw ( s'3rys3r S.	}~L ywYrffx3rw
s L
 3
{	
r } s'yHr S   s } s } y  xYs    x '} s . r [ t%u v Y  ] ( s3r  y S'S r  yxw  x3w . s S   s  yx
 -'} s . r  9
3r S rffy S r  s'3r 0}8M32 rxYs S y  y  xYs   y   t%u v  [   .  .0 x    r 
{
 ~( x3r }S s  ]  y S'S r  yxw   S r . r ~ s'y 
y
s'3r S r }S r7s  y } r = r  s'3r S  *[ >]	A0y S
{0 	
RTS'  [-X_\[ 8]']
[8 ]  ys'3r ~.} s's'r S#L
  [ >]

xs'3r S s } r    r ,}S'
j
{H
{l 
j -O-  
}8~. yHy  s  r
 .7}~L y   ~( r  s' } s   . yx . srxMs   s's'3r  yx  s Sff}8 xMs %[-[ 8]']rxYs }8(~ rw
{H
X_[ 8]   yFs } s   .}8~. ys'3r  x    r 0}8M32 rxYs S y  y  xYsy%   t%u  [  3r S r
 F[ 8]
j
X_\[ 8]Y`	t%u v ]
t%u
r } x2s'3r S rffy S r  r	y S y ~(~.}S'  } xw  r ,}*S'
s'y  yx ~ wYr%s' } s
j
{
{l
{l
RTS U  [X Z [ 8]t%u%]
[  ]
RTS  [ B2>] } xws' } s }8~(~ s S rr2s'r S'0	}S r  r ~(~ wYrffx3rw
jb  '"L- -L-(
j
{
 '3 r  yxs'3r	ys3r S  } xw  s' } s  [ >g]
   ys' } s RS'[ B2>] . x3ys  r ~(~ wYrffx3rw
xHs' .
j
{
} r  r } x  r }g x3y  x S r Y~ s [ rr [RT}SL\ rx  y } 
]]:y S s'3r ,}8Y73 rxMs S y 
l
y  xYs	yr S%}  } r0wYrffx3rw ~( x3r }*Sg yx  s S}8 xYs   } xw  yx ~ wYr0s' } sy S%}8~(~  '} s .   x3H9 
 x3s'3r  yx3x3r  s  yx0rs  rrx,w . s S   s  yx   } s .   x3	9 } xwgy  xYs 
x3r  r ''}*S(~  [ >]

j
{T
  x   t%u v - r  yx ~ wYrs' } s	s L#.2}8~. yHs'3r } r)y S}8~(~
     t%u v 
  }S s [} ]y
{
3ry S r 
s' . r } x  s' } s  x } x   y S~ w '} s .   x3t%u v  s'3r S yy S s  yx X_[ ]i  L

{ 
x3r  r ''}*S(~ 
   t%u v . x  yx . srxMs   s' X _ [ 8]  } xw RS U  [-X Z [ 8]i X _ [ 8]3`t%u v ] .\}8~. yx3ys
{T
(
~

~

r
Y
w
ff
r


3
x

r
w

{
JJ2TO'0':-:
 &=	M=5 6 
&
	: $fi RTS U  [ 	: t%u	]
H

j l

o 	p(

  s Y r  s'y  3y  s' } s	s3r S r . y  ryrxx3r  Yy S 3yMy3w  yx 
3ry S r 


3{l 
s }8 x  x3fiff  s'3r ,}8Y32 rxYs S y  y  xMs  y*J 3  t%u -  0s' } s\rr S'  y S~ 
w  yt%u  xs' .
x3r  Yy S 3yYy3w2 } 	 [  ]
	: { y  3y  rs' .. x3ysTs'3r } r { 3rx,s'3r S r .J y  r  r  rx  r
j
 s' } s [ '   ] t%u
y  y S~ w    8
` 	  } xw ~(  U x
  [ 
]   

nn8n
j
j
{
 
d 
 x  r2 . y   } ss'3r  r  rx  
[
[





}
}
~

}


}


ff

3

7

Y

.
~
}

r    ]ff  !ff]'
s  r s r syx3r
s yx

nn8n
 s   x } s  ff .	}~ y  rw
y  xYs  '}8 
 . y  xYs  s%r  xs'3r ~ y 3S r2ys'3r  r"
s ff
{,
{0
 rs [ r } rrxYs S y L}2 yxYs  x  y    x  s  yxO] } xw  y F
  ff
  }S s [} ]Ty
3ry S r 
{

{ 
 $} xw  y   x  r2s L%  } r L%~ y  rw  
     t%u 
 [ fi-]     t%u`#	   )y S rr S'#
` 	   }
 r ~(~ {  ss' . r } x  s } s   .\} x  x '} r ,}8Y32 rxYs S y  y  xYs   yxMs S}S' s'y%s'3rwYrffx  s  yx
} xw }3 3s  yxHy  s }  (~( s 
{

U	2

11 6 t%u

*fi+   

 
xs'3r S r ,}8 xwYr S y\s' .7 r  s  yx  r2 S 
y r
3ry S r P
y S 's  .  3S y  r    t%u


{{2|
j
` t%u v %\ } xw&	:s'yr }# xs'3r  s } s'r  rxYs	y%s' .  s'3ry S r   } 

x w ~ rs   rs'3r  x    r
,}8Y32 rxMs S y  y  xMsy* '   t%u 
{


(*)

fi+-,/./0214365&1/7/8902:;,/./0=<",/>/?@3-A/3BC./D/714EGF

HJILKNMPOQSRLT9U*V9V*V URXWNYZ[IK \/I^]_ILK;`Gacb`ed[]fKhgGdKN]_ijZ[`Gk]lgGm/mnI*gGo_pqd/rpqdstgGd[uvpqdxwzyl{;|/IK `
K \/I^]_ILm[gGogGZp}k~pqK_ige] ]_|/jm/K_pq`edCllb`edKhg9pqd[];d/`ed/I^`Ga-KX\/Ib`d[]_KhgGdKN]fijZ[`k@]pqdMylHILKlc  ZnI
 R yI;[oh]fKm/o `GeIlK \[gGKz   \[g]zm/o `eZ[gGZp}k}pqK_ilrGpqeILdlly
K \/I;a`eo j|kg^ R cO

4 
n=fi[;Gzt
 G l  G GGLohc
  l  O
 9[IgebK |[g9k}kqifi]f\/`SK \[gGK
oh     l q Ot/yHILKlRlgGd[uR  ZnIK_z`"b`ed[]fKhgGdK
]_ijZn`Gk]

pqdQSRLT9U*V*V9V UhRXWlYgGd[ub`ed[]puILo
o  ROR   l;  yCINgrg9pqd"|[]fIlK \/INupqo I*bKpqdaILo ILd[bIK I*bX\/dpe|/Iey
`eK I^K \[gK;a`eogdic`o_ku`Ga
]pqLI"K \/I^m/oX`em[`eoXK_pq`edI/m/o I*] ]pq`ed @ O   @ G * uILd/`eK I*]I4gebKfki
Gh=yKp]K \|[]CI*ge]_iK `]_ILI;K \[gGK-o   q O   @ G  n    l   O6;a`eo-gdi^bX\/`GpbI
`Ga  yCz\|[]L
Zi"z\/IL`eo ILj/y@*/o  ROR  lN  Oo  ROR  l
G q O /q G *     y|/K
]pqd[bIR;gGd[u
R  gGm/m[I*go
d/`G\/ILo Ipqdl;zIbLgGd|[]_I\/IL`eo ILj[yq;K `#b`ed[bXkq|[uIKX\[gGK
o  R;OtR   l;  Ot/y
Kp@]]_K og9pqre\Kfa`eoXgohuK `ILo_p}ai=K \[gGK*]pqd[bIz  p@]I*|pGg9kqILdK#KX`xgfi[dpKXIfiup]_|/d[bK_pq`edI*gebX\
up]_|/d[bK`ac\pbX\pqj^mk}pI*]R^OR  a`ogGK;kqI*ge]_K`d/Im[gSpo`Ga
b`ed[]_KhgdKh];R^gGd[u!R  zIj|[]_Kl\[g9eI
o  X    l
  O4y
 ]cI]_KhgGKXI*upd=eI*bK_pq`ed[y[/`e|/o;reILd/ILohg9kK I*bX\/dpe|/Ia`eoNb`j^m/|/K_pqd/r#K \/Im/oX`eZ[gGZp}k}pK_i`GacgGd
gGo ZpqK ogGo ia`eoXj|kg^wp]K `m[gGo K_pqK_pq`edK \/Ilz`eo_ku/]zpqdK `#g[dpqK I^b`Gk}kI*bKfp`dfi`abXkge] ]fI*]
]_|[bX\KX\[gGK
w
Z[IL\[g9eI*]|/dp}a`o jkqi`GeILoI*gb \bXk@g] ]lgGd[u#KX\/ILdK `#b`ej^m/|/K IK \/IoXIk@gK_pqeIcIpqre\Kh]z`a-K \/IbXkge] ]fI*]Ly
 ]zI]_\/`GkgGK ILo*K \/IfibXkge]X]_I*]"go I#I*] ]_ILdK_pg9k}kqiuI[d/I*u&|[]pd/r&b`ej^mkqILK IuI*] bofpm/Kfp`d[]Ly\/Ipo
o IkgGK_pqeIlzIpqre\K
b`eo oXI*]_m[`ed[u/]K `K \/Ilm/o `eZ[gGZp}k}pqK_pqI*];`GaK \/Iup}ILo ILdK
b`ej^mkqILK IuI*]Xbo_pqm/K_pq`ed[]rpILd
l^y
9C2*@*@9lOl  "s G    G  GGS;  ^  ohs  l @ [
*   #  ;2 9   L     GGL
M  -   [
      ^s

  

   2  [     ^   -  o    l  O[

 	 

 l  [     
   z 
o    l  O



  



ff fi 
 

!

   
ff fi  

V

9[#" pqoh]_K*`eZ[]_ILoXeIlK \[gGKzp}a-g9k}kk}pqjpqKh];Ip]_KlgGd[uK \/IuILd/`jpqd[gGK `eozp]d/`ed/LILo `[4K \/ILd
oh c  
 s  l  
V
o  s  l
 

o       s!#l   O

i
\im[`eK \/I*]p@] GK \/I-uILd/`ejpqd[gGK `op]pqd[uILI*ud/`ed/LILo `[y
"/|/o KX\/ILo j^`eo eI  ZilHILj^j"g;{yqeLo   c  
s  l %$ o   c
  l
  O /y'&ILd[bIo  zc
  l  Oo   cc
  l
s  O yIbLgGd
K \/ILo Ia`eo Il|[]fIz\/IL`eo ILj 4yq*K `"b`ed[bXkq|[uIK \[gGK
o  _  l  Oo  _  l ^    V
gGo K;g  `aK \/Ilm/oX`em[`]pKfp`d#a`Gk}k`G
]pqj^j^I*upgGK Ikqiey
 `^m/o `GeIm[gGo KlZ  [oXI*bLg9k}kK \[gK
s p];I*e|pqGg9kqILdKK `^K \/Iup@]|/d[bK_pq`ed(*) +
 , yi]pqj^mkqI
m/o `eZ[gZp~k}p]_K_pbo I*g]_`edpqd/r[KX\/I"ge] ]_|/jm/K_pq`edK \[gGKo  s  l  /gGd[uxm[gGo Kg  
 cI^b`ed[bXkq|[uI
K \[gGK
o   ^s  l  
o  ^s  l  
o   sl   O
O
V
 )    o   ,  l  
o  s  l  

-/.

fi0#13254!687:9<;!=?>/6/1!@7
ACBD2=?=E6/1

FHGJI/KLKNM!O%P!QSRT/UVWCRXK#YTUK	RXKSQLZ[U5Q]\DRQ_^a`]c b IdUefRgKRUihfjlk*mon:pRUYZqWCRXK#IqYT/O%P5rZ[QLZse5Z?KLYtSRP!QSRT/UV
\<ZJOqMKSQu^IEv/ZJQ_^IQwWyx kzRXKuv+I+r{RXe|n~}<^5MK[V
QL^!ZUM!O%Z[tIQLT/tuT/UQ_^!ZJtSR/^5QL^IUe~KRge5ZaTdQL^5RXK
Z?MIQSRT/URXK#K	RO%P5rGi:tLjSW#mon:Z[UYZ/VQ_^!ZP!tLT5rZ[OTYT/O%P!M!QNRU!:tofjWsm:tLZ?e5MYZ?KQLT
I%KSZ[tNRZ?KTYTO%P!M!QoIQSRT/UKTQ_^!ZT/tLO:t  ja  m:T/t<v+IdtSRT/MKYTO%P5rZ[QLZwe5Z?KLYtNRP!QNRTUKJn
RIdUGKNMYL^~e5Z?KLYtSRP!QSRT/UJn<Z?Y[IErrQL^IQ%Y[IUZie5Z?YTO%PTKNZ?eRU5QLTQL^!tLZ[ZPItLQK[qQL^!Z
M!UItLGPItLQq?V|QL^!ZqU!T/U!M!UIdtLGPItLQ%EVIUeQL^!ZqZ?MIErRQGPIt_Q c nqpRUYZJCRXK*RU'hfjl` c b moV
\<ZYT/UY_rMe5ZsQ_^IQ:` c b RgKHZ?M5Rv+IErZ[U5Q#QLTw c n:K	RU!%}<^!Z[T/t_Z[On?*QS\<RXYZIdUe%KST/O%Z*P!tLT/Id5R{rRXKSQSRXY
tLZ?I/KNT/U5RU!V!\<Z/Z[Q?
:tofj :  :  c   my





tofj
tofj
t  j
tofj

: 
  
 
 

 
 
  `
  `

c {    ` c b m
  ` cb m
c b    mE:t  j      ` c b m
c b    mE:tofj     mo

lUT/toe5Z[t*QLTiK	RO%P5rRG'Q_^!ZstKSQZ!P!tLZ?KLKRTUVtLZ?Y[IErrQL^IdQU!T/U!ZqT]QL^!ZqP!tLZ?eRXY[IQ_ZJKSG5Ow8TrXKRU 
T!Y[YM!tIdUG5\#^!Z[tLZqRU  `]c b    ni}<^!Z[tLZT/tLZ/VQL^!ZJP!t_T/I5RrRQSG'Td  Rv/Z[U  `]c b RgK
Z?MIEr3Q_TQL^!Z<P!tLTI5Rr{RQSGqQL^IQQ_^!Z]ZrZ[O%Z[U5QoK:e5Z[U!T/QNRU!Q_^!Z+jeRZ[t_Z[UQ[mYT/UKSQIUQKKLIdQSRXK	GsKNT/O%Z
PItLQNRgYM5rXItYT/U5/M!tIQSRT/UiTdU!T/U!M!UIdtLGaP!tLT/P8Z[tLQSRZ?K[n<lQ*KS^!T/M5rXeZwY_rZ?It*QL^IQEV!GaKSG5O%O%Z[QLt_G/VIErr
KSMY_^YTU5/M!toIQSRT/UKuItLZ%Z?MIErrG'rR/ZrG/n}<^!Z[tLZT/tLZ/V
QL^!Z%P!tLTI5Rr{RQSGTIUGT/U!ZfT#QL^!Z[ORXKqI
YT/UKSQIUQEVZ?MIErQLTqTv/Z[tQ_^!ZwQ_T/QoIErU5M!OqZ[tT#YT/U5/M!toIdQSRT/UK[n S~ Z[Qe5Z[U!T/QLZqQL^!Z%YT/UKSQoIdUQ
\#^5RXY_^aRXK#Z?MIErQ_Ttofjf+  ` c b  qm:TtIErrn
}D^!Z*rgIKSQKSQLZ[PRXK#QLTKS^!T\Q_^IQ?V5R]  RXKZ?/M5RvIErZ[UQQLT< < j  moV!QL^!Z[Uit  j    m
c
 
jE  mo

:tLj    j  m  m
 
c





tofj  g j   m    j  m    m?tofj   j  m     j  m    m


c|
c8
?E?[:t%j  
d jS   m[    j  m    mq:tofj    j   m  m
 X %E?s    jlMK	RU!}D^!Z[T/tLZ[Ong//KNZ[ZsZrT\m
  
 j?  mo

}<^!ZtoKNQKNQLZ[PRXK%K	RO%P5rG~P!tLT/I5RrRXKSQSRXYtLZ?I/KSTU5RU!8n}D^!ZiKSZ?YT/Ue~KSQLZ[P~MKNZ?KqIdP!P5r{RXY[IQNRTUK%T
}<^!Z[T/t_Z[On//nClQRXKaZ?I/KSGQLTKSZ[Z'Q_^IQ   jS  mqRXKiI~K	RO%P5rZ~/M!Z[tLGT/t  {l/ j L  m  ?E 

D  j  m   n
'Zs\<T/M5rXefrR/ZqQLT%KS^!T\QL^IQ

:t%j   j  m    jS  m    m::tofj   j  m{  m:  +
 c L 
\#^!Z[tLZs}D^!Z[T/tLZ[On/MKNQSRZ?K<QL^!ZrgIKSQ<Z?/MIErRQSG/n]}TqP!tLTv/Z*QL^!Z#tKSQ<Z?/MIErRQSG/V!\<ZKN^!T+\QL^IdQT/t
IErr|VQ_^!ZKSPIYZ?K  <IUe    N 
   j  m  <^I?vZ%QL^!ZiKLIOfZ%OJIE5ROwM!OfZ[UQLt_T/PG
PTdRU5Q?VUIO%ZrG  ns}<^5RXKRXKP!tLTv/Z?eGc I/Y_\#Itoe!KDRUe5MYQSRT/U:QL^!ZY[I/KSZuRXKQLtNRvRXIErrGQ_tLM!Z/n
}<^!ZeR{Z[tLZ[UYZZ[QS\<Z[Z[UQL^!ZjamSKSQ%IUe'5QL^~Y[I/KSZRgKfQL^!ZiI/e!e5Z?eYT/USM!UYQ   j  moVH\#^5RXY_^
IO%TM!UQoK
Q_TwI/e!eRU!qQL^!Z*U!Z[\YT/UKSQ_toIERUQH  n}D^!Z[tLZItLZQ\<TP8TKLK	R5RrRQNRZK[n#RtoKSQ?VdR  { V
SEEoEo
 E
 Eo
 	

	 fiffN	 H ! S  [
 	 S S L  		 !	 "#$S% '&
 ff
()&

fi

6
'
7
:
8

9

;
>
<
	
=
?
 _ ' ffS fifi*,+.-/)0 2 1435

'fi@BADC EFC

G	H

fiIKJMLMNPO.QSRTOMUMVNPWXJMLMNZY[JM\M]#QK^MQ`_LMaMUbO.ced
fgMhi`km
j ln fpo lrq h l f$gso l iMhtvuwxi l fy n o)isf n iszst n z n i|{ l w}yh~ n o)i l fgMh~ n o)~M~'hify$w4zD|weo)isf	
uw4~,s)hf
o)iMTfgso ll f$hwefgMho)i|{s|uf
o)w4i%' kZ fgso l o l iMwxf,fgMhu n4l h4 n i|{o)i|{shh	{XfgMh
Myw4hyf
zth n yhFfy$z4o)iMfwMy$wxhu n i,hF n  l h'wxyT}Mffgso l {swh l iMw4f~ n ff$hy	e|h	u n  l h
thKfgMhisiMwetmfg n f!ypr : 
$  p  ) r  	FX)  fiyr : r$>X k :  fieo)i|uh
|wxfgwefifgMhMywM{s|uf l o)ixMh l f
o)w4io)i|u$)|{sh n,  n uf$w4y	xo)fFo l oy$yh)h n isf nxl fw,tFgMhf$gMhyfgMhwxfgMhy
fhy~ lFn 4yhh4
 hu n iiMwetMMfFh4hyzsfgso)iMfw44hfgMhyfwuw4i|u$)|{shf$g n f
fiy  
>  Dfi:!|y 4 | r}fi>y r  >    fie!. x| 	 k j   	j 
s
M    k
MywexoiM n yf
 hiMwt n {M{syh l$l fgMhXo ll Mhw2!uw4~MMf
o)iMfiy  rF>'w4y n i n yso)fy n y$z,'w4y~s n Fw[{sw
fg n feth"~ l f q y l fo)ixh l f
o) n fh"fgMhF|hg n xo)w4ywe!y  rF>'w4y l ~ n :F j fio l w4~,h l su$ohisf
)z
l ~ n j   n i|{)hf,hfgMh l hfFwefi~ n o~M~,'hisfywxz|weo)isf l we M  fi l$l M~,h n i|{
j n yh l f n shX'w4yF%Kz[{sh q iso)f
o)w4i%fgso l ~,h n i l f$g n fw4yh4hy$zmkj  thXg n 4h	k j   %	hf
 hfgMh l hfwe l w4yt"gso#u$gm  uw4isf n o)i l fgMh,uw4ie
Mi|uf,|  reoi|uh	k j     wxy n :k j 
th~ l fg n 4hf$g n f k	fi wxy n %   eo)i|uho l"n u$)w l h	{ l hff$gso l o~so)h l fg n ffgMhyhh  o l f l
l w4~h l |ugf$g n fw4y n :k[j   n i|{'w4y n :%   thXg n 4h k   hfF  
%|hf$gMhF'w4y~s n
 )(  r)   
 4
gMhX'we:)wtoiMMyw4w l o)f
o)w4io l iMweth n4l zfwMywe4h4
 
	
fiff"!$#  #%&  j #'()#$*,+-/.0'   #%&"!$# 2 1( 1K  
) 1 #%&436 5
#'(7#8#$*9:;<4=fi!$,%

!y   rF> 

!y   rF>    
.  [?	fiy   r}>
 > :  

@ACB )h n y
)z4  
 l$n f
o lq h l fgMhuw4i|{xo)f
o)w4i l we B w4yw2 n y$zEDM
FHG| n :)wtoiM l fw[uw4i|u$)|{shfg n f
fiye  
  
r>  F4 eo)~o: n y
)z4zgMhw4yh~IG|KJ0G n i|{Tf$gMh nxll M~,Mf
o)w4i l wegMhwxyh~IG|KJL.
thu n i}uw4i|u$)|{sh,fg n ffiye  
    F4eo)i|uhfgMh,uw4ie
Mi|uf
o)w4i}weKf
tw n4ll hy$f
o)w4i l f$g n fFg n 4h
Myw4 n so:o)f
zMF n  l wFg n4l Mywx n so:o)f
M
z Fx	thKu n i l hgMhw4yhN
~ DM FOfwuwxi|u$|{shfg n ffiy   rF 
fiye  
F>[  
[  
P wetyh	u n :fg n 
f Q o l h	xso n )hif}fwTf$gMh {xo l 
Mi|uf
o)w4S
i R e   z l fy n o)4gfpw4y$t n y{

Myw4 n so:o l f
ouyh n4l w4iso)iM||thu n if$gMhyhwxyhuw4i|u$)|{shfg n f
fiy   rF[  
[   

fiy   rF>[  
M  fi?	!y   r}>[  
[  
e >   

z,gMhw4yh~TDMFO n  n o)i%sfiye  r}>  p%e  fiye  r}>gMh{sh l o)yh	{h  Myh l$l o)w4i,iMwet
'we:wet l 
 hiMwt l o)~,s:o'zf$gMhh  Myh l$l o)w4i!y   rF>[  p|[%!
UV

fiWYX[Z]\^`_ba/cde^Xffi_gihjZkdd^X

l8mnonpq
rq
nfistu-vfiwCxfiyz|{~}b27}fi,}}0]K/8$9y;,}b 2b
  2]}"$,
    {Y2]KM  Mb   {Y  MA
7"C;K2H)"$,z8yz2y)8"]bA2"]-)),z`zy]($)"MyKz()HHzA)yzA"yz(Hz
Hyz7-}~2"[,,by8"])y-Hz(;H
l8mnnAw6j(C]()]CA(HC22/~( ( (/HY`AYH(
YY(/(2](
(0]-](9)]HYH](HA2YHA
$/]209Y)(fi  Y](4H(H]-Y/Y~H-4yHHHzA"y0
 ( (YH|;
fi0(fiA9H8bH97-
0|(9]CH`8((
(A)()]2A9H47(C(AA2E]K]|fiAC(]
-7  2(b(~A)()]($9)]2(~7Ab)YAH9
(2(AH$2]H-H(9AH(4(2(]HY9 ( 9;|H|;
)/)]]H-H
j]  ]
9MA9-7]((2  [;](((9
0(//(C[]A]9A
(C  7(H(NY]99H$
;AAY|,;),Ayy0H/](]A
A(H](C(7$]((9A((Y(4[]AY]A]A4]H9
](AH7/A(H]M-](]YY]A]Y$7(H]9AM4
(2(b2](A  ,;),Y|]9AE  -;A A0  (/8AA
 
   A(H] ~(j9
 (
fi  YH(2  /8A4]H9
](AH

 
  2A]H(](AH
]9
(4bA[9H)b`(464bA(H~ 9(A(H]/(  

(H ;9  ]/S8A]H(  (C)29)(7] A9H8   M2  
]
  /
S(H b     Ck(  /-)-|2(0CY  [(H
b   k fi~/2  C  ]A(]((N0|H7/7]-H9HA)(
((]Y 9 (H/Y(7/H (i(  0
HHH /
A2 E]K  M]9Y  M
 
`$ 7Y9A(H]
 
fi  /N(

b  k2 ]Kfi     7Y$7(T(7($()0]2(
Ab2A 
(H$
CH(E99HC(](]C0|j9 jH(H


(/b  22~b  {Y22]K   A2/|(C(7(6   226k
)-|~(06b   2 8]K8fi86k$4HA72 8]K8fi 6`A(H]
-]M;  H
A]HC(8HY6Y()2M]KE  M Y
A]H889A]
0 ]MAH4H$,fi(
 ( `(2()   YH97(
AA(HC9]H0Y0(7A0$(8-  ( 6k|70H
 k]H(Y(/HH]9
 ( $H
 (  2()  H7(0
 (
 kH2 ]K]fi7 A](Y9YA
(
 M  0b/(C(]--M
]]/|]H(0$A0$0|HY`2H]4]Y7(2$/]2
/]HY9]
4(0]- 
9 9)- ` j ]9A   ]H9H(7/$`
8(H(
 /((H(
A /((
7(Y]9
87CA 99A
0CH/HH
7(7(HM;];]  (
(8)0((H(]7H A`CA(H]|j9  98](A  
 -  ]-

7YA]E7AA
 ~M]A]fi]Kfi7~(H(A)(
A] (EA A   TH HAb((]--  Y]( 
Y7
H8$ 9H](
fi(9]--0j]9 
YY]( 8-fiH(H$)(
 C(]( $(M]A]Y(4A[(H  ]/7C7  /
 9



  
	
 fffi


%'&

*

!

)(

+



/. +0

4=&>< 4  
	
 64 fi  @? 4
4

Dfi
;F

fi

4  	

 ff4 fi

 	
	 fffi  fi

T

, 
	
 fffi

- fi

*

%3

A? 4

'45 
	
 647fi
24  
	
 64 fi 64

C4

fi	

#"$


21

98
:4 

	 ff4;fi
24  
	
 64 fi
=B

Efi GF
IH@J
Kfi
L 
	
 6fi
*
H J  fi AM
 H J 
NHOJ  P 'Q
R4 SH@J
:0
K4 UHOJ
6VW
XZY

fi[2\^]^_`bacd`^e^f	_g\^]^_ih:\^j^kla2m^ano]^p^e`bq7r
s^tuwvx;vy{z|y~}S}x;}:5	
	
67
6Kx	zudx7}yR}^=tZ:x	y~y~^S6uw7^6}ffu;CN@7y~wZ}x7}>yl
y~Sx7}uw@)x7i57	
	67:x;}yi  oy+wZtR:x	z|z%v^^}Evuw^
Sx	%x	tu^ibuwt+}y
}9u= ^u7zo@+^Z
K}^xw^s^}y~uwK}x7}9}^^uw^^x;ts^t
yZx7}
)x;t^uw}9Z}y~uw^
y~i}^
|DOylyC}^EZxwEv
Zx7+}^+}uw}6x	z^EvZt9u72suy~vz~:%x	O}uD^uu5+}^)s^tuwsZt}y/

u72=xw}^Z=t6zx7}9}u!5	
	
67ZAyOy/ZsZZ5}Lu72RoK+Zx7=}^Zt6uwt)6uz/+}x;}%}^
s^tuwvx;vy{z|y~}Ru;bEuwt+Dy~Z}z~Kzx7tDff7y~wZR}x7}5	
	
67x7}yK'y+vu^

x	%x
tuwvRuwKy~ZsZZ}:u;i7y~6=}^:s^tuwsZt}y/
Lu79x7R6z~ZZ}Kx7>y~}ff
t6zx7}y~uw}uD7
	
ff;EZx7v!^u5Z'y~ZsZZ5}z~iu7}^Es^tuwsZt}y/
Cu7Ox=y|$ZtZ}96z~ZZ5}
  ^}^9y|$ZtZ5}ZwZ5}6%+bff6+  ff
	
2x;txz{zy/ZsZZ5}	%@^Zt6uwtw}^9s^tuwvx;vy{z|y~}=}x7}
}^Zt!y^uR uw:xy/6z~ZZ5}=x7}:xz{z}x7}
A}uwwZ}^ZtOy/}S57	

67@x7}yl
Ny:x7}u5}
ffL d@y+vuw^^}^=s^tuwvx7vy|z|y~}du;}^=6^}Zy~uwx5y~uwv6y~^xzlw2t6zx7}y/'}u
^^
'
	

ff;@^Zt)x7t=  ^ %x	^2u;}^
)^uu5y~^+6z~ZZ }ffZu+}^)s^tuvx7vy|z{y~}=u7A}^
x	y~uwv6y/^x	z9x75^Zt@y~DxCu^6zy@x7}Au}     ffo=  A@y}Z^A}uE)x2wu

}uy~y~}w@^Zt6uw9tw}:^=6:}Z$y~uwx	y~uw7

	ff$ 5$N~)xEx5s^}uw}y
s^tuwvx;vy{z|y~}K97y~wZ
^xw%
y~t

y~x	z|z~w)x;ty~x+su5y~}y~uw'}us^tu7w9@^ZuwtZw^
 9    7 ZZG
 	
+	 oG$ 	%76+|iGS27 i|
 9
 	 %| wKfi d  w d Z ff 75Z| A i  ff  
9 $
 - 5! 	)
ff fi ffG 7
67"Z7+ ff#ff ff76G$G> 7G &% Z'5w 9  67;');!:567"Z7EG)('7*
|
, +./#- ! 59Z76+| 02143 16587fi9;:!< :  !=>65! 5w9 5= ?
 Z @ ffB A
C wDff ff G7  6$ 
 5w EoZ7:wG2
 GIF H E 9 7 JFG 7C Z5Z|;   E7* 5w 5C  ff # 6L KNOM |99 5 : PZ^
 ?
G+5; QZG ff 	 ff 7GR S F UTV5
W t X 
 Y 9  [Z\ 7]_^a`cbed"gif 7h ]_W ^ajt`cX!bed" f Y k m   SbF  l knm \po  SbF 
gqh \po
Z \
 ) 5L w7+Gw79  ff fi ffG 7r 
s 	" t62
 u ^+@y~}^uw^}z~u5u72Z^Ztffx	z|y~}}x7}  Z}y~uwx	z|z2}^6uw}ffx7}+vu7zy~  
u}x7w} v i + /- N xIv  ff y W tuwsuy~}y~uw{ z+} |b
W t ~X M  
 Y 9   7 ]_^a` W t ~X M   Y 9:^=   =V  W t ~X M  Y 9 ff
h
\
 uw}%}x;}@Zx;^^uw}@
xwy|z~:}ffxfiw@z|y~+y~}ff@u7 W t ~ X M  
 Y 9K)7)   2xw G!F wu
A}u F v
Zx7
}yA6^s^t
W y/u:ZsZ^uw  x7L}^%7x	z~^u;  
ZsZ^uw+}^^u7y6%u7 G$F  %u7@ZwZt

x7s^sz~y/^ tuwsu5y~}y~uw z+N@9wZ}
W t ~X M  
 Y 9   7r ]p^` W t X  Y    =p  W t ~X M  Y 9 ff
\

h

KKZx7^u7 }6xw}^=z|y~+y~}Kxw GF u5
!W }u ^F  Y 9ud ud}yZ W tusu5y~}y~uwz+^@^
5suw7r}]_^^a`"
b#
d +f u;}^!F }^ZuwtZy~sz~i}x7W } tX  LHiuwtLuw}^ZtOylwA}^'Z^uw+y~x7}uwt
 ZZtu^ff x;t}@x$u7$}^s^tuwsuy~}y~uw:}6z{zA@Zx;+y~w^uwt%}^u5
g h k m \po  S$@uwzv
Z \
6uwsz~Z})
6ty~s^}y~uw%}x7}%x7ty/6uy}Z}%@y~} + /- AZx7=^u7 x7s^sz~!sx7t}vA}u+wZ}@}^

y~t
t
z~}



fi$q'wq##qVpc#

#Nc6"n_""#
;j)#jC#fijVjCjj4e2j##,jq;"6*jq2"jjUifinjqC4
 #B#Bl#fie8BrB"B)qBLwBj;jqwqj"Vje"iB4B#L2}qpww#>ae
jL"q'Bw#"qwBj!q#w4fijjCw#jeBqL#jR#qfij;j4jV
"I!i4qCNeR#;"4#ULieq#B#"C;j;"'qB;B"
#laefi"j"'Nq")B,jrjN,"2$fii[CwN2"q**
 #L,"jpj4fij#V'4#jL>aRq[2j#N")qqq2a,wj.  #
RaeB4"Cwjq2lwBew4Njwwj#,4"#"#ja!"j
jqBc#U
 ;  Bi4Cw4j
 6)  
 'q";N#j#2
 	ff
fffiff4
 ffffq
fiLlw 2#"caaV'"LLRB#B4L.#j;j },pi4qj#r
qB4BV

je"Nq'
w#i"'wffff.4'D$!#"$w%fiD'q'&,j	()(+*}-,)*.&*"e!l njj
.;q4##q#j

w#i"'wB*re#i;/q80ra'jV#/q1;B2 2fiB*;#%3ff.cj#4444Vqrae
"#42j#)"BjVVjV4ffe#q*lw;2rBiqeiL#"Rjj#
ae#i j4B"} 5qq#
 5"#i"*eV#2Vjj4
 675ff5B##i i4Bi"
qjIqjB$
 
a"fij)#B#;qjpw#j)q"fij>aC,r9
 8V#D*)j#
 #fi: ff*;$fi*_, <j*
>
 =2D ?.@ *" *A*
ae*!
 B) ;*C
 =)E
 D F.GH#4
 ffIq#"eff 
ffI3Jqff 
ffq
,$q"*	/q8qNij##Bff2 w#i%3ffKffMLON PN Q=R* SN (+TqUN *A*63fi2V=*
W <RX{3 "#"% Y)ZX[#$#  q4Bq#)4'VNB\0R8B'j"
."Vr>ff%3#ffeVfiff*3]Vi#"ff#"wW<N,j	()(+*}##B#Bl*N#)jj#Ne"
."VN)^%efffi_8Vi N"
N#"

`<j:"qAYraXi3" RaeB4 N# njj

Nq4CVNp,^%ffffIb Ljqq)#Lqq4Bq#q7c we q#"a4Id
qR#2 eq"j4q4jC26I,rNBi!j##fi:ff*#;q),<j*\=2D ?.@*
j3 *f*
B#*'
 B) ;
 =)E
 D g.GH#qqV4
 ffSJbfifffffiq
2aeV;nB42 2aeV9/c  hff#L,j"!iw*j# !j*fi#*$,)*.&*%"e
.;q4#RaeB4jj"w;q4##"};
"fiBV")#%3KS
pje"B4B2#"BjLq;q#ff*_`<)"E(jff*
)Vfilkbm#."ffSJ$ffq
"fiBV")B02B"jV/c18b2 !q"lnl%ff*B#fi8e.#4#Bq'#qwqj#"B4B
j <o
 e\
 #",2"$+e*Cgl%.5SfiblKS3J:fiq
pVq0B2 p /c%3ffff  Lw#j #Lj##BqIwBj 6B 6 2iqq"
/B# 0l qB#r*#6V)B42 .44eVV;4sq,qjV,).&*%"#!w4"j*+#\:"at)+<%fi(*
. Dfi"$#eqV fi.iS Jbfiff
qRaw)#;jj"2#jnjq8fi"q

uv

fiwxyz:{}|~i{3z:-xyzEx||yb{}.
dWl)#b#s#7%l%ff%^ff.Ab.-A[R.lo:ff+.l@..Ab9Zff	.R.@a.4
	.>.)l!l	.[}%.f)
dW!d	-	.4	!%dldffff4ffd3f..:l%3ffff%l.ffR.aff)
.C)3jd.jjds.M@fffff7Z)R)WWf)a)f.)!3f7R)%#AASffl	M.bff}
Qa.44l!4%3ffff%9d	R)b+ffSf.`7ZE3d))ff>fW)WdWdff
[W))f#ZsP^E-.)$
Q`!fUff>)Wfffd	_.W	}%ff%E37!))ff)	ff$)Rffffff
)fffR)Wffd).MffA+.#ff^.)#%'.[-A +ff#:+A7#%@-Q .ff
4.	3ffff
Q`!fUff>)Wfffd	_.W	}%ff%E37!))ff)	ff$)Rffffff
)fff$ffWffd)^`ffA+.$Wa++ -#ff  Ao:
 ff ffA: ):+3fdff:
 W%ffff3ffff
Q.
	s4l%ff%^ff7dWE.h)fiff%WW	%)ff)a.3d$	W3jW)))^).
oA@.\.#>^.:A)ffj  	ff3ff.

QSff	!#d-3d)44}!d -.j734!#%ff%ffff` .ES	d! ))	ff
)3S  )^
  
 V.4%@f.+:+#%34ff3b
QSff!CQ3dl)4h#C -.jdh!%ffff%RRW$)ffWf!ffdWdff3)ff.jjdWd
)Rff+.)ffWff^W.%>ff)-Eff.!
QSff!4d"Q3dl)4C#!d4 - dh!M%ff.#%RRW$)ffWf!ffdWdff3)ff.jjdWd
)>. ffWffPW%))lff)ffffff#UPMi..d$sfi&%%#ffQ
.
 Afff

-3d)4}ff!%ff%lQ.3df^.'ff%W)+ffhdff.f^.C).j dWffC A @ff}):+3fdff:
(*) bffff}
ff3S S.%ffbff%3+ff)E.`7 )ff.'W%.``Wf3	$.fl+  @ff.3, @.-    ) }%
ffff3bff

ff3ff.R%Sb%0/)1W%.'ff'E3d))	32SE#dff	Rff!S 4Wd
Usj%R4 	5
  6A7
 	 #A)  8 .%$ffA%$M433:ff}4>W h)).!Wfffff
[)

ff3: R#ffff+9Z) .Wdff3d 9ES	d!$+))ffE)b^`3SM)^:Ms%
ffff3bff
ff34#RM%ffffb%-ff)%.`7>.fW)`7`7 .-	)ffE37aO	W%.)ff
R:!Vs#j4-94 %  :. ; .\^)	)++ < :+ffAAA@ < .:=#+ffAfA+%ffV+  @ 
43ffff 7> -ff))@ ? )Wf.
-:}ff.C )%Af .^`)	 @+  9ffo jf.4##ffff4

ACB

fiDFE*G>H@I3J:KML@NCO0I0E@PJ"QSRTGUNCN
I0E
VWXYX[Z\C]^7_[]>`badceXgf3Z\ih]j@_>k7_3lnmCo0o0p*qn_'rsX[W0tuwvyxzW0\Fcf@f@\iW
{|u[}~ciZF\iZCc0W0h>u[h@t_"hyZZX]_[]@uwvi]
 _[]+`0Fc\iW0@C]:b_Ml!@_Yqn]T+iC7wii'z0z'0+Ci.5n.Y.#
1FYn
0y#3..z0z5Mn3w@1 
0]0f@f_3mC0
m
_CW0\it>chV1c>x}=ch@h]
|chciZW]  r7]3|chU\nchvuwivW_
V>@@\it]j\
_[]a_F_3lnmCo0>qn_"M@Z\iZxzZ\iZhvZ7vXci_M0Y~#'z'n
]04l!>qn]@>
*0o>>_
cf>Xwc0vZ0]M"__'_lnmC0p>qn_nF0Y.*n>Y.+i||z@. _:h@tXYuw#i\nchXwc#u[W0hu
+0zY0zn03n~>i|z.]>^W0Z\d:@>XYuwvc#u[W0h.]yZk:W0\i']mCo@m0_
'vZ0]'1_^7_[]@`SFc
uYc@]a_lmCo0>0q_FF71n.w_uYXgZ0]yZk:W0\_
TuXwiW0h]_'lnm
o00>qn_":\iWc>uYXuw#uvfiX[W0tuwv_M Mz03iz
w[0'n
]>*]4|m**|_
:c\#uw]3j@__[]`:ZhvWe@#c@]@r7_'lnmCo0o>qn_Fhi@Zcf@f>Xuwvc>uYXYuw#Wx:}~c
{>ug}7@}Zh>i\iWf|=iWu[h@Z{Uc0v
\iZCc0#W0h>u[h@t_Tiz.n'003@|#dT0iC0z7Mn3w@0]'0]m@_
"ZCc\#X]:j@_lnmCo00*qn_=+i||zwzMn3w@=wzCg'+3z._~W0\t|chV1c>xz}~ch@h]|ch
@\nchvuwivW3]  c
XYuYx_
"ZCc\#X]jU_lnm
o00o>qn_:\iW0c>uYXYuw##uwv#Z}~ch|#uwvxzW0\Fh@Wh@}W0h@W0iWh>uvfi\iZCc0#Wh>ugh@t3+r#@\0Z0_+h\nc0v@
}~ch]|fi_|j@_[]>'Z0ZCi@Z0]@a_>j@_[]>`MZu[iZ\
]*fi_@l!@_Yqn]>
e3:4iz.n'0z0'Ci'n
n.Y.#1FYC0#3..z0zs*1 00]Mf@f_+0
*@mCU_
MZf@\#u[h|ZCugh0*F'n.z=*0]>7_@0c
xzZ\Fchj@_@"ZCc\XlZC@_Yqn]>W0\it|ch
V1c>x}=ch@h]'|chU\nchvuwivW]  c
XYuxi_[]m
o0o0@]>f@f_0oo
|mCU_
"WXYX[W*v']j@_:_4lnmCo@qn_"@W0@h@cugWhxW\du[\iZCvFu[h>xzZ\iZhvZ0_|n=']>C]'p0p@m*p0@_
MZuwv@Zh|c0v]a_lmCo|o>q_4|nn~1+i||z0_:Fh>u[0Z\u[!5Wx  ceXuYxzW0\ih>uwc=:\iZCi.]*Z\iZXgZ0_
0ch@h@W0h]  _[]|`$ZCcCZ\C]>_3lnm
o|o>qn_4|10|0z0M|#+77|30z_"Fh>u[0Z\
u[!=Wx:zXYXYu[h@Wuw1:\iZCi._
0c0#\#u]:_lmCo00o>q_^Zxc>X[1\iZCc0#Wh>ugh@tu[h #Z}~ch|#uwvfih@Z!MW0\*Mc xW0\}~c
XYu  c#u[W0hWx+\iZCvW0th>ugugWh
chu[h@@Z\#u[nchvZ0_F Mz03iz
w[0.C]@| l!>qn]3p00
*0@_
0f>u[Zt0ZX[c
X[iZ\C]'^7_|j@_3lnm
o00>qn_':\W0c>uYXYu#uwv1\iZCc0W0h>u[h@tu[h5f@\iZCuwv#u[0Z1Z{@fZ\T*#Z}~_hV1c}~c
X]
:_e_[]`'Z}}Z\C]0j@_0M_l#+@_Yq]4zw .0i'zC[0.C]f@f_@@0@_FW\ii@
aFWXYXwch']3rd}=#iZ\n@c}_
"c\n#u]|r7_@lmCo0@mq_b1nz5
|CTY. .zfi e7'5FC5l!ph7ZCu[#u[W0h'qn_
Fh>u['_@Wx  c
XYuYxW0\h>uc=:\ZCi_



fi